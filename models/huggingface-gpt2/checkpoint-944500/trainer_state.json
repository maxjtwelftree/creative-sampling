{
  "best_metric": 0.3731182813644409,
  "best_model_checkpoint": "./models/huggingface-gpt2/checkpoint-936500",
  "epoch": 9.998840785301793,
  "eval_steps": 500,
  "global_step": 944500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005293217800032818,
      "grad_norm": 3.587369918823242,
      "learning_rate": 4.9997353377090836e-05,
      "loss": 3.5757,
      "step": 50
    },
    {
      "epoch": 0.0010586435600065636,
      "grad_norm": 2.3269758224487305,
      "learning_rate": 4.9994706754181664e-05,
      "loss": 2.8761,
      "step": 100
    },
    {
      "epoch": 0.0015879653400098454,
      "grad_norm": 2.3957557678222656,
      "learning_rate": 4.99920601312725e-05,
      "loss": 2.5162,
      "step": 150
    },
    {
      "epoch": 0.0021172871200131273,
      "grad_norm": 1.7959121465682983,
      "learning_rate": 4.998941350836333e-05,
      "loss": 2.3501,
      "step": 200
    },
    {
      "epoch": 0.002646608900016409,
      "grad_norm": 2.1284263134002686,
      "learning_rate": 4.998676688545416e-05,
      "loss": 2.2641,
      "step": 250
    },
    {
      "epoch": 0.0031759306800196907,
      "grad_norm": 1.693628191947937,
      "learning_rate": 4.9984120262544993e-05,
      "loss": 2.1942,
      "step": 300
    },
    {
      "epoch": 0.0037052524600229724,
      "grad_norm": 1.6994264125823975,
      "learning_rate": 4.998147363963583e-05,
      "loss": 2.1304,
      "step": 350
    },
    {
      "epoch": 0.004234574240026255,
      "grad_norm": 1.9640440940856934,
      "learning_rate": 4.997882701672666e-05,
      "loss": 2.0949,
      "step": 400
    },
    {
      "epoch": 0.004763896020029536,
      "grad_norm": 1.6641255617141724,
      "learning_rate": 4.997618039381749e-05,
      "loss": 2.0683,
      "step": 450
    },
    {
      "epoch": 0.005293217800032818,
      "grad_norm": 1.644972324371338,
      "learning_rate": 4.997353377090832e-05,
      "loss": 2.0664,
      "step": 500
    },
    {
      "epoch": 0.005293217800032818,
      "eval_loss": 2.0892956256866455,
      "eval_runtime": 46.5162,
      "eval_samples_per_second": 3610.143,
      "eval_steps_per_second": 451.284,
      "step": 500
    },
    {
      "epoch": 0.0058225395800361,
      "grad_norm": 1.519552230834961,
      "learning_rate": 4.997088714799916e-05,
      "loss": 2.0709,
      "step": 550
    },
    {
      "epoch": 0.006351861360039381,
      "grad_norm": 1.6418753862380981,
      "learning_rate": 4.9968240525089984e-05,
      "loss": 2.0401,
      "step": 600
    },
    {
      "epoch": 0.006881183140042663,
      "grad_norm": 1.724061369895935,
      "learning_rate": 4.996559390218082e-05,
      "loss": 2.0197,
      "step": 650
    },
    {
      "epoch": 0.007410504920045945,
      "grad_norm": 1.524307370185852,
      "learning_rate": 4.9962947279271646e-05,
      "loss": 2.0069,
      "step": 700
    },
    {
      "epoch": 0.007939826700049227,
      "grad_norm": 1.4757012128829956,
      "learning_rate": 4.996030065636249e-05,
      "loss": 1.9985,
      "step": 750
    },
    {
      "epoch": 0.00846914848005251,
      "grad_norm": 1.7947090864181519,
      "learning_rate": 4.9957654033453314e-05,
      "loss": 2.0287,
      "step": 800
    },
    {
      "epoch": 0.008998470260055791,
      "grad_norm": 1.620296835899353,
      "learning_rate": 4.995500741054415e-05,
      "loss": 1.9932,
      "step": 850
    },
    {
      "epoch": 0.009527792040059073,
      "grad_norm": 1.8339812755584717,
      "learning_rate": 4.9952360787634976e-05,
      "loss": 2.0178,
      "step": 900
    },
    {
      "epoch": 0.010057113820062354,
      "grad_norm": 1.6608103513717651,
      "learning_rate": 4.9949714164725816e-05,
      "loss": 1.9669,
      "step": 950
    },
    {
      "epoch": 0.010586435600065636,
      "grad_norm": 1.6927753686904907,
      "learning_rate": 4.9947067541816644e-05,
      "loss": 2.0045,
      "step": 1000
    },
    {
      "epoch": 0.010586435600065636,
      "eval_loss": 2.006878137588501,
      "eval_runtime": 46.5495,
      "eval_samples_per_second": 3607.56,
      "eval_steps_per_second": 450.961,
      "step": 1000
    },
    {
      "epoch": 0.011115757380068918,
      "grad_norm": 1.8308521509170532,
      "learning_rate": 4.994442091890748e-05,
      "loss": 1.9888,
      "step": 1050
    },
    {
      "epoch": 0.0116450791600722,
      "grad_norm": 1.5932401418685913,
      "learning_rate": 4.9941774295998305e-05,
      "loss": 1.9824,
      "step": 1100
    },
    {
      "epoch": 0.012174400940075481,
      "grad_norm": 1.4242571592330933,
      "learning_rate": 4.993912767308914e-05,
      "loss": 2.009,
      "step": 1150
    },
    {
      "epoch": 0.012703722720078763,
      "grad_norm": 1.7359496355056763,
      "learning_rate": 4.993648105017997e-05,
      "loss": 1.9745,
      "step": 1200
    },
    {
      "epoch": 0.013233044500082045,
      "grad_norm": 1.5020173788070679,
      "learning_rate": 4.99338344272708e-05,
      "loss": 1.9869,
      "step": 1250
    },
    {
      "epoch": 0.013762366280085326,
      "grad_norm": 1.4757840633392334,
      "learning_rate": 4.9931187804361635e-05,
      "loss": 1.9719,
      "step": 1300
    },
    {
      "epoch": 0.014291688060088608,
      "grad_norm": 1.3473317623138428,
      "learning_rate": 4.992854118145247e-05,
      "loss": 1.954,
      "step": 1350
    },
    {
      "epoch": 0.01482100984009189,
      "grad_norm": 1.5222853422164917,
      "learning_rate": 4.99258945585433e-05,
      "loss": 1.9545,
      "step": 1400
    },
    {
      "epoch": 0.015350331620095171,
      "grad_norm": 1.5765146017074585,
      "learning_rate": 4.992324793563413e-05,
      "loss": 1.938,
      "step": 1450
    },
    {
      "epoch": 0.015879653400098455,
      "grad_norm": 1.6837284564971924,
      "learning_rate": 4.9920601312724964e-05,
      "loss": 1.953,
      "step": 1500
    },
    {
      "epoch": 0.015879653400098455,
      "eval_loss": 1.961235523223877,
      "eval_runtime": 46.5331,
      "eval_samples_per_second": 3608.833,
      "eval_steps_per_second": 451.12,
      "step": 1500
    },
    {
      "epoch": 0.016408975180101735,
      "grad_norm": 1.5174068212509155,
      "learning_rate": 4.99179546898158e-05,
      "loss": 1.9544,
      "step": 1550
    },
    {
      "epoch": 0.01693829696010502,
      "grad_norm": 1.5922508239746094,
      "learning_rate": 4.991530806690663e-05,
      "loss": 1.945,
      "step": 1600
    },
    {
      "epoch": 0.0174676187401083,
      "grad_norm": 1.4376224279403687,
      "learning_rate": 4.991266144399746e-05,
      "loss": 1.9406,
      "step": 1650
    },
    {
      "epoch": 0.017996940520111582,
      "grad_norm": 1.6148635149002075,
      "learning_rate": 4.9910014821088294e-05,
      "loss": 1.9322,
      "step": 1700
    },
    {
      "epoch": 0.01852626230011486,
      "grad_norm": 1.5007990598678589,
      "learning_rate": 4.990736819817913e-05,
      "loss": 1.9181,
      "step": 1750
    },
    {
      "epoch": 0.019055584080118145,
      "grad_norm": 1.7568250894546509,
      "learning_rate": 4.9904721575269955e-05,
      "loss": 1.918,
      "step": 1800
    },
    {
      "epoch": 0.019584905860121425,
      "grad_norm": 1.4664902687072754,
      "learning_rate": 4.990207495236079e-05,
      "loss": 1.9294,
      "step": 1850
    },
    {
      "epoch": 0.02011422764012471,
      "grad_norm": 1.6777172088623047,
      "learning_rate": 4.989942832945162e-05,
      "loss": 1.926,
      "step": 1900
    },
    {
      "epoch": 0.02064354942012799,
      "grad_norm": 1.7478281259536743,
      "learning_rate": 4.989678170654246e-05,
      "loss": 1.9408,
      "step": 1950
    },
    {
      "epoch": 0.021172871200131272,
      "grad_norm": 1.6996266841888428,
      "learning_rate": 4.9894135083633285e-05,
      "loss": 1.9519,
      "step": 2000
    },
    {
      "epoch": 0.021172871200131272,
      "eval_loss": 1.9353572130203247,
      "eval_runtime": 46.6908,
      "eval_samples_per_second": 3596.639,
      "eval_steps_per_second": 449.596,
      "step": 2000
    },
    {
      "epoch": 0.021702192980134552,
      "grad_norm": 1.5108977556228638,
      "learning_rate": 4.989148846072412e-05,
      "loss": 1.9253,
      "step": 2050
    },
    {
      "epoch": 0.022231514760137835,
      "grad_norm": 1.659511923789978,
      "learning_rate": 4.9888841837814947e-05,
      "loss": 1.9096,
      "step": 2100
    },
    {
      "epoch": 0.02276083654014112,
      "grad_norm": 1.7466782331466675,
      "learning_rate": 4.988619521490579e-05,
      "loss": 1.9202,
      "step": 2150
    },
    {
      "epoch": 0.0232901583201444,
      "grad_norm": 1.4440720081329346,
      "learning_rate": 4.9883548591996615e-05,
      "loss": 1.9303,
      "step": 2200
    },
    {
      "epoch": 0.023819480100147682,
      "grad_norm": 1.6429141759872437,
      "learning_rate": 4.988090196908745e-05,
      "loss": 1.887,
      "step": 2250
    },
    {
      "epoch": 0.024348801880150962,
      "grad_norm": 1.4015417098999023,
      "learning_rate": 4.9878255346178276e-05,
      "loss": 1.9045,
      "step": 2300
    },
    {
      "epoch": 0.024878123660154246,
      "grad_norm": 1.4553568363189697,
      "learning_rate": 4.987560872326911e-05,
      "loss": 1.8907,
      "step": 2350
    },
    {
      "epoch": 0.025407445440157526,
      "grad_norm": 1.5687406063079834,
      "learning_rate": 4.9872962100359944e-05,
      "loss": 1.9124,
      "step": 2400
    },
    {
      "epoch": 0.02593676722016081,
      "grad_norm": 1.3934013843536377,
      "learning_rate": 4.987031547745077e-05,
      "loss": 1.8972,
      "step": 2450
    },
    {
      "epoch": 0.02646608900016409,
      "grad_norm": 1.441023826599121,
      "learning_rate": 4.9867668854541606e-05,
      "loss": 1.8906,
      "step": 2500
    },
    {
      "epoch": 0.02646608900016409,
      "eval_loss": 1.9159692525863647,
      "eval_runtime": 46.5554,
      "eval_samples_per_second": 3607.099,
      "eval_steps_per_second": 450.903,
      "step": 2500
    },
    {
      "epoch": 0.026995410780167373,
      "grad_norm": 1.6051620244979858,
      "learning_rate": 4.986502223163244e-05,
      "loss": 1.8932,
      "step": 2550
    },
    {
      "epoch": 0.027524732560170653,
      "grad_norm": 1.4412956237792969,
      "learning_rate": 4.9862375608723274e-05,
      "loss": 1.8806,
      "step": 2600
    },
    {
      "epoch": 0.028054054340173936,
      "grad_norm": 1.490559458732605,
      "learning_rate": 4.98597289858141e-05,
      "loss": 1.9088,
      "step": 2650
    },
    {
      "epoch": 0.028583376120177216,
      "grad_norm": 1.4365718364715576,
      "learning_rate": 4.9857082362904935e-05,
      "loss": 1.8776,
      "step": 2700
    },
    {
      "epoch": 0.0291126979001805,
      "grad_norm": 1.5732345581054688,
      "learning_rate": 4.985443573999577e-05,
      "loss": 1.8752,
      "step": 2750
    },
    {
      "epoch": 0.02964201968018378,
      "grad_norm": 1.491005778312683,
      "learning_rate": 4.9851789117086604e-05,
      "loss": 1.8803,
      "step": 2800
    },
    {
      "epoch": 0.030171341460187063,
      "grad_norm": 1.5242211818695068,
      "learning_rate": 4.984914249417743e-05,
      "loss": 1.8929,
      "step": 2850
    },
    {
      "epoch": 0.030700663240190343,
      "grad_norm": 1.4984562397003174,
      "learning_rate": 4.9846495871268265e-05,
      "loss": 1.8756,
      "step": 2900
    },
    {
      "epoch": 0.031229985020193626,
      "grad_norm": 1.5682624578475952,
      "learning_rate": 4.98438492483591e-05,
      "loss": 1.8757,
      "step": 2950
    },
    {
      "epoch": 0.03175930680019691,
      "grad_norm": 1.5445681810379028,
      "learning_rate": 4.9841202625449926e-05,
      "loss": 1.8748,
      "step": 3000
    },
    {
      "epoch": 0.03175930680019691,
      "eval_loss": 1.8895446062088013,
      "eval_runtime": 46.5337,
      "eval_samples_per_second": 3608.781,
      "eval_steps_per_second": 451.114,
      "step": 3000
    },
    {
      "epoch": 0.032288628580200186,
      "grad_norm": 1.5199373960494995,
      "learning_rate": 4.983855600254076e-05,
      "loss": 1.8753,
      "step": 3050
    },
    {
      "epoch": 0.03281795036020347,
      "grad_norm": 1.6125414371490479,
      "learning_rate": 4.983590937963159e-05,
      "loss": 1.8824,
      "step": 3100
    },
    {
      "epoch": 0.03334727214020675,
      "grad_norm": 1.668878197669983,
      "learning_rate": 4.983326275672243e-05,
      "loss": 1.8587,
      "step": 3150
    },
    {
      "epoch": 0.03387659392021004,
      "grad_norm": 1.91363525390625,
      "learning_rate": 4.9830616133813256e-05,
      "loss": 1.8742,
      "step": 3200
    },
    {
      "epoch": 0.03440591570021332,
      "grad_norm": 1.5011446475982666,
      "learning_rate": 4.982796951090409e-05,
      "loss": 1.8705,
      "step": 3250
    },
    {
      "epoch": 0.0349352374802166,
      "grad_norm": 1.5796926021575928,
      "learning_rate": 4.982532288799492e-05,
      "loss": 1.8506,
      "step": 3300
    },
    {
      "epoch": 0.03546455926021988,
      "grad_norm": 1.7108945846557617,
      "learning_rate": 4.982267626508575e-05,
      "loss": 1.8633,
      "step": 3350
    },
    {
      "epoch": 0.035993881040223163,
      "grad_norm": 1.5082141160964966,
      "learning_rate": 4.9820029642176586e-05,
      "loss": 1.8476,
      "step": 3400
    },
    {
      "epoch": 0.03652320282022645,
      "grad_norm": 1.7150261402130127,
      "learning_rate": 4.981738301926741e-05,
      "loss": 1.8615,
      "step": 3450
    },
    {
      "epoch": 0.03705252460022972,
      "grad_norm": 1.5771830081939697,
      "learning_rate": 4.981473639635825e-05,
      "loss": 1.8577,
      "step": 3500
    },
    {
      "epoch": 0.03705252460022972,
      "eval_loss": 1.8615922927856445,
      "eval_runtime": 46.5781,
      "eval_samples_per_second": 3605.343,
      "eval_steps_per_second": 450.684,
      "step": 3500
    },
    {
      "epoch": 0.03758184638023301,
      "grad_norm": 1.678925633430481,
      "learning_rate": 4.981208977344908e-05,
      "loss": 1.8673,
      "step": 3550
    },
    {
      "epoch": 0.03811116816023629,
      "grad_norm": 1.8070203065872192,
      "learning_rate": 4.9809443150539915e-05,
      "loss": 1.8399,
      "step": 3600
    },
    {
      "epoch": 0.038640489940239574,
      "grad_norm": 1.7179620265960693,
      "learning_rate": 4.980679652763074e-05,
      "loss": 1.8839,
      "step": 3650
    },
    {
      "epoch": 0.03916981172024285,
      "grad_norm": 1.5656359195709229,
      "learning_rate": 4.980414990472158e-05,
      "loss": 1.8344,
      "step": 3700
    },
    {
      "epoch": 0.039699133500246134,
      "grad_norm": 1.7424432039260864,
      "learning_rate": 4.980150328181241e-05,
      "loss": 1.8473,
      "step": 3750
    },
    {
      "epoch": 0.04022845528024942,
      "grad_norm": 1.6372932195663452,
      "learning_rate": 4.9798856658903245e-05,
      "loss": 1.8174,
      "step": 3800
    },
    {
      "epoch": 0.0407577770602527,
      "grad_norm": 1.7333364486694336,
      "learning_rate": 4.979621003599407e-05,
      "loss": 1.8612,
      "step": 3850
    },
    {
      "epoch": 0.04128709884025598,
      "grad_norm": 1.5036479234695435,
      "learning_rate": 4.9793563413084906e-05,
      "loss": 1.8537,
      "step": 3900
    },
    {
      "epoch": 0.04181642062025926,
      "grad_norm": 1.6543670892715454,
      "learning_rate": 4.979091679017574e-05,
      "loss": 1.833,
      "step": 3950
    },
    {
      "epoch": 0.042345742400262544,
      "grad_norm": 1.7239749431610107,
      "learning_rate": 4.978827016726657e-05,
      "loss": 1.8424,
      "step": 4000
    },
    {
      "epoch": 0.042345742400262544,
      "eval_loss": 1.8369171619415283,
      "eval_runtime": 46.5871,
      "eval_samples_per_second": 3604.649,
      "eval_steps_per_second": 450.597,
      "step": 4000
    },
    {
      "epoch": 0.04287506418026583,
      "grad_norm": 1.7075642347335815,
      "learning_rate": 4.97856235443574e-05,
      "loss": 1.8275,
      "step": 4050
    },
    {
      "epoch": 0.043404385960269104,
      "grad_norm": 1.7028326988220215,
      "learning_rate": 4.978297692144823e-05,
      "loss": 1.8344,
      "step": 4100
    },
    {
      "epoch": 0.04393370774027239,
      "grad_norm": 1.8145432472229004,
      "learning_rate": 4.978033029853907e-05,
      "loss": 1.8305,
      "step": 4150
    },
    {
      "epoch": 0.04446302952027567,
      "grad_norm": 1.5542991161346436,
      "learning_rate": 4.97776836756299e-05,
      "loss": 1.8204,
      "step": 4200
    },
    {
      "epoch": 0.044992351300278954,
      "grad_norm": 1.7863481044769287,
      "learning_rate": 4.977503705272073e-05,
      "loss": 1.8293,
      "step": 4250
    },
    {
      "epoch": 0.04552167308028224,
      "grad_norm": 1.5386077165603638,
      "learning_rate": 4.977239042981156e-05,
      "loss": 1.8347,
      "step": 4300
    },
    {
      "epoch": 0.046050994860285514,
      "grad_norm": 1.7479331493377686,
      "learning_rate": 4.97697438069024e-05,
      "loss": 1.8299,
      "step": 4350
    },
    {
      "epoch": 0.0465803166402888,
      "grad_norm": 1.5952035188674927,
      "learning_rate": 4.976709718399323e-05,
      "loss": 1.8053,
      "step": 4400
    },
    {
      "epoch": 0.04710963842029208,
      "grad_norm": 1.7003698348999023,
      "learning_rate": 4.976445056108406e-05,
      "loss": 1.8023,
      "step": 4450
    },
    {
      "epoch": 0.047638960200295365,
      "grad_norm": 1.7568702697753906,
      "learning_rate": 4.976180393817489e-05,
      "loss": 1.7974,
      "step": 4500
    },
    {
      "epoch": 0.047638960200295365,
      "eval_loss": 1.8121587038040161,
      "eval_runtime": 46.611,
      "eval_samples_per_second": 3602.801,
      "eval_steps_per_second": 450.366,
      "step": 4500
    },
    {
      "epoch": 0.04816828198029864,
      "grad_norm": 1.6008641719818115,
      "learning_rate": 4.975915731526572e-05,
      "loss": 1.8254,
      "step": 4550
    },
    {
      "epoch": 0.048697603760301925,
      "grad_norm": 1.6789484024047852,
      "learning_rate": 4.975651069235656e-05,
      "loss": 1.82,
      "step": 4600
    },
    {
      "epoch": 0.04922692554030521,
      "grad_norm": 1.8372867107391357,
      "learning_rate": 4.9753864069447384e-05,
      "loss": 1.8306,
      "step": 4650
    },
    {
      "epoch": 0.04975624732030849,
      "grad_norm": 1.6848104000091553,
      "learning_rate": 4.975121744653822e-05,
      "loss": 1.8224,
      "step": 4700
    },
    {
      "epoch": 0.05028556910031177,
      "grad_norm": 1.7731353044509888,
      "learning_rate": 4.974857082362905e-05,
      "loss": 1.832,
      "step": 4750
    },
    {
      "epoch": 0.05081489088031505,
      "grad_norm": 1.7493476867675781,
      "learning_rate": 4.9745924200719886e-05,
      "loss": 1.8097,
      "step": 4800
    },
    {
      "epoch": 0.051344212660318335,
      "grad_norm": 1.721683144569397,
      "learning_rate": 4.9743277577810714e-05,
      "loss": 1.7985,
      "step": 4850
    },
    {
      "epoch": 0.05187353444032162,
      "grad_norm": 1.8382996320724487,
      "learning_rate": 4.974063095490155e-05,
      "loss": 1.7825,
      "step": 4900
    },
    {
      "epoch": 0.052402856220324895,
      "grad_norm": 1.718113899230957,
      "learning_rate": 4.973798433199238e-05,
      "loss": 1.7873,
      "step": 4950
    },
    {
      "epoch": 0.05293217800032818,
      "grad_norm": 1.8436856269836426,
      "learning_rate": 4.9735337709083216e-05,
      "loss": 1.7852,
      "step": 5000
    },
    {
      "epoch": 0.05293217800032818,
      "eval_loss": 1.7799029350280762,
      "eval_runtime": 46.5939,
      "eval_samples_per_second": 3604.117,
      "eval_steps_per_second": 450.531,
      "step": 5000
    },
    {
      "epoch": 0.05346149978033146,
      "grad_norm": 1.8181498050689697,
      "learning_rate": 4.973269108617404e-05,
      "loss": 1.7886,
      "step": 5050
    },
    {
      "epoch": 0.053990821560334745,
      "grad_norm": 1.8374758958816528,
      "learning_rate": 4.973004446326488e-05,
      "loss": 1.79,
      "step": 5100
    },
    {
      "epoch": 0.05452014334033802,
      "grad_norm": 1.753582239151001,
      "learning_rate": 4.972739784035571e-05,
      "loss": 1.7836,
      "step": 5150
    },
    {
      "epoch": 0.055049465120341305,
      "grad_norm": 1.630520224571228,
      "learning_rate": 4.972475121744654e-05,
      "loss": 1.7973,
      "step": 5200
    },
    {
      "epoch": 0.05557878690034459,
      "grad_norm": 1.5829899311065674,
      "learning_rate": 4.972210459453737e-05,
      "loss": 1.7971,
      "step": 5250
    },
    {
      "epoch": 0.05610810868034787,
      "grad_norm": 1.797606348991394,
      "learning_rate": 4.97194579716282e-05,
      "loss": 1.79,
      "step": 5300
    },
    {
      "epoch": 0.056637430460351156,
      "grad_norm": 1.7891367673873901,
      "learning_rate": 4.971681134871904e-05,
      "loss": 1.7757,
      "step": 5350
    },
    {
      "epoch": 0.05716675224035443,
      "grad_norm": 1.7209174633026123,
      "learning_rate": 4.971416472580987e-05,
      "loss": 1.7719,
      "step": 5400
    },
    {
      "epoch": 0.057696074020357715,
      "grad_norm": 1.8500356674194336,
      "learning_rate": 4.97115181029007e-05,
      "loss": 1.8005,
      "step": 5450
    },
    {
      "epoch": 0.058225395800361,
      "grad_norm": 2.044553518295288,
      "learning_rate": 4.970887147999153e-05,
      "loss": 1.7891,
      "step": 5500
    },
    {
      "epoch": 0.058225395800361,
      "eval_loss": 1.7544649839401245,
      "eval_runtime": 46.5417,
      "eval_samples_per_second": 3608.165,
      "eval_steps_per_second": 451.037,
      "step": 5500
    },
    {
      "epoch": 0.05875471758036428,
      "grad_norm": 1.8179633617401123,
      "learning_rate": 4.970622485708237e-05,
      "loss": 1.7723,
      "step": 5550
    },
    {
      "epoch": 0.05928403936036756,
      "grad_norm": 1.8317607641220093,
      "learning_rate": 4.97035782341732e-05,
      "loss": 1.766,
      "step": 5600
    },
    {
      "epoch": 0.05981336114037084,
      "grad_norm": 2.119749069213867,
      "learning_rate": 4.970093161126403e-05,
      "loss": 1.7682,
      "step": 5650
    },
    {
      "epoch": 0.060342682920374126,
      "grad_norm": 1.9041239023208618,
      "learning_rate": 4.969828498835486e-05,
      "loss": 1.757,
      "step": 5700
    },
    {
      "epoch": 0.06087200470037741,
      "grad_norm": 1.9554243087768555,
      "learning_rate": 4.9695638365445693e-05,
      "loss": 1.7612,
      "step": 5750
    },
    {
      "epoch": 0.061401326480380686,
      "grad_norm": 2.14341139793396,
      "learning_rate": 4.969299174253653e-05,
      "loss": 1.7489,
      "step": 5800
    },
    {
      "epoch": 0.06193064826038397,
      "grad_norm": 1.8555598258972168,
      "learning_rate": 4.9690345119627355e-05,
      "loss": 1.7593,
      "step": 5850
    },
    {
      "epoch": 0.06245997004038725,
      "grad_norm": 1.8496214151382446,
      "learning_rate": 4.968769849671819e-05,
      "loss": 1.7526,
      "step": 5900
    },
    {
      "epoch": 0.06298929182039054,
      "grad_norm": 1.8993233442306519,
      "learning_rate": 4.968505187380902e-05,
      "loss": 1.7547,
      "step": 5950
    },
    {
      "epoch": 0.06351861360039382,
      "grad_norm": 1.769494652748108,
      "learning_rate": 4.968240525089986e-05,
      "loss": 1.7407,
      "step": 6000
    },
    {
      "epoch": 0.06351861360039382,
      "eval_loss": 1.7321572303771973,
      "eval_runtime": 46.6205,
      "eval_samples_per_second": 3602.065,
      "eval_steps_per_second": 450.274,
      "step": 6000
    },
    {
      "epoch": 0.0640479353803971,
      "grad_norm": 1.6972037553787231,
      "learning_rate": 4.9679758627990685e-05,
      "loss": 1.7515,
      "step": 6050
    },
    {
      "epoch": 0.06457725716040037,
      "grad_norm": 1.8969271183013916,
      "learning_rate": 4.967711200508152e-05,
      "loss": 1.747,
      "step": 6100
    },
    {
      "epoch": 0.06510657894040366,
      "grad_norm": 1.9300404787063599,
      "learning_rate": 4.967446538217235e-05,
      "loss": 1.732,
      "step": 6150
    },
    {
      "epoch": 0.06563590072040694,
      "grad_norm": 1.9546147584915161,
      "learning_rate": 4.967181875926318e-05,
      "loss": 1.7482,
      "step": 6200
    },
    {
      "epoch": 0.06616522250041022,
      "grad_norm": 2.154317617416382,
      "learning_rate": 4.9669172136354014e-05,
      "loss": 1.739,
      "step": 6250
    },
    {
      "epoch": 0.0666945442804135,
      "grad_norm": 2.0347321033477783,
      "learning_rate": 4.966652551344484e-05,
      "loss": 1.7505,
      "step": 6300
    },
    {
      "epoch": 0.06722386606041679,
      "grad_norm": 1.9030994176864624,
      "learning_rate": 4.966387889053568e-05,
      "loss": 1.7406,
      "step": 6350
    },
    {
      "epoch": 0.06775318784042007,
      "grad_norm": 2.056689977645874,
      "learning_rate": 4.966123226762651e-05,
      "loss": 1.7389,
      "step": 6400
    },
    {
      "epoch": 0.06828250962042336,
      "grad_norm": 1.952502965927124,
      "learning_rate": 4.9658585644717344e-05,
      "loss": 1.7435,
      "step": 6450
    },
    {
      "epoch": 0.06881183140042664,
      "grad_norm": 1.8475886583328247,
      "learning_rate": 4.965593902180817e-05,
      "loss": 1.7404,
      "step": 6500
    },
    {
      "epoch": 0.06881183140042664,
      "eval_loss": 1.7116862535476685,
      "eval_runtime": 46.5494,
      "eval_samples_per_second": 3607.569,
      "eval_steps_per_second": 450.962,
      "step": 6500
    },
    {
      "epoch": 0.06934115318042991,
      "grad_norm": 2.041748523712158,
      "learning_rate": 4.965329239889901e-05,
      "loss": 1.7291,
      "step": 6550
    },
    {
      "epoch": 0.0698704749604332,
      "grad_norm": 1.9363127946853638,
      "learning_rate": 4.965064577598984e-05,
      "loss": 1.7311,
      "step": 6600
    },
    {
      "epoch": 0.07039979674043648,
      "grad_norm": 1.8939764499664307,
      "learning_rate": 4.9647999153080673e-05,
      "loss": 1.7458,
      "step": 6650
    },
    {
      "epoch": 0.07092911852043976,
      "grad_norm": 1.8103477954864502,
      "learning_rate": 4.96453525301715e-05,
      "loss": 1.7571,
      "step": 6700
    },
    {
      "epoch": 0.07145844030044304,
      "grad_norm": 2.0027918815612793,
      "learning_rate": 4.9642705907262335e-05,
      "loss": 1.7139,
      "step": 6750
    },
    {
      "epoch": 0.07198776208044633,
      "grad_norm": 1.8022987842559814,
      "learning_rate": 4.964005928435317e-05,
      "loss": 1.7495,
      "step": 6800
    },
    {
      "epoch": 0.07251708386044961,
      "grad_norm": 1.9511195421218872,
      "learning_rate": 4.9637412661443996e-05,
      "loss": 1.7332,
      "step": 6850
    },
    {
      "epoch": 0.0730464056404529,
      "grad_norm": 1.9377214908599854,
      "learning_rate": 4.963476603853483e-05,
      "loss": 1.7171,
      "step": 6900
    },
    {
      "epoch": 0.07357572742045616,
      "grad_norm": 1.7662124633789062,
      "learning_rate": 4.9632119415625664e-05,
      "loss": 1.7241,
      "step": 6950
    },
    {
      "epoch": 0.07410504920045945,
      "grad_norm": 1.8665989637374878,
      "learning_rate": 4.96294727927165e-05,
      "loss": 1.7046,
      "step": 7000
    },
    {
      "epoch": 0.07410504920045945,
      "eval_loss": 1.6982522010803223,
      "eval_runtime": 46.6008,
      "eval_samples_per_second": 3603.59,
      "eval_steps_per_second": 450.465,
      "step": 7000
    },
    {
      "epoch": 0.07463437098046273,
      "grad_norm": 1.7995758056640625,
      "learning_rate": 4.9626826169807326e-05,
      "loss": 1.7301,
      "step": 7050
    },
    {
      "epoch": 0.07516369276046601,
      "grad_norm": 2.050879955291748,
      "learning_rate": 4.962417954689816e-05,
      "loss": 1.744,
      "step": 7100
    },
    {
      "epoch": 0.0756930145404693,
      "grad_norm": 1.7280192375183105,
      "learning_rate": 4.9621532923988994e-05,
      "loss": 1.7472,
      "step": 7150
    },
    {
      "epoch": 0.07622233632047258,
      "grad_norm": 2.228095531463623,
      "learning_rate": 4.961888630107983e-05,
      "loss": 1.7149,
      "step": 7200
    },
    {
      "epoch": 0.07675165810047586,
      "grad_norm": 1.9476805925369263,
      "learning_rate": 4.9616239678170656e-05,
      "loss": 1.7122,
      "step": 7250
    },
    {
      "epoch": 0.07728097988047915,
      "grad_norm": 1.9597926139831543,
      "learning_rate": 4.961359305526149e-05,
      "loss": 1.7034,
      "step": 7300
    },
    {
      "epoch": 0.07781030166048242,
      "grad_norm": 2.376338005065918,
      "learning_rate": 4.9610946432352324e-05,
      "loss": 1.7113,
      "step": 7350
    },
    {
      "epoch": 0.0783396234404857,
      "grad_norm": 1.8708374500274658,
      "learning_rate": 4.960829980944315e-05,
      "loss": 1.7242,
      "step": 7400
    },
    {
      "epoch": 0.07886894522048898,
      "grad_norm": 1.8774964809417725,
      "learning_rate": 4.9605653186533985e-05,
      "loss": 1.7214,
      "step": 7450
    },
    {
      "epoch": 0.07939826700049227,
      "grad_norm": 2.0154623985290527,
      "learning_rate": 4.960300656362481e-05,
      "loss": 1.7237,
      "step": 7500
    },
    {
      "epoch": 0.07939826700049227,
      "eval_loss": 1.6812313795089722,
      "eval_runtime": 46.8969,
      "eval_samples_per_second": 3580.831,
      "eval_steps_per_second": 447.62,
      "step": 7500
    },
    {
      "epoch": 0.07992758878049555,
      "grad_norm": 2.084084987640381,
      "learning_rate": 4.960035994071565e-05,
      "loss": 1.6841,
      "step": 7550
    },
    {
      "epoch": 0.08045691056049883,
      "grad_norm": 2.238542079925537,
      "learning_rate": 4.959771331780648e-05,
      "loss": 1.6823,
      "step": 7600
    },
    {
      "epoch": 0.08098623234050212,
      "grad_norm": 2.116056442260742,
      "learning_rate": 4.9595066694897315e-05,
      "loss": 1.6971,
      "step": 7650
    },
    {
      "epoch": 0.0815155541205054,
      "grad_norm": 1.8658268451690674,
      "learning_rate": 4.959242007198814e-05,
      "loss": 1.7122,
      "step": 7700
    },
    {
      "epoch": 0.08204487590050868,
      "grad_norm": 1.8759171962738037,
      "learning_rate": 4.958977344907898e-05,
      "loss": 1.7152,
      "step": 7750
    },
    {
      "epoch": 0.08257419768051195,
      "grad_norm": 2.063255786895752,
      "learning_rate": 4.958712682616981e-05,
      "loss": 1.7038,
      "step": 7800
    },
    {
      "epoch": 0.08310351946051524,
      "grad_norm": 2.007535934448242,
      "learning_rate": 4.9584480203260644e-05,
      "loss": 1.6966,
      "step": 7850
    },
    {
      "epoch": 0.08363284124051852,
      "grad_norm": 1.7946234941482544,
      "learning_rate": 4.958183358035147e-05,
      "loss": 1.6961,
      "step": 7900
    },
    {
      "epoch": 0.0841621630205218,
      "grad_norm": 2.05599045753479,
      "learning_rate": 4.9579186957442306e-05,
      "loss": 1.7096,
      "step": 7950
    },
    {
      "epoch": 0.08469148480052509,
      "grad_norm": 2.082432746887207,
      "learning_rate": 4.957654033453314e-05,
      "loss": 1.6529,
      "step": 8000
    },
    {
      "epoch": 0.08469148480052509,
      "eval_loss": 1.6660670042037964,
      "eval_runtime": 46.7768,
      "eval_samples_per_second": 3590.028,
      "eval_steps_per_second": 448.77,
      "step": 8000
    },
    {
      "epoch": 0.08522080658052837,
      "grad_norm": 1.904552698135376,
      "learning_rate": 4.9573946644082155e-05,
      "loss": 1.6942,
      "step": 8050
    },
    {
      "epoch": 0.08575012836053165,
      "grad_norm": 2.003558874130249,
      "learning_rate": 4.957130002117298e-05,
      "loss": 1.7185,
      "step": 8100
    },
    {
      "epoch": 0.08627945014053494,
      "grad_norm": 2.139554977416992,
      "learning_rate": 4.956865339826382e-05,
      "loss": 1.6995,
      "step": 8150
    },
    {
      "epoch": 0.08680877192053821,
      "grad_norm": 1.7661203145980835,
      "learning_rate": 4.956600677535465e-05,
      "loss": 1.7076,
      "step": 8200
    },
    {
      "epoch": 0.08733809370054149,
      "grad_norm": 2.0834407806396484,
      "learning_rate": 4.9563360152445484e-05,
      "loss": 1.6997,
      "step": 8250
    },
    {
      "epoch": 0.08786741548054477,
      "grad_norm": 1.8778756856918335,
      "learning_rate": 4.956071352953631e-05,
      "loss": 1.676,
      "step": 8300
    },
    {
      "epoch": 0.08839673726054806,
      "grad_norm": 1.9039260149002075,
      "learning_rate": 4.9558066906627146e-05,
      "loss": 1.716,
      "step": 8350
    },
    {
      "epoch": 0.08892605904055134,
      "grad_norm": 1.8419842720031738,
      "learning_rate": 4.955542028371798e-05,
      "loss": 1.6792,
      "step": 8400
    },
    {
      "epoch": 0.08945538082055463,
      "grad_norm": 1.9227850437164307,
      "learning_rate": 4.955277366080881e-05,
      "loss": 1.6991,
      "step": 8450
    },
    {
      "epoch": 0.08998470260055791,
      "grad_norm": 1.8738776445388794,
      "learning_rate": 4.955012703789964e-05,
      "loss": 1.688,
      "step": 8500
    },
    {
      "epoch": 0.08998470260055791,
      "eval_loss": 1.6504237651824951,
      "eval_runtime": 46.7587,
      "eval_samples_per_second": 3591.415,
      "eval_steps_per_second": 448.943,
      "step": 8500
    },
    {
      "epoch": 0.09051402438056119,
      "grad_norm": 2.2126502990722656,
      "learning_rate": 4.9547480414990475e-05,
      "loss": 1.6942,
      "step": 8550
    },
    {
      "epoch": 0.09104334616056448,
      "grad_norm": 1.8633240461349487,
      "learning_rate": 4.954483379208131e-05,
      "loss": 1.6951,
      "step": 8600
    },
    {
      "epoch": 0.09157266794056775,
      "grad_norm": 2.0860190391540527,
      "learning_rate": 4.954218716917214e-05,
      "loss": 1.6688,
      "step": 8650
    },
    {
      "epoch": 0.09210198972057103,
      "grad_norm": 2.1335184574127197,
      "learning_rate": 4.953954054626297e-05,
      "loss": 1.6675,
      "step": 8700
    },
    {
      "epoch": 0.09263131150057431,
      "grad_norm": 1.989023208618164,
      "learning_rate": 4.9536893923353805e-05,
      "loss": 1.6907,
      "step": 8750
    },
    {
      "epoch": 0.0931606332805776,
      "grad_norm": 2.067888021469116,
      "learning_rate": 4.953424730044464e-05,
      "loss": 1.6755,
      "step": 8800
    },
    {
      "epoch": 0.09368995506058088,
      "grad_norm": 1.9482041597366333,
      "learning_rate": 4.9531600677535466e-05,
      "loss": 1.6804,
      "step": 8850
    },
    {
      "epoch": 0.09421927684058416,
      "grad_norm": 2.149925947189331,
      "learning_rate": 4.95289540546263e-05,
      "loss": 1.6828,
      "step": 8900
    },
    {
      "epoch": 0.09474859862058745,
      "grad_norm": 2.0060837268829346,
      "learning_rate": 4.9526307431717135e-05,
      "loss": 1.6738,
      "step": 8950
    },
    {
      "epoch": 0.09527792040059073,
      "grad_norm": 2.0011508464813232,
      "learning_rate": 4.952366080880796e-05,
      "loss": 1.6766,
      "step": 9000
    },
    {
      "epoch": 0.09527792040059073,
      "eval_loss": 1.6394610404968262,
      "eval_runtime": 46.6486,
      "eval_samples_per_second": 3599.892,
      "eval_steps_per_second": 450.003,
      "step": 9000
    },
    {
      "epoch": 0.095807242180594,
      "grad_norm": 2.052149772644043,
      "learning_rate": 4.9521014185898796e-05,
      "loss": 1.6873,
      "step": 9050
    },
    {
      "epoch": 0.09633656396059728,
      "grad_norm": 1.8832931518554688,
      "learning_rate": 4.951836756298962e-05,
      "loss": 1.6655,
      "step": 9100
    },
    {
      "epoch": 0.09686588574060057,
      "grad_norm": 2.110600471496582,
      "learning_rate": 4.9515720940080464e-05,
      "loss": 1.6415,
      "step": 9150
    },
    {
      "epoch": 0.09739520752060385,
      "grad_norm": 2.0700950622558594,
      "learning_rate": 4.951307431717129e-05,
      "loss": 1.6702,
      "step": 9200
    },
    {
      "epoch": 0.09792452930060713,
      "grad_norm": 1.8515602350234985,
      "learning_rate": 4.9510427694262126e-05,
      "loss": 1.6697,
      "step": 9250
    },
    {
      "epoch": 0.09845385108061042,
      "grad_norm": 2.038757801055908,
      "learning_rate": 4.950778107135295e-05,
      "loss": 1.6669,
      "step": 9300
    },
    {
      "epoch": 0.0989831728606137,
      "grad_norm": 1.9629560708999634,
      "learning_rate": 4.9505134448443794e-05,
      "loss": 1.6757,
      "step": 9350
    },
    {
      "epoch": 0.09951249464061698,
      "grad_norm": 2.2807326316833496,
      "learning_rate": 4.950248782553462e-05,
      "loss": 1.6549,
      "step": 9400
    },
    {
      "epoch": 0.10004181642062025,
      "grad_norm": 1.938232421875,
      "learning_rate": 4.9499841202625455e-05,
      "loss": 1.6537,
      "step": 9450
    },
    {
      "epoch": 0.10057113820062354,
      "grad_norm": 2.0702435970306396,
      "learning_rate": 4.949719457971628e-05,
      "loss": 1.6733,
      "step": 9500
    },
    {
      "epoch": 0.10057113820062354,
      "eval_loss": 1.6267563104629517,
      "eval_runtime": 46.6694,
      "eval_samples_per_second": 3598.292,
      "eval_steps_per_second": 449.803,
      "step": 9500
    },
    {
      "epoch": 0.10110045998062682,
      "grad_norm": 2.001622438430786,
      "learning_rate": 4.949454795680712e-05,
      "loss": 1.6835,
      "step": 9550
    },
    {
      "epoch": 0.1016297817606301,
      "grad_norm": 2.1001999378204346,
      "learning_rate": 4.949190133389795e-05,
      "loss": 1.6521,
      "step": 9600
    },
    {
      "epoch": 0.10215910354063339,
      "grad_norm": 2.1239867210388184,
      "learning_rate": 4.948925471098878e-05,
      "loss": 1.6537,
      "step": 9650
    },
    {
      "epoch": 0.10268842532063667,
      "grad_norm": 1.9887666702270508,
      "learning_rate": 4.948660808807961e-05,
      "loss": 1.664,
      "step": 9700
    },
    {
      "epoch": 0.10321774710063995,
      "grad_norm": 2.094954252243042,
      "learning_rate": 4.9483961465170446e-05,
      "loss": 1.6419,
      "step": 9750
    },
    {
      "epoch": 0.10374706888064324,
      "grad_norm": 1.9199175834655762,
      "learning_rate": 4.948131484226128e-05,
      "loss": 1.639,
      "step": 9800
    },
    {
      "epoch": 0.10427639066064652,
      "grad_norm": 1.8915011882781982,
      "learning_rate": 4.947866821935211e-05,
      "loss": 1.6351,
      "step": 9850
    },
    {
      "epoch": 0.10480571244064979,
      "grad_norm": 2.1344826221466064,
      "learning_rate": 4.947602159644294e-05,
      "loss": 1.6583,
      "step": 9900
    },
    {
      "epoch": 0.10533503422065307,
      "grad_norm": 1.9802355766296387,
      "learning_rate": 4.9473374973533776e-05,
      "loss": 1.6524,
      "step": 9950
    },
    {
      "epoch": 0.10586435600065636,
      "grad_norm": 2.034553289413452,
      "learning_rate": 4.947072835062461e-05,
      "loss": 1.6648,
      "step": 10000
    },
    {
      "epoch": 0.10586435600065636,
      "eval_loss": 1.6137605905532837,
      "eval_runtime": 46.7352,
      "eval_samples_per_second": 3593.221,
      "eval_steps_per_second": 449.169,
      "step": 10000
    },
    {
      "epoch": 0.10639367778065964,
      "grad_norm": 2.0119216442108154,
      "learning_rate": 4.946808172771544e-05,
      "loss": 1.6486,
      "step": 10050
    },
    {
      "epoch": 0.10692299956066292,
      "grad_norm": 2.083156108856201,
      "learning_rate": 4.946543510480627e-05,
      "loss": 1.6329,
      "step": 10100
    },
    {
      "epoch": 0.10745232134066621,
      "grad_norm": 2.0737547874450684,
      "learning_rate": 4.9462788481897105e-05,
      "loss": 1.6664,
      "step": 10150
    },
    {
      "epoch": 0.10798164312066949,
      "grad_norm": 1.9356728792190552,
      "learning_rate": 4.946014185898793e-05,
      "loss": 1.6341,
      "step": 10200
    },
    {
      "epoch": 0.10851096490067277,
      "grad_norm": 2.053938150405884,
      "learning_rate": 4.945749523607877e-05,
      "loss": 1.646,
      "step": 10250
    },
    {
      "epoch": 0.10904028668067604,
      "grad_norm": 2.015157699584961,
      "learning_rate": 4.9454848613169594e-05,
      "loss": 1.6571,
      "step": 10300
    },
    {
      "epoch": 0.10956960846067933,
      "grad_norm": 2.0010933876037598,
      "learning_rate": 4.9452201990260435e-05,
      "loss": 1.6698,
      "step": 10350
    },
    {
      "epoch": 0.11009893024068261,
      "grad_norm": 1.9521007537841797,
      "learning_rate": 4.944960829980945e-05,
      "loss": 1.6391,
      "step": 10400
    },
    {
      "epoch": 0.1106282520206859,
      "grad_norm": 2.1191465854644775,
      "learning_rate": 4.944696167690028e-05,
      "loss": 1.6262,
      "step": 10450
    },
    {
      "epoch": 0.11115757380068918,
      "grad_norm": 1.8988345861434937,
      "learning_rate": 4.944431505399111e-05,
      "loss": 1.6572,
      "step": 10500
    },
    {
      "epoch": 0.11115757380068918,
      "eval_loss": 1.6037187576293945,
      "eval_runtime": 46.8307,
      "eval_samples_per_second": 3585.892,
      "eval_steps_per_second": 448.253,
      "step": 10500
    },
    {
      "epoch": 0.11168689558069246,
      "grad_norm": 2.2484848499298096,
      "learning_rate": 4.9441668431081945e-05,
      "loss": 1.6368,
      "step": 10550
    },
    {
      "epoch": 0.11221621736069574,
      "grad_norm": 2.039722204208374,
      "learning_rate": 4.943902180817277e-05,
      "loss": 1.6415,
      "step": 10600
    },
    {
      "epoch": 0.11274553914069903,
      "grad_norm": 1.949142575263977,
      "learning_rate": 4.943637518526361e-05,
      "loss": 1.644,
      "step": 10650
    },
    {
      "epoch": 0.11327486092070231,
      "grad_norm": 1.9456031322479248,
      "learning_rate": 4.9433728562354434e-05,
      "loss": 1.6366,
      "step": 10700
    },
    {
      "epoch": 0.11380418270070558,
      "grad_norm": 1.9768712520599365,
      "learning_rate": 4.9431081939445275e-05,
      "loss": 1.6402,
      "step": 10750
    },
    {
      "epoch": 0.11433350448070886,
      "grad_norm": 2.1935856342315674,
      "learning_rate": 4.94284353165361e-05,
      "loss": 1.6546,
      "step": 10800
    },
    {
      "epoch": 0.11486282626071215,
      "grad_norm": 1.862411618232727,
      "learning_rate": 4.9425788693626936e-05,
      "loss": 1.6324,
      "step": 10850
    },
    {
      "epoch": 0.11539214804071543,
      "grad_norm": 2.1165897846221924,
      "learning_rate": 4.9423142070717764e-05,
      "loss": 1.6295,
      "step": 10900
    },
    {
      "epoch": 0.11592146982071871,
      "grad_norm": 1.8657565116882324,
      "learning_rate": 4.9420495447808605e-05,
      "loss": 1.6208,
      "step": 10950
    },
    {
      "epoch": 0.116450791600722,
      "grad_norm": 2.00816011428833,
      "learning_rate": 4.941784882489943e-05,
      "loss": 1.6314,
      "step": 11000
    },
    {
      "epoch": 0.116450791600722,
      "eval_loss": 1.5927499532699585,
      "eval_runtime": 46.5502,
      "eval_samples_per_second": 3607.501,
      "eval_steps_per_second": 450.954,
      "step": 11000
    },
    {
      "epoch": 0.11698011338072528,
      "grad_norm": 1.9675357341766357,
      "learning_rate": 4.9415202201990266e-05,
      "loss": 1.6471,
      "step": 11050
    },
    {
      "epoch": 0.11750943516072856,
      "grad_norm": 1.8457378149032593,
      "learning_rate": 4.941255557908109e-05,
      "loss": 1.634,
      "step": 11100
    },
    {
      "epoch": 0.11803875694073183,
      "grad_norm": 2.1237289905548096,
      "learning_rate": 4.940990895617193e-05,
      "loss": 1.6246,
      "step": 11150
    },
    {
      "epoch": 0.11856807872073512,
      "grad_norm": 1.8853517770767212,
      "learning_rate": 4.940726233326276e-05,
      "loss": 1.6325,
      "step": 11200
    },
    {
      "epoch": 0.1190974005007384,
      "grad_norm": 1.8943036794662476,
      "learning_rate": 4.940461571035359e-05,
      "loss": 1.6196,
      "step": 11250
    },
    {
      "epoch": 0.11962672228074168,
      "grad_norm": 1.8600529432296753,
      "learning_rate": 4.940196908744442e-05,
      "loss": 1.6169,
      "step": 11300
    },
    {
      "epoch": 0.12015604406074497,
      "grad_norm": 2.120365619659424,
      "learning_rate": 4.939932246453526e-05,
      "loss": 1.6218,
      "step": 11350
    },
    {
      "epoch": 0.12068536584074825,
      "grad_norm": 2.2112832069396973,
      "learning_rate": 4.939667584162609e-05,
      "loss": 1.649,
      "step": 11400
    },
    {
      "epoch": 0.12121468762075154,
      "grad_norm": 2.031696081161499,
      "learning_rate": 4.939402921871692e-05,
      "loss": 1.6261,
      "step": 11450
    },
    {
      "epoch": 0.12174400940075482,
      "grad_norm": 2.1305763721466064,
      "learning_rate": 4.939138259580775e-05,
      "loss": 1.6271,
      "step": 11500
    },
    {
      "epoch": 0.12174400940075482,
      "eval_loss": 1.587058186531067,
      "eval_runtime": 46.577,
      "eval_samples_per_second": 3605.425,
      "eval_steps_per_second": 450.694,
      "step": 11500
    },
    {
      "epoch": 0.12227333118075809,
      "grad_norm": 2.105808734893799,
      "learning_rate": 4.938873597289858e-05,
      "loss": 1.6274,
      "step": 11550
    },
    {
      "epoch": 0.12280265296076137,
      "grad_norm": 2.0247066020965576,
      "learning_rate": 4.9386089349989414e-05,
      "loss": 1.6496,
      "step": 11600
    },
    {
      "epoch": 0.12333197474076465,
      "grad_norm": 2.229799270629883,
      "learning_rate": 4.938344272708025e-05,
      "loss": 1.6315,
      "step": 11650
    },
    {
      "epoch": 0.12386129652076794,
      "grad_norm": 2.063190460205078,
      "learning_rate": 4.9380796104171075e-05,
      "loss": 1.6236,
      "step": 11700
    },
    {
      "epoch": 0.12439061830077122,
      "grad_norm": 1.9414582252502441,
      "learning_rate": 4.937814948126191e-05,
      "loss": 1.6103,
      "step": 11750
    },
    {
      "epoch": 0.1249199400807745,
      "grad_norm": 1.9969052076339722,
      "learning_rate": 4.9375502858352744e-05,
      "loss": 1.6263,
      "step": 11800
    },
    {
      "epoch": 0.1254492618607778,
      "grad_norm": 2.4197089672088623,
      "learning_rate": 4.937285623544358e-05,
      "loss": 1.6247,
      "step": 11850
    },
    {
      "epoch": 0.12597858364078107,
      "grad_norm": 2.177104949951172,
      "learning_rate": 4.9370209612534405e-05,
      "loss": 1.624,
      "step": 11900
    },
    {
      "epoch": 0.12650790542078436,
      "grad_norm": 2.137951374053955,
      "learning_rate": 4.936756298962524e-05,
      "loss": 1.6301,
      "step": 11950
    },
    {
      "epoch": 0.12703722720078764,
      "grad_norm": 1.9829812049865723,
      "learning_rate": 4.936491636671607e-05,
      "loss": 1.628,
      "step": 12000
    },
    {
      "epoch": 0.12703722720078764,
      "eval_loss": 1.5781980752944946,
      "eval_runtime": 46.6221,
      "eval_samples_per_second": 3601.939,
      "eval_steps_per_second": 450.258,
      "step": 12000
    },
    {
      "epoch": 0.12756654898079092,
      "grad_norm": 1.8913259506225586,
      "learning_rate": 4.936226974380691e-05,
      "loss": 1.6356,
      "step": 12050
    },
    {
      "epoch": 0.1280958707607942,
      "grad_norm": 2.018082857131958,
      "learning_rate": 4.9359623120897735e-05,
      "loss": 1.6136,
      "step": 12100
    },
    {
      "epoch": 0.1286251925407975,
      "grad_norm": 1.8758201599121094,
      "learning_rate": 4.935697649798857e-05,
      "loss": 1.6008,
      "step": 12150
    },
    {
      "epoch": 0.12915451432080075,
      "grad_norm": 1.9212303161621094,
      "learning_rate": 4.93543298750794e-05,
      "loss": 1.5999,
      "step": 12200
    },
    {
      "epoch": 0.12968383610080403,
      "grad_norm": 1.9338537454605103,
      "learning_rate": 4.935168325217023e-05,
      "loss": 1.6289,
      "step": 12250
    },
    {
      "epoch": 0.1302131578808073,
      "grad_norm": 2.010542154312134,
      "learning_rate": 4.9349036629261064e-05,
      "loss": 1.5864,
      "step": 12300
    },
    {
      "epoch": 0.1307424796608106,
      "grad_norm": 1.9543077945709229,
      "learning_rate": 4.934639000635189e-05,
      "loss": 1.6206,
      "step": 12350
    },
    {
      "epoch": 0.13127180144081388,
      "grad_norm": 1.9755477905273438,
      "learning_rate": 4.934374338344273e-05,
      "loss": 1.6203,
      "step": 12400
    },
    {
      "epoch": 0.13180112322081716,
      "grad_norm": 2.1447839736938477,
      "learning_rate": 4.934109676053356e-05,
      "loss": 1.5865,
      "step": 12450
    },
    {
      "epoch": 0.13233044500082045,
      "grad_norm": 1.8900408744812012,
      "learning_rate": 4.9338450137624394e-05,
      "loss": 1.6098,
      "step": 12500
    },
    {
      "epoch": 0.13233044500082045,
      "eval_loss": 1.5705631971359253,
      "eval_runtime": 46.5382,
      "eval_samples_per_second": 3608.435,
      "eval_steps_per_second": 451.071,
      "step": 12500
    },
    {
      "epoch": 0.13285976678082373,
      "grad_norm": 1.9410173892974854,
      "learning_rate": 4.933580351471522e-05,
      "loss": 1.6268,
      "step": 12550
    },
    {
      "epoch": 0.133389088560827,
      "grad_norm": 1.9882267713546753,
      "learning_rate": 4.933315689180606e-05,
      "loss": 1.6034,
      "step": 12600
    },
    {
      "epoch": 0.1339184103408303,
      "grad_norm": 2.212082624435425,
      "learning_rate": 4.933051026889689e-05,
      "loss": 1.5955,
      "step": 12650
    },
    {
      "epoch": 0.13444773212083358,
      "grad_norm": 2.064971685409546,
      "learning_rate": 4.9327863645987724e-05,
      "loss": 1.5924,
      "step": 12700
    },
    {
      "epoch": 0.13497705390083686,
      "grad_norm": 1.8910285234451294,
      "learning_rate": 4.932521702307855e-05,
      "loss": 1.5946,
      "step": 12750
    },
    {
      "epoch": 0.13550637568084015,
      "grad_norm": 2.0614211559295654,
      "learning_rate": 4.932262333262757e-05,
      "loss": 1.625,
      "step": 12800
    },
    {
      "epoch": 0.13603569746084343,
      "grad_norm": 1.9481327533721924,
      "learning_rate": 4.93199767097184e-05,
      "loss": 1.6068,
      "step": 12850
    },
    {
      "epoch": 0.1365650192408467,
      "grad_norm": 1.9937067031860352,
      "learning_rate": 4.9317330086809234e-05,
      "loss": 1.6291,
      "step": 12900
    },
    {
      "epoch": 0.13709434102085,
      "grad_norm": 2.112520933151245,
      "learning_rate": 4.931468346390006e-05,
      "loss": 1.6057,
      "step": 12950
    },
    {
      "epoch": 0.13762366280085328,
      "grad_norm": 1.8036315441131592,
      "learning_rate": 4.93120368409909e-05,
      "loss": 1.6015,
      "step": 13000
    },
    {
      "epoch": 0.13762366280085328,
      "eval_loss": 1.5604431629180908,
      "eval_runtime": 46.5717,
      "eval_samples_per_second": 3605.841,
      "eval_steps_per_second": 450.746,
      "step": 13000
    },
    {
      "epoch": 0.13815298458085654,
      "grad_norm": 2.133211851119995,
      "learning_rate": 4.930939021808173e-05,
      "loss": 1.6173,
      "step": 13050
    },
    {
      "epoch": 0.13868230636085982,
      "grad_norm": 2.0392236709594727,
      "learning_rate": 4.9306743595172563e-05,
      "loss": 1.6154,
      "step": 13100
    },
    {
      "epoch": 0.1392116281408631,
      "grad_norm": 2.0312488079071045,
      "learning_rate": 4.930409697226339e-05,
      "loss": 1.5769,
      "step": 13150
    },
    {
      "epoch": 0.1397409499208664,
      "grad_norm": 2.015424966812134,
      "learning_rate": 4.9301450349354225e-05,
      "loss": 1.5984,
      "step": 13200
    },
    {
      "epoch": 0.14027027170086967,
      "grad_norm": 1.8357223272323608,
      "learning_rate": 4.929880372644506e-05,
      "loss": 1.5876,
      "step": 13250
    },
    {
      "epoch": 0.14079959348087295,
      "grad_norm": 1.7146064043045044,
      "learning_rate": 4.9296157103535886e-05,
      "loss": 1.6024,
      "step": 13300
    },
    {
      "epoch": 0.14132891526087624,
      "grad_norm": 2.0913918018341064,
      "learning_rate": 4.929351048062672e-05,
      "loss": 1.5973,
      "step": 13350
    },
    {
      "epoch": 0.14185823704087952,
      "grad_norm": 2.0401904582977295,
      "learning_rate": 4.9290863857717554e-05,
      "loss": 1.5904,
      "step": 13400
    },
    {
      "epoch": 0.1423875588208828,
      "grad_norm": 2.033846378326416,
      "learning_rate": 4.928821723480839e-05,
      "loss": 1.5914,
      "step": 13450
    },
    {
      "epoch": 0.1429168806008861,
      "grad_norm": 1.9990729093551636,
      "learning_rate": 4.9285570611899216e-05,
      "loss": 1.5753,
      "step": 13500
    },
    {
      "epoch": 0.1429168806008861,
      "eval_loss": 1.5560760498046875,
      "eval_runtime": 46.5718,
      "eval_samples_per_second": 3605.832,
      "eval_steps_per_second": 450.745,
      "step": 13500
    },
    {
      "epoch": 0.14344620238088937,
      "grad_norm": 1.949765920639038,
      "learning_rate": 4.928292398899005e-05,
      "loss": 1.6024,
      "step": 13550
    },
    {
      "epoch": 0.14397552416089265,
      "grad_norm": 2.0088632106781006,
      "learning_rate": 4.9280277366080884e-05,
      "loss": 1.5706,
      "step": 13600
    },
    {
      "epoch": 0.14450484594089594,
      "grad_norm": 2.1408097743988037,
      "learning_rate": 4.927763074317172e-05,
      "loss": 1.6013,
      "step": 13650
    },
    {
      "epoch": 0.14503416772089922,
      "grad_norm": 1.9182792901992798,
      "learning_rate": 4.9274984120262545e-05,
      "loss": 1.5982,
      "step": 13700
    },
    {
      "epoch": 0.1455634895009025,
      "grad_norm": 1.9117987155914307,
      "learning_rate": 4.927233749735338e-05,
      "loss": 1.5873,
      "step": 13750
    },
    {
      "epoch": 0.1460928112809058,
      "grad_norm": 1.9806766510009766,
      "learning_rate": 4.9269690874444214e-05,
      "loss": 1.5975,
      "step": 13800
    },
    {
      "epoch": 0.14662213306090904,
      "grad_norm": 1.9125590324401855,
      "learning_rate": 4.926704425153504e-05,
      "loss": 1.5812,
      "step": 13850
    },
    {
      "epoch": 0.14715145484091233,
      "grad_norm": 1.9278596639633179,
      "learning_rate": 4.9264397628625875e-05,
      "loss": 1.5959,
      "step": 13900
    },
    {
      "epoch": 0.1476807766209156,
      "grad_norm": 1.882049798965454,
      "learning_rate": 4.92617510057167e-05,
      "loss": 1.5806,
      "step": 13950
    },
    {
      "epoch": 0.1482100984009189,
      "grad_norm": 2.0439553260803223,
      "learning_rate": 4.925910438280754e-05,
      "loss": 1.5818,
      "step": 14000
    },
    {
      "epoch": 0.1482100984009189,
      "eval_loss": 1.548224687576294,
      "eval_runtime": 46.7428,
      "eval_samples_per_second": 3592.636,
      "eval_steps_per_second": 449.096,
      "step": 14000
    },
    {
      "epoch": 0.14873942018092218,
      "grad_norm": 1.8662317991256714,
      "learning_rate": 4.925645775989837e-05,
      "loss": 1.5845,
      "step": 14050
    },
    {
      "epoch": 0.14926874196092546,
      "grad_norm": 1.960716962814331,
      "learning_rate": 4.9253811136989205e-05,
      "loss": 1.5897,
      "step": 14100
    },
    {
      "epoch": 0.14979806374092874,
      "grad_norm": 2.0414535999298096,
      "learning_rate": 4.925116451408003e-05,
      "loss": 1.5841,
      "step": 14150
    },
    {
      "epoch": 0.15032738552093203,
      "grad_norm": 1.9807016849517822,
      "learning_rate": 4.924851789117087e-05,
      "loss": 1.5634,
      "step": 14200
    },
    {
      "epoch": 0.1508567073009353,
      "grad_norm": 2.133692502975464,
      "learning_rate": 4.92458712682617e-05,
      "loss": 1.58,
      "step": 14250
    },
    {
      "epoch": 0.1513860290809386,
      "grad_norm": 1.8023266792297363,
      "learning_rate": 4.9243224645352534e-05,
      "loss": 1.5837,
      "step": 14300
    },
    {
      "epoch": 0.15191535086094188,
      "grad_norm": 2.098290205001831,
      "learning_rate": 4.924057802244336e-05,
      "loss": 1.5831,
      "step": 14350
    },
    {
      "epoch": 0.15244467264094516,
      "grad_norm": 2.035372734069824,
      "learning_rate": 4.9237931399534196e-05,
      "loss": 1.5884,
      "step": 14400
    },
    {
      "epoch": 0.15297399442094844,
      "grad_norm": 1.9700307846069336,
      "learning_rate": 4.923528477662503e-05,
      "loss": 1.5753,
      "step": 14450
    },
    {
      "epoch": 0.15350331620095173,
      "grad_norm": 1.823540210723877,
      "learning_rate": 4.923263815371586e-05,
      "loss": 1.583,
      "step": 14500
    },
    {
      "epoch": 0.15350331620095173,
      "eval_loss": 1.5428104400634766,
      "eval_runtime": 46.6594,
      "eval_samples_per_second": 3599.061,
      "eval_steps_per_second": 449.899,
      "step": 14500
    },
    {
      "epoch": 0.154032637980955,
      "grad_norm": 2.068502187728882,
      "learning_rate": 4.922999153080669e-05,
      "loss": 1.5891,
      "step": 14550
    },
    {
      "epoch": 0.1545619597609583,
      "grad_norm": 1.6478511095046997,
      "learning_rate": 4.9227344907897525e-05,
      "loss": 1.5927,
      "step": 14600
    },
    {
      "epoch": 0.15509128154096158,
      "grad_norm": 2.019501209259033,
      "learning_rate": 4.922469828498836e-05,
      "loss": 1.5771,
      "step": 14650
    },
    {
      "epoch": 0.15562060332096483,
      "grad_norm": 2.066162347793579,
      "learning_rate": 4.922205166207919e-05,
      "loss": 1.5776,
      "step": 14700
    },
    {
      "epoch": 0.15614992510096812,
      "grad_norm": 1.8745994567871094,
      "learning_rate": 4.921940503917002e-05,
      "loss": 1.5847,
      "step": 14750
    },
    {
      "epoch": 0.1566792468809714,
      "grad_norm": 2.170773506164551,
      "learning_rate": 4.9216758416260855e-05,
      "loss": 1.5712,
      "step": 14800
    },
    {
      "epoch": 0.15720856866097468,
      "grad_norm": 2.1297523975372314,
      "learning_rate": 4.921411179335169e-05,
      "loss": 1.56,
      "step": 14850
    },
    {
      "epoch": 0.15773789044097797,
      "grad_norm": 1.961189866065979,
      "learning_rate": 4.9211465170442516e-05,
      "loss": 1.6055,
      "step": 14900
    },
    {
      "epoch": 0.15826721222098125,
      "grad_norm": 2.0110676288604736,
      "learning_rate": 4.920881854753335e-05,
      "loss": 1.5696,
      "step": 14950
    },
    {
      "epoch": 0.15879653400098453,
      "grad_norm": 1.9063996076583862,
      "learning_rate": 4.9206171924624185e-05,
      "loss": 1.5732,
      "step": 15000
    },
    {
      "epoch": 0.15879653400098453,
      "eval_loss": 1.5348910093307495,
      "eval_runtime": 46.6076,
      "eval_samples_per_second": 3603.062,
      "eval_steps_per_second": 450.399,
      "step": 15000
    },
    {
      "epoch": 0.15932585578098782,
      "grad_norm": 2.0273373126983643,
      "learning_rate": 4.920352530171501e-05,
      "loss": 1.5464,
      "step": 15050
    },
    {
      "epoch": 0.1598551775609911,
      "grad_norm": 1.8851537704467773,
      "learning_rate": 4.9200878678805846e-05,
      "loss": 1.58,
      "step": 15100
    },
    {
      "epoch": 0.16038449934099439,
      "grad_norm": 1.9709466695785522,
      "learning_rate": 4.9198232055896673e-05,
      "loss": 1.555,
      "step": 15150
    },
    {
      "epoch": 0.16091382112099767,
      "grad_norm": 2.0422630310058594,
      "learning_rate": 4.9195585432987514e-05,
      "loss": 1.5523,
      "step": 15200
    },
    {
      "epoch": 0.16144314290100095,
      "grad_norm": 1.8363170623779297,
      "learning_rate": 4.919293881007834e-05,
      "loss": 1.5704,
      "step": 15250
    },
    {
      "epoch": 0.16197246468100424,
      "grad_norm": 1.7560871839523315,
      "learning_rate": 4.9190292187169176e-05,
      "loss": 1.5512,
      "step": 15300
    },
    {
      "epoch": 0.16250178646100752,
      "grad_norm": 1.9007879495620728,
      "learning_rate": 4.918769849671819e-05,
      "loss": 1.561,
      "step": 15350
    },
    {
      "epoch": 0.1630311082410108,
      "grad_norm": 2.0112149715423584,
      "learning_rate": 4.9185051873809025e-05,
      "loss": 1.5661,
      "step": 15400
    },
    {
      "epoch": 0.16356043002101409,
      "grad_norm": 2.034029722213745,
      "learning_rate": 4.918240525089985e-05,
      "loss": 1.5717,
      "step": 15450
    },
    {
      "epoch": 0.16408975180101737,
      "grad_norm": 1.847021460533142,
      "learning_rate": 4.9179758627990686e-05,
      "loss": 1.5449,
      "step": 15500
    },
    {
      "epoch": 0.16408975180101737,
      "eval_loss": 1.5308383703231812,
      "eval_runtime": 46.628,
      "eval_samples_per_second": 3601.482,
      "eval_steps_per_second": 450.201,
      "step": 15500
    },
    {
      "epoch": 0.16461907358102063,
      "grad_norm": 1.9154971837997437,
      "learning_rate": 4.917711200508151e-05,
      "loss": 1.5472,
      "step": 15550
    },
    {
      "epoch": 0.1651483953610239,
      "grad_norm": 2.0311062335968018,
      "learning_rate": 4.9174465382172354e-05,
      "loss": 1.5473,
      "step": 15600
    },
    {
      "epoch": 0.1656777171410272,
      "grad_norm": 2.010004997253418,
      "learning_rate": 4.917181875926318e-05,
      "loss": 1.5808,
      "step": 15650
    },
    {
      "epoch": 0.16620703892103048,
      "grad_norm": 2.132111072540283,
      "learning_rate": 4.9169172136354016e-05,
      "loss": 1.5658,
      "step": 15700
    },
    {
      "epoch": 0.16673636070103376,
      "grad_norm": 2.2036631107330322,
      "learning_rate": 4.916652551344484e-05,
      "loss": 1.5595,
      "step": 15750
    },
    {
      "epoch": 0.16726568248103704,
      "grad_norm": 2.128641128540039,
      "learning_rate": 4.9163878890535684e-05,
      "loss": 1.563,
      "step": 15800
    },
    {
      "epoch": 0.16779500426104033,
      "grad_norm": 1.944536566734314,
      "learning_rate": 4.916123226762651e-05,
      "loss": 1.5557,
      "step": 15850
    },
    {
      "epoch": 0.1683243260410436,
      "grad_norm": 2.0263404846191406,
      "learning_rate": 4.9158585644717345e-05,
      "loss": 1.5524,
      "step": 15900
    },
    {
      "epoch": 0.1688536478210469,
      "grad_norm": 2.001709461212158,
      "learning_rate": 4.915593902180817e-05,
      "loss": 1.5606,
      "step": 15950
    },
    {
      "epoch": 0.16938296960105018,
      "grad_norm": 1.8711037635803223,
      "learning_rate": 4.915329239889901e-05,
      "loss": 1.5837,
      "step": 16000
    },
    {
      "epoch": 0.16938296960105018,
      "eval_loss": 1.5250117778778076,
      "eval_runtime": 46.5447,
      "eval_samples_per_second": 3607.933,
      "eval_steps_per_second": 451.008,
      "step": 16000
    },
    {
      "epoch": 0.16991229138105346,
      "grad_norm": 2.1075856685638428,
      "learning_rate": 4.915064577598984e-05,
      "loss": 1.5616,
      "step": 16050
    },
    {
      "epoch": 0.17044161316105674,
      "grad_norm": 1.8884427547454834,
      "learning_rate": 4.914799915308067e-05,
      "loss": 1.5525,
      "step": 16100
    },
    {
      "epoch": 0.17097093494106003,
      "grad_norm": 2.0008511543273926,
      "learning_rate": 4.91453525301715e-05,
      "loss": 1.5443,
      "step": 16150
    },
    {
      "epoch": 0.1715002567210633,
      "grad_norm": 2.0224828720092773,
      "learning_rate": 4.9142705907262336e-05,
      "loss": 1.5818,
      "step": 16200
    },
    {
      "epoch": 0.1720295785010666,
      "grad_norm": 1.995642066001892,
      "learning_rate": 4.914005928435317e-05,
      "loss": 1.5583,
      "step": 16250
    },
    {
      "epoch": 0.17255890028106988,
      "grad_norm": 2.046581745147705,
      "learning_rate": 4.9137412661444e-05,
      "loss": 1.5693,
      "step": 16300
    },
    {
      "epoch": 0.17308822206107316,
      "grad_norm": 2.0535480976104736,
      "learning_rate": 4.913476603853483e-05,
      "loss": 1.5533,
      "step": 16350
    },
    {
      "epoch": 0.17361754384107642,
      "grad_norm": 1.8980739116668701,
      "learning_rate": 4.9132119415625666e-05,
      "loss": 1.5545,
      "step": 16400
    },
    {
      "epoch": 0.1741468656210797,
      "grad_norm": 1.7877416610717773,
      "learning_rate": 4.91294727927165e-05,
      "loss": 1.5413,
      "step": 16450
    },
    {
      "epoch": 0.17467618740108298,
      "grad_norm": 1.8616228103637695,
      "learning_rate": 4.912682616980733e-05,
      "loss": 1.5586,
      "step": 16500
    },
    {
      "epoch": 0.17467618740108298,
      "eval_loss": 1.5198650360107422,
      "eval_runtime": 46.5176,
      "eval_samples_per_second": 3610.033,
      "eval_steps_per_second": 451.27,
      "step": 16500
    },
    {
      "epoch": 0.17520550918108627,
      "grad_norm": 1.9427512884140015,
      "learning_rate": 4.912417954689816e-05,
      "loss": 1.5673,
      "step": 16550
    },
    {
      "epoch": 0.17573483096108955,
      "grad_norm": 1.9846547842025757,
      "learning_rate": 4.9121532923988995e-05,
      "loss": 1.5448,
      "step": 16600
    },
    {
      "epoch": 0.17626415274109283,
      "grad_norm": 2.0573015213012695,
      "learning_rate": 4.911888630107982e-05,
      "loss": 1.5375,
      "step": 16650
    },
    {
      "epoch": 0.17679347452109612,
      "grad_norm": 1.9457427263259888,
      "learning_rate": 4.911623967817066e-05,
      "loss": 1.5804,
      "step": 16700
    },
    {
      "epoch": 0.1773227963010994,
      "grad_norm": 1.9713680744171143,
      "learning_rate": 4.9113593055261484e-05,
      "loss": 1.5498,
      "step": 16750
    },
    {
      "epoch": 0.17785211808110268,
      "grad_norm": 1.9783987998962402,
      "learning_rate": 4.9110946432352325e-05,
      "loss": 1.5428,
      "step": 16800
    },
    {
      "epoch": 0.17838143986110597,
      "grad_norm": 1.814770221710205,
      "learning_rate": 4.910829980944315e-05,
      "loss": 1.554,
      "step": 16850
    },
    {
      "epoch": 0.17891076164110925,
      "grad_norm": 1.8895468711853027,
      "learning_rate": 4.9105653186533987e-05,
      "loss": 1.5329,
      "step": 16900
    },
    {
      "epoch": 0.17944008342111253,
      "grad_norm": 1.9814562797546387,
      "learning_rate": 4.9103006563624814e-05,
      "loss": 1.5409,
      "step": 16950
    },
    {
      "epoch": 0.17996940520111582,
      "grad_norm": 2.0817134380340576,
      "learning_rate": 4.910035994071565e-05,
      "loss": 1.5436,
      "step": 17000
    },
    {
      "epoch": 0.17996940520111582,
      "eval_loss": 1.5134464502334595,
      "eval_runtime": 46.5714,
      "eval_samples_per_second": 3605.86,
      "eval_steps_per_second": 450.749,
      "step": 17000
    },
    {
      "epoch": 0.1804987269811191,
      "grad_norm": 1.9797266721725464,
      "learning_rate": 4.909771331780648e-05,
      "loss": 1.5412,
      "step": 17050
    },
    {
      "epoch": 0.18102804876112238,
      "grad_norm": 1.916986107826233,
      "learning_rate": 4.909506669489731e-05,
      "loss": 1.5538,
      "step": 17100
    },
    {
      "epoch": 0.18155737054112567,
      "grad_norm": 1.9754772186279297,
      "learning_rate": 4.9092420071988143e-05,
      "loss": 1.5344,
      "step": 17150
    },
    {
      "epoch": 0.18208669232112895,
      "grad_norm": 1.9316679239273071,
      "learning_rate": 4.908977344907898e-05,
      "loss": 1.5474,
      "step": 17200
    },
    {
      "epoch": 0.1826160141011322,
      "grad_norm": 1.9037516117095947,
      "learning_rate": 4.908712682616981e-05,
      "loss": 1.5544,
      "step": 17250
    },
    {
      "epoch": 0.1831453358811355,
      "grad_norm": 1.8188484907150269,
      "learning_rate": 4.908448020326064e-05,
      "loss": 1.539,
      "step": 17300
    },
    {
      "epoch": 0.18367465766113877,
      "grad_norm": 1.763899564743042,
      "learning_rate": 4.908183358035147e-05,
      "loss": 1.5155,
      "step": 17350
    },
    {
      "epoch": 0.18420397944114206,
      "grad_norm": 1.8647913932800293,
      "learning_rate": 4.907918695744231e-05,
      "loss": 1.5393,
      "step": 17400
    },
    {
      "epoch": 0.18473330122114534,
      "grad_norm": 1.8249518871307373,
      "learning_rate": 4.907654033453314e-05,
      "loss": 1.546,
      "step": 17450
    },
    {
      "epoch": 0.18526262300114862,
      "grad_norm": 2.082728147506714,
      "learning_rate": 4.907389371162397e-05,
      "loss": 1.5536,
      "step": 17500
    },
    {
      "epoch": 0.18526262300114862,
      "eval_loss": 1.5111818313598633,
      "eval_runtime": 46.7345,
      "eval_samples_per_second": 3593.278,
      "eval_steps_per_second": 449.176,
      "step": 17500
    },
    {
      "epoch": 0.1857919447811519,
      "grad_norm": 1.9215706586837769,
      "learning_rate": 4.90712470887148e-05,
      "loss": 1.5388,
      "step": 17550
    },
    {
      "epoch": 0.1863212665611552,
      "grad_norm": 1.9517405033111572,
      "learning_rate": 4.906860046580564e-05,
      "loss": 1.5316,
      "step": 17600
    },
    {
      "epoch": 0.18685058834115847,
      "grad_norm": 1.9171926975250244,
      "learning_rate": 4.9065953842896464e-05,
      "loss": 1.5274,
      "step": 17650
    },
    {
      "epoch": 0.18737991012116176,
      "grad_norm": 2.0807485580444336,
      "learning_rate": 4.90633072199873e-05,
      "loss": 1.5429,
      "step": 17700
    },
    {
      "epoch": 0.18790923190116504,
      "grad_norm": 2.0478463172912598,
      "learning_rate": 4.9060660597078126e-05,
      "loss": 1.5547,
      "step": 17750
    },
    {
      "epoch": 0.18843855368116832,
      "grad_norm": 1.779668927192688,
      "learning_rate": 4.9058013974168966e-05,
      "loss": 1.5249,
      "step": 17800
    },
    {
      "epoch": 0.1889678754611716,
      "grad_norm": 2.0632379055023193,
      "learning_rate": 4.9055367351259794e-05,
      "loss": 1.5613,
      "step": 17850
    },
    {
      "epoch": 0.1894971972411749,
      "grad_norm": 1.8572478294372559,
      "learning_rate": 4.905272072835063e-05,
      "loss": 1.5397,
      "step": 17900
    },
    {
      "epoch": 0.19002651902117818,
      "grad_norm": 1.95940101146698,
      "learning_rate": 4.9050074105441455e-05,
      "loss": 1.5374,
      "step": 17950
    },
    {
      "epoch": 0.19055584080118146,
      "grad_norm": 1.881949543952942,
      "learning_rate": 4.9047427482532296e-05,
      "loss": 1.5537,
      "step": 18000
    },
    {
      "epoch": 0.19055584080118146,
      "eval_loss": 1.5035945177078247,
      "eval_runtime": 46.6033,
      "eval_samples_per_second": 3603.391,
      "eval_steps_per_second": 450.44,
      "step": 18000
    },
    {
      "epoch": 0.19108516258118471,
      "grad_norm": 2.0296878814697266,
      "learning_rate": 4.9044780859623123e-05,
      "loss": 1.5242,
      "step": 18050
    },
    {
      "epoch": 0.191614484361188,
      "grad_norm": 1.952677607536316,
      "learning_rate": 4.904213423671396e-05,
      "loss": 1.5235,
      "step": 18100
    },
    {
      "epoch": 0.19214380614119128,
      "grad_norm": 1.7837469577789307,
      "learning_rate": 4.9039487613804785e-05,
      "loss": 1.5259,
      "step": 18150
    },
    {
      "epoch": 0.19267312792119456,
      "grad_norm": 1.9083919525146484,
      "learning_rate": 4.903684099089562e-05,
      "loss": 1.5451,
      "step": 18200
    },
    {
      "epoch": 0.19320244970119785,
      "grad_norm": 1.970438003540039,
      "learning_rate": 4.903419436798645e-05,
      "loss": 1.5663,
      "step": 18250
    },
    {
      "epoch": 0.19373177148120113,
      "grad_norm": 2.013751745223999,
      "learning_rate": 4.903154774507728e-05,
      "loss": 1.5233,
      "step": 18300
    },
    {
      "epoch": 0.19426109326120442,
      "grad_norm": 1.9768176078796387,
      "learning_rate": 4.9028901122168114e-05,
      "loss": 1.5282,
      "step": 18350
    },
    {
      "epoch": 0.1947904150412077,
      "grad_norm": 1.9253822565078735,
      "learning_rate": 4.902625449925895e-05,
      "loss": 1.5204,
      "step": 18400
    },
    {
      "epoch": 0.19531973682121098,
      "grad_norm": 2.000218391418457,
      "learning_rate": 4.902360787634978e-05,
      "loss": 1.5438,
      "step": 18450
    },
    {
      "epoch": 0.19584905860121427,
      "grad_norm": 2.0398287773132324,
      "learning_rate": 4.902096125344061e-05,
      "loss": 1.5175,
      "step": 18500
    },
    {
      "epoch": 0.19584905860121427,
      "eval_loss": 1.5004962682724,
      "eval_runtime": 46.5836,
      "eval_samples_per_second": 3604.918,
      "eval_steps_per_second": 450.631,
      "step": 18500
    },
    {
      "epoch": 0.19637838038121755,
      "grad_norm": 1.997974157333374,
      "learning_rate": 4.9018367562989625e-05,
      "loss": 1.5453,
      "step": 18550
    },
    {
      "epoch": 0.19690770216122083,
      "grad_norm": 1.9946551322937012,
      "learning_rate": 4.901572094008046e-05,
      "loss": 1.5202,
      "step": 18600
    },
    {
      "epoch": 0.19743702394122412,
      "grad_norm": 1.8960381746292114,
      "learning_rate": 4.901307431717129e-05,
      "loss": 1.5389,
      "step": 18650
    },
    {
      "epoch": 0.1979663457212274,
      "grad_norm": 1.8732538223266602,
      "learning_rate": 4.901042769426212e-05,
      "loss": 1.5251,
      "step": 18700
    },
    {
      "epoch": 0.19849566750123068,
      "grad_norm": 1.9413079023361206,
      "learning_rate": 4.9007781071352954e-05,
      "loss": 1.5208,
      "step": 18750
    },
    {
      "epoch": 0.19902498928123397,
      "grad_norm": 1.8991590738296509,
      "learning_rate": 4.900513444844379e-05,
      "loss": 1.498,
      "step": 18800
    },
    {
      "epoch": 0.19955431106123725,
      "grad_norm": 1.9280498027801514,
      "learning_rate": 4.900248782553462e-05,
      "loss": 1.5389,
      "step": 18850
    },
    {
      "epoch": 0.2000836328412405,
      "grad_norm": 1.86397123336792,
      "learning_rate": 4.899984120262545e-05,
      "loss": 1.5325,
      "step": 18900
    },
    {
      "epoch": 0.2006129546212438,
      "grad_norm": 1.9587020874023438,
      "learning_rate": 4.8997194579716284e-05,
      "loss": 1.5153,
      "step": 18950
    },
    {
      "epoch": 0.20114227640124707,
      "grad_norm": 1.8773765563964844,
      "learning_rate": 4.899454795680712e-05,
      "loss": 1.5319,
      "step": 19000
    },
    {
      "epoch": 0.20114227640124707,
      "eval_loss": 1.4978744983673096,
      "eval_runtime": 46.5703,
      "eval_samples_per_second": 3605.947,
      "eval_steps_per_second": 450.759,
      "step": 19000
    },
    {
      "epoch": 0.20167159818125036,
      "grad_norm": 1.9880638122558594,
      "learning_rate": 4.899190133389795e-05,
      "loss": 1.5188,
      "step": 19050
    },
    {
      "epoch": 0.20220091996125364,
      "grad_norm": 2.0773017406463623,
      "learning_rate": 4.898925471098878e-05,
      "loss": 1.5247,
      "step": 19100
    },
    {
      "epoch": 0.20273024174125692,
      "grad_norm": 1.8691582679748535,
      "learning_rate": 4.8986608088079614e-05,
      "loss": 1.5209,
      "step": 19150
    },
    {
      "epoch": 0.2032595635212602,
      "grad_norm": 1.923261284828186,
      "learning_rate": 4.898396146517045e-05,
      "loss": 1.5053,
      "step": 19200
    },
    {
      "epoch": 0.2037888853012635,
      "grad_norm": 1.9170187711715698,
      "learning_rate": 4.8981314842261275e-05,
      "loss": 1.5194,
      "step": 19250
    },
    {
      "epoch": 0.20431820708126677,
      "grad_norm": 1.7968780994415283,
      "learning_rate": 4.897866821935211e-05,
      "loss": 1.5067,
      "step": 19300
    },
    {
      "epoch": 0.20484752886127006,
      "grad_norm": 1.9013186693191528,
      "learning_rate": 4.8976021596442936e-05,
      "loss": 1.5281,
      "step": 19350
    },
    {
      "epoch": 0.20537685064127334,
      "grad_norm": 1.9974919557571411,
      "learning_rate": 4.897337497353378e-05,
      "loss": 1.5235,
      "step": 19400
    },
    {
      "epoch": 0.20590617242127662,
      "grad_norm": 1.8132978677749634,
      "learning_rate": 4.8970728350624605e-05,
      "loss": 1.5166,
      "step": 19450
    },
    {
      "epoch": 0.2064354942012799,
      "grad_norm": 1.8384225368499756,
      "learning_rate": 4.896808172771544e-05,
      "loss": 1.5171,
      "step": 19500
    },
    {
      "epoch": 0.2064354942012799,
      "eval_loss": 1.4937243461608887,
      "eval_runtime": 46.5711,
      "eval_samples_per_second": 3605.888,
      "eval_steps_per_second": 450.752,
      "step": 19500
    },
    {
      "epoch": 0.2069648159812832,
      "grad_norm": 2.3116772174835205,
      "learning_rate": 4.8965435104806266e-05,
      "loss": 1.5227,
      "step": 19550
    },
    {
      "epoch": 0.20749413776128647,
      "grad_norm": 1.7901062965393066,
      "learning_rate": 4.896278848189711e-05,
      "loss": 1.521,
      "step": 19600
    },
    {
      "epoch": 0.20802345954128976,
      "grad_norm": 1.7403489351272583,
      "learning_rate": 4.8960141858987934e-05,
      "loss": 1.5124,
      "step": 19650
    },
    {
      "epoch": 0.20855278132129304,
      "grad_norm": 1.948004126548767,
      "learning_rate": 4.895749523607877e-05,
      "loss": 1.5237,
      "step": 19700
    },
    {
      "epoch": 0.2090821031012963,
      "grad_norm": 1.8592844009399414,
      "learning_rate": 4.8954848613169596e-05,
      "loss": 1.5035,
      "step": 19750
    },
    {
      "epoch": 0.20961142488129958,
      "grad_norm": 1.7106693983078003,
      "learning_rate": 4.895220199026043e-05,
      "loss": 1.5127,
      "step": 19800
    },
    {
      "epoch": 0.21014074666130286,
      "grad_norm": 1.8889963626861572,
      "learning_rate": 4.8949555367351264e-05,
      "loss": 1.538,
      "step": 19850
    },
    {
      "epoch": 0.21067006844130615,
      "grad_norm": 1.967343807220459,
      "learning_rate": 4.894690874444209e-05,
      "loss": 1.5238,
      "step": 19900
    },
    {
      "epoch": 0.21119939022130943,
      "grad_norm": 1.993245005607605,
      "learning_rate": 4.8944262121532925e-05,
      "loss": 1.5247,
      "step": 19950
    },
    {
      "epoch": 0.2117287120013127,
      "grad_norm": 1.808371901512146,
      "learning_rate": 4.894161549862376e-05,
      "loss": 1.5208,
      "step": 20000
    },
    {
      "epoch": 0.2117287120013127,
      "eval_loss": 1.4890244007110596,
      "eval_runtime": 46.6359,
      "eval_samples_per_second": 3600.873,
      "eval_steps_per_second": 450.125,
      "step": 20000
    },
    {
      "epoch": 0.212258033781316,
      "grad_norm": 1.8779131174087524,
      "learning_rate": 4.8938968875714593e-05,
      "loss": 1.4927,
      "step": 20050
    },
    {
      "epoch": 0.21278735556131928,
      "grad_norm": 1.9727482795715332,
      "learning_rate": 4.893632225280542e-05,
      "loss": 1.5251,
      "step": 20100
    },
    {
      "epoch": 0.21331667734132256,
      "grad_norm": 2.051304340362549,
      "learning_rate": 4.8933675629896255e-05,
      "loss": 1.5088,
      "step": 20150
    },
    {
      "epoch": 0.21384599912132585,
      "grad_norm": 2.012547731399536,
      "learning_rate": 4.893102900698709e-05,
      "loss": 1.5159,
      "step": 20200
    },
    {
      "epoch": 0.21437532090132913,
      "grad_norm": 2.034508228302002,
      "learning_rate": 4.892838238407792e-05,
      "loss": 1.512,
      "step": 20250
    },
    {
      "epoch": 0.21490464268133241,
      "grad_norm": 1.9328186511993408,
      "learning_rate": 4.892573576116875e-05,
      "loss": 1.5122,
      "step": 20300
    },
    {
      "epoch": 0.2154339644613357,
      "grad_norm": 2.0773212909698486,
      "learning_rate": 4.8923089138259585e-05,
      "loss": 1.5481,
      "step": 20350
    },
    {
      "epoch": 0.21596328624133898,
      "grad_norm": 1.7773746252059937,
      "learning_rate": 4.892044251535042e-05,
      "loss": 1.5212,
      "step": 20400
    },
    {
      "epoch": 0.21649260802134226,
      "grad_norm": 2.1177797317504883,
      "learning_rate": 4.8917795892441246e-05,
      "loss": 1.5128,
      "step": 20450
    },
    {
      "epoch": 0.21702192980134555,
      "grad_norm": 1.931761384010315,
      "learning_rate": 4.891514926953208e-05,
      "loss": 1.5022,
      "step": 20500
    },
    {
      "epoch": 0.21702192980134555,
      "eval_loss": 1.4891523122787476,
      "eval_runtime": 46.5652,
      "eval_samples_per_second": 3606.339,
      "eval_steps_per_second": 450.808,
      "step": 20500
    },
    {
      "epoch": 0.21755125158134883,
      "grad_norm": 1.8545410633087158,
      "learning_rate": 4.891250264662291e-05,
      "loss": 1.5232,
      "step": 20550
    },
    {
      "epoch": 0.2180805733613521,
      "grad_norm": 1.8797070980072021,
      "learning_rate": 4.890985602371375e-05,
      "loss": 1.5104,
      "step": 20600
    },
    {
      "epoch": 0.21860989514135537,
      "grad_norm": 1.7170624732971191,
      "learning_rate": 4.8907209400804576e-05,
      "loss": 1.4782,
      "step": 20650
    },
    {
      "epoch": 0.21913921692135865,
      "grad_norm": 1.9346510171890259,
      "learning_rate": 4.890456277789541e-05,
      "loss": 1.5326,
      "step": 20700
    },
    {
      "epoch": 0.21966853870136194,
      "grad_norm": 2.0184457302093506,
      "learning_rate": 4.890191615498624e-05,
      "loss": 1.5135,
      "step": 20750
    },
    {
      "epoch": 0.22019786048136522,
      "grad_norm": 2.0642452239990234,
      "learning_rate": 4.889926953207707e-05,
      "loss": 1.5106,
      "step": 20800
    },
    {
      "epoch": 0.2207271822613685,
      "grad_norm": 2.0686681270599365,
      "learning_rate": 4.8896622909167905e-05,
      "loss": 1.5068,
      "step": 20850
    },
    {
      "epoch": 0.2212565040413718,
      "grad_norm": 1.8927850723266602,
      "learning_rate": 4.889397628625873e-05,
      "loss": 1.5201,
      "step": 20900
    },
    {
      "epoch": 0.22178582582137507,
      "grad_norm": 1.8441848754882812,
      "learning_rate": 4.8891329663349567e-05,
      "loss": 1.4875,
      "step": 20950
    },
    {
      "epoch": 0.22231514760137835,
      "grad_norm": 2.073258399963379,
      "learning_rate": 4.88886830404404e-05,
      "loss": 1.5064,
      "step": 21000
    },
    {
      "epoch": 0.22231514760137835,
      "eval_loss": 1.4829596281051636,
      "eval_runtime": 46.6927,
      "eval_samples_per_second": 3596.494,
      "eval_steps_per_second": 449.578,
      "step": 21000
    },
    {
      "epoch": 0.22284446938138164,
      "grad_norm": 1.8025703430175781,
      "learning_rate": 4.8886036417531235e-05,
      "loss": 1.499,
      "step": 21050
    },
    {
      "epoch": 0.22337379116138492,
      "grad_norm": 1.827247977256775,
      "learning_rate": 4.888338979462206e-05,
      "loss": 1.5027,
      "step": 21100
    },
    {
      "epoch": 0.2239031129413882,
      "grad_norm": 2.051954746246338,
      "learning_rate": 4.8880743171712896e-05,
      "loss": 1.5189,
      "step": 21150
    },
    {
      "epoch": 0.2244324347213915,
      "grad_norm": 1.7848565578460693,
      "learning_rate": 4.887809654880373e-05,
      "loss": 1.4926,
      "step": 21200
    },
    {
      "epoch": 0.22496175650139477,
      "grad_norm": 1.9640165567398071,
      "learning_rate": 4.8875449925894564e-05,
      "loss": 1.5191,
      "step": 21250
    },
    {
      "epoch": 0.22549107828139806,
      "grad_norm": 1.9993339776992798,
      "learning_rate": 4.887280330298539e-05,
      "loss": 1.5237,
      "step": 21300
    },
    {
      "epoch": 0.22602040006140134,
      "grad_norm": 1.8427826166152954,
      "learning_rate": 4.8870156680076226e-05,
      "loss": 1.5058,
      "step": 21350
    },
    {
      "epoch": 0.22654972184140462,
      "grad_norm": 1.8299541473388672,
      "learning_rate": 4.886751005716706e-05,
      "loss": 1.502,
      "step": 21400
    },
    {
      "epoch": 0.22707904362140788,
      "grad_norm": 1.8445128202438354,
      "learning_rate": 4.886486343425789e-05,
      "loss": 1.4903,
      "step": 21450
    },
    {
      "epoch": 0.22760836540141116,
      "grad_norm": 1.8577158451080322,
      "learning_rate": 4.886221681134872e-05,
      "loss": 1.4844,
      "step": 21500
    },
    {
      "epoch": 0.22760836540141116,
      "eval_loss": 1.4816011190414429,
      "eval_runtime": 46.6749,
      "eval_samples_per_second": 3597.862,
      "eval_steps_per_second": 449.749,
      "step": 21500
    },
    {
      "epoch": 0.22813768718141444,
      "grad_norm": 1.7032458782196045,
      "learning_rate": 4.885957018843955e-05,
      "loss": 1.51,
      "step": 21550
    },
    {
      "epoch": 0.22866700896141773,
      "grad_norm": 1.808184027671814,
      "learning_rate": 4.885692356553039e-05,
      "loss": 1.4898,
      "step": 21600
    },
    {
      "epoch": 0.229196330741421,
      "grad_norm": 1.8309119939804077,
      "learning_rate": 4.885427694262122e-05,
      "loss": 1.5195,
      "step": 21650
    },
    {
      "epoch": 0.2297256525214243,
      "grad_norm": 1.8346370458602905,
      "learning_rate": 4.885168325217023e-05,
      "loss": 1.4997,
      "step": 21700
    },
    {
      "epoch": 0.23025497430142758,
      "grad_norm": 1.9574289321899414,
      "learning_rate": 4.8849036629261066e-05,
      "loss": 1.523,
      "step": 21750
    },
    {
      "epoch": 0.23078429608143086,
      "grad_norm": 1.9382827281951904,
      "learning_rate": 4.88463900063519e-05,
      "loss": 1.4985,
      "step": 21800
    },
    {
      "epoch": 0.23131361786143415,
      "grad_norm": 1.997944712638855,
      "learning_rate": 4.884374338344273e-05,
      "loss": 1.5148,
      "step": 21850
    },
    {
      "epoch": 0.23184293964143743,
      "grad_norm": 1.6177250146865845,
      "learning_rate": 4.884109676053356e-05,
      "loss": 1.5039,
      "step": 21900
    },
    {
      "epoch": 0.2323722614214407,
      "grad_norm": 1.8524848222732544,
      "learning_rate": 4.883845013762439e-05,
      "loss": 1.5089,
      "step": 21950
    },
    {
      "epoch": 0.232901583201444,
      "grad_norm": 1.8970668315887451,
      "learning_rate": 4.883580351471523e-05,
      "loss": 1.4886,
      "step": 22000
    },
    {
      "epoch": 0.232901583201444,
      "eval_loss": 1.4772669076919556,
      "eval_runtime": 46.5496,
      "eval_samples_per_second": 3607.55,
      "eval_steps_per_second": 450.96,
      "step": 22000
    },
    {
      "epoch": 0.23343090498144728,
      "grad_norm": 1.9363734722137451,
      "learning_rate": 4.883315689180606e-05,
      "loss": 1.5064,
      "step": 22050
    },
    {
      "epoch": 0.23396022676145056,
      "grad_norm": 1.816143274307251,
      "learning_rate": 4.883051026889689e-05,
      "loss": 1.5162,
      "step": 22100
    },
    {
      "epoch": 0.23448954854145385,
      "grad_norm": 1.8693583011627197,
      "learning_rate": 4.882786364598772e-05,
      "loss": 1.5108,
      "step": 22150
    },
    {
      "epoch": 0.23501887032145713,
      "grad_norm": 1.9783560037612915,
      "learning_rate": 4.882521702307856e-05,
      "loss": 1.51,
      "step": 22200
    },
    {
      "epoch": 0.23554819210146039,
      "grad_norm": 2.039818048477173,
      "learning_rate": 4.8822570400169386e-05,
      "loss": 1.4996,
      "step": 22250
    },
    {
      "epoch": 0.23607751388146367,
      "grad_norm": 1.7810382843017578,
      "learning_rate": 4.881992377726022e-05,
      "loss": 1.4955,
      "step": 22300
    },
    {
      "epoch": 0.23660683566146695,
      "grad_norm": 1.7806179523468018,
      "learning_rate": 4.881727715435105e-05,
      "loss": 1.4798,
      "step": 22350
    },
    {
      "epoch": 0.23713615744147024,
      "grad_norm": 1.8546403646469116,
      "learning_rate": 4.881463053144188e-05,
      "loss": 1.5088,
      "step": 22400
    },
    {
      "epoch": 0.23766547922147352,
      "grad_norm": 1.8249008655548096,
      "learning_rate": 4.8811983908532716e-05,
      "loss": 1.5186,
      "step": 22450
    },
    {
      "epoch": 0.2381948010014768,
      "grad_norm": 1.8763508796691895,
      "learning_rate": 4.880933728562354e-05,
      "loss": 1.4799,
      "step": 22500
    },
    {
      "epoch": 0.2381948010014768,
      "eval_loss": 1.472684621810913,
      "eval_runtime": 46.5903,
      "eval_samples_per_second": 3604.395,
      "eval_steps_per_second": 450.565,
      "step": 22500
    },
    {
      "epoch": 0.23872412278148009,
      "grad_norm": 1.7191170454025269,
      "learning_rate": 4.880669066271438e-05,
      "loss": 1.4948,
      "step": 22550
    },
    {
      "epoch": 0.23925344456148337,
      "grad_norm": 1.8175146579742432,
      "learning_rate": 4.880404403980521e-05,
      "loss": 1.4883,
      "step": 22600
    },
    {
      "epoch": 0.23978276634148665,
      "grad_norm": 2.0230579376220703,
      "learning_rate": 4.8801397416896046e-05,
      "loss": 1.5003,
      "step": 22650
    },
    {
      "epoch": 0.24031208812148994,
      "grad_norm": 1.8575587272644043,
      "learning_rate": 4.879875079398687e-05,
      "loss": 1.5052,
      "step": 22700
    },
    {
      "epoch": 0.24084140990149322,
      "grad_norm": 1.8582048416137695,
      "learning_rate": 4.879610417107771e-05,
      "loss": 1.5103,
      "step": 22750
    },
    {
      "epoch": 0.2413707316814965,
      "grad_norm": 1.760922908782959,
      "learning_rate": 4.879345754816854e-05,
      "loss": 1.4766,
      "step": 22800
    },
    {
      "epoch": 0.2419000534614998,
      "grad_norm": 1.7266180515289307,
      "learning_rate": 4.8790810925259375e-05,
      "loss": 1.4973,
      "step": 22850
    },
    {
      "epoch": 0.24242937524150307,
      "grad_norm": 1.7118562459945679,
      "learning_rate": 4.87881643023502e-05,
      "loss": 1.4778,
      "step": 22900
    },
    {
      "epoch": 0.24295869702150635,
      "grad_norm": 1.8633556365966797,
      "learning_rate": 4.878551767944104e-05,
      "loss": 1.4897,
      "step": 22950
    },
    {
      "epoch": 0.24348801880150964,
      "grad_norm": 1.8949174880981445,
      "learning_rate": 4.878287105653187e-05,
      "loss": 1.4782,
      "step": 23000
    },
    {
      "epoch": 0.24348801880150964,
      "eval_loss": 1.4697192907333374,
      "eval_runtime": 46.549,
      "eval_samples_per_second": 3607.598,
      "eval_steps_per_second": 450.966,
      "step": 23000
    },
    {
      "epoch": 0.24401734058151292,
      "grad_norm": 2.098334550857544,
      "learning_rate": 4.87802244336227e-05,
      "loss": 1.5037,
      "step": 23050
    },
    {
      "epoch": 0.24454666236151618,
      "grad_norm": 1.8625223636627197,
      "learning_rate": 4.877757781071353e-05,
      "loss": 1.4772,
      "step": 23100
    },
    {
      "epoch": 0.24507598414151946,
      "grad_norm": 1.7967729568481445,
      "learning_rate": 4.877493118780436e-05,
      "loss": 1.4887,
      "step": 23150
    },
    {
      "epoch": 0.24560530592152274,
      "grad_norm": 1.6988346576690674,
      "learning_rate": 4.87722845648952e-05,
      "loss": 1.5058,
      "step": 23200
    },
    {
      "epoch": 0.24613462770152603,
      "grad_norm": 1.916954755783081,
      "learning_rate": 4.876963794198603e-05,
      "loss": 1.4761,
      "step": 23250
    },
    {
      "epoch": 0.2466639494815293,
      "grad_norm": 1.9835351705551147,
      "learning_rate": 4.876699131907686e-05,
      "loss": 1.4715,
      "step": 23300
    },
    {
      "epoch": 0.2471932712615326,
      "grad_norm": 1.7434656620025635,
      "learning_rate": 4.876434469616769e-05,
      "loss": 1.4935,
      "step": 23350
    },
    {
      "epoch": 0.24772259304153588,
      "grad_norm": 1.9510748386383057,
      "learning_rate": 4.876169807325853e-05,
      "loss": 1.4754,
      "step": 23400
    },
    {
      "epoch": 0.24825191482153916,
      "grad_norm": 1.8465683460235596,
      "learning_rate": 4.875905145034936e-05,
      "loss": 1.4872,
      "step": 23450
    },
    {
      "epoch": 0.24878123660154244,
      "grad_norm": 1.8092540502548218,
      "learning_rate": 4.875640482744019e-05,
      "loss": 1.5149,
      "step": 23500
    },
    {
      "epoch": 0.24878123660154244,
      "eval_loss": 1.47012197971344,
      "eval_runtime": 46.6321,
      "eval_samples_per_second": 3601.168,
      "eval_steps_per_second": 450.162,
      "step": 23500
    },
    {
      "epoch": 0.24931055838154573,
      "grad_norm": 1.895991325378418,
      "learning_rate": 4.875375820453102e-05,
      "loss": 1.5002,
      "step": 23550
    },
    {
      "epoch": 0.249839880161549,
      "grad_norm": 1.7832802534103394,
      "learning_rate": 4.875111158162185e-05,
      "loss": 1.5122,
      "step": 23600
    },
    {
      "epoch": 0.25036920194155227,
      "grad_norm": 2.176226854324341,
      "learning_rate": 4.874846495871269e-05,
      "loss": 1.5054,
      "step": 23650
    },
    {
      "epoch": 0.2508985237215556,
      "grad_norm": 1.7494503259658813,
      "learning_rate": 4.8745818335803514e-05,
      "loss": 1.4943,
      "step": 23700
    },
    {
      "epoch": 0.25142784550155883,
      "grad_norm": 1.828025460243225,
      "learning_rate": 4.874317171289435e-05,
      "loss": 1.4914,
      "step": 23750
    },
    {
      "epoch": 0.25195716728156214,
      "grad_norm": 1.8176069259643555,
      "learning_rate": 4.874052508998518e-05,
      "loss": 1.4796,
      "step": 23800
    },
    {
      "epoch": 0.2524864890615654,
      "grad_norm": 1.87238347530365,
      "learning_rate": 4.8737878467076017e-05,
      "loss": 1.4918,
      "step": 23850
    },
    {
      "epoch": 0.2530158108415687,
      "grad_norm": 2.014259099960327,
      "learning_rate": 4.8735231844166844e-05,
      "loss": 1.4767,
      "step": 23900
    },
    {
      "epoch": 0.25354513262157197,
      "grad_norm": 1.9450509548187256,
      "learning_rate": 4.873258522125768e-05,
      "loss": 1.4958,
      "step": 23950
    },
    {
      "epoch": 0.2540744544015753,
      "grad_norm": 1.8332117795944214,
      "learning_rate": 4.872993859834851e-05,
      "loss": 1.4908,
      "step": 24000
    },
    {
      "epoch": 0.2540744544015753,
      "eval_loss": 1.4630229473114014,
      "eval_runtime": 46.7964,
      "eval_samples_per_second": 3588.527,
      "eval_steps_per_second": 448.582,
      "step": 24000
    },
    {
      "epoch": 0.25460377618157853,
      "grad_norm": 1.8443068265914917,
      "learning_rate": 4.8727291975439346e-05,
      "loss": 1.5074,
      "step": 24050
    },
    {
      "epoch": 0.25513309796158185,
      "grad_norm": 1.8254609107971191,
      "learning_rate": 4.8724645352530174e-05,
      "loss": 1.4778,
      "step": 24100
    },
    {
      "epoch": 0.2556624197415851,
      "grad_norm": 1.903305172920227,
      "learning_rate": 4.872199872962101e-05,
      "loss": 1.489,
      "step": 24150
    },
    {
      "epoch": 0.2561917415215884,
      "grad_norm": 1.6241635084152222,
      "learning_rate": 4.871935210671184e-05,
      "loss": 1.4868,
      "step": 24200
    },
    {
      "epoch": 0.25672106330159167,
      "grad_norm": 1.8533190488815308,
      "learning_rate": 4.871670548380267e-05,
      "loss": 1.4893,
      "step": 24250
    },
    {
      "epoch": 0.257250385081595,
      "grad_norm": 1.8577067852020264,
      "learning_rate": 4.87140588608935e-05,
      "loss": 1.4878,
      "step": 24300
    },
    {
      "epoch": 0.25777970686159823,
      "grad_norm": 1.7679425477981567,
      "learning_rate": 4.871141223798433e-05,
      "loss": 1.4862,
      "step": 24350
    },
    {
      "epoch": 0.2583090286416015,
      "grad_norm": 1.8160873651504517,
      "learning_rate": 4.8708765615075165e-05,
      "loss": 1.4714,
      "step": 24400
    },
    {
      "epoch": 0.2588383504216048,
      "grad_norm": 1.7949844598770142,
      "learning_rate": 4.8706118992166e-05,
      "loss": 1.5027,
      "step": 24450
    },
    {
      "epoch": 0.25936767220160806,
      "grad_norm": 1.9260647296905518,
      "learning_rate": 4.870347236925683e-05,
      "loss": 1.4862,
      "step": 24500
    },
    {
      "epoch": 0.25936767220160806,
      "eval_loss": 1.4641492366790771,
      "eval_runtime": 46.7196,
      "eval_samples_per_second": 3594.425,
      "eval_steps_per_second": 449.319,
      "step": 24500
    },
    {
      "epoch": 0.25989699398161137,
      "grad_norm": 1.804552435874939,
      "learning_rate": 4.870082574634766e-05,
      "loss": 1.4885,
      "step": 24550
    },
    {
      "epoch": 0.2604263157616146,
      "grad_norm": 1.7566567659378052,
      "learning_rate": 4.8698179123438494e-05,
      "loss": 1.4782,
      "step": 24600
    },
    {
      "epoch": 0.26095563754161794,
      "grad_norm": 1.7990471124649048,
      "learning_rate": 4.869553250052933e-05,
      "loss": 1.5106,
      "step": 24650
    },
    {
      "epoch": 0.2614849593216212,
      "grad_norm": 1.740976333618164,
      "learning_rate": 4.869288587762016e-05,
      "loss": 1.4816,
      "step": 24700
    },
    {
      "epoch": 0.2620142811016245,
      "grad_norm": 1.7011678218841553,
      "learning_rate": 4.869023925471099e-05,
      "loss": 1.4933,
      "step": 24750
    },
    {
      "epoch": 0.26254360288162776,
      "grad_norm": 1.9652628898620605,
      "learning_rate": 4.8687592631801824e-05,
      "loss": 1.4961,
      "step": 24800
    },
    {
      "epoch": 0.26307292466163107,
      "grad_norm": 1.8774973154067993,
      "learning_rate": 4.868494600889266e-05,
      "loss": 1.4652,
      "step": 24850
    },
    {
      "epoch": 0.2636022464416343,
      "grad_norm": 1.7469377517700195,
      "learning_rate": 4.8682299385983485e-05,
      "loss": 1.489,
      "step": 24900
    },
    {
      "epoch": 0.26413156822163764,
      "grad_norm": 1.7761703729629517,
      "learning_rate": 4.867965276307432e-05,
      "loss": 1.4826,
      "step": 24950
    },
    {
      "epoch": 0.2646608900016409,
      "grad_norm": 1.7698991298675537,
      "learning_rate": 4.867700614016515e-05,
      "loss": 1.4746,
      "step": 25000
    },
    {
      "epoch": 0.2646608900016409,
      "eval_loss": 1.4584347009658813,
      "eval_runtime": 46.5839,
      "eval_samples_per_second": 3604.891,
      "eval_steps_per_second": 450.627,
      "step": 25000
    },
    {
      "epoch": 0.2651902117816442,
      "grad_norm": 1.8144676685333252,
      "learning_rate": 4.867435951725599e-05,
      "loss": 1.4676,
      "step": 25050
    },
    {
      "epoch": 0.26571953356164746,
      "grad_norm": 1.8396843671798706,
      "learning_rate": 4.8671712894346815e-05,
      "loss": 1.4905,
      "step": 25100
    },
    {
      "epoch": 0.26624885534165077,
      "grad_norm": 1.606764793395996,
      "learning_rate": 4.866906627143765e-05,
      "loss": 1.4993,
      "step": 25150
    },
    {
      "epoch": 0.266778177121654,
      "grad_norm": 1.9305152893066406,
      "learning_rate": 4.8666419648528476e-05,
      "loss": 1.4586,
      "step": 25200
    },
    {
      "epoch": 0.2673074989016573,
      "grad_norm": 1.7467058897018433,
      "learning_rate": 4.866377302561931e-05,
      "loss": 1.4667,
      "step": 25250
    },
    {
      "epoch": 0.2678368206816606,
      "grad_norm": 2.0113933086395264,
      "learning_rate": 4.8661126402710144e-05,
      "loss": 1.4499,
      "step": 25300
    },
    {
      "epoch": 0.26836614246166385,
      "grad_norm": 1.7036594152450562,
      "learning_rate": 4.865847977980097e-05,
      "loss": 1.4887,
      "step": 25350
    },
    {
      "epoch": 0.26889546424166716,
      "grad_norm": 1.5996423959732056,
      "learning_rate": 4.8655833156891806e-05,
      "loss": 1.4673,
      "step": 25400
    },
    {
      "epoch": 0.2694247860216704,
      "grad_norm": 1.7694281339645386,
      "learning_rate": 4.865318653398264e-05,
      "loss": 1.4804,
      "step": 25450
    },
    {
      "epoch": 0.2699541078016737,
      "grad_norm": 1.729606032371521,
      "learning_rate": 4.8650539911073474e-05,
      "loss": 1.486,
      "step": 25500
    },
    {
      "epoch": 0.2699541078016737,
      "eval_loss": 1.456199288368225,
      "eval_runtime": 46.7213,
      "eval_samples_per_second": 3594.29,
      "eval_steps_per_second": 449.302,
      "step": 25500
    },
    {
      "epoch": 0.270483429581677,
      "grad_norm": 1.9707614183425903,
      "learning_rate": 4.86478932881643e-05,
      "loss": 1.4794,
      "step": 25550
    },
    {
      "epoch": 0.2710127513616803,
      "grad_norm": 1.6233396530151367,
      "learning_rate": 4.8645246665255136e-05,
      "loss": 1.4706,
      "step": 25600
    },
    {
      "epoch": 0.27154207314168355,
      "grad_norm": 1.7038445472717285,
      "learning_rate": 4.864265297480416e-05,
      "loss": 1.4834,
      "step": 25650
    },
    {
      "epoch": 0.27207139492168686,
      "grad_norm": 2.029857873916626,
      "learning_rate": 4.8640006351894984e-05,
      "loss": 1.4771,
      "step": 25700
    },
    {
      "epoch": 0.2726007167016901,
      "grad_norm": 1.889413833618164,
      "learning_rate": 4.863735972898582e-05,
      "loss": 1.4892,
      "step": 25750
    },
    {
      "epoch": 0.2731300384816934,
      "grad_norm": 1.6666280031204224,
      "learning_rate": 4.8634713106076646e-05,
      "loss": 1.4828,
      "step": 25800
    },
    {
      "epoch": 0.2736593602616967,
      "grad_norm": 1.6978322267532349,
      "learning_rate": 4.863206648316748e-05,
      "loss": 1.5034,
      "step": 25850
    },
    {
      "epoch": 0.2741886820417,
      "grad_norm": 1.748762607574463,
      "learning_rate": 4.8629419860258314e-05,
      "loss": 1.4916,
      "step": 25900
    },
    {
      "epoch": 0.27471800382170325,
      "grad_norm": 1.8279677629470825,
      "learning_rate": 4.862677323734914e-05,
      "loss": 1.4638,
      "step": 25950
    },
    {
      "epoch": 0.27524732560170656,
      "grad_norm": 1.7399109601974487,
      "learning_rate": 4.8624126614439975e-05,
      "loss": 1.4943,
      "step": 26000
    },
    {
      "epoch": 0.27524732560170656,
      "eval_loss": 1.4536547660827637,
      "eval_runtime": 46.696,
      "eval_samples_per_second": 3596.237,
      "eval_steps_per_second": 449.546,
      "step": 26000
    },
    {
      "epoch": 0.2757766473817098,
      "grad_norm": 1.8831205368041992,
      "learning_rate": 4.862147999153081e-05,
      "loss": 1.5039,
      "step": 26050
    },
    {
      "epoch": 0.27630596916171307,
      "grad_norm": 1.67902672290802,
      "learning_rate": 4.8618833368621644e-05,
      "loss": 1.481,
      "step": 26100
    },
    {
      "epoch": 0.2768352909417164,
      "grad_norm": 1.7577786445617676,
      "learning_rate": 4.861618674571247e-05,
      "loss": 1.481,
      "step": 26150
    },
    {
      "epoch": 0.27736461272171964,
      "grad_norm": 1.9392527341842651,
      "learning_rate": 4.8613540122803305e-05,
      "loss": 1.4883,
      "step": 26200
    },
    {
      "epoch": 0.27789393450172295,
      "grad_norm": 1.8689444065093994,
      "learning_rate": 4.861089349989414e-05,
      "loss": 1.4985,
      "step": 26250
    },
    {
      "epoch": 0.2784232562817262,
      "grad_norm": 1.7319023609161377,
      "learning_rate": 4.8608246876984966e-05,
      "loss": 1.4694,
      "step": 26300
    },
    {
      "epoch": 0.2789525780617295,
      "grad_norm": 1.8310625553131104,
      "learning_rate": 4.86056002540758e-05,
      "loss": 1.4528,
      "step": 26350
    },
    {
      "epoch": 0.2794818998417328,
      "grad_norm": 1.7476009130477905,
      "learning_rate": 4.860295363116663e-05,
      "loss": 1.4606,
      "step": 26400
    },
    {
      "epoch": 0.2800112216217361,
      "grad_norm": 1.7124866247177124,
      "learning_rate": 4.860030700825747e-05,
      "loss": 1.4552,
      "step": 26450
    },
    {
      "epoch": 0.28054054340173934,
      "grad_norm": 2.067936897277832,
      "learning_rate": 4.8597660385348296e-05,
      "loss": 1.4632,
      "step": 26500
    },
    {
      "epoch": 0.28054054340173934,
      "eval_loss": 1.450263261795044,
      "eval_runtime": 46.6177,
      "eval_samples_per_second": 3602.28,
      "eval_steps_per_second": 450.301,
      "step": 26500
    },
    {
      "epoch": 0.28106986518174265,
      "grad_norm": 1.7757290601730347,
      "learning_rate": 4.859501376243913e-05,
      "loss": 1.468,
      "step": 26550
    },
    {
      "epoch": 0.2815991869617459,
      "grad_norm": 1.728471040725708,
      "learning_rate": 4.859236713952996e-05,
      "loss": 1.472,
      "step": 26600
    },
    {
      "epoch": 0.2821285087417492,
      "grad_norm": 1.8492285013198853,
      "learning_rate": 4.85897205166208e-05,
      "loss": 1.4834,
      "step": 26650
    },
    {
      "epoch": 0.2826578305217525,
      "grad_norm": 1.7969574928283691,
      "learning_rate": 4.8587073893711626e-05,
      "loss": 1.4846,
      "step": 26700
    },
    {
      "epoch": 0.2831871523017558,
      "grad_norm": 1.9097336530685425,
      "learning_rate": 4.858442727080246e-05,
      "loss": 1.4632,
      "step": 26750
    },
    {
      "epoch": 0.28371647408175904,
      "grad_norm": 1.9261958599090576,
      "learning_rate": 4.858178064789329e-05,
      "loss": 1.4667,
      "step": 26800
    },
    {
      "epoch": 0.28424579586176235,
      "grad_norm": 1.9436482191085815,
      "learning_rate": 4.857913402498412e-05,
      "loss": 1.4831,
      "step": 26850
    },
    {
      "epoch": 0.2847751176417656,
      "grad_norm": 1.739112138748169,
      "learning_rate": 4.8576487402074955e-05,
      "loss": 1.4661,
      "step": 26900
    },
    {
      "epoch": 0.28530443942176886,
      "grad_norm": 1.884439468383789,
      "learning_rate": 4.857384077916578e-05,
      "loss": 1.4688,
      "step": 26950
    },
    {
      "epoch": 0.2858337612017722,
      "grad_norm": 1.6803683042526245,
      "learning_rate": 4.857119415625662e-05,
      "loss": 1.4895,
      "step": 27000
    },
    {
      "epoch": 0.2858337612017722,
      "eval_loss": 1.4475315809249878,
      "eval_runtime": 46.583,
      "eval_samples_per_second": 3604.96,
      "eval_steps_per_second": 450.636,
      "step": 27000
    },
    {
      "epoch": 0.28636308298177543,
      "grad_norm": 1.7998193502426147,
      "learning_rate": 4.856854753334745e-05,
      "loss": 1.4571,
      "step": 27050
    },
    {
      "epoch": 0.28689240476177874,
      "grad_norm": 1.7186640501022339,
      "learning_rate": 4.8565900910438285e-05,
      "loss": 1.4805,
      "step": 27100
    },
    {
      "epoch": 0.287421726541782,
      "grad_norm": 1.905083179473877,
      "learning_rate": 4.856325428752911e-05,
      "loss": 1.4615,
      "step": 27150
    },
    {
      "epoch": 0.2879510483217853,
      "grad_norm": 1.905164361000061,
      "learning_rate": 4.8560607664619946e-05,
      "loss": 1.4584,
      "step": 27200
    },
    {
      "epoch": 0.28848037010178856,
      "grad_norm": 1.6548579931259155,
      "learning_rate": 4.855796104171078e-05,
      "loss": 1.4663,
      "step": 27250
    },
    {
      "epoch": 0.2890096918817919,
      "grad_norm": 1.886736273765564,
      "learning_rate": 4.8555314418801615e-05,
      "loss": 1.465,
      "step": 27300
    },
    {
      "epoch": 0.28953901366179513,
      "grad_norm": 1.5953489542007446,
      "learning_rate": 4.855266779589244e-05,
      "loss": 1.4902,
      "step": 27350
    },
    {
      "epoch": 0.29006833544179844,
      "grad_norm": 1.7508645057678223,
      "learning_rate": 4.8550021172983276e-05,
      "loss": 1.4967,
      "step": 27400
    },
    {
      "epoch": 0.2905976572218017,
      "grad_norm": 1.8998852968215942,
      "learning_rate": 4.854737455007411e-05,
      "loss": 1.4884,
      "step": 27450
    },
    {
      "epoch": 0.291126979001805,
      "grad_norm": 1.6672372817993164,
      "learning_rate": 4.854472792716494e-05,
      "loss": 1.5026,
      "step": 27500
    },
    {
      "epoch": 0.291126979001805,
      "eval_loss": 1.4435662031173706,
      "eval_runtime": 46.5661,
      "eval_samples_per_second": 3606.27,
      "eval_steps_per_second": 450.8,
      "step": 27500
    },
    {
      "epoch": 0.29165630078180826,
      "grad_norm": 1.8247318267822266,
      "learning_rate": 4.854208130425577e-05,
      "loss": 1.4603,
      "step": 27550
    },
    {
      "epoch": 0.2921856225618116,
      "grad_norm": 1.851391315460205,
      "learning_rate": 4.85394346813466e-05,
      "loss": 1.4475,
      "step": 27600
    },
    {
      "epoch": 0.29271494434181483,
      "grad_norm": 1.7207921743392944,
      "learning_rate": 4.853678805843744e-05,
      "loss": 1.4859,
      "step": 27650
    },
    {
      "epoch": 0.2932442661218181,
      "grad_norm": 1.9122823476791382,
      "learning_rate": 4.853414143552827e-05,
      "loss": 1.473,
      "step": 27700
    },
    {
      "epoch": 0.2937735879018214,
      "grad_norm": 1.6810359954833984,
      "learning_rate": 4.85314948126191e-05,
      "loss": 1.4654,
      "step": 27750
    },
    {
      "epoch": 0.29430290968182465,
      "grad_norm": 1.8483035564422607,
      "learning_rate": 4.852884818970993e-05,
      "loss": 1.4657,
      "step": 27800
    },
    {
      "epoch": 0.29483223146182796,
      "grad_norm": 1.8851314783096313,
      "learning_rate": 4.852620156680077e-05,
      "loss": 1.4632,
      "step": 27850
    },
    {
      "epoch": 0.2953615532418312,
      "grad_norm": 1.916193962097168,
      "learning_rate": 4.85235549438916e-05,
      "loss": 1.4639,
      "step": 27900
    },
    {
      "epoch": 0.29589087502183453,
      "grad_norm": 1.8105005025863647,
      "learning_rate": 4.852090832098243e-05,
      "loss": 1.4651,
      "step": 27950
    },
    {
      "epoch": 0.2964201968018378,
      "grad_norm": 1.7103632688522339,
      "learning_rate": 4.851826169807326e-05,
      "loss": 1.455,
      "step": 28000
    },
    {
      "epoch": 0.2964201968018378,
      "eval_loss": 1.44272780418396,
      "eval_runtime": 46.6218,
      "eval_samples_per_second": 3601.962,
      "eval_steps_per_second": 450.261,
      "step": 28000
    },
    {
      "epoch": 0.2969495185818411,
      "grad_norm": 1.8350058794021606,
      "learning_rate": 4.851561507516409e-05,
      "loss": 1.4835,
      "step": 28050
    },
    {
      "epoch": 0.29747884036184435,
      "grad_norm": 1.665438175201416,
      "learning_rate": 4.8512968452254926e-05,
      "loss": 1.4526,
      "step": 28100
    },
    {
      "epoch": 0.29800816214184767,
      "grad_norm": 1.785492181777954,
      "learning_rate": 4.8510321829345754e-05,
      "loss": 1.4646,
      "step": 28150
    },
    {
      "epoch": 0.2985374839218509,
      "grad_norm": 1.893873691558838,
      "learning_rate": 4.850767520643659e-05,
      "loss": 1.4499,
      "step": 28200
    },
    {
      "epoch": 0.29906680570185423,
      "grad_norm": 1.942003846168518,
      "learning_rate": 4.850502858352742e-05,
      "loss": 1.4585,
      "step": 28250
    },
    {
      "epoch": 0.2995961274818575,
      "grad_norm": 1.9216957092285156,
      "learning_rate": 4.8502381960618256e-05,
      "loss": 1.4758,
      "step": 28300
    },
    {
      "epoch": 0.3001254492618608,
      "grad_norm": 1.6861387491226196,
      "learning_rate": 4.849973533770908e-05,
      "loss": 1.4597,
      "step": 28350
    },
    {
      "epoch": 0.30065477104186406,
      "grad_norm": 1.9763240814208984,
      "learning_rate": 4.849708871479992e-05,
      "loss": 1.4682,
      "step": 28400
    },
    {
      "epoch": 0.30118409282186737,
      "grad_norm": 1.659584403038025,
      "learning_rate": 4.849444209189075e-05,
      "loss": 1.4733,
      "step": 28450
    },
    {
      "epoch": 0.3017134146018706,
      "grad_norm": 1.6784334182739258,
      "learning_rate": 4.8491795468981586e-05,
      "loss": 1.4642,
      "step": 28500
    },
    {
      "epoch": 0.3017134146018706,
      "eval_loss": 1.4422218799591064,
      "eval_runtime": 46.5928,
      "eval_samples_per_second": 3604.208,
      "eval_steps_per_second": 450.542,
      "step": 28500
    },
    {
      "epoch": 0.3022427363818739,
      "grad_norm": 1.699108600616455,
      "learning_rate": 4.848914884607241e-05,
      "loss": 1.4671,
      "step": 28550
    },
    {
      "epoch": 0.3027720581618772,
      "grad_norm": 1.83063542842865,
      "learning_rate": 4.848650222316325e-05,
      "loss": 1.4667,
      "step": 28600
    },
    {
      "epoch": 0.30330137994188044,
      "grad_norm": 1.668327808380127,
      "learning_rate": 4.848385560025408e-05,
      "loss": 1.4731,
      "step": 28650
    },
    {
      "epoch": 0.30383070172188376,
      "grad_norm": 1.8471819162368774,
      "learning_rate": 4.8481261909803096e-05,
      "loss": 1.4429,
      "step": 28700
    },
    {
      "epoch": 0.304360023501887,
      "grad_norm": 1.9070847034454346,
      "learning_rate": 4.847861528689392e-05,
      "loss": 1.4654,
      "step": 28750
    },
    {
      "epoch": 0.3048893452818903,
      "grad_norm": 1.7644118070602417,
      "learning_rate": 4.847596866398476e-05,
      "loss": 1.4676,
      "step": 28800
    },
    {
      "epoch": 0.3054186670618936,
      "grad_norm": 1.870728611946106,
      "learning_rate": 4.847332204107559e-05,
      "loss": 1.473,
      "step": 28850
    },
    {
      "epoch": 0.3059479888418969,
      "grad_norm": 1.7839895486831665,
      "learning_rate": 4.8470675418166425e-05,
      "loss": 1.4463,
      "step": 28900
    },
    {
      "epoch": 0.30647731062190015,
      "grad_norm": 2.017857313156128,
      "learning_rate": 4.846802879525725e-05,
      "loss": 1.4428,
      "step": 28950
    },
    {
      "epoch": 0.30700663240190346,
      "grad_norm": 1.8885520696640015,
      "learning_rate": 4.846538217234809e-05,
      "loss": 1.4747,
      "step": 29000
    },
    {
      "epoch": 0.30700663240190346,
      "eval_loss": 1.4357891082763672,
      "eval_runtime": 46.5734,
      "eval_samples_per_second": 3605.708,
      "eval_steps_per_second": 450.73,
      "step": 29000
    },
    {
      "epoch": 0.3075359541819067,
      "grad_norm": 1.8037962913513184,
      "learning_rate": 4.846273554943892e-05,
      "loss": 1.4622,
      "step": 29050
    },
    {
      "epoch": 0.30806527596191,
      "grad_norm": 1.9788098335266113,
      "learning_rate": 4.846008892652975e-05,
      "loss": 1.4483,
      "step": 29100
    },
    {
      "epoch": 0.3085945977419133,
      "grad_norm": 1.8947765827178955,
      "learning_rate": 4.845744230362058e-05,
      "loss": 1.472,
      "step": 29150
    },
    {
      "epoch": 0.3091239195219166,
      "grad_norm": 1.6178598403930664,
      "learning_rate": 4.845479568071141e-05,
      "loss": 1.4614,
      "step": 29200
    },
    {
      "epoch": 0.30965324130191985,
      "grad_norm": 1.7799885272979736,
      "learning_rate": 4.845214905780225e-05,
      "loss": 1.4587,
      "step": 29250
    },
    {
      "epoch": 0.31018256308192316,
      "grad_norm": 1.7796070575714111,
      "learning_rate": 4.844950243489308e-05,
      "loss": 1.4562,
      "step": 29300
    },
    {
      "epoch": 0.3107118848619264,
      "grad_norm": 1.846660852432251,
      "learning_rate": 4.844685581198391e-05,
      "loss": 1.472,
      "step": 29350
    },
    {
      "epoch": 0.31124120664192967,
      "grad_norm": 1.7596580982208252,
      "learning_rate": 4.844420918907474e-05,
      "loss": 1.467,
      "step": 29400
    },
    {
      "epoch": 0.311770528421933,
      "grad_norm": 1.8692898750305176,
      "learning_rate": 4.844156256616558e-05,
      "loss": 1.4699,
      "step": 29450
    },
    {
      "epoch": 0.31229985020193624,
      "grad_norm": 1.8270846605300903,
      "learning_rate": 4.843891594325641e-05,
      "loss": 1.4573,
      "step": 29500
    },
    {
      "epoch": 0.31229985020193624,
      "eval_loss": 1.4352824687957764,
      "eval_runtime": 46.599,
      "eval_samples_per_second": 3603.722,
      "eval_steps_per_second": 450.481,
      "step": 29500
    },
    {
      "epoch": 0.31282917198193955,
      "grad_norm": 1.8768293857574463,
      "learning_rate": 4.843626932034724e-05,
      "loss": 1.4762,
      "step": 29550
    },
    {
      "epoch": 0.3133584937619428,
      "grad_norm": 1.84703528881073,
      "learning_rate": 4.843362269743807e-05,
      "loss": 1.4541,
      "step": 29600
    },
    {
      "epoch": 0.3138878155419461,
      "grad_norm": 1.9899094104766846,
      "learning_rate": 4.84309760745289e-05,
      "loss": 1.4727,
      "step": 29650
    },
    {
      "epoch": 0.31441713732194937,
      "grad_norm": 1.823024034500122,
      "learning_rate": 4.842832945161974e-05,
      "loss": 1.4502,
      "step": 29700
    },
    {
      "epoch": 0.3149464591019527,
      "grad_norm": 1.8592740297317505,
      "learning_rate": 4.8425682828710564e-05,
      "loss": 1.4361,
      "step": 29750
    },
    {
      "epoch": 0.31547578088195594,
      "grad_norm": 1.7378509044647217,
      "learning_rate": 4.84230362058014e-05,
      "loss": 1.4512,
      "step": 29800
    },
    {
      "epoch": 0.31600510266195925,
      "grad_norm": 1.757703185081482,
      "learning_rate": 4.842038958289223e-05,
      "loss": 1.4513,
      "step": 29850
    },
    {
      "epoch": 0.3165344244419625,
      "grad_norm": 1.8143309354782104,
      "learning_rate": 4.841774295998307e-05,
      "loss": 1.4591,
      "step": 29900
    },
    {
      "epoch": 0.3170637462219658,
      "grad_norm": 1.805384635925293,
      "learning_rate": 4.8415096337073894e-05,
      "loss": 1.4388,
      "step": 29950
    },
    {
      "epoch": 0.31759306800196907,
      "grad_norm": 1.6723839044570923,
      "learning_rate": 4.841244971416473e-05,
      "loss": 1.4569,
      "step": 30000
    },
    {
      "epoch": 0.31759306800196907,
      "eval_loss": 1.4321472644805908,
      "eval_runtime": 46.6089,
      "eval_samples_per_second": 3602.963,
      "eval_steps_per_second": 450.386,
      "step": 30000
    },
    {
      "epoch": 0.3181223897819724,
      "grad_norm": 1.9503101110458374,
      "learning_rate": 4.840980309125556e-05,
      "loss": 1.4501,
      "step": 30050
    },
    {
      "epoch": 0.31865171156197564,
      "grad_norm": 1.7924816608428955,
      "learning_rate": 4.840715646834639e-05,
      "loss": 1.458,
      "step": 30100
    },
    {
      "epoch": 0.31918103334197895,
      "grad_norm": 1.5982871055603027,
      "learning_rate": 4.8404509845437224e-05,
      "loss": 1.4575,
      "step": 30150
    },
    {
      "epoch": 0.3197103551219822,
      "grad_norm": 1.8957874774932861,
      "learning_rate": 4.840186322252806e-05,
      "loss": 1.4752,
      "step": 30200
    },
    {
      "epoch": 0.32023967690198546,
      "grad_norm": 1.8273433446884155,
      "learning_rate": 4.839921659961889e-05,
      "loss": 1.4586,
      "step": 30250
    },
    {
      "epoch": 0.32076899868198877,
      "grad_norm": 1.8069440126419067,
      "learning_rate": 4.839656997670972e-05,
      "loss": 1.4385,
      "step": 30300
    },
    {
      "epoch": 0.321298320461992,
      "grad_norm": 1.7674704790115356,
      "learning_rate": 4.839392335380055e-05,
      "loss": 1.4478,
      "step": 30350
    },
    {
      "epoch": 0.32182764224199534,
      "grad_norm": 1.8570667505264282,
      "learning_rate": 4.839127673089138e-05,
      "loss": 1.4657,
      "step": 30400
    },
    {
      "epoch": 0.3223569640219986,
      "grad_norm": 1.9627753496170044,
      "learning_rate": 4.838863010798222e-05,
      "loss": 1.4663,
      "step": 30450
    },
    {
      "epoch": 0.3228862858020019,
      "grad_norm": 1.8949869871139526,
      "learning_rate": 4.838598348507305e-05,
      "loss": 1.4464,
      "step": 30500
    },
    {
      "epoch": 0.3228862858020019,
      "eval_loss": 1.433369755744934,
      "eval_runtime": 46.5219,
      "eval_samples_per_second": 3609.701,
      "eval_steps_per_second": 451.229,
      "step": 30500
    },
    {
      "epoch": 0.32341560758200516,
      "grad_norm": 1.7722772359848022,
      "learning_rate": 4.838333686216388e-05,
      "loss": 1.4397,
      "step": 30550
    },
    {
      "epoch": 0.32394492936200847,
      "grad_norm": 1.7878851890563965,
      "learning_rate": 4.838069023925471e-05,
      "loss": 1.4731,
      "step": 30600
    },
    {
      "epoch": 0.3244742511420117,
      "grad_norm": 1.7247880697250366,
      "learning_rate": 4.8378043616345544e-05,
      "loss": 1.4432,
      "step": 30650
    },
    {
      "epoch": 0.32500357292201504,
      "grad_norm": 1.8919943571090698,
      "learning_rate": 4.837539699343638e-05,
      "loss": 1.4487,
      "step": 30700
    },
    {
      "epoch": 0.3255328947020183,
      "grad_norm": 1.8186748027801514,
      "learning_rate": 4.8372750370527206e-05,
      "loss": 1.4432,
      "step": 30750
    },
    {
      "epoch": 0.3260622164820216,
      "grad_norm": 1.7914297580718994,
      "learning_rate": 4.837010374761804e-05,
      "loss": 1.4522,
      "step": 30800
    },
    {
      "epoch": 0.32659153826202486,
      "grad_norm": 1.8185011148452759,
      "learning_rate": 4.8367457124708874e-05,
      "loss": 1.464,
      "step": 30850
    },
    {
      "epoch": 0.32712086004202817,
      "grad_norm": 1.9130182266235352,
      "learning_rate": 4.836481050179971e-05,
      "loss": 1.4564,
      "step": 30900
    },
    {
      "epoch": 0.3276501818220314,
      "grad_norm": 1.8036348819732666,
      "learning_rate": 4.8362163878890535e-05,
      "loss": 1.4365,
      "step": 30950
    },
    {
      "epoch": 0.32817950360203474,
      "grad_norm": 1.6645699739456177,
      "learning_rate": 4.835951725598137e-05,
      "loss": 1.4519,
      "step": 31000
    },
    {
      "epoch": 0.32817950360203474,
      "eval_loss": 1.4311054944992065,
      "eval_runtime": 46.7272,
      "eval_samples_per_second": 3593.839,
      "eval_steps_per_second": 449.246,
      "step": 31000
    },
    {
      "epoch": 0.328708825382038,
      "grad_norm": 1.9048885107040405,
      "learning_rate": 4.8356870633072204e-05,
      "loss": 1.4396,
      "step": 31050
    },
    {
      "epoch": 0.32923814716204125,
      "grad_norm": 1.9759360551834106,
      "learning_rate": 4.835422401016304e-05,
      "loss": 1.4462,
      "step": 31100
    },
    {
      "epoch": 0.32976746894204456,
      "grad_norm": 1.6923794746398926,
      "learning_rate": 4.8351577387253865e-05,
      "loss": 1.4456,
      "step": 31150
    },
    {
      "epoch": 0.3302967907220478,
      "grad_norm": 1.7205919027328491,
      "learning_rate": 4.83489307643447e-05,
      "loss": 1.4747,
      "step": 31200
    },
    {
      "epoch": 0.33082611250205113,
      "grad_norm": 1.7886918783187866,
      "learning_rate": 4.834628414143553e-05,
      "loss": 1.4508,
      "step": 31250
    },
    {
      "epoch": 0.3313554342820544,
      "grad_norm": 1.7546772956848145,
      "learning_rate": 4.834363751852636e-05,
      "loss": 1.4438,
      "step": 31300
    },
    {
      "epoch": 0.3318847560620577,
      "grad_norm": 1.8100005388259888,
      "learning_rate": 4.8340990895617195e-05,
      "loss": 1.4745,
      "step": 31350
    },
    {
      "epoch": 0.33241407784206095,
      "grad_norm": 1.7207435369491577,
      "learning_rate": 4.833834427270802e-05,
      "loss": 1.4401,
      "step": 31400
    },
    {
      "epoch": 0.33294339962206426,
      "grad_norm": 1.8169056177139282,
      "learning_rate": 4.833569764979886e-05,
      "loss": 1.4509,
      "step": 31450
    },
    {
      "epoch": 0.3334727214020675,
      "grad_norm": 1.6094880104064941,
      "learning_rate": 4.833305102688969e-05,
      "loss": 1.4269,
      "step": 31500
    },
    {
      "epoch": 0.3334727214020675,
      "eval_loss": 1.4249546527862549,
      "eval_runtime": 46.9465,
      "eval_samples_per_second": 3577.05,
      "eval_steps_per_second": 447.147,
      "step": 31500
    },
    {
      "epoch": 0.33400204318207083,
      "grad_norm": 1.7601263523101807,
      "learning_rate": 4.8330404403980524e-05,
      "loss": 1.4505,
      "step": 31550
    },
    {
      "epoch": 0.3345313649620741,
      "grad_norm": 1.7374070882797241,
      "learning_rate": 4.832775778107135e-05,
      "loss": 1.4284,
      "step": 31600
    },
    {
      "epoch": 0.3350606867420774,
      "grad_norm": 1.8527932167053223,
      "learning_rate": 4.832511115816219e-05,
      "loss": 1.4579,
      "step": 31650
    },
    {
      "epoch": 0.33559000852208065,
      "grad_norm": 1.719624400138855,
      "learning_rate": 4.832246453525302e-05,
      "loss": 1.4607,
      "step": 31700
    },
    {
      "epoch": 0.33611933030208396,
      "grad_norm": 1.7403894662857056,
      "learning_rate": 4.8319817912343854e-05,
      "loss": 1.4325,
      "step": 31750
    },
    {
      "epoch": 0.3366486520820872,
      "grad_norm": 1.7535936832427979,
      "learning_rate": 4.831717128943468e-05,
      "loss": 1.4271,
      "step": 31800
    },
    {
      "epoch": 0.33717797386209053,
      "grad_norm": 1.5911972522735596,
      "learning_rate": 4.8314524666525515e-05,
      "loss": 1.4467,
      "step": 31850
    },
    {
      "epoch": 0.3377072956420938,
      "grad_norm": 1.8577929735183716,
      "learning_rate": 4.831187804361635e-05,
      "loss": 1.4325,
      "step": 31900
    },
    {
      "epoch": 0.33823661742209704,
      "grad_norm": 1.7941049337387085,
      "learning_rate": 4.830923142070718e-05,
      "loss": 1.47,
      "step": 31950
    },
    {
      "epoch": 0.33876593920210035,
      "grad_norm": 1.7196766138076782,
      "learning_rate": 4.830658479779801e-05,
      "loss": 1.4575,
      "step": 32000
    },
    {
      "epoch": 0.33876593920210035,
      "eval_loss": 1.4235703945159912,
      "eval_runtime": 46.6018,
      "eval_samples_per_second": 3603.51,
      "eval_steps_per_second": 450.455,
      "step": 32000
    },
    {
      "epoch": 0.3392952609821036,
      "grad_norm": 2.024237871170044,
      "learning_rate": 4.8303938174888845e-05,
      "loss": 1.4123,
      "step": 32050
    },
    {
      "epoch": 0.3398245827621069,
      "grad_norm": 1.8334321975708008,
      "learning_rate": 4.830129155197968e-05,
      "loss": 1.4346,
      "step": 32100
    },
    {
      "epoch": 0.3403539045421102,
      "grad_norm": 1.6822705268859863,
      "learning_rate": 4.8298644929070506e-05,
      "loss": 1.4592,
      "step": 32150
    },
    {
      "epoch": 0.3408832263221135,
      "grad_norm": 1.6694813966751099,
      "learning_rate": 4.829599830616134e-05,
      "loss": 1.4654,
      "step": 32200
    },
    {
      "epoch": 0.34141254810211674,
      "grad_norm": 1.5496737957000732,
      "learning_rate": 4.8293351683252175e-05,
      "loss": 1.4518,
      "step": 32250
    },
    {
      "epoch": 0.34194186988212005,
      "grad_norm": 1.974173665046692,
      "learning_rate": 4.829070506034301e-05,
      "loss": 1.4321,
      "step": 32300
    },
    {
      "epoch": 0.3424711916621233,
      "grad_norm": 1.650242567062378,
      "learning_rate": 4.8288058437433836e-05,
      "loss": 1.4672,
      "step": 32350
    },
    {
      "epoch": 0.3430005134421266,
      "grad_norm": 1.6968114376068115,
      "learning_rate": 4.828541181452467e-05,
      "loss": 1.4555,
      "step": 32400
    },
    {
      "epoch": 0.3435298352221299,
      "grad_norm": 1.8156355619430542,
      "learning_rate": 4.8282765191615504e-05,
      "loss": 1.4446,
      "step": 32450
    },
    {
      "epoch": 0.3440591570021332,
      "grad_norm": 1.7643241882324219,
      "learning_rate": 4.828011856870633e-05,
      "loss": 1.4238,
      "step": 32500
    },
    {
      "epoch": 0.3440591570021332,
      "eval_loss": 1.423793911933899,
      "eval_runtime": 46.6523,
      "eval_samples_per_second": 3599.605,
      "eval_steps_per_second": 449.967,
      "step": 32500
    },
    {
      "epoch": 0.34458847878213644,
      "grad_norm": 1.7614858150482178,
      "learning_rate": 4.8277524878255346e-05,
      "loss": 1.4396,
      "step": 32550
    },
    {
      "epoch": 0.34511780056213975,
      "grad_norm": 1.969670057296753,
      "learning_rate": 4.827487825534618e-05,
      "loss": 1.4477,
      "step": 32600
    },
    {
      "epoch": 0.345647122342143,
      "grad_norm": 1.806249976158142,
      "learning_rate": 4.8272231632437014e-05,
      "loss": 1.4485,
      "step": 32650
    },
    {
      "epoch": 0.3461764441221463,
      "grad_norm": 1.9052162170410156,
      "learning_rate": 4.826958500952785e-05,
      "loss": 1.4425,
      "step": 32700
    },
    {
      "epoch": 0.3467057659021496,
      "grad_norm": 1.779189109802246,
      "learning_rate": 4.8266938386618676e-05,
      "loss": 1.4234,
      "step": 32750
    },
    {
      "epoch": 0.34723508768215283,
      "grad_norm": 1.8305221796035767,
      "learning_rate": 4.826429176370951e-05,
      "loss": 1.454,
      "step": 32800
    },
    {
      "epoch": 0.34776440946215614,
      "grad_norm": 1.708508849143982,
      "learning_rate": 4.8261645140800344e-05,
      "loss": 1.445,
      "step": 32850
    },
    {
      "epoch": 0.3482937312421594,
      "grad_norm": 1.7489951848983765,
      "learning_rate": 4.825899851789117e-05,
      "loss": 1.428,
      "step": 32900
    },
    {
      "epoch": 0.3488230530221627,
      "grad_norm": 1.73701012134552,
      "learning_rate": 4.8256351894982005e-05,
      "loss": 1.4458,
      "step": 32950
    },
    {
      "epoch": 0.34935237480216597,
      "grad_norm": 1.8207948207855225,
      "learning_rate": 4.825370527207283e-05,
      "loss": 1.4503,
      "step": 33000
    },
    {
      "epoch": 0.34935237480216597,
      "eval_loss": 1.4178277254104614,
      "eval_runtime": 46.5669,
      "eval_samples_per_second": 3606.21,
      "eval_steps_per_second": 450.792,
      "step": 33000
    },
    {
      "epoch": 0.3498816965821693,
      "grad_norm": 1.9129811525344849,
      "learning_rate": 4.8251058649163674e-05,
      "loss": 1.4426,
      "step": 33050
    },
    {
      "epoch": 0.35041101836217253,
      "grad_norm": 1.9142045974731445,
      "learning_rate": 4.82484120262545e-05,
      "loss": 1.4323,
      "step": 33100
    },
    {
      "epoch": 0.35094034014217584,
      "grad_norm": 1.8137712478637695,
      "learning_rate": 4.8245765403345335e-05,
      "loss": 1.4326,
      "step": 33150
    },
    {
      "epoch": 0.3514696619221791,
      "grad_norm": 1.760102391242981,
      "learning_rate": 4.824311878043616e-05,
      "loss": 1.4468,
      "step": 33200
    },
    {
      "epoch": 0.3519989837021824,
      "grad_norm": 1.7150967121124268,
      "learning_rate": 4.8240472157527e-05,
      "loss": 1.4519,
      "step": 33250
    },
    {
      "epoch": 0.35252830548218567,
      "grad_norm": 1.774446964263916,
      "learning_rate": 4.823782553461783e-05,
      "loss": 1.4546,
      "step": 33300
    },
    {
      "epoch": 0.353057627262189,
      "grad_norm": 1.7414180040359497,
      "learning_rate": 4.8235178911708665e-05,
      "loss": 1.4322,
      "step": 33350
    },
    {
      "epoch": 0.35358694904219223,
      "grad_norm": 1.8641374111175537,
      "learning_rate": 4.823253228879949e-05,
      "loss": 1.4364,
      "step": 33400
    },
    {
      "epoch": 0.35411627082219554,
      "grad_norm": 1.846176266670227,
      "learning_rate": 4.8229885665890326e-05,
      "loss": 1.4614,
      "step": 33450
    },
    {
      "epoch": 0.3546455926021988,
      "grad_norm": 1.8167495727539062,
      "learning_rate": 4.822723904298116e-05,
      "loss": 1.4425,
      "step": 33500
    },
    {
      "epoch": 0.3546455926021988,
      "eval_loss": 1.4185550212860107,
      "eval_runtime": 46.4656,
      "eval_samples_per_second": 3614.07,
      "eval_steps_per_second": 451.775,
      "step": 33500
    },
    {
      "epoch": 0.3551749143822021,
      "grad_norm": 1.8114153146743774,
      "learning_rate": 4.822459242007199e-05,
      "loss": 1.447,
      "step": 33550
    },
    {
      "epoch": 0.35570423616220537,
      "grad_norm": 1.757973313331604,
      "learning_rate": 4.822194579716282e-05,
      "loss": 1.4541,
      "step": 33600
    },
    {
      "epoch": 0.3562335579422086,
      "grad_norm": 1.7027792930603027,
      "learning_rate": 4.8219299174253656e-05,
      "loss": 1.4199,
      "step": 33650
    },
    {
      "epoch": 0.35676287972221193,
      "grad_norm": 1.9547163248062134,
      "learning_rate": 4.821665255134449e-05,
      "loss": 1.449,
      "step": 33700
    },
    {
      "epoch": 0.3572922015022152,
      "grad_norm": 1.8448797464370728,
      "learning_rate": 4.821400592843532e-05,
      "loss": 1.4558,
      "step": 33750
    },
    {
      "epoch": 0.3578215232822185,
      "grad_norm": 1.8884965181350708,
      "learning_rate": 4.821135930552615e-05,
      "loss": 1.4206,
      "step": 33800
    },
    {
      "epoch": 0.35835084506222176,
      "grad_norm": 1.7320902347564697,
      "learning_rate": 4.8208712682616985e-05,
      "loss": 1.4448,
      "step": 33850
    },
    {
      "epoch": 0.35888016684222507,
      "grad_norm": 1.696230411529541,
      "learning_rate": 4.820606605970782e-05,
      "loss": 1.4201,
      "step": 33900
    },
    {
      "epoch": 0.3594094886222283,
      "grad_norm": 1.924454689025879,
      "learning_rate": 4.820341943679865e-05,
      "loss": 1.4385,
      "step": 33950
    },
    {
      "epoch": 0.35993881040223163,
      "grad_norm": 1.6596484184265137,
      "learning_rate": 4.820077281388948e-05,
      "loss": 1.4139,
      "step": 34000
    },
    {
      "epoch": 0.35993881040223163,
      "eval_loss": 1.4155447483062744,
      "eval_runtime": 46.7314,
      "eval_samples_per_second": 3593.514,
      "eval_steps_per_second": 449.205,
      "step": 34000
    },
    {
      "epoch": 0.3604681321822349,
      "grad_norm": 1.6625102758407593,
      "learning_rate": 4.8198126190980315e-05,
      "loss": 1.4441,
      "step": 34050
    },
    {
      "epoch": 0.3609974539622382,
      "grad_norm": 1.7862039804458618,
      "learning_rate": 4.819547956807114e-05,
      "loss": 1.4217,
      "step": 34100
    },
    {
      "epoch": 0.36152677574224146,
      "grad_norm": 1.8199362754821777,
      "learning_rate": 4.8192832945161976e-05,
      "loss": 1.4409,
      "step": 34150
    },
    {
      "epoch": 0.36205609752224477,
      "grad_norm": 1.8422635793685913,
      "learning_rate": 4.8190186322252804e-05,
      "loss": 1.4475,
      "step": 34200
    },
    {
      "epoch": 0.362585419302248,
      "grad_norm": 1.7951571941375732,
      "learning_rate": 4.8187539699343645e-05,
      "loss": 1.4229,
      "step": 34250
    },
    {
      "epoch": 0.36311474108225134,
      "grad_norm": 1.5833717584609985,
      "learning_rate": 4.818489307643447e-05,
      "loss": 1.432,
      "step": 34300
    },
    {
      "epoch": 0.3636440628622546,
      "grad_norm": 1.5619983673095703,
      "learning_rate": 4.8182246453525306e-05,
      "loss": 1.4285,
      "step": 34350
    },
    {
      "epoch": 0.3641733846422579,
      "grad_norm": 1.7401140928268433,
      "learning_rate": 4.817959983061613e-05,
      "loss": 1.4185,
      "step": 34400
    },
    {
      "epoch": 0.36470270642226116,
      "grad_norm": 1.881047010421753,
      "learning_rate": 4.817695320770697e-05,
      "loss": 1.4498,
      "step": 34450
    },
    {
      "epoch": 0.3652320282022644,
      "grad_norm": 1.5592988729476929,
      "learning_rate": 4.81743065847978e-05,
      "loss": 1.4439,
      "step": 34500
    },
    {
      "epoch": 0.3652320282022644,
      "eval_loss": 1.4127821922302246,
      "eval_runtime": 46.5998,
      "eval_samples_per_second": 3603.666,
      "eval_steps_per_second": 450.474,
      "step": 34500
    },
    {
      "epoch": 0.3657613499822677,
      "grad_norm": 1.9182225465774536,
      "learning_rate": 4.817165996188863e-05,
      "loss": 1.4484,
      "step": 34550
    },
    {
      "epoch": 0.366290671762271,
      "grad_norm": 1.697115182876587,
      "learning_rate": 4.816901333897946e-05,
      "loss": 1.4251,
      "step": 34600
    },
    {
      "epoch": 0.3668199935422743,
      "grad_norm": 1.6456303596496582,
      "learning_rate": 4.81663667160703e-05,
      "loss": 1.4568,
      "step": 34650
    },
    {
      "epoch": 0.36734931532227755,
      "grad_norm": 1.8828678131103516,
      "learning_rate": 4.816372009316113e-05,
      "loss": 1.4237,
      "step": 34700
    },
    {
      "epoch": 0.36787863710228086,
      "grad_norm": 1.688152551651001,
      "learning_rate": 4.816107347025196e-05,
      "loss": 1.4495,
      "step": 34750
    },
    {
      "epoch": 0.3684079588822841,
      "grad_norm": 1.795410394668579,
      "learning_rate": 4.815842684734279e-05,
      "loss": 1.4489,
      "step": 34800
    },
    {
      "epoch": 0.3689372806622874,
      "grad_norm": 1.689538836479187,
      "learning_rate": 4.815578022443363e-05,
      "loss": 1.4248,
      "step": 34850
    },
    {
      "epoch": 0.3694666024422907,
      "grad_norm": 1.8615800142288208,
      "learning_rate": 4.815313360152446e-05,
      "loss": 1.4203,
      "step": 34900
    },
    {
      "epoch": 0.369995924222294,
      "grad_norm": 1.7455137968063354,
      "learning_rate": 4.815048697861529e-05,
      "loss": 1.4276,
      "step": 34950
    },
    {
      "epoch": 0.37052524600229725,
      "grad_norm": 1.7754350900650024,
      "learning_rate": 4.814784035570612e-05,
      "loss": 1.4495,
      "step": 35000
    },
    {
      "epoch": 0.37052524600229725,
      "eval_loss": 1.4095568656921387,
      "eval_runtime": 46.5212,
      "eval_samples_per_second": 3609.753,
      "eval_steps_per_second": 451.235,
      "step": 35000
    },
    {
      "epoch": 0.37105456778230056,
      "grad_norm": 1.775141716003418,
      "learning_rate": 4.8145193732796956e-05,
      "loss": 1.4423,
      "step": 35050
    },
    {
      "epoch": 0.3715838895623038,
      "grad_norm": 1.7861396074295044,
      "learning_rate": 4.8142547109887784e-05,
      "loss": 1.4365,
      "step": 35100
    },
    {
      "epoch": 0.3721132113423071,
      "grad_norm": 1.7955175638198853,
      "learning_rate": 4.813990048697862e-05,
      "loss": 1.451,
      "step": 35150
    },
    {
      "epoch": 0.3726425331223104,
      "grad_norm": 1.8429545164108276,
      "learning_rate": 4.8137253864069445e-05,
      "loss": 1.4383,
      "step": 35200
    },
    {
      "epoch": 0.37317185490231364,
      "grad_norm": 1.8084254264831543,
      "learning_rate": 4.8134607241160286e-05,
      "loss": 1.4273,
      "step": 35250
    },
    {
      "epoch": 0.37370117668231695,
      "grad_norm": 1.9029595851898193,
      "learning_rate": 4.813196061825111e-05,
      "loss": 1.4481,
      "step": 35300
    },
    {
      "epoch": 0.3742304984623202,
      "grad_norm": 1.6737442016601562,
      "learning_rate": 4.812931399534195e-05,
      "loss": 1.4171,
      "step": 35350
    },
    {
      "epoch": 0.3747598202423235,
      "grad_norm": 1.9137394428253174,
      "learning_rate": 4.8126667372432775e-05,
      "loss": 1.43,
      "step": 35400
    },
    {
      "epoch": 0.37528914202232677,
      "grad_norm": 1.859070897102356,
      "learning_rate": 4.8124020749523616e-05,
      "loss": 1.434,
      "step": 35450
    },
    {
      "epoch": 0.3758184638023301,
      "grad_norm": 1.816637396812439,
      "learning_rate": 4.812137412661444e-05,
      "loss": 1.4026,
      "step": 35500
    },
    {
      "epoch": 0.3758184638023301,
      "eval_loss": 1.4094029664993286,
      "eval_runtime": 46.6561,
      "eval_samples_per_second": 3599.312,
      "eval_steps_per_second": 449.93,
      "step": 35500
    },
    {
      "epoch": 0.37634778558233334,
      "grad_norm": 1.6898877620697021,
      "learning_rate": 4.811872750370528e-05,
      "loss": 1.4477,
      "step": 35550
    },
    {
      "epoch": 0.37687710736233665,
      "grad_norm": 1.6927531957626343,
      "learning_rate": 4.8116080880796104e-05,
      "loss": 1.434,
      "step": 35600
    },
    {
      "epoch": 0.3774064291423399,
      "grad_norm": 1.6401313543319702,
      "learning_rate": 4.811343425788694e-05,
      "loss": 1.4047,
      "step": 35650
    },
    {
      "epoch": 0.3779357509223432,
      "grad_norm": 1.6173712015151978,
      "learning_rate": 4.811078763497777e-05,
      "loss": 1.4059,
      "step": 35700
    },
    {
      "epoch": 0.37846507270234647,
      "grad_norm": 1.7748737335205078,
      "learning_rate": 4.81081410120686e-05,
      "loss": 1.4384,
      "step": 35750
    },
    {
      "epoch": 0.3789943944823498,
      "grad_norm": 1.7447551488876343,
      "learning_rate": 4.8105494389159434e-05,
      "loss": 1.4159,
      "step": 35800
    },
    {
      "epoch": 0.37952371626235304,
      "grad_norm": 1.9098998308181763,
      "learning_rate": 4.810284776625027e-05,
      "loss": 1.4288,
      "step": 35850
    },
    {
      "epoch": 0.38005303804235635,
      "grad_norm": 1.7782464027404785,
      "learning_rate": 4.81002011433411e-05,
      "loss": 1.4282,
      "step": 35900
    },
    {
      "epoch": 0.3805823598223596,
      "grad_norm": 1.9227374792099,
      "learning_rate": 4.809755452043193e-05,
      "loss": 1.4238,
      "step": 35950
    },
    {
      "epoch": 0.3811116816023629,
      "grad_norm": 1.7099133729934692,
      "learning_rate": 4.8094907897522764e-05,
      "loss": 1.4589,
      "step": 36000
    },
    {
      "epoch": 0.3811116816023629,
      "eval_loss": 1.4055293798446655,
      "eval_runtime": 46.5283,
      "eval_samples_per_second": 3609.202,
      "eval_steps_per_second": 451.166,
      "step": 36000
    },
    {
      "epoch": 0.3816410033823662,
      "grad_norm": 1.8036479949951172,
      "learning_rate": 4.80922612746136e-05,
      "loss": 1.4161,
      "step": 36050
    },
    {
      "epoch": 0.38217032516236943,
      "grad_norm": 1.585619330406189,
      "learning_rate": 4.808961465170443e-05,
      "loss": 1.4355,
      "step": 36100
    },
    {
      "epoch": 0.38269964694237274,
      "grad_norm": 1.721753716468811,
      "learning_rate": 4.808696802879526e-05,
      "loss": 1.4457,
      "step": 36150
    },
    {
      "epoch": 0.383228968722376,
      "grad_norm": 1.9366130828857422,
      "learning_rate": 4.808432140588609e-05,
      "loss": 1.4112,
      "step": 36200
    },
    {
      "epoch": 0.3837582905023793,
      "grad_norm": 1.5427459478378296,
      "learning_rate": 4.808167478297693e-05,
      "loss": 1.4337,
      "step": 36250
    },
    {
      "epoch": 0.38428761228238256,
      "grad_norm": 1.7035514116287231,
      "learning_rate": 4.8079028160067755e-05,
      "loss": 1.4506,
      "step": 36300
    },
    {
      "epoch": 0.3848169340623859,
      "grad_norm": 2.025712251663208,
      "learning_rate": 4.807638153715859e-05,
      "loss": 1.4352,
      "step": 36350
    },
    {
      "epoch": 0.38534625584238913,
      "grad_norm": 1.8093490600585938,
      "learning_rate": 4.8073734914249416e-05,
      "loss": 1.4336,
      "step": 36400
    },
    {
      "epoch": 0.38587557762239244,
      "grad_norm": 1.7950727939605713,
      "learning_rate": 4.807108829134025e-05,
      "loss": 1.4335,
      "step": 36450
    },
    {
      "epoch": 0.3864048994023957,
      "grad_norm": 1.7446635961532593,
      "learning_rate": 4.8068441668431084e-05,
      "loss": 1.4313,
      "step": 36500
    },
    {
      "epoch": 0.3864048994023957,
      "eval_loss": 1.4037373065948486,
      "eval_runtime": 46.4714,
      "eval_samples_per_second": 3613.619,
      "eval_steps_per_second": 451.719,
      "step": 36500
    },
    {
      "epoch": 0.386934221182399,
      "grad_norm": 1.8879603147506714,
      "learning_rate": 4.80658479779801e-05,
      "loss": 1.414,
      "step": 36550
    },
    {
      "epoch": 0.38746354296240226,
      "grad_norm": 2.003906726837158,
      "learning_rate": 4.806320135507093e-05,
      "loss": 1.4345,
      "step": 36600
    },
    {
      "epoch": 0.3879928647424056,
      "grad_norm": 1.8172276020050049,
      "learning_rate": 4.806055473216177e-05,
      "loss": 1.4195,
      "step": 36650
    },
    {
      "epoch": 0.38852218652240883,
      "grad_norm": 1.9593712091445923,
      "learning_rate": 4.8057908109252594e-05,
      "loss": 1.417,
      "step": 36700
    },
    {
      "epoch": 0.38905150830241214,
      "grad_norm": 1.7838739156723022,
      "learning_rate": 4.805526148634343e-05,
      "loss": 1.4268,
      "step": 36750
    },
    {
      "epoch": 0.3895808300824154,
      "grad_norm": 1.6502370834350586,
      "learning_rate": 4.8052614863434256e-05,
      "loss": 1.4118,
      "step": 36800
    },
    {
      "epoch": 0.3901101518624187,
      "grad_norm": 1.7746320962905884,
      "learning_rate": 4.80499682405251e-05,
      "loss": 1.4263,
      "step": 36850
    },
    {
      "epoch": 0.39063947364242196,
      "grad_norm": 1.8435386419296265,
      "learning_rate": 4.8047321617615924e-05,
      "loss": 1.4469,
      "step": 36900
    },
    {
      "epoch": 0.3911687954224252,
      "grad_norm": 1.7327752113342285,
      "learning_rate": 4.804467499470676e-05,
      "loss": 1.425,
      "step": 36950
    },
    {
      "epoch": 0.39169811720242853,
      "grad_norm": 1.8678779602050781,
      "learning_rate": 4.8042028371797586e-05,
      "loss": 1.4138,
      "step": 37000
    },
    {
      "epoch": 0.39169811720242853,
      "eval_loss": 1.4040911197662354,
      "eval_runtime": 46.603,
      "eval_samples_per_second": 3603.415,
      "eval_steps_per_second": 450.443,
      "step": 37000
    },
    {
      "epoch": 0.3922274389824318,
      "grad_norm": 1.7309931516647339,
      "learning_rate": 4.803938174888842e-05,
      "loss": 1.4217,
      "step": 37050
    },
    {
      "epoch": 0.3927567607624351,
      "grad_norm": 1.7060917615890503,
      "learning_rate": 4.8036735125979254e-05,
      "loss": 1.414,
      "step": 37100
    },
    {
      "epoch": 0.39328608254243835,
      "grad_norm": 1.7572520971298218,
      "learning_rate": 4.803408850307009e-05,
      "loss": 1.4259,
      "step": 37150
    },
    {
      "epoch": 0.39381540432244166,
      "grad_norm": 1.7524499893188477,
      "learning_rate": 4.8031441880160915e-05,
      "loss": 1.4292,
      "step": 37200
    },
    {
      "epoch": 0.3943447261024449,
      "grad_norm": 2.011061668395996,
      "learning_rate": 4.802879525725175e-05,
      "loss": 1.416,
      "step": 37250
    },
    {
      "epoch": 0.39487404788244823,
      "grad_norm": 1.875850796699524,
      "learning_rate": 4.802614863434258e-05,
      "loss": 1.4223,
      "step": 37300
    },
    {
      "epoch": 0.3954033696624515,
      "grad_norm": 1.7817168235778809,
      "learning_rate": 4.802350201143341e-05,
      "loss": 1.4321,
      "step": 37350
    },
    {
      "epoch": 0.3959326914424548,
      "grad_norm": 1.7056471109390259,
      "learning_rate": 4.8020855388524245e-05,
      "loss": 1.4135,
      "step": 37400
    },
    {
      "epoch": 0.39646201322245805,
      "grad_norm": 1.8991553783416748,
      "learning_rate": 4.801820876561507e-05,
      "loss": 1.429,
      "step": 37450
    },
    {
      "epoch": 0.39699133500246137,
      "grad_norm": 1.7439545392990112,
      "learning_rate": 4.801556214270591e-05,
      "loss": 1.4125,
      "step": 37500
    },
    {
      "epoch": 0.39699133500246137,
      "eval_loss": 1.4039809703826904,
      "eval_runtime": 46.6168,
      "eval_samples_per_second": 3602.351,
      "eval_steps_per_second": 450.31,
      "step": 37500
    },
    {
      "epoch": 0.3975206567824646,
      "grad_norm": 1.6876319646835327,
      "learning_rate": 4.801291551979674e-05,
      "loss": 1.4306,
      "step": 37550
    },
    {
      "epoch": 0.39804997856246793,
      "grad_norm": 1.7870575189590454,
      "learning_rate": 4.8010268896887574e-05,
      "loss": 1.3922,
      "step": 37600
    },
    {
      "epoch": 0.3985793003424712,
      "grad_norm": 2.0274949073791504,
      "learning_rate": 4.80076222739784e-05,
      "loss": 1.4314,
      "step": 37650
    },
    {
      "epoch": 0.3991086221224745,
      "grad_norm": 1.701462984085083,
      "learning_rate": 4.800497565106924e-05,
      "loss": 1.4045,
      "step": 37700
    },
    {
      "epoch": 0.39963794390247775,
      "grad_norm": 1.8682013750076294,
      "learning_rate": 4.800232902816007e-05,
      "loss": 1.4346,
      "step": 37750
    },
    {
      "epoch": 0.400167265682481,
      "grad_norm": 1.7509487867355347,
      "learning_rate": 4.7999682405250904e-05,
      "loss": 1.4316,
      "step": 37800
    },
    {
      "epoch": 0.4006965874624843,
      "grad_norm": 1.7766213417053223,
      "learning_rate": 4.799703578234173e-05,
      "loss": 1.4005,
      "step": 37850
    },
    {
      "epoch": 0.4012259092424876,
      "grad_norm": 1.8034603595733643,
      "learning_rate": 4.7994389159432565e-05,
      "loss": 1.4231,
      "step": 37900
    },
    {
      "epoch": 0.4017552310224909,
      "grad_norm": 1.9105875492095947,
      "learning_rate": 4.79917425365234e-05,
      "loss": 1.416,
      "step": 37950
    },
    {
      "epoch": 0.40228455280249414,
      "grad_norm": 1.822779655456543,
      "learning_rate": 4.798909591361423e-05,
      "loss": 1.418,
      "step": 38000
    },
    {
      "epoch": 0.40228455280249414,
      "eval_loss": 1.3971604108810425,
      "eval_runtime": 46.6808,
      "eval_samples_per_second": 3597.408,
      "eval_steps_per_second": 449.692,
      "step": 38000
    },
    {
      "epoch": 0.40281387458249746,
      "grad_norm": 1.7862226963043213,
      "learning_rate": 4.798644929070506e-05,
      "loss": 1.4115,
      "step": 38050
    },
    {
      "epoch": 0.4033431963625007,
      "grad_norm": 1.919566035270691,
      "learning_rate": 4.7983802667795895e-05,
      "loss": 1.4494,
      "step": 38100
    },
    {
      "epoch": 0.403872518142504,
      "grad_norm": 1.788914442062378,
      "learning_rate": 4.798115604488673e-05,
      "loss": 1.4076,
      "step": 38150
    },
    {
      "epoch": 0.4044018399225073,
      "grad_norm": 1.8458421230316162,
      "learning_rate": 4.7978509421977556e-05,
      "loss": 1.4053,
      "step": 38200
    },
    {
      "epoch": 0.4049311617025106,
      "grad_norm": 1.7354317903518677,
      "learning_rate": 4.797586279906839e-05,
      "loss": 1.4066,
      "step": 38250
    },
    {
      "epoch": 0.40546048348251384,
      "grad_norm": 1.7664788961410522,
      "learning_rate": 4.7973216176159225e-05,
      "loss": 1.4105,
      "step": 38300
    },
    {
      "epoch": 0.40598980526251716,
      "grad_norm": 1.7977346181869507,
      "learning_rate": 4.797056955325006e-05,
      "loss": 1.4256,
      "step": 38350
    },
    {
      "epoch": 0.4065191270425204,
      "grad_norm": 1.8686459064483643,
      "learning_rate": 4.7967922930340886e-05,
      "loss": 1.4159,
      "step": 38400
    },
    {
      "epoch": 0.4070484488225237,
      "grad_norm": 1.7197085618972778,
      "learning_rate": 4.796527630743172e-05,
      "loss": 1.4091,
      "step": 38450
    },
    {
      "epoch": 0.407577770602527,
      "grad_norm": 1.7303166389465332,
      "learning_rate": 4.7962629684522554e-05,
      "loss": 1.4028,
      "step": 38500
    },
    {
      "epoch": 0.407577770602527,
      "eval_loss": 1.3969483375549316,
      "eval_runtime": 46.6705,
      "eval_samples_per_second": 3598.203,
      "eval_steps_per_second": 449.791,
      "step": 38500
    },
    {
      "epoch": 0.4081070923825303,
      "grad_norm": 1.7262890338897705,
      "learning_rate": 4.796003599407157e-05,
      "loss": 1.4166,
      "step": 38550
    },
    {
      "epoch": 0.40863641416253355,
      "grad_norm": 1.6732971668243408,
      "learning_rate": 4.7957389371162396e-05,
      "loss": 1.4123,
      "step": 38600
    },
    {
      "epoch": 0.4091657359425368,
      "grad_norm": 1.7447528839111328,
      "learning_rate": 4.795474274825323e-05,
      "loss": 1.4273,
      "step": 38650
    },
    {
      "epoch": 0.4096950577225401,
      "grad_norm": 1.8420051336288452,
      "learning_rate": 4.7952096125344065e-05,
      "loss": 1.4355,
      "step": 38700
    },
    {
      "epoch": 0.41022437950254337,
      "grad_norm": 1.7104723453521729,
      "learning_rate": 4.79494495024349e-05,
      "loss": 1.4005,
      "step": 38750
    },
    {
      "epoch": 0.4107537012825467,
      "grad_norm": 1.738542079925537,
      "learning_rate": 4.7946802879525726e-05,
      "loss": 1.4213,
      "step": 38800
    },
    {
      "epoch": 0.41128302306254994,
      "grad_norm": 1.7906419038772583,
      "learning_rate": 4.794415625661656e-05,
      "loss": 1.4356,
      "step": 38850
    },
    {
      "epoch": 0.41181234484255325,
      "grad_norm": 1.9602993726730347,
      "learning_rate": 4.7941509633707394e-05,
      "loss": 1.4212,
      "step": 38900
    },
    {
      "epoch": 0.4123416666225565,
      "grad_norm": 1.8677432537078857,
      "learning_rate": 4.793886301079822e-05,
      "loss": 1.4421,
      "step": 38950
    },
    {
      "epoch": 0.4128709884025598,
      "grad_norm": 1.6458219289779663,
      "learning_rate": 4.7936216387889056e-05,
      "loss": 1.4199,
      "step": 39000
    },
    {
      "epoch": 0.4128709884025598,
      "eval_loss": 1.3927313089370728,
      "eval_runtime": 46.4949,
      "eval_samples_per_second": 3611.797,
      "eval_steps_per_second": 451.491,
      "step": 39000
    },
    {
      "epoch": 0.41340031018256307,
      "grad_norm": 1.7623379230499268,
      "learning_rate": 4.793356976497988e-05,
      "loss": 1.4007,
      "step": 39050
    },
    {
      "epoch": 0.4139296319625664,
      "grad_norm": 1.7842692136764526,
      "learning_rate": 4.7930923142070724e-05,
      "loss": 1.4279,
      "step": 39100
    },
    {
      "epoch": 0.41445895374256964,
      "grad_norm": 1.7555198669433594,
      "learning_rate": 4.792827651916155e-05,
      "loss": 1.428,
      "step": 39150
    },
    {
      "epoch": 0.41498827552257295,
      "grad_norm": 1.9137916564941406,
      "learning_rate": 4.7925629896252385e-05,
      "loss": 1.4161,
      "step": 39200
    },
    {
      "epoch": 0.4155175973025762,
      "grad_norm": 1.957228422164917,
      "learning_rate": 4.792298327334321e-05,
      "loss": 1.4025,
      "step": 39250
    },
    {
      "epoch": 0.4160469190825795,
      "grad_norm": 1.742627501487732,
      "learning_rate": 4.7920336650434053e-05,
      "loss": 1.4209,
      "step": 39300
    },
    {
      "epoch": 0.41657624086258277,
      "grad_norm": 1.8717970848083496,
      "learning_rate": 4.791769002752488e-05,
      "loss": 1.4306,
      "step": 39350
    },
    {
      "epoch": 0.4171055626425861,
      "grad_norm": 1.9032868146896362,
      "learning_rate": 4.7915096337073895e-05,
      "loss": 1.4089,
      "step": 39400
    },
    {
      "epoch": 0.41763488442258934,
      "grad_norm": 1.6380112171173096,
      "learning_rate": 4.791244971416472e-05,
      "loss": 1.4035,
      "step": 39450
    },
    {
      "epoch": 0.4181642062025926,
      "grad_norm": 1.728912115097046,
      "learning_rate": 4.7909803091255564e-05,
      "loss": 1.4033,
      "step": 39500
    },
    {
      "epoch": 0.4181642062025926,
      "eval_loss": 1.3917627334594727,
      "eval_runtime": 46.6933,
      "eval_samples_per_second": 3596.449,
      "eval_steps_per_second": 449.572,
      "step": 39500
    },
    {
      "epoch": 0.4186935279825959,
      "grad_norm": 1.7175343036651611,
      "learning_rate": 4.790715646834639e-05,
      "loss": 1.4296,
      "step": 39550
    },
    {
      "epoch": 0.41922284976259916,
      "grad_norm": 1.7979620695114136,
      "learning_rate": 4.7904509845437225e-05,
      "loss": 1.401,
      "step": 39600
    },
    {
      "epoch": 0.41975217154260247,
      "grad_norm": 1.7307506799697876,
      "learning_rate": 4.790186322252805e-05,
      "loss": 1.4043,
      "step": 39650
    },
    {
      "epoch": 0.4202814933226057,
      "grad_norm": 1.7566308975219727,
      "learning_rate": 4.789921659961889e-05,
      "loss": 1.4251,
      "step": 39700
    },
    {
      "epoch": 0.42081081510260904,
      "grad_norm": 1.886019229888916,
      "learning_rate": 4.789656997670972e-05,
      "loss": 1.4347,
      "step": 39750
    },
    {
      "epoch": 0.4213401368826123,
      "grad_norm": 1.9810715913772583,
      "learning_rate": 4.7893923353800555e-05,
      "loss": 1.4174,
      "step": 39800
    },
    {
      "epoch": 0.4218694586626156,
      "grad_norm": 1.780768871307373,
      "learning_rate": 4.789127673089138e-05,
      "loss": 1.4111,
      "step": 39850
    },
    {
      "epoch": 0.42239878044261886,
      "grad_norm": 1.6305090188980103,
      "learning_rate": 4.7888630107982216e-05,
      "loss": 1.4046,
      "step": 39900
    },
    {
      "epoch": 0.42292810222262217,
      "grad_norm": 1.861567735671997,
      "learning_rate": 4.788598348507305e-05,
      "loss": 1.4337,
      "step": 39950
    },
    {
      "epoch": 0.4234574240026254,
      "grad_norm": 1.8363362550735474,
      "learning_rate": 4.788333686216388e-05,
      "loss": 1.4041,
      "step": 40000
    },
    {
      "epoch": 0.4234574240026254,
      "eval_loss": 1.394001841545105,
      "eval_runtime": 46.4903,
      "eval_samples_per_second": 3612.153,
      "eval_steps_per_second": 451.535,
      "step": 40000
    },
    {
      "epoch": 0.42398674578262874,
      "grad_norm": 1.6194790601730347,
      "learning_rate": 4.788069023925471e-05,
      "loss": 1.3941,
      "step": 40050
    },
    {
      "epoch": 0.424516067562632,
      "grad_norm": 1.8853765726089478,
      "learning_rate": 4.7878043616345546e-05,
      "loss": 1.4342,
      "step": 40100
    },
    {
      "epoch": 0.4250453893426353,
      "grad_norm": 1.7199079990386963,
      "learning_rate": 4.787539699343638e-05,
      "loss": 1.4413,
      "step": 40150
    },
    {
      "epoch": 0.42557471112263856,
      "grad_norm": 1.7378121614456177,
      "learning_rate": 4.787275037052721e-05,
      "loss": 1.4279,
      "step": 40200
    },
    {
      "epoch": 0.42610403290264187,
      "grad_norm": 1.8578016757965088,
      "learning_rate": 4.787010374761804e-05,
      "loss": 1.4123,
      "step": 40250
    },
    {
      "epoch": 0.4266333546826451,
      "grad_norm": 1.819143533706665,
      "learning_rate": 4.7867457124708875e-05,
      "loss": 1.3976,
      "step": 40300
    },
    {
      "epoch": 0.4271626764626484,
      "grad_norm": 1.7054402828216553,
      "learning_rate": 4.786481050179971e-05,
      "loss": 1.3897,
      "step": 40350
    },
    {
      "epoch": 0.4276919982426517,
      "grad_norm": 1.7083266973495483,
      "learning_rate": 4.786216387889054e-05,
      "loss": 1.3974,
      "step": 40400
    },
    {
      "epoch": 0.42822132002265495,
      "grad_norm": 1.8031963109970093,
      "learning_rate": 4.785951725598137e-05,
      "loss": 1.399,
      "step": 40450
    },
    {
      "epoch": 0.42875064180265826,
      "grad_norm": 1.6600987911224365,
      "learning_rate": 4.7856870633072205e-05,
      "loss": 1.3978,
      "step": 40500
    },
    {
      "epoch": 0.42875064180265826,
      "eval_loss": 1.3864753246307373,
      "eval_runtime": 46.568,
      "eval_samples_per_second": 3606.122,
      "eval_steps_per_second": 450.781,
      "step": 40500
    },
    {
      "epoch": 0.4292799635826615,
      "grad_norm": 1.7243707180023193,
      "learning_rate": 4.785422401016303e-05,
      "loss": 1.3893,
      "step": 40550
    },
    {
      "epoch": 0.42980928536266483,
      "grad_norm": 1.6222379207611084,
      "learning_rate": 4.7851577387253866e-05,
      "loss": 1.421,
      "step": 40600
    },
    {
      "epoch": 0.4303386071426681,
      "grad_norm": 1.8332234621047974,
      "learning_rate": 4.7848930764344694e-05,
      "loss": 1.4155,
      "step": 40650
    },
    {
      "epoch": 0.4308679289226714,
      "grad_norm": 1.7431634664535522,
      "learning_rate": 4.7846284141435535e-05,
      "loss": 1.4084,
      "step": 40700
    },
    {
      "epoch": 0.43139725070267465,
      "grad_norm": 1.9296619892120361,
      "learning_rate": 4.784363751852636e-05,
      "loss": 1.4069,
      "step": 40750
    },
    {
      "epoch": 0.43192657248267796,
      "grad_norm": 1.8399567604064941,
      "learning_rate": 4.7840990895617196e-05,
      "loss": 1.4159,
      "step": 40800
    },
    {
      "epoch": 0.4324558942626812,
      "grad_norm": 1.8623073101043701,
      "learning_rate": 4.783834427270802e-05,
      "loss": 1.4286,
      "step": 40850
    },
    {
      "epoch": 0.43298521604268453,
      "grad_norm": 1.9048748016357422,
      "learning_rate": 4.783569764979886e-05,
      "loss": 1.3987,
      "step": 40900
    },
    {
      "epoch": 0.4335145378226878,
      "grad_norm": 1.7100712060928345,
      "learning_rate": 4.783305102688969e-05,
      "loss": 1.3993,
      "step": 40950
    },
    {
      "epoch": 0.4340438596026911,
      "grad_norm": 1.793788194656372,
      "learning_rate": 4.783040440398052e-05,
      "loss": 1.4173,
      "step": 41000
    },
    {
      "epoch": 0.4340438596026911,
      "eval_loss": 1.383220911026001,
      "eval_runtime": 46.7669,
      "eval_samples_per_second": 3590.784,
      "eval_steps_per_second": 448.864,
      "step": 41000
    },
    {
      "epoch": 0.43457318138269435,
      "grad_norm": 1.9137930870056152,
      "learning_rate": 4.782775778107135e-05,
      "loss": 1.3827,
      "step": 41050
    },
    {
      "epoch": 0.43510250316269766,
      "grad_norm": 1.883609414100647,
      "learning_rate": 4.782511115816219e-05,
      "loss": 1.4034,
      "step": 41100
    },
    {
      "epoch": 0.4356318249427009,
      "grad_norm": 1.7517807483673096,
      "learning_rate": 4.782246453525302e-05,
      "loss": 1.4153,
      "step": 41150
    },
    {
      "epoch": 0.4361611467227042,
      "grad_norm": 1.991010308265686,
      "learning_rate": 4.781981791234385e-05,
      "loss": 1.4111,
      "step": 41200
    },
    {
      "epoch": 0.4366904685027075,
      "grad_norm": 1.8675413131713867,
      "learning_rate": 4.781717128943468e-05,
      "loss": 1.3993,
      "step": 41250
    },
    {
      "epoch": 0.43721979028271074,
      "grad_norm": 1.8771647214889526,
      "learning_rate": 4.781452466652552e-05,
      "loss": 1.4239,
      "step": 41300
    },
    {
      "epoch": 0.43774911206271405,
      "grad_norm": 1.6981940269470215,
      "learning_rate": 4.781187804361635e-05,
      "loss": 1.4145,
      "step": 41350
    },
    {
      "epoch": 0.4382784338427173,
      "grad_norm": 2.019653797149658,
      "learning_rate": 4.780923142070718e-05,
      "loss": 1.4173,
      "step": 41400
    },
    {
      "epoch": 0.4388077556227206,
      "grad_norm": 1.706247091293335,
      "learning_rate": 4.780658479779801e-05,
      "loss": 1.403,
      "step": 41450
    },
    {
      "epoch": 0.4393370774027239,
      "grad_norm": 1.7966781854629517,
      "learning_rate": 4.7803938174888846e-05,
      "loss": 1.4092,
      "step": 41500
    },
    {
      "epoch": 0.4393370774027239,
      "eval_loss": 1.381414532661438,
      "eval_runtime": 46.5525,
      "eval_samples_per_second": 3607.323,
      "eval_steps_per_second": 450.931,
      "step": 41500
    },
    {
      "epoch": 0.4398663991827272,
      "grad_norm": 1.7448190450668335,
      "learning_rate": 4.7801291551979674e-05,
      "loss": 1.392,
      "step": 41550
    },
    {
      "epoch": 0.44039572096273044,
      "grad_norm": 1.6607398986816406,
      "learning_rate": 4.779864492907051e-05,
      "loss": 1.4331,
      "step": 41600
    },
    {
      "epoch": 0.44092504274273375,
      "grad_norm": 1.7914445400238037,
      "learning_rate": 4.7795998306161335e-05,
      "loss": 1.4046,
      "step": 41650
    },
    {
      "epoch": 0.441454364522737,
      "grad_norm": 1.6974977254867554,
      "learning_rate": 4.7793351683252176e-05,
      "loss": 1.4043,
      "step": 41700
    },
    {
      "epoch": 0.4419836863027403,
      "grad_norm": 1.8384184837341309,
      "learning_rate": 4.7790705060343e-05,
      "loss": 1.4066,
      "step": 41750
    },
    {
      "epoch": 0.4425130080827436,
      "grad_norm": 1.823207139968872,
      "learning_rate": 4.778805843743384e-05,
      "loss": 1.4131,
      "step": 41800
    },
    {
      "epoch": 0.4430423298627469,
      "grad_norm": 1.8346822261810303,
      "learning_rate": 4.7785411814524665e-05,
      "loss": 1.3981,
      "step": 41850
    },
    {
      "epoch": 0.44357165164275014,
      "grad_norm": 1.870958685874939,
      "learning_rate": 4.7782765191615506e-05,
      "loss": 1.432,
      "step": 41900
    },
    {
      "epoch": 0.44410097342275345,
      "grad_norm": 1.909643530845642,
      "learning_rate": 4.778011856870633e-05,
      "loss": 1.4237,
      "step": 41950
    },
    {
      "epoch": 0.4446302952027567,
      "grad_norm": 1.8455694913864136,
      "learning_rate": 4.777747194579717e-05,
      "loss": 1.4058,
      "step": 42000
    },
    {
      "epoch": 0.4446302952027567,
      "eval_loss": 1.3800721168518066,
      "eval_runtime": 46.5331,
      "eval_samples_per_second": 3608.832,
      "eval_steps_per_second": 451.12,
      "step": 42000
    },
    {
      "epoch": 0.44515961698275996,
      "grad_norm": 1.9191871881484985,
      "learning_rate": 4.7774825322887994e-05,
      "loss": 1.4212,
      "step": 42050
    },
    {
      "epoch": 0.4456889387627633,
      "grad_norm": 2.044356346130371,
      "learning_rate": 4.777217869997883e-05,
      "loss": 1.4131,
      "step": 42100
    },
    {
      "epoch": 0.44621826054276653,
      "grad_norm": 1.7766977548599243,
      "learning_rate": 4.776953207706966e-05,
      "loss": 1.4075,
      "step": 42150
    },
    {
      "epoch": 0.44674758232276984,
      "grad_norm": 1.8626364469528198,
      "learning_rate": 4.776688545416049e-05,
      "loss": 1.3915,
      "step": 42200
    },
    {
      "epoch": 0.4472769041027731,
      "grad_norm": 1.9178926944732666,
      "learning_rate": 4.7764238831251324e-05,
      "loss": 1.4493,
      "step": 42250
    },
    {
      "epoch": 0.4478062258827764,
      "grad_norm": 1.7947267293930054,
      "learning_rate": 4.776159220834216e-05,
      "loss": 1.4099,
      "step": 42300
    },
    {
      "epoch": 0.44833554766277967,
      "grad_norm": 1.9543609619140625,
      "learning_rate": 4.775894558543299e-05,
      "loss": 1.4144,
      "step": 42350
    },
    {
      "epoch": 0.448864869442783,
      "grad_norm": 1.8023457527160645,
      "learning_rate": 4.775629896252382e-05,
      "loss": 1.3851,
      "step": 42400
    },
    {
      "epoch": 0.44939419122278623,
      "grad_norm": 1.8554306030273438,
      "learning_rate": 4.7753652339614654e-05,
      "loss": 1.4132,
      "step": 42450
    },
    {
      "epoch": 0.44992351300278954,
      "grad_norm": 1.832837462425232,
      "learning_rate": 4.775100571670549e-05,
      "loss": 1.4108,
      "step": 42500
    },
    {
      "epoch": 0.44992351300278954,
      "eval_loss": 1.3821780681610107,
      "eval_runtime": 46.5976,
      "eval_samples_per_second": 3603.834,
      "eval_steps_per_second": 450.495,
      "step": 42500
    },
    {
      "epoch": 0.4504528347827928,
      "grad_norm": 1.836525321006775,
      "learning_rate": 4.774835909379632e-05,
      "loss": 1.4136,
      "step": 42550
    },
    {
      "epoch": 0.4509821565627961,
      "grad_norm": 1.7635698318481445,
      "learning_rate": 4.774571247088715e-05,
      "loss": 1.4122,
      "step": 42600
    },
    {
      "epoch": 0.45151147834279937,
      "grad_norm": 1.797019362449646,
      "learning_rate": 4.774306584797798e-05,
      "loss": 1.3948,
      "step": 42650
    },
    {
      "epoch": 0.4520408001228027,
      "grad_norm": 1.9344936609268188,
      "learning_rate": 4.774041922506882e-05,
      "loss": 1.4195,
      "step": 42700
    },
    {
      "epoch": 0.45257012190280593,
      "grad_norm": 1.771720290184021,
      "learning_rate": 4.7737772602159645e-05,
      "loss": 1.4082,
      "step": 42750
    },
    {
      "epoch": 0.45309944368280924,
      "grad_norm": 1.7653422355651855,
      "learning_rate": 4.773512597925048e-05,
      "loss": 1.405,
      "step": 42800
    },
    {
      "epoch": 0.4536287654628125,
      "grad_norm": 1.9225406646728516,
      "learning_rate": 4.7732479356341306e-05,
      "loss": 1.4097,
      "step": 42850
    },
    {
      "epoch": 0.45415808724281576,
      "grad_norm": 2.043196678161621,
      "learning_rate": 4.772983273343215e-05,
      "loss": 1.3975,
      "step": 42900
    },
    {
      "epoch": 0.45468740902281907,
      "grad_norm": 1.7788559198379517,
      "learning_rate": 4.7727186110522974e-05,
      "loss": 1.4019,
      "step": 42950
    },
    {
      "epoch": 0.4552167308028223,
      "grad_norm": 1.8457088470458984,
      "learning_rate": 4.772453948761381e-05,
      "loss": 1.401,
      "step": 43000
    },
    {
      "epoch": 0.4552167308028223,
      "eval_loss": 1.3760963678359985,
      "eval_runtime": 46.5946,
      "eval_samples_per_second": 3604.069,
      "eval_steps_per_second": 450.525,
      "step": 43000
    },
    {
      "epoch": 0.45574605258282563,
      "grad_norm": 1.782664179801941,
      "learning_rate": 4.7721892864704636e-05,
      "loss": 1.3934,
      "step": 43050
    },
    {
      "epoch": 0.4562753743628289,
      "grad_norm": 1.8462646007537842,
      "learning_rate": 4.7719246241795477e-05,
      "loss": 1.4025,
      "step": 43100
    },
    {
      "epoch": 0.4568046961428322,
      "grad_norm": 1.7259058952331543,
      "learning_rate": 4.7716599618886304e-05,
      "loss": 1.3925,
      "step": 43150
    },
    {
      "epoch": 0.45733401792283546,
      "grad_norm": 1.530517578125,
      "learning_rate": 4.771395299597714e-05,
      "loss": 1.4045,
      "step": 43200
    },
    {
      "epoch": 0.45786333970283877,
      "grad_norm": 1.939389705657959,
      "learning_rate": 4.7711306373067965e-05,
      "loss": 1.3912,
      "step": 43250
    },
    {
      "epoch": 0.458392661482842,
      "grad_norm": 1.7675788402557373,
      "learning_rate": 4.77086597501588e-05,
      "loss": 1.3872,
      "step": 43300
    },
    {
      "epoch": 0.45892198326284533,
      "grad_norm": 1.9150478839874268,
      "learning_rate": 4.7706013127249633e-05,
      "loss": 1.4019,
      "step": 43350
    },
    {
      "epoch": 0.4594513050428486,
      "grad_norm": 1.7330878973007202,
      "learning_rate": 4.770341943679865e-05,
      "loss": 1.3892,
      "step": 43400
    },
    {
      "epoch": 0.4599806268228519,
      "grad_norm": 1.8628273010253906,
      "learning_rate": 4.7700772813889476e-05,
      "loss": 1.4003,
      "step": 43450
    },
    {
      "epoch": 0.46050994860285516,
      "grad_norm": 1.8490437269210815,
      "learning_rate": 4.7698126190980316e-05,
      "loss": 1.4167,
      "step": 43500
    },
    {
      "epoch": 0.46050994860285516,
      "eval_loss": 1.3733867406845093,
      "eval_runtime": 46.5576,
      "eval_samples_per_second": 3606.93,
      "eval_steps_per_second": 450.882,
      "step": 43500
    },
    {
      "epoch": 0.46103927038285847,
      "grad_norm": 1.7515816688537598,
      "learning_rate": 4.7695479568071144e-05,
      "loss": 1.3798,
      "step": 43550
    },
    {
      "epoch": 0.4615685921628617,
      "grad_norm": 1.785470724105835,
      "learning_rate": 4.769283294516198e-05,
      "loss": 1.4079,
      "step": 43600
    },
    {
      "epoch": 0.462097913942865,
      "grad_norm": 1.7310339212417603,
      "learning_rate": 4.7690186322252805e-05,
      "loss": 1.3824,
      "step": 43650
    },
    {
      "epoch": 0.4626272357228683,
      "grad_norm": 1.8215166330337524,
      "learning_rate": 4.768753969934364e-05,
      "loss": 1.3746,
      "step": 43700
    },
    {
      "epoch": 0.46315655750287155,
      "grad_norm": 1.7836248874664307,
      "learning_rate": 4.768489307643447e-05,
      "loss": 1.4135,
      "step": 43750
    },
    {
      "epoch": 0.46368587928287486,
      "grad_norm": 1.7559784650802612,
      "learning_rate": 4.76822464535253e-05,
      "loss": 1.3941,
      "step": 43800
    },
    {
      "epoch": 0.4642152010628781,
      "grad_norm": 1.6825621128082275,
      "learning_rate": 4.7679599830616135e-05,
      "loss": 1.3979,
      "step": 43850
    },
    {
      "epoch": 0.4647445228428814,
      "grad_norm": 1.7586121559143066,
      "learning_rate": 4.767695320770697e-05,
      "loss": 1.3939,
      "step": 43900
    },
    {
      "epoch": 0.4652738446228847,
      "grad_norm": 1.9539705514907837,
      "learning_rate": 4.76743065847978e-05,
      "loss": 1.3917,
      "step": 43950
    },
    {
      "epoch": 0.465803166402888,
      "grad_norm": 1.6350129842758179,
      "learning_rate": 4.767165996188863e-05,
      "loss": 1.4245,
      "step": 44000
    },
    {
      "epoch": 0.465803166402888,
      "eval_loss": 1.3719488382339478,
      "eval_runtime": 46.6255,
      "eval_samples_per_second": 3601.674,
      "eval_steps_per_second": 450.225,
      "step": 44000
    },
    {
      "epoch": 0.46633248818289125,
      "grad_norm": 1.8507100343704224,
      "learning_rate": 4.7669013338979464e-05,
      "loss": 1.4185,
      "step": 44050
    },
    {
      "epoch": 0.46686180996289456,
      "grad_norm": 1.9500731229782104,
      "learning_rate": 4.76663667160703e-05,
      "loss": 1.3941,
      "step": 44100
    },
    {
      "epoch": 0.4673911317428978,
      "grad_norm": 1.8630914688110352,
      "learning_rate": 4.766372009316113e-05,
      "loss": 1.3924,
      "step": 44150
    },
    {
      "epoch": 0.4679204535229011,
      "grad_norm": 1.572167992591858,
      "learning_rate": 4.766107347025196e-05,
      "loss": 1.3956,
      "step": 44200
    },
    {
      "epoch": 0.4684497753029044,
      "grad_norm": 1.76211416721344,
      "learning_rate": 4.7658426847342794e-05,
      "loss": 1.3872,
      "step": 44250
    },
    {
      "epoch": 0.4689790970829077,
      "grad_norm": 1.758998155593872,
      "learning_rate": 4.765578022443363e-05,
      "loss": 1.4001,
      "step": 44300
    },
    {
      "epoch": 0.46950841886291095,
      "grad_norm": 1.9394041299819946,
      "learning_rate": 4.7653133601524455e-05,
      "loss": 1.4024,
      "step": 44350
    },
    {
      "epoch": 0.47003774064291426,
      "grad_norm": 1.8416110277175903,
      "learning_rate": 4.765048697861529e-05,
      "loss": 1.3861,
      "step": 44400
    },
    {
      "epoch": 0.4705670624229175,
      "grad_norm": 1.9071966409683228,
      "learning_rate": 4.764784035570612e-05,
      "loss": 1.3885,
      "step": 44450
    },
    {
      "epoch": 0.47109638420292077,
      "grad_norm": 1.8774479627609253,
      "learning_rate": 4.764519373279696e-05,
      "loss": 1.4065,
      "step": 44500
    },
    {
      "epoch": 0.47109638420292077,
      "eval_loss": 1.368176817893982,
      "eval_runtime": 46.5999,
      "eval_samples_per_second": 3603.657,
      "eval_steps_per_second": 450.473,
      "step": 44500
    },
    {
      "epoch": 0.4716257059829241,
      "grad_norm": 1.8002609014511108,
      "learning_rate": 4.7642547109887785e-05,
      "loss": 1.4059,
      "step": 44550
    },
    {
      "epoch": 0.47215502776292734,
      "grad_norm": 1.8671348094940186,
      "learning_rate": 4.763990048697862e-05,
      "loss": 1.3851,
      "step": 44600
    },
    {
      "epoch": 0.47268434954293065,
      "grad_norm": 1.658783197402954,
      "learning_rate": 4.7637253864069446e-05,
      "loss": 1.4,
      "step": 44650
    },
    {
      "epoch": 0.4732136713229339,
      "grad_norm": 1.837022304534912,
      "learning_rate": 4.763460724116028e-05,
      "loss": 1.3762,
      "step": 44700
    },
    {
      "epoch": 0.4737429931029372,
      "grad_norm": 1.7751022577285767,
      "learning_rate": 4.7631960618251115e-05,
      "loss": 1.3913,
      "step": 44750
    },
    {
      "epoch": 0.47427231488294047,
      "grad_norm": 1.7396057844161987,
      "learning_rate": 4.762931399534194e-05,
      "loss": 1.3844,
      "step": 44800
    },
    {
      "epoch": 0.4748016366629438,
      "grad_norm": 1.7948427200317383,
      "learning_rate": 4.7626667372432776e-05,
      "loss": 1.3894,
      "step": 44850
    },
    {
      "epoch": 0.47533095844294704,
      "grad_norm": 1.7958166599273682,
      "learning_rate": 4.762402074952361e-05,
      "loss": 1.3953,
      "step": 44900
    },
    {
      "epoch": 0.47586028022295035,
      "grad_norm": 1.7918232679367065,
      "learning_rate": 4.7621374126614444e-05,
      "loss": 1.4017,
      "step": 44950
    },
    {
      "epoch": 0.4763896020029536,
      "grad_norm": 1.8461766242980957,
      "learning_rate": 4.761872750370527e-05,
      "loss": 1.4164,
      "step": 45000
    },
    {
      "epoch": 0.4763896020029536,
      "eval_loss": 1.3687794208526611,
      "eval_runtime": 46.759,
      "eval_samples_per_second": 3591.394,
      "eval_steps_per_second": 448.94,
      "step": 45000
    },
    {
      "epoch": 0.4769189237829569,
      "grad_norm": 1.9848474264144897,
      "learning_rate": 4.7616080880796106e-05,
      "loss": 1.3851,
      "step": 45050
    },
    {
      "epoch": 0.47744824556296017,
      "grad_norm": 1.708924412727356,
      "learning_rate": 4.761343425788694e-05,
      "loss": 1.3954,
      "step": 45100
    },
    {
      "epoch": 0.4779775673429635,
      "grad_norm": 1.9491535425186157,
      "learning_rate": 4.7610787634977774e-05,
      "loss": 1.4156,
      "step": 45150
    },
    {
      "epoch": 0.47850688912296674,
      "grad_norm": 1.9230430126190186,
      "learning_rate": 4.76081410120686e-05,
      "loss": 1.3936,
      "step": 45200
    },
    {
      "epoch": 0.47903621090297005,
      "grad_norm": 1.7891347408294678,
      "learning_rate": 4.7605494389159435e-05,
      "loss": 1.3899,
      "step": 45250
    },
    {
      "epoch": 0.4795655326829733,
      "grad_norm": 1.6586660146713257,
      "learning_rate": 4.760284776625027e-05,
      "loss": 1.3923,
      "step": 45300
    },
    {
      "epoch": 0.48009485446297656,
      "grad_norm": 1.7507493495941162,
      "learning_rate": 4.76002011433411e-05,
      "loss": 1.375,
      "step": 45350
    },
    {
      "epoch": 0.4806241762429799,
      "grad_norm": 1.7832838296890259,
      "learning_rate": 4.759760745289011e-05,
      "loss": 1.3846,
      "step": 45400
    },
    {
      "epoch": 0.48115349802298313,
      "grad_norm": 1.7492963075637817,
      "learning_rate": 4.7594960829980946e-05,
      "loss": 1.4081,
      "step": 45450
    },
    {
      "epoch": 0.48168281980298644,
      "grad_norm": 1.79313325881958,
      "learning_rate": 4.759231420707178e-05,
      "loss": 1.3816,
      "step": 45500
    },
    {
      "epoch": 0.48168281980298644,
      "eval_loss": 1.3655970096588135,
      "eval_runtime": 46.5228,
      "eval_samples_per_second": 3609.631,
      "eval_steps_per_second": 451.22,
      "step": 45500
    },
    {
      "epoch": 0.4822121415829897,
      "grad_norm": 1.8790594339370728,
      "learning_rate": 4.7589667584162614e-05,
      "loss": 1.3943,
      "step": 45550
    },
    {
      "epoch": 0.482741463362993,
      "grad_norm": 1.8062855005264282,
      "learning_rate": 4.758702096125344e-05,
      "loss": 1.3915,
      "step": 45600
    },
    {
      "epoch": 0.48327078514299626,
      "grad_norm": 1.8893048763275146,
      "learning_rate": 4.7584374338344275e-05,
      "loss": 1.3648,
      "step": 45650
    },
    {
      "epoch": 0.4838001069229996,
      "grad_norm": 1.8398497104644775,
      "learning_rate": 4.758172771543511e-05,
      "loss": 1.3936,
      "step": 45700
    },
    {
      "epoch": 0.48432942870300283,
      "grad_norm": 2.081455707550049,
      "learning_rate": 4.7579081092525943e-05,
      "loss": 1.3885,
      "step": 45750
    },
    {
      "epoch": 0.48485875048300614,
      "grad_norm": 1.7113560438156128,
      "learning_rate": 4.757643446961677e-05,
      "loss": 1.3804,
      "step": 45800
    },
    {
      "epoch": 0.4853880722630094,
      "grad_norm": 1.908489465713501,
      "learning_rate": 4.7573787846707605e-05,
      "loss": 1.3972,
      "step": 45850
    },
    {
      "epoch": 0.4859173940430127,
      "grad_norm": 1.919298768043518,
      "learning_rate": 4.757114122379844e-05,
      "loss": 1.405,
      "step": 45900
    },
    {
      "epoch": 0.48644671582301596,
      "grad_norm": 1.8352854251861572,
      "learning_rate": 4.7568494600889266e-05,
      "loss": 1.379,
      "step": 45950
    },
    {
      "epoch": 0.4869760376030193,
      "grad_norm": 1.8004884719848633,
      "learning_rate": 4.75658479779801e-05,
      "loss": 1.3842,
      "step": 46000
    },
    {
      "epoch": 0.4869760376030193,
      "eval_loss": 1.363187551498413,
      "eval_runtime": 46.5574,
      "eval_samples_per_second": 3606.948,
      "eval_steps_per_second": 450.885,
      "step": 46000
    },
    {
      "epoch": 0.48750535938302253,
      "grad_norm": 1.7084639072418213,
      "learning_rate": 4.756320135507093e-05,
      "loss": 1.4012,
      "step": 46050
    },
    {
      "epoch": 0.48803468116302584,
      "grad_norm": 1.8280408382415771,
      "learning_rate": 4.756055473216177e-05,
      "loss": 1.3716,
      "step": 46100
    },
    {
      "epoch": 0.4885640029430291,
      "grad_norm": 2.0694375038146973,
      "learning_rate": 4.7557908109252596e-05,
      "loss": 1.3734,
      "step": 46150
    },
    {
      "epoch": 0.48909332472303235,
      "grad_norm": 1.8238760232925415,
      "learning_rate": 4.755526148634343e-05,
      "loss": 1.3805,
      "step": 46200
    },
    {
      "epoch": 0.48962264650303566,
      "grad_norm": 1.780906081199646,
      "learning_rate": 4.755261486343426e-05,
      "loss": 1.3997,
      "step": 46250
    },
    {
      "epoch": 0.4901519682830389,
      "grad_norm": 1.855955958366394,
      "learning_rate": 4.754996824052509e-05,
      "loss": 1.3939,
      "step": 46300
    },
    {
      "epoch": 0.49068129006304223,
      "grad_norm": 1.9055812358856201,
      "learning_rate": 4.7547321617615926e-05,
      "loss": 1.4032,
      "step": 46350
    },
    {
      "epoch": 0.4912106118430455,
      "grad_norm": 1.8198871612548828,
      "learning_rate": 4.754467499470675e-05,
      "loss": 1.3721,
      "step": 46400
    },
    {
      "epoch": 0.4917399336230488,
      "grad_norm": 1.87752366065979,
      "learning_rate": 4.754202837179759e-05,
      "loss": 1.3902,
      "step": 46450
    },
    {
      "epoch": 0.49226925540305205,
      "grad_norm": 1.745375156402588,
      "learning_rate": 4.753938174888842e-05,
      "loss": 1.37,
      "step": 46500
    },
    {
      "epoch": 0.49226925540305205,
      "eval_loss": 1.3611645698547363,
      "eval_runtime": 46.5678,
      "eval_samples_per_second": 3606.143,
      "eval_steps_per_second": 450.784,
      "step": 46500
    },
    {
      "epoch": 0.49279857718305536,
      "grad_norm": 1.8649500608444214,
      "learning_rate": 4.7536735125979255e-05,
      "loss": 1.4066,
      "step": 46550
    },
    {
      "epoch": 0.4933278989630586,
      "grad_norm": 2.058222532272339,
      "learning_rate": 4.753408850307008e-05,
      "loss": 1.3771,
      "step": 46600
    },
    {
      "epoch": 0.49385722074306193,
      "grad_norm": 1.6754248142242432,
      "learning_rate": 4.7531441880160917e-05,
      "loss": 1.3823,
      "step": 46650
    },
    {
      "epoch": 0.4943865425230652,
      "grad_norm": 1.762087106704712,
      "learning_rate": 4.752879525725175e-05,
      "loss": 1.4001,
      "step": 46700
    },
    {
      "epoch": 0.4949158643030685,
      "grad_norm": 1.8450807332992554,
      "learning_rate": 4.7526148634342585e-05,
      "loss": 1.4057,
      "step": 46750
    },
    {
      "epoch": 0.49544518608307175,
      "grad_norm": 1.7778016328811646,
      "learning_rate": 4.752350201143341e-05,
      "loss": 1.3851,
      "step": 46800
    },
    {
      "epoch": 0.49597450786307506,
      "grad_norm": 1.7642368078231812,
      "learning_rate": 4.7520855388524246e-05,
      "loss": 1.3769,
      "step": 46850
    },
    {
      "epoch": 0.4965038296430783,
      "grad_norm": 1.744771957397461,
      "learning_rate": 4.751820876561508e-05,
      "loss": 1.3736,
      "step": 46900
    },
    {
      "epoch": 0.49703315142308163,
      "grad_norm": 1.8013724088668823,
      "learning_rate": 4.751556214270591e-05,
      "loss": 1.3824,
      "step": 46950
    },
    {
      "epoch": 0.4975624732030849,
      "grad_norm": 1.875462293624878,
      "learning_rate": 4.751291551979674e-05,
      "loss": 1.3819,
      "step": 47000
    },
    {
      "epoch": 0.4975624732030849,
      "eval_loss": 1.3593244552612305,
      "eval_runtime": 46.6047,
      "eval_samples_per_second": 3603.283,
      "eval_steps_per_second": 450.426,
      "step": 47000
    },
    {
      "epoch": 0.49809179498308814,
      "grad_norm": 1.5699832439422607,
      "learning_rate": 4.751026889688757e-05,
      "loss": 1.4008,
      "step": 47050
    },
    {
      "epoch": 0.49862111676309145,
      "grad_norm": 1.8710999488830566,
      "learning_rate": 4.750762227397841e-05,
      "loss": 1.408,
      "step": 47100
    },
    {
      "epoch": 0.4991504385430947,
      "grad_norm": 1.912147045135498,
      "learning_rate": 4.750497565106924e-05,
      "loss": 1.3725,
      "step": 47150
    },
    {
      "epoch": 0.499679760323098,
      "grad_norm": 1.809396743774414,
      "learning_rate": 4.750232902816007e-05,
      "loss": 1.3834,
      "step": 47200
    },
    {
      "epoch": 0.5002090821031013,
      "grad_norm": 1.7910330295562744,
      "learning_rate": 4.74996824052509e-05,
      "loss": 1.3888,
      "step": 47250
    },
    {
      "epoch": 0.5007384038831045,
      "grad_norm": 1.8893808126449585,
      "learning_rate": 4.749703578234174e-05,
      "loss": 1.3596,
      "step": 47300
    },
    {
      "epoch": 0.5012677256631078,
      "grad_norm": 1.9171717166900635,
      "learning_rate": 4.749438915943257e-05,
      "loss": 1.376,
      "step": 47350
    },
    {
      "epoch": 0.5017970474431112,
      "grad_norm": 1.9049571752548218,
      "learning_rate": 4.749179546898158e-05,
      "loss": 1.3873,
      "step": 47400
    },
    {
      "epoch": 0.5023263692231145,
      "grad_norm": 1.777466058731079,
      "learning_rate": 4.748914884607241e-05,
      "loss": 1.3866,
      "step": 47450
    },
    {
      "epoch": 0.5028556910031177,
      "grad_norm": 1.895365834236145,
      "learning_rate": 4.748650222316325e-05,
      "loss": 1.3803,
      "step": 47500
    },
    {
      "epoch": 0.5028556910031177,
      "eval_loss": 1.3573914766311646,
      "eval_runtime": 46.5487,
      "eval_samples_per_second": 3607.623,
      "eval_steps_per_second": 450.969,
      "step": 47500
    },
    {
      "epoch": 0.503385012783121,
      "grad_norm": 1.8431196212768555,
      "learning_rate": 4.748385560025408e-05,
      "loss": 1.3887,
      "step": 47550
    },
    {
      "epoch": 0.5039143345631243,
      "grad_norm": 1.8732997179031372,
      "learning_rate": 4.748120897734491e-05,
      "loss": 1.3855,
      "step": 47600
    },
    {
      "epoch": 0.5044436563431276,
      "grad_norm": 1.8674509525299072,
      "learning_rate": 4.747856235443574e-05,
      "loss": 1.3941,
      "step": 47650
    },
    {
      "epoch": 0.5049729781231308,
      "grad_norm": 2.032599449157715,
      "learning_rate": 4.747596866398476e-05,
      "loss": 1.3701,
      "step": 47700
    },
    {
      "epoch": 0.5055022999031341,
      "grad_norm": 1.7635935544967651,
      "learning_rate": 4.7473322041075594e-05,
      "loss": 1.3787,
      "step": 47750
    },
    {
      "epoch": 0.5060316216831374,
      "grad_norm": 1.8299227952957153,
      "learning_rate": 4.747067541816642e-05,
      "loss": 1.365,
      "step": 47800
    },
    {
      "epoch": 0.5065609434631406,
      "grad_norm": 1.9508774280548096,
      "learning_rate": 4.7468028795257256e-05,
      "loss": 1.3812,
      "step": 47850
    },
    {
      "epoch": 0.5070902652431439,
      "grad_norm": 2.0042567253112793,
      "learning_rate": 4.746538217234809e-05,
      "loss": 1.3862,
      "step": 47900
    },
    {
      "epoch": 0.5076195870231472,
      "grad_norm": 1.852808952331543,
      "learning_rate": 4.746273554943892e-05,
      "loss": 1.3855,
      "step": 47950
    },
    {
      "epoch": 0.5081489088031506,
      "grad_norm": 1.8811874389648438,
      "learning_rate": 4.746008892652975e-05,
      "loss": 1.3743,
      "step": 48000
    },
    {
      "epoch": 0.5081489088031506,
      "eval_loss": 1.3575067520141602,
      "eval_runtime": 46.6211,
      "eval_samples_per_second": 3602.014,
      "eval_steps_per_second": 450.268,
      "step": 48000
    },
    {
      "epoch": 0.5086782305831538,
      "grad_norm": 1.7140166759490967,
      "learning_rate": 4.745744230362058e-05,
      "loss": 1.3718,
      "step": 48050
    },
    {
      "epoch": 0.5092075523631571,
      "grad_norm": 1.8431600332260132,
      "learning_rate": 4.745479568071142e-05,
      "loss": 1.3509,
      "step": 48100
    },
    {
      "epoch": 0.5097368741431604,
      "grad_norm": 1.9388426542282104,
      "learning_rate": 4.7452149057802247e-05,
      "loss": 1.3916,
      "step": 48150
    },
    {
      "epoch": 0.5102661959231637,
      "grad_norm": 1.654616117477417,
      "learning_rate": 4.744950243489308e-05,
      "loss": 1.3704,
      "step": 48200
    },
    {
      "epoch": 0.5107955177031669,
      "grad_norm": 1.7875068187713623,
      "learning_rate": 4.744685581198391e-05,
      "loss": 1.3769,
      "step": 48250
    },
    {
      "epoch": 0.5113248394831702,
      "grad_norm": 1.7263226509094238,
      "learning_rate": 4.744420918907474e-05,
      "loss": 1.3882,
      "step": 48300
    },
    {
      "epoch": 0.5118541612631735,
      "grad_norm": 1.899369478225708,
      "learning_rate": 4.7441562566165576e-05,
      "loss": 1.367,
      "step": 48350
    },
    {
      "epoch": 0.5123834830431768,
      "grad_norm": 1.8888686895370483,
      "learning_rate": 4.7438915943256403e-05,
      "loss": 1.3764,
      "step": 48400
    },
    {
      "epoch": 0.51291280482318,
      "grad_norm": 1.9819306135177612,
      "learning_rate": 4.743626932034724e-05,
      "loss": 1.387,
      "step": 48450
    },
    {
      "epoch": 0.5134421266031833,
      "grad_norm": 1.7128005027770996,
      "learning_rate": 4.743362269743807e-05,
      "loss": 1.3672,
      "step": 48500
    },
    {
      "epoch": 0.5134421266031833,
      "eval_loss": 1.3531262874603271,
      "eval_runtime": 46.7031,
      "eval_samples_per_second": 3595.694,
      "eval_steps_per_second": 449.478,
      "step": 48500
    },
    {
      "epoch": 0.5139714483831866,
      "grad_norm": 1.833970308303833,
      "learning_rate": 4.7430976074528906e-05,
      "loss": 1.3581,
      "step": 48550
    },
    {
      "epoch": 0.51450077016319,
      "grad_norm": 2.0846176147460938,
      "learning_rate": 4.742832945161973e-05,
      "loss": 1.3522,
      "step": 48600
    },
    {
      "epoch": 0.5150300919431932,
      "grad_norm": 1.9315215349197388,
      "learning_rate": 4.742568282871057e-05,
      "loss": 1.3784,
      "step": 48650
    },
    {
      "epoch": 0.5155594137231965,
      "grad_norm": 1.8366755247116089,
      "learning_rate": 4.74230362058014e-05,
      "loss": 1.3437,
      "step": 48700
    },
    {
      "epoch": 0.5160887355031998,
      "grad_norm": 1.9094722270965576,
      "learning_rate": 4.7420389582892235e-05,
      "loss": 1.362,
      "step": 48750
    },
    {
      "epoch": 0.516618057283203,
      "grad_norm": 1.7352834939956665,
      "learning_rate": 4.741774295998306e-05,
      "loss": 1.394,
      "step": 48800
    },
    {
      "epoch": 0.5171473790632063,
      "grad_norm": 1.7421342134475708,
      "learning_rate": 4.74150963370739e-05,
      "loss": 1.3765,
      "step": 48850
    },
    {
      "epoch": 0.5176767008432096,
      "grad_norm": 1.874304175376892,
      "learning_rate": 4.741244971416473e-05,
      "loss": 1.3895,
      "step": 48900
    },
    {
      "epoch": 0.5182060226232129,
      "grad_norm": 1.9743529558181763,
      "learning_rate": 4.740980309125556e-05,
      "loss": 1.3654,
      "step": 48950
    },
    {
      "epoch": 0.5187353444032161,
      "grad_norm": 1.9118726253509521,
      "learning_rate": 4.740715646834639e-05,
      "loss": 1.3759,
      "step": 49000
    },
    {
      "epoch": 0.5187353444032161,
      "eval_loss": 1.3516584634780884,
      "eval_runtime": 46.5445,
      "eval_samples_per_second": 3607.948,
      "eval_steps_per_second": 451.01,
      "step": 49000
    },
    {
      "epoch": 0.5192646661832194,
      "grad_norm": 1.8737142086029053,
      "learning_rate": 4.740450984543722e-05,
      "loss": 1.3811,
      "step": 49050
    },
    {
      "epoch": 0.5197939879632227,
      "grad_norm": 1.9048407077789307,
      "learning_rate": 4.740186322252806e-05,
      "loss": 1.3689,
      "step": 49100
    },
    {
      "epoch": 0.520323309743226,
      "grad_norm": 1.9147427082061768,
      "learning_rate": 4.739921659961889e-05,
      "loss": 1.3662,
      "step": 49150
    },
    {
      "epoch": 0.5208526315232292,
      "grad_norm": 1.936214804649353,
      "learning_rate": 4.739656997670972e-05,
      "loss": 1.3836,
      "step": 49200
    },
    {
      "epoch": 0.5213819533032326,
      "grad_norm": 1.9514353275299072,
      "learning_rate": 4.739392335380055e-05,
      "loss": 1.3917,
      "step": 49250
    },
    {
      "epoch": 0.5219112750832359,
      "grad_norm": 1.8364408016204834,
      "learning_rate": 4.739127673089139e-05,
      "loss": 1.3816,
      "step": 49300
    },
    {
      "epoch": 0.5224405968632392,
      "grad_norm": 1.8596179485321045,
      "learning_rate": 4.738863010798222e-05,
      "loss": 1.3689,
      "step": 49350
    },
    {
      "epoch": 0.5229699186432424,
      "grad_norm": 1.8569198846817017,
      "learning_rate": 4.738598348507305e-05,
      "loss": 1.3612,
      "step": 49400
    },
    {
      "epoch": 0.5234992404232457,
      "grad_norm": 1.7610862255096436,
      "learning_rate": 4.738333686216388e-05,
      "loss": 1.3607,
      "step": 49450
    },
    {
      "epoch": 0.524028562203249,
      "grad_norm": 1.9144926071166992,
      "learning_rate": 4.738069023925471e-05,
      "loss": 1.3949,
      "step": 49500
    },
    {
      "epoch": 0.524028562203249,
      "eval_loss": 1.346549391746521,
      "eval_runtime": 46.6625,
      "eval_samples_per_second": 3598.818,
      "eval_steps_per_second": 449.868,
      "step": 49500
    },
    {
      "epoch": 0.5245578839832522,
      "grad_norm": 2.024628162384033,
      "learning_rate": 4.737804361634555e-05,
      "loss": 1.3727,
      "step": 49550
    },
    {
      "epoch": 0.5250872057632555,
      "grad_norm": 1.942892074584961,
      "learning_rate": 4.7375396993436374e-05,
      "loss": 1.3938,
      "step": 49600
    },
    {
      "epoch": 0.5256165275432588,
      "grad_norm": 1.8636146783828735,
      "learning_rate": 4.737275037052721e-05,
      "loss": 1.3622,
      "step": 49650
    },
    {
      "epoch": 0.5261458493232621,
      "grad_norm": 1.824126958847046,
      "learning_rate": 4.737010374761804e-05,
      "loss": 1.3842,
      "step": 49700
    },
    {
      "epoch": 0.5266751711032653,
      "grad_norm": 1.8034217357635498,
      "learning_rate": 4.736745712470888e-05,
      "loss": 1.3695,
      "step": 49750
    },
    {
      "epoch": 0.5272044928832686,
      "grad_norm": 1.9719610214233398,
      "learning_rate": 4.7364810501799704e-05,
      "loss": 1.372,
      "step": 49800
    },
    {
      "epoch": 0.527733814663272,
      "grad_norm": 1.8291181325912476,
      "learning_rate": 4.736216387889054e-05,
      "loss": 1.3641,
      "step": 49850
    },
    {
      "epoch": 0.5282631364432753,
      "grad_norm": 1.8307161331176758,
      "learning_rate": 4.735951725598137e-05,
      "loss": 1.3734,
      "step": 49900
    },
    {
      "epoch": 0.5287924582232785,
      "grad_norm": 1.890809178352356,
      "learning_rate": 4.7356870633072206e-05,
      "loss": 1.3743,
      "step": 49950
    },
    {
      "epoch": 0.5293217800032818,
      "grad_norm": 1.8118095397949219,
      "learning_rate": 4.7354224010163034e-05,
      "loss": 1.3536,
      "step": 50000
    },
    {
      "epoch": 0.5293217800032818,
      "eval_loss": 1.3423177003860474,
      "eval_runtime": 46.6611,
      "eval_samples_per_second": 3598.929,
      "eval_steps_per_second": 449.882,
      "step": 50000
    },
    {
      "epoch": 0.5298511017832851,
      "grad_norm": 1.868903636932373,
      "learning_rate": 4.735157738725387e-05,
      "loss": 1.3822,
      "step": 50050
    },
    {
      "epoch": 0.5303804235632884,
      "grad_norm": 1.893984317779541,
      "learning_rate": 4.73489307643447e-05,
      "loss": 1.3638,
      "step": 50100
    },
    {
      "epoch": 0.5309097453432916,
      "grad_norm": 1.962365984916687,
      "learning_rate": 4.734628414143553e-05,
      "loss": 1.3705,
      "step": 50150
    },
    {
      "epoch": 0.5314390671232949,
      "grad_norm": 1.998844027519226,
      "learning_rate": 4.734363751852636e-05,
      "loss": 1.3552,
      "step": 50200
    },
    {
      "epoch": 0.5319683889032982,
      "grad_norm": 1.807401418685913,
      "learning_rate": 4.734099089561719e-05,
      "loss": 1.3849,
      "step": 50250
    },
    {
      "epoch": 0.5324977106833015,
      "grad_norm": 1.7468271255493164,
      "learning_rate": 4.733834427270803e-05,
      "loss": 1.3645,
      "step": 50300
    },
    {
      "epoch": 0.5330270324633047,
      "grad_norm": 1.810687780380249,
      "learning_rate": 4.733569764979886e-05,
      "loss": 1.3648,
      "step": 50350
    },
    {
      "epoch": 0.533556354243308,
      "grad_norm": 1.830518126487732,
      "learning_rate": 4.733305102688969e-05,
      "loss": 1.357,
      "step": 50400
    },
    {
      "epoch": 0.5340856760233114,
      "grad_norm": 2.0337467193603516,
      "learning_rate": 4.733040440398052e-05,
      "loss": 1.3749,
      "step": 50450
    },
    {
      "epoch": 0.5346149978033146,
      "grad_norm": 1.8713866472244263,
      "learning_rate": 4.732775778107136e-05,
      "loss": 1.3806,
      "step": 50500
    },
    {
      "epoch": 0.5346149978033146,
      "eval_loss": 1.3436671495437622,
      "eval_runtime": 46.5768,
      "eval_samples_per_second": 3605.447,
      "eval_steps_per_second": 450.697,
      "step": 50500
    },
    {
      "epoch": 0.5351443195833179,
      "grad_norm": 2.0038392543792725,
      "learning_rate": 4.732511115816219e-05,
      "loss": 1.3595,
      "step": 50550
    },
    {
      "epoch": 0.5356736413633212,
      "grad_norm": 1.9586143493652344,
      "learning_rate": 4.732246453525302e-05,
      "loss": 1.3594,
      "step": 50600
    },
    {
      "epoch": 0.5362029631433245,
      "grad_norm": 1.816715121269226,
      "learning_rate": 4.731981791234385e-05,
      "loss": 1.3645,
      "step": 50650
    },
    {
      "epoch": 0.5367322849233277,
      "grad_norm": 1.7949775457382202,
      "learning_rate": 4.7317171289434684e-05,
      "loss": 1.3779,
      "step": 50700
    },
    {
      "epoch": 0.537261606703331,
      "grad_norm": 1.9893097877502441,
      "learning_rate": 4.731452466652552e-05,
      "loss": 1.3551,
      "step": 50750
    },
    {
      "epoch": 0.5377909284833343,
      "grad_norm": 1.9640196561813354,
      "learning_rate": 4.7311878043616345e-05,
      "loss": 1.3588,
      "step": 50800
    },
    {
      "epoch": 0.5383202502633376,
      "grad_norm": 1.8880648612976074,
      "learning_rate": 4.730923142070718e-05,
      "loss": 1.3467,
      "step": 50850
    },
    {
      "epoch": 0.5388495720433408,
      "grad_norm": 1.9277814626693726,
      "learning_rate": 4.7306584797798014e-05,
      "loss": 1.3696,
      "step": 50900
    },
    {
      "epoch": 0.5393788938233441,
      "grad_norm": 1.8162105083465576,
      "learning_rate": 4.730393817488885e-05,
      "loss": 1.3583,
      "step": 50950
    },
    {
      "epoch": 0.5399082156033475,
      "grad_norm": 1.936844825744629,
      "learning_rate": 4.730134448443786e-05,
      "loss": 1.3723,
      "step": 51000
    },
    {
      "epoch": 0.5399082156033475,
      "eval_loss": 1.339883804321289,
      "eval_runtime": 46.6177,
      "eval_samples_per_second": 3602.277,
      "eval_steps_per_second": 450.301,
      "step": 51000
    },
    {
      "epoch": 0.5404375373833508,
      "grad_norm": 1.7992682456970215,
      "learning_rate": 4.729869786152869e-05,
      "loss": 1.3607,
      "step": 51050
    },
    {
      "epoch": 0.540966859163354,
      "grad_norm": 1.9505516290664673,
      "learning_rate": 4.7296051238619524e-05,
      "loss": 1.3582,
      "step": 51100
    },
    {
      "epoch": 0.5414961809433573,
      "grad_norm": 1.9124252796173096,
      "learning_rate": 4.729340461571036e-05,
      "loss": 1.3865,
      "step": 51150
    },
    {
      "epoch": 0.5420255027233606,
      "grad_norm": 1.9509170055389404,
      "learning_rate": 4.7290757992801185e-05,
      "loss": 1.3632,
      "step": 51200
    },
    {
      "epoch": 0.5425548245033638,
      "grad_norm": 1.9097578525543213,
      "learning_rate": 4.728811136989202e-05,
      "loss": 1.3456,
      "step": 51250
    },
    {
      "epoch": 0.5430841462833671,
      "grad_norm": 1.8305925130844116,
      "learning_rate": 4.7285464746982853e-05,
      "loss": 1.3725,
      "step": 51300
    },
    {
      "epoch": 0.5436134680633704,
      "grad_norm": 1.8613039255142212,
      "learning_rate": 4.728281812407369e-05,
      "loss": 1.3868,
      "step": 51350
    },
    {
      "epoch": 0.5441427898433737,
      "grad_norm": 1.872243881225586,
      "learning_rate": 4.7280171501164515e-05,
      "loss": 1.3677,
      "step": 51400
    },
    {
      "epoch": 0.5446721116233769,
      "grad_norm": 1.8940027952194214,
      "learning_rate": 4.727752487825535e-05,
      "loss": 1.3868,
      "step": 51450
    },
    {
      "epoch": 0.5452014334033802,
      "grad_norm": 1.8859754800796509,
      "learning_rate": 4.727487825534618e-05,
      "loss": 1.381,
      "step": 51500
    },
    {
      "epoch": 0.5452014334033802,
      "eval_loss": 1.336742877960205,
      "eval_runtime": 46.815,
      "eval_samples_per_second": 3587.097,
      "eval_steps_per_second": 448.403,
      "step": 51500
    },
    {
      "epoch": 0.5457307551833835,
      "grad_norm": 1.8787826299667358,
      "learning_rate": 4.727223163243702e-05,
      "loss": 1.3502,
      "step": 51550
    },
    {
      "epoch": 0.5462600769633869,
      "grad_norm": 1.8554726839065552,
      "learning_rate": 4.7269585009527845e-05,
      "loss": 1.3488,
      "step": 51600
    },
    {
      "epoch": 0.54678939874339,
      "grad_norm": 1.9290047883987427,
      "learning_rate": 4.726693838661868e-05,
      "loss": 1.3654,
      "step": 51650
    },
    {
      "epoch": 0.5473187205233934,
      "grad_norm": 1.8003994226455688,
      "learning_rate": 4.7264291763709506e-05,
      "loss": 1.369,
      "step": 51700
    },
    {
      "epoch": 0.5478480423033967,
      "grad_norm": 1.790905237197876,
      "learning_rate": 4.726164514080034e-05,
      "loss": 1.3755,
      "step": 51750
    },
    {
      "epoch": 0.5483773640834,
      "grad_norm": 1.8573874235153198,
      "learning_rate": 4.7258998517891174e-05,
      "loss": 1.3798,
      "step": 51800
    },
    {
      "epoch": 0.5489066858634032,
      "grad_norm": 1.7709681987762451,
      "learning_rate": 4.7256351894982e-05,
      "loss": 1.375,
      "step": 51850
    },
    {
      "epoch": 0.5494360076434065,
      "grad_norm": 1.9728028774261475,
      "learning_rate": 4.7253705272072836e-05,
      "loss": 1.3651,
      "step": 51900
    },
    {
      "epoch": 0.5499653294234098,
      "grad_norm": 2.0260229110717773,
      "learning_rate": 4.725105864916367e-05,
      "loss": 1.3782,
      "step": 51950
    },
    {
      "epoch": 0.5504946512034131,
      "grad_norm": 1.780875325202942,
      "learning_rate": 4.7248412026254504e-05,
      "loss": 1.385,
      "step": 52000
    },
    {
      "epoch": 0.5504946512034131,
      "eval_loss": 1.3347808122634888,
      "eval_runtime": 46.5664,
      "eval_samples_per_second": 3606.249,
      "eval_steps_per_second": 450.797,
      "step": 52000
    },
    {
      "epoch": 0.5510239729834163,
      "grad_norm": 1.8133286237716675,
      "learning_rate": 4.724576540334533e-05,
      "loss": 1.3773,
      "step": 52050
    },
    {
      "epoch": 0.5515532947634196,
      "grad_norm": 1.9804328680038452,
      "learning_rate": 4.7243118780436165e-05,
      "loss": 1.3462,
      "step": 52100
    },
    {
      "epoch": 0.5520826165434229,
      "grad_norm": 2.028353214263916,
      "learning_rate": 4.7240472157527e-05,
      "loss": 1.3653,
      "step": 52150
    },
    {
      "epoch": 0.5526119383234261,
      "grad_norm": 1.742059588432312,
      "learning_rate": 4.723782553461783e-05,
      "loss": 1.3778,
      "step": 52200
    },
    {
      "epoch": 0.5531412601034295,
      "grad_norm": 1.8958852291107178,
      "learning_rate": 4.723517891170866e-05,
      "loss": 1.3706,
      "step": 52250
    },
    {
      "epoch": 0.5536705818834328,
      "grad_norm": 2.0284173488616943,
      "learning_rate": 4.7232532288799495e-05,
      "loss": 1.3665,
      "step": 52300
    },
    {
      "epoch": 0.5541999036634361,
      "grad_norm": 1.8568364381790161,
      "learning_rate": 4.722988566589033e-05,
      "loss": 1.3755,
      "step": 52350
    },
    {
      "epoch": 0.5547292254434393,
      "grad_norm": 1.9838463068008423,
      "learning_rate": 4.7227239042981156e-05,
      "loss": 1.3524,
      "step": 52400
    },
    {
      "epoch": 0.5552585472234426,
      "grad_norm": 1.8252153396606445,
      "learning_rate": 4.722459242007199e-05,
      "loss": 1.3713,
      "step": 52450
    },
    {
      "epoch": 0.5557878690034459,
      "grad_norm": 1.8851207494735718,
      "learning_rate": 4.722194579716282e-05,
      "loss": 1.3767,
      "step": 52500
    },
    {
      "epoch": 0.5557878690034459,
      "eval_loss": 1.3341048955917358,
      "eval_runtime": 46.7415,
      "eval_samples_per_second": 3592.737,
      "eval_steps_per_second": 449.108,
      "step": 52500
    },
    {
      "epoch": 0.5563171907834492,
      "grad_norm": 1.8794807195663452,
      "learning_rate": 4.721929917425366e-05,
      "loss": 1.3641,
      "step": 52550
    },
    {
      "epoch": 0.5568465125634524,
      "grad_norm": 1.8724174499511719,
      "learning_rate": 4.7216652551344486e-05,
      "loss": 1.3785,
      "step": 52600
    },
    {
      "epoch": 0.5573758343434557,
      "grad_norm": 1.91338050365448,
      "learning_rate": 4.721400592843532e-05,
      "loss": 1.377,
      "step": 52650
    },
    {
      "epoch": 0.557905156123459,
      "grad_norm": 1.954464316368103,
      "learning_rate": 4.721135930552615e-05,
      "loss": 1.3569,
      "step": 52700
    },
    {
      "epoch": 0.5584344779034623,
      "grad_norm": 1.8395109176635742,
      "learning_rate": 4.720871268261698e-05,
      "loss": 1.3846,
      "step": 52750
    },
    {
      "epoch": 0.5589637996834655,
      "grad_norm": 1.9259397983551025,
      "learning_rate": 4.7206066059707815e-05,
      "loss": 1.3708,
      "step": 52800
    },
    {
      "epoch": 0.5594931214634689,
      "grad_norm": 1.7422559261322021,
      "learning_rate": 4.720341943679864e-05,
      "loss": 1.3511,
      "step": 52850
    },
    {
      "epoch": 0.5600224432434722,
      "grad_norm": 1.9594454765319824,
      "learning_rate": 4.720077281388948e-05,
      "loss": 1.3647,
      "step": 52900
    },
    {
      "epoch": 0.5605517650234754,
      "grad_norm": 1.8478971719741821,
      "learning_rate": 4.719812619098031e-05,
      "loss": 1.3574,
      "step": 52950
    },
    {
      "epoch": 0.5610810868034787,
      "grad_norm": 2.0752475261688232,
      "learning_rate": 4.7195479568071145e-05,
      "loss": 1.3442,
      "step": 53000
    },
    {
      "epoch": 0.5610810868034787,
      "eval_loss": 1.3338345289230347,
      "eval_runtime": 46.7097,
      "eval_samples_per_second": 3595.182,
      "eval_steps_per_second": 449.414,
      "step": 53000
    },
    {
      "epoch": 0.561610408583482,
      "grad_norm": 1.8077973127365112,
      "learning_rate": 4.719283294516197e-05,
      "loss": 1.3469,
      "step": 53050
    },
    {
      "epoch": 0.5621397303634853,
      "grad_norm": 1.8298969268798828,
      "learning_rate": 4.7190186322252807e-05,
      "loss": 1.3731,
      "step": 53100
    },
    {
      "epoch": 0.5626690521434885,
      "grad_norm": 2.0428075790405273,
      "learning_rate": 4.718753969934364e-05,
      "loss": 1.3552,
      "step": 53150
    },
    {
      "epoch": 0.5631983739234918,
      "grad_norm": 1.8307641744613647,
      "learning_rate": 4.7184893076434475e-05,
      "loss": 1.3812,
      "step": 53200
    },
    {
      "epoch": 0.5637276957034951,
      "grad_norm": 2.1158266067504883,
      "learning_rate": 4.71822464535253e-05,
      "loss": 1.3594,
      "step": 53250
    },
    {
      "epoch": 0.5642570174834984,
      "grad_norm": 1.8285995721817017,
      "learning_rate": 4.7179599830616136e-05,
      "loss": 1.3691,
      "step": 53300
    },
    {
      "epoch": 0.5647863392635016,
      "grad_norm": 1.8258483409881592,
      "learning_rate": 4.717695320770697e-05,
      "loss": 1.3289,
      "step": 53350
    },
    {
      "epoch": 0.565315661043505,
      "grad_norm": 1.9372901916503906,
      "learning_rate": 4.71743065847978e-05,
      "loss": 1.352,
      "step": 53400
    },
    {
      "epoch": 0.5658449828235083,
      "grad_norm": 2.097632646560669,
      "learning_rate": 4.717165996188863e-05,
      "loss": 1.3704,
      "step": 53450
    },
    {
      "epoch": 0.5663743046035116,
      "grad_norm": 1.9253382682800293,
      "learning_rate": 4.716901333897946e-05,
      "loss": 1.3528,
      "step": 53500
    },
    {
      "epoch": 0.5663743046035116,
      "eval_loss": 1.3283056020736694,
      "eval_runtime": 46.6429,
      "eval_samples_per_second": 3600.334,
      "eval_steps_per_second": 450.058,
      "step": 53500
    },
    {
      "epoch": 0.5669036263835148,
      "grad_norm": 1.7937067747116089,
      "learning_rate": 4.71663667160703e-05,
      "loss": 1.3573,
      "step": 53550
    },
    {
      "epoch": 0.5674329481635181,
      "grad_norm": 2.0254597663879395,
      "learning_rate": 4.716372009316113e-05,
      "loss": 1.3559,
      "step": 53600
    },
    {
      "epoch": 0.5679622699435214,
      "grad_norm": 2.1797842979431152,
      "learning_rate": 4.716107347025196e-05,
      "loss": 1.3212,
      "step": 53650
    },
    {
      "epoch": 0.5684915917235247,
      "grad_norm": 1.740500807762146,
      "learning_rate": 4.715842684734279e-05,
      "loss": 1.3486,
      "step": 53700
    },
    {
      "epoch": 0.5690209135035279,
      "grad_norm": 1.8423205614089966,
      "learning_rate": 4.715578022443363e-05,
      "loss": 1.3468,
      "step": 53750
    },
    {
      "epoch": 0.5695502352835312,
      "grad_norm": 1.7747927904129028,
      "learning_rate": 4.715313360152446e-05,
      "loss": 1.367,
      "step": 53800
    },
    {
      "epoch": 0.5700795570635345,
      "grad_norm": 1.9062294960021973,
      "learning_rate": 4.715053991107347e-05,
      "loss": 1.3481,
      "step": 53850
    },
    {
      "epoch": 0.5706088788435377,
      "grad_norm": 1.8376680612564087,
      "learning_rate": 4.71478932881643e-05,
      "loss": 1.3477,
      "step": 53900
    },
    {
      "epoch": 0.571138200623541,
      "grad_norm": 2.012087345123291,
      "learning_rate": 4.714524666525514e-05,
      "loss": 1.3363,
      "step": 53950
    },
    {
      "epoch": 0.5716675224035443,
      "grad_norm": 1.726515531539917,
      "learning_rate": 4.714260004234597e-05,
      "loss": 1.3697,
      "step": 54000
    },
    {
      "epoch": 0.5716675224035443,
      "eval_loss": 1.325621247291565,
      "eval_runtime": 46.6431,
      "eval_samples_per_second": 3600.318,
      "eval_steps_per_second": 450.056,
      "step": 54000
    },
    {
      "epoch": 0.5721968441835477,
      "grad_norm": 2.0256659984588623,
      "learning_rate": 4.71399534194368e-05,
      "loss": 1.3452,
      "step": 54050
    },
    {
      "epoch": 0.5727261659635509,
      "grad_norm": 1.9285751581192017,
      "learning_rate": 4.713730679652763e-05,
      "loss": 1.3737,
      "step": 54100
    },
    {
      "epoch": 0.5732554877435542,
      "grad_norm": 1.837114691734314,
      "learning_rate": 4.713466017361847e-05,
      "loss": 1.3421,
      "step": 54150
    },
    {
      "epoch": 0.5737848095235575,
      "grad_norm": 1.9581557512283325,
      "learning_rate": 4.71320135507093e-05,
      "loss": 1.3432,
      "step": 54200
    },
    {
      "epoch": 0.5743141313035608,
      "grad_norm": 2.1431238651275635,
      "learning_rate": 4.712936692780013e-05,
      "loss": 1.3499,
      "step": 54250
    },
    {
      "epoch": 0.574843453083564,
      "grad_norm": 1.7526005506515503,
      "learning_rate": 4.712672030489096e-05,
      "loss": 1.3653,
      "step": 54300
    },
    {
      "epoch": 0.5753727748635673,
      "grad_norm": 2.1395273208618164,
      "learning_rate": 4.712407368198179e-05,
      "loss": 1.3483,
      "step": 54350
    },
    {
      "epoch": 0.5759020966435706,
      "grad_norm": 2.0381505489349365,
      "learning_rate": 4.7121427059072626e-05,
      "loss": 1.3637,
      "step": 54400
    },
    {
      "epoch": 0.5764314184235739,
      "grad_norm": 2.0114760398864746,
      "learning_rate": 4.7118780436163454e-05,
      "loss": 1.3694,
      "step": 54450
    },
    {
      "epoch": 0.5769607402035771,
      "grad_norm": 1.9733314514160156,
      "learning_rate": 4.711613381325429e-05,
      "loss": 1.3565,
      "step": 54500
    },
    {
      "epoch": 0.5769607402035771,
      "eval_loss": 1.324609637260437,
      "eval_runtime": 46.6322,
      "eval_samples_per_second": 3601.16,
      "eval_steps_per_second": 450.161,
      "step": 54500
    },
    {
      "epoch": 0.5774900619835804,
      "grad_norm": 1.7665687799453735,
      "learning_rate": 4.711348719034512e-05,
      "loss": 1.3478,
      "step": 54550
    },
    {
      "epoch": 0.5780193837635837,
      "grad_norm": 2.062267303466797,
      "learning_rate": 4.7110840567435956e-05,
      "loss": 1.327,
      "step": 54600
    },
    {
      "epoch": 0.578548705543587,
      "grad_norm": 2.0524449348449707,
      "learning_rate": 4.710819394452678e-05,
      "loss": 1.3609,
      "step": 54650
    },
    {
      "epoch": 0.5790780273235903,
      "grad_norm": 1.9000821113586426,
      "learning_rate": 4.710554732161762e-05,
      "loss": 1.3709,
      "step": 54700
    },
    {
      "epoch": 0.5796073491035936,
      "grad_norm": 1.9461508989334106,
      "learning_rate": 4.710290069870845e-05,
      "loss": 1.3569,
      "step": 54750
    },
    {
      "epoch": 0.5801366708835969,
      "grad_norm": 1.9642484188079834,
      "learning_rate": 4.7100254075799286e-05,
      "loss": 1.3537,
      "step": 54800
    },
    {
      "epoch": 0.5806659926636001,
      "grad_norm": 2.0218169689178467,
      "learning_rate": 4.709760745289011e-05,
      "loss": 1.3508,
      "step": 54850
    },
    {
      "epoch": 0.5811953144436034,
      "grad_norm": 2.0211853981018066,
      "learning_rate": 4.709496082998095e-05,
      "loss": 1.368,
      "step": 54900
    },
    {
      "epoch": 0.5817246362236067,
      "grad_norm": 1.994641661643982,
      "learning_rate": 4.709231420707178e-05,
      "loss": 1.3714,
      "step": 54950
    },
    {
      "epoch": 0.58225395800361,
      "grad_norm": 2.0964739322662354,
      "learning_rate": 4.708966758416261e-05,
      "loss": 1.3542,
      "step": 55000
    },
    {
      "epoch": 0.58225395800361,
      "eval_loss": 1.3198096752166748,
      "eval_runtime": 46.5673,
      "eval_samples_per_second": 3606.18,
      "eval_steps_per_second": 450.789,
      "step": 55000
    },
    {
      "epoch": 0.5827832797836132,
      "grad_norm": 1.8635631799697876,
      "learning_rate": 4.708702096125344e-05,
      "loss": 1.3434,
      "step": 55050
    },
    {
      "epoch": 0.5833126015636165,
      "grad_norm": 1.9109458923339844,
      "learning_rate": 4.708437433834427e-05,
      "loss": 1.3632,
      "step": 55100
    },
    {
      "epoch": 0.5838419233436198,
      "grad_norm": 1.9550771713256836,
      "learning_rate": 4.708172771543511e-05,
      "loss": 1.3666,
      "step": 55150
    },
    {
      "epoch": 0.5843712451236232,
      "grad_norm": 1.7267571687698364,
      "learning_rate": 4.707908109252594e-05,
      "loss": 1.3598,
      "step": 55200
    },
    {
      "epoch": 0.5849005669036264,
      "grad_norm": 2.036893606185913,
      "learning_rate": 4.707643446961677e-05,
      "loss": 1.3649,
      "step": 55250
    },
    {
      "epoch": 0.5854298886836297,
      "grad_norm": 1.8047780990600586,
      "learning_rate": 4.70737878467076e-05,
      "loss": 1.3641,
      "step": 55300
    },
    {
      "epoch": 0.585959210463633,
      "grad_norm": 1.973283052444458,
      "learning_rate": 4.707114122379844e-05,
      "loss": 1.3718,
      "step": 55350
    },
    {
      "epoch": 0.5864885322436362,
      "grad_norm": 1.9731662273406982,
      "learning_rate": 4.706849460088927e-05,
      "loss": 1.343,
      "step": 55400
    },
    {
      "epoch": 0.5870178540236395,
      "grad_norm": 2.0134692192077637,
      "learning_rate": 4.70658479779801e-05,
      "loss": 1.3753,
      "step": 55450
    },
    {
      "epoch": 0.5875471758036428,
      "grad_norm": 1.8504118919372559,
      "learning_rate": 4.706320135507093e-05,
      "loss": 1.356,
      "step": 55500
    },
    {
      "epoch": 0.5875471758036428,
      "eval_loss": 1.3204399347305298,
      "eval_runtime": 46.7764,
      "eval_samples_per_second": 3590.057,
      "eval_steps_per_second": 448.773,
      "step": 55500
    },
    {
      "epoch": 0.5880764975836461,
      "grad_norm": 1.9649990797042847,
      "learning_rate": 4.706055473216176e-05,
      "loss": 1.3483,
      "step": 55550
    },
    {
      "epoch": 0.5886058193636493,
      "grad_norm": 1.973953366279602,
      "learning_rate": 4.70579081092526e-05,
      "loss": 1.3425,
      "step": 55600
    },
    {
      "epoch": 0.5891351411436526,
      "grad_norm": 2.068833589553833,
      "learning_rate": 4.7055261486343425e-05,
      "loss": 1.3264,
      "step": 55650
    },
    {
      "epoch": 0.5896644629236559,
      "grad_norm": 1.9754582643508911,
      "learning_rate": 4.705261486343426e-05,
      "loss": 1.3482,
      "step": 55700
    },
    {
      "epoch": 0.5901937847036592,
      "grad_norm": 2.009162664413452,
      "learning_rate": 4.704996824052509e-05,
      "loss": 1.3574,
      "step": 55750
    },
    {
      "epoch": 0.5907231064836624,
      "grad_norm": 1.8894667625427246,
      "learning_rate": 4.704732161761593e-05,
      "loss": 1.3473,
      "step": 55800
    },
    {
      "epoch": 0.5912524282636658,
      "grad_norm": 1.9255915880203247,
      "learning_rate": 4.7044674994706754e-05,
      "loss": 1.3376,
      "step": 55850
    },
    {
      "epoch": 0.5917817500436691,
      "grad_norm": 1.8706772327423096,
      "learning_rate": 4.704202837179759e-05,
      "loss": 1.3517,
      "step": 55900
    },
    {
      "epoch": 0.5923110718236724,
      "grad_norm": 1.8773045539855957,
      "learning_rate": 4.703938174888842e-05,
      "loss": 1.3528,
      "step": 55950
    },
    {
      "epoch": 0.5928403936036756,
      "grad_norm": 2.131805181503296,
      "learning_rate": 4.7036735125979257e-05,
      "loss": 1.3355,
      "step": 56000
    },
    {
      "epoch": 0.5928403936036756,
      "eval_loss": 1.3179421424865723,
      "eval_runtime": 46.5678,
      "eval_samples_per_second": 3606.136,
      "eval_steps_per_second": 450.783,
      "step": 56000
    },
    {
      "epoch": 0.5933697153836789,
      "grad_norm": 1.912370204925537,
      "learning_rate": 4.7034088503070084e-05,
      "loss": 1.3434,
      "step": 56050
    },
    {
      "epoch": 0.5938990371636822,
      "grad_norm": 1.9826419353485107,
      "learning_rate": 4.703144188016092e-05,
      "loss": 1.3649,
      "step": 56100
    },
    {
      "epoch": 0.5944283589436855,
      "grad_norm": 2.0153214931488037,
      "learning_rate": 4.702879525725175e-05,
      "loss": 1.3744,
      "step": 56150
    },
    {
      "epoch": 0.5949576807236887,
      "grad_norm": 2.03157901763916,
      "learning_rate": 4.702614863434258e-05,
      "loss": 1.3123,
      "step": 56200
    },
    {
      "epoch": 0.595487002503692,
      "grad_norm": 2.2636733055114746,
      "learning_rate": 4.7023502011433413e-05,
      "loss": 1.3287,
      "step": 56250
    },
    {
      "epoch": 0.5960163242836953,
      "grad_norm": 1.885980248451233,
      "learning_rate": 4.702085538852424e-05,
      "loss": 1.3546,
      "step": 56300
    },
    {
      "epoch": 0.5965456460636985,
      "grad_norm": 1.9922356605529785,
      "learning_rate": 4.701820876561508e-05,
      "loss": 1.3345,
      "step": 56350
    },
    {
      "epoch": 0.5970749678437018,
      "grad_norm": 2.0428240299224854,
      "learning_rate": 4.701556214270591e-05,
      "loss": 1.3308,
      "step": 56400
    },
    {
      "epoch": 0.5976042896237052,
      "grad_norm": 1.8808530569076538,
      "learning_rate": 4.701291551979674e-05,
      "loss": 1.3595,
      "step": 56450
    },
    {
      "epoch": 0.5981336114037085,
      "grad_norm": 2.1167166233062744,
      "learning_rate": 4.701026889688757e-05,
      "loss": 1.3352,
      "step": 56500
    },
    {
      "epoch": 0.5981336114037085,
      "eval_loss": 1.3145396709442139,
      "eval_runtime": 46.6174,
      "eval_samples_per_second": 3602.3,
      "eval_steps_per_second": 450.304,
      "step": 56500
    },
    {
      "epoch": 0.5986629331837117,
      "grad_norm": 2.161625862121582,
      "learning_rate": 4.7007622273978405e-05,
      "loss": 1.3369,
      "step": 56550
    },
    {
      "epoch": 0.599192254963715,
      "grad_norm": 1.967389464378357,
      "learning_rate": 4.700497565106924e-05,
      "loss": 1.3426,
      "step": 56600
    },
    {
      "epoch": 0.5997215767437183,
      "grad_norm": 2.0775046348571777,
      "learning_rate": 4.700238196061825e-05,
      "loss": 1.3611,
      "step": 56650
    },
    {
      "epoch": 0.6002508985237216,
      "grad_norm": 2.023773431777954,
      "learning_rate": 4.699973533770908e-05,
      "loss": 1.3686,
      "step": 56700
    },
    {
      "epoch": 0.6007802203037248,
      "grad_norm": 2.0009920597076416,
      "learning_rate": 4.699708871479992e-05,
      "loss": 1.3331,
      "step": 56750
    },
    {
      "epoch": 0.6013095420837281,
      "grad_norm": 2.0672059059143066,
      "learning_rate": 4.699444209189075e-05,
      "loss": 1.3378,
      "step": 56800
    },
    {
      "epoch": 0.6018388638637314,
      "grad_norm": 2.149890184402466,
      "learning_rate": 4.699179546898158e-05,
      "loss": 1.353,
      "step": 56850
    },
    {
      "epoch": 0.6023681856437347,
      "grad_norm": 2.161161422729492,
      "learning_rate": 4.698914884607241e-05,
      "loss": 1.3468,
      "step": 56900
    },
    {
      "epoch": 0.6028975074237379,
      "grad_norm": 2.021014451980591,
      "learning_rate": 4.698650222316325e-05,
      "loss": 1.3376,
      "step": 56950
    },
    {
      "epoch": 0.6034268292037412,
      "grad_norm": 2.106109619140625,
      "learning_rate": 4.698385560025408e-05,
      "loss": 1.3349,
      "step": 57000
    },
    {
      "epoch": 0.6034268292037412,
      "eval_loss": 1.313002109527588,
      "eval_runtime": 46.5397,
      "eval_samples_per_second": 3608.319,
      "eval_steps_per_second": 451.056,
      "step": 57000
    },
    {
      "epoch": 0.6039561509837446,
      "grad_norm": 2.1426868438720703,
      "learning_rate": 4.698120897734491e-05,
      "loss": 1.3421,
      "step": 57050
    },
    {
      "epoch": 0.6044854727637478,
      "grad_norm": 2.055816650390625,
      "learning_rate": 4.697856235443574e-05,
      "loss": 1.3503,
      "step": 57100
    },
    {
      "epoch": 0.6050147945437511,
      "grad_norm": 1.9158411026000977,
      "learning_rate": 4.6975915731526574e-05,
      "loss": 1.3504,
      "step": 57150
    },
    {
      "epoch": 0.6055441163237544,
      "grad_norm": 2.0051066875457764,
      "learning_rate": 4.697326910861741e-05,
      "loss": 1.3401,
      "step": 57200
    },
    {
      "epoch": 0.6060734381037577,
      "grad_norm": 1.8046424388885498,
      "learning_rate": 4.6970622485708235e-05,
      "loss": 1.3601,
      "step": 57250
    },
    {
      "epoch": 0.6066027598837609,
      "grad_norm": 1.9786721467971802,
      "learning_rate": 4.696797586279907e-05,
      "loss": 1.3415,
      "step": 57300
    },
    {
      "epoch": 0.6071320816637642,
      "grad_norm": 2.0487053394317627,
      "learning_rate": 4.6965329239889904e-05,
      "loss": 1.3613,
      "step": 57350
    },
    {
      "epoch": 0.6076614034437675,
      "grad_norm": 2.1185266971588135,
      "learning_rate": 4.696268261698074e-05,
      "loss": 1.3477,
      "step": 57400
    },
    {
      "epoch": 0.6081907252237708,
      "grad_norm": 1.9072930812835693,
      "learning_rate": 4.6960035994071565e-05,
      "loss": 1.352,
      "step": 57450
    },
    {
      "epoch": 0.608720047003774,
      "grad_norm": 2.09798264503479,
      "learning_rate": 4.69573893711624e-05,
      "loss": 1.3314,
      "step": 57500
    },
    {
      "epoch": 0.608720047003774,
      "eval_loss": 1.3146275281906128,
      "eval_runtime": 46.6698,
      "eval_samples_per_second": 3598.258,
      "eval_steps_per_second": 449.798,
      "step": 57500
    },
    {
      "epoch": 0.6092493687837773,
      "grad_norm": 2.0379655361175537,
      "learning_rate": 4.695474274825323e-05,
      "loss": 1.3552,
      "step": 57550
    },
    {
      "epoch": 0.6097786905637806,
      "grad_norm": 2.1041738986968994,
      "learning_rate": 4.695209612534406e-05,
      "loss": 1.3515,
      "step": 57600
    },
    {
      "epoch": 0.610308012343784,
      "grad_norm": 2.0611913204193115,
      "learning_rate": 4.6949449502434895e-05,
      "loss": 1.3514,
      "step": 57650
    },
    {
      "epoch": 0.6108373341237872,
      "grad_norm": 1.996330738067627,
      "learning_rate": 4.694680287952572e-05,
      "loss": 1.3368,
      "step": 57700
    },
    {
      "epoch": 0.6113666559037905,
      "grad_norm": 2.031102418899536,
      "learning_rate": 4.694415625661656e-05,
      "loss": 1.3379,
      "step": 57750
    },
    {
      "epoch": 0.6118959776837938,
      "grad_norm": 2.0582191944122314,
      "learning_rate": 4.694150963370739e-05,
      "loss": 1.3305,
      "step": 57800
    },
    {
      "epoch": 0.6124252994637971,
      "grad_norm": 1.9537557363510132,
      "learning_rate": 4.6938863010798224e-05,
      "loss": 1.3318,
      "step": 57850
    },
    {
      "epoch": 0.6129546212438003,
      "grad_norm": 2.0161678791046143,
      "learning_rate": 4.693621638788905e-05,
      "loss": 1.3367,
      "step": 57900
    },
    {
      "epoch": 0.6134839430238036,
      "grad_norm": 2.017144203186035,
      "learning_rate": 4.693356976497989e-05,
      "loss": 1.3411,
      "step": 57950
    },
    {
      "epoch": 0.6140132648038069,
      "grad_norm": 1.9262198209762573,
      "learning_rate": 4.693092314207072e-05,
      "loss": 1.3428,
      "step": 58000
    },
    {
      "epoch": 0.6140132648038069,
      "eval_loss": 1.3080402612686157,
      "eval_runtime": 46.6158,
      "eval_samples_per_second": 3602.428,
      "eval_steps_per_second": 450.32,
      "step": 58000
    },
    {
      "epoch": 0.6145425865838101,
      "grad_norm": 2.0985589027404785,
      "learning_rate": 4.6928276519161554e-05,
      "loss": 1.3302,
      "step": 58050
    },
    {
      "epoch": 0.6150719083638134,
      "grad_norm": 1.9533452987670898,
      "learning_rate": 4.692562989625238e-05,
      "loss": 1.3296,
      "step": 58100
    },
    {
      "epoch": 0.6156012301438167,
      "grad_norm": 1.9943424463272095,
      "learning_rate": 4.6922983273343215e-05,
      "loss": 1.3476,
      "step": 58150
    },
    {
      "epoch": 0.61613055192382,
      "grad_norm": 1.7423323392868042,
      "learning_rate": 4.692033665043405e-05,
      "loss": 1.3359,
      "step": 58200
    },
    {
      "epoch": 0.6166598737038232,
      "grad_norm": 1.8606470823287964,
      "learning_rate": 4.691769002752488e-05,
      "loss": 1.3388,
      "step": 58250
    },
    {
      "epoch": 0.6171891954838266,
      "grad_norm": 1.9884015321731567,
      "learning_rate": 4.691504340461571e-05,
      "loss": 1.3543,
      "step": 58300
    },
    {
      "epoch": 0.6177185172638299,
      "grad_norm": 1.903447151184082,
      "learning_rate": 4.6912396781706545e-05,
      "loss": 1.3404,
      "step": 58350
    },
    {
      "epoch": 0.6182478390438332,
      "grad_norm": 1.9323409795761108,
      "learning_rate": 4.690975015879738e-05,
      "loss": 1.346,
      "step": 58400
    },
    {
      "epoch": 0.6187771608238364,
      "grad_norm": 1.8621808290481567,
      "learning_rate": 4.6907103535888206e-05,
      "loss": 1.3387,
      "step": 58450
    },
    {
      "epoch": 0.6193064826038397,
      "grad_norm": 2.0963757038116455,
      "learning_rate": 4.690445691297904e-05,
      "loss": 1.3511,
      "step": 58500
    },
    {
      "epoch": 0.6193064826038397,
      "eval_loss": 1.3057126998901367,
      "eval_runtime": 46.6225,
      "eval_samples_per_second": 3601.912,
      "eval_steps_per_second": 450.255,
      "step": 58500
    },
    {
      "epoch": 0.619835804383843,
      "grad_norm": 1.9822503328323364,
      "learning_rate": 4.6901810290069875e-05,
      "loss": 1.3375,
      "step": 58550
    },
    {
      "epoch": 0.6203651261638463,
      "grad_norm": 2.0316269397735596,
      "learning_rate": 4.689916366716071e-05,
      "loss": 1.333,
      "step": 58600
    },
    {
      "epoch": 0.6208944479438495,
      "grad_norm": 2.0071184635162354,
      "learning_rate": 4.6896517044251536e-05,
      "loss": 1.3547,
      "step": 58650
    },
    {
      "epoch": 0.6214237697238528,
      "grad_norm": 1.8814259767532349,
      "learning_rate": 4.689392335380055e-05,
      "loss": 1.352,
      "step": 58700
    },
    {
      "epoch": 0.6219530915038561,
      "grad_norm": 1.8370766639709473,
      "learning_rate": 4.6891276730891385e-05,
      "loss": 1.3611,
      "step": 58750
    },
    {
      "epoch": 0.6224824132838593,
      "grad_norm": 1.946639060974121,
      "learning_rate": 4.688863010798222e-05,
      "loss": 1.3406,
      "step": 58800
    },
    {
      "epoch": 0.6230117350638626,
      "grad_norm": 2.0168752670288086,
      "learning_rate": 4.6885983485073046e-05,
      "loss": 1.353,
      "step": 58850
    },
    {
      "epoch": 0.623541056843866,
      "grad_norm": 1.9623854160308838,
      "learning_rate": 4.688333686216388e-05,
      "loss": 1.3445,
      "step": 58900
    },
    {
      "epoch": 0.6240703786238693,
      "grad_norm": 2.2035200595855713,
      "learning_rate": 4.6880690239254714e-05,
      "loss": 1.3421,
      "step": 58950
    },
    {
      "epoch": 0.6245997004038725,
      "grad_norm": 2.0495758056640625,
      "learning_rate": 4.687804361634555e-05,
      "loss": 1.3562,
      "step": 59000
    },
    {
      "epoch": 0.6245997004038725,
      "eval_loss": 1.3022409677505493,
      "eval_runtime": 46.5403,
      "eval_samples_per_second": 3608.27,
      "eval_steps_per_second": 451.05,
      "step": 59000
    },
    {
      "epoch": 0.6251290221838758,
      "grad_norm": 2.0958921909332275,
      "learning_rate": 4.6875396993436376e-05,
      "loss": 1.3323,
      "step": 59050
    },
    {
      "epoch": 0.6256583439638791,
      "grad_norm": 2.1338117122650146,
      "learning_rate": 4.687275037052721e-05,
      "loss": 1.3555,
      "step": 59100
    },
    {
      "epoch": 0.6261876657438824,
      "grad_norm": 2.141113519668579,
      "learning_rate": 4.6870103747618044e-05,
      "loss": 1.3411,
      "step": 59150
    },
    {
      "epoch": 0.6267169875238856,
      "grad_norm": 2.172673463821411,
      "learning_rate": 4.686745712470887e-05,
      "loss": 1.3324,
      "step": 59200
    },
    {
      "epoch": 0.6272463093038889,
      "grad_norm": 1.917190670967102,
      "learning_rate": 4.6864810501799705e-05,
      "loss": 1.3296,
      "step": 59250
    },
    {
      "epoch": 0.6277756310838922,
      "grad_norm": 1.9548269510269165,
      "learning_rate": 4.686216387889053e-05,
      "loss": 1.3269,
      "step": 59300
    },
    {
      "epoch": 0.6283049528638955,
      "grad_norm": 1.932326078414917,
      "learning_rate": 4.6859517255981374e-05,
      "loss": 1.3154,
      "step": 59350
    },
    {
      "epoch": 0.6288342746438987,
      "grad_norm": 1.946290135383606,
      "learning_rate": 4.68568706330722e-05,
      "loss": 1.3441,
      "step": 59400
    },
    {
      "epoch": 0.629363596423902,
      "grad_norm": 1.9887745380401611,
      "learning_rate": 4.6854224010163035e-05,
      "loss": 1.3162,
      "step": 59450
    },
    {
      "epoch": 0.6298929182039054,
      "grad_norm": 2.0200915336608887,
      "learning_rate": 4.685157738725386e-05,
      "loss": 1.3246,
      "step": 59500
    },
    {
      "epoch": 0.6298929182039054,
      "eval_loss": 1.3017654418945312,
      "eval_runtime": 46.59,
      "eval_samples_per_second": 3604.423,
      "eval_steps_per_second": 450.569,
      "step": 59500
    },
    {
      "epoch": 0.6304222399839087,
      "grad_norm": 1.9543743133544922,
      "learning_rate": 4.68489307643447e-05,
      "loss": 1.331,
      "step": 59550
    },
    {
      "epoch": 0.6309515617639119,
      "grad_norm": 1.8814892768859863,
      "learning_rate": 4.684628414143553e-05,
      "loss": 1.3271,
      "step": 59600
    },
    {
      "epoch": 0.6314808835439152,
      "grad_norm": 2.227945566177368,
      "learning_rate": 4.6843637518526365e-05,
      "loss": 1.3329,
      "step": 59650
    },
    {
      "epoch": 0.6320102053239185,
      "grad_norm": 1.8899909257888794,
      "learning_rate": 4.684099089561719e-05,
      "loss": 1.345,
      "step": 59700
    },
    {
      "epoch": 0.6325395271039217,
      "grad_norm": 2.085451602935791,
      "learning_rate": 4.6838344272708026e-05,
      "loss": 1.3495,
      "step": 59750
    },
    {
      "epoch": 0.633068848883925,
      "grad_norm": 2.096858501434326,
      "learning_rate": 4.683569764979886e-05,
      "loss": 1.3424,
      "step": 59800
    },
    {
      "epoch": 0.6335981706639283,
      "grad_norm": 2.136147975921631,
      "learning_rate": 4.683305102688969e-05,
      "loss": 1.3391,
      "step": 59850
    },
    {
      "epoch": 0.6341274924439316,
      "grad_norm": 1.9391062259674072,
      "learning_rate": 4.683040440398052e-05,
      "loss": 1.3279,
      "step": 59900
    },
    {
      "epoch": 0.6346568142239348,
      "grad_norm": 1.9689444303512573,
      "learning_rate": 4.6827757781071356e-05,
      "loss": 1.3557,
      "step": 59950
    },
    {
      "epoch": 0.6351861360039381,
      "grad_norm": 2.1145079135894775,
      "learning_rate": 4.682511115816219e-05,
      "loss": 1.3449,
      "step": 60000
    },
    {
      "epoch": 0.6351861360039381,
      "eval_loss": 1.29965341091156,
      "eval_runtime": 46.6165,
      "eval_samples_per_second": 3602.372,
      "eval_steps_per_second": 450.313,
      "step": 60000
    },
    {
      "epoch": 0.6357154577839415,
      "grad_norm": 1.894973635673523,
      "learning_rate": 4.682246453525302e-05,
      "loss": 1.3398,
      "step": 60050
    },
    {
      "epoch": 0.6362447795639448,
      "grad_norm": 2.011312246322632,
      "learning_rate": 4.681981791234385e-05,
      "loss": 1.3315,
      "step": 60100
    },
    {
      "epoch": 0.636774101343948,
      "grad_norm": 1.9194172620773315,
      "learning_rate": 4.6817171289434685e-05,
      "loss": 1.3361,
      "step": 60150
    },
    {
      "epoch": 0.6373034231239513,
      "grad_norm": 2.184386730194092,
      "learning_rate": 4.681452466652552e-05,
      "loss": 1.3388,
      "step": 60200
    },
    {
      "epoch": 0.6378327449039546,
      "grad_norm": 1.8581287860870361,
      "learning_rate": 4.681187804361635e-05,
      "loss": 1.3351,
      "step": 60250
    },
    {
      "epoch": 0.6383620666839579,
      "grad_norm": 2.2790653705596924,
      "learning_rate": 4.680923142070718e-05,
      "loss": 1.3221,
      "step": 60300
    },
    {
      "epoch": 0.6388913884639611,
      "grad_norm": 1.9153813123703003,
      "learning_rate": 4.6806584797798015e-05,
      "loss": 1.3385,
      "step": 60350
    },
    {
      "epoch": 0.6394207102439644,
      "grad_norm": 1.9888490438461304,
      "learning_rate": 4.680393817488884e-05,
      "loss": 1.3298,
      "step": 60400
    },
    {
      "epoch": 0.6399500320239677,
      "grad_norm": 1.9566376209259033,
      "learning_rate": 4.6801291551979676e-05,
      "loss": 1.3322,
      "step": 60450
    },
    {
      "epoch": 0.6404793538039709,
      "grad_norm": 1.9299232959747314,
      "learning_rate": 4.6798644929070504e-05,
      "loss": 1.3286,
      "step": 60500
    },
    {
      "epoch": 0.6404793538039709,
      "eval_loss": 1.297846794128418,
      "eval_runtime": 46.5625,
      "eval_samples_per_second": 3606.553,
      "eval_steps_per_second": 450.835,
      "step": 60500
    },
    {
      "epoch": 0.6410086755839742,
      "grad_norm": 1.9682209491729736,
      "learning_rate": 4.6795998306161345e-05,
      "loss": 1.3465,
      "step": 60550
    },
    {
      "epoch": 0.6415379973639775,
      "grad_norm": 2.13077449798584,
      "learning_rate": 4.679335168325217e-05,
      "loss": 1.3336,
      "step": 60600
    },
    {
      "epoch": 0.6420673191439809,
      "grad_norm": 1.9925696849822998,
      "learning_rate": 4.6790705060343006e-05,
      "loss": 1.338,
      "step": 60650
    },
    {
      "epoch": 0.642596640923984,
      "grad_norm": 1.9321892261505127,
      "learning_rate": 4.6788058437433833e-05,
      "loss": 1.3293,
      "step": 60700
    },
    {
      "epoch": 0.6431259627039874,
      "grad_norm": 1.7996158599853516,
      "learning_rate": 4.6785411814524674e-05,
      "loss": 1.324,
      "step": 60750
    },
    {
      "epoch": 0.6436552844839907,
      "grad_norm": 1.9602558612823486,
      "learning_rate": 4.67827651916155e-05,
      "loss": 1.3454,
      "step": 60800
    },
    {
      "epoch": 0.644184606263994,
      "grad_norm": 2.1396255493164062,
      "learning_rate": 4.6780118568706336e-05,
      "loss": 1.3176,
      "step": 60850
    },
    {
      "epoch": 0.6447139280439972,
      "grad_norm": 2.0690040588378906,
      "learning_rate": 4.677747194579716e-05,
      "loss": 1.3171,
      "step": 60900
    },
    {
      "epoch": 0.6452432498240005,
      "grad_norm": 2.182114362716675,
      "learning_rate": 4.6774825322888e-05,
      "loss": 1.3249,
      "step": 60950
    },
    {
      "epoch": 0.6457725716040038,
      "grad_norm": 2.148744583129883,
      "learning_rate": 4.677217869997883e-05,
      "loss": 1.3312,
      "step": 61000
    },
    {
      "epoch": 0.6457725716040038,
      "eval_loss": 1.2923017740249634,
      "eval_runtime": 46.7413,
      "eval_samples_per_second": 3592.753,
      "eval_steps_per_second": 449.11,
      "step": 61000
    },
    {
      "epoch": 0.6463018933840071,
      "grad_norm": 1.9207141399383545,
      "learning_rate": 4.676953207706966e-05,
      "loss": 1.3256,
      "step": 61050
    },
    {
      "epoch": 0.6468312151640103,
      "grad_norm": 2.0125844478607178,
      "learning_rate": 4.676688545416049e-05,
      "loss": 1.3007,
      "step": 61100
    },
    {
      "epoch": 0.6473605369440136,
      "grad_norm": 1.8589863777160645,
      "learning_rate": 4.676423883125133e-05,
      "loss": 1.3381,
      "step": 61150
    },
    {
      "epoch": 0.6478898587240169,
      "grad_norm": 2.3568053245544434,
      "learning_rate": 4.676159220834216e-05,
      "loss": 1.3182,
      "step": 61200
    },
    {
      "epoch": 0.6484191805040203,
      "grad_norm": 2.052492141723633,
      "learning_rate": 4.675894558543299e-05,
      "loss": 1.3245,
      "step": 61250
    },
    {
      "epoch": 0.6489485022840235,
      "grad_norm": 2.3182690143585205,
      "learning_rate": 4.675629896252382e-05,
      "loss": 1.3419,
      "step": 61300
    },
    {
      "epoch": 0.6494778240640268,
      "grad_norm": 1.9961957931518555,
      "learning_rate": 4.6753652339614656e-05,
      "loss": 1.3356,
      "step": 61350
    },
    {
      "epoch": 0.6500071458440301,
      "grad_norm": 2.0780465602874756,
      "learning_rate": 4.675100571670549e-05,
      "loss": 1.3412,
      "step": 61400
    },
    {
      "epoch": 0.6505364676240333,
      "grad_norm": 1.9721381664276123,
      "learning_rate": 4.674835909379632e-05,
      "loss": 1.3396,
      "step": 61450
    },
    {
      "epoch": 0.6510657894040366,
      "grad_norm": 1.9482684135437012,
      "learning_rate": 4.674571247088715e-05,
      "loss": 1.3453,
      "step": 61500
    },
    {
      "epoch": 0.6510657894040366,
      "eval_loss": 1.292705774307251,
      "eval_runtime": 46.6087,
      "eval_samples_per_second": 3602.972,
      "eval_steps_per_second": 450.388,
      "step": 61500
    },
    {
      "epoch": 0.6515951111840399,
      "grad_norm": 2.03975248336792,
      "learning_rate": 4.6743065847977986e-05,
      "loss": 1.3334,
      "step": 61550
    },
    {
      "epoch": 0.6521244329640432,
      "grad_norm": 1.939509630203247,
      "learning_rate": 4.674041922506881e-05,
      "loss": 1.3267,
      "step": 61600
    },
    {
      "epoch": 0.6526537547440464,
      "grad_norm": 1.9451587200164795,
      "learning_rate": 4.673777260215965e-05,
      "loss": 1.328,
      "step": 61650
    },
    {
      "epoch": 0.6531830765240497,
      "grad_norm": 2.259533166885376,
      "learning_rate": 4.6735125979250475e-05,
      "loss": 1.3305,
      "step": 61700
    },
    {
      "epoch": 0.653712398304053,
      "grad_norm": 2.0366315841674805,
      "learning_rate": 4.6732479356341316e-05,
      "loss": 1.3304,
      "step": 61750
    },
    {
      "epoch": 0.6542417200840563,
      "grad_norm": 2.128296375274658,
      "learning_rate": 4.672983273343214e-05,
      "loss": 1.3203,
      "step": 61800
    },
    {
      "epoch": 0.6547710418640595,
      "grad_norm": 2.2238845825195312,
      "learning_rate": 4.672718611052298e-05,
      "loss": 1.3208,
      "step": 61850
    },
    {
      "epoch": 0.6553003636440629,
      "grad_norm": 2.009888172149658,
      "learning_rate": 4.6724539487613804e-05,
      "loss": 1.3337,
      "step": 61900
    },
    {
      "epoch": 0.6558296854240662,
      "grad_norm": 2.053725242614746,
      "learning_rate": 4.672189286470464e-05,
      "loss": 1.3311,
      "step": 61950
    },
    {
      "epoch": 0.6563590072040695,
      "grad_norm": 2.043497323989868,
      "learning_rate": 4.671924624179547e-05,
      "loss": 1.329,
      "step": 62000
    },
    {
      "epoch": 0.6563590072040695,
      "eval_loss": 1.28966224193573,
      "eval_runtime": 46.6021,
      "eval_samples_per_second": 3603.483,
      "eval_steps_per_second": 450.451,
      "step": 62000
    },
    {
      "epoch": 0.6568883289840727,
      "grad_norm": 1.7725085020065308,
      "learning_rate": 4.67165996188863e-05,
      "loss": 1.3211,
      "step": 62050
    },
    {
      "epoch": 0.657417650764076,
      "grad_norm": 2.218250036239624,
      "learning_rate": 4.6713952995977134e-05,
      "loss": 1.3102,
      "step": 62100
    },
    {
      "epoch": 0.6579469725440793,
      "grad_norm": 1.9049139022827148,
      "learning_rate": 4.671130637306797e-05,
      "loss": 1.3268,
      "step": 62150
    },
    {
      "epoch": 0.6584762943240825,
      "grad_norm": 2.002854108810425,
      "learning_rate": 4.67086597501588e-05,
      "loss": 1.3265,
      "step": 62200
    },
    {
      "epoch": 0.6590056161040858,
      "grad_norm": 2.1508443355560303,
      "learning_rate": 4.670601312724963e-05,
      "loss": 1.3048,
      "step": 62250
    },
    {
      "epoch": 0.6595349378840891,
      "grad_norm": 2.114231824874878,
      "learning_rate": 4.6703366504340464e-05,
      "loss": 1.3348,
      "step": 62300
    },
    {
      "epoch": 0.6600642596640924,
      "grad_norm": 2.052090883255005,
      "learning_rate": 4.67007198814313e-05,
      "loss": 1.3324,
      "step": 62350
    },
    {
      "epoch": 0.6605935814440956,
      "grad_norm": 1.9355051517486572,
      "learning_rate": 4.669807325852213e-05,
      "loss": 1.3255,
      "step": 62400
    },
    {
      "epoch": 0.661122903224099,
      "grad_norm": 2.091514825820923,
      "learning_rate": 4.669542663561296e-05,
      "loss": 1.3181,
      "step": 62450
    },
    {
      "epoch": 0.6616522250041023,
      "grad_norm": 2.06461501121521,
      "learning_rate": 4.669278001270379e-05,
      "loss": 1.3234,
      "step": 62500
    },
    {
      "epoch": 0.6616522250041023,
      "eval_loss": 1.285779595375061,
      "eval_runtime": 46.726,
      "eval_samples_per_second": 3593.933,
      "eval_steps_per_second": 449.258,
      "step": 62500
    },
    {
      "epoch": 0.6621815467841056,
      "grad_norm": 2.191005229949951,
      "learning_rate": 4.669013338979463e-05,
      "loss": 1.3016,
      "step": 62550
    },
    {
      "epoch": 0.6627108685641088,
      "grad_norm": 1.9949191808700562,
      "learning_rate": 4.6687486766885455e-05,
      "loss": 1.3357,
      "step": 62600
    },
    {
      "epoch": 0.6632401903441121,
      "grad_norm": 2.239952564239502,
      "learning_rate": 4.668484014397629e-05,
      "loss": 1.3098,
      "step": 62650
    },
    {
      "epoch": 0.6637695121241154,
      "grad_norm": 2.0967397689819336,
      "learning_rate": 4.6682246453525303e-05,
      "loss": 1.3464,
      "step": 62700
    },
    {
      "epoch": 0.6642988339041187,
      "grad_norm": 2.0708203315734863,
      "learning_rate": 4.667959983061614e-05,
      "loss": 1.3079,
      "step": 62750
    },
    {
      "epoch": 0.6648281556841219,
      "grad_norm": 2.00439190864563,
      "learning_rate": 4.667695320770697e-05,
      "loss": 1.3463,
      "step": 62800
    },
    {
      "epoch": 0.6653574774641252,
      "grad_norm": 2.044684410095215,
      "learning_rate": 4.66743065847978e-05,
      "loss": 1.3146,
      "step": 62850
    },
    {
      "epoch": 0.6658867992441285,
      "grad_norm": 1.9821248054504395,
      "learning_rate": 4.667165996188863e-05,
      "loss": 1.3321,
      "step": 62900
    },
    {
      "epoch": 0.6664161210241317,
      "grad_norm": 2.046246290206909,
      "learning_rate": 4.666901333897947e-05,
      "loss": 1.3197,
      "step": 62950
    },
    {
      "epoch": 0.666945442804135,
      "grad_norm": 2.0542523860931396,
      "learning_rate": 4.6666366716070295e-05,
      "loss": 1.3192,
      "step": 63000
    },
    {
      "epoch": 0.666945442804135,
      "eval_loss": 1.2838574647903442,
      "eval_runtime": 46.5341,
      "eval_samples_per_second": 3608.749,
      "eval_steps_per_second": 451.11,
      "step": 63000
    },
    {
      "epoch": 0.6674747645841383,
      "grad_norm": 2.0023229122161865,
      "learning_rate": 4.666372009316113e-05,
      "loss": 1.3094,
      "step": 63050
    },
    {
      "epoch": 0.6680040863641417,
      "grad_norm": 2.025327444076538,
      "learning_rate": 4.6661073470251956e-05,
      "loss": 1.3245,
      "step": 63100
    },
    {
      "epoch": 0.6685334081441449,
      "grad_norm": 1.9630639553070068,
      "learning_rate": 4.66584268473428e-05,
      "loss": 1.3229,
      "step": 63150
    },
    {
      "epoch": 0.6690627299241482,
      "grad_norm": 2.027946710586548,
      "learning_rate": 4.6655780224433624e-05,
      "loss": 1.3238,
      "step": 63200
    },
    {
      "epoch": 0.6695920517041515,
      "grad_norm": 2.170273780822754,
      "learning_rate": 4.665313360152446e-05,
      "loss": 1.3104,
      "step": 63250
    },
    {
      "epoch": 0.6701213734841548,
      "grad_norm": 2.3437750339508057,
      "learning_rate": 4.6650486978615286e-05,
      "loss": 1.3446,
      "step": 63300
    },
    {
      "epoch": 0.670650695264158,
      "grad_norm": 2.0286412239074707,
      "learning_rate": 4.6647840355706126e-05,
      "loss": 1.3228,
      "step": 63350
    },
    {
      "epoch": 0.6711800170441613,
      "grad_norm": 2.0235652923583984,
      "learning_rate": 4.6645193732796954e-05,
      "loss": 1.3388,
      "step": 63400
    },
    {
      "epoch": 0.6717093388241646,
      "grad_norm": 2.013714075088501,
      "learning_rate": 4.664254710988779e-05,
      "loss": 1.3122,
      "step": 63450
    },
    {
      "epoch": 0.6722386606041679,
      "grad_norm": 2.120685338973999,
      "learning_rate": 4.6639900486978615e-05,
      "loss": 1.3122,
      "step": 63500
    },
    {
      "epoch": 0.6722386606041679,
      "eval_loss": 1.2818658351898193,
      "eval_runtime": 46.5403,
      "eval_samples_per_second": 3608.274,
      "eval_steps_per_second": 451.05,
      "step": 63500
    },
    {
      "epoch": 0.6727679823841711,
      "grad_norm": 2.0496649742126465,
      "learning_rate": 4.663725386406945e-05,
      "loss": 1.3486,
      "step": 63550
    },
    {
      "epoch": 0.6732973041641744,
      "grad_norm": 2.1460134983062744,
      "learning_rate": 4.663460724116028e-05,
      "loss": 1.3172,
      "step": 63600
    },
    {
      "epoch": 0.6738266259441777,
      "grad_norm": 2.2326977252960205,
      "learning_rate": 4.663196061825111e-05,
      "loss": 1.3187,
      "step": 63650
    },
    {
      "epoch": 0.6743559477241811,
      "grad_norm": 2.077749490737915,
      "learning_rate": 4.6629313995341945e-05,
      "loss": 1.3117,
      "step": 63700
    },
    {
      "epoch": 0.6748852695041843,
      "grad_norm": 1.9574406147003174,
      "learning_rate": 4.662666737243278e-05,
      "loss": 1.3291,
      "step": 63750
    },
    {
      "epoch": 0.6754145912841876,
      "grad_norm": 2.0871355533599854,
      "learning_rate": 4.662402074952361e-05,
      "loss": 1.3178,
      "step": 63800
    },
    {
      "epoch": 0.6759439130641909,
      "grad_norm": 2.090383291244507,
      "learning_rate": 4.662137412661444e-05,
      "loss": 1.3257,
      "step": 63850
    },
    {
      "epoch": 0.6764732348441941,
      "grad_norm": 1.9082329273223877,
      "learning_rate": 4.6618727503705274e-05,
      "loss": 1.3105,
      "step": 63900
    },
    {
      "epoch": 0.6770025566241974,
      "grad_norm": 2.2731261253356934,
      "learning_rate": 4.661608088079611e-05,
      "loss": 1.3112,
      "step": 63950
    },
    {
      "epoch": 0.6775318784042007,
      "grad_norm": 2.1100668907165527,
      "learning_rate": 4.661343425788694e-05,
      "loss": 1.329,
      "step": 64000
    },
    {
      "epoch": 0.6775318784042007,
      "eval_loss": 1.2806419134140015,
      "eval_runtime": 46.5866,
      "eval_samples_per_second": 3604.682,
      "eval_steps_per_second": 450.601,
      "step": 64000
    },
    {
      "epoch": 0.678061200184204,
      "grad_norm": 2.0593767166137695,
      "learning_rate": 4.661078763497777e-05,
      "loss": 1.3261,
      "step": 64050
    },
    {
      "epoch": 0.6785905219642072,
      "grad_norm": 2.004662036895752,
      "learning_rate": 4.6608141012068604e-05,
      "loss": 1.3044,
      "step": 64100
    },
    {
      "epoch": 0.6791198437442105,
      "grad_norm": 1.9805854558944702,
      "learning_rate": 4.660549438915944e-05,
      "loss": 1.3115,
      "step": 64150
    },
    {
      "epoch": 0.6796491655242138,
      "grad_norm": 2.1220879554748535,
      "learning_rate": 4.6602847766250265e-05,
      "loss": 1.3247,
      "step": 64200
    },
    {
      "epoch": 0.6801784873042171,
      "grad_norm": 2.099431037902832,
      "learning_rate": 4.66002011433411e-05,
      "loss": 1.331,
      "step": 64250
    },
    {
      "epoch": 0.6807078090842203,
      "grad_norm": 2.004580497741699,
      "learning_rate": 4.659755452043193e-05,
      "loss": 1.3114,
      "step": 64300
    },
    {
      "epoch": 0.6812371308642237,
      "grad_norm": 1.990426778793335,
      "learning_rate": 4.659490789752276e-05,
      "loss": 1.3161,
      "step": 64350
    },
    {
      "epoch": 0.681766452644227,
      "grad_norm": 1.89814031124115,
      "learning_rate": 4.6592261274613595e-05,
      "loss": 1.3252,
      "step": 64400
    },
    {
      "epoch": 0.6822957744242303,
      "grad_norm": 1.957130789756775,
      "learning_rate": 4.658961465170443e-05,
      "loss": 1.3235,
      "step": 64450
    },
    {
      "epoch": 0.6828250962042335,
      "grad_norm": 2.314115524291992,
      "learning_rate": 4.6587020961253444e-05,
      "loss": 1.3203,
      "step": 64500
    },
    {
      "epoch": 0.6828250962042335,
      "eval_loss": 1.27863609790802,
      "eval_runtime": 46.6156,
      "eval_samples_per_second": 3602.441,
      "eval_steps_per_second": 450.321,
      "step": 64500
    },
    {
      "epoch": 0.6833544179842368,
      "grad_norm": 2.106961488723755,
      "learning_rate": 4.658437433834428e-05,
      "loss": 1.322,
      "step": 64550
    },
    {
      "epoch": 0.6838837397642401,
      "grad_norm": 2.179560899734497,
      "learning_rate": 4.6581727715435105e-05,
      "loss": 1.3238,
      "step": 64600
    },
    {
      "epoch": 0.6844130615442433,
      "grad_norm": 2.28261661529541,
      "learning_rate": 4.657908109252594e-05,
      "loss": 1.3318,
      "step": 64650
    },
    {
      "epoch": 0.6849423833242466,
      "grad_norm": 2.158546209335327,
      "learning_rate": 4.657643446961677e-05,
      "loss": 1.3312,
      "step": 64700
    },
    {
      "epoch": 0.6854717051042499,
      "grad_norm": 2.0380234718322754,
      "learning_rate": 4.657378784670761e-05,
      "loss": 1.316,
      "step": 64750
    },
    {
      "epoch": 0.6860010268842532,
      "grad_norm": 2.1902968883514404,
      "learning_rate": 4.6571141223798435e-05,
      "loss": 1.3224,
      "step": 64800
    },
    {
      "epoch": 0.6865303486642564,
      "grad_norm": 2.1273012161254883,
      "learning_rate": 4.656849460088927e-05,
      "loss": 1.2985,
      "step": 64850
    },
    {
      "epoch": 0.6870596704442598,
      "grad_norm": 2.1861729621887207,
      "learning_rate": 4.6565847977980096e-05,
      "loss": 1.3109,
      "step": 64900
    },
    {
      "epoch": 0.6875889922242631,
      "grad_norm": 2.0726099014282227,
      "learning_rate": 4.656320135507093e-05,
      "loss": 1.329,
      "step": 64950
    },
    {
      "epoch": 0.6881183140042664,
      "grad_norm": 2.2513480186462402,
      "learning_rate": 4.6560554732161765e-05,
      "loss": 1.3121,
      "step": 65000
    },
    {
      "epoch": 0.6881183140042664,
      "eval_loss": 1.2810542583465576,
      "eval_runtime": 46.6082,
      "eval_samples_per_second": 3603.015,
      "eval_steps_per_second": 450.393,
      "step": 65000
    },
    {
      "epoch": 0.6886476357842696,
      "grad_norm": 2.0612385272979736,
      "learning_rate": 4.65579081092526e-05,
      "loss": 1.3164,
      "step": 65050
    },
    {
      "epoch": 0.6891769575642729,
      "grad_norm": 1.9263156652450562,
      "learning_rate": 4.6555261486343426e-05,
      "loss": 1.3042,
      "step": 65100
    },
    {
      "epoch": 0.6897062793442762,
      "grad_norm": 2.1004445552825928,
      "learning_rate": 4.655261486343426e-05,
      "loss": 1.324,
      "step": 65150
    },
    {
      "epoch": 0.6902356011242795,
      "grad_norm": 2.05840802192688,
      "learning_rate": 4.6549968240525094e-05,
      "loss": 1.3444,
      "step": 65200
    },
    {
      "epoch": 0.6907649229042827,
      "grad_norm": 2.128812551498413,
      "learning_rate": 4.654732161761592e-05,
      "loss": 1.296,
      "step": 65250
    },
    {
      "epoch": 0.691294244684286,
      "grad_norm": 1.9465678930282593,
      "learning_rate": 4.6544674994706756e-05,
      "loss": 1.2935,
      "step": 65300
    },
    {
      "epoch": 0.6918235664642893,
      "grad_norm": 2.0702128410339355,
      "learning_rate": 4.654202837179758e-05,
      "loss": 1.3071,
      "step": 65350
    },
    {
      "epoch": 0.6923528882442926,
      "grad_norm": 2.06961989402771,
      "learning_rate": 4.6539381748888424e-05,
      "loss": 1.3276,
      "step": 65400
    },
    {
      "epoch": 0.6928822100242958,
      "grad_norm": 2.107219934463501,
      "learning_rate": 4.653673512597925e-05,
      "loss": 1.2995,
      "step": 65450
    },
    {
      "epoch": 0.6934115318042992,
      "grad_norm": 2.000232219696045,
      "learning_rate": 4.6534088503070085e-05,
      "loss": 1.3199,
      "step": 65500
    },
    {
      "epoch": 0.6934115318042992,
      "eval_loss": 1.27162504196167,
      "eval_runtime": 46.5093,
      "eval_samples_per_second": 3610.674,
      "eval_steps_per_second": 451.35,
      "step": 65500
    },
    {
      "epoch": 0.6939408535843025,
      "grad_norm": 2.1449787616729736,
      "learning_rate": 4.653144188016091e-05,
      "loss": 1.3015,
      "step": 65550
    },
    {
      "epoch": 0.6944701753643057,
      "grad_norm": 2.0057055950164795,
      "learning_rate": 4.6528795257251753e-05,
      "loss": 1.3174,
      "step": 65600
    },
    {
      "epoch": 0.694999497144309,
      "grad_norm": 2.068570375442505,
      "learning_rate": 4.652614863434258e-05,
      "loss": 1.3255,
      "step": 65650
    },
    {
      "epoch": 0.6955288189243123,
      "grad_norm": 2.080003499984741,
      "learning_rate": 4.6523502011433415e-05,
      "loss": 1.3155,
      "step": 65700
    },
    {
      "epoch": 0.6960581407043156,
      "grad_norm": 2.4074370861053467,
      "learning_rate": 4.652085538852424e-05,
      "loss": 1.3147,
      "step": 65750
    },
    {
      "epoch": 0.6965874624843188,
      "grad_norm": 2.188156843185425,
      "learning_rate": 4.6518208765615076e-05,
      "loss": 1.3388,
      "step": 65800
    },
    {
      "epoch": 0.6971167842643221,
      "grad_norm": 2.2921061515808105,
      "learning_rate": 4.651556214270591e-05,
      "loss": 1.3101,
      "step": 65850
    },
    {
      "epoch": 0.6976461060443254,
      "grad_norm": 1.9780242443084717,
      "learning_rate": 4.651291551979674e-05,
      "loss": 1.2927,
      "step": 65900
    },
    {
      "epoch": 0.6981754278243287,
      "grad_norm": 2.125417470932007,
      "learning_rate": 4.651026889688757e-05,
      "loss": 1.3078,
      "step": 65950
    },
    {
      "epoch": 0.6987047496043319,
      "grad_norm": 1.9446173906326294,
      "learning_rate": 4.6507622273978406e-05,
      "loss": 1.3122,
      "step": 66000
    },
    {
      "epoch": 0.6987047496043319,
      "eval_loss": 1.2693697214126587,
      "eval_runtime": 46.6263,
      "eval_samples_per_second": 3601.614,
      "eval_steps_per_second": 450.218,
      "step": 66000
    },
    {
      "epoch": 0.6992340713843352,
      "grad_norm": 2.0841689109802246,
      "learning_rate": 4.650497565106924e-05,
      "loss": 1.3044,
      "step": 66050
    },
    {
      "epoch": 0.6997633931643386,
      "grad_norm": 2.1778345108032227,
      "learning_rate": 4.650232902816007e-05,
      "loss": 1.3079,
      "step": 66100
    },
    {
      "epoch": 0.7002927149443419,
      "grad_norm": 2.1704611778259277,
      "learning_rate": 4.64996824052509e-05,
      "loss": 1.3095,
      "step": 66150
    },
    {
      "epoch": 0.7008220367243451,
      "grad_norm": 2.2534282207489014,
      "learning_rate": 4.6497035782341736e-05,
      "loss": 1.3168,
      "step": 66200
    },
    {
      "epoch": 0.7013513585043484,
      "grad_norm": 2.3843631744384766,
      "learning_rate": 4.649438915943257e-05,
      "loss": 1.3034,
      "step": 66250
    },
    {
      "epoch": 0.7018806802843517,
      "grad_norm": 2.0510752201080322,
      "learning_rate": 4.64917425365234e-05,
      "loss": 1.298,
      "step": 66300
    },
    {
      "epoch": 0.7024100020643549,
      "grad_norm": 2.1413321495056152,
      "learning_rate": 4.648909591361423e-05,
      "loss": 1.3057,
      "step": 66350
    },
    {
      "epoch": 0.7029393238443582,
      "grad_norm": 2.104588270187378,
      "learning_rate": 4.6486449290705065e-05,
      "loss": 1.2974,
      "step": 66400
    },
    {
      "epoch": 0.7034686456243615,
      "grad_norm": 2.2183949947357178,
      "learning_rate": 4.648380266779589e-05,
      "loss": 1.3077,
      "step": 66450
    },
    {
      "epoch": 0.7039979674043648,
      "grad_norm": 2.092729330062866,
      "learning_rate": 4.6481156044886727e-05,
      "loss": 1.3282,
      "step": 66500
    },
    {
      "epoch": 0.7039979674043648,
      "eval_loss": 1.2703912258148193,
      "eval_runtime": 46.69,
      "eval_samples_per_second": 3596.7,
      "eval_steps_per_second": 449.604,
      "step": 66500
    },
    {
      "epoch": 0.704527289184368,
      "grad_norm": 2.2446889877319336,
      "learning_rate": 4.6478509421977554e-05,
      "loss": 1.31,
      "step": 66550
    },
    {
      "epoch": 0.7050566109643713,
      "grad_norm": 2.07372784614563,
      "learning_rate": 4.6475862799068395e-05,
      "loss": 1.3,
      "step": 66600
    },
    {
      "epoch": 0.7055859327443746,
      "grad_norm": 2.105391502380371,
      "learning_rate": 4.647321617615922e-05,
      "loss": 1.2951,
      "step": 66650
    },
    {
      "epoch": 0.706115254524378,
      "grad_norm": 1.938279151916504,
      "learning_rate": 4.6470569553250056e-05,
      "loss": 1.3052,
      "step": 66700
    },
    {
      "epoch": 0.7066445763043812,
      "grad_norm": 1.9149500131607056,
      "learning_rate": 4.6467922930340884e-05,
      "loss": 1.3293,
      "step": 66750
    },
    {
      "epoch": 0.7071738980843845,
      "grad_norm": 2.187624216079712,
      "learning_rate": 4.646527630743172e-05,
      "loss": 1.2845,
      "step": 66800
    },
    {
      "epoch": 0.7077032198643878,
      "grad_norm": 1.939836859703064,
      "learning_rate": 4.646262968452255e-05,
      "loss": 1.3216,
      "step": 66850
    },
    {
      "epoch": 0.7082325416443911,
      "grad_norm": 2.0140368938446045,
      "learning_rate": 4.645998306161338e-05,
      "loss": 1.2907,
      "step": 66900
    },
    {
      "epoch": 0.7087618634243943,
      "grad_norm": 1.984518051147461,
      "learning_rate": 4.645733643870421e-05,
      "loss": 1.2938,
      "step": 66950
    },
    {
      "epoch": 0.7092911852043976,
      "grad_norm": 1.9586994647979736,
      "learning_rate": 4.645468981579505e-05,
      "loss": 1.3041,
      "step": 67000
    },
    {
      "epoch": 0.7092911852043976,
      "eval_loss": 1.2667440176010132,
      "eval_runtime": 46.8705,
      "eval_samples_per_second": 3582.848,
      "eval_steps_per_second": 447.872,
      "step": 67000
    },
    {
      "epoch": 0.7098205069844009,
      "grad_norm": 2.264721632003784,
      "learning_rate": 4.645204319288588e-05,
      "loss": 1.3298,
      "step": 67050
    },
    {
      "epoch": 0.7103498287644042,
      "grad_norm": 2.3297033309936523,
      "learning_rate": 4.644939656997671e-05,
      "loss": 1.2882,
      "step": 67100
    },
    {
      "epoch": 0.7108791505444074,
      "grad_norm": 2.043626308441162,
      "learning_rate": 4.644674994706754e-05,
      "loss": 1.3022,
      "step": 67150
    },
    {
      "epoch": 0.7114084723244107,
      "grad_norm": 2.2946698665618896,
      "learning_rate": 4.644410332415838e-05,
      "loss": 1.3037,
      "step": 67200
    },
    {
      "epoch": 0.711937794104414,
      "grad_norm": 2.1615681648254395,
      "learning_rate": 4.644145670124921e-05,
      "loss": 1.3013,
      "step": 67250
    },
    {
      "epoch": 0.7124671158844172,
      "grad_norm": 2.1485114097595215,
      "learning_rate": 4.643881007834004e-05,
      "loss": 1.3098,
      "step": 67300
    },
    {
      "epoch": 0.7129964376644206,
      "grad_norm": 2.3273301124572754,
      "learning_rate": 4.643616345543087e-05,
      "loss": 1.3146,
      "step": 67350
    },
    {
      "epoch": 0.7135257594444239,
      "grad_norm": 2.0877137184143066,
      "learning_rate": 4.6433516832521707e-05,
      "loss": 1.306,
      "step": 67400
    },
    {
      "epoch": 0.7140550812244272,
      "grad_norm": 1.9985685348510742,
      "learning_rate": 4.6430870209612534e-05,
      "loss": 1.3035,
      "step": 67450
    },
    {
      "epoch": 0.7145844030044304,
      "grad_norm": 1.9644140005111694,
      "learning_rate": 4.642822358670337e-05,
      "loss": 1.2937,
      "step": 67500
    },
    {
      "epoch": 0.7145844030044304,
      "eval_loss": 1.2632278203964233,
      "eval_runtime": 46.5234,
      "eval_samples_per_second": 3609.584,
      "eval_steps_per_second": 451.214,
      "step": 67500
    },
    {
      "epoch": 0.7151137247844337,
      "grad_norm": 2.212783098220825,
      "learning_rate": 4.6425576963794195e-05,
      "loss": 1.3107,
      "step": 67550
    },
    {
      "epoch": 0.715643046564437,
      "grad_norm": 2.078738212585449,
      "learning_rate": 4.6422930340885036e-05,
      "loss": 1.301,
      "step": 67600
    },
    {
      "epoch": 0.7161723683444403,
      "grad_norm": 2.0507771968841553,
      "learning_rate": 4.6420283717975863e-05,
      "loss": 1.3084,
      "step": 67650
    },
    {
      "epoch": 0.7167016901244435,
      "grad_norm": 2.1704375743865967,
      "learning_rate": 4.64176370950667e-05,
      "loss": 1.2906,
      "step": 67700
    },
    {
      "epoch": 0.7172310119044468,
      "grad_norm": 2.006845712661743,
      "learning_rate": 4.6414990472157525e-05,
      "loss": 1.2987,
      "step": 67750
    },
    {
      "epoch": 0.7177603336844501,
      "grad_norm": 2.1369194984436035,
      "learning_rate": 4.6412343849248366e-05,
      "loss": 1.2957,
      "step": 67800
    },
    {
      "epoch": 0.7182896554644534,
      "grad_norm": 2.327877998352051,
      "learning_rate": 4.640969722633919e-05,
      "loss": 1.3103,
      "step": 67850
    },
    {
      "epoch": 0.7188189772444566,
      "grad_norm": 2.026215076446533,
      "learning_rate": 4.640705060343003e-05,
      "loss": 1.2856,
      "step": 67900
    },
    {
      "epoch": 0.71934829902446,
      "grad_norm": 2.177625894546509,
      "learning_rate": 4.6404403980520854e-05,
      "loss": 1.3039,
      "step": 67950
    },
    {
      "epoch": 0.7198776208044633,
      "grad_norm": 2.193361759185791,
      "learning_rate": 4.640175735761169e-05,
      "loss": 1.3099,
      "step": 68000
    },
    {
      "epoch": 0.7198776208044633,
      "eval_loss": 1.2602523565292358,
      "eval_runtime": 46.5541,
      "eval_samples_per_second": 3607.204,
      "eval_steps_per_second": 450.917,
      "step": 68000
    },
    {
      "epoch": 0.7204069425844665,
      "grad_norm": 2.1515872478485107,
      "learning_rate": 4.639911073470252e-05,
      "loss": 1.3029,
      "step": 68050
    },
    {
      "epoch": 0.7209362643644698,
      "grad_norm": 2.1388394832611084,
      "learning_rate": 4.639646411179335e-05,
      "loss": 1.3118,
      "step": 68100
    },
    {
      "epoch": 0.7214655861444731,
      "grad_norm": 2.0222065448760986,
      "learning_rate": 4.6393817488884184e-05,
      "loss": 1.3143,
      "step": 68150
    },
    {
      "epoch": 0.7219949079244764,
      "grad_norm": 2.1488900184631348,
      "learning_rate": 4.639117086597502e-05,
      "loss": 1.3059,
      "step": 68200
    },
    {
      "epoch": 0.7225242297044796,
      "grad_norm": 2.1086113452911377,
      "learning_rate": 4.638852424306585e-05,
      "loss": 1.3094,
      "step": 68250
    },
    {
      "epoch": 0.7230535514844829,
      "grad_norm": 2.082259178161621,
      "learning_rate": 4.638587762015668e-05,
      "loss": 1.2966,
      "step": 68300
    },
    {
      "epoch": 0.7235828732644862,
      "grad_norm": 2.224806785583496,
      "learning_rate": 4.6383230997247514e-05,
      "loss": 1.3115,
      "step": 68350
    },
    {
      "epoch": 0.7241121950444895,
      "grad_norm": 2.082982301712036,
      "learning_rate": 4.638058437433835e-05,
      "loss": 1.3219,
      "step": 68400
    },
    {
      "epoch": 0.7246415168244927,
      "grad_norm": 2.163336753845215,
      "learning_rate": 4.637793775142918e-05,
      "loss": 1.2841,
      "step": 68450
    },
    {
      "epoch": 0.725170838604496,
      "grad_norm": 2.2973833084106445,
      "learning_rate": 4.637534406097819e-05,
      "loss": 1.3088,
      "step": 68500
    },
    {
      "epoch": 0.725170838604496,
      "eval_loss": 1.259179711341858,
      "eval_runtime": 46.5688,
      "eval_samples_per_second": 3606.064,
      "eval_steps_per_second": 450.774,
      "step": 68500
    },
    {
      "epoch": 0.7257001603844994,
      "grad_norm": 2.202617645263672,
      "learning_rate": 4.6372697438069024e-05,
      "loss": 1.308,
      "step": 68550
    },
    {
      "epoch": 0.7262294821645027,
      "grad_norm": 2.0266642570495605,
      "learning_rate": 4.637005081515986e-05,
      "loss": 1.3135,
      "step": 68600
    },
    {
      "epoch": 0.7267588039445059,
      "grad_norm": 2.192906379699707,
      "learning_rate": 4.636740419225069e-05,
      "loss": 1.3057,
      "step": 68650
    },
    {
      "epoch": 0.7272881257245092,
      "grad_norm": 2.1517481803894043,
      "learning_rate": 4.636475756934152e-05,
      "loss": 1.3012,
      "step": 68700
    },
    {
      "epoch": 0.7278174475045125,
      "grad_norm": 2.04215669631958,
      "learning_rate": 4.6362110946432354e-05,
      "loss": 1.3212,
      "step": 68750
    },
    {
      "epoch": 0.7283467692845158,
      "grad_norm": 2.2100746631622314,
      "learning_rate": 4.635946432352319e-05,
      "loss": 1.3325,
      "step": 68800
    },
    {
      "epoch": 0.728876091064519,
      "grad_norm": 2.1206283569335938,
      "learning_rate": 4.635681770061402e-05,
      "loss": 1.2996,
      "step": 68850
    },
    {
      "epoch": 0.7294054128445223,
      "grad_norm": 2.42423677444458,
      "learning_rate": 4.635417107770485e-05,
      "loss": 1.2992,
      "step": 68900
    },
    {
      "epoch": 0.7299347346245256,
      "grad_norm": 2.157083034515381,
      "learning_rate": 4.635152445479568e-05,
      "loss": 1.2873,
      "step": 68950
    },
    {
      "epoch": 0.7304640564045288,
      "grad_norm": 2.2105469703674316,
      "learning_rate": 4.634887783188652e-05,
      "loss": 1.3044,
      "step": 69000
    },
    {
      "epoch": 0.7304640564045288,
      "eval_loss": 1.2543636560440063,
      "eval_runtime": 46.586,
      "eval_samples_per_second": 3604.732,
      "eval_steps_per_second": 450.608,
      "step": 69000
    },
    {
      "epoch": 0.7309933781845321,
      "grad_norm": 2.0066680908203125,
      "learning_rate": 4.6346231208977345e-05,
      "loss": 1.2968,
      "step": 69050
    },
    {
      "epoch": 0.7315226999645354,
      "grad_norm": 2.0837655067443848,
      "learning_rate": 4.634358458606818e-05,
      "loss": 1.3115,
      "step": 69100
    },
    {
      "epoch": 0.7320520217445388,
      "grad_norm": 2.2337327003479004,
      "learning_rate": 4.6340937963159006e-05,
      "loss": 1.2909,
      "step": 69150
    },
    {
      "epoch": 0.732581343524542,
      "grad_norm": 2.2787389755249023,
      "learning_rate": 4.633829134024985e-05,
      "loss": 1.3032,
      "step": 69200
    },
    {
      "epoch": 0.7331106653045453,
      "grad_norm": 2.1126461029052734,
      "learning_rate": 4.6335644717340674e-05,
      "loss": 1.3049,
      "step": 69250
    },
    {
      "epoch": 0.7336399870845486,
      "grad_norm": 2.1088273525238037,
      "learning_rate": 4.633299809443151e-05,
      "loss": 1.2944,
      "step": 69300
    },
    {
      "epoch": 0.7341693088645519,
      "grad_norm": 2.162731647491455,
      "learning_rate": 4.6330351471522336e-05,
      "loss": 1.2803,
      "step": 69350
    },
    {
      "epoch": 0.7346986306445551,
      "grad_norm": 2.325575828552246,
      "learning_rate": 4.6327704848613177e-05,
      "loss": 1.2932,
      "step": 69400
    },
    {
      "epoch": 0.7352279524245584,
      "grad_norm": 2.371183395385742,
      "learning_rate": 4.6325058225704004e-05,
      "loss": 1.2894,
      "step": 69450
    },
    {
      "epoch": 0.7357572742045617,
      "grad_norm": 2.3891730308532715,
      "learning_rate": 4.632241160279484e-05,
      "loss": 1.3046,
      "step": 69500
    },
    {
      "epoch": 0.7357572742045617,
      "eval_loss": 1.2515926361083984,
      "eval_runtime": 46.7208,
      "eval_samples_per_second": 3594.331,
      "eval_steps_per_second": 449.307,
      "step": 69500
    },
    {
      "epoch": 0.736286595984565,
      "grad_norm": 2.176347255706787,
      "learning_rate": 4.6319764979885665e-05,
      "loss": 1.2942,
      "step": 69550
    },
    {
      "epoch": 0.7368159177645682,
      "grad_norm": 2.0400314331054688,
      "learning_rate": 4.63171183569765e-05,
      "loss": 1.3038,
      "step": 69600
    },
    {
      "epoch": 0.7373452395445715,
      "grad_norm": 2.3472185134887695,
      "learning_rate": 4.6314471734067334e-05,
      "loss": 1.2787,
      "step": 69650
    },
    {
      "epoch": 0.7378745613245749,
      "grad_norm": 2.1965489387512207,
      "learning_rate": 4.631182511115816e-05,
      "loss": 1.3237,
      "step": 69700
    },
    {
      "epoch": 0.738403883104578,
      "grad_norm": 2.03085994720459,
      "learning_rate": 4.6309178488248995e-05,
      "loss": 1.2951,
      "step": 69750
    },
    {
      "epoch": 0.7389332048845814,
      "grad_norm": 2.251049757003784,
      "learning_rate": 4.630653186533983e-05,
      "loss": 1.2907,
      "step": 69800
    },
    {
      "epoch": 0.7394625266645847,
      "grad_norm": 2.2636470794677734,
      "learning_rate": 4.630388524243066e-05,
      "loss": 1.2888,
      "step": 69850
    },
    {
      "epoch": 0.739991848444588,
      "grad_norm": 2.1575276851654053,
      "learning_rate": 4.630123861952149e-05,
      "loss": 1.3053,
      "step": 69900
    },
    {
      "epoch": 0.7405211702245912,
      "grad_norm": 2.3544437885284424,
      "learning_rate": 4.6298591996612325e-05,
      "loss": 1.2866,
      "step": 69950
    },
    {
      "epoch": 0.7410504920045945,
      "grad_norm": 2.126046657562256,
      "learning_rate": 4.629594537370316e-05,
      "loss": 1.2856,
      "step": 70000
    },
    {
      "epoch": 0.7410504920045945,
      "eval_loss": 1.2512882947921753,
      "eval_runtime": 46.8,
      "eval_samples_per_second": 3588.247,
      "eval_steps_per_second": 448.547,
      "step": 70000
    },
    {
      "epoch": 0.7415798137845978,
      "grad_norm": 2.095520257949829,
      "learning_rate": 4.629329875079399e-05,
      "loss": 1.2828,
      "step": 70050
    },
    {
      "epoch": 0.7421091355646011,
      "grad_norm": 2.2112789154052734,
      "learning_rate": 4.629065212788482e-05,
      "loss": 1.2997,
      "step": 70100
    },
    {
      "epoch": 0.7426384573446043,
      "grad_norm": 2.3447086811065674,
      "learning_rate": 4.6288005504975654e-05,
      "loss": 1.3151,
      "step": 70150
    },
    {
      "epoch": 0.7431677791246076,
      "grad_norm": 2.314181327819824,
      "learning_rate": 4.628535888206649e-05,
      "loss": 1.2776,
      "step": 70200
    },
    {
      "epoch": 0.7436971009046109,
      "grad_norm": 1.8781054019927979,
      "learning_rate": 4.6282712259157316e-05,
      "loss": 1.3074,
      "step": 70250
    },
    {
      "epoch": 0.7442264226846143,
      "grad_norm": 2.2458958625793457,
      "learning_rate": 4.628006563624815e-05,
      "loss": 1.3038,
      "step": 70300
    },
    {
      "epoch": 0.7447557444646175,
      "grad_norm": 2.4926295280456543,
      "learning_rate": 4.627741901333898e-05,
      "loss": 1.2699,
      "step": 70350
    },
    {
      "epoch": 0.7452850662446208,
      "grad_norm": 2.184852123260498,
      "learning_rate": 4.627477239042982e-05,
      "loss": 1.3131,
      "step": 70400
    },
    {
      "epoch": 0.7458143880246241,
      "grad_norm": 2.0050089359283447,
      "learning_rate": 4.6272125767520645e-05,
      "loss": 1.2914,
      "step": 70450
    },
    {
      "epoch": 0.7463437098046273,
      "grad_norm": 2.233103036880493,
      "learning_rate": 4.626953207706966e-05,
      "loss": 1.2903,
      "step": 70500
    },
    {
      "epoch": 0.7463437098046273,
      "eval_loss": 1.2498635053634644,
      "eval_runtime": 46.7261,
      "eval_samples_per_second": 3593.923,
      "eval_steps_per_second": 449.256,
      "step": 70500
    },
    {
      "epoch": 0.7468730315846306,
      "grad_norm": 2.29351544380188,
      "learning_rate": 4.6266885454160494e-05,
      "loss": 1.2938,
      "step": 70550
    },
    {
      "epoch": 0.7474023533646339,
      "grad_norm": 2.1009278297424316,
      "learning_rate": 4.626423883125133e-05,
      "loss": 1.2989,
      "step": 70600
    },
    {
      "epoch": 0.7479316751446372,
      "grad_norm": 2.2433602809906006,
      "learning_rate": 4.6261592208342155e-05,
      "loss": 1.2869,
      "step": 70650
    },
    {
      "epoch": 0.7484609969246404,
      "grad_norm": 2.3698782920837402,
      "learning_rate": 4.625894558543299e-05,
      "loss": 1.2817,
      "step": 70700
    },
    {
      "epoch": 0.7489903187046437,
      "grad_norm": 2.3539650440216064,
      "learning_rate": 4.625629896252382e-05,
      "loss": 1.2897,
      "step": 70750
    },
    {
      "epoch": 0.749519640484647,
      "grad_norm": 2.1335537433624268,
      "learning_rate": 4.625365233961466e-05,
      "loss": 1.2899,
      "step": 70800
    },
    {
      "epoch": 0.7500489622646503,
      "grad_norm": 2.29268479347229,
      "learning_rate": 4.625105864916367e-05,
      "loss": 1.2959,
      "step": 70850
    },
    {
      "epoch": 0.7505782840446535,
      "grad_norm": 2.2191691398620605,
      "learning_rate": 4.62484120262545e-05,
      "loss": 1.2824,
      "step": 70900
    },
    {
      "epoch": 0.7511076058246569,
      "grad_norm": 2.3772101402282715,
      "learning_rate": 4.6245765403345334e-05,
      "loss": 1.3045,
      "step": 70950
    },
    {
      "epoch": 0.7516369276046602,
      "grad_norm": 2.351205348968506,
      "learning_rate": 4.624311878043617e-05,
      "loss": 1.2823,
      "step": 71000
    },
    {
      "epoch": 0.7516369276046602,
      "eval_loss": 1.248043179512024,
      "eval_runtime": 46.5666,
      "eval_samples_per_second": 3606.234,
      "eval_steps_per_second": 450.795,
      "step": 71000
    },
    {
      "epoch": 0.7521662493846635,
      "grad_norm": 2.4220077991485596,
      "learning_rate": 4.6240472157526995e-05,
      "loss": 1.2958,
      "step": 71050
    },
    {
      "epoch": 0.7526955711646667,
      "grad_norm": 2.2897233963012695,
      "learning_rate": 4.623782553461783e-05,
      "loss": 1.2912,
      "step": 71100
    },
    {
      "epoch": 0.75322489294467,
      "grad_norm": 2.204171657562256,
      "learning_rate": 4.623517891170866e-05,
      "loss": 1.2889,
      "step": 71150
    },
    {
      "epoch": 0.7537542147246733,
      "grad_norm": 2.2298803329467773,
      "learning_rate": 4.62325322887995e-05,
      "loss": 1.2906,
      "step": 71200
    },
    {
      "epoch": 0.7542835365046766,
      "grad_norm": 2.172295093536377,
      "learning_rate": 4.6229885665890325e-05,
      "loss": 1.2599,
      "step": 71250
    },
    {
      "epoch": 0.7548128582846798,
      "grad_norm": 2.135214328765869,
      "learning_rate": 4.622723904298116e-05,
      "loss": 1.2808,
      "step": 71300
    },
    {
      "epoch": 0.7553421800646831,
      "grad_norm": 2.1600701808929443,
      "learning_rate": 4.6224592420071986e-05,
      "loss": 1.2802,
      "step": 71350
    },
    {
      "epoch": 0.7558715018446864,
      "grad_norm": 2.3075931072235107,
      "learning_rate": 4.622194579716283e-05,
      "loss": 1.2924,
      "step": 71400
    },
    {
      "epoch": 0.7564008236246896,
      "grad_norm": 2.3679494857788086,
      "learning_rate": 4.6219299174253655e-05,
      "loss": 1.2952,
      "step": 71450
    },
    {
      "epoch": 0.7569301454046929,
      "grad_norm": 2.068922996520996,
      "learning_rate": 4.621665255134449e-05,
      "loss": 1.2968,
      "step": 71500
    },
    {
      "epoch": 0.7569301454046929,
      "eval_loss": 1.2421607971191406,
      "eval_runtime": 46.5142,
      "eval_samples_per_second": 3610.292,
      "eval_steps_per_second": 451.303,
      "step": 71500
    },
    {
      "epoch": 0.7574594671846963,
      "grad_norm": 2.203230857849121,
      "learning_rate": 4.6214005928435316e-05,
      "loss": 1.2892,
      "step": 71550
    },
    {
      "epoch": 0.7579887889646996,
      "grad_norm": 2.1951653957366943,
      "learning_rate": 4.621135930552615e-05,
      "loss": 1.2807,
      "step": 71600
    },
    {
      "epoch": 0.7585181107447028,
      "grad_norm": 1.9604777097702026,
      "learning_rate": 4.6208712682616984e-05,
      "loss": 1.3038,
      "step": 71650
    },
    {
      "epoch": 0.7590474325247061,
      "grad_norm": 2.343904733657837,
      "learning_rate": 4.620606605970781e-05,
      "loss": 1.298,
      "step": 71700
    },
    {
      "epoch": 0.7595767543047094,
      "grad_norm": 2.1991961002349854,
      "learning_rate": 4.6203419436798646e-05,
      "loss": 1.2955,
      "step": 71750
    },
    {
      "epoch": 0.7601060760847127,
      "grad_norm": 2.0691463947296143,
      "learning_rate": 4.620077281388948e-05,
      "loss": 1.2902,
      "step": 71800
    },
    {
      "epoch": 0.7606353978647159,
      "grad_norm": 2.033881187438965,
      "learning_rate": 4.6198126190980314e-05,
      "loss": 1.2838,
      "step": 71850
    },
    {
      "epoch": 0.7611647196447192,
      "grad_norm": 2.2241127490997314,
      "learning_rate": 4.619547956807114e-05,
      "loss": 1.3001,
      "step": 71900
    },
    {
      "epoch": 0.7616940414247225,
      "grad_norm": 2.105304479598999,
      "learning_rate": 4.6192832945161975e-05,
      "loss": 1.2989,
      "step": 71950
    },
    {
      "epoch": 0.7622233632047258,
      "grad_norm": 2.115882158279419,
      "learning_rate": 4.619018632225281e-05,
      "loss": 1.2969,
      "step": 72000
    },
    {
      "epoch": 0.7622233632047258,
      "eval_loss": 1.240038514137268,
      "eval_runtime": 46.5366,
      "eval_samples_per_second": 3608.554,
      "eval_steps_per_second": 451.085,
      "step": 72000
    },
    {
      "epoch": 0.762752684984729,
      "grad_norm": 2.1303205490112305,
      "learning_rate": 4.6187539699343643e-05,
      "loss": 1.2825,
      "step": 72050
    },
    {
      "epoch": 0.7632820067647323,
      "grad_norm": 2.0191307067871094,
      "learning_rate": 4.618489307643447e-05,
      "loss": 1.2927,
      "step": 72100
    },
    {
      "epoch": 0.7638113285447357,
      "grad_norm": 2.218346118927002,
      "learning_rate": 4.6182246453525305e-05,
      "loss": 1.3014,
      "step": 72150
    },
    {
      "epoch": 0.7643406503247389,
      "grad_norm": 2.0710175037384033,
      "learning_rate": 4.617959983061614e-05,
      "loss": 1.2895,
      "step": 72200
    },
    {
      "epoch": 0.7648699721047422,
      "grad_norm": 2.1552350521087646,
      "learning_rate": 4.6176953207706966e-05,
      "loss": 1.3074,
      "step": 72250
    },
    {
      "epoch": 0.7653992938847455,
      "grad_norm": 2.2425589561462402,
      "learning_rate": 4.61743065847978e-05,
      "loss": 1.2705,
      "step": 72300
    },
    {
      "epoch": 0.7659286156647488,
      "grad_norm": 2.418198585510254,
      "learning_rate": 4.617165996188863e-05,
      "loss": 1.2684,
      "step": 72350
    },
    {
      "epoch": 0.766457937444752,
      "grad_norm": 2.156175136566162,
      "learning_rate": 4.616901333897947e-05,
      "loss": 1.3083,
      "step": 72400
    },
    {
      "epoch": 0.7669872592247553,
      "grad_norm": 2.2576425075531006,
      "learning_rate": 4.6166366716070296e-05,
      "loss": 1.2912,
      "step": 72450
    },
    {
      "epoch": 0.7675165810047586,
      "grad_norm": 2.208493709564209,
      "learning_rate": 4.616372009316113e-05,
      "loss": 1.2836,
      "step": 72500
    },
    {
      "epoch": 0.7675165810047586,
      "eval_loss": 1.2393147945404053,
      "eval_runtime": 46.551,
      "eval_samples_per_second": 3607.442,
      "eval_steps_per_second": 450.946,
      "step": 72500
    },
    {
      "epoch": 0.7680459027847619,
      "grad_norm": 2.288024425506592,
      "learning_rate": 4.616107347025196e-05,
      "loss": 1.2862,
      "step": 72550
    },
    {
      "epoch": 0.7685752245647651,
      "grad_norm": 2.0152432918548584,
      "learning_rate": 4.61584268473428e-05,
      "loss": 1.2868,
      "step": 72600
    },
    {
      "epoch": 0.7691045463447684,
      "grad_norm": 2.124737024307251,
      "learning_rate": 4.6155780224433626e-05,
      "loss": 1.3078,
      "step": 72650
    },
    {
      "epoch": 0.7696338681247717,
      "grad_norm": 2.2553822994232178,
      "learning_rate": 4.615313360152446e-05,
      "loss": 1.2631,
      "step": 72700
    },
    {
      "epoch": 0.7701631899047751,
      "grad_norm": 2.421269655227661,
      "learning_rate": 4.615048697861529e-05,
      "loss": 1.2883,
      "step": 72750
    },
    {
      "epoch": 0.7706925116847783,
      "grad_norm": 2.3352696895599365,
      "learning_rate": 4.614784035570612e-05,
      "loss": 1.2895,
      "step": 72800
    },
    {
      "epoch": 0.7712218334647816,
      "grad_norm": 2.2445361614227295,
      "learning_rate": 4.6145193732796955e-05,
      "loss": 1.2963,
      "step": 72850
    },
    {
      "epoch": 0.7717511552447849,
      "grad_norm": 2.1313934326171875,
      "learning_rate": 4.614254710988778e-05,
      "loss": 1.2766,
      "step": 72900
    },
    {
      "epoch": 0.7722804770247882,
      "grad_norm": 2.352540969848633,
      "learning_rate": 4.6139900486978617e-05,
      "loss": 1.3058,
      "step": 72950
    },
    {
      "epoch": 0.7728097988047914,
      "grad_norm": 2.233915090560913,
      "learning_rate": 4.613725386406945e-05,
      "loss": 1.2929,
      "step": 73000
    },
    {
      "epoch": 0.7728097988047914,
      "eval_loss": 1.2373818159103394,
      "eval_runtime": 46.5581,
      "eval_samples_per_second": 3606.892,
      "eval_steps_per_second": 450.878,
      "step": 73000
    },
    {
      "epoch": 0.7733391205847947,
      "grad_norm": 2.1128177642822266,
      "learning_rate": 4.6134607241160285e-05,
      "loss": 1.2952,
      "step": 73050
    },
    {
      "epoch": 0.773868442364798,
      "grad_norm": 2.2026286125183105,
      "learning_rate": 4.613196061825111e-05,
      "loss": 1.2624,
      "step": 73100
    },
    {
      "epoch": 0.7743977641448012,
      "grad_norm": 2.0476794242858887,
      "learning_rate": 4.6129313995341946e-05,
      "loss": 1.2794,
      "step": 73150
    },
    {
      "epoch": 0.7749270859248045,
      "grad_norm": 2.104412317276001,
      "learning_rate": 4.612666737243278e-05,
      "loss": 1.2839,
      "step": 73200
    },
    {
      "epoch": 0.7754564077048078,
      "grad_norm": 2.4047441482543945,
      "learning_rate": 4.612402074952361e-05,
      "loss": 1.2833,
      "step": 73250
    },
    {
      "epoch": 0.7759857294848111,
      "grad_norm": 2.3219637870788574,
      "learning_rate": 4.612137412661444e-05,
      "loss": 1.2861,
      "step": 73300
    },
    {
      "epoch": 0.7765150512648143,
      "grad_norm": 2.2597134113311768,
      "learning_rate": 4.611872750370527e-05,
      "loss": 1.2899,
      "step": 73350
    },
    {
      "epoch": 0.7770443730448177,
      "grad_norm": 2.20629620552063,
      "learning_rate": 4.611608088079611e-05,
      "loss": 1.2957,
      "step": 73400
    },
    {
      "epoch": 0.777573694824821,
      "grad_norm": 2.1111302375793457,
      "learning_rate": 4.611343425788694e-05,
      "loss": 1.2774,
      "step": 73450
    },
    {
      "epoch": 0.7781030166048243,
      "grad_norm": 2.161405324935913,
      "learning_rate": 4.611078763497777e-05,
      "loss": 1.2691,
      "step": 73500
    },
    {
      "epoch": 0.7781030166048243,
      "eval_loss": 1.2344568967819214,
      "eval_runtime": 46.5455,
      "eval_samples_per_second": 3607.871,
      "eval_steps_per_second": 451.0,
      "step": 73500
    },
    {
      "epoch": 0.7786323383848275,
      "grad_norm": 2.3419063091278076,
      "learning_rate": 4.61081410120686e-05,
      "loss": 1.2834,
      "step": 73550
    },
    {
      "epoch": 0.7791616601648308,
      "grad_norm": 2.3086516857147217,
      "learning_rate": 4.610549438915944e-05,
      "loss": 1.2717,
      "step": 73600
    },
    {
      "epoch": 0.7796909819448341,
      "grad_norm": 2.337237596511841,
      "learning_rate": 4.610284776625027e-05,
      "loss": 1.3046,
      "step": 73650
    },
    {
      "epoch": 0.7802203037248374,
      "grad_norm": 2.2416446208953857,
      "learning_rate": 4.61002011433411e-05,
      "loss": 1.2893,
      "step": 73700
    },
    {
      "epoch": 0.7807496255048406,
      "grad_norm": 2.3860859870910645,
      "learning_rate": 4.609755452043193e-05,
      "loss": 1.2899,
      "step": 73750
    },
    {
      "epoch": 0.7812789472848439,
      "grad_norm": 2.2809641361236572,
      "learning_rate": 4.609490789752276e-05,
      "loss": 1.298,
      "step": 73800
    },
    {
      "epoch": 0.7818082690648472,
      "grad_norm": 2.260807991027832,
      "learning_rate": 4.6092261274613596e-05,
      "loss": 1.3005,
      "step": 73850
    },
    {
      "epoch": 0.7823375908448504,
      "grad_norm": 2.1433990001678467,
      "learning_rate": 4.6089614651704424e-05,
      "loss": 1.2896,
      "step": 73900
    },
    {
      "epoch": 0.7828669126248538,
      "grad_norm": 2.1270222663879395,
      "learning_rate": 4.608696802879526e-05,
      "loss": 1.2715,
      "step": 73950
    },
    {
      "epoch": 0.7833962344048571,
      "grad_norm": 2.412724018096924,
      "learning_rate": 4.608432140588609e-05,
      "loss": 1.303,
      "step": 74000
    },
    {
      "epoch": 0.7833962344048571,
      "eval_loss": 1.2294753789901733,
      "eval_runtime": 46.6902,
      "eval_samples_per_second": 3596.684,
      "eval_steps_per_second": 449.602,
      "step": 74000
    },
    {
      "epoch": 0.7839255561848604,
      "grad_norm": 2.3391706943511963,
      "learning_rate": 4.608172771543511e-05,
      "loss": 1.267,
      "step": 74050
    },
    {
      "epoch": 0.7844548779648636,
      "grad_norm": 2.178783893585205,
      "learning_rate": 4.607908109252594e-05,
      "loss": 1.2807,
      "step": 74100
    },
    {
      "epoch": 0.7849841997448669,
      "grad_norm": 2.3216733932495117,
      "learning_rate": 4.607643446961677e-05,
      "loss": 1.2697,
      "step": 74150
    },
    {
      "epoch": 0.7855135215248702,
      "grad_norm": 2.287170648574829,
      "learning_rate": 4.60737878467076e-05,
      "loss": 1.2948,
      "step": 74200
    },
    {
      "epoch": 0.7860428433048735,
      "grad_norm": 2.433445453643799,
      "learning_rate": 4.6071141223798436e-05,
      "loss": 1.272,
      "step": 74250
    },
    {
      "epoch": 0.7865721650848767,
      "grad_norm": 2.1439125537872314,
      "learning_rate": 4.6068494600889264e-05,
      "loss": 1.2819,
      "step": 74300
    },
    {
      "epoch": 0.78710148686488,
      "grad_norm": 2.283848524093628,
      "learning_rate": 4.60658479779801e-05,
      "loss": 1.2663,
      "step": 74350
    },
    {
      "epoch": 0.7876308086448833,
      "grad_norm": 2.1491708755493164,
      "learning_rate": 4.606320135507093e-05,
      "loss": 1.2975,
      "step": 74400
    },
    {
      "epoch": 0.7881601304248866,
      "grad_norm": 2.1494927406311035,
      "learning_rate": 4.6060554732161766e-05,
      "loss": 1.295,
      "step": 74450
    },
    {
      "epoch": 0.7886894522048898,
      "grad_norm": 2.0960254669189453,
      "learning_rate": 4.605790810925259e-05,
      "loss": 1.2702,
      "step": 74500
    },
    {
      "epoch": 0.7886894522048898,
      "eval_loss": 1.227820634841919,
      "eval_runtime": 46.5946,
      "eval_samples_per_second": 3604.068,
      "eval_steps_per_second": 450.525,
      "step": 74500
    },
    {
      "epoch": 0.7892187739848932,
      "grad_norm": 2.373781681060791,
      "learning_rate": 4.605526148634343e-05,
      "loss": 1.2853,
      "step": 74550
    },
    {
      "epoch": 0.7897480957648965,
      "grad_norm": 2.4371895790100098,
      "learning_rate": 4.605261486343426e-05,
      "loss": 1.2728,
      "step": 74600
    },
    {
      "epoch": 0.7902774175448998,
      "grad_norm": 2.337623119354248,
      "learning_rate": 4.6049968240525096e-05,
      "loss": 1.2702,
      "step": 74650
    },
    {
      "epoch": 0.790806739324903,
      "grad_norm": 2.472797155380249,
      "learning_rate": 4.604732161761592e-05,
      "loss": 1.2804,
      "step": 74700
    },
    {
      "epoch": 0.7913360611049063,
      "grad_norm": 2.2645809650421143,
      "learning_rate": 4.604467499470676e-05,
      "loss": 1.2718,
      "step": 74750
    },
    {
      "epoch": 0.7918653828849096,
      "grad_norm": 2.1190083026885986,
      "learning_rate": 4.604202837179759e-05,
      "loss": 1.2805,
      "step": 74800
    },
    {
      "epoch": 0.7923947046649128,
      "grad_norm": 2.3347761631011963,
      "learning_rate": 4.603938174888842e-05,
      "loss": 1.2921,
      "step": 74850
    },
    {
      "epoch": 0.7929240264449161,
      "grad_norm": 2.3576629161834717,
      "learning_rate": 4.603673512597925e-05,
      "loss": 1.2842,
      "step": 74900
    },
    {
      "epoch": 0.7934533482249194,
      "grad_norm": 2.511427879333496,
      "learning_rate": 4.603408850307008e-05,
      "loss": 1.2817,
      "step": 74950
    },
    {
      "epoch": 0.7939826700049227,
      "grad_norm": 2.1732447147369385,
      "learning_rate": 4.603144188016092e-05,
      "loss": 1.2842,
      "step": 75000
    },
    {
      "epoch": 0.7939826700049227,
      "eval_loss": 1.2252951860427856,
      "eval_runtime": 46.9327,
      "eval_samples_per_second": 3578.099,
      "eval_steps_per_second": 447.278,
      "step": 75000
    },
    {
      "epoch": 0.7945119917849259,
      "grad_norm": 2.3255295753479004,
      "learning_rate": 4.602879525725175e-05,
      "loss": 1.2837,
      "step": 75050
    },
    {
      "epoch": 0.7950413135649292,
      "grad_norm": 2.0083107948303223,
      "learning_rate": 4.602614863434258e-05,
      "loss": 1.2928,
      "step": 75100
    },
    {
      "epoch": 0.7955706353449326,
      "grad_norm": 2.181985855102539,
      "learning_rate": 4.602350201143341e-05,
      "loss": 1.2706,
      "step": 75150
    },
    {
      "epoch": 0.7960999571249359,
      "grad_norm": 2.134565591812134,
      "learning_rate": 4.602085538852425e-05,
      "loss": 1.2786,
      "step": 75200
    },
    {
      "epoch": 0.7966292789049391,
      "grad_norm": 2.0878419876098633,
      "learning_rate": 4.601820876561508e-05,
      "loss": 1.2798,
      "step": 75250
    },
    {
      "epoch": 0.7971586006849424,
      "grad_norm": 2.127434253692627,
      "learning_rate": 4.601556214270591e-05,
      "loss": 1.2681,
      "step": 75300
    },
    {
      "epoch": 0.7976879224649457,
      "grad_norm": 2.2536568641662598,
      "learning_rate": 4.601291551979674e-05,
      "loss": 1.267,
      "step": 75350
    },
    {
      "epoch": 0.798217244244949,
      "grad_norm": 2.149665117263794,
      "learning_rate": 4.601026889688757e-05,
      "loss": 1.2707,
      "step": 75400
    },
    {
      "epoch": 0.7987465660249522,
      "grad_norm": 2.181840658187866,
      "learning_rate": 4.600762227397841e-05,
      "loss": 1.2681,
      "step": 75450
    },
    {
      "epoch": 0.7992758878049555,
      "grad_norm": 2.057248592376709,
      "learning_rate": 4.6004975651069235e-05,
      "loss": 1.2629,
      "step": 75500
    },
    {
      "epoch": 0.7992758878049555,
      "eval_loss": 1.2235987186431885,
      "eval_runtime": 46.4897,
      "eval_samples_per_second": 3612.199,
      "eval_steps_per_second": 451.541,
      "step": 75500
    },
    {
      "epoch": 0.7998052095849588,
      "grad_norm": 2.4618711471557617,
      "learning_rate": 4.600232902816007e-05,
      "loss": 1.2856,
      "step": 75550
    },
    {
      "epoch": 0.800334531364962,
      "grad_norm": 2.2705695629119873,
      "learning_rate": 4.59996824052509e-05,
      "loss": 1.2806,
      "step": 75600
    },
    {
      "epoch": 0.8008638531449653,
      "grad_norm": 2.2550241947174072,
      "learning_rate": 4.599703578234174e-05,
      "loss": 1.2639,
      "step": 75650
    },
    {
      "epoch": 0.8013931749249686,
      "grad_norm": 2.3885412216186523,
      "learning_rate": 4.5994389159432564e-05,
      "loss": 1.2613,
      "step": 75700
    },
    {
      "epoch": 0.801922496704972,
      "grad_norm": 2.173131227493286,
      "learning_rate": 4.59917425365234e-05,
      "loss": 1.2811,
      "step": 75750
    },
    {
      "epoch": 0.8024518184849752,
      "grad_norm": 2.308427572250366,
      "learning_rate": 4.598909591361423e-05,
      "loss": 1.273,
      "step": 75800
    },
    {
      "epoch": 0.8029811402649785,
      "grad_norm": 2.3547658920288086,
      "learning_rate": 4.5986449290705067e-05,
      "loss": 1.2887,
      "step": 75850
    },
    {
      "epoch": 0.8035104620449818,
      "grad_norm": 2.3181324005126953,
      "learning_rate": 4.5983802667795894e-05,
      "loss": 1.2812,
      "step": 75900
    },
    {
      "epoch": 0.8040397838249851,
      "grad_norm": 2.359487771987915,
      "learning_rate": 4.598115604488673e-05,
      "loss": 1.2735,
      "step": 75950
    },
    {
      "epoch": 0.8045691056049883,
      "grad_norm": 2.222034215927124,
      "learning_rate": 4.597850942197756e-05,
      "loss": 1.2677,
      "step": 76000
    },
    {
      "epoch": 0.8045691056049883,
      "eval_loss": 1.218790888786316,
      "eval_runtime": 46.6715,
      "eval_samples_per_second": 3598.128,
      "eval_steps_per_second": 449.782,
      "step": 76000
    },
    {
      "epoch": 0.8050984273849916,
      "grad_norm": 2.232543706893921,
      "learning_rate": 4.597586279906839e-05,
      "loss": 1.2827,
      "step": 76050
    },
    {
      "epoch": 0.8056277491649949,
      "grad_norm": 2.353118419647217,
      "learning_rate": 4.5973216176159224e-05,
      "loss": 1.2804,
      "step": 76100
    },
    {
      "epoch": 0.8061570709449982,
      "grad_norm": 2.273137092590332,
      "learning_rate": 4.597056955325005e-05,
      "loss": 1.2845,
      "step": 76150
    },
    {
      "epoch": 0.8066863927250014,
      "grad_norm": 2.2070424556732178,
      "learning_rate": 4.596792293034089e-05,
      "loss": 1.287,
      "step": 76200
    },
    {
      "epoch": 0.8072157145050047,
      "grad_norm": 2.245675563812256,
      "learning_rate": 4.596527630743172e-05,
      "loss": 1.2874,
      "step": 76250
    },
    {
      "epoch": 0.807745036285008,
      "grad_norm": 2.4205522537231445,
      "learning_rate": 4.596262968452255e-05,
      "loss": 1.2845,
      "step": 76300
    },
    {
      "epoch": 0.8082743580650114,
      "grad_norm": 2.2600066661834717,
      "learning_rate": 4.595998306161338e-05,
      "loss": 1.2768,
      "step": 76350
    },
    {
      "epoch": 0.8088036798450146,
      "grad_norm": 2.3170619010925293,
      "learning_rate": 4.595733643870422e-05,
      "loss": 1.2846,
      "step": 76400
    },
    {
      "epoch": 0.8093330016250179,
      "grad_norm": 2.5936455726623535,
      "learning_rate": 4.595468981579505e-05,
      "loss": 1.2791,
      "step": 76450
    },
    {
      "epoch": 0.8098623234050212,
      "grad_norm": 2.0388073921203613,
      "learning_rate": 4.595204319288588e-05,
      "loss": 1.276,
      "step": 76500
    },
    {
      "epoch": 0.8098623234050212,
      "eval_loss": 1.2168978452682495,
      "eval_runtime": 46.5566,
      "eval_samples_per_second": 3607.004,
      "eval_steps_per_second": 450.892,
      "step": 76500
    },
    {
      "epoch": 0.8103916451850244,
      "grad_norm": 2.2694685459136963,
      "learning_rate": 4.594939656997671e-05,
      "loss": 1.2797,
      "step": 76550
    },
    {
      "epoch": 0.8109209669650277,
      "grad_norm": 2.427077293395996,
      "learning_rate": 4.5946749947067544e-05,
      "loss": 1.2714,
      "step": 76600
    },
    {
      "epoch": 0.811450288745031,
      "grad_norm": 2.263521432876587,
      "learning_rate": 4.594410332415838e-05,
      "loss": 1.2951,
      "step": 76650
    },
    {
      "epoch": 0.8119796105250343,
      "grad_norm": 2.280116081237793,
      "learning_rate": 4.5941456701249206e-05,
      "loss": 1.2928,
      "step": 76700
    },
    {
      "epoch": 0.8125089323050375,
      "grad_norm": 2.3371524810791016,
      "learning_rate": 4.593881007834004e-05,
      "loss": 1.2609,
      "step": 76750
    },
    {
      "epoch": 0.8130382540850408,
      "grad_norm": 2.2117133140563965,
      "learning_rate": 4.5936163455430874e-05,
      "loss": 1.2755,
      "step": 76800
    },
    {
      "epoch": 0.8135675758650441,
      "grad_norm": 2.152456283569336,
      "learning_rate": 4.593351683252171e-05,
      "loss": 1.2744,
      "step": 76850
    },
    {
      "epoch": 0.8140968976450474,
      "grad_norm": 2.2736685276031494,
      "learning_rate": 4.5930870209612535e-05,
      "loss": 1.2511,
      "step": 76900
    },
    {
      "epoch": 0.8146262194250506,
      "grad_norm": 2.507758855819702,
      "learning_rate": 4.592822358670337e-05,
      "loss": 1.2716,
      "step": 76950
    },
    {
      "epoch": 0.815155541205054,
      "grad_norm": 2.4788198471069336,
      "learning_rate": 4.5925576963794203e-05,
      "loss": 1.2726,
      "step": 77000
    },
    {
      "epoch": 0.815155541205054,
      "eval_loss": 1.2160574197769165,
      "eval_runtime": 46.5759,
      "eval_samples_per_second": 3605.516,
      "eval_steps_per_second": 450.706,
      "step": 77000
    },
    {
      "epoch": 0.8156848629850573,
      "grad_norm": 2.4436333179473877,
      "learning_rate": 4.592293034088504e-05,
      "loss": 1.2453,
      "step": 77050
    },
    {
      "epoch": 0.8162141847650606,
      "grad_norm": 2.397974967956543,
      "learning_rate": 4.5920283717975865e-05,
      "loss": 1.2659,
      "step": 77100
    },
    {
      "epoch": 0.8167435065450638,
      "grad_norm": 2.1201095581054688,
      "learning_rate": 4.59176370950667e-05,
      "loss": 1.2923,
      "step": 77150
    },
    {
      "epoch": 0.8172728283250671,
      "grad_norm": 2.3553552627563477,
      "learning_rate": 4.591499047215753e-05,
      "loss": 1.2712,
      "step": 77200
    },
    {
      "epoch": 0.8178021501050704,
      "grad_norm": 2.353142023086548,
      "learning_rate": 4.591234384924836e-05,
      "loss": 1.2768,
      "step": 77250
    },
    {
      "epoch": 0.8183314718850736,
      "grad_norm": 2.5552003383636475,
      "learning_rate": 4.5909697226339194e-05,
      "loss": 1.2775,
      "step": 77300
    },
    {
      "epoch": 0.8188607936650769,
      "grad_norm": 2.3970720767974854,
      "learning_rate": 4.590705060343002e-05,
      "loss": 1.2826,
      "step": 77350
    },
    {
      "epoch": 0.8193901154450802,
      "grad_norm": 2.2498836517333984,
      "learning_rate": 4.590440398052086e-05,
      "loss": 1.2802,
      "step": 77400
    },
    {
      "epoch": 0.8199194372250835,
      "grad_norm": 2.217430830001831,
      "learning_rate": 4.590175735761169e-05,
      "loss": 1.2609,
      "step": 77450
    },
    {
      "epoch": 0.8204487590050867,
      "grad_norm": 2.2037179470062256,
      "learning_rate": 4.5899110734702524e-05,
      "loss": 1.2846,
      "step": 77500
    },
    {
      "epoch": 0.8204487590050867,
      "eval_loss": 1.210729718208313,
      "eval_runtime": 46.57,
      "eval_samples_per_second": 3605.969,
      "eval_steps_per_second": 450.762,
      "step": 77500
    },
    {
      "epoch": 0.82097808078509,
      "grad_norm": 2.364936351776123,
      "learning_rate": 4.589646411179335e-05,
      "loss": 1.2545,
      "step": 77550
    },
    {
      "epoch": 0.8215074025650934,
      "grad_norm": 2.3246374130249023,
      "learning_rate": 4.5893817488884186e-05,
      "loss": 1.2811,
      "step": 77600
    },
    {
      "epoch": 0.8220367243450967,
      "grad_norm": 2.286421775817871,
      "learning_rate": 4.589117086597502e-05,
      "loss": 1.264,
      "step": 77650
    },
    {
      "epoch": 0.8225660461250999,
      "grad_norm": 2.163618803024292,
      "learning_rate": 4.588852424306585e-05,
      "loss": 1.2657,
      "step": 77700
    },
    {
      "epoch": 0.8230953679051032,
      "grad_norm": 2.3003973960876465,
      "learning_rate": 4.588587762015668e-05,
      "loss": 1.2621,
      "step": 77750
    },
    {
      "epoch": 0.8236246896851065,
      "grad_norm": 2.1125073432922363,
      "learning_rate": 4.588323099724751e-05,
      "loss": 1.2692,
      "step": 77800
    },
    {
      "epoch": 0.8241540114651098,
      "grad_norm": 2.164659261703491,
      "learning_rate": 4.588058437433835e-05,
      "loss": 1.2527,
      "step": 77850
    },
    {
      "epoch": 0.824683333245113,
      "grad_norm": 2.290184736251831,
      "learning_rate": 4.5877937751429177e-05,
      "loss": 1.2532,
      "step": 77900
    },
    {
      "epoch": 0.8252126550251163,
      "grad_norm": 2.048888683319092,
      "learning_rate": 4.587529112852001e-05,
      "loss": 1.2716,
      "step": 77950
    },
    {
      "epoch": 0.8257419768051196,
      "grad_norm": 2.2255489826202393,
      "learning_rate": 4.587264450561084e-05,
      "loss": 1.2583,
      "step": 78000
    },
    {
      "epoch": 0.8257419768051196,
      "eval_loss": 1.2092550992965698,
      "eval_runtime": 46.6905,
      "eval_samples_per_second": 3596.662,
      "eval_steps_per_second": 449.599,
      "step": 78000
    },
    {
      "epoch": 0.8262712985851229,
      "grad_norm": 2.3605704307556152,
      "learning_rate": 4.587005081515986e-05,
      "loss": 1.2858,
      "step": 78050
    },
    {
      "epoch": 0.8268006203651261,
      "grad_norm": 2.1573455333709717,
      "learning_rate": 4.5867404192250694e-05,
      "loss": 1.2642,
      "step": 78100
    },
    {
      "epoch": 0.8273299421451294,
      "grad_norm": 2.370867967605591,
      "learning_rate": 4.586475756934152e-05,
      "loss": 1.2643,
      "step": 78150
    },
    {
      "epoch": 0.8278592639251328,
      "grad_norm": 2.385108709335327,
      "learning_rate": 4.5862110946432355e-05,
      "loss": 1.2652,
      "step": 78200
    },
    {
      "epoch": 0.828388585705136,
      "grad_norm": 2.433467149734497,
      "learning_rate": 4.585946432352319e-05,
      "loss": 1.2784,
      "step": 78250
    },
    {
      "epoch": 0.8289179074851393,
      "grad_norm": 2.4012198448181152,
      "learning_rate": 4.5856817700614016e-05,
      "loss": 1.2645,
      "step": 78300
    },
    {
      "epoch": 0.8294472292651426,
      "grad_norm": 2.227348566055298,
      "learning_rate": 4.585417107770485e-05,
      "loss": 1.2536,
      "step": 78350
    },
    {
      "epoch": 0.8299765510451459,
      "grad_norm": 2.1941561698913574,
      "learning_rate": 4.585152445479568e-05,
      "loss": 1.2549,
      "step": 78400
    },
    {
      "epoch": 0.8305058728251491,
      "grad_norm": 2.400836944580078,
      "learning_rate": 4.584887783188652e-05,
      "loss": 1.273,
      "step": 78450
    },
    {
      "epoch": 0.8310351946051524,
      "grad_norm": 2.247143507003784,
      "learning_rate": 4.5846231208977346e-05,
      "loss": 1.2664,
      "step": 78500
    },
    {
      "epoch": 0.8310351946051524,
      "eval_loss": 1.2088570594787598,
      "eval_runtime": 46.6145,
      "eval_samples_per_second": 3602.524,
      "eval_steps_per_second": 450.332,
      "step": 78500
    },
    {
      "epoch": 0.8315645163851557,
      "grad_norm": 2.3220489025115967,
      "learning_rate": 4.584358458606818e-05,
      "loss": 1.2677,
      "step": 78550
    },
    {
      "epoch": 0.832093838165159,
      "grad_norm": 2.4349288940429688,
      "learning_rate": 4.584093796315901e-05,
      "loss": 1.2428,
      "step": 78600
    },
    {
      "epoch": 0.8326231599451622,
      "grad_norm": 2.64410400390625,
      "learning_rate": 4.583829134024984e-05,
      "loss": 1.2447,
      "step": 78650
    },
    {
      "epoch": 0.8331524817251655,
      "grad_norm": 2.1485061645507812,
      "learning_rate": 4.5835697649798856e-05,
      "loss": 1.2616,
      "step": 78700
    },
    {
      "epoch": 0.8336818035051689,
      "grad_norm": 2.4160220623016357,
      "learning_rate": 4.583305102688969e-05,
      "loss": 1.2572,
      "step": 78750
    },
    {
      "epoch": 0.8342111252851722,
      "grad_norm": 2.5637755393981934,
      "learning_rate": 4.5830404403980524e-05,
      "loss": 1.2725,
      "step": 78800
    },
    {
      "epoch": 0.8347404470651754,
      "grad_norm": 2.2697527408599854,
      "learning_rate": 4.582775778107136e-05,
      "loss": 1.25,
      "step": 78850
    },
    {
      "epoch": 0.8352697688451787,
      "grad_norm": 2.1577532291412354,
      "learning_rate": 4.5825111158162186e-05,
      "loss": 1.2431,
      "step": 78900
    },
    {
      "epoch": 0.835799090625182,
      "grad_norm": 2.4169890880584717,
      "learning_rate": 4.582246453525302e-05,
      "loss": 1.2585,
      "step": 78950
    },
    {
      "epoch": 0.8363284124051852,
      "grad_norm": 2.278592109680176,
      "learning_rate": 4.581981791234385e-05,
      "loss": 1.2673,
      "step": 79000
    },
    {
      "epoch": 0.8363284124051852,
      "eval_loss": 1.205380916595459,
      "eval_runtime": 46.512,
      "eval_samples_per_second": 3610.466,
      "eval_steps_per_second": 451.324,
      "step": 79000
    },
    {
      "epoch": 0.8368577341851885,
      "grad_norm": 2.6038784980773926,
      "learning_rate": 4.581717128943469e-05,
      "loss": 1.2794,
      "step": 79050
    },
    {
      "epoch": 0.8373870559651918,
      "grad_norm": 2.241117238998413,
      "learning_rate": 4.5814524666525516e-05,
      "loss": 1.2735,
      "step": 79100
    },
    {
      "epoch": 0.8379163777451951,
      "grad_norm": 2.3111157417297363,
      "learning_rate": 4.581187804361635e-05,
      "loss": 1.2605,
      "step": 79150
    },
    {
      "epoch": 0.8384456995251983,
      "grad_norm": 2.215371608734131,
      "learning_rate": 4.580923142070718e-05,
      "loss": 1.2732,
      "step": 79200
    },
    {
      "epoch": 0.8389750213052016,
      "grad_norm": 2.0825746059417725,
      "learning_rate": 4.580658479779801e-05,
      "loss": 1.251,
      "step": 79250
    },
    {
      "epoch": 0.8395043430852049,
      "grad_norm": 2.25258469581604,
      "learning_rate": 4.5803938174888845e-05,
      "loss": 1.2363,
      "step": 79300
    },
    {
      "epoch": 0.8400336648652083,
      "grad_norm": 2.3121941089630127,
      "learning_rate": 4.580129155197967e-05,
      "loss": 1.2549,
      "step": 79350
    },
    {
      "epoch": 0.8405629866452115,
      "grad_norm": 2.384451389312744,
      "learning_rate": 4.5798644929070507e-05,
      "loss": 1.2521,
      "step": 79400
    },
    {
      "epoch": 0.8410923084252148,
      "grad_norm": 2.2686710357666016,
      "learning_rate": 4.579599830616134e-05,
      "loss": 1.2636,
      "step": 79450
    },
    {
      "epoch": 0.8416216302052181,
      "grad_norm": 2.2625937461853027,
      "learning_rate": 4.5793351683252175e-05,
      "loss": 1.2793,
      "step": 79500
    },
    {
      "epoch": 0.8416216302052181,
      "eval_loss": 1.2021137475967407,
      "eval_runtime": 46.5745,
      "eval_samples_per_second": 3605.625,
      "eval_steps_per_second": 450.719,
      "step": 79500
    },
    {
      "epoch": 0.8421509519852214,
      "grad_norm": 2.4403419494628906,
      "learning_rate": 4.5790705060343e-05,
      "loss": 1.2702,
      "step": 79550
    },
    {
      "epoch": 0.8426802737652246,
      "grad_norm": 2.3923351764678955,
      "learning_rate": 4.5788058437433836e-05,
      "loss": 1.2581,
      "step": 79600
    },
    {
      "epoch": 0.8432095955452279,
      "grad_norm": 2.300473213195801,
      "learning_rate": 4.578541181452467e-05,
      "loss": 1.2629,
      "step": 79650
    },
    {
      "epoch": 0.8437389173252312,
      "grad_norm": 2.370377540588379,
      "learning_rate": 4.57827651916155e-05,
      "loss": 1.2303,
      "step": 79700
    },
    {
      "epoch": 0.8442682391052344,
      "grad_norm": 2.599184274673462,
      "learning_rate": 4.578011856870633e-05,
      "loss": 1.2653,
      "step": 79750
    },
    {
      "epoch": 0.8447975608852377,
      "grad_norm": 2.3250155448913574,
      "learning_rate": 4.577747194579716e-05,
      "loss": 1.2606,
      "step": 79800
    },
    {
      "epoch": 0.845326882665241,
      "grad_norm": 2.4954802989959717,
      "learning_rate": 4.5774825322888e-05,
      "loss": 1.2642,
      "step": 79850
    },
    {
      "epoch": 0.8458562044452443,
      "grad_norm": 2.3735575675964355,
      "learning_rate": 4.577217869997883e-05,
      "loss": 1.2583,
      "step": 79900
    },
    {
      "epoch": 0.8463855262252475,
      "grad_norm": 2.4027152061462402,
      "learning_rate": 4.576953207706966e-05,
      "loss": 1.2551,
      "step": 79950
    },
    {
      "epoch": 0.8469148480052509,
      "grad_norm": 2.3856945037841797,
      "learning_rate": 4.576688545416049e-05,
      "loss": 1.2699,
      "step": 80000
    },
    {
      "epoch": 0.8469148480052509,
      "eval_loss": 1.2009276151657104,
      "eval_runtime": 46.6031,
      "eval_samples_per_second": 3603.41,
      "eval_steps_per_second": 450.442,
      "step": 80000
    },
    {
      "epoch": 0.8474441697852542,
      "grad_norm": 2.450943946838379,
      "learning_rate": 4.576423883125133e-05,
      "loss": 1.2779,
      "step": 80050
    },
    {
      "epoch": 0.8479734915652575,
      "grad_norm": 2.5521726608276367,
      "learning_rate": 4.576159220834216e-05,
      "loss": 1.2691,
      "step": 80100
    },
    {
      "epoch": 0.8485028133452607,
      "grad_norm": 2.2930452823638916,
      "learning_rate": 4.575894558543299e-05,
      "loss": 1.2678,
      "step": 80150
    },
    {
      "epoch": 0.849032135125264,
      "grad_norm": 2.5029776096343994,
      "learning_rate": 4.575629896252382e-05,
      "loss": 1.2689,
      "step": 80200
    },
    {
      "epoch": 0.8495614569052673,
      "grad_norm": 2.3241636753082275,
      "learning_rate": 4.575365233961465e-05,
      "loss": 1.2615,
      "step": 80250
    },
    {
      "epoch": 0.8500907786852706,
      "grad_norm": 2.38230299949646,
      "learning_rate": 4.5751005716705486e-05,
      "loss": 1.2588,
      "step": 80300
    },
    {
      "epoch": 0.8506201004652738,
      "grad_norm": 2.307286262512207,
      "learning_rate": 4.5748359093796314e-05,
      "loss": 1.2612,
      "step": 80350
    },
    {
      "epoch": 0.8511494222452771,
      "grad_norm": 2.536655902862549,
      "learning_rate": 4.574571247088715e-05,
      "loss": 1.2623,
      "step": 80400
    },
    {
      "epoch": 0.8516787440252804,
      "grad_norm": 2.286166191101074,
      "learning_rate": 4.574306584797798e-05,
      "loss": 1.2615,
      "step": 80450
    },
    {
      "epoch": 0.8522080658052837,
      "grad_norm": 2.5118608474731445,
      "learning_rate": 4.5740419225068816e-05,
      "loss": 1.2648,
      "step": 80500
    },
    {
      "epoch": 0.8522080658052837,
      "eval_loss": 1.1966620683670044,
      "eval_runtime": 46.5835,
      "eval_samples_per_second": 3604.928,
      "eval_steps_per_second": 450.632,
      "step": 80500
    },
    {
      "epoch": 0.8527373875852869,
      "grad_norm": 2.3907196521759033,
      "learning_rate": 4.5737772602159643e-05,
      "loss": 1.2567,
      "step": 80550
    },
    {
      "epoch": 0.8532667093652903,
      "grad_norm": 2.29693341255188,
      "learning_rate": 4.573512597925048e-05,
      "loss": 1.2598,
      "step": 80600
    },
    {
      "epoch": 0.8537960311452936,
      "grad_norm": 2.4500784873962402,
      "learning_rate": 4.573247935634131e-05,
      "loss": 1.2487,
      "step": 80650
    },
    {
      "epoch": 0.8543253529252968,
      "grad_norm": 2.330130100250244,
      "learning_rate": 4.5729832733432146e-05,
      "loss": 1.2458,
      "step": 80700
    },
    {
      "epoch": 0.8548546747053001,
      "grad_norm": 2.219522476196289,
      "learning_rate": 4.572718611052297e-05,
      "loss": 1.2369,
      "step": 80750
    },
    {
      "epoch": 0.8553839964853034,
      "grad_norm": 2.730437755584717,
      "learning_rate": 4.572453948761381e-05,
      "loss": 1.2443,
      "step": 80800
    },
    {
      "epoch": 0.8559133182653067,
      "grad_norm": 2.1391007900238037,
      "learning_rate": 4.572194579716282e-05,
      "loss": 1.2691,
      "step": 80850
    },
    {
      "epoch": 0.8564426400453099,
      "grad_norm": 2.3581383228302,
      "learning_rate": 4.5719299174253656e-05,
      "loss": 1.2544,
      "step": 80900
    },
    {
      "epoch": 0.8569719618253132,
      "grad_norm": 2.435567617416382,
      "learning_rate": 4.571665255134448e-05,
      "loss": 1.2461,
      "step": 80950
    },
    {
      "epoch": 0.8575012836053165,
      "grad_norm": 2.2102794647216797,
      "learning_rate": 4.571400592843532e-05,
      "loss": 1.2573,
      "step": 81000
    },
    {
      "epoch": 0.8575012836053165,
      "eval_loss": 1.1949758529663086,
      "eval_runtime": 46.5429,
      "eval_samples_per_second": 3608.069,
      "eval_steps_per_second": 451.025,
      "step": 81000
    },
    {
      "epoch": 0.8580306053853198,
      "grad_norm": 2.474043607711792,
      "learning_rate": 4.571135930552615e-05,
      "loss": 1.2511,
      "step": 81050
    },
    {
      "epoch": 0.858559927165323,
      "grad_norm": 2.446986675262451,
      "learning_rate": 4.5708712682616986e-05,
      "loss": 1.2483,
      "step": 81100
    },
    {
      "epoch": 0.8590892489453263,
      "grad_norm": 2.307955503463745,
      "learning_rate": 4.570606605970781e-05,
      "loss": 1.2593,
      "step": 81150
    },
    {
      "epoch": 0.8596185707253297,
      "grad_norm": 2.7970407009124756,
      "learning_rate": 4.570341943679865e-05,
      "loss": 1.2717,
      "step": 81200
    },
    {
      "epoch": 0.860147892505333,
      "grad_norm": 2.345574140548706,
      "learning_rate": 4.570077281388948e-05,
      "loss": 1.2299,
      "step": 81250
    },
    {
      "epoch": 0.8606772142853362,
      "grad_norm": 2.359487295150757,
      "learning_rate": 4.569812619098031e-05,
      "loss": 1.2861,
      "step": 81300
    },
    {
      "epoch": 0.8612065360653395,
      "grad_norm": 2.3398406505584717,
      "learning_rate": 4.569547956807114e-05,
      "loss": 1.259,
      "step": 81350
    },
    {
      "epoch": 0.8617358578453428,
      "grad_norm": 2.4244492053985596,
      "learning_rate": 4.569283294516197e-05,
      "loss": 1.2401,
      "step": 81400
    },
    {
      "epoch": 0.862265179625346,
      "grad_norm": 2.3217196464538574,
      "learning_rate": 4.569018632225281e-05,
      "loss": 1.2435,
      "step": 81450
    },
    {
      "epoch": 0.8627945014053493,
      "grad_norm": 2.3791942596435547,
      "learning_rate": 4.568753969934364e-05,
      "loss": 1.275,
      "step": 81500
    },
    {
      "epoch": 0.8627945014053493,
      "eval_loss": 1.1907597780227661,
      "eval_runtime": 46.5981,
      "eval_samples_per_second": 3603.792,
      "eval_steps_per_second": 450.49,
      "step": 81500
    },
    {
      "epoch": 0.8633238231853526,
      "grad_norm": 2.304255247116089,
      "learning_rate": 4.568489307643447e-05,
      "loss": 1.2621,
      "step": 81550
    },
    {
      "epoch": 0.8638531449653559,
      "grad_norm": 2.1516530513763428,
      "learning_rate": 4.56822464535253e-05,
      "loss": 1.2466,
      "step": 81600
    },
    {
      "epoch": 0.8643824667453591,
      "grad_norm": 2.236386775970459,
      "learning_rate": 4.567959983061614e-05,
      "loss": 1.2675,
      "step": 81650
    },
    {
      "epoch": 0.8649117885253624,
      "grad_norm": 2.3682870864868164,
      "learning_rate": 4.567695320770697e-05,
      "loss": 1.2493,
      "step": 81700
    },
    {
      "epoch": 0.8654411103053657,
      "grad_norm": 2.2896604537963867,
      "learning_rate": 4.56743065847978e-05,
      "loss": 1.2578,
      "step": 81750
    },
    {
      "epoch": 0.8659704320853691,
      "grad_norm": 2.3411664962768555,
      "learning_rate": 4.567165996188863e-05,
      "loss": 1.2514,
      "step": 81800
    },
    {
      "epoch": 0.8664997538653723,
      "grad_norm": 2.298192024230957,
      "learning_rate": 4.566901333897946e-05,
      "loss": 1.262,
      "step": 81850
    },
    {
      "epoch": 0.8670290756453756,
      "grad_norm": 2.346086025238037,
      "learning_rate": 4.56663667160703e-05,
      "loss": 1.2361,
      "step": 81900
    },
    {
      "epoch": 0.8675583974253789,
      "grad_norm": 2.4599108695983887,
      "learning_rate": 4.5663720093161125e-05,
      "loss": 1.2719,
      "step": 81950
    },
    {
      "epoch": 0.8680877192053822,
      "grad_norm": 2.6004080772399902,
      "learning_rate": 4.566107347025196e-05,
      "loss": 1.2297,
      "step": 82000
    },
    {
      "epoch": 0.8680877192053822,
      "eval_loss": 1.1902395486831665,
      "eval_runtime": 46.6061,
      "eval_samples_per_second": 3603.176,
      "eval_steps_per_second": 450.413,
      "step": 82000
    },
    {
      "epoch": 0.8686170409853854,
      "grad_norm": 2.3217291831970215,
      "learning_rate": 4.565842684734279e-05,
      "loss": 1.2542,
      "step": 82050
    },
    {
      "epoch": 0.8691463627653887,
      "grad_norm": 2.3928606510162354,
      "learning_rate": 4.565578022443363e-05,
      "loss": 1.2569,
      "step": 82100
    },
    {
      "epoch": 0.869675684545392,
      "grad_norm": 2.433682918548584,
      "learning_rate": 4.5653133601524454e-05,
      "loss": 1.2508,
      "step": 82150
    },
    {
      "epoch": 0.8702050063253953,
      "grad_norm": 2.395603656768799,
      "learning_rate": 4.565048697861529e-05,
      "loss": 1.2332,
      "step": 82200
    },
    {
      "epoch": 0.8707343281053985,
      "grad_norm": 2.391972064971924,
      "learning_rate": 4.564784035570612e-05,
      "loss": 1.2398,
      "step": 82250
    },
    {
      "epoch": 0.8712636498854018,
      "grad_norm": 2.363132953643799,
      "learning_rate": 4.5645193732796957e-05,
      "loss": 1.2509,
      "step": 82300
    },
    {
      "epoch": 0.8717929716654051,
      "grad_norm": 2.391369342803955,
      "learning_rate": 4.5642547109887784e-05,
      "loss": 1.2584,
      "step": 82350
    },
    {
      "epoch": 0.8723222934454083,
      "grad_norm": 2.492954730987549,
      "learning_rate": 4.563990048697862e-05,
      "loss": 1.2523,
      "step": 82400
    },
    {
      "epoch": 0.8728516152254117,
      "grad_norm": 2.3017101287841797,
      "learning_rate": 4.563725386406945e-05,
      "loss": 1.2288,
      "step": 82450
    },
    {
      "epoch": 0.873380937005415,
      "grad_norm": 2.4523065090179443,
      "learning_rate": 4.563460724116028e-05,
      "loss": 1.2503,
      "step": 82500
    },
    {
      "epoch": 0.873380937005415,
      "eval_loss": 1.1869468688964844,
      "eval_runtime": 46.5501,
      "eval_samples_per_second": 3607.51,
      "eval_steps_per_second": 450.955,
      "step": 82500
    },
    {
      "epoch": 0.8739102587854183,
      "grad_norm": 2.441434144973755,
      "learning_rate": 4.5631960618251114e-05,
      "loss": 1.2376,
      "step": 82550
    },
    {
      "epoch": 0.8744395805654215,
      "grad_norm": 2.462372064590454,
      "learning_rate": 4.562931399534194e-05,
      "loss": 1.2623,
      "step": 82600
    },
    {
      "epoch": 0.8749689023454248,
      "grad_norm": 2.2749505043029785,
      "learning_rate": 4.562666737243278e-05,
      "loss": 1.2663,
      "step": 82650
    },
    {
      "epoch": 0.8754982241254281,
      "grad_norm": 2.5161325931549072,
      "learning_rate": 4.562402074952361e-05,
      "loss": 1.252,
      "step": 82700
    },
    {
      "epoch": 0.8760275459054314,
      "grad_norm": 2.530153274536133,
      "learning_rate": 4.562137412661444e-05,
      "loss": 1.2389,
      "step": 82750
    },
    {
      "epoch": 0.8765568676854346,
      "grad_norm": 2.302826404571533,
      "learning_rate": 4.561872750370527e-05,
      "loss": 1.2306,
      "step": 82800
    },
    {
      "epoch": 0.8770861894654379,
      "grad_norm": 2.5128352642059326,
      "learning_rate": 4.561608088079611e-05,
      "loss": 1.2535,
      "step": 82850
    },
    {
      "epoch": 0.8776155112454412,
      "grad_norm": 2.5650148391723633,
      "learning_rate": 4.561343425788694e-05,
      "loss": 1.2541,
      "step": 82900
    },
    {
      "epoch": 0.8781448330254445,
      "grad_norm": 2.39263916015625,
      "learning_rate": 4.561078763497777e-05,
      "loss": 1.2455,
      "step": 82950
    },
    {
      "epoch": 0.8786741548054477,
      "grad_norm": 2.3080246448516846,
      "learning_rate": 4.56081410120686e-05,
      "loss": 1.2347,
      "step": 83000
    },
    {
      "epoch": 0.8786741548054477,
      "eval_loss": 1.1852186918258667,
      "eval_runtime": 46.5254,
      "eval_samples_per_second": 3609.43,
      "eval_steps_per_second": 451.195,
      "step": 83000
    },
    {
      "epoch": 0.8792034765854511,
      "grad_norm": 2.2805042266845703,
      "learning_rate": 4.5605494389159434e-05,
      "loss": 1.2555,
      "step": 83050
    },
    {
      "epoch": 0.8797327983654544,
      "grad_norm": 2.236402988433838,
      "learning_rate": 4.560284776625027e-05,
      "loss": 1.2346,
      "step": 83100
    },
    {
      "epoch": 0.8802621201454576,
      "grad_norm": 2.3396596908569336,
      "learning_rate": 4.5600201143341096e-05,
      "loss": 1.2241,
      "step": 83150
    },
    {
      "epoch": 0.8807914419254609,
      "grad_norm": 2.451533555984497,
      "learning_rate": 4.559755452043193e-05,
      "loss": 1.2545,
      "step": 83200
    },
    {
      "epoch": 0.8813207637054642,
      "grad_norm": 2.708538293838501,
      "learning_rate": 4.5594907897522764e-05,
      "loss": 1.231,
      "step": 83250
    },
    {
      "epoch": 0.8818500854854675,
      "grad_norm": 2.117753028869629,
      "learning_rate": 4.55922612746136e-05,
      "loss": 1.2504,
      "step": 83300
    },
    {
      "epoch": 0.8823794072654707,
      "grad_norm": 2.3840770721435547,
      "learning_rate": 4.5589614651704425e-05,
      "loss": 1.2364,
      "step": 83350
    },
    {
      "epoch": 0.882908729045474,
      "grad_norm": 2.333217144012451,
      "learning_rate": 4.558702096125344e-05,
      "loss": 1.2383,
      "step": 83400
    },
    {
      "epoch": 0.8834380508254773,
      "grad_norm": 2.4366633892059326,
      "learning_rate": 4.5584374338344274e-05,
      "loss": 1.2409,
      "step": 83450
    },
    {
      "epoch": 0.8839673726054806,
      "grad_norm": 2.3649702072143555,
      "learning_rate": 4.558172771543511e-05,
      "loss": 1.2515,
      "step": 83500
    },
    {
      "epoch": 0.8839673726054806,
      "eval_loss": 1.1821365356445312,
      "eval_runtime": 46.6639,
      "eval_samples_per_second": 3598.717,
      "eval_steps_per_second": 449.856,
      "step": 83500
    },
    {
      "epoch": 0.8844966943854838,
      "grad_norm": 2.5074408054351807,
      "learning_rate": 4.5579081092525935e-05,
      "loss": 1.25,
      "step": 83550
    },
    {
      "epoch": 0.8850260161654872,
      "grad_norm": 2.5256307125091553,
      "learning_rate": 4.557643446961677e-05,
      "loss": 1.2579,
      "step": 83600
    },
    {
      "epoch": 0.8855553379454905,
      "grad_norm": 2.4628400802612305,
      "learning_rate": 4.5573787846707604e-05,
      "loss": 1.2527,
      "step": 83650
    },
    {
      "epoch": 0.8860846597254938,
      "grad_norm": 2.351731061935425,
      "learning_rate": 4.557114122379844e-05,
      "loss": 1.2463,
      "step": 83700
    },
    {
      "epoch": 0.886613981505497,
      "grad_norm": 2.583458185195923,
      "learning_rate": 4.5568494600889265e-05,
      "loss": 1.248,
      "step": 83750
    },
    {
      "epoch": 0.8871433032855003,
      "grad_norm": 2.600148916244507,
      "learning_rate": 4.55658479779801e-05,
      "loss": 1.2524,
      "step": 83800
    },
    {
      "epoch": 0.8876726250655036,
      "grad_norm": 2.497532844543457,
      "learning_rate": 4.556320135507093e-05,
      "loss": 1.2485,
      "step": 83850
    },
    {
      "epoch": 0.8882019468455069,
      "grad_norm": 2.4255106449127197,
      "learning_rate": 4.556055473216177e-05,
      "loss": 1.2476,
      "step": 83900
    },
    {
      "epoch": 0.8887312686255101,
      "grad_norm": 2.6473472118377686,
      "learning_rate": 4.5557908109252595e-05,
      "loss": 1.2581,
      "step": 83950
    },
    {
      "epoch": 0.8892605904055134,
      "grad_norm": 2.392627239227295,
      "learning_rate": 4.555526148634343e-05,
      "loss": 1.2451,
      "step": 84000
    },
    {
      "epoch": 0.8892605904055134,
      "eval_loss": 1.178829312324524,
      "eval_runtime": 46.5937,
      "eval_samples_per_second": 3604.132,
      "eval_steps_per_second": 450.533,
      "step": 84000
    },
    {
      "epoch": 0.8897899121855167,
      "grad_norm": 2.6717851161956787,
      "learning_rate": 4.555261486343426e-05,
      "loss": 1.2505,
      "step": 84050
    },
    {
      "epoch": 0.8903192339655199,
      "grad_norm": 2.3232178688049316,
      "learning_rate": 4.554996824052509e-05,
      "loss": 1.2767,
      "step": 84100
    },
    {
      "epoch": 0.8908485557455232,
      "grad_norm": 2.4827163219451904,
      "learning_rate": 4.5547321617615924e-05,
      "loss": 1.2471,
      "step": 84150
    },
    {
      "epoch": 0.8913778775255266,
      "grad_norm": 2.4964888095855713,
      "learning_rate": 4.554467499470675e-05,
      "loss": 1.2583,
      "step": 84200
    },
    {
      "epoch": 0.8919071993055299,
      "grad_norm": 2.376155376434326,
      "learning_rate": 4.554202837179759e-05,
      "loss": 1.2221,
      "step": 84250
    },
    {
      "epoch": 0.8924365210855331,
      "grad_norm": 2.359658718109131,
      "learning_rate": 4.553938174888842e-05,
      "loss": 1.2521,
      "step": 84300
    },
    {
      "epoch": 0.8929658428655364,
      "grad_norm": 2.440316915512085,
      "learning_rate": 4.5536735125979254e-05,
      "loss": 1.2351,
      "step": 84350
    },
    {
      "epoch": 0.8934951646455397,
      "grad_norm": 2.415703296661377,
      "learning_rate": 4.553408850307008e-05,
      "loss": 1.2423,
      "step": 84400
    },
    {
      "epoch": 0.894024486425543,
      "grad_norm": 2.4398696422576904,
      "learning_rate": 4.553144188016092e-05,
      "loss": 1.2382,
      "step": 84450
    },
    {
      "epoch": 0.8945538082055462,
      "grad_norm": 2.3121562004089355,
      "learning_rate": 4.552879525725175e-05,
      "loss": 1.2497,
      "step": 84500
    },
    {
      "epoch": 0.8945538082055462,
      "eval_loss": 1.1779186725616455,
      "eval_runtime": 46.9202,
      "eval_samples_per_second": 3579.052,
      "eval_steps_per_second": 447.398,
      "step": 84500
    },
    {
      "epoch": 0.8950831299855495,
      "grad_norm": 2.299018383026123,
      "learning_rate": 4.5526148634342584e-05,
      "loss": 1.2456,
      "step": 84550
    },
    {
      "epoch": 0.8956124517655528,
      "grad_norm": 2.5251705646514893,
      "learning_rate": 4.552350201143341e-05,
      "loss": 1.2619,
      "step": 84600
    },
    {
      "epoch": 0.8961417735455561,
      "grad_norm": 2.32981276512146,
      "learning_rate": 4.5520855388524245e-05,
      "loss": 1.2518,
      "step": 84650
    },
    {
      "epoch": 0.8966710953255593,
      "grad_norm": 2.4089407920837402,
      "learning_rate": 4.551820876561508e-05,
      "loss": 1.2461,
      "step": 84700
    },
    {
      "epoch": 0.8972004171055626,
      "grad_norm": 2.4850499629974365,
      "learning_rate": 4.5515562142705906e-05,
      "loss": 1.2433,
      "step": 84750
    },
    {
      "epoch": 0.897729738885566,
      "grad_norm": 2.5111067295074463,
      "learning_rate": 4.551291551979674e-05,
      "loss": 1.2341,
      "step": 84800
    },
    {
      "epoch": 0.8982590606655692,
      "grad_norm": 2.3668406009674072,
      "learning_rate": 4.5510268896887575e-05,
      "loss": 1.2563,
      "step": 84850
    },
    {
      "epoch": 0.8987883824455725,
      "grad_norm": 2.520195245742798,
      "learning_rate": 4.550762227397841e-05,
      "loss": 1.2426,
      "step": 84900
    },
    {
      "epoch": 0.8993177042255758,
      "grad_norm": 2.7412168979644775,
      "learning_rate": 4.5504975651069236e-05,
      "loss": 1.2326,
      "step": 84950
    },
    {
      "epoch": 0.8998470260055791,
      "grad_norm": 2.3193376064300537,
      "learning_rate": 4.550232902816007e-05,
      "loss": 1.2275,
      "step": 85000
    },
    {
      "epoch": 0.8998470260055791,
      "eval_loss": 1.174460530281067,
      "eval_runtime": 46.5915,
      "eval_samples_per_second": 3604.308,
      "eval_steps_per_second": 450.555,
      "step": 85000
    },
    {
      "epoch": 0.9003763477855823,
      "grad_norm": 2.7901909351348877,
      "learning_rate": 4.5499682405250904e-05,
      "loss": 1.2366,
      "step": 85050
    },
    {
      "epoch": 0.9009056695655856,
      "grad_norm": 2.4905128479003906,
      "learning_rate": 4.549703578234173e-05,
      "loss": 1.2375,
      "step": 85100
    },
    {
      "epoch": 0.9014349913455889,
      "grad_norm": 2.5642130374908447,
      "learning_rate": 4.5494389159432566e-05,
      "loss": 1.2626,
      "step": 85150
    },
    {
      "epoch": 0.9019643131255922,
      "grad_norm": 2.6097495555877686,
      "learning_rate": 4.549174253652339e-05,
      "loss": 1.2461,
      "step": 85200
    },
    {
      "epoch": 0.9024936349055954,
      "grad_norm": 2.5567619800567627,
      "learning_rate": 4.5489095913614234e-05,
      "loss": 1.2297,
      "step": 85250
    },
    {
      "epoch": 0.9030229566855987,
      "grad_norm": 2.610417127609253,
      "learning_rate": 4.548644929070506e-05,
      "loss": 1.252,
      "step": 85300
    },
    {
      "epoch": 0.903552278465602,
      "grad_norm": 2.456256628036499,
      "learning_rate": 4.5483802667795895e-05,
      "loss": 1.253,
      "step": 85350
    },
    {
      "epoch": 0.9040816002456054,
      "grad_norm": 2.4039266109466553,
      "learning_rate": 4.548115604488672e-05,
      "loss": 1.2513,
      "step": 85400
    },
    {
      "epoch": 0.9046109220256086,
      "grad_norm": 2.6042215824127197,
      "learning_rate": 4.5478509421977563e-05,
      "loss": 1.2314,
      "step": 85450
    },
    {
      "epoch": 0.9051402438056119,
      "grad_norm": 2.4919321537017822,
      "learning_rate": 4.547586279906839e-05,
      "loss": 1.2423,
      "step": 85500
    },
    {
      "epoch": 0.9051402438056119,
      "eval_loss": 1.1733644008636475,
      "eval_runtime": 46.6509,
      "eval_samples_per_second": 3599.715,
      "eval_steps_per_second": 449.98,
      "step": 85500
    },
    {
      "epoch": 0.9056695655856152,
      "grad_norm": 2.505659580230713,
      "learning_rate": 4.5473216176159225e-05,
      "loss": 1.2255,
      "step": 85550
    },
    {
      "epoch": 0.9061988873656185,
      "grad_norm": 2.405794858932495,
      "learning_rate": 4.547056955325005e-05,
      "loss": 1.2423,
      "step": 85600
    },
    {
      "epoch": 0.9067282091456217,
      "grad_norm": 2.559556722640991,
      "learning_rate": 4.5467975862799074e-05,
      "loss": 1.2537,
      "step": 85650
    },
    {
      "epoch": 0.907257530925625,
      "grad_norm": 2.30564284324646,
      "learning_rate": 4.54653292398899e-05,
      "loss": 1.2346,
      "step": 85700
    },
    {
      "epoch": 0.9077868527056283,
      "grad_norm": 2.402611255645752,
      "learning_rate": 4.5462682616980735e-05,
      "loss": 1.2321,
      "step": 85750
    },
    {
      "epoch": 0.9083161744856315,
      "grad_norm": 2.6677260398864746,
      "learning_rate": 4.546003599407156e-05,
      "loss": 1.2323,
      "step": 85800
    },
    {
      "epoch": 0.9088454962656348,
      "grad_norm": 2.251840591430664,
      "learning_rate": 4.54573893711624e-05,
      "loss": 1.2385,
      "step": 85850
    },
    {
      "epoch": 0.9093748180456381,
      "grad_norm": 2.683771848678589,
      "learning_rate": 4.545474274825323e-05,
      "loss": 1.2436,
      "step": 85900
    },
    {
      "epoch": 0.9099041398256414,
      "grad_norm": 2.614229202270508,
      "learning_rate": 4.5452096125344065e-05,
      "loss": 1.2259,
      "step": 85950
    },
    {
      "epoch": 0.9104334616056446,
      "grad_norm": 2.4878158569335938,
      "learning_rate": 4.544944950243489e-05,
      "loss": 1.2313,
      "step": 86000
    },
    {
      "epoch": 0.9104334616056446,
      "eval_loss": 1.1696683168411255,
      "eval_runtime": 46.7071,
      "eval_samples_per_second": 3595.383,
      "eval_steps_per_second": 449.439,
      "step": 86000
    },
    {
      "epoch": 0.910962783385648,
      "grad_norm": 2.5146713256835938,
      "learning_rate": 4.5446802879525726e-05,
      "loss": 1.2357,
      "step": 86050
    },
    {
      "epoch": 0.9114921051656513,
      "grad_norm": 2.3550539016723633,
      "learning_rate": 4.544415625661656e-05,
      "loss": 1.2485,
      "step": 86100
    },
    {
      "epoch": 0.9120214269456546,
      "grad_norm": 2.221607208251953,
      "learning_rate": 4.544150963370739e-05,
      "loss": 1.2484,
      "step": 86150
    },
    {
      "epoch": 0.9125507487256578,
      "grad_norm": 2.486119270324707,
      "learning_rate": 4.543886301079822e-05,
      "loss": 1.2448,
      "step": 86200
    },
    {
      "epoch": 0.9130800705056611,
      "grad_norm": 2.5023326873779297,
      "learning_rate": 4.5436216387889056e-05,
      "loss": 1.2684,
      "step": 86250
    },
    {
      "epoch": 0.9136093922856644,
      "grad_norm": 2.697185516357422,
      "learning_rate": 4.543356976497989e-05,
      "loss": 1.2509,
      "step": 86300
    },
    {
      "epoch": 0.9141387140656677,
      "grad_norm": 2.6337194442749023,
      "learning_rate": 4.543092314207072e-05,
      "loss": 1.2226,
      "step": 86350
    },
    {
      "epoch": 0.9146680358456709,
      "grad_norm": 2.5729429721832275,
      "learning_rate": 4.542827651916155e-05,
      "loss": 1.2384,
      "step": 86400
    },
    {
      "epoch": 0.9151973576256742,
      "grad_norm": 2.532930374145508,
      "learning_rate": 4.5425629896252385e-05,
      "loss": 1.2452,
      "step": 86450
    },
    {
      "epoch": 0.9157266794056775,
      "grad_norm": 2.637657403945923,
      "learning_rate": 4.542298327334322e-05,
      "loss": 1.2255,
      "step": 86500
    },
    {
      "epoch": 0.9157266794056775,
      "eval_loss": 1.1659431457519531,
      "eval_runtime": 46.6411,
      "eval_samples_per_second": 3600.469,
      "eval_steps_per_second": 450.075,
      "step": 86500
    },
    {
      "epoch": 0.9162560011856807,
      "grad_norm": 2.5435919761657715,
      "learning_rate": 4.542033665043405e-05,
      "loss": 1.2328,
      "step": 86550
    },
    {
      "epoch": 0.916785322965684,
      "grad_norm": 2.6063930988311768,
      "learning_rate": 4.541769002752488e-05,
      "loss": 1.2374,
      "step": 86600
    },
    {
      "epoch": 0.9173146447456874,
      "grad_norm": 2.6015684604644775,
      "learning_rate": 4.5415043404615715e-05,
      "loss": 1.2339,
      "step": 86650
    },
    {
      "epoch": 0.9178439665256907,
      "grad_norm": 2.5228095054626465,
      "learning_rate": 4.541239678170654e-05,
      "loss": 1.2339,
      "step": 86700
    },
    {
      "epoch": 0.9183732883056939,
      "grad_norm": 2.6155991554260254,
      "learning_rate": 4.5409750158797376e-05,
      "loss": 1.2436,
      "step": 86750
    },
    {
      "epoch": 0.9189026100856972,
      "grad_norm": 2.6184141635894775,
      "learning_rate": 4.5407103535888204e-05,
      "loss": 1.2625,
      "step": 86800
    },
    {
      "epoch": 0.9194319318657005,
      "grad_norm": 2.600792646408081,
      "learning_rate": 4.5404456912979045e-05,
      "loss": 1.238,
      "step": 86850
    },
    {
      "epoch": 0.9199612536457038,
      "grad_norm": 2.4414920806884766,
      "learning_rate": 4.540181029006987e-05,
      "loss": 1.2392,
      "step": 86900
    },
    {
      "epoch": 0.920490575425707,
      "grad_norm": 2.6391782760620117,
      "learning_rate": 4.5399163667160706e-05,
      "loss": 1.2259,
      "step": 86950
    },
    {
      "epoch": 0.9210198972057103,
      "grad_norm": 2.2768242359161377,
      "learning_rate": 4.5396517044251533e-05,
      "loss": 1.2372,
      "step": 87000
    },
    {
      "epoch": 0.9210198972057103,
      "eval_loss": 1.165321707725525,
      "eval_runtime": 46.6104,
      "eval_samples_per_second": 3602.845,
      "eval_steps_per_second": 450.372,
      "step": 87000
    },
    {
      "epoch": 0.9215492189857136,
      "grad_norm": 2.612257480621338,
      "learning_rate": 4.5393870421342374e-05,
      "loss": 1.2295,
      "step": 87050
    },
    {
      "epoch": 0.9220785407657169,
      "grad_norm": 2.4696285724639893,
      "learning_rate": 4.53912237984332e-05,
      "loss": 1.2354,
      "step": 87100
    },
    {
      "epoch": 0.9226078625457201,
      "grad_norm": 2.4662373065948486,
      "learning_rate": 4.5388577175524036e-05,
      "loss": 1.238,
      "step": 87150
    },
    {
      "epoch": 0.9231371843257234,
      "grad_norm": 2.397965431213379,
      "learning_rate": 4.538593055261486e-05,
      "loss": 1.2286,
      "step": 87200
    },
    {
      "epoch": 0.9236665061057268,
      "grad_norm": 2.5794739723205566,
      "learning_rate": 4.53832839297057e-05,
      "loss": 1.228,
      "step": 87250
    },
    {
      "epoch": 0.92419582788573,
      "grad_norm": 2.334573984146118,
      "learning_rate": 4.538063730679653e-05,
      "loss": 1.2365,
      "step": 87300
    },
    {
      "epoch": 0.9247251496657333,
      "grad_norm": 2.5203194618225098,
      "learning_rate": 4.537799068388736e-05,
      "loss": 1.2354,
      "step": 87350
    },
    {
      "epoch": 0.9252544714457366,
      "grad_norm": 2.2620391845703125,
      "learning_rate": 4.537534406097819e-05,
      "loss": 1.2299,
      "step": 87400
    },
    {
      "epoch": 0.9257837932257399,
      "grad_norm": 2.8842387199401855,
      "learning_rate": 4.537269743806903e-05,
      "loss": 1.2265,
      "step": 87450
    },
    {
      "epoch": 0.9263131150057431,
      "grad_norm": 2.5146634578704834,
      "learning_rate": 4.537005081515986e-05,
      "loss": 1.2231,
      "step": 87500
    },
    {
      "epoch": 0.9263131150057431,
      "eval_loss": 1.1627733707427979,
      "eval_runtime": 46.6397,
      "eval_samples_per_second": 3600.584,
      "eval_steps_per_second": 450.089,
      "step": 87500
    },
    {
      "epoch": 0.9268424367857464,
      "grad_norm": 2.4016807079315186,
      "learning_rate": 4.536740419225069e-05,
      "loss": 1.2202,
      "step": 87550
    },
    {
      "epoch": 0.9273717585657497,
      "grad_norm": 2.2813940048217773,
      "learning_rate": 4.536475756934152e-05,
      "loss": 1.2447,
      "step": 87600
    },
    {
      "epoch": 0.927901080345753,
      "grad_norm": 2.3911471366882324,
      "learning_rate": 4.5362110946432356e-05,
      "loss": 1.2202,
      "step": 87650
    },
    {
      "epoch": 0.9284304021257562,
      "grad_norm": 2.428691864013672,
      "learning_rate": 4.535946432352319e-05,
      "loss": 1.258,
      "step": 87700
    },
    {
      "epoch": 0.9289597239057595,
      "grad_norm": 2.7485430240631104,
      "learning_rate": 4.535681770061402e-05,
      "loss": 1.2326,
      "step": 87750
    },
    {
      "epoch": 0.9294890456857628,
      "grad_norm": 3.1152124404907227,
      "learning_rate": 4.535417107770485e-05,
      "loss": 1.2376,
      "step": 87800
    },
    {
      "epoch": 0.9300183674657662,
      "grad_norm": 2.3673646450042725,
      "learning_rate": 4.5351524454795686e-05,
      "loss": 1.2475,
      "step": 87850
    },
    {
      "epoch": 0.9305476892457694,
      "grad_norm": 2.6867387294769287,
      "learning_rate": 4.534887783188651e-05,
      "loss": 1.232,
      "step": 87900
    },
    {
      "epoch": 0.9310770110257727,
      "grad_norm": 2.8923020362854004,
      "learning_rate": 4.534623120897735e-05,
      "loss": 1.2265,
      "step": 87950
    },
    {
      "epoch": 0.931606332805776,
      "grad_norm": 2.7142035961151123,
      "learning_rate": 4.5343584586068175e-05,
      "loss": 1.2359,
      "step": 88000
    },
    {
      "epoch": 0.931606332805776,
      "eval_loss": 1.162402629852295,
      "eval_runtime": 46.6955,
      "eval_samples_per_second": 3596.275,
      "eval_steps_per_second": 449.55,
      "step": 88000
    },
    {
      "epoch": 0.9321356545857793,
      "grad_norm": 2.4908337593078613,
      "learning_rate": 4.5340990895617196e-05,
      "loss": 1.2125,
      "step": 88050
    },
    {
      "epoch": 0.9326649763657825,
      "grad_norm": 2.536959171295166,
      "learning_rate": 4.533834427270803e-05,
      "loss": 1.2386,
      "step": 88100
    },
    {
      "epoch": 0.9331942981457858,
      "grad_norm": 2.2137465476989746,
      "learning_rate": 4.533569764979886e-05,
      "loss": 1.2525,
      "step": 88150
    },
    {
      "epoch": 0.9337236199257891,
      "grad_norm": 2.6678287982940674,
      "learning_rate": 4.533305102688969e-05,
      "loss": 1.231,
      "step": 88200
    },
    {
      "epoch": 0.9342529417057923,
      "grad_norm": 2.353732109069824,
      "learning_rate": 4.5330404403980526e-05,
      "loss": 1.2145,
      "step": 88250
    },
    {
      "epoch": 0.9347822634857956,
      "grad_norm": 2.60588002204895,
      "learning_rate": 4.532775778107135e-05,
      "loss": 1.2415,
      "step": 88300
    },
    {
      "epoch": 0.9353115852657989,
      "grad_norm": 2.4072842597961426,
      "learning_rate": 4.532511115816219e-05,
      "loss": 1.2377,
      "step": 88350
    },
    {
      "epoch": 0.9358409070458023,
      "grad_norm": 2.82771372795105,
      "learning_rate": 4.5322464535253015e-05,
      "loss": 1.244,
      "step": 88400
    },
    {
      "epoch": 0.9363702288258055,
      "grad_norm": 2.3515617847442627,
      "learning_rate": 4.5319817912343855e-05,
      "loss": 1.2268,
      "step": 88450
    },
    {
      "epoch": 0.9368995506058088,
      "grad_norm": 2.590291976928711,
      "learning_rate": 4.531717128943468e-05,
      "loss": 1.2281,
      "step": 88500
    },
    {
      "epoch": 0.9368995506058088,
      "eval_loss": 1.158159613609314,
      "eval_runtime": 46.6278,
      "eval_samples_per_second": 3601.502,
      "eval_steps_per_second": 450.204,
      "step": 88500
    },
    {
      "epoch": 0.9374288723858121,
      "grad_norm": 2.4353885650634766,
      "learning_rate": 4.531452466652552e-05,
      "loss": 1.2368,
      "step": 88550
    },
    {
      "epoch": 0.9379581941658154,
      "grad_norm": 2.4752285480499268,
      "learning_rate": 4.5311878043616344e-05,
      "loss": 1.216,
      "step": 88600
    },
    {
      "epoch": 0.9384875159458186,
      "grad_norm": 2.424436330795288,
      "learning_rate": 4.5309231420707185e-05,
      "loss": 1.225,
      "step": 88650
    },
    {
      "epoch": 0.9390168377258219,
      "grad_norm": 2.43196964263916,
      "learning_rate": 4.530658479779801e-05,
      "loss": 1.2003,
      "step": 88700
    },
    {
      "epoch": 0.9395461595058252,
      "grad_norm": 2.6149966716766357,
      "learning_rate": 4.5303938174888847e-05,
      "loss": 1.2372,
      "step": 88750
    },
    {
      "epoch": 0.9400754812858285,
      "grad_norm": 2.4482085704803467,
      "learning_rate": 4.5301291551979674e-05,
      "loss": 1.2279,
      "step": 88800
    },
    {
      "epoch": 0.9406048030658317,
      "grad_norm": 2.528202533721924,
      "learning_rate": 4.529864492907051e-05,
      "loss": 1.2336,
      "step": 88850
    },
    {
      "epoch": 0.941134124845835,
      "grad_norm": 2.534538745880127,
      "learning_rate": 4.529599830616134e-05,
      "loss": 1.2312,
      "step": 88900
    },
    {
      "epoch": 0.9416634466258383,
      "grad_norm": 2.578150987625122,
      "learning_rate": 4.529335168325217e-05,
      "loss": 1.22,
      "step": 88950
    },
    {
      "epoch": 0.9421927684058415,
      "grad_norm": 2.506617307662964,
      "learning_rate": 4.5290705060343003e-05,
      "loss": 1.2276,
      "step": 89000
    },
    {
      "epoch": 0.9421927684058415,
      "eval_loss": 1.1535885334014893,
      "eval_runtime": 46.5612,
      "eval_samples_per_second": 3606.65,
      "eval_steps_per_second": 450.847,
      "step": 89000
    },
    {
      "epoch": 0.9427220901858449,
      "grad_norm": 2.396352767944336,
      "learning_rate": 4.528805843743384e-05,
      "loss": 1.235,
      "step": 89050
    },
    {
      "epoch": 0.9432514119658482,
      "grad_norm": 2.5155446529388428,
      "learning_rate": 4.528541181452467e-05,
      "loss": 1.2154,
      "step": 89100
    },
    {
      "epoch": 0.9437807337458515,
      "grad_norm": 2.623166084289551,
      "learning_rate": 4.52827651916155e-05,
      "loss": 1.2388,
      "step": 89150
    },
    {
      "epoch": 0.9443100555258547,
      "grad_norm": 2.8101963996887207,
      "learning_rate": 4.528011856870633e-05,
      "loss": 1.239,
      "step": 89200
    },
    {
      "epoch": 0.944839377305858,
      "grad_norm": 2.434828281402588,
      "learning_rate": 4.527747194579717e-05,
      "loss": 1.2346,
      "step": 89250
    },
    {
      "epoch": 0.9453686990858613,
      "grad_norm": 2.6790378093719482,
      "learning_rate": 4.5274825322888e-05,
      "loss": 1.2339,
      "step": 89300
    },
    {
      "epoch": 0.9458980208658646,
      "grad_norm": 2.3232574462890625,
      "learning_rate": 4.527217869997883e-05,
      "loss": 1.2332,
      "step": 89350
    },
    {
      "epoch": 0.9464273426458678,
      "grad_norm": 2.4822614192962646,
      "learning_rate": 4.526953207706966e-05,
      "loss": 1.2259,
      "step": 89400
    },
    {
      "epoch": 0.9469566644258711,
      "grad_norm": 2.465355396270752,
      "learning_rate": 4.52668854541605e-05,
      "loss": 1.2199,
      "step": 89450
    },
    {
      "epoch": 0.9474859862058744,
      "grad_norm": 2.7283313274383545,
      "learning_rate": 4.5264238831251324e-05,
      "loss": 1.2114,
      "step": 89500
    },
    {
      "epoch": 0.9474859862058744,
      "eval_loss": 1.1542372703552246,
      "eval_runtime": 46.6218,
      "eval_samples_per_second": 3601.96,
      "eval_steps_per_second": 450.261,
      "step": 89500
    },
    {
      "epoch": 0.9480153079858777,
      "grad_norm": 2.8868753910064697,
      "learning_rate": 4.526159220834216e-05,
      "loss": 1.2257,
      "step": 89550
    },
    {
      "epoch": 0.9485446297658809,
      "grad_norm": 2.746748208999634,
      "learning_rate": 4.5258945585432986e-05,
      "loss": 1.2172,
      "step": 89600
    },
    {
      "epoch": 0.9490739515458843,
      "grad_norm": 2.3975906372070312,
      "learning_rate": 4.5256298962523826e-05,
      "loss": 1.2276,
      "step": 89650
    },
    {
      "epoch": 0.9496032733258876,
      "grad_norm": 2.4230220317840576,
      "learning_rate": 4.5253652339614654e-05,
      "loss": 1.222,
      "step": 89700
    },
    {
      "epoch": 0.9501325951058909,
      "grad_norm": 2.5464670658111572,
      "learning_rate": 4.525100571670549e-05,
      "loss": 1.2388,
      "step": 89750
    },
    {
      "epoch": 0.9506619168858941,
      "grad_norm": 2.420125722885132,
      "learning_rate": 4.5248359093796315e-05,
      "loss": 1.2372,
      "step": 89800
    },
    {
      "epoch": 0.9511912386658974,
      "grad_norm": 2.70637583732605,
      "learning_rate": 4.5245712470887156e-05,
      "loss": 1.2251,
      "step": 89850
    },
    {
      "epoch": 0.9517205604459007,
      "grad_norm": 2.6295273303985596,
      "learning_rate": 4.5243065847977983e-05,
      "loss": 1.2351,
      "step": 89900
    },
    {
      "epoch": 0.9522498822259039,
      "grad_norm": 2.4014484882354736,
      "learning_rate": 4.524041922506882e-05,
      "loss": 1.2331,
      "step": 89950
    },
    {
      "epoch": 0.9527792040059072,
      "grad_norm": 2.744617462158203,
      "learning_rate": 4.5237772602159645e-05,
      "loss": 1.2309,
      "step": 90000
    },
    {
      "epoch": 0.9527792040059072,
      "eval_loss": 1.149709701538086,
      "eval_runtime": 46.587,
      "eval_samples_per_second": 3604.657,
      "eval_steps_per_second": 450.598,
      "step": 90000
    },
    {
      "epoch": 0.9533085257859105,
      "grad_norm": 2.4934635162353516,
      "learning_rate": 4.523512597925048e-05,
      "loss": 1.2377,
      "step": 90050
    },
    {
      "epoch": 0.9538378475659138,
      "grad_norm": 2.584907293319702,
      "learning_rate": 4.523247935634131e-05,
      "loss": 1.2296,
      "step": 90100
    },
    {
      "epoch": 0.954367169345917,
      "grad_norm": 2.4756269454956055,
      "learning_rate": 4.522983273343214e-05,
      "loss": 1.2283,
      "step": 90150
    },
    {
      "epoch": 0.9548964911259203,
      "grad_norm": 2.644979953765869,
      "learning_rate": 4.5227186110522974e-05,
      "loss": 1.2519,
      "step": 90200
    },
    {
      "epoch": 0.9554258129059237,
      "grad_norm": 2.501049041748047,
      "learning_rate": 4.522453948761381e-05,
      "loss": 1.2264,
      "step": 90250
    },
    {
      "epoch": 0.955955134685927,
      "grad_norm": 2.79435658454895,
      "learning_rate": 4.522189286470464e-05,
      "loss": 1.2013,
      "step": 90300
    },
    {
      "epoch": 0.9564844564659302,
      "grad_norm": 2.776370048522949,
      "learning_rate": 4.521924624179547e-05,
      "loss": 1.224,
      "step": 90350
    },
    {
      "epoch": 0.9570137782459335,
      "grad_norm": 2.758798360824585,
      "learning_rate": 4.5216599618886304e-05,
      "loss": 1.2283,
      "step": 90400
    },
    {
      "epoch": 0.9575431000259368,
      "grad_norm": 2.5633792877197266,
      "learning_rate": 4.521395299597714e-05,
      "loss": 1.2334,
      "step": 90450
    },
    {
      "epoch": 0.9580724218059401,
      "grad_norm": 2.45245099067688,
      "learning_rate": 4.5211306373067966e-05,
      "loss": 1.19,
      "step": 90500
    },
    {
      "epoch": 0.9580724218059401,
      "eval_loss": 1.145477056503296,
      "eval_runtime": 46.5861,
      "eval_samples_per_second": 3604.727,
      "eval_steps_per_second": 450.607,
      "step": 90500
    },
    {
      "epoch": 0.9586017435859433,
      "grad_norm": 2.6403558254241943,
      "learning_rate": 4.52086597501588e-05,
      "loss": 1.2102,
      "step": 90550
    },
    {
      "epoch": 0.9591310653659466,
      "grad_norm": 2.979990243911743,
      "learning_rate": 4.520601312724963e-05,
      "loss": 1.2048,
      "step": 90600
    },
    {
      "epoch": 0.9596603871459499,
      "grad_norm": 2.5927934646606445,
      "learning_rate": 4.520336650434047e-05,
      "loss": 1.222,
      "step": 90650
    },
    {
      "epoch": 0.9601897089259531,
      "grad_norm": 2.3476998805999756,
      "learning_rate": 4.520077281388948e-05,
      "loss": 1.2288,
      "step": 90700
    },
    {
      "epoch": 0.9607190307059564,
      "grad_norm": 2.5271921157836914,
      "learning_rate": 4.519812619098031e-05,
      "loss": 1.2313,
      "step": 90750
    },
    {
      "epoch": 0.9612483524859597,
      "grad_norm": 2.448782205581665,
      "learning_rate": 4.5195479568071144e-05,
      "loss": 1.2296,
      "step": 90800
    },
    {
      "epoch": 0.9617776742659631,
      "grad_norm": 2.4676477909088135,
      "learning_rate": 4.519283294516198e-05,
      "loss": 1.2343,
      "step": 90850
    },
    {
      "epoch": 0.9623069960459663,
      "grad_norm": 2.709484577178955,
      "learning_rate": 4.519018632225281e-05,
      "loss": 1.2355,
      "step": 90900
    },
    {
      "epoch": 0.9628363178259696,
      "grad_norm": 2.708937168121338,
      "learning_rate": 4.518753969934364e-05,
      "loss": 1.2167,
      "step": 90950
    },
    {
      "epoch": 0.9633656396059729,
      "grad_norm": 2.6538467407226562,
      "learning_rate": 4.5184893076434474e-05,
      "loss": 1.2262,
      "step": 91000
    },
    {
      "epoch": 0.9633656396059729,
      "eval_loss": 1.1474653482437134,
      "eval_runtime": 46.7536,
      "eval_samples_per_second": 3591.807,
      "eval_steps_per_second": 448.992,
      "step": 91000
    },
    {
      "epoch": 0.9638949613859762,
      "grad_norm": 2.572901487350464,
      "learning_rate": 4.518224645352531e-05,
      "loss": 1.2248,
      "step": 91050
    },
    {
      "epoch": 0.9644242831659794,
      "grad_norm": 2.4852793216705322,
      "learning_rate": 4.5179599830616135e-05,
      "loss": 1.2026,
      "step": 91100
    },
    {
      "epoch": 0.9649536049459827,
      "grad_norm": 2.4065585136413574,
      "learning_rate": 4.517695320770697e-05,
      "loss": 1.243,
      "step": 91150
    },
    {
      "epoch": 0.965482926725986,
      "grad_norm": 2.4975314140319824,
      "learning_rate": 4.5174306584797796e-05,
      "loss": 1.2211,
      "step": 91200
    },
    {
      "epoch": 0.9660122485059893,
      "grad_norm": 2.481889486312866,
      "learning_rate": 4.517165996188864e-05,
      "loss": 1.2151,
      "step": 91250
    },
    {
      "epoch": 0.9665415702859925,
      "grad_norm": 2.477389335632324,
      "learning_rate": 4.5169013338979465e-05,
      "loss": 1.2336,
      "step": 91300
    },
    {
      "epoch": 0.9670708920659958,
      "grad_norm": 2.491659641265869,
      "learning_rate": 4.51663667160703e-05,
      "loss": 1.2137,
      "step": 91350
    },
    {
      "epoch": 0.9676002138459991,
      "grad_norm": 2.5564327239990234,
      "learning_rate": 4.5163720093161126e-05,
      "loss": 1.2104,
      "step": 91400
    },
    {
      "epoch": 0.9681295356260025,
      "grad_norm": 2.5327115058898926,
      "learning_rate": 4.516107347025196e-05,
      "loss": 1.2274,
      "step": 91450
    },
    {
      "epoch": 0.9686588574060057,
      "grad_norm": 2.6854054927825928,
      "learning_rate": 4.5158426847342794e-05,
      "loss": 1.2106,
      "step": 91500
    },
    {
      "epoch": 0.9686588574060057,
      "eval_loss": 1.141774296760559,
      "eval_runtime": 46.6574,
      "eval_samples_per_second": 3599.216,
      "eval_steps_per_second": 449.918,
      "step": 91500
    },
    {
      "epoch": 0.969188179186009,
      "grad_norm": 2.654768943786621,
      "learning_rate": 4.515578022443362e-05,
      "loss": 1.2102,
      "step": 91550
    },
    {
      "epoch": 0.9697175009660123,
      "grad_norm": 2.414593458175659,
      "learning_rate": 4.5153133601524456e-05,
      "loss": 1.2055,
      "step": 91600
    },
    {
      "epoch": 0.9702468227460155,
      "grad_norm": 2.649836778640747,
      "learning_rate": 4.515048697861529e-05,
      "loss": 1.2328,
      "step": 91650
    },
    {
      "epoch": 0.9707761445260188,
      "grad_norm": 2.64357852935791,
      "learning_rate": 4.5147840355706124e-05,
      "loss": 1.2144,
      "step": 91700
    },
    {
      "epoch": 0.9713054663060221,
      "grad_norm": 2.3448054790496826,
      "learning_rate": 4.514519373279695e-05,
      "loss": 1.2123,
      "step": 91750
    },
    {
      "epoch": 0.9718347880860254,
      "grad_norm": 2.3439841270446777,
      "learning_rate": 4.5142547109887785e-05,
      "loss": 1.211,
      "step": 91800
    },
    {
      "epoch": 0.9723641098660286,
      "grad_norm": 2.740250825881958,
      "learning_rate": 4.513990048697862e-05,
      "loss": 1.2065,
      "step": 91850
    },
    {
      "epoch": 0.9728934316460319,
      "grad_norm": 2.634611129760742,
      "learning_rate": 4.5137253864069453e-05,
      "loss": 1.2174,
      "step": 91900
    },
    {
      "epoch": 0.9734227534260352,
      "grad_norm": 2.421633005142212,
      "learning_rate": 4.513460724116028e-05,
      "loss": 1.2196,
      "step": 91950
    },
    {
      "epoch": 0.9739520752060385,
      "grad_norm": 2.5686910152435303,
      "learning_rate": 4.5131960618251115e-05,
      "loss": 1.2352,
      "step": 92000
    },
    {
      "epoch": 0.9739520752060385,
      "eval_loss": 1.1395981311798096,
      "eval_runtime": 46.6164,
      "eval_samples_per_second": 3602.378,
      "eval_steps_per_second": 450.313,
      "step": 92000
    },
    {
      "epoch": 0.9744813969860417,
      "grad_norm": 2.1631805896759033,
      "learning_rate": 4.512931399534195e-05,
      "loss": 1.2067,
      "step": 92050
    },
    {
      "epoch": 0.9750107187660451,
      "grad_norm": 2.6897473335266113,
      "learning_rate": 4.5126667372432776e-05,
      "loss": 1.1982,
      "step": 92100
    },
    {
      "epoch": 0.9755400405460484,
      "grad_norm": 2.4183778762817383,
      "learning_rate": 4.512402074952361e-05,
      "loss": 1.2181,
      "step": 92150
    },
    {
      "epoch": 0.9760693623260517,
      "grad_norm": 2.5095877647399902,
      "learning_rate": 4.512137412661444e-05,
      "loss": 1.2144,
      "step": 92200
    },
    {
      "epoch": 0.9765986841060549,
      "grad_norm": 2.6838223934173584,
      "learning_rate": 4.511872750370527e-05,
      "loss": 1.2104,
      "step": 92250
    },
    {
      "epoch": 0.9771280058860582,
      "grad_norm": 2.6020543575286865,
      "learning_rate": 4.5116080880796106e-05,
      "loss": 1.2321,
      "step": 92300
    },
    {
      "epoch": 0.9776573276660615,
      "grad_norm": 2.72658371925354,
      "learning_rate": 4.511343425788694e-05,
      "loss": 1.2168,
      "step": 92350
    },
    {
      "epoch": 0.9781866494460647,
      "grad_norm": 2.663630723953247,
      "learning_rate": 4.511078763497777e-05,
      "loss": 1.2127,
      "step": 92400
    },
    {
      "epoch": 0.978715971226068,
      "grad_norm": 2.6824371814727783,
      "learning_rate": 4.51081410120686e-05,
      "loss": 1.2202,
      "step": 92450
    },
    {
      "epoch": 0.9792452930060713,
      "grad_norm": 2.7818453311920166,
      "learning_rate": 4.5105494389159436e-05,
      "loss": 1.2179,
      "step": 92500
    },
    {
      "epoch": 0.9792452930060713,
      "eval_loss": 1.138104796409607,
      "eval_runtime": 46.6191,
      "eval_samples_per_second": 3602.173,
      "eval_steps_per_second": 450.288,
      "step": 92500
    },
    {
      "epoch": 0.9797746147860746,
      "grad_norm": 2.607520580291748,
      "learning_rate": 4.510284776625027e-05,
      "loss": 1.2109,
      "step": 92550
    },
    {
      "epoch": 0.9803039365660778,
      "grad_norm": 2.5013773441314697,
      "learning_rate": 4.51002011433411e-05,
      "loss": 1.2059,
      "step": 92600
    },
    {
      "epoch": 0.9808332583460811,
      "grad_norm": 2.627023935317993,
      "learning_rate": 4.509755452043193e-05,
      "loss": 1.2189,
      "step": 92650
    },
    {
      "epoch": 0.9813625801260845,
      "grad_norm": 2.636054039001465,
      "learning_rate": 4.5094907897522765e-05,
      "loss": 1.2253,
      "step": 92700
    },
    {
      "epoch": 0.9818919019060878,
      "grad_norm": 2.486388683319092,
      "learning_rate": 4.509231420707178e-05,
      "loss": 1.1972,
      "step": 92750
    },
    {
      "epoch": 0.982421223686091,
      "grad_norm": 2.6880619525909424,
      "learning_rate": 4.508966758416261e-05,
      "loss": 1.2164,
      "step": 92800
    },
    {
      "epoch": 0.9829505454660943,
      "grad_norm": 2.590017557144165,
      "learning_rate": 4.508702096125345e-05,
      "loss": 1.2081,
      "step": 92850
    },
    {
      "epoch": 0.9834798672460976,
      "grad_norm": 2.4281728267669678,
      "learning_rate": 4.5084374338344275e-05,
      "loss": 1.2098,
      "step": 92900
    },
    {
      "epoch": 0.9840091890261009,
      "grad_norm": 2.622837781906128,
      "learning_rate": 4.508172771543511e-05,
      "loss": 1.2055,
      "step": 92950
    },
    {
      "epoch": 0.9845385108061041,
      "grad_norm": 2.6154613494873047,
      "learning_rate": 4.507908109252594e-05,
      "loss": 1.1952,
      "step": 93000
    },
    {
      "epoch": 0.9845385108061041,
      "eval_loss": 1.1331887245178223,
      "eval_runtime": 46.5744,
      "eval_samples_per_second": 3605.627,
      "eval_steps_per_second": 450.719,
      "step": 93000
    },
    {
      "epoch": 0.9850678325861074,
      "grad_norm": 3.056642770767212,
      "learning_rate": 4.507643446961677e-05,
      "loss": 1.2069,
      "step": 93050
    },
    {
      "epoch": 0.9855971543661107,
      "grad_norm": 2.3177411556243896,
      "learning_rate": 4.5073787846707605e-05,
      "loss": 1.1975,
      "step": 93100
    },
    {
      "epoch": 0.986126476146114,
      "grad_norm": 2.4454843997955322,
      "learning_rate": 4.507114122379843e-05,
      "loss": 1.2149,
      "step": 93150
    },
    {
      "epoch": 0.9866557979261172,
      "grad_norm": 2.5392072200775146,
      "learning_rate": 4.5068494600889266e-05,
      "loss": 1.2133,
      "step": 93200
    },
    {
      "epoch": 0.9871851197061206,
      "grad_norm": 2.52946400642395,
      "learning_rate": 4.5065847977980094e-05,
      "loss": 1.2301,
      "step": 93250
    },
    {
      "epoch": 0.9877144414861239,
      "grad_norm": 2.589766502380371,
      "learning_rate": 4.5063201355070935e-05,
      "loss": 1.197,
      "step": 93300
    },
    {
      "epoch": 0.9882437632661271,
      "grad_norm": 2.593355655670166,
      "learning_rate": 4.506055473216176e-05,
      "loss": 1.2085,
      "step": 93350
    },
    {
      "epoch": 0.9887730850461304,
      "grad_norm": 2.578664541244507,
      "learning_rate": 4.5057908109252596e-05,
      "loss": 1.2069,
      "step": 93400
    },
    {
      "epoch": 0.9893024068261337,
      "grad_norm": 2.669210433959961,
      "learning_rate": 4.5055261486343423e-05,
      "loss": 1.2227,
      "step": 93450
    },
    {
      "epoch": 0.989831728606137,
      "grad_norm": 2.6537861824035645,
      "learning_rate": 4.5052614863434264e-05,
      "loss": 1.2193,
      "step": 93500
    },
    {
      "epoch": 0.989831728606137,
      "eval_loss": 1.133939504623413,
      "eval_runtime": 46.6682,
      "eval_samples_per_second": 3598.382,
      "eval_steps_per_second": 449.814,
      "step": 93500
    },
    {
      "epoch": 0.9903610503861402,
      "grad_norm": 2.7522900104522705,
      "learning_rate": 4.504996824052509e-05,
      "loss": 1.2504,
      "step": 93550
    },
    {
      "epoch": 0.9908903721661435,
      "grad_norm": 2.568690299987793,
      "learning_rate": 4.5047321617615926e-05,
      "loss": 1.2139,
      "step": 93600
    },
    {
      "epoch": 0.9914196939461468,
      "grad_norm": 2.3710131645202637,
      "learning_rate": 4.504467499470675e-05,
      "loss": 1.2325,
      "step": 93650
    },
    {
      "epoch": 0.9919490157261501,
      "grad_norm": 2.778029203414917,
      "learning_rate": 4.504202837179759e-05,
      "loss": 1.2071,
      "step": 93700
    },
    {
      "epoch": 0.9924783375061533,
      "grad_norm": 2.7454304695129395,
      "learning_rate": 4.503938174888842e-05,
      "loss": 1.2028,
      "step": 93750
    },
    {
      "epoch": 0.9930076592861566,
      "grad_norm": 2.7110538482666016,
      "learning_rate": 4.503673512597925e-05,
      "loss": 1.2111,
      "step": 93800
    },
    {
      "epoch": 0.99353698106616,
      "grad_norm": 2.3326876163482666,
      "learning_rate": 4.503408850307008e-05,
      "loss": 1.2101,
      "step": 93850
    },
    {
      "epoch": 0.9940663028461633,
      "grad_norm": 2.6391186714172363,
      "learning_rate": 4.503144188016092e-05,
      "loss": 1.2017,
      "step": 93900
    },
    {
      "epoch": 0.9945956246261665,
      "grad_norm": 2.6043481826782227,
      "learning_rate": 4.502879525725175e-05,
      "loss": 1.2266,
      "step": 93950
    },
    {
      "epoch": 0.9951249464061698,
      "grad_norm": 2.5982556343078613,
      "learning_rate": 4.502614863434258e-05,
      "loss": 1.1934,
      "step": 94000
    },
    {
      "epoch": 0.9951249464061698,
      "eval_loss": 1.129612922668457,
      "eval_runtime": 46.625,
      "eval_samples_per_second": 3601.714,
      "eval_steps_per_second": 450.23,
      "step": 94000
    },
    {
      "epoch": 0.9956542681861731,
      "grad_norm": 2.5650548934936523,
      "learning_rate": 4.502350201143341e-05,
      "loss": 1.1924,
      "step": 94050
    },
    {
      "epoch": 0.9961835899661763,
      "grad_norm": 2.4114863872528076,
      "learning_rate": 4.5020855388524246e-05,
      "loss": 1.2224,
      "step": 94100
    },
    {
      "epoch": 0.9967129117461796,
      "grad_norm": 2.70800518989563,
      "learning_rate": 4.501820876561508e-05,
      "loss": 1.2102,
      "step": 94150
    },
    {
      "epoch": 0.9972422335261829,
      "grad_norm": 2.398667097091675,
      "learning_rate": 4.501556214270591e-05,
      "loss": 1.1993,
      "step": 94200
    },
    {
      "epoch": 0.9977715553061862,
      "grad_norm": 2.938997268676758,
      "learning_rate": 4.501291551979674e-05,
      "loss": 1.1844,
      "step": 94250
    },
    {
      "epoch": 0.9983008770861894,
      "grad_norm": 2.521505117416382,
      "learning_rate": 4.5010268896887576e-05,
      "loss": 1.1823,
      "step": 94300
    },
    {
      "epoch": 0.9988301988661927,
      "grad_norm": 2.592238187789917,
      "learning_rate": 4.50076222739784e-05,
      "loss": 1.2003,
      "step": 94350
    },
    {
      "epoch": 0.999359520646196,
      "grad_norm": 2.9454212188720703,
      "learning_rate": 4.500497565106924e-05,
      "loss": 1.2152,
      "step": 94400
    },
    {
      "epoch": 0.9998888424261994,
      "grad_norm": 2.74375057220459,
      "learning_rate": 4.5002329028160065e-05,
      "loss": 1.1893,
      "step": 94450
    },
    {
      "epoch": 1.0004128709884026,
      "grad_norm": 2.6968472003936768,
      "learning_rate": 4.4999682405250906e-05,
      "loss": 1.2119,
      "step": 94500
    },
    {
      "epoch": 1.0004128709884026,
      "eval_loss": 1.1267532110214233,
      "eval_runtime": 46.6487,
      "eval_samples_per_second": 3599.882,
      "eval_steps_per_second": 450.001,
      "step": 94500
    },
    {
      "epoch": 1.000942192768406,
      "grad_norm": 2.6684200763702393,
      "learning_rate": 4.499703578234173e-05,
      "loss": 1.2003,
      "step": 94550
    },
    {
      "epoch": 1.0014715145484092,
      "grad_norm": 2.8228886127471924,
      "learning_rate": 4.499438915943257e-05,
      "loss": 1.1907,
      "step": 94600
    },
    {
      "epoch": 1.0020008363284123,
      "grad_norm": 2.6700034141540527,
      "learning_rate": 4.4991742536523394e-05,
      "loss": 1.2012,
      "step": 94650
    },
    {
      "epoch": 1.0025301581084156,
      "grad_norm": 2.7624287605285645,
      "learning_rate": 4.4989095913614235e-05,
      "loss": 1.1933,
      "step": 94700
    },
    {
      "epoch": 1.003059479888419,
      "grad_norm": 2.513310670852661,
      "learning_rate": 4.498650222316324e-05,
      "loss": 1.1998,
      "step": 94750
    },
    {
      "epoch": 1.0035888016684222,
      "grad_norm": 2.67747163772583,
      "learning_rate": 4.498385560025408e-05,
      "loss": 1.196,
      "step": 94800
    },
    {
      "epoch": 1.0041181234484255,
      "grad_norm": 2.7604305744171143,
      "learning_rate": 4.4981208977344905e-05,
      "loss": 1.1986,
      "step": 94850
    },
    {
      "epoch": 1.0046474452284289,
      "grad_norm": 2.598634958267212,
      "learning_rate": 4.4978562354435745e-05,
      "loss": 1.1771,
      "step": 94900
    },
    {
      "epoch": 1.0051767670084322,
      "grad_norm": 2.4693381786346436,
      "learning_rate": 4.497591573152657e-05,
      "loss": 1.1999,
      "step": 94950
    },
    {
      "epoch": 1.0057060887884355,
      "grad_norm": 2.595698833465576,
      "learning_rate": 4.497326910861741e-05,
      "loss": 1.2294,
      "step": 95000
    },
    {
      "epoch": 1.0057060887884355,
      "eval_loss": 1.1237713098526,
      "eval_runtime": 46.6148,
      "eval_samples_per_second": 3602.506,
      "eval_steps_per_second": 450.329,
      "step": 95000
    },
    {
      "epoch": 1.0062354105684386,
      "grad_norm": 2.722541332244873,
      "learning_rate": 4.4970622485708234e-05,
      "loss": 1.2058,
      "step": 95050
    },
    {
      "epoch": 1.0067647323484419,
      "grad_norm": 2.5157268047332764,
      "learning_rate": 4.4967975862799075e-05,
      "loss": 1.1929,
      "step": 95100
    },
    {
      "epoch": 1.0072940541284452,
      "grad_norm": 2.6611366271972656,
      "learning_rate": 4.49653292398899e-05,
      "loss": 1.2034,
      "step": 95150
    },
    {
      "epoch": 1.0078233759084485,
      "grad_norm": 2.767338514328003,
      "learning_rate": 4.4962682616980737e-05,
      "loss": 1.2026,
      "step": 95200
    },
    {
      "epoch": 1.0083526976884518,
      "grad_norm": 2.750023603439331,
      "learning_rate": 4.4960035994071564e-05,
      "loss": 1.2,
      "step": 95250
    },
    {
      "epoch": 1.0088820194684551,
      "grad_norm": 2.6196908950805664,
      "learning_rate": 4.49573893711624e-05,
      "loss": 1.189,
      "step": 95300
    },
    {
      "epoch": 1.0094113412484584,
      "grad_norm": 2.5366320610046387,
      "learning_rate": 4.495474274825323e-05,
      "loss": 1.1994,
      "step": 95350
    },
    {
      "epoch": 1.0099406630284615,
      "grad_norm": 2.867853879928589,
      "learning_rate": 4.495209612534406e-05,
      "loss": 1.193,
      "step": 95400
    },
    {
      "epoch": 1.0104699848084648,
      "grad_norm": 2.6624927520751953,
      "learning_rate": 4.4949449502434893e-05,
      "loss": 1.19,
      "step": 95450
    },
    {
      "epoch": 1.0109993065884681,
      "grad_norm": 2.670408010482788,
      "learning_rate": 4.494680287952573e-05,
      "loss": 1.2138,
      "step": 95500
    },
    {
      "epoch": 1.0109993065884681,
      "eval_loss": 1.1221023797988892,
      "eval_runtime": 46.6504,
      "eval_samples_per_second": 3599.755,
      "eval_steps_per_second": 449.985,
      "step": 95500
    },
    {
      "epoch": 1.0115286283684715,
      "grad_norm": 2.6441988945007324,
      "learning_rate": 4.494415625661656e-05,
      "loss": 1.1877,
      "step": 95550
    },
    {
      "epoch": 1.0120579501484748,
      "grad_norm": 2.950894832611084,
      "learning_rate": 4.494150963370739e-05,
      "loss": 1.2079,
      "step": 95600
    },
    {
      "epoch": 1.012587271928478,
      "grad_norm": 2.6508548259735107,
      "learning_rate": 4.493886301079822e-05,
      "loss": 1.1923,
      "step": 95650
    },
    {
      "epoch": 1.0131165937084814,
      "grad_norm": 2.876368999481201,
      "learning_rate": 4.493621638788906e-05,
      "loss": 1.2074,
      "step": 95700
    },
    {
      "epoch": 1.0136459154884847,
      "grad_norm": 2.5963475704193115,
      "learning_rate": 4.493356976497989e-05,
      "loss": 1.1991,
      "step": 95750
    },
    {
      "epoch": 1.0141752372684878,
      "grad_norm": 2.7495381832122803,
      "learning_rate": 4.493092314207072e-05,
      "loss": 1.1923,
      "step": 95800
    },
    {
      "epoch": 1.014704559048491,
      "grad_norm": 2.3969149589538574,
      "learning_rate": 4.492827651916155e-05,
      "loss": 1.2047,
      "step": 95850
    },
    {
      "epoch": 1.0152338808284944,
      "grad_norm": 2.736389398574829,
      "learning_rate": 4.492562989625239e-05,
      "loss": 1.2045,
      "step": 95900
    },
    {
      "epoch": 1.0157632026084977,
      "grad_norm": 2.5783581733703613,
      "learning_rate": 4.4922983273343214e-05,
      "loss": 1.1864,
      "step": 95950
    },
    {
      "epoch": 1.016292524388501,
      "grad_norm": 2.7297637462615967,
      "learning_rate": 4.492033665043405e-05,
      "loss": 1.2114,
      "step": 96000
    },
    {
      "epoch": 1.016292524388501,
      "eval_loss": 1.1216219663619995,
      "eval_runtime": 46.6117,
      "eval_samples_per_second": 3602.742,
      "eval_steps_per_second": 450.359,
      "step": 96000
    },
    {
      "epoch": 1.0168218461685044,
      "grad_norm": 2.537904977798462,
      "learning_rate": 4.4917690027524876e-05,
      "loss": 1.1998,
      "step": 96050
    },
    {
      "epoch": 1.0173511679485077,
      "grad_norm": 2.3175160884857178,
      "learning_rate": 4.4915043404615716e-05,
      "loss": 1.1938,
      "step": 96100
    },
    {
      "epoch": 1.0178804897285108,
      "grad_norm": 2.6943418979644775,
      "learning_rate": 4.4912396781706544e-05,
      "loss": 1.2056,
      "step": 96150
    },
    {
      "epoch": 1.018409811508514,
      "grad_norm": 2.5064070224761963,
      "learning_rate": 4.490975015879738e-05,
      "loss": 1.1998,
      "step": 96200
    },
    {
      "epoch": 1.0189391332885174,
      "grad_norm": 3.029144525527954,
      "learning_rate": 4.4907103535888205e-05,
      "loss": 1.1949,
      "step": 96250
    },
    {
      "epoch": 1.0194684550685207,
      "grad_norm": 2.532878875732422,
      "learning_rate": 4.490445691297904e-05,
      "loss": 1.2087,
      "step": 96300
    },
    {
      "epoch": 1.019997776848524,
      "grad_norm": 2.59423565864563,
      "learning_rate": 4.4901810290069873e-05,
      "loss": 1.1975,
      "step": 96350
    },
    {
      "epoch": 1.0205270986285273,
      "grad_norm": 2.578768253326416,
      "learning_rate": 4.48991636671607e-05,
      "loss": 1.2048,
      "step": 96400
    },
    {
      "epoch": 1.0210564204085306,
      "grad_norm": 2.660773277282715,
      "learning_rate": 4.4896517044251535e-05,
      "loss": 1.216,
      "step": 96450
    },
    {
      "epoch": 1.021585742188534,
      "grad_norm": 2.781904697418213,
      "learning_rate": 4.489387042134237e-05,
      "loss": 1.196,
      "step": 96500
    },
    {
      "epoch": 1.021585742188534,
      "eval_loss": 1.115519404411316,
      "eval_runtime": 46.6903,
      "eval_samples_per_second": 3596.682,
      "eval_steps_per_second": 449.601,
      "step": 96500
    },
    {
      "epoch": 1.022115063968537,
      "grad_norm": 2.765439033508301,
      "learning_rate": 4.48912237984332e-05,
      "loss": 1.2031,
      "step": 96550
    },
    {
      "epoch": 1.0226443857485403,
      "grad_norm": 2.6572203636169434,
      "learning_rate": 4.488857717552403e-05,
      "loss": 1.1979,
      "step": 96600
    },
    {
      "epoch": 1.0231737075285436,
      "grad_norm": 2.9810986518859863,
      "learning_rate": 4.4885930552614864e-05,
      "loss": 1.1953,
      "step": 96650
    },
    {
      "epoch": 1.023703029308547,
      "grad_norm": 2.8658225536346436,
      "learning_rate": 4.48832839297057e-05,
      "loss": 1.1814,
      "step": 96700
    },
    {
      "epoch": 1.0242323510885503,
      "grad_norm": 2.651703119277954,
      "learning_rate": 4.488063730679653e-05,
      "loss": 1.194,
      "step": 96750
    },
    {
      "epoch": 1.0247616728685536,
      "grad_norm": 2.7446963787078857,
      "learning_rate": 4.487799068388736e-05,
      "loss": 1.1823,
      "step": 96800
    },
    {
      "epoch": 1.0252909946485569,
      "grad_norm": 2.711756944656372,
      "learning_rate": 4.4875344060978194e-05,
      "loss": 1.2022,
      "step": 96850
    },
    {
      "epoch": 1.0258203164285602,
      "grad_norm": 2.7674803733825684,
      "learning_rate": 4.487275037052721e-05,
      "loss": 1.2045,
      "step": 96900
    },
    {
      "epoch": 1.0263496382085633,
      "grad_norm": 2.6228818893432617,
      "learning_rate": 4.487010374761804e-05,
      "loss": 1.2105,
      "step": 96950
    },
    {
      "epoch": 1.0268789599885666,
      "grad_norm": 2.570579767227173,
      "learning_rate": 4.486745712470887e-05,
      "loss": 1.1961,
      "step": 97000
    },
    {
      "epoch": 1.0268789599885666,
      "eval_loss": 1.113303780555725,
      "eval_runtime": 46.5858,
      "eval_samples_per_second": 3604.748,
      "eval_steps_per_second": 450.61,
      "step": 97000
    },
    {
      "epoch": 1.02740828176857,
      "grad_norm": 2.678128480911255,
      "learning_rate": 4.4864810501799704e-05,
      "loss": 1.1852,
      "step": 97050
    },
    {
      "epoch": 1.0279376035485732,
      "grad_norm": 2.755983591079712,
      "learning_rate": 4.486216387889054e-05,
      "loss": 1.1956,
      "step": 97100
    },
    {
      "epoch": 1.0284669253285765,
      "grad_norm": 2.673049211502075,
      "learning_rate": 4.485951725598137e-05,
      "loss": 1.1936,
      "step": 97150
    },
    {
      "epoch": 1.0289962471085798,
      "grad_norm": 2.976895570755005,
      "learning_rate": 4.48568706330722e-05,
      "loss": 1.1854,
      "step": 97200
    },
    {
      "epoch": 1.0295255688885832,
      "grad_norm": 2.759705066680908,
      "learning_rate": 4.4854224010163034e-05,
      "loss": 1.1829,
      "step": 97250
    },
    {
      "epoch": 1.0300548906685862,
      "grad_norm": 2.9279778003692627,
      "learning_rate": 4.485157738725387e-05,
      "loss": 1.1934,
      "step": 97300
    },
    {
      "epoch": 1.0305842124485896,
      "grad_norm": 2.6039538383483887,
      "learning_rate": 4.48489307643447e-05,
      "loss": 1.1912,
      "step": 97350
    },
    {
      "epoch": 1.0311135342285929,
      "grad_norm": 2.5727972984313965,
      "learning_rate": 4.484628414143553e-05,
      "loss": 1.2004,
      "step": 97400
    },
    {
      "epoch": 1.0316428560085962,
      "grad_norm": 2.3635880947113037,
      "learning_rate": 4.4843637518526364e-05,
      "loss": 1.1923,
      "step": 97450
    },
    {
      "epoch": 1.0321721777885995,
      "grad_norm": 2.5842959880828857,
      "learning_rate": 4.48409908956172e-05,
      "loss": 1.2182,
      "step": 97500
    },
    {
      "epoch": 1.0321721777885995,
      "eval_loss": 1.1122515201568604,
      "eval_runtime": 46.6581,
      "eval_samples_per_second": 3599.161,
      "eval_steps_per_second": 449.911,
      "step": 97500
    },
    {
      "epoch": 1.0327014995686028,
      "grad_norm": 2.6772966384887695,
      "learning_rate": 4.4838344272708025e-05,
      "loss": 1.2214,
      "step": 97550
    },
    {
      "epoch": 1.033230821348606,
      "grad_norm": 2.6749660968780518,
      "learning_rate": 4.483569764979886e-05,
      "loss": 1.2123,
      "step": 97600
    },
    {
      "epoch": 1.0337601431286094,
      "grad_norm": 2.8024911880493164,
      "learning_rate": 4.4833051026889686e-05,
      "loss": 1.187,
      "step": 97650
    },
    {
      "epoch": 1.0342894649086125,
      "grad_norm": 2.7848544120788574,
      "learning_rate": 4.483040440398053e-05,
      "loss": 1.1991,
      "step": 97700
    },
    {
      "epoch": 1.0348187866886158,
      "grad_norm": 2.8453218936920166,
      "learning_rate": 4.4827757781071355e-05,
      "loss": 1.1938,
      "step": 97750
    },
    {
      "epoch": 1.0353481084686191,
      "grad_norm": 2.4799015522003174,
      "learning_rate": 4.482511115816219e-05,
      "loss": 1.1792,
      "step": 97800
    },
    {
      "epoch": 1.0358774302486224,
      "grad_norm": 2.789217472076416,
      "learning_rate": 4.4822464535253016e-05,
      "loss": 1.1782,
      "step": 97850
    },
    {
      "epoch": 1.0364067520286258,
      "grad_norm": 2.737130880355835,
      "learning_rate": 4.481981791234385e-05,
      "loss": 1.2073,
      "step": 97900
    },
    {
      "epoch": 1.036936073808629,
      "grad_norm": 2.7375059127807617,
      "learning_rate": 4.4817171289434684e-05,
      "loss": 1.2032,
      "step": 97950
    },
    {
      "epoch": 1.0374653955886324,
      "grad_norm": 2.698931932449341,
      "learning_rate": 4.481452466652551e-05,
      "loss": 1.2009,
      "step": 98000
    },
    {
      "epoch": 1.0374653955886324,
      "eval_loss": 1.1093608140945435,
      "eval_runtime": 46.5786,
      "eval_samples_per_second": 3605.307,
      "eval_steps_per_second": 450.679,
      "step": 98000
    },
    {
      "epoch": 1.0379947173686355,
      "grad_norm": 2.8361358642578125,
      "learning_rate": 4.4811878043616346e-05,
      "loss": 1.1922,
      "step": 98050
    },
    {
      "epoch": 1.0385240391486388,
      "grad_norm": 2.9175055027008057,
      "learning_rate": 4.480923142070718e-05,
      "loss": 1.1987,
      "step": 98100
    },
    {
      "epoch": 1.039053360928642,
      "grad_norm": 2.738677740097046,
      "learning_rate": 4.4806584797798014e-05,
      "loss": 1.1973,
      "step": 98150
    },
    {
      "epoch": 1.0395826827086454,
      "grad_norm": 2.6876423358917236,
      "learning_rate": 4.480393817488884e-05,
      "loss": 1.1965,
      "step": 98200
    },
    {
      "epoch": 1.0401120044886487,
      "grad_norm": 2.7843353748321533,
      "learning_rate": 4.4801291551979675e-05,
      "loss": 1.1695,
      "step": 98250
    },
    {
      "epoch": 1.040641326268652,
      "grad_norm": 2.760570764541626,
      "learning_rate": 4.479864492907051e-05,
      "loss": 1.1756,
      "step": 98300
    },
    {
      "epoch": 1.0411706480486553,
      "grad_norm": 2.7702932357788086,
      "learning_rate": 4.4795998306161343e-05,
      "loss": 1.1952,
      "step": 98350
    },
    {
      "epoch": 1.0416999698286586,
      "grad_norm": 2.4893791675567627,
      "learning_rate": 4.479335168325217e-05,
      "loss": 1.2016,
      "step": 98400
    },
    {
      "epoch": 1.0422292916086617,
      "grad_norm": 2.5226786136627197,
      "learning_rate": 4.4790705060343005e-05,
      "loss": 1.1886,
      "step": 98450
    },
    {
      "epoch": 1.042758613388665,
      "grad_norm": 2.784630060195923,
      "learning_rate": 4.478805843743384e-05,
      "loss": 1.2064,
      "step": 98500
    },
    {
      "epoch": 1.042758613388665,
      "eval_loss": 1.1075981855392456,
      "eval_runtime": 46.6828,
      "eval_samples_per_second": 3597.258,
      "eval_steps_per_second": 449.673,
      "step": 98500
    },
    {
      "epoch": 1.0432879351686684,
      "grad_norm": 2.367842435836792,
      "learning_rate": 4.4785411814524666e-05,
      "loss": 1.1925,
      "step": 98550
    },
    {
      "epoch": 1.0438172569486717,
      "grad_norm": 2.7465829849243164,
      "learning_rate": 4.47827651916155e-05,
      "loss": 1.178,
      "step": 98600
    },
    {
      "epoch": 1.044346578728675,
      "grad_norm": 2.71308970451355,
      "learning_rate": 4.478011856870633e-05,
      "loss": 1.2081,
      "step": 98650
    },
    {
      "epoch": 1.0448759005086783,
      "grad_norm": 3.0341334342956543,
      "learning_rate": 4.477747194579717e-05,
      "loss": 1.1893,
      "step": 98700
    },
    {
      "epoch": 1.0454052222886816,
      "grad_norm": 2.9160103797912598,
      "learning_rate": 4.4774825322887996e-05,
      "loss": 1.1862,
      "step": 98750
    },
    {
      "epoch": 1.0459345440686847,
      "grad_norm": 2.790635824203491,
      "learning_rate": 4.477217869997883e-05,
      "loss": 1.1788,
      "step": 98800
    },
    {
      "epoch": 1.046463865848688,
      "grad_norm": 2.805982828140259,
      "learning_rate": 4.476953207706966e-05,
      "loss": 1.1852,
      "step": 98850
    },
    {
      "epoch": 1.0469931876286913,
      "grad_norm": 2.712959051132202,
      "learning_rate": 4.47668854541605e-05,
      "loss": 1.192,
      "step": 98900
    },
    {
      "epoch": 1.0475225094086946,
      "grad_norm": 2.6467976570129395,
      "learning_rate": 4.4764238831251326e-05,
      "loss": 1.1766,
      "step": 98950
    },
    {
      "epoch": 1.048051831188698,
      "grad_norm": 2.8043136596679688,
      "learning_rate": 4.476159220834216e-05,
      "loss": 1.2102,
      "step": 99000
    },
    {
      "epoch": 1.048051831188698,
      "eval_loss": 1.1061677932739258,
      "eval_runtime": 46.558,
      "eval_samples_per_second": 3606.896,
      "eval_steps_per_second": 450.878,
      "step": 99000
    },
    {
      "epoch": 1.0485811529687012,
      "grad_norm": 2.9008538722991943,
      "learning_rate": 4.475894558543299e-05,
      "loss": 1.1977,
      "step": 99050
    },
    {
      "epoch": 1.0491104747487046,
      "grad_norm": 2.7685227394104004,
      "learning_rate": 4.475629896252382e-05,
      "loss": 1.1762,
      "step": 99100
    },
    {
      "epoch": 1.0496397965287079,
      "grad_norm": 2.9797866344451904,
      "learning_rate": 4.4753705272072836e-05,
      "loss": 1.203,
      "step": 99150
    },
    {
      "epoch": 1.050169118308711,
      "grad_norm": 2.539860248565674,
      "learning_rate": 4.475105864916367e-05,
      "loss": 1.187,
      "step": 99200
    },
    {
      "epoch": 1.0506984400887143,
      "grad_norm": 2.8867201805114746,
      "learning_rate": 4.47484120262545e-05,
      "loss": 1.1737,
      "step": 99250
    },
    {
      "epoch": 1.0512277618687176,
      "grad_norm": 2.818331480026245,
      "learning_rate": 4.474576540334534e-05,
      "loss": 1.1702,
      "step": 99300
    },
    {
      "epoch": 1.051757083648721,
      "grad_norm": 2.382535219192505,
      "learning_rate": 4.4743118780436165e-05,
      "loss": 1.192,
      "step": 99350
    },
    {
      "epoch": 1.0522864054287242,
      "grad_norm": 3.0595173835754395,
      "learning_rate": 4.4740472157527e-05,
      "loss": 1.1869,
      "step": 99400
    },
    {
      "epoch": 1.0528157272087275,
      "grad_norm": 2.553316354751587,
      "learning_rate": 4.473782553461783e-05,
      "loss": 1.1766,
      "step": 99450
    },
    {
      "epoch": 1.0533450489887308,
      "grad_norm": 2.7882537841796875,
      "learning_rate": 4.473517891170866e-05,
      "loss": 1.1831,
      "step": 99500
    },
    {
      "epoch": 1.0533450489887308,
      "eval_loss": 1.1025052070617676,
      "eval_runtime": 46.6558,
      "eval_samples_per_second": 3599.336,
      "eval_steps_per_second": 449.933,
      "step": 99500
    },
    {
      "epoch": 1.053874370768734,
      "grad_norm": 2.8406453132629395,
      "learning_rate": 4.4732532288799495e-05,
      "loss": 1.2011,
      "step": 99550
    },
    {
      "epoch": 1.0544036925487372,
      "grad_norm": 2.908773183822632,
      "learning_rate": 4.472988566589032e-05,
      "loss": 1.1845,
      "step": 99600
    },
    {
      "epoch": 1.0549330143287405,
      "grad_norm": 2.763528347015381,
      "learning_rate": 4.4727239042981156e-05,
      "loss": 1.1661,
      "step": 99650
    },
    {
      "epoch": 1.0554623361087438,
      "grad_norm": 2.746281862258911,
      "learning_rate": 4.472459242007199e-05,
      "loss": 1.1735,
      "step": 99700
    },
    {
      "epoch": 1.0559916578887472,
      "grad_norm": 2.685129404067993,
      "learning_rate": 4.4721945797162825e-05,
      "loss": 1.1876,
      "step": 99750
    },
    {
      "epoch": 1.0565209796687505,
      "grad_norm": 2.4606287479400635,
      "learning_rate": 4.471929917425365e-05,
      "loss": 1.1788,
      "step": 99800
    },
    {
      "epoch": 1.0570503014487538,
      "grad_norm": 2.733847141265869,
      "learning_rate": 4.4716652551344486e-05,
      "loss": 1.189,
      "step": 99850
    },
    {
      "epoch": 1.057579623228757,
      "grad_norm": 2.5590860843658447,
      "learning_rate": 4.471400592843532e-05,
      "loss": 1.1994,
      "step": 99900
    },
    {
      "epoch": 1.0581089450087602,
      "grad_norm": 2.8929402828216553,
      "learning_rate": 4.4711359305526154e-05,
      "loss": 1.1821,
      "step": 99950
    },
    {
      "epoch": 1.0586382667887635,
      "grad_norm": 2.6797728538513184,
      "learning_rate": 4.470871268261698e-05,
      "loss": 1.1749,
      "step": 100000
    },
    {
      "epoch": 1.0586382667887635,
      "eval_loss": 1.0995796918869019,
      "eval_runtime": 46.5649,
      "eval_samples_per_second": 3606.363,
      "eval_steps_per_second": 450.811,
      "step": 100000
    },
    {
      "epoch": 1.0591675885687668,
      "grad_norm": 2.6182198524475098,
      "learning_rate": 4.4706066059707816e-05,
      "loss": 1.1741,
      "step": 100050
    },
    {
      "epoch": 1.0596969103487701,
      "grad_norm": 2.5095930099487305,
      "learning_rate": 4.470341943679865e-05,
      "loss": 1.193,
      "step": 100100
    },
    {
      "epoch": 1.0602262321287734,
      "grad_norm": 2.8991551399230957,
      "learning_rate": 4.470077281388948e-05,
      "loss": 1.1941,
      "step": 100150
    },
    {
      "epoch": 1.0607555539087767,
      "grad_norm": 2.6030404567718506,
      "learning_rate": 4.469812619098031e-05,
      "loss": 1.1868,
      "step": 100200
    },
    {
      "epoch": 1.06128487568878,
      "grad_norm": 2.5642101764678955,
      "learning_rate": 4.469547956807114e-05,
      "loss": 1.177,
      "step": 100250
    },
    {
      "epoch": 1.0618141974687831,
      "grad_norm": 2.8323538303375244,
      "learning_rate": 4.469283294516198e-05,
      "loss": 1.2055,
      "step": 100300
    },
    {
      "epoch": 1.0623435192487864,
      "grad_norm": 2.7884507179260254,
      "learning_rate": 4.469018632225281e-05,
      "loss": 1.1844,
      "step": 100350
    },
    {
      "epoch": 1.0628728410287898,
      "grad_norm": 2.5640618801116943,
      "learning_rate": 4.468753969934364e-05,
      "loss": 1.166,
      "step": 100400
    },
    {
      "epoch": 1.063402162808793,
      "grad_norm": 2.610337257385254,
      "learning_rate": 4.468489307643447e-05,
      "loss": 1.2088,
      "step": 100450
    },
    {
      "epoch": 1.0639314845887964,
      "grad_norm": 2.921151876449585,
      "learning_rate": 4.468224645352531e-05,
      "loss": 1.1737,
      "step": 100500
    },
    {
      "epoch": 1.0639314845887964,
      "eval_loss": 1.0980374813079834,
      "eval_runtime": 46.5837,
      "eval_samples_per_second": 3604.905,
      "eval_steps_per_second": 450.629,
      "step": 100500
    },
    {
      "epoch": 1.0644608063687997,
      "grad_norm": 2.917941093444824,
      "learning_rate": 4.4679599830616136e-05,
      "loss": 1.1836,
      "step": 100550
    },
    {
      "epoch": 1.064990128148803,
      "grad_norm": 2.704956293106079,
      "learning_rate": 4.467695320770697e-05,
      "loss": 1.1969,
      "step": 100600
    },
    {
      "epoch": 1.0655194499288063,
      "grad_norm": 2.6580352783203125,
      "learning_rate": 4.46743065847978e-05,
      "loss": 1.1898,
      "step": 100650
    },
    {
      "epoch": 1.0660487717088094,
      "grad_norm": 2.5999956130981445,
      "learning_rate": 4.467165996188863e-05,
      "loss": 1.1731,
      "step": 100700
    },
    {
      "epoch": 1.0665780934888127,
      "grad_norm": 2.9058027267456055,
      "learning_rate": 4.4669013338979466e-05,
      "loss": 1.1503,
      "step": 100750
    },
    {
      "epoch": 1.067107415268816,
      "grad_norm": 2.805171012878418,
      "learning_rate": 4.466636671607029e-05,
      "loss": 1.1905,
      "step": 100800
    },
    {
      "epoch": 1.0676367370488193,
      "grad_norm": 2.6420416831970215,
      "learning_rate": 4.466372009316113e-05,
      "loss": 1.1685,
      "step": 100850
    },
    {
      "epoch": 1.0681660588288227,
      "grad_norm": 2.7345170974731445,
      "learning_rate": 4.466107347025196e-05,
      "loss": 1.1952,
      "step": 100900
    },
    {
      "epoch": 1.068695380608826,
      "grad_norm": 3.189394474029541,
      "learning_rate": 4.4658426847342796e-05,
      "loss": 1.1915,
      "step": 100950
    },
    {
      "epoch": 1.0692247023888293,
      "grad_norm": 2.7423012256622314,
      "learning_rate": 4.465578022443362e-05,
      "loss": 1.1851,
      "step": 101000
    },
    {
      "epoch": 1.0692247023888293,
      "eval_loss": 1.094184160232544,
      "eval_runtime": 46.6186,
      "eval_samples_per_second": 3602.208,
      "eval_steps_per_second": 450.292,
      "step": 101000
    },
    {
      "epoch": 1.0697540241688324,
      "grad_norm": 2.798766851425171,
      "learning_rate": 4.465313360152446e-05,
      "loss": 1.1773,
      "step": 101050
    },
    {
      "epoch": 1.0702833459488357,
      "grad_norm": 2.8311545848846436,
      "learning_rate": 4.465048697861529e-05,
      "loss": 1.1858,
      "step": 101100
    },
    {
      "epoch": 1.070812667728839,
      "grad_norm": 2.791083812713623,
      "learning_rate": 4.4647840355706125e-05,
      "loss": 1.1918,
      "step": 101150
    },
    {
      "epoch": 1.0713419895088423,
      "grad_norm": 2.78932785987854,
      "learning_rate": 4.464519373279695e-05,
      "loss": 1.1876,
      "step": 101200
    },
    {
      "epoch": 1.0718713112888456,
      "grad_norm": 2.8908298015594482,
      "learning_rate": 4.464254710988779e-05,
      "loss": 1.1816,
      "step": 101250
    },
    {
      "epoch": 1.072400633068849,
      "grad_norm": 2.5950632095336914,
      "learning_rate": 4.463990048697862e-05,
      "loss": 1.1942,
      "step": 101300
    },
    {
      "epoch": 1.0729299548488522,
      "grad_norm": 2.376096487045288,
      "learning_rate": 4.463725386406945e-05,
      "loss": 1.1745,
      "step": 101350
    },
    {
      "epoch": 1.0734592766288555,
      "grad_norm": 2.972304344177246,
      "learning_rate": 4.463460724116028e-05,
      "loss": 1.1916,
      "step": 101400
    },
    {
      "epoch": 1.0739885984088586,
      "grad_norm": 2.8566982746124268,
      "learning_rate": 4.463196061825111e-05,
      "loss": 1.177,
      "step": 101450
    },
    {
      "epoch": 1.074517920188862,
      "grad_norm": 2.6043474674224854,
      "learning_rate": 4.462931399534195e-05,
      "loss": 1.1924,
      "step": 101500
    },
    {
      "epoch": 1.074517920188862,
      "eval_loss": 1.0929639339447021,
      "eval_runtime": 46.5936,
      "eval_samples_per_second": 3604.146,
      "eval_steps_per_second": 450.534,
      "step": 101500
    },
    {
      "epoch": 1.0750472419688653,
      "grad_norm": 2.7456648349761963,
      "learning_rate": 4.462666737243278e-05,
      "loss": 1.1786,
      "step": 101550
    },
    {
      "epoch": 1.0755765637488686,
      "grad_norm": 2.7137091159820557,
      "learning_rate": 4.462402074952361e-05,
      "loss": 1.1863,
      "step": 101600
    },
    {
      "epoch": 1.0761058855288719,
      "grad_norm": 2.7754297256469727,
      "learning_rate": 4.462137412661444e-05,
      "loss": 1.191,
      "step": 101650
    },
    {
      "epoch": 1.0766352073088752,
      "grad_norm": 3.0570569038391113,
      "learning_rate": 4.461872750370527e-05,
      "loss": 1.1876,
      "step": 101700
    },
    {
      "epoch": 1.0771645290888785,
      "grad_norm": 2.6335971355438232,
      "learning_rate": 4.461608088079611e-05,
      "loss": 1.1865,
      "step": 101750
    },
    {
      "epoch": 1.0776938508688816,
      "grad_norm": 3.031723976135254,
      "learning_rate": 4.4613434257886935e-05,
      "loss": 1.1672,
      "step": 101800
    },
    {
      "epoch": 1.078223172648885,
      "grad_norm": 2.833430528640747,
      "learning_rate": 4.461078763497777e-05,
      "loss": 1.182,
      "step": 101850
    },
    {
      "epoch": 1.0787524944288882,
      "grad_norm": 3.0432183742523193,
      "learning_rate": 4.46081410120686e-05,
      "loss": 1.1579,
      "step": 101900
    },
    {
      "epoch": 1.0792818162088915,
      "grad_norm": 2.8016719818115234,
      "learning_rate": 4.460549438915944e-05,
      "loss": 1.1627,
      "step": 101950
    },
    {
      "epoch": 1.0798111379888948,
      "grad_norm": 2.8366482257843018,
      "learning_rate": 4.4602847766250264e-05,
      "loss": 1.1904,
      "step": 102000
    },
    {
      "epoch": 1.0798111379888948,
      "eval_loss": 1.0917717218399048,
      "eval_runtime": 46.6022,
      "eval_samples_per_second": 3603.477,
      "eval_steps_per_second": 450.451,
      "step": 102000
    },
    {
      "epoch": 1.0803404597688981,
      "grad_norm": 2.648855209350586,
      "learning_rate": 4.46002011433411e-05,
      "loss": 1.1858,
      "step": 102050
    },
    {
      "epoch": 1.0808697815489015,
      "grad_norm": 2.635586977005005,
      "learning_rate": 4.459755452043193e-05,
      "loss": 1.1831,
      "step": 102100
    },
    {
      "epoch": 1.0813991033289048,
      "grad_norm": 2.7471976280212402,
      "learning_rate": 4.4594907897522767e-05,
      "loss": 1.1717,
      "step": 102150
    },
    {
      "epoch": 1.0819284251089079,
      "grad_norm": 2.769019365310669,
      "learning_rate": 4.4592261274613594e-05,
      "loss": 1.193,
      "step": 102200
    },
    {
      "epoch": 1.0824577468889112,
      "grad_norm": 2.82759165763855,
      "learning_rate": 4.458966758416261e-05,
      "loss": 1.1771,
      "step": 102250
    },
    {
      "epoch": 1.0829870686689145,
      "grad_norm": 2.761286735534668,
      "learning_rate": 4.458702096125344e-05,
      "loss": 1.2032,
      "step": 102300
    },
    {
      "epoch": 1.0835163904489178,
      "grad_norm": 2.8267159461975098,
      "learning_rate": 4.458437433834428e-05,
      "loss": 1.1931,
      "step": 102350
    },
    {
      "epoch": 1.084045712228921,
      "grad_norm": 2.900301456451416,
      "learning_rate": 4.4581727715435104e-05,
      "loss": 1.1668,
      "step": 102400
    },
    {
      "epoch": 1.0845750340089244,
      "grad_norm": 2.548473358154297,
      "learning_rate": 4.457908109252594e-05,
      "loss": 1.1825,
      "step": 102450
    },
    {
      "epoch": 1.0851043557889277,
      "grad_norm": 2.719520092010498,
      "learning_rate": 4.457643446961677e-05,
      "loss": 1.1891,
      "step": 102500
    },
    {
      "epoch": 1.0851043557889277,
      "eval_loss": 1.0869492292404175,
      "eval_runtime": 46.5927,
      "eval_samples_per_second": 3604.212,
      "eval_steps_per_second": 450.543,
      "step": 102500
    },
    {
      "epoch": 1.085633677568931,
      "grad_norm": 2.6814217567443848,
      "learning_rate": 4.4573787846707606e-05,
      "loss": 1.1975,
      "step": 102550
    },
    {
      "epoch": 1.0861629993489341,
      "grad_norm": 2.6945605278015137,
      "learning_rate": 4.4571141223798434e-05,
      "loss": 1.1847,
      "step": 102600
    },
    {
      "epoch": 1.0866923211289374,
      "grad_norm": 2.773136854171753,
      "learning_rate": 4.456849460088927e-05,
      "loss": 1.1656,
      "step": 102650
    },
    {
      "epoch": 1.0872216429089407,
      "grad_norm": 2.999533176422119,
      "learning_rate": 4.45658479779801e-05,
      "loss": 1.1752,
      "step": 102700
    },
    {
      "epoch": 1.087750964688944,
      "grad_norm": 2.588892936706543,
      "learning_rate": 4.456320135507093e-05,
      "loss": 1.1725,
      "step": 102750
    },
    {
      "epoch": 1.0882802864689474,
      "grad_norm": 2.785907506942749,
      "learning_rate": 4.4560554732161763e-05,
      "loss": 1.2017,
      "step": 102800
    },
    {
      "epoch": 1.0888096082489507,
      "grad_norm": 3.053668260574341,
      "learning_rate": 4.455790810925259e-05,
      "loss": 1.1779,
      "step": 102850
    },
    {
      "epoch": 1.089338930028954,
      "grad_norm": 2.8945043087005615,
      "learning_rate": 4.455526148634343e-05,
      "loss": 1.1684,
      "step": 102900
    },
    {
      "epoch": 1.0898682518089573,
      "grad_norm": 2.5507471561431885,
      "learning_rate": 4.455261486343426e-05,
      "loss": 1.167,
      "step": 102950
    },
    {
      "epoch": 1.0903975735889604,
      "grad_norm": 2.6126041412353516,
      "learning_rate": 4.454996824052509e-05,
      "loss": 1.1475,
      "step": 103000
    },
    {
      "epoch": 1.0903975735889604,
      "eval_loss": 1.0864129066467285,
      "eval_runtime": 46.7066,
      "eval_samples_per_second": 3595.421,
      "eval_steps_per_second": 449.444,
      "step": 103000
    },
    {
      "epoch": 1.0909268953689637,
      "grad_norm": 2.9398725032806396,
      "learning_rate": 4.454732161761592e-05,
      "loss": 1.1685,
      "step": 103050
    },
    {
      "epoch": 1.091456217148967,
      "grad_norm": 2.854926586151123,
      "learning_rate": 4.454467499470676e-05,
      "loss": 1.1643,
      "step": 103100
    },
    {
      "epoch": 1.0919855389289703,
      "grad_norm": 2.6545119285583496,
      "learning_rate": 4.454202837179759e-05,
      "loss": 1.1827,
      "step": 103150
    },
    {
      "epoch": 1.0925148607089736,
      "grad_norm": 2.6588666439056396,
      "learning_rate": 4.453938174888842e-05,
      "loss": 1.159,
      "step": 103200
    },
    {
      "epoch": 1.093044182488977,
      "grad_norm": 2.8328280448913574,
      "learning_rate": 4.453673512597925e-05,
      "loss": 1.1753,
      "step": 103250
    },
    {
      "epoch": 1.0935735042689803,
      "grad_norm": 2.693366765975952,
      "learning_rate": 4.4534088503070084e-05,
      "loss": 1.1729,
      "step": 103300
    },
    {
      "epoch": 1.0941028260489833,
      "grad_norm": 2.999117374420166,
      "learning_rate": 4.453144188016092e-05,
      "loss": 1.1787,
      "step": 103350
    },
    {
      "epoch": 1.0946321478289867,
      "grad_norm": 2.8514842987060547,
      "learning_rate": 4.4528795257251745e-05,
      "loss": 1.1765,
      "step": 103400
    },
    {
      "epoch": 1.09516146960899,
      "grad_norm": 3.024033546447754,
      "learning_rate": 4.452614863434258e-05,
      "loss": 1.1531,
      "step": 103450
    },
    {
      "epoch": 1.0956907913889933,
      "grad_norm": 2.6908223628997803,
      "learning_rate": 4.4523502011433414e-05,
      "loss": 1.1841,
      "step": 103500
    },
    {
      "epoch": 1.0956907913889933,
      "eval_loss": 1.084560513496399,
      "eval_runtime": 46.5802,
      "eval_samples_per_second": 3605.177,
      "eval_steps_per_second": 450.663,
      "step": 103500
    },
    {
      "epoch": 1.0962201131689966,
      "grad_norm": 2.6593406200408936,
      "learning_rate": 4.452085538852425e-05,
      "loss": 1.1651,
      "step": 103550
    },
    {
      "epoch": 1.096749434949,
      "grad_norm": 2.818049430847168,
      "learning_rate": 4.4518208765615075e-05,
      "loss": 1.1674,
      "step": 103600
    },
    {
      "epoch": 1.0972787567290032,
      "grad_norm": 2.462667942047119,
      "learning_rate": 4.451556214270591e-05,
      "loss": 1.1584,
      "step": 103650
    },
    {
      "epoch": 1.0978080785090065,
      "grad_norm": 3.0484886169433594,
      "learning_rate": 4.451291551979674e-05,
      "loss": 1.1613,
      "step": 103700
    },
    {
      "epoch": 1.0983374002890096,
      "grad_norm": 2.5946507453918457,
      "learning_rate": 4.451026889688758e-05,
      "loss": 1.1862,
      "step": 103750
    },
    {
      "epoch": 1.098866722069013,
      "grad_norm": 2.9749691486358643,
      "learning_rate": 4.4507622273978405e-05,
      "loss": 1.1645,
      "step": 103800
    },
    {
      "epoch": 1.0993960438490162,
      "grad_norm": 2.9839348793029785,
      "learning_rate": 4.450497565106924e-05,
      "loss": 1.1643,
      "step": 103850
    },
    {
      "epoch": 1.0999253656290195,
      "grad_norm": 2.7958290576934814,
      "learning_rate": 4.450232902816007e-05,
      "loss": 1.1499,
      "step": 103900
    },
    {
      "epoch": 1.1004546874090229,
      "grad_norm": 3.2102177143096924,
      "learning_rate": 4.44996824052509e-05,
      "loss": 1.1921,
      "step": 103950
    },
    {
      "epoch": 1.1009840091890262,
      "grad_norm": 2.837357759475708,
      "learning_rate": 4.4497035782341734e-05,
      "loss": 1.1762,
      "step": 104000
    },
    {
      "epoch": 1.1009840091890262,
      "eval_loss": 1.080627202987671,
      "eval_runtime": 46.5617,
      "eval_samples_per_second": 3606.608,
      "eval_steps_per_second": 450.842,
      "step": 104000
    },
    {
      "epoch": 1.1015133309690295,
      "grad_norm": 2.7899248600006104,
      "learning_rate": 4.449438915943256e-05,
      "loss": 1.1738,
      "step": 104050
    },
    {
      "epoch": 1.1020426527490326,
      "grad_norm": 2.926436185836792,
      "learning_rate": 4.44917425365234e-05,
      "loss": 1.1573,
      "step": 104100
    },
    {
      "epoch": 1.1025719745290359,
      "grad_norm": 2.6530871391296387,
      "learning_rate": 4.448909591361423e-05,
      "loss": 1.1463,
      "step": 104150
    },
    {
      "epoch": 1.1031012963090392,
      "grad_norm": 2.8464677333831787,
      "learning_rate": 4.4486449290705064e-05,
      "loss": 1.1804,
      "step": 104200
    },
    {
      "epoch": 1.1036306180890425,
      "grad_norm": 2.693665027618408,
      "learning_rate": 4.448380266779589e-05,
      "loss": 1.1545,
      "step": 104250
    },
    {
      "epoch": 1.1041599398690458,
      "grad_norm": 2.574707269668579,
      "learning_rate": 4.448115604488673e-05,
      "loss": 1.1634,
      "step": 104300
    },
    {
      "epoch": 1.1046892616490491,
      "grad_norm": 2.939641237258911,
      "learning_rate": 4.447850942197756e-05,
      "loss": 1.1769,
      "step": 104350
    },
    {
      "epoch": 1.1052185834290524,
      "grad_norm": 2.989865779876709,
      "learning_rate": 4.4475862799068394e-05,
      "loss": 1.1708,
      "step": 104400
    },
    {
      "epoch": 1.1057479052090557,
      "grad_norm": 2.7231743335723877,
      "learning_rate": 4.447321617615922e-05,
      "loss": 1.1604,
      "step": 104450
    },
    {
      "epoch": 1.1062772269890588,
      "grad_norm": 2.9818520545959473,
      "learning_rate": 4.4470569553250055e-05,
      "loss": 1.1776,
      "step": 104500
    },
    {
      "epoch": 1.1062772269890588,
      "eval_loss": 1.0786538124084473,
      "eval_runtime": 46.58,
      "eval_samples_per_second": 3605.195,
      "eval_steps_per_second": 450.666,
      "step": 104500
    },
    {
      "epoch": 1.1068065487690621,
      "grad_norm": 2.7499678134918213,
      "learning_rate": 4.446792293034089e-05,
      "loss": 1.1926,
      "step": 104550
    },
    {
      "epoch": 1.1073358705490655,
      "grad_norm": 2.8462576866149902,
      "learning_rate": 4.4465276307431716e-05,
      "loss": 1.1821,
      "step": 104600
    },
    {
      "epoch": 1.1078651923290688,
      "grad_norm": 2.610499620437622,
      "learning_rate": 4.446262968452255e-05,
      "loss": 1.169,
      "step": 104650
    },
    {
      "epoch": 1.108394514109072,
      "grad_norm": 2.9490487575531006,
      "learning_rate": 4.4459983061613385e-05,
      "loss": 1.1575,
      "step": 104700
    },
    {
      "epoch": 1.1089238358890754,
      "grad_norm": 3.230503559112549,
      "learning_rate": 4.445733643870422e-05,
      "loss": 1.1659,
      "step": 104750
    },
    {
      "epoch": 1.1094531576690787,
      "grad_norm": 2.9360241889953613,
      "learning_rate": 4.4454689815795046e-05,
      "loss": 1.1705,
      "step": 104800
    },
    {
      "epoch": 1.1099824794490818,
      "grad_norm": 2.9449009895324707,
      "learning_rate": 4.445204319288588e-05,
      "loss": 1.1816,
      "step": 104850
    },
    {
      "epoch": 1.110511801229085,
      "grad_norm": 2.8935229778289795,
      "learning_rate": 4.4449396569976714e-05,
      "loss": 1.1716,
      "step": 104900
    },
    {
      "epoch": 1.1110411230090884,
      "grad_norm": 2.965341091156006,
      "learning_rate": 4.444674994706755e-05,
      "loss": 1.168,
      "step": 104950
    },
    {
      "epoch": 1.1115704447890917,
      "grad_norm": 2.8782036304473877,
      "learning_rate": 4.4444103324158376e-05,
      "loss": 1.1825,
      "step": 105000
    },
    {
      "epoch": 1.1115704447890917,
      "eval_loss": 1.0811784267425537,
      "eval_runtime": 46.5965,
      "eval_samples_per_second": 3603.919,
      "eval_steps_per_second": 450.506,
      "step": 105000
    },
    {
      "epoch": 1.112099766569095,
      "grad_norm": 2.698540210723877,
      "learning_rate": 4.444145670124921e-05,
      "loss": 1.1728,
      "step": 105050
    },
    {
      "epoch": 1.1126290883490983,
      "grad_norm": 2.8276820182800293,
      "learning_rate": 4.4438810078340044e-05,
      "loss": 1.1712,
      "step": 105100
    },
    {
      "epoch": 1.1131584101291017,
      "grad_norm": 2.9230854511260986,
      "learning_rate": 4.443621638788906e-05,
      "loss": 1.1596,
      "step": 105150
    },
    {
      "epoch": 1.113687731909105,
      "grad_norm": 2.822892904281616,
      "learning_rate": 4.4433569764979886e-05,
      "loss": 1.1691,
      "step": 105200
    },
    {
      "epoch": 1.114217053689108,
      "grad_norm": 3.0366318225860596,
      "learning_rate": 4.443092314207072e-05,
      "loss": 1.1602,
      "step": 105250
    },
    {
      "epoch": 1.1147463754691114,
      "grad_norm": 2.8070991039276123,
      "learning_rate": 4.4428276519161554e-05,
      "loss": 1.1646,
      "step": 105300
    },
    {
      "epoch": 1.1152756972491147,
      "grad_norm": 2.771638870239258,
      "learning_rate": 4.442562989625239e-05,
      "loss": 1.1577,
      "step": 105350
    },
    {
      "epoch": 1.115805019029118,
      "grad_norm": 2.922954797744751,
      "learning_rate": 4.4422983273343216e-05,
      "loss": 1.1551,
      "step": 105400
    },
    {
      "epoch": 1.1163343408091213,
      "grad_norm": 2.759160041809082,
      "learning_rate": 4.442033665043405e-05,
      "loss": 1.1686,
      "step": 105450
    },
    {
      "epoch": 1.1168636625891246,
      "grad_norm": 2.889007329940796,
      "learning_rate": 4.4417690027524884e-05,
      "loss": 1.1601,
      "step": 105500
    },
    {
      "epoch": 1.1168636625891246,
      "eval_loss": 1.0749268531799316,
      "eval_runtime": 46.6569,
      "eval_samples_per_second": 3599.253,
      "eval_steps_per_second": 449.923,
      "step": 105500
    },
    {
      "epoch": 1.117392984369128,
      "grad_norm": 3.0614795684814453,
      "learning_rate": 4.441504340461571e-05,
      "loss": 1.1619,
      "step": 105550
    },
    {
      "epoch": 1.117922306149131,
      "grad_norm": 2.7544875144958496,
      "learning_rate": 4.4412396781706545e-05,
      "loss": 1.1511,
      "step": 105600
    },
    {
      "epoch": 1.1184516279291343,
      "grad_norm": 2.9993038177490234,
      "learning_rate": 4.440975015879737e-05,
      "loss": 1.1687,
      "step": 105650
    },
    {
      "epoch": 1.1189809497091376,
      "grad_norm": 2.6127145290374756,
      "learning_rate": 4.440710353588821e-05,
      "loss": 1.1555,
      "step": 105700
    },
    {
      "epoch": 1.119510271489141,
      "grad_norm": 3.0467140674591064,
      "learning_rate": 4.440445691297904e-05,
      "loss": 1.1533,
      "step": 105750
    },
    {
      "epoch": 1.1200395932691443,
      "grad_norm": 3.1248152256011963,
      "learning_rate": 4.4401810290069875e-05,
      "loss": 1.2061,
      "step": 105800
    },
    {
      "epoch": 1.1205689150491476,
      "grad_norm": 3.000694513320923,
      "learning_rate": 4.43991636671607e-05,
      "loss": 1.1715,
      "step": 105850
    },
    {
      "epoch": 1.1210982368291509,
      "grad_norm": 2.852022409439087,
      "learning_rate": 4.439651704425154e-05,
      "loss": 1.1591,
      "step": 105900
    },
    {
      "epoch": 1.1216275586091542,
      "grad_norm": 3.1987178325653076,
      "learning_rate": 4.439387042134237e-05,
      "loss": 1.1577,
      "step": 105950
    },
    {
      "epoch": 1.1221568803891573,
      "grad_norm": 2.7133305072784424,
      "learning_rate": 4.4391223798433204e-05,
      "loss": 1.1574,
      "step": 106000
    },
    {
      "epoch": 1.1221568803891573,
      "eval_loss": 1.0721311569213867,
      "eval_runtime": 46.6306,
      "eval_samples_per_second": 3601.284,
      "eval_steps_per_second": 450.177,
      "step": 106000
    },
    {
      "epoch": 1.1226862021691606,
      "grad_norm": 2.9495363235473633,
      "learning_rate": 4.438857717552403e-05,
      "loss": 1.1681,
      "step": 106050
    },
    {
      "epoch": 1.123215523949164,
      "grad_norm": 2.858905076980591,
      "learning_rate": 4.4385930552614866e-05,
      "loss": 1.1561,
      "step": 106100
    },
    {
      "epoch": 1.1237448457291672,
      "grad_norm": 2.9247241020202637,
      "learning_rate": 4.43832839297057e-05,
      "loss": 1.1806,
      "step": 106150
    },
    {
      "epoch": 1.1242741675091705,
      "grad_norm": 2.803187131881714,
      "learning_rate": 4.438063730679653e-05,
      "loss": 1.158,
      "step": 106200
    },
    {
      "epoch": 1.1248034892891738,
      "grad_norm": 2.565096616744995,
      "learning_rate": 4.437799068388736e-05,
      "loss": 1.1519,
      "step": 106250
    },
    {
      "epoch": 1.1253328110691772,
      "grad_norm": 3.0470023155212402,
      "learning_rate": 4.437534406097819e-05,
      "loss": 1.16,
      "step": 106300
    },
    {
      "epoch": 1.1258621328491802,
      "grad_norm": 3.1327831745147705,
      "learning_rate": 4.437269743806903e-05,
      "loss": 1.1561,
      "step": 106350
    },
    {
      "epoch": 1.1263914546291836,
      "grad_norm": 3.142292022705078,
      "learning_rate": 4.437005081515986e-05,
      "loss": 1.1389,
      "step": 106400
    },
    {
      "epoch": 1.1269207764091869,
      "grad_norm": 3.0623178482055664,
      "learning_rate": 4.436740419225069e-05,
      "loss": 1.1515,
      "step": 106450
    },
    {
      "epoch": 1.1274500981891902,
      "grad_norm": 2.8200433254241943,
      "learning_rate": 4.436475756934152e-05,
      "loss": 1.1579,
      "step": 106500
    },
    {
      "epoch": 1.1274500981891902,
      "eval_loss": 1.0690298080444336,
      "eval_runtime": 46.6411,
      "eval_samples_per_second": 3600.474,
      "eval_steps_per_second": 450.075,
      "step": 106500
    },
    {
      "epoch": 1.1279794199691935,
      "grad_norm": 2.837575674057007,
      "learning_rate": 4.436211094643236e-05,
      "loss": 1.1613,
      "step": 106550
    },
    {
      "epoch": 1.1285087417491968,
      "grad_norm": 2.8047235012054443,
      "learning_rate": 4.4359464323523187e-05,
      "loss": 1.1589,
      "step": 106600
    },
    {
      "epoch": 1.1290380635292,
      "grad_norm": 3.088120460510254,
      "learning_rate": 4.435681770061402e-05,
      "loss": 1.1706,
      "step": 106650
    },
    {
      "epoch": 1.1295673853092034,
      "grad_norm": 2.8500776290893555,
      "learning_rate": 4.435417107770485e-05,
      "loss": 1.1574,
      "step": 106700
    },
    {
      "epoch": 1.1300967070892065,
      "grad_norm": 3.048445463180542,
      "learning_rate": 4.435152445479568e-05,
      "loss": 1.1548,
      "step": 106750
    },
    {
      "epoch": 1.1306260288692098,
      "grad_norm": 2.9520320892333984,
      "learning_rate": 4.4348877831886516e-05,
      "loss": 1.1841,
      "step": 106800
    },
    {
      "epoch": 1.1311553506492131,
      "grad_norm": 2.857675075531006,
      "learning_rate": 4.4346231208977343e-05,
      "loss": 1.165,
      "step": 106850
    },
    {
      "epoch": 1.1316846724292164,
      "grad_norm": 2.4759867191314697,
      "learning_rate": 4.434358458606818e-05,
      "loss": 1.1379,
      "step": 106900
    },
    {
      "epoch": 1.1322139942092198,
      "grad_norm": 2.9188425540924072,
      "learning_rate": 4.434093796315901e-05,
      "loss": 1.1713,
      "step": 106950
    },
    {
      "epoch": 1.132743315989223,
      "grad_norm": 2.55668306350708,
      "learning_rate": 4.4338291340249846e-05,
      "loss": 1.1662,
      "step": 107000
    },
    {
      "epoch": 1.132743315989223,
      "eval_loss": 1.0680088996887207,
      "eval_runtime": 46.5748,
      "eval_samples_per_second": 3605.6,
      "eval_steps_per_second": 450.716,
      "step": 107000
    },
    {
      "epoch": 1.1332726377692264,
      "grad_norm": 2.9768776893615723,
      "learning_rate": 4.433564471734067e-05,
      "loss": 1.1671,
      "step": 107050
    },
    {
      "epoch": 1.1338019595492295,
      "grad_norm": 2.8472962379455566,
      "learning_rate": 4.433299809443151e-05,
      "loss": 1.1596,
      "step": 107100
    },
    {
      "epoch": 1.1343312813292328,
      "grad_norm": 2.8833529949188232,
      "learning_rate": 4.433035147152234e-05,
      "loss": 1.1569,
      "step": 107150
    },
    {
      "epoch": 1.134860603109236,
      "grad_norm": 2.599377393722534,
      "learning_rate": 4.432770484861317e-05,
      "loss": 1.1663,
      "step": 107200
    },
    {
      "epoch": 1.1353899248892394,
      "grad_norm": 2.929136037826538,
      "learning_rate": 4.4325058225704e-05,
      "loss": 1.1831,
      "step": 107250
    },
    {
      "epoch": 1.1359192466692427,
      "grad_norm": 3.034515619277954,
      "learning_rate": 4.432241160279483e-05,
      "loss": 1.1659,
      "step": 107300
    },
    {
      "epoch": 1.136448568449246,
      "grad_norm": 2.852329969406128,
      "learning_rate": 4.431976497988567e-05,
      "loss": 1.1573,
      "step": 107350
    },
    {
      "epoch": 1.1369778902292493,
      "grad_norm": 2.7534408569335938,
      "learning_rate": 4.43171183569765e-05,
      "loss": 1.1495,
      "step": 107400
    },
    {
      "epoch": 1.1375072120092526,
      "grad_norm": 2.8818705081939697,
      "learning_rate": 4.431452466652551e-05,
      "loss": 1.1419,
      "step": 107450
    },
    {
      "epoch": 1.1380365337892557,
      "grad_norm": 2.729501962661743,
      "learning_rate": 4.431187804361635e-05,
      "loss": 1.1415,
      "step": 107500
    },
    {
      "epoch": 1.1380365337892557,
      "eval_loss": 1.0643103122711182,
      "eval_runtime": 46.6191,
      "eval_samples_per_second": 3602.173,
      "eval_steps_per_second": 450.288,
      "step": 107500
    },
    {
      "epoch": 1.138565855569259,
      "grad_norm": 3.090865135192871,
      "learning_rate": 4.430923142070718e-05,
      "loss": 1.154,
      "step": 107550
    },
    {
      "epoch": 1.1390951773492624,
      "grad_norm": 2.733736038208008,
      "learning_rate": 4.4306584797798015e-05,
      "loss": 1.141,
      "step": 107600
    },
    {
      "epoch": 1.1396244991292657,
      "grad_norm": 3.085515260696411,
      "learning_rate": 4.430393817488884e-05,
      "loss": 1.1612,
      "step": 107650
    },
    {
      "epoch": 1.140153820909269,
      "grad_norm": 2.7023444175720215,
      "learning_rate": 4.430129155197968e-05,
      "loss": 1.1651,
      "step": 107700
    },
    {
      "epoch": 1.1406831426892723,
      "grad_norm": 2.593445301055908,
      "learning_rate": 4.429864492907051e-05,
      "loss": 1.1555,
      "step": 107750
    },
    {
      "epoch": 1.1412124644692756,
      "grad_norm": 3.000638961791992,
      "learning_rate": 4.429599830616134e-05,
      "loss": 1.1677,
      "step": 107800
    },
    {
      "epoch": 1.1417417862492787,
      "grad_norm": 2.9451777935028076,
      "learning_rate": 4.429335168325217e-05,
      "loss": 1.1446,
      "step": 107850
    },
    {
      "epoch": 1.142271108029282,
      "grad_norm": 3.0356128215789795,
      "learning_rate": 4.4290705060343e-05,
      "loss": 1.1733,
      "step": 107900
    },
    {
      "epoch": 1.1428004298092853,
      "grad_norm": 2.960232734680176,
      "learning_rate": 4.428805843743384e-05,
      "loss": 1.1552,
      "step": 107950
    },
    {
      "epoch": 1.1433297515892886,
      "grad_norm": 3.009282112121582,
      "learning_rate": 4.428541181452467e-05,
      "loss": 1.167,
      "step": 108000
    },
    {
      "epoch": 1.1433297515892886,
      "eval_loss": 1.0624022483825684,
      "eval_runtime": 46.5939,
      "eval_samples_per_second": 3604.118,
      "eval_steps_per_second": 450.531,
      "step": 108000
    },
    {
      "epoch": 1.143859073369292,
      "grad_norm": 2.541041851043701,
      "learning_rate": 4.42827651916155e-05,
      "loss": 1.1776,
      "step": 108050
    },
    {
      "epoch": 1.1443883951492952,
      "grad_norm": 2.8721909523010254,
      "learning_rate": 4.428011856870633e-05,
      "loss": 1.1675,
      "step": 108100
    },
    {
      "epoch": 1.1449177169292986,
      "grad_norm": 2.9489972591400146,
      "learning_rate": 4.427747194579716e-05,
      "loss": 1.1685,
      "step": 108150
    },
    {
      "epoch": 1.1454470387093019,
      "grad_norm": 3.013592481613159,
      "learning_rate": 4.4274825322888e-05,
      "loss": 1.153,
      "step": 108200
    },
    {
      "epoch": 1.145976360489305,
      "grad_norm": 2.8606479167938232,
      "learning_rate": 4.4272178699978825e-05,
      "loss": 1.164,
      "step": 108250
    },
    {
      "epoch": 1.1465056822693083,
      "grad_norm": 2.8433032035827637,
      "learning_rate": 4.426953207706966e-05,
      "loss": 1.1559,
      "step": 108300
    },
    {
      "epoch": 1.1470350040493116,
      "grad_norm": 2.6387884616851807,
      "learning_rate": 4.426688545416049e-05,
      "loss": 1.1471,
      "step": 108350
    },
    {
      "epoch": 1.147564325829315,
      "grad_norm": 2.9526257514953613,
      "learning_rate": 4.426423883125133e-05,
      "loss": 1.1606,
      "step": 108400
    },
    {
      "epoch": 1.1480936476093182,
      "grad_norm": 3.203835964202881,
      "learning_rate": 4.4261592208342154e-05,
      "loss": 1.1689,
      "step": 108450
    },
    {
      "epoch": 1.1486229693893215,
      "grad_norm": 2.986520290374756,
      "learning_rate": 4.425894558543299e-05,
      "loss": 1.1647,
      "step": 108500
    },
    {
      "epoch": 1.1486229693893215,
      "eval_loss": 1.0607590675354004,
      "eval_runtime": 46.58,
      "eval_samples_per_second": 3605.198,
      "eval_steps_per_second": 450.666,
      "step": 108500
    },
    {
      "epoch": 1.1491522911693248,
      "grad_norm": 2.6610333919525146,
      "learning_rate": 4.425629896252382e-05,
      "loss": 1.1591,
      "step": 108550
    },
    {
      "epoch": 1.149681612949328,
      "grad_norm": 3.0369460582733154,
      "learning_rate": 4.4253652339614657e-05,
      "loss": 1.1558,
      "step": 108600
    },
    {
      "epoch": 1.1502109347293312,
      "grad_norm": 2.8331000804901123,
      "learning_rate": 4.4251005716705484e-05,
      "loss": 1.1664,
      "step": 108650
    },
    {
      "epoch": 1.1507402565093345,
      "grad_norm": 2.903157949447632,
      "learning_rate": 4.424835909379632e-05,
      "loss": 1.1536,
      "step": 108700
    },
    {
      "epoch": 1.1512695782893378,
      "grad_norm": 2.6938138008117676,
      "learning_rate": 4.424571247088715e-05,
      "loss": 1.1525,
      "step": 108750
    },
    {
      "epoch": 1.1517989000693412,
      "grad_norm": 2.9010860919952393,
      "learning_rate": 4.424306584797798e-05,
      "loss": 1.1296,
      "step": 108800
    },
    {
      "epoch": 1.1523282218493445,
      "grad_norm": 2.5880746841430664,
      "learning_rate": 4.4240419225068814e-05,
      "loss": 1.1472,
      "step": 108850
    },
    {
      "epoch": 1.1528575436293478,
      "grad_norm": 2.881528615951538,
      "learning_rate": 4.423777260215964e-05,
      "loss": 1.1529,
      "step": 108900
    },
    {
      "epoch": 1.153386865409351,
      "grad_norm": 2.9057071208953857,
      "learning_rate": 4.423512597925048e-05,
      "loss": 1.175,
      "step": 108950
    },
    {
      "epoch": 1.1539161871893544,
      "grad_norm": 2.9153120517730713,
      "learning_rate": 4.423247935634131e-05,
      "loss": 1.1333,
      "step": 109000
    },
    {
      "epoch": 1.1539161871893544,
      "eval_loss": 1.056573510169983,
      "eval_runtime": 46.5954,
      "eval_samples_per_second": 3604.007,
      "eval_steps_per_second": 450.517,
      "step": 109000
    },
    {
      "epoch": 1.1544455089693575,
      "grad_norm": 2.9603707790374756,
      "learning_rate": 4.422983273343214e-05,
      "loss": 1.1508,
      "step": 109050
    },
    {
      "epoch": 1.1549748307493608,
      "grad_norm": 3.057105779647827,
      "learning_rate": 4.422718611052297e-05,
      "loss": 1.1651,
      "step": 109100
    },
    {
      "epoch": 1.1555041525293641,
      "grad_norm": 2.896955728530884,
      "learning_rate": 4.422453948761381e-05,
      "loss": 1.1604,
      "step": 109150
    },
    {
      "epoch": 1.1560334743093674,
      "grad_norm": 2.9969658851623535,
      "learning_rate": 4.422189286470464e-05,
      "loss": 1.1527,
      "step": 109200
    },
    {
      "epoch": 1.1565627960893707,
      "grad_norm": 3.006075382232666,
      "learning_rate": 4.421924624179547e-05,
      "loss": 1.1703,
      "step": 109250
    },
    {
      "epoch": 1.157092117869374,
      "grad_norm": 2.810108184814453,
      "learning_rate": 4.42165996188863e-05,
      "loss": 1.1599,
      "step": 109300
    },
    {
      "epoch": 1.1576214396493771,
      "grad_norm": 2.8819289207458496,
      "learning_rate": 4.4213952995977134e-05,
      "loss": 1.152,
      "step": 109350
    },
    {
      "epoch": 1.1581507614293804,
      "grad_norm": 2.9216208457946777,
      "learning_rate": 4.421130637306797e-05,
      "loss": 1.1212,
      "step": 109400
    },
    {
      "epoch": 1.1586800832093838,
      "grad_norm": 2.87404727935791,
      "learning_rate": 4.4208659750158796e-05,
      "loss": 1.1687,
      "step": 109450
    },
    {
      "epoch": 1.159209404989387,
      "grad_norm": 2.969627857208252,
      "learning_rate": 4.420606605970781e-05,
      "loss": 1.1412,
      "step": 109500
    },
    {
      "epoch": 1.159209404989387,
      "eval_loss": 1.0543735027313232,
      "eval_runtime": 46.7771,
      "eval_samples_per_second": 3590.003,
      "eval_steps_per_second": 448.766,
      "step": 109500
    },
    {
      "epoch": 1.1597387267693904,
      "grad_norm": 3.053792715072632,
      "learning_rate": 4.420341943679865e-05,
      "loss": 1.1551,
      "step": 109550
    },
    {
      "epoch": 1.1602680485493937,
      "grad_norm": 3.2002952098846436,
      "learning_rate": 4.420077281388948e-05,
      "loss": 1.162,
      "step": 109600
    },
    {
      "epoch": 1.160797370329397,
      "grad_norm": 3.2576498985290527,
      "learning_rate": 4.419812619098031e-05,
      "loss": 1.1539,
      "step": 109650
    },
    {
      "epoch": 1.1613266921094003,
      "grad_norm": 2.7706074714660645,
      "learning_rate": 4.419547956807114e-05,
      "loss": 1.1231,
      "step": 109700
    },
    {
      "epoch": 1.1618560138894036,
      "grad_norm": 2.982156991958618,
      "learning_rate": 4.4192832945161974e-05,
      "loss": 1.1684,
      "step": 109750
    },
    {
      "epoch": 1.1623853356694067,
      "grad_norm": 2.712231159210205,
      "learning_rate": 4.419018632225281e-05,
      "loss": 1.1563,
      "step": 109800
    },
    {
      "epoch": 1.16291465744941,
      "grad_norm": 3.068887710571289,
      "learning_rate": 4.4187539699343635e-05,
      "loss": 1.1557,
      "step": 109850
    },
    {
      "epoch": 1.1634439792294133,
      "grad_norm": 2.8000717163085938,
      "learning_rate": 4.418489307643447e-05,
      "loss": 1.1572,
      "step": 109900
    },
    {
      "epoch": 1.1639733010094166,
      "grad_norm": 3.105055332183838,
      "learning_rate": 4.4182246453525304e-05,
      "loss": 1.1604,
      "step": 109950
    },
    {
      "epoch": 1.16450262278942,
      "grad_norm": 2.955142021179199,
      "learning_rate": 4.417959983061614e-05,
      "loss": 1.1641,
      "step": 110000
    },
    {
      "epoch": 1.16450262278942,
      "eval_loss": 1.0514421463012695,
      "eval_runtime": 46.6877,
      "eval_samples_per_second": 3596.876,
      "eval_steps_per_second": 449.626,
      "step": 110000
    },
    {
      "epoch": 1.1650319445694233,
      "grad_norm": 2.9401872158050537,
      "learning_rate": 4.4176953207706965e-05,
      "loss": 1.1454,
      "step": 110050
    },
    {
      "epoch": 1.1655612663494264,
      "grad_norm": 2.64399790763855,
      "learning_rate": 4.41743065847978e-05,
      "loss": 1.1583,
      "step": 110100
    },
    {
      "epoch": 1.1660905881294297,
      "grad_norm": 2.9856491088867188,
      "learning_rate": 4.417165996188863e-05,
      "loss": 1.1521,
      "step": 110150
    },
    {
      "epoch": 1.166619909909433,
      "grad_norm": 2.9759693145751953,
      "learning_rate": 4.416901333897947e-05,
      "loss": 1.1442,
      "step": 110200
    },
    {
      "epoch": 1.1671492316894363,
      "grad_norm": 3.1039211750030518,
      "learning_rate": 4.4166366716070295e-05,
      "loss": 1.1602,
      "step": 110250
    },
    {
      "epoch": 1.1676785534694396,
      "grad_norm": 3.0126912593841553,
      "learning_rate": 4.416372009316113e-05,
      "loss": 1.1427,
      "step": 110300
    },
    {
      "epoch": 1.168207875249443,
      "grad_norm": 2.9789600372314453,
      "learning_rate": 4.416107347025196e-05,
      "loss": 1.1406,
      "step": 110350
    },
    {
      "epoch": 1.1687371970294462,
      "grad_norm": 3.226952075958252,
      "learning_rate": 4.415842684734279e-05,
      "loss": 1.1677,
      "step": 110400
    },
    {
      "epoch": 1.1692665188094495,
      "grad_norm": 3.2497920989990234,
      "learning_rate": 4.4155780224433624e-05,
      "loss": 1.1429,
      "step": 110450
    },
    {
      "epoch": 1.1697958405894529,
      "grad_norm": 2.9454236030578613,
      "learning_rate": 4.415313360152445e-05,
      "loss": 1.1449,
      "step": 110500
    },
    {
      "epoch": 1.1697958405894529,
      "eval_loss": 1.0498130321502686,
      "eval_runtime": 46.6904,
      "eval_samples_per_second": 3596.67,
      "eval_steps_per_second": 449.6,
      "step": 110500
    },
    {
      "epoch": 1.170325162369456,
      "grad_norm": 3.0634162425994873,
      "learning_rate": 4.415048697861529e-05,
      "loss": 1.1458,
      "step": 110550
    },
    {
      "epoch": 1.1708544841494593,
      "grad_norm": 3.0082859992980957,
      "learning_rate": 4.414784035570612e-05,
      "loss": 1.1471,
      "step": 110600
    },
    {
      "epoch": 1.1713838059294626,
      "grad_norm": 2.9576804637908936,
      "learning_rate": 4.4145193732796954e-05,
      "loss": 1.1458,
      "step": 110650
    },
    {
      "epoch": 1.1719131277094659,
      "grad_norm": 3.2385778427124023,
      "learning_rate": 4.414254710988778e-05,
      "loss": 1.1732,
      "step": 110700
    },
    {
      "epoch": 1.1724424494894692,
      "grad_norm": 3.1693899631500244,
      "learning_rate": 4.413990048697862e-05,
      "loss": 1.1501,
      "step": 110750
    },
    {
      "epoch": 1.1729717712694725,
      "grad_norm": 2.814164638519287,
      "learning_rate": 4.413725386406945e-05,
      "loss": 1.1589,
      "step": 110800
    },
    {
      "epoch": 1.1735010930494756,
      "grad_norm": 2.986452341079712,
      "learning_rate": 4.4134607241160284e-05,
      "loss": 1.1625,
      "step": 110850
    },
    {
      "epoch": 1.174030414829479,
      "grad_norm": 3.036306619644165,
      "learning_rate": 4.413196061825111e-05,
      "loss": 1.1325,
      "step": 110900
    },
    {
      "epoch": 1.1745597366094822,
      "grad_norm": 2.7230348587036133,
      "learning_rate": 4.4129313995341945e-05,
      "loss": 1.1211,
      "step": 110950
    },
    {
      "epoch": 1.1750890583894855,
      "grad_norm": 2.9766080379486084,
      "learning_rate": 4.412666737243278e-05,
      "loss": 1.1415,
      "step": 111000
    },
    {
      "epoch": 1.1750890583894855,
      "eval_loss": 1.0497283935546875,
      "eval_runtime": 46.6896,
      "eval_samples_per_second": 3596.731,
      "eval_steps_per_second": 449.607,
      "step": 111000
    },
    {
      "epoch": 1.1756183801694888,
      "grad_norm": 2.912548542022705,
      "learning_rate": 4.4124020749523606e-05,
      "loss": 1.1563,
      "step": 111050
    },
    {
      "epoch": 1.1761477019494921,
      "grad_norm": 3.0158913135528564,
      "learning_rate": 4.412137412661444e-05,
      "loss": 1.1381,
      "step": 111100
    },
    {
      "epoch": 1.1766770237294955,
      "grad_norm": 2.9100537300109863,
      "learning_rate": 4.4118727503705275e-05,
      "loss": 1.1369,
      "step": 111150
    },
    {
      "epoch": 1.1772063455094988,
      "grad_norm": 2.5629072189331055,
      "learning_rate": 4.411608088079611e-05,
      "loss": 1.1466,
      "step": 111200
    },
    {
      "epoch": 1.177735667289502,
      "grad_norm": 3.2961199283599854,
      "learning_rate": 4.4113434257886936e-05,
      "loss": 1.1209,
      "step": 111250
    },
    {
      "epoch": 1.1782649890695052,
      "grad_norm": 2.903704881668091,
      "learning_rate": 4.411078763497777e-05,
      "loss": 1.1427,
      "step": 111300
    },
    {
      "epoch": 1.1787943108495085,
      "grad_norm": 2.9522621631622314,
      "learning_rate": 4.4108141012068604e-05,
      "loss": 1.1369,
      "step": 111350
    },
    {
      "epoch": 1.1793236326295118,
      "grad_norm": 2.852890968322754,
      "learning_rate": 4.410549438915944e-05,
      "loss": 1.1606,
      "step": 111400
    },
    {
      "epoch": 1.179852954409515,
      "grad_norm": 3.1336870193481445,
      "learning_rate": 4.4102847766250266e-05,
      "loss": 1.189,
      "step": 111450
    },
    {
      "epoch": 1.1803822761895184,
      "grad_norm": 2.792600154876709,
      "learning_rate": 4.41002011433411e-05,
      "loss": 1.1362,
      "step": 111500
    },
    {
      "epoch": 1.1803822761895184,
      "eval_loss": 1.0484293699264526,
      "eval_runtime": 46.6966,
      "eval_samples_per_second": 3596.196,
      "eval_steps_per_second": 449.541,
      "step": 111500
    },
    {
      "epoch": 1.1809115979695217,
      "grad_norm": 2.627725839614868,
      "learning_rate": 4.4097607452890114e-05,
      "loss": 1.1507,
      "step": 111550
    },
    {
      "epoch": 1.1814409197495248,
      "grad_norm": 2.8253304958343506,
      "learning_rate": 4.409496082998095e-05,
      "loss": 1.1561,
      "step": 111600
    },
    {
      "epoch": 1.1819702415295281,
      "grad_norm": 2.9448165893554688,
      "learning_rate": 4.4092314207071776e-05,
      "loss": 1.1567,
      "step": 111650
    },
    {
      "epoch": 1.1824995633095314,
      "grad_norm": 2.864367723464966,
      "learning_rate": 4.408966758416261e-05,
      "loss": 1.1478,
      "step": 111700
    },
    {
      "epoch": 1.1830288850895347,
      "grad_norm": 3.1650493144989014,
      "learning_rate": 4.4087020961253444e-05,
      "loss": 1.1719,
      "step": 111750
    },
    {
      "epoch": 1.183558206869538,
      "grad_norm": 2.87723708152771,
      "learning_rate": 4.408437433834428e-05,
      "loss": 1.137,
      "step": 111800
    },
    {
      "epoch": 1.1840875286495414,
      "grad_norm": 2.958308696746826,
      "learning_rate": 4.4081727715435106e-05,
      "loss": 1.1406,
      "step": 111850
    },
    {
      "epoch": 1.1846168504295447,
      "grad_norm": 3.060378313064575,
      "learning_rate": 4.407908109252594e-05,
      "loss": 1.1435,
      "step": 111900
    },
    {
      "epoch": 1.185146172209548,
      "grad_norm": 2.948310136795044,
      "learning_rate": 4.4076434469616774e-05,
      "loss": 1.1322,
      "step": 111950
    },
    {
      "epoch": 1.1856754939895513,
      "grad_norm": 3.007892370223999,
      "learning_rate": 4.40737878467076e-05,
      "loss": 1.146,
      "step": 112000
    },
    {
      "epoch": 1.1856754939895513,
      "eval_loss": 1.0440860986709595,
      "eval_runtime": 46.5738,
      "eval_samples_per_second": 3605.672,
      "eval_steps_per_second": 450.725,
      "step": 112000
    },
    {
      "epoch": 1.1862048157695544,
      "grad_norm": 2.8194398880004883,
      "learning_rate": 4.4071141223798435e-05,
      "loss": 1.1413,
      "step": 112050
    },
    {
      "epoch": 1.1867341375495577,
      "grad_norm": 2.9889211654663086,
      "learning_rate": 4.406849460088926e-05,
      "loss": 1.168,
      "step": 112100
    },
    {
      "epoch": 1.187263459329561,
      "grad_norm": 3.014857292175293,
      "learning_rate": 4.40658479779801e-05,
      "loss": 1.1566,
      "step": 112150
    },
    {
      "epoch": 1.1877927811095643,
      "grad_norm": 2.7593979835510254,
      "learning_rate": 4.406320135507093e-05,
      "loss": 1.1286,
      "step": 112200
    },
    {
      "epoch": 1.1883221028895676,
      "grad_norm": 3.0810563564300537,
      "learning_rate": 4.4060554732161765e-05,
      "loss": 1.1419,
      "step": 112250
    },
    {
      "epoch": 1.188851424669571,
      "grad_norm": 2.861513137817383,
      "learning_rate": 4.405790810925259e-05,
      "loss": 1.1551,
      "step": 112300
    },
    {
      "epoch": 1.1893807464495743,
      "grad_norm": 2.745257616043091,
      "learning_rate": 4.405526148634343e-05,
      "loss": 1.141,
      "step": 112350
    },
    {
      "epoch": 1.1899100682295773,
      "grad_norm": 2.802949905395508,
      "learning_rate": 4.405261486343426e-05,
      "loss": 1.1326,
      "step": 112400
    },
    {
      "epoch": 1.1904393900095807,
      "grad_norm": 3.0005388259887695,
      "learning_rate": 4.4049968240525094e-05,
      "loss": 1.1525,
      "step": 112450
    },
    {
      "epoch": 1.190968711789584,
      "grad_norm": 2.8307716846466064,
      "learning_rate": 4.404732161761592e-05,
      "loss": 1.1351,
      "step": 112500
    },
    {
      "epoch": 1.190968711789584,
      "eval_loss": 1.0416163206100464,
      "eval_runtime": 46.5758,
      "eval_samples_per_second": 3605.52,
      "eval_steps_per_second": 450.706,
      "step": 112500
    },
    {
      "epoch": 1.1914980335695873,
      "grad_norm": 2.7629024982452393,
      "learning_rate": 4.4044674994706756e-05,
      "loss": 1.1316,
      "step": 112550
    },
    {
      "epoch": 1.1920273553495906,
      "grad_norm": 3.0833516120910645,
      "learning_rate": 4.404202837179759e-05,
      "loss": 1.1523,
      "step": 112600
    },
    {
      "epoch": 1.192556677129594,
      "grad_norm": 2.8899152278900146,
      "learning_rate": 4.403938174888842e-05,
      "loss": 1.131,
      "step": 112650
    },
    {
      "epoch": 1.1930859989095972,
      "grad_norm": 3.0023248195648193,
      "learning_rate": 4.403673512597925e-05,
      "loss": 1.1492,
      "step": 112700
    },
    {
      "epoch": 1.1936153206896005,
      "grad_norm": 3.1211345195770264,
      "learning_rate": 4.4034088503070085e-05,
      "loss": 1.1353,
      "step": 112750
    },
    {
      "epoch": 1.1941446424696036,
      "grad_norm": 3.3341896533966064,
      "learning_rate": 4.403144188016092e-05,
      "loss": 1.1344,
      "step": 112800
    },
    {
      "epoch": 1.194673964249607,
      "grad_norm": 2.9631240367889404,
      "learning_rate": 4.402879525725175e-05,
      "loss": 1.1364,
      "step": 112850
    },
    {
      "epoch": 1.1952032860296102,
      "grad_norm": 3.1085572242736816,
      "learning_rate": 4.402614863434258e-05,
      "loss": 1.1472,
      "step": 112900
    },
    {
      "epoch": 1.1957326078096135,
      "grad_norm": 3.277472734451294,
      "learning_rate": 4.4023502011433415e-05,
      "loss": 1.1454,
      "step": 112950
    },
    {
      "epoch": 1.1962619295896169,
      "grad_norm": 2.9982242584228516,
      "learning_rate": 4.402085538852425e-05,
      "loss": 1.1454,
      "step": 113000
    },
    {
      "epoch": 1.1962619295896169,
      "eval_loss": 1.0414952039718628,
      "eval_runtime": 46.6434,
      "eval_samples_per_second": 3600.291,
      "eval_steps_per_second": 450.052,
      "step": 113000
    },
    {
      "epoch": 1.1967912513696202,
      "grad_norm": 2.967923402786255,
      "learning_rate": 4.4018208765615077e-05,
      "loss": 1.1281,
      "step": 113050
    },
    {
      "epoch": 1.1973205731496235,
      "grad_norm": 3.0622801780700684,
      "learning_rate": 4.401556214270591e-05,
      "loss": 1.1358,
      "step": 113100
    },
    {
      "epoch": 1.1978498949296266,
      "grad_norm": 2.8996806144714355,
      "learning_rate": 4.4012915519796745e-05,
      "loss": 1.1336,
      "step": 113150
    },
    {
      "epoch": 1.1983792167096299,
      "grad_norm": 3.071302652359009,
      "learning_rate": 4.401026889688757e-05,
      "loss": 1.1489,
      "step": 113200
    },
    {
      "epoch": 1.1989085384896332,
      "grad_norm": 2.996717929840088,
      "learning_rate": 4.4007622273978406e-05,
      "loss": 1.1325,
      "step": 113250
    },
    {
      "epoch": 1.1994378602696365,
      "grad_norm": 2.7184290885925293,
      "learning_rate": 4.4004975651069233e-05,
      "loss": 1.143,
      "step": 113300
    },
    {
      "epoch": 1.1999671820496398,
      "grad_norm": 2.809102773666382,
      "learning_rate": 4.4002329028160074e-05,
      "loss": 1.1508,
      "step": 113350
    },
    {
      "epoch": 1.2004965038296431,
      "grad_norm": 3.056246519088745,
      "learning_rate": 4.39996824052509e-05,
      "loss": 1.1416,
      "step": 113400
    },
    {
      "epoch": 1.2010258256096464,
      "grad_norm": 2.8664262294769287,
      "learning_rate": 4.3997035782341736e-05,
      "loss": 1.1413,
      "step": 113450
    },
    {
      "epoch": 1.2015551473896497,
      "grad_norm": 2.9792320728302,
      "learning_rate": 4.399438915943256e-05,
      "loss": 1.1371,
      "step": 113500
    },
    {
      "epoch": 1.2015551473896497,
      "eval_loss": 1.0359697341918945,
      "eval_runtime": 46.7108,
      "eval_samples_per_second": 3595.097,
      "eval_steps_per_second": 449.403,
      "step": 113500
    },
    {
      "epoch": 1.2020844691696528,
      "grad_norm": 2.629880905151367,
      "learning_rate": 4.39917425365234e-05,
      "loss": 1.1448,
      "step": 113550
    },
    {
      "epoch": 1.2026137909496561,
      "grad_norm": 2.837942600250244,
      "learning_rate": 4.398909591361423e-05,
      "loss": 1.142,
      "step": 113600
    },
    {
      "epoch": 1.2031431127296595,
      "grad_norm": 2.715181827545166,
      "learning_rate": 4.398644929070506e-05,
      "loss": 1.1245,
      "step": 113650
    },
    {
      "epoch": 1.2036724345096628,
      "grad_norm": 3.503678321838379,
      "learning_rate": 4.398385560025407e-05,
      "loss": 1.1524,
      "step": 113700
    },
    {
      "epoch": 1.204201756289666,
      "grad_norm": 2.990865468978882,
      "learning_rate": 4.3981208977344914e-05,
      "loss": 1.1212,
      "step": 113750
    },
    {
      "epoch": 1.2047310780696694,
      "grad_norm": 2.9075820446014404,
      "learning_rate": 4.397856235443574e-05,
      "loss": 1.1207,
      "step": 113800
    },
    {
      "epoch": 1.2052603998496727,
      "grad_norm": 3.4204108715057373,
      "learning_rate": 4.3975915731526576e-05,
      "loss": 1.1435,
      "step": 113850
    },
    {
      "epoch": 1.2057897216296758,
      "grad_norm": 2.837890148162842,
      "learning_rate": 4.39732691086174e-05,
      "loss": 1.1618,
      "step": 113900
    },
    {
      "epoch": 1.206319043409679,
      "grad_norm": 3.0755460262298584,
      "learning_rate": 4.3970622485708244e-05,
      "loss": 1.1273,
      "step": 113950
    },
    {
      "epoch": 1.2068483651896824,
      "grad_norm": 2.653027296066284,
      "learning_rate": 4.396797586279907e-05,
      "loss": 1.1429,
      "step": 114000
    },
    {
      "epoch": 1.2068483651896824,
      "eval_loss": 1.034669280052185,
      "eval_runtime": 46.6288,
      "eval_samples_per_second": 3601.424,
      "eval_steps_per_second": 450.194,
      "step": 114000
    },
    {
      "epoch": 1.2073776869696857,
      "grad_norm": 3.13826584815979,
      "learning_rate": 4.3965329239889905e-05,
      "loss": 1.1236,
      "step": 114050
    },
    {
      "epoch": 1.207907008749689,
      "grad_norm": 3.0445094108581543,
      "learning_rate": 4.396268261698073e-05,
      "loss": 1.1307,
      "step": 114100
    },
    {
      "epoch": 1.2084363305296923,
      "grad_norm": 2.965050458908081,
      "learning_rate": 4.396003599407157e-05,
      "loss": 1.1366,
      "step": 114150
    },
    {
      "epoch": 1.2089656523096957,
      "grad_norm": 2.919708490371704,
      "learning_rate": 4.39573893711624e-05,
      "loss": 1.1177,
      "step": 114200
    },
    {
      "epoch": 1.209494974089699,
      "grad_norm": 2.9170103073120117,
      "learning_rate": 4.395474274825323e-05,
      "loss": 1.1484,
      "step": 114250
    },
    {
      "epoch": 1.210024295869702,
      "grad_norm": 2.9282076358795166,
      "learning_rate": 4.395209612534406e-05,
      "loss": 1.1353,
      "step": 114300
    },
    {
      "epoch": 1.2105536176497054,
      "grad_norm": 3.181643009185791,
      "learning_rate": 4.3949449502434896e-05,
      "loss": 1.1158,
      "step": 114350
    },
    {
      "epoch": 1.2110829394297087,
      "grad_norm": 3.102825880050659,
      "learning_rate": 4.394680287952573e-05,
      "loss": 1.1603,
      "step": 114400
    },
    {
      "epoch": 1.211612261209712,
      "grad_norm": 3.0961740016937256,
      "learning_rate": 4.394415625661656e-05,
      "loss": 1.1352,
      "step": 114450
    },
    {
      "epoch": 1.2121415829897153,
      "grad_norm": 3.1947996616363525,
      "learning_rate": 4.394150963370739e-05,
      "loss": 1.1354,
      "step": 114500
    },
    {
      "epoch": 1.2121415829897153,
      "eval_loss": 1.030785322189331,
      "eval_runtime": 46.7435,
      "eval_samples_per_second": 3592.586,
      "eval_steps_per_second": 449.089,
      "step": 114500
    },
    {
      "epoch": 1.2126709047697186,
      "grad_norm": 3.179537534713745,
      "learning_rate": 4.3938863010798226e-05,
      "loss": 1.1463,
      "step": 114550
    },
    {
      "epoch": 1.213200226549722,
      "grad_norm": 3.0598580837249756,
      "learning_rate": 4.393621638788905e-05,
      "loss": 1.1477,
      "step": 114600
    },
    {
      "epoch": 1.213729548329725,
      "grad_norm": 3.102283477783203,
      "learning_rate": 4.393356976497989e-05,
      "loss": 1.1345,
      "step": 114650
    },
    {
      "epoch": 1.2142588701097283,
      "grad_norm": 2.6505844593048096,
      "learning_rate": 4.3930923142070715e-05,
      "loss": 1.1472,
      "step": 114700
    },
    {
      "epoch": 1.2147881918897316,
      "grad_norm": 2.840299367904663,
      "learning_rate": 4.3928276519161556e-05,
      "loss": 1.1381,
      "step": 114750
    },
    {
      "epoch": 1.215317513669735,
      "grad_norm": 2.918675661087036,
      "learning_rate": 4.392562989625238e-05,
      "loss": 1.1472,
      "step": 114800
    },
    {
      "epoch": 1.2158468354497383,
      "grad_norm": 3.015348196029663,
      "learning_rate": 4.392298327334322e-05,
      "loss": 1.1241,
      "step": 114850
    },
    {
      "epoch": 1.2163761572297416,
      "grad_norm": 2.914196014404297,
      "learning_rate": 4.3920336650434044e-05,
      "loss": 1.1339,
      "step": 114900
    },
    {
      "epoch": 1.2169054790097449,
      "grad_norm": 2.8636717796325684,
      "learning_rate": 4.3917690027524885e-05,
      "loss": 1.1394,
      "step": 114950
    },
    {
      "epoch": 1.2174348007897482,
      "grad_norm": 3.312913656234741,
      "learning_rate": 4.391504340461571e-05,
      "loss": 1.1466,
      "step": 115000
    },
    {
      "epoch": 1.2174348007897482,
      "eval_loss": 1.0308427810668945,
      "eval_runtime": 46.6159,
      "eval_samples_per_second": 3602.42,
      "eval_steps_per_second": 450.319,
      "step": 115000
    },
    {
      "epoch": 1.2179641225697513,
      "grad_norm": 2.991945266723633,
      "learning_rate": 4.3912396781706547e-05,
      "loss": 1.1414,
      "step": 115050
    },
    {
      "epoch": 1.2184934443497546,
      "grad_norm": 2.7125329971313477,
      "learning_rate": 4.3909750158797374e-05,
      "loss": 1.1345,
      "step": 115100
    },
    {
      "epoch": 1.219022766129758,
      "grad_norm": 3.0082547664642334,
      "learning_rate": 4.390710353588821e-05,
      "loss": 1.1305,
      "step": 115150
    },
    {
      "epoch": 1.2195520879097612,
      "grad_norm": 2.862851858139038,
      "learning_rate": 4.390445691297904e-05,
      "loss": 1.1427,
      "step": 115200
    },
    {
      "epoch": 1.2200814096897645,
      "grad_norm": 3.0661706924438477,
      "learning_rate": 4.390181029006987e-05,
      "loss": 1.1416,
      "step": 115250
    },
    {
      "epoch": 1.2206107314697678,
      "grad_norm": 2.9979474544525146,
      "learning_rate": 4.3899163667160704e-05,
      "loss": 1.1294,
      "step": 115300
    },
    {
      "epoch": 1.2211400532497712,
      "grad_norm": 2.682497262954712,
      "learning_rate": 4.389651704425154e-05,
      "loss": 1.1508,
      "step": 115350
    },
    {
      "epoch": 1.2216693750297742,
      "grad_norm": 2.675206184387207,
      "learning_rate": 4.389387042134237e-05,
      "loss": 1.1274,
      "step": 115400
    },
    {
      "epoch": 1.2221986968097776,
      "grad_norm": 3.0335466861724854,
      "learning_rate": 4.38912237984332e-05,
      "loss": 1.1379,
      "step": 115450
    },
    {
      "epoch": 1.2227280185897809,
      "grad_norm": 3.0746731758117676,
      "learning_rate": 4.388857717552403e-05,
      "loss": 1.1299,
      "step": 115500
    },
    {
      "epoch": 1.2227280185897809,
      "eval_loss": 1.0275194644927979,
      "eval_runtime": 46.7055,
      "eval_samples_per_second": 3595.505,
      "eval_steps_per_second": 449.454,
      "step": 115500
    },
    {
      "epoch": 1.2232573403697842,
      "grad_norm": 2.946279287338257,
      "learning_rate": 4.388593055261487e-05,
      "loss": 1.1353,
      "step": 115550
    },
    {
      "epoch": 1.2237866621497875,
      "grad_norm": 2.780864715576172,
      "learning_rate": 4.38832839297057e-05,
      "loss": 1.1195,
      "step": 115600
    },
    {
      "epoch": 1.2243159839297908,
      "grad_norm": 3.027214288711548,
      "learning_rate": 4.388063730679653e-05,
      "loss": 1.124,
      "step": 115650
    },
    {
      "epoch": 1.224845305709794,
      "grad_norm": 3.260312557220459,
      "learning_rate": 4.387799068388736e-05,
      "loss": 1.134,
      "step": 115700
    },
    {
      "epoch": 1.2253746274897974,
      "grad_norm": 2.8497262001037598,
      "learning_rate": 4.38753440609782e-05,
      "loss": 1.1351,
      "step": 115750
    },
    {
      "epoch": 1.2259039492698005,
      "grad_norm": 3.088745594024658,
      "learning_rate": 4.3872697438069024e-05,
      "loss": 1.125,
      "step": 115800
    },
    {
      "epoch": 1.2264332710498038,
      "grad_norm": 2.639824390411377,
      "learning_rate": 4.387005081515986e-05,
      "loss": 1.1254,
      "step": 115850
    },
    {
      "epoch": 1.2269625928298071,
      "grad_norm": 3.0427682399749756,
      "learning_rate": 4.386745712470887e-05,
      "loss": 1.1338,
      "step": 115900
    },
    {
      "epoch": 1.2274919146098104,
      "grad_norm": 2.906601667404175,
      "learning_rate": 4.386481050179971e-05,
      "loss": 1.1485,
      "step": 115950
    },
    {
      "epoch": 1.2280212363898138,
      "grad_norm": 2.903613567352295,
      "learning_rate": 4.386216387889054e-05,
      "loss": 1.1294,
      "step": 116000
    },
    {
      "epoch": 1.2280212363898138,
      "eval_loss": 1.0242085456848145,
      "eval_runtime": 46.6052,
      "eval_samples_per_second": 3603.245,
      "eval_steps_per_second": 450.422,
      "step": 116000
    },
    {
      "epoch": 1.228550558169817,
      "grad_norm": 2.9838345050811768,
      "learning_rate": 4.385951725598137e-05,
      "loss": 1.1435,
      "step": 116050
    },
    {
      "epoch": 1.2290798799498204,
      "grad_norm": 2.6677794456481934,
      "learning_rate": 4.38568706330722e-05,
      "loss": 1.1232,
      "step": 116100
    },
    {
      "epoch": 1.2296092017298235,
      "grad_norm": 2.974257230758667,
      "learning_rate": 4.385422401016304e-05,
      "loss": 1.134,
      "step": 116150
    },
    {
      "epoch": 1.2301385235098268,
      "grad_norm": 3.245093584060669,
      "learning_rate": 4.3851577387253864e-05,
      "loss": 1.1489,
      "step": 116200
    },
    {
      "epoch": 1.23066784528983,
      "grad_norm": 2.6822261810302734,
      "learning_rate": 4.38489307643447e-05,
      "loss": 1.1265,
      "step": 116250
    },
    {
      "epoch": 1.2311971670698334,
      "grad_norm": 3.0509965419769287,
      "learning_rate": 4.3846284141435525e-05,
      "loss": 1.1361,
      "step": 116300
    },
    {
      "epoch": 1.2317264888498367,
      "grad_norm": 3.1861650943756104,
      "learning_rate": 4.3843637518526366e-05,
      "loss": 1.1398,
      "step": 116350
    },
    {
      "epoch": 1.23225581062984,
      "grad_norm": 3.178844690322876,
      "learning_rate": 4.3840990895617194e-05,
      "loss": 1.1164,
      "step": 116400
    },
    {
      "epoch": 1.2327851324098433,
      "grad_norm": 3.0734336376190186,
      "learning_rate": 4.383834427270803e-05,
      "loss": 1.1383,
      "step": 116450
    },
    {
      "epoch": 1.2333144541898466,
      "grad_norm": 2.703547716140747,
      "learning_rate": 4.3835697649798855e-05,
      "loss": 1.1227,
      "step": 116500
    },
    {
      "epoch": 1.2333144541898466,
      "eval_loss": 1.0246130228042603,
      "eval_runtime": 46.8268,
      "eval_samples_per_second": 3586.194,
      "eval_steps_per_second": 448.29,
      "step": 116500
    },
    {
      "epoch": 1.23384377596985,
      "grad_norm": 2.928907871246338,
      "learning_rate": 4.3833051026889696e-05,
      "loss": 1.146,
      "step": 116550
    },
    {
      "epoch": 1.234373097749853,
      "grad_norm": 3.026139974594116,
      "learning_rate": 4.383040440398052e-05,
      "loss": 1.1219,
      "step": 116600
    },
    {
      "epoch": 1.2349024195298564,
      "grad_norm": 2.8541958332061768,
      "learning_rate": 4.382775778107136e-05,
      "loss": 1.1374,
      "step": 116650
    },
    {
      "epoch": 1.2354317413098597,
      "grad_norm": 2.7597451210021973,
      "learning_rate": 4.3825111158162185e-05,
      "loss": 1.1345,
      "step": 116700
    },
    {
      "epoch": 1.235961063089863,
      "grad_norm": 2.8570821285247803,
      "learning_rate": 4.382246453525302e-05,
      "loss": 1.1371,
      "step": 116750
    },
    {
      "epoch": 1.2364903848698663,
      "grad_norm": 3.010380268096924,
      "learning_rate": 4.381981791234385e-05,
      "loss": 1.121,
      "step": 116800
    },
    {
      "epoch": 1.2370197066498696,
      "grad_norm": 3.207902193069458,
      "learning_rate": 4.381717128943468e-05,
      "loss": 1.1245,
      "step": 116850
    },
    {
      "epoch": 1.2375490284298727,
      "grad_norm": 2.9375293254852295,
      "learning_rate": 4.3814524666525514e-05,
      "loss": 1.1454,
      "step": 116900
    },
    {
      "epoch": 1.238078350209876,
      "grad_norm": 3.4423165321350098,
      "learning_rate": 4.381187804361635e-05,
      "loss": 1.1458,
      "step": 116950
    },
    {
      "epoch": 1.2386076719898793,
      "grad_norm": 2.8539676666259766,
      "learning_rate": 4.380923142070718e-05,
      "loss": 1.113,
      "step": 117000
    },
    {
      "epoch": 1.2386076719898793,
      "eval_loss": 1.0229105949401855,
      "eval_runtime": 46.6394,
      "eval_samples_per_second": 3600.605,
      "eval_steps_per_second": 450.092,
      "step": 117000
    },
    {
      "epoch": 1.2391369937698826,
      "grad_norm": 2.9045844078063965,
      "learning_rate": 4.380658479779801e-05,
      "loss": 1.1271,
      "step": 117050
    },
    {
      "epoch": 1.239666315549886,
      "grad_norm": 3.187493324279785,
      "learning_rate": 4.3803938174888844e-05,
      "loss": 1.1008,
      "step": 117100
    },
    {
      "epoch": 1.2401956373298892,
      "grad_norm": 2.9808287620544434,
      "learning_rate": 4.380129155197968e-05,
      "loss": 1.131,
      "step": 117150
    },
    {
      "epoch": 1.2407249591098926,
      "grad_norm": 2.812540054321289,
      "learning_rate": 4.379864492907051e-05,
      "loss": 1.1212,
      "step": 117200
    },
    {
      "epoch": 1.2412542808898959,
      "grad_norm": 3.482438325881958,
      "learning_rate": 4.379599830616134e-05,
      "loss": 1.1463,
      "step": 117250
    },
    {
      "epoch": 1.2417836026698992,
      "grad_norm": 2.7829182147979736,
      "learning_rate": 4.3793351683252174e-05,
      "loss": 1.1296,
      "step": 117300
    },
    {
      "epoch": 1.2423129244499023,
      "grad_norm": 3.078244924545288,
      "learning_rate": 4.379070506034301e-05,
      "loss": 1.1445,
      "step": 117350
    },
    {
      "epoch": 1.2428422462299056,
      "grad_norm": 2.94509220123291,
      "learning_rate": 4.3788058437433835e-05,
      "loss": 1.1382,
      "step": 117400
    },
    {
      "epoch": 1.243371568009909,
      "grad_norm": 2.7656190395355225,
      "learning_rate": 4.378541181452467e-05,
      "loss": 1.1147,
      "step": 117450
    },
    {
      "epoch": 1.2439008897899122,
      "grad_norm": 3.1659657955169678,
      "learning_rate": 4.3782765191615496e-05,
      "loss": 1.1327,
      "step": 117500
    },
    {
      "epoch": 1.2439008897899122,
      "eval_loss": 1.0196897983551025,
      "eval_runtime": 46.8636,
      "eval_samples_per_second": 3583.377,
      "eval_steps_per_second": 447.938,
      "step": 117500
    },
    {
      "epoch": 1.2444302115699155,
      "grad_norm": 3.070958137512207,
      "learning_rate": 4.378011856870634e-05,
      "loss": 1.1389,
      "step": 117550
    },
    {
      "epoch": 1.2449595333499188,
      "grad_norm": 2.8483152389526367,
      "learning_rate": 4.3777471945797165e-05,
      "loss": 1.1124,
      "step": 117600
    },
    {
      "epoch": 1.245488855129922,
      "grad_norm": 3.1105711460113525,
      "learning_rate": 4.3774825322888e-05,
      "loss": 1.1341,
      "step": 117650
    },
    {
      "epoch": 1.2460181769099252,
      "grad_norm": 3.1152801513671875,
      "learning_rate": 4.3772178699978826e-05,
      "loss": 1.1381,
      "step": 117700
    },
    {
      "epoch": 1.2465474986899285,
      "grad_norm": 2.960082769393921,
      "learning_rate": 4.376953207706967e-05,
      "loss": 1.1249,
      "step": 117750
    },
    {
      "epoch": 1.2470768204699318,
      "grad_norm": 3.057582139968872,
      "learning_rate": 4.3766885454160494e-05,
      "loss": 1.1364,
      "step": 117800
    },
    {
      "epoch": 1.2476061422499352,
      "grad_norm": 3.034252166748047,
      "learning_rate": 4.376423883125133e-05,
      "loss": 1.1265,
      "step": 117850
    },
    {
      "epoch": 1.2481354640299385,
      "grad_norm": 2.774794578552246,
      "learning_rate": 4.3761645140800336e-05,
      "loss": 1.1326,
      "step": 117900
    },
    {
      "epoch": 1.2486647858099418,
      "grad_norm": 2.6532790660858154,
      "learning_rate": 4.375899851789118e-05,
      "loss": 1.1185,
      "step": 117950
    },
    {
      "epoch": 1.249194107589945,
      "grad_norm": 3.1037490367889404,
      "learning_rate": 4.3756351894982004e-05,
      "loss": 1.1151,
      "step": 118000
    },
    {
      "epoch": 1.249194107589945,
      "eval_loss": 1.0180912017822266,
      "eval_runtime": 46.7109,
      "eval_samples_per_second": 3595.09,
      "eval_steps_per_second": 449.402,
      "step": 118000
    },
    {
      "epoch": 1.2497234293699484,
      "grad_norm": 3.1432015895843506,
      "learning_rate": 4.375370527207284e-05,
      "loss": 1.1291,
      "step": 118050
    },
    {
      "epoch": 1.2502527511499515,
      "grad_norm": 3.1703577041625977,
      "learning_rate": 4.3751058649163666e-05,
      "loss": 1.1208,
      "step": 118100
    },
    {
      "epoch": 1.2507820729299548,
      "grad_norm": 3.249232530593872,
      "learning_rate": 4.374841202625451e-05,
      "loss": 1.1295,
      "step": 118150
    },
    {
      "epoch": 1.2513113947099581,
      "grad_norm": 3.1195199489593506,
      "learning_rate": 4.3745765403345334e-05,
      "loss": 1.137,
      "step": 118200
    },
    {
      "epoch": 1.2518407164899614,
      "grad_norm": 2.763624429702759,
      "learning_rate": 4.374311878043617e-05,
      "loss": 1.1255,
      "step": 118250
    },
    {
      "epoch": 1.2523700382699647,
      "grad_norm": 3.2233240604400635,
      "learning_rate": 4.3740472157526996e-05,
      "loss": 1.1143,
      "step": 118300
    },
    {
      "epoch": 1.252899360049968,
      "grad_norm": 3.2757890224456787,
      "learning_rate": 4.373782553461783e-05,
      "loss": 1.1259,
      "step": 118350
    },
    {
      "epoch": 1.2534286818299711,
      "grad_norm": 3.085221290588379,
      "learning_rate": 4.3735178911708664e-05,
      "loss": 1.1311,
      "step": 118400
    },
    {
      "epoch": 1.2539580036099744,
      "grad_norm": 2.9206087589263916,
      "learning_rate": 4.373253228879949e-05,
      "loss": 1.1207,
      "step": 118450
    },
    {
      "epoch": 1.2544873253899778,
      "grad_norm": 2.687764883041382,
      "learning_rate": 4.3729885665890325e-05,
      "loss": 1.1219,
      "step": 118500
    },
    {
      "epoch": 1.2544873253899778,
      "eval_loss": 1.0173823833465576,
      "eval_runtime": 46.5977,
      "eval_samples_per_second": 3603.828,
      "eval_steps_per_second": 450.495,
      "step": 118500
    },
    {
      "epoch": 1.255016647169981,
      "grad_norm": 2.9299230575561523,
      "learning_rate": 4.372723904298116e-05,
      "loss": 1.1336,
      "step": 118550
    },
    {
      "epoch": 1.2555459689499844,
      "grad_norm": 2.9221255779266357,
      "learning_rate": 4.372459242007199e-05,
      "loss": 1.1293,
      "step": 118600
    },
    {
      "epoch": 1.2560752907299877,
      "grad_norm": 3.4196887016296387,
      "learning_rate": 4.372194579716282e-05,
      "loss": 1.1236,
      "step": 118650
    },
    {
      "epoch": 1.256604612509991,
      "grad_norm": 2.932565689086914,
      "learning_rate": 4.3719299174253655e-05,
      "loss": 1.1136,
      "step": 118700
    },
    {
      "epoch": 1.2571339342899943,
      "grad_norm": 2.7486884593963623,
      "learning_rate": 4.371665255134449e-05,
      "loss": 1.1245,
      "step": 118750
    },
    {
      "epoch": 1.2576632560699976,
      "grad_norm": 2.8816821575164795,
      "learning_rate": 4.371400592843532e-05,
      "loss": 1.1215,
      "step": 118800
    },
    {
      "epoch": 1.2581925778500007,
      "grad_norm": 3.238109827041626,
      "learning_rate": 4.371135930552615e-05,
      "loss": 1.1322,
      "step": 118850
    },
    {
      "epoch": 1.258721899630004,
      "grad_norm": 3.1283066272735596,
      "learning_rate": 4.3708712682616984e-05,
      "loss": 1.1221,
      "step": 118900
    },
    {
      "epoch": 1.2592512214100073,
      "grad_norm": 2.9267117977142334,
      "learning_rate": 4.370606605970782e-05,
      "loss": 1.136,
      "step": 118950
    },
    {
      "epoch": 1.2597805431900106,
      "grad_norm": 2.987213611602783,
      "learning_rate": 4.3703419436798646e-05,
      "loss": 1.1263,
      "step": 119000
    },
    {
      "epoch": 1.2597805431900106,
      "eval_loss": 1.01626455783844,
      "eval_runtime": 46.5663,
      "eval_samples_per_second": 3606.259,
      "eval_steps_per_second": 450.798,
      "step": 119000
    },
    {
      "epoch": 1.260309864970014,
      "grad_norm": 3.1979823112487793,
      "learning_rate": 4.370077281388948e-05,
      "loss": 1.1334,
      "step": 119050
    },
    {
      "epoch": 1.2608391867500173,
      "grad_norm": 2.900507926940918,
      "learning_rate": 4.369812619098031e-05,
      "loss": 1.1256,
      "step": 119100
    },
    {
      "epoch": 1.2613685085300204,
      "grad_norm": 3.3714559078216553,
      "learning_rate": 4.369547956807115e-05,
      "loss": 1.1269,
      "step": 119150
    },
    {
      "epoch": 1.2618978303100237,
      "grad_norm": 3.0585696697235107,
      "learning_rate": 4.3692832945161975e-05,
      "loss": 1.1435,
      "step": 119200
    },
    {
      "epoch": 1.262427152090027,
      "grad_norm": 2.9277305603027344,
      "learning_rate": 4.369018632225281e-05,
      "loss": 1.1151,
      "step": 119250
    },
    {
      "epoch": 1.2629564738700303,
      "grad_norm": 3.286332368850708,
      "learning_rate": 4.368753969934364e-05,
      "loss": 1.1275,
      "step": 119300
    },
    {
      "epoch": 1.2634857956500336,
      "grad_norm": 3.0118372440338135,
      "learning_rate": 4.368489307643448e-05,
      "loss": 1.1325,
      "step": 119350
    },
    {
      "epoch": 1.264015117430037,
      "grad_norm": 2.952871084213257,
      "learning_rate": 4.3682246453525305e-05,
      "loss": 1.1289,
      "step": 119400
    },
    {
      "epoch": 1.2645444392100402,
      "grad_norm": 3.2517480850219727,
      "learning_rate": 4.367959983061614e-05,
      "loss": 1.1342,
      "step": 119450
    },
    {
      "epoch": 1.2650737609900435,
      "grad_norm": 3.044618606567383,
      "learning_rate": 4.3676953207706967e-05,
      "loss": 1.1397,
      "step": 119500
    },
    {
      "epoch": 1.2650737609900435,
      "eval_loss": 1.0121535062789917,
      "eval_runtime": 46.6464,
      "eval_samples_per_second": 3600.066,
      "eval_steps_per_second": 450.024,
      "step": 119500
    },
    {
      "epoch": 1.2656030827700468,
      "grad_norm": 2.6826367378234863,
      "learning_rate": 4.36743065847978e-05,
      "loss": 1.1308,
      "step": 119550
    },
    {
      "epoch": 1.26613240455005,
      "grad_norm": 2.799346685409546,
      "learning_rate": 4.3671659961888635e-05,
      "loss": 1.1328,
      "step": 119600
    },
    {
      "epoch": 1.2666617263300533,
      "grad_norm": 3.1059675216674805,
      "learning_rate": 4.366901333897946e-05,
      "loss": 1.1198,
      "step": 119650
    },
    {
      "epoch": 1.2671910481100566,
      "grad_norm": 3.0272672176361084,
      "learning_rate": 4.3666366716070296e-05,
      "loss": 1.1328,
      "step": 119700
    },
    {
      "epoch": 1.2677203698900599,
      "grad_norm": 2.9185256958007812,
      "learning_rate": 4.366372009316113e-05,
      "loss": 1.1125,
      "step": 119750
    },
    {
      "epoch": 1.2682496916700632,
      "grad_norm": 3.068753242492676,
      "learning_rate": 4.3661073470251964e-05,
      "loss": 1.1152,
      "step": 119800
    },
    {
      "epoch": 1.2687790134500665,
      "grad_norm": 2.7834858894348145,
      "learning_rate": 4.365842684734279e-05,
      "loss": 1.1082,
      "step": 119850
    },
    {
      "epoch": 1.2693083352300696,
      "grad_norm": 3.1087796688079834,
      "learning_rate": 4.3655780224433626e-05,
      "loss": 1.1245,
      "step": 119900
    },
    {
      "epoch": 1.269837657010073,
      "grad_norm": 2.9759106636047363,
      "learning_rate": 4.365313360152446e-05,
      "loss": 1.123,
      "step": 119950
    },
    {
      "epoch": 1.2703669787900762,
      "grad_norm": 3.0557148456573486,
      "learning_rate": 4.3650539911073475e-05,
      "loss": 1.1369,
      "step": 120000
    },
    {
      "epoch": 1.2703669787900762,
      "eval_loss": 1.0111874341964722,
      "eval_runtime": 46.7176,
      "eval_samples_per_second": 3594.575,
      "eval_steps_per_second": 449.338,
      "step": 120000
    },
    {
      "epoch": 1.2708963005700795,
      "grad_norm": 3.0524795055389404,
      "learning_rate": 4.36478932881643e-05,
      "loss": 1.1152,
      "step": 120050
    },
    {
      "epoch": 1.2714256223500828,
      "grad_norm": 2.826744794845581,
      "learning_rate": 4.3645246665255136e-05,
      "loss": 1.1153,
      "step": 120100
    },
    {
      "epoch": 1.2719549441300861,
      "grad_norm": 2.9150631427764893,
      "learning_rate": 4.364260004234597e-05,
      "loss": 1.1215,
      "step": 120150
    },
    {
      "epoch": 1.2724842659100895,
      "grad_norm": 3.149984121322632,
      "learning_rate": 4.3639953419436804e-05,
      "loss": 1.1182,
      "step": 120200
    },
    {
      "epoch": 1.2730135876900928,
      "grad_norm": 3.2479844093322754,
      "learning_rate": 4.363730679652763e-05,
      "loss": 1.1232,
      "step": 120250
    },
    {
      "epoch": 1.273542909470096,
      "grad_norm": 2.8164632320404053,
      "learning_rate": 4.3634660173618466e-05,
      "loss": 1.1307,
      "step": 120300
    },
    {
      "epoch": 1.2740722312500994,
      "grad_norm": 3.1786258220672607,
      "learning_rate": 4.36320135507093e-05,
      "loss": 1.1188,
      "step": 120350
    },
    {
      "epoch": 1.2746015530301025,
      "grad_norm": 2.8347487449645996,
      "learning_rate": 4.3629366927800134e-05,
      "loss": 1.1203,
      "step": 120400
    },
    {
      "epoch": 1.2751308748101058,
      "grad_norm": 2.81058931350708,
      "learning_rate": 4.362672030489096e-05,
      "loss": 1.1397,
      "step": 120450
    },
    {
      "epoch": 1.275660196590109,
      "grad_norm": 3.027092695236206,
      "learning_rate": 4.3624073681981795e-05,
      "loss": 1.1246,
      "step": 120500
    },
    {
      "epoch": 1.275660196590109,
      "eval_loss": 1.0081406831741333,
      "eval_runtime": 46.6074,
      "eval_samples_per_second": 3603.076,
      "eval_steps_per_second": 450.401,
      "step": 120500
    },
    {
      "epoch": 1.2761895183701124,
      "grad_norm": 2.889761447906494,
      "learning_rate": 4.362142705907263e-05,
      "loss": 1.1097,
      "step": 120550
    },
    {
      "epoch": 1.2767188401501157,
      "grad_norm": 3.51882266998291,
      "learning_rate": 4.361878043616346e-05,
      "loss": 1.1092,
      "step": 120600
    },
    {
      "epoch": 1.2772481619301188,
      "grad_norm": 3.4881327152252197,
      "learning_rate": 4.361613381325429e-05,
      "loss": 1.1044,
      "step": 120650
    },
    {
      "epoch": 1.2777774837101221,
      "grad_norm": 3.0508408546447754,
      "learning_rate": 4.361348719034512e-05,
      "loss": 1.1098,
      "step": 120700
    },
    {
      "epoch": 1.2783068054901254,
      "grad_norm": 2.9270737171173096,
      "learning_rate": 4.361084056743596e-05,
      "loss": 1.108,
      "step": 120750
    },
    {
      "epoch": 1.2788361272701287,
      "grad_norm": 3.162806510925293,
      "learning_rate": 4.3608193944526786e-05,
      "loss": 1.1226,
      "step": 120800
    },
    {
      "epoch": 1.279365449050132,
      "grad_norm": 3.045370578765869,
      "learning_rate": 4.360554732161762e-05,
      "loss": 1.1124,
      "step": 120850
    },
    {
      "epoch": 1.2798947708301354,
      "grad_norm": 2.7479453086853027,
      "learning_rate": 4.360290069870845e-05,
      "loss": 1.1236,
      "step": 120900
    },
    {
      "epoch": 1.2804240926101387,
      "grad_norm": 3.24422550201416,
      "learning_rate": 4.360025407579928e-05,
      "loss": 1.1176,
      "step": 120950
    },
    {
      "epoch": 1.280953414390142,
      "grad_norm": 3.2170631885528564,
      "learning_rate": 4.3597607452890116e-05,
      "loss": 1.103,
      "step": 121000
    },
    {
      "epoch": 1.280953414390142,
      "eval_loss": 1.005432367324829,
      "eval_runtime": 46.6578,
      "eval_samples_per_second": 3599.182,
      "eval_steps_per_second": 449.914,
      "step": 121000
    },
    {
      "epoch": 1.2814827361701453,
      "grad_norm": 3.157968044281006,
      "learning_rate": 4.359496082998094e-05,
      "loss": 1.1041,
      "step": 121050
    },
    {
      "epoch": 1.2820120579501486,
      "grad_norm": 2.958815813064575,
      "learning_rate": 4.359231420707178e-05,
      "loss": 1.1113,
      "step": 121100
    },
    {
      "epoch": 1.2825413797301517,
      "grad_norm": 3.081474542617798,
      "learning_rate": 4.3589667584162605e-05,
      "loss": 1.1163,
      "step": 121150
    },
    {
      "epoch": 1.283070701510155,
      "grad_norm": 2.836101531982422,
      "learning_rate": 4.3587020961253446e-05,
      "loss": 1.1256,
      "step": 121200
    },
    {
      "epoch": 1.2836000232901583,
      "grad_norm": 2.7918384075164795,
      "learning_rate": 4.358437433834427e-05,
      "loss": 1.1161,
      "step": 121250
    },
    {
      "epoch": 1.2841293450701616,
      "grad_norm": 3.1133646965026855,
      "learning_rate": 4.358172771543511e-05,
      "loss": 1.117,
      "step": 121300
    },
    {
      "epoch": 1.284658666850165,
      "grad_norm": 3.194159746170044,
      "learning_rate": 4.3579081092525934e-05,
      "loss": 1.1253,
      "step": 121350
    },
    {
      "epoch": 1.285187988630168,
      "grad_norm": 2.935025453567505,
      "learning_rate": 4.3576434469616775e-05,
      "loss": 1.1097,
      "step": 121400
    },
    {
      "epoch": 1.2857173104101713,
      "grad_norm": 3.290921688079834,
      "learning_rate": 4.35737878467076e-05,
      "loss": 1.1089,
      "step": 121450
    },
    {
      "epoch": 1.2862466321901747,
      "grad_norm": 2.9967362880706787,
      "learning_rate": 4.3571141223798437e-05,
      "loss": 1.1045,
      "step": 121500
    },
    {
      "epoch": 1.2862466321901747,
      "eval_loss": 1.0032719373703003,
      "eval_runtime": 46.6469,
      "eval_samples_per_second": 3600.025,
      "eval_steps_per_second": 450.019,
      "step": 121500
    },
    {
      "epoch": 1.286775953970178,
      "grad_norm": 3.1197903156280518,
      "learning_rate": 4.3568494600889264e-05,
      "loss": 1.0931,
      "step": 121550
    },
    {
      "epoch": 1.2873052757501813,
      "grad_norm": 3.250788688659668,
      "learning_rate": 4.35658479779801e-05,
      "loss": 1.1129,
      "step": 121600
    },
    {
      "epoch": 1.2878345975301846,
      "grad_norm": 3.1563637256622314,
      "learning_rate": 4.356320135507093e-05,
      "loss": 1.1115,
      "step": 121650
    },
    {
      "epoch": 1.288363919310188,
      "grad_norm": 3.314687728881836,
      "learning_rate": 4.356055473216176e-05,
      "loss": 1.0913,
      "step": 121700
    },
    {
      "epoch": 1.2888932410901912,
      "grad_norm": 3.054713726043701,
      "learning_rate": 4.3557908109252594e-05,
      "loss": 1.1166,
      "step": 121750
    },
    {
      "epoch": 1.2894225628701945,
      "grad_norm": 3.2758336067199707,
      "learning_rate": 4.355526148634343e-05,
      "loss": 1.1474,
      "step": 121800
    },
    {
      "epoch": 1.2899518846501978,
      "grad_norm": 3.1245622634887695,
      "learning_rate": 4.355261486343426e-05,
      "loss": 1.1256,
      "step": 121850
    },
    {
      "epoch": 1.290481206430201,
      "grad_norm": 2.8354392051696777,
      "learning_rate": 4.354996824052509e-05,
      "loss": 1.0868,
      "step": 121900
    },
    {
      "epoch": 1.2910105282102042,
      "grad_norm": 3.302856922149658,
      "learning_rate": 4.354732161761592e-05,
      "loss": 1.0901,
      "step": 121950
    },
    {
      "epoch": 1.2915398499902075,
      "grad_norm": 3.3886451721191406,
      "learning_rate": 4.354467499470676e-05,
      "loss": 1.1054,
      "step": 122000
    },
    {
      "epoch": 1.2915398499902075,
      "eval_loss": 1.0021321773529053,
      "eval_runtime": 46.5684,
      "eval_samples_per_second": 3606.095,
      "eval_steps_per_second": 450.778,
      "step": 122000
    },
    {
      "epoch": 1.2920691717702109,
      "grad_norm": 3.1957225799560547,
      "learning_rate": 4.354208130425577e-05,
      "loss": 1.1203,
      "step": 122050
    },
    {
      "epoch": 1.2925984935502142,
      "grad_norm": 3.4893741607666016,
      "learning_rate": 4.35394346813466e-05,
      "loss": 1.1103,
      "step": 122100
    },
    {
      "epoch": 1.2931278153302173,
      "grad_norm": 2.936065435409546,
      "learning_rate": 4.353678805843743e-05,
      "loss": 1.1115,
      "step": 122150
    },
    {
      "epoch": 1.2936571371102206,
      "grad_norm": 2.819749355316162,
      "learning_rate": 4.353414143552827e-05,
      "loss": 1.1084,
      "step": 122200
    },
    {
      "epoch": 1.2941864588902239,
      "grad_norm": 3.1324374675750732,
      "learning_rate": 4.35314948126191e-05,
      "loss": 1.1184,
      "step": 122250
    },
    {
      "epoch": 1.2947157806702272,
      "grad_norm": 3.065093517303467,
      "learning_rate": 4.352884818970993e-05,
      "loss": 1.1159,
      "step": 122300
    },
    {
      "epoch": 1.2952451024502305,
      "grad_norm": 3.0764455795288086,
      "learning_rate": 4.352620156680076e-05,
      "loss": 1.1144,
      "step": 122350
    },
    {
      "epoch": 1.2957744242302338,
      "grad_norm": 3.0654730796813965,
      "learning_rate": 4.35235549438916e-05,
      "loss": 1.1023,
      "step": 122400
    },
    {
      "epoch": 1.2963037460102371,
      "grad_norm": 3.2506377696990967,
      "learning_rate": 4.352090832098243e-05,
      "loss": 1.1072,
      "step": 122450
    },
    {
      "epoch": 1.2968330677902404,
      "grad_norm": 3.0291237831115723,
      "learning_rate": 4.351826169807326e-05,
      "loss": 1.1151,
      "step": 122500
    },
    {
      "epoch": 1.2968330677902404,
      "eval_loss": 0.9987284541130066,
      "eval_runtime": 46.7317,
      "eval_samples_per_second": 3593.493,
      "eval_steps_per_second": 449.203,
      "step": 122500
    },
    {
      "epoch": 1.2973623895702437,
      "grad_norm": 3.281656503677368,
      "learning_rate": 4.351561507516409e-05,
      "loss": 1.1011,
      "step": 122550
    },
    {
      "epoch": 1.297891711350247,
      "grad_norm": 2.83001446723938,
      "learning_rate": 4.351296845225493e-05,
      "loss": 1.0992,
      "step": 122600
    },
    {
      "epoch": 1.2984210331302501,
      "grad_norm": 2.8641774654388428,
      "learning_rate": 4.3510321829345754e-05,
      "loss": 1.1155,
      "step": 122650
    },
    {
      "epoch": 1.2989503549102535,
      "grad_norm": 3.127415657043457,
      "learning_rate": 4.350767520643659e-05,
      "loss": 1.1175,
      "step": 122700
    },
    {
      "epoch": 1.2994796766902568,
      "grad_norm": 2.7675139904022217,
      "learning_rate": 4.3505028583527415e-05,
      "loss": 1.1171,
      "step": 122750
    },
    {
      "epoch": 1.30000899847026,
      "grad_norm": 3.2638814449310303,
      "learning_rate": 4.3502381960618256e-05,
      "loss": 1.1144,
      "step": 122800
    },
    {
      "epoch": 1.3005383202502634,
      "grad_norm": 3.1742312908172607,
      "learning_rate": 4.3499735337709084e-05,
      "loss": 1.1109,
      "step": 122850
    },
    {
      "epoch": 1.3010676420302667,
      "grad_norm": 3.128324270248413,
      "learning_rate": 4.349708871479992e-05,
      "loss": 1.1157,
      "step": 122900
    },
    {
      "epoch": 1.3015969638102698,
      "grad_norm": 3.143183708190918,
      "learning_rate": 4.3494442091890745e-05,
      "loss": 1.1006,
      "step": 122950
    },
    {
      "epoch": 1.302126285590273,
      "grad_norm": 3.0766124725341797,
      "learning_rate": 4.3491795468981586e-05,
      "loss": 1.1286,
      "step": 123000
    },
    {
      "epoch": 1.302126285590273,
      "eval_loss": 0.9970743060112,
      "eval_runtime": 46.5236,
      "eval_samples_per_second": 3609.563,
      "eval_steps_per_second": 451.211,
      "step": 123000
    },
    {
      "epoch": 1.3026556073702764,
      "grad_norm": 3.0719833374023438,
      "learning_rate": 4.348914884607241e-05,
      "loss": 1.0979,
      "step": 123050
    },
    {
      "epoch": 1.3031849291502797,
      "grad_norm": 2.8963441848754883,
      "learning_rate": 4.348650222316325e-05,
      "loss": 1.1128,
      "step": 123100
    },
    {
      "epoch": 1.303714250930283,
      "grad_norm": 3.114177703857422,
      "learning_rate": 4.3483855600254075e-05,
      "loss": 1.1142,
      "step": 123150
    },
    {
      "epoch": 1.3042435727102863,
      "grad_norm": 3.1094870567321777,
      "learning_rate": 4.348120897734491e-05,
      "loss": 1.1132,
      "step": 123200
    },
    {
      "epoch": 1.3047728944902897,
      "grad_norm": 3.0774199962615967,
      "learning_rate": 4.347856235443574e-05,
      "loss": 1.11,
      "step": 123250
    },
    {
      "epoch": 1.305302216270293,
      "grad_norm": 3.041714906692505,
      "learning_rate": 4.347591573152657e-05,
      "loss": 1.1299,
      "step": 123300
    },
    {
      "epoch": 1.3058315380502963,
      "grad_norm": 3.235504388809204,
      "learning_rate": 4.3473269108617404e-05,
      "loss": 1.106,
      "step": 123350
    },
    {
      "epoch": 1.3063608598302994,
      "grad_norm": 2.976383924484253,
      "learning_rate": 4.347062248570824e-05,
      "loss": 1.0857,
      "step": 123400
    },
    {
      "epoch": 1.3068901816103027,
      "grad_norm": 3.1034746170043945,
      "learning_rate": 4.346797586279907e-05,
      "loss": 1.0983,
      "step": 123450
    },
    {
      "epoch": 1.307419503390306,
      "grad_norm": 2.7278614044189453,
      "learning_rate": 4.34653292398899e-05,
      "loss": 1.1167,
      "step": 123500
    },
    {
      "epoch": 1.307419503390306,
      "eval_loss": 0.9941459894180298,
      "eval_runtime": 46.6824,
      "eval_samples_per_second": 3597.291,
      "eval_steps_per_second": 449.677,
      "step": 123500
    },
    {
      "epoch": 1.3079488251703093,
      "grad_norm": 3.1237711906433105,
      "learning_rate": 4.3462682616980734e-05,
      "loss": 1.1174,
      "step": 123550
    },
    {
      "epoch": 1.3084781469503126,
      "grad_norm": 2.8481054306030273,
      "learning_rate": 4.346003599407157e-05,
      "loss": 1.1172,
      "step": 123600
    },
    {
      "epoch": 1.309007468730316,
      "grad_norm": 3.093928575515747,
      "learning_rate": 4.34573893711624e-05,
      "loss": 1.1172,
      "step": 123650
    },
    {
      "epoch": 1.309536790510319,
      "grad_norm": 3.2903456687927246,
      "learning_rate": 4.345474274825323e-05,
      "loss": 1.1042,
      "step": 123700
    },
    {
      "epoch": 1.3100661122903223,
      "grad_norm": 3.264920711517334,
      "learning_rate": 4.3452096125344064e-05,
      "loss": 1.1227,
      "step": 123750
    },
    {
      "epoch": 1.3105954340703256,
      "grad_norm": 2.9563138484954834,
      "learning_rate": 4.34494495024349e-05,
      "loss": 1.095,
      "step": 123800
    },
    {
      "epoch": 1.311124755850329,
      "grad_norm": 3.084404230117798,
      "learning_rate": 4.3446802879525725e-05,
      "loss": 1.118,
      "step": 123850
    },
    {
      "epoch": 1.3116540776303323,
      "grad_norm": 3.113748550415039,
      "learning_rate": 4.344415625661656e-05,
      "loss": 1.0878,
      "step": 123900
    },
    {
      "epoch": 1.3121833994103356,
      "grad_norm": 3.0429418087005615,
      "learning_rate": 4.3441509633707386e-05,
      "loss": 1.1246,
      "step": 123950
    },
    {
      "epoch": 1.3127127211903389,
      "grad_norm": 3.1880757808685303,
      "learning_rate": 4.343886301079823e-05,
      "loss": 1.1155,
      "step": 124000
    },
    {
      "epoch": 1.3127127211903389,
      "eval_loss": 0.9906726479530334,
      "eval_runtime": 46.6648,
      "eval_samples_per_second": 3598.644,
      "eval_steps_per_second": 449.847,
      "step": 124000
    },
    {
      "epoch": 1.3132420429703422,
      "grad_norm": 2.906588554382324,
      "learning_rate": 4.3436216387889055e-05,
      "loss": 1.1083,
      "step": 124050
    },
    {
      "epoch": 1.3137713647503455,
      "grad_norm": 3.177020311355591,
      "learning_rate": 4.343356976497989e-05,
      "loss": 1.1289,
      "step": 124100
    },
    {
      "epoch": 1.3143006865303486,
      "grad_norm": 3.0441315174102783,
      "learning_rate": 4.3430923142070716e-05,
      "loss": 1.1043,
      "step": 124150
    },
    {
      "epoch": 1.314830008310352,
      "grad_norm": 2.974281072616577,
      "learning_rate": 4.342832945161974e-05,
      "loss": 1.1028,
      "step": 124200
    },
    {
      "epoch": 1.3153593300903552,
      "grad_norm": 3.2109768390655518,
      "learning_rate": 4.3425682828710565e-05,
      "loss": 1.1032,
      "step": 124250
    },
    {
      "epoch": 1.3158886518703585,
      "grad_norm": 2.931692361831665,
      "learning_rate": 4.34230362058014e-05,
      "loss": 1.1084,
      "step": 124300
    },
    {
      "epoch": 1.3164179736503618,
      "grad_norm": 3.2988851070404053,
      "learning_rate": 4.3420389582892226e-05,
      "loss": 1.115,
      "step": 124350
    },
    {
      "epoch": 1.3169472954303652,
      "grad_norm": 3.0876882076263428,
      "learning_rate": 4.341774295998307e-05,
      "loss": 1.1193,
      "step": 124400
    },
    {
      "epoch": 1.3174766172103682,
      "grad_norm": 3.1350889205932617,
      "learning_rate": 4.3415096337073894e-05,
      "loss": 1.1336,
      "step": 124450
    },
    {
      "epoch": 1.3180059389903716,
      "grad_norm": 2.724076986312866,
      "learning_rate": 4.341244971416473e-05,
      "loss": 1.1139,
      "step": 124500
    },
    {
      "epoch": 1.3180059389903716,
      "eval_loss": 0.990454375743866,
      "eval_runtime": 46.6203,
      "eval_samples_per_second": 3602.076,
      "eval_steps_per_second": 450.276,
      "step": 124500
    },
    {
      "epoch": 1.3185352607703749,
      "grad_norm": 2.9571261405944824,
      "learning_rate": 4.3409803091255556e-05,
      "loss": 1.1064,
      "step": 124550
    },
    {
      "epoch": 1.3190645825503782,
      "grad_norm": 3.3054330348968506,
      "learning_rate": 4.34071564683464e-05,
      "loss": 1.1136,
      "step": 124600
    },
    {
      "epoch": 1.3195939043303815,
      "grad_norm": 3.0863308906555176,
      "learning_rate": 4.3404509845437224e-05,
      "loss": 1.0866,
      "step": 124650
    },
    {
      "epoch": 1.3201232261103848,
      "grad_norm": 3.19891619682312,
      "learning_rate": 4.340186322252806e-05,
      "loss": 1.0984,
      "step": 124700
    },
    {
      "epoch": 1.320652547890388,
      "grad_norm": 3.1244733333587646,
      "learning_rate": 4.3399216599618886e-05,
      "loss": 1.0942,
      "step": 124750
    },
    {
      "epoch": 1.3211818696703914,
      "grad_norm": 3.003295660018921,
      "learning_rate": 4.339656997670972e-05,
      "loss": 1.0891,
      "step": 124800
    },
    {
      "epoch": 1.3217111914503947,
      "grad_norm": 3.112955093383789,
      "learning_rate": 4.3393923353800554e-05,
      "loss": 1.1223,
      "step": 124850
    },
    {
      "epoch": 1.3222405132303978,
      "grad_norm": 3.0214788913726807,
      "learning_rate": 4.339127673089138e-05,
      "loss": 1.0958,
      "step": 124900
    },
    {
      "epoch": 1.3227698350104011,
      "grad_norm": 3.1324784755706787,
      "learning_rate": 4.3388630107982215e-05,
      "loss": 1.0972,
      "step": 124950
    },
    {
      "epoch": 1.3232991567904044,
      "grad_norm": 3.1289284229278564,
      "learning_rate": 4.338598348507305e-05,
      "loss": 1.091,
      "step": 125000
    },
    {
      "epoch": 1.3232991567904044,
      "eval_loss": 0.9884572625160217,
      "eval_runtime": 46.6367,
      "eval_samples_per_second": 3600.815,
      "eval_steps_per_second": 450.118,
      "step": 125000
    },
    {
      "epoch": 1.3238284785704078,
      "grad_norm": 3.079561948776245,
      "learning_rate": 4.338333686216388e-05,
      "loss": 1.0968,
      "step": 125050
    },
    {
      "epoch": 1.324357800350411,
      "grad_norm": 3.249439001083374,
      "learning_rate": 4.338069023925471e-05,
      "loss": 1.1039,
      "step": 125100
    },
    {
      "epoch": 1.3248871221304144,
      "grad_norm": 2.7957820892333984,
      "learning_rate": 4.3378043616345545e-05,
      "loss": 1.1224,
      "step": 125150
    },
    {
      "epoch": 1.3254164439104175,
      "grad_norm": 2.9839394092559814,
      "learning_rate": 4.337539699343638e-05,
      "loss": 1.109,
      "step": 125200
    },
    {
      "epoch": 1.3259457656904208,
      "grad_norm": 2.986393690109253,
      "learning_rate": 4.337275037052721e-05,
      "loss": 1.1056,
      "step": 125250
    },
    {
      "epoch": 1.326475087470424,
      "grad_norm": 3.371600389480591,
      "learning_rate": 4.337010374761804e-05,
      "loss": 1.1087,
      "step": 125300
    },
    {
      "epoch": 1.3270044092504274,
      "grad_norm": 3.129582405090332,
      "learning_rate": 4.3367457124708874e-05,
      "loss": 1.1068,
      "step": 125350
    },
    {
      "epoch": 1.3275337310304307,
      "grad_norm": 2.75992751121521,
      "learning_rate": 4.336481050179971e-05,
      "loss": 1.0905,
      "step": 125400
    },
    {
      "epoch": 1.328063052810434,
      "grad_norm": 3.0925941467285156,
      "learning_rate": 4.3362163878890536e-05,
      "loss": 1.1173,
      "step": 125450
    },
    {
      "epoch": 1.3285923745904373,
      "grad_norm": 2.953221082687378,
      "learning_rate": 4.335951725598137e-05,
      "loss": 1.1109,
      "step": 125500
    },
    {
      "epoch": 1.3285923745904373,
      "eval_loss": 0.9878923892974854,
      "eval_runtime": 46.6114,
      "eval_samples_per_second": 3602.765,
      "eval_steps_per_second": 450.362,
      "step": 125500
    },
    {
      "epoch": 1.3291216963704406,
      "grad_norm": 2.9549455642700195,
      "learning_rate": 4.33568706330722e-05,
      "loss": 1.1131,
      "step": 125550
    },
    {
      "epoch": 1.329651018150444,
      "grad_norm": 3.0407698154449463,
      "learning_rate": 4.335422401016304e-05,
      "loss": 1.1181,
      "step": 125600
    },
    {
      "epoch": 1.330180339930447,
      "grad_norm": 2.881620168685913,
      "learning_rate": 4.3351577387253865e-05,
      "loss": 1.0844,
      "step": 125650
    },
    {
      "epoch": 1.3307096617104504,
      "grad_norm": 3.02645206451416,
      "learning_rate": 4.33489307643447e-05,
      "loss": 1.0931,
      "step": 125700
    },
    {
      "epoch": 1.3312389834904537,
      "grad_norm": 3.412545919418335,
      "learning_rate": 4.334628414143553e-05,
      "loss": 1.1206,
      "step": 125750
    },
    {
      "epoch": 1.331768305270457,
      "grad_norm": 3.1709914207458496,
      "learning_rate": 4.334363751852636e-05,
      "loss": 1.102,
      "step": 125800
    },
    {
      "epoch": 1.3322976270504603,
      "grad_norm": 3.206496000289917,
      "learning_rate": 4.3340990895617195e-05,
      "loss": 1.1064,
      "step": 125850
    },
    {
      "epoch": 1.3328269488304636,
      "grad_norm": 2.7404749393463135,
      "learning_rate": 4.333834427270802e-05,
      "loss": 1.1085,
      "step": 125900
    },
    {
      "epoch": 1.3333562706104667,
      "grad_norm": 3.1207494735717773,
      "learning_rate": 4.3335697649798856e-05,
      "loss": 1.0927,
      "step": 125950
    },
    {
      "epoch": 1.33388559239047,
      "grad_norm": 3.1149415969848633,
      "learning_rate": 4.333305102688969e-05,
      "loss": 1.0973,
      "step": 126000
    },
    {
      "epoch": 1.33388559239047,
      "eval_loss": 0.9857228398323059,
      "eval_runtime": 46.5632,
      "eval_samples_per_second": 3606.494,
      "eval_steps_per_second": 450.828,
      "step": 126000
    },
    {
      "epoch": 1.3344149141704733,
      "grad_norm": 2.8639376163482666,
      "learning_rate": 4.3330404403980525e-05,
      "loss": 1.1016,
      "step": 126050
    },
    {
      "epoch": 1.3349442359504766,
      "grad_norm": 3.2546322345733643,
      "learning_rate": 4.332775778107135e-05,
      "loss": 1.1069,
      "step": 126100
    },
    {
      "epoch": 1.33547355773048,
      "grad_norm": 3.128701686859131,
      "learning_rate": 4.3325111158162186e-05,
      "loss": 1.1113,
      "step": 126150
    },
    {
      "epoch": 1.3360028795104832,
      "grad_norm": 3.121109962463379,
      "learning_rate": 4.332251746771121e-05,
      "loss": 1.1046,
      "step": 126200
    },
    {
      "epoch": 1.3365322012904866,
      "grad_norm": 3.3583362102508545,
      "learning_rate": 4.3319870844802035e-05,
      "loss": 1.1073,
      "step": 126250
    },
    {
      "epoch": 1.3370615230704899,
      "grad_norm": 2.943185806274414,
      "learning_rate": 4.331722422189287e-05,
      "loss": 1.1093,
      "step": 126300
    },
    {
      "epoch": 1.3375908448504932,
      "grad_norm": 3.0091919898986816,
      "learning_rate": 4.3314577598983696e-05,
      "loss": 1.1235,
      "step": 126350
    },
    {
      "epoch": 1.3381201666304963,
      "grad_norm": 3.1272528171539307,
      "learning_rate": 4.331193097607453e-05,
      "loss": 1.0904,
      "step": 126400
    },
    {
      "epoch": 1.3386494884104996,
      "grad_norm": 3.166513442993164,
      "learning_rate": 4.3309284353165365e-05,
      "loss": 1.1102,
      "step": 126450
    },
    {
      "epoch": 1.3391788101905029,
      "grad_norm": 3.058809518814087,
      "learning_rate": 4.330663773025619e-05,
      "loss": 1.1044,
      "step": 126500
    },
    {
      "epoch": 1.3391788101905029,
      "eval_loss": 0.9843836426734924,
      "eval_runtime": 46.7893,
      "eval_samples_per_second": 3589.071,
      "eval_steps_per_second": 448.65,
      "step": 126500
    },
    {
      "epoch": 1.3397081319705062,
      "grad_norm": 3.0137407779693604,
      "learning_rate": 4.3303991107347026e-05,
      "loss": 1.0898,
      "step": 126550
    },
    {
      "epoch": 1.3402374537505095,
      "grad_norm": 3.385974168777466,
      "learning_rate": 4.330134448443786e-05,
      "loss": 1.102,
      "step": 126600
    },
    {
      "epoch": 1.3407667755305128,
      "grad_norm": 3.09981369972229,
      "learning_rate": 4.3298697861528694e-05,
      "loss": 1.1224,
      "step": 126650
    },
    {
      "epoch": 1.341296097310516,
      "grad_norm": 3.082371950149536,
      "learning_rate": 4.329605123861952e-05,
      "loss": 1.0974,
      "step": 126700
    },
    {
      "epoch": 1.3418254190905192,
      "grad_norm": 3.24491024017334,
      "learning_rate": 4.3293404615710356e-05,
      "loss": 1.0957,
      "step": 126750
    },
    {
      "epoch": 1.3423547408705225,
      "grad_norm": 3.1570932865142822,
      "learning_rate": 4.329075799280119e-05,
      "loss": 1.1208,
      "step": 126800
    },
    {
      "epoch": 1.3428840626505258,
      "grad_norm": 2.9516656398773193,
      "learning_rate": 4.3288111369892024e-05,
      "loss": 1.095,
      "step": 126850
    },
    {
      "epoch": 1.3434133844305292,
      "grad_norm": 3.1271169185638428,
      "learning_rate": 4.328546474698285e-05,
      "loss": 1.1358,
      "step": 126900
    },
    {
      "epoch": 1.3439427062105325,
      "grad_norm": 3.108243942260742,
      "learning_rate": 4.3282818124073685e-05,
      "loss": 1.1096,
      "step": 126950
    },
    {
      "epoch": 1.3444720279905358,
      "grad_norm": 3.239036798477173,
      "learning_rate": 4.328017150116452e-05,
      "loss": 1.1055,
      "step": 127000
    },
    {
      "epoch": 1.3444720279905358,
      "eval_loss": 0.97951340675354,
      "eval_runtime": 46.5569,
      "eval_samples_per_second": 3606.983,
      "eval_steps_per_second": 450.889,
      "step": 127000
    },
    {
      "epoch": 1.345001349770539,
      "grad_norm": 3.0101494789123535,
      "learning_rate": 4.327752487825535e-05,
      "loss": 1.1196,
      "step": 127050
    },
    {
      "epoch": 1.3455306715505424,
      "grad_norm": 3.403099298477173,
      "learning_rate": 4.327487825534618e-05,
      "loss": 1.0926,
      "step": 127100
    },
    {
      "epoch": 1.3460599933305455,
      "grad_norm": 3.532784938812256,
      "learning_rate": 4.327223163243701e-05,
      "loss": 1.0918,
      "step": 127150
    },
    {
      "epoch": 1.3465893151105488,
      "grad_norm": 3.1356289386749268,
      "learning_rate": 4.326958500952785e-05,
      "loss": 1.1095,
      "step": 127200
    },
    {
      "epoch": 1.3471186368905521,
      "grad_norm": 3.392071485519409,
      "learning_rate": 4.3266938386618676e-05,
      "loss": 1.0857,
      "step": 127250
    },
    {
      "epoch": 1.3476479586705554,
      "grad_norm": 3.098752975463867,
      "learning_rate": 4.326429176370951e-05,
      "loss": 1.1011,
      "step": 127300
    },
    {
      "epoch": 1.3481772804505587,
      "grad_norm": 3.1600937843322754,
      "learning_rate": 4.326164514080034e-05,
      "loss": 1.0898,
      "step": 127350
    },
    {
      "epoch": 1.348706602230562,
      "grad_norm": 3.220663070678711,
      "learning_rate": 4.325899851789117e-05,
      "loss": 1.0987,
      "step": 127400
    },
    {
      "epoch": 1.3492359240105651,
      "grad_norm": 3.2135636806488037,
      "learning_rate": 4.3256351894982006e-05,
      "loss": 1.0985,
      "step": 127450
    },
    {
      "epoch": 1.3497652457905684,
      "grad_norm": 3.124683141708374,
      "learning_rate": 4.325370527207283e-05,
      "loss": 1.1198,
      "step": 127500
    },
    {
      "epoch": 1.3497652457905684,
      "eval_loss": 0.9788234829902649,
      "eval_runtime": 46.624,
      "eval_samples_per_second": 3601.792,
      "eval_steps_per_second": 450.24,
      "step": 127500
    },
    {
      "epoch": 1.3502945675705718,
      "grad_norm": 3.2270352840423584,
      "learning_rate": 4.325105864916367e-05,
      "loss": 1.113,
      "step": 127550
    },
    {
      "epoch": 1.350823889350575,
      "grad_norm": 3.1254756450653076,
      "learning_rate": 4.32484120262545e-05,
      "loss": 1.1104,
      "step": 127600
    },
    {
      "epoch": 1.3513532111305784,
      "grad_norm": 3.2102670669555664,
      "learning_rate": 4.3245765403345336e-05,
      "loss": 1.1046,
      "step": 127650
    },
    {
      "epoch": 1.3518825329105817,
      "grad_norm": 3.4924654960632324,
      "learning_rate": 4.324311878043616e-05,
      "loss": 1.1056,
      "step": 127700
    },
    {
      "epoch": 1.352411854690585,
      "grad_norm": 3.0472333431243896,
      "learning_rate": 4.3240472157527e-05,
      "loss": 1.094,
      "step": 127750
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 3.2604427337646484,
      "learning_rate": 4.323782553461783e-05,
      "loss": 1.1055,
      "step": 127800
    },
    {
      "epoch": 1.3534704982505916,
      "grad_norm": 3.167903423309326,
      "learning_rate": 4.3235178911708665e-05,
      "loss": 1.0968,
      "step": 127850
    },
    {
      "epoch": 1.353999820030595,
      "grad_norm": 3.18278431892395,
      "learning_rate": 4.323253228879949e-05,
      "loss": 1.1062,
      "step": 127900
    },
    {
      "epoch": 1.354529141810598,
      "grad_norm": 3.1098473072052,
      "learning_rate": 4.3229885665890327e-05,
      "loss": 1.0979,
      "step": 127950
    },
    {
      "epoch": 1.3550584635906013,
      "grad_norm": 3.062472105026245,
      "learning_rate": 4.322723904298116e-05,
      "loss": 1.0844,
      "step": 128000
    },
    {
      "epoch": 1.3550584635906013,
      "eval_loss": 0.9763779640197754,
      "eval_runtime": 46.7046,
      "eval_samples_per_second": 3595.579,
      "eval_steps_per_second": 449.463,
      "step": 128000
    },
    {
      "epoch": 1.3555877853706046,
      "grad_norm": 3.048701047897339,
      "learning_rate": 4.322459242007199e-05,
      "loss": 1.1053,
      "step": 128050
    },
    {
      "epoch": 1.356117107150608,
      "grad_norm": 2.9240176677703857,
      "learning_rate": 4.322194579716282e-05,
      "loss": 1.1057,
      "step": 128100
    },
    {
      "epoch": 1.3566464289306113,
      "grad_norm": 3.206735849380493,
      "learning_rate": 4.321929917425365e-05,
      "loss": 1.115,
      "step": 128150
    },
    {
      "epoch": 1.3571757507106144,
      "grad_norm": 3.097832441329956,
      "learning_rate": 4.321665255134449e-05,
      "loss": 1.0981,
      "step": 128200
    },
    {
      "epoch": 1.3577050724906177,
      "grad_norm": 3.157691240310669,
      "learning_rate": 4.321400592843532e-05,
      "loss": 1.0925,
      "step": 128250
    },
    {
      "epoch": 1.358234394270621,
      "grad_norm": 3.077075958251953,
      "learning_rate": 4.321141223798433e-05,
      "loss": 1.0819,
      "step": 128300
    },
    {
      "epoch": 1.3587637160506243,
      "grad_norm": 3.375869035720825,
      "learning_rate": 4.3208765615075166e-05,
      "loss": 1.0912,
      "step": 128350
    },
    {
      "epoch": 1.3592930378306276,
      "grad_norm": 3.4420461654663086,
      "learning_rate": 4.3206118992166e-05,
      "loss": 1.0952,
      "step": 128400
    },
    {
      "epoch": 1.359822359610631,
      "grad_norm": 3.226271629333496,
      "learning_rate": 4.320347236925683e-05,
      "loss": 1.1038,
      "step": 128450
    },
    {
      "epoch": 1.3603516813906342,
      "grad_norm": 3.3080482482910156,
      "learning_rate": 4.320082574634766e-05,
      "loss": 1.1135,
      "step": 128500
    },
    {
      "epoch": 1.3603516813906342,
      "eval_loss": 0.9737975001335144,
      "eval_runtime": 46.7021,
      "eval_samples_per_second": 3595.77,
      "eval_steps_per_second": 449.487,
      "step": 128500
    },
    {
      "epoch": 1.3608810031706375,
      "grad_norm": 2.948235511779785,
      "learning_rate": 4.319817912343849e-05,
      "loss": 1.1017,
      "step": 128550
    },
    {
      "epoch": 1.3614103249506408,
      "grad_norm": 2.9977383613586426,
      "learning_rate": 4.319553250052933e-05,
      "loss": 1.1048,
      "step": 128600
    },
    {
      "epoch": 1.3619396467306442,
      "grad_norm": 3.3272695541381836,
      "learning_rate": 4.319288587762016e-05,
      "loss": 1.1134,
      "step": 128650
    },
    {
      "epoch": 1.3624689685106472,
      "grad_norm": 3.3813843727111816,
      "learning_rate": 4.319023925471099e-05,
      "loss": 1.1175,
      "step": 128700
    },
    {
      "epoch": 1.3629982902906506,
      "grad_norm": 3.5170843601226807,
      "learning_rate": 4.318759263180182e-05,
      "loss": 1.0985,
      "step": 128750
    },
    {
      "epoch": 1.3635276120706539,
      "grad_norm": 3.0857975482940674,
      "learning_rate": 4.318494600889266e-05,
      "loss": 1.11,
      "step": 128800
    },
    {
      "epoch": 1.3640569338506572,
      "grad_norm": 3.2821173667907715,
      "learning_rate": 4.318229938598349e-05,
      "loss": 1.1176,
      "step": 128850
    },
    {
      "epoch": 1.3645862556306605,
      "grad_norm": 3.3007848262786865,
      "learning_rate": 4.317965276307432e-05,
      "loss": 1.0997,
      "step": 128900
    },
    {
      "epoch": 1.3651155774106636,
      "grad_norm": 3.028925657272339,
      "learning_rate": 4.317700614016515e-05,
      "loss": 1.0954,
      "step": 128950
    },
    {
      "epoch": 1.365644899190667,
      "grad_norm": 3.1591758728027344,
      "learning_rate": 4.317435951725598e-05,
      "loss": 1.1028,
      "step": 129000
    },
    {
      "epoch": 1.365644899190667,
      "eval_loss": 0.9693954586982727,
      "eval_runtime": 46.7526,
      "eval_samples_per_second": 3591.884,
      "eval_steps_per_second": 449.002,
      "step": 129000
    },
    {
      "epoch": 1.3661742209706702,
      "grad_norm": 3.29034161567688,
      "learning_rate": 4.317171289434682e-05,
      "loss": 1.0937,
      "step": 129050
    },
    {
      "epoch": 1.3667035427506735,
      "grad_norm": 3.2715442180633545,
      "learning_rate": 4.3169066271437644e-05,
      "loss": 1.0964,
      "step": 129100
    },
    {
      "epoch": 1.3672328645306768,
      "grad_norm": 3.11993145942688,
      "learning_rate": 4.316641964852848e-05,
      "loss": 1.1006,
      "step": 129150
    },
    {
      "epoch": 1.3677621863106801,
      "grad_norm": 3.101198434829712,
      "learning_rate": 4.316377302561931e-05,
      "loss": 1.0951,
      "step": 129200
    },
    {
      "epoch": 1.3682915080906835,
      "grad_norm": 3.2155022621154785,
      "learning_rate": 4.3161126402710146e-05,
      "loss": 1.0885,
      "step": 129250
    },
    {
      "epoch": 1.3688208298706868,
      "grad_norm": 3.1911728382110596,
      "learning_rate": 4.3158479779800974e-05,
      "loss": 1.0844,
      "step": 129300
    },
    {
      "epoch": 1.36935015165069,
      "grad_norm": 3.069108724594116,
      "learning_rate": 4.315583315689181e-05,
      "loss": 1.0827,
      "step": 129350
    },
    {
      "epoch": 1.3698794734306934,
      "grad_norm": 3.271793842315674,
      "learning_rate": 4.315318653398264e-05,
      "loss": 1.087,
      "step": 129400
    },
    {
      "epoch": 1.3704087952106965,
      "grad_norm": 3.281067371368408,
      "learning_rate": 4.3150539911073476e-05,
      "loss": 1.1041,
      "step": 129450
    },
    {
      "epoch": 1.3709381169906998,
      "grad_norm": 3.041015386581421,
      "learning_rate": 4.31478932881643e-05,
      "loss": 1.0854,
      "step": 129500
    },
    {
      "epoch": 1.3709381169906998,
      "eval_loss": 0.9705812335014343,
      "eval_runtime": 46.61,
      "eval_samples_per_second": 3602.877,
      "eval_steps_per_second": 450.376,
      "step": 129500
    },
    {
      "epoch": 1.371467438770703,
      "grad_norm": 2.8496198654174805,
      "learning_rate": 4.314524666525514e-05,
      "loss": 1.1025,
      "step": 129550
    },
    {
      "epoch": 1.3719967605507064,
      "grad_norm": 3.4535889625549316,
      "learning_rate": 4.314260004234597e-05,
      "loss": 1.1001,
      "step": 129600
    },
    {
      "epoch": 1.3725260823307097,
      "grad_norm": 3.127399206161499,
      "learning_rate": 4.31399534194368e-05,
      "loss": 1.0997,
      "step": 129650
    },
    {
      "epoch": 1.3730554041107128,
      "grad_norm": 2.9297866821289062,
      "learning_rate": 4.313730679652763e-05,
      "loss": 1.0993,
      "step": 129700
    },
    {
      "epoch": 1.3735847258907161,
      "grad_norm": 3.126795530319214,
      "learning_rate": 4.313466017361846e-05,
      "loss": 1.0798,
      "step": 129750
    },
    {
      "epoch": 1.3741140476707194,
      "grad_norm": 2.9480156898498535,
      "learning_rate": 4.31320135507093e-05,
      "loss": 1.0911,
      "step": 129800
    },
    {
      "epoch": 1.3746433694507227,
      "grad_norm": 3.0984368324279785,
      "learning_rate": 4.312936692780013e-05,
      "loss": 1.0959,
      "step": 129850
    },
    {
      "epoch": 1.375172691230726,
      "grad_norm": 3.293008327484131,
      "learning_rate": 4.312672030489096e-05,
      "loss": 1.1002,
      "step": 129900
    },
    {
      "epoch": 1.3757020130107294,
      "grad_norm": 3.3195595741271973,
      "learning_rate": 4.312407368198179e-05,
      "loss": 1.1092,
      "step": 129950
    },
    {
      "epoch": 1.3762313347907327,
      "grad_norm": 3.0254061222076416,
      "learning_rate": 4.312142705907263e-05,
      "loss": 1.0937,
      "step": 130000
    },
    {
      "epoch": 1.3762313347907327,
      "eval_loss": 0.967627763748169,
      "eval_runtime": 46.8424,
      "eval_samples_per_second": 3585.001,
      "eval_steps_per_second": 448.141,
      "step": 130000
    },
    {
      "epoch": 1.376760656570736,
      "grad_norm": 2.7496016025543213,
      "learning_rate": 4.311878043616346e-05,
      "loss": 1.1031,
      "step": 130050
    },
    {
      "epoch": 1.3772899783507393,
      "grad_norm": 2.9981043338775635,
      "learning_rate": 4.311613381325429e-05,
      "loss": 1.106,
      "step": 130100
    },
    {
      "epoch": 1.3778193001307426,
      "grad_norm": 3.530813694000244,
      "learning_rate": 4.311348719034512e-05,
      "loss": 1.0821,
      "step": 130150
    },
    {
      "epoch": 1.3783486219107457,
      "grad_norm": 3.2434611320495605,
      "learning_rate": 4.3110840567435954e-05,
      "loss": 1.1076,
      "step": 130200
    },
    {
      "epoch": 1.378877943690749,
      "grad_norm": 2.996354341506958,
      "learning_rate": 4.310819394452679e-05,
      "loss": 1.108,
      "step": 130250
    },
    {
      "epoch": 1.3794072654707523,
      "grad_norm": 3.1502864360809326,
      "learning_rate": 4.3105547321617615e-05,
      "loss": 1.0902,
      "step": 130300
    },
    {
      "epoch": 1.3799365872507556,
      "grad_norm": 3.399012565612793,
      "learning_rate": 4.310295363116663e-05,
      "loss": 1.0867,
      "step": 130350
    },
    {
      "epoch": 1.380465909030759,
      "grad_norm": 3.251997947692871,
      "learning_rate": 4.310030700825747e-05,
      "loss": 1.0788,
      "step": 130400
    },
    {
      "epoch": 1.3809952308107623,
      "grad_norm": 3.124882698059082,
      "learning_rate": 4.30976603853483e-05,
      "loss": 1.0975,
      "step": 130450
    },
    {
      "epoch": 1.3815245525907653,
      "grad_norm": 3.1808977127075195,
      "learning_rate": 4.309501376243913e-05,
      "loss": 1.0862,
      "step": 130500
    },
    {
      "epoch": 1.3815245525907653,
      "eval_loss": 0.96597820520401,
      "eval_runtime": 46.6187,
      "eval_samples_per_second": 3602.205,
      "eval_steps_per_second": 450.292,
      "step": 130500
    },
    {
      "epoch": 1.3820538743707687,
      "grad_norm": 2.9234509468078613,
      "learning_rate": 4.309236713952996e-05,
      "loss": 1.0883,
      "step": 130550
    },
    {
      "epoch": 1.382583196150772,
      "grad_norm": 3.6167449951171875,
      "learning_rate": 4.3089720516620793e-05,
      "loss": 1.0955,
      "step": 130600
    },
    {
      "epoch": 1.3831125179307753,
      "grad_norm": 3.3062126636505127,
      "learning_rate": 4.308707389371163e-05,
      "loss": 1.0803,
      "step": 130650
    },
    {
      "epoch": 1.3836418397107786,
      "grad_norm": 3.137136220932007,
      "learning_rate": 4.3084427270802455e-05,
      "loss": 1.0792,
      "step": 130700
    },
    {
      "epoch": 1.384171161490782,
      "grad_norm": 3.2891621589660645,
      "learning_rate": 4.308178064789329e-05,
      "loss": 1.0681,
      "step": 130750
    },
    {
      "epoch": 1.3847004832707852,
      "grad_norm": 3.005659580230713,
      "learning_rate": 4.307913402498412e-05,
      "loss": 1.0817,
      "step": 130800
    },
    {
      "epoch": 1.3852298050507885,
      "grad_norm": 3.074218988418579,
      "learning_rate": 4.307648740207496e-05,
      "loss": 1.1164,
      "step": 130850
    },
    {
      "epoch": 1.3857591268307918,
      "grad_norm": 3.3579394817352295,
      "learning_rate": 4.3073840779165784e-05,
      "loss": 1.107,
      "step": 130900
    },
    {
      "epoch": 1.386288448610795,
      "grad_norm": 3.2113873958587646,
      "learning_rate": 4.307119415625662e-05,
      "loss": 1.0897,
      "step": 130950
    },
    {
      "epoch": 1.3868177703907982,
      "grad_norm": 3.109193801879883,
      "learning_rate": 4.306854753334745e-05,
      "loss": 1.0935,
      "step": 131000
    },
    {
      "epoch": 1.3868177703907982,
      "eval_loss": 0.9653373956680298,
      "eval_runtime": 46.7005,
      "eval_samples_per_second": 3595.891,
      "eval_steps_per_second": 449.502,
      "step": 131000
    },
    {
      "epoch": 1.3873470921708015,
      "grad_norm": 3.356194496154785,
      "learning_rate": 4.306590091043829e-05,
      "loss": 1.0638,
      "step": 131050
    },
    {
      "epoch": 1.3878764139508049,
      "grad_norm": 3.0002639293670654,
      "learning_rate": 4.3063254287529114e-05,
      "loss": 1.0735,
      "step": 131100
    },
    {
      "epoch": 1.3884057357308082,
      "grad_norm": 3.2196035385131836,
      "learning_rate": 4.306060766461995e-05,
      "loss": 1.0878,
      "step": 131150
    },
    {
      "epoch": 1.3889350575108115,
      "grad_norm": 3.2304797172546387,
      "learning_rate": 4.305796104171078e-05,
      "loss": 1.073,
      "step": 131200
    },
    {
      "epoch": 1.3894643792908146,
      "grad_norm": 3.186993360519409,
      "learning_rate": 4.305531441880161e-05,
      "loss": 1.0874,
      "step": 131250
    },
    {
      "epoch": 1.3899937010708179,
      "grad_norm": 3.5632171630859375,
      "learning_rate": 4.3052667795892444e-05,
      "loss": 1.0797,
      "step": 131300
    },
    {
      "epoch": 1.3905230228508212,
      "grad_norm": 3.213378667831421,
      "learning_rate": 4.305002117298327e-05,
      "loss": 1.0978,
      "step": 131350
    },
    {
      "epoch": 1.3910523446308245,
      "grad_norm": 3.4529435634613037,
      "learning_rate": 4.304737455007411e-05,
      "loss": 1.0943,
      "step": 131400
    },
    {
      "epoch": 1.3915816664108278,
      "grad_norm": 3.143096923828125,
      "learning_rate": 4.304472792716494e-05,
      "loss": 1.1018,
      "step": 131450
    },
    {
      "epoch": 1.3921109881908311,
      "grad_norm": 3.2368533611297607,
      "learning_rate": 4.304208130425577e-05,
      "loss": 1.0711,
      "step": 131500
    },
    {
      "epoch": 1.3921109881908311,
      "eval_loss": 0.9578703045845032,
      "eval_runtime": 46.6122,
      "eval_samples_per_second": 3602.702,
      "eval_steps_per_second": 450.354,
      "step": 131500
    },
    {
      "epoch": 1.3926403099708344,
      "grad_norm": 3.418957233428955,
      "learning_rate": 4.30394346813466e-05,
      "loss": 1.0991,
      "step": 131550
    },
    {
      "epoch": 1.3931696317508377,
      "grad_norm": 3.0312910079956055,
      "learning_rate": 4.303678805843744e-05,
      "loss": 1.0728,
      "step": 131600
    },
    {
      "epoch": 1.393698953530841,
      "grad_norm": 3.358036518096924,
      "learning_rate": 4.303414143552827e-05,
      "loss": 1.0827,
      "step": 131650
    },
    {
      "epoch": 1.3942282753108441,
      "grad_norm": 3.025941848754883,
      "learning_rate": 4.30314948126191e-05,
      "loss": 1.0919,
      "step": 131700
    },
    {
      "epoch": 1.3947575970908475,
      "grad_norm": 3.306556463241577,
      "learning_rate": 4.302884818970993e-05,
      "loss": 1.0821,
      "step": 131750
    },
    {
      "epoch": 1.3952869188708508,
      "grad_norm": 3.2017650604248047,
      "learning_rate": 4.3026201566800764e-05,
      "loss": 1.0935,
      "step": 131800
    },
    {
      "epoch": 1.395816240650854,
      "grad_norm": 3.193922996520996,
      "learning_rate": 4.30235549438916e-05,
      "loss": 1.0932,
      "step": 131850
    },
    {
      "epoch": 1.3963455624308574,
      "grad_norm": 3.244601011276245,
      "learning_rate": 4.3020908320982426e-05,
      "loss": 1.0812,
      "step": 131900
    },
    {
      "epoch": 1.3968748842108607,
      "grad_norm": 3.121750831604004,
      "learning_rate": 4.301826169807326e-05,
      "loss": 1.1017,
      "step": 131950
    },
    {
      "epoch": 1.3974042059908638,
      "grad_norm": 3.2650744915008545,
      "learning_rate": 4.3015615075164094e-05,
      "loss": 1.0749,
      "step": 132000
    },
    {
      "epoch": 1.3974042059908638,
      "eval_loss": 0.9594689607620239,
      "eval_runtime": 46.6719,
      "eval_samples_per_second": 3598.093,
      "eval_steps_per_second": 449.778,
      "step": 132000
    },
    {
      "epoch": 1.397933527770867,
      "grad_norm": 3.0181057453155518,
      "learning_rate": 4.301296845225493e-05,
      "loss": 1.1052,
      "step": 132050
    },
    {
      "epoch": 1.3984628495508704,
      "grad_norm": 2.8998138904571533,
      "learning_rate": 4.3010321829345755e-05,
      "loss": 1.0875,
      "step": 132100
    },
    {
      "epoch": 1.3989921713308737,
      "grad_norm": 3.4414308071136475,
      "learning_rate": 4.300767520643659e-05,
      "loss": 1.0743,
      "step": 132150
    },
    {
      "epoch": 1.399521493110877,
      "grad_norm": 3.1720869541168213,
      "learning_rate": 4.3005028583527424e-05,
      "loss": 1.0829,
      "step": 132200
    },
    {
      "epoch": 1.4000508148908803,
      "grad_norm": 3.2721030712127686,
      "learning_rate": 4.300238196061825e-05,
      "loss": 1.0897,
      "step": 132250
    },
    {
      "epoch": 1.4005801366708837,
      "grad_norm": 3.2314560413360596,
      "learning_rate": 4.2999735337709085e-05,
      "loss": 1.0909,
      "step": 132300
    },
    {
      "epoch": 1.401109458450887,
      "grad_norm": 3.134467124938965,
      "learning_rate": 4.299708871479991e-05,
      "loss": 1.0943,
      "step": 132350
    },
    {
      "epoch": 1.4016387802308903,
      "grad_norm": 3.161900281906128,
      "learning_rate": 4.2994495024348934e-05,
      "loss": 1.0716,
      "step": 132400
    },
    {
      "epoch": 1.4021681020108934,
      "grad_norm": 3.3998019695281982,
      "learning_rate": 4.299184840143977e-05,
      "loss": 1.0764,
      "step": 132450
    },
    {
      "epoch": 1.4026974237908967,
      "grad_norm": 3.0721142292022705,
      "learning_rate": 4.2989201778530595e-05,
      "loss": 1.1065,
      "step": 132500
    },
    {
      "epoch": 1.4026974237908967,
      "eval_loss": 0.9573884010314941,
      "eval_runtime": 46.7172,
      "eval_samples_per_second": 3594.608,
      "eval_steps_per_second": 449.342,
      "step": 132500
    },
    {
      "epoch": 1.4032267455709,
      "grad_norm": 3.2424163818359375,
      "learning_rate": 4.298655515562143e-05,
      "loss": 1.083,
      "step": 132550
    },
    {
      "epoch": 1.4037560673509033,
      "grad_norm": 3.490657329559326,
      "learning_rate": 4.2983908532712263e-05,
      "loss": 1.0818,
      "step": 132600
    },
    {
      "epoch": 1.4042853891309066,
      "grad_norm": 3.2124717235565186,
      "learning_rate": 4.29812619098031e-05,
      "loss": 1.095,
      "step": 132650
    },
    {
      "epoch": 1.40481471091091,
      "grad_norm": 3.305983304977417,
      "learning_rate": 4.2978615286893925e-05,
      "loss": 1.0867,
      "step": 132700
    },
    {
      "epoch": 1.405344032690913,
      "grad_norm": 2.836780548095703,
      "learning_rate": 4.297596866398476e-05,
      "loss": 1.0837,
      "step": 132750
    },
    {
      "epoch": 1.4058733544709163,
      "grad_norm": 3.1883487701416016,
      "learning_rate": 4.297332204107559e-05,
      "loss": 1.0978,
      "step": 132800
    },
    {
      "epoch": 1.4064026762509196,
      "grad_norm": 3.127828359603882,
      "learning_rate": 4.297067541816642e-05,
      "loss": 1.0972,
      "step": 132850
    },
    {
      "epoch": 1.406931998030923,
      "grad_norm": 3.4859018325805664,
      "learning_rate": 4.2968028795257255e-05,
      "loss": 1.0866,
      "step": 132900
    },
    {
      "epoch": 1.4074613198109263,
      "grad_norm": 3.614468812942505,
      "learning_rate": 4.296538217234808e-05,
      "loss": 1.0986,
      "step": 132950
    },
    {
      "epoch": 1.4079906415909296,
      "grad_norm": 3.230447292327881,
      "learning_rate": 4.296273554943892e-05,
      "loss": 1.0996,
      "step": 133000
    },
    {
      "epoch": 1.4079906415909296,
      "eval_loss": 0.9573597311973572,
      "eval_runtime": 46.6604,
      "eval_samples_per_second": 3598.986,
      "eval_steps_per_second": 449.889,
      "step": 133000
    },
    {
      "epoch": 1.4085199633709329,
      "grad_norm": 3.2644572257995605,
      "learning_rate": 4.296008892652975e-05,
      "loss": 1.0727,
      "step": 133050
    },
    {
      "epoch": 1.4090492851509362,
      "grad_norm": 3.2727391719818115,
      "learning_rate": 4.2957442303620584e-05,
      "loss": 1.0895,
      "step": 133100
    },
    {
      "epoch": 1.4095786069309395,
      "grad_norm": 3.3683676719665527,
      "learning_rate": 4.295479568071141e-05,
      "loss": 1.0951,
      "step": 133150
    },
    {
      "epoch": 1.4101079287109426,
      "grad_norm": 3.6539528369903564,
      "learning_rate": 4.2952149057802246e-05,
      "loss": 1.0921,
      "step": 133200
    },
    {
      "epoch": 1.410637250490946,
      "grad_norm": 3.149132013320923,
      "learning_rate": 4.294950243489308e-05,
      "loss": 1.083,
      "step": 133250
    },
    {
      "epoch": 1.4111665722709492,
      "grad_norm": 2.779792547225952,
      "learning_rate": 4.294685581198391e-05,
      "loss": 1.0648,
      "step": 133300
    },
    {
      "epoch": 1.4116958940509525,
      "grad_norm": 3.1418232917785645,
      "learning_rate": 4.294420918907474e-05,
      "loss": 1.0909,
      "step": 133350
    },
    {
      "epoch": 1.4122252158309558,
      "grad_norm": 3.397474527359009,
      "learning_rate": 4.2941562566165575e-05,
      "loss": 1.0764,
      "step": 133400
    },
    {
      "epoch": 1.4127545376109591,
      "grad_norm": 3.109297037124634,
      "learning_rate": 4.293891594325641e-05,
      "loss": 1.1035,
      "step": 133450
    },
    {
      "epoch": 1.4132838593909622,
      "grad_norm": 3.281259775161743,
      "learning_rate": 4.293626932034724e-05,
      "loss": 1.0886,
      "step": 133500
    },
    {
      "epoch": 1.4132838593909622,
      "eval_loss": 0.9527397155761719,
      "eval_runtime": 46.6178,
      "eval_samples_per_second": 3602.27,
      "eval_steps_per_second": 450.3,
      "step": 133500
    },
    {
      "epoch": 1.4138131811709655,
      "grad_norm": 3.007901668548584,
      "learning_rate": 4.293362269743807e-05,
      "loss": 1.0833,
      "step": 133550
    },
    {
      "epoch": 1.4143425029509689,
      "grad_norm": 3.1416709423065186,
      "learning_rate": 4.2930976074528905e-05,
      "loss": 1.0928,
      "step": 133600
    },
    {
      "epoch": 1.4148718247309722,
      "grad_norm": 3.253249406814575,
      "learning_rate": 4.292832945161974e-05,
      "loss": 1.0891,
      "step": 133650
    },
    {
      "epoch": 1.4154011465109755,
      "grad_norm": 2.7663135528564453,
      "learning_rate": 4.2925682828710566e-05,
      "loss": 1.0875,
      "step": 133700
    },
    {
      "epoch": 1.4159304682909788,
      "grad_norm": 2.989097833633423,
      "learning_rate": 4.29230362058014e-05,
      "loss": 1.0749,
      "step": 133750
    },
    {
      "epoch": 1.416459790070982,
      "grad_norm": 3.0254805088043213,
      "learning_rate": 4.2920389582892234e-05,
      "loss": 1.0843,
      "step": 133800
    },
    {
      "epoch": 1.4169891118509854,
      "grad_norm": 3.287801504135132,
      "learning_rate": 4.291774295998306e-05,
      "loss": 1.0948,
      "step": 133850
    },
    {
      "epoch": 1.4175184336309887,
      "grad_norm": 3.2312657833099365,
      "learning_rate": 4.2915096337073896e-05,
      "loss": 1.0822,
      "step": 133900
    },
    {
      "epoch": 1.4180477554109918,
      "grad_norm": 2.854994297027588,
      "learning_rate": 4.291244971416472e-05,
      "loss": 1.0947,
      "step": 133950
    },
    {
      "epoch": 1.4185770771909951,
      "grad_norm": 3.222372531890869,
      "learning_rate": 4.2909803091255564e-05,
      "loss": 1.0886,
      "step": 134000
    },
    {
      "epoch": 1.4185770771909951,
      "eval_loss": 0.9521422386169434,
      "eval_runtime": 46.6396,
      "eval_samples_per_second": 3600.587,
      "eval_steps_per_second": 450.089,
      "step": 134000
    },
    {
      "epoch": 1.4191063989709984,
      "grad_norm": 3.553251266479492,
      "learning_rate": 4.290715646834639e-05,
      "loss": 1.1006,
      "step": 134050
    },
    {
      "epoch": 1.4196357207510018,
      "grad_norm": 2.878431558609009,
      "learning_rate": 4.2904509845437226e-05,
      "loss": 1.102,
      "step": 134100
    },
    {
      "epoch": 1.420165042531005,
      "grad_norm": 3.304056406021118,
      "learning_rate": 4.290186322252805e-05,
      "loss": 1.0861,
      "step": 134150
    },
    {
      "epoch": 1.4206943643110084,
      "grad_norm": 3.314669609069824,
      "learning_rate": 4.2899216599618894e-05,
      "loss": 1.0689,
      "step": 134200
    },
    {
      "epoch": 1.4212236860910115,
      "grad_norm": 3.020357608795166,
      "learning_rate": 4.289656997670972e-05,
      "loss": 1.0674,
      "step": 134250
    },
    {
      "epoch": 1.4217530078710148,
      "grad_norm": 2.813721179962158,
      "learning_rate": 4.2893923353800555e-05,
      "loss": 1.0827,
      "step": 134300
    },
    {
      "epoch": 1.422282329651018,
      "grad_norm": 3.6246025562286377,
      "learning_rate": 4.289127673089138e-05,
      "loss": 1.0728,
      "step": 134350
    },
    {
      "epoch": 1.4228116514310214,
      "grad_norm": 3.1657822132110596,
      "learning_rate": 4.2888630107982217e-05,
      "loss": 1.1091,
      "step": 134400
    },
    {
      "epoch": 1.4233409732110247,
      "grad_norm": 3.565166711807251,
      "learning_rate": 4.288598348507305e-05,
      "loss": 1.0732,
      "step": 134450
    },
    {
      "epoch": 1.423870294991028,
      "grad_norm": 3.381898880004883,
      "learning_rate": 4.2883389794622065e-05,
      "loss": 1.075,
      "step": 134500
    },
    {
      "epoch": 1.423870294991028,
      "eval_loss": 0.9492807388305664,
      "eval_runtime": 46.587,
      "eval_samples_per_second": 3604.651,
      "eval_steps_per_second": 450.597,
      "step": 134500
    },
    {
      "epoch": 1.4243996167710313,
      "grad_norm": 3.4300942420959473,
      "learning_rate": 4.288074317171289e-05,
      "loss": 1.0909,
      "step": 134550
    },
    {
      "epoch": 1.4249289385510346,
      "grad_norm": 3.256990671157837,
      "learning_rate": 4.2878096548803734e-05,
      "loss": 1.0838,
      "step": 134600
    },
    {
      "epoch": 1.425458260331038,
      "grad_norm": 3.2189176082611084,
      "learning_rate": 4.287544992589456e-05,
      "loss": 1.0647,
      "step": 134650
    },
    {
      "epoch": 1.425987582111041,
      "grad_norm": 2.999018907546997,
      "learning_rate": 4.2872803302985395e-05,
      "loss": 1.0801,
      "step": 134700
    },
    {
      "epoch": 1.4265169038910444,
      "grad_norm": 3.319371223449707,
      "learning_rate": 4.287015668007622e-05,
      "loss": 1.0816,
      "step": 134750
    },
    {
      "epoch": 1.4270462256710477,
      "grad_norm": 3.350233793258667,
      "learning_rate": 4.2867510057167056e-05,
      "loss": 1.0865,
      "step": 134800
    },
    {
      "epoch": 1.427575547451051,
      "grad_norm": 2.776866912841797,
      "learning_rate": 4.286486343425789e-05,
      "loss": 1.081,
      "step": 134850
    },
    {
      "epoch": 1.4281048692310543,
      "grad_norm": 2.988370895385742,
      "learning_rate": 4.286221681134872e-05,
      "loss": 1.0731,
      "step": 134900
    },
    {
      "epoch": 1.4286341910110576,
      "grad_norm": 3.4107608795166016,
      "learning_rate": 4.285957018843955e-05,
      "loss": 1.0757,
      "step": 134950
    },
    {
      "epoch": 1.4291635127910607,
      "grad_norm": 3.1612019538879395,
      "learning_rate": 4.2856923565530386e-05,
      "loss": 1.0688,
      "step": 135000
    },
    {
      "epoch": 1.4291635127910607,
      "eval_loss": 0.948896050453186,
      "eval_runtime": 46.6412,
      "eval_samples_per_second": 3600.461,
      "eval_steps_per_second": 450.074,
      "step": 135000
    },
    {
      "epoch": 1.429692834571064,
      "grad_norm": 3.1295197010040283,
      "learning_rate": 4.285427694262122e-05,
      "loss": 1.0946,
      "step": 135050
    },
    {
      "epoch": 1.4302221563510673,
      "grad_norm": 3.2645373344421387,
      "learning_rate": 4.285163031971205e-05,
      "loss": 1.0762,
      "step": 135100
    },
    {
      "epoch": 1.4307514781310706,
      "grad_norm": 3.231797218322754,
      "learning_rate": 4.284898369680288e-05,
      "loss": 1.0817,
      "step": 135150
    },
    {
      "epoch": 1.431280799911074,
      "grad_norm": 3.411059617996216,
      "learning_rate": 4.2846337073893716e-05,
      "loss": 1.0786,
      "step": 135200
    },
    {
      "epoch": 1.4318101216910772,
      "grad_norm": 3.1969053745269775,
      "learning_rate": 4.284369045098455e-05,
      "loss": 1.0799,
      "step": 135250
    },
    {
      "epoch": 1.4323394434710806,
      "grad_norm": 3.113896369934082,
      "learning_rate": 4.284104382807538e-05,
      "loss": 1.0821,
      "step": 135300
    },
    {
      "epoch": 1.4328687652510839,
      "grad_norm": 3.1829047203063965,
      "learning_rate": 4.283839720516621e-05,
      "loss": 1.0921,
      "step": 135350
    },
    {
      "epoch": 1.4333980870310872,
      "grad_norm": 3.24783992767334,
      "learning_rate": 4.283575058225704e-05,
      "loss": 1.0825,
      "step": 135400
    },
    {
      "epoch": 1.4339274088110905,
      "grad_norm": 3.601696729660034,
      "learning_rate": 4.283310395934787e-05,
      "loss": 1.0706,
      "step": 135450
    },
    {
      "epoch": 1.4344567305910936,
      "grad_norm": 3.313045024871826,
      "learning_rate": 4.283045733643871e-05,
      "loss": 1.074,
      "step": 135500
    },
    {
      "epoch": 1.4344567305910936,
      "eval_loss": 0.9453871250152588,
      "eval_runtime": 46.6207,
      "eval_samples_per_second": 3602.051,
      "eval_steps_per_second": 450.272,
      "step": 135500
    },
    {
      "epoch": 1.4349860523710969,
      "grad_norm": 3.2756893634796143,
      "learning_rate": 4.2827810713529534e-05,
      "loss": 1.0697,
      "step": 135550
    },
    {
      "epoch": 1.4355153741511002,
      "grad_norm": 3.312567710876465,
      "learning_rate": 4.282516409062037e-05,
      "loss": 1.0639,
      "step": 135600
    },
    {
      "epoch": 1.4360446959311035,
      "grad_norm": 3.0078799724578857,
      "learning_rate": 4.28225174677112e-05,
      "loss": 1.0606,
      "step": 135650
    },
    {
      "epoch": 1.4365740177111068,
      "grad_norm": 3.20172381401062,
      "learning_rate": 4.2819870844802036e-05,
      "loss": 1.0587,
      "step": 135700
    },
    {
      "epoch": 1.43710333949111,
      "grad_norm": 3.259368419647217,
      "learning_rate": 4.2817224221892864e-05,
      "loss": 1.0598,
      "step": 135750
    },
    {
      "epoch": 1.4376326612711132,
      "grad_norm": 3.0973997116088867,
      "learning_rate": 4.28145775989837e-05,
      "loss": 1.0721,
      "step": 135800
    },
    {
      "epoch": 1.4381619830511165,
      "grad_norm": 3.3192152976989746,
      "learning_rate": 4.281193097607453e-05,
      "loss": 1.0678,
      "step": 135850
    },
    {
      "epoch": 1.4386913048311198,
      "grad_norm": 3.296973705291748,
      "learning_rate": 4.2809284353165366e-05,
      "loss": 1.0863,
      "step": 135900
    },
    {
      "epoch": 1.4392206266111232,
      "grad_norm": 3.4002349376678467,
      "learning_rate": 4.280663773025619e-05,
      "loss": 1.0724,
      "step": 135950
    },
    {
      "epoch": 1.4397499483911265,
      "grad_norm": 3.347661256790161,
      "learning_rate": 4.280399110734703e-05,
      "loss": 1.0752,
      "step": 136000
    },
    {
      "epoch": 1.4397499483911265,
      "eval_loss": 0.9431588649749756,
      "eval_runtime": 46.6405,
      "eval_samples_per_second": 3600.52,
      "eval_steps_per_second": 450.081,
      "step": 136000
    },
    {
      "epoch": 1.4402792701711298,
      "grad_norm": 3.3007681369781494,
      "learning_rate": 4.280134448443786e-05,
      "loss": 1.0683,
      "step": 136050
    },
    {
      "epoch": 1.440808591951133,
      "grad_norm": 3.4005954265594482,
      "learning_rate": 4.279869786152869e-05,
      "loss": 1.0774,
      "step": 136100
    },
    {
      "epoch": 1.4413379137311364,
      "grad_norm": 3.0939202308654785,
      "learning_rate": 4.279605123861952e-05,
      "loss": 1.0823,
      "step": 136150
    },
    {
      "epoch": 1.4418672355111397,
      "grad_norm": 3.4513015747070312,
      "learning_rate": 4.279340461571035e-05,
      "loss": 1.0673,
      "step": 136200
    },
    {
      "epoch": 1.4423965572911428,
      "grad_norm": 2.9241843223571777,
      "learning_rate": 4.279075799280119e-05,
      "loss": 1.0849,
      "step": 136250
    },
    {
      "epoch": 1.4429258790711461,
      "grad_norm": 3.2577741146087646,
      "learning_rate": 4.278811136989202e-05,
      "loss": 1.0737,
      "step": 136300
    },
    {
      "epoch": 1.4434552008511494,
      "grad_norm": 3.3355259895324707,
      "learning_rate": 4.278546474698285e-05,
      "loss": 1.0653,
      "step": 136350
    },
    {
      "epoch": 1.4439845226311527,
      "grad_norm": 3.178046464920044,
      "learning_rate": 4.278281812407368e-05,
      "loss": 1.0848,
      "step": 136400
    },
    {
      "epoch": 1.444513844411156,
      "grad_norm": 3.3674426078796387,
      "learning_rate": 4.278017150116452e-05,
      "loss": 1.0733,
      "step": 136450
    },
    {
      "epoch": 1.4450431661911591,
      "grad_norm": 3.2148709297180176,
      "learning_rate": 4.277757781071353e-05,
      "loss": 1.0541,
      "step": 136500
    },
    {
      "epoch": 1.4450431661911591,
      "eval_loss": 0.9433835744857788,
      "eval_runtime": 46.5865,
      "eval_samples_per_second": 3604.692,
      "eval_steps_per_second": 450.603,
      "step": 136500
    },
    {
      "epoch": 1.4455724879711624,
      "grad_norm": 2.741046190261841,
      "learning_rate": 4.277493118780436e-05,
      "loss": 1.0535,
      "step": 136550
    },
    {
      "epoch": 1.4461018097511658,
      "grad_norm": 3.218963861465454,
      "learning_rate": 4.277228456489519e-05,
      "loss": 1.0726,
      "step": 136600
    },
    {
      "epoch": 1.446631131531169,
      "grad_norm": 3.156085252761841,
      "learning_rate": 4.276963794198603e-05,
      "loss": 1.0546,
      "step": 136650
    },
    {
      "epoch": 1.4471604533111724,
      "grad_norm": 3.4668450355529785,
      "learning_rate": 4.276699131907686e-05,
      "loss": 1.0851,
      "step": 136700
    },
    {
      "epoch": 1.4476897750911757,
      "grad_norm": 3.1438872814178467,
      "learning_rate": 4.276434469616769e-05,
      "loss": 1.0982,
      "step": 136750
    },
    {
      "epoch": 1.448219096871179,
      "grad_norm": 3.1395225524902344,
      "learning_rate": 4.276169807325852e-05,
      "loss": 1.0646,
      "step": 136800
    },
    {
      "epoch": 1.4487484186511823,
      "grad_norm": 3.0864412784576416,
      "learning_rate": 4.275905145034936e-05,
      "loss": 1.0579,
      "step": 136850
    },
    {
      "epoch": 1.4492777404311856,
      "grad_norm": 3.367551326751709,
      "learning_rate": 4.275640482744019e-05,
      "loss": 1.0767,
      "step": 136900
    },
    {
      "epoch": 1.449807062211189,
      "grad_norm": 3.202932596206665,
      "learning_rate": 4.275375820453102e-05,
      "loss": 1.0766,
      "step": 136950
    },
    {
      "epoch": 1.450336383991192,
      "grad_norm": 3.0520763397216797,
      "learning_rate": 4.275111158162185e-05,
      "loss": 1.0883,
      "step": 137000
    },
    {
      "epoch": 1.450336383991192,
      "eval_loss": 0.9429177045822144,
      "eval_runtime": 46.7005,
      "eval_samples_per_second": 3595.895,
      "eval_steps_per_second": 449.503,
      "step": 137000
    },
    {
      "epoch": 1.4508657057711953,
      "grad_norm": 3.4580039978027344,
      "learning_rate": 4.2748464958712683e-05,
      "loss": 1.0775,
      "step": 137050
    },
    {
      "epoch": 1.4513950275511986,
      "grad_norm": 3.293868064880371,
      "learning_rate": 4.274581833580352e-05,
      "loss": 1.0803,
      "step": 137100
    },
    {
      "epoch": 1.451924349331202,
      "grad_norm": 3.065222978591919,
      "learning_rate": 4.2743171712894345e-05,
      "loss": 1.0644,
      "step": 137150
    },
    {
      "epoch": 1.4524536711112053,
      "grad_norm": 3.5095155239105225,
      "learning_rate": 4.274052508998518e-05,
      "loss": 1.0682,
      "step": 137200
    },
    {
      "epoch": 1.4529829928912084,
      "grad_norm": 3.3039791584014893,
      "learning_rate": 4.273787846707601e-05,
      "loss": 1.0855,
      "step": 137250
    },
    {
      "epoch": 1.4535123146712117,
      "grad_norm": 3.2173633575439453,
      "learning_rate": 4.273523184416685e-05,
      "loss": 1.0738,
      "step": 137300
    },
    {
      "epoch": 1.454041636451215,
      "grad_norm": 3.377027988433838,
      "learning_rate": 4.2732585221257674e-05,
      "loss": 1.0714,
      "step": 137350
    },
    {
      "epoch": 1.4545709582312183,
      "grad_norm": 3.5683765411376953,
      "learning_rate": 4.272993859834851e-05,
      "loss": 1.0801,
      "step": 137400
    },
    {
      "epoch": 1.4551002800112216,
      "grad_norm": 2.8337583541870117,
      "learning_rate": 4.272729197543934e-05,
      "loss": 1.061,
      "step": 137450
    },
    {
      "epoch": 1.455629601791225,
      "grad_norm": 3.2281105518341064,
      "learning_rate": 4.272464535253018e-05,
      "loss": 1.0499,
      "step": 137500
    },
    {
      "epoch": 1.455629601791225,
      "eval_loss": 0.9391546845436096,
      "eval_runtime": 46.6283,
      "eval_samples_per_second": 3601.46,
      "eval_steps_per_second": 450.199,
      "step": 137500
    },
    {
      "epoch": 1.4561589235712282,
      "grad_norm": 3.1625685691833496,
      "learning_rate": 4.2721998729621004e-05,
      "loss": 1.0862,
      "step": 137550
    },
    {
      "epoch": 1.4566882453512315,
      "grad_norm": 3.3457815647125244,
      "learning_rate": 4.271935210671184e-05,
      "loss": 1.0676,
      "step": 137600
    },
    {
      "epoch": 1.4572175671312348,
      "grad_norm": 3.4619534015655518,
      "learning_rate": 4.271670548380267e-05,
      "loss": 1.0787,
      "step": 137650
    },
    {
      "epoch": 1.4577468889112382,
      "grad_norm": 3.3343098163604736,
      "learning_rate": 4.27140588608935e-05,
      "loss": 1.0901,
      "step": 137700
    },
    {
      "epoch": 1.4582762106912412,
      "grad_norm": 3.254110097885132,
      "learning_rate": 4.2711412237984334e-05,
      "loss": 1.0569,
      "step": 137750
    },
    {
      "epoch": 1.4588055324712446,
      "grad_norm": 3.47005558013916,
      "learning_rate": 4.270876561507516e-05,
      "loss": 1.0838,
      "step": 137800
    },
    {
      "epoch": 1.4593348542512479,
      "grad_norm": 3.2044379711151123,
      "learning_rate": 4.2706118992166e-05,
      "loss": 1.0676,
      "step": 137850
    },
    {
      "epoch": 1.4598641760312512,
      "grad_norm": 3.9896717071533203,
      "learning_rate": 4.270347236925683e-05,
      "loss": 1.0828,
      "step": 137900
    },
    {
      "epoch": 1.4603934978112545,
      "grad_norm": 3.0477092266082764,
      "learning_rate": 4.270082574634766e-05,
      "loss": 1.0723,
      "step": 137950
    },
    {
      "epoch": 1.4609228195912578,
      "grad_norm": 3.2956647872924805,
      "learning_rate": 4.269817912343849e-05,
      "loss": 1.0572,
      "step": 138000
    },
    {
      "epoch": 1.4609228195912578,
      "eval_loss": 0.935042679309845,
      "eval_runtime": 46.6298,
      "eval_samples_per_second": 3601.345,
      "eval_steps_per_second": 450.184,
      "step": 138000
    },
    {
      "epoch": 1.461452141371261,
      "grad_norm": 3.3527584075927734,
      "learning_rate": 4.269553250052933e-05,
      "loss": 1.0538,
      "step": 138050
    },
    {
      "epoch": 1.4619814631512642,
      "grad_norm": 2.8548271656036377,
      "learning_rate": 4.269288587762016e-05,
      "loss": 1.0699,
      "step": 138100
    },
    {
      "epoch": 1.4625107849312675,
      "grad_norm": 3.073193311691284,
      "learning_rate": 4.269023925471099e-05,
      "loss": 1.081,
      "step": 138150
    },
    {
      "epoch": 1.4630401067112708,
      "grad_norm": 3.349236011505127,
      "learning_rate": 4.268759263180182e-05,
      "loss": 1.0668,
      "step": 138200
    },
    {
      "epoch": 1.4635694284912741,
      "grad_norm": 3.5023932456970215,
      "learning_rate": 4.2684946008892654e-05,
      "loss": 1.0624,
      "step": 138250
    },
    {
      "epoch": 1.4640987502712774,
      "grad_norm": 3.1343536376953125,
      "learning_rate": 4.268229938598349e-05,
      "loss": 1.0745,
      "step": 138300
    },
    {
      "epoch": 1.4646280720512808,
      "grad_norm": 3.427210807800293,
      "learning_rate": 4.2679652763074316e-05,
      "loss": 1.068,
      "step": 138350
    },
    {
      "epoch": 1.465157393831284,
      "grad_norm": 3.1573281288146973,
      "learning_rate": 4.267700614016515e-05,
      "loss": 1.0764,
      "step": 138400
    },
    {
      "epoch": 1.4656867156112874,
      "grad_norm": 3.1463370323181152,
      "learning_rate": 4.2674359517255984e-05,
      "loss": 1.081,
      "step": 138450
    },
    {
      "epoch": 1.4662160373912905,
      "grad_norm": 3.1683850288391113,
      "learning_rate": 4.267171289434682e-05,
      "loss": 1.0812,
      "step": 138500
    },
    {
      "epoch": 1.4662160373912905,
      "eval_loss": 0.9362982511520386,
      "eval_runtime": 46.6029,
      "eval_samples_per_second": 3603.421,
      "eval_steps_per_second": 450.444,
      "step": 138500
    },
    {
      "epoch": 1.4667453591712938,
      "grad_norm": 3.319775342941284,
      "learning_rate": 4.266911920389583e-05,
      "loss": 1.0583,
      "step": 138550
    },
    {
      "epoch": 1.467274680951297,
      "grad_norm": 3.1978416442871094,
      "learning_rate": 4.266647258098666e-05,
      "loss": 1.0579,
      "step": 138600
    },
    {
      "epoch": 1.4678040027313004,
      "grad_norm": 3.317891836166382,
      "learning_rate": 4.2663825958077494e-05,
      "loss": 1.0648,
      "step": 138650
    },
    {
      "epoch": 1.4683333245113037,
      "grad_norm": 3.3986635208129883,
      "learning_rate": 4.266117933516833e-05,
      "loss": 1.0711,
      "step": 138700
    },
    {
      "epoch": 1.468862646291307,
      "grad_norm": 3.604541063308716,
      "learning_rate": 4.2658532712259156e-05,
      "loss": 1.0693,
      "step": 138750
    },
    {
      "epoch": 1.4693919680713101,
      "grad_norm": 3.104095697402954,
      "learning_rate": 4.265588608934999e-05,
      "loss": 1.0681,
      "step": 138800
    },
    {
      "epoch": 1.4699212898513134,
      "grad_norm": 3.327988624572754,
      "learning_rate": 4.2653239466440824e-05,
      "loss": 1.0713,
      "step": 138850
    },
    {
      "epoch": 1.4704506116313167,
      "grad_norm": 3.2492077350616455,
      "learning_rate": 4.265059284353166e-05,
      "loss": 1.0649,
      "step": 138900
    },
    {
      "epoch": 1.47097993341132,
      "grad_norm": 3.659566640853882,
      "learning_rate": 4.2647946220622485e-05,
      "loss": 1.0787,
      "step": 138950
    },
    {
      "epoch": 1.4715092551913234,
      "grad_norm": 3.614204168319702,
      "learning_rate": 4.264529959771332e-05,
      "loss": 1.0718,
      "step": 139000
    },
    {
      "epoch": 1.4715092551913234,
      "eval_loss": 0.9312305450439453,
      "eval_runtime": 46.657,
      "eval_samples_per_second": 3599.243,
      "eval_steps_per_second": 449.921,
      "step": 139000
    },
    {
      "epoch": 1.4720385769713267,
      "grad_norm": 2.730302572250366,
      "learning_rate": 4.2642652974804153e-05,
      "loss": 1.0754,
      "step": 139050
    },
    {
      "epoch": 1.47256789875133,
      "grad_norm": 3.0675573348999023,
      "learning_rate": 4.264000635189499e-05,
      "loss": 1.0745,
      "step": 139100
    },
    {
      "epoch": 1.4730972205313333,
      "grad_norm": 3.5755350589752197,
      "learning_rate": 4.2637359728985815e-05,
      "loss": 1.0696,
      "step": 139150
    },
    {
      "epoch": 1.4736265423113366,
      "grad_norm": 3.498663902282715,
      "learning_rate": 4.263471310607665e-05,
      "loss": 1.0607,
      "step": 139200
    },
    {
      "epoch": 1.4741558640913397,
      "grad_norm": 3.551401138305664,
      "learning_rate": 4.263206648316748e-05,
      "loss": 1.06,
      "step": 139250
    },
    {
      "epoch": 1.474685185871343,
      "grad_norm": 3.0330357551574707,
      "learning_rate": 4.262941986025831e-05,
      "loss": 1.0692,
      "step": 139300
    },
    {
      "epoch": 1.4752145076513463,
      "grad_norm": 3.030764579772949,
      "learning_rate": 4.2626773237349145e-05,
      "loss": 1.0887,
      "step": 139350
    },
    {
      "epoch": 1.4757438294313496,
      "grad_norm": 3.6349167823791504,
      "learning_rate": 4.262412661443997e-05,
      "loss": 1.062,
      "step": 139400
    },
    {
      "epoch": 1.476273151211353,
      "grad_norm": 3.5469250679016113,
      "learning_rate": 4.262147999153081e-05,
      "loss": 1.0591,
      "step": 139450
    },
    {
      "epoch": 1.4768024729913563,
      "grad_norm": 3.241882085800171,
      "learning_rate": 4.261883336862164e-05,
      "loss": 1.057,
      "step": 139500
    },
    {
      "epoch": 1.4768024729913563,
      "eval_loss": 0.932541012763977,
      "eval_runtime": 46.657,
      "eval_samples_per_second": 3599.242,
      "eval_steps_per_second": 449.921,
      "step": 139500
    },
    {
      "epoch": 1.4773317947713593,
      "grad_norm": 3.258284568786621,
      "learning_rate": 4.2616186745712474e-05,
      "loss": 1.0666,
      "step": 139550
    },
    {
      "epoch": 1.4778611165513627,
      "grad_norm": 3.0889978408813477,
      "learning_rate": 4.26135401228033e-05,
      "loss": 1.064,
      "step": 139600
    },
    {
      "epoch": 1.478390438331366,
      "grad_norm": 3.2269668579101562,
      "learning_rate": 4.2610893499894136e-05,
      "loss": 1.0668,
      "step": 139650
    },
    {
      "epoch": 1.4789197601113693,
      "grad_norm": 3.147305965423584,
      "learning_rate": 4.260824687698497e-05,
      "loss": 1.063,
      "step": 139700
    },
    {
      "epoch": 1.4794490818913726,
      "grad_norm": 3.5119693279266357,
      "learning_rate": 4.26056002540758e-05,
      "loss": 1.0724,
      "step": 139750
    },
    {
      "epoch": 1.479978403671376,
      "grad_norm": 2.9838333129882812,
      "learning_rate": 4.260295363116663e-05,
      "loss": 1.0773,
      "step": 139800
    },
    {
      "epoch": 1.4805077254513792,
      "grad_norm": 3.168879508972168,
      "learning_rate": 4.2600307008257465e-05,
      "loss": 1.083,
      "step": 139850
    },
    {
      "epoch": 1.4810370472313825,
      "grad_norm": 3.2767229080200195,
      "learning_rate": 4.25976603853483e-05,
      "loss": 1.0729,
      "step": 139900
    },
    {
      "epoch": 1.4815663690113858,
      "grad_norm": 3.450380802154541,
      "learning_rate": 4.259501376243913e-05,
      "loss": 1.0686,
      "step": 139950
    },
    {
      "epoch": 1.482095690791389,
      "grad_norm": 3.4470393657684326,
      "learning_rate": 4.259236713952996e-05,
      "loss": 1.0648,
      "step": 140000
    },
    {
      "epoch": 1.482095690791389,
      "eval_loss": 0.9286919236183167,
      "eval_runtime": 46.5723,
      "eval_samples_per_second": 3605.791,
      "eval_steps_per_second": 450.74,
      "step": 140000
    },
    {
      "epoch": 1.4826250125713922,
      "grad_norm": 3.175034999847412,
      "learning_rate": 4.2589720516620795e-05,
      "loss": 1.0858,
      "step": 140050
    },
    {
      "epoch": 1.4831543343513955,
      "grad_norm": 3.4968624114990234,
      "learning_rate": 4.258707389371163e-05,
      "loss": 1.0759,
      "step": 140100
    },
    {
      "epoch": 1.4836836561313989,
      "grad_norm": 3.5172793865203857,
      "learning_rate": 4.2584427270802456e-05,
      "loss": 1.0759,
      "step": 140150
    },
    {
      "epoch": 1.4842129779114022,
      "grad_norm": 3.283515453338623,
      "learning_rate": 4.258178064789329e-05,
      "loss": 1.0729,
      "step": 140200
    },
    {
      "epoch": 1.4847422996914055,
      "grad_norm": 3.218472719192505,
      "learning_rate": 4.2579134024984124e-05,
      "loss": 1.0609,
      "step": 140250
    },
    {
      "epoch": 1.4852716214714086,
      "grad_norm": 2.9985241889953613,
      "learning_rate": 4.257648740207495e-05,
      "loss": 1.0694,
      "step": 140300
    },
    {
      "epoch": 1.4858009432514119,
      "grad_norm": 3.3020689487457275,
      "learning_rate": 4.2573840779165786e-05,
      "loss": 1.0635,
      "step": 140350
    },
    {
      "epoch": 1.4863302650314152,
      "grad_norm": 3.4638020992279053,
      "learning_rate": 4.257119415625661e-05,
      "loss": 1.0586,
      "step": 140400
    },
    {
      "epoch": 1.4868595868114185,
      "grad_norm": 2.9383797645568848,
      "learning_rate": 4.2568547533347454e-05,
      "loss": 1.0672,
      "step": 140450
    },
    {
      "epoch": 1.4873889085914218,
      "grad_norm": 3.25840425491333,
      "learning_rate": 4.256590091043828e-05,
      "loss": 1.0485,
      "step": 140500
    },
    {
      "epoch": 1.4873889085914218,
      "eval_loss": 0.9274156093597412,
      "eval_runtime": 46.6878,
      "eval_samples_per_second": 3596.869,
      "eval_steps_per_second": 449.625,
      "step": 140500
    },
    {
      "epoch": 1.4879182303714251,
      "grad_norm": 3.4406182765960693,
      "learning_rate": 4.2563254287529115e-05,
      "loss": 1.0536,
      "step": 140550
    },
    {
      "epoch": 1.4884475521514284,
      "grad_norm": 3.411604881286621,
      "learning_rate": 4.256060766461994e-05,
      "loss": 1.0476,
      "step": 140600
    },
    {
      "epoch": 1.4889768739314317,
      "grad_norm": 3.3932857513427734,
      "learning_rate": 4.2557961041710784e-05,
      "loss": 1.0674,
      "step": 140650
    },
    {
      "epoch": 1.489506195711435,
      "grad_norm": 3.3761961460113525,
      "learning_rate": 4.255536735125979e-05,
      "loss": 1.0715,
      "step": 140700
    },
    {
      "epoch": 1.4900355174914381,
      "grad_norm": 3.214651584625244,
      "learning_rate": 4.2552720728350626e-05,
      "loss": 1.0554,
      "step": 140750
    },
    {
      "epoch": 1.4905648392714415,
      "grad_norm": 3.202577590942383,
      "learning_rate": 4.255007410544146e-05,
      "loss": 1.0652,
      "step": 140800
    },
    {
      "epoch": 1.4910941610514448,
      "grad_norm": 3.347153663635254,
      "learning_rate": 4.2547427482532294e-05,
      "loss": 1.0692,
      "step": 140850
    },
    {
      "epoch": 1.491623482831448,
      "grad_norm": 3.2425730228424072,
      "learning_rate": 4.254478085962312e-05,
      "loss": 1.0557,
      "step": 140900
    },
    {
      "epoch": 1.4921528046114514,
      "grad_norm": 3.458857297897339,
      "learning_rate": 4.2542134236713955e-05,
      "loss": 1.054,
      "step": 140950
    },
    {
      "epoch": 1.4926821263914547,
      "grad_norm": 3.355562210083008,
      "learning_rate": 4.253948761380478e-05,
      "loss": 1.0645,
      "step": 141000
    },
    {
      "epoch": 1.4926821263914547,
      "eval_loss": 0.9251310229301453,
      "eval_runtime": 46.5419,
      "eval_samples_per_second": 3608.146,
      "eval_steps_per_second": 451.034,
      "step": 141000
    },
    {
      "epoch": 1.4932114481714578,
      "grad_norm": 3.319002151489258,
      "learning_rate": 4.2536840990895624e-05,
      "loss": 1.0853,
      "step": 141050
    },
    {
      "epoch": 1.493740769951461,
      "grad_norm": 3.1502327919006348,
      "learning_rate": 4.253419436798645e-05,
      "loss": 1.0597,
      "step": 141100
    },
    {
      "epoch": 1.4942700917314644,
      "grad_norm": 3.1918084621429443,
      "learning_rate": 4.2531547745077285e-05,
      "loss": 1.0599,
      "step": 141150
    },
    {
      "epoch": 1.4947994135114677,
      "grad_norm": 3.3852274417877197,
      "learning_rate": 4.252890112216811e-05,
      "loss": 1.0506,
      "step": 141200
    },
    {
      "epoch": 1.495328735291471,
      "grad_norm": 3.531676769256592,
      "learning_rate": 4.2526254499258946e-05,
      "loss": 1.0747,
      "step": 141250
    },
    {
      "epoch": 1.4958580570714743,
      "grad_norm": 3.304593086242676,
      "learning_rate": 4.252360787634978e-05,
      "loss": 1.0607,
      "step": 141300
    },
    {
      "epoch": 1.4963873788514777,
      "grad_norm": 3.6738922595977783,
      "learning_rate": 4.252096125344061e-05,
      "loss": 1.0516,
      "step": 141350
    },
    {
      "epoch": 1.496916700631481,
      "grad_norm": 3.2216224670410156,
      "learning_rate": 4.251831463053144e-05,
      "loss": 1.0674,
      "step": 141400
    },
    {
      "epoch": 1.4974460224114843,
      "grad_norm": 3.285362720489502,
      "learning_rate": 4.2515668007622276e-05,
      "loss": 1.0739,
      "step": 141450
    },
    {
      "epoch": 1.4979753441914874,
      "grad_norm": 3.3266472816467285,
      "learning_rate": 4.251302138471311e-05,
      "loss": 1.0451,
      "step": 141500
    },
    {
      "epoch": 1.4979753441914874,
      "eval_loss": 0.9228980541229248,
      "eval_runtime": 46.5526,
      "eval_samples_per_second": 3607.314,
      "eval_steps_per_second": 450.93,
      "step": 141500
    },
    {
      "epoch": 1.4985046659714907,
      "grad_norm": 3.1587629318237305,
      "learning_rate": 4.251037476180394e-05,
      "loss": 1.0715,
      "step": 141550
    },
    {
      "epoch": 1.499033987751494,
      "grad_norm": 3.4868979454040527,
      "learning_rate": 4.250772813889477e-05,
      "loss": 1.0704,
      "step": 141600
    },
    {
      "epoch": 1.4995633095314973,
      "grad_norm": 3.3598527908325195,
      "learning_rate": 4.2505081515985606e-05,
      "loss": 1.0596,
      "step": 141650
    },
    {
      "epoch": 1.5000926313115006,
      "grad_norm": 3.458610773086548,
      "learning_rate": 4.250243489307644e-05,
      "loss": 1.0659,
      "step": 141700
    },
    {
      "epoch": 1.5006219530915037,
      "grad_norm": 3.2520663738250732,
      "learning_rate": 4.249978827016727e-05,
      "loss": 1.0464,
      "step": 141750
    },
    {
      "epoch": 1.501151274871507,
      "grad_norm": 3.0700411796569824,
      "learning_rate": 4.24971416472581e-05,
      "loss": 1.0531,
      "step": 141800
    },
    {
      "epoch": 1.5016805966515103,
      "grad_norm": 3.1949987411499023,
      "learning_rate": 4.2494495024348935e-05,
      "loss": 1.0568,
      "step": 141850
    },
    {
      "epoch": 1.5022099184315136,
      "grad_norm": 3.4721996784210205,
      "learning_rate": 4.249184840143976e-05,
      "loss": 1.0712,
      "step": 141900
    },
    {
      "epoch": 1.502739240211517,
      "grad_norm": 3.406959056854248,
      "learning_rate": 4.24892017785306e-05,
      "loss": 1.066,
      "step": 141950
    },
    {
      "epoch": 1.5032685619915203,
      "grad_norm": 3.46856427192688,
      "learning_rate": 4.2486555155621424e-05,
      "loss": 1.0338,
      "step": 142000
    },
    {
      "epoch": 1.5032685619915203,
      "eval_loss": 0.9224876761436462,
      "eval_runtime": 46.5968,
      "eval_samples_per_second": 3603.896,
      "eval_steps_per_second": 450.503,
      "step": 142000
    },
    {
      "epoch": 1.5037978837715236,
      "grad_norm": 3.4882187843322754,
      "learning_rate": 4.2483908532712265e-05,
      "loss": 1.0819,
      "step": 142050
    },
    {
      "epoch": 1.5043272055515269,
      "grad_norm": 3.5200929641723633,
      "learning_rate": 4.248126190980309e-05,
      "loss": 1.0534,
      "step": 142100
    },
    {
      "epoch": 1.5048565273315302,
      "grad_norm": 3.6991991996765137,
      "learning_rate": 4.2478615286893926e-05,
      "loss": 1.0556,
      "step": 142150
    },
    {
      "epoch": 1.5053858491115335,
      "grad_norm": 3.4829111099243164,
      "learning_rate": 4.2475968663984754e-05,
      "loss": 1.061,
      "step": 142200
    },
    {
      "epoch": 1.5059151708915368,
      "grad_norm": 3.3826308250427246,
      "learning_rate": 4.2473322041075595e-05,
      "loss": 1.0526,
      "step": 142250
    },
    {
      "epoch": 1.50644449267154,
      "grad_norm": 3.2259061336517334,
      "learning_rate": 4.247067541816642e-05,
      "loss": 1.0698,
      "step": 142300
    },
    {
      "epoch": 1.5069738144515432,
      "grad_norm": 3.453677177429199,
      "learning_rate": 4.2468028795257256e-05,
      "loss": 1.0584,
      "step": 142350
    },
    {
      "epoch": 1.5075031362315465,
      "grad_norm": 3.497324228286743,
      "learning_rate": 4.246538217234808e-05,
      "loss": 1.0565,
      "step": 142400
    },
    {
      "epoch": 1.5080324580115498,
      "grad_norm": 3.093132495880127,
      "learning_rate": 4.246273554943892e-05,
      "loss": 1.0724,
      "step": 142450
    },
    {
      "epoch": 1.508561779791553,
      "grad_norm": 3.065615177154541,
      "learning_rate": 4.246008892652975e-05,
      "loss": 1.0604,
      "step": 142500
    },
    {
      "epoch": 1.508561779791553,
      "eval_loss": 0.9247164130210876,
      "eval_runtime": 46.5617,
      "eval_samples_per_second": 3606.609,
      "eval_steps_per_second": 450.842,
      "step": 142500
    },
    {
      "epoch": 1.5090911015715562,
      "grad_norm": 3.5523929595947266,
      "learning_rate": 4.245744230362058e-05,
      "loss": 1.0733,
      "step": 142550
    },
    {
      "epoch": 1.5096204233515595,
      "grad_norm": 3.303851842880249,
      "learning_rate": 4.245479568071141e-05,
      "loss": 1.0713,
      "step": 142600
    },
    {
      "epoch": 1.5101497451315629,
      "grad_norm": 3.2347142696380615,
      "learning_rate": 4.245214905780225e-05,
      "loss": 1.065,
      "step": 142650
    },
    {
      "epoch": 1.5106790669115662,
      "grad_norm": 3.2180614471435547,
      "learning_rate": 4.244950243489308e-05,
      "loss": 1.0696,
      "step": 142700
    },
    {
      "epoch": 1.5112083886915695,
      "grad_norm": 3.26153564453125,
      "learning_rate": 4.2446908744442096e-05,
      "loss": 1.0561,
      "step": 142750
    },
    {
      "epoch": 1.5117377104715728,
      "grad_norm": 3.5370450019836426,
      "learning_rate": 4.244426212153292e-05,
      "loss": 1.0653,
      "step": 142800
    },
    {
      "epoch": 1.512267032251576,
      "grad_norm": 3.4211807250976562,
      "learning_rate": 4.244161549862376e-05,
      "loss": 1.0532,
      "step": 142850
    },
    {
      "epoch": 1.5127963540315794,
      "grad_norm": 3.289224624633789,
      "learning_rate": 4.243896887571459e-05,
      "loss": 1.0586,
      "step": 142900
    },
    {
      "epoch": 1.5133256758115827,
      "grad_norm": 3.222137928009033,
      "learning_rate": 4.243632225280542e-05,
      "loss": 1.0607,
      "step": 142950
    },
    {
      "epoch": 1.513854997591586,
      "grad_norm": 3.1385421752929688,
      "learning_rate": 4.243367562989625e-05,
      "loss": 1.067,
      "step": 143000
    },
    {
      "epoch": 1.513854997591586,
      "eval_loss": 0.9176473021507263,
      "eval_runtime": 46.6414,
      "eval_samples_per_second": 3600.447,
      "eval_steps_per_second": 450.072,
      "step": 143000
    },
    {
      "epoch": 1.5143843193715893,
      "grad_norm": 3.4245681762695312,
      "learning_rate": 4.243102900698709e-05,
      "loss": 1.0574,
      "step": 143050
    },
    {
      "epoch": 1.5149136411515924,
      "grad_norm": 3.593238353729248,
      "learning_rate": 4.242838238407792e-05,
      "loss": 1.0681,
      "step": 143100
    },
    {
      "epoch": 1.5154429629315957,
      "grad_norm": 3.1193902492523193,
      "learning_rate": 4.242573576116875e-05,
      "loss": 1.0661,
      "step": 143150
    },
    {
      "epoch": 1.515972284711599,
      "grad_norm": 3.6240220069885254,
      "learning_rate": 4.242308913825958e-05,
      "loss": 1.0481,
      "step": 143200
    },
    {
      "epoch": 1.5165016064916021,
      "grad_norm": 2.9410862922668457,
      "learning_rate": 4.2420442515350416e-05,
      "loss": 1.0626,
      "step": 143250
    },
    {
      "epoch": 1.5170309282716055,
      "grad_norm": 3.6593048572540283,
      "learning_rate": 4.241779589244125e-05,
      "loss": 1.0613,
      "step": 143300
    },
    {
      "epoch": 1.5175602500516088,
      "grad_norm": 3.183525562286377,
      "learning_rate": 4.241514926953208e-05,
      "loss": 1.0588,
      "step": 143350
    },
    {
      "epoch": 1.518089571831612,
      "grad_norm": 3.3005731105804443,
      "learning_rate": 4.241250264662291e-05,
      "loss": 1.0529,
      "step": 143400
    },
    {
      "epoch": 1.5186188936116154,
      "grad_norm": 3.3481078147888184,
      "learning_rate": 4.2409856023713746e-05,
      "loss": 1.0733,
      "step": 143450
    },
    {
      "epoch": 1.5191482153916187,
      "grad_norm": 3.460200071334839,
      "learning_rate": 4.2407209400804573e-05,
      "loss": 1.0405,
      "step": 143500
    },
    {
      "epoch": 1.5191482153916187,
      "eval_loss": 0.9167094230651855,
      "eval_runtime": 46.6375,
      "eval_samples_per_second": 3600.753,
      "eval_steps_per_second": 450.11,
      "step": 143500
    },
    {
      "epoch": 1.519677537171622,
      "grad_norm": 3.430091619491577,
      "learning_rate": 4.240456277789541e-05,
      "loss": 1.0309,
      "step": 143550
    },
    {
      "epoch": 1.5202068589516253,
      "grad_norm": 3.470365047454834,
      "learning_rate": 4.2401916154986235e-05,
      "loss": 1.0549,
      "step": 143600
    },
    {
      "epoch": 1.5207361807316286,
      "grad_norm": 3.290738344192505,
      "learning_rate": 4.2399269532077076e-05,
      "loss": 1.0422,
      "step": 143650
    },
    {
      "epoch": 1.521265502511632,
      "grad_norm": 2.9105441570281982,
      "learning_rate": 4.23966229091679e-05,
      "loss": 1.0551,
      "step": 143700
    },
    {
      "epoch": 1.5217948242916353,
      "grad_norm": 3.2368581295013428,
      "learning_rate": 4.239397628625874e-05,
      "loss": 1.0533,
      "step": 143750
    },
    {
      "epoch": 1.5223241460716386,
      "grad_norm": 3.207674980163574,
      "learning_rate": 4.2391329663349564e-05,
      "loss": 1.0736,
      "step": 143800
    },
    {
      "epoch": 1.5228534678516417,
      "grad_norm": 3.3975989818573,
      "learning_rate": 4.2388683040440405e-05,
      "loss": 1.066,
      "step": 143850
    },
    {
      "epoch": 1.523382789631645,
      "grad_norm": 3.279529571533203,
      "learning_rate": 4.238603641753123e-05,
      "loss": 1.0571,
      "step": 143900
    },
    {
      "epoch": 1.5239121114116483,
      "grad_norm": 3.553863763809204,
      "learning_rate": 4.238338979462207e-05,
      "loss": 1.0841,
      "step": 143950
    },
    {
      "epoch": 1.5244414331916514,
      "grad_norm": 3.1525590419769287,
      "learning_rate": 4.2380743171712894e-05,
      "loss": 1.042,
      "step": 144000
    },
    {
      "epoch": 1.5244414331916514,
      "eval_loss": 0.9185807704925537,
      "eval_runtime": 46.5259,
      "eval_samples_per_second": 3609.386,
      "eval_steps_per_second": 451.189,
      "step": 144000
    },
    {
      "epoch": 1.5249707549716547,
      "grad_norm": 3.276174783706665,
      "learning_rate": 4.237809654880373e-05,
      "loss": 1.0325,
      "step": 144050
    },
    {
      "epoch": 1.525500076751658,
      "grad_norm": 3.4324381351470947,
      "learning_rate": 4.237544992589456e-05,
      "loss": 1.044,
      "step": 144100
    },
    {
      "epoch": 1.5260293985316613,
      "grad_norm": 3.3204081058502197,
      "learning_rate": 4.237280330298539e-05,
      "loss": 1.0514,
      "step": 144150
    },
    {
      "epoch": 1.5265587203116646,
      "grad_norm": 3.122019052505493,
      "learning_rate": 4.2370156680076224e-05,
      "loss": 1.0594,
      "step": 144200
    },
    {
      "epoch": 1.527088042091668,
      "grad_norm": 3.571431875228882,
      "learning_rate": 4.236751005716706e-05,
      "loss": 1.0369,
      "step": 144250
    },
    {
      "epoch": 1.5276173638716712,
      "grad_norm": 3.345318555831909,
      "learning_rate": 4.236486343425789e-05,
      "loss": 1.0621,
      "step": 144300
    },
    {
      "epoch": 1.5281466856516746,
      "grad_norm": 3.1158461570739746,
      "learning_rate": 4.236221681134872e-05,
      "loss": 1.0583,
      "step": 144350
    },
    {
      "epoch": 1.5286760074316779,
      "grad_norm": 3.1881866455078125,
      "learning_rate": 4.235957018843955e-05,
      "loss": 1.0431,
      "step": 144400
    },
    {
      "epoch": 1.5292053292116812,
      "grad_norm": 2.9755682945251465,
      "learning_rate": 4.235692356553039e-05,
      "loss": 1.0594,
      "step": 144450
    },
    {
      "epoch": 1.5297346509916845,
      "grad_norm": 3.845954418182373,
      "learning_rate": 4.235427694262122e-05,
      "loss": 1.0665,
      "step": 144500
    },
    {
      "epoch": 1.5297346509916845,
      "eval_loss": 0.9139652848243713,
      "eval_runtime": 46.5628,
      "eval_samples_per_second": 3606.526,
      "eval_steps_per_second": 450.832,
      "step": 144500
    },
    {
      "epoch": 1.5302639727716878,
      "grad_norm": 3.284264326095581,
      "learning_rate": 4.235163031971205e-05,
      "loss": 1.047,
      "step": 144550
    },
    {
      "epoch": 1.5307932945516909,
      "grad_norm": 3.5368611812591553,
      "learning_rate": 4.234898369680288e-05,
      "loss": 1.0549,
      "step": 144600
    },
    {
      "epoch": 1.5313226163316942,
      "grad_norm": 3.4028494358062744,
      "learning_rate": 4.234633707389372e-05,
      "loss": 1.0701,
      "step": 144650
    },
    {
      "epoch": 1.5318519381116975,
      "grad_norm": 3.368570566177368,
      "learning_rate": 4.2343690450984544e-05,
      "loss": 1.059,
      "step": 144700
    },
    {
      "epoch": 1.5323812598917006,
      "grad_norm": 3.4729580879211426,
      "learning_rate": 4.234109676053356e-05,
      "loss": 1.0653,
      "step": 144750
    },
    {
      "epoch": 1.532910581671704,
      "grad_norm": 3.400987386703491,
      "learning_rate": 4.233845013762439e-05,
      "loss": 1.0491,
      "step": 144800
    },
    {
      "epoch": 1.5334399034517072,
      "grad_norm": 3.063736915588379,
      "learning_rate": 4.233580351471523e-05,
      "loss": 1.0506,
      "step": 144850
    },
    {
      "epoch": 1.5339692252317105,
      "grad_norm": 3.2943735122680664,
      "learning_rate": 4.233315689180606e-05,
      "loss": 1.0589,
      "step": 144900
    },
    {
      "epoch": 1.5344985470117138,
      "grad_norm": 3.233842611312866,
      "learning_rate": 4.233051026889689e-05,
      "loss": 1.0494,
      "step": 144950
    },
    {
      "epoch": 1.5350278687917172,
      "grad_norm": 3.214273691177368,
      "learning_rate": 4.232786364598772e-05,
      "loss": 1.052,
      "step": 145000
    },
    {
      "epoch": 1.5350278687917172,
      "eval_loss": 0.9111059904098511,
      "eval_runtime": 46.7371,
      "eval_samples_per_second": 3593.075,
      "eval_steps_per_second": 449.15,
      "step": 145000
    },
    {
      "epoch": 1.5355571905717205,
      "grad_norm": 3.4084136486053467,
      "learning_rate": 4.232521702307856e-05,
      "loss": 1.0519,
      "step": 145050
    },
    {
      "epoch": 1.5360865123517238,
      "grad_norm": 3.2161784172058105,
      "learning_rate": 4.2322570400169384e-05,
      "loss": 1.0706,
      "step": 145100
    },
    {
      "epoch": 1.536615834131727,
      "grad_norm": 3.287632942199707,
      "learning_rate": 4.231992377726022e-05,
      "loss": 1.052,
      "step": 145150
    },
    {
      "epoch": 1.5371451559117304,
      "grad_norm": 3.303826093673706,
      "learning_rate": 4.2317277154351046e-05,
      "loss": 1.0675,
      "step": 145200
    },
    {
      "epoch": 1.5376744776917337,
      "grad_norm": 3.235020637512207,
      "learning_rate": 4.2314630531441887e-05,
      "loss": 1.0653,
      "step": 145250
    },
    {
      "epoch": 1.538203799471737,
      "grad_norm": 3.118215799331665,
      "learning_rate": 4.2311983908532714e-05,
      "loss": 1.0556,
      "step": 145300
    },
    {
      "epoch": 1.53873312125174,
      "grad_norm": 3.3006227016448975,
      "learning_rate": 4.230933728562355e-05,
      "loss": 1.0488,
      "step": 145350
    },
    {
      "epoch": 1.5392624430317434,
      "grad_norm": 3.6997880935668945,
      "learning_rate": 4.2306690662714375e-05,
      "loss": 1.0449,
      "step": 145400
    },
    {
      "epoch": 1.5397917648117467,
      "grad_norm": 3.9342708587646484,
      "learning_rate": 4.2304044039805216e-05,
      "loss": 1.0369,
      "step": 145450
    },
    {
      "epoch": 1.54032108659175,
      "grad_norm": 3.3220231533050537,
      "learning_rate": 4.2301397416896043e-05,
      "loss": 1.0642,
      "step": 145500
    },
    {
      "epoch": 1.54032108659175,
      "eval_loss": 0.9100905060768127,
      "eval_runtime": 46.6016,
      "eval_samples_per_second": 3603.523,
      "eval_steps_per_second": 450.456,
      "step": 145500
    },
    {
      "epoch": 1.5408504083717531,
      "grad_norm": 3.13419508934021,
      "learning_rate": 4.229875079398688e-05,
      "loss": 1.0574,
      "step": 145550
    },
    {
      "epoch": 1.5413797301517564,
      "grad_norm": 3.246849775314331,
      "learning_rate": 4.2296104171077705e-05,
      "loss": 1.0538,
      "step": 145600
    },
    {
      "epoch": 1.5419090519317598,
      "grad_norm": 3.1687867641448975,
      "learning_rate": 4.229345754816854e-05,
      "loss": 1.0436,
      "step": 145650
    },
    {
      "epoch": 1.542438373711763,
      "grad_norm": 3.4750008583068848,
      "learning_rate": 4.229081092525937e-05,
      "loss": 1.0585,
      "step": 145700
    },
    {
      "epoch": 1.5429676954917664,
      "grad_norm": 3.6732068061828613,
      "learning_rate": 4.22881643023502e-05,
      "loss": 1.0451,
      "step": 145750
    },
    {
      "epoch": 1.5434970172717697,
      "grad_norm": 3.517279863357544,
      "learning_rate": 4.2285517679441035e-05,
      "loss": 1.0564,
      "step": 145800
    },
    {
      "epoch": 1.544026339051773,
      "grad_norm": 3.4093315601348877,
      "learning_rate": 4.228287105653187e-05,
      "loss": 1.0539,
      "step": 145850
    },
    {
      "epoch": 1.5445556608317763,
      "grad_norm": 3.3644185066223145,
      "learning_rate": 4.22802244336227e-05,
      "loss": 1.0434,
      "step": 145900
    },
    {
      "epoch": 1.5450849826117796,
      "grad_norm": 3.2841110229492188,
      "learning_rate": 4.227757781071353e-05,
      "loss": 1.0544,
      "step": 145950
    },
    {
      "epoch": 1.545614304391783,
      "grad_norm": 3.052854061126709,
      "learning_rate": 4.2274931187804364e-05,
      "loss": 1.0565,
      "step": 146000
    },
    {
      "epoch": 1.545614304391783,
      "eval_loss": 0.9088913798332214,
      "eval_runtime": 46.588,
      "eval_samples_per_second": 3604.573,
      "eval_steps_per_second": 450.588,
      "step": 146000
    },
    {
      "epoch": 1.5461436261717862,
      "grad_norm": 3.4021072387695312,
      "learning_rate": 4.22722845648952e-05,
      "loss": 1.0284,
      "step": 146050
    },
    {
      "epoch": 1.5466729479517893,
      "grad_norm": 2.9821479320526123,
      "learning_rate": 4.2269637941986026e-05,
      "loss": 1.042,
      "step": 146100
    },
    {
      "epoch": 1.5472022697317926,
      "grad_norm": 3.514613628387451,
      "learning_rate": 4.226699131907686e-05,
      "loss": 1.0496,
      "step": 146150
    },
    {
      "epoch": 1.547731591511796,
      "grad_norm": 3.366780996322632,
      "learning_rate": 4.226434469616769e-05,
      "loss": 1.046,
      "step": 146200
    },
    {
      "epoch": 1.5482609132917993,
      "grad_norm": 3.3021204471588135,
      "learning_rate": 4.226169807325853e-05,
      "loss": 1.0483,
      "step": 146250
    },
    {
      "epoch": 1.5487902350718024,
      "grad_norm": 3.508946657180786,
      "learning_rate": 4.2259051450349355e-05,
      "loss": 1.0477,
      "step": 146300
    },
    {
      "epoch": 1.5493195568518057,
      "grad_norm": 3.03926682472229,
      "learning_rate": 4.225640482744019e-05,
      "loss": 1.0588,
      "step": 146350
    },
    {
      "epoch": 1.549848878631809,
      "grad_norm": 3.3695507049560547,
      "learning_rate": 4.225375820453102e-05,
      "loss": 1.0526,
      "step": 146400
    },
    {
      "epoch": 1.5503782004118123,
      "grad_norm": 3.4871442317962646,
      "learning_rate": 4.225111158162186e-05,
      "loss": 1.0348,
      "step": 146450
    },
    {
      "epoch": 1.5509075221918156,
      "grad_norm": 3.593200445175171,
      "learning_rate": 4.2248464958712685e-05,
      "loss": 1.0258,
      "step": 146500
    },
    {
      "epoch": 1.5509075221918156,
      "eval_loss": 0.9085272550582886,
      "eval_runtime": 46.7666,
      "eval_samples_per_second": 3590.808,
      "eval_steps_per_second": 448.867,
      "step": 146500
    },
    {
      "epoch": 1.551436843971819,
      "grad_norm": 3.684021234512329,
      "learning_rate": 4.224581833580352e-05,
      "loss": 1.0482,
      "step": 146550
    },
    {
      "epoch": 1.5519661657518222,
      "grad_norm": 3.3803908824920654,
      "learning_rate": 4.2243171712894346e-05,
      "loss": 1.0333,
      "step": 146600
    },
    {
      "epoch": 1.5524954875318255,
      "grad_norm": 3.5169620513916016,
      "learning_rate": 4.224052508998518e-05,
      "loss": 1.0532,
      "step": 146650
    },
    {
      "epoch": 1.5530248093118288,
      "grad_norm": 3.407623052597046,
      "learning_rate": 4.2237878467076014e-05,
      "loss": 1.0398,
      "step": 146700
    },
    {
      "epoch": 1.5535541310918322,
      "grad_norm": 3.6370651721954346,
      "learning_rate": 4.223523184416684e-05,
      "loss": 1.0414,
      "step": 146750
    },
    {
      "epoch": 1.5540834528718355,
      "grad_norm": 3.2280402183532715,
      "learning_rate": 4.2232638153715856e-05,
      "loss": 1.0467,
      "step": 146800
    },
    {
      "epoch": 1.5546127746518386,
      "grad_norm": 3.1392242908477783,
      "learning_rate": 4.22299915308067e-05,
      "loss": 1.0482,
      "step": 146850
    },
    {
      "epoch": 1.5551420964318419,
      "grad_norm": 3.2462034225463867,
      "learning_rate": 4.2227344907897525e-05,
      "loss": 1.0496,
      "step": 146900
    },
    {
      "epoch": 1.5556714182118452,
      "grad_norm": 3.6200664043426514,
      "learning_rate": 4.222469828498836e-05,
      "loss": 1.0525,
      "step": 146950
    },
    {
      "epoch": 1.5562007399918485,
      "grad_norm": 3.3775010108947754,
      "learning_rate": 4.2222051662079186e-05,
      "loss": 1.065,
      "step": 147000
    },
    {
      "epoch": 1.5562007399918485,
      "eval_loss": 0.904578447341919,
      "eval_runtime": 46.5467,
      "eval_samples_per_second": 3607.772,
      "eval_steps_per_second": 450.988,
      "step": 147000
    },
    {
      "epoch": 1.5567300617718516,
      "grad_norm": 3.650498628616333,
      "learning_rate": 4.221940503917002e-05,
      "loss": 1.0414,
      "step": 147050
    },
    {
      "epoch": 1.557259383551855,
      "grad_norm": 3.5628821849823,
      "learning_rate": 4.2216758416260854e-05,
      "loss": 1.0587,
      "step": 147100
    },
    {
      "epoch": 1.5577887053318582,
      "grad_norm": 3.3805363178253174,
      "learning_rate": 4.221411179335168e-05,
      "loss": 1.042,
      "step": 147150
    },
    {
      "epoch": 1.5583180271118615,
      "grad_norm": 3.4097888469696045,
      "learning_rate": 4.2211465170442516e-05,
      "loss": 1.0609,
      "step": 147200
    },
    {
      "epoch": 1.5588473488918648,
      "grad_norm": 3.3241724967956543,
      "learning_rate": 4.220881854753335e-05,
      "loss": 1.045,
      "step": 147250
    },
    {
      "epoch": 1.5593766706718681,
      "grad_norm": 3.3059020042419434,
      "learning_rate": 4.2206171924624184e-05,
      "loss": 1.0216,
      "step": 147300
    },
    {
      "epoch": 1.5599059924518714,
      "grad_norm": 3.078214168548584,
      "learning_rate": 4.220352530171501e-05,
      "loss": 1.0367,
      "step": 147350
    },
    {
      "epoch": 1.5604353142318748,
      "grad_norm": 3.449636936187744,
      "learning_rate": 4.2200878678805845e-05,
      "loss": 1.0383,
      "step": 147400
    },
    {
      "epoch": 1.560964636011878,
      "grad_norm": 3.4367759227752686,
      "learning_rate": 4.219823205589668e-05,
      "loss": 1.0207,
      "step": 147450
    },
    {
      "epoch": 1.5614939577918814,
      "grad_norm": 3.5910210609436035,
      "learning_rate": 4.2195585432987514e-05,
      "loss": 1.0545,
      "step": 147500
    },
    {
      "epoch": 1.5614939577918814,
      "eval_loss": 0.9019244313240051,
      "eval_runtime": 46.5404,
      "eval_samples_per_second": 3608.261,
      "eval_steps_per_second": 451.049,
      "step": 147500
    },
    {
      "epoch": 1.5620232795718847,
      "grad_norm": 3.7988550662994385,
      "learning_rate": 4.219293881007834e-05,
      "loss": 1.0465,
      "step": 147550
    },
    {
      "epoch": 1.5625526013518878,
      "grad_norm": 3.447239398956299,
      "learning_rate": 4.2190292187169175e-05,
      "loss": 1.038,
      "step": 147600
    },
    {
      "epoch": 1.563081923131891,
      "grad_norm": 3.2429816722869873,
      "learning_rate": 4.218764556426001e-05,
      "loss": 1.0514,
      "step": 147650
    },
    {
      "epoch": 1.5636112449118944,
      "grad_norm": 3.4516332149505615,
      "learning_rate": 4.2184998941350836e-05,
      "loss": 1.0346,
      "step": 147700
    },
    {
      "epoch": 1.5641405666918977,
      "grad_norm": 3.873091697692871,
      "learning_rate": 4.218235231844167e-05,
      "loss": 1.0508,
      "step": 147750
    },
    {
      "epoch": 1.5646698884719008,
      "grad_norm": 3.779147148132324,
      "learning_rate": 4.21797056955325e-05,
      "loss": 1.0572,
      "step": 147800
    },
    {
      "epoch": 1.5651992102519041,
      "grad_norm": 3.6650776863098145,
      "learning_rate": 4.217705907262334e-05,
      "loss": 1.0508,
      "step": 147850
    },
    {
      "epoch": 1.5657285320319074,
      "grad_norm": 3.1272823810577393,
      "learning_rate": 4.2174412449714166e-05,
      "loss": 1.0349,
      "step": 147900
    },
    {
      "epoch": 1.5662578538119107,
      "grad_norm": 3.0602376461029053,
      "learning_rate": 4.2171765826805e-05,
      "loss": 1.0661,
      "step": 147950
    },
    {
      "epoch": 1.566787175591914,
      "grad_norm": 3.564425468444824,
      "learning_rate": 4.216911920389583e-05,
      "loss": 1.0333,
      "step": 148000
    },
    {
      "epoch": 1.566787175591914,
      "eval_loss": 0.9037882089614868,
      "eval_runtime": 46.5484,
      "eval_samples_per_second": 3607.643,
      "eval_steps_per_second": 450.971,
      "step": 148000
    },
    {
      "epoch": 1.5673164973719174,
      "grad_norm": 3.03279709815979,
      "learning_rate": 4.216647258098667e-05,
      "loss": 1.0489,
      "step": 148050
    },
    {
      "epoch": 1.5678458191519207,
      "grad_norm": 3.245502233505249,
      "learning_rate": 4.2163825958077496e-05,
      "loss": 1.0557,
      "step": 148100
    },
    {
      "epoch": 1.568375140931924,
      "grad_norm": 3.4365265369415283,
      "learning_rate": 4.216117933516833e-05,
      "loss": 1.0493,
      "step": 148150
    },
    {
      "epoch": 1.5689044627119273,
      "grad_norm": 3.3930318355560303,
      "learning_rate": 4.215853271225916e-05,
      "loss": 1.0439,
      "step": 148200
    },
    {
      "epoch": 1.5694337844919306,
      "grad_norm": 3.4998221397399902,
      "learning_rate": 4.215588608934999e-05,
      "loss": 1.0447,
      "step": 148250
    },
    {
      "epoch": 1.569963106271934,
      "grad_norm": 3.3893887996673584,
      "learning_rate": 4.2153239466440825e-05,
      "loss": 1.0642,
      "step": 148300
    },
    {
      "epoch": 1.570492428051937,
      "grad_norm": 3.2288007736206055,
      "learning_rate": 4.215059284353165e-05,
      "loss": 1.053,
      "step": 148350
    },
    {
      "epoch": 1.5710217498319403,
      "grad_norm": 3.3361947536468506,
      "learning_rate": 4.214794622062249e-05,
      "loss": 1.0667,
      "step": 148400
    },
    {
      "epoch": 1.5715510716119436,
      "grad_norm": 3.2852420806884766,
      "learning_rate": 4.214529959771332e-05,
      "loss": 1.0529,
      "step": 148450
    },
    {
      "epoch": 1.572080393391947,
      "grad_norm": 3.719788074493408,
      "learning_rate": 4.2142652974804155e-05,
      "loss": 1.0365,
      "step": 148500
    },
    {
      "epoch": 1.572080393391947,
      "eval_loss": 0.8977410793304443,
      "eval_runtime": 46.7313,
      "eval_samples_per_second": 3593.521,
      "eval_steps_per_second": 449.206,
      "step": 148500
    },
    {
      "epoch": 1.57260971517195,
      "grad_norm": 3.249692678451538,
      "learning_rate": 4.214000635189498e-05,
      "loss": 1.0615,
      "step": 148550
    },
    {
      "epoch": 1.5731390369519533,
      "grad_norm": 3.614731788635254,
      "learning_rate": 4.2137359728985816e-05,
      "loss": 1.0516,
      "step": 148600
    },
    {
      "epoch": 1.5736683587319567,
      "grad_norm": 3.3720152378082275,
      "learning_rate": 4.213471310607665e-05,
      "loss": 1.0401,
      "step": 148650
    },
    {
      "epoch": 1.57419768051196,
      "grad_norm": 3.6228151321411133,
      "learning_rate": 4.2132066483167485e-05,
      "loss": 1.0594,
      "step": 148700
    },
    {
      "epoch": 1.5747270022919633,
      "grad_norm": 3.4986422061920166,
      "learning_rate": 4.212941986025831e-05,
      "loss": 1.0576,
      "step": 148750
    },
    {
      "epoch": 1.5752563240719666,
      "grad_norm": 2.922273635864258,
      "learning_rate": 4.2126773237349146e-05,
      "loss": 1.0426,
      "step": 148800
    },
    {
      "epoch": 1.57578564585197,
      "grad_norm": 3.4686543941497803,
      "learning_rate": 4.212417954689816e-05,
      "loss": 1.0437,
      "step": 148850
    },
    {
      "epoch": 1.5763149676319732,
      "grad_norm": 3.21437668800354,
      "learning_rate": 4.2121532923988995e-05,
      "loss": 1.0452,
      "step": 148900
    },
    {
      "epoch": 1.5768442894119765,
      "grad_norm": 3.6948401927948,
      "learning_rate": 4.211888630107982e-05,
      "loss": 1.0401,
      "step": 148950
    },
    {
      "epoch": 1.5773736111919798,
      "grad_norm": 3.583320140838623,
      "learning_rate": 4.2116239678170656e-05,
      "loss": 1.0417,
      "step": 149000
    },
    {
      "epoch": 1.5773736111919798,
      "eval_loss": 0.8985674977302551,
      "eval_runtime": 46.6323,
      "eval_samples_per_second": 3601.149,
      "eval_steps_per_second": 450.16,
      "step": 149000
    },
    {
      "epoch": 1.5779029329719831,
      "grad_norm": 3.7539010047912598,
      "learning_rate": 4.211359305526149e-05,
      "loss": 1.0325,
      "step": 149050
    },
    {
      "epoch": 1.5784322547519862,
      "grad_norm": 3.234009265899658,
      "learning_rate": 4.2110946432352324e-05,
      "loss": 1.0613,
      "step": 149100
    },
    {
      "epoch": 1.5789615765319895,
      "grad_norm": 3.156572103500366,
      "learning_rate": 4.210829980944315e-05,
      "loss": 1.0382,
      "step": 149150
    },
    {
      "epoch": 1.5794908983119929,
      "grad_norm": 3.4708852767944336,
      "learning_rate": 4.2105653186533986e-05,
      "loss": 1.0506,
      "step": 149200
    },
    {
      "epoch": 1.5800202200919962,
      "grad_norm": 3.8441736698150635,
      "learning_rate": 4.210300656362482e-05,
      "loss": 1.0473,
      "step": 149250
    },
    {
      "epoch": 1.5805495418719993,
      "grad_norm": 3.3027772903442383,
      "learning_rate": 4.210035994071565e-05,
      "loss": 1.0396,
      "step": 149300
    },
    {
      "epoch": 1.5810788636520026,
      "grad_norm": 3.4589877128601074,
      "learning_rate": 4.209771331780648e-05,
      "loss": 1.046,
      "step": 149350
    },
    {
      "epoch": 1.5816081854320059,
      "grad_norm": 3.6590373516082764,
      "learning_rate": 4.209506669489731e-05,
      "loss": 1.0426,
      "step": 149400
    },
    {
      "epoch": 1.5821375072120092,
      "grad_norm": 3.228609085083008,
      "learning_rate": 4.209242007198815e-05,
      "loss": 1.0516,
      "step": 149450
    },
    {
      "epoch": 1.5826668289920125,
      "grad_norm": 3.2652130126953125,
      "learning_rate": 4.208977344907898e-05,
      "loss": 1.0301,
      "step": 149500
    },
    {
      "epoch": 1.5826668289920125,
      "eval_loss": 0.8956990242004395,
      "eval_runtime": 46.5367,
      "eval_samples_per_second": 3608.552,
      "eval_steps_per_second": 451.085,
      "step": 149500
    },
    {
      "epoch": 1.5831961507720158,
      "grad_norm": 3.4890050888061523,
      "learning_rate": 4.208712682616981e-05,
      "loss": 1.0358,
      "step": 149550
    },
    {
      "epoch": 1.5837254725520191,
      "grad_norm": 3.4957611560821533,
      "learning_rate": 4.208448020326064e-05,
      "loss": 1.0426,
      "step": 149600
    },
    {
      "epoch": 1.5842547943320224,
      "grad_norm": 3.453620672225952,
      "learning_rate": 4.208183358035148e-05,
      "loss": 1.0448,
      "step": 149650
    },
    {
      "epoch": 1.5847841161120257,
      "grad_norm": 3.332742214202881,
      "learning_rate": 4.2079186957442306e-05,
      "loss": 1.0399,
      "step": 149700
    },
    {
      "epoch": 1.585313437892029,
      "grad_norm": 3.409926414489746,
      "learning_rate": 4.207654033453314e-05,
      "loss": 1.0348,
      "step": 149750
    },
    {
      "epoch": 1.5858427596720324,
      "grad_norm": 3.3654470443725586,
      "learning_rate": 4.207389371162397e-05,
      "loss": 1.0504,
      "step": 149800
    },
    {
      "epoch": 1.5863720814520355,
      "grad_norm": 3.359476089477539,
      "learning_rate": 4.20712470887148e-05,
      "loss": 1.0478,
      "step": 149850
    },
    {
      "epoch": 1.5869014032320388,
      "grad_norm": 3.453291416168213,
      "learning_rate": 4.2068600465805636e-05,
      "loss": 1.0562,
      "step": 149900
    },
    {
      "epoch": 1.587430725012042,
      "grad_norm": 3.3270227909088135,
      "learning_rate": 4.2065953842896463e-05,
      "loss": 1.0361,
      "step": 149950
    },
    {
      "epoch": 1.5879600467920454,
      "grad_norm": 3.6035146713256836,
      "learning_rate": 4.20633072199873e-05,
      "loss": 1.0524,
      "step": 150000
    },
    {
      "epoch": 1.5879600467920454,
      "eval_loss": 0.8963285684585571,
      "eval_runtime": 46.5921,
      "eval_samples_per_second": 3604.255,
      "eval_steps_per_second": 450.548,
      "step": 150000
    },
    {
      "epoch": 1.5884893685720485,
      "grad_norm": 3.458495855331421,
      "learning_rate": 4.2060660597078125e-05,
      "loss": 1.0308,
      "step": 150050
    },
    {
      "epoch": 1.5890186903520518,
      "grad_norm": 3.492255687713623,
      "learning_rate": 4.2058013974168966e-05,
      "loss": 1.0439,
      "step": 150100
    },
    {
      "epoch": 1.589548012132055,
      "grad_norm": 3.4237301349639893,
      "learning_rate": 4.205536735125979e-05,
      "loss": 1.0321,
      "step": 150150
    },
    {
      "epoch": 1.5900773339120584,
      "grad_norm": 3.336305618286133,
      "learning_rate": 4.205272072835063e-05,
      "loss": 1.0472,
      "step": 150200
    },
    {
      "epoch": 1.5906066556920617,
      "grad_norm": 3.1133272647857666,
      "learning_rate": 4.2050074105441454e-05,
      "loss": 1.0193,
      "step": 150250
    },
    {
      "epoch": 1.591135977472065,
      "grad_norm": 3.4113714694976807,
      "learning_rate": 4.2047427482532295e-05,
      "loss": 1.029,
      "step": 150300
    },
    {
      "epoch": 1.5916652992520683,
      "grad_norm": 3.572340250015259,
      "learning_rate": 4.204478085962312e-05,
      "loss": 1.0294,
      "step": 150350
    },
    {
      "epoch": 1.5921946210320717,
      "grad_norm": 3.3232638835906982,
      "learning_rate": 4.204213423671396e-05,
      "loss": 1.0324,
      "step": 150400
    },
    {
      "epoch": 1.592723942812075,
      "grad_norm": 3.5086684226989746,
      "learning_rate": 4.2039487613804784e-05,
      "loss": 1.0363,
      "step": 150450
    },
    {
      "epoch": 1.5932532645920783,
      "grad_norm": 3.2099757194519043,
      "learning_rate": 4.203684099089562e-05,
      "loss": 1.0465,
      "step": 150500
    },
    {
      "epoch": 1.5932532645920783,
      "eval_loss": 0.8925315737724304,
      "eval_runtime": 46.5344,
      "eval_samples_per_second": 3608.73,
      "eval_steps_per_second": 451.107,
      "step": 150500
    },
    {
      "epoch": 1.5937825863720816,
      "grad_norm": 3.5802056789398193,
      "learning_rate": 4.203419436798645e-05,
      "loss": 1.0401,
      "step": 150550
    },
    {
      "epoch": 1.594311908152085,
      "grad_norm": 3.710202932357788,
      "learning_rate": 4.203154774507728e-05,
      "loss": 1.0513,
      "step": 150600
    },
    {
      "epoch": 1.594841229932088,
      "grad_norm": 3.316251516342163,
      "learning_rate": 4.2028901122168114e-05,
      "loss": 1.0347,
      "step": 150650
    },
    {
      "epoch": 1.5953705517120913,
      "grad_norm": 3.666156530380249,
      "learning_rate": 4.202625449925895e-05,
      "loss": 1.037,
      "step": 150700
    },
    {
      "epoch": 1.5958998734920946,
      "grad_norm": 3.6526029109954834,
      "learning_rate": 4.202360787634978e-05,
      "loss": 1.0414,
      "step": 150750
    },
    {
      "epoch": 1.5964291952720977,
      "grad_norm": 3.0050430297851562,
      "learning_rate": 4.202096125344061e-05,
      "loss": 1.0412,
      "step": 150800
    },
    {
      "epoch": 1.596958517052101,
      "grad_norm": 3.361973285675049,
      "learning_rate": 4.201831463053144e-05,
      "loss": 1.0359,
      "step": 150850
    },
    {
      "epoch": 1.5974878388321043,
      "grad_norm": 3.478910207748413,
      "learning_rate": 4.201566800762228e-05,
      "loss": 1.0326,
      "step": 150900
    },
    {
      "epoch": 1.5980171606121076,
      "grad_norm": 3.2234127521514893,
      "learning_rate": 4.201307431717129e-05,
      "loss": 1.0249,
      "step": 150950
    },
    {
      "epoch": 1.598546482392111,
      "grad_norm": 3.286203384399414,
      "learning_rate": 4.201042769426212e-05,
      "loss": 1.0324,
      "step": 151000
    },
    {
      "epoch": 1.598546482392111,
      "eval_loss": 0.8905555605888367,
      "eval_runtime": 46.6416,
      "eval_samples_per_second": 3600.433,
      "eval_steps_per_second": 450.07,
      "step": 151000
    },
    {
      "epoch": 1.5990758041721143,
      "grad_norm": 3.0118203163146973,
      "learning_rate": 4.2007781071352954e-05,
      "loss": 1.0161,
      "step": 151050
    },
    {
      "epoch": 1.5996051259521176,
      "grad_norm": 3.344024181365967,
      "learning_rate": 4.200513444844379e-05,
      "loss": 1.0474,
      "step": 151100
    },
    {
      "epoch": 1.6001344477321209,
      "grad_norm": 3.355501413345337,
      "learning_rate": 4.200248782553462e-05,
      "loss": 1.041,
      "step": 151150
    },
    {
      "epoch": 1.6006637695121242,
      "grad_norm": 3.193810224533081,
      "learning_rate": 4.199984120262545e-05,
      "loss": 1.0428,
      "step": 151200
    },
    {
      "epoch": 1.6011930912921275,
      "grad_norm": 3.973374843597412,
      "learning_rate": 4.199719457971628e-05,
      "loss": 1.0398,
      "step": 151250
    },
    {
      "epoch": 1.6017224130721308,
      "grad_norm": 3.3291516304016113,
      "learning_rate": 4.199454795680712e-05,
      "loss": 1.0326,
      "step": 151300
    },
    {
      "epoch": 1.6022517348521341,
      "grad_norm": 3.5764691829681396,
      "learning_rate": 4.199190133389795e-05,
      "loss": 1.03,
      "step": 151350
    },
    {
      "epoch": 1.6027810566321372,
      "grad_norm": 3.2800192832946777,
      "learning_rate": 4.198925471098878e-05,
      "loss": 1.0421,
      "step": 151400
    },
    {
      "epoch": 1.6033103784121405,
      "grad_norm": 3.474545478820801,
      "learning_rate": 4.198660808807961e-05,
      "loss": 1.0352,
      "step": 151450
    },
    {
      "epoch": 1.6038397001921438,
      "grad_norm": 3.3379249572753906,
      "learning_rate": 4.198396146517045e-05,
      "loss": 1.0431,
      "step": 151500
    },
    {
      "epoch": 1.6038397001921438,
      "eval_loss": 0.8908029794692993,
      "eval_runtime": 46.5473,
      "eval_samples_per_second": 3607.727,
      "eval_steps_per_second": 450.982,
      "step": 151500
    },
    {
      "epoch": 1.604369021972147,
      "grad_norm": 3.141343116760254,
      "learning_rate": 4.1981314842261274e-05,
      "loss": 1.0422,
      "step": 151550
    },
    {
      "epoch": 1.6048983437521502,
      "grad_norm": 3.2258615493774414,
      "learning_rate": 4.197866821935211e-05,
      "loss": 1.0236,
      "step": 151600
    },
    {
      "epoch": 1.6054276655321535,
      "grad_norm": 3.1541364192962646,
      "learning_rate": 4.1976021596442936e-05,
      "loss": 1.0259,
      "step": 151650
    },
    {
      "epoch": 1.6059569873121569,
      "grad_norm": 3.4280543327331543,
      "learning_rate": 4.1973374973533777e-05,
      "loss": 1.0427,
      "step": 151700
    },
    {
      "epoch": 1.6064863090921602,
      "grad_norm": 3.3454947471618652,
      "learning_rate": 4.1970728350624604e-05,
      "loss": 1.027,
      "step": 151750
    },
    {
      "epoch": 1.6070156308721635,
      "grad_norm": 3.184687614440918,
      "learning_rate": 4.196808172771544e-05,
      "loss": 1.0453,
      "step": 151800
    },
    {
      "epoch": 1.6075449526521668,
      "grad_norm": 3.4331419467926025,
      "learning_rate": 4.1965435104806265e-05,
      "loss": 1.0492,
      "step": 151850
    },
    {
      "epoch": 1.60807427443217,
      "grad_norm": 3.4422619342803955,
      "learning_rate": 4.1962788481897106e-05,
      "loss": 1.0459,
      "step": 151900
    },
    {
      "epoch": 1.6086035962121734,
      "grad_norm": 3.4306485652923584,
      "learning_rate": 4.1960141858987933e-05,
      "loss": 1.0498,
      "step": 151950
    },
    {
      "epoch": 1.6091329179921767,
      "grad_norm": 3.3732898235321045,
      "learning_rate": 4.195749523607877e-05,
      "loss": 1.0464,
      "step": 152000
    },
    {
      "epoch": 1.6091329179921767,
      "eval_loss": 0.8857633471488953,
      "eval_runtime": 46.5211,
      "eval_samples_per_second": 3609.76,
      "eval_steps_per_second": 451.236,
      "step": 152000
    },
    {
      "epoch": 1.60966223977218,
      "grad_norm": 3.4117283821105957,
      "learning_rate": 4.1954848613169595e-05,
      "loss": 1.0444,
      "step": 152050
    },
    {
      "epoch": 1.6101915615521833,
      "grad_norm": 3.6456894874572754,
      "learning_rate": 4.195220199026043e-05,
      "loss": 1.0526,
      "step": 152100
    },
    {
      "epoch": 1.6107208833321864,
      "grad_norm": 3.5329105854034424,
      "learning_rate": 4.194955536735126e-05,
      "loss": 1.0319,
      "step": 152150
    },
    {
      "epoch": 1.6112502051121897,
      "grad_norm": 3.4260215759277344,
      "learning_rate": 4.194690874444209e-05,
      "loss": 1.0454,
      "step": 152200
    },
    {
      "epoch": 1.611779526892193,
      "grad_norm": 3.932021141052246,
      "learning_rate": 4.1944262121532925e-05,
      "loss": 1.0738,
      "step": 152250
    },
    {
      "epoch": 1.6123088486721961,
      "grad_norm": 3.4197046756744385,
      "learning_rate": 4.194161549862376e-05,
      "loss": 1.0544,
      "step": 152300
    },
    {
      "epoch": 1.6128381704521995,
      "grad_norm": 3.561215877532959,
      "learning_rate": 4.193896887571459e-05,
      "loss": 1.0473,
      "step": 152350
    },
    {
      "epoch": 1.6133674922322028,
      "grad_norm": 3.2406258583068848,
      "learning_rate": 4.193632225280542e-05,
      "loss": 1.0371,
      "step": 152400
    },
    {
      "epoch": 1.613896814012206,
      "grad_norm": 3.255037784576416,
      "learning_rate": 4.1933675629896254e-05,
      "loss": 1.0451,
      "step": 152450
    },
    {
      "epoch": 1.6144261357922094,
      "grad_norm": 3.6218764781951904,
      "learning_rate": 4.193102900698709e-05,
      "loss": 1.0401,
      "step": 152500
    },
    {
      "epoch": 1.6144261357922094,
      "eval_loss": 0.8862296342849731,
      "eval_runtime": 46.6413,
      "eval_samples_per_second": 3600.46,
      "eval_steps_per_second": 450.074,
      "step": 152500
    },
    {
      "epoch": 1.6149554575722127,
      "grad_norm": 3.6705784797668457,
      "learning_rate": 4.1928382384077916e-05,
      "loss": 1.0425,
      "step": 152550
    },
    {
      "epoch": 1.615484779352216,
      "grad_norm": 3.357184886932373,
      "learning_rate": 4.192573576116875e-05,
      "loss": 1.0149,
      "step": 152600
    },
    {
      "epoch": 1.6160141011322193,
      "grad_norm": 3.567884683609009,
      "learning_rate": 4.192308913825958e-05,
      "loss": 1.0347,
      "step": 152650
    },
    {
      "epoch": 1.6165434229122226,
      "grad_norm": 3.502246379852295,
      "learning_rate": 4.192044251535042e-05,
      "loss": 1.0338,
      "step": 152700
    },
    {
      "epoch": 1.617072744692226,
      "grad_norm": 3.1620230674743652,
      "learning_rate": 4.1917795892441245e-05,
      "loss": 1.0287,
      "step": 152750
    },
    {
      "epoch": 1.6176020664722293,
      "grad_norm": 3.518986225128174,
      "learning_rate": 4.191514926953208e-05,
      "loss": 1.0115,
      "step": 152800
    },
    {
      "epoch": 1.6181313882522326,
      "grad_norm": 3.6247339248657227,
      "learning_rate": 4.191250264662291e-05,
      "loss": 1.0339,
      "step": 152850
    },
    {
      "epoch": 1.6186607100322357,
      "grad_norm": 4.118136882781982,
      "learning_rate": 4.190985602371375e-05,
      "loss": 1.0319,
      "step": 152900
    },
    {
      "epoch": 1.619190031812239,
      "grad_norm": 3.6599619388580322,
      "learning_rate": 4.190726233326276e-05,
      "loss": 1.0227,
      "step": 152950
    },
    {
      "epoch": 1.6197193535922423,
      "grad_norm": 3.212808847427368,
      "learning_rate": 4.190461571035359e-05,
      "loss": 1.0327,
      "step": 153000
    },
    {
      "epoch": 1.6197193535922423,
      "eval_loss": 0.8829458355903625,
      "eval_runtime": 46.6697,
      "eval_samples_per_second": 3598.27,
      "eval_steps_per_second": 449.8,
      "step": 153000
    },
    {
      "epoch": 1.6202486753722456,
      "grad_norm": 3.0624306201934814,
      "learning_rate": 4.1901969087444424e-05,
      "loss": 1.0261,
      "step": 153050
    },
    {
      "epoch": 1.6207779971522487,
      "grad_norm": 3.6091856956481934,
      "learning_rate": 4.189932246453526e-05,
      "loss": 1.0336,
      "step": 153100
    },
    {
      "epoch": 1.621307318932252,
      "grad_norm": 3.755528211593628,
      "learning_rate": 4.1896675841626085e-05,
      "loss": 1.0365,
      "step": 153150
    },
    {
      "epoch": 1.6218366407122553,
      "grad_norm": 3.691336154937744,
      "learning_rate": 4.189402921871692e-05,
      "loss": 1.0399,
      "step": 153200
    },
    {
      "epoch": 1.6223659624922586,
      "grad_norm": 3.372051477432251,
      "learning_rate": 4.1891382595807746e-05,
      "loss": 1.043,
      "step": 153250
    },
    {
      "epoch": 1.622895284272262,
      "grad_norm": 3.566197156906128,
      "learning_rate": 4.188873597289859e-05,
      "loss": 1.0338,
      "step": 153300
    },
    {
      "epoch": 1.6234246060522652,
      "grad_norm": 3.392160415649414,
      "learning_rate": 4.1886089349989415e-05,
      "loss": 1.0275,
      "step": 153350
    },
    {
      "epoch": 1.6239539278322686,
      "grad_norm": 3.6135146617889404,
      "learning_rate": 4.188344272708025e-05,
      "loss": 1.0166,
      "step": 153400
    },
    {
      "epoch": 1.6244832496122719,
      "grad_norm": 3.3139431476593018,
      "learning_rate": 4.1880796104171076e-05,
      "loss": 1.0302,
      "step": 153450
    },
    {
      "epoch": 1.6250125713922752,
      "grad_norm": 3.1395416259765625,
      "learning_rate": 4.187814948126191e-05,
      "loss": 1.0428,
      "step": 153500
    },
    {
      "epoch": 1.6250125713922752,
      "eval_loss": 0.8792523145675659,
      "eval_runtime": 46.6496,
      "eval_samples_per_second": 3599.819,
      "eval_steps_per_second": 449.993,
      "step": 153500
    },
    {
      "epoch": 1.6255418931722785,
      "grad_norm": 3.4882590770721436,
      "learning_rate": 4.1875502858352744e-05,
      "loss": 1.0372,
      "step": 153550
    },
    {
      "epoch": 1.6260712149522818,
      "grad_norm": 3.531644105911255,
      "learning_rate": 4.187285623544357e-05,
      "loss": 1.0395,
      "step": 153600
    },
    {
      "epoch": 1.6266005367322849,
      "grad_norm": 3.486311435699463,
      "learning_rate": 4.1870209612534406e-05,
      "loss": 1.0224,
      "step": 153650
    },
    {
      "epoch": 1.6271298585122882,
      "grad_norm": 3.5333003997802734,
      "learning_rate": 4.186756298962524e-05,
      "loss": 1.02,
      "step": 153700
    },
    {
      "epoch": 1.6276591802922915,
      "grad_norm": 3.442500591278076,
      "learning_rate": 4.1864916366716074e-05,
      "loss": 1.024,
      "step": 153750
    },
    {
      "epoch": 1.6281885020722948,
      "grad_norm": 3.3827884197235107,
      "learning_rate": 4.18622697438069e-05,
      "loss": 1.0213,
      "step": 153800
    },
    {
      "epoch": 1.628717823852298,
      "grad_norm": 3.2896976470947266,
      "learning_rate": 4.1859623120897735e-05,
      "loss": 1.0481,
      "step": 153850
    },
    {
      "epoch": 1.6292471456323012,
      "grad_norm": 3.31381893157959,
      "learning_rate": 4.185697649798857e-05,
      "loss": 1.0406,
      "step": 153900
    },
    {
      "epoch": 1.6297764674123045,
      "grad_norm": 3.268247365951538,
      "learning_rate": 4.1854329875079404e-05,
      "loss": 1.0323,
      "step": 153950
    },
    {
      "epoch": 1.6303057891923078,
      "grad_norm": 3.442920684814453,
      "learning_rate": 4.185168325217023e-05,
      "loss": 1.0275,
      "step": 154000
    },
    {
      "epoch": 1.6303057891923078,
      "eval_loss": 0.8807022571563721,
      "eval_runtime": 46.71,
      "eval_samples_per_second": 3595.159,
      "eval_steps_per_second": 449.411,
      "step": 154000
    },
    {
      "epoch": 1.6308351109723112,
      "grad_norm": 3.843768835067749,
      "learning_rate": 4.1849036629261065e-05,
      "loss": 1.0308,
      "step": 154050
    },
    {
      "epoch": 1.6313644327523145,
      "grad_norm": 3.3291802406311035,
      "learning_rate": 4.18463900063519e-05,
      "loss": 1.0301,
      "step": 154100
    },
    {
      "epoch": 1.6318937545323178,
      "grad_norm": 3.2098891735076904,
      "learning_rate": 4.1843743383442726e-05,
      "loss": 1.0246,
      "step": 154150
    },
    {
      "epoch": 1.632423076312321,
      "grad_norm": 3.4683618545532227,
      "learning_rate": 4.184109676053356e-05,
      "loss": 1.0449,
      "step": 154200
    },
    {
      "epoch": 1.6329523980923244,
      "grad_norm": 3.388049364089966,
      "learning_rate": 4.183845013762439e-05,
      "loss": 1.0415,
      "step": 154250
    },
    {
      "epoch": 1.6334817198723277,
      "grad_norm": 3.390059232711792,
      "learning_rate": 4.183580351471523e-05,
      "loss": 1.0369,
      "step": 154300
    },
    {
      "epoch": 1.634011041652331,
      "grad_norm": 3.6763343811035156,
      "learning_rate": 4.1833156891806056e-05,
      "loss": 1.0272,
      "step": 154350
    },
    {
      "epoch": 1.634540363432334,
      "grad_norm": 3.418991804122925,
      "learning_rate": 4.183051026889689e-05,
      "loss": 1.0397,
      "step": 154400
    },
    {
      "epoch": 1.6350696852123374,
      "grad_norm": 3.080448627471924,
      "learning_rate": 4.182786364598772e-05,
      "loss": 1.0288,
      "step": 154450
    },
    {
      "epoch": 1.6355990069923407,
      "grad_norm": 3.366024971008301,
      "learning_rate": 4.182521702307856e-05,
      "loss": 1.0162,
      "step": 154500
    },
    {
      "epoch": 1.6355990069923407,
      "eval_loss": 0.879859983921051,
      "eval_runtime": 46.8092,
      "eval_samples_per_second": 3587.54,
      "eval_steps_per_second": 448.459,
      "step": 154500
    },
    {
      "epoch": 1.636128328772344,
      "grad_norm": 3.3132410049438477,
      "learning_rate": 4.1822570400169386e-05,
      "loss": 1.0362,
      "step": 154550
    },
    {
      "epoch": 1.6366576505523471,
      "grad_norm": 3.4937095642089844,
      "learning_rate": 4.181992377726022e-05,
      "loss": 1.0083,
      "step": 154600
    },
    {
      "epoch": 1.6371869723323504,
      "grad_norm": 3.6417014598846436,
      "learning_rate": 4.181727715435105e-05,
      "loss": 1.0401,
      "step": 154650
    },
    {
      "epoch": 1.6377162941123538,
      "grad_norm": 3.445387840270996,
      "learning_rate": 4.181463053144188e-05,
      "loss": 1.027,
      "step": 154700
    },
    {
      "epoch": 1.638245615892357,
      "grad_norm": 3.51743221282959,
      "learning_rate": 4.1811983908532715e-05,
      "loss": 1.0325,
      "step": 154750
    },
    {
      "epoch": 1.6387749376723604,
      "grad_norm": 3.4113569259643555,
      "learning_rate": 4.180933728562354e-05,
      "loss": 1.036,
      "step": 154800
    },
    {
      "epoch": 1.6393042594523637,
      "grad_norm": 3.4179627895355225,
      "learning_rate": 4.180669066271438e-05,
      "loss": 1.0144,
      "step": 154850
    },
    {
      "epoch": 1.639833581232367,
      "grad_norm": 3.4185001850128174,
      "learning_rate": 4.180404403980521e-05,
      "loss": 1.0437,
      "step": 154900
    },
    {
      "epoch": 1.6403629030123703,
      "grad_norm": 3.320441961288452,
      "learning_rate": 4.1801397416896045e-05,
      "loss": 1.03,
      "step": 154950
    },
    {
      "epoch": 1.6408922247923736,
      "grad_norm": 3.5755202770233154,
      "learning_rate": 4.179880372644506e-05,
      "loss": 1.0297,
      "step": 155000
    },
    {
      "epoch": 1.6408922247923736,
      "eval_loss": 0.8778923749923706,
      "eval_runtime": 46.5323,
      "eval_samples_per_second": 3608.894,
      "eval_steps_per_second": 451.128,
      "step": 155000
    },
    {
      "epoch": 1.641421546572377,
      "grad_norm": 3.343179702758789,
      "learning_rate": 4.179615710353589e-05,
      "loss": 1.0379,
      "step": 155050
    },
    {
      "epoch": 1.6419508683523802,
      "grad_norm": 3.5486574172973633,
      "learning_rate": 4.179351048062672e-05,
      "loss": 1.0338,
      "step": 155100
    },
    {
      "epoch": 1.6424801901323833,
      "grad_norm": 3.4134442806243896,
      "learning_rate": 4.1790863857717555e-05,
      "loss": 1.0347,
      "step": 155150
    },
    {
      "epoch": 1.6430095119123866,
      "grad_norm": 3.5008175373077393,
      "learning_rate": 4.178821723480838e-05,
      "loss": 1.0425,
      "step": 155200
    },
    {
      "epoch": 1.64353883369239,
      "grad_norm": 3.5431034564971924,
      "learning_rate": 4.1785570611899217e-05,
      "loss": 1.0329,
      "step": 155250
    },
    {
      "epoch": 1.6440681554723933,
      "grad_norm": 3.23620343208313,
      "learning_rate": 4.178292398899005e-05,
      "loss": 1.0279,
      "step": 155300
    },
    {
      "epoch": 1.6445974772523964,
      "grad_norm": 3.48524808883667,
      "learning_rate": 4.1780277366080885e-05,
      "loss": 1.036,
      "step": 155350
    },
    {
      "epoch": 1.6451267990323997,
      "grad_norm": 3.579289674758911,
      "learning_rate": 4.177763074317171e-05,
      "loss": 1.0261,
      "step": 155400
    },
    {
      "epoch": 1.645656120812403,
      "grad_norm": 3.5213067531585693,
      "learning_rate": 4.1774984120262546e-05,
      "loss": 1.0627,
      "step": 155450
    },
    {
      "epoch": 1.6461854425924063,
      "grad_norm": 2.7244772911071777,
      "learning_rate": 4.177233749735338e-05,
      "loss": 1.0189,
      "step": 155500
    },
    {
      "epoch": 1.6461854425924063,
      "eval_loss": 0.876804769039154,
      "eval_runtime": 46.8846,
      "eval_samples_per_second": 3581.776,
      "eval_steps_per_second": 447.738,
      "step": 155500
    },
    {
      "epoch": 1.6467147643724096,
      "grad_norm": 3.5094964504241943,
      "learning_rate": 4.1769690874444214e-05,
      "loss": 1.03,
      "step": 155550
    },
    {
      "epoch": 1.647244086152413,
      "grad_norm": 3.312727928161621,
      "learning_rate": 4.176704425153504e-05,
      "loss": 1.0365,
      "step": 155600
    },
    {
      "epoch": 1.6477734079324162,
      "grad_norm": 3.7282958030700684,
      "learning_rate": 4.1764397628625876e-05,
      "loss": 1.0229,
      "step": 155650
    },
    {
      "epoch": 1.6483027297124195,
      "grad_norm": 3.8119871616363525,
      "learning_rate": 4.176175100571671e-05,
      "loss": 1.0447,
      "step": 155700
    },
    {
      "epoch": 1.6488320514924228,
      "grad_norm": 3.346175193786621,
      "learning_rate": 4.175910438280754e-05,
      "loss": 1.0263,
      "step": 155750
    },
    {
      "epoch": 1.6493613732724262,
      "grad_norm": 3.581774950027466,
      "learning_rate": 4.175645775989837e-05,
      "loss": 1.0331,
      "step": 155800
    },
    {
      "epoch": 1.6498906950524295,
      "grad_norm": 3.532625436782837,
      "learning_rate": 4.17538111369892e-05,
      "loss": 1.0387,
      "step": 155850
    },
    {
      "epoch": 1.6504200168324326,
      "grad_norm": 3.050804615020752,
      "learning_rate": 4.175116451408004e-05,
      "loss": 1.0366,
      "step": 155900
    },
    {
      "epoch": 1.6509493386124359,
      "grad_norm": 3.3582510948181152,
      "learning_rate": 4.174851789117087e-05,
      "loss": 1.034,
      "step": 155950
    },
    {
      "epoch": 1.6514786603924392,
      "grad_norm": 3.3204565048217773,
      "learning_rate": 4.17458712682617e-05,
      "loss": 1.024,
      "step": 156000
    },
    {
      "epoch": 1.6514786603924392,
      "eval_loss": 0.8736291527748108,
      "eval_runtime": 46.8797,
      "eval_samples_per_second": 3582.144,
      "eval_steps_per_second": 447.784,
      "step": 156000
    },
    {
      "epoch": 1.6520079821724425,
      "grad_norm": 3.2521727085113525,
      "learning_rate": 4.174322464535253e-05,
      "loss": 1.034,
      "step": 156050
    },
    {
      "epoch": 1.6525373039524456,
      "grad_norm": 3.4015793800354004,
      "learning_rate": 4.174057802244337e-05,
      "loss": 1.0222,
      "step": 156100
    },
    {
      "epoch": 1.653066625732449,
      "grad_norm": 3.4424753189086914,
      "learning_rate": 4.1737931399534196e-05,
      "loss": 1.0159,
      "step": 156150
    },
    {
      "epoch": 1.6535959475124522,
      "grad_norm": 3.439979314804077,
      "learning_rate": 4.173528477662503e-05,
      "loss": 1.0293,
      "step": 156200
    },
    {
      "epoch": 1.6541252692924555,
      "grad_norm": 3.544062614440918,
      "learning_rate": 4.173263815371586e-05,
      "loss": 1.0293,
      "step": 156250
    },
    {
      "epoch": 1.6546545910724588,
      "grad_norm": 3.6295924186706543,
      "learning_rate": 4.172999153080669e-05,
      "loss": 1.0216,
      "step": 156300
    },
    {
      "epoch": 1.6551839128524621,
      "grad_norm": 3.4748075008392334,
      "learning_rate": 4.1727344907897526e-05,
      "loss": 1.023,
      "step": 156350
    },
    {
      "epoch": 1.6557132346324654,
      "grad_norm": 3.493922710418701,
      "learning_rate": 4.1724698284988353e-05,
      "loss": 1.0194,
      "step": 156400
    },
    {
      "epoch": 1.6562425564124688,
      "grad_norm": 3.3025243282318115,
      "learning_rate": 4.172205166207919e-05,
      "loss": 1.0101,
      "step": 156450
    },
    {
      "epoch": 1.656771878192472,
      "grad_norm": 3.3956069946289062,
      "learning_rate": 4.171940503917002e-05,
      "loss": 1.0338,
      "step": 156500
    },
    {
      "epoch": 1.656771878192472,
      "eval_loss": 0.8721129894256592,
      "eval_runtime": 46.558,
      "eval_samples_per_second": 3606.902,
      "eval_steps_per_second": 450.879,
      "step": 156500
    },
    {
      "epoch": 1.6573011999724754,
      "grad_norm": 3.296623706817627,
      "learning_rate": 4.1716758416260856e-05,
      "loss": 1.0251,
      "step": 156550
    },
    {
      "epoch": 1.6578305217524787,
      "grad_norm": 3.2157952785491943,
      "learning_rate": 4.171411179335168e-05,
      "loss": 1.0233,
      "step": 156600
    },
    {
      "epoch": 1.6583598435324818,
      "grad_norm": 3.14035701751709,
      "learning_rate": 4.171146517044252e-05,
      "loss": 1.0364,
      "step": 156650
    },
    {
      "epoch": 1.658889165312485,
      "grad_norm": 3.6026906967163086,
      "learning_rate": 4.170881854753335e-05,
      "loss": 1.0307,
      "step": 156700
    },
    {
      "epoch": 1.6594184870924884,
      "grad_norm": 3.255521297454834,
      "learning_rate": 4.1706171924624185e-05,
      "loss": 1.012,
      "step": 156750
    },
    {
      "epoch": 1.6599478088724917,
      "grad_norm": 3.7855398654937744,
      "learning_rate": 4.170352530171501e-05,
      "loss": 1.0363,
      "step": 156800
    },
    {
      "epoch": 1.6604771306524948,
      "grad_norm": 3.1366262435913086,
      "learning_rate": 4.170087867880585e-05,
      "loss": 1.0138,
      "step": 156850
    },
    {
      "epoch": 1.6610064524324981,
      "grad_norm": 3.567580461502075,
      "learning_rate": 4.169823205589668e-05,
      "loss": 1.0225,
      "step": 156900
    },
    {
      "epoch": 1.6615357742125014,
      "grad_norm": 3.8670151233673096,
      "learning_rate": 4.169558543298751e-05,
      "loss": 1.0453,
      "step": 156950
    },
    {
      "epoch": 1.6620650959925047,
      "grad_norm": 3.0802407264709473,
      "learning_rate": 4.169299174253652e-05,
      "loss": 1.037,
      "step": 157000
    },
    {
      "epoch": 1.6620650959925047,
      "eval_loss": 0.8685862421989441,
      "eval_runtime": 46.6019,
      "eval_samples_per_second": 3603.502,
      "eval_steps_per_second": 450.454,
      "step": 157000
    },
    {
      "epoch": 1.662594417772508,
      "grad_norm": 3.259291648864746,
      "learning_rate": 4.169034511962736e-05,
      "loss": 1.027,
      "step": 157050
    },
    {
      "epoch": 1.6631237395525114,
      "grad_norm": 3.458738327026367,
      "learning_rate": 4.168769849671819e-05,
      "loss": 1.0162,
      "step": 157100
    },
    {
      "epoch": 1.6636530613325147,
      "grad_norm": 3.4617955684661865,
      "learning_rate": 4.1685051873809025e-05,
      "loss": 1.0336,
      "step": 157150
    },
    {
      "epoch": 1.664182383112518,
      "grad_norm": 3.7011194229125977,
      "learning_rate": 4.168240525089985e-05,
      "loss": 1.0216,
      "step": 157200
    },
    {
      "epoch": 1.6647117048925213,
      "grad_norm": 3.231498956680298,
      "learning_rate": 4.1679758627990687e-05,
      "loss": 1.0327,
      "step": 157250
    },
    {
      "epoch": 1.6652410266725246,
      "grad_norm": 3.3537018299102783,
      "learning_rate": 4.167711200508152e-05,
      "loss": 1.022,
      "step": 157300
    },
    {
      "epoch": 1.665770348452528,
      "grad_norm": 3.3084182739257812,
      "learning_rate": 4.167446538217235e-05,
      "loss": 1.0196,
      "step": 157350
    },
    {
      "epoch": 1.666299670232531,
      "grad_norm": 2.964195728302002,
      "learning_rate": 4.167181875926318e-05,
      "loss": 1.0232,
      "step": 157400
    },
    {
      "epoch": 1.6668289920125343,
      "grad_norm": 3.3559248447418213,
      "learning_rate": 4.166917213635401e-05,
      "loss": 1.0309,
      "step": 157450
    },
    {
      "epoch": 1.6673583137925376,
      "grad_norm": 3.6508848667144775,
      "learning_rate": 4.166652551344485e-05,
      "loss": 1.0146,
      "step": 157500
    },
    {
      "epoch": 1.6673583137925376,
      "eval_loss": 0.8671858906745911,
      "eval_runtime": 46.6124,
      "eval_samples_per_second": 3602.687,
      "eval_steps_per_second": 450.352,
      "step": 157500
    },
    {
      "epoch": 1.667887635572541,
      "grad_norm": 3.925942897796631,
      "learning_rate": 4.166387889053568e-05,
      "loss": 1.0148,
      "step": 157550
    },
    {
      "epoch": 1.668416957352544,
      "grad_norm": 3.1780099868774414,
      "learning_rate": 4.166123226762651e-05,
      "loss": 1.0269,
      "step": 157600
    },
    {
      "epoch": 1.6689462791325473,
      "grad_norm": 3.3359358310699463,
      "learning_rate": 4.165858564471734e-05,
      "loss": 1.0145,
      "step": 157650
    },
    {
      "epoch": 1.6694756009125507,
      "grad_norm": 3.5886948108673096,
      "learning_rate": 4.165593902180818e-05,
      "loss": 1.0122,
      "step": 157700
    },
    {
      "epoch": 1.670004922692554,
      "grad_norm": 3.5273451805114746,
      "learning_rate": 4.165329239889901e-05,
      "loss": 1.0202,
      "step": 157750
    },
    {
      "epoch": 1.6705342444725573,
      "grad_norm": 3.691309690475464,
      "learning_rate": 4.165064577598984e-05,
      "loss": 1.0305,
      "step": 157800
    },
    {
      "epoch": 1.6710635662525606,
      "grad_norm": 3.3722994327545166,
      "learning_rate": 4.164799915308067e-05,
      "loss": 1.0264,
      "step": 157850
    },
    {
      "epoch": 1.671592888032564,
      "grad_norm": 3.75663161277771,
      "learning_rate": 4.16453525301715e-05,
      "loss": 1.0076,
      "step": 157900
    },
    {
      "epoch": 1.6721222098125672,
      "grad_norm": 3.702547788619995,
      "learning_rate": 4.164270590726234e-05,
      "loss": 1.0251,
      "step": 157950
    },
    {
      "epoch": 1.6726515315925705,
      "grad_norm": 3.322551727294922,
      "learning_rate": 4.1640059284353164e-05,
      "loss": 1.026,
      "step": 158000
    },
    {
      "epoch": 1.6726515315925705,
      "eval_loss": 0.865770161151886,
      "eval_runtime": 46.6193,
      "eval_samples_per_second": 3602.157,
      "eval_steps_per_second": 450.286,
      "step": 158000
    },
    {
      "epoch": 1.6731808533725738,
      "grad_norm": 3.8073859214782715,
      "learning_rate": 4.1637412661444e-05,
      "loss": 1.0164,
      "step": 158050
    },
    {
      "epoch": 1.6737101751525771,
      "grad_norm": 3.259638786315918,
      "learning_rate": 4.163476603853483e-05,
      "loss": 1.041,
      "step": 158100
    },
    {
      "epoch": 1.6742394969325805,
      "grad_norm": 3.498413324356079,
      "learning_rate": 4.1632119415625667e-05,
      "loss": 1.0185,
      "step": 158150
    },
    {
      "epoch": 1.6747688187125835,
      "grad_norm": 3.163693904876709,
      "learning_rate": 4.1629472792716494e-05,
      "loss": 1.0182,
      "step": 158200
    },
    {
      "epoch": 1.6752981404925869,
      "grad_norm": 3.3814902305603027,
      "learning_rate": 4.162682616980733e-05,
      "loss": 1.0259,
      "step": 158250
    },
    {
      "epoch": 1.6758274622725902,
      "grad_norm": 3.2089550495147705,
      "learning_rate": 4.162417954689816e-05,
      "loss": 1.0369,
      "step": 158300
    },
    {
      "epoch": 1.6763567840525933,
      "grad_norm": 3.2840659618377686,
      "learning_rate": 4.1621532923988996e-05,
      "loss": 1.0103,
      "step": 158350
    },
    {
      "epoch": 1.6768861058325966,
      "grad_norm": 3.2469420433044434,
      "learning_rate": 4.1618886301079823e-05,
      "loss": 1.0228,
      "step": 158400
    },
    {
      "epoch": 1.6774154276125999,
      "grad_norm": 3.5131447315216064,
      "learning_rate": 4.161623967817066e-05,
      "loss": 1.0396,
      "step": 158450
    },
    {
      "epoch": 1.6779447493926032,
      "grad_norm": 3.6926143169403076,
      "learning_rate": 4.161359305526149e-05,
      "loss": 1.0409,
      "step": 158500
    },
    {
      "epoch": 1.6779447493926032,
      "eval_loss": 0.8670281171798706,
      "eval_runtime": 46.5421,
      "eval_samples_per_second": 3608.132,
      "eval_steps_per_second": 451.033,
      "step": 158500
    },
    {
      "epoch": 1.6784740711726065,
      "grad_norm": 3.3083362579345703,
      "learning_rate": 4.161094643235232e-05,
      "loss": 1.026,
      "step": 158550
    },
    {
      "epoch": 1.6790033929526098,
      "grad_norm": 3.274277925491333,
      "learning_rate": 4.160829980944315e-05,
      "loss": 1.0399,
      "step": 158600
    },
    {
      "epoch": 1.6795327147326131,
      "grad_norm": 3.0859689712524414,
      "learning_rate": 4.160565318653398e-05,
      "loss": 0.9961,
      "step": 158650
    },
    {
      "epoch": 1.6800620365126164,
      "grad_norm": 3.436239004135132,
      "learning_rate": 4.160300656362482e-05,
      "loss": 1.0161,
      "step": 158700
    },
    {
      "epoch": 1.6805913582926197,
      "grad_norm": 3.4968011379241943,
      "learning_rate": 4.160035994071565e-05,
      "loss": 1.0121,
      "step": 158750
    },
    {
      "epoch": 1.681120680072623,
      "grad_norm": 3.2220664024353027,
      "learning_rate": 4.159771331780648e-05,
      "loss": 1.0218,
      "step": 158800
    },
    {
      "epoch": 1.6816500018526264,
      "grad_norm": 3.395116090774536,
      "learning_rate": 4.159506669489731e-05,
      "loss": 1.0,
      "step": 158850
    },
    {
      "epoch": 1.6821793236326297,
      "grad_norm": 3.3832075595855713,
      "learning_rate": 4.1592420071988144e-05,
      "loss": 1.0258,
      "step": 158900
    },
    {
      "epoch": 1.6827086454126328,
      "grad_norm": 3.371403694152832,
      "learning_rate": 4.158977344907898e-05,
      "loss": 1.0205,
      "step": 158950
    },
    {
      "epoch": 1.683237967192636,
      "grad_norm": 3.334500312805176,
      "learning_rate": 4.158717975862799e-05,
      "loss": 1.0148,
      "step": 159000
    },
    {
      "epoch": 1.683237967192636,
      "eval_loss": 0.8640469908714294,
      "eval_runtime": 46.6252,
      "eval_samples_per_second": 3601.703,
      "eval_steps_per_second": 450.229,
      "step": 159000
    },
    {
      "epoch": 1.6837672889726394,
      "grad_norm": 3.3173117637634277,
      "learning_rate": 4.158453313571882e-05,
      "loss": 1.0226,
      "step": 159050
    },
    {
      "epoch": 1.6842966107526425,
      "grad_norm": 3.519930124282837,
      "learning_rate": 4.158188651280966e-05,
      "loss": 1.0076,
      "step": 159100
    },
    {
      "epoch": 1.6848259325326458,
      "grad_norm": 3.6175124645233154,
      "learning_rate": 4.157923988990049e-05,
      "loss": 1.0071,
      "step": 159150
    },
    {
      "epoch": 1.685355254312649,
      "grad_norm": 3.529522657394409,
      "learning_rate": 4.157659326699132e-05,
      "loss": 1.0238,
      "step": 159200
    },
    {
      "epoch": 1.6858845760926524,
      "grad_norm": 3.304516077041626,
      "learning_rate": 4.157394664408215e-05,
      "loss": 1.0201,
      "step": 159250
    },
    {
      "epoch": 1.6864138978726557,
      "grad_norm": 3.3873190879821777,
      "learning_rate": 4.157130002117299e-05,
      "loss": 1.0133,
      "step": 159300
    },
    {
      "epoch": 1.686943219652659,
      "grad_norm": 3.4507412910461426,
      "learning_rate": 4.156865339826382e-05,
      "loss": 1.0199,
      "step": 159350
    },
    {
      "epoch": 1.6874725414326623,
      "grad_norm": 3.022085666656494,
      "learning_rate": 4.156600677535465e-05,
      "loss": 1.0182,
      "step": 159400
    },
    {
      "epoch": 1.6880018632126657,
      "grad_norm": 3.481416702270508,
      "learning_rate": 4.156336015244548e-05,
      "loss": 1.0105,
      "step": 159450
    },
    {
      "epoch": 1.688531184992669,
      "grad_norm": 3.6058473587036133,
      "learning_rate": 4.1560713529536314e-05,
      "loss": 1.036,
      "step": 159500
    },
    {
      "epoch": 1.688531184992669,
      "eval_loss": 0.863548994064331,
      "eval_runtime": 46.6343,
      "eval_samples_per_second": 3600.998,
      "eval_steps_per_second": 450.141,
      "step": 159500
    },
    {
      "epoch": 1.6890605067726723,
      "grad_norm": 3.1753344535827637,
      "learning_rate": 4.155806690662715e-05,
      "loss": 1.0133,
      "step": 159550
    },
    {
      "epoch": 1.6895898285526756,
      "grad_norm": 3.8674325942993164,
      "learning_rate": 4.1555420283717975e-05,
      "loss": 1.018,
      "step": 159600
    },
    {
      "epoch": 1.690119150332679,
      "grad_norm": 3.2643885612487793,
      "learning_rate": 4.155277366080881e-05,
      "loss": 1.0065,
      "step": 159650
    },
    {
      "epoch": 1.690648472112682,
      "grad_norm": 3.4401659965515137,
      "learning_rate": 4.155012703789964e-05,
      "loss": 1.0175,
      "step": 159700
    },
    {
      "epoch": 1.6911777938926853,
      "grad_norm": 3.622816324234009,
      "learning_rate": 4.154748041499048e-05,
      "loss": 1.0232,
      "step": 159750
    },
    {
      "epoch": 1.6917071156726886,
      "grad_norm": 3.4279963970184326,
      "learning_rate": 4.1544833792081305e-05,
      "loss": 1.0058,
      "step": 159800
    },
    {
      "epoch": 1.6922364374526917,
      "grad_norm": 3.4652297496795654,
      "learning_rate": 4.154218716917214e-05,
      "loss": 1.0214,
      "step": 159850
    },
    {
      "epoch": 1.692765759232695,
      "grad_norm": 3.5507349967956543,
      "learning_rate": 4.153954054626297e-05,
      "loss": 1.0277,
      "step": 159900
    },
    {
      "epoch": 1.6932950810126983,
      "grad_norm": 3.4034860134124756,
      "learning_rate": 4.15368939233538e-05,
      "loss": 1.0145,
      "step": 159950
    },
    {
      "epoch": 1.6938244027927016,
      "grad_norm": 3.487443208694458,
      "learning_rate": 4.1534247300444634e-05,
      "loss": 1.0124,
      "step": 160000
    },
    {
      "epoch": 1.6938244027927016,
      "eval_loss": 0.8588273525238037,
      "eval_runtime": 46.5481,
      "eval_samples_per_second": 3607.668,
      "eval_steps_per_second": 450.975,
      "step": 160000
    },
    {
      "epoch": 1.694353724572705,
      "grad_norm": 3.7293179035186768,
      "learning_rate": 4.153160067753546e-05,
      "loss": 1.0204,
      "step": 160050
    },
    {
      "epoch": 1.6948830463527083,
      "grad_norm": 3.6050543785095215,
      "learning_rate": 4.15289540546263e-05,
      "loss": 1.0181,
      "step": 160100
    },
    {
      "epoch": 1.6954123681327116,
      "grad_norm": 3.6463518142700195,
      "learning_rate": 4.152630743171713e-05,
      "loss": 1.0236,
      "step": 160150
    },
    {
      "epoch": 1.6959416899127149,
      "grad_norm": 3.67999267578125,
      "learning_rate": 4.1523660808807964e-05,
      "loss": 1.0126,
      "step": 160200
    },
    {
      "epoch": 1.6964710116927182,
      "grad_norm": 3.3981945514678955,
      "learning_rate": 4.152101418589879e-05,
      "loss": 1.0104,
      "step": 160250
    },
    {
      "epoch": 1.6970003334727215,
      "grad_norm": 3.335764169692993,
      "learning_rate": 4.151836756298963e-05,
      "loss": 1.0108,
      "step": 160300
    },
    {
      "epoch": 1.6975296552527248,
      "grad_norm": 3.824514150619507,
      "learning_rate": 4.151572094008046e-05,
      "loss": 1.0194,
      "step": 160350
    },
    {
      "epoch": 1.6980589770327281,
      "grad_norm": 3.564406394958496,
      "learning_rate": 4.1513074317171294e-05,
      "loss": 1.0252,
      "step": 160400
    },
    {
      "epoch": 1.6985882988127312,
      "grad_norm": 3.512340545654297,
      "learning_rate": 4.151042769426212e-05,
      "loss": 1.028,
      "step": 160450
    },
    {
      "epoch": 1.6991176205927345,
      "grad_norm": 3.331869602203369,
      "learning_rate": 4.1507781071352955e-05,
      "loss": 1.0297,
      "step": 160500
    },
    {
      "epoch": 1.6991176205927345,
      "eval_loss": 0.8597398996353149,
      "eval_runtime": 46.6293,
      "eval_samples_per_second": 3601.381,
      "eval_steps_per_second": 450.189,
      "step": 160500
    },
    {
      "epoch": 1.6996469423727378,
      "grad_norm": 3.7180380821228027,
      "learning_rate": 4.150513444844379e-05,
      "loss": 1.0132,
      "step": 160550
    },
    {
      "epoch": 1.7001762641527411,
      "grad_norm": 3.864168643951416,
      "learning_rate": 4.1502487825534616e-05,
      "loss": 1.0162,
      "step": 160600
    },
    {
      "epoch": 1.7007055859327442,
      "grad_norm": 3.346644163131714,
      "learning_rate": 4.149984120262545e-05,
      "loss": 1.019,
      "step": 160650
    },
    {
      "epoch": 1.7012349077127475,
      "grad_norm": 3.429516315460205,
      "learning_rate": 4.1497194579716285e-05,
      "loss": 1.0228,
      "step": 160700
    },
    {
      "epoch": 1.7017642294927509,
      "grad_norm": 3.8616795539855957,
      "learning_rate": 4.149454795680712e-05,
      "loss": 1.0184,
      "step": 160750
    },
    {
      "epoch": 1.7022935512727542,
      "grad_norm": 3.4610486030578613,
      "learning_rate": 4.1491901333897946e-05,
      "loss": 1.0067,
      "step": 160800
    },
    {
      "epoch": 1.7028228730527575,
      "grad_norm": 3.433013677597046,
      "learning_rate": 4.148925471098878e-05,
      "loss": 1.0262,
      "step": 160850
    },
    {
      "epoch": 1.7033521948327608,
      "grad_norm": 3.5836009979248047,
      "learning_rate": 4.1486608088079614e-05,
      "loss": 1.0183,
      "step": 160900
    },
    {
      "epoch": 1.703881516612764,
      "grad_norm": 3.594597816467285,
      "learning_rate": 4.148396146517045e-05,
      "loss": 1.0237,
      "step": 160950
    },
    {
      "epoch": 1.7044108383927674,
      "grad_norm": 3.328233242034912,
      "learning_rate": 4.1481314842261276e-05,
      "loss": 1.0092,
      "step": 161000
    },
    {
      "epoch": 1.7044108383927674,
      "eval_loss": 0.8611858487129211,
      "eval_runtime": 46.607,
      "eval_samples_per_second": 3603.107,
      "eval_steps_per_second": 450.404,
      "step": 161000
    },
    {
      "epoch": 1.7049401601727707,
      "grad_norm": 3.0916662216186523,
      "learning_rate": 4.147872115181029e-05,
      "loss": 1.0033,
      "step": 161050
    },
    {
      "epoch": 1.705469481952774,
      "grad_norm": 3.7520415782928467,
      "learning_rate": 4.1476074528901124e-05,
      "loss": 1.0127,
      "step": 161100
    },
    {
      "epoch": 1.7059988037327773,
      "grad_norm": 3.306173324584961,
      "learning_rate": 4.147342790599196e-05,
      "loss": 1.0241,
      "step": 161150
    },
    {
      "epoch": 1.7065281255127804,
      "grad_norm": 3.3268909454345703,
      "learning_rate": 4.1470781283082786e-05,
      "loss": 1.0151,
      "step": 161200
    },
    {
      "epoch": 1.7070574472927837,
      "grad_norm": 3.8318092823028564,
      "learning_rate": 4.146813466017362e-05,
      "loss": 1.009,
      "step": 161250
    },
    {
      "epoch": 1.707586769072787,
      "grad_norm": 3.441771984100342,
      "learning_rate": 4.1465488037264454e-05,
      "loss": 1.0172,
      "step": 161300
    },
    {
      "epoch": 1.7081160908527904,
      "grad_norm": 3.4983768463134766,
      "learning_rate": 4.146284141435529e-05,
      "loss": 1.0078,
      "step": 161350
    },
    {
      "epoch": 1.7086454126327935,
      "grad_norm": 3.4831223487854004,
      "learning_rate": 4.1460194791446115e-05,
      "loss": 1.0274,
      "step": 161400
    },
    {
      "epoch": 1.7091747344127968,
      "grad_norm": 3.729564666748047,
      "learning_rate": 4.145754816853695e-05,
      "loss": 1.0095,
      "step": 161450
    },
    {
      "epoch": 1.7097040561928,
      "grad_norm": 3.3448643684387207,
      "learning_rate": 4.1454901545627784e-05,
      "loss": 1.0219,
      "step": 161500
    },
    {
      "epoch": 1.7097040561928,
      "eval_loss": 0.8585127592086792,
      "eval_runtime": 46.546,
      "eval_samples_per_second": 3607.832,
      "eval_steps_per_second": 450.995,
      "step": 161500
    },
    {
      "epoch": 1.7102333779728034,
      "grad_norm": 3.9841389656066895,
      "learning_rate": 4.145225492271861e-05,
      "loss": 1.0136,
      "step": 161550
    },
    {
      "epoch": 1.7107626997528067,
      "grad_norm": 3.4881491661071777,
      "learning_rate": 4.1449608299809445e-05,
      "loss": 1.0057,
      "step": 161600
    },
    {
      "epoch": 1.71129202153281,
      "grad_norm": 3.3382043838500977,
      "learning_rate": 4.144696167690027e-05,
      "loss": 1.0097,
      "step": 161650
    },
    {
      "epoch": 1.7118213433128133,
      "grad_norm": 3.2992358207702637,
      "learning_rate": 4.144431505399111e-05,
      "loss": 1.005,
      "step": 161700
    },
    {
      "epoch": 1.7123506650928166,
      "grad_norm": 3.452402353286743,
      "learning_rate": 4.144166843108194e-05,
      "loss": 1.0256,
      "step": 161750
    },
    {
      "epoch": 1.71287998687282,
      "grad_norm": 3.4369587898254395,
      "learning_rate": 4.1439021808172775e-05,
      "loss": 1.0282,
      "step": 161800
    },
    {
      "epoch": 1.7134093086528233,
      "grad_norm": 3.4226129055023193,
      "learning_rate": 4.14363751852636e-05,
      "loss": 0.9917,
      "step": 161850
    },
    {
      "epoch": 1.7139386304328266,
      "grad_norm": 3.5626823902130127,
      "learning_rate": 4.143372856235444e-05,
      "loss": 1.003,
      "step": 161900
    },
    {
      "epoch": 1.7144679522128297,
      "grad_norm": 3.3025898933410645,
      "learning_rate": 4.143108193944527e-05,
      "loss": 1.0283,
      "step": 161950
    },
    {
      "epoch": 1.714997273992833,
      "grad_norm": 3.499213695526123,
      "learning_rate": 4.1428435316536104e-05,
      "loss": 1.0009,
      "step": 162000
    },
    {
      "epoch": 1.714997273992833,
      "eval_loss": 0.856135368347168,
      "eval_runtime": 46.5165,
      "eval_samples_per_second": 3610.119,
      "eval_steps_per_second": 451.281,
      "step": 162000
    },
    {
      "epoch": 1.7155265957728363,
      "grad_norm": 3.520397186279297,
      "learning_rate": 4.142578869362693e-05,
      "loss": 1.0151,
      "step": 162050
    },
    {
      "epoch": 1.7160559175528396,
      "grad_norm": 3.6604127883911133,
      "learning_rate": 4.1423142070717766e-05,
      "loss": 0.9978,
      "step": 162100
    },
    {
      "epoch": 1.7165852393328427,
      "grad_norm": 3.644336700439453,
      "learning_rate": 4.14204954478086e-05,
      "loss": 1.009,
      "step": 162150
    },
    {
      "epoch": 1.717114561112846,
      "grad_norm": 3.454728603363037,
      "learning_rate": 4.141784882489943e-05,
      "loss": 1.0165,
      "step": 162200
    },
    {
      "epoch": 1.7176438828928493,
      "grad_norm": 3.4925358295440674,
      "learning_rate": 4.141520220199026e-05,
      "loss": 1.024,
      "step": 162250
    },
    {
      "epoch": 1.7181732046728526,
      "grad_norm": 3.671231508255005,
      "learning_rate": 4.1412555579081095e-05,
      "loss": 1.0244,
      "step": 162300
    },
    {
      "epoch": 1.718702526452856,
      "grad_norm": 3.9250400066375732,
      "learning_rate": 4.140990895617193e-05,
      "loss": 1.0224,
      "step": 162350
    },
    {
      "epoch": 1.7192318482328592,
      "grad_norm": 3.670686721801758,
      "learning_rate": 4.140726233326276e-05,
      "loss": 1.0225,
      "step": 162400
    },
    {
      "epoch": 1.7197611700128626,
      "grad_norm": 3.6204745769500732,
      "learning_rate": 4.140461571035359e-05,
      "loss": 1.0435,
      "step": 162450
    },
    {
      "epoch": 1.7202904917928659,
      "grad_norm": 3.406066656112671,
      "learning_rate": 4.1401969087444425e-05,
      "loss": 1.0229,
      "step": 162500
    },
    {
      "epoch": 1.7202904917928659,
      "eval_loss": 0.8575906753540039,
      "eval_runtime": 46.5094,
      "eval_samples_per_second": 3610.665,
      "eval_steps_per_second": 451.349,
      "step": 162500
    },
    {
      "epoch": 1.7208198135728692,
      "grad_norm": 3.349693536758423,
      "learning_rate": 4.139932246453526e-05,
      "loss": 1.0109,
      "step": 162550
    },
    {
      "epoch": 1.7213491353528725,
      "grad_norm": 3.751377582550049,
      "learning_rate": 4.1396675841626086e-05,
      "loss": 1.01,
      "step": 162600
    },
    {
      "epoch": 1.7218784571328758,
      "grad_norm": 3.1589269638061523,
      "learning_rate": 4.139402921871692e-05,
      "loss": 1.0274,
      "step": 162650
    },
    {
      "epoch": 1.7224077789128789,
      "grad_norm": 3.3471126556396484,
      "learning_rate": 4.1391382595807755e-05,
      "loss": 1.0155,
      "step": 162700
    },
    {
      "epoch": 1.7229371006928822,
      "grad_norm": 3.1897425651550293,
      "learning_rate": 4.138873597289858e-05,
      "loss": 1.0192,
      "step": 162750
    },
    {
      "epoch": 1.7234664224728855,
      "grad_norm": 3.5336711406707764,
      "learning_rate": 4.1386089349989416e-05,
      "loss": 1.0302,
      "step": 162800
    },
    {
      "epoch": 1.7239957442528888,
      "grad_norm": 3.5849101543426514,
      "learning_rate": 4.1383442727080243e-05,
      "loss": 1.0151,
      "step": 162850
    },
    {
      "epoch": 1.724525066032892,
      "grad_norm": 3.2178714275360107,
      "learning_rate": 4.1380796104171084e-05,
      "loss": 1.003,
      "step": 162900
    },
    {
      "epoch": 1.7250543878128952,
      "grad_norm": 3.688976764678955,
      "learning_rate": 4.137814948126191e-05,
      "loss": 1.0179,
      "step": 162950
    },
    {
      "epoch": 1.7255837095928985,
      "grad_norm": 3.2962775230407715,
      "learning_rate": 4.1375502858352746e-05,
      "loss": 1.0145,
      "step": 163000
    },
    {
      "epoch": 1.7255837095928985,
      "eval_loss": 0.8520647287368774,
      "eval_runtime": 46.6197,
      "eval_samples_per_second": 3602.123,
      "eval_steps_per_second": 450.281,
      "step": 163000
    },
    {
      "epoch": 1.7261130313729018,
      "grad_norm": 3.506307601928711,
      "learning_rate": 4.137290916790176e-05,
      "loss": 1.003,
      "step": 163050
    },
    {
      "epoch": 1.7266423531529052,
      "grad_norm": 3.4403839111328125,
      "learning_rate": 4.1370262544992594e-05,
      "loss": 1.0049,
      "step": 163100
    },
    {
      "epoch": 1.7271716749329085,
      "grad_norm": 3.573277235031128,
      "learning_rate": 4.136761592208342e-05,
      "loss": 1.0235,
      "step": 163150
    },
    {
      "epoch": 1.7277009967129118,
      "grad_norm": 3.7179195880889893,
      "learning_rate": 4.1364969299174256e-05,
      "loss": 1.0032,
      "step": 163200
    },
    {
      "epoch": 1.728230318492915,
      "grad_norm": 3.5034165382385254,
      "learning_rate": 4.136232267626508e-05,
      "loss": 1.0026,
      "step": 163250
    },
    {
      "epoch": 1.7287596402729184,
      "grad_norm": 3.21781587600708,
      "learning_rate": 4.1359676053355924e-05,
      "loss": 0.9974,
      "step": 163300
    },
    {
      "epoch": 1.7292889620529217,
      "grad_norm": 3.5096118450164795,
      "learning_rate": 4.135702943044675e-05,
      "loss": 1.0203,
      "step": 163350
    },
    {
      "epoch": 1.729818283832925,
      "grad_norm": 3.6406588554382324,
      "learning_rate": 4.1354382807537586e-05,
      "loss": 1.011,
      "step": 163400
    },
    {
      "epoch": 1.730347605612928,
      "grad_norm": 3.733140230178833,
      "learning_rate": 4.135173618462841e-05,
      "loss": 1.0095,
      "step": 163450
    },
    {
      "epoch": 1.7308769273929314,
      "grad_norm": 3.738980770111084,
      "learning_rate": 4.1349089561719254e-05,
      "loss": 1.0234,
      "step": 163500
    },
    {
      "epoch": 1.7308769273929314,
      "eval_loss": 0.8504258394241333,
      "eval_runtime": 46.7576,
      "eval_samples_per_second": 3591.504,
      "eval_steps_per_second": 448.954,
      "step": 163500
    },
    {
      "epoch": 1.7314062491729347,
      "grad_norm": 3.3513600826263428,
      "learning_rate": 4.134644293881008e-05,
      "loss": 0.9941,
      "step": 163550
    },
    {
      "epoch": 1.731935570952938,
      "grad_norm": 3.566251754760742,
      "learning_rate": 4.1343796315900915e-05,
      "loss": 1.0011,
      "step": 163600
    },
    {
      "epoch": 1.7324648927329411,
      "grad_norm": 3.385488986968994,
      "learning_rate": 4.134114969299174e-05,
      "loss": 1.0275,
      "step": 163650
    },
    {
      "epoch": 1.7329942145129444,
      "grad_norm": 4.083247184753418,
      "learning_rate": 4.1338503070082577e-05,
      "loss": 1.0129,
      "step": 163700
    },
    {
      "epoch": 1.7335235362929478,
      "grad_norm": 3.2783725261688232,
      "learning_rate": 4.133585644717341e-05,
      "loss": 0.9993,
      "step": 163750
    },
    {
      "epoch": 1.734052858072951,
      "grad_norm": 3.685624361038208,
      "learning_rate": 4.133320982426424e-05,
      "loss": 1.012,
      "step": 163800
    },
    {
      "epoch": 1.7345821798529544,
      "grad_norm": 3.922419309616089,
      "learning_rate": 4.133056320135507e-05,
      "loss": 0.9996,
      "step": 163850
    },
    {
      "epoch": 1.7351115016329577,
      "grad_norm": 3.520962715148926,
      "learning_rate": 4.1327916578445906e-05,
      "loss": 1.009,
      "step": 163900
    },
    {
      "epoch": 1.735640823412961,
      "grad_norm": 3.538710832595825,
      "learning_rate": 4.132526995553674e-05,
      "loss": 1.0123,
      "step": 163950
    },
    {
      "epoch": 1.7361701451929643,
      "grad_norm": 3.154775381088257,
      "learning_rate": 4.132262333262757e-05,
      "loss": 1.0016,
      "step": 164000
    },
    {
      "epoch": 1.7361701451929643,
      "eval_loss": 0.8500593900680542,
      "eval_runtime": 46.6239,
      "eval_samples_per_second": 3601.798,
      "eval_steps_per_second": 450.241,
      "step": 164000
    },
    {
      "epoch": 1.7366994669729676,
      "grad_norm": 2.960843563079834,
      "learning_rate": 4.13199767097184e-05,
      "loss": 1.0072,
      "step": 164050
    },
    {
      "epoch": 1.737228788752971,
      "grad_norm": 3.790391206741333,
      "learning_rate": 4.1317330086809236e-05,
      "loss": 1.0092,
      "step": 164100
    },
    {
      "epoch": 1.7377581105329742,
      "grad_norm": 3.645148515701294,
      "learning_rate": 4.131468346390007e-05,
      "loss": 1.025,
      "step": 164150
    },
    {
      "epoch": 1.7382874323129773,
      "grad_norm": 3.6659440994262695,
      "learning_rate": 4.13120368409909e-05,
      "loss": 1.0104,
      "step": 164200
    },
    {
      "epoch": 1.7388167540929806,
      "grad_norm": 3.5410895347595215,
      "learning_rate": 4.130939021808173e-05,
      "loss": 1.0108,
      "step": 164250
    },
    {
      "epoch": 1.739346075872984,
      "grad_norm": 3.706547498703003,
      "learning_rate": 4.1306743595172565e-05,
      "loss": 1.0063,
      "step": 164300
    },
    {
      "epoch": 1.7398753976529873,
      "grad_norm": 3.410059928894043,
      "learning_rate": 4.130409697226339e-05,
      "loss": 1.0111,
      "step": 164350
    },
    {
      "epoch": 1.7404047194329904,
      "grad_norm": 3.7659144401550293,
      "learning_rate": 4.130145034935423e-05,
      "loss": 1.0094,
      "step": 164400
    },
    {
      "epoch": 1.7409340412129937,
      "grad_norm": 3.436255931854248,
      "learning_rate": 4.1298803726445054e-05,
      "loss": 0.9996,
      "step": 164450
    },
    {
      "epoch": 1.741463362992997,
      "grad_norm": 3.448232650756836,
      "learning_rate": 4.1296157103535895e-05,
      "loss": 1.0089,
      "step": 164500
    },
    {
      "epoch": 1.741463362992997,
      "eval_loss": 0.8494631052017212,
      "eval_runtime": 46.6539,
      "eval_samples_per_second": 3599.487,
      "eval_steps_per_second": 449.952,
      "step": 164500
    },
    {
      "epoch": 1.7419926847730003,
      "grad_norm": 3.8788340091705322,
      "learning_rate": 4.129351048062672e-05,
      "loss": 1.0077,
      "step": 164550
    },
    {
      "epoch": 1.7425220065530036,
      "grad_norm": 3.423588275909424,
      "learning_rate": 4.1290863857717557e-05,
      "loss": 1.0117,
      "step": 164600
    },
    {
      "epoch": 1.743051328333007,
      "grad_norm": 3.2174062728881836,
      "learning_rate": 4.1288217234808384e-05,
      "loss": 1.0119,
      "step": 164650
    },
    {
      "epoch": 1.7435806501130102,
      "grad_norm": 3.6182823181152344,
      "learning_rate": 4.128557061189922e-05,
      "loss": 1.0159,
      "step": 164700
    },
    {
      "epoch": 1.7441099718930135,
      "grad_norm": 3.385298013687134,
      "learning_rate": 4.128292398899005e-05,
      "loss": 0.99,
      "step": 164750
    },
    {
      "epoch": 1.7446392936730168,
      "grad_norm": 3.203402519226074,
      "learning_rate": 4.1280277366080886e-05,
      "loss": 0.9906,
      "step": 164800
    },
    {
      "epoch": 1.7451686154530202,
      "grad_norm": 3.4537596702575684,
      "learning_rate": 4.1277630743171713e-05,
      "loss": 1.0053,
      "step": 164850
    },
    {
      "epoch": 1.7456979372330235,
      "grad_norm": 3.5704262256622314,
      "learning_rate": 4.127498412026255e-05,
      "loss": 1.0092,
      "step": 164900
    },
    {
      "epoch": 1.7462272590130266,
      "grad_norm": 3.32795786857605,
      "learning_rate": 4.127233749735338e-05,
      "loss": 1.0221,
      "step": 164950
    },
    {
      "epoch": 1.7467565807930299,
      "grad_norm": 3.659862518310547,
      "learning_rate": 4.126969087444421e-05,
      "loss": 1.0122,
      "step": 165000
    },
    {
      "epoch": 1.7467565807930299,
      "eval_loss": 0.845135509967804,
      "eval_runtime": 46.6963,
      "eval_samples_per_second": 3596.217,
      "eval_steps_per_second": 449.543,
      "step": 165000
    },
    {
      "epoch": 1.7472859025730332,
      "grad_norm": 3.344517469406128,
      "learning_rate": 4.1267097183993224e-05,
      "loss": 0.9977,
      "step": 165050
    },
    {
      "epoch": 1.7478152243530365,
      "grad_norm": 3.754739761352539,
      "learning_rate": 4.1264450561084065e-05,
      "loss": 1.0109,
      "step": 165100
    },
    {
      "epoch": 1.7483445461330396,
      "grad_norm": 3.576880931854248,
      "learning_rate": 4.126180393817489e-05,
      "loss": 0.9988,
      "step": 165150
    },
    {
      "epoch": 1.748873867913043,
      "grad_norm": 3.855916976928711,
      "learning_rate": 4.1259157315265726e-05,
      "loss": 1.0099,
      "step": 165200
    },
    {
      "epoch": 1.7494031896930462,
      "grad_norm": 3.7019424438476562,
      "learning_rate": 4.125651069235655e-05,
      "loss": 0.9984,
      "step": 165250
    },
    {
      "epoch": 1.7499325114730495,
      "grad_norm": 3.683058977127075,
      "learning_rate": 4.125386406944739e-05,
      "loss": 1.0112,
      "step": 165300
    },
    {
      "epoch": 1.7504618332530528,
      "grad_norm": 3.652339220046997,
      "learning_rate": 4.125121744653822e-05,
      "loss": 1.0141,
      "step": 165350
    },
    {
      "epoch": 1.7509911550330561,
      "grad_norm": 3.5106682777404785,
      "learning_rate": 4.124857082362905e-05,
      "loss": 1.0175,
      "step": 165400
    },
    {
      "epoch": 1.7515204768130594,
      "grad_norm": 3.675856351852417,
      "learning_rate": 4.124592420071988e-05,
      "loss": 1.0169,
      "step": 165450
    },
    {
      "epoch": 1.7520497985930628,
      "grad_norm": 3.622605800628662,
      "learning_rate": 4.124327757781071e-05,
      "loss": 1.0118,
      "step": 165500
    },
    {
      "epoch": 1.7520497985930628,
      "eval_loss": 0.845435619354248,
      "eval_runtime": 46.7026,
      "eval_samples_per_second": 3595.735,
      "eval_steps_per_second": 449.483,
      "step": 165500
    },
    {
      "epoch": 1.752579120373066,
      "grad_norm": 3.5525012016296387,
      "learning_rate": 4.124063095490155e-05,
      "loss": 1.0129,
      "step": 165550
    },
    {
      "epoch": 1.7531084421530694,
      "grad_norm": 3.733438491821289,
      "learning_rate": 4.123798433199238e-05,
      "loss": 1.0059,
      "step": 165600
    },
    {
      "epoch": 1.7536377639330727,
      "grad_norm": 3.606149673461914,
      "learning_rate": 4.123533770908321e-05,
      "loss": 1.0043,
      "step": 165650
    },
    {
      "epoch": 1.754167085713076,
      "grad_norm": 4.007650852203369,
      "learning_rate": 4.123269108617404e-05,
      "loss": 1.0068,
      "step": 165700
    },
    {
      "epoch": 1.754696407493079,
      "grad_norm": 3.617964744567871,
      "learning_rate": 4.123004446326488e-05,
      "loss": 1.0114,
      "step": 165750
    },
    {
      "epoch": 1.7552257292730824,
      "grad_norm": 3.444481611251831,
      "learning_rate": 4.122739784035571e-05,
      "loss": 1.0003,
      "step": 165800
    },
    {
      "epoch": 1.7557550510530857,
      "grad_norm": 3.102534294128418,
      "learning_rate": 4.122475121744654e-05,
      "loss": 1.0057,
      "step": 165850
    },
    {
      "epoch": 1.7562843728330888,
      "grad_norm": 3.372415781021118,
      "learning_rate": 4.122210459453737e-05,
      "loss": 1.0141,
      "step": 165900
    },
    {
      "epoch": 1.7568136946130921,
      "grad_norm": 3.6935253143310547,
      "learning_rate": 4.1219457971628204e-05,
      "loss": 1.0118,
      "step": 165950
    },
    {
      "epoch": 1.7573430163930954,
      "grad_norm": 3.604872703552246,
      "learning_rate": 4.121681134871904e-05,
      "loss": 1.0063,
      "step": 166000
    },
    {
      "epoch": 1.7573430163930954,
      "eval_loss": 0.8448807597160339,
      "eval_runtime": 46.5458,
      "eval_samples_per_second": 3607.842,
      "eval_steps_per_second": 450.996,
      "step": 166000
    },
    {
      "epoch": 1.7578723381730987,
      "grad_norm": 3.74406361579895,
      "learning_rate": 4.1214164725809865e-05,
      "loss": 1.0131,
      "step": 166050
    },
    {
      "epoch": 1.758401659953102,
      "grad_norm": 3.674931287765503,
      "learning_rate": 4.12115181029007e-05,
      "loss": 1.0015,
      "step": 166100
    },
    {
      "epoch": 1.7589309817331054,
      "grad_norm": 3.547041416168213,
      "learning_rate": 4.120887147999153e-05,
      "loss": 0.9956,
      "step": 166150
    },
    {
      "epoch": 1.7594603035131087,
      "grad_norm": 3.3845255374908447,
      "learning_rate": 4.120622485708237e-05,
      "loss": 0.9985,
      "step": 166200
    },
    {
      "epoch": 1.759989625293112,
      "grad_norm": 3.7004032135009766,
      "learning_rate": 4.1203578234173195e-05,
      "loss": 1.0089,
      "step": 166250
    },
    {
      "epoch": 1.7605189470731153,
      "grad_norm": 3.7806594371795654,
      "learning_rate": 4.120093161126403e-05,
      "loss": 1.0125,
      "step": 166300
    },
    {
      "epoch": 1.7610482688531186,
      "grad_norm": 3.7141129970550537,
      "learning_rate": 4.119828498835486e-05,
      "loss": 1.0206,
      "step": 166350
    },
    {
      "epoch": 1.761577590633122,
      "grad_norm": 3.5354480743408203,
      "learning_rate": 4.119563836544569e-05,
      "loss": 1.01,
      "step": 166400
    },
    {
      "epoch": 1.7621069124131252,
      "grad_norm": 3.400270938873291,
      "learning_rate": 4.1192991742536524e-05,
      "loss": 1.0064,
      "step": 166450
    },
    {
      "epoch": 1.7626362341931283,
      "grad_norm": 3.331209421157837,
      "learning_rate": 4.119034511962735e-05,
      "loss": 1.0066,
      "step": 166500
    },
    {
      "epoch": 1.7626362341931283,
      "eval_loss": 0.8432326912879944,
      "eval_runtime": 46.5658,
      "eval_samples_per_second": 3606.292,
      "eval_steps_per_second": 450.803,
      "step": 166500
    },
    {
      "epoch": 1.7631655559731316,
      "grad_norm": 3.465071201324463,
      "learning_rate": 4.118769849671819e-05,
      "loss": 1.0121,
      "step": 166550
    },
    {
      "epoch": 1.763694877753135,
      "grad_norm": 3.5634799003601074,
      "learning_rate": 4.118505187380902e-05,
      "loss": 0.9971,
      "step": 166600
    },
    {
      "epoch": 1.764224199533138,
      "grad_norm": 4.211853504180908,
      "learning_rate": 4.1182405250899854e-05,
      "loss": 0.9923,
      "step": 166650
    },
    {
      "epoch": 1.7647535213131413,
      "grad_norm": 3.440593719482422,
      "learning_rate": 4.117975862799068e-05,
      "loss": 0.9843,
      "step": 166700
    },
    {
      "epoch": 1.7652828430931446,
      "grad_norm": 3.461272716522217,
      "learning_rate": 4.117711200508152e-05,
      "loss": 0.9906,
      "step": 166750
    },
    {
      "epoch": 1.765812164873148,
      "grad_norm": 3.354837656021118,
      "learning_rate": 4.117446538217235e-05,
      "loss": 1.0046,
      "step": 166800
    },
    {
      "epoch": 1.7663414866531513,
      "grad_norm": 3.425140142440796,
      "learning_rate": 4.1171818759263184e-05,
      "loss": 0.9955,
      "step": 166850
    },
    {
      "epoch": 1.7668708084331546,
      "grad_norm": 3.6416239738464355,
      "learning_rate": 4.116917213635401e-05,
      "loss": 0.9909,
      "step": 166900
    },
    {
      "epoch": 1.767400130213158,
      "grad_norm": 3.9875807762145996,
      "learning_rate": 4.1166525513444845e-05,
      "loss": 1.0025,
      "step": 166950
    },
    {
      "epoch": 1.7679294519931612,
      "grad_norm": 3.258794069290161,
      "learning_rate": 4.116387889053568e-05,
      "loss": 0.9928,
      "step": 167000
    },
    {
      "epoch": 1.7679294519931612,
      "eval_loss": 0.8413180112838745,
      "eval_runtime": 46.4934,
      "eval_samples_per_second": 3611.91,
      "eval_steps_per_second": 451.505,
      "step": 167000
    },
    {
      "epoch": 1.7684587737731645,
      "grad_norm": 3.4346840381622314,
      "learning_rate": 4.1161232267626506e-05,
      "loss": 1.0181,
      "step": 167050
    },
    {
      "epoch": 1.7689880955531678,
      "grad_norm": 3.6152989864349365,
      "learning_rate": 4.115863857717552e-05,
      "loss": 1.0103,
      "step": 167100
    },
    {
      "epoch": 1.7695174173331711,
      "grad_norm": 3.672429323196411,
      "learning_rate": 4.115599195426636e-05,
      "loss": 1.0057,
      "step": 167150
    },
    {
      "epoch": 1.7700467391131744,
      "grad_norm": 3.5609965324401855,
      "learning_rate": 4.115334533135719e-05,
      "loss": 0.9949,
      "step": 167200
    },
    {
      "epoch": 1.7705760608931775,
      "grad_norm": 3.547335386276245,
      "learning_rate": 4.115069870844802e-05,
      "loss": 1.0089,
      "step": 167250
    },
    {
      "epoch": 1.7711053826731809,
      "grad_norm": 3.8376588821411133,
      "learning_rate": 4.114805208553885e-05,
      "loss": 0.9989,
      "step": 167300
    },
    {
      "epoch": 1.7716347044531842,
      "grad_norm": 3.3999600410461426,
      "learning_rate": 4.1145405462629685e-05,
      "loss": 1.0048,
      "step": 167350
    },
    {
      "epoch": 1.7721640262331873,
      "grad_norm": 3.5397493839263916,
      "learning_rate": 4.114275883972052e-05,
      "loss": 1.005,
      "step": 167400
    },
    {
      "epoch": 1.7726933480131906,
      "grad_norm": 3.2538719177246094,
      "learning_rate": 4.1140112216811346e-05,
      "loss": 1.0162,
      "step": 167450
    },
    {
      "epoch": 1.7732226697931939,
      "grad_norm": 3.6809275150299072,
      "learning_rate": 4.113746559390218e-05,
      "loss": 1.0136,
      "step": 167500
    },
    {
      "epoch": 1.7732226697931939,
      "eval_loss": 0.8412835597991943,
      "eval_runtime": 46.6089,
      "eval_samples_per_second": 3602.961,
      "eval_steps_per_second": 450.386,
      "step": 167500
    },
    {
      "epoch": 1.7737519915731972,
      "grad_norm": 3.21789813041687,
      "learning_rate": 4.1134818970993014e-05,
      "loss": 0.9911,
      "step": 167550
    },
    {
      "epoch": 1.7742813133532005,
      "grad_norm": 3.800982713699341,
      "learning_rate": 4.113217234808385e-05,
      "loss": 1.0032,
      "step": 167600
    },
    {
      "epoch": 1.7748106351332038,
      "grad_norm": 3.3862125873565674,
      "learning_rate": 4.1129525725174676e-05,
      "loss": 1.0126,
      "step": 167650
    },
    {
      "epoch": 1.7753399569132071,
      "grad_norm": 3.555936574935913,
      "learning_rate": 4.112687910226551e-05,
      "loss": 1.0009,
      "step": 167700
    },
    {
      "epoch": 1.7758692786932104,
      "grad_norm": 3.3208765983581543,
      "learning_rate": 4.1124232479356344e-05,
      "loss": 0.9985,
      "step": 167750
    },
    {
      "epoch": 1.7763986004732137,
      "grad_norm": 3.583024024963379,
      "learning_rate": 4.112158585644718e-05,
      "loss": 1.0098,
      "step": 167800
    },
    {
      "epoch": 1.776927922253217,
      "grad_norm": 3.424541473388672,
      "learning_rate": 4.1118939233538005e-05,
      "loss": 1.001,
      "step": 167850
    },
    {
      "epoch": 1.7774572440332204,
      "grad_norm": 3.6170012950897217,
      "learning_rate": 4.111629261062884e-05,
      "loss": 1.0049,
      "step": 167900
    },
    {
      "epoch": 1.7779865658132237,
      "grad_norm": 4.066291332244873,
      "learning_rate": 4.1113645987719674e-05,
      "loss": 0.9984,
      "step": 167950
    },
    {
      "epoch": 1.7785158875932268,
      "grad_norm": 3.440270185470581,
      "learning_rate": 4.11109993648105e-05,
      "loss": 1.0056,
      "step": 168000
    },
    {
      "epoch": 1.7785158875932268,
      "eval_loss": 0.8395315408706665,
      "eval_runtime": 46.5589,
      "eval_samples_per_second": 3606.833,
      "eval_steps_per_second": 450.87,
      "step": 168000
    },
    {
      "epoch": 1.77904520937323,
      "grad_norm": 3.6579596996307373,
      "learning_rate": 4.1108352741901335e-05,
      "loss": 0.9851,
      "step": 168050
    },
    {
      "epoch": 1.7795745311532334,
      "grad_norm": 3.366116762161255,
      "learning_rate": 4.110570611899216e-05,
      "loss": 0.9978,
      "step": 168100
    },
    {
      "epoch": 1.7801038529332367,
      "grad_norm": 3.4312026500701904,
      "learning_rate": 4.1103059496083e-05,
      "loss": 0.9905,
      "step": 168150
    },
    {
      "epoch": 1.7806331747132398,
      "grad_norm": 3.473586082458496,
      "learning_rate": 4.110041287317383e-05,
      "loss": 1.0089,
      "step": 168200
    },
    {
      "epoch": 1.781162496493243,
      "grad_norm": 3.1941168308258057,
      "learning_rate": 4.1097766250264665e-05,
      "loss": 1.0118,
      "step": 168250
    },
    {
      "epoch": 1.7816918182732464,
      "grad_norm": 3.322277784347534,
      "learning_rate": 4.109511962735549e-05,
      "loss": 0.9896,
      "step": 168300
    },
    {
      "epoch": 1.7822211400532497,
      "grad_norm": 3.5318069458007812,
      "learning_rate": 4.109247300444633e-05,
      "loss": 1.0034,
      "step": 168350
    },
    {
      "epoch": 1.782750461833253,
      "grad_norm": 3.6799817085266113,
      "learning_rate": 4.108982638153716e-05,
      "loss": 0.996,
      "step": 168400
    },
    {
      "epoch": 1.7832797836132563,
      "grad_norm": 3.426848888397217,
      "learning_rate": 4.1087179758627994e-05,
      "loss": 1.0045,
      "step": 168450
    },
    {
      "epoch": 1.7838091053932597,
      "grad_norm": 3.3438973426818848,
      "learning_rate": 4.108453313571882e-05,
      "loss": 1.0072,
      "step": 168500
    },
    {
      "epoch": 1.7838091053932597,
      "eval_loss": 0.8363282084465027,
      "eval_runtime": 46.5431,
      "eval_samples_per_second": 3608.056,
      "eval_steps_per_second": 451.023,
      "step": 168500
    },
    {
      "epoch": 1.784338427173263,
      "grad_norm": 3.4304141998291016,
      "learning_rate": 4.1081886512809656e-05,
      "loss": 0.9948,
      "step": 168550
    },
    {
      "epoch": 1.7848677489532663,
      "grad_norm": 3.5856919288635254,
      "learning_rate": 4.107923988990049e-05,
      "loss": 0.9965,
      "step": 168600
    },
    {
      "epoch": 1.7853970707332696,
      "grad_norm": 3.858712911605835,
      "learning_rate": 4.107659326699132e-05,
      "loss": 0.9992,
      "step": 168650
    },
    {
      "epoch": 1.785926392513273,
      "grad_norm": 3.3506648540496826,
      "learning_rate": 4.107394664408215e-05,
      "loss": 1.0188,
      "step": 168700
    },
    {
      "epoch": 1.786455714293276,
      "grad_norm": 3.4835119247436523,
      "learning_rate": 4.1071300021172985e-05,
      "loss": 1.0029,
      "step": 168750
    },
    {
      "epoch": 1.7869850360732793,
      "grad_norm": 3.438847303390503,
      "learning_rate": 4.106865339826382e-05,
      "loss": 0.9825,
      "step": 168800
    },
    {
      "epoch": 1.7875143578532826,
      "grad_norm": 3.671278953552246,
      "learning_rate": 4.106600677535465e-05,
      "loss": 0.9836,
      "step": 168850
    },
    {
      "epoch": 1.788043679633286,
      "grad_norm": 3.3230538368225098,
      "learning_rate": 4.106336015244548e-05,
      "loss": 0.9903,
      "step": 168900
    },
    {
      "epoch": 1.788573001413289,
      "grad_norm": 3.714205026626587,
      "learning_rate": 4.1060713529536315e-05,
      "loss": 0.9957,
      "step": 168950
    },
    {
      "epoch": 1.7891023231932923,
      "grad_norm": 3.633016347885132,
      "learning_rate": 4.105806690662715e-05,
      "loss": 1.0043,
      "step": 169000
    },
    {
      "epoch": 1.7891023231932923,
      "eval_loss": 0.8314642906188965,
      "eval_runtime": 46.6099,
      "eval_samples_per_second": 3602.886,
      "eval_steps_per_second": 450.377,
      "step": 169000
    },
    {
      "epoch": 1.7896316449732956,
      "grad_norm": 3.381805896759033,
      "learning_rate": 4.1055420283717976e-05,
      "loss": 1.0044,
      "step": 169050
    },
    {
      "epoch": 1.790160966753299,
      "grad_norm": 3.7457118034362793,
      "learning_rate": 4.105277366080881e-05,
      "loss": 0.9883,
      "step": 169100
    },
    {
      "epoch": 1.7906902885333023,
      "grad_norm": 3.3923180103302,
      "learning_rate": 4.1050179970357825e-05,
      "loss": 0.9971,
      "step": 169150
    },
    {
      "epoch": 1.7912196103133056,
      "grad_norm": 3.925539493560791,
      "learning_rate": 4.104753334744866e-05,
      "loss": 0.9987,
      "step": 169200
    },
    {
      "epoch": 1.7917489320933089,
      "grad_norm": 3.3605730533599854,
      "learning_rate": 4.104488672453949e-05,
      "loss": 1.0129,
      "step": 169250
    },
    {
      "epoch": 1.7922782538733122,
      "grad_norm": 3.341127395629883,
      "learning_rate": 4.104224010163032e-05,
      "loss": 0.9838,
      "step": 169300
    },
    {
      "epoch": 1.7928075756533155,
      "grad_norm": 3.7961580753326416,
      "learning_rate": 4.1039593478721155e-05,
      "loss": 0.9943,
      "step": 169350
    },
    {
      "epoch": 1.7933368974333188,
      "grad_norm": 3.3057966232299805,
      "learning_rate": 4.103694685581199e-05,
      "loss": 1.0067,
      "step": 169400
    },
    {
      "epoch": 1.7938662192133221,
      "grad_norm": 3.7082180976867676,
      "learning_rate": 4.1034300232902816e-05,
      "loss": 1.0044,
      "step": 169450
    },
    {
      "epoch": 1.7943955409933252,
      "grad_norm": 3.350266933441162,
      "learning_rate": 4.103165360999365e-05,
      "loss": 1.0085,
      "step": 169500
    },
    {
      "epoch": 1.7943955409933252,
      "eval_loss": 0.8339045643806458,
      "eval_runtime": 46.5451,
      "eval_samples_per_second": 3607.897,
      "eval_steps_per_second": 451.003,
      "step": 169500
    },
    {
      "epoch": 1.7949248627733285,
      "grad_norm": 3.1230666637420654,
      "learning_rate": 4.1029006987084484e-05,
      "loss": 0.9887,
      "step": 169550
    },
    {
      "epoch": 1.7954541845533318,
      "grad_norm": 4.183992385864258,
      "learning_rate": 4.102636036417531e-05,
      "loss": 0.9957,
      "step": 169600
    },
    {
      "epoch": 1.7959835063333351,
      "grad_norm": 3.93839955329895,
      "learning_rate": 4.1023713741266146e-05,
      "loss": 0.9866,
      "step": 169650
    },
    {
      "epoch": 1.7965128281133382,
      "grad_norm": 3.922245979309082,
      "learning_rate": 4.102106711835697e-05,
      "loss": 1.0091,
      "step": 169700
    },
    {
      "epoch": 1.7970421498933415,
      "grad_norm": 3.6477296352386475,
      "learning_rate": 4.1018420495447814e-05,
      "loss": 1.0043,
      "step": 169750
    },
    {
      "epoch": 1.7975714716733449,
      "grad_norm": 3.3940625190734863,
      "learning_rate": 4.101577387253864e-05,
      "loss": 1.0039,
      "step": 169800
    },
    {
      "epoch": 1.7981007934533482,
      "grad_norm": 3.2711925506591797,
      "learning_rate": 4.1013127249629476e-05,
      "loss": 0.9878,
      "step": 169850
    },
    {
      "epoch": 1.7986301152333515,
      "grad_norm": 3.9080047607421875,
      "learning_rate": 4.101053355917849e-05,
      "loss": 0.9963,
      "step": 169900
    },
    {
      "epoch": 1.7991594370133548,
      "grad_norm": 3.7203664779663086,
      "learning_rate": 4.1007886936269324e-05,
      "loss": 0.9889,
      "step": 169950
    },
    {
      "epoch": 1.799688758793358,
      "grad_norm": 3.434819221496582,
      "learning_rate": 4.100524031336015e-05,
      "loss": 1.0183,
      "step": 170000
    },
    {
      "epoch": 1.799688758793358,
      "eval_loss": 0.8346278071403503,
      "eval_runtime": 46.5912,
      "eval_samples_per_second": 3604.328,
      "eval_steps_per_second": 450.557,
      "step": 170000
    },
    {
      "epoch": 1.8002180805733614,
      "grad_norm": 3.5028152465820312,
      "learning_rate": 4.1002593690450986e-05,
      "loss": 1.0204,
      "step": 170050
    },
    {
      "epoch": 1.8007474023533647,
      "grad_norm": 3.0300140380859375,
      "learning_rate": 4.099994706754181e-05,
      "loss": 0.9826,
      "step": 170100
    },
    {
      "epoch": 1.801276724133368,
      "grad_norm": 3.376171350479126,
      "learning_rate": 4.0997300444632654e-05,
      "loss": 0.9906,
      "step": 170150
    },
    {
      "epoch": 1.8018060459133713,
      "grad_norm": 3.7055904865264893,
      "learning_rate": 4.099465382172348e-05,
      "loss": 0.9921,
      "step": 170200
    },
    {
      "epoch": 1.8023353676933744,
      "grad_norm": 3.5391833782196045,
      "learning_rate": 4.0992007198814315e-05,
      "loss": 0.9981,
      "step": 170250
    },
    {
      "epoch": 1.8028646894733777,
      "grad_norm": 3.2938027381896973,
      "learning_rate": 4.098936057590514e-05,
      "loss": 0.9976,
      "step": 170300
    },
    {
      "epoch": 1.803394011253381,
      "grad_norm": 3.4023706912994385,
      "learning_rate": 4.0986713952995984e-05,
      "loss": 1.0104,
      "step": 170350
    },
    {
      "epoch": 1.8039233330333844,
      "grad_norm": 3.6636433601379395,
      "learning_rate": 4.098406733008681e-05,
      "loss": 0.9966,
      "step": 170400
    },
    {
      "epoch": 1.8044526548133875,
      "grad_norm": 3.2933051586151123,
      "learning_rate": 4.0981420707177645e-05,
      "loss": 1.0162,
      "step": 170450
    },
    {
      "epoch": 1.8049819765933908,
      "grad_norm": 3.834041118621826,
      "learning_rate": 4.097877408426847e-05,
      "loss": 0.991,
      "step": 170500
    },
    {
      "epoch": 1.8049819765933908,
      "eval_loss": 0.8287035226821899,
      "eval_runtime": 46.5816,
      "eval_samples_per_second": 3605.068,
      "eval_steps_per_second": 450.65,
      "step": 170500
    },
    {
      "epoch": 1.805511298373394,
      "grad_norm": 3.5980641841888428,
      "learning_rate": 4.0976127461359306e-05,
      "loss": 1.0081,
      "step": 170550
    },
    {
      "epoch": 1.8060406201533974,
      "grad_norm": 3.6222212314605713,
      "learning_rate": 4.097348083845014e-05,
      "loss": 0.9851,
      "step": 170600
    },
    {
      "epoch": 1.8065699419334007,
      "grad_norm": 3.489563465118408,
      "learning_rate": 4.097083421554097e-05,
      "loss": 0.9839,
      "step": 170650
    },
    {
      "epoch": 1.807099263713404,
      "grad_norm": 3.4528770446777344,
      "learning_rate": 4.09681875926318e-05,
      "loss": 1.0018,
      "step": 170700
    },
    {
      "epoch": 1.8076285854934073,
      "grad_norm": 3.7958858013153076,
      "learning_rate": 4.0965540969722636e-05,
      "loss": 1.0077,
      "step": 170750
    },
    {
      "epoch": 1.8081579072734106,
      "grad_norm": 3.7192158699035645,
      "learning_rate": 4.096289434681347e-05,
      "loss": 0.9949,
      "step": 170800
    },
    {
      "epoch": 1.808687229053414,
      "grad_norm": 3.8341152667999268,
      "learning_rate": 4.09602477239043e-05,
      "loss": 1.005,
      "step": 170850
    },
    {
      "epoch": 1.8092165508334173,
      "grad_norm": 3.6201603412628174,
      "learning_rate": 4.095760110099513e-05,
      "loss": 0.9874,
      "step": 170900
    },
    {
      "epoch": 1.8097458726134206,
      "grad_norm": 3.712904214859009,
      "learning_rate": 4.0954954478085966e-05,
      "loss": 1.0014,
      "step": 170950
    },
    {
      "epoch": 1.8102751943934237,
      "grad_norm": 3.560666084289551,
      "learning_rate": 4.09523078551768e-05,
      "loss": 1.0048,
      "step": 171000
    },
    {
      "epoch": 1.8102751943934237,
      "eval_loss": 0.8282470107078552,
      "eval_runtime": 46.7833,
      "eval_samples_per_second": 3589.527,
      "eval_steps_per_second": 448.707,
      "step": 171000
    },
    {
      "epoch": 1.810804516173427,
      "grad_norm": 3.613433837890625,
      "learning_rate": 4.094966123226763e-05,
      "loss": 0.9922,
      "step": 171050
    },
    {
      "epoch": 1.8113338379534303,
      "grad_norm": 3.794503688812256,
      "learning_rate": 4.094701460935846e-05,
      "loss": 0.9931,
      "step": 171100
    },
    {
      "epoch": 1.8118631597334336,
      "grad_norm": 3.4684319496154785,
      "learning_rate": 4.0944367986449295e-05,
      "loss": 1.0003,
      "step": 171150
    },
    {
      "epoch": 1.8123924815134367,
      "grad_norm": 3.5414252281188965,
      "learning_rate": 4.094172136354012e-05,
      "loss": 1.0018,
      "step": 171200
    },
    {
      "epoch": 1.81292180329344,
      "grad_norm": 3.2315561771392822,
      "learning_rate": 4.093907474063096e-05,
      "loss": 0.9938,
      "step": 171250
    },
    {
      "epoch": 1.8134511250734433,
      "grad_norm": 3.4570062160491943,
      "learning_rate": 4.0936428117721784e-05,
      "loss": 0.9938,
      "step": 171300
    },
    {
      "epoch": 1.8139804468534466,
      "grad_norm": 3.9022469520568848,
      "learning_rate": 4.0933781494812625e-05,
      "loss": 1.0018,
      "step": 171350
    },
    {
      "epoch": 1.81450976863345,
      "grad_norm": 3.782332420349121,
      "learning_rate": 4.093113487190345e-05,
      "loss": 0.9896,
      "step": 171400
    },
    {
      "epoch": 1.8150390904134532,
      "grad_norm": 3.6583473682403564,
      "learning_rate": 4.0928488248994286e-05,
      "loss": 0.9874,
      "step": 171450
    },
    {
      "epoch": 1.8155684121934565,
      "grad_norm": 3.7128822803497314,
      "learning_rate": 4.0925841626085114e-05,
      "loss": 0.9837,
      "step": 171500
    },
    {
      "epoch": 1.8155684121934565,
      "eval_loss": 0.8277351260185242,
      "eval_runtime": 46.6289,
      "eval_samples_per_second": 3601.418,
      "eval_steps_per_second": 450.193,
      "step": 171500
    },
    {
      "epoch": 1.8160977339734599,
      "grad_norm": 3.611301898956299,
      "learning_rate": 4.0923195003175955e-05,
      "loss": 0.9863,
      "step": 171550
    },
    {
      "epoch": 1.8166270557534632,
      "grad_norm": 3.329064130783081,
      "learning_rate": 4.092054838026678e-05,
      "loss": 0.9799,
      "step": 171600
    },
    {
      "epoch": 1.8171563775334665,
      "grad_norm": 3.6099188327789307,
      "learning_rate": 4.0917901757357616e-05,
      "loss": 0.9842,
      "step": 171650
    },
    {
      "epoch": 1.8176856993134698,
      "grad_norm": 3.9872217178344727,
      "learning_rate": 4.091525513444844e-05,
      "loss": 0.9876,
      "step": 171700
    },
    {
      "epoch": 1.8182150210934729,
      "grad_norm": 3.7256743907928467,
      "learning_rate": 4.091260851153928e-05,
      "loss": 0.9939,
      "step": 171750
    },
    {
      "epoch": 1.8187443428734762,
      "grad_norm": 3.7487523555755615,
      "learning_rate": 4.090996188863011e-05,
      "loss": 1.0142,
      "step": 171800
    },
    {
      "epoch": 1.8192736646534795,
      "grad_norm": 3.488248109817505,
      "learning_rate": 4.090731526572094e-05,
      "loss": 1.0002,
      "step": 171850
    },
    {
      "epoch": 1.8198029864334828,
      "grad_norm": 3.4649457931518555,
      "learning_rate": 4.090466864281177e-05,
      "loss": 0.9937,
      "step": 171900
    },
    {
      "epoch": 1.820332308213486,
      "grad_norm": 3.540966033935547,
      "learning_rate": 4.090202201990261e-05,
      "loss": 0.9869,
      "step": 171950
    },
    {
      "epoch": 1.8208616299934892,
      "grad_norm": 3.69528865814209,
      "learning_rate": 4.089937539699344e-05,
      "loss": 0.9934,
      "step": 172000
    },
    {
      "epoch": 1.8208616299934892,
      "eval_loss": 0.8263642191886902,
      "eval_runtime": 46.7411,
      "eval_samples_per_second": 3592.773,
      "eval_steps_per_second": 449.113,
      "step": 172000
    },
    {
      "epoch": 1.8213909517734925,
      "grad_norm": 3.631197452545166,
      "learning_rate": 4.089672877408427e-05,
      "loss": 0.9778,
      "step": 172050
    },
    {
      "epoch": 1.8219202735534958,
      "grad_norm": 3.6499922275543213,
      "learning_rate": 4.08940821511751e-05,
      "loss": 0.987,
      "step": 172100
    },
    {
      "epoch": 1.8224495953334992,
      "grad_norm": 3.8560359477996826,
      "learning_rate": 4.089143552826594e-05,
      "loss": 0.9857,
      "step": 172150
    },
    {
      "epoch": 1.8229789171135025,
      "grad_norm": 3.865460157394409,
      "learning_rate": 4.088878890535677e-05,
      "loss": 1.006,
      "step": 172200
    },
    {
      "epoch": 1.8235082388935058,
      "grad_norm": 3.5933303833007812,
      "learning_rate": 4.08861422824476e-05,
      "loss": 0.9991,
      "step": 172250
    },
    {
      "epoch": 1.824037560673509,
      "grad_norm": 3.4478986263275146,
      "learning_rate": 4.088349565953843e-05,
      "loss": 0.9915,
      "step": 172300
    },
    {
      "epoch": 1.8245668824535124,
      "grad_norm": 3.5225117206573486,
      "learning_rate": 4.0880849036629266e-05,
      "loss": 1.0001,
      "step": 172350
    },
    {
      "epoch": 1.8250962042335157,
      "grad_norm": 3.715508222579956,
      "learning_rate": 4.0878202413720094e-05,
      "loss": 0.979,
      "step": 172400
    },
    {
      "epoch": 1.825625526013519,
      "grad_norm": 3.6662521362304688,
      "learning_rate": 4.087555579081093e-05,
      "loss": 0.9904,
      "step": 172450
    },
    {
      "epoch": 1.826154847793522,
      "grad_norm": 3.6408417224884033,
      "learning_rate": 4.0872909167901755e-05,
      "loss": 1.005,
      "step": 172500
    },
    {
      "epoch": 1.826154847793522,
      "eval_loss": 0.8233245611190796,
      "eval_runtime": 46.7176,
      "eval_samples_per_second": 3594.58,
      "eval_steps_per_second": 449.339,
      "step": 172500
    },
    {
      "epoch": 1.8266841695735254,
      "grad_norm": 3.3727755546569824,
      "learning_rate": 4.0870262544992596e-05,
      "loss": 1.0026,
      "step": 172550
    },
    {
      "epoch": 1.8272134913535287,
      "grad_norm": 3.582318067550659,
      "learning_rate": 4.086761592208342e-05,
      "loss": 0.9955,
      "step": 172600
    },
    {
      "epoch": 1.827742813133532,
      "grad_norm": 3.6925711631774902,
      "learning_rate": 4.086496929917426e-05,
      "loss": 0.9875,
      "step": 172650
    },
    {
      "epoch": 1.8282721349135351,
      "grad_norm": 4.028083324432373,
      "learning_rate": 4.0862322676265085e-05,
      "loss": 0.9861,
      "step": 172700
    },
    {
      "epoch": 1.8288014566935384,
      "grad_norm": 3.7469239234924316,
      "learning_rate": 4.085967605335592e-05,
      "loss": 0.9758,
      "step": 172750
    },
    {
      "epoch": 1.8293307784735418,
      "grad_norm": 3.394728183746338,
      "learning_rate": 4.085702943044675e-05,
      "loss": 0.9677,
      "step": 172800
    },
    {
      "epoch": 1.829860100253545,
      "grad_norm": 3.594489574432373,
      "learning_rate": 4.085438280753758e-05,
      "loss": 0.9938,
      "step": 172850
    },
    {
      "epoch": 1.8303894220335484,
      "grad_norm": 3.6309823989868164,
      "learning_rate": 4.0851736184628414e-05,
      "loss": 0.9886,
      "step": 172900
    },
    {
      "epoch": 1.8309187438135517,
      "grad_norm": 3.6698529720306396,
      "learning_rate": 4.084908956171925e-05,
      "loss": 1.0001,
      "step": 172950
    },
    {
      "epoch": 1.831448065593555,
      "grad_norm": 3.256235122680664,
      "learning_rate": 4.084644293881008e-05,
      "loss": 0.9952,
      "step": 173000
    },
    {
      "epoch": 1.831448065593555,
      "eval_loss": 0.8238820433616638,
      "eval_runtime": 46.4991,
      "eval_samples_per_second": 3611.469,
      "eval_steps_per_second": 451.45,
      "step": 173000
    },
    {
      "epoch": 1.8319773873735583,
      "grad_norm": 3.5805726051330566,
      "learning_rate": 4.084379631590091e-05,
      "loss": 0.9894,
      "step": 173050
    },
    {
      "epoch": 1.8325067091535616,
      "grad_norm": 3.3191349506378174,
      "learning_rate": 4.0841149692991744e-05,
      "loss": 1.0013,
      "step": 173100
    },
    {
      "epoch": 1.833036030933565,
      "grad_norm": 3.5992343425750732,
      "learning_rate": 4.083850307008258e-05,
      "loss": 0.9862,
      "step": 173150
    },
    {
      "epoch": 1.8335653527135682,
      "grad_norm": 3.8291354179382324,
      "learning_rate": 4.083585644717341e-05,
      "loss": 0.9892,
      "step": 173200
    },
    {
      "epoch": 1.8340946744935716,
      "grad_norm": 3.6083781719207764,
      "learning_rate": 4.083320982426424e-05,
      "loss": 1.0063,
      "step": 173250
    },
    {
      "epoch": 1.8346239962735746,
      "grad_norm": 3.416804313659668,
      "learning_rate": 4.0830563201355074e-05,
      "loss": 0.9737,
      "step": 173300
    },
    {
      "epoch": 1.835153318053578,
      "grad_norm": 3.2078983783721924,
      "learning_rate": 4.082791657844591e-05,
      "loss": 0.9716,
      "step": 173350
    },
    {
      "epoch": 1.8356826398335813,
      "grad_norm": 3.3480052947998047,
      "learning_rate": 4.0825269955536735e-05,
      "loss": 0.9836,
      "step": 173400
    },
    {
      "epoch": 1.8362119616135844,
      "grad_norm": 3.8202555179595947,
      "learning_rate": 4.082262333262757e-05,
      "loss": 0.9736,
      "step": 173450
    },
    {
      "epoch": 1.8367412833935877,
      "grad_norm": 3.282003879547119,
      "learning_rate": 4.0819976709718396e-05,
      "loss": 0.986,
      "step": 173500
    },
    {
      "epoch": 1.8367412833935877,
      "eval_loss": 0.8208314180374146,
      "eval_runtime": 46.7987,
      "eval_samples_per_second": 3588.349,
      "eval_steps_per_second": 448.56,
      "step": 173500
    },
    {
      "epoch": 1.837270605173591,
      "grad_norm": 3.609869956970215,
      "learning_rate": 4.081733008680924e-05,
      "loss": 0.9853,
      "step": 173550
    },
    {
      "epoch": 1.8377999269535943,
      "grad_norm": 3.436732053756714,
      "learning_rate": 4.0814683463900065e-05,
      "loss": 0.9903,
      "step": 173600
    },
    {
      "epoch": 1.8383292487335976,
      "grad_norm": 3.5709519386291504,
      "learning_rate": 4.08120368409909e-05,
      "loss": 1.0011,
      "step": 173650
    },
    {
      "epoch": 1.838858570513601,
      "grad_norm": 3.5098965167999268,
      "learning_rate": 4.0809390218081726e-05,
      "loss": 0.9934,
      "step": 173700
    },
    {
      "epoch": 1.8393878922936042,
      "grad_norm": 3.3749868869781494,
      "learning_rate": 4.080674359517257e-05,
      "loss": 0.9809,
      "step": 173750
    },
    {
      "epoch": 1.8399172140736075,
      "grad_norm": 3.341228485107422,
      "learning_rate": 4.0804096972263394e-05,
      "loss": 0.9849,
      "step": 173800
    },
    {
      "epoch": 1.8404465358536108,
      "grad_norm": 3.939706563949585,
      "learning_rate": 4.080145034935423e-05,
      "loss": 1.0008,
      "step": 173850
    },
    {
      "epoch": 1.8409758576336142,
      "grad_norm": 3.4807262420654297,
      "learning_rate": 4.0798856658903236e-05,
      "loss": 0.99,
      "step": 173900
    },
    {
      "epoch": 1.8415051794136175,
      "grad_norm": 3.672555446624756,
      "learning_rate": 4.079621003599408e-05,
      "loss": 0.9913,
      "step": 173950
    },
    {
      "epoch": 1.8420345011936208,
      "grad_norm": 3.5839805603027344,
      "learning_rate": 4.0793563413084904e-05,
      "loss": 0.9881,
      "step": 174000
    },
    {
      "epoch": 1.8420345011936208,
      "eval_loss": 0.8175367116928101,
      "eval_runtime": 46.5931,
      "eval_samples_per_second": 3604.179,
      "eval_steps_per_second": 450.539,
      "step": 174000
    },
    {
      "epoch": 1.8425638229736239,
      "grad_norm": 3.4309160709381104,
      "learning_rate": 4.079091679017574e-05,
      "loss": 0.9867,
      "step": 174050
    },
    {
      "epoch": 1.8430931447536272,
      "grad_norm": 3.5349721908569336,
      "learning_rate": 4.0788270167266566e-05,
      "loss": 0.9835,
      "step": 174100
    },
    {
      "epoch": 1.8436224665336305,
      "grad_norm": 3.3297650814056396,
      "learning_rate": 4.078562354435741e-05,
      "loss": 0.979,
      "step": 174150
    },
    {
      "epoch": 1.8441517883136336,
      "grad_norm": 3.589416980743408,
      "learning_rate": 4.0782976921448234e-05,
      "loss": 0.9969,
      "step": 174200
    },
    {
      "epoch": 1.8446811100936369,
      "grad_norm": 3.517089605331421,
      "learning_rate": 4.078033029853907e-05,
      "loss": 0.9927,
      "step": 174250
    },
    {
      "epoch": 1.8452104318736402,
      "grad_norm": 3.664550542831421,
      "learning_rate": 4.0777683675629895e-05,
      "loss": 0.9899,
      "step": 174300
    },
    {
      "epoch": 1.8457397536536435,
      "grad_norm": 3.630420446395874,
      "learning_rate": 4.077503705272073e-05,
      "loss": 0.9932,
      "step": 174350
    },
    {
      "epoch": 1.8462690754336468,
      "grad_norm": 3.942883253097534,
      "learning_rate": 4.0772390429811564e-05,
      "loss": 0.9918,
      "step": 174400
    },
    {
      "epoch": 1.8467983972136501,
      "grad_norm": 3.8819427490234375,
      "learning_rate": 4.076974380690239e-05,
      "loss": 0.9919,
      "step": 174450
    },
    {
      "epoch": 1.8473277189936534,
      "grad_norm": 3.516436815261841,
      "learning_rate": 4.0767097183993225e-05,
      "loss": 0.9961,
      "step": 174500
    },
    {
      "epoch": 1.8473277189936534,
      "eval_loss": 0.8193149566650391,
      "eval_runtime": 46.5677,
      "eval_samples_per_second": 3606.145,
      "eval_steps_per_second": 450.784,
      "step": 174500
    },
    {
      "epoch": 1.8478570407736568,
      "grad_norm": 3.7561821937561035,
      "learning_rate": 4.076445056108406e-05,
      "loss": 0.9844,
      "step": 174550
    },
    {
      "epoch": 1.84838636255366,
      "grad_norm": 3.5311691761016846,
      "learning_rate": 4.076180393817489e-05,
      "loss": 0.9901,
      "step": 174600
    },
    {
      "epoch": 1.8489156843336634,
      "grad_norm": 3.5089352130889893,
      "learning_rate": 4.075915731526572e-05,
      "loss": 0.9751,
      "step": 174650
    },
    {
      "epoch": 1.8494450061136667,
      "grad_norm": 3.472533941268921,
      "learning_rate": 4.0756510692356555e-05,
      "loss": 0.9985,
      "step": 174700
    },
    {
      "epoch": 1.84997432789367,
      "grad_norm": 3.5325369834899902,
      "learning_rate": 4.075386406944739e-05,
      "loss": 0.9919,
      "step": 174750
    },
    {
      "epoch": 1.850503649673673,
      "grad_norm": 3.52013897895813,
      "learning_rate": 4.075121744653822e-05,
      "loss": 0.9798,
      "step": 174800
    },
    {
      "epoch": 1.8510329714536764,
      "grad_norm": 3.279780387878418,
      "learning_rate": 4.074857082362905e-05,
      "loss": 0.9864,
      "step": 174850
    },
    {
      "epoch": 1.8515622932336797,
      "grad_norm": 3.4845149517059326,
      "learning_rate": 4.0745924200719884e-05,
      "loss": 0.986,
      "step": 174900
    },
    {
      "epoch": 1.8520916150136828,
      "grad_norm": 3.528350830078125,
      "learning_rate": 4.074327757781072e-05,
      "loss": 0.981,
      "step": 174950
    },
    {
      "epoch": 1.8526209367936861,
      "grad_norm": 3.818368434906006,
      "learning_rate": 4.0740630954901546e-05,
      "loss": 0.9851,
      "step": 175000
    },
    {
      "epoch": 1.8526209367936861,
      "eval_loss": 0.8163343667984009,
      "eval_runtime": 46.5902,
      "eval_samples_per_second": 3604.403,
      "eval_steps_per_second": 450.566,
      "step": 175000
    },
    {
      "epoch": 1.8531502585736894,
      "grad_norm": 3.506598472595215,
      "learning_rate": 4.073798433199238e-05,
      "loss": 0.966,
      "step": 175050
    },
    {
      "epoch": 1.8536795803536927,
      "grad_norm": 3.505445718765259,
      "learning_rate": 4.073533770908321e-05,
      "loss": 0.9927,
      "step": 175100
    },
    {
      "epoch": 1.854208902133696,
      "grad_norm": 3.7594738006591797,
      "learning_rate": 4.073269108617405e-05,
      "loss": 0.9898,
      "step": 175150
    },
    {
      "epoch": 1.8547382239136994,
      "grad_norm": 3.365755319595337,
      "learning_rate": 4.0730044463264875e-05,
      "loss": 0.9782,
      "step": 175200
    },
    {
      "epoch": 1.8552675456937027,
      "grad_norm": 3.594021797180176,
      "learning_rate": 4.072739784035571e-05,
      "loss": 0.971,
      "step": 175250
    },
    {
      "epoch": 1.855796867473706,
      "grad_norm": 3.608576774597168,
      "learning_rate": 4.072475121744654e-05,
      "loss": 0.9775,
      "step": 175300
    },
    {
      "epoch": 1.8563261892537093,
      "grad_norm": 3.364999771118164,
      "learning_rate": 4.072210459453738e-05,
      "loss": 0.9855,
      "step": 175350
    },
    {
      "epoch": 1.8568555110337126,
      "grad_norm": 3.44659161567688,
      "learning_rate": 4.0719457971628205e-05,
      "loss": 1.0039,
      "step": 175400
    },
    {
      "epoch": 1.857384832813716,
      "grad_norm": 3.7063722610473633,
      "learning_rate": 4.071681134871904e-05,
      "loss": 0.9941,
      "step": 175450
    },
    {
      "epoch": 1.8579141545937192,
      "grad_norm": 3.5556628704071045,
      "learning_rate": 4.0714164725809866e-05,
      "loss": 0.9745,
      "step": 175500
    },
    {
      "epoch": 1.8579141545937192,
      "eval_loss": 0.815378725528717,
      "eval_runtime": 46.6465,
      "eval_samples_per_second": 3600.054,
      "eval_steps_per_second": 450.023,
      "step": 175500
    },
    {
      "epoch": 1.8584434763737223,
      "grad_norm": 3.4244396686553955,
      "learning_rate": 4.07115181029007e-05,
      "loss": 0.9799,
      "step": 175550
    },
    {
      "epoch": 1.8589727981537256,
      "grad_norm": 2.908639907836914,
      "learning_rate": 4.0708871479991535e-05,
      "loss": 0.9724,
      "step": 175600
    },
    {
      "epoch": 1.859502119933729,
      "grad_norm": 3.564788579940796,
      "learning_rate": 4.070622485708236e-05,
      "loss": 0.9898,
      "step": 175650
    },
    {
      "epoch": 1.8600314417137322,
      "grad_norm": 3.6121833324432373,
      "learning_rate": 4.0703578234173196e-05,
      "loss": 0.9951,
      "step": 175700
    },
    {
      "epoch": 1.8605607634937353,
      "grad_norm": 3.695772886276245,
      "learning_rate": 4.070093161126403e-05,
      "loss": 0.9786,
      "step": 175750
    },
    {
      "epoch": 1.8610900852737386,
      "grad_norm": 3.20157790184021,
      "learning_rate": 4.0698284988354864e-05,
      "loss": 0.9899,
      "step": 175800
    },
    {
      "epoch": 1.861619407053742,
      "grad_norm": 3.008244037628174,
      "learning_rate": 4.069563836544569e-05,
      "loss": 0.9844,
      "step": 175850
    },
    {
      "epoch": 1.8621487288337453,
      "grad_norm": 3.6010007858276367,
      "learning_rate": 4.0693044674994706e-05,
      "loss": 0.9963,
      "step": 175900
    },
    {
      "epoch": 1.8626780506137486,
      "grad_norm": 3.7140674591064453,
      "learning_rate": 4.069039805208554e-05,
      "loss": 0.9826,
      "step": 175950
    },
    {
      "epoch": 1.863207372393752,
      "grad_norm": 3.540285348892212,
      "learning_rate": 4.0687751429176374e-05,
      "loss": 1.0072,
      "step": 176000
    },
    {
      "epoch": 1.863207372393752,
      "eval_loss": 0.8136199116706848,
      "eval_runtime": 46.6054,
      "eval_samples_per_second": 3603.229,
      "eval_steps_per_second": 450.42,
      "step": 176000
    },
    {
      "epoch": 1.8637366941737552,
      "grad_norm": 3.595025062561035,
      "learning_rate": 4.06851048062672e-05,
      "loss": 0.9904,
      "step": 176050
    },
    {
      "epoch": 1.8642660159537585,
      "grad_norm": 3.6416425704956055,
      "learning_rate": 4.0682458183358036e-05,
      "loss": 1.0054,
      "step": 176100
    },
    {
      "epoch": 1.8647953377337618,
      "grad_norm": 3.6245925426483154,
      "learning_rate": 4.067981156044887e-05,
      "loss": 1.0004,
      "step": 176150
    },
    {
      "epoch": 1.8653246595137651,
      "grad_norm": 3.512791872024536,
      "learning_rate": 4.0677164937539704e-05,
      "loss": 0.9874,
      "step": 176200
    },
    {
      "epoch": 1.8658539812937684,
      "grad_norm": 3.8202126026153564,
      "learning_rate": 4.067451831463053e-05,
      "loss": 0.9813,
      "step": 176250
    },
    {
      "epoch": 1.8663833030737715,
      "grad_norm": 3.70188307762146,
      "learning_rate": 4.0671871691721366e-05,
      "loss": 0.973,
      "step": 176300
    },
    {
      "epoch": 1.8669126248537748,
      "grad_norm": 3.5130510330200195,
      "learning_rate": 4.06692250688122e-05,
      "loss": 0.9724,
      "step": 176350
    },
    {
      "epoch": 1.8674419466337782,
      "grad_norm": 3.883962631225586,
      "learning_rate": 4.0666578445903034e-05,
      "loss": 0.9763,
      "step": 176400
    },
    {
      "epoch": 1.8679712684137815,
      "grad_norm": 3.701911211013794,
      "learning_rate": 4.066393182299386e-05,
      "loss": 0.9744,
      "step": 176450
    },
    {
      "epoch": 1.8685005901937846,
      "grad_norm": 3.5362260341644287,
      "learning_rate": 4.0661285200084695e-05,
      "loss": 0.9928,
      "step": 176500
    },
    {
      "epoch": 1.8685005901937846,
      "eval_loss": 0.8116292953491211,
      "eval_runtime": 46.5785,
      "eval_samples_per_second": 3605.314,
      "eval_steps_per_second": 450.68,
      "step": 176500
    },
    {
      "epoch": 1.8690299119737879,
      "grad_norm": 3.1532530784606934,
      "learning_rate": 4.065863857717553e-05,
      "loss": 1.005,
      "step": 176550
    },
    {
      "epoch": 1.8695592337537912,
      "grad_norm": 3.2304186820983887,
      "learning_rate": 4.0655991954266357e-05,
      "loss": 0.9883,
      "step": 176600
    },
    {
      "epoch": 1.8700885555337945,
      "grad_norm": 4.202096462249756,
      "learning_rate": 4.065334533135719e-05,
      "loss": 0.978,
      "step": 176650
    },
    {
      "epoch": 1.8706178773137978,
      "grad_norm": 3.5126452445983887,
      "learning_rate": 4.065069870844802e-05,
      "loss": 0.9915,
      "step": 176700
    },
    {
      "epoch": 1.8711471990938011,
      "grad_norm": 3.5423853397369385,
      "learning_rate": 4.064805208553886e-05,
      "loss": 0.97,
      "step": 176750
    },
    {
      "epoch": 1.8716765208738044,
      "grad_norm": 3.379520893096924,
      "learning_rate": 4.0645405462629686e-05,
      "loss": 0.9848,
      "step": 176800
    },
    {
      "epoch": 1.8722058426538077,
      "grad_norm": 3.3594110012054443,
      "learning_rate": 4.064275883972052e-05,
      "loss": 0.972,
      "step": 176850
    },
    {
      "epoch": 1.872735164433811,
      "grad_norm": 3.7159111499786377,
      "learning_rate": 4.064011221681135e-05,
      "loss": 0.9817,
      "step": 176900
    },
    {
      "epoch": 1.8732644862138144,
      "grad_norm": 3.6051974296569824,
      "learning_rate": 4.063746559390219e-05,
      "loss": 1.0006,
      "step": 176950
    },
    {
      "epoch": 1.8737938079938177,
      "grad_norm": 3.4338951110839844,
      "learning_rate": 4.0634818970993016e-05,
      "loss": 0.9829,
      "step": 177000
    },
    {
      "epoch": 1.8737938079938177,
      "eval_loss": 0.8094702959060669,
      "eval_runtime": 46.5498,
      "eval_samples_per_second": 3607.535,
      "eval_steps_per_second": 450.958,
      "step": 177000
    },
    {
      "epoch": 1.8743231297738208,
      "grad_norm": 3.3977489471435547,
      "learning_rate": 4.063217234808385e-05,
      "loss": 0.9731,
      "step": 177050
    },
    {
      "epoch": 1.874852451553824,
      "grad_norm": 3.5589983463287354,
      "learning_rate": 4.062952572517468e-05,
      "loss": 1.002,
      "step": 177100
    },
    {
      "epoch": 1.8753817733338274,
      "grad_norm": 3.785038471221924,
      "learning_rate": 4.062687910226551e-05,
      "loss": 0.9904,
      "step": 177150
    },
    {
      "epoch": 1.8759110951138307,
      "grad_norm": 4.0114827156066895,
      "learning_rate": 4.0624232479356345e-05,
      "loss": 0.9768,
      "step": 177200
    },
    {
      "epoch": 1.8764404168938338,
      "grad_norm": 3.4191107749938965,
      "learning_rate": 4.062158585644717e-05,
      "loss": 0.9858,
      "step": 177250
    },
    {
      "epoch": 1.876969738673837,
      "grad_norm": 3.685391426086426,
      "learning_rate": 4.061893923353801e-05,
      "loss": 1.001,
      "step": 177300
    },
    {
      "epoch": 1.8774990604538404,
      "grad_norm": 3.735954523086548,
      "learning_rate": 4.061629261062884e-05,
      "loss": 0.9712,
      "step": 177350
    },
    {
      "epoch": 1.8780283822338437,
      "grad_norm": 3.7122819423675537,
      "learning_rate": 4.0613645987719675e-05,
      "loss": 0.9823,
      "step": 177400
    },
    {
      "epoch": 1.878557704013847,
      "grad_norm": 4.001739978790283,
      "learning_rate": 4.06109993648105e-05,
      "loss": 0.9722,
      "step": 177450
    },
    {
      "epoch": 1.8790870257938503,
      "grad_norm": 3.705430746078491,
      "learning_rate": 4.0608352741901336e-05,
      "loss": 0.9714,
      "step": 177500
    },
    {
      "epoch": 1.8790870257938503,
      "eval_loss": 0.8091129064559937,
      "eval_runtime": 46.5686,
      "eval_samples_per_second": 3606.074,
      "eval_steps_per_second": 450.775,
      "step": 177500
    },
    {
      "epoch": 1.8796163475738537,
      "grad_norm": 3.610119342803955,
      "learning_rate": 4.060570611899217e-05,
      "loss": 0.9874,
      "step": 177550
    },
    {
      "epoch": 1.880145669353857,
      "grad_norm": 3.4272584915161133,
      "learning_rate": 4.0603059496083e-05,
      "loss": 0.9898,
      "step": 177600
    },
    {
      "epoch": 1.8806749911338603,
      "grad_norm": 3.6751506328582764,
      "learning_rate": 4.060041287317383e-05,
      "loss": 0.9833,
      "step": 177650
    },
    {
      "epoch": 1.8812043129138636,
      "grad_norm": 3.3579673767089844,
      "learning_rate": 4.0597766250264666e-05,
      "loss": 1.0008,
      "step": 177700
    },
    {
      "epoch": 1.881733634693867,
      "grad_norm": 3.334099054336548,
      "learning_rate": 4.05951196273555e-05,
      "loss": 0.9655,
      "step": 177750
    },
    {
      "epoch": 1.88226295647387,
      "grad_norm": 3.5354530811309814,
      "learning_rate": 4.059247300444633e-05,
      "loss": 0.9712,
      "step": 177800
    },
    {
      "epoch": 1.8827922782538733,
      "grad_norm": 3.805185556411743,
      "learning_rate": 4.058982638153716e-05,
      "loss": 0.9886,
      "step": 177850
    },
    {
      "epoch": 1.8833216000338766,
      "grad_norm": 3.685244083404541,
      "learning_rate": 4.0587232691086176e-05,
      "loss": 0.9703,
      "step": 177900
    },
    {
      "epoch": 1.88385092181388,
      "grad_norm": 3.3850977420806885,
      "learning_rate": 4.058463900063519e-05,
      "loss": 0.9927,
      "step": 177950
    },
    {
      "epoch": 1.884380243593883,
      "grad_norm": 3.8254616260528564,
      "learning_rate": 4.0581992377726025e-05,
      "loss": 0.9693,
      "step": 178000
    },
    {
      "epoch": 1.884380243593883,
      "eval_loss": 0.8101350665092468,
      "eval_runtime": 46.6188,
      "eval_samples_per_second": 3602.196,
      "eval_steps_per_second": 450.291,
      "step": 178000
    },
    {
      "epoch": 1.8849095653738863,
      "grad_norm": 3.2038660049438477,
      "learning_rate": 4.057934575481685e-05,
      "loss": 0.9907,
      "step": 178050
    },
    {
      "epoch": 1.8854388871538896,
      "grad_norm": 3.605977773666382,
      "learning_rate": 4.0576699131907687e-05,
      "loss": 1.0034,
      "step": 178100
    },
    {
      "epoch": 1.885968208933893,
      "grad_norm": 3.3846373558044434,
      "learning_rate": 4.057405250899852e-05,
      "loss": 0.9627,
      "step": 178150
    },
    {
      "epoch": 1.8864975307138963,
      "grad_norm": 3.452934503555298,
      "learning_rate": 4.0571405886089355e-05,
      "loss": 0.9762,
      "step": 178200
    },
    {
      "epoch": 1.8870268524938996,
      "grad_norm": 3.588355302810669,
      "learning_rate": 4.056875926318018e-05,
      "loss": 0.9747,
      "step": 178250
    },
    {
      "epoch": 1.8875561742739029,
      "grad_norm": 3.2387502193450928,
      "learning_rate": 4.0566112640271016e-05,
      "loss": 0.9779,
      "step": 178300
    },
    {
      "epoch": 1.8880854960539062,
      "grad_norm": 3.419950008392334,
      "learning_rate": 4.056346601736185e-05,
      "loss": 0.9969,
      "step": 178350
    },
    {
      "epoch": 1.8886148178339095,
      "grad_norm": 3.4970433712005615,
      "learning_rate": 4.0560819394452684e-05,
      "loss": 0.9684,
      "step": 178400
    },
    {
      "epoch": 1.8891441396139128,
      "grad_norm": 3.532543659210205,
      "learning_rate": 4.055817277154351e-05,
      "loss": 0.9881,
      "step": 178450
    },
    {
      "epoch": 1.8896734613939161,
      "grad_norm": 3.3764452934265137,
      "learning_rate": 4.0555526148634346e-05,
      "loss": 0.9736,
      "step": 178500
    },
    {
      "epoch": 1.8896734613939161,
      "eval_loss": 0.8103585839271545,
      "eval_runtime": 46.61,
      "eval_samples_per_second": 3602.872,
      "eval_steps_per_second": 450.375,
      "step": 178500
    },
    {
      "epoch": 1.8902027831739192,
      "grad_norm": 3.4199576377868652,
      "learning_rate": 4.055287952572518e-05,
      "loss": 0.9745,
      "step": 178550
    },
    {
      "epoch": 1.8907321049539225,
      "grad_norm": 3.549875259399414,
      "learning_rate": 4.055023290281601e-05,
      "loss": 0.9699,
      "step": 178600
    },
    {
      "epoch": 1.8912614267339258,
      "grad_norm": 3.4995245933532715,
      "learning_rate": 4.054758627990684e-05,
      "loss": 0.9676,
      "step": 178650
    },
    {
      "epoch": 1.8917907485139291,
      "grad_norm": 3.751861572265625,
      "learning_rate": 4.054493965699767e-05,
      "loss": 0.9798,
      "step": 178700
    },
    {
      "epoch": 1.8923200702939322,
      "grad_norm": 3.653604030609131,
      "learning_rate": 4.054229303408851e-05,
      "loss": 0.9701,
      "step": 178750
    },
    {
      "epoch": 1.8928493920739355,
      "grad_norm": 3.7343575954437256,
      "learning_rate": 4.053964641117934e-05,
      "loss": 0.9815,
      "step": 178800
    },
    {
      "epoch": 1.8933787138539389,
      "grad_norm": 3.4560868740081787,
      "learning_rate": 4.053699978827017e-05,
      "loss": 0.985,
      "step": 178850
    },
    {
      "epoch": 1.8939080356339422,
      "grad_norm": 3.7247889041900635,
      "learning_rate": 4.0534353165361e-05,
      "loss": 0.9708,
      "step": 178900
    },
    {
      "epoch": 1.8944373574139455,
      "grad_norm": 3.4496607780456543,
      "learning_rate": 4.053170654245184e-05,
      "loss": 0.9817,
      "step": 178950
    },
    {
      "epoch": 1.8949666791939488,
      "grad_norm": 3.555351972579956,
      "learning_rate": 4.0529059919542666e-05,
      "loss": 0.9713,
      "step": 179000
    },
    {
      "epoch": 1.8949666791939488,
      "eval_loss": 0.8063358068466187,
      "eval_runtime": 46.7108,
      "eval_samples_per_second": 3595.102,
      "eval_steps_per_second": 449.404,
      "step": 179000
    },
    {
      "epoch": 1.895496000973952,
      "grad_norm": 3.619558095932007,
      "learning_rate": 4.05264132966335e-05,
      "loss": 0.9716,
      "step": 179050
    },
    {
      "epoch": 1.8960253227539554,
      "grad_norm": 3.890589475631714,
      "learning_rate": 4.052376667372433e-05,
      "loss": 0.9871,
      "step": 179100
    },
    {
      "epoch": 1.8965546445339587,
      "grad_norm": 3.480358839035034,
      "learning_rate": 4.052112005081516e-05,
      "loss": 0.98,
      "step": 179150
    },
    {
      "epoch": 1.897083966313962,
      "grad_norm": 3.2063565254211426,
      "learning_rate": 4.0518473427905996e-05,
      "loss": 0.9766,
      "step": 179200
    },
    {
      "epoch": 1.8976132880939653,
      "grad_norm": 3.361793279647827,
      "learning_rate": 4.0515826804996823e-05,
      "loss": 0.9791,
      "step": 179250
    },
    {
      "epoch": 1.8981426098739684,
      "grad_norm": 3.444957971572876,
      "learning_rate": 4.051318018208766e-05,
      "loss": 0.969,
      "step": 179300
    },
    {
      "epoch": 1.8986719316539717,
      "grad_norm": 3.7488653659820557,
      "learning_rate": 4.051053355917849e-05,
      "loss": 0.9833,
      "step": 179350
    },
    {
      "epoch": 1.899201253433975,
      "grad_norm": 3.5323309898376465,
      "learning_rate": 4.0507886936269326e-05,
      "loss": 0.9794,
      "step": 179400
    },
    {
      "epoch": 1.8997305752139784,
      "grad_norm": 4.017626762390137,
      "learning_rate": 4.050524031336015e-05,
      "loss": 0.9842,
      "step": 179450
    },
    {
      "epoch": 1.9002598969939815,
      "grad_norm": 3.5173277854919434,
      "learning_rate": 4.050259369045099e-05,
      "loss": 0.9868,
      "step": 179500
    },
    {
      "epoch": 1.9002598969939815,
      "eval_loss": 0.8052354454994202,
      "eval_runtime": 46.5399,
      "eval_samples_per_second": 3608.3,
      "eval_steps_per_second": 451.054,
      "step": 179500
    },
    {
      "epoch": 1.9007892187739848,
      "grad_norm": 3.558412790298462,
      "learning_rate": 4.049994706754182e-05,
      "loss": 0.9832,
      "step": 179550
    },
    {
      "epoch": 1.901318540553988,
      "grad_norm": 3.7093288898468018,
      "learning_rate": 4.0497300444632655e-05,
      "loss": 0.9753,
      "step": 179600
    },
    {
      "epoch": 1.9018478623339914,
      "grad_norm": 3.8631460666656494,
      "learning_rate": 4.049465382172348e-05,
      "loss": 0.9872,
      "step": 179650
    },
    {
      "epoch": 1.9023771841139947,
      "grad_norm": 3.3864948749542236,
      "learning_rate": 4.049200719881432e-05,
      "loss": 0.9663,
      "step": 179700
    },
    {
      "epoch": 1.902906505893998,
      "grad_norm": 3.413374185562134,
      "learning_rate": 4.048936057590515e-05,
      "loss": 0.9815,
      "step": 179750
    },
    {
      "epoch": 1.9034358276740013,
      "grad_norm": 3.993009090423584,
      "learning_rate": 4.048671395299598e-05,
      "loss": 0.9872,
      "step": 179800
    },
    {
      "epoch": 1.9039651494540046,
      "grad_norm": 3.5367496013641357,
      "learning_rate": 4.048406733008681e-05,
      "loss": 0.9902,
      "step": 179850
    },
    {
      "epoch": 1.904494471234008,
      "grad_norm": 3.815934419631958,
      "learning_rate": 4.048142070717764e-05,
      "loss": 0.995,
      "step": 179900
    },
    {
      "epoch": 1.9050237930140113,
      "grad_norm": 3.8927001953125,
      "learning_rate": 4.0478774084268474e-05,
      "loss": 0.9819,
      "step": 179950
    },
    {
      "epoch": 1.9055531147940146,
      "grad_norm": 3.5634889602661133,
      "learning_rate": 4.047612746135931e-05,
      "loss": 0.9751,
      "step": 180000
    },
    {
      "epoch": 1.9055531147940146,
      "eval_loss": 0.8053095936775208,
      "eval_runtime": 46.5853,
      "eval_samples_per_second": 3604.785,
      "eval_steps_per_second": 450.614,
      "step": 180000
    },
    {
      "epoch": 1.9060824365740177,
      "grad_norm": 3.4292352199554443,
      "learning_rate": 4.047348083845014e-05,
      "loss": 0.964,
      "step": 180050
    },
    {
      "epoch": 1.906611758354021,
      "grad_norm": 3.7775022983551025,
      "learning_rate": 4.047083421554097e-05,
      "loss": 0.9782,
      "step": 180100
    },
    {
      "epoch": 1.9071410801340243,
      "grad_norm": 3.7913520336151123,
      "learning_rate": 4.04681875926318e-05,
      "loss": 0.9943,
      "step": 180150
    },
    {
      "epoch": 1.9076704019140276,
      "grad_norm": 3.5210177898406982,
      "learning_rate": 4.046554096972264e-05,
      "loss": 0.9702,
      "step": 180200
    },
    {
      "epoch": 1.9081997236940307,
      "grad_norm": 3.968656301498413,
      "learning_rate": 4.0462894346813465e-05,
      "loss": 0.9926,
      "step": 180250
    },
    {
      "epoch": 1.908729045474034,
      "grad_norm": 3.4467344284057617,
      "learning_rate": 4.04602477239043e-05,
      "loss": 0.9692,
      "step": 180300
    },
    {
      "epoch": 1.9092583672540373,
      "grad_norm": 3.636597156524658,
      "learning_rate": 4.0457601100995126e-05,
      "loss": 0.9703,
      "step": 180350
    },
    {
      "epoch": 1.9097876890340406,
      "grad_norm": 3.61145281791687,
      "learning_rate": 4.045495447808597e-05,
      "loss": 0.9745,
      "step": 180400
    },
    {
      "epoch": 1.910317010814044,
      "grad_norm": 3.6683857440948486,
      "learning_rate": 4.0452307855176794e-05,
      "loss": 0.9774,
      "step": 180450
    },
    {
      "epoch": 1.9108463325940472,
      "grad_norm": 3.849618673324585,
      "learning_rate": 4.044966123226763e-05,
      "loss": 0.9915,
      "step": 180500
    },
    {
      "epoch": 1.9108463325940472,
      "eval_loss": 0.8035881519317627,
      "eval_runtime": 46.6379,
      "eval_samples_per_second": 3600.718,
      "eval_steps_per_second": 450.106,
      "step": 180500
    },
    {
      "epoch": 1.9113756543740505,
      "grad_norm": 3.8134524822235107,
      "learning_rate": 4.0447014609358456e-05,
      "loss": 0.9886,
      "step": 180550
    },
    {
      "epoch": 1.9119049761540539,
      "grad_norm": 3.381990671157837,
      "learning_rate": 4.04443679864493e-05,
      "loss": 0.9851,
      "step": 180600
    },
    {
      "epoch": 1.9124342979340572,
      "grad_norm": 3.36307692527771,
      "learning_rate": 4.0441721363540124e-05,
      "loss": 0.9735,
      "step": 180650
    },
    {
      "epoch": 1.9129636197140605,
      "grad_norm": 3.6745779514312744,
      "learning_rate": 4.043907474063096e-05,
      "loss": 0.9871,
      "step": 180700
    },
    {
      "epoch": 1.9134929414940638,
      "grad_norm": 3.5781116485595703,
      "learning_rate": 4.0436428117721785e-05,
      "loss": 0.9731,
      "step": 180750
    },
    {
      "epoch": 1.914022263274067,
      "grad_norm": 3.6084983348846436,
      "learning_rate": 4.043378149481262e-05,
      "loss": 0.978,
      "step": 180800
    },
    {
      "epoch": 1.9145515850540702,
      "grad_norm": 3.411130428314209,
      "learning_rate": 4.0431134871903454e-05,
      "loss": 0.9713,
      "step": 180850
    },
    {
      "epoch": 1.9150809068340735,
      "grad_norm": 3.907227039337158,
      "learning_rate": 4.042848824899428e-05,
      "loss": 0.9783,
      "step": 180900
    },
    {
      "epoch": 1.9156102286140768,
      "grad_norm": 3.5055859088897705,
      "learning_rate": 4.0425841626085115e-05,
      "loss": 0.9759,
      "step": 180950
    },
    {
      "epoch": 1.91613955039408,
      "grad_norm": 3.5947136878967285,
      "learning_rate": 4.042319500317595e-05,
      "loss": 0.9685,
      "step": 181000
    },
    {
      "epoch": 1.91613955039408,
      "eval_loss": 0.802159309387207,
      "eval_runtime": 46.5342,
      "eval_samples_per_second": 3608.746,
      "eval_steps_per_second": 451.109,
      "step": 181000
    },
    {
      "epoch": 1.9166688721740832,
      "grad_norm": 3.4256622791290283,
      "learning_rate": 4.042054838026678e-05,
      "loss": 0.9881,
      "step": 181050
    },
    {
      "epoch": 1.9171981939540865,
      "grad_norm": 3.568988800048828,
      "learning_rate": 4.041790175735761e-05,
      "loss": 0.9738,
      "step": 181100
    },
    {
      "epoch": 1.9177275157340898,
      "grad_norm": 3.5430195331573486,
      "learning_rate": 4.0415255134448445e-05,
      "loss": 0.9771,
      "step": 181150
    },
    {
      "epoch": 1.9182568375140931,
      "grad_norm": 3.2180521488189697,
      "learning_rate": 4.041260851153928e-05,
      "loss": 0.9558,
      "step": 181200
    },
    {
      "epoch": 1.9187861592940965,
      "grad_norm": 3.7382586002349854,
      "learning_rate": 4.040996188863011e-05,
      "loss": 0.9761,
      "step": 181250
    },
    {
      "epoch": 1.9193154810740998,
      "grad_norm": 3.974867105484009,
      "learning_rate": 4.040731526572094e-05,
      "loss": 0.9853,
      "step": 181300
    },
    {
      "epoch": 1.919844802854103,
      "grad_norm": 4.050734519958496,
      "learning_rate": 4.0404668642811774e-05,
      "loss": 0.9736,
      "step": 181350
    },
    {
      "epoch": 1.9203741246341064,
      "grad_norm": 3.7851064205169678,
      "learning_rate": 4.040202201990261e-05,
      "loss": 0.9629,
      "step": 181400
    },
    {
      "epoch": 1.9209034464141097,
      "grad_norm": 3.596574544906616,
      "learning_rate": 4.0399375396993436e-05,
      "loss": 0.9811,
      "step": 181450
    },
    {
      "epoch": 1.921432768194113,
      "grad_norm": 3.8255984783172607,
      "learning_rate": 4.039672877408427e-05,
      "loss": 0.9752,
      "step": 181500
    },
    {
      "epoch": 1.921432768194113,
      "eval_loss": 0.7984609603881836,
      "eval_runtime": 46.5959,
      "eval_samples_per_second": 3603.968,
      "eval_steps_per_second": 450.512,
      "step": 181500
    },
    {
      "epoch": 1.9219620899741163,
      "grad_norm": 3.65415096282959,
      "learning_rate": 4.03940821511751e-05,
      "loss": 0.9777,
      "step": 181550
    },
    {
      "epoch": 1.9224914117541194,
      "grad_norm": 3.624389171600342,
      "learning_rate": 4.039143552826594e-05,
      "loss": 0.9852,
      "step": 181600
    },
    {
      "epoch": 1.9230207335341227,
      "grad_norm": 3.6849207878112793,
      "learning_rate": 4.0388788905356765e-05,
      "loss": 0.9804,
      "step": 181650
    },
    {
      "epoch": 1.923550055314126,
      "grad_norm": 3.5849316120147705,
      "learning_rate": 4.03861422824476e-05,
      "loss": 0.99,
      "step": 181700
    },
    {
      "epoch": 1.9240793770941291,
      "grad_norm": 4.057621955871582,
      "learning_rate": 4.038349565953843e-05,
      "loss": 0.9712,
      "step": 181750
    },
    {
      "epoch": 1.9246086988741324,
      "grad_norm": 3.6207773685455322,
      "learning_rate": 4.038084903662927e-05,
      "loss": 0.9674,
      "step": 181800
    },
    {
      "epoch": 1.9251380206541358,
      "grad_norm": 3.2698261737823486,
      "learning_rate": 4.0378202413720095e-05,
      "loss": 0.9902,
      "step": 181850
    },
    {
      "epoch": 1.925667342434139,
      "grad_norm": 3.790004253387451,
      "learning_rate": 4.037555579081093e-05,
      "loss": 0.9858,
      "step": 181900
    },
    {
      "epoch": 1.9261966642141424,
      "grad_norm": 3.8160102367401123,
      "learning_rate": 4.037296210035994e-05,
      "loss": 0.9716,
      "step": 181950
    },
    {
      "epoch": 1.9267259859941457,
      "grad_norm": 3.169938087463379,
      "learning_rate": 4.037031547745078e-05,
      "loss": 0.9594,
      "step": 182000
    },
    {
      "epoch": 1.9267259859941457,
      "eval_loss": 0.7992920875549316,
      "eval_runtime": 46.6316,
      "eval_samples_per_second": 3601.208,
      "eval_steps_per_second": 450.167,
      "step": 182000
    },
    {
      "epoch": 1.927255307774149,
      "grad_norm": 3.890432119369507,
      "learning_rate": 4.0367668854541605e-05,
      "loss": 0.9676,
      "step": 182050
    },
    {
      "epoch": 1.9277846295541523,
      "grad_norm": 3.45792293548584,
      "learning_rate": 4.036502223163244e-05,
      "loss": 0.9694,
      "step": 182100
    },
    {
      "epoch": 1.9283139513341556,
      "grad_norm": 3.3766555786132812,
      "learning_rate": 4.036237560872327e-05,
      "loss": 0.9694,
      "step": 182150
    },
    {
      "epoch": 1.928843273114159,
      "grad_norm": 3.676738739013672,
      "learning_rate": 4.035972898581411e-05,
      "loss": 0.9627,
      "step": 182200
    },
    {
      "epoch": 1.9293725948941622,
      "grad_norm": 3.4510648250579834,
      "learning_rate": 4.0357082362904935e-05,
      "loss": 0.9716,
      "step": 182250
    },
    {
      "epoch": 1.9299019166741656,
      "grad_norm": 3.680058717727661,
      "learning_rate": 4.035443573999577e-05,
      "loss": 0.9852,
      "step": 182300
    },
    {
      "epoch": 1.9304312384541686,
      "grad_norm": 3.645934820175171,
      "learning_rate": 4.0351789117086596e-05,
      "loss": 0.9864,
      "step": 182350
    },
    {
      "epoch": 1.930960560234172,
      "grad_norm": 3.7195212841033936,
      "learning_rate": 4.034914249417743e-05,
      "loss": 0.9803,
      "step": 182400
    },
    {
      "epoch": 1.9314898820141753,
      "grad_norm": 3.2692384719848633,
      "learning_rate": 4.0346495871268264e-05,
      "loss": 0.9763,
      "step": 182450
    },
    {
      "epoch": 1.9320192037941786,
      "grad_norm": 3.565216302871704,
      "learning_rate": 4.034384924835909e-05,
      "loss": 0.9763,
      "step": 182500
    },
    {
      "epoch": 1.9320192037941786,
      "eval_loss": 0.7963136434555054,
      "eval_runtime": 46.8015,
      "eval_samples_per_second": 3588.136,
      "eval_steps_per_second": 448.533,
      "step": 182500
    },
    {
      "epoch": 1.9325485255741817,
      "grad_norm": 3.432040214538574,
      "learning_rate": 4.0341202625449926e-05,
      "loss": 0.9769,
      "step": 182550
    },
    {
      "epoch": 1.933077847354185,
      "grad_norm": 3.750386953353882,
      "learning_rate": 4.033855600254076e-05,
      "loss": 0.978,
      "step": 182600
    },
    {
      "epoch": 1.9336071691341883,
      "grad_norm": 3.5132718086242676,
      "learning_rate": 4.0335909379631594e-05,
      "loss": 0.9617,
      "step": 182650
    },
    {
      "epoch": 1.9341364909141916,
      "grad_norm": 4.01688814163208,
      "learning_rate": 4.033326275672242e-05,
      "loss": 0.9373,
      "step": 182700
    },
    {
      "epoch": 1.934665812694195,
      "grad_norm": 3.8638052940368652,
      "learning_rate": 4.0330616133813256e-05,
      "loss": 0.9698,
      "step": 182750
    },
    {
      "epoch": 1.9351951344741982,
      "grad_norm": 3.9340016841888428,
      "learning_rate": 4.032796951090409e-05,
      "loss": 0.9924,
      "step": 182800
    },
    {
      "epoch": 1.9357244562542015,
      "grad_norm": 3.9184372425079346,
      "learning_rate": 4.0325322887994924e-05,
      "loss": 0.9804,
      "step": 182850
    },
    {
      "epoch": 1.9362537780342048,
      "grad_norm": 3.784389019012451,
      "learning_rate": 4.032267626508575e-05,
      "loss": 0.9679,
      "step": 182900
    },
    {
      "epoch": 1.9367830998142082,
      "grad_norm": 3.68027663230896,
      "learning_rate": 4.0320029642176585e-05,
      "loss": 0.9767,
      "step": 182950
    },
    {
      "epoch": 1.9373124215942115,
      "grad_norm": 3.6458992958068848,
      "learning_rate": 4.031738301926742e-05,
      "loss": 0.9857,
      "step": 183000
    },
    {
      "epoch": 1.9373124215942115,
      "eval_loss": 0.7980486750602722,
      "eval_runtime": 46.6304,
      "eval_samples_per_second": 3601.301,
      "eval_steps_per_second": 450.179,
      "step": 183000
    },
    {
      "epoch": 1.9378417433742148,
      "grad_norm": 3.5477211475372314,
      "learning_rate": 4.0314736396358247e-05,
      "loss": 0.9615,
      "step": 183050
    },
    {
      "epoch": 1.9383710651542179,
      "grad_norm": 3.6578493118286133,
      "learning_rate": 4.031208977344908e-05,
      "loss": 0.968,
      "step": 183100
    },
    {
      "epoch": 1.9389003869342212,
      "grad_norm": 3.8400871753692627,
      "learning_rate": 4.030944315053991e-05,
      "loss": 0.9822,
      "step": 183150
    },
    {
      "epoch": 1.9394297087142245,
      "grad_norm": 3.4144649505615234,
      "learning_rate": 4.030679652763075e-05,
      "loss": 0.9644,
      "step": 183200
    },
    {
      "epoch": 1.9399590304942278,
      "grad_norm": 3.944502353668213,
      "learning_rate": 4.0304149904721576e-05,
      "loss": 0.9739,
      "step": 183250
    },
    {
      "epoch": 1.9404883522742309,
      "grad_norm": 3.398963689804077,
      "learning_rate": 4.030150328181241e-05,
      "loss": 0.9592,
      "step": 183300
    },
    {
      "epoch": 1.9410176740542342,
      "grad_norm": 3.935532331466675,
      "learning_rate": 4.029885665890324e-05,
      "loss": 0.9805,
      "step": 183350
    },
    {
      "epoch": 1.9415469958342375,
      "grad_norm": 3.650188684463501,
      "learning_rate": 4.029621003599408e-05,
      "loss": 0.9787,
      "step": 183400
    },
    {
      "epoch": 1.9420763176142408,
      "grad_norm": 3.5990025997161865,
      "learning_rate": 4.0293563413084906e-05,
      "loss": 0.975,
      "step": 183450
    },
    {
      "epoch": 1.9426056393942441,
      "grad_norm": 3.5981733798980713,
      "learning_rate": 4.029091679017574e-05,
      "loss": 0.982,
      "step": 183500
    },
    {
      "epoch": 1.9426056393942441,
      "eval_loss": 0.7966330647468567,
      "eval_runtime": 46.7007,
      "eval_samples_per_second": 3595.876,
      "eval_steps_per_second": 449.501,
      "step": 183500
    },
    {
      "epoch": 1.9431349611742474,
      "grad_norm": 3.7810122966766357,
      "learning_rate": 4.028827016726657e-05,
      "loss": 0.9744,
      "step": 183550
    },
    {
      "epoch": 1.9436642829542508,
      "grad_norm": 3.3676023483276367,
      "learning_rate": 4.02856235443574e-05,
      "loss": 0.9686,
      "step": 183600
    },
    {
      "epoch": 1.944193604734254,
      "grad_norm": 3.5298686027526855,
      "learning_rate": 4.0282976921448235e-05,
      "loss": 0.9393,
      "step": 183650
    },
    {
      "epoch": 1.9447229265142574,
      "grad_norm": 3.530625343322754,
      "learning_rate": 4.028033029853906e-05,
      "loss": 0.9719,
      "step": 183700
    },
    {
      "epoch": 1.9452522482942607,
      "grad_norm": 3.570556163787842,
      "learning_rate": 4.02776836756299e-05,
      "loss": 0.9648,
      "step": 183750
    },
    {
      "epoch": 1.945781570074264,
      "grad_norm": 3.668292999267578,
      "learning_rate": 4.027503705272073e-05,
      "loss": 0.9744,
      "step": 183800
    },
    {
      "epoch": 1.946310891854267,
      "grad_norm": 3.726661443710327,
      "learning_rate": 4.0272390429811565e-05,
      "loss": 0.9849,
      "step": 183850
    },
    {
      "epoch": 1.9468402136342704,
      "grad_norm": 4.00273323059082,
      "learning_rate": 4.026974380690239e-05,
      "loss": 0.9705,
      "step": 183900
    },
    {
      "epoch": 1.9473695354142737,
      "grad_norm": 3.7474262714385986,
      "learning_rate": 4.026715011645141e-05,
      "loss": 0.9837,
      "step": 183950
    },
    {
      "epoch": 1.947898857194277,
      "grad_norm": 3.652052402496338,
      "learning_rate": 4.026450349354224e-05,
      "loss": 0.9519,
      "step": 184000
    },
    {
      "epoch": 1.947898857194277,
      "eval_loss": 0.7956288456916809,
      "eval_runtime": 46.6186,
      "eval_samples_per_second": 3602.21,
      "eval_steps_per_second": 450.292,
      "step": 184000
    },
    {
      "epoch": 1.9484281789742801,
      "grad_norm": 3.752897262573242,
      "learning_rate": 4.0261856870633075e-05,
      "loss": 0.9767,
      "step": 184050
    },
    {
      "epoch": 1.9489575007542834,
      "grad_norm": 3.5492327213287354,
      "learning_rate": 4.02592102477239e-05,
      "loss": 0.9482,
      "step": 184100
    },
    {
      "epoch": 1.9494868225342867,
      "grad_norm": 3.6199748516082764,
      "learning_rate": 4.025656362481474e-05,
      "loss": 0.9703,
      "step": 184150
    },
    {
      "epoch": 1.95001614431429,
      "grad_norm": 3.5322539806365967,
      "learning_rate": 4.025391700190557e-05,
      "loss": 0.9763,
      "step": 184200
    },
    {
      "epoch": 1.9505454660942934,
      "grad_norm": 3.7025439739227295,
      "learning_rate": 4.0251270378996405e-05,
      "loss": 0.9746,
      "step": 184250
    },
    {
      "epoch": 1.9510747878742967,
      "grad_norm": 3.8843255043029785,
      "learning_rate": 4.024862375608723e-05,
      "loss": 0.9854,
      "step": 184300
    },
    {
      "epoch": 1.9516041096543,
      "grad_norm": 3.9894211292266846,
      "learning_rate": 4.0245977133178066e-05,
      "loss": 0.9819,
      "step": 184350
    },
    {
      "epoch": 1.9521334314343033,
      "grad_norm": 3.804255247116089,
      "learning_rate": 4.02433305102689e-05,
      "loss": 0.9698,
      "step": 184400
    },
    {
      "epoch": 1.9526627532143066,
      "grad_norm": 3.7900567054748535,
      "learning_rate": 4.0240683887359735e-05,
      "loss": 0.9773,
      "step": 184450
    },
    {
      "epoch": 1.95319207499431,
      "grad_norm": 3.4096362590789795,
      "learning_rate": 4.023803726445056e-05,
      "loss": 0.9692,
      "step": 184500
    },
    {
      "epoch": 1.95319207499431,
      "eval_loss": 0.7932448387145996,
      "eval_runtime": 46.6269,
      "eval_samples_per_second": 3601.571,
      "eval_steps_per_second": 450.212,
      "step": 184500
    },
    {
      "epoch": 1.9537213967743132,
      "grad_norm": 3.5396580696105957,
      "learning_rate": 4.0235390641541396e-05,
      "loss": 0.9533,
      "step": 184550
    },
    {
      "epoch": 1.9542507185543163,
      "grad_norm": 3.592228889465332,
      "learning_rate": 4.023274401863223e-05,
      "loss": 0.9681,
      "step": 184600
    },
    {
      "epoch": 1.9547800403343196,
      "grad_norm": 3.6876606941223145,
      "learning_rate": 4.023009739572306e-05,
      "loss": 0.9703,
      "step": 184650
    },
    {
      "epoch": 1.955309362114323,
      "grad_norm": 3.691906452178955,
      "learning_rate": 4.022745077281389e-05,
      "loss": 0.9773,
      "step": 184700
    },
    {
      "epoch": 1.9558386838943262,
      "grad_norm": 3.3879809379577637,
      "learning_rate": 4.022480414990472e-05,
      "loss": 0.9616,
      "step": 184750
    },
    {
      "epoch": 1.9563680056743293,
      "grad_norm": 3.793827533721924,
      "learning_rate": 4.022215752699556e-05,
      "loss": 0.9803,
      "step": 184800
    },
    {
      "epoch": 1.9568973274543326,
      "grad_norm": 3.978192090988159,
      "learning_rate": 4.021951090408639e-05,
      "loss": 0.9559,
      "step": 184850
    },
    {
      "epoch": 1.957426649234336,
      "grad_norm": 3.551089286804199,
      "learning_rate": 4.021686428117722e-05,
      "loss": 0.977,
      "step": 184900
    },
    {
      "epoch": 1.9579559710143393,
      "grad_norm": 3.742258071899414,
      "learning_rate": 4.021421765826805e-05,
      "loss": 0.971,
      "step": 184950
    },
    {
      "epoch": 1.9584852927943426,
      "grad_norm": 3.8090415000915527,
      "learning_rate": 4.021157103535889e-05,
      "loss": 0.962,
      "step": 185000
    },
    {
      "epoch": 1.9584852927943426,
      "eval_loss": 0.7922948002815247,
      "eval_runtime": 46.6374,
      "eval_samples_per_second": 3600.759,
      "eval_steps_per_second": 450.111,
      "step": 185000
    },
    {
      "epoch": 1.959014614574346,
      "grad_norm": 3.7405714988708496,
      "learning_rate": 4.020892441244972e-05,
      "loss": 0.9732,
      "step": 185050
    },
    {
      "epoch": 1.9595439363543492,
      "grad_norm": 3.9665775299072266,
      "learning_rate": 4.020627778954055e-05,
      "loss": 0.9563,
      "step": 185100
    },
    {
      "epoch": 1.9600732581343525,
      "grad_norm": 3.713181257247925,
      "learning_rate": 4.020363116663138e-05,
      "loss": 0.9516,
      "step": 185150
    },
    {
      "epoch": 1.9606025799143558,
      "grad_norm": 3.7849559783935547,
      "learning_rate": 4.020098454372221e-05,
      "loss": 0.9763,
      "step": 185200
    },
    {
      "epoch": 1.9611319016943591,
      "grad_norm": 3.177004098892212,
      "learning_rate": 4.0198337920813046e-05,
      "loss": 0.9616,
      "step": 185250
    },
    {
      "epoch": 1.9616612234743624,
      "grad_norm": 3.4839625358581543,
      "learning_rate": 4.0195691297903874e-05,
      "loss": 0.9718,
      "step": 185300
    },
    {
      "epoch": 1.9621905452543655,
      "grad_norm": 3.8545775413513184,
      "learning_rate": 4.019304467499471e-05,
      "loss": 0.967,
      "step": 185350
    },
    {
      "epoch": 1.9627198670343688,
      "grad_norm": 3.5230841636657715,
      "learning_rate": 4.019039805208554e-05,
      "loss": 0.9698,
      "step": 185400
    },
    {
      "epoch": 1.9632491888143722,
      "grad_norm": 3.7815773487091064,
      "learning_rate": 4.0187751429176376e-05,
      "loss": 0.9683,
      "step": 185450
    },
    {
      "epoch": 1.9637785105943755,
      "grad_norm": 3.4871115684509277,
      "learning_rate": 4.01851048062672e-05,
      "loss": 0.9695,
      "step": 185500
    },
    {
      "epoch": 1.9637785105943755,
      "eval_loss": 0.789505660533905,
      "eval_runtime": 46.6087,
      "eval_samples_per_second": 3602.972,
      "eval_steps_per_second": 450.388,
      "step": 185500
    },
    {
      "epoch": 1.9643078323743786,
      "grad_norm": 3.7317657470703125,
      "learning_rate": 4.018245818335804e-05,
      "loss": 0.9625,
      "step": 185550
    },
    {
      "epoch": 1.9648371541543819,
      "grad_norm": 3.983701229095459,
      "learning_rate": 4.017981156044887e-05,
      "loss": 0.9563,
      "step": 185600
    },
    {
      "epoch": 1.9653664759343852,
      "grad_norm": 3.638183116912842,
      "learning_rate": 4.01771649375397e-05,
      "loss": 0.9631,
      "step": 185650
    },
    {
      "epoch": 1.9658957977143885,
      "grad_norm": 3.5976080894470215,
      "learning_rate": 4.017451831463053e-05,
      "loss": 0.9734,
      "step": 185700
    },
    {
      "epoch": 1.9664251194943918,
      "grad_norm": 3.3828670978546143,
      "learning_rate": 4.017187169172136e-05,
      "loss": 0.9661,
      "step": 185750
    },
    {
      "epoch": 1.9669544412743951,
      "grad_norm": 3.7845211029052734,
      "learning_rate": 4.01692250688122e-05,
      "loss": 0.9726,
      "step": 185800
    },
    {
      "epoch": 1.9674837630543984,
      "grad_norm": 3.489670515060425,
      "learning_rate": 4.016657844590303e-05,
      "loss": 0.9591,
      "step": 185850
    },
    {
      "epoch": 1.9680130848344017,
      "grad_norm": 3.6036341190338135,
      "learning_rate": 4.016393182299386e-05,
      "loss": 0.9708,
      "step": 185900
    },
    {
      "epoch": 1.968542406614405,
      "grad_norm": 3.7517459392547607,
      "learning_rate": 4.016133813254288e-05,
      "loss": 0.9849,
      "step": 185950
    },
    {
      "epoch": 1.9690717283944084,
      "grad_norm": 3.9414427280426025,
      "learning_rate": 4.015869150963371e-05,
      "loss": 0.963,
      "step": 186000
    },
    {
      "epoch": 1.9690717283944084,
      "eval_loss": 0.7880328893661499,
      "eval_runtime": 46.6423,
      "eval_samples_per_second": 3600.38,
      "eval_steps_per_second": 450.064,
      "step": 186000
    },
    {
      "epoch": 1.9696010501744117,
      "grad_norm": 3.817128896713257,
      "learning_rate": 4.0156044886724545e-05,
      "loss": 0.9822,
      "step": 186050
    },
    {
      "epoch": 1.9701303719544148,
      "grad_norm": 3.337995767593384,
      "learning_rate": 4.015339826381537e-05,
      "loss": 0.9644,
      "step": 186100
    },
    {
      "epoch": 1.970659693734418,
      "grad_norm": 3.7820775508880615,
      "learning_rate": 4.015075164090621e-05,
      "loss": 0.9709,
      "step": 186150
    },
    {
      "epoch": 1.9711890155144214,
      "grad_norm": 3.255725860595703,
      "learning_rate": 4.014810501799704e-05,
      "loss": 0.9769,
      "step": 186200
    },
    {
      "epoch": 1.9717183372944247,
      "grad_norm": 3.308339834213257,
      "learning_rate": 4.014545839508787e-05,
      "loss": 0.9646,
      "step": 186250
    },
    {
      "epoch": 1.9722476590744278,
      "grad_norm": 3.839139223098755,
      "learning_rate": 4.01428117721787e-05,
      "loss": 0.9713,
      "step": 186300
    },
    {
      "epoch": 1.972776980854431,
      "grad_norm": 3.9214727878570557,
      "learning_rate": 4.014016514926953e-05,
      "loss": 0.9726,
      "step": 186350
    },
    {
      "epoch": 1.9733063026344344,
      "grad_norm": 3.809227228164673,
      "learning_rate": 4.013751852636037e-05,
      "loss": 0.9607,
      "step": 186400
    },
    {
      "epoch": 1.9738356244144377,
      "grad_norm": 3.575744867324829,
      "learning_rate": 4.01348719034512e-05,
      "loss": 0.9767,
      "step": 186450
    },
    {
      "epoch": 1.974364946194441,
      "grad_norm": 3.8884825706481934,
      "learning_rate": 4.013222528054203e-05,
      "loss": 0.9668,
      "step": 186500
    },
    {
      "epoch": 1.974364946194441,
      "eval_loss": 0.7880520224571228,
      "eval_runtime": 46.5157,
      "eval_samples_per_second": 3610.176,
      "eval_steps_per_second": 451.288,
      "step": 186500
    },
    {
      "epoch": 1.9748942679744443,
      "grad_norm": 3.310776948928833,
      "learning_rate": 4.012957865763286e-05,
      "loss": 0.9646,
      "step": 186550
    },
    {
      "epoch": 1.9754235897544477,
      "grad_norm": 3.2637972831726074,
      "learning_rate": 4.012693203472369e-05,
      "loss": 0.9566,
      "step": 186600
    },
    {
      "epoch": 1.975952911534451,
      "grad_norm": 3.64258074760437,
      "learning_rate": 4.012428541181453e-05,
      "loss": 0.9609,
      "step": 186650
    },
    {
      "epoch": 1.9764822333144543,
      "grad_norm": 3.7736713886260986,
      "learning_rate": 4.0121638788905355e-05,
      "loss": 0.9687,
      "step": 186700
    },
    {
      "epoch": 1.9770115550944576,
      "grad_norm": 3.5799131393432617,
      "learning_rate": 4.011899216599619e-05,
      "loss": 0.9659,
      "step": 186750
    },
    {
      "epoch": 1.977540876874461,
      "grad_norm": 3.8366215229034424,
      "learning_rate": 4.011634554308702e-05,
      "loss": 0.9825,
      "step": 186800
    },
    {
      "epoch": 1.978070198654464,
      "grad_norm": 3.706773519515991,
      "learning_rate": 4.011369892017786e-05,
      "loss": 0.9722,
      "step": 186850
    },
    {
      "epoch": 1.9785995204344673,
      "grad_norm": 3.391214609146118,
      "learning_rate": 4.0111052297268684e-05,
      "loss": 0.9646,
      "step": 186900
    },
    {
      "epoch": 1.9791288422144706,
      "grad_norm": 3.944270133972168,
      "learning_rate": 4.010840567435952e-05,
      "loss": 0.9608,
      "step": 186950
    },
    {
      "epoch": 1.979658163994474,
      "grad_norm": 4.465926170349121,
      "learning_rate": 4.010575905145035e-05,
      "loss": 0.9634,
      "step": 187000
    },
    {
      "epoch": 1.979658163994474,
      "eval_loss": 0.7839846611022949,
      "eval_runtime": 46.5999,
      "eval_samples_per_second": 3603.657,
      "eval_steps_per_second": 450.473,
      "step": 187000
    },
    {
      "epoch": 1.980187485774477,
      "grad_norm": 3.7472198009490967,
      "learning_rate": 4.010311242854119e-05,
      "loss": 0.9745,
      "step": 187050
    },
    {
      "epoch": 1.9807168075544803,
      "grad_norm": 3.309782028198242,
      "learning_rate": 4.0100465805632014e-05,
      "loss": 0.9548,
      "step": 187100
    },
    {
      "epoch": 1.9812461293344836,
      "grad_norm": 3.492610454559326,
      "learning_rate": 4.009781918272285e-05,
      "loss": 0.9668,
      "step": 187150
    },
    {
      "epoch": 1.981775451114487,
      "grad_norm": 3.5996248722076416,
      "learning_rate": 4.009517255981368e-05,
      "loss": 0.9747,
      "step": 187200
    },
    {
      "epoch": 1.9823047728944903,
      "grad_norm": 3.430398941040039,
      "learning_rate": 4.009252593690451e-05,
      "loss": 0.9613,
      "step": 187250
    },
    {
      "epoch": 1.9828340946744936,
      "grad_norm": 3.6871120929718018,
      "learning_rate": 4.0089879313995344e-05,
      "loss": 0.964,
      "step": 187300
    },
    {
      "epoch": 1.9833634164544969,
      "grad_norm": 3.6841514110565186,
      "learning_rate": 4.008723269108617e-05,
      "loss": 0.9646,
      "step": 187350
    },
    {
      "epoch": 1.9838927382345002,
      "grad_norm": 3.437300682067871,
      "learning_rate": 4.008458606817701e-05,
      "loss": 0.976,
      "step": 187400
    },
    {
      "epoch": 1.9844220600145035,
      "grad_norm": 3.4464385509490967,
      "learning_rate": 4.008193944526784e-05,
      "loss": 0.9676,
      "step": 187450
    },
    {
      "epoch": 1.9849513817945068,
      "grad_norm": 3.725463628768921,
      "learning_rate": 4.007929282235867e-05,
      "loss": 0.9591,
      "step": 187500
    },
    {
      "epoch": 1.9849513817945068,
      "eval_loss": 0.787514328956604,
      "eval_runtime": 46.5691,
      "eval_samples_per_second": 3606.039,
      "eval_steps_per_second": 450.771,
      "step": 187500
    },
    {
      "epoch": 1.9854807035745101,
      "grad_norm": 3.744755268096924,
      "learning_rate": 4.00766461994495e-05,
      "loss": 0.9629,
      "step": 187550
    },
    {
      "epoch": 1.9860100253545132,
      "grad_norm": 3.619699716567993,
      "learning_rate": 4.007399957654034e-05,
      "loss": 0.9597,
      "step": 187600
    },
    {
      "epoch": 1.9865393471345165,
      "grad_norm": 3.5536303520202637,
      "learning_rate": 4.007135295363117e-05,
      "loss": 0.9578,
      "step": 187650
    },
    {
      "epoch": 1.9870686689145198,
      "grad_norm": 3.664975881576538,
      "learning_rate": 4.0068706330722e-05,
      "loss": 0.9603,
      "step": 187700
    },
    {
      "epoch": 1.9875979906945231,
      "grad_norm": 3.480417013168335,
      "learning_rate": 4.006605970781283e-05,
      "loss": 0.972,
      "step": 187750
    },
    {
      "epoch": 1.9881273124745262,
      "grad_norm": 3.653877019882202,
      "learning_rate": 4.0063413084903664e-05,
      "loss": 0.9573,
      "step": 187800
    },
    {
      "epoch": 1.9886566342545295,
      "grad_norm": 3.660311222076416,
      "learning_rate": 4.00607664619945e-05,
      "loss": 0.9647,
      "step": 187850
    },
    {
      "epoch": 1.9891859560345329,
      "grad_norm": 3.8816945552825928,
      "learning_rate": 4.0058119839085326e-05,
      "loss": 0.9742,
      "step": 187900
    },
    {
      "epoch": 1.9897152778145362,
      "grad_norm": 3.984531879425049,
      "learning_rate": 4.005552614863434e-05,
      "loss": 0.9649,
      "step": 187950
    },
    {
      "epoch": 1.9902445995945395,
      "grad_norm": 3.737771511077881,
      "learning_rate": 4.005287952572518e-05,
      "loss": 0.9769,
      "step": 188000
    },
    {
      "epoch": 1.9902445995945395,
      "eval_loss": 0.7844350934028625,
      "eval_runtime": 46.5483,
      "eval_samples_per_second": 3607.653,
      "eval_steps_per_second": 450.973,
      "step": 188000
    },
    {
      "epoch": 1.9907739213745428,
      "grad_norm": 3.419478416442871,
      "learning_rate": 4.005023290281601e-05,
      "loss": 0.9478,
      "step": 188050
    },
    {
      "epoch": 1.991303243154546,
      "grad_norm": 3.577831983566284,
      "learning_rate": 4.004758627990684e-05,
      "loss": 0.9688,
      "step": 188100
    },
    {
      "epoch": 1.9918325649345494,
      "grad_norm": 3.573949098587036,
      "learning_rate": 4.004493965699767e-05,
      "loss": 0.9643,
      "step": 188150
    },
    {
      "epoch": 1.9923618867145527,
      "grad_norm": 3.5552332401275635,
      "learning_rate": 4.0042293034088504e-05,
      "loss": 0.9671,
      "step": 188200
    },
    {
      "epoch": 1.992891208494556,
      "grad_norm": 3.8857715129852295,
      "learning_rate": 4.003964641117934e-05,
      "loss": 0.9503,
      "step": 188250
    },
    {
      "epoch": 1.9934205302745593,
      "grad_norm": 3.586833953857422,
      "learning_rate": 4.0036999788270166e-05,
      "loss": 0.9692,
      "step": 188300
    },
    {
      "epoch": 1.9939498520545627,
      "grad_norm": 3.7308483123779297,
      "learning_rate": 4.0034353165361e-05,
      "loss": 0.9637,
      "step": 188350
    },
    {
      "epoch": 1.9944791738345657,
      "grad_norm": 3.6633007526397705,
      "learning_rate": 4.0031706542451834e-05,
      "loss": 0.9603,
      "step": 188400
    },
    {
      "epoch": 1.995008495614569,
      "grad_norm": 3.421553134918213,
      "learning_rate": 4.002905991954267e-05,
      "loss": 0.9653,
      "step": 188450
    },
    {
      "epoch": 1.9955378173945724,
      "grad_norm": 3.5204474925994873,
      "learning_rate": 4.0026413296633495e-05,
      "loss": 0.9636,
      "step": 188500
    },
    {
      "epoch": 1.9955378173945724,
      "eval_loss": 0.7808751463890076,
      "eval_runtime": 46.5892,
      "eval_samples_per_second": 3604.484,
      "eval_steps_per_second": 450.577,
      "step": 188500
    },
    {
      "epoch": 1.9960671391745755,
      "grad_norm": 3.455082893371582,
      "learning_rate": 4.002376667372433e-05,
      "loss": 0.9442,
      "step": 188550
    },
    {
      "epoch": 1.9965964609545788,
      "grad_norm": 3.7850544452667236,
      "learning_rate": 4.0021120050815163e-05,
      "loss": 0.9383,
      "step": 188600
    },
    {
      "epoch": 1.997125782734582,
      "grad_norm": 3.410151481628418,
      "learning_rate": 4.0018473427906e-05,
      "loss": 0.9509,
      "step": 188650
    },
    {
      "epoch": 1.9976551045145854,
      "grad_norm": 4.067887783050537,
      "learning_rate": 4.0015826804996825e-05,
      "loss": 0.9506,
      "step": 188700
    },
    {
      "epoch": 1.9981844262945887,
      "grad_norm": 3.9025187492370605,
      "learning_rate": 4.001318018208766e-05,
      "loss": 0.9624,
      "step": 188750
    },
    {
      "epoch": 1.998713748074592,
      "grad_norm": 3.504193067550659,
      "learning_rate": 4.001053355917849e-05,
      "loss": 0.9663,
      "step": 188800
    },
    {
      "epoch": 1.9992430698545953,
      "grad_norm": 3.287710666656494,
      "learning_rate": 4.000788693626932e-05,
      "loss": 0.9568,
      "step": 188850
    },
    {
      "epoch": 1.9997723916345986,
      "grad_norm": 3.630932092666626,
      "learning_rate": 4.0005240313360154e-05,
      "loss": 0.9824,
      "step": 188900
    },
    {
      "epoch": 2.000296420196802,
      "grad_norm": 3.8192977905273438,
      "learning_rate": 4.000264662290917e-05,
      "loss": 0.9348,
      "step": 188950
    },
    {
      "epoch": 2.000825741976805,
      "grad_norm": 3.761899948120117,
      "learning_rate": 4e-05,
      "loss": 0.9478,
      "step": 189000
    },
    {
      "epoch": 2.000825741976805,
      "eval_loss": 0.778014063835144,
      "eval_runtime": 46.5681,
      "eval_samples_per_second": 3606.114,
      "eval_steps_per_second": 450.78,
      "step": 189000
    },
    {
      "epoch": 2.0013550637568085,
      "grad_norm": 3.683892250061035,
      "learning_rate": 3.999735337709084e-05,
      "loss": 0.9523,
      "step": 189050
    },
    {
      "epoch": 2.001884385536812,
      "grad_norm": 3.6451427936553955,
      "learning_rate": 3.9994706754181665e-05,
      "loss": 0.9661,
      "step": 189100
    },
    {
      "epoch": 2.002413707316815,
      "grad_norm": 4.048081874847412,
      "learning_rate": 3.99920601312725e-05,
      "loss": 0.9724,
      "step": 189150
    },
    {
      "epoch": 2.0029430290968184,
      "grad_norm": 3.932878255844116,
      "learning_rate": 3.998941350836333e-05,
      "loss": 0.9563,
      "step": 189200
    },
    {
      "epoch": 2.0034723508768217,
      "grad_norm": 4.062744140625,
      "learning_rate": 3.998676688545416e-05,
      "loss": 0.9604,
      "step": 189250
    },
    {
      "epoch": 2.0040016726568246,
      "grad_norm": 4.0572509765625,
      "learning_rate": 3.9984120262544994e-05,
      "loss": 0.9485,
      "step": 189300
    },
    {
      "epoch": 2.004530994436828,
      "grad_norm": 3.4585886001586914,
      "learning_rate": 3.998147363963582e-05,
      "loss": 0.9683,
      "step": 189350
    },
    {
      "epoch": 2.0050603162168312,
      "grad_norm": 3.664247989654541,
      "learning_rate": 3.997882701672666e-05,
      "loss": 0.9486,
      "step": 189400
    },
    {
      "epoch": 2.0055896379968345,
      "grad_norm": 3.8676891326904297,
      "learning_rate": 3.997618039381749e-05,
      "loss": 0.9677,
      "step": 189450
    },
    {
      "epoch": 2.006118959776838,
      "grad_norm": 3.988842248916626,
      "learning_rate": 3.9973533770908324e-05,
      "loss": 0.9474,
      "step": 189500
    },
    {
      "epoch": 2.006118959776838,
      "eval_loss": 0.7790902853012085,
      "eval_runtime": 46.5823,
      "eval_samples_per_second": 3605.02,
      "eval_steps_per_second": 450.644,
      "step": 189500
    },
    {
      "epoch": 2.006648281556841,
      "grad_norm": 3.5858113765716553,
      "learning_rate": 3.997088714799915e-05,
      "loss": 0.9215,
      "step": 189550
    },
    {
      "epoch": 2.0071776033368445,
      "grad_norm": 4.030597686767578,
      "learning_rate": 3.996824052508999e-05,
      "loss": 0.9561,
      "step": 189600
    },
    {
      "epoch": 2.007706925116848,
      "grad_norm": 3.979810953140259,
      "learning_rate": 3.996559390218082e-05,
      "loss": 0.9566,
      "step": 189650
    },
    {
      "epoch": 2.008236246896851,
      "grad_norm": 3.601276159286499,
      "learning_rate": 3.9962947279271654e-05,
      "loss": 0.9546,
      "step": 189700
    },
    {
      "epoch": 2.0087655686768544,
      "grad_norm": 3.7238919734954834,
      "learning_rate": 3.996030065636248e-05,
      "loss": 0.9607,
      "step": 189750
    },
    {
      "epoch": 2.0092948904568577,
      "grad_norm": 4.003591060638428,
      "learning_rate": 3.9957654033453315e-05,
      "loss": 0.9596,
      "step": 189800
    },
    {
      "epoch": 2.009824212236861,
      "grad_norm": 3.3887128829956055,
      "learning_rate": 3.995500741054415e-05,
      "loss": 0.9486,
      "step": 189850
    },
    {
      "epoch": 2.0103535340168643,
      "grad_norm": 3.597482204437256,
      "learning_rate": 3.9952360787634976e-05,
      "loss": 0.9626,
      "step": 189900
    },
    {
      "epoch": 2.0108828557968677,
      "grad_norm": 3.622063159942627,
      "learning_rate": 3.994971416472581e-05,
      "loss": 0.9527,
      "step": 189950
    },
    {
      "epoch": 2.011412177576871,
      "grad_norm": 3.9675090312957764,
      "learning_rate": 3.9947067541816645e-05,
      "loss": 0.9505,
      "step": 190000
    },
    {
      "epoch": 2.011412177576871,
      "eval_loss": 0.7783104181289673,
      "eval_runtime": 46.5389,
      "eval_samples_per_second": 3608.38,
      "eval_steps_per_second": 451.064,
      "step": 190000
    },
    {
      "epoch": 2.011941499356874,
      "grad_norm": 3.6144192218780518,
      "learning_rate": 3.994442091890748e-05,
      "loss": 0.9482,
      "step": 190050
    },
    {
      "epoch": 2.012470821136877,
      "grad_norm": 3.8486948013305664,
      "learning_rate": 3.9941774295998306e-05,
      "loss": 0.9374,
      "step": 190100
    },
    {
      "epoch": 2.0130001429168805,
      "grad_norm": 3.1845669746398926,
      "learning_rate": 3.993912767308914e-05,
      "loss": 0.9639,
      "step": 190150
    },
    {
      "epoch": 2.0135294646968838,
      "grad_norm": 4.1971116065979,
      "learning_rate": 3.9936481050179974e-05,
      "loss": 0.9464,
      "step": 190200
    },
    {
      "epoch": 2.014058786476887,
      "grad_norm": 3.3268494606018066,
      "learning_rate": 3.993383442727081e-05,
      "loss": 0.9436,
      "step": 190250
    },
    {
      "epoch": 2.0145881082568904,
      "grad_norm": 3.585749626159668,
      "learning_rate": 3.9931187804361636e-05,
      "loss": 0.959,
      "step": 190300
    },
    {
      "epoch": 2.0151174300368937,
      "grad_norm": 3.5084333419799805,
      "learning_rate": 3.992854118145247e-05,
      "loss": 0.9558,
      "step": 190350
    },
    {
      "epoch": 2.015646751816897,
      "grad_norm": 3.6533844470977783,
      "learning_rate": 3.9925894558543304e-05,
      "loss": 0.9649,
      "step": 190400
    },
    {
      "epoch": 2.0161760735969003,
      "grad_norm": 3.5988340377807617,
      "learning_rate": 3.992324793563413e-05,
      "loss": 0.9476,
      "step": 190450
    },
    {
      "epoch": 2.0167053953769036,
      "grad_norm": 3.8262882232666016,
      "learning_rate": 3.9920601312724965e-05,
      "loss": 0.9523,
      "step": 190500
    },
    {
      "epoch": 2.0167053953769036,
      "eval_loss": 0.775757372379303,
      "eval_runtime": 46.6183,
      "eval_samples_per_second": 3602.233,
      "eval_steps_per_second": 450.295,
      "step": 190500
    },
    {
      "epoch": 2.017234717156907,
      "grad_norm": 3.646343469619751,
      "learning_rate": 3.991795468981579e-05,
      "loss": 0.9354,
      "step": 190550
    },
    {
      "epoch": 2.0177640389369103,
      "grad_norm": 3.7662200927734375,
      "learning_rate": 3.9915308066906633e-05,
      "loss": 0.9524,
      "step": 190600
    },
    {
      "epoch": 2.0182933607169136,
      "grad_norm": 3.41702938079834,
      "learning_rate": 3.991266144399746e-05,
      "loss": 0.9667,
      "step": 190650
    },
    {
      "epoch": 2.018822682496917,
      "grad_norm": 3.698002576828003,
      "learning_rate": 3.9910014821088295e-05,
      "loss": 0.9565,
      "step": 190700
    },
    {
      "epoch": 2.01935200427692,
      "grad_norm": 3.584784984588623,
      "learning_rate": 3.990736819817912e-05,
      "loss": 0.9521,
      "step": 190750
    },
    {
      "epoch": 2.019881326056923,
      "grad_norm": 3.4240643978118896,
      "learning_rate": 3.990472157526996e-05,
      "loss": 0.9406,
      "step": 190800
    },
    {
      "epoch": 2.0204106478369264,
      "grad_norm": 3.1883392333984375,
      "learning_rate": 3.990207495236079e-05,
      "loss": 0.9412,
      "step": 190850
    },
    {
      "epoch": 2.0209399696169297,
      "grad_norm": 3.7187752723693848,
      "learning_rate": 3.9899428329451625e-05,
      "loss": 0.9328,
      "step": 190900
    },
    {
      "epoch": 2.021469291396933,
      "grad_norm": 3.624451160430908,
      "learning_rate": 3.989678170654245e-05,
      "loss": 0.942,
      "step": 190950
    },
    {
      "epoch": 2.0219986131769363,
      "grad_norm": 3.847377061843872,
      "learning_rate": 3.9894135083633286e-05,
      "loss": 0.9545,
      "step": 191000
    },
    {
      "epoch": 2.0219986131769363,
      "eval_loss": 0.7738206386566162,
      "eval_runtime": 46.6194,
      "eval_samples_per_second": 3602.145,
      "eval_steps_per_second": 450.284,
      "step": 191000
    },
    {
      "epoch": 2.0225279349569396,
      "grad_norm": 3.703728675842285,
      "learning_rate": 3.989148846072412e-05,
      "loss": 0.9413,
      "step": 191050
    },
    {
      "epoch": 2.023057256736943,
      "grad_norm": 3.315534830093384,
      "learning_rate": 3.988884183781495e-05,
      "loss": 0.9597,
      "step": 191100
    },
    {
      "epoch": 2.0235865785169462,
      "grad_norm": 3.667436122894287,
      "learning_rate": 3.988619521490578e-05,
      "loss": 0.9515,
      "step": 191150
    },
    {
      "epoch": 2.0241159002969495,
      "grad_norm": 3.889394998550415,
      "learning_rate": 3.9883548591996616e-05,
      "loss": 0.956,
      "step": 191200
    },
    {
      "epoch": 2.024645222076953,
      "grad_norm": 3.5501952171325684,
      "learning_rate": 3.988090196908745e-05,
      "loss": 0.9658,
      "step": 191250
    },
    {
      "epoch": 2.025174543856956,
      "grad_norm": 3.555152177810669,
      "learning_rate": 3.987825534617828e-05,
      "loss": 0.9549,
      "step": 191300
    },
    {
      "epoch": 2.0257038656369595,
      "grad_norm": 3.8146536350250244,
      "learning_rate": 3.987560872326911e-05,
      "loss": 0.9512,
      "step": 191350
    },
    {
      "epoch": 2.026233187416963,
      "grad_norm": 3.9122910499572754,
      "learning_rate": 3.9872962100359945e-05,
      "loss": 0.9659,
      "step": 191400
    },
    {
      "epoch": 2.026762509196966,
      "grad_norm": 3.8207061290740967,
      "learning_rate": 3.987031547745077e-05,
      "loss": 0.9537,
      "step": 191450
    },
    {
      "epoch": 2.0272918309769694,
      "grad_norm": 3.78853440284729,
      "learning_rate": 3.986766885454161e-05,
      "loss": 0.9656,
      "step": 191500
    },
    {
      "epoch": 2.0272918309769694,
      "eval_loss": 0.7763471007347107,
      "eval_runtime": 46.6015,
      "eval_samples_per_second": 3603.536,
      "eval_steps_per_second": 450.458,
      "step": 191500
    },
    {
      "epoch": 2.0278211527569723,
      "grad_norm": 3.610168695449829,
      "learning_rate": 3.9865022231632434e-05,
      "loss": 0.9459,
      "step": 191550
    },
    {
      "epoch": 2.0283504745369756,
      "grad_norm": 3.559671401977539,
      "learning_rate": 3.9862375608723275e-05,
      "loss": 0.9499,
      "step": 191600
    },
    {
      "epoch": 2.028879796316979,
      "grad_norm": 3.922483205795288,
      "learning_rate": 3.98597289858141e-05,
      "loss": 0.9755,
      "step": 191650
    },
    {
      "epoch": 2.029409118096982,
      "grad_norm": 3.7251951694488525,
      "learning_rate": 3.9857082362904936e-05,
      "loss": 0.9487,
      "step": 191700
    },
    {
      "epoch": 2.0299384398769855,
      "grad_norm": 3.812102794647217,
      "learning_rate": 3.9854435739995764e-05,
      "loss": 0.9607,
      "step": 191750
    },
    {
      "epoch": 2.030467761656989,
      "grad_norm": 3.623908519744873,
      "learning_rate": 3.9851789117086604e-05,
      "loss": 0.9572,
      "step": 191800
    },
    {
      "epoch": 2.030997083436992,
      "grad_norm": 3.4701292514801025,
      "learning_rate": 3.984914249417743e-05,
      "loss": 0.9422,
      "step": 191850
    },
    {
      "epoch": 2.0315264052169955,
      "grad_norm": 3.962535858154297,
      "learning_rate": 3.9846495871268266e-05,
      "loss": 0.9636,
      "step": 191900
    },
    {
      "epoch": 2.0320557269969988,
      "grad_norm": 3.8421823978424072,
      "learning_rate": 3.984384924835909e-05,
      "loss": 0.9469,
      "step": 191950
    },
    {
      "epoch": 2.032585048777002,
      "grad_norm": 3.441108226776123,
      "learning_rate": 3.984120262544993e-05,
      "loss": 0.9526,
      "step": 192000
    },
    {
      "epoch": 2.032585048777002,
      "eval_loss": 0.7732966542243958,
      "eval_runtime": 46.6023,
      "eval_samples_per_second": 3603.467,
      "eval_steps_per_second": 450.45,
      "step": 192000
    },
    {
      "epoch": 2.0331143705570054,
      "grad_norm": 3.634517192840576,
      "learning_rate": 3.983855600254076e-05,
      "loss": 0.9492,
      "step": 192050
    },
    {
      "epoch": 2.0336436923370087,
      "grad_norm": 3.9700541496276855,
      "learning_rate": 3.983590937963159e-05,
      "loss": 0.9557,
      "step": 192100
    },
    {
      "epoch": 2.034173014117012,
      "grad_norm": 3.893354892730713,
      "learning_rate": 3.983326275672242e-05,
      "loss": 0.9632,
      "step": 192150
    },
    {
      "epoch": 2.0347023358970153,
      "grad_norm": 3.757072925567627,
      "learning_rate": 3.983061613381326e-05,
      "loss": 0.9413,
      "step": 192200
    },
    {
      "epoch": 2.0352316576770186,
      "grad_norm": 3.8060333728790283,
      "learning_rate": 3.982796951090409e-05,
      "loss": 0.9409,
      "step": 192250
    },
    {
      "epoch": 2.0357609794570215,
      "grad_norm": 3.571392297744751,
      "learning_rate": 3.982532288799492e-05,
      "loss": 0.9517,
      "step": 192300
    },
    {
      "epoch": 2.036290301237025,
      "grad_norm": 3.7609610557556152,
      "learning_rate": 3.982267626508575e-05,
      "loss": 0.9348,
      "step": 192350
    },
    {
      "epoch": 2.036819623017028,
      "grad_norm": 3.620706558227539,
      "learning_rate": 3.9820029642176587e-05,
      "loss": 0.9652,
      "step": 192400
    },
    {
      "epoch": 2.0373489447970314,
      "grad_norm": 3.7900946140289307,
      "learning_rate": 3.981738301926742e-05,
      "loss": 0.9625,
      "step": 192450
    },
    {
      "epoch": 2.0378782665770347,
      "grad_norm": 3.685242176055908,
      "learning_rate": 3.981473639635825e-05,
      "loss": 0.9771,
      "step": 192500
    },
    {
      "epoch": 2.0378782665770347,
      "eval_loss": 0.7729151844978333,
      "eval_runtime": 46.5149,
      "eval_samples_per_second": 3610.239,
      "eval_steps_per_second": 451.296,
      "step": 192500
    },
    {
      "epoch": 2.038407588357038,
      "grad_norm": 3.9342117309570312,
      "learning_rate": 3.981208977344908e-05,
      "loss": 0.9557,
      "step": 192550
    },
    {
      "epoch": 2.0389369101370414,
      "grad_norm": 3.9600720405578613,
      "learning_rate": 3.9809443150539916e-05,
      "loss": 0.9489,
      "step": 192600
    },
    {
      "epoch": 2.0394662319170447,
      "grad_norm": 3.5376529693603516,
      "learning_rate": 3.9806796527630743e-05,
      "loss": 0.9465,
      "step": 192650
    },
    {
      "epoch": 2.039995553697048,
      "grad_norm": 3.57138991355896,
      "learning_rate": 3.980420283717976e-05,
      "loss": 0.9563,
      "step": 192700
    },
    {
      "epoch": 2.0405248754770513,
      "grad_norm": 3.4090917110443115,
      "learning_rate": 3.980155621427059e-05,
      "loss": 0.9435,
      "step": 192750
    },
    {
      "epoch": 2.0410541972570546,
      "grad_norm": 3.4179723262786865,
      "learning_rate": 3.9798909591361426e-05,
      "loss": 0.9581,
      "step": 192800
    },
    {
      "epoch": 2.041583519037058,
      "grad_norm": 3.830134153366089,
      "learning_rate": 3.979626296845226e-05,
      "loss": 0.9496,
      "step": 192850
    },
    {
      "epoch": 2.0421128408170612,
      "grad_norm": 3.6178700923919678,
      "learning_rate": 3.979361634554309e-05,
      "loss": 0.9629,
      "step": 192900
    },
    {
      "epoch": 2.0426421625970645,
      "grad_norm": 3.4650659561157227,
      "learning_rate": 3.979096972263392e-05,
      "loss": 0.9657,
      "step": 192950
    },
    {
      "epoch": 2.043171484377068,
      "grad_norm": 3.5921523571014404,
      "learning_rate": 3.9788323099724756e-05,
      "loss": 0.9529,
      "step": 193000
    },
    {
      "epoch": 2.043171484377068,
      "eval_loss": 0.7732131481170654,
      "eval_runtime": 46.5847,
      "eval_samples_per_second": 3604.835,
      "eval_steps_per_second": 450.621,
      "step": 193000
    },
    {
      "epoch": 2.043700806157071,
      "grad_norm": 4.143731117248535,
      "learning_rate": 3.978567647681558e-05,
      "loss": 0.9447,
      "step": 193050
    },
    {
      "epoch": 2.044230127937074,
      "grad_norm": 3.6981236934661865,
      "learning_rate": 3.978302985390642e-05,
      "loss": 0.9523,
      "step": 193100
    },
    {
      "epoch": 2.0447594497170773,
      "grad_norm": 3.8153085708618164,
      "learning_rate": 3.9780383230997245e-05,
      "loss": 0.9559,
      "step": 193150
    },
    {
      "epoch": 2.0452887714970807,
      "grad_norm": 3.4206526279449463,
      "learning_rate": 3.9777736608088086e-05,
      "loss": 0.9405,
      "step": 193200
    },
    {
      "epoch": 2.045818093277084,
      "grad_norm": 3.7597930431365967,
      "learning_rate": 3.977508998517891e-05,
      "loss": 0.9501,
      "step": 193250
    },
    {
      "epoch": 2.0463474150570873,
      "grad_norm": 3.842703342437744,
      "learning_rate": 3.977244336226975e-05,
      "loss": 0.9307,
      "step": 193300
    },
    {
      "epoch": 2.0468767368370906,
      "grad_norm": 3.6448287963867188,
      "learning_rate": 3.9769796739360574e-05,
      "loss": 0.9483,
      "step": 193350
    },
    {
      "epoch": 2.047406058617094,
      "grad_norm": 3.905501127243042,
      "learning_rate": 3.9767150116451415e-05,
      "loss": 0.9511,
      "step": 193400
    },
    {
      "epoch": 2.047935380397097,
      "grad_norm": 3.776243209838867,
      "learning_rate": 3.976450349354224e-05,
      "loss": 0.9502,
      "step": 193450
    },
    {
      "epoch": 2.0484647021771005,
      "grad_norm": 3.4829766750335693,
      "learning_rate": 3.976185687063308e-05,
      "loss": 0.9408,
      "step": 193500
    },
    {
      "epoch": 2.0484647021771005,
      "eval_loss": 0.770880937576294,
      "eval_runtime": 46.5637,
      "eval_samples_per_second": 3606.456,
      "eval_steps_per_second": 450.823,
      "step": 193500
    },
    {
      "epoch": 2.048994023957104,
      "grad_norm": 3.9181478023529053,
      "learning_rate": 3.9759210247723904e-05,
      "loss": 0.9527,
      "step": 193550
    },
    {
      "epoch": 2.049523345737107,
      "grad_norm": 3.833153247833252,
      "learning_rate": 3.975656362481474e-05,
      "loss": 0.9505,
      "step": 193600
    },
    {
      "epoch": 2.0500526675171105,
      "grad_norm": 4.173313140869141,
      "learning_rate": 3.975391700190557e-05,
      "loss": 0.947,
      "step": 193650
    },
    {
      "epoch": 2.0505819892971138,
      "grad_norm": 3.8336918354034424,
      "learning_rate": 3.97512703789964e-05,
      "loss": 0.9656,
      "step": 193700
    },
    {
      "epoch": 2.051111311077117,
      "grad_norm": 3.714797258377075,
      "learning_rate": 3.9748623756087234e-05,
      "loss": 0.9537,
      "step": 193750
    },
    {
      "epoch": 2.0516406328571204,
      "grad_norm": 3.591210126876831,
      "learning_rate": 3.974597713317806e-05,
      "loss": 0.9437,
      "step": 193800
    },
    {
      "epoch": 2.0521699546371233,
      "grad_norm": 4.06166410446167,
      "learning_rate": 3.97433305102689e-05,
      "loss": 0.9547,
      "step": 193850
    },
    {
      "epoch": 2.0526992764171266,
      "grad_norm": 3.631474256515503,
      "learning_rate": 3.974068388735973e-05,
      "loss": 0.9437,
      "step": 193900
    },
    {
      "epoch": 2.05322859819713,
      "grad_norm": 3.8090224266052246,
      "learning_rate": 3.973803726445056e-05,
      "loss": 0.9406,
      "step": 193950
    },
    {
      "epoch": 2.053757919977133,
      "grad_norm": 3.70729923248291,
      "learning_rate": 3.973539064154139e-05,
      "loss": 0.9376,
      "step": 194000
    },
    {
      "epoch": 2.053757919977133,
      "eval_loss": 0.768956184387207,
      "eval_runtime": 46.5769,
      "eval_samples_per_second": 3605.432,
      "eval_steps_per_second": 450.695,
      "step": 194000
    },
    {
      "epoch": 2.0542872417571365,
      "grad_norm": 3.6222450733184814,
      "learning_rate": 3.973274401863223e-05,
      "loss": 0.9511,
      "step": 194050
    },
    {
      "epoch": 2.05481656353714,
      "grad_norm": 3.590954542160034,
      "learning_rate": 3.973009739572306e-05,
      "loss": 0.9534,
      "step": 194100
    },
    {
      "epoch": 2.055345885317143,
      "grad_norm": 3.7723124027252197,
      "learning_rate": 3.972745077281389e-05,
      "loss": 0.9442,
      "step": 194150
    },
    {
      "epoch": 2.0558752070971464,
      "grad_norm": 3.417581796646118,
      "learning_rate": 3.972480414990472e-05,
      "loss": 0.9677,
      "step": 194200
    },
    {
      "epoch": 2.0564045288771498,
      "grad_norm": 3.4194111824035645,
      "learning_rate": 3.9722157526995554e-05,
      "loss": 0.9329,
      "step": 194250
    },
    {
      "epoch": 2.056933850657153,
      "grad_norm": 4.139132022857666,
      "learning_rate": 3.971951090408639e-05,
      "loss": 0.944,
      "step": 194300
    },
    {
      "epoch": 2.0574631724371564,
      "grad_norm": 3.542517900466919,
      "learning_rate": 3.9716864281177216e-05,
      "loss": 0.9546,
      "step": 194350
    },
    {
      "epoch": 2.0579924942171597,
      "grad_norm": 3.6766090393066406,
      "learning_rate": 3.971421765826805e-05,
      "loss": 0.9497,
      "step": 194400
    },
    {
      "epoch": 2.058521815997163,
      "grad_norm": 4.044068336486816,
      "learning_rate": 3.9711571035358884e-05,
      "loss": 0.9523,
      "step": 194450
    },
    {
      "epoch": 2.0590511377771663,
      "grad_norm": 3.5316851139068604,
      "learning_rate": 3.970892441244972e-05,
      "loss": 0.9642,
      "step": 194500
    },
    {
      "epoch": 2.0590511377771663,
      "eval_loss": 0.7657791972160339,
      "eval_runtime": 46.6333,
      "eval_samples_per_second": 3601.072,
      "eval_steps_per_second": 450.15,
      "step": 194500
    },
    {
      "epoch": 2.0595804595571696,
      "grad_norm": 3.556405544281006,
      "learning_rate": 3.9706277789540545e-05,
      "loss": 0.9416,
      "step": 194550
    },
    {
      "epoch": 2.0601097813371725,
      "grad_norm": 4.011841297149658,
      "learning_rate": 3.970363116663138e-05,
      "loss": 0.9367,
      "step": 194600
    },
    {
      "epoch": 2.060639103117176,
      "grad_norm": 3.5717103481292725,
      "learning_rate": 3.9700984543722214e-05,
      "loss": 0.9451,
      "step": 194650
    },
    {
      "epoch": 2.061168424897179,
      "grad_norm": 3.721181631088257,
      "learning_rate": 3.969833792081305e-05,
      "loss": 0.9138,
      "step": 194700
    },
    {
      "epoch": 2.0616977466771824,
      "grad_norm": 3.652395486831665,
      "learning_rate": 3.9695691297903875e-05,
      "loss": 0.951,
      "step": 194750
    },
    {
      "epoch": 2.0622270684571857,
      "grad_norm": 4.031022071838379,
      "learning_rate": 3.969304467499471e-05,
      "loss": 0.9591,
      "step": 194800
    },
    {
      "epoch": 2.062756390237189,
      "grad_norm": 3.431926965713501,
      "learning_rate": 3.969039805208554e-05,
      "loss": 0.944,
      "step": 194850
    },
    {
      "epoch": 2.0632857120171924,
      "grad_norm": 3.6653640270233154,
      "learning_rate": 3.968775142917637e-05,
      "loss": 0.9576,
      "step": 194900
    },
    {
      "epoch": 2.0638150337971957,
      "grad_norm": 3.6409895420074463,
      "learning_rate": 3.9685104806267205e-05,
      "loss": 0.953,
      "step": 194950
    },
    {
      "epoch": 2.064344355577199,
      "grad_norm": 3.7539491653442383,
      "learning_rate": 3.968245818335803e-05,
      "loss": 0.954,
      "step": 195000
    },
    {
      "epoch": 2.064344355577199,
      "eval_loss": 0.7663686871528625,
      "eval_runtime": 46.5021,
      "eval_samples_per_second": 3611.232,
      "eval_steps_per_second": 451.42,
      "step": 195000
    },
    {
      "epoch": 2.0648736773572023,
      "grad_norm": 4.252203941345215,
      "learning_rate": 3.967981156044887e-05,
      "loss": 0.9396,
      "step": 195050
    },
    {
      "epoch": 2.0654029991372056,
      "grad_norm": 3.8351008892059326,
      "learning_rate": 3.96771649375397e-05,
      "loss": 0.9361,
      "step": 195100
    },
    {
      "epoch": 2.065932320917209,
      "grad_norm": 3.553107738494873,
      "learning_rate": 3.9674518314630534e-05,
      "loss": 0.9387,
      "step": 195150
    },
    {
      "epoch": 2.066461642697212,
      "grad_norm": 3.6450870037078857,
      "learning_rate": 3.967187169172136e-05,
      "loss": 0.9571,
      "step": 195200
    },
    {
      "epoch": 2.0669909644772155,
      "grad_norm": 3.584573984146118,
      "learning_rate": 3.96692250688122e-05,
      "loss": 0.9591,
      "step": 195250
    },
    {
      "epoch": 2.067520286257219,
      "grad_norm": 3.746068239212036,
      "learning_rate": 3.966657844590303e-05,
      "loss": 0.9293,
      "step": 195300
    },
    {
      "epoch": 2.0680496080372217,
      "grad_norm": 4.146078109741211,
      "learning_rate": 3.9663931822993864e-05,
      "loss": 0.9448,
      "step": 195350
    },
    {
      "epoch": 2.068578929817225,
      "grad_norm": 3.341648817062378,
      "learning_rate": 3.966128520008469e-05,
      "loss": 0.9409,
      "step": 195400
    },
    {
      "epoch": 2.0691082515972283,
      "grad_norm": 3.428239583969116,
      "learning_rate": 3.9658638577175525e-05,
      "loss": 0.935,
      "step": 195450
    },
    {
      "epoch": 2.0696375733772316,
      "grad_norm": 3.62986421585083,
      "learning_rate": 3.965599195426636e-05,
      "loss": 0.9612,
      "step": 195500
    },
    {
      "epoch": 2.0696375733772316,
      "eval_loss": 0.7648605704307556,
      "eval_runtime": 46.5768,
      "eval_samples_per_second": 3605.442,
      "eval_steps_per_second": 450.696,
      "step": 195500
    },
    {
      "epoch": 2.070166895157235,
      "grad_norm": 3.9188456535339355,
      "learning_rate": 3.965334533135719e-05,
      "loss": 0.9531,
      "step": 195550
    },
    {
      "epoch": 2.0706962169372383,
      "grad_norm": 4.0140509605407715,
      "learning_rate": 3.965069870844802e-05,
      "loss": 0.9366,
      "step": 195600
    },
    {
      "epoch": 2.0712255387172416,
      "grad_norm": 3.7292027473449707,
      "learning_rate": 3.9648052085538855e-05,
      "loss": 0.9332,
      "step": 195650
    },
    {
      "epoch": 2.071754860497245,
      "grad_norm": 3.599566698074341,
      "learning_rate": 3.964540546262969e-05,
      "loss": 0.9447,
      "step": 195700
    },
    {
      "epoch": 2.072284182277248,
      "grad_norm": 3.7054991722106934,
      "learning_rate": 3.9642758839720516e-05,
      "loss": 0.9411,
      "step": 195750
    },
    {
      "epoch": 2.0728135040572515,
      "grad_norm": 3.840780735015869,
      "learning_rate": 3.964011221681135e-05,
      "loss": 0.9655,
      "step": 195800
    },
    {
      "epoch": 2.073342825837255,
      "grad_norm": 3.9389283657073975,
      "learning_rate": 3.9637465593902185e-05,
      "loss": 0.9586,
      "step": 195850
    },
    {
      "epoch": 2.073872147617258,
      "grad_norm": 4.3830766677856445,
      "learning_rate": 3.963481897099301e-05,
      "loss": 0.943,
      "step": 195900
    },
    {
      "epoch": 2.0744014693972614,
      "grad_norm": 3.720996379852295,
      "learning_rate": 3.9632172348083846e-05,
      "loss": 0.9434,
      "step": 195950
    },
    {
      "epoch": 2.0749307911772648,
      "grad_norm": 4.074337959289551,
      "learning_rate": 3.962952572517467e-05,
      "loss": 0.9477,
      "step": 196000
    },
    {
      "epoch": 2.0749307911772648,
      "eval_loss": 0.7643025517463684,
      "eval_runtime": 46.6187,
      "eval_samples_per_second": 3602.2,
      "eval_steps_per_second": 450.291,
      "step": 196000
    },
    {
      "epoch": 2.075460112957268,
      "grad_norm": 3.7725415229797363,
      "learning_rate": 3.9626879102265514e-05,
      "loss": 0.9346,
      "step": 196050
    },
    {
      "epoch": 2.075989434737271,
      "grad_norm": 3.6110117435455322,
      "learning_rate": 3.962423247935634e-05,
      "loss": 0.957,
      "step": 196100
    },
    {
      "epoch": 2.0765187565172742,
      "grad_norm": 4.088498115539551,
      "learning_rate": 3.9621585856447176e-05,
      "loss": 0.9327,
      "step": 196150
    },
    {
      "epoch": 2.0770480782972776,
      "grad_norm": 3.6659717559814453,
      "learning_rate": 3.9618939233538e-05,
      "loss": 0.9498,
      "step": 196200
    },
    {
      "epoch": 2.077577400077281,
      "grad_norm": 3.7085609436035156,
      "learning_rate": 3.9616292610628844e-05,
      "loss": 0.9557,
      "step": 196250
    },
    {
      "epoch": 2.078106721857284,
      "grad_norm": 3.7413129806518555,
      "learning_rate": 3.961364598771967e-05,
      "loss": 0.9355,
      "step": 196300
    },
    {
      "epoch": 2.0786360436372875,
      "grad_norm": 3.4787867069244385,
      "learning_rate": 3.9610999364810505e-05,
      "loss": 0.9461,
      "step": 196350
    },
    {
      "epoch": 2.079165365417291,
      "grad_norm": 3.966344118118286,
      "learning_rate": 3.960835274190133e-05,
      "loss": 0.9365,
      "step": 196400
    },
    {
      "epoch": 2.079694687197294,
      "grad_norm": 3.671435832977295,
      "learning_rate": 3.960570611899217e-05,
      "loss": 0.9276,
      "step": 196450
    },
    {
      "epoch": 2.0802240089772974,
      "grad_norm": 3.7316927909851074,
      "learning_rate": 3.9603059496083e-05,
      "loss": 0.9438,
      "step": 196500
    },
    {
      "epoch": 2.0802240089772974,
      "eval_loss": 0.7637042999267578,
      "eval_runtime": 46.7941,
      "eval_samples_per_second": 3588.697,
      "eval_steps_per_second": 448.603,
      "step": 196500
    },
    {
      "epoch": 2.0807533307573007,
      "grad_norm": 3.652467727661133,
      "learning_rate": 3.960041287317383e-05,
      "loss": 0.9541,
      "step": 196550
    },
    {
      "epoch": 2.081282652537304,
      "grad_norm": 3.7774200439453125,
      "learning_rate": 3.959776625026466e-05,
      "loss": 0.9559,
      "step": 196600
    },
    {
      "epoch": 2.0818119743173074,
      "grad_norm": 3.6876983642578125,
      "learning_rate": 3.9595119627355496e-05,
      "loss": 0.9416,
      "step": 196650
    },
    {
      "epoch": 2.0823412960973107,
      "grad_norm": 3.8291049003601074,
      "learning_rate": 3.959252593690451e-05,
      "loss": 0.9488,
      "step": 196700
    },
    {
      "epoch": 2.082870617877314,
      "grad_norm": 4.1312255859375,
      "learning_rate": 3.9589879313995345e-05,
      "loss": 0.9395,
      "step": 196750
    },
    {
      "epoch": 2.0833999396573173,
      "grad_norm": 3.592564105987549,
      "learning_rate": 3.958723269108617e-05,
      "loss": 0.9376,
      "step": 196800
    },
    {
      "epoch": 2.08392926143732,
      "grad_norm": 3.7406482696533203,
      "learning_rate": 3.9584586068177006e-05,
      "loss": 0.9549,
      "step": 196850
    },
    {
      "epoch": 2.0844585832173235,
      "grad_norm": 4.13189697265625,
      "learning_rate": 3.958193944526784e-05,
      "loss": 0.9652,
      "step": 196900
    },
    {
      "epoch": 2.084987904997327,
      "grad_norm": 3.6373403072357178,
      "learning_rate": 3.957929282235867e-05,
      "loss": 0.9609,
      "step": 196950
    },
    {
      "epoch": 2.08551722677733,
      "grad_norm": 3.951716184616089,
      "learning_rate": 3.95766461994495e-05,
      "loss": 0.9405,
      "step": 197000
    },
    {
      "epoch": 2.08551722677733,
      "eval_loss": 0.7595731616020203,
      "eval_runtime": 46.6162,
      "eval_samples_per_second": 3602.395,
      "eval_steps_per_second": 450.315,
      "step": 197000
    },
    {
      "epoch": 2.0860465485573334,
      "grad_norm": 4.18604040145874,
      "learning_rate": 3.9573999576540336e-05,
      "loss": 0.955,
      "step": 197050
    },
    {
      "epoch": 2.0865758703373367,
      "grad_norm": 3.863002061843872,
      "learning_rate": 3.957135295363117e-05,
      "loss": 0.9334,
      "step": 197100
    },
    {
      "epoch": 2.08710519211734,
      "grad_norm": 3.7550292015075684,
      "learning_rate": 3.9568706330722e-05,
      "loss": 0.9397,
      "step": 197150
    },
    {
      "epoch": 2.0876345138973433,
      "grad_norm": 3.904733180999756,
      "learning_rate": 3.956605970781283e-05,
      "loss": 0.9461,
      "step": 197200
    },
    {
      "epoch": 2.0881638356773466,
      "grad_norm": 3.6287479400634766,
      "learning_rate": 3.9563413084903666e-05,
      "loss": 0.9505,
      "step": 197250
    },
    {
      "epoch": 2.08869315745735,
      "grad_norm": 3.528792381286621,
      "learning_rate": 3.95607664619945e-05,
      "loss": 0.9375,
      "step": 197300
    },
    {
      "epoch": 2.0892224792373533,
      "grad_norm": 3.4521381855010986,
      "learning_rate": 3.955811983908533e-05,
      "loss": 0.954,
      "step": 197350
    },
    {
      "epoch": 2.0897518010173566,
      "grad_norm": 3.9448394775390625,
      "learning_rate": 3.955547321617616e-05,
      "loss": 0.941,
      "step": 197400
    },
    {
      "epoch": 2.09028112279736,
      "grad_norm": 3.486550807952881,
      "learning_rate": 3.9552826593266995e-05,
      "loss": 0.9431,
      "step": 197450
    },
    {
      "epoch": 2.090810444577363,
      "grad_norm": 3.893378734588623,
      "learning_rate": 3.955017997035782e-05,
      "loss": 0.9379,
      "step": 197500
    },
    {
      "epoch": 2.090810444577363,
      "eval_loss": 0.7627215385437012,
      "eval_runtime": 46.5557,
      "eval_samples_per_second": 3607.076,
      "eval_steps_per_second": 450.901,
      "step": 197500
    },
    {
      "epoch": 2.0913397663573665,
      "grad_norm": 3.7534592151641846,
      "learning_rate": 3.954753334744866e-05,
      "loss": 0.938,
      "step": 197550
    },
    {
      "epoch": 2.0918690881373694,
      "grad_norm": 3.9055135250091553,
      "learning_rate": 3.9544886724539484e-05,
      "loss": 0.9491,
      "step": 197600
    },
    {
      "epoch": 2.0923984099173727,
      "grad_norm": 3.460232734680176,
      "learning_rate": 3.9542240101630325e-05,
      "loss": 0.9525,
      "step": 197650
    },
    {
      "epoch": 2.092927731697376,
      "grad_norm": 3.5904905796051025,
      "learning_rate": 3.953959347872115e-05,
      "loss": 0.9479,
      "step": 197700
    },
    {
      "epoch": 2.0934570534773793,
      "grad_norm": 3.786893606185913,
      "learning_rate": 3.9536946855811986e-05,
      "loss": 0.9361,
      "step": 197750
    },
    {
      "epoch": 2.0939863752573826,
      "grad_norm": 3.8052895069122314,
      "learning_rate": 3.9534300232902814e-05,
      "loss": 0.9484,
      "step": 197800
    },
    {
      "epoch": 2.094515697037386,
      "grad_norm": 4.024715900421143,
      "learning_rate": 3.9531653609993655e-05,
      "loss": 0.9307,
      "step": 197850
    },
    {
      "epoch": 2.0950450188173892,
      "grad_norm": 3.804053544998169,
      "learning_rate": 3.952900698708448e-05,
      "loss": 0.9345,
      "step": 197900
    },
    {
      "epoch": 2.0955743405973926,
      "grad_norm": 3.8030905723571777,
      "learning_rate": 3.9526360364175316e-05,
      "loss": 0.9498,
      "step": 197950
    },
    {
      "epoch": 2.096103662377396,
      "grad_norm": 3.658418893814087,
      "learning_rate": 3.952371374126614e-05,
      "loss": 0.9483,
      "step": 198000
    },
    {
      "epoch": 2.096103662377396,
      "eval_loss": 0.760556161403656,
      "eval_runtime": 46.5961,
      "eval_samples_per_second": 3603.947,
      "eval_steps_per_second": 450.51,
      "step": 198000
    },
    {
      "epoch": 2.096632984157399,
      "grad_norm": 3.5086770057678223,
      "learning_rate": 3.952106711835698e-05,
      "loss": 0.9414,
      "step": 198050
    },
    {
      "epoch": 2.0971623059374025,
      "grad_norm": 3.9943478107452393,
      "learning_rate": 3.951842049544781e-05,
      "loss": 0.9435,
      "step": 198100
    },
    {
      "epoch": 2.097691627717406,
      "grad_norm": 3.845313787460327,
      "learning_rate": 3.951577387253864e-05,
      "loss": 0.9364,
      "step": 198150
    },
    {
      "epoch": 2.098220949497409,
      "grad_norm": 3.797987699508667,
      "learning_rate": 3.951312724962947e-05,
      "loss": 0.9304,
      "step": 198200
    },
    {
      "epoch": 2.0987502712774124,
      "grad_norm": 3.4928500652313232,
      "learning_rate": 3.951048062672031e-05,
      "loss": 0.9321,
      "step": 198250
    },
    {
      "epoch": 2.0992795930574157,
      "grad_norm": 3.891660690307617,
      "learning_rate": 3.950783400381114e-05,
      "loss": 0.9384,
      "step": 198300
    },
    {
      "epoch": 2.0998089148374186,
      "grad_norm": 4.010277271270752,
      "learning_rate": 3.950518738090197e-05,
      "loss": 0.961,
      "step": 198350
    },
    {
      "epoch": 2.100338236617422,
      "grad_norm": 4.068119525909424,
      "learning_rate": 3.95025407579928e-05,
      "loss": 0.937,
      "step": 198400
    },
    {
      "epoch": 2.1008675583974252,
      "grad_norm": 3.489936351776123,
      "learning_rate": 3.949989413508364e-05,
      "loss": 0.9513,
      "step": 198450
    },
    {
      "epoch": 2.1013968801774285,
      "grad_norm": 3.5647826194763184,
      "learning_rate": 3.949724751217447e-05,
      "loss": 0.9577,
      "step": 198500
    },
    {
      "epoch": 2.1013968801774285,
      "eval_loss": 0.7597243189811707,
      "eval_runtime": 46.5806,
      "eval_samples_per_second": 3605.145,
      "eval_steps_per_second": 450.659,
      "step": 198500
    },
    {
      "epoch": 2.101926201957432,
      "grad_norm": 3.756085157394409,
      "learning_rate": 3.94946008892653e-05,
      "loss": 0.9398,
      "step": 198550
    },
    {
      "epoch": 2.102455523737435,
      "grad_norm": 4.029774188995361,
      "learning_rate": 3.949195426635613e-05,
      "loss": 0.9504,
      "step": 198600
    },
    {
      "epoch": 2.1029848455174385,
      "grad_norm": 3.768465280532837,
      "learning_rate": 3.9489307643446966e-05,
      "loss": 0.9397,
      "step": 198650
    },
    {
      "epoch": 2.103514167297442,
      "grad_norm": 3.908484697341919,
      "learning_rate": 3.9486661020537794e-05,
      "loss": 0.9457,
      "step": 198700
    },
    {
      "epoch": 2.104043489077445,
      "grad_norm": 4.028212070465088,
      "learning_rate": 3.948406733008681e-05,
      "loss": 0.9387,
      "step": 198750
    },
    {
      "epoch": 2.1045728108574484,
      "grad_norm": 3.795644998550415,
      "learning_rate": 3.948142070717764e-05,
      "loss": 0.9446,
      "step": 198800
    },
    {
      "epoch": 2.1051021326374517,
      "grad_norm": 3.8222217559814453,
      "learning_rate": 3.9478774084268477e-05,
      "loss": 0.9411,
      "step": 198850
    },
    {
      "epoch": 2.105631454417455,
      "grad_norm": 3.874018669128418,
      "learning_rate": 3.947612746135931e-05,
      "loss": 0.9348,
      "step": 198900
    },
    {
      "epoch": 2.1061607761974583,
      "grad_norm": 3.8643791675567627,
      "learning_rate": 3.947348083845014e-05,
      "loss": 0.9383,
      "step": 198950
    },
    {
      "epoch": 2.1066900979774617,
      "grad_norm": 3.9171764850616455,
      "learning_rate": 3.947083421554097e-05,
      "loss": 0.9401,
      "step": 199000
    },
    {
      "epoch": 2.1066900979774617,
      "eval_loss": 0.7583488821983337,
      "eval_runtime": 46.704,
      "eval_samples_per_second": 3595.623,
      "eval_steps_per_second": 449.469,
      "step": 199000
    },
    {
      "epoch": 2.107219419757465,
      "grad_norm": 4.135377407073975,
      "learning_rate": 3.9468187592631806e-05,
      "loss": 0.9548,
      "step": 199050
    },
    {
      "epoch": 2.107748741537468,
      "grad_norm": 3.526590347290039,
      "learning_rate": 3.9465540969722633e-05,
      "loss": 0.9355,
      "step": 199100
    },
    {
      "epoch": 2.108278063317471,
      "grad_norm": 4.043412685394287,
      "learning_rate": 3.946289434681347e-05,
      "loss": 0.9393,
      "step": 199150
    },
    {
      "epoch": 2.1088073850974745,
      "grad_norm": 3.7354373931884766,
      "learning_rate": 3.9460247723904295e-05,
      "loss": 0.9359,
      "step": 199200
    },
    {
      "epoch": 2.1093367068774778,
      "grad_norm": 3.6970458030700684,
      "learning_rate": 3.9457601100995136e-05,
      "loss": 0.9437,
      "step": 199250
    },
    {
      "epoch": 2.109866028657481,
      "grad_norm": 3.928940773010254,
      "learning_rate": 3.945495447808596e-05,
      "loss": 0.9245,
      "step": 199300
    },
    {
      "epoch": 2.1103953504374844,
      "grad_norm": 3.6879830360412598,
      "learning_rate": 3.94523078551768e-05,
      "loss": 0.9507,
      "step": 199350
    },
    {
      "epoch": 2.1109246722174877,
      "grad_norm": 3.5632858276367188,
      "learning_rate": 3.9449661232267625e-05,
      "loss": 0.9345,
      "step": 199400
    },
    {
      "epoch": 2.111453993997491,
      "grad_norm": 3.6153171062469482,
      "learning_rate": 3.9447014609358465e-05,
      "loss": 0.9205,
      "step": 199450
    },
    {
      "epoch": 2.1119833157774943,
      "grad_norm": 3.644984483718872,
      "learning_rate": 3.944436798644929e-05,
      "loss": 0.9309,
      "step": 199500
    },
    {
      "epoch": 2.1119833157774943,
      "eval_loss": 0.7560630440711975,
      "eval_runtime": 46.6318,
      "eval_samples_per_second": 3601.189,
      "eval_steps_per_second": 450.165,
      "step": 199500
    },
    {
      "epoch": 2.1125126375574976,
      "grad_norm": 4.167887210845947,
      "learning_rate": 3.944172136354013e-05,
      "loss": 0.9501,
      "step": 199550
    },
    {
      "epoch": 2.113041959337501,
      "grad_norm": 4.03485107421875,
      "learning_rate": 3.9439074740630954e-05,
      "loss": 0.9229,
      "step": 199600
    },
    {
      "epoch": 2.1135712811175043,
      "grad_norm": 3.717844009399414,
      "learning_rate": 3.943642811772179e-05,
      "loss": 0.9425,
      "step": 199650
    },
    {
      "epoch": 2.1141006028975076,
      "grad_norm": 3.6883175373077393,
      "learning_rate": 3.943378149481262e-05,
      "loss": 0.9302,
      "step": 199700
    },
    {
      "epoch": 2.114629924677511,
      "grad_norm": 3.633812189102173,
      "learning_rate": 3.943113487190345e-05,
      "loss": 0.9531,
      "step": 199750
    },
    {
      "epoch": 2.115159246457514,
      "grad_norm": 3.8239498138427734,
      "learning_rate": 3.9428488248994284e-05,
      "loss": 0.9397,
      "step": 199800
    },
    {
      "epoch": 2.115688568237517,
      "grad_norm": 3.7421066761016846,
      "learning_rate": 3.942584162608512e-05,
      "loss": 0.9388,
      "step": 199850
    },
    {
      "epoch": 2.1162178900175204,
      "grad_norm": 3.5916712284088135,
      "learning_rate": 3.942319500317595e-05,
      "loss": 0.9455,
      "step": 199900
    },
    {
      "epoch": 2.1167472117975237,
      "grad_norm": 3.701291799545288,
      "learning_rate": 3.942054838026678e-05,
      "loss": 0.9354,
      "step": 199950
    },
    {
      "epoch": 2.117276533577527,
      "grad_norm": 3.7949271202087402,
      "learning_rate": 3.9417901757357613e-05,
      "loss": 0.9451,
      "step": 200000
    },
    {
      "epoch": 2.117276533577527,
      "eval_loss": 0.7586026191711426,
      "eval_runtime": 46.5834,
      "eval_samples_per_second": 3604.929,
      "eval_steps_per_second": 450.632,
      "step": 200000
    },
    {
      "epoch": 2.1178058553575303,
      "grad_norm": 3.25286865234375,
      "learning_rate": 3.941525513444845e-05,
      "loss": 0.9266,
      "step": 200050
    },
    {
      "epoch": 2.1183351771375336,
      "grad_norm": 3.5940046310424805,
      "learning_rate": 3.941260851153928e-05,
      "loss": 0.9415,
      "step": 200100
    },
    {
      "epoch": 2.118864498917537,
      "grad_norm": 3.9262053966522217,
      "learning_rate": 3.940996188863011e-05,
      "loss": 0.9429,
      "step": 200150
    },
    {
      "epoch": 2.1193938206975402,
      "grad_norm": 3.6978137493133545,
      "learning_rate": 3.940731526572094e-05,
      "loss": 0.9572,
      "step": 200200
    },
    {
      "epoch": 2.1199231424775435,
      "grad_norm": 3.800849199295044,
      "learning_rate": 3.940466864281178e-05,
      "loss": 0.9456,
      "step": 200250
    },
    {
      "epoch": 2.120452464257547,
      "grad_norm": 4.139858722686768,
      "learning_rate": 3.9402022019902604e-05,
      "loss": 0.945,
      "step": 200300
    },
    {
      "epoch": 2.12098178603755,
      "grad_norm": 3.8522582054138184,
      "learning_rate": 3.939937539699344e-05,
      "loss": 0.9401,
      "step": 200350
    },
    {
      "epoch": 2.1215111078175535,
      "grad_norm": 4.138461112976074,
      "learning_rate": 3.9396728774084266e-05,
      "loss": 0.9311,
      "step": 200400
    },
    {
      "epoch": 2.122040429597557,
      "grad_norm": 3.792534351348877,
      "learning_rate": 3.939408215117511e-05,
      "loss": 0.9368,
      "step": 200450
    },
    {
      "epoch": 2.12256975137756,
      "grad_norm": 3.8049068450927734,
      "learning_rate": 3.9391435528265934e-05,
      "loss": 0.9476,
      "step": 200500
    },
    {
      "epoch": 2.12256975137756,
      "eval_loss": 0.7550212740898132,
      "eval_runtime": 46.7138,
      "eval_samples_per_second": 3594.866,
      "eval_steps_per_second": 449.374,
      "step": 200500
    },
    {
      "epoch": 2.1230990731575634,
      "grad_norm": 3.866286277770996,
      "learning_rate": 3.938878890535677e-05,
      "loss": 0.9421,
      "step": 200550
    },
    {
      "epoch": 2.1236283949375663,
      "grad_norm": 4.118778705596924,
      "learning_rate": 3.9386142282447595e-05,
      "loss": 0.9295,
      "step": 200600
    },
    {
      "epoch": 2.1241577167175696,
      "grad_norm": 3.5211334228515625,
      "learning_rate": 3.9383495659538436e-05,
      "loss": 0.945,
      "step": 200650
    },
    {
      "epoch": 2.124687038497573,
      "grad_norm": 3.679551362991333,
      "learning_rate": 3.9380849036629264e-05,
      "loss": 0.9261,
      "step": 200700
    },
    {
      "epoch": 2.125216360277576,
      "grad_norm": 3.7527992725372314,
      "learning_rate": 3.937825534617828e-05,
      "loss": 0.9351,
      "step": 200750
    },
    {
      "epoch": 2.1257456820575795,
      "grad_norm": 4.039988994598389,
      "learning_rate": 3.9375608723269106e-05,
      "loss": 0.9317,
      "step": 200800
    },
    {
      "epoch": 2.126275003837583,
      "grad_norm": 3.5907442569732666,
      "learning_rate": 3.9372962100359947e-05,
      "loss": 0.9347,
      "step": 200850
    },
    {
      "epoch": 2.126804325617586,
      "grad_norm": 3.874506711959839,
      "learning_rate": 3.9370315477450774e-05,
      "loss": 0.9603,
      "step": 200900
    },
    {
      "epoch": 2.1273336473975895,
      "grad_norm": 4.002490997314453,
      "learning_rate": 3.936766885454161e-05,
      "loss": 0.9403,
      "step": 200950
    },
    {
      "epoch": 2.1278629691775928,
      "grad_norm": 3.9189493656158447,
      "learning_rate": 3.9365022231632435e-05,
      "loss": 0.9392,
      "step": 201000
    },
    {
      "epoch": 2.1278629691775928,
      "eval_loss": 0.7519916892051697,
      "eval_runtime": 46.641,
      "eval_samples_per_second": 3600.478,
      "eval_steps_per_second": 450.076,
      "step": 201000
    },
    {
      "epoch": 2.128392290957596,
      "grad_norm": 3.8460466861724854,
      "learning_rate": 3.9362375608723276e-05,
      "loss": 0.9488,
      "step": 201050
    },
    {
      "epoch": 2.1289216127375994,
      "grad_norm": 3.794642686843872,
      "learning_rate": 3.9359728985814104e-05,
      "loss": 0.9545,
      "step": 201100
    },
    {
      "epoch": 2.1294509345176027,
      "grad_norm": 3.6676995754241943,
      "learning_rate": 3.935708236290494e-05,
      "loss": 0.9392,
      "step": 201150
    },
    {
      "epoch": 2.129980256297606,
      "grad_norm": 3.8884031772613525,
      "learning_rate": 3.9354435739995765e-05,
      "loss": 0.9294,
      "step": 201200
    },
    {
      "epoch": 2.1305095780776093,
      "grad_norm": 3.4887478351593018,
      "learning_rate": 3.93517891170866e-05,
      "loss": 0.9259,
      "step": 201250
    },
    {
      "epoch": 2.1310388998576126,
      "grad_norm": 3.5574803352355957,
      "learning_rate": 3.934914249417743e-05,
      "loss": 0.9439,
      "step": 201300
    },
    {
      "epoch": 2.1315682216376155,
      "grad_norm": 3.9492557048797607,
      "learning_rate": 3.934649587126826e-05,
      "loss": 0.936,
      "step": 201350
    },
    {
      "epoch": 2.132097543417619,
      "grad_norm": 3.636486053466797,
      "learning_rate": 3.9343849248359095e-05,
      "loss": 0.9288,
      "step": 201400
    },
    {
      "epoch": 2.132626865197622,
      "grad_norm": 3.8352651596069336,
      "learning_rate": 3.934120262544993e-05,
      "loss": 0.94,
      "step": 201450
    },
    {
      "epoch": 2.1331561869776254,
      "grad_norm": 3.531214714050293,
      "learning_rate": 3.933855600254076e-05,
      "loss": 0.9365,
      "step": 201500
    },
    {
      "epoch": 2.1331561869776254,
      "eval_loss": 0.7530294060707092,
      "eval_runtime": 46.5613,
      "eval_samples_per_second": 3606.647,
      "eval_steps_per_second": 450.847,
      "step": 201500
    },
    {
      "epoch": 2.1336855087576287,
      "grad_norm": 4.2148051261901855,
      "learning_rate": 3.933590937963159e-05,
      "loss": 0.9461,
      "step": 201550
    },
    {
      "epoch": 2.134214830537632,
      "grad_norm": 3.761887550354004,
      "learning_rate": 3.9333262756722424e-05,
      "loss": 0.9379,
      "step": 201600
    },
    {
      "epoch": 2.1347441523176354,
      "grad_norm": 3.9331586360931396,
      "learning_rate": 3.933061613381326e-05,
      "loss": 0.9389,
      "step": 201650
    },
    {
      "epoch": 2.1352734740976387,
      "grad_norm": 3.546470880508423,
      "learning_rate": 3.932796951090409e-05,
      "loss": 0.9385,
      "step": 201700
    },
    {
      "epoch": 2.135802795877642,
      "grad_norm": 4.33494234085083,
      "learning_rate": 3.932532288799492e-05,
      "loss": 0.9332,
      "step": 201750
    },
    {
      "epoch": 2.1363321176576453,
      "grad_norm": 4.115678310394287,
      "learning_rate": 3.9322676265085754e-05,
      "loss": 0.9395,
      "step": 201800
    },
    {
      "epoch": 2.1368614394376486,
      "grad_norm": 3.801896572113037,
      "learning_rate": 3.932002964217659e-05,
      "loss": 0.9464,
      "step": 201850
    },
    {
      "epoch": 2.137390761217652,
      "grad_norm": 4.334453105926514,
      "learning_rate": 3.9317383019267415e-05,
      "loss": 0.9401,
      "step": 201900
    },
    {
      "epoch": 2.1379200829976552,
      "grad_norm": 3.540311574935913,
      "learning_rate": 3.931473639635825e-05,
      "loss": 0.9394,
      "step": 201950
    },
    {
      "epoch": 2.1384494047776585,
      "grad_norm": 3.5363235473632812,
      "learning_rate": 3.931208977344908e-05,
      "loss": 0.928,
      "step": 202000
    },
    {
      "epoch": 2.1384494047776585,
      "eval_loss": 0.7523664832115173,
      "eval_runtime": 46.6356,
      "eval_samples_per_second": 3600.896,
      "eval_steps_per_second": 450.128,
      "step": 202000
    },
    {
      "epoch": 2.138978726557662,
      "grad_norm": 3.7449069023132324,
      "learning_rate": 3.930944315053992e-05,
      "loss": 0.9329,
      "step": 202050
    },
    {
      "epoch": 2.1395080483376647,
      "grad_norm": 3.727968454360962,
      "learning_rate": 3.9306796527630745e-05,
      "loss": 0.92,
      "step": 202100
    },
    {
      "epoch": 2.140037370117668,
      "grad_norm": 3.5121114253997803,
      "learning_rate": 3.930414990472158e-05,
      "loss": 0.9474,
      "step": 202150
    },
    {
      "epoch": 2.1405666918976713,
      "grad_norm": 3.4425458908081055,
      "learning_rate": 3.9301503281812406e-05,
      "loss": 0.9438,
      "step": 202200
    },
    {
      "epoch": 2.1410960136776747,
      "grad_norm": 3.53066086769104,
      "learning_rate": 3.929885665890324e-05,
      "loss": 0.9212,
      "step": 202250
    },
    {
      "epoch": 2.141625335457678,
      "grad_norm": 3.5662357807159424,
      "learning_rate": 3.9296210035994075e-05,
      "loss": 0.9301,
      "step": 202300
    },
    {
      "epoch": 2.1421546572376813,
      "grad_norm": 3.5403218269348145,
      "learning_rate": 3.92935634130849e-05,
      "loss": 0.924,
      "step": 202350
    },
    {
      "epoch": 2.1426839790176846,
      "grad_norm": 3.556210994720459,
      "learning_rate": 3.9290916790175736e-05,
      "loss": 0.9319,
      "step": 202400
    },
    {
      "epoch": 2.143213300797688,
      "grad_norm": 3.702188491821289,
      "learning_rate": 3.928827016726657e-05,
      "loss": 0.9276,
      "step": 202450
    },
    {
      "epoch": 2.143742622577691,
      "grad_norm": 3.395495891571045,
      "learning_rate": 3.9285623544357404e-05,
      "loss": 0.931,
      "step": 202500
    },
    {
      "epoch": 2.143742622577691,
      "eval_loss": 0.7492868304252625,
      "eval_runtime": 46.5892,
      "eval_samples_per_second": 3604.484,
      "eval_steps_per_second": 450.577,
      "step": 202500
    },
    {
      "epoch": 2.1442719443576945,
      "grad_norm": 3.5893120765686035,
      "learning_rate": 3.928297692144823e-05,
      "loss": 0.9444,
      "step": 202550
    },
    {
      "epoch": 2.144801266137698,
      "grad_norm": 4.0251054763793945,
      "learning_rate": 3.9280330298539066e-05,
      "loss": 0.9329,
      "step": 202600
    },
    {
      "epoch": 2.145330587917701,
      "grad_norm": 3.764575958251953,
      "learning_rate": 3.92776836756299e-05,
      "loss": 0.928,
      "step": 202650
    },
    {
      "epoch": 2.1458599096977045,
      "grad_norm": 3.6499388217926025,
      "learning_rate": 3.9275037052720734e-05,
      "loss": 0.9311,
      "step": 202700
    },
    {
      "epoch": 2.1463892314777078,
      "grad_norm": 3.5702075958251953,
      "learning_rate": 3.927244336226975e-05,
      "loss": 0.947,
      "step": 202750
    },
    {
      "epoch": 2.146918553257711,
      "grad_norm": 3.7335126399993896,
      "learning_rate": 3.9269796739360576e-05,
      "loss": 0.9293,
      "step": 202800
    },
    {
      "epoch": 2.147447875037714,
      "grad_norm": 3.7334134578704834,
      "learning_rate": 3.926715011645141e-05,
      "loss": 0.9356,
      "step": 202850
    },
    {
      "epoch": 2.1479771968177173,
      "grad_norm": 3.9713523387908936,
      "learning_rate": 3.9264503493542244e-05,
      "loss": 0.9514,
      "step": 202900
    },
    {
      "epoch": 2.1485065185977206,
      "grad_norm": 4.2870283126831055,
      "learning_rate": 3.926185687063307e-05,
      "loss": 0.9215,
      "step": 202950
    },
    {
      "epoch": 2.149035840377724,
      "grad_norm": 3.8555428981781006,
      "learning_rate": 3.9259210247723905e-05,
      "loss": 0.9392,
      "step": 203000
    },
    {
      "epoch": 2.149035840377724,
      "eval_loss": 0.7510113716125488,
      "eval_runtime": 46.8102,
      "eval_samples_per_second": 3587.466,
      "eval_steps_per_second": 448.449,
      "step": 203000
    },
    {
      "epoch": 2.149565162157727,
      "grad_norm": 3.229363203048706,
      "learning_rate": 3.925656362481474e-05,
      "loss": 0.9323,
      "step": 203050
    },
    {
      "epoch": 2.1500944839377305,
      "grad_norm": 3.5938820838928223,
      "learning_rate": 3.9253917001905574e-05,
      "loss": 0.9335,
      "step": 203100
    },
    {
      "epoch": 2.150623805717734,
      "grad_norm": 3.5763676166534424,
      "learning_rate": 3.92512703789964e-05,
      "loss": 0.9326,
      "step": 203150
    },
    {
      "epoch": 2.151153127497737,
      "grad_norm": 3.7152347564697266,
      "learning_rate": 3.9248623756087235e-05,
      "loss": 0.9412,
      "step": 203200
    },
    {
      "epoch": 2.1516824492777404,
      "grad_norm": 3.797152042388916,
      "learning_rate": 3.924597713317807e-05,
      "loss": 0.9251,
      "step": 203250
    },
    {
      "epoch": 2.1522117710577437,
      "grad_norm": 4.042919635772705,
      "learning_rate": 3.9243330510268896e-05,
      "loss": 0.9362,
      "step": 203300
    },
    {
      "epoch": 2.152741092837747,
      "grad_norm": 3.7438924312591553,
      "learning_rate": 3.924068388735973e-05,
      "loss": 0.9464,
      "step": 203350
    },
    {
      "epoch": 2.1532704146177504,
      "grad_norm": 3.4413204193115234,
      "learning_rate": 3.923803726445056e-05,
      "loss": 0.9307,
      "step": 203400
    },
    {
      "epoch": 2.1537997363977537,
      "grad_norm": 3.5389862060546875,
      "learning_rate": 3.92353906415414e-05,
      "loss": 0.9256,
      "step": 203450
    },
    {
      "epoch": 2.154329058177757,
      "grad_norm": 3.9082555770874023,
      "learning_rate": 3.9232744018632226e-05,
      "loss": 0.9295,
      "step": 203500
    },
    {
      "epoch": 2.154329058177757,
      "eval_loss": 0.7462813258171082,
      "eval_runtime": 46.6062,
      "eval_samples_per_second": 3603.172,
      "eval_steps_per_second": 450.413,
      "step": 203500
    },
    {
      "epoch": 2.1548583799577603,
      "grad_norm": 3.2309978008270264,
      "learning_rate": 3.923009739572306e-05,
      "loss": 0.9231,
      "step": 203550
    },
    {
      "epoch": 2.155387701737763,
      "grad_norm": 4.139369010925293,
      "learning_rate": 3.922745077281389e-05,
      "loss": 0.9334,
      "step": 203600
    },
    {
      "epoch": 2.1559170235177665,
      "grad_norm": 3.3240413665771484,
      "learning_rate": 3.922480414990473e-05,
      "loss": 0.9273,
      "step": 203650
    },
    {
      "epoch": 2.15644634529777,
      "grad_norm": 3.6824357509613037,
      "learning_rate": 3.9222157526995556e-05,
      "loss": 0.9408,
      "step": 203700
    },
    {
      "epoch": 2.156975667077773,
      "grad_norm": 3.735032081604004,
      "learning_rate": 3.921951090408639e-05,
      "loss": 0.9356,
      "step": 203750
    },
    {
      "epoch": 2.1575049888577764,
      "grad_norm": 3.737574577331543,
      "learning_rate": 3.921686428117722e-05,
      "loss": 0.9312,
      "step": 203800
    },
    {
      "epoch": 2.1580343106377797,
      "grad_norm": 4.199897289276123,
      "learning_rate": 3.921421765826805e-05,
      "loss": 0.9326,
      "step": 203850
    },
    {
      "epoch": 2.158563632417783,
      "grad_norm": 3.791635751724243,
      "learning_rate": 3.9211571035358885e-05,
      "loss": 0.95,
      "step": 203900
    },
    {
      "epoch": 2.1590929541977864,
      "grad_norm": 3.9413633346557617,
      "learning_rate": 3.920892441244971e-05,
      "loss": 0.9358,
      "step": 203950
    },
    {
      "epoch": 2.1596222759777897,
      "grad_norm": 3.384197473526001,
      "learning_rate": 3.920627778954055e-05,
      "loss": 0.9239,
      "step": 204000
    },
    {
      "epoch": 2.1596222759777897,
      "eval_loss": 0.7449764013290405,
      "eval_runtime": 46.5421,
      "eval_samples_per_second": 3608.131,
      "eval_steps_per_second": 451.032,
      "step": 204000
    },
    {
      "epoch": 2.160151597757793,
      "grad_norm": 3.746767044067383,
      "learning_rate": 3.920363116663138e-05,
      "loss": 0.9439,
      "step": 204050
    },
    {
      "epoch": 2.1606809195377963,
      "grad_norm": 3.646554946899414,
      "learning_rate": 3.9200984543722215e-05,
      "loss": 0.9435,
      "step": 204100
    },
    {
      "epoch": 2.1612102413177996,
      "grad_norm": 3.729306221008301,
      "learning_rate": 3.919833792081304e-05,
      "loss": 0.9364,
      "step": 204150
    },
    {
      "epoch": 2.161739563097803,
      "grad_norm": 3.8961410522460938,
      "learning_rate": 3.9195691297903876e-05,
      "loss": 0.9316,
      "step": 204200
    },
    {
      "epoch": 2.162268884877806,
      "grad_norm": 3.755361557006836,
      "learning_rate": 3.919304467499471e-05,
      "loss": 0.9259,
      "step": 204250
    },
    {
      "epoch": 2.1627982066578095,
      "grad_norm": 3.688829183578491,
      "learning_rate": 3.9190398052085545e-05,
      "loss": 0.9492,
      "step": 204300
    },
    {
      "epoch": 2.1633275284378124,
      "grad_norm": 3.5054898262023926,
      "learning_rate": 3.918775142917637e-05,
      "loss": 0.9347,
      "step": 204350
    },
    {
      "epoch": 2.1638568502178157,
      "grad_norm": 3.7491343021392822,
      "learning_rate": 3.9185104806267206e-05,
      "loss": 0.9296,
      "step": 204400
    },
    {
      "epoch": 2.164386171997819,
      "grad_norm": 3.730860471725464,
      "learning_rate": 3.918245818335804e-05,
      "loss": 0.953,
      "step": 204450
    },
    {
      "epoch": 2.1649154937778223,
      "grad_norm": 3.722416400909424,
      "learning_rate": 3.917981156044887e-05,
      "loss": 0.9259,
      "step": 204500
    },
    {
      "epoch": 2.1649154937778223,
      "eval_loss": 0.7466340065002441,
      "eval_runtime": 46.6687,
      "eval_samples_per_second": 3598.342,
      "eval_steps_per_second": 449.809,
      "step": 204500
    },
    {
      "epoch": 2.1654448155578256,
      "grad_norm": 3.940995693206787,
      "learning_rate": 3.91771649375397e-05,
      "loss": 0.9285,
      "step": 204550
    },
    {
      "epoch": 2.165974137337829,
      "grad_norm": 3.4979186058044434,
      "learning_rate": 3.917451831463053e-05,
      "loss": 0.944,
      "step": 204600
    },
    {
      "epoch": 2.1665034591178323,
      "grad_norm": 3.600693941116333,
      "learning_rate": 3.917187169172137e-05,
      "loss": 0.9301,
      "step": 204650
    },
    {
      "epoch": 2.1670327808978356,
      "grad_norm": 3.72432279586792,
      "learning_rate": 3.91692250688122e-05,
      "loss": 0.9301,
      "step": 204700
    },
    {
      "epoch": 2.167562102677839,
      "grad_norm": 3.857867956161499,
      "learning_rate": 3.916663137836121e-05,
      "loss": 0.9406,
      "step": 204750
    },
    {
      "epoch": 2.168091424457842,
      "grad_norm": 3.831088066101074,
      "learning_rate": 3.9163984755452046e-05,
      "loss": 0.9352,
      "step": 204800
    },
    {
      "epoch": 2.1686207462378455,
      "grad_norm": 3.687619209289551,
      "learning_rate": 3.916133813254288e-05,
      "loss": 0.9302,
      "step": 204850
    },
    {
      "epoch": 2.169150068017849,
      "grad_norm": 3.885233163833618,
      "learning_rate": 3.915869150963371e-05,
      "loss": 0.9418,
      "step": 204900
    },
    {
      "epoch": 2.169679389797852,
      "grad_norm": 3.978632926940918,
      "learning_rate": 3.915604488672454e-05,
      "loss": 0.9222,
      "step": 204950
    },
    {
      "epoch": 2.1702087115778554,
      "grad_norm": 4.023279190063477,
      "learning_rate": 3.915339826381537e-05,
      "loss": 0.9311,
      "step": 205000
    },
    {
      "epoch": 2.1702087115778554,
      "eval_loss": 0.7428639531135559,
      "eval_runtime": 46.5384,
      "eval_samples_per_second": 3608.42,
      "eval_steps_per_second": 451.069,
      "step": 205000
    },
    {
      "epoch": 2.1707380333578588,
      "grad_norm": 4.001476287841797,
      "learning_rate": 3.915075164090621e-05,
      "loss": 0.9375,
      "step": 205050
    },
    {
      "epoch": 2.171267355137862,
      "grad_norm": 3.9157726764678955,
      "learning_rate": 3.914810501799704e-05,
      "loss": 0.9372,
      "step": 205100
    },
    {
      "epoch": 2.171796676917865,
      "grad_norm": 3.9493155479431152,
      "learning_rate": 3.914545839508787e-05,
      "loss": 0.9418,
      "step": 205150
    },
    {
      "epoch": 2.1723259986978682,
      "grad_norm": 3.9749345779418945,
      "learning_rate": 3.91428117721787e-05,
      "loss": 0.9294,
      "step": 205200
    },
    {
      "epoch": 2.1728553204778716,
      "grad_norm": 3.884047269821167,
      "learning_rate": 3.914016514926954e-05,
      "loss": 0.9445,
      "step": 205250
    },
    {
      "epoch": 2.173384642257875,
      "grad_norm": 3.6529760360717773,
      "learning_rate": 3.9137518526360367e-05,
      "loss": 0.9355,
      "step": 205300
    },
    {
      "epoch": 2.173913964037878,
      "grad_norm": 3.6503849029541016,
      "learning_rate": 3.91348719034512e-05,
      "loss": 0.9225,
      "step": 205350
    },
    {
      "epoch": 2.1744432858178815,
      "grad_norm": 3.70237135887146,
      "learning_rate": 3.913222528054203e-05,
      "loss": 0.9419,
      "step": 205400
    },
    {
      "epoch": 2.174972607597885,
      "grad_norm": 3.745042324066162,
      "learning_rate": 3.912957865763286e-05,
      "loss": 0.9248,
      "step": 205450
    },
    {
      "epoch": 2.175501929377888,
      "grad_norm": 3.8764851093292236,
      "learning_rate": 3.9126932034723696e-05,
      "loss": 0.9422,
      "step": 205500
    },
    {
      "epoch": 2.175501929377888,
      "eval_loss": 0.7439568042755127,
      "eval_runtime": 46.5635,
      "eval_samples_per_second": 3606.473,
      "eval_steps_per_second": 450.825,
      "step": 205500
    },
    {
      "epoch": 2.1760312511578914,
      "grad_norm": 3.907275438308716,
      "learning_rate": 3.9124285411814523e-05,
      "loss": 0.9343,
      "step": 205550
    },
    {
      "epoch": 2.1765605729378947,
      "grad_norm": 3.269937753677368,
      "learning_rate": 3.912163878890536e-05,
      "loss": 0.9252,
      "step": 205600
    },
    {
      "epoch": 2.177089894717898,
      "grad_norm": 3.5830628871917725,
      "learning_rate": 3.911899216599619e-05,
      "loss": 0.9336,
      "step": 205650
    },
    {
      "epoch": 2.1776192164979014,
      "grad_norm": 3.8144724369049072,
      "learning_rate": 3.9116345543087026e-05,
      "loss": 0.9182,
      "step": 205700
    },
    {
      "epoch": 2.1781485382779047,
      "grad_norm": 3.94437313079834,
      "learning_rate": 3.911369892017785e-05,
      "loss": 0.9392,
      "step": 205750
    },
    {
      "epoch": 2.178677860057908,
      "grad_norm": 3.9604005813598633,
      "learning_rate": 3.911105229726869e-05,
      "loss": 0.9357,
      "step": 205800
    },
    {
      "epoch": 2.1792071818379113,
      "grad_norm": 3.726620674133301,
      "learning_rate": 3.910840567435952e-05,
      "loss": 0.9175,
      "step": 205850
    },
    {
      "epoch": 2.1797365036179146,
      "grad_norm": 3.7505435943603516,
      "learning_rate": 3.9105759051450355e-05,
      "loss": 0.9372,
      "step": 205900
    },
    {
      "epoch": 2.1802658253979175,
      "grad_norm": 3.663832426071167,
      "learning_rate": 3.910311242854118e-05,
      "loss": 0.9247,
      "step": 205950
    },
    {
      "epoch": 2.180795147177921,
      "grad_norm": 3.4163320064544678,
      "learning_rate": 3.910046580563202e-05,
      "loss": 0.9245,
      "step": 206000
    },
    {
      "epoch": 2.180795147177921,
      "eval_loss": 0.7405552268028259,
      "eval_runtime": 46.543,
      "eval_samples_per_second": 3608.063,
      "eval_steps_per_second": 451.024,
      "step": 206000
    },
    {
      "epoch": 2.181324468957924,
      "grad_norm": 3.3504838943481445,
      "learning_rate": 3.909781918272285e-05,
      "loss": 0.9138,
      "step": 206050
    },
    {
      "epoch": 2.1818537907379274,
      "grad_norm": 3.908357620239258,
      "learning_rate": 3.909517255981368e-05,
      "loss": 0.9067,
      "step": 206100
    },
    {
      "epoch": 2.1823831125179307,
      "grad_norm": 3.5595200061798096,
      "learning_rate": 3.909252593690451e-05,
      "loss": 0.9259,
      "step": 206150
    },
    {
      "epoch": 2.182912434297934,
      "grad_norm": 3.936619758605957,
      "learning_rate": 3.908987931399534e-05,
      "loss": 0.9326,
      "step": 206200
    },
    {
      "epoch": 2.1834417560779373,
      "grad_norm": 3.60663104057312,
      "learning_rate": 3.908723269108618e-05,
      "loss": 0.929,
      "step": 206250
    },
    {
      "epoch": 2.1839710778579406,
      "grad_norm": 3.7414915561676025,
      "learning_rate": 3.908458606817701e-05,
      "loss": 0.9198,
      "step": 206300
    },
    {
      "epoch": 2.184500399637944,
      "grad_norm": 3.883821487426758,
      "learning_rate": 3.908193944526784e-05,
      "loss": 0.9375,
      "step": 206350
    },
    {
      "epoch": 2.1850297214179473,
      "grad_norm": 4.005013465881348,
      "learning_rate": 3.907929282235867e-05,
      "loss": 0.9251,
      "step": 206400
    },
    {
      "epoch": 2.1855590431979506,
      "grad_norm": 3.8864691257476807,
      "learning_rate": 3.907664619944951e-05,
      "loss": 0.9208,
      "step": 206450
    },
    {
      "epoch": 2.186088364977954,
      "grad_norm": 3.7249629497528076,
      "learning_rate": 3.907399957654034e-05,
      "loss": 0.9352,
      "step": 206500
    },
    {
      "epoch": 2.186088364977954,
      "eval_loss": 0.7391692399978638,
      "eval_runtime": 46.5551,
      "eval_samples_per_second": 3607.123,
      "eval_steps_per_second": 450.907,
      "step": 206500
    },
    {
      "epoch": 2.186617686757957,
      "grad_norm": 4.136986255645752,
      "learning_rate": 3.907135295363117e-05,
      "loss": 0.9296,
      "step": 206550
    },
    {
      "epoch": 2.1871470085379605,
      "grad_norm": 3.49111270904541,
      "learning_rate": 3.9068706330722e-05,
      "loss": 0.9265,
      "step": 206600
    },
    {
      "epoch": 2.187676330317964,
      "grad_norm": 3.9123950004577637,
      "learning_rate": 3.906605970781283e-05,
      "loss": 0.9317,
      "step": 206650
    },
    {
      "epoch": 2.1882056520979667,
      "grad_norm": 3.7217748165130615,
      "learning_rate": 3.906341308490367e-05,
      "loss": 0.919,
      "step": 206700
    },
    {
      "epoch": 2.18873497387797,
      "grad_norm": 3.730043888092041,
      "learning_rate": 3.906081939445268e-05,
      "loss": 0.9388,
      "step": 206750
    },
    {
      "epoch": 2.1892642956579733,
      "grad_norm": 3.879065990447998,
      "learning_rate": 3.905817277154351e-05,
      "loss": 0.9115,
      "step": 206800
    },
    {
      "epoch": 2.1897936174379766,
      "grad_norm": 4.154867172241211,
      "learning_rate": 3.905552614863435e-05,
      "loss": 0.9336,
      "step": 206850
    },
    {
      "epoch": 2.19032293921798,
      "grad_norm": 3.7808501720428467,
      "learning_rate": 3.905287952572518e-05,
      "loss": 0.9113,
      "step": 206900
    },
    {
      "epoch": 2.1908522609979832,
      "grad_norm": 3.9486727714538574,
      "learning_rate": 3.905023290281601e-05,
      "loss": 0.9268,
      "step": 206950
    },
    {
      "epoch": 2.1913815827779866,
      "grad_norm": 3.9595212936401367,
      "learning_rate": 3.904758627990684e-05,
      "loss": 0.9391,
      "step": 207000
    },
    {
      "epoch": 2.1913815827779866,
      "eval_loss": 0.7415861487388611,
      "eval_runtime": 46.5414,
      "eval_samples_per_second": 3608.184,
      "eval_steps_per_second": 451.039,
      "step": 207000
    },
    {
      "epoch": 2.19191090455799,
      "grad_norm": 3.48394775390625,
      "learning_rate": 3.904493965699767e-05,
      "loss": 0.9281,
      "step": 207050
    },
    {
      "epoch": 2.192440226337993,
      "grad_norm": 4.076056957244873,
      "learning_rate": 3.904229303408851e-05,
      "loss": 0.9418,
      "step": 207100
    },
    {
      "epoch": 2.1929695481179965,
      "grad_norm": 3.717517614364624,
      "learning_rate": 3.9039646411179334e-05,
      "loss": 0.9203,
      "step": 207150
    },
    {
      "epoch": 2.193498869898,
      "grad_norm": 3.6233572959899902,
      "learning_rate": 3.903699978827017e-05,
      "loss": 0.9294,
      "step": 207200
    },
    {
      "epoch": 2.194028191678003,
      "grad_norm": 3.9200353622436523,
      "learning_rate": 3.9034353165361e-05,
      "loss": 0.9301,
      "step": 207250
    },
    {
      "epoch": 2.1945575134580064,
      "grad_norm": 3.8781068325042725,
      "learning_rate": 3.9031706542451837e-05,
      "loss": 0.9347,
      "step": 207300
    },
    {
      "epoch": 2.1950868352380097,
      "grad_norm": 3.5649211406707764,
      "learning_rate": 3.9029059919542664e-05,
      "loss": 0.9488,
      "step": 207350
    },
    {
      "epoch": 2.195616157018013,
      "grad_norm": 3.473989725112915,
      "learning_rate": 3.90264132966335e-05,
      "loss": 0.9318,
      "step": 207400
    },
    {
      "epoch": 2.196145478798016,
      "grad_norm": 3.7918550968170166,
      "learning_rate": 3.902376667372433e-05,
      "loss": 0.936,
      "step": 207450
    },
    {
      "epoch": 2.1966748005780192,
      "grad_norm": 3.6955032348632812,
      "learning_rate": 3.9021120050815166e-05,
      "loss": 0.9206,
      "step": 207500
    },
    {
      "epoch": 2.1966748005780192,
      "eval_loss": 0.7392118573188782,
      "eval_runtime": 46.5758,
      "eval_samples_per_second": 3605.517,
      "eval_steps_per_second": 450.706,
      "step": 207500
    },
    {
      "epoch": 2.1972041223580225,
      "grad_norm": 3.8075010776519775,
      "learning_rate": 3.9018473427905994e-05,
      "loss": 0.9312,
      "step": 207550
    },
    {
      "epoch": 2.197733444138026,
      "grad_norm": 3.3507068157196045,
      "learning_rate": 3.901582680499683e-05,
      "loss": 0.921,
      "step": 207600
    },
    {
      "epoch": 2.198262765918029,
      "grad_norm": 3.8708972930908203,
      "learning_rate": 3.901318018208766e-05,
      "loss": 0.9345,
      "step": 207650
    },
    {
      "epoch": 2.1987920876980325,
      "grad_norm": 3.899451732635498,
      "learning_rate": 3.901053355917849e-05,
      "loss": 0.9412,
      "step": 207700
    },
    {
      "epoch": 2.199321409478036,
      "grad_norm": 3.276074171066284,
      "learning_rate": 3.900788693626932e-05,
      "loss": 0.9335,
      "step": 207750
    },
    {
      "epoch": 2.199850731258039,
      "grad_norm": 3.5826468467712402,
      "learning_rate": 3.900524031336015e-05,
      "loss": 0.9387,
      "step": 207800
    },
    {
      "epoch": 2.2003800530380424,
      "grad_norm": 3.5535521507263184,
      "learning_rate": 3.9002593690450985e-05,
      "loss": 0.926,
      "step": 207850
    },
    {
      "epoch": 2.2009093748180457,
      "grad_norm": 3.690216302871704,
      "learning_rate": 3.899994706754182e-05,
      "loss": 0.921,
      "step": 207900
    },
    {
      "epoch": 2.201438696598049,
      "grad_norm": 3.677468776702881,
      "learning_rate": 3.899730044463265e-05,
      "loss": 0.9321,
      "step": 207950
    },
    {
      "epoch": 2.2019680183780523,
      "grad_norm": 3.9688944816589355,
      "learning_rate": 3.899465382172348e-05,
      "loss": 0.9269,
      "step": 208000
    },
    {
      "epoch": 2.2019680183780523,
      "eval_loss": 0.7399599552154541,
      "eval_runtime": 46.5921,
      "eval_samples_per_second": 3604.26,
      "eval_steps_per_second": 450.549,
      "step": 208000
    },
    {
      "epoch": 2.2024973401580556,
      "grad_norm": 3.771360158920288,
      "learning_rate": 3.8992007198814314e-05,
      "loss": 0.9241,
      "step": 208050
    },
    {
      "epoch": 2.203026661938059,
      "grad_norm": 3.561248540878296,
      "learning_rate": 3.898936057590515e-05,
      "loss": 0.9416,
      "step": 208100
    },
    {
      "epoch": 2.2035559837180623,
      "grad_norm": 3.8455066680908203,
      "learning_rate": 3.898671395299598e-05,
      "loss": 0.9224,
      "step": 208150
    },
    {
      "epoch": 2.204085305498065,
      "grad_norm": 3.507500171661377,
      "learning_rate": 3.898406733008681e-05,
      "loss": 0.9336,
      "step": 208200
    },
    {
      "epoch": 2.2046146272780685,
      "grad_norm": 4.119946002960205,
      "learning_rate": 3.8981420707177644e-05,
      "loss": 0.9261,
      "step": 208250
    },
    {
      "epoch": 2.2051439490580718,
      "grad_norm": 3.568239450454712,
      "learning_rate": 3.897877408426848e-05,
      "loss": 0.9366,
      "step": 208300
    },
    {
      "epoch": 2.205673270838075,
      "grad_norm": 3.52384352684021,
      "learning_rate": 3.8976127461359305e-05,
      "loss": 0.9344,
      "step": 208350
    },
    {
      "epoch": 2.2062025926180784,
      "grad_norm": 3.3951525688171387,
      "learning_rate": 3.897348083845014e-05,
      "loss": 0.9042,
      "step": 208400
    },
    {
      "epoch": 2.2067319143980817,
      "grad_norm": 3.749295711517334,
      "learning_rate": 3.897083421554097e-05,
      "loss": 0.916,
      "step": 208450
    },
    {
      "epoch": 2.207261236178085,
      "grad_norm": 3.9243366718292236,
      "learning_rate": 3.896818759263181e-05,
      "loss": 0.9243,
      "step": 208500
    },
    {
      "epoch": 2.207261236178085,
      "eval_loss": 0.7384280562400818,
      "eval_runtime": 46.7783,
      "eval_samples_per_second": 3589.913,
      "eval_steps_per_second": 448.755,
      "step": 208500
    },
    {
      "epoch": 2.2077905579580883,
      "grad_norm": 3.9138901233673096,
      "learning_rate": 3.8965540969722635e-05,
      "loss": 0.9316,
      "step": 208550
    },
    {
      "epoch": 2.2083198797380916,
      "grad_norm": 3.784656524658203,
      "learning_rate": 3.896289434681347e-05,
      "loss": 0.9381,
      "step": 208600
    },
    {
      "epoch": 2.208849201518095,
      "grad_norm": 3.801635980606079,
      "learning_rate": 3.8960247723904296e-05,
      "loss": 0.9181,
      "step": 208650
    },
    {
      "epoch": 2.2093785232980983,
      "grad_norm": 4.019967555999756,
      "learning_rate": 3.895760110099513e-05,
      "loss": 0.9424,
      "step": 208700
    },
    {
      "epoch": 2.2099078450781016,
      "grad_norm": 3.7716424465179443,
      "learning_rate": 3.8955007410544145e-05,
      "loss": 0.9279,
      "step": 208750
    },
    {
      "epoch": 2.210437166858105,
      "grad_norm": 3.878753423690796,
      "learning_rate": 3.895236078763498e-05,
      "loss": 0.9128,
      "step": 208800
    },
    {
      "epoch": 2.210966488638108,
      "grad_norm": 4.0661797523498535,
      "learning_rate": 3.8949714164725807e-05,
      "loss": 0.9243,
      "step": 208850
    },
    {
      "epoch": 2.2114958104181115,
      "grad_norm": 3.662972927093506,
      "learning_rate": 3.894706754181665e-05,
      "loss": 0.9383,
      "step": 208900
    },
    {
      "epoch": 2.2120251321981144,
      "grad_norm": 3.9948034286499023,
      "learning_rate": 3.8944420918907475e-05,
      "loss": 0.9362,
      "step": 208950
    },
    {
      "epoch": 2.2125544539781177,
      "grad_norm": 3.5743556022644043,
      "learning_rate": 3.894177429599831e-05,
      "loss": 0.9344,
      "step": 209000
    },
    {
      "epoch": 2.2125544539781177,
      "eval_loss": 0.7360752820968628,
      "eval_runtime": 46.6118,
      "eval_samples_per_second": 3602.738,
      "eval_steps_per_second": 450.358,
      "step": 209000
    },
    {
      "epoch": 2.213083775758121,
      "grad_norm": 3.6368725299835205,
      "learning_rate": 3.8939127673089136e-05,
      "loss": 0.9265,
      "step": 209050
    },
    {
      "epoch": 2.2136130975381243,
      "grad_norm": 4.001761436462402,
      "learning_rate": 3.893648105017998e-05,
      "loss": 0.9262,
      "step": 209100
    },
    {
      "epoch": 2.2141424193181276,
      "grad_norm": 3.8771584033966064,
      "learning_rate": 3.8933834427270804e-05,
      "loss": 0.9162,
      "step": 209150
    },
    {
      "epoch": 2.214671741098131,
      "grad_norm": 4.015599250793457,
      "learning_rate": 3.893118780436164e-05,
      "loss": 0.9235,
      "step": 209200
    },
    {
      "epoch": 2.2152010628781342,
      "grad_norm": 3.878507614135742,
      "learning_rate": 3.8928541181452466e-05,
      "loss": 0.9054,
      "step": 209250
    },
    {
      "epoch": 2.2157303846581375,
      "grad_norm": 3.7638895511627197,
      "learning_rate": 3.89258945585433e-05,
      "loss": 0.9192,
      "step": 209300
    },
    {
      "epoch": 2.216259706438141,
      "grad_norm": 3.602003812789917,
      "learning_rate": 3.8923247935634134e-05,
      "loss": 0.92,
      "step": 209350
    },
    {
      "epoch": 2.216789028218144,
      "grad_norm": 3.9299604892730713,
      "learning_rate": 3.892060131272496e-05,
      "loss": 0.9403,
      "step": 209400
    },
    {
      "epoch": 2.2173183499981475,
      "grad_norm": 3.664635181427002,
      "learning_rate": 3.8917954689815795e-05,
      "loss": 0.9135,
      "step": 209450
    },
    {
      "epoch": 2.217847671778151,
      "grad_norm": 3.8142857551574707,
      "learning_rate": 3.891530806690663e-05,
      "loss": 0.9148,
      "step": 209500
    },
    {
      "epoch": 2.217847671778151,
      "eval_loss": 0.7355544567108154,
      "eval_runtime": 46.5685,
      "eval_samples_per_second": 3606.089,
      "eval_steps_per_second": 450.777,
      "step": 209500
    },
    {
      "epoch": 2.218376993558154,
      "grad_norm": 3.9871277809143066,
      "learning_rate": 3.8912661443997464e-05,
      "loss": 0.9134,
      "step": 209550
    },
    {
      "epoch": 2.2189063153381574,
      "grad_norm": 4.223238468170166,
      "learning_rate": 3.891001482108829e-05,
      "loss": 0.9423,
      "step": 209600
    },
    {
      "epoch": 2.2194356371181607,
      "grad_norm": 3.8153839111328125,
      "learning_rate": 3.8907368198179125e-05,
      "loss": 0.9278,
      "step": 209650
    },
    {
      "epoch": 2.2199649588981636,
      "grad_norm": 3.840953826904297,
      "learning_rate": 3.890472157526996e-05,
      "loss": 0.9243,
      "step": 209700
    },
    {
      "epoch": 2.220494280678167,
      "grad_norm": 3.898761749267578,
      "learning_rate": 3.8902074952360786e-05,
      "loss": 0.9117,
      "step": 209750
    },
    {
      "epoch": 2.22102360245817,
      "grad_norm": 3.9480624198913574,
      "learning_rate": 3.889942832945162e-05,
      "loss": 0.9315,
      "step": 209800
    },
    {
      "epoch": 2.2215529242381735,
      "grad_norm": 3.880676507949829,
      "learning_rate": 3.889678170654245e-05,
      "loss": 0.9177,
      "step": 209850
    },
    {
      "epoch": 2.222082246018177,
      "grad_norm": 3.561400890350342,
      "learning_rate": 3.889413508363329e-05,
      "loss": 0.929,
      "step": 209900
    },
    {
      "epoch": 2.22261156779818,
      "grad_norm": 3.969481945037842,
      "learning_rate": 3.8891488460724116e-05,
      "loss": 0.9406,
      "step": 209950
    },
    {
      "epoch": 2.2231408895781835,
      "grad_norm": 4.0528178215026855,
      "learning_rate": 3.888884183781495e-05,
      "loss": 0.9338,
      "step": 210000
    },
    {
      "epoch": 2.2231408895781835,
      "eval_loss": 0.733607828617096,
      "eval_runtime": 46.6218,
      "eval_samples_per_second": 3601.962,
      "eval_steps_per_second": 450.261,
      "step": 210000
    },
    {
      "epoch": 2.2236702113581868,
      "grad_norm": 3.69832706451416,
      "learning_rate": 3.888619521490578e-05,
      "loss": 0.9226,
      "step": 210050
    },
    {
      "epoch": 2.22419953313819,
      "grad_norm": 3.7246451377868652,
      "learning_rate": 3.888354859199662e-05,
      "loss": 0.9295,
      "step": 210100
    },
    {
      "epoch": 2.2247288549181934,
      "grad_norm": 3.597195625305176,
      "learning_rate": 3.8880901969087446e-05,
      "loss": 0.9114,
      "step": 210150
    },
    {
      "epoch": 2.2252581766981967,
      "grad_norm": 4.084117889404297,
      "learning_rate": 3.887825534617828e-05,
      "loss": 0.9354,
      "step": 210200
    },
    {
      "epoch": 2.2257874984782,
      "grad_norm": 3.5870559215545654,
      "learning_rate": 3.887560872326911e-05,
      "loss": 0.9305,
      "step": 210250
    },
    {
      "epoch": 2.2263168202582033,
      "grad_norm": 3.926239490509033,
      "learning_rate": 3.887296210035994e-05,
      "loss": 0.917,
      "step": 210300
    },
    {
      "epoch": 2.2268461420382066,
      "grad_norm": 3.4178617000579834,
      "learning_rate": 3.8870315477450775e-05,
      "loss": 0.9311,
      "step": 210350
    },
    {
      "epoch": 2.22737546381821,
      "grad_norm": 3.5839667320251465,
      "learning_rate": 3.88676688545416e-05,
      "loss": 0.9093,
      "step": 210400
    },
    {
      "epoch": 2.227904785598213,
      "grad_norm": 3.7412948608398438,
      "learning_rate": 3.886502223163244e-05,
      "loss": 0.9156,
      "step": 210450
    },
    {
      "epoch": 2.228434107378216,
      "grad_norm": 4.1226420402526855,
      "learning_rate": 3.886237560872327e-05,
      "loss": 0.9203,
      "step": 210500
    },
    {
      "epoch": 2.228434107378216,
      "eval_loss": 0.734715461730957,
      "eval_runtime": 46.6281,
      "eval_samples_per_second": 3601.479,
      "eval_steps_per_second": 450.201,
      "step": 210500
    },
    {
      "epoch": 2.2289634291582194,
      "grad_norm": 3.7872488498687744,
      "learning_rate": 3.8859728985814105e-05,
      "loss": 0.9024,
      "step": 210550
    },
    {
      "epoch": 2.2294927509382227,
      "grad_norm": 3.5927035808563232,
      "learning_rate": 3.885708236290493e-05,
      "loss": 0.9185,
      "step": 210600
    },
    {
      "epoch": 2.230022072718226,
      "grad_norm": 3.928804636001587,
      "learning_rate": 3.8854435739995766e-05,
      "loss": 0.9137,
      "step": 210650
    },
    {
      "epoch": 2.2305513944982294,
      "grad_norm": 4.0959038734436035,
      "learning_rate": 3.88517891170866e-05,
      "loss": 0.9263,
      "step": 210700
    },
    {
      "epoch": 2.2310807162782327,
      "grad_norm": 4.117420673370361,
      "learning_rate": 3.8849195426635615e-05,
      "loss": 0.919,
      "step": 210750
    },
    {
      "epoch": 2.231610038058236,
      "grad_norm": 3.8466172218322754,
      "learning_rate": 3.884654880372644e-05,
      "loss": 0.9282,
      "step": 210800
    },
    {
      "epoch": 2.2321393598382393,
      "grad_norm": 3.63830304145813,
      "learning_rate": 3.8843902180817277e-05,
      "loss": 0.9119,
      "step": 210850
    },
    {
      "epoch": 2.2326686816182426,
      "grad_norm": 4.076326847076416,
      "learning_rate": 3.884125555790811e-05,
      "loss": 0.9333,
      "step": 210900
    },
    {
      "epoch": 2.233198003398246,
      "grad_norm": 3.609741449356079,
      "learning_rate": 3.8838608934998945e-05,
      "loss": 0.9118,
      "step": 210950
    },
    {
      "epoch": 2.2337273251782492,
      "grad_norm": 3.8673365116119385,
      "learning_rate": 3.883596231208977e-05,
      "loss": 0.9137,
      "step": 211000
    },
    {
      "epoch": 2.2337273251782492,
      "eval_loss": 0.7333234548568726,
      "eval_runtime": 46.7809,
      "eval_samples_per_second": 3589.716,
      "eval_steps_per_second": 448.731,
      "step": 211000
    },
    {
      "epoch": 2.2342566469582525,
      "grad_norm": 3.6010143756866455,
      "learning_rate": 3.8833315689180606e-05,
      "loss": 0.925,
      "step": 211050
    },
    {
      "epoch": 2.234785968738256,
      "grad_norm": 3.593571901321411,
      "learning_rate": 3.883066906627144e-05,
      "loss": 0.9232,
      "step": 211100
    },
    {
      "epoch": 2.235315290518259,
      "grad_norm": 3.9890213012695312,
      "learning_rate": 3.8828022443362274e-05,
      "loss": 0.9138,
      "step": 211150
    },
    {
      "epoch": 2.235844612298262,
      "grad_norm": 3.7909762859344482,
      "learning_rate": 3.88253758204531e-05,
      "loss": 0.916,
      "step": 211200
    },
    {
      "epoch": 2.2363739340782653,
      "grad_norm": 3.9300758838653564,
      "learning_rate": 3.8822782130002116e-05,
      "loss": 0.9191,
      "step": 211250
    },
    {
      "epoch": 2.2369032558582687,
      "grad_norm": 3.750528573989868,
      "learning_rate": 3.882013550709295e-05,
      "loss": 0.9315,
      "step": 211300
    },
    {
      "epoch": 2.237432577638272,
      "grad_norm": 3.7896745204925537,
      "learning_rate": 3.8817488884183785e-05,
      "loss": 0.936,
      "step": 211350
    },
    {
      "epoch": 2.2379618994182753,
      "grad_norm": 3.629849672317505,
      "learning_rate": 3.881484226127461e-05,
      "loss": 0.9196,
      "step": 211400
    },
    {
      "epoch": 2.2384912211982786,
      "grad_norm": 4.1479716300964355,
      "learning_rate": 3.8812195638365446e-05,
      "loss": 0.9108,
      "step": 211450
    },
    {
      "epoch": 2.239020542978282,
      "grad_norm": 4.097816467285156,
      "learning_rate": 3.880954901545628e-05,
      "loss": 0.9184,
      "step": 211500
    },
    {
      "epoch": 2.239020542978282,
      "eval_loss": 0.7305128574371338,
      "eval_runtime": 46.6092,
      "eval_samples_per_second": 3602.94,
      "eval_steps_per_second": 450.384,
      "step": 211500
    },
    {
      "epoch": 2.239549864758285,
      "grad_norm": 3.8148751258850098,
      "learning_rate": 3.8806902392547114e-05,
      "loss": 0.9266,
      "step": 211550
    },
    {
      "epoch": 2.2400791865382885,
      "grad_norm": 3.5821237564086914,
      "learning_rate": 3.880425576963794e-05,
      "loss": 0.9161,
      "step": 211600
    },
    {
      "epoch": 2.240608508318292,
      "grad_norm": 3.7820770740509033,
      "learning_rate": 3.8801609146728776e-05,
      "loss": 0.9264,
      "step": 211650
    },
    {
      "epoch": 2.241137830098295,
      "grad_norm": 4.419674396514893,
      "learning_rate": 3.879896252381961e-05,
      "loss": 0.9207,
      "step": 211700
    },
    {
      "epoch": 2.2416671518782985,
      "grad_norm": 3.5646939277648926,
      "learning_rate": 3.879631590091044e-05,
      "loss": 0.9322,
      "step": 211750
    },
    {
      "epoch": 2.2421964736583018,
      "grad_norm": 4.117759704589844,
      "learning_rate": 3.879366927800127e-05,
      "loss": 0.9237,
      "step": 211800
    },
    {
      "epoch": 2.242725795438305,
      "grad_norm": 3.9583702087402344,
      "learning_rate": 3.87910226550921e-05,
      "loss": 0.9185,
      "step": 211850
    },
    {
      "epoch": 2.2432551172183084,
      "grad_norm": 3.629993438720703,
      "learning_rate": 3.878837603218294e-05,
      "loss": 0.9162,
      "step": 211900
    },
    {
      "epoch": 2.2437844389983113,
      "grad_norm": 3.837341070175171,
      "learning_rate": 3.878572940927377e-05,
      "loss": 0.9212,
      "step": 211950
    },
    {
      "epoch": 2.2443137607783146,
      "grad_norm": 3.953066349029541,
      "learning_rate": 3.87830827863646e-05,
      "loss": 0.9098,
      "step": 212000
    },
    {
      "epoch": 2.2443137607783146,
      "eval_loss": 0.7295520901679993,
      "eval_runtime": 46.5661,
      "eval_samples_per_second": 3606.271,
      "eval_steps_per_second": 450.8,
      "step": 212000
    },
    {
      "epoch": 2.244843082558318,
      "grad_norm": 3.879528760910034,
      "learning_rate": 3.878043616345543e-05,
      "loss": 0.914,
      "step": 212050
    },
    {
      "epoch": 2.245372404338321,
      "grad_norm": 3.6911065578460693,
      "learning_rate": 3.877778954054627e-05,
      "loss": 0.918,
      "step": 212100
    },
    {
      "epoch": 2.2459017261183245,
      "grad_norm": 3.730231523513794,
      "learning_rate": 3.8775142917637096e-05,
      "loss": 0.9012,
      "step": 212150
    },
    {
      "epoch": 2.246431047898328,
      "grad_norm": 4.1521315574646,
      "learning_rate": 3.877249629472793e-05,
      "loss": 0.925,
      "step": 212200
    },
    {
      "epoch": 2.246960369678331,
      "grad_norm": 4.046037197113037,
      "learning_rate": 3.876984967181876e-05,
      "loss": 0.9115,
      "step": 212250
    },
    {
      "epoch": 2.2474896914583344,
      "grad_norm": 3.5934641361236572,
      "learning_rate": 3.876720304890959e-05,
      "loss": 0.9356,
      "step": 212300
    },
    {
      "epoch": 2.2480190132383377,
      "grad_norm": 3.5287983417510986,
      "learning_rate": 3.8764556426000426e-05,
      "loss": 0.9154,
      "step": 212350
    },
    {
      "epoch": 2.248548335018341,
      "grad_norm": 3.7404980659484863,
      "learning_rate": 3.876190980309125e-05,
      "loss": 0.9189,
      "step": 212400
    },
    {
      "epoch": 2.2490776567983444,
      "grad_norm": 3.6998183727264404,
      "learning_rate": 3.875926318018209e-05,
      "loss": 0.9141,
      "step": 212450
    },
    {
      "epoch": 2.2496069785783477,
      "grad_norm": 3.831724166870117,
      "learning_rate": 3.875661655727292e-05,
      "loss": 0.9188,
      "step": 212500
    },
    {
      "epoch": 2.2496069785783477,
      "eval_loss": 0.7289380431175232,
      "eval_runtime": 46.5283,
      "eval_samples_per_second": 3609.199,
      "eval_steps_per_second": 451.166,
      "step": 212500
    },
    {
      "epoch": 2.250136300358351,
      "grad_norm": 3.391770362854004,
      "learning_rate": 3.8753969934363756e-05,
      "loss": 0.9363,
      "step": 212550
    },
    {
      "epoch": 2.2506656221383543,
      "grad_norm": 3.751248359680176,
      "learning_rate": 3.875132331145458e-05,
      "loss": 0.9243,
      "step": 212600
    },
    {
      "epoch": 2.2511949439183576,
      "grad_norm": 4.055469512939453,
      "learning_rate": 3.874867668854542e-05,
      "loss": 0.9262,
      "step": 212650
    },
    {
      "epoch": 2.2517242656983605,
      "grad_norm": 4.244832992553711,
      "learning_rate": 3.874603006563625e-05,
      "loss": 0.9253,
      "step": 212700
    },
    {
      "epoch": 2.252253587478364,
      "grad_norm": 3.977566957473755,
      "learning_rate": 3.8743383442727085e-05,
      "loss": 0.9233,
      "step": 212750
    },
    {
      "epoch": 2.252782909258367,
      "grad_norm": 4.179144859313965,
      "learning_rate": 3.874073681981791e-05,
      "loss": 0.898,
      "step": 212800
    },
    {
      "epoch": 2.2533122310383704,
      "grad_norm": 4.018533229827881,
      "learning_rate": 3.873809019690875e-05,
      "loss": 0.9422,
      "step": 212850
    },
    {
      "epoch": 2.2538415528183737,
      "grad_norm": 3.701336622238159,
      "learning_rate": 3.873544357399958e-05,
      "loss": 0.9192,
      "step": 212900
    },
    {
      "epoch": 2.254370874598377,
      "grad_norm": 3.8715765476226807,
      "learning_rate": 3.873279695109041e-05,
      "loss": 0.9036,
      "step": 212950
    },
    {
      "epoch": 2.2549001963783804,
      "grad_norm": 4.039436340332031,
      "learning_rate": 3.873015032818124e-05,
      "loss": 0.9078,
      "step": 213000
    },
    {
      "epoch": 2.2549001963783804,
      "eval_loss": 0.7278611660003662,
      "eval_runtime": 46.5439,
      "eval_samples_per_second": 3607.988,
      "eval_steps_per_second": 451.015,
      "step": 213000
    },
    {
      "epoch": 2.2554295181583837,
      "grad_norm": 4.157283306121826,
      "learning_rate": 3.872750370527207e-05,
      "loss": 0.9194,
      "step": 213050
    },
    {
      "epoch": 2.255958839938387,
      "grad_norm": 3.9991636276245117,
      "learning_rate": 3.872485708236291e-05,
      "loss": 0.9342,
      "step": 213100
    },
    {
      "epoch": 2.2564881617183903,
      "grad_norm": 3.924640655517578,
      "learning_rate": 3.872221045945374e-05,
      "loss": 0.929,
      "step": 213150
    },
    {
      "epoch": 2.2570174834983936,
      "grad_norm": 4.038267612457275,
      "learning_rate": 3.871956383654457e-05,
      "loss": 0.9285,
      "step": 213200
    },
    {
      "epoch": 2.257546805278397,
      "grad_norm": 4.301643371582031,
      "learning_rate": 3.87169172136354e-05,
      "loss": 0.9174,
      "step": 213250
    },
    {
      "epoch": 2.2580761270584,
      "grad_norm": 3.8940672874450684,
      "learning_rate": 3.871427059072624e-05,
      "loss": 0.9252,
      "step": 213300
    },
    {
      "epoch": 2.2586054488384035,
      "grad_norm": 3.7411606311798096,
      "learning_rate": 3.871162396781707e-05,
      "loss": 0.9235,
      "step": 213350
    },
    {
      "epoch": 2.259134770618407,
      "grad_norm": 4.105300426483154,
      "learning_rate": 3.87089773449079e-05,
      "loss": 0.9253,
      "step": 213400
    },
    {
      "epoch": 2.2596640923984097,
      "grad_norm": 3.7629570960998535,
      "learning_rate": 3.870633072199873e-05,
      "loss": 0.9164,
      "step": 213450
    },
    {
      "epoch": 2.260193414178413,
      "grad_norm": 3.9429452419281006,
      "learning_rate": 3.870368409908956e-05,
      "loss": 0.9152,
      "step": 213500
    },
    {
      "epoch": 2.260193414178413,
      "eval_loss": 0.7272513508796692,
      "eval_runtime": 46.5647,
      "eval_samples_per_second": 3606.382,
      "eval_steps_per_second": 450.814,
      "step": 213500
    },
    {
      "epoch": 2.2607227359584163,
      "grad_norm": 4.101785659790039,
      "learning_rate": 3.87010374761804e-05,
      "loss": 0.9279,
      "step": 213550
    },
    {
      "epoch": 2.2612520577384196,
      "grad_norm": 3.843158006668091,
      "learning_rate": 3.8698390853271224e-05,
      "loss": 0.9117,
      "step": 213600
    },
    {
      "epoch": 2.261781379518423,
      "grad_norm": 3.6823816299438477,
      "learning_rate": 3.869574423036206e-05,
      "loss": 0.922,
      "step": 213650
    },
    {
      "epoch": 2.2623107012984263,
      "grad_norm": 4.165548324584961,
      "learning_rate": 3.869309760745289e-05,
      "loss": 0.9222,
      "step": 213700
    },
    {
      "epoch": 2.2628400230784296,
      "grad_norm": 3.8640780448913574,
      "learning_rate": 3.8690450984543727e-05,
      "loss": 0.9258,
      "step": 213750
    },
    {
      "epoch": 2.263369344858433,
      "grad_norm": 4.061565399169922,
      "learning_rate": 3.8687804361634554e-05,
      "loss": 0.9298,
      "step": 213800
    },
    {
      "epoch": 2.263898666638436,
      "grad_norm": 3.7280359268188477,
      "learning_rate": 3.868515773872539e-05,
      "loss": 0.9175,
      "step": 213850
    },
    {
      "epoch": 2.2644279884184395,
      "grad_norm": 3.896327257156372,
      "learning_rate": 3.868251111581622e-05,
      "loss": 0.9373,
      "step": 213900
    },
    {
      "epoch": 2.264957310198443,
      "grad_norm": 3.883385419845581,
      "learning_rate": 3.8679864492907056e-05,
      "loss": 0.9228,
      "step": 213950
    },
    {
      "epoch": 2.265486631978446,
      "grad_norm": 3.987565040588379,
      "learning_rate": 3.8677217869997884e-05,
      "loss": 0.9149,
      "step": 214000
    },
    {
      "epoch": 2.265486631978446,
      "eval_loss": 0.723935067653656,
      "eval_runtime": 46.6265,
      "eval_samples_per_second": 3601.604,
      "eval_steps_per_second": 450.217,
      "step": 214000
    },
    {
      "epoch": 2.2660159537584494,
      "grad_norm": 4.150205135345459,
      "learning_rate": 3.86746241795469e-05,
      "loss": 0.9262,
      "step": 214050
    },
    {
      "epoch": 2.2665452755384528,
      "grad_norm": 3.673849582672119,
      "learning_rate": 3.867197755663773e-05,
      "loss": 0.9037,
      "step": 214100
    },
    {
      "epoch": 2.267074597318456,
      "grad_norm": 3.7572574615478516,
      "learning_rate": 3.8669330933728566e-05,
      "loss": 0.9271,
      "step": 214150
    },
    {
      "epoch": 2.267603919098459,
      "grad_norm": 3.7538657188415527,
      "learning_rate": 3.8666684310819394e-05,
      "loss": 0.9362,
      "step": 214200
    },
    {
      "epoch": 2.2681332408784622,
      "grad_norm": 4.06874942779541,
      "learning_rate": 3.866403768791023e-05,
      "loss": 0.9199,
      "step": 214250
    },
    {
      "epoch": 2.2686625626584656,
      "grad_norm": 4.035738468170166,
      "learning_rate": 3.866139106500106e-05,
      "loss": 0.9045,
      "step": 214300
    },
    {
      "epoch": 2.269191884438469,
      "grad_norm": 3.553544759750366,
      "learning_rate": 3.8658744442091896e-05,
      "loss": 0.9066,
      "step": 214350
    },
    {
      "epoch": 2.269721206218472,
      "grad_norm": 3.641096830368042,
      "learning_rate": 3.865609781918272e-05,
      "loss": 0.9157,
      "step": 214400
    },
    {
      "epoch": 2.2702505279984755,
      "grad_norm": 3.6965389251708984,
      "learning_rate": 3.865345119627356e-05,
      "loss": 0.9071,
      "step": 214450
    },
    {
      "epoch": 2.270779849778479,
      "grad_norm": 3.8976831436157227,
      "learning_rate": 3.865080457336439e-05,
      "loss": 0.9066,
      "step": 214500
    },
    {
      "epoch": 2.270779849778479,
      "eval_loss": 0.7245081663131714,
      "eval_runtime": 46.6068,
      "eval_samples_per_second": 3603.124,
      "eval_steps_per_second": 450.407,
      "step": 214500
    },
    {
      "epoch": 2.271309171558482,
      "grad_norm": 3.9712135791778564,
      "learning_rate": 3.864815795045522e-05,
      "loss": 0.9173,
      "step": 214550
    },
    {
      "epoch": 2.2718384933384854,
      "grad_norm": 3.837378740310669,
      "learning_rate": 3.864551132754605e-05,
      "loss": 0.9036,
      "step": 214600
    },
    {
      "epoch": 2.2723678151184887,
      "grad_norm": 3.764486074447632,
      "learning_rate": 3.864286470463688e-05,
      "loss": 0.9221,
      "step": 214650
    },
    {
      "epoch": 2.272897136898492,
      "grad_norm": 3.724684715270996,
      "learning_rate": 3.864021808172772e-05,
      "loss": 0.9417,
      "step": 214700
    },
    {
      "epoch": 2.2734264586784954,
      "grad_norm": 3.6078600883483887,
      "learning_rate": 3.863757145881855e-05,
      "loss": 0.925,
      "step": 214750
    },
    {
      "epoch": 2.2739557804584987,
      "grad_norm": 3.8857035636901855,
      "learning_rate": 3.863492483590938e-05,
      "loss": 0.9247,
      "step": 214800
    },
    {
      "epoch": 2.274485102238502,
      "grad_norm": 3.8012752532958984,
      "learning_rate": 3.863227821300021e-05,
      "loss": 0.9261,
      "step": 214850
    },
    {
      "epoch": 2.2750144240185053,
      "grad_norm": 3.6429014205932617,
      "learning_rate": 3.862963159009105e-05,
      "loss": 0.9139,
      "step": 214900
    },
    {
      "epoch": 2.275543745798508,
      "grad_norm": 3.8798069953918457,
      "learning_rate": 3.862698496718188e-05,
      "loss": 0.9199,
      "step": 214950
    },
    {
      "epoch": 2.2760730675785115,
      "grad_norm": 3.836606025695801,
      "learning_rate": 3.862433834427271e-05,
      "loss": 0.9296,
      "step": 215000
    },
    {
      "epoch": 2.2760730675785115,
      "eval_loss": 0.724020779132843,
      "eval_runtime": 46.5814,
      "eval_samples_per_second": 3605.089,
      "eval_steps_per_second": 450.652,
      "step": 215000
    },
    {
      "epoch": 2.2766023893585148,
      "grad_norm": 3.8450851440429688,
      "learning_rate": 3.862169172136354e-05,
      "loss": 0.9139,
      "step": 215050
    },
    {
      "epoch": 2.277131711138518,
      "grad_norm": 4.112887859344482,
      "learning_rate": 3.8619045098454374e-05,
      "loss": 0.9346,
      "step": 215100
    },
    {
      "epoch": 2.2776610329185214,
      "grad_norm": 3.5735435485839844,
      "learning_rate": 3.861639847554521e-05,
      "loss": 0.9319,
      "step": 215150
    },
    {
      "epoch": 2.2781903546985247,
      "grad_norm": 3.902228355407715,
      "learning_rate": 3.8613751852636035e-05,
      "loss": 0.9185,
      "step": 215200
    },
    {
      "epoch": 2.278719676478528,
      "grad_norm": 4.104791164398193,
      "learning_rate": 3.861110522972687e-05,
      "loss": 0.9173,
      "step": 215250
    },
    {
      "epoch": 2.2792489982585313,
      "grad_norm": 3.6253321170806885,
      "learning_rate": 3.86084586068177e-05,
      "loss": 0.9251,
      "step": 215300
    },
    {
      "epoch": 2.2797783200385346,
      "grad_norm": 4.0882062911987305,
      "learning_rate": 3.860581198390854e-05,
      "loss": 0.9233,
      "step": 215350
    },
    {
      "epoch": 2.280307641818538,
      "grad_norm": 3.824320077896118,
      "learning_rate": 3.8603165360999365e-05,
      "loss": 0.9184,
      "step": 215400
    },
    {
      "epoch": 2.2808369635985413,
      "grad_norm": 3.9570677280426025,
      "learning_rate": 3.86005187380902e-05,
      "loss": 0.9291,
      "step": 215450
    },
    {
      "epoch": 2.2813662853785446,
      "grad_norm": 3.7648260593414307,
      "learning_rate": 3.859787211518103e-05,
      "loss": 0.9322,
      "step": 215500
    },
    {
      "epoch": 2.2813662853785446,
      "eval_loss": 0.7217463254928589,
      "eval_runtime": 46.56,
      "eval_samples_per_second": 3606.746,
      "eval_steps_per_second": 450.859,
      "step": 215500
    },
    {
      "epoch": 2.281895607158548,
      "grad_norm": 3.9623117446899414,
      "learning_rate": 3.859522549227187e-05,
      "loss": 0.9282,
      "step": 215550
    },
    {
      "epoch": 2.282424928938551,
      "grad_norm": 3.7257044315338135,
      "learning_rate": 3.8592578869362694e-05,
      "loss": 0.9183,
      "step": 215600
    },
    {
      "epoch": 2.2829542507185545,
      "grad_norm": 4.151682376861572,
      "learning_rate": 3.858993224645353e-05,
      "loss": 0.9201,
      "step": 215650
    },
    {
      "epoch": 2.2834835724985574,
      "grad_norm": 3.5551090240478516,
      "learning_rate": 3.858728562354436e-05,
      "loss": 0.9155,
      "step": 215700
    },
    {
      "epoch": 2.2840128942785607,
      "grad_norm": 3.283658504486084,
      "learning_rate": 3.858463900063519e-05,
      "loss": 0.9104,
      "step": 215750
    },
    {
      "epoch": 2.284542216058564,
      "grad_norm": 3.9395909309387207,
      "learning_rate": 3.8581992377726024e-05,
      "loss": 0.922,
      "step": 215800
    },
    {
      "epoch": 2.2850715378385673,
      "grad_norm": 3.705906391143799,
      "learning_rate": 3.857934575481685e-05,
      "loss": 0.9171,
      "step": 215850
    },
    {
      "epoch": 2.2856008596185706,
      "grad_norm": 3.8396494388580322,
      "learning_rate": 3.857669913190769e-05,
      "loss": 0.9153,
      "step": 215900
    },
    {
      "epoch": 2.286130181398574,
      "grad_norm": 3.801697254180908,
      "learning_rate": 3.857405250899852e-05,
      "loss": 0.9249,
      "step": 215950
    },
    {
      "epoch": 2.2866595031785772,
      "grad_norm": 3.7152302265167236,
      "learning_rate": 3.8571405886089354e-05,
      "loss": 0.9053,
      "step": 216000
    },
    {
      "epoch": 2.2866595031785772,
      "eval_loss": 0.7234823703765869,
      "eval_runtime": 46.5672,
      "eval_samples_per_second": 3606.186,
      "eval_steps_per_second": 450.789,
      "step": 216000
    },
    {
      "epoch": 2.2871888249585806,
      "grad_norm": 3.715676784515381,
      "learning_rate": 3.856875926318018e-05,
      "loss": 0.9249,
      "step": 216050
    },
    {
      "epoch": 2.287718146738584,
      "grad_norm": 3.394348621368408,
      "learning_rate": 3.8566112640271015e-05,
      "loss": 0.9088,
      "step": 216100
    },
    {
      "epoch": 2.288247468518587,
      "grad_norm": 4.032154560089111,
      "learning_rate": 3.856346601736185e-05,
      "loss": 0.9218,
      "step": 216150
    },
    {
      "epoch": 2.2887767902985905,
      "grad_norm": 4.115226745605469,
      "learning_rate": 3.8560819394452676e-05,
      "loss": 0.9103,
      "step": 216200
    },
    {
      "epoch": 2.289306112078594,
      "grad_norm": 4.550808429718018,
      "learning_rate": 3.855817277154351e-05,
      "loss": 0.9123,
      "step": 216250
    },
    {
      "epoch": 2.289835433858597,
      "grad_norm": 4.030376434326172,
      "learning_rate": 3.8555526148634345e-05,
      "loss": 0.9228,
      "step": 216300
    },
    {
      "epoch": 2.2903647556386004,
      "grad_norm": 4.202714920043945,
      "learning_rate": 3.855287952572518e-05,
      "loss": 0.9253,
      "step": 216350
    },
    {
      "epoch": 2.2908940774186037,
      "grad_norm": 3.512728214263916,
      "learning_rate": 3.8550232902816006e-05,
      "loss": 0.9251,
      "step": 216400
    },
    {
      "epoch": 2.2914233991986066,
      "grad_norm": 3.6412603855133057,
      "learning_rate": 3.854758627990684e-05,
      "loss": 0.906,
      "step": 216450
    },
    {
      "epoch": 2.29195272097861,
      "grad_norm": 4.195975303649902,
      "learning_rate": 3.8544939656997674e-05,
      "loss": 0.9209,
      "step": 216500
    },
    {
      "epoch": 2.29195272097861,
      "eval_loss": 0.7232480049133301,
      "eval_runtime": 46.5072,
      "eval_samples_per_second": 3610.84,
      "eval_steps_per_second": 451.371,
      "step": 216500
    },
    {
      "epoch": 2.2924820427586132,
      "grad_norm": 3.6463370323181152,
      "learning_rate": 3.854229303408851e-05,
      "loss": 0.9129,
      "step": 216550
    },
    {
      "epoch": 2.2930113645386165,
      "grad_norm": 3.751795768737793,
      "learning_rate": 3.8539646411179336e-05,
      "loss": 0.8972,
      "step": 216600
    },
    {
      "epoch": 2.29354068631862,
      "grad_norm": 3.293610095977783,
      "learning_rate": 3.853699978827017e-05,
      "loss": 0.8984,
      "step": 216650
    },
    {
      "epoch": 2.294070008098623,
      "grad_norm": 4.1059112548828125,
      "learning_rate": 3.8534353165361004e-05,
      "loss": 0.9202,
      "step": 216700
    },
    {
      "epoch": 2.2945993298786265,
      "grad_norm": 3.696014404296875,
      "learning_rate": 3.853170654245183e-05,
      "loss": 0.9169,
      "step": 216750
    },
    {
      "epoch": 2.29512865165863,
      "grad_norm": 4.061631679534912,
      "learning_rate": 3.8529059919542665e-05,
      "loss": 0.9188,
      "step": 216800
    },
    {
      "epoch": 2.295657973438633,
      "grad_norm": 3.699096918106079,
      "learning_rate": 3.852641329663349e-05,
      "loss": 0.9093,
      "step": 216850
    },
    {
      "epoch": 2.2961872952186364,
      "grad_norm": 3.984010696411133,
      "learning_rate": 3.8523766673724334e-05,
      "loss": 0.9311,
      "step": 216900
    },
    {
      "epoch": 2.2967166169986397,
      "grad_norm": 4.217850208282471,
      "learning_rate": 3.852112005081516e-05,
      "loss": 0.9165,
      "step": 216950
    },
    {
      "epoch": 2.297245938778643,
      "grad_norm": 4.167273044586182,
      "learning_rate": 3.8518473427905995e-05,
      "loss": 0.8999,
      "step": 217000
    },
    {
      "epoch": 2.297245938778643,
      "eval_loss": 0.7219477891921997,
      "eval_runtime": 46.5302,
      "eval_samples_per_second": 3609.058,
      "eval_steps_per_second": 451.148,
      "step": 217000
    },
    {
      "epoch": 2.2977752605586463,
      "grad_norm": 3.5737390518188477,
      "learning_rate": 3.851582680499682e-05,
      "loss": 0.9274,
      "step": 217050
    },
    {
      "epoch": 2.2983045823386496,
      "grad_norm": 3.5973060131073,
      "learning_rate": 3.851318018208766e-05,
      "loss": 0.8997,
      "step": 217100
    },
    {
      "epoch": 2.298833904118653,
      "grad_norm": 3.535961389541626,
      "learning_rate": 3.851053355917849e-05,
      "loss": 0.9158,
      "step": 217150
    },
    {
      "epoch": 2.299363225898656,
      "grad_norm": 3.733396530151367,
      "learning_rate": 3.8507886936269325e-05,
      "loss": 0.9149,
      "step": 217200
    },
    {
      "epoch": 2.2998925476786596,
      "grad_norm": 3.82708477973938,
      "learning_rate": 3.850524031336015e-05,
      "loss": 0.9158,
      "step": 217250
    },
    {
      "epoch": 2.3004218694586624,
      "grad_norm": 4.012594699859619,
      "learning_rate": 3.8502593690450986e-05,
      "loss": 0.9407,
      "step": 217300
    },
    {
      "epoch": 2.3009511912386658,
      "grad_norm": 3.817317008972168,
      "learning_rate": 3.849994706754182e-05,
      "loss": 0.9356,
      "step": 217350
    },
    {
      "epoch": 2.301480513018669,
      "grad_norm": 3.9027047157287598,
      "learning_rate": 3.849730044463265e-05,
      "loss": 0.9186,
      "step": 217400
    },
    {
      "epoch": 2.3020098347986724,
      "grad_norm": 3.369044303894043,
      "learning_rate": 3.849465382172348e-05,
      "loss": 0.9274,
      "step": 217450
    },
    {
      "epoch": 2.3025391565786757,
      "grad_norm": 3.856543779373169,
      "learning_rate": 3.8492007198814316e-05,
      "loss": 0.9236,
      "step": 217500
    },
    {
      "epoch": 2.3025391565786757,
      "eval_loss": 0.7200711965560913,
      "eval_runtime": 46.5486,
      "eval_samples_per_second": 3607.624,
      "eval_steps_per_second": 450.969,
      "step": 217500
    },
    {
      "epoch": 2.303068478358679,
      "grad_norm": 4.185915470123291,
      "learning_rate": 3.848936057590515e-05,
      "loss": 0.9043,
      "step": 217550
    },
    {
      "epoch": 2.3035978001386823,
      "grad_norm": 3.930786371231079,
      "learning_rate": 3.848671395299598e-05,
      "loss": 0.9033,
      "step": 217600
    },
    {
      "epoch": 2.3041271219186856,
      "grad_norm": 3.9990148544311523,
      "learning_rate": 3.848406733008681e-05,
      "loss": 0.9209,
      "step": 217650
    },
    {
      "epoch": 2.304656443698689,
      "grad_norm": 3.7543113231658936,
      "learning_rate": 3.8481420707177645e-05,
      "loss": 0.9144,
      "step": 217700
    },
    {
      "epoch": 2.3051857654786923,
      "grad_norm": 3.719187021255493,
      "learning_rate": 3.847877408426848e-05,
      "loss": 0.9173,
      "step": 217750
    },
    {
      "epoch": 2.3057150872586956,
      "grad_norm": 3.655113935470581,
      "learning_rate": 3.847612746135931e-05,
      "loss": 0.914,
      "step": 217800
    },
    {
      "epoch": 2.306244409038699,
      "grad_norm": 3.6702067852020264,
      "learning_rate": 3.847348083845014e-05,
      "loss": 0.9107,
      "step": 217850
    },
    {
      "epoch": 2.306773730818702,
      "grad_norm": 3.880854606628418,
      "learning_rate": 3.8470834215540975e-05,
      "loss": 0.9091,
      "step": 217900
    },
    {
      "epoch": 2.307303052598705,
      "grad_norm": 3.6701717376708984,
      "learning_rate": 3.84681875926318e-05,
      "loss": 0.9129,
      "step": 217950
    },
    {
      "epoch": 2.307832374378709,
      "grad_norm": 4.027108192443848,
      "learning_rate": 3.8465540969722636e-05,
      "loss": 0.9068,
      "step": 218000
    },
    {
      "epoch": 2.307832374378709,
      "eval_loss": 0.7196448445320129,
      "eval_runtime": 46.5885,
      "eval_samples_per_second": 3604.537,
      "eval_steps_per_second": 450.583,
      "step": 218000
    },
    {
      "epoch": 2.3083616961587117,
      "grad_norm": 3.9291272163391113,
      "learning_rate": 3.8462894346813464e-05,
      "loss": 0.9144,
      "step": 218050
    },
    {
      "epoch": 2.308891017938715,
      "grad_norm": 4.006547451019287,
      "learning_rate": 3.8460300656362485e-05,
      "loss": 0.9362,
      "step": 218100
    },
    {
      "epoch": 2.3094203397187183,
      "grad_norm": 3.7450690269470215,
      "learning_rate": 3.845765403345332e-05,
      "loss": 0.9208,
      "step": 218150
    },
    {
      "epoch": 2.3099496614987216,
      "grad_norm": 4.028854846954346,
      "learning_rate": 3.8455007410544147e-05,
      "loss": 0.9109,
      "step": 218200
    },
    {
      "epoch": 2.310478983278725,
      "grad_norm": 3.911663770675659,
      "learning_rate": 3.845236078763498e-05,
      "loss": 0.906,
      "step": 218250
    },
    {
      "epoch": 2.3110083050587282,
      "grad_norm": 3.944624185562134,
      "learning_rate": 3.8449714164725815e-05,
      "loss": 0.9079,
      "step": 218300
    },
    {
      "epoch": 2.3115376268387315,
      "grad_norm": 3.803497552871704,
      "learning_rate": 3.844706754181664e-05,
      "loss": 0.9123,
      "step": 218350
    },
    {
      "epoch": 2.312066948618735,
      "grad_norm": 3.5347740650177,
      "learning_rate": 3.8444420918907476e-05,
      "loss": 0.9226,
      "step": 218400
    },
    {
      "epoch": 2.312596270398738,
      "grad_norm": 3.830493211746216,
      "learning_rate": 3.8441774295998303e-05,
      "loss": 0.9043,
      "step": 218450
    },
    {
      "epoch": 2.3131255921787415,
      "grad_norm": 3.7895021438598633,
      "learning_rate": 3.8439127673089144e-05,
      "loss": 0.9164,
      "step": 218500
    },
    {
      "epoch": 2.3131255921787415,
      "eval_loss": 0.7177812457084656,
      "eval_runtime": 46.5243,
      "eval_samples_per_second": 3609.508,
      "eval_steps_per_second": 451.205,
      "step": 218500
    },
    {
      "epoch": 2.313654913958745,
      "grad_norm": 3.5366122722625732,
      "learning_rate": 3.843648105017997e-05,
      "loss": 0.9377,
      "step": 218550
    },
    {
      "epoch": 2.314184235738748,
      "grad_norm": 3.9843029975891113,
      "learning_rate": 3.8433834427270806e-05,
      "loss": 0.911,
      "step": 218600
    },
    {
      "epoch": 2.3147135575187514,
      "grad_norm": 4.18845272064209,
      "learning_rate": 3.843118780436163e-05,
      "loss": 0.8975,
      "step": 218650
    },
    {
      "epoch": 2.3152428792987543,
      "grad_norm": 3.666217565536499,
      "learning_rate": 3.8428541181452474e-05,
      "loss": 0.9168,
      "step": 218700
    },
    {
      "epoch": 2.315772201078758,
      "grad_norm": 3.917348623275757,
      "learning_rate": 3.84258945585433e-05,
      "loss": 0.9106,
      "step": 218750
    },
    {
      "epoch": 2.316301522858761,
      "grad_norm": 3.7730910778045654,
      "learning_rate": 3.8423247935634135e-05,
      "loss": 0.8984,
      "step": 218800
    },
    {
      "epoch": 2.316830844638764,
      "grad_norm": 3.9801478385925293,
      "learning_rate": 3.842060131272496e-05,
      "loss": 0.9159,
      "step": 218850
    },
    {
      "epoch": 2.3173601664187675,
      "grad_norm": 3.534151792526245,
      "learning_rate": 3.84179546898158e-05,
      "loss": 0.9073,
      "step": 218900
    },
    {
      "epoch": 2.317889488198771,
      "grad_norm": 3.7092151641845703,
      "learning_rate": 3.841530806690663e-05,
      "loss": 0.8959,
      "step": 218950
    },
    {
      "epoch": 2.318418809978774,
      "grad_norm": 3.9491586685180664,
      "learning_rate": 3.8412714376455646e-05,
      "loss": 0.8917,
      "step": 219000
    },
    {
      "epoch": 2.318418809978774,
      "eval_loss": 0.7148720622062683,
      "eval_runtime": 46.5699,
      "eval_samples_per_second": 3605.975,
      "eval_steps_per_second": 450.763,
      "step": 219000
    },
    {
      "epoch": 2.3189481317587775,
      "grad_norm": 3.6300482749938965,
      "learning_rate": 3.841006775354647e-05,
      "loss": 0.9039,
      "step": 219050
    },
    {
      "epoch": 2.3194774535387808,
      "grad_norm": 3.765063762664795,
      "learning_rate": 3.8407421130637314e-05,
      "loss": 0.9233,
      "step": 219100
    },
    {
      "epoch": 2.320006775318784,
      "grad_norm": 3.592664957046509,
      "learning_rate": 3.840477450772814e-05,
      "loss": 0.9141,
      "step": 219150
    },
    {
      "epoch": 2.3205360970987874,
      "grad_norm": 3.9190802574157715,
      "learning_rate": 3.8402127884818975e-05,
      "loss": 0.9021,
      "step": 219200
    },
    {
      "epoch": 2.3210654188787907,
      "grad_norm": 3.874594211578369,
      "learning_rate": 3.83994812619098e-05,
      "loss": 0.9205,
      "step": 219250
    },
    {
      "epoch": 2.321594740658794,
      "grad_norm": 3.8501393795013428,
      "learning_rate": 3.839683463900064e-05,
      "loss": 0.9091,
      "step": 219300
    },
    {
      "epoch": 2.3221240624387973,
      "grad_norm": 3.636971950531006,
      "learning_rate": 3.839418801609147e-05,
      "loss": 0.9172,
      "step": 219350
    },
    {
      "epoch": 2.3226533842188006,
      "grad_norm": 3.771045684814453,
      "learning_rate": 3.83915413931823e-05,
      "loss": 0.9143,
      "step": 219400
    },
    {
      "epoch": 2.3231827059988035,
      "grad_norm": 4.109254837036133,
      "learning_rate": 3.838889477027313e-05,
      "loss": 0.9161,
      "step": 219450
    },
    {
      "epoch": 2.3237120277788073,
      "grad_norm": 3.530108690261841,
      "learning_rate": 3.8386248147363966e-05,
      "loss": 0.9118,
      "step": 219500
    },
    {
      "epoch": 2.3237120277788073,
      "eval_loss": 0.7170729637145996,
      "eval_runtime": 46.5044,
      "eval_samples_per_second": 3611.056,
      "eval_steps_per_second": 451.398,
      "step": 219500
    },
    {
      "epoch": 2.32424134955881,
      "grad_norm": 3.4697470664978027,
      "learning_rate": 3.83836015244548e-05,
      "loss": 0.9074,
      "step": 219550
    },
    {
      "epoch": 2.3247706713388134,
      "grad_norm": 3.9842021465301514,
      "learning_rate": 3.838095490154563e-05,
      "loss": 0.9052,
      "step": 219600
    },
    {
      "epoch": 2.3252999931188167,
      "grad_norm": 3.8169286251068115,
      "learning_rate": 3.837830827863646e-05,
      "loss": 0.9224,
      "step": 219650
    },
    {
      "epoch": 2.32582931489882,
      "grad_norm": 3.961620807647705,
      "learning_rate": 3.8375661655727296e-05,
      "loss": 0.9235,
      "step": 219700
    },
    {
      "epoch": 2.3263586366788234,
      "grad_norm": 3.830003261566162,
      "learning_rate": 3.837301503281813e-05,
      "loss": 0.9179,
      "step": 219750
    },
    {
      "epoch": 2.3268879584588267,
      "grad_norm": 3.5382132530212402,
      "learning_rate": 3.837036840990896e-05,
      "loss": 0.9309,
      "step": 219800
    },
    {
      "epoch": 2.32741728023883,
      "grad_norm": 3.7380545139312744,
      "learning_rate": 3.836772178699979e-05,
      "loss": 0.9104,
      "step": 219850
    },
    {
      "epoch": 2.3279466020188333,
      "grad_norm": 3.728207588195801,
      "learning_rate": 3.8365075164090626e-05,
      "loss": 0.9023,
      "step": 219900
    },
    {
      "epoch": 2.3284759237988366,
      "grad_norm": 3.9722707271575928,
      "learning_rate": 3.836242854118145e-05,
      "loss": 0.9185,
      "step": 219950
    },
    {
      "epoch": 2.32900524557884,
      "grad_norm": 3.6217479705810547,
      "learning_rate": 3.835978191827229e-05,
      "loss": 0.9055,
      "step": 220000
    },
    {
      "epoch": 2.32900524557884,
      "eval_loss": 0.7183179259300232,
      "eval_runtime": 46.5448,
      "eval_samples_per_second": 3607.921,
      "eval_steps_per_second": 451.006,
      "step": 220000
    },
    {
      "epoch": 2.3295345673588432,
      "grad_norm": 4.0347900390625,
      "learning_rate": 3.8357135295363114e-05,
      "loss": 0.9223,
      "step": 220050
    },
    {
      "epoch": 2.3300638891388465,
      "grad_norm": 4.121484756469727,
      "learning_rate": 3.8354488672453955e-05,
      "loss": 0.9069,
      "step": 220100
    },
    {
      "epoch": 2.33059321091885,
      "grad_norm": 4.0942888259887695,
      "learning_rate": 3.835184204954478e-05,
      "loss": 0.9071,
      "step": 220150
    },
    {
      "epoch": 2.3311225326988527,
      "grad_norm": 3.7664804458618164,
      "learning_rate": 3.8349195426635617e-05,
      "loss": 0.9074,
      "step": 220200
    },
    {
      "epoch": 2.3316518544788565,
      "grad_norm": 3.7097079753875732,
      "learning_rate": 3.8346548803726444e-05,
      "loss": 0.911,
      "step": 220250
    },
    {
      "epoch": 2.3321811762588593,
      "grad_norm": 4.151937961578369,
      "learning_rate": 3.8343902180817285e-05,
      "loss": 0.9135,
      "step": 220300
    },
    {
      "epoch": 2.3327104980388627,
      "grad_norm": 3.729510545730591,
      "learning_rate": 3.834125555790811e-05,
      "loss": 0.904,
      "step": 220350
    },
    {
      "epoch": 2.333239819818866,
      "grad_norm": 3.937216281890869,
      "learning_rate": 3.8338608934998946e-05,
      "loss": 0.9185,
      "step": 220400
    },
    {
      "epoch": 2.3337691415988693,
      "grad_norm": 3.698052406311035,
      "learning_rate": 3.8335962312089774e-05,
      "loss": 0.9099,
      "step": 220450
    },
    {
      "epoch": 2.3342984633788726,
      "grad_norm": 4.052134990692139,
      "learning_rate": 3.833331568918061e-05,
      "loss": 0.9,
      "step": 220500
    },
    {
      "epoch": 2.3342984633788726,
      "eval_loss": 0.7129803895950317,
      "eval_runtime": 46.6332,
      "eval_samples_per_second": 3601.086,
      "eval_steps_per_second": 450.152,
      "step": 220500
    },
    {
      "epoch": 2.334827785158876,
      "grad_norm": 3.642651319503784,
      "learning_rate": 3.833066906627144e-05,
      "loss": 0.9123,
      "step": 220550
    },
    {
      "epoch": 2.335357106938879,
      "grad_norm": 3.7776074409484863,
      "learning_rate": 3.832802244336227e-05,
      "loss": 0.9045,
      "step": 220600
    },
    {
      "epoch": 2.3358864287188825,
      "grad_norm": 4.168097496032715,
      "learning_rate": 3.83253758204531e-05,
      "loss": 0.9207,
      "step": 220650
    },
    {
      "epoch": 2.336415750498886,
      "grad_norm": 3.516853094100952,
      "learning_rate": 3.832272919754394e-05,
      "loss": 0.9124,
      "step": 220700
    },
    {
      "epoch": 2.336945072278889,
      "grad_norm": 3.694581985473633,
      "learning_rate": 3.832008257463477e-05,
      "loss": 0.92,
      "step": 220750
    },
    {
      "epoch": 2.3374743940588925,
      "grad_norm": 3.6977803707122803,
      "learning_rate": 3.83174359517256e-05,
      "loss": 0.937,
      "step": 220800
    },
    {
      "epoch": 2.3380037158388958,
      "grad_norm": 3.5550990104675293,
      "learning_rate": 3.831478932881643e-05,
      "loss": 0.9101,
      "step": 220850
    },
    {
      "epoch": 2.338533037618899,
      "grad_norm": 3.7478585243225098,
      "learning_rate": 3.831214270590727e-05,
      "loss": 0.9166,
      "step": 220900
    },
    {
      "epoch": 2.339062359398902,
      "grad_norm": 4.1191840171813965,
      "learning_rate": 3.8309496082998094e-05,
      "loss": 0.9262,
      "step": 220950
    },
    {
      "epoch": 2.3395916811789057,
      "grad_norm": 3.8517351150512695,
      "learning_rate": 3.830684946008893e-05,
      "loss": 0.9081,
      "step": 221000
    },
    {
      "epoch": 2.3395916811789057,
      "eval_loss": 0.7130061388015747,
      "eval_runtime": 46.5058,
      "eval_samples_per_second": 3610.944,
      "eval_steps_per_second": 451.384,
      "step": 221000
    },
    {
      "epoch": 2.3401210029589086,
      "grad_norm": 3.6044118404388428,
      "learning_rate": 3.8304202837179756e-05,
      "loss": 0.917,
      "step": 221050
    },
    {
      "epoch": 2.340650324738912,
      "grad_norm": 3.830700635910034,
      "learning_rate": 3.8301556214270596e-05,
      "loss": 0.9162,
      "step": 221100
    },
    {
      "epoch": 2.341179646518915,
      "grad_norm": 3.929638385772705,
      "learning_rate": 3.8298909591361424e-05,
      "loss": 0.9196,
      "step": 221150
    },
    {
      "epoch": 2.3417089682989185,
      "grad_norm": 3.7355055809020996,
      "learning_rate": 3.829626296845226e-05,
      "loss": 0.9008,
      "step": 221200
    },
    {
      "epoch": 2.342238290078922,
      "grad_norm": 3.710622787475586,
      "learning_rate": 3.8293616345543085e-05,
      "loss": 0.9116,
      "step": 221250
    },
    {
      "epoch": 2.342767611858925,
      "grad_norm": 3.6727166175842285,
      "learning_rate": 3.829102265509211e-05,
      "loss": 0.9207,
      "step": 221300
    },
    {
      "epoch": 2.3432969336389284,
      "grad_norm": 3.7590925693511963,
      "learning_rate": 3.828837603218294e-05,
      "loss": 0.9235,
      "step": 221350
    },
    {
      "epoch": 2.3438262554189317,
      "grad_norm": 3.854825496673584,
      "learning_rate": 3.828572940927377e-05,
      "loss": 0.9197,
      "step": 221400
    },
    {
      "epoch": 2.344355577198935,
      "grad_norm": 3.858485460281372,
      "learning_rate": 3.82830827863646e-05,
      "loss": 0.9111,
      "step": 221450
    },
    {
      "epoch": 2.3448848989789384,
      "grad_norm": 3.899115800857544,
      "learning_rate": 3.8280436163455436e-05,
      "loss": 0.9167,
      "step": 221500
    },
    {
      "epoch": 2.3448848989789384,
      "eval_loss": 0.7137671113014221,
      "eval_runtime": 46.6655,
      "eval_samples_per_second": 3598.592,
      "eval_steps_per_second": 449.84,
      "step": 221500
    },
    {
      "epoch": 2.3454142207589417,
      "grad_norm": 3.946225166320801,
      "learning_rate": 3.8277789540546264e-05,
      "loss": 0.9041,
      "step": 221550
    },
    {
      "epoch": 2.345943542538945,
      "grad_norm": 4.249178886413574,
      "learning_rate": 3.82751429176371e-05,
      "loss": 0.89,
      "step": 221600
    },
    {
      "epoch": 2.3464728643189483,
      "grad_norm": 3.429999589920044,
      "learning_rate": 3.8272496294727925e-05,
      "loss": 0.9243,
      "step": 221650
    },
    {
      "epoch": 2.347002186098951,
      "grad_norm": 4.115826606750488,
      "learning_rate": 3.8269849671818766e-05,
      "loss": 0.8871,
      "step": 221700
    },
    {
      "epoch": 2.347531507878955,
      "grad_norm": 3.850939989089966,
      "learning_rate": 3.826720304890959e-05,
      "loss": 0.8986,
      "step": 221750
    },
    {
      "epoch": 2.348060829658958,
      "grad_norm": 3.769713878631592,
      "learning_rate": 3.826455642600043e-05,
      "loss": 0.9077,
      "step": 221800
    },
    {
      "epoch": 2.348590151438961,
      "grad_norm": 4.095935821533203,
      "learning_rate": 3.8261909803091255e-05,
      "loss": 0.9227,
      "step": 221850
    },
    {
      "epoch": 2.3491194732189644,
      "grad_norm": 3.7199904918670654,
      "learning_rate": 3.8259263180182096e-05,
      "loss": 0.9008,
      "step": 221900
    },
    {
      "epoch": 2.3496487949989677,
      "grad_norm": 3.9123215675354004,
      "learning_rate": 3.825661655727292e-05,
      "loss": 0.9024,
      "step": 221950
    },
    {
      "epoch": 2.350178116778971,
      "grad_norm": 4.033973693847656,
      "learning_rate": 3.825396993436376e-05,
      "loss": 0.9182,
      "step": 222000
    },
    {
      "epoch": 2.350178116778971,
      "eval_loss": 0.7124919295310974,
      "eval_runtime": 46.6008,
      "eval_samples_per_second": 3603.587,
      "eval_steps_per_second": 450.464,
      "step": 222000
    },
    {
      "epoch": 2.3507074385589743,
      "grad_norm": 3.5599944591522217,
      "learning_rate": 3.8251323311454584e-05,
      "loss": 0.9169,
      "step": 222050
    },
    {
      "epoch": 2.3512367603389777,
      "grad_norm": 4.3621134757995605,
      "learning_rate": 3.824867668854542e-05,
      "loss": 0.915,
      "step": 222100
    },
    {
      "epoch": 2.351766082118981,
      "grad_norm": 3.8104770183563232,
      "learning_rate": 3.824603006563625e-05,
      "loss": 0.9078,
      "step": 222150
    },
    {
      "epoch": 2.3522954038989843,
      "grad_norm": 3.7647128105163574,
      "learning_rate": 3.824338344272708e-05,
      "loss": 0.9109,
      "step": 222200
    },
    {
      "epoch": 2.3528247256789876,
      "grad_norm": 3.8503077030181885,
      "learning_rate": 3.8240736819817914e-05,
      "loss": 0.9141,
      "step": 222250
    },
    {
      "epoch": 2.353354047458991,
      "grad_norm": 4.368862152099609,
      "learning_rate": 3.823809019690874e-05,
      "loss": 0.9171,
      "step": 222300
    },
    {
      "epoch": 2.353883369238994,
      "grad_norm": 3.6832611560821533,
      "learning_rate": 3.823544357399958e-05,
      "loss": 0.9135,
      "step": 222350
    },
    {
      "epoch": 2.3544126910189975,
      "grad_norm": 4.035793304443359,
      "learning_rate": 3.823279695109041e-05,
      "loss": 0.9173,
      "step": 222400
    },
    {
      "epoch": 2.3549420127990004,
      "grad_norm": 3.9280643463134766,
      "learning_rate": 3.8230150328181244e-05,
      "loss": 0.9137,
      "step": 222450
    },
    {
      "epoch": 2.355471334579004,
      "grad_norm": 3.843971014022827,
      "learning_rate": 3.822750370527207e-05,
      "loss": 0.8979,
      "step": 222500
    },
    {
      "epoch": 2.355471334579004,
      "eval_loss": 0.7095180749893188,
      "eval_runtime": 46.6203,
      "eval_samples_per_second": 3602.082,
      "eval_steps_per_second": 450.276,
      "step": 222500
    },
    {
      "epoch": 2.356000656359007,
      "grad_norm": 3.710282325744629,
      "learning_rate": 3.8224857082362905e-05,
      "loss": 0.9041,
      "step": 222550
    },
    {
      "epoch": 2.3565299781390103,
      "grad_norm": 3.506641387939453,
      "learning_rate": 3.822221045945374e-05,
      "loss": 0.9059,
      "step": 222600
    },
    {
      "epoch": 2.3570592999190136,
      "grad_norm": 3.7789597511291504,
      "learning_rate": 3.8219563836544566e-05,
      "loss": 0.9007,
      "step": 222650
    },
    {
      "epoch": 2.357588621699017,
      "grad_norm": 3.942197322845459,
      "learning_rate": 3.82169172136354e-05,
      "loss": 0.9183,
      "step": 222700
    },
    {
      "epoch": 2.3581179434790203,
      "grad_norm": 3.844573736190796,
      "learning_rate": 3.8214270590726235e-05,
      "loss": 0.8949,
      "step": 222750
    },
    {
      "epoch": 2.3586472652590236,
      "grad_norm": 3.7337467670440674,
      "learning_rate": 3.821162396781707e-05,
      "loss": 0.9096,
      "step": 222800
    },
    {
      "epoch": 2.359176587039027,
      "grad_norm": 3.7567243576049805,
      "learning_rate": 3.8208977344907896e-05,
      "loss": 0.9146,
      "step": 222850
    },
    {
      "epoch": 2.35970590881903,
      "grad_norm": 3.615237236022949,
      "learning_rate": 3.820633072199873e-05,
      "loss": 0.9079,
      "step": 222900
    },
    {
      "epoch": 2.3602352305990335,
      "grad_norm": 3.453768730163574,
      "learning_rate": 3.8203684099089564e-05,
      "loss": 0.895,
      "step": 222950
    },
    {
      "epoch": 2.360764552379037,
      "grad_norm": 4.042538642883301,
      "learning_rate": 3.82010374761804e-05,
      "loss": 0.9086,
      "step": 223000
    },
    {
      "epoch": 2.360764552379037,
      "eval_loss": 0.7075807452201843,
      "eval_runtime": 46.4858,
      "eval_samples_per_second": 3612.5,
      "eval_steps_per_second": 451.579,
      "step": 223000
    },
    {
      "epoch": 2.36129387415904,
      "grad_norm": 3.8089959621429443,
      "learning_rate": 3.8198390853271226e-05,
      "loss": 0.9039,
      "step": 223050
    },
    {
      "epoch": 2.3618231959390434,
      "grad_norm": 3.9099228382110596,
      "learning_rate": 3.819574423036206e-05,
      "loss": 0.9082,
      "step": 223100
    },
    {
      "epoch": 2.3623525177190468,
      "grad_norm": 3.881617546081543,
      "learning_rate": 3.8193097607452894e-05,
      "loss": 0.9146,
      "step": 223150
    },
    {
      "epoch": 2.3628818394990496,
      "grad_norm": 3.596611261367798,
      "learning_rate": 3.819045098454372e-05,
      "loss": 0.918,
      "step": 223200
    },
    {
      "epoch": 2.3634111612790534,
      "grad_norm": 4.316618919372559,
      "learning_rate": 3.8187804361634555e-05,
      "loss": 0.9113,
      "step": 223250
    },
    {
      "epoch": 2.3639404830590562,
      "grad_norm": 3.9065263271331787,
      "learning_rate": 3.818515773872538e-05,
      "loss": 0.9345,
      "step": 223300
    },
    {
      "epoch": 2.3644698048390596,
      "grad_norm": 3.8727526664733887,
      "learning_rate": 3.8182511115816224e-05,
      "loss": 0.8874,
      "step": 223350
    },
    {
      "epoch": 2.364999126619063,
      "grad_norm": 3.623304605484009,
      "learning_rate": 3.817986449290705e-05,
      "loss": 0.9022,
      "step": 223400
    },
    {
      "epoch": 2.365528448399066,
      "grad_norm": 3.7317628860473633,
      "learning_rate": 3.8177217869997885e-05,
      "loss": 0.8898,
      "step": 223450
    },
    {
      "epoch": 2.3660577701790695,
      "grad_norm": 4.326436519622803,
      "learning_rate": 3.817457124708871e-05,
      "loss": 0.9011,
      "step": 223500
    },
    {
      "epoch": 2.3660577701790695,
      "eval_loss": 0.7068368792533875,
      "eval_runtime": 46.5811,
      "eval_samples_per_second": 3605.11,
      "eval_steps_per_second": 450.655,
      "step": 223500
    },
    {
      "epoch": 2.366587091959073,
      "grad_norm": 3.7367169857025146,
      "learning_rate": 3.817192462417955e-05,
      "loss": 0.9163,
      "step": 223550
    },
    {
      "epoch": 2.367116413739076,
      "grad_norm": 3.510193109512329,
      "learning_rate": 3.816927800127038e-05,
      "loss": 0.8983,
      "step": 223600
    },
    {
      "epoch": 2.3676457355190794,
      "grad_norm": 3.799959421157837,
      "learning_rate": 3.8166631378361215e-05,
      "loss": 0.9161,
      "step": 223650
    },
    {
      "epoch": 2.3681750572990827,
      "grad_norm": 4.105815887451172,
      "learning_rate": 3.816398475545204e-05,
      "loss": 0.9282,
      "step": 223700
    },
    {
      "epoch": 2.368704379079086,
      "grad_norm": 3.6464335918426514,
      "learning_rate": 3.8161338132542876e-05,
      "loss": 0.9104,
      "step": 223750
    },
    {
      "epoch": 2.3692337008590894,
      "grad_norm": 3.944120407104492,
      "learning_rate": 3.815869150963371e-05,
      "loss": 0.9021,
      "step": 223800
    },
    {
      "epoch": 2.3697630226390927,
      "grad_norm": 3.9065186977386475,
      "learning_rate": 3.815604488672454e-05,
      "loss": 0.8869,
      "step": 223850
    },
    {
      "epoch": 2.370292344419096,
      "grad_norm": 4.160333156585693,
      "learning_rate": 3.815339826381537e-05,
      "loss": 0.9034,
      "step": 223900
    },
    {
      "epoch": 2.3708216661990993,
      "grad_norm": 3.806830406188965,
      "learning_rate": 3.8150751640906206e-05,
      "loss": 0.9052,
      "step": 223950
    },
    {
      "epoch": 2.3713509879791026,
      "grad_norm": 3.256197690963745,
      "learning_rate": 3.814810501799704e-05,
      "loss": 0.8861,
      "step": 224000
    },
    {
      "epoch": 2.3713509879791026,
      "eval_loss": 0.7069742679595947,
      "eval_runtime": 46.5422,
      "eval_samples_per_second": 3608.126,
      "eval_steps_per_second": 451.032,
      "step": 224000
    },
    {
      "epoch": 2.3718803097591055,
      "grad_norm": 3.6185433864593506,
      "learning_rate": 3.814545839508787e-05,
      "loss": 0.9096,
      "step": 224050
    },
    {
      "epoch": 2.3724096315391088,
      "grad_norm": 3.4274351596832275,
      "learning_rate": 3.81428117721787e-05,
      "loss": 0.8914,
      "step": 224100
    },
    {
      "epoch": 2.372938953319112,
      "grad_norm": 3.8436968326568604,
      "learning_rate": 3.8140165149269535e-05,
      "loss": 0.9132,
      "step": 224150
    },
    {
      "epoch": 2.3734682750991154,
      "grad_norm": 3.637467384338379,
      "learning_rate": 3.813751852636037e-05,
      "loss": 0.9024,
      "step": 224200
    },
    {
      "epoch": 2.3739975968791187,
      "grad_norm": 4.112079620361328,
      "learning_rate": 3.81348719034512e-05,
      "loss": 0.8951,
      "step": 224250
    },
    {
      "epoch": 2.374526918659122,
      "grad_norm": 3.7259790897369385,
      "learning_rate": 3.813222528054203e-05,
      "loss": 0.9142,
      "step": 224300
    },
    {
      "epoch": 2.3750562404391253,
      "grad_norm": 3.614948034286499,
      "learning_rate": 3.8129578657632865e-05,
      "loss": 0.8886,
      "step": 224350
    },
    {
      "epoch": 2.3755855622191286,
      "grad_norm": 3.8269059658050537,
      "learning_rate": 3.812693203472369e-05,
      "loss": 0.9096,
      "step": 224400
    },
    {
      "epoch": 2.376114883999132,
      "grad_norm": 3.3917031288146973,
      "learning_rate": 3.8124285411814526e-05,
      "loss": 0.9002,
      "step": 224450
    },
    {
      "epoch": 2.3766442057791353,
      "grad_norm": 3.9367048740386963,
      "learning_rate": 3.8121638788905354e-05,
      "loss": 0.9032,
      "step": 224500
    },
    {
      "epoch": 2.3766442057791353,
      "eval_loss": 0.7060219645500183,
      "eval_runtime": 46.537,
      "eval_samples_per_second": 3608.526,
      "eval_steps_per_second": 451.082,
      "step": 224500
    },
    {
      "epoch": 2.3771735275591386,
      "grad_norm": 3.781407594680786,
      "learning_rate": 3.8118992165996194e-05,
      "loss": 0.9092,
      "step": 224550
    },
    {
      "epoch": 2.377702849339142,
      "grad_norm": 3.5054855346679688,
      "learning_rate": 3.811634554308702e-05,
      "loss": 0.8927,
      "step": 224600
    },
    {
      "epoch": 2.378232171119145,
      "grad_norm": 3.9493510723114014,
      "learning_rate": 3.8113698920177856e-05,
      "loss": 0.9046,
      "step": 224650
    },
    {
      "epoch": 2.3787614928991485,
      "grad_norm": 4.035895347595215,
      "learning_rate": 3.811105229726868e-05,
      "loss": 0.9043,
      "step": 224700
    },
    {
      "epoch": 2.379290814679152,
      "grad_norm": 3.6022214889526367,
      "learning_rate": 3.8108458606817705e-05,
      "loss": 0.8897,
      "step": 224750
    },
    {
      "epoch": 2.3798201364591547,
      "grad_norm": 4.303852558135986,
      "learning_rate": 3.810581198390853e-05,
      "loss": 0.9068,
      "step": 224800
    },
    {
      "epoch": 2.380349458239158,
      "grad_norm": 3.9276175498962402,
      "learning_rate": 3.8103165360999366e-05,
      "loss": 0.9189,
      "step": 224850
    },
    {
      "epoch": 2.3808787800191613,
      "grad_norm": 3.9674489498138428,
      "learning_rate": 3.8100518738090193e-05,
      "loss": 0.9145,
      "step": 224900
    },
    {
      "epoch": 2.3814081017991646,
      "grad_norm": 3.560612678527832,
      "learning_rate": 3.8097872115181034e-05,
      "loss": 0.8882,
      "step": 224950
    },
    {
      "epoch": 2.381937423579168,
      "grad_norm": 3.8379528522491455,
      "learning_rate": 3.809522549227186e-05,
      "loss": 0.8979,
      "step": 225000
    },
    {
      "epoch": 2.381937423579168,
      "eval_loss": 0.7069657444953918,
      "eval_runtime": 46.6961,
      "eval_samples_per_second": 3596.229,
      "eval_steps_per_second": 449.545,
      "step": 225000
    },
    {
      "epoch": 2.3824667453591712,
      "grad_norm": 3.973670244216919,
      "learning_rate": 3.8092578869362696e-05,
      "loss": 0.904,
      "step": 225050
    },
    {
      "epoch": 2.3829960671391746,
      "grad_norm": 3.853294849395752,
      "learning_rate": 3.808993224645352e-05,
      "loss": 0.9,
      "step": 225100
    },
    {
      "epoch": 2.383525388919178,
      "grad_norm": 3.923429012298584,
      "learning_rate": 3.8087285623544364e-05,
      "loss": 0.901,
      "step": 225150
    },
    {
      "epoch": 2.384054710699181,
      "grad_norm": 4.533279895782471,
      "learning_rate": 3.808463900063519e-05,
      "loss": 0.9122,
      "step": 225200
    },
    {
      "epoch": 2.3845840324791845,
      "grad_norm": 3.4592537879943848,
      "learning_rate": 3.8081992377726025e-05,
      "loss": 0.8906,
      "step": 225250
    },
    {
      "epoch": 2.385113354259188,
      "grad_norm": 4.253555774688721,
      "learning_rate": 3.807934575481685e-05,
      "loss": 0.9117,
      "step": 225300
    },
    {
      "epoch": 2.385642676039191,
      "grad_norm": 4.254448413848877,
      "learning_rate": 3.807669913190769e-05,
      "loss": 0.9083,
      "step": 225350
    },
    {
      "epoch": 2.3861719978191944,
      "grad_norm": 3.813369035720825,
      "learning_rate": 3.807405250899852e-05,
      "loss": 0.9092,
      "step": 225400
    },
    {
      "epoch": 2.3867013195991977,
      "grad_norm": 4.032497406005859,
      "learning_rate": 3.807140588608935e-05,
      "loss": 0.8979,
      "step": 225450
    },
    {
      "epoch": 2.387230641379201,
      "grad_norm": 3.4916694164276123,
      "learning_rate": 3.806875926318018e-05,
      "loss": 0.9011,
      "step": 225500
    },
    {
      "epoch": 2.387230641379201,
      "eval_loss": 0.705323338508606,
      "eval_runtime": 46.5434,
      "eval_samples_per_second": 3608.032,
      "eval_steps_per_second": 451.02,
      "step": 225500
    },
    {
      "epoch": 2.387759963159204,
      "grad_norm": 3.794166326522827,
      "learning_rate": 3.8066112640271016e-05,
      "loss": 0.9175,
      "step": 225550
    },
    {
      "epoch": 2.3882892849392072,
      "grad_norm": 3.905766725540161,
      "learning_rate": 3.806346601736185e-05,
      "loss": 0.8966,
      "step": 225600
    },
    {
      "epoch": 2.3888186067192105,
      "grad_norm": 4.0656304359436035,
      "learning_rate": 3.806081939445268e-05,
      "loss": 0.9147,
      "step": 225650
    },
    {
      "epoch": 2.389347928499214,
      "grad_norm": 3.7508552074432373,
      "learning_rate": 3.805817277154351e-05,
      "loss": 0.9054,
      "step": 225700
    },
    {
      "epoch": 2.389877250279217,
      "grad_norm": 4.161679267883301,
      "learning_rate": 3.8055526148634346e-05,
      "loss": 0.9116,
      "step": 225750
    },
    {
      "epoch": 2.3904065720592205,
      "grad_norm": 3.6121370792388916,
      "learning_rate": 3.805287952572518e-05,
      "loss": 0.912,
      "step": 225800
    },
    {
      "epoch": 2.390935893839224,
      "grad_norm": 4.1637091636657715,
      "learning_rate": 3.805023290281601e-05,
      "loss": 0.9033,
      "step": 225850
    },
    {
      "epoch": 2.391465215619227,
      "grad_norm": 3.5662436485290527,
      "learning_rate": 3.804758627990684e-05,
      "loss": 0.9189,
      "step": 225900
    },
    {
      "epoch": 2.3919945373992304,
      "grad_norm": 3.8793365955352783,
      "learning_rate": 3.8044939656997676e-05,
      "loss": 0.9021,
      "step": 225950
    },
    {
      "epoch": 2.3925238591792337,
      "grad_norm": 3.7645649909973145,
      "learning_rate": 3.80422930340885e-05,
      "loss": 0.8941,
      "step": 226000
    },
    {
      "epoch": 2.3925238591792337,
      "eval_loss": 0.704842746257782,
      "eval_runtime": 46.5847,
      "eval_samples_per_second": 3604.834,
      "eval_steps_per_second": 450.62,
      "step": 226000
    },
    {
      "epoch": 2.393053180959237,
      "grad_norm": 3.754774332046509,
      "learning_rate": 3.803964641117934e-05,
      "loss": 0.8986,
      "step": 226050
    },
    {
      "epoch": 2.3935825027392403,
      "grad_norm": 3.9962847232818604,
      "learning_rate": 3.8036999788270164e-05,
      "loss": 0.8994,
      "step": 226100
    },
    {
      "epoch": 2.3941118245192436,
      "grad_norm": 3.826496124267578,
      "learning_rate": 3.8034353165361005e-05,
      "loss": 0.8925,
      "step": 226150
    },
    {
      "epoch": 2.394641146299247,
      "grad_norm": 4.293170928955078,
      "learning_rate": 3.803170654245183e-05,
      "loss": 0.899,
      "step": 226200
    },
    {
      "epoch": 2.3951704680792503,
      "grad_norm": 4.063845157623291,
      "learning_rate": 3.802905991954267e-05,
      "loss": 0.8988,
      "step": 226250
    },
    {
      "epoch": 2.395699789859253,
      "grad_norm": 4.3696136474609375,
      "learning_rate": 3.8026413296633494e-05,
      "loss": 0.9011,
      "step": 226300
    },
    {
      "epoch": 2.3962291116392564,
      "grad_norm": 3.8019139766693115,
      "learning_rate": 3.802376667372433e-05,
      "loss": 0.8816,
      "step": 226350
    },
    {
      "epoch": 2.3967584334192598,
      "grad_norm": 3.7427937984466553,
      "learning_rate": 3.802112005081516e-05,
      "loss": 0.8865,
      "step": 226400
    },
    {
      "epoch": 2.397287755199263,
      "grad_norm": 3.7253081798553467,
      "learning_rate": 3.801847342790599e-05,
      "loss": 0.8987,
      "step": 226450
    },
    {
      "epoch": 2.3978170769792664,
      "grad_norm": 3.684931516647339,
      "learning_rate": 3.8015826804996824e-05,
      "loss": 0.9038,
      "step": 226500
    },
    {
      "epoch": 2.3978170769792664,
      "eval_loss": 0.7046651244163513,
      "eval_runtime": 46.6044,
      "eval_samples_per_second": 3603.304,
      "eval_steps_per_second": 450.429,
      "step": 226500
    },
    {
      "epoch": 2.3983463987592697,
      "grad_norm": 3.923788547515869,
      "learning_rate": 3.801318018208766e-05,
      "loss": 0.8819,
      "step": 226550
    },
    {
      "epoch": 2.398875720539273,
      "grad_norm": 3.863511800765991,
      "learning_rate": 3.801053355917849e-05,
      "loss": 0.9005,
      "step": 226600
    },
    {
      "epoch": 2.3994050423192763,
      "grad_norm": 4.126602649688721,
      "learning_rate": 3.800788693626932e-05,
      "loss": 0.8921,
      "step": 226650
    },
    {
      "epoch": 2.3999343640992796,
      "grad_norm": 3.673219680786133,
      "learning_rate": 3.800524031336015e-05,
      "loss": 0.9005,
      "step": 226700
    },
    {
      "epoch": 2.400463685879283,
      "grad_norm": 4.029494762420654,
      "learning_rate": 3.800259369045099e-05,
      "loss": 0.8936,
      "step": 226750
    },
    {
      "epoch": 2.4009930076592862,
      "grad_norm": 3.530876874923706,
      "learning_rate": 3.799994706754182e-05,
      "loss": 0.9009,
      "step": 226800
    },
    {
      "epoch": 2.4015223294392896,
      "grad_norm": 4.002869129180908,
      "learning_rate": 3.799730044463265e-05,
      "loss": 0.8943,
      "step": 226850
    },
    {
      "epoch": 2.402051651219293,
      "grad_norm": 3.3232531547546387,
      "learning_rate": 3.799465382172348e-05,
      "loss": 0.8796,
      "step": 226900
    },
    {
      "epoch": 2.402580972999296,
      "grad_norm": 3.893841028213501,
      "learning_rate": 3.799200719881432e-05,
      "loss": 0.8959,
      "step": 226950
    },
    {
      "epoch": 2.4031102947792995,
      "grad_norm": 3.4933362007141113,
      "learning_rate": 3.7989360575905144e-05,
      "loss": 0.9162,
      "step": 227000
    },
    {
      "epoch": 2.4031102947792995,
      "eval_loss": 0.7034392356872559,
      "eval_runtime": 46.6273,
      "eval_samples_per_second": 3601.542,
      "eval_steps_per_second": 450.209,
      "step": 227000
    },
    {
      "epoch": 2.4036396165593024,
      "grad_norm": 3.720421314239502,
      "learning_rate": 3.798671395299598e-05,
      "loss": 0.905,
      "step": 227050
    },
    {
      "epoch": 2.4041689383393057,
      "grad_norm": 3.723980188369751,
      "learning_rate": 3.7984067330086806e-05,
      "loss": 0.8962,
      "step": 227100
    },
    {
      "epoch": 2.404698260119309,
      "grad_norm": 3.7987794876098633,
      "learning_rate": 3.798142070717765e-05,
      "loss": 0.9071,
      "step": 227150
    },
    {
      "epoch": 2.4052275818993123,
      "grad_norm": 3.770847797393799,
      "learning_rate": 3.7978774084268474e-05,
      "loss": 0.8844,
      "step": 227200
    },
    {
      "epoch": 2.4057569036793156,
      "grad_norm": 3.6067147254943848,
      "learning_rate": 3.797612746135931e-05,
      "loss": 0.8967,
      "step": 227250
    },
    {
      "epoch": 2.406286225459319,
      "grad_norm": 3.7354774475097656,
      "learning_rate": 3.7973480838450135e-05,
      "loss": 0.897,
      "step": 227300
    },
    {
      "epoch": 2.4068155472393222,
      "grad_norm": 3.897526264190674,
      "learning_rate": 3.7970834215540976e-05,
      "loss": 0.8994,
      "step": 227350
    },
    {
      "epoch": 2.4073448690193255,
      "grad_norm": 3.60868501663208,
      "learning_rate": 3.7968187592631804e-05,
      "loss": 0.895,
      "step": 227400
    },
    {
      "epoch": 2.407874190799329,
      "grad_norm": 3.7206568717956543,
      "learning_rate": 3.796554096972264e-05,
      "loss": 0.8916,
      "step": 227450
    },
    {
      "epoch": 2.408403512579332,
      "grad_norm": 4.187774658203125,
      "learning_rate": 3.7962894346813465e-05,
      "loss": 0.8964,
      "step": 227500
    },
    {
      "epoch": 2.408403512579332,
      "eval_loss": 0.7007085680961609,
      "eval_runtime": 46.7061,
      "eval_samples_per_second": 3595.461,
      "eval_steps_per_second": 449.449,
      "step": 227500
    },
    {
      "epoch": 2.4089328343593355,
      "grad_norm": 4.078390121459961,
      "learning_rate": 3.79602477239043e-05,
      "loss": 0.9039,
      "step": 227550
    },
    {
      "epoch": 2.409462156139339,
      "grad_norm": 3.8458707332611084,
      "learning_rate": 3.795760110099513e-05,
      "loss": 0.9049,
      "step": 227600
    },
    {
      "epoch": 2.409991477919342,
      "grad_norm": 4.210651397705078,
      "learning_rate": 3.795495447808596e-05,
      "loss": 0.9111,
      "step": 227650
    },
    {
      "epoch": 2.4105207996993454,
      "grad_norm": 3.6571505069732666,
      "learning_rate": 3.7952307855176795e-05,
      "loss": 0.8977,
      "step": 227700
    },
    {
      "epoch": 2.4110501214793487,
      "grad_norm": 3.598679780960083,
      "learning_rate": 3.794966123226763e-05,
      "loss": 0.9001,
      "step": 227750
    },
    {
      "epoch": 2.4115794432593516,
      "grad_norm": 4.297916889190674,
      "learning_rate": 3.794701460935846e-05,
      "loss": 0.8999,
      "step": 227800
    },
    {
      "epoch": 2.412108765039355,
      "grad_norm": 4.1786909103393555,
      "learning_rate": 3.794436798644929e-05,
      "loss": 0.8879,
      "step": 227850
    },
    {
      "epoch": 2.412638086819358,
      "grad_norm": 4.041821479797363,
      "learning_rate": 3.7941721363540124e-05,
      "loss": 0.8997,
      "step": 227900
    },
    {
      "epoch": 2.4131674085993615,
      "grad_norm": 3.5890254974365234,
      "learning_rate": 3.793907474063096e-05,
      "loss": 0.8968,
      "step": 227950
    },
    {
      "epoch": 2.413696730379365,
      "grad_norm": 4.045624732971191,
      "learning_rate": 3.793642811772179e-05,
      "loss": 0.9002,
      "step": 228000
    },
    {
      "epoch": 2.413696730379365,
      "eval_loss": 0.702505886554718,
      "eval_runtime": 46.54,
      "eval_samples_per_second": 3608.298,
      "eval_steps_per_second": 451.053,
      "step": 228000
    },
    {
      "epoch": 2.414226052159368,
      "grad_norm": 3.951964855194092,
      "learning_rate": 3.793378149481262e-05,
      "loss": 0.9,
      "step": 228050
    },
    {
      "epoch": 2.4147553739393715,
      "grad_norm": 4.064621448516846,
      "learning_rate": 3.7931134871903454e-05,
      "loss": 0.8917,
      "step": 228100
    },
    {
      "epoch": 2.4152846957193748,
      "grad_norm": 3.977595806121826,
      "learning_rate": 3.792848824899429e-05,
      "loss": 0.9031,
      "step": 228150
    },
    {
      "epoch": 2.415814017499378,
      "grad_norm": 3.694077253341675,
      "learning_rate": 3.7925841626085115e-05,
      "loss": 0.9055,
      "step": 228200
    },
    {
      "epoch": 2.4163433392793814,
      "grad_norm": 3.677199602127075,
      "learning_rate": 3.792319500317595e-05,
      "loss": 0.8985,
      "step": 228250
    },
    {
      "epoch": 2.4168726610593847,
      "grad_norm": 3.949340581893921,
      "learning_rate": 3.792054838026678e-05,
      "loss": 0.9197,
      "step": 228300
    },
    {
      "epoch": 2.417401982839388,
      "grad_norm": 3.844219207763672,
      "learning_rate": 3.791790175735762e-05,
      "loss": 0.8964,
      "step": 228350
    },
    {
      "epoch": 2.4179313046193913,
      "grad_norm": 3.713198661804199,
      "learning_rate": 3.7915255134448445e-05,
      "loss": 0.9137,
      "step": 228400
    },
    {
      "epoch": 2.4184606263993946,
      "grad_norm": 4.042593479156494,
      "learning_rate": 3.791260851153928e-05,
      "loss": 0.9049,
      "step": 228450
    },
    {
      "epoch": 2.418989948179398,
      "grad_norm": 4.159635066986084,
      "learning_rate": 3.7909961888630106e-05,
      "loss": 0.8987,
      "step": 228500
    },
    {
      "epoch": 2.418989948179398,
      "eval_loss": 0.6987680196762085,
      "eval_runtime": 46.447,
      "eval_samples_per_second": 3615.518,
      "eval_steps_per_second": 451.956,
      "step": 228500
    },
    {
      "epoch": 2.419519269959401,
      "grad_norm": 3.6606833934783936,
      "learning_rate": 3.790731526572095e-05,
      "loss": 0.906,
      "step": 228550
    },
    {
      "epoch": 2.420048591739404,
      "grad_norm": 3.546917200088501,
      "learning_rate": 3.7904668642811775e-05,
      "loss": 0.9172,
      "step": 228600
    },
    {
      "epoch": 2.4205779135194074,
      "grad_norm": 3.4816701412200928,
      "learning_rate": 3.790207495236079e-05,
      "loss": 0.8906,
      "step": 228650
    },
    {
      "epoch": 2.4211072352994107,
      "grad_norm": 3.349954128265381,
      "learning_rate": 3.7899428329451617e-05,
      "loss": 0.8981,
      "step": 228700
    },
    {
      "epoch": 2.421636557079414,
      "grad_norm": 3.91837477684021,
      "learning_rate": 3.789678170654246e-05,
      "loss": 0.8994,
      "step": 228750
    },
    {
      "epoch": 2.4221658788594174,
      "grad_norm": 3.5235369205474854,
      "learning_rate": 3.7894135083633285e-05,
      "loss": 0.8943,
      "step": 228800
    },
    {
      "epoch": 2.4226952006394207,
      "grad_norm": 3.6769776344299316,
      "learning_rate": 3.789148846072412e-05,
      "loss": 0.8868,
      "step": 228850
    },
    {
      "epoch": 2.423224522419424,
      "grad_norm": 4.1165361404418945,
      "learning_rate": 3.7888841837814946e-05,
      "loss": 0.9064,
      "step": 228900
    },
    {
      "epoch": 2.4237538441994273,
      "grad_norm": 3.9239609241485596,
      "learning_rate": 3.788619521490579e-05,
      "loss": 0.9005,
      "step": 228950
    },
    {
      "epoch": 2.4242831659794306,
      "grad_norm": 4.066464424133301,
      "learning_rate": 3.7883548591996614e-05,
      "loss": 0.894,
      "step": 229000
    },
    {
      "epoch": 2.4242831659794306,
      "eval_loss": 0.6996023654937744,
      "eval_runtime": 46.5,
      "eval_samples_per_second": 3611.4,
      "eval_steps_per_second": 451.441,
      "step": 229000
    },
    {
      "epoch": 2.424812487759434,
      "grad_norm": 4.016529083251953,
      "learning_rate": 3.788090196908745e-05,
      "loss": 0.8989,
      "step": 229050
    },
    {
      "epoch": 2.4253418095394372,
      "grad_norm": 3.7498037815093994,
      "learning_rate": 3.7878255346178276e-05,
      "loss": 0.8946,
      "step": 229100
    },
    {
      "epoch": 2.4258711313194405,
      "grad_norm": 3.7309553623199463,
      "learning_rate": 3.787560872326911e-05,
      "loss": 0.8873,
      "step": 229150
    },
    {
      "epoch": 2.426400453099444,
      "grad_norm": 3.576897382736206,
      "learning_rate": 3.7872962100359944e-05,
      "loss": 0.9043,
      "step": 229200
    },
    {
      "epoch": 2.426929774879447,
      "grad_norm": 3.9407172203063965,
      "learning_rate": 3.787031547745077e-05,
      "loss": 0.8969,
      "step": 229250
    },
    {
      "epoch": 2.42745909665945,
      "grad_norm": 4.01207160949707,
      "learning_rate": 3.7867668854541605e-05,
      "loss": 0.8936,
      "step": 229300
    },
    {
      "epoch": 2.4279884184394533,
      "grad_norm": 4.1479034423828125,
      "learning_rate": 3.786502223163244e-05,
      "loss": 0.8845,
      "step": 229350
    },
    {
      "epoch": 2.4285177402194567,
      "grad_norm": 3.8175196647644043,
      "learning_rate": 3.7862375608723274e-05,
      "loss": 0.9001,
      "step": 229400
    },
    {
      "epoch": 2.42904706199946,
      "grad_norm": 4.298247814178467,
      "learning_rate": 3.78597289858141e-05,
      "loss": 0.9081,
      "step": 229450
    },
    {
      "epoch": 2.4295763837794633,
      "grad_norm": 3.9001381397247314,
      "learning_rate": 3.7857082362904935e-05,
      "loss": 0.8913,
      "step": 229500
    },
    {
      "epoch": 2.4295763837794633,
      "eval_loss": 0.6971771717071533,
      "eval_runtime": 46.5717,
      "eval_samples_per_second": 3605.834,
      "eval_steps_per_second": 450.745,
      "step": 229500
    },
    {
      "epoch": 2.4301057055594666,
      "grad_norm": 3.914170980453491,
      "learning_rate": 3.785443573999577e-05,
      "loss": 0.9015,
      "step": 229550
    },
    {
      "epoch": 2.43063502733947,
      "grad_norm": 3.525649309158325,
      "learning_rate": 3.78517891170866e-05,
      "loss": 0.8927,
      "step": 229600
    },
    {
      "epoch": 2.431164349119473,
      "grad_norm": 3.8708293437957764,
      "learning_rate": 3.784914249417743e-05,
      "loss": 0.9025,
      "step": 229650
    },
    {
      "epoch": 2.4316936708994765,
      "grad_norm": 4.228196620941162,
      "learning_rate": 3.7846495871268265e-05,
      "loss": 0.8914,
      "step": 229700
    },
    {
      "epoch": 2.43222299267948,
      "grad_norm": 3.8905115127563477,
      "learning_rate": 3.78438492483591e-05,
      "loss": 0.8962,
      "step": 229750
    },
    {
      "epoch": 2.432752314459483,
      "grad_norm": 3.8133320808410645,
      "learning_rate": 3.7841202625449926e-05,
      "loss": 0.908,
      "step": 229800
    },
    {
      "epoch": 2.4332816362394865,
      "grad_norm": 4.268306255340576,
      "learning_rate": 3.783855600254076e-05,
      "loss": 0.9104,
      "step": 229850
    },
    {
      "epoch": 2.4338109580194898,
      "grad_norm": 4.007115840911865,
      "learning_rate": 3.783590937963159e-05,
      "loss": 0.9113,
      "step": 229900
    },
    {
      "epoch": 2.434340279799493,
      "grad_norm": 3.7836427688598633,
      "learning_rate": 3.783326275672243e-05,
      "loss": 0.8855,
      "step": 229950
    },
    {
      "epoch": 2.4348696015794964,
      "grad_norm": 3.954880475997925,
      "learning_rate": 3.7830616133813256e-05,
      "loss": 0.8888,
      "step": 230000
    },
    {
      "epoch": 2.4348696015794964,
      "eval_loss": 0.6959145069122314,
      "eval_runtime": 46.5983,
      "eval_samples_per_second": 3603.78,
      "eval_steps_per_second": 450.489,
      "step": 230000
    },
    {
      "epoch": 2.4353989233594993,
      "grad_norm": 3.8157050609588623,
      "learning_rate": 3.782796951090409e-05,
      "loss": 0.8998,
      "step": 230050
    },
    {
      "epoch": 2.4359282451395026,
      "grad_norm": 4.12326192855835,
      "learning_rate": 3.782532288799492e-05,
      "loss": 0.8901,
      "step": 230100
    },
    {
      "epoch": 2.436457566919506,
      "grad_norm": 3.7233309745788574,
      "learning_rate": 3.782267626508576e-05,
      "loss": 0.9008,
      "step": 230150
    },
    {
      "epoch": 2.436986888699509,
      "grad_norm": 4.210658073425293,
      "learning_rate": 3.7820029642176585e-05,
      "loss": 0.9105,
      "step": 230200
    },
    {
      "epoch": 2.4375162104795125,
      "grad_norm": 3.792393684387207,
      "learning_rate": 3.781738301926742e-05,
      "loss": 0.891,
      "step": 230250
    },
    {
      "epoch": 2.438045532259516,
      "grad_norm": 4.050133228302002,
      "learning_rate": 3.781473639635825e-05,
      "loss": 0.9038,
      "step": 230300
    },
    {
      "epoch": 2.438574854039519,
      "grad_norm": 3.669816255569458,
      "learning_rate": 3.781208977344908e-05,
      "loss": 0.8983,
      "step": 230350
    },
    {
      "epoch": 2.4391041758195224,
      "grad_norm": 3.6949620246887207,
      "learning_rate": 3.7809443150539915e-05,
      "loss": 0.9041,
      "step": 230400
    },
    {
      "epoch": 2.4396334975995257,
      "grad_norm": 3.7898311614990234,
      "learning_rate": 3.780679652763074e-05,
      "loss": 0.921,
      "step": 230450
    },
    {
      "epoch": 2.440162819379529,
      "grad_norm": 4.520287036895752,
      "learning_rate": 3.7804149904721576e-05,
      "loss": 0.894,
      "step": 230500
    },
    {
      "epoch": 2.440162819379529,
      "eval_loss": 0.6945688724517822,
      "eval_runtime": 46.5867,
      "eval_samples_per_second": 3604.679,
      "eval_steps_per_second": 450.601,
      "step": 230500
    },
    {
      "epoch": 2.4406921411595324,
      "grad_norm": 4.0159525871276855,
      "learning_rate": 3.780150328181241e-05,
      "loss": 0.8779,
      "step": 230550
    },
    {
      "epoch": 2.4412214629395357,
      "grad_norm": 4.239818572998047,
      "learning_rate": 3.7798856658903245e-05,
      "loss": 0.9031,
      "step": 230600
    },
    {
      "epoch": 2.441750784719539,
      "grad_norm": 4.069439888000488,
      "learning_rate": 3.779621003599407e-05,
      "loss": 0.8892,
      "step": 230650
    },
    {
      "epoch": 2.4422801064995423,
      "grad_norm": 3.6288914680480957,
      "learning_rate": 3.7793563413084906e-05,
      "loss": 0.9118,
      "step": 230700
    },
    {
      "epoch": 2.4428094282795456,
      "grad_norm": 3.710846185684204,
      "learning_rate": 3.779091679017574e-05,
      "loss": 0.9024,
      "step": 230750
    },
    {
      "epoch": 2.4433387500595485,
      "grad_norm": 4.031753063201904,
      "learning_rate": 3.778827016726657e-05,
      "loss": 0.8898,
      "step": 230800
    },
    {
      "epoch": 2.443868071839552,
      "grad_norm": 4.186949729919434,
      "learning_rate": 3.77856235443574e-05,
      "loss": 0.9035,
      "step": 230850
    },
    {
      "epoch": 2.444397393619555,
      "grad_norm": 3.892599582672119,
      "learning_rate": 3.778297692144823e-05,
      "loss": 0.9022,
      "step": 230900
    },
    {
      "epoch": 2.4449267153995584,
      "grad_norm": 3.9989264011383057,
      "learning_rate": 3.778033029853907e-05,
      "loss": 0.8903,
      "step": 230950
    },
    {
      "epoch": 2.4454560371795617,
      "grad_norm": 4.143525123596191,
      "learning_rate": 3.77776836756299e-05,
      "loss": 0.8985,
      "step": 231000
    },
    {
      "epoch": 2.4454560371795617,
      "eval_loss": 0.6937265396118164,
      "eval_runtime": 46.6244,
      "eval_samples_per_second": 3601.76,
      "eval_steps_per_second": 450.236,
      "step": 231000
    },
    {
      "epoch": 2.445985358959565,
      "grad_norm": 3.6821377277374268,
      "learning_rate": 3.777503705272073e-05,
      "loss": 0.9094,
      "step": 231050
    },
    {
      "epoch": 2.4465146807395683,
      "grad_norm": 3.9148385524749756,
      "learning_rate": 3.777239042981156e-05,
      "loss": 0.9061,
      "step": 231100
    },
    {
      "epoch": 2.4470440025195717,
      "grad_norm": 3.9992990493774414,
      "learning_rate": 3.77697438069024e-05,
      "loss": 0.893,
      "step": 231150
    },
    {
      "epoch": 2.447573324299575,
      "grad_norm": 4.207277297973633,
      "learning_rate": 3.776709718399323e-05,
      "loss": 0.9121,
      "step": 231200
    },
    {
      "epoch": 2.4481026460795783,
      "grad_norm": 3.5830905437469482,
      "learning_rate": 3.776445056108406e-05,
      "loss": 0.8963,
      "step": 231250
    },
    {
      "epoch": 2.4486319678595816,
      "grad_norm": 3.916614055633545,
      "learning_rate": 3.776180393817489e-05,
      "loss": 0.8978,
      "step": 231300
    },
    {
      "epoch": 2.449161289639585,
      "grad_norm": 3.723936080932617,
      "learning_rate": 3.775915731526572e-05,
      "loss": 0.89,
      "step": 231350
    },
    {
      "epoch": 2.449690611419588,
      "grad_norm": 4.009842872619629,
      "learning_rate": 3.7756510692356556e-05,
      "loss": 0.8851,
      "step": 231400
    },
    {
      "epoch": 2.4502199331995915,
      "grad_norm": 3.605663776397705,
      "learning_rate": 3.7753864069447384e-05,
      "loss": 0.8996,
      "step": 231450
    },
    {
      "epoch": 2.450749254979595,
      "grad_norm": 3.768238067626953,
      "learning_rate": 3.775121744653822e-05,
      "loss": 0.8912,
      "step": 231500
    },
    {
      "epoch": 2.450749254979595,
      "eval_loss": 0.6931242942810059,
      "eval_runtime": 46.5412,
      "eval_samples_per_second": 3608.199,
      "eval_steps_per_second": 451.041,
      "step": 231500
    },
    {
      "epoch": 2.4512785767595977,
      "grad_norm": 4.00632905960083,
      "learning_rate": 3.774857082362905e-05,
      "loss": 0.893,
      "step": 231550
    },
    {
      "epoch": 2.451807898539601,
      "grad_norm": 4.161268711090088,
      "learning_rate": 3.7745924200719886e-05,
      "loss": 0.8822,
      "step": 231600
    },
    {
      "epoch": 2.4523372203196043,
      "grad_norm": 4.255337715148926,
      "learning_rate": 3.774327757781071e-05,
      "loss": 0.9154,
      "step": 231650
    },
    {
      "epoch": 2.4528665420996076,
      "grad_norm": 3.779651165008545,
      "learning_rate": 3.774063095490155e-05,
      "loss": 0.899,
      "step": 231700
    },
    {
      "epoch": 2.453395863879611,
      "grad_norm": 3.791517972946167,
      "learning_rate": 3.773798433199238e-05,
      "loss": 0.9015,
      "step": 231750
    },
    {
      "epoch": 2.4539251856596143,
      "grad_norm": 3.7946736812591553,
      "learning_rate": 3.7735337709083216e-05,
      "loss": 0.886,
      "step": 231800
    },
    {
      "epoch": 2.4544545074396176,
      "grad_norm": 4.027955532073975,
      "learning_rate": 3.773269108617404e-05,
      "loss": 0.8988,
      "step": 231850
    },
    {
      "epoch": 2.454983829219621,
      "grad_norm": 3.9338572025299072,
      "learning_rate": 3.773004446326488e-05,
      "loss": 0.8875,
      "step": 231900
    },
    {
      "epoch": 2.455513150999624,
      "grad_norm": 3.620027780532837,
      "learning_rate": 3.772739784035571e-05,
      "loss": 0.9096,
      "step": 231950
    },
    {
      "epoch": 2.4560424727796275,
      "grad_norm": 3.5207102298736572,
      "learning_rate": 3.772475121744654e-05,
      "loss": 0.8889,
      "step": 232000
    },
    {
      "epoch": 2.4560424727796275,
      "eval_loss": 0.6952341198921204,
      "eval_runtime": 46.5189,
      "eval_samples_per_second": 3609.934,
      "eval_steps_per_second": 451.258,
      "step": 232000
    },
    {
      "epoch": 2.456571794559631,
      "grad_norm": 3.764683961868286,
      "learning_rate": 3.772210459453737e-05,
      "loss": 0.9082,
      "step": 232050
    },
    {
      "epoch": 2.457101116339634,
      "grad_norm": 3.7977488040924072,
      "learning_rate": 3.77194579716282e-05,
      "loss": 0.8945,
      "step": 232100
    },
    {
      "epoch": 2.4576304381196374,
      "grad_norm": 3.540682792663574,
      "learning_rate": 3.771681134871904e-05,
      "loss": 0.9084,
      "step": 232150
    },
    {
      "epoch": 2.4581597598996408,
      "grad_norm": 4.001914024353027,
      "learning_rate": 3.771416472580987e-05,
      "loss": 0.8893,
      "step": 232200
    },
    {
      "epoch": 2.458689081679644,
      "grad_norm": 3.7530386447906494,
      "learning_rate": 3.77115181029007e-05,
      "loss": 0.8724,
      "step": 232250
    },
    {
      "epoch": 2.459218403459647,
      "grad_norm": 4.237550258636475,
      "learning_rate": 3.770887147999153e-05,
      "loss": 0.8935,
      "step": 232300
    },
    {
      "epoch": 2.4597477252396507,
      "grad_norm": 3.9320571422576904,
      "learning_rate": 3.770622485708237e-05,
      "loss": 0.8919,
      "step": 232350
    },
    {
      "epoch": 2.4602770470196536,
      "grad_norm": 4.173556804656982,
      "learning_rate": 3.77035782341732e-05,
      "loss": 0.8937,
      "step": 232400
    },
    {
      "epoch": 2.460806368799657,
      "grad_norm": 4.053564071655273,
      "learning_rate": 3.770093161126403e-05,
      "loss": 0.8909,
      "step": 232450
    },
    {
      "epoch": 2.46133569057966,
      "grad_norm": 4.210835933685303,
      "learning_rate": 3.769828498835486e-05,
      "loss": 0.891,
      "step": 232500
    },
    {
      "epoch": 2.46133569057966,
      "eval_loss": 0.6917142868041992,
      "eval_runtime": 46.5344,
      "eval_samples_per_second": 3608.731,
      "eval_steps_per_second": 451.107,
      "step": 232500
    },
    {
      "epoch": 2.4618650123596635,
      "grad_norm": 4.416632652282715,
      "learning_rate": 3.769563836544569e-05,
      "loss": 0.9135,
      "step": 232550
    },
    {
      "epoch": 2.462394334139667,
      "grad_norm": 3.51267409324646,
      "learning_rate": 3.769299174253653e-05,
      "loss": 0.8919,
      "step": 232600
    },
    {
      "epoch": 2.46292365591967,
      "grad_norm": 4.13602876663208,
      "learning_rate": 3.769039805208554e-05,
      "loss": 0.8926,
      "step": 232650
    },
    {
      "epoch": 2.4634529776996734,
      "grad_norm": 3.902961492538452,
      "learning_rate": 3.768775142917637e-05,
      "loss": 0.8791,
      "step": 232700
    },
    {
      "epoch": 2.4639822994796767,
      "grad_norm": 4.267088413238525,
      "learning_rate": 3.768510480626721e-05,
      "loss": 0.8983,
      "step": 232750
    },
    {
      "epoch": 2.46451162125968,
      "grad_norm": 3.7978641986846924,
      "learning_rate": 3.768245818335804e-05,
      "loss": 0.905,
      "step": 232800
    },
    {
      "epoch": 2.4650409430396834,
      "grad_norm": 3.42639422416687,
      "learning_rate": 3.767981156044887e-05,
      "loss": 0.9002,
      "step": 232850
    },
    {
      "epoch": 2.4655702648196867,
      "grad_norm": 3.7318103313446045,
      "learning_rate": 3.76771649375397e-05,
      "loss": 0.888,
      "step": 232900
    },
    {
      "epoch": 2.46609958659969,
      "grad_norm": 3.6912167072296143,
      "learning_rate": 3.767451831463053e-05,
      "loss": 0.8858,
      "step": 232950
    },
    {
      "epoch": 2.4666289083796933,
      "grad_norm": 4.083795547485352,
      "learning_rate": 3.767187169172137e-05,
      "loss": 0.8982,
      "step": 233000
    },
    {
      "epoch": 2.4666289083796933,
      "eval_loss": 0.6918303966522217,
      "eval_runtime": 46.617,
      "eval_samples_per_second": 3602.336,
      "eval_steps_per_second": 450.308,
      "step": 233000
    },
    {
      "epoch": 2.467158230159696,
      "grad_norm": 3.311347723007202,
      "learning_rate": 3.7669225068812194e-05,
      "loss": 0.8836,
      "step": 233050
    },
    {
      "epoch": 2.4676875519397,
      "grad_norm": 3.727720260620117,
      "learning_rate": 3.766657844590303e-05,
      "loss": 0.8881,
      "step": 233100
    },
    {
      "epoch": 2.4682168737197028,
      "grad_norm": 3.7289981842041016,
      "learning_rate": 3.766393182299386e-05,
      "loss": 0.8912,
      "step": 233150
    },
    {
      "epoch": 2.468746195499706,
      "grad_norm": 4.013906955718994,
      "learning_rate": 3.76612852000847e-05,
      "loss": 0.8817,
      "step": 233200
    },
    {
      "epoch": 2.4692755172797094,
      "grad_norm": 3.9629178047180176,
      "learning_rate": 3.7658638577175524e-05,
      "loss": 0.9096,
      "step": 233250
    },
    {
      "epoch": 2.4698048390597127,
      "grad_norm": 3.8971564769744873,
      "learning_rate": 3.765599195426636e-05,
      "loss": 0.8925,
      "step": 233300
    },
    {
      "epoch": 2.470334160839716,
      "grad_norm": 4.101435661315918,
      "learning_rate": 3.765334533135719e-05,
      "loss": 0.8899,
      "step": 233350
    },
    {
      "epoch": 2.4708634826197193,
      "grad_norm": 3.7414677143096924,
      "learning_rate": 3.7650698708448026e-05,
      "loss": 0.8954,
      "step": 233400
    },
    {
      "epoch": 2.4713928043997226,
      "grad_norm": 3.9351682662963867,
      "learning_rate": 3.7648052085538854e-05,
      "loss": 0.9069,
      "step": 233450
    },
    {
      "epoch": 2.471922126179726,
      "grad_norm": 3.8680036067962646,
      "learning_rate": 3.764540546262969e-05,
      "loss": 0.8977,
      "step": 233500
    },
    {
      "epoch": 2.471922126179726,
      "eval_loss": 0.6917169094085693,
      "eval_runtime": 46.6044,
      "eval_samples_per_second": 3603.311,
      "eval_steps_per_second": 450.43,
      "step": 233500
    },
    {
      "epoch": 2.4724514479597293,
      "grad_norm": 3.9338929653167725,
      "learning_rate": 3.764275883972052e-05,
      "loss": 0.8989,
      "step": 233550
    },
    {
      "epoch": 2.4729807697397326,
      "grad_norm": 3.683560609817505,
      "learning_rate": 3.764011221681135e-05,
      "loss": 0.8887,
      "step": 233600
    },
    {
      "epoch": 2.473510091519736,
      "grad_norm": 4.206657886505127,
      "learning_rate": 3.763746559390218e-05,
      "loss": 0.8899,
      "step": 233650
    },
    {
      "epoch": 2.474039413299739,
      "grad_norm": 4.474470615386963,
      "learning_rate": 3.763481897099301e-05,
      "loss": 0.898,
      "step": 233700
    },
    {
      "epoch": 2.4745687350797425,
      "grad_norm": 3.905954122543335,
      "learning_rate": 3.763217234808385e-05,
      "loss": 0.8886,
      "step": 233750
    },
    {
      "epoch": 2.4750980568597454,
      "grad_norm": 4.115920543670654,
      "learning_rate": 3.762952572517468e-05,
      "loss": 0.9095,
      "step": 233800
    },
    {
      "epoch": 2.475627378639749,
      "grad_norm": 3.878089427947998,
      "learning_rate": 3.762687910226551e-05,
      "loss": 0.884,
      "step": 233850
    },
    {
      "epoch": 2.476156700419752,
      "grad_norm": 3.8032562732696533,
      "learning_rate": 3.762423247935634e-05,
      "loss": 0.8887,
      "step": 233900
    },
    {
      "epoch": 2.4766860221997553,
      "grad_norm": 4.168117523193359,
      "learning_rate": 3.762158585644718e-05,
      "loss": 0.893,
      "step": 233950
    },
    {
      "epoch": 2.4772153439797586,
      "grad_norm": 3.7036855220794678,
      "learning_rate": 3.761893923353801e-05,
      "loss": 0.9002,
      "step": 234000
    },
    {
      "epoch": 2.4772153439797586,
      "eval_loss": 0.6901578307151794,
      "eval_runtime": 46.6106,
      "eval_samples_per_second": 3602.826,
      "eval_steps_per_second": 450.369,
      "step": 234000
    },
    {
      "epoch": 2.477744665759762,
      "grad_norm": 4.134927272796631,
      "learning_rate": 3.761629261062884e-05,
      "loss": 0.8897,
      "step": 234050
    },
    {
      "epoch": 2.4782739875397652,
      "grad_norm": 3.738325357437134,
      "learning_rate": 3.761364598771967e-05,
      "loss": 0.8937,
      "step": 234100
    },
    {
      "epoch": 2.4788033093197686,
      "grad_norm": 3.773285388946533,
      "learning_rate": 3.7610999364810504e-05,
      "loss": 0.8903,
      "step": 234150
    },
    {
      "epoch": 2.479332631099772,
      "grad_norm": 3.96288800239563,
      "learning_rate": 3.760835274190134e-05,
      "loss": 0.8991,
      "step": 234200
    },
    {
      "epoch": 2.479861952879775,
      "grad_norm": 3.860689640045166,
      "learning_rate": 3.7605706118992165e-05,
      "loss": 0.8822,
      "step": 234250
    },
    {
      "epoch": 2.4803912746597785,
      "grad_norm": 4.166354656219482,
      "learning_rate": 3.7603059496083e-05,
      "loss": 0.8857,
      "step": 234300
    },
    {
      "epoch": 2.480920596439782,
      "grad_norm": 4.151968479156494,
      "learning_rate": 3.7600412873173834e-05,
      "loss": 0.9076,
      "step": 234350
    },
    {
      "epoch": 2.481449918219785,
      "grad_norm": 3.441511392593384,
      "learning_rate": 3.759781918272285e-05,
      "loss": 0.9057,
      "step": 234400
    },
    {
      "epoch": 2.4819792399997884,
      "grad_norm": 3.499481439590454,
      "learning_rate": 3.759517255981368e-05,
      "loss": 0.8822,
      "step": 234450
    },
    {
      "epoch": 2.4825085617797917,
      "grad_norm": 3.8553507328033447,
      "learning_rate": 3.759252593690451e-05,
      "loss": 0.8905,
      "step": 234500
    },
    {
      "epoch": 2.4825085617797917,
      "eval_loss": 0.6904044151306152,
      "eval_runtime": 46.5768,
      "eval_samples_per_second": 3605.443,
      "eval_steps_per_second": 450.697,
      "step": 234500
    },
    {
      "epoch": 2.4830378835597946,
      "grad_norm": 3.7300257682800293,
      "learning_rate": 3.7589879313995344e-05,
      "loss": 0.8932,
      "step": 234550
    },
    {
      "epoch": 2.4835672053397984,
      "grad_norm": 4.253570556640625,
      "learning_rate": 3.758723269108618e-05,
      "loss": 0.8893,
      "step": 234600
    },
    {
      "epoch": 2.4840965271198012,
      "grad_norm": 4.309081554412842,
      "learning_rate": 3.7584586068177005e-05,
      "loss": 0.8891,
      "step": 234650
    },
    {
      "epoch": 2.4846258488998045,
      "grad_norm": 4.0993499755859375,
      "learning_rate": 3.758193944526784e-05,
      "loss": 0.8883,
      "step": 234700
    },
    {
      "epoch": 2.485155170679808,
      "grad_norm": 4.02211332321167,
      "learning_rate": 3.7579292822358673e-05,
      "loss": 0.8867,
      "step": 234750
    },
    {
      "epoch": 2.485684492459811,
      "grad_norm": 4.193838119506836,
      "learning_rate": 3.757664619944951e-05,
      "loss": 0.9004,
      "step": 234800
    },
    {
      "epoch": 2.4862138142398145,
      "grad_norm": 3.988542318344116,
      "learning_rate": 3.7573999576540335e-05,
      "loss": 0.8799,
      "step": 234850
    },
    {
      "epoch": 2.486743136019818,
      "grad_norm": 3.937080144882202,
      "learning_rate": 3.757135295363117e-05,
      "loss": 0.8883,
      "step": 234900
    },
    {
      "epoch": 2.487272457799821,
      "grad_norm": 3.4574742317199707,
      "learning_rate": 3.7568706330722e-05,
      "loss": 0.8927,
      "step": 234950
    },
    {
      "epoch": 2.4878017795798244,
      "grad_norm": 4.030246257781982,
      "learning_rate": 3.756605970781284e-05,
      "loss": 0.8879,
      "step": 235000
    },
    {
      "epoch": 2.4878017795798244,
      "eval_loss": 0.6871131062507629,
      "eval_runtime": 46.637,
      "eval_samples_per_second": 3600.788,
      "eval_steps_per_second": 450.115,
      "step": 235000
    },
    {
      "epoch": 2.4883311013598277,
      "grad_norm": 3.5496718883514404,
      "learning_rate": 3.7563413084903665e-05,
      "loss": 0.8879,
      "step": 235050
    },
    {
      "epoch": 2.488860423139831,
      "grad_norm": 3.6361565589904785,
      "learning_rate": 3.75607664619945e-05,
      "loss": 0.8776,
      "step": 235100
    },
    {
      "epoch": 2.4893897449198343,
      "grad_norm": 3.75192928314209,
      "learning_rate": 3.7558119839085326e-05,
      "loss": 0.9008,
      "step": 235150
    },
    {
      "epoch": 2.4899190666998376,
      "grad_norm": 3.2888176441192627,
      "learning_rate": 3.755547321617616e-05,
      "loss": 0.8874,
      "step": 235200
    },
    {
      "epoch": 2.490448388479841,
      "grad_norm": 3.9890315532684326,
      "learning_rate": 3.7552826593266994e-05,
      "loss": 0.898,
      "step": 235250
    },
    {
      "epoch": 2.490977710259844,
      "grad_norm": 3.7576382160186768,
      "learning_rate": 3.755017997035782e-05,
      "loss": 0.8884,
      "step": 235300
    },
    {
      "epoch": 2.4915070320398476,
      "grad_norm": 4.173429489135742,
      "learning_rate": 3.7547533347448656e-05,
      "loss": 0.857,
      "step": 235350
    },
    {
      "epoch": 2.4920363538198504,
      "grad_norm": 3.976890802383423,
      "learning_rate": 3.754488672453949e-05,
      "loss": 0.8837,
      "step": 235400
    },
    {
      "epoch": 2.4925656755998538,
      "grad_norm": 3.686016082763672,
      "learning_rate": 3.7542240101630324e-05,
      "loss": 0.896,
      "step": 235450
    },
    {
      "epoch": 2.493094997379857,
      "grad_norm": 3.475959539413452,
      "learning_rate": 3.753959347872115e-05,
      "loss": 0.8831,
      "step": 235500
    },
    {
      "epoch": 2.493094997379857,
      "eval_loss": 0.6863352656364441,
      "eval_runtime": 46.5578,
      "eval_samples_per_second": 3606.912,
      "eval_steps_per_second": 450.88,
      "step": 235500
    },
    {
      "epoch": 2.4936243191598604,
      "grad_norm": 3.763963460922241,
      "learning_rate": 3.7536946855811985e-05,
      "loss": 0.9057,
      "step": 235550
    },
    {
      "epoch": 2.4941536409398637,
      "grad_norm": 3.8707849979400635,
      "learning_rate": 3.753430023290282e-05,
      "loss": 0.9009,
      "step": 235600
    },
    {
      "epoch": 2.494682962719867,
      "grad_norm": 4.054122447967529,
      "learning_rate": 3.753165360999365e-05,
      "loss": 0.8794,
      "step": 235650
    },
    {
      "epoch": 2.4952122844998703,
      "grad_norm": 4.00755500793457,
      "learning_rate": 3.752900698708448e-05,
      "loss": 0.8776,
      "step": 235700
    },
    {
      "epoch": 2.4957416062798736,
      "grad_norm": 4.032227039337158,
      "learning_rate": 3.752636036417531e-05,
      "loss": 0.8931,
      "step": 235750
    },
    {
      "epoch": 2.496270928059877,
      "grad_norm": 4.064776420593262,
      "learning_rate": 3.752371374126615e-05,
      "loss": 0.8945,
      "step": 235800
    },
    {
      "epoch": 2.4968002498398802,
      "grad_norm": 3.78817081451416,
      "learning_rate": 3.7521067118356976e-05,
      "loss": 0.8771,
      "step": 235850
    },
    {
      "epoch": 2.4973295716198836,
      "grad_norm": 4.089669227600098,
      "learning_rate": 3.751842049544781e-05,
      "loss": 0.9028,
      "step": 235900
    },
    {
      "epoch": 2.497858893399887,
      "grad_norm": 4.38502836227417,
      "learning_rate": 3.751577387253864e-05,
      "loss": 0.8968,
      "step": 235950
    },
    {
      "epoch": 2.49838821517989,
      "grad_norm": 4.270825386047363,
      "learning_rate": 3.751312724962948e-05,
      "loss": 0.8839,
      "step": 236000
    },
    {
      "epoch": 2.49838821517989,
      "eval_loss": 0.6873624324798584,
      "eval_runtime": 46.5405,
      "eval_samples_per_second": 3608.259,
      "eval_steps_per_second": 451.048,
      "step": 236000
    },
    {
      "epoch": 2.498917536959893,
      "grad_norm": 4.079989433288574,
      "learning_rate": 3.7510480626720306e-05,
      "loss": 0.8904,
      "step": 236050
    },
    {
      "epoch": 2.499446858739897,
      "grad_norm": 3.786327838897705,
      "learning_rate": 3.750783400381114e-05,
      "loss": 0.8866,
      "step": 236100
    },
    {
      "epoch": 2.4999761805198997,
      "grad_norm": 3.8566629886627197,
      "learning_rate": 3.750518738090197e-05,
      "loss": 0.8845,
      "step": 236150
    },
    {
      "epoch": 2.500505502299903,
      "grad_norm": 3.6060850620269775,
      "learning_rate": 3.75025407579928e-05,
      "loss": 0.8867,
      "step": 236200
    },
    {
      "epoch": 2.5010348240799063,
      "grad_norm": 3.3893630504608154,
      "learning_rate": 3.7499894135083635e-05,
      "loss": 0.9054,
      "step": 236250
    },
    {
      "epoch": 2.5015641458599096,
      "grad_norm": 3.9601094722747803,
      "learning_rate": 3.749724751217446e-05,
      "loss": 0.8759,
      "step": 236300
    },
    {
      "epoch": 2.502093467639913,
      "grad_norm": 4.028994560241699,
      "learning_rate": 3.74946008892653e-05,
      "loss": 0.9125,
      "step": 236350
    },
    {
      "epoch": 2.5026227894199162,
      "grad_norm": 3.513601064682007,
      "learning_rate": 3.749195426635613e-05,
      "loss": 0.8866,
      "step": 236400
    },
    {
      "epoch": 2.5031521111999195,
      "grad_norm": 3.8002302646636963,
      "learning_rate": 3.7489307643446965e-05,
      "loss": 0.8907,
      "step": 236450
    },
    {
      "epoch": 2.503681432979923,
      "grad_norm": 3.9488272666931152,
      "learning_rate": 3.748666102053779e-05,
      "loss": 0.8772,
      "step": 236500
    },
    {
      "epoch": 2.503681432979923,
      "eval_loss": 0.6835280656814575,
      "eval_runtime": 46.6739,
      "eval_samples_per_second": 3597.946,
      "eval_steps_per_second": 449.759,
      "step": 236500
    },
    {
      "epoch": 2.504210754759926,
      "grad_norm": 3.700298309326172,
      "learning_rate": 3.7484014397628627e-05,
      "loss": 0.8974,
      "step": 236550
    },
    {
      "epoch": 2.5047400765399295,
      "grad_norm": 3.519972085952759,
      "learning_rate": 3.748136777471946e-05,
      "loss": 0.8907,
      "step": 236600
    },
    {
      "epoch": 2.505269398319933,
      "grad_norm": 3.693559408187866,
      "learning_rate": 3.7478721151810295e-05,
      "loss": 0.889,
      "step": 236650
    },
    {
      "epoch": 2.505798720099936,
      "grad_norm": 3.919356346130371,
      "learning_rate": 3.747607452890112e-05,
      "loss": 0.8711,
      "step": 236700
    },
    {
      "epoch": 2.5063280418799394,
      "grad_norm": 3.7519948482513428,
      "learning_rate": 3.7473427905991956e-05,
      "loss": 0.8879,
      "step": 236750
    },
    {
      "epoch": 2.5068573636599423,
      "grad_norm": 4.061941146850586,
      "learning_rate": 3.747078128308279e-05,
      "loss": 0.8846,
      "step": 236800
    },
    {
      "epoch": 2.507386685439946,
      "grad_norm": 4.151666164398193,
      "learning_rate": 3.746813466017362e-05,
      "loss": 0.882,
      "step": 236850
    },
    {
      "epoch": 2.507916007219949,
      "grad_norm": 3.8149125576019287,
      "learning_rate": 3.746548803726445e-05,
      "loss": 0.8814,
      "step": 236900
    },
    {
      "epoch": 2.508445328999952,
      "grad_norm": 3.9203059673309326,
      "learning_rate": 3.746284141435528e-05,
      "loss": 0.8858,
      "step": 236950
    },
    {
      "epoch": 2.5089746507799555,
      "grad_norm": 3.6145946979522705,
      "learning_rate": 3.746019479144612e-05,
      "loss": 0.8993,
      "step": 237000
    },
    {
      "epoch": 2.5089746507799555,
      "eval_loss": 0.6856426000595093,
      "eval_runtime": 46.6324,
      "eval_samples_per_second": 3601.147,
      "eval_steps_per_second": 450.159,
      "step": 237000
    },
    {
      "epoch": 2.509503972559959,
      "grad_norm": 3.6588151454925537,
      "learning_rate": 3.745754816853695e-05,
      "loss": 0.8876,
      "step": 237050
    },
    {
      "epoch": 2.510033294339962,
      "grad_norm": 3.823106288909912,
      "learning_rate": 3.745490154562778e-05,
      "loss": 0.8929,
      "step": 237100
    },
    {
      "epoch": 2.5105626161199655,
      "grad_norm": 4.016625881195068,
      "learning_rate": 3.745225492271861e-05,
      "loss": 0.8809,
      "step": 237150
    },
    {
      "epoch": 2.5110919378999688,
      "grad_norm": 3.908285140991211,
      "learning_rate": 3.744960829980945e-05,
      "loss": 0.8985,
      "step": 237200
    },
    {
      "epoch": 2.511621259679972,
      "grad_norm": 3.9289209842681885,
      "learning_rate": 3.744696167690028e-05,
      "loss": 0.8868,
      "step": 237250
    },
    {
      "epoch": 2.5121505814599754,
      "grad_norm": 3.664494276046753,
      "learning_rate": 3.744431505399111e-05,
      "loss": 0.8931,
      "step": 237300
    },
    {
      "epoch": 2.5126799032399787,
      "grad_norm": 4.3899455070495605,
      "learning_rate": 3.744166843108194e-05,
      "loss": 0.8855,
      "step": 237350
    },
    {
      "epoch": 2.513209225019982,
      "grad_norm": 3.783597469329834,
      "learning_rate": 3.743902180817277e-05,
      "loss": 0.8855,
      "step": 237400
    },
    {
      "epoch": 2.5137385467999853,
      "grad_norm": 4.070597171783447,
      "learning_rate": 3.7436375185263606e-05,
      "loss": 0.8684,
      "step": 237450
    },
    {
      "epoch": 2.5142678685799886,
      "grad_norm": 3.8379807472229004,
      "learning_rate": 3.7433728562354434e-05,
      "loss": 0.8921,
      "step": 237500
    },
    {
      "epoch": 2.5142678685799886,
      "eval_loss": 0.6863635778427124,
      "eval_runtime": 46.5332,
      "eval_samples_per_second": 3608.824,
      "eval_steps_per_second": 451.119,
      "step": 237500
    },
    {
      "epoch": 2.5147971903599915,
      "grad_norm": 3.6556174755096436,
      "learning_rate": 3.743108193944527e-05,
      "loss": 0.8877,
      "step": 237550
    },
    {
      "epoch": 2.5153265121399953,
      "grad_norm": 3.5529468059539795,
      "learning_rate": 3.74284353165361e-05,
      "loss": 0.8933,
      "step": 237600
    },
    {
      "epoch": 2.515855833919998,
      "grad_norm": 3.847370147705078,
      "learning_rate": 3.7425788693626936e-05,
      "loss": 0.8849,
      "step": 237650
    },
    {
      "epoch": 2.5163851557000014,
      "grad_norm": 3.6243326663970947,
      "learning_rate": 3.7423142070717763e-05,
      "loss": 0.8982,
      "step": 237700
    },
    {
      "epoch": 2.5169144774800047,
      "grad_norm": 3.8685238361358643,
      "learning_rate": 3.74204954478086e-05,
      "loss": 0.8965,
      "step": 237750
    },
    {
      "epoch": 2.517443799260008,
      "grad_norm": 4.08643102645874,
      "learning_rate": 3.741784882489943e-05,
      "loss": 0.8661,
      "step": 237800
    },
    {
      "epoch": 2.5179731210400114,
      "grad_norm": 4.034544944763184,
      "learning_rate": 3.7415202201990266e-05,
      "loss": 0.8951,
      "step": 237850
    },
    {
      "epoch": 2.5185024428200147,
      "grad_norm": 4.0304155349731445,
      "learning_rate": 3.741255557908109e-05,
      "loss": 0.8931,
      "step": 237900
    },
    {
      "epoch": 2.519031764600018,
      "grad_norm": 4.448029041290283,
      "learning_rate": 3.740990895617193e-05,
      "loss": 0.8991,
      "step": 237950
    },
    {
      "epoch": 2.5195610863800213,
      "grad_norm": 3.955997943878174,
      "learning_rate": 3.740726233326276e-05,
      "loss": 0.8916,
      "step": 238000
    },
    {
      "epoch": 2.5195610863800213,
      "eval_loss": 0.6825945377349854,
      "eval_runtime": 46.5525,
      "eval_samples_per_second": 3607.323,
      "eval_steps_per_second": 450.931,
      "step": 238000
    },
    {
      "epoch": 2.5200904081600246,
      "grad_norm": 3.761317253112793,
      "learning_rate": 3.740461571035359e-05,
      "loss": 0.8773,
      "step": 238050
    },
    {
      "epoch": 2.520619729940028,
      "grad_norm": 3.769089698791504,
      "learning_rate": 3.740196908744442e-05,
      "loss": 0.8899,
      "step": 238100
    },
    {
      "epoch": 2.5211490517200312,
      "grad_norm": 3.7599682807922363,
      "learning_rate": 3.739932246453525e-05,
      "loss": 0.9057,
      "step": 238150
    },
    {
      "epoch": 2.5216783735000345,
      "grad_norm": 3.8879477977752686,
      "learning_rate": 3.739667584162609e-05,
      "loss": 0.8823,
      "step": 238200
    },
    {
      "epoch": 2.522207695280038,
      "grad_norm": 3.896091938018799,
      "learning_rate": 3.739402921871692e-05,
      "loss": 0.8826,
      "step": 238250
    },
    {
      "epoch": 2.5227370170600407,
      "grad_norm": 4.209888935089111,
      "learning_rate": 3.739138259580775e-05,
      "loss": 0.8948,
      "step": 238300
    },
    {
      "epoch": 2.5232663388400445,
      "grad_norm": 3.887416124343872,
      "learning_rate": 3.738873597289858e-05,
      "loss": 0.8691,
      "step": 238350
    },
    {
      "epoch": 2.5237956606200473,
      "grad_norm": 3.502389907836914,
      "learning_rate": 3.73861422824476e-05,
      "loss": 0.8723,
      "step": 238400
    },
    {
      "epoch": 2.5243249824000507,
      "grad_norm": 3.8610644340515137,
      "learning_rate": 3.738349565953843e-05,
      "loss": 0.8936,
      "step": 238450
    },
    {
      "epoch": 2.524854304180054,
      "grad_norm": 3.950697660446167,
      "learning_rate": 3.738084903662926e-05,
      "loss": 0.8923,
      "step": 238500
    },
    {
      "epoch": 2.524854304180054,
      "eval_loss": 0.6817888617515564,
      "eval_runtime": 46.5187,
      "eval_samples_per_second": 3609.945,
      "eval_steps_per_second": 451.259,
      "step": 238500
    },
    {
      "epoch": 2.5253836259600573,
      "grad_norm": 3.916146755218506,
      "learning_rate": 3.737820241372009e-05,
      "loss": 0.865,
      "step": 238550
    },
    {
      "epoch": 2.5259129477400606,
      "grad_norm": 3.7031848430633545,
      "learning_rate": 3.737555579081093e-05,
      "loss": 0.8847,
      "step": 238600
    },
    {
      "epoch": 2.526442269520064,
      "grad_norm": 4.1621599197387695,
      "learning_rate": 3.737290916790176e-05,
      "loss": 0.9019,
      "step": 238650
    },
    {
      "epoch": 2.526971591300067,
      "grad_norm": 3.9777891635894775,
      "learning_rate": 3.737026254499259e-05,
      "loss": 0.8907,
      "step": 238700
    },
    {
      "epoch": 2.5275009130800705,
      "grad_norm": 3.7488667964935303,
      "learning_rate": 3.736761592208342e-05,
      "loss": 0.8828,
      "step": 238750
    },
    {
      "epoch": 2.528030234860074,
      "grad_norm": 3.553281545639038,
      "learning_rate": 3.736496929917426e-05,
      "loss": 0.8948,
      "step": 238800
    },
    {
      "epoch": 2.528559556640077,
      "grad_norm": 4.206274509429932,
      "learning_rate": 3.736232267626509e-05,
      "loss": 0.8916,
      "step": 238850
    },
    {
      "epoch": 2.5290888784200805,
      "grad_norm": 3.5869710445404053,
      "learning_rate": 3.735967605335592e-05,
      "loss": 0.868,
      "step": 238900
    },
    {
      "epoch": 2.5296182002000838,
      "grad_norm": 3.5368926525115967,
      "learning_rate": 3.735702943044675e-05,
      "loss": 0.8835,
      "step": 238950
    },
    {
      "epoch": 2.530147521980087,
      "grad_norm": 4.196878910064697,
      "learning_rate": 3.735438280753758e-05,
      "loss": 0.8632,
      "step": 239000
    },
    {
      "epoch": 2.530147521980087,
      "eval_loss": 0.6827030777931213,
      "eval_runtime": 46.5479,
      "eval_samples_per_second": 3607.682,
      "eval_steps_per_second": 450.976,
      "step": 239000
    },
    {
      "epoch": 2.53067684376009,
      "grad_norm": 3.894324779510498,
      "learning_rate": 3.735173618462842e-05,
      "loss": 0.8947,
      "step": 239050
    },
    {
      "epoch": 2.5312061655400937,
      "grad_norm": 3.634945869445801,
      "learning_rate": 3.7349089561719245e-05,
      "loss": 0.892,
      "step": 239100
    },
    {
      "epoch": 2.5317354873200966,
      "grad_norm": 3.9192557334899902,
      "learning_rate": 3.734644293881008e-05,
      "loss": 0.8944,
      "step": 239150
    },
    {
      "epoch": 2.5322648091001,
      "grad_norm": 3.998927593231201,
      "learning_rate": 3.734379631590091e-05,
      "loss": 0.8846,
      "step": 239200
    },
    {
      "epoch": 2.532794130880103,
      "grad_norm": 3.863248348236084,
      "learning_rate": 3.734114969299175e-05,
      "loss": 0.8936,
      "step": 239250
    },
    {
      "epoch": 2.5333234526601065,
      "grad_norm": 3.542916774749756,
      "learning_rate": 3.7338503070082574e-05,
      "loss": 0.8886,
      "step": 239300
    },
    {
      "epoch": 2.53385277444011,
      "grad_norm": 3.8724474906921387,
      "learning_rate": 3.733585644717341e-05,
      "loss": 0.8738,
      "step": 239350
    },
    {
      "epoch": 2.534382096220113,
      "grad_norm": 4.3376264572143555,
      "learning_rate": 3.733320982426424e-05,
      "loss": 0.8855,
      "step": 239400
    },
    {
      "epoch": 2.5349114180001164,
      "grad_norm": 3.9018170833587646,
      "learning_rate": 3.7330563201355077e-05,
      "loss": 0.9016,
      "step": 239450
    },
    {
      "epoch": 2.5354407397801197,
      "grad_norm": 3.94716739654541,
      "learning_rate": 3.7327916578445904e-05,
      "loss": 0.8713,
      "step": 239500
    },
    {
      "epoch": 2.5354407397801197,
      "eval_loss": 0.67972332239151,
      "eval_runtime": 46.535,
      "eval_samples_per_second": 3608.68,
      "eval_steps_per_second": 451.101,
      "step": 239500
    },
    {
      "epoch": 2.535970061560123,
      "grad_norm": 4.435242176055908,
      "learning_rate": 3.732526995553674e-05,
      "loss": 0.8793,
      "step": 239550
    },
    {
      "epoch": 2.5364993833401264,
      "grad_norm": 3.9854536056518555,
      "learning_rate": 3.732262333262757e-05,
      "loss": 0.8855,
      "step": 239600
    },
    {
      "epoch": 2.5370287051201297,
      "grad_norm": 3.849113941192627,
      "learning_rate": 3.73199767097184e-05,
      "loss": 0.8774,
      "step": 239650
    },
    {
      "epoch": 2.537558026900133,
      "grad_norm": 3.850229263305664,
      "learning_rate": 3.7317330086809233e-05,
      "loss": 0.905,
      "step": 239700
    },
    {
      "epoch": 2.5380873486801363,
      "grad_norm": 3.5682265758514404,
      "learning_rate": 3.731468346390006e-05,
      "loss": 0.8893,
      "step": 239750
    },
    {
      "epoch": 2.538616670460139,
      "grad_norm": 4.044775009155273,
      "learning_rate": 3.73120368409909e-05,
      "loss": 0.9141,
      "step": 239800
    },
    {
      "epoch": 2.539145992240143,
      "grad_norm": 4.0652570724487305,
      "learning_rate": 3.730939021808173e-05,
      "loss": 0.8906,
      "step": 239850
    },
    {
      "epoch": 2.539675314020146,
      "grad_norm": 3.9542276859283447,
      "learning_rate": 3.730674359517256e-05,
      "loss": 0.8819,
      "step": 239900
    },
    {
      "epoch": 2.540204635800149,
      "grad_norm": 3.8703181743621826,
      "learning_rate": 3.730409697226339e-05,
      "loss": 0.8941,
      "step": 239950
    },
    {
      "epoch": 2.5407339575801524,
      "grad_norm": 4.003397464752197,
      "learning_rate": 3.7301450349354225e-05,
      "loss": 0.8796,
      "step": 240000
    },
    {
      "epoch": 2.5407339575801524,
      "eval_loss": 0.6798405647277832,
      "eval_runtime": 46.5392,
      "eval_samples_per_second": 3608.354,
      "eval_steps_per_second": 451.06,
      "step": 240000
    },
    {
      "epoch": 2.5412632793601557,
      "grad_norm": 3.6152548789978027,
      "learning_rate": 3.729880372644506e-05,
      "loss": 0.8746,
      "step": 240050
    },
    {
      "epoch": 2.541792601140159,
      "grad_norm": 3.8299269676208496,
      "learning_rate": 3.7296157103535886e-05,
      "loss": 0.89,
      "step": 240100
    },
    {
      "epoch": 2.5423219229201623,
      "grad_norm": 3.8248229026794434,
      "learning_rate": 3.729351048062672e-05,
      "loss": 0.8776,
      "step": 240150
    },
    {
      "epoch": 2.5428512447001657,
      "grad_norm": 4.041599273681641,
      "learning_rate": 3.7290863857717554e-05,
      "loss": 0.8758,
      "step": 240200
    },
    {
      "epoch": 2.543380566480169,
      "grad_norm": 3.9088921546936035,
      "learning_rate": 3.728821723480839e-05,
      "loss": 0.9006,
      "step": 240250
    },
    {
      "epoch": 2.5439098882601723,
      "grad_norm": 3.7364256381988525,
      "learning_rate": 3.7285570611899216e-05,
      "loss": 0.8822,
      "step": 240300
    },
    {
      "epoch": 2.5444392100401756,
      "grad_norm": 3.641207695007324,
      "learning_rate": 3.728292398899005e-05,
      "loss": 0.8679,
      "step": 240350
    },
    {
      "epoch": 2.544968531820179,
      "grad_norm": 3.9421334266662598,
      "learning_rate": 3.728033029853907e-05,
      "loss": 0.8925,
      "step": 240400
    },
    {
      "epoch": 2.545497853600182,
      "grad_norm": 3.739126443862915,
      "learning_rate": 3.72776836756299e-05,
      "loss": 0.8748,
      "step": 240450
    },
    {
      "epoch": 2.5460271753801855,
      "grad_norm": 3.7526328563690186,
      "learning_rate": 3.727503705272073e-05,
      "loss": 0.8956,
      "step": 240500
    },
    {
      "epoch": 2.5460271753801855,
      "eval_loss": 0.6794722080230713,
      "eval_runtime": 46.5827,
      "eval_samples_per_second": 3604.986,
      "eval_steps_per_second": 450.639,
      "step": 240500
    },
    {
      "epoch": 2.5465564971601884,
      "grad_norm": 3.8346166610717773,
      "learning_rate": 3.727239042981156e-05,
      "loss": 0.8928,
      "step": 240550
    },
    {
      "epoch": 2.547085818940192,
      "grad_norm": 4.069080829620361,
      "learning_rate": 3.7269743806902394e-05,
      "loss": 0.8775,
      "step": 240600
    },
    {
      "epoch": 2.547615140720195,
      "grad_norm": 3.941742181777954,
      "learning_rate": 3.726709718399323e-05,
      "loss": 0.8902,
      "step": 240650
    },
    {
      "epoch": 2.5481444625001988,
      "grad_norm": 4.126028537750244,
      "learning_rate": 3.7264450561084055e-05,
      "loss": 0.8929,
      "step": 240700
    },
    {
      "epoch": 2.5486737842802016,
      "grad_norm": 4.155507564544678,
      "learning_rate": 3.726180393817489e-05,
      "loss": 0.8955,
      "step": 240750
    },
    {
      "epoch": 2.549203106060205,
      "grad_norm": 3.596433639526367,
      "learning_rate": 3.7259157315265724e-05,
      "loss": 0.8794,
      "step": 240800
    },
    {
      "epoch": 2.5497324278402083,
      "grad_norm": 3.954982042312622,
      "learning_rate": 3.725651069235656e-05,
      "loss": 0.9045,
      "step": 240850
    },
    {
      "epoch": 2.5502617496202116,
      "grad_norm": 3.7330682277679443,
      "learning_rate": 3.7253864069447385e-05,
      "loss": 0.8795,
      "step": 240900
    },
    {
      "epoch": 2.550791071400215,
      "grad_norm": 3.6929471492767334,
      "learning_rate": 3.725121744653822e-05,
      "loss": 0.8748,
      "step": 240950
    },
    {
      "epoch": 2.551320393180218,
      "grad_norm": 3.812983751296997,
      "learning_rate": 3.724857082362905e-05,
      "loss": 0.8786,
      "step": 241000
    },
    {
      "epoch": 2.551320393180218,
      "eval_loss": 0.6794060468673706,
      "eval_runtime": 46.5918,
      "eval_samples_per_second": 3604.281,
      "eval_steps_per_second": 450.551,
      "step": 241000
    },
    {
      "epoch": 2.5518497149602215,
      "grad_norm": 3.9479739665985107,
      "learning_rate": 3.724592420071988e-05,
      "loss": 0.8886,
      "step": 241050
    },
    {
      "epoch": 2.552379036740225,
      "grad_norm": 3.7688190937042236,
      "learning_rate": 3.7243277577810715e-05,
      "loss": 0.8844,
      "step": 241100
    },
    {
      "epoch": 2.552908358520228,
      "grad_norm": 4.022265911102295,
      "learning_rate": 3.724063095490154e-05,
      "loss": 0.8963,
      "step": 241150
    },
    {
      "epoch": 2.5534376803002314,
      "grad_norm": 4.002457141876221,
      "learning_rate": 3.723798433199238e-05,
      "loss": 0.8759,
      "step": 241200
    },
    {
      "epoch": 2.5539670020802347,
      "grad_norm": 3.9998955726623535,
      "learning_rate": 3.723533770908321e-05,
      "loss": 0.8895,
      "step": 241250
    },
    {
      "epoch": 2.5544963238602376,
      "grad_norm": 3.9400691986083984,
      "learning_rate": 3.7232691086174044e-05,
      "loss": 0.8838,
      "step": 241300
    },
    {
      "epoch": 2.5550256456402414,
      "grad_norm": 3.8744773864746094,
      "learning_rate": 3.723004446326487e-05,
      "loss": 0.8878,
      "step": 241350
    },
    {
      "epoch": 2.5555549674202442,
      "grad_norm": 3.95285964012146,
      "learning_rate": 3.722739784035571e-05,
      "loss": 0.8788,
      "step": 241400
    },
    {
      "epoch": 2.556084289200248,
      "grad_norm": 4.026309967041016,
      "learning_rate": 3.722475121744654e-05,
      "loss": 0.8684,
      "step": 241450
    },
    {
      "epoch": 2.556613610980251,
      "grad_norm": 4.0501275062561035,
      "learning_rate": 3.7222104594537374e-05,
      "loss": 0.8913,
      "step": 241500
    },
    {
      "epoch": 2.556613610980251,
      "eval_loss": 0.6784664988517761,
      "eval_runtime": 46.6158,
      "eval_samples_per_second": 3602.424,
      "eval_steps_per_second": 450.319,
      "step": 241500
    },
    {
      "epoch": 2.557142932760254,
      "grad_norm": 3.816793203353882,
      "learning_rate": 3.72194579716282e-05,
      "loss": 0.8818,
      "step": 241550
    },
    {
      "epoch": 2.5576722545402575,
      "grad_norm": 3.774827718734741,
      "learning_rate": 3.7216811348719035e-05,
      "loss": 0.8707,
      "step": 241600
    },
    {
      "epoch": 2.558201576320261,
      "grad_norm": 3.6530933380126953,
      "learning_rate": 3.721416472580987e-05,
      "loss": 0.875,
      "step": 241650
    },
    {
      "epoch": 2.558730898100264,
      "grad_norm": 3.7270820140838623,
      "learning_rate": 3.72115181029007e-05,
      "loss": 0.8865,
      "step": 241700
    },
    {
      "epoch": 2.5592602198802674,
      "grad_norm": 3.745091676712036,
      "learning_rate": 3.720887147999153e-05,
      "loss": 0.882,
      "step": 241750
    },
    {
      "epoch": 2.5597895416602707,
      "grad_norm": 3.832956552505493,
      "learning_rate": 3.7206224857082365e-05,
      "loss": 0.8753,
      "step": 241800
    },
    {
      "epoch": 2.560318863440274,
      "grad_norm": 3.7260582447052,
      "learning_rate": 3.72035782341732e-05,
      "loss": 0.8597,
      "step": 241850
    },
    {
      "epoch": 2.5608481852202774,
      "grad_norm": 3.9917685985565186,
      "learning_rate": 3.7200931611264026e-05,
      "loss": 0.882,
      "step": 241900
    },
    {
      "epoch": 2.5613775070002807,
      "grad_norm": 3.855708360671997,
      "learning_rate": 3.719828498835486e-05,
      "loss": 0.8652,
      "step": 241950
    },
    {
      "epoch": 2.561906828780284,
      "grad_norm": 3.84061336517334,
      "learning_rate": 3.7195638365445695e-05,
      "loss": 0.8706,
      "step": 242000
    },
    {
      "epoch": 2.561906828780284,
      "eval_loss": 0.6762969493865967,
      "eval_runtime": 46.6096,
      "eval_samples_per_second": 3602.906,
      "eval_steps_per_second": 450.379,
      "step": 242000
    },
    {
      "epoch": 2.562436150560287,
      "grad_norm": 4.049193382263184,
      "learning_rate": 3.719299174253653e-05,
      "loss": 0.8812,
      "step": 242050
    },
    {
      "epoch": 2.5629654723402906,
      "grad_norm": 3.9936363697052,
      "learning_rate": 3.7190345119627356e-05,
      "loss": 0.8823,
      "step": 242100
    },
    {
      "epoch": 2.5634947941202935,
      "grad_norm": 3.837219715118408,
      "learning_rate": 3.718769849671819e-05,
      "loss": 0.8834,
      "step": 242150
    },
    {
      "epoch": 2.564024115900297,
      "grad_norm": 4.190263271331787,
      "learning_rate": 3.7185051873809024e-05,
      "loss": 0.8742,
      "step": 242200
    },
    {
      "epoch": 2.5645534376803,
      "grad_norm": 4.025341510772705,
      "learning_rate": 3.718240525089985e-05,
      "loss": 0.8847,
      "step": 242250
    },
    {
      "epoch": 2.5650827594603034,
      "grad_norm": 3.8744921684265137,
      "learning_rate": 3.7179758627990686e-05,
      "loss": 0.8768,
      "step": 242300
    },
    {
      "epoch": 2.5656120812403067,
      "grad_norm": 3.922517776489258,
      "learning_rate": 3.717711200508151e-05,
      "loss": 0.8822,
      "step": 242350
    },
    {
      "epoch": 2.56614140302031,
      "grad_norm": 3.7057785987854004,
      "learning_rate": 3.7174465382172354e-05,
      "loss": 0.8675,
      "step": 242400
    },
    {
      "epoch": 2.5666707248003133,
      "grad_norm": 4.263016700744629,
      "learning_rate": 3.717192462417955e-05,
      "loss": 0.89,
      "step": 242450
    },
    {
      "epoch": 2.5672000465803166,
      "grad_norm": 3.677222490310669,
      "learning_rate": 3.716927800127038e-05,
      "loss": 0.874,
      "step": 242500
    },
    {
      "epoch": 2.5672000465803166,
      "eval_loss": 0.675236165523529,
      "eval_runtime": 46.6138,
      "eval_samples_per_second": 3602.582,
      "eval_steps_per_second": 450.339,
      "step": 242500
    },
    {
      "epoch": 2.56772936836032,
      "grad_norm": 3.7107439041137695,
      "learning_rate": 3.716663137836121e-05,
      "loss": 0.8877,
      "step": 242550
    },
    {
      "epoch": 2.5682586901403233,
      "grad_norm": 3.7332870960235596,
      "learning_rate": 3.7163984755452045e-05,
      "loss": 0.8762,
      "step": 242600
    },
    {
      "epoch": 2.5687880119203266,
      "grad_norm": 3.944603443145752,
      "learning_rate": 3.716133813254288e-05,
      "loss": 0.8964,
      "step": 242650
    },
    {
      "epoch": 2.56931733370033,
      "grad_norm": 3.922947645187378,
      "learning_rate": 3.7158691509633706e-05,
      "loss": 0.8902,
      "step": 242700
    },
    {
      "epoch": 2.569846655480333,
      "grad_norm": 4.105258464813232,
      "learning_rate": 3.715604488672454e-05,
      "loss": 0.878,
      "step": 242750
    },
    {
      "epoch": 2.570375977260336,
      "grad_norm": 3.964702606201172,
      "learning_rate": 3.7153398263815374e-05,
      "loss": 0.8866,
      "step": 242800
    },
    {
      "epoch": 2.57090529904034,
      "grad_norm": 3.611224412918091,
      "learning_rate": 3.715075164090621e-05,
      "loss": 0.8901,
      "step": 242850
    },
    {
      "epoch": 2.5714346208203427,
      "grad_norm": 3.865198850631714,
      "learning_rate": 3.7148105017997036e-05,
      "loss": 0.881,
      "step": 242900
    },
    {
      "epoch": 2.5719639426003464,
      "grad_norm": 3.8080124855041504,
      "learning_rate": 3.714545839508787e-05,
      "loss": 0.887,
      "step": 242950
    },
    {
      "epoch": 2.5724932643803493,
      "grad_norm": 3.9458701610565186,
      "learning_rate": 3.7142811772178704e-05,
      "loss": 0.8726,
      "step": 243000
    },
    {
      "epoch": 2.5724932643803493,
      "eval_loss": 0.6749057769775391,
      "eval_runtime": 46.6117,
      "eval_samples_per_second": 3602.744,
      "eval_steps_per_second": 450.359,
      "step": 243000
    },
    {
      "epoch": 2.5730225861603526,
      "grad_norm": 3.5805749893188477,
      "learning_rate": 3.714016514926953e-05,
      "loss": 0.8794,
      "step": 243050
    },
    {
      "epoch": 2.573551907940356,
      "grad_norm": 3.930391788482666,
      "learning_rate": 3.7137518526360365e-05,
      "loss": 0.8831,
      "step": 243100
    },
    {
      "epoch": 2.5740812297203592,
      "grad_norm": 3.9783740043640137,
      "learning_rate": 3.713487190345119e-05,
      "loss": 0.8823,
      "step": 243150
    },
    {
      "epoch": 2.5746105515003626,
      "grad_norm": 3.8398139476776123,
      "learning_rate": 3.7132225280542034e-05,
      "loss": 0.8709,
      "step": 243200
    },
    {
      "epoch": 2.575139873280366,
      "grad_norm": 4.060924053192139,
      "learning_rate": 3.712957865763286e-05,
      "loss": 0.8891,
      "step": 243250
    },
    {
      "epoch": 2.575669195060369,
      "grad_norm": 3.9139044284820557,
      "learning_rate": 3.7126932034723695e-05,
      "loss": 0.8909,
      "step": 243300
    },
    {
      "epoch": 2.5761985168403725,
      "grad_norm": 4.1306047439575195,
      "learning_rate": 3.712428541181452e-05,
      "loss": 0.8812,
      "step": 243350
    },
    {
      "epoch": 2.576727838620376,
      "grad_norm": 3.599611520767212,
      "learning_rate": 3.712163878890536e-05,
      "loss": 0.8878,
      "step": 243400
    },
    {
      "epoch": 2.577257160400379,
      "grad_norm": 3.72343373298645,
      "learning_rate": 3.711899216599619e-05,
      "loss": 0.877,
      "step": 243450
    },
    {
      "epoch": 2.5777864821803824,
      "grad_norm": 3.972108840942383,
      "learning_rate": 3.7116345543087025e-05,
      "loss": 0.8931,
      "step": 243500
    },
    {
      "epoch": 2.5777864821803824,
      "eval_loss": 0.6759874820709229,
      "eval_runtime": 46.634,
      "eval_samples_per_second": 3601.023,
      "eval_steps_per_second": 450.144,
      "step": 243500
    },
    {
      "epoch": 2.5783158039603853,
      "grad_norm": 3.816647529602051,
      "learning_rate": 3.711369892017785e-05,
      "loss": 0.8723,
      "step": 243550
    },
    {
      "epoch": 2.578845125740389,
      "grad_norm": 3.932359218597412,
      "learning_rate": 3.7111052297268686e-05,
      "loss": 0.886,
      "step": 243600
    },
    {
      "epoch": 2.579374447520392,
      "grad_norm": 3.877926826477051,
      "learning_rate": 3.710840567435952e-05,
      "loss": 0.8898,
      "step": 243650
    },
    {
      "epoch": 2.5799037693003957,
      "grad_norm": 3.872230291366577,
      "learning_rate": 3.710575905145035e-05,
      "loss": 0.8976,
      "step": 243700
    },
    {
      "epoch": 2.5804330910803985,
      "grad_norm": 3.801668167114258,
      "learning_rate": 3.710311242854118e-05,
      "loss": 0.8852,
      "step": 243750
    },
    {
      "epoch": 2.580962412860402,
      "grad_norm": 3.6602365970611572,
      "learning_rate": 3.7100465805632016e-05,
      "loss": 0.8772,
      "step": 243800
    },
    {
      "epoch": 2.581491734640405,
      "grad_norm": 4.2777180671691895,
      "learning_rate": 3.709781918272285e-05,
      "loss": 0.862,
      "step": 243850
    },
    {
      "epoch": 2.5820210564204085,
      "grad_norm": 3.9156761169433594,
      "learning_rate": 3.709517255981368e-05,
      "loss": 0.8575,
      "step": 243900
    },
    {
      "epoch": 2.582550378200412,
      "grad_norm": 3.9618258476257324,
      "learning_rate": 3.709252593690451e-05,
      "loss": 0.8797,
      "step": 243950
    },
    {
      "epoch": 2.583079699980415,
      "grad_norm": 4.026359558105469,
      "learning_rate": 3.7089879313995345e-05,
      "loss": 0.8778,
      "step": 244000
    },
    {
      "epoch": 2.583079699980415,
      "eval_loss": 0.6749072670936584,
      "eval_runtime": 46.5735,
      "eval_samples_per_second": 3605.695,
      "eval_steps_per_second": 450.728,
      "step": 244000
    },
    {
      "epoch": 2.5836090217604184,
      "grad_norm": 3.910691499710083,
      "learning_rate": 3.708723269108618e-05,
      "loss": 0.8801,
      "step": 244050
    },
    {
      "epoch": 2.5841383435404217,
      "grad_norm": 4.020809173583984,
      "learning_rate": 3.708458606817701e-05,
      "loss": 0.8646,
      "step": 244100
    },
    {
      "epoch": 2.584667665320425,
      "grad_norm": 3.7281723022460938,
      "learning_rate": 3.708193944526784e-05,
      "loss": 0.8803,
      "step": 244150
    },
    {
      "epoch": 2.5851969871004283,
      "grad_norm": 4.052804470062256,
      "learning_rate": 3.7079292822358675e-05,
      "loss": 0.8844,
      "step": 244200
    },
    {
      "epoch": 2.5857263088804316,
      "grad_norm": 3.982302665710449,
      "learning_rate": 3.70766461994495e-05,
      "loss": 0.8864,
      "step": 244250
    },
    {
      "epoch": 2.5862556306604345,
      "grad_norm": 4.054893493652344,
      "learning_rate": 3.7073999576540336e-05,
      "loss": 0.8798,
      "step": 244300
    },
    {
      "epoch": 2.5867849524404383,
      "grad_norm": 4.160971164703369,
      "learning_rate": 3.7071352953631164e-05,
      "loss": 0.88,
      "step": 244350
    },
    {
      "epoch": 2.587314274220441,
      "grad_norm": 3.9720675945281982,
      "learning_rate": 3.7068706330722005e-05,
      "loss": 0.8852,
      "step": 244400
    },
    {
      "epoch": 2.587843596000445,
      "grad_norm": 4.023605823516846,
      "learning_rate": 3.706605970781283e-05,
      "loss": 0.8796,
      "step": 244450
    },
    {
      "epoch": 2.5883729177804478,
      "grad_norm": 3.2720947265625,
      "learning_rate": 3.7063413084903666e-05,
      "loss": 0.876,
      "step": 244500
    },
    {
      "epoch": 2.5883729177804478,
      "eval_loss": 0.6742453575134277,
      "eval_runtime": 46.6249,
      "eval_samples_per_second": 3601.722,
      "eval_steps_per_second": 450.231,
      "step": 244500
    },
    {
      "epoch": 2.588902239560451,
      "grad_norm": 4.0598907470703125,
      "learning_rate": 3.706076646199449e-05,
      "loss": 0.8867,
      "step": 244550
    },
    {
      "epoch": 2.5894315613404544,
      "grad_norm": 3.8983469009399414,
      "learning_rate": 3.7058119839085334e-05,
      "loss": 0.8768,
      "step": 244600
    },
    {
      "epoch": 2.5899608831204577,
      "grad_norm": 3.914074659347534,
      "learning_rate": 3.705547321617616e-05,
      "loss": 0.882,
      "step": 244650
    },
    {
      "epoch": 2.590490204900461,
      "grad_norm": 3.7079596519470215,
      "learning_rate": 3.7052826593266996e-05,
      "loss": 0.8848,
      "step": 244700
    },
    {
      "epoch": 2.5910195266804643,
      "grad_norm": 4.15120267868042,
      "learning_rate": 3.705017997035782e-05,
      "loss": 0.8628,
      "step": 244750
    },
    {
      "epoch": 2.5915488484604676,
      "grad_norm": 4.113774299621582,
      "learning_rate": 3.704753334744866e-05,
      "loss": 0.8709,
      "step": 244800
    },
    {
      "epoch": 2.592078170240471,
      "grad_norm": 4.296744346618652,
      "learning_rate": 3.704488672453949e-05,
      "loss": 0.8642,
      "step": 244850
    },
    {
      "epoch": 2.5926074920204742,
      "grad_norm": 4.232182502746582,
      "learning_rate": 3.704224010163032e-05,
      "loss": 0.9008,
      "step": 244900
    },
    {
      "epoch": 2.5931368138004776,
      "grad_norm": 4.042727470397949,
      "learning_rate": 3.703959347872115e-05,
      "loss": 0.8762,
      "step": 244950
    },
    {
      "epoch": 2.593666135580481,
      "grad_norm": 3.648254871368408,
      "learning_rate": 3.7036946855811987e-05,
      "loss": 0.8796,
      "step": 245000
    },
    {
      "epoch": 2.593666135580481,
      "eval_loss": 0.6719593405723572,
      "eval_runtime": 46.5597,
      "eval_samples_per_second": 3606.765,
      "eval_steps_per_second": 450.862,
      "step": 245000
    },
    {
      "epoch": 2.5941954573604837,
      "grad_norm": 4.245842456817627,
      "learning_rate": 3.703430023290282e-05,
      "loss": 0.8864,
      "step": 245050
    },
    {
      "epoch": 2.5947247791404875,
      "grad_norm": 3.6364808082580566,
      "learning_rate": 3.703165360999365e-05,
      "loss": 0.8757,
      "step": 245100
    },
    {
      "epoch": 2.5952541009204904,
      "grad_norm": 3.994206666946411,
      "learning_rate": 3.702900698708448e-05,
      "loss": 0.8753,
      "step": 245150
    },
    {
      "epoch": 2.595783422700494,
      "grad_norm": 3.4259018898010254,
      "learning_rate": 3.7026360364175316e-05,
      "loss": 0.8827,
      "step": 245200
    },
    {
      "epoch": 2.596312744480497,
      "grad_norm": 3.83695125579834,
      "learning_rate": 3.702371374126615e-05,
      "loss": 0.8848,
      "step": 245250
    },
    {
      "epoch": 2.5968420662605003,
      "grad_norm": 3.957608461380005,
      "learning_rate": 3.702106711835698e-05,
      "loss": 0.8783,
      "step": 245300
    },
    {
      "epoch": 2.5973713880405036,
      "grad_norm": 4.125570774078369,
      "learning_rate": 3.701842049544781e-05,
      "loss": 0.8741,
      "step": 245350
    },
    {
      "epoch": 2.597900709820507,
      "grad_norm": 3.996986150741577,
      "learning_rate": 3.7015773872538646e-05,
      "loss": 0.8863,
      "step": 245400
    },
    {
      "epoch": 2.5984300316005102,
      "grad_norm": 4.020756244659424,
      "learning_rate": 3.701318018208766e-05,
      "loss": 0.8923,
      "step": 245450
    },
    {
      "epoch": 2.5989593533805135,
      "grad_norm": 4.091188430786133,
      "learning_rate": 3.701053355917849e-05,
      "loss": 0.8909,
      "step": 245500
    },
    {
      "epoch": 2.5989593533805135,
      "eval_loss": 0.6715134382247925,
      "eval_runtime": 46.6843,
      "eval_samples_per_second": 3597.143,
      "eval_steps_per_second": 449.659,
      "step": 245500
    },
    {
      "epoch": 2.599488675160517,
      "grad_norm": 3.6471517086029053,
      "learning_rate": 3.700788693626932e-05,
      "loss": 0.8816,
      "step": 245550
    },
    {
      "epoch": 2.60001799694052,
      "grad_norm": 4.031339645385742,
      "learning_rate": 3.7005240313360156e-05,
      "loss": 0.8868,
      "step": 245600
    },
    {
      "epoch": 2.6005473187205235,
      "grad_norm": 3.808177947998047,
      "learning_rate": 3.700259369045099e-05,
      "loss": 0.886,
      "step": 245650
    },
    {
      "epoch": 2.601076640500527,
      "grad_norm": 4.027670860290527,
      "learning_rate": 3.699994706754182e-05,
      "loss": 0.8859,
      "step": 245700
    },
    {
      "epoch": 2.60160596228053,
      "grad_norm": 3.8924944400787354,
      "learning_rate": 3.699730044463265e-05,
      "loss": 0.8812,
      "step": 245750
    },
    {
      "epoch": 2.6021352840605334,
      "grad_norm": 3.7407984733581543,
      "learning_rate": 3.6994653821723486e-05,
      "loss": 0.8666,
      "step": 245800
    },
    {
      "epoch": 2.6026646058405367,
      "grad_norm": 4.0442376136779785,
      "learning_rate": 3.699200719881431e-05,
      "loss": 0.8736,
      "step": 245850
    },
    {
      "epoch": 2.6031939276205396,
      "grad_norm": 4.086638450622559,
      "learning_rate": 3.698936057590515e-05,
      "loss": 0.8773,
      "step": 245900
    },
    {
      "epoch": 2.6037232494005433,
      "grad_norm": 3.981050491333008,
      "learning_rate": 3.6986713952995974e-05,
      "loss": 0.8807,
      "step": 245950
    },
    {
      "epoch": 2.604252571180546,
      "grad_norm": 4.345855712890625,
      "learning_rate": 3.6984067330086815e-05,
      "loss": 0.8734,
      "step": 246000
    },
    {
      "epoch": 2.604252571180546,
      "eval_loss": 0.6691028475761414,
      "eval_runtime": 46.5471,
      "eval_samples_per_second": 3607.747,
      "eval_steps_per_second": 450.984,
      "step": 246000
    },
    {
      "epoch": 2.6047818929605495,
      "grad_norm": 4.026812553405762,
      "learning_rate": 3.698142070717764e-05,
      "loss": 0.8565,
      "step": 246050
    },
    {
      "epoch": 2.605311214740553,
      "grad_norm": 3.8472824096679688,
      "learning_rate": 3.697877408426848e-05,
      "loss": 0.8775,
      "step": 246100
    },
    {
      "epoch": 2.605840536520556,
      "grad_norm": 4.097729682922363,
      "learning_rate": 3.6976127461359304e-05,
      "loss": 0.8709,
      "step": 246150
    },
    {
      "epoch": 2.6063698583005595,
      "grad_norm": 3.9659130573272705,
      "learning_rate": 3.6973480838450145e-05,
      "loss": 0.871,
      "step": 246200
    },
    {
      "epoch": 2.6068991800805628,
      "grad_norm": 4.116076469421387,
      "learning_rate": 3.697083421554097e-05,
      "loss": 0.8699,
      "step": 246250
    },
    {
      "epoch": 2.607428501860566,
      "grad_norm": 4.349303722381592,
      "learning_rate": 3.6968187592631806e-05,
      "loss": 0.8816,
      "step": 246300
    },
    {
      "epoch": 2.6079578236405694,
      "grad_norm": 4.1089558601379395,
      "learning_rate": 3.6965540969722634e-05,
      "loss": 0.8614,
      "step": 246350
    },
    {
      "epoch": 2.6084871454205727,
      "grad_norm": 3.890619993209839,
      "learning_rate": 3.696289434681347e-05,
      "loss": 0.8596,
      "step": 246400
    },
    {
      "epoch": 2.609016467200576,
      "grad_norm": 4.045241832733154,
      "learning_rate": 3.69602477239043e-05,
      "loss": 0.8784,
      "step": 246450
    },
    {
      "epoch": 2.6095457889805793,
      "grad_norm": 3.9714105129241943,
      "learning_rate": 3.695760110099513e-05,
      "loss": 0.8825,
      "step": 246500
    },
    {
      "epoch": 2.6095457889805793,
      "eval_loss": 0.6698181629180908,
      "eval_runtime": 46.5892,
      "eval_samples_per_second": 3604.48,
      "eval_steps_per_second": 450.576,
      "step": 246500
    },
    {
      "epoch": 2.6100751107605826,
      "grad_norm": 4.313265800476074,
      "learning_rate": 3.695495447808596e-05,
      "loss": 0.8721,
      "step": 246550
    },
    {
      "epoch": 2.610604432540586,
      "grad_norm": 4.028119087219238,
      "learning_rate": 3.69523078551768e-05,
      "loss": 0.8802,
      "step": 246600
    },
    {
      "epoch": 2.611133754320589,
      "grad_norm": 3.7332401275634766,
      "learning_rate": 3.694966123226763e-05,
      "loss": 0.8875,
      "step": 246650
    },
    {
      "epoch": 2.6116630761005926,
      "grad_norm": 3.9886505603790283,
      "learning_rate": 3.694701460935846e-05,
      "loss": 0.897,
      "step": 246700
    },
    {
      "epoch": 2.6121923978805954,
      "grad_norm": 4.059398174285889,
      "learning_rate": 3.694436798644929e-05,
      "loss": 0.8841,
      "step": 246750
    },
    {
      "epoch": 2.6127217196605987,
      "grad_norm": 3.8570377826690674,
      "learning_rate": 3.694172136354013e-05,
      "loss": 0.8621,
      "step": 246800
    },
    {
      "epoch": 2.613251041440602,
      "grad_norm": 3.500274181365967,
      "learning_rate": 3.693907474063096e-05,
      "loss": 0.8708,
      "step": 246850
    },
    {
      "epoch": 2.6137803632206054,
      "grad_norm": 4.064943313598633,
      "learning_rate": 3.693642811772179e-05,
      "loss": 0.8656,
      "step": 246900
    },
    {
      "epoch": 2.6143096850006087,
      "grad_norm": 3.651135206222534,
      "learning_rate": 3.693378149481262e-05,
      "loss": 0.8835,
      "step": 246950
    },
    {
      "epoch": 2.614839006780612,
      "grad_norm": 3.7701897621154785,
      "learning_rate": 3.693113487190346e-05,
      "loss": 0.8933,
      "step": 247000
    },
    {
      "epoch": 2.614839006780612,
      "eval_loss": 0.6702319979667664,
      "eval_runtime": 46.5745,
      "eval_samples_per_second": 3605.621,
      "eval_steps_per_second": 450.719,
      "step": 247000
    },
    {
      "epoch": 2.6153683285606153,
      "grad_norm": 3.5029115676879883,
      "learning_rate": 3.6928488248994284e-05,
      "loss": 0.889,
      "step": 247050
    },
    {
      "epoch": 2.6158976503406186,
      "grad_norm": 3.7665181159973145,
      "learning_rate": 3.692584162608512e-05,
      "loss": 0.8658,
      "step": 247100
    },
    {
      "epoch": 2.616426972120622,
      "grad_norm": 3.8275575637817383,
      "learning_rate": 3.6923195003175945e-05,
      "loss": 0.8816,
      "step": 247150
    },
    {
      "epoch": 2.6169562939006252,
      "grad_norm": 4.042138576507568,
      "learning_rate": 3.6920548380266786e-05,
      "loss": 0.8878,
      "step": 247200
    },
    {
      "epoch": 2.6174856156806285,
      "grad_norm": 4.1748247146606445,
      "learning_rate": 3.6917901757357614e-05,
      "loss": 0.8778,
      "step": 247250
    },
    {
      "epoch": 2.618014937460632,
      "grad_norm": 3.7295360565185547,
      "learning_rate": 3.691525513444845e-05,
      "loss": 0.8549,
      "step": 247300
    },
    {
      "epoch": 2.618544259240635,
      "grad_norm": 3.853736400604248,
      "learning_rate": 3.6912608511539275e-05,
      "loss": 0.8765,
      "step": 247350
    },
    {
      "epoch": 2.619073581020638,
      "grad_norm": 3.8814921379089355,
      "learning_rate": 3.690996188863011e-05,
      "loss": 0.8784,
      "step": 247400
    },
    {
      "epoch": 2.619602902800642,
      "grad_norm": 3.725567102432251,
      "learning_rate": 3.690731526572094e-05,
      "loss": 0.8742,
      "step": 247450
    },
    {
      "epoch": 2.6201322245806447,
      "grad_norm": 3.9335005283355713,
      "learning_rate": 3.690466864281177e-05,
      "loss": 0.8649,
      "step": 247500
    },
    {
      "epoch": 2.6201322245806447,
      "eval_loss": 0.667077362537384,
      "eval_runtime": 46.5468,
      "eval_samples_per_second": 3607.765,
      "eval_steps_per_second": 450.987,
      "step": 247500
    },
    {
      "epoch": 2.620661546360648,
      "grad_norm": 4.119165420532227,
      "learning_rate": 3.6902022019902605e-05,
      "loss": 0.8844,
      "step": 247550
    },
    {
      "epoch": 2.6211908681406513,
      "grad_norm": 3.739169120788574,
      "learning_rate": 3.6899428329451626e-05,
      "loss": 0.8706,
      "step": 247600
    },
    {
      "epoch": 2.6217201899206546,
      "grad_norm": 4.125152111053467,
      "learning_rate": 3.6896781706542453e-05,
      "loss": 0.8781,
      "step": 247650
    },
    {
      "epoch": 2.622249511700658,
      "grad_norm": 3.7375617027282715,
      "learning_rate": 3.689413508363329e-05,
      "loss": 0.8636,
      "step": 247700
    },
    {
      "epoch": 2.622778833480661,
      "grad_norm": 3.465188980102539,
      "learning_rate": 3.6891488460724115e-05,
      "loss": 0.8634,
      "step": 247750
    },
    {
      "epoch": 2.6233081552606645,
      "grad_norm": 3.796473503112793,
      "learning_rate": 3.6888841837814956e-05,
      "loss": 0.879,
      "step": 247800
    },
    {
      "epoch": 2.623837477040668,
      "grad_norm": 4.043431282043457,
      "learning_rate": 3.688619521490578e-05,
      "loss": 0.8724,
      "step": 247850
    },
    {
      "epoch": 2.624366798820671,
      "grad_norm": 4.185113906860352,
      "learning_rate": 3.688354859199662e-05,
      "loss": 0.864,
      "step": 247900
    },
    {
      "epoch": 2.6248961206006745,
      "grad_norm": 4.143582820892334,
      "learning_rate": 3.6880901969087445e-05,
      "loss": 0.8671,
      "step": 247950
    },
    {
      "epoch": 2.6254254423806778,
      "grad_norm": 3.839740037918091,
      "learning_rate": 3.687825534617828e-05,
      "loss": 0.8694,
      "step": 248000
    },
    {
      "epoch": 2.6254254423806778,
      "eval_loss": 0.6659427285194397,
      "eval_runtime": 46.5965,
      "eval_samples_per_second": 3603.919,
      "eval_steps_per_second": 450.506,
      "step": 248000
    },
    {
      "epoch": 2.625954764160681,
      "grad_norm": 4.127933502197266,
      "learning_rate": 3.687560872326911e-05,
      "loss": 0.8869,
      "step": 248050
    },
    {
      "epoch": 2.6264840859406844,
      "grad_norm": 3.584935426712036,
      "learning_rate": 3.687296210035994e-05,
      "loss": 0.8653,
      "step": 248100
    },
    {
      "epoch": 2.6270134077206873,
      "grad_norm": 4.14705228805542,
      "learning_rate": 3.6870315477450774e-05,
      "loss": 0.8842,
      "step": 248150
    },
    {
      "epoch": 2.627542729500691,
      "grad_norm": 3.6943726539611816,
      "learning_rate": 3.686766885454161e-05,
      "loss": 0.8738,
      "step": 248200
    },
    {
      "epoch": 2.628072051280694,
      "grad_norm": 3.7406044006347656,
      "learning_rate": 3.686502223163244e-05,
      "loss": 0.8764,
      "step": 248250
    },
    {
      "epoch": 2.628601373060697,
      "grad_norm": 3.616217851638794,
      "learning_rate": 3.686237560872327e-05,
      "loss": 0.8853,
      "step": 248300
    },
    {
      "epoch": 2.6291306948407005,
      "grad_norm": 4.421919822692871,
      "learning_rate": 3.6859728985814104e-05,
      "loss": 0.8751,
      "step": 248350
    },
    {
      "epoch": 2.629660016620704,
      "grad_norm": 3.9412715435028076,
      "learning_rate": 3.685708236290494e-05,
      "loss": 0.8655,
      "step": 248400
    },
    {
      "epoch": 2.630189338400707,
      "grad_norm": 4.058474063873291,
      "learning_rate": 3.6854435739995765e-05,
      "loss": 0.867,
      "step": 248450
    },
    {
      "epoch": 2.6307186601807104,
      "grad_norm": 3.8175318241119385,
      "learning_rate": 3.68517891170866e-05,
      "loss": 0.8797,
      "step": 248500
    },
    {
      "epoch": 2.6307186601807104,
      "eval_loss": 0.6691663861274719,
      "eval_runtime": 46.7383,
      "eval_samples_per_second": 3592.983,
      "eval_steps_per_second": 449.139,
      "step": 248500
    },
    {
      "epoch": 2.6312479819607137,
      "grad_norm": 3.7073895931243896,
      "learning_rate": 3.684914249417743e-05,
      "loss": 0.8609,
      "step": 248550
    },
    {
      "epoch": 2.631777303740717,
      "grad_norm": 4.240307331085205,
      "learning_rate": 3.684649587126827e-05,
      "loss": 0.8603,
      "step": 248600
    },
    {
      "epoch": 2.6323066255207204,
      "grad_norm": 3.7205514907836914,
      "learning_rate": 3.6843849248359095e-05,
      "loss": 0.8815,
      "step": 248650
    },
    {
      "epoch": 2.6328359473007237,
      "grad_norm": 3.8856072425842285,
      "learning_rate": 3.684120262544993e-05,
      "loss": 0.8829,
      "step": 248700
    },
    {
      "epoch": 2.633365269080727,
      "grad_norm": 3.858269214630127,
      "learning_rate": 3.6838556002540756e-05,
      "loss": 0.8797,
      "step": 248750
    },
    {
      "epoch": 2.6338945908607303,
      "grad_norm": 3.636321783065796,
      "learning_rate": 3.68359093796316e-05,
      "loss": 0.8715,
      "step": 248800
    },
    {
      "epoch": 2.6344239126407336,
      "grad_norm": 4.262706279754639,
      "learning_rate": 3.6833262756722424e-05,
      "loss": 0.8747,
      "step": 248850
    },
    {
      "epoch": 2.6349532344207365,
      "grad_norm": 3.842533826828003,
      "learning_rate": 3.683061613381326e-05,
      "loss": 0.8632,
      "step": 248900
    },
    {
      "epoch": 2.6354825562007402,
      "grad_norm": 4.015936851501465,
      "learning_rate": 3.6827969510904086e-05,
      "loss": 0.8647,
      "step": 248950
    },
    {
      "epoch": 2.636011877980743,
      "grad_norm": 3.6072068214416504,
      "learning_rate": 3.682532288799492e-05,
      "loss": 0.8689,
      "step": 249000
    },
    {
      "epoch": 2.636011877980743,
      "eval_loss": 0.6667828559875488,
      "eval_runtime": 46.5357,
      "eval_samples_per_second": 3608.625,
      "eval_steps_per_second": 451.094,
      "step": 249000
    },
    {
      "epoch": 2.6365411997607464,
      "grad_norm": 4.1842780113220215,
      "learning_rate": 3.6822676265085754e-05,
      "loss": 0.8796,
      "step": 249050
    },
    {
      "epoch": 2.6370705215407497,
      "grad_norm": 3.7655601501464844,
      "learning_rate": 3.682002964217658e-05,
      "loss": 0.8675,
      "step": 249100
    },
    {
      "epoch": 2.637599843320753,
      "grad_norm": 3.9317853450775146,
      "learning_rate": 3.6817383019267415e-05,
      "loss": 0.8829,
      "step": 249150
    },
    {
      "epoch": 2.6381291651007563,
      "grad_norm": 4.279160022735596,
      "learning_rate": 3.681473639635824e-05,
      "loss": 0.8765,
      "step": 249200
    },
    {
      "epoch": 2.6386584868807597,
      "grad_norm": 4.177915096282959,
      "learning_rate": 3.6812089773449084e-05,
      "loss": 0.876,
      "step": 249250
    },
    {
      "epoch": 2.639187808660763,
      "grad_norm": 3.9320642948150635,
      "learning_rate": 3.680944315053991e-05,
      "loss": 0.8785,
      "step": 249300
    },
    {
      "epoch": 2.6397171304407663,
      "grad_norm": 4.288302421569824,
      "learning_rate": 3.6806796527630745e-05,
      "loss": 0.8598,
      "step": 249350
    },
    {
      "epoch": 2.6402464522207696,
      "grad_norm": 4.089962959289551,
      "learning_rate": 3.680414990472157e-05,
      "loss": 0.8757,
      "step": 249400
    },
    {
      "epoch": 2.640775774000773,
      "grad_norm": 4.103667736053467,
      "learning_rate": 3.680150328181241e-05,
      "loss": 0.8883,
      "step": 249450
    },
    {
      "epoch": 2.641305095780776,
      "grad_norm": 3.881364107131958,
      "learning_rate": 3.679885665890324e-05,
      "loss": 0.8593,
      "step": 249500
    },
    {
      "epoch": 2.641305095780776,
      "eval_loss": 0.662899911403656,
      "eval_runtime": 46.7775,
      "eval_samples_per_second": 3589.975,
      "eval_steps_per_second": 448.763,
      "step": 249500
    },
    {
      "epoch": 2.6418344175607795,
      "grad_norm": 3.8723132610321045,
      "learning_rate": 3.6796210035994075e-05,
      "loss": 0.883,
      "step": 249550
    },
    {
      "epoch": 2.642363739340783,
      "grad_norm": 3.4400460720062256,
      "learning_rate": 3.67935634130849e-05,
      "loss": 0.8683,
      "step": 249600
    },
    {
      "epoch": 2.6428930611207857,
      "grad_norm": 4.29324197769165,
      "learning_rate": 3.6790916790175736e-05,
      "loss": 0.8762,
      "step": 249650
    },
    {
      "epoch": 2.6434223829007895,
      "grad_norm": 3.6190648078918457,
      "learning_rate": 3.678827016726657e-05,
      "loss": 0.8579,
      "step": 249700
    },
    {
      "epoch": 2.6439517046807923,
      "grad_norm": 3.8948075771331787,
      "learning_rate": 3.67856235443574e-05,
      "loss": 0.8562,
      "step": 249750
    },
    {
      "epoch": 2.6444810264607956,
      "grad_norm": 3.929034471511841,
      "learning_rate": 3.678297692144823e-05,
      "loss": 0.8737,
      "step": 249800
    },
    {
      "epoch": 2.645010348240799,
      "grad_norm": 4.208181381225586,
      "learning_rate": 3.6780330298539066e-05,
      "loss": 0.8738,
      "step": 249850
    },
    {
      "epoch": 2.6455396700208023,
      "grad_norm": 3.7441329956054688,
      "learning_rate": 3.67776836756299e-05,
      "loss": 0.8759,
      "step": 249900
    },
    {
      "epoch": 2.6460689918008056,
      "grad_norm": 3.7883739471435547,
      "learning_rate": 3.677503705272073e-05,
      "loss": 0.8834,
      "step": 249950
    },
    {
      "epoch": 2.646598313580809,
      "grad_norm": 3.6782777309417725,
      "learning_rate": 3.677239042981156e-05,
      "loss": 0.8817,
      "step": 250000
    },
    {
      "epoch": 2.646598313580809,
      "eval_loss": 0.6681782007217407,
      "eval_runtime": 46.7073,
      "eval_samples_per_second": 3595.369,
      "eval_steps_per_second": 449.437,
      "step": 250000
    },
    {
      "epoch": 2.647127635360812,
      "grad_norm": 4.10154914855957,
      "learning_rate": 3.6769743806902395e-05,
      "loss": 0.8673,
      "step": 250050
    },
    {
      "epoch": 2.6476569571408155,
      "grad_norm": 3.737039089202881,
      "learning_rate": 3.676709718399323e-05,
      "loss": 0.8862,
      "step": 250100
    },
    {
      "epoch": 2.648186278920819,
      "grad_norm": 3.985438108444214,
      "learning_rate": 3.676445056108406e-05,
      "loss": 0.8688,
      "step": 250150
    },
    {
      "epoch": 2.648715600700822,
      "grad_norm": 3.803253650665283,
      "learning_rate": 3.676180393817489e-05,
      "loss": 0.8741,
      "step": 250200
    },
    {
      "epoch": 2.6492449224808254,
      "grad_norm": 3.977245807647705,
      "learning_rate": 3.6759157315265725e-05,
      "loss": 0.8622,
      "step": 250250
    },
    {
      "epoch": 2.6497742442608287,
      "grad_norm": 3.6964685916900635,
      "learning_rate": 3.675656362481474e-05,
      "loss": 0.8691,
      "step": 250300
    },
    {
      "epoch": 2.650303566040832,
      "grad_norm": 4.025739669799805,
      "learning_rate": 3.675391700190557e-05,
      "loss": 0.8632,
      "step": 250350
    },
    {
      "epoch": 2.650832887820835,
      "grad_norm": 3.6583445072174072,
      "learning_rate": 3.67512703789964e-05,
      "loss": 0.8889,
      "step": 250400
    },
    {
      "epoch": 2.6513622096008387,
      "grad_norm": 4.068045616149902,
      "learning_rate": 3.6748623756087235e-05,
      "loss": 0.875,
      "step": 250450
    },
    {
      "epoch": 2.6518915313808415,
      "grad_norm": 3.9231081008911133,
      "learning_rate": 3.674597713317807e-05,
      "loss": 0.8671,
      "step": 250500
    },
    {
      "epoch": 2.6518915313808415,
      "eval_loss": 0.6634775996208191,
      "eval_runtime": 46.6434,
      "eval_samples_per_second": 3600.293,
      "eval_steps_per_second": 450.053,
      "step": 250500
    },
    {
      "epoch": 2.652420853160845,
      "grad_norm": 4.0560197830200195,
      "learning_rate": 3.67433305102689e-05,
      "loss": 0.8757,
      "step": 250550
    },
    {
      "epoch": 2.652950174940848,
      "grad_norm": 3.7439944744110107,
      "learning_rate": 3.674068388735973e-05,
      "loss": 0.8807,
      "step": 250600
    },
    {
      "epoch": 2.6534794967208515,
      "grad_norm": 3.8562142848968506,
      "learning_rate": 3.6738037264450565e-05,
      "loss": 0.8663,
      "step": 250650
    },
    {
      "epoch": 2.654008818500855,
      "grad_norm": 3.8555092811584473,
      "learning_rate": 3.673539064154139e-05,
      "loss": 0.8796,
      "step": 250700
    },
    {
      "epoch": 2.654538140280858,
      "grad_norm": 3.8547704219818115,
      "learning_rate": 3.6732744018632226e-05,
      "loss": 0.8779,
      "step": 250750
    },
    {
      "epoch": 2.6550674620608614,
      "grad_norm": 4.148958683013916,
      "learning_rate": 3.6730097395723054e-05,
      "loss": 0.8501,
      "step": 250800
    },
    {
      "epoch": 2.6555967838408647,
      "grad_norm": 3.701918601989746,
      "learning_rate": 3.6727450772813895e-05,
      "loss": 0.8692,
      "step": 250850
    },
    {
      "epoch": 2.656126105620868,
      "grad_norm": 3.4639997482299805,
      "learning_rate": 3.672480414990472e-05,
      "loss": 0.8561,
      "step": 250900
    },
    {
      "epoch": 2.6566554274008713,
      "grad_norm": 4.004690170288086,
      "learning_rate": 3.6722157526995556e-05,
      "loss": 0.8731,
      "step": 250950
    },
    {
      "epoch": 2.6571847491808747,
      "grad_norm": 4.413210868835449,
      "learning_rate": 3.671951090408638e-05,
      "loss": 0.8689,
      "step": 251000
    },
    {
      "epoch": 2.6571847491808747,
      "eval_loss": 0.6603981852531433,
      "eval_runtime": 46.5756,
      "eval_samples_per_second": 3605.534,
      "eval_steps_per_second": 450.708,
      "step": 251000
    },
    {
      "epoch": 2.657714070960878,
      "grad_norm": 4.108975887298584,
      "learning_rate": 3.6716864281177224e-05,
      "loss": 0.8746,
      "step": 251050
    },
    {
      "epoch": 2.6582433927408813,
      "grad_norm": 3.858107566833496,
      "learning_rate": 3.671421765826805e-05,
      "loss": 0.8841,
      "step": 251100
    },
    {
      "epoch": 2.658772714520884,
      "grad_norm": 3.662663221359253,
      "learning_rate": 3.6711571035358886e-05,
      "loss": 0.8798,
      "step": 251150
    },
    {
      "epoch": 2.659302036300888,
      "grad_norm": 3.8824269771575928,
      "learning_rate": 3.670892441244971e-05,
      "loss": 0.8657,
      "step": 251200
    },
    {
      "epoch": 2.6598313580808908,
      "grad_norm": 3.987352132797241,
      "learning_rate": 3.670627778954055e-05,
      "loss": 0.876,
      "step": 251250
    },
    {
      "epoch": 2.660360679860894,
      "grad_norm": 4.222529411315918,
      "learning_rate": 3.670363116663138e-05,
      "loss": 0.869,
      "step": 251300
    },
    {
      "epoch": 2.6608900016408974,
      "grad_norm": 3.7652604579925537,
      "learning_rate": 3.670098454372221e-05,
      "loss": 0.889,
      "step": 251350
    },
    {
      "epoch": 2.6614193234209007,
      "grad_norm": 3.4254817962646484,
      "learning_rate": 3.669833792081304e-05,
      "loss": 0.8788,
      "step": 251400
    },
    {
      "epoch": 2.661948645200904,
      "grad_norm": 3.8910117149353027,
      "learning_rate": 3.6695691297903877e-05,
      "loss": 0.8765,
      "step": 251450
    },
    {
      "epoch": 2.6624779669809073,
      "grad_norm": 3.96327543258667,
      "learning_rate": 3.669304467499471e-05,
      "loss": 0.8676,
      "step": 251500
    },
    {
      "epoch": 2.6624779669809073,
      "eval_loss": 0.6604995131492615,
      "eval_runtime": 46.5654,
      "eval_samples_per_second": 3606.329,
      "eval_steps_per_second": 450.807,
      "step": 251500
    },
    {
      "epoch": 2.6630072887609106,
      "grad_norm": 4.402435302734375,
      "learning_rate": 3.669039805208554e-05,
      "loss": 0.8669,
      "step": 251550
    },
    {
      "epoch": 2.663536610540914,
      "grad_norm": 4.0313286781311035,
      "learning_rate": 3.668775142917637e-05,
      "loss": 0.8687,
      "step": 251600
    },
    {
      "epoch": 2.6640659323209173,
      "grad_norm": 3.626699924468994,
      "learning_rate": 3.6685104806267206e-05,
      "loss": 0.872,
      "step": 251650
    },
    {
      "epoch": 2.6645952541009206,
      "grad_norm": 3.7138559818267822,
      "learning_rate": 3.668245818335804e-05,
      "loss": 0.8712,
      "step": 251700
    },
    {
      "epoch": 2.665124575880924,
      "grad_norm": 3.9587316513061523,
      "learning_rate": 3.667981156044887e-05,
      "loss": 0.8751,
      "step": 251750
    },
    {
      "epoch": 2.665653897660927,
      "grad_norm": 3.9438297748565674,
      "learning_rate": 3.66771649375397e-05,
      "loss": 0.8799,
      "step": 251800
    },
    {
      "epoch": 2.6661832194409305,
      "grad_norm": 3.9370150566101074,
      "learning_rate": 3.6674518314630536e-05,
      "loss": 0.8778,
      "step": 251850
    },
    {
      "epoch": 2.6667125412209334,
      "grad_norm": 3.795597791671753,
      "learning_rate": 3.667187169172136e-05,
      "loss": 0.8816,
      "step": 251900
    },
    {
      "epoch": 2.667241863000937,
      "grad_norm": 3.9708449840545654,
      "learning_rate": 3.66692250688122e-05,
      "loss": 0.8756,
      "step": 251950
    },
    {
      "epoch": 2.66777118478094,
      "grad_norm": 3.9691460132598877,
      "learning_rate": 3.6666578445903025e-05,
      "loss": 0.8839,
      "step": 252000
    },
    {
      "epoch": 2.66777118478094,
      "eval_loss": 0.6624158620834351,
      "eval_runtime": 46.604,
      "eval_samples_per_second": 3603.338,
      "eval_steps_per_second": 450.433,
      "step": 252000
    },
    {
      "epoch": 2.6683005065609433,
      "grad_norm": 4.044593334197998,
      "learning_rate": 3.6663931822993865e-05,
      "loss": 0.8588,
      "step": 252050
    },
    {
      "epoch": 2.6688298283409466,
      "grad_norm": 3.9686782360076904,
      "learning_rate": 3.666128520008469e-05,
      "loss": 0.8701,
      "step": 252100
    },
    {
      "epoch": 2.66935915012095,
      "grad_norm": 3.822206974029541,
      "learning_rate": 3.665863857717553e-05,
      "loss": 0.8655,
      "step": 252150
    },
    {
      "epoch": 2.6698884719009532,
      "grad_norm": 3.686699390411377,
      "learning_rate": 3.6655991954266354e-05,
      "loss": 0.8689,
      "step": 252200
    },
    {
      "epoch": 2.6704177936809566,
      "grad_norm": 3.9377083778381348,
      "learning_rate": 3.6653345331357195e-05,
      "loss": 0.867,
      "step": 252250
    },
    {
      "epoch": 2.67094711546096,
      "grad_norm": 3.9892380237579346,
      "learning_rate": 3.665069870844802e-05,
      "loss": 0.8703,
      "step": 252300
    },
    {
      "epoch": 2.671476437240963,
      "grad_norm": 3.4943385124206543,
      "learning_rate": 3.6648052085538857e-05,
      "loss": 0.8721,
      "step": 252350
    },
    {
      "epoch": 2.6720057590209665,
      "grad_norm": 4.10016393661499,
      "learning_rate": 3.6645405462629684e-05,
      "loss": 0.8701,
      "step": 252400
    },
    {
      "epoch": 2.67253508080097,
      "grad_norm": 3.77736234664917,
      "learning_rate": 3.664275883972052e-05,
      "loss": 0.8752,
      "step": 252450
    },
    {
      "epoch": 2.673064402580973,
      "grad_norm": 3.55403995513916,
      "learning_rate": 3.664011221681135e-05,
      "loss": 0.8769,
      "step": 252500
    },
    {
      "epoch": 2.673064402580973,
      "eval_loss": 0.6611501574516296,
      "eval_runtime": 46.5636,
      "eval_samples_per_second": 3606.463,
      "eval_steps_per_second": 450.824,
      "step": 252500
    },
    {
      "epoch": 2.6735937243609764,
      "grad_norm": 4.3946709632873535,
      "learning_rate": 3.663746559390218e-05,
      "loss": 0.8722,
      "step": 252550
    },
    {
      "epoch": 2.6741230461409797,
      "grad_norm": 3.8852713108062744,
      "learning_rate": 3.6634818970993013e-05,
      "loss": 0.8675,
      "step": 252600
    },
    {
      "epoch": 2.6746523679209826,
      "grad_norm": 4.122748851776123,
      "learning_rate": 3.663217234808385e-05,
      "loss": 0.8784,
      "step": 252650
    },
    {
      "epoch": 2.6751816897009864,
      "grad_norm": 3.7380168437957764,
      "learning_rate": 3.662952572517468e-05,
      "loss": 0.871,
      "step": 252700
    },
    {
      "epoch": 2.675711011480989,
      "grad_norm": 3.730933666229248,
      "learning_rate": 3.662687910226551e-05,
      "loss": 0.8705,
      "step": 252750
    },
    {
      "epoch": 2.6762403332609925,
      "grad_norm": 3.566864490509033,
      "learning_rate": 3.662423247935634e-05,
      "loss": 0.8564,
      "step": 252800
    },
    {
      "epoch": 2.676769655040996,
      "grad_norm": 4.057000637054443,
      "learning_rate": 3.662158585644718e-05,
      "loss": 0.8568,
      "step": 252850
    },
    {
      "epoch": 2.677298976820999,
      "grad_norm": 3.7989721298217773,
      "learning_rate": 3.6618939233538005e-05,
      "loss": 0.8661,
      "step": 252900
    },
    {
      "epoch": 2.6778282986010025,
      "grad_norm": 3.9274232387542725,
      "learning_rate": 3.661629261062884e-05,
      "loss": 0.8588,
      "step": 252950
    },
    {
      "epoch": 2.6783576203810058,
      "grad_norm": 3.912839889526367,
      "learning_rate": 3.6613645987719666e-05,
      "loss": 0.8658,
      "step": 253000
    },
    {
      "epoch": 2.6783576203810058,
      "eval_loss": 0.6600512266159058,
      "eval_runtime": 46.7316,
      "eval_samples_per_second": 3593.497,
      "eval_steps_per_second": 449.203,
      "step": 253000
    },
    {
      "epoch": 2.678886942161009,
      "grad_norm": 4.022051811218262,
      "learning_rate": 3.661099936481051e-05,
      "loss": 0.8462,
      "step": 253050
    },
    {
      "epoch": 2.6794162639410124,
      "grad_norm": 3.6774728298187256,
      "learning_rate": 3.6608352741901334e-05,
      "loss": 0.8827,
      "step": 253100
    },
    {
      "epoch": 2.6799455857210157,
      "grad_norm": 3.6779026985168457,
      "learning_rate": 3.660570611899217e-05,
      "loss": 0.8796,
      "step": 253150
    },
    {
      "epoch": 2.680474907501019,
      "grad_norm": 4.488513469696045,
      "learning_rate": 3.6603059496082996e-05,
      "loss": 0.8935,
      "step": 253200
    },
    {
      "epoch": 2.6810042292810223,
      "grad_norm": 4.071262359619141,
      "learning_rate": 3.6600412873173836e-05,
      "loss": 0.8781,
      "step": 253250
    },
    {
      "epoch": 2.6815335510610256,
      "grad_norm": 4.070347309112549,
      "learning_rate": 3.6597766250264664e-05,
      "loss": 0.8795,
      "step": 253300
    },
    {
      "epoch": 2.682062872841029,
      "grad_norm": 3.8629636764526367,
      "learning_rate": 3.65951196273555e-05,
      "loss": 0.8741,
      "step": 253350
    },
    {
      "epoch": 2.682592194621032,
      "grad_norm": 4.053961753845215,
      "learning_rate": 3.6592473004446325e-05,
      "loss": 0.8597,
      "step": 253400
    },
    {
      "epoch": 2.6831215164010356,
      "grad_norm": 3.921565294265747,
      "learning_rate": 3.658982638153716e-05,
      "loss": 0.8808,
      "step": 253450
    },
    {
      "epoch": 2.6836508381810384,
      "grad_norm": 3.5794882774353027,
      "learning_rate": 3.658717975862799e-05,
      "loss": 0.858,
      "step": 253500
    },
    {
      "epoch": 2.6836508381810384,
      "eval_loss": 0.6595471501350403,
      "eval_runtime": 46.7295,
      "eval_samples_per_second": 3593.66,
      "eval_steps_per_second": 449.224,
      "step": 253500
    },
    {
      "epoch": 2.6841801599610418,
      "grad_norm": 3.7800238132476807,
      "learning_rate": 3.658458606817701e-05,
      "loss": 0.8799,
      "step": 253550
    },
    {
      "epoch": 2.684709481741045,
      "grad_norm": 4.072564601898193,
      "learning_rate": 3.6581939445267835e-05,
      "loss": 0.8769,
      "step": 253600
    },
    {
      "epoch": 2.6852388035210484,
      "grad_norm": 4.405737400054932,
      "learning_rate": 3.6579292822358676e-05,
      "loss": 0.8664,
      "step": 253650
    },
    {
      "epoch": 2.6857681253010517,
      "grad_norm": 3.5913712978363037,
      "learning_rate": 3.6576646199449504e-05,
      "loss": 0.8669,
      "step": 253700
    },
    {
      "epoch": 2.686297447081055,
      "grad_norm": 3.884690046310425,
      "learning_rate": 3.657399957654034e-05,
      "loss": 0.873,
      "step": 253750
    },
    {
      "epoch": 2.6868267688610583,
      "grad_norm": 4.07445764541626,
      "learning_rate": 3.6571352953631165e-05,
      "loss": 0.873,
      "step": 253800
    },
    {
      "epoch": 2.6873560906410616,
      "grad_norm": 4.165106773376465,
      "learning_rate": 3.6568706330722e-05,
      "loss": 0.8624,
      "step": 253850
    },
    {
      "epoch": 2.687885412421065,
      "grad_norm": 3.7737932205200195,
      "learning_rate": 3.656605970781283e-05,
      "loss": 0.8669,
      "step": 253900
    },
    {
      "epoch": 2.6884147342010682,
      "grad_norm": 3.671931028366089,
      "learning_rate": 3.656341308490366e-05,
      "loss": 0.8611,
      "step": 253950
    },
    {
      "epoch": 2.6889440559810716,
      "grad_norm": 3.8905880451202393,
      "learning_rate": 3.6560766461994495e-05,
      "loss": 0.8611,
      "step": 254000
    },
    {
      "epoch": 2.6889440559810716,
      "eval_loss": 0.6588570475578308,
      "eval_runtime": 46.575,
      "eval_samples_per_second": 3605.582,
      "eval_steps_per_second": 450.714,
      "step": 254000
    },
    {
      "epoch": 2.689473377761075,
      "grad_norm": 3.8666889667510986,
      "learning_rate": 3.655811983908533e-05,
      "loss": 0.8514,
      "step": 254050
    },
    {
      "epoch": 2.690002699541078,
      "grad_norm": 3.894589900970459,
      "learning_rate": 3.655547321617616e-05,
      "loss": 0.8749,
      "step": 254100
    },
    {
      "epoch": 2.690532021321081,
      "grad_norm": 3.7614033222198486,
      "learning_rate": 3.655282659326699e-05,
      "loss": 0.8647,
      "step": 254150
    },
    {
      "epoch": 2.691061343101085,
      "grad_norm": 3.5948305130004883,
      "learning_rate": 3.6550179970357824e-05,
      "loss": 0.8629,
      "step": 254200
    },
    {
      "epoch": 2.6915906648810877,
      "grad_norm": 4.146200180053711,
      "learning_rate": 3.654753334744866e-05,
      "loss": 0.8857,
      "step": 254250
    },
    {
      "epoch": 2.692119986661091,
      "grad_norm": 3.8689451217651367,
      "learning_rate": 3.654488672453949e-05,
      "loss": 0.8775,
      "step": 254300
    },
    {
      "epoch": 2.6926493084410943,
      "grad_norm": 3.6313459873199463,
      "learning_rate": 3.654224010163032e-05,
      "loss": 0.8664,
      "step": 254350
    },
    {
      "epoch": 2.6931786302210976,
      "grad_norm": 3.88808536529541,
      "learning_rate": 3.6539593478721154e-05,
      "loss": 0.8796,
      "step": 254400
    },
    {
      "epoch": 2.693707952001101,
      "grad_norm": 3.824657917022705,
      "learning_rate": 3.653694685581199e-05,
      "loss": 0.8785,
      "step": 254450
    },
    {
      "epoch": 2.6942372737811042,
      "grad_norm": 4.054410934448242,
      "learning_rate": 3.6534300232902815e-05,
      "loss": 0.8714,
      "step": 254500
    },
    {
      "epoch": 2.6942372737811042,
      "eval_loss": 0.6571839451789856,
      "eval_runtime": 46.5713,
      "eval_samples_per_second": 3605.868,
      "eval_steps_per_second": 450.75,
      "step": 254500
    },
    {
      "epoch": 2.6947665955611075,
      "grad_norm": 4.04527473449707,
      "learning_rate": 3.653165360999365e-05,
      "loss": 0.8591,
      "step": 254550
    },
    {
      "epoch": 2.695295917341111,
      "grad_norm": 3.82772159576416,
      "learning_rate": 3.652900698708448e-05,
      "loss": 0.8702,
      "step": 254600
    },
    {
      "epoch": 2.695825239121114,
      "grad_norm": 3.865185499191284,
      "learning_rate": 3.652636036417532e-05,
      "loss": 0.8729,
      "step": 254650
    },
    {
      "epoch": 2.6963545609011175,
      "grad_norm": 3.772214889526367,
      "learning_rate": 3.6523713741266145e-05,
      "loss": 0.8631,
      "step": 254700
    },
    {
      "epoch": 2.696883882681121,
      "grad_norm": 4.205719947814941,
      "learning_rate": 3.652106711835698e-05,
      "loss": 0.8786,
      "step": 254750
    },
    {
      "epoch": 2.697413204461124,
      "grad_norm": 4.278631687164307,
      "learning_rate": 3.6518420495447806e-05,
      "loss": 0.8727,
      "step": 254800
    },
    {
      "epoch": 2.6979425262411274,
      "grad_norm": 3.6432151794433594,
      "learning_rate": 3.651577387253865e-05,
      "loss": 0.8705,
      "step": 254850
    },
    {
      "epoch": 2.6984718480211303,
      "grad_norm": 4.014889240264893,
      "learning_rate": 3.6513127249629475e-05,
      "loss": 0.8647,
      "step": 254900
    },
    {
      "epoch": 2.699001169801134,
      "grad_norm": 4.134754180908203,
      "learning_rate": 3.651048062672031e-05,
      "loss": 0.8928,
      "step": 254950
    },
    {
      "epoch": 2.699530491581137,
      "grad_norm": 4.353355884552002,
      "learning_rate": 3.6507834003811136e-05,
      "loss": 0.8756,
      "step": 255000
    },
    {
      "epoch": 2.699530491581137,
      "eval_loss": 0.65524822473526,
      "eval_runtime": 46.5894,
      "eval_samples_per_second": 3604.465,
      "eval_steps_per_second": 450.574,
      "step": 255000
    },
    {
      "epoch": 2.7000598133611406,
      "grad_norm": 3.857919931411743,
      "learning_rate": 3.650518738090197e-05,
      "loss": 0.8568,
      "step": 255050
    },
    {
      "epoch": 2.7005891351411435,
      "grad_norm": 3.731210470199585,
      "learning_rate": 3.6502540757992804e-05,
      "loss": 0.8631,
      "step": 255100
    },
    {
      "epoch": 2.701118456921147,
      "grad_norm": 3.6074719429016113,
      "learning_rate": 3.649989413508363e-05,
      "loss": 0.8653,
      "step": 255150
    },
    {
      "epoch": 2.70164777870115,
      "grad_norm": 3.7503437995910645,
      "learning_rate": 3.6497247512174466e-05,
      "loss": 0.8658,
      "step": 255200
    },
    {
      "epoch": 2.7021771004811534,
      "grad_norm": 3.8502142429351807,
      "learning_rate": 3.64946008892653e-05,
      "loss": 0.8793,
      "step": 255250
    },
    {
      "epoch": 2.7027064222611568,
      "grad_norm": 3.930696487426758,
      "learning_rate": 3.6491954266356134e-05,
      "loss": 0.8596,
      "step": 255300
    },
    {
      "epoch": 2.70323574404116,
      "grad_norm": 3.727863311767578,
      "learning_rate": 3.648930764344696e-05,
      "loss": 0.8679,
      "step": 255350
    },
    {
      "epoch": 2.7037650658211634,
      "grad_norm": 3.6650726795196533,
      "learning_rate": 3.6486661020537795e-05,
      "loss": 0.8571,
      "step": 255400
    },
    {
      "epoch": 2.7042943876011667,
      "grad_norm": 4.042500019073486,
      "learning_rate": 3.648401439762863e-05,
      "loss": 0.8698,
      "step": 255450
    },
    {
      "epoch": 2.70482370938117,
      "grad_norm": 4.110936164855957,
      "learning_rate": 3.6481367774719463e-05,
      "loss": 0.8612,
      "step": 255500
    },
    {
      "epoch": 2.70482370938117,
      "eval_loss": 0.6555780172348022,
      "eval_runtime": 46.5932,
      "eval_samples_per_second": 3604.175,
      "eval_steps_per_second": 450.538,
      "step": 255500
    },
    {
      "epoch": 2.7053530311611733,
      "grad_norm": 4.1550445556640625,
      "learning_rate": 3.647872115181029e-05,
      "loss": 0.8587,
      "step": 255550
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 4.331006050109863,
      "learning_rate": 3.6476127461359305e-05,
      "loss": 0.8665,
      "step": 255600
    },
    {
      "epoch": 2.7064116747211795,
      "grad_norm": 4.195867538452148,
      "learning_rate": 3.647348083845014e-05,
      "loss": 0.8752,
      "step": 255650
    },
    {
      "epoch": 2.7069409965011832,
      "grad_norm": 3.854668140411377,
      "learning_rate": 3.6470834215540974e-05,
      "loss": 0.864,
      "step": 255700
    },
    {
      "epoch": 2.707470318281186,
      "grad_norm": 4.041477203369141,
      "learning_rate": 3.64681875926318e-05,
      "loss": 0.8801,
      "step": 255750
    },
    {
      "epoch": 2.70799964006119,
      "grad_norm": 3.8212547302246094,
      "learning_rate": 3.6465540969722635e-05,
      "loss": 0.8611,
      "step": 255800
    },
    {
      "epoch": 2.7085289618411927,
      "grad_norm": 4.211496829986572,
      "learning_rate": 3.646289434681347e-05,
      "loss": 0.8652,
      "step": 255850
    },
    {
      "epoch": 2.709058283621196,
      "grad_norm": 3.928162097930908,
      "learning_rate": 3.64602477239043e-05,
      "loss": 0.8665,
      "step": 255900
    },
    {
      "epoch": 2.7095876054011994,
      "grad_norm": 3.9444761276245117,
      "learning_rate": 3.645760110099513e-05,
      "loss": 0.8666,
      "step": 255950
    },
    {
      "epoch": 2.7101169271812027,
      "grad_norm": 4.552072525024414,
      "learning_rate": 3.6454954478085965e-05,
      "loss": 0.8884,
      "step": 256000
    },
    {
      "epoch": 2.7101169271812027,
      "eval_loss": 0.6558679938316345,
      "eval_runtime": 46.4982,
      "eval_samples_per_second": 3611.538,
      "eval_steps_per_second": 451.458,
      "step": 256000
    },
    {
      "epoch": 2.710646248961206,
      "grad_norm": 3.985776901245117,
      "learning_rate": 3.64523078551768e-05,
      "loss": 0.8563,
      "step": 256050
    },
    {
      "epoch": 2.7111755707412093,
      "grad_norm": 3.684551239013672,
      "learning_rate": 3.6449661232267626e-05,
      "loss": 0.8693,
      "step": 256100
    },
    {
      "epoch": 2.7117048925212126,
      "grad_norm": 4.094453811645508,
      "learning_rate": 3.644701460935846e-05,
      "loss": 0.8675,
      "step": 256150
    },
    {
      "epoch": 2.712234214301216,
      "grad_norm": 4.235994815826416,
      "learning_rate": 3.644436798644929e-05,
      "loss": 0.8805,
      "step": 256200
    },
    {
      "epoch": 2.7127635360812192,
      "grad_norm": 3.7543702125549316,
      "learning_rate": 3.644172136354013e-05,
      "loss": 0.8595,
      "step": 256250
    },
    {
      "epoch": 2.7132928578612225,
      "grad_norm": 3.6834611892700195,
      "learning_rate": 3.6439074740630956e-05,
      "loss": 0.8616,
      "step": 256300
    },
    {
      "epoch": 2.713822179641226,
      "grad_norm": 3.9290685653686523,
      "learning_rate": 3.643642811772179e-05,
      "loss": 0.8776,
      "step": 256350
    },
    {
      "epoch": 2.7143515014212287,
      "grad_norm": 4.428916931152344,
      "learning_rate": 3.643378149481262e-05,
      "loss": 0.8646,
      "step": 256400
    },
    {
      "epoch": 2.7148808232012325,
      "grad_norm": 3.8722448348999023,
      "learning_rate": 3.643113487190346e-05,
      "loss": 0.8877,
      "step": 256450
    },
    {
      "epoch": 2.7154101449812353,
      "grad_norm": 4.001769065856934,
      "learning_rate": 3.6428488248994285e-05,
      "loss": 0.8802,
      "step": 256500
    },
    {
      "epoch": 2.7154101449812353,
      "eval_loss": 0.653282642364502,
      "eval_runtime": 46.6522,
      "eval_samples_per_second": 3599.615,
      "eval_steps_per_second": 449.968,
      "step": 256500
    },
    {
      "epoch": 2.715939466761239,
      "grad_norm": 3.9863133430480957,
      "learning_rate": 3.642584162608512e-05,
      "loss": 0.8585,
      "step": 256550
    },
    {
      "epoch": 2.716468788541242,
      "grad_norm": 4.043560028076172,
      "learning_rate": 3.642319500317595e-05,
      "loss": 0.8659,
      "step": 256600
    },
    {
      "epoch": 2.7169981103212453,
      "grad_norm": 3.9635350704193115,
      "learning_rate": 3.642054838026678e-05,
      "loss": 0.8757,
      "step": 256650
    },
    {
      "epoch": 2.7175274321012486,
      "grad_norm": 3.709944009780884,
      "learning_rate": 3.6417901757357615e-05,
      "loss": 0.8735,
      "step": 256700
    },
    {
      "epoch": 2.718056753881252,
      "grad_norm": 3.6008896827697754,
      "learning_rate": 3.641525513444844e-05,
      "loss": 0.8674,
      "step": 256750
    },
    {
      "epoch": 2.718586075661255,
      "grad_norm": 3.683955669403076,
      "learning_rate": 3.6412608511539276e-05,
      "loss": 0.8547,
      "step": 256800
    },
    {
      "epoch": 2.7191153974412585,
      "grad_norm": 3.6545019149780273,
      "learning_rate": 3.640996188863011e-05,
      "loss": 0.8586,
      "step": 256850
    },
    {
      "epoch": 2.719644719221262,
      "grad_norm": 4.053727626800537,
      "learning_rate": 3.6407315265720945e-05,
      "loss": 0.8671,
      "step": 256900
    },
    {
      "epoch": 2.720174041001265,
      "grad_norm": 4.0888800621032715,
      "learning_rate": 3.640466864281177e-05,
      "loss": 0.8657,
      "step": 256950
    },
    {
      "epoch": 2.7207033627812685,
      "grad_norm": 4.314048767089844,
      "learning_rate": 3.6402022019902606e-05,
      "loss": 0.8573,
      "step": 257000
    },
    {
      "epoch": 2.7207033627812685,
      "eval_loss": 0.6517754197120667,
      "eval_runtime": 46.6575,
      "eval_samples_per_second": 3599.206,
      "eval_steps_per_second": 449.917,
      "step": 257000
    },
    {
      "epoch": 2.7212326845612718,
      "grad_norm": 4.031486988067627,
      "learning_rate": 3.639937539699344e-05,
      "loss": 0.8696,
      "step": 257050
    },
    {
      "epoch": 2.721762006341275,
      "grad_norm": 3.7100167274475098,
      "learning_rate": 3.6396728774084274e-05,
      "loss": 0.8601,
      "step": 257100
    },
    {
      "epoch": 2.722291328121278,
      "grad_norm": 4.1785969734191895,
      "learning_rate": 3.63940821511751e-05,
      "loss": 0.8783,
      "step": 257150
    },
    {
      "epoch": 2.7228206499012817,
      "grad_norm": 3.741793394088745,
      "learning_rate": 3.6391435528265936e-05,
      "loss": 0.8716,
      "step": 257200
    },
    {
      "epoch": 2.7233499716812846,
      "grad_norm": 3.6988422870635986,
      "learning_rate": 3.638878890535677e-05,
      "loss": 0.8722,
      "step": 257250
    },
    {
      "epoch": 2.7238792934612883,
      "grad_norm": 3.4996657371520996,
      "learning_rate": 3.63861422824476e-05,
      "loss": 0.8525,
      "step": 257300
    },
    {
      "epoch": 2.724408615241291,
      "grad_norm": 4.3342437744140625,
      "learning_rate": 3.638349565953843e-05,
      "loss": 0.8674,
      "step": 257350
    },
    {
      "epoch": 2.7249379370212945,
      "grad_norm": 4.321096420288086,
      "learning_rate": 3.638084903662926e-05,
      "loss": 0.8575,
      "step": 257400
    },
    {
      "epoch": 2.725467258801298,
      "grad_norm": 3.684478759765625,
      "learning_rate": 3.63782024137201e-05,
      "loss": 0.8739,
      "step": 257450
    },
    {
      "epoch": 2.725996580581301,
      "grad_norm": 3.9926462173461914,
      "learning_rate": 3.637555579081093e-05,
      "loss": 0.8632,
      "step": 257500
    },
    {
      "epoch": 2.725996580581301,
      "eval_loss": 0.6541775465011597,
      "eval_runtime": 46.6851,
      "eval_samples_per_second": 3597.076,
      "eval_steps_per_second": 449.651,
      "step": 257500
    },
    {
      "epoch": 2.7265259023613044,
      "grad_norm": 4.036035537719727,
      "learning_rate": 3.637290916790176e-05,
      "loss": 0.876,
      "step": 257550
    },
    {
      "epoch": 2.7270552241413077,
      "grad_norm": 4.232624053955078,
      "learning_rate": 3.637026254499259e-05,
      "loss": 0.8553,
      "step": 257600
    },
    {
      "epoch": 2.727584545921311,
      "grad_norm": 3.785332202911377,
      "learning_rate": 3.636761592208342e-05,
      "loss": 0.8658,
      "step": 257650
    },
    {
      "epoch": 2.7281138677013144,
      "grad_norm": 4.0172505378723145,
      "learning_rate": 3.6364969299174256e-05,
      "loss": 0.8597,
      "step": 257700
    },
    {
      "epoch": 2.7286431894813177,
      "grad_norm": 4.322309970855713,
      "learning_rate": 3.6362322676265084e-05,
      "loss": 0.8598,
      "step": 257750
    },
    {
      "epoch": 2.729172511261321,
      "grad_norm": 3.9853861331939697,
      "learning_rate": 3.635967605335592e-05,
      "loss": 0.8526,
      "step": 257800
    },
    {
      "epoch": 2.7297018330413243,
      "grad_norm": 4.581762790679932,
      "learning_rate": 3.635702943044675e-05,
      "loss": 0.8556,
      "step": 257850
    },
    {
      "epoch": 2.730231154821327,
      "grad_norm": 3.7088637351989746,
      "learning_rate": 3.6354382807537586e-05,
      "loss": 0.8584,
      "step": 257900
    },
    {
      "epoch": 2.730760476601331,
      "grad_norm": 3.7461583614349365,
      "learning_rate": 3.635173618462841e-05,
      "loss": 0.8659,
      "step": 257950
    },
    {
      "epoch": 2.731289798381334,
      "grad_norm": 3.933126449584961,
      "learning_rate": 3.634908956171925e-05,
      "loss": 0.8639,
      "step": 258000
    },
    {
      "epoch": 2.731289798381334,
      "eval_loss": 0.6530753970146179,
      "eval_runtime": 46.5964,
      "eval_samples_per_second": 3603.925,
      "eval_steps_per_second": 450.507,
      "step": 258000
    },
    {
      "epoch": 2.7318191201613375,
      "grad_norm": 3.8747618198394775,
      "learning_rate": 3.634644293881008e-05,
      "loss": 0.8681,
      "step": 258050
    },
    {
      "epoch": 2.7323484419413404,
      "grad_norm": 4.003540992736816,
      "learning_rate": 3.6343796315900916e-05,
      "loss": 0.8685,
      "step": 258100
    },
    {
      "epoch": 2.7328777637213437,
      "grad_norm": 3.757341146469116,
      "learning_rate": 3.634114969299174e-05,
      "loss": 0.8762,
      "step": 258150
    },
    {
      "epoch": 2.733407085501347,
      "grad_norm": 3.9669768810272217,
      "learning_rate": 3.633850307008258e-05,
      "loss": 0.8755,
      "step": 258200
    },
    {
      "epoch": 2.7339364072813503,
      "grad_norm": 4.016017913818359,
      "learning_rate": 3.633585644717341e-05,
      "loss": 0.8674,
      "step": 258250
    },
    {
      "epoch": 2.7344657290613537,
      "grad_norm": 3.942322015762329,
      "learning_rate": 3.633320982426424e-05,
      "loss": 0.8646,
      "step": 258300
    },
    {
      "epoch": 2.734995050841357,
      "grad_norm": 3.8517186641693115,
      "learning_rate": 3.633056320135507e-05,
      "loss": 0.8675,
      "step": 258350
    },
    {
      "epoch": 2.7355243726213603,
      "grad_norm": 3.9628942012786865,
      "learning_rate": 3.63279165784459e-05,
      "loss": 0.8773,
      "step": 258400
    },
    {
      "epoch": 2.7360536944013636,
      "grad_norm": 3.8864872455596924,
      "learning_rate": 3.632526995553674e-05,
      "loss": 0.868,
      "step": 258450
    },
    {
      "epoch": 2.736583016181367,
      "grad_norm": 3.872002601623535,
      "learning_rate": 3.632262333262757e-05,
      "loss": 0.8655,
      "step": 258500
    },
    {
      "epoch": 2.736583016181367,
      "eval_loss": 0.6516168117523193,
      "eval_runtime": 46.6399,
      "eval_samples_per_second": 3600.565,
      "eval_steps_per_second": 450.087,
      "step": 258500
    },
    {
      "epoch": 2.73711233796137,
      "grad_norm": 4.063736915588379,
      "learning_rate": 3.63199767097184e-05,
      "loss": 0.8581,
      "step": 258550
    },
    {
      "epoch": 2.7376416597413735,
      "grad_norm": 3.5380215644836426,
      "learning_rate": 3.631733008680923e-05,
      "loss": 0.8791,
      "step": 258600
    },
    {
      "epoch": 2.7381709815213764,
      "grad_norm": 4.072978496551514,
      "learning_rate": 3.631468346390007e-05,
      "loss": 0.8677,
      "step": 258650
    },
    {
      "epoch": 2.73870030330138,
      "grad_norm": 4.067422866821289,
      "learning_rate": 3.63120368409909e-05,
      "loss": 0.8522,
      "step": 258700
    },
    {
      "epoch": 2.739229625081383,
      "grad_norm": 3.733611822128296,
      "learning_rate": 3.630939021808173e-05,
      "loss": 0.8561,
      "step": 258750
    },
    {
      "epoch": 2.7397589468613868,
      "grad_norm": 4.0074896812438965,
      "learning_rate": 3.630674359517256e-05,
      "loss": 0.8633,
      "step": 258800
    },
    {
      "epoch": 2.7402882686413896,
      "grad_norm": 3.9007952213287354,
      "learning_rate": 3.630409697226339e-05,
      "loss": 0.8621,
      "step": 258850
    },
    {
      "epoch": 2.740817590421393,
      "grad_norm": 3.7861227989196777,
      "learning_rate": 3.630145034935423e-05,
      "loss": 0.8687,
      "step": 258900
    },
    {
      "epoch": 2.7413469122013963,
      "grad_norm": 3.8431003093719482,
      "learning_rate": 3.6298803726445055e-05,
      "loss": 0.8613,
      "step": 258950
    },
    {
      "epoch": 2.7418762339813996,
      "grad_norm": 3.943692922592163,
      "learning_rate": 3.629615710353589e-05,
      "loss": 0.8769,
      "step": 259000
    },
    {
      "epoch": 2.7418762339813996,
      "eval_loss": 0.6508833169937134,
      "eval_runtime": 46.6113,
      "eval_samples_per_second": 3602.773,
      "eval_steps_per_second": 450.363,
      "step": 259000
    },
    {
      "epoch": 2.742405555761403,
      "grad_norm": 4.101813793182373,
      "learning_rate": 3.629351048062672e-05,
      "loss": 0.8661,
      "step": 259050
    },
    {
      "epoch": 2.742934877541406,
      "grad_norm": 4.074248313903809,
      "learning_rate": 3.629086385771756e-05,
      "loss": 0.8571,
      "step": 259100
    },
    {
      "epoch": 2.7434641993214095,
      "grad_norm": 4.07366943359375,
      "learning_rate": 3.6288217234808384e-05,
      "loss": 0.8694,
      "step": 259150
    },
    {
      "epoch": 2.743993521101413,
      "grad_norm": 3.848703384399414,
      "learning_rate": 3.628557061189922e-05,
      "loss": 0.8738,
      "step": 259200
    },
    {
      "epoch": 2.744522842881416,
      "grad_norm": 4.053548812866211,
      "learning_rate": 3.628292398899005e-05,
      "loss": 0.8554,
      "step": 259250
    },
    {
      "epoch": 2.7450521646614194,
      "grad_norm": 4.088359355926514,
      "learning_rate": 3.6280277366080887e-05,
      "loss": 0.8545,
      "step": 259300
    },
    {
      "epoch": 2.7455814864414227,
      "grad_norm": 4.075507640838623,
      "learning_rate": 3.6277630743171714e-05,
      "loss": 0.8589,
      "step": 259350
    },
    {
      "epoch": 2.7461108082214256,
      "grad_norm": 4.001372814178467,
      "learning_rate": 3.627498412026255e-05,
      "loss": 0.8717,
      "step": 259400
    },
    {
      "epoch": 2.7466401300014294,
      "grad_norm": 3.4865076541900635,
      "learning_rate": 3.627233749735338e-05,
      "loss": 0.8668,
      "step": 259450
    },
    {
      "epoch": 2.7471694517814322,
      "grad_norm": 3.753791093826294,
      "learning_rate": 3.626969087444421e-05,
      "loss": 0.8671,
      "step": 259500
    },
    {
      "epoch": 2.7471694517814322,
      "eval_loss": 0.6503320336341858,
      "eval_runtime": 46.665,
      "eval_samples_per_second": 3598.63,
      "eval_steps_per_second": 449.845,
      "step": 259500
    },
    {
      "epoch": 2.747698773561436,
      "grad_norm": 3.899742364883423,
      "learning_rate": 3.6267044251535044e-05,
      "loss": 0.859,
      "step": 259550
    },
    {
      "epoch": 2.748228095341439,
      "grad_norm": 3.9596409797668457,
      "learning_rate": 3.626445056108406e-05,
      "loss": 0.8697,
      "step": 259600
    },
    {
      "epoch": 2.748757417121442,
      "grad_norm": 3.682677745819092,
      "learning_rate": 3.626180393817489e-05,
      "loss": 0.8572,
      "step": 259650
    },
    {
      "epoch": 2.7492867389014455,
      "grad_norm": 3.647312641143799,
      "learning_rate": 3.6259157315265726e-05,
      "loss": 0.8629,
      "step": 259700
    },
    {
      "epoch": 2.749816060681449,
      "grad_norm": 3.9580671787261963,
      "learning_rate": 3.6256510692356554e-05,
      "loss": 0.8645,
      "step": 259750
    },
    {
      "epoch": 2.750345382461452,
      "grad_norm": 3.893552780151367,
      "learning_rate": 3.625386406944739e-05,
      "loss": 0.867,
      "step": 259800
    },
    {
      "epoch": 2.7508747042414554,
      "grad_norm": 3.7710330486297607,
      "learning_rate": 3.625121744653822e-05,
      "loss": 0.8641,
      "step": 259850
    },
    {
      "epoch": 2.7514040260214587,
      "grad_norm": 3.863489866256714,
      "learning_rate": 3.624857082362905e-05,
      "loss": 0.8535,
      "step": 259900
    },
    {
      "epoch": 2.751933347801462,
      "grad_norm": 3.9210474491119385,
      "learning_rate": 3.624592420071988e-05,
      "loss": 0.8696,
      "step": 259950
    },
    {
      "epoch": 2.7524626695814653,
      "grad_norm": 3.845271348953247,
      "learning_rate": 3.624327757781071e-05,
      "loss": 0.8718,
      "step": 260000
    },
    {
      "epoch": 2.7524626695814653,
      "eval_loss": 0.6499878764152527,
      "eval_runtime": 46.6145,
      "eval_samples_per_second": 3602.524,
      "eval_steps_per_second": 450.332,
      "step": 260000
    },
    {
      "epoch": 2.7529919913614687,
      "grad_norm": 4.101229667663574,
      "learning_rate": 3.624063095490155e-05,
      "loss": 0.8752,
      "step": 260050
    },
    {
      "epoch": 2.753521313141472,
      "grad_norm": 4.244567394256592,
      "learning_rate": 3.623798433199238e-05,
      "loss": 0.8497,
      "step": 260100
    },
    {
      "epoch": 2.754050634921475,
      "grad_norm": 3.4867258071899414,
      "learning_rate": 3.623533770908321e-05,
      "loss": 0.8791,
      "step": 260150
    },
    {
      "epoch": 2.7545799567014786,
      "grad_norm": 3.994515895843506,
      "learning_rate": 3.623269108617404e-05,
      "loss": 0.8578,
      "step": 260200
    },
    {
      "epoch": 2.7551092784814815,
      "grad_norm": 4.220098495483398,
      "learning_rate": 3.623004446326488e-05,
      "loss": 0.8648,
      "step": 260250
    },
    {
      "epoch": 2.755638600261485,
      "grad_norm": 4.103850364685059,
      "learning_rate": 3.622739784035571e-05,
      "loss": 0.87,
      "step": 260300
    },
    {
      "epoch": 2.756167922041488,
      "grad_norm": 4.248142719268799,
      "learning_rate": 3.622475121744654e-05,
      "loss": 0.8667,
      "step": 260350
    },
    {
      "epoch": 2.7566972438214914,
      "grad_norm": 3.608018159866333,
      "learning_rate": 3.622210459453737e-05,
      "loss": 0.8642,
      "step": 260400
    },
    {
      "epoch": 2.7572265656014947,
      "grad_norm": 4.037806510925293,
      "learning_rate": 3.6219457971628204e-05,
      "loss": 0.8601,
      "step": 260450
    },
    {
      "epoch": 2.757755887381498,
      "grad_norm": 4.162280082702637,
      "learning_rate": 3.621681134871904e-05,
      "loss": 0.871,
      "step": 260500
    },
    {
      "epoch": 2.757755887381498,
      "eval_loss": 0.6515400409698486,
      "eval_runtime": 46.5678,
      "eval_samples_per_second": 3606.143,
      "eval_steps_per_second": 450.784,
      "step": 260500
    },
    {
      "epoch": 2.7582852091615013,
      "grad_norm": 4.053720474243164,
      "learning_rate": 3.6214164725809865e-05,
      "loss": 0.8549,
      "step": 260550
    },
    {
      "epoch": 2.7588145309415046,
      "grad_norm": 4.063094615936279,
      "learning_rate": 3.62115181029007e-05,
      "loss": 0.8621,
      "step": 260600
    },
    {
      "epoch": 2.759343852721508,
      "grad_norm": 4.306285381317139,
      "learning_rate": 3.6208871479991534e-05,
      "loss": 0.8646,
      "step": 260650
    },
    {
      "epoch": 2.7598731745015113,
      "grad_norm": 4.2342400550842285,
      "learning_rate": 3.620622485708237e-05,
      "loss": 0.8548,
      "step": 260700
    },
    {
      "epoch": 2.7604024962815146,
      "grad_norm": 3.7604520320892334,
      "learning_rate": 3.6203578234173195e-05,
      "loss": 0.874,
      "step": 260750
    },
    {
      "epoch": 2.760931818061518,
      "grad_norm": 4.269411563873291,
      "learning_rate": 3.620093161126403e-05,
      "loss": 0.8504,
      "step": 260800
    },
    {
      "epoch": 2.761461139841521,
      "grad_norm": 4.186743259429932,
      "learning_rate": 3.619828498835486e-05,
      "loss": 0.8513,
      "step": 260850
    },
    {
      "epoch": 2.7619904616215245,
      "grad_norm": 3.8137612342834473,
      "learning_rate": 3.61956383654457e-05,
      "loss": 0.8709,
      "step": 260900
    },
    {
      "epoch": 2.762519783401528,
      "grad_norm": 4.251788139343262,
      "learning_rate": 3.6193044674994705e-05,
      "loss": 0.885,
      "step": 260950
    },
    {
      "epoch": 2.7630491051815307,
      "grad_norm": 4.16814661026001,
      "learning_rate": 3.619039805208554e-05,
      "loss": 0.8617,
      "step": 261000
    },
    {
      "epoch": 2.7630491051815307,
      "eval_loss": 0.6471889019012451,
      "eval_runtime": 46.9256,
      "eval_samples_per_second": 3578.642,
      "eval_steps_per_second": 447.346,
      "step": 261000
    },
    {
      "epoch": 2.7635784269615344,
      "grad_norm": 3.944589138031006,
      "learning_rate": 3.6187751429176374e-05,
      "loss": 0.8646,
      "step": 261050
    },
    {
      "epoch": 2.7641077487415373,
      "grad_norm": 3.8924813270568848,
      "learning_rate": 3.618510480626721e-05,
      "loss": 0.8681,
      "step": 261100
    },
    {
      "epoch": 2.7646370705215406,
      "grad_norm": 4.333724498748779,
      "learning_rate": 3.6182458183358035e-05,
      "loss": 0.8525,
      "step": 261150
    },
    {
      "epoch": 2.765166392301544,
      "grad_norm": 4.045638561248779,
      "learning_rate": 3.617981156044887e-05,
      "loss": 0.8695,
      "step": 261200
    },
    {
      "epoch": 2.7656957140815472,
      "grad_norm": 4.106619834899902,
      "learning_rate": 3.61771649375397e-05,
      "loss": 0.8734,
      "step": 261250
    },
    {
      "epoch": 2.7662250358615506,
      "grad_norm": 4.3926215171813965,
      "learning_rate": 3.617451831463054e-05,
      "loss": 0.8715,
      "step": 261300
    },
    {
      "epoch": 2.766754357641554,
      "grad_norm": 3.9452226161956787,
      "learning_rate": 3.6171871691721365e-05,
      "loss": 0.8495,
      "step": 261350
    },
    {
      "epoch": 2.767283679421557,
      "grad_norm": 3.8140509128570557,
      "learning_rate": 3.61692250688122e-05,
      "loss": 0.8638,
      "step": 261400
    },
    {
      "epoch": 2.7678130012015605,
      "grad_norm": 4.004820346832275,
      "learning_rate": 3.616657844590303e-05,
      "loss": 0.8663,
      "step": 261450
    },
    {
      "epoch": 2.768342322981564,
      "grad_norm": 3.9344325065612793,
      "learning_rate": 3.616393182299386e-05,
      "loss": 0.8618,
      "step": 261500
    },
    {
      "epoch": 2.768342322981564,
      "eval_loss": 0.6486771702766418,
      "eval_runtime": 46.601,
      "eval_samples_per_second": 3603.568,
      "eval_steps_per_second": 450.462,
      "step": 261500
    },
    {
      "epoch": 2.768871644761567,
      "grad_norm": 3.8696656227111816,
      "learning_rate": 3.6161285200084694e-05,
      "loss": 0.8675,
      "step": 261550
    },
    {
      "epoch": 2.7694009665415704,
      "grad_norm": 3.6889827251434326,
      "learning_rate": 3.615863857717552e-05,
      "loss": 0.8519,
      "step": 261600
    },
    {
      "epoch": 2.7699302883215737,
      "grad_norm": 3.8104681968688965,
      "learning_rate": 3.615599195426636e-05,
      "loss": 0.8704,
      "step": 261650
    },
    {
      "epoch": 2.770459610101577,
      "grad_norm": 3.982308864593506,
      "learning_rate": 3.615334533135719e-05,
      "loss": 0.867,
      "step": 261700
    },
    {
      "epoch": 2.77098893188158,
      "grad_norm": 3.2646210193634033,
      "learning_rate": 3.6150698708448024e-05,
      "loss": 0.8521,
      "step": 261750
    },
    {
      "epoch": 2.7715182536615837,
      "grad_norm": 3.368241548538208,
      "learning_rate": 3.614805208553885e-05,
      "loss": 0.8685,
      "step": 261800
    },
    {
      "epoch": 2.7720475754415865,
      "grad_norm": 4.104496479034424,
      "learning_rate": 3.614540546262969e-05,
      "loss": 0.8729,
      "step": 261850
    },
    {
      "epoch": 2.77257689722159,
      "grad_norm": 3.9420199394226074,
      "learning_rate": 3.614275883972052e-05,
      "loss": 0.8614,
      "step": 261900
    },
    {
      "epoch": 2.773106219001593,
      "grad_norm": 4.255369186401367,
      "learning_rate": 3.6140112216811353e-05,
      "loss": 0.8547,
      "step": 261950
    },
    {
      "epoch": 2.7736355407815965,
      "grad_norm": 3.8848929405212402,
      "learning_rate": 3.613746559390218e-05,
      "loss": 0.842,
      "step": 262000
    },
    {
      "epoch": 2.7736355407815965,
      "eval_loss": 0.6451412439346313,
      "eval_runtime": 46.6688,
      "eval_samples_per_second": 3598.339,
      "eval_steps_per_second": 449.808,
      "step": 262000
    },
    {
      "epoch": 2.7741648625615998,
      "grad_norm": 3.776886224746704,
      "learning_rate": 3.6134818970993015e-05,
      "loss": 0.865,
      "step": 262050
    },
    {
      "epoch": 2.774694184341603,
      "grad_norm": 4.182957649230957,
      "learning_rate": 3.613217234808385e-05,
      "loss": 0.8556,
      "step": 262100
    },
    {
      "epoch": 2.7752235061216064,
      "grad_norm": 3.859590530395508,
      "learning_rate": 3.6129525725174676e-05,
      "loss": 0.8659,
      "step": 262150
    },
    {
      "epoch": 2.7757528279016097,
      "grad_norm": 3.96450138092041,
      "learning_rate": 3.612687910226551e-05,
      "loss": 0.8611,
      "step": 262200
    },
    {
      "epoch": 2.776282149681613,
      "grad_norm": 3.7768774032592773,
      "learning_rate": 3.6124232479356344e-05,
      "loss": 0.8508,
      "step": 262250
    },
    {
      "epoch": 2.7768114714616163,
      "grad_norm": 3.9100818634033203,
      "learning_rate": 3.612158585644718e-05,
      "loss": 0.8687,
      "step": 262300
    },
    {
      "epoch": 2.7773407932416196,
      "grad_norm": 3.892895460128784,
      "learning_rate": 3.6118939233538006e-05,
      "loss": 0.8431,
      "step": 262350
    },
    {
      "epoch": 2.777870115021623,
      "grad_norm": 4.274874687194824,
      "learning_rate": 3.611629261062884e-05,
      "loss": 0.8584,
      "step": 262400
    },
    {
      "epoch": 2.7783994368016263,
      "grad_norm": 3.9451658725738525,
      "learning_rate": 3.611364598771967e-05,
      "loss": 0.8661,
      "step": 262450
    },
    {
      "epoch": 2.778928758581629,
      "grad_norm": 3.7030162811279297,
      "learning_rate": 3.611099936481051e-05,
      "loss": 0.87,
      "step": 262500
    },
    {
      "epoch": 2.778928758581629,
      "eval_loss": 0.6458933353424072,
      "eval_runtime": 46.619,
      "eval_samples_per_second": 3602.182,
      "eval_steps_per_second": 450.289,
      "step": 262500
    },
    {
      "epoch": 2.779458080361633,
      "grad_norm": 3.5956945419311523,
      "learning_rate": 3.6108352741901336e-05,
      "loss": 0.8658,
      "step": 262550
    },
    {
      "epoch": 2.7799874021416358,
      "grad_norm": 3.663534641265869,
      "learning_rate": 3.610570611899217e-05,
      "loss": 0.8676,
      "step": 262600
    },
    {
      "epoch": 2.780516723921639,
      "grad_norm": 3.9218649864196777,
      "learning_rate": 3.6103059496083e-05,
      "loss": 0.8726,
      "step": 262650
    },
    {
      "epoch": 2.7810460457016424,
      "grad_norm": 3.7215969562530518,
      "learning_rate": 3.610041287317383e-05,
      "loss": 0.8709,
      "step": 262700
    },
    {
      "epoch": 2.7815753674816457,
      "grad_norm": 3.7868130207061768,
      "learning_rate": 3.6097766250264665e-05,
      "loss": 0.8709,
      "step": 262750
    },
    {
      "epoch": 2.782104689261649,
      "grad_norm": 3.246793508529663,
      "learning_rate": 3.609511962735549e-05,
      "loss": 0.8566,
      "step": 262800
    },
    {
      "epoch": 2.7826340110416523,
      "grad_norm": 3.82293438911438,
      "learning_rate": 3.6092473004446327e-05,
      "loss": 0.8566,
      "step": 262850
    },
    {
      "epoch": 2.7831633328216556,
      "grad_norm": 3.7871222496032715,
      "learning_rate": 3.608982638153716e-05,
      "loss": 0.8628,
      "step": 262900
    },
    {
      "epoch": 2.783692654601659,
      "grad_norm": 3.749847412109375,
      "learning_rate": 3.6087179758627995e-05,
      "loss": 0.8594,
      "step": 262950
    },
    {
      "epoch": 2.7842219763816622,
      "grad_norm": 3.7756855487823486,
      "learning_rate": 3.608453313571882e-05,
      "loss": 0.8739,
      "step": 263000
    },
    {
      "epoch": 2.7842219763816622,
      "eval_loss": 0.6450362205505371,
      "eval_runtime": 46.549,
      "eval_samples_per_second": 3607.596,
      "eval_steps_per_second": 450.966,
      "step": 263000
    },
    {
      "epoch": 2.7847512981616656,
      "grad_norm": 4.181473731994629,
      "learning_rate": 3.6081886512809656e-05,
      "loss": 0.8746,
      "step": 263050
    },
    {
      "epoch": 2.785280619941669,
      "grad_norm": 3.8037660121917725,
      "learning_rate": 3.607929282235867e-05,
      "loss": 0.8509,
      "step": 263100
    },
    {
      "epoch": 2.785809941721672,
      "grad_norm": 4.073724269866943,
      "learning_rate": 3.6076646199449505e-05,
      "loss": 0.8587,
      "step": 263150
    },
    {
      "epoch": 2.7863392635016755,
      "grad_norm": 3.2630317211151123,
      "learning_rate": 3.607399957654033e-05,
      "loss": 0.8579,
      "step": 263200
    },
    {
      "epoch": 2.7868685852816784,
      "grad_norm": 4.31606388092041,
      "learning_rate": 3.6071352953631166e-05,
      "loss": 0.8666,
      "step": 263250
    },
    {
      "epoch": 2.787397907061682,
      "grad_norm": 4.104951858520508,
      "learning_rate": 3.6068706330722e-05,
      "loss": 0.8721,
      "step": 263300
    },
    {
      "epoch": 2.787927228841685,
      "grad_norm": 3.5292232036590576,
      "learning_rate": 3.6066059707812835e-05,
      "loss": 0.8627,
      "step": 263350
    },
    {
      "epoch": 2.7884565506216883,
      "grad_norm": 3.896360397338867,
      "learning_rate": 3.606341308490366e-05,
      "loss": 0.8469,
      "step": 263400
    },
    {
      "epoch": 2.7889858724016916,
      "grad_norm": 4.068262100219727,
      "learning_rate": 3.6060766461994496e-05,
      "loss": 0.8594,
      "step": 263450
    },
    {
      "epoch": 2.789515194181695,
      "grad_norm": 4.073467254638672,
      "learning_rate": 3.605811983908533e-05,
      "loss": 0.8568,
      "step": 263500
    },
    {
      "epoch": 2.789515194181695,
      "eval_loss": 0.644946813583374,
      "eval_runtime": 46.572,
      "eval_samples_per_second": 3605.812,
      "eval_steps_per_second": 450.743,
      "step": 263500
    },
    {
      "epoch": 2.7900445159616982,
      "grad_norm": 3.5595641136169434,
      "learning_rate": 3.6055473216176164e-05,
      "loss": 0.8592,
      "step": 263550
    },
    {
      "epoch": 2.7905738377417015,
      "grad_norm": 4.091568946838379,
      "learning_rate": 3.605282659326699e-05,
      "loss": 0.8515,
      "step": 263600
    },
    {
      "epoch": 2.791103159521705,
      "grad_norm": 3.9494504928588867,
      "learning_rate": 3.6050179970357826e-05,
      "loss": 0.8674,
      "step": 263650
    },
    {
      "epoch": 2.791632481301708,
      "grad_norm": 3.707472085952759,
      "learning_rate": 3.604753334744866e-05,
      "loss": 0.8583,
      "step": 263700
    },
    {
      "epoch": 2.7921618030817115,
      "grad_norm": 4.092304229736328,
      "learning_rate": 3.604488672453949e-05,
      "loss": 0.8597,
      "step": 263750
    },
    {
      "epoch": 2.792691124861715,
      "grad_norm": 3.8426315784454346,
      "learning_rate": 3.604224010163032e-05,
      "loss": 0.8789,
      "step": 263800
    },
    {
      "epoch": 2.793220446641718,
      "grad_norm": 4.242600917816162,
      "learning_rate": 3.603959347872115e-05,
      "loss": 0.8623,
      "step": 263850
    },
    {
      "epoch": 2.7937497684217214,
      "grad_norm": 4.189151763916016,
      "learning_rate": 3.603694685581199e-05,
      "loss": 0.8594,
      "step": 263900
    },
    {
      "epoch": 2.7942790902017247,
      "grad_norm": 4.206157207489014,
      "learning_rate": 3.603430023290282e-05,
      "loss": 0.8654,
      "step": 263950
    },
    {
      "epoch": 2.7948084119817276,
      "grad_norm": 4.0884575843811035,
      "learning_rate": 3.603165360999365e-05,
      "loss": 0.854,
      "step": 264000
    },
    {
      "epoch": 2.7948084119817276,
      "eval_loss": 0.6443617939949036,
      "eval_runtime": 46.6358,
      "eval_samples_per_second": 3600.879,
      "eval_steps_per_second": 450.126,
      "step": 264000
    },
    {
      "epoch": 2.7953377337617313,
      "grad_norm": 3.9085328578948975,
      "learning_rate": 3.602900698708448e-05,
      "loss": 0.8637,
      "step": 264050
    },
    {
      "epoch": 2.795867055541734,
      "grad_norm": 3.7389473915100098,
      "learning_rate": 3.602636036417531e-05,
      "loss": 0.8468,
      "step": 264100
    },
    {
      "epoch": 2.7963963773217375,
      "grad_norm": 4.108588695526123,
      "learning_rate": 3.6023713741266146e-05,
      "loss": 0.8593,
      "step": 264150
    },
    {
      "epoch": 2.796925699101741,
      "grad_norm": 3.810811758041382,
      "learning_rate": 3.6021067118356974e-05,
      "loss": 0.8497,
      "step": 264200
    },
    {
      "epoch": 2.797455020881744,
      "grad_norm": 3.7563741207122803,
      "learning_rate": 3.601842049544781e-05,
      "loss": 0.8811,
      "step": 264250
    },
    {
      "epoch": 2.7979843426617474,
      "grad_norm": 3.715158700942993,
      "learning_rate": 3.601577387253864e-05,
      "loss": 0.8613,
      "step": 264300
    },
    {
      "epoch": 2.7985136644417508,
      "grad_norm": 4.479537010192871,
      "learning_rate": 3.6013127249629476e-05,
      "loss": 0.864,
      "step": 264350
    },
    {
      "epoch": 2.799042986221754,
      "grad_norm": 4.37296724319458,
      "learning_rate": 3.60104806267203e-05,
      "loss": 0.8688,
      "step": 264400
    },
    {
      "epoch": 2.7995723080017574,
      "grad_norm": 4.048581600189209,
      "learning_rate": 3.600783400381114e-05,
      "loss": 0.8547,
      "step": 264450
    },
    {
      "epoch": 2.8001016297817607,
      "grad_norm": 3.8560564517974854,
      "learning_rate": 3.600518738090197e-05,
      "loss": 0.8526,
      "step": 264500
    },
    {
      "epoch": 2.8001016297817607,
      "eval_loss": 0.6426470875740051,
      "eval_runtime": 46.6273,
      "eval_samples_per_second": 3601.536,
      "eval_steps_per_second": 450.208,
      "step": 264500
    },
    {
      "epoch": 2.800630951561764,
      "grad_norm": 3.852158546447754,
      "learning_rate": 3.6002540757992806e-05,
      "loss": 0.8458,
      "step": 264550
    },
    {
      "epoch": 2.8011602733417673,
      "grad_norm": 4.242941856384277,
      "learning_rate": 3.599989413508363e-05,
      "loss": 0.8627,
      "step": 264600
    },
    {
      "epoch": 2.8016895951217706,
      "grad_norm": 4.197229385375977,
      "learning_rate": 3.599724751217447e-05,
      "loss": 0.858,
      "step": 264650
    },
    {
      "epoch": 2.802218916901774,
      "grad_norm": 4.097797870635986,
      "learning_rate": 3.59946008892653e-05,
      "loss": 0.8601,
      "step": 264700
    },
    {
      "epoch": 2.802748238681777,
      "grad_norm": 4.183643817901611,
      "learning_rate": 3.599195426635613e-05,
      "loss": 0.8596,
      "step": 264750
    },
    {
      "epoch": 2.8032775604617806,
      "grad_norm": 3.9729363918304443,
      "learning_rate": 3.598930764344696e-05,
      "loss": 0.8728,
      "step": 264800
    },
    {
      "epoch": 2.8038068822417834,
      "grad_norm": 4.134285926818848,
      "learning_rate": 3.598666102053779e-05,
      "loss": 0.869,
      "step": 264850
    },
    {
      "epoch": 2.8043362040217867,
      "grad_norm": 4.0514817237854,
      "learning_rate": 3.598401439762863e-05,
      "loss": 0.8399,
      "step": 264900
    },
    {
      "epoch": 2.80486552580179,
      "grad_norm": 3.625558614730835,
      "learning_rate": 3.598136777471946e-05,
      "loss": 0.8473,
      "step": 264950
    },
    {
      "epoch": 2.8053948475817934,
      "grad_norm": 3.8461873531341553,
      "learning_rate": 3.597872115181029e-05,
      "loss": 0.8357,
      "step": 265000
    },
    {
      "epoch": 2.8053948475817934,
      "eval_loss": 0.6414933204650879,
      "eval_runtime": 46.7406,
      "eval_samples_per_second": 3592.811,
      "eval_steps_per_second": 449.117,
      "step": 265000
    },
    {
      "epoch": 2.8059241693617967,
      "grad_norm": 4.192399024963379,
      "learning_rate": 3.597607452890112e-05,
      "loss": 0.8716,
      "step": 265050
    },
    {
      "epoch": 2.8064534911418,
      "grad_norm": 3.906346559524536,
      "learning_rate": 3.597342790599196e-05,
      "loss": 0.8615,
      "step": 265100
    },
    {
      "epoch": 2.8069828129218033,
      "grad_norm": 3.90938138961792,
      "learning_rate": 3.597078128308279e-05,
      "loss": 0.8517,
      "step": 265150
    },
    {
      "epoch": 2.8075121347018066,
      "grad_norm": 3.567220687866211,
      "learning_rate": 3.596813466017362e-05,
      "loss": 0.8436,
      "step": 265200
    },
    {
      "epoch": 2.80804145648181,
      "grad_norm": 4.162646293640137,
      "learning_rate": 3.596548803726445e-05,
      "loss": 0.8693,
      "step": 265250
    },
    {
      "epoch": 2.8085707782618132,
      "grad_norm": 4.2950968742370605,
      "learning_rate": 3.596284141435528e-05,
      "loss": 0.8603,
      "step": 265300
    },
    {
      "epoch": 2.8091001000418165,
      "grad_norm": 4.319927215576172,
      "learning_rate": 3.596019479144612e-05,
      "loss": 0.852,
      "step": 265350
    },
    {
      "epoch": 2.80962942182182,
      "grad_norm": 4.537970066070557,
      "learning_rate": 3.5957548168536945e-05,
      "loss": 0.8543,
      "step": 265400
    },
    {
      "epoch": 2.810158743601823,
      "grad_norm": 4.174731254577637,
      "learning_rate": 3.595490154562778e-05,
      "loss": 0.876,
      "step": 265450
    },
    {
      "epoch": 2.810688065381826,
      "grad_norm": 3.869988203048706,
      "learning_rate": 3.595225492271861e-05,
      "loss": 0.8726,
      "step": 265500
    },
    {
      "epoch": 2.810688065381826,
      "eval_loss": 0.642646849155426,
      "eval_runtime": 46.5682,
      "eval_samples_per_second": 3606.108,
      "eval_steps_per_second": 450.78,
      "step": 265500
    },
    {
      "epoch": 2.81121738716183,
      "grad_norm": 3.8996667861938477,
      "learning_rate": 3.594960829980945e-05,
      "loss": 0.8665,
      "step": 265550
    },
    {
      "epoch": 2.8117467089418327,
      "grad_norm": 3.9784796237945557,
      "learning_rate": 3.5946961676900274e-05,
      "loss": 0.8589,
      "step": 265600
    },
    {
      "epoch": 2.812276030721836,
      "grad_norm": 3.2851226329803467,
      "learning_rate": 3.594431505399111e-05,
      "loss": 0.8512,
      "step": 265650
    },
    {
      "epoch": 2.8128053525018393,
      "grad_norm": 3.6895751953125,
      "learning_rate": 3.594166843108194e-05,
      "loss": 0.8678,
      "step": 265700
    },
    {
      "epoch": 2.8133346742818426,
      "grad_norm": 4.0480546951293945,
      "learning_rate": 3.5939021808172777e-05,
      "loss": 0.8585,
      "step": 265750
    },
    {
      "epoch": 2.813863996061846,
      "grad_norm": 3.748467206954956,
      "learning_rate": 3.5936375185263604e-05,
      "loss": 0.8565,
      "step": 265800
    },
    {
      "epoch": 2.814393317841849,
      "grad_norm": 3.796886920928955,
      "learning_rate": 3.593372856235444e-05,
      "loss": 0.8625,
      "step": 265850
    },
    {
      "epoch": 2.8149226396218525,
      "grad_norm": 3.9375813007354736,
      "learning_rate": 3.593108193944527e-05,
      "loss": 0.831,
      "step": 265900
    },
    {
      "epoch": 2.815451961401856,
      "grad_norm": 3.4033992290496826,
      "learning_rate": 3.59284353165361e-05,
      "loss": 0.8385,
      "step": 265950
    },
    {
      "epoch": 2.815981283181859,
      "grad_norm": 3.7477338314056396,
      "learning_rate": 3.5925788693626934e-05,
      "loss": 0.8468,
      "step": 266000
    },
    {
      "epoch": 2.815981283181859,
      "eval_loss": 0.6419591903686523,
      "eval_runtime": 46.5898,
      "eval_samples_per_second": 3604.433,
      "eval_steps_per_second": 450.57,
      "step": 266000
    },
    {
      "epoch": 2.8165106049618625,
      "grad_norm": 4.014646053314209,
      "learning_rate": 3.592314207071776e-05,
      "loss": 0.8503,
      "step": 266050
    },
    {
      "epoch": 2.8170399267418658,
      "grad_norm": 3.8317437171936035,
      "learning_rate": 3.59204954478086e-05,
      "loss": 0.8714,
      "step": 266100
    },
    {
      "epoch": 2.817569248521869,
      "grad_norm": 3.953080415725708,
      "learning_rate": 3.591784882489943e-05,
      "loss": 0.8663,
      "step": 266150
    },
    {
      "epoch": 2.8180985703018724,
      "grad_norm": 3.6874897480010986,
      "learning_rate": 3.591520220199026e-05,
      "loss": 0.8557,
      "step": 266200
    },
    {
      "epoch": 2.8186278920818753,
      "grad_norm": 4.083223342895508,
      "learning_rate": 3.591255557908109e-05,
      "loss": 0.8497,
      "step": 266250
    },
    {
      "epoch": 2.819157213861879,
      "grad_norm": 4.1314778327941895,
      "learning_rate": 3.590990895617193e-05,
      "loss": 0.854,
      "step": 266300
    },
    {
      "epoch": 2.819686535641882,
      "grad_norm": 4.071208477020264,
      "learning_rate": 3.590726233326276e-05,
      "loss": 0.8457,
      "step": 266350
    },
    {
      "epoch": 2.820215857421885,
      "grad_norm": 4.053569793701172,
      "learning_rate": 3.590461571035359e-05,
      "loss": 0.8465,
      "step": 266400
    },
    {
      "epoch": 2.8207451792018885,
      "grad_norm": 3.9555776119232178,
      "learning_rate": 3.590196908744442e-05,
      "loss": 0.8596,
      "step": 266450
    },
    {
      "epoch": 2.821274500981892,
      "grad_norm": 3.9096333980560303,
      "learning_rate": 3.5899322464535254e-05,
      "loss": 0.8513,
      "step": 266500
    },
    {
      "epoch": 2.821274500981892,
      "eval_loss": 0.6391786932945251,
      "eval_runtime": 46.5823,
      "eval_samples_per_second": 3605.016,
      "eval_steps_per_second": 450.643,
      "step": 266500
    },
    {
      "epoch": 2.821803822761895,
      "grad_norm": 3.8488504886627197,
      "learning_rate": 3.589667584162609e-05,
      "loss": 0.8458,
      "step": 266550
    },
    {
      "epoch": 2.8223331445418984,
      "grad_norm": 3.862379550933838,
      "learning_rate": 3.5894029218716916e-05,
      "loss": 0.8464,
      "step": 266600
    },
    {
      "epoch": 2.8228624663219017,
      "grad_norm": 4.048119068145752,
      "learning_rate": 3.589138259580775e-05,
      "loss": 0.8562,
      "step": 266650
    },
    {
      "epoch": 2.823391788101905,
      "grad_norm": 4.060555458068848,
      "learning_rate": 3.5888735972898584e-05,
      "loss": 0.8504,
      "step": 266700
    },
    {
      "epoch": 2.8239211098819084,
      "grad_norm": 3.964207887649536,
      "learning_rate": 3.588608934998942e-05,
      "loss": 0.8509,
      "step": 266750
    },
    {
      "epoch": 2.8244504316619117,
      "grad_norm": 4.138335704803467,
      "learning_rate": 3.5883442727080245e-05,
      "loss": 0.8636,
      "step": 266800
    },
    {
      "epoch": 2.824979753441915,
      "grad_norm": 3.8441555500030518,
      "learning_rate": 3.588079610417108e-05,
      "loss": 0.8545,
      "step": 266850
    },
    {
      "epoch": 2.8255090752219183,
      "grad_norm": 4.162812232971191,
      "learning_rate": 3.5878149481261913e-05,
      "loss": 0.85,
      "step": 266900
    },
    {
      "epoch": 2.8260383970019216,
      "grad_norm": 4.117151260375977,
      "learning_rate": 3.587550285835275e-05,
      "loss": 0.8368,
      "step": 266950
    },
    {
      "epoch": 2.8265677187819245,
      "grad_norm": 4.0874223709106445,
      "learning_rate": 3.5872856235443575e-05,
      "loss": 0.8661,
      "step": 267000
    },
    {
      "epoch": 2.8265677187819245,
      "eval_loss": 0.6414088010787964,
      "eval_runtime": 46.7394,
      "eval_samples_per_second": 3592.903,
      "eval_steps_per_second": 449.129,
      "step": 267000
    },
    {
      "epoch": 2.8270970405619282,
      "grad_norm": 4.006929874420166,
      "learning_rate": 3.587020961253441e-05,
      "loss": 0.8552,
      "step": 267050
    },
    {
      "epoch": 2.827626362341931,
      "grad_norm": 3.740023374557495,
      "learning_rate": 3.5867615922083424e-05,
      "loss": 0.8584,
      "step": 267100
    },
    {
      "epoch": 2.8281556841219344,
      "grad_norm": 4.136566638946533,
      "learning_rate": 3.586496929917426e-05,
      "loss": 0.8668,
      "step": 267150
    },
    {
      "epoch": 2.8286850059019377,
      "grad_norm": 4.248349666595459,
      "learning_rate": 3.5862322676265085e-05,
      "loss": 0.8558,
      "step": 267200
    },
    {
      "epoch": 2.829214327681941,
      "grad_norm": 3.5822079181671143,
      "learning_rate": 3.585967605335592e-05,
      "loss": 0.8568,
      "step": 267250
    },
    {
      "epoch": 2.8297436494619443,
      "grad_norm": 3.7582297325134277,
      "learning_rate": 3.585702943044675e-05,
      "loss": 0.8553,
      "step": 267300
    },
    {
      "epoch": 2.8302729712419477,
      "grad_norm": 3.787473678588867,
      "learning_rate": 3.585438280753759e-05,
      "loss": 0.8639,
      "step": 267350
    },
    {
      "epoch": 2.830802293021951,
      "grad_norm": 3.90486478805542,
      "learning_rate": 3.5851736184628415e-05,
      "loss": 0.8588,
      "step": 267400
    },
    {
      "epoch": 2.8313316148019543,
      "grad_norm": 3.9823505878448486,
      "learning_rate": 3.584908956171925e-05,
      "loss": 0.8532,
      "step": 267450
    },
    {
      "epoch": 2.8318609365819576,
      "grad_norm": 4.022298336029053,
      "learning_rate": 3.584644293881008e-05,
      "loss": 0.8637,
      "step": 267500
    },
    {
      "epoch": 2.8318609365819576,
      "eval_loss": 0.6392901539802551,
      "eval_runtime": 46.5438,
      "eval_samples_per_second": 3607.997,
      "eval_steps_per_second": 451.016,
      "step": 267500
    },
    {
      "epoch": 2.832390258361961,
      "grad_norm": 4.3028974533081055,
      "learning_rate": 3.584379631590091e-05,
      "loss": 0.8348,
      "step": 267550
    },
    {
      "epoch": 2.832919580141964,
      "grad_norm": 3.7239444255828857,
      "learning_rate": 3.5841149692991744e-05,
      "loss": 0.8691,
      "step": 267600
    },
    {
      "epoch": 2.8334489019219675,
      "grad_norm": 3.911602735519409,
      "learning_rate": 3.583850307008257e-05,
      "loss": 0.8581,
      "step": 267650
    },
    {
      "epoch": 2.833978223701971,
      "grad_norm": 4.079605579376221,
      "learning_rate": 3.583585644717341e-05,
      "loss": 0.8576,
      "step": 267700
    },
    {
      "epoch": 2.8345075454819737,
      "grad_norm": 4.179864406585693,
      "learning_rate": 3.583320982426424e-05,
      "loss": 0.8601,
      "step": 267750
    },
    {
      "epoch": 2.8350368672619775,
      "grad_norm": 4.102598667144775,
      "learning_rate": 3.5830563201355074e-05,
      "loss": 0.8412,
      "step": 267800
    },
    {
      "epoch": 2.8355661890419803,
      "grad_norm": 3.7080700397491455,
      "learning_rate": 3.58279165784459e-05,
      "loss": 0.8511,
      "step": 267850
    },
    {
      "epoch": 2.8360955108219836,
      "grad_norm": 4.431516170501709,
      "learning_rate": 3.582526995553674e-05,
      "loss": 0.8482,
      "step": 267900
    },
    {
      "epoch": 2.836624832601987,
      "grad_norm": 4.422958850860596,
      "learning_rate": 3.582262333262757e-05,
      "loss": 0.86,
      "step": 267950
    },
    {
      "epoch": 2.8371541543819903,
      "grad_norm": 3.934236764907837,
      "learning_rate": 3.5819976709718404e-05,
      "loss": 0.8481,
      "step": 268000
    },
    {
      "epoch": 2.8371541543819903,
      "eval_loss": 0.6367323994636536,
      "eval_runtime": 46.6175,
      "eval_samples_per_second": 3602.292,
      "eval_steps_per_second": 450.303,
      "step": 268000
    },
    {
      "epoch": 2.8376834761619936,
      "grad_norm": 3.8515002727508545,
      "learning_rate": 3.581733008680923e-05,
      "loss": 0.8755,
      "step": 268050
    },
    {
      "epoch": 2.838212797941997,
      "grad_norm": 3.91304349899292,
      "learning_rate": 3.5814683463900065e-05,
      "loss": 0.8571,
      "step": 268100
    },
    {
      "epoch": 2.838742119722,
      "grad_norm": 3.4434800148010254,
      "learning_rate": 3.58120368409909e-05,
      "loss": 0.8564,
      "step": 268150
    },
    {
      "epoch": 2.8392714415020035,
      "grad_norm": 3.9155101776123047,
      "learning_rate": 3.5809390218081726e-05,
      "loss": 0.8436,
      "step": 268200
    },
    {
      "epoch": 2.839800763282007,
      "grad_norm": 4.166971683502197,
      "learning_rate": 3.580674359517256e-05,
      "loss": 0.849,
      "step": 268250
    },
    {
      "epoch": 2.84033008506201,
      "grad_norm": 4.020757675170898,
      "learning_rate": 3.5804096972263395e-05,
      "loss": 0.8327,
      "step": 268300
    },
    {
      "epoch": 2.8408594068420134,
      "grad_norm": 4.226865768432617,
      "learning_rate": 3.580145034935423e-05,
      "loss": 0.8441,
      "step": 268350
    },
    {
      "epoch": 2.8413887286220167,
      "grad_norm": 3.8961355686187744,
      "learning_rate": 3.5798803726445056e-05,
      "loss": 0.8705,
      "step": 268400
    },
    {
      "epoch": 2.84191805040202,
      "grad_norm": 4.02908182144165,
      "learning_rate": 3.579615710353589e-05,
      "loss": 0.845,
      "step": 268450
    },
    {
      "epoch": 2.842447372182023,
      "grad_norm": 3.946629762649536,
      "learning_rate": 3.5793510480626724e-05,
      "loss": 0.8519,
      "step": 268500
    },
    {
      "epoch": 2.842447372182023,
      "eval_loss": 0.6386033892631531,
      "eval_runtime": 46.6269,
      "eval_samples_per_second": 3601.572,
      "eval_steps_per_second": 450.213,
      "step": 268500
    },
    {
      "epoch": 2.8429766939620267,
      "grad_norm": 4.078978538513184,
      "learning_rate": 3.579086385771755e-05,
      "loss": 0.8418,
      "step": 268550
    },
    {
      "epoch": 2.8435060157420295,
      "grad_norm": 4.3714189529418945,
      "learning_rate": 3.5788217234808386e-05,
      "loss": 0.8529,
      "step": 268600
    },
    {
      "epoch": 2.844035337522033,
      "grad_norm": 4.081637382507324,
      "learning_rate": 3.578557061189921e-05,
      "loss": 0.8515,
      "step": 268650
    },
    {
      "epoch": 2.844564659302036,
      "grad_norm": 3.9507956504821777,
      "learning_rate": 3.5782923988990054e-05,
      "loss": 0.8394,
      "step": 268700
    },
    {
      "epoch": 2.8450939810820395,
      "grad_norm": 3.933652639389038,
      "learning_rate": 3.578027736608088e-05,
      "loss": 0.8451,
      "step": 268750
    },
    {
      "epoch": 2.845623302862043,
      "grad_norm": 4.207588195800781,
      "learning_rate": 3.5777630743171715e-05,
      "loss": 0.8455,
      "step": 268800
    },
    {
      "epoch": 2.846152624642046,
      "grad_norm": 3.8033266067504883,
      "learning_rate": 3.577498412026254e-05,
      "loss": 0.8524,
      "step": 268850
    },
    {
      "epoch": 2.8466819464220494,
      "grad_norm": 4.376186847686768,
      "learning_rate": 3.5772337497353383e-05,
      "loss": 0.8488,
      "step": 268900
    },
    {
      "epoch": 2.8472112682020527,
      "grad_norm": 4.254469394683838,
      "learning_rate": 3.576969087444421e-05,
      "loss": 0.8576,
      "step": 268950
    },
    {
      "epoch": 2.847740589982056,
      "grad_norm": 4.183172225952148,
      "learning_rate": 3.5767044251535045e-05,
      "loss": 0.8602,
      "step": 269000
    },
    {
      "epoch": 2.847740589982056,
      "eval_loss": 0.6390896439552307,
      "eval_runtime": 46.6048,
      "eval_samples_per_second": 3603.274,
      "eval_steps_per_second": 450.425,
      "step": 269000
    },
    {
      "epoch": 2.8482699117620593,
      "grad_norm": 3.988002061843872,
      "learning_rate": 3.576439762862587e-05,
      "loss": 0.8449,
      "step": 269050
    },
    {
      "epoch": 2.8487992335420627,
      "grad_norm": 3.9647350311279297,
      "learning_rate": 3.5761803938174894e-05,
      "loss": 0.853,
      "step": 269100
    },
    {
      "epoch": 2.849328555322066,
      "grad_norm": 4.124497413635254,
      "learning_rate": 3.575915731526572e-05,
      "loss": 0.8588,
      "step": 269150
    },
    {
      "epoch": 2.8498578771020693,
      "grad_norm": 4.290109634399414,
      "learning_rate": 3.5756510692356555e-05,
      "loss": 0.8661,
      "step": 269200
    },
    {
      "epoch": 2.850387198882072,
      "grad_norm": 4.294811725616455,
      "learning_rate": 3.575386406944738e-05,
      "loss": 0.8487,
      "step": 269250
    },
    {
      "epoch": 2.850916520662076,
      "grad_norm": 3.766413450241089,
      "learning_rate": 3.575121744653822e-05,
      "loss": 0.8657,
      "step": 269300
    },
    {
      "epoch": 2.8514458424420788,
      "grad_norm": 4.151881217956543,
      "learning_rate": 3.574857082362905e-05,
      "loss": 0.8646,
      "step": 269350
    },
    {
      "epoch": 2.851975164222082,
      "grad_norm": 3.836987018585205,
      "learning_rate": 3.5745924200719885e-05,
      "loss": 0.8421,
      "step": 269400
    },
    {
      "epoch": 2.8525044860020854,
      "grad_norm": 4.141262054443359,
      "learning_rate": 3.574327757781071e-05,
      "loss": 0.8512,
      "step": 269450
    },
    {
      "epoch": 2.8530338077820887,
      "grad_norm": 3.595778465270996,
      "learning_rate": 3.5740630954901546e-05,
      "loss": 0.8518,
      "step": 269500
    },
    {
      "epoch": 2.8530338077820887,
      "eval_loss": 0.6391342878341675,
      "eval_runtime": 46.604,
      "eval_samples_per_second": 3603.34,
      "eval_steps_per_second": 450.434,
      "step": 269500
    },
    {
      "epoch": 2.853563129562092,
      "grad_norm": 3.7821173667907715,
      "learning_rate": 3.573798433199238e-05,
      "loss": 0.8676,
      "step": 269550
    },
    {
      "epoch": 2.8540924513420953,
      "grad_norm": 3.8825366497039795,
      "learning_rate": 3.573533770908321e-05,
      "loss": 0.8506,
      "step": 269600
    },
    {
      "epoch": 2.8546217731220986,
      "grad_norm": 4.030066967010498,
      "learning_rate": 3.573269108617404e-05,
      "loss": 0.8431,
      "step": 269650
    },
    {
      "epoch": 2.855151094902102,
      "grad_norm": 4.0904998779296875,
      "learning_rate": 3.5730044463264876e-05,
      "loss": 0.8502,
      "step": 269700
    },
    {
      "epoch": 2.8556804166821053,
      "grad_norm": 4.298209190368652,
      "learning_rate": 3.572739784035571e-05,
      "loss": 0.8468,
      "step": 269750
    },
    {
      "epoch": 2.8562097384621086,
      "grad_norm": 4.36435604095459,
      "learning_rate": 3.572475121744654e-05,
      "loss": 0.8617,
      "step": 269800
    },
    {
      "epoch": 2.856739060242112,
      "grad_norm": 3.960155963897705,
      "learning_rate": 3.572210459453737e-05,
      "loss": 0.8521,
      "step": 269850
    },
    {
      "epoch": 2.857268382022115,
      "grad_norm": 3.8721327781677246,
      "learning_rate": 3.5719457971628205e-05,
      "loss": 0.8509,
      "step": 269900
    },
    {
      "epoch": 2.8577977038021185,
      "grad_norm": 4.562060832977295,
      "learning_rate": 3.571681134871904e-05,
      "loss": 0.861,
      "step": 269950
    },
    {
      "epoch": 2.8583270255821214,
      "grad_norm": 3.9304609298706055,
      "learning_rate": 3.571416472580987e-05,
      "loss": 0.8596,
      "step": 270000
    },
    {
      "epoch": 2.8583270255821214,
      "eval_loss": 0.6359062194824219,
      "eval_runtime": 46.6273,
      "eval_samples_per_second": 3601.54,
      "eval_steps_per_second": 450.209,
      "step": 270000
    },
    {
      "epoch": 2.858856347362125,
      "grad_norm": 4.036496639251709,
      "learning_rate": 3.57115181029007e-05,
      "loss": 0.8521,
      "step": 270050
    },
    {
      "epoch": 2.859385669142128,
      "grad_norm": 3.9936740398406982,
      "learning_rate": 3.5708871479991535e-05,
      "loss": 0.8469,
      "step": 270100
    },
    {
      "epoch": 2.8599149909221318,
      "grad_norm": 3.7565348148345947,
      "learning_rate": 3.570622485708236e-05,
      "loss": 0.8522,
      "step": 270150
    },
    {
      "epoch": 2.8604443127021346,
      "grad_norm": 3.9876978397369385,
      "learning_rate": 3.5703578234173196e-05,
      "loss": 0.8491,
      "step": 270200
    },
    {
      "epoch": 2.860973634482138,
      "grad_norm": 3.9304921627044678,
      "learning_rate": 3.5700931611264024e-05,
      "loss": 0.8524,
      "step": 270250
    },
    {
      "epoch": 2.8615029562621412,
      "grad_norm": 4.359764575958252,
      "learning_rate": 3.5698284988354865e-05,
      "loss": 0.8646,
      "step": 270300
    },
    {
      "epoch": 2.8620322780421446,
      "grad_norm": 3.8494105339050293,
      "learning_rate": 3.569563836544569e-05,
      "loss": 0.8413,
      "step": 270350
    },
    {
      "epoch": 2.862561599822148,
      "grad_norm": 4.184330463409424,
      "learning_rate": 3.5692991742536526e-05,
      "loss": 0.8732,
      "step": 270400
    },
    {
      "epoch": 2.863090921602151,
      "grad_norm": 3.9885923862457275,
      "learning_rate": 3.5690345119627353e-05,
      "loss": 0.8631,
      "step": 270450
    },
    {
      "epoch": 2.8636202433821545,
      "grad_norm": 3.6074142456054688,
      "learning_rate": 3.5687698496718194e-05,
      "loss": 0.8392,
      "step": 270500
    },
    {
      "epoch": 2.8636202433821545,
      "eval_loss": 0.6338162422180176,
      "eval_runtime": 46.5784,
      "eval_samples_per_second": 3605.318,
      "eval_steps_per_second": 450.681,
      "step": 270500
    },
    {
      "epoch": 2.864149565162158,
      "grad_norm": 3.974635601043701,
      "learning_rate": 3.568505187380902e-05,
      "loss": 0.8506,
      "step": 270550
    },
    {
      "epoch": 2.864678886942161,
      "grad_norm": 4.049594879150391,
      "learning_rate": 3.5682405250899856e-05,
      "loss": 0.8486,
      "step": 270600
    },
    {
      "epoch": 2.8652082087221644,
      "grad_norm": 3.631824016571045,
      "learning_rate": 3.567975862799068e-05,
      "loss": 0.8609,
      "step": 270650
    },
    {
      "epoch": 2.8657375305021677,
      "grad_norm": 4.091927528381348,
      "learning_rate": 3.567711200508152e-05,
      "loss": 0.8605,
      "step": 270700
    },
    {
      "epoch": 2.8662668522821706,
      "grad_norm": 3.791806936264038,
      "learning_rate": 3.567446538217235e-05,
      "loss": 0.849,
      "step": 270750
    },
    {
      "epoch": 2.8667961740621744,
      "grad_norm": 3.6617157459259033,
      "learning_rate": 3.567181875926318e-05,
      "loss": 0.8395,
      "step": 270800
    },
    {
      "epoch": 2.867325495842177,
      "grad_norm": 3.696443796157837,
      "learning_rate": 3.566917213635401e-05,
      "loss": 0.8512,
      "step": 270850
    },
    {
      "epoch": 2.867854817622181,
      "grad_norm": 3.7431087493896484,
      "learning_rate": 3.566652551344485e-05,
      "loss": 0.8308,
      "step": 270900
    },
    {
      "epoch": 2.868384139402184,
      "grad_norm": 3.799753189086914,
      "learning_rate": 3.566387889053568e-05,
      "loss": 0.8499,
      "step": 270950
    },
    {
      "epoch": 2.868913461182187,
      "grad_norm": 3.9273016452789307,
      "learning_rate": 3.566123226762651e-05,
      "loss": 0.8493,
      "step": 271000
    },
    {
      "epoch": 2.868913461182187,
      "eval_loss": 0.6325061917304993,
      "eval_runtime": 46.5701,
      "eval_samples_per_second": 3605.965,
      "eval_steps_per_second": 450.762,
      "step": 271000
    },
    {
      "epoch": 2.8694427829621905,
      "grad_norm": 4.141202449798584,
      "learning_rate": 3.565858564471734e-05,
      "loss": 0.8485,
      "step": 271050
    },
    {
      "epoch": 2.8699721047421938,
      "grad_norm": 3.508296489715576,
      "learning_rate": 3.565599195426636e-05,
      "loss": 0.8479,
      "step": 271100
    },
    {
      "epoch": 2.870501426522197,
      "grad_norm": 3.706284523010254,
      "learning_rate": 3.565334533135719e-05,
      "loss": 0.8489,
      "step": 271150
    },
    {
      "epoch": 2.8710307483022004,
      "grad_norm": 3.9995338916778564,
      "learning_rate": 3.565069870844802e-05,
      "loss": 0.8447,
      "step": 271200
    },
    {
      "epoch": 2.8715600700822037,
      "grad_norm": 3.674099922180176,
      "learning_rate": 3.564805208553885e-05,
      "loss": 0.8522,
      "step": 271250
    },
    {
      "epoch": 2.872089391862207,
      "grad_norm": 4.125051021575928,
      "learning_rate": 3.564540546262969e-05,
      "loss": 0.8516,
      "step": 271300
    },
    {
      "epoch": 2.8726187136422103,
      "grad_norm": 4.100374698638916,
      "learning_rate": 3.564275883972052e-05,
      "loss": 0.8591,
      "step": 271350
    },
    {
      "epoch": 2.8731480354222136,
      "grad_norm": 3.9369239807128906,
      "learning_rate": 3.564011221681135e-05,
      "loss": 0.8394,
      "step": 271400
    },
    {
      "epoch": 2.873677357202217,
      "grad_norm": 4.155711650848389,
      "learning_rate": 3.563746559390218e-05,
      "loss": 0.8528,
      "step": 271450
    },
    {
      "epoch": 2.87420667898222,
      "grad_norm": 4.2317047119140625,
      "learning_rate": 3.5634818970993016e-05,
      "loss": 0.85,
      "step": 271500
    },
    {
      "epoch": 2.87420667898222,
      "eval_loss": 0.6367151737213135,
      "eval_runtime": 46.642,
      "eval_samples_per_second": 3600.406,
      "eval_steps_per_second": 450.067,
      "step": 271500
    },
    {
      "epoch": 2.8747360007622236,
      "grad_norm": 4.155524730682373,
      "learning_rate": 3.563217234808385e-05,
      "loss": 0.8576,
      "step": 271550
    },
    {
      "epoch": 2.8752653225422264,
      "grad_norm": 3.615723133087158,
      "learning_rate": 3.562952572517468e-05,
      "loss": 0.8314,
      "step": 271600
    },
    {
      "epoch": 2.87579464432223,
      "grad_norm": 4.472925186157227,
      "learning_rate": 3.562687910226551e-05,
      "loss": 0.8496,
      "step": 271650
    },
    {
      "epoch": 2.876323966102233,
      "grad_norm": 3.821030616760254,
      "learning_rate": 3.5624285411814526e-05,
      "loss": 0.8509,
      "step": 271700
    },
    {
      "epoch": 2.8768532878822364,
      "grad_norm": 4.095244407653809,
      "learning_rate": 3.562163878890536e-05,
      "loss": 0.8386,
      "step": 271750
    },
    {
      "epoch": 2.8773826096622397,
      "grad_norm": 3.654531478881836,
      "learning_rate": 3.561899216599619e-05,
      "loss": 0.8619,
      "step": 271800
    },
    {
      "epoch": 2.877911931442243,
      "grad_norm": 4.538516044616699,
      "learning_rate": 3.561634554308702e-05,
      "loss": 0.8508,
      "step": 271850
    },
    {
      "epoch": 2.8784412532222463,
      "grad_norm": 4.2362518310546875,
      "learning_rate": 3.5613698920177856e-05,
      "loss": 0.8586,
      "step": 271900
    },
    {
      "epoch": 2.8789705750022496,
      "grad_norm": 3.7635014057159424,
      "learning_rate": 3.561105229726869e-05,
      "loss": 0.844,
      "step": 271950
    },
    {
      "epoch": 2.879499896782253,
      "grad_norm": 3.9670419692993164,
      "learning_rate": 3.560840567435952e-05,
      "loss": 0.8415,
      "step": 272000
    },
    {
      "epoch": 2.879499896782253,
      "eval_loss": 0.6329368352890015,
      "eval_runtime": 46.6945,
      "eval_samples_per_second": 3596.355,
      "eval_steps_per_second": 449.56,
      "step": 272000
    },
    {
      "epoch": 2.8800292185622562,
      "grad_norm": 4.029603958129883,
      "learning_rate": 3.560575905145035e-05,
      "loss": 0.854,
      "step": 272050
    },
    {
      "epoch": 2.8805585403422596,
      "grad_norm": 3.819127082824707,
      "learning_rate": 3.5603112428541186e-05,
      "loss": 0.844,
      "step": 272100
    },
    {
      "epoch": 2.881087862122263,
      "grad_norm": 4.2336812019348145,
      "learning_rate": 3.560046580563201e-05,
      "loss": 0.844,
      "step": 272150
    },
    {
      "epoch": 2.881617183902266,
      "grad_norm": 3.6686244010925293,
      "learning_rate": 3.559781918272285e-05,
      "loss": 0.8486,
      "step": 272200
    },
    {
      "epoch": 2.882146505682269,
      "grad_norm": 4.20747709274292,
      "learning_rate": 3.5595172559813674e-05,
      "loss": 0.8533,
      "step": 272250
    },
    {
      "epoch": 2.882675827462273,
      "grad_norm": 3.9243133068084717,
      "learning_rate": 3.5592525936904515e-05,
      "loss": 0.8557,
      "step": 272300
    },
    {
      "epoch": 2.8832051492422757,
      "grad_norm": 3.7149581909179688,
      "learning_rate": 3.558987931399534e-05,
      "loss": 0.8471,
      "step": 272350
    },
    {
      "epoch": 2.8837344710222794,
      "grad_norm": 3.990736246109009,
      "learning_rate": 3.558723269108618e-05,
      "loss": 0.8388,
      "step": 272400
    },
    {
      "epoch": 2.8842637928022823,
      "grad_norm": 3.9678664207458496,
      "learning_rate": 3.5584586068177004e-05,
      "loss": 0.8485,
      "step": 272450
    },
    {
      "epoch": 2.8847931145822856,
      "grad_norm": 4.004377365112305,
      "learning_rate": 3.5581939445267845e-05,
      "loss": 0.838,
      "step": 272500
    },
    {
      "epoch": 2.8847931145822856,
      "eval_loss": 0.6326607465744019,
      "eval_runtime": 46.5832,
      "eval_samples_per_second": 3604.944,
      "eval_steps_per_second": 450.634,
      "step": 272500
    },
    {
      "epoch": 2.885322436362289,
      "grad_norm": 3.700718641281128,
      "learning_rate": 3.557929282235867e-05,
      "loss": 0.8554,
      "step": 272550
    },
    {
      "epoch": 2.8858517581422922,
      "grad_norm": 4.096814155578613,
      "learning_rate": 3.5576646199449506e-05,
      "loss": 0.8522,
      "step": 272600
    },
    {
      "epoch": 2.8863810799222955,
      "grad_norm": 3.920884847640991,
      "learning_rate": 3.5573999576540334e-05,
      "loss": 0.8359,
      "step": 272650
    },
    {
      "epoch": 2.886910401702299,
      "grad_norm": 4.040319442749023,
      "learning_rate": 3.557135295363117e-05,
      "loss": 0.8555,
      "step": 272700
    },
    {
      "epoch": 2.887439723482302,
      "grad_norm": 4.0374226570129395,
      "learning_rate": 3.5568706330722e-05,
      "loss": 0.8453,
      "step": 272750
    },
    {
      "epoch": 2.8879690452623055,
      "grad_norm": 4.006245136260986,
      "learning_rate": 3.556605970781283e-05,
      "loss": 0.8682,
      "step": 272800
    },
    {
      "epoch": 2.888498367042309,
      "grad_norm": 4.307013034820557,
      "learning_rate": 3.556341308490366e-05,
      "loss": 0.8585,
      "step": 272850
    },
    {
      "epoch": 2.889027688822312,
      "grad_norm": 4.390113830566406,
      "learning_rate": 3.55607664619945e-05,
      "loss": 0.8409,
      "step": 272900
    },
    {
      "epoch": 2.8895570106023154,
      "grad_norm": 3.5782127380371094,
      "learning_rate": 3.555811983908533e-05,
      "loss": 0.8709,
      "step": 272950
    },
    {
      "epoch": 2.8900863323823183,
      "grad_norm": 3.737046718597412,
      "learning_rate": 3.555547321617616e-05,
      "loss": 0.8645,
      "step": 273000
    },
    {
      "epoch": 2.8900863323823183,
      "eval_loss": 0.6325788497924805,
      "eval_runtime": 46.5791,
      "eval_samples_per_second": 3605.266,
      "eval_steps_per_second": 450.674,
      "step": 273000
    },
    {
      "epoch": 2.890615654162322,
      "grad_norm": 3.9594602584838867,
      "learning_rate": 3.555282659326699e-05,
      "loss": 0.8425,
      "step": 273050
    },
    {
      "epoch": 2.891144975942325,
      "grad_norm": 3.801236629486084,
      "learning_rate": 3.555017997035783e-05,
      "loss": 0.8557,
      "step": 273100
    },
    {
      "epoch": 2.8916742977223286,
      "grad_norm": 3.9998669624328613,
      "learning_rate": 3.554753334744866e-05,
      "loss": 0.8587,
      "step": 273150
    },
    {
      "epoch": 2.8922036195023315,
      "grad_norm": 3.9689202308654785,
      "learning_rate": 3.554488672453949e-05,
      "loss": 0.8406,
      "step": 273200
    },
    {
      "epoch": 2.892732941282335,
      "grad_norm": 3.89668869972229,
      "learning_rate": 3.554224010163032e-05,
      "loss": 0.8446,
      "step": 273250
    },
    {
      "epoch": 2.893262263062338,
      "grad_norm": 4.22653341293335,
      "learning_rate": 3.553959347872116e-05,
      "loss": 0.854,
      "step": 273300
    },
    {
      "epoch": 2.8937915848423414,
      "grad_norm": 3.7807419300079346,
      "learning_rate": 3.5536946855811984e-05,
      "loss": 0.868,
      "step": 273350
    },
    {
      "epoch": 2.8943209066223448,
      "grad_norm": 4.091305255889893,
      "learning_rate": 3.553430023290282e-05,
      "loss": 0.8544,
      "step": 273400
    },
    {
      "epoch": 2.894850228402348,
      "grad_norm": 3.85444974899292,
      "learning_rate": 3.5531653609993645e-05,
      "loss": 0.8399,
      "step": 273450
    },
    {
      "epoch": 2.8953795501823514,
      "grad_norm": 3.941599130630493,
      "learning_rate": 3.5529006987084486e-05,
      "loss": 0.8536,
      "step": 273500
    },
    {
      "epoch": 2.8953795501823514,
      "eval_loss": 0.6315901875495911,
      "eval_runtime": 46.5773,
      "eval_samples_per_second": 3605.404,
      "eval_steps_per_second": 450.692,
      "step": 273500
    },
    {
      "epoch": 2.8959088719623547,
      "grad_norm": 4.022270202636719,
      "learning_rate": 3.5526360364175314e-05,
      "loss": 0.8526,
      "step": 273550
    },
    {
      "epoch": 2.896438193742358,
      "grad_norm": 3.9247772693634033,
      "learning_rate": 3.552371374126615e-05,
      "loss": 0.8636,
      "step": 273600
    },
    {
      "epoch": 2.8969675155223613,
      "grad_norm": 4.243120193481445,
      "learning_rate": 3.5521067118356975e-05,
      "loss": 0.8507,
      "step": 273650
    },
    {
      "epoch": 2.8974968373023646,
      "grad_norm": 3.8509814739227295,
      "learning_rate": 3.5518420495447816e-05,
      "loss": 0.8415,
      "step": 273700
    },
    {
      "epoch": 2.8980261590823675,
      "grad_norm": 4.1341681480407715,
      "learning_rate": 3.551577387253864e-05,
      "loss": 0.8518,
      "step": 273750
    },
    {
      "epoch": 2.8985554808623712,
      "grad_norm": 4.309733867645264,
      "learning_rate": 3.551312724962948e-05,
      "loss": 0.8568,
      "step": 273800
    },
    {
      "epoch": 2.899084802642374,
      "grad_norm": 3.9509198665618896,
      "learning_rate": 3.5510480626720305e-05,
      "loss": 0.8506,
      "step": 273850
    },
    {
      "epoch": 2.899614124422378,
      "grad_norm": 3.907492160797119,
      "learning_rate": 3.550783400381114e-05,
      "loss": 0.8418,
      "step": 273900
    },
    {
      "epoch": 2.9001434462023807,
      "grad_norm": 3.9798808097839355,
      "learning_rate": 3.550518738090197e-05,
      "loss": 0.8439,
      "step": 273950
    },
    {
      "epoch": 2.900672767982384,
      "grad_norm": 3.853472948074341,
      "learning_rate": 3.55025407579928e-05,
      "loss": 0.8268,
      "step": 274000
    },
    {
      "epoch": 2.900672767982384,
      "eval_loss": 0.6298850774765015,
      "eval_runtime": 46.6725,
      "eval_samples_per_second": 3598.048,
      "eval_steps_per_second": 449.772,
      "step": 274000
    },
    {
      "epoch": 2.9012020897623874,
      "grad_norm": 3.849043846130371,
      "learning_rate": 3.5499894135083634e-05,
      "loss": 0.8679,
      "step": 274050
    },
    {
      "epoch": 2.9017314115423907,
      "grad_norm": 4.1301140785217285,
      "learning_rate": 3.549724751217447e-05,
      "loss": 0.8607,
      "step": 274100
    },
    {
      "epoch": 2.902260733322394,
      "grad_norm": 4.328882217407227,
      "learning_rate": 3.54946008892653e-05,
      "loss": 0.8553,
      "step": 274150
    },
    {
      "epoch": 2.9027900551023973,
      "grad_norm": 4.1908392906188965,
      "learning_rate": 3.549195426635613e-05,
      "loss": 0.8458,
      "step": 274200
    },
    {
      "epoch": 2.9033193768824006,
      "grad_norm": 3.6526122093200684,
      "learning_rate": 3.5489307643446964e-05,
      "loss": 0.8559,
      "step": 274250
    },
    {
      "epoch": 2.903848698662404,
      "grad_norm": 4.1121625900268555,
      "learning_rate": 3.548671395299598e-05,
      "loss": 0.8522,
      "step": 274300
    },
    {
      "epoch": 2.9043780204424072,
      "grad_norm": 3.9964795112609863,
      "learning_rate": 3.548406733008681e-05,
      "loss": 0.8511,
      "step": 274350
    },
    {
      "epoch": 2.9049073422224105,
      "grad_norm": 4.35731840133667,
      "learning_rate": 3.548142070717764e-05,
      "loss": 0.8418,
      "step": 274400
    },
    {
      "epoch": 2.905436664002414,
      "grad_norm": 4.1131391525268555,
      "learning_rate": 3.5478774084268474e-05,
      "loss": 0.8557,
      "step": 274450
    },
    {
      "epoch": 2.9059659857824167,
      "grad_norm": 4.19211483001709,
      "learning_rate": 3.547612746135931e-05,
      "loss": 0.8583,
      "step": 274500
    },
    {
      "epoch": 2.9059659857824167,
      "eval_loss": 0.6295409798622131,
      "eval_runtime": 46.6061,
      "eval_samples_per_second": 3603.175,
      "eval_steps_per_second": 450.413,
      "step": 274500
    },
    {
      "epoch": 2.9064953075624205,
      "grad_norm": 4.391176223754883,
      "learning_rate": 3.547348083845014e-05,
      "loss": 0.8355,
      "step": 274550
    },
    {
      "epoch": 2.9070246293424233,
      "grad_norm": 4.203173637390137,
      "learning_rate": 3.547083421554097e-05,
      "loss": 0.8504,
      "step": 274600
    },
    {
      "epoch": 2.907553951122427,
      "grad_norm": 4.124401569366455,
      "learning_rate": 3.5468187592631804e-05,
      "loss": 0.8448,
      "step": 274650
    },
    {
      "epoch": 2.90808327290243,
      "grad_norm": 4.011610984802246,
      "learning_rate": 3.546554096972264e-05,
      "loss": 0.8619,
      "step": 274700
    },
    {
      "epoch": 2.9086125946824333,
      "grad_norm": 3.666252374649048,
      "learning_rate": 3.546289434681347e-05,
      "loss": 0.854,
      "step": 274750
    },
    {
      "epoch": 2.9091419164624366,
      "grad_norm": 4.068704128265381,
      "learning_rate": 3.54602477239043e-05,
      "loss": 0.8374,
      "step": 274800
    },
    {
      "epoch": 2.90967123824244,
      "grad_norm": 3.8874871730804443,
      "learning_rate": 3.5457601100995133e-05,
      "loss": 0.8608,
      "step": 274850
    },
    {
      "epoch": 2.910200560022443,
      "grad_norm": 4.501458168029785,
      "learning_rate": 3.545495447808597e-05,
      "loss": 0.8625,
      "step": 274900
    },
    {
      "epoch": 2.9107298818024465,
      "grad_norm": 4.071955680847168,
      "learning_rate": 3.5452307855176795e-05,
      "loss": 0.8508,
      "step": 274950
    },
    {
      "epoch": 2.91125920358245,
      "grad_norm": 3.866641044616699,
      "learning_rate": 3.544966123226763e-05,
      "loss": 0.8753,
      "step": 275000
    },
    {
      "epoch": 2.91125920358245,
      "eval_loss": 0.6298742890357971,
      "eval_runtime": 46.6495,
      "eval_samples_per_second": 3599.827,
      "eval_steps_per_second": 449.994,
      "step": 275000
    },
    {
      "epoch": 2.911788525362453,
      "grad_norm": 4.003485679626465,
      "learning_rate": 3.5447014609358456e-05,
      "loss": 0.85,
      "step": 275050
    },
    {
      "epoch": 2.9123178471424565,
      "grad_norm": 4.440498352050781,
      "learning_rate": 3.54443679864493e-05,
      "loss": 0.8624,
      "step": 275100
    },
    {
      "epoch": 2.9128471689224598,
      "grad_norm": 3.9637935161590576,
      "learning_rate": 3.5441721363540124e-05,
      "loss": 0.8497,
      "step": 275150
    },
    {
      "epoch": 2.913376490702463,
      "grad_norm": 3.749086380004883,
      "learning_rate": 3.543907474063096e-05,
      "loss": 0.8486,
      "step": 275200
    },
    {
      "epoch": 2.913905812482466,
      "grad_norm": 3.8570358753204346,
      "learning_rate": 3.5436428117721786e-05,
      "loss": 0.845,
      "step": 275250
    },
    {
      "epoch": 2.9144351342624697,
      "grad_norm": 3.8201210498809814,
      "learning_rate": 3.543378149481263e-05,
      "loss": 0.8477,
      "step": 275300
    },
    {
      "epoch": 2.9149644560424726,
      "grad_norm": 4.059825420379639,
      "learning_rate": 3.5431134871903454e-05,
      "loss": 0.8423,
      "step": 275350
    },
    {
      "epoch": 2.9154937778224763,
      "grad_norm": 3.8724470138549805,
      "learning_rate": 3.542848824899429e-05,
      "loss": 0.8392,
      "step": 275400
    },
    {
      "epoch": 2.916023099602479,
      "grad_norm": 4.281963348388672,
      "learning_rate": 3.5425841626085116e-05,
      "loss": 0.8496,
      "step": 275450
    },
    {
      "epoch": 2.9165524213824825,
      "grad_norm": 4.2556047439575195,
      "learning_rate": 3.542319500317595e-05,
      "loss": 0.848,
      "step": 275500
    },
    {
      "epoch": 2.9165524213824825,
      "eval_loss": 0.6281244158744812,
      "eval_runtime": 46.5758,
      "eval_samples_per_second": 3605.524,
      "eval_steps_per_second": 450.707,
      "step": 275500
    },
    {
      "epoch": 2.917081743162486,
      "grad_norm": 4.1546630859375,
      "learning_rate": 3.5420548380266784e-05,
      "loss": 0.8393,
      "step": 275550
    },
    {
      "epoch": 2.917611064942489,
      "grad_norm": 4.382198333740234,
      "learning_rate": 3.541790175735761e-05,
      "loss": 0.8475,
      "step": 275600
    },
    {
      "epoch": 2.9181403867224924,
      "grad_norm": 3.9042603969573975,
      "learning_rate": 3.5415255134448445e-05,
      "loss": 0.8472,
      "step": 275650
    },
    {
      "epoch": 2.9186697085024957,
      "grad_norm": 4.137210369110107,
      "learning_rate": 3.541260851153928e-05,
      "loss": 0.8484,
      "step": 275700
    },
    {
      "epoch": 2.919199030282499,
      "grad_norm": 3.6963624954223633,
      "learning_rate": 3.540996188863011e-05,
      "loss": 0.843,
      "step": 275750
    },
    {
      "epoch": 2.9197283520625024,
      "grad_norm": 4.134023666381836,
      "learning_rate": 3.540731526572094e-05,
      "loss": 0.835,
      "step": 275800
    },
    {
      "epoch": 2.9202576738425057,
      "grad_norm": 3.822385549545288,
      "learning_rate": 3.5404668642811775e-05,
      "loss": 0.8286,
      "step": 275850
    },
    {
      "epoch": 2.920786995622509,
      "grad_norm": 3.8520188331604004,
      "learning_rate": 3.540202201990261e-05,
      "loss": 0.8462,
      "step": 275900
    },
    {
      "epoch": 2.9213163174025123,
      "grad_norm": 3.977832317352295,
      "learning_rate": 3.5399375396993436e-05,
      "loss": 0.8452,
      "step": 275950
    },
    {
      "epoch": 2.9218456391825156,
      "grad_norm": 3.8690319061279297,
      "learning_rate": 3.539672877408427e-05,
      "loss": 0.8495,
      "step": 276000
    },
    {
      "epoch": 2.9218456391825156,
      "eval_loss": 0.6288321614265442,
      "eval_runtime": 46.5416,
      "eval_samples_per_second": 3608.168,
      "eval_steps_per_second": 451.037,
      "step": 276000
    },
    {
      "epoch": 2.922374960962519,
      "grad_norm": 3.6267735958099365,
      "learning_rate": 3.53940821511751e-05,
      "loss": 0.827,
      "step": 276050
    },
    {
      "epoch": 2.922904282742522,
      "grad_norm": 4.18142557144165,
      "learning_rate": 3.539143552826594e-05,
      "loss": 0.8556,
      "step": 276100
    },
    {
      "epoch": 2.9234336045225255,
      "grad_norm": 3.8604578971862793,
      "learning_rate": 3.5388788905356766e-05,
      "loss": 0.8451,
      "step": 276150
    },
    {
      "epoch": 2.9239629263025284,
      "grad_norm": 4.115235805511475,
      "learning_rate": 3.53861422824476e-05,
      "loss": 0.8514,
      "step": 276200
    },
    {
      "epoch": 2.9244922480825317,
      "grad_norm": 3.6408791542053223,
      "learning_rate": 3.538349565953843e-05,
      "loss": 0.8482,
      "step": 276250
    },
    {
      "epoch": 2.925021569862535,
      "grad_norm": 4.055780410766602,
      "learning_rate": 3.538084903662927e-05,
      "loss": 0.845,
      "step": 276300
    },
    {
      "epoch": 2.9255508916425383,
      "grad_norm": 4.003499507904053,
      "learning_rate": 3.5378202413720095e-05,
      "loss": 0.8502,
      "step": 276350
    },
    {
      "epoch": 2.9260802134225417,
      "grad_norm": 3.9504811763763428,
      "learning_rate": 3.537555579081093e-05,
      "loss": 0.8309,
      "step": 276400
    },
    {
      "epoch": 2.926609535202545,
      "grad_norm": 4.135168552398682,
      "learning_rate": 3.537290916790176e-05,
      "loss": 0.8513,
      "step": 276450
    },
    {
      "epoch": 2.9271388569825483,
      "grad_norm": 3.7621757984161377,
      "learning_rate": 3.537026254499259e-05,
      "loss": 0.8486,
      "step": 276500
    },
    {
      "epoch": 2.9271388569825483,
      "eval_loss": 0.6263979077339172,
      "eval_runtime": 46.677,
      "eval_samples_per_second": 3597.707,
      "eval_steps_per_second": 449.729,
      "step": 276500
    },
    {
      "epoch": 2.9276681787625516,
      "grad_norm": 4.040857315063477,
      "learning_rate": 3.5367615922083425e-05,
      "loss": 0.8483,
      "step": 276550
    },
    {
      "epoch": 2.928197500542555,
      "grad_norm": 4.210868835449219,
      "learning_rate": 3.536496929917425e-05,
      "loss": 0.8483,
      "step": 276600
    },
    {
      "epoch": 2.928726822322558,
      "grad_norm": 3.582533597946167,
      "learning_rate": 3.5362322676265086e-05,
      "loss": 0.8465,
      "step": 276650
    },
    {
      "epoch": 2.9292561441025615,
      "grad_norm": 4.219508647918701,
      "learning_rate": 3.5359676053355914e-05,
      "loss": 0.8523,
      "step": 276700
    },
    {
      "epoch": 2.929785465882565,
      "grad_norm": 3.8050403594970703,
      "learning_rate": 3.5357029430446755e-05,
      "loss": 0.852,
      "step": 276750
    },
    {
      "epoch": 2.930314787662568,
      "grad_norm": 4.088647365570068,
      "learning_rate": 3.535438280753758e-05,
      "loss": 0.8419,
      "step": 276800
    },
    {
      "epoch": 2.930844109442571,
      "grad_norm": 3.849562168121338,
      "learning_rate": 3.5351736184628416e-05,
      "loss": 0.8448,
      "step": 276850
    },
    {
      "epoch": 2.9313734312225748,
      "grad_norm": 4.150054931640625,
      "learning_rate": 3.5349089561719243e-05,
      "loss": 0.8429,
      "step": 276900
    },
    {
      "epoch": 2.9319027530025776,
      "grad_norm": 4.067559719085693,
      "learning_rate": 3.5346442938810084e-05,
      "loss": 0.8392,
      "step": 276950
    },
    {
      "epoch": 2.932432074782581,
      "grad_norm": 3.7387917041778564,
      "learning_rate": 3.534379631590091e-05,
      "loss": 0.8435,
      "step": 277000
    },
    {
      "epoch": 2.932432074782581,
      "eval_loss": 0.628771960735321,
      "eval_runtime": 46.6009,
      "eval_samples_per_second": 3603.582,
      "eval_steps_per_second": 450.464,
      "step": 277000
    },
    {
      "epoch": 2.9329613965625843,
      "grad_norm": 3.9681386947631836,
      "learning_rate": 3.5341149692991746e-05,
      "loss": 0.8442,
      "step": 277050
    },
    {
      "epoch": 2.9334907183425876,
      "grad_norm": 4.193036079406738,
      "learning_rate": 3.533850307008257e-05,
      "loss": 0.8346,
      "step": 277100
    },
    {
      "epoch": 2.934020040122591,
      "grad_norm": 4.05622673034668,
      "learning_rate": 3.533585644717341e-05,
      "loss": 0.8515,
      "step": 277150
    },
    {
      "epoch": 2.934549361902594,
      "grad_norm": 4.21406364440918,
      "learning_rate": 3.533320982426424e-05,
      "loss": 0.8402,
      "step": 277200
    },
    {
      "epoch": 2.9350786836825975,
      "grad_norm": 4.102391242980957,
      "learning_rate": 3.533056320135507e-05,
      "loss": 0.8622,
      "step": 277250
    },
    {
      "epoch": 2.935608005462601,
      "grad_norm": 4.040306568145752,
      "learning_rate": 3.53279165784459e-05,
      "loss": 0.8498,
      "step": 277300
    },
    {
      "epoch": 2.936137327242604,
      "grad_norm": 4.009486675262451,
      "learning_rate": 3.532526995553674e-05,
      "loss": 0.8234,
      "step": 277350
    },
    {
      "epoch": 2.9366666490226074,
      "grad_norm": 4.372391700744629,
      "learning_rate": 3.532262333262757e-05,
      "loss": 0.8389,
      "step": 277400
    },
    {
      "epoch": 2.9371959708026107,
      "grad_norm": 3.9737446308135986,
      "learning_rate": 3.53199767097184e-05,
      "loss": 0.851,
      "step": 277450
    },
    {
      "epoch": 2.937725292582614,
      "grad_norm": 3.86186146736145,
      "learning_rate": 3.531738301926741e-05,
      "loss": 0.8398,
      "step": 277500
    },
    {
      "epoch": 2.937725292582614,
      "eval_loss": 0.6251583695411682,
      "eval_runtime": 46.5442,
      "eval_samples_per_second": 3607.971,
      "eval_steps_per_second": 451.012,
      "step": 277500
    },
    {
      "epoch": 2.9382546143626174,
      "grad_norm": 3.5219194889068604,
      "learning_rate": 3.531473639635825e-05,
      "loss": 0.8502,
      "step": 277550
    },
    {
      "epoch": 2.9387839361426202,
      "grad_norm": 3.927673101425171,
      "learning_rate": 3.531208977344908e-05,
      "loss": 0.8468,
      "step": 277600
    },
    {
      "epoch": 2.939313257922624,
      "grad_norm": 4.166903018951416,
      "learning_rate": 3.530944315053991e-05,
      "loss": 0.8334,
      "step": 277650
    },
    {
      "epoch": 2.939842579702627,
      "grad_norm": 4.213497161865234,
      "learning_rate": 3.530679652763074e-05,
      "loss": 0.8443,
      "step": 277700
    },
    {
      "epoch": 2.94037190148263,
      "grad_norm": 3.666959285736084,
      "learning_rate": 3.530414990472158e-05,
      "loss": 0.8516,
      "step": 277750
    },
    {
      "epoch": 2.9409012232626335,
      "grad_norm": 3.9387922286987305,
      "learning_rate": 3.530150328181241e-05,
      "loss": 0.8467,
      "step": 277800
    },
    {
      "epoch": 2.941430545042637,
      "grad_norm": 4.184382915496826,
      "learning_rate": 3.529885665890324e-05,
      "loss": 0.8449,
      "step": 277850
    },
    {
      "epoch": 2.94195986682264,
      "grad_norm": 3.665395736694336,
      "learning_rate": 3.529621003599407e-05,
      "loss": 0.841,
      "step": 277900
    },
    {
      "epoch": 2.9424891886026434,
      "grad_norm": 3.9009413719177246,
      "learning_rate": 3.5293563413084906e-05,
      "loss": 0.8477,
      "step": 277950
    },
    {
      "epoch": 2.9430185103826467,
      "grad_norm": 3.805306911468506,
      "learning_rate": 3.529091679017574e-05,
      "loss": 0.8299,
      "step": 278000
    },
    {
      "epoch": 2.9430185103826467,
      "eval_loss": 0.6263098120689392,
      "eval_runtime": 46.5525,
      "eval_samples_per_second": 3607.326,
      "eval_steps_per_second": 450.932,
      "step": 278000
    },
    {
      "epoch": 2.94354783216265,
      "grad_norm": 3.745560884475708,
      "learning_rate": 3.528827016726657e-05,
      "loss": 0.8491,
      "step": 278050
    },
    {
      "epoch": 2.9440771539426533,
      "grad_norm": 4.093855381011963,
      "learning_rate": 3.52856235443574e-05,
      "loss": 0.8512,
      "step": 278100
    },
    {
      "epoch": 2.9446064757226567,
      "grad_norm": 3.8805460929870605,
      "learning_rate": 3.5282976921448236e-05,
      "loss": 0.8447,
      "step": 278150
    },
    {
      "epoch": 2.94513579750266,
      "grad_norm": 4.126753330230713,
      "learning_rate": 3.528033029853906e-05,
      "loss": 0.8548,
      "step": 278200
    },
    {
      "epoch": 2.9456651192826633,
      "grad_norm": 4.245975971221924,
      "learning_rate": 3.52776836756299e-05,
      "loss": 0.85,
      "step": 278250
    },
    {
      "epoch": 2.9461944410626666,
      "grad_norm": 3.892803907394409,
      "learning_rate": 3.5275037052720725e-05,
      "loss": 0.8384,
      "step": 278300
    },
    {
      "epoch": 2.9467237628426695,
      "grad_norm": 4.281065940856934,
      "learning_rate": 3.5272390429811565e-05,
      "loss": 0.85,
      "step": 278350
    },
    {
      "epoch": 2.947253084622673,
      "grad_norm": 4.280494689941406,
      "learning_rate": 3.526974380690239e-05,
      "loss": 0.8541,
      "step": 278400
    },
    {
      "epoch": 2.947782406402676,
      "grad_norm": 3.9349544048309326,
      "learning_rate": 3.526709718399323e-05,
      "loss": 0.8299,
      "step": 278450
    },
    {
      "epoch": 2.9483117281826794,
      "grad_norm": 3.9898247718811035,
      "learning_rate": 3.5264450561084054e-05,
      "loss": 0.8512,
      "step": 278500
    },
    {
      "epoch": 2.9483117281826794,
      "eval_loss": 0.624671459197998,
      "eval_runtime": 46.6167,
      "eval_samples_per_second": 3602.355,
      "eval_steps_per_second": 450.311,
      "step": 278500
    },
    {
      "epoch": 2.9488410499626827,
      "grad_norm": 3.559617519378662,
      "learning_rate": 3.5261803938174895e-05,
      "loss": 0.8481,
      "step": 278550
    },
    {
      "epoch": 2.949370371742686,
      "grad_norm": 3.646575689315796,
      "learning_rate": 3.525915731526572e-05,
      "loss": 0.8384,
      "step": 278600
    },
    {
      "epoch": 2.9498996935226893,
      "grad_norm": 4.124196529388428,
      "learning_rate": 3.5256510692356557e-05,
      "loss": 0.8305,
      "step": 278650
    },
    {
      "epoch": 2.9504290153026926,
      "grad_norm": 4.085525989532471,
      "learning_rate": 3.5253864069447384e-05,
      "loss": 0.8508,
      "step": 278700
    },
    {
      "epoch": 2.950958337082696,
      "grad_norm": 4.007084369659424,
      "learning_rate": 3.525121744653822e-05,
      "loss": 0.8438,
      "step": 278750
    },
    {
      "epoch": 2.9514876588626993,
      "grad_norm": 3.785372734069824,
      "learning_rate": 3.524857082362905e-05,
      "loss": 0.8459,
      "step": 278800
    },
    {
      "epoch": 2.9520169806427026,
      "grad_norm": 3.8992884159088135,
      "learning_rate": 3.524592420071988e-05,
      "loss": 0.8348,
      "step": 278850
    },
    {
      "epoch": 2.952546302422706,
      "grad_norm": 4.0016045570373535,
      "learning_rate": 3.5243277577810713e-05,
      "loss": 0.8511,
      "step": 278900
    },
    {
      "epoch": 2.953075624202709,
      "grad_norm": 3.5749001502990723,
      "learning_rate": 3.524063095490155e-05,
      "loss": 0.8553,
      "step": 278950
    },
    {
      "epoch": 2.9536049459827125,
      "grad_norm": 4.208661079406738,
      "learning_rate": 3.523798433199238e-05,
      "loss": 0.8393,
      "step": 279000
    },
    {
      "epoch": 2.9536049459827125,
      "eval_loss": 0.6244538426399231,
      "eval_runtime": 46.5805,
      "eval_samples_per_second": 3605.157,
      "eval_steps_per_second": 450.661,
      "step": 279000
    },
    {
      "epoch": 2.954134267762716,
      "grad_norm": 3.8829360008239746,
      "learning_rate": 3.523533770908321e-05,
      "loss": 0.8473,
      "step": 279050
    },
    {
      "epoch": 2.9546635895427187,
      "grad_norm": 4.041160583496094,
      "learning_rate": 3.523269108617404e-05,
      "loss": 0.8277,
      "step": 279100
    },
    {
      "epoch": 2.9551929113227224,
      "grad_norm": 4.190068244934082,
      "learning_rate": 3.523004446326488e-05,
      "loss": 0.8263,
      "step": 279150
    },
    {
      "epoch": 2.9557222331027253,
      "grad_norm": 4.005649089813232,
      "learning_rate": 3.522739784035571e-05,
      "loss": 0.8461,
      "step": 279200
    },
    {
      "epoch": 2.9562515548827286,
      "grad_norm": 4.113104820251465,
      "learning_rate": 3.522475121744654e-05,
      "loss": 0.8389,
      "step": 279250
    },
    {
      "epoch": 2.956780876662732,
      "grad_norm": 3.6024086475372314,
      "learning_rate": 3.522210459453737e-05,
      "loss": 0.8369,
      "step": 279300
    },
    {
      "epoch": 2.9573101984427352,
      "grad_norm": 4.026036739349365,
      "learning_rate": 3.521945797162821e-05,
      "loss": 0.8437,
      "step": 279350
    },
    {
      "epoch": 2.9578395202227385,
      "grad_norm": 4.091102600097656,
      "learning_rate": 3.5216811348719034e-05,
      "loss": 0.8396,
      "step": 279400
    },
    {
      "epoch": 2.958368842002742,
      "grad_norm": 3.980102777481079,
      "learning_rate": 3.521416472580987e-05,
      "loss": 0.838,
      "step": 279450
    },
    {
      "epoch": 2.958898163782745,
      "grad_norm": 3.816854953765869,
      "learning_rate": 3.5211518102900696e-05,
      "loss": 0.8444,
      "step": 279500
    },
    {
      "epoch": 2.958898163782745,
      "eval_loss": 0.6225996613502502,
      "eval_runtime": 46.609,
      "eval_samples_per_second": 3602.952,
      "eval_steps_per_second": 450.385,
      "step": 279500
    },
    {
      "epoch": 2.9594274855627485,
      "grad_norm": 4.038741111755371,
      "learning_rate": 3.5208871479991536e-05,
      "loss": 0.8436,
      "step": 279550
    },
    {
      "epoch": 2.959956807342752,
      "grad_norm": 4.852073669433594,
      "learning_rate": 3.5206224857082364e-05,
      "loss": 0.8476,
      "step": 279600
    },
    {
      "epoch": 2.960486129122755,
      "grad_norm": 4.255814552307129,
      "learning_rate": 3.52035782341732e-05,
      "loss": 0.8461,
      "step": 279650
    },
    {
      "epoch": 2.9610154509027584,
      "grad_norm": 4.005970001220703,
      "learning_rate": 3.5200931611264025e-05,
      "loss": 0.8463,
      "step": 279700
    },
    {
      "epoch": 2.9615447726827617,
      "grad_norm": 4.17169713973999,
      "learning_rate": 3.519833792081305e-05,
      "loss": 0.8223,
      "step": 279750
    },
    {
      "epoch": 2.962074094462765,
      "grad_norm": 4.022470951080322,
      "learning_rate": 3.5195691297903874e-05,
      "loss": 0.8453,
      "step": 279800
    },
    {
      "epoch": 2.962603416242768,
      "grad_norm": 4.102392673492432,
      "learning_rate": 3.519304467499471e-05,
      "loss": 0.8268,
      "step": 279850
    },
    {
      "epoch": 2.9631327380227717,
      "grad_norm": 4.022467613220215,
      "learning_rate": 3.5190398052085535e-05,
      "loss": 0.8664,
      "step": 279900
    },
    {
      "epoch": 2.9636620598027745,
      "grad_norm": 4.348055362701416,
      "learning_rate": 3.5187751429176376e-05,
      "loss": 0.8501,
      "step": 279950
    },
    {
      "epoch": 2.964191381582778,
      "grad_norm": 3.924440622329712,
      "learning_rate": 3.5185104806267204e-05,
      "loss": 0.8421,
      "step": 280000
    },
    {
      "epoch": 2.964191381582778,
      "eval_loss": 0.621608316898346,
      "eval_runtime": 46.5947,
      "eval_samples_per_second": 3604.061,
      "eval_steps_per_second": 450.524,
      "step": 280000
    },
    {
      "epoch": 2.964720703362781,
      "grad_norm": 4.086202621459961,
      "learning_rate": 3.518245818335804e-05,
      "loss": 0.8359,
      "step": 280050
    },
    {
      "epoch": 2.9652500251427845,
      "grad_norm": 3.6004221439361572,
      "learning_rate": 3.5179811560448865e-05,
      "loss": 0.8456,
      "step": 280100
    },
    {
      "epoch": 2.9657793469227878,
      "grad_norm": 3.6365582942962646,
      "learning_rate": 3.5177164937539706e-05,
      "loss": 0.8348,
      "step": 280150
    },
    {
      "epoch": 2.966308668702791,
      "grad_norm": 4.1584153175354,
      "learning_rate": 3.517451831463053e-05,
      "loss": 0.8485,
      "step": 280200
    },
    {
      "epoch": 2.9668379904827944,
      "grad_norm": 4.010409355163574,
      "learning_rate": 3.517187169172137e-05,
      "loss": 0.8341,
      "step": 280250
    },
    {
      "epoch": 2.9673673122627977,
      "grad_norm": 3.7610323429107666,
      "learning_rate": 3.5169225068812195e-05,
      "loss": 0.8393,
      "step": 280300
    },
    {
      "epoch": 2.967896634042801,
      "grad_norm": 3.985239028930664,
      "learning_rate": 3.516657844590303e-05,
      "loss": 0.8392,
      "step": 280350
    },
    {
      "epoch": 2.9684259558228043,
      "grad_norm": 4.2632598876953125,
      "learning_rate": 3.516393182299386e-05,
      "loss": 0.8465,
      "step": 280400
    },
    {
      "epoch": 2.9689552776028076,
      "grad_norm": 4.277009010314941,
      "learning_rate": 3.516128520008469e-05,
      "loss": 0.8481,
      "step": 280450
    },
    {
      "epoch": 2.969484599382811,
      "grad_norm": 3.6889030933380127,
      "learning_rate": 3.5158638577175524e-05,
      "loss": 0.8457,
      "step": 280500
    },
    {
      "epoch": 2.969484599382811,
      "eval_loss": 0.6214408874511719,
      "eval_runtime": 46.6273,
      "eval_samples_per_second": 3601.535,
      "eval_steps_per_second": 450.208,
      "step": 280500
    },
    {
      "epoch": 2.9700139211628143,
      "grad_norm": 4.001926422119141,
      "learning_rate": 3.515599195426636e-05,
      "loss": 0.8546,
      "step": 280550
    },
    {
      "epoch": 2.970543242942817,
      "grad_norm": 4.0342535972595215,
      "learning_rate": 3.515334533135719e-05,
      "loss": 0.8469,
      "step": 280600
    },
    {
      "epoch": 2.971072564722821,
      "grad_norm": 4.15266227722168,
      "learning_rate": 3.515069870844802e-05,
      "loss": 0.8426,
      "step": 280650
    },
    {
      "epoch": 2.9716018865028238,
      "grad_norm": 3.9471607208251953,
      "learning_rate": 3.5148052085538854e-05,
      "loss": 0.8332,
      "step": 280700
    },
    {
      "epoch": 2.972131208282827,
      "grad_norm": 3.782508373260498,
      "learning_rate": 3.514540546262969e-05,
      "loss": 0.8389,
      "step": 280750
    },
    {
      "epoch": 2.9726605300628304,
      "grad_norm": 4.098743915557861,
      "learning_rate": 3.5142758839720515e-05,
      "loss": 0.8394,
      "step": 280800
    },
    {
      "epoch": 2.9731898518428337,
      "grad_norm": 4.1717329025268555,
      "learning_rate": 3.514011221681135e-05,
      "loss": 0.8361,
      "step": 280850
    },
    {
      "epoch": 2.973719173622837,
      "grad_norm": 3.6972787380218506,
      "learning_rate": 3.5137465593902184e-05,
      "loss": 0.8329,
      "step": 280900
    },
    {
      "epoch": 2.9742484954028403,
      "grad_norm": 3.8629257678985596,
      "learning_rate": 3.513481897099302e-05,
      "loss": 0.836,
      "step": 280950
    },
    {
      "epoch": 2.9747778171828436,
      "grad_norm": 3.8323771953582764,
      "learning_rate": 3.5132172348083845e-05,
      "loss": 0.8397,
      "step": 281000
    },
    {
      "epoch": 2.9747778171828436,
      "eval_loss": 0.6216587424278259,
      "eval_runtime": 46.6925,
      "eval_samples_per_second": 3596.507,
      "eval_steps_per_second": 449.579,
      "step": 281000
    },
    {
      "epoch": 2.975307138962847,
      "grad_norm": 4.138302326202393,
      "learning_rate": 3.512952572517468e-05,
      "loss": 0.8505,
      "step": 281050
    },
    {
      "epoch": 2.9758364607428502,
      "grad_norm": 3.7457027435302734,
      "learning_rate": 3.5126879102265506e-05,
      "loss": 0.8297,
      "step": 281100
    },
    {
      "epoch": 2.9763657825228536,
      "grad_norm": 4.061763763427734,
      "learning_rate": 3.512423247935635e-05,
      "loss": 0.833,
      "step": 281150
    },
    {
      "epoch": 2.976895104302857,
      "grad_norm": 3.5053141117095947,
      "learning_rate": 3.5121585856447175e-05,
      "loss": 0.8423,
      "step": 281200
    },
    {
      "epoch": 2.97742442608286,
      "grad_norm": 3.820441961288452,
      "learning_rate": 3.511893923353801e-05,
      "loss": 0.8413,
      "step": 281250
    },
    {
      "epoch": 2.9779537478628635,
      "grad_norm": 3.8444602489471436,
      "learning_rate": 3.5116292610628836e-05,
      "loss": 0.834,
      "step": 281300
    },
    {
      "epoch": 2.9784830696428664,
      "grad_norm": 3.9577748775482178,
      "learning_rate": 3.511364598771967e-05,
      "loss": 0.8475,
      "step": 281350
    },
    {
      "epoch": 2.97901239142287,
      "grad_norm": 4.114161968231201,
      "learning_rate": 3.5110999364810504e-05,
      "loss": 0.8295,
      "step": 281400
    },
    {
      "epoch": 2.979541713202873,
      "grad_norm": 3.9336843490600586,
      "learning_rate": 3.510835274190133e-05,
      "loss": 0.852,
      "step": 281450
    },
    {
      "epoch": 2.9800710349828763,
      "grad_norm": 4.271095275878906,
      "learning_rate": 3.5105706118992166e-05,
      "loss": 0.8462,
      "step": 281500
    },
    {
      "epoch": 2.9800710349828763,
      "eval_loss": 0.6221914887428284,
      "eval_runtime": 46.6995,
      "eval_samples_per_second": 3595.972,
      "eval_steps_per_second": 449.513,
      "step": 281500
    },
    {
      "epoch": 2.9806003567628796,
      "grad_norm": 4.135777950286865,
      "learning_rate": 3.5103059496083e-05,
      "loss": 0.862,
      "step": 281550
    },
    {
      "epoch": 2.981129678542883,
      "grad_norm": 3.9414584636688232,
      "learning_rate": 3.5100412873173834e-05,
      "loss": 0.8499,
      "step": 281600
    },
    {
      "epoch": 2.981659000322886,
      "grad_norm": 3.7447774410247803,
      "learning_rate": 3.509776625026466e-05,
      "loss": 0.8325,
      "step": 281650
    },
    {
      "epoch": 2.9821883221028895,
      "grad_norm": 4.235463619232178,
      "learning_rate": 3.5095119627355495e-05,
      "loss": 0.8469,
      "step": 281700
    },
    {
      "epoch": 2.982717643882893,
      "grad_norm": 3.7281129360198975,
      "learning_rate": 3.509247300444633e-05,
      "loss": 0.8508,
      "step": 281750
    },
    {
      "epoch": 2.983246965662896,
      "grad_norm": 4.048933506011963,
      "learning_rate": 3.5089826381537163e-05,
      "loss": 0.8398,
      "step": 281800
    },
    {
      "epoch": 2.9837762874428995,
      "grad_norm": 3.9096779823303223,
      "learning_rate": 3.508717975862799e-05,
      "loss": 0.8345,
      "step": 281850
    },
    {
      "epoch": 2.9843056092229028,
      "grad_norm": 4.109957218170166,
      "learning_rate": 3.5084533135718825e-05,
      "loss": 0.8412,
      "step": 281900
    },
    {
      "epoch": 2.984834931002906,
      "grad_norm": 4.207146167755127,
      "learning_rate": 3.508188651280966e-05,
      "loss": 0.8443,
      "step": 281950
    },
    {
      "epoch": 2.9853642527829094,
      "grad_norm": 3.841482639312744,
      "learning_rate": 3.5079239889900486e-05,
      "loss": 0.8366,
      "step": 282000
    },
    {
      "epoch": 2.9853642527829094,
      "eval_loss": 0.6220877170562744,
      "eval_runtime": 46.6705,
      "eval_samples_per_second": 3598.204,
      "eval_steps_per_second": 449.792,
      "step": 282000
    },
    {
      "epoch": 2.9858935745629127,
      "grad_norm": 3.8856289386749268,
      "learning_rate": 3.507659326699132e-05,
      "loss": 0.8393,
      "step": 282050
    },
    {
      "epoch": 2.9864228963429156,
      "grad_norm": 4.017986297607422,
      "learning_rate": 3.507394664408215e-05,
      "loss": 0.8397,
      "step": 282100
    },
    {
      "epoch": 2.9869522181229193,
      "grad_norm": 3.9840776920318604,
      "learning_rate": 3.507130002117299e-05,
      "loss": 0.8502,
      "step": 282150
    },
    {
      "epoch": 2.987481539902922,
      "grad_norm": 4.407249927520752,
      "learning_rate": 3.5068653398263816e-05,
      "loss": 0.8466,
      "step": 282200
    },
    {
      "epoch": 2.9880108616829255,
      "grad_norm": 3.735586166381836,
      "learning_rate": 3.506600677535465e-05,
      "loss": 0.842,
      "step": 282250
    },
    {
      "epoch": 2.988540183462929,
      "grad_norm": 3.821375846862793,
      "learning_rate": 3.506336015244548e-05,
      "loss": 0.842,
      "step": 282300
    },
    {
      "epoch": 2.989069505242932,
      "grad_norm": 4.025804042816162,
      "learning_rate": 3.506071352953632e-05,
      "loss": 0.8396,
      "step": 282350
    },
    {
      "epoch": 2.9895988270229354,
      "grad_norm": 4.424248218536377,
      "learning_rate": 3.5058066906627146e-05,
      "loss": 0.8595,
      "step": 282400
    },
    {
      "epoch": 2.9901281488029388,
      "grad_norm": 4.197072982788086,
      "learning_rate": 3.505542028371798e-05,
      "loss": 0.843,
      "step": 282450
    },
    {
      "epoch": 2.990657470582942,
      "grad_norm": 4.121912479400635,
      "learning_rate": 3.505277366080881e-05,
      "loss": 0.8493,
      "step": 282500
    },
    {
      "epoch": 2.990657470582942,
      "eval_loss": 0.6182758212089539,
      "eval_runtime": 46.6277,
      "eval_samples_per_second": 3601.506,
      "eval_steps_per_second": 450.204,
      "step": 282500
    },
    {
      "epoch": 2.9911867923629454,
      "grad_norm": 3.960510015487671,
      "learning_rate": 3.505012703789964e-05,
      "loss": 0.8433,
      "step": 282550
    },
    {
      "epoch": 2.9917161141429487,
      "grad_norm": 4.119891166687012,
      "learning_rate": 3.5047480414990475e-05,
      "loss": 0.8461,
      "step": 282600
    },
    {
      "epoch": 2.992245435922952,
      "grad_norm": 4.269187927246094,
      "learning_rate": 3.50448337920813e-05,
      "loss": 0.8375,
      "step": 282650
    },
    {
      "epoch": 2.9927747577029553,
      "grad_norm": 4.015249729156494,
      "learning_rate": 3.504218716917214e-05,
      "loss": 0.8604,
      "step": 282700
    },
    {
      "epoch": 2.9933040794829586,
      "grad_norm": 4.298632621765137,
      "learning_rate": 3.503954054626297e-05,
      "loss": 0.8504,
      "step": 282750
    },
    {
      "epoch": 2.993833401262962,
      "grad_norm": 3.848698377609253,
      "learning_rate": 3.5036893923353805e-05,
      "loss": 0.8127,
      "step": 282800
    },
    {
      "epoch": 2.994362723042965,
      "grad_norm": 3.639526128768921,
      "learning_rate": 3.503424730044463e-05,
      "loss": 0.8371,
      "step": 282850
    },
    {
      "epoch": 2.9948920448229686,
      "grad_norm": 3.7496087551116943,
      "learning_rate": 3.5031600677535466e-05,
      "loss": 0.8519,
      "step": 282900
    },
    {
      "epoch": 2.9954213666029714,
      "grad_norm": 3.8761656284332275,
      "learning_rate": 3.50289540546263e-05,
      "loss": 0.8498,
      "step": 282950
    },
    {
      "epoch": 2.9959506883829747,
      "grad_norm": 4.41572904586792,
      "learning_rate": 3.5026307431717134e-05,
      "loss": 0.8391,
      "step": 283000
    },
    {
      "epoch": 2.9959506883829747,
      "eval_loss": 0.6173155307769775,
      "eval_runtime": 46.5651,
      "eval_samples_per_second": 3606.348,
      "eval_steps_per_second": 450.81,
      "step": 283000
    },
    {
      "epoch": 2.996480010162978,
      "grad_norm": 4.074332237243652,
      "learning_rate": 3.502366080880796e-05,
      "loss": 0.8407,
      "step": 283050
    },
    {
      "epoch": 2.9970093319429814,
      "grad_norm": 3.962712287902832,
      "learning_rate": 3.5021014185898796e-05,
      "loss": 0.821,
      "step": 283100
    },
    {
      "epoch": 2.9975386537229847,
      "grad_norm": 3.927029609680176,
      "learning_rate": 3.501836756298963e-05,
      "loss": 0.845,
      "step": 283150
    },
    {
      "epoch": 2.998067975502988,
      "grad_norm": 4.020622253417969,
      "learning_rate": 3.501572094008046e-05,
      "loss": 0.8272,
      "step": 283200
    },
    {
      "epoch": 2.9985972972829913,
      "grad_norm": 3.9569814205169678,
      "learning_rate": 3.501307431717129e-05,
      "loss": 0.8498,
      "step": 283250
    },
    {
      "epoch": 2.9991266190629946,
      "grad_norm": 4.2345380783081055,
      "learning_rate": 3.501042769426212e-05,
      "loss": 0.8386,
      "step": 283300
    },
    {
      "epoch": 2.999655940842998,
      "grad_norm": 3.750074863433838,
      "learning_rate": 3.500778107135296e-05,
      "loss": 0.8376,
      "step": 283350
    },
    {
      "epoch": 3.000179969405201,
      "grad_norm": 4.063737392425537,
      "learning_rate": 3.500513444844379e-05,
      "loss": 0.8389,
      "step": 283400
    },
    {
      "epoch": 3.0007092911852045,
      "grad_norm": 4.166393756866455,
      "learning_rate": 3.500248782553462e-05,
      "loss": 0.837,
      "step": 283450
    },
    {
      "epoch": 3.0012386129652078,
      "grad_norm": 3.7025387287139893,
      "learning_rate": 3.499984120262545e-05,
      "loss": 0.8332,
      "step": 283500
    },
    {
      "epoch": 3.0012386129652078,
      "eval_loss": 0.6195319890975952,
      "eval_runtime": 46.5973,
      "eval_samples_per_second": 3603.855,
      "eval_steps_per_second": 450.498,
      "step": 283500
    },
    {
      "epoch": 3.001767934745211,
      "grad_norm": 4.246213912963867,
      "learning_rate": 3.499719457971629e-05,
      "loss": 0.8468,
      "step": 283550
    },
    {
      "epoch": 3.0022972565252144,
      "grad_norm": 3.9544241428375244,
      "learning_rate": 3.4994547956807117e-05,
      "loss": 0.821,
      "step": 283600
    },
    {
      "epoch": 3.0028265783052177,
      "grad_norm": 4.403262138366699,
      "learning_rate": 3.499190133389795e-05,
      "loss": 0.8512,
      "step": 283650
    },
    {
      "epoch": 3.003355900085221,
      "grad_norm": 4.019800662994385,
      "learning_rate": 3.498925471098878e-05,
      "loss": 0.8506,
      "step": 283700
    },
    {
      "epoch": 3.003885221865224,
      "grad_norm": 3.719619035720825,
      "learning_rate": 3.49866610205378e-05,
      "loss": 0.8196,
      "step": 283750
    },
    {
      "epoch": 3.004414543645227,
      "grad_norm": 3.939196825027466,
      "learning_rate": 3.498401439762863e-05,
      "loss": 0.8355,
      "step": 283800
    },
    {
      "epoch": 3.0049438654252305,
      "grad_norm": 4.1055121421813965,
      "learning_rate": 3.498136777471946e-05,
      "loss": 0.8373,
      "step": 283850
    },
    {
      "epoch": 3.005473187205234,
      "grad_norm": 3.836808919906616,
      "learning_rate": 3.497872115181029e-05,
      "loss": 0.8432,
      "step": 283900
    },
    {
      "epoch": 3.006002508985237,
      "grad_norm": 3.945972204208374,
      "learning_rate": 3.497607452890113e-05,
      "loss": 0.8282,
      "step": 283950
    },
    {
      "epoch": 3.0065318307652404,
      "grad_norm": 3.8045449256896973,
      "learning_rate": 3.4973427905991956e-05,
      "loss": 0.8453,
      "step": 284000
    },
    {
      "epoch": 3.0065318307652404,
      "eval_loss": 0.6172413229942322,
      "eval_runtime": 46.7269,
      "eval_samples_per_second": 3593.864,
      "eval_steps_per_second": 449.249,
      "step": 284000
    },
    {
      "epoch": 3.0070611525452438,
      "grad_norm": 3.868666410446167,
      "learning_rate": 3.497078128308279e-05,
      "loss": 0.8491,
      "step": 284050
    },
    {
      "epoch": 3.007590474325247,
      "grad_norm": 3.851353168487549,
      "learning_rate": 3.496813466017362e-05,
      "loss": 0.8302,
      "step": 284100
    },
    {
      "epoch": 3.0081197961052504,
      "grad_norm": 4.079726696014404,
      "learning_rate": 3.496548803726445e-05,
      "loss": 0.8339,
      "step": 284150
    },
    {
      "epoch": 3.0086491178852537,
      "grad_norm": 3.975835084915161,
      "learning_rate": 3.4962841414355286e-05,
      "loss": 0.8405,
      "step": 284200
    },
    {
      "epoch": 3.009178439665257,
      "grad_norm": 4.474481105804443,
      "learning_rate": 3.496019479144611e-05,
      "loss": 0.8498,
      "step": 284250
    },
    {
      "epoch": 3.0097077614452603,
      "grad_norm": 4.157958507537842,
      "learning_rate": 3.495754816853695e-05,
      "loss": 0.8221,
      "step": 284300
    },
    {
      "epoch": 3.0102370832252636,
      "grad_norm": 3.9176809787750244,
      "learning_rate": 3.495490154562778e-05,
      "loss": 0.8438,
      "step": 284350
    },
    {
      "epoch": 3.010766405005267,
      "grad_norm": 3.8990578651428223,
      "learning_rate": 3.4952254922718616e-05,
      "loss": 0.8367,
      "step": 284400
    },
    {
      "epoch": 3.0112957267852702,
      "grad_norm": 4.073189735412598,
      "learning_rate": 3.494960829980944e-05,
      "loss": 0.8282,
      "step": 284450
    },
    {
      "epoch": 3.011825048565273,
      "grad_norm": 4.316754341125488,
      "learning_rate": 3.494696167690028e-05,
      "loss": 0.8358,
      "step": 284500
    },
    {
      "epoch": 3.011825048565273,
      "eval_loss": 0.6167026162147522,
      "eval_runtime": 46.5603,
      "eval_samples_per_second": 3606.721,
      "eval_steps_per_second": 450.856,
      "step": 284500
    },
    {
      "epoch": 3.0123543703452764,
      "grad_norm": 4.363908290863037,
      "learning_rate": 3.494431505399111e-05,
      "loss": 0.8353,
      "step": 284550
    },
    {
      "epoch": 3.0128836921252797,
      "grad_norm": 4.1439208984375,
      "learning_rate": 3.4941668431081945e-05,
      "loss": 0.8359,
      "step": 284600
    },
    {
      "epoch": 3.013413013905283,
      "grad_norm": 4.378626823425293,
      "learning_rate": 3.493902180817277e-05,
      "loss": 0.8365,
      "step": 284650
    },
    {
      "epoch": 3.0139423356852864,
      "grad_norm": 3.903303623199463,
      "learning_rate": 3.493637518526361e-05,
      "loss": 0.834,
      "step": 284700
    },
    {
      "epoch": 3.0144716574652897,
      "grad_norm": 4.1639790534973145,
      "learning_rate": 3.493372856235444e-05,
      "loss": 0.8389,
      "step": 284750
    },
    {
      "epoch": 3.015000979245293,
      "grad_norm": 4.033010482788086,
      "learning_rate": 3.493108193944527e-05,
      "loss": 0.8245,
      "step": 284800
    },
    {
      "epoch": 3.0155303010252963,
      "grad_norm": 3.66878342628479,
      "learning_rate": 3.49284353165361e-05,
      "loss": 0.818,
      "step": 284850
    },
    {
      "epoch": 3.0160596228052996,
      "grad_norm": 4.015873908996582,
      "learning_rate": 3.492578869362693e-05,
      "loss": 0.8256,
      "step": 284900
    },
    {
      "epoch": 3.016588944585303,
      "grad_norm": 3.8177196979522705,
      "learning_rate": 3.492314207071777e-05,
      "loss": 0.8291,
      "step": 284950
    },
    {
      "epoch": 3.0171182663653062,
      "grad_norm": 3.8792037963867188,
      "learning_rate": 3.49204954478086e-05,
      "loss": 0.8344,
      "step": 285000
    },
    {
      "epoch": 3.0171182663653062,
      "eval_loss": 0.6161741614341736,
      "eval_runtime": 46.5997,
      "eval_samples_per_second": 3603.668,
      "eval_steps_per_second": 450.475,
      "step": 285000
    },
    {
      "epoch": 3.0176475881453095,
      "grad_norm": 4.245969295501709,
      "learning_rate": 3.491784882489943e-05,
      "loss": 0.8415,
      "step": 285050
    },
    {
      "epoch": 3.018176909925313,
      "grad_norm": 3.848529100418091,
      "learning_rate": 3.491520220199026e-05,
      "loss": 0.8306,
      "step": 285100
    },
    {
      "epoch": 3.018706231705316,
      "grad_norm": 3.8273656368255615,
      "learning_rate": 3.491255557908109e-05,
      "loss": 0.8247,
      "step": 285150
    },
    {
      "epoch": 3.0192355534853195,
      "grad_norm": 4.305962085723877,
      "learning_rate": 3.490990895617193e-05,
      "loss": 0.8303,
      "step": 285200
    },
    {
      "epoch": 3.0197648752653223,
      "grad_norm": 3.8444159030914307,
      "learning_rate": 3.4907262333262755e-05,
      "loss": 0.8288,
      "step": 285250
    },
    {
      "epoch": 3.0202941970453256,
      "grad_norm": 4.349377632141113,
      "learning_rate": 3.490461571035359e-05,
      "loss": 0.8119,
      "step": 285300
    },
    {
      "epoch": 3.020823518825329,
      "grad_norm": 4.010073661804199,
      "learning_rate": 3.490196908744442e-05,
      "loss": 0.8374,
      "step": 285350
    },
    {
      "epoch": 3.0213528406053323,
      "grad_norm": 3.843050479888916,
      "learning_rate": 3.489932246453526e-05,
      "loss": 0.8348,
      "step": 285400
    },
    {
      "epoch": 3.0218821623853356,
      "grad_norm": 3.8515830039978027,
      "learning_rate": 3.4896675841626084e-05,
      "loss": 0.8264,
      "step": 285450
    },
    {
      "epoch": 3.022411484165339,
      "grad_norm": 4.31844425201416,
      "learning_rate": 3.489402921871692e-05,
      "loss": 0.8302,
      "step": 285500
    },
    {
      "epoch": 3.022411484165339,
      "eval_loss": 0.6143971085548401,
      "eval_runtime": 46.5576,
      "eval_samples_per_second": 3606.932,
      "eval_steps_per_second": 450.883,
      "step": 285500
    },
    {
      "epoch": 3.022940805945342,
      "grad_norm": 4.145216941833496,
      "learning_rate": 3.489138259580775e-05,
      "loss": 0.8356,
      "step": 285550
    },
    {
      "epoch": 3.0234701277253455,
      "grad_norm": 3.8359670639038086,
      "learning_rate": 3.4888735972898587e-05,
      "loss": 0.8138,
      "step": 285600
    },
    {
      "epoch": 3.023999449505349,
      "grad_norm": 4.0472540855407715,
      "learning_rate": 3.4886089349989414e-05,
      "loss": 0.8474,
      "step": 285650
    },
    {
      "epoch": 3.024528771285352,
      "grad_norm": 3.915546417236328,
      "learning_rate": 3.488344272708025e-05,
      "loss": 0.8208,
      "step": 285700
    },
    {
      "epoch": 3.0250580930653554,
      "grad_norm": 3.9132001399993896,
      "learning_rate": 3.488084903662926e-05,
      "loss": 0.8372,
      "step": 285750
    },
    {
      "epoch": 3.0255874148453588,
      "grad_norm": 4.0517578125,
      "learning_rate": 3.48782024137201e-05,
      "loss": 0.8395,
      "step": 285800
    },
    {
      "epoch": 3.026116736625362,
      "grad_norm": 4.075199127197266,
      "learning_rate": 3.4875555790810924e-05,
      "loss": 0.8358,
      "step": 285850
    },
    {
      "epoch": 3.0266460584053654,
      "grad_norm": 4.16714334487915,
      "learning_rate": 3.487290916790176e-05,
      "loss": 0.8231,
      "step": 285900
    },
    {
      "epoch": 3.0271753801853687,
      "grad_norm": 4.097568511962891,
      "learning_rate": 3.487026254499259e-05,
      "loss": 0.8157,
      "step": 285950
    },
    {
      "epoch": 3.0277047019653716,
      "grad_norm": 4.448592185974121,
      "learning_rate": 3.4867615922083426e-05,
      "loss": 0.8408,
      "step": 286000
    },
    {
      "epoch": 3.0277047019653716,
      "eval_loss": 0.6150028109550476,
      "eval_runtime": 46.5684,
      "eval_samples_per_second": 3606.095,
      "eval_steps_per_second": 450.778,
      "step": 286000
    },
    {
      "epoch": 3.028234023745375,
      "grad_norm": 3.9395058155059814,
      "learning_rate": 3.4864969299174254e-05,
      "loss": 0.8331,
      "step": 286050
    },
    {
      "epoch": 3.028763345525378,
      "grad_norm": 4.142255783081055,
      "learning_rate": 3.486232267626509e-05,
      "loss": 0.8378,
      "step": 286100
    },
    {
      "epoch": 3.0292926673053815,
      "grad_norm": 4.1961517333984375,
      "learning_rate": 3.485967605335592e-05,
      "loss": 0.8338,
      "step": 286150
    },
    {
      "epoch": 3.029821989085385,
      "grad_norm": 4.135561466217041,
      "learning_rate": 3.485702943044675e-05,
      "loss": 0.8475,
      "step": 286200
    },
    {
      "epoch": 3.030351310865388,
      "grad_norm": 4.060301303863525,
      "learning_rate": 3.4854382807537583e-05,
      "loss": 0.833,
      "step": 286250
    },
    {
      "epoch": 3.0308806326453914,
      "grad_norm": 3.6434154510498047,
      "learning_rate": 3.485173618462841e-05,
      "loss": 0.8237,
      "step": 286300
    },
    {
      "epoch": 3.0314099544253947,
      "grad_norm": 4.174474716186523,
      "learning_rate": 3.484908956171925e-05,
      "loss": 0.8307,
      "step": 286350
    },
    {
      "epoch": 3.031939276205398,
      "grad_norm": 4.194633483886719,
      "learning_rate": 3.484644293881008e-05,
      "loss": 0.8336,
      "step": 286400
    },
    {
      "epoch": 3.0324685979854014,
      "grad_norm": 4.1814799308776855,
      "learning_rate": 3.484379631590091e-05,
      "loss": 0.8407,
      "step": 286450
    },
    {
      "epoch": 3.0329979197654047,
      "grad_norm": 4.2222747802734375,
      "learning_rate": 3.484114969299174e-05,
      "loss": 0.8475,
      "step": 286500
    },
    {
      "epoch": 3.0329979197654047,
      "eval_loss": 0.6121134757995605,
      "eval_runtime": 46.691,
      "eval_samples_per_second": 3596.621,
      "eval_steps_per_second": 449.594,
      "step": 286500
    },
    {
      "epoch": 3.033527241545408,
      "grad_norm": 3.771496295928955,
      "learning_rate": 3.483850307008258e-05,
      "loss": 0.8205,
      "step": 286550
    },
    {
      "epoch": 3.0340565633254113,
      "grad_norm": 3.5687766075134277,
      "learning_rate": 3.483585644717341e-05,
      "loss": 0.8223,
      "step": 286600
    },
    {
      "epoch": 3.0345858851054146,
      "grad_norm": 4.180985450744629,
      "learning_rate": 3.483320982426424e-05,
      "loss": 0.8334,
      "step": 286650
    },
    {
      "epoch": 3.035115206885418,
      "grad_norm": 4.047712326049805,
      "learning_rate": 3.483056320135507e-05,
      "loss": 0.8343,
      "step": 286700
    },
    {
      "epoch": 3.035644528665421,
      "grad_norm": 4.455265045166016,
      "learning_rate": 3.4827916578445904e-05,
      "loss": 0.8425,
      "step": 286750
    },
    {
      "epoch": 3.036173850445424,
      "grad_norm": 3.8145477771759033,
      "learning_rate": 3.482526995553674e-05,
      "loss": 0.835,
      "step": 286800
    },
    {
      "epoch": 3.0367031722254274,
      "grad_norm": 4.119102478027344,
      "learning_rate": 3.4822623332627565e-05,
      "loss": 0.8134,
      "step": 286850
    },
    {
      "epoch": 3.0372324940054307,
      "grad_norm": 3.9179141521453857,
      "learning_rate": 3.48199767097184e-05,
      "loss": 0.824,
      "step": 286900
    },
    {
      "epoch": 3.037761815785434,
      "grad_norm": 4.154338836669922,
      "learning_rate": 3.4817330086809234e-05,
      "loss": 0.8269,
      "step": 286950
    },
    {
      "epoch": 3.0382911375654373,
      "grad_norm": 4.061286926269531,
      "learning_rate": 3.481468346390007e-05,
      "loss": 0.8232,
      "step": 287000
    },
    {
      "epoch": 3.0382911375654373,
      "eval_loss": 0.6140706539154053,
      "eval_runtime": 46.5901,
      "eval_samples_per_second": 3604.411,
      "eval_steps_per_second": 450.567,
      "step": 287000
    },
    {
      "epoch": 3.0388204593454406,
      "grad_norm": 4.354345798492432,
      "learning_rate": 3.4812036840990895e-05,
      "loss": 0.823,
      "step": 287050
    },
    {
      "epoch": 3.039349781125444,
      "grad_norm": 3.769247531890869,
      "learning_rate": 3.480939021808173e-05,
      "loss": 0.8306,
      "step": 287100
    },
    {
      "epoch": 3.0398791029054473,
      "grad_norm": 3.9542582035064697,
      "learning_rate": 3.480674359517256e-05,
      "loss": 0.8302,
      "step": 287150
    },
    {
      "epoch": 3.0404084246854506,
      "grad_norm": 3.929074287414551,
      "learning_rate": 3.48040969722634e-05,
      "loss": 0.8412,
      "step": 287200
    },
    {
      "epoch": 3.040937746465454,
      "grad_norm": 3.7214128971099854,
      "learning_rate": 3.4801450349354225e-05,
      "loss": 0.8221,
      "step": 287250
    },
    {
      "epoch": 3.041467068245457,
      "grad_norm": 3.9335105419158936,
      "learning_rate": 3.479880372644506e-05,
      "loss": 0.8323,
      "step": 287300
    },
    {
      "epoch": 3.0419963900254605,
      "grad_norm": 3.809826612472534,
      "learning_rate": 3.479615710353589e-05,
      "loss": 0.83,
      "step": 287350
    },
    {
      "epoch": 3.042525711805464,
      "grad_norm": 3.728789806365967,
      "learning_rate": 3.479351048062672e-05,
      "loss": 0.8306,
      "step": 287400
    },
    {
      "epoch": 3.043055033585467,
      "grad_norm": 3.749460458755493,
      "learning_rate": 3.4790863857717554e-05,
      "loss": 0.8295,
      "step": 287450
    },
    {
      "epoch": 3.04358435536547,
      "grad_norm": 3.867551565170288,
      "learning_rate": 3.478821723480838e-05,
      "loss": 0.8411,
      "step": 287500
    },
    {
      "epoch": 3.04358435536547,
      "eval_loss": 0.613102376461029,
      "eval_runtime": 46.5301,
      "eval_samples_per_second": 3609.064,
      "eval_steps_per_second": 451.149,
      "step": 287500
    },
    {
      "epoch": 3.0441136771454733,
      "grad_norm": 4.190853118896484,
      "learning_rate": 3.478557061189922e-05,
      "loss": 0.8335,
      "step": 287550
    },
    {
      "epoch": 3.0446429989254766,
      "grad_norm": 4.098245143890381,
      "learning_rate": 3.478292398899005e-05,
      "loss": 0.8343,
      "step": 287600
    },
    {
      "epoch": 3.04517232070548,
      "grad_norm": 3.8485662937164307,
      "learning_rate": 3.4780277366080884e-05,
      "loss": 0.8295,
      "step": 287650
    },
    {
      "epoch": 3.0457016424854833,
      "grad_norm": 3.93534779548645,
      "learning_rate": 3.477763074317171e-05,
      "loss": 0.8323,
      "step": 287700
    },
    {
      "epoch": 3.0462309642654866,
      "grad_norm": 3.9467341899871826,
      "learning_rate": 3.477503705272073e-05,
      "loss": 0.8333,
      "step": 287750
    },
    {
      "epoch": 3.04676028604549,
      "grad_norm": 3.9656600952148438,
      "learning_rate": 3.477239042981156e-05,
      "loss": 0.8318,
      "step": 287800
    },
    {
      "epoch": 3.047289607825493,
      "grad_norm": 3.8604331016540527,
      "learning_rate": 3.4769743806902394e-05,
      "loss": 0.8434,
      "step": 287850
    },
    {
      "epoch": 3.0478189296054965,
      "grad_norm": 4.457461357116699,
      "learning_rate": 3.476709718399322e-05,
      "loss": 0.8417,
      "step": 287900
    },
    {
      "epoch": 3.0483482513855,
      "grad_norm": 3.6912994384765625,
      "learning_rate": 3.476445056108406e-05,
      "loss": 0.8335,
      "step": 287950
    },
    {
      "epoch": 3.048877573165503,
      "grad_norm": 3.9419963359832764,
      "learning_rate": 3.476180393817489e-05,
      "loss": 0.8306,
      "step": 288000
    },
    {
      "epoch": 3.048877573165503,
      "eval_loss": 0.6112675070762634,
      "eval_runtime": 46.5875,
      "eval_samples_per_second": 3604.618,
      "eval_steps_per_second": 450.593,
      "step": 288000
    },
    {
      "epoch": 3.0494068949455064,
      "grad_norm": 4.082878589630127,
      "learning_rate": 3.4759157315265724e-05,
      "loss": 0.8384,
      "step": 288050
    },
    {
      "epoch": 3.0499362167255097,
      "grad_norm": 4.146993160247803,
      "learning_rate": 3.475651069235655e-05,
      "loss": 0.8104,
      "step": 288100
    },
    {
      "epoch": 3.050465538505513,
      "grad_norm": 4.071109294891357,
      "learning_rate": 3.475386406944739e-05,
      "loss": 0.8441,
      "step": 288150
    },
    {
      "epoch": 3.0509948602855164,
      "grad_norm": 4.146365642547607,
      "learning_rate": 3.475121744653822e-05,
      "loss": 0.8288,
      "step": 288200
    },
    {
      "epoch": 3.0515241820655197,
      "grad_norm": 4.1421966552734375,
      "learning_rate": 3.4748570823629053e-05,
      "loss": 0.8425,
      "step": 288250
    },
    {
      "epoch": 3.0520535038455225,
      "grad_norm": 3.688281536102295,
      "learning_rate": 3.474592420071988e-05,
      "loss": 0.8267,
      "step": 288300
    },
    {
      "epoch": 3.052582825625526,
      "grad_norm": 4.155092239379883,
      "learning_rate": 3.4743277577810715e-05,
      "loss": 0.8349,
      "step": 288350
    },
    {
      "epoch": 3.053112147405529,
      "grad_norm": 3.8838541507720947,
      "learning_rate": 3.474063095490155e-05,
      "loss": 0.8397,
      "step": 288400
    },
    {
      "epoch": 3.0536414691855325,
      "grad_norm": 3.962062120437622,
      "learning_rate": 3.4737984331992376e-05,
      "loss": 0.8195,
      "step": 288450
    },
    {
      "epoch": 3.054170790965536,
      "grad_norm": 4.165674209594727,
      "learning_rate": 3.473533770908321e-05,
      "loss": 0.8309,
      "step": 288500
    },
    {
      "epoch": 3.054170790965536,
      "eval_loss": 0.6098450422286987,
      "eval_runtime": 46.559,
      "eval_samples_per_second": 3606.824,
      "eval_steps_per_second": 450.869,
      "step": 288500
    },
    {
      "epoch": 3.054700112745539,
      "grad_norm": 3.8620264530181885,
      "learning_rate": 3.4732691086174045e-05,
      "loss": 0.8216,
      "step": 288550
    },
    {
      "epoch": 3.0552294345255424,
      "grad_norm": 3.8998429775238037,
      "learning_rate": 3.473004446326488e-05,
      "loss": 0.8257,
      "step": 288600
    },
    {
      "epoch": 3.0557587563055457,
      "grad_norm": 3.937535285949707,
      "learning_rate": 3.4727397840355706e-05,
      "loss": 0.8286,
      "step": 288650
    },
    {
      "epoch": 3.056288078085549,
      "grad_norm": 4.014310359954834,
      "learning_rate": 3.472475121744654e-05,
      "loss": 0.8405,
      "step": 288700
    },
    {
      "epoch": 3.0568173998655523,
      "grad_norm": 3.6892008781433105,
      "learning_rate": 3.4722104594537374e-05,
      "loss": 0.8335,
      "step": 288750
    },
    {
      "epoch": 3.0573467216455557,
      "grad_norm": 4.051815986633301,
      "learning_rate": 3.471945797162821e-05,
      "loss": 0.8346,
      "step": 288800
    },
    {
      "epoch": 3.057876043425559,
      "grad_norm": 4.336041450500488,
      "learning_rate": 3.4716811348719036e-05,
      "loss": 0.8328,
      "step": 288850
    },
    {
      "epoch": 3.0584053652055623,
      "grad_norm": 4.057882785797119,
      "learning_rate": 3.471416472580987e-05,
      "loss": 0.8191,
      "step": 288900
    },
    {
      "epoch": 3.0589346869855656,
      "grad_norm": 3.9409196376800537,
      "learning_rate": 3.4711518102900704e-05,
      "loss": 0.8111,
      "step": 288950
    },
    {
      "epoch": 3.059464008765569,
      "grad_norm": 3.9222936630249023,
      "learning_rate": 3.470887147999153e-05,
      "loss": 0.8388,
      "step": 289000
    },
    {
      "epoch": 3.059464008765569,
      "eval_loss": 0.6129199266433716,
      "eval_runtime": 46.7717,
      "eval_samples_per_second": 3590.42,
      "eval_steps_per_second": 448.819,
      "step": 289000
    },
    {
      "epoch": 3.0599933305455718,
      "grad_norm": 3.623581886291504,
      "learning_rate": 3.4706224857082365e-05,
      "loss": 0.8332,
      "step": 289050
    },
    {
      "epoch": 3.060522652325575,
      "grad_norm": 4.405102252960205,
      "learning_rate": 3.470357823417319e-05,
      "loss": 0.8216,
      "step": 289100
    },
    {
      "epoch": 3.0610519741055784,
      "grad_norm": 3.923461675643921,
      "learning_rate": 3.470093161126403e-05,
      "loss": 0.8269,
      "step": 289150
    },
    {
      "epoch": 3.0615812958855817,
      "grad_norm": 3.5693039894104004,
      "learning_rate": 3.469828498835486e-05,
      "loss": 0.8383,
      "step": 289200
    },
    {
      "epoch": 3.062110617665585,
      "grad_norm": 3.7908148765563965,
      "learning_rate": 3.4695638365445695e-05,
      "loss": 0.8372,
      "step": 289250
    },
    {
      "epoch": 3.0626399394455883,
      "grad_norm": 4.458485126495361,
      "learning_rate": 3.469299174253652e-05,
      "loss": 0.8273,
      "step": 289300
    },
    {
      "epoch": 3.0631692612255916,
      "grad_norm": 3.9985978603363037,
      "learning_rate": 3.469034511962736e-05,
      "loss": 0.8255,
      "step": 289350
    },
    {
      "epoch": 3.063698583005595,
      "grad_norm": 4.056757926940918,
      "learning_rate": 3.468769849671819e-05,
      "loss": 0.8146,
      "step": 289400
    },
    {
      "epoch": 3.0642279047855983,
      "grad_norm": 3.91591477394104,
      "learning_rate": 3.4685051873809024e-05,
      "loss": 0.8255,
      "step": 289450
    },
    {
      "epoch": 3.0647572265656016,
      "grad_norm": 4.409867286682129,
      "learning_rate": 3.468245818335803e-05,
      "loss": 0.8188,
      "step": 289500
    },
    {
      "epoch": 3.0647572265656016,
      "eval_loss": 0.6126782298088074,
      "eval_runtime": 46.6126,
      "eval_samples_per_second": 3602.671,
      "eval_steps_per_second": 450.35,
      "step": 289500
    },
    {
      "epoch": 3.065286548345605,
      "grad_norm": 3.9582724571228027,
      "learning_rate": 3.467981156044887e-05,
      "loss": 0.8219,
      "step": 289550
    },
    {
      "epoch": 3.065815870125608,
      "grad_norm": 3.978569984436035,
      "learning_rate": 3.46771649375397e-05,
      "loss": 0.8216,
      "step": 289600
    },
    {
      "epoch": 3.0663451919056115,
      "grad_norm": 3.6851425170898438,
      "learning_rate": 3.4674518314630535e-05,
      "loss": 0.8235,
      "step": 289650
    },
    {
      "epoch": 3.066874513685615,
      "grad_norm": 3.8532872200012207,
      "learning_rate": 3.467187169172136e-05,
      "loss": 0.8298,
      "step": 289700
    },
    {
      "epoch": 3.067403835465618,
      "grad_norm": 4.0134172439575195,
      "learning_rate": 3.46692250688122e-05,
      "loss": 0.8278,
      "step": 289750
    },
    {
      "epoch": 3.067933157245621,
      "grad_norm": 3.8592424392700195,
      "learning_rate": 3.466657844590303e-05,
      "loss": 0.8312,
      "step": 289800
    },
    {
      "epoch": 3.0684624790256243,
      "grad_norm": 3.999469041824341,
      "learning_rate": 3.4663931822993864e-05,
      "loss": 0.833,
      "step": 289850
    },
    {
      "epoch": 3.0689918008056276,
      "grad_norm": 3.9159364700317383,
      "learning_rate": 3.466128520008469e-05,
      "loss": 0.8165,
      "step": 289900
    },
    {
      "epoch": 3.069521122585631,
      "grad_norm": 4.166749477386475,
      "learning_rate": 3.4658638577175526e-05,
      "loss": 0.8348,
      "step": 289950
    },
    {
      "epoch": 3.0700504443656342,
      "grad_norm": 4.126643657684326,
      "learning_rate": 3.465599195426636e-05,
      "loss": 0.825,
      "step": 290000
    },
    {
      "epoch": 3.0700504443656342,
      "eval_loss": 0.6098611354827881,
      "eval_runtime": 46.6528,
      "eval_samples_per_second": 3599.569,
      "eval_steps_per_second": 449.962,
      "step": 290000
    },
    {
      "epoch": 3.0705797661456375,
      "grad_norm": 4.050325393676758,
      "learning_rate": 3.465334533135719e-05,
      "loss": 0.8209,
      "step": 290050
    },
    {
      "epoch": 3.071109087925641,
      "grad_norm": 4.086915016174316,
      "learning_rate": 3.465069870844802e-05,
      "loss": 0.8208,
      "step": 290100
    },
    {
      "epoch": 3.071638409705644,
      "grad_norm": 4.14981746673584,
      "learning_rate": 3.4648052085538855e-05,
      "loss": 0.8333,
      "step": 290150
    },
    {
      "epoch": 3.0721677314856475,
      "grad_norm": 4.376349449157715,
      "learning_rate": 3.464540546262969e-05,
      "loss": 0.8227,
      "step": 290200
    },
    {
      "epoch": 3.072697053265651,
      "grad_norm": 4.131429195404053,
      "learning_rate": 3.464275883972052e-05,
      "loss": 0.8228,
      "step": 290250
    },
    {
      "epoch": 3.073226375045654,
      "grad_norm": 3.8681910037994385,
      "learning_rate": 3.464011221681135e-05,
      "loss": 0.8314,
      "step": 290300
    },
    {
      "epoch": 3.0737556968256574,
      "grad_norm": 4.33123779296875,
      "learning_rate": 3.463746559390218e-05,
      "loss": 0.839,
      "step": 290350
    },
    {
      "epoch": 3.0742850186056607,
      "grad_norm": 3.851254940032959,
      "learning_rate": 3.463481897099302e-05,
      "loss": 0.8422,
      "step": 290400
    },
    {
      "epoch": 3.074814340385664,
      "grad_norm": 4.036794662475586,
      "learning_rate": 3.4632172348083846e-05,
      "loss": 0.8258,
      "step": 290450
    },
    {
      "epoch": 3.0753436621656673,
      "grad_norm": 4.112916469573975,
      "learning_rate": 3.462952572517468e-05,
      "loss": 0.8298,
      "step": 290500
    },
    {
      "epoch": 3.0753436621656673,
      "eval_loss": 0.60941082239151,
      "eval_runtime": 46.5552,
      "eval_samples_per_second": 3607.115,
      "eval_steps_per_second": 450.905,
      "step": 290500
    },
    {
      "epoch": 3.07587298394567,
      "grad_norm": 4.385196208953857,
      "learning_rate": 3.462687910226551e-05,
      "loss": 0.8276,
      "step": 290550
    },
    {
      "epoch": 3.0764023057256735,
      "grad_norm": 4.056958198547363,
      "learning_rate": 3.462423247935634e-05,
      "loss": 0.836,
      "step": 290600
    },
    {
      "epoch": 3.076931627505677,
      "grad_norm": 3.8684279918670654,
      "learning_rate": 3.4621585856447176e-05,
      "loss": 0.835,
      "step": 290650
    },
    {
      "epoch": 3.07746094928568,
      "grad_norm": 3.9311583042144775,
      "learning_rate": 3.4618939233538e-05,
      "loss": 0.8219,
      "step": 290700
    },
    {
      "epoch": 3.0779902710656835,
      "grad_norm": 4.021574020385742,
      "learning_rate": 3.461629261062884e-05,
      "loss": 0.8102,
      "step": 290750
    },
    {
      "epoch": 3.0785195928456868,
      "grad_norm": 4.188576698303223,
      "learning_rate": 3.461364598771967e-05,
      "loss": 0.8387,
      "step": 290800
    },
    {
      "epoch": 3.07904891462569,
      "grad_norm": 4.101311683654785,
      "learning_rate": 3.4610999364810506e-05,
      "loss": 0.8337,
      "step": 290850
    },
    {
      "epoch": 3.0795782364056934,
      "grad_norm": 3.8746092319488525,
      "learning_rate": 3.460835274190133e-05,
      "loss": 0.8397,
      "step": 290900
    },
    {
      "epoch": 3.0801075581856967,
      "grad_norm": 4.118384838104248,
      "learning_rate": 3.460570611899217e-05,
      "loss": 0.8202,
      "step": 290950
    },
    {
      "epoch": 3.0806368799657,
      "grad_norm": 4.072125434875488,
      "learning_rate": 3.4603059496083e-05,
      "loss": 0.8333,
      "step": 291000
    },
    {
      "epoch": 3.0806368799657,
      "eval_loss": 0.6104291677474976,
      "eval_runtime": 46.7051,
      "eval_samples_per_second": 3595.537,
      "eval_steps_per_second": 449.458,
      "step": 291000
    },
    {
      "epoch": 3.0811662017457033,
      "grad_norm": 3.8860251903533936,
      "learning_rate": 3.4600412873173835e-05,
      "loss": 0.8189,
      "step": 291050
    },
    {
      "epoch": 3.0816955235257066,
      "grad_norm": 4.3303327560424805,
      "learning_rate": 3.459776625026466e-05,
      "loss": 0.8318,
      "step": 291100
    },
    {
      "epoch": 3.08222484530571,
      "grad_norm": 4.493895530700684,
      "learning_rate": 3.45951196273555e-05,
      "loss": 0.8275,
      "step": 291150
    },
    {
      "epoch": 3.0827541670857133,
      "grad_norm": 3.957406759262085,
      "learning_rate": 3.459247300444633e-05,
      "loss": 0.8287,
      "step": 291200
    },
    {
      "epoch": 3.0832834888657166,
      "grad_norm": 3.968944549560547,
      "learning_rate": 3.458982638153716e-05,
      "loss": 0.824,
      "step": 291250
    },
    {
      "epoch": 3.0838128106457194,
      "grad_norm": 4.40408992767334,
      "learning_rate": 3.458717975862799e-05,
      "loss": 0.8361,
      "step": 291300
    },
    {
      "epoch": 3.0843421324257227,
      "grad_norm": 3.833817481994629,
      "learning_rate": 3.458453313571882e-05,
      "loss": 0.8242,
      "step": 291350
    },
    {
      "epoch": 3.084871454205726,
      "grad_norm": 3.981898307800293,
      "learning_rate": 3.458188651280966e-05,
      "loss": 0.8225,
      "step": 291400
    },
    {
      "epoch": 3.0854007759857294,
      "grad_norm": 3.8116087913513184,
      "learning_rate": 3.457923988990049e-05,
      "loss": 0.8261,
      "step": 291450
    },
    {
      "epoch": 3.0859300977657327,
      "grad_norm": 3.906118154525757,
      "learning_rate": 3.457659326699132e-05,
      "loss": 0.8398,
      "step": 291500
    },
    {
      "epoch": 3.0859300977657327,
      "eval_loss": 0.6111539006233215,
      "eval_runtime": 46.5384,
      "eval_samples_per_second": 3608.416,
      "eval_steps_per_second": 451.068,
      "step": 291500
    },
    {
      "epoch": 3.086459419545736,
      "grad_norm": 4.080061435699463,
      "learning_rate": 3.457394664408215e-05,
      "loss": 0.8517,
      "step": 291550
    },
    {
      "epoch": 3.0869887413257393,
      "grad_norm": 3.735928535461426,
      "learning_rate": 3.457130002117298e-05,
      "loss": 0.8451,
      "step": 291600
    },
    {
      "epoch": 3.0875180631057426,
      "grad_norm": 4.309847354888916,
      "learning_rate": 3.456865339826382e-05,
      "loss": 0.8323,
      "step": 291650
    },
    {
      "epoch": 3.088047384885746,
      "grad_norm": 4.184759140014648,
      "learning_rate": 3.4566006775354645e-05,
      "loss": 0.8334,
      "step": 291700
    },
    {
      "epoch": 3.0885767066657492,
      "grad_norm": 3.653214454650879,
      "learning_rate": 3.456341308490366e-05,
      "loss": 0.8274,
      "step": 291750
    },
    {
      "epoch": 3.0891060284457525,
      "grad_norm": 4.5419111251831055,
      "learning_rate": 3.45607664619945e-05,
      "loss": 0.8226,
      "step": 291800
    },
    {
      "epoch": 3.089635350225756,
      "grad_norm": 4.010722637176514,
      "learning_rate": 3.455811983908533e-05,
      "loss": 0.8429,
      "step": 291850
    },
    {
      "epoch": 3.090164672005759,
      "grad_norm": 4.203857898712158,
      "learning_rate": 3.455547321617616e-05,
      "loss": 0.8226,
      "step": 291900
    },
    {
      "epoch": 3.0906939937857625,
      "grad_norm": 4.144420146942139,
      "learning_rate": 3.455282659326699e-05,
      "loss": 0.8228,
      "step": 291950
    },
    {
      "epoch": 3.091223315565766,
      "grad_norm": 3.801650285720825,
      "learning_rate": 3.455017997035783e-05,
      "loss": 0.8221,
      "step": 292000
    },
    {
      "epoch": 3.091223315565766,
      "eval_loss": 0.6077326536178589,
      "eval_runtime": 46.6352,
      "eval_samples_per_second": 3600.925,
      "eval_steps_per_second": 450.132,
      "step": 292000
    },
    {
      "epoch": 3.0917526373457687,
      "grad_norm": 4.065199851989746,
      "learning_rate": 3.454753334744866e-05,
      "loss": 0.8304,
      "step": 292050
    },
    {
      "epoch": 3.092281959125772,
      "grad_norm": 3.8595941066741943,
      "learning_rate": 3.454488672453949e-05,
      "loss": 0.8167,
      "step": 292100
    },
    {
      "epoch": 3.0928112809057753,
      "grad_norm": 4.127562522888184,
      "learning_rate": 3.454224010163032e-05,
      "loss": 0.8361,
      "step": 292150
    },
    {
      "epoch": 3.0933406026857786,
      "grad_norm": 4.029088973999023,
      "learning_rate": 3.453959347872115e-05,
      "loss": 0.8213,
      "step": 292200
    },
    {
      "epoch": 3.093869924465782,
      "grad_norm": 3.8961610794067383,
      "learning_rate": 3.453694685581199e-05,
      "loss": 0.8289,
      "step": 292250
    },
    {
      "epoch": 3.094399246245785,
      "grad_norm": 4.314502239227295,
      "learning_rate": 3.4534300232902814e-05,
      "loss": 0.84,
      "step": 292300
    },
    {
      "epoch": 3.0949285680257885,
      "grad_norm": 4.335659980773926,
      "learning_rate": 3.453165360999365e-05,
      "loss": 0.8338,
      "step": 292350
    },
    {
      "epoch": 3.095457889805792,
      "grad_norm": 3.950272798538208,
      "learning_rate": 3.452900698708448e-05,
      "loss": 0.8279,
      "step": 292400
    },
    {
      "epoch": 3.095987211585795,
      "grad_norm": 3.831108808517456,
      "learning_rate": 3.4526360364175316e-05,
      "loss": 0.8254,
      "step": 292450
    },
    {
      "epoch": 3.0965165333657985,
      "grad_norm": 4.061082363128662,
      "learning_rate": 3.4523713741266144e-05,
      "loss": 0.829,
      "step": 292500
    },
    {
      "epoch": 3.0965165333657985,
      "eval_loss": 0.6092672348022461,
      "eval_runtime": 46.6239,
      "eval_samples_per_second": 3601.801,
      "eval_steps_per_second": 450.241,
      "step": 292500
    },
    {
      "epoch": 3.0970458551458018,
      "grad_norm": 3.9133801460266113,
      "learning_rate": 3.452106711835698e-05,
      "loss": 0.8315,
      "step": 292550
    },
    {
      "epoch": 3.097575176925805,
      "grad_norm": 3.9480152130126953,
      "learning_rate": 3.451842049544781e-05,
      "loss": 0.8288,
      "step": 292600
    },
    {
      "epoch": 3.0981044987058084,
      "grad_norm": 4.009571075439453,
      "learning_rate": 3.451577387253864e-05,
      "loss": 0.8366,
      "step": 292650
    },
    {
      "epoch": 3.0986338204858117,
      "grad_norm": 4.085840225219727,
      "learning_rate": 3.4513127249629473e-05,
      "loss": 0.8178,
      "step": 292700
    },
    {
      "epoch": 3.099163142265815,
      "grad_norm": 3.7646169662475586,
      "learning_rate": 3.45104806267203e-05,
      "loss": 0.8246,
      "step": 292750
    },
    {
      "epoch": 3.099692464045818,
      "grad_norm": 4.050097942352295,
      "learning_rate": 3.450783400381114e-05,
      "loss": 0.8385,
      "step": 292800
    },
    {
      "epoch": 3.100221785825821,
      "grad_norm": 3.9319722652435303,
      "learning_rate": 3.450518738090197e-05,
      "loss": 0.836,
      "step": 292850
    },
    {
      "epoch": 3.1007511076058245,
      "grad_norm": 4.154612064361572,
      "learning_rate": 3.45025407579928e-05,
      "loss": 0.8459,
      "step": 292900
    },
    {
      "epoch": 3.101280429385828,
      "grad_norm": 3.778719425201416,
      "learning_rate": 3.449989413508363e-05,
      "loss": 0.8178,
      "step": 292950
    },
    {
      "epoch": 3.101809751165831,
      "grad_norm": 4.133437156677246,
      "learning_rate": 3.449724751217447e-05,
      "loss": 0.8217,
      "step": 293000
    },
    {
      "epoch": 3.101809751165831,
      "eval_loss": 0.6050919890403748,
      "eval_runtime": 46.4993,
      "eval_samples_per_second": 3611.453,
      "eval_steps_per_second": 451.448,
      "step": 293000
    },
    {
      "epoch": 3.1023390729458344,
      "grad_norm": 3.677480936050415,
      "learning_rate": 3.44946008892653e-05,
      "loss": 0.8303,
      "step": 293050
    },
    {
      "epoch": 3.1028683947258378,
      "grad_norm": 4.205140113830566,
      "learning_rate": 3.449195426635613e-05,
      "loss": 0.8268,
      "step": 293100
    },
    {
      "epoch": 3.103397716505841,
      "grad_norm": 4.152088642120361,
      "learning_rate": 3.448930764344696e-05,
      "loss": 0.8306,
      "step": 293150
    },
    {
      "epoch": 3.1039270382858444,
      "grad_norm": 4.161297798156738,
      "learning_rate": 3.4486661020537794e-05,
      "loss": 0.8339,
      "step": 293200
    },
    {
      "epoch": 3.1044563600658477,
      "grad_norm": 3.8522751331329346,
      "learning_rate": 3.448401439762863e-05,
      "loss": 0.8342,
      "step": 293250
    },
    {
      "epoch": 3.104985681845851,
      "grad_norm": 4.110116958618164,
      "learning_rate": 3.4481367774719455e-05,
      "loss": 0.8101,
      "step": 293300
    },
    {
      "epoch": 3.1055150036258543,
      "grad_norm": 4.045888900756836,
      "learning_rate": 3.447872115181029e-05,
      "loss": 0.8256,
      "step": 293350
    },
    {
      "epoch": 3.1060443254058576,
      "grad_norm": 3.9614458084106445,
      "learning_rate": 3.4476074528901124e-05,
      "loss": 0.817,
      "step": 293400
    },
    {
      "epoch": 3.106573647185861,
      "grad_norm": 3.993945837020874,
      "learning_rate": 3.447342790599196e-05,
      "loss": 0.8303,
      "step": 293450
    },
    {
      "epoch": 3.1071029689658642,
      "grad_norm": 4.017057418823242,
      "learning_rate": 3.4470781283082785e-05,
      "loss": 0.824,
      "step": 293500
    },
    {
      "epoch": 3.1071029689658642,
      "eval_loss": 0.6055890321731567,
      "eval_runtime": 46.5969,
      "eval_samples_per_second": 3603.884,
      "eval_steps_per_second": 450.502,
      "step": 293500
    },
    {
      "epoch": 3.107632290745867,
      "grad_norm": 4.14739990234375,
      "learning_rate": 3.446813466017362e-05,
      "loss": 0.827,
      "step": 293550
    },
    {
      "epoch": 3.1081616125258704,
      "grad_norm": 3.948284387588501,
      "learning_rate": 3.446548803726445e-05,
      "loss": 0.8068,
      "step": 293600
    },
    {
      "epoch": 3.1086909343058737,
      "grad_norm": 4.316876411437988,
      "learning_rate": 3.446284141435529e-05,
      "loss": 0.8325,
      "step": 293650
    },
    {
      "epoch": 3.109220256085877,
      "grad_norm": 4.298998832702637,
      "learning_rate": 3.4460194791446115e-05,
      "loss": 0.8302,
      "step": 293700
    },
    {
      "epoch": 3.1097495778658804,
      "grad_norm": 3.5577754974365234,
      "learning_rate": 3.445754816853695e-05,
      "loss": 0.8147,
      "step": 293750
    },
    {
      "epoch": 3.1102788996458837,
      "grad_norm": 3.571690797805786,
      "learning_rate": 3.445490154562778e-05,
      "loss": 0.8192,
      "step": 293800
    },
    {
      "epoch": 3.110808221425887,
      "grad_norm": 4.258175849914551,
      "learning_rate": 3.445225492271861e-05,
      "loss": 0.8217,
      "step": 293850
    },
    {
      "epoch": 3.1113375432058903,
      "grad_norm": 4.133481979370117,
      "learning_rate": 3.4449608299809444e-05,
      "loss": 0.8215,
      "step": 293900
    },
    {
      "epoch": 3.1118668649858936,
      "grad_norm": 3.861348867416382,
      "learning_rate": 3.444696167690027e-05,
      "loss": 0.829,
      "step": 293950
    },
    {
      "epoch": 3.112396186765897,
      "grad_norm": 4.6062493324279785,
      "learning_rate": 3.444431505399111e-05,
      "loss": 0.8239,
      "step": 294000
    },
    {
      "epoch": 3.112396186765897,
      "eval_loss": 0.6072825789451599,
      "eval_runtime": 46.6137,
      "eval_samples_per_second": 3602.588,
      "eval_steps_per_second": 450.34,
      "step": 294000
    },
    {
      "epoch": 3.1129255085459,
      "grad_norm": 4.246335983276367,
      "learning_rate": 3.444166843108194e-05,
      "loss": 0.8273,
      "step": 294050
    },
    {
      "epoch": 3.1134548303259035,
      "grad_norm": 4.195059299468994,
      "learning_rate": 3.4439021808172774e-05,
      "loss": 0.804,
      "step": 294100
    },
    {
      "epoch": 3.113984152105907,
      "grad_norm": 3.8755648136138916,
      "learning_rate": 3.44363751852636e-05,
      "loss": 0.8229,
      "step": 294150
    },
    {
      "epoch": 3.11451347388591,
      "grad_norm": 3.9097068309783936,
      "learning_rate": 3.443372856235444e-05,
      "loss": 0.8217,
      "step": 294200
    },
    {
      "epoch": 3.1150427956659135,
      "grad_norm": 4.008903503417969,
      "learning_rate": 3.443108193944527e-05,
      "loss": 0.8194,
      "step": 294250
    },
    {
      "epoch": 3.1155721174459163,
      "grad_norm": 4.228353023529053,
      "learning_rate": 3.4428435316536104e-05,
      "loss": 0.8181,
      "step": 294300
    },
    {
      "epoch": 3.1161014392259196,
      "grad_norm": 4.073716640472412,
      "learning_rate": 3.442578869362693e-05,
      "loss": 0.8456,
      "step": 294350
    },
    {
      "epoch": 3.116630761005923,
      "grad_norm": 3.93333101272583,
      "learning_rate": 3.4423142070717765e-05,
      "loss": 0.8207,
      "step": 294400
    },
    {
      "epoch": 3.1171600827859263,
      "grad_norm": 4.0392255783081055,
      "learning_rate": 3.44204954478086e-05,
      "loss": 0.821,
      "step": 294450
    },
    {
      "epoch": 3.1176894045659296,
      "grad_norm": 4.292041778564453,
      "learning_rate": 3.4417848824899426e-05,
      "loss": 0.8366,
      "step": 294500
    },
    {
      "epoch": 3.1176894045659296,
      "eval_loss": 0.6060901284217834,
      "eval_runtime": 46.6022,
      "eval_samples_per_second": 3603.475,
      "eval_steps_per_second": 450.45,
      "step": 294500
    },
    {
      "epoch": 3.118218726345933,
      "grad_norm": 3.9775803089141846,
      "learning_rate": 3.441525513444844e-05,
      "loss": 0.8251,
      "step": 294550
    },
    {
      "epoch": 3.118748048125936,
      "grad_norm": 4.321412086486816,
      "learning_rate": 3.441260851153928e-05,
      "loss": 0.8166,
      "step": 294600
    },
    {
      "epoch": 3.1192773699059395,
      "grad_norm": 3.688061237335205,
      "learning_rate": 3.440996188863011e-05,
      "loss": 0.8237,
      "step": 294650
    },
    {
      "epoch": 3.119806691685943,
      "grad_norm": 4.065792083740234,
      "learning_rate": 3.4407315265720943e-05,
      "loss": 0.8426,
      "step": 294700
    },
    {
      "epoch": 3.120336013465946,
      "grad_norm": 4.251885890960693,
      "learning_rate": 3.440466864281177e-05,
      "loss": 0.8099,
      "step": 294750
    },
    {
      "epoch": 3.1208653352459494,
      "grad_norm": 4.101593017578125,
      "learning_rate": 3.4402022019902605e-05,
      "loss": 0.8341,
      "step": 294800
    },
    {
      "epoch": 3.1213946570259528,
      "grad_norm": 4.005572319030762,
      "learning_rate": 3.439937539699344e-05,
      "loss": 0.8208,
      "step": 294850
    },
    {
      "epoch": 3.121923978805956,
      "grad_norm": 4.0930495262146,
      "learning_rate": 3.4396728774084266e-05,
      "loss": 0.8198,
      "step": 294900
    },
    {
      "epoch": 3.1224533005859594,
      "grad_norm": 4.117367267608643,
      "learning_rate": 3.43940821511751e-05,
      "loss": 0.814,
      "step": 294950
    },
    {
      "epoch": 3.1229826223659627,
      "grad_norm": 4.392335891723633,
      "learning_rate": 3.4391435528265935e-05,
      "loss": 0.8213,
      "step": 295000
    },
    {
      "epoch": 3.1229826223659627,
      "eval_loss": 0.6043266654014587,
      "eval_runtime": 46.5667,
      "eval_samples_per_second": 3606.227,
      "eval_steps_per_second": 450.794,
      "step": 295000
    },
    {
      "epoch": 3.1235119441459656,
      "grad_norm": 3.758517265319824,
      "learning_rate": 3.438878890535677e-05,
      "loss": 0.824,
      "step": 295050
    },
    {
      "epoch": 3.124041265925969,
      "grad_norm": 3.962507486343384,
      "learning_rate": 3.4386142282447596e-05,
      "loss": 0.8225,
      "step": 295100
    },
    {
      "epoch": 3.124570587705972,
      "grad_norm": 4.374752998352051,
      "learning_rate": 3.438349565953843e-05,
      "loss": 0.8285,
      "step": 295150
    },
    {
      "epoch": 3.1250999094859755,
      "grad_norm": 3.8617098331451416,
      "learning_rate": 3.4380849036629264e-05,
      "loss": 0.8179,
      "step": 295200
    },
    {
      "epoch": 3.125629231265979,
      "grad_norm": 4.179999828338623,
      "learning_rate": 3.43782024137201e-05,
      "loss": 0.813,
      "step": 295250
    },
    {
      "epoch": 3.126158553045982,
      "grad_norm": 3.923408269882202,
      "learning_rate": 3.4375555790810926e-05,
      "loss": 0.8252,
      "step": 295300
    },
    {
      "epoch": 3.1266878748259854,
      "grad_norm": 4.326088905334473,
      "learning_rate": 3.437290916790176e-05,
      "loss": 0.829,
      "step": 295350
    },
    {
      "epoch": 3.1272171966059887,
      "grad_norm": 3.5876402854919434,
      "learning_rate": 3.4370262544992594e-05,
      "loss": 0.8173,
      "step": 295400
    },
    {
      "epoch": 3.127746518385992,
      "grad_norm": 4.149172306060791,
      "learning_rate": 3.436761592208342e-05,
      "loss": 0.8441,
      "step": 295450
    },
    {
      "epoch": 3.1282758401659954,
      "grad_norm": 4.311921119689941,
      "learning_rate": 3.4364969299174255e-05,
      "loss": 0.8182,
      "step": 295500
    },
    {
      "epoch": 3.1282758401659954,
      "eval_loss": 0.6051047444343567,
      "eval_runtime": 46.6007,
      "eval_samples_per_second": 3603.592,
      "eval_steps_per_second": 450.465,
      "step": 295500
    },
    {
      "epoch": 3.1288051619459987,
      "grad_norm": 4.328339576721191,
      "learning_rate": 3.436232267626508e-05,
      "loss": 0.8261,
      "step": 295550
    },
    {
      "epoch": 3.129334483726002,
      "grad_norm": 4.157444953918457,
      "learning_rate": 3.435967605335592e-05,
      "loss": 0.8305,
      "step": 295600
    },
    {
      "epoch": 3.1298638055060053,
      "grad_norm": 4.375686168670654,
      "learning_rate": 3.435702943044675e-05,
      "loss": 0.8274,
      "step": 295650
    },
    {
      "epoch": 3.1303931272860086,
      "grad_norm": 3.8326833248138428,
      "learning_rate": 3.4354382807537585e-05,
      "loss": 0.8154,
      "step": 295700
    },
    {
      "epoch": 3.130922449066012,
      "grad_norm": 3.719892978668213,
      "learning_rate": 3.435173618462841e-05,
      "loss": 0.8321,
      "step": 295750
    },
    {
      "epoch": 3.131451770846015,
      "grad_norm": 4.21687650680542,
      "learning_rate": 3.434908956171925e-05,
      "loss": 0.8252,
      "step": 295800
    },
    {
      "epoch": 3.131981092626018,
      "grad_norm": 4.123592853546143,
      "learning_rate": 3.434644293881008e-05,
      "loss": 0.8269,
      "step": 295850
    },
    {
      "epoch": 3.1325104144060214,
      "grad_norm": 4.547501564025879,
      "learning_rate": 3.4343796315900914e-05,
      "loss": 0.8108,
      "step": 295900
    },
    {
      "epoch": 3.1330397361860247,
      "grad_norm": 3.8441812992095947,
      "learning_rate": 3.434114969299174e-05,
      "loss": 0.8193,
      "step": 295950
    },
    {
      "epoch": 3.133569057966028,
      "grad_norm": 4.327723979949951,
      "learning_rate": 3.4338503070082576e-05,
      "loss": 0.8214,
      "step": 296000
    },
    {
      "epoch": 3.133569057966028,
      "eval_loss": 0.6042507290840149,
      "eval_runtime": 46.6764,
      "eval_samples_per_second": 3597.747,
      "eval_steps_per_second": 449.734,
      "step": 296000
    },
    {
      "epoch": 3.1340983797460313,
      "grad_norm": 4.26704216003418,
      "learning_rate": 3.433585644717341e-05,
      "loss": 0.8372,
      "step": 296050
    },
    {
      "epoch": 3.1346277015260346,
      "grad_norm": 3.987116575241089,
      "learning_rate": 3.433320982426424e-05,
      "loss": 0.8249,
      "step": 296100
    },
    {
      "epoch": 3.135157023306038,
      "grad_norm": 3.7737109661102295,
      "learning_rate": 3.433056320135507e-05,
      "loss": 0.8065,
      "step": 296150
    },
    {
      "epoch": 3.1356863450860413,
      "grad_norm": 4.53731632232666,
      "learning_rate": 3.4327916578445905e-05,
      "loss": 0.828,
      "step": 296200
    },
    {
      "epoch": 3.1362156668660446,
      "grad_norm": 4.037403106689453,
      "learning_rate": 3.432526995553674e-05,
      "loss": 0.8291,
      "step": 296250
    },
    {
      "epoch": 3.136744988646048,
      "grad_norm": 3.94914174079895,
      "learning_rate": 3.432262333262757e-05,
      "loss": 0.8208,
      "step": 296300
    },
    {
      "epoch": 3.137274310426051,
      "grad_norm": 3.8131496906280518,
      "learning_rate": 3.43199767097184e-05,
      "loss": 0.8262,
      "step": 296350
    },
    {
      "epoch": 3.1378036322060545,
      "grad_norm": 4.231821060180664,
      "learning_rate": 3.4317330086809235e-05,
      "loss": 0.8361,
      "step": 296400
    },
    {
      "epoch": 3.138332953986058,
      "grad_norm": 3.9068331718444824,
      "learning_rate": 3.431468346390007e-05,
      "loss": 0.8326,
      "step": 296450
    },
    {
      "epoch": 3.138862275766061,
      "grad_norm": 4.059396266937256,
      "learning_rate": 3.4312036840990897e-05,
      "loss": 0.8343,
      "step": 296500
    },
    {
      "epoch": 3.138862275766061,
      "eval_loss": 0.603191614151001,
      "eval_runtime": 46.5641,
      "eval_samples_per_second": 3606.43,
      "eval_steps_per_second": 450.82,
      "step": 296500
    },
    {
      "epoch": 3.139391597546064,
      "grad_norm": 4.592348098754883,
      "learning_rate": 3.430939021808173e-05,
      "loss": 0.8351,
      "step": 296550
    },
    {
      "epoch": 3.1399209193260673,
      "grad_norm": 4.065619945526123,
      "learning_rate": 3.4306743595172565e-05,
      "loss": 0.8355,
      "step": 296600
    },
    {
      "epoch": 3.1404502411060706,
      "grad_norm": 4.242433547973633,
      "learning_rate": 3.430409697226339e-05,
      "loss": 0.8283,
      "step": 296650
    },
    {
      "epoch": 3.140979562886074,
      "grad_norm": 3.8359644412994385,
      "learning_rate": 3.4301450349354226e-05,
      "loss": 0.8177,
      "step": 296700
    },
    {
      "epoch": 3.1415088846660773,
      "grad_norm": 4.020566940307617,
      "learning_rate": 3.4298803726445053e-05,
      "loss": 0.8258,
      "step": 296750
    },
    {
      "epoch": 3.1420382064460806,
      "grad_norm": 3.802612066268921,
      "learning_rate": 3.4296157103535894e-05,
      "loss": 0.8138,
      "step": 296800
    },
    {
      "epoch": 3.142567528226084,
      "grad_norm": 4.264091968536377,
      "learning_rate": 3.429351048062672e-05,
      "loss": 0.8305,
      "step": 296850
    },
    {
      "epoch": 3.143096850006087,
      "grad_norm": 4.120992660522461,
      "learning_rate": 3.4290863857717556e-05,
      "loss": 0.8119,
      "step": 296900
    },
    {
      "epoch": 3.1436261717860905,
      "grad_norm": 4.252083778381348,
      "learning_rate": 3.428821723480838e-05,
      "loss": 0.8123,
      "step": 296950
    },
    {
      "epoch": 3.144155493566094,
      "grad_norm": 3.8622138500213623,
      "learning_rate": 3.428557061189922e-05,
      "loss": 0.8363,
      "step": 297000
    },
    {
      "epoch": 3.144155493566094,
      "eval_loss": 0.6059913635253906,
      "eval_runtime": 46.605,
      "eval_samples_per_second": 3603.264,
      "eval_steps_per_second": 450.424,
      "step": 297000
    },
    {
      "epoch": 3.144684815346097,
      "grad_norm": 3.8273427486419678,
      "learning_rate": 3.428292398899005e-05,
      "loss": 0.8336,
      "step": 297050
    },
    {
      "epoch": 3.1452141371261004,
      "grad_norm": 4.05962610244751,
      "learning_rate": 3.428027736608088e-05,
      "loss": 0.8268,
      "step": 297100
    },
    {
      "epoch": 3.1457434589061037,
      "grad_norm": 4.093734264373779,
      "learning_rate": 3.427763074317171e-05,
      "loss": 0.8168,
      "step": 297150
    },
    {
      "epoch": 3.146272780686107,
      "grad_norm": 4.08863639831543,
      "learning_rate": 3.427498412026255e-05,
      "loss": 0.8169,
      "step": 297200
    },
    {
      "epoch": 3.1468021024661104,
      "grad_norm": 4.1822028160095215,
      "learning_rate": 3.427233749735338e-05,
      "loss": 0.8244,
      "step": 297250
    },
    {
      "epoch": 3.1473314242461132,
      "grad_norm": 3.70725679397583,
      "learning_rate": 3.426969087444421e-05,
      "loss": 0.8136,
      "step": 297300
    },
    {
      "epoch": 3.1478607460261165,
      "grad_norm": 3.967456817626953,
      "learning_rate": 3.426704425153504e-05,
      "loss": 0.8212,
      "step": 297350
    },
    {
      "epoch": 3.14839006780612,
      "grad_norm": 4.12796688079834,
      "learning_rate": 3.4264397628625876e-05,
      "loss": 0.8342,
      "step": 297400
    },
    {
      "epoch": 3.148919389586123,
      "grad_norm": 4.352338790893555,
      "learning_rate": 3.426175100571671e-05,
      "loss": 0.8288,
      "step": 297450
    },
    {
      "epoch": 3.1494487113661265,
      "grad_norm": 3.971268892288208,
      "learning_rate": 3.425910438280754e-05,
      "loss": 0.8266,
      "step": 297500
    },
    {
      "epoch": 3.1494487113661265,
      "eval_loss": 0.6029715538024902,
      "eval_runtime": 46.5366,
      "eval_samples_per_second": 3608.555,
      "eval_steps_per_second": 451.086,
      "step": 297500
    },
    {
      "epoch": 3.14997803314613,
      "grad_norm": 4.054682731628418,
      "learning_rate": 3.425645775989837e-05,
      "loss": 0.8379,
      "step": 297550
    },
    {
      "epoch": 3.150507354926133,
      "grad_norm": 4.056510925292969,
      "learning_rate": 3.4253811136989206e-05,
      "loss": 0.8228,
      "step": 297600
    },
    {
      "epoch": 3.1510366767061364,
      "grad_norm": 4.352908134460449,
      "learning_rate": 3.425116451408003e-05,
      "loss": 0.8204,
      "step": 297650
    },
    {
      "epoch": 3.1515659984861397,
      "grad_norm": 4.106861591339111,
      "learning_rate": 3.424851789117087e-05,
      "loss": 0.8191,
      "step": 297700
    },
    {
      "epoch": 3.152095320266143,
      "grad_norm": 3.6015968322753906,
      "learning_rate": 3.4245871268261695e-05,
      "loss": 0.8205,
      "step": 297750
    },
    {
      "epoch": 3.1526246420461463,
      "grad_norm": 3.811903953552246,
      "learning_rate": 3.4243224645352536e-05,
      "loss": 0.838,
      "step": 297800
    },
    {
      "epoch": 3.1531539638261497,
      "grad_norm": 3.798837184906006,
      "learning_rate": 3.424057802244336e-05,
      "loss": 0.8117,
      "step": 297850
    },
    {
      "epoch": 3.153683285606153,
      "grad_norm": 4.211691379547119,
      "learning_rate": 3.423798433199238e-05,
      "loss": 0.8343,
      "step": 297900
    },
    {
      "epoch": 3.1542126073861563,
      "grad_norm": 4.054213523864746,
      "learning_rate": 3.423533770908321e-05,
      "loss": 0.8204,
      "step": 297950
    },
    {
      "epoch": 3.1547419291661596,
      "grad_norm": 4.043185710906982,
      "learning_rate": 3.4232691086174046e-05,
      "loss": 0.8364,
      "step": 298000
    },
    {
      "epoch": 3.1547419291661596,
      "eval_loss": 0.6039635539054871,
      "eval_runtime": 46.8235,
      "eval_samples_per_second": 3586.445,
      "eval_steps_per_second": 448.322,
      "step": 298000
    },
    {
      "epoch": 3.1552712509461625,
      "grad_norm": 3.5705618858337402,
      "learning_rate": 3.423004446326487e-05,
      "loss": 0.8138,
      "step": 298050
    },
    {
      "epoch": 3.1558005727261658,
      "grad_norm": 4.351252555847168,
      "learning_rate": 3.422739784035571e-05,
      "loss": 0.8039,
      "step": 298100
    },
    {
      "epoch": 3.156329894506169,
      "grad_norm": 3.8780081272125244,
      "learning_rate": 3.4224751217446535e-05,
      "loss": 0.8203,
      "step": 298150
    },
    {
      "epoch": 3.1568592162861724,
      "grad_norm": 4.311305999755859,
      "learning_rate": 3.4222104594537376e-05,
      "loss": 0.8329,
      "step": 298200
    },
    {
      "epoch": 3.1573885380661757,
      "grad_norm": 4.091690540313721,
      "learning_rate": 3.42194579716282e-05,
      "loss": 0.8179,
      "step": 298250
    },
    {
      "epoch": 3.157917859846179,
      "grad_norm": 4.321452617645264,
      "learning_rate": 3.421681134871904e-05,
      "loss": 0.8303,
      "step": 298300
    },
    {
      "epoch": 3.1584471816261823,
      "grad_norm": 4.0094757080078125,
      "learning_rate": 3.4214164725809864e-05,
      "loss": 0.8373,
      "step": 298350
    },
    {
      "epoch": 3.1589765034061856,
      "grad_norm": 3.6309592723846436,
      "learning_rate": 3.4211518102900705e-05,
      "loss": 0.8032,
      "step": 298400
    },
    {
      "epoch": 3.159505825186189,
      "grad_norm": 4.01055908203125,
      "learning_rate": 3.420887147999153e-05,
      "loss": 0.835,
      "step": 298450
    },
    {
      "epoch": 3.1600351469661923,
      "grad_norm": 3.9032251834869385,
      "learning_rate": 3.4206224857082367e-05,
      "loss": 0.8267,
      "step": 298500
    },
    {
      "epoch": 3.1600351469661923,
      "eval_loss": 0.6008734703063965,
      "eval_runtime": 46.7357,
      "eval_samples_per_second": 3593.182,
      "eval_steps_per_second": 449.164,
      "step": 298500
    },
    {
      "epoch": 3.1605644687461956,
      "grad_norm": 3.58719539642334,
      "learning_rate": 3.4203578234173194e-05,
      "loss": 0.8319,
      "step": 298550
    },
    {
      "epoch": 3.161093790526199,
      "grad_norm": 4.142009735107422,
      "learning_rate": 3.420093161126403e-05,
      "loss": 0.8311,
      "step": 298600
    },
    {
      "epoch": 3.161623112306202,
      "grad_norm": 4.185924530029297,
      "learning_rate": 3.419828498835486e-05,
      "loss": 0.8263,
      "step": 298650
    },
    {
      "epoch": 3.1621524340862055,
      "grad_norm": 4.0990142822265625,
      "learning_rate": 3.419563836544569e-05,
      "loss": 0.8292,
      "step": 298700
    },
    {
      "epoch": 3.162681755866209,
      "grad_norm": 4.111244201660156,
      "learning_rate": 3.4192991742536524e-05,
      "loss": 0.812,
      "step": 298750
    },
    {
      "epoch": 3.1632110776462117,
      "grad_norm": 4.471916198730469,
      "learning_rate": 3.419034511962736e-05,
      "loss": 0.8289,
      "step": 298800
    },
    {
      "epoch": 3.163740399426215,
      "grad_norm": 4.125274181365967,
      "learning_rate": 3.418769849671819e-05,
      "loss": 0.8281,
      "step": 298850
    },
    {
      "epoch": 3.1642697212062183,
      "grad_norm": 4.419642925262451,
      "learning_rate": 3.418505187380902e-05,
      "loss": 0.8175,
      "step": 298900
    },
    {
      "epoch": 3.1647990429862216,
      "grad_norm": 4.439271450042725,
      "learning_rate": 3.418240525089985e-05,
      "loss": 0.8144,
      "step": 298950
    },
    {
      "epoch": 3.165328364766225,
      "grad_norm": 4.150981426239014,
      "learning_rate": 3.417975862799069e-05,
      "loss": 0.8147,
      "step": 299000
    },
    {
      "epoch": 3.165328364766225,
      "eval_loss": 0.5999975800514221,
      "eval_runtime": 46.6427,
      "eval_samples_per_second": 3600.353,
      "eval_steps_per_second": 450.06,
      "step": 299000
    },
    {
      "epoch": 3.1658576865462282,
      "grad_norm": 4.1749138832092285,
      "learning_rate": 3.417711200508152e-05,
      "loss": 0.816,
      "step": 299050
    },
    {
      "epoch": 3.1663870083262315,
      "grad_norm": 3.673060417175293,
      "learning_rate": 3.417446538217235e-05,
      "loss": 0.8263,
      "step": 299100
    },
    {
      "epoch": 3.166916330106235,
      "grad_norm": 4.126952648162842,
      "learning_rate": 3.417181875926318e-05,
      "loss": 0.8264,
      "step": 299150
    },
    {
      "epoch": 3.167445651886238,
      "grad_norm": 3.811307430267334,
      "learning_rate": 3.416917213635402e-05,
      "loss": 0.8351,
      "step": 299200
    },
    {
      "epoch": 3.1679749736662415,
      "grad_norm": 4.189073085784912,
      "learning_rate": 3.4166525513444844e-05,
      "loss": 0.809,
      "step": 299250
    },
    {
      "epoch": 3.168504295446245,
      "grad_norm": 4.156988143920898,
      "learning_rate": 3.416387889053568e-05,
      "loss": 0.8321,
      "step": 299300
    },
    {
      "epoch": 3.169033617226248,
      "grad_norm": 3.856271266937256,
      "learning_rate": 3.4161232267626506e-05,
      "loss": 0.8227,
      "step": 299350
    },
    {
      "epoch": 3.1695629390062514,
      "grad_norm": 3.9974205493927,
      "learning_rate": 3.4158585644717347e-05,
      "loss": 0.8102,
      "step": 299400
    },
    {
      "epoch": 3.1700922607862547,
      "grad_norm": 4.010885238647461,
      "learning_rate": 3.4155939021808174e-05,
      "loss": 0.8129,
      "step": 299450
    },
    {
      "epoch": 3.170621582566258,
      "grad_norm": 4.024787425994873,
      "learning_rate": 3.415329239889901e-05,
      "loss": 0.8291,
      "step": 299500
    },
    {
      "epoch": 3.170621582566258,
      "eval_loss": 0.5988774299621582,
      "eval_runtime": 46.6037,
      "eval_samples_per_second": 3603.363,
      "eval_steps_per_second": 450.437,
      "step": 299500
    },
    {
      "epoch": 3.171150904346261,
      "grad_norm": 4.381378650665283,
      "learning_rate": 3.4150645775989835e-05,
      "loss": 0.8282,
      "step": 299550
    },
    {
      "epoch": 3.171680226126264,
      "grad_norm": 3.98637318611145,
      "learning_rate": 3.4147999153080676e-05,
      "loss": 0.824,
      "step": 299600
    },
    {
      "epoch": 3.1722095479062675,
      "grad_norm": 4.113097190856934,
      "learning_rate": 3.4145352530171503e-05,
      "loss": 0.824,
      "step": 299650
    },
    {
      "epoch": 3.172738869686271,
      "grad_norm": 4.1218953132629395,
      "learning_rate": 3.414270590726234e-05,
      "loss": 0.8179,
      "step": 299700
    },
    {
      "epoch": 3.173268191466274,
      "grad_norm": 4.108673572540283,
      "learning_rate": 3.4140059284353165e-05,
      "loss": 0.8122,
      "step": 299750
    },
    {
      "epoch": 3.1737975132462775,
      "grad_norm": 3.834616184234619,
      "learning_rate": 3.4137412661444e-05,
      "loss": 0.8251,
      "step": 299800
    },
    {
      "epoch": 3.1743268350262808,
      "grad_norm": 3.693995475769043,
      "learning_rate": 3.413476603853483e-05,
      "loss": 0.8286,
      "step": 299850
    },
    {
      "epoch": 3.174856156806284,
      "grad_norm": 4.152275562286377,
      "learning_rate": 3.413211941562566e-05,
      "loss": 0.8228,
      "step": 299900
    },
    {
      "epoch": 3.1753854785862874,
      "grad_norm": 4.2406206130981445,
      "learning_rate": 3.4129472792716494e-05,
      "loss": 0.8127,
      "step": 299950
    },
    {
      "epoch": 3.1759148003662907,
      "grad_norm": 4.494316577911377,
      "learning_rate": 3.412682616980733e-05,
      "loss": 0.8105,
      "step": 300000
    },
    {
      "epoch": 3.1759148003662907,
      "eval_loss": 0.5991565585136414,
      "eval_runtime": 46.5091,
      "eval_samples_per_second": 3610.693,
      "eval_steps_per_second": 451.353,
      "step": 300000
    },
    {
      "epoch": 3.176444122146294,
      "grad_norm": 3.998164653778076,
      "learning_rate": 3.412417954689816e-05,
      "loss": 0.826,
      "step": 300050
    },
    {
      "epoch": 3.1769734439262973,
      "grad_norm": 4.4088029861450195,
      "learning_rate": 3.412153292398899e-05,
      "loss": 0.8184,
      "step": 300100
    },
    {
      "epoch": 3.1775027657063006,
      "grad_norm": 3.9930636882781982,
      "learning_rate": 3.4118886301079824e-05,
      "loss": 0.8197,
      "step": 300150
    },
    {
      "epoch": 3.178032087486304,
      "grad_norm": 4.190886497497559,
      "learning_rate": 3.411623967817066e-05,
      "loss": 0.8387,
      "step": 300200
    },
    {
      "epoch": 3.1785614092663073,
      "grad_norm": 3.77497935295105,
      "learning_rate": 3.411364598771967e-05,
      "loss": 0.8097,
      "step": 300250
    },
    {
      "epoch": 3.1790907310463106,
      "grad_norm": 4.606921672821045,
      "learning_rate": 3.41109993648105e-05,
      "loss": 0.8289,
      "step": 300300
    },
    {
      "epoch": 3.1796200528263134,
      "grad_norm": 4.443066596984863,
      "learning_rate": 3.4108352741901334e-05,
      "loss": 0.8076,
      "step": 300350
    },
    {
      "epoch": 3.1801493746063167,
      "grad_norm": 4.316727161407471,
      "learning_rate": 3.410570611899217e-05,
      "loss": 0.8153,
      "step": 300400
    },
    {
      "epoch": 3.18067869638632,
      "grad_norm": 4.655040264129639,
      "learning_rate": 3.4103059496083e-05,
      "loss": 0.8215,
      "step": 300450
    },
    {
      "epoch": 3.1812080181663234,
      "grad_norm": 4.552608489990234,
      "learning_rate": 3.410041287317383e-05,
      "loss": 0.8225,
      "step": 300500
    },
    {
      "epoch": 3.1812080181663234,
      "eval_loss": 0.5995796918869019,
      "eval_runtime": 46.5892,
      "eval_samples_per_second": 3604.483,
      "eval_steps_per_second": 450.577,
      "step": 300500
    },
    {
      "epoch": 3.1817373399463267,
      "grad_norm": 4.531546115875244,
      "learning_rate": 3.4097766250264664e-05,
      "loss": 0.8088,
      "step": 300550
    },
    {
      "epoch": 3.18226666172633,
      "grad_norm": 4.071277141571045,
      "learning_rate": 3.40951196273555e-05,
      "loss": 0.8123,
      "step": 300600
    },
    {
      "epoch": 3.1827959835063333,
      "grad_norm": 4.015937805175781,
      "learning_rate": 3.409247300444633e-05,
      "loss": 0.828,
      "step": 300650
    },
    {
      "epoch": 3.1833253052863366,
      "grad_norm": 4.181141376495361,
      "learning_rate": 3.408982638153716e-05,
      "loss": 0.8195,
      "step": 300700
    },
    {
      "epoch": 3.18385462706634,
      "grad_norm": 4.004236221313477,
      "learning_rate": 3.4087179758627994e-05,
      "loss": 0.8142,
      "step": 300750
    },
    {
      "epoch": 3.1843839488463432,
      "grad_norm": 3.8085856437683105,
      "learning_rate": 3.408453313571883e-05,
      "loss": 0.8121,
      "step": 300800
    },
    {
      "epoch": 3.1849132706263465,
      "grad_norm": 4.297459125518799,
      "learning_rate": 3.4081886512809655e-05,
      "loss": 0.8271,
      "step": 300850
    },
    {
      "epoch": 3.18544259240635,
      "grad_norm": 4.0724639892578125,
      "learning_rate": 3.407923988990049e-05,
      "loss": 0.8242,
      "step": 300900
    },
    {
      "epoch": 3.185971914186353,
      "grad_norm": 4.084055423736572,
      "learning_rate": 3.4076593266991316e-05,
      "loss": 0.824,
      "step": 300950
    },
    {
      "epoch": 3.1865012359663565,
      "grad_norm": 4.209538459777832,
      "learning_rate": 3.407394664408216e-05,
      "loss": 0.8342,
      "step": 301000
    },
    {
      "epoch": 3.1865012359663565,
      "eval_loss": 0.598465085029602,
      "eval_runtime": 46.5563,
      "eval_samples_per_second": 3607.029,
      "eval_steps_per_second": 450.895,
      "step": 301000
    },
    {
      "epoch": 3.18703055774636,
      "grad_norm": 3.997572660446167,
      "learning_rate": 3.4071300021172985e-05,
      "loss": 0.8342,
      "step": 301050
    },
    {
      "epoch": 3.187559879526363,
      "grad_norm": 4.028564453125,
      "learning_rate": 3.406865339826382e-05,
      "loss": 0.8293,
      "step": 301100
    },
    {
      "epoch": 3.188089201306366,
      "grad_norm": 3.772948980331421,
      "learning_rate": 3.4066006775354646e-05,
      "loss": 0.8123,
      "step": 301150
    },
    {
      "epoch": 3.1886185230863693,
      "grad_norm": 3.707982063293457,
      "learning_rate": 3.406336015244549e-05,
      "loss": 0.8055,
      "step": 301200
    },
    {
      "epoch": 3.1891478448663726,
      "grad_norm": 4.063892841339111,
      "learning_rate": 3.4060713529536314e-05,
      "loss": 0.8074,
      "step": 301250
    },
    {
      "epoch": 3.189677166646376,
      "grad_norm": 3.4100821018218994,
      "learning_rate": 3.405806690662715e-05,
      "loss": 0.8088,
      "step": 301300
    },
    {
      "epoch": 3.190206488426379,
      "grad_norm": 3.7895278930664062,
      "learning_rate": 3.4055420283717976e-05,
      "loss": 0.8027,
      "step": 301350
    },
    {
      "epoch": 3.1907358102063825,
      "grad_norm": 4.0793986320495605,
      "learning_rate": 3.405277366080881e-05,
      "loss": 0.8283,
      "step": 301400
    },
    {
      "epoch": 3.191265131986386,
      "grad_norm": 4.199124813079834,
      "learning_rate": 3.4050127037899644e-05,
      "loss": 0.8218,
      "step": 301450
    },
    {
      "epoch": 3.191794453766389,
      "grad_norm": 4.2403340339660645,
      "learning_rate": 3.404748041499047e-05,
      "loss": 0.8065,
      "step": 301500
    },
    {
      "epoch": 3.191794453766389,
      "eval_loss": 0.5976765155792236,
      "eval_runtime": 46.7782,
      "eval_samples_per_second": 3589.922,
      "eval_steps_per_second": 448.756,
      "step": 301500
    },
    {
      "epoch": 3.1923237755463925,
      "grad_norm": 3.8984029293060303,
      "learning_rate": 3.4044833792081305e-05,
      "loss": 0.8097,
      "step": 301550
    },
    {
      "epoch": 3.1928530973263958,
      "grad_norm": 4.0995097160339355,
      "learning_rate": 3.404218716917214e-05,
      "loss": 0.8302,
      "step": 301600
    },
    {
      "epoch": 3.193382419106399,
      "grad_norm": 4.19497013092041,
      "learning_rate": 3.4039540546262974e-05,
      "loss": 0.8371,
      "step": 301650
    },
    {
      "epoch": 3.1939117408864024,
      "grad_norm": 3.945687770843506,
      "learning_rate": 3.40368939233538e-05,
      "loss": 0.8121,
      "step": 301700
    },
    {
      "epoch": 3.1944410626664057,
      "grad_norm": 4.471031665802002,
      "learning_rate": 3.4034247300444635e-05,
      "loss": 0.8173,
      "step": 301750
    },
    {
      "epoch": 3.194970384446409,
      "grad_norm": 4.228965759277344,
      "learning_rate": 3.403160067753547e-05,
      "loss": 0.8329,
      "step": 301800
    },
    {
      "epoch": 3.1954997062264123,
      "grad_norm": 3.94675350189209,
      "learning_rate": 3.4028954054626296e-05,
      "loss": 0.8184,
      "step": 301850
    },
    {
      "epoch": 3.196029028006415,
      "grad_norm": 3.8265724182128906,
      "learning_rate": 3.402630743171713e-05,
      "loss": 0.8229,
      "step": 301900
    },
    {
      "epoch": 3.1965583497864185,
      "grad_norm": 4.269475936889648,
      "learning_rate": 3.402366080880796e-05,
      "loss": 0.8255,
      "step": 301950
    },
    {
      "epoch": 3.197087671566422,
      "grad_norm": 4.043603420257568,
      "learning_rate": 3.40210141858988e-05,
      "loss": 0.8184,
      "step": 302000
    },
    {
      "epoch": 3.197087671566422,
      "eval_loss": 0.5973847508430481,
      "eval_runtime": 46.5016,
      "eval_samples_per_second": 3611.27,
      "eval_steps_per_second": 451.425,
      "step": 302000
    },
    {
      "epoch": 3.197616993346425,
      "grad_norm": 3.899834156036377,
      "learning_rate": 3.4018367562989626e-05,
      "loss": 0.8206,
      "step": 302050
    },
    {
      "epoch": 3.1981463151264284,
      "grad_norm": 4.209798812866211,
      "learning_rate": 3.401572094008046e-05,
      "loss": 0.8346,
      "step": 302100
    },
    {
      "epoch": 3.1986756369064318,
      "grad_norm": 4.220602035522461,
      "learning_rate": 3.401307431717129e-05,
      "loss": 0.8264,
      "step": 302150
    },
    {
      "epoch": 3.199204958686435,
      "grad_norm": 4.29976749420166,
      "learning_rate": 3.401042769426213e-05,
      "loss": 0.8139,
      "step": 302200
    },
    {
      "epoch": 3.1997342804664384,
      "grad_norm": 3.9442951679229736,
      "learning_rate": 3.4007781071352956e-05,
      "loss": 0.8142,
      "step": 302250
    },
    {
      "epoch": 3.2002636022464417,
      "grad_norm": 4.3778157234191895,
      "learning_rate": 3.400513444844379e-05,
      "loss": 0.8219,
      "step": 302300
    },
    {
      "epoch": 3.200792924026445,
      "grad_norm": 3.9817910194396973,
      "learning_rate": 3.400248782553462e-05,
      "loss": 0.8256,
      "step": 302350
    },
    {
      "epoch": 3.2013222458064483,
      "grad_norm": 3.8886420726776123,
      "learning_rate": 3.399984120262545e-05,
      "loss": 0.8316,
      "step": 302400
    },
    {
      "epoch": 3.2018515675864516,
      "grad_norm": 4.200351715087891,
      "learning_rate": 3.3997194579716285e-05,
      "loss": 0.8252,
      "step": 302450
    },
    {
      "epoch": 3.202380889366455,
      "grad_norm": 4.068443775177002,
      "learning_rate": 3.399454795680711e-05,
      "loss": 0.8412,
      "step": 302500
    },
    {
      "epoch": 3.202380889366455,
      "eval_loss": 0.5983043313026428,
      "eval_runtime": 46.5983,
      "eval_samples_per_second": 3603.778,
      "eval_steps_per_second": 450.488,
      "step": 302500
    },
    {
      "epoch": 3.2029102111464582,
      "grad_norm": 3.8932607173919678,
      "learning_rate": 3.399190133389795e-05,
      "loss": 0.8205,
      "step": 302550
    },
    {
      "epoch": 3.2034395329264616,
      "grad_norm": 3.787900447845459,
      "learning_rate": 3.398925471098878e-05,
      "loss": 0.832,
      "step": 302600
    },
    {
      "epoch": 3.2039688547064644,
      "grad_norm": 3.872865676879883,
      "learning_rate": 3.3986608088079615e-05,
      "loss": 0.8125,
      "step": 302650
    },
    {
      "epoch": 3.2044981764864677,
      "grad_norm": 4.430974006652832,
      "learning_rate": 3.398396146517044e-05,
      "loss": 0.8239,
      "step": 302700
    },
    {
      "epoch": 3.205027498266471,
      "grad_norm": 3.993046283721924,
      "learning_rate": 3.3981314842261276e-05,
      "loss": 0.8157,
      "step": 302750
    },
    {
      "epoch": 3.2055568200464744,
      "grad_norm": 4.186671257019043,
      "learning_rate": 3.397866821935211e-05,
      "loss": 0.8315,
      "step": 302800
    },
    {
      "epoch": 3.2060861418264777,
      "grad_norm": 3.870821475982666,
      "learning_rate": 3.3976021596442944e-05,
      "loss": 0.8166,
      "step": 302850
    },
    {
      "epoch": 3.206615463606481,
      "grad_norm": 4.502368927001953,
      "learning_rate": 3.397337497353377e-05,
      "loss": 0.8309,
      "step": 302900
    },
    {
      "epoch": 3.2071447853864843,
      "grad_norm": 4.004633903503418,
      "learning_rate": 3.3970728350624606e-05,
      "loss": 0.8138,
      "step": 302950
    },
    {
      "epoch": 3.2076741071664876,
      "grad_norm": 4.196320533752441,
      "learning_rate": 3.396808172771544e-05,
      "loss": 0.8223,
      "step": 303000
    },
    {
      "epoch": 3.2076741071664876,
      "eval_loss": 0.5969740152359009,
      "eval_runtime": 46.6029,
      "eval_samples_per_second": 3603.427,
      "eval_steps_per_second": 450.444,
      "step": 303000
    },
    {
      "epoch": 3.208203428946491,
      "grad_norm": 4.101891994476318,
      "learning_rate": 3.396543510480627e-05,
      "loss": 0.8291,
      "step": 303050
    },
    {
      "epoch": 3.208732750726494,
      "grad_norm": 4.077635765075684,
      "learning_rate": 3.39627884818971e-05,
      "loss": 0.8254,
      "step": 303100
    },
    {
      "epoch": 3.2092620725064975,
      "grad_norm": 4.217067718505859,
      "learning_rate": 3.396014185898793e-05,
      "loss": 0.8322,
      "step": 303150
    },
    {
      "epoch": 3.209791394286501,
      "grad_norm": 4.203120708465576,
      "learning_rate": 3.395749523607876e-05,
      "loss": 0.8222,
      "step": 303200
    },
    {
      "epoch": 3.210320716066504,
      "grad_norm": 3.8506295680999756,
      "learning_rate": 3.39548486131696e-05,
      "loss": 0.8083,
      "step": 303250
    },
    {
      "epoch": 3.2108500378465075,
      "grad_norm": 4.349692344665527,
      "learning_rate": 3.395220199026043e-05,
      "loss": 0.804,
      "step": 303300
    },
    {
      "epoch": 3.2113793596265108,
      "grad_norm": 4.101215839385986,
      "learning_rate": 3.394955536735126e-05,
      "loss": 0.8182,
      "step": 303350
    },
    {
      "epoch": 3.2119086814065136,
      "grad_norm": 4.173540115356445,
      "learning_rate": 3.394690874444209e-05,
      "loss": 0.8282,
      "step": 303400
    },
    {
      "epoch": 3.212438003186517,
      "grad_norm": 3.8757846355438232,
      "learning_rate": 3.3944262121532927e-05,
      "loss": 0.8252,
      "step": 303450
    },
    {
      "epoch": 3.2129673249665203,
      "grad_norm": 3.817185640335083,
      "learning_rate": 3.394161549862376e-05,
      "loss": 0.8298,
      "step": 303500
    },
    {
      "epoch": 3.2129673249665203,
      "eval_loss": 0.5967146158218384,
      "eval_runtime": 46.6311,
      "eval_samples_per_second": 3601.243,
      "eval_steps_per_second": 450.171,
      "step": 303500
    },
    {
      "epoch": 3.2134966467465236,
      "grad_norm": 3.8155713081359863,
      "learning_rate": 3.393896887571459e-05,
      "loss": 0.8197,
      "step": 303550
    },
    {
      "epoch": 3.214025968526527,
      "grad_norm": 3.7345738410949707,
      "learning_rate": 3.393632225280542e-05,
      "loss": 0.8145,
      "step": 303600
    },
    {
      "epoch": 3.21455529030653,
      "grad_norm": 4.295445919036865,
      "learning_rate": 3.3933675629896256e-05,
      "loss": 0.8469,
      "step": 303650
    },
    {
      "epoch": 3.2150846120865335,
      "grad_norm": 4.387514114379883,
      "learning_rate": 3.3931029006987084e-05,
      "loss": 0.807,
      "step": 303700
    },
    {
      "epoch": 3.215613933866537,
      "grad_norm": 4.331158638000488,
      "learning_rate": 3.392838238407792e-05,
      "loss": 0.828,
      "step": 303750
    },
    {
      "epoch": 3.21614325564654,
      "grad_norm": 3.6962943077087402,
      "learning_rate": 3.3925735761168745e-05,
      "loss": 0.8265,
      "step": 303800
    },
    {
      "epoch": 3.2166725774265434,
      "grad_norm": 3.627255439758301,
      "learning_rate": 3.3923089138259586e-05,
      "loss": 0.8163,
      "step": 303850
    },
    {
      "epoch": 3.2172018992065468,
      "grad_norm": 4.086264133453369,
      "learning_rate": 3.392044251535041e-05,
      "loss": 0.821,
      "step": 303900
    },
    {
      "epoch": 3.21773122098655,
      "grad_norm": 3.902761459350586,
      "learning_rate": 3.391779589244125e-05,
      "loss": 0.8185,
      "step": 303950
    },
    {
      "epoch": 3.2182605427665534,
      "grad_norm": 3.995286703109741,
      "learning_rate": 3.3915149269532075e-05,
      "loss": 0.8241,
      "step": 304000
    },
    {
      "epoch": 3.2182605427665534,
      "eval_loss": 0.593873918056488,
      "eval_runtime": 46.6701,
      "eval_samples_per_second": 3598.239,
      "eval_steps_per_second": 449.796,
      "step": 304000
    },
    {
      "epoch": 3.2187898645465567,
      "grad_norm": 4.064055919647217,
      "learning_rate": 3.3912502646622915e-05,
      "loss": 0.8136,
      "step": 304050
    },
    {
      "epoch": 3.21931918632656,
      "grad_norm": 3.562404155731201,
      "learning_rate": 3.390985602371374e-05,
      "loss": 0.8145,
      "step": 304100
    },
    {
      "epoch": 3.219848508106563,
      "grad_norm": 4.238532543182373,
      "learning_rate": 3.390720940080458e-05,
      "loss": 0.8164,
      "step": 304150
    },
    {
      "epoch": 3.220377829886566,
      "grad_norm": 4.111063480377197,
      "learning_rate": 3.3904562777895404e-05,
      "loss": 0.8203,
      "step": 304200
    },
    {
      "epoch": 3.2209071516665695,
      "grad_norm": 4.200841426849365,
      "learning_rate": 3.3901969087444426e-05,
      "loss": 0.8178,
      "step": 304250
    },
    {
      "epoch": 3.221436473446573,
      "grad_norm": 3.9022607803344727,
      "learning_rate": 3.389932246453525e-05,
      "loss": 0.8242,
      "step": 304300
    },
    {
      "epoch": 3.221965795226576,
      "grad_norm": 4.15477180480957,
      "learning_rate": 3.389667584162609e-05,
      "loss": 0.8064,
      "step": 304350
    },
    {
      "epoch": 3.2224951170065794,
      "grad_norm": 4.248705863952637,
      "learning_rate": 3.3894029218716914e-05,
      "loss": 0.8379,
      "step": 304400
    },
    {
      "epoch": 3.2230244387865827,
      "grad_norm": 4.058484077453613,
      "learning_rate": 3.3891382595807755e-05,
      "loss": 0.8026,
      "step": 304450
    },
    {
      "epoch": 3.223553760566586,
      "grad_norm": 4.042374610900879,
      "learning_rate": 3.388873597289858e-05,
      "loss": 0.8306,
      "step": 304500
    },
    {
      "epoch": 3.223553760566586,
      "eval_loss": 0.5968831181526184,
      "eval_runtime": 46.7268,
      "eval_samples_per_second": 3593.871,
      "eval_steps_per_second": 449.25,
      "step": 304500
    },
    {
      "epoch": 3.2240830823465894,
      "grad_norm": 4.1878252029418945,
      "learning_rate": 3.388608934998942e-05,
      "loss": 0.8381,
      "step": 304550
    },
    {
      "epoch": 3.2246124041265927,
      "grad_norm": 4.335170269012451,
      "learning_rate": 3.3883442727080244e-05,
      "loss": 0.815,
      "step": 304600
    },
    {
      "epoch": 3.225141725906596,
      "grad_norm": 3.800649642944336,
      "learning_rate": 3.388079610417108e-05,
      "loss": 0.8212,
      "step": 304650
    },
    {
      "epoch": 3.2256710476865993,
      "grad_norm": 4.044549465179443,
      "learning_rate": 3.387814948126191e-05,
      "loss": 0.8154,
      "step": 304700
    },
    {
      "epoch": 3.2262003694666026,
      "grad_norm": 4.03288459777832,
      "learning_rate": 3.387550285835274e-05,
      "loss": 0.8094,
      "step": 304750
    },
    {
      "epoch": 3.226729691246606,
      "grad_norm": 4.056512355804443,
      "learning_rate": 3.3872856235443574e-05,
      "loss": 0.8206,
      "step": 304800
    },
    {
      "epoch": 3.2272590130266092,
      "grad_norm": 4.316967010498047,
      "learning_rate": 3.387020961253441e-05,
      "loss": 0.8214,
      "step": 304850
    },
    {
      "epoch": 3.227788334806612,
      "grad_norm": 4.190029144287109,
      "learning_rate": 3.386756298962524e-05,
      "loss": 0.8189,
      "step": 304900
    },
    {
      "epoch": 3.2283176565866154,
      "grad_norm": 3.936143636703491,
      "learning_rate": 3.386491636671607e-05,
      "loss": 0.8199,
      "step": 304950
    },
    {
      "epoch": 3.2288469783666187,
      "grad_norm": 3.9837143421173096,
      "learning_rate": 3.38622697438069e-05,
      "loss": 0.8235,
      "step": 305000
    },
    {
      "epoch": 3.2288469783666187,
      "eval_loss": 0.5947907567024231,
      "eval_runtime": 46.613,
      "eval_samples_per_second": 3602.642,
      "eval_steps_per_second": 450.346,
      "step": 305000
    },
    {
      "epoch": 3.229376300146622,
      "grad_norm": 3.997530937194824,
      "learning_rate": 3.385962312089774e-05,
      "loss": 0.8158,
      "step": 305050
    },
    {
      "epoch": 3.2299056219266253,
      "grad_norm": 4.290392875671387,
      "learning_rate": 3.385697649798857e-05,
      "loss": 0.8193,
      "step": 305100
    },
    {
      "epoch": 3.2304349437066286,
      "grad_norm": 3.767704725265503,
      "learning_rate": 3.38543298750794e-05,
      "loss": 0.832,
      "step": 305150
    },
    {
      "epoch": 3.230964265486632,
      "grad_norm": 4.243080139160156,
      "learning_rate": 3.385168325217023e-05,
      "loss": 0.8217,
      "step": 305200
    },
    {
      "epoch": 3.2314935872666353,
      "grad_norm": 4.064172744750977,
      "learning_rate": 3.384903662926107e-05,
      "loss": 0.8243,
      "step": 305250
    },
    {
      "epoch": 3.2320229090466386,
      "grad_norm": 4.266632556915283,
      "learning_rate": 3.3846390006351894e-05,
      "loss": 0.8199,
      "step": 305300
    },
    {
      "epoch": 3.232552230826642,
      "grad_norm": 4.1850905418396,
      "learning_rate": 3.384374338344273e-05,
      "loss": 0.8155,
      "step": 305350
    },
    {
      "epoch": 3.233081552606645,
      "grad_norm": 4.368434906005859,
      "learning_rate": 3.3841096760533556e-05,
      "loss": 0.8032,
      "step": 305400
    },
    {
      "epoch": 3.2336108743866485,
      "grad_norm": 4.055863857269287,
      "learning_rate": 3.38384501376244e-05,
      "loss": 0.8238,
      "step": 305450
    },
    {
      "epoch": 3.234140196166652,
      "grad_norm": 3.986570358276367,
      "learning_rate": 3.3835803514715224e-05,
      "loss": 0.8219,
      "step": 305500
    },
    {
      "epoch": 3.234140196166652,
      "eval_loss": 0.5937924981117249,
      "eval_runtime": 46.6265,
      "eval_samples_per_second": 3601.6,
      "eval_steps_per_second": 450.216,
      "step": 305500
    },
    {
      "epoch": 3.234669517946655,
      "grad_norm": 4.201000213623047,
      "learning_rate": 3.383315689180606e-05,
      "loss": 0.8014,
      "step": 305550
    },
    {
      "epoch": 3.2351988397266584,
      "grad_norm": 4.113102912902832,
      "learning_rate": 3.3830510268896885e-05,
      "loss": 0.8114,
      "step": 305600
    },
    {
      "epoch": 3.2357281615066613,
      "grad_norm": 3.9707064628601074,
      "learning_rate": 3.3827863645987726e-05,
      "loss": 0.8134,
      "step": 305650
    },
    {
      "epoch": 3.2362574832866646,
      "grad_norm": 4.038420677185059,
      "learning_rate": 3.3825217023078554e-05,
      "loss": 0.8202,
      "step": 305700
    },
    {
      "epoch": 3.236786805066668,
      "grad_norm": 3.9351344108581543,
      "learning_rate": 3.382257040016939e-05,
      "loss": 0.8069,
      "step": 305750
    },
    {
      "epoch": 3.2373161268466712,
      "grad_norm": 4.225788116455078,
      "learning_rate": 3.3819923777260215e-05,
      "loss": 0.8191,
      "step": 305800
    },
    {
      "epoch": 3.2378454486266746,
      "grad_norm": 4.5074944496154785,
      "learning_rate": 3.381727715435105e-05,
      "loss": 0.8295,
      "step": 305850
    },
    {
      "epoch": 3.238374770406678,
      "grad_norm": 4.175055980682373,
      "learning_rate": 3.381463053144188e-05,
      "loss": 0.8281,
      "step": 305900
    },
    {
      "epoch": 3.238904092186681,
      "grad_norm": 3.908555030822754,
      "learning_rate": 3.381198390853271e-05,
      "loss": 0.7992,
      "step": 305950
    },
    {
      "epoch": 3.2394334139666845,
      "grad_norm": 3.8860599994659424,
      "learning_rate": 3.3809337285623545e-05,
      "loss": 0.8005,
      "step": 306000
    },
    {
      "epoch": 3.2394334139666845,
      "eval_loss": 0.5939570069313049,
      "eval_runtime": 46.6589,
      "eval_samples_per_second": 3599.098,
      "eval_steps_per_second": 449.903,
      "step": 306000
    },
    {
      "epoch": 3.239962735746688,
      "grad_norm": 4.010995388031006,
      "learning_rate": 3.380669066271438e-05,
      "loss": 0.8228,
      "step": 306050
    },
    {
      "epoch": 3.240492057526691,
      "grad_norm": 4.1942949295043945,
      "learning_rate": 3.380404403980521e-05,
      "loss": 0.8314,
      "step": 306100
    },
    {
      "epoch": 3.2410213793066944,
      "grad_norm": 3.86826753616333,
      "learning_rate": 3.380139741689604e-05,
      "loss": 0.8194,
      "step": 306150
    },
    {
      "epoch": 3.2415507010866977,
      "grad_norm": 3.9099385738372803,
      "learning_rate": 3.3798750793986874e-05,
      "loss": 0.8064,
      "step": 306200
    },
    {
      "epoch": 3.242080022866701,
      "grad_norm": 4.048810005187988,
      "learning_rate": 3.379615710353589e-05,
      "loss": 0.8227,
      "step": 306250
    },
    {
      "epoch": 3.2426093446467044,
      "grad_norm": 3.5878283977508545,
      "learning_rate": 3.379351048062672e-05,
      "loss": 0.8175,
      "step": 306300
    },
    {
      "epoch": 3.2431386664267077,
      "grad_norm": 4.376782417297363,
      "learning_rate": 3.379086385771755e-05,
      "loss": 0.8227,
      "step": 306350
    },
    {
      "epoch": 3.2436679882067105,
      "grad_norm": 4.108927249908447,
      "learning_rate": 3.3788217234808384e-05,
      "loss": 0.8019,
      "step": 306400
    },
    {
      "epoch": 3.244197309986714,
      "grad_norm": 4.180116653442383,
      "learning_rate": 3.378557061189922e-05,
      "loss": 0.8187,
      "step": 306450
    },
    {
      "epoch": 3.244726631766717,
      "grad_norm": 4.114356994628906,
      "learning_rate": 3.378292398899005e-05,
      "loss": 0.8128,
      "step": 306500
    },
    {
      "epoch": 3.244726631766717,
      "eval_loss": 0.5924596786499023,
      "eval_runtime": 46.6027,
      "eval_samples_per_second": 3603.443,
      "eval_steps_per_second": 450.446,
      "step": 306500
    },
    {
      "epoch": 3.2452559535467205,
      "grad_norm": 4.02992057800293,
      "learning_rate": 3.378027736608088e-05,
      "loss": 0.8237,
      "step": 306550
    },
    {
      "epoch": 3.245785275326724,
      "grad_norm": 4.333498001098633,
      "learning_rate": 3.3777630743171714e-05,
      "loss": 0.8275,
      "step": 306600
    },
    {
      "epoch": 3.246314597106727,
      "grad_norm": 3.8582937717437744,
      "learning_rate": 3.377498412026255e-05,
      "loss": 0.8182,
      "step": 306650
    },
    {
      "epoch": 3.2468439188867304,
      "grad_norm": 3.9845335483551025,
      "learning_rate": 3.377233749735338e-05,
      "loss": 0.8101,
      "step": 306700
    },
    {
      "epoch": 3.2473732406667337,
      "grad_norm": 3.8225197792053223,
      "learning_rate": 3.376969087444421e-05,
      "loss": 0.8064,
      "step": 306750
    },
    {
      "epoch": 3.247902562446737,
      "grad_norm": 4.158013343811035,
      "learning_rate": 3.3767044251535044e-05,
      "loss": 0.8264,
      "step": 306800
    },
    {
      "epoch": 3.2484318842267403,
      "grad_norm": 3.7594478130340576,
      "learning_rate": 3.376439762862588e-05,
      "loss": 0.8175,
      "step": 306850
    },
    {
      "epoch": 3.2489612060067437,
      "grad_norm": 4.430495738983154,
      "learning_rate": 3.3761751005716705e-05,
      "loss": 0.7994,
      "step": 306900
    },
    {
      "epoch": 3.249490527786747,
      "grad_norm": 3.7761526107788086,
      "learning_rate": 3.375910438280754e-05,
      "loss": 0.8299,
      "step": 306950
    },
    {
      "epoch": 3.2500198495667503,
      "grad_norm": 4.191513538360596,
      "learning_rate": 3.3756457759898367e-05,
      "loss": 0.8278,
      "step": 307000
    },
    {
      "epoch": 3.2500198495667503,
      "eval_loss": 0.5941513776779175,
      "eval_runtime": 46.7507,
      "eval_samples_per_second": 3592.029,
      "eval_steps_per_second": 449.02,
      "step": 307000
    },
    {
      "epoch": 3.2505491713467536,
      "grad_norm": 4.178023815155029,
      "learning_rate": 3.375381113698921e-05,
      "loss": 0.824,
      "step": 307050
    },
    {
      "epoch": 3.251078493126757,
      "grad_norm": 3.835926055908203,
      "learning_rate": 3.375121744653822e-05,
      "loss": 0.8184,
      "step": 307100
    },
    {
      "epoch": 3.2516078149067598,
      "grad_norm": 4.301214694976807,
      "learning_rate": 3.374857082362905e-05,
      "loss": 0.8087,
      "step": 307150
    },
    {
      "epoch": 3.252137136686763,
      "grad_norm": 4.171547889709473,
      "learning_rate": 3.3745924200719884e-05,
      "loss": 0.8141,
      "step": 307200
    },
    {
      "epoch": 3.2526664584667664,
      "grad_norm": 4.04445219039917,
      "learning_rate": 3.374327757781072e-05,
      "loss": 0.8075,
      "step": 307250
    },
    {
      "epoch": 3.2531957802467697,
      "grad_norm": 4.000892639160156,
      "learning_rate": 3.3740630954901545e-05,
      "loss": 0.818,
      "step": 307300
    },
    {
      "epoch": 3.253725102026773,
      "grad_norm": 4.207683563232422,
      "learning_rate": 3.373798433199238e-05,
      "loss": 0.8197,
      "step": 307350
    },
    {
      "epoch": 3.2542544238067763,
      "grad_norm": 4.262832164764404,
      "learning_rate": 3.3735337709083206e-05,
      "loss": 0.8165,
      "step": 307400
    },
    {
      "epoch": 3.2547837455867796,
      "grad_norm": 3.950045108795166,
      "learning_rate": 3.373269108617405e-05,
      "loss": 0.8177,
      "step": 307450
    },
    {
      "epoch": 3.255313067366783,
      "grad_norm": 3.7858850955963135,
      "learning_rate": 3.3730044463264875e-05,
      "loss": 0.8185,
      "step": 307500
    },
    {
      "epoch": 3.255313067366783,
      "eval_loss": 0.5913822054862976,
      "eval_runtime": 46.6208,
      "eval_samples_per_second": 3602.04,
      "eval_steps_per_second": 450.271,
      "step": 307500
    },
    {
      "epoch": 3.2558423891467863,
      "grad_norm": 3.9468510150909424,
      "learning_rate": 3.372739784035571e-05,
      "loss": 0.8267,
      "step": 307550
    },
    {
      "epoch": 3.2563717109267896,
      "grad_norm": 4.283165454864502,
      "learning_rate": 3.3724751217446536e-05,
      "loss": 0.8156,
      "step": 307600
    },
    {
      "epoch": 3.256901032706793,
      "grad_norm": 4.067766189575195,
      "learning_rate": 3.372210459453738e-05,
      "loss": 0.8052,
      "step": 307650
    },
    {
      "epoch": 3.257430354486796,
      "grad_norm": 3.7371678352355957,
      "learning_rate": 3.3719457971628204e-05,
      "loss": 0.8248,
      "step": 307700
    },
    {
      "epoch": 3.2579596762667995,
      "grad_norm": 4.277226448059082,
      "learning_rate": 3.371681134871904e-05,
      "loss": 0.8124,
      "step": 307750
    },
    {
      "epoch": 3.258488998046803,
      "grad_norm": 4.013044357299805,
      "learning_rate": 3.3714164725809866e-05,
      "loss": 0.818,
      "step": 307800
    },
    {
      "epoch": 3.259018319826806,
      "grad_norm": 3.860508441925049,
      "learning_rate": 3.37115181029007e-05,
      "loss": 0.8051,
      "step": 307850
    },
    {
      "epoch": 3.259547641606809,
      "grad_norm": 3.378925085067749,
      "learning_rate": 3.3708871479991534e-05,
      "loss": 0.8304,
      "step": 307900
    },
    {
      "epoch": 3.2600769633868123,
      "grad_norm": 4.052353382110596,
      "learning_rate": 3.370622485708236e-05,
      "loss": 0.8176,
      "step": 307950
    },
    {
      "epoch": 3.2606062851668156,
      "grad_norm": 4.286294460296631,
      "learning_rate": 3.3703578234173195e-05,
      "loss": 0.8157,
      "step": 308000
    },
    {
      "epoch": 3.2606062851668156,
      "eval_loss": 0.5895983576774597,
      "eval_runtime": 46.6006,
      "eval_samples_per_second": 3603.603,
      "eval_steps_per_second": 450.466,
      "step": 308000
    },
    {
      "epoch": 3.261135606946819,
      "grad_norm": 4.03389835357666,
      "learning_rate": 3.370093161126403e-05,
      "loss": 0.8039,
      "step": 308050
    },
    {
      "epoch": 3.2616649287268222,
      "grad_norm": 3.996307849884033,
      "learning_rate": 3.3698284988354864e-05,
      "loss": 0.8085,
      "step": 308100
    },
    {
      "epoch": 3.2621942505068255,
      "grad_norm": 3.8561534881591797,
      "learning_rate": 3.369563836544569e-05,
      "loss": 0.816,
      "step": 308150
    },
    {
      "epoch": 3.262723572286829,
      "grad_norm": 4.1539130210876465,
      "learning_rate": 3.3692991742536525e-05,
      "loss": 0.8265,
      "step": 308200
    },
    {
      "epoch": 3.263252894066832,
      "grad_norm": 3.8048558235168457,
      "learning_rate": 3.369034511962736e-05,
      "loss": 0.8213,
      "step": 308250
    },
    {
      "epoch": 3.2637822158468355,
      "grad_norm": 3.803318738937378,
      "learning_rate": 3.3687698496718186e-05,
      "loss": 0.8193,
      "step": 308300
    },
    {
      "epoch": 3.264311537626839,
      "grad_norm": 4.267322540283203,
      "learning_rate": 3.368505187380902e-05,
      "loss": 0.8163,
      "step": 308350
    },
    {
      "epoch": 3.264840859406842,
      "grad_norm": 4.124020576477051,
      "learning_rate": 3.368240525089985e-05,
      "loss": 0.8145,
      "step": 308400
    },
    {
      "epoch": 3.2653701811868454,
      "grad_norm": 4.2523627281188965,
      "learning_rate": 3.367975862799069e-05,
      "loss": 0.8136,
      "step": 308450
    },
    {
      "epoch": 3.2658995029668487,
      "grad_norm": 3.989331007003784,
      "learning_rate": 3.3677112005081516e-05,
      "loss": 0.8177,
      "step": 308500
    },
    {
      "epoch": 3.2658995029668487,
      "eval_loss": 0.590965211391449,
      "eval_runtime": 46.6858,
      "eval_samples_per_second": 3597.024,
      "eval_steps_per_second": 449.644,
      "step": 308500
    },
    {
      "epoch": 3.266428824746852,
      "grad_norm": 4.521273612976074,
      "learning_rate": 3.367446538217235e-05,
      "loss": 0.816,
      "step": 308550
    },
    {
      "epoch": 3.2669581465268553,
      "grad_norm": 4.067190647125244,
      "learning_rate": 3.367181875926318e-05,
      "loss": 0.819,
      "step": 308600
    },
    {
      "epoch": 3.267487468306858,
      "grad_norm": 4.210280895233154,
      "learning_rate": 3.366917213635402e-05,
      "loss": 0.8148,
      "step": 308650
    },
    {
      "epoch": 3.2680167900868615,
      "grad_norm": 3.9766299724578857,
      "learning_rate": 3.3666525513444846e-05,
      "loss": 0.8153,
      "step": 308700
    },
    {
      "epoch": 3.268546111866865,
      "grad_norm": 4.072138786315918,
      "learning_rate": 3.366387889053568e-05,
      "loss": 0.8221,
      "step": 308750
    },
    {
      "epoch": 3.269075433646868,
      "grad_norm": 4.206971168518066,
      "learning_rate": 3.366123226762651e-05,
      "loss": 0.8114,
      "step": 308800
    },
    {
      "epoch": 3.2696047554268715,
      "grad_norm": 4.350994110107422,
      "learning_rate": 3.365858564471734e-05,
      "loss": 0.8216,
      "step": 308850
    },
    {
      "epoch": 3.2701340772068748,
      "grad_norm": 4.093640327453613,
      "learning_rate": 3.3655939021808175e-05,
      "loss": 0.8038,
      "step": 308900
    },
    {
      "epoch": 3.270663398986878,
      "grad_norm": 4.198400020599365,
      "learning_rate": 3.3653292398899e-05,
      "loss": 0.7952,
      "step": 308950
    },
    {
      "epoch": 3.2711927207668814,
      "grad_norm": 4.125114917755127,
      "learning_rate": 3.365064577598984e-05,
      "loss": 0.8107,
      "step": 309000
    },
    {
      "epoch": 3.2711927207668814,
      "eval_loss": 0.5902736186981201,
      "eval_runtime": 46.9306,
      "eval_samples_per_second": 3578.259,
      "eval_steps_per_second": 447.298,
      "step": 309000
    },
    {
      "epoch": 3.2717220425468847,
      "grad_norm": 4.087802410125732,
      "learning_rate": 3.364799915308067e-05,
      "loss": 0.8098,
      "step": 309050
    },
    {
      "epoch": 3.272251364326888,
      "grad_norm": 4.135064125061035,
      "learning_rate": 3.3645352530171505e-05,
      "loss": 0.8099,
      "step": 309100
    },
    {
      "epoch": 3.2727806861068913,
      "grad_norm": 3.9483253955841064,
      "learning_rate": 3.364270590726233e-05,
      "loss": 0.8351,
      "step": 309150
    },
    {
      "epoch": 3.2733100078868946,
      "grad_norm": 4.253023624420166,
      "learning_rate": 3.3640059284353166e-05,
      "loss": 0.8122,
      "step": 309200
    },
    {
      "epoch": 3.273839329666898,
      "grad_norm": 3.7193400859832764,
      "learning_rate": 3.3637412661444e-05,
      "loss": 0.8177,
      "step": 309250
    },
    {
      "epoch": 3.2743686514469013,
      "grad_norm": 4.320718288421631,
      "learning_rate": 3.3634766038534834e-05,
      "loss": 0.8347,
      "step": 309300
    },
    {
      "epoch": 3.2748979732269046,
      "grad_norm": 4.220320701599121,
      "learning_rate": 3.363211941562566e-05,
      "loss": 0.8009,
      "step": 309350
    },
    {
      "epoch": 3.2754272950069074,
      "grad_norm": 3.8492963314056396,
      "learning_rate": 3.3629472792716496e-05,
      "loss": 0.8157,
      "step": 309400
    },
    {
      "epoch": 3.2759566167869107,
      "grad_norm": 3.8228883743286133,
      "learning_rate": 3.362682616980733e-05,
      "loss": 0.8129,
      "step": 309450
    },
    {
      "epoch": 3.276485938566914,
      "grad_norm": 4.033651351928711,
      "learning_rate": 3.362417954689816e-05,
      "loss": 0.8118,
      "step": 309500
    },
    {
      "epoch": 3.276485938566914,
      "eval_loss": 0.5900353193283081,
      "eval_runtime": 46.8861,
      "eval_samples_per_second": 3581.656,
      "eval_steps_per_second": 447.723,
      "step": 309500
    },
    {
      "epoch": 3.2770152603469174,
      "grad_norm": 3.78349232673645,
      "learning_rate": 3.362153292398899e-05,
      "loss": 0.8085,
      "step": 309550
    },
    {
      "epoch": 3.2775445821269207,
      "grad_norm": 4.072319030761719,
      "learning_rate": 3.361888630107982e-05,
      "loss": 0.8301,
      "step": 309600
    },
    {
      "epoch": 3.278073903906924,
      "grad_norm": 3.8042960166931152,
      "learning_rate": 3.361623967817066e-05,
      "loss": 0.8066,
      "step": 309650
    },
    {
      "epoch": 3.2786032256869273,
      "grad_norm": 4.1025471687316895,
      "learning_rate": 3.361359305526149e-05,
      "loss": 0.81,
      "step": 309700
    },
    {
      "epoch": 3.2791325474669306,
      "grad_norm": 3.813351631164551,
      "learning_rate": 3.361094643235232e-05,
      "loss": 0.8052,
      "step": 309750
    },
    {
      "epoch": 3.279661869246934,
      "grad_norm": 3.9758074283599854,
      "learning_rate": 3.360829980944315e-05,
      "loss": 0.7891,
      "step": 309800
    },
    {
      "epoch": 3.2801911910269372,
      "grad_norm": 4.191153049468994,
      "learning_rate": 3.360565318653399e-05,
      "loss": 0.8111,
      "step": 309850
    },
    {
      "epoch": 3.2807205128069405,
      "grad_norm": 3.9301538467407227,
      "learning_rate": 3.3603006563624817e-05,
      "loss": 0.8251,
      "step": 309900
    },
    {
      "epoch": 3.281249834586944,
      "grad_norm": 4.266959190368652,
      "learning_rate": 3.360035994071565e-05,
      "loss": 0.8361,
      "step": 309950
    },
    {
      "epoch": 3.281779156366947,
      "grad_norm": 3.8051040172576904,
      "learning_rate": 3.359771331780648e-05,
      "loss": 0.8296,
      "step": 310000
    },
    {
      "epoch": 3.281779156366947,
      "eval_loss": 0.5892999768257141,
      "eval_runtime": 46.6126,
      "eval_samples_per_second": 3602.672,
      "eval_steps_per_second": 450.35,
      "step": 310000
    },
    {
      "epoch": 3.2823084781469505,
      "grad_norm": 3.8562517166137695,
      "learning_rate": 3.359506669489731e-05,
      "loss": 0.8231,
      "step": 310050
    },
    {
      "epoch": 3.282837799926954,
      "grad_norm": 3.978200674057007,
      "learning_rate": 3.3592420071988146e-05,
      "loss": 0.808,
      "step": 310100
    },
    {
      "epoch": 3.2833671217069567,
      "grad_norm": 4.017518043518066,
      "learning_rate": 3.3589773449078974e-05,
      "loss": 0.8288,
      "step": 310150
    },
    {
      "epoch": 3.28389644348696,
      "grad_norm": 3.7715933322906494,
      "learning_rate": 3.358717975862799e-05,
      "loss": 0.8101,
      "step": 310200
    },
    {
      "epoch": 3.2844257652669633,
      "grad_norm": 4.063940048217773,
      "learning_rate": 3.358453313571883e-05,
      "loss": 0.8167,
      "step": 310250
    },
    {
      "epoch": 3.2849550870469666,
      "grad_norm": 4.10985803604126,
      "learning_rate": 3.3581886512809656e-05,
      "loss": 0.8143,
      "step": 310300
    },
    {
      "epoch": 3.28548440882697,
      "grad_norm": 3.92675518989563,
      "learning_rate": 3.357923988990049e-05,
      "loss": 0.8196,
      "step": 310350
    },
    {
      "epoch": 3.286013730606973,
      "grad_norm": 4.185901641845703,
      "learning_rate": 3.357659326699132e-05,
      "loss": 0.8092,
      "step": 310400
    },
    {
      "epoch": 3.2865430523869765,
      "grad_norm": 4.616332054138184,
      "learning_rate": 3.357394664408215e-05,
      "loss": 0.8134,
      "step": 310450
    },
    {
      "epoch": 3.28707237416698,
      "grad_norm": 4.172842502593994,
      "learning_rate": 3.3571300021172986e-05,
      "loss": 0.8255,
      "step": 310500
    },
    {
      "epoch": 3.28707237416698,
      "eval_loss": 0.5914667248725891,
      "eval_runtime": 46.6484,
      "eval_samples_per_second": 3599.91,
      "eval_steps_per_second": 450.005,
      "step": 310500
    },
    {
      "epoch": 3.287601695946983,
      "grad_norm": 3.9362123012542725,
      "learning_rate": 3.356865339826381e-05,
      "loss": 0.8174,
      "step": 310550
    },
    {
      "epoch": 3.2881310177269865,
      "grad_norm": 3.972470283508301,
      "learning_rate": 3.356600677535465e-05,
      "loss": 0.8167,
      "step": 310600
    },
    {
      "epoch": 3.2886603395069898,
      "grad_norm": 3.5176708698272705,
      "learning_rate": 3.356336015244548e-05,
      "loss": 0.8301,
      "step": 310650
    },
    {
      "epoch": 3.289189661286993,
      "grad_norm": 4.096860885620117,
      "learning_rate": 3.3560713529536316e-05,
      "loss": 0.7995,
      "step": 310700
    },
    {
      "epoch": 3.2897189830669964,
      "grad_norm": 4.1673583984375,
      "learning_rate": 3.355806690662714e-05,
      "loss": 0.8054,
      "step": 310750
    },
    {
      "epoch": 3.2902483048469997,
      "grad_norm": 4.3198723793029785,
      "learning_rate": 3.355542028371798e-05,
      "loss": 0.8172,
      "step": 310800
    },
    {
      "epoch": 3.290777626627003,
      "grad_norm": 3.920355796813965,
      "learning_rate": 3.355277366080881e-05,
      "loss": 0.8147,
      "step": 310850
    },
    {
      "epoch": 3.291306948407006,
      "grad_norm": 4.405495643615723,
      "learning_rate": 3.3550127037899645e-05,
      "loss": 0.8124,
      "step": 310900
    },
    {
      "epoch": 3.291836270187009,
      "grad_norm": 4.390115261077881,
      "learning_rate": 3.354748041499047e-05,
      "loss": 0.8092,
      "step": 310950
    },
    {
      "epoch": 3.2923655919670125,
      "grad_norm": 4.3232831954956055,
      "learning_rate": 3.354483379208131e-05,
      "loss": 0.8145,
      "step": 311000
    },
    {
      "epoch": 3.2923655919670125,
      "eval_loss": 0.5874979496002197,
      "eval_runtime": 46.7163,
      "eval_samples_per_second": 3594.677,
      "eval_steps_per_second": 449.351,
      "step": 311000
    },
    {
      "epoch": 3.292894913747016,
      "grad_norm": 3.8565585613250732,
      "learning_rate": 3.354218716917214e-05,
      "loss": 0.8136,
      "step": 311050
    },
    {
      "epoch": 3.293424235527019,
      "grad_norm": 3.7750446796417236,
      "learning_rate": 3.353954054626297e-05,
      "loss": 0.8125,
      "step": 311100
    },
    {
      "epoch": 3.2939535573070224,
      "grad_norm": 4.218610763549805,
      "learning_rate": 3.35368939233538e-05,
      "loss": 0.8258,
      "step": 311150
    },
    {
      "epoch": 3.2944828790870258,
      "grad_norm": 3.775569200515747,
      "learning_rate": 3.353424730044463e-05,
      "loss": 0.8036,
      "step": 311200
    },
    {
      "epoch": 3.295012200867029,
      "grad_norm": 4.228000164031982,
      "learning_rate": 3.353160067753547e-05,
      "loss": 0.8069,
      "step": 311250
    },
    {
      "epoch": 3.2955415226470324,
      "grad_norm": 4.4003424644470215,
      "learning_rate": 3.35289540546263e-05,
      "loss": 0.8168,
      "step": 311300
    },
    {
      "epoch": 3.2960708444270357,
      "grad_norm": 4.238883972167969,
      "learning_rate": 3.352630743171713e-05,
      "loss": 0.8293,
      "step": 311350
    },
    {
      "epoch": 3.296600166207039,
      "grad_norm": 4.222416400909424,
      "learning_rate": 3.352366080880796e-05,
      "loss": 0.8087,
      "step": 311400
    },
    {
      "epoch": 3.2971294879870423,
      "grad_norm": 4.175817489624023,
      "learning_rate": 3.35210141858988e-05,
      "loss": 0.8,
      "step": 311450
    },
    {
      "epoch": 3.2976588097670456,
      "grad_norm": 3.7707879543304443,
      "learning_rate": 3.351836756298963e-05,
      "loss": 0.8202,
      "step": 311500
    },
    {
      "epoch": 3.2976588097670456,
      "eval_loss": 0.5878552198410034,
      "eval_runtime": 46.6472,
      "eval_samples_per_second": 3600.003,
      "eval_steps_per_second": 450.016,
      "step": 311500
    },
    {
      "epoch": 3.298188131547049,
      "grad_norm": 4.185605049133301,
      "learning_rate": 3.351572094008046e-05,
      "loss": 0.8267,
      "step": 311550
    },
    {
      "epoch": 3.2987174533270522,
      "grad_norm": 4.166297912597656,
      "learning_rate": 3.351307431717129e-05,
      "loss": 0.8205,
      "step": 311600
    },
    {
      "epoch": 3.299246775107055,
      "grad_norm": 3.6917638778686523,
      "learning_rate": 3.351042769426212e-05,
      "loss": 0.814,
      "step": 311650
    },
    {
      "epoch": 3.2997760968870584,
      "grad_norm": 4.089860916137695,
      "learning_rate": 3.350778107135296e-05,
      "loss": 0.8095,
      "step": 311700
    },
    {
      "epoch": 3.3003054186670617,
      "grad_norm": 4.042248725891113,
      "learning_rate": 3.3505134448443784e-05,
      "loss": 0.8046,
      "step": 311750
    },
    {
      "epoch": 3.300834740447065,
      "grad_norm": 3.9184300899505615,
      "learning_rate": 3.350248782553462e-05,
      "loss": 0.8082,
      "step": 311800
    },
    {
      "epoch": 3.3013640622270684,
      "grad_norm": 4.381123065948486,
      "learning_rate": 3.349984120262545e-05,
      "loss": 0.8172,
      "step": 311850
    },
    {
      "epoch": 3.3018933840070717,
      "grad_norm": 4.1392645835876465,
      "learning_rate": 3.349719457971629e-05,
      "loss": 0.8053,
      "step": 311900
    },
    {
      "epoch": 3.302422705787075,
      "grad_norm": 4.132262706756592,
      "learning_rate": 3.3494547956807114e-05,
      "loss": 0.8211,
      "step": 311950
    },
    {
      "epoch": 3.3029520275670783,
      "grad_norm": 3.8794336318969727,
      "learning_rate": 3.349190133389795e-05,
      "loss": 0.81,
      "step": 312000
    },
    {
      "epoch": 3.3029520275670783,
      "eval_loss": 0.5868526697158813,
      "eval_runtime": 46.6259,
      "eval_samples_per_second": 3601.648,
      "eval_steps_per_second": 450.222,
      "step": 312000
    },
    {
      "epoch": 3.3034813493470816,
      "grad_norm": 3.9776434898376465,
      "learning_rate": 3.348925471098878e-05,
      "loss": 0.8096,
      "step": 312050
    },
    {
      "epoch": 3.304010671127085,
      "grad_norm": 4.25688362121582,
      "learning_rate": 3.3486608088079616e-05,
      "loss": 0.8068,
      "step": 312100
    },
    {
      "epoch": 3.304539992907088,
      "grad_norm": 3.8901944160461426,
      "learning_rate": 3.3483961465170444e-05,
      "loss": 0.8058,
      "step": 312150
    },
    {
      "epoch": 3.3050693146870915,
      "grad_norm": 4.072356224060059,
      "learning_rate": 3.348131484226128e-05,
      "loss": 0.81,
      "step": 312200
    },
    {
      "epoch": 3.305598636467095,
      "grad_norm": 4.164477825164795,
      "learning_rate": 3.347866821935211e-05,
      "loss": 0.8269,
      "step": 312250
    },
    {
      "epoch": 3.306127958247098,
      "grad_norm": 4.264063835144043,
      "learning_rate": 3.347602159644294e-05,
      "loss": 0.8081,
      "step": 312300
    },
    {
      "epoch": 3.3066572800271015,
      "grad_norm": 3.955256938934326,
      "learning_rate": 3.347337497353377e-05,
      "loss": 0.8066,
      "step": 312350
    },
    {
      "epoch": 3.3071866018071043,
      "grad_norm": 4.18080997467041,
      "learning_rate": 3.34707283506246e-05,
      "loss": 0.8044,
      "step": 312400
    },
    {
      "epoch": 3.307715923587108,
      "grad_norm": 4.108820915222168,
      "learning_rate": 3.346808172771544e-05,
      "loss": 0.8034,
      "step": 312450
    },
    {
      "epoch": 3.308245245367111,
      "grad_norm": 4.546892166137695,
      "learning_rate": 3.346543510480627e-05,
      "loss": 0.8151,
      "step": 312500
    },
    {
      "epoch": 3.308245245367111,
      "eval_loss": 0.5862337946891785,
      "eval_runtime": 46.5613,
      "eval_samples_per_second": 3606.645,
      "eval_steps_per_second": 450.847,
      "step": 312500
    },
    {
      "epoch": 3.3087745671471143,
      "grad_norm": 4.263413429260254,
      "learning_rate": 3.34627884818971e-05,
      "loss": 0.8223,
      "step": 312550
    },
    {
      "epoch": 3.3093038889271176,
      "grad_norm": 4.179234981536865,
      "learning_rate": 3.346014185898793e-05,
      "loss": 0.8034,
      "step": 312600
    },
    {
      "epoch": 3.309833210707121,
      "grad_norm": 4.4404497146606445,
      "learning_rate": 3.3457495236078764e-05,
      "loss": 0.8074,
      "step": 312650
    },
    {
      "epoch": 3.310362532487124,
      "grad_norm": 3.559980869293213,
      "learning_rate": 3.34548486131696e-05,
      "loss": 0.8084,
      "step": 312700
    },
    {
      "epoch": 3.3108918542671275,
      "grad_norm": 4.526306629180908,
      "learning_rate": 3.3452201990260426e-05,
      "loss": 0.8178,
      "step": 312750
    },
    {
      "epoch": 3.311421176047131,
      "grad_norm": 4.441436767578125,
      "learning_rate": 3.344955536735126e-05,
      "loss": 0.8211,
      "step": 312800
    },
    {
      "epoch": 3.311950497827134,
      "grad_norm": 4.196687698364258,
      "learning_rate": 3.3446908744442094e-05,
      "loss": 0.8141,
      "step": 312850
    },
    {
      "epoch": 3.3124798196071374,
      "grad_norm": 3.9169487953186035,
      "learning_rate": 3.344426212153293e-05,
      "loss": 0.8125,
      "step": 312900
    },
    {
      "epoch": 3.3130091413871408,
      "grad_norm": 4.144352436065674,
      "learning_rate": 3.3441615498623755e-05,
      "loss": 0.8257,
      "step": 312950
    },
    {
      "epoch": 3.313538463167144,
      "grad_norm": 4.03426456451416,
      "learning_rate": 3.343896887571459e-05,
      "loss": 0.8095,
      "step": 313000
    },
    {
      "epoch": 3.313538463167144,
      "eval_loss": 0.5870285034179688,
      "eval_runtime": 46.5965,
      "eval_samples_per_second": 3603.915,
      "eval_steps_per_second": 450.505,
      "step": 313000
    },
    {
      "epoch": 3.3140677849471474,
      "grad_norm": 4.198922157287598,
      "learning_rate": 3.3436322252805423e-05,
      "loss": 0.8195,
      "step": 313050
    },
    {
      "epoch": 3.3145971067271507,
      "grad_norm": 4.614606857299805,
      "learning_rate": 3.343367562989626e-05,
      "loss": 0.8108,
      "step": 313100
    },
    {
      "epoch": 3.3151264285071536,
      "grad_norm": 3.8984267711639404,
      "learning_rate": 3.3431029006987085e-05,
      "loss": 0.8206,
      "step": 313150
    },
    {
      "epoch": 3.3156557502871573,
      "grad_norm": 4.226416110992432,
      "learning_rate": 3.342838238407792e-05,
      "loss": 0.8155,
      "step": 313200
    },
    {
      "epoch": 3.31618507206716,
      "grad_norm": 4.1904215812683105,
      "learning_rate": 3.342573576116875e-05,
      "loss": 0.8148,
      "step": 313250
    },
    {
      "epoch": 3.3167143938471635,
      "grad_norm": 4.436544895172119,
      "learning_rate": 3.342308913825958e-05,
      "loss": 0.8229,
      "step": 313300
    },
    {
      "epoch": 3.317243715627167,
      "grad_norm": 4.370621681213379,
      "learning_rate": 3.3420442515350415e-05,
      "loss": 0.8188,
      "step": 313350
    },
    {
      "epoch": 3.31777303740717,
      "grad_norm": 3.9569807052612305,
      "learning_rate": 3.341779589244124e-05,
      "loss": 0.8032,
      "step": 313400
    },
    {
      "epoch": 3.3183023591871734,
      "grad_norm": 4.186617374420166,
      "learning_rate": 3.341514926953208e-05,
      "loss": 0.809,
      "step": 313450
    },
    {
      "epoch": 3.3188316809671767,
      "grad_norm": 4.200092792510986,
      "learning_rate": 3.341250264662291e-05,
      "loss": 0.8007,
      "step": 313500
    },
    {
      "epoch": 3.3188316809671767,
      "eval_loss": 0.5860904455184937,
      "eval_runtime": 46.7918,
      "eval_samples_per_second": 3588.88,
      "eval_steps_per_second": 448.626,
      "step": 313500
    },
    {
      "epoch": 3.31936100274718,
      "grad_norm": 4.00049352645874,
      "learning_rate": 3.3409856023713744e-05,
      "loss": 0.821,
      "step": 313550
    },
    {
      "epoch": 3.3198903245271834,
      "grad_norm": 4.0204315185546875,
      "learning_rate": 3.340720940080457e-05,
      "loss": 0.8169,
      "step": 313600
    },
    {
      "epoch": 3.3204196463071867,
      "grad_norm": 4.368417739868164,
      "learning_rate": 3.340456277789541e-05,
      "loss": 0.8082,
      "step": 313650
    },
    {
      "epoch": 3.32094896808719,
      "grad_norm": 4.008419036865234,
      "learning_rate": 3.340191615498624e-05,
      "loss": 0.8114,
      "step": 313700
    },
    {
      "epoch": 3.3214782898671933,
      "grad_norm": 4.087469100952148,
      "learning_rate": 3.3399269532077074e-05,
      "loss": 0.8169,
      "step": 313750
    },
    {
      "epoch": 3.3220076116471966,
      "grad_norm": 3.939173460006714,
      "learning_rate": 3.33966229091679e-05,
      "loss": 0.8072,
      "step": 313800
    },
    {
      "epoch": 3.3225369334272,
      "grad_norm": 3.9502153396606445,
      "learning_rate": 3.3393976286258735e-05,
      "loss": 0.8043,
      "step": 313850
    },
    {
      "epoch": 3.323066255207203,
      "grad_norm": 4.110661506652832,
      "learning_rate": 3.339132966334957e-05,
      "loss": 0.8221,
      "step": 313900
    },
    {
      "epoch": 3.3235955769872065,
      "grad_norm": 3.9992053508758545,
      "learning_rate": 3.33886830404404e-05,
      "loss": 0.8109,
      "step": 313950
    },
    {
      "epoch": 3.3241248987672094,
      "grad_norm": 4.0830912590026855,
      "learning_rate": 3.338603641753123e-05,
      "loss": 0.8177,
      "step": 314000
    },
    {
      "epoch": 3.3241248987672094,
      "eval_loss": 0.5862941145896912,
      "eval_runtime": 46.6485,
      "eval_samples_per_second": 3599.903,
      "eval_steps_per_second": 450.004,
      "step": 314000
    },
    {
      "epoch": 3.3246542205472127,
      "grad_norm": 4.212324142456055,
      "learning_rate": 3.3383389794622065e-05,
      "loss": 0.816,
      "step": 314050
    },
    {
      "epoch": 3.325183542327216,
      "grad_norm": 4.185478210449219,
      "learning_rate": 3.338079610417108e-05,
      "loss": 0.8136,
      "step": 314100
    },
    {
      "epoch": 3.3257128641072193,
      "grad_norm": 4.031293869018555,
      "learning_rate": 3.3378149481261914e-05,
      "loss": 0.7963,
      "step": 314150
    },
    {
      "epoch": 3.3262421858872226,
      "grad_norm": 3.9172277450561523,
      "learning_rate": 3.337550285835274e-05,
      "loss": 0.8049,
      "step": 314200
    },
    {
      "epoch": 3.326771507667226,
      "grad_norm": 4.219105243682861,
      "learning_rate": 3.3372856235443575e-05,
      "loss": 0.8182,
      "step": 314250
    },
    {
      "epoch": 3.3273008294472293,
      "grad_norm": 4.210011959075928,
      "learning_rate": 3.337020961253441e-05,
      "loss": 0.7946,
      "step": 314300
    },
    {
      "epoch": 3.3278301512272326,
      "grad_norm": 4.3770432472229,
      "learning_rate": 3.3367562989625236e-05,
      "loss": 0.8252,
      "step": 314350
    },
    {
      "epoch": 3.328359473007236,
      "grad_norm": 4.381750583648682,
      "learning_rate": 3.336491636671607e-05,
      "loss": 0.7923,
      "step": 314400
    },
    {
      "epoch": 3.328888794787239,
      "grad_norm": 4.131167888641357,
      "learning_rate": 3.3362269743806905e-05,
      "loss": 0.8173,
      "step": 314450
    },
    {
      "epoch": 3.3294181165672425,
      "grad_norm": 4.288393497467041,
      "learning_rate": 3.335962312089774e-05,
      "loss": 0.8142,
      "step": 314500
    },
    {
      "epoch": 3.3294181165672425,
      "eval_loss": 0.5856709480285645,
      "eval_runtime": 46.5454,
      "eval_samples_per_second": 3607.875,
      "eval_steps_per_second": 451.0,
      "step": 314500
    },
    {
      "epoch": 3.329947438347246,
      "grad_norm": 4.549111366271973,
      "learning_rate": 3.3356976497988566e-05,
      "loss": 0.8124,
      "step": 314550
    },
    {
      "epoch": 3.330476760127249,
      "grad_norm": 3.8795344829559326,
      "learning_rate": 3.33543298750794e-05,
      "loss": 0.7972,
      "step": 314600
    },
    {
      "epoch": 3.331006081907252,
      "grad_norm": 3.904186248779297,
      "learning_rate": 3.3351683252170234e-05,
      "loss": 0.8038,
      "step": 314650
    },
    {
      "epoch": 3.3315354036872558,
      "grad_norm": 4.172668933868408,
      "learning_rate": 3.334903662926107e-05,
      "loss": 0.8216,
      "step": 314700
    },
    {
      "epoch": 3.3320647254672586,
      "grad_norm": 3.673034906387329,
      "learning_rate": 3.3346390006351896e-05,
      "loss": 0.8091,
      "step": 314750
    },
    {
      "epoch": 3.332594047247262,
      "grad_norm": 3.9672279357910156,
      "learning_rate": 3.334374338344273e-05,
      "loss": 0.818,
      "step": 314800
    },
    {
      "epoch": 3.3331233690272652,
      "grad_norm": 4.586888790130615,
      "learning_rate": 3.3341096760533564e-05,
      "loss": 0.8136,
      "step": 314850
    },
    {
      "epoch": 3.3336526908072686,
      "grad_norm": 3.8249363899230957,
      "learning_rate": 3.333845013762439e-05,
      "loss": 0.8103,
      "step": 314900
    },
    {
      "epoch": 3.334182012587272,
      "grad_norm": 4.156940460205078,
      "learning_rate": 3.3335803514715225e-05,
      "loss": 0.8158,
      "step": 314950
    },
    {
      "epoch": 3.334711334367275,
      "grad_norm": 4.453298091888428,
      "learning_rate": 3.333315689180605e-05,
      "loss": 0.7822,
      "step": 315000
    },
    {
      "epoch": 3.334711334367275,
      "eval_loss": 0.5848277807235718,
      "eval_runtime": 46.5278,
      "eval_samples_per_second": 3609.239,
      "eval_steps_per_second": 451.171,
      "step": 315000
    },
    {
      "epoch": 3.3352406561472785,
      "grad_norm": 3.88332200050354,
      "learning_rate": 3.3330510268896894e-05,
      "loss": 0.8169,
      "step": 315050
    },
    {
      "epoch": 3.335769977927282,
      "grad_norm": 4.337421894073486,
      "learning_rate": 3.332786364598772e-05,
      "loss": 0.8261,
      "step": 315100
    },
    {
      "epoch": 3.336299299707285,
      "grad_norm": 3.924833059310913,
      "learning_rate": 3.3325217023078555e-05,
      "loss": 0.8176,
      "step": 315150
    },
    {
      "epoch": 3.3368286214872884,
      "grad_norm": 3.7383275032043457,
      "learning_rate": 3.332257040016938e-05,
      "loss": 0.8074,
      "step": 315200
    },
    {
      "epoch": 3.3373579432672917,
      "grad_norm": 4.496440887451172,
      "learning_rate": 3.331992377726022e-05,
      "loss": 0.8041,
      "step": 315250
    },
    {
      "epoch": 3.337887265047295,
      "grad_norm": 3.949950933456421,
      "learning_rate": 3.331727715435105e-05,
      "loss": 0.8188,
      "step": 315300
    },
    {
      "epoch": 3.3384165868272984,
      "grad_norm": 4.125393867492676,
      "learning_rate": 3.3314630531441885e-05,
      "loss": 0.8142,
      "step": 315350
    },
    {
      "epoch": 3.3389459086073012,
      "grad_norm": 4.160016059875488,
      "learning_rate": 3.331198390853271e-05,
      "loss": 0.8191,
      "step": 315400
    },
    {
      "epoch": 3.339475230387305,
      "grad_norm": 4.142270565032959,
      "learning_rate": 3.3309337285623546e-05,
      "loss": 0.8179,
      "step": 315450
    },
    {
      "epoch": 3.340004552167308,
      "grad_norm": 3.8244717121124268,
      "learning_rate": 3.330669066271438e-05,
      "loss": 0.8143,
      "step": 315500
    },
    {
      "epoch": 3.340004552167308,
      "eval_loss": 0.5839284658432007,
      "eval_runtime": 46.5967,
      "eval_samples_per_second": 3603.905,
      "eval_steps_per_second": 450.504,
      "step": 315500
    },
    {
      "epoch": 3.340533873947311,
      "grad_norm": 4.0367560386657715,
      "learning_rate": 3.330404403980521e-05,
      "loss": 0.8149,
      "step": 315550
    },
    {
      "epoch": 3.3410631957273145,
      "grad_norm": 4.1583428382873535,
      "learning_rate": 3.330139741689604e-05,
      "loss": 0.8225,
      "step": 315600
    },
    {
      "epoch": 3.341592517507318,
      "grad_norm": 4.0253400802612305,
      "learning_rate": 3.3298750793986876e-05,
      "loss": 0.8094,
      "step": 315650
    },
    {
      "epoch": 3.342121839287321,
      "grad_norm": 3.8778135776519775,
      "learning_rate": 3.329610417107771e-05,
      "loss": 0.8065,
      "step": 315700
    },
    {
      "epoch": 3.3426511610673244,
      "grad_norm": 4.12774658203125,
      "learning_rate": 3.329345754816854e-05,
      "loss": 0.8168,
      "step": 315750
    },
    {
      "epoch": 3.3431804828473277,
      "grad_norm": 4.034452438354492,
      "learning_rate": 3.329081092525937e-05,
      "loss": 0.8045,
      "step": 315800
    },
    {
      "epoch": 3.343709804627331,
      "grad_norm": 4.084794998168945,
      "learning_rate": 3.3288164302350205e-05,
      "loss": 0.8037,
      "step": 315850
    },
    {
      "epoch": 3.3442391264073343,
      "grad_norm": 3.8961191177368164,
      "learning_rate": 3.328551767944104e-05,
      "loss": 0.8046,
      "step": 315900
    },
    {
      "epoch": 3.3447684481873377,
      "grad_norm": 4.056300163269043,
      "learning_rate": 3.328287105653187e-05,
      "loss": 0.8183,
      "step": 315950
    },
    {
      "epoch": 3.345297769967341,
      "grad_norm": 4.013350486755371,
      "learning_rate": 3.32802244336227e-05,
      "loss": 0.8098,
      "step": 316000
    },
    {
      "epoch": 3.345297769967341,
      "eval_loss": 0.5846583843231201,
      "eval_runtime": 46.5472,
      "eval_samples_per_second": 3607.736,
      "eval_steps_per_second": 450.983,
      "step": 316000
    },
    {
      "epoch": 3.3458270917473443,
      "grad_norm": 4.039935111999512,
      "learning_rate": 3.3277577810713535e-05,
      "loss": 0.809,
      "step": 316050
    },
    {
      "epoch": 3.3463564135273476,
      "grad_norm": 4.122863292694092,
      "learning_rate": 3.327493118780436e-05,
      "loss": 0.8165,
      "step": 316100
    },
    {
      "epoch": 3.3468857353073505,
      "grad_norm": 4.005309104919434,
      "learning_rate": 3.3272284564895196e-05,
      "loss": 0.817,
      "step": 316150
    },
    {
      "epoch": 3.347415057087354,
      "grad_norm": 4.2678985595703125,
      "learning_rate": 3.3269637941986024e-05,
      "loss": 0.8159,
      "step": 316200
    },
    {
      "epoch": 3.347944378867357,
      "grad_norm": 4.010315418243408,
      "learning_rate": 3.3266991319076865e-05,
      "loss": 0.8091,
      "step": 316250
    },
    {
      "epoch": 3.3484737006473604,
      "grad_norm": 4.215328693389893,
      "learning_rate": 3.326434469616769e-05,
      "loss": 0.8064,
      "step": 316300
    },
    {
      "epoch": 3.3490030224273637,
      "grad_norm": 3.8601930141448975,
      "learning_rate": 3.3261698073258526e-05,
      "loss": 0.7992,
      "step": 316350
    },
    {
      "epoch": 3.349532344207367,
      "grad_norm": 4.521927833557129,
      "learning_rate": 3.325905145034935e-05,
      "loss": 0.8124,
      "step": 316400
    },
    {
      "epoch": 3.3500616659873703,
      "grad_norm": 4.092737197875977,
      "learning_rate": 3.325640482744019e-05,
      "loss": 0.8093,
      "step": 316450
    },
    {
      "epoch": 3.3505909877673736,
      "grad_norm": 4.432687282562256,
      "learning_rate": 3.325375820453102e-05,
      "loss": 0.8126,
      "step": 316500
    },
    {
      "epoch": 3.3505909877673736,
      "eval_loss": 0.5821272730827332,
      "eval_runtime": 46.5689,
      "eval_samples_per_second": 3606.057,
      "eval_steps_per_second": 450.773,
      "step": 316500
    },
    {
      "epoch": 3.351120309547377,
      "grad_norm": 3.8964617252349854,
      "learning_rate": 3.325111158162185e-05,
      "loss": 0.8009,
      "step": 316550
    },
    {
      "epoch": 3.3516496313273803,
      "grad_norm": 4.048933506011963,
      "learning_rate": 3.324846495871268e-05,
      "loss": 0.8184,
      "step": 316600
    },
    {
      "epoch": 3.3521789531073836,
      "grad_norm": 4.358470916748047,
      "learning_rate": 3.324581833580351e-05,
      "loss": 0.8218,
      "step": 316650
    },
    {
      "epoch": 3.352708274887387,
      "grad_norm": 4.0624799728393555,
      "learning_rate": 3.324317171289435e-05,
      "loss": 0.8115,
      "step": 316700
    },
    {
      "epoch": 3.35323759666739,
      "grad_norm": 3.8435702323913574,
      "learning_rate": 3.324052508998518e-05,
      "loss": 0.811,
      "step": 316750
    },
    {
      "epoch": 3.3537669184473935,
      "grad_norm": 4.136070728302002,
      "learning_rate": 3.323787846707601e-05,
      "loss": 0.8006,
      "step": 316800
    },
    {
      "epoch": 3.354296240227397,
      "grad_norm": 4.059343338012695,
      "learning_rate": 3.323523184416684e-05,
      "loss": 0.8064,
      "step": 316850
    },
    {
      "epoch": 3.3548255620073997,
      "grad_norm": 4.258129596710205,
      "learning_rate": 3.323258522125768e-05,
      "loss": 0.7971,
      "step": 316900
    },
    {
      "epoch": 3.3553548837874034,
      "grad_norm": 4.300953388214111,
      "learning_rate": 3.322993859834851e-05,
      "loss": 0.797,
      "step": 316950
    },
    {
      "epoch": 3.3558842055674063,
      "grad_norm": 4.278332710266113,
      "learning_rate": 3.322729197543934e-05,
      "loss": 0.8184,
      "step": 317000
    },
    {
      "epoch": 3.3558842055674063,
      "eval_loss": 0.5819228887557983,
      "eval_runtime": 46.6005,
      "eval_samples_per_second": 3603.607,
      "eval_steps_per_second": 450.467,
      "step": 317000
    },
    {
      "epoch": 3.3564135273474096,
      "grad_norm": 4.281296730041504,
      "learning_rate": 3.322464535253017e-05,
      "loss": 0.8084,
      "step": 317050
    },
    {
      "epoch": 3.356942849127413,
      "grad_norm": 4.49165678024292,
      "learning_rate": 3.3221998729621004e-05,
      "loss": 0.8102,
      "step": 317100
    },
    {
      "epoch": 3.3574721709074162,
      "grad_norm": 3.4602344036102295,
      "learning_rate": 3.321935210671184e-05,
      "loss": 0.8191,
      "step": 317150
    },
    {
      "epoch": 3.3580014926874195,
      "grad_norm": 4.109914302825928,
      "learning_rate": 3.3216705483802665e-05,
      "loss": 0.8078,
      "step": 317200
    },
    {
      "epoch": 3.358530814467423,
      "grad_norm": 4.2957329750061035,
      "learning_rate": 3.32140588608935e-05,
      "loss": 0.8035,
      "step": 317250
    },
    {
      "epoch": 3.359060136247426,
      "grad_norm": 3.9505982398986816,
      "learning_rate": 3.321141223798433e-05,
      "loss": 0.8087,
      "step": 317300
    },
    {
      "epoch": 3.3595894580274295,
      "grad_norm": 4.29042911529541,
      "learning_rate": 3.320876561507517e-05,
      "loss": 0.8199,
      "step": 317350
    },
    {
      "epoch": 3.360118779807433,
      "grad_norm": 3.7995595932006836,
      "learning_rate": 3.3206118992165995e-05,
      "loss": 0.8046,
      "step": 317400
    },
    {
      "epoch": 3.360648101587436,
      "grad_norm": 4.016903877258301,
      "learning_rate": 3.320347236925683e-05,
      "loss": 0.7989,
      "step": 317450
    },
    {
      "epoch": 3.3611774233674394,
      "grad_norm": 4.3091959953308105,
      "learning_rate": 3.320082574634766e-05,
      "loss": 0.8215,
      "step": 317500
    },
    {
      "epoch": 3.3611774233674394,
      "eval_loss": 0.5823109745979309,
      "eval_runtime": 46.8877,
      "eval_samples_per_second": 3581.536,
      "eval_steps_per_second": 447.708,
      "step": 317500
    },
    {
      "epoch": 3.3617067451474427,
      "grad_norm": 3.947313070297241,
      "learning_rate": 3.31981791234385e-05,
      "loss": 0.8211,
      "step": 317550
    },
    {
      "epoch": 3.362236066927446,
      "grad_norm": 4.143215656280518,
      "learning_rate": 3.3195532500529324e-05,
      "loss": 0.8137,
      "step": 317600
    },
    {
      "epoch": 3.362765388707449,
      "grad_norm": 3.7269675731658936,
      "learning_rate": 3.319288587762016e-05,
      "loss": 0.8113,
      "step": 317650
    },
    {
      "epoch": 3.3632947104874527,
      "grad_norm": 3.899440288543701,
      "learning_rate": 3.319023925471099e-05,
      "loss": 0.8277,
      "step": 317700
    },
    {
      "epoch": 3.3638240322674555,
      "grad_norm": 4.191736698150635,
      "learning_rate": 3.318759263180182e-05,
      "loss": 0.7998,
      "step": 317750
    },
    {
      "epoch": 3.364353354047459,
      "grad_norm": 4.273808479309082,
      "learning_rate": 3.3184946008892654e-05,
      "loss": 0.8036,
      "step": 317800
    },
    {
      "epoch": 3.364882675827462,
      "grad_norm": 4.154428482055664,
      "learning_rate": 3.318229938598348e-05,
      "loss": 0.817,
      "step": 317850
    },
    {
      "epoch": 3.3654119976074655,
      "grad_norm": 4.328262805938721,
      "learning_rate": 3.317965276307432e-05,
      "loss": 0.8146,
      "step": 317900
    },
    {
      "epoch": 3.3659413193874688,
      "grad_norm": 4.16204309463501,
      "learning_rate": 3.317700614016515e-05,
      "loss": 0.809,
      "step": 317950
    },
    {
      "epoch": 3.366470641167472,
      "grad_norm": 4.040108680725098,
      "learning_rate": 3.3174359517255983e-05,
      "loss": 0.8006,
      "step": 318000
    },
    {
      "epoch": 3.366470641167472,
      "eval_loss": 0.5810734629631042,
      "eval_runtime": 46.6057,
      "eval_samples_per_second": 3603.206,
      "eval_steps_per_second": 450.417,
      "step": 318000
    },
    {
      "epoch": 3.3669999629474754,
      "grad_norm": 3.9978110790252686,
      "learning_rate": 3.317171289434681e-05,
      "loss": 0.8159,
      "step": 318050
    },
    {
      "epoch": 3.3675292847274787,
      "grad_norm": 3.8592543601989746,
      "learning_rate": 3.316911920389583e-05,
      "loss": 0.8049,
      "step": 318100
    },
    {
      "epoch": 3.368058606507482,
      "grad_norm": 3.9370861053466797,
      "learning_rate": 3.316647258098666e-05,
      "loss": 0.8114,
      "step": 318150
    },
    {
      "epoch": 3.3685879282874853,
      "grad_norm": 4.294960021972656,
      "learning_rate": 3.3163825958077494e-05,
      "loss": 0.8054,
      "step": 318200
    },
    {
      "epoch": 3.3691172500674886,
      "grad_norm": 4.231526851654053,
      "learning_rate": 3.316117933516832e-05,
      "loss": 0.8272,
      "step": 318250
    },
    {
      "epoch": 3.369646571847492,
      "grad_norm": 4.119060516357422,
      "learning_rate": 3.315853271225916e-05,
      "loss": 0.8206,
      "step": 318300
    },
    {
      "epoch": 3.3701758936274953,
      "grad_norm": 4.10955810546875,
      "learning_rate": 3.315588608934999e-05,
      "loss": 0.8028,
      "step": 318350
    },
    {
      "epoch": 3.370705215407498,
      "grad_norm": 3.7602438926696777,
      "learning_rate": 3.315323946644082e-05,
      "loss": 0.8088,
      "step": 318400
    },
    {
      "epoch": 3.371234537187502,
      "grad_norm": 3.7207982540130615,
      "learning_rate": 3.315059284353165e-05,
      "loss": 0.7977,
      "step": 318450
    },
    {
      "epoch": 3.3717638589675047,
      "grad_norm": 4.362513065338135,
      "learning_rate": 3.314794622062249e-05,
      "loss": 0.7932,
      "step": 318500
    },
    {
      "epoch": 3.3717638589675047,
      "eval_loss": 0.5776605606079102,
      "eval_runtime": 46.6958,
      "eval_samples_per_second": 3596.258,
      "eval_steps_per_second": 449.548,
      "step": 318500
    },
    {
      "epoch": 3.372293180747508,
      "grad_norm": 3.7515387535095215,
      "learning_rate": 3.314529959771332e-05,
      "loss": 0.7981,
      "step": 318550
    },
    {
      "epoch": 3.3728225025275114,
      "grad_norm": 4.097480297088623,
      "learning_rate": 3.314265297480415e-05,
      "loss": 0.8147,
      "step": 318600
    },
    {
      "epoch": 3.3733518243075147,
      "grad_norm": 4.041143894195557,
      "learning_rate": 3.314000635189498e-05,
      "loss": 0.8073,
      "step": 318650
    },
    {
      "epoch": 3.373881146087518,
      "grad_norm": 4.060582637786865,
      "learning_rate": 3.3137359728985814e-05,
      "loss": 0.8187,
      "step": 318700
    },
    {
      "epoch": 3.3744104678675213,
      "grad_norm": 4.1576714515686035,
      "learning_rate": 3.313471310607665e-05,
      "loss": 0.8216,
      "step": 318750
    },
    {
      "epoch": 3.3749397896475246,
      "grad_norm": 4.288666725158691,
      "learning_rate": 3.3132066483167476e-05,
      "loss": 0.7901,
      "step": 318800
    },
    {
      "epoch": 3.375469111427528,
      "grad_norm": 4.508535861968994,
      "learning_rate": 3.312941986025831e-05,
      "loss": 0.806,
      "step": 318850
    },
    {
      "epoch": 3.3759984332075312,
      "grad_norm": 4.119896411895752,
      "learning_rate": 3.3126773237349144e-05,
      "loss": 0.8077,
      "step": 318900
    },
    {
      "epoch": 3.3765277549875345,
      "grad_norm": 3.6980206966400146,
      "learning_rate": 3.312412661443998e-05,
      "loss": 0.8016,
      "step": 318950
    },
    {
      "epoch": 3.377057076767538,
      "grad_norm": 4.072272300720215,
      "learning_rate": 3.3121479991530805e-05,
      "loss": 0.8016,
      "step": 319000
    },
    {
      "epoch": 3.377057076767538,
      "eval_loss": 0.5804306268692017,
      "eval_runtime": 46.6223,
      "eval_samples_per_second": 3601.928,
      "eval_steps_per_second": 450.257,
      "step": 319000
    },
    {
      "epoch": 3.377586398547541,
      "grad_norm": 3.990422010421753,
      "learning_rate": 3.311883336862164e-05,
      "loss": 0.8061,
      "step": 319050
    },
    {
      "epoch": 3.3781157203275445,
      "grad_norm": 3.9322307109832764,
      "learning_rate": 3.3116186745712474e-05,
      "loss": 0.8048,
      "step": 319100
    },
    {
      "epoch": 3.378645042107548,
      "grad_norm": 4.274456024169922,
      "learning_rate": 3.311354012280331e-05,
      "loss": 0.8279,
      "step": 319150
    },
    {
      "epoch": 3.379174363887551,
      "grad_norm": 3.9175057411193848,
      "learning_rate": 3.3110893499894135e-05,
      "loss": 0.8103,
      "step": 319200
    },
    {
      "epoch": 3.379703685667554,
      "grad_norm": 4.127187252044678,
      "learning_rate": 3.310824687698497e-05,
      "loss": 0.8074,
      "step": 319250
    },
    {
      "epoch": 3.3802330074475573,
      "grad_norm": 4.197738170623779,
      "learning_rate": 3.31056002540758e-05,
      "loss": 0.8112,
      "step": 319300
    },
    {
      "epoch": 3.3807623292275606,
      "grad_norm": 4.653997898101807,
      "learning_rate": 3.310295363116663e-05,
      "loss": 0.8076,
      "step": 319350
    },
    {
      "epoch": 3.381291651007564,
      "grad_norm": 4.060265064239502,
      "learning_rate": 3.3100307008257465e-05,
      "loss": 0.8129,
      "step": 319400
    },
    {
      "epoch": 3.381820972787567,
      "grad_norm": 3.879894971847534,
      "learning_rate": 3.309766038534829e-05,
      "loss": 0.8104,
      "step": 319450
    },
    {
      "epoch": 3.3823502945675705,
      "grad_norm": 3.945143461227417,
      "learning_rate": 3.309501376243913e-05,
      "loss": 0.7958,
      "step": 319500
    },
    {
      "epoch": 3.3823502945675705,
      "eval_loss": 0.5806671380996704,
      "eval_runtime": 46.6886,
      "eval_samples_per_second": 3596.808,
      "eval_steps_per_second": 449.617,
      "step": 319500
    },
    {
      "epoch": 3.382879616347574,
      "grad_norm": 3.912773847579956,
      "learning_rate": 3.309236713952996e-05,
      "loss": 0.8058,
      "step": 319550
    },
    {
      "epoch": 3.383408938127577,
      "grad_norm": 3.935652256011963,
      "learning_rate": 3.3089720516620794e-05,
      "loss": 0.8034,
      "step": 319600
    },
    {
      "epoch": 3.3839382599075805,
      "grad_norm": 3.892059326171875,
      "learning_rate": 3.308707389371162e-05,
      "loss": 0.8176,
      "step": 319650
    },
    {
      "epoch": 3.3844675816875838,
      "grad_norm": 4.2423882484436035,
      "learning_rate": 3.308442727080246e-05,
      "loss": 0.8017,
      "step": 319700
    },
    {
      "epoch": 3.384996903467587,
      "grad_norm": 4.18700647354126,
      "learning_rate": 3.308178064789329e-05,
      "loss": 0.8005,
      "step": 319750
    },
    {
      "epoch": 3.3855262252475904,
      "grad_norm": 4.1501569747924805,
      "learning_rate": 3.3079134024984124e-05,
      "loss": 0.8109,
      "step": 319800
    },
    {
      "epoch": 3.3860555470275937,
      "grad_norm": 4.054157733917236,
      "learning_rate": 3.307648740207495e-05,
      "loss": 0.8098,
      "step": 319850
    },
    {
      "epoch": 3.386584868807597,
      "grad_norm": 3.9693377017974854,
      "learning_rate": 3.3073840779165785e-05,
      "loss": 0.8088,
      "step": 319900
    },
    {
      "epoch": 3.3871141905876003,
      "grad_norm": 4.299491882324219,
      "learning_rate": 3.307119415625662e-05,
      "loss": 0.8238,
      "step": 319950
    },
    {
      "epoch": 3.387643512367603,
      "grad_norm": 4.388350486755371,
      "learning_rate": 3.306854753334745e-05,
      "loss": 0.793,
      "step": 320000
    },
    {
      "epoch": 3.387643512367603,
      "eval_loss": 0.5781710147857666,
      "eval_runtime": 46.6769,
      "eval_samples_per_second": 3597.709,
      "eval_steps_per_second": 449.73,
      "step": 320000
    },
    {
      "epoch": 3.3881728341476065,
      "grad_norm": 4.182741641998291,
      "learning_rate": 3.306590091043828e-05,
      "loss": 0.8032,
      "step": 320050
    },
    {
      "epoch": 3.38870215592761,
      "grad_norm": 4.2152099609375,
      "learning_rate": 3.30633072199873e-05,
      "loss": 0.8112,
      "step": 320100
    },
    {
      "epoch": 3.389231477707613,
      "grad_norm": 4.128808975219727,
      "learning_rate": 3.306066059707813e-05,
      "loss": 0.8106,
      "step": 320150
    },
    {
      "epoch": 3.3897607994876164,
      "grad_norm": 4.142758846282959,
      "learning_rate": 3.3058013974168964e-05,
      "loss": 0.8054,
      "step": 320200
    },
    {
      "epoch": 3.3902901212676197,
      "grad_norm": 4.269389629364014,
      "learning_rate": 3.305536735125979e-05,
      "loss": 0.7892,
      "step": 320250
    },
    {
      "epoch": 3.390819443047623,
      "grad_norm": 4.343765735626221,
      "learning_rate": 3.3052720728350625e-05,
      "loss": 0.7933,
      "step": 320300
    },
    {
      "epoch": 3.3913487648276264,
      "grad_norm": 3.9405667781829834,
      "learning_rate": 3.305007410544146e-05,
      "loss": 0.8068,
      "step": 320350
    },
    {
      "epoch": 3.3918780866076297,
      "grad_norm": 4.397610664367676,
      "learning_rate": 3.304742748253229e-05,
      "loss": 0.7966,
      "step": 320400
    },
    {
      "epoch": 3.392407408387633,
      "grad_norm": 3.87905216217041,
      "learning_rate": 3.304478085962312e-05,
      "loss": 0.8171,
      "step": 320450
    },
    {
      "epoch": 3.3929367301676363,
      "grad_norm": 4.51840877532959,
      "learning_rate": 3.3042134236713955e-05,
      "loss": 0.8112,
      "step": 320500
    },
    {
      "epoch": 3.3929367301676363,
      "eval_loss": 0.5785611271858215,
      "eval_runtime": 46.6234,
      "eval_samples_per_second": 3601.838,
      "eval_steps_per_second": 450.246,
      "step": 320500
    },
    {
      "epoch": 3.3934660519476396,
      "grad_norm": 3.9053890705108643,
      "learning_rate": 3.303948761380479e-05,
      "loss": 0.805,
      "step": 320550
    },
    {
      "epoch": 3.393995373727643,
      "grad_norm": 4.232982158660889,
      "learning_rate": 3.3036840990895616e-05,
      "loss": 0.8074,
      "step": 320600
    },
    {
      "epoch": 3.3945246955076462,
      "grad_norm": 4.097164154052734,
      "learning_rate": 3.303419436798645e-05,
      "loss": 0.8057,
      "step": 320650
    },
    {
      "epoch": 3.3950540172876496,
      "grad_norm": 4.494931697845459,
      "learning_rate": 3.3031547745077284e-05,
      "loss": 0.8152,
      "step": 320700
    },
    {
      "epoch": 3.3955833390676524,
      "grad_norm": 4.115018367767334,
      "learning_rate": 3.302890112216812e-05,
      "loss": 0.8087,
      "step": 320750
    },
    {
      "epoch": 3.3961126608476557,
      "grad_norm": 4.021275043487549,
      "learning_rate": 3.3026254499258946e-05,
      "loss": 0.7928,
      "step": 320800
    },
    {
      "epoch": 3.396641982627659,
      "grad_norm": 4.135788917541504,
      "learning_rate": 3.302360787634978e-05,
      "loss": 0.812,
      "step": 320850
    },
    {
      "epoch": 3.3971713044076624,
      "grad_norm": 3.7397053241729736,
      "learning_rate": 3.3020961253440614e-05,
      "loss": 0.8141,
      "step": 320900
    },
    {
      "epoch": 3.3977006261876657,
      "grad_norm": 4.126075267791748,
      "learning_rate": 3.301831463053144e-05,
      "loss": 0.8201,
      "step": 320950
    },
    {
      "epoch": 3.398229947967669,
      "grad_norm": 4.4171462059021,
      "learning_rate": 3.3015668007622276e-05,
      "loss": 0.8185,
      "step": 321000
    },
    {
      "epoch": 3.398229947967669,
      "eval_loss": 0.5781710743904114,
      "eval_runtime": 46.6973,
      "eval_samples_per_second": 3596.137,
      "eval_steps_per_second": 449.533,
      "step": 321000
    },
    {
      "epoch": 3.3987592697476723,
      "grad_norm": 4.276150226593018,
      "learning_rate": 3.30130213847131e-05,
      "loss": 0.8093,
      "step": 321050
    },
    {
      "epoch": 3.3992885915276756,
      "grad_norm": 3.9317612648010254,
      "learning_rate": 3.3010374761803944e-05,
      "loss": 0.7918,
      "step": 321100
    },
    {
      "epoch": 3.399817913307679,
      "grad_norm": 4.092757701873779,
      "learning_rate": 3.300772813889477e-05,
      "loss": 0.8091,
      "step": 321150
    },
    {
      "epoch": 3.400347235087682,
      "grad_norm": 4.509311199188232,
      "learning_rate": 3.3005081515985605e-05,
      "loss": 0.8139,
      "step": 321200
    },
    {
      "epoch": 3.4008765568676855,
      "grad_norm": 4.067862510681152,
      "learning_rate": 3.300243489307643e-05,
      "loss": 0.8134,
      "step": 321250
    },
    {
      "epoch": 3.401405878647689,
      "grad_norm": 4.373751163482666,
      "learning_rate": 3.299978827016727e-05,
      "loss": 0.8192,
      "step": 321300
    },
    {
      "epoch": 3.401935200427692,
      "grad_norm": 4.11965799331665,
      "learning_rate": 3.29971416472581e-05,
      "loss": 0.8048,
      "step": 321350
    },
    {
      "epoch": 3.4024645222076955,
      "grad_norm": 4.015341281890869,
      "learning_rate": 3.2994495024348935e-05,
      "loss": 0.8211,
      "step": 321400
    },
    {
      "epoch": 3.4029938439876988,
      "grad_norm": 4.235813617706299,
      "learning_rate": 3.299184840143976e-05,
      "loss": 0.7919,
      "step": 321450
    },
    {
      "epoch": 3.4035231657677016,
      "grad_norm": 3.9174673557281494,
      "learning_rate": 3.2989201778530596e-05,
      "loss": 0.8107,
      "step": 321500
    },
    {
      "epoch": 3.4035231657677016,
      "eval_loss": 0.5772026181221008,
      "eval_runtime": 46.6122,
      "eval_samples_per_second": 3602.705,
      "eval_steps_per_second": 450.354,
      "step": 321500
    },
    {
      "epoch": 3.404052487547705,
      "grad_norm": 4.011691093444824,
      "learning_rate": 3.298655515562143e-05,
      "loss": 0.7969,
      "step": 321550
    },
    {
      "epoch": 3.4045818093277083,
      "grad_norm": 3.658418655395508,
      "learning_rate": 3.298390853271226e-05,
      "loss": 0.8238,
      "step": 321600
    },
    {
      "epoch": 3.4051111311077116,
      "grad_norm": 3.6873579025268555,
      "learning_rate": 3.298126190980309e-05,
      "loss": 0.8048,
      "step": 321650
    },
    {
      "epoch": 3.405640452887715,
      "grad_norm": 3.7334604263305664,
      "learning_rate": 3.297866821935211e-05,
      "loss": 0.7922,
      "step": 321700
    },
    {
      "epoch": 3.406169774667718,
      "grad_norm": 3.4332261085510254,
      "learning_rate": 3.297602159644294e-05,
      "loss": 0.8048,
      "step": 321750
    },
    {
      "epoch": 3.4066990964477215,
      "grad_norm": 3.886046886444092,
      "learning_rate": 3.2973374973533775e-05,
      "loss": 0.7966,
      "step": 321800
    },
    {
      "epoch": 3.407228418227725,
      "grad_norm": 4.045165061950684,
      "learning_rate": 3.29707283506246e-05,
      "loss": 0.8079,
      "step": 321850
    },
    {
      "epoch": 3.407757740007728,
      "grad_norm": 4.658859729766846,
      "learning_rate": 3.2968081727715436e-05,
      "loss": 0.804,
      "step": 321900
    },
    {
      "epoch": 3.4082870617877314,
      "grad_norm": 3.9713892936706543,
      "learning_rate": 3.296543510480627e-05,
      "loss": 0.8049,
      "step": 321950
    },
    {
      "epoch": 3.4088163835677348,
      "grad_norm": 4.301203727722168,
      "learning_rate": 3.29627884818971e-05,
      "loss": 0.8032,
      "step": 322000
    },
    {
      "epoch": 3.4088163835677348,
      "eval_loss": 0.5764764547348022,
      "eval_runtime": 46.6209,
      "eval_samples_per_second": 3602.032,
      "eval_steps_per_second": 450.27,
      "step": 322000
    },
    {
      "epoch": 3.409345705347738,
      "grad_norm": 4.191380500793457,
      "learning_rate": 3.296014185898793e-05,
      "loss": 0.7983,
      "step": 322050
    },
    {
      "epoch": 3.4098750271277414,
      "grad_norm": 4.090077877044678,
      "learning_rate": 3.2957495236078766e-05,
      "loss": 0.809,
      "step": 322100
    },
    {
      "epoch": 3.4104043489077447,
      "grad_norm": 4.047390937805176,
      "learning_rate": 3.29548486131696e-05,
      "loss": 0.8012,
      "step": 322150
    },
    {
      "epoch": 3.410933670687748,
      "grad_norm": 3.932358741760254,
      "learning_rate": 3.295220199026043e-05,
      "loss": 0.8019,
      "step": 322200
    },
    {
      "epoch": 3.411462992467751,
      "grad_norm": 4.26503324508667,
      "learning_rate": 3.294955536735126e-05,
      "loss": 0.8117,
      "step": 322250
    },
    {
      "epoch": 3.411992314247754,
      "grad_norm": 4.2300310134887695,
      "learning_rate": 3.2946908744442095e-05,
      "loss": 0.8085,
      "step": 322300
    },
    {
      "epoch": 3.4125216360277575,
      "grad_norm": 4.261626720428467,
      "learning_rate": 3.294426212153293e-05,
      "loss": 0.8116,
      "step": 322350
    },
    {
      "epoch": 3.413050957807761,
      "grad_norm": 4.10362434387207,
      "learning_rate": 3.294161549862376e-05,
      "loss": 0.8075,
      "step": 322400
    },
    {
      "epoch": 3.413580279587764,
      "grad_norm": 4.089475154876709,
      "learning_rate": 3.293896887571459e-05,
      "loss": 0.7985,
      "step": 322450
    },
    {
      "epoch": 3.4141096013677674,
      "grad_norm": 3.9108059406280518,
      "learning_rate": 3.2936322252805425e-05,
      "loss": 0.8147,
      "step": 322500
    },
    {
      "epoch": 3.4141096013677674,
      "eval_loss": 0.5761793255805969,
      "eval_runtime": 46.5503,
      "eval_samples_per_second": 3607.492,
      "eval_steps_per_second": 450.953,
      "step": 322500
    },
    {
      "epoch": 3.4146389231477707,
      "grad_norm": 4.151360034942627,
      "learning_rate": 3.293367562989625e-05,
      "loss": 0.818,
      "step": 322550
    },
    {
      "epoch": 3.415168244927774,
      "grad_norm": 3.741426467895508,
      "learning_rate": 3.2931029006987086e-05,
      "loss": 0.8091,
      "step": 322600
    },
    {
      "epoch": 3.4156975667077774,
      "grad_norm": 4.197854042053223,
      "learning_rate": 3.2928382384077914e-05,
      "loss": 0.7973,
      "step": 322650
    },
    {
      "epoch": 3.4162268884877807,
      "grad_norm": 4.322773456573486,
      "learning_rate": 3.2925735761168755e-05,
      "loss": 0.8198,
      "step": 322700
    },
    {
      "epoch": 3.416756210267784,
      "grad_norm": 4.372220516204834,
      "learning_rate": 3.292308913825958e-05,
      "loss": 0.8022,
      "step": 322750
    },
    {
      "epoch": 3.4172855320477873,
      "grad_norm": 4.217456340789795,
      "learning_rate": 3.2920442515350416e-05,
      "loss": 0.8101,
      "step": 322800
    },
    {
      "epoch": 3.4178148538277906,
      "grad_norm": 4.036147117614746,
      "learning_rate": 3.291779589244124e-05,
      "loss": 0.8022,
      "step": 322850
    },
    {
      "epoch": 3.418344175607794,
      "grad_norm": 3.977299213409424,
      "learning_rate": 3.291514926953208e-05,
      "loss": 0.805,
      "step": 322900
    },
    {
      "epoch": 3.4188734973877972,
      "grad_norm": 3.7494072914123535,
      "learning_rate": 3.291250264662291e-05,
      "loss": 0.791,
      "step": 322950
    },
    {
      "epoch": 3.4194028191678,
      "grad_norm": 3.9395811557769775,
      "learning_rate": 3.290985602371374e-05,
      "loss": 0.7851,
      "step": 323000
    },
    {
      "epoch": 3.4194028191678,
      "eval_loss": 0.575203537940979,
      "eval_runtime": 46.6057,
      "eval_samples_per_second": 3603.209,
      "eval_steps_per_second": 450.417,
      "step": 323000
    },
    {
      "epoch": 3.4199321409478034,
      "grad_norm": 4.068427085876465,
      "learning_rate": 3.290720940080457e-05,
      "loss": 0.8084,
      "step": 323050
    },
    {
      "epoch": 3.4204614627278067,
      "grad_norm": 4.152734756469727,
      "learning_rate": 3.290456277789541e-05,
      "loss": 0.8087,
      "step": 323100
    },
    {
      "epoch": 3.42099078450781,
      "grad_norm": 3.987630605697632,
      "learning_rate": 3.290191615498624e-05,
      "loss": 0.7941,
      "step": 323150
    },
    {
      "epoch": 3.4215201062878133,
      "grad_norm": 4.22703218460083,
      "learning_rate": 3.289926953207707e-05,
      "loss": 0.8084,
      "step": 323200
    },
    {
      "epoch": 3.4220494280678166,
      "grad_norm": 4.140468120574951,
      "learning_rate": 3.28966229091679e-05,
      "loss": 0.7934,
      "step": 323250
    },
    {
      "epoch": 3.42257874984782,
      "grad_norm": 4.424014568328857,
      "learning_rate": 3.289397628625874e-05,
      "loss": 0.8134,
      "step": 323300
    },
    {
      "epoch": 3.4231080716278233,
      "grad_norm": 4.373829364776611,
      "learning_rate": 3.289132966334957e-05,
      "loss": 0.8004,
      "step": 323350
    },
    {
      "epoch": 3.4236373934078266,
      "grad_norm": 4.170352935791016,
      "learning_rate": 3.28886830404404e-05,
      "loss": 0.8085,
      "step": 323400
    },
    {
      "epoch": 3.42416671518783,
      "grad_norm": 4.43510627746582,
      "learning_rate": 3.288603641753123e-05,
      "loss": 0.8112,
      "step": 323450
    },
    {
      "epoch": 3.424696036967833,
      "grad_norm": 3.9880220890045166,
      "learning_rate": 3.2883389794622066e-05,
      "loss": 0.8133,
      "step": 323500
    },
    {
      "epoch": 3.424696036967833,
      "eval_loss": 0.5764433741569519,
      "eval_runtime": 46.6003,
      "eval_samples_per_second": 3603.627,
      "eval_steps_per_second": 450.47,
      "step": 323500
    },
    {
      "epoch": 3.4252253587478365,
      "grad_norm": 4.023452281951904,
      "learning_rate": 3.2880743171712894e-05,
      "loss": 0.7976,
      "step": 323550
    },
    {
      "epoch": 3.42575468052784,
      "grad_norm": 3.7401888370513916,
      "learning_rate": 3.287809654880373e-05,
      "loss": 0.8056,
      "step": 323600
    },
    {
      "epoch": 3.426284002307843,
      "grad_norm": 4.1705522537231445,
      "learning_rate": 3.2875449925894555e-05,
      "loss": 0.8072,
      "step": 323650
    },
    {
      "epoch": 3.4268133240878464,
      "grad_norm": 4.334506988525391,
      "learning_rate": 3.2872803302985396e-05,
      "loss": 0.8177,
      "step": 323700
    },
    {
      "epoch": 3.4273426458678493,
      "grad_norm": 4.3272480964660645,
      "learning_rate": 3.287015668007622e-05,
      "loss": 0.8118,
      "step": 323750
    },
    {
      "epoch": 3.4278719676478526,
      "grad_norm": 4.389456272125244,
      "learning_rate": 3.286751005716706e-05,
      "loss": 0.7949,
      "step": 323800
    },
    {
      "epoch": 3.428401289427856,
      "grad_norm": 3.7280306816101074,
      "learning_rate": 3.2864863434257885e-05,
      "loss": 0.8101,
      "step": 323850
    },
    {
      "epoch": 3.4289306112078592,
      "grad_norm": 4.053770065307617,
      "learning_rate": 3.2862216811348725e-05,
      "loss": 0.8144,
      "step": 323900
    },
    {
      "epoch": 3.4294599329878626,
      "grad_norm": 4.530767440795898,
      "learning_rate": 3.285957018843955e-05,
      "loss": 0.7972,
      "step": 323950
    },
    {
      "epoch": 3.429989254767866,
      "grad_norm": 4.32480525970459,
      "learning_rate": 3.285692356553039e-05,
      "loss": 0.8055,
      "step": 324000
    },
    {
      "epoch": 3.429989254767866,
      "eval_loss": 0.5768314599990845,
      "eval_runtime": 46.6428,
      "eval_samples_per_second": 3600.342,
      "eval_steps_per_second": 450.059,
      "step": 324000
    },
    {
      "epoch": 3.430518576547869,
      "grad_norm": 3.944518566131592,
      "learning_rate": 3.2854276942621214e-05,
      "loss": 0.797,
      "step": 324050
    },
    {
      "epoch": 3.4310478983278725,
      "grad_norm": 4.233877182006836,
      "learning_rate": 3.285163031971205e-05,
      "loss": 0.8058,
      "step": 324100
    },
    {
      "epoch": 3.431577220107876,
      "grad_norm": 3.9288179874420166,
      "learning_rate": 3.284898369680288e-05,
      "loss": 0.8158,
      "step": 324150
    },
    {
      "epoch": 3.432106541887879,
      "grad_norm": 4.066677570343018,
      "learning_rate": 3.284633707389371e-05,
      "loss": 0.8013,
      "step": 324200
    },
    {
      "epoch": 3.4326358636678824,
      "grad_norm": 4.486300468444824,
      "learning_rate": 3.2843690450984544e-05,
      "loss": 0.8019,
      "step": 324250
    },
    {
      "epoch": 3.4331651854478857,
      "grad_norm": 3.785743236541748,
      "learning_rate": 3.284104382807538e-05,
      "loss": 0.8012,
      "step": 324300
    },
    {
      "epoch": 3.433694507227889,
      "grad_norm": 4.206705570220947,
      "learning_rate": 3.283839720516621e-05,
      "loss": 0.8059,
      "step": 324350
    },
    {
      "epoch": 3.4342238290078924,
      "grad_norm": 4.0265960693359375,
      "learning_rate": 3.283575058225704e-05,
      "loss": 0.7995,
      "step": 324400
    },
    {
      "epoch": 3.4347531507878957,
      "grad_norm": 3.752788543701172,
      "learning_rate": 3.2833103959347873e-05,
      "loss": 0.8034,
      "step": 324450
    },
    {
      "epoch": 3.4352824725678985,
      "grad_norm": 4.096670150756836,
      "learning_rate": 3.283045733643871e-05,
      "loss": 0.8056,
      "step": 324500
    },
    {
      "epoch": 3.4352824725678985,
      "eval_loss": 0.5736114382743835,
      "eval_runtime": 46.7268,
      "eval_samples_per_second": 3593.871,
      "eval_steps_per_second": 449.25,
      "step": 324500
    },
    {
      "epoch": 3.435811794347902,
      "grad_norm": 4.38978910446167,
      "learning_rate": 3.282781071352954e-05,
      "loss": 0.8054,
      "step": 324550
    },
    {
      "epoch": 3.436341116127905,
      "grad_norm": 4.0408854484558105,
      "learning_rate": 3.282516409062037e-05,
      "loss": 0.8063,
      "step": 324600
    },
    {
      "epoch": 3.4368704379079085,
      "grad_norm": 4.603285312652588,
      "learning_rate": 3.28225174677112e-05,
      "loss": 0.8234,
      "step": 324650
    },
    {
      "epoch": 3.437399759687912,
      "grad_norm": 4.3151469230651855,
      "learning_rate": 3.281987084480204e-05,
      "loss": 0.7966,
      "step": 324700
    },
    {
      "epoch": 3.437929081467915,
      "grad_norm": 4.060735702514648,
      "learning_rate": 3.2817224221892865e-05,
      "loss": 0.8088,
      "step": 324750
    },
    {
      "epoch": 3.4384584032479184,
      "grad_norm": 3.6104681491851807,
      "learning_rate": 3.28145775989837e-05,
      "loss": 0.8032,
      "step": 324800
    },
    {
      "epoch": 3.4389877250279217,
      "grad_norm": 3.7046446800231934,
      "learning_rate": 3.2811930976074526e-05,
      "loss": 0.8115,
      "step": 324850
    },
    {
      "epoch": 3.439517046807925,
      "grad_norm": 3.9546782970428467,
      "learning_rate": 3.280928435316537e-05,
      "loss": 0.8082,
      "step": 324900
    },
    {
      "epoch": 3.4400463685879283,
      "grad_norm": 3.7036542892456055,
      "learning_rate": 3.2806637730256194e-05,
      "loss": 0.8098,
      "step": 324950
    },
    {
      "epoch": 3.4405756903679316,
      "grad_norm": 4.005921840667725,
      "learning_rate": 3.280399110734703e-05,
      "loss": 0.8046,
      "step": 325000
    },
    {
      "epoch": 3.4405756903679316,
      "eval_loss": 0.5735448002815247,
      "eval_runtime": 46.4998,
      "eval_samples_per_second": 3611.413,
      "eval_steps_per_second": 451.443,
      "step": 325000
    },
    {
      "epoch": 3.441105012147935,
      "grad_norm": 4.0636444091796875,
      "learning_rate": 3.2801344484437856e-05,
      "loss": 0.8066,
      "step": 325050
    },
    {
      "epoch": 3.4416343339279383,
      "grad_norm": 3.627077341079712,
      "learning_rate": 3.2798697861528696e-05,
      "loss": 0.8118,
      "step": 325100
    },
    {
      "epoch": 3.4421636557079416,
      "grad_norm": 4.19903564453125,
      "learning_rate": 3.2796051238619524e-05,
      "loss": 0.799,
      "step": 325150
    },
    {
      "epoch": 3.442692977487945,
      "grad_norm": 3.926361560821533,
      "learning_rate": 3.279340461571036e-05,
      "loss": 0.7928,
      "step": 325200
    },
    {
      "epoch": 3.4432222992679478,
      "grad_norm": 4.134844779968262,
      "learning_rate": 3.2790757992801185e-05,
      "loss": 0.8038,
      "step": 325250
    },
    {
      "epoch": 3.443751621047951,
      "grad_norm": 4.101051330566406,
      "learning_rate": 3.278811136989202e-05,
      "loss": 0.8047,
      "step": 325300
    },
    {
      "epoch": 3.4442809428279544,
      "grad_norm": 3.885070562362671,
      "learning_rate": 3.2785464746982853e-05,
      "loss": 0.8033,
      "step": 325350
    },
    {
      "epoch": 3.4448102646079577,
      "grad_norm": 4.496248722076416,
      "learning_rate": 3.278281812407368e-05,
      "loss": 0.8074,
      "step": 325400
    },
    {
      "epoch": 3.445339586387961,
      "grad_norm": 4.054523944854736,
      "learning_rate": 3.2780171501164515e-05,
      "loss": 0.8182,
      "step": 325450
    },
    {
      "epoch": 3.4458689081679643,
      "grad_norm": 4.125922679901123,
      "learning_rate": 3.277752487825535e-05,
      "loss": 0.783,
      "step": 325500
    },
    {
      "epoch": 3.4458689081679643,
      "eval_loss": 0.5725288391113281,
      "eval_runtime": 46.5934,
      "eval_samples_per_second": 3604.158,
      "eval_steps_per_second": 450.536,
      "step": 325500
    },
    {
      "epoch": 3.4463982299479676,
      "grad_norm": 3.885892391204834,
      "learning_rate": 3.277487825534618e-05,
      "loss": 0.8045,
      "step": 325550
    },
    {
      "epoch": 3.446927551727971,
      "grad_norm": 3.86543345451355,
      "learning_rate": 3.277223163243701e-05,
      "loss": 0.8001,
      "step": 325600
    },
    {
      "epoch": 3.4474568735079743,
      "grad_norm": 3.7462334632873535,
      "learning_rate": 3.2769585009527844e-05,
      "loss": 0.8019,
      "step": 325650
    },
    {
      "epoch": 3.4479861952879776,
      "grad_norm": 3.99078106880188,
      "learning_rate": 3.276699131907686e-05,
      "loss": 0.7961,
      "step": 325700
    },
    {
      "epoch": 3.448515517067981,
      "grad_norm": 3.956031560897827,
      "learning_rate": 3.276434469616769e-05,
      "loss": 0.8081,
      "step": 325750
    },
    {
      "epoch": 3.449044838847984,
      "grad_norm": 4.389606952667236,
      "learning_rate": 3.276169807325852e-05,
      "loss": 0.8005,
      "step": 325800
    },
    {
      "epoch": 3.4495741606279875,
      "grad_norm": 3.9596481323242188,
      "learning_rate": 3.2759051450349355e-05,
      "loss": 0.8059,
      "step": 325850
    },
    {
      "epoch": 3.450103482407991,
      "grad_norm": 4.343353748321533,
      "learning_rate": 3.2756457759898376e-05,
      "loss": 0.794,
      "step": 325900
    },
    {
      "epoch": 3.450632804187994,
      "grad_norm": 4.258572101593018,
      "learning_rate": 3.2753811136989203e-05,
      "loss": 0.8053,
      "step": 325950
    },
    {
      "epoch": 3.451162125967997,
      "grad_norm": 4.197073459625244,
      "learning_rate": 3.275116451408004e-05,
      "loss": 0.8073,
      "step": 326000
    },
    {
      "epoch": 3.451162125967997,
      "eval_loss": 0.5746944546699524,
      "eval_runtime": 46.696,
      "eval_samples_per_second": 3596.24,
      "eval_steps_per_second": 449.546,
      "step": 326000
    },
    {
      "epoch": 3.4516914477480003,
      "grad_norm": 4.017541408538818,
      "learning_rate": 3.2748517891170865e-05,
      "loss": 0.8191,
      "step": 326050
    },
    {
      "epoch": 3.4522207695280036,
      "grad_norm": 3.7451210021972656,
      "learning_rate": 3.27458712682617e-05,
      "loss": 0.8049,
      "step": 326100
    },
    {
      "epoch": 3.452750091308007,
      "grad_norm": 4.16391658782959,
      "learning_rate": 3.274322464535253e-05,
      "loss": 0.8228,
      "step": 326150
    },
    {
      "epoch": 3.4532794130880102,
      "grad_norm": 4.009072303771973,
      "learning_rate": 3.274057802244336e-05,
      "loss": 0.7935,
      "step": 326200
    },
    {
      "epoch": 3.4538087348680135,
      "grad_norm": 4.361654281616211,
      "learning_rate": 3.2737931399534195e-05,
      "loss": 0.7986,
      "step": 326250
    },
    {
      "epoch": 3.454338056648017,
      "grad_norm": 4.365171432495117,
      "learning_rate": 3.273528477662503e-05,
      "loss": 0.805,
      "step": 326300
    },
    {
      "epoch": 3.45486737842802,
      "grad_norm": 4.147866249084473,
      "learning_rate": 3.273263815371586e-05,
      "loss": 0.8096,
      "step": 326350
    },
    {
      "epoch": 3.4553967002080235,
      "grad_norm": 3.605402946472168,
      "learning_rate": 3.272999153080669e-05,
      "loss": 0.807,
      "step": 326400
    },
    {
      "epoch": 3.455926021988027,
      "grad_norm": 3.958141803741455,
      "learning_rate": 3.2727344907897524e-05,
      "loss": 0.8003,
      "step": 326450
    },
    {
      "epoch": 3.45645534376803,
      "grad_norm": 4.395881175994873,
      "learning_rate": 3.272469828498836e-05,
      "loss": 0.7965,
      "step": 326500
    },
    {
      "epoch": 3.45645534376803,
      "eval_loss": 0.5715563893318176,
      "eval_runtime": 46.734,
      "eval_samples_per_second": 3593.319,
      "eval_steps_per_second": 449.181,
      "step": 326500
    },
    {
      "epoch": 3.4569846655480334,
      "grad_norm": 4.3737874031066895,
      "learning_rate": 3.272205166207919e-05,
      "loss": 0.8026,
      "step": 326550
    },
    {
      "epoch": 3.4575139873280367,
      "grad_norm": 4.201296329498291,
      "learning_rate": 3.271940503917002e-05,
      "loss": 0.8048,
      "step": 326600
    },
    {
      "epoch": 3.45804330910804,
      "grad_norm": 3.853553056716919,
      "learning_rate": 3.2716758416260854e-05,
      "loss": 0.7985,
      "step": 326650
    },
    {
      "epoch": 3.4585726308880433,
      "grad_norm": 4.039078235626221,
      "learning_rate": 3.271411179335169e-05,
      "loss": 0.7996,
      "step": 326700
    },
    {
      "epoch": 3.459101952668046,
      "grad_norm": 3.9655542373657227,
      "learning_rate": 3.2711465170442515e-05,
      "loss": 0.7877,
      "step": 326750
    },
    {
      "epoch": 3.4596312744480495,
      "grad_norm": 4.166440486907959,
      "learning_rate": 3.270881854753335e-05,
      "loss": 0.8001,
      "step": 326800
    },
    {
      "epoch": 3.460160596228053,
      "grad_norm": 3.7318103313446045,
      "learning_rate": 3.270617192462418e-05,
      "loss": 0.7916,
      "step": 326850
    },
    {
      "epoch": 3.460689918008056,
      "grad_norm": 3.4122726917266846,
      "learning_rate": 3.270352530171502e-05,
      "loss": 0.8125,
      "step": 326900
    },
    {
      "epoch": 3.4612192397880595,
      "grad_norm": 3.917818784713745,
      "learning_rate": 3.2700878678805845e-05,
      "loss": 0.792,
      "step": 326950
    },
    {
      "epoch": 3.4617485615680628,
      "grad_norm": 3.9756081104278564,
      "learning_rate": 3.269823205589668e-05,
      "loss": 0.8169,
      "step": 327000
    },
    {
      "epoch": 3.4617485615680628,
      "eval_loss": 0.5747199058532715,
      "eval_runtime": 46.6125,
      "eval_samples_per_second": 3602.678,
      "eval_steps_per_second": 450.351,
      "step": 327000
    },
    {
      "epoch": 3.462277883348066,
      "grad_norm": 3.986025810241699,
      "learning_rate": 3.2695585432987506e-05,
      "loss": 0.8086,
      "step": 327050
    },
    {
      "epoch": 3.4628072051280694,
      "grad_norm": 4.262334823608398,
      "learning_rate": 3.269293881007835e-05,
      "loss": 0.8145,
      "step": 327100
    },
    {
      "epoch": 3.4633365269080727,
      "grad_norm": 3.9949841499328613,
      "learning_rate": 3.2690292187169174e-05,
      "loss": 0.7949,
      "step": 327150
    },
    {
      "epoch": 3.463865848688076,
      "grad_norm": 3.6777310371398926,
      "learning_rate": 3.268764556426001e-05,
      "loss": 0.8174,
      "step": 327200
    },
    {
      "epoch": 3.4643951704680793,
      "grad_norm": 4.199769496917725,
      "learning_rate": 3.2684998941350836e-05,
      "loss": 0.7944,
      "step": 327250
    },
    {
      "epoch": 3.4649244922480826,
      "grad_norm": 4.5328688621521,
      "learning_rate": 3.268235231844167e-05,
      "loss": 0.8026,
      "step": 327300
    },
    {
      "epoch": 3.465453814028086,
      "grad_norm": 4.583000659942627,
      "learning_rate": 3.2679705695532504e-05,
      "loss": 0.7944,
      "step": 327350
    },
    {
      "epoch": 3.4659831358080893,
      "grad_norm": 4.065957069396973,
      "learning_rate": 3.267705907262333e-05,
      "loss": 0.8006,
      "step": 327400
    },
    {
      "epoch": 3.4665124575880926,
      "grad_norm": 4.411521911621094,
      "learning_rate": 3.2674412449714165e-05,
      "loss": 0.7971,
      "step": 327450
    },
    {
      "epoch": 3.4670417793680954,
      "grad_norm": 4.45643424987793,
      "learning_rate": 3.2671765826805e-05,
      "loss": 0.805,
      "step": 327500
    },
    {
      "epoch": 3.4670417793680954,
      "eval_loss": 0.5712062120437622,
      "eval_runtime": 46.6928,
      "eval_samples_per_second": 3596.49,
      "eval_steps_per_second": 449.577,
      "step": 327500
    },
    {
      "epoch": 3.467571101148099,
      "grad_norm": 4.4466657638549805,
      "learning_rate": 3.2669119203895834e-05,
      "loss": 0.7985,
      "step": 327550
    },
    {
      "epoch": 3.468100422928102,
      "grad_norm": 4.252292156219482,
      "learning_rate": 3.266647258098666e-05,
      "loss": 0.8104,
      "step": 327600
    },
    {
      "epoch": 3.4686297447081054,
      "grad_norm": 3.9621334075927734,
      "learning_rate": 3.2663825958077495e-05,
      "loss": 0.8019,
      "step": 327650
    },
    {
      "epoch": 3.4691590664881087,
      "grad_norm": 3.4812533855438232,
      "learning_rate": 3.266117933516833e-05,
      "loss": 0.795,
      "step": 327700
    },
    {
      "epoch": 3.469688388268112,
      "grad_norm": 4.101845741271973,
      "learning_rate": 3.265853271225916e-05,
      "loss": 0.7868,
      "step": 327750
    },
    {
      "epoch": 3.4702177100481153,
      "grad_norm": 3.8477513790130615,
      "learning_rate": 3.265588608934999e-05,
      "loss": 0.8041,
      "step": 327800
    },
    {
      "epoch": 3.4707470318281186,
      "grad_norm": 4.013373374938965,
      "learning_rate": 3.2653239466440825e-05,
      "loss": 0.8009,
      "step": 327850
    },
    {
      "epoch": 3.471276353608122,
      "grad_norm": 4.468918323516846,
      "learning_rate": 3.265059284353166e-05,
      "loss": 0.7992,
      "step": 327900
    },
    {
      "epoch": 3.4718056753881252,
      "grad_norm": 3.7110378742218018,
      "learning_rate": 3.2647946220622486e-05,
      "loss": 0.8025,
      "step": 327950
    },
    {
      "epoch": 3.4723349971681285,
      "grad_norm": 4.4019269943237305,
      "learning_rate": 3.264529959771332e-05,
      "loss": 0.7997,
      "step": 328000
    },
    {
      "epoch": 3.4723349971681285,
      "eval_loss": 0.5719747543334961,
      "eval_runtime": 46.6465,
      "eval_samples_per_second": 3600.055,
      "eval_steps_per_second": 450.023,
      "step": 328000
    },
    {
      "epoch": 3.472864318948132,
      "grad_norm": 3.989891290664673,
      "learning_rate": 3.264265297480415e-05,
      "loss": 0.8041,
      "step": 328050
    },
    {
      "epoch": 3.473393640728135,
      "grad_norm": 4.052237033843994,
      "learning_rate": 3.264000635189499e-05,
      "loss": 0.8037,
      "step": 328100
    },
    {
      "epoch": 3.4739229625081385,
      "grad_norm": 4.436230182647705,
      "learning_rate": 3.2637359728985816e-05,
      "loss": 0.8136,
      "step": 328150
    },
    {
      "epoch": 3.474452284288142,
      "grad_norm": 3.945673942565918,
      "learning_rate": 3.263471310607665e-05,
      "loss": 0.817,
      "step": 328200
    },
    {
      "epoch": 3.4749816060681447,
      "grad_norm": 3.934215784072876,
      "learning_rate": 3.263206648316748e-05,
      "loss": 0.805,
      "step": 328250
    },
    {
      "epoch": 3.4755109278481484,
      "grad_norm": 4.102227687835693,
      "learning_rate": 3.262941986025831e-05,
      "loss": 0.8021,
      "step": 328300
    },
    {
      "epoch": 3.4760402496281513,
      "grad_norm": 4.119774341583252,
      "learning_rate": 3.2626773237349145e-05,
      "loss": 0.8014,
      "step": 328350
    },
    {
      "epoch": 3.4765695714081546,
      "grad_norm": 4.392165184020996,
      "learning_rate": 3.262412661443997e-05,
      "loss": 0.8081,
      "step": 328400
    },
    {
      "epoch": 3.477098893188158,
      "grad_norm": 4.159501552581787,
      "learning_rate": 3.262147999153081e-05,
      "loss": 0.8008,
      "step": 328450
    },
    {
      "epoch": 3.477628214968161,
      "grad_norm": 3.9046852588653564,
      "learning_rate": 3.261883336862164e-05,
      "loss": 0.8122,
      "step": 328500
    },
    {
      "epoch": 3.477628214968161,
      "eval_loss": 0.5717847943305969,
      "eval_runtime": 46.5705,
      "eval_samples_per_second": 3605.933,
      "eval_steps_per_second": 450.758,
      "step": 328500
    },
    {
      "epoch": 3.4781575367481645,
      "grad_norm": 4.490329265594482,
      "learning_rate": 3.2616186745712475e-05,
      "loss": 0.8099,
      "step": 328550
    },
    {
      "epoch": 3.478686858528168,
      "grad_norm": 4.597127437591553,
      "learning_rate": 3.26135401228033e-05,
      "loss": 0.799,
      "step": 328600
    },
    {
      "epoch": 3.479216180308171,
      "grad_norm": 3.752147912979126,
      "learning_rate": 3.2610893499894136e-05,
      "loss": 0.8082,
      "step": 328650
    },
    {
      "epoch": 3.4797455020881745,
      "grad_norm": 4.344825744628906,
      "learning_rate": 3.260824687698497e-05,
      "loss": 0.8055,
      "step": 328700
    },
    {
      "epoch": 3.4802748238681778,
      "grad_norm": 3.9574575424194336,
      "learning_rate": 3.2605600254075805e-05,
      "loss": 0.79,
      "step": 328750
    },
    {
      "epoch": 3.480804145648181,
      "grad_norm": 4.029931545257568,
      "learning_rate": 3.260295363116663e-05,
      "loss": 0.7993,
      "step": 328800
    },
    {
      "epoch": 3.4813334674281844,
      "grad_norm": 4.1992034912109375,
      "learning_rate": 3.2600307008257466e-05,
      "loss": 0.7958,
      "step": 328850
    },
    {
      "epoch": 3.4818627892081877,
      "grad_norm": 4.023080348968506,
      "learning_rate": 3.25976603853483e-05,
      "loss": 0.8144,
      "step": 328900
    },
    {
      "epoch": 3.482392110988191,
      "grad_norm": 3.847791910171509,
      "learning_rate": 3.259501376243913e-05,
      "loss": 0.7956,
      "step": 328950
    },
    {
      "epoch": 3.482921432768194,
      "grad_norm": 4.506291389465332,
      "learning_rate": 3.259236713952996e-05,
      "loss": 0.8025,
      "step": 329000
    },
    {
      "epoch": 3.482921432768194,
      "eval_loss": 0.5712424516677856,
      "eval_runtime": 46.7798,
      "eval_samples_per_second": 3589.794,
      "eval_steps_per_second": 448.74,
      "step": 329000
    },
    {
      "epoch": 3.4834507545481976,
      "grad_norm": 3.9365413188934326,
      "learning_rate": 3.258972051662079e-05,
      "loss": 0.8073,
      "step": 329050
    },
    {
      "epoch": 3.4839800763282005,
      "grad_norm": 4.163569927215576,
      "learning_rate": 3.258707389371163e-05,
      "loss": 0.804,
      "step": 329100
    },
    {
      "epoch": 3.484509398108204,
      "grad_norm": 4.183993339538574,
      "learning_rate": 3.258442727080246e-05,
      "loss": 0.8094,
      "step": 329150
    },
    {
      "epoch": 3.485038719888207,
      "grad_norm": 4.0492753982543945,
      "learning_rate": 3.258178064789329e-05,
      "loss": 0.8074,
      "step": 329200
    },
    {
      "epoch": 3.4855680416682104,
      "grad_norm": 4.068727016448975,
      "learning_rate": 3.257913402498412e-05,
      "loss": 0.7997,
      "step": 329250
    },
    {
      "epoch": 3.4860973634482137,
      "grad_norm": 3.9935407638549805,
      "learning_rate": 3.257648740207496e-05,
      "loss": 0.8037,
      "step": 329300
    },
    {
      "epoch": 3.486626685228217,
      "grad_norm": 4.476754665374756,
      "learning_rate": 3.257384077916579e-05,
      "loss": 0.8056,
      "step": 329350
    },
    {
      "epoch": 3.4871560070082204,
      "grad_norm": 4.517024517059326,
      "learning_rate": 3.257119415625662e-05,
      "loss": 0.7944,
      "step": 329400
    },
    {
      "epoch": 3.4876853287882237,
      "grad_norm": 4.106703281402588,
      "learning_rate": 3.256854753334745e-05,
      "loss": 0.822,
      "step": 329450
    },
    {
      "epoch": 3.488214650568227,
      "grad_norm": 4.1473212242126465,
      "learning_rate": 3.256590091043828e-05,
      "loss": 0.7971,
      "step": 329500
    },
    {
      "epoch": 3.488214650568227,
      "eval_loss": 0.5698776245117188,
      "eval_runtime": 46.6455,
      "eval_samples_per_second": 3600.133,
      "eval_steps_per_second": 450.033,
      "step": 329500
    },
    {
      "epoch": 3.4887439723482303,
      "grad_norm": 4.217249393463135,
      "learning_rate": 3.2563254287529116e-05,
      "loss": 0.7944,
      "step": 329550
    },
    {
      "epoch": 3.4892732941282336,
      "grad_norm": 4.348731994628906,
      "learning_rate": 3.2560607664619944e-05,
      "loss": 0.7868,
      "step": 329600
    },
    {
      "epoch": 3.489802615908237,
      "grad_norm": 4.228038787841797,
      "learning_rate": 3.255796104171078e-05,
      "loss": 0.7949,
      "step": 329650
    },
    {
      "epoch": 3.4903319376882402,
      "grad_norm": 4.459926128387451,
      "learning_rate": 3.255531441880161e-05,
      "loss": 0.8159,
      "step": 329700
    },
    {
      "epoch": 3.490861259468243,
      "grad_norm": 4.205484867095947,
      "learning_rate": 3.2552667795892446e-05,
      "loss": 0.8091,
      "step": 329750
    },
    {
      "epoch": 3.491390581248247,
      "grad_norm": 3.879625082015991,
      "learning_rate": 3.255002117298327e-05,
      "loss": 0.8084,
      "step": 329800
    },
    {
      "epoch": 3.4919199030282497,
      "grad_norm": 4.146195888519287,
      "learning_rate": 3.254737455007411e-05,
      "loss": 0.8021,
      "step": 329850
    },
    {
      "epoch": 3.492449224808253,
      "grad_norm": 3.899806261062622,
      "learning_rate": 3.254478085962312e-05,
      "loss": 0.786,
      "step": 329900
    },
    {
      "epoch": 3.4929785465882563,
      "grad_norm": 4.3499932289123535,
      "learning_rate": 3.2542134236713956e-05,
      "loss": 0.8142,
      "step": 329950
    },
    {
      "epoch": 3.4935078683682597,
      "grad_norm": 3.7229087352752686,
      "learning_rate": 3.2539487613804784e-05,
      "loss": 0.8022,
      "step": 330000
    },
    {
      "epoch": 3.4935078683682597,
      "eval_loss": 0.570282518863678,
      "eval_runtime": 46.6401,
      "eval_samples_per_second": 3600.547,
      "eval_steps_per_second": 450.084,
      "step": 330000
    },
    {
      "epoch": 3.494037190148263,
      "grad_norm": 4.15819787979126,
      "learning_rate": 3.253684099089562e-05,
      "loss": 0.7977,
      "step": 330050
    },
    {
      "epoch": 3.4945665119282663,
      "grad_norm": 3.5525424480438232,
      "learning_rate": 3.253419436798645e-05,
      "loss": 0.8131,
      "step": 330100
    },
    {
      "epoch": 3.4950958337082696,
      "grad_norm": 4.324398517608643,
      "learning_rate": 3.2531547745077286e-05,
      "loss": 0.8033,
      "step": 330150
    },
    {
      "epoch": 3.495625155488273,
      "grad_norm": 4.549274444580078,
      "learning_rate": 3.252890112216811e-05,
      "loss": 0.7901,
      "step": 330200
    },
    {
      "epoch": 3.496154477268276,
      "grad_norm": 4.066527843475342,
      "learning_rate": 3.252625449925895e-05,
      "loss": 0.8001,
      "step": 330250
    },
    {
      "epoch": 3.4966837990482795,
      "grad_norm": 4.179359436035156,
      "learning_rate": 3.252360787634978e-05,
      "loss": 0.7868,
      "step": 330300
    },
    {
      "epoch": 3.497213120828283,
      "grad_norm": 4.341211318969727,
      "learning_rate": 3.2520961253440615e-05,
      "loss": 0.8053,
      "step": 330350
    },
    {
      "epoch": 3.497742442608286,
      "grad_norm": 4.058917999267578,
      "learning_rate": 3.251831463053144e-05,
      "loss": 0.7865,
      "step": 330400
    },
    {
      "epoch": 3.4982717643882895,
      "grad_norm": 4.316774368286133,
      "learning_rate": 3.251566800762228e-05,
      "loss": 0.8102,
      "step": 330450
    },
    {
      "epoch": 3.4988010861682923,
      "grad_norm": 4.079437732696533,
      "learning_rate": 3.2513021384713104e-05,
      "loss": 0.8038,
      "step": 330500
    },
    {
      "epoch": 3.4988010861682923,
      "eval_loss": 0.569381058216095,
      "eval_runtime": 46.7376,
      "eval_samples_per_second": 3593.038,
      "eval_steps_per_second": 449.146,
      "step": 330500
    },
    {
      "epoch": 3.499330407948296,
      "grad_norm": 4.054575443267822,
      "learning_rate": 3.251037476180394e-05,
      "loss": 0.8007,
      "step": 330550
    },
    {
      "epoch": 3.499859729728299,
      "grad_norm": 4.262081146240234,
      "learning_rate": 3.250772813889477e-05,
      "loss": 0.8103,
      "step": 330600
    },
    {
      "epoch": 3.5003890515083023,
      "grad_norm": 4.061818599700928,
      "learning_rate": 3.25050815159856e-05,
      "loss": 0.8084,
      "step": 330650
    },
    {
      "epoch": 3.5009183732883056,
      "grad_norm": 4.1253156661987305,
      "learning_rate": 3.2502434893076434e-05,
      "loss": 0.8034,
      "step": 330700
    },
    {
      "epoch": 3.501447695068309,
      "grad_norm": 3.8844873905181885,
      "learning_rate": 3.249978827016727e-05,
      "loss": 0.7984,
      "step": 330750
    },
    {
      "epoch": 3.501977016848312,
      "grad_norm": 4.097464561462402,
      "learning_rate": 3.24971416472581e-05,
      "loss": 0.8012,
      "step": 330800
    },
    {
      "epoch": 3.5025063386283155,
      "grad_norm": 4.018738269805908,
      "learning_rate": 3.249449502434893e-05,
      "loss": 0.7964,
      "step": 330850
    },
    {
      "epoch": 3.503035660408319,
      "grad_norm": 3.9647555351257324,
      "learning_rate": 3.2491848401439763e-05,
      "loss": 0.7955,
      "step": 330900
    },
    {
      "epoch": 3.503564982188322,
      "grad_norm": 4.013843536376953,
      "learning_rate": 3.24892017785306e-05,
      "loss": 0.7841,
      "step": 330950
    },
    {
      "epoch": 3.5040943039683254,
      "grad_norm": 3.8681576251983643,
      "learning_rate": 3.248655515562143e-05,
      "loss": 0.788,
      "step": 331000
    },
    {
      "epoch": 3.5040943039683254,
      "eval_loss": 0.5697734951972961,
      "eval_runtime": 46.6024,
      "eval_samples_per_second": 3603.46,
      "eval_steps_per_second": 450.449,
      "step": 331000
    },
    {
      "epoch": 3.5046236257483288,
      "grad_norm": 3.7029471397399902,
      "learning_rate": 3.248390853271226e-05,
      "loss": 0.7874,
      "step": 331050
    },
    {
      "epoch": 3.505152947528332,
      "grad_norm": 4.023440361022949,
      "learning_rate": 3.248126190980309e-05,
      "loss": 0.8067,
      "step": 331100
    },
    {
      "epoch": 3.5056822693083354,
      "grad_norm": 4.011859893798828,
      "learning_rate": 3.247861528689393e-05,
      "loss": 0.7921,
      "step": 331150
    },
    {
      "epoch": 3.5062115910883387,
      "grad_norm": 4.428633689880371,
      "learning_rate": 3.2475968663984755e-05,
      "loss": 0.7883,
      "step": 331200
    },
    {
      "epoch": 3.5067409128683416,
      "grad_norm": 3.8842108249664307,
      "learning_rate": 3.247332204107559e-05,
      "loss": 0.8072,
      "step": 331250
    },
    {
      "epoch": 3.5072702346483453,
      "grad_norm": 4.009946823120117,
      "learning_rate": 3.2470675418166416e-05,
      "loss": 0.8109,
      "step": 331300
    },
    {
      "epoch": 3.507799556428348,
      "grad_norm": 4.0100178718566895,
      "learning_rate": 3.246802879525726e-05,
      "loss": 0.8044,
      "step": 331350
    },
    {
      "epoch": 3.5083288782083515,
      "grad_norm": 3.889228582382202,
      "learning_rate": 3.2465382172348084e-05,
      "loss": 0.7824,
      "step": 331400
    },
    {
      "epoch": 3.508858199988355,
      "grad_norm": 3.9881207942962646,
      "learning_rate": 3.246273554943892e-05,
      "loss": 0.7925,
      "step": 331450
    },
    {
      "epoch": 3.509387521768358,
      "grad_norm": 3.8101091384887695,
      "learning_rate": 3.2460088926529746e-05,
      "loss": 0.8061,
      "step": 331500
    },
    {
      "epoch": 3.509387521768358,
      "eval_loss": 0.5700166821479797,
      "eval_runtime": 46.5763,
      "eval_samples_per_second": 3605.48,
      "eval_steps_per_second": 450.701,
      "step": 331500
    },
    {
      "epoch": 3.5099168435483614,
      "grad_norm": 3.9642651081085205,
      "learning_rate": 3.2457442303620586e-05,
      "loss": 0.8169,
      "step": 331550
    },
    {
      "epoch": 3.5104461653283647,
      "grad_norm": 4.250743389129639,
      "learning_rate": 3.2454848613169594e-05,
      "loss": 0.7997,
      "step": 331600
    },
    {
      "epoch": 3.510975487108368,
      "grad_norm": 4.405304908752441,
      "learning_rate": 3.245220199026043e-05,
      "loss": 0.7962,
      "step": 331650
    },
    {
      "epoch": 3.5115048088883714,
      "grad_norm": 3.966728925704956,
      "learning_rate": 3.2449555367351256e-05,
      "loss": 0.8106,
      "step": 331700
    },
    {
      "epoch": 3.5120341306683747,
      "grad_norm": 4.05925989151001,
      "learning_rate": 3.24469087444421e-05,
      "loss": 0.8021,
      "step": 331750
    },
    {
      "epoch": 3.512563452448378,
      "grad_norm": 4.256124496459961,
      "learning_rate": 3.2444262121532924e-05,
      "loss": 0.7907,
      "step": 331800
    },
    {
      "epoch": 3.5130927742283813,
      "grad_norm": 3.7134292125701904,
      "learning_rate": 3.244161549862376e-05,
      "loss": 0.8063,
      "step": 331850
    },
    {
      "epoch": 3.5136220960083846,
      "grad_norm": 4.13431978225708,
      "learning_rate": 3.2438968875714585e-05,
      "loss": 0.7906,
      "step": 331900
    },
    {
      "epoch": 3.514151417788388,
      "grad_norm": 3.8373031616210938,
      "learning_rate": 3.2436322252805426e-05,
      "loss": 0.8073,
      "step": 331950
    },
    {
      "epoch": 3.5146807395683908,
      "grad_norm": 4.064690113067627,
      "learning_rate": 3.2433675629896254e-05,
      "loss": 0.7976,
      "step": 332000
    },
    {
      "epoch": 3.5146807395683908,
      "eval_loss": 0.5689795613288879,
      "eval_runtime": 46.5408,
      "eval_samples_per_second": 3608.231,
      "eval_steps_per_second": 451.045,
      "step": 332000
    },
    {
      "epoch": 3.5152100613483945,
      "grad_norm": 3.9274590015411377,
      "learning_rate": 3.243102900698709e-05,
      "loss": 0.8027,
      "step": 332050
    },
    {
      "epoch": 3.5157393831283974,
      "grad_norm": 4.164802074432373,
      "learning_rate": 3.2428382384077915e-05,
      "loss": 0.79,
      "step": 332100
    },
    {
      "epoch": 3.5162687049084007,
      "grad_norm": 4.155160903930664,
      "learning_rate": 3.242573576116875e-05,
      "loss": 0.8019,
      "step": 332150
    },
    {
      "epoch": 3.516798026688404,
      "grad_norm": 4.178018569946289,
      "learning_rate": 3.242308913825958e-05,
      "loss": 0.8064,
      "step": 332200
    },
    {
      "epoch": 3.5173273484684073,
      "grad_norm": 4.0744218826293945,
      "learning_rate": 3.242044251535041e-05,
      "loss": 0.7877,
      "step": 332250
    },
    {
      "epoch": 3.5178566702484106,
      "grad_norm": 3.7810449600219727,
      "learning_rate": 3.2417795892441245e-05,
      "loss": 0.8094,
      "step": 332300
    },
    {
      "epoch": 3.518385992028414,
      "grad_norm": 3.981980085372925,
      "learning_rate": 3.241514926953208e-05,
      "loss": 0.7912,
      "step": 332350
    },
    {
      "epoch": 3.5189153138084173,
      "grad_norm": 3.9890174865722656,
      "learning_rate": 3.241250264662291e-05,
      "loss": 0.7986,
      "step": 332400
    },
    {
      "epoch": 3.5194446355884206,
      "grad_norm": 3.865630626678467,
      "learning_rate": 3.240985602371374e-05,
      "loss": 0.7976,
      "step": 332450
    },
    {
      "epoch": 3.519973957368424,
      "grad_norm": 4.158064842224121,
      "learning_rate": 3.2407209400804574e-05,
      "loss": 0.8061,
      "step": 332500
    },
    {
      "epoch": 3.519973957368424,
      "eval_loss": 0.5699983239173889,
      "eval_runtime": 46.6511,
      "eval_samples_per_second": 3599.703,
      "eval_steps_per_second": 449.979,
      "step": 332500
    },
    {
      "epoch": 3.520503279148427,
      "grad_norm": 4.149741172790527,
      "learning_rate": 3.240456277789541e-05,
      "loss": 0.7993,
      "step": 332550
    },
    {
      "epoch": 3.5210326009284305,
      "grad_norm": 4.261981010437012,
      "learning_rate": 3.240191615498624e-05,
      "loss": 0.7985,
      "step": 332600
    },
    {
      "epoch": 3.521561922708434,
      "grad_norm": 4.475959300994873,
      "learning_rate": 3.239926953207707e-05,
      "loss": 0.8036,
      "step": 332650
    },
    {
      "epoch": 3.522091244488437,
      "grad_norm": 4.630225658416748,
      "learning_rate": 3.2396622909167904e-05,
      "loss": 0.7934,
      "step": 332700
    },
    {
      "epoch": 3.52262056626844,
      "grad_norm": 4.375130653381348,
      "learning_rate": 3.239397628625874e-05,
      "loss": 0.7752,
      "step": 332750
    },
    {
      "epoch": 3.5231498880484438,
      "grad_norm": 4.068220615386963,
      "learning_rate": 3.2391329663349565e-05,
      "loss": 0.7873,
      "step": 332800
    },
    {
      "epoch": 3.5236792098284466,
      "grad_norm": 3.5614941120147705,
      "learning_rate": 3.23886830404404e-05,
      "loss": 0.778,
      "step": 332850
    },
    {
      "epoch": 3.52420853160845,
      "grad_norm": 3.8804128170013428,
      "learning_rate": 3.238603641753123e-05,
      "loss": 0.8007,
      "step": 332900
    },
    {
      "epoch": 3.5247378533884532,
      "grad_norm": 4.426466941833496,
      "learning_rate": 3.238338979462207e-05,
      "loss": 0.8045,
      "step": 332950
    },
    {
      "epoch": 3.5252671751684566,
      "grad_norm": 3.830587863922119,
      "learning_rate": 3.2380743171712895e-05,
      "loss": 0.8032,
      "step": 333000
    },
    {
      "epoch": 3.5252671751684566,
      "eval_loss": 0.5678212642669678,
      "eval_runtime": 46.5694,
      "eval_samples_per_second": 3606.016,
      "eval_steps_per_second": 450.768,
      "step": 333000
    },
    {
      "epoch": 3.52579649694846,
      "grad_norm": 3.78399920463562,
      "learning_rate": 3.237809654880373e-05,
      "loss": 0.7994,
      "step": 333050
    },
    {
      "epoch": 3.526325818728463,
      "grad_norm": 3.970184087753296,
      "learning_rate": 3.2375449925894556e-05,
      "loss": 0.7942,
      "step": 333100
    },
    {
      "epoch": 3.5268551405084665,
      "grad_norm": 4.137270927429199,
      "learning_rate": 3.23728033029854e-05,
      "loss": 0.7928,
      "step": 333150
    },
    {
      "epoch": 3.52738446228847,
      "grad_norm": 4.1166205406188965,
      "learning_rate": 3.2370156680076225e-05,
      "loss": 0.8081,
      "step": 333200
    },
    {
      "epoch": 3.527913784068473,
      "grad_norm": 3.9547293186187744,
      "learning_rate": 3.236751005716706e-05,
      "loss": 0.7947,
      "step": 333250
    },
    {
      "epoch": 3.5284431058484764,
      "grad_norm": 3.883512496948242,
      "learning_rate": 3.2364863434257886e-05,
      "loss": 0.784,
      "step": 333300
    },
    {
      "epoch": 3.5289724276284797,
      "grad_norm": 4.220179557800293,
      "learning_rate": 3.236221681134872e-05,
      "loss": 0.813,
      "step": 333350
    },
    {
      "epoch": 3.529501749408483,
      "grad_norm": 3.998910903930664,
      "learning_rate": 3.2359570188439554e-05,
      "loss": 0.7743,
      "step": 333400
    },
    {
      "epoch": 3.5300310711884864,
      "grad_norm": 4.05515718460083,
      "learning_rate": 3.235692356553038e-05,
      "loss": 0.8031,
      "step": 333450
    },
    {
      "epoch": 3.5305603929684892,
      "grad_norm": 4.285801410675049,
      "learning_rate": 3.2354276942621216e-05,
      "loss": 0.7933,
      "step": 333500
    },
    {
      "epoch": 3.5305603929684892,
      "eval_loss": 0.5672345161437988,
      "eval_runtime": 46.6089,
      "eval_samples_per_second": 3602.96,
      "eval_steps_per_second": 450.386,
      "step": 333500
    },
    {
      "epoch": 3.531089714748493,
      "grad_norm": 3.7566030025482178,
      "learning_rate": 3.235163031971205e-05,
      "loss": 0.8108,
      "step": 333550
    },
    {
      "epoch": 3.531619036528496,
      "grad_norm": 4.068524360656738,
      "learning_rate": 3.2348983696802884e-05,
      "loss": 0.8135,
      "step": 333600
    },
    {
      "epoch": 3.532148358308499,
      "grad_norm": 4.141519546508789,
      "learning_rate": 3.234633707389371e-05,
      "loss": 0.7839,
      "step": 333650
    },
    {
      "epoch": 3.5326776800885025,
      "grad_norm": 4.52708625793457,
      "learning_rate": 3.2343690450984545e-05,
      "loss": 0.7934,
      "step": 333700
    },
    {
      "epoch": 3.533207001868506,
      "grad_norm": 3.984118700027466,
      "learning_rate": 3.234104382807538e-05,
      "loss": 0.7959,
      "step": 333750
    },
    {
      "epoch": 3.533736323648509,
      "grad_norm": 3.689342975616455,
      "learning_rate": 3.233839720516621e-05,
      "loss": 0.7979,
      "step": 333800
    },
    {
      "epoch": 3.5342656454285124,
      "grad_norm": 4.231034755706787,
      "learning_rate": 3.233575058225704e-05,
      "loss": 0.7953,
      "step": 333850
    },
    {
      "epoch": 3.5347949672085157,
      "grad_norm": 4.251152515411377,
      "learning_rate": 3.233310395934787e-05,
      "loss": 0.7839,
      "step": 333900
    },
    {
      "epoch": 3.535324288988519,
      "grad_norm": 4.454198360443115,
      "learning_rate": 3.233045733643871e-05,
      "loss": 0.7965,
      "step": 333950
    },
    {
      "epoch": 3.5358536107685223,
      "grad_norm": 4.644101142883301,
      "learning_rate": 3.2327810713529536e-05,
      "loss": 0.8139,
      "step": 334000
    },
    {
      "epoch": 3.5358536107685223,
      "eval_loss": 0.5663886666297913,
      "eval_runtime": 46.6915,
      "eval_samples_per_second": 3596.585,
      "eval_steps_per_second": 449.589,
      "step": 334000
    },
    {
      "epoch": 3.5363829325485256,
      "grad_norm": 4.214841842651367,
      "learning_rate": 3.232516409062037e-05,
      "loss": 0.8039,
      "step": 334050
    },
    {
      "epoch": 3.536912254328529,
      "grad_norm": 4.674973964691162,
      "learning_rate": 3.23225174677112e-05,
      "loss": 0.8049,
      "step": 334100
    },
    {
      "epoch": 3.5374415761085323,
      "grad_norm": 4.35054349899292,
      "learning_rate": 3.231987084480204e-05,
      "loss": 0.8073,
      "step": 334150
    },
    {
      "epoch": 3.5379708978885356,
      "grad_norm": 3.9365313053131104,
      "learning_rate": 3.2317224221892866e-05,
      "loss": 0.7873,
      "step": 334200
    },
    {
      "epoch": 3.5385002196685384,
      "grad_norm": 3.8944990634918213,
      "learning_rate": 3.23145775989837e-05,
      "loss": 0.8145,
      "step": 334250
    },
    {
      "epoch": 3.539029541448542,
      "grad_norm": 3.8407351970672607,
      "learning_rate": 3.231193097607453e-05,
      "loss": 0.8011,
      "step": 334300
    },
    {
      "epoch": 3.539558863228545,
      "grad_norm": 4.088288307189941,
      "learning_rate": 3.230928435316536e-05,
      "loss": 0.7907,
      "step": 334350
    },
    {
      "epoch": 3.5400881850085484,
      "grad_norm": 3.977688789367676,
      "learning_rate": 3.2306637730256196e-05,
      "loss": 0.8042,
      "step": 334400
    },
    {
      "epoch": 3.5406175067885517,
      "grad_norm": 4.107665538787842,
      "learning_rate": 3.230399110734702e-05,
      "loss": 0.7831,
      "step": 334450
    },
    {
      "epoch": 3.541146828568555,
      "grad_norm": 4.116556167602539,
      "learning_rate": 3.230134448443786e-05,
      "loss": 0.775,
      "step": 334500
    },
    {
      "epoch": 3.541146828568555,
      "eval_loss": 0.5642073750495911,
      "eval_runtime": 46.8751,
      "eval_samples_per_second": 3582.499,
      "eval_steps_per_second": 447.828,
      "step": 334500
    },
    {
      "epoch": 3.5416761503485583,
      "grad_norm": 3.9269914627075195,
      "learning_rate": 3.229869786152869e-05,
      "loss": 0.8001,
      "step": 334550
    },
    {
      "epoch": 3.5422054721285616,
      "grad_norm": 3.9194629192352295,
      "learning_rate": 3.2296051238619525e-05,
      "loss": 0.8075,
      "step": 334600
    },
    {
      "epoch": 3.542734793908565,
      "grad_norm": 4.080418109893799,
      "learning_rate": 3.229340461571035e-05,
      "loss": 0.8007,
      "step": 334650
    },
    {
      "epoch": 3.5432641156885682,
      "grad_norm": 3.942068099975586,
      "learning_rate": 3.2290757992801187e-05,
      "loss": 0.7971,
      "step": 334700
    },
    {
      "epoch": 3.5437934374685716,
      "grad_norm": 4.037552356719971,
      "learning_rate": 3.228811136989202e-05,
      "loss": 0.8009,
      "step": 334750
    },
    {
      "epoch": 3.544322759248575,
      "grad_norm": 4.271718978881836,
      "learning_rate": 3.2285464746982855e-05,
      "loss": 0.7943,
      "step": 334800
    },
    {
      "epoch": 3.544852081028578,
      "grad_norm": 3.739230155944824,
      "learning_rate": 3.228281812407368e-05,
      "loss": 0.7983,
      "step": 334850
    },
    {
      "epoch": 3.5453814028085815,
      "grad_norm": 4.131651401519775,
      "learning_rate": 3.2280171501164516e-05,
      "loss": 0.7952,
      "step": 334900
    },
    {
      "epoch": 3.545910724588585,
      "grad_norm": 4.025315284729004,
      "learning_rate": 3.227757781071353e-05,
      "loss": 0.8079,
      "step": 334950
    },
    {
      "epoch": 3.5464400463685877,
      "grad_norm": 4.004558563232422,
      "learning_rate": 3.2274931187804365e-05,
      "loss": 0.804,
      "step": 335000
    },
    {
      "epoch": 3.5464400463685877,
      "eval_loss": 0.566618025302887,
      "eval_runtime": 46.7562,
      "eval_samples_per_second": 3591.607,
      "eval_steps_per_second": 448.967,
      "step": 335000
    },
    {
      "epoch": 3.5469693681485914,
      "grad_norm": 3.867582082748413,
      "learning_rate": 3.227228456489519e-05,
      "loss": 0.8035,
      "step": 335050
    },
    {
      "epoch": 3.5474986899285943,
      "grad_norm": 4.179934978485107,
      "learning_rate": 3.2269637941986026e-05,
      "loss": 0.7823,
      "step": 335100
    },
    {
      "epoch": 3.548028011708598,
      "grad_norm": 4.150599479675293,
      "learning_rate": 3.226699131907686e-05,
      "loss": 0.7989,
      "step": 335150
    },
    {
      "epoch": 3.548557333488601,
      "grad_norm": 3.923035144805908,
      "learning_rate": 3.2264344696167695e-05,
      "loss": 0.8046,
      "step": 335200
    },
    {
      "epoch": 3.5490866552686042,
      "grad_norm": 4.0978803634643555,
      "learning_rate": 3.226169807325852e-05,
      "loss": 0.8159,
      "step": 335250
    },
    {
      "epoch": 3.5496159770486075,
      "grad_norm": 3.903416872024536,
      "learning_rate": 3.2259051450349356e-05,
      "loss": 0.7927,
      "step": 335300
    },
    {
      "epoch": 3.550145298828611,
      "grad_norm": 4.305172443389893,
      "learning_rate": 3.225640482744019e-05,
      "loss": 0.7952,
      "step": 335350
    },
    {
      "epoch": 3.550674620608614,
      "grad_norm": 4.279330253601074,
      "learning_rate": 3.225375820453102e-05,
      "loss": 0.8024,
      "step": 335400
    },
    {
      "epoch": 3.5512039423886175,
      "grad_norm": 4.043092250823975,
      "learning_rate": 3.225111158162185e-05,
      "loss": 0.8138,
      "step": 335450
    },
    {
      "epoch": 3.551733264168621,
      "grad_norm": 3.7793846130371094,
      "learning_rate": 3.224846495871268e-05,
      "loss": 0.7986,
      "step": 335500
    },
    {
      "epoch": 3.551733264168621,
      "eval_loss": 0.565802276134491,
      "eval_runtime": 46.5751,
      "eval_samples_per_second": 3605.576,
      "eval_steps_per_second": 450.713,
      "step": 335500
    },
    {
      "epoch": 3.552262585948624,
      "grad_norm": 4.13484525680542,
      "learning_rate": 3.224581833580352e-05,
      "loss": 0.8018,
      "step": 335550
    },
    {
      "epoch": 3.5527919077286274,
      "grad_norm": 4.3306474685668945,
      "learning_rate": 3.224317171289435e-05,
      "loss": 0.8067,
      "step": 335600
    },
    {
      "epoch": 3.5533212295086307,
      "grad_norm": 4.139924049377441,
      "learning_rate": 3.224052508998518e-05,
      "loss": 0.7858,
      "step": 335650
    },
    {
      "epoch": 3.553850551288634,
      "grad_norm": 4.078094482421875,
      "learning_rate": 3.223787846707601e-05,
      "loss": 0.8057,
      "step": 335700
    },
    {
      "epoch": 3.554379873068637,
      "grad_norm": 3.972785711288452,
      "learning_rate": 3.223523184416685e-05,
      "loss": 0.8109,
      "step": 335750
    },
    {
      "epoch": 3.5549091948486407,
      "grad_norm": 3.755950689315796,
      "learning_rate": 3.223258522125768e-05,
      "loss": 0.7988,
      "step": 335800
    },
    {
      "epoch": 3.5554385166286435,
      "grad_norm": 3.8683810234069824,
      "learning_rate": 3.222993859834851e-05,
      "loss": 0.7822,
      "step": 335850
    },
    {
      "epoch": 3.5559678384086473,
      "grad_norm": 4.246728420257568,
      "learning_rate": 3.222729197543934e-05,
      "loss": 0.7889,
      "step": 335900
    },
    {
      "epoch": 3.55649716018865,
      "grad_norm": 3.947697877883911,
      "learning_rate": 3.222464535253017e-05,
      "loss": 0.7878,
      "step": 335950
    },
    {
      "epoch": 3.5570264819686535,
      "grad_norm": 4.22109317779541,
      "learning_rate": 3.2221998729621006e-05,
      "loss": 0.7833,
      "step": 336000
    },
    {
      "epoch": 3.5570264819686535,
      "eval_loss": 0.5646386742591858,
      "eval_runtime": 46.616,
      "eval_samples_per_second": 3602.41,
      "eval_steps_per_second": 450.317,
      "step": 336000
    },
    {
      "epoch": 3.5575558037486568,
      "grad_norm": 4.099803924560547,
      "learning_rate": 3.2219352106711834e-05,
      "loss": 0.7918,
      "step": 336050
    },
    {
      "epoch": 3.55808512552866,
      "grad_norm": 4.3967204093933105,
      "learning_rate": 3.221670548380267e-05,
      "loss": 0.7991,
      "step": 336100
    },
    {
      "epoch": 3.5586144473086634,
      "grad_norm": 4.443371295928955,
      "learning_rate": 3.22140588608935e-05,
      "loss": 0.8094,
      "step": 336150
    },
    {
      "epoch": 3.5591437690886667,
      "grad_norm": 4.190793514251709,
      "learning_rate": 3.2211412237984336e-05,
      "loss": 0.7907,
      "step": 336200
    },
    {
      "epoch": 3.55967309086867,
      "grad_norm": 3.9210565090179443,
      "learning_rate": 3.220876561507516e-05,
      "loss": 0.8045,
      "step": 336250
    },
    {
      "epoch": 3.5602024126486733,
      "grad_norm": 4.342054843902588,
      "learning_rate": 3.2206118992166e-05,
      "loss": 0.801,
      "step": 336300
    },
    {
      "epoch": 3.5607317344286766,
      "grad_norm": 3.883983850479126,
      "learning_rate": 3.220347236925683e-05,
      "loss": 0.7906,
      "step": 336350
    },
    {
      "epoch": 3.56126105620868,
      "grad_norm": 3.9800422191619873,
      "learning_rate": 3.2200825746347666e-05,
      "loss": 0.7828,
      "step": 336400
    },
    {
      "epoch": 3.5617903779886833,
      "grad_norm": 3.993039131164551,
      "learning_rate": 3.219817912343849e-05,
      "loss": 0.7967,
      "step": 336450
    },
    {
      "epoch": 3.562319699768686,
      "grad_norm": 4.058017730712891,
      "learning_rate": 3.219553250052933e-05,
      "loss": 0.798,
      "step": 336500
    },
    {
      "epoch": 3.562319699768686,
      "eval_loss": 0.5622853636741638,
      "eval_runtime": 46.5279,
      "eval_samples_per_second": 3609.232,
      "eval_steps_per_second": 451.17,
      "step": 336500
    },
    {
      "epoch": 3.56284902154869,
      "grad_norm": 3.7671058177948,
      "learning_rate": 3.219288587762016e-05,
      "loss": 0.7914,
      "step": 336550
    },
    {
      "epoch": 3.5633783433286927,
      "grad_norm": 4.025847434997559,
      "learning_rate": 3.219023925471099e-05,
      "loss": 0.797,
      "step": 336600
    },
    {
      "epoch": 3.5639076651086965,
      "grad_norm": 3.740992307662964,
      "learning_rate": 3.218759263180182e-05,
      "loss": 0.793,
      "step": 336650
    },
    {
      "epoch": 3.5644369868886994,
      "grad_norm": 4.250072956085205,
      "learning_rate": 3.218494600889265e-05,
      "loss": 0.8027,
      "step": 336700
    },
    {
      "epoch": 3.5649663086687027,
      "grad_norm": 4.55207633972168,
      "learning_rate": 3.218229938598349e-05,
      "loss": 0.7979,
      "step": 336750
    },
    {
      "epoch": 3.565495630448706,
      "grad_norm": 4.046260833740234,
      "learning_rate": 3.217965276307432e-05,
      "loss": 0.811,
      "step": 336800
    },
    {
      "epoch": 3.5660249522287093,
      "grad_norm": 4.055725574493408,
      "learning_rate": 3.217700614016515e-05,
      "loss": 0.816,
      "step": 336850
    },
    {
      "epoch": 3.5665542740087126,
      "grad_norm": 3.88665771484375,
      "learning_rate": 3.217435951725598e-05,
      "loss": 0.793,
      "step": 336900
    },
    {
      "epoch": 3.567083595788716,
      "grad_norm": 4.087185382843018,
      "learning_rate": 3.217171289434682e-05,
      "loss": 0.7882,
      "step": 336950
    },
    {
      "epoch": 3.5676129175687192,
      "grad_norm": 3.8080451488494873,
      "learning_rate": 3.216906627143765e-05,
      "loss": 0.7946,
      "step": 337000
    },
    {
      "epoch": 3.5676129175687192,
      "eval_loss": 0.5659535527229309,
      "eval_runtime": 46.5276,
      "eval_samples_per_second": 3609.253,
      "eval_steps_per_second": 451.173,
      "step": 337000
    },
    {
      "epoch": 3.5681422393487225,
      "grad_norm": 4.314974308013916,
      "learning_rate": 3.216641964852848e-05,
      "loss": 0.7894,
      "step": 337050
    },
    {
      "epoch": 3.568671561128726,
      "grad_norm": 4.053499221801758,
      "learning_rate": 3.216377302561931e-05,
      "loss": 0.7935,
      "step": 337100
    },
    {
      "epoch": 3.569200882908729,
      "grad_norm": 3.7223222255706787,
      "learning_rate": 3.216112640271014e-05,
      "loss": 0.7927,
      "step": 337150
    },
    {
      "epoch": 3.5697302046887325,
      "grad_norm": 4.369375705718994,
      "learning_rate": 3.215847977980098e-05,
      "loss": 0.8,
      "step": 337200
    },
    {
      "epoch": 3.5702595264687353,
      "grad_norm": 3.884611129760742,
      "learning_rate": 3.2155833156891805e-05,
      "loss": 0.7992,
      "step": 337250
    },
    {
      "epoch": 3.570788848248739,
      "grad_norm": 4.2923994064331055,
      "learning_rate": 3.215318653398264e-05,
      "loss": 0.7909,
      "step": 337300
    },
    {
      "epoch": 3.571318170028742,
      "grad_norm": 3.8916513919830322,
      "learning_rate": 3.215053991107347e-05,
      "loss": 0.7976,
      "step": 337350
    },
    {
      "epoch": 3.5718474918087457,
      "grad_norm": 3.855952739715576,
      "learning_rate": 3.214789328816431e-05,
      "loss": 0.7836,
      "step": 337400
    },
    {
      "epoch": 3.5723768135887486,
      "grad_norm": 4.143858432769775,
      "learning_rate": 3.2145246665255134e-05,
      "loss": 0.7987,
      "step": 337450
    },
    {
      "epoch": 3.572906135368752,
      "grad_norm": 4.354339122772217,
      "learning_rate": 3.214260004234597e-05,
      "loss": 0.8062,
      "step": 337500
    },
    {
      "epoch": 3.572906135368752,
      "eval_loss": 0.563856840133667,
      "eval_runtime": 46.5658,
      "eval_samples_per_second": 3606.292,
      "eval_steps_per_second": 450.803,
      "step": 337500
    },
    {
      "epoch": 3.573435457148755,
      "grad_norm": 3.7824482917785645,
      "learning_rate": 3.21399534194368e-05,
      "loss": 0.7896,
      "step": 337550
    },
    {
      "epoch": 3.5739647789287585,
      "grad_norm": 4.284084320068359,
      "learning_rate": 3.213730679652763e-05,
      "loss": 0.8029,
      "step": 337600
    },
    {
      "epoch": 3.574494100708762,
      "grad_norm": 4.025671482086182,
      "learning_rate": 3.2134660173618464e-05,
      "loss": 0.7956,
      "step": 337650
    },
    {
      "epoch": 3.575023422488765,
      "grad_norm": 3.7893569469451904,
      "learning_rate": 3.213201355070929e-05,
      "loss": 0.7972,
      "step": 337700
    },
    {
      "epoch": 3.5755527442687685,
      "grad_norm": 4.2206926345825195,
      "learning_rate": 3.212936692780013e-05,
      "loss": 0.7927,
      "step": 337750
    },
    {
      "epoch": 3.5760820660487718,
      "grad_norm": 4.144475936889648,
      "learning_rate": 3.212672030489096e-05,
      "loss": 0.7958,
      "step": 337800
    },
    {
      "epoch": 3.576611387828775,
      "grad_norm": 4.290369510650635,
      "learning_rate": 3.2124126614439974e-05,
      "loss": 0.7928,
      "step": 337850
    },
    {
      "epoch": 3.5771407096087784,
      "grad_norm": 4.3231916427612305,
      "learning_rate": 3.212147999153081e-05,
      "loss": 0.7963,
      "step": 337900
    },
    {
      "epoch": 3.5776700313887817,
      "grad_norm": 3.7912566661834717,
      "learning_rate": 3.211883336862164e-05,
      "loss": 0.7878,
      "step": 337950
    },
    {
      "epoch": 3.5781993531687846,
      "grad_norm": 3.9029393196105957,
      "learning_rate": 3.2116186745712476e-05,
      "loss": 0.8013,
      "step": 338000
    },
    {
      "epoch": 3.5781993531687846,
      "eval_loss": 0.5652798414230347,
      "eval_runtime": 46.5487,
      "eval_samples_per_second": 3607.616,
      "eval_steps_per_second": 450.968,
      "step": 338000
    },
    {
      "epoch": 3.5787286749487883,
      "grad_norm": 4.10489559173584,
      "learning_rate": 3.2113540122803304e-05,
      "loss": 0.7889,
      "step": 338050
    },
    {
      "epoch": 3.579257996728791,
      "grad_norm": 3.7777066230773926,
      "learning_rate": 3.211089349989414e-05,
      "loss": 0.7809,
      "step": 338100
    },
    {
      "epoch": 3.579787318508795,
      "grad_norm": 4.242789268493652,
      "learning_rate": 3.210824687698497e-05,
      "loss": 0.7876,
      "step": 338150
    },
    {
      "epoch": 3.580316640288798,
      "grad_norm": 4.461092948913574,
      "learning_rate": 3.21056002540758e-05,
      "loss": 0.7997,
      "step": 338200
    },
    {
      "epoch": 3.580845962068801,
      "grad_norm": 4.328065872192383,
      "learning_rate": 3.210295363116663e-05,
      "loss": 0.8089,
      "step": 338250
    },
    {
      "epoch": 3.5813752838488044,
      "grad_norm": 3.9899446964263916,
      "learning_rate": 3.210030700825746e-05,
      "loss": 0.8041,
      "step": 338300
    },
    {
      "epoch": 3.5819046056288077,
      "grad_norm": 4.071066379547119,
      "learning_rate": 3.20976603853483e-05,
      "loss": 0.8016,
      "step": 338350
    },
    {
      "epoch": 3.582433927408811,
      "grad_norm": 3.74957537651062,
      "learning_rate": 3.209501376243913e-05,
      "loss": 0.8062,
      "step": 338400
    },
    {
      "epoch": 3.5829632491888144,
      "grad_norm": 3.820819616317749,
      "learning_rate": 3.209236713952996e-05,
      "loss": 0.8014,
      "step": 338450
    },
    {
      "epoch": 3.5834925709688177,
      "grad_norm": 3.602477550506592,
      "learning_rate": 3.208972051662079e-05,
      "loss": 0.7712,
      "step": 338500
    },
    {
      "epoch": 3.5834925709688177,
      "eval_loss": 0.560002326965332,
      "eval_runtime": 46.6114,
      "eval_samples_per_second": 3602.765,
      "eval_steps_per_second": 450.362,
      "step": 338500
    },
    {
      "epoch": 3.584021892748821,
      "grad_norm": 4.0015435218811035,
      "learning_rate": 3.2087073893711624e-05,
      "loss": 0.8,
      "step": 338550
    },
    {
      "epoch": 3.5845512145288243,
      "grad_norm": 4.4915971755981445,
      "learning_rate": 3.208442727080246e-05,
      "loss": 0.7941,
      "step": 338600
    },
    {
      "epoch": 3.5850805363088276,
      "grad_norm": 4.110957622528076,
      "learning_rate": 3.2081780647893286e-05,
      "loss": 0.7725,
      "step": 338650
    },
    {
      "epoch": 3.585609858088831,
      "grad_norm": 3.9182474613189697,
      "learning_rate": 3.207913402498412e-05,
      "loss": 0.7993,
      "step": 338700
    },
    {
      "epoch": 3.586139179868834,
      "grad_norm": 4.342498779296875,
      "learning_rate": 3.2076487402074954e-05,
      "loss": 0.7939,
      "step": 338750
    },
    {
      "epoch": 3.5866685016488375,
      "grad_norm": 4.008321762084961,
      "learning_rate": 3.207384077916579e-05,
      "loss": 0.7917,
      "step": 338800
    },
    {
      "epoch": 3.5871978234288404,
      "grad_norm": 4.405947685241699,
      "learning_rate": 3.2071194156256615e-05,
      "loss": 0.7972,
      "step": 338850
    },
    {
      "epoch": 3.587727145208844,
      "grad_norm": 4.254783630371094,
      "learning_rate": 3.206854753334745e-05,
      "loss": 0.7894,
      "step": 338900
    },
    {
      "epoch": 3.588256466988847,
      "grad_norm": 3.953181743621826,
      "learning_rate": 3.2065900910438284e-05,
      "loss": 0.7969,
      "step": 338950
    },
    {
      "epoch": 3.5887857887688503,
      "grad_norm": 4.139368057250977,
      "learning_rate": 3.206325428752912e-05,
      "loss": 0.7982,
      "step": 339000
    },
    {
      "epoch": 3.5887857887688503,
      "eval_loss": 0.5612450838088989,
      "eval_runtime": 46.7242,
      "eval_samples_per_second": 3594.072,
      "eval_steps_per_second": 449.275,
      "step": 339000
    },
    {
      "epoch": 3.5893151105488537,
      "grad_norm": 3.990443706512451,
      "learning_rate": 3.2060607664619945e-05,
      "loss": 0.784,
      "step": 339050
    },
    {
      "epoch": 3.589844432328857,
      "grad_norm": 3.7478086948394775,
      "learning_rate": 3.205796104171078e-05,
      "loss": 0.7922,
      "step": 339100
    },
    {
      "epoch": 3.5903737541088603,
      "grad_norm": 4.26847505569458,
      "learning_rate": 3.205531441880161e-05,
      "loss": 0.7931,
      "step": 339150
    },
    {
      "epoch": 3.5909030758888636,
      "grad_norm": 3.831881284713745,
      "learning_rate": 3.205266779589244e-05,
      "loss": 0.7831,
      "step": 339200
    },
    {
      "epoch": 3.591432397668867,
      "grad_norm": 4.256251811981201,
      "learning_rate": 3.2050021172983275e-05,
      "loss": 0.7982,
      "step": 339250
    },
    {
      "epoch": 3.59196171944887,
      "grad_norm": 3.5863969326019287,
      "learning_rate": 3.20473745500741e-05,
      "loss": 0.7947,
      "step": 339300
    },
    {
      "epoch": 3.5924910412288735,
      "grad_norm": 4.194197654724121,
      "learning_rate": 3.204472792716494e-05,
      "loss": 0.8006,
      "step": 339350
    },
    {
      "epoch": 3.593020363008877,
      "grad_norm": 3.975794792175293,
      "learning_rate": 3.204208130425577e-05,
      "loss": 0.7732,
      "step": 339400
    },
    {
      "epoch": 3.59354968478888,
      "grad_norm": 4.186200141906738,
      "learning_rate": 3.2039434681346604e-05,
      "loss": 0.7906,
      "step": 339450
    },
    {
      "epoch": 3.594079006568883,
      "grad_norm": 3.9986274242401123,
      "learning_rate": 3.203678805843743e-05,
      "loss": 0.7979,
      "step": 339500
    },
    {
      "epoch": 3.594079006568883,
      "eval_loss": 0.5619029998779297,
      "eval_runtime": 46.4976,
      "eval_samples_per_second": 3611.588,
      "eval_steps_per_second": 451.465,
      "step": 339500
    },
    {
      "epoch": 3.5946083283488868,
      "grad_norm": 4.299276828765869,
      "learning_rate": 3.203414143552827e-05,
      "loss": 0.7863,
      "step": 339550
    },
    {
      "epoch": 3.5951376501288896,
      "grad_norm": 4.039522171020508,
      "learning_rate": 3.20314948126191e-05,
      "loss": 0.7831,
      "step": 339600
    },
    {
      "epoch": 3.5956669719088934,
      "grad_norm": 4.08139705657959,
      "learning_rate": 3.2028848189709934e-05,
      "loss": 0.7958,
      "step": 339650
    },
    {
      "epoch": 3.5961962936888963,
      "grad_norm": 3.706395387649536,
      "learning_rate": 3.202620156680076e-05,
      "loss": 0.7986,
      "step": 339700
    },
    {
      "epoch": 3.5967256154688996,
      "grad_norm": 4.105184078216553,
      "learning_rate": 3.2023554943891595e-05,
      "loss": 0.7899,
      "step": 339750
    },
    {
      "epoch": 3.597254937248903,
      "grad_norm": 4.0435919761657715,
      "learning_rate": 3.202090832098243e-05,
      "loss": 0.7994,
      "step": 339800
    },
    {
      "epoch": 3.597784259028906,
      "grad_norm": 4.0480170249938965,
      "learning_rate": 3.201826169807326e-05,
      "loss": 0.809,
      "step": 339850
    },
    {
      "epoch": 3.5983135808089095,
      "grad_norm": 4.318488121032715,
      "learning_rate": 3.201561507516409e-05,
      "loss": 0.7773,
      "step": 339900
    },
    {
      "epoch": 3.598842902588913,
      "grad_norm": 3.951247453689575,
      "learning_rate": 3.2012968452254925e-05,
      "loss": 0.804,
      "step": 339950
    },
    {
      "epoch": 3.599372224368916,
      "grad_norm": 3.9818637371063232,
      "learning_rate": 3.201032182934576e-05,
      "loss": 0.7947,
      "step": 340000
    },
    {
      "epoch": 3.599372224368916,
      "eval_loss": 0.5608170628547668,
      "eval_runtime": 46.5793,
      "eval_samples_per_second": 3605.25,
      "eval_steps_per_second": 450.672,
      "step": 340000
    },
    {
      "epoch": 3.5999015461489194,
      "grad_norm": 4.702138423919678,
      "learning_rate": 3.2007675206436586e-05,
      "loss": 0.7918,
      "step": 340050
    },
    {
      "epoch": 3.6004308679289228,
      "grad_norm": 4.234812259674072,
      "learning_rate": 3.200502858352742e-05,
      "loss": 0.8048,
      "step": 340100
    },
    {
      "epoch": 3.600960189708926,
      "grad_norm": 4.092554092407227,
      "learning_rate": 3.2002381960618255e-05,
      "loss": 0.8016,
      "step": 340150
    },
    {
      "epoch": 3.6014895114889294,
      "grad_norm": 4.180749416351318,
      "learning_rate": 3.199973533770909e-05,
      "loss": 0.8032,
      "step": 340200
    },
    {
      "epoch": 3.6020188332689322,
      "grad_norm": 3.887148857116699,
      "learning_rate": 3.1997088714799916e-05,
      "loss": 0.8004,
      "step": 340250
    },
    {
      "epoch": 3.602548155048936,
      "grad_norm": 4.006501197814941,
      "learning_rate": 3.199444209189075e-05,
      "loss": 0.7924,
      "step": 340300
    },
    {
      "epoch": 3.603077476828939,
      "grad_norm": 4.252735137939453,
      "learning_rate": 3.1991795468981584e-05,
      "loss": 0.7819,
      "step": 340350
    },
    {
      "epoch": 3.6036067986089426,
      "grad_norm": 4.097387313842773,
      "learning_rate": 3.198914884607241e-05,
      "loss": 0.7931,
      "step": 340400
    },
    {
      "epoch": 3.6041361203889455,
      "grad_norm": 4.247506141662598,
      "learning_rate": 3.1986502223163246e-05,
      "loss": 0.795,
      "step": 340450
    },
    {
      "epoch": 3.604665442168949,
      "grad_norm": 4.378226280212402,
      "learning_rate": 3.198385560025407e-05,
      "loss": 0.8111,
      "step": 340500
    },
    {
      "epoch": 3.604665442168949,
      "eval_loss": 0.5606443285942078,
      "eval_runtime": 46.5345,
      "eval_samples_per_second": 3608.717,
      "eval_steps_per_second": 451.106,
      "step": 340500
    },
    {
      "epoch": 3.605194763948952,
      "grad_norm": 3.726889133453369,
      "learning_rate": 3.1981208977344914e-05,
      "loss": 0.7859,
      "step": 340550
    },
    {
      "epoch": 3.6057240857289554,
      "grad_norm": 4.393128871917725,
      "learning_rate": 3.197856235443574e-05,
      "loss": 0.7936,
      "step": 340600
    },
    {
      "epoch": 3.6062534075089587,
      "grad_norm": 3.9028568267822266,
      "learning_rate": 3.1975915731526575e-05,
      "loss": 0.7904,
      "step": 340650
    },
    {
      "epoch": 3.606782729288962,
      "grad_norm": 4.308553218841553,
      "learning_rate": 3.19732691086174e-05,
      "loss": 0.802,
      "step": 340700
    },
    {
      "epoch": 3.6073120510689654,
      "grad_norm": 3.8409292697906494,
      "learning_rate": 3.1970622485708244e-05,
      "loss": 0.793,
      "step": 340750
    },
    {
      "epoch": 3.6078413728489687,
      "grad_norm": 4.206920623779297,
      "learning_rate": 3.196797586279907e-05,
      "loss": 0.785,
      "step": 340800
    },
    {
      "epoch": 3.608370694628972,
      "grad_norm": 4.249945640563965,
      "learning_rate": 3.1965329239889905e-05,
      "loss": 0.7976,
      "step": 340850
    },
    {
      "epoch": 3.6089000164089753,
      "grad_norm": 4.182823181152344,
      "learning_rate": 3.196268261698073e-05,
      "loss": 0.8044,
      "step": 340900
    },
    {
      "epoch": 3.6094293381889786,
      "grad_norm": 4.056502819061279,
      "learning_rate": 3.1960035994071566e-05,
      "loss": 0.7813,
      "step": 340950
    },
    {
      "epoch": 3.609958659968982,
      "grad_norm": 4.007509708404541,
      "learning_rate": 3.19573893711624e-05,
      "loss": 0.8076,
      "step": 341000
    },
    {
      "epoch": 3.609958659968982,
      "eval_loss": 0.5599684119224548,
      "eval_runtime": 46.6141,
      "eval_samples_per_second": 3602.557,
      "eval_steps_per_second": 450.336,
      "step": 341000
    },
    {
      "epoch": 3.610487981748985,
      "grad_norm": 3.887080192565918,
      "learning_rate": 3.195474274825323e-05,
      "loss": 0.7995,
      "step": 341050
    },
    {
      "epoch": 3.611017303528988,
      "grad_norm": 4.256361961364746,
      "learning_rate": 3.195214905780224e-05,
      "loss": 0.8057,
      "step": 341100
    },
    {
      "epoch": 3.611546625308992,
      "grad_norm": 4.349632263183594,
      "learning_rate": 3.194950243489308e-05,
      "loss": 0.797,
      "step": 341150
    },
    {
      "epoch": 3.6120759470889947,
      "grad_norm": 4.514275074005127,
      "learning_rate": 3.194685581198391e-05,
      "loss": 0.8047,
      "step": 341200
    },
    {
      "epoch": 3.612605268868998,
      "grad_norm": 4.2830657958984375,
      "learning_rate": 3.1944209189074745e-05,
      "loss": 0.8016,
      "step": 341250
    },
    {
      "epoch": 3.6131345906490013,
      "grad_norm": 4.2872700691223145,
      "learning_rate": 3.194156256616557e-05,
      "loss": 0.7902,
      "step": 341300
    },
    {
      "epoch": 3.6136639124290046,
      "grad_norm": 4.315491199493408,
      "learning_rate": 3.1938915943256406e-05,
      "loss": 0.7972,
      "step": 341350
    },
    {
      "epoch": 3.614193234209008,
      "grad_norm": 4.136987686157227,
      "learning_rate": 3.193626932034724e-05,
      "loss": 0.7881,
      "step": 341400
    },
    {
      "epoch": 3.6147225559890113,
      "grad_norm": 4.397132396697998,
      "learning_rate": 3.193362269743807e-05,
      "loss": 0.7973,
      "step": 341450
    },
    {
      "epoch": 3.6152518777690146,
      "grad_norm": 3.84757399559021,
      "learning_rate": 3.19309760745289e-05,
      "loss": 0.792,
      "step": 341500
    },
    {
      "epoch": 3.6152518777690146,
      "eval_loss": 0.5589626431465149,
      "eval_runtime": 46.5892,
      "eval_samples_per_second": 3604.485,
      "eval_steps_per_second": 450.577,
      "step": 341500
    },
    {
      "epoch": 3.615781199549018,
      "grad_norm": 4.226472854614258,
      "learning_rate": 3.1928329451619736e-05,
      "loss": 0.7877,
      "step": 341550
    },
    {
      "epoch": 3.616310521329021,
      "grad_norm": 3.6402595043182373,
      "learning_rate": 3.192568282871057e-05,
      "loss": 0.7911,
      "step": 341600
    },
    {
      "epoch": 3.6168398431090245,
      "grad_norm": 3.72715163230896,
      "learning_rate": 3.19230362058014e-05,
      "loss": 0.7835,
      "step": 341650
    },
    {
      "epoch": 3.617369164889028,
      "grad_norm": 3.965312957763672,
      "learning_rate": 3.192038958289223e-05,
      "loss": 0.7959,
      "step": 341700
    },
    {
      "epoch": 3.617898486669031,
      "grad_norm": 4.0610671043396,
      "learning_rate": 3.1917742959983065e-05,
      "loss": 0.7852,
      "step": 341750
    },
    {
      "epoch": 3.6184278084490344,
      "grad_norm": 4.2772626876831055,
      "learning_rate": 3.19150963370739e-05,
      "loss": 0.7957,
      "step": 341800
    },
    {
      "epoch": 3.6189571302290373,
      "grad_norm": 3.8789405822753906,
      "learning_rate": 3.191244971416473e-05,
      "loss": 0.783,
      "step": 341850
    },
    {
      "epoch": 3.619486452009041,
      "grad_norm": 3.6664421558380127,
      "learning_rate": 3.190980309125556e-05,
      "loss": 0.7916,
      "step": 341900
    },
    {
      "epoch": 3.620015773789044,
      "grad_norm": 4.650171756744385,
      "learning_rate": 3.1907156468346395e-05,
      "loss": 0.7928,
      "step": 341950
    },
    {
      "epoch": 3.6205450955690472,
      "grad_norm": 3.971097946166992,
      "learning_rate": 3.190450984543722e-05,
      "loss": 0.7825,
      "step": 342000
    },
    {
      "epoch": 3.6205450955690472,
      "eval_loss": 0.5603469014167786,
      "eval_runtime": 46.535,
      "eval_samples_per_second": 3608.685,
      "eval_steps_per_second": 451.102,
      "step": 342000
    },
    {
      "epoch": 3.6210744173490506,
      "grad_norm": 4.0563812255859375,
      "learning_rate": 3.1901863222528057e-05,
      "loss": 0.7944,
      "step": 342050
    },
    {
      "epoch": 3.621603739129054,
      "grad_norm": 4.374436378479004,
      "learning_rate": 3.1899216599618884e-05,
      "loss": 0.7862,
      "step": 342100
    },
    {
      "epoch": 3.622133060909057,
      "grad_norm": 3.6998236179351807,
      "learning_rate": 3.1896569976709725e-05,
      "loss": 0.7891,
      "step": 342150
    },
    {
      "epoch": 3.6226623826890605,
      "grad_norm": 3.8735134601593018,
      "learning_rate": 3.189392335380055e-05,
      "loss": 0.7978,
      "step": 342200
    },
    {
      "epoch": 3.623191704469064,
      "grad_norm": 3.8855056762695312,
      "learning_rate": 3.1891276730891386e-05,
      "loss": 0.7868,
      "step": 342250
    },
    {
      "epoch": 3.623721026249067,
      "grad_norm": 3.572338819503784,
      "learning_rate": 3.1888630107982213e-05,
      "loss": 0.8024,
      "step": 342300
    },
    {
      "epoch": 3.6242503480290704,
      "grad_norm": 3.7619893550872803,
      "learning_rate": 3.1885983485073054e-05,
      "loss": 0.7927,
      "step": 342350
    },
    {
      "epoch": 3.6247796698090737,
      "grad_norm": 4.567137718200684,
      "learning_rate": 3.188333686216388e-05,
      "loss": 0.7897,
      "step": 342400
    },
    {
      "epoch": 3.625308991589077,
      "grad_norm": 4.064509391784668,
      "learning_rate": 3.1880690239254716e-05,
      "loss": 0.8076,
      "step": 342450
    },
    {
      "epoch": 3.6258383133690804,
      "grad_norm": 4.4349846839904785,
      "learning_rate": 3.187804361634554e-05,
      "loss": 0.7902,
      "step": 342500
    },
    {
      "epoch": 3.6258383133690804,
      "eval_loss": 0.5581881999969482,
      "eval_runtime": 46.608,
      "eval_samples_per_second": 3603.026,
      "eval_steps_per_second": 450.394,
      "step": 342500
    },
    {
      "epoch": 3.6263676351490837,
      "grad_norm": 4.138022422790527,
      "learning_rate": 3.187539699343638e-05,
      "loss": 0.8063,
      "step": 342550
    },
    {
      "epoch": 3.6268969569290865,
      "grad_norm": 3.731738567352295,
      "learning_rate": 3.187275037052721e-05,
      "loss": 0.7919,
      "step": 342600
    },
    {
      "epoch": 3.6274262787090903,
      "grad_norm": 3.9352197647094727,
      "learning_rate": 3.187010374761804e-05,
      "loss": 0.7923,
      "step": 342650
    },
    {
      "epoch": 3.627955600489093,
      "grad_norm": 4.178497314453125,
      "learning_rate": 3.186745712470887e-05,
      "loss": 0.7813,
      "step": 342700
    },
    {
      "epoch": 3.6284849222690965,
      "grad_norm": 4.412610054016113,
      "learning_rate": 3.186481050179971e-05,
      "loss": 0.7974,
      "step": 342750
    },
    {
      "epoch": 3.6290142440491,
      "grad_norm": 3.7145450115203857,
      "learning_rate": 3.186216387889054e-05,
      "loss": 0.7877,
      "step": 342800
    },
    {
      "epoch": 3.629543565829103,
      "grad_norm": 4.695365905761719,
      "learning_rate": 3.185951725598137e-05,
      "loss": 0.8037,
      "step": 342850
    },
    {
      "epoch": 3.6300728876091064,
      "grad_norm": 3.9772276878356934,
      "learning_rate": 3.18568706330722e-05,
      "loss": 0.8045,
      "step": 342900
    },
    {
      "epoch": 3.6306022093891097,
      "grad_norm": 4.062234401702881,
      "learning_rate": 3.1854224010163036e-05,
      "loss": 0.7896,
      "step": 342950
    },
    {
      "epoch": 3.631131531169113,
      "grad_norm": 3.9316086769104004,
      "learning_rate": 3.1851577387253864e-05,
      "loss": 0.7878,
      "step": 343000
    },
    {
      "epoch": 3.631131531169113,
      "eval_loss": 0.5594456195831299,
      "eval_runtime": 46.869,
      "eval_samples_per_second": 3582.967,
      "eval_steps_per_second": 447.887,
      "step": 343000
    },
    {
      "epoch": 3.6316608529491163,
      "grad_norm": 4.229258060455322,
      "learning_rate": 3.18489307643447e-05,
      "loss": 0.7817,
      "step": 343050
    },
    {
      "epoch": 3.6321901747291196,
      "grad_norm": 3.618875741958618,
      "learning_rate": 3.1846284141435525e-05,
      "loss": 0.786,
      "step": 343100
    },
    {
      "epoch": 3.632719496509123,
      "grad_norm": 3.956174373626709,
      "learning_rate": 3.184363751852636e-05,
      "loss": 0.7891,
      "step": 343150
    },
    {
      "epoch": 3.6332488182891263,
      "grad_norm": 4.2316508293151855,
      "learning_rate": 3.184099089561719e-05,
      "loss": 0.7934,
      "step": 343200
    },
    {
      "epoch": 3.6337781400691296,
      "grad_norm": 4.233088493347168,
      "learning_rate": 3.183834427270803e-05,
      "loss": 0.7811,
      "step": 343250
    },
    {
      "epoch": 3.634307461849133,
      "grad_norm": 4.053042411804199,
      "learning_rate": 3.1835697649798855e-05,
      "loss": 0.7972,
      "step": 343300
    },
    {
      "epoch": 3.6348367836291358,
      "grad_norm": 4.342632293701172,
      "learning_rate": 3.183305102688969e-05,
      "loss": 0.8051,
      "step": 343350
    },
    {
      "epoch": 3.6353661054091395,
      "grad_norm": 3.6714634895324707,
      "learning_rate": 3.183040440398052e-05,
      "loss": 0.7872,
      "step": 343400
    },
    {
      "epoch": 3.6358954271891424,
      "grad_norm": 3.7220797538757324,
      "learning_rate": 3.182775778107136e-05,
      "loss": 0.7846,
      "step": 343450
    },
    {
      "epoch": 3.6364247489691457,
      "grad_norm": 4.001376152038574,
      "learning_rate": 3.1825111158162184e-05,
      "loss": 0.7812,
      "step": 343500
    },
    {
      "epoch": 3.6364247489691457,
      "eval_loss": 0.5590336322784424,
      "eval_runtime": 46.5537,
      "eval_samples_per_second": 3607.232,
      "eval_steps_per_second": 450.92,
      "step": 343500
    },
    {
      "epoch": 3.636954070749149,
      "grad_norm": 4.122519493103027,
      "learning_rate": 3.182246453525302e-05,
      "loss": 0.7952,
      "step": 343550
    },
    {
      "epoch": 3.6374833925291523,
      "grad_norm": 4.169575214385986,
      "learning_rate": 3.181981791234385e-05,
      "loss": 0.7903,
      "step": 343600
    },
    {
      "epoch": 3.6380127143091556,
      "grad_norm": 4.4225077629089355,
      "learning_rate": 3.181717128943468e-05,
      "loss": 0.7984,
      "step": 343650
    },
    {
      "epoch": 3.638542036089159,
      "grad_norm": 4.067433834075928,
      "learning_rate": 3.1814524666525514e-05,
      "loss": 0.7798,
      "step": 343700
    },
    {
      "epoch": 3.6390713578691622,
      "grad_norm": 4.196660995483398,
      "learning_rate": 3.181187804361634e-05,
      "loss": 0.781,
      "step": 343750
    },
    {
      "epoch": 3.6396006796491656,
      "grad_norm": 4.49351692199707,
      "learning_rate": 3.180923142070718e-05,
      "loss": 0.7881,
      "step": 343800
    },
    {
      "epoch": 3.640130001429169,
      "grad_norm": 4.1788835525512695,
      "learning_rate": 3.180658479779801e-05,
      "loss": 0.7979,
      "step": 343850
    },
    {
      "epoch": 3.640659323209172,
      "grad_norm": 4.2265801429748535,
      "learning_rate": 3.1803938174888844e-05,
      "loss": 0.7993,
      "step": 343900
    },
    {
      "epoch": 3.6411886449891755,
      "grad_norm": 4.300387382507324,
      "learning_rate": 3.180129155197967e-05,
      "loss": 0.7928,
      "step": 343950
    },
    {
      "epoch": 3.641717966769179,
      "grad_norm": 4.289434432983398,
      "learning_rate": 3.179864492907051e-05,
      "loss": 0.791,
      "step": 344000
    },
    {
      "epoch": 3.641717966769179,
      "eval_loss": 0.5601365566253662,
      "eval_runtime": 46.6555,
      "eval_samples_per_second": 3599.358,
      "eval_steps_per_second": 449.936,
      "step": 344000
    },
    {
      "epoch": 3.642247288549182,
      "grad_norm": 4.078336238861084,
      "learning_rate": 3.179599830616134e-05,
      "loss": 0.7898,
      "step": 344050
    },
    {
      "epoch": 3.642776610329185,
      "grad_norm": 3.84081768989563,
      "learning_rate": 3.179335168325217e-05,
      "loss": 0.7919,
      "step": 344100
    },
    {
      "epoch": 3.6433059321091887,
      "grad_norm": 3.8613414764404297,
      "learning_rate": 3.1790705060343e-05,
      "loss": 0.7926,
      "step": 344150
    },
    {
      "epoch": 3.6438352538891916,
      "grad_norm": 4.260085582733154,
      "learning_rate": 3.1788058437433835e-05,
      "loss": 0.7929,
      "step": 344200
    },
    {
      "epoch": 3.644364575669195,
      "grad_norm": 3.781273603439331,
      "learning_rate": 3.178541181452467e-05,
      "loss": 0.7878,
      "step": 344250
    },
    {
      "epoch": 3.6448938974491982,
      "grad_norm": 4.271315574645996,
      "learning_rate": 3.1782765191615496e-05,
      "loss": 0.7941,
      "step": 344300
    },
    {
      "epoch": 3.6454232192292015,
      "grad_norm": 3.9513704776763916,
      "learning_rate": 3.178011856870633e-05,
      "loss": 0.7887,
      "step": 344350
    },
    {
      "epoch": 3.645952541009205,
      "grad_norm": 4.376145839691162,
      "learning_rate": 3.1777471945797164e-05,
      "loss": 0.7839,
      "step": 344400
    },
    {
      "epoch": 3.646481862789208,
      "grad_norm": 4.981791973114014,
      "learning_rate": 3.1774825322888e-05,
      "loss": 0.7901,
      "step": 344450
    },
    {
      "epoch": 3.6470111845692115,
      "grad_norm": 3.8812339305877686,
      "learning_rate": 3.1772178699978826e-05,
      "loss": 0.7834,
      "step": 344500
    },
    {
      "epoch": 3.6470111845692115,
      "eval_loss": 0.5564104318618774,
      "eval_runtime": 46.7054,
      "eval_samples_per_second": 3595.515,
      "eval_steps_per_second": 449.455,
      "step": 344500
    },
    {
      "epoch": 3.647540506349215,
      "grad_norm": 3.7289557456970215,
      "learning_rate": 3.176953207706966e-05,
      "loss": 0.8009,
      "step": 344550
    },
    {
      "epoch": 3.648069828129218,
      "grad_norm": 4.081851005554199,
      "learning_rate": 3.1766885454160494e-05,
      "loss": 0.8029,
      "step": 344600
    },
    {
      "epoch": 3.6485991499092214,
      "grad_norm": 4.039560317993164,
      "learning_rate": 3.176423883125133e-05,
      "loss": 0.7975,
      "step": 344650
    },
    {
      "epoch": 3.6491284716892247,
      "grad_norm": 4.251372337341309,
      "learning_rate": 3.1761592208342155e-05,
      "loss": 0.797,
      "step": 344700
    },
    {
      "epoch": 3.649657793469228,
      "grad_norm": 3.4095299243927,
      "learning_rate": 3.175894558543299e-05,
      "loss": 0.7787,
      "step": 344750
    },
    {
      "epoch": 3.6501871152492313,
      "grad_norm": 3.979344367980957,
      "learning_rate": 3.1756298962523824e-05,
      "loss": 0.7963,
      "step": 344800
    },
    {
      "epoch": 3.650716437029234,
      "grad_norm": 4.01793909072876,
      "learning_rate": 3.175365233961465e-05,
      "loss": 0.794,
      "step": 344850
    },
    {
      "epoch": 3.651245758809238,
      "grad_norm": 4.1164374351501465,
      "learning_rate": 3.1751005716705485e-05,
      "loss": 0.7964,
      "step": 344900
    },
    {
      "epoch": 3.651775080589241,
      "grad_norm": 4.3439717292785645,
      "learning_rate": 3.174835909379631e-05,
      "loss": 0.7823,
      "step": 344950
    },
    {
      "epoch": 3.652304402369244,
      "grad_norm": 4.065284729003906,
      "learning_rate": 3.174571247088715e-05,
      "loss": 0.779,
      "step": 345000
    },
    {
      "epoch": 3.652304402369244,
      "eval_loss": 0.5574162006378174,
      "eval_runtime": 46.571,
      "eval_samples_per_second": 3605.893,
      "eval_steps_per_second": 450.753,
      "step": 345000
    },
    {
      "epoch": 3.6528337241492475,
      "grad_norm": 4.1476054191589355,
      "learning_rate": 3.174306584797798e-05,
      "loss": 0.8035,
      "step": 345050
    },
    {
      "epoch": 3.6533630459292508,
      "grad_norm": 3.9682395458221436,
      "learning_rate": 3.1740472157526995e-05,
      "loss": 0.791,
      "step": 345100
    },
    {
      "epoch": 3.653892367709254,
      "grad_norm": 4.211565017700195,
      "learning_rate": 3.173782553461783e-05,
      "loss": 0.7836,
      "step": 345150
    },
    {
      "epoch": 3.6544216894892574,
      "grad_norm": 4.150819778442383,
      "learning_rate": 3.1735178911708663e-05,
      "loss": 0.7879,
      "step": 345200
    },
    {
      "epoch": 3.6549510112692607,
      "grad_norm": 4.111588001251221,
      "learning_rate": 3.173253228879949e-05,
      "loss": 0.7788,
      "step": 345250
    },
    {
      "epoch": 3.655480333049264,
      "grad_norm": 4.641148090362549,
      "learning_rate": 3.1729885665890325e-05,
      "loss": 0.7848,
      "step": 345300
    },
    {
      "epoch": 3.6560096548292673,
      "grad_norm": 4.329748630523682,
      "learning_rate": 3.172723904298115e-05,
      "loss": 0.7981,
      "step": 345350
    },
    {
      "epoch": 3.6565389766092706,
      "grad_norm": 4.257359027862549,
      "learning_rate": 3.172459242007199e-05,
      "loss": 0.7968,
      "step": 345400
    },
    {
      "epoch": 3.657068298389274,
      "grad_norm": 3.944021224975586,
      "learning_rate": 3.172194579716282e-05,
      "loss": 0.7813,
      "step": 345450
    },
    {
      "epoch": 3.6575976201692773,
      "grad_norm": 4.352718830108643,
      "learning_rate": 3.1719299174253654e-05,
      "loss": 0.794,
      "step": 345500
    },
    {
      "epoch": 3.6575976201692773,
      "eval_loss": 0.5589461922645569,
      "eval_runtime": 46.5648,
      "eval_samples_per_second": 3606.375,
      "eval_steps_per_second": 450.813,
      "step": 345500
    },
    {
      "epoch": 3.6581269419492806,
      "grad_norm": 4.347787380218506,
      "learning_rate": 3.171665255134448e-05,
      "loss": 0.7905,
      "step": 345550
    },
    {
      "epoch": 3.6586562637292834,
      "grad_norm": 4.020508766174316,
      "learning_rate": 3.171400592843532e-05,
      "loss": 0.7973,
      "step": 345600
    },
    {
      "epoch": 3.659185585509287,
      "grad_norm": 3.8592946529388428,
      "learning_rate": 3.171135930552615e-05,
      "loss": 0.7896,
      "step": 345650
    },
    {
      "epoch": 3.65971490728929,
      "grad_norm": 4.3566203117370605,
      "learning_rate": 3.1708712682616984e-05,
      "loss": 0.7907,
      "step": 345700
    },
    {
      "epoch": 3.6602442290692934,
      "grad_norm": 4.162861347198486,
      "learning_rate": 3.170606605970781e-05,
      "loss": 0.7994,
      "step": 345750
    },
    {
      "epoch": 3.6607735508492967,
      "grad_norm": 4.235241889953613,
      "learning_rate": 3.1703419436798646e-05,
      "loss": 0.7931,
      "step": 345800
    },
    {
      "epoch": 3.6613028726293,
      "grad_norm": 4.053263187408447,
      "learning_rate": 3.170077281388948e-05,
      "loss": 0.7946,
      "step": 345850
    },
    {
      "epoch": 3.6618321944093033,
      "grad_norm": 4.608381748199463,
      "learning_rate": 3.169812619098031e-05,
      "loss": 0.7886,
      "step": 345900
    },
    {
      "epoch": 3.6623615161893066,
      "grad_norm": 4.205154895782471,
      "learning_rate": 3.169547956807114e-05,
      "loss": 0.802,
      "step": 345950
    },
    {
      "epoch": 3.66289083796931,
      "grad_norm": 3.9093384742736816,
      "learning_rate": 3.1692832945161975e-05,
      "loss": 0.7903,
      "step": 346000
    },
    {
      "epoch": 3.66289083796931,
      "eval_loss": 0.5572705864906311,
      "eval_runtime": 46.5775,
      "eval_samples_per_second": 3605.387,
      "eval_steps_per_second": 450.69,
      "step": 346000
    },
    {
      "epoch": 3.6634201597493132,
      "grad_norm": 3.9923155307769775,
      "learning_rate": 3.169018632225281e-05,
      "loss": 0.7859,
      "step": 346050
    },
    {
      "epoch": 3.6639494815293165,
      "grad_norm": 4.091723918914795,
      "learning_rate": 3.1687539699343637e-05,
      "loss": 0.7846,
      "step": 346100
    },
    {
      "epoch": 3.66447880330932,
      "grad_norm": 4.104403972625732,
      "learning_rate": 3.168489307643447e-05,
      "loss": 0.7866,
      "step": 346150
    },
    {
      "epoch": 3.665008125089323,
      "grad_norm": 4.103809833526611,
      "learning_rate": 3.1682246453525305e-05,
      "loss": 0.7836,
      "step": 346200
    },
    {
      "epoch": 3.6655374468693265,
      "grad_norm": 4.530733585357666,
      "learning_rate": 3.167959983061614e-05,
      "loss": 0.7869,
      "step": 346250
    },
    {
      "epoch": 3.66606676864933,
      "grad_norm": 3.9246082305908203,
      "learning_rate": 3.1676953207706966e-05,
      "loss": 0.8043,
      "step": 346300
    },
    {
      "epoch": 3.6665960904293327,
      "grad_norm": 4.034900188446045,
      "learning_rate": 3.16743065847978e-05,
      "loss": 0.8038,
      "step": 346350
    },
    {
      "epoch": 3.6671254122093364,
      "grad_norm": 4.0194010734558105,
      "learning_rate": 3.1671659961888634e-05,
      "loss": 0.7905,
      "step": 346400
    },
    {
      "epoch": 3.6676547339893393,
      "grad_norm": 3.8385870456695557,
      "learning_rate": 3.166901333897946e-05,
      "loss": 0.8047,
      "step": 346450
    },
    {
      "epoch": 3.6681840557693426,
      "grad_norm": 4.263280868530273,
      "learning_rate": 3.1666366716070296e-05,
      "loss": 0.7882,
      "step": 346500
    },
    {
      "epoch": 3.6681840557693426,
      "eval_loss": 0.5566454529762268,
      "eval_runtime": 46.5184,
      "eval_samples_per_second": 3609.973,
      "eval_steps_per_second": 451.263,
      "step": 346500
    },
    {
      "epoch": 3.668713377549346,
      "grad_norm": 4.009146690368652,
      "learning_rate": 3.166372009316112e-05,
      "loss": 0.7934,
      "step": 346550
    },
    {
      "epoch": 3.669242699329349,
      "grad_norm": 4.206406116485596,
      "learning_rate": 3.1661073470251964e-05,
      "loss": 0.778,
      "step": 346600
    },
    {
      "epoch": 3.6697720211093525,
      "grad_norm": 3.91959285736084,
      "learning_rate": 3.165842684734279e-05,
      "loss": 0.7993,
      "step": 346650
    },
    {
      "epoch": 3.670301342889356,
      "grad_norm": 3.936660051345825,
      "learning_rate": 3.1655780224433625e-05,
      "loss": 0.7898,
      "step": 346700
    },
    {
      "epoch": 3.670830664669359,
      "grad_norm": 3.4423515796661377,
      "learning_rate": 3.165313360152445e-05,
      "loss": 0.7785,
      "step": 346750
    },
    {
      "epoch": 3.6713599864493625,
      "grad_norm": 4.397805690765381,
      "learning_rate": 3.165048697861529e-05,
      "loss": 0.7853,
      "step": 346800
    },
    {
      "epoch": 3.6718893082293658,
      "grad_norm": 3.7961525917053223,
      "learning_rate": 3.164784035570612e-05,
      "loss": 0.7983,
      "step": 346850
    },
    {
      "epoch": 3.672418630009369,
      "grad_norm": 4.211240291595459,
      "learning_rate": 3.164519373279695e-05,
      "loss": 0.7811,
      "step": 346900
    },
    {
      "epoch": 3.6729479517893724,
      "grad_norm": 4.802608966827393,
      "learning_rate": 3.164254710988778e-05,
      "loss": 0.7893,
      "step": 346950
    },
    {
      "epoch": 3.6734772735693757,
      "grad_norm": 3.930973768234253,
      "learning_rate": 3.1639900486978616e-05,
      "loss": 0.7987,
      "step": 347000
    },
    {
      "epoch": 3.6734772735693757,
      "eval_loss": 0.5557690262794495,
      "eval_runtime": 46.5738,
      "eval_samples_per_second": 3605.672,
      "eval_steps_per_second": 450.725,
      "step": 347000
    },
    {
      "epoch": 3.674006595349379,
      "grad_norm": 4.059635162353516,
      "learning_rate": 3.163725386406945e-05,
      "loss": 0.7879,
      "step": 347050
    },
    {
      "epoch": 3.674535917129382,
      "grad_norm": 3.988633871078491,
      "learning_rate": 3.163460724116028e-05,
      "loss": 0.7821,
      "step": 347100
    },
    {
      "epoch": 3.6750652389093856,
      "grad_norm": 4.108388423919678,
      "learning_rate": 3.163201355070929e-05,
      "loss": 0.7806,
      "step": 347150
    },
    {
      "epoch": 3.6755945606893885,
      "grad_norm": 3.7139089107513428,
      "learning_rate": 3.1629366927800134e-05,
      "loss": 0.7955,
      "step": 347200
    },
    {
      "epoch": 3.676123882469392,
      "grad_norm": 4.593837738037109,
      "learning_rate": 3.162672030489096e-05,
      "loss": 0.7927,
      "step": 347250
    },
    {
      "epoch": 3.676653204249395,
      "grad_norm": 3.8761796951293945,
      "learning_rate": 3.1624073681981795e-05,
      "loss": 0.7921,
      "step": 347300
    },
    {
      "epoch": 3.6771825260293984,
      "grad_norm": 4.010688781738281,
      "learning_rate": 3.162142705907262e-05,
      "loss": 0.793,
      "step": 347350
    },
    {
      "epoch": 3.6777118478094017,
      "grad_norm": 3.9505386352539062,
      "learning_rate": 3.1618780436163456e-05,
      "loss": 0.7778,
      "step": 347400
    },
    {
      "epoch": 3.678241169589405,
      "grad_norm": 4.1182990074157715,
      "learning_rate": 3.161613381325429e-05,
      "loss": 0.778,
      "step": 347450
    },
    {
      "epoch": 3.6787704913694084,
      "grad_norm": 4.116270542144775,
      "learning_rate": 3.161348719034512e-05,
      "loss": 0.7886,
      "step": 347500
    },
    {
      "epoch": 3.6787704913694084,
      "eval_loss": 0.5551413893699646,
      "eval_runtime": 46.5482,
      "eval_samples_per_second": 3607.657,
      "eval_steps_per_second": 450.973,
      "step": 347500
    },
    {
      "epoch": 3.6792998131494117,
      "grad_norm": 4.119560718536377,
      "learning_rate": 3.161084056743595e-05,
      "loss": 0.7871,
      "step": 347550
    },
    {
      "epoch": 3.679829134929415,
      "grad_norm": 4.30238676071167,
      "learning_rate": 3.1608193944526786e-05,
      "loss": 0.7992,
      "step": 347600
    },
    {
      "epoch": 3.6803584567094183,
      "grad_norm": 3.555307149887085,
      "learning_rate": 3.160554732161762e-05,
      "loss": 0.7911,
      "step": 347650
    },
    {
      "epoch": 3.6808877784894216,
      "grad_norm": 3.9544878005981445,
      "learning_rate": 3.160290069870845e-05,
      "loss": 0.7843,
      "step": 347700
    },
    {
      "epoch": 3.681417100269425,
      "grad_norm": 3.9453237056732178,
      "learning_rate": 3.160025407579928e-05,
      "loss": 0.7837,
      "step": 347750
    },
    {
      "epoch": 3.6819464220494282,
      "grad_norm": 3.982414960861206,
      "learning_rate": 3.1597607452890116e-05,
      "loss": 0.7916,
      "step": 347800
    },
    {
      "epoch": 3.682475743829431,
      "grad_norm": 4.214894771575928,
      "learning_rate": 3.159496082998095e-05,
      "loss": 0.7837,
      "step": 347850
    },
    {
      "epoch": 3.683005065609435,
      "grad_norm": 4.19143533706665,
      "learning_rate": 3.159231420707178e-05,
      "loss": 0.7888,
      "step": 347900
    },
    {
      "epoch": 3.6835343873894377,
      "grad_norm": 3.9792540073394775,
      "learning_rate": 3.158966758416261e-05,
      "loss": 0.7922,
      "step": 347950
    },
    {
      "epoch": 3.684063709169441,
      "grad_norm": 3.8685085773468018,
      "learning_rate": 3.1587020961253445e-05,
      "loss": 0.7793,
      "step": 348000
    },
    {
      "epoch": 3.684063709169441,
      "eval_loss": 0.5558714270591736,
      "eval_runtime": 46.5358,
      "eval_samples_per_second": 3608.618,
      "eval_steps_per_second": 451.093,
      "step": 348000
    },
    {
      "epoch": 3.6845930309494443,
      "grad_norm": 3.8125696182250977,
      "learning_rate": 3.158437433834427e-05,
      "loss": 0.782,
      "step": 348050
    },
    {
      "epoch": 3.6851223527294477,
      "grad_norm": 4.444813251495361,
      "learning_rate": 3.158172771543511e-05,
      "loss": 0.7903,
      "step": 348100
    },
    {
      "epoch": 3.685651674509451,
      "grad_norm": 3.6893088817596436,
      "learning_rate": 3.1579081092525934e-05,
      "loss": 0.7805,
      "step": 348150
    },
    {
      "epoch": 3.6861809962894543,
      "grad_norm": 4.037693500518799,
      "learning_rate": 3.1576434469616775e-05,
      "loss": 0.7801,
      "step": 348200
    },
    {
      "epoch": 3.6867103180694576,
      "grad_norm": 4.05889368057251,
      "learning_rate": 3.15737878467076e-05,
      "loss": 0.7955,
      "step": 348250
    },
    {
      "epoch": 3.687239639849461,
      "grad_norm": 4.210369110107422,
      "learning_rate": 3.1571141223798436e-05,
      "loss": 0.7817,
      "step": 348300
    },
    {
      "epoch": 3.687768961629464,
      "grad_norm": 3.802410364151001,
      "learning_rate": 3.1568494600889264e-05,
      "loss": 0.7846,
      "step": 348350
    },
    {
      "epoch": 3.6882982834094675,
      "grad_norm": 4.103437900543213,
      "learning_rate": 3.15658479779801e-05,
      "loss": 0.792,
      "step": 348400
    },
    {
      "epoch": 3.688827605189471,
      "grad_norm": 4.197746276855469,
      "learning_rate": 3.156320135507093e-05,
      "loss": 0.7803,
      "step": 348450
    },
    {
      "epoch": 3.689356926969474,
      "grad_norm": 4.311733245849609,
      "learning_rate": 3.156055473216176e-05,
      "loss": 0.7912,
      "step": 348500
    },
    {
      "epoch": 3.689356926969474,
      "eval_loss": 0.5532707571983337,
      "eval_runtime": 46.7296,
      "eval_samples_per_second": 3593.655,
      "eval_steps_per_second": 449.223,
      "step": 348500
    },
    {
      "epoch": 3.6898862487494775,
      "grad_norm": 3.6826939582824707,
      "learning_rate": 3.155790810925259e-05,
      "loss": 0.7772,
      "step": 348550
    },
    {
      "epoch": 3.6904155705294803,
      "grad_norm": 4.32375955581665,
      "learning_rate": 3.155526148634343e-05,
      "loss": 0.7902,
      "step": 348600
    },
    {
      "epoch": 3.690944892309484,
      "grad_norm": 3.729288339614868,
      "learning_rate": 3.155261486343426e-05,
      "loss": 0.781,
      "step": 348650
    },
    {
      "epoch": 3.691474214089487,
      "grad_norm": 4.039859771728516,
      "learning_rate": 3.154996824052509e-05,
      "loss": 0.7869,
      "step": 348700
    },
    {
      "epoch": 3.6920035358694903,
      "grad_norm": 4.264838218688965,
      "learning_rate": 3.154732161761592e-05,
      "loss": 0.7856,
      "step": 348750
    },
    {
      "epoch": 3.6925328576494936,
      "grad_norm": 4.21009635925293,
      "learning_rate": 3.154467499470676e-05,
      "loss": 0.7927,
      "step": 348800
    },
    {
      "epoch": 3.693062179429497,
      "grad_norm": 4.145117282867432,
      "learning_rate": 3.154202837179759e-05,
      "loss": 0.7991,
      "step": 348850
    },
    {
      "epoch": 3.6935915012095,
      "grad_norm": 4.292262077331543,
      "learning_rate": 3.153938174888842e-05,
      "loss": 0.8061,
      "step": 348900
    },
    {
      "epoch": 3.6941208229895035,
      "grad_norm": 4.349492073059082,
      "learning_rate": 3.153673512597925e-05,
      "loss": 0.7787,
      "step": 348950
    },
    {
      "epoch": 3.694650144769507,
      "grad_norm": 4.146811485290527,
      "learning_rate": 3.1534088503070087e-05,
      "loss": 0.7847,
      "step": 349000
    },
    {
      "epoch": 3.694650144769507,
      "eval_loss": 0.5538299679756165,
      "eval_runtime": 46.5104,
      "eval_samples_per_second": 3610.59,
      "eval_steps_per_second": 451.34,
      "step": 349000
    },
    {
      "epoch": 3.69517946654951,
      "grad_norm": 4.02685022354126,
      "learning_rate": 3.1531441880160914e-05,
      "loss": 0.7905,
      "step": 349050
    },
    {
      "epoch": 3.6957087883295134,
      "grad_norm": 3.6985926628112793,
      "learning_rate": 3.152879525725175e-05,
      "loss": 0.7922,
      "step": 349100
    },
    {
      "epoch": 3.6962381101095168,
      "grad_norm": 4.257696628570557,
      "learning_rate": 3.152620156680076e-05,
      "loss": 0.7819,
      "step": 349150
    },
    {
      "epoch": 3.69676743188952,
      "grad_norm": 4.21748685836792,
      "learning_rate": 3.15235549438916e-05,
      "loss": 0.7859,
      "step": 349200
    },
    {
      "epoch": 3.6972967536695234,
      "grad_norm": 4.38916015625,
      "learning_rate": 3.152090832098243e-05,
      "loss": 0.7953,
      "step": 349250
    },
    {
      "epoch": 3.6978260754495267,
      "grad_norm": 4.359219551086426,
      "learning_rate": 3.151826169807326e-05,
      "loss": 0.7864,
      "step": 349300
    },
    {
      "epoch": 3.6983553972295296,
      "grad_norm": 4.384781837463379,
      "learning_rate": 3.151561507516409e-05,
      "loss": 0.7844,
      "step": 349350
    },
    {
      "epoch": 3.6988847190095333,
      "grad_norm": 4.322035789489746,
      "learning_rate": 3.1512968452254926e-05,
      "loss": 0.7888,
      "step": 349400
    },
    {
      "epoch": 3.699414040789536,
      "grad_norm": 4.407168388366699,
      "learning_rate": 3.1510321829345754e-05,
      "loss": 0.7983,
      "step": 349450
    },
    {
      "epoch": 3.6999433625695395,
      "grad_norm": 4.236907958984375,
      "learning_rate": 3.150767520643659e-05,
      "loss": 0.787,
      "step": 349500
    },
    {
      "epoch": 3.6999433625695395,
      "eval_loss": 0.555029034614563,
      "eval_runtime": 46.5837,
      "eval_samples_per_second": 3604.911,
      "eval_steps_per_second": 450.63,
      "step": 349500
    },
    {
      "epoch": 3.700472684349543,
      "grad_norm": 4.117900371551514,
      "learning_rate": 3.1505028583527415e-05,
      "loss": 0.7872,
      "step": 349550
    },
    {
      "epoch": 3.701002006129546,
      "grad_norm": 3.773581027984619,
      "learning_rate": 3.1502381960618256e-05,
      "loss": 0.8118,
      "step": 349600
    },
    {
      "epoch": 3.7015313279095494,
      "grad_norm": 4.888250350952148,
      "learning_rate": 3.149973533770908e-05,
      "loss": 0.7928,
      "step": 349650
    },
    {
      "epoch": 3.7020606496895527,
      "grad_norm": 4.1476898193359375,
      "learning_rate": 3.149708871479992e-05,
      "loss": 0.7952,
      "step": 349700
    },
    {
      "epoch": 3.702589971469556,
      "grad_norm": 4.408294200897217,
      "learning_rate": 3.1494442091890745e-05,
      "loss": 0.8089,
      "step": 349750
    },
    {
      "epoch": 3.7031192932495594,
      "grad_norm": 3.8982856273651123,
      "learning_rate": 3.1491795468981586e-05,
      "loss": 0.7793,
      "step": 349800
    },
    {
      "epoch": 3.7036486150295627,
      "grad_norm": 4.706719398498535,
      "learning_rate": 3.148914884607241e-05,
      "loss": 0.7893,
      "step": 349850
    },
    {
      "epoch": 3.704177936809566,
      "grad_norm": 4.075570583343506,
      "learning_rate": 3.148650222316325e-05,
      "loss": 0.7813,
      "step": 349900
    },
    {
      "epoch": 3.7047072585895693,
      "grad_norm": 3.8895745277404785,
      "learning_rate": 3.1483855600254074e-05,
      "loss": 0.7853,
      "step": 349950
    },
    {
      "epoch": 3.7052365803695726,
      "grad_norm": 4.031398773193359,
      "learning_rate": 3.148120897734491e-05,
      "loss": 0.7817,
      "step": 350000
    },
    {
      "epoch": 3.7052365803695726,
      "eval_loss": 0.5534270405769348,
      "eval_runtime": 46.54,
      "eval_samples_per_second": 3608.29,
      "eval_steps_per_second": 451.052,
      "step": 350000
    },
    {
      "epoch": 3.705765902149576,
      "grad_norm": 4.220131874084473,
      "learning_rate": 3.147856235443574e-05,
      "loss": 0.788,
      "step": 350050
    },
    {
      "epoch": 3.7062952239295788,
      "grad_norm": 4.40451717376709,
      "learning_rate": 3.147591573152657e-05,
      "loss": 0.7934,
      "step": 350100
    },
    {
      "epoch": 3.7068245457095825,
      "grad_norm": 4.141091823577881,
      "learning_rate": 3.1473269108617404e-05,
      "loss": 0.8006,
      "step": 350150
    },
    {
      "epoch": 3.7073538674895854,
      "grad_norm": 4.310259819030762,
      "learning_rate": 3.147062248570824e-05,
      "loss": 0.7906,
      "step": 350200
    },
    {
      "epoch": 3.707883189269589,
      "grad_norm": 4.224329948425293,
      "learning_rate": 3.146797586279907e-05,
      "loss": 0.7842,
      "step": 350250
    },
    {
      "epoch": 3.708412511049592,
      "grad_norm": 4.123193264007568,
      "learning_rate": 3.14653292398899e-05,
      "loss": 0.7915,
      "step": 350300
    },
    {
      "epoch": 3.7089418328295953,
      "grad_norm": 3.816232442855835,
      "learning_rate": 3.1462682616980734e-05,
      "loss": 0.7697,
      "step": 350350
    },
    {
      "epoch": 3.7094711546095986,
      "grad_norm": 4.360876083374023,
      "learning_rate": 3.146008892652975e-05,
      "loss": 0.788,
      "step": 350400
    },
    {
      "epoch": 3.710000476389602,
      "grad_norm": 3.8962323665618896,
      "learning_rate": 3.145744230362058e-05,
      "loss": 0.7833,
      "step": 350450
    },
    {
      "epoch": 3.7105297981696053,
      "grad_norm": 3.7928411960601807,
      "learning_rate": 3.145479568071141e-05,
      "loss": 0.7977,
      "step": 350500
    },
    {
      "epoch": 3.7105297981696053,
      "eval_loss": 0.5531973242759705,
      "eval_runtime": 46.5423,
      "eval_samples_per_second": 3608.112,
      "eval_steps_per_second": 451.03,
      "step": 350500
    },
    {
      "epoch": 3.7110591199496086,
      "grad_norm": 4.517531871795654,
      "learning_rate": 3.1452149057802244e-05,
      "loss": 0.7828,
      "step": 350550
    },
    {
      "epoch": 3.711588441729612,
      "grad_norm": 3.5067479610443115,
      "learning_rate": 3.144950243489308e-05,
      "loss": 0.7846,
      "step": 350600
    },
    {
      "epoch": 3.712117763509615,
      "grad_norm": 3.6003189086914062,
      "learning_rate": 3.144685581198391e-05,
      "loss": 0.7772,
      "step": 350650
    },
    {
      "epoch": 3.7126470852896185,
      "grad_norm": 3.976531505584717,
      "learning_rate": 3.144420918907474e-05,
      "loss": 0.7783,
      "step": 350700
    },
    {
      "epoch": 3.713176407069622,
      "grad_norm": 4.279515743255615,
      "learning_rate": 3.1441562566165574e-05,
      "loss": 0.7938,
      "step": 350750
    },
    {
      "epoch": 3.713705728849625,
      "grad_norm": 4.201696395874023,
      "learning_rate": 3.143891594325641e-05,
      "loss": 0.7938,
      "step": 350800
    },
    {
      "epoch": 3.714235050629628,
      "grad_norm": 3.9679248332977295,
      "learning_rate": 3.143626932034724e-05,
      "loss": 0.7847,
      "step": 350850
    },
    {
      "epoch": 3.7147643724096318,
      "grad_norm": 4.088907718658447,
      "learning_rate": 3.143362269743807e-05,
      "loss": 0.7877,
      "step": 350900
    },
    {
      "epoch": 3.7152936941896346,
      "grad_norm": 4.252607822418213,
      "learning_rate": 3.14309760745289e-05,
      "loss": 0.8026,
      "step": 350950
    },
    {
      "epoch": 3.7158230159696384,
      "grad_norm": 4.1410017013549805,
      "learning_rate": 3.142832945161974e-05,
      "loss": 0.7852,
      "step": 351000
    },
    {
      "epoch": 3.7158230159696384,
      "eval_loss": 0.5517443418502808,
      "eval_runtime": 46.7133,
      "eval_samples_per_second": 3594.906,
      "eval_steps_per_second": 449.379,
      "step": 351000
    },
    {
      "epoch": 3.7163523377496412,
      "grad_norm": 4.343806266784668,
      "learning_rate": 3.1425682828710565e-05,
      "loss": 0.7857,
      "step": 351050
    },
    {
      "epoch": 3.7168816595296446,
      "grad_norm": 4.129818439483643,
      "learning_rate": 3.14230362058014e-05,
      "loss": 0.786,
      "step": 351100
    },
    {
      "epoch": 3.717410981309648,
      "grad_norm": 4.290287494659424,
      "learning_rate": 3.1420389582892226e-05,
      "loss": 0.7826,
      "step": 351150
    },
    {
      "epoch": 3.717940303089651,
      "grad_norm": 3.7925500869750977,
      "learning_rate": 3.141774295998307e-05,
      "loss": 0.7859,
      "step": 351200
    },
    {
      "epoch": 3.7184696248696545,
      "grad_norm": 4.154123783111572,
      "learning_rate": 3.1415096337073894e-05,
      "loss": 0.7778,
      "step": 351250
    },
    {
      "epoch": 3.718998946649658,
      "grad_norm": 3.931051731109619,
      "learning_rate": 3.141244971416473e-05,
      "loss": 0.7939,
      "step": 351300
    },
    {
      "epoch": 3.719528268429661,
      "grad_norm": 4.11496114730835,
      "learning_rate": 3.1409803091255556e-05,
      "loss": 0.787,
      "step": 351350
    },
    {
      "epoch": 3.7200575902096644,
      "grad_norm": 4.245141983032227,
      "learning_rate": 3.1407156468346396e-05,
      "loss": 0.7877,
      "step": 351400
    },
    {
      "epoch": 3.7205869119896677,
      "grad_norm": 4.033559799194336,
      "learning_rate": 3.1404509845437224e-05,
      "loss": 0.7903,
      "step": 351450
    },
    {
      "epoch": 3.721116233769671,
      "grad_norm": 4.514949321746826,
      "learning_rate": 3.140186322252806e-05,
      "loss": 0.7872,
      "step": 351500
    },
    {
      "epoch": 3.721116233769671,
      "eval_loss": 0.5540258884429932,
      "eval_runtime": 46.699,
      "eval_samples_per_second": 3596.012,
      "eval_steps_per_second": 449.518,
      "step": 351500
    },
    {
      "epoch": 3.7216455555496744,
      "grad_norm": 4.193871974945068,
      "learning_rate": 3.1399216599618885e-05,
      "loss": 0.7808,
      "step": 351550
    },
    {
      "epoch": 3.7221748773296772,
      "grad_norm": 4.005854606628418,
      "learning_rate": 3.139656997670972e-05,
      "loss": 0.779,
      "step": 351600
    },
    {
      "epoch": 3.722704199109681,
      "grad_norm": 4.2567243576049805,
      "learning_rate": 3.1393923353800553e-05,
      "loss": 0.7877,
      "step": 351650
    },
    {
      "epoch": 3.723233520889684,
      "grad_norm": 4.00512170791626,
      "learning_rate": 3.139127673089138e-05,
      "loss": 0.7804,
      "step": 351700
    },
    {
      "epoch": 3.7237628426696876,
      "grad_norm": 4.057041645050049,
      "learning_rate": 3.1388630107982215e-05,
      "loss": 0.7848,
      "step": 351750
    },
    {
      "epoch": 3.7242921644496905,
      "grad_norm": 3.825159788131714,
      "learning_rate": 3.138598348507305e-05,
      "loss": 0.7971,
      "step": 351800
    },
    {
      "epoch": 3.724821486229694,
      "grad_norm": 4.197357177734375,
      "learning_rate": 3.138333686216388e-05,
      "loss": 0.7802,
      "step": 351850
    },
    {
      "epoch": 3.725350808009697,
      "grad_norm": 4.126071453094482,
      "learning_rate": 3.138069023925471e-05,
      "loss": 0.7893,
      "step": 351900
    },
    {
      "epoch": 3.7258801297897004,
      "grad_norm": 3.7990148067474365,
      "learning_rate": 3.1378043616345544e-05,
      "loss": 0.792,
      "step": 351950
    },
    {
      "epoch": 3.7264094515697037,
      "grad_norm": 4.30784797668457,
      "learning_rate": 3.137539699343638e-05,
      "loss": 0.781,
      "step": 352000
    },
    {
      "epoch": 3.7264094515697037,
      "eval_loss": 0.5497007966041565,
      "eval_runtime": 46.5416,
      "eval_samples_per_second": 3608.173,
      "eval_steps_per_second": 451.038,
      "step": 352000
    },
    {
      "epoch": 3.726938773349707,
      "grad_norm": 4.052123546600342,
      "learning_rate": 3.137275037052721e-05,
      "loss": 0.7873,
      "step": 352050
    },
    {
      "epoch": 3.7274680951297103,
      "grad_norm": 3.9595773220062256,
      "learning_rate": 3.137010374761804e-05,
      "loss": 0.783,
      "step": 352100
    },
    {
      "epoch": 3.7279974169097136,
      "grad_norm": 3.965116262435913,
      "learning_rate": 3.1367457124708874e-05,
      "loss": 0.7837,
      "step": 352150
    },
    {
      "epoch": 3.728526738689717,
      "grad_norm": 3.8255438804626465,
      "learning_rate": 3.136481050179971e-05,
      "loss": 0.7871,
      "step": 352200
    },
    {
      "epoch": 3.7290560604697203,
      "grad_norm": 4.370752811431885,
      "learning_rate": 3.1362163878890536e-05,
      "loss": 0.7827,
      "step": 352250
    },
    {
      "epoch": 3.7295853822497236,
      "grad_norm": 4.1440229415893555,
      "learning_rate": 3.135951725598137e-05,
      "loss": 0.7979,
      "step": 352300
    },
    {
      "epoch": 3.7301147040297264,
      "grad_norm": 4.252212047576904,
      "learning_rate": 3.13568706330722e-05,
      "loss": 0.7806,
      "step": 352350
    },
    {
      "epoch": 3.73064402580973,
      "grad_norm": 4.2563796043396,
      "learning_rate": 3.135422401016304e-05,
      "loss": 0.7829,
      "step": 352400
    },
    {
      "epoch": 3.731173347589733,
      "grad_norm": 4.3063578605651855,
      "learning_rate": 3.1351577387253865e-05,
      "loss": 0.7852,
      "step": 352450
    },
    {
      "epoch": 3.731702669369737,
      "grad_norm": 3.8639347553253174,
      "learning_rate": 3.13489307643447e-05,
      "loss": 0.7788,
      "step": 352500
    },
    {
      "epoch": 3.731702669369737,
      "eval_loss": 0.5508993268013,
      "eval_runtime": 46.5489,
      "eval_samples_per_second": 3607.607,
      "eval_steps_per_second": 450.967,
      "step": 352500
    },
    {
      "epoch": 3.7322319911497397,
      "grad_norm": 4.355790138244629,
      "learning_rate": 3.1346284141435527e-05,
      "loss": 0.7816,
      "step": 352550
    },
    {
      "epoch": 3.732761312929743,
      "grad_norm": 3.6765596866607666,
      "learning_rate": 3.134363751852637e-05,
      "loss": 0.7707,
      "step": 352600
    },
    {
      "epoch": 3.7332906347097463,
      "grad_norm": 3.996966600418091,
      "learning_rate": 3.1340990895617195e-05,
      "loss": 0.7809,
      "step": 352650
    },
    {
      "epoch": 3.7338199564897496,
      "grad_norm": 3.930732011795044,
      "learning_rate": 3.133834427270803e-05,
      "loss": 0.7783,
      "step": 352700
    },
    {
      "epoch": 3.734349278269753,
      "grad_norm": 4.249030590057373,
      "learning_rate": 3.1335697649798856e-05,
      "loss": 0.8017,
      "step": 352750
    },
    {
      "epoch": 3.7348786000497562,
      "grad_norm": 4.17677116394043,
      "learning_rate": 3.133305102688969e-05,
      "loss": 0.7781,
      "step": 352800
    },
    {
      "epoch": 3.7354079218297596,
      "grad_norm": 3.7643184661865234,
      "learning_rate": 3.1330404403980524e-05,
      "loss": 0.7738,
      "step": 352850
    },
    {
      "epoch": 3.735937243609763,
      "grad_norm": 3.9859983921051025,
      "learning_rate": 3.132775778107135e-05,
      "loss": 0.7771,
      "step": 352900
    },
    {
      "epoch": 3.736466565389766,
      "grad_norm": 4.316786289215088,
      "learning_rate": 3.1325111158162186e-05,
      "loss": 0.7875,
      "step": 352950
    },
    {
      "epoch": 3.7369958871697695,
      "grad_norm": 4.420897483825684,
      "learning_rate": 3.132246453525302e-05,
      "loss": 0.7829,
      "step": 353000
    },
    {
      "epoch": 3.7369958871697695,
      "eval_loss": 0.5501480102539062,
      "eval_runtime": 46.5425,
      "eval_samples_per_second": 3608.101,
      "eval_steps_per_second": 451.029,
      "step": 353000
    },
    {
      "epoch": 3.737525208949773,
      "grad_norm": 4.115929126739502,
      "learning_rate": 3.1319817912343854e-05,
      "loss": 0.7847,
      "step": 353050
    },
    {
      "epoch": 3.7380545307297757,
      "grad_norm": 4.1605544090271,
      "learning_rate": 3.131717128943468e-05,
      "loss": 0.7947,
      "step": 353100
    },
    {
      "epoch": 3.7385838525097794,
      "grad_norm": 4.296472549438477,
      "learning_rate": 3.1314524666525515e-05,
      "loss": 0.7835,
      "step": 353150
    },
    {
      "epoch": 3.7391131742897823,
      "grad_norm": 4.225498676300049,
      "learning_rate": 3.131187804361635e-05,
      "loss": 0.7745,
      "step": 353200
    },
    {
      "epoch": 3.739642496069786,
      "grad_norm": 4.117544651031494,
      "learning_rate": 3.130923142070718e-05,
      "loss": 0.772,
      "step": 353250
    },
    {
      "epoch": 3.740171817849789,
      "grad_norm": 4.38542366027832,
      "learning_rate": 3.130658479779801e-05,
      "loss": 0.7752,
      "step": 353300
    },
    {
      "epoch": 3.7407011396297922,
      "grad_norm": 3.847524404525757,
      "learning_rate": 3.130393817488884e-05,
      "loss": 0.7915,
      "step": 353350
    },
    {
      "epoch": 3.7412304614097955,
      "grad_norm": 4.150177478790283,
      "learning_rate": 3.130129155197968e-05,
      "loss": 0.7804,
      "step": 353400
    },
    {
      "epoch": 3.741759783189799,
      "grad_norm": 3.971996545791626,
      "learning_rate": 3.1298644929070506e-05,
      "loss": 0.7864,
      "step": 353450
    },
    {
      "epoch": 3.742289104969802,
      "grad_norm": 4.076145648956299,
      "learning_rate": 3.129599830616134e-05,
      "loss": 0.7852,
      "step": 353500
    },
    {
      "epoch": 3.742289104969802,
      "eval_loss": 0.5500530004501343,
      "eval_runtime": 46.4877,
      "eval_samples_per_second": 3612.354,
      "eval_steps_per_second": 451.56,
      "step": 353500
    },
    {
      "epoch": 3.7428184267498055,
      "grad_norm": 4.036370277404785,
      "learning_rate": 3.129335168325217e-05,
      "loss": 0.7871,
      "step": 353550
    },
    {
      "epoch": 3.743347748529809,
      "grad_norm": 4.132560729980469,
      "learning_rate": 3.129070506034301e-05,
      "loss": 0.7862,
      "step": 353600
    },
    {
      "epoch": 3.743877070309812,
      "grad_norm": 4.672184944152832,
      "learning_rate": 3.1288058437433836e-05,
      "loss": 0.7764,
      "step": 353650
    },
    {
      "epoch": 3.7444063920898154,
      "grad_norm": 4.369710922241211,
      "learning_rate": 3.128541181452467e-05,
      "loss": 0.7844,
      "step": 353700
    },
    {
      "epoch": 3.7449357138698187,
      "grad_norm": 4.13651180267334,
      "learning_rate": 3.12827651916155e-05,
      "loss": 0.7872,
      "step": 353750
    },
    {
      "epoch": 3.745465035649822,
      "grad_norm": 4.1320109367370605,
      "learning_rate": 3.128011856870633e-05,
      "loss": 0.7839,
      "step": 353800
    },
    {
      "epoch": 3.745994357429825,
      "grad_norm": 4.443977355957031,
      "learning_rate": 3.1277471945797166e-05,
      "loss": 0.7881,
      "step": 353850
    },
    {
      "epoch": 3.7465236792098287,
      "grad_norm": 4.307331562042236,
      "learning_rate": 3.127482532288799e-05,
      "loss": 0.7907,
      "step": 353900
    },
    {
      "epoch": 3.7470530009898315,
      "grad_norm": 3.886432647705078,
      "learning_rate": 3.127217869997883e-05,
      "loss": 0.7803,
      "step": 353950
    },
    {
      "epoch": 3.7475823227698353,
      "grad_norm": 4.0170745849609375,
      "learning_rate": 3.126953207706966e-05,
      "loss": 0.7754,
      "step": 354000
    },
    {
      "epoch": 3.7475823227698353,
      "eval_loss": 0.5507346987724304,
      "eval_runtime": 46.5084,
      "eval_samples_per_second": 3610.745,
      "eval_steps_per_second": 451.359,
      "step": 354000
    },
    {
      "epoch": 3.748111644549838,
      "grad_norm": 4.442014217376709,
      "learning_rate": 3.1266885454160495e-05,
      "loss": 0.7984,
      "step": 354050
    },
    {
      "epoch": 3.7486409663298415,
      "grad_norm": 4.601709842681885,
      "learning_rate": 3.126423883125132e-05,
      "loss": 0.781,
      "step": 354100
    },
    {
      "epoch": 3.7491702881098448,
      "grad_norm": 4.282792091369629,
      "learning_rate": 3.126159220834216e-05,
      "loss": 0.7911,
      "step": 354150
    },
    {
      "epoch": 3.749699609889848,
      "grad_norm": 4.388281345367432,
      "learning_rate": 3.125894558543299e-05,
      "loss": 0.7891,
      "step": 354200
    },
    {
      "epoch": 3.7502289316698514,
      "grad_norm": 4.098182201385498,
      "learning_rate": 3.1256298962523825e-05,
      "loss": 0.7991,
      "step": 354250
    },
    {
      "epoch": 3.7507582534498547,
      "grad_norm": 4.109612941741943,
      "learning_rate": 3.125365233961465e-05,
      "loss": 0.794,
      "step": 354300
    },
    {
      "epoch": 3.751287575229858,
      "grad_norm": 4.1579670906066895,
      "learning_rate": 3.1251005716705486e-05,
      "loss": 0.7872,
      "step": 354350
    },
    {
      "epoch": 3.7518168970098613,
      "grad_norm": 3.8662734031677246,
      "learning_rate": 3.12484120262545e-05,
      "loss": 0.7841,
      "step": 354400
    },
    {
      "epoch": 3.7523462187898646,
      "grad_norm": 3.5896239280700684,
      "learning_rate": 3.1245765403345335e-05,
      "loss": 0.7785,
      "step": 354450
    },
    {
      "epoch": 3.752875540569868,
      "grad_norm": 4.119807720184326,
      "learning_rate": 3.124311878043616e-05,
      "loss": 0.7917,
      "step": 354500
    },
    {
      "epoch": 3.752875540569868,
      "eval_loss": 0.5491458773612976,
      "eval_runtime": 46.5755,
      "eval_samples_per_second": 3605.548,
      "eval_steps_per_second": 450.71,
      "step": 354500
    },
    {
      "epoch": 3.7534048623498713,
      "grad_norm": 4.221850395202637,
      "learning_rate": 3.1240472157527e-05,
      "loss": 0.7746,
      "step": 354550
    },
    {
      "epoch": 3.753934184129874,
      "grad_norm": 4.285836696624756,
      "learning_rate": 3.123782553461783e-05,
      "loss": 0.7883,
      "step": 354600
    },
    {
      "epoch": 3.754463505909878,
      "grad_norm": 4.175177574157715,
      "learning_rate": 3.1235178911708665e-05,
      "loss": 0.7946,
      "step": 354650
    },
    {
      "epoch": 3.7549928276898807,
      "grad_norm": 4.334564685821533,
      "learning_rate": 3.123253228879949e-05,
      "loss": 0.788,
      "step": 354700
    },
    {
      "epoch": 3.7555221494698845,
      "grad_norm": 3.718247890472412,
      "learning_rate": 3.1229885665890326e-05,
      "loss": 0.778,
      "step": 354750
    },
    {
      "epoch": 3.7560514712498874,
      "grad_norm": 4.280166149139404,
      "learning_rate": 3.122723904298116e-05,
      "loss": 0.7723,
      "step": 354800
    },
    {
      "epoch": 3.7565807930298907,
      "grad_norm": 4.413830280303955,
      "learning_rate": 3.122459242007199e-05,
      "loss": 0.788,
      "step": 354850
    },
    {
      "epoch": 3.757110114809894,
      "grad_norm": 3.856436014175415,
      "learning_rate": 3.122194579716282e-05,
      "loss": 0.7763,
      "step": 354900
    },
    {
      "epoch": 3.7576394365898973,
      "grad_norm": 3.9746012687683105,
      "learning_rate": 3.121929917425365e-05,
      "loss": 0.7807,
      "step": 354950
    },
    {
      "epoch": 3.7581687583699006,
      "grad_norm": 4.500844955444336,
      "learning_rate": 3.121665255134449e-05,
      "loss": 0.7935,
      "step": 355000
    },
    {
      "epoch": 3.7581687583699006,
      "eval_loss": 0.5502963662147522,
      "eval_runtime": 46.4946,
      "eval_samples_per_second": 3611.819,
      "eval_steps_per_second": 451.494,
      "step": 355000
    },
    {
      "epoch": 3.758698080149904,
      "grad_norm": 4.1135573387146,
      "learning_rate": 3.121400592843532e-05,
      "loss": 0.7713,
      "step": 355050
    },
    {
      "epoch": 3.7592274019299072,
      "grad_norm": 3.888669013977051,
      "learning_rate": 3.121135930552615e-05,
      "loss": 0.7827,
      "step": 355100
    },
    {
      "epoch": 3.7597567237099105,
      "grad_norm": 4.078571796417236,
      "learning_rate": 3.120871268261698e-05,
      "loss": 0.7924,
      "step": 355150
    },
    {
      "epoch": 3.760286045489914,
      "grad_norm": 4.481532573699951,
      "learning_rate": 3.120606605970782e-05,
      "loss": 0.7777,
      "step": 355200
    },
    {
      "epoch": 3.760815367269917,
      "grad_norm": 4.4030632972717285,
      "learning_rate": 3.120341943679865e-05,
      "loss": 0.7929,
      "step": 355250
    },
    {
      "epoch": 3.7613446890499205,
      "grad_norm": 3.678053140640259,
      "learning_rate": 3.120077281388948e-05,
      "loss": 0.7828,
      "step": 355300
    },
    {
      "epoch": 3.7618740108299233,
      "grad_norm": 3.9467034339904785,
      "learning_rate": 3.119812619098031e-05,
      "loss": 0.79,
      "step": 355350
    },
    {
      "epoch": 3.762403332609927,
      "grad_norm": 4.554342746734619,
      "learning_rate": 3.119547956807114e-05,
      "loss": 0.796,
      "step": 355400
    },
    {
      "epoch": 3.76293265438993,
      "grad_norm": 4.4179182052612305,
      "learning_rate": 3.1192832945161977e-05,
      "loss": 0.772,
      "step": 355450
    },
    {
      "epoch": 3.7634619761699337,
      "grad_norm": 3.858011245727539,
      "learning_rate": 3.1190186322252804e-05,
      "loss": 0.7727,
      "step": 355500
    },
    {
      "epoch": 3.7634619761699337,
      "eval_loss": 0.5469196438789368,
      "eval_runtime": 46.8974,
      "eval_samples_per_second": 3580.794,
      "eval_steps_per_second": 447.615,
      "step": 355500
    },
    {
      "epoch": 3.7639912979499366,
      "grad_norm": 3.8371386528015137,
      "learning_rate": 3.118753969934364e-05,
      "loss": 0.7841,
      "step": 355550
    },
    {
      "epoch": 3.76452061972994,
      "grad_norm": 3.9908783435821533,
      "learning_rate": 3.118489307643447e-05,
      "loss": 0.7855,
      "step": 355600
    },
    {
      "epoch": 3.765049941509943,
      "grad_norm": 4.102477550506592,
      "learning_rate": 3.1182246453525306e-05,
      "loss": 0.7859,
      "step": 355650
    },
    {
      "epoch": 3.7655792632899465,
      "grad_norm": 4.448387622833252,
      "learning_rate": 3.1179599830616133e-05,
      "loss": 0.7931,
      "step": 355700
    },
    {
      "epoch": 3.76610858506995,
      "grad_norm": 4.106377601623535,
      "learning_rate": 3.117695320770697e-05,
      "loss": 0.785,
      "step": 355750
    },
    {
      "epoch": 3.766637906849953,
      "grad_norm": 4.187577724456787,
      "learning_rate": 3.11743065847978e-05,
      "loss": 0.7905,
      "step": 355800
    },
    {
      "epoch": 3.7671672286299565,
      "grad_norm": 4.057387351989746,
      "learning_rate": 3.1171659961888636e-05,
      "loss": 0.7918,
      "step": 355850
    },
    {
      "epoch": 3.7676965504099598,
      "grad_norm": 4.128992080688477,
      "learning_rate": 3.116901333897946e-05,
      "loss": 0.7923,
      "step": 355900
    },
    {
      "epoch": 3.768225872189963,
      "grad_norm": 4.512448310852051,
      "learning_rate": 3.11663667160703e-05,
      "loss": 0.7825,
      "step": 355950
    },
    {
      "epoch": 3.7687551939699664,
      "grad_norm": 3.6248490810394287,
      "learning_rate": 3.116372009316113e-05,
      "loss": 0.7773,
      "step": 356000
    },
    {
      "epoch": 3.7687551939699664,
      "eval_loss": 0.5493301749229431,
      "eval_runtime": 46.759,
      "eval_samples_per_second": 3591.391,
      "eval_steps_per_second": 448.94,
      "step": 356000
    },
    {
      "epoch": 3.7692845157499697,
      "grad_norm": 4.272589206695557,
      "learning_rate": 3.116107347025196e-05,
      "loss": 0.7818,
      "step": 356050
    },
    {
      "epoch": 3.769813837529973,
      "grad_norm": 4.461773872375488,
      "learning_rate": 3.115842684734279e-05,
      "loss": 0.789,
      "step": 356100
    },
    {
      "epoch": 3.7703431593099763,
      "grad_norm": 3.9877772331237793,
      "learning_rate": 3.115578022443362e-05,
      "loss": 0.7938,
      "step": 356150
    },
    {
      "epoch": 3.770872481089979,
      "grad_norm": 4.134486675262451,
      "learning_rate": 3.115313360152446e-05,
      "loss": 0.7796,
      "step": 356200
    },
    {
      "epoch": 3.771401802869983,
      "grad_norm": 3.987548589706421,
      "learning_rate": 3.115048697861529e-05,
      "loss": 0.7769,
      "step": 356250
    },
    {
      "epoch": 3.771931124649986,
      "grad_norm": 3.7662160396575928,
      "learning_rate": 3.114784035570612e-05,
      "loss": 0.7952,
      "step": 356300
    },
    {
      "epoch": 3.772460446429989,
      "grad_norm": 3.9245519638061523,
      "learning_rate": 3.114519373279695e-05,
      "loss": 0.7802,
      "step": 356350
    },
    {
      "epoch": 3.7729897682099924,
      "grad_norm": 4.327670574188232,
      "learning_rate": 3.114260004234597e-05,
      "loss": 0.7979,
      "step": 356400
    },
    {
      "epoch": 3.7735190899899957,
      "grad_norm": 4.126080513000488,
      "learning_rate": 3.11399534194368e-05,
      "loss": 0.7899,
      "step": 356450
    },
    {
      "epoch": 3.774048411769999,
      "grad_norm": 3.733386754989624,
      "learning_rate": 3.113730679652763e-05,
      "loss": 0.775,
      "step": 356500
    },
    {
      "epoch": 3.774048411769999,
      "eval_loss": 0.5506068468093872,
      "eval_runtime": 46.6147,
      "eval_samples_per_second": 3602.509,
      "eval_steps_per_second": 450.33,
      "step": 356500
    },
    {
      "epoch": 3.7745777335500024,
      "grad_norm": 4.420312881469727,
      "learning_rate": 3.113466017361846e-05,
      "loss": 0.784,
      "step": 356550
    },
    {
      "epoch": 3.7751070553300057,
      "grad_norm": 4.096879005432129,
      "learning_rate": 3.11320135507093e-05,
      "loss": 0.7816,
      "step": 356600
    },
    {
      "epoch": 3.775636377110009,
      "grad_norm": 4.443553447723389,
      "learning_rate": 3.112936692780013e-05,
      "loss": 0.7838,
      "step": 356650
    },
    {
      "epoch": 3.7761656988900123,
      "grad_norm": 4.273377895355225,
      "learning_rate": 3.112672030489096e-05,
      "loss": 0.7843,
      "step": 356700
    },
    {
      "epoch": 3.7766950206700156,
      "grad_norm": 3.8087921142578125,
      "learning_rate": 3.112407368198179e-05,
      "loss": 0.7832,
      "step": 356750
    },
    {
      "epoch": 3.777224342450019,
      "grad_norm": 3.9043455123901367,
      "learning_rate": 3.112142705907263e-05,
      "loss": 0.7706,
      "step": 356800
    },
    {
      "epoch": 3.7777536642300222,
      "grad_norm": 4.561562538146973,
      "learning_rate": 3.111878043616346e-05,
      "loss": 0.797,
      "step": 356850
    },
    {
      "epoch": 3.7782829860100255,
      "grad_norm": 3.969210624694824,
      "learning_rate": 3.111613381325429e-05,
      "loss": 0.7797,
      "step": 356900
    },
    {
      "epoch": 3.7788123077900284,
      "grad_norm": 4.137920379638672,
      "learning_rate": 3.111348719034512e-05,
      "loss": 0.782,
      "step": 356950
    },
    {
      "epoch": 3.779341629570032,
      "grad_norm": 4.1688947677612305,
      "learning_rate": 3.111084056743595e-05,
      "loss": 0.7892,
      "step": 357000
    },
    {
      "epoch": 3.779341629570032,
      "eval_loss": 0.547099232673645,
      "eval_runtime": 46.6275,
      "eval_samples_per_second": 3601.521,
      "eval_steps_per_second": 450.206,
      "step": 357000
    },
    {
      "epoch": 3.779870951350035,
      "grad_norm": 3.873948812484741,
      "learning_rate": 3.110819394452679e-05,
      "loss": 0.7775,
      "step": 357050
    },
    {
      "epoch": 3.7804002731300383,
      "grad_norm": 4.265421390533447,
      "learning_rate": 3.1105547321617615e-05,
      "loss": 0.7723,
      "step": 357100
    },
    {
      "epoch": 3.7809295949100417,
      "grad_norm": 3.998582601547241,
      "learning_rate": 3.110290069870845e-05,
      "loss": 0.7822,
      "step": 357150
    },
    {
      "epoch": 3.781458916690045,
      "grad_norm": 3.8188188076019287,
      "learning_rate": 3.1100254075799276e-05,
      "loss": 0.7986,
      "step": 357200
    },
    {
      "epoch": 3.7819882384700483,
      "grad_norm": 3.846877098083496,
      "learning_rate": 3.109760745289012e-05,
      "loss": 0.7762,
      "step": 357250
    },
    {
      "epoch": 3.7825175602500516,
      "grad_norm": 4.116351127624512,
      "learning_rate": 3.1094960829980944e-05,
      "loss": 0.7741,
      "step": 357300
    },
    {
      "epoch": 3.783046882030055,
      "grad_norm": 4.455377101898193,
      "learning_rate": 3.109231420707178e-05,
      "loss": 0.78,
      "step": 357350
    },
    {
      "epoch": 3.783576203810058,
      "grad_norm": 4.2626543045043945,
      "learning_rate": 3.1089667584162606e-05,
      "loss": 0.7897,
      "step": 357400
    },
    {
      "epoch": 3.7841055255900615,
      "grad_norm": 3.900514602661133,
      "learning_rate": 3.108702096125345e-05,
      "loss": 0.7856,
      "step": 357450
    },
    {
      "epoch": 3.784634847370065,
      "grad_norm": 4.176992893218994,
      "learning_rate": 3.1084374338344274e-05,
      "loss": 0.7845,
      "step": 357500
    },
    {
      "epoch": 3.784634847370065,
      "eval_loss": 0.5493287444114685,
      "eval_runtime": 46.6169,
      "eval_samples_per_second": 3602.345,
      "eval_steps_per_second": 450.309,
      "step": 357500
    },
    {
      "epoch": 3.785164169150068,
      "grad_norm": 3.939380645751953,
      "learning_rate": 3.108172771543511e-05,
      "loss": 0.7769,
      "step": 357550
    },
    {
      "epoch": 3.7856934909300715,
      "grad_norm": 3.7427356243133545,
      "learning_rate": 3.1079081092525935e-05,
      "loss": 0.7881,
      "step": 357600
    },
    {
      "epoch": 3.7862228127100748,
      "grad_norm": 4.008701801300049,
      "learning_rate": 3.107643446961677e-05,
      "loss": 0.7756,
      "step": 357650
    },
    {
      "epoch": 3.7867521344900776,
      "grad_norm": 4.1813883781433105,
      "learning_rate": 3.1073787846707604e-05,
      "loss": 0.7846,
      "step": 357700
    },
    {
      "epoch": 3.7872814562700814,
      "grad_norm": 4.337357997894287,
      "learning_rate": 3.107114122379843e-05,
      "loss": 0.7884,
      "step": 357750
    },
    {
      "epoch": 3.7878107780500843,
      "grad_norm": 4.119193077087402,
      "learning_rate": 3.1068494600889265e-05,
      "loss": 0.7857,
      "step": 357800
    },
    {
      "epoch": 3.7883400998300876,
      "grad_norm": 4.040599822998047,
      "learning_rate": 3.10658479779801e-05,
      "loss": 0.7864,
      "step": 357850
    },
    {
      "epoch": 3.788869421610091,
      "grad_norm": 4.287855625152588,
      "learning_rate": 3.106320135507093e-05,
      "loss": 0.7763,
      "step": 357900
    },
    {
      "epoch": 3.789398743390094,
      "grad_norm": 4.358197212219238,
      "learning_rate": 3.106055473216176e-05,
      "loss": 0.7757,
      "step": 357950
    },
    {
      "epoch": 3.7899280651700975,
      "grad_norm": 4.263533115386963,
      "learning_rate": 3.1057908109252595e-05,
      "loss": 0.7876,
      "step": 358000
    },
    {
      "epoch": 3.7899280651700975,
      "eval_loss": 0.5502474308013916,
      "eval_runtime": 46.5533,
      "eval_samples_per_second": 3607.265,
      "eval_steps_per_second": 450.924,
      "step": 358000
    },
    {
      "epoch": 3.790457386950101,
      "grad_norm": 4.122011661529541,
      "learning_rate": 3.105526148634343e-05,
      "loss": 0.7842,
      "step": 358050
    },
    {
      "epoch": 3.790986708730104,
      "grad_norm": 4.206130504608154,
      "learning_rate": 3.105261486343426e-05,
      "loss": 0.7821,
      "step": 358100
    },
    {
      "epoch": 3.7915160305101074,
      "grad_norm": 4.161717414855957,
      "learning_rate": 3.104996824052509e-05,
      "loss": 0.7825,
      "step": 358150
    },
    {
      "epoch": 3.7920453522901107,
      "grad_norm": 4.442805767059326,
      "learning_rate": 3.1047321617615924e-05,
      "loss": 0.7601,
      "step": 358200
    },
    {
      "epoch": 3.792574674070114,
      "grad_norm": 3.9012644290924072,
      "learning_rate": 3.104467499470676e-05,
      "loss": 0.7857,
      "step": 358250
    },
    {
      "epoch": 3.7931039958501174,
      "grad_norm": 4.298882961273193,
      "learning_rate": 3.1042028371797586e-05,
      "loss": 0.776,
      "step": 358300
    },
    {
      "epoch": 3.7936333176301207,
      "grad_norm": 4.123044013977051,
      "learning_rate": 3.103938174888842e-05,
      "loss": 0.7895,
      "step": 358350
    },
    {
      "epoch": 3.794162639410124,
      "grad_norm": 3.950397491455078,
      "learning_rate": 3.1036788058437434e-05,
      "loss": 0.7828,
      "step": 358400
    },
    {
      "epoch": 3.794691961190127,
      "grad_norm": 4.029148101806641,
      "learning_rate": 3.103414143552827e-05,
      "loss": 0.778,
      "step": 358450
    },
    {
      "epoch": 3.7952212829701306,
      "grad_norm": 3.9768216609954834,
      "learning_rate": 3.10314948126191e-05,
      "loss": 0.7743,
      "step": 358500
    },
    {
      "epoch": 3.7952212829701306,
      "eval_loss": 0.5461209416389465,
      "eval_runtime": 46.5695,
      "eval_samples_per_second": 3606.008,
      "eval_steps_per_second": 450.767,
      "step": 358500
    },
    {
      "epoch": 3.7957506047501335,
      "grad_norm": 4.325606822967529,
      "learning_rate": 3.102884818970993e-05,
      "loss": 0.7811,
      "step": 358550
    },
    {
      "epoch": 3.796279926530137,
      "grad_norm": 3.8835458755493164,
      "learning_rate": 3.1026201566800764e-05,
      "loss": 0.7836,
      "step": 358600
    },
    {
      "epoch": 3.79680924831014,
      "grad_norm": 4.716806411743164,
      "learning_rate": 3.10235549438916e-05,
      "loss": 0.7939,
      "step": 358650
    },
    {
      "epoch": 3.7973385700901434,
      "grad_norm": 4.255497932434082,
      "learning_rate": 3.1020908320982426e-05,
      "loss": 0.7827,
      "step": 358700
    },
    {
      "epoch": 3.7978678918701467,
      "grad_norm": 4.342439651489258,
      "learning_rate": 3.101826169807326e-05,
      "loss": 0.7839,
      "step": 358750
    },
    {
      "epoch": 3.79839721365015,
      "grad_norm": 4.039286136627197,
      "learning_rate": 3.101561507516409e-05,
      "loss": 0.7785,
      "step": 358800
    },
    {
      "epoch": 3.7989265354301534,
      "grad_norm": 3.908086061477661,
      "learning_rate": 3.101296845225493e-05,
      "loss": 0.7955,
      "step": 358850
    },
    {
      "epoch": 3.7994558572101567,
      "grad_norm": 3.943450689315796,
      "learning_rate": 3.1010321829345755e-05,
      "loss": 0.7822,
      "step": 358900
    },
    {
      "epoch": 3.79998517899016,
      "grad_norm": 4.145578861236572,
      "learning_rate": 3.100767520643659e-05,
      "loss": 0.7776,
      "step": 358950
    },
    {
      "epoch": 3.8005145007701633,
      "grad_norm": 4.164817810058594,
      "learning_rate": 3.1005028583527417e-05,
      "loss": 0.7883,
      "step": 359000
    },
    {
      "epoch": 3.8005145007701633,
      "eval_loss": 0.545859158039093,
      "eval_runtime": 46.6419,
      "eval_samples_per_second": 3600.412,
      "eval_steps_per_second": 450.068,
      "step": 359000
    },
    {
      "epoch": 3.8010438225501666,
      "grad_norm": 4.29702091217041,
      "learning_rate": 3.100238196061826e-05,
      "loss": 0.7774,
      "step": 359050
    },
    {
      "epoch": 3.80157314433017,
      "grad_norm": 4.173527240753174,
      "learning_rate": 3.0999735337709085e-05,
      "loss": 0.7847,
      "step": 359100
    },
    {
      "epoch": 3.802102466110173,
      "grad_norm": 4.162288665771484,
      "learning_rate": 3.099708871479992e-05,
      "loss": 0.7905,
      "step": 359150
    },
    {
      "epoch": 3.802631787890176,
      "grad_norm": 4.085897445678711,
      "learning_rate": 3.0994442091890746e-05,
      "loss": 0.7717,
      "step": 359200
    },
    {
      "epoch": 3.80316110967018,
      "grad_norm": 3.9207305908203125,
      "learning_rate": 3.099179546898158e-05,
      "loss": 0.7744,
      "step": 359250
    },
    {
      "epoch": 3.8036904314501827,
      "grad_norm": 4.3681440353393555,
      "learning_rate": 3.0989148846072414e-05,
      "loss": 0.7675,
      "step": 359300
    },
    {
      "epoch": 3.804219753230186,
      "grad_norm": 3.8608341217041016,
      "learning_rate": 3.098650222316324e-05,
      "loss": 0.7735,
      "step": 359350
    },
    {
      "epoch": 3.8047490750101893,
      "grad_norm": 3.8278307914733887,
      "learning_rate": 3.0983855600254076e-05,
      "loss": 0.7803,
      "step": 359400
    },
    {
      "epoch": 3.8052783967901926,
      "grad_norm": 4.526639461517334,
      "learning_rate": 3.098120897734491e-05,
      "loss": 0.7845,
      "step": 359450
    },
    {
      "epoch": 3.805807718570196,
      "grad_norm": 3.717341899871826,
      "learning_rate": 3.0978562354435744e-05,
      "loss": 0.7831,
      "step": 359500
    },
    {
      "epoch": 3.805807718570196,
      "eval_loss": 0.5472655296325684,
      "eval_runtime": 46.6153,
      "eval_samples_per_second": 3602.466,
      "eval_steps_per_second": 450.324,
      "step": 359500
    },
    {
      "epoch": 3.8063370403501993,
      "grad_norm": 4.462911128997803,
      "learning_rate": 3.097596866398476e-05,
      "loss": 0.7921,
      "step": 359550
    },
    {
      "epoch": 3.8068663621302026,
      "grad_norm": 4.15854549407959,
      "learning_rate": 3.0973322041075586e-05,
      "loss": 0.782,
      "step": 359600
    },
    {
      "epoch": 3.807395683910206,
      "grad_norm": 4.257749557495117,
      "learning_rate": 3.097067541816642e-05,
      "loss": 0.7777,
      "step": 359650
    },
    {
      "epoch": 3.807925005690209,
      "grad_norm": 3.819032907485962,
      "learning_rate": 3.0968028795257254e-05,
      "loss": 0.7761,
      "step": 359700
    },
    {
      "epoch": 3.8084543274702125,
      "grad_norm": 3.952829122543335,
      "learning_rate": 3.096538217234808e-05,
      "loss": 0.7856,
      "step": 359750
    },
    {
      "epoch": 3.808983649250216,
      "grad_norm": 3.7964656352996826,
      "learning_rate": 3.0962735549438916e-05,
      "loss": 0.7867,
      "step": 359800
    },
    {
      "epoch": 3.809512971030219,
      "grad_norm": 4.6185688972473145,
      "learning_rate": 3.096008892652975e-05,
      "loss": 0.7659,
      "step": 359850
    },
    {
      "epoch": 3.8100422928102224,
      "grad_norm": 4.448727607727051,
      "learning_rate": 3.0957442303620584e-05,
      "loss": 0.7839,
      "step": 359900
    },
    {
      "epoch": 3.8105716145902253,
      "grad_norm": 3.9089722633361816,
      "learning_rate": 3.095479568071141e-05,
      "loss": 0.7838,
      "step": 359950
    },
    {
      "epoch": 3.811100936370229,
      "grad_norm": 3.6365528106689453,
      "learning_rate": 3.0952149057802245e-05,
      "loss": 0.7885,
      "step": 360000
    },
    {
      "epoch": 3.811100936370229,
      "eval_loss": 0.5471804738044739,
      "eval_runtime": 46.6149,
      "eval_samples_per_second": 3602.495,
      "eval_steps_per_second": 450.328,
      "step": 360000
    },
    {
      "epoch": 3.811630258150232,
      "grad_norm": 3.9198238849639893,
      "learning_rate": 3.094950243489308e-05,
      "loss": 0.786,
      "step": 360050
    },
    {
      "epoch": 3.8121595799302352,
      "grad_norm": 3.9552953243255615,
      "learning_rate": 3.0946855811983913e-05,
      "loss": 0.7765,
      "step": 360100
    },
    {
      "epoch": 3.8126889017102386,
      "grad_norm": 4.134573459625244,
      "learning_rate": 3.094420918907474e-05,
      "loss": 0.7806,
      "step": 360150
    },
    {
      "epoch": 3.813218223490242,
      "grad_norm": 4.013362884521484,
      "learning_rate": 3.0941562566165575e-05,
      "loss": 0.7914,
      "step": 360200
    },
    {
      "epoch": 3.813747545270245,
      "grad_norm": 4.135920524597168,
      "learning_rate": 3.093891594325641e-05,
      "loss": 0.7843,
      "step": 360250
    },
    {
      "epoch": 3.8142768670502485,
      "grad_norm": 4.20057487487793,
      "learning_rate": 3.0936269320347236e-05,
      "loss": 0.7798,
      "step": 360300
    },
    {
      "epoch": 3.814806188830252,
      "grad_norm": 4.219293117523193,
      "learning_rate": 3.093362269743807e-05,
      "loss": 0.7737,
      "step": 360350
    },
    {
      "epoch": 3.815335510610255,
      "grad_norm": 3.740769863128662,
      "learning_rate": 3.09309760745289e-05,
      "loss": 0.7806,
      "step": 360400
    },
    {
      "epoch": 3.8158648323902584,
      "grad_norm": 4.285026550292969,
      "learning_rate": 3.092832945161974e-05,
      "loss": 0.7736,
      "step": 360450
    },
    {
      "epoch": 3.8163941541702617,
      "grad_norm": 4.035924911499023,
      "learning_rate": 3.0925682828710566e-05,
      "loss": 0.7844,
      "step": 360500
    },
    {
      "epoch": 3.8163941541702617,
      "eval_loss": 0.5458453297615051,
      "eval_runtime": 46.7038,
      "eval_samples_per_second": 3595.638,
      "eval_steps_per_second": 449.471,
      "step": 360500
    },
    {
      "epoch": 3.816923475950265,
      "grad_norm": 4.280502796173096,
      "learning_rate": 3.09230362058014e-05,
      "loss": 0.7849,
      "step": 360550
    },
    {
      "epoch": 3.8174527977302684,
      "grad_norm": 4.475584030151367,
      "learning_rate": 3.092038958289223e-05,
      "loss": 0.7906,
      "step": 360600
    },
    {
      "epoch": 3.8179821195102717,
      "grad_norm": 4.294877529144287,
      "learning_rate": 3.091774295998306e-05,
      "loss": 0.7821,
      "step": 360650
    },
    {
      "epoch": 3.8185114412902745,
      "grad_norm": 3.9186854362487793,
      "learning_rate": 3.0915096337073896e-05,
      "loss": 0.7709,
      "step": 360700
    },
    {
      "epoch": 3.8190407630702783,
      "grad_norm": 4.163693904876709,
      "learning_rate": 3.091244971416472e-05,
      "loss": 0.7774,
      "step": 360750
    },
    {
      "epoch": 3.819570084850281,
      "grad_norm": 4.143995761871338,
      "learning_rate": 3.090980309125556e-05,
      "loss": 0.7871,
      "step": 360800
    },
    {
      "epoch": 3.8200994066302845,
      "grad_norm": 4.0440473556518555,
      "learning_rate": 3.090715646834639e-05,
      "loss": 0.7799,
      "step": 360850
    },
    {
      "epoch": 3.8206287284102878,
      "grad_norm": 4.020531177520752,
      "learning_rate": 3.0904509845437225e-05,
      "loss": 0.7766,
      "step": 360900
    },
    {
      "epoch": 3.821158050190291,
      "grad_norm": 3.805471897125244,
      "learning_rate": 3.090186322252805e-05,
      "loss": 0.7894,
      "step": 360950
    },
    {
      "epoch": 3.8216873719702944,
      "grad_norm": 3.8757033348083496,
      "learning_rate": 3.089921659961889e-05,
      "loss": 0.7655,
      "step": 361000
    },
    {
      "epoch": 3.8216873719702944,
      "eval_loss": 0.5437895059585571,
      "eval_runtime": 46.6615,
      "eval_samples_per_second": 3598.9,
      "eval_steps_per_second": 449.879,
      "step": 361000
    },
    {
      "epoch": 3.8222166937502977,
      "grad_norm": 4.2865824699401855,
      "learning_rate": 3.089656997670972e-05,
      "loss": 0.7809,
      "step": 361050
    },
    {
      "epoch": 3.822746015530301,
      "grad_norm": 4.371178150177002,
      "learning_rate": 3.0893923353800555e-05,
      "loss": 0.8029,
      "step": 361100
    },
    {
      "epoch": 3.8232753373103043,
      "grad_norm": 4.036509037017822,
      "learning_rate": 3.089127673089138e-05,
      "loss": 0.7845,
      "step": 361150
    },
    {
      "epoch": 3.8238046590903076,
      "grad_norm": 4.588886737823486,
      "learning_rate": 3.0888630107982216e-05,
      "loss": 0.7736,
      "step": 361200
    },
    {
      "epoch": 3.824333980870311,
      "grad_norm": 3.481384038925171,
      "learning_rate": 3.088598348507305e-05,
      "loss": 0.7916,
      "step": 361250
    },
    {
      "epoch": 3.8248633026503143,
      "grad_norm": 4.650205612182617,
      "learning_rate": 3.088333686216388e-05,
      "loss": 0.7741,
      "step": 361300
    },
    {
      "epoch": 3.8253926244303176,
      "grad_norm": 4.428003311157227,
      "learning_rate": 3.088069023925471e-05,
      "loss": 0.7958,
      "step": 361350
    },
    {
      "epoch": 3.825921946210321,
      "grad_norm": 4.253472328186035,
      "learning_rate": 3.087804361634554e-05,
      "loss": 0.7873,
      "step": 361400
    },
    {
      "epoch": 3.8264512679903238,
      "grad_norm": 3.8533904552459717,
      "learning_rate": 3.087539699343638e-05,
      "loss": 0.7814,
      "step": 361450
    },
    {
      "epoch": 3.8269805897703275,
      "grad_norm": 4.220469951629639,
      "learning_rate": 3.087275037052721e-05,
      "loss": 0.7722,
      "step": 361500
    },
    {
      "epoch": 3.8269805897703275,
      "eval_loss": 0.543695330619812,
      "eval_runtime": 46.474,
      "eval_samples_per_second": 3613.417,
      "eval_steps_per_second": 451.693,
      "step": 361500
    },
    {
      "epoch": 3.8275099115503304,
      "grad_norm": 4.275047779083252,
      "learning_rate": 3.087010374761804e-05,
      "loss": 0.7876,
      "step": 361550
    },
    {
      "epoch": 3.8280392333303337,
      "grad_norm": 3.9379916191101074,
      "learning_rate": 3.086745712470887e-05,
      "loss": 0.7831,
      "step": 361600
    },
    {
      "epoch": 3.828568555110337,
      "grad_norm": 3.954813241958618,
      "learning_rate": 3.086481050179971e-05,
      "loss": 0.7861,
      "step": 361650
    },
    {
      "epoch": 3.8290978768903403,
      "grad_norm": 4.10101318359375,
      "learning_rate": 3.086216387889054e-05,
      "loss": 0.7744,
      "step": 361700
    },
    {
      "epoch": 3.8296271986703436,
      "grad_norm": 3.7830312252044678,
      "learning_rate": 3.085951725598137e-05,
      "loss": 0.7724,
      "step": 361750
    },
    {
      "epoch": 3.830156520450347,
      "grad_norm": 4.332812786102295,
      "learning_rate": 3.08568706330722e-05,
      "loss": 0.777,
      "step": 361800
    },
    {
      "epoch": 3.8306858422303502,
      "grad_norm": 4.01708459854126,
      "learning_rate": 3.085422401016303e-05,
      "loss": 0.7714,
      "step": 361850
    },
    {
      "epoch": 3.8312151640103536,
      "grad_norm": 4.198593616485596,
      "learning_rate": 3.0851577387253867e-05,
      "loss": 0.7794,
      "step": 361900
    },
    {
      "epoch": 3.831744485790357,
      "grad_norm": 4.630792140960693,
      "learning_rate": 3.0848930764344694e-05,
      "loss": 0.7696,
      "step": 361950
    },
    {
      "epoch": 3.83227380757036,
      "grad_norm": 3.9926323890686035,
      "learning_rate": 3.084628414143553e-05,
      "loss": 0.7819,
      "step": 362000
    },
    {
      "epoch": 3.83227380757036,
      "eval_loss": 0.5438128113746643,
      "eval_runtime": 46.6503,
      "eval_samples_per_second": 3599.76,
      "eval_steps_per_second": 449.986,
      "step": 362000
    },
    {
      "epoch": 3.8328031293503635,
      "grad_norm": 4.494129657745361,
      "learning_rate": 3.084363751852636e-05,
      "loss": 0.7759,
      "step": 362050
    },
    {
      "epoch": 3.833332451130367,
      "grad_norm": 4.008256912231445,
      "learning_rate": 3.0840990895617196e-05,
      "loss": 0.7765,
      "step": 362100
    },
    {
      "epoch": 3.83386177291037,
      "grad_norm": 4.552044868469238,
      "learning_rate": 3.0838344272708023e-05,
      "loss": 0.79,
      "step": 362150
    },
    {
      "epoch": 3.834391094690373,
      "grad_norm": 4.360326766967773,
      "learning_rate": 3.083569764979886e-05,
      "loss": 0.7741,
      "step": 362200
    },
    {
      "epoch": 3.8349204164703767,
      "grad_norm": 3.9796886444091797,
      "learning_rate": 3.083305102688969e-05,
      "loss": 0.7847,
      "step": 362250
    },
    {
      "epoch": 3.8354497382503796,
      "grad_norm": 4.326406002044678,
      "learning_rate": 3.0830404403980526e-05,
      "loss": 0.7888,
      "step": 362300
    },
    {
      "epoch": 3.835979060030383,
      "grad_norm": 3.5383293628692627,
      "learning_rate": 3.082775778107135e-05,
      "loss": 0.7782,
      "step": 362350
    },
    {
      "epoch": 3.8365083818103862,
      "grad_norm": 4.39420223236084,
      "learning_rate": 3.082511115816219e-05,
      "loss": 0.7613,
      "step": 362400
    },
    {
      "epoch": 3.8370377035903895,
      "grad_norm": 3.5335452556610107,
      "learning_rate": 3.082246453525302e-05,
      "loss": 0.7794,
      "step": 362450
    },
    {
      "epoch": 3.837567025370393,
      "grad_norm": 4.045769691467285,
      "learning_rate": 3.081981791234385e-05,
      "loss": 0.7746,
      "step": 362500
    },
    {
      "epoch": 3.837567025370393,
      "eval_loss": 0.541388750076294,
      "eval_runtime": 46.5204,
      "eval_samples_per_second": 3609.817,
      "eval_steps_per_second": 451.243,
      "step": 362500
    },
    {
      "epoch": 3.838096347150396,
      "grad_norm": 4.1140947341918945,
      "learning_rate": 3.081717128943468e-05,
      "loss": 0.7982,
      "step": 362550
    },
    {
      "epoch": 3.8386256689303995,
      "grad_norm": 4.635469913482666,
      "learning_rate": 3.081452466652551e-05,
      "loss": 0.7869,
      "step": 362600
    },
    {
      "epoch": 3.839154990710403,
      "grad_norm": 3.953768730163574,
      "learning_rate": 3.081187804361635e-05,
      "loss": 0.7772,
      "step": 362650
    },
    {
      "epoch": 3.839684312490406,
      "grad_norm": 3.801893711090088,
      "learning_rate": 3.080923142070718e-05,
      "loss": 0.7812,
      "step": 362700
    },
    {
      "epoch": 3.8402136342704094,
      "grad_norm": 3.9473493099212646,
      "learning_rate": 3.080658479779801e-05,
      "loss": 0.7661,
      "step": 362750
    },
    {
      "epoch": 3.8407429560504127,
      "grad_norm": 3.555783987045288,
      "learning_rate": 3.080393817488884e-05,
      "loss": 0.7727,
      "step": 362800
    },
    {
      "epoch": 3.841272277830416,
      "grad_norm": 4.451169490814209,
      "learning_rate": 3.080129155197968e-05,
      "loss": 0.7792,
      "step": 362850
    },
    {
      "epoch": 3.8418015996104193,
      "grad_norm": 4.138216495513916,
      "learning_rate": 3.079864492907051e-05,
      "loss": 0.7771,
      "step": 362900
    },
    {
      "epoch": 3.842330921390422,
      "grad_norm": 4.01910924911499,
      "learning_rate": 3.079599830616134e-05,
      "loss": 0.7973,
      "step": 362950
    },
    {
      "epoch": 3.842860243170426,
      "grad_norm": 4.053580284118652,
      "learning_rate": 3.079335168325217e-05,
      "loss": 0.7842,
      "step": 363000
    },
    {
      "epoch": 3.842860243170426,
      "eval_loss": 0.5425832271575928,
      "eval_runtime": 46.5574,
      "eval_samples_per_second": 3606.944,
      "eval_steps_per_second": 450.884,
      "step": 363000
    },
    {
      "epoch": 3.843389564950429,
      "grad_norm": 4.07243013381958,
      "learning_rate": 3.0790705060343003e-05,
      "loss": 0.7835,
      "step": 363050
    },
    {
      "epoch": 3.843918886730432,
      "grad_norm": 4.144949436187744,
      "learning_rate": 3.078805843743384e-05,
      "loss": 0.776,
      "step": 363100
    },
    {
      "epoch": 3.8444482085104354,
      "grad_norm": 4.270769119262695,
      "learning_rate": 3.0785411814524665e-05,
      "loss": 0.7759,
      "step": 363150
    },
    {
      "epoch": 3.8449775302904388,
      "grad_norm": 4.524953365325928,
      "learning_rate": 3.07827651916155e-05,
      "loss": 0.776,
      "step": 363200
    },
    {
      "epoch": 3.845506852070442,
      "grad_norm": 3.696672201156616,
      "learning_rate": 3.078011856870633e-05,
      "loss": 0.7708,
      "step": 363250
    },
    {
      "epoch": 3.8460361738504454,
      "grad_norm": 4.162593364715576,
      "learning_rate": 3.077747194579717e-05,
      "loss": 0.7811,
      "step": 363300
    },
    {
      "epoch": 3.8465654956304487,
      "grad_norm": 3.887925148010254,
      "learning_rate": 3.0774825322887994e-05,
      "loss": 0.7933,
      "step": 363350
    },
    {
      "epoch": 3.847094817410452,
      "grad_norm": 4.210644245147705,
      "learning_rate": 3.077217869997883e-05,
      "loss": 0.7626,
      "step": 363400
    },
    {
      "epoch": 3.8476241391904553,
      "grad_norm": 4.454006195068359,
      "learning_rate": 3.076953207706966e-05,
      "loss": 0.7826,
      "step": 363450
    },
    {
      "epoch": 3.8481534609704586,
      "grad_norm": 4.426251411437988,
      "learning_rate": 3.07668854541605e-05,
      "loss": 0.7957,
      "step": 363500
    },
    {
      "epoch": 3.8481534609704586,
      "eval_loss": 0.542690098285675,
      "eval_runtime": 46.5819,
      "eval_samples_per_second": 3605.05,
      "eval_steps_per_second": 450.647,
      "step": 363500
    },
    {
      "epoch": 3.848682782750462,
      "grad_norm": 4.35370397567749,
      "learning_rate": 3.0764291763709505e-05,
      "loss": 0.7765,
      "step": 363550
    },
    {
      "epoch": 3.8492121045304653,
      "grad_norm": 4.152710914611816,
      "learning_rate": 3.076164514080034e-05,
      "loss": 0.7699,
      "step": 363600
    },
    {
      "epoch": 3.8497414263104686,
      "grad_norm": 4.274779319763184,
      "learning_rate": 3.075899851789117e-05,
      "loss": 0.7804,
      "step": 363650
    },
    {
      "epoch": 3.8502707480904714,
      "grad_norm": 4.037847995758057,
      "learning_rate": 3.075635189498201e-05,
      "loss": 0.7741,
      "step": 363700
    },
    {
      "epoch": 3.850800069870475,
      "grad_norm": 4.180673599243164,
      "learning_rate": 3.0753705272072834e-05,
      "loss": 0.7903,
      "step": 363750
    },
    {
      "epoch": 3.851329391650478,
      "grad_norm": 4.326624870300293,
      "learning_rate": 3.075105864916367e-05,
      "loss": 0.7879,
      "step": 363800
    },
    {
      "epoch": 3.8518587134304814,
      "grad_norm": 4.425285339355469,
      "learning_rate": 3.07484120262545e-05,
      "loss": 0.7854,
      "step": 363850
    },
    {
      "epoch": 3.8523880352104847,
      "grad_norm": 4.309463024139404,
      "learning_rate": 3.0745765403345337e-05,
      "loss": 0.7825,
      "step": 363900
    },
    {
      "epoch": 3.852917356990488,
      "grad_norm": 4.216745376586914,
      "learning_rate": 3.0743118780436164e-05,
      "loss": 0.7649,
      "step": 363950
    },
    {
      "epoch": 3.8534466787704913,
      "grad_norm": 4.491228103637695,
      "learning_rate": 3.0740472157527e-05,
      "loss": 0.7681,
      "step": 364000
    },
    {
      "epoch": 3.8534466787704913,
      "eval_loss": 0.5410069227218628,
      "eval_runtime": 46.4958,
      "eval_samples_per_second": 3611.727,
      "eval_steps_per_second": 451.482,
      "step": 364000
    },
    {
      "epoch": 3.8539760005504946,
      "grad_norm": 4.318782329559326,
      "learning_rate": 3.073782553461783e-05,
      "loss": 0.7878,
      "step": 364050
    },
    {
      "epoch": 3.854505322330498,
      "grad_norm": 4.315195083618164,
      "learning_rate": 3.073517891170866e-05,
      "loss": 0.7782,
      "step": 364100
    },
    {
      "epoch": 3.8550346441105012,
      "grad_norm": 4.132615566253662,
      "learning_rate": 3.0732532288799494e-05,
      "loss": 0.775,
      "step": 364150
    },
    {
      "epoch": 3.8555639658905045,
      "grad_norm": 4.445636749267578,
      "learning_rate": 3.072988566589032e-05,
      "loss": 0.7756,
      "step": 364200
    },
    {
      "epoch": 3.856093287670508,
      "grad_norm": 3.9759957790374756,
      "learning_rate": 3.072723904298116e-05,
      "loss": 0.7738,
      "step": 364250
    },
    {
      "epoch": 3.856622609450511,
      "grad_norm": 4.610811710357666,
      "learning_rate": 3.072459242007199e-05,
      "loss": 0.781,
      "step": 364300
    },
    {
      "epoch": 3.8571519312305145,
      "grad_norm": 4.418332099914551,
      "learning_rate": 3.072194579716282e-05,
      "loss": 0.7722,
      "step": 364350
    },
    {
      "epoch": 3.857681253010518,
      "grad_norm": 3.886188268661499,
      "learning_rate": 3.071929917425365e-05,
      "loss": 0.7884,
      "step": 364400
    },
    {
      "epoch": 3.8582105747905207,
      "grad_norm": 4.034396171569824,
      "learning_rate": 3.071665255134449e-05,
      "loss": 0.7743,
      "step": 364450
    },
    {
      "epoch": 3.8587398965705244,
      "grad_norm": 3.973555326461792,
      "learning_rate": 3.071400592843532e-05,
      "loss": 0.7743,
      "step": 364500
    },
    {
      "epoch": 3.8587398965705244,
      "eval_loss": 0.5408996343612671,
      "eval_runtime": 46.4924,
      "eval_samples_per_second": 3611.989,
      "eval_steps_per_second": 451.515,
      "step": 364500
    },
    {
      "epoch": 3.8592692183505273,
      "grad_norm": 3.6493489742279053,
      "learning_rate": 3.071135930552615e-05,
      "loss": 0.7824,
      "step": 364550
    },
    {
      "epoch": 3.8597985401305306,
      "grad_norm": 4.174828052520752,
      "learning_rate": 3.070871268261698e-05,
      "loss": 0.7702,
      "step": 364600
    },
    {
      "epoch": 3.860327861910534,
      "grad_norm": 3.953941822052002,
      "learning_rate": 3.0706066059707814e-05,
      "loss": 0.7778,
      "step": 364650
    },
    {
      "epoch": 3.860857183690537,
      "grad_norm": 4.1400017738342285,
      "learning_rate": 3.070341943679865e-05,
      "loss": 0.788,
      "step": 364700
    },
    {
      "epoch": 3.8613865054705405,
      "grad_norm": 3.8259103298187256,
      "learning_rate": 3.0700772813889476e-05,
      "loss": 0.7797,
      "step": 364750
    },
    {
      "epoch": 3.861915827250544,
      "grad_norm": 4.441603660583496,
      "learning_rate": 3.069812619098031e-05,
      "loss": 0.7758,
      "step": 364800
    },
    {
      "epoch": 3.862445149030547,
      "grad_norm": 4.230831623077393,
      "learning_rate": 3.0695479568071144e-05,
      "loss": 0.7654,
      "step": 364850
    },
    {
      "epoch": 3.8629744708105505,
      "grad_norm": 3.8450264930725098,
      "learning_rate": 3.069283294516198e-05,
      "loss": 0.7935,
      "step": 364900
    },
    {
      "epoch": 3.8635037925905538,
      "grad_norm": 4.2890119552612305,
      "learning_rate": 3.0690186322252805e-05,
      "loss": 0.7783,
      "step": 364950
    },
    {
      "epoch": 3.864033114370557,
      "grad_norm": 4.274104118347168,
      "learning_rate": 3.068753969934364e-05,
      "loss": 0.778,
      "step": 365000
    },
    {
      "epoch": 3.864033114370557,
      "eval_loss": 0.5420595407485962,
      "eval_runtime": 46.5534,
      "eval_samples_per_second": 3607.256,
      "eval_steps_per_second": 450.923,
      "step": 365000
    },
    {
      "epoch": 3.8645624361505604,
      "grad_norm": 4.361265182495117,
      "learning_rate": 3.0684893076434473e-05,
      "loss": 0.7682,
      "step": 365050
    },
    {
      "epoch": 3.8650917579305637,
      "grad_norm": 4.3112921714782715,
      "learning_rate": 3.06822464535253e-05,
      "loss": 0.7792,
      "step": 365100
    },
    {
      "epoch": 3.865621079710567,
      "grad_norm": 3.8820362091064453,
      "learning_rate": 3.0679599830616135e-05,
      "loss": 0.772,
      "step": 365150
    },
    {
      "epoch": 3.86615040149057,
      "grad_norm": 3.9279439449310303,
      "learning_rate": 3.067695320770696e-05,
      "loss": 0.7642,
      "step": 365200
    },
    {
      "epoch": 3.8666797232705736,
      "grad_norm": 4.262490272521973,
      "learning_rate": 3.06743065847978e-05,
      "loss": 0.7822,
      "step": 365250
    },
    {
      "epoch": 3.8672090450505765,
      "grad_norm": 4.3819260597229,
      "learning_rate": 3.067165996188863e-05,
      "loss": 0.7789,
      "step": 365300
    },
    {
      "epoch": 3.8677383668305803,
      "grad_norm": 4.167573928833008,
      "learning_rate": 3.0669013338979465e-05,
      "loss": 0.7919,
      "step": 365350
    },
    {
      "epoch": 3.868267688610583,
      "grad_norm": 4.511765003204346,
      "learning_rate": 3.066636671607029e-05,
      "loss": 0.7807,
      "step": 365400
    },
    {
      "epoch": 3.8687970103905864,
      "grad_norm": 4.126941680908203,
      "learning_rate": 3.066372009316113e-05,
      "loss": 0.787,
      "step": 365450
    },
    {
      "epoch": 3.8693263321705897,
      "grad_norm": 4.151037693023682,
      "learning_rate": 3.066107347025196e-05,
      "loss": 0.7879,
      "step": 365500
    },
    {
      "epoch": 3.8693263321705897,
      "eval_loss": 0.543004035949707,
      "eval_runtime": 46.7028,
      "eval_samples_per_second": 3595.718,
      "eval_steps_per_second": 449.481,
      "step": 365500
    },
    {
      "epoch": 3.869855653950593,
      "grad_norm": 3.7413716316223145,
      "learning_rate": 3.0658479779800975e-05,
      "loss": 0.793,
      "step": 365550
    },
    {
      "epoch": 3.8703849757305964,
      "grad_norm": 4.118940353393555,
      "learning_rate": 3.065583315689181e-05,
      "loss": 0.802,
      "step": 365600
    },
    {
      "epoch": 3.8709142975105997,
      "grad_norm": 4.3926310539245605,
      "learning_rate": 3.065318653398264e-05,
      "loss": 0.7874,
      "step": 365650
    },
    {
      "epoch": 3.871443619290603,
      "grad_norm": 4.1680402755737305,
      "learning_rate": 3.065053991107347e-05,
      "loss": 0.7807,
      "step": 365700
    },
    {
      "epoch": 3.8719729410706063,
      "grad_norm": 4.3346710205078125,
      "learning_rate": 3.0647893288164304e-05,
      "loss": 0.7837,
      "step": 365750
    },
    {
      "epoch": 3.8725022628506096,
      "grad_norm": 4.107644557952881,
      "learning_rate": 3.064524666525513e-05,
      "loss": 0.7685,
      "step": 365800
    },
    {
      "epoch": 3.873031584630613,
      "grad_norm": 4.566917896270752,
      "learning_rate": 3.064260004234597e-05,
      "loss": 0.7776,
      "step": 365850
    },
    {
      "epoch": 3.8735609064106162,
      "grad_norm": 4.088099479675293,
      "learning_rate": 3.06399534194368e-05,
      "loss": 0.7792,
      "step": 365900
    },
    {
      "epoch": 3.874090228190619,
      "grad_norm": 4.021536827087402,
      "learning_rate": 3.0637306796527634e-05,
      "loss": 0.7698,
      "step": 365950
    },
    {
      "epoch": 3.874619549970623,
      "grad_norm": 4.102994918823242,
      "learning_rate": 3.063471310607665e-05,
      "loss": 0.7838,
      "step": 366000
    },
    {
      "epoch": 3.874619549970623,
      "eval_loss": 0.5432414412498474,
      "eval_runtime": 46.5161,
      "eval_samples_per_second": 3610.144,
      "eval_steps_per_second": 451.284,
      "step": 366000
    },
    {
      "epoch": 3.8751488717506257,
      "grad_norm": 4.250389575958252,
      "learning_rate": 3.063206648316748e-05,
      "loss": 0.7796,
      "step": 366050
    },
    {
      "epoch": 3.8756781935306295,
      "grad_norm": 4.401905536651611,
      "learning_rate": 3.062941986025831e-05,
      "loss": 0.7826,
      "step": 366100
    },
    {
      "epoch": 3.8762075153106323,
      "grad_norm": 4.31817102432251,
      "learning_rate": 3.0626773237349144e-05,
      "loss": 0.7887,
      "step": 366150
    },
    {
      "epoch": 3.8767368370906357,
      "grad_norm": 4.6240997314453125,
      "learning_rate": 3.062412661443997e-05,
      "loss": 0.7662,
      "step": 366200
    },
    {
      "epoch": 3.877266158870639,
      "grad_norm": 4.065376281738281,
      "learning_rate": 3.062147999153081e-05,
      "loss": 0.7712,
      "step": 366250
    },
    {
      "epoch": 3.8777954806506423,
      "grad_norm": 4.232882499694824,
      "learning_rate": 3.061883336862164e-05,
      "loss": 0.7755,
      "step": 366300
    },
    {
      "epoch": 3.8783248024306456,
      "grad_norm": 4.375457286834717,
      "learning_rate": 3.0616186745712474e-05,
      "loss": 0.7806,
      "step": 366350
    },
    {
      "epoch": 3.878854124210649,
      "grad_norm": 4.465768337249756,
      "learning_rate": 3.06135401228033e-05,
      "loss": 0.7798,
      "step": 366400
    },
    {
      "epoch": 3.879383445990652,
      "grad_norm": 4.07908821105957,
      "learning_rate": 3.061089349989414e-05,
      "loss": 0.7869,
      "step": 366450
    },
    {
      "epoch": 3.8799127677706555,
      "grad_norm": 3.9409966468811035,
      "learning_rate": 3.060824687698497e-05,
      "loss": 0.7807,
      "step": 366500
    },
    {
      "epoch": 3.8799127677706555,
      "eval_loss": 0.5398250222206116,
      "eval_runtime": 46.5173,
      "eval_samples_per_second": 3610.058,
      "eval_steps_per_second": 451.273,
      "step": 366500
    },
    {
      "epoch": 3.880442089550659,
      "grad_norm": 4.450329780578613,
      "learning_rate": 3.0605600254075803e-05,
      "loss": 0.7899,
      "step": 366550
    },
    {
      "epoch": 3.880971411330662,
      "grad_norm": 4.053315162658691,
      "learning_rate": 3.060295363116663e-05,
      "loss": 0.7942,
      "step": 366600
    },
    {
      "epoch": 3.8815007331106655,
      "grad_norm": 4.439478397369385,
      "learning_rate": 3.0600307008257465e-05,
      "loss": 0.7711,
      "step": 366650
    },
    {
      "epoch": 3.8820300548906683,
      "grad_norm": 4.163730621337891,
      "learning_rate": 3.05976603853483e-05,
      "loss": 0.7896,
      "step": 366700
    },
    {
      "epoch": 3.882559376670672,
      "grad_norm": 3.809645175933838,
      "learning_rate": 3.0595013762439126e-05,
      "loss": 0.7817,
      "step": 366750
    },
    {
      "epoch": 3.883088698450675,
      "grad_norm": 4.409650802612305,
      "learning_rate": 3.059236713952996e-05,
      "loss": 0.7642,
      "step": 366800
    },
    {
      "epoch": 3.8836180202306787,
      "grad_norm": 4.269626617431641,
      "learning_rate": 3.0589720516620795e-05,
      "loss": 0.7799,
      "step": 366850
    },
    {
      "epoch": 3.8841473420106816,
      "grad_norm": 4.322839736938477,
      "learning_rate": 3.058707389371163e-05,
      "loss": 0.7747,
      "step": 366900
    },
    {
      "epoch": 3.884676663790685,
      "grad_norm": 4.181500434875488,
      "learning_rate": 3.0584427270802456e-05,
      "loss": 0.7747,
      "step": 366950
    },
    {
      "epoch": 3.885205985570688,
      "grad_norm": 3.919140100479126,
      "learning_rate": 3.058178064789329e-05,
      "loss": 0.7693,
      "step": 367000
    },
    {
      "epoch": 3.885205985570688,
      "eval_loss": 0.5403943061828613,
      "eval_runtime": 46.5437,
      "eval_samples_per_second": 3608.005,
      "eval_steps_per_second": 451.017,
      "step": 367000
    },
    {
      "epoch": 3.8857353073506915,
      "grad_norm": 4.186391830444336,
      "learning_rate": 3.0579134024984124e-05,
      "loss": 0.7717,
      "step": 367050
    },
    {
      "epoch": 3.886264629130695,
      "grad_norm": 4.530355930328369,
      "learning_rate": 3.057648740207495e-05,
      "loss": 0.7823,
      "step": 367100
    },
    {
      "epoch": 3.886793950910698,
      "grad_norm": 4.11451530456543,
      "learning_rate": 3.0573840779165786e-05,
      "loss": 0.7676,
      "step": 367150
    },
    {
      "epoch": 3.8873232726907014,
      "grad_norm": 4.186550140380859,
      "learning_rate": 3.057119415625661e-05,
      "loss": 0.771,
      "step": 367200
    },
    {
      "epoch": 3.8878525944707047,
      "grad_norm": 4.523643493652344,
      "learning_rate": 3.0568547533347454e-05,
      "loss": 0.7741,
      "step": 367250
    },
    {
      "epoch": 3.888381916250708,
      "grad_norm": 4.337493896484375,
      "learning_rate": 3.056590091043828e-05,
      "loss": 0.7742,
      "step": 367300
    },
    {
      "epoch": 3.8889112380307114,
      "grad_norm": 4.392333507537842,
      "learning_rate": 3.0563254287529115e-05,
      "loss": 0.7689,
      "step": 367350
    },
    {
      "epoch": 3.8894405598107147,
      "grad_norm": 4.47238302230835,
      "learning_rate": 3.056060766461994e-05,
      "loss": 0.7753,
      "step": 367400
    },
    {
      "epoch": 3.8899698815907175,
      "grad_norm": 4.385308742523193,
      "learning_rate": 3.0557961041710783e-05,
      "loss": 0.7867,
      "step": 367450
    },
    {
      "epoch": 3.8904992033707213,
      "grad_norm": 3.9672675132751465,
      "learning_rate": 3.055531441880161e-05,
      "loss": 0.7703,
      "step": 367500
    },
    {
      "epoch": 3.8904992033707213,
      "eval_loss": 0.5413900017738342,
      "eval_runtime": 46.5392,
      "eval_samples_per_second": 3608.354,
      "eval_steps_per_second": 451.06,
      "step": 367500
    },
    {
      "epoch": 3.891028525150724,
      "grad_norm": 4.09232759475708,
      "learning_rate": 3.0552667795892445e-05,
      "loss": 0.7725,
      "step": 367550
    },
    {
      "epoch": 3.891557846930728,
      "grad_norm": 4.256331920623779,
      "learning_rate": 3.055002117298327e-05,
      "loss": 0.79,
      "step": 367600
    },
    {
      "epoch": 3.892087168710731,
      "grad_norm": 4.066280841827393,
      "learning_rate": 3.0547374550074106e-05,
      "loss": 0.7693,
      "step": 367650
    },
    {
      "epoch": 3.892616490490734,
      "grad_norm": 3.819894552230835,
      "learning_rate": 3.054472792716494e-05,
      "loss": 0.7984,
      "step": 367700
    },
    {
      "epoch": 3.8931458122707374,
      "grad_norm": 4.3121771812438965,
      "learning_rate": 3.054208130425577e-05,
      "loss": 0.774,
      "step": 367750
    },
    {
      "epoch": 3.8936751340507407,
      "grad_norm": 4.376194000244141,
      "learning_rate": 3.05394346813466e-05,
      "loss": 0.7795,
      "step": 367800
    },
    {
      "epoch": 3.894204455830744,
      "grad_norm": 4.087320804595947,
      "learning_rate": 3.0536788058437436e-05,
      "loss": 0.7719,
      "step": 367850
    },
    {
      "epoch": 3.8947337776107473,
      "grad_norm": 3.981726884841919,
      "learning_rate": 3.053414143552827e-05,
      "loss": 0.7829,
      "step": 367900
    },
    {
      "epoch": 3.8952630993907507,
      "grad_norm": 3.9988858699798584,
      "learning_rate": 3.05314948126191e-05,
      "loss": 0.778,
      "step": 367950
    },
    {
      "epoch": 3.895792421170754,
      "grad_norm": 4.255793571472168,
      "learning_rate": 3.052884818970993e-05,
      "loss": 0.7768,
      "step": 368000
    },
    {
      "epoch": 3.895792421170754,
      "eval_loss": 0.5395479798316956,
      "eval_runtime": 46.7527,
      "eval_samples_per_second": 3591.877,
      "eval_steps_per_second": 449.001,
      "step": 368000
    },
    {
      "epoch": 3.8963217429507573,
      "grad_norm": 3.9658894538879395,
      "learning_rate": 3.0526201566800765e-05,
      "loss": 0.7654,
      "step": 368050
    },
    {
      "epoch": 3.8968510647307606,
      "grad_norm": 3.9673144817352295,
      "learning_rate": 3.05235549438916e-05,
      "loss": 0.7787,
      "step": 368100
    },
    {
      "epoch": 3.897380386510764,
      "grad_norm": 4.545598030090332,
      "learning_rate": 3.052090832098243e-05,
      "loss": 0.7844,
      "step": 368150
    },
    {
      "epoch": 3.8979097082907668,
      "grad_norm": 3.8639917373657227,
      "learning_rate": 3.051826169807326e-05,
      "loss": 0.7738,
      "step": 368200
    },
    {
      "epoch": 3.8984390300707705,
      "grad_norm": 3.7685599327087402,
      "learning_rate": 3.0515615075164095e-05,
      "loss": 0.7827,
      "step": 368250
    },
    {
      "epoch": 3.8989683518507734,
      "grad_norm": 3.7762725353240967,
      "learning_rate": 3.0512968452254926e-05,
      "loss": 0.7607,
      "step": 368300
    },
    {
      "epoch": 3.899497673630777,
      "grad_norm": 4.160935878753662,
      "learning_rate": 3.0510321829345757e-05,
      "loss": 0.7678,
      "step": 368350
    },
    {
      "epoch": 3.90002699541078,
      "grad_norm": 4.104691028594971,
      "learning_rate": 3.0507675206436587e-05,
      "loss": 0.7757,
      "step": 368400
    },
    {
      "epoch": 3.9005563171907833,
      "grad_norm": 3.912726640701294,
      "learning_rate": 3.050502858352742e-05,
      "loss": 0.7734,
      "step": 368450
    },
    {
      "epoch": 3.9010856389707866,
      "grad_norm": 3.8279354572296143,
      "learning_rate": 3.0502381960618252e-05,
      "loss": 0.7733,
      "step": 368500
    },
    {
      "epoch": 3.9010856389707866,
      "eval_loss": 0.5378792881965637,
      "eval_runtime": 46.6904,
      "eval_samples_per_second": 3596.67,
      "eval_steps_per_second": 449.6,
      "step": 368500
    },
    {
      "epoch": 3.90161496075079,
      "grad_norm": 3.911942720413208,
      "learning_rate": 3.0499735337709083e-05,
      "loss": 0.7792,
      "step": 368550
    },
    {
      "epoch": 3.9021442825307933,
      "grad_norm": 3.948638677597046,
      "learning_rate": 3.0497088714799913e-05,
      "loss": 0.7725,
      "step": 368600
    },
    {
      "epoch": 3.9026736043107966,
      "grad_norm": 4.173583507537842,
      "learning_rate": 3.049444209189075e-05,
      "loss": 0.7738,
      "step": 368650
    },
    {
      "epoch": 3.9032029260908,
      "grad_norm": 3.8447377681732178,
      "learning_rate": 3.049179546898158e-05,
      "loss": 0.777,
      "step": 368700
    },
    {
      "epoch": 3.903732247870803,
      "grad_norm": 4.547183036804199,
      "learning_rate": 3.0489148846072412e-05,
      "loss": 0.772,
      "step": 368750
    },
    {
      "epoch": 3.9042615696508065,
      "grad_norm": 4.454697132110596,
      "learning_rate": 3.0486502223163243e-05,
      "loss": 0.7799,
      "step": 368800
    },
    {
      "epoch": 3.90479089143081,
      "grad_norm": 4.231529712677002,
      "learning_rate": 3.048385560025408e-05,
      "loss": 0.7729,
      "step": 368850
    },
    {
      "epoch": 3.905320213210813,
      "grad_norm": 4.013616561889648,
      "learning_rate": 3.048120897734491e-05,
      "loss": 0.7721,
      "step": 368900
    },
    {
      "epoch": 3.905849534990816,
      "grad_norm": 4.0254011154174805,
      "learning_rate": 3.0478562354435742e-05,
      "loss": 0.7799,
      "step": 368950
    },
    {
      "epoch": 3.9063788567708198,
      "grad_norm": 3.896509885787964,
      "learning_rate": 3.0475915731526573e-05,
      "loss": 0.7648,
      "step": 369000
    },
    {
      "epoch": 3.9063788567708198,
      "eval_loss": 0.5379568934440613,
      "eval_runtime": 46.5555,
      "eval_samples_per_second": 3607.091,
      "eval_steps_per_second": 450.903,
      "step": 369000
    },
    {
      "epoch": 3.9069081785508226,
      "grad_norm": 4.199793815612793,
      "learning_rate": 3.0473269108617407e-05,
      "loss": 0.7697,
      "step": 369050
    },
    {
      "epoch": 3.9074375003308264,
      "grad_norm": 3.97648286819458,
      "learning_rate": 3.0470622485708238e-05,
      "loss": 0.7728,
      "step": 369100
    },
    {
      "epoch": 3.9079668221108292,
      "grad_norm": 3.9098293781280518,
      "learning_rate": 3.0467975862799068e-05,
      "loss": 0.7656,
      "step": 369150
    },
    {
      "epoch": 3.9084961438908326,
      "grad_norm": 4.290953159332275,
      "learning_rate": 3.04653292398899e-05,
      "loss": 0.7672,
      "step": 369200
    },
    {
      "epoch": 3.909025465670836,
      "grad_norm": 4.056497097015381,
      "learning_rate": 3.0462682616980736e-05,
      "loss": 0.7749,
      "step": 369250
    },
    {
      "epoch": 3.909554787450839,
      "grad_norm": 3.9959237575531006,
      "learning_rate": 3.0460035994071567e-05,
      "loss": 0.7815,
      "step": 369300
    },
    {
      "epoch": 3.9100841092308425,
      "grad_norm": 4.132387161254883,
      "learning_rate": 3.0457389371162398e-05,
      "loss": 0.7702,
      "step": 369350
    },
    {
      "epoch": 3.910613431010846,
      "grad_norm": 4.132789611816406,
      "learning_rate": 3.045474274825323e-05,
      "loss": 0.7635,
      "step": 369400
    },
    {
      "epoch": 3.911142752790849,
      "grad_norm": 3.8612053394317627,
      "learning_rate": 3.0452096125344066e-05,
      "loss": 0.7792,
      "step": 369450
    },
    {
      "epoch": 3.9116720745708524,
      "grad_norm": 4.107428073883057,
      "learning_rate": 3.0449449502434897e-05,
      "loss": 0.7813,
      "step": 369500
    },
    {
      "epoch": 3.9116720745708524,
      "eval_loss": 0.5375730991363525,
      "eval_runtime": 46.5644,
      "eval_samples_per_second": 3606.405,
      "eval_steps_per_second": 450.817,
      "step": 369500
    },
    {
      "epoch": 3.9122013963508557,
      "grad_norm": 4.043186664581299,
      "learning_rate": 3.0446802879525728e-05,
      "loss": 0.7819,
      "step": 369550
    },
    {
      "epoch": 3.912730718130859,
      "grad_norm": 4.112199783325195,
      "learning_rate": 3.0444156256616558e-05,
      "loss": 0.7526,
      "step": 369600
    },
    {
      "epoch": 3.9132600399108624,
      "grad_norm": 4.2095866203308105,
      "learning_rate": 3.0441509633707392e-05,
      "loss": 0.7674,
      "step": 369650
    },
    {
      "epoch": 3.913789361690865,
      "grad_norm": 4.029609203338623,
      "learning_rate": 3.0438863010798223e-05,
      "loss": 0.773,
      "step": 369700
    },
    {
      "epoch": 3.914318683470869,
      "grad_norm": 4.328759670257568,
      "learning_rate": 3.0436216387889054e-05,
      "loss": 0.7892,
      "step": 369750
    },
    {
      "epoch": 3.914848005250872,
      "grad_norm": 4.36428165435791,
      "learning_rate": 3.0433569764979884e-05,
      "loss": 0.7846,
      "step": 369800
    },
    {
      "epoch": 3.9153773270308756,
      "grad_norm": 4.654750347137451,
      "learning_rate": 3.0430923142070722e-05,
      "loss": 0.7651,
      "step": 369850
    },
    {
      "epoch": 3.9159066488108785,
      "grad_norm": 4.021515846252441,
      "learning_rate": 3.0428276519161553e-05,
      "loss": 0.773,
      "step": 369900
    },
    {
      "epoch": 3.9164359705908818,
      "grad_norm": 3.9491190910339355,
      "learning_rate": 3.0425629896252383e-05,
      "loss": 0.7811,
      "step": 369950
    },
    {
      "epoch": 3.916965292370885,
      "grad_norm": 4.413283824920654,
      "learning_rate": 3.0423036205801398e-05,
      "loss": 0.7676,
      "step": 370000
    },
    {
      "epoch": 3.916965292370885,
      "eval_loss": 0.5353122353553772,
      "eval_runtime": 46.5696,
      "eval_samples_per_second": 3606.003,
      "eval_steps_per_second": 450.767,
      "step": 370000
    },
    {
      "epoch": 3.9174946141508884,
      "grad_norm": 3.961014986038208,
      "learning_rate": 3.0420389582892232e-05,
      "loss": 0.7628,
      "step": 370050
    },
    {
      "epoch": 3.9180239359308917,
      "grad_norm": 4.075870037078857,
      "learning_rate": 3.0417742959983063e-05,
      "loss": 0.7838,
      "step": 370100
    },
    {
      "epoch": 3.918553257710895,
      "grad_norm": 4.454899787902832,
      "learning_rate": 3.0415096337073894e-05,
      "loss": 0.7725,
      "step": 370150
    },
    {
      "epoch": 3.9190825794908983,
      "grad_norm": 4.472954750061035,
      "learning_rate": 3.0412449714164724e-05,
      "loss": 0.7955,
      "step": 370200
    },
    {
      "epoch": 3.9196119012709016,
      "grad_norm": 4.395705223083496,
      "learning_rate": 3.0409803091255562e-05,
      "loss": 0.7737,
      "step": 370250
    },
    {
      "epoch": 3.920141223050905,
      "grad_norm": 4.161141395568848,
      "learning_rate": 3.0407156468346393e-05,
      "loss": 0.7606,
      "step": 370300
    },
    {
      "epoch": 3.9206705448309083,
      "grad_norm": 3.8235156536102295,
      "learning_rate": 3.0404509845437223e-05,
      "loss": 0.7885,
      "step": 370350
    },
    {
      "epoch": 3.9211998666109116,
      "grad_norm": 4.316444396972656,
      "learning_rate": 3.0401863222528054e-05,
      "loss": 0.7651,
      "step": 370400
    },
    {
      "epoch": 3.9217291883909144,
      "grad_norm": 4.053318023681641,
      "learning_rate": 3.039921659961889e-05,
      "loss": 0.7876,
      "step": 370450
    },
    {
      "epoch": 3.922258510170918,
      "grad_norm": 4.09135103225708,
      "learning_rate": 3.0396569976709722e-05,
      "loss": 0.7612,
      "step": 370500
    },
    {
      "epoch": 3.922258510170918,
      "eval_loss": 0.5370100736618042,
      "eval_runtime": 46.5959,
      "eval_samples_per_second": 3603.964,
      "eval_steps_per_second": 450.512,
      "step": 370500
    },
    {
      "epoch": 3.922787831950921,
      "grad_norm": 3.8610026836395264,
      "learning_rate": 3.0393923353800553e-05,
      "loss": 0.7807,
      "step": 370550
    },
    {
      "epoch": 3.923317153730925,
      "grad_norm": 4.143535614013672,
      "learning_rate": 3.0391276730891384e-05,
      "loss": 0.7817,
      "step": 370600
    },
    {
      "epoch": 3.9238464755109277,
      "grad_norm": 3.477332592010498,
      "learning_rate": 3.0388630107982218e-05,
      "loss": 0.7618,
      "step": 370650
    },
    {
      "epoch": 3.924375797290931,
      "grad_norm": 3.9201300144195557,
      "learning_rate": 3.038598348507305e-05,
      "loss": 0.7785,
      "step": 370700
    },
    {
      "epoch": 3.9249051190709343,
      "grad_norm": 3.9634673595428467,
      "learning_rate": 3.038333686216388e-05,
      "loss": 0.7837,
      "step": 370750
    },
    {
      "epoch": 3.9254344408509376,
      "grad_norm": 3.811633825302124,
      "learning_rate": 3.038069023925471e-05,
      "loss": 0.7707,
      "step": 370800
    },
    {
      "epoch": 3.925963762630941,
      "grad_norm": 4.292322158813477,
      "learning_rate": 3.0378043616345547e-05,
      "loss": 0.787,
      "step": 370850
    },
    {
      "epoch": 3.9264930844109442,
      "grad_norm": 4.133114337921143,
      "learning_rate": 3.0375396993436378e-05,
      "loss": 0.7744,
      "step": 370900
    },
    {
      "epoch": 3.9270224061909476,
      "grad_norm": 4.430985927581787,
      "learning_rate": 3.037275037052721e-05,
      "loss": 0.766,
      "step": 370950
    },
    {
      "epoch": 3.927551727970951,
      "grad_norm": 4.188401699066162,
      "learning_rate": 3.037010374761804e-05,
      "loss": 0.7795,
      "step": 371000
    },
    {
      "epoch": 3.927551727970951,
      "eval_loss": 0.5374526381492615,
      "eval_runtime": 46.6002,
      "eval_samples_per_second": 3603.634,
      "eval_steps_per_second": 450.47,
      "step": 371000
    },
    {
      "epoch": 3.928081049750954,
      "grad_norm": 4.555958271026611,
      "learning_rate": 3.036745712470887e-05,
      "loss": 0.7943,
      "step": 371050
    },
    {
      "epoch": 3.9286103715309575,
      "grad_norm": 4.17989444732666,
      "learning_rate": 3.0364810501799708e-05,
      "loss": 0.772,
      "step": 371100
    },
    {
      "epoch": 3.929139693310961,
      "grad_norm": 4.122916221618652,
      "learning_rate": 3.036216387889054e-05,
      "loss": 0.7713,
      "step": 371150
    },
    {
      "epoch": 3.929669015090964,
      "grad_norm": 4.005776405334473,
      "learning_rate": 3.035951725598137e-05,
      "loss": 0.7639,
      "step": 371200
    },
    {
      "epoch": 3.9301983368709674,
      "grad_norm": 4.0327606201171875,
      "learning_rate": 3.03568706330722e-05,
      "loss": 0.7789,
      "step": 371250
    },
    {
      "epoch": 3.9307276586509703,
      "grad_norm": 4.438920021057129,
      "learning_rate": 3.0354224010163034e-05,
      "loss": 0.7745,
      "step": 371300
    },
    {
      "epoch": 3.931256980430974,
      "grad_norm": 4.245284080505371,
      "learning_rate": 3.0351577387253865e-05,
      "loss": 0.7755,
      "step": 371350
    },
    {
      "epoch": 3.931786302210977,
      "grad_norm": 4.657740592956543,
      "learning_rate": 3.0348930764344695e-05,
      "loss": 0.7729,
      "step": 371400
    },
    {
      "epoch": 3.9323156239909802,
      "grad_norm": 4.50093936920166,
      "learning_rate": 3.0346284141435526e-05,
      "loss": 0.7624,
      "step": 371450
    },
    {
      "epoch": 3.9328449457709835,
      "grad_norm": 4.112741470336914,
      "learning_rate": 3.0343637518526363e-05,
      "loss": 0.7798,
      "step": 371500
    },
    {
      "epoch": 3.9328449457709835,
      "eval_loss": 0.5370448231697083,
      "eval_runtime": 46.7551,
      "eval_samples_per_second": 3591.697,
      "eval_steps_per_second": 448.978,
      "step": 371500
    },
    {
      "epoch": 3.933374267550987,
      "grad_norm": 4.268033027648926,
      "learning_rate": 3.0340990895617194e-05,
      "loss": 0.7717,
      "step": 371550
    },
    {
      "epoch": 3.93390358933099,
      "grad_norm": 3.679687976837158,
      "learning_rate": 3.0338344272708025e-05,
      "loss": 0.7791,
      "step": 371600
    },
    {
      "epoch": 3.9344329111109935,
      "grad_norm": 3.9616103172302246,
      "learning_rate": 3.0335697649798856e-05,
      "loss": 0.7819,
      "step": 371650
    },
    {
      "epoch": 3.934962232890997,
      "grad_norm": 4.213682651519775,
      "learning_rate": 3.0333051026889693e-05,
      "loss": 0.7693,
      "step": 371700
    },
    {
      "epoch": 3.935491554671,
      "grad_norm": 3.841082811355591,
      "learning_rate": 3.0330404403980524e-05,
      "loss": 0.7676,
      "step": 371750
    },
    {
      "epoch": 3.9360208764510034,
      "grad_norm": 4.2264251708984375,
      "learning_rate": 3.0327757781071355e-05,
      "loss": 0.7737,
      "step": 371800
    },
    {
      "epoch": 3.9365501982310067,
      "grad_norm": 4.191009044647217,
      "learning_rate": 3.0325111158162185e-05,
      "loss": 0.779,
      "step": 371850
    },
    {
      "epoch": 3.93707952001101,
      "grad_norm": 4.476443767547607,
      "learning_rate": 3.032246453525302e-05,
      "loss": 0.7769,
      "step": 371900
    },
    {
      "epoch": 3.9376088417910133,
      "grad_norm": 3.9299442768096924,
      "learning_rate": 3.031981791234385e-05,
      "loss": 0.7782,
      "step": 371950
    },
    {
      "epoch": 3.9381381635710166,
      "grad_norm": 4.286562919616699,
      "learning_rate": 3.0317224221892865e-05,
      "loss": 0.7747,
      "step": 372000
    },
    {
      "epoch": 3.9381381635710166,
      "eval_loss": 0.5358858704566956,
      "eval_runtime": 46.7201,
      "eval_samples_per_second": 3594.382,
      "eval_steps_per_second": 449.314,
      "step": 372000
    },
    {
      "epoch": 3.9386674853510195,
      "grad_norm": 3.605260133743286,
      "learning_rate": 3.0314577598983695e-05,
      "loss": 0.7816,
      "step": 372050
    },
    {
      "epoch": 3.9391968071310233,
      "grad_norm": 3.8185713291168213,
      "learning_rate": 3.0311930976074533e-05,
      "loss": 0.7746,
      "step": 372100
    },
    {
      "epoch": 3.939726128911026,
      "grad_norm": 4.169692039489746,
      "learning_rate": 3.0309284353165364e-05,
      "loss": 0.7689,
      "step": 372150
    },
    {
      "epoch": 3.9402554506910294,
      "grad_norm": 4.383861541748047,
      "learning_rate": 3.0306637730256194e-05,
      "loss": 0.7785,
      "step": 372200
    },
    {
      "epoch": 3.9407847724710328,
      "grad_norm": 4.241631984710693,
      "learning_rate": 3.0303991107347025e-05,
      "loss": 0.775,
      "step": 372250
    },
    {
      "epoch": 3.941314094251036,
      "grad_norm": 3.7840049266815186,
      "learning_rate": 3.030134448443786e-05,
      "loss": 0.7744,
      "step": 372300
    },
    {
      "epoch": 3.9418434160310394,
      "grad_norm": 4.515494346618652,
      "learning_rate": 3.029869786152869e-05,
      "loss": 0.7705,
      "step": 372350
    },
    {
      "epoch": 3.9423727378110427,
      "grad_norm": 3.820889472961426,
      "learning_rate": 3.029605123861952e-05,
      "loss": 0.7786,
      "step": 372400
    },
    {
      "epoch": 3.942902059591046,
      "grad_norm": 4.271435260772705,
      "learning_rate": 3.029340461571035e-05,
      "loss": 0.7719,
      "step": 372450
    },
    {
      "epoch": 3.9434313813710493,
      "grad_norm": 4.004973411560059,
      "learning_rate": 3.029075799280119e-05,
      "loss": 0.7853,
      "step": 372500
    },
    {
      "epoch": 3.9434313813710493,
      "eval_loss": 0.5384801626205444,
      "eval_runtime": 46.5968,
      "eval_samples_per_second": 3603.893,
      "eval_steps_per_second": 450.503,
      "step": 372500
    },
    {
      "epoch": 3.9439607031510526,
      "grad_norm": 4.139218330383301,
      "learning_rate": 3.028811136989202e-05,
      "loss": 0.7895,
      "step": 372550
    },
    {
      "epoch": 3.944490024931056,
      "grad_norm": 4.516480922698975,
      "learning_rate": 3.028546474698285e-05,
      "loss": 0.793,
      "step": 372600
    },
    {
      "epoch": 3.9450193467110592,
      "grad_norm": 4.202691078186035,
      "learning_rate": 3.028281812407368e-05,
      "loss": 0.767,
      "step": 372650
    },
    {
      "epoch": 3.9455486684910626,
      "grad_norm": 4.031774044036865,
      "learning_rate": 3.028017150116452e-05,
      "loss": 0.7794,
      "step": 372700
    },
    {
      "epoch": 3.946077990271066,
      "grad_norm": 4.0419020652771,
      "learning_rate": 3.027752487825535e-05,
      "loss": 0.7679,
      "step": 372750
    },
    {
      "epoch": 3.9466073120510687,
      "grad_norm": 4.187643527984619,
      "learning_rate": 3.027487825534618e-05,
      "loss": 0.7755,
      "step": 372800
    },
    {
      "epoch": 3.9471366338310725,
      "grad_norm": 3.86916184425354,
      "learning_rate": 3.027223163243701e-05,
      "loss": 0.7785,
      "step": 372850
    },
    {
      "epoch": 3.9476659556110754,
      "grad_norm": 4.353824615478516,
      "learning_rate": 3.0269585009527845e-05,
      "loss": 0.7681,
      "step": 372900
    },
    {
      "epoch": 3.9481952773910787,
      "grad_norm": 3.972717046737671,
      "learning_rate": 3.0266938386618675e-05,
      "loss": 0.7646,
      "step": 372950
    },
    {
      "epoch": 3.948724599171082,
      "grad_norm": 4.036218643188477,
      "learning_rate": 3.0264291763709506e-05,
      "loss": 0.7736,
      "step": 373000
    },
    {
      "epoch": 3.948724599171082,
      "eval_loss": 0.5355086326599121,
      "eval_runtime": 46.5558,
      "eval_samples_per_second": 3607.066,
      "eval_steps_per_second": 450.899,
      "step": 373000
    },
    {
      "epoch": 3.9492539209510853,
      "grad_norm": 4.57806921005249,
      "learning_rate": 3.0261645140800337e-05,
      "loss": 0.7835,
      "step": 373050
    },
    {
      "epoch": 3.9497832427310886,
      "grad_norm": 4.1997456550598145,
      "learning_rate": 3.0258998517891174e-05,
      "loss": 0.7807,
      "step": 373100
    },
    {
      "epoch": 3.950312564511092,
      "grad_norm": 4.156503677368164,
      "learning_rate": 3.0256351894982005e-05,
      "loss": 0.7678,
      "step": 373150
    },
    {
      "epoch": 3.9508418862910952,
      "grad_norm": 3.7834537029266357,
      "learning_rate": 3.0253705272072836e-05,
      "loss": 0.7644,
      "step": 373200
    },
    {
      "epoch": 3.9513712080710985,
      "grad_norm": 4.020482540130615,
      "learning_rate": 3.0251058649163666e-05,
      "loss": 0.7696,
      "step": 373250
    },
    {
      "epoch": 3.951900529851102,
      "grad_norm": 4.103616714477539,
      "learning_rate": 3.0248412026254504e-05,
      "loss": 0.7678,
      "step": 373300
    },
    {
      "epoch": 3.952429851631105,
      "grad_norm": 3.9049365520477295,
      "learning_rate": 3.0245765403345335e-05,
      "loss": 0.7717,
      "step": 373350
    },
    {
      "epoch": 3.9529591734111085,
      "grad_norm": 4.021058082580566,
      "learning_rate": 3.0243118780436165e-05,
      "loss": 0.7615,
      "step": 373400
    },
    {
      "epoch": 3.953488495191112,
      "grad_norm": 4.03449010848999,
      "learning_rate": 3.0240472157526996e-05,
      "loss": 0.7668,
      "step": 373450
    },
    {
      "epoch": 3.954017816971115,
      "grad_norm": 3.7969448566436768,
      "learning_rate": 3.023782553461783e-05,
      "loss": 0.7779,
      "step": 373500
    },
    {
      "epoch": 3.954017816971115,
      "eval_loss": 0.5366564393043518,
      "eval_runtime": 46.5879,
      "eval_samples_per_second": 3604.581,
      "eval_steps_per_second": 450.589,
      "step": 373500
    },
    {
      "epoch": 3.954547138751118,
      "grad_norm": 4.215839385986328,
      "learning_rate": 3.023517891170866e-05,
      "loss": 0.7804,
      "step": 373550
    },
    {
      "epoch": 3.9550764605311217,
      "grad_norm": 4.251184940338135,
      "learning_rate": 3.023253228879949e-05,
      "loss": 0.7665,
      "step": 373600
    },
    {
      "epoch": 3.9556057823111246,
      "grad_norm": 4.40224552154541,
      "learning_rate": 3.0229885665890322e-05,
      "loss": 0.7842,
      "step": 373650
    },
    {
      "epoch": 3.956135104091128,
      "grad_norm": 4.164985179901123,
      "learning_rate": 3.022723904298116e-05,
      "loss": 0.7748,
      "step": 373700
    },
    {
      "epoch": 3.956664425871131,
      "grad_norm": 4.219110012054443,
      "learning_rate": 3.022459242007199e-05,
      "loss": 0.7628,
      "step": 373750
    },
    {
      "epoch": 3.9571937476511345,
      "grad_norm": 4.493709564208984,
      "learning_rate": 3.022194579716282e-05,
      "loss": 0.774,
      "step": 373800
    },
    {
      "epoch": 3.957723069431138,
      "grad_norm": 3.8077690601348877,
      "learning_rate": 3.0219299174253652e-05,
      "loss": 0.779,
      "step": 373850
    },
    {
      "epoch": 3.958252391211141,
      "grad_norm": 4.2375335693359375,
      "learning_rate": 3.0216652551344486e-05,
      "loss": 0.7747,
      "step": 373900
    },
    {
      "epoch": 3.9587817129911445,
      "grad_norm": 4.1835246086120605,
      "learning_rate": 3.0214005928435317e-05,
      "loss": 0.7735,
      "step": 373950
    },
    {
      "epoch": 3.9593110347711478,
      "grad_norm": 4.362729072570801,
      "learning_rate": 3.021141223798433e-05,
      "loss": 0.777,
      "step": 374000
    },
    {
      "epoch": 3.9593110347711478,
      "eval_loss": 0.5343750715255737,
      "eval_runtime": 46.7634,
      "eval_samples_per_second": 3591.055,
      "eval_steps_per_second": 448.898,
      "step": 374000
    },
    {
      "epoch": 3.959840356551151,
      "grad_norm": 3.6341331005096436,
      "learning_rate": 3.0208765615075162e-05,
      "loss": 0.7694,
      "step": 374050
    },
    {
      "epoch": 3.9603696783311544,
      "grad_norm": 4.05379581451416,
      "learning_rate": 3.0206118992166e-05,
      "loss": 0.7877,
      "step": 374100
    },
    {
      "epoch": 3.9608990001111577,
      "grad_norm": 3.999814748764038,
      "learning_rate": 3.020347236925683e-05,
      "loss": 0.7808,
      "step": 374150
    },
    {
      "epoch": 3.961428321891161,
      "grad_norm": 3.781285524368286,
      "learning_rate": 3.020082574634766e-05,
      "loss": 0.7573,
      "step": 374200
    },
    {
      "epoch": 3.9619576436711643,
      "grad_norm": 4.27024507522583,
      "learning_rate": 3.0198179123438492e-05,
      "loss": 0.7656,
      "step": 374250
    },
    {
      "epoch": 3.962486965451167,
      "grad_norm": 4.08022403717041,
      "learning_rate": 3.019553250052933e-05,
      "loss": 0.7558,
      "step": 374300
    },
    {
      "epoch": 3.963016287231171,
      "grad_norm": 4.105074882507324,
      "learning_rate": 3.019288587762016e-05,
      "loss": 0.7798,
      "step": 374350
    },
    {
      "epoch": 3.963545609011174,
      "grad_norm": 4.305837154388428,
      "learning_rate": 3.019023925471099e-05,
      "loss": 0.7842,
      "step": 374400
    },
    {
      "epoch": 3.964074930791177,
      "grad_norm": 4.153212070465088,
      "learning_rate": 3.018759263180182e-05,
      "loss": 0.7726,
      "step": 374450
    },
    {
      "epoch": 3.9646042525711804,
      "grad_norm": 3.918156385421753,
      "learning_rate": 3.0184946008892655e-05,
      "loss": 0.7663,
      "step": 374500
    },
    {
      "epoch": 3.9646042525711804,
      "eval_loss": 0.5354229807853699,
      "eval_runtime": 46.7968,
      "eval_samples_per_second": 3588.492,
      "eval_steps_per_second": 448.578,
      "step": 374500
    },
    {
      "epoch": 3.9651335743511837,
      "grad_norm": 4.561142921447754,
      "learning_rate": 3.0182299385983486e-05,
      "loss": 0.7695,
      "step": 374550
    },
    {
      "epoch": 3.965662896131187,
      "grad_norm": 3.9901411533355713,
      "learning_rate": 3.0179652763074317e-05,
      "loss": 0.7741,
      "step": 374600
    },
    {
      "epoch": 3.9661922179111904,
      "grad_norm": 4.208408355712891,
      "learning_rate": 3.0177006140165148e-05,
      "loss": 0.7845,
      "step": 374650
    },
    {
      "epoch": 3.9667215396911937,
      "grad_norm": 4.548604488372803,
      "learning_rate": 3.0174359517255985e-05,
      "loss": 0.7683,
      "step": 374700
    },
    {
      "epoch": 3.967250861471197,
      "grad_norm": 4.227700233459473,
      "learning_rate": 3.0171712894346816e-05,
      "loss": 0.7813,
      "step": 374750
    },
    {
      "epoch": 3.9677801832512003,
      "grad_norm": 4.0949249267578125,
      "learning_rate": 3.0169066271437647e-05,
      "loss": 0.7731,
      "step": 374800
    },
    {
      "epoch": 3.9683095050312036,
      "grad_norm": 4.238680839538574,
      "learning_rate": 3.0166419648528477e-05,
      "loss": 0.7798,
      "step": 374850
    },
    {
      "epoch": 3.968838826811207,
      "grad_norm": 4.206009387969971,
      "learning_rate": 3.016377302561931e-05,
      "loss": 0.7659,
      "step": 374900
    },
    {
      "epoch": 3.9693681485912102,
      "grad_norm": 3.8599700927734375,
      "learning_rate": 3.0161126402710142e-05,
      "loss": 0.7746,
      "step": 374950
    },
    {
      "epoch": 3.9698974703712135,
      "grad_norm": 4.224859714508057,
      "learning_rate": 3.0158479779800973e-05,
      "loss": 0.7808,
      "step": 375000
    },
    {
      "epoch": 3.9698974703712135,
      "eval_loss": 0.5352782607078552,
      "eval_runtime": 46.562,
      "eval_samples_per_second": 3606.585,
      "eval_steps_per_second": 450.839,
      "step": 375000
    },
    {
      "epoch": 3.9704267921512164,
      "grad_norm": 4.367305278778076,
      "learning_rate": 3.0155833156891803e-05,
      "loss": 0.7694,
      "step": 375050
    },
    {
      "epoch": 3.97095611393122,
      "grad_norm": 4.298569679260254,
      "learning_rate": 3.015318653398264e-05,
      "loss": 0.7897,
      "step": 375100
    },
    {
      "epoch": 3.971485435711223,
      "grad_norm": 4.234951972961426,
      "learning_rate": 3.015053991107347e-05,
      "loss": 0.7857,
      "step": 375150
    },
    {
      "epoch": 3.9720147574912263,
      "grad_norm": 4.2053046226501465,
      "learning_rate": 3.0147893288164302e-05,
      "loss": 0.7653,
      "step": 375200
    },
    {
      "epoch": 3.9725440792712297,
      "grad_norm": 4.153021812438965,
      "learning_rate": 3.0145246665255133e-05,
      "loss": 0.7697,
      "step": 375250
    },
    {
      "epoch": 3.973073401051233,
      "grad_norm": 4.253928184509277,
      "learning_rate": 3.014260004234597e-05,
      "loss": 0.7709,
      "step": 375300
    },
    {
      "epoch": 3.9736027228312363,
      "grad_norm": 4.1471405029296875,
      "learning_rate": 3.01399534194368e-05,
      "loss": 0.7616,
      "step": 375350
    },
    {
      "epoch": 3.9741320446112396,
      "grad_norm": 4.369604587554932,
      "learning_rate": 3.0137306796527632e-05,
      "loss": 0.7724,
      "step": 375400
    },
    {
      "epoch": 3.974661366391243,
      "grad_norm": 4.447230339050293,
      "learning_rate": 3.0134660173618463e-05,
      "loss": 0.7675,
      "step": 375450
    },
    {
      "epoch": 3.975190688171246,
      "grad_norm": 3.7406487464904785,
      "learning_rate": 3.0132013550709297e-05,
      "loss": 0.7621,
      "step": 375500
    },
    {
      "epoch": 3.975190688171246,
      "eval_loss": 0.5337135195732117,
      "eval_runtime": 46.5739,
      "eval_samples_per_second": 3605.67,
      "eval_steps_per_second": 450.725,
      "step": 375500
    },
    {
      "epoch": 3.9757200099512495,
      "grad_norm": 4.098247528076172,
      "learning_rate": 3.0129366927800128e-05,
      "loss": 0.772,
      "step": 375550
    },
    {
      "epoch": 3.976249331731253,
      "grad_norm": 4.707272529602051,
      "learning_rate": 3.0126720304890958e-05,
      "loss": 0.773,
      "step": 375600
    },
    {
      "epoch": 3.976778653511256,
      "grad_norm": 3.9250402450561523,
      "learning_rate": 3.012407368198179e-05,
      "loss": 0.7785,
      "step": 375650
    },
    {
      "epoch": 3.9773079752912595,
      "grad_norm": 3.8776090145111084,
      "learning_rate": 3.0121427059072626e-05,
      "loss": 0.7649,
      "step": 375700
    },
    {
      "epoch": 3.9778372970712628,
      "grad_norm": 4.334721088409424,
      "learning_rate": 3.0118780436163457e-05,
      "loss": 0.7693,
      "step": 375750
    },
    {
      "epoch": 3.9783666188512656,
      "grad_norm": 3.7729556560516357,
      "learning_rate": 3.0116133813254288e-05,
      "loss": 0.7794,
      "step": 375800
    },
    {
      "epoch": 3.9788959406312694,
      "grad_norm": 4.039055347442627,
      "learning_rate": 3.011348719034512e-05,
      "loss": 0.7861,
      "step": 375850
    },
    {
      "epoch": 3.9794252624112723,
      "grad_norm": 4.3634185791015625,
      "learning_rate": 3.0110840567435956e-05,
      "loss": 0.7902,
      "step": 375900
    },
    {
      "epoch": 3.9799545841912756,
      "grad_norm": 4.094968318939209,
      "learning_rate": 3.0108193944526787e-05,
      "loss": 0.7693,
      "step": 375950
    },
    {
      "epoch": 3.980483905971279,
      "grad_norm": 4.057435512542725,
      "learning_rate": 3.0105600254075798e-05,
      "loss": 0.7742,
      "step": 376000
    },
    {
      "epoch": 3.980483905971279,
      "eval_loss": 0.5320929884910583,
      "eval_runtime": 46.6006,
      "eval_samples_per_second": 3603.603,
      "eval_steps_per_second": 450.466,
      "step": 376000
    },
    {
      "epoch": 3.981013227751282,
      "grad_norm": 4.154664516448975,
      "learning_rate": 3.010295363116663e-05,
      "loss": 0.7758,
      "step": 376050
    },
    {
      "epoch": 3.9815425495312855,
      "grad_norm": 4.446500301361084,
      "learning_rate": 3.0100307008257466e-05,
      "loss": 0.7661,
      "step": 376100
    },
    {
      "epoch": 3.982071871311289,
      "grad_norm": 3.9634828567504883,
      "learning_rate": 3.0097660385348297e-05,
      "loss": 0.7644,
      "step": 376150
    },
    {
      "epoch": 3.982601193091292,
      "grad_norm": 4.2403411865234375,
      "learning_rate": 3.0095013762439128e-05,
      "loss": 0.7666,
      "step": 376200
    },
    {
      "epoch": 3.9831305148712954,
      "grad_norm": 4.131462574005127,
      "learning_rate": 3.009236713952996e-05,
      "loss": 0.7677,
      "step": 376250
    },
    {
      "epoch": 3.9836598366512987,
      "grad_norm": 4.096032619476318,
      "learning_rate": 3.0089720516620796e-05,
      "loss": 0.7714,
      "step": 376300
    },
    {
      "epoch": 3.984189158431302,
      "grad_norm": 4.145463943481445,
      "learning_rate": 3.0087073893711627e-05,
      "loss": 0.764,
      "step": 376350
    },
    {
      "epoch": 3.9847184802113054,
      "grad_norm": 3.8746564388275146,
      "learning_rate": 3.0084427270802457e-05,
      "loss": 0.7674,
      "step": 376400
    },
    {
      "epoch": 3.9852478019913087,
      "grad_norm": 4.3862528800964355,
      "learning_rate": 3.0081780647893288e-05,
      "loss": 0.7682,
      "step": 376450
    },
    {
      "epoch": 3.985777123771312,
      "grad_norm": 4.7360382080078125,
      "learning_rate": 3.0079134024984122e-05,
      "loss": 0.7748,
      "step": 376500
    },
    {
      "epoch": 3.985777123771312,
      "eval_loss": 0.5307037830352783,
      "eval_runtime": 46.5587,
      "eval_samples_per_second": 3606.847,
      "eval_steps_per_second": 450.872,
      "step": 376500
    },
    {
      "epoch": 3.986306445551315,
      "grad_norm": 4.127739906311035,
      "learning_rate": 3.0076487402074953e-05,
      "loss": 0.7664,
      "step": 376550
    },
    {
      "epoch": 3.9868357673313186,
      "grad_norm": 4.478370189666748,
      "learning_rate": 3.0073840779165784e-05,
      "loss": 0.7744,
      "step": 376600
    },
    {
      "epoch": 3.9873650891113215,
      "grad_norm": 4.488682746887207,
      "learning_rate": 3.0071194156256614e-05,
      "loss": 0.7752,
      "step": 376650
    },
    {
      "epoch": 3.987894410891325,
      "grad_norm": 4.011255264282227,
      "learning_rate": 3.0068547533347452e-05,
      "loss": 0.7814,
      "step": 376700
    },
    {
      "epoch": 3.988423732671328,
      "grad_norm": 4.624486923217773,
      "learning_rate": 3.0065900910438282e-05,
      "loss": 0.7681,
      "step": 376750
    },
    {
      "epoch": 3.9889530544513314,
      "grad_norm": 4.098458290100098,
      "learning_rate": 3.0063254287529113e-05,
      "loss": 0.7541,
      "step": 376800
    },
    {
      "epoch": 3.9894823762313347,
      "grad_norm": 4.301809310913086,
      "learning_rate": 3.0060607664619944e-05,
      "loss": 0.7688,
      "step": 376850
    },
    {
      "epoch": 3.990011698011338,
      "grad_norm": 4.126350402832031,
      "learning_rate": 3.005796104171078e-05,
      "loss": 0.7763,
      "step": 376900
    },
    {
      "epoch": 3.9905410197913413,
      "grad_norm": 3.9404098987579346,
      "learning_rate": 3.0055314418801612e-05,
      "loss": 0.7617,
      "step": 376950
    },
    {
      "epoch": 3.9910703415713447,
      "grad_norm": 4.070647716522217,
      "learning_rate": 3.0052667795892443e-05,
      "loss": 0.7785,
      "step": 377000
    },
    {
      "epoch": 3.9910703415713447,
      "eval_loss": 0.5321515798568726,
      "eval_runtime": 46.5846,
      "eval_samples_per_second": 3604.841,
      "eval_steps_per_second": 450.621,
      "step": 377000
    },
    {
      "epoch": 3.991599663351348,
      "grad_norm": 4.052696704864502,
      "learning_rate": 3.0050021172983274e-05,
      "loss": 0.7575,
      "step": 377050
    },
    {
      "epoch": 3.9921289851313513,
      "grad_norm": 4.191850185394287,
      "learning_rate": 3.0047374550074108e-05,
      "loss": 0.7733,
      "step": 377100
    },
    {
      "epoch": 3.9926583069113546,
      "grad_norm": 4.090133190155029,
      "learning_rate": 3.004472792716494e-05,
      "loss": 0.7745,
      "step": 377150
    },
    {
      "epoch": 3.993187628691358,
      "grad_norm": 4.179385185241699,
      "learning_rate": 3.004208130425577e-05,
      "loss": 0.7699,
      "step": 377200
    },
    {
      "epoch": 3.993716950471361,
      "grad_norm": 4.174865245819092,
      "learning_rate": 3.00394346813466e-05,
      "loss": 0.7656,
      "step": 377250
    },
    {
      "epoch": 3.994246272251364,
      "grad_norm": 4.309226989746094,
      "learning_rate": 3.0036788058437437e-05,
      "loss": 0.7877,
      "step": 377300
    },
    {
      "epoch": 3.994775594031368,
      "grad_norm": 4.101950168609619,
      "learning_rate": 3.0034141435528268e-05,
      "loss": 0.7717,
      "step": 377350
    },
    {
      "epoch": 3.9953049158113707,
      "grad_norm": 3.9487290382385254,
      "learning_rate": 3.00314948126191e-05,
      "loss": 0.7803,
      "step": 377400
    },
    {
      "epoch": 3.995834237591374,
      "grad_norm": 3.969576358795166,
      "learning_rate": 3.002884818970993e-05,
      "loss": 0.7708,
      "step": 377450
    },
    {
      "epoch": 3.9963635593713773,
      "grad_norm": 3.7610995769500732,
      "learning_rate": 3.0026201566800767e-05,
      "loss": 0.7558,
      "step": 377500
    },
    {
      "epoch": 3.9963635593713773,
      "eval_loss": 0.5315985083580017,
      "eval_runtime": 46.6221,
      "eval_samples_per_second": 3601.944,
      "eval_steps_per_second": 450.259,
      "step": 377500
    },
    {
      "epoch": 3.9968928811513806,
      "grad_norm": 4.2561259269714355,
      "learning_rate": 3.0023554943891598e-05,
      "loss": 0.7597,
      "step": 377550
    },
    {
      "epoch": 3.997422202931384,
      "grad_norm": 3.78507661819458,
      "learning_rate": 3.002090832098243e-05,
      "loss": 0.7783,
      "step": 377600
    },
    {
      "epoch": 3.9979515247113873,
      "grad_norm": 4.24613618850708,
      "learning_rate": 3.001826169807326e-05,
      "loss": 0.7704,
      "step": 377650
    },
    {
      "epoch": 3.9984808464913906,
      "grad_norm": 4.030115604400635,
      "learning_rate": 3.0015615075164093e-05,
      "loss": 0.7573,
      "step": 377700
    },
    {
      "epoch": 3.999010168271394,
      "grad_norm": 4.35135555267334,
      "learning_rate": 3.0012968452254924e-05,
      "loss": 0.7645,
      "step": 377750
    },
    {
      "epoch": 3.999539490051397,
      "grad_norm": 3.8837082386016846,
      "learning_rate": 3.0010321829345755e-05,
      "loss": 0.7705,
      "step": 377800
    },
    {
      "epoch": 4.0000635186136,
      "grad_norm": 4.093972206115723,
      "learning_rate": 3.0007675206436585e-05,
      "loss": 0.7713,
      "step": 377850
    },
    {
      "epoch": 4.000592840393604,
      "grad_norm": 4.40943717956543,
      "learning_rate": 3.0005028583527423e-05,
      "loss": 0.7652,
      "step": 377900
    },
    {
      "epoch": 4.001122162173607,
      "grad_norm": 4.576634407043457,
      "learning_rate": 3.0002381960618253e-05,
      "loss": 0.758,
      "step": 377950
    },
    {
      "epoch": 4.00165148395361,
      "grad_norm": 4.341341972351074,
      "learning_rate": 2.9999788270167268e-05,
      "loss": 0.7628,
      "step": 378000
    },
    {
      "epoch": 4.00165148395361,
      "eval_loss": 0.5335950255393982,
      "eval_runtime": 46.5387,
      "eval_samples_per_second": 3608.395,
      "eval_steps_per_second": 451.065,
      "step": 378000
    },
    {
      "epoch": 4.002180805733613,
      "grad_norm": 4.1130595207214355,
      "learning_rate": 2.99971416472581e-05,
      "loss": 0.7631,
      "step": 378050
    },
    {
      "epoch": 4.002710127513617,
      "grad_norm": 4.4151811599731445,
      "learning_rate": 2.9994495024348933e-05,
      "loss": 0.7613,
      "step": 378100
    },
    {
      "epoch": 4.00323944929362,
      "grad_norm": 3.901963949203491,
      "learning_rate": 2.9991848401439764e-05,
      "loss": 0.7712,
      "step": 378150
    },
    {
      "epoch": 4.003768771073624,
      "grad_norm": 4.114243507385254,
      "learning_rate": 2.9989201778530594e-05,
      "loss": 0.7463,
      "step": 378200
    },
    {
      "epoch": 4.0042980928536265,
      "grad_norm": 4.092478275299072,
      "learning_rate": 2.9986555155621425e-05,
      "loss": 0.7582,
      "step": 378250
    },
    {
      "epoch": 4.00482741463363,
      "grad_norm": 4.358151435852051,
      "learning_rate": 2.9983908532712263e-05,
      "loss": 0.7675,
      "step": 378300
    },
    {
      "epoch": 4.005356736413633,
      "grad_norm": 4.201253414154053,
      "learning_rate": 2.9981261909803093e-05,
      "loss": 0.765,
      "step": 378350
    },
    {
      "epoch": 4.005886058193637,
      "grad_norm": 4.734517574310303,
      "learning_rate": 2.9978615286893924e-05,
      "loss": 0.7629,
      "step": 378400
    },
    {
      "epoch": 4.00641537997364,
      "grad_norm": 4.273502349853516,
      "learning_rate": 2.9975968663984755e-05,
      "loss": 0.766,
      "step": 378450
    },
    {
      "epoch": 4.0069447017536435,
      "grad_norm": 3.8187897205352783,
      "learning_rate": 2.9973322041075592e-05,
      "loss": 0.7641,
      "step": 378500
    },
    {
      "epoch": 4.0069447017536435,
      "eval_loss": 0.5303916931152344,
      "eval_runtime": 46.5822,
      "eval_samples_per_second": 3605.029,
      "eval_steps_per_second": 450.645,
      "step": 378500
    },
    {
      "epoch": 4.007474023533646,
      "grad_norm": 4.33804178237915,
      "learning_rate": 2.9970675418166423e-05,
      "loss": 0.7607,
      "step": 378550
    },
    {
      "epoch": 4.008003345313649,
      "grad_norm": 4.454745769500732,
      "learning_rate": 2.9968028795257254e-05,
      "loss": 0.7658,
      "step": 378600
    },
    {
      "epoch": 4.008532667093653,
      "grad_norm": 3.903373956680298,
      "learning_rate": 2.9965382172348084e-05,
      "loss": 0.7636,
      "step": 378650
    },
    {
      "epoch": 4.009061988873656,
      "grad_norm": 4.083543300628662,
      "learning_rate": 2.996273554943892e-05,
      "loss": 0.7602,
      "step": 378700
    },
    {
      "epoch": 4.00959131065366,
      "grad_norm": 4.027923107147217,
      "learning_rate": 2.996008892652975e-05,
      "loss": 0.7602,
      "step": 378750
    },
    {
      "epoch": 4.0101206324336625,
      "grad_norm": 4.313352584838867,
      "learning_rate": 2.995744230362058e-05,
      "loss": 0.744,
      "step": 378800
    },
    {
      "epoch": 4.010649954213666,
      "grad_norm": 4.007747650146484,
      "learning_rate": 2.995479568071141e-05,
      "loss": 0.7603,
      "step": 378850
    },
    {
      "epoch": 4.011179275993669,
      "grad_norm": 4.328745365142822,
      "learning_rate": 2.9952149057802248e-05,
      "loss": 0.7588,
      "step": 378900
    },
    {
      "epoch": 4.011708597773673,
      "grad_norm": 4.421525478363037,
      "learning_rate": 2.994950243489308e-05,
      "loss": 0.7636,
      "step": 378950
    },
    {
      "epoch": 4.012237919553676,
      "grad_norm": 4.6600022315979,
      "learning_rate": 2.994685581198391e-05,
      "loss": 0.767,
      "step": 379000
    },
    {
      "epoch": 4.012237919553676,
      "eval_loss": 0.5321521162986755,
      "eval_runtime": 46.5169,
      "eval_samples_per_second": 3610.085,
      "eval_steps_per_second": 451.277,
      "step": 379000
    },
    {
      "epoch": 4.0127672413336795,
      "grad_norm": 3.5732786655426025,
      "learning_rate": 2.994420918907474e-05,
      "loss": 0.7583,
      "step": 379050
    },
    {
      "epoch": 4.013296563113682,
      "grad_norm": 4.380545616149902,
      "learning_rate": 2.9941562566165578e-05,
      "loss": 0.7561,
      "step": 379100
    },
    {
      "epoch": 4.013825884893686,
      "grad_norm": 3.832979440689087,
      "learning_rate": 2.993891594325641e-05,
      "loss": 0.7688,
      "step": 379150
    },
    {
      "epoch": 4.014355206673689,
      "grad_norm": 4.352747917175293,
      "learning_rate": 2.993626932034724e-05,
      "loss": 0.7649,
      "step": 379200
    },
    {
      "epoch": 4.014884528453693,
      "grad_norm": 4.458528518676758,
      "learning_rate": 2.993362269743807e-05,
      "loss": 0.7789,
      "step": 379250
    },
    {
      "epoch": 4.015413850233696,
      "grad_norm": 4.091719627380371,
      "learning_rate": 2.9930976074528904e-05,
      "loss": 0.7729,
      "step": 379300
    },
    {
      "epoch": 4.015943172013698,
      "grad_norm": 4.290952682495117,
      "learning_rate": 2.9928329451619735e-05,
      "loss": 0.7553,
      "step": 379350
    },
    {
      "epoch": 4.016472493793702,
      "grad_norm": 4.308701038360596,
      "learning_rate": 2.9925682828710565e-05,
      "loss": 0.77,
      "step": 379400
    },
    {
      "epoch": 4.017001815573705,
      "grad_norm": 4.505492687225342,
      "learning_rate": 2.9923036205801396e-05,
      "loss": 0.7671,
      "step": 379450
    },
    {
      "epoch": 4.017531137353709,
      "grad_norm": 4.044183254241943,
      "learning_rate": 2.9920389582892234e-05,
      "loss": 0.7598,
      "step": 379500
    },
    {
      "epoch": 4.017531137353709,
      "eval_loss": 0.531796932220459,
      "eval_runtime": 46.6015,
      "eval_samples_per_second": 3603.532,
      "eval_steps_per_second": 450.458,
      "step": 379500
    },
    {
      "epoch": 4.018060459133712,
      "grad_norm": 4.023841381072998,
      "learning_rate": 2.9917742959983064e-05,
      "loss": 0.7812,
      "step": 379550
    },
    {
      "epoch": 4.018589780913715,
      "grad_norm": 4.059785842895508,
      "learning_rate": 2.9915096337073895e-05,
      "loss": 0.751,
      "step": 379600
    },
    {
      "epoch": 4.019119102693718,
      "grad_norm": 3.620069980621338,
      "learning_rate": 2.9912449714164726e-05,
      "loss": 0.7633,
      "step": 379650
    },
    {
      "epoch": 4.019648424473722,
      "grad_norm": 4.170368671417236,
      "learning_rate": 2.9909803091255563e-05,
      "loss": 0.7656,
      "step": 379700
    },
    {
      "epoch": 4.020177746253725,
      "grad_norm": 4.229648113250732,
      "learning_rate": 2.9907156468346394e-05,
      "loss": 0.7654,
      "step": 379750
    },
    {
      "epoch": 4.020707068033729,
      "grad_norm": 4.009994983673096,
      "learning_rate": 2.9904562777895405e-05,
      "loss": 0.7687,
      "step": 379800
    },
    {
      "epoch": 4.0212363898137315,
      "grad_norm": 4.041070938110352,
      "learning_rate": 2.9901916154986236e-05,
      "loss": 0.7662,
      "step": 379850
    },
    {
      "epoch": 4.021765711593735,
      "grad_norm": 4.317413330078125,
      "learning_rate": 2.9899269532077073e-05,
      "loss": 0.7647,
      "step": 379900
    },
    {
      "epoch": 4.022295033373738,
      "grad_norm": 4.315250873565674,
      "learning_rate": 2.9896622909167904e-05,
      "loss": 0.7783,
      "step": 379950
    },
    {
      "epoch": 4.022824355153742,
      "grad_norm": 4.401484966278076,
      "learning_rate": 2.9893976286258735e-05,
      "loss": 0.7616,
      "step": 380000
    },
    {
      "epoch": 4.022824355153742,
      "eval_loss": 0.531063973903656,
      "eval_runtime": 46.5409,
      "eval_samples_per_second": 3608.221,
      "eval_steps_per_second": 451.044,
      "step": 380000
    },
    {
      "epoch": 4.023353676933745,
      "grad_norm": 4.228377342224121,
      "learning_rate": 2.9891329663349566e-05,
      "loss": 0.763,
      "step": 380050
    },
    {
      "epoch": 4.023882998713748,
      "grad_norm": 4.387795925140381,
      "learning_rate": 2.9888683040440403e-05,
      "loss": 0.7697,
      "step": 380100
    },
    {
      "epoch": 4.024412320493751,
      "grad_norm": 4.616596698760986,
      "learning_rate": 2.9886036417531234e-05,
      "loss": 0.7519,
      "step": 380150
    },
    {
      "epoch": 4.024941642273754,
      "grad_norm": 4.358026027679443,
      "learning_rate": 2.9883389794622064e-05,
      "loss": 0.7565,
      "step": 380200
    },
    {
      "epoch": 4.025470964053758,
      "grad_norm": 4.224277973175049,
      "learning_rate": 2.9880743171712895e-05,
      "loss": 0.7718,
      "step": 380250
    },
    {
      "epoch": 4.026000285833761,
      "grad_norm": 4.092035293579102,
      "learning_rate": 2.987809654880373e-05,
      "loss": 0.7719,
      "step": 380300
    },
    {
      "epoch": 4.026529607613765,
      "grad_norm": 3.8996963500976562,
      "learning_rate": 2.987544992589456e-05,
      "loss": 0.7567,
      "step": 380350
    },
    {
      "epoch": 4.0270589293937675,
      "grad_norm": 4.199379920959473,
      "learning_rate": 2.987280330298539e-05,
      "loss": 0.7538,
      "step": 380400
    },
    {
      "epoch": 4.027588251173771,
      "grad_norm": 4.781591892242432,
      "learning_rate": 2.987015668007622e-05,
      "loss": 0.7626,
      "step": 380450
    },
    {
      "epoch": 4.028117572953774,
      "grad_norm": 3.971179723739624,
      "learning_rate": 2.986751005716706e-05,
      "loss": 0.7566,
      "step": 380500
    },
    {
      "epoch": 4.028117572953774,
      "eval_loss": 0.5308670997619629,
      "eval_runtime": 46.5284,
      "eval_samples_per_second": 3609.196,
      "eval_steps_per_second": 451.166,
      "step": 380500
    },
    {
      "epoch": 4.028646894733778,
      "grad_norm": 4.210834503173828,
      "learning_rate": 2.986486343425789e-05,
      "loss": 0.7779,
      "step": 380550
    },
    {
      "epoch": 4.029176216513781,
      "grad_norm": 4.0960516929626465,
      "learning_rate": 2.986221681134872e-05,
      "loss": 0.749,
      "step": 380600
    },
    {
      "epoch": 4.0297055382937845,
      "grad_norm": 3.9712131023406982,
      "learning_rate": 2.985957018843955e-05,
      "loss": 0.7648,
      "step": 380650
    },
    {
      "epoch": 4.030234860073787,
      "grad_norm": 4.522880554199219,
      "learning_rate": 2.985692356553039e-05,
      "loss": 0.7675,
      "step": 380700
    },
    {
      "epoch": 4.030764181853791,
      "grad_norm": 3.8895864486694336,
      "learning_rate": 2.985427694262122e-05,
      "loss": 0.7551,
      "step": 380750
    },
    {
      "epoch": 4.031293503633794,
      "grad_norm": 4.236183166503906,
      "learning_rate": 2.985163031971205e-05,
      "loss": 0.7646,
      "step": 380800
    },
    {
      "epoch": 4.031822825413797,
      "grad_norm": 3.7726855278015137,
      "learning_rate": 2.984898369680288e-05,
      "loss": 0.755,
      "step": 380850
    },
    {
      "epoch": 4.032352147193801,
      "grad_norm": 3.9072883129119873,
      "learning_rate": 2.9846337073893715e-05,
      "loss": 0.7621,
      "step": 380900
    },
    {
      "epoch": 4.0328814689738035,
      "grad_norm": 4.427225589752197,
      "learning_rate": 2.9843690450984545e-05,
      "loss": 0.767,
      "step": 380950
    },
    {
      "epoch": 4.033410790753807,
      "grad_norm": 4.422409534454346,
      "learning_rate": 2.9841043828075376e-05,
      "loss": 0.7689,
      "step": 381000
    },
    {
      "epoch": 4.033410790753807,
      "eval_loss": 0.5302286148071289,
      "eval_runtime": 46.574,
      "eval_samples_per_second": 3605.662,
      "eval_steps_per_second": 450.724,
      "step": 381000
    },
    {
      "epoch": 4.03394011253381,
      "grad_norm": 4.179310321807861,
      "learning_rate": 2.9838397205166207e-05,
      "loss": 0.7587,
      "step": 381050
    },
    {
      "epoch": 4.034469434313814,
      "grad_norm": 3.834364414215088,
      "learning_rate": 2.9835750582257044e-05,
      "loss": 0.7739,
      "step": 381100
    },
    {
      "epoch": 4.034998756093817,
      "grad_norm": 4.1810832023620605,
      "learning_rate": 2.9833103959347875e-05,
      "loss": 0.7586,
      "step": 381150
    },
    {
      "epoch": 4.0355280778738205,
      "grad_norm": 4.382955074310303,
      "learning_rate": 2.9830457336438706e-05,
      "loss": 0.7528,
      "step": 381200
    },
    {
      "epoch": 4.036057399653823,
      "grad_norm": 4.373548984527588,
      "learning_rate": 2.9827810713529537e-05,
      "loss": 0.7563,
      "step": 381250
    },
    {
      "epoch": 4.036586721433827,
      "grad_norm": 3.851290225982666,
      "learning_rate": 2.982516409062037e-05,
      "loss": 0.7576,
      "step": 381300
    },
    {
      "epoch": 4.03711604321383,
      "grad_norm": 4.0782246589660645,
      "learning_rate": 2.98225174677112e-05,
      "loss": 0.7711,
      "step": 381350
    },
    {
      "epoch": 4.037645364993834,
      "grad_norm": 4.553401470184326,
      "learning_rate": 2.9819870844802032e-05,
      "loss": 0.765,
      "step": 381400
    },
    {
      "epoch": 4.038174686773837,
      "grad_norm": 4.213583946228027,
      "learning_rate": 2.9817224221892863e-05,
      "loss": 0.7715,
      "step": 381450
    },
    {
      "epoch": 4.03870400855384,
      "grad_norm": 4.12986946105957,
      "learning_rate": 2.98145775989837e-05,
      "loss": 0.7608,
      "step": 381500
    },
    {
      "epoch": 4.03870400855384,
      "eval_loss": 0.5296184420585632,
      "eval_runtime": 46.5909,
      "eval_samples_per_second": 3604.354,
      "eval_steps_per_second": 450.56,
      "step": 381500
    },
    {
      "epoch": 4.039233330333843,
      "grad_norm": 4.28407096862793,
      "learning_rate": 2.981193097607453e-05,
      "loss": 0.7771,
      "step": 381550
    },
    {
      "epoch": 4.039762652113846,
      "grad_norm": 3.985630750656128,
      "learning_rate": 2.980928435316536e-05,
      "loss": 0.7614,
      "step": 381600
    },
    {
      "epoch": 4.04029197389385,
      "grad_norm": 4.572123050689697,
      "learning_rate": 2.9806637730256192e-05,
      "loss": 0.7704,
      "step": 381650
    },
    {
      "epoch": 4.040821295673853,
      "grad_norm": 4.394506454467773,
      "learning_rate": 2.980399110734703e-05,
      "loss": 0.7714,
      "step": 381700
    },
    {
      "epoch": 4.0413506174538565,
      "grad_norm": 3.946957588195801,
      "learning_rate": 2.980134448443786e-05,
      "loss": 0.7555,
      "step": 381750
    },
    {
      "epoch": 4.041879939233859,
      "grad_norm": 4.134579181671143,
      "learning_rate": 2.979869786152869e-05,
      "loss": 0.7671,
      "step": 381800
    },
    {
      "epoch": 4.042409261013863,
      "grad_norm": 4.317967891693115,
      "learning_rate": 2.9796051238619522e-05,
      "loss": 0.7647,
      "step": 381850
    },
    {
      "epoch": 4.042938582793866,
      "grad_norm": 4.219317436218262,
      "learning_rate": 2.9793404615710356e-05,
      "loss": 0.7783,
      "step": 381900
    },
    {
      "epoch": 4.04346790457387,
      "grad_norm": 4.107919692993164,
      "learning_rate": 2.9790757992801187e-05,
      "loss": 0.7588,
      "step": 381950
    },
    {
      "epoch": 4.043997226353873,
      "grad_norm": 4.481422424316406,
      "learning_rate": 2.9788111369892018e-05,
      "loss": 0.7614,
      "step": 382000
    },
    {
      "epoch": 4.043997226353873,
      "eval_loss": 0.5292726159095764,
      "eval_runtime": 46.5278,
      "eval_samples_per_second": 3609.242,
      "eval_steps_per_second": 451.171,
      "step": 382000
    },
    {
      "epoch": 4.044526548133876,
      "grad_norm": 3.907508134841919,
      "learning_rate": 2.9785464746982848e-05,
      "loss": 0.7504,
      "step": 382050
    },
    {
      "epoch": 4.045055869913879,
      "grad_norm": 3.950958251953125,
      "learning_rate": 2.9782818124073686e-05,
      "loss": 0.7519,
      "step": 382100
    },
    {
      "epoch": 4.045585191693883,
      "grad_norm": 3.908931255340576,
      "learning_rate": 2.9780171501164516e-05,
      "loss": 0.7709,
      "step": 382150
    },
    {
      "epoch": 4.046114513473886,
      "grad_norm": 4.3242669105529785,
      "learning_rate": 2.9777524878255347e-05,
      "loss": 0.7587,
      "step": 382200
    },
    {
      "epoch": 4.04664383525389,
      "grad_norm": 4.225714683532715,
      "learning_rate": 2.9774878255346178e-05,
      "loss": 0.7599,
      "step": 382250
    },
    {
      "epoch": 4.0471731570338925,
      "grad_norm": 4.444633483886719,
      "learning_rate": 2.9772231632437015e-05,
      "loss": 0.7662,
      "step": 382300
    },
    {
      "epoch": 4.047702478813895,
      "grad_norm": 4.375622749328613,
      "learning_rate": 2.9769585009527846e-05,
      "loss": 0.7648,
      "step": 382350
    },
    {
      "epoch": 4.048231800593899,
      "grad_norm": 4.302059173583984,
      "learning_rate": 2.9766938386618677e-05,
      "loss": 0.7586,
      "step": 382400
    },
    {
      "epoch": 4.048761122373902,
      "grad_norm": 4.438632965087891,
      "learning_rate": 2.9764291763709507e-05,
      "loss": 0.7726,
      "step": 382450
    },
    {
      "epoch": 4.049290444153906,
      "grad_norm": 4.153834819793701,
      "learning_rate": 2.976164514080034e-05,
      "loss": 0.7796,
      "step": 382500
    },
    {
      "epoch": 4.049290444153906,
      "eval_loss": 0.5289766788482666,
      "eval_runtime": 46.5138,
      "eval_samples_per_second": 3610.326,
      "eval_steps_per_second": 451.307,
      "step": 382500
    },
    {
      "epoch": 4.049819765933909,
      "grad_norm": 4.217895030975342,
      "learning_rate": 2.9758998517891172e-05,
      "loss": 0.7652,
      "step": 382550
    },
    {
      "epoch": 4.050349087713912,
      "grad_norm": 4.368393421173096,
      "learning_rate": 2.9756351894982003e-05,
      "loss": 0.7743,
      "step": 382600
    },
    {
      "epoch": 4.050878409493915,
      "grad_norm": 4.295719623565674,
      "learning_rate": 2.9753705272072834e-05,
      "loss": 0.768,
      "step": 382650
    },
    {
      "epoch": 4.051407731273919,
      "grad_norm": 4.0590996742248535,
      "learning_rate": 2.975105864916367e-05,
      "loss": 0.7714,
      "step": 382700
    },
    {
      "epoch": 4.051937053053922,
      "grad_norm": 4.425597667694092,
      "learning_rate": 2.9748412026254502e-05,
      "loss": 0.7555,
      "step": 382750
    },
    {
      "epoch": 4.052466374833926,
      "grad_norm": 4.398949146270752,
      "learning_rate": 2.9745765403345333e-05,
      "loss": 0.7657,
      "step": 382800
    },
    {
      "epoch": 4.0529956966139284,
      "grad_norm": 3.678510904312134,
      "learning_rate": 2.9743118780436163e-05,
      "loss": 0.7735,
      "step": 382850
    },
    {
      "epoch": 4.053525018393932,
      "grad_norm": 4.475417613983154,
      "learning_rate": 2.9740472157527e-05,
      "loss": 0.7663,
      "step": 382900
    },
    {
      "epoch": 4.054054340173935,
      "grad_norm": 4.01842737197876,
      "learning_rate": 2.973782553461783e-05,
      "loss": 0.7498,
      "step": 382950
    },
    {
      "epoch": 4.054583661953939,
      "grad_norm": 4.128309726715088,
      "learning_rate": 2.9735178911708662e-05,
      "loss": 0.7594,
      "step": 383000
    },
    {
      "epoch": 4.054583661953939,
      "eval_loss": 0.5294097661972046,
      "eval_runtime": 46.4899,
      "eval_samples_per_second": 3612.179,
      "eval_steps_per_second": 451.538,
      "step": 383000
    },
    {
      "epoch": 4.055112983733942,
      "grad_norm": 3.8432347774505615,
      "learning_rate": 2.9732532288799493e-05,
      "loss": 0.7663,
      "step": 383050
    },
    {
      "epoch": 4.055642305513945,
      "grad_norm": 4.161632061004639,
      "learning_rate": 2.9729885665890327e-05,
      "loss": 0.7639,
      "step": 383100
    },
    {
      "epoch": 4.056171627293948,
      "grad_norm": 4.354556560516357,
      "learning_rate": 2.9727239042981158e-05,
      "loss": 0.7518,
      "step": 383150
    },
    {
      "epoch": 4.056700949073951,
      "grad_norm": 4.288875579833984,
      "learning_rate": 2.972459242007199e-05,
      "loss": 0.7649,
      "step": 383200
    },
    {
      "epoch": 4.057230270853955,
      "grad_norm": 4.383194923400879,
      "learning_rate": 2.972194579716282e-05,
      "loss": 0.7555,
      "step": 383250
    },
    {
      "epoch": 4.057759592633958,
      "grad_norm": 4.2136077880859375,
      "learning_rate": 2.9719299174253657e-05,
      "loss": 0.7741,
      "step": 383300
    },
    {
      "epoch": 4.058288914413962,
      "grad_norm": 4.240868091583252,
      "learning_rate": 2.9716652551344487e-05,
      "loss": 0.7596,
      "step": 383350
    },
    {
      "epoch": 4.058818236193964,
      "grad_norm": 4.293349742889404,
      "learning_rate": 2.9714005928435318e-05,
      "loss": 0.7597,
      "step": 383400
    },
    {
      "epoch": 4.059347557973968,
      "grad_norm": 3.990034818649292,
      "learning_rate": 2.971135930552615e-05,
      "loss": 0.7733,
      "step": 383450
    },
    {
      "epoch": 4.059876879753971,
      "grad_norm": 3.9512217044830322,
      "learning_rate": 2.9708712682616986e-05,
      "loss": 0.7684,
      "step": 383500
    },
    {
      "epoch": 4.059876879753971,
      "eval_loss": 0.5277302265167236,
      "eval_runtime": 46.5772,
      "eval_samples_per_second": 3605.412,
      "eval_steps_per_second": 450.693,
      "step": 383500
    },
    {
      "epoch": 4.060406201533975,
      "grad_norm": 4.033934593200684,
      "learning_rate": 2.9706066059707817e-05,
      "loss": 0.7551,
      "step": 383550
    },
    {
      "epoch": 4.060935523313978,
      "grad_norm": 4.498709678649902,
      "learning_rate": 2.9703419436798648e-05,
      "loss": 0.7654,
      "step": 383600
    },
    {
      "epoch": 4.061464845093981,
      "grad_norm": 4.307400226593018,
      "learning_rate": 2.970077281388948e-05,
      "loss": 0.7756,
      "step": 383650
    },
    {
      "epoch": 4.061994166873984,
      "grad_norm": 4.371833324432373,
      "learning_rate": 2.9698126190980313e-05,
      "loss": 0.7662,
      "step": 383700
    },
    {
      "epoch": 4.062523488653988,
      "grad_norm": 4.140801906585693,
      "learning_rate": 2.9695479568071143e-05,
      "loss": 0.7489,
      "step": 383750
    },
    {
      "epoch": 4.063052810433991,
      "grad_norm": 4.072778701782227,
      "learning_rate": 2.9692885877620158e-05,
      "loss": 0.7517,
      "step": 383800
    },
    {
      "epoch": 4.063582132213994,
      "grad_norm": 3.9853124618530273,
      "learning_rate": 2.969023925471099e-05,
      "loss": 0.7741,
      "step": 383850
    },
    {
      "epoch": 4.0641114539939975,
      "grad_norm": 4.08955192565918,
      "learning_rate": 2.9687592631801826e-05,
      "loss": 0.7545,
      "step": 383900
    },
    {
      "epoch": 4.064640775774,
      "grad_norm": 4.765847206115723,
      "learning_rate": 2.9684946008892657e-05,
      "loss": 0.7596,
      "step": 383950
    },
    {
      "epoch": 4.065170097554004,
      "grad_norm": 4.219085693359375,
      "learning_rate": 2.9682299385983488e-05,
      "loss": 0.7833,
      "step": 384000
    },
    {
      "epoch": 4.065170097554004,
      "eval_loss": 0.5277657508850098,
      "eval_runtime": 46.5021,
      "eval_samples_per_second": 3611.238,
      "eval_steps_per_second": 451.421,
      "step": 384000
    },
    {
      "epoch": 4.065699419334007,
      "grad_norm": 4.430149555206299,
      "learning_rate": 2.9679652763074318e-05,
      "loss": 0.7602,
      "step": 384050
    },
    {
      "epoch": 4.066228741114011,
      "grad_norm": 4.027163505554199,
      "learning_rate": 2.9677006140165152e-05,
      "loss": 0.7768,
      "step": 384100
    },
    {
      "epoch": 4.066758062894014,
      "grad_norm": 3.84317946434021,
      "learning_rate": 2.9674359517255983e-05,
      "loss": 0.7502,
      "step": 384150
    },
    {
      "epoch": 4.067287384674017,
      "grad_norm": 4.329580307006836,
      "learning_rate": 2.9671712894346814e-05,
      "loss": 0.7661,
      "step": 384200
    },
    {
      "epoch": 4.06781670645402,
      "grad_norm": 4.498425483703613,
      "learning_rate": 2.9669066271437645e-05,
      "loss": 0.7619,
      "step": 384250
    },
    {
      "epoch": 4.068346028234024,
      "grad_norm": 3.943525791168213,
      "learning_rate": 2.9666419648528482e-05,
      "loss": 0.773,
      "step": 384300
    },
    {
      "epoch": 4.068875350014027,
      "grad_norm": 4.395912170410156,
      "learning_rate": 2.9663773025619313e-05,
      "loss": 0.7573,
      "step": 384350
    },
    {
      "epoch": 4.069404671794031,
      "grad_norm": 3.913084030151367,
      "learning_rate": 2.9661126402710143e-05,
      "loss": 0.7676,
      "step": 384400
    },
    {
      "epoch": 4.0699339935740335,
      "grad_norm": 4.140228748321533,
      "learning_rate": 2.9658479779800974e-05,
      "loss": 0.7609,
      "step": 384450
    },
    {
      "epoch": 4.070463315354037,
      "grad_norm": 4.56555700302124,
      "learning_rate": 2.965583315689181e-05,
      "loss": 0.7618,
      "step": 384500
    },
    {
      "epoch": 4.070463315354037,
      "eval_loss": 0.527048647403717,
      "eval_runtime": 46.5052,
      "eval_samples_per_second": 3610.993,
      "eval_steps_per_second": 451.39,
      "step": 384500
    },
    {
      "epoch": 4.07099263713404,
      "grad_norm": 4.176001071929932,
      "learning_rate": 2.9653186533982642e-05,
      "loss": 0.7484,
      "step": 384550
    },
    {
      "epoch": 4.071521958914043,
      "grad_norm": 4.504903793334961,
      "learning_rate": 2.9650539911073473e-05,
      "loss": 0.7586,
      "step": 384600
    },
    {
      "epoch": 4.072051280694047,
      "grad_norm": 4.09109354019165,
      "learning_rate": 2.9647893288164304e-05,
      "loss": 0.7615,
      "step": 384650
    },
    {
      "epoch": 4.07258060247405,
      "grad_norm": 4.041542053222656,
      "learning_rate": 2.9645246665255138e-05,
      "loss": 0.7776,
      "step": 384700
    },
    {
      "epoch": 4.073109924254053,
      "grad_norm": 3.9794974327087402,
      "learning_rate": 2.964260004234597e-05,
      "loss": 0.7602,
      "step": 384750
    },
    {
      "epoch": 4.073639246034056,
      "grad_norm": 4.2258992195129395,
      "learning_rate": 2.96399534194368e-05,
      "loss": 0.7602,
      "step": 384800
    },
    {
      "epoch": 4.07416856781406,
      "grad_norm": 4.434426784515381,
      "learning_rate": 2.963730679652763e-05,
      "loss": 0.7693,
      "step": 384850
    },
    {
      "epoch": 4.074697889594063,
      "grad_norm": 3.9830856323242188,
      "learning_rate": 2.9634660173618468e-05,
      "loss": 0.7644,
      "step": 384900
    },
    {
      "epoch": 4.075227211374067,
      "grad_norm": 4.3710737228393555,
      "learning_rate": 2.9632013550709298e-05,
      "loss": 0.7524,
      "step": 384950
    },
    {
      "epoch": 4.0757565331540695,
      "grad_norm": 3.9815258979797363,
      "learning_rate": 2.962936692780013e-05,
      "loss": 0.7699,
      "step": 385000
    },
    {
      "epoch": 4.0757565331540695,
      "eval_loss": 0.5256626605987549,
      "eval_runtime": 46.5325,
      "eval_samples_per_second": 3608.878,
      "eval_steps_per_second": 451.126,
      "step": 385000
    },
    {
      "epoch": 4.076285854934073,
      "grad_norm": 4.248737335205078,
      "learning_rate": 2.962672030489096e-05,
      "loss": 0.7536,
      "step": 385050
    },
    {
      "epoch": 4.076815176714076,
      "grad_norm": 4.279881000518799,
      "learning_rate": 2.962407368198179e-05,
      "loss": 0.7579,
      "step": 385100
    },
    {
      "epoch": 4.07734449849408,
      "grad_norm": 4.62556791305542,
      "learning_rate": 2.9621427059072628e-05,
      "loss": 0.7607,
      "step": 385150
    },
    {
      "epoch": 4.077873820274083,
      "grad_norm": 4.231188774108887,
      "learning_rate": 2.961878043616346e-05,
      "loss": 0.7568,
      "step": 385200
    },
    {
      "epoch": 4.0784031420540865,
      "grad_norm": 4.286266326904297,
      "learning_rate": 2.961613381325429e-05,
      "loss": 0.767,
      "step": 385250
    },
    {
      "epoch": 4.078932463834089,
      "grad_norm": 4.100372791290283,
      "learning_rate": 2.961348719034512e-05,
      "loss": 0.775,
      "step": 385300
    },
    {
      "epoch": 4.079461785614092,
      "grad_norm": 4.136229515075684,
      "learning_rate": 2.9610840567435954e-05,
      "loss": 0.7612,
      "step": 385350
    },
    {
      "epoch": 4.079991107394096,
      "grad_norm": 4.52493143081665,
      "learning_rate": 2.9608193944526785e-05,
      "loss": 0.7735,
      "step": 385400
    },
    {
      "epoch": 4.080520429174099,
      "grad_norm": 4.291000843048096,
      "learning_rate": 2.9605547321617616e-05,
      "loss": 0.7549,
      "step": 385450
    },
    {
      "epoch": 4.081049750954103,
      "grad_norm": 4.317451477050781,
      "learning_rate": 2.9602900698708446e-05,
      "loss": 0.7523,
      "step": 385500
    },
    {
      "epoch": 4.081049750954103,
      "eval_loss": 0.5234965085983276,
      "eval_runtime": 46.6034,
      "eval_samples_per_second": 3603.382,
      "eval_steps_per_second": 450.439,
      "step": 385500
    },
    {
      "epoch": 4.0815790727341055,
      "grad_norm": 4.266585826873779,
      "learning_rate": 2.9600254075799284e-05,
      "loss": 0.7604,
      "step": 385550
    },
    {
      "epoch": 4.082108394514109,
      "grad_norm": 4.342759132385254,
      "learning_rate": 2.9597607452890114e-05,
      "loss": 0.7729,
      "step": 385600
    },
    {
      "epoch": 4.082637716294112,
      "grad_norm": 4.2024149894714355,
      "learning_rate": 2.9594960829980945e-05,
      "loss": 0.7689,
      "step": 385650
    },
    {
      "epoch": 4.083167038074116,
      "grad_norm": 4.2104668617248535,
      "learning_rate": 2.9592314207071776e-05,
      "loss": 0.7606,
      "step": 385700
    },
    {
      "epoch": 4.083696359854119,
      "grad_norm": 4.557609558105469,
      "learning_rate": 2.958966758416261e-05,
      "loss": 0.7657,
      "step": 385750
    },
    {
      "epoch": 4.0842256816341225,
      "grad_norm": 4.232842445373535,
      "learning_rate": 2.9587073893711625e-05,
      "loss": 0.7551,
      "step": 385800
    },
    {
      "epoch": 4.084755003414125,
      "grad_norm": 4.221548557281494,
      "learning_rate": 2.9584427270802455e-05,
      "loss": 0.7689,
      "step": 385850
    },
    {
      "epoch": 4.085284325194129,
      "grad_norm": 3.849738597869873,
      "learning_rate": 2.9581780647893286e-05,
      "loss": 0.7565,
      "step": 385900
    },
    {
      "epoch": 4.085813646974132,
      "grad_norm": 4.073444843292236,
      "learning_rate": 2.9579134024984124e-05,
      "loss": 0.7593,
      "step": 385950
    },
    {
      "epoch": 4.086342968754136,
      "grad_norm": 4.1995015144348145,
      "learning_rate": 2.9576487402074954e-05,
      "loss": 0.7571,
      "step": 386000
    },
    {
      "epoch": 4.086342968754136,
      "eval_loss": 0.5256859064102173,
      "eval_runtime": 46.6288,
      "eval_samples_per_second": 3601.421,
      "eval_steps_per_second": 450.194,
      "step": 386000
    },
    {
      "epoch": 4.086872290534139,
      "grad_norm": 4.186793327331543,
      "learning_rate": 2.9573840779165785e-05,
      "loss": 0.7695,
      "step": 386050
    },
    {
      "epoch": 4.087401612314142,
      "grad_norm": 4.278379917144775,
      "learning_rate": 2.9571194156256616e-05,
      "loss": 0.7537,
      "step": 386100
    },
    {
      "epoch": 4.087930934094145,
      "grad_norm": 3.9614853858947754,
      "learning_rate": 2.9568547533347453e-05,
      "loss": 0.7639,
      "step": 386150
    },
    {
      "epoch": 4.088460255874148,
      "grad_norm": 4.310866832733154,
      "learning_rate": 2.9565900910438284e-05,
      "loss": 0.7637,
      "step": 386200
    },
    {
      "epoch": 4.088989577654152,
      "grad_norm": 3.9106836318969727,
      "learning_rate": 2.9563254287529115e-05,
      "loss": 0.7692,
      "step": 386250
    },
    {
      "epoch": 4.089518899434155,
      "grad_norm": 3.902564525604248,
      "learning_rate": 2.9560607664619945e-05,
      "loss": 0.7779,
      "step": 386300
    },
    {
      "epoch": 4.0900482212141585,
      "grad_norm": 4.34165096282959,
      "learning_rate": 2.955796104171078e-05,
      "loss": 0.7561,
      "step": 386350
    },
    {
      "epoch": 4.090577542994161,
      "grad_norm": 4.140294075012207,
      "learning_rate": 2.955531441880161e-05,
      "loss": 0.754,
      "step": 386400
    },
    {
      "epoch": 4.091106864774165,
      "grad_norm": 3.7384843826293945,
      "learning_rate": 2.955266779589244e-05,
      "loss": 0.7697,
      "step": 386450
    },
    {
      "epoch": 4.091636186554168,
      "grad_norm": 4.048930644989014,
      "learning_rate": 2.955002117298327e-05,
      "loss": 0.7619,
      "step": 386500
    },
    {
      "epoch": 4.091636186554168,
      "eval_loss": 0.5239469408988953,
      "eval_runtime": 46.5557,
      "eval_samples_per_second": 3607.079,
      "eval_steps_per_second": 450.901,
      "step": 386500
    },
    {
      "epoch": 4.092165508334172,
      "grad_norm": 4.232360363006592,
      "learning_rate": 2.954737455007411e-05,
      "loss": 0.7686,
      "step": 386550
    },
    {
      "epoch": 4.092694830114175,
      "grad_norm": 4.199079990386963,
      "learning_rate": 2.954472792716494e-05,
      "loss": 0.7776,
      "step": 386600
    },
    {
      "epoch": 4.093224151894178,
      "grad_norm": 4.0903143882751465,
      "learning_rate": 2.954208130425577e-05,
      "loss": 0.757,
      "step": 386650
    },
    {
      "epoch": 4.093753473674181,
      "grad_norm": 4.344687461853027,
      "learning_rate": 2.95394346813466e-05,
      "loss": 0.7566,
      "step": 386700
    },
    {
      "epoch": 4.094282795454185,
      "grad_norm": 4.077544212341309,
      "learning_rate": 2.9536788058437435e-05,
      "loss": 0.7483,
      "step": 386750
    },
    {
      "epoch": 4.094812117234188,
      "grad_norm": 3.7809407711029053,
      "learning_rate": 2.9534141435528266e-05,
      "loss": 0.765,
      "step": 386800
    },
    {
      "epoch": 4.095341439014192,
      "grad_norm": 4.259209632873535,
      "learning_rate": 2.9531494812619097e-05,
      "loss": 0.7722,
      "step": 386850
    },
    {
      "epoch": 4.095870760794194,
      "grad_norm": 3.89642596244812,
      "learning_rate": 2.9528848189709927e-05,
      "loss": 0.7684,
      "step": 386900
    },
    {
      "epoch": 4.096400082574197,
      "grad_norm": 4.320885181427002,
      "learning_rate": 2.9526201566800765e-05,
      "loss": 0.7635,
      "step": 386950
    },
    {
      "epoch": 4.096929404354201,
      "grad_norm": 3.9330170154571533,
      "learning_rate": 2.9523554943891596e-05,
      "loss": 0.7717,
      "step": 387000
    },
    {
      "epoch": 4.096929404354201,
      "eval_loss": 0.5255987644195557,
      "eval_runtime": 46.6742,
      "eval_samples_per_second": 3597.92,
      "eval_steps_per_second": 449.756,
      "step": 387000
    },
    {
      "epoch": 4.097458726134204,
      "grad_norm": 4.526287078857422,
      "learning_rate": 2.9520908320982426e-05,
      "loss": 0.7717,
      "step": 387050
    },
    {
      "epoch": 4.097988047914208,
      "grad_norm": 4.128446102142334,
      "learning_rate": 2.9518261698073257e-05,
      "loss": 0.7699,
      "step": 387100
    },
    {
      "epoch": 4.0985173696942105,
      "grad_norm": 4.078320503234863,
      "learning_rate": 2.9515615075164095e-05,
      "loss": 0.7628,
      "step": 387150
    },
    {
      "epoch": 4.099046691474214,
      "grad_norm": 4.037356853485107,
      "learning_rate": 2.9512968452254925e-05,
      "loss": 0.7646,
      "step": 387200
    },
    {
      "epoch": 4.099576013254217,
      "grad_norm": 4.571269989013672,
      "learning_rate": 2.9510321829345756e-05,
      "loss": 0.7773,
      "step": 387250
    },
    {
      "epoch": 4.100105335034221,
      "grad_norm": 4.2710747718811035,
      "learning_rate": 2.9507675206436587e-05,
      "loss": 0.7669,
      "step": 387300
    },
    {
      "epoch": 4.100634656814224,
      "grad_norm": 4.219757080078125,
      "learning_rate": 2.950502858352742e-05,
      "loss": 0.7717,
      "step": 387350
    },
    {
      "epoch": 4.1011639785942275,
      "grad_norm": 4.184330463409424,
      "learning_rate": 2.950238196061825e-05,
      "loss": 0.7625,
      "step": 387400
    },
    {
      "epoch": 4.10169330037423,
      "grad_norm": 4.250524997711182,
      "learning_rate": 2.9499735337709082e-05,
      "loss": 0.7648,
      "step": 387450
    },
    {
      "epoch": 4.102222622154234,
      "grad_norm": 4.067229270935059,
      "learning_rate": 2.9497088714799913e-05,
      "loss": 0.7714,
      "step": 387500
    },
    {
      "epoch": 4.102222622154234,
      "eval_loss": 0.526088297367096,
      "eval_runtime": 46.7648,
      "eval_samples_per_second": 3590.949,
      "eval_steps_per_second": 448.885,
      "step": 387500
    },
    {
      "epoch": 4.102751943934237,
      "grad_norm": 4.05208158493042,
      "learning_rate": 2.949444209189075e-05,
      "loss": 0.7546,
      "step": 387550
    },
    {
      "epoch": 4.103281265714241,
      "grad_norm": 4.117391109466553,
      "learning_rate": 2.949179546898158e-05,
      "loss": 0.77,
      "step": 387600
    },
    {
      "epoch": 4.103810587494244,
      "grad_norm": 3.97537899017334,
      "learning_rate": 2.9489148846072412e-05,
      "loss": 0.7689,
      "step": 387650
    },
    {
      "epoch": 4.1043399092742465,
      "grad_norm": 4.269654273986816,
      "learning_rate": 2.9486502223163243e-05,
      "loss": 0.7692,
      "step": 387700
    },
    {
      "epoch": 4.10486923105425,
      "grad_norm": 3.8266844749450684,
      "learning_rate": 2.948385560025408e-05,
      "loss": 0.7593,
      "step": 387750
    },
    {
      "epoch": 4.105398552834253,
      "grad_norm": 4.200038433074951,
      "learning_rate": 2.948126190980309e-05,
      "loss": 0.7593,
      "step": 387800
    },
    {
      "epoch": 4.105927874614257,
      "grad_norm": 3.9068267345428467,
      "learning_rate": 2.9478615286893922e-05,
      "loss": 0.7617,
      "step": 387850
    },
    {
      "epoch": 4.10645719639426,
      "grad_norm": 4.581441402435303,
      "learning_rate": 2.9475968663984753e-05,
      "loss": 0.7674,
      "step": 387900
    },
    {
      "epoch": 4.1069865181742635,
      "grad_norm": 4.150703430175781,
      "learning_rate": 2.947332204107559e-05,
      "loss": 0.7519,
      "step": 387950
    },
    {
      "epoch": 4.107515839954266,
      "grad_norm": 4.422143459320068,
      "learning_rate": 2.947067541816642e-05,
      "loss": 0.769,
      "step": 388000
    },
    {
      "epoch": 4.107515839954266,
      "eval_loss": 0.526640772819519,
      "eval_runtime": 46.5806,
      "eval_samples_per_second": 3605.147,
      "eval_steps_per_second": 450.659,
      "step": 388000
    },
    {
      "epoch": 4.10804516173427,
      "grad_norm": 4.259177207946777,
      "learning_rate": 2.946802879525725e-05,
      "loss": 0.7657,
      "step": 388050
    },
    {
      "epoch": 4.108574483514273,
      "grad_norm": 4.540133476257324,
      "learning_rate": 2.9465382172348082e-05,
      "loss": 0.7695,
      "step": 388100
    },
    {
      "epoch": 4.109103805294277,
      "grad_norm": 4.084564685821533,
      "learning_rate": 2.946273554943892e-05,
      "loss": 0.7478,
      "step": 388150
    },
    {
      "epoch": 4.10963312707428,
      "grad_norm": 4.106934070587158,
      "learning_rate": 2.946008892652975e-05,
      "loss": 0.7717,
      "step": 388200
    },
    {
      "epoch": 4.110162448854283,
      "grad_norm": 4.256328105926514,
      "learning_rate": 2.945744230362058e-05,
      "loss": 0.7608,
      "step": 388250
    },
    {
      "epoch": 4.110691770634286,
      "grad_norm": 4.191086769104004,
      "learning_rate": 2.9454795680711412e-05,
      "loss": 0.7646,
      "step": 388300
    },
    {
      "epoch": 4.11122109241429,
      "grad_norm": 4.40498161315918,
      "learning_rate": 2.9452149057802246e-05,
      "loss": 0.7613,
      "step": 388350
    },
    {
      "epoch": 4.111750414194293,
      "grad_norm": 4.005038261413574,
      "learning_rate": 2.9449502434893077e-05,
      "loss": 0.7641,
      "step": 388400
    },
    {
      "epoch": 4.112279735974296,
      "grad_norm": 4.098432540893555,
      "learning_rate": 2.9446855811983908e-05,
      "loss": 0.767,
      "step": 388450
    },
    {
      "epoch": 4.1128090577542995,
      "grad_norm": 4.147642135620117,
      "learning_rate": 2.9444209189074738e-05,
      "loss": 0.7545,
      "step": 388500
    },
    {
      "epoch": 4.1128090577542995,
      "eval_loss": 0.5256965160369873,
      "eval_runtime": 46.6107,
      "eval_samples_per_second": 3602.821,
      "eval_steps_per_second": 450.369,
      "step": 388500
    },
    {
      "epoch": 4.113338379534302,
      "grad_norm": 4.269736289978027,
      "learning_rate": 2.9441562566165576e-05,
      "loss": 0.7662,
      "step": 388550
    },
    {
      "epoch": 4.113867701314306,
      "grad_norm": 4.111142635345459,
      "learning_rate": 2.9438915943256406e-05,
      "loss": 0.7598,
      "step": 388600
    },
    {
      "epoch": 4.114397023094309,
      "grad_norm": 3.715221405029297,
      "learning_rate": 2.9436269320347237e-05,
      "loss": 0.7568,
      "step": 388650
    },
    {
      "epoch": 4.114926344874313,
      "grad_norm": 4.063857078552246,
      "learning_rate": 2.9433622697438068e-05,
      "loss": 0.7652,
      "step": 388700
    },
    {
      "epoch": 4.115455666654316,
      "grad_norm": 4.067409515380859,
      "learning_rate": 2.9430976074528905e-05,
      "loss": 0.761,
      "step": 388750
    },
    {
      "epoch": 4.115984988434319,
      "grad_norm": 4.179115295410156,
      "learning_rate": 2.9428329451619736e-05,
      "loss": 0.7555,
      "step": 388800
    },
    {
      "epoch": 4.116514310214322,
      "grad_norm": 4.444468021392822,
      "learning_rate": 2.9425682828710567e-05,
      "loss": 0.7774,
      "step": 388850
    },
    {
      "epoch": 4.117043631994326,
      "grad_norm": 4.032278060913086,
      "learning_rate": 2.9423036205801397e-05,
      "loss": 0.7564,
      "step": 388900
    },
    {
      "epoch": 4.117572953774329,
      "grad_norm": 3.700458526611328,
      "learning_rate": 2.942038958289223e-05,
      "loss": 0.7628,
      "step": 388950
    },
    {
      "epoch": 4.118102275554333,
      "grad_norm": 4.141853332519531,
      "learning_rate": 2.9417742959983062e-05,
      "loss": 0.7627,
      "step": 389000
    },
    {
      "epoch": 4.118102275554333,
      "eval_loss": 0.5257174968719482,
      "eval_runtime": 46.6119,
      "eval_samples_per_second": 3602.725,
      "eval_steps_per_second": 450.357,
      "step": 389000
    },
    {
      "epoch": 4.1186315973343355,
      "grad_norm": 4.24179744720459,
      "learning_rate": 2.9415096337073893e-05,
      "loss": 0.7673,
      "step": 389050
    },
    {
      "epoch": 4.119160919114339,
      "grad_norm": 4.520725727081299,
      "learning_rate": 2.9412449714164724e-05,
      "loss": 0.7682,
      "step": 389100
    },
    {
      "epoch": 4.119690240894342,
      "grad_norm": 4.111605167388916,
      "learning_rate": 2.940980309125556e-05,
      "loss": 0.7478,
      "step": 389150
    },
    {
      "epoch": 4.120219562674345,
      "grad_norm": 3.785876750946045,
      "learning_rate": 2.9407156468346392e-05,
      "loss": 0.7736,
      "step": 389200
    },
    {
      "epoch": 4.120748884454349,
      "grad_norm": 4.133206367492676,
      "learning_rate": 2.9404509845437223e-05,
      "loss": 0.7514,
      "step": 389250
    },
    {
      "epoch": 4.121278206234352,
      "grad_norm": 3.8509368896484375,
      "learning_rate": 2.9401863222528053e-05,
      "loss": 0.7591,
      "step": 389300
    },
    {
      "epoch": 4.121807528014355,
      "grad_norm": 4.144536018371582,
      "learning_rate": 2.939921659961889e-05,
      "loss": 0.7571,
      "step": 389350
    },
    {
      "epoch": 4.122336849794358,
      "grad_norm": 4.2188191413879395,
      "learning_rate": 2.939656997670972e-05,
      "loss": 0.7611,
      "step": 389400
    },
    {
      "epoch": 4.122866171574362,
      "grad_norm": 4.352386474609375,
      "learning_rate": 2.9393923353800552e-05,
      "loss": 0.7581,
      "step": 389450
    },
    {
      "epoch": 4.123395493354365,
      "grad_norm": 4.154202461242676,
      "learning_rate": 2.9391276730891383e-05,
      "loss": 0.7505,
      "step": 389500
    },
    {
      "epoch": 4.123395493354365,
      "eval_loss": 0.5223612189292908,
      "eval_runtime": 46.6723,
      "eval_samples_per_second": 3598.063,
      "eval_steps_per_second": 449.774,
      "step": 389500
    },
    {
      "epoch": 4.123924815134369,
      "grad_norm": 4.350898742675781,
      "learning_rate": 2.9388630107982217e-05,
      "loss": 0.7667,
      "step": 389550
    },
    {
      "epoch": 4.1244541369143715,
      "grad_norm": 4.220709323883057,
      "learning_rate": 2.9385983485073048e-05,
      "loss": 0.7582,
      "step": 389600
    },
    {
      "epoch": 4.124983458694375,
      "grad_norm": 3.5507678985595703,
      "learning_rate": 2.938333686216388e-05,
      "loss": 0.7591,
      "step": 389650
    },
    {
      "epoch": 4.125512780474378,
      "grad_norm": 3.8634912967681885,
      "learning_rate": 2.938069023925471e-05,
      "loss": 0.7502,
      "step": 389700
    },
    {
      "epoch": 4.126042102254382,
      "grad_norm": 4.628000259399414,
      "learning_rate": 2.9378043616345547e-05,
      "loss": 0.7548,
      "step": 389750
    },
    {
      "epoch": 4.126571424034385,
      "grad_norm": 4.008823871612549,
      "learning_rate": 2.937544992589456e-05,
      "loss": 0.7492,
      "step": 389800
    },
    {
      "epoch": 4.1271007458143885,
      "grad_norm": 4.570419788360596,
      "learning_rate": 2.9372803302985392e-05,
      "loss": 0.7585,
      "step": 389850
    },
    {
      "epoch": 4.127630067594391,
      "grad_norm": 4.296205043792725,
      "learning_rate": 2.9370156680076223e-05,
      "loss": 0.7477,
      "step": 389900
    },
    {
      "epoch": 4.128159389374394,
      "grad_norm": 4.051198482513428,
      "learning_rate": 2.9367510057167057e-05,
      "loss": 0.7564,
      "step": 389950
    },
    {
      "epoch": 4.128688711154398,
      "grad_norm": 4.06360387802124,
      "learning_rate": 2.9364863434257888e-05,
      "loss": 0.7634,
      "step": 390000
    },
    {
      "epoch": 4.128688711154398,
      "eval_loss": 0.5224844813346863,
      "eval_runtime": 46.529,
      "eval_samples_per_second": 3609.148,
      "eval_steps_per_second": 451.16,
      "step": 390000
    },
    {
      "epoch": 4.129218032934401,
      "grad_norm": 4.545629978179932,
      "learning_rate": 2.936221681134872e-05,
      "loss": 0.7601,
      "step": 390050
    },
    {
      "epoch": 4.129747354714405,
      "grad_norm": 4.092965602874756,
      "learning_rate": 2.935957018843955e-05,
      "loss": 0.7614,
      "step": 390100
    },
    {
      "epoch": 4.130276676494407,
      "grad_norm": 3.8729195594787598,
      "learning_rate": 2.9356923565530387e-05,
      "loss": 0.7726,
      "step": 390150
    },
    {
      "epoch": 4.130805998274411,
      "grad_norm": 4.30145263671875,
      "learning_rate": 2.9354276942621217e-05,
      "loss": 0.76,
      "step": 390200
    },
    {
      "epoch": 4.131335320054414,
      "grad_norm": 4.232026100158691,
      "learning_rate": 2.9351630319712048e-05,
      "loss": 0.7607,
      "step": 390250
    },
    {
      "epoch": 4.131864641834418,
      "grad_norm": 4.24725341796875,
      "learning_rate": 2.934898369680288e-05,
      "loss": 0.7601,
      "step": 390300
    },
    {
      "epoch": 4.132393963614421,
      "grad_norm": 4.081479549407959,
      "learning_rate": 2.9346337073893716e-05,
      "loss": 0.76,
      "step": 390350
    },
    {
      "epoch": 4.132923285394424,
      "grad_norm": 4.356529235839844,
      "learning_rate": 2.9343690450984547e-05,
      "loss": 0.7623,
      "step": 390400
    },
    {
      "epoch": 4.133452607174427,
      "grad_norm": 4.020717620849609,
      "learning_rate": 2.9341043828075378e-05,
      "loss": 0.7619,
      "step": 390450
    },
    {
      "epoch": 4.133981928954431,
      "grad_norm": 4.369042873382568,
      "learning_rate": 2.9338397205166208e-05,
      "loss": 0.7591,
      "step": 390500
    },
    {
      "epoch": 4.133981928954431,
      "eval_loss": 0.5232748985290527,
      "eval_runtime": 46.6194,
      "eval_samples_per_second": 3602.148,
      "eval_steps_per_second": 450.285,
      "step": 390500
    },
    {
      "epoch": 4.134511250734434,
      "grad_norm": 4.439446449279785,
      "learning_rate": 2.9335750582257042e-05,
      "loss": 0.7601,
      "step": 390550
    },
    {
      "epoch": 4.135040572514438,
      "grad_norm": 4.353841781616211,
      "learning_rate": 2.9333103959347873e-05,
      "loss": 0.7756,
      "step": 390600
    },
    {
      "epoch": 4.1355698942944406,
      "grad_norm": 4.106093406677246,
      "learning_rate": 2.9330457336438704e-05,
      "loss": 0.77,
      "step": 390650
    },
    {
      "epoch": 4.136099216074443,
      "grad_norm": 4.263765811920166,
      "learning_rate": 2.9327810713529535e-05,
      "loss": 0.755,
      "step": 390700
    },
    {
      "epoch": 4.136628537854447,
      "grad_norm": 4.424821376800537,
      "learning_rate": 2.9325164090620372e-05,
      "loss": 0.7603,
      "step": 390750
    },
    {
      "epoch": 4.13715785963445,
      "grad_norm": 4.235560417175293,
      "learning_rate": 2.9322517467711203e-05,
      "loss": 0.7553,
      "step": 390800
    },
    {
      "epoch": 4.137687181414454,
      "grad_norm": 3.9322197437286377,
      "learning_rate": 2.9319870844802033e-05,
      "loss": 0.7532,
      "step": 390850
    },
    {
      "epoch": 4.138216503194457,
      "grad_norm": 4.340583324432373,
      "learning_rate": 2.9317224221892864e-05,
      "loss": 0.7551,
      "step": 390900
    },
    {
      "epoch": 4.13874582497446,
      "grad_norm": 4.097496509552002,
      "learning_rate": 2.93145775989837e-05,
      "loss": 0.7715,
      "step": 390950
    },
    {
      "epoch": 4.139275146754463,
      "grad_norm": 4.159259796142578,
      "learning_rate": 2.9311930976074532e-05,
      "loss": 0.7637,
      "step": 391000
    },
    {
      "epoch": 4.139275146754463,
      "eval_loss": 0.5217412710189819,
      "eval_runtime": 46.531,
      "eval_samples_per_second": 3608.994,
      "eval_steps_per_second": 451.14,
      "step": 391000
    },
    {
      "epoch": 4.139804468534467,
      "grad_norm": 4.292387008666992,
      "learning_rate": 2.9309284353165363e-05,
      "loss": 0.7601,
      "step": 391050
    },
    {
      "epoch": 4.14033379031447,
      "grad_norm": 4.5814056396484375,
      "learning_rate": 2.9306637730256194e-05,
      "loss": 0.7717,
      "step": 391100
    },
    {
      "epoch": 4.140863112094474,
      "grad_norm": 4.64483118057251,
      "learning_rate": 2.9303991107347028e-05,
      "loss": 0.7598,
      "step": 391150
    },
    {
      "epoch": 4.1413924338744765,
      "grad_norm": 3.990290403366089,
      "learning_rate": 2.930134448443786e-05,
      "loss": 0.7621,
      "step": 391200
    },
    {
      "epoch": 4.14192175565448,
      "grad_norm": 4.391115665435791,
      "learning_rate": 2.929869786152869e-05,
      "loss": 0.7462,
      "step": 391250
    },
    {
      "epoch": 4.142451077434483,
      "grad_norm": 4.120781421661377,
      "learning_rate": 2.929605123861952e-05,
      "loss": 0.7385,
      "step": 391300
    },
    {
      "epoch": 4.142980399214487,
      "grad_norm": 4.0019025802612305,
      "learning_rate": 2.9293404615710358e-05,
      "loss": 0.7603,
      "step": 391350
    },
    {
      "epoch": 4.14350972099449,
      "grad_norm": 4.308999061584473,
      "learning_rate": 2.9290757992801188e-05,
      "loss": 0.7534,
      "step": 391400
    },
    {
      "epoch": 4.144039042774493,
      "grad_norm": 4.29060697555542,
      "learning_rate": 2.928811136989202e-05,
      "loss": 0.7658,
      "step": 391450
    },
    {
      "epoch": 4.144568364554496,
      "grad_norm": 4.0340776443481445,
      "learning_rate": 2.928546474698285e-05,
      "loss": 0.7637,
      "step": 391500
    },
    {
      "epoch": 4.144568364554496,
      "eval_loss": 0.5204203128814697,
      "eval_runtime": 46.611,
      "eval_samples_per_second": 3602.795,
      "eval_steps_per_second": 450.365,
      "step": 391500
    },
    {
      "epoch": 4.145097686334499,
      "grad_norm": 4.407994747161865,
      "learning_rate": 2.9282818124073684e-05,
      "loss": 0.7566,
      "step": 391550
    },
    {
      "epoch": 4.145627008114503,
      "grad_norm": 4.516451358795166,
      "learning_rate": 2.9280171501164514e-05,
      "loss": 0.7547,
      "step": 391600
    },
    {
      "epoch": 4.146156329894506,
      "grad_norm": 4.23992919921875,
      "learning_rate": 2.9277524878255345e-05,
      "loss": 0.7604,
      "step": 391650
    },
    {
      "epoch": 4.14668565167451,
      "grad_norm": 4.025264739990234,
      "learning_rate": 2.9274878255346176e-05,
      "loss": 0.7596,
      "step": 391700
    },
    {
      "epoch": 4.1472149734545125,
      "grad_norm": 4.198383331298828,
      "learning_rate": 2.9272231632437013e-05,
      "loss": 0.7505,
      "step": 391750
    },
    {
      "epoch": 4.147744295234516,
      "grad_norm": 4.433132648468018,
      "learning_rate": 2.9269637941986028e-05,
      "loss": 0.7616,
      "step": 391800
    },
    {
      "epoch": 4.148273617014519,
      "grad_norm": 4.2779459953308105,
      "learning_rate": 2.926699131907686e-05,
      "loss": 0.778,
      "step": 391850
    },
    {
      "epoch": 4.148802938794523,
      "grad_norm": 4.487973213195801,
      "learning_rate": 2.926434469616769e-05,
      "loss": 0.7516,
      "step": 391900
    },
    {
      "epoch": 4.149332260574526,
      "grad_norm": 4.494879722595215,
      "learning_rate": 2.9261698073258527e-05,
      "loss": 0.7606,
      "step": 391950
    },
    {
      "epoch": 4.1498615823545295,
      "grad_norm": 4.347310543060303,
      "learning_rate": 2.9259051450349358e-05,
      "loss": 0.7659,
      "step": 392000
    },
    {
      "epoch": 4.1498615823545295,
      "eval_loss": 0.5213338732719421,
      "eval_runtime": 46.6343,
      "eval_samples_per_second": 3600.996,
      "eval_steps_per_second": 450.141,
      "step": 392000
    },
    {
      "epoch": 4.150390904134532,
      "grad_norm": 4.5747175216674805,
      "learning_rate": 2.925640482744019e-05,
      "loss": 0.7568,
      "step": 392050
    },
    {
      "epoch": 4.150920225914536,
      "grad_norm": 3.8590545654296875,
      "learning_rate": 2.925375820453102e-05,
      "loss": 0.7654,
      "step": 392100
    },
    {
      "epoch": 4.151449547694539,
      "grad_norm": 4.3812479972839355,
      "learning_rate": 2.9251111581621853e-05,
      "loss": 0.7562,
      "step": 392150
    },
    {
      "epoch": 4.151978869474542,
      "grad_norm": 3.8769819736480713,
      "learning_rate": 2.9248464958712684e-05,
      "loss": 0.7539,
      "step": 392200
    },
    {
      "epoch": 4.152508191254546,
      "grad_norm": 4.032371997833252,
      "learning_rate": 2.9245818335803515e-05,
      "loss": 0.7504,
      "step": 392250
    },
    {
      "epoch": 4.1530375130345485,
      "grad_norm": 3.722465991973877,
      "learning_rate": 2.9243171712894345e-05,
      "loss": 0.747,
      "step": 392300
    },
    {
      "epoch": 4.153566834814552,
      "grad_norm": 4.624805927276611,
      "learning_rate": 2.9240525089985183e-05,
      "loss": 0.7719,
      "step": 392350
    },
    {
      "epoch": 4.154096156594555,
      "grad_norm": 4.273484706878662,
      "learning_rate": 2.9237878467076014e-05,
      "loss": 0.7753,
      "step": 392400
    },
    {
      "epoch": 4.154625478374559,
      "grad_norm": 4.09661340713501,
      "learning_rate": 2.9235231844166844e-05,
      "loss": 0.7667,
      "step": 392450
    },
    {
      "epoch": 4.155154800154562,
      "grad_norm": 4.4488043785095215,
      "learning_rate": 2.9232585221257675e-05,
      "loss": 0.7539,
      "step": 392500
    },
    {
      "epoch": 4.155154800154562,
      "eval_loss": 0.5214600563049316,
      "eval_runtime": 46.6613,
      "eval_samples_per_second": 3598.913,
      "eval_steps_per_second": 449.88,
      "step": 392500
    },
    {
      "epoch": 4.1556841219345655,
      "grad_norm": 4.188859462738037,
      "learning_rate": 2.9229938598348512e-05,
      "loss": 0.7452,
      "step": 392550
    },
    {
      "epoch": 4.156213443714568,
      "grad_norm": 4.321814060211182,
      "learning_rate": 2.9227291975439343e-05,
      "loss": 0.7583,
      "step": 392600
    },
    {
      "epoch": 4.156742765494572,
      "grad_norm": 4.44285249710083,
      "learning_rate": 2.9224645352530174e-05,
      "loss": 0.7718,
      "step": 392650
    },
    {
      "epoch": 4.157272087274575,
      "grad_norm": 4.488039493560791,
      "learning_rate": 2.9221998729621005e-05,
      "loss": 0.7539,
      "step": 392700
    },
    {
      "epoch": 4.157801409054579,
      "grad_norm": 4.412601947784424,
      "learning_rate": 2.921935210671184e-05,
      "loss": 0.7659,
      "step": 392750
    },
    {
      "epoch": 4.158330730834582,
      "grad_norm": 3.9575388431549072,
      "learning_rate": 2.921670548380267e-05,
      "loss": 0.7625,
      "step": 392800
    },
    {
      "epoch": 4.158860052614585,
      "grad_norm": 4.4724602699279785,
      "learning_rate": 2.92140588608935e-05,
      "loss": 0.7623,
      "step": 392850
    },
    {
      "epoch": 4.159389374394588,
      "grad_norm": 4.143228530883789,
      "learning_rate": 2.921141223798433e-05,
      "loss": 0.7537,
      "step": 392900
    },
    {
      "epoch": 4.159918696174591,
      "grad_norm": 4.243837356567383,
      "learning_rate": 2.920876561507517e-05,
      "loss": 0.7666,
      "step": 392950
    },
    {
      "epoch": 4.160448017954595,
      "grad_norm": 4.4094414710998535,
      "learning_rate": 2.9206118992166e-05,
      "loss": 0.7486,
      "step": 393000
    },
    {
      "epoch": 4.160448017954595,
      "eval_loss": 0.5206669569015503,
      "eval_runtime": 46.7256,
      "eval_samples_per_second": 3593.961,
      "eval_steps_per_second": 449.261,
      "step": 393000
    },
    {
      "epoch": 4.160977339734598,
      "grad_norm": 4.348575592041016,
      "learning_rate": 2.920347236925683e-05,
      "loss": 0.7632,
      "step": 393050
    },
    {
      "epoch": 4.1615066615146015,
      "grad_norm": 4.256320476531982,
      "learning_rate": 2.920082574634766e-05,
      "loss": 0.77,
      "step": 393100
    },
    {
      "epoch": 4.162035983294604,
      "grad_norm": 3.937725305557251,
      "learning_rate": 2.9198179123438495e-05,
      "loss": 0.7413,
      "step": 393150
    },
    {
      "epoch": 4.162565305074608,
      "grad_norm": 4.147632122039795,
      "learning_rate": 2.9195532500529325e-05,
      "loss": 0.759,
      "step": 393200
    },
    {
      "epoch": 4.163094626854611,
      "grad_norm": 4.1396331787109375,
      "learning_rate": 2.9192885877620156e-05,
      "loss": 0.7511,
      "step": 393250
    },
    {
      "epoch": 4.163623948634615,
      "grad_norm": 3.883167266845703,
      "learning_rate": 2.9190239254710987e-05,
      "loss": 0.7574,
      "step": 393300
    },
    {
      "epoch": 4.164153270414618,
      "grad_norm": 4.572281360626221,
      "learning_rate": 2.9187592631801824e-05,
      "loss": 0.7544,
      "step": 393350
    },
    {
      "epoch": 4.164682592194621,
      "grad_norm": 4.425053596496582,
      "learning_rate": 2.9184946008892655e-05,
      "loss": 0.7699,
      "step": 393400
    },
    {
      "epoch": 4.165211913974624,
      "grad_norm": 4.19905948638916,
      "learning_rate": 2.9182299385983486e-05,
      "loss": 0.7562,
      "step": 393450
    },
    {
      "epoch": 4.165741235754628,
      "grad_norm": 4.05183744430542,
      "learning_rate": 2.9179652763074316e-05,
      "loss": 0.7502,
      "step": 393500
    },
    {
      "epoch": 4.165741235754628,
      "eval_loss": 0.5239514112472534,
      "eval_runtime": 46.652,
      "eval_samples_per_second": 3599.63,
      "eval_steps_per_second": 449.97,
      "step": 393500
    },
    {
      "epoch": 4.166270557534631,
      "grad_norm": 4.308135032653809,
      "learning_rate": 2.9177006140165154e-05,
      "loss": 0.7612,
      "step": 393550
    },
    {
      "epoch": 4.166799879314635,
      "grad_norm": 3.6328179836273193,
      "learning_rate": 2.9174359517255985e-05,
      "loss": 0.7645,
      "step": 393600
    },
    {
      "epoch": 4.1673292010946374,
      "grad_norm": 3.837043523788452,
      "learning_rate": 2.9171712894346815e-05,
      "loss": 0.7506,
      "step": 393650
    },
    {
      "epoch": 4.16785852287464,
      "grad_norm": 4.099254608154297,
      "learning_rate": 2.9169066271437646e-05,
      "loss": 0.7489,
      "step": 393700
    },
    {
      "epoch": 4.168387844654644,
      "grad_norm": 4.131579875946045,
      "learning_rate": 2.916641964852848e-05,
      "loss": 0.759,
      "step": 393750
    },
    {
      "epoch": 4.168917166434647,
      "grad_norm": 4.021478176116943,
      "learning_rate": 2.9163825958077495e-05,
      "loss": 0.7506,
      "step": 393800
    },
    {
      "epoch": 4.169446488214651,
      "grad_norm": 4.127751350402832,
      "learning_rate": 2.9161179335168325e-05,
      "loss": 0.7669,
      "step": 393850
    },
    {
      "epoch": 4.169975809994654,
      "grad_norm": 4.267858982086182,
      "learning_rate": 2.9158532712259156e-05,
      "loss": 0.762,
      "step": 393900
    },
    {
      "epoch": 4.170505131774657,
      "grad_norm": 4.58866024017334,
      "learning_rate": 2.9155886089349994e-05,
      "loss": 0.7672,
      "step": 393950
    },
    {
      "epoch": 4.17103445355466,
      "grad_norm": 4.105896472930908,
      "learning_rate": 2.9153239466440824e-05,
      "loss": 0.7713,
      "step": 394000
    },
    {
      "epoch": 4.17103445355466,
      "eval_loss": 0.5212035775184631,
      "eval_runtime": 46.7212,
      "eval_samples_per_second": 3594.303,
      "eval_steps_per_second": 449.304,
      "step": 394000
    },
    {
      "epoch": 4.171563775334664,
      "grad_norm": 3.6771438121795654,
      "learning_rate": 2.9150592843531655e-05,
      "loss": 0.7594,
      "step": 394050
    },
    {
      "epoch": 4.172093097114667,
      "grad_norm": 4.058367729187012,
      "learning_rate": 2.9147946220622486e-05,
      "loss": 0.7544,
      "step": 394100
    },
    {
      "epoch": 4.172622418894671,
      "grad_norm": 4.07789945602417,
      "learning_rate": 2.914529959771332e-05,
      "loss": 0.7538,
      "step": 394150
    },
    {
      "epoch": 4.173151740674673,
      "grad_norm": 4.023751258850098,
      "learning_rate": 2.914265297480415e-05,
      "loss": 0.7542,
      "step": 394200
    },
    {
      "epoch": 4.173681062454677,
      "grad_norm": 4.2375946044921875,
      "learning_rate": 2.914000635189498e-05,
      "loss": 0.7582,
      "step": 394250
    },
    {
      "epoch": 4.17421038423468,
      "grad_norm": 3.9871973991394043,
      "learning_rate": 2.9137359728985812e-05,
      "loss": 0.7539,
      "step": 394300
    },
    {
      "epoch": 4.174739706014684,
      "grad_norm": 4.37014627456665,
      "learning_rate": 2.913471310607665e-05,
      "loss": 0.7541,
      "step": 394350
    },
    {
      "epoch": 4.175269027794687,
      "grad_norm": 4.063811302185059,
      "learning_rate": 2.913206648316748e-05,
      "loss": 0.7495,
      "step": 394400
    },
    {
      "epoch": 4.1757983495746895,
      "grad_norm": 4.5380425453186035,
      "learning_rate": 2.912941986025831e-05,
      "loss": 0.7674,
      "step": 394450
    },
    {
      "epoch": 4.176327671354693,
      "grad_norm": 4.2167229652404785,
      "learning_rate": 2.912677323734914e-05,
      "loss": 0.746,
      "step": 394500
    },
    {
      "epoch": 4.176327671354693,
      "eval_loss": 0.5209020376205444,
      "eval_runtime": 46.5377,
      "eval_samples_per_second": 3608.47,
      "eval_steps_per_second": 451.075,
      "step": 394500
    },
    {
      "epoch": 4.176856993134696,
      "grad_norm": 4.002427101135254,
      "learning_rate": 2.912412661443998e-05,
      "loss": 0.7647,
      "step": 394550
    },
    {
      "epoch": 4.1773863149147,
      "grad_norm": 4.350857734680176,
      "learning_rate": 2.912147999153081e-05,
      "loss": 0.7623,
      "step": 394600
    },
    {
      "epoch": 4.177915636694703,
      "grad_norm": 4.513318061828613,
      "learning_rate": 2.911883336862164e-05,
      "loss": 0.7685,
      "step": 394650
    },
    {
      "epoch": 4.1784449584747065,
      "grad_norm": 4.094629287719727,
      "learning_rate": 2.911618674571247e-05,
      "loss": 0.7674,
      "step": 394700
    },
    {
      "epoch": 4.178974280254709,
      "grad_norm": 4.193798542022705,
      "learning_rate": 2.9113540122803305e-05,
      "loss": 0.7649,
      "step": 394750
    },
    {
      "epoch": 4.179503602034713,
      "grad_norm": 4.379946231842041,
      "learning_rate": 2.9110893499894136e-05,
      "loss": 0.761,
      "step": 394800
    },
    {
      "epoch": 4.180032923814716,
      "grad_norm": 4.1039533615112305,
      "learning_rate": 2.9108246876984967e-05,
      "loss": 0.7473,
      "step": 394850
    },
    {
      "epoch": 4.18056224559472,
      "grad_norm": 4.178147315979004,
      "learning_rate": 2.9105600254075798e-05,
      "loss": 0.7614,
      "step": 394900
    },
    {
      "epoch": 4.181091567374723,
      "grad_norm": 4.290456771850586,
      "learning_rate": 2.9102953631166635e-05,
      "loss": 0.7418,
      "step": 394950
    },
    {
      "epoch": 4.181620889154726,
      "grad_norm": 4.2315874099731445,
      "learning_rate": 2.9100307008257466e-05,
      "loss": 0.7652,
      "step": 395000
    },
    {
      "epoch": 4.181620889154726,
      "eval_loss": 0.5205895900726318,
      "eval_runtime": 46.6059,
      "eval_samples_per_second": 3603.189,
      "eval_steps_per_second": 450.415,
      "step": 395000
    },
    {
      "epoch": 4.182150210934729,
      "grad_norm": 4.170521259307861,
      "learning_rate": 2.9097660385348296e-05,
      "loss": 0.7496,
      "step": 395050
    },
    {
      "epoch": 4.182679532714733,
      "grad_norm": 4.112667083740234,
      "learning_rate": 2.9095013762439127e-05,
      "loss": 0.7429,
      "step": 395100
    },
    {
      "epoch": 4.183208854494736,
      "grad_norm": 4.16819429397583,
      "learning_rate": 2.9092367139529965e-05,
      "loss": 0.7628,
      "step": 395150
    },
    {
      "epoch": 4.183738176274739,
      "grad_norm": 4.057417869567871,
      "learning_rate": 2.9089720516620795e-05,
      "loss": 0.7593,
      "step": 395200
    },
    {
      "epoch": 4.1842674980547425,
      "grad_norm": 4.417728900909424,
      "learning_rate": 2.9087073893711626e-05,
      "loss": 0.7624,
      "step": 395250
    },
    {
      "epoch": 4.184796819834745,
      "grad_norm": 4.524006366729736,
      "learning_rate": 2.9084480203260637e-05,
      "loss": 0.7675,
      "step": 395300
    },
    {
      "epoch": 4.185326141614749,
      "grad_norm": 4.06110143661499,
      "learning_rate": 2.9081833580351475e-05,
      "loss": 0.7579,
      "step": 395350
    },
    {
      "epoch": 4.185855463394752,
      "grad_norm": 4.126036643981934,
      "learning_rate": 2.9079186957442306e-05,
      "loss": 0.7511,
      "step": 395400
    },
    {
      "epoch": 4.186384785174756,
      "grad_norm": 3.7194807529449463,
      "learning_rate": 2.9076540334533136e-05,
      "loss": 0.7342,
      "step": 395450
    },
    {
      "epoch": 4.186914106954759,
      "grad_norm": 4.420926094055176,
      "learning_rate": 2.9073893711623967e-05,
      "loss": 0.7524,
      "step": 395500
    },
    {
      "epoch": 4.186914106954759,
      "eval_loss": 0.5188409686088562,
      "eval_runtime": 46.5573,
      "eval_samples_per_second": 3606.954,
      "eval_steps_per_second": 450.885,
      "step": 395500
    },
    {
      "epoch": 4.187443428734762,
      "grad_norm": 4.422238349914551,
      "learning_rate": 2.9071247088714804e-05,
      "loss": 0.7662,
      "step": 395550
    },
    {
      "epoch": 4.187972750514765,
      "grad_norm": 4.309587478637695,
      "learning_rate": 2.9068600465805635e-05,
      "loss": 0.772,
      "step": 395600
    },
    {
      "epoch": 4.188502072294769,
      "grad_norm": 4.329751014709473,
      "learning_rate": 2.9065953842896466e-05,
      "loss": 0.7597,
      "step": 395650
    },
    {
      "epoch": 4.189031394074772,
      "grad_norm": 4.333121299743652,
      "learning_rate": 2.9063307219987297e-05,
      "loss": 0.7617,
      "step": 395700
    },
    {
      "epoch": 4.189560715854776,
      "grad_norm": 4.09083366394043,
      "learning_rate": 2.906066059707813e-05,
      "loss": 0.7492,
      "step": 395750
    },
    {
      "epoch": 4.1900900376347785,
      "grad_norm": 4.551945209503174,
      "learning_rate": 2.905801397416896e-05,
      "loss": 0.773,
      "step": 395800
    },
    {
      "epoch": 4.190619359414782,
      "grad_norm": 4.1356120109558105,
      "learning_rate": 2.9055367351259792e-05,
      "loss": 0.7649,
      "step": 395850
    },
    {
      "epoch": 4.191148681194785,
      "grad_norm": 4.022490501403809,
      "learning_rate": 2.9052720728350623e-05,
      "loss": 0.7651,
      "step": 395900
    },
    {
      "epoch": 4.191678002974788,
      "grad_norm": 4.304473876953125,
      "learning_rate": 2.905007410544146e-05,
      "loss": 0.766,
      "step": 395950
    },
    {
      "epoch": 4.192207324754792,
      "grad_norm": 3.948629140853882,
      "learning_rate": 2.904742748253229e-05,
      "loss": 0.7517,
      "step": 396000
    },
    {
      "epoch": 4.192207324754792,
      "eval_loss": 0.5204069018363953,
      "eval_runtime": 46.6151,
      "eval_samples_per_second": 3602.481,
      "eval_steps_per_second": 450.326,
      "step": 396000
    },
    {
      "epoch": 4.192736646534795,
      "grad_norm": 4.1370463371276855,
      "learning_rate": 2.9044780859623122e-05,
      "loss": 0.7561,
      "step": 396050
    },
    {
      "epoch": 4.193265968314798,
      "grad_norm": 4.2497992515563965,
      "learning_rate": 2.9042134236713952e-05,
      "loss": 0.767,
      "step": 396100
    },
    {
      "epoch": 4.193795290094801,
      "grad_norm": 3.766833782196045,
      "learning_rate": 2.903948761380479e-05,
      "loss": 0.7575,
      "step": 396150
    },
    {
      "epoch": 4.194324611874805,
      "grad_norm": 3.806187868118286,
      "learning_rate": 2.903684099089562e-05,
      "loss": 0.7534,
      "step": 396200
    },
    {
      "epoch": 4.194853933654808,
      "grad_norm": 4.302764892578125,
      "learning_rate": 2.903419436798645e-05,
      "loss": 0.7565,
      "step": 396250
    },
    {
      "epoch": 4.195383255434812,
      "grad_norm": 4.202207565307617,
      "learning_rate": 2.9031547745077282e-05,
      "loss": 0.7628,
      "step": 396300
    },
    {
      "epoch": 4.1959125772148145,
      "grad_norm": 4.269794464111328,
      "learning_rate": 2.9028901122168116e-05,
      "loss": 0.764,
      "step": 396350
    },
    {
      "epoch": 4.196441898994818,
      "grad_norm": 4.2087321281433105,
      "learning_rate": 2.9026254499258947e-05,
      "loss": 0.749,
      "step": 396400
    },
    {
      "epoch": 4.196971220774821,
      "grad_norm": 4.195587635040283,
      "learning_rate": 2.9023607876349778e-05,
      "loss": 0.7604,
      "step": 396450
    },
    {
      "epoch": 4.197500542554825,
      "grad_norm": 4.244026184082031,
      "learning_rate": 2.902096125344061e-05,
      "loss": 0.7608,
      "step": 396500
    },
    {
      "epoch": 4.197500542554825,
      "eval_loss": 0.5223742723464966,
      "eval_runtime": 46.5752,
      "eval_samples_per_second": 3605.568,
      "eval_steps_per_second": 450.712,
      "step": 396500
    },
    {
      "epoch": 4.198029864334828,
      "grad_norm": 3.9863288402557373,
      "learning_rate": 2.9018314630531446e-05,
      "loss": 0.7478,
      "step": 396550
    },
    {
      "epoch": 4.1985591861148315,
      "grad_norm": 4.686966896057129,
      "learning_rate": 2.9015668007622277e-05,
      "loss": 0.7649,
      "step": 396600
    },
    {
      "epoch": 4.199088507894834,
      "grad_norm": 4.437432765960693,
      "learning_rate": 2.9013021384713107e-05,
      "loss": 0.7494,
      "step": 396650
    },
    {
      "epoch": 4.199617829674837,
      "grad_norm": 3.858201503753662,
      "learning_rate": 2.9010374761803938e-05,
      "loss": 0.7661,
      "step": 396700
    },
    {
      "epoch": 4.200147151454841,
      "grad_norm": 4.195391654968262,
      "learning_rate": 2.9007728138894775e-05,
      "loss": 0.7532,
      "step": 396750
    },
    {
      "epoch": 4.200676473234844,
      "grad_norm": 3.78515887260437,
      "learning_rate": 2.9005081515985606e-05,
      "loss": 0.758,
      "step": 396800
    },
    {
      "epoch": 4.201205795014848,
      "grad_norm": 4.419428825378418,
      "learning_rate": 2.9002434893076437e-05,
      "loss": 0.761,
      "step": 396850
    },
    {
      "epoch": 4.2017351167948505,
      "grad_norm": 3.8917505741119385,
      "learning_rate": 2.8999788270167268e-05,
      "loss": 0.7419,
      "step": 396900
    },
    {
      "epoch": 4.202264438574854,
      "grad_norm": 3.8656105995178223,
      "learning_rate": 2.89971416472581e-05,
      "loss": 0.7509,
      "step": 396950
    },
    {
      "epoch": 4.202793760354857,
      "grad_norm": 3.881732225418091,
      "learning_rate": 2.8994495024348932e-05,
      "loss": 0.7487,
      "step": 397000
    },
    {
      "epoch": 4.202793760354857,
      "eval_loss": 0.5203845500946045,
      "eval_runtime": 46.5547,
      "eval_samples_per_second": 3607.158,
      "eval_steps_per_second": 450.911,
      "step": 397000
    },
    {
      "epoch": 4.203323082134861,
      "grad_norm": 4.033899307250977,
      "learning_rate": 2.8991848401439763e-05,
      "loss": 0.7603,
      "step": 397050
    },
    {
      "epoch": 4.203852403914864,
      "grad_norm": 3.861858367919922,
      "learning_rate": 2.8989201778530594e-05,
      "loss": 0.7468,
      "step": 397100
    },
    {
      "epoch": 4.2043817256948675,
      "grad_norm": 4.12414026260376,
      "learning_rate": 2.898655515562143e-05,
      "loss": 0.7484,
      "step": 397150
    },
    {
      "epoch": 4.20491104747487,
      "grad_norm": 4.0522284507751465,
      "learning_rate": 2.8983908532712262e-05,
      "loss": 0.7591,
      "step": 397200
    },
    {
      "epoch": 4.205440369254874,
      "grad_norm": 4.607287406921387,
      "learning_rate": 2.8981261909803093e-05,
      "loss": 0.7539,
      "step": 397250
    },
    {
      "epoch": 4.205969691034877,
      "grad_norm": 4.219159126281738,
      "learning_rate": 2.8978615286893923e-05,
      "loss": 0.7685,
      "step": 397300
    },
    {
      "epoch": 4.206499012814881,
      "grad_norm": 3.8711986541748047,
      "learning_rate": 2.897596866398476e-05,
      "loss": 0.7616,
      "step": 397350
    },
    {
      "epoch": 4.207028334594884,
      "grad_norm": 3.8667383193969727,
      "learning_rate": 2.897332204107559e-05,
      "loss": 0.7532,
      "step": 397400
    },
    {
      "epoch": 4.207557656374886,
      "grad_norm": 4.130987644195557,
      "learning_rate": 2.8970675418166422e-05,
      "loss": 0.7435,
      "step": 397450
    },
    {
      "epoch": 4.20808697815489,
      "grad_norm": 4.060652732849121,
      "learning_rate": 2.8968028795257253e-05,
      "loss": 0.7588,
      "step": 397500
    },
    {
      "epoch": 4.20808697815489,
      "eval_loss": 0.5180138945579529,
      "eval_runtime": 46.6272,
      "eval_samples_per_second": 3601.543,
      "eval_steps_per_second": 450.209,
      "step": 397500
    },
    {
      "epoch": 4.208616299934893,
      "grad_norm": 4.012056827545166,
      "learning_rate": 2.8965382172348087e-05,
      "loss": 0.7391,
      "step": 397550
    },
    {
      "epoch": 4.209145621714897,
      "grad_norm": 4.1136860847473145,
      "learning_rate": 2.8962735549438918e-05,
      "loss": 0.7574,
      "step": 397600
    },
    {
      "epoch": 4.2096749434949,
      "grad_norm": 3.9508280754089355,
      "learning_rate": 2.896008892652975e-05,
      "loss": 0.7589,
      "step": 397650
    },
    {
      "epoch": 4.210204265274903,
      "grad_norm": 4.17275333404541,
      "learning_rate": 2.895744230362058e-05,
      "loss": 0.7614,
      "step": 397700
    },
    {
      "epoch": 4.210733587054906,
      "grad_norm": 4.015835285186768,
      "learning_rate": 2.8954795680711417e-05,
      "loss": 0.7615,
      "step": 397750
    },
    {
      "epoch": 4.21126290883491,
      "grad_norm": 4.112851142883301,
      "learning_rate": 2.8952149057802247e-05,
      "loss": 0.755,
      "step": 397800
    },
    {
      "epoch": 4.211792230614913,
      "grad_norm": 4.173743724822998,
      "learning_rate": 2.8949502434893078e-05,
      "loss": 0.7493,
      "step": 397850
    },
    {
      "epoch": 4.212321552394917,
      "grad_norm": 4.019656658172607,
      "learning_rate": 2.894685581198391e-05,
      "loss": 0.763,
      "step": 397900
    },
    {
      "epoch": 4.2128508741749195,
      "grad_norm": 4.437777042388916,
      "learning_rate": 2.8944209189074743e-05,
      "loss": 0.7517,
      "step": 397950
    },
    {
      "epoch": 4.213380195954923,
      "grad_norm": 4.398357391357422,
      "learning_rate": 2.8941615498623758e-05,
      "loss": 0.7557,
      "step": 398000
    },
    {
      "epoch": 4.213380195954923,
      "eval_loss": 0.5183503031730652,
      "eval_runtime": 46.5994,
      "eval_samples_per_second": 3603.694,
      "eval_steps_per_second": 450.478,
      "step": 398000
    },
    {
      "epoch": 4.213909517734926,
      "grad_norm": 4.094433307647705,
      "learning_rate": 2.893896887571459e-05,
      "loss": 0.7646,
      "step": 398050
    },
    {
      "epoch": 4.21443883951493,
      "grad_norm": 4.286682605743408,
      "learning_rate": 2.893632225280542e-05,
      "loss": 0.7753,
      "step": 398100
    },
    {
      "epoch": 4.214968161294933,
      "grad_norm": 4.092868328094482,
      "learning_rate": 2.8933675629896257e-05,
      "loss": 0.7553,
      "step": 398150
    },
    {
      "epoch": 4.215497483074936,
      "grad_norm": 3.9381630420684814,
      "learning_rate": 2.8931029006987087e-05,
      "loss": 0.7605,
      "step": 398200
    },
    {
      "epoch": 4.216026804854939,
      "grad_norm": 4.024779796600342,
      "learning_rate": 2.8928382384077918e-05,
      "loss": 0.7611,
      "step": 398250
    },
    {
      "epoch": 4.216556126634942,
      "grad_norm": 4.571946144104004,
      "learning_rate": 2.892573576116875e-05,
      "loss": 0.7473,
      "step": 398300
    },
    {
      "epoch": 4.217085448414946,
      "grad_norm": 4.2196245193481445,
      "learning_rate": 2.8923089138259586e-05,
      "loss": 0.7512,
      "step": 398350
    },
    {
      "epoch": 4.217614770194949,
      "grad_norm": 4.237552165985107,
      "learning_rate": 2.8920442515350417e-05,
      "loss": 0.764,
      "step": 398400
    },
    {
      "epoch": 4.218144091974953,
      "grad_norm": 4.289968490600586,
      "learning_rate": 2.8917795892441248e-05,
      "loss": 0.7534,
      "step": 398450
    },
    {
      "epoch": 4.2186734137549555,
      "grad_norm": 4.372425079345703,
      "learning_rate": 2.891514926953208e-05,
      "loss": 0.7531,
      "step": 398500
    },
    {
      "epoch": 4.2186734137549555,
      "eval_loss": 0.5175457000732422,
      "eval_runtime": 46.597,
      "eval_samples_per_second": 3603.882,
      "eval_steps_per_second": 450.501,
      "step": 398500
    },
    {
      "epoch": 4.219202735534959,
      "grad_norm": 3.864978790283203,
      "learning_rate": 2.8912502646622912e-05,
      "loss": 0.7583,
      "step": 398550
    },
    {
      "epoch": 4.219732057314962,
      "grad_norm": 4.281522750854492,
      "learning_rate": 2.8909856023713743e-05,
      "loss": 0.7491,
      "step": 398600
    },
    {
      "epoch": 4.220261379094966,
      "grad_norm": 3.9573686122894287,
      "learning_rate": 2.8907209400804574e-05,
      "loss": 0.7637,
      "step": 398650
    },
    {
      "epoch": 4.220790700874969,
      "grad_norm": 4.13362455368042,
      "learning_rate": 2.8904562777895405e-05,
      "loss": 0.7508,
      "step": 398700
    },
    {
      "epoch": 4.2213200226549725,
      "grad_norm": 3.987609386444092,
      "learning_rate": 2.8901916154986242e-05,
      "loss": 0.7578,
      "step": 398750
    },
    {
      "epoch": 4.221849344434975,
      "grad_norm": 4.005130767822266,
      "learning_rate": 2.8899269532077073e-05,
      "loss": 0.7534,
      "step": 398800
    },
    {
      "epoch": 4.222378666214979,
      "grad_norm": 4.045340538024902,
      "learning_rate": 2.8896622909167904e-05,
      "loss": 0.7565,
      "step": 398850
    },
    {
      "epoch": 4.222907987994982,
      "grad_norm": 4.410553932189941,
      "learning_rate": 2.8893976286258734e-05,
      "loss": 0.7585,
      "step": 398900
    },
    {
      "epoch": 4.223437309774985,
      "grad_norm": 3.96539568901062,
      "learning_rate": 2.889132966334957e-05,
      "loss": 0.7545,
      "step": 398950
    },
    {
      "epoch": 4.223966631554989,
      "grad_norm": 4.331038475036621,
      "learning_rate": 2.88886830404404e-05,
      "loss": 0.7663,
      "step": 399000
    },
    {
      "epoch": 4.223966631554989,
      "eval_loss": 0.5190659165382385,
      "eval_runtime": 46.5911,
      "eval_samples_per_second": 3604.337,
      "eval_steps_per_second": 450.558,
      "step": 399000
    },
    {
      "epoch": 4.2244959533349915,
      "grad_norm": 3.9980685710906982,
      "learning_rate": 2.888603641753123e-05,
      "loss": 0.7614,
      "step": 399050
    },
    {
      "epoch": 4.225025275114995,
      "grad_norm": 4.06728458404541,
      "learning_rate": 2.888338979462206e-05,
      "loss": 0.7612,
      "step": 399100
    },
    {
      "epoch": 4.225554596894998,
      "grad_norm": 3.518568277359009,
      "learning_rate": 2.8880743171712898e-05,
      "loss": 0.7437,
      "step": 399150
    },
    {
      "epoch": 4.226083918675002,
      "grad_norm": 4.575751781463623,
      "learning_rate": 2.887809654880373e-05,
      "loss": 0.7479,
      "step": 399200
    },
    {
      "epoch": 4.226613240455005,
      "grad_norm": 4.028792381286621,
      "learning_rate": 2.887544992589456e-05,
      "loss": 0.7628,
      "step": 399250
    },
    {
      "epoch": 4.2271425622350085,
      "grad_norm": 4.106833457946777,
      "learning_rate": 2.887280330298539e-05,
      "loss": 0.7604,
      "step": 399300
    },
    {
      "epoch": 4.227671884015011,
      "grad_norm": 3.8010406494140625,
      "learning_rate": 2.8870156680076228e-05,
      "loss": 0.7365,
      "step": 399350
    },
    {
      "epoch": 4.228201205795015,
      "grad_norm": 4.499826908111572,
      "learning_rate": 2.886751005716706e-05,
      "loss": 0.7563,
      "step": 399400
    },
    {
      "epoch": 4.228730527575018,
      "grad_norm": 4.481573581695557,
      "learning_rate": 2.886486343425789e-05,
      "loss": 0.7486,
      "step": 399450
    },
    {
      "epoch": 4.229259849355022,
      "grad_norm": 4.102579116821289,
      "learning_rate": 2.886221681134872e-05,
      "loss": 0.7573,
      "step": 399500
    },
    {
      "epoch": 4.229259849355022,
      "eval_loss": 0.5197386145591736,
      "eval_runtime": 46.5571,
      "eval_samples_per_second": 3606.971,
      "eval_steps_per_second": 450.887,
      "step": 399500
    },
    {
      "epoch": 4.229789171135025,
      "grad_norm": 3.9364230632781982,
      "learning_rate": 2.8859570188439554e-05,
      "loss": 0.7436,
      "step": 399550
    },
    {
      "epoch": 4.230318492915028,
      "grad_norm": 3.7741715908050537,
      "learning_rate": 2.8856923565530385e-05,
      "loss": 0.7648,
      "step": 399600
    },
    {
      "epoch": 4.230847814695031,
      "grad_norm": 4.199322700500488,
      "learning_rate": 2.8854276942621215e-05,
      "loss": 0.7503,
      "step": 399650
    },
    {
      "epoch": 4.231377136475034,
      "grad_norm": 4.090229034423828,
      "learning_rate": 2.8851630319712046e-05,
      "loss": 0.7598,
      "step": 399700
    },
    {
      "epoch": 4.231906458255038,
      "grad_norm": 4.06606388092041,
      "learning_rate": 2.8848983696802877e-05,
      "loss": 0.7484,
      "step": 399750
    },
    {
      "epoch": 4.232435780035041,
      "grad_norm": 3.798041343688965,
      "learning_rate": 2.8846337073893714e-05,
      "loss": 0.7593,
      "step": 399800
    },
    {
      "epoch": 4.2329651018150445,
      "grad_norm": 4.32462739944458,
      "learning_rate": 2.8843690450984545e-05,
      "loss": 0.7508,
      "step": 399850
    },
    {
      "epoch": 4.233494423595047,
      "grad_norm": 4.194877624511719,
      "learning_rate": 2.8841043828075376e-05,
      "loss": 0.7617,
      "step": 399900
    },
    {
      "epoch": 4.234023745375051,
      "grad_norm": 4.429391384124756,
      "learning_rate": 2.8838397205166206e-05,
      "loss": 0.7599,
      "step": 399950
    },
    {
      "epoch": 4.234553067155054,
      "grad_norm": 3.941389799118042,
      "learning_rate": 2.8835750582257044e-05,
      "loss": 0.7529,
      "step": 400000
    },
    {
      "epoch": 4.234553067155054,
      "eval_loss": 0.5171529054641724,
      "eval_runtime": 46.5788,
      "eval_samples_per_second": 3605.285,
      "eval_steps_per_second": 450.677,
      "step": 400000
    },
    {
      "epoch": 4.235082388935058,
      "grad_norm": 3.9823834896087646,
      "learning_rate": 2.8833103959347875e-05,
      "loss": 0.7608,
      "step": 400050
    },
    {
      "epoch": 4.235611710715061,
      "grad_norm": 3.772866725921631,
      "learning_rate": 2.8830457336438705e-05,
      "loss": 0.7608,
      "step": 400100
    },
    {
      "epoch": 4.236141032495064,
      "grad_norm": 4.2306108474731445,
      "learning_rate": 2.8827810713529536e-05,
      "loss": 0.773,
      "step": 400150
    },
    {
      "epoch": 4.236670354275067,
      "grad_norm": 4.21908712387085,
      "learning_rate": 2.882516409062037e-05,
      "loss": 0.7699,
      "step": 400200
    },
    {
      "epoch": 4.237199676055071,
      "grad_norm": 4.470900058746338,
      "learning_rate": 2.88225174677112e-05,
      "loss": 0.7504,
      "step": 400250
    },
    {
      "epoch": 4.237728997835074,
      "grad_norm": 4.169887542724609,
      "learning_rate": 2.881987084480203e-05,
      "loss": 0.7572,
      "step": 400300
    },
    {
      "epoch": 4.238258319615078,
      "grad_norm": 4.10449743270874,
      "learning_rate": 2.8817224221892862e-05,
      "loss": 0.7491,
      "step": 400350
    },
    {
      "epoch": 4.2387876413950805,
      "grad_norm": 3.8292744159698486,
      "learning_rate": 2.88145775989837e-05,
      "loss": 0.7412,
      "step": 400400
    },
    {
      "epoch": 4.239316963175083,
      "grad_norm": 3.797703504562378,
      "learning_rate": 2.881193097607453e-05,
      "loss": 0.7436,
      "step": 400450
    },
    {
      "epoch": 4.239846284955087,
      "grad_norm": 4.217083930969238,
      "learning_rate": 2.880928435316536e-05,
      "loss": 0.744,
      "step": 400500
    },
    {
      "epoch": 4.239846284955087,
      "eval_loss": 0.5163255333900452,
      "eval_runtime": 46.6136,
      "eval_samples_per_second": 3602.594,
      "eval_steps_per_second": 450.34,
      "step": 400500
    },
    {
      "epoch": 4.24037560673509,
      "grad_norm": 4.053990364074707,
      "learning_rate": 2.8806637730256192e-05,
      "loss": 0.7466,
      "step": 400550
    },
    {
      "epoch": 4.240904928515094,
      "grad_norm": 4.4375529289245605,
      "learning_rate": 2.880399110734703e-05,
      "loss": 0.767,
      "step": 400600
    },
    {
      "epoch": 4.241434250295097,
      "grad_norm": 4.100478172302246,
      "learning_rate": 2.880134448443786e-05,
      "loss": 0.7604,
      "step": 400650
    },
    {
      "epoch": 4.2419635720751,
      "grad_norm": 4.037447452545166,
      "learning_rate": 2.879869786152869e-05,
      "loss": 0.756,
      "step": 400700
    },
    {
      "epoch": 4.242492893855103,
      "grad_norm": 4.163928508758545,
      "learning_rate": 2.879605123861952e-05,
      "loss": 0.7585,
      "step": 400750
    },
    {
      "epoch": 4.243022215635107,
      "grad_norm": 3.8521578311920166,
      "learning_rate": 2.8793404615710356e-05,
      "loss": 0.7485,
      "step": 400800
    },
    {
      "epoch": 4.24355153741511,
      "grad_norm": 3.898094654083252,
      "learning_rate": 2.8790757992801186e-05,
      "loss": 0.757,
      "step": 400850
    },
    {
      "epoch": 4.244080859195114,
      "grad_norm": 4.398581504821777,
      "learning_rate": 2.8788111369892017e-05,
      "loss": 0.7537,
      "step": 400900
    },
    {
      "epoch": 4.244610180975116,
      "grad_norm": 3.8689937591552734,
      "learning_rate": 2.8785464746982848e-05,
      "loss": 0.7442,
      "step": 400950
    },
    {
      "epoch": 4.24513950275512,
      "grad_norm": 4.619098663330078,
      "learning_rate": 2.8782818124073685e-05,
      "loss": 0.7655,
      "step": 401000
    },
    {
      "epoch": 4.24513950275512,
      "eval_loss": 0.5169209241867065,
      "eval_runtime": 46.573,
      "eval_samples_per_second": 3605.738,
      "eval_steps_per_second": 450.733,
      "step": 401000
    },
    {
      "epoch": 4.245668824535123,
      "grad_norm": 4.403347015380859,
      "learning_rate": 2.8780171501164516e-05,
      "loss": 0.7534,
      "step": 401050
    },
    {
      "epoch": 4.246198146315127,
      "grad_norm": 4.507254123687744,
      "learning_rate": 2.8777524878255347e-05,
      "loss": 0.7546,
      "step": 401100
    },
    {
      "epoch": 4.24672746809513,
      "grad_norm": 4.292660713195801,
      "learning_rate": 2.8774878255346177e-05,
      "loss": 0.7712,
      "step": 401150
    },
    {
      "epoch": 4.2472567898751326,
      "grad_norm": 3.975335121154785,
      "learning_rate": 2.8772231632437015e-05,
      "loss": 0.7532,
      "step": 401200
    },
    {
      "epoch": 4.247786111655136,
      "grad_norm": 4.249192237854004,
      "learning_rate": 2.8769585009527845e-05,
      "loss": 0.7509,
      "step": 401250
    },
    {
      "epoch": 4.248315433435139,
      "grad_norm": 3.556580066680908,
      "learning_rate": 2.8766938386618676e-05,
      "loss": 0.7515,
      "step": 401300
    },
    {
      "epoch": 4.248844755215143,
      "grad_norm": 3.945981740951538,
      "learning_rate": 2.8764291763709507e-05,
      "loss": 0.7451,
      "step": 401350
    },
    {
      "epoch": 4.249374076995146,
      "grad_norm": 4.35410737991333,
      "learning_rate": 2.876164514080034e-05,
      "loss": 0.764,
      "step": 401400
    },
    {
      "epoch": 4.2499033987751496,
      "grad_norm": 4.015575885772705,
      "learning_rate": 2.8758998517891172e-05,
      "loss": 0.7483,
      "step": 401450
    },
    {
      "epoch": 4.250432720555152,
      "grad_norm": 4.2459893226623535,
      "learning_rate": 2.8756351894982002e-05,
      "loss": 0.7526,
      "step": 401500
    },
    {
      "epoch": 4.250432720555152,
      "eval_loss": 0.5170021653175354,
      "eval_runtime": 46.5708,
      "eval_samples_per_second": 3605.908,
      "eval_steps_per_second": 450.755,
      "step": 401500
    },
    {
      "epoch": 4.250962042335156,
      "grad_norm": 3.8384628295898438,
      "learning_rate": 2.8753705272072833e-05,
      "loss": 0.7562,
      "step": 401550
    },
    {
      "epoch": 4.251491364115159,
      "grad_norm": 4.2473554611206055,
      "learning_rate": 2.875105864916367e-05,
      "loss": 0.752,
      "step": 401600
    },
    {
      "epoch": 4.252020685895163,
      "grad_norm": 4.365211009979248,
      "learning_rate": 2.87484120262545e-05,
      "loss": 0.7637,
      "step": 401650
    },
    {
      "epoch": 4.252550007675166,
      "grad_norm": 4.358198642730713,
      "learning_rate": 2.8745765403345332e-05,
      "loss": 0.759,
      "step": 401700
    },
    {
      "epoch": 4.253079329455169,
      "grad_norm": 4.228992462158203,
      "learning_rate": 2.8743118780436163e-05,
      "loss": 0.752,
      "step": 401750
    },
    {
      "epoch": 4.253608651235172,
      "grad_norm": 3.9989888668060303,
      "learning_rate": 2.8740472157527e-05,
      "loss": 0.7579,
      "step": 401800
    },
    {
      "epoch": 4.254137973015176,
      "grad_norm": 4.4712653160095215,
      "learning_rate": 2.873782553461783e-05,
      "loss": 0.7519,
      "step": 401850
    },
    {
      "epoch": 4.254667294795179,
      "grad_norm": 4.041754245758057,
      "learning_rate": 2.873517891170866e-05,
      "loss": 0.7657,
      "step": 401900
    },
    {
      "epoch": 4.255196616575182,
      "grad_norm": 4.036991596221924,
      "learning_rate": 2.8732532288799492e-05,
      "loss": 0.7439,
      "step": 401950
    },
    {
      "epoch": 4.2557259383551855,
      "grad_norm": 4.343108177185059,
      "learning_rate": 2.872993859834851e-05,
      "loss": 0.7512,
      "step": 402000
    },
    {
      "epoch": 4.2557259383551855,
      "eval_loss": 0.5154823660850525,
      "eval_runtime": 46.6578,
      "eval_samples_per_second": 3599.182,
      "eval_steps_per_second": 449.914,
      "step": 402000
    },
    {
      "epoch": 4.256255260135188,
      "grad_norm": 4.183871746063232,
      "learning_rate": 2.872729197543934e-05,
      "loss": 0.7755,
      "step": 402050
    },
    {
      "epoch": 4.256784581915192,
      "grad_norm": 4.051677703857422,
      "learning_rate": 2.8724645352530172e-05,
      "loss": 0.7493,
      "step": 402100
    },
    {
      "epoch": 4.257313903695195,
      "grad_norm": 4.342772483825684,
      "learning_rate": 2.8721998729621003e-05,
      "loss": 0.761,
      "step": 402150
    },
    {
      "epoch": 4.257843225475199,
      "grad_norm": 4.397199630737305,
      "learning_rate": 2.871935210671184e-05,
      "loss": 0.7555,
      "step": 402200
    },
    {
      "epoch": 4.258372547255202,
      "grad_norm": 4.167757034301758,
      "learning_rate": 2.871670548380267e-05,
      "loss": 0.767,
      "step": 402250
    },
    {
      "epoch": 4.258901869035205,
      "grad_norm": 4.390736103057861,
      "learning_rate": 2.87140588608935e-05,
      "loss": 0.7486,
      "step": 402300
    },
    {
      "epoch": 4.259431190815208,
      "grad_norm": 4.3649001121521,
      "learning_rate": 2.8711412237984332e-05,
      "loss": 0.7531,
      "step": 402350
    },
    {
      "epoch": 4.259960512595212,
      "grad_norm": 4.194231986999512,
      "learning_rate": 2.8708765615075166e-05,
      "loss": 0.7506,
      "step": 402400
    },
    {
      "epoch": 4.260489834375215,
      "grad_norm": 4.6602606773376465,
      "learning_rate": 2.8706118992165997e-05,
      "loss": 0.7507,
      "step": 402450
    },
    {
      "epoch": 4.261019156155219,
      "grad_norm": 3.926022529602051,
      "learning_rate": 2.8703472369256828e-05,
      "loss": 0.7574,
      "step": 402500
    },
    {
      "epoch": 4.261019156155219,
      "eval_loss": 0.5156224966049194,
      "eval_runtime": 46.5749,
      "eval_samples_per_second": 3605.591,
      "eval_steps_per_second": 450.715,
      "step": 402500
    },
    {
      "epoch": 4.2615484779352215,
      "grad_norm": 3.9895615577697754,
      "learning_rate": 2.870082574634766e-05,
      "loss": 0.7637,
      "step": 402550
    },
    {
      "epoch": 4.262077799715225,
      "grad_norm": 4.106959819793701,
      "learning_rate": 2.8698179123438496e-05,
      "loss": 0.7583,
      "step": 402600
    },
    {
      "epoch": 4.262607121495228,
      "grad_norm": 4.170071125030518,
      "learning_rate": 2.8695532500529327e-05,
      "loss": 0.7542,
      "step": 402650
    },
    {
      "epoch": 4.263136443275231,
      "grad_norm": 4.240810394287109,
      "learning_rate": 2.8692885877620157e-05,
      "loss": 0.7594,
      "step": 402700
    },
    {
      "epoch": 4.263665765055235,
      "grad_norm": 4.155837059020996,
      "learning_rate": 2.8690239254710988e-05,
      "loss": 0.7417,
      "step": 402750
    },
    {
      "epoch": 4.264195086835238,
      "grad_norm": 4.315770626068115,
      "learning_rate": 2.8687592631801826e-05,
      "loss": 0.7688,
      "step": 402800
    },
    {
      "epoch": 4.264724408615241,
      "grad_norm": 3.8571927547454834,
      "learning_rate": 2.8684946008892656e-05,
      "loss": 0.7327,
      "step": 402850
    },
    {
      "epoch": 4.265253730395244,
      "grad_norm": 4.308600902557373,
      "learning_rate": 2.8682299385983487e-05,
      "loss": 0.7626,
      "step": 402900
    },
    {
      "epoch": 4.265783052175248,
      "grad_norm": 4.251230716705322,
      "learning_rate": 2.8679652763074318e-05,
      "loss": 0.7518,
      "step": 402950
    },
    {
      "epoch": 4.266312373955251,
      "grad_norm": 4.053706645965576,
      "learning_rate": 2.8677006140165152e-05,
      "loss": 0.7646,
      "step": 403000
    },
    {
      "epoch": 4.266312373955251,
      "eval_loss": 0.5158376097679138,
      "eval_runtime": 46.5624,
      "eval_samples_per_second": 3606.561,
      "eval_steps_per_second": 450.836,
      "step": 403000
    },
    {
      "epoch": 4.266841695735255,
      "grad_norm": 3.940068006515503,
      "learning_rate": 2.8674359517255983e-05,
      "loss": 0.7572,
      "step": 403050
    },
    {
      "epoch": 4.2673710175152575,
      "grad_norm": 4.407284259796143,
      "learning_rate": 2.8671712894346813e-05,
      "loss": 0.7634,
      "step": 403100
    },
    {
      "epoch": 4.267900339295261,
      "grad_norm": 4.041903972625732,
      "learning_rate": 2.8669066271437644e-05,
      "loss": 0.7529,
      "step": 403150
    },
    {
      "epoch": 4.268429661075264,
      "grad_norm": 4.218668460845947,
      "learning_rate": 2.866641964852848e-05,
      "loss": 0.7523,
      "step": 403200
    },
    {
      "epoch": 4.268958982855268,
      "grad_norm": 3.771760940551758,
      "learning_rate": 2.8663773025619312e-05,
      "loss": 0.7611,
      "step": 403250
    },
    {
      "epoch": 4.269488304635271,
      "grad_norm": 3.872580051422119,
      "learning_rate": 2.8661126402710143e-05,
      "loss": 0.7631,
      "step": 403300
    },
    {
      "epoch": 4.2700176264152745,
      "grad_norm": 4.124227523803711,
      "learning_rate": 2.8658479779800974e-05,
      "loss": 0.755,
      "step": 403350
    },
    {
      "epoch": 4.270546948195277,
      "grad_norm": 3.917294502258301,
      "learning_rate": 2.8655833156891808e-05,
      "loss": 0.7427,
      "step": 403400
    },
    {
      "epoch": 4.27107626997528,
      "grad_norm": 4.25480842590332,
      "learning_rate": 2.865318653398264e-05,
      "loss": 0.7457,
      "step": 403450
    },
    {
      "epoch": 4.271605591755284,
      "grad_norm": 4.22526216506958,
      "learning_rate": 2.865053991107347e-05,
      "loss": 0.7629,
      "step": 403500
    },
    {
      "epoch": 4.271605591755284,
      "eval_loss": 0.5150381922721863,
      "eval_runtime": 46.5602,
      "eval_samples_per_second": 3606.728,
      "eval_steps_per_second": 450.857,
      "step": 403500
    },
    {
      "epoch": 4.272134913535287,
      "grad_norm": 4.134400367736816,
      "learning_rate": 2.86478932881643e-05,
      "loss": 0.7498,
      "step": 403550
    },
    {
      "epoch": 4.272664235315291,
      "grad_norm": 4.2485456466674805,
      "learning_rate": 2.8645246665255137e-05,
      "loss": 0.7417,
      "step": 403600
    },
    {
      "epoch": 4.2731935570952935,
      "grad_norm": 4.477100849151611,
      "learning_rate": 2.8642600042345968e-05,
      "loss": 0.768,
      "step": 403650
    },
    {
      "epoch": 4.273722878875297,
      "grad_norm": 3.9057493209838867,
      "learning_rate": 2.86399534194368e-05,
      "loss": 0.7554,
      "step": 403700
    },
    {
      "epoch": 4.2742522006553,
      "grad_norm": 3.909313678741455,
      "learning_rate": 2.863730679652763e-05,
      "loss": 0.7558,
      "step": 403750
    },
    {
      "epoch": 4.274781522435304,
      "grad_norm": 3.874542713165283,
      "learning_rate": 2.8634660173618467e-05,
      "loss": 0.7615,
      "step": 403800
    },
    {
      "epoch": 4.275310844215307,
      "grad_norm": 4.514782905578613,
      "learning_rate": 2.8632013550709298e-05,
      "loss": 0.7547,
      "step": 403850
    },
    {
      "epoch": 4.2758401659953105,
      "grad_norm": 4.049864292144775,
      "learning_rate": 2.862936692780013e-05,
      "loss": 0.7401,
      "step": 403900
    },
    {
      "epoch": 4.276369487775313,
      "grad_norm": 4.293988227844238,
      "learning_rate": 2.862672030489096e-05,
      "loss": 0.7495,
      "step": 403950
    },
    {
      "epoch": 4.276898809555317,
      "grad_norm": 3.7812955379486084,
      "learning_rate": 2.8624126614439977e-05,
      "loss": 0.7528,
      "step": 404000
    },
    {
      "epoch": 4.276898809555317,
      "eval_loss": 0.5144472122192383,
      "eval_runtime": 46.6137,
      "eval_samples_per_second": 3602.591,
      "eval_steps_per_second": 450.34,
      "step": 404000
    },
    {
      "epoch": 4.27742813133532,
      "grad_norm": 4.169942855834961,
      "learning_rate": 2.8621479991530808e-05,
      "loss": 0.7457,
      "step": 404050
    },
    {
      "epoch": 4.277957453115324,
      "grad_norm": 4.046943664550781,
      "learning_rate": 2.861883336862164e-05,
      "loss": 0.7464,
      "step": 404100
    },
    {
      "epoch": 4.278486774895327,
      "grad_norm": 4.158999443054199,
      "learning_rate": 2.861618674571247e-05,
      "loss": 0.7512,
      "step": 404150
    },
    {
      "epoch": 4.2790160966753295,
      "grad_norm": 4.026153564453125,
      "learning_rate": 2.8613540122803307e-05,
      "loss": 0.7514,
      "step": 404200
    },
    {
      "epoch": 4.279545418455333,
      "grad_norm": 4.1478400230407715,
      "learning_rate": 2.8610893499894137e-05,
      "loss": 0.7551,
      "step": 404250
    },
    {
      "epoch": 4.280074740235336,
      "grad_norm": 4.430219650268555,
      "learning_rate": 2.8608246876984968e-05,
      "loss": 0.7448,
      "step": 404300
    },
    {
      "epoch": 4.28060406201534,
      "grad_norm": 4.229584217071533,
      "learning_rate": 2.86056002540758e-05,
      "loss": 0.7623,
      "step": 404350
    },
    {
      "epoch": 4.281133383795343,
      "grad_norm": 4.302910327911377,
      "learning_rate": 2.8602953631166633e-05,
      "loss": 0.7516,
      "step": 404400
    },
    {
      "epoch": 4.2816627055753465,
      "grad_norm": 4.319631576538086,
      "learning_rate": 2.8600307008257464e-05,
      "loss": 0.747,
      "step": 404450
    },
    {
      "epoch": 4.282192027355349,
      "grad_norm": 4.19650411605835,
      "learning_rate": 2.8597660385348294e-05,
      "loss": 0.7391,
      "step": 404500
    },
    {
      "epoch": 4.282192027355349,
      "eval_loss": 0.5130756497383118,
      "eval_runtime": 46.5728,
      "eval_samples_per_second": 3605.752,
      "eval_steps_per_second": 450.735,
      "step": 404500
    },
    {
      "epoch": 4.282721349135353,
      "grad_norm": 4.172374725341797,
      "learning_rate": 2.8595013762439125e-05,
      "loss": 0.7562,
      "step": 404550
    },
    {
      "epoch": 4.283250670915356,
      "grad_norm": 4.213613510131836,
      "learning_rate": 2.8592367139529963e-05,
      "loss": 0.7521,
      "step": 404600
    },
    {
      "epoch": 4.28377999269536,
      "grad_norm": 4.041450500488281,
      "learning_rate": 2.8589720516620793e-05,
      "loss": 0.7549,
      "step": 404650
    },
    {
      "epoch": 4.284309314475363,
      "grad_norm": 3.9408624172210693,
      "learning_rate": 2.8587073893711624e-05,
      "loss": 0.7466,
      "step": 404700
    },
    {
      "epoch": 4.284838636255366,
      "grad_norm": 4.476790428161621,
      "learning_rate": 2.8584427270802455e-05,
      "loss": 0.756,
      "step": 404750
    },
    {
      "epoch": 4.285367958035369,
      "grad_norm": 4.769967555999756,
      "learning_rate": 2.8581780647893292e-05,
      "loss": 0.7753,
      "step": 404800
    },
    {
      "epoch": 4.285897279815373,
      "grad_norm": 4.3255205154418945,
      "learning_rate": 2.8579134024984123e-05,
      "loss": 0.7566,
      "step": 404850
    },
    {
      "epoch": 4.286426601595376,
      "grad_norm": 4.302193641662598,
      "learning_rate": 2.8576487402074954e-05,
      "loss": 0.7554,
      "step": 404900
    },
    {
      "epoch": 4.286955923375379,
      "grad_norm": 3.9007065296173096,
      "learning_rate": 2.8573840779165784e-05,
      "loss": 0.7379,
      "step": 404950
    },
    {
      "epoch": 4.287485245155382,
      "grad_norm": 4.231107234954834,
      "learning_rate": 2.857119415625662e-05,
      "loss": 0.7492,
      "step": 405000
    },
    {
      "epoch": 4.287485245155382,
      "eval_loss": 0.5152151584625244,
      "eval_runtime": 46.6494,
      "eval_samples_per_second": 3599.834,
      "eval_steps_per_second": 449.995,
      "step": 405000
    },
    {
      "epoch": 4.288014566935385,
      "grad_norm": 4.542501926422119,
      "learning_rate": 2.856854753334745e-05,
      "loss": 0.7619,
      "step": 405050
    },
    {
      "epoch": 4.288543888715389,
      "grad_norm": 4.664002418518066,
      "learning_rate": 2.856590091043828e-05,
      "loss": 0.7523,
      "step": 405100
    },
    {
      "epoch": 4.289073210495392,
      "grad_norm": 4.240000247955322,
      "learning_rate": 2.856325428752911e-05,
      "loss": 0.7578,
      "step": 405150
    },
    {
      "epoch": 4.289602532275396,
      "grad_norm": 4.100565433502197,
      "learning_rate": 2.8560607664619948e-05,
      "loss": 0.7661,
      "step": 405200
    },
    {
      "epoch": 4.2901318540553985,
      "grad_norm": 4.350768089294434,
      "learning_rate": 2.855796104171078e-05,
      "loss": 0.7603,
      "step": 405250
    },
    {
      "epoch": 4.290661175835402,
      "grad_norm": 3.7752931118011475,
      "learning_rate": 2.855531441880161e-05,
      "loss": 0.7533,
      "step": 405300
    },
    {
      "epoch": 4.291190497615405,
      "grad_norm": 3.9822587966918945,
      "learning_rate": 2.855266779589244e-05,
      "loss": 0.7479,
      "step": 405350
    },
    {
      "epoch": 4.291719819395409,
      "grad_norm": 4.127317428588867,
      "learning_rate": 2.8550021172983278e-05,
      "loss": 0.7378,
      "step": 405400
    },
    {
      "epoch": 4.292249141175412,
      "grad_norm": 4.06207799911499,
      "learning_rate": 2.854737455007411e-05,
      "loss": 0.7534,
      "step": 405450
    },
    {
      "epoch": 4.2927784629554155,
      "grad_norm": 3.888932466506958,
      "learning_rate": 2.854472792716494e-05,
      "loss": 0.7637,
      "step": 405500
    },
    {
      "epoch": 4.2927784629554155,
      "eval_loss": 0.5170183181762695,
      "eval_runtime": 46.727,
      "eval_samples_per_second": 3593.852,
      "eval_steps_per_second": 449.248,
      "step": 405500
    },
    {
      "epoch": 4.293307784735418,
      "grad_norm": 4.317487716674805,
      "learning_rate": 2.854208130425577e-05,
      "loss": 0.7584,
      "step": 405550
    },
    {
      "epoch": 4.293837106515422,
      "grad_norm": 4.7224650382995605,
      "learning_rate": 2.8539434681346604e-05,
      "loss": 0.7552,
      "step": 405600
    },
    {
      "epoch": 4.294366428295425,
      "grad_norm": 3.913250207901001,
      "learning_rate": 2.8536788058437435e-05,
      "loss": 0.7506,
      "step": 405650
    },
    {
      "epoch": 4.294895750075428,
      "grad_norm": 4.341571807861328,
      "learning_rate": 2.8534141435528265e-05,
      "loss": 0.7567,
      "step": 405700
    },
    {
      "epoch": 4.295425071855432,
      "grad_norm": 4.47132682800293,
      "learning_rate": 2.8531494812619096e-05,
      "loss": 0.7549,
      "step": 405750
    },
    {
      "epoch": 4.2959543936354345,
      "grad_norm": 4.443992614746094,
      "learning_rate": 2.8528848189709934e-05,
      "loss": 0.7465,
      "step": 405800
    },
    {
      "epoch": 4.296483715415438,
      "grad_norm": 3.9087555408477783,
      "learning_rate": 2.8526201566800764e-05,
      "loss": 0.7584,
      "step": 405850
    },
    {
      "epoch": 4.297013037195441,
      "grad_norm": 4.027833938598633,
      "learning_rate": 2.8523554943891595e-05,
      "loss": 0.7483,
      "step": 405900
    },
    {
      "epoch": 4.297542358975445,
      "grad_norm": 4.097026824951172,
      "learning_rate": 2.8520908320982426e-05,
      "loss": 0.766,
      "step": 405950
    },
    {
      "epoch": 4.298071680755448,
      "grad_norm": 4.431562900543213,
      "learning_rate": 2.8518314630531444e-05,
      "loss": 0.7719,
      "step": 406000
    },
    {
      "epoch": 4.298071680755448,
      "eval_loss": 0.5140669345855713,
      "eval_runtime": 46.5777,
      "eval_samples_per_second": 3605.376,
      "eval_steps_per_second": 450.688,
      "step": 406000
    },
    {
      "epoch": 4.2986010025354515,
      "grad_norm": 4.16763162612915,
      "learning_rate": 2.8515668007622275e-05,
      "loss": 0.75,
      "step": 406050
    },
    {
      "epoch": 4.299130324315454,
      "grad_norm": 4.1757025718688965,
      "learning_rate": 2.8513021384713105e-05,
      "loss": 0.7471,
      "step": 406100
    },
    {
      "epoch": 4.299659646095458,
      "grad_norm": 4.287193298339844,
      "learning_rate": 2.8510374761803936e-05,
      "loss": 0.7515,
      "step": 406150
    },
    {
      "epoch": 4.300188967875461,
      "grad_norm": 4.475818634033203,
      "learning_rate": 2.8507728138894773e-05,
      "loss": 0.762,
      "step": 406200
    },
    {
      "epoch": 4.300718289655465,
      "grad_norm": 4.2679009437561035,
      "learning_rate": 2.8505081515985604e-05,
      "loss": 0.7568,
      "step": 406250
    },
    {
      "epoch": 4.301247611435468,
      "grad_norm": 4.2919135093688965,
      "learning_rate": 2.8502434893076435e-05,
      "loss": 0.7479,
      "step": 406300
    },
    {
      "epoch": 4.301776933215471,
      "grad_norm": 4.729813098907471,
      "learning_rate": 2.8499788270167266e-05,
      "loss": 0.7604,
      "step": 406350
    },
    {
      "epoch": 4.302306254995474,
      "grad_norm": 3.969724416732788,
      "learning_rate": 2.8497141647258103e-05,
      "loss": 0.7446,
      "step": 406400
    },
    {
      "epoch": 4.302835576775477,
      "grad_norm": 4.504383087158203,
      "learning_rate": 2.8494495024348934e-05,
      "loss": 0.7529,
      "step": 406450
    },
    {
      "epoch": 4.303364898555481,
      "grad_norm": 4.182399272918701,
      "learning_rate": 2.8491848401439764e-05,
      "loss": 0.7599,
      "step": 406500
    },
    {
      "epoch": 4.303364898555481,
      "eval_loss": 0.5136073231697083,
      "eval_runtime": 46.8273,
      "eval_samples_per_second": 3586.156,
      "eval_steps_per_second": 448.285,
      "step": 406500
    },
    {
      "epoch": 4.303894220335484,
      "grad_norm": 4.135924816131592,
      "learning_rate": 2.8489201778530595e-05,
      "loss": 0.7446,
      "step": 406550
    },
    {
      "epoch": 4.3044235421154875,
      "grad_norm": 4.145436763763428,
      "learning_rate": 2.848655515562143e-05,
      "loss": 0.7471,
      "step": 406600
    },
    {
      "epoch": 4.30495286389549,
      "grad_norm": 3.741541862487793,
      "learning_rate": 2.848390853271226e-05,
      "loss": 0.7542,
      "step": 406650
    },
    {
      "epoch": 4.305482185675494,
      "grad_norm": 3.9347996711730957,
      "learning_rate": 2.848126190980309e-05,
      "loss": 0.7624,
      "step": 406700
    },
    {
      "epoch": 4.306011507455497,
      "grad_norm": 4.107354164123535,
      "learning_rate": 2.847861528689392e-05,
      "loss": 0.747,
      "step": 406750
    },
    {
      "epoch": 4.306540829235501,
      "grad_norm": 4.228738784790039,
      "learning_rate": 2.847596866398476e-05,
      "loss": 0.7513,
      "step": 406800
    },
    {
      "epoch": 4.307070151015504,
      "grad_norm": 3.9620981216430664,
      "learning_rate": 2.847332204107559e-05,
      "loss": 0.7505,
      "step": 406850
    },
    {
      "epoch": 4.307599472795507,
      "grad_norm": 4.137087821960449,
      "learning_rate": 2.847067541816642e-05,
      "loss": 0.7586,
      "step": 406900
    },
    {
      "epoch": 4.30812879457551,
      "grad_norm": 4.079419136047363,
      "learning_rate": 2.846802879525725e-05,
      "loss": 0.749,
      "step": 406950
    },
    {
      "epoch": 4.308658116355514,
      "grad_norm": 4.245723247528076,
      "learning_rate": 2.846538217234809e-05,
      "loss": 0.7539,
      "step": 407000
    },
    {
      "epoch": 4.308658116355514,
      "eval_loss": 0.5132249593734741,
      "eval_runtime": 46.6125,
      "eval_samples_per_second": 3602.679,
      "eval_steps_per_second": 450.351,
      "step": 407000
    },
    {
      "epoch": 4.309187438135517,
      "grad_norm": 3.6072938442230225,
      "learning_rate": 2.846273554943892e-05,
      "loss": 0.7457,
      "step": 407050
    },
    {
      "epoch": 4.309716759915521,
      "grad_norm": 4.019131183624268,
      "learning_rate": 2.846008892652975e-05,
      "loss": 0.7458,
      "step": 407100
    },
    {
      "epoch": 4.3102460816955235,
      "grad_norm": 4.328962802886963,
      "learning_rate": 2.845744230362058e-05,
      "loss": 0.7515,
      "step": 407150
    },
    {
      "epoch": 4.310775403475526,
      "grad_norm": 4.181673526763916,
      "learning_rate": 2.8454795680711415e-05,
      "loss": 0.7467,
      "step": 407200
    },
    {
      "epoch": 4.31130472525553,
      "grad_norm": 4.734692573547363,
      "learning_rate": 2.8452149057802246e-05,
      "loss": 0.7624,
      "step": 407250
    },
    {
      "epoch": 4.311834047035533,
      "grad_norm": 4.190519332885742,
      "learning_rate": 2.8449502434893076e-05,
      "loss": 0.7693,
      "step": 407300
    },
    {
      "epoch": 4.312363368815537,
      "grad_norm": 4.193560600280762,
      "learning_rate": 2.8446855811983907e-05,
      "loss": 0.7505,
      "step": 407350
    },
    {
      "epoch": 4.31289269059554,
      "grad_norm": 4.044147968292236,
      "learning_rate": 2.8444209189074744e-05,
      "loss": 0.7651,
      "step": 407400
    },
    {
      "epoch": 4.313422012375543,
      "grad_norm": 4.1938018798828125,
      "learning_rate": 2.8441562566165575e-05,
      "loss": 0.7381,
      "step": 407450
    },
    {
      "epoch": 4.313951334155546,
      "grad_norm": 4.2098164558410645,
      "learning_rate": 2.8438915943256406e-05,
      "loss": 0.7381,
      "step": 407500
    },
    {
      "epoch": 4.313951334155546,
      "eval_loss": 0.5115280747413635,
      "eval_runtime": 46.831,
      "eval_samples_per_second": 3585.875,
      "eval_steps_per_second": 448.25,
      "step": 407500
    },
    {
      "epoch": 4.31448065593555,
      "grad_norm": 3.896103858947754,
      "learning_rate": 2.8436269320347237e-05,
      "loss": 0.7522,
      "step": 407550
    },
    {
      "epoch": 4.315009977715553,
      "grad_norm": 3.8697822093963623,
      "learning_rate": 2.8433622697438074e-05,
      "loss": 0.7577,
      "step": 407600
    },
    {
      "epoch": 4.315539299495557,
      "grad_norm": 4.213805198669434,
      "learning_rate": 2.8430976074528905e-05,
      "loss": 0.7358,
      "step": 407650
    },
    {
      "epoch": 4.3160686212755595,
      "grad_norm": 4.449706077575684,
      "learning_rate": 2.8428329451619735e-05,
      "loss": 0.7536,
      "step": 407700
    },
    {
      "epoch": 4.316597943055563,
      "grad_norm": 4.294355869293213,
      "learning_rate": 2.8425682828710566e-05,
      "loss": 0.7501,
      "step": 407750
    },
    {
      "epoch": 4.317127264835566,
      "grad_norm": 4.427496910095215,
      "learning_rate": 2.84230362058014e-05,
      "loss": 0.7403,
      "step": 407800
    },
    {
      "epoch": 4.31765658661557,
      "grad_norm": 4.029057502746582,
      "learning_rate": 2.842038958289223e-05,
      "loss": 0.7452,
      "step": 407850
    },
    {
      "epoch": 4.318185908395573,
      "grad_norm": 3.7705440521240234,
      "learning_rate": 2.8417742959983062e-05,
      "loss": 0.7391,
      "step": 407900
    },
    {
      "epoch": 4.318715230175576,
      "grad_norm": 4.121275424957275,
      "learning_rate": 2.8415096337073892e-05,
      "loss": 0.7464,
      "step": 407950
    },
    {
      "epoch": 4.319244551955579,
      "grad_norm": 3.7234866619110107,
      "learning_rate": 2.8412502646622914e-05,
      "loss": 0.7497,
      "step": 408000
    },
    {
      "epoch": 4.319244551955579,
      "eval_loss": 0.5125150084495544,
      "eval_runtime": 46.559,
      "eval_samples_per_second": 3606.823,
      "eval_steps_per_second": 450.869,
      "step": 408000
    },
    {
      "epoch": 4.319773873735582,
      "grad_norm": 4.097398281097412,
      "learning_rate": 2.8409856023713745e-05,
      "loss": 0.7505,
      "step": 408050
    },
    {
      "epoch": 4.320303195515586,
      "grad_norm": 4.081875324249268,
      "learning_rate": 2.8407209400804575e-05,
      "loss": 0.7503,
      "step": 408100
    },
    {
      "epoch": 4.320832517295589,
      "grad_norm": 3.871663808822632,
      "learning_rate": 2.8404562777895406e-05,
      "loss": 0.7572,
      "step": 408150
    },
    {
      "epoch": 4.321361839075593,
      "grad_norm": 3.9349000453948975,
      "learning_rate": 2.840191615498624e-05,
      "loss": 0.7552,
      "step": 408200
    },
    {
      "epoch": 4.321891160855595,
      "grad_norm": 3.9370715618133545,
      "learning_rate": 2.839926953207707e-05,
      "loss": 0.7731,
      "step": 408250
    },
    {
      "epoch": 4.322420482635599,
      "grad_norm": 4.22988748550415,
      "learning_rate": 2.83966229091679e-05,
      "loss": 0.7593,
      "step": 408300
    },
    {
      "epoch": 4.322949804415602,
      "grad_norm": 3.943044900894165,
      "learning_rate": 2.8393976286258732e-05,
      "loss": 0.7467,
      "step": 408350
    },
    {
      "epoch": 4.323479126195606,
      "grad_norm": 3.956296920776367,
      "learning_rate": 2.839132966334957e-05,
      "loss": 0.7598,
      "step": 408400
    },
    {
      "epoch": 4.324008447975609,
      "grad_norm": 4.287611961364746,
      "learning_rate": 2.83886830404404e-05,
      "loss": 0.765,
      "step": 408450
    },
    {
      "epoch": 4.324537769755612,
      "grad_norm": 4.202018737792969,
      "learning_rate": 2.838603641753123e-05,
      "loss": 0.7432,
      "step": 408500
    },
    {
      "epoch": 4.324537769755612,
      "eval_loss": 0.5112876296043396,
      "eval_runtime": 46.7416,
      "eval_samples_per_second": 3592.732,
      "eval_steps_per_second": 449.107,
      "step": 408500
    },
    {
      "epoch": 4.325067091535615,
      "grad_norm": 3.9490206241607666,
      "learning_rate": 2.8383389794622062e-05,
      "loss": 0.7462,
      "step": 408550
    },
    {
      "epoch": 4.325596413315619,
      "grad_norm": 3.882079839706421,
      "learning_rate": 2.83807431717129e-05,
      "loss": 0.769,
      "step": 408600
    },
    {
      "epoch": 4.326125735095622,
      "grad_norm": 3.9992761611938477,
      "learning_rate": 2.837809654880373e-05,
      "loss": 0.7509,
      "step": 408650
    },
    {
      "epoch": 4.326655056875625,
      "grad_norm": 3.7685773372650146,
      "learning_rate": 2.837544992589456e-05,
      "loss": 0.7479,
      "step": 408700
    },
    {
      "epoch": 4.3271843786556285,
      "grad_norm": 4.09483528137207,
      "learning_rate": 2.837280330298539e-05,
      "loss": 0.7625,
      "step": 408750
    },
    {
      "epoch": 4.327713700435631,
      "grad_norm": 4.245248794555664,
      "learning_rate": 2.8370156680076226e-05,
      "loss": 0.7604,
      "step": 408800
    },
    {
      "epoch": 4.328243022215635,
      "grad_norm": 3.7836804389953613,
      "learning_rate": 2.8367510057167056e-05,
      "loss": 0.7536,
      "step": 408850
    },
    {
      "epoch": 4.328772343995638,
      "grad_norm": 4.078564167022705,
      "learning_rate": 2.8364863434257887e-05,
      "loss": 0.7456,
      "step": 408900
    },
    {
      "epoch": 4.329301665775642,
      "grad_norm": 4.097855091094971,
      "learning_rate": 2.8362216811348718e-05,
      "loss": 0.7572,
      "step": 408950
    },
    {
      "epoch": 4.329830987555645,
      "grad_norm": 4.227263450622559,
      "learning_rate": 2.8359570188439555e-05,
      "loss": 0.7627,
      "step": 409000
    },
    {
      "epoch": 4.329830987555645,
      "eval_loss": 0.5118845701217651,
      "eval_runtime": 46.7993,
      "eval_samples_per_second": 3588.301,
      "eval_steps_per_second": 448.554,
      "step": 409000
    },
    {
      "epoch": 4.330360309335648,
      "grad_norm": 4.1898369789123535,
      "learning_rate": 2.8356923565530386e-05,
      "loss": 0.7532,
      "step": 409050
    },
    {
      "epoch": 4.330889631115651,
      "grad_norm": 4.028017997741699,
      "learning_rate": 2.8354276942621217e-05,
      "loss": 0.7341,
      "step": 409100
    },
    {
      "epoch": 4.331418952895655,
      "grad_norm": 4.481965065002441,
      "learning_rate": 2.8351630319712047e-05,
      "loss": 0.7515,
      "step": 409150
    },
    {
      "epoch": 4.331948274675658,
      "grad_norm": 4.400759696960449,
      "learning_rate": 2.8348983696802885e-05,
      "loss": 0.747,
      "step": 409200
    },
    {
      "epoch": 4.332477596455662,
      "grad_norm": 3.924060583114624,
      "learning_rate": 2.8346337073893716e-05,
      "loss": 0.7542,
      "step": 409250
    },
    {
      "epoch": 4.3330069182356645,
      "grad_norm": 3.892285108566284,
      "learning_rate": 2.8343690450984546e-05,
      "loss": 0.7542,
      "step": 409300
    },
    {
      "epoch": 4.333536240015668,
      "grad_norm": 4.1995768547058105,
      "learning_rate": 2.8341043828075377e-05,
      "loss": 0.7615,
      "step": 409350
    },
    {
      "epoch": 4.334065561795671,
      "grad_norm": 4.391000747680664,
      "learning_rate": 2.833839720516621e-05,
      "loss": 0.7468,
      "step": 409400
    },
    {
      "epoch": 4.334594883575674,
      "grad_norm": 4.126381874084473,
      "learning_rate": 2.8335750582257042e-05,
      "loss": 0.7441,
      "step": 409450
    },
    {
      "epoch": 4.335124205355678,
      "grad_norm": 4.246587753295898,
      "learning_rate": 2.8333103959347873e-05,
      "loss": 0.7434,
      "step": 409500
    },
    {
      "epoch": 4.335124205355678,
      "eval_loss": 0.5116603374481201,
      "eval_runtime": 46.5413,
      "eval_samples_per_second": 3608.196,
      "eval_steps_per_second": 451.041,
      "step": 409500
    },
    {
      "epoch": 4.335653527135681,
      "grad_norm": 4.267345905303955,
      "learning_rate": 2.8330457336438703e-05,
      "loss": 0.7526,
      "step": 409550
    },
    {
      "epoch": 4.336182848915684,
      "grad_norm": 4.1735615730285645,
      "learning_rate": 2.832781071352954e-05,
      "loss": 0.7527,
      "step": 409600
    },
    {
      "epoch": 4.336712170695687,
      "grad_norm": 4.074271202087402,
      "learning_rate": 2.832516409062037e-05,
      "loss": 0.7453,
      "step": 409650
    },
    {
      "epoch": 4.337241492475691,
      "grad_norm": 4.229205131530762,
      "learning_rate": 2.8322517467711202e-05,
      "loss": 0.7381,
      "step": 409700
    },
    {
      "epoch": 4.337770814255694,
      "grad_norm": 4.11674165725708,
      "learning_rate": 2.8319870844802033e-05,
      "loss": 0.7591,
      "step": 409750
    },
    {
      "epoch": 4.338300136035698,
      "grad_norm": 4.125452995300293,
      "learning_rate": 2.8317224221892867e-05,
      "loss": 0.7423,
      "step": 409800
    },
    {
      "epoch": 4.3388294578157005,
      "grad_norm": 4.031521320343018,
      "learning_rate": 2.8314577598983698e-05,
      "loss": 0.7646,
      "step": 409850
    },
    {
      "epoch": 4.339358779595704,
      "grad_norm": 4.03175687789917,
      "learning_rate": 2.831193097607453e-05,
      "loss": 0.7648,
      "step": 409900
    },
    {
      "epoch": 4.339888101375707,
      "grad_norm": 4.23969841003418,
      "learning_rate": 2.830928435316536e-05,
      "loss": 0.7435,
      "step": 409950
    },
    {
      "epoch": 4.340417423155711,
      "grad_norm": 4.345791816711426,
      "learning_rate": 2.830669066271438e-05,
      "loss": 0.7621,
      "step": 410000
    },
    {
      "epoch": 4.340417423155711,
      "eval_loss": 0.511434018611908,
      "eval_runtime": 46.6926,
      "eval_samples_per_second": 3596.498,
      "eval_steps_per_second": 449.578,
      "step": 410000
    },
    {
      "epoch": 4.340946744935714,
      "grad_norm": 3.821270227432251,
      "learning_rate": 2.830404403980521e-05,
      "loss": 0.7463,
      "step": 410050
    },
    {
      "epoch": 4.3414760667157175,
      "grad_norm": 4.04447603225708,
      "learning_rate": 2.8301397416896042e-05,
      "loss": 0.7674,
      "step": 410100
    },
    {
      "epoch": 4.34200538849572,
      "grad_norm": 4.3355278968811035,
      "learning_rate": 2.8298750793986873e-05,
      "loss": 0.7452,
      "step": 410150
    },
    {
      "epoch": 4.342534710275724,
      "grad_norm": 4.554257392883301,
      "learning_rate": 2.829610417107771e-05,
      "loss": 0.7641,
      "step": 410200
    },
    {
      "epoch": 4.343064032055727,
      "grad_norm": 4.287938594818115,
      "learning_rate": 2.829345754816854e-05,
      "loss": 0.7498,
      "step": 410250
    },
    {
      "epoch": 4.34359335383573,
      "grad_norm": 4.0149383544921875,
      "learning_rate": 2.829081092525937e-05,
      "loss": 0.7599,
      "step": 410300
    },
    {
      "epoch": 4.344122675615734,
      "grad_norm": 4.346739292144775,
      "learning_rate": 2.8288164302350202e-05,
      "loss": 0.7661,
      "step": 410350
    },
    {
      "epoch": 4.3446519973957365,
      "grad_norm": 4.1897196769714355,
      "learning_rate": 2.8285517679441036e-05,
      "loss": 0.765,
      "step": 410400
    },
    {
      "epoch": 4.34518131917574,
      "grad_norm": 4.442408561706543,
      "learning_rate": 2.8282871056531867e-05,
      "loss": 0.7613,
      "step": 410450
    },
    {
      "epoch": 4.345710640955743,
      "grad_norm": 4.649702548980713,
      "learning_rate": 2.8280224433622698e-05,
      "loss": 0.7609,
      "step": 410500
    },
    {
      "epoch": 4.345710640955743,
      "eval_loss": 0.5118180513381958,
      "eval_runtime": 46.6209,
      "eval_samples_per_second": 3602.034,
      "eval_steps_per_second": 450.27,
      "step": 410500
    },
    {
      "epoch": 4.346239962735747,
      "grad_norm": 4.649007797241211,
      "learning_rate": 2.827757781071353e-05,
      "loss": 0.7659,
      "step": 410550
    },
    {
      "epoch": 4.34676928451575,
      "grad_norm": 4.116486549377441,
      "learning_rate": 2.8274931187804366e-05,
      "loss": 0.7611,
      "step": 410600
    },
    {
      "epoch": 4.3472986062957535,
      "grad_norm": 4.334035873413086,
      "learning_rate": 2.8272284564895197e-05,
      "loss": 0.7448,
      "step": 410650
    },
    {
      "epoch": 4.347827928075756,
      "grad_norm": 4.082640647888184,
      "learning_rate": 2.8269637941986027e-05,
      "loss": 0.7573,
      "step": 410700
    },
    {
      "epoch": 4.34835724985576,
      "grad_norm": 4.1278533935546875,
      "learning_rate": 2.8266991319076858e-05,
      "loss": 0.7574,
      "step": 410750
    },
    {
      "epoch": 4.348886571635763,
      "grad_norm": 4.319868087768555,
      "learning_rate": 2.8264344696167692e-05,
      "loss": 0.7637,
      "step": 410800
    },
    {
      "epoch": 4.349415893415767,
      "grad_norm": 4.243597030639648,
      "learning_rate": 2.8261698073258523e-05,
      "loss": 0.7422,
      "step": 410850
    },
    {
      "epoch": 4.34994521519577,
      "grad_norm": 4.623998165130615,
      "learning_rate": 2.8259051450349354e-05,
      "loss": 0.7597,
      "step": 410900
    },
    {
      "epoch": 4.350474536975773,
      "grad_norm": 4.322988510131836,
      "learning_rate": 2.8256404827440184e-05,
      "loss": 0.7427,
      "step": 410950
    },
    {
      "epoch": 4.351003858755776,
      "grad_norm": 4.657896995544434,
      "learning_rate": 2.8253758204531022e-05,
      "loss": 0.7504,
      "step": 411000
    },
    {
      "epoch": 4.351003858755776,
      "eval_loss": 0.5109879970550537,
      "eval_runtime": 46.5398,
      "eval_samples_per_second": 3608.31,
      "eval_steps_per_second": 451.055,
      "step": 411000
    },
    {
      "epoch": 4.35153318053578,
      "grad_norm": 4.108870506286621,
      "learning_rate": 2.8251111581621853e-05,
      "loss": 0.7373,
      "step": 411050
    },
    {
      "epoch": 4.352062502315783,
      "grad_norm": 4.0345282554626465,
      "learning_rate": 2.8248464958712683e-05,
      "loss": 0.75,
      "step": 411100
    },
    {
      "epoch": 4.352591824095786,
      "grad_norm": 4.478574275970459,
      "learning_rate": 2.8245818335803514e-05,
      "loss": 0.7389,
      "step": 411150
    },
    {
      "epoch": 4.3531211458757895,
      "grad_norm": 4.768001556396484,
      "learning_rate": 2.824317171289435e-05,
      "loss": 0.7541,
      "step": 411200
    },
    {
      "epoch": 4.353650467655792,
      "grad_norm": 4.164373397827148,
      "learning_rate": 2.8240525089985182e-05,
      "loss": 0.7537,
      "step": 411250
    },
    {
      "epoch": 4.354179789435796,
      "grad_norm": 4.5739054679870605,
      "learning_rate": 2.8237878467076013e-05,
      "loss": 0.7529,
      "step": 411300
    },
    {
      "epoch": 4.354709111215799,
      "grad_norm": 4.098331928253174,
      "learning_rate": 2.8235231844166844e-05,
      "loss": 0.7597,
      "step": 411350
    },
    {
      "epoch": 4.355238432995803,
      "grad_norm": 4.044241428375244,
      "learning_rate": 2.8232585221257678e-05,
      "loss": 0.7531,
      "step": 411400
    },
    {
      "epoch": 4.355767754775806,
      "grad_norm": 4.371823310852051,
      "learning_rate": 2.822993859834851e-05,
      "loss": 0.7683,
      "step": 411450
    },
    {
      "epoch": 4.356297076555809,
      "grad_norm": 4.315181732177734,
      "learning_rate": 2.822729197543934e-05,
      "loss": 0.7521,
      "step": 411500
    },
    {
      "epoch": 4.356297076555809,
      "eval_loss": 0.5104826092720032,
      "eval_runtime": 46.6338,
      "eval_samples_per_second": 3601.035,
      "eval_steps_per_second": 450.145,
      "step": 411500
    },
    {
      "epoch": 4.356826398335812,
      "grad_norm": 3.8385941982269287,
      "learning_rate": 2.822464535253017e-05,
      "loss": 0.7502,
      "step": 411550
    },
    {
      "epoch": 4.357355720115816,
      "grad_norm": 4.729025363922119,
      "learning_rate": 2.8221998729621007e-05,
      "loss": 0.7623,
      "step": 411600
    },
    {
      "epoch": 4.357885041895819,
      "grad_norm": 3.709129571914673,
      "learning_rate": 2.8219352106711838e-05,
      "loss": 0.7514,
      "step": 411650
    },
    {
      "epoch": 4.358414363675823,
      "grad_norm": 3.98201847076416,
      "learning_rate": 2.821670548380267e-05,
      "loss": 0.7372,
      "step": 411700
    },
    {
      "epoch": 4.3589436854558254,
      "grad_norm": 4.070249080657959,
      "learning_rate": 2.82140588608935e-05,
      "loss": 0.7612,
      "step": 411750
    },
    {
      "epoch": 4.359473007235829,
      "grad_norm": 4.233991622924805,
      "learning_rate": 2.8211412237984337e-05,
      "loss": 0.7525,
      "step": 411800
    },
    {
      "epoch": 4.360002329015832,
      "grad_norm": 3.6439425945281982,
      "learning_rate": 2.8208765615075168e-05,
      "loss": 0.7399,
      "step": 411850
    },
    {
      "epoch": 4.360531650795835,
      "grad_norm": 3.961681365966797,
      "learning_rate": 2.8206118992166e-05,
      "loss": 0.7502,
      "step": 411900
    },
    {
      "epoch": 4.361060972575839,
      "grad_norm": 4.210827827453613,
      "learning_rate": 2.820347236925683e-05,
      "loss": 0.7523,
      "step": 411950
    },
    {
      "epoch": 4.361590294355842,
      "grad_norm": 4.65244197845459,
      "learning_rate": 2.8200878678805847e-05,
      "loss": 0.7644,
      "step": 412000
    },
    {
      "epoch": 4.361590294355842,
      "eval_loss": 0.5101736783981323,
      "eval_runtime": 46.5646,
      "eval_samples_per_second": 3606.387,
      "eval_steps_per_second": 450.814,
      "step": 412000
    },
    {
      "epoch": 4.362119616135845,
      "grad_norm": 4.372048854827881,
      "learning_rate": 2.8198232055896678e-05,
      "loss": 0.7621,
      "step": 412050
    },
    {
      "epoch": 4.362648937915848,
      "grad_norm": 4.471002101898193,
      "learning_rate": 2.819558543298751e-05,
      "loss": 0.7413,
      "step": 412100
    },
    {
      "epoch": 4.363178259695852,
      "grad_norm": 4.103054046630859,
      "learning_rate": 2.819293881007834e-05,
      "loss": 0.7596,
      "step": 412150
    },
    {
      "epoch": 4.363707581475855,
      "grad_norm": 4.315173149108887,
      "learning_rate": 2.8190292187169177e-05,
      "loss": 0.751,
      "step": 412200
    },
    {
      "epoch": 4.364236903255859,
      "grad_norm": 4.268138408660889,
      "learning_rate": 2.8187645564260008e-05,
      "loss": 0.7591,
      "step": 412250
    },
    {
      "epoch": 4.364766225035861,
      "grad_norm": 4.442276954650879,
      "learning_rate": 2.8184998941350838e-05,
      "loss": 0.7429,
      "step": 412300
    },
    {
      "epoch": 4.365295546815865,
      "grad_norm": 4.211441993713379,
      "learning_rate": 2.818235231844167e-05,
      "loss": 0.7561,
      "step": 412350
    },
    {
      "epoch": 4.365824868595868,
      "grad_norm": 4.31138801574707,
      "learning_rate": 2.8179705695532503e-05,
      "loss": 0.7383,
      "step": 412400
    },
    {
      "epoch": 4.366354190375872,
      "grad_norm": 4.295533657073975,
      "learning_rate": 2.8177059072623334e-05,
      "loss": 0.7459,
      "step": 412450
    },
    {
      "epoch": 4.366883512155875,
      "grad_norm": 4.174458026885986,
      "learning_rate": 2.8174412449714165e-05,
      "loss": 0.7627,
      "step": 412500
    },
    {
      "epoch": 4.366883512155875,
      "eval_loss": 0.5110054016113281,
      "eval_runtime": 46.4937,
      "eval_samples_per_second": 3611.891,
      "eval_steps_per_second": 451.503,
      "step": 412500
    },
    {
      "epoch": 4.367412833935878,
      "grad_norm": 3.891416311264038,
      "learning_rate": 2.8171765826804995e-05,
      "loss": 0.7489,
      "step": 412550
    },
    {
      "epoch": 4.367942155715881,
      "grad_norm": 4.40334415435791,
      "learning_rate": 2.8169119203895833e-05,
      "loss": 0.7721,
      "step": 412600
    },
    {
      "epoch": 4.368471477495884,
      "grad_norm": 4.112096786499023,
      "learning_rate": 2.8166472580986663e-05,
      "loss": 0.7592,
      "step": 412650
    },
    {
      "epoch": 4.369000799275888,
      "grad_norm": 4.027674198150635,
      "learning_rate": 2.8163825958077494e-05,
      "loss": 0.7439,
      "step": 412700
    },
    {
      "epoch": 4.369530121055891,
      "grad_norm": 3.9115102291107178,
      "learning_rate": 2.8161179335168325e-05,
      "loss": 0.7641,
      "step": 412750
    },
    {
      "epoch": 4.3700594428358945,
      "grad_norm": 4.142405033111572,
      "learning_rate": 2.8158532712259162e-05,
      "loss": 0.7522,
      "step": 412800
    },
    {
      "epoch": 4.370588764615897,
      "grad_norm": 3.9509127140045166,
      "learning_rate": 2.8155886089349993e-05,
      "loss": 0.7297,
      "step": 412850
    },
    {
      "epoch": 4.371118086395901,
      "grad_norm": 4.387038230895996,
      "learning_rate": 2.8153239466440824e-05,
      "loss": 0.7396,
      "step": 412900
    },
    {
      "epoch": 4.371647408175904,
      "grad_norm": 4.487293720245361,
      "learning_rate": 2.8150592843531654e-05,
      "loss": 0.7638,
      "step": 412950
    },
    {
      "epoch": 4.372176729955908,
      "grad_norm": 3.9957633018493652,
      "learning_rate": 2.814794622062249e-05,
      "loss": 0.748,
      "step": 413000
    },
    {
      "epoch": 4.372176729955908,
      "eval_loss": 0.5108997821807861,
      "eval_runtime": 46.6462,
      "eval_samples_per_second": 3600.081,
      "eval_steps_per_second": 450.026,
      "step": 413000
    },
    {
      "epoch": 4.372706051735911,
      "grad_norm": 3.9931480884552,
      "learning_rate": 2.814529959771332e-05,
      "loss": 0.7533,
      "step": 413050
    },
    {
      "epoch": 4.373235373515914,
      "grad_norm": 4.25099515914917,
      "learning_rate": 2.814265297480415e-05,
      "loss": 0.7495,
      "step": 413100
    },
    {
      "epoch": 4.373764695295917,
      "grad_norm": 4.3052897453308105,
      "learning_rate": 2.814000635189498e-05,
      "loss": 0.7414,
      "step": 413150
    },
    {
      "epoch": 4.374294017075921,
      "grad_norm": 4.43438720703125,
      "learning_rate": 2.8137359728985818e-05,
      "loss": 0.7438,
      "step": 413200
    },
    {
      "epoch": 4.374823338855924,
      "grad_norm": 3.654717206954956,
      "learning_rate": 2.813471310607665e-05,
      "loss": 0.7552,
      "step": 413250
    },
    {
      "epoch": 4.375352660635928,
      "grad_norm": 4.187983512878418,
      "learning_rate": 2.813206648316748e-05,
      "loss": 0.7496,
      "step": 413300
    },
    {
      "epoch": 4.3758819824159305,
      "grad_norm": 4.027928352355957,
      "learning_rate": 2.812941986025831e-05,
      "loss": 0.7523,
      "step": 413350
    },
    {
      "epoch": 4.376411304195933,
      "grad_norm": 4.188514232635498,
      "learning_rate": 2.8126773237349148e-05,
      "loss": 0.7494,
      "step": 413400
    },
    {
      "epoch": 4.376940625975937,
      "grad_norm": 4.36562442779541,
      "learning_rate": 2.812412661443998e-05,
      "loss": 0.7432,
      "step": 413450
    },
    {
      "epoch": 4.37746994775594,
      "grad_norm": 4.467976093292236,
      "learning_rate": 2.812147999153081e-05,
      "loss": 0.7511,
      "step": 413500
    },
    {
      "epoch": 4.37746994775594,
      "eval_loss": 0.5091770887374878,
      "eval_runtime": 46.6288,
      "eval_samples_per_second": 3601.42,
      "eval_steps_per_second": 450.194,
      "step": 413500
    },
    {
      "epoch": 4.377999269535944,
      "grad_norm": 4.431484699249268,
      "learning_rate": 2.811883336862164e-05,
      "loss": 0.7594,
      "step": 413550
    },
    {
      "epoch": 4.378528591315947,
      "grad_norm": 4.318333625793457,
      "learning_rate": 2.811618674571247e-05,
      "loss": 0.7703,
      "step": 413600
    },
    {
      "epoch": 4.37905791309595,
      "grad_norm": 4.296391010284424,
      "learning_rate": 2.8113540122803305e-05,
      "loss": 0.7406,
      "step": 413650
    },
    {
      "epoch": 4.379587234875953,
      "grad_norm": 4.382420539855957,
      "learning_rate": 2.8110893499894135e-05,
      "loss": 0.7641,
      "step": 413700
    },
    {
      "epoch": 4.380116556655957,
      "grad_norm": 4.510191440582275,
      "learning_rate": 2.8108246876984966e-05,
      "loss": 0.7541,
      "step": 413750
    },
    {
      "epoch": 4.38064587843596,
      "grad_norm": 4.325024127960205,
      "learning_rate": 2.8105600254075797e-05,
      "loss": 0.7422,
      "step": 413800
    },
    {
      "epoch": 4.381175200215964,
      "grad_norm": 4.201309680938721,
      "learning_rate": 2.8102953631166634e-05,
      "loss": 0.741,
      "step": 413850
    },
    {
      "epoch": 4.3817045219959665,
      "grad_norm": 3.935781717300415,
      "learning_rate": 2.8100307008257465e-05,
      "loss": 0.7461,
      "step": 413900
    },
    {
      "epoch": 4.38223384377597,
      "grad_norm": 4.398411273956299,
      "learning_rate": 2.8097660385348296e-05,
      "loss": 0.7458,
      "step": 413950
    },
    {
      "epoch": 4.382763165555973,
      "grad_norm": 3.7311902046203613,
      "learning_rate": 2.8095066694897314e-05,
      "loss": 0.7387,
      "step": 414000
    },
    {
      "epoch": 4.382763165555973,
      "eval_loss": 0.5071182250976562,
      "eval_runtime": 46.5669,
      "eval_samples_per_second": 3606.21,
      "eval_steps_per_second": 450.792,
      "step": 414000
    },
    {
      "epoch": 4.383292487335977,
      "grad_norm": 4.881304740905762,
      "learning_rate": 2.8092420071988145e-05,
      "loss": 0.7579,
      "step": 414050
    },
    {
      "epoch": 4.38382180911598,
      "grad_norm": 3.9916536808013916,
      "learning_rate": 2.8089773449078975e-05,
      "loss": 0.7434,
      "step": 414100
    },
    {
      "epoch": 4.384351130895983,
      "grad_norm": 4.235286235809326,
      "learning_rate": 2.8087126826169806e-05,
      "loss": 0.7397,
      "step": 414150
    },
    {
      "epoch": 4.384880452675986,
      "grad_norm": 4.003332138061523,
      "learning_rate": 2.8084480203260637e-05,
      "loss": 0.7483,
      "step": 414200
    },
    {
      "epoch": 4.385409774455989,
      "grad_norm": 4.089694499969482,
      "learning_rate": 2.8081833580351474e-05,
      "loss": 0.745,
      "step": 414250
    },
    {
      "epoch": 4.385939096235993,
      "grad_norm": 4.4006500244140625,
      "learning_rate": 2.8079186957442305e-05,
      "loss": 0.7586,
      "step": 414300
    },
    {
      "epoch": 4.386468418015996,
      "grad_norm": 4.014288425445557,
      "learning_rate": 2.8076540334533136e-05,
      "loss": 0.7386,
      "step": 414350
    },
    {
      "epoch": 4.386997739796,
      "grad_norm": 4.349830150604248,
      "learning_rate": 2.8073893711623966e-05,
      "loss": 0.7536,
      "step": 414400
    },
    {
      "epoch": 4.3875270615760025,
      "grad_norm": 4.489689826965332,
      "learning_rate": 2.8071247088714804e-05,
      "loss": 0.7519,
      "step": 414450
    },
    {
      "epoch": 4.388056383356006,
      "grad_norm": 4.344213008880615,
      "learning_rate": 2.8068600465805635e-05,
      "loss": 0.7626,
      "step": 414500
    },
    {
      "epoch": 4.388056383356006,
      "eval_loss": 0.5074436664581299,
      "eval_runtime": 46.7329,
      "eval_samples_per_second": 3593.397,
      "eval_steps_per_second": 449.191,
      "step": 414500
    },
    {
      "epoch": 4.388585705136009,
      "grad_norm": 4.396038055419922,
      "learning_rate": 2.8065953842896465e-05,
      "loss": 0.7426,
      "step": 414550
    },
    {
      "epoch": 4.389115026916013,
      "grad_norm": 4.270897388458252,
      "learning_rate": 2.8063307219987296e-05,
      "loss": 0.7433,
      "step": 414600
    },
    {
      "epoch": 4.389644348696016,
      "grad_norm": 4.3019585609436035,
      "learning_rate": 2.806066059707813e-05,
      "loss": 0.7512,
      "step": 414650
    },
    {
      "epoch": 4.3901736704760195,
      "grad_norm": 4.83364725112915,
      "learning_rate": 2.805801397416896e-05,
      "loss": 0.7462,
      "step": 414700
    },
    {
      "epoch": 4.390702992256022,
      "grad_norm": 4.142247200012207,
      "learning_rate": 2.805536735125979e-05,
      "loss": 0.7556,
      "step": 414750
    },
    {
      "epoch": 4.391232314036026,
      "grad_norm": 4.076440334320068,
      "learning_rate": 2.8052720728350622e-05,
      "loss": 0.7403,
      "step": 414800
    },
    {
      "epoch": 4.391761635816029,
      "grad_norm": 4.526087760925293,
      "learning_rate": 2.805007410544146e-05,
      "loss": 0.7486,
      "step": 414850
    },
    {
      "epoch": 4.392290957596032,
      "grad_norm": 4.538761138916016,
      "learning_rate": 2.804742748253229e-05,
      "loss": 0.7522,
      "step": 414900
    },
    {
      "epoch": 4.392820279376036,
      "grad_norm": 3.7804269790649414,
      "learning_rate": 2.804478085962312e-05,
      "loss": 0.7421,
      "step": 414950
    },
    {
      "epoch": 4.3933496011560385,
      "grad_norm": 4.437267780303955,
      "learning_rate": 2.8042134236713952e-05,
      "loss": 0.7555,
      "step": 415000
    },
    {
      "epoch": 4.3933496011560385,
      "eval_loss": 0.5092823505401611,
      "eval_runtime": 46.4726,
      "eval_samples_per_second": 3613.528,
      "eval_steps_per_second": 451.707,
      "step": 415000
    },
    {
      "epoch": 4.393878922936042,
      "grad_norm": 4.118458271026611,
      "learning_rate": 2.803948761380479e-05,
      "loss": 0.7443,
      "step": 415050
    },
    {
      "epoch": 4.394408244716045,
      "grad_norm": 4.214748859405518,
      "learning_rate": 2.803684099089562e-05,
      "loss": 0.7532,
      "step": 415100
    },
    {
      "epoch": 4.394937566496049,
      "grad_norm": 4.4512619972229,
      "learning_rate": 2.803419436798645e-05,
      "loss": 0.7475,
      "step": 415150
    },
    {
      "epoch": 4.395466888276052,
      "grad_norm": 4.167084693908691,
      "learning_rate": 2.803154774507728e-05,
      "loss": 0.7489,
      "step": 415200
    },
    {
      "epoch": 4.3959962100560555,
      "grad_norm": 4.070749282836914,
      "learning_rate": 2.8028901122168116e-05,
      "loss": 0.7305,
      "step": 415250
    },
    {
      "epoch": 4.396525531836058,
      "grad_norm": 4.098426818847656,
      "learning_rate": 2.8026254499258946e-05,
      "loss": 0.7488,
      "step": 415300
    },
    {
      "epoch": 4.397054853616062,
      "grad_norm": 4.226784706115723,
      "learning_rate": 2.8023607876349777e-05,
      "loss": 0.7414,
      "step": 415350
    },
    {
      "epoch": 4.397584175396065,
      "grad_norm": 4.163635730743408,
      "learning_rate": 2.8020961253440608e-05,
      "loss": 0.7616,
      "step": 415400
    },
    {
      "epoch": 4.398113497176069,
      "grad_norm": 4.060927391052246,
      "learning_rate": 2.8018314630531445e-05,
      "loss": 0.7543,
      "step": 415450
    },
    {
      "epoch": 4.398642818956072,
      "grad_norm": 4.353085994720459,
      "learning_rate": 2.8015668007622276e-05,
      "loss": 0.7501,
      "step": 415500
    },
    {
      "epoch": 4.398642818956072,
      "eval_loss": 0.5087334513664246,
      "eval_runtime": 46.5546,
      "eval_samples_per_second": 3607.161,
      "eval_steps_per_second": 450.911,
      "step": 415500
    },
    {
      "epoch": 4.399172140736075,
      "grad_norm": 4.4807257652282715,
      "learning_rate": 2.8013021384713107e-05,
      "loss": 0.7529,
      "step": 415550
    },
    {
      "epoch": 4.399701462516078,
      "grad_norm": 4.303016662597656,
      "learning_rate": 2.8010374761803937e-05,
      "loss": 0.7566,
      "step": 415600
    },
    {
      "epoch": 4.400230784296081,
      "grad_norm": 4.214725017547607,
      "learning_rate": 2.8007728138894775e-05,
      "loss": 0.7458,
      "step": 415650
    },
    {
      "epoch": 4.400760106076085,
      "grad_norm": 4.1539483070373535,
      "learning_rate": 2.8005081515985606e-05,
      "loss": 0.7422,
      "step": 415700
    },
    {
      "epoch": 4.401289427856088,
      "grad_norm": 4.025469779968262,
      "learning_rate": 2.8002434893076436e-05,
      "loss": 0.7396,
      "step": 415750
    },
    {
      "epoch": 4.401818749636091,
      "grad_norm": 4.764556407928467,
      "learning_rate": 2.7999788270167267e-05,
      "loss": 0.753,
      "step": 415800
    },
    {
      "epoch": 4.402348071416094,
      "grad_norm": 4.277211666107178,
      "learning_rate": 2.79971416472581e-05,
      "loss": 0.7547,
      "step": 415850
    },
    {
      "epoch": 4.402877393196098,
      "grad_norm": 3.6989965438842773,
      "learning_rate": 2.7994495024348932e-05,
      "loss": 0.7541,
      "step": 415900
    },
    {
      "epoch": 4.403406714976101,
      "grad_norm": 4.270590782165527,
      "learning_rate": 2.7991848401439763e-05,
      "loss": 0.7422,
      "step": 415950
    },
    {
      "epoch": 4.403936036756105,
      "grad_norm": 4.204188346862793,
      "learning_rate": 2.7989254710988777e-05,
      "loss": 0.7406,
      "step": 416000
    },
    {
      "epoch": 4.403936036756105,
      "eval_loss": 0.5070074200630188,
      "eval_runtime": 46.5278,
      "eval_samples_per_second": 3609.241,
      "eval_steps_per_second": 451.171,
      "step": 416000
    },
    {
      "epoch": 4.4044653585361075,
      "grad_norm": 4.573390007019043,
      "learning_rate": 2.7986608088079615e-05,
      "loss": 0.7479,
      "step": 416050
    },
    {
      "epoch": 4.404994680316111,
      "grad_norm": 4.288639068603516,
      "learning_rate": 2.7983961465170445e-05,
      "loss": 0.739,
      "step": 416100
    },
    {
      "epoch": 4.405524002096114,
      "grad_norm": 4.181312561035156,
      "learning_rate": 2.7981314842261276e-05,
      "loss": 0.7451,
      "step": 416150
    },
    {
      "epoch": 4.406053323876118,
      "grad_norm": 4.024346351623535,
      "learning_rate": 2.7978668219352107e-05,
      "loss": 0.7571,
      "step": 416200
    },
    {
      "epoch": 4.406582645656121,
      "grad_norm": 4.244122505187988,
      "learning_rate": 2.797602159644294e-05,
      "loss": 0.7465,
      "step": 416250
    },
    {
      "epoch": 4.4071119674361245,
      "grad_norm": 4.337242126464844,
      "learning_rate": 2.797337497353377e-05,
      "loss": 0.7473,
      "step": 416300
    },
    {
      "epoch": 4.407641289216127,
      "grad_norm": 4.2471747398376465,
      "learning_rate": 2.7970728350624602e-05,
      "loss": 0.7486,
      "step": 416350
    },
    {
      "epoch": 4.40817061099613,
      "grad_norm": 4.47442626953125,
      "learning_rate": 2.7968081727715433e-05,
      "loss": 0.7592,
      "step": 416400
    },
    {
      "epoch": 4.408699932776134,
      "grad_norm": 4.220123291015625,
      "learning_rate": 2.796543510480627e-05,
      "loss": 0.7528,
      "step": 416450
    },
    {
      "epoch": 4.409229254556137,
      "grad_norm": 4.264554977416992,
      "learning_rate": 2.79627884818971e-05,
      "loss": 0.7538,
      "step": 416500
    },
    {
      "epoch": 4.409229254556137,
      "eval_loss": 0.5086410641670227,
      "eval_runtime": 46.6738,
      "eval_samples_per_second": 3597.954,
      "eval_steps_per_second": 449.76,
      "step": 416500
    },
    {
      "epoch": 4.409758576336141,
      "grad_norm": 4.199913024902344,
      "learning_rate": 2.7960141858987932e-05,
      "loss": 0.7479,
      "step": 416550
    },
    {
      "epoch": 4.4102878981161435,
      "grad_norm": 4.380609512329102,
      "learning_rate": 2.7957495236078763e-05,
      "loss": 0.7583,
      "step": 416600
    },
    {
      "epoch": 4.410817219896147,
      "grad_norm": 4.02234411239624,
      "learning_rate": 2.79548486131696e-05,
      "loss": 0.7527,
      "step": 416650
    },
    {
      "epoch": 4.41134654167615,
      "grad_norm": 4.1555280685424805,
      "learning_rate": 2.795220199026043e-05,
      "loss": 0.745,
      "step": 416700
    },
    {
      "epoch": 4.411875863456154,
      "grad_norm": 3.863163709640503,
      "learning_rate": 2.794955536735126e-05,
      "loss": 0.7585,
      "step": 416750
    },
    {
      "epoch": 4.412405185236157,
      "grad_norm": 4.394192218780518,
      "learning_rate": 2.7946908744442092e-05,
      "loss": 0.7373,
      "step": 416800
    },
    {
      "epoch": 4.4129345070161605,
      "grad_norm": 4.3215131759643555,
      "learning_rate": 2.7944262121532926e-05,
      "loss": 0.7449,
      "step": 416850
    },
    {
      "epoch": 4.413463828796163,
      "grad_norm": 4.118797302246094,
      "learning_rate": 2.7941615498623757e-05,
      "loss": 0.7574,
      "step": 416900
    },
    {
      "epoch": 4.413993150576167,
      "grad_norm": 4.184167385101318,
      "learning_rate": 2.7938968875714588e-05,
      "loss": 0.7591,
      "step": 416950
    },
    {
      "epoch": 4.41452247235617,
      "grad_norm": 3.89507794380188,
      "learning_rate": 2.793632225280542e-05,
      "loss": 0.7329,
      "step": 417000
    },
    {
      "epoch": 4.41452247235617,
      "eval_loss": 0.5064404606819153,
      "eval_runtime": 46.4944,
      "eval_samples_per_second": 3611.836,
      "eval_steps_per_second": 451.496,
      "step": 417000
    },
    {
      "epoch": 4.415051794136174,
      "grad_norm": 4.153711795806885,
      "learning_rate": 2.7933675629896256e-05,
      "loss": 0.7428,
      "step": 417050
    },
    {
      "epoch": 4.415581115916177,
      "grad_norm": 4.347376346588135,
      "learning_rate": 2.7931029006987087e-05,
      "loss": 0.7456,
      "step": 417100
    },
    {
      "epoch": 4.4161104376961795,
      "grad_norm": 3.9707744121551514,
      "learning_rate": 2.7928382384077917e-05,
      "loss": 0.758,
      "step": 417150
    },
    {
      "epoch": 4.416639759476183,
      "grad_norm": 3.929041624069214,
      "learning_rate": 2.7925735761168748e-05,
      "loss": 0.7622,
      "step": 417200
    },
    {
      "epoch": 4.417169081256186,
      "grad_norm": 3.9484424591064453,
      "learning_rate": 2.7923089138259582e-05,
      "loss": 0.7513,
      "step": 417250
    },
    {
      "epoch": 4.41769840303619,
      "grad_norm": 4.3104963302612305,
      "learning_rate": 2.7920442515350413e-05,
      "loss": 0.7537,
      "step": 417300
    },
    {
      "epoch": 4.418227724816193,
      "grad_norm": 3.9525482654571533,
      "learning_rate": 2.7917795892441244e-05,
      "loss": 0.7446,
      "step": 417350
    },
    {
      "epoch": 4.4187570465961965,
      "grad_norm": 4.099399566650391,
      "learning_rate": 2.7915149269532074e-05,
      "loss": 0.7489,
      "step": 417400
    },
    {
      "epoch": 4.419286368376199,
      "grad_norm": 3.7751479148864746,
      "learning_rate": 2.7912502646622912e-05,
      "loss": 0.7526,
      "step": 417450
    },
    {
      "epoch": 4.419815690156203,
      "grad_norm": 4.284944534301758,
      "learning_rate": 2.7909856023713743e-05,
      "loss": 0.7366,
      "step": 417500
    },
    {
      "epoch": 4.419815690156203,
      "eval_loss": 0.5063550472259521,
      "eval_runtime": 46.6304,
      "eval_samples_per_second": 3601.3,
      "eval_steps_per_second": 450.179,
      "step": 417500
    },
    {
      "epoch": 4.420345011936206,
      "grad_norm": 4.234008312225342,
      "learning_rate": 2.7907209400804573e-05,
      "loss": 0.7428,
      "step": 417550
    },
    {
      "epoch": 4.42087433371621,
      "grad_norm": 4.438491344451904,
      "learning_rate": 2.7904562777895404e-05,
      "loss": 0.7517,
      "step": 417600
    },
    {
      "epoch": 4.421403655496213,
      "grad_norm": 4.159782409667969,
      "learning_rate": 2.790191615498624e-05,
      "loss": 0.7438,
      "step": 417650
    },
    {
      "epoch": 4.421932977276216,
      "grad_norm": 4.270914077758789,
      "learning_rate": 2.7899269532077072e-05,
      "loss": 0.7584,
      "step": 417700
    },
    {
      "epoch": 4.422462299056219,
      "grad_norm": 4.438635349273682,
      "learning_rate": 2.7896622909167903e-05,
      "loss": 0.7373,
      "step": 417750
    },
    {
      "epoch": 4.422991620836223,
      "grad_norm": 4.2658867835998535,
      "learning_rate": 2.7893976286258734e-05,
      "loss": 0.7381,
      "step": 417800
    },
    {
      "epoch": 4.423520942616226,
      "grad_norm": 4.381842136383057,
      "learning_rate": 2.7891329663349568e-05,
      "loss": 0.7607,
      "step": 417850
    },
    {
      "epoch": 4.424050264396229,
      "grad_norm": 4.368051052093506,
      "learning_rate": 2.78886830404404e-05,
      "loss": 0.7403,
      "step": 417900
    },
    {
      "epoch": 4.4245795861762325,
      "grad_norm": 4.062287330627441,
      "learning_rate": 2.788603641753123e-05,
      "loss": 0.7569,
      "step": 417950
    },
    {
      "epoch": 4.425108907956235,
      "grad_norm": 4.37947940826416,
      "learning_rate": 2.7883442727080244e-05,
      "loss": 0.7421,
      "step": 418000
    },
    {
      "epoch": 4.425108907956235,
      "eval_loss": 0.5060543417930603,
      "eval_runtime": 46.6926,
      "eval_samples_per_second": 3596.503,
      "eval_steps_per_second": 449.579,
      "step": 418000
    },
    {
      "epoch": 4.425638229736239,
      "grad_norm": 4.282835483551025,
      "learning_rate": 2.788079610417108e-05,
      "loss": 0.7432,
      "step": 418050
    },
    {
      "epoch": 4.426167551516242,
      "grad_norm": 4.117387294769287,
      "learning_rate": 2.7878149481261912e-05,
      "loss": 0.7376,
      "step": 418100
    },
    {
      "epoch": 4.426696873296246,
      "grad_norm": 4.278437614440918,
      "learning_rate": 2.7875502858352743e-05,
      "loss": 0.7616,
      "step": 418150
    },
    {
      "epoch": 4.427226195076249,
      "grad_norm": 3.8710272312164307,
      "learning_rate": 2.7872856235443574e-05,
      "loss": 0.7417,
      "step": 418200
    },
    {
      "epoch": 4.427755516856252,
      "grad_norm": 4.055604934692383,
      "learning_rate": 2.7870209612534408e-05,
      "loss": 0.7585,
      "step": 418250
    },
    {
      "epoch": 4.428284838636255,
      "grad_norm": 4.168694019317627,
      "learning_rate": 2.7867615922083422e-05,
      "loss": 0.7444,
      "step": 418300
    },
    {
      "epoch": 4.428814160416259,
      "grad_norm": 4.380472183227539,
      "learning_rate": 2.7864969299174253e-05,
      "loss": 0.7538,
      "step": 418350
    },
    {
      "epoch": 4.429343482196262,
      "grad_norm": 3.831676721572876,
      "learning_rate": 2.7862322676265084e-05,
      "loss": 0.749,
      "step": 418400
    },
    {
      "epoch": 4.429872803976266,
      "grad_norm": 4.375080585479736,
      "learning_rate": 2.785967605335592e-05,
      "loss": 0.7569,
      "step": 418450
    },
    {
      "epoch": 4.4304021257562685,
      "grad_norm": 4.107267379760742,
      "learning_rate": 2.7857029430446752e-05,
      "loss": 0.7437,
      "step": 418500
    },
    {
      "epoch": 4.4304021257562685,
      "eval_loss": 0.5055270195007324,
      "eval_runtime": 46.7729,
      "eval_samples_per_second": 3590.329,
      "eval_steps_per_second": 448.807,
      "step": 418500
    },
    {
      "epoch": 4.430931447536272,
      "grad_norm": 3.991968870162964,
      "learning_rate": 2.7854382807537583e-05,
      "loss": 0.7499,
      "step": 418550
    },
    {
      "epoch": 4.431460769316275,
      "grad_norm": 4.550214767456055,
      "learning_rate": 2.7851736184628413e-05,
      "loss": 0.7279,
      "step": 418600
    },
    {
      "epoch": 4.431990091096278,
      "grad_norm": 4.553396701812744,
      "learning_rate": 2.784908956171925e-05,
      "loss": 0.7576,
      "step": 418650
    },
    {
      "epoch": 4.432519412876282,
      "grad_norm": 4.419525146484375,
      "learning_rate": 2.784644293881008e-05,
      "loss": 0.75,
      "step": 418700
    },
    {
      "epoch": 4.433048734656285,
      "grad_norm": 4.533186435699463,
      "learning_rate": 2.7843796315900912e-05,
      "loss": 0.7426,
      "step": 418750
    },
    {
      "epoch": 4.433578056436288,
      "grad_norm": 4.086045742034912,
      "learning_rate": 2.7841149692991743e-05,
      "loss": 0.7479,
      "step": 418800
    },
    {
      "epoch": 4.434107378216291,
      "grad_norm": 4.4815354347229,
      "learning_rate": 2.7838503070082577e-05,
      "loss": 0.7472,
      "step": 418850
    },
    {
      "epoch": 4.434636699996295,
      "grad_norm": 4.281431198120117,
      "learning_rate": 2.7835856447173408e-05,
      "loss": 0.7403,
      "step": 418900
    },
    {
      "epoch": 4.435166021776298,
      "grad_norm": 4.430001258850098,
      "learning_rate": 2.783320982426424e-05,
      "loss": 0.741,
      "step": 418950
    },
    {
      "epoch": 4.435695343556302,
      "grad_norm": 4.058254241943359,
      "learning_rate": 2.783056320135507e-05,
      "loss": 0.7459,
      "step": 419000
    },
    {
      "epoch": 4.435695343556302,
      "eval_loss": 0.5063316226005554,
      "eval_runtime": 46.5381,
      "eval_samples_per_second": 3608.438,
      "eval_steps_per_second": 451.071,
      "step": 419000
    },
    {
      "epoch": 4.436224665336304,
      "grad_norm": 4.216361999511719,
      "learning_rate": 2.7827916578445907e-05,
      "loss": 0.7465,
      "step": 419050
    },
    {
      "epoch": 4.436753987116308,
      "grad_norm": 4.335798263549805,
      "learning_rate": 2.7825269955536737e-05,
      "loss": 0.7383,
      "step": 419100
    },
    {
      "epoch": 4.437283308896311,
      "grad_norm": 4.099960803985596,
      "learning_rate": 2.7822623332627568e-05,
      "loss": 0.7385,
      "step": 419150
    },
    {
      "epoch": 4.437812630676315,
      "grad_norm": 4.462164402008057,
      "learning_rate": 2.78199767097184e-05,
      "loss": 0.7456,
      "step": 419200
    },
    {
      "epoch": 4.438341952456318,
      "grad_norm": 4.19045352935791,
      "learning_rate": 2.7817330086809233e-05,
      "loss": 0.7489,
      "step": 419250
    },
    {
      "epoch": 4.438871274236321,
      "grad_norm": 4.1025590896606445,
      "learning_rate": 2.7814683463900064e-05,
      "loss": 0.7534,
      "step": 419300
    },
    {
      "epoch": 4.439400596016324,
      "grad_norm": 4.471736907958984,
      "learning_rate": 2.7812036840990894e-05,
      "loss": 0.7561,
      "step": 419350
    },
    {
      "epoch": 4.439929917796327,
      "grad_norm": 4.3225297927856445,
      "learning_rate": 2.7809390218081725e-05,
      "loss": 0.7435,
      "step": 419400
    },
    {
      "epoch": 4.440459239576331,
      "grad_norm": 4.2148003578186035,
      "learning_rate": 2.7806743595172563e-05,
      "loss": 0.7507,
      "step": 419450
    },
    {
      "epoch": 4.440988561356334,
      "grad_norm": 3.852567672729492,
      "learning_rate": 2.7804096972263393e-05,
      "loss": 0.7328,
      "step": 419500
    },
    {
      "epoch": 4.440988561356334,
      "eval_loss": 0.5050429701805115,
      "eval_runtime": 46.5728,
      "eval_samples_per_second": 3605.754,
      "eval_steps_per_second": 450.735,
      "step": 419500
    },
    {
      "epoch": 4.4415178831363376,
      "grad_norm": 4.201285362243652,
      "learning_rate": 2.7801450349354224e-05,
      "loss": 0.7503,
      "step": 419550
    },
    {
      "epoch": 4.44204720491634,
      "grad_norm": 4.335474014282227,
      "learning_rate": 2.7798803726445055e-05,
      "loss": 0.7401,
      "step": 419600
    },
    {
      "epoch": 4.442576526696344,
      "grad_norm": 4.048551082611084,
      "learning_rate": 2.7796157103535892e-05,
      "loss": 0.7604,
      "step": 419650
    },
    {
      "epoch": 4.443105848476347,
      "grad_norm": 4.353311538696289,
      "learning_rate": 2.7793510480626723e-05,
      "loss": 0.7658,
      "step": 419700
    },
    {
      "epoch": 4.443635170256351,
      "grad_norm": 4.265608787536621,
      "learning_rate": 2.7790863857717554e-05,
      "loss": 0.7463,
      "step": 419750
    },
    {
      "epoch": 4.444164492036354,
      "grad_norm": 3.88493013381958,
      "learning_rate": 2.7788217234808384e-05,
      "loss": 0.7406,
      "step": 419800
    },
    {
      "epoch": 4.444693813816357,
      "grad_norm": 3.6937475204467773,
      "learning_rate": 2.778557061189922e-05,
      "loss": 0.7528,
      "step": 419850
    },
    {
      "epoch": 4.44522313559636,
      "grad_norm": 4.005687713623047,
      "learning_rate": 2.778292398899005e-05,
      "loss": 0.7438,
      "step": 419900
    },
    {
      "epoch": 4.445752457376364,
      "grad_norm": 3.987046480178833,
      "learning_rate": 2.778027736608088e-05,
      "loss": 0.7544,
      "step": 419950
    },
    {
      "epoch": 4.446281779156367,
      "grad_norm": 3.9978532791137695,
      "learning_rate": 2.777763074317171e-05,
      "loss": 0.7386,
      "step": 420000
    },
    {
      "epoch": 4.446281779156367,
      "eval_loss": 0.5057412981987,
      "eval_runtime": 46.616,
      "eval_samples_per_second": 3602.41,
      "eval_steps_per_second": 450.317,
      "step": 420000
    },
    {
      "epoch": 4.446811100936371,
      "grad_norm": 4.200122356414795,
      "learning_rate": 2.7774984120262548e-05,
      "loss": 0.744,
      "step": 420050
    },
    {
      "epoch": 4.4473404227163735,
      "grad_norm": 4.3422651290893555,
      "learning_rate": 2.777233749735338e-05,
      "loss": 0.7467,
      "step": 420100
    },
    {
      "epoch": 4.447869744496376,
      "grad_norm": 4.224493503570557,
      "learning_rate": 2.776969087444421e-05,
      "loss": 0.7398,
      "step": 420150
    },
    {
      "epoch": 4.44839906627638,
      "grad_norm": 4.597830295562744,
      "learning_rate": 2.776704425153504e-05,
      "loss": 0.7313,
      "step": 420200
    },
    {
      "epoch": 4.448928388056383,
      "grad_norm": 4.242760181427002,
      "learning_rate": 2.7764397628625878e-05,
      "loss": 0.7357,
      "step": 420250
    },
    {
      "epoch": 4.449457709836387,
      "grad_norm": 4.110593318939209,
      "learning_rate": 2.776175100571671e-05,
      "loss": 0.7398,
      "step": 420300
    },
    {
      "epoch": 4.44998703161639,
      "grad_norm": 4.472922325134277,
      "learning_rate": 2.775910438280754e-05,
      "loss": 0.746,
      "step": 420350
    },
    {
      "epoch": 4.450516353396393,
      "grad_norm": 4.612612724304199,
      "learning_rate": 2.775645775989837e-05,
      "loss": 0.7486,
      "step": 420400
    },
    {
      "epoch": 4.451045675176396,
      "grad_norm": 4.3718461990356445,
      "learning_rate": 2.7753811136989204e-05,
      "loss": 0.748,
      "step": 420450
    },
    {
      "epoch": 4.4515749969564,
      "grad_norm": 4.154468536376953,
      "learning_rate": 2.7751164514080035e-05,
      "loss": 0.7512,
      "step": 420500
    },
    {
      "epoch": 4.4515749969564,
      "eval_loss": 0.5049704313278198,
      "eval_runtime": 46.5757,
      "eval_samples_per_second": 3605.524,
      "eval_steps_per_second": 450.707,
      "step": 420500
    },
    {
      "epoch": 4.452104318736403,
      "grad_norm": 4.380807876586914,
      "learning_rate": 2.7748517891170865e-05,
      "loss": 0.737,
      "step": 420550
    },
    {
      "epoch": 4.452633640516407,
      "grad_norm": 4.053071975708008,
      "learning_rate": 2.7745871268261696e-05,
      "loss": 0.753,
      "step": 420600
    },
    {
      "epoch": 4.4531629622964095,
      "grad_norm": 3.8847298622131348,
      "learning_rate": 2.7743224645352534e-05,
      "loss": 0.7452,
      "step": 420650
    },
    {
      "epoch": 4.453692284076413,
      "grad_norm": 4.1169514656066895,
      "learning_rate": 2.7740578022443364e-05,
      "loss": 0.7434,
      "step": 420700
    },
    {
      "epoch": 4.454221605856416,
      "grad_norm": 3.9926986694335938,
      "learning_rate": 2.7737931399534195e-05,
      "loss": 0.7389,
      "step": 420750
    },
    {
      "epoch": 4.45475092763642,
      "grad_norm": 4.18183708190918,
      "learning_rate": 2.7735284776625026e-05,
      "loss": 0.7439,
      "step": 420800
    },
    {
      "epoch": 4.455280249416423,
      "grad_norm": 4.043800354003906,
      "learning_rate": 2.7732638153715863e-05,
      "loss": 0.755,
      "step": 420850
    },
    {
      "epoch": 4.455809571196426,
      "grad_norm": 4.4657087326049805,
      "learning_rate": 2.7729991530806694e-05,
      "loss": 0.7473,
      "step": 420900
    },
    {
      "epoch": 4.456338892976429,
      "grad_norm": 4.366654872894287,
      "learning_rate": 2.7727344907897525e-05,
      "loss": 0.7315,
      "step": 420950
    },
    {
      "epoch": 4.456868214756432,
      "grad_norm": 4.286681175231934,
      "learning_rate": 2.7724698284988355e-05,
      "loss": 0.747,
      "step": 421000
    },
    {
      "epoch": 4.456868214756432,
      "eval_loss": 0.5057200789451599,
      "eval_runtime": 46.641,
      "eval_samples_per_second": 3600.479,
      "eval_steps_per_second": 450.076,
      "step": 421000
    },
    {
      "epoch": 4.457397536536436,
      "grad_norm": 4.430605411529541,
      "learning_rate": 2.772205166207919e-05,
      "loss": 0.7567,
      "step": 421050
    },
    {
      "epoch": 4.457926858316439,
      "grad_norm": 4.242417335510254,
      "learning_rate": 2.771940503917002e-05,
      "loss": 0.7389,
      "step": 421100
    },
    {
      "epoch": 4.458456180096443,
      "grad_norm": 3.9637625217437744,
      "learning_rate": 2.771675841626085e-05,
      "loss": 0.7483,
      "step": 421150
    },
    {
      "epoch": 4.4589855018764455,
      "grad_norm": 4.081308364868164,
      "learning_rate": 2.771411179335168e-05,
      "loss": 0.7623,
      "step": 421200
    },
    {
      "epoch": 4.459514823656449,
      "grad_norm": 4.434996128082275,
      "learning_rate": 2.771146517044252e-05,
      "loss": 0.7388,
      "step": 421250
    },
    {
      "epoch": 4.460044145436452,
      "grad_norm": 4.202982425689697,
      "learning_rate": 2.770881854753335e-05,
      "loss": 0.7481,
      "step": 421300
    },
    {
      "epoch": 4.460573467216456,
      "grad_norm": 4.244929790496826,
      "learning_rate": 2.770617192462418e-05,
      "loss": 0.755,
      "step": 421350
    },
    {
      "epoch": 4.461102788996459,
      "grad_norm": 4.382157325744629,
      "learning_rate": 2.770352530171501e-05,
      "loss": 0.7433,
      "step": 421400
    },
    {
      "epoch": 4.4616321107764625,
      "grad_norm": 4.404204845428467,
      "learning_rate": 2.770087867880585e-05,
      "loss": 0.7408,
      "step": 421450
    },
    {
      "epoch": 4.462161432556465,
      "grad_norm": 4.092475414276123,
      "learning_rate": 2.769823205589668e-05,
      "loss": 0.746,
      "step": 421500
    },
    {
      "epoch": 4.462161432556465,
      "eval_loss": 0.5033003687858582,
      "eval_runtime": 46.5584,
      "eval_samples_per_second": 3606.869,
      "eval_steps_per_second": 450.875,
      "step": 421500
    },
    {
      "epoch": 4.462690754336469,
      "grad_norm": 4.260855674743652,
      "learning_rate": 2.769558543298751e-05,
      "loss": 0.7607,
      "step": 421550
    },
    {
      "epoch": 4.463220076116472,
      "grad_norm": 4.160076141357422,
      "learning_rate": 2.769293881007834e-05,
      "loss": 0.7553,
      "step": 421600
    },
    {
      "epoch": 4.463749397896475,
      "grad_norm": 4.400545597076416,
      "learning_rate": 2.7690292187169175e-05,
      "loss": 0.7384,
      "step": 421650
    },
    {
      "epoch": 4.464278719676479,
      "grad_norm": 4.176939964294434,
      "learning_rate": 2.7687645564260006e-05,
      "loss": 0.7512,
      "step": 421700
    },
    {
      "epoch": 4.4648080414564815,
      "grad_norm": 3.9977777004241943,
      "learning_rate": 2.7684998941350836e-05,
      "loss": 0.7617,
      "step": 421750
    },
    {
      "epoch": 4.465337363236485,
      "grad_norm": 4.105052471160889,
      "learning_rate": 2.7682352318441667e-05,
      "loss": 0.7438,
      "step": 421800
    },
    {
      "epoch": 4.465866685016488,
      "grad_norm": 4.320504665374756,
      "learning_rate": 2.7679705695532505e-05,
      "loss": 0.7436,
      "step": 421850
    },
    {
      "epoch": 4.466396006796492,
      "grad_norm": 3.868067502975464,
      "learning_rate": 2.7677059072623335e-05,
      "loss": 0.737,
      "step": 421900
    },
    {
      "epoch": 4.466925328576495,
      "grad_norm": 4.1567840576171875,
      "learning_rate": 2.7674412449714166e-05,
      "loss": 0.7528,
      "step": 421950
    },
    {
      "epoch": 4.4674546503564985,
      "grad_norm": 4.334201335906982,
      "learning_rate": 2.7671765826804997e-05,
      "loss": 0.7456,
      "step": 422000
    },
    {
      "epoch": 4.4674546503564985,
      "eval_loss": 0.5025699138641357,
      "eval_runtime": 46.5614,
      "eval_samples_per_second": 3606.636,
      "eval_steps_per_second": 450.846,
      "step": 422000
    },
    {
      "epoch": 4.467983972136501,
      "grad_norm": 4.4856038093566895,
      "learning_rate": 2.7669119203895834e-05,
      "loss": 0.7386,
      "step": 422050
    },
    {
      "epoch": 4.468513293916505,
      "grad_norm": 4.200639247894287,
      "learning_rate": 2.7666472580986665e-05,
      "loss": 0.7429,
      "step": 422100
    },
    {
      "epoch": 4.469042615696508,
      "grad_norm": 4.759123802185059,
      "learning_rate": 2.7663825958077496e-05,
      "loss": 0.7503,
      "step": 422150
    },
    {
      "epoch": 4.469571937476512,
      "grad_norm": 3.7099573612213135,
      "learning_rate": 2.7661179335168326e-05,
      "loss": 0.7445,
      "step": 422200
    },
    {
      "epoch": 4.470101259256515,
      "grad_norm": 4.124349594116211,
      "learning_rate": 2.765853271225916e-05,
      "loss": 0.7437,
      "step": 422250
    },
    {
      "epoch": 4.470630581036518,
      "grad_norm": 4.417098045349121,
      "learning_rate": 2.7655939021808175e-05,
      "loss": 0.7431,
      "step": 422300
    },
    {
      "epoch": 4.471159902816521,
      "grad_norm": 4.3396406173706055,
      "learning_rate": 2.7653292398899006e-05,
      "loss": 0.7489,
      "step": 422350
    },
    {
      "epoch": 4.471689224596524,
      "grad_norm": 4.335515022277832,
      "learning_rate": 2.7650645775989836e-05,
      "loss": 0.7334,
      "step": 422400
    },
    {
      "epoch": 4.472218546376528,
      "grad_norm": 4.055730819702148,
      "learning_rate": 2.7647999153080674e-05,
      "loss": 0.7428,
      "step": 422450
    },
    {
      "epoch": 4.472747868156531,
      "grad_norm": 3.9770238399505615,
      "learning_rate": 2.7645352530171505e-05,
      "loss": 0.7298,
      "step": 422500
    },
    {
      "epoch": 4.472747868156531,
      "eval_loss": 0.5029474496841431,
      "eval_runtime": 46.5779,
      "eval_samples_per_second": 3605.355,
      "eval_steps_per_second": 450.685,
      "step": 422500
    },
    {
      "epoch": 4.4732771899365344,
      "grad_norm": 4.275066375732422,
      "learning_rate": 2.7642705907262335e-05,
      "loss": 0.748,
      "step": 422550
    },
    {
      "epoch": 4.473806511716537,
      "grad_norm": 4.554428577423096,
      "learning_rate": 2.7640059284353166e-05,
      "loss": 0.7453,
      "step": 422600
    },
    {
      "epoch": 4.474335833496541,
      "grad_norm": 3.9936845302581787,
      "learning_rate": 2.7637412661444e-05,
      "loss": 0.7379,
      "step": 422650
    },
    {
      "epoch": 4.474865155276544,
      "grad_norm": 3.914013385772705,
      "learning_rate": 2.763476603853483e-05,
      "loss": 0.7456,
      "step": 422700
    },
    {
      "epoch": 4.475394477056548,
      "grad_norm": 4.2804388999938965,
      "learning_rate": 2.763211941562566e-05,
      "loss": 0.7241,
      "step": 422750
    },
    {
      "epoch": 4.475923798836551,
      "grad_norm": 4.57108736038208,
      "learning_rate": 2.7629472792716492e-05,
      "loss": 0.74,
      "step": 422800
    },
    {
      "epoch": 4.476453120616554,
      "grad_norm": 4.5434956550598145,
      "learning_rate": 2.762682616980733e-05,
      "loss": 0.758,
      "step": 422850
    },
    {
      "epoch": 4.476982442396557,
      "grad_norm": 3.962606191635132,
      "learning_rate": 2.762417954689816e-05,
      "loss": 0.7456,
      "step": 422900
    },
    {
      "epoch": 4.477511764176561,
      "grad_norm": 3.9329261779785156,
      "learning_rate": 2.762153292398899e-05,
      "loss": 0.7558,
      "step": 422950
    },
    {
      "epoch": 4.478041085956564,
      "grad_norm": 4.237725734710693,
      "learning_rate": 2.7618886301079822e-05,
      "loss": 0.7496,
      "step": 423000
    },
    {
      "epoch": 4.478041085956564,
      "eval_loss": 0.5036770701408386,
      "eval_runtime": 46.7491,
      "eval_samples_per_second": 3592.152,
      "eval_steps_per_second": 449.035,
      "step": 423000
    },
    {
      "epoch": 4.478570407736568,
      "grad_norm": 4.378911972045898,
      "learning_rate": 2.761623967817066e-05,
      "loss": 0.743,
      "step": 423050
    },
    {
      "epoch": 4.47909972951657,
      "grad_norm": 4.480949401855469,
      "learning_rate": 2.761359305526149e-05,
      "loss": 0.7462,
      "step": 423100
    },
    {
      "epoch": 4.479629051296573,
      "grad_norm": 4.180039882659912,
      "learning_rate": 2.761094643235232e-05,
      "loss": 0.7512,
      "step": 423150
    },
    {
      "epoch": 4.480158373076577,
      "grad_norm": 4.159318923950195,
      "learning_rate": 2.760829980944315e-05,
      "loss": 0.7453,
      "step": 423200
    },
    {
      "epoch": 4.48068769485658,
      "grad_norm": 4.165978908538818,
      "learning_rate": 2.7605653186533986e-05,
      "loss": 0.7324,
      "step": 423250
    },
    {
      "epoch": 4.481217016636584,
      "grad_norm": 4.01878023147583,
      "learning_rate": 2.7603006563624816e-05,
      "loss": 0.7429,
      "step": 423300
    },
    {
      "epoch": 4.4817463384165865,
      "grad_norm": 4.8090338706970215,
      "learning_rate": 2.7600359940715647e-05,
      "loss": 0.7394,
      "step": 423350
    },
    {
      "epoch": 4.48227566019659,
      "grad_norm": 4.356168746948242,
      "learning_rate": 2.7597713317806478e-05,
      "loss": 0.7459,
      "step": 423400
    },
    {
      "epoch": 4.482804981976593,
      "grad_norm": 4.1321868896484375,
      "learning_rate": 2.7595066694897315e-05,
      "loss": 0.7592,
      "step": 423450
    },
    {
      "epoch": 4.483334303756597,
      "grad_norm": 4.463966369628906,
      "learning_rate": 2.7592420071988146e-05,
      "loss": 0.744,
      "step": 423500
    },
    {
      "epoch": 4.483334303756597,
      "eval_loss": 0.5035260915756226,
      "eval_runtime": 46.5875,
      "eval_samples_per_second": 3604.618,
      "eval_steps_per_second": 450.593,
      "step": 423500
    },
    {
      "epoch": 4.4838636255366,
      "grad_norm": 4.04005765914917,
      "learning_rate": 2.7589773449078977e-05,
      "loss": 0.7301,
      "step": 423550
    },
    {
      "epoch": 4.4843929473166035,
      "grad_norm": 4.25359582901001,
      "learning_rate": 2.7587126826169807e-05,
      "loss": 0.7415,
      "step": 423600
    },
    {
      "epoch": 4.484922269096606,
      "grad_norm": 4.360910415649414,
      "learning_rate": 2.758448020326064e-05,
      "loss": 0.7547,
      "step": 423650
    },
    {
      "epoch": 4.48545159087661,
      "grad_norm": 4.100114822387695,
      "learning_rate": 2.7581833580351472e-05,
      "loss": 0.7598,
      "step": 423700
    },
    {
      "epoch": 4.485980912656613,
      "grad_norm": 4.1993608474731445,
      "learning_rate": 2.7579186957442303e-05,
      "loss": 0.7318,
      "step": 423750
    },
    {
      "epoch": 4.486510234436617,
      "grad_norm": 4.031099319458008,
      "learning_rate": 2.7576540334533134e-05,
      "loss": 0.7565,
      "step": 423800
    },
    {
      "epoch": 4.48703955621662,
      "grad_norm": 4.095917224884033,
      "learning_rate": 2.757389371162397e-05,
      "loss": 0.7512,
      "step": 423850
    },
    {
      "epoch": 4.4875688779966225,
      "grad_norm": 4.137609481811523,
      "learning_rate": 2.7571247088714802e-05,
      "loss": 0.7397,
      "step": 423900
    },
    {
      "epoch": 4.488098199776626,
      "grad_norm": 3.972978115081787,
      "learning_rate": 2.7568600465805633e-05,
      "loss": 0.7507,
      "step": 423950
    },
    {
      "epoch": 4.488627521556629,
      "grad_norm": 4.61558723449707,
      "learning_rate": 2.7565953842896463e-05,
      "loss": 0.7556,
      "step": 424000
    },
    {
      "epoch": 4.488627521556629,
      "eval_loss": 0.5052616596221924,
      "eval_runtime": 46.598,
      "eval_samples_per_second": 3603.8,
      "eval_steps_per_second": 450.491,
      "step": 424000
    },
    {
      "epoch": 4.489156843336633,
      "grad_norm": 4.253442764282227,
      "learning_rate": 2.75633072199873e-05,
      "loss": 0.7372,
      "step": 424050
    },
    {
      "epoch": 4.489686165116636,
      "grad_norm": 4.0796709060668945,
      "learning_rate": 2.756066059707813e-05,
      "loss": 0.7364,
      "step": 424100
    },
    {
      "epoch": 4.4902154868966395,
      "grad_norm": 4.209396839141846,
      "learning_rate": 2.7558013974168962e-05,
      "loss": 0.7544,
      "step": 424150
    },
    {
      "epoch": 4.490744808676642,
      "grad_norm": 4.4503583908081055,
      "learning_rate": 2.7555367351259793e-05,
      "loss": 0.7429,
      "step": 424200
    },
    {
      "epoch": 4.491274130456646,
      "grad_norm": 4.907379627227783,
      "learning_rate": 2.7552720728350627e-05,
      "loss": 0.7484,
      "step": 424250
    },
    {
      "epoch": 4.491803452236649,
      "grad_norm": 4.358158111572266,
      "learning_rate": 2.7550127037899642e-05,
      "loss": 0.737,
      "step": 424300
    },
    {
      "epoch": 4.492332774016653,
      "grad_norm": 4.789807319641113,
      "learning_rate": 2.7547480414990472e-05,
      "loss": 0.7504,
      "step": 424350
    },
    {
      "epoch": 4.492862095796656,
      "grad_norm": 4.200906753540039,
      "learning_rate": 2.7544833792081303e-05,
      "loss": 0.7552,
      "step": 424400
    },
    {
      "epoch": 4.493391417576659,
      "grad_norm": 4.002754211425781,
      "learning_rate": 2.754218716917214e-05,
      "loss": 0.7518,
      "step": 424450
    },
    {
      "epoch": 4.493920739356662,
      "grad_norm": 4.132815361022949,
      "learning_rate": 2.753954054626297e-05,
      "loss": 0.7575,
      "step": 424500
    },
    {
      "epoch": 4.493920739356662,
      "eval_loss": 0.5030110478401184,
      "eval_runtime": 46.5874,
      "eval_samples_per_second": 3604.62,
      "eval_steps_per_second": 450.594,
      "step": 424500
    },
    {
      "epoch": 4.494450061136666,
      "grad_norm": 4.160314559936523,
      "learning_rate": 2.7536893923353802e-05,
      "loss": 0.7421,
      "step": 424550
    },
    {
      "epoch": 4.494979382916669,
      "grad_norm": 4.427155017852783,
      "learning_rate": 2.7534247300444633e-05,
      "loss": 0.7541,
      "step": 424600
    },
    {
      "epoch": 4.495508704696672,
      "grad_norm": 3.9201765060424805,
      "learning_rate": 2.7531600677535467e-05,
      "loss": 0.7389,
      "step": 424650
    },
    {
      "epoch": 4.4960380264766755,
      "grad_norm": 3.6106104850769043,
      "learning_rate": 2.7528954054626298e-05,
      "loss": 0.741,
      "step": 424700
    },
    {
      "epoch": 4.496567348256678,
      "grad_norm": 4.61732816696167,
      "learning_rate": 2.752630743171713e-05,
      "loss": 0.7433,
      "step": 424750
    },
    {
      "epoch": 4.497096670036682,
      "grad_norm": 4.183948993682861,
      "learning_rate": 2.752366080880796e-05,
      "loss": 0.7453,
      "step": 424800
    },
    {
      "epoch": 4.497625991816685,
      "grad_norm": 4.331382751464844,
      "learning_rate": 2.7521014185898797e-05,
      "loss": 0.75,
      "step": 424850
    },
    {
      "epoch": 4.498155313596689,
      "grad_norm": 4.145472526550293,
      "learning_rate": 2.7518367562989627e-05,
      "loss": 0.7448,
      "step": 424900
    },
    {
      "epoch": 4.498684635376692,
      "grad_norm": 4.202110290527344,
      "learning_rate": 2.7515720940080458e-05,
      "loss": 0.7314,
      "step": 424950
    },
    {
      "epoch": 4.499213957156695,
      "grad_norm": 4.394374370574951,
      "learning_rate": 2.751307431717129e-05,
      "loss": 0.7595,
      "step": 425000
    },
    {
      "epoch": 4.499213957156695,
      "eval_loss": 0.5027586817741394,
      "eval_runtime": 46.6182,
      "eval_samples_per_second": 3602.237,
      "eval_steps_per_second": 450.296,
      "step": 425000
    },
    {
      "epoch": 4.499743278936698,
      "grad_norm": 4.126947402954102,
      "learning_rate": 2.7510427694262126e-05,
      "loss": 0.7557,
      "step": 425050
    },
    {
      "epoch": 4.500272600716702,
      "grad_norm": 4.74469518661499,
      "learning_rate": 2.7507781071352957e-05,
      "loss": 0.7486,
      "step": 425100
    },
    {
      "epoch": 4.500801922496705,
      "grad_norm": 4.203065395355225,
      "learning_rate": 2.7505134448443788e-05,
      "loss": 0.7439,
      "step": 425150
    },
    {
      "epoch": 4.501331244276709,
      "grad_norm": 4.186792373657227,
      "learning_rate": 2.7502487825534618e-05,
      "loss": 0.7435,
      "step": 425200
    },
    {
      "epoch": 4.5018605660567115,
      "grad_norm": 4.387057781219482,
      "learning_rate": 2.7499841202625452e-05,
      "loss": 0.7458,
      "step": 425250
    },
    {
      "epoch": 4.502389887836715,
      "grad_norm": 4.526740550994873,
      "learning_rate": 2.7497194579716283e-05,
      "loss": 0.7476,
      "step": 425300
    },
    {
      "epoch": 4.502919209616718,
      "grad_norm": 4.037314414978027,
      "learning_rate": 2.7494547956807114e-05,
      "loss": 0.7447,
      "step": 425350
    },
    {
      "epoch": 4.503448531396721,
      "grad_norm": 4.29218053817749,
      "learning_rate": 2.7491901333897945e-05,
      "loss": 0.7408,
      "step": 425400
    },
    {
      "epoch": 4.503977853176725,
      "grad_norm": 3.9981186389923096,
      "learning_rate": 2.7489254710988782e-05,
      "loss": 0.7389,
      "step": 425450
    },
    {
      "epoch": 4.504507174956728,
      "grad_norm": 4.374264240264893,
      "learning_rate": 2.7486608088079613e-05,
      "loss": 0.7245,
      "step": 425500
    },
    {
      "epoch": 4.504507174956728,
      "eval_loss": 0.5020577907562256,
      "eval_runtime": 46.5764,
      "eval_samples_per_second": 3605.477,
      "eval_steps_per_second": 450.701,
      "step": 425500
    },
    {
      "epoch": 4.505036496736731,
      "grad_norm": 4.546356678009033,
      "learning_rate": 2.7483961465170443e-05,
      "loss": 0.7488,
      "step": 425550
    },
    {
      "epoch": 4.505565818516734,
      "grad_norm": 4.214950084686279,
      "learning_rate": 2.7481314842261274e-05,
      "loss": 0.7419,
      "step": 425600
    },
    {
      "epoch": 4.506095140296738,
      "grad_norm": 3.9160284996032715,
      "learning_rate": 2.747866821935211e-05,
      "loss": 0.7436,
      "step": 425650
    },
    {
      "epoch": 4.506624462076741,
      "grad_norm": 4.085980415344238,
      "learning_rate": 2.7476021596442942e-05,
      "loss": 0.7504,
      "step": 425700
    },
    {
      "epoch": 4.507153783856745,
      "grad_norm": 4.237053871154785,
      "learning_rate": 2.7473374973533773e-05,
      "loss": 0.7287,
      "step": 425750
    },
    {
      "epoch": 4.5076831056367475,
      "grad_norm": 4.417235851287842,
      "learning_rate": 2.7470728350624604e-05,
      "loss": 0.7399,
      "step": 425800
    },
    {
      "epoch": 4.508212427416751,
      "grad_norm": 4.22957181930542,
      "learning_rate": 2.7468081727715438e-05,
      "loss": 0.7489,
      "step": 425850
    },
    {
      "epoch": 4.508741749196754,
      "grad_norm": 3.9629321098327637,
      "learning_rate": 2.746543510480627e-05,
      "loss": 0.755,
      "step": 425900
    },
    {
      "epoch": 4.509271070976758,
      "grad_norm": 3.912668466567993,
      "learning_rate": 2.74627884818971e-05,
      "loss": 0.7387,
      "step": 425950
    },
    {
      "epoch": 4.509800392756761,
      "grad_norm": 4.377951622009277,
      "learning_rate": 2.746014185898793e-05,
      "loss": 0.7549,
      "step": 426000
    },
    {
      "epoch": 4.509800392756761,
      "eval_loss": 0.5017834901809692,
      "eval_runtime": 46.6081,
      "eval_samples_per_second": 3603.019,
      "eval_steps_per_second": 450.393,
      "step": 426000
    },
    {
      "epoch": 4.5103297145367645,
      "grad_norm": 4.579832077026367,
      "learning_rate": 2.7457495236078767e-05,
      "loss": 0.7471,
      "step": 426050
    },
    {
      "epoch": 4.510859036316767,
      "grad_norm": 3.936570644378662,
      "learning_rate": 2.7454848613169598e-05,
      "loss": 0.7426,
      "step": 426100
    },
    {
      "epoch": 4.51138835809677,
      "grad_norm": 4.318919658660889,
      "learning_rate": 2.745220199026043e-05,
      "loss": 0.7255,
      "step": 426150
    },
    {
      "epoch": 4.511917679876774,
      "grad_norm": 4.593923568725586,
      "learning_rate": 2.744955536735126e-05,
      "loss": 0.7468,
      "step": 426200
    },
    {
      "epoch": 4.512447001656777,
      "grad_norm": 4.249393939971924,
      "learning_rate": 2.7446908744442097e-05,
      "loss": 0.7497,
      "step": 426250
    },
    {
      "epoch": 4.512976323436781,
      "grad_norm": 3.6286613941192627,
      "learning_rate": 2.744431505399111e-05,
      "loss": 0.751,
      "step": 426300
    },
    {
      "epoch": 4.513505645216783,
      "grad_norm": 4.153911590576172,
      "learning_rate": 2.744166843108194e-05,
      "loss": 0.7481,
      "step": 426350
    },
    {
      "epoch": 4.514034966996787,
      "grad_norm": 4.697303295135498,
      "learning_rate": 2.743902180817277e-05,
      "loss": 0.7409,
      "step": 426400
    },
    {
      "epoch": 4.51456428877679,
      "grad_norm": 4.348114967346191,
      "learning_rate": 2.7436375185263607e-05,
      "loss": 0.7348,
      "step": 426450
    },
    {
      "epoch": 4.515093610556794,
      "grad_norm": 4.412121772766113,
      "learning_rate": 2.7433728562354438e-05,
      "loss": 0.7381,
      "step": 426500
    },
    {
      "epoch": 4.515093610556794,
      "eval_loss": 0.5026472210884094,
      "eval_runtime": 46.5229,
      "eval_samples_per_second": 3609.618,
      "eval_steps_per_second": 451.218,
      "step": 426500
    },
    {
      "epoch": 4.515622932336797,
      "grad_norm": 4.109304428100586,
      "learning_rate": 2.743108193944527e-05,
      "loss": 0.7462,
      "step": 426550
    },
    {
      "epoch": 4.5161522541168,
      "grad_norm": 3.755413770675659,
      "learning_rate": 2.74284353165361e-05,
      "loss": 0.7435,
      "step": 426600
    },
    {
      "epoch": 4.516681575896803,
      "grad_norm": 4.313797473907471,
      "learning_rate": 2.7425788693626937e-05,
      "loss": 0.7388,
      "step": 426650
    },
    {
      "epoch": 4.517210897676807,
      "grad_norm": 3.8368277549743652,
      "learning_rate": 2.7423142070717768e-05,
      "loss": 0.75,
      "step": 426700
    },
    {
      "epoch": 4.51774021945681,
      "grad_norm": 4.419669151306152,
      "learning_rate": 2.74204954478086e-05,
      "loss": 0.7543,
      "step": 426750
    },
    {
      "epoch": 4.518269541236814,
      "grad_norm": 4.2886199951171875,
      "learning_rate": 2.741784882489943e-05,
      "loss": 0.7481,
      "step": 426800
    },
    {
      "epoch": 4.5187988630168165,
      "grad_norm": 4.050542831420898,
      "learning_rate": 2.7415202201990263e-05,
      "loss": 0.7381,
      "step": 426850
    },
    {
      "epoch": 4.519328184796819,
      "grad_norm": 4.514625549316406,
      "learning_rate": 2.7412555579081094e-05,
      "loss": 0.7485,
      "step": 426900
    },
    {
      "epoch": 4.519857506576823,
      "grad_norm": 4.082573413848877,
      "learning_rate": 2.7409908956171925e-05,
      "loss": 0.7407,
      "step": 426950
    },
    {
      "epoch": 4.520386828356826,
      "grad_norm": 4.457533359527588,
      "learning_rate": 2.7407262333262755e-05,
      "loss": 0.7407,
      "step": 427000
    },
    {
      "epoch": 4.520386828356826,
      "eval_loss": 0.500919759273529,
      "eval_runtime": 46.8912,
      "eval_samples_per_second": 3581.269,
      "eval_steps_per_second": 447.675,
      "step": 427000
    },
    {
      "epoch": 4.52091615013683,
      "grad_norm": 4.005970001220703,
      "learning_rate": 2.7404615710353593e-05,
      "loss": 0.7394,
      "step": 427050
    },
    {
      "epoch": 4.521445471916833,
      "grad_norm": 4.195990085601807,
      "learning_rate": 2.7401969087444424e-05,
      "loss": 0.75,
      "step": 427100
    },
    {
      "epoch": 4.521974793696836,
      "grad_norm": 4.863515377044678,
      "learning_rate": 2.7399322464535254e-05,
      "loss": 0.7572,
      "step": 427150
    },
    {
      "epoch": 4.522504115476839,
      "grad_norm": 4.222896575927734,
      "learning_rate": 2.7396675841626085e-05,
      "loss": 0.741,
      "step": 427200
    },
    {
      "epoch": 4.523033437256843,
      "grad_norm": 4.171154499053955,
      "learning_rate": 2.7394029218716922e-05,
      "loss": 0.7419,
      "step": 427250
    },
    {
      "epoch": 4.523562759036846,
      "grad_norm": 4.106906890869141,
      "learning_rate": 2.7391382595807753e-05,
      "loss": 0.7503,
      "step": 427300
    },
    {
      "epoch": 4.52409208081685,
      "grad_norm": 4.300812721252441,
      "learning_rate": 2.7388788905356764e-05,
      "loss": 0.7366,
      "step": 427350
    },
    {
      "epoch": 4.5246214025968525,
      "grad_norm": 3.6629295349121094,
      "learning_rate": 2.7386142282447595e-05,
      "loss": 0.7348,
      "step": 427400
    },
    {
      "epoch": 4.525150724376856,
      "grad_norm": 4.564199447631836,
      "learning_rate": 2.7383495659538433e-05,
      "loss": 0.7462,
      "step": 427450
    },
    {
      "epoch": 4.525680046156859,
      "grad_norm": 3.9185619354248047,
      "learning_rate": 2.7380849036629263e-05,
      "loss": 0.7445,
      "step": 427500
    },
    {
      "epoch": 4.525680046156859,
      "eval_loss": 0.5018445253372192,
      "eval_runtime": 46.9082,
      "eval_samples_per_second": 3579.969,
      "eval_steps_per_second": 447.512,
      "step": 427500
    },
    {
      "epoch": 4.526209367936863,
      "grad_norm": 4.47599983215332,
      "learning_rate": 2.7378202413720094e-05,
      "loss": 0.7562,
      "step": 427550
    },
    {
      "epoch": 4.526738689716866,
      "grad_norm": 4.09751558303833,
      "learning_rate": 2.7375555790810925e-05,
      "loss": 0.7524,
      "step": 427600
    },
    {
      "epoch": 4.527268011496869,
      "grad_norm": 4.1509222984313965,
      "learning_rate": 2.7372909167901762e-05,
      "loss": 0.7319,
      "step": 427650
    },
    {
      "epoch": 4.527797333276872,
      "grad_norm": 3.9288127422332764,
      "learning_rate": 2.7370262544992593e-05,
      "loss": 0.7411,
      "step": 427700
    },
    {
      "epoch": 4.528326655056875,
      "grad_norm": 4.019178867340088,
      "learning_rate": 2.7367615922083424e-05,
      "loss": 0.7436,
      "step": 427750
    },
    {
      "epoch": 4.528855976836879,
      "grad_norm": 4.255506992340088,
      "learning_rate": 2.7364969299174254e-05,
      "loss": 0.7419,
      "step": 427800
    },
    {
      "epoch": 4.529385298616882,
      "grad_norm": 4.093707084655762,
      "learning_rate": 2.736232267626509e-05,
      "loss": 0.7352,
      "step": 427850
    },
    {
      "epoch": 4.529914620396886,
      "grad_norm": 4.2923760414123535,
      "learning_rate": 2.735967605335592e-05,
      "loss": 0.7356,
      "step": 427900
    },
    {
      "epoch": 4.5304439421768885,
      "grad_norm": 4.354833602905273,
      "learning_rate": 2.735702943044675e-05,
      "loss": 0.7379,
      "step": 427950
    },
    {
      "epoch": 4.530973263956892,
      "grad_norm": 4.589748382568359,
      "learning_rate": 2.735438280753758e-05,
      "loss": 0.7421,
      "step": 428000
    },
    {
      "epoch": 4.530973263956892,
      "eval_loss": 0.5007793307304382,
      "eval_runtime": 46.7539,
      "eval_samples_per_second": 3591.785,
      "eval_steps_per_second": 448.989,
      "step": 428000
    },
    {
      "epoch": 4.531502585736895,
      "grad_norm": 4.1832780838012695,
      "learning_rate": 2.7351736184628418e-05,
      "loss": 0.7448,
      "step": 428050
    },
    {
      "epoch": 4.532031907516899,
      "grad_norm": 4.105393886566162,
      "learning_rate": 2.734908956171925e-05,
      "loss": 0.742,
      "step": 428100
    },
    {
      "epoch": 4.532561229296902,
      "grad_norm": 4.1561689376831055,
      "learning_rate": 2.734644293881008e-05,
      "loss": 0.7306,
      "step": 428150
    },
    {
      "epoch": 4.5330905510769055,
      "grad_norm": 4.3116984367370605,
      "learning_rate": 2.734379631590091e-05,
      "loss": 0.7586,
      "step": 428200
    },
    {
      "epoch": 4.533619872856908,
      "grad_norm": 4.164801597595215,
      "learning_rate": 2.7341149692991748e-05,
      "loss": 0.7383,
      "step": 428250
    },
    {
      "epoch": 4.534149194636912,
      "grad_norm": 4.427539825439453,
      "learning_rate": 2.733850307008258e-05,
      "loss": 0.7279,
      "step": 428300
    },
    {
      "epoch": 4.534678516416915,
      "grad_norm": 4.235256195068359,
      "learning_rate": 2.733585644717341e-05,
      "loss": 0.7546,
      "step": 428350
    },
    {
      "epoch": 4.535207838196918,
      "grad_norm": 3.9367053508758545,
      "learning_rate": 2.733320982426424e-05,
      "loss": 0.7463,
      "step": 428400
    },
    {
      "epoch": 4.535737159976922,
      "grad_norm": 4.322179317474365,
      "learning_rate": 2.7330563201355074e-05,
      "loss": 0.7455,
      "step": 428450
    },
    {
      "epoch": 4.5362664817569245,
      "grad_norm": 4.126583576202393,
      "learning_rate": 2.7327916578445905e-05,
      "loss": 0.7285,
      "step": 428500
    },
    {
      "epoch": 4.5362664817569245,
      "eval_loss": 0.49871161580085754,
      "eval_runtime": 47.1684,
      "eval_samples_per_second": 3560.225,
      "eval_steps_per_second": 445.044,
      "step": 428500
    },
    {
      "epoch": 4.536795803536928,
      "grad_norm": 3.835543632507324,
      "learning_rate": 2.7325269955536735e-05,
      "loss": 0.7499,
      "step": 428550
    },
    {
      "epoch": 4.537325125316931,
      "grad_norm": 4.118711471557617,
      "learning_rate": 2.7322623332627566e-05,
      "loss": 0.7364,
      "step": 428600
    },
    {
      "epoch": 4.537854447096935,
      "grad_norm": 4.748835563659668,
      "learning_rate": 2.7319976709718404e-05,
      "loss": 0.7439,
      "step": 428650
    },
    {
      "epoch": 4.538383768876938,
      "grad_norm": 4.39290714263916,
      "learning_rate": 2.7317330086809234e-05,
      "loss": 0.7374,
      "step": 428700
    },
    {
      "epoch": 4.5389130906569415,
      "grad_norm": 4.418133735656738,
      "learning_rate": 2.7314683463900065e-05,
      "loss": 0.7471,
      "step": 428750
    },
    {
      "epoch": 4.539442412436944,
      "grad_norm": 4.129456043243408,
      "learning_rate": 2.7312036840990896e-05,
      "loss": 0.7472,
      "step": 428800
    },
    {
      "epoch": 4.539971734216948,
      "grad_norm": 3.937161445617676,
      "learning_rate": 2.7309390218081726e-05,
      "loss": 0.7315,
      "step": 428850
    },
    {
      "epoch": 4.540501055996951,
      "grad_norm": 4.177696228027344,
      "learning_rate": 2.7306743595172564e-05,
      "loss": 0.7601,
      "step": 428900
    },
    {
      "epoch": 4.541030377776955,
      "grad_norm": 4.200759410858154,
      "learning_rate": 2.7304096972263395e-05,
      "loss": 0.7411,
      "step": 428950
    },
    {
      "epoch": 4.541559699556958,
      "grad_norm": 3.7731356620788574,
      "learning_rate": 2.7301450349354225e-05,
      "loss": 0.7428,
      "step": 429000
    },
    {
      "epoch": 4.541559699556958,
      "eval_loss": 0.5011039972305298,
      "eval_runtime": 47.612,
      "eval_samples_per_second": 3527.049,
      "eval_steps_per_second": 440.897,
      "step": 429000
    },
    {
      "epoch": 4.542089021336961,
      "grad_norm": 3.643921375274658,
      "learning_rate": 2.7298803726445056e-05,
      "loss": 0.7363,
      "step": 429050
    },
    {
      "epoch": 4.542618343116964,
      "grad_norm": 4.528096675872803,
      "learning_rate": 2.729615710353589e-05,
      "loss": 0.7561,
      "step": 429100
    },
    {
      "epoch": 4.543147664896967,
      "grad_norm": 4.540703773498535,
      "learning_rate": 2.729351048062672e-05,
      "loss": 0.7567,
      "step": 429150
    },
    {
      "epoch": 4.543676986676971,
      "grad_norm": 4.097955226898193,
      "learning_rate": 2.729086385771755e-05,
      "loss": 0.7431,
      "step": 429200
    },
    {
      "epoch": 4.544206308456974,
      "grad_norm": 4.0000224113464355,
      "learning_rate": 2.7288217234808382e-05,
      "loss": 0.7474,
      "step": 429250
    },
    {
      "epoch": 4.5447356302369775,
      "grad_norm": 3.850572109222412,
      "learning_rate": 2.728557061189922e-05,
      "loss": 0.7255,
      "step": 429300
    },
    {
      "epoch": 4.54526495201698,
      "grad_norm": 4.366720676422119,
      "learning_rate": 2.728292398899005e-05,
      "loss": 0.7526,
      "step": 429350
    },
    {
      "epoch": 4.545794273796984,
      "grad_norm": 4.0724382400512695,
      "learning_rate": 2.728027736608088e-05,
      "loss": 0.7476,
      "step": 429400
    },
    {
      "epoch": 4.546323595576987,
      "grad_norm": 4.445221424102783,
      "learning_rate": 2.7277630743171712e-05,
      "loss": 0.7345,
      "step": 429450
    },
    {
      "epoch": 4.546852917356991,
      "grad_norm": 4.1008405685424805,
      "learning_rate": 2.727498412026255e-05,
      "loss": 0.7435,
      "step": 429500
    },
    {
      "epoch": 4.546852917356991,
      "eval_loss": 0.4987737238407135,
      "eval_runtime": 47.3969,
      "eval_samples_per_second": 3543.059,
      "eval_steps_per_second": 442.898,
      "step": 429500
    },
    {
      "epoch": 4.547382239136994,
      "grad_norm": 3.9992666244506836,
      "learning_rate": 2.727233749735338e-05,
      "loss": 0.7477,
      "step": 429550
    },
    {
      "epoch": 4.547911560916997,
      "grad_norm": 4.195008754730225,
      "learning_rate": 2.726969087444421e-05,
      "loss": 0.7368,
      "step": 429600
    },
    {
      "epoch": 4.548440882697,
      "grad_norm": 4.268657207489014,
      "learning_rate": 2.726704425153504e-05,
      "loss": 0.7535,
      "step": 429650
    },
    {
      "epoch": 4.548970204477004,
      "grad_norm": 4.292191028594971,
      "learning_rate": 2.7264397628625876e-05,
      "loss": 0.7392,
      "step": 429700
    },
    {
      "epoch": 4.549499526257007,
      "grad_norm": 4.488155364990234,
      "learning_rate": 2.7261751005716706e-05,
      "loss": 0.7544,
      "step": 429750
    },
    {
      "epoch": 4.550028848037011,
      "grad_norm": 4.16763973236084,
      "learning_rate": 2.7259104382807537e-05,
      "loss": 0.7419,
      "step": 429800
    },
    {
      "epoch": 4.550558169817013,
      "grad_norm": 4.335850715637207,
      "learning_rate": 2.7256457759898368e-05,
      "loss": 0.7409,
      "step": 429850
    },
    {
      "epoch": 4.551087491597016,
      "grad_norm": 4.360682010650635,
      "learning_rate": 2.7253811136989205e-05,
      "loss": 0.7479,
      "step": 429900
    },
    {
      "epoch": 4.55161681337702,
      "grad_norm": 4.317724227905273,
      "learning_rate": 2.7251164514080036e-05,
      "loss": 0.7409,
      "step": 429950
    },
    {
      "epoch": 4.552146135157023,
      "grad_norm": 4.463780879974365,
      "learning_rate": 2.7248517891170867e-05,
      "loss": 0.7562,
      "step": 430000
    },
    {
      "epoch": 4.552146135157023,
      "eval_loss": 0.5001857876777649,
      "eval_runtime": 46.9766,
      "eval_samples_per_second": 3574.759,
      "eval_steps_per_second": 446.861,
      "step": 430000
    },
    {
      "epoch": 4.552675456937027,
      "grad_norm": 3.8328611850738525,
      "learning_rate": 2.7245871268261697e-05,
      "loss": 0.7451,
      "step": 430050
    },
    {
      "epoch": 4.5532047787170296,
      "grad_norm": 4.235525131225586,
      "learning_rate": 2.724322464535253e-05,
      "loss": 0.7371,
      "step": 430100
    },
    {
      "epoch": 4.553734100497033,
      "grad_norm": 4.150697708129883,
      "learning_rate": 2.7240578022443362e-05,
      "loss": 0.7337,
      "step": 430150
    },
    {
      "epoch": 4.554263422277036,
      "grad_norm": 4.489282131195068,
      "learning_rate": 2.7237931399534193e-05,
      "loss": 0.7424,
      "step": 430200
    },
    {
      "epoch": 4.55479274405704,
      "grad_norm": 4.0586466789245605,
      "learning_rate": 2.7235284776625024e-05,
      "loss": 0.7353,
      "step": 430250
    },
    {
      "epoch": 4.555322065837043,
      "grad_norm": 4.452017784118652,
      "learning_rate": 2.723263815371586e-05,
      "loss": 0.7413,
      "step": 430300
    },
    {
      "epoch": 4.5558513876170466,
      "grad_norm": 4.42088508605957,
      "learning_rate": 2.7229991530806692e-05,
      "loss": 0.7439,
      "step": 430350
    },
    {
      "epoch": 4.556380709397049,
      "grad_norm": 4.078893661499023,
      "learning_rate": 2.7227344907897523e-05,
      "loss": 0.7453,
      "step": 430400
    },
    {
      "epoch": 4.556910031177053,
      "grad_norm": 3.865464925765991,
      "learning_rate": 2.7224698284988353e-05,
      "loss": 0.7375,
      "step": 430450
    },
    {
      "epoch": 4.557439352957056,
      "grad_norm": 4.592127323150635,
      "learning_rate": 2.722205166207919e-05,
      "loss": 0.7421,
      "step": 430500
    },
    {
      "epoch": 4.557439352957056,
      "eval_loss": 0.4988778829574585,
      "eval_runtime": 46.8078,
      "eval_samples_per_second": 3587.651,
      "eval_steps_per_second": 448.472,
      "step": 430500
    },
    {
      "epoch": 4.55796867473706,
      "grad_norm": 3.889103889465332,
      "learning_rate": 2.721940503917002e-05,
      "loss": 0.7453,
      "step": 430550
    },
    {
      "epoch": 4.558497996517063,
      "grad_norm": 4.41609001159668,
      "learning_rate": 2.7216758416260852e-05,
      "loss": 0.744,
      "step": 430600
    },
    {
      "epoch": 4.5590273182970655,
      "grad_norm": 4.38847541809082,
      "learning_rate": 2.7214111793351683e-05,
      "loss": 0.744,
      "step": 430650
    },
    {
      "epoch": 4.559556640077069,
      "grad_norm": 4.588459014892578,
      "learning_rate": 2.7211465170442517e-05,
      "loss": 0.7485,
      "step": 430700
    },
    {
      "epoch": 4.560085961857072,
      "grad_norm": 4.380582332611084,
      "learning_rate": 2.7208818547533348e-05,
      "loss": 0.7306,
      "step": 430750
    },
    {
      "epoch": 4.560615283637076,
      "grad_norm": 4.027584552764893,
      "learning_rate": 2.720617192462418e-05,
      "loss": 0.733,
      "step": 430800
    },
    {
      "epoch": 4.561144605417079,
      "grad_norm": 4.20280122756958,
      "learning_rate": 2.720352530171501e-05,
      "loss": 0.7618,
      "step": 430850
    },
    {
      "epoch": 4.5616739271970825,
      "grad_norm": 3.7495603561401367,
      "learning_rate": 2.7200878678805847e-05,
      "loss": 0.747,
      "step": 430900
    },
    {
      "epoch": 4.562203248977085,
      "grad_norm": 3.848630666732788,
      "learning_rate": 2.7198232055896677e-05,
      "loss": 0.7442,
      "step": 430950
    },
    {
      "epoch": 4.562732570757089,
      "grad_norm": 4.4387102127075195,
      "learning_rate": 2.7195585432987508e-05,
      "loss": 0.7303,
      "step": 431000
    },
    {
      "epoch": 4.562732570757089,
      "eval_loss": 0.49853965640068054,
      "eval_runtime": 48.4142,
      "eval_samples_per_second": 3468.614,
      "eval_steps_per_second": 433.592,
      "step": 431000
    },
    {
      "epoch": 4.563261892537092,
      "grad_norm": 4.091886043548584,
      "learning_rate": 2.719293881007834e-05,
      "loss": 0.7437,
      "step": 431050
    },
    {
      "epoch": 4.563791214317096,
      "grad_norm": 4.306236743927002,
      "learning_rate": 2.7190292187169176e-05,
      "loss": 0.728,
      "step": 431100
    },
    {
      "epoch": 4.564320536097099,
      "grad_norm": 4.5734758377075195,
      "learning_rate": 2.7187645564260007e-05,
      "loss": 0.7594,
      "step": 431150
    },
    {
      "epoch": 4.564849857877102,
      "grad_norm": 4.464322090148926,
      "learning_rate": 2.7184998941350838e-05,
      "loss": 0.7597,
      "step": 431200
    },
    {
      "epoch": 4.565379179657105,
      "grad_norm": 4.768270969390869,
      "learning_rate": 2.718235231844167e-05,
      "loss": 0.735,
      "step": 431250
    },
    {
      "epoch": 4.565908501437109,
      "grad_norm": 4.494406700134277,
      "learning_rate": 2.7179705695532503e-05,
      "loss": 0.7439,
      "step": 431300
    },
    {
      "epoch": 4.566437823217112,
      "grad_norm": 3.8688876628875732,
      "learning_rate": 2.7177112005081517e-05,
      "loss": 0.7387,
      "step": 431350
    },
    {
      "epoch": 4.566967144997115,
      "grad_norm": 4.461805820465088,
      "learning_rate": 2.7174465382172348e-05,
      "loss": 0.7422,
      "step": 431400
    },
    {
      "epoch": 4.5674964667771185,
      "grad_norm": 4.169509410858154,
      "learning_rate": 2.717181875926318e-05,
      "loss": 0.7363,
      "step": 431450
    },
    {
      "epoch": 4.568025788557121,
      "grad_norm": 4.249886989593506,
      "learning_rate": 2.7169172136354016e-05,
      "loss": 0.7455,
      "step": 431500
    },
    {
      "epoch": 4.568025788557121,
      "eval_loss": 0.4996534585952759,
      "eval_runtime": 47.2974,
      "eval_samples_per_second": 3550.516,
      "eval_steps_per_second": 443.83,
      "step": 431500
    },
    {
      "epoch": 4.568555110337125,
      "grad_norm": 4.05892276763916,
      "learning_rate": 2.7166525513444847e-05,
      "loss": 0.7429,
      "step": 431550
    },
    {
      "epoch": 4.569084432117128,
      "grad_norm": 4.748954772949219,
      "learning_rate": 2.7163878890535678e-05,
      "loss": 0.7536,
      "step": 431600
    },
    {
      "epoch": 4.569613753897132,
      "grad_norm": 4.1963958740234375,
      "learning_rate": 2.7161232267626508e-05,
      "loss": 0.7374,
      "step": 431650
    },
    {
      "epoch": 4.570143075677135,
      "grad_norm": 4.214873313903809,
      "learning_rate": 2.7158585644717342e-05,
      "loss": 0.7404,
      "step": 431700
    },
    {
      "epoch": 4.570672397457138,
      "grad_norm": 4.200596809387207,
      "learning_rate": 2.7155939021808173e-05,
      "loss": 0.7397,
      "step": 431750
    },
    {
      "epoch": 4.571201719237141,
      "grad_norm": 4.55126953125,
      "learning_rate": 2.7153292398899004e-05,
      "loss": 0.7305,
      "step": 431800
    },
    {
      "epoch": 4.571731041017145,
      "grad_norm": 3.999375820159912,
      "learning_rate": 2.7150645775989835e-05,
      "loss": 0.7458,
      "step": 431850
    },
    {
      "epoch": 4.572260362797148,
      "grad_norm": 4.0694580078125,
      "learning_rate": 2.7147999153080672e-05,
      "loss": 0.7437,
      "step": 431900
    },
    {
      "epoch": 4.572789684577152,
      "grad_norm": 3.872248649597168,
      "learning_rate": 2.7145352530171503e-05,
      "loss": 0.7255,
      "step": 431950
    },
    {
      "epoch": 4.5733190063571545,
      "grad_norm": 4.0553436279296875,
      "learning_rate": 2.7142705907262333e-05,
      "loss": 0.743,
      "step": 432000
    },
    {
      "epoch": 4.5733190063571545,
      "eval_loss": 0.49802669882774353,
      "eval_runtime": 47.3514,
      "eval_samples_per_second": 3546.463,
      "eval_steps_per_second": 443.324,
      "step": 432000
    },
    {
      "epoch": 4.573848328137158,
      "grad_norm": 4.061593055725098,
      "learning_rate": 2.7140059284353164e-05,
      "loss": 0.7416,
      "step": 432050
    },
    {
      "epoch": 4.574377649917161,
      "grad_norm": 3.8767647743225098,
      "learning_rate": 2.7137412661444e-05,
      "loss": 0.7411,
      "step": 432100
    },
    {
      "epoch": 4.574906971697164,
      "grad_norm": 4.230347156524658,
      "learning_rate": 2.7134766038534832e-05,
      "loss": 0.7518,
      "step": 432150
    },
    {
      "epoch": 4.575436293477168,
      "grad_norm": 3.8510358333587646,
      "learning_rate": 2.7132119415625663e-05,
      "loss": 0.7317,
      "step": 432200
    },
    {
      "epoch": 4.575965615257171,
      "grad_norm": 3.940007448196411,
      "learning_rate": 2.7129472792716494e-05,
      "loss": 0.7281,
      "step": 432250
    },
    {
      "epoch": 4.576494937037174,
      "grad_norm": 4.623006820678711,
      "learning_rate": 2.7126826169807328e-05,
      "loss": 0.7371,
      "step": 432300
    },
    {
      "epoch": 4.577024258817177,
      "grad_norm": 4.136831283569336,
      "learning_rate": 2.712417954689816e-05,
      "loss": 0.7438,
      "step": 432350
    },
    {
      "epoch": 4.577553580597181,
      "grad_norm": 4.083052158355713,
      "learning_rate": 2.712153292398899e-05,
      "loss": 0.7389,
      "step": 432400
    },
    {
      "epoch": 4.578082902377184,
      "grad_norm": 4.174593925476074,
      "learning_rate": 2.711888630107982e-05,
      "loss": 0.7406,
      "step": 432450
    },
    {
      "epoch": 4.578612224157188,
      "grad_norm": 4.068782329559326,
      "learning_rate": 2.7116239678170657e-05,
      "loss": 0.7513,
      "step": 432500
    },
    {
      "epoch": 4.578612224157188,
      "eval_loss": 0.4980663061141968,
      "eval_runtime": 47.5205,
      "eval_samples_per_second": 3533.847,
      "eval_steps_per_second": 441.747,
      "step": 432500
    },
    {
      "epoch": 4.5791415459371905,
      "grad_norm": 4.074377536773682,
      "learning_rate": 2.7113593055261488e-05,
      "loss": 0.7475,
      "step": 432550
    },
    {
      "epoch": 4.579670867717194,
      "grad_norm": 4.056827068328857,
      "learning_rate": 2.711094643235232e-05,
      "loss": 0.7516,
      "step": 432600
    },
    {
      "epoch": 4.580200189497197,
      "grad_norm": 4.0644049644470215,
      "learning_rate": 2.710829980944315e-05,
      "loss": 0.7524,
      "step": 432650
    },
    {
      "epoch": 4.580729511277201,
      "grad_norm": 4.077338695526123,
      "learning_rate": 2.7105653186533987e-05,
      "loss": 0.7321,
      "step": 432700
    },
    {
      "epoch": 4.581258833057204,
      "grad_norm": 4.300039768218994,
      "learning_rate": 2.7103006563624818e-05,
      "loss": 0.7423,
      "step": 432750
    },
    {
      "epoch": 4.5817881548372075,
      "grad_norm": 4.522196292877197,
      "learning_rate": 2.710035994071565e-05,
      "loss": 0.745,
      "step": 432800
    },
    {
      "epoch": 4.58231747661721,
      "grad_norm": 4.1413445472717285,
      "learning_rate": 2.709771331780648e-05,
      "loss": 0.728,
      "step": 432850
    },
    {
      "epoch": 4.582846798397213,
      "grad_norm": 4.18563985824585,
      "learning_rate": 2.7095066694897313e-05,
      "loss": 0.7402,
      "step": 432900
    },
    {
      "epoch": 4.583376120177217,
      "grad_norm": 4.3042144775390625,
      "learning_rate": 2.7092420071988144e-05,
      "loss": 0.7428,
      "step": 432950
    },
    {
      "epoch": 4.58390544195722,
      "grad_norm": 4.157704830169678,
      "learning_rate": 2.7089773449078975e-05,
      "loss": 0.7328,
      "step": 433000
    },
    {
      "epoch": 4.58390544195722,
      "eval_loss": 0.4984530806541443,
      "eval_runtime": 47.1611,
      "eval_samples_per_second": 3560.776,
      "eval_steps_per_second": 445.113,
      "step": 433000
    },
    {
      "epoch": 4.584434763737224,
      "grad_norm": 4.062069892883301,
      "learning_rate": 2.7087126826169805e-05,
      "loss": 0.7429,
      "step": 433050
    },
    {
      "epoch": 4.5849640855172265,
      "grad_norm": 4.21973991394043,
      "learning_rate": 2.7084480203260643e-05,
      "loss": 0.7528,
      "step": 433100
    },
    {
      "epoch": 4.58549340729723,
      "grad_norm": 3.777005910873413,
      "learning_rate": 2.7081833580351474e-05,
      "loss": 0.7422,
      "step": 433150
    },
    {
      "epoch": 4.586022729077233,
      "grad_norm": 5.043220520019531,
      "learning_rate": 2.7079186957442304e-05,
      "loss": 0.7425,
      "step": 433200
    },
    {
      "epoch": 4.586552050857237,
      "grad_norm": 4.213840007781982,
      "learning_rate": 2.7076540334533135e-05,
      "loss": 0.7361,
      "step": 433250
    },
    {
      "epoch": 4.58708137263724,
      "grad_norm": 3.8775689601898193,
      "learning_rate": 2.7073893711623973e-05,
      "loss": 0.7333,
      "step": 433300
    },
    {
      "epoch": 4.5876106944172435,
      "grad_norm": 4.033019065856934,
      "learning_rate": 2.7071300021172984e-05,
      "loss": 0.7409,
      "step": 433350
    },
    {
      "epoch": 4.588140016197246,
      "grad_norm": 4.350188255310059,
      "learning_rate": 2.7068653398263815e-05,
      "loss": 0.7505,
      "step": 433400
    },
    {
      "epoch": 4.58866933797725,
      "grad_norm": 4.305291175842285,
      "learning_rate": 2.7066006775354645e-05,
      "loss": 0.7378,
      "step": 433450
    },
    {
      "epoch": 4.589198659757253,
      "grad_norm": 3.8269379138946533,
      "learning_rate": 2.7063360152445483e-05,
      "loss": 0.7404,
      "step": 433500
    },
    {
      "epoch": 4.589198659757253,
      "eval_loss": 0.4962514042854309,
      "eval_runtime": 47.421,
      "eval_samples_per_second": 3541.255,
      "eval_steps_per_second": 442.673,
      "step": 433500
    },
    {
      "epoch": 4.589727981537257,
      "grad_norm": 4.155632019042969,
      "learning_rate": 2.7060713529536314e-05,
      "loss": 0.738,
      "step": 433550
    },
    {
      "epoch": 4.59025730331726,
      "grad_norm": 4.577559471130371,
      "learning_rate": 2.7058066906627144e-05,
      "loss": 0.7444,
      "step": 433600
    },
    {
      "epoch": 4.590786625097262,
      "grad_norm": 4.279081344604492,
      "learning_rate": 2.7055420283717975e-05,
      "loss": 0.7384,
      "step": 433650
    },
    {
      "epoch": 4.591315946877266,
      "grad_norm": 4.549869537353516,
      "learning_rate": 2.7052773660808812e-05,
      "loss": 0.7458,
      "step": 433700
    },
    {
      "epoch": 4.591845268657269,
      "grad_norm": 4.136384010314941,
      "learning_rate": 2.7050127037899643e-05,
      "loss": 0.748,
      "step": 433750
    },
    {
      "epoch": 4.592374590437273,
      "grad_norm": 4.362789630889893,
      "learning_rate": 2.7047480414990474e-05,
      "loss": 0.7504,
      "step": 433800
    },
    {
      "epoch": 4.592903912217276,
      "grad_norm": 4.073574542999268,
      "learning_rate": 2.7044833792081305e-05,
      "loss": 0.7337,
      "step": 433850
    },
    {
      "epoch": 4.593433233997279,
      "grad_norm": 4.318422317504883,
      "learning_rate": 2.704218716917214e-05,
      "loss": 0.741,
      "step": 433900
    },
    {
      "epoch": 4.593962555777282,
      "grad_norm": 4.331966400146484,
      "learning_rate": 2.703954054626297e-05,
      "loss": 0.7419,
      "step": 433950
    },
    {
      "epoch": 4.594491877557286,
      "grad_norm": 4.014517307281494,
      "learning_rate": 2.70368939233538e-05,
      "loss": 0.7321,
      "step": 434000
    },
    {
      "epoch": 4.594491877557286,
      "eval_loss": 0.49578753113746643,
      "eval_runtime": 47.4237,
      "eval_samples_per_second": 3541.057,
      "eval_steps_per_second": 442.648,
      "step": 434000
    },
    {
      "epoch": 4.595021199337289,
      "grad_norm": 4.264194011688232,
      "learning_rate": 2.703424730044463e-05,
      "loss": 0.7331,
      "step": 434050
    },
    {
      "epoch": 4.595550521117293,
      "grad_norm": 3.784701108932495,
      "learning_rate": 2.7031600677535468e-05,
      "loss": 0.7397,
      "step": 434100
    },
    {
      "epoch": 4.5960798428972955,
      "grad_norm": 4.494932651519775,
      "learning_rate": 2.70289540546263e-05,
      "loss": 0.7387,
      "step": 434150
    },
    {
      "epoch": 4.596609164677299,
      "grad_norm": 4.658732891082764,
      "learning_rate": 2.702630743171713e-05,
      "loss": 0.7398,
      "step": 434200
    },
    {
      "epoch": 4.597138486457302,
      "grad_norm": 4.47206449508667,
      "learning_rate": 2.702366080880796e-05,
      "loss": 0.7423,
      "step": 434250
    },
    {
      "epoch": 4.597667808237306,
      "grad_norm": 4.177111625671387,
      "learning_rate": 2.7021014185898798e-05,
      "loss": 0.7307,
      "step": 434300
    },
    {
      "epoch": 4.598197130017309,
      "grad_norm": 4.076548099517822,
      "learning_rate": 2.701836756298963e-05,
      "loss": 0.7407,
      "step": 434350
    },
    {
      "epoch": 4.598726451797312,
      "grad_norm": 4.3097825050354,
      "learning_rate": 2.701572094008046e-05,
      "loss": 0.7445,
      "step": 434400
    },
    {
      "epoch": 4.599255773577315,
      "grad_norm": 4.123270511627197,
      "learning_rate": 2.701307431717129e-05,
      "loss": 0.7483,
      "step": 434450
    },
    {
      "epoch": 4.599785095357319,
      "grad_norm": 4.1429829597473145,
      "learning_rate": 2.7010427694262124e-05,
      "loss": 0.7288,
      "step": 434500
    },
    {
      "epoch": 4.599785095357319,
      "eval_loss": 0.498078852891922,
      "eval_runtime": 47.452,
      "eval_samples_per_second": 3538.948,
      "eval_steps_per_second": 442.384,
      "step": 434500
    },
    {
      "epoch": 4.600314417137322,
      "grad_norm": 4.320498943328857,
      "learning_rate": 2.7007781071352955e-05,
      "loss": 0.7485,
      "step": 434550
    },
    {
      "epoch": 4.600843738917325,
      "grad_norm": 4.044730186462402,
      "learning_rate": 2.7005134448443786e-05,
      "loss": 0.7487,
      "step": 434600
    },
    {
      "epoch": 4.601373060697329,
      "grad_norm": 4.23057222366333,
      "learning_rate": 2.7002487825534616e-05,
      "loss": 0.7344,
      "step": 434650
    },
    {
      "epoch": 4.6019023824773315,
      "grad_norm": 3.8821921348571777,
      "learning_rate": 2.6999841202625454e-05,
      "loss": 0.7343,
      "step": 434700
    },
    {
      "epoch": 4.602431704257335,
      "grad_norm": 4.277008056640625,
      "learning_rate": 2.6997194579716284e-05,
      "loss": 0.7412,
      "step": 434750
    },
    {
      "epoch": 4.602961026037338,
      "grad_norm": 4.302285194396973,
      "learning_rate": 2.6994547956807115e-05,
      "loss": 0.7254,
      "step": 434800
    },
    {
      "epoch": 4.603490347817342,
      "grad_norm": 4.278244972229004,
      "learning_rate": 2.6991901333897946e-05,
      "loss": 0.7497,
      "step": 434850
    },
    {
      "epoch": 4.604019669597345,
      "grad_norm": 4.2142863273620605,
      "learning_rate": 2.698925471098878e-05,
      "loss": 0.7372,
      "step": 434900
    },
    {
      "epoch": 4.6045489913773485,
      "grad_norm": 3.767340660095215,
      "learning_rate": 2.698660808807961e-05,
      "loss": 0.7389,
      "step": 434950
    },
    {
      "epoch": 4.605078313157351,
      "grad_norm": 3.608029365539551,
      "learning_rate": 2.698396146517044e-05,
      "loss": 0.7293,
      "step": 435000
    },
    {
      "epoch": 4.605078313157351,
      "eval_loss": 0.4969249665737152,
      "eval_runtime": 46.777,
      "eval_samples_per_second": 3590.01,
      "eval_steps_per_second": 448.767,
      "step": 435000
    },
    {
      "epoch": 4.605607634937355,
      "grad_norm": 4.075376987457275,
      "learning_rate": 2.6981314842261272e-05,
      "loss": 0.7436,
      "step": 435050
    },
    {
      "epoch": 4.606136956717358,
      "grad_norm": 4.240853309631348,
      "learning_rate": 2.697866821935211e-05,
      "loss": 0.7314,
      "step": 435100
    },
    {
      "epoch": 4.606666278497361,
      "grad_norm": 4.075717926025391,
      "learning_rate": 2.697602159644294e-05,
      "loss": 0.7433,
      "step": 435150
    },
    {
      "epoch": 4.607195600277365,
      "grad_norm": 4.088070392608643,
      "learning_rate": 2.697337497353377e-05,
      "loss": 0.7381,
      "step": 435200
    },
    {
      "epoch": 4.607724922057368,
      "grad_norm": 4.1410112380981445,
      "learning_rate": 2.6970728350624602e-05,
      "loss": 0.7417,
      "step": 435250
    },
    {
      "epoch": 4.608254243837371,
      "grad_norm": 4.010412693023682,
      "learning_rate": 2.696808172771544e-05,
      "loss": 0.7465,
      "step": 435300
    },
    {
      "epoch": 4.608783565617374,
      "grad_norm": 3.6342878341674805,
      "learning_rate": 2.6965488037264454e-05,
      "loss": 0.7326,
      "step": 435350
    },
    {
      "epoch": 4.609312887397378,
      "grad_norm": 4.539391994476318,
      "learning_rate": 2.6962841414355285e-05,
      "loss": 0.7317,
      "step": 435400
    },
    {
      "epoch": 4.609842209177381,
      "grad_norm": 4.523758411407471,
      "learning_rate": 2.6960194791446115e-05,
      "loss": 0.7479,
      "step": 435450
    },
    {
      "epoch": 4.6103715309573845,
      "grad_norm": 4.264470100402832,
      "learning_rate": 2.695754816853695e-05,
      "loss": 0.7349,
      "step": 435500
    },
    {
      "epoch": 4.6103715309573845,
      "eval_loss": 0.49623340368270874,
      "eval_runtime": 46.6584,
      "eval_samples_per_second": 3599.136,
      "eval_steps_per_second": 449.908,
      "step": 435500
    },
    {
      "epoch": 4.610900852737387,
      "grad_norm": 4.411721229553223,
      "learning_rate": 2.695490154562778e-05,
      "loss": 0.747,
      "step": 435550
    },
    {
      "epoch": 4.611430174517391,
      "grad_norm": 4.540379047393799,
      "learning_rate": 2.695225492271861e-05,
      "loss": 0.7289,
      "step": 435600
    },
    {
      "epoch": 4.611959496297394,
      "grad_norm": 3.800672769546509,
      "learning_rate": 2.694960829980944e-05,
      "loss": 0.7395,
      "step": 435650
    },
    {
      "epoch": 4.612488818077398,
      "grad_norm": 4.220618724822998,
      "learning_rate": 2.694696167690028e-05,
      "loss": 0.738,
      "step": 435700
    },
    {
      "epoch": 4.613018139857401,
      "grad_norm": 4.886682033538818,
      "learning_rate": 2.694431505399111e-05,
      "loss": 0.7507,
      "step": 435750
    },
    {
      "epoch": 4.613547461637404,
      "grad_norm": 4.4259161949157715,
      "learning_rate": 2.694166843108194e-05,
      "loss": 0.7328,
      "step": 435800
    },
    {
      "epoch": 4.614076783417407,
      "grad_norm": 4.116363525390625,
      "learning_rate": 2.693902180817277e-05,
      "loss": 0.7145,
      "step": 435850
    },
    {
      "epoch": 4.61460610519741,
      "grad_norm": 4.463421821594238,
      "learning_rate": 2.6936375185263605e-05,
      "loss": 0.7357,
      "step": 435900
    },
    {
      "epoch": 4.615135426977414,
      "grad_norm": 4.847713947296143,
      "learning_rate": 2.6933728562354436e-05,
      "loss": 0.7474,
      "step": 435950
    },
    {
      "epoch": 4.615664748757418,
      "grad_norm": 4.266323089599609,
      "learning_rate": 2.693108193944527e-05,
      "loss": 0.7479,
      "step": 436000
    },
    {
      "epoch": 4.615664748757418,
      "eval_loss": 0.4952620565891266,
      "eval_runtime": 46.5471,
      "eval_samples_per_second": 3607.741,
      "eval_steps_per_second": 450.984,
      "step": 436000
    },
    {
      "epoch": 4.6161940705374205,
      "grad_norm": 4.433374881744385,
      "learning_rate": 2.69284353165361e-05,
      "loss": 0.7383,
      "step": 436050
    },
    {
      "epoch": 4.616723392317423,
      "grad_norm": 4.564351558685303,
      "learning_rate": 2.6925788693626935e-05,
      "loss": 0.7477,
      "step": 436100
    },
    {
      "epoch": 4.617252714097427,
      "grad_norm": 4.225516319274902,
      "learning_rate": 2.6923142070717766e-05,
      "loss": 0.7389,
      "step": 436150
    },
    {
      "epoch": 4.61778203587743,
      "grad_norm": 4.256927013397217,
      "learning_rate": 2.6920495447808596e-05,
      "loss": 0.7503,
      "step": 436200
    },
    {
      "epoch": 4.618311357657434,
      "grad_norm": 4.181281089782715,
      "learning_rate": 2.6917848824899427e-05,
      "loss": 0.7432,
      "step": 436250
    },
    {
      "epoch": 4.618840679437437,
      "grad_norm": 4.10849142074585,
      "learning_rate": 2.6915202201990265e-05,
      "loss": 0.7455,
      "step": 436300
    },
    {
      "epoch": 4.61937000121744,
      "grad_norm": 4.298656940460205,
      "learning_rate": 2.6912555579081095e-05,
      "loss": 0.7477,
      "step": 436350
    },
    {
      "epoch": 4.619899322997443,
      "grad_norm": 4.418222904205322,
      "learning_rate": 2.6909908956171926e-05,
      "loss": 0.7416,
      "step": 436400
    },
    {
      "epoch": 4.620428644777447,
      "grad_norm": 4.071845054626465,
      "learning_rate": 2.6907262333262757e-05,
      "loss": 0.7512,
      "step": 436450
    },
    {
      "epoch": 4.62095796655745,
      "grad_norm": 4.368199825286865,
      "learning_rate": 2.690461571035359e-05,
      "loss": 0.7455,
      "step": 436500
    },
    {
      "epoch": 4.62095796655745,
      "eval_loss": 0.496925950050354,
      "eval_runtime": 46.5721,
      "eval_samples_per_second": 3605.808,
      "eval_steps_per_second": 450.742,
      "step": 436500
    },
    {
      "epoch": 4.621487288337454,
      "grad_norm": 4.404365062713623,
      "learning_rate": 2.690196908744442e-05,
      "loss": 0.7342,
      "step": 436550
    },
    {
      "epoch": 4.6220166101174565,
      "grad_norm": 4.135206699371338,
      "learning_rate": 2.6899322464535252e-05,
      "loss": 0.7478,
      "step": 436600
    },
    {
      "epoch": 4.622545931897459,
      "grad_norm": 4.420474529266357,
      "learning_rate": 2.6896675841626083e-05,
      "loss": 0.7505,
      "step": 436650
    },
    {
      "epoch": 4.623075253677463,
      "grad_norm": 4.611835956573486,
      "learning_rate": 2.689402921871692e-05,
      "loss": 0.7484,
      "step": 436700
    },
    {
      "epoch": 4.623604575457467,
      "grad_norm": 4.319197177886963,
      "learning_rate": 2.689138259580775e-05,
      "loss": 0.7429,
      "step": 436750
    },
    {
      "epoch": 4.62413389723747,
      "grad_norm": 4.563014030456543,
      "learning_rate": 2.6888735972898582e-05,
      "loss": 0.7316,
      "step": 436800
    },
    {
      "epoch": 4.624663219017473,
      "grad_norm": 4.543796539306641,
      "learning_rate": 2.6886089349989413e-05,
      "loss": 0.7384,
      "step": 436850
    },
    {
      "epoch": 4.625192540797476,
      "grad_norm": 4.246028900146484,
      "learning_rate": 2.688344272708025e-05,
      "loss": 0.7407,
      "step": 436900
    },
    {
      "epoch": 4.625721862577479,
      "grad_norm": 4.506919860839844,
      "learning_rate": 2.688079610417108e-05,
      "loss": 0.7253,
      "step": 436950
    },
    {
      "epoch": 4.626251184357483,
      "grad_norm": 4.488630294799805,
      "learning_rate": 2.687814948126191e-05,
      "loss": 0.7366,
      "step": 437000
    },
    {
      "epoch": 4.626251184357483,
      "eval_loss": 0.49562782049179077,
      "eval_runtime": 46.5327,
      "eval_samples_per_second": 3608.861,
      "eval_steps_per_second": 451.124,
      "step": 437000
    },
    {
      "epoch": 4.626780506137486,
      "grad_norm": 4.267319679260254,
      "learning_rate": 2.6875502858352742e-05,
      "loss": 0.7447,
      "step": 437050
    },
    {
      "epoch": 4.62730982791749,
      "grad_norm": 4.010159015655518,
      "learning_rate": 2.6872856235443576e-05,
      "loss": 0.7474,
      "step": 437100
    },
    {
      "epoch": 4.627839149697492,
      "grad_norm": 3.9900944232940674,
      "learning_rate": 2.6870209612534407e-05,
      "loss": 0.7253,
      "step": 437150
    },
    {
      "epoch": 4.628368471477496,
      "grad_norm": 4.3417158126831055,
      "learning_rate": 2.6867562989625238e-05,
      "loss": 0.7357,
      "step": 437200
    },
    {
      "epoch": 4.628897793257499,
      "grad_norm": 4.525546550750732,
      "learning_rate": 2.686491636671607e-05,
      "loss": 0.7425,
      "step": 437250
    },
    {
      "epoch": 4.629427115037503,
      "grad_norm": 4.538339614868164,
      "learning_rate": 2.6862269743806906e-05,
      "loss": 0.7424,
      "step": 437300
    },
    {
      "epoch": 4.629956436817506,
      "grad_norm": 4.148224830627441,
      "learning_rate": 2.685967605335592e-05,
      "loss": 0.7405,
      "step": 437350
    },
    {
      "epoch": 4.6304857585975085,
      "grad_norm": 4.181319236755371,
      "learning_rate": 2.685702943044675e-05,
      "loss": 0.7457,
      "step": 437400
    },
    {
      "epoch": 4.631015080377512,
      "grad_norm": 3.905961751937866,
      "learning_rate": 2.6854382807537582e-05,
      "loss": 0.7347,
      "step": 437450
    },
    {
      "epoch": 4.631544402157516,
      "grad_norm": 4.43700647354126,
      "learning_rate": 2.6851736184628416e-05,
      "loss": 0.74,
      "step": 437500
    },
    {
      "epoch": 4.631544402157516,
      "eval_loss": 0.49465280771255493,
      "eval_runtime": 46.9332,
      "eval_samples_per_second": 3578.065,
      "eval_steps_per_second": 447.274,
      "step": 437500
    },
    {
      "epoch": 4.632073723937519,
      "grad_norm": 4.47034215927124,
      "learning_rate": 2.6849089561719247e-05,
      "loss": 0.7195,
      "step": 437550
    },
    {
      "epoch": 4.632603045717522,
      "grad_norm": 4.593043327331543,
      "learning_rate": 2.6846442938810078e-05,
      "loss": 0.7352,
      "step": 437600
    },
    {
      "epoch": 4.6331323674975255,
      "grad_norm": 4.342480659484863,
      "learning_rate": 2.6843796315900908e-05,
      "loss": 0.7391,
      "step": 437650
    },
    {
      "epoch": 4.633661689277528,
      "grad_norm": 4.165383815765381,
      "learning_rate": 2.6841149692991746e-05,
      "loss": 0.744,
      "step": 437700
    },
    {
      "epoch": 4.634191011057532,
      "grad_norm": 3.9450125694274902,
      "learning_rate": 2.6838503070082577e-05,
      "loss": 0.7419,
      "step": 437750
    },
    {
      "epoch": 4.634720332837535,
      "grad_norm": 4.225545883178711,
      "learning_rate": 2.6835856447173407e-05,
      "loss": 0.7463,
      "step": 437800
    },
    {
      "epoch": 4.635249654617539,
      "grad_norm": 4.278335094451904,
      "learning_rate": 2.6833209824264238e-05,
      "loss": 0.7354,
      "step": 437850
    },
    {
      "epoch": 4.635778976397542,
      "grad_norm": 4.149316787719727,
      "learning_rate": 2.6830563201355075e-05,
      "loss": 0.7507,
      "step": 437900
    },
    {
      "epoch": 4.636308298177545,
      "grad_norm": 4.0605268478393555,
      "learning_rate": 2.6827916578445906e-05,
      "loss": 0.7493,
      "step": 437950
    },
    {
      "epoch": 4.636837619957548,
      "grad_norm": 3.777338743209839,
      "learning_rate": 2.6825269955536737e-05,
      "loss": 0.7318,
      "step": 438000
    },
    {
      "epoch": 4.636837619957548,
      "eval_loss": 0.49434348940849304,
      "eval_runtime": 46.5375,
      "eval_samples_per_second": 3608.485,
      "eval_steps_per_second": 451.077,
      "step": 438000
    },
    {
      "epoch": 4.637366941737552,
      "grad_norm": 4.071371555328369,
      "learning_rate": 2.6822623332627568e-05,
      "loss": 0.7304,
      "step": 438050
    },
    {
      "epoch": 4.637896263517555,
      "grad_norm": 4.266625881195068,
      "learning_rate": 2.68199767097184e-05,
      "loss": 0.7299,
      "step": 438100
    },
    {
      "epoch": 4.638425585297558,
      "grad_norm": 4.219767093658447,
      "learning_rate": 2.6817330086809232e-05,
      "loss": 0.7312,
      "step": 438150
    },
    {
      "epoch": 4.6389549070775615,
      "grad_norm": 4.259822845458984,
      "learning_rate": 2.6814683463900063e-05,
      "loss": 0.7288,
      "step": 438200
    },
    {
      "epoch": 4.639484228857565,
      "grad_norm": 4.391718864440918,
      "learning_rate": 2.6812036840990894e-05,
      "loss": 0.7371,
      "step": 438250
    },
    {
      "epoch": 4.640013550637568,
      "grad_norm": 4.179922103881836,
      "learning_rate": 2.680939021808173e-05,
      "loss": 0.7391,
      "step": 438300
    },
    {
      "epoch": 4.640542872417571,
      "grad_norm": 4.12585973739624,
      "learning_rate": 2.6806743595172562e-05,
      "loss": 0.7398,
      "step": 438350
    },
    {
      "epoch": 4.641072194197575,
      "grad_norm": 4.644295692443848,
      "learning_rate": 2.6804096972263393e-05,
      "loss": 0.7434,
      "step": 438400
    },
    {
      "epoch": 4.641601515977578,
      "grad_norm": 4.170454025268555,
      "learning_rate": 2.6801450349354223e-05,
      "loss": 0.7431,
      "step": 438450
    },
    {
      "epoch": 4.642130837757581,
      "grad_norm": 3.980926990509033,
      "learning_rate": 2.679880372644506e-05,
      "loss": 0.7506,
      "step": 438500
    },
    {
      "epoch": 4.642130837757581,
      "eval_loss": 0.49337729811668396,
      "eval_runtime": 46.6268,
      "eval_samples_per_second": 3601.578,
      "eval_steps_per_second": 450.213,
      "step": 438500
    },
    {
      "epoch": 4.642660159537584,
      "grad_norm": 4.5191426277160645,
      "learning_rate": 2.679615710353589e-05,
      "loss": 0.7427,
      "step": 438550
    },
    {
      "epoch": 4.643189481317588,
      "grad_norm": 4.427475452423096,
      "learning_rate": 2.6793510480626722e-05,
      "loss": 0.7466,
      "step": 438600
    },
    {
      "epoch": 4.643718803097591,
      "grad_norm": 4.344703674316406,
      "learning_rate": 2.6790863857717553e-05,
      "loss": 0.7305,
      "step": 438650
    },
    {
      "epoch": 4.644248124877595,
      "grad_norm": 4.002524375915527,
      "learning_rate": 2.6788217234808387e-05,
      "loss": 0.7381,
      "step": 438700
    },
    {
      "epoch": 4.6447774466575975,
      "grad_norm": 4.043854713439941,
      "learning_rate": 2.6785570611899218e-05,
      "loss": 0.7406,
      "step": 438750
    },
    {
      "epoch": 4.645306768437601,
      "grad_norm": 3.999417304992676,
      "learning_rate": 2.678292398899005e-05,
      "loss": 0.7288,
      "step": 438800
    },
    {
      "epoch": 4.645836090217604,
      "grad_norm": 4.049194812774658,
      "learning_rate": 2.678027736608088e-05,
      "loss": 0.7303,
      "step": 438850
    },
    {
      "epoch": 4.646365411997607,
      "grad_norm": 4.500842094421387,
      "learning_rate": 2.6777630743171717e-05,
      "loss": 0.7348,
      "step": 438900
    },
    {
      "epoch": 4.646894733777611,
      "grad_norm": 4.282612323760986,
      "learning_rate": 2.6774984120262547e-05,
      "loss": 0.7412,
      "step": 438950
    },
    {
      "epoch": 4.6474240555576145,
      "grad_norm": 4.344794750213623,
      "learning_rate": 2.6772337497353378e-05,
      "loss": 0.7372,
      "step": 439000
    },
    {
      "epoch": 4.6474240555576145,
      "eval_loss": 0.4938173294067383,
      "eval_runtime": 46.616,
      "eval_samples_per_second": 3602.407,
      "eval_steps_per_second": 450.317,
      "step": 439000
    },
    {
      "epoch": 4.647953377337617,
      "grad_norm": 4.277637958526611,
      "learning_rate": 2.676969087444421e-05,
      "loss": 0.7319,
      "step": 439050
    },
    {
      "epoch": 4.64848269911762,
      "grad_norm": 3.8018176555633545,
      "learning_rate": 2.6767044251535046e-05,
      "loss": 0.7391,
      "step": 439100
    },
    {
      "epoch": 4.649012020897624,
      "grad_norm": 3.952285051345825,
      "learning_rate": 2.6764397628625877e-05,
      "loss": 0.7382,
      "step": 439150
    },
    {
      "epoch": 4.649541342677627,
      "grad_norm": 4.401415824890137,
      "learning_rate": 2.6761751005716708e-05,
      "loss": 0.741,
      "step": 439200
    },
    {
      "epoch": 4.650070664457631,
      "grad_norm": 4.356426239013672,
      "learning_rate": 2.675910438280754e-05,
      "loss": 0.7323,
      "step": 439250
    },
    {
      "epoch": 4.6505999862376335,
      "grad_norm": 3.943804979324341,
      "learning_rate": 2.6756457759898373e-05,
      "loss": 0.7366,
      "step": 439300
    },
    {
      "epoch": 4.651129308017637,
      "grad_norm": 4.516475200653076,
      "learning_rate": 2.6753864069447387e-05,
      "loss": 0.7281,
      "step": 439350
    },
    {
      "epoch": 4.65165862979764,
      "grad_norm": 4.63798713684082,
      "learning_rate": 2.6751217446538218e-05,
      "loss": 0.7423,
      "step": 439400
    },
    {
      "epoch": 4.652187951577644,
      "grad_norm": 4.434606552124023,
      "learning_rate": 2.674857082362905e-05,
      "loss": 0.7561,
      "step": 439450
    },
    {
      "epoch": 4.652717273357647,
      "grad_norm": 3.897212505340576,
      "learning_rate": 2.6745924200719886e-05,
      "loss": 0.7325,
      "step": 439500
    },
    {
      "epoch": 4.652717273357647,
      "eval_loss": 0.49278852343559265,
      "eval_runtime": 46.7689,
      "eval_samples_per_second": 3590.633,
      "eval_steps_per_second": 448.845,
      "step": 439500
    },
    {
      "epoch": 4.6532465951376505,
      "grad_norm": 4.239351749420166,
      "learning_rate": 2.6743277577810717e-05,
      "loss": 0.7439,
      "step": 439550
    },
    {
      "epoch": 4.653775916917653,
      "grad_norm": 3.8009774684906006,
      "learning_rate": 2.6740630954901548e-05,
      "loss": 0.7387,
      "step": 439600
    },
    {
      "epoch": 4.654305238697656,
      "grad_norm": 4.266032695770264,
      "learning_rate": 2.673798433199238e-05,
      "loss": 0.7374,
      "step": 439650
    },
    {
      "epoch": 4.65483456047766,
      "grad_norm": 4.425271987915039,
      "learning_rate": 2.6735337709083212e-05,
      "loss": 0.7289,
      "step": 439700
    },
    {
      "epoch": 4.655363882257664,
      "grad_norm": 4.375113010406494,
      "learning_rate": 2.6732691086174043e-05,
      "loss": 0.7324,
      "step": 439750
    },
    {
      "epoch": 4.655893204037667,
      "grad_norm": 3.9179065227508545,
      "learning_rate": 2.6730044463264874e-05,
      "loss": 0.7249,
      "step": 439800
    },
    {
      "epoch": 4.6564225258176695,
      "grad_norm": 4.415336608886719,
      "learning_rate": 2.6727397840355705e-05,
      "loss": 0.7371,
      "step": 439850
    },
    {
      "epoch": 4.656951847597673,
      "grad_norm": 3.9097306728363037,
      "learning_rate": 2.6724751217446542e-05,
      "loss": 0.7354,
      "step": 439900
    },
    {
      "epoch": 4.657481169377676,
      "grad_norm": 4.513888835906982,
      "learning_rate": 2.6722104594537373e-05,
      "loss": 0.7421,
      "step": 439950
    },
    {
      "epoch": 4.65801049115768,
      "grad_norm": 4.376378536224365,
      "learning_rate": 2.6719457971628204e-05,
      "loss": 0.7373,
      "step": 440000
    },
    {
      "epoch": 4.65801049115768,
      "eval_loss": 0.49401402473449707,
      "eval_runtime": 47.1463,
      "eval_samples_per_second": 3561.891,
      "eval_steps_per_second": 445.252,
      "step": 440000
    },
    {
      "epoch": 4.658539812937683,
      "grad_norm": 3.8175063133239746,
      "learning_rate": 2.6716811348719034e-05,
      "loss": 0.732,
      "step": 440050
    },
    {
      "epoch": 4.6590691347176865,
      "grad_norm": 4.28844690322876,
      "learning_rate": 2.6714164725809872e-05,
      "loss": 0.7476,
      "step": 440100
    },
    {
      "epoch": 4.659598456497689,
      "grad_norm": 3.9595577716827393,
      "learning_rate": 2.6711518102900702e-05,
      "loss": 0.7306,
      "step": 440150
    },
    {
      "epoch": 4.660127778277693,
      "grad_norm": 4.789488792419434,
      "learning_rate": 2.6708871479991533e-05,
      "loss": 0.7601,
      "step": 440200
    },
    {
      "epoch": 4.660657100057696,
      "grad_norm": 4.2217607498168945,
      "learning_rate": 2.6706224857082364e-05,
      "loss": 0.7436,
      "step": 440250
    },
    {
      "epoch": 4.6611864218377,
      "grad_norm": 4.620652675628662,
      "learning_rate": 2.6703578234173198e-05,
      "loss": 0.7397,
      "step": 440300
    },
    {
      "epoch": 4.661715743617703,
      "grad_norm": 3.985529899597168,
      "learning_rate": 2.670093161126403e-05,
      "loss": 0.7567,
      "step": 440350
    },
    {
      "epoch": 4.6622450653977054,
      "grad_norm": 4.389235019683838,
      "learning_rate": 2.669828498835486e-05,
      "loss": 0.7251,
      "step": 440400
    },
    {
      "epoch": 4.662774387177709,
      "grad_norm": 4.487223148345947,
      "learning_rate": 2.669563836544569e-05,
      "loss": 0.7417,
      "step": 440450
    },
    {
      "epoch": 4.663303708957713,
      "grad_norm": 4.217310905456543,
      "learning_rate": 2.6692991742536528e-05,
      "loss": 0.7361,
      "step": 440500
    },
    {
      "epoch": 4.663303708957713,
      "eval_loss": 0.49264708161354065,
      "eval_runtime": 47.3171,
      "eval_samples_per_second": 3549.031,
      "eval_steps_per_second": 443.645,
      "step": 440500
    },
    {
      "epoch": 4.663833030737716,
      "grad_norm": 4.31278657913208,
      "learning_rate": 2.6690345119627358e-05,
      "loss": 0.7138,
      "step": 440550
    },
    {
      "epoch": 4.664362352517719,
      "grad_norm": 4.252835750579834,
      "learning_rate": 2.668769849671819e-05,
      "loss": 0.7355,
      "step": 440600
    },
    {
      "epoch": 4.6648916742977224,
      "grad_norm": 4.838312149047852,
      "learning_rate": 2.668505187380902e-05,
      "loss": 0.7369,
      "step": 440650
    },
    {
      "epoch": 4.665420996077725,
      "grad_norm": 4.250983715057373,
      "learning_rate": 2.6682405250899857e-05,
      "loss": 0.7269,
      "step": 440700
    },
    {
      "epoch": 4.665950317857729,
      "grad_norm": 4.185174942016602,
      "learning_rate": 2.6679758627990688e-05,
      "loss": 0.7304,
      "step": 440750
    },
    {
      "epoch": 4.666479639637732,
      "grad_norm": 4.596981048583984,
      "learning_rate": 2.667711200508152e-05,
      "loss": 0.7455,
      "step": 440800
    },
    {
      "epoch": 4.667008961417736,
      "grad_norm": 4.2471394538879395,
      "learning_rate": 2.667446538217235e-05,
      "loss": 0.734,
      "step": 440850
    },
    {
      "epoch": 4.667538283197739,
      "grad_norm": 4.801558494567871,
      "learning_rate": 2.6671818759263183e-05,
      "loss": 0.7523,
      "step": 440900
    },
    {
      "epoch": 4.668067604977742,
      "grad_norm": 4.134949684143066,
      "learning_rate": 2.6669172136354014e-05,
      "loss": 0.7388,
      "step": 440950
    },
    {
      "epoch": 4.668596926757745,
      "grad_norm": 4.1648993492126465,
      "learning_rate": 2.6666525513444845e-05,
      "loss": 0.742,
      "step": 441000
    },
    {
      "epoch": 4.668596926757745,
      "eval_loss": 0.494260311126709,
      "eval_runtime": 46.9646,
      "eval_samples_per_second": 3575.672,
      "eval_steps_per_second": 446.975,
      "step": 441000
    },
    {
      "epoch": 4.669126248537749,
      "grad_norm": 4.192338943481445,
      "learning_rate": 2.6663878890535676e-05,
      "loss": 0.7292,
      "step": 441050
    },
    {
      "epoch": 4.669655570317752,
      "grad_norm": 4.213037490844727,
      "learning_rate": 2.6661232267626513e-05,
      "loss": 0.7416,
      "step": 441100
    },
    {
      "epoch": 4.670184892097755,
      "grad_norm": 4.369813442230225,
      "learning_rate": 2.6658585644717344e-05,
      "loss": 0.7342,
      "step": 441150
    },
    {
      "epoch": 4.670714213877758,
      "grad_norm": 3.983948230743408,
      "learning_rate": 2.6655939021808174e-05,
      "loss": 0.7389,
      "step": 441200
    },
    {
      "epoch": 4.671243535657762,
      "grad_norm": 4.301532745361328,
      "learning_rate": 2.6653292398899005e-05,
      "loss": 0.7269,
      "step": 441250
    },
    {
      "epoch": 4.671772857437765,
      "grad_norm": 4.043866157531738,
      "learning_rate": 2.665064577598984e-05,
      "loss": 0.7292,
      "step": 441300
    },
    {
      "epoch": 4.672302179217768,
      "grad_norm": 4.543252944946289,
      "learning_rate": 2.6648052085538854e-05,
      "loss": 0.7332,
      "step": 441350
    },
    {
      "epoch": 4.672831500997772,
      "grad_norm": 4.124171733856201,
      "learning_rate": 2.6645405462629685e-05,
      "loss": 0.7323,
      "step": 441400
    },
    {
      "epoch": 4.6733608227777745,
      "grad_norm": 4.297388076782227,
      "learning_rate": 2.6642758839720515e-05,
      "loss": 0.7353,
      "step": 441450
    },
    {
      "epoch": 4.673890144557778,
      "grad_norm": 4.482399940490723,
      "learning_rate": 2.6640112216811353e-05,
      "loss": 0.7368,
      "step": 441500
    },
    {
      "epoch": 4.673890144557778,
      "eval_loss": 0.49220117926597595,
      "eval_runtime": 47.1141,
      "eval_samples_per_second": 3564.327,
      "eval_steps_per_second": 445.557,
      "step": 441500
    },
    {
      "epoch": 4.674419466337781,
      "grad_norm": 4.179230690002441,
      "learning_rate": 2.6637465593902184e-05,
      "loss": 0.7294,
      "step": 441550
    },
    {
      "epoch": 4.674948788117785,
      "grad_norm": 4.1898417472839355,
      "learning_rate": 2.6634818970993014e-05,
      "loss": 0.7293,
      "step": 441600
    },
    {
      "epoch": 4.675478109897788,
      "grad_norm": 4.115106105804443,
      "learning_rate": 2.6632172348083845e-05,
      "loss": 0.7417,
      "step": 441650
    },
    {
      "epoch": 4.6760074316777915,
      "grad_norm": 4.168796539306641,
      "learning_rate": 2.6629525725174683e-05,
      "loss": 0.733,
      "step": 441700
    },
    {
      "epoch": 4.676536753457794,
      "grad_norm": 4.0099053382873535,
      "learning_rate": 2.6626879102265513e-05,
      "loss": 0.7337,
      "step": 441750
    },
    {
      "epoch": 4.677066075237798,
      "grad_norm": 4.033756732940674,
      "learning_rate": 2.6624232479356344e-05,
      "loss": 0.7314,
      "step": 441800
    },
    {
      "epoch": 4.677595397017801,
      "grad_norm": 4.253225803375244,
      "learning_rate": 2.6621585856447175e-05,
      "loss": 0.7264,
      "step": 441850
    },
    {
      "epoch": 4.678124718797804,
      "grad_norm": 4.392378807067871,
      "learning_rate": 2.661893923353801e-05,
      "loss": 0.7425,
      "step": 441900
    },
    {
      "epoch": 4.678654040577808,
      "grad_norm": 4.061695098876953,
      "learning_rate": 2.661629261062884e-05,
      "loss": 0.7484,
      "step": 441950
    },
    {
      "epoch": 4.679183362357811,
      "grad_norm": 4.244382858276367,
      "learning_rate": 2.661364598771967e-05,
      "loss": 0.7265,
      "step": 442000
    },
    {
      "epoch": 4.679183362357811,
      "eval_loss": 0.49330976605415344,
      "eval_runtime": 46.8971,
      "eval_samples_per_second": 3580.817,
      "eval_steps_per_second": 447.618,
      "step": 442000
    },
    {
      "epoch": 4.679712684137814,
      "grad_norm": 4.1037068367004395,
      "learning_rate": 2.66109993648105e-05,
      "loss": 0.7345,
      "step": 442050
    },
    {
      "epoch": 4.680242005917817,
      "grad_norm": 4.1349005699157715,
      "learning_rate": 2.660835274190134e-05,
      "loss": 0.7387,
      "step": 442100
    },
    {
      "epoch": 4.680771327697821,
      "grad_norm": 4.392893314361572,
      "learning_rate": 2.660570611899217e-05,
      "loss": 0.7435,
      "step": 442150
    },
    {
      "epoch": 4.681300649477824,
      "grad_norm": 4.111293792724609,
      "learning_rate": 2.6603059496083e-05,
      "loss": 0.7335,
      "step": 442200
    },
    {
      "epoch": 4.6818299712578275,
      "grad_norm": 3.886784791946411,
      "learning_rate": 2.660041287317383e-05,
      "loss": 0.7394,
      "step": 442250
    },
    {
      "epoch": 4.68235929303783,
      "grad_norm": 4.243985652923584,
      "learning_rate": 2.6597766250264665e-05,
      "loss": 0.7439,
      "step": 442300
    },
    {
      "epoch": 4.682888614817834,
      "grad_norm": 4.497260570526123,
      "learning_rate": 2.6595119627355495e-05,
      "loss": 0.7388,
      "step": 442350
    },
    {
      "epoch": 4.683417936597837,
      "grad_norm": 4.389547824859619,
      "learning_rate": 2.6592473004446326e-05,
      "loss": 0.7485,
      "step": 442400
    },
    {
      "epoch": 4.683947258377841,
      "grad_norm": 4.54019832611084,
      "learning_rate": 2.6589826381537157e-05,
      "loss": 0.7495,
      "step": 442450
    },
    {
      "epoch": 4.684476580157844,
      "grad_norm": 4.640531539916992,
      "learning_rate": 2.6587179758627994e-05,
      "loss": 0.744,
      "step": 442500
    },
    {
      "epoch": 4.684476580157844,
      "eval_loss": 0.4930291473865509,
      "eval_runtime": 47.127,
      "eval_samples_per_second": 3563.347,
      "eval_steps_per_second": 445.434,
      "step": 442500
    },
    {
      "epoch": 4.685005901937847,
      "grad_norm": 4.428846836090088,
      "learning_rate": 2.6584533135718825e-05,
      "loss": 0.7443,
      "step": 442550
    },
    {
      "epoch": 4.68553522371785,
      "grad_norm": 4.336357593536377,
      "learning_rate": 2.6581886512809656e-05,
      "loss": 0.74,
      "step": 442600
    },
    {
      "epoch": 4.686064545497853,
      "grad_norm": 4.124919891357422,
      "learning_rate": 2.6579239889900486e-05,
      "loss": 0.7462,
      "step": 442650
    },
    {
      "epoch": 4.686593867277857,
      "grad_norm": 4.652214050292969,
      "learning_rate": 2.6576593266991324e-05,
      "loss": 0.7328,
      "step": 442700
    },
    {
      "epoch": 4.687123189057861,
      "grad_norm": 3.845278024673462,
      "learning_rate": 2.6573946644082155e-05,
      "loss": 0.7479,
      "step": 442750
    },
    {
      "epoch": 4.6876525108378635,
      "grad_norm": 3.9462804794311523,
      "learning_rate": 2.6571300021172985e-05,
      "loss": 0.7281,
      "step": 442800
    },
    {
      "epoch": 4.688181832617866,
      "grad_norm": 4.57218074798584,
      "learning_rate": 2.6568653398263816e-05,
      "loss": 0.7295,
      "step": 442850
    },
    {
      "epoch": 4.68871115439787,
      "grad_norm": 4.0442585945129395,
      "learning_rate": 2.6566006775354647e-05,
      "loss": 0.7335,
      "step": 442900
    },
    {
      "epoch": 4.689240476177873,
      "grad_norm": 3.9750373363494873,
      "learning_rate": 2.656336015244548e-05,
      "loss": 0.7446,
      "step": 442950
    },
    {
      "epoch": 4.689769797957877,
      "grad_norm": 4.263753414154053,
      "learning_rate": 2.656071352953631e-05,
      "loss": 0.7387,
      "step": 443000
    },
    {
      "epoch": 4.689769797957877,
      "eval_loss": 0.49282756447792053,
      "eval_runtime": 46.9667,
      "eval_samples_per_second": 3575.514,
      "eval_steps_per_second": 446.955,
      "step": 443000
    },
    {
      "epoch": 4.69029911973788,
      "grad_norm": 4.117664337158203,
      "learning_rate": 2.6558066906627142e-05,
      "loss": 0.7382,
      "step": 443050
    },
    {
      "epoch": 4.690828441517883,
      "grad_norm": 4.11110258102417,
      "learning_rate": 2.6555420283717973e-05,
      "loss": 0.7362,
      "step": 443100
    },
    {
      "epoch": 4.691357763297886,
      "grad_norm": 4.253312110900879,
      "learning_rate": 2.655277366080881e-05,
      "loss": 0.7301,
      "step": 443150
    },
    {
      "epoch": 4.69188708507789,
      "grad_norm": 4.240919589996338,
      "learning_rate": 2.655012703789964e-05,
      "loss": 0.7368,
      "step": 443200
    },
    {
      "epoch": 4.692416406857893,
      "grad_norm": 4.400846004486084,
      "learning_rate": 2.6547480414990472e-05,
      "loss": 0.7453,
      "step": 443250
    },
    {
      "epoch": 4.692945728637897,
      "grad_norm": 3.86997389793396,
      "learning_rate": 2.6544833792081303e-05,
      "loss": 0.7299,
      "step": 443300
    },
    {
      "epoch": 4.6934750504178995,
      "grad_norm": 4.45782470703125,
      "learning_rate": 2.6542240101630324e-05,
      "loss": 0.7338,
      "step": 443350
    },
    {
      "epoch": 4.694004372197902,
      "grad_norm": 3.821289300918579,
      "learning_rate": 2.6539593478721155e-05,
      "loss": 0.7404,
      "step": 443400
    },
    {
      "epoch": 4.694533693977906,
      "grad_norm": 4.328921794891357,
      "learning_rate": 2.6536946855811985e-05,
      "loss": 0.7421,
      "step": 443450
    },
    {
      "epoch": 4.69506301575791,
      "grad_norm": 4.071142673492432,
      "learning_rate": 2.6534300232902816e-05,
      "loss": 0.7369,
      "step": 443500
    },
    {
      "epoch": 4.69506301575791,
      "eval_loss": 0.4909440875053406,
      "eval_runtime": 46.823,
      "eval_samples_per_second": 3586.487,
      "eval_steps_per_second": 448.327,
      "step": 443500
    },
    {
      "epoch": 4.695592337537913,
      "grad_norm": 4.04467248916626,
      "learning_rate": 2.653165360999365e-05,
      "loss": 0.7299,
      "step": 443550
    },
    {
      "epoch": 4.696121659317916,
      "grad_norm": 4.456148624420166,
      "learning_rate": 2.652900698708448e-05,
      "loss": 0.736,
      "step": 443600
    },
    {
      "epoch": 4.696650981097919,
      "grad_norm": 4.105169773101807,
      "learning_rate": 2.6526360364175312e-05,
      "loss": 0.7378,
      "step": 443650
    },
    {
      "epoch": 4.697180302877922,
      "grad_norm": 4.126476287841797,
      "learning_rate": 2.6523713741266142e-05,
      "loss": 0.7271,
      "step": 443700
    },
    {
      "epoch": 4.697709624657926,
      "grad_norm": 4.09409236907959,
      "learning_rate": 2.652106711835698e-05,
      "loss": 0.7296,
      "step": 443750
    },
    {
      "epoch": 4.698238946437929,
      "grad_norm": 4.265506267547607,
      "learning_rate": 2.651842049544781e-05,
      "loss": 0.7269,
      "step": 443800
    },
    {
      "epoch": 4.698768268217933,
      "grad_norm": 4.3229217529296875,
      "learning_rate": 2.651577387253864e-05,
      "loss": 0.7491,
      "step": 443850
    },
    {
      "epoch": 4.6992975899979355,
      "grad_norm": 3.9086883068084717,
      "learning_rate": 2.6513127249629472e-05,
      "loss": 0.7264,
      "step": 443900
    },
    {
      "epoch": 4.699826911777939,
      "grad_norm": 4.302403450012207,
      "learning_rate": 2.6510480626720306e-05,
      "loss": 0.7404,
      "step": 443950
    },
    {
      "epoch": 4.700356233557942,
      "grad_norm": 4.348088264465332,
      "learning_rate": 2.6507834003811137e-05,
      "loss": 0.7348,
      "step": 444000
    },
    {
      "epoch": 4.700356233557942,
      "eval_loss": 0.4912817180156708,
      "eval_runtime": 46.7581,
      "eval_samples_per_second": 3591.465,
      "eval_steps_per_second": 448.949,
      "step": 444000
    },
    {
      "epoch": 4.700885555337946,
      "grad_norm": 4.391634941101074,
      "learning_rate": 2.6505187380901968e-05,
      "loss": 0.7292,
      "step": 444050
    },
    {
      "epoch": 4.701414877117949,
      "grad_norm": 4.32666540145874,
      "learning_rate": 2.6502540757992798e-05,
      "loss": 0.7497,
      "step": 444100
    },
    {
      "epoch": 4.701944198897952,
      "grad_norm": 4.458240032196045,
      "learning_rate": 2.6499894135083636e-05,
      "loss": 0.7376,
      "step": 444150
    },
    {
      "epoch": 4.702473520677955,
      "grad_norm": 4.153941631317139,
      "learning_rate": 2.6497247512174466e-05,
      "loss": 0.7396,
      "step": 444200
    },
    {
      "epoch": 4.703002842457959,
      "grad_norm": 4.080160617828369,
      "learning_rate": 2.6494600889265297e-05,
      "loss": 0.754,
      "step": 444250
    },
    {
      "epoch": 4.703532164237962,
      "grad_norm": 4.012194633483887,
      "learning_rate": 2.6491954266356128e-05,
      "loss": 0.7339,
      "step": 444300
    },
    {
      "epoch": 4.704061486017965,
      "grad_norm": 4.229933738708496,
      "learning_rate": 2.6489307643446965e-05,
      "loss": 0.7246,
      "step": 444350
    },
    {
      "epoch": 4.704590807797969,
      "grad_norm": 4.520356178283691,
      "learning_rate": 2.6486661020537796e-05,
      "loss": 0.7328,
      "step": 444400
    },
    {
      "epoch": 4.705120129577971,
      "grad_norm": 3.9374475479125977,
      "learning_rate": 2.6484014397628627e-05,
      "loss": 0.7392,
      "step": 444450
    },
    {
      "epoch": 4.705649451357975,
      "grad_norm": 3.9172616004943848,
      "learning_rate": 2.6481367774719458e-05,
      "loss": 0.7288,
      "step": 444500
    },
    {
      "epoch": 4.705649451357975,
      "eval_loss": 0.49197736382484436,
      "eval_runtime": 46.7034,
      "eval_samples_per_second": 3595.67,
      "eval_steps_per_second": 449.475,
      "step": 444500
    },
    {
      "epoch": 4.706178773137978,
      "grad_norm": 4.176132678985596,
      "learning_rate": 2.647872115181029e-05,
      "loss": 0.7256,
      "step": 444550
    },
    {
      "epoch": 4.706708094917982,
      "grad_norm": 4.024293422698975,
      "learning_rate": 2.6476074528901122e-05,
      "loss": 0.7391,
      "step": 444600
    },
    {
      "epoch": 4.707237416697985,
      "grad_norm": 4.031522750854492,
      "learning_rate": 2.6473427905991953e-05,
      "loss": 0.737,
      "step": 444650
    },
    {
      "epoch": 4.707766738477988,
      "grad_norm": 3.989757537841797,
      "learning_rate": 2.6470781283082784e-05,
      "loss": 0.7279,
      "step": 444700
    },
    {
      "epoch": 4.708296060257991,
      "grad_norm": 4.236209869384766,
      "learning_rate": 2.646813466017362e-05,
      "loss": 0.7312,
      "step": 444750
    },
    {
      "epoch": 4.708825382037995,
      "grad_norm": 4.229506492614746,
      "learning_rate": 2.6465488037264452e-05,
      "loss": 0.7259,
      "step": 444800
    },
    {
      "epoch": 4.709354703817998,
      "grad_norm": 4.307563781738281,
      "learning_rate": 2.6462841414355283e-05,
      "loss": 0.742,
      "step": 444850
    },
    {
      "epoch": 4.709884025598001,
      "grad_norm": 4.103868007659912,
      "learning_rate": 2.6460194791446113e-05,
      "loss": 0.7325,
      "step": 444900
    },
    {
      "epoch": 4.7104133473780045,
      "grad_norm": 3.955956220626831,
      "learning_rate": 2.645754816853695e-05,
      "loss": 0.7349,
      "step": 444950
    },
    {
      "epoch": 4.710942669158008,
      "grad_norm": 4.116445541381836,
      "learning_rate": 2.645490154562778e-05,
      "loss": 0.7356,
      "step": 445000
    },
    {
      "epoch": 4.710942669158008,
      "eval_loss": 0.49023282527923584,
      "eval_runtime": 46.6519,
      "eval_samples_per_second": 3599.642,
      "eval_steps_per_second": 449.971,
      "step": 445000
    },
    {
      "epoch": 4.711471990938011,
      "grad_norm": 4.426841735839844,
      "learning_rate": 2.6452254922718612e-05,
      "loss": 0.7444,
      "step": 445050
    },
    {
      "epoch": 4.712001312718014,
      "grad_norm": 4.560309410095215,
      "learning_rate": 2.6449608299809443e-05,
      "loss": 0.7365,
      "step": 445100
    },
    {
      "epoch": 4.712530634498018,
      "grad_norm": 4.23832368850708,
      "learning_rate": 2.6446961676900277e-05,
      "loss": 0.7274,
      "step": 445150
    },
    {
      "epoch": 4.713059956278021,
      "grad_norm": 4.199709415435791,
      "learning_rate": 2.6444315053991108e-05,
      "loss": 0.7449,
      "step": 445200
    },
    {
      "epoch": 4.713589278058024,
      "grad_norm": 4.429864406585693,
      "learning_rate": 2.644166843108194e-05,
      "loss": 0.7322,
      "step": 445250
    },
    {
      "epoch": 4.714118599838027,
      "grad_norm": 4.367641925811768,
      "learning_rate": 2.643902180817277e-05,
      "loss": 0.745,
      "step": 445300
    },
    {
      "epoch": 4.714647921618031,
      "grad_norm": 4.006186008453369,
      "learning_rate": 2.643642811772179e-05,
      "loss": 0.73,
      "step": 445350
    },
    {
      "epoch": 4.715177243398034,
      "grad_norm": 4.304440975189209,
      "learning_rate": 2.643378149481262e-05,
      "loss": 0.743,
      "step": 445400
    },
    {
      "epoch": 4.715706565178038,
      "grad_norm": 4.3779730796813965,
      "learning_rate": 2.6431134871903452e-05,
      "loss": 0.734,
      "step": 445450
    },
    {
      "epoch": 4.7162358869580405,
      "grad_norm": 4.054537296295166,
      "learning_rate": 2.6428488248994283e-05,
      "loss": 0.725,
      "step": 445500
    },
    {
      "epoch": 4.7162358869580405,
      "eval_loss": 0.4915115237236023,
      "eval_runtime": 46.786,
      "eval_samples_per_second": 3589.318,
      "eval_steps_per_second": 448.681,
      "step": 445500
    },
    {
      "epoch": 4.716765208738044,
      "grad_norm": 4.4803080558776855,
      "learning_rate": 2.6425841626085117e-05,
      "loss": 0.7467,
      "step": 445550
    },
    {
      "epoch": 4.717294530518047,
      "grad_norm": 4.540874481201172,
      "learning_rate": 2.642324793563413e-05,
      "loss": 0.729,
      "step": 445600
    },
    {
      "epoch": 4.71782385229805,
      "grad_norm": 3.972188949584961,
      "learning_rate": 2.6420601312724962e-05,
      "loss": 0.7466,
      "step": 445650
    },
    {
      "epoch": 4.718353174078054,
      "grad_norm": 4.04362154006958,
      "learning_rate": 2.6417954689815793e-05,
      "loss": 0.7464,
      "step": 445700
    },
    {
      "epoch": 4.7188824958580575,
      "grad_norm": 3.918699026107788,
      "learning_rate": 2.641530806690663e-05,
      "loss": 0.7348,
      "step": 445750
    },
    {
      "epoch": 4.71941181763806,
      "grad_norm": 4.225731372833252,
      "learning_rate": 2.641266144399746e-05,
      "loss": 0.7392,
      "step": 445800
    },
    {
      "epoch": 4.719941139418063,
      "grad_norm": 4.334760665893555,
      "learning_rate": 2.6410014821088292e-05,
      "loss": 0.7448,
      "step": 445850
    },
    {
      "epoch": 4.720470461198067,
      "grad_norm": 4.219359397888184,
      "learning_rate": 2.6407368198179123e-05,
      "loss": 0.7166,
      "step": 445900
    },
    {
      "epoch": 4.72099978297807,
      "grad_norm": 4.572322368621826,
      "learning_rate": 2.6404721575269957e-05,
      "loss": 0.7333,
      "step": 445950
    },
    {
      "epoch": 4.721529104758074,
      "grad_norm": 4.1576104164123535,
      "learning_rate": 2.6402074952360788e-05,
      "loss": 0.7301,
      "step": 446000
    },
    {
      "epoch": 4.721529104758074,
      "eval_loss": 0.49050459265708923,
      "eval_runtime": 46.7502,
      "eval_samples_per_second": 3592.07,
      "eval_steps_per_second": 449.025,
      "step": 446000
    },
    {
      "epoch": 4.7220584265380765,
      "grad_norm": 4.218734264373779,
      "learning_rate": 2.6399428329451618e-05,
      "loss": 0.7326,
      "step": 446050
    },
    {
      "epoch": 4.72258774831808,
      "grad_norm": 4.776344299316406,
      "learning_rate": 2.639678170654245e-05,
      "loss": 0.7225,
      "step": 446100
    },
    {
      "epoch": 4.723117070098083,
      "grad_norm": 4.089823246002197,
      "learning_rate": 2.6394135083633286e-05,
      "loss": 0.7368,
      "step": 446150
    },
    {
      "epoch": 4.723646391878087,
      "grad_norm": 4.263035774230957,
      "learning_rate": 2.6391488460724117e-05,
      "loss": 0.7422,
      "step": 446200
    },
    {
      "epoch": 4.72417571365809,
      "grad_norm": 4.467488765716553,
      "learning_rate": 2.6388841837814948e-05,
      "loss": 0.7333,
      "step": 446250
    },
    {
      "epoch": 4.7247050354380935,
      "grad_norm": 3.877408504486084,
      "learning_rate": 2.638619521490578e-05,
      "loss": 0.7299,
      "step": 446300
    },
    {
      "epoch": 4.725234357218096,
      "grad_norm": 4.013343334197998,
      "learning_rate": 2.6383548591996616e-05,
      "loss": 0.7372,
      "step": 446350
    },
    {
      "epoch": 4.725763678998099,
      "grad_norm": 4.774312496185303,
      "learning_rate": 2.6380901969087447e-05,
      "loss": 0.7439,
      "step": 446400
    },
    {
      "epoch": 4.726293000778103,
      "grad_norm": 4.496806621551514,
      "learning_rate": 2.6378255346178278e-05,
      "loss": 0.7282,
      "step": 446450
    },
    {
      "epoch": 4.726822322558107,
      "grad_norm": 4.3060832023620605,
      "learning_rate": 2.6375608723269108e-05,
      "loss": 0.7264,
      "step": 446500
    },
    {
      "epoch": 4.726822322558107,
      "eval_loss": 0.48961788415908813,
      "eval_runtime": 46.9565,
      "eval_samples_per_second": 3576.291,
      "eval_steps_per_second": 447.052,
      "step": 446500
    },
    {
      "epoch": 4.72735164433811,
      "grad_norm": 4.229521751403809,
      "learning_rate": 2.6372962100359942e-05,
      "loss": 0.7287,
      "step": 446550
    },
    {
      "epoch": 4.7278809661181125,
      "grad_norm": 4.300878524780273,
      "learning_rate": 2.6370315477450773e-05,
      "loss": 0.7467,
      "step": 446600
    },
    {
      "epoch": 4.728410287898116,
      "grad_norm": 4.001867771148682,
      "learning_rate": 2.6367668854541604e-05,
      "loss": 0.7309,
      "step": 446650
    },
    {
      "epoch": 4.728939609678119,
      "grad_norm": 4.14055061340332,
      "learning_rate": 2.6365022231632434e-05,
      "loss": 0.7264,
      "step": 446700
    },
    {
      "epoch": 4.729468931458123,
      "grad_norm": 4.310951232910156,
      "learning_rate": 2.6362375608723272e-05,
      "loss": 0.7204,
      "step": 446750
    },
    {
      "epoch": 4.729998253238126,
      "grad_norm": 4.347110271453857,
      "learning_rate": 2.6359728985814103e-05,
      "loss": 0.7356,
      "step": 446800
    },
    {
      "epoch": 4.7305275750181295,
      "grad_norm": 4.705575466156006,
      "learning_rate": 2.6357082362904933e-05,
      "loss": 0.7296,
      "step": 446850
    },
    {
      "epoch": 4.731056896798132,
      "grad_norm": 4.222264766693115,
      "learning_rate": 2.6354435739995764e-05,
      "loss": 0.7296,
      "step": 446900
    },
    {
      "epoch": 4.731586218578136,
      "grad_norm": 4.05790376663208,
      "learning_rate": 2.63517891170866e-05,
      "loss": 0.719,
      "step": 446950
    },
    {
      "epoch": 4.732115540358139,
      "grad_norm": 4.469099044799805,
      "learning_rate": 2.6349142494177432e-05,
      "loss": 0.7394,
      "step": 447000
    },
    {
      "epoch": 4.732115540358139,
      "eval_loss": 0.4919985234737396,
      "eval_runtime": 46.7962,
      "eval_samples_per_second": 3588.54,
      "eval_steps_per_second": 448.584,
      "step": 447000
    },
    {
      "epoch": 4.732644862138143,
      "grad_norm": 4.153534412384033,
      "learning_rate": 2.6346495871268263e-05,
      "loss": 0.7287,
      "step": 447050
    },
    {
      "epoch": 4.733174183918146,
      "grad_norm": 4.5110697746276855,
      "learning_rate": 2.6343849248359094e-05,
      "loss": 0.7356,
      "step": 447100
    },
    {
      "epoch": 4.733703505698149,
      "grad_norm": 4.077086925506592,
      "learning_rate": 2.6341202625449928e-05,
      "loss": 0.7214,
      "step": 447150
    },
    {
      "epoch": 4.734232827478152,
      "grad_norm": 4.126726150512695,
      "learning_rate": 2.633855600254076e-05,
      "loss": 0.7365,
      "step": 447200
    },
    {
      "epoch": 4.734762149258156,
      "grad_norm": 4.029604911804199,
      "learning_rate": 2.633590937963159e-05,
      "loss": 0.7333,
      "step": 447250
    },
    {
      "epoch": 4.735291471038159,
      "grad_norm": 4.092373371124268,
      "learning_rate": 2.633326275672242e-05,
      "loss": 0.7383,
      "step": 447300
    },
    {
      "epoch": 4.735820792818162,
      "grad_norm": 4.285863399505615,
      "learning_rate": 2.6330616133813257e-05,
      "loss": 0.7359,
      "step": 447350
    },
    {
      "epoch": 4.7363501145981655,
      "grad_norm": 4.517014980316162,
      "learning_rate": 2.6327969510904088e-05,
      "loss": 0.7338,
      "step": 447400
    },
    {
      "epoch": 4.736879436378168,
      "grad_norm": 4.153655052185059,
      "learning_rate": 2.632532288799492e-05,
      "loss": 0.737,
      "step": 447450
    },
    {
      "epoch": 4.737408758158172,
      "grad_norm": 4.34844970703125,
      "learning_rate": 2.632267626508575e-05,
      "loss": 0.727,
      "step": 447500
    },
    {
      "epoch": 4.737408758158172,
      "eval_loss": 0.4899137318134308,
      "eval_runtime": 46.7757,
      "eval_samples_per_second": 3590.113,
      "eval_steps_per_second": 448.78,
      "step": 447500
    },
    {
      "epoch": 4.737938079938175,
      "grad_norm": 4.079178333282471,
      "learning_rate": 2.6320029642176587e-05,
      "loss": 0.7195,
      "step": 447550
    },
    {
      "epoch": 4.738467401718179,
      "grad_norm": 4.451828956604004,
      "learning_rate": 2.6317383019267418e-05,
      "loss": 0.7329,
      "step": 447600
    },
    {
      "epoch": 4.738996723498182,
      "grad_norm": 4.22705078125,
      "learning_rate": 2.631473639635825e-05,
      "loss": 0.7295,
      "step": 447650
    },
    {
      "epoch": 4.739526045278185,
      "grad_norm": 4.171034336090088,
      "learning_rate": 2.631208977344908e-05,
      "loss": 0.729,
      "step": 447700
    },
    {
      "epoch": 4.740055367058188,
      "grad_norm": 4.467424392700195,
      "learning_rate": 2.6309443150539913e-05,
      "loss": 0.7349,
      "step": 447750
    },
    {
      "epoch": 4.740584688838192,
      "grad_norm": 4.557657718658447,
      "learning_rate": 2.6306796527630744e-05,
      "loss": 0.7272,
      "step": 447800
    },
    {
      "epoch": 4.741114010618195,
      "grad_norm": 4.320414066314697,
      "learning_rate": 2.6304149904721575e-05,
      "loss": 0.7451,
      "step": 447850
    },
    {
      "epoch": 4.741643332398199,
      "grad_norm": 4.5686421394348145,
      "learning_rate": 2.6301503281812405e-05,
      "loss": 0.7398,
      "step": 447900
    },
    {
      "epoch": 4.742172654178201,
      "grad_norm": 4.08776330947876,
      "learning_rate": 2.6298856658903243e-05,
      "loss": 0.7318,
      "step": 447950
    },
    {
      "epoch": 4.742701975958205,
      "grad_norm": 4.172084331512451,
      "learning_rate": 2.6296210035994074e-05,
      "loss": 0.7232,
      "step": 448000
    },
    {
      "epoch": 4.742701975958205,
      "eval_loss": 0.48925578594207764,
      "eval_runtime": 46.7428,
      "eval_samples_per_second": 3592.641,
      "eval_steps_per_second": 449.096,
      "step": 448000
    },
    {
      "epoch": 4.743231297738208,
      "grad_norm": 4.595152378082275,
      "learning_rate": 2.6293563413084904e-05,
      "loss": 0.7334,
      "step": 448050
    },
    {
      "epoch": 4.743760619518211,
      "grad_norm": 4.365325927734375,
      "learning_rate": 2.6290916790175735e-05,
      "loss": 0.724,
      "step": 448100
    },
    {
      "epoch": 4.744289941298215,
      "grad_norm": 4.2059454917907715,
      "learning_rate": 2.6288270167266573e-05,
      "loss": 0.7209,
      "step": 448150
    },
    {
      "epoch": 4.7448192630782176,
      "grad_norm": 4.5970139503479,
      "learning_rate": 2.6285623544357403e-05,
      "loss": 0.735,
      "step": 448200
    },
    {
      "epoch": 4.745348584858221,
      "grad_norm": 4.340762138366699,
      "learning_rate": 2.6282976921448234e-05,
      "loss": 0.7396,
      "step": 448250
    },
    {
      "epoch": 4.745877906638224,
      "grad_norm": 3.842590570449829,
      "learning_rate": 2.6280330298539065e-05,
      "loss": 0.7243,
      "step": 448300
    },
    {
      "epoch": 4.746407228418228,
      "grad_norm": 4.327641487121582,
      "learning_rate": 2.62776836756299e-05,
      "loss": 0.7342,
      "step": 448350
    },
    {
      "epoch": 4.746936550198231,
      "grad_norm": 4.463390827178955,
      "learning_rate": 2.627503705272073e-05,
      "loss": 0.7213,
      "step": 448400
    },
    {
      "epoch": 4.7474658719782346,
      "grad_norm": 4.263298988342285,
      "learning_rate": 2.627239042981156e-05,
      "loss": 0.7479,
      "step": 448450
    },
    {
      "epoch": 4.747995193758237,
      "grad_norm": 4.1621479988098145,
      "learning_rate": 2.626974380690239e-05,
      "loss": 0.7336,
      "step": 448500
    },
    {
      "epoch": 4.747995193758237,
      "eval_loss": 0.48882532119750977,
      "eval_runtime": 46.7389,
      "eval_samples_per_second": 3592.937,
      "eval_steps_per_second": 449.133,
      "step": 448500
    },
    {
      "epoch": 4.748524515538241,
      "grad_norm": 4.3298187255859375,
      "learning_rate": 2.626709718399323e-05,
      "loss": 0.7308,
      "step": 448550
    },
    {
      "epoch": 4.749053837318244,
      "grad_norm": 4.390799045562744,
      "learning_rate": 2.626445056108406e-05,
      "loss": 0.7406,
      "step": 448600
    },
    {
      "epoch": 4.749583159098248,
      "grad_norm": 4.022615432739258,
      "learning_rate": 2.626180393817489e-05,
      "loss": 0.7258,
      "step": 448650
    },
    {
      "epoch": 4.750112480878251,
      "grad_norm": 4.714284420013428,
      "learning_rate": 2.625915731526572e-05,
      "loss": 0.7286,
      "step": 448700
    },
    {
      "epoch": 4.750641802658254,
      "grad_norm": 4.578808307647705,
      "learning_rate": 2.6256510692356555e-05,
      "loss": 0.734,
      "step": 448750
    },
    {
      "epoch": 4.751171124438257,
      "grad_norm": 4.047842979431152,
      "learning_rate": 2.6253864069447385e-05,
      "loss": 0.7279,
      "step": 448800
    },
    {
      "epoch": 4.75170044621826,
      "grad_norm": 4.511451244354248,
      "learning_rate": 2.6251217446538216e-05,
      "loss": 0.7451,
      "step": 448850
    },
    {
      "epoch": 4.752229767998264,
      "grad_norm": 4.572729587554932,
      "learning_rate": 2.6248570823629047e-05,
      "loss": 0.7268,
      "step": 448900
    },
    {
      "epoch": 4.752759089778267,
      "grad_norm": 4.381646156311035,
      "learning_rate": 2.6245924200719884e-05,
      "loss": 0.7348,
      "step": 448950
    },
    {
      "epoch": 4.7532884115582705,
      "grad_norm": 4.007542133331299,
      "learning_rate": 2.6243277577810715e-05,
      "loss": 0.7429,
      "step": 449000
    },
    {
      "epoch": 4.7532884115582705,
      "eval_loss": 0.4895212948322296,
      "eval_runtime": 46.756,
      "eval_samples_per_second": 3591.628,
      "eval_steps_per_second": 448.97,
      "step": 449000
    },
    {
      "epoch": 4.753817733338273,
      "grad_norm": 4.286637306213379,
      "learning_rate": 2.6240630954901546e-05,
      "loss": 0.7394,
      "step": 449050
    },
    {
      "epoch": 4.754347055118277,
      "grad_norm": 4.203049659729004,
      "learning_rate": 2.6237984331992376e-05,
      "loss": 0.7278,
      "step": 449100
    },
    {
      "epoch": 4.75487637689828,
      "grad_norm": 4.221005916595459,
      "learning_rate": 2.6235337709083214e-05,
      "loss": 0.7369,
      "step": 449150
    },
    {
      "epoch": 4.755405698678284,
      "grad_norm": 4.076308727264404,
      "learning_rate": 2.6232691086174045e-05,
      "loss": 0.725,
      "step": 449200
    },
    {
      "epoch": 4.755935020458287,
      "grad_norm": 4.450545310974121,
      "learning_rate": 2.6230044463264875e-05,
      "loss": 0.733,
      "step": 449250
    },
    {
      "epoch": 4.75646434223829,
      "grad_norm": 4.231319904327393,
      "learning_rate": 2.6227397840355706e-05,
      "loss": 0.75,
      "step": 449300
    },
    {
      "epoch": 4.756993664018293,
      "grad_norm": 4.341386318206787,
      "learning_rate": 2.622475121744654e-05,
      "loss": 0.735,
      "step": 449350
    },
    {
      "epoch": 4.757522985798297,
      "grad_norm": 4.617364406585693,
      "learning_rate": 2.622210459453737e-05,
      "loss": 0.7372,
      "step": 449400
    },
    {
      "epoch": 4.7580523075783,
      "grad_norm": 4.61365270614624,
      "learning_rate": 2.62194579716282e-05,
      "loss": 0.7393,
      "step": 449450
    },
    {
      "epoch": 4.758581629358304,
      "grad_norm": 4.080214500427246,
      "learning_rate": 2.6216811348719032e-05,
      "loss": 0.7306,
      "step": 449500
    },
    {
      "epoch": 4.758581629358304,
      "eval_loss": 0.4893951714038849,
      "eval_runtime": 46.7952,
      "eval_samples_per_second": 3588.615,
      "eval_steps_per_second": 448.593,
      "step": 449500
    },
    {
      "epoch": 4.7591109511383065,
      "grad_norm": 4.097900390625,
      "learning_rate": 2.621416472580987e-05,
      "loss": 0.7293,
      "step": 449550
    },
    {
      "epoch": 4.759640272918309,
      "grad_norm": 4.500972747802734,
      "learning_rate": 2.6211571035358884e-05,
      "loss": 0.7285,
      "step": 449600
    },
    {
      "epoch": 4.760169594698313,
      "grad_norm": 4.214838981628418,
      "learning_rate": 2.6208924412449715e-05,
      "loss": 0.7282,
      "step": 449650
    },
    {
      "epoch": 4.760698916478316,
      "grad_norm": 4.1925458908081055,
      "learning_rate": 2.6206277789540546e-05,
      "loss": 0.7418,
      "step": 449700
    },
    {
      "epoch": 4.76122823825832,
      "grad_norm": 4.556700706481934,
      "learning_rate": 2.620363116663138e-05,
      "loss": 0.7296,
      "step": 449750
    },
    {
      "epoch": 4.761757560038323,
      "grad_norm": 4.411326885223389,
      "learning_rate": 2.620098454372221e-05,
      "loss": 0.7239,
      "step": 449800
    },
    {
      "epoch": 4.762286881818326,
      "grad_norm": 4.2765679359436035,
      "learning_rate": 2.619833792081304e-05,
      "loss": 0.7302,
      "step": 449850
    },
    {
      "epoch": 4.762816203598329,
      "grad_norm": 4.257686138153076,
      "learning_rate": 2.6195691297903872e-05,
      "loss": 0.7329,
      "step": 449900
    },
    {
      "epoch": 4.763345525378333,
      "grad_norm": 4.52326774597168,
      "learning_rate": 2.619304467499471e-05,
      "loss": 0.7201,
      "step": 449950
    },
    {
      "epoch": 4.763874847158336,
      "grad_norm": 4.663913726806641,
      "learning_rate": 2.619039805208554e-05,
      "loss": 0.7312,
      "step": 450000
    },
    {
      "epoch": 4.763874847158336,
      "eval_loss": 0.48690059781074524,
      "eval_runtime": 46.7227,
      "eval_samples_per_second": 3594.182,
      "eval_steps_per_second": 449.289,
      "step": 450000
    },
    {
      "epoch": 4.76440416893834,
      "grad_norm": 4.401273727416992,
      "learning_rate": 2.618775142917637e-05,
      "loss": 0.7345,
      "step": 450050
    },
    {
      "epoch": 4.7649334907183425,
      "grad_norm": 4.781621932983398,
      "learning_rate": 2.6185104806267202e-05,
      "loss": 0.7361,
      "step": 450100
    },
    {
      "epoch": 4.765462812498346,
      "grad_norm": 4.257706165313721,
      "learning_rate": 2.618245818335804e-05,
      "loss": 0.7262,
      "step": 450150
    },
    {
      "epoch": 4.765992134278349,
      "grad_norm": 4.407878398895264,
      "learning_rate": 2.617981156044887e-05,
      "loss": 0.7259,
      "step": 450200
    },
    {
      "epoch": 4.766521456058353,
      "grad_norm": 3.963329792022705,
      "learning_rate": 2.61771649375397e-05,
      "loss": 0.7323,
      "step": 450250
    },
    {
      "epoch": 4.767050777838356,
      "grad_norm": 3.9999806880950928,
      "learning_rate": 2.617451831463053e-05,
      "loss": 0.7314,
      "step": 450300
    },
    {
      "epoch": 4.767580099618359,
      "grad_norm": 4.310857772827148,
      "learning_rate": 2.6171871691721365e-05,
      "loss": 0.7451,
      "step": 450350
    },
    {
      "epoch": 4.768109421398362,
      "grad_norm": 3.976060152053833,
      "learning_rate": 2.6169225068812196e-05,
      "loss": 0.7237,
      "step": 450400
    },
    {
      "epoch": 4.768638743178365,
      "grad_norm": 4.256175994873047,
      "learning_rate": 2.6166578445903027e-05,
      "loss": 0.7257,
      "step": 450450
    },
    {
      "epoch": 4.769168064958369,
      "grad_norm": 4.488626003265381,
      "learning_rate": 2.6163931822993858e-05,
      "loss": 0.7362,
      "step": 450500
    },
    {
      "epoch": 4.769168064958369,
      "eval_loss": 0.4886743128299713,
      "eval_runtime": 46.7984,
      "eval_samples_per_second": 3588.374,
      "eval_steps_per_second": 448.563,
      "step": 450500
    },
    {
      "epoch": 4.769697386738372,
      "grad_norm": 4.5337700843811035,
      "learning_rate": 2.6161285200084695e-05,
      "loss": 0.7476,
      "step": 450550
    },
    {
      "epoch": 4.770226708518376,
      "grad_norm": 4.04118537902832,
      "learning_rate": 2.6158638577175526e-05,
      "loss": 0.7301,
      "step": 450600
    },
    {
      "epoch": 4.7707560302983785,
      "grad_norm": 4.265666484832764,
      "learning_rate": 2.6155991954266356e-05,
      "loss": 0.7359,
      "step": 450650
    },
    {
      "epoch": 4.771285352078382,
      "grad_norm": 4.261295795440674,
      "learning_rate": 2.6153345331357187e-05,
      "loss": 0.7392,
      "step": 450700
    },
    {
      "epoch": 4.771814673858385,
      "grad_norm": 4.184730052947998,
      "learning_rate": 2.6150698708448025e-05,
      "loss": 0.7285,
      "step": 450750
    },
    {
      "epoch": 4.772343995638389,
      "grad_norm": 4.1574015617370605,
      "learning_rate": 2.6148052085538855e-05,
      "loss": 0.721,
      "step": 450800
    },
    {
      "epoch": 4.772873317418392,
      "grad_norm": 3.77176833152771,
      "learning_rate": 2.6145405462629686e-05,
      "loss": 0.7278,
      "step": 450850
    },
    {
      "epoch": 4.7734026391983955,
      "grad_norm": 4.166588306427002,
      "learning_rate": 2.6142758839720517e-05,
      "loss": 0.7341,
      "step": 450900
    },
    {
      "epoch": 4.773931960978398,
      "grad_norm": 4.134112358093262,
      "learning_rate": 2.614011221681135e-05,
      "loss": 0.7452,
      "step": 450950
    },
    {
      "epoch": 4.774461282758402,
      "grad_norm": 4.180298328399658,
      "learning_rate": 2.613746559390218e-05,
      "loss": 0.735,
      "step": 451000
    },
    {
      "epoch": 4.774461282758402,
      "eval_loss": 0.48844027519226074,
      "eval_runtime": 46.7623,
      "eval_samples_per_second": 3591.141,
      "eval_steps_per_second": 448.909,
      "step": 451000
    },
    {
      "epoch": 4.774990604538405,
      "grad_norm": 3.9627485275268555,
      "learning_rate": 2.6134818970993012e-05,
      "loss": 0.7281,
      "step": 451050
    },
    {
      "epoch": 4.775519926318408,
      "grad_norm": 4.258702278137207,
      "learning_rate": 2.6132172348083843e-05,
      "loss": 0.7346,
      "step": 451100
    },
    {
      "epoch": 4.776049248098412,
      "grad_norm": 4.3563761711120605,
      "learning_rate": 2.612952572517468e-05,
      "loss": 0.7343,
      "step": 451150
    },
    {
      "epoch": 4.7765785698784144,
      "grad_norm": 4.129585266113281,
      "learning_rate": 2.612687910226551e-05,
      "loss": 0.7412,
      "step": 451200
    },
    {
      "epoch": 4.777107891658418,
      "grad_norm": 3.8967905044555664,
      "learning_rate": 2.6124232479356342e-05,
      "loss": 0.7197,
      "step": 451250
    },
    {
      "epoch": 4.777637213438421,
      "grad_norm": 4.021770477294922,
      "learning_rate": 2.6121585856447173e-05,
      "loss": 0.7286,
      "step": 451300
    },
    {
      "epoch": 4.778166535218425,
      "grad_norm": 3.921764612197876,
      "learning_rate": 2.611893923353801e-05,
      "loss": 0.7262,
      "step": 451350
    },
    {
      "epoch": 4.778695856998428,
      "grad_norm": 4.063426494598389,
      "learning_rate": 2.611629261062884e-05,
      "loss": 0.7133,
      "step": 451400
    },
    {
      "epoch": 4.7792251787784314,
      "grad_norm": 4.252052307128906,
      "learning_rate": 2.611364598771967e-05,
      "loss": 0.7315,
      "step": 451450
    },
    {
      "epoch": 4.779754500558434,
      "grad_norm": 4.1995720863342285,
      "learning_rate": 2.6110999364810502e-05,
      "loss": 0.7238,
      "step": 451500
    },
    {
      "epoch": 4.779754500558434,
      "eval_loss": 0.4872056543827057,
      "eval_runtime": 46.9016,
      "eval_samples_per_second": 3580.474,
      "eval_steps_per_second": 447.575,
      "step": 451500
    },
    {
      "epoch": 4.780283822338438,
      "grad_norm": 4.339197158813477,
      "learning_rate": 2.6108352741901336e-05,
      "loss": 0.7226,
      "step": 451550
    },
    {
      "epoch": 4.780813144118441,
      "grad_norm": 4.031273365020752,
      "learning_rate": 2.610575905145035e-05,
      "loss": 0.7383,
      "step": 451600
    },
    {
      "epoch": 4.781342465898445,
      "grad_norm": 4.071184158325195,
      "learning_rate": 2.6103112428541182e-05,
      "loss": 0.7354,
      "step": 451650
    },
    {
      "epoch": 4.781871787678448,
      "grad_norm": 4.13322639465332,
      "learning_rate": 2.6100465805632013e-05,
      "loss": 0.7381,
      "step": 451700
    },
    {
      "epoch": 4.782401109458451,
      "grad_norm": 4.432956695556641,
      "learning_rate": 2.609781918272285e-05,
      "loss": 0.7305,
      "step": 451750
    },
    {
      "epoch": 4.782930431238454,
      "grad_norm": 4.387598037719727,
      "learning_rate": 2.609517255981368e-05,
      "loss": 0.7348,
      "step": 451800
    },
    {
      "epoch": 4.783459753018457,
      "grad_norm": 4.0608110427856445,
      "learning_rate": 2.609252593690451e-05,
      "loss": 0.7264,
      "step": 451850
    },
    {
      "epoch": 4.783989074798461,
      "grad_norm": 4.227966785430908,
      "learning_rate": 2.6089879313995342e-05,
      "loss": 0.7242,
      "step": 451900
    },
    {
      "epoch": 4.784518396578464,
      "grad_norm": 4.455422878265381,
      "learning_rate": 2.6087232691086176e-05,
      "loss": 0.7326,
      "step": 451950
    },
    {
      "epoch": 4.785047718358467,
      "grad_norm": 4.19631814956665,
      "learning_rate": 2.6084586068177007e-05,
      "loss": 0.7161,
      "step": 452000
    },
    {
      "epoch": 4.785047718358467,
      "eval_loss": 0.4873911738395691,
      "eval_runtime": 46.7831,
      "eval_samples_per_second": 3589.542,
      "eval_steps_per_second": 448.709,
      "step": 452000
    },
    {
      "epoch": 4.78557704013847,
      "grad_norm": 4.180161952972412,
      "learning_rate": 2.6081939445267838e-05,
      "loss": 0.7267,
      "step": 452050
    },
    {
      "epoch": 4.786106361918474,
      "grad_norm": 4.209142208099365,
      "learning_rate": 2.607929282235867e-05,
      "loss": 0.7359,
      "step": 452100
    },
    {
      "epoch": 4.786635683698477,
      "grad_norm": 4.701608657836914,
      "learning_rate": 2.6076646199449506e-05,
      "loss": 0.7354,
      "step": 452150
    },
    {
      "epoch": 4.787165005478481,
      "grad_norm": 4.388350009918213,
      "learning_rate": 2.6073999576540337e-05,
      "loss": 0.7247,
      "step": 452200
    },
    {
      "epoch": 4.7876943272584835,
      "grad_norm": 4.43011999130249,
      "learning_rate": 2.6071352953631167e-05,
      "loss": 0.7275,
      "step": 452250
    },
    {
      "epoch": 4.788223649038487,
      "grad_norm": 4.082137107849121,
      "learning_rate": 2.6068706330721998e-05,
      "loss": 0.7192,
      "step": 452300
    },
    {
      "epoch": 4.78875297081849,
      "grad_norm": 4.685056686401367,
      "learning_rate": 2.6066059707812836e-05,
      "loss": 0.7302,
      "step": 452350
    },
    {
      "epoch": 4.789282292598494,
      "grad_norm": 4.34592342376709,
      "learning_rate": 2.6063413084903666e-05,
      "loss": 0.7306,
      "step": 452400
    },
    {
      "epoch": 4.789811614378497,
      "grad_norm": 4.365388870239258,
      "learning_rate": 2.6060766461994497e-05,
      "loss": 0.7289,
      "step": 452450
    },
    {
      "epoch": 4.7903409361585005,
      "grad_norm": 4.422213554382324,
      "learning_rate": 2.6058119839085328e-05,
      "loss": 0.7358,
      "step": 452500
    },
    {
      "epoch": 4.7903409361585005,
      "eval_loss": 0.4886729121208191,
      "eval_runtime": 46.7528,
      "eval_samples_per_second": 3591.867,
      "eval_steps_per_second": 448.999,
      "step": 452500
    },
    {
      "epoch": 4.790870257938503,
      "grad_norm": 4.730396270751953,
      "learning_rate": 2.6055473216176162e-05,
      "loss": 0.7451,
      "step": 452550
    },
    {
      "epoch": 4.791399579718506,
      "grad_norm": 4.289958953857422,
      "learning_rate": 2.6052826593266992e-05,
      "loss": 0.7313,
      "step": 452600
    },
    {
      "epoch": 4.79192890149851,
      "grad_norm": 4.732044219970703,
      "learning_rate": 2.6050179970357823e-05,
      "loss": 0.7351,
      "step": 452650
    },
    {
      "epoch": 4.792458223278513,
      "grad_norm": 4.024305820465088,
      "learning_rate": 2.6047533347448654e-05,
      "loss": 0.7197,
      "step": 452700
    },
    {
      "epoch": 4.792987545058517,
      "grad_norm": 4.614851474761963,
      "learning_rate": 2.604488672453949e-05,
      "loss": 0.7306,
      "step": 452750
    },
    {
      "epoch": 4.7935168668385195,
      "grad_norm": 4.0660200119018555,
      "learning_rate": 2.6042240101630322e-05,
      "loss": 0.7378,
      "step": 452800
    },
    {
      "epoch": 4.794046188618523,
      "grad_norm": 4.226853370666504,
      "learning_rate": 2.6039593478721153e-05,
      "loss": 0.7325,
      "step": 452850
    },
    {
      "epoch": 4.794575510398526,
      "grad_norm": 4.345937252044678,
      "learning_rate": 2.6036946855811984e-05,
      "loss": 0.7358,
      "step": 452900
    },
    {
      "epoch": 4.79510483217853,
      "grad_norm": 4.441562652587891,
      "learning_rate": 2.603430023290282e-05,
      "loss": 0.7361,
      "step": 452950
    },
    {
      "epoch": 4.795634153958533,
      "grad_norm": 4.10145378112793,
      "learning_rate": 2.6031653609993652e-05,
      "loss": 0.7438,
      "step": 453000
    },
    {
      "epoch": 4.795634153958533,
      "eval_loss": 0.4880916178226471,
      "eval_runtime": 46.7293,
      "eval_samples_per_second": 3593.68,
      "eval_steps_per_second": 449.226,
      "step": 453000
    },
    {
      "epoch": 4.7961634757385365,
      "grad_norm": 4.348982810974121,
      "learning_rate": 2.6029006987084482e-05,
      "loss": 0.7303,
      "step": 453050
    },
    {
      "epoch": 4.796692797518539,
      "grad_norm": 4.333325386047363,
      "learning_rate": 2.6026360364175313e-05,
      "loss": 0.7358,
      "step": 453100
    },
    {
      "epoch": 4.797222119298543,
      "grad_norm": 4.384149074554443,
      "learning_rate": 2.6023713741266147e-05,
      "loss": 0.7505,
      "step": 453150
    },
    {
      "epoch": 4.797751441078546,
      "grad_norm": 4.089287281036377,
      "learning_rate": 2.6021067118356978e-05,
      "loss": 0.7294,
      "step": 453200
    },
    {
      "epoch": 4.79828076285855,
      "grad_norm": 4.213444232940674,
      "learning_rate": 2.601842049544781e-05,
      "loss": 0.7324,
      "step": 453250
    },
    {
      "epoch": 4.798810084638553,
      "grad_norm": 4.270601749420166,
      "learning_rate": 2.601577387253864e-05,
      "loss": 0.7254,
      "step": 453300
    },
    {
      "epoch": 4.7993394064185555,
      "grad_norm": 4.3169264793396,
      "learning_rate": 2.6013127249629477e-05,
      "loss": 0.7333,
      "step": 453350
    },
    {
      "epoch": 4.799868728198559,
      "grad_norm": 4.7022624015808105,
      "learning_rate": 2.6010480626720308e-05,
      "loss": 0.7405,
      "step": 453400
    },
    {
      "epoch": 4.800398049978562,
      "grad_norm": 4.572572231292725,
      "learning_rate": 2.6007834003811138e-05,
      "loss": 0.7265,
      "step": 453450
    },
    {
      "epoch": 4.800927371758566,
      "grad_norm": 4.038070201873779,
      "learning_rate": 2.600518738090197e-05,
      "loss": 0.7309,
      "step": 453500
    },
    {
      "epoch": 4.800927371758566,
      "eval_loss": 0.4851342439651489,
      "eval_runtime": 46.7382,
      "eval_samples_per_second": 3592.994,
      "eval_steps_per_second": 449.14,
      "step": 453500
    },
    {
      "epoch": 4.801456693538569,
      "grad_norm": 4.589480400085449,
      "learning_rate": 2.6002540757992806e-05,
      "loss": 0.7362,
      "step": 453550
    },
    {
      "epoch": 4.8019860153185725,
      "grad_norm": 4.247616767883301,
      "learning_rate": 2.5999947067541818e-05,
      "loss": 0.7367,
      "step": 453600
    },
    {
      "epoch": 4.802515337098575,
      "grad_norm": 4.2884931564331055,
      "learning_rate": 2.599730044463265e-05,
      "loss": 0.7398,
      "step": 453650
    },
    {
      "epoch": 4.803044658878579,
      "grad_norm": 4.207142353057861,
      "learning_rate": 2.599465382172348e-05,
      "loss": 0.7274,
      "step": 453700
    },
    {
      "epoch": 4.803573980658582,
      "grad_norm": 3.7430918216705322,
      "learning_rate": 2.5992007198814317e-05,
      "loss": 0.7368,
      "step": 453750
    },
    {
      "epoch": 4.804103302438586,
      "grad_norm": 4.046220302581787,
      "learning_rate": 2.5989360575905147e-05,
      "loss": 0.7428,
      "step": 453800
    },
    {
      "epoch": 4.804632624218589,
      "grad_norm": 4.233555793762207,
      "learning_rate": 2.5986713952995978e-05,
      "loss": 0.7331,
      "step": 453850
    },
    {
      "epoch": 4.805161945998592,
      "grad_norm": 4.341740608215332,
      "learning_rate": 2.598406733008681e-05,
      "loss": 0.724,
      "step": 453900
    },
    {
      "epoch": 4.805691267778595,
      "grad_norm": 4.239088535308838,
      "learning_rate": 2.5981420707177646e-05,
      "loss": 0.7217,
      "step": 453950
    },
    {
      "epoch": 4.806220589558599,
      "grad_norm": 4.013333797454834,
      "learning_rate": 2.5978774084268477e-05,
      "loss": 0.7257,
      "step": 454000
    },
    {
      "epoch": 4.806220589558599,
      "eval_loss": 0.48740482330322266,
      "eval_runtime": 46.759,
      "eval_samples_per_second": 3591.393,
      "eval_steps_per_second": 448.94,
      "step": 454000
    },
    {
      "epoch": 4.806749911338602,
      "grad_norm": 4.2429890632629395,
      "learning_rate": 2.5976127461359308e-05,
      "loss": 0.7369,
      "step": 454050
    },
    {
      "epoch": 4.807279233118605,
      "grad_norm": 4.637030124664307,
      "learning_rate": 2.597348083845014e-05,
      "loss": 0.7375,
      "step": 454100
    },
    {
      "epoch": 4.8078085548986085,
      "grad_norm": 4.080801486968994,
      "learning_rate": 2.5970834215540973e-05,
      "loss": 0.7314,
      "step": 454150
    },
    {
      "epoch": 4.808337876678611,
      "grad_norm": 4.173304557800293,
      "learning_rate": 2.5968187592631803e-05,
      "loss": 0.7382,
      "step": 454200
    },
    {
      "epoch": 4.808867198458615,
      "grad_norm": 4.325645923614502,
      "learning_rate": 2.5965540969722634e-05,
      "loss": 0.7376,
      "step": 454250
    },
    {
      "epoch": 4.809396520238618,
      "grad_norm": 4.539228439331055,
      "learning_rate": 2.5962894346813465e-05,
      "loss": 0.7352,
      "step": 454300
    },
    {
      "epoch": 4.809925842018622,
      "grad_norm": 3.9821674823760986,
      "learning_rate": 2.5960247723904302e-05,
      "loss": 0.7252,
      "step": 454350
    },
    {
      "epoch": 4.810455163798625,
      "grad_norm": 4.479933738708496,
      "learning_rate": 2.5957601100995133e-05,
      "loss": 0.7388,
      "step": 454400
    },
    {
      "epoch": 4.810984485578628,
      "grad_norm": 4.479747295379639,
      "learning_rate": 2.5954954478085964e-05,
      "loss": 0.7367,
      "step": 454450
    },
    {
      "epoch": 4.811513807358631,
      "grad_norm": 4.741336822509766,
      "learning_rate": 2.5952307855176794e-05,
      "loss": 0.7464,
      "step": 454500
    },
    {
      "epoch": 4.811513807358631,
      "eval_loss": 0.4877221882343292,
      "eval_runtime": 46.7836,
      "eval_samples_per_second": 3589.506,
      "eval_steps_per_second": 448.704,
      "step": 454500
    },
    {
      "epoch": 4.812043129138635,
      "grad_norm": 4.445461273193359,
      "learning_rate": 2.5949661232267632e-05,
      "loss": 0.7275,
      "step": 454550
    },
    {
      "epoch": 4.812572450918638,
      "grad_norm": 4.557739734649658,
      "learning_rate": 2.5947014609358463e-05,
      "loss": 0.7271,
      "step": 454600
    },
    {
      "epoch": 4.813101772698642,
      "grad_norm": 4.497137546539307,
      "learning_rate": 2.5944367986449293e-05,
      "loss": 0.7397,
      "step": 454650
    },
    {
      "epoch": 4.8136310944786445,
      "grad_norm": 4.217740058898926,
      "learning_rate": 2.5941721363540124e-05,
      "loss": 0.7364,
      "step": 454700
    },
    {
      "epoch": 4.814160416258648,
      "grad_norm": 4.317683219909668,
      "learning_rate": 2.5939074740630958e-05,
      "loss": 0.7247,
      "step": 454750
    },
    {
      "epoch": 4.814689738038651,
      "grad_norm": 4.289970397949219,
      "learning_rate": 2.593642811772179e-05,
      "loss": 0.7317,
      "step": 454800
    },
    {
      "epoch": 4.815219059818654,
      "grad_norm": 3.5305895805358887,
      "learning_rate": 2.593378149481262e-05,
      "loss": 0.7323,
      "step": 454850
    },
    {
      "epoch": 4.815748381598658,
      "grad_norm": 3.9394447803497314,
      "learning_rate": 2.593113487190345e-05,
      "loss": 0.727,
      "step": 454900
    },
    {
      "epoch": 4.816277703378661,
      "grad_norm": 4.217495441436768,
      "learning_rate": 2.5928488248994288e-05,
      "loss": 0.742,
      "step": 454950
    },
    {
      "epoch": 4.816807025158664,
      "grad_norm": 4.274739742279053,
      "learning_rate": 2.592584162608512e-05,
      "loss": 0.7334,
      "step": 455000
    },
    {
      "epoch": 4.816807025158664,
      "eval_loss": 0.4873943328857422,
      "eval_runtime": 46.9884,
      "eval_samples_per_second": 3573.857,
      "eval_steps_per_second": 446.748,
      "step": 455000
    },
    {
      "epoch": 4.817336346938667,
      "grad_norm": 4.348149299621582,
      "learning_rate": 2.592319500317595e-05,
      "loss": 0.7342,
      "step": 455050
    },
    {
      "epoch": 4.817865668718671,
      "grad_norm": 4.508347511291504,
      "learning_rate": 2.592054838026678e-05,
      "loss": 0.729,
      "step": 455100
    },
    {
      "epoch": 4.818394990498674,
      "grad_norm": 4.66391134262085,
      "learning_rate": 2.5917901757357614e-05,
      "loss": 0.724,
      "step": 455150
    },
    {
      "epoch": 4.818924312278678,
      "grad_norm": 3.9448418617248535,
      "learning_rate": 2.5915255134448445e-05,
      "loss": 0.7259,
      "step": 455200
    },
    {
      "epoch": 4.81945363405868,
      "grad_norm": 4.295399188995361,
      "learning_rate": 2.5912608511539275e-05,
      "loss": 0.7253,
      "step": 455250
    },
    {
      "epoch": 4.819982955838684,
      "grad_norm": 3.867619037628174,
      "learning_rate": 2.5909961888630106e-05,
      "loss": 0.7415,
      "step": 455300
    },
    {
      "epoch": 4.820512277618687,
      "grad_norm": 4.619553565979004,
      "learning_rate": 2.5907315265720944e-05,
      "loss": 0.7251,
      "step": 455350
    },
    {
      "epoch": 4.821041599398691,
      "grad_norm": 4.209468841552734,
      "learning_rate": 2.5904668642811774e-05,
      "loss": 0.7317,
      "step": 455400
    },
    {
      "epoch": 4.821570921178694,
      "grad_norm": 4.129261493682861,
      "learning_rate": 2.5902022019902605e-05,
      "loss": 0.7366,
      "step": 455450
    },
    {
      "epoch": 4.822100242958697,
      "grad_norm": 4.388129234313965,
      "learning_rate": 2.5899375396993436e-05,
      "loss": 0.7313,
      "step": 455500
    },
    {
      "epoch": 4.822100242958697,
      "eval_loss": 0.486676961183548,
      "eval_runtime": 46.9,
      "eval_samples_per_second": 3580.6,
      "eval_steps_per_second": 447.591,
      "step": 455500
    },
    {
      "epoch": 4.8226295647387,
      "grad_norm": 4.3467912673950195,
      "learning_rate": 2.5896728774084273e-05,
      "loss": 0.7368,
      "step": 455550
    },
    {
      "epoch": 4.823158886518703,
      "grad_norm": 3.823970079421997,
      "learning_rate": 2.5894135083633288e-05,
      "loss": 0.7268,
      "step": 455600
    },
    {
      "epoch": 4.823688208298707,
      "grad_norm": 4.365471839904785,
      "learning_rate": 2.589148846072412e-05,
      "loss": 0.7336,
      "step": 455650
    },
    {
      "epoch": 4.82421753007871,
      "grad_norm": 4.515201091766357,
      "learning_rate": 2.588884183781495e-05,
      "loss": 0.7312,
      "step": 455700
    },
    {
      "epoch": 4.8247468518587135,
      "grad_norm": 4.134561538696289,
      "learning_rate": 2.5886195214905783e-05,
      "loss": 0.7356,
      "step": 455750
    },
    {
      "epoch": 4.825276173638716,
      "grad_norm": 4.09883451461792,
      "learning_rate": 2.5883548591996614e-05,
      "loss": 0.7251,
      "step": 455800
    },
    {
      "epoch": 4.82580549541872,
      "grad_norm": 4.291906833648682,
      "learning_rate": 2.5880901969087445e-05,
      "loss": 0.7338,
      "step": 455850
    },
    {
      "epoch": 4.826334817198723,
      "grad_norm": 3.847043991088867,
      "learning_rate": 2.5878255346178276e-05,
      "loss": 0.7298,
      "step": 455900
    },
    {
      "epoch": 4.826864138978727,
      "grad_norm": 4.12097692489624,
      "learning_rate": 2.5875608723269113e-05,
      "loss": 0.7355,
      "step": 455950
    },
    {
      "epoch": 4.82739346075873,
      "grad_norm": 3.892911195755005,
      "learning_rate": 2.5872962100359944e-05,
      "loss": 0.7281,
      "step": 456000
    },
    {
      "epoch": 4.82739346075873,
      "eval_loss": 0.48550257086753845,
      "eval_runtime": 46.7366,
      "eval_samples_per_second": 3593.112,
      "eval_steps_per_second": 449.155,
      "step": 456000
    },
    {
      "epoch": 4.827922782538733,
      "grad_norm": 4.406229019165039,
      "learning_rate": 2.5870315477450774e-05,
      "loss": 0.7172,
      "step": 456050
    },
    {
      "epoch": 4.828452104318736,
      "grad_norm": 4.04032039642334,
      "learning_rate": 2.5867668854541605e-05,
      "loss": 0.726,
      "step": 456100
    },
    {
      "epoch": 4.82898142609874,
      "grad_norm": 4.041022777557373,
      "learning_rate": 2.586502223163244e-05,
      "loss": 0.7306,
      "step": 456150
    },
    {
      "epoch": 4.829510747878743,
      "grad_norm": 4.51113748550415,
      "learning_rate": 2.586237560872327e-05,
      "loss": 0.7272,
      "step": 456200
    },
    {
      "epoch": 4.830040069658747,
      "grad_norm": 4.553369045257568,
      "learning_rate": 2.58597289858141e-05,
      "loss": 0.7314,
      "step": 456250
    },
    {
      "epoch": 4.8305693914387495,
      "grad_norm": 4.545474052429199,
      "learning_rate": 2.585708236290493e-05,
      "loss": 0.7249,
      "step": 456300
    },
    {
      "epoch": 4.831098713218752,
      "grad_norm": 4.56491756439209,
      "learning_rate": 2.585443573999577e-05,
      "loss": 0.7309,
      "step": 456350
    },
    {
      "epoch": 4.831628034998756,
      "grad_norm": 4.7240681648254395,
      "learning_rate": 2.58517891170866e-05,
      "loss": 0.7268,
      "step": 456400
    },
    {
      "epoch": 4.832157356778759,
      "grad_norm": 4.286722183227539,
      "learning_rate": 2.584914249417743e-05,
      "loss": 0.7368,
      "step": 456450
    },
    {
      "epoch": 4.832686678558763,
      "grad_norm": 3.9135758876800537,
      "learning_rate": 2.584649587126826e-05,
      "loss": 0.7428,
      "step": 456500
    },
    {
      "epoch": 4.832686678558763,
      "eval_loss": 0.48551177978515625,
      "eval_runtime": 46.7884,
      "eval_samples_per_second": 3589.141,
      "eval_steps_per_second": 448.659,
      "step": 456500
    },
    {
      "epoch": 4.833216000338766,
      "grad_norm": 4.5609235763549805,
      "learning_rate": 2.58438492483591e-05,
      "loss": 0.7322,
      "step": 456550
    },
    {
      "epoch": 4.833745322118769,
      "grad_norm": 3.784607172012329,
      "learning_rate": 2.584120262544993e-05,
      "loss": 0.7329,
      "step": 456600
    },
    {
      "epoch": 4.834274643898772,
      "grad_norm": 3.9886319637298584,
      "learning_rate": 2.583855600254076e-05,
      "loss": 0.7166,
      "step": 456650
    },
    {
      "epoch": 4.834803965678776,
      "grad_norm": 4.06494140625,
      "learning_rate": 2.583590937963159e-05,
      "loss": 0.7296,
      "step": 456700
    },
    {
      "epoch": 4.835333287458779,
      "grad_norm": 4.169051170349121,
      "learning_rate": 2.5833262756722425e-05,
      "loss": 0.7262,
      "step": 456750
    },
    {
      "epoch": 4.835862609238783,
      "grad_norm": 4.536304950714111,
      "learning_rate": 2.5830616133813255e-05,
      "loss": 0.7447,
      "step": 456800
    },
    {
      "epoch": 4.8363919310187855,
      "grad_norm": 4.363611698150635,
      "learning_rate": 2.5827969510904086e-05,
      "loss": 0.7344,
      "step": 456850
    },
    {
      "epoch": 4.836921252798789,
      "grad_norm": 4.34412956237793,
      "learning_rate": 2.5825322887994917e-05,
      "loss": 0.7406,
      "step": 456900
    },
    {
      "epoch": 4.837450574578792,
      "grad_norm": 4.148733139038086,
      "learning_rate": 2.5822676265085754e-05,
      "loss": 0.7356,
      "step": 456950
    },
    {
      "epoch": 4.837979896358796,
      "grad_norm": 4.312551021575928,
      "learning_rate": 2.5820029642176585e-05,
      "loss": 0.7479,
      "step": 457000
    },
    {
      "epoch": 4.837979896358796,
      "eval_loss": 0.48583683371543884,
      "eval_runtime": 46.7437,
      "eval_samples_per_second": 3592.568,
      "eval_steps_per_second": 449.087,
      "step": 457000
    },
    {
      "epoch": 4.838509218138799,
      "grad_norm": 4.729526996612549,
      "learning_rate": 2.5817383019267416e-05,
      "loss": 0.7361,
      "step": 457050
    },
    {
      "epoch": 4.839038539918802,
      "grad_norm": 3.995628833770752,
      "learning_rate": 2.5814736396358246e-05,
      "loss": 0.7248,
      "step": 457100
    },
    {
      "epoch": 4.839567861698805,
      "grad_norm": 4.211800575256348,
      "learning_rate": 2.5812089773449084e-05,
      "loss": 0.7177,
      "step": 457150
    },
    {
      "epoch": 4.840097183478808,
      "grad_norm": 4.265669345855713,
      "learning_rate": 2.5809443150539915e-05,
      "loss": 0.7236,
      "step": 457200
    },
    {
      "epoch": 4.840626505258812,
      "grad_norm": 4.455984592437744,
      "learning_rate": 2.5806796527630745e-05,
      "loss": 0.7351,
      "step": 457250
    },
    {
      "epoch": 4.841155827038815,
      "grad_norm": 4.314312934875488,
      "learning_rate": 2.5804149904721576e-05,
      "loss": 0.7192,
      "step": 457300
    },
    {
      "epoch": 4.841685148818819,
      "grad_norm": 4.668512344360352,
      "learning_rate": 2.5801503281812407e-05,
      "loss": 0.7383,
      "step": 457350
    },
    {
      "epoch": 4.8422144705988215,
      "grad_norm": 4.250835418701172,
      "learning_rate": 2.579885665890324e-05,
      "loss": 0.7364,
      "step": 457400
    },
    {
      "epoch": 4.842743792378825,
      "grad_norm": 4.365624904632568,
      "learning_rate": 2.579621003599407e-05,
      "loss": 0.7319,
      "step": 457450
    },
    {
      "epoch": 4.843273114158828,
      "grad_norm": 4.713863849639893,
      "learning_rate": 2.5793563413084902e-05,
      "loss": 0.7422,
      "step": 457500
    },
    {
      "epoch": 4.843273114158828,
      "eval_loss": 0.48558709025382996,
      "eval_runtime": 46.699,
      "eval_samples_per_second": 3596.006,
      "eval_steps_per_second": 449.517,
      "step": 457500
    },
    {
      "epoch": 4.843802435938832,
      "grad_norm": 4.694065570831299,
      "learning_rate": 2.5790916790175733e-05,
      "loss": 0.7284,
      "step": 457550
    },
    {
      "epoch": 4.844331757718835,
      "grad_norm": 4.107455253601074,
      "learning_rate": 2.578827016726657e-05,
      "loss": 0.714,
      "step": 457600
    },
    {
      "epoch": 4.8448610794988385,
      "grad_norm": 4.209367275238037,
      "learning_rate": 2.5785676476815585e-05,
      "loss": 0.7315,
      "step": 457650
    },
    {
      "epoch": 4.845390401278841,
      "grad_norm": 4.353334903717041,
      "learning_rate": 2.5783029853906416e-05,
      "loss": 0.7192,
      "step": 457700
    },
    {
      "epoch": 4.845919723058845,
      "grad_norm": 3.97746205329895,
      "learning_rate": 2.578038323099725e-05,
      "loss": 0.7296,
      "step": 457750
    },
    {
      "epoch": 4.846449044838848,
      "grad_norm": 4.039159774780273,
      "learning_rate": 2.577773660808808e-05,
      "loss": 0.7328,
      "step": 457800
    },
    {
      "epoch": 4.846978366618851,
      "grad_norm": 3.9565160274505615,
      "learning_rate": 2.577508998517891e-05,
      "loss": 0.7203,
      "step": 457850
    },
    {
      "epoch": 4.847507688398855,
      "grad_norm": 4.069591045379639,
      "learning_rate": 2.5772443362269742e-05,
      "loss": 0.727,
      "step": 457900
    },
    {
      "epoch": 4.8480370101788575,
      "grad_norm": 4.147671222686768,
      "learning_rate": 2.5769796739360573e-05,
      "loss": 0.7307,
      "step": 457950
    },
    {
      "epoch": 4.848566331958861,
      "grad_norm": 4.423308372497559,
      "learning_rate": 2.576715011645141e-05,
      "loss": 0.7281,
      "step": 458000
    },
    {
      "epoch": 4.848566331958861,
      "eval_loss": 0.4848780035972595,
      "eval_runtime": 46.7717,
      "eval_samples_per_second": 3590.421,
      "eval_steps_per_second": 448.819,
      "step": 458000
    },
    {
      "epoch": 4.849095653738864,
      "grad_norm": 4.388350963592529,
      "learning_rate": 2.576450349354224e-05,
      "loss": 0.7286,
      "step": 458050
    },
    {
      "epoch": 4.849624975518868,
      "grad_norm": 4.506346225738525,
      "learning_rate": 2.5761856870633072e-05,
      "loss": 0.7466,
      "step": 458100
    },
    {
      "epoch": 4.850154297298871,
      "grad_norm": 4.068062782287598,
      "learning_rate": 2.5759210247723903e-05,
      "loss": 0.7324,
      "step": 458150
    },
    {
      "epoch": 4.8506836190788745,
      "grad_norm": 4.469240188598633,
      "learning_rate": 2.575656362481474e-05,
      "loss": 0.7224,
      "step": 458200
    },
    {
      "epoch": 4.851212940858877,
      "grad_norm": 4.321425437927246,
      "learning_rate": 2.575391700190557e-05,
      "loss": 0.7315,
      "step": 458250
    },
    {
      "epoch": 4.851742262638881,
      "grad_norm": 4.158736705780029,
      "learning_rate": 2.57512703789964e-05,
      "loss": 0.7306,
      "step": 458300
    },
    {
      "epoch": 4.852271584418884,
      "grad_norm": 4.503968715667725,
      "learning_rate": 2.5748623756087232e-05,
      "loss": 0.7272,
      "step": 458350
    },
    {
      "epoch": 4.852800906198888,
      "grad_norm": 4.229466438293457,
      "learning_rate": 2.5745977133178066e-05,
      "loss": 0.7275,
      "step": 458400
    },
    {
      "epoch": 4.853330227978891,
      "grad_norm": 4.331479549407959,
      "learning_rate": 2.5743330510268897e-05,
      "loss": 0.7273,
      "step": 458450
    },
    {
      "epoch": 4.853859549758894,
      "grad_norm": 4.633298873901367,
      "learning_rate": 2.5740683887359728e-05,
      "loss": 0.7278,
      "step": 458500
    },
    {
      "epoch": 4.853859549758894,
      "eval_loss": 0.48351019620895386,
      "eval_runtime": 46.8736,
      "eval_samples_per_second": 3582.617,
      "eval_steps_per_second": 447.843,
      "step": 458500
    },
    {
      "epoch": 4.854388871538897,
      "grad_norm": 3.8885297775268555,
      "learning_rate": 2.573803726445056e-05,
      "loss": 0.7222,
      "step": 458550
    },
    {
      "epoch": 4.8549181933189,
      "grad_norm": 4.023642063140869,
      "learning_rate": 2.5735390641541396e-05,
      "loss": 0.7315,
      "step": 458600
    },
    {
      "epoch": 4.855447515098904,
      "grad_norm": 4.090335845947266,
      "learning_rate": 2.5732744018632227e-05,
      "loss": 0.713,
      "step": 458650
    },
    {
      "epoch": 4.855976836878907,
      "grad_norm": 4.514262676239014,
      "learning_rate": 2.5730097395723057e-05,
      "loss": 0.7314,
      "step": 458700
    },
    {
      "epoch": 4.85650615865891,
      "grad_norm": 4.320009231567383,
      "learning_rate": 2.5727450772813888e-05,
      "loss": 0.7413,
      "step": 458750
    },
    {
      "epoch": 4.857035480438913,
      "grad_norm": 4.37684440612793,
      "learning_rate": 2.5724804149904726e-05,
      "loss": 0.7367,
      "step": 458800
    },
    {
      "epoch": 4.857564802218917,
      "grad_norm": 4.4210076332092285,
      "learning_rate": 2.5722157526995556e-05,
      "loss": 0.7223,
      "step": 458850
    },
    {
      "epoch": 4.85809412399892,
      "grad_norm": 4.081238746643066,
      "learning_rate": 2.5719510904086387e-05,
      "loss": 0.7178,
      "step": 458900
    },
    {
      "epoch": 4.858623445778924,
      "grad_norm": 3.986574411392212,
      "learning_rate": 2.5716864281177218e-05,
      "loss": 0.727,
      "step": 458950
    },
    {
      "epoch": 4.8591527675589266,
      "grad_norm": 4.325271129608154,
      "learning_rate": 2.5714217658268052e-05,
      "loss": 0.7291,
      "step": 459000
    },
    {
      "epoch": 4.8591527675589266,
      "eval_loss": 0.48476582765579224,
      "eval_runtime": 46.7634,
      "eval_samples_per_second": 3591.053,
      "eval_steps_per_second": 448.898,
      "step": 459000
    },
    {
      "epoch": 4.85968208933893,
      "grad_norm": 4.45350456237793,
      "learning_rate": 2.5711571035358882e-05,
      "loss": 0.7296,
      "step": 459050
    },
    {
      "epoch": 4.860211411118933,
      "grad_norm": 4.39130163192749,
      "learning_rate": 2.5708924412449713e-05,
      "loss": 0.7296,
      "step": 459100
    },
    {
      "epoch": 4.860740732898937,
      "grad_norm": 4.549038887023926,
      "learning_rate": 2.5706277789540544e-05,
      "loss": 0.7324,
      "step": 459150
    },
    {
      "epoch": 4.86127005467894,
      "grad_norm": 4.625488758087158,
      "learning_rate": 2.570363116663138e-05,
      "loss": 0.7404,
      "step": 459200
    },
    {
      "epoch": 4.8617993764589436,
      "grad_norm": 4.057873725891113,
      "learning_rate": 2.5700984543722212e-05,
      "loss": 0.7354,
      "step": 459250
    },
    {
      "epoch": 4.862328698238946,
      "grad_norm": 4.057173252105713,
      "learning_rate": 2.5698337920813043e-05,
      "loss": 0.7278,
      "step": 459300
    },
    {
      "epoch": 4.862858020018949,
      "grad_norm": 4.604922294616699,
      "learning_rate": 2.5695691297903873e-05,
      "loss": 0.7322,
      "step": 459350
    },
    {
      "epoch": 4.863387341798953,
      "grad_norm": 3.802027940750122,
      "learning_rate": 2.569304467499471e-05,
      "loss": 0.73,
      "step": 459400
    },
    {
      "epoch": 4.863916663578956,
      "grad_norm": 4.657491207122803,
      "learning_rate": 2.5690398052085542e-05,
      "loss": 0.7196,
      "step": 459450
    },
    {
      "epoch": 4.86444598535896,
      "grad_norm": 4.0842084884643555,
      "learning_rate": 2.5687751429176372e-05,
      "loss": 0.7302,
      "step": 459500
    },
    {
      "epoch": 4.86444598535896,
      "eval_loss": 0.4838631749153137,
      "eval_runtime": 46.9087,
      "eval_samples_per_second": 3579.934,
      "eval_steps_per_second": 447.508,
      "step": 459500
    },
    {
      "epoch": 4.8649753071389625,
      "grad_norm": 4.269781589508057,
      "learning_rate": 2.5685104806267203e-05,
      "loss": 0.7264,
      "step": 459550
    },
    {
      "epoch": 4.865504628918966,
      "grad_norm": 4.485824108123779,
      "learning_rate": 2.5682458183358037e-05,
      "loss": 0.7321,
      "step": 459600
    },
    {
      "epoch": 4.866033950698969,
      "grad_norm": 4.430237770080566,
      "learning_rate": 2.5679864492907052e-05,
      "loss": 0.7413,
      "step": 459650
    },
    {
      "epoch": 4.866563272478973,
      "grad_norm": 4.555477142333984,
      "learning_rate": 2.5677217869997883e-05,
      "loss": 0.7191,
      "step": 459700
    },
    {
      "epoch": 4.867092594258976,
      "grad_norm": 3.7221453189849854,
      "learning_rate": 2.5674571247088713e-05,
      "loss": 0.7265,
      "step": 459750
    },
    {
      "epoch": 4.8676219160389795,
      "grad_norm": 3.9176383018493652,
      "learning_rate": 2.567192462417955e-05,
      "loss": 0.7208,
      "step": 459800
    },
    {
      "epoch": 4.868151237818982,
      "grad_norm": 4.058672904968262,
      "learning_rate": 2.566927800127038e-05,
      "loss": 0.7346,
      "step": 459850
    },
    {
      "epoch": 4.868680559598986,
      "grad_norm": 4.402821063995361,
      "learning_rate": 2.5666631378361212e-05,
      "loss": 0.7425,
      "step": 459900
    },
    {
      "epoch": 4.869209881378989,
      "grad_norm": 4.388796806335449,
      "learning_rate": 2.5663984755452043e-05,
      "loss": 0.7373,
      "step": 459950
    },
    {
      "epoch": 4.869739203158993,
      "grad_norm": 4.026397228240967,
      "learning_rate": 2.5661338132542877e-05,
      "loss": 0.722,
      "step": 460000
    },
    {
      "epoch": 4.869739203158993,
      "eval_loss": 0.48288819193840027,
      "eval_runtime": 46.8084,
      "eval_samples_per_second": 3587.606,
      "eval_steps_per_second": 448.467,
      "step": 460000
    },
    {
      "epoch": 4.870268524938996,
      "grad_norm": 4.372328758239746,
      "learning_rate": 2.5658691509633708e-05,
      "loss": 0.7252,
      "step": 460050
    },
    {
      "epoch": 4.8707978467189985,
      "grad_norm": 4.1088738441467285,
      "learning_rate": 2.565604488672454e-05,
      "loss": 0.7246,
      "step": 460100
    },
    {
      "epoch": 4.871327168499002,
      "grad_norm": 4.375613689422607,
      "learning_rate": 2.565339826381537e-05,
      "loss": 0.7161,
      "step": 460150
    },
    {
      "epoch": 4.871856490279005,
      "grad_norm": 4.340729713439941,
      "learning_rate": 2.5650751640906207e-05,
      "loss": 0.7206,
      "step": 460200
    },
    {
      "epoch": 4.872385812059009,
      "grad_norm": 4.641964912414551,
      "learning_rate": 2.5648105017997037e-05,
      "loss": 0.7228,
      "step": 460250
    },
    {
      "epoch": 4.872915133839012,
      "grad_norm": 3.9712324142456055,
      "learning_rate": 2.5645458395087868e-05,
      "loss": 0.7316,
      "step": 460300
    },
    {
      "epoch": 4.8734444556190155,
      "grad_norm": 4.082038879394531,
      "learning_rate": 2.56428117721787e-05,
      "loss": 0.722,
      "step": 460350
    },
    {
      "epoch": 4.873973777399018,
      "grad_norm": 4.110827922821045,
      "learning_rate": 2.5640165149269536e-05,
      "loss": 0.7326,
      "step": 460400
    },
    {
      "epoch": 4.874503099179022,
      "grad_norm": 4.057986736297607,
      "learning_rate": 2.5637518526360367e-05,
      "loss": 0.7337,
      "step": 460450
    },
    {
      "epoch": 4.875032420959025,
      "grad_norm": 4.0259575843811035,
      "learning_rate": 2.5634871903451198e-05,
      "loss": 0.7254,
      "step": 460500
    },
    {
      "epoch": 4.875032420959025,
      "eval_loss": 0.4826270043849945,
      "eval_runtime": 46.6982,
      "eval_samples_per_second": 3596.068,
      "eval_steps_per_second": 449.525,
      "step": 460500
    },
    {
      "epoch": 4.875561742739029,
      "grad_norm": 4.005971431732178,
      "learning_rate": 2.563222528054203e-05,
      "loss": 0.73,
      "step": 460550
    },
    {
      "epoch": 4.876091064519032,
      "grad_norm": 4.503507614135742,
      "learning_rate": 2.5629578657632863e-05,
      "loss": 0.7398,
      "step": 460600
    },
    {
      "epoch": 4.876620386299035,
      "grad_norm": 4.139743804931641,
      "learning_rate": 2.5626932034723693e-05,
      "loss": 0.7336,
      "step": 460650
    },
    {
      "epoch": 4.877149708079038,
      "grad_norm": 4.088099956512451,
      "learning_rate": 2.5624285411814524e-05,
      "loss": 0.741,
      "step": 460700
    },
    {
      "epoch": 4.877679029859042,
      "grad_norm": 4.5094780921936035,
      "learning_rate": 2.5621638788905355e-05,
      "loss": 0.7262,
      "step": 460750
    },
    {
      "epoch": 4.878208351639045,
      "grad_norm": 3.9368934631347656,
      "learning_rate": 2.5618992165996192e-05,
      "loss": 0.7437,
      "step": 460800
    },
    {
      "epoch": 4.878737673419048,
      "grad_norm": 4.178300380706787,
      "learning_rate": 2.5616345543087023e-05,
      "loss": 0.7287,
      "step": 460850
    },
    {
      "epoch": 4.8792669951990515,
      "grad_norm": 4.493653774261475,
      "learning_rate": 2.5613698920177854e-05,
      "loss": 0.7213,
      "step": 460900
    },
    {
      "epoch": 4.879796316979054,
      "grad_norm": 4.383063793182373,
      "learning_rate": 2.5611052297268684e-05,
      "loss": 0.7327,
      "step": 460950
    },
    {
      "epoch": 4.880325638759058,
      "grad_norm": 4.230781078338623,
      "learning_rate": 2.5608405674359522e-05,
      "loss": 0.7172,
      "step": 461000
    },
    {
      "epoch": 4.880325638759058,
      "eval_loss": 0.48229289054870605,
      "eval_runtime": 46.7389,
      "eval_samples_per_second": 3592.941,
      "eval_steps_per_second": 449.134,
      "step": 461000
    },
    {
      "epoch": 4.880854960539061,
      "grad_norm": 4.127779483795166,
      "learning_rate": 2.5605759051450353e-05,
      "loss": 0.7303,
      "step": 461050
    },
    {
      "epoch": 4.881384282319065,
      "grad_norm": 4.552300930023193,
      "learning_rate": 2.5603112428541183e-05,
      "loss": 0.7243,
      "step": 461100
    },
    {
      "epoch": 4.881913604099068,
      "grad_norm": 3.8654417991638184,
      "learning_rate": 2.5600465805632014e-05,
      "loss": 0.7265,
      "step": 461150
    },
    {
      "epoch": 4.882442925879071,
      "grad_norm": 4.4510273933410645,
      "learning_rate": 2.5597819182722848e-05,
      "loss": 0.715,
      "step": 461200
    },
    {
      "epoch": 4.882972247659074,
      "grad_norm": 4.507480144500732,
      "learning_rate": 2.559517255981368e-05,
      "loss": 0.7297,
      "step": 461250
    },
    {
      "epoch": 4.883501569439078,
      "grad_norm": 3.977262496948242,
      "learning_rate": 2.559252593690451e-05,
      "loss": 0.7135,
      "step": 461300
    },
    {
      "epoch": 4.884030891219081,
      "grad_norm": 3.985765218734741,
      "learning_rate": 2.558987931399534e-05,
      "loss": 0.714,
      "step": 461350
    },
    {
      "epoch": 4.884560212999085,
      "grad_norm": 3.7880799770355225,
      "learning_rate": 2.5587232691086178e-05,
      "loss": 0.7282,
      "step": 461400
    },
    {
      "epoch": 4.8850895347790875,
      "grad_norm": 4.146572113037109,
      "learning_rate": 2.558458606817701e-05,
      "loss": 0.7366,
      "step": 461450
    },
    {
      "epoch": 4.885618856559091,
      "grad_norm": 4.360276699066162,
      "learning_rate": 2.558193944526784e-05,
      "loss": 0.7264,
      "step": 461500
    },
    {
      "epoch": 4.885618856559091,
      "eval_loss": 0.4830487072467804,
      "eval_runtime": 46.7385,
      "eval_samples_per_second": 3592.971,
      "eval_steps_per_second": 449.137,
      "step": 461500
    },
    {
      "epoch": 4.886148178339094,
      "grad_norm": 4.410518169403076,
      "learning_rate": 2.557929282235867e-05,
      "loss": 0.7255,
      "step": 461550
    },
    {
      "epoch": 4.886677500119097,
      "grad_norm": 4.1123433113098145,
      "learning_rate": 2.5576646199449504e-05,
      "loss": 0.7362,
      "step": 461600
    },
    {
      "epoch": 4.887206821899101,
      "grad_norm": 3.909571886062622,
      "learning_rate": 2.557405250899852e-05,
      "loss": 0.7212,
      "step": 461650
    },
    {
      "epoch": 4.887736143679104,
      "grad_norm": 4.260398864746094,
      "learning_rate": 2.557140588608935e-05,
      "loss": 0.7141,
      "step": 461700
    },
    {
      "epoch": 4.888265465459107,
      "grad_norm": 4.586499214172363,
      "learning_rate": 2.556875926318018e-05,
      "loss": 0.7354,
      "step": 461750
    },
    {
      "epoch": 4.88879478723911,
      "grad_norm": 4.199159145355225,
      "learning_rate": 2.5566112640271018e-05,
      "loss": 0.7296,
      "step": 461800
    },
    {
      "epoch": 4.889324109019114,
      "grad_norm": 4.545609951019287,
      "learning_rate": 2.5563466017361848e-05,
      "loss": 0.7279,
      "step": 461850
    },
    {
      "epoch": 4.889853430799117,
      "grad_norm": 4.311649799346924,
      "learning_rate": 2.556081939445268e-05,
      "loss": 0.7322,
      "step": 461900
    },
    {
      "epoch": 4.890382752579121,
      "grad_norm": 4.533373832702637,
      "learning_rate": 2.555817277154351e-05,
      "loss": 0.7269,
      "step": 461950
    },
    {
      "epoch": 4.8909120743591235,
      "grad_norm": 4.262574672698975,
      "learning_rate": 2.5555526148634347e-05,
      "loss": 0.7269,
      "step": 462000
    },
    {
      "epoch": 4.8909120743591235,
      "eval_loss": 0.4821036756038666,
      "eval_runtime": 46.9948,
      "eval_samples_per_second": 3573.374,
      "eval_steps_per_second": 446.688,
      "step": 462000
    },
    {
      "epoch": 4.891441396139127,
      "grad_norm": 4.263185501098633,
      "learning_rate": 2.5552879525725178e-05,
      "loss": 0.7276,
      "step": 462050
    },
    {
      "epoch": 4.89197071791913,
      "grad_norm": 4.155479907989502,
      "learning_rate": 2.555023290281601e-05,
      "loss": 0.7213,
      "step": 462100
    },
    {
      "epoch": 4.892500039699134,
      "grad_norm": 4.439497947692871,
      "learning_rate": 2.554758627990684e-05,
      "loss": 0.7267,
      "step": 462150
    },
    {
      "epoch": 4.893029361479137,
      "grad_norm": 4.514240741729736,
      "learning_rate": 2.5544939656997673e-05,
      "loss": 0.7191,
      "step": 462200
    },
    {
      "epoch": 4.8935586832591405,
      "grad_norm": 4.442189693450928,
      "learning_rate": 2.5542293034088504e-05,
      "loss": 0.7333,
      "step": 462250
    },
    {
      "epoch": 4.894088005039143,
      "grad_norm": 4.249323844909668,
      "learning_rate": 2.5539646411179335e-05,
      "loss": 0.7292,
      "step": 462300
    },
    {
      "epoch": 4.894617326819146,
      "grad_norm": 4.444530010223389,
      "learning_rate": 2.5536999788270166e-05,
      "loss": 0.7189,
      "step": 462350
    },
    {
      "epoch": 4.89514664859915,
      "grad_norm": 4.257415771484375,
      "learning_rate": 2.5534353165361003e-05,
      "loss": 0.7248,
      "step": 462400
    },
    {
      "epoch": 4.895675970379153,
      "grad_norm": 4.880152702331543,
      "learning_rate": 2.5531706542451834e-05,
      "loss": 0.7351,
      "step": 462450
    },
    {
      "epoch": 4.896205292159157,
      "grad_norm": 4.136229991912842,
      "learning_rate": 2.5529059919542664e-05,
      "loss": 0.7307,
      "step": 462500
    },
    {
      "epoch": 4.896205292159157,
      "eval_loss": 0.48227429389953613,
      "eval_runtime": 46.8143,
      "eval_samples_per_second": 3587.151,
      "eval_steps_per_second": 448.41,
      "step": 462500
    },
    {
      "epoch": 4.896734613939159,
      "grad_norm": 4.010996341705322,
      "learning_rate": 2.5526413296633495e-05,
      "loss": 0.7296,
      "step": 462550
    },
    {
      "epoch": 4.897263935719163,
      "grad_norm": 4.4383625984191895,
      "learning_rate": 2.552376667372433e-05,
      "loss": 0.7326,
      "step": 462600
    },
    {
      "epoch": 4.897793257499166,
      "grad_norm": 4.53234338760376,
      "learning_rate": 2.552112005081516e-05,
      "loss": 0.7296,
      "step": 462650
    },
    {
      "epoch": 4.89832257927917,
      "grad_norm": 4.510356903076172,
      "learning_rate": 2.551847342790599e-05,
      "loss": 0.7477,
      "step": 462700
    },
    {
      "epoch": 4.898851901059173,
      "grad_norm": 4.021810531616211,
      "learning_rate": 2.551582680499682e-05,
      "loss": 0.7239,
      "step": 462750
    },
    {
      "epoch": 4.899381222839176,
      "grad_norm": 4.197246551513672,
      "learning_rate": 2.551318018208766e-05,
      "loss": 0.7321,
      "step": 462800
    },
    {
      "epoch": 4.899910544619179,
      "grad_norm": 4.252377986907959,
      "learning_rate": 2.551053355917849e-05,
      "loss": 0.7312,
      "step": 462850
    },
    {
      "epoch": 4.900439866399183,
      "grad_norm": 4.341890335083008,
      "learning_rate": 2.550788693626932e-05,
      "loss": 0.7242,
      "step": 462900
    },
    {
      "epoch": 4.900969188179186,
      "grad_norm": 3.9613447189331055,
      "learning_rate": 2.550524031336015e-05,
      "loss": 0.7335,
      "step": 462950
    },
    {
      "epoch": 4.90149850995919,
      "grad_norm": 3.966832160949707,
      "learning_rate": 2.550259369045099e-05,
      "loss": 0.7237,
      "step": 463000
    },
    {
      "epoch": 4.90149850995919,
      "eval_loss": 0.4829392731189728,
      "eval_runtime": 46.7516,
      "eval_samples_per_second": 3591.96,
      "eval_steps_per_second": 449.011,
      "step": 463000
    },
    {
      "epoch": 4.9020278317391925,
      "grad_norm": 4.578371047973633,
      "learning_rate": 2.549994706754182e-05,
      "loss": 0.7344,
      "step": 463050
    },
    {
      "epoch": 4.902557153519195,
      "grad_norm": 4.070396423339844,
      "learning_rate": 2.549730044463265e-05,
      "loss": 0.732,
      "step": 463100
    },
    {
      "epoch": 4.903086475299199,
      "grad_norm": 4.508193492889404,
      "learning_rate": 2.549465382172348e-05,
      "loss": 0.7332,
      "step": 463150
    },
    {
      "epoch": 4.903615797079202,
      "grad_norm": 4.118239879608154,
      "learning_rate": 2.5492007198814315e-05,
      "loss": 0.7398,
      "step": 463200
    },
    {
      "epoch": 4.904145118859206,
      "grad_norm": 4.4617438316345215,
      "learning_rate": 2.5489360575905145e-05,
      "loss": 0.7045,
      "step": 463250
    },
    {
      "epoch": 4.904674440639209,
      "grad_norm": 4.077829360961914,
      "learning_rate": 2.5486713952995976e-05,
      "loss": 0.7341,
      "step": 463300
    },
    {
      "epoch": 4.905203762419212,
      "grad_norm": 4.139708995819092,
      "learning_rate": 2.5484067330086807e-05,
      "loss": 0.7316,
      "step": 463350
    },
    {
      "epoch": 4.905733084199215,
      "grad_norm": 4.196562767028809,
      "learning_rate": 2.5481420707177644e-05,
      "loss": 0.7281,
      "step": 463400
    },
    {
      "epoch": 4.906262405979219,
      "grad_norm": 4.270400524139404,
      "learning_rate": 2.5478774084268475e-05,
      "loss": 0.7259,
      "step": 463450
    },
    {
      "epoch": 4.906791727759222,
      "grad_norm": 4.695687294006348,
      "learning_rate": 2.5476127461359306e-05,
      "loss": 0.7248,
      "step": 463500
    },
    {
      "epoch": 4.906791727759222,
      "eval_loss": 0.4831494092941284,
      "eval_runtime": 46.8159,
      "eval_samples_per_second": 3587.027,
      "eval_steps_per_second": 448.394,
      "step": 463500
    },
    {
      "epoch": 4.907321049539226,
      "grad_norm": 4.378417015075684,
      "learning_rate": 2.5473480838450136e-05,
      "loss": 0.7367,
      "step": 463550
    },
    {
      "epoch": 4.9078503713192285,
      "grad_norm": 4.367959022521973,
      "learning_rate": 2.5470834215540974e-05,
      "loss": 0.7293,
      "step": 463600
    },
    {
      "epoch": 4.908379693099232,
      "grad_norm": 4.660955429077148,
      "learning_rate": 2.5468240525089985e-05,
      "loss": 0.7316,
      "step": 463650
    },
    {
      "epoch": 4.908909014879235,
      "grad_norm": 4.541643142700195,
      "learning_rate": 2.5465593902180816e-05,
      "loss": 0.7188,
      "step": 463700
    },
    {
      "epoch": 4.909438336659239,
      "grad_norm": 4.388274669647217,
      "learning_rate": 2.5462947279271647e-05,
      "loss": 0.7511,
      "step": 463750
    },
    {
      "epoch": 4.909967658439242,
      "grad_norm": 3.898287057876587,
      "learning_rate": 2.5460300656362484e-05,
      "loss": 0.7261,
      "step": 463800
    },
    {
      "epoch": 4.910496980219245,
      "grad_norm": 3.523064136505127,
      "learning_rate": 2.5457654033453315e-05,
      "loss": 0.7336,
      "step": 463850
    },
    {
      "epoch": 4.911026301999248,
      "grad_norm": 4.103763580322266,
      "learning_rate": 2.5455007410544146e-05,
      "loss": 0.7295,
      "step": 463900
    },
    {
      "epoch": 4.911555623779252,
      "grad_norm": 4.381045818328857,
      "learning_rate": 2.5452360787634976e-05,
      "loss": 0.734,
      "step": 463950
    },
    {
      "epoch": 4.912084945559255,
      "grad_norm": 4.421152114868164,
      "learning_rate": 2.5449714164725814e-05,
      "loss": 0.7316,
      "step": 464000
    },
    {
      "epoch": 4.912084945559255,
      "eval_loss": 0.4830332398414612,
      "eval_runtime": 46.8412,
      "eval_samples_per_second": 3585.096,
      "eval_steps_per_second": 448.153,
      "step": 464000
    },
    {
      "epoch": 4.912614267339258,
      "grad_norm": 4.618128299713135,
      "learning_rate": 2.5447067541816645e-05,
      "loss": 0.7309,
      "step": 464050
    },
    {
      "epoch": 4.913143589119262,
      "grad_norm": 4.5763936042785645,
      "learning_rate": 2.5444420918907475e-05,
      "loss": 0.7216,
      "step": 464100
    },
    {
      "epoch": 4.9136729108992645,
      "grad_norm": 4.4201483726501465,
      "learning_rate": 2.5441774295998306e-05,
      "loss": 0.726,
      "step": 464150
    },
    {
      "epoch": 4.914202232679268,
      "grad_norm": 3.9911656379699707,
      "learning_rate": 2.543912767308914e-05,
      "loss": 0.7244,
      "step": 464200
    },
    {
      "epoch": 4.914731554459271,
      "grad_norm": 4.399991989135742,
      "learning_rate": 2.543648105017997e-05,
      "loss": 0.7142,
      "step": 464250
    },
    {
      "epoch": 4.915260876239275,
      "grad_norm": 4.365200519561768,
      "learning_rate": 2.54338344272708e-05,
      "loss": 0.7286,
      "step": 464300
    },
    {
      "epoch": 4.915790198019278,
      "grad_norm": 4.396077632904053,
      "learning_rate": 2.5431187804361632e-05,
      "loss": 0.7309,
      "step": 464350
    },
    {
      "epoch": 4.9163195197992815,
      "grad_norm": 4.456493377685547,
      "learning_rate": 2.542854118145247e-05,
      "loss": 0.7313,
      "step": 464400
    },
    {
      "epoch": 4.916848841579284,
      "grad_norm": 4.830990314483643,
      "learning_rate": 2.54258945585433e-05,
      "loss": 0.7274,
      "step": 464450
    },
    {
      "epoch": 4.917378163359288,
      "grad_norm": 4.121339321136475,
      "learning_rate": 2.542324793563413e-05,
      "loss": 0.7155,
      "step": 464500
    },
    {
      "epoch": 4.917378163359288,
      "eval_loss": 0.48126810789108276,
      "eval_runtime": 46.7846,
      "eval_samples_per_second": 3589.43,
      "eval_steps_per_second": 448.695,
      "step": 464500
    },
    {
      "epoch": 4.917907485139291,
      "grad_norm": 4.242153644561768,
      "learning_rate": 2.5420601312724962e-05,
      "loss": 0.7392,
      "step": 464550
    },
    {
      "epoch": 4.918436806919294,
      "grad_norm": 4.665351867675781,
      "learning_rate": 2.54179546898158e-05,
      "loss": 0.7197,
      "step": 464600
    },
    {
      "epoch": 4.918966128699298,
      "grad_norm": 4.622809410095215,
      "learning_rate": 2.541530806690663e-05,
      "loss": 0.7244,
      "step": 464650
    },
    {
      "epoch": 4.919495450479301,
      "grad_norm": 4.209261894226074,
      "learning_rate": 2.541266144399746e-05,
      "loss": 0.722,
      "step": 464700
    },
    {
      "epoch": 4.920024772259304,
      "grad_norm": 4.143243789672852,
      "learning_rate": 2.541001482108829e-05,
      "loss": 0.7319,
      "step": 464750
    },
    {
      "epoch": 4.920554094039307,
      "grad_norm": 4.55253267288208,
      "learning_rate": 2.5407368198179126e-05,
      "loss": 0.7357,
      "step": 464800
    },
    {
      "epoch": 4.921083415819311,
      "grad_norm": 4.30073356628418,
      "learning_rate": 2.5404721575269956e-05,
      "loss": 0.7292,
      "step": 464850
    },
    {
      "epoch": 4.921612737599314,
      "grad_norm": 4.175655364990234,
      "learning_rate": 2.5402074952360787e-05,
      "loss": 0.7357,
      "step": 464900
    },
    {
      "epoch": 4.9221420593793175,
      "grad_norm": 4.219020366668701,
      "learning_rate": 2.5399428329451618e-05,
      "loss": 0.726,
      "step": 464950
    },
    {
      "epoch": 4.92267138115932,
      "grad_norm": 4.525857448577881,
      "learning_rate": 2.5396781706542455e-05,
      "loss": 0.7288,
      "step": 465000
    },
    {
      "epoch": 4.92267138115932,
      "eval_loss": 0.48133954405784607,
      "eval_runtime": 46.9419,
      "eval_samples_per_second": 3577.398,
      "eval_steps_per_second": 447.191,
      "step": 465000
    },
    {
      "epoch": 4.923200702939324,
      "grad_norm": 4.109564781188965,
      "learning_rate": 2.5394135083633286e-05,
      "loss": 0.7367,
      "step": 465050
    },
    {
      "epoch": 4.923730024719327,
      "grad_norm": 4.389822959899902,
      "learning_rate": 2.5391488460724117e-05,
      "loss": 0.7286,
      "step": 465100
    },
    {
      "epoch": 4.924259346499331,
      "grad_norm": 4.312991619110107,
      "learning_rate": 2.5388841837814947e-05,
      "loss": 0.7146,
      "step": 465150
    },
    {
      "epoch": 4.924788668279334,
      "grad_norm": 4.358517646789551,
      "learning_rate": 2.5386195214905785e-05,
      "loss": 0.7321,
      "step": 465200
    },
    {
      "epoch": 4.925317990059337,
      "grad_norm": 4.273486137390137,
      "learning_rate": 2.5383548591996615e-05,
      "loss": 0.7353,
      "step": 465250
    },
    {
      "epoch": 4.92584731183934,
      "grad_norm": 3.6894948482513428,
      "learning_rate": 2.5380901969087446e-05,
      "loss": 0.7196,
      "step": 465300
    },
    {
      "epoch": 4.926376633619343,
      "grad_norm": 4.275295734405518,
      "learning_rate": 2.5378255346178277e-05,
      "loss": 0.7297,
      "step": 465350
    },
    {
      "epoch": 4.926905955399347,
      "grad_norm": 4.808003902435303,
      "learning_rate": 2.537560872326911e-05,
      "loss": 0.7243,
      "step": 465400
    },
    {
      "epoch": 4.927435277179351,
      "grad_norm": 4.4433064460754395,
      "learning_rate": 2.5372962100359942e-05,
      "loss": 0.7195,
      "step": 465450
    },
    {
      "epoch": 4.9279645989593535,
      "grad_norm": 4.250992298126221,
      "learning_rate": 2.5370315477450772e-05,
      "loss": 0.7292,
      "step": 465500
    },
    {
      "epoch": 4.9279645989593535,
      "eval_loss": 0.4807261526584625,
      "eval_runtime": 46.7457,
      "eval_samples_per_second": 3592.416,
      "eval_steps_per_second": 449.068,
      "step": 465500
    },
    {
      "epoch": 4.928493920739356,
      "grad_norm": 4.302537441253662,
      "learning_rate": 2.5367668854541603e-05,
      "loss": 0.7337,
      "step": 465550
    },
    {
      "epoch": 4.92902324251936,
      "grad_norm": 4.373384475708008,
      "learning_rate": 2.536502223163244e-05,
      "loss": 0.7308,
      "step": 465600
    },
    {
      "epoch": 4.929552564299363,
      "grad_norm": 4.2549614906311035,
      "learning_rate": 2.5362428541181455e-05,
      "loss": 0.7333,
      "step": 465650
    },
    {
      "epoch": 4.930081886079367,
      "grad_norm": 4.206977844238281,
      "learning_rate": 2.5359781918272286e-05,
      "loss": 0.7202,
      "step": 465700
    },
    {
      "epoch": 4.93061120785937,
      "grad_norm": 4.120083808898926,
      "learning_rate": 2.5357135295363117e-05,
      "loss": 0.7336,
      "step": 465750
    },
    {
      "epoch": 4.931140529639373,
      "grad_norm": 4.659875392913818,
      "learning_rate": 2.535448867245395e-05,
      "loss": 0.7191,
      "step": 465800
    },
    {
      "epoch": 4.931669851419376,
      "grad_norm": 4.435980319976807,
      "learning_rate": 2.535184204954478e-05,
      "loss": 0.7305,
      "step": 465850
    },
    {
      "epoch": 4.93219917319938,
      "grad_norm": 4.513493061065674,
      "learning_rate": 2.5349195426635612e-05,
      "loss": 0.7393,
      "step": 465900
    },
    {
      "epoch": 4.932728494979383,
      "grad_norm": 3.651695728302002,
      "learning_rate": 2.5346548803726443e-05,
      "loss": 0.7264,
      "step": 465950
    },
    {
      "epoch": 4.933257816759387,
      "grad_norm": 4.538505554199219,
      "learning_rate": 2.534390218081728e-05,
      "loss": 0.7184,
      "step": 466000
    },
    {
      "epoch": 4.933257816759387,
      "eval_loss": 0.480508029460907,
      "eval_runtime": 46.7639,
      "eval_samples_per_second": 3591.019,
      "eval_steps_per_second": 448.893,
      "step": 466000
    },
    {
      "epoch": 4.933787138539389,
      "grad_norm": 3.893429756164551,
      "learning_rate": 2.534125555790811e-05,
      "loss": 0.7219,
      "step": 466050
    },
    {
      "epoch": 4.934316460319392,
      "grad_norm": 4.522857189178467,
      "learning_rate": 2.5338608934998942e-05,
      "loss": 0.7162,
      "step": 466100
    },
    {
      "epoch": 4.934845782099396,
      "grad_norm": 4.3757643699646,
      "learning_rate": 2.5335962312089773e-05,
      "loss": 0.7258,
      "step": 466150
    },
    {
      "epoch": 4.9353751038794,
      "grad_norm": 4.2316179275512695,
      "learning_rate": 2.533331568918061e-05,
      "loss": 0.7165,
      "step": 466200
    },
    {
      "epoch": 4.935904425659403,
      "grad_norm": 4.257519721984863,
      "learning_rate": 2.533066906627144e-05,
      "loss": 0.7361,
      "step": 466250
    },
    {
      "epoch": 4.9364337474394056,
      "grad_norm": 4.454246997833252,
      "learning_rate": 2.532802244336227e-05,
      "loss": 0.7259,
      "step": 466300
    },
    {
      "epoch": 4.936963069219409,
      "grad_norm": 4.253580093383789,
      "learning_rate": 2.5325375820453102e-05,
      "loss": 0.7311,
      "step": 466350
    },
    {
      "epoch": 4.937492390999412,
      "grad_norm": 4.381605625152588,
      "learning_rate": 2.5322729197543936e-05,
      "loss": 0.7357,
      "step": 466400
    },
    {
      "epoch": 4.938021712779416,
      "grad_norm": 4.104340553283691,
      "learning_rate": 2.5320082574634767e-05,
      "loss": 0.7176,
      "step": 466450
    },
    {
      "epoch": 4.938551034559419,
      "grad_norm": 4.25949764251709,
      "learning_rate": 2.5317435951725598e-05,
      "loss": 0.734,
      "step": 466500
    },
    {
      "epoch": 4.938551034559419,
      "eval_loss": 0.48177850246429443,
      "eval_runtime": 46.8799,
      "eval_samples_per_second": 3582.132,
      "eval_steps_per_second": 447.782,
      "step": 466500
    },
    {
      "epoch": 4.9390803563394226,
      "grad_norm": 3.9565093517303467,
      "learning_rate": 2.531478932881643e-05,
      "loss": 0.7329,
      "step": 466550
    },
    {
      "epoch": 4.939609678119425,
      "grad_norm": 3.9376957416534424,
      "learning_rate": 2.5312142705907266e-05,
      "loss": 0.7262,
      "step": 466600
    },
    {
      "epoch": 4.940138999899429,
      "grad_norm": 3.7618489265441895,
      "learning_rate": 2.5309496082998097e-05,
      "loss": 0.7329,
      "step": 466650
    },
    {
      "epoch": 4.940668321679432,
      "grad_norm": 4.1606340408325195,
      "learning_rate": 2.5306849460088927e-05,
      "loss": 0.7311,
      "step": 466700
    },
    {
      "epoch": 4.941197643459436,
      "grad_norm": 3.7055623531341553,
      "learning_rate": 2.5304202837179758e-05,
      "loss": 0.7295,
      "step": 466750
    },
    {
      "epoch": 4.941726965239439,
      "grad_norm": 4.609432697296143,
      "learning_rate": 2.5301556214270596e-05,
      "loss": 0.7403,
      "step": 466800
    },
    {
      "epoch": 4.9422562870194415,
      "grad_norm": 4.183571815490723,
      "learning_rate": 2.5298909591361426e-05,
      "loss": 0.7306,
      "step": 466850
    },
    {
      "epoch": 4.942785608799445,
      "grad_norm": 4.517980098724365,
      "learning_rate": 2.5296262968452257e-05,
      "loss": 0.7132,
      "step": 466900
    },
    {
      "epoch": 4.943314930579449,
      "grad_norm": 4.4048333168029785,
      "learning_rate": 2.5293616345543088e-05,
      "loss": 0.714,
      "step": 466950
    },
    {
      "epoch": 4.943844252359452,
      "grad_norm": 3.910684823989868,
      "learning_rate": 2.5290969722633922e-05,
      "loss": 0.7271,
      "step": 467000
    },
    {
      "epoch": 4.943844252359452,
      "eval_loss": 0.4800848066806793,
      "eval_runtime": 46.6396,
      "eval_samples_per_second": 3600.592,
      "eval_steps_per_second": 450.09,
      "step": 467000
    },
    {
      "epoch": 4.944373574139455,
      "grad_norm": 4.322871208190918,
      "learning_rate": 2.5288323099724753e-05,
      "loss": 0.7252,
      "step": 467050
    },
    {
      "epoch": 4.9449028959194585,
      "grad_norm": 4.047272205352783,
      "learning_rate": 2.5285676476815583e-05,
      "loss": 0.7262,
      "step": 467100
    },
    {
      "epoch": 4.945432217699461,
      "grad_norm": 4.482979774475098,
      "learning_rate": 2.5283029853906414e-05,
      "loss": 0.7257,
      "step": 467150
    },
    {
      "epoch": 4.945961539479465,
      "grad_norm": 4.2146759033203125,
      "learning_rate": 2.528038323099725e-05,
      "loss": 0.7254,
      "step": 467200
    },
    {
      "epoch": 4.946490861259468,
      "grad_norm": 3.8229448795318604,
      "learning_rate": 2.5277736608088082e-05,
      "loss": 0.7334,
      "step": 467250
    },
    {
      "epoch": 4.947020183039472,
      "grad_norm": 4.012966156005859,
      "learning_rate": 2.5275089985178913e-05,
      "loss": 0.7276,
      "step": 467300
    },
    {
      "epoch": 4.947549504819475,
      "grad_norm": 4.182666301727295,
      "learning_rate": 2.5272443362269744e-05,
      "loss": 0.7322,
      "step": 467350
    },
    {
      "epoch": 4.948078826599478,
      "grad_norm": 4.4037652015686035,
      "learning_rate": 2.526979673936058e-05,
      "loss": 0.7147,
      "step": 467400
    },
    {
      "epoch": 4.948608148379481,
      "grad_norm": 4.368865013122559,
      "learning_rate": 2.5267150116451412e-05,
      "loss": 0.7208,
      "step": 467450
    },
    {
      "epoch": 4.949137470159485,
      "grad_norm": 3.686509132385254,
      "learning_rate": 2.5264503493542243e-05,
      "loss": 0.7308,
      "step": 467500
    },
    {
      "epoch": 4.949137470159485,
      "eval_loss": 0.48098692297935486,
      "eval_runtime": 46.7471,
      "eval_samples_per_second": 3592.305,
      "eval_steps_per_second": 449.054,
      "step": 467500
    },
    {
      "epoch": 4.949666791939488,
      "grad_norm": 3.765437126159668,
      "learning_rate": 2.5261856870633073e-05,
      "loss": 0.7238,
      "step": 467550
    },
    {
      "epoch": 4.950196113719491,
      "grad_norm": 4.22489595413208,
      "learning_rate": 2.5259210247723907e-05,
      "loss": 0.7259,
      "step": 467600
    },
    {
      "epoch": 4.9507254354994945,
      "grad_norm": 4.603249549865723,
      "learning_rate": 2.5256563624814738e-05,
      "loss": 0.7265,
      "step": 467650
    },
    {
      "epoch": 4.951254757279498,
      "grad_norm": 3.942660331726074,
      "learning_rate": 2.5253969934363753e-05,
      "loss": 0.727,
      "step": 467700
    },
    {
      "epoch": 4.951784079059501,
      "grad_norm": 4.445863723754883,
      "learning_rate": 2.5251323311454583e-05,
      "loss": 0.733,
      "step": 467750
    },
    {
      "epoch": 4.952313400839504,
      "grad_norm": 3.97983980178833,
      "learning_rate": 2.524867668854542e-05,
      "loss": 0.72,
      "step": 467800
    },
    {
      "epoch": 4.952842722619508,
      "grad_norm": 4.204339504241943,
      "learning_rate": 2.524603006563625e-05,
      "loss": 0.7235,
      "step": 467850
    },
    {
      "epoch": 4.953372044399511,
      "grad_norm": 4.366918563842773,
      "learning_rate": 2.5243383442727082e-05,
      "loss": 0.7261,
      "step": 467900
    },
    {
      "epoch": 4.953901366179514,
      "grad_norm": 4.490236759185791,
      "learning_rate": 2.5240736819817913e-05,
      "loss": 0.7233,
      "step": 467950
    },
    {
      "epoch": 4.954430687959517,
      "grad_norm": 4.568903923034668,
      "learning_rate": 2.5238090196908747e-05,
      "loss": 0.7207,
      "step": 468000
    },
    {
      "epoch": 4.954430687959517,
      "eval_loss": 0.4787578582763672,
      "eval_runtime": 46.886,
      "eval_samples_per_second": 3581.666,
      "eval_steps_per_second": 447.724,
      "step": 468000
    },
    {
      "epoch": 4.954960009739521,
      "grad_norm": 4.217061519622803,
      "learning_rate": 2.5235443573999578e-05,
      "loss": 0.7214,
      "step": 468050
    },
    {
      "epoch": 4.955489331519524,
      "grad_norm": 4.207086563110352,
      "learning_rate": 2.523279695109041e-05,
      "loss": 0.725,
      "step": 468100
    },
    {
      "epoch": 4.956018653299528,
      "grad_norm": 3.9784040451049805,
      "learning_rate": 2.523015032818124e-05,
      "loss": 0.7239,
      "step": 468150
    },
    {
      "epoch": 4.9565479750795305,
      "grad_norm": 4.225768089294434,
      "learning_rate": 2.5227503705272077e-05,
      "loss": 0.7239,
      "step": 468200
    },
    {
      "epoch": 4.957077296859534,
      "grad_norm": 4.81072998046875,
      "learning_rate": 2.5224857082362908e-05,
      "loss": 0.7129,
      "step": 468250
    },
    {
      "epoch": 4.957606618639537,
      "grad_norm": 4.198668479919434,
      "learning_rate": 2.5222210459453738e-05,
      "loss": 0.7278,
      "step": 468300
    },
    {
      "epoch": 4.95813594041954,
      "grad_norm": 4.5661420822143555,
      "learning_rate": 2.521956383654457e-05,
      "loss": 0.729,
      "step": 468350
    },
    {
      "epoch": 4.958665262199544,
      "grad_norm": 4.24424409866333,
      "learning_rate": 2.5216917213635406e-05,
      "loss": 0.7351,
      "step": 468400
    },
    {
      "epoch": 4.9591945839795475,
      "grad_norm": 4.031302452087402,
      "learning_rate": 2.5214270590726237e-05,
      "loss": 0.7204,
      "step": 468450
    },
    {
      "epoch": 4.95972390575955,
      "grad_norm": 4.083863258361816,
      "learning_rate": 2.5211623967817068e-05,
      "loss": 0.7242,
      "step": 468500
    },
    {
      "epoch": 4.95972390575955,
      "eval_loss": 0.47871118783950806,
      "eval_runtime": 46.7894,
      "eval_samples_per_second": 3589.061,
      "eval_steps_per_second": 448.649,
      "step": 468500
    },
    {
      "epoch": 4.960253227539553,
      "grad_norm": 4.423101425170898,
      "learning_rate": 2.52089773449079e-05,
      "loss": 0.7185,
      "step": 468550
    },
    {
      "epoch": 4.960782549319557,
      "grad_norm": 4.518667697906494,
      "learning_rate": 2.5206330721998733e-05,
      "loss": 0.719,
      "step": 468600
    },
    {
      "epoch": 4.96131187109956,
      "grad_norm": 4.197750568389893,
      "learning_rate": 2.5203684099089563e-05,
      "loss": 0.727,
      "step": 468650
    },
    {
      "epoch": 4.961841192879564,
      "grad_norm": 4.079005241394043,
      "learning_rate": 2.5201037476180394e-05,
      "loss": 0.7243,
      "step": 468700
    },
    {
      "epoch": 4.9623705146595665,
      "grad_norm": 4.749282360076904,
      "learning_rate": 2.5198390853271225e-05,
      "loss": 0.7142,
      "step": 468750
    },
    {
      "epoch": 4.96289983643957,
      "grad_norm": 4.297744274139404,
      "learning_rate": 2.5195744230362062e-05,
      "loss": 0.7264,
      "step": 468800
    },
    {
      "epoch": 4.963429158219573,
      "grad_norm": 4.30713415145874,
      "learning_rate": 2.5193097607452893e-05,
      "loss": 0.744,
      "step": 468850
    },
    {
      "epoch": 4.963958479999577,
      "grad_norm": 4.288534164428711,
      "learning_rate": 2.5190450984543724e-05,
      "loss": 0.7248,
      "step": 468900
    },
    {
      "epoch": 4.96448780177958,
      "grad_norm": 3.7557482719421387,
      "learning_rate": 2.5187804361634554e-05,
      "loss": 0.7097,
      "step": 468950
    },
    {
      "epoch": 4.9650171235595835,
      "grad_norm": 4.214559078216553,
      "learning_rate": 2.518515773872539e-05,
      "loss": 0.7256,
      "step": 469000
    },
    {
      "epoch": 4.9650171235595835,
      "eval_loss": 0.48149996995925903,
      "eval_runtime": 46.7598,
      "eval_samples_per_second": 3591.329,
      "eval_steps_per_second": 448.932,
      "step": 469000
    },
    {
      "epoch": 4.965546445339586,
      "grad_norm": 4.120982646942139,
      "learning_rate": 2.518251111581622e-05,
      "loss": 0.7134,
      "step": 469050
    },
    {
      "epoch": 4.966075767119589,
      "grad_norm": 4.25623083114624,
      "learning_rate": 2.517986449290705e-05,
      "loss": 0.712,
      "step": 469100
    },
    {
      "epoch": 4.966605088899593,
      "grad_norm": 4.5379157066345215,
      "learning_rate": 2.517721786999788e-05,
      "loss": 0.724,
      "step": 469150
    },
    {
      "epoch": 4.967134410679597,
      "grad_norm": 4.006434917449951,
      "learning_rate": 2.5174571247088718e-05,
      "loss": 0.7145,
      "step": 469200
    },
    {
      "epoch": 4.9676637324596,
      "grad_norm": 4.159990310668945,
      "learning_rate": 2.517192462417955e-05,
      "loss": 0.7269,
      "step": 469250
    },
    {
      "epoch": 4.9681930542396024,
      "grad_norm": 4.0859856605529785,
      "learning_rate": 2.516927800127038e-05,
      "loss": 0.7261,
      "step": 469300
    },
    {
      "epoch": 4.968722376019606,
      "grad_norm": 3.9685845375061035,
      "learning_rate": 2.516663137836121e-05,
      "loss": 0.721,
      "step": 469350
    },
    {
      "epoch": 4.969251697799609,
      "grad_norm": 4.152381896972656,
      "learning_rate": 2.5163984755452048e-05,
      "loss": 0.7136,
      "step": 469400
    },
    {
      "epoch": 4.969781019579613,
      "grad_norm": 4.3367509841918945,
      "learning_rate": 2.516133813254288e-05,
      "loss": 0.7218,
      "step": 469450
    },
    {
      "epoch": 4.970310341359616,
      "grad_norm": 4.141163349151611,
      "learning_rate": 2.515869150963371e-05,
      "loss": 0.7356,
      "step": 469500
    },
    {
      "epoch": 4.970310341359616,
      "eval_loss": 0.4809502959251404,
      "eval_runtime": 46.7361,
      "eval_samples_per_second": 3593.15,
      "eval_steps_per_second": 449.16,
      "step": 469500
    },
    {
      "epoch": 4.9708396631396194,
      "grad_norm": 4.073263645172119,
      "learning_rate": 2.515604488672454e-05,
      "loss": 0.7368,
      "step": 469550
    },
    {
      "epoch": 4.971368984919622,
      "grad_norm": 4.280244827270508,
      "learning_rate": 2.5153398263815374e-05,
      "loss": 0.7265,
      "step": 469600
    },
    {
      "epoch": 4.971898306699626,
      "grad_norm": 3.73451566696167,
      "learning_rate": 2.5150751640906205e-05,
      "loss": 0.7168,
      "step": 469650
    },
    {
      "epoch": 4.972427628479629,
      "grad_norm": 4.433890342712402,
      "learning_rate": 2.514815795045522e-05,
      "loss": 0.7072,
      "step": 469700
    },
    {
      "epoch": 4.972956950259633,
      "grad_norm": 3.9349403381347656,
      "learning_rate": 2.514551132754605e-05,
      "loss": 0.7394,
      "step": 469750
    },
    {
      "epoch": 4.973486272039636,
      "grad_norm": 4.441351413726807,
      "learning_rate": 2.5142864704636888e-05,
      "loss": 0.7442,
      "step": 469800
    },
    {
      "epoch": 4.974015593819638,
      "grad_norm": 4.414246559143066,
      "learning_rate": 2.514021808172772e-05,
      "loss": 0.7188,
      "step": 469850
    },
    {
      "epoch": 4.974544915599642,
      "grad_norm": 3.7922070026397705,
      "learning_rate": 2.513757145881855e-05,
      "loss": 0.7277,
      "step": 469900
    },
    {
      "epoch": 4.975074237379646,
      "grad_norm": 4.079723834991455,
      "learning_rate": 2.513492483590938e-05,
      "loss": 0.7253,
      "step": 469950
    },
    {
      "epoch": 4.975603559159649,
      "grad_norm": 4.175792217254639,
      "learning_rate": 2.5132278213000214e-05,
      "loss": 0.7257,
      "step": 470000
    },
    {
      "epoch": 4.975603559159649,
      "eval_loss": 0.4778667688369751,
      "eval_runtime": 46.8002,
      "eval_samples_per_second": 3588.232,
      "eval_steps_per_second": 448.545,
      "step": 470000
    },
    {
      "epoch": 4.976132880939652,
      "grad_norm": 4.154961585998535,
      "learning_rate": 2.5129631590091045e-05,
      "loss": 0.7397,
      "step": 470050
    },
    {
      "epoch": 4.976662202719655,
      "grad_norm": 4.5945844650268555,
      "learning_rate": 2.5126984967181875e-05,
      "loss": 0.7396,
      "step": 470100
    },
    {
      "epoch": 4.977191524499658,
      "grad_norm": 4.747813701629639,
      "learning_rate": 2.5124338344272706e-05,
      "loss": 0.7302,
      "step": 470150
    },
    {
      "epoch": 4.977720846279662,
      "grad_norm": 4.707949161529541,
      "learning_rate": 2.5121691721363543e-05,
      "loss": 0.7332,
      "step": 470200
    },
    {
      "epoch": 4.978250168059665,
      "grad_norm": 4.076770305633545,
      "learning_rate": 2.5119045098454374e-05,
      "loss": 0.729,
      "step": 470250
    },
    {
      "epoch": 4.978779489839669,
      "grad_norm": 4.522966384887695,
      "learning_rate": 2.5116398475545205e-05,
      "loss": 0.731,
      "step": 470300
    },
    {
      "epoch": 4.9793088116196715,
      "grad_norm": 4.5304460525512695,
      "learning_rate": 2.5113751852636036e-05,
      "loss": 0.7132,
      "step": 470350
    },
    {
      "epoch": 4.979838133399675,
      "grad_norm": 4.5250654220581055,
      "learning_rate": 2.5111105229726873e-05,
      "loss": 0.7304,
      "step": 470400
    },
    {
      "epoch": 4.980367455179678,
      "grad_norm": 4.675051212310791,
      "learning_rate": 2.5108458606817704e-05,
      "loss": 0.727,
      "step": 470450
    },
    {
      "epoch": 4.980896776959682,
      "grad_norm": 3.9515528678894043,
      "learning_rate": 2.5105811983908535e-05,
      "loss": 0.7339,
      "step": 470500
    },
    {
      "epoch": 4.980896776959682,
      "eval_loss": 0.4790744185447693,
      "eval_runtime": 46.9813,
      "eval_samples_per_second": 3574.403,
      "eval_steps_per_second": 446.816,
      "step": 470500
    },
    {
      "epoch": 4.981426098739685,
      "grad_norm": 3.891678810119629,
      "learning_rate": 2.5103165360999365e-05,
      "loss": 0.7209,
      "step": 470550
    },
    {
      "epoch": 4.981955420519688,
      "grad_norm": 4.316888809204102,
      "learning_rate": 2.51005187380902e-05,
      "loss": 0.7311,
      "step": 470600
    },
    {
      "epoch": 4.982484742299691,
      "grad_norm": 4.037059307098389,
      "learning_rate": 2.509787211518103e-05,
      "loss": 0.7221,
      "step": 470650
    },
    {
      "epoch": 4.983014064079695,
      "grad_norm": 4.333138465881348,
      "learning_rate": 2.509522549227186e-05,
      "loss": 0.733,
      "step": 470700
    },
    {
      "epoch": 4.983543385859698,
      "grad_norm": 4.293965816497803,
      "learning_rate": 2.509257886936269e-05,
      "loss": 0.7178,
      "step": 470750
    },
    {
      "epoch": 4.984072707639701,
      "grad_norm": 4.114407062530518,
      "learning_rate": 2.508993224645353e-05,
      "loss": 0.7174,
      "step": 470800
    },
    {
      "epoch": 4.984602029419705,
      "grad_norm": 4.37769889831543,
      "learning_rate": 2.508728562354436e-05,
      "loss": 0.7337,
      "step": 470850
    },
    {
      "epoch": 4.9851313511997075,
      "grad_norm": 4.310875415802002,
      "learning_rate": 2.508463900063519e-05,
      "loss": 0.7196,
      "step": 470900
    },
    {
      "epoch": 4.985660672979711,
      "grad_norm": 4.177337169647217,
      "learning_rate": 2.508199237772602e-05,
      "loss": 0.7391,
      "step": 470950
    },
    {
      "epoch": 4.986189994759714,
      "grad_norm": 4.010585308074951,
      "learning_rate": 2.507934575481686e-05,
      "loss": 0.7104,
      "step": 471000
    },
    {
      "epoch": 4.986189994759714,
      "eval_loss": 0.47763943672180176,
      "eval_runtime": 46.8122,
      "eval_samples_per_second": 3587.314,
      "eval_steps_per_second": 448.43,
      "step": 471000
    },
    {
      "epoch": 4.986719316539718,
      "grad_norm": 4.103366851806641,
      "learning_rate": 2.507669913190769e-05,
      "loss": 0.73,
      "step": 471050
    },
    {
      "epoch": 4.987248638319721,
      "grad_norm": 4.348256587982178,
      "learning_rate": 2.507405250899852e-05,
      "loss": 0.7191,
      "step": 471100
    },
    {
      "epoch": 4.9877779600997245,
      "grad_norm": 4.117913722991943,
      "learning_rate": 2.507140588608935e-05,
      "loss": 0.7164,
      "step": 471150
    },
    {
      "epoch": 4.988307281879727,
      "grad_norm": 4.384671211242676,
      "learning_rate": 2.5068759263180185e-05,
      "loss": 0.7191,
      "step": 471200
    },
    {
      "epoch": 4.988836603659731,
      "grad_norm": 3.96854305267334,
      "learning_rate": 2.5066112640271016e-05,
      "loss": 0.7175,
      "step": 471250
    },
    {
      "epoch": 4.989365925439734,
      "grad_norm": 4.060473442077637,
      "learning_rate": 2.5063466017361846e-05,
      "loss": 0.7254,
      "step": 471300
    },
    {
      "epoch": 4.989895247219737,
      "grad_norm": 4.062210559844971,
      "learning_rate": 2.5060819394452677e-05,
      "loss": 0.7296,
      "step": 471350
    },
    {
      "epoch": 4.990424568999741,
      "grad_norm": 3.974621534347534,
      "learning_rate": 2.5058172771543514e-05,
      "loss": 0.7284,
      "step": 471400
    },
    {
      "epoch": 4.990953890779744,
      "grad_norm": 4.396048545837402,
      "learning_rate": 2.5055526148634345e-05,
      "loss": 0.7374,
      "step": 471450
    },
    {
      "epoch": 4.991483212559747,
      "grad_norm": 4.244518280029297,
      "learning_rate": 2.5052879525725176e-05,
      "loss": 0.7272,
      "step": 471500
    },
    {
      "epoch": 4.991483212559747,
      "eval_loss": 0.477497935295105,
      "eval_runtime": 46.9196,
      "eval_samples_per_second": 3579.101,
      "eval_steps_per_second": 447.404,
      "step": 471500
    },
    {
      "epoch": 4.99201253433975,
      "grad_norm": 4.459685802459717,
      "learning_rate": 2.5050232902816007e-05,
      "loss": 0.723,
      "step": 471550
    },
    {
      "epoch": 4.992541856119754,
      "grad_norm": 4.328647136688232,
      "learning_rate": 2.5047586279906844e-05,
      "loss": 0.7276,
      "step": 471600
    },
    {
      "epoch": 4.993071177899757,
      "grad_norm": 4.259835243225098,
      "learning_rate": 2.5044939656997675e-05,
      "loss": 0.7275,
      "step": 471650
    },
    {
      "epoch": 4.9936004996797605,
      "grad_norm": 4.314902305603027,
      "learning_rate": 2.5042345966546686e-05,
      "loss": 0.7386,
      "step": 471700
    },
    {
      "epoch": 4.994129821459763,
      "grad_norm": 4.767035007476807,
      "learning_rate": 2.5039699343637517e-05,
      "loss": 0.7338,
      "step": 471750
    },
    {
      "epoch": 4.994659143239767,
      "grad_norm": 4.762462139129639,
      "learning_rate": 2.5037052720728354e-05,
      "loss": 0.7233,
      "step": 471800
    },
    {
      "epoch": 4.99518846501977,
      "grad_norm": 4.387960433959961,
      "learning_rate": 2.5034406097819185e-05,
      "loss": 0.7316,
      "step": 471850
    },
    {
      "epoch": 4.995717786799774,
      "grad_norm": 4.160930156707764,
      "learning_rate": 2.5031759474910016e-05,
      "loss": 0.7155,
      "step": 471900
    },
    {
      "epoch": 4.996247108579777,
      "grad_norm": 4.496904373168945,
      "learning_rate": 2.5029112852000846e-05,
      "loss": 0.7263,
      "step": 471950
    },
    {
      "epoch": 4.99677643035978,
      "grad_norm": 4.342928886413574,
      "learning_rate": 2.5026466229091684e-05,
      "loss": 0.7288,
      "step": 472000
    },
    {
      "epoch": 4.99677643035978,
      "eval_loss": 0.47849830985069275,
      "eval_runtime": 46.7828,
      "eval_samples_per_second": 3589.566,
      "eval_steps_per_second": 448.712,
      "step": 472000
    },
    {
      "epoch": 4.997305752139783,
      "grad_norm": 4.701725959777832,
      "learning_rate": 2.5023819606182515e-05,
      "loss": 0.7356,
      "step": 472050
    },
    {
      "epoch": 4.997835073919786,
      "grad_norm": 4.7322797775268555,
      "learning_rate": 2.5021172983273345e-05,
      "loss": 0.7222,
      "step": 472100
    },
    {
      "epoch": 4.99836439569979,
      "grad_norm": 4.151986122131348,
      "learning_rate": 2.5018526360364176e-05,
      "loss": 0.7259,
      "step": 472150
    },
    {
      "epoch": 4.998893717479794,
      "grad_norm": 3.9438536167144775,
      "learning_rate": 2.501587973745501e-05,
      "loss": 0.7298,
      "step": 472200
    },
    {
      "epoch": 4.9994230392597965,
      "grad_norm": 4.098765850067139,
      "learning_rate": 2.501323311454584e-05,
      "loss": 0.7285,
      "step": 472250
    },
    {
      "epoch": 4.999952361039799,
      "grad_norm": 4.383487701416016,
      "learning_rate": 2.501058649163667e-05,
      "loss": 0.7249,
      "step": 472300
    },
    {
      "epoch": 5.000476389602003,
      "grad_norm": 4.057528495788574,
      "learning_rate": 2.5007939868727502e-05,
      "loss": 0.7027,
      "step": 472350
    },
    {
      "epoch": 5.001005711382006,
      "grad_norm": 4.235307216644287,
      "learning_rate": 2.500529324581834e-05,
      "loss": 0.7186,
      "step": 472400
    },
    {
      "epoch": 5.00153503316201,
      "grad_norm": 4.390863418579102,
      "learning_rate": 2.500264662290917e-05,
      "loss": 0.7151,
      "step": 472450
    },
    {
      "epoch": 5.0020643549420125,
      "grad_norm": 4.262141704559326,
      "learning_rate": 2.5e-05,
      "loss": 0.7173,
      "step": 472500
    },
    {
      "epoch": 5.0020643549420125,
      "eval_loss": 0.4772094488143921,
      "eval_runtime": 46.8161,
      "eval_samples_per_second": 3587.011,
      "eval_steps_per_second": 448.392,
      "step": 472500
    },
    {
      "epoch": 5.002593676722016,
      "grad_norm": 4.439311981201172,
      "learning_rate": 2.4997353377090832e-05,
      "loss": 0.7167,
      "step": 472550
    },
    {
      "epoch": 5.003122998502019,
      "grad_norm": 4.493383884429932,
      "learning_rate": 2.4994706754181666e-05,
      "loss": 0.7137,
      "step": 472600
    },
    {
      "epoch": 5.003652320282023,
      "grad_norm": 4.350980281829834,
      "learning_rate": 2.4992060131272497e-05,
      "loss": 0.7246,
      "step": 472650
    },
    {
      "epoch": 5.004181642062026,
      "grad_norm": 4.32239294052124,
      "learning_rate": 2.498941350836333e-05,
      "loss": 0.7243,
      "step": 472700
    },
    {
      "epoch": 5.0047109638420295,
      "grad_norm": 4.362125873565674,
      "learning_rate": 2.498676688545416e-05,
      "loss": 0.7129,
      "step": 472750
    },
    {
      "epoch": 5.005240285622032,
      "grad_norm": 3.7860991954803467,
      "learning_rate": 2.4984120262544992e-05,
      "loss": 0.7283,
      "step": 472800
    },
    {
      "epoch": 5.005769607402036,
      "grad_norm": 3.7977712154388428,
      "learning_rate": 2.4981473639635823e-05,
      "loss": 0.7103,
      "step": 472850
    },
    {
      "epoch": 5.006298929182039,
      "grad_norm": 4.404760360717773,
      "learning_rate": 2.4978827016726657e-05,
      "loss": 0.7251,
      "step": 472900
    },
    {
      "epoch": 5.006828250962043,
      "grad_norm": 4.155025005340576,
      "learning_rate": 2.4976180393817488e-05,
      "loss": 0.7208,
      "step": 472950
    },
    {
      "epoch": 5.007357572742046,
      "grad_norm": 4.075077533721924,
      "learning_rate": 2.4973533770908322e-05,
      "loss": 0.7318,
      "step": 473000
    },
    {
      "epoch": 5.007357572742046,
      "eval_loss": 0.4789089858531952,
      "eval_runtime": 46.713,
      "eval_samples_per_second": 3594.931,
      "eval_steps_per_second": 449.382,
      "step": 473000
    },
    {
      "epoch": 5.0078868945220485,
      "grad_norm": 4.491512775421143,
      "learning_rate": 2.4970887147999153e-05,
      "loss": 0.7252,
      "step": 473050
    },
    {
      "epoch": 5.008416216302052,
      "grad_norm": 4.385743618011475,
      "learning_rate": 2.4968240525089987e-05,
      "loss": 0.7265,
      "step": 473100
    },
    {
      "epoch": 5.008945538082055,
      "grad_norm": 4.46504020690918,
      "learning_rate": 2.4965593902180817e-05,
      "loss": 0.7139,
      "step": 473150
    },
    {
      "epoch": 5.009474859862059,
      "grad_norm": 4.068988800048828,
      "learning_rate": 2.496294727927165e-05,
      "loss": 0.7228,
      "step": 473200
    },
    {
      "epoch": 5.010004181642062,
      "grad_norm": 4.2464919090271,
      "learning_rate": 2.4960300656362482e-05,
      "loss": 0.728,
      "step": 473250
    },
    {
      "epoch": 5.0105335034220655,
      "grad_norm": 4.135723114013672,
      "learning_rate": 2.4957654033453316e-05,
      "loss": 0.7179,
      "step": 473300
    },
    {
      "epoch": 5.011062825202068,
      "grad_norm": 4.2681403160095215,
      "learning_rate": 2.4955007410544147e-05,
      "loss": 0.7273,
      "step": 473350
    },
    {
      "epoch": 5.011592146982072,
      "grad_norm": 4.439168453216553,
      "learning_rate": 2.4952360787634978e-05,
      "loss": 0.7211,
      "step": 473400
    },
    {
      "epoch": 5.012121468762075,
      "grad_norm": 3.8428661823272705,
      "learning_rate": 2.494971416472581e-05,
      "loss": 0.7141,
      "step": 473450
    },
    {
      "epoch": 5.012650790542079,
      "grad_norm": 4.112518787384033,
      "learning_rate": 2.4947067541816643e-05,
      "loss": 0.7268,
      "step": 473500
    },
    {
      "epoch": 5.012650790542079,
      "eval_loss": 0.47863173484802246,
      "eval_runtime": 47.023,
      "eval_samples_per_second": 3571.235,
      "eval_steps_per_second": 446.42,
      "step": 473500
    },
    {
      "epoch": 5.013180112322082,
      "grad_norm": 4.530980587005615,
      "learning_rate": 2.4944420918907473e-05,
      "loss": 0.7181,
      "step": 473550
    },
    {
      "epoch": 5.013709434102085,
      "grad_norm": 4.337420463562012,
      "learning_rate": 2.4941774295998307e-05,
      "loss": 0.7201,
      "step": 473600
    },
    {
      "epoch": 5.014238755882088,
      "grad_norm": 4.353339672088623,
      "learning_rate": 2.4939127673089138e-05,
      "loss": 0.7151,
      "step": 473650
    },
    {
      "epoch": 5.014768077662092,
      "grad_norm": 3.8782949447631836,
      "learning_rate": 2.4936533982638156e-05,
      "loss": 0.711,
      "step": 473700
    },
    {
      "epoch": 5.015297399442095,
      "grad_norm": 4.251032829284668,
      "learning_rate": 2.4933887359728987e-05,
      "loss": 0.7294,
      "step": 473750
    },
    {
      "epoch": 5.015826721222098,
      "grad_norm": 4.4643449783325195,
      "learning_rate": 2.4931240736819818e-05,
      "loss": 0.7206,
      "step": 473800
    },
    {
      "epoch": 5.0163560430021015,
      "grad_norm": 4.574725151062012,
      "learning_rate": 2.4928594113910648e-05,
      "loss": 0.7282,
      "step": 473850
    },
    {
      "epoch": 5.016885364782104,
      "grad_norm": 4.296572685241699,
      "learning_rate": 2.4925947491001482e-05,
      "loss": 0.7189,
      "step": 473900
    },
    {
      "epoch": 5.017414686562108,
      "grad_norm": 4.5577802658081055,
      "learning_rate": 2.4923300868092313e-05,
      "loss": 0.7111,
      "step": 473950
    },
    {
      "epoch": 5.017944008342111,
      "grad_norm": 4.5629563331604,
      "learning_rate": 2.4920654245183147e-05,
      "loss": 0.7172,
      "step": 474000
    },
    {
      "epoch": 5.017944008342111,
      "eval_loss": 0.4772109389305115,
      "eval_runtime": 46.7666,
      "eval_samples_per_second": 3590.813,
      "eval_steps_per_second": 448.868,
      "step": 474000
    },
    {
      "epoch": 5.018473330122115,
      "grad_norm": 4.087670803070068,
      "learning_rate": 2.4918007622273978e-05,
      "loss": 0.7177,
      "step": 474050
    },
    {
      "epoch": 5.019002651902118,
      "grad_norm": 4.354153156280518,
      "learning_rate": 2.4915360999364812e-05,
      "loss": 0.7292,
      "step": 474100
    },
    {
      "epoch": 5.019531973682121,
      "grad_norm": 3.7359635829925537,
      "learning_rate": 2.4912714376455643e-05,
      "loss": 0.7107,
      "step": 474150
    },
    {
      "epoch": 5.020061295462124,
      "grad_norm": 4.430324554443359,
      "learning_rate": 2.4910067753546477e-05,
      "loss": 0.7165,
      "step": 474200
    },
    {
      "epoch": 5.020590617242128,
      "grad_norm": 4.410202503204346,
      "learning_rate": 2.4907421130637308e-05,
      "loss": 0.7281,
      "step": 474250
    },
    {
      "epoch": 5.021119939022131,
      "grad_norm": 4.337016582489014,
      "learning_rate": 2.490477450772814e-05,
      "loss": 0.7169,
      "step": 474300
    },
    {
      "epoch": 5.021649260802135,
      "grad_norm": 3.918868064880371,
      "learning_rate": 2.4902127884818972e-05,
      "loss": 0.7143,
      "step": 474350
    },
    {
      "epoch": 5.0221785825821375,
      "grad_norm": 4.443653583526611,
      "learning_rate": 2.4899481261909803e-05,
      "loss": 0.7207,
      "step": 474400
    },
    {
      "epoch": 5.022707904362141,
      "grad_norm": 4.107517719268799,
      "learning_rate": 2.4896834639000634e-05,
      "loss": 0.7238,
      "step": 474450
    },
    {
      "epoch": 5.023237226142144,
      "grad_norm": 4.309278964996338,
      "learning_rate": 2.4894188016091468e-05,
      "loss": 0.721,
      "step": 474500
    },
    {
      "epoch": 5.023237226142144,
      "eval_loss": 0.47783511877059937,
      "eval_runtime": 46.8446,
      "eval_samples_per_second": 3584.831,
      "eval_steps_per_second": 448.12,
      "step": 474500
    },
    {
      "epoch": 5.023766547922147,
      "grad_norm": 4.455761909484863,
      "learning_rate": 2.48915413931823e-05,
      "loss": 0.7241,
      "step": 474550
    },
    {
      "epoch": 5.024295869702151,
      "grad_norm": 4.321926116943359,
      "learning_rate": 2.4888894770273133e-05,
      "loss": 0.717,
      "step": 474600
    },
    {
      "epoch": 5.024825191482154,
      "grad_norm": 4.41100549697876,
      "learning_rate": 2.4886248147363963e-05,
      "loss": 0.7174,
      "step": 474650
    },
    {
      "epoch": 5.025354513262157,
      "grad_norm": 4.2316203117370605,
      "learning_rate": 2.4883601524454797e-05,
      "loss": 0.7176,
      "step": 474700
    },
    {
      "epoch": 5.02588383504216,
      "grad_norm": 4.177448749542236,
      "learning_rate": 2.4880954901545628e-05,
      "loss": 0.7179,
      "step": 474750
    },
    {
      "epoch": 5.026413156822164,
      "grad_norm": 4.122503757476807,
      "learning_rate": 2.4878308278636462e-05,
      "loss": 0.7275,
      "step": 474800
    },
    {
      "epoch": 5.026942478602167,
      "grad_norm": 3.8552327156066895,
      "learning_rate": 2.4875661655727293e-05,
      "loss": 0.715,
      "step": 474850
    },
    {
      "epoch": 5.027471800382171,
      "grad_norm": 4.1188883781433105,
      "learning_rate": 2.4873015032818127e-05,
      "loss": 0.7267,
      "step": 474900
    },
    {
      "epoch": 5.028001122162173,
      "grad_norm": 4.373752117156982,
      "learning_rate": 2.4870368409908958e-05,
      "loss": 0.7155,
      "step": 474950
    },
    {
      "epoch": 5.028530443942177,
      "grad_norm": 4.637859344482422,
      "learning_rate": 2.486772178699979e-05,
      "loss": 0.7233,
      "step": 475000
    },
    {
      "epoch": 5.028530443942177,
      "eval_loss": 0.4762759804725647,
      "eval_runtime": 46.8841,
      "eval_samples_per_second": 3581.814,
      "eval_steps_per_second": 447.743,
      "step": 475000
    },
    {
      "epoch": 5.02905976572218,
      "grad_norm": 3.9510440826416016,
      "learning_rate": 2.486507516409062e-05,
      "loss": 0.7217,
      "step": 475050
    },
    {
      "epoch": 5.029589087502184,
      "grad_norm": 4.236252307891846,
      "learning_rate": 2.4862428541181453e-05,
      "loss": 0.7205,
      "step": 475100
    },
    {
      "epoch": 5.030118409282187,
      "grad_norm": 4.730312824249268,
      "learning_rate": 2.4859781918272284e-05,
      "loss": 0.7249,
      "step": 475150
    },
    {
      "epoch": 5.03064773106219,
      "grad_norm": 4.034948348999023,
      "learning_rate": 2.4857135295363118e-05,
      "loss": 0.734,
      "step": 475200
    },
    {
      "epoch": 5.031177052842193,
      "grad_norm": 4.136282920837402,
      "learning_rate": 2.485448867245395e-05,
      "loss": 0.7239,
      "step": 475250
    },
    {
      "epoch": 5.031706374622196,
      "grad_norm": 4.727460861206055,
      "learning_rate": 2.4851842049544783e-05,
      "loss": 0.7283,
      "step": 475300
    },
    {
      "epoch": 5.0322356964022,
      "grad_norm": 4.254971981048584,
      "learning_rate": 2.4849195426635614e-05,
      "loss": 0.734,
      "step": 475350
    },
    {
      "epoch": 5.032765018182203,
      "grad_norm": 4.242844104766846,
      "learning_rate": 2.4846548803726448e-05,
      "loss": 0.7112,
      "step": 475400
    },
    {
      "epoch": 5.0332943399622065,
      "grad_norm": 4.17938756942749,
      "learning_rate": 2.484390218081728e-05,
      "loss": 0.7178,
      "step": 475450
    },
    {
      "epoch": 5.033823661742209,
      "grad_norm": 4.3409552574157715,
      "learning_rate": 2.484125555790811e-05,
      "loss": 0.7157,
      "step": 475500
    },
    {
      "epoch": 5.033823661742209,
      "eval_loss": 0.47658050060272217,
      "eval_runtime": 46.7936,
      "eval_samples_per_second": 3588.742,
      "eval_steps_per_second": 448.609,
      "step": 475500
    },
    {
      "epoch": 5.034352983522213,
      "grad_norm": 4.304862022399902,
      "learning_rate": 2.483860893499894e-05,
      "loss": 0.7292,
      "step": 475550
    },
    {
      "epoch": 5.034882305302216,
      "grad_norm": 4.469487190246582,
      "learning_rate": 2.4835962312089774e-05,
      "loss": 0.7154,
      "step": 475600
    },
    {
      "epoch": 5.03541162708222,
      "grad_norm": 4.291687965393066,
      "learning_rate": 2.4833315689180605e-05,
      "loss": 0.7151,
      "step": 475650
    },
    {
      "epoch": 5.035940948862223,
      "grad_norm": 4.285683631896973,
      "learning_rate": 2.4830721998729623e-05,
      "loss": 0.7187,
      "step": 475700
    },
    {
      "epoch": 5.036470270642226,
      "grad_norm": 3.718456983566284,
      "learning_rate": 2.4828075375820454e-05,
      "loss": 0.7302,
      "step": 475750
    },
    {
      "epoch": 5.036999592422229,
      "grad_norm": 4.010456562042236,
      "learning_rate": 2.4825428752911288e-05,
      "loss": 0.7177,
      "step": 475800
    },
    {
      "epoch": 5.037528914202233,
      "grad_norm": 4.211907386779785,
      "learning_rate": 2.482278213000212e-05,
      "loss": 0.7223,
      "step": 475850
    },
    {
      "epoch": 5.038058235982236,
      "grad_norm": 4.7966437339782715,
      "learning_rate": 2.4820135507092952e-05,
      "loss": 0.7157,
      "step": 475900
    },
    {
      "epoch": 5.03858755776224,
      "grad_norm": 4.282172679901123,
      "learning_rate": 2.4817488884183783e-05,
      "loss": 0.716,
      "step": 475950
    },
    {
      "epoch": 5.0391168795422425,
      "grad_norm": 4.426885604858398,
      "learning_rate": 2.4814842261274614e-05,
      "loss": 0.7238,
      "step": 476000
    },
    {
      "epoch": 5.0391168795422425,
      "eval_loss": 0.4748314619064331,
      "eval_runtime": 46.7848,
      "eval_samples_per_second": 3589.415,
      "eval_steps_per_second": 448.693,
      "step": 476000
    },
    {
      "epoch": 5.039646201322245,
      "grad_norm": 4.663364887237549,
      "learning_rate": 2.4812195638365445e-05,
      "loss": 0.7229,
      "step": 476050
    },
    {
      "epoch": 5.040175523102249,
      "grad_norm": 4.414268970489502,
      "learning_rate": 2.480954901545628e-05,
      "loss": 0.7149,
      "step": 476100
    },
    {
      "epoch": 5.040704844882252,
      "grad_norm": 4.327487945556641,
      "learning_rate": 2.480690239254711e-05,
      "loss": 0.7367,
      "step": 476150
    },
    {
      "epoch": 5.041234166662256,
      "grad_norm": 4.219353199005127,
      "learning_rate": 2.4804255769637944e-05,
      "loss": 0.7277,
      "step": 476200
    },
    {
      "epoch": 5.041763488442259,
      "grad_norm": 4.423796653747559,
      "learning_rate": 2.4801609146728774e-05,
      "loss": 0.7192,
      "step": 476250
    },
    {
      "epoch": 5.042292810222262,
      "grad_norm": 4.366684913635254,
      "learning_rate": 2.479896252381961e-05,
      "loss": 0.714,
      "step": 476300
    },
    {
      "epoch": 5.042822132002265,
      "grad_norm": 4.288923263549805,
      "learning_rate": 2.479631590091044e-05,
      "loss": 0.7279,
      "step": 476350
    },
    {
      "epoch": 5.043351453782269,
      "grad_norm": 4.439103603363037,
      "learning_rate": 2.4793669278001273e-05,
      "loss": 0.716,
      "step": 476400
    },
    {
      "epoch": 5.043880775562272,
      "grad_norm": 4.488668918609619,
      "learning_rate": 2.4791022655092104e-05,
      "loss": 0.7211,
      "step": 476450
    },
    {
      "epoch": 5.044410097342276,
      "grad_norm": 4.146139144897461,
      "learning_rate": 2.4788376032182935e-05,
      "loss": 0.7187,
      "step": 476500
    },
    {
      "epoch": 5.044410097342276,
      "eval_loss": 0.47684329748153687,
      "eval_runtime": 46.8169,
      "eval_samples_per_second": 3586.955,
      "eval_steps_per_second": 448.385,
      "step": 476500
    },
    {
      "epoch": 5.0449394191222785,
      "grad_norm": 3.8801822662353516,
      "learning_rate": 2.4785729409273765e-05,
      "loss": 0.7246,
      "step": 476550
    },
    {
      "epoch": 5.045468740902282,
      "grad_norm": 4.707900524139404,
      "learning_rate": 2.47830827863646e-05,
      "loss": 0.7168,
      "step": 476600
    },
    {
      "epoch": 5.045998062682285,
      "grad_norm": 4.744385719299316,
      "learning_rate": 2.478043616345543e-05,
      "loss": 0.7205,
      "step": 476650
    },
    {
      "epoch": 5.046527384462289,
      "grad_norm": 4.3858513832092285,
      "learning_rate": 2.4777789540546264e-05,
      "loss": 0.7112,
      "step": 476700
    },
    {
      "epoch": 5.047056706242292,
      "grad_norm": 3.7896552085876465,
      "learning_rate": 2.4775142917637095e-05,
      "loss": 0.7078,
      "step": 476750
    },
    {
      "epoch": 5.047586028022295,
      "grad_norm": 4.1224493980407715,
      "learning_rate": 2.477249629472793e-05,
      "loss": 0.7103,
      "step": 476800
    },
    {
      "epoch": 5.048115349802298,
      "grad_norm": 4.294456481933594,
      "learning_rate": 2.476984967181876e-05,
      "loss": 0.7138,
      "step": 476850
    },
    {
      "epoch": 5.048644671582301,
      "grad_norm": 4.449466705322266,
      "learning_rate": 2.4767203048909594e-05,
      "loss": 0.7281,
      "step": 476900
    },
    {
      "epoch": 5.049173993362305,
      "grad_norm": 4.087087631225586,
      "learning_rate": 2.4764556426000425e-05,
      "loss": 0.715,
      "step": 476950
    },
    {
      "epoch": 5.049703315142308,
      "grad_norm": 4.188782215118408,
      "learning_rate": 2.476190980309126e-05,
      "loss": 0.7151,
      "step": 477000
    },
    {
      "epoch": 5.049703315142308,
      "eval_loss": 0.4749583601951599,
      "eval_runtime": 46.7179,
      "eval_samples_per_second": 3594.551,
      "eval_steps_per_second": 449.335,
      "step": 477000
    },
    {
      "epoch": 5.050232636922312,
      "grad_norm": 4.09997034072876,
      "learning_rate": 2.475926318018209e-05,
      "loss": 0.707,
      "step": 477050
    },
    {
      "epoch": 5.0507619587023145,
      "grad_norm": 4.2444939613342285,
      "learning_rate": 2.475661655727292e-05,
      "loss": 0.7252,
      "step": 477100
    },
    {
      "epoch": 5.051291280482318,
      "grad_norm": 4.50015115737915,
      "learning_rate": 2.475396993436375e-05,
      "loss": 0.7205,
      "step": 477150
    },
    {
      "epoch": 5.051820602262321,
      "grad_norm": 4.354849815368652,
      "learning_rate": 2.4751323311454585e-05,
      "loss": 0.7252,
      "step": 477200
    },
    {
      "epoch": 5.052349924042325,
      "grad_norm": 4.145562171936035,
      "learning_rate": 2.4748676688545416e-05,
      "loss": 0.7227,
      "step": 477250
    },
    {
      "epoch": 5.052879245822328,
      "grad_norm": 4.2814741134643555,
      "learning_rate": 2.474603006563625e-05,
      "loss": 0.715,
      "step": 477300
    },
    {
      "epoch": 5.0534085676023315,
      "grad_norm": 4.732924938201904,
      "learning_rate": 2.474338344272708e-05,
      "loss": 0.71,
      "step": 477350
    },
    {
      "epoch": 5.053937889382334,
      "grad_norm": 4.283998012542725,
      "learning_rate": 2.4740736819817914e-05,
      "loss": 0.7098,
      "step": 477400
    },
    {
      "epoch": 5.054467211162338,
      "grad_norm": 4.299798965454102,
      "learning_rate": 2.4738090196908745e-05,
      "loss": 0.7205,
      "step": 477450
    },
    {
      "epoch": 5.054996532942341,
      "grad_norm": 4.77126932144165,
      "learning_rate": 2.473544357399958e-05,
      "loss": 0.6989,
      "step": 477500
    },
    {
      "epoch": 5.054996532942341,
      "eval_loss": 0.47540026903152466,
      "eval_runtime": 46.9396,
      "eval_samples_per_second": 3577.576,
      "eval_steps_per_second": 447.213,
      "step": 477500
    },
    {
      "epoch": 5.055525854722344,
      "grad_norm": 3.792379140853882,
      "learning_rate": 2.473279695109041e-05,
      "loss": 0.7227,
      "step": 477550
    },
    {
      "epoch": 5.056055176502348,
      "grad_norm": 4.2699971199035645,
      "learning_rate": 2.4730150328181244e-05,
      "loss": 0.7273,
      "step": 477600
    },
    {
      "epoch": 5.0565844982823505,
      "grad_norm": 4.3970136642456055,
      "learning_rate": 2.4727503705272075e-05,
      "loss": 0.7159,
      "step": 477650
    },
    {
      "epoch": 5.057113820062354,
      "grad_norm": 4.730823040008545,
      "learning_rate": 2.472491001482109e-05,
      "loss": 0.7252,
      "step": 477700
    },
    {
      "epoch": 5.057643141842357,
      "grad_norm": 4.360062122344971,
      "learning_rate": 2.472226339191192e-05,
      "loss": 0.7204,
      "step": 477750
    },
    {
      "epoch": 5.058172463622361,
      "grad_norm": 4.136003494262695,
      "learning_rate": 2.4719616769002754e-05,
      "loss": 0.7123,
      "step": 477800
    },
    {
      "epoch": 5.058701785402364,
      "grad_norm": 4.164120197296143,
      "learning_rate": 2.4716970146093585e-05,
      "loss": 0.7138,
      "step": 477850
    },
    {
      "epoch": 5.0592311071823675,
      "grad_norm": 4.266279697418213,
      "learning_rate": 2.471432352318442e-05,
      "loss": 0.7237,
      "step": 477900
    },
    {
      "epoch": 5.05976042896237,
      "grad_norm": 4.390081882476807,
      "learning_rate": 2.471167690027525e-05,
      "loss": 0.7199,
      "step": 477950
    },
    {
      "epoch": 5.060289750742374,
      "grad_norm": 4.486384391784668,
      "learning_rate": 2.4709030277366084e-05,
      "loss": 0.7104,
      "step": 478000
    },
    {
      "epoch": 5.060289750742374,
      "eval_loss": 0.47438278794288635,
      "eval_runtime": 46.7662,
      "eval_samples_per_second": 3590.838,
      "eval_steps_per_second": 448.871,
      "step": 478000
    },
    {
      "epoch": 5.060819072522377,
      "grad_norm": 4.015047550201416,
      "learning_rate": 2.4706383654456915e-05,
      "loss": 0.7222,
      "step": 478050
    },
    {
      "epoch": 5.061348394302381,
      "grad_norm": 3.9752016067504883,
      "learning_rate": 2.4703737031547745e-05,
      "loss": 0.7159,
      "step": 478100
    },
    {
      "epoch": 5.061877716082384,
      "grad_norm": 4.198690891265869,
      "learning_rate": 2.4701090408638576e-05,
      "loss": 0.7119,
      "step": 478150
    },
    {
      "epoch": 5.062407037862387,
      "grad_norm": 4.452589511871338,
      "learning_rate": 2.469844378572941e-05,
      "loss": 0.7193,
      "step": 478200
    },
    {
      "epoch": 5.06293635964239,
      "grad_norm": 4.005354881286621,
      "learning_rate": 2.469579716282024e-05,
      "loss": 0.7064,
      "step": 478250
    },
    {
      "epoch": 5.063465681422393,
      "grad_norm": 4.422174453735352,
      "learning_rate": 2.4693150539911075e-05,
      "loss": 0.7232,
      "step": 478300
    },
    {
      "epoch": 5.063995003202397,
      "grad_norm": 4.282299518585205,
      "learning_rate": 2.4690503917001906e-05,
      "loss": 0.7121,
      "step": 478350
    },
    {
      "epoch": 5.0645243249824,
      "grad_norm": 4.616438388824463,
      "learning_rate": 2.468785729409274e-05,
      "loss": 0.7275,
      "step": 478400
    },
    {
      "epoch": 5.065053646762403,
      "grad_norm": 4.036197185516357,
      "learning_rate": 2.468521067118357e-05,
      "loss": 0.7129,
      "step": 478450
    },
    {
      "epoch": 5.065582968542406,
      "grad_norm": 4.15022087097168,
      "learning_rate": 2.4682564048274405e-05,
      "loss": 0.7224,
      "step": 478500
    },
    {
      "epoch": 5.065582968542406,
      "eval_loss": 0.4760051965713501,
      "eval_runtime": 46.808,
      "eval_samples_per_second": 3587.634,
      "eval_steps_per_second": 448.47,
      "step": 478500
    },
    {
      "epoch": 5.06611229032241,
      "grad_norm": 4.49085807800293,
      "learning_rate": 2.4679917425365235e-05,
      "loss": 0.722,
      "step": 478550
    },
    {
      "epoch": 5.066641612102413,
      "grad_norm": 4.096802234649658,
      "learning_rate": 2.467727080245607e-05,
      "loss": 0.7242,
      "step": 478600
    },
    {
      "epoch": 5.067170933882417,
      "grad_norm": 4.583816051483154,
      "learning_rate": 2.46746241795469e-05,
      "loss": 0.7223,
      "step": 478650
    },
    {
      "epoch": 5.0677002556624196,
      "grad_norm": 4.295777320861816,
      "learning_rate": 2.467197755663773e-05,
      "loss": 0.7095,
      "step": 478700
    },
    {
      "epoch": 5.068229577442423,
      "grad_norm": 4.520633697509766,
      "learning_rate": 2.466933093372856e-05,
      "loss": 0.7251,
      "step": 478750
    },
    {
      "epoch": 5.068758899222426,
      "grad_norm": 4.338415145874023,
      "learning_rate": 2.4666684310819396e-05,
      "loss": 0.7189,
      "step": 478800
    },
    {
      "epoch": 5.06928822100243,
      "grad_norm": 4.069211483001709,
      "learning_rate": 2.4664037687910226e-05,
      "loss": 0.7133,
      "step": 478850
    },
    {
      "epoch": 5.069817542782433,
      "grad_norm": 4.24436092376709,
      "learning_rate": 2.466139106500106e-05,
      "loss": 0.7277,
      "step": 478900
    },
    {
      "epoch": 5.0703468645624366,
      "grad_norm": 4.111857891082764,
      "learning_rate": 2.465874444209189e-05,
      "loss": 0.7022,
      "step": 478950
    },
    {
      "epoch": 5.070876186342439,
      "grad_norm": 4.474018573760986,
      "learning_rate": 2.4656097819182725e-05,
      "loss": 0.7137,
      "step": 479000
    },
    {
      "epoch": 5.070876186342439,
      "eval_loss": 0.4735143482685089,
      "eval_runtime": 47.2373,
      "eval_samples_per_second": 3555.032,
      "eval_steps_per_second": 444.395,
      "step": 479000
    },
    {
      "epoch": 5.071405508122442,
      "grad_norm": 4.031826019287109,
      "learning_rate": 2.4653451196273556e-05,
      "loss": 0.7213,
      "step": 479050
    },
    {
      "epoch": 5.071934829902446,
      "grad_norm": 4.4364728927612305,
      "learning_rate": 2.465080457336439e-05,
      "loss": 0.719,
      "step": 479100
    },
    {
      "epoch": 5.072464151682449,
      "grad_norm": 4.015417098999023,
      "learning_rate": 2.464815795045522e-05,
      "loss": 0.7064,
      "step": 479150
    },
    {
      "epoch": 5.072993473462453,
      "grad_norm": 4.3646039962768555,
      "learning_rate": 2.464551132754605e-05,
      "loss": 0.7283,
      "step": 479200
    },
    {
      "epoch": 5.0735227952424555,
      "grad_norm": 4.449952602386475,
      "learning_rate": 2.4642864704636882e-05,
      "loss": 0.7162,
      "step": 479250
    },
    {
      "epoch": 5.074052117022459,
      "grad_norm": 4.067128658294678,
      "learning_rate": 2.4640218081727716e-05,
      "loss": 0.7115,
      "step": 479300
    },
    {
      "epoch": 5.074581438802462,
      "grad_norm": 4.494427680969238,
      "learning_rate": 2.4637571458818547e-05,
      "loss": 0.72,
      "step": 479350
    },
    {
      "epoch": 5.075110760582466,
      "grad_norm": 4.054492473602295,
      "learning_rate": 2.463492483590938e-05,
      "loss": 0.7276,
      "step": 479400
    },
    {
      "epoch": 5.075640082362469,
      "grad_norm": 3.968334197998047,
      "learning_rate": 2.4632278213000212e-05,
      "loss": 0.7219,
      "step": 479450
    },
    {
      "epoch": 5.0761694041424725,
      "grad_norm": 4.306994915008545,
      "learning_rate": 2.4629631590091046e-05,
      "loss": 0.6932,
      "step": 479500
    },
    {
      "epoch": 5.0761694041424725,
      "eval_loss": 0.4737148582935333,
      "eval_runtime": 47.0305,
      "eval_samples_per_second": 3570.665,
      "eval_steps_per_second": 446.349,
      "step": 479500
    },
    {
      "epoch": 5.076698725922475,
      "grad_norm": 4.940512657165527,
      "learning_rate": 2.4626984967181877e-05,
      "loss": 0.7199,
      "step": 479550
    },
    {
      "epoch": 5.077228047702479,
      "grad_norm": 4.297146797180176,
      "learning_rate": 2.462433834427271e-05,
      "loss": 0.7204,
      "step": 479600
    },
    {
      "epoch": 5.077757369482482,
      "grad_norm": 4.386714458465576,
      "learning_rate": 2.462169172136354e-05,
      "loss": 0.7182,
      "step": 479650
    },
    {
      "epoch": 5.078286691262486,
      "grad_norm": 3.9296629428863525,
      "learning_rate": 2.4619098030912556e-05,
      "loss": 0.7265,
      "step": 479700
    },
    {
      "epoch": 5.078816013042489,
      "grad_norm": 4.494450092315674,
      "learning_rate": 2.4616451408003387e-05,
      "loss": 0.7149,
      "step": 479750
    },
    {
      "epoch": 5.0793453348224915,
      "grad_norm": 4.300411224365234,
      "learning_rate": 2.461380478509422e-05,
      "loss": 0.7291,
      "step": 479800
    },
    {
      "epoch": 5.079874656602495,
      "grad_norm": 3.871077537536621,
      "learning_rate": 2.4611158162185052e-05,
      "loss": 0.7032,
      "step": 479850
    },
    {
      "epoch": 5.080403978382498,
      "grad_norm": 4.121483325958252,
      "learning_rate": 2.4608511539275886e-05,
      "loss": 0.711,
      "step": 479900
    },
    {
      "epoch": 5.080933300162502,
      "grad_norm": 4.164252281188965,
      "learning_rate": 2.4605864916366717e-05,
      "loss": 0.7163,
      "step": 479950
    },
    {
      "epoch": 5.081462621942505,
      "grad_norm": 4.200754642486572,
      "learning_rate": 2.460321829345755e-05,
      "loss": 0.7071,
      "step": 480000
    },
    {
      "epoch": 5.081462621942505,
      "eval_loss": 0.4742298126220703,
      "eval_runtime": 46.6926,
      "eval_samples_per_second": 3596.501,
      "eval_steps_per_second": 449.579,
      "step": 480000
    },
    {
      "epoch": 5.0819919437225085,
      "grad_norm": 4.473814964294434,
      "learning_rate": 2.460057167054838e-05,
      "loss": 0.7222,
      "step": 480050
    },
    {
      "epoch": 5.082521265502511,
      "grad_norm": 4.427260875701904,
      "learning_rate": 2.4597925047639215e-05,
      "loss": 0.7274,
      "step": 480100
    },
    {
      "epoch": 5.083050587282515,
      "grad_norm": 3.817949056625366,
      "learning_rate": 2.4595278424730046e-05,
      "loss": 0.7177,
      "step": 480150
    },
    {
      "epoch": 5.083579909062518,
      "grad_norm": 4.366151332855225,
      "learning_rate": 2.4592631801820877e-05,
      "loss": 0.7165,
      "step": 480200
    },
    {
      "epoch": 5.084109230842522,
      "grad_norm": 4.334967136383057,
      "learning_rate": 2.4589985178911708e-05,
      "loss": 0.718,
      "step": 480250
    },
    {
      "epoch": 5.084638552622525,
      "grad_norm": 4.313018321990967,
      "learning_rate": 2.458733855600254e-05,
      "loss": 0.7247,
      "step": 480300
    },
    {
      "epoch": 5.085167874402528,
      "grad_norm": 4.598323822021484,
      "learning_rate": 2.4584691933093372e-05,
      "loss": 0.7126,
      "step": 480350
    },
    {
      "epoch": 5.085697196182531,
      "grad_norm": 4.297520160675049,
      "learning_rate": 2.4582045310184206e-05,
      "loss": 0.7191,
      "step": 480400
    },
    {
      "epoch": 5.086226517962535,
      "grad_norm": 4.506511211395264,
      "learning_rate": 2.4579398687275037e-05,
      "loss": 0.7202,
      "step": 480450
    },
    {
      "epoch": 5.086755839742538,
      "grad_norm": 4.200692653656006,
      "learning_rate": 2.457675206436587e-05,
      "loss": 0.7223,
      "step": 480500
    },
    {
      "epoch": 5.086755839742538,
      "eval_loss": 0.4763699769973755,
      "eval_runtime": 46.7582,
      "eval_samples_per_second": 3591.452,
      "eval_steps_per_second": 448.948,
      "step": 480500
    },
    {
      "epoch": 5.087285161522541,
      "grad_norm": 4.119268417358398,
      "learning_rate": 2.4574105441456702e-05,
      "loss": 0.7314,
      "step": 480550
    },
    {
      "epoch": 5.0878144833025445,
      "grad_norm": 4.300178527832031,
      "learning_rate": 2.4571458818547536e-05,
      "loss": 0.719,
      "step": 480600
    },
    {
      "epoch": 5.088343805082547,
      "grad_norm": 4.4148406982421875,
      "learning_rate": 2.4568812195638367e-05,
      "loss": 0.7284,
      "step": 480650
    },
    {
      "epoch": 5.088873126862551,
      "grad_norm": 4.201965808868408,
      "learning_rate": 2.45661655727292e-05,
      "loss": 0.7311,
      "step": 480700
    },
    {
      "epoch": 5.089402448642554,
      "grad_norm": 4.7149200439453125,
      "learning_rate": 2.456351894982003e-05,
      "loss": 0.7251,
      "step": 480750
    },
    {
      "epoch": 5.089931770422558,
      "grad_norm": 4.235297679901123,
      "learning_rate": 2.4560872326910862e-05,
      "loss": 0.7241,
      "step": 480800
    },
    {
      "epoch": 5.090461092202561,
      "grad_norm": 4.578495502471924,
      "learning_rate": 2.4558225704001693e-05,
      "loss": 0.7222,
      "step": 480850
    },
    {
      "epoch": 5.090990413982564,
      "grad_norm": 4.653253555297852,
      "learning_rate": 2.4555579081092527e-05,
      "loss": 0.7264,
      "step": 480900
    },
    {
      "epoch": 5.091519735762567,
      "grad_norm": 4.054655075073242,
      "learning_rate": 2.4552932458183358e-05,
      "loss": 0.7146,
      "step": 480950
    },
    {
      "epoch": 5.092049057542571,
      "grad_norm": 4.14139461517334,
      "learning_rate": 2.4550285835274192e-05,
      "loss": 0.7102,
      "step": 481000
    },
    {
      "epoch": 5.092049057542571,
      "eval_loss": 0.473358690738678,
      "eval_runtime": 46.7821,
      "eval_samples_per_second": 3589.622,
      "eval_steps_per_second": 448.719,
      "step": 481000
    },
    {
      "epoch": 5.092578379322574,
      "grad_norm": 4.050866603851318,
      "learning_rate": 2.4547639212365023e-05,
      "loss": 0.7054,
      "step": 481050
    },
    {
      "epoch": 5.093107701102578,
      "grad_norm": 4.001132965087891,
      "learning_rate": 2.4544992589455857e-05,
      "loss": 0.7123,
      "step": 481100
    },
    {
      "epoch": 5.0936370228825805,
      "grad_norm": 4.5715250968933105,
      "learning_rate": 2.4542345966546687e-05,
      "loss": 0.7203,
      "step": 481150
    },
    {
      "epoch": 5.094166344662584,
      "grad_norm": 4.296536922454834,
      "learning_rate": 2.453969934363752e-05,
      "loss": 0.7281,
      "step": 481200
    },
    {
      "epoch": 5.094695666442587,
      "grad_norm": 4.321032524108887,
      "learning_rate": 2.4537052720728352e-05,
      "loss": 0.7208,
      "step": 481250
    },
    {
      "epoch": 5.09522498822259,
      "grad_norm": 4.077810287475586,
      "learning_rate": 2.4534406097819186e-05,
      "loss": 0.7117,
      "step": 481300
    },
    {
      "epoch": 5.095754310002594,
      "grad_norm": 4.390193939208984,
      "learning_rate": 2.4531759474910017e-05,
      "loss": 0.7254,
      "step": 481350
    },
    {
      "epoch": 5.096283631782597,
      "grad_norm": 4.040715217590332,
      "learning_rate": 2.4529112852000848e-05,
      "loss": 0.7102,
      "step": 481400
    },
    {
      "epoch": 5.0968129535626,
      "grad_norm": 4.549117565155029,
      "learning_rate": 2.452646622909168e-05,
      "loss": 0.7276,
      "step": 481450
    },
    {
      "epoch": 5.097342275342603,
      "grad_norm": 4.2646260261535645,
      "learning_rate": 2.4523819606182513e-05,
      "loss": 0.7185,
      "step": 481500
    },
    {
      "epoch": 5.097342275342603,
      "eval_loss": 0.4734278619289398,
      "eval_runtime": 46.8561,
      "eval_samples_per_second": 3583.952,
      "eval_steps_per_second": 448.01,
      "step": 481500
    },
    {
      "epoch": 5.097871597122607,
      "grad_norm": 4.416114330291748,
      "learning_rate": 2.4521172983273343e-05,
      "loss": 0.7224,
      "step": 481550
    },
    {
      "epoch": 5.09840091890261,
      "grad_norm": 4.451285362243652,
      "learning_rate": 2.4518526360364177e-05,
      "loss": 0.7176,
      "step": 481600
    },
    {
      "epoch": 5.098930240682614,
      "grad_norm": 4.4442572593688965,
      "learning_rate": 2.4515879737455008e-05,
      "loss": 0.7242,
      "step": 481650
    },
    {
      "epoch": 5.0994595624626164,
      "grad_norm": 4.1287031173706055,
      "learning_rate": 2.4513286047004026e-05,
      "loss": 0.7167,
      "step": 481700
    },
    {
      "epoch": 5.09998888424262,
      "grad_norm": 4.118087291717529,
      "learning_rate": 2.4510639424094857e-05,
      "loss": 0.7083,
      "step": 481750
    },
    {
      "epoch": 5.100518206022623,
      "grad_norm": 4.066776752471924,
      "learning_rate": 2.4507992801185688e-05,
      "loss": 0.713,
      "step": 481800
    },
    {
      "epoch": 5.101047527802627,
      "grad_norm": 4.266035556793213,
      "learning_rate": 2.450534617827652e-05,
      "loss": 0.714,
      "step": 481850
    },
    {
      "epoch": 5.10157684958263,
      "grad_norm": 4.378840923309326,
      "learning_rate": 2.4502699555367352e-05,
      "loss": 0.7064,
      "step": 481900
    },
    {
      "epoch": 5.1021061713626334,
      "grad_norm": 4.708976745605469,
      "learning_rate": 2.4500052932458183e-05,
      "loss": 0.7238,
      "step": 481950
    },
    {
      "epoch": 5.102635493142636,
      "grad_norm": 4.568299770355225,
      "learning_rate": 2.4497406309549017e-05,
      "loss": 0.7298,
      "step": 482000
    },
    {
      "epoch": 5.102635493142636,
      "eval_loss": 0.4735058844089508,
      "eval_runtime": 46.736,
      "eval_samples_per_second": 3593.165,
      "eval_steps_per_second": 449.162,
      "step": 482000
    },
    {
      "epoch": 5.103164814922639,
      "grad_norm": 4.52733850479126,
      "learning_rate": 2.4494759686639848e-05,
      "loss": 0.7088,
      "step": 482050
    },
    {
      "epoch": 5.103694136702643,
      "grad_norm": 4.4422287940979,
      "learning_rate": 2.4492113063730682e-05,
      "loss": 0.7149,
      "step": 482100
    },
    {
      "epoch": 5.104223458482646,
      "grad_norm": 4.482783794403076,
      "learning_rate": 2.4489466440821513e-05,
      "loss": 0.716,
      "step": 482150
    },
    {
      "epoch": 5.10475278026265,
      "grad_norm": 4.194875240325928,
      "learning_rate": 2.4486819817912347e-05,
      "loss": 0.7237,
      "step": 482200
    },
    {
      "epoch": 5.105282102042652,
      "grad_norm": 3.8744757175445557,
      "learning_rate": 2.4484173195003178e-05,
      "loss": 0.7132,
      "step": 482250
    },
    {
      "epoch": 5.105811423822656,
      "grad_norm": 4.206014633178711,
      "learning_rate": 2.4481526572094012e-05,
      "loss": 0.7211,
      "step": 482300
    },
    {
      "epoch": 5.106340745602659,
      "grad_norm": 3.8208351135253906,
      "learning_rate": 2.4478879949184842e-05,
      "loss": 0.7035,
      "step": 482350
    },
    {
      "epoch": 5.106870067382663,
      "grad_norm": 4.015275001525879,
      "learning_rate": 2.4476233326275673e-05,
      "loss": 0.7205,
      "step": 482400
    },
    {
      "epoch": 5.107399389162666,
      "grad_norm": 4.044663429260254,
      "learning_rate": 2.4473586703366504e-05,
      "loss": 0.7099,
      "step": 482450
    },
    {
      "epoch": 5.107928710942669,
      "grad_norm": 3.886913537979126,
      "learning_rate": 2.4470940080457338e-05,
      "loss": 0.7161,
      "step": 482500
    },
    {
      "epoch": 5.107928710942669,
      "eval_loss": 0.47485265135765076,
      "eval_runtime": 46.8241,
      "eval_samples_per_second": 3586.399,
      "eval_steps_per_second": 448.316,
      "step": 482500
    },
    {
      "epoch": 5.108458032722672,
      "grad_norm": 4.612907409667969,
      "learning_rate": 2.446829345754817e-05,
      "loss": 0.7188,
      "step": 482550
    },
    {
      "epoch": 5.108987354502676,
      "grad_norm": 3.930690288543701,
      "learning_rate": 2.4465646834639003e-05,
      "loss": 0.7097,
      "step": 482600
    },
    {
      "epoch": 5.109516676282679,
      "grad_norm": 4.2249627113342285,
      "learning_rate": 2.4463000211729833e-05,
      "loss": 0.7252,
      "step": 482650
    },
    {
      "epoch": 5.110045998062683,
      "grad_norm": 4.5030012130737305,
      "learning_rate": 2.4460353588820668e-05,
      "loss": 0.7058,
      "step": 482700
    },
    {
      "epoch": 5.1105753198426855,
      "grad_norm": 4.1872992515563965,
      "learning_rate": 2.44577069659115e-05,
      "loss": 0.7223,
      "step": 482750
    },
    {
      "epoch": 5.111104641622688,
      "grad_norm": 4.231688499450684,
      "learning_rate": 2.4455060343002332e-05,
      "loss": 0.7232,
      "step": 482800
    },
    {
      "epoch": 5.111633963402692,
      "grad_norm": 4.379924297332764,
      "learning_rate": 2.4452413720093163e-05,
      "loss": 0.7228,
      "step": 482850
    },
    {
      "epoch": 5.112163285182695,
      "grad_norm": 4.229406833648682,
      "learning_rate": 2.4449767097183994e-05,
      "loss": 0.6973,
      "step": 482900
    },
    {
      "epoch": 5.112692606962699,
      "grad_norm": 4.011386871337891,
      "learning_rate": 2.4447120474274825e-05,
      "loss": 0.7276,
      "step": 482950
    },
    {
      "epoch": 5.113221928742702,
      "grad_norm": 4.2561354637146,
      "learning_rate": 2.444447385136566e-05,
      "loss": 0.7065,
      "step": 483000
    },
    {
      "epoch": 5.113221928742702,
      "eval_loss": 0.47353288531303406,
      "eval_runtime": 47.0284,
      "eval_samples_per_second": 3570.82,
      "eval_steps_per_second": 446.368,
      "step": 483000
    },
    {
      "epoch": 5.113751250522705,
      "grad_norm": 4.3130364418029785,
      "learning_rate": 2.444182722845649e-05,
      "loss": 0.7254,
      "step": 483050
    },
    {
      "epoch": 5.114280572302708,
      "grad_norm": 4.281567096710205,
      "learning_rate": 2.4439180605547323e-05,
      "loss": 0.7201,
      "step": 483100
    },
    {
      "epoch": 5.114809894082712,
      "grad_norm": 4.487432479858398,
      "learning_rate": 2.4436533982638154e-05,
      "loss": 0.7164,
      "step": 483150
    },
    {
      "epoch": 5.115339215862715,
      "grad_norm": 4.010725021362305,
      "learning_rate": 2.4433887359728988e-05,
      "loss": 0.7133,
      "step": 483200
    },
    {
      "epoch": 5.115868537642719,
      "grad_norm": 4.438525199890137,
      "learning_rate": 2.443124073681982e-05,
      "loss": 0.7205,
      "step": 483250
    },
    {
      "epoch": 5.1163978594227215,
      "grad_norm": 4.611400127410889,
      "learning_rate": 2.4428594113910653e-05,
      "loss": 0.7201,
      "step": 483300
    },
    {
      "epoch": 5.116927181202725,
      "grad_norm": 4.079685211181641,
      "learning_rate": 2.4425947491001484e-05,
      "loss": 0.723,
      "step": 483350
    },
    {
      "epoch": 5.117456502982728,
      "grad_norm": 3.9642868041992188,
      "learning_rate": 2.4423300868092318e-05,
      "loss": 0.7065,
      "step": 483400
    },
    {
      "epoch": 5.117985824762732,
      "grad_norm": 4.183554649353027,
      "learning_rate": 2.442065424518315e-05,
      "loss": 0.7135,
      "step": 483450
    },
    {
      "epoch": 5.118515146542735,
      "grad_norm": 4.356776714324951,
      "learning_rate": 2.441800762227398e-05,
      "loss": 0.7148,
      "step": 483500
    },
    {
      "epoch": 5.118515146542735,
      "eval_loss": 0.4724288582801819,
      "eval_runtime": 46.8427,
      "eval_samples_per_second": 3584.974,
      "eval_steps_per_second": 448.138,
      "step": 483500
    },
    {
      "epoch": 5.119044468322738,
      "grad_norm": 4.39900541305542,
      "learning_rate": 2.441536099936481e-05,
      "loss": 0.7248,
      "step": 483550
    },
    {
      "epoch": 5.119573790102741,
      "grad_norm": 4.729177474975586,
      "learning_rate": 2.4412714376455644e-05,
      "loss": 0.7232,
      "step": 483600
    },
    {
      "epoch": 5.120103111882744,
      "grad_norm": 4.41705322265625,
      "learning_rate": 2.4410067753546475e-05,
      "loss": 0.7193,
      "step": 483650
    },
    {
      "epoch": 5.120632433662748,
      "grad_norm": 4.121364593505859,
      "learning_rate": 2.440742113063731e-05,
      "loss": 0.7112,
      "step": 483700
    },
    {
      "epoch": 5.121161755442751,
      "grad_norm": 4.404208660125732,
      "learning_rate": 2.4404827440186324e-05,
      "loss": 0.7138,
      "step": 483750
    },
    {
      "epoch": 5.121691077222755,
      "grad_norm": 3.4884047508239746,
      "learning_rate": 2.4402180817277158e-05,
      "loss": 0.7139,
      "step": 483800
    },
    {
      "epoch": 5.1222203990027575,
      "grad_norm": 4.4030351638793945,
      "learning_rate": 2.439953419436799e-05,
      "loss": 0.7183,
      "step": 483850
    },
    {
      "epoch": 5.122749720782761,
      "grad_norm": 4.339372634887695,
      "learning_rate": 2.439688757145882e-05,
      "loss": 0.7181,
      "step": 483900
    },
    {
      "epoch": 5.123279042562764,
      "grad_norm": 4.133488655090332,
      "learning_rate": 2.439424094854965e-05,
      "loss": 0.7154,
      "step": 483950
    },
    {
      "epoch": 5.123808364342768,
      "grad_norm": 4.585785865783691,
      "learning_rate": 2.4391594325640484e-05,
      "loss": 0.711,
      "step": 484000
    },
    {
      "epoch": 5.123808364342768,
      "eval_loss": 0.4720233082771301,
      "eval_runtime": 46.98,
      "eval_samples_per_second": 3574.502,
      "eval_steps_per_second": 446.829,
      "step": 484000
    },
    {
      "epoch": 5.124337686122771,
      "grad_norm": 4.409510612487793,
      "learning_rate": 2.4388947702731315e-05,
      "loss": 0.7282,
      "step": 484050
    },
    {
      "epoch": 5.1248670079027745,
      "grad_norm": 4.8665642738342285,
      "learning_rate": 2.438630107982215e-05,
      "loss": 0.7147,
      "step": 484100
    },
    {
      "epoch": 5.125396329682777,
      "grad_norm": 4.017582893371582,
      "learning_rate": 2.438365445691298e-05,
      "loss": 0.7183,
      "step": 484150
    },
    {
      "epoch": 5.125925651462781,
      "grad_norm": 3.978248119354248,
      "learning_rate": 2.4381007834003814e-05,
      "loss": 0.7229,
      "step": 484200
    },
    {
      "epoch": 5.126454973242784,
      "grad_norm": 4.1396565437316895,
      "learning_rate": 2.4378361211094644e-05,
      "loss": 0.7113,
      "step": 484250
    },
    {
      "epoch": 5.126984295022787,
      "grad_norm": 4.264228343963623,
      "learning_rate": 2.437571458818548e-05,
      "loss": 0.7185,
      "step": 484300
    },
    {
      "epoch": 5.127513616802791,
      "grad_norm": 4.370999336242676,
      "learning_rate": 2.437306796527631e-05,
      "loss": 0.7121,
      "step": 484350
    },
    {
      "epoch": 5.1280429385827935,
      "grad_norm": 4.394607067108154,
      "learning_rate": 2.4370421342367143e-05,
      "loss": 0.7239,
      "step": 484400
    },
    {
      "epoch": 5.128572260362797,
      "grad_norm": 4.523098945617676,
      "learning_rate": 2.4367774719457974e-05,
      "loss": 0.727,
      "step": 484450
    },
    {
      "epoch": 5.1291015821428,
      "grad_norm": 3.919950485229492,
      "learning_rate": 2.4365128096548805e-05,
      "loss": 0.7151,
      "step": 484500
    },
    {
      "epoch": 5.1291015821428,
      "eval_loss": 0.47252508997917175,
      "eval_runtime": 47.3098,
      "eval_samples_per_second": 3549.578,
      "eval_steps_per_second": 443.713,
      "step": 484500
    },
    {
      "epoch": 5.129630903922804,
      "grad_norm": 4.294710636138916,
      "learning_rate": 2.4362481473639635e-05,
      "loss": 0.7127,
      "step": 484550
    },
    {
      "epoch": 5.130160225702807,
      "grad_norm": 4.377376079559326,
      "learning_rate": 2.435983485073047e-05,
      "loss": 0.7117,
      "step": 484600
    },
    {
      "epoch": 5.1306895474828105,
      "grad_norm": 4.176812648773193,
      "learning_rate": 2.43571882278213e-05,
      "loss": 0.7082,
      "step": 484650
    },
    {
      "epoch": 5.131218869262813,
      "grad_norm": 4.2311272621154785,
      "learning_rate": 2.4354541604912134e-05,
      "loss": 0.7113,
      "step": 484700
    },
    {
      "epoch": 5.131748191042817,
      "grad_norm": 4.334692478179932,
      "learning_rate": 2.4351894982002965e-05,
      "loss": 0.7166,
      "step": 484750
    },
    {
      "epoch": 5.13227751282282,
      "grad_norm": 4.424510478973389,
      "learning_rate": 2.43492483590938e-05,
      "loss": 0.7208,
      "step": 484800
    },
    {
      "epoch": 5.132806834602824,
      "grad_norm": 4.254344940185547,
      "learning_rate": 2.434660173618463e-05,
      "loss": 0.721,
      "step": 484850
    },
    {
      "epoch": 5.133336156382827,
      "grad_norm": 4.364973068237305,
      "learning_rate": 2.4343955113275464e-05,
      "loss": 0.7109,
      "step": 484900
    },
    {
      "epoch": 5.13386547816283,
      "grad_norm": 4.467804908752441,
      "learning_rate": 2.4341308490366295e-05,
      "loss": 0.7272,
      "step": 484950
    },
    {
      "epoch": 5.134394799942833,
      "grad_norm": 4.095815658569336,
      "learning_rate": 2.433866186745713e-05,
      "loss": 0.715,
      "step": 485000
    },
    {
      "epoch": 5.134394799942833,
      "eval_loss": 0.47231194376945496,
      "eval_runtime": 46.9858,
      "eval_samples_per_second": 3574.06,
      "eval_steps_per_second": 446.773,
      "step": 485000
    },
    {
      "epoch": 5.134924121722836,
      "grad_norm": 4.537463188171387,
      "learning_rate": 2.433601524454796e-05,
      "loss": 0.7104,
      "step": 485050
    },
    {
      "epoch": 5.13545344350284,
      "grad_norm": 4.57219123840332,
      "learning_rate": 2.433336862163879e-05,
      "loss": 0.735,
      "step": 485100
    },
    {
      "epoch": 5.135982765282843,
      "grad_norm": 4.130978107452393,
      "learning_rate": 2.433072199872962e-05,
      "loss": 0.7188,
      "step": 485150
    },
    {
      "epoch": 5.1365120870628465,
      "grad_norm": 4.0770039558410645,
      "learning_rate": 2.4328075375820455e-05,
      "loss": 0.7275,
      "step": 485200
    },
    {
      "epoch": 5.137041408842849,
      "grad_norm": 4.269511699676514,
      "learning_rate": 2.4325428752911286e-05,
      "loss": 0.7106,
      "step": 485250
    },
    {
      "epoch": 5.137570730622853,
      "grad_norm": 4.591057300567627,
      "learning_rate": 2.432278213000212e-05,
      "loss": 0.7166,
      "step": 485300
    },
    {
      "epoch": 5.138100052402856,
      "grad_norm": 4.755039215087891,
      "learning_rate": 2.432013550709295e-05,
      "loss": 0.7116,
      "step": 485350
    },
    {
      "epoch": 5.13862937418286,
      "grad_norm": 4.0600666999816895,
      "learning_rate": 2.4317488884183785e-05,
      "loss": 0.7134,
      "step": 485400
    },
    {
      "epoch": 5.139158695962863,
      "grad_norm": 4.152105808258057,
      "learning_rate": 2.4314842261274615e-05,
      "loss": 0.7063,
      "step": 485450
    },
    {
      "epoch": 5.139688017742866,
      "grad_norm": 4.0104475021362305,
      "learning_rate": 2.431219563836545e-05,
      "loss": 0.7162,
      "step": 485500
    },
    {
      "epoch": 5.139688017742866,
      "eval_loss": 0.47252151370048523,
      "eval_runtime": 46.8554,
      "eval_samples_per_second": 3584.005,
      "eval_steps_per_second": 448.017,
      "step": 485500
    },
    {
      "epoch": 5.140217339522869,
      "grad_norm": 4.155357837677002,
      "learning_rate": 2.430954901545628e-05,
      "loss": 0.7161,
      "step": 485550
    },
    {
      "epoch": 5.140746661302873,
      "grad_norm": 4.258358478546143,
      "learning_rate": 2.430690239254711e-05,
      "loss": 0.7131,
      "step": 485600
    },
    {
      "epoch": 5.141275983082876,
      "grad_norm": 4.207988739013672,
      "learning_rate": 2.430425576963794e-05,
      "loss": 0.7212,
      "step": 485650
    },
    {
      "epoch": 5.14180530486288,
      "grad_norm": 3.8373477458953857,
      "learning_rate": 2.4301609146728776e-05,
      "loss": 0.7219,
      "step": 485700
    },
    {
      "epoch": 5.142334626642882,
      "grad_norm": 4.855121612548828,
      "learning_rate": 2.429901545627779e-05,
      "loss": 0.7137,
      "step": 485750
    },
    {
      "epoch": 5.142863948422885,
      "grad_norm": 4.200937271118164,
      "learning_rate": 2.4296368833368624e-05,
      "loss": 0.7076,
      "step": 485800
    },
    {
      "epoch": 5.143393270202889,
      "grad_norm": 4.194437026977539,
      "learning_rate": 2.4293722210459455e-05,
      "loss": 0.7132,
      "step": 485850
    },
    {
      "epoch": 5.143922591982892,
      "grad_norm": 3.8998570442199707,
      "learning_rate": 2.429107558755029e-05,
      "loss": 0.7173,
      "step": 485900
    },
    {
      "epoch": 5.144451913762896,
      "grad_norm": 4.137413501739502,
      "learning_rate": 2.428842896464112e-05,
      "loss": 0.7245,
      "step": 485950
    },
    {
      "epoch": 5.1449812355428985,
      "grad_norm": 4.2576823234558105,
      "learning_rate": 2.4285782341731954e-05,
      "loss": 0.715,
      "step": 486000
    },
    {
      "epoch": 5.1449812355428985,
      "eval_loss": 0.4721469283103943,
      "eval_runtime": 46.9396,
      "eval_samples_per_second": 3577.575,
      "eval_steps_per_second": 447.213,
      "step": 486000
    },
    {
      "epoch": 5.145510557322902,
      "grad_norm": 4.38187313079834,
      "learning_rate": 2.4283135718822785e-05,
      "loss": 0.7168,
      "step": 486050
    },
    {
      "epoch": 5.146039879102905,
      "grad_norm": 3.8921592235565186,
      "learning_rate": 2.4280489095913615e-05,
      "loss": 0.7066,
      "step": 486100
    },
    {
      "epoch": 5.146569200882909,
      "grad_norm": 3.837484836578369,
      "learning_rate": 2.4277842473004446e-05,
      "loss": 0.7148,
      "step": 486150
    },
    {
      "epoch": 5.147098522662912,
      "grad_norm": 4.386269569396973,
      "learning_rate": 2.427519585009528e-05,
      "loss": 0.7226,
      "step": 486200
    },
    {
      "epoch": 5.1476278444429155,
      "grad_norm": 4.490574359893799,
      "learning_rate": 2.427254922718611e-05,
      "loss": 0.7092,
      "step": 486250
    },
    {
      "epoch": 5.148157166222918,
      "grad_norm": 3.927251100540161,
      "learning_rate": 2.4269902604276945e-05,
      "loss": 0.7069,
      "step": 486300
    },
    {
      "epoch": 5.148686488002922,
      "grad_norm": 4.238992691040039,
      "learning_rate": 2.4267255981367776e-05,
      "loss": 0.7205,
      "step": 486350
    },
    {
      "epoch": 5.149215809782925,
      "grad_norm": 4.105581283569336,
      "learning_rate": 2.426460935845861e-05,
      "loss": 0.7317,
      "step": 486400
    },
    {
      "epoch": 5.149745131562929,
      "grad_norm": 4.251198768615723,
      "learning_rate": 2.426196273554944e-05,
      "loss": 0.7225,
      "step": 486450
    },
    {
      "epoch": 5.150274453342932,
      "grad_norm": 4.200188159942627,
      "learning_rate": 2.4259316112640275e-05,
      "loss": 0.714,
      "step": 486500
    },
    {
      "epoch": 5.150274453342932,
      "eval_loss": 0.47169029712677,
      "eval_runtime": 46.7634,
      "eval_samples_per_second": 3591.053,
      "eval_steps_per_second": 448.898,
      "step": 486500
    },
    {
      "epoch": 5.150803775122935,
      "grad_norm": 4.867751598358154,
      "learning_rate": 2.4256669489731105e-05,
      "loss": 0.7118,
      "step": 486550
    },
    {
      "epoch": 5.151333096902938,
      "grad_norm": 4.706111431121826,
      "learning_rate": 2.4254022866821936e-05,
      "loss": 0.7091,
      "step": 486600
    },
    {
      "epoch": 5.151862418682941,
      "grad_norm": 3.8524885177612305,
      "learning_rate": 2.4251376243912767e-05,
      "loss": 0.7076,
      "step": 486650
    },
    {
      "epoch": 5.152391740462945,
      "grad_norm": 3.8241634368896484,
      "learning_rate": 2.42487296210036e-05,
      "loss": 0.7114,
      "step": 486700
    },
    {
      "epoch": 5.152921062242948,
      "grad_norm": 4.257039546966553,
      "learning_rate": 2.424608299809443e-05,
      "loss": 0.7146,
      "step": 486750
    },
    {
      "epoch": 5.1534503840229515,
      "grad_norm": 4.524775981903076,
      "learning_rate": 2.4243436375185266e-05,
      "loss": 0.71,
      "step": 486800
    },
    {
      "epoch": 5.153979705802954,
      "grad_norm": 4.266708850860596,
      "learning_rate": 2.4240789752276096e-05,
      "loss": 0.7217,
      "step": 486850
    },
    {
      "epoch": 5.154509027582958,
      "grad_norm": 4.073853015899658,
      "learning_rate": 2.423814312936693e-05,
      "loss": 0.7169,
      "step": 486900
    },
    {
      "epoch": 5.155038349362961,
      "grad_norm": 4.355621814727783,
      "learning_rate": 2.423549650645776e-05,
      "loss": 0.7082,
      "step": 486950
    },
    {
      "epoch": 5.155567671142965,
      "grad_norm": 4.525472164154053,
      "learning_rate": 2.4232849883548595e-05,
      "loss": 0.7152,
      "step": 487000
    },
    {
      "epoch": 5.155567671142965,
      "eval_loss": 0.47167345881462097,
      "eval_runtime": 47.421,
      "eval_samples_per_second": 3541.256,
      "eval_steps_per_second": 442.673,
      "step": 487000
    },
    {
      "epoch": 5.156096992922968,
      "grad_norm": 4.440306663513184,
      "learning_rate": 2.4230203260639426e-05,
      "loss": 0.7209,
      "step": 487050
    },
    {
      "epoch": 5.156626314702971,
      "grad_norm": 4.323564529418945,
      "learning_rate": 2.4227556637730257e-05,
      "loss": 0.7084,
      "step": 487100
    },
    {
      "epoch": 5.157155636482974,
      "grad_norm": 4.303312301635742,
      "learning_rate": 2.422491001482109e-05,
      "loss": 0.7158,
      "step": 487150
    },
    {
      "epoch": 5.157684958262978,
      "grad_norm": 4.334662437438965,
      "learning_rate": 2.422226339191192e-05,
      "loss": 0.7094,
      "step": 487200
    },
    {
      "epoch": 5.158214280042981,
      "grad_norm": 4.359165191650391,
      "learning_rate": 2.4219616769002752e-05,
      "loss": 0.7146,
      "step": 487250
    },
    {
      "epoch": 5.158743601822985,
      "grad_norm": 4.151142597198486,
      "learning_rate": 2.4216970146093583e-05,
      "loss": 0.71,
      "step": 487300
    },
    {
      "epoch": 5.1592729236029875,
      "grad_norm": 4.639049053192139,
      "learning_rate": 2.4214323523184417e-05,
      "loss": 0.7127,
      "step": 487350
    },
    {
      "epoch": 5.15980224538299,
      "grad_norm": 4.510376930236816,
      "learning_rate": 2.4211676900275248e-05,
      "loss": 0.7243,
      "step": 487400
    },
    {
      "epoch": 5.160331567162994,
      "grad_norm": 4.098781108856201,
      "learning_rate": 2.4209030277366082e-05,
      "loss": 0.7227,
      "step": 487450
    },
    {
      "epoch": 5.160860888942997,
      "grad_norm": 4.145703315734863,
      "learning_rate": 2.4206383654456913e-05,
      "loss": 0.7129,
      "step": 487500
    },
    {
      "epoch": 5.160860888942997,
      "eval_loss": 0.4716256856918335,
      "eval_runtime": 47.1029,
      "eval_samples_per_second": 3565.17,
      "eval_steps_per_second": 445.662,
      "step": 487500
    },
    {
      "epoch": 5.161390210723001,
      "grad_norm": 4.587989807128906,
      "learning_rate": 2.4203737031547747e-05,
      "loss": 0.7243,
      "step": 487550
    },
    {
      "epoch": 5.161919532503004,
      "grad_norm": 4.216979026794434,
      "learning_rate": 2.4201090408638577e-05,
      "loss": 0.7186,
      "step": 487600
    },
    {
      "epoch": 5.162448854283007,
      "grad_norm": 4.445601463317871,
      "learning_rate": 2.419844378572941e-05,
      "loss": 0.7128,
      "step": 487650
    },
    {
      "epoch": 5.16297817606301,
      "grad_norm": 4.335022926330566,
      "learning_rate": 2.4195797162820242e-05,
      "loss": 0.7056,
      "step": 487700
    },
    {
      "epoch": 5.163507497843014,
      "grad_norm": 4.044292449951172,
      "learning_rate": 2.4193203472369257e-05,
      "loss": 0.7126,
      "step": 487750
    },
    {
      "epoch": 5.164036819623017,
      "grad_norm": 4.6403703689575195,
      "learning_rate": 2.4190556849460088e-05,
      "loss": 0.7131,
      "step": 487800
    },
    {
      "epoch": 5.164566141403021,
      "grad_norm": 4.113173484802246,
      "learning_rate": 2.4187910226550922e-05,
      "loss": 0.7093,
      "step": 487850
    },
    {
      "epoch": 5.1650954631830235,
      "grad_norm": 3.9488370418548584,
      "learning_rate": 2.4185263603641753e-05,
      "loss": 0.7228,
      "step": 487900
    },
    {
      "epoch": 5.165624784963027,
      "grad_norm": 4.656824111938477,
      "learning_rate": 2.4182616980732587e-05,
      "loss": 0.7354,
      "step": 487950
    },
    {
      "epoch": 5.16615410674303,
      "grad_norm": 4.300992012023926,
      "learning_rate": 2.4179970357823417e-05,
      "loss": 0.7092,
      "step": 488000
    },
    {
      "epoch": 5.16615410674303,
      "eval_loss": 0.47077563405036926,
      "eval_runtime": 46.8594,
      "eval_samples_per_second": 3583.698,
      "eval_steps_per_second": 447.978,
      "step": 488000
    },
    {
      "epoch": 5.166683428523034,
      "grad_norm": 4.258363246917725,
      "learning_rate": 2.417732373491425e-05,
      "loss": 0.7022,
      "step": 488050
    },
    {
      "epoch": 5.167212750303037,
      "grad_norm": 4.4478349685668945,
      "learning_rate": 2.4174677112005082e-05,
      "loss": 0.7178,
      "step": 488100
    },
    {
      "epoch": 5.16774207208304,
      "grad_norm": 3.8340532779693604,
      "learning_rate": 2.4172030489095916e-05,
      "loss": 0.7186,
      "step": 488150
    },
    {
      "epoch": 5.168271393863043,
      "grad_norm": 4.534996032714844,
      "learning_rate": 2.4169383866186747e-05,
      "loss": 0.7204,
      "step": 488200
    },
    {
      "epoch": 5.168800715643046,
      "grad_norm": 4.467733860015869,
      "learning_rate": 2.4166737243277578e-05,
      "loss": 0.7173,
      "step": 488250
    },
    {
      "epoch": 5.16933003742305,
      "grad_norm": 3.8537538051605225,
      "learning_rate": 2.416409062036841e-05,
      "loss": 0.7151,
      "step": 488300
    },
    {
      "epoch": 5.169859359203053,
      "grad_norm": 4.090874671936035,
      "learning_rate": 2.4161443997459242e-05,
      "loss": 0.7024,
      "step": 488350
    },
    {
      "epoch": 5.170388680983057,
      "grad_norm": 4.493046283721924,
      "learning_rate": 2.4158797374550073e-05,
      "loss": 0.7317,
      "step": 488400
    },
    {
      "epoch": 5.1709180027630595,
      "grad_norm": 4.520596504211426,
      "learning_rate": 2.4156150751640907e-05,
      "loss": 0.7236,
      "step": 488450
    },
    {
      "epoch": 5.171447324543063,
      "grad_norm": 4.752651691436768,
      "learning_rate": 2.4153504128731738e-05,
      "loss": 0.7096,
      "step": 488500
    },
    {
      "epoch": 5.171447324543063,
      "eval_loss": 0.4704303443431854,
      "eval_runtime": 46.9038,
      "eval_samples_per_second": 3580.304,
      "eval_steps_per_second": 447.554,
      "step": 488500
    },
    {
      "epoch": 5.171976646323066,
      "grad_norm": 4.455890655517578,
      "learning_rate": 2.4150910438280756e-05,
      "loss": 0.7158,
      "step": 488550
    },
    {
      "epoch": 5.17250596810307,
      "grad_norm": 4.15502405166626,
      "learning_rate": 2.4148263815371587e-05,
      "loss": 0.7243,
      "step": 488600
    },
    {
      "epoch": 5.173035289883073,
      "grad_norm": 4.475322246551514,
      "learning_rate": 2.4145617192462418e-05,
      "loss": 0.726,
      "step": 488650
    },
    {
      "epoch": 5.1735646116630765,
      "grad_norm": 4.212611198425293,
      "learning_rate": 2.4142970569553248e-05,
      "loss": 0.7211,
      "step": 488700
    },
    {
      "epoch": 5.174093933443079,
      "grad_norm": 4.793044090270996,
      "learning_rate": 2.4140323946644082e-05,
      "loss": 0.7177,
      "step": 488750
    },
    {
      "epoch": 5.174623255223083,
      "grad_norm": 4.266864776611328,
      "learning_rate": 2.4137677323734913e-05,
      "loss": 0.6998,
      "step": 488800
    },
    {
      "epoch": 5.175152577003086,
      "grad_norm": 4.236696243286133,
      "learning_rate": 2.4135030700825747e-05,
      "loss": 0.7049,
      "step": 488850
    },
    {
      "epoch": 5.175681898783089,
      "grad_norm": 4.048894882202148,
      "learning_rate": 2.4132384077916578e-05,
      "loss": 0.6995,
      "step": 488900
    },
    {
      "epoch": 5.176211220563093,
      "grad_norm": 4.166927814483643,
      "learning_rate": 2.4129737455007412e-05,
      "loss": 0.7088,
      "step": 488950
    },
    {
      "epoch": 5.176740542343095,
      "grad_norm": 4.192826747894287,
      "learning_rate": 2.4127090832098243e-05,
      "loss": 0.7122,
      "step": 489000
    },
    {
      "epoch": 5.176740542343095,
      "eval_loss": 0.47029486298561096,
      "eval_runtime": 46.7721,
      "eval_samples_per_second": 3590.386,
      "eval_steps_per_second": 448.814,
      "step": 489000
    },
    {
      "epoch": 5.177269864123099,
      "grad_norm": 4.2810235023498535,
      "learning_rate": 2.4124444209189077e-05,
      "loss": 0.7318,
      "step": 489050
    },
    {
      "epoch": 5.177799185903102,
      "grad_norm": 3.681694507598877,
      "learning_rate": 2.4121797586279907e-05,
      "loss": 0.7312,
      "step": 489100
    },
    {
      "epoch": 5.178328507683106,
      "grad_norm": 3.4732677936553955,
      "learning_rate": 2.411915096337074e-05,
      "loss": 0.7212,
      "step": 489150
    },
    {
      "epoch": 5.178857829463109,
      "grad_norm": 4.140411376953125,
      "learning_rate": 2.4116504340461572e-05,
      "loss": 0.7025,
      "step": 489200
    },
    {
      "epoch": 5.179387151243112,
      "grad_norm": 3.946786642074585,
      "learning_rate": 2.4113857717552403e-05,
      "loss": 0.7248,
      "step": 489250
    },
    {
      "epoch": 5.179916473023115,
      "grad_norm": 4.327129364013672,
      "learning_rate": 2.4111211094643234e-05,
      "loss": 0.7213,
      "step": 489300
    },
    {
      "epoch": 5.180445794803119,
      "grad_norm": 4.634955406188965,
      "learning_rate": 2.4108564471734068e-05,
      "loss": 0.7252,
      "step": 489350
    },
    {
      "epoch": 5.180975116583122,
      "grad_norm": 4.611092567443848,
      "learning_rate": 2.41059178488249e-05,
      "loss": 0.7091,
      "step": 489400
    },
    {
      "epoch": 5.181504438363126,
      "grad_norm": 4.313045978546143,
      "learning_rate": 2.4103271225915733e-05,
      "loss": 0.7194,
      "step": 489450
    },
    {
      "epoch": 5.1820337601431286,
      "grad_norm": 4.270553112030029,
      "learning_rate": 2.4100624603006563e-05,
      "loss": 0.7071,
      "step": 489500
    },
    {
      "epoch": 5.1820337601431286,
      "eval_loss": 0.4695557653903961,
      "eval_runtime": 47.0321,
      "eval_samples_per_second": 3570.543,
      "eval_steps_per_second": 446.334,
      "step": 489500
    },
    {
      "epoch": 5.182563081923132,
      "grad_norm": 4.069560527801514,
      "learning_rate": 2.4097977980097397e-05,
      "loss": 0.7023,
      "step": 489550
    },
    {
      "epoch": 5.183092403703135,
      "grad_norm": 4.143048286437988,
      "learning_rate": 2.4095331357188228e-05,
      "loss": 0.7121,
      "step": 489600
    },
    {
      "epoch": 5.183621725483138,
      "grad_norm": 4.526163578033447,
      "learning_rate": 2.4092684734279062e-05,
      "loss": 0.7069,
      "step": 489650
    },
    {
      "epoch": 5.184151047263142,
      "grad_norm": 4.088067531585693,
      "learning_rate": 2.4090038111369893e-05,
      "loss": 0.7007,
      "step": 489700
    },
    {
      "epoch": 5.184680369043145,
      "grad_norm": 4.306939601898193,
      "learning_rate": 2.4087391488460727e-05,
      "loss": 0.7142,
      "step": 489750
    },
    {
      "epoch": 5.185209690823148,
      "grad_norm": 4.357669353485107,
      "learning_rate": 2.4084744865551558e-05,
      "loss": 0.7115,
      "step": 489800
    },
    {
      "epoch": 5.185739012603151,
      "grad_norm": 4.304030418395996,
      "learning_rate": 2.408209824264239e-05,
      "loss": 0.7115,
      "step": 489850
    },
    {
      "epoch": 5.186268334383155,
      "grad_norm": 4.389387130737305,
      "learning_rate": 2.407945161973322e-05,
      "loss": 0.7204,
      "step": 489900
    },
    {
      "epoch": 5.186797656163158,
      "grad_norm": 4.21685791015625,
      "learning_rate": 2.4076804996824053e-05,
      "loss": 0.7197,
      "step": 489950
    },
    {
      "epoch": 5.187326977943162,
      "grad_norm": 4.46743631362915,
      "learning_rate": 2.4074158373914884e-05,
      "loss": 0.718,
      "step": 490000
    },
    {
      "epoch": 5.187326977943162,
      "eval_loss": 0.47029608488082886,
      "eval_runtime": 46.9571,
      "eval_samples_per_second": 3576.242,
      "eval_steps_per_second": 447.046,
      "step": 490000
    },
    {
      "epoch": 5.1878562997231645,
      "grad_norm": 4.330705642700195,
      "learning_rate": 2.4071511751005718e-05,
      "loss": 0.71,
      "step": 490050
    },
    {
      "epoch": 5.188385621503168,
      "grad_norm": 4.058190822601318,
      "learning_rate": 2.406886512809655e-05,
      "loss": 0.7111,
      "step": 490100
    },
    {
      "epoch": 5.188914943283171,
      "grad_norm": 4.642303466796875,
      "learning_rate": 2.4066218505187383e-05,
      "loss": 0.7143,
      "step": 490150
    },
    {
      "epoch": 5.189444265063175,
      "grad_norm": 4.023025035858154,
      "learning_rate": 2.4063571882278214e-05,
      "loss": 0.7173,
      "step": 490200
    },
    {
      "epoch": 5.189973586843178,
      "grad_norm": 4.610391616821289,
      "learning_rate": 2.4060925259369048e-05,
      "loss": 0.7202,
      "step": 490250
    },
    {
      "epoch": 5.1905029086231815,
      "grad_norm": 4.075124263763428,
      "learning_rate": 2.405827863645988e-05,
      "loss": 0.712,
      "step": 490300
    },
    {
      "epoch": 5.191032230403184,
      "grad_norm": 4.817342758178711,
      "learning_rate": 2.405563201355071e-05,
      "loss": 0.7093,
      "step": 490350
    },
    {
      "epoch": 5.191561552183187,
      "grad_norm": 4.383243560791016,
      "learning_rate": 2.405298539064154e-05,
      "loss": 0.7283,
      "step": 490400
    },
    {
      "epoch": 5.192090873963191,
      "grad_norm": 3.9455134868621826,
      "learning_rate": 2.4050338767732374e-05,
      "loss": 0.7089,
      "step": 490450
    },
    {
      "epoch": 5.192620195743194,
      "grad_norm": 3.9679758548736572,
      "learning_rate": 2.4047692144823205e-05,
      "loss": 0.703,
      "step": 490500
    },
    {
      "epoch": 5.192620195743194,
      "eval_loss": 0.4702818989753723,
      "eval_runtime": 46.82,
      "eval_samples_per_second": 3586.713,
      "eval_steps_per_second": 448.355,
      "step": 490500
    },
    {
      "epoch": 5.193149517523198,
      "grad_norm": 4.379634380340576,
      "learning_rate": 2.404504552191404e-05,
      "loss": 0.7256,
      "step": 490550
    },
    {
      "epoch": 5.1936788393032005,
      "grad_norm": 4.36994743347168,
      "learning_rate": 2.404239889900487e-05,
      "loss": 0.7141,
      "step": 490600
    },
    {
      "epoch": 5.194208161083204,
      "grad_norm": 4.5229387283325195,
      "learning_rate": 2.4039752276095704e-05,
      "loss": 0.7178,
      "step": 490650
    },
    {
      "epoch": 5.194737482863207,
      "grad_norm": 3.9557900428771973,
      "learning_rate": 2.4037105653186534e-05,
      "loss": 0.715,
      "step": 490700
    },
    {
      "epoch": 5.195266804643211,
      "grad_norm": 3.839353561401367,
      "learning_rate": 2.403445903027737e-05,
      "loss": 0.7041,
      "step": 490750
    },
    {
      "epoch": 5.195796126423214,
      "grad_norm": 4.567377090454102,
      "learning_rate": 2.40318124073682e-05,
      "loss": 0.7116,
      "step": 490800
    },
    {
      "epoch": 5.1963254482032175,
      "grad_norm": 4.479532241821289,
      "learning_rate": 2.4029165784459033e-05,
      "loss": 0.7277,
      "step": 490850
    },
    {
      "epoch": 5.19685476998322,
      "grad_norm": 4.583770751953125,
      "learning_rate": 2.4026519161549864e-05,
      "loss": 0.7141,
      "step": 490900
    },
    {
      "epoch": 5.197384091763224,
      "grad_norm": 4.389840602874756,
      "learning_rate": 2.4023872538640695e-05,
      "loss": 0.7142,
      "step": 490950
    },
    {
      "epoch": 5.197913413543227,
      "grad_norm": 4.5284104347229,
      "learning_rate": 2.4021225915731525e-05,
      "loss": 0.7179,
      "step": 491000
    },
    {
      "epoch": 5.197913413543227,
      "eval_loss": 0.47018447518348694,
      "eval_runtime": 46.9401,
      "eval_samples_per_second": 3577.535,
      "eval_steps_per_second": 447.208,
      "step": 491000
    },
    {
      "epoch": 5.198442735323231,
      "grad_norm": 4.131247520446777,
      "learning_rate": 2.401857929282236e-05,
      "loss": 0.726,
      "step": 491050
    },
    {
      "epoch": 5.198972057103234,
      "grad_norm": 4.517557144165039,
      "learning_rate": 2.401593266991319e-05,
      "loss": 0.718,
      "step": 491100
    },
    {
      "epoch": 5.1995013788832365,
      "grad_norm": 4.455162048339844,
      "learning_rate": 2.4013286047004024e-05,
      "loss": 0.7116,
      "step": 491150
    },
    {
      "epoch": 5.20003070066324,
      "grad_norm": 4.315114974975586,
      "learning_rate": 2.4010639424094855e-05,
      "loss": 0.7216,
      "step": 491200
    },
    {
      "epoch": 5.200560022443243,
      "grad_norm": 4.878330707550049,
      "learning_rate": 2.400799280118569e-05,
      "loss": 0.7104,
      "step": 491250
    },
    {
      "epoch": 5.201089344223247,
      "grad_norm": 4.681350231170654,
      "learning_rate": 2.400534617827652e-05,
      "loss": 0.7151,
      "step": 491300
    },
    {
      "epoch": 5.20161866600325,
      "grad_norm": 4.5259318351745605,
      "learning_rate": 2.4002699555367354e-05,
      "loss": 0.7087,
      "step": 491350
    },
    {
      "epoch": 5.2021479877832535,
      "grad_norm": 3.9754586219787598,
      "learning_rate": 2.4000052932458185e-05,
      "loss": 0.7137,
      "step": 491400
    },
    {
      "epoch": 5.202677309563256,
      "grad_norm": 4.284913539886475,
      "learning_rate": 2.399740630954902e-05,
      "loss": 0.7116,
      "step": 491450
    },
    {
      "epoch": 5.20320663134326,
      "grad_norm": 4.635071277618408,
      "learning_rate": 2.399475968663985e-05,
      "loss": 0.7258,
      "step": 491500
    },
    {
      "epoch": 5.20320663134326,
      "eval_loss": 0.47019872069358826,
      "eval_runtime": 46.7167,
      "eval_samples_per_second": 3594.645,
      "eval_steps_per_second": 449.347,
      "step": 491500
    },
    {
      "epoch": 5.203735953123263,
      "grad_norm": 4.172702312469482,
      "learning_rate": 2.399211306373068e-05,
      "loss": 0.7218,
      "step": 491550
    },
    {
      "epoch": 5.204265274903267,
      "grad_norm": 4.411917686462402,
      "learning_rate": 2.398946644082151e-05,
      "loss": 0.7118,
      "step": 491600
    },
    {
      "epoch": 5.20479459668327,
      "grad_norm": 4.174582004547119,
      "learning_rate": 2.3986819817912345e-05,
      "loss": 0.7307,
      "step": 491650
    },
    {
      "epoch": 5.205323918463273,
      "grad_norm": 4.526339054107666,
      "learning_rate": 2.3984173195003176e-05,
      "loss": 0.7197,
      "step": 491700
    },
    {
      "epoch": 5.205853240243276,
      "grad_norm": 3.956242322921753,
      "learning_rate": 2.398152657209401e-05,
      "loss": 0.721,
      "step": 491750
    },
    {
      "epoch": 5.20638256202328,
      "grad_norm": 3.8588831424713135,
      "learning_rate": 2.397887994918484e-05,
      "loss": 0.7123,
      "step": 491800
    },
    {
      "epoch": 5.206911883803283,
      "grad_norm": 4.088962078094482,
      "learning_rate": 2.3976233326275675e-05,
      "loss": 0.7157,
      "step": 491850
    },
    {
      "epoch": 5.207441205583286,
      "grad_norm": 4.242755889892578,
      "learning_rate": 2.3973586703366505e-05,
      "loss": 0.7055,
      "step": 491900
    },
    {
      "epoch": 5.2079705273632895,
      "grad_norm": 4.339201927185059,
      "learning_rate": 2.397094008045734e-05,
      "loss": 0.7261,
      "step": 491950
    },
    {
      "epoch": 5.208499849143292,
      "grad_norm": 3.7612457275390625,
      "learning_rate": 2.396829345754817e-05,
      "loss": 0.7107,
      "step": 492000
    },
    {
      "epoch": 5.208499849143292,
      "eval_loss": 0.4685160517692566,
      "eval_runtime": 46.88,
      "eval_samples_per_second": 3582.128,
      "eval_steps_per_second": 447.782,
      "step": 492000
    },
    {
      "epoch": 5.209029170923296,
      "grad_norm": 4.450189113616943,
      "learning_rate": 2.3965646834639e-05,
      "loss": 0.714,
      "step": 492050
    },
    {
      "epoch": 5.209558492703299,
      "grad_norm": 4.603140830993652,
      "learning_rate": 2.396300021172983e-05,
      "loss": 0.7321,
      "step": 492100
    },
    {
      "epoch": 5.210087814483303,
      "grad_norm": 4.4837799072265625,
      "learning_rate": 2.3960353588820666e-05,
      "loss": 0.7206,
      "step": 492150
    },
    {
      "epoch": 5.210617136263306,
      "grad_norm": 4.3286213874816895,
      "learning_rate": 2.3957706965911496e-05,
      "loss": 0.7016,
      "step": 492200
    },
    {
      "epoch": 5.211146458043309,
      "grad_norm": 4.03240966796875,
      "learning_rate": 2.395506034300233e-05,
      "loss": 0.7027,
      "step": 492250
    },
    {
      "epoch": 5.211675779823312,
      "grad_norm": 4.409711837768555,
      "learning_rate": 2.395241372009316e-05,
      "loss": 0.7202,
      "step": 492300
    },
    {
      "epoch": 5.212205101603316,
      "grad_norm": 4.225456714630127,
      "learning_rate": 2.3949767097183995e-05,
      "loss": 0.7213,
      "step": 492350
    },
    {
      "epoch": 5.212734423383319,
      "grad_norm": 4.552907466888428,
      "learning_rate": 2.3947120474274826e-05,
      "loss": 0.7003,
      "step": 492400
    },
    {
      "epoch": 5.213263745163323,
      "grad_norm": 4.40350866317749,
      "learning_rate": 2.394447385136566e-05,
      "loss": 0.7062,
      "step": 492450
    },
    {
      "epoch": 5.2137930669433254,
      "grad_norm": 4.391812324523926,
      "learning_rate": 2.394182722845649e-05,
      "loss": 0.719,
      "step": 492500
    },
    {
      "epoch": 5.2137930669433254,
      "eval_loss": 0.46899229288101196,
      "eval_runtime": 46.7151,
      "eval_samples_per_second": 3594.769,
      "eval_steps_per_second": 449.362,
      "step": 492500
    },
    {
      "epoch": 5.214322388723329,
      "grad_norm": 4.338924407958984,
      "learning_rate": 2.3939233538005505e-05,
      "loss": 0.7153,
      "step": 492550
    },
    {
      "epoch": 5.214851710503332,
      "grad_norm": 4.544452667236328,
      "learning_rate": 2.3936586915096336e-05,
      "loss": 0.7133,
      "step": 492600
    },
    {
      "epoch": 5.215381032283335,
      "grad_norm": 4.620503902435303,
      "learning_rate": 2.393394029218717e-05,
      "loss": 0.707,
      "step": 492650
    },
    {
      "epoch": 5.215910354063339,
      "grad_norm": 4.654317378997803,
      "learning_rate": 2.3931293669278e-05,
      "loss": 0.7185,
      "step": 492700
    },
    {
      "epoch": 5.216439675843342,
      "grad_norm": 4.547628402709961,
      "learning_rate": 2.3928647046368835e-05,
      "loss": 0.7152,
      "step": 492750
    },
    {
      "epoch": 5.216968997623345,
      "grad_norm": 4.08823299407959,
      "learning_rate": 2.3926000423459666e-05,
      "loss": 0.7213,
      "step": 492800
    },
    {
      "epoch": 5.217498319403348,
      "grad_norm": 4.633918762207031,
      "learning_rate": 2.39233538005505e-05,
      "loss": 0.7173,
      "step": 492850
    },
    {
      "epoch": 5.218027641183352,
      "grad_norm": 4.317077159881592,
      "learning_rate": 2.392070717764133e-05,
      "loss": 0.721,
      "step": 492900
    },
    {
      "epoch": 5.218556962963355,
      "grad_norm": 3.8388445377349854,
      "learning_rate": 2.3918060554732165e-05,
      "loss": 0.7113,
      "step": 492950
    },
    {
      "epoch": 5.219086284743359,
      "grad_norm": 3.9527971744537354,
      "learning_rate": 2.3915413931822995e-05,
      "loss": 0.7151,
      "step": 493000
    },
    {
      "epoch": 5.219086284743359,
      "eval_loss": 0.4694930911064148,
      "eval_runtime": 46.767,
      "eval_samples_per_second": 3590.781,
      "eval_steps_per_second": 448.864,
      "step": 493000
    },
    {
      "epoch": 5.219615606523361,
      "grad_norm": 4.331706523895264,
      "learning_rate": 2.3912767308913826e-05,
      "loss": 0.7186,
      "step": 493050
    },
    {
      "epoch": 5.220144928303365,
      "grad_norm": 4.423273086547852,
      "learning_rate": 2.3910120686004657e-05,
      "loss": 0.7189,
      "step": 493100
    },
    {
      "epoch": 5.220674250083368,
      "grad_norm": 4.183821678161621,
      "learning_rate": 2.390747406309549e-05,
      "loss": 0.7223,
      "step": 493150
    },
    {
      "epoch": 5.221203571863372,
      "grad_norm": 4.253942966461182,
      "learning_rate": 2.390482744018632e-05,
      "loss": 0.7187,
      "step": 493200
    },
    {
      "epoch": 5.221732893643375,
      "grad_norm": 4.278495788574219,
      "learning_rate": 2.3902180817277156e-05,
      "loss": 0.7111,
      "step": 493250
    },
    {
      "epoch": 5.222262215423378,
      "grad_norm": 4.468906402587891,
      "learning_rate": 2.3899534194367986e-05,
      "loss": 0.7291,
      "step": 493300
    },
    {
      "epoch": 5.222791537203381,
      "grad_norm": 4.2080159187316895,
      "learning_rate": 2.389688757145882e-05,
      "loss": 0.706,
      "step": 493350
    },
    {
      "epoch": 5.223320858983384,
      "grad_norm": 4.483046054840088,
      "learning_rate": 2.389424094854965e-05,
      "loss": 0.7104,
      "step": 493400
    },
    {
      "epoch": 5.223850180763388,
      "grad_norm": 4.39784574508667,
      "learning_rate": 2.3891594325640485e-05,
      "loss": 0.7178,
      "step": 493450
    },
    {
      "epoch": 5.224379502543391,
      "grad_norm": 4.448554515838623,
      "learning_rate": 2.3888947702731316e-05,
      "loss": 0.7069,
      "step": 493500
    },
    {
      "epoch": 5.224379502543391,
      "eval_loss": 0.46939173340797424,
      "eval_runtime": 46.7684,
      "eval_samples_per_second": 3590.672,
      "eval_steps_per_second": 448.85,
      "step": 493500
    },
    {
      "epoch": 5.2249088243233945,
      "grad_norm": 3.72847843170166,
      "learning_rate": 2.388630107982215e-05,
      "loss": 0.7116,
      "step": 493550
    },
    {
      "epoch": 5.225438146103397,
      "grad_norm": 4.374862194061279,
      "learning_rate": 2.388365445691298e-05,
      "loss": 0.698,
      "step": 493600
    },
    {
      "epoch": 5.225967467883401,
      "grad_norm": 4.309643268585205,
      "learning_rate": 2.388100783400381e-05,
      "loss": 0.7167,
      "step": 493650
    },
    {
      "epoch": 5.226496789663404,
      "grad_norm": 4.103418350219727,
      "learning_rate": 2.3878361211094642e-05,
      "loss": 0.7128,
      "step": 493700
    },
    {
      "epoch": 5.227026111443408,
      "grad_norm": 4.6214752197265625,
      "learning_rate": 2.3875714588185476e-05,
      "loss": 0.7051,
      "step": 493750
    },
    {
      "epoch": 5.227555433223411,
      "grad_norm": 4.363483428955078,
      "learning_rate": 2.3873067965276307e-05,
      "loss": 0.7194,
      "step": 493800
    },
    {
      "epoch": 5.228084755003414,
      "grad_norm": 4.528928756713867,
      "learning_rate": 2.387042134236714e-05,
      "loss": 0.7074,
      "step": 493850
    },
    {
      "epoch": 5.228614076783417,
      "grad_norm": 4.333975791931152,
      "learning_rate": 2.3867774719457972e-05,
      "loss": 0.7108,
      "step": 493900
    },
    {
      "epoch": 5.229143398563421,
      "grad_norm": 4.1291913986206055,
      "learning_rate": 2.3865128096548806e-05,
      "loss": 0.7151,
      "step": 493950
    },
    {
      "epoch": 5.229672720343424,
      "grad_norm": 4.250641345977783,
      "learning_rate": 2.3862481473639637e-05,
      "loss": 0.7096,
      "step": 494000
    },
    {
      "epoch": 5.229672720343424,
      "eval_loss": 0.47029492259025574,
      "eval_runtime": 46.7829,
      "eval_samples_per_second": 3589.563,
      "eval_steps_per_second": 448.711,
      "step": 494000
    },
    {
      "epoch": 5.230202042123428,
      "grad_norm": 4.8315019607543945,
      "learning_rate": 2.385983485073047e-05,
      "loss": 0.7019,
      "step": 494050
    },
    {
      "epoch": 5.2307313639034305,
      "grad_norm": 3.877371311187744,
      "learning_rate": 2.38571882278213e-05,
      "loss": 0.7209,
      "step": 494100
    },
    {
      "epoch": 5.231260685683433,
      "grad_norm": 4.520510673522949,
      "learning_rate": 2.3854541604912132e-05,
      "loss": 0.7139,
      "step": 494150
    },
    {
      "epoch": 5.231790007463437,
      "grad_norm": 4.081097602844238,
      "learning_rate": 2.3851894982002963e-05,
      "loss": 0.7256,
      "step": 494200
    },
    {
      "epoch": 5.23231932924344,
      "grad_norm": 4.284626007080078,
      "learning_rate": 2.3849248359093797e-05,
      "loss": 0.7046,
      "step": 494250
    },
    {
      "epoch": 5.232848651023444,
      "grad_norm": 3.959775447845459,
      "learning_rate": 2.3846601736184628e-05,
      "loss": 0.6932,
      "step": 494300
    },
    {
      "epoch": 5.233377972803447,
      "grad_norm": 4.016665458679199,
      "learning_rate": 2.3843955113275462e-05,
      "loss": 0.7069,
      "step": 494350
    },
    {
      "epoch": 5.23390729458345,
      "grad_norm": 4.509130477905273,
      "learning_rate": 2.3841308490366293e-05,
      "loss": 0.7144,
      "step": 494400
    },
    {
      "epoch": 5.234436616363453,
      "grad_norm": 4.010590553283691,
      "learning_rate": 2.3838661867457127e-05,
      "loss": 0.7101,
      "step": 494450
    },
    {
      "epoch": 5.234965938143457,
      "grad_norm": 4.18242883682251,
      "learning_rate": 2.3836015244547957e-05,
      "loss": 0.7044,
      "step": 494500
    },
    {
      "epoch": 5.234965938143457,
      "eval_loss": 0.4697110056877136,
      "eval_runtime": 46.9182,
      "eval_samples_per_second": 3579.205,
      "eval_steps_per_second": 447.417,
      "step": 494500
    },
    {
      "epoch": 5.23549525992346,
      "grad_norm": 3.8261632919311523,
      "learning_rate": 2.3833421554096976e-05,
      "loss": 0.72,
      "step": 494550
    },
    {
      "epoch": 5.236024581703464,
      "grad_norm": 4.12580680847168,
      "learning_rate": 2.3830774931187806e-05,
      "loss": 0.7256,
      "step": 494600
    },
    {
      "epoch": 5.2365539034834665,
      "grad_norm": 4.3983259201049805,
      "learning_rate": 2.3828128308278637e-05,
      "loss": 0.7183,
      "step": 494650
    },
    {
      "epoch": 5.23708322526347,
      "grad_norm": 4.4097065925598145,
      "learning_rate": 2.3825481685369468e-05,
      "loss": 0.7321,
      "step": 494700
    },
    {
      "epoch": 5.237612547043473,
      "grad_norm": 3.9224839210510254,
      "learning_rate": 2.3822835062460302e-05,
      "loss": 0.7025,
      "step": 494750
    },
    {
      "epoch": 5.238141868823477,
      "grad_norm": 4.060418605804443,
      "learning_rate": 2.3820188439551132e-05,
      "loss": 0.7187,
      "step": 494800
    },
    {
      "epoch": 5.23867119060348,
      "grad_norm": 4.5225090980529785,
      "learning_rate": 2.3817541816641967e-05,
      "loss": 0.7179,
      "step": 494850
    },
    {
      "epoch": 5.2392005123834835,
      "grad_norm": 3.87024188041687,
      "learning_rate": 2.3814895193732797e-05,
      "loss": 0.7298,
      "step": 494900
    },
    {
      "epoch": 5.239729834163486,
      "grad_norm": 4.178379058837891,
      "learning_rate": 2.381224857082363e-05,
      "loss": 0.7184,
      "step": 494950
    },
    {
      "epoch": 5.240259155943489,
      "grad_norm": 4.324976921081543,
      "learning_rate": 2.3809601947914462e-05,
      "loss": 0.7082,
      "step": 495000
    },
    {
      "epoch": 5.240259155943489,
      "eval_loss": 0.4688855707645416,
      "eval_runtime": 46.9138,
      "eval_samples_per_second": 3579.546,
      "eval_steps_per_second": 447.459,
      "step": 495000
    },
    {
      "epoch": 5.240788477723493,
      "grad_norm": 4.326104640960693,
      "learning_rate": 2.3806955325005296e-05,
      "loss": 0.7177,
      "step": 495050
    },
    {
      "epoch": 5.241317799503496,
      "grad_norm": 4.07350492477417,
      "learning_rate": 2.3804308702096127e-05,
      "loss": 0.7165,
      "step": 495100
    },
    {
      "epoch": 5.2418471212835,
      "grad_norm": 4.413079738616943,
      "learning_rate": 2.380166207918696e-05,
      "loss": 0.7247,
      "step": 495150
    },
    {
      "epoch": 5.2423764430635025,
      "grad_norm": 4.524816513061523,
      "learning_rate": 2.3799015456277792e-05,
      "loss": 0.7245,
      "step": 495200
    },
    {
      "epoch": 5.242905764843506,
      "grad_norm": 4.048964977264404,
      "learning_rate": 2.3796368833368622e-05,
      "loss": 0.712,
      "step": 495250
    },
    {
      "epoch": 5.243435086623509,
      "grad_norm": 4.827948093414307,
      "learning_rate": 2.3793722210459453e-05,
      "loss": 0.7115,
      "step": 495300
    },
    {
      "epoch": 5.243964408403513,
      "grad_norm": 4.075279235839844,
      "learning_rate": 2.3791075587550287e-05,
      "loss": 0.7097,
      "step": 495350
    },
    {
      "epoch": 5.244493730183516,
      "grad_norm": 4.158885478973389,
      "learning_rate": 2.3788428964641118e-05,
      "loss": 0.7183,
      "step": 495400
    },
    {
      "epoch": 5.2450230519635195,
      "grad_norm": 4.147514820098877,
      "learning_rate": 2.3785782341731952e-05,
      "loss": 0.7206,
      "step": 495450
    },
    {
      "epoch": 5.245552373743522,
      "grad_norm": 4.1952314376831055,
      "learning_rate": 2.3783135718822783e-05,
      "loss": 0.7219,
      "step": 495500
    },
    {
      "epoch": 5.245552373743522,
      "eval_loss": 0.4670116901397705,
      "eval_runtime": 46.9336,
      "eval_samples_per_second": 3578.036,
      "eval_steps_per_second": 447.27,
      "step": 495500
    },
    {
      "epoch": 5.246081695523526,
      "grad_norm": 4.252915382385254,
      "learning_rate": 2.3780489095913617e-05,
      "loss": 0.7071,
      "step": 495550
    },
    {
      "epoch": 5.246611017303529,
      "grad_norm": 4.913347244262695,
      "learning_rate": 2.3777842473004448e-05,
      "loss": 0.712,
      "step": 495600
    },
    {
      "epoch": 5.247140339083533,
      "grad_norm": 4.064975738525391,
      "learning_rate": 2.377519585009528e-05,
      "loss": 0.71,
      "step": 495650
    },
    {
      "epoch": 5.247669660863536,
      "grad_norm": 4.220901966094971,
      "learning_rate": 2.3772549227186112e-05,
      "loss": 0.7059,
      "step": 495700
    },
    {
      "epoch": 5.2481989826435385,
      "grad_norm": 4.504427909851074,
      "learning_rate": 2.3769902604276943e-05,
      "loss": 0.7023,
      "step": 495750
    },
    {
      "epoch": 5.248728304423542,
      "grad_norm": 4.326120853424072,
      "learning_rate": 2.3767255981367774e-05,
      "loss": 0.7148,
      "step": 495800
    },
    {
      "epoch": 5.249257626203545,
      "grad_norm": 4.393715858459473,
      "learning_rate": 2.3764609358458608e-05,
      "loss": 0.7035,
      "step": 495850
    },
    {
      "epoch": 5.249786947983549,
      "grad_norm": 4.050365924835205,
      "learning_rate": 2.376196273554944e-05,
      "loss": 0.7205,
      "step": 495900
    },
    {
      "epoch": 5.250316269763552,
      "grad_norm": 4.341571807861328,
      "learning_rate": 2.3759316112640273e-05,
      "loss": 0.7062,
      "step": 495950
    },
    {
      "epoch": 5.2508455915435555,
      "grad_norm": 4.53027868270874,
      "learning_rate": 2.3756669489731103e-05,
      "loss": 0.7104,
      "step": 496000
    },
    {
      "epoch": 5.2508455915435555,
      "eval_loss": 0.4687945246696472,
      "eval_runtime": 46.9143,
      "eval_samples_per_second": 3579.509,
      "eval_steps_per_second": 447.455,
      "step": 496000
    },
    {
      "epoch": 5.251374913323558,
      "grad_norm": 4.210775852203369,
      "learning_rate": 2.3754022866821938e-05,
      "loss": 0.7195,
      "step": 496050
    },
    {
      "epoch": 5.251904235103562,
      "grad_norm": 4.218702793121338,
      "learning_rate": 2.3751376243912768e-05,
      "loss": 0.7153,
      "step": 496100
    },
    {
      "epoch": 5.252433556883565,
      "grad_norm": 4.2687811851501465,
      "learning_rate": 2.3748729621003602e-05,
      "loss": 0.7047,
      "step": 496150
    },
    {
      "epoch": 5.252962878663569,
      "grad_norm": 4.476626873016357,
      "learning_rate": 2.3746082998094433e-05,
      "loss": 0.7168,
      "step": 496200
    },
    {
      "epoch": 5.253492200443572,
      "grad_norm": 4.062244415283203,
      "learning_rate": 2.3743436375185267e-05,
      "loss": 0.7049,
      "step": 496250
    },
    {
      "epoch": 5.254021522223575,
      "grad_norm": 4.003299713134766,
      "learning_rate": 2.3740789752276098e-05,
      "loss": 0.7195,
      "step": 496300
    },
    {
      "epoch": 5.254550844003578,
      "grad_norm": 4.438943386077881,
      "learning_rate": 2.373814312936693e-05,
      "loss": 0.7015,
      "step": 496350
    },
    {
      "epoch": 5.255080165783582,
      "grad_norm": 4.061014652252197,
      "learning_rate": 2.373549650645776e-05,
      "loss": 0.7164,
      "step": 496400
    },
    {
      "epoch": 5.255609487563585,
      "grad_norm": 4.592598915100098,
      "learning_rate": 2.3732849883548593e-05,
      "loss": 0.7059,
      "step": 496450
    },
    {
      "epoch": 5.256138809343588,
      "grad_norm": 4.585510730743408,
      "learning_rate": 2.3730203260639424e-05,
      "loss": 0.7035,
      "step": 496500
    },
    {
      "epoch": 5.256138809343588,
      "eval_loss": 0.4669232964515686,
      "eval_runtime": 46.9592,
      "eval_samples_per_second": 3576.081,
      "eval_steps_per_second": 447.026,
      "step": 496500
    },
    {
      "epoch": 5.256668131123591,
      "grad_norm": 4.102728843688965,
      "learning_rate": 2.3727609570188442e-05,
      "loss": 0.7141,
      "step": 496550
    },
    {
      "epoch": 5.257197452903594,
      "grad_norm": 4.172842025756836,
      "learning_rate": 2.3724962947279273e-05,
      "loss": 0.7114,
      "step": 496600
    },
    {
      "epoch": 5.257726774683598,
      "grad_norm": 4.548572540283203,
      "learning_rate": 2.3722316324370107e-05,
      "loss": 0.7138,
      "step": 496650
    },
    {
      "epoch": 5.258256096463601,
      "grad_norm": 4.729181289672852,
      "learning_rate": 2.3719669701460938e-05,
      "loss": 0.7074,
      "step": 496700
    },
    {
      "epoch": 5.258785418243605,
      "grad_norm": 4.771417617797852,
      "learning_rate": 2.371702307855177e-05,
      "loss": 0.7087,
      "step": 496750
    },
    {
      "epoch": 5.2593147400236075,
      "grad_norm": 4.495319366455078,
      "learning_rate": 2.37143764556426e-05,
      "loss": 0.7174,
      "step": 496800
    },
    {
      "epoch": 5.259844061803611,
      "grad_norm": 4.179945945739746,
      "learning_rate": 2.3711729832733433e-05,
      "loss": 0.7066,
      "step": 496850
    },
    {
      "epoch": 5.260373383583614,
      "grad_norm": 4.184690952301025,
      "learning_rate": 2.3709083209824264e-05,
      "loss": 0.7203,
      "step": 496900
    },
    {
      "epoch": 5.260902705363618,
      "grad_norm": 4.361494064331055,
      "learning_rate": 2.3706436586915098e-05,
      "loss": 0.7265,
      "step": 496950
    },
    {
      "epoch": 5.261432027143621,
      "grad_norm": 4.625524997711182,
      "learning_rate": 2.370378996400593e-05,
      "loss": 0.7091,
      "step": 497000
    },
    {
      "epoch": 5.261432027143621,
      "eval_loss": 0.46694836020469666,
      "eval_runtime": 46.7583,
      "eval_samples_per_second": 3591.452,
      "eval_steps_per_second": 448.948,
      "step": 497000
    },
    {
      "epoch": 5.2619613489236245,
      "grad_norm": 4.168310165405273,
      "learning_rate": 2.3701143341096763e-05,
      "loss": 0.7124,
      "step": 497050
    },
    {
      "epoch": 5.262490670703627,
      "grad_norm": 4.44989538192749,
      "learning_rate": 2.3698496718187594e-05,
      "loss": 0.7249,
      "step": 497100
    },
    {
      "epoch": 5.263019992483631,
      "grad_norm": 4.369133472442627,
      "learning_rate": 2.3695850095278428e-05,
      "loss": 0.7225,
      "step": 497150
    },
    {
      "epoch": 5.263549314263634,
      "grad_norm": 4.342087745666504,
      "learning_rate": 2.3693256404827442e-05,
      "loss": 0.6995,
      "step": 497200
    },
    {
      "epoch": 5.264078636043637,
      "grad_norm": 4.062812328338623,
      "learning_rate": 2.3690609781918273e-05,
      "loss": 0.7146,
      "step": 497250
    },
    {
      "epoch": 5.264607957823641,
      "grad_norm": 3.783529043197632,
      "learning_rate": 2.3687963159009104e-05,
      "loss": 0.7215,
      "step": 497300
    },
    {
      "epoch": 5.2651372796036435,
      "grad_norm": 4.465710163116455,
      "learning_rate": 2.3685316536099938e-05,
      "loss": 0.7047,
      "step": 497350
    },
    {
      "epoch": 5.265666601383647,
      "grad_norm": 4.3519182205200195,
      "learning_rate": 2.368266991319077e-05,
      "loss": 0.7225,
      "step": 497400
    },
    {
      "epoch": 5.26619592316365,
      "grad_norm": 4.3834686279296875,
      "learning_rate": 2.3680023290281603e-05,
      "loss": 0.7058,
      "step": 497450
    },
    {
      "epoch": 5.266725244943654,
      "grad_norm": 4.342512607574463,
      "learning_rate": 2.3677376667372433e-05,
      "loss": 0.7086,
      "step": 497500
    },
    {
      "epoch": 5.266725244943654,
      "eval_loss": 0.4677363634109497,
      "eval_runtime": 47.0986,
      "eval_samples_per_second": 3565.497,
      "eval_steps_per_second": 445.703,
      "step": 497500
    },
    {
      "epoch": 5.267254566723657,
      "grad_norm": 4.577651500701904,
      "learning_rate": 2.3674730044463268e-05,
      "loss": 0.7088,
      "step": 497550
    },
    {
      "epoch": 5.2677838885036605,
      "grad_norm": 4.406349182128906,
      "learning_rate": 2.3672083421554098e-05,
      "loss": 0.7057,
      "step": 497600
    },
    {
      "epoch": 5.268313210283663,
      "grad_norm": 4.523298263549805,
      "learning_rate": 2.3669436798644932e-05,
      "loss": 0.7048,
      "step": 497650
    },
    {
      "epoch": 5.268842532063667,
      "grad_norm": 3.9544239044189453,
      "learning_rate": 2.3666790175735763e-05,
      "loss": 0.7098,
      "step": 497700
    },
    {
      "epoch": 5.26937185384367,
      "grad_norm": 4.477282524108887,
      "learning_rate": 2.3664143552826594e-05,
      "loss": 0.7123,
      "step": 497750
    },
    {
      "epoch": 5.269901175623674,
      "grad_norm": 4.503516674041748,
      "learning_rate": 2.3661496929917424e-05,
      "loss": 0.7149,
      "step": 497800
    },
    {
      "epoch": 5.270430497403677,
      "grad_norm": 4.390398025512695,
      "learning_rate": 2.365885030700826e-05,
      "loss": 0.7149,
      "step": 497850
    },
    {
      "epoch": 5.27095981918368,
      "grad_norm": 4.502319812774658,
      "learning_rate": 2.365620368409909e-05,
      "loss": 0.7169,
      "step": 497900
    },
    {
      "epoch": 5.271489140963683,
      "grad_norm": 4.5502095222473145,
      "learning_rate": 2.3653557061189923e-05,
      "loss": 0.7236,
      "step": 497950
    },
    {
      "epoch": 5.272018462743686,
      "grad_norm": 4.150879383087158,
      "learning_rate": 2.3650910438280754e-05,
      "loss": 0.7156,
      "step": 498000
    },
    {
      "epoch": 5.272018462743686,
      "eval_loss": 0.46620866656303406,
      "eval_runtime": 46.7249,
      "eval_samples_per_second": 3594.016,
      "eval_steps_per_second": 449.268,
      "step": 498000
    },
    {
      "epoch": 5.27254778452369,
      "grad_norm": 4.059301376342773,
      "learning_rate": 2.3648263815371588e-05,
      "loss": 0.7156,
      "step": 498050
    },
    {
      "epoch": 5.273077106303693,
      "grad_norm": 4.119355201721191,
      "learning_rate": 2.364561719246242e-05,
      "loss": 0.704,
      "step": 498100
    },
    {
      "epoch": 5.2736064280836965,
      "grad_norm": 4.342977046966553,
      "learning_rate": 2.3642970569553253e-05,
      "loss": 0.7136,
      "step": 498150
    },
    {
      "epoch": 5.274135749863699,
      "grad_norm": 4.149126052856445,
      "learning_rate": 2.3640323946644084e-05,
      "loss": 0.7256,
      "step": 498200
    },
    {
      "epoch": 5.274665071643703,
      "grad_norm": 3.98054838180542,
      "learning_rate": 2.3637677323734918e-05,
      "loss": 0.7088,
      "step": 498250
    },
    {
      "epoch": 5.275194393423706,
      "grad_norm": 4.192399978637695,
      "learning_rate": 2.363503070082575e-05,
      "loss": 0.7211,
      "step": 498300
    },
    {
      "epoch": 5.27572371520371,
      "grad_norm": 4.296777725219727,
      "learning_rate": 2.363238407791658e-05,
      "loss": 0.71,
      "step": 498350
    },
    {
      "epoch": 5.276253036983713,
      "grad_norm": 3.8136179447174072,
      "learning_rate": 2.362973745500741e-05,
      "loss": 0.715,
      "step": 498400
    },
    {
      "epoch": 5.276782358763716,
      "grad_norm": 4.259268760681152,
      "learning_rate": 2.3627090832098244e-05,
      "loss": 0.7051,
      "step": 498450
    },
    {
      "epoch": 5.277311680543719,
      "grad_norm": 4.381707191467285,
      "learning_rate": 2.3624444209189075e-05,
      "loss": 0.7031,
      "step": 498500
    },
    {
      "epoch": 5.277311680543719,
      "eval_loss": 0.4659895598888397,
      "eval_runtime": 46.8111,
      "eval_samples_per_second": 3587.397,
      "eval_steps_per_second": 448.441,
      "step": 498500
    },
    {
      "epoch": 5.277841002323723,
      "grad_norm": 4.102319717407227,
      "learning_rate": 2.362179758627991e-05,
      "loss": 0.7166,
      "step": 498550
    },
    {
      "epoch": 5.278370324103726,
      "grad_norm": 4.229208946228027,
      "learning_rate": 2.361915096337074e-05,
      "loss": 0.7289,
      "step": 498600
    },
    {
      "epoch": 5.27889964588373,
      "grad_norm": 4.333743572235107,
      "learning_rate": 2.3616504340461574e-05,
      "loss": 0.7045,
      "step": 498650
    },
    {
      "epoch": 5.2794289676637325,
      "grad_norm": 4.441524982452393,
      "learning_rate": 2.3613857717552404e-05,
      "loss": 0.7173,
      "step": 498700
    },
    {
      "epoch": 5.279958289443735,
      "grad_norm": 3.9537196159362793,
      "learning_rate": 2.361121109464324e-05,
      "loss": 0.7119,
      "step": 498750
    },
    {
      "epoch": 5.280487611223739,
      "grad_norm": 4.170851230621338,
      "learning_rate": 2.360856447173407e-05,
      "loss": 0.6976,
      "step": 498800
    },
    {
      "epoch": 5.281016933003742,
      "grad_norm": 4.689993858337402,
      "learning_rate": 2.3605917848824903e-05,
      "loss": 0.7088,
      "step": 498850
    },
    {
      "epoch": 5.281546254783746,
      "grad_norm": 4.2893500328063965,
      "learning_rate": 2.3603271225915734e-05,
      "loss": 0.7225,
      "step": 498900
    },
    {
      "epoch": 5.282075576563749,
      "grad_norm": 4.105228424072266,
      "learning_rate": 2.3600624603006565e-05,
      "loss": 0.697,
      "step": 498950
    },
    {
      "epoch": 5.282604898343752,
      "grad_norm": 4.093367099761963,
      "learning_rate": 2.3597977980097395e-05,
      "loss": 0.7157,
      "step": 499000
    },
    {
      "epoch": 5.282604898343752,
      "eval_loss": 0.4681187868118286,
      "eval_runtime": 46.7534,
      "eval_samples_per_second": 3591.825,
      "eval_steps_per_second": 448.994,
      "step": 499000
    },
    {
      "epoch": 5.283134220123755,
      "grad_norm": 4.323092937469482,
      "learning_rate": 2.359533135718823e-05,
      "loss": 0.7024,
      "step": 499050
    },
    {
      "epoch": 5.283663541903759,
      "grad_norm": 4.064040660858154,
      "learning_rate": 2.359268473427906e-05,
      "loss": 0.7044,
      "step": 499100
    },
    {
      "epoch": 5.284192863683762,
      "grad_norm": 4.14776086807251,
      "learning_rate": 2.3590038111369894e-05,
      "loss": 0.7091,
      "step": 499150
    },
    {
      "epoch": 5.284722185463766,
      "grad_norm": 4.394894599914551,
      "learning_rate": 2.3587391488460725e-05,
      "loss": 0.7031,
      "step": 499200
    },
    {
      "epoch": 5.2852515072437685,
      "grad_norm": 4.279821872711182,
      "learning_rate": 2.358474486555156e-05,
      "loss": 0.6981,
      "step": 499250
    },
    {
      "epoch": 5.285780829023772,
      "grad_norm": 4.485105514526367,
      "learning_rate": 2.358209824264239e-05,
      "loss": 0.7128,
      "step": 499300
    },
    {
      "epoch": 5.286310150803775,
      "grad_norm": 4.4853363037109375,
      "learning_rate": 2.3579451619733224e-05,
      "loss": 0.7056,
      "step": 499350
    },
    {
      "epoch": 5.286839472583779,
      "grad_norm": 4.446258544921875,
      "learning_rate": 2.3576804996824055e-05,
      "loss": 0.7089,
      "step": 499400
    },
    {
      "epoch": 5.287368794363782,
      "grad_norm": 4.4035210609436035,
      "learning_rate": 2.3574158373914885e-05,
      "loss": 0.7229,
      "step": 499450
    },
    {
      "epoch": 5.287898116143785,
      "grad_norm": 4.273161888122559,
      "learning_rate": 2.3571511751005716e-05,
      "loss": 0.701,
      "step": 499500
    },
    {
      "epoch": 5.287898116143785,
      "eval_loss": 0.4659401476383209,
      "eval_runtime": 46.7357,
      "eval_samples_per_second": 3593.185,
      "eval_steps_per_second": 449.164,
      "step": 499500
    },
    {
      "epoch": 5.288427437923788,
      "grad_norm": 4.089279651641846,
      "learning_rate": 2.356886512809655e-05,
      "loss": 0.7133,
      "step": 499550
    },
    {
      "epoch": 5.288956759703791,
      "grad_norm": 4.484317302703857,
      "learning_rate": 2.356621850518738e-05,
      "loss": 0.7113,
      "step": 499600
    },
    {
      "epoch": 5.289486081483795,
      "grad_norm": 4.342334747314453,
      "learning_rate": 2.3563571882278215e-05,
      "loss": 0.7109,
      "step": 499650
    },
    {
      "epoch": 5.290015403263798,
      "grad_norm": 3.934506893157959,
      "learning_rate": 2.3560925259369046e-05,
      "loss": 0.7056,
      "step": 499700
    },
    {
      "epoch": 5.290544725043802,
      "grad_norm": 4.382274150848389,
      "learning_rate": 2.355827863645988e-05,
      "loss": 0.7103,
      "step": 499750
    },
    {
      "epoch": 5.2910740468238044,
      "grad_norm": 4.179498195648193,
      "learning_rate": 2.355563201355071e-05,
      "loss": 0.7152,
      "step": 499800
    },
    {
      "epoch": 5.291603368603808,
      "grad_norm": 4.577499866485596,
      "learning_rate": 2.3552985390641545e-05,
      "loss": 0.7106,
      "step": 499850
    },
    {
      "epoch": 5.292132690383811,
      "grad_norm": 4.186979293823242,
      "learning_rate": 2.3550338767732375e-05,
      "loss": 0.7148,
      "step": 499900
    },
    {
      "epoch": 5.292662012163815,
      "grad_norm": 4.688322067260742,
      "learning_rate": 2.354769214482321e-05,
      "loss": 0.7071,
      "step": 499950
    },
    {
      "epoch": 5.293191333943818,
      "grad_norm": 4.470713138580322,
      "learning_rate": 2.354504552191404e-05,
      "loss": 0.7103,
      "step": 500000
    },
    {
      "epoch": 5.293191333943818,
      "eval_loss": 0.46680304408073425,
      "eval_runtime": 46.7217,
      "eval_samples_per_second": 3594.259,
      "eval_steps_per_second": 449.298,
      "step": 500000
    },
    {
      "epoch": 5.2937206557238214,
      "grad_norm": 4.264878273010254,
      "learning_rate": 2.354239889900487e-05,
      "loss": 0.7174,
      "step": 500050
    },
    {
      "epoch": 5.294249977503824,
      "grad_norm": 4.4163994789123535,
      "learning_rate": 2.35397522760957e-05,
      "loss": 0.7203,
      "step": 500100
    },
    {
      "epoch": 5.294779299283828,
      "grad_norm": 4.206735610961914,
      "learning_rate": 2.3537105653186536e-05,
      "loss": 0.7051,
      "step": 500150
    },
    {
      "epoch": 5.295308621063831,
      "grad_norm": 4.285710334777832,
      "learning_rate": 2.3534459030277366e-05,
      "loss": 0.7139,
      "step": 500200
    },
    {
      "epoch": 5.295837942843834,
      "grad_norm": 3.9199068546295166,
      "learning_rate": 2.35318124073682e-05,
      "loss": 0.7182,
      "step": 500250
    },
    {
      "epoch": 5.296367264623838,
      "grad_norm": 4.251558303833008,
      "learning_rate": 2.352916578445903e-05,
      "loss": 0.7095,
      "step": 500300
    },
    {
      "epoch": 5.29689658640384,
      "grad_norm": 4.297763824462891,
      "learning_rate": 2.3526519161549865e-05,
      "loss": 0.7118,
      "step": 500350
    },
    {
      "epoch": 5.297425908183844,
      "grad_norm": 4.419537544250488,
      "learning_rate": 2.3523872538640696e-05,
      "loss": 0.7117,
      "step": 500400
    },
    {
      "epoch": 5.297955229963847,
      "grad_norm": 3.974757671356201,
      "learning_rate": 2.352122591573153e-05,
      "loss": 0.7142,
      "step": 500450
    },
    {
      "epoch": 5.298484551743851,
      "grad_norm": 4.354299545288086,
      "learning_rate": 2.351857929282236e-05,
      "loss": 0.7146,
      "step": 500500
    },
    {
      "epoch": 5.298484551743851,
      "eval_loss": 0.46696290373802185,
      "eval_runtime": 46.7087,
      "eval_samples_per_second": 3595.261,
      "eval_steps_per_second": 449.424,
      "step": 500500
    },
    {
      "epoch": 5.299013873523854,
      "grad_norm": 4.31491756439209,
      "learning_rate": 2.351593266991319e-05,
      "loss": 0.7192,
      "step": 500550
    },
    {
      "epoch": 5.299543195303857,
      "grad_norm": 4.528942108154297,
      "learning_rate": 2.3513286047004022e-05,
      "loss": 0.7063,
      "step": 500600
    },
    {
      "epoch": 5.30007251708386,
      "grad_norm": 4.255948066711426,
      "learning_rate": 2.3510639424094856e-05,
      "loss": 0.7059,
      "step": 500650
    },
    {
      "epoch": 5.300601838863864,
      "grad_norm": 4.112791538238525,
      "learning_rate": 2.3507992801185687e-05,
      "loss": 0.7142,
      "step": 500700
    },
    {
      "epoch": 5.301131160643867,
      "grad_norm": 4.251422882080078,
      "learning_rate": 2.350534617827652e-05,
      "loss": 0.7048,
      "step": 500750
    },
    {
      "epoch": 5.301660482423871,
      "grad_norm": 4.340241432189941,
      "learning_rate": 2.3502699555367352e-05,
      "loss": 0.7026,
      "step": 500800
    },
    {
      "epoch": 5.3021898042038735,
      "grad_norm": 4.6650004386901855,
      "learning_rate": 2.3500052932458186e-05,
      "loss": 0.7125,
      "step": 500850
    },
    {
      "epoch": 5.302719125983877,
      "grad_norm": 4.416500568389893,
      "learning_rate": 2.3497406309549017e-05,
      "loss": 0.7202,
      "step": 500900
    },
    {
      "epoch": 5.30324844776388,
      "grad_norm": 4.127348899841309,
      "learning_rate": 2.349475968663985e-05,
      "loss": 0.7079,
      "step": 500950
    },
    {
      "epoch": 5.303777769543883,
      "grad_norm": 4.309615135192871,
      "learning_rate": 2.349211306373068e-05,
      "loss": 0.7052,
      "step": 501000
    },
    {
      "epoch": 5.303777769543883,
      "eval_loss": 0.4642948806285858,
      "eval_runtime": 46.6863,
      "eval_samples_per_second": 3596.985,
      "eval_steps_per_second": 449.639,
      "step": 501000
    },
    {
      "epoch": 5.304307091323887,
      "grad_norm": 3.7946956157684326,
      "learning_rate": 2.3489466440821516e-05,
      "loss": 0.7165,
      "step": 501050
    },
    {
      "epoch": 5.30483641310389,
      "grad_norm": 4.2996625900268555,
      "learning_rate": 2.3486819817912346e-05,
      "loss": 0.7238,
      "step": 501100
    },
    {
      "epoch": 5.305365734883893,
      "grad_norm": 4.427710056304932,
      "learning_rate": 2.3484173195003177e-05,
      "loss": 0.7108,
      "step": 501150
    },
    {
      "epoch": 5.305895056663896,
      "grad_norm": 4.057411193847656,
      "learning_rate": 2.3481579504552192e-05,
      "loss": 0.7106,
      "step": 501200
    },
    {
      "epoch": 5.3064243784439,
      "grad_norm": 4.233269691467285,
      "learning_rate": 2.3478932881643026e-05,
      "loss": 0.7069,
      "step": 501250
    },
    {
      "epoch": 5.306953700223903,
      "grad_norm": 4.296518325805664,
      "learning_rate": 2.3476286258733857e-05,
      "loss": 0.7149,
      "step": 501300
    },
    {
      "epoch": 5.307483022003907,
      "grad_norm": 4.2859086990356445,
      "learning_rate": 2.347363963582469e-05,
      "loss": 0.7193,
      "step": 501350
    },
    {
      "epoch": 5.3080123437839095,
      "grad_norm": 4.571013450622559,
      "learning_rate": 2.347099301291552e-05,
      "loss": 0.7209,
      "step": 501400
    },
    {
      "epoch": 5.308541665563913,
      "grad_norm": 4.23671817779541,
      "learning_rate": 2.3468346390006355e-05,
      "loss": 0.7058,
      "step": 501450
    },
    {
      "epoch": 5.309070987343916,
      "grad_norm": 4.353786945343018,
      "learning_rate": 2.3465699767097186e-05,
      "loss": 0.7137,
      "step": 501500
    },
    {
      "epoch": 5.309070987343916,
      "eval_loss": 0.4646417498588562,
      "eval_runtime": 46.7223,
      "eval_samples_per_second": 3594.214,
      "eval_steps_per_second": 449.293,
      "step": 501500
    },
    {
      "epoch": 5.30960030912392,
      "grad_norm": 4.275901794433594,
      "learning_rate": 2.3463053144188017e-05,
      "loss": 0.7142,
      "step": 501550
    },
    {
      "epoch": 5.310129630903923,
      "grad_norm": 4.6702094078063965,
      "learning_rate": 2.3460406521278848e-05,
      "loss": 0.7202,
      "step": 501600
    },
    {
      "epoch": 5.3106589526839265,
      "grad_norm": 3.9272420406341553,
      "learning_rate": 2.3457759898369682e-05,
      "loss": 0.7141,
      "step": 501650
    },
    {
      "epoch": 5.311188274463929,
      "grad_norm": 4.14993143081665,
      "learning_rate": 2.3455113275460512e-05,
      "loss": 0.7072,
      "step": 501700
    },
    {
      "epoch": 5.311717596243932,
      "grad_norm": 3.8557684421539307,
      "learning_rate": 2.3452466652551343e-05,
      "loss": 0.7151,
      "step": 501750
    },
    {
      "epoch": 5.312246918023936,
      "grad_norm": 4.266019344329834,
      "learning_rate": 2.3449820029642177e-05,
      "loss": 0.7031,
      "step": 501800
    },
    {
      "epoch": 5.312776239803939,
      "grad_norm": 4.153572082519531,
      "learning_rate": 2.3447173406733008e-05,
      "loss": 0.7072,
      "step": 501850
    },
    {
      "epoch": 5.313305561583943,
      "grad_norm": 4.778543949127197,
      "learning_rate": 2.3444526783823842e-05,
      "loss": 0.704,
      "step": 501900
    },
    {
      "epoch": 5.3138348833639455,
      "grad_norm": 4.326418876647949,
      "learning_rate": 2.3441880160914673e-05,
      "loss": 0.703,
      "step": 501950
    },
    {
      "epoch": 5.314364205143949,
      "grad_norm": 4.774225234985352,
      "learning_rate": 2.3439233538005507e-05,
      "loss": 0.7139,
      "step": 502000
    },
    {
      "epoch": 5.314364205143949,
      "eval_loss": 0.46546095609664917,
      "eval_runtime": 46.7809,
      "eval_samples_per_second": 3589.711,
      "eval_steps_per_second": 448.73,
      "step": 502000
    },
    {
      "epoch": 5.314893526923952,
      "grad_norm": 4.487916946411133,
      "learning_rate": 2.3436586915096338e-05,
      "loss": 0.7088,
      "step": 502050
    },
    {
      "epoch": 5.315422848703956,
      "grad_norm": 4.360558032989502,
      "learning_rate": 2.343394029218717e-05,
      "loss": 0.7094,
      "step": 502100
    },
    {
      "epoch": 5.315952170483959,
      "grad_norm": 3.8403372764587402,
      "learning_rate": 2.3431293669278002e-05,
      "loss": 0.7041,
      "step": 502150
    },
    {
      "epoch": 5.3164814922639625,
      "grad_norm": 4.3383378982543945,
      "learning_rate": 2.3428647046368833e-05,
      "loss": 0.7083,
      "step": 502200
    },
    {
      "epoch": 5.317010814043965,
      "grad_norm": 4.317549228668213,
      "learning_rate": 2.3426000423459664e-05,
      "loss": 0.6949,
      "step": 502250
    },
    {
      "epoch": 5.317540135823969,
      "grad_norm": 4.2625956535339355,
      "learning_rate": 2.3423353800550498e-05,
      "loss": 0.7177,
      "step": 502300
    },
    {
      "epoch": 5.318069457603972,
      "grad_norm": 4.431931018829346,
      "learning_rate": 2.342070717764133e-05,
      "loss": 0.696,
      "step": 502350
    },
    {
      "epoch": 5.318598779383976,
      "grad_norm": 3.871046781539917,
      "learning_rate": 2.3418060554732163e-05,
      "loss": 0.7112,
      "step": 502400
    },
    {
      "epoch": 5.319128101163979,
      "grad_norm": 4.746356964111328,
      "learning_rate": 2.3415413931822993e-05,
      "loss": 0.7118,
      "step": 502450
    },
    {
      "epoch": 5.3196574229439815,
      "grad_norm": 4.09542179107666,
      "learning_rate": 2.3412767308913828e-05,
      "loss": 0.723,
      "step": 502500
    },
    {
      "epoch": 5.3196574229439815,
      "eval_loss": 0.46373268961906433,
      "eval_runtime": 46.7483,
      "eval_samples_per_second": 3592.214,
      "eval_steps_per_second": 449.043,
      "step": 502500
    },
    {
      "epoch": 5.320186744723985,
      "grad_norm": 4.302735328674316,
      "learning_rate": 2.3410120686004658e-05,
      "loss": 0.7055,
      "step": 502550
    },
    {
      "epoch": 5.320716066503988,
      "grad_norm": 4.146485805511475,
      "learning_rate": 2.3407474063095492e-05,
      "loss": 0.7013,
      "step": 502600
    },
    {
      "epoch": 5.321245388283992,
      "grad_norm": 4.548459529876709,
      "learning_rate": 2.3404827440186323e-05,
      "loss": 0.7166,
      "step": 502650
    },
    {
      "epoch": 5.321774710063995,
      "grad_norm": 4.141499042510986,
      "learning_rate": 2.3402180817277157e-05,
      "loss": 0.7014,
      "step": 502700
    },
    {
      "epoch": 5.3223040318439985,
      "grad_norm": 4.333282470703125,
      "learning_rate": 2.3399534194367988e-05,
      "loss": 0.7223,
      "step": 502750
    },
    {
      "epoch": 5.322833353624001,
      "grad_norm": 4.425881385803223,
      "learning_rate": 2.339688757145882e-05,
      "loss": 0.7118,
      "step": 502800
    },
    {
      "epoch": 5.323362675404005,
      "grad_norm": 4.336605548858643,
      "learning_rate": 2.339424094854965e-05,
      "loss": 0.7112,
      "step": 502850
    },
    {
      "epoch": 5.323891997184008,
      "grad_norm": 4.7983856201171875,
      "learning_rate": 2.3391594325640483e-05,
      "loss": 0.7196,
      "step": 502900
    },
    {
      "epoch": 5.324421318964012,
      "grad_norm": 3.76446795463562,
      "learning_rate": 2.3388947702731314e-05,
      "loss": 0.7046,
      "step": 502950
    },
    {
      "epoch": 5.324950640744015,
      "grad_norm": 4.184357643127441,
      "learning_rate": 2.3386301079822148e-05,
      "loss": 0.7007,
      "step": 503000
    },
    {
      "epoch": 5.324950640744015,
      "eval_loss": 0.4649653732776642,
      "eval_runtime": 46.9405,
      "eval_samples_per_second": 3577.51,
      "eval_steps_per_second": 447.205,
      "step": 503000
    },
    {
      "epoch": 5.325479962524018,
      "grad_norm": 4.184908390045166,
      "learning_rate": 2.338365445691298e-05,
      "loss": 0.7107,
      "step": 503050
    },
    {
      "epoch": 5.326009284304021,
      "grad_norm": 4.324790954589844,
      "learning_rate": 2.3381007834003813e-05,
      "loss": 0.7135,
      "step": 503100
    },
    {
      "epoch": 5.326538606084025,
      "grad_norm": 4.389064788818359,
      "learning_rate": 2.3378361211094644e-05,
      "loss": 0.7061,
      "step": 503150
    },
    {
      "epoch": 5.327067927864028,
      "grad_norm": 4.020301818847656,
      "learning_rate": 2.337576752064366e-05,
      "loss": 0.7011,
      "step": 503200
    },
    {
      "epoch": 5.327597249644031,
      "grad_norm": 4.459860801696777,
      "learning_rate": 2.337312089773449e-05,
      "loss": 0.7098,
      "step": 503250
    },
    {
      "epoch": 5.3281265714240345,
      "grad_norm": 4.290271282196045,
      "learning_rate": 2.3370474274825323e-05,
      "loss": 0.7064,
      "step": 503300
    },
    {
      "epoch": 5.328655893204037,
      "grad_norm": 4.67380428314209,
      "learning_rate": 2.3367827651916154e-05,
      "loss": 0.7191,
      "step": 503350
    },
    {
      "epoch": 5.329185214984041,
      "grad_norm": 4.574968338012695,
      "learning_rate": 2.3365181029006988e-05,
      "loss": 0.708,
      "step": 503400
    },
    {
      "epoch": 5.329714536764044,
      "grad_norm": 4.38979434967041,
      "learning_rate": 2.336253440609782e-05,
      "loss": 0.7156,
      "step": 503450
    },
    {
      "epoch": 5.330243858544048,
      "grad_norm": 4.647468090057373,
      "learning_rate": 2.3359887783188653e-05,
      "loss": 0.7167,
      "step": 503500
    },
    {
      "epoch": 5.330243858544048,
      "eval_loss": 0.4654417932033539,
      "eval_runtime": 46.8447,
      "eval_samples_per_second": 3584.826,
      "eval_steps_per_second": 448.119,
      "step": 503500
    },
    {
      "epoch": 5.330773180324051,
      "grad_norm": 4.01779842376709,
      "learning_rate": 2.3357241160279484e-05,
      "loss": 0.7109,
      "step": 503550
    },
    {
      "epoch": 5.331302502104054,
      "grad_norm": 3.9764063358306885,
      "learning_rate": 2.3354594537370318e-05,
      "loss": 0.7091,
      "step": 503600
    },
    {
      "epoch": 5.331831823884057,
      "grad_norm": 4.223738193511963,
      "learning_rate": 2.335194791446115e-05,
      "loss": 0.7184,
      "step": 503650
    },
    {
      "epoch": 5.332361145664061,
      "grad_norm": 4.214495658874512,
      "learning_rate": 2.3349301291551982e-05,
      "loss": 0.7165,
      "step": 503700
    },
    {
      "epoch": 5.332890467444064,
      "grad_norm": 4.350931644439697,
      "learning_rate": 2.3346654668642813e-05,
      "loss": 0.7094,
      "step": 503750
    },
    {
      "epoch": 5.333419789224068,
      "grad_norm": 4.1590423583984375,
      "learning_rate": 2.3344008045733644e-05,
      "loss": 0.6982,
      "step": 503800
    },
    {
      "epoch": 5.33394911100407,
      "grad_norm": 4.235330104827881,
      "learning_rate": 2.3341361422824475e-05,
      "loss": 0.7003,
      "step": 503850
    },
    {
      "epoch": 5.334478432784074,
      "grad_norm": 4.477375030517578,
      "learning_rate": 2.333871479991531e-05,
      "loss": 0.7072,
      "step": 503900
    },
    {
      "epoch": 5.335007754564077,
      "grad_norm": 4.392002582550049,
      "learning_rate": 2.333606817700614e-05,
      "loss": 0.7123,
      "step": 503950
    },
    {
      "epoch": 5.33553707634408,
      "grad_norm": 4.3986077308654785,
      "learning_rate": 2.3333421554096974e-05,
      "loss": 0.7108,
      "step": 504000
    },
    {
      "epoch": 5.33553707634408,
      "eval_loss": 0.46487948298454285,
      "eval_runtime": 47.016,
      "eval_samples_per_second": 3571.763,
      "eval_steps_per_second": 446.486,
      "step": 504000
    },
    {
      "epoch": 5.336066398124084,
      "grad_norm": 4.239454746246338,
      "learning_rate": 2.3330774931187804e-05,
      "loss": 0.7218,
      "step": 504050
    },
    {
      "epoch": 5.3365957199040865,
      "grad_norm": 4.573823928833008,
      "learning_rate": 2.332812830827864e-05,
      "loss": 0.7102,
      "step": 504100
    },
    {
      "epoch": 5.33712504168409,
      "grad_norm": 4.147708415985107,
      "learning_rate": 2.332548168536947e-05,
      "loss": 0.7059,
      "step": 504150
    },
    {
      "epoch": 5.337654363464093,
      "grad_norm": 4.198095321655273,
      "learning_rate": 2.3322835062460303e-05,
      "loss": 0.7009,
      "step": 504200
    },
    {
      "epoch": 5.338183685244097,
      "grad_norm": 4.2428717613220215,
      "learning_rate": 2.3320188439551134e-05,
      "loss": 0.7067,
      "step": 504250
    },
    {
      "epoch": 5.3387130070241,
      "grad_norm": 3.9457175731658936,
      "learning_rate": 2.3317541816641965e-05,
      "loss": 0.7,
      "step": 504300
    },
    {
      "epoch": 5.3392423288041035,
      "grad_norm": 4.0675153732299805,
      "learning_rate": 2.3314895193732795e-05,
      "loss": 0.7077,
      "step": 504350
    },
    {
      "epoch": 5.339771650584106,
      "grad_norm": 4.048547744750977,
      "learning_rate": 2.331224857082363e-05,
      "loss": 0.7077,
      "step": 504400
    },
    {
      "epoch": 5.34030097236411,
      "grad_norm": 4.057923793792725,
      "learning_rate": 2.330960194791446e-05,
      "loss": 0.6994,
      "step": 504450
    },
    {
      "epoch": 5.340830294144113,
      "grad_norm": 4.308452129364014,
      "learning_rate": 2.3306955325005294e-05,
      "loss": 0.704,
      "step": 504500
    },
    {
      "epoch": 5.340830294144113,
      "eval_loss": 0.4631185233592987,
      "eval_runtime": 46.814,
      "eval_samples_per_second": 3587.174,
      "eval_steps_per_second": 448.413,
      "step": 504500
    },
    {
      "epoch": 5.341359615924117,
      "grad_norm": 4.177320957183838,
      "learning_rate": 2.3304308702096125e-05,
      "loss": 0.7087,
      "step": 504550
    },
    {
      "epoch": 5.34188893770412,
      "grad_norm": 4.047717094421387,
      "learning_rate": 2.330166207918696e-05,
      "loss": 0.7109,
      "step": 504600
    },
    {
      "epoch": 5.342418259484123,
      "grad_norm": 4.4392924308776855,
      "learning_rate": 2.329901545627779e-05,
      "loss": 0.7119,
      "step": 504650
    },
    {
      "epoch": 5.342947581264126,
      "grad_norm": 4.2976765632629395,
      "learning_rate": 2.3296368833368624e-05,
      "loss": 0.7198,
      "step": 504700
    },
    {
      "epoch": 5.343476903044129,
      "grad_norm": 4.555713176727295,
      "learning_rate": 2.3293722210459455e-05,
      "loss": 0.7087,
      "step": 504750
    },
    {
      "epoch": 5.344006224824133,
      "grad_norm": 4.501054763793945,
      "learning_rate": 2.329107558755029e-05,
      "loss": 0.722,
      "step": 504800
    },
    {
      "epoch": 5.344535546604136,
      "grad_norm": 4.789445877075195,
      "learning_rate": 2.328842896464112e-05,
      "loss": 0.7123,
      "step": 504850
    },
    {
      "epoch": 5.3450648683841395,
      "grad_norm": 4.327761650085449,
      "learning_rate": 2.328578234173195e-05,
      "loss": 0.7046,
      "step": 504900
    },
    {
      "epoch": 5.345594190164142,
      "grad_norm": 4.231471061706543,
      "learning_rate": 2.328313571882278e-05,
      "loss": 0.7156,
      "step": 504950
    },
    {
      "epoch": 5.346123511944146,
      "grad_norm": 4.142928123474121,
      "learning_rate": 2.3280489095913615e-05,
      "loss": 0.7152,
      "step": 505000
    },
    {
      "epoch": 5.346123511944146,
      "eval_loss": 0.46543681621551514,
      "eval_runtime": 46.7262,
      "eval_samples_per_second": 3593.915,
      "eval_steps_per_second": 449.255,
      "step": 505000
    },
    {
      "epoch": 5.346652833724149,
      "grad_norm": 4.245632648468018,
      "learning_rate": 2.3277842473004446e-05,
      "loss": 0.7029,
      "step": 505050
    },
    {
      "epoch": 5.347182155504153,
      "grad_norm": 4.407452583312988,
      "learning_rate": 2.327519585009528e-05,
      "loss": 0.7008,
      "step": 505100
    },
    {
      "epoch": 5.347711477284156,
      "grad_norm": 4.1273579597473145,
      "learning_rate": 2.327254922718611e-05,
      "loss": 0.718,
      "step": 505150
    },
    {
      "epoch": 5.348240799064159,
      "grad_norm": 4.622853755950928,
      "learning_rate": 2.326995553673513e-05,
      "loss": 0.7069,
      "step": 505200
    },
    {
      "epoch": 5.348770120844162,
      "grad_norm": 4.865358352661133,
      "learning_rate": 2.326730891382596e-05,
      "loss": 0.7068,
      "step": 505250
    },
    {
      "epoch": 5.349299442624166,
      "grad_norm": 4.428651809692383,
      "learning_rate": 2.326466229091679e-05,
      "loss": 0.7095,
      "step": 505300
    },
    {
      "epoch": 5.349828764404169,
      "grad_norm": 4.5248332023620605,
      "learning_rate": 2.3262015668007624e-05,
      "loss": 0.702,
      "step": 505350
    },
    {
      "epoch": 5.350358086184173,
      "grad_norm": 4.1677470207214355,
      "learning_rate": 2.3259369045098455e-05,
      "loss": 0.7003,
      "step": 505400
    },
    {
      "epoch": 5.3508874079641755,
      "grad_norm": 3.8731770515441895,
      "learning_rate": 2.3256722422189285e-05,
      "loss": 0.7052,
      "step": 505450
    },
    {
      "epoch": 5.351416729744178,
      "grad_norm": 4.37233829498291,
      "learning_rate": 2.325407579928012e-05,
      "loss": 0.7055,
      "step": 505500
    },
    {
      "epoch": 5.351416729744178,
      "eval_loss": 0.4654504060745239,
      "eval_runtime": 46.7954,
      "eval_samples_per_second": 3588.602,
      "eval_steps_per_second": 448.591,
      "step": 505500
    },
    {
      "epoch": 5.351946051524182,
      "grad_norm": 4.21710205078125,
      "learning_rate": 2.325142917637095e-05,
      "loss": 0.7124,
      "step": 505550
    },
    {
      "epoch": 5.352475373304185,
      "grad_norm": 4.37054967880249,
      "learning_rate": 2.3248782553461784e-05,
      "loss": 0.701,
      "step": 505600
    },
    {
      "epoch": 5.353004695084189,
      "grad_norm": 4.416402816772461,
      "learning_rate": 2.3246135930552615e-05,
      "loss": 0.6916,
      "step": 505650
    },
    {
      "epoch": 5.353534016864192,
      "grad_norm": 4.1525373458862305,
      "learning_rate": 2.324348930764345e-05,
      "loss": 0.7107,
      "step": 505700
    },
    {
      "epoch": 5.354063338644195,
      "grad_norm": 4.359533309936523,
      "learning_rate": 2.324084268473428e-05,
      "loss": 0.7033,
      "step": 505750
    },
    {
      "epoch": 5.354592660424198,
      "grad_norm": 4.5743489265441895,
      "learning_rate": 2.3238196061825114e-05,
      "loss": 0.7122,
      "step": 505800
    },
    {
      "epoch": 5.355121982204202,
      "grad_norm": 4.24026346206665,
      "learning_rate": 2.3235549438915945e-05,
      "loss": 0.7043,
      "step": 505850
    },
    {
      "epoch": 5.355651303984205,
      "grad_norm": 4.018198490142822,
      "learning_rate": 2.3232902816006775e-05,
      "loss": 0.7155,
      "step": 505900
    },
    {
      "epoch": 5.356180625764209,
      "grad_norm": 4.19057559967041,
      "learning_rate": 2.3230256193097606e-05,
      "loss": 0.7065,
      "step": 505950
    },
    {
      "epoch": 5.3567099475442115,
      "grad_norm": 4.262535572052002,
      "learning_rate": 2.322760957018844e-05,
      "loss": 0.7083,
      "step": 506000
    },
    {
      "epoch": 5.3567099475442115,
      "eval_loss": 0.463849812746048,
      "eval_runtime": 46.7712,
      "eval_samples_per_second": 3590.456,
      "eval_steps_per_second": 448.823,
      "step": 506000
    },
    {
      "epoch": 5.357239269324215,
      "grad_norm": 4.307997226715088,
      "learning_rate": 2.322496294727927e-05,
      "loss": 0.7107,
      "step": 506050
    },
    {
      "epoch": 5.357768591104218,
      "grad_norm": 4.313841342926025,
      "learning_rate": 2.3222316324370105e-05,
      "loss": 0.7055,
      "step": 506100
    },
    {
      "epoch": 5.358297912884222,
      "grad_norm": 4.289483547210693,
      "learning_rate": 2.3219669701460936e-05,
      "loss": 0.7083,
      "step": 506150
    },
    {
      "epoch": 5.358827234664225,
      "grad_norm": 4.3494873046875,
      "learning_rate": 2.321702307855177e-05,
      "loss": 0.7013,
      "step": 506200
    },
    {
      "epoch": 5.359356556444228,
      "grad_norm": 4.167331218719482,
      "learning_rate": 2.32143764556426e-05,
      "loss": 0.7059,
      "step": 506250
    },
    {
      "epoch": 5.359885878224231,
      "grad_norm": 4.197912216186523,
      "learning_rate": 2.3211729832733435e-05,
      "loss": 0.7105,
      "step": 506300
    },
    {
      "epoch": 5.360415200004234,
      "grad_norm": 4.016332149505615,
      "learning_rate": 2.3209083209824265e-05,
      "loss": 0.7048,
      "step": 506350
    },
    {
      "epoch": 5.360944521784238,
      "grad_norm": 4.179649353027344,
      "learning_rate": 2.32064365869151e-05,
      "loss": 0.7132,
      "step": 506400
    },
    {
      "epoch": 5.361473843564241,
      "grad_norm": 3.9838390350341797,
      "learning_rate": 2.320378996400593e-05,
      "loss": 0.7226,
      "step": 506450
    },
    {
      "epoch": 5.362003165344245,
      "grad_norm": 4.414741039276123,
      "learning_rate": 2.320114334109676e-05,
      "loss": 0.7076,
      "step": 506500
    },
    {
      "epoch": 5.362003165344245,
      "eval_loss": 0.46446719765663147,
      "eval_runtime": 46.8696,
      "eval_samples_per_second": 3582.92,
      "eval_steps_per_second": 447.881,
      "step": 506500
    },
    {
      "epoch": 5.3625324871242475,
      "grad_norm": 4.4054856300354,
      "learning_rate": 2.319849671818759e-05,
      "loss": 0.7092,
      "step": 506550
    },
    {
      "epoch": 5.363061808904251,
      "grad_norm": 4.383996486663818,
      "learning_rate": 2.3195850095278426e-05,
      "loss": 0.7215,
      "step": 506600
    },
    {
      "epoch": 5.363591130684254,
      "grad_norm": 4.340981960296631,
      "learning_rate": 2.3193203472369256e-05,
      "loss": 0.7094,
      "step": 506650
    },
    {
      "epoch": 5.364120452464258,
      "grad_norm": 4.476987361907959,
      "learning_rate": 2.319055684946009e-05,
      "loss": 0.7166,
      "step": 506700
    },
    {
      "epoch": 5.364649774244261,
      "grad_norm": 4.402662754058838,
      "learning_rate": 2.318791022655092e-05,
      "loss": 0.7118,
      "step": 506750
    },
    {
      "epoch": 5.3651790960242645,
      "grad_norm": 4.833667755126953,
      "learning_rate": 2.3185263603641755e-05,
      "loss": 0.7155,
      "step": 506800
    },
    {
      "epoch": 5.365708417804267,
      "grad_norm": 3.75398850440979,
      "learning_rate": 2.3182616980732586e-05,
      "loss": 0.7062,
      "step": 506850
    },
    {
      "epoch": 5.366237739584271,
      "grad_norm": 4.529891014099121,
      "learning_rate": 2.317997035782342e-05,
      "loss": 0.7056,
      "step": 506900
    },
    {
      "epoch": 5.366767061364274,
      "grad_norm": 4.36821985244751,
      "learning_rate": 2.317732373491425e-05,
      "loss": 0.6958,
      "step": 506950
    },
    {
      "epoch": 5.367296383144277,
      "grad_norm": 4.288085460662842,
      "learning_rate": 2.317467711200508e-05,
      "loss": 0.6997,
      "step": 507000
    },
    {
      "epoch": 5.367296383144277,
      "eval_loss": 0.46428725123405457,
      "eval_runtime": 47.0958,
      "eval_samples_per_second": 3565.711,
      "eval_steps_per_second": 445.73,
      "step": 507000
    },
    {
      "epoch": 5.367825704924281,
      "grad_norm": 3.9253854751586914,
      "learning_rate": 2.3172030489095912e-05,
      "loss": 0.7164,
      "step": 507050
    },
    {
      "epoch": 5.368355026704283,
      "grad_norm": 4.314031600952148,
      "learning_rate": 2.3169383866186746e-05,
      "loss": 0.7204,
      "step": 507100
    },
    {
      "epoch": 5.368884348484287,
      "grad_norm": 4.273576736450195,
      "learning_rate": 2.3166737243277577e-05,
      "loss": 0.7125,
      "step": 507150
    },
    {
      "epoch": 5.36941367026429,
      "grad_norm": 4.199798583984375,
      "learning_rate": 2.316409062036841e-05,
      "loss": 0.7234,
      "step": 507200
    },
    {
      "epoch": 5.369942992044294,
      "grad_norm": 4.095719814300537,
      "learning_rate": 2.3161496929917426e-05,
      "loss": 0.7104,
      "step": 507250
    },
    {
      "epoch": 5.370472313824297,
      "grad_norm": 4.245704650878906,
      "learning_rate": 2.315885030700826e-05,
      "loss": 0.7087,
      "step": 507300
    },
    {
      "epoch": 5.3710016356043,
      "grad_norm": 4.256708145141602,
      "learning_rate": 2.315620368409909e-05,
      "loss": 0.715,
      "step": 507350
    },
    {
      "epoch": 5.371530957384303,
      "grad_norm": 4.3641228675842285,
      "learning_rate": 2.3153557061189925e-05,
      "loss": 0.7171,
      "step": 507400
    },
    {
      "epoch": 5.372060279164307,
      "grad_norm": 4.386818885803223,
      "learning_rate": 2.3150910438280756e-05,
      "loss": 0.7106,
      "step": 507450
    },
    {
      "epoch": 5.37258960094431,
      "grad_norm": 4.292190074920654,
      "learning_rate": 2.3148263815371586e-05,
      "loss": 0.7193,
      "step": 507500
    },
    {
      "epoch": 5.37258960094431,
      "eval_loss": 0.4626762270927429,
      "eval_runtime": 46.7816,
      "eval_samples_per_second": 3589.663,
      "eval_steps_per_second": 448.724,
      "step": 507500
    },
    {
      "epoch": 5.373118922724314,
      "grad_norm": 4.389206409454346,
      "learning_rate": 2.3145617192462417e-05,
      "loss": 0.706,
      "step": 507550
    },
    {
      "epoch": 5.3736482445043166,
      "grad_norm": 4.714814186096191,
      "learning_rate": 2.314297056955325e-05,
      "loss": 0.7159,
      "step": 507600
    },
    {
      "epoch": 5.37417756628432,
      "grad_norm": 4.4496684074401855,
      "learning_rate": 2.3140323946644082e-05,
      "loss": 0.7215,
      "step": 507650
    },
    {
      "epoch": 5.374706888064323,
      "grad_norm": 4.121206760406494,
      "learning_rate": 2.3137677323734916e-05,
      "loss": 0.7166,
      "step": 507700
    },
    {
      "epoch": 5.375236209844326,
      "grad_norm": 4.467477321624756,
      "learning_rate": 2.3135030700825747e-05,
      "loss": 0.7002,
      "step": 507750
    },
    {
      "epoch": 5.37576553162433,
      "grad_norm": 4.335108280181885,
      "learning_rate": 2.313238407791658e-05,
      "loss": 0.6982,
      "step": 507800
    },
    {
      "epoch": 5.376294853404333,
      "grad_norm": 3.937303304672241,
      "learning_rate": 2.312973745500741e-05,
      "loss": 0.7095,
      "step": 507850
    },
    {
      "epoch": 5.376824175184336,
      "grad_norm": 3.811976909637451,
      "learning_rate": 2.3127090832098245e-05,
      "loss": 0.7133,
      "step": 507900
    },
    {
      "epoch": 5.377353496964339,
      "grad_norm": 4.061642646789551,
      "learning_rate": 2.3124444209189076e-05,
      "loss": 0.7087,
      "step": 507950
    },
    {
      "epoch": 5.377882818744343,
      "grad_norm": 4.1610493659973145,
      "learning_rate": 2.3121797586279907e-05,
      "loss": 0.7092,
      "step": 508000
    },
    {
      "epoch": 5.377882818744343,
      "eval_loss": 0.4645334780216217,
      "eval_runtime": 46.8094,
      "eval_samples_per_second": 3587.527,
      "eval_steps_per_second": 448.457,
      "step": 508000
    },
    {
      "epoch": 5.378412140524346,
      "grad_norm": 4.247777462005615,
      "learning_rate": 2.3119150963370738e-05,
      "loss": 0.7127,
      "step": 508050
    },
    {
      "epoch": 5.37894146230435,
      "grad_norm": 4.431328773498535,
      "learning_rate": 2.3116504340461572e-05,
      "loss": 0.6999,
      "step": 508100
    },
    {
      "epoch": 5.3794707840843525,
      "grad_norm": 4.019072532653809,
      "learning_rate": 2.3113857717552402e-05,
      "loss": 0.7128,
      "step": 508150
    },
    {
      "epoch": 5.380000105864356,
      "grad_norm": 3.929987668991089,
      "learning_rate": 2.3111211094643237e-05,
      "loss": 0.705,
      "step": 508200
    },
    {
      "epoch": 5.380529427644359,
      "grad_norm": 4.464632987976074,
      "learning_rate": 2.3108564471734067e-05,
      "loss": 0.7034,
      "step": 508250
    },
    {
      "epoch": 5.381058749424363,
      "grad_norm": 3.9304604530334473,
      "learning_rate": 2.31059178488249e-05,
      "loss": 0.7027,
      "step": 508300
    },
    {
      "epoch": 5.381588071204366,
      "grad_norm": 4.2815141677856445,
      "learning_rate": 2.3103271225915732e-05,
      "loss": 0.713,
      "step": 508350
    },
    {
      "epoch": 5.3821173929843695,
      "grad_norm": 3.727740526199341,
      "learning_rate": 2.3100624603006566e-05,
      "loss": 0.7093,
      "step": 508400
    },
    {
      "epoch": 5.382646714764372,
      "grad_norm": 4.2161359786987305,
      "learning_rate": 2.3097977980097397e-05,
      "loss": 0.705,
      "step": 508450
    },
    {
      "epoch": 5.383176036544375,
      "grad_norm": 4.320317268371582,
      "learning_rate": 2.309533135718823e-05,
      "loss": 0.6952,
      "step": 508500
    },
    {
      "epoch": 5.383176036544375,
      "eval_loss": 0.4631366729736328,
      "eval_runtime": 46.8032,
      "eval_samples_per_second": 3588.001,
      "eval_steps_per_second": 448.516,
      "step": 508500
    },
    {
      "epoch": 5.383705358324379,
      "grad_norm": 4.668626308441162,
      "learning_rate": 2.309268473427906e-05,
      "loss": 0.7092,
      "step": 508550
    },
    {
      "epoch": 5.384234680104382,
      "grad_norm": 4.173113822937012,
      "learning_rate": 2.3090038111369892e-05,
      "loss": 0.7049,
      "step": 508600
    },
    {
      "epoch": 5.384764001884386,
      "grad_norm": 3.802788734436035,
      "learning_rate": 2.3087391488460723e-05,
      "loss": 0.7167,
      "step": 508650
    },
    {
      "epoch": 5.3852933236643885,
      "grad_norm": 4.316944599151611,
      "learning_rate": 2.3084744865551557e-05,
      "loss": 0.6956,
      "step": 508700
    },
    {
      "epoch": 5.385822645444392,
      "grad_norm": 4.1597723960876465,
      "learning_rate": 2.3082098242642388e-05,
      "loss": 0.7166,
      "step": 508750
    },
    {
      "epoch": 5.386351967224395,
      "grad_norm": 4.275291442871094,
      "learning_rate": 2.3079451619733222e-05,
      "loss": 0.7021,
      "step": 508800
    },
    {
      "epoch": 5.386881289004399,
      "grad_norm": 4.223531246185303,
      "learning_rate": 2.3076804996824053e-05,
      "loss": 0.7069,
      "step": 508850
    },
    {
      "epoch": 5.387410610784402,
      "grad_norm": 4.394790172576904,
      "learning_rate": 2.3074158373914887e-05,
      "loss": 0.7051,
      "step": 508900
    },
    {
      "epoch": 5.3879399325644055,
      "grad_norm": 4.172224044799805,
      "learning_rate": 2.3071511751005718e-05,
      "loss": 0.6956,
      "step": 508950
    },
    {
      "epoch": 5.388469254344408,
      "grad_norm": 4.105618953704834,
      "learning_rate": 2.306886512809655e-05,
      "loss": 0.7027,
      "step": 509000
    },
    {
      "epoch": 5.388469254344408,
      "eval_loss": 0.46220844984054565,
      "eval_runtime": 46.7328,
      "eval_samples_per_second": 3593.409,
      "eval_steps_per_second": 449.192,
      "step": 509000
    },
    {
      "epoch": 5.388998576124412,
      "grad_norm": 4.177440166473389,
      "learning_rate": 2.3066218505187382e-05,
      "loss": 0.7067,
      "step": 509050
    },
    {
      "epoch": 5.389527897904415,
      "grad_norm": 4.330263614654541,
      "learning_rate": 2.3063571882278216e-05,
      "loss": 0.692,
      "step": 509100
    },
    {
      "epoch": 5.390057219684419,
      "grad_norm": 4.523775577545166,
      "learning_rate": 2.3060925259369047e-05,
      "loss": 0.7051,
      "step": 509150
    },
    {
      "epoch": 5.390586541464422,
      "grad_norm": 3.908522129058838,
      "learning_rate": 2.3058278636459878e-05,
      "loss": 0.7055,
      "step": 509200
    },
    {
      "epoch": 5.3911158632444245,
      "grad_norm": 3.960913896560669,
      "learning_rate": 2.3055684946008893e-05,
      "loss": 0.7077,
      "step": 509250
    },
    {
      "epoch": 5.391645185024428,
      "grad_norm": 4.538529872894287,
      "learning_rate": 2.3053038323099727e-05,
      "loss": 0.7093,
      "step": 509300
    },
    {
      "epoch": 5.392174506804431,
      "grad_norm": 4.439494609832764,
      "learning_rate": 2.3050391700190557e-05,
      "loss": 0.7058,
      "step": 509350
    },
    {
      "epoch": 5.392703828584435,
      "grad_norm": 4.501227855682373,
      "learning_rate": 2.304774507728139e-05,
      "loss": 0.7058,
      "step": 509400
    },
    {
      "epoch": 5.393233150364438,
      "grad_norm": 4.495439052581787,
      "learning_rate": 2.3045098454372222e-05,
      "loss": 0.7115,
      "step": 509450
    },
    {
      "epoch": 5.3937624721444415,
      "grad_norm": 4.422703266143799,
      "learning_rate": 2.3042451831463056e-05,
      "loss": 0.7072,
      "step": 509500
    },
    {
      "epoch": 5.3937624721444415,
      "eval_loss": 0.46179816126823425,
      "eval_runtime": 46.8765,
      "eval_samples_per_second": 3582.392,
      "eval_steps_per_second": 447.815,
      "step": 509500
    },
    {
      "epoch": 5.394291793924444,
      "grad_norm": 4.378329753875732,
      "learning_rate": 2.3039805208553887e-05,
      "loss": 0.7074,
      "step": 509550
    },
    {
      "epoch": 5.394821115704448,
      "grad_norm": 4.319454669952393,
      "learning_rate": 2.3037158585644718e-05,
      "loss": 0.7078,
      "step": 509600
    },
    {
      "epoch": 5.395350437484451,
      "grad_norm": 4.282545566558838,
      "learning_rate": 2.303451196273555e-05,
      "loss": 0.6962,
      "step": 509650
    },
    {
      "epoch": 5.395879759264455,
      "grad_norm": 4.2896223068237305,
      "learning_rate": 2.3031865339826383e-05,
      "loss": 0.723,
      "step": 509700
    },
    {
      "epoch": 5.396409081044458,
      "grad_norm": 4.486889362335205,
      "learning_rate": 2.3029218716917213e-05,
      "loss": 0.7149,
      "step": 509750
    },
    {
      "epoch": 5.396938402824461,
      "grad_norm": 4.234846115112305,
      "learning_rate": 2.3026572094008047e-05,
      "loss": 0.7122,
      "step": 509800
    },
    {
      "epoch": 5.397467724604464,
      "grad_norm": 4.258995532989502,
      "learning_rate": 2.3023925471098878e-05,
      "loss": 0.7147,
      "step": 509850
    },
    {
      "epoch": 5.397997046384468,
      "grad_norm": 4.366048812866211,
      "learning_rate": 2.3021278848189712e-05,
      "loss": 0.7048,
      "step": 509900
    },
    {
      "epoch": 5.398526368164471,
      "grad_norm": 4.0591511726379395,
      "learning_rate": 2.3018632225280543e-05,
      "loss": 0.7103,
      "step": 509950
    },
    {
      "epoch": 5.399055689944474,
      "grad_norm": 4.643092155456543,
      "learning_rate": 2.3015985602371377e-05,
      "loss": 0.7149,
      "step": 510000
    },
    {
      "epoch": 5.399055689944474,
      "eval_loss": 0.4621589779853821,
      "eval_runtime": 46.8096,
      "eval_samples_per_second": 3587.511,
      "eval_steps_per_second": 448.455,
      "step": 510000
    },
    {
      "epoch": 5.3995850117244775,
      "grad_norm": 4.2409987449646,
      "learning_rate": 2.3013338979462208e-05,
      "loss": 0.7097,
      "step": 510050
    },
    {
      "epoch": 5.40011433350448,
      "grad_norm": 4.333565711975098,
      "learning_rate": 2.3010692356553042e-05,
      "loss": 0.7004,
      "step": 510100
    },
    {
      "epoch": 5.400643655284484,
      "grad_norm": 4.2568793296813965,
      "learning_rate": 2.3008045733643872e-05,
      "loss": 0.7159,
      "step": 510150
    },
    {
      "epoch": 5.401172977064487,
      "grad_norm": 4.671564102172852,
      "learning_rate": 2.3005399110734703e-05,
      "loss": 0.7032,
      "step": 510200
    },
    {
      "epoch": 5.401702298844491,
      "grad_norm": 4.0266265869140625,
      "learning_rate": 2.3002752487825534e-05,
      "loss": 0.7196,
      "step": 510250
    },
    {
      "epoch": 5.402231620624494,
      "grad_norm": 4.34223747253418,
      "learning_rate": 2.3000105864916368e-05,
      "loss": 0.7126,
      "step": 510300
    },
    {
      "epoch": 5.402760942404497,
      "grad_norm": 4.6014885902404785,
      "learning_rate": 2.29974592420072e-05,
      "loss": 0.7133,
      "step": 510350
    },
    {
      "epoch": 5.4032902641845,
      "grad_norm": 4.14069938659668,
      "learning_rate": 2.2994812619098033e-05,
      "loss": 0.7036,
      "step": 510400
    },
    {
      "epoch": 5.403819585964504,
      "grad_norm": 4.275671482086182,
      "learning_rate": 2.2992165996188864e-05,
      "loss": 0.7081,
      "step": 510450
    },
    {
      "epoch": 5.404348907744507,
      "grad_norm": 4.497611999511719,
      "learning_rate": 2.2989519373279698e-05,
      "loss": 0.7186,
      "step": 510500
    },
    {
      "epoch": 5.404348907744507,
      "eval_loss": 0.4623258709907532,
      "eval_runtime": 46.7911,
      "eval_samples_per_second": 3588.929,
      "eval_steps_per_second": 448.632,
      "step": 510500
    },
    {
      "epoch": 5.404878229524511,
      "grad_norm": 4.37437629699707,
      "learning_rate": 2.298687275037053e-05,
      "loss": 0.6976,
      "step": 510550
    },
    {
      "epoch": 5.4054075513045134,
      "grad_norm": 4.430015563964844,
      "learning_rate": 2.2984226127461362e-05,
      "loss": 0.7103,
      "step": 510600
    },
    {
      "epoch": 5.405936873084517,
      "grad_norm": 4.178730010986328,
      "learning_rate": 2.2981579504552193e-05,
      "loss": 0.6998,
      "step": 510650
    },
    {
      "epoch": 5.40646619486452,
      "grad_norm": 4.19018030166626,
      "learning_rate": 2.2978932881643024e-05,
      "loss": 0.7128,
      "step": 510700
    },
    {
      "epoch": 5.406995516644523,
      "grad_norm": 4.318716526031494,
      "learning_rate": 2.2976286258733855e-05,
      "loss": 0.7139,
      "step": 510750
    },
    {
      "epoch": 5.407524838424527,
      "grad_norm": 4.1721014976501465,
      "learning_rate": 2.297363963582469e-05,
      "loss": 0.6965,
      "step": 510800
    },
    {
      "epoch": 5.40805416020453,
      "grad_norm": 4.308100700378418,
      "learning_rate": 2.297099301291552e-05,
      "loss": 0.7127,
      "step": 510850
    },
    {
      "epoch": 5.408583481984533,
      "grad_norm": 3.993337392807007,
      "learning_rate": 2.2968346390006353e-05,
      "loss": 0.7012,
      "step": 510900
    },
    {
      "epoch": 5.409112803764536,
      "grad_norm": 4.682030200958252,
      "learning_rate": 2.2965699767097184e-05,
      "loss": 0.7132,
      "step": 510950
    },
    {
      "epoch": 5.40964212554454,
      "grad_norm": 4.499521255493164,
      "learning_rate": 2.2963053144188018e-05,
      "loss": 0.7033,
      "step": 511000
    },
    {
      "epoch": 5.40964212554454,
      "eval_loss": 0.4613470435142517,
      "eval_runtime": 46.7686,
      "eval_samples_per_second": 3590.661,
      "eval_steps_per_second": 448.849,
      "step": 511000
    },
    {
      "epoch": 5.410171447324543,
      "grad_norm": 4.036444664001465,
      "learning_rate": 2.296040652127885e-05,
      "loss": 0.7073,
      "step": 511050
    },
    {
      "epoch": 5.410700769104547,
      "grad_norm": 4.240053176879883,
      "learning_rate": 2.2957759898369683e-05,
      "loss": 0.7039,
      "step": 511100
    },
    {
      "epoch": 5.411230090884549,
      "grad_norm": 4.44947624206543,
      "learning_rate": 2.2955113275460514e-05,
      "loss": 0.7207,
      "step": 511150
    },
    {
      "epoch": 5.411759412664553,
      "grad_norm": 4.322113513946533,
      "learning_rate": 2.2952466652551348e-05,
      "loss": 0.7072,
      "step": 511200
    },
    {
      "epoch": 5.412288734444556,
      "grad_norm": 4.087790012359619,
      "learning_rate": 2.294987296210036e-05,
      "loss": 0.6924,
      "step": 511250
    },
    {
      "epoch": 5.41281805622456,
      "grad_norm": 3.9012112617492676,
      "learning_rate": 2.2947226339191193e-05,
      "loss": 0.6985,
      "step": 511300
    },
    {
      "epoch": 5.413347378004563,
      "grad_norm": 4.780645370483398,
      "learning_rate": 2.2944579716282024e-05,
      "loss": 0.7117,
      "step": 511350
    },
    {
      "epoch": 5.413876699784566,
      "grad_norm": 4.211714744567871,
      "learning_rate": 2.2941933093372858e-05,
      "loss": 0.7096,
      "step": 511400
    },
    {
      "epoch": 5.414406021564569,
      "grad_norm": 4.069422245025635,
      "learning_rate": 2.293928647046369e-05,
      "loss": 0.7095,
      "step": 511450
    },
    {
      "epoch": 5.414935343344572,
      "grad_norm": 3.9011902809143066,
      "learning_rate": 2.2936639847554523e-05,
      "loss": 0.7092,
      "step": 511500
    },
    {
      "epoch": 5.414935343344572,
      "eval_loss": 0.4629930555820465,
      "eval_runtime": 46.7286,
      "eval_samples_per_second": 3593.731,
      "eval_steps_per_second": 449.232,
      "step": 511500
    },
    {
      "epoch": 5.415464665124576,
      "grad_norm": 4.687455654144287,
      "learning_rate": 2.2933993224645354e-05,
      "loss": 0.7186,
      "step": 511550
    },
    {
      "epoch": 5.415993986904579,
      "grad_norm": 4.252029895782471,
      "learning_rate": 2.2931346601736188e-05,
      "loss": 0.7129,
      "step": 511600
    },
    {
      "epoch": 5.4165233086845825,
      "grad_norm": 4.2384138107299805,
      "learning_rate": 2.292869997882702e-05,
      "loss": 0.7142,
      "step": 511650
    },
    {
      "epoch": 5.417052630464585,
      "grad_norm": 3.8703858852386475,
      "learning_rate": 2.292605335591785e-05,
      "loss": 0.7042,
      "step": 511700
    },
    {
      "epoch": 5.417581952244589,
      "grad_norm": 4.294084548950195,
      "learning_rate": 2.292340673300868e-05,
      "loss": 0.7141,
      "step": 511750
    },
    {
      "epoch": 5.418111274024592,
      "grad_norm": 4.003053188323975,
      "learning_rate": 2.2920760110099514e-05,
      "loss": 0.7012,
      "step": 511800
    },
    {
      "epoch": 5.418640595804596,
      "grad_norm": 4.268901824951172,
      "learning_rate": 2.2918113487190345e-05,
      "loss": 0.6932,
      "step": 511850
    },
    {
      "epoch": 5.419169917584599,
      "grad_norm": 4.520442962646484,
      "learning_rate": 2.291546686428118e-05,
      "loss": 0.7127,
      "step": 511900
    },
    {
      "epoch": 5.419699239364602,
      "grad_norm": 4.0829081535339355,
      "learning_rate": 2.291282024137201e-05,
      "loss": 0.7048,
      "step": 511950
    },
    {
      "epoch": 5.420228561144605,
      "grad_norm": 4.230574607849121,
      "learning_rate": 2.2910173618462844e-05,
      "loss": 0.7097,
      "step": 512000
    },
    {
      "epoch": 5.420228561144605,
      "eval_loss": 0.4615228474140167,
      "eval_runtime": 46.764,
      "eval_samples_per_second": 3591.01,
      "eval_steps_per_second": 448.892,
      "step": 512000
    },
    {
      "epoch": 5.420757882924609,
      "grad_norm": 4.455174922943115,
      "learning_rate": 2.2907526995553674e-05,
      "loss": 0.7041,
      "step": 512050
    },
    {
      "epoch": 5.421287204704612,
      "grad_norm": 4.257218837738037,
      "learning_rate": 2.290488037264451e-05,
      "loss": 0.7091,
      "step": 512100
    },
    {
      "epoch": 5.421816526484616,
      "grad_norm": 4.770268440246582,
      "learning_rate": 2.290223374973534e-05,
      "loss": 0.7048,
      "step": 512150
    },
    {
      "epoch": 5.4223458482646185,
      "grad_norm": 4.475320816040039,
      "learning_rate": 2.2899587126826173e-05,
      "loss": 0.7102,
      "step": 512200
    },
    {
      "epoch": 5.422875170044621,
      "grad_norm": 4.277082920074463,
      "learning_rate": 2.2896940503917004e-05,
      "loss": 0.6994,
      "step": 512250
    },
    {
      "epoch": 5.423404491824625,
      "grad_norm": 4.513139724731445,
      "learning_rate": 2.2894293881007835e-05,
      "loss": 0.7046,
      "step": 512300
    },
    {
      "epoch": 5.423933813604628,
      "grad_norm": 4.234098434448242,
      "learning_rate": 2.2891647258098665e-05,
      "loss": 0.709,
      "step": 512350
    },
    {
      "epoch": 5.424463135384632,
      "grad_norm": 4.324174404144287,
      "learning_rate": 2.28890006351895e-05,
      "loss": 0.6915,
      "step": 512400
    },
    {
      "epoch": 5.424992457164635,
      "grad_norm": 4.212671279907227,
      "learning_rate": 2.288635401228033e-05,
      "loss": 0.7037,
      "step": 512450
    },
    {
      "epoch": 5.425521778944638,
      "grad_norm": 4.422366142272949,
      "learning_rate": 2.2883707389371164e-05,
      "loss": 0.7211,
      "step": 512500
    },
    {
      "epoch": 5.425521778944638,
      "eval_loss": 0.46185046434402466,
      "eval_runtime": 46.8804,
      "eval_samples_per_second": 3582.091,
      "eval_steps_per_second": 447.777,
      "step": 512500
    },
    {
      "epoch": 5.426051100724641,
      "grad_norm": 4.29017972946167,
      "learning_rate": 2.2881060766461995e-05,
      "loss": 0.7277,
      "step": 512550
    },
    {
      "epoch": 5.426580422504645,
      "grad_norm": 4.119739055633545,
      "learning_rate": 2.287841414355283e-05,
      "loss": 0.7067,
      "step": 512600
    },
    {
      "epoch": 5.427109744284648,
      "grad_norm": 3.6793718338012695,
      "learning_rate": 2.287576752064366e-05,
      "loss": 0.7141,
      "step": 512650
    },
    {
      "epoch": 5.427639066064652,
      "grad_norm": 4.365096092224121,
      "learning_rate": 2.2873120897734494e-05,
      "loss": 0.7144,
      "step": 512700
    },
    {
      "epoch": 5.4281683878446545,
      "grad_norm": 4.552035808563232,
      "learning_rate": 2.2870474274825325e-05,
      "loss": 0.7112,
      "step": 512750
    },
    {
      "epoch": 5.428697709624658,
      "grad_norm": 4.518559455871582,
      "learning_rate": 2.286782765191616e-05,
      "loss": 0.712,
      "step": 512800
    },
    {
      "epoch": 5.429227031404661,
      "grad_norm": 4.365865230560303,
      "learning_rate": 2.286518102900699e-05,
      "loss": 0.7155,
      "step": 512850
    },
    {
      "epoch": 5.429756353184665,
      "grad_norm": 4.269465923309326,
      "learning_rate": 2.286253440609782e-05,
      "loss": 0.716,
      "step": 512900
    },
    {
      "epoch": 5.430285674964668,
      "grad_norm": 4.4110894203186035,
      "learning_rate": 2.285988778318865e-05,
      "loss": 0.7068,
      "step": 512950
    },
    {
      "epoch": 5.430814996744671,
      "grad_norm": 4.173233509063721,
      "learning_rate": 2.2857241160279485e-05,
      "loss": 0.7034,
      "step": 513000
    },
    {
      "epoch": 5.430814996744671,
      "eval_loss": 0.4614426791667938,
      "eval_runtime": 46.9123,
      "eval_samples_per_second": 3579.656,
      "eval_steps_per_second": 447.473,
      "step": 513000
    },
    {
      "epoch": 5.431344318524674,
      "grad_norm": 3.899312973022461,
      "learning_rate": 2.2854594537370316e-05,
      "loss": 0.7102,
      "step": 513050
    },
    {
      "epoch": 5.431873640304677,
      "grad_norm": 4.114861488342285,
      "learning_rate": 2.285194791446115e-05,
      "loss": 0.7121,
      "step": 513100
    },
    {
      "epoch": 5.432402962084681,
      "grad_norm": 5.073186874389648,
      "learning_rate": 2.284930129155198e-05,
      "loss": 0.7032,
      "step": 513150
    },
    {
      "epoch": 5.432932283864684,
      "grad_norm": 4.572988510131836,
      "learning_rate": 2.2846654668642815e-05,
      "loss": 0.699,
      "step": 513200
    },
    {
      "epoch": 5.433461605644688,
      "grad_norm": 3.983013868331909,
      "learning_rate": 2.284406097819183e-05,
      "loss": 0.7057,
      "step": 513250
    },
    {
      "epoch": 5.4339909274246905,
      "grad_norm": 4.400146961212158,
      "learning_rate": 2.284141435528266e-05,
      "loss": 0.7051,
      "step": 513300
    },
    {
      "epoch": 5.434520249204694,
      "grad_norm": 4.518276214599609,
      "learning_rate": 2.283876773237349e-05,
      "loss": 0.7023,
      "step": 513350
    },
    {
      "epoch": 5.435049570984697,
      "grad_norm": 4.446208477020264,
      "learning_rate": 2.2836121109464325e-05,
      "loss": 0.7226,
      "step": 513400
    },
    {
      "epoch": 5.435578892764701,
      "grad_norm": 4.31874418258667,
      "learning_rate": 2.2833474486555156e-05,
      "loss": 0.7026,
      "step": 513450
    },
    {
      "epoch": 5.436108214544704,
      "grad_norm": 3.8521502017974854,
      "learning_rate": 2.283082786364599e-05,
      "loss": 0.7058,
      "step": 513500
    },
    {
      "epoch": 5.436108214544704,
      "eval_loss": 0.4622003138065338,
      "eval_runtime": 46.9446,
      "eval_samples_per_second": 3577.192,
      "eval_steps_per_second": 447.165,
      "step": 513500
    },
    {
      "epoch": 5.4366375363247075,
      "grad_norm": 4.270730018615723,
      "learning_rate": 2.282818124073682e-05,
      "loss": 0.7032,
      "step": 513550
    },
    {
      "epoch": 5.43716685810471,
      "grad_norm": 4.0404887199401855,
      "learning_rate": 2.2825534617827654e-05,
      "loss": 0.7057,
      "step": 513600
    },
    {
      "epoch": 5.437696179884714,
      "grad_norm": 4.500629425048828,
      "learning_rate": 2.2822887994918485e-05,
      "loss": 0.6998,
      "step": 513650
    },
    {
      "epoch": 5.438225501664717,
      "grad_norm": 4.154893398284912,
      "learning_rate": 2.282024137200932e-05,
      "loss": 0.704,
      "step": 513700
    },
    {
      "epoch": 5.43875482344472,
      "grad_norm": 4.359192848205566,
      "learning_rate": 2.281759474910015e-05,
      "loss": 0.7139,
      "step": 513750
    },
    {
      "epoch": 5.439284145224724,
      "grad_norm": 4.07969856262207,
      "learning_rate": 2.2814948126190984e-05,
      "loss": 0.7031,
      "step": 513800
    },
    {
      "epoch": 5.4398134670047265,
      "grad_norm": 4.077416896820068,
      "learning_rate": 2.2812301503281815e-05,
      "loss": 0.7063,
      "step": 513850
    },
    {
      "epoch": 5.44034278878473,
      "grad_norm": 5.087303161621094,
      "learning_rate": 2.2809654880372646e-05,
      "loss": 0.7101,
      "step": 513900
    },
    {
      "epoch": 5.440872110564733,
      "grad_norm": 4.63191032409668,
      "learning_rate": 2.2807008257463476e-05,
      "loss": 0.7075,
      "step": 513950
    },
    {
      "epoch": 5.441401432344737,
      "grad_norm": 4.240024089813232,
      "learning_rate": 2.280436163455431e-05,
      "loss": 0.7121,
      "step": 514000
    },
    {
      "epoch": 5.441401432344737,
      "eval_loss": 0.459222674369812,
      "eval_runtime": 46.7333,
      "eval_samples_per_second": 3593.37,
      "eval_steps_per_second": 449.187,
      "step": 514000
    },
    {
      "epoch": 5.44193075412474,
      "grad_norm": 4.34781551361084,
      "learning_rate": 2.280171501164514e-05,
      "loss": 0.7022,
      "step": 514050
    },
    {
      "epoch": 5.4424600759047435,
      "grad_norm": 4.074497222900391,
      "learning_rate": 2.2799068388735975e-05,
      "loss": 0.6984,
      "step": 514100
    },
    {
      "epoch": 5.442989397684746,
      "grad_norm": 4.53804874420166,
      "learning_rate": 2.2796421765826806e-05,
      "loss": 0.6959,
      "step": 514150
    },
    {
      "epoch": 5.44351871946475,
      "grad_norm": 3.578953742980957,
      "learning_rate": 2.279377514291764e-05,
      "loss": 0.7029,
      "step": 514200
    },
    {
      "epoch": 5.444048041244753,
      "grad_norm": 4.233964920043945,
      "learning_rate": 2.279112852000847e-05,
      "loss": 0.7072,
      "step": 514250
    },
    {
      "epoch": 5.444577363024757,
      "grad_norm": 4.342529773712158,
      "learning_rate": 2.2788481897099305e-05,
      "loss": 0.7161,
      "step": 514300
    },
    {
      "epoch": 5.44510668480476,
      "grad_norm": 4.438976287841797,
      "learning_rate": 2.2785835274190135e-05,
      "loss": 0.7166,
      "step": 514350
    },
    {
      "epoch": 5.445636006584763,
      "grad_norm": 4.845742225646973,
      "learning_rate": 2.2783188651280966e-05,
      "loss": 0.709,
      "step": 514400
    },
    {
      "epoch": 5.446165328364766,
      "grad_norm": 4.0967912673950195,
      "learning_rate": 2.2780542028371797e-05,
      "loss": 0.7169,
      "step": 514450
    },
    {
      "epoch": 5.446694650144769,
      "grad_norm": 4.522916316986084,
      "learning_rate": 2.277789540546263e-05,
      "loss": 0.7044,
      "step": 514500
    },
    {
      "epoch": 5.446694650144769,
      "eval_loss": 0.46075257658958435,
      "eval_runtime": 46.8973,
      "eval_samples_per_second": 3580.802,
      "eval_steps_per_second": 447.616,
      "step": 514500
    },
    {
      "epoch": 5.447223971924773,
      "grad_norm": 4.571364879608154,
      "learning_rate": 2.2775248782553462e-05,
      "loss": 0.6947,
      "step": 514550
    },
    {
      "epoch": 5.447753293704776,
      "grad_norm": 3.7556402683258057,
      "learning_rate": 2.2772602159644296e-05,
      "loss": 0.6994,
      "step": 514600
    },
    {
      "epoch": 5.448282615484779,
      "grad_norm": 4.19867467880249,
      "learning_rate": 2.2769955536735127e-05,
      "loss": 0.6906,
      "step": 514650
    },
    {
      "epoch": 5.448811937264782,
      "grad_norm": 4.336885929107666,
      "learning_rate": 2.276730891382596e-05,
      "loss": 0.7174,
      "step": 514700
    },
    {
      "epoch": 5.449341259044786,
      "grad_norm": 4.641170024871826,
      "learning_rate": 2.276466229091679e-05,
      "loss": 0.7048,
      "step": 514750
    },
    {
      "epoch": 5.449870580824789,
      "grad_norm": 4.201528549194336,
      "learning_rate": 2.2762015668007625e-05,
      "loss": 0.7075,
      "step": 514800
    },
    {
      "epoch": 5.450399902604793,
      "grad_norm": 4.164247989654541,
      "learning_rate": 2.2759369045098456e-05,
      "loss": 0.7012,
      "step": 514850
    },
    {
      "epoch": 5.4509292243847955,
      "grad_norm": 4.282524108886719,
      "learning_rate": 2.275672242218929e-05,
      "loss": 0.7133,
      "step": 514900
    },
    {
      "epoch": 5.451458546164799,
      "grad_norm": 4.566065311431885,
      "learning_rate": 2.275407579928012e-05,
      "loss": 0.7157,
      "step": 514950
    },
    {
      "epoch": 5.451987867944802,
      "grad_norm": 4.435638904571533,
      "learning_rate": 2.275142917637095e-05,
      "loss": 0.7044,
      "step": 515000
    },
    {
      "epoch": 5.451987867944802,
      "eval_loss": 0.46070972084999084,
      "eval_runtime": 46.7555,
      "eval_samples_per_second": 3591.664,
      "eval_steps_per_second": 448.974,
      "step": 515000
    },
    {
      "epoch": 5.452517189724806,
      "grad_norm": 4.302878379821777,
      "learning_rate": 2.2748782553461782e-05,
      "loss": 0.7067,
      "step": 515050
    },
    {
      "epoch": 5.453046511504809,
      "grad_norm": 4.15629768371582,
      "learning_rate": 2.2746135930552616e-05,
      "loss": 0.7064,
      "step": 515100
    },
    {
      "epoch": 5.4535758332848125,
      "grad_norm": 4.118819236755371,
      "learning_rate": 2.2743489307643447e-05,
      "loss": 0.7231,
      "step": 515150
    },
    {
      "epoch": 5.454105155064815,
      "grad_norm": 4.076456546783447,
      "learning_rate": 2.274084268473428e-05,
      "loss": 0.7075,
      "step": 515200
    },
    {
      "epoch": 5.454634476844818,
      "grad_norm": 4.652956008911133,
      "learning_rate": 2.2738248994283296e-05,
      "loss": 0.708,
      "step": 515250
    },
    {
      "epoch": 5.455163798624822,
      "grad_norm": 4.500459671020508,
      "learning_rate": 2.273560237137413e-05,
      "loss": 0.7048,
      "step": 515300
    },
    {
      "epoch": 5.455693120404825,
      "grad_norm": 4.262955188751221,
      "learning_rate": 2.273295574846496e-05,
      "loss": 0.6986,
      "step": 515350
    },
    {
      "epoch": 5.456222442184829,
      "grad_norm": 4.384692668914795,
      "learning_rate": 2.273030912555579e-05,
      "loss": 0.7108,
      "step": 515400
    },
    {
      "epoch": 5.4567517639648315,
      "grad_norm": 4.401788711547852,
      "learning_rate": 2.2727662502646622e-05,
      "loss": 0.7083,
      "step": 515450
    },
    {
      "epoch": 5.457281085744835,
      "grad_norm": 4.203360557556152,
      "learning_rate": 2.2725015879737456e-05,
      "loss": 0.6973,
      "step": 515500
    },
    {
      "epoch": 5.457281085744835,
      "eval_loss": 0.45970308780670166,
      "eval_runtime": 46.7252,
      "eval_samples_per_second": 3593.993,
      "eval_steps_per_second": 449.265,
      "step": 515500
    },
    {
      "epoch": 5.457810407524838,
      "grad_norm": 4.315927982330322,
      "learning_rate": 2.2722369256828287e-05,
      "loss": 0.7044,
      "step": 515550
    },
    {
      "epoch": 5.458339729304842,
      "grad_norm": 4.902719020843506,
      "learning_rate": 2.271972263391912e-05,
      "loss": 0.7067,
      "step": 515600
    },
    {
      "epoch": 5.458869051084845,
      "grad_norm": 4.53196907043457,
      "learning_rate": 2.2717076011009952e-05,
      "loss": 0.7035,
      "step": 515650
    },
    {
      "epoch": 5.4593983728648485,
      "grad_norm": 4.170405864715576,
      "learning_rate": 2.2714429388100786e-05,
      "loss": 0.7062,
      "step": 515700
    },
    {
      "epoch": 5.459927694644851,
      "grad_norm": 4.0693864822387695,
      "learning_rate": 2.2711782765191617e-05,
      "loss": 0.7111,
      "step": 515750
    },
    {
      "epoch": 5.460457016424855,
      "grad_norm": 4.292069435119629,
      "learning_rate": 2.270913614228245e-05,
      "loss": 0.7108,
      "step": 515800
    },
    {
      "epoch": 5.460986338204858,
      "grad_norm": 4.251253604888916,
      "learning_rate": 2.270648951937328e-05,
      "loss": 0.7029,
      "step": 515850
    },
    {
      "epoch": 5.461515659984862,
      "grad_norm": 4.317915916442871,
      "learning_rate": 2.2703842896464116e-05,
      "loss": 0.7025,
      "step": 515900
    },
    {
      "epoch": 5.462044981764865,
      "grad_norm": 4.5040998458862305,
      "learning_rate": 2.2701196273554946e-05,
      "loss": 0.707,
      "step": 515950
    },
    {
      "epoch": 5.4625743035448675,
      "grad_norm": 4.427035808563232,
      "learning_rate": 2.2698549650645777e-05,
      "loss": 0.7031,
      "step": 516000
    },
    {
      "epoch": 5.4625743035448675,
      "eval_loss": 0.45999306440353394,
      "eval_runtime": 46.7271,
      "eval_samples_per_second": 3593.846,
      "eval_steps_per_second": 449.247,
      "step": 516000
    },
    {
      "epoch": 5.463103625324871,
      "grad_norm": 4.2964091300964355,
      "learning_rate": 2.2695903027736608e-05,
      "loss": 0.694,
      "step": 516050
    },
    {
      "epoch": 5.463632947104874,
      "grad_norm": 4.144755840301514,
      "learning_rate": 2.2693256404827442e-05,
      "loss": 0.6995,
      "step": 516100
    },
    {
      "epoch": 5.464162268884878,
      "grad_norm": 4.778369903564453,
      "learning_rate": 2.2690609781918273e-05,
      "loss": 0.7173,
      "step": 516150
    },
    {
      "epoch": 5.464691590664881,
      "grad_norm": 4.1344194412231445,
      "learning_rate": 2.2687963159009107e-05,
      "loss": 0.7136,
      "step": 516200
    },
    {
      "epoch": 5.4652209124448845,
      "grad_norm": 4.716172695159912,
      "learning_rate": 2.2685316536099937e-05,
      "loss": 0.7096,
      "step": 516250
    },
    {
      "epoch": 5.465750234224887,
      "grad_norm": 4.353965759277344,
      "learning_rate": 2.2682669913190768e-05,
      "loss": 0.7086,
      "step": 516300
    },
    {
      "epoch": 5.466279556004891,
      "grad_norm": 4.120787143707275,
      "learning_rate": 2.2680023290281602e-05,
      "loss": 0.703,
      "step": 516350
    },
    {
      "epoch": 5.466808877784894,
      "grad_norm": 4.655004501342773,
      "learning_rate": 2.2677376667372433e-05,
      "loss": 0.7238,
      "step": 516400
    },
    {
      "epoch": 5.467338199564898,
      "grad_norm": 4.690564155578613,
      "learning_rate": 2.2674730044463267e-05,
      "loss": 0.7145,
      "step": 516450
    },
    {
      "epoch": 5.467867521344901,
      "grad_norm": 4.427621364593506,
      "learning_rate": 2.2672083421554098e-05,
      "loss": 0.7169,
      "step": 516500
    },
    {
      "epoch": 5.467867521344901,
      "eval_loss": 0.46000757813453674,
      "eval_runtime": 46.8242,
      "eval_samples_per_second": 3586.393,
      "eval_steps_per_second": 448.315,
      "step": 516500
    },
    {
      "epoch": 5.468396843124904,
      "grad_norm": 4.106575012207031,
      "learning_rate": 2.2669436798644932e-05,
      "loss": 0.711,
      "step": 516550
    },
    {
      "epoch": 5.468926164904907,
      "grad_norm": 4.381404399871826,
      "learning_rate": 2.2666790175735762e-05,
      "loss": 0.7029,
      "step": 516600
    },
    {
      "epoch": 5.469455486684911,
      "grad_norm": 4.13942289352417,
      "learning_rate": 2.2664143552826593e-05,
      "loss": 0.7016,
      "step": 516650
    },
    {
      "epoch": 5.469984808464914,
      "grad_norm": 4.416447162628174,
      "learning_rate": 2.2661496929917424e-05,
      "loss": 0.7126,
      "step": 516700
    },
    {
      "epoch": 5.470514130244917,
      "grad_norm": 4.414472579956055,
      "learning_rate": 2.2658850307008258e-05,
      "loss": 0.7197,
      "step": 516750
    },
    {
      "epoch": 5.4710434520249205,
      "grad_norm": 4.225679397583008,
      "learning_rate": 2.265620368409909e-05,
      "loss": 0.7005,
      "step": 516800
    },
    {
      "epoch": 5.471572773804923,
      "grad_norm": 4.3186421394348145,
      "learning_rate": 2.2653557061189923e-05,
      "loss": 0.6981,
      "step": 516850
    },
    {
      "epoch": 5.472102095584927,
      "grad_norm": 4.273446559906006,
      "learning_rate": 2.2650910438280754e-05,
      "loss": 0.7045,
      "step": 516900
    },
    {
      "epoch": 5.47263141736493,
      "grad_norm": 3.971719980239868,
      "learning_rate": 2.2648263815371588e-05,
      "loss": 0.6953,
      "step": 516950
    },
    {
      "epoch": 5.473160739144934,
      "grad_norm": 4.161594867706299,
      "learning_rate": 2.264561719246242e-05,
      "loss": 0.717,
      "step": 517000
    },
    {
      "epoch": 5.473160739144934,
      "eval_loss": 0.45934414863586426,
      "eval_runtime": 46.7638,
      "eval_samples_per_second": 3591.022,
      "eval_steps_per_second": 448.894,
      "step": 517000
    },
    {
      "epoch": 5.473690060924937,
      "grad_norm": 3.7024028301239014,
      "learning_rate": 2.2642970569553252e-05,
      "loss": 0.7118,
      "step": 517050
    },
    {
      "epoch": 5.47421938270494,
      "grad_norm": 4.603419303894043,
      "learning_rate": 2.2640323946644083e-05,
      "loss": 0.7056,
      "step": 517100
    },
    {
      "epoch": 5.474748704484943,
      "grad_norm": 4.89012336730957,
      "learning_rate": 2.2637677323734914e-05,
      "loss": 0.6952,
      "step": 517150
    },
    {
      "epoch": 5.475278026264947,
      "grad_norm": 4.493114471435547,
      "learning_rate": 2.2635030700825745e-05,
      "loss": 0.7111,
      "step": 517200
    },
    {
      "epoch": 5.47580734804495,
      "grad_norm": 4.37092399597168,
      "learning_rate": 2.2632437010374763e-05,
      "loss": 0.7117,
      "step": 517250
    },
    {
      "epoch": 5.476336669824954,
      "grad_norm": 3.5918126106262207,
      "learning_rate": 2.2629790387465593e-05,
      "loss": 0.7018,
      "step": 517300
    },
    {
      "epoch": 5.4768659916049565,
      "grad_norm": 4.255054950714111,
      "learning_rate": 2.2627143764556427e-05,
      "loss": 0.692,
      "step": 517350
    },
    {
      "epoch": 5.47739531338496,
      "grad_norm": 4.762734413146973,
      "learning_rate": 2.2624497141647258e-05,
      "loss": 0.7097,
      "step": 517400
    },
    {
      "epoch": 5.477924635164963,
      "grad_norm": 4.463063716888428,
      "learning_rate": 2.2621850518738092e-05,
      "loss": 0.7086,
      "step": 517450
    },
    {
      "epoch": 5.478453956944966,
      "grad_norm": 4.775528907775879,
      "learning_rate": 2.2619203895828923e-05,
      "loss": 0.7169,
      "step": 517500
    },
    {
      "epoch": 5.478453956944966,
      "eval_loss": 0.4589226543903351,
      "eval_runtime": 46.7181,
      "eval_samples_per_second": 3594.54,
      "eval_steps_per_second": 449.334,
      "step": 517500
    },
    {
      "epoch": 5.47898327872497,
      "grad_norm": 4.325081825256348,
      "learning_rate": 2.2616557272919757e-05,
      "loss": 0.7123,
      "step": 517550
    },
    {
      "epoch": 5.479512600504973,
      "grad_norm": 4.301761627197266,
      "learning_rate": 2.2613910650010588e-05,
      "loss": 0.7078,
      "step": 517600
    },
    {
      "epoch": 5.480041922284976,
      "grad_norm": 4.4666666984558105,
      "learning_rate": 2.261126402710142e-05,
      "loss": 0.7148,
      "step": 517650
    },
    {
      "epoch": 5.480571244064979,
      "grad_norm": 4.232646942138672,
      "learning_rate": 2.260861740419225e-05,
      "loss": 0.7072,
      "step": 517700
    },
    {
      "epoch": 5.481100565844983,
      "grad_norm": 4.242899417877197,
      "learning_rate": 2.2605970781283083e-05,
      "loss": 0.6975,
      "step": 517750
    },
    {
      "epoch": 5.481629887624986,
      "grad_norm": 4.406315326690674,
      "learning_rate": 2.2603324158373914e-05,
      "loss": 0.7066,
      "step": 517800
    },
    {
      "epoch": 5.48215920940499,
      "grad_norm": 3.86257004737854,
      "learning_rate": 2.2600677535464748e-05,
      "loss": 0.7077,
      "step": 517850
    },
    {
      "epoch": 5.482688531184992,
      "grad_norm": 4.454010486602783,
      "learning_rate": 2.259803091255558e-05,
      "loss": 0.7058,
      "step": 517900
    },
    {
      "epoch": 5.483217852964996,
      "grad_norm": 4.470112323760986,
      "learning_rate": 2.2595384289646413e-05,
      "loss": 0.6919,
      "step": 517950
    },
    {
      "epoch": 5.483747174744999,
      "grad_norm": 4.607954025268555,
      "learning_rate": 2.2592737666737244e-05,
      "loss": 0.7205,
      "step": 518000
    },
    {
      "epoch": 5.483747174744999,
      "eval_loss": 0.45966967940330505,
      "eval_runtime": 46.7349,
      "eval_samples_per_second": 3593.246,
      "eval_steps_per_second": 449.172,
      "step": 518000
    },
    {
      "epoch": 5.484276496525003,
      "grad_norm": 4.812648773193359,
      "learning_rate": 2.2590091043828078e-05,
      "loss": 0.7187,
      "step": 518050
    },
    {
      "epoch": 5.484805818305006,
      "grad_norm": 4.345741271972656,
      "learning_rate": 2.258744442091891e-05,
      "loss": 0.7194,
      "step": 518100
    },
    {
      "epoch": 5.485335140085009,
      "grad_norm": 4.328851222991943,
      "learning_rate": 2.258479779800974e-05,
      "loss": 0.7045,
      "step": 518150
    },
    {
      "epoch": 5.485864461865012,
      "grad_norm": 4.449753284454346,
      "learning_rate": 2.258215117510057e-05,
      "loss": 0.7077,
      "step": 518200
    },
    {
      "epoch": 5.486393783645015,
      "grad_norm": 4.116918563842773,
      "learning_rate": 2.2579504552191404e-05,
      "loss": 0.7023,
      "step": 518250
    },
    {
      "epoch": 5.486923105425019,
      "grad_norm": 4.266434192657471,
      "learning_rate": 2.2576857929282235e-05,
      "loss": 0.6992,
      "step": 518300
    },
    {
      "epoch": 5.487452427205022,
      "grad_norm": 4.405918598175049,
      "learning_rate": 2.257421130637307e-05,
      "loss": 0.6977,
      "step": 518350
    },
    {
      "epoch": 5.4879817489850256,
      "grad_norm": 4.513495445251465,
      "learning_rate": 2.25715646834639e-05,
      "loss": 0.7157,
      "step": 518400
    },
    {
      "epoch": 5.488511070765028,
      "grad_norm": 4.276200294494629,
      "learning_rate": 2.2568918060554734e-05,
      "loss": 0.6856,
      "step": 518450
    },
    {
      "epoch": 5.489040392545032,
      "grad_norm": 4.309440612792969,
      "learning_rate": 2.2566271437645564e-05,
      "loss": 0.7199,
      "step": 518500
    },
    {
      "epoch": 5.489040392545032,
      "eval_loss": 0.4586441218852997,
      "eval_runtime": 46.7077,
      "eval_samples_per_second": 3595.339,
      "eval_steps_per_second": 449.433,
      "step": 518500
    },
    {
      "epoch": 5.489569714325035,
      "grad_norm": 4.8848066329956055,
      "learning_rate": 2.25636248147364e-05,
      "loss": 0.7134,
      "step": 518550
    },
    {
      "epoch": 5.490099036105039,
      "grad_norm": 4.057159423828125,
      "learning_rate": 2.256097819182723e-05,
      "loss": 0.7085,
      "step": 518600
    },
    {
      "epoch": 5.490628357885042,
      "grad_norm": 3.9205029010772705,
      "learning_rate": 2.2558331568918063e-05,
      "loss": 0.7079,
      "step": 518650
    },
    {
      "epoch": 5.491157679665045,
      "grad_norm": 4.157342910766602,
      "learning_rate": 2.2555684946008894e-05,
      "loss": 0.7113,
      "step": 518700
    },
    {
      "epoch": 5.491687001445048,
      "grad_norm": 4.334641456604004,
      "learning_rate": 2.2553038323099725e-05,
      "loss": 0.7107,
      "step": 518750
    },
    {
      "epoch": 5.492216323225052,
      "grad_norm": 4.215108871459961,
      "learning_rate": 2.2550391700190555e-05,
      "loss": 0.7062,
      "step": 518800
    },
    {
      "epoch": 5.492745645005055,
      "grad_norm": 4.266139984130859,
      "learning_rate": 2.254774507728139e-05,
      "loss": 0.7042,
      "step": 518850
    },
    {
      "epoch": 5.493274966785059,
      "grad_norm": 4.306562423706055,
      "learning_rate": 2.254509845437222e-05,
      "loss": 0.7064,
      "step": 518900
    },
    {
      "epoch": 5.4938042885650615,
      "grad_norm": 4.40101957321167,
      "learning_rate": 2.2542451831463054e-05,
      "loss": 0.7089,
      "step": 518950
    },
    {
      "epoch": 5.494333610345064,
      "grad_norm": 4.084768295288086,
      "learning_rate": 2.2539805208553885e-05,
      "loss": 0.72,
      "step": 519000
    },
    {
      "epoch": 5.494333610345064,
      "eval_loss": 0.4590540826320648,
      "eval_runtime": 46.9604,
      "eval_samples_per_second": 3575.991,
      "eval_steps_per_second": 447.015,
      "step": 519000
    },
    {
      "epoch": 5.494862932125068,
      "grad_norm": 4.606021881103516,
      "learning_rate": 2.253715858564472e-05,
      "loss": 0.6995,
      "step": 519050
    },
    {
      "epoch": 5.495392253905071,
      "grad_norm": 4.354742050170898,
      "learning_rate": 2.253451196273555e-05,
      "loss": 0.7113,
      "step": 519100
    },
    {
      "epoch": 5.495921575685075,
      "grad_norm": 4.16347599029541,
      "learning_rate": 2.2531865339826384e-05,
      "loss": 0.697,
      "step": 519150
    },
    {
      "epoch": 5.496450897465078,
      "grad_norm": 4.449570178985596,
      "learning_rate": 2.2529218716917215e-05,
      "loss": 0.7132,
      "step": 519200
    },
    {
      "epoch": 5.496980219245081,
      "grad_norm": 4.133325099945068,
      "learning_rate": 2.252662502646623e-05,
      "loss": 0.707,
      "step": 519250
    },
    {
      "epoch": 5.497509541025084,
      "grad_norm": 4.391284942626953,
      "learning_rate": 2.252397840355706e-05,
      "loss": 0.7163,
      "step": 519300
    },
    {
      "epoch": 5.498038862805088,
      "grad_norm": 4.305078029632568,
      "learning_rate": 2.2521331780647894e-05,
      "loss": 0.7102,
      "step": 519350
    },
    {
      "epoch": 5.498568184585091,
      "grad_norm": 4.457894802093506,
      "learning_rate": 2.2518685157738725e-05,
      "loss": 0.7025,
      "step": 519400
    },
    {
      "epoch": 5.499097506365095,
      "grad_norm": 3.7783260345458984,
      "learning_rate": 2.251603853482956e-05,
      "loss": 0.695,
      "step": 519450
    },
    {
      "epoch": 5.4996268281450975,
      "grad_norm": 3.7588560581207275,
      "learning_rate": 2.251339191192039e-05,
      "loss": 0.7005,
      "step": 519500
    },
    {
      "epoch": 5.4996268281450975,
      "eval_loss": 0.4580911099910736,
      "eval_runtime": 46.7716,
      "eval_samples_per_second": 3590.425,
      "eval_steps_per_second": 448.819,
      "step": 519500
    },
    {
      "epoch": 5.500156149925101,
      "grad_norm": 4.312656879425049,
      "learning_rate": 2.2510745289011224e-05,
      "loss": 0.6937,
      "step": 519550
    },
    {
      "epoch": 5.500685471705104,
      "grad_norm": 4.2883734703063965,
      "learning_rate": 2.2508098666102054e-05,
      "loss": 0.7026,
      "step": 519600
    },
    {
      "epoch": 5.501214793485108,
      "grad_norm": 4.316777229309082,
      "learning_rate": 2.250545204319289e-05,
      "loss": 0.6975,
      "step": 519650
    },
    {
      "epoch": 5.501744115265111,
      "grad_norm": 4.517939567565918,
      "learning_rate": 2.250280542028372e-05,
      "loss": 0.7069,
      "step": 519700
    },
    {
      "epoch": 5.502273437045114,
      "grad_norm": 4.3707356452941895,
      "learning_rate": 2.250015879737455e-05,
      "loss": 0.7107,
      "step": 519750
    },
    {
      "epoch": 5.502802758825117,
      "grad_norm": 4.3138203620910645,
      "learning_rate": 2.249751217446538e-05,
      "loss": 0.7016,
      "step": 519800
    },
    {
      "epoch": 5.503332080605121,
      "grad_norm": 4.028339862823486,
      "learning_rate": 2.2494865551556215e-05,
      "loss": 0.6965,
      "step": 519850
    },
    {
      "epoch": 5.503861402385124,
      "grad_norm": 4.319360733032227,
      "learning_rate": 2.2492218928647046e-05,
      "loss": 0.7017,
      "step": 519900
    },
    {
      "epoch": 5.504390724165127,
      "grad_norm": 4.569633483886719,
      "learning_rate": 2.248957230573788e-05,
      "loss": 0.7035,
      "step": 519950
    },
    {
      "epoch": 5.504920045945131,
      "grad_norm": 4.491489410400391,
      "learning_rate": 2.248692568282871e-05,
      "loss": 0.7023,
      "step": 520000
    },
    {
      "epoch": 5.504920045945131,
      "eval_loss": 0.45749884843826294,
      "eval_runtime": 46.7358,
      "eval_samples_per_second": 3593.18,
      "eval_steps_per_second": 449.164,
      "step": 520000
    },
    {
      "epoch": 5.5054493677251335,
      "grad_norm": 4.316373348236084,
      "learning_rate": 2.2484279059919544e-05,
      "loss": 0.7006,
      "step": 520050
    },
    {
      "epoch": 5.505978689505137,
      "grad_norm": 4.753673076629639,
      "learning_rate": 2.2481632437010375e-05,
      "loss": 0.717,
      "step": 520100
    },
    {
      "epoch": 5.50650801128514,
      "grad_norm": 4.362178802490234,
      "learning_rate": 2.247898581410121e-05,
      "loss": 0.7025,
      "step": 520150
    },
    {
      "epoch": 5.507037333065144,
      "grad_norm": 4.062485218048096,
      "learning_rate": 2.247633919119204e-05,
      "loss": 0.7051,
      "step": 520200
    },
    {
      "epoch": 5.507566654845147,
      "grad_norm": 4.282618045806885,
      "learning_rate": 2.2473692568282874e-05,
      "loss": 0.6981,
      "step": 520250
    },
    {
      "epoch": 5.5080959766251505,
      "grad_norm": 4.326839923858643,
      "learning_rate": 2.2471045945373705e-05,
      "loss": 0.703,
      "step": 520300
    },
    {
      "epoch": 5.508625298405153,
      "grad_norm": 3.857449769973755,
      "learning_rate": 2.2468399322464535e-05,
      "loss": 0.6961,
      "step": 520350
    },
    {
      "epoch": 5.509154620185157,
      "grad_norm": 4.508505344390869,
      "learning_rate": 2.2465752699555366e-05,
      "loss": 0.7048,
      "step": 520400
    },
    {
      "epoch": 5.50968394196516,
      "grad_norm": 4.4923529624938965,
      "learning_rate": 2.24631060766462e-05,
      "loss": 0.7104,
      "step": 520450
    },
    {
      "epoch": 5.510213263745163,
      "grad_norm": 4.640463829040527,
      "learning_rate": 2.246045945373703e-05,
      "loss": 0.7026,
      "step": 520500
    },
    {
      "epoch": 5.510213263745163,
      "eval_loss": 0.45712634921073914,
      "eval_runtime": 46.7859,
      "eval_samples_per_second": 3589.328,
      "eval_steps_per_second": 448.682,
      "step": 520500
    },
    {
      "epoch": 5.510742585525167,
      "grad_norm": 4.197425365447998,
      "learning_rate": 2.2457812830827865e-05,
      "loss": 0.7066,
      "step": 520550
    },
    {
      "epoch": 5.51127190730517,
      "grad_norm": 4.57202672958374,
      "learning_rate": 2.245521914037688e-05,
      "loss": 0.7111,
      "step": 520600
    },
    {
      "epoch": 5.511801229085173,
      "grad_norm": 3.8437283039093018,
      "learning_rate": 2.2452572517467714e-05,
      "loss": 0.6978,
      "step": 520650
    },
    {
      "epoch": 5.512330550865176,
      "grad_norm": 4.062616348266602,
      "learning_rate": 2.2449925894558545e-05,
      "loss": 0.723,
      "step": 520700
    },
    {
      "epoch": 5.51285987264518,
      "grad_norm": 4.60121488571167,
      "learning_rate": 2.2447279271649375e-05,
      "loss": 0.7086,
      "step": 520750
    },
    {
      "epoch": 5.513389194425183,
      "grad_norm": 4.379872798919678,
      "learning_rate": 2.2444632648740206e-05,
      "loss": 0.7012,
      "step": 520800
    },
    {
      "epoch": 5.5139185162051865,
      "grad_norm": 4.076221942901611,
      "learning_rate": 2.244198602583104e-05,
      "loss": 0.7178,
      "step": 520850
    },
    {
      "epoch": 5.514447837985189,
      "grad_norm": 4.592629432678223,
      "learning_rate": 2.243933940292187e-05,
      "loss": 0.6955,
      "step": 520900
    },
    {
      "epoch": 5.514977159765193,
      "grad_norm": 4.176861763000488,
      "learning_rate": 2.2436692780012705e-05,
      "loss": 0.6973,
      "step": 520950
    },
    {
      "epoch": 5.515506481545196,
      "grad_norm": 4.468173980712891,
      "learning_rate": 2.2434046157103536e-05,
      "loss": 0.7131,
      "step": 521000
    },
    {
      "epoch": 5.515506481545196,
      "eval_loss": 0.45921263098716736,
      "eval_runtime": 47.0487,
      "eval_samples_per_second": 3569.279,
      "eval_steps_per_second": 446.176,
      "step": 521000
    },
    {
      "epoch": 5.5160358033252,
      "grad_norm": 4.0015869140625,
      "learning_rate": 2.243139953419437e-05,
      "loss": 0.7067,
      "step": 521050
    },
    {
      "epoch": 5.516565125105203,
      "grad_norm": 4.331173896789551,
      "learning_rate": 2.24287529112852e-05,
      "loss": 0.709,
      "step": 521100
    },
    {
      "epoch": 5.517094446885206,
      "grad_norm": 4.36283016204834,
      "learning_rate": 2.2426106288376035e-05,
      "loss": 0.7048,
      "step": 521150
    },
    {
      "epoch": 5.517623768665209,
      "grad_norm": 4.3927178382873535,
      "learning_rate": 2.2423459665466865e-05,
      "loss": 0.6983,
      "step": 521200
    },
    {
      "epoch": 5.518153090445212,
      "grad_norm": 4.469115734100342,
      "learning_rate": 2.24208130425577e-05,
      "loss": 0.7053,
      "step": 521250
    },
    {
      "epoch": 5.518682412225216,
      "grad_norm": 4.165366172790527,
      "learning_rate": 2.241816641964853e-05,
      "loss": 0.7073,
      "step": 521300
    },
    {
      "epoch": 5.51921173400522,
      "grad_norm": 4.828094959259033,
      "learning_rate": 2.241551979673936e-05,
      "loss": 0.7186,
      "step": 521350
    },
    {
      "epoch": 5.5197410557852224,
      "grad_norm": 4.63844633102417,
      "learning_rate": 2.241287317383019e-05,
      "loss": 0.7011,
      "step": 521400
    },
    {
      "epoch": 5.520270377565225,
      "grad_norm": 3.868027925491333,
      "learning_rate": 2.2410226550921026e-05,
      "loss": 0.7068,
      "step": 521450
    },
    {
      "epoch": 5.520799699345229,
      "grad_norm": 4.202408790588379,
      "learning_rate": 2.2407579928011856e-05,
      "loss": 0.7161,
      "step": 521500
    },
    {
      "epoch": 5.520799699345229,
      "eval_loss": 0.45761170983314514,
      "eval_runtime": 46.9321,
      "eval_samples_per_second": 3578.152,
      "eval_steps_per_second": 447.285,
      "step": 521500
    },
    {
      "epoch": 5.521329021125232,
      "grad_norm": 4.386759281158447,
      "learning_rate": 2.240493330510269e-05,
      "loss": 0.7075,
      "step": 521550
    },
    {
      "epoch": 5.521858342905236,
      "grad_norm": 4.1502203941345215,
      "learning_rate": 2.240228668219352e-05,
      "loss": 0.6899,
      "step": 521600
    },
    {
      "epoch": 5.522387664685239,
      "grad_norm": 4.041194915771484,
      "learning_rate": 2.2399640059284355e-05,
      "loss": 0.6992,
      "step": 521650
    },
    {
      "epoch": 5.522916986465242,
      "grad_norm": 3.8891522884368896,
      "learning_rate": 2.2396993436375186e-05,
      "loss": 0.7004,
      "step": 521700
    },
    {
      "epoch": 5.523446308245245,
      "grad_norm": 4.282417297363281,
      "learning_rate": 2.239434681346602e-05,
      "loss": 0.7052,
      "step": 521750
    },
    {
      "epoch": 5.523975630025249,
      "grad_norm": 4.58442497253418,
      "learning_rate": 2.239170019055685e-05,
      "loss": 0.7059,
      "step": 521800
    },
    {
      "epoch": 5.524504951805252,
      "grad_norm": 4.494822025299072,
      "learning_rate": 2.238905356764768e-05,
      "loss": 0.7089,
      "step": 521850
    },
    {
      "epoch": 5.525034273585256,
      "grad_norm": 4.609893798828125,
      "learning_rate": 2.2386406944738512e-05,
      "loss": 0.7009,
      "step": 521900
    },
    {
      "epoch": 5.525563595365258,
      "grad_norm": 4.56320858001709,
      "learning_rate": 2.2383760321829346e-05,
      "loss": 0.7157,
      "step": 521950
    },
    {
      "epoch": 5.526092917145261,
      "grad_norm": 4.611181259155273,
      "learning_rate": 2.2381113698920177e-05,
      "loss": 0.6986,
      "step": 522000
    },
    {
      "epoch": 5.526092917145261,
      "eval_loss": 0.4568580090999603,
      "eval_runtime": 47.2517,
      "eval_samples_per_second": 3553.943,
      "eval_steps_per_second": 444.259,
      "step": 522000
    },
    {
      "epoch": 5.526622238925265,
      "grad_norm": 4.431440830230713,
      "learning_rate": 2.237846707601101e-05,
      "loss": 0.7066,
      "step": 522050
    },
    {
      "epoch": 5.527151560705269,
      "grad_norm": 4.670992374420166,
      "learning_rate": 2.2375820453101842e-05,
      "loss": 0.7005,
      "step": 522100
    },
    {
      "epoch": 5.527680882485272,
      "grad_norm": 4.561468601226807,
      "learning_rate": 2.2373173830192676e-05,
      "loss": 0.6833,
      "step": 522150
    },
    {
      "epoch": 5.5282102042652745,
      "grad_norm": 3.972860336303711,
      "learning_rate": 2.2370527207283507e-05,
      "loss": 0.7117,
      "step": 522200
    },
    {
      "epoch": 5.528739526045278,
      "grad_norm": 4.32198429107666,
      "learning_rate": 2.236788058437434e-05,
      "loss": 0.708,
      "step": 522250
    },
    {
      "epoch": 5.529268847825281,
      "grad_norm": 4.309317111968994,
      "learning_rate": 2.236523396146517e-05,
      "loss": 0.7241,
      "step": 522300
    },
    {
      "epoch": 5.529798169605285,
      "grad_norm": 4.268727779388428,
      "learning_rate": 2.2362587338556006e-05,
      "loss": 0.7015,
      "step": 522350
    },
    {
      "epoch": 5.530327491385288,
      "grad_norm": 4.542735576629639,
      "learning_rate": 2.2359940715646836e-05,
      "loss": 0.7069,
      "step": 522400
    },
    {
      "epoch": 5.5308568131652915,
      "grad_norm": 4.318892478942871,
      "learning_rate": 2.2357294092737667e-05,
      "loss": 0.7029,
      "step": 522450
    },
    {
      "epoch": 5.531386134945294,
      "grad_norm": 4.586081027984619,
      "learning_rate": 2.2354647469828498e-05,
      "loss": 0.6922,
      "step": 522500
    },
    {
      "epoch": 5.531386134945294,
      "eval_loss": 0.4572640359401703,
      "eval_runtime": 47.0635,
      "eval_samples_per_second": 3568.156,
      "eval_steps_per_second": 446.035,
      "step": 522500
    },
    {
      "epoch": 5.531915456725298,
      "grad_norm": 3.777973175048828,
      "learning_rate": 2.2352000846919332e-05,
      "loss": 0.6926,
      "step": 522550
    },
    {
      "epoch": 5.532444778505301,
      "grad_norm": 4.17554235458374,
      "learning_rate": 2.2349354224010163e-05,
      "loss": 0.6988,
      "step": 522600
    },
    {
      "epoch": 5.532974100285305,
      "grad_norm": 4.3527631759643555,
      "learning_rate": 2.2346707601100997e-05,
      "loss": 0.7061,
      "step": 522650
    },
    {
      "epoch": 5.533503422065308,
      "grad_norm": 4.360491752624512,
      "learning_rate": 2.2344060978191827e-05,
      "loss": 0.7078,
      "step": 522700
    },
    {
      "epoch": 5.5340327438453105,
      "grad_norm": 4.539263725280762,
      "learning_rate": 2.234141435528266e-05,
      "loss": 0.7053,
      "step": 522750
    },
    {
      "epoch": 5.534562065625314,
      "grad_norm": 4.7721848487854,
      "learning_rate": 2.2338767732373492e-05,
      "loss": 0.695,
      "step": 522800
    },
    {
      "epoch": 5.535091387405318,
      "grad_norm": 3.715829372406006,
      "learning_rate": 2.2336121109464326e-05,
      "loss": 0.695,
      "step": 522850
    },
    {
      "epoch": 5.535620709185321,
      "grad_norm": 4.4462409019470215,
      "learning_rate": 2.2333474486555157e-05,
      "loss": 0.6988,
      "step": 522900
    },
    {
      "epoch": 5.536150030965324,
      "grad_norm": 4.423608779907227,
      "learning_rate": 2.233082786364599e-05,
      "loss": 0.7065,
      "step": 522950
    },
    {
      "epoch": 5.5366793527453275,
      "grad_norm": 4.836156368255615,
      "learning_rate": 2.2328181240736822e-05,
      "loss": 0.7083,
      "step": 523000
    },
    {
      "epoch": 5.5366793527453275,
      "eval_loss": 0.45768943428993225,
      "eval_runtime": 46.8332,
      "eval_samples_per_second": 3585.705,
      "eval_steps_per_second": 448.229,
      "step": 523000
    },
    {
      "epoch": 5.53720867452533,
      "grad_norm": 4.544186592102051,
      "learning_rate": 2.2325534617827652e-05,
      "loss": 0.7105,
      "step": 523050
    },
    {
      "epoch": 5.537737996305334,
      "grad_norm": 4.091378688812256,
      "learning_rate": 2.2322887994918483e-05,
      "loss": 0.7042,
      "step": 523100
    },
    {
      "epoch": 5.538267318085337,
      "grad_norm": 4.743727207183838,
      "learning_rate": 2.2320241372009317e-05,
      "loss": 0.7022,
      "step": 523150
    },
    {
      "epoch": 5.538796639865341,
      "grad_norm": 4.174924850463867,
      "learning_rate": 2.2317594749100148e-05,
      "loss": 0.6986,
      "step": 523200
    },
    {
      "epoch": 5.539325961645344,
      "grad_norm": 4.528620719909668,
      "learning_rate": 2.2314948126190982e-05,
      "loss": 0.6996,
      "step": 523250
    },
    {
      "epoch": 5.539855283425347,
      "grad_norm": 4.294093132019043,
      "learning_rate": 2.2312301503281813e-05,
      "loss": 0.7057,
      "step": 523300
    },
    {
      "epoch": 5.54038460520535,
      "grad_norm": 4.183736801147461,
      "learning_rate": 2.2309654880372647e-05,
      "loss": 0.7218,
      "step": 523350
    },
    {
      "epoch": 5.540913926985354,
      "grad_norm": 4.329290866851807,
      "learning_rate": 2.2307008257463478e-05,
      "loss": 0.7069,
      "step": 523400
    },
    {
      "epoch": 5.541443248765357,
      "grad_norm": 4.2057271003723145,
      "learning_rate": 2.2304361634554312e-05,
      "loss": 0.7099,
      "step": 523450
    },
    {
      "epoch": 5.54197257054536,
      "grad_norm": 4.078272819519043,
      "learning_rate": 2.2301715011645142e-05,
      "loss": 0.7009,
      "step": 523500
    },
    {
      "epoch": 5.54197257054536,
      "eval_loss": 0.4551790952682495,
      "eval_runtime": 46.8466,
      "eval_samples_per_second": 3584.677,
      "eval_steps_per_second": 448.101,
      "step": 523500
    },
    {
      "epoch": 5.5425018923253635,
      "grad_norm": 4.262477874755859,
      "learning_rate": 2.2299068388735973e-05,
      "loss": 0.7145,
      "step": 523550
    },
    {
      "epoch": 5.543031214105367,
      "grad_norm": 4.215411186218262,
      "learning_rate": 2.2296421765826804e-05,
      "loss": 0.692,
      "step": 523600
    },
    {
      "epoch": 5.54356053588537,
      "grad_norm": 4.312711238861084,
      "learning_rate": 2.2293775142917638e-05,
      "loss": 0.7133,
      "step": 523650
    },
    {
      "epoch": 5.544089857665373,
      "grad_norm": 4.4887566566467285,
      "learning_rate": 2.229112852000847e-05,
      "loss": 0.7078,
      "step": 523700
    },
    {
      "epoch": 5.544619179445377,
      "grad_norm": 4.118330001831055,
      "learning_rate": 2.2288481897099303e-05,
      "loss": 0.7055,
      "step": 523750
    },
    {
      "epoch": 5.54514850122538,
      "grad_norm": 4.280663967132568,
      "learning_rate": 2.2285835274190133e-05,
      "loss": 0.7041,
      "step": 523800
    },
    {
      "epoch": 5.545677823005383,
      "grad_norm": 4.522922515869141,
      "learning_rate": 2.2283188651280968e-05,
      "loss": 0.7067,
      "step": 523850
    },
    {
      "epoch": 5.546207144785386,
      "grad_norm": 4.391250133514404,
      "learning_rate": 2.2280542028371798e-05,
      "loss": 0.6974,
      "step": 523900
    },
    {
      "epoch": 5.54673646656539,
      "grad_norm": 4.052062034606934,
      "learning_rate": 2.2277895405462632e-05,
      "loss": 0.6889,
      "step": 523950
    },
    {
      "epoch": 5.547265788345393,
      "grad_norm": 4.5906147956848145,
      "learning_rate": 2.2275248782553463e-05,
      "loss": 0.7067,
      "step": 524000
    },
    {
      "epoch": 5.547265788345393,
      "eval_loss": 0.45634105801582336,
      "eval_runtime": 46.9553,
      "eval_samples_per_second": 3576.384,
      "eval_steps_per_second": 447.064,
      "step": 524000
    },
    {
      "epoch": 5.547795110125397,
      "grad_norm": 4.2862443923950195,
      "learning_rate": 2.2272602159644297e-05,
      "loss": 0.7091,
      "step": 524050
    },
    {
      "epoch": 5.5483244319053995,
      "grad_norm": 4.395543098449707,
      "learning_rate": 2.2269955536735128e-05,
      "loss": 0.7051,
      "step": 524100
    },
    {
      "epoch": 5.548853753685403,
      "grad_norm": 4.2371087074279785,
      "learning_rate": 2.226730891382596e-05,
      "loss": 0.7057,
      "step": 524150
    },
    {
      "epoch": 5.549383075465406,
      "grad_norm": 4.476887226104736,
      "learning_rate": 2.226466229091679e-05,
      "loss": 0.7142,
      "step": 524200
    },
    {
      "epoch": 5.549912397245409,
      "grad_norm": 4.389756679534912,
      "learning_rate": 2.2262015668007623e-05,
      "loss": 0.7156,
      "step": 524250
    },
    {
      "epoch": 5.550441719025413,
      "grad_norm": 4.335468769073486,
      "learning_rate": 2.2259369045098454e-05,
      "loss": 0.7118,
      "step": 524300
    },
    {
      "epoch": 5.5509710408054165,
      "grad_norm": 3.6959948539733887,
      "learning_rate": 2.2256722422189288e-05,
      "loss": 0.7001,
      "step": 524350
    },
    {
      "epoch": 5.551500362585419,
      "grad_norm": 4.438312530517578,
      "learning_rate": 2.225407579928012e-05,
      "loss": 0.6989,
      "step": 524400
    },
    {
      "epoch": 5.552029684365422,
      "grad_norm": 4.207722187042236,
      "learning_rate": 2.2251429176370953e-05,
      "loss": 0.6969,
      "step": 524450
    },
    {
      "epoch": 5.552559006145426,
      "grad_norm": 4.313141345977783,
      "learning_rate": 2.2248782553461784e-05,
      "loss": 0.6905,
      "step": 524500
    },
    {
      "epoch": 5.552559006145426,
      "eval_loss": 0.4571717381477356,
      "eval_runtime": 46.9828,
      "eval_samples_per_second": 3574.286,
      "eval_steps_per_second": 446.802,
      "step": 524500
    },
    {
      "epoch": 5.553088327925429,
      "grad_norm": 4.35695743560791,
      "learning_rate": 2.2246135930552618e-05,
      "loss": 0.7031,
      "step": 524550
    },
    {
      "epoch": 5.553617649705433,
      "grad_norm": 4.4886369705200195,
      "learning_rate": 2.224354224010163e-05,
      "loss": 0.7064,
      "step": 524600
    },
    {
      "epoch": 5.5541469714854355,
      "grad_norm": 4.401256561279297,
      "learning_rate": 2.2240895617192463e-05,
      "loss": 0.6868,
      "step": 524650
    },
    {
      "epoch": 5.554676293265439,
      "grad_norm": 4.121261119842529,
      "learning_rate": 2.2238248994283294e-05,
      "loss": 0.7138,
      "step": 524700
    },
    {
      "epoch": 5.555205615045442,
      "grad_norm": 4.239821910858154,
      "learning_rate": 2.2235602371374128e-05,
      "loss": 0.7164,
      "step": 524750
    },
    {
      "epoch": 5.555734936825446,
      "grad_norm": 4.61380672454834,
      "learning_rate": 2.2233008680923143e-05,
      "loss": 0.7009,
      "step": 524800
    },
    {
      "epoch": 5.556264258605449,
      "grad_norm": 4.166378021240234,
      "learning_rate": 2.2230362058013977e-05,
      "loss": 0.6894,
      "step": 524850
    },
    {
      "epoch": 5.5567935803854525,
      "grad_norm": 4.482860565185547,
      "learning_rate": 2.2227715435104808e-05,
      "loss": 0.7023,
      "step": 524900
    },
    {
      "epoch": 5.557322902165455,
      "grad_norm": 4.273764133453369,
      "learning_rate": 2.2225068812195642e-05,
      "loss": 0.6988,
      "step": 524950
    },
    {
      "epoch": 5.557852223945458,
      "grad_norm": 4.300267696380615,
      "learning_rate": 2.2222422189286472e-05,
      "loss": 0.7214,
      "step": 525000
    },
    {
      "epoch": 5.557852223945458,
      "eval_loss": 0.45653676986694336,
      "eval_runtime": 46.8849,
      "eval_samples_per_second": 3581.75,
      "eval_steps_per_second": 447.735,
      "step": 525000
    },
    {
      "epoch": 5.558381545725462,
      "grad_norm": 4.411212921142578,
      "learning_rate": 2.2219775566377303e-05,
      "loss": 0.7023,
      "step": 525050
    },
    {
      "epoch": 5.558910867505466,
      "grad_norm": 4.263271808624268,
      "learning_rate": 2.2217128943468134e-05,
      "loss": 0.7013,
      "step": 525100
    },
    {
      "epoch": 5.559440189285469,
      "grad_norm": 4.254815101623535,
      "learning_rate": 2.2214482320558968e-05,
      "loss": 0.6858,
      "step": 525150
    },
    {
      "epoch": 5.559969511065471,
      "grad_norm": 4.065199851989746,
      "learning_rate": 2.22118356976498e-05,
      "loss": 0.6874,
      "step": 525200
    },
    {
      "epoch": 5.560498832845475,
      "grad_norm": 4.111536026000977,
      "learning_rate": 2.2209189074740633e-05,
      "loss": 0.7021,
      "step": 525250
    },
    {
      "epoch": 5.561028154625478,
      "grad_norm": 4.446317195892334,
      "learning_rate": 2.2206542451831463e-05,
      "loss": 0.7057,
      "step": 525300
    },
    {
      "epoch": 5.561557476405482,
      "grad_norm": 4.299837112426758,
      "learning_rate": 2.2203895828922298e-05,
      "loss": 0.6985,
      "step": 525350
    },
    {
      "epoch": 5.562086798185485,
      "grad_norm": 4.354240417480469,
      "learning_rate": 2.2201249206013128e-05,
      "loss": 0.6933,
      "step": 525400
    },
    {
      "epoch": 5.562616119965488,
      "grad_norm": 4.157129287719727,
      "learning_rate": 2.2198602583103962e-05,
      "loss": 0.7019,
      "step": 525450
    },
    {
      "epoch": 5.563145441745491,
      "grad_norm": 4.284816741943359,
      "learning_rate": 2.2195955960194793e-05,
      "loss": 0.7028,
      "step": 525500
    },
    {
      "epoch": 5.563145441745491,
      "eval_loss": 0.4562070071697235,
      "eval_runtime": 46.9954,
      "eval_samples_per_second": 3573.329,
      "eval_steps_per_second": 446.682,
      "step": 525500
    },
    {
      "epoch": 5.563674763525495,
      "grad_norm": 4.6068854331970215,
      "learning_rate": 2.2193309337285624e-05,
      "loss": 0.7041,
      "step": 525550
    },
    {
      "epoch": 5.564204085305498,
      "grad_norm": 4.256946086883545,
      "learning_rate": 2.2190662714376455e-05,
      "loss": 0.6949,
      "step": 525600
    },
    {
      "epoch": 5.564733407085502,
      "grad_norm": 4.120626926422119,
      "learning_rate": 2.218801609146729e-05,
      "loss": 0.7078,
      "step": 525650
    },
    {
      "epoch": 5.5652627288655045,
      "grad_norm": 4.587723255157471,
      "learning_rate": 2.218536946855812e-05,
      "loss": 0.6987,
      "step": 525700
    },
    {
      "epoch": 5.565792050645507,
      "grad_norm": 4.559925079345703,
      "learning_rate": 2.2182722845648953e-05,
      "loss": 0.71,
      "step": 525750
    },
    {
      "epoch": 5.566321372425511,
      "grad_norm": 4.401313781738281,
      "learning_rate": 2.2180076222739784e-05,
      "loss": 0.7043,
      "step": 525800
    },
    {
      "epoch": 5.566850694205515,
      "grad_norm": 4.155372619628906,
      "learning_rate": 2.2177429599830618e-05,
      "loss": 0.7042,
      "step": 525850
    },
    {
      "epoch": 5.567380015985518,
      "grad_norm": 4.03269624710083,
      "learning_rate": 2.217478297692145e-05,
      "loss": 0.695,
      "step": 525900
    },
    {
      "epoch": 5.567909337765521,
      "grad_norm": 4.088648319244385,
      "learning_rate": 2.2172136354012283e-05,
      "loss": 0.6879,
      "step": 525950
    },
    {
      "epoch": 5.568438659545524,
      "grad_norm": 4.278474807739258,
      "learning_rate": 2.2169489731103114e-05,
      "loss": 0.7014,
      "step": 526000
    },
    {
      "epoch": 5.568438659545524,
      "eval_loss": 0.4547972083091736,
      "eval_runtime": 46.9745,
      "eval_samples_per_second": 3574.918,
      "eval_steps_per_second": 446.881,
      "step": 526000
    },
    {
      "epoch": 5.568967981325527,
      "grad_norm": 4.491090774536133,
      "learning_rate": 2.2166843108193948e-05,
      "loss": 0.6944,
      "step": 526050
    },
    {
      "epoch": 5.569497303105531,
      "grad_norm": 4.573993682861328,
      "learning_rate": 2.216419648528478e-05,
      "loss": 0.7036,
      "step": 526100
    },
    {
      "epoch": 5.570026624885534,
      "grad_norm": 4.775211334228516,
      "learning_rate": 2.216154986237561e-05,
      "loss": 0.7132,
      "step": 526150
    },
    {
      "epoch": 5.570555946665538,
      "grad_norm": 4.349388122558594,
      "learning_rate": 2.215890323946644e-05,
      "loss": 0.7031,
      "step": 526200
    },
    {
      "epoch": 5.5710852684455405,
      "grad_norm": 4.44870662689209,
      "learning_rate": 2.2156256616557274e-05,
      "loss": 0.7042,
      "step": 526250
    },
    {
      "epoch": 5.571614590225544,
      "grad_norm": 4.739016056060791,
      "learning_rate": 2.2153609993648105e-05,
      "loss": 0.7184,
      "step": 526300
    },
    {
      "epoch": 5.572143912005547,
      "grad_norm": 4.072770118713379,
      "learning_rate": 2.215096337073894e-05,
      "loss": 0.6969,
      "step": 526350
    },
    {
      "epoch": 5.572673233785551,
      "grad_norm": 4.24489688873291,
      "learning_rate": 2.214831674782977e-05,
      "loss": 0.7011,
      "step": 526400
    },
    {
      "epoch": 5.573202555565554,
      "grad_norm": 4.69968843460083,
      "learning_rate": 2.2145670124920604e-05,
      "loss": 0.7002,
      "step": 526450
    },
    {
      "epoch": 5.573731877345557,
      "grad_norm": 4.522922039031982,
      "learning_rate": 2.2143023502011434e-05,
      "loss": 0.6937,
      "step": 526500
    },
    {
      "epoch": 5.573731877345557,
      "eval_loss": 0.45612069964408875,
      "eval_runtime": 47.1559,
      "eval_samples_per_second": 3561.168,
      "eval_steps_per_second": 445.162,
      "step": 526500
    },
    {
      "epoch": 5.57426119912556,
      "grad_norm": 4.192212104797363,
      "learning_rate": 2.214037687910227e-05,
      "loss": 0.709,
      "step": 526550
    },
    {
      "epoch": 5.574790520905564,
      "grad_norm": 4.302167892456055,
      "learning_rate": 2.21377302561931e-05,
      "loss": 0.6959,
      "step": 526600
    },
    {
      "epoch": 5.575319842685567,
      "grad_norm": 4.185502529144287,
      "learning_rate": 2.2135083633283933e-05,
      "loss": 0.7062,
      "step": 526650
    },
    {
      "epoch": 5.57584916446557,
      "grad_norm": 4.188216209411621,
      "learning_rate": 2.2132437010374764e-05,
      "loss": 0.6985,
      "step": 526700
    },
    {
      "epoch": 5.576378486245574,
      "grad_norm": 4.3744425773620605,
      "learning_rate": 2.2129790387465595e-05,
      "loss": 0.6986,
      "step": 526750
    },
    {
      "epoch": 5.5769078080255765,
      "grad_norm": 4.520305633544922,
      "learning_rate": 2.2127143764556425e-05,
      "loss": 0.7005,
      "step": 526800
    },
    {
      "epoch": 5.57743712980558,
      "grad_norm": 4.517192363739014,
      "learning_rate": 2.212449714164726e-05,
      "loss": 0.7028,
      "step": 526850
    },
    {
      "epoch": 5.577966451585583,
      "grad_norm": 3.9449827671051025,
      "learning_rate": 2.212185051873809e-05,
      "loss": 0.6947,
      "step": 526900
    },
    {
      "epoch": 5.578495773365587,
      "grad_norm": 4.361477375030518,
      "learning_rate": 2.2119203895828924e-05,
      "loss": 0.7033,
      "step": 526950
    },
    {
      "epoch": 5.57902509514559,
      "grad_norm": 4.340901851654053,
      "learning_rate": 2.2116557272919755e-05,
      "loss": 0.7086,
      "step": 527000
    },
    {
      "epoch": 5.57902509514559,
      "eval_loss": 0.4545212388038635,
      "eval_runtime": 46.8628,
      "eval_samples_per_second": 3583.443,
      "eval_steps_per_second": 447.946,
      "step": 527000
    },
    {
      "epoch": 5.5795544169255935,
      "grad_norm": 4.6782941818237305,
      "learning_rate": 2.211391065001059e-05,
      "loss": 0.7161,
      "step": 527050
    },
    {
      "epoch": 5.580083738705596,
      "grad_norm": 4.035737037658691,
      "learning_rate": 2.211126402710142e-05,
      "loss": 0.706,
      "step": 527100
    },
    {
      "epoch": 5.5806130604856,
      "grad_norm": 4.359690189361572,
      "learning_rate": 2.2108617404192254e-05,
      "loss": 0.6974,
      "step": 527150
    },
    {
      "epoch": 5.581142382265603,
      "grad_norm": 4.035968780517578,
      "learning_rate": 2.2105970781283085e-05,
      "loss": 0.6991,
      "step": 527200
    },
    {
      "epoch": 5.581671704045607,
      "grad_norm": 3.962146520614624,
      "learning_rate": 2.2103324158373915e-05,
      "loss": 0.7036,
      "step": 527250
    },
    {
      "epoch": 5.58220102582561,
      "grad_norm": 4.000707626342773,
      "learning_rate": 2.2100677535464746e-05,
      "loss": 0.7108,
      "step": 527300
    },
    {
      "epoch": 5.582730347605613,
      "grad_norm": 4.110509395599365,
      "learning_rate": 2.209803091255558e-05,
      "loss": 0.6953,
      "step": 527350
    },
    {
      "epoch": 5.583259669385616,
      "grad_norm": 4.338698863983154,
      "learning_rate": 2.209538428964641e-05,
      "loss": 0.7038,
      "step": 527400
    },
    {
      "epoch": 5.583788991165619,
      "grad_norm": 3.9714345932006836,
      "learning_rate": 2.2092737666737245e-05,
      "loss": 0.7134,
      "step": 527450
    },
    {
      "epoch": 5.584318312945623,
      "grad_norm": 4.537919998168945,
      "learning_rate": 2.2090091043828076e-05,
      "loss": 0.7173,
      "step": 527500
    },
    {
      "epoch": 5.584318312945623,
      "eval_loss": 0.4567284882068634,
      "eval_runtime": 47.0387,
      "eval_samples_per_second": 3570.04,
      "eval_steps_per_second": 446.271,
      "step": 527500
    },
    {
      "epoch": 5.584847634725626,
      "grad_norm": 4.576442241668701,
      "learning_rate": 2.208744442091891e-05,
      "loss": 0.7071,
      "step": 527550
    },
    {
      "epoch": 5.5853769565056295,
      "grad_norm": 4.001825332641602,
      "learning_rate": 2.208479779800974e-05,
      "loss": 0.698,
      "step": 527600
    },
    {
      "epoch": 5.585906278285632,
      "grad_norm": 4.355848789215088,
      "learning_rate": 2.2082151175100575e-05,
      "loss": 0.699,
      "step": 527650
    },
    {
      "epoch": 5.586435600065636,
      "grad_norm": 4.642223834991455,
      "learning_rate": 2.2079504552191405e-05,
      "loss": 0.7076,
      "step": 527700
    },
    {
      "epoch": 5.586964921845639,
      "grad_norm": 4.006943702697754,
      "learning_rate": 2.207685792928224e-05,
      "loss": 0.7019,
      "step": 527750
    },
    {
      "epoch": 5.587494243625643,
      "grad_norm": 4.501837730407715,
      "learning_rate": 2.207426423883125e-05,
      "loss": 0.6926,
      "step": 527800
    },
    {
      "epoch": 5.588023565405646,
      "grad_norm": 4.13215970993042,
      "learning_rate": 2.2071617615922085e-05,
      "loss": 0.6969,
      "step": 527850
    },
    {
      "epoch": 5.588552887185649,
      "grad_norm": 4.478823184967041,
      "learning_rate": 2.2068970993012916e-05,
      "loss": 0.696,
      "step": 527900
    },
    {
      "epoch": 5.589082208965652,
      "grad_norm": 4.823347568511963,
      "learning_rate": 2.206632437010375e-05,
      "loss": 0.7062,
      "step": 527950
    },
    {
      "epoch": 5.589611530745656,
      "grad_norm": 4.682850360870361,
      "learning_rate": 2.206367774719458e-05,
      "loss": 0.7053,
      "step": 528000
    },
    {
      "epoch": 5.589611530745656,
      "eval_loss": 0.4550054371356964,
      "eval_runtime": 46.8362,
      "eval_samples_per_second": 3585.473,
      "eval_steps_per_second": 448.2,
      "step": 528000
    },
    {
      "epoch": 5.590140852525659,
      "grad_norm": 4.396855354309082,
      "learning_rate": 2.2061031124285415e-05,
      "loss": 0.6965,
      "step": 528050
    },
    {
      "epoch": 5.590670174305663,
      "grad_norm": 4.229605674743652,
      "learning_rate": 2.2058384501376245e-05,
      "loss": 0.7089,
      "step": 528100
    },
    {
      "epoch": 5.5911994960856655,
      "grad_norm": 4.08368444442749,
      "learning_rate": 2.205573787846708e-05,
      "loss": 0.7069,
      "step": 528150
    },
    {
      "epoch": 5.591728817865668,
      "grad_norm": 4.661921977996826,
      "learning_rate": 2.205309125555791e-05,
      "loss": 0.7129,
      "step": 528200
    },
    {
      "epoch": 5.592258139645672,
      "grad_norm": 3.9229698181152344,
      "learning_rate": 2.205044463264874e-05,
      "loss": 0.702,
      "step": 528250
    },
    {
      "epoch": 5.592787461425675,
      "grad_norm": 4.093278408050537,
      "learning_rate": 2.204779800973957e-05,
      "loss": 0.7071,
      "step": 528300
    },
    {
      "epoch": 5.593316783205679,
      "grad_norm": 4.535246849060059,
      "learning_rate": 2.2045151386830406e-05,
      "loss": 0.6992,
      "step": 528350
    },
    {
      "epoch": 5.593846104985682,
      "grad_norm": 4.547852993011475,
      "learning_rate": 2.2042504763921236e-05,
      "loss": 0.6878,
      "step": 528400
    },
    {
      "epoch": 5.594375426765685,
      "grad_norm": 4.346734523773193,
      "learning_rate": 2.203985814101207e-05,
      "loss": 0.6921,
      "step": 528450
    },
    {
      "epoch": 5.594904748545688,
      "grad_norm": 4.202535152435303,
      "learning_rate": 2.20372115181029e-05,
      "loss": 0.7025,
      "step": 528500
    },
    {
      "epoch": 5.594904748545688,
      "eval_loss": 0.4544287323951721,
      "eval_runtime": 46.7845,
      "eval_samples_per_second": 3589.437,
      "eval_steps_per_second": 448.696,
      "step": 528500
    },
    {
      "epoch": 5.595434070325692,
      "grad_norm": 4.649550437927246,
      "learning_rate": 2.2034564895193735e-05,
      "loss": 0.7012,
      "step": 528550
    },
    {
      "epoch": 5.595963392105695,
      "grad_norm": 4.708829402923584,
      "learning_rate": 2.2031918272284566e-05,
      "loss": 0.6955,
      "step": 528600
    },
    {
      "epoch": 5.596492713885699,
      "grad_norm": 4.182468891143799,
      "learning_rate": 2.20292716493754e-05,
      "loss": 0.6906,
      "step": 528650
    },
    {
      "epoch": 5.5970220356657014,
      "grad_norm": 4.860487461090088,
      "learning_rate": 2.202662502646623e-05,
      "loss": 0.6981,
      "step": 528700
    },
    {
      "epoch": 5.597551357445705,
      "grad_norm": 4.024606704711914,
      "learning_rate": 2.2023978403557065e-05,
      "loss": 0.6966,
      "step": 528750
    },
    {
      "epoch": 5.598080679225708,
      "grad_norm": 4.629333972930908,
      "learning_rate": 2.2021331780647896e-05,
      "loss": 0.6983,
      "step": 528800
    },
    {
      "epoch": 5.598610001005712,
      "grad_norm": 4.684307098388672,
      "learning_rate": 2.2018685157738726e-05,
      "loss": 0.7093,
      "step": 528850
    },
    {
      "epoch": 5.599139322785715,
      "grad_norm": 4.272481441497803,
      "learning_rate": 2.2016038534829557e-05,
      "loss": 0.7047,
      "step": 528900
    },
    {
      "epoch": 5.599668644565718,
      "grad_norm": 4.2941508293151855,
      "learning_rate": 2.201339191192039e-05,
      "loss": 0.7078,
      "step": 528950
    },
    {
      "epoch": 5.600197966345721,
      "grad_norm": 4.065212726593018,
      "learning_rate": 2.2010745289011222e-05,
      "loss": 0.6942,
      "step": 529000
    },
    {
      "epoch": 5.600197966345721,
      "eval_loss": 0.4551924467086792,
      "eval_runtime": 46.8269,
      "eval_samples_per_second": 3586.187,
      "eval_steps_per_second": 448.289,
      "step": 529000
    },
    {
      "epoch": 5.600727288125724,
      "grad_norm": 4.353424549102783,
      "learning_rate": 2.2008098666102056e-05,
      "loss": 0.7011,
      "step": 529050
    },
    {
      "epoch": 5.601256609905728,
      "grad_norm": 4.585850238800049,
      "learning_rate": 2.2005452043192887e-05,
      "loss": 0.7127,
      "step": 529100
    },
    {
      "epoch": 5.601785931685731,
      "grad_norm": 3.9268600940704346,
      "learning_rate": 2.200280542028372e-05,
      "loss": 0.7021,
      "step": 529150
    },
    {
      "epoch": 5.602315253465735,
      "grad_norm": 4.218993186950684,
      "learning_rate": 2.200015879737455e-05,
      "loss": 0.7042,
      "step": 529200
    },
    {
      "epoch": 5.602844575245737,
      "grad_norm": 4.5800981521606445,
      "learning_rate": 2.1997512174465386e-05,
      "loss": 0.7133,
      "step": 529250
    },
    {
      "epoch": 5.603373897025741,
      "grad_norm": 4.898931980133057,
      "learning_rate": 2.1994865551556216e-05,
      "loss": 0.7035,
      "step": 529300
    },
    {
      "epoch": 5.603903218805744,
      "grad_norm": 4.254824638366699,
      "learning_rate": 2.199221892864705e-05,
      "loss": 0.7175,
      "step": 529350
    },
    {
      "epoch": 5.604432540585748,
      "grad_norm": 4.399613857269287,
      "learning_rate": 2.198957230573788e-05,
      "loss": 0.7072,
      "step": 529400
    },
    {
      "epoch": 5.604961862365751,
      "grad_norm": 4.5147199630737305,
      "learning_rate": 2.1986925682828712e-05,
      "loss": 0.6998,
      "step": 529450
    },
    {
      "epoch": 5.605491184145754,
      "grad_norm": 4.568129539489746,
      "learning_rate": 2.1984279059919542e-05,
      "loss": 0.6936,
      "step": 529500
    },
    {
      "epoch": 5.605491184145754,
      "eval_loss": 0.4534870982170105,
      "eval_runtime": 46.8384,
      "eval_samples_per_second": 3585.309,
      "eval_steps_per_second": 448.18,
      "step": 529500
    },
    {
      "epoch": 5.606020505925757,
      "grad_norm": 4.483158111572266,
      "learning_rate": 2.1981632437010377e-05,
      "loss": 0.7041,
      "step": 529550
    },
    {
      "epoch": 5.606549827705761,
      "grad_norm": 4.600621700286865,
      "learning_rate": 2.1978985814101207e-05,
      "loss": 0.7032,
      "step": 529600
    },
    {
      "epoch": 5.607079149485764,
      "grad_norm": 4.057551860809326,
      "learning_rate": 2.197633919119204e-05,
      "loss": 0.7008,
      "step": 529650
    },
    {
      "epoch": 5.607608471265767,
      "grad_norm": 4.017104625701904,
      "learning_rate": 2.1973692568282872e-05,
      "loss": 0.6962,
      "step": 529700
    },
    {
      "epoch": 5.6081377930457705,
      "grad_norm": 4.525650501251221,
      "learning_rate": 2.1971045945373706e-05,
      "loss": 0.7055,
      "step": 529750
    },
    {
      "epoch": 5.608667114825773,
      "grad_norm": 4.309014320373535,
      "learning_rate": 2.1968399322464537e-05,
      "loss": 0.7035,
      "step": 529800
    },
    {
      "epoch": 5.609196436605777,
      "grad_norm": 4.1759843826293945,
      "learning_rate": 2.196575269955537e-05,
      "loss": 0.683,
      "step": 529850
    },
    {
      "epoch": 5.60972575838578,
      "grad_norm": 4.193552494049072,
      "learning_rate": 2.1963106076646202e-05,
      "loss": 0.7107,
      "step": 529900
    },
    {
      "epoch": 5.610255080165784,
      "grad_norm": 4.082571029663086,
      "learning_rate": 2.1960459453737032e-05,
      "loss": 0.7037,
      "step": 529950
    },
    {
      "epoch": 5.610784401945787,
      "grad_norm": 4.539287090301514,
      "learning_rate": 2.1957812830827863e-05,
      "loss": 0.7083,
      "step": 530000
    },
    {
      "epoch": 5.610784401945787,
      "eval_loss": 0.45400357246398926,
      "eval_runtime": 46.9214,
      "eval_samples_per_second": 3578.968,
      "eval_steps_per_second": 447.387,
      "step": 530000
    },
    {
      "epoch": 5.61131372372579,
      "grad_norm": 4.220334529876709,
      "learning_rate": 2.1955166207918697e-05,
      "loss": 0.6926,
      "step": 530050
    },
    {
      "epoch": 5.611843045505793,
      "grad_norm": 4.579733848571777,
      "learning_rate": 2.1952519585009528e-05,
      "loss": 0.7071,
      "step": 530100
    },
    {
      "epoch": 5.612372367285797,
      "grad_norm": 4.172333717346191,
      "learning_rate": 2.1949872962100362e-05,
      "loss": 0.7116,
      "step": 530150
    },
    {
      "epoch": 5.6129016890658,
      "grad_norm": 4.160092353820801,
      "learning_rate": 2.1947226339191193e-05,
      "loss": 0.7102,
      "step": 530200
    },
    {
      "epoch": 5.613431010845804,
      "grad_norm": 4.703421592712402,
      "learning_rate": 2.1944579716282023e-05,
      "loss": 0.7114,
      "step": 530250
    },
    {
      "epoch": 5.6139603326258065,
      "grad_norm": 4.183370113372803,
      "learning_rate": 2.1941933093372858e-05,
      "loss": 0.704,
      "step": 530300
    },
    {
      "epoch": 5.61448965440581,
      "grad_norm": 4.496654987335205,
      "learning_rate": 2.1939286470463688e-05,
      "loss": 0.6971,
      "step": 530350
    },
    {
      "epoch": 5.615018976185813,
      "grad_norm": 4.259139060974121,
      "learning_rate": 2.1936639847554522e-05,
      "loss": 0.6938,
      "step": 530400
    },
    {
      "epoch": 5.615548297965816,
      "grad_norm": 4.164422512054443,
      "learning_rate": 2.1933993224645353e-05,
      "loss": 0.7104,
      "step": 530450
    },
    {
      "epoch": 5.61607761974582,
      "grad_norm": 4.740800857543945,
      "learning_rate": 2.1931346601736187e-05,
      "loss": 0.689,
      "step": 530500
    },
    {
      "epoch": 5.61607761974582,
      "eval_loss": 0.4541933536529541,
      "eval_runtime": 46.9066,
      "eval_samples_per_second": 3580.092,
      "eval_steps_per_second": 447.527,
      "step": 530500
    },
    {
      "epoch": 5.616606941525823,
      "grad_norm": 4.74973201751709,
      "learning_rate": 2.1928699978827018e-05,
      "loss": 0.6916,
      "step": 530550
    },
    {
      "epoch": 5.617136263305826,
      "grad_norm": 4.110274791717529,
      "learning_rate": 2.192605335591785e-05,
      "loss": 0.7083,
      "step": 530600
    },
    {
      "epoch": 5.617665585085829,
      "grad_norm": 4.576233386993408,
      "learning_rate": 2.192340673300868e-05,
      "loss": 0.7139,
      "step": 530650
    },
    {
      "epoch": 5.618194906865833,
      "grad_norm": 4.44491720199585,
      "learning_rate": 2.1920760110099513e-05,
      "loss": 0.6964,
      "step": 530700
    },
    {
      "epoch": 5.618724228645836,
      "grad_norm": 4.09077262878418,
      "learning_rate": 2.1918113487190344e-05,
      "loss": 0.7043,
      "step": 530750
    },
    {
      "epoch": 5.61925355042584,
      "grad_norm": 4.06229305267334,
      "learning_rate": 2.1915466864281178e-05,
      "loss": 0.7054,
      "step": 530800
    },
    {
      "epoch": 5.6197828722058425,
      "grad_norm": 4.180037021636963,
      "learning_rate": 2.191282024137201e-05,
      "loss": 0.7074,
      "step": 530850
    },
    {
      "epoch": 5.620312193985846,
      "grad_norm": 4.265846252441406,
      "learning_rate": 2.1910173618462843e-05,
      "loss": 0.7035,
      "step": 530900
    },
    {
      "epoch": 5.620841515765849,
      "grad_norm": 3.7485275268554688,
      "learning_rate": 2.1907526995553674e-05,
      "loss": 0.7053,
      "step": 530950
    },
    {
      "epoch": 5.621370837545853,
      "grad_norm": 5.071102619171143,
      "learning_rate": 2.1904880372644508e-05,
      "loss": 0.7011,
      "step": 531000
    },
    {
      "epoch": 5.621370837545853,
      "eval_loss": 0.4540306627750397,
      "eval_runtime": 46.8908,
      "eval_samples_per_second": 3581.301,
      "eval_steps_per_second": 447.679,
      "step": 531000
    },
    {
      "epoch": 5.621900159325856,
      "grad_norm": 4.318655967712402,
      "learning_rate": 2.190223374973534e-05,
      "loss": 0.6973,
      "step": 531050
    },
    {
      "epoch": 5.6224294811058595,
      "grad_norm": 4.740124702453613,
      "learning_rate": 2.189958712682617e-05,
      "loss": 0.6925,
      "step": 531100
    },
    {
      "epoch": 5.622958802885862,
      "grad_norm": 4.498642921447754,
      "learning_rate": 2.1896940503917003e-05,
      "loss": 0.6915,
      "step": 531150
    },
    {
      "epoch": 5.623488124665865,
      "grad_norm": 4.0997185707092285,
      "learning_rate": 2.1894293881007834e-05,
      "loss": 0.6942,
      "step": 531200
    },
    {
      "epoch": 5.624017446445869,
      "grad_norm": 4.540836334228516,
      "learning_rate": 2.1891647258098665e-05,
      "loss": 0.7019,
      "step": 531250
    },
    {
      "epoch": 5.624546768225872,
      "grad_norm": 4.6263885498046875,
      "learning_rate": 2.18890006351895e-05,
      "loss": 0.7103,
      "step": 531300
    },
    {
      "epoch": 5.625076090005876,
      "grad_norm": 4.345250606536865,
      "learning_rate": 2.188635401228033e-05,
      "loss": 0.7068,
      "step": 531350
    },
    {
      "epoch": 5.6256054117858785,
      "grad_norm": 4.31557559967041,
      "learning_rate": 2.1883707389371164e-05,
      "loss": 0.6975,
      "step": 531400
    },
    {
      "epoch": 5.626134733565882,
      "grad_norm": 4.802469253540039,
      "learning_rate": 2.1881060766461994e-05,
      "loss": 0.7065,
      "step": 531450
    },
    {
      "epoch": 5.626664055345885,
      "grad_norm": 4.2835693359375,
      "learning_rate": 2.187841414355283e-05,
      "loss": 0.6987,
      "step": 531500
    },
    {
      "epoch": 5.626664055345885,
      "eval_loss": 0.4537181258201599,
      "eval_runtime": 46.9722,
      "eval_samples_per_second": 3575.096,
      "eval_steps_per_second": 446.903,
      "step": 531500
    },
    {
      "epoch": 5.627193377125889,
      "grad_norm": 4.225768089294434,
      "learning_rate": 2.187576752064366e-05,
      "loss": 0.7018,
      "step": 531550
    },
    {
      "epoch": 5.627722698905892,
      "grad_norm": 4.20399808883667,
      "learning_rate": 2.1873120897734493e-05,
      "loss": 0.6988,
      "step": 531600
    },
    {
      "epoch": 5.6282520206858955,
      "grad_norm": 4.308473587036133,
      "learning_rate": 2.1870474274825324e-05,
      "loss": 0.6996,
      "step": 531650
    },
    {
      "epoch": 5.628781342465898,
      "grad_norm": 4.476316452026367,
      "learning_rate": 2.1867827651916155e-05,
      "loss": 0.7075,
      "step": 531700
    },
    {
      "epoch": 5.629310664245902,
      "grad_norm": 4.256948947906494,
      "learning_rate": 2.1865181029006985e-05,
      "loss": 0.7056,
      "step": 531750
    },
    {
      "epoch": 5.629839986025905,
      "grad_norm": 4.152642726898193,
      "learning_rate": 2.1862587338556004e-05,
      "loss": 0.7088,
      "step": 531800
    },
    {
      "epoch": 5.630369307805909,
      "grad_norm": 4.213015079498291,
      "learning_rate": 2.1859940715646834e-05,
      "loss": 0.6973,
      "step": 531850
    },
    {
      "epoch": 5.630898629585912,
      "grad_norm": 4.17970085144043,
      "learning_rate": 2.185729409273767e-05,
      "loss": 0.6972,
      "step": 531900
    },
    {
      "epoch": 5.6314279513659145,
      "grad_norm": 4.0933709144592285,
      "learning_rate": 2.18546474698285e-05,
      "loss": 0.7163,
      "step": 531950
    },
    {
      "epoch": 5.631957273145918,
      "grad_norm": 4.306189060211182,
      "learning_rate": 2.1852000846919333e-05,
      "loss": 0.6994,
      "step": 532000
    },
    {
      "epoch": 5.631957273145918,
      "eval_loss": 0.45327267050743103,
      "eval_runtime": 46.9782,
      "eval_samples_per_second": 3574.633,
      "eval_steps_per_second": 446.845,
      "step": 532000
    },
    {
      "epoch": 5.632486594925921,
      "grad_norm": 4.197356700897217,
      "learning_rate": 2.1849354224010164e-05,
      "loss": 0.7014,
      "step": 532050
    },
    {
      "epoch": 5.633015916705925,
      "grad_norm": 4.108184814453125,
      "learning_rate": 2.1846707601100998e-05,
      "loss": 0.6865,
      "step": 532100
    },
    {
      "epoch": 5.633545238485928,
      "grad_norm": 4.377054214477539,
      "learning_rate": 2.184406097819183e-05,
      "loss": 0.6999,
      "step": 532150
    },
    {
      "epoch": 5.6340745602659315,
      "grad_norm": 4.620828151702881,
      "learning_rate": 2.184141435528266e-05,
      "loss": 0.695,
      "step": 532200
    },
    {
      "epoch": 5.634603882045934,
      "grad_norm": 3.8375344276428223,
      "learning_rate": 2.183876773237349e-05,
      "loss": 0.6943,
      "step": 532250
    },
    {
      "epoch": 5.635133203825938,
      "grad_norm": 4.313010215759277,
      "learning_rate": 2.1836121109464324e-05,
      "loss": 0.6994,
      "step": 532300
    },
    {
      "epoch": 5.635662525605941,
      "grad_norm": 4.487983703613281,
      "learning_rate": 2.1833474486555155e-05,
      "loss": 0.7008,
      "step": 532350
    },
    {
      "epoch": 5.636191847385945,
      "grad_norm": 4.092066764831543,
      "learning_rate": 2.183082786364599e-05,
      "loss": 0.6914,
      "step": 532400
    },
    {
      "epoch": 5.636721169165948,
      "grad_norm": 4.719046592712402,
      "learning_rate": 2.182818124073682e-05,
      "loss": 0.6994,
      "step": 532450
    },
    {
      "epoch": 5.637250490945951,
      "grad_norm": 4.495124340057373,
      "learning_rate": 2.1825534617827654e-05,
      "loss": 0.6958,
      "step": 532500
    },
    {
      "epoch": 5.637250490945951,
      "eval_loss": 0.4542198181152344,
      "eval_runtime": 46.8799,
      "eval_samples_per_second": 3582.129,
      "eval_steps_per_second": 447.782,
      "step": 532500
    },
    {
      "epoch": 5.637779812725954,
      "grad_norm": 4.142995834350586,
      "learning_rate": 2.1822887994918485e-05,
      "loss": 0.7055,
      "step": 532550
    },
    {
      "epoch": 5.638309134505958,
      "grad_norm": 4.381991863250732,
      "learning_rate": 2.182024137200932e-05,
      "loss": 0.6976,
      "step": 532600
    },
    {
      "epoch": 5.638838456285961,
      "grad_norm": 4.528783798217773,
      "learning_rate": 2.181759474910015e-05,
      "loss": 0.709,
      "step": 532650
    },
    {
      "epoch": 5.639367778065964,
      "grad_norm": 4.3006591796875,
      "learning_rate": 2.181494812619098e-05,
      "loss": 0.7083,
      "step": 532700
    },
    {
      "epoch": 5.639897099845967,
      "grad_norm": 4.008585453033447,
      "learning_rate": 2.181230150328181e-05,
      "loss": 0.6981,
      "step": 532750
    },
    {
      "epoch": 5.64042642162597,
      "grad_norm": 4.629546642303467,
      "learning_rate": 2.1809654880372645e-05,
      "loss": 0.7062,
      "step": 532800
    },
    {
      "epoch": 5.640955743405974,
      "grad_norm": 4.301776885986328,
      "learning_rate": 2.1807008257463476e-05,
      "loss": 0.6914,
      "step": 532850
    },
    {
      "epoch": 5.641485065185977,
      "grad_norm": 4.114539623260498,
      "learning_rate": 2.180436163455431e-05,
      "loss": 0.7055,
      "step": 532900
    },
    {
      "epoch": 5.642014386965981,
      "grad_norm": 4.5108842849731445,
      "learning_rate": 2.180171501164514e-05,
      "loss": 0.6874,
      "step": 532950
    },
    {
      "epoch": 5.6425437087459835,
      "grad_norm": 4.13161563873291,
      "learning_rate": 2.1799068388735975e-05,
      "loss": 0.6987,
      "step": 533000
    },
    {
      "epoch": 5.6425437087459835,
      "eval_loss": 0.45252764225006104,
      "eval_runtime": 46.8031,
      "eval_samples_per_second": 3588.008,
      "eval_steps_per_second": 448.517,
      "step": 533000
    },
    {
      "epoch": 5.643073030525987,
      "grad_norm": 4.596473217010498,
      "learning_rate": 2.1796421765826805e-05,
      "loss": 0.6927,
      "step": 533050
    },
    {
      "epoch": 5.64360235230599,
      "grad_norm": 4.5655694007873535,
      "learning_rate": 2.179377514291764e-05,
      "loss": 0.6986,
      "step": 533100
    },
    {
      "epoch": 5.644131674085994,
      "grad_norm": 4.070134162902832,
      "learning_rate": 2.179112852000847e-05,
      "loss": 0.7066,
      "step": 533150
    },
    {
      "epoch": 5.644660995865997,
      "grad_norm": 4.035987854003906,
      "learning_rate": 2.1788481897099304e-05,
      "loss": 0.6891,
      "step": 533200
    },
    {
      "epoch": 5.6451903176460005,
      "grad_norm": 4.303687572479248,
      "learning_rate": 2.1785835274190135e-05,
      "loss": 0.6984,
      "step": 533250
    },
    {
      "epoch": 5.645719639426003,
      "grad_norm": 4.230486869812012,
      "learning_rate": 2.1783188651280966e-05,
      "loss": 0.7105,
      "step": 533300
    },
    {
      "epoch": 5.646248961206007,
      "grad_norm": 3.8928122520446777,
      "learning_rate": 2.1780542028371796e-05,
      "loss": 0.6968,
      "step": 533350
    },
    {
      "epoch": 5.64677828298601,
      "grad_norm": 4.379360675811768,
      "learning_rate": 2.177789540546263e-05,
      "loss": 0.7021,
      "step": 533400
    },
    {
      "epoch": 5.647307604766013,
      "grad_norm": 4.187836647033691,
      "learning_rate": 2.177524878255346e-05,
      "loss": 0.7004,
      "step": 533450
    },
    {
      "epoch": 5.647836926546017,
      "grad_norm": 4.312726974487305,
      "learning_rate": 2.1772602159644295e-05,
      "loss": 0.7024,
      "step": 533500
    },
    {
      "epoch": 5.647836926546017,
      "eval_loss": 0.45370015501976013,
      "eval_runtime": 47.1209,
      "eval_samples_per_second": 3563.808,
      "eval_steps_per_second": 445.492,
      "step": 533500
    },
    {
      "epoch": 5.6483662483260195,
      "grad_norm": 4.673104763031006,
      "learning_rate": 2.1769955536735126e-05,
      "loss": 0.7059,
      "step": 533550
    },
    {
      "epoch": 5.648895570106023,
      "grad_norm": 4.160367012023926,
      "learning_rate": 2.176730891382596e-05,
      "loss": 0.6928,
      "step": 533600
    },
    {
      "epoch": 5.649424891886026,
      "grad_norm": 4.1170454025268555,
      "learning_rate": 2.176466229091679e-05,
      "loss": 0.698,
      "step": 533650
    },
    {
      "epoch": 5.64995421366603,
      "grad_norm": 4.4179840087890625,
      "learning_rate": 2.1762015668007625e-05,
      "loss": 0.7034,
      "step": 533700
    },
    {
      "epoch": 5.650483535446033,
      "grad_norm": 4.354252815246582,
      "learning_rate": 2.1759369045098456e-05,
      "loss": 0.7028,
      "step": 533750
    },
    {
      "epoch": 5.6510128572260365,
      "grad_norm": 4.407286167144775,
      "learning_rate": 2.175677535464747e-05,
      "loss": 0.704,
      "step": 533800
    },
    {
      "epoch": 5.651542179006039,
      "grad_norm": 4.191444396972656,
      "learning_rate": 2.17541287317383e-05,
      "loss": 0.7066,
      "step": 533850
    },
    {
      "epoch": 5.652071500786043,
      "grad_norm": 4.153367519378662,
      "learning_rate": 2.1751482108829135e-05,
      "loss": 0.7002,
      "step": 533900
    },
    {
      "epoch": 5.652600822566046,
      "grad_norm": 4.217931747436523,
      "learning_rate": 2.1748835485919966e-05,
      "loss": 0.695,
      "step": 533950
    },
    {
      "epoch": 5.65313014434605,
      "grad_norm": 4.493646144866943,
      "learning_rate": 2.17461888630108e-05,
      "loss": 0.7025,
      "step": 534000
    },
    {
      "epoch": 5.65313014434605,
      "eval_loss": 0.453630268573761,
      "eval_runtime": 46.7788,
      "eval_samples_per_second": 3589.878,
      "eval_steps_per_second": 448.751,
      "step": 534000
    },
    {
      "epoch": 5.653659466126053,
      "grad_norm": 4.24260139465332,
      "learning_rate": 2.174354224010163e-05,
      "loss": 0.7026,
      "step": 534050
    },
    {
      "epoch": 5.654188787906056,
      "grad_norm": 4.429576873779297,
      "learning_rate": 2.1740895617192465e-05,
      "loss": 0.7029,
      "step": 534100
    },
    {
      "epoch": 5.654718109686059,
      "grad_norm": 4.398532867431641,
      "learning_rate": 2.1738248994283295e-05,
      "loss": 0.7175,
      "step": 534150
    },
    {
      "epoch": 5.655247431466062,
      "grad_norm": 3.710366725921631,
      "learning_rate": 2.173560237137413e-05,
      "loss": 0.7013,
      "step": 534200
    },
    {
      "epoch": 5.655776753246066,
      "grad_norm": 4.119998931884766,
      "learning_rate": 2.173295574846496e-05,
      "loss": 0.7005,
      "step": 534250
    },
    {
      "epoch": 5.656306075026069,
      "grad_norm": 4.3479766845703125,
      "learning_rate": 2.173030912555579e-05,
      "loss": 0.7028,
      "step": 534300
    },
    {
      "epoch": 5.6568353968060725,
      "grad_norm": 4.274901866912842,
      "learning_rate": 2.172766250264662e-05,
      "loss": 0.6843,
      "step": 534350
    },
    {
      "epoch": 5.657364718586075,
      "grad_norm": 4.288839817047119,
      "learning_rate": 2.1725015879737456e-05,
      "loss": 0.707,
      "step": 534400
    },
    {
      "epoch": 5.657894040366079,
      "grad_norm": 4.489778995513916,
      "learning_rate": 2.1722369256828286e-05,
      "loss": 0.6943,
      "step": 534450
    },
    {
      "epoch": 5.658423362146082,
      "grad_norm": 4.368219375610352,
      "learning_rate": 2.171972263391912e-05,
      "loss": 0.6928,
      "step": 534500
    },
    {
      "epoch": 5.658423362146082,
      "eval_loss": 0.4529128074645996,
      "eval_runtime": 46.8449,
      "eval_samples_per_second": 3584.808,
      "eval_steps_per_second": 448.117,
      "step": 534500
    },
    {
      "epoch": 5.658952683926086,
      "grad_norm": 4.442136764526367,
      "learning_rate": 2.171707601100995e-05,
      "loss": 0.7005,
      "step": 534550
    },
    {
      "epoch": 5.659482005706089,
      "grad_norm": 4.1708149909973145,
      "learning_rate": 2.1714429388100785e-05,
      "loss": 0.6909,
      "step": 534600
    },
    {
      "epoch": 5.660011327486092,
      "grad_norm": 3.8852555751800537,
      "learning_rate": 2.1711782765191616e-05,
      "loss": 0.7016,
      "step": 534650
    },
    {
      "epoch": 5.660540649266095,
      "grad_norm": 3.978381872177124,
      "learning_rate": 2.170913614228245e-05,
      "loss": 0.6937,
      "step": 534700
    },
    {
      "epoch": 5.661069971046099,
      "grad_norm": 4.109107494354248,
      "learning_rate": 2.170648951937328e-05,
      "loss": 0.6981,
      "step": 534750
    },
    {
      "epoch": 5.661599292826102,
      "grad_norm": 4.215357780456543,
      "learning_rate": 2.170384289646411e-05,
      "loss": 0.6858,
      "step": 534800
    },
    {
      "epoch": 5.662128614606106,
      "grad_norm": 4.317890644073486,
      "learning_rate": 2.1701196273554946e-05,
      "loss": 0.6913,
      "step": 534850
    },
    {
      "epoch": 5.6626579363861085,
      "grad_norm": 4.552714824676514,
      "learning_rate": 2.1698549650645776e-05,
      "loss": 0.7079,
      "step": 534900
    },
    {
      "epoch": 5.663187258166111,
      "grad_norm": 4.376948833465576,
      "learning_rate": 2.1695903027736607e-05,
      "loss": 0.695,
      "step": 534950
    },
    {
      "epoch": 5.663716579946115,
      "grad_norm": 4.616860389709473,
      "learning_rate": 2.169325640482744e-05,
      "loss": 0.6971,
      "step": 535000
    },
    {
      "epoch": 5.663716579946115,
      "eval_loss": 0.4522287845611572,
      "eval_runtime": 46.8821,
      "eval_samples_per_second": 3581.966,
      "eval_steps_per_second": 447.762,
      "step": 535000
    },
    {
      "epoch": 5.664245901726118,
      "grad_norm": 3.9153544902801514,
      "learning_rate": 2.1690609781918272e-05,
      "loss": 0.7017,
      "step": 535050
    },
    {
      "epoch": 5.664775223506122,
      "grad_norm": 4.065706729888916,
      "learning_rate": 2.1687963159009106e-05,
      "loss": 0.7047,
      "step": 535100
    },
    {
      "epoch": 5.665304545286125,
      "grad_norm": 4.121439456939697,
      "learning_rate": 2.1685316536099937e-05,
      "loss": 0.7019,
      "step": 535150
    },
    {
      "epoch": 5.665833867066128,
      "grad_norm": 4.4634904861450195,
      "learning_rate": 2.168266991319077e-05,
      "loss": 0.6989,
      "step": 535200
    },
    {
      "epoch": 5.666363188846131,
      "grad_norm": 4.3366594314575195,
      "learning_rate": 2.16800232902816e-05,
      "loss": 0.7045,
      "step": 535250
    },
    {
      "epoch": 5.666892510626135,
      "grad_norm": 4.6628098487854,
      "learning_rate": 2.1677376667372436e-05,
      "loss": 0.7065,
      "step": 535300
    },
    {
      "epoch": 5.667421832406138,
      "grad_norm": 4.449918746948242,
      "learning_rate": 2.1674730044463266e-05,
      "loss": 0.6896,
      "step": 535350
    },
    {
      "epoch": 5.667951154186142,
      "grad_norm": 4.485288619995117,
      "learning_rate": 2.1672083421554097e-05,
      "loss": 0.7051,
      "step": 535400
    },
    {
      "epoch": 5.6684804759661445,
      "grad_norm": 4.1295247077941895,
      "learning_rate": 2.1669436798644928e-05,
      "loss": 0.7039,
      "step": 535450
    },
    {
      "epoch": 5.669009797746148,
      "grad_norm": 4.4790873527526855,
      "learning_rate": 2.1666790175735762e-05,
      "loss": 0.703,
      "step": 535500
    },
    {
      "epoch": 5.669009797746148,
      "eval_loss": 0.45298486948013306,
      "eval_runtime": 46.9256,
      "eval_samples_per_second": 3578.64,
      "eval_steps_per_second": 447.346,
      "step": 535500
    },
    {
      "epoch": 5.669539119526151,
      "grad_norm": 4.46770715713501,
      "learning_rate": 2.1664143552826593e-05,
      "loss": 0.7007,
      "step": 535550
    },
    {
      "epoch": 5.670068441306155,
      "grad_norm": 4.289888858795166,
      "learning_rate": 2.1661496929917427e-05,
      "loss": 0.6995,
      "step": 535600
    },
    {
      "epoch": 5.670597763086158,
      "grad_norm": 4.139512062072754,
      "learning_rate": 2.1658850307008257e-05,
      "loss": 0.6878,
      "step": 535650
    },
    {
      "epoch": 5.671127084866161,
      "grad_norm": 4.679684162139893,
      "learning_rate": 2.165620368409909e-05,
      "loss": 0.7079,
      "step": 535700
    },
    {
      "epoch": 5.671656406646164,
      "grad_norm": 4.260028839111328,
      "learning_rate": 2.1653557061189922e-05,
      "loss": 0.6982,
      "step": 535750
    },
    {
      "epoch": 5.672185728426167,
      "grad_norm": Infinity,
      "learning_rate": 2.165096337073894e-05,
      "loss": 0.7111,
      "step": 535800
    },
    {
      "epoch": 5.672715050206171,
      "grad_norm": 4.187687873840332,
      "learning_rate": 2.164831674782977e-05,
      "loss": 0.7046,
      "step": 535850
    },
    {
      "epoch": 5.673244371986174,
      "grad_norm": 4.396596431732178,
      "learning_rate": 2.1645670124920602e-05,
      "loss": 0.7058,
      "step": 535900
    },
    {
      "epoch": 5.673773693766178,
      "grad_norm": 4.0979905128479,
      "learning_rate": 2.1643023502011432e-05,
      "loss": 0.7064,
      "step": 535950
    },
    {
      "epoch": 5.67430301554618,
      "grad_norm": 4.494274616241455,
      "learning_rate": 2.1640376879102267e-05,
      "loss": 0.7021,
      "step": 536000
    },
    {
      "epoch": 5.67430301554618,
      "eval_loss": 0.45338571071624756,
      "eval_runtime": 46.9266,
      "eval_samples_per_second": 3578.564,
      "eval_steps_per_second": 447.336,
      "step": 536000
    },
    {
      "epoch": 5.674832337326184,
      "grad_norm": 4.338953971862793,
      "learning_rate": 2.1637730256193097e-05,
      "loss": 0.7037,
      "step": 536050
    },
    {
      "epoch": 5.675361659106187,
      "grad_norm": 4.379620552062988,
      "learning_rate": 2.163508363328393e-05,
      "loss": 0.6816,
      "step": 536100
    },
    {
      "epoch": 5.675890980886191,
      "grad_norm": 3.9977376461029053,
      "learning_rate": 2.1632437010374762e-05,
      "loss": 0.7006,
      "step": 536150
    },
    {
      "epoch": 5.676420302666194,
      "grad_norm": 4.634949207305908,
      "learning_rate": 2.1629790387465596e-05,
      "loss": 0.707,
      "step": 536200
    },
    {
      "epoch": 5.676949624446197,
      "grad_norm": 4.524426460266113,
      "learning_rate": 2.1627143764556427e-05,
      "loss": 0.6869,
      "step": 536250
    },
    {
      "epoch": 5.6774789462262,
      "grad_norm": 4.34051513671875,
      "learning_rate": 2.162449714164726e-05,
      "loss": 0.6899,
      "step": 536300
    },
    {
      "epoch": 5.678008268006204,
      "grad_norm": 4.35292911529541,
      "learning_rate": 2.1621850518738092e-05,
      "loss": 0.694,
      "step": 536350
    },
    {
      "epoch": 5.678537589786207,
      "grad_norm": 4.55045223236084,
      "learning_rate": 2.1619203895828922e-05,
      "loss": 0.7021,
      "step": 536400
    },
    {
      "epoch": 5.67906691156621,
      "grad_norm": 4.627591609954834,
      "learning_rate": 2.1616557272919753e-05,
      "loss": 0.701,
      "step": 536450
    },
    {
      "epoch": 5.6795962333462136,
      "grad_norm": 4.084836959838867,
      "learning_rate": 2.1613910650010587e-05,
      "loss": 0.7021,
      "step": 536500
    },
    {
      "epoch": 5.6795962333462136,
      "eval_loss": 0.4527873992919922,
      "eval_runtime": 46.777,
      "eval_samples_per_second": 3590.011,
      "eval_steps_per_second": 448.767,
      "step": 536500
    },
    {
      "epoch": 5.680125555126216,
      "grad_norm": 4.392030715942383,
      "learning_rate": 2.1611264027101418e-05,
      "loss": 0.7131,
      "step": 536550
    },
    {
      "epoch": 5.68065487690622,
      "grad_norm": 4.135538578033447,
      "learning_rate": 2.1608617404192252e-05,
      "loss": 0.7101,
      "step": 536600
    },
    {
      "epoch": 5.681184198686223,
      "grad_norm": 4.263946533203125,
      "learning_rate": 2.1605970781283083e-05,
      "loss": 0.6836,
      "step": 536650
    },
    {
      "epoch": 5.681713520466227,
      "grad_norm": 3.8642640113830566,
      "learning_rate": 2.1603324158373917e-05,
      "loss": 0.6944,
      "step": 536700
    },
    {
      "epoch": 5.68224284224623,
      "grad_norm": 4.26618766784668,
      "learning_rate": 2.1600677535464748e-05,
      "loss": 0.7041,
      "step": 536750
    },
    {
      "epoch": 5.682772164026233,
      "grad_norm": 4.016818046569824,
      "learning_rate": 2.159803091255558e-05,
      "loss": 0.6882,
      "step": 536800
    },
    {
      "epoch": 5.683301485806236,
      "grad_norm": 4.164767265319824,
      "learning_rate": 2.1595384289646412e-05,
      "loss": 0.689,
      "step": 536850
    },
    {
      "epoch": 5.68383080758624,
      "grad_norm": 4.0391154289245605,
      "learning_rate": 2.1592737666737246e-05,
      "loss": 0.7077,
      "step": 536900
    },
    {
      "epoch": 5.684360129366243,
      "grad_norm": 4.403076171875,
      "learning_rate": 2.1590143976286258e-05,
      "loss": 0.693,
      "step": 536950
    },
    {
      "epoch": 5.684889451146247,
      "grad_norm": 4.233182430267334,
      "learning_rate": 2.1587497353377092e-05,
      "loss": 0.7055,
      "step": 537000
    },
    {
      "epoch": 5.684889451146247,
      "eval_loss": 0.4522552192211151,
      "eval_runtime": 46.8765,
      "eval_samples_per_second": 3582.391,
      "eval_steps_per_second": 447.815,
      "step": 537000
    },
    {
      "epoch": 5.6854187729262495,
      "grad_norm": 4.270205497741699,
      "learning_rate": 2.1584850730467923e-05,
      "loss": 0.7054,
      "step": 537050
    },
    {
      "epoch": 5.685948094706253,
      "grad_norm": 4.516678810119629,
      "learning_rate": 2.1582204107558757e-05,
      "loss": 0.6958,
      "step": 537100
    },
    {
      "epoch": 5.686477416486256,
      "grad_norm": 4.359385967254639,
      "learning_rate": 2.1579557484649587e-05,
      "loss": 0.6996,
      "step": 537150
    },
    {
      "epoch": 5.687006738266259,
      "grad_norm": 4.1285271644592285,
      "learning_rate": 2.157691086174042e-05,
      "loss": 0.701,
      "step": 537200
    },
    {
      "epoch": 5.687536060046263,
      "grad_norm": 4.319835186004639,
      "learning_rate": 2.1574264238831252e-05,
      "loss": 0.6888,
      "step": 537250
    },
    {
      "epoch": 5.688065381826266,
      "grad_norm": 4.056235313415527,
      "learning_rate": 2.1571617615922086e-05,
      "loss": 0.7005,
      "step": 537300
    },
    {
      "epoch": 5.688594703606269,
      "grad_norm": 4.062685012817383,
      "learning_rate": 2.1568970993012917e-05,
      "loss": 0.7066,
      "step": 537350
    },
    {
      "epoch": 5.689124025386272,
      "grad_norm": 4.26334285736084,
      "learning_rate": 2.1566324370103748e-05,
      "loss": 0.7015,
      "step": 537400
    },
    {
      "epoch": 5.689653347166276,
      "grad_norm": 4.297347068786621,
      "learning_rate": 2.156367774719458e-05,
      "loss": 0.6951,
      "step": 537450
    },
    {
      "epoch": 5.690182668946279,
      "grad_norm": 4.727916240692139,
      "learning_rate": 2.1561031124285413e-05,
      "loss": 0.6983,
      "step": 537500
    },
    {
      "epoch": 5.690182668946279,
      "eval_loss": 0.4520856440067291,
      "eval_runtime": 46.7543,
      "eval_samples_per_second": 3591.757,
      "eval_steps_per_second": 448.986,
      "step": 537500
    },
    {
      "epoch": 5.690711990726283,
      "grad_norm": 4.818825721740723,
      "learning_rate": 2.1558384501376243e-05,
      "loss": 0.6973,
      "step": 537550
    },
    {
      "epoch": 5.6912413125062855,
      "grad_norm": 4.361107349395752,
      "learning_rate": 2.1555737878467077e-05,
      "loss": 0.7012,
      "step": 537600
    },
    {
      "epoch": 5.691770634286289,
      "grad_norm": 4.68454122543335,
      "learning_rate": 2.1553091255557908e-05,
      "loss": 0.6984,
      "step": 537650
    },
    {
      "epoch": 5.692299956066292,
      "grad_norm": 4.221154689788818,
      "learning_rate": 2.1550444632648742e-05,
      "loss": 0.7029,
      "step": 537700
    },
    {
      "epoch": 5.692829277846296,
      "grad_norm": 4.497141361236572,
      "learning_rate": 2.1547798009739573e-05,
      "loss": 0.7143,
      "step": 537750
    },
    {
      "epoch": 5.693358599626299,
      "grad_norm": 3.991053581237793,
      "learning_rate": 2.1545151386830407e-05,
      "loss": 0.6945,
      "step": 537800
    },
    {
      "epoch": 5.6938879214063025,
      "grad_norm": 4.026276111602783,
      "learning_rate": 2.1542504763921238e-05,
      "loss": 0.6912,
      "step": 537850
    },
    {
      "epoch": 5.694417243186305,
      "grad_norm": 4.288947105407715,
      "learning_rate": 2.1539858141012072e-05,
      "loss": 0.7064,
      "step": 537900
    },
    {
      "epoch": 5.694946564966308,
      "grad_norm": 4.38197660446167,
      "learning_rate": 2.1537211518102903e-05,
      "loss": 0.7014,
      "step": 537950
    },
    {
      "epoch": 5.695475886746312,
      "grad_norm": 4.243671894073486,
      "learning_rate": 2.1534564895193733e-05,
      "loss": 0.6965,
      "step": 538000
    },
    {
      "epoch": 5.695475886746312,
      "eval_loss": 0.4518440067768097,
      "eval_runtime": 46.8179,
      "eval_samples_per_second": 3586.877,
      "eval_steps_per_second": 448.376,
      "step": 538000
    },
    {
      "epoch": 5.696005208526315,
      "grad_norm": 4.375216484069824,
      "learning_rate": 2.1531918272284564e-05,
      "loss": 0.7013,
      "step": 538050
    },
    {
      "epoch": 5.696534530306319,
      "grad_norm": 4.5548834800720215,
      "learning_rate": 2.1529271649375398e-05,
      "loss": 0.6896,
      "step": 538100
    },
    {
      "epoch": 5.6970638520863215,
      "grad_norm": 4.495274066925049,
      "learning_rate": 2.152662502646623e-05,
      "loss": 0.6938,
      "step": 538150
    },
    {
      "epoch": 5.697593173866325,
      "grad_norm": 4.488956451416016,
      "learning_rate": 2.1523978403557063e-05,
      "loss": 0.7105,
      "step": 538200
    },
    {
      "epoch": 5.698122495646328,
      "grad_norm": 4.657912731170654,
      "learning_rate": 2.1521331780647894e-05,
      "loss": 0.6953,
      "step": 538250
    },
    {
      "epoch": 5.698651817426332,
      "grad_norm": 4.345277786254883,
      "learning_rate": 2.1518685157738728e-05,
      "loss": 0.6882,
      "step": 538300
    },
    {
      "epoch": 5.699181139206335,
      "grad_norm": 3.9393646717071533,
      "learning_rate": 2.151603853482956e-05,
      "loss": 0.703,
      "step": 538350
    },
    {
      "epoch": 5.6997104609863385,
      "grad_norm": 4.546133518218994,
      "learning_rate": 2.1513391911920392e-05,
      "loss": 0.716,
      "step": 538400
    },
    {
      "epoch": 5.700239782766341,
      "grad_norm": 4.446007251739502,
      "learning_rate": 2.1510745289011223e-05,
      "loss": 0.6978,
      "step": 538450
    },
    {
      "epoch": 5.700769104546345,
      "grad_norm": 4.169017791748047,
      "learning_rate": 2.1508098666102054e-05,
      "loss": 0.6945,
      "step": 538500
    },
    {
      "epoch": 5.700769104546345,
      "eval_loss": 0.451750785112381,
      "eval_runtime": 46.9566,
      "eval_samples_per_second": 3576.283,
      "eval_steps_per_second": 447.051,
      "step": 538500
    },
    {
      "epoch": 5.701298426326348,
      "grad_norm": 4.064133167266846,
      "learning_rate": 2.1505452043192888e-05,
      "loss": 0.7034,
      "step": 538550
    },
    {
      "epoch": 5.701827748106352,
      "grad_norm": 4.289552211761475,
      "learning_rate": 2.150280542028372e-05,
      "loss": 0.6928,
      "step": 538600
    },
    {
      "epoch": 5.702357069886355,
      "grad_norm": 4.491549015045166,
      "learning_rate": 2.150015879737455e-05,
      "loss": 0.6968,
      "step": 538650
    },
    {
      "epoch": 5.7028863916663575,
      "grad_norm": 4.25101900100708,
      "learning_rate": 2.1497512174465384e-05,
      "loss": 0.7006,
      "step": 538700
    },
    {
      "epoch": 5.703415713446361,
      "grad_norm": 4.69560432434082,
      "learning_rate": 2.1494865551556214e-05,
      "loss": 0.7082,
      "step": 538750
    },
    {
      "epoch": 5.703945035226364,
      "grad_norm": 4.19399356842041,
      "learning_rate": 2.149221892864705e-05,
      "loss": 0.6908,
      "step": 538800
    },
    {
      "epoch": 5.704474357006368,
      "grad_norm": 4.4541473388671875,
      "learning_rate": 2.148957230573788e-05,
      "loss": 0.6923,
      "step": 538850
    },
    {
      "epoch": 5.705003678786371,
      "grad_norm": 4.386116027832031,
      "learning_rate": 2.1486925682828713e-05,
      "loss": 0.6982,
      "step": 538900
    },
    {
      "epoch": 5.7055330005663745,
      "grad_norm": 4.373019218444824,
      "learning_rate": 2.1484279059919544e-05,
      "loss": 0.6961,
      "step": 538950
    },
    {
      "epoch": 5.706062322346377,
      "grad_norm": 4.411920547485352,
      "learning_rate": 2.1481632437010378e-05,
      "loss": 0.6927,
      "step": 539000
    },
    {
      "epoch": 5.706062322346377,
      "eval_loss": 0.45071202516555786,
      "eval_runtime": 46.8788,
      "eval_samples_per_second": 3582.213,
      "eval_steps_per_second": 447.793,
      "step": 539000
    },
    {
      "epoch": 5.706591644126381,
      "grad_norm": 4.47393274307251,
      "learning_rate": 2.147898581410121e-05,
      "loss": 0.6968,
      "step": 539050
    },
    {
      "epoch": 5.707120965906384,
      "grad_norm": 4.098743438720703,
      "learning_rate": 2.147633919119204e-05,
      "loss": 0.6991,
      "step": 539100
    },
    {
      "epoch": 5.707650287686388,
      "grad_norm": 4.809042930603027,
      "learning_rate": 2.147369256828287e-05,
      "loss": 0.6854,
      "step": 539150
    },
    {
      "epoch": 5.708179609466391,
      "grad_norm": 4.673096656799316,
      "learning_rate": 2.1471045945373704e-05,
      "loss": 0.7056,
      "step": 539200
    },
    {
      "epoch": 5.708708931246394,
      "grad_norm": 4.368319034576416,
      "learning_rate": 2.1468399322464535e-05,
      "loss": 0.7084,
      "step": 539250
    },
    {
      "epoch": 5.709238253026397,
      "grad_norm": 4.037673473358154,
      "learning_rate": 2.146575269955537e-05,
      "loss": 0.6987,
      "step": 539300
    },
    {
      "epoch": 5.709767574806401,
      "grad_norm": 4.221156120300293,
      "learning_rate": 2.14631060766462e-05,
      "loss": 0.6961,
      "step": 539350
    },
    {
      "epoch": 5.710296896586404,
      "grad_norm": 4.572324752807617,
      "learning_rate": 2.1460459453737034e-05,
      "loss": 0.7095,
      "step": 539400
    },
    {
      "epoch": 5.710826218366407,
      "grad_norm": 3.965902328491211,
      "learning_rate": 2.1457812830827865e-05,
      "loss": 0.7154,
      "step": 539450
    },
    {
      "epoch": 5.7113555401464104,
      "grad_norm": 4.393352508544922,
      "learning_rate": 2.14551662079187e-05,
      "loss": 0.6905,
      "step": 539500
    },
    {
      "epoch": 5.7113555401464104,
      "eval_loss": 0.44930219650268555,
      "eval_runtime": 46.8493,
      "eval_samples_per_second": 3584.473,
      "eval_steps_per_second": 448.075,
      "step": 539500
    },
    {
      "epoch": 5.711884861926413,
      "grad_norm": 4.457083702087402,
      "learning_rate": 2.145251958500953e-05,
      "loss": 0.7119,
      "step": 539550
    },
    {
      "epoch": 5.712414183706417,
      "grad_norm": 4.466332912445068,
      "learning_rate": 2.1449872962100363e-05,
      "loss": 0.6979,
      "step": 539600
    },
    {
      "epoch": 5.71294350548642,
      "grad_norm": 4.366425037384033,
      "learning_rate": 2.1447226339191194e-05,
      "loss": 0.704,
      "step": 539650
    },
    {
      "epoch": 5.713472827266424,
      "grad_norm": 4.376542091369629,
      "learning_rate": 2.1444579716282025e-05,
      "loss": 0.6923,
      "step": 539700
    },
    {
      "epoch": 5.714002149046427,
      "grad_norm": 4.651148796081543,
      "learning_rate": 2.1441933093372856e-05,
      "loss": 0.7145,
      "step": 539750
    },
    {
      "epoch": 5.71453147082643,
      "grad_norm": 4.162866592407227,
      "learning_rate": 2.143928647046369e-05,
      "loss": 0.692,
      "step": 539800
    },
    {
      "epoch": 5.715060792606433,
      "grad_norm": 4.602969169616699,
      "learning_rate": 2.143663984755452e-05,
      "loss": 0.6821,
      "step": 539850
    },
    {
      "epoch": 5.715590114386437,
      "grad_norm": 3.9393014907836914,
      "learning_rate": 2.1433993224645354e-05,
      "loss": 0.6909,
      "step": 539900
    },
    {
      "epoch": 5.71611943616644,
      "grad_norm": 4.068813800811768,
      "learning_rate": 2.1431346601736185e-05,
      "loss": 0.7102,
      "step": 539950
    },
    {
      "epoch": 5.716648757946444,
      "grad_norm": 4.113556861877441,
      "learning_rate": 2.142869997882702e-05,
      "loss": 0.6951,
      "step": 540000
    },
    {
      "epoch": 5.716648757946444,
      "eval_loss": 0.44999971985816956,
      "eval_runtime": 46.8514,
      "eval_samples_per_second": 3584.31,
      "eval_steps_per_second": 448.055,
      "step": 540000
    },
    {
      "epoch": 5.717178079726446,
      "grad_norm": 4.5918803215026855,
      "learning_rate": 2.142605335591785e-05,
      "loss": 0.6932,
      "step": 540050
    },
    {
      "epoch": 5.71770740150645,
      "grad_norm": 4.073059558868408,
      "learning_rate": 2.1423406733008684e-05,
      "loss": 0.7056,
      "step": 540100
    },
    {
      "epoch": 5.718236723286453,
      "grad_norm": 4.289549350738525,
      "learning_rate": 2.1420760110099515e-05,
      "loss": 0.6993,
      "step": 540150
    },
    {
      "epoch": 5.718766045066456,
      "grad_norm": 4.655249118804932,
      "learning_rate": 2.1418113487190346e-05,
      "loss": 0.701,
      "step": 540200
    },
    {
      "epoch": 5.71929536684646,
      "grad_norm": 4.611129283905029,
      "learning_rate": 2.1415466864281176e-05,
      "loss": 0.7027,
      "step": 540250
    },
    {
      "epoch": 5.7198246886264625,
      "grad_norm": 4.26182746887207,
      "learning_rate": 2.141282024137201e-05,
      "loss": 0.6985,
      "step": 540300
    },
    {
      "epoch": 5.720354010406466,
      "grad_norm": 4.595004558563232,
      "learning_rate": 2.141017361846284e-05,
      "loss": 0.6941,
      "step": 540350
    },
    {
      "epoch": 5.720883332186469,
      "grad_norm": 4.179193496704102,
      "learning_rate": 2.1407526995553675e-05,
      "loss": 0.6987,
      "step": 540400
    },
    {
      "epoch": 5.721412653966473,
      "grad_norm": 4.578373908996582,
      "learning_rate": 2.1404880372644506e-05,
      "loss": 0.7085,
      "step": 540450
    },
    {
      "epoch": 5.721941975746476,
      "grad_norm": 3.770031213760376,
      "learning_rate": 2.140223374973534e-05,
      "loss": 0.6937,
      "step": 540500
    },
    {
      "epoch": 5.721941975746476,
      "eval_loss": 0.45042529702186584,
      "eval_runtime": 46.9058,
      "eval_samples_per_second": 3580.155,
      "eval_steps_per_second": 447.535,
      "step": 540500
    },
    {
      "epoch": 5.7224712975264795,
      "grad_norm": 4.304062366485596,
      "learning_rate": 2.139958712682617e-05,
      "loss": 0.7158,
      "step": 540550
    },
    {
      "epoch": 5.723000619306482,
      "grad_norm": 4.360248565673828,
      "learning_rate": 2.1396940503917005e-05,
      "loss": 0.6933,
      "step": 540600
    },
    {
      "epoch": 5.723529941086486,
      "grad_norm": 4.257759094238281,
      "learning_rate": 2.1394293881007835e-05,
      "loss": 0.7025,
      "step": 540650
    },
    {
      "epoch": 5.724059262866489,
      "grad_norm": 4.160103797912598,
      "learning_rate": 2.139164725809867e-05,
      "loss": 0.708,
      "step": 540700
    },
    {
      "epoch": 5.724588584646493,
      "grad_norm": 4.065588474273682,
      "learning_rate": 2.13890006351895e-05,
      "loss": 0.6893,
      "step": 540750
    },
    {
      "epoch": 5.725117906426496,
      "grad_norm": 4.624356269836426,
      "learning_rate": 2.138635401228033e-05,
      "loss": 0.7023,
      "step": 540800
    },
    {
      "epoch": 5.725647228206499,
      "grad_norm": 4.042956829071045,
      "learning_rate": 2.1383707389371162e-05,
      "loss": 0.6945,
      "step": 540850
    },
    {
      "epoch": 5.726176549986502,
      "grad_norm": 4.243811130523682,
      "learning_rate": 2.1381060766461996e-05,
      "loss": 0.6955,
      "step": 540900
    },
    {
      "epoch": 5.726705871766505,
      "grad_norm": 4.46816349029541,
      "learning_rate": 2.137846707601101e-05,
      "loss": 0.6998,
      "step": 540950
    },
    {
      "epoch": 5.727235193546509,
      "grad_norm": 4.2666015625,
      "learning_rate": 2.1375820453101845e-05,
      "loss": 0.7022,
      "step": 541000
    },
    {
      "epoch": 5.727235193546509,
      "eval_loss": 0.45088091492652893,
      "eval_runtime": 46.828,
      "eval_samples_per_second": 3586.105,
      "eval_steps_per_second": 448.279,
      "step": 541000
    },
    {
      "epoch": 5.727764515326512,
      "grad_norm": 4.647714614868164,
      "learning_rate": 2.1373173830192675e-05,
      "loss": 0.6945,
      "step": 541050
    },
    {
      "epoch": 5.7282938371065155,
      "grad_norm": 3.9770166873931885,
      "learning_rate": 2.137052720728351e-05,
      "loss": 0.6932,
      "step": 541100
    },
    {
      "epoch": 5.728823158886518,
      "grad_norm": 3.9781720638275146,
      "learning_rate": 2.136788058437434e-05,
      "loss": 0.6965,
      "step": 541150
    },
    {
      "epoch": 5.729352480666522,
      "grad_norm": 4.239123344421387,
      "learning_rate": 2.136523396146517e-05,
      "loss": 0.6825,
      "step": 541200
    },
    {
      "epoch": 5.729881802446525,
      "grad_norm": 4.040078163146973,
      "learning_rate": 2.1362587338556e-05,
      "loss": 0.7003,
      "step": 541250
    },
    {
      "epoch": 5.730411124226529,
      "grad_norm": 4.487638473510742,
      "learning_rate": 2.1359940715646836e-05,
      "loss": 0.6954,
      "step": 541300
    },
    {
      "epoch": 5.730940446006532,
      "grad_norm": 4.3610124588012695,
      "learning_rate": 2.1357294092737666e-05,
      "loss": 0.7009,
      "step": 541350
    },
    {
      "epoch": 5.731469767786535,
      "grad_norm": 4.156976222991943,
      "learning_rate": 2.13546474698285e-05,
      "loss": 0.6968,
      "step": 541400
    },
    {
      "epoch": 5.731999089566538,
      "grad_norm": 4.003169536590576,
      "learning_rate": 2.135200084691933e-05,
      "loss": 0.6994,
      "step": 541450
    },
    {
      "epoch": 5.732528411346542,
      "grad_norm": 4.50614595413208,
      "learning_rate": 2.1349354224010165e-05,
      "loss": 0.6953,
      "step": 541500
    },
    {
      "epoch": 5.732528411346542,
      "eval_loss": 0.4489052891731262,
      "eval_runtime": 46.9523,
      "eval_samples_per_second": 3576.609,
      "eval_steps_per_second": 447.092,
      "step": 541500
    },
    {
      "epoch": 5.733057733126545,
      "grad_norm": 4.243494033813477,
      "learning_rate": 2.1346707601100996e-05,
      "loss": 0.71,
      "step": 541550
    },
    {
      "epoch": 5.733587054906549,
      "grad_norm": 4.011244773864746,
      "learning_rate": 2.134406097819183e-05,
      "loss": 0.689,
      "step": 541600
    },
    {
      "epoch": 5.7341163766865515,
      "grad_norm": 4.1726884841918945,
      "learning_rate": 2.134141435528266e-05,
      "loss": 0.7034,
      "step": 541650
    },
    {
      "epoch": 5.734645698466554,
      "grad_norm": 4.309797763824463,
      "learning_rate": 2.1338767732373495e-05,
      "loss": 0.6861,
      "step": 541700
    },
    {
      "epoch": 5.735175020246558,
      "grad_norm": 4.067887306213379,
      "learning_rate": 2.1336121109464326e-05,
      "loss": 0.6961,
      "step": 541750
    },
    {
      "epoch": 5.735704342026561,
      "grad_norm": 3.951478958129883,
      "learning_rate": 2.1333474486555156e-05,
      "loss": 0.6891,
      "step": 541800
    },
    {
      "epoch": 5.736233663806565,
      "grad_norm": 4.442509651184082,
      "learning_rate": 2.1330827863645987e-05,
      "loss": 0.7007,
      "step": 541850
    },
    {
      "epoch": 5.736762985586568,
      "grad_norm": 3.7140326499938965,
      "learning_rate": 2.132818124073682e-05,
      "loss": 0.6823,
      "step": 541900
    },
    {
      "epoch": 5.737292307366571,
      "grad_norm": 4.191184997558594,
      "learning_rate": 2.1325534617827652e-05,
      "loss": 0.6938,
      "step": 541950
    },
    {
      "epoch": 5.737821629146574,
      "grad_norm": 3.705794095993042,
      "learning_rate": 2.1322887994918486e-05,
      "loss": 0.6994,
      "step": 542000
    },
    {
      "epoch": 5.737821629146574,
      "eval_loss": 0.45256757736206055,
      "eval_runtime": 46.8748,
      "eval_samples_per_second": 3582.521,
      "eval_steps_per_second": 447.831,
      "step": 542000
    },
    {
      "epoch": 5.738350950926578,
      "grad_norm": 4.22814416885376,
      "learning_rate": 2.1320241372009317e-05,
      "loss": 0.6896,
      "step": 542050
    },
    {
      "epoch": 5.738880272706581,
      "grad_norm": 4.383349418640137,
      "learning_rate": 2.131759474910015e-05,
      "loss": 0.6976,
      "step": 542100
    },
    {
      "epoch": 5.739409594486585,
      "grad_norm": 4.28604793548584,
      "learning_rate": 2.131494812619098e-05,
      "loss": 0.6838,
      "step": 542150
    },
    {
      "epoch": 5.7399389162665875,
      "grad_norm": 3.9067366123199463,
      "learning_rate": 2.1312301503281816e-05,
      "loss": 0.7031,
      "step": 542200
    },
    {
      "epoch": 5.740468238046591,
      "grad_norm": 4.5402913093566895,
      "learning_rate": 2.1309654880372646e-05,
      "loss": 0.6944,
      "step": 542250
    },
    {
      "epoch": 5.740997559826594,
      "grad_norm": 4.178824424743652,
      "learning_rate": 2.130700825746348e-05,
      "loss": 0.7062,
      "step": 542300
    },
    {
      "epoch": 5.741526881606598,
      "grad_norm": 4.151401042938232,
      "learning_rate": 2.130436163455431e-05,
      "loss": 0.7058,
      "step": 542350
    },
    {
      "epoch": 5.742056203386601,
      "grad_norm": 4.235154151916504,
      "learning_rate": 2.1301715011645142e-05,
      "loss": 0.6959,
      "step": 542400
    },
    {
      "epoch": 5.742585525166604,
      "grad_norm": 4.196929931640625,
      "learning_rate": 2.1299068388735973e-05,
      "loss": 0.6993,
      "step": 542450
    },
    {
      "epoch": 5.743114846946607,
      "grad_norm": 4.184237957000732,
      "learning_rate": 2.1296421765826807e-05,
      "loss": 0.6947,
      "step": 542500
    },
    {
      "epoch": 5.743114846946607,
      "eval_loss": 0.44940075278282166,
      "eval_runtime": 46.8367,
      "eval_samples_per_second": 3585.438,
      "eval_steps_per_second": 448.196,
      "step": 542500
    },
    {
      "epoch": 5.74364416872661,
      "grad_norm": 4.2548675537109375,
      "learning_rate": 2.1293775142917637e-05,
      "loss": 0.692,
      "step": 542550
    },
    {
      "epoch": 5.744173490506614,
      "grad_norm": 4.250415325164795,
      "learning_rate": 2.129112852000847e-05,
      "loss": 0.6945,
      "step": 542600
    },
    {
      "epoch": 5.744702812286617,
      "grad_norm": 4.310653209686279,
      "learning_rate": 2.1288481897099302e-05,
      "loss": 0.6922,
      "step": 542650
    },
    {
      "epoch": 5.745232134066621,
      "grad_norm": 4.125646591186523,
      "learning_rate": 2.1285835274190136e-05,
      "loss": 0.702,
      "step": 542700
    },
    {
      "epoch": 5.7457614558466235,
      "grad_norm": 4.215859889984131,
      "learning_rate": 2.1283188651280967e-05,
      "loss": 0.6864,
      "step": 542750
    },
    {
      "epoch": 5.746290777626627,
      "grad_norm": 4.645349025726318,
      "learning_rate": 2.12805420283718e-05,
      "loss": 0.7008,
      "step": 542800
    },
    {
      "epoch": 5.74682009940663,
      "grad_norm": 4.089481353759766,
      "learning_rate": 2.1277895405462632e-05,
      "loss": 0.6889,
      "step": 542850
    },
    {
      "epoch": 5.747349421186634,
      "grad_norm": 4.370334625244141,
      "learning_rate": 2.1275248782553463e-05,
      "loss": 0.7001,
      "step": 542900
    },
    {
      "epoch": 5.747878742966637,
      "grad_norm": 4.4070868492126465,
      "learning_rate": 2.1272655092102477e-05,
      "loss": 0.6903,
      "step": 542950
    },
    {
      "epoch": 5.7484080647466405,
      "grad_norm": 4.556572914123535,
      "learning_rate": 2.127000846919331e-05,
      "loss": 0.7012,
      "step": 543000
    },
    {
      "epoch": 5.7484080647466405,
      "eval_loss": 0.4500386714935303,
      "eval_runtime": 46.8841,
      "eval_samples_per_second": 3581.808,
      "eval_steps_per_second": 447.742,
      "step": 543000
    },
    {
      "epoch": 5.748937386526643,
      "grad_norm": 4.260151386260986,
      "learning_rate": 2.1267361846284142e-05,
      "loss": 0.7006,
      "step": 543050
    },
    {
      "epoch": 5.749466708306647,
      "grad_norm": 3.9455833435058594,
      "learning_rate": 2.1264715223374976e-05,
      "loss": 0.7108,
      "step": 543100
    },
    {
      "epoch": 5.74999603008665,
      "grad_norm": 4.10948371887207,
      "learning_rate": 2.1262068600465807e-05,
      "loss": 0.6962,
      "step": 543150
    },
    {
      "epoch": 5.750525351866653,
      "grad_norm": 4.041234970092773,
      "learning_rate": 2.125942197755664e-05,
      "loss": 0.7053,
      "step": 543200
    },
    {
      "epoch": 5.751054673646657,
      "grad_norm": 4.517321586608887,
      "learning_rate": 2.125677535464747e-05,
      "loss": 0.691,
      "step": 543250
    },
    {
      "epoch": 5.751583995426659,
      "grad_norm": 4.332218170166016,
      "learning_rate": 2.1254128731738306e-05,
      "loss": 0.6822,
      "step": 543300
    },
    {
      "epoch": 5.752113317206663,
      "grad_norm": 4.156901836395264,
      "learning_rate": 2.1251482108829136e-05,
      "loss": 0.6921,
      "step": 543350
    },
    {
      "epoch": 5.752642638986666,
      "grad_norm": 4.583972930908203,
      "learning_rate": 2.1248835485919967e-05,
      "loss": 0.7007,
      "step": 543400
    },
    {
      "epoch": 5.75317196076667,
      "grad_norm": 4.4981794357299805,
      "learning_rate": 2.1246188863010798e-05,
      "loss": 0.693,
      "step": 543450
    },
    {
      "epoch": 5.753701282546673,
      "grad_norm": 4.569093227386475,
      "learning_rate": 2.1243542240101632e-05,
      "loss": 0.7064,
      "step": 543500
    },
    {
      "epoch": 5.753701282546673,
      "eval_loss": 0.4496002793312073,
      "eval_runtime": 47.0945,
      "eval_samples_per_second": 3565.813,
      "eval_steps_per_second": 445.743,
      "step": 543500
    },
    {
      "epoch": 5.754230604326676,
      "grad_norm": 4.2712602615356445,
      "learning_rate": 2.1240895617192463e-05,
      "loss": 0.6998,
      "step": 543550
    },
    {
      "epoch": 5.754759926106679,
      "grad_norm": 4.82505464553833,
      "learning_rate": 2.1238248994283297e-05,
      "loss": 0.6904,
      "step": 543600
    },
    {
      "epoch": 5.755289247886683,
      "grad_norm": 4.3676276206970215,
      "learning_rate": 2.1235602371374128e-05,
      "loss": 0.6834,
      "step": 543650
    },
    {
      "epoch": 5.755818569666686,
      "grad_norm": 4.695195198059082,
      "learning_rate": 2.123295574846496e-05,
      "loss": 0.6928,
      "step": 543700
    },
    {
      "epoch": 5.75634789144669,
      "grad_norm": 4.262084007263184,
      "learning_rate": 2.1230309125555792e-05,
      "loss": 0.7049,
      "step": 543750
    },
    {
      "epoch": 5.7568772132266925,
      "grad_norm": 4.56282377243042,
      "learning_rate": 2.1227662502646626e-05,
      "loss": 0.6931,
      "step": 543800
    },
    {
      "epoch": 5.757406535006696,
      "grad_norm": 4.497783660888672,
      "learning_rate": 2.1225015879737457e-05,
      "loss": 0.7014,
      "step": 543850
    },
    {
      "epoch": 5.757935856786699,
      "grad_norm": 4.119061470031738,
      "learning_rate": 2.1222369256828288e-05,
      "loss": 0.7111,
      "step": 543900
    },
    {
      "epoch": 5.758465178566702,
      "grad_norm": 4.384277820587158,
      "learning_rate": 2.121972263391912e-05,
      "loss": 0.6937,
      "step": 543950
    },
    {
      "epoch": 5.758994500346706,
      "grad_norm": 4.427388668060303,
      "learning_rate": 2.1217076011009953e-05,
      "loss": 0.7025,
      "step": 544000
    },
    {
      "epoch": 5.758994500346706,
      "eval_loss": 0.44903865456581116,
      "eval_runtime": 46.9006,
      "eval_samples_per_second": 3580.55,
      "eval_steps_per_second": 447.585,
      "step": 544000
    },
    {
      "epoch": 5.7595238221267095,
      "grad_norm": 4.089337348937988,
      "learning_rate": 2.1214429388100783e-05,
      "loss": 0.6945,
      "step": 544050
    },
    {
      "epoch": 5.760053143906712,
      "grad_norm": 4.232778072357178,
      "learning_rate": 2.1211782765191617e-05,
      "loss": 0.7011,
      "step": 544100
    },
    {
      "epoch": 5.760582465686715,
      "grad_norm": 4.026824951171875,
      "learning_rate": 2.1209136142282448e-05,
      "loss": 0.6912,
      "step": 544150
    },
    {
      "epoch": 5.761111787466719,
      "grad_norm": 4.605881690979004,
      "learning_rate": 2.120648951937328e-05,
      "loss": 0.6984,
      "step": 544200
    },
    {
      "epoch": 5.761641109246722,
      "grad_norm": 4.307197570800781,
      "learning_rate": 2.1203842896464113e-05,
      "loss": 0.697,
      "step": 544250
    },
    {
      "epoch": 5.762170431026726,
      "grad_norm": 4.654695987701416,
      "learning_rate": 2.1201196273554944e-05,
      "loss": 0.7015,
      "step": 544300
    },
    {
      "epoch": 5.7626997528067285,
      "grad_norm": 3.9955875873565674,
      "learning_rate": 2.1198549650645778e-05,
      "loss": 0.6817,
      "step": 544350
    },
    {
      "epoch": 5.763229074586732,
      "grad_norm": 4.14860725402832,
      "learning_rate": 2.119590302773661e-05,
      "loss": 0.6898,
      "step": 544400
    },
    {
      "epoch": 5.763758396366735,
      "grad_norm": 4.467089653015137,
      "learning_rate": 2.1193256404827443e-05,
      "loss": 0.6895,
      "step": 544450
    },
    {
      "epoch": 5.764287718146739,
      "grad_norm": 3.7830891609191895,
      "learning_rate": 2.1190609781918273e-05,
      "loss": 0.6865,
      "step": 544500
    },
    {
      "epoch": 5.764287718146739,
      "eval_loss": 0.4495043456554413,
      "eval_runtime": 46.7411,
      "eval_samples_per_second": 3592.773,
      "eval_steps_per_second": 449.113,
      "step": 544500
    },
    {
      "epoch": 5.764817039926742,
      "grad_norm": 4.007659912109375,
      "learning_rate": 2.1187963159009104e-05,
      "loss": 0.6914,
      "step": 544550
    },
    {
      "epoch": 5.7653463617067455,
      "grad_norm": 4.434635162353516,
      "learning_rate": 2.1185316536099935e-05,
      "loss": 0.7026,
      "step": 544600
    },
    {
      "epoch": 5.765875683486748,
      "grad_norm": 4.443460941314697,
      "learning_rate": 2.118266991319077e-05,
      "loss": 0.6875,
      "step": 544650
    },
    {
      "epoch": 5.766405005266751,
      "grad_norm": 4.509347438812256,
      "learning_rate": 2.11800232902816e-05,
      "loss": 0.6917,
      "step": 544700
    },
    {
      "epoch": 5.766934327046755,
      "grad_norm": 3.9896414279937744,
      "learning_rate": 2.1177376667372434e-05,
      "loss": 0.6883,
      "step": 544750
    },
    {
      "epoch": 5.767463648826759,
      "grad_norm": 4.586398124694824,
      "learning_rate": 2.1174730044463264e-05,
      "loss": 0.6892,
      "step": 544800
    },
    {
      "epoch": 5.767992970606762,
      "grad_norm": 4.233164310455322,
      "learning_rate": 2.11720834215541e-05,
      "loss": 0.6932,
      "step": 544850
    },
    {
      "epoch": 5.7685222923867645,
      "grad_norm": 4.2587385177612305,
      "learning_rate": 2.116943679864493e-05,
      "loss": 0.6994,
      "step": 544900
    },
    {
      "epoch": 5.769051614166768,
      "grad_norm": 4.2161455154418945,
      "learning_rate": 2.1166790175735763e-05,
      "loss": 0.7027,
      "step": 544950
    },
    {
      "epoch": 5.769580935946771,
      "grad_norm": 4.6769022941589355,
      "learning_rate": 2.1164196485284775e-05,
      "loss": 0.7014,
      "step": 545000
    },
    {
      "epoch": 5.769580935946771,
      "eval_loss": 0.44815412163734436,
      "eval_runtime": 46.8441,
      "eval_samples_per_second": 3584.867,
      "eval_steps_per_second": 448.124,
      "step": 545000
    },
    {
      "epoch": 5.770110257726775,
      "grad_norm": 4.2164130210876465,
      "learning_rate": 2.116154986237561e-05,
      "loss": 0.695,
      "step": 545050
    },
    {
      "epoch": 5.770639579506778,
      "grad_norm": 4.239665985107422,
      "learning_rate": 2.115890323946644e-05,
      "loss": 0.6961,
      "step": 545100
    },
    {
      "epoch": 5.7711689012867815,
      "grad_norm": 4.624140739440918,
      "learning_rate": 2.1156256616557274e-05,
      "loss": 0.6908,
      "step": 545150
    },
    {
      "epoch": 5.771698223066784,
      "grad_norm": 4.186965465545654,
      "learning_rate": 2.1153609993648104e-05,
      "loss": 0.6921,
      "step": 545200
    },
    {
      "epoch": 5.772227544846788,
      "grad_norm": 4.254047393798828,
      "learning_rate": 2.115096337073894e-05,
      "loss": 0.6932,
      "step": 545250
    },
    {
      "epoch": 5.772756866626791,
      "grad_norm": 4.698916912078857,
      "learning_rate": 2.114831674782977e-05,
      "loss": 0.6948,
      "step": 545300
    },
    {
      "epoch": 5.773286188406795,
      "grad_norm": 4.5642242431640625,
      "learning_rate": 2.1145670124920603e-05,
      "loss": 0.6971,
      "step": 545350
    },
    {
      "epoch": 5.773815510186798,
      "grad_norm": 4.769505023956299,
      "learning_rate": 2.1143023502011434e-05,
      "loss": 0.6879,
      "step": 545400
    },
    {
      "epoch": 5.7743448319668005,
      "grad_norm": 4.017345428466797,
      "learning_rate": 2.1140376879102268e-05,
      "loss": 0.6966,
      "step": 545450
    },
    {
      "epoch": 5.774874153746804,
      "grad_norm": 4.045660018920898,
      "learning_rate": 2.113778318865128e-05,
      "loss": 0.6933,
      "step": 545500
    },
    {
      "epoch": 5.774874153746804,
      "eval_loss": 0.4489800035953522,
      "eval_runtime": 46.8182,
      "eval_samples_per_second": 3586.852,
      "eval_steps_per_second": 448.372,
      "step": 545500
    },
    {
      "epoch": 5.775403475526808,
      "grad_norm": 4.361175537109375,
      "learning_rate": 2.1135136565742113e-05,
      "loss": 0.719,
      "step": 545550
    },
    {
      "epoch": 5.775932797306811,
      "grad_norm": 4.525028228759766,
      "learning_rate": 2.1132489942832944e-05,
      "loss": 0.6895,
      "step": 545600
    },
    {
      "epoch": 5.776462119086814,
      "grad_norm": 4.347797393798828,
      "learning_rate": 2.1129843319923778e-05,
      "loss": 0.7082,
      "step": 545650
    },
    {
      "epoch": 5.7769914408668175,
      "grad_norm": 4.272747993469238,
      "learning_rate": 2.112719669701461e-05,
      "loss": 0.6952,
      "step": 545700
    },
    {
      "epoch": 5.77752076264682,
      "grad_norm": 4.118154048919678,
      "learning_rate": 2.1124550074105443e-05,
      "loss": 0.6835,
      "step": 545750
    },
    {
      "epoch": 5.778050084426824,
      "grad_norm": 4.329954624176025,
      "learning_rate": 2.1121903451196274e-05,
      "loss": 0.7018,
      "step": 545800
    },
    {
      "epoch": 5.778579406206827,
      "grad_norm": 4.545809745788574,
      "learning_rate": 2.1119256828287108e-05,
      "loss": 0.6958,
      "step": 545850
    },
    {
      "epoch": 5.779108727986831,
      "grad_norm": 4.3052754402160645,
      "learning_rate": 2.111661020537794e-05,
      "loss": 0.6953,
      "step": 545900
    },
    {
      "epoch": 5.779638049766834,
      "grad_norm": 4.308632850646973,
      "learning_rate": 2.1113963582468773e-05,
      "loss": 0.7206,
      "step": 545950
    },
    {
      "epoch": 5.780167371546837,
      "grad_norm": 4.371015548706055,
      "learning_rate": 2.1111316959559603e-05,
      "loss": 0.7026,
      "step": 546000
    },
    {
      "epoch": 5.780167371546837,
      "eval_loss": 0.44898658990859985,
      "eval_runtime": 47.2065,
      "eval_samples_per_second": 3557.349,
      "eval_steps_per_second": 444.685,
      "step": 546000
    },
    {
      "epoch": 5.78069669332684,
      "grad_norm": 3.996034622192383,
      "learning_rate": 2.1108670336650434e-05,
      "loss": 0.7058,
      "step": 546050
    },
    {
      "epoch": 5.781226015106844,
      "grad_norm": 5.020799160003662,
      "learning_rate": 2.1106023713741265e-05,
      "loss": 0.7045,
      "step": 546100
    },
    {
      "epoch": 5.781755336886847,
      "grad_norm": 4.530641555786133,
      "learning_rate": 2.11033770908321e-05,
      "loss": 0.695,
      "step": 546150
    },
    {
      "epoch": 5.78228465866685,
      "grad_norm": 4.219956398010254,
      "learning_rate": 2.110073046792293e-05,
      "loss": 0.7013,
      "step": 546200
    },
    {
      "epoch": 5.7828139804468535,
      "grad_norm": 4.21819543838501,
      "learning_rate": 2.1098083845013764e-05,
      "loss": 0.6962,
      "step": 546250
    },
    {
      "epoch": 5.783343302226857,
      "grad_norm": 4.4727678298950195,
      "learning_rate": 2.1095437222104594e-05,
      "loss": 0.6925,
      "step": 546300
    },
    {
      "epoch": 5.78387262400686,
      "grad_norm": 4.366265773773193,
      "learning_rate": 2.109279059919543e-05,
      "loss": 0.6984,
      "step": 546350
    },
    {
      "epoch": 5.784401945786863,
      "grad_norm": 4.0764546394348145,
      "learning_rate": 2.109014397628626e-05,
      "loss": 0.6873,
      "step": 546400
    },
    {
      "epoch": 5.784931267566867,
      "grad_norm": 4.421458721160889,
      "learning_rate": 2.1087497353377093e-05,
      "loss": 0.6903,
      "step": 546450
    },
    {
      "epoch": 5.78546058934687,
      "grad_norm": 4.646646499633789,
      "learning_rate": 2.1084850730467924e-05,
      "loss": 0.7005,
      "step": 546500
    },
    {
      "epoch": 5.78546058934687,
      "eval_loss": 0.44861429929733276,
      "eval_runtime": 47.3713,
      "eval_samples_per_second": 3544.977,
      "eval_steps_per_second": 443.138,
      "step": 546500
    },
    {
      "epoch": 5.785989911126873,
      "grad_norm": 4.3225555419921875,
      "learning_rate": 2.1082204107558755e-05,
      "loss": 0.6992,
      "step": 546550
    },
    {
      "epoch": 5.786519232906876,
      "grad_norm": 4.528989315032959,
      "learning_rate": 2.1079557484649585e-05,
      "loss": 0.6984,
      "step": 546600
    },
    {
      "epoch": 5.78704855468688,
      "grad_norm": 4.742319583892822,
      "learning_rate": 2.107691086174042e-05,
      "loss": 0.6994,
      "step": 546650
    },
    {
      "epoch": 5.787577876466883,
      "grad_norm": 4.255844593048096,
      "learning_rate": 2.107426423883125e-05,
      "loss": 0.6941,
      "step": 546700
    },
    {
      "epoch": 5.788107198246887,
      "grad_norm": 4.34743070602417,
      "learning_rate": 2.1071617615922084e-05,
      "loss": 0.6931,
      "step": 546750
    },
    {
      "epoch": 5.788636520026889,
      "grad_norm": 3.8048861026763916,
      "learning_rate": 2.1068970993012915e-05,
      "loss": 0.6903,
      "step": 546800
    },
    {
      "epoch": 5.789165841806893,
      "grad_norm": 4.715765476226807,
      "learning_rate": 2.106632437010375e-05,
      "loss": 0.6955,
      "step": 546850
    },
    {
      "epoch": 5.789695163586896,
      "grad_norm": 4.687858581542969,
      "learning_rate": 2.106367774719458e-05,
      "loss": 0.7019,
      "step": 546900
    },
    {
      "epoch": 5.790224485366899,
      "grad_norm": 4.247631549835205,
      "learning_rate": 2.1061031124285414e-05,
      "loss": 0.6995,
      "step": 546950
    },
    {
      "epoch": 5.790753807146903,
      "grad_norm": 4.6073994636535645,
      "learning_rate": 2.1058384501376245e-05,
      "loss": 0.7046,
      "step": 547000
    },
    {
      "epoch": 5.790753807146903,
      "eval_loss": 0.4489539861679077,
      "eval_runtime": 46.8132,
      "eval_samples_per_second": 3587.235,
      "eval_steps_per_second": 448.42,
      "step": 547000
    },
    {
      "epoch": 5.791283128926906,
      "grad_norm": 4.612892150878906,
      "learning_rate": 2.105573787846708e-05,
      "loss": 0.699,
      "step": 547050
    },
    {
      "epoch": 5.791812450706909,
      "grad_norm": 3.8533694744110107,
      "learning_rate": 2.105309125555791e-05,
      "loss": 0.6928,
      "step": 547100
    },
    {
      "epoch": 5.792341772486912,
      "grad_norm": 4.669111728668213,
      "learning_rate": 2.105044463264874e-05,
      "loss": 0.6901,
      "step": 547150
    },
    {
      "epoch": 5.792871094266916,
      "grad_norm": 4.70451545715332,
      "learning_rate": 2.104779800973957e-05,
      "loss": 0.6964,
      "step": 547200
    },
    {
      "epoch": 5.793400416046919,
      "grad_norm": 4.227692127227783,
      "learning_rate": 2.1045151386830405e-05,
      "loss": 0.6917,
      "step": 547250
    },
    {
      "epoch": 5.7939297378269226,
      "grad_norm": 4.366464614868164,
      "learning_rate": 2.1042504763921236e-05,
      "loss": 0.7075,
      "step": 547300
    },
    {
      "epoch": 5.794459059606925,
      "grad_norm": 4.34570837020874,
      "learning_rate": 2.103985814101207e-05,
      "loss": 0.714,
      "step": 547350
    },
    {
      "epoch": 5.794988381386929,
      "grad_norm": 4.007303714752197,
      "learning_rate": 2.10372115181029e-05,
      "loss": 0.7011,
      "step": 547400
    },
    {
      "epoch": 5.795517703166932,
      "grad_norm": 4.168308258056641,
      "learning_rate": 2.1034564895193735e-05,
      "loss": 0.7008,
      "step": 547450
    },
    {
      "epoch": 5.796047024946936,
      "grad_norm": 4.592828750610352,
      "learning_rate": 2.1031918272284565e-05,
      "loss": 0.6993,
      "step": 547500
    },
    {
      "epoch": 5.796047024946936,
      "eval_loss": 0.44867703318595886,
      "eval_runtime": 46.7936,
      "eval_samples_per_second": 3588.739,
      "eval_steps_per_second": 448.608,
      "step": 547500
    },
    {
      "epoch": 5.796576346726939,
      "grad_norm": 4.255037784576416,
      "learning_rate": 2.10292716493754e-05,
      "loss": 0.6908,
      "step": 547550
    },
    {
      "epoch": 5.797105668506942,
      "grad_norm": 4.469661235809326,
      "learning_rate": 2.102662502646623e-05,
      "loss": 0.7027,
      "step": 547600
    },
    {
      "epoch": 5.797634990286945,
      "grad_norm": 4.502397537231445,
      "learning_rate": 2.102397840355706e-05,
      "loss": 0.7034,
      "step": 547650
    },
    {
      "epoch": 5.798164312066948,
      "grad_norm": 4.919874668121338,
      "learning_rate": 2.102133178064789e-05,
      "loss": 0.6978,
      "step": 547700
    },
    {
      "epoch": 5.798693633846952,
      "grad_norm": 4.627314567565918,
      "learning_rate": 2.1018685157738726e-05,
      "loss": 0.7043,
      "step": 547750
    },
    {
      "epoch": 5.799222955626956,
      "grad_norm": 4.087690830230713,
      "learning_rate": 2.1016038534829556e-05,
      "loss": 0.6922,
      "step": 547800
    },
    {
      "epoch": 5.7997522774069585,
      "grad_norm": 4.491491317749023,
      "learning_rate": 2.101339191192039e-05,
      "loss": 0.7033,
      "step": 547850
    },
    {
      "epoch": 5.800281599186961,
      "grad_norm": 4.263375282287598,
      "learning_rate": 2.101074528901122e-05,
      "loss": 0.6977,
      "step": 547900
    },
    {
      "epoch": 5.800810920966965,
      "grad_norm": 4.5189290046691895,
      "learning_rate": 2.1008098666102055e-05,
      "loss": 0.7003,
      "step": 547950
    },
    {
      "epoch": 5.801340242746968,
      "grad_norm": 4.505908489227295,
      "learning_rate": 2.1005452043192886e-05,
      "loss": 0.6972,
      "step": 548000
    },
    {
      "epoch": 5.801340242746968,
      "eval_loss": 0.44894930720329285,
      "eval_runtime": 46.8902,
      "eval_samples_per_second": 3581.348,
      "eval_steps_per_second": 447.684,
      "step": 548000
    },
    {
      "epoch": 5.801869564526972,
      "grad_norm": 4.547762870788574,
      "learning_rate": 2.100280542028372e-05,
      "loss": 0.6999,
      "step": 548050
    },
    {
      "epoch": 5.802398886306975,
      "grad_norm": 4.38067102432251,
      "learning_rate": 2.100015879737455e-05,
      "loss": 0.6959,
      "step": 548100
    },
    {
      "epoch": 5.802928208086978,
      "grad_norm": 4.109218120574951,
      "learning_rate": 2.0997512174465385e-05,
      "loss": 0.6915,
      "step": 548150
    },
    {
      "epoch": 5.803457529866981,
      "grad_norm": 4.25654411315918,
      "learning_rate": 2.0994865551556216e-05,
      "loss": 0.6948,
      "step": 548200
    },
    {
      "epoch": 5.803986851646985,
      "grad_norm": 4.164346694946289,
      "learning_rate": 2.0992218928647046e-05,
      "loss": 0.6919,
      "step": 548250
    },
    {
      "epoch": 5.804516173426988,
      "grad_norm": 4.537709712982178,
      "learning_rate": 2.0989572305737877e-05,
      "loss": 0.6949,
      "step": 548300
    },
    {
      "epoch": 5.805045495206992,
      "grad_norm": 3.882741689682007,
      "learning_rate": 2.098692568282871e-05,
      "loss": 0.6889,
      "step": 548350
    },
    {
      "epoch": 5.8055748169869945,
      "grad_norm": 4.133090972900391,
      "learning_rate": 2.0984279059919542e-05,
      "loss": 0.7042,
      "step": 548400
    },
    {
      "epoch": 5.806104138766997,
      "grad_norm": 3.7170636653900146,
      "learning_rate": 2.0981632437010376e-05,
      "loss": 0.6947,
      "step": 548450
    },
    {
      "epoch": 5.806633460547001,
      "grad_norm": 4.321393013000488,
      "learning_rate": 2.0978985814101207e-05,
      "loss": 0.6856,
      "step": 548500
    },
    {
      "epoch": 5.806633460547001,
      "eval_loss": 0.4482993185520172,
      "eval_runtime": 46.8466,
      "eval_samples_per_second": 3584.676,
      "eval_steps_per_second": 448.101,
      "step": 548500
    },
    {
      "epoch": 5.807162782327005,
      "grad_norm": 4.463319301605225,
      "learning_rate": 2.097633919119204e-05,
      "loss": 0.6961,
      "step": 548550
    },
    {
      "epoch": 5.807692104107008,
      "grad_norm": 3.904905319213867,
      "learning_rate": 2.097369256828287e-05,
      "loss": 0.6985,
      "step": 548600
    },
    {
      "epoch": 5.808221425887011,
      "grad_norm": 3.8798913955688477,
      "learning_rate": 2.0971045945373706e-05,
      "loss": 0.6961,
      "step": 548650
    },
    {
      "epoch": 5.808750747667014,
      "grad_norm": 4.669574737548828,
      "learning_rate": 2.0968399322464536e-05,
      "loss": 0.7094,
      "step": 548700
    },
    {
      "epoch": 5.809280069447017,
      "grad_norm": 4.473383903503418,
      "learning_rate": 2.096575269955537e-05,
      "loss": 0.7034,
      "step": 548750
    },
    {
      "epoch": 5.809809391227021,
      "grad_norm": 3.9594740867614746,
      "learning_rate": 2.09631060766462e-05,
      "loss": 0.6892,
      "step": 548800
    },
    {
      "epoch": 5.810338713007024,
      "grad_norm": 4.617635726928711,
      "learning_rate": 2.0960459453737032e-05,
      "loss": 0.6953,
      "step": 548850
    },
    {
      "epoch": 5.810868034787028,
      "grad_norm": 4.267827033996582,
      "learning_rate": 2.0957812830827863e-05,
      "loss": 0.6897,
      "step": 548900
    },
    {
      "epoch": 5.8113973565670305,
      "grad_norm": 4.212303161621094,
      "learning_rate": 2.0955166207918697e-05,
      "loss": 0.6992,
      "step": 548950
    },
    {
      "epoch": 5.811926678347034,
      "grad_norm": 4.386004447937012,
      "learning_rate": 2.0952519585009527e-05,
      "loss": 0.6938,
      "step": 549000
    },
    {
      "epoch": 5.811926678347034,
      "eval_loss": 0.4490458369255066,
      "eval_runtime": 46.8159,
      "eval_samples_per_second": 3587.028,
      "eval_steps_per_second": 448.395,
      "step": 549000
    },
    {
      "epoch": 5.812456000127037,
      "grad_norm": 4.367464065551758,
      "learning_rate": 2.094987296210036e-05,
      "loss": 0.706,
      "step": 549050
    },
    {
      "epoch": 5.812985321907041,
      "grad_norm": 4.221211910247803,
      "learning_rate": 2.0947226339191192e-05,
      "loss": 0.6881,
      "step": 549100
    },
    {
      "epoch": 5.813514643687044,
      "grad_norm": 4.4505181312561035,
      "learning_rate": 2.0944579716282026e-05,
      "loss": 0.7001,
      "step": 549150
    },
    {
      "epoch": 5.814043965467047,
      "grad_norm": 4.403186798095703,
      "learning_rate": 2.0941933093372857e-05,
      "loss": 0.6998,
      "step": 549200
    },
    {
      "epoch": 5.81457328724705,
      "grad_norm": 3.9926371574401855,
      "learning_rate": 2.093928647046369e-05,
      "loss": 0.6985,
      "step": 549250
    },
    {
      "epoch": 5.815102609027054,
      "grad_norm": 4.0149383544921875,
      "learning_rate": 2.0936639847554522e-05,
      "loss": 0.6989,
      "step": 549300
    },
    {
      "epoch": 5.815631930807057,
      "grad_norm": 4.899272918701172,
      "learning_rate": 2.0933993224645353e-05,
      "loss": 0.7112,
      "step": 549350
    },
    {
      "epoch": 5.81616125258706,
      "grad_norm": 4.529082775115967,
      "learning_rate": 2.0931346601736183e-05,
      "loss": 0.7003,
      "step": 549400
    },
    {
      "epoch": 5.816690574367064,
      "grad_norm": 4.689740180969238,
      "learning_rate": 2.0928699978827017e-05,
      "loss": 0.6974,
      "step": 549450
    },
    {
      "epoch": 5.8172198961470665,
      "grad_norm": 4.5384650230407715,
      "learning_rate": 2.0926106288376032e-05,
      "loss": 0.692,
      "step": 549500
    },
    {
      "epoch": 5.8172198961470665,
      "eval_loss": 0.44787880778312683,
      "eval_runtime": 46.9159,
      "eval_samples_per_second": 3579.38,
      "eval_steps_per_second": 447.439,
      "step": 549500
    },
    {
      "epoch": 5.81774921792707,
      "grad_norm": 4.59495735168457,
      "learning_rate": 2.0923459665466866e-05,
      "loss": 0.6923,
      "step": 549550
    },
    {
      "epoch": 5.818278539707073,
      "grad_norm": 4.3045125007629395,
      "learning_rate": 2.0920813042557697e-05,
      "loss": 0.6971,
      "step": 549600
    },
    {
      "epoch": 5.818807861487077,
      "grad_norm": 4.36256742477417,
      "learning_rate": 2.091816641964853e-05,
      "loss": 0.6953,
      "step": 549650
    },
    {
      "epoch": 5.81933718326708,
      "grad_norm": 4.496243476867676,
      "learning_rate": 2.091551979673936e-05,
      "loss": 0.6956,
      "step": 549700
    },
    {
      "epoch": 5.8198665050470835,
      "grad_norm": 4.295491695404053,
      "learning_rate": 2.0912873173830196e-05,
      "loss": 0.6898,
      "step": 549750
    },
    {
      "epoch": 5.820395826827086,
      "grad_norm": 4.405294418334961,
      "learning_rate": 2.0910226550921026e-05,
      "loss": 0.6888,
      "step": 549800
    },
    {
      "epoch": 5.82092514860709,
      "grad_norm": 4.609572410583496,
      "learning_rate": 2.0907579928011857e-05,
      "loss": 0.6904,
      "step": 549850
    },
    {
      "epoch": 5.821454470387093,
      "grad_norm": 4.534962177276611,
      "learning_rate": 2.0904933305102688e-05,
      "loss": 0.7058,
      "step": 549900
    },
    {
      "epoch": 5.821983792167096,
      "grad_norm": 4.60268497467041,
      "learning_rate": 2.0902286682193522e-05,
      "loss": 0.6923,
      "step": 549950
    },
    {
      "epoch": 5.8225131139471,
      "grad_norm": 4.112832069396973,
      "learning_rate": 2.0899640059284353e-05,
      "loss": 0.6925,
      "step": 550000
    },
    {
      "epoch": 5.8225131139471,
      "eval_loss": 0.44726768136024475,
      "eval_runtime": 46.7395,
      "eval_samples_per_second": 3592.895,
      "eval_steps_per_second": 449.128,
      "step": 550000
    },
    {
      "epoch": 5.823042435727103,
      "grad_norm": 4.785283088684082,
      "learning_rate": 2.0896993436375187e-05,
      "loss": 0.704,
      "step": 550050
    },
    {
      "epoch": 5.823571757507106,
      "grad_norm": 4.627325534820557,
      "learning_rate": 2.0894346813466018e-05,
      "loss": 0.6955,
      "step": 550100
    },
    {
      "epoch": 5.824101079287109,
      "grad_norm": 4.416672229766846,
      "learning_rate": 2.089170019055685e-05,
      "loss": 0.7027,
      "step": 550150
    },
    {
      "epoch": 5.824630401067113,
      "grad_norm": 4.449058532714844,
      "learning_rate": 2.0889053567647682e-05,
      "loss": 0.7062,
      "step": 550200
    },
    {
      "epoch": 5.825159722847116,
      "grad_norm": 4.484542369842529,
      "learning_rate": 2.0886406944738516e-05,
      "loss": 0.6939,
      "step": 550250
    },
    {
      "epoch": 5.8256890446271195,
      "grad_norm": 4.366769313812256,
      "learning_rate": 2.0883760321829347e-05,
      "loss": 0.6932,
      "step": 550300
    },
    {
      "epoch": 5.826218366407122,
      "grad_norm": 4.739776134490967,
      "learning_rate": 2.0881166631378362e-05,
      "loss": 0.7,
      "step": 550350
    },
    {
      "epoch": 5.826747688187126,
      "grad_norm": 4.646728515625,
      "learning_rate": 2.0878520008469193e-05,
      "loss": 0.6901,
      "step": 550400
    },
    {
      "epoch": 5.827277009967129,
      "grad_norm": 4.038058280944824,
      "learning_rate": 2.0875873385560027e-05,
      "loss": 0.7048,
      "step": 550450
    },
    {
      "epoch": 5.827806331747133,
      "grad_norm": 4.145384788513184,
      "learning_rate": 2.0873226762650857e-05,
      "loss": 0.6963,
      "step": 550500
    },
    {
      "epoch": 5.827806331747133,
      "eval_loss": 0.4463199973106384,
      "eval_runtime": 46.7749,
      "eval_samples_per_second": 3590.171,
      "eval_steps_per_second": 448.787,
      "step": 550500
    },
    {
      "epoch": 5.828335653527136,
      "grad_norm": 4.325801372528076,
      "learning_rate": 2.087058013974169e-05,
      "loss": 0.7038,
      "step": 550550
    },
    {
      "epoch": 5.828864975307139,
      "grad_norm": 4.397915840148926,
      "learning_rate": 2.0867933516832522e-05,
      "loss": 0.7028,
      "step": 550600
    },
    {
      "epoch": 5.829394297087142,
      "grad_norm": 4.474059104919434,
      "learning_rate": 2.0865286893923356e-05,
      "loss": 0.6954,
      "step": 550650
    },
    {
      "epoch": 5.829923618867145,
      "grad_norm": 4.493392467498779,
      "learning_rate": 2.0862640271014187e-05,
      "loss": 0.6981,
      "step": 550700
    },
    {
      "epoch": 5.830452940647149,
      "grad_norm": 4.027388095855713,
      "learning_rate": 2.085999364810502e-05,
      "loss": 0.7021,
      "step": 550750
    },
    {
      "epoch": 5.830982262427153,
      "grad_norm": 4.433525562286377,
      "learning_rate": 2.0857347025195852e-05,
      "loss": 0.7025,
      "step": 550800
    },
    {
      "epoch": 5.831511584207155,
      "grad_norm": 4.319886684417725,
      "learning_rate": 2.0854700402286683e-05,
      "loss": 0.6952,
      "step": 550850
    },
    {
      "epoch": 5.832040905987158,
      "grad_norm": 4.511551856994629,
      "learning_rate": 2.0852053779377513e-05,
      "loss": 0.6885,
      "step": 550900
    },
    {
      "epoch": 5.832570227767162,
      "grad_norm": 4.438395023345947,
      "learning_rate": 2.0849407156468347e-05,
      "loss": 0.6849,
      "step": 550950
    },
    {
      "epoch": 5.833099549547165,
      "grad_norm": 4.615546226501465,
      "learning_rate": 2.0846760533559178e-05,
      "loss": 0.6908,
      "step": 551000
    },
    {
      "epoch": 5.833099549547165,
      "eval_loss": 0.4463675022125244,
      "eval_runtime": 46.7741,
      "eval_samples_per_second": 3590.237,
      "eval_steps_per_second": 448.796,
      "step": 551000
    },
    {
      "epoch": 5.833628871327169,
      "grad_norm": 4.440452575683594,
      "learning_rate": 2.0844113910650012e-05,
      "loss": 0.6936,
      "step": 551050
    },
    {
      "epoch": 5.8341581931071715,
      "grad_norm": 4.44721794128418,
      "learning_rate": 2.0841467287740843e-05,
      "loss": 0.7056,
      "step": 551100
    },
    {
      "epoch": 5.834687514887175,
      "grad_norm": 4.474375247955322,
      "learning_rate": 2.0838820664831677e-05,
      "loss": 0.6909,
      "step": 551150
    },
    {
      "epoch": 5.835216836667178,
      "grad_norm": 4.308577537536621,
      "learning_rate": 2.0836174041922508e-05,
      "loss": 0.6982,
      "step": 551200
    },
    {
      "epoch": 5.835746158447182,
      "grad_norm": 4.6367411613464355,
      "learning_rate": 2.0833527419013342e-05,
      "loss": 0.6863,
      "step": 551250
    },
    {
      "epoch": 5.836275480227185,
      "grad_norm": 4.188179016113281,
      "learning_rate": 2.0830880796104172e-05,
      "loss": 0.6931,
      "step": 551300
    },
    {
      "epoch": 5.8368048020071885,
      "grad_norm": 4.587961196899414,
      "learning_rate": 2.0828234173195003e-05,
      "loss": 0.6945,
      "step": 551350
    },
    {
      "epoch": 5.837334123787191,
      "grad_norm": 4.003058433532715,
      "learning_rate": 2.0825587550285834e-05,
      "loss": 0.7031,
      "step": 551400
    },
    {
      "epoch": 5.837863445567194,
      "grad_norm": 4.3453874588012695,
      "learning_rate": 2.0822940927376668e-05,
      "loss": 0.695,
      "step": 551450
    },
    {
      "epoch": 5.838392767347198,
      "grad_norm": 4.404419422149658,
      "learning_rate": 2.08202943044675e-05,
      "loss": 0.6796,
      "step": 551500
    },
    {
      "epoch": 5.838392767347198,
      "eval_loss": 0.44638633728027344,
      "eval_runtime": 46.7533,
      "eval_samples_per_second": 3591.833,
      "eval_steps_per_second": 448.995,
      "step": 551500
    },
    {
      "epoch": 5.838922089127202,
      "grad_norm": 4.774746894836426,
      "learning_rate": 2.0817647681558333e-05,
      "loss": 0.7131,
      "step": 551550
    },
    {
      "epoch": 5.839451410907205,
      "grad_norm": 4.26439905166626,
      "learning_rate": 2.0815001058649164e-05,
      "loss": 0.6957,
      "step": 551600
    },
    {
      "epoch": 5.8399807326872075,
      "grad_norm": 4.969426155090332,
      "learning_rate": 2.0812354435739998e-05,
      "loss": 0.686,
      "step": 551650
    },
    {
      "epoch": 5.840510054467211,
      "grad_norm": 4.5581889152526855,
      "learning_rate": 2.080970781283083e-05,
      "loss": 0.7128,
      "step": 551700
    },
    {
      "epoch": 5.841039376247214,
      "grad_norm": 4.30753755569458,
      "learning_rate": 2.0807061189921662e-05,
      "loss": 0.6966,
      "step": 551750
    },
    {
      "epoch": 5.841568698027218,
      "grad_norm": 4.625425338745117,
      "learning_rate": 2.0804414567012493e-05,
      "loss": 0.6949,
      "step": 551800
    },
    {
      "epoch": 5.842098019807221,
      "grad_norm": 4.4046454429626465,
      "learning_rate": 2.0801767944103327e-05,
      "loss": 0.6997,
      "step": 551850
    },
    {
      "epoch": 5.8426273415872245,
      "grad_norm": 4.444422721862793,
      "learning_rate": 2.0799121321194158e-05,
      "loss": 0.6908,
      "step": 551900
    },
    {
      "epoch": 5.843156663367227,
      "grad_norm": 4.335852146148682,
      "learning_rate": 2.079647469828499e-05,
      "loss": 0.6883,
      "step": 551950
    },
    {
      "epoch": 5.843685985147231,
      "grad_norm": 3.8847498893737793,
      "learning_rate": 2.079382807537582e-05,
      "loss": 0.6755,
      "step": 552000
    },
    {
      "epoch": 5.843685985147231,
      "eval_loss": 0.4461691081523895,
      "eval_runtime": 46.7351,
      "eval_samples_per_second": 3593.228,
      "eval_steps_per_second": 449.17,
      "step": 552000
    },
    {
      "epoch": 5.844215306927234,
      "grad_norm": 4.607968807220459,
      "learning_rate": 2.0791181452466653e-05,
      "loss": 0.6965,
      "step": 552050
    },
    {
      "epoch": 5.844744628707238,
      "grad_norm": 4.29742956161499,
      "learning_rate": 2.0788534829557484e-05,
      "loss": 0.6963,
      "step": 552100
    },
    {
      "epoch": 5.845273950487241,
      "grad_norm": 4.290924072265625,
      "learning_rate": 2.0785888206648318e-05,
      "loss": 0.6942,
      "step": 552150
    },
    {
      "epoch": 5.8458032722672435,
      "grad_norm": 4.068161487579346,
      "learning_rate": 2.078324158373915e-05,
      "loss": 0.6921,
      "step": 552200
    },
    {
      "epoch": 5.846332594047247,
      "grad_norm": 4.07554292678833,
      "learning_rate": 2.0780594960829983e-05,
      "loss": 0.7032,
      "step": 552250
    },
    {
      "epoch": 5.846861915827251,
      "grad_norm": 4.426825046539307,
      "learning_rate": 2.0777948337920814e-05,
      "loss": 0.7008,
      "step": 552300
    },
    {
      "epoch": 5.847391237607254,
      "grad_norm": 4.273596286773682,
      "learning_rate": 2.0775301715011648e-05,
      "loss": 0.6964,
      "step": 552350
    },
    {
      "epoch": 5.847920559387257,
      "grad_norm": 4.578212261199951,
      "learning_rate": 2.077265509210248e-05,
      "loss": 0.7154,
      "step": 552400
    },
    {
      "epoch": 5.8484498811672605,
      "grad_norm": 4.161007404327393,
      "learning_rate": 2.0770008469193313e-05,
      "loss": 0.7106,
      "step": 552450
    },
    {
      "epoch": 5.848979202947263,
      "grad_norm": 4.601541519165039,
      "learning_rate": 2.0767361846284143e-05,
      "loss": 0.6944,
      "step": 552500
    },
    {
      "epoch": 5.848979202947263,
      "eval_loss": 0.44632863998413086,
      "eval_runtime": 47.0281,
      "eval_samples_per_second": 3570.842,
      "eval_steps_per_second": 446.371,
      "step": 552500
    },
    {
      "epoch": 5.849508524727267,
      "grad_norm": 4.160762310028076,
      "learning_rate": 2.0764715223374974e-05,
      "loss": 0.6995,
      "step": 552550
    },
    {
      "epoch": 5.85003784650727,
      "grad_norm": 4.391551494598389,
      "learning_rate": 2.0762068600465805e-05,
      "loss": 0.6844,
      "step": 552600
    },
    {
      "epoch": 5.850567168287274,
      "grad_norm": 3.642690420150757,
      "learning_rate": 2.075942197755664e-05,
      "loss": 0.6923,
      "step": 552650
    },
    {
      "epoch": 5.851096490067277,
      "grad_norm": 4.081944465637207,
      "learning_rate": 2.075677535464747e-05,
      "loss": 0.6972,
      "step": 552700
    },
    {
      "epoch": 5.85162581184728,
      "grad_norm": 4.237748622894287,
      "learning_rate": 2.0754128731738304e-05,
      "loss": 0.6812,
      "step": 552750
    },
    {
      "epoch": 5.852155133627283,
      "grad_norm": 4.5344929695129395,
      "learning_rate": 2.0751482108829134e-05,
      "loss": 0.6961,
      "step": 552800
    },
    {
      "epoch": 5.852684455407287,
      "grad_norm": 4.153749942779541,
      "learning_rate": 2.074883548591997e-05,
      "loss": 0.7027,
      "step": 552850
    },
    {
      "epoch": 5.85321377718729,
      "grad_norm": 4.546579837799072,
      "learning_rate": 2.07461888630108e-05,
      "loss": 0.7011,
      "step": 552900
    },
    {
      "epoch": 5.853743098967293,
      "grad_norm": 4.229002475738525,
      "learning_rate": 2.0743542240101633e-05,
      "loss": 0.69,
      "step": 552950
    },
    {
      "epoch": 5.8542724207472965,
      "grad_norm": 4.312479496002197,
      "learning_rate": 2.0740895617192464e-05,
      "loss": 0.7008,
      "step": 553000
    },
    {
      "epoch": 5.8542724207472965,
      "eval_loss": 0.4457129240036011,
      "eval_runtime": 46.8041,
      "eval_samples_per_second": 3587.931,
      "eval_steps_per_second": 448.507,
      "step": 553000
    },
    {
      "epoch": 5.8548017425273,
      "grad_norm": 4.0152082443237305,
      "learning_rate": 2.0738248994283295e-05,
      "loss": 0.6906,
      "step": 553050
    },
    {
      "epoch": 5.855331064307303,
      "grad_norm": 4.020113945007324,
      "learning_rate": 2.0735602371374126e-05,
      "loss": 0.7047,
      "step": 553100
    },
    {
      "epoch": 5.855860386087306,
      "grad_norm": 4.6428446769714355,
      "learning_rate": 2.073295574846496e-05,
      "loss": 0.6903,
      "step": 553150
    },
    {
      "epoch": 5.85638970786731,
      "grad_norm": 4.692317485809326,
      "learning_rate": 2.073030912555579e-05,
      "loss": 0.6881,
      "step": 553200
    },
    {
      "epoch": 5.856919029647313,
      "grad_norm": 4.306855201721191,
      "learning_rate": 2.0727662502646624e-05,
      "loss": 0.688,
      "step": 553250
    },
    {
      "epoch": 5.857448351427316,
      "grad_norm": 3.9439992904663086,
      "learning_rate": 2.0725015879737455e-05,
      "loss": 0.6919,
      "step": 553300
    },
    {
      "epoch": 5.857977673207319,
      "grad_norm": 3.974278211593628,
      "learning_rate": 2.072236925682829e-05,
      "loss": 0.7019,
      "step": 553350
    },
    {
      "epoch": 5.858506994987323,
      "grad_norm": 4.09060525894165,
      "learning_rate": 2.071972263391912e-05,
      "loss": 0.6888,
      "step": 553400
    },
    {
      "epoch": 5.859036316767326,
      "grad_norm": 4.4906697273254395,
      "learning_rate": 2.0717076011009954e-05,
      "loss": 0.6988,
      "step": 553450
    },
    {
      "epoch": 5.85956563854733,
      "grad_norm": 4.321320056915283,
      "learning_rate": 2.0714429388100785e-05,
      "loss": 0.6869,
      "step": 553500
    },
    {
      "epoch": 5.85956563854733,
      "eval_loss": 0.44598883390426636,
      "eval_runtime": 46.84,
      "eval_samples_per_second": 3585.181,
      "eval_steps_per_second": 448.164,
      "step": 553500
    },
    {
      "epoch": 5.8600949603273325,
      "grad_norm": 4.12295389175415,
      "learning_rate": 2.071178276519162e-05,
      "loss": 0.703,
      "step": 553550
    },
    {
      "epoch": 5.860624282107336,
      "grad_norm": 4.216680526733398,
      "learning_rate": 2.070913614228245e-05,
      "loss": 0.6976,
      "step": 553600
    },
    {
      "epoch": 5.861153603887339,
      "grad_norm": 4.417963027954102,
      "learning_rate": 2.070648951937328e-05,
      "loss": 0.6971,
      "step": 553650
    },
    {
      "epoch": 5.861682925667342,
      "grad_norm": 4.3706536293029785,
      "learning_rate": 2.070384289646411e-05,
      "loss": 0.6875,
      "step": 553700
    },
    {
      "epoch": 5.862212247447346,
      "grad_norm": 4.010274410247803,
      "learning_rate": 2.0701196273554945e-05,
      "loss": 0.7023,
      "step": 553750
    },
    {
      "epoch": 5.8627415692273495,
      "grad_norm": 4.007462501525879,
      "learning_rate": 2.0698549650645776e-05,
      "loss": 0.6895,
      "step": 553800
    },
    {
      "epoch": 5.863270891007352,
      "grad_norm": 4.336842060089111,
      "learning_rate": 2.069590302773661e-05,
      "loss": 0.6955,
      "step": 553850
    },
    {
      "epoch": 5.863800212787355,
      "grad_norm": 4.10852575302124,
      "learning_rate": 2.069325640482744e-05,
      "loss": 0.6978,
      "step": 553900
    },
    {
      "epoch": 5.864329534567359,
      "grad_norm": 4.397464752197266,
      "learning_rate": 2.0690609781918275e-05,
      "loss": 0.6918,
      "step": 553950
    },
    {
      "epoch": 5.864858856347362,
      "grad_norm": 4.5349626541137695,
      "learning_rate": 2.0687963159009105e-05,
      "loss": 0.6851,
      "step": 554000
    },
    {
      "epoch": 5.864858856347362,
      "eval_loss": 0.44442611932754517,
      "eval_runtime": 46.7452,
      "eval_samples_per_second": 3592.455,
      "eval_steps_per_second": 449.073,
      "step": 554000
    },
    {
      "epoch": 5.865388178127366,
      "grad_norm": 4.423053741455078,
      "learning_rate": 2.068531653609994e-05,
      "loss": 0.7061,
      "step": 554050
    },
    {
      "epoch": 5.865917499907368,
      "grad_norm": 4.1839919090271,
      "learning_rate": 2.068266991319077e-05,
      "loss": 0.6881,
      "step": 554100
    },
    {
      "epoch": 5.866446821687372,
      "grad_norm": 4.1979522705078125,
      "learning_rate": 2.0680023290281604e-05,
      "loss": 0.6911,
      "step": 554150
    },
    {
      "epoch": 5.866976143467375,
      "grad_norm": 4.094511032104492,
      "learning_rate": 2.0677376667372435e-05,
      "loss": 0.7018,
      "step": 554200
    },
    {
      "epoch": 5.867505465247379,
      "grad_norm": 4.067322731018066,
      "learning_rate": 2.0674730044463266e-05,
      "loss": 0.6957,
      "step": 554250
    },
    {
      "epoch": 5.868034787027382,
      "grad_norm": 4.251957416534424,
      "learning_rate": 2.0672083421554096e-05,
      "loss": 0.6964,
      "step": 554300
    },
    {
      "epoch": 5.868564108807385,
      "grad_norm": 4.221292972564697,
      "learning_rate": 2.0669489731103115e-05,
      "loss": 0.685,
      "step": 554350
    },
    {
      "epoch": 5.869093430587388,
      "grad_norm": 4.340104579925537,
      "learning_rate": 2.0666843108193945e-05,
      "loss": 0.6935,
      "step": 554400
    },
    {
      "epoch": 5.869622752367391,
      "grad_norm": 4.837345600128174,
      "learning_rate": 2.066419648528478e-05,
      "loss": 0.7024,
      "step": 554450
    },
    {
      "epoch": 5.870152074147395,
      "grad_norm": 4.556928634643555,
      "learning_rate": 2.066154986237561e-05,
      "loss": 0.7069,
      "step": 554500
    },
    {
      "epoch": 5.870152074147395,
      "eval_loss": 0.44553306698799133,
      "eval_runtime": 46.8437,
      "eval_samples_per_second": 3584.902,
      "eval_steps_per_second": 448.129,
      "step": 554500
    },
    {
      "epoch": 5.870681395927399,
      "grad_norm": 4.545853614807129,
      "learning_rate": 2.0658903239466444e-05,
      "loss": 0.6929,
      "step": 554550
    },
    {
      "epoch": 5.8712107177074015,
      "grad_norm": 4.360733985900879,
      "learning_rate": 2.0656256616557275e-05,
      "loss": 0.6896,
      "step": 554600
    },
    {
      "epoch": 5.871740039487404,
      "grad_norm": 4.518673896789551,
      "learning_rate": 2.0653609993648106e-05,
      "loss": 0.7016,
      "step": 554650
    },
    {
      "epoch": 5.872269361267408,
      "grad_norm": 4.484629154205322,
      "learning_rate": 2.0650963370738936e-05,
      "loss": 0.7077,
      "step": 554700
    },
    {
      "epoch": 5.872798683047411,
      "grad_norm": 4.522752285003662,
      "learning_rate": 2.064831674782977e-05,
      "loss": 0.7024,
      "step": 554750
    },
    {
      "epoch": 5.873328004827415,
      "grad_norm": 4.218247413635254,
      "learning_rate": 2.06456701249206e-05,
      "loss": 0.6886,
      "step": 554800
    },
    {
      "epoch": 5.873857326607418,
      "grad_norm": 4.577406406402588,
      "learning_rate": 2.0643023502011435e-05,
      "loss": 0.7,
      "step": 554850
    },
    {
      "epoch": 5.874386648387421,
      "grad_norm": 4.7122626304626465,
      "learning_rate": 2.0640376879102266e-05,
      "loss": 0.6928,
      "step": 554900
    },
    {
      "epoch": 5.874915970167424,
      "grad_norm": 4.118072509765625,
      "learning_rate": 2.06377302561931e-05,
      "loss": 0.6792,
      "step": 554950
    },
    {
      "epoch": 5.875445291947428,
      "grad_norm": 4.229557037353516,
      "learning_rate": 2.063508363328393e-05,
      "loss": 0.7042,
      "step": 555000
    },
    {
      "epoch": 5.875445291947428,
      "eval_loss": 0.4464247226715088,
      "eval_runtime": 46.7424,
      "eval_samples_per_second": 3592.673,
      "eval_steps_per_second": 449.1,
      "step": 555000
    },
    {
      "epoch": 5.875974613727431,
      "grad_norm": 4.174019813537598,
      "learning_rate": 2.0632437010374765e-05,
      "loss": 0.692,
      "step": 555050
    },
    {
      "epoch": 5.876503935507435,
      "grad_norm": 4.52414608001709,
      "learning_rate": 2.0629790387465596e-05,
      "loss": 0.695,
      "step": 555100
    },
    {
      "epoch": 5.8770332572874375,
      "grad_norm": 4.570414066314697,
      "learning_rate": 2.062714376455643e-05,
      "loss": 0.6949,
      "step": 555150
    },
    {
      "epoch": 5.87756257906744,
      "grad_norm": 4.557314395904541,
      "learning_rate": 2.062449714164726e-05,
      "loss": 0.7011,
      "step": 555200
    },
    {
      "epoch": 5.878091900847444,
      "grad_norm": 4.759851932525635,
      "learning_rate": 2.062185051873809e-05,
      "loss": 0.6984,
      "step": 555250
    },
    {
      "epoch": 5.878621222627448,
      "grad_norm": 4.287092208862305,
      "learning_rate": 2.0619203895828922e-05,
      "loss": 0.6827,
      "step": 555300
    },
    {
      "epoch": 5.879150544407451,
      "grad_norm": 3.9522504806518555,
      "learning_rate": 2.0616557272919756e-05,
      "loss": 0.6857,
      "step": 555350
    },
    {
      "epoch": 5.879679866187454,
      "grad_norm": 4.278684139251709,
      "learning_rate": 2.0613910650010587e-05,
      "loss": 0.693,
      "step": 555400
    },
    {
      "epoch": 5.880209187967457,
      "grad_norm": 4.379089832305908,
      "learning_rate": 2.061126402710142e-05,
      "loss": 0.7047,
      "step": 555450
    },
    {
      "epoch": 5.88073850974746,
      "grad_norm": 4.252532005310059,
      "learning_rate": 2.060861740419225e-05,
      "loss": 0.6946,
      "step": 555500
    },
    {
      "epoch": 5.88073850974746,
      "eval_loss": 0.4451516270637512,
      "eval_runtime": 46.7274,
      "eval_samples_per_second": 3593.821,
      "eval_steps_per_second": 449.244,
      "step": 555500
    },
    {
      "epoch": 5.881267831527464,
      "grad_norm": 4.561340808868408,
      "learning_rate": 2.0605970781283086e-05,
      "loss": 0.7064,
      "step": 555550
    },
    {
      "epoch": 5.881797153307467,
      "grad_norm": 4.448638916015625,
      "learning_rate": 2.0603324158373916e-05,
      "loss": 0.7071,
      "step": 555600
    },
    {
      "epoch": 5.882326475087471,
      "grad_norm": 4.89296817779541,
      "learning_rate": 2.060067753546475e-05,
      "loss": 0.6985,
      "step": 555650
    },
    {
      "epoch": 5.8828557968674735,
      "grad_norm": 4.644524574279785,
      "learning_rate": 2.059803091255558e-05,
      "loss": 0.7014,
      "step": 555700
    },
    {
      "epoch": 5.883385118647477,
      "grad_norm": 4.433832168579102,
      "learning_rate": 2.0595384289646412e-05,
      "loss": 0.6827,
      "step": 555750
    },
    {
      "epoch": 5.88391444042748,
      "grad_norm": 4.168123722076416,
      "learning_rate": 2.0592737666737242e-05,
      "loss": 0.7017,
      "step": 555800
    },
    {
      "epoch": 5.884443762207484,
      "grad_norm": 3.9592862129211426,
      "learning_rate": 2.0590091043828077e-05,
      "loss": 0.6897,
      "step": 555850
    },
    {
      "epoch": 5.884973083987487,
      "grad_norm": 4.515817642211914,
      "learning_rate": 2.0587444420918907e-05,
      "loss": 0.7001,
      "step": 555900
    },
    {
      "epoch": 5.88550240576749,
      "grad_norm": 4.21903657913208,
      "learning_rate": 2.058479779800974e-05,
      "loss": 0.6856,
      "step": 555950
    },
    {
      "epoch": 5.886031727547493,
      "grad_norm": 4.486085414886475,
      "learning_rate": 2.0582151175100572e-05,
      "loss": 0.6987,
      "step": 556000
    },
    {
      "epoch": 5.886031727547493,
      "eval_loss": 0.4446874260902405,
      "eval_runtime": 46.7841,
      "eval_samples_per_second": 3589.465,
      "eval_steps_per_second": 448.699,
      "step": 556000
    },
    {
      "epoch": 5.886561049327497,
      "grad_norm": 4.342146873474121,
      "learning_rate": 2.0579504552191406e-05,
      "loss": 0.6858,
      "step": 556050
    },
    {
      "epoch": 5.8870903711075,
      "grad_norm": 3.8680739402770996,
      "learning_rate": 2.0576857929282237e-05,
      "loss": 0.6849,
      "step": 556100
    },
    {
      "epoch": 5.887619692887503,
      "grad_norm": 4.788031101226807,
      "learning_rate": 2.057421130637307e-05,
      "loss": 0.687,
      "step": 556150
    },
    {
      "epoch": 5.888149014667507,
      "grad_norm": 4.710796356201172,
      "learning_rate": 2.0571564683463902e-05,
      "loss": 0.7062,
      "step": 556200
    },
    {
      "epoch": 5.8886783364475095,
      "grad_norm": 4.607211589813232,
      "learning_rate": 2.0568918060554736e-05,
      "loss": 0.6989,
      "step": 556250
    },
    {
      "epoch": 5.889207658227513,
      "grad_norm": 4.29469633102417,
      "learning_rate": 2.0566271437645567e-05,
      "loss": 0.6909,
      "step": 556300
    },
    {
      "epoch": 5.889736980007516,
      "grad_norm": 4.077094554901123,
      "learning_rate": 2.056367774719458e-05,
      "loss": 0.6895,
      "step": 556350
    },
    {
      "epoch": 5.89026630178752,
      "grad_norm": 4.578100681304932,
      "learning_rate": 2.0561031124285412e-05,
      "loss": 0.7062,
      "step": 556400
    },
    {
      "epoch": 5.890795623567523,
      "grad_norm": 4.521846294403076,
      "learning_rate": 2.0558384501376246e-05,
      "loss": 0.6941,
      "step": 556450
    },
    {
      "epoch": 5.8913249453475265,
      "grad_norm": 4.447410583496094,
      "learning_rate": 2.0555737878467077e-05,
      "loss": 0.6909,
      "step": 556500
    },
    {
      "epoch": 5.8913249453475265,
      "eval_loss": 0.4445236623287201,
      "eval_runtime": 46.6858,
      "eval_samples_per_second": 3597.025,
      "eval_steps_per_second": 449.644,
      "step": 556500
    },
    {
      "epoch": 5.891854267127529,
      "grad_norm": 4.356537342071533,
      "learning_rate": 2.055309125555791e-05,
      "loss": 0.6996,
      "step": 556550
    },
    {
      "epoch": 5.892383588907533,
      "grad_norm": 4.021582126617432,
      "learning_rate": 2.055044463264874e-05,
      "loss": 0.6803,
      "step": 556600
    },
    {
      "epoch": 5.892912910687536,
      "grad_norm": 4.705825328826904,
      "learning_rate": 2.0547798009739576e-05,
      "loss": 0.7102,
      "step": 556650
    },
    {
      "epoch": 5.893442232467539,
      "grad_norm": 4.143182277679443,
      "learning_rate": 2.0545151386830406e-05,
      "loss": 0.7001,
      "step": 556700
    },
    {
      "epoch": 5.893971554247543,
      "grad_norm": 4.148083209991455,
      "learning_rate": 2.0542504763921237e-05,
      "loss": 0.6915,
      "step": 556750
    },
    {
      "epoch": 5.894500876027546,
      "grad_norm": 4.5414862632751465,
      "learning_rate": 2.0539858141012068e-05,
      "loss": 0.6933,
      "step": 556800
    },
    {
      "epoch": 5.895030197807549,
      "grad_norm": 4.378730297088623,
      "learning_rate": 2.0537211518102902e-05,
      "loss": 0.6975,
      "step": 556850
    },
    {
      "epoch": 5.895559519587552,
      "grad_norm": 4.482872009277344,
      "learning_rate": 2.0534564895193733e-05,
      "loss": 0.6948,
      "step": 556900
    },
    {
      "epoch": 5.896088841367556,
      "grad_norm": 4.1440324783325195,
      "learning_rate": 2.0531918272284567e-05,
      "loss": 0.6842,
      "step": 556950
    },
    {
      "epoch": 5.896618163147559,
      "grad_norm": 4.616878986358643,
      "learning_rate": 2.0529271649375397e-05,
      "loss": 0.6917,
      "step": 557000
    },
    {
      "epoch": 5.896618163147559,
      "eval_loss": 0.44450435042381287,
      "eval_runtime": 46.7569,
      "eval_samples_per_second": 3591.555,
      "eval_steps_per_second": 448.96,
      "step": 557000
    },
    {
      "epoch": 5.8971474849275625,
      "grad_norm": 4.364151954650879,
      "learning_rate": 2.052662502646623e-05,
      "loss": 0.6952,
      "step": 557050
    },
    {
      "epoch": 5.897676806707565,
      "grad_norm": 4.006160736083984,
      "learning_rate": 2.0523978403557062e-05,
      "loss": 0.683,
      "step": 557100
    },
    {
      "epoch": 5.898206128487569,
      "grad_norm": 4.275480270385742,
      "learning_rate": 2.0521331780647896e-05,
      "loss": 0.698,
      "step": 557150
    },
    {
      "epoch": 5.898735450267572,
      "grad_norm": 4.380503177642822,
      "learning_rate": 2.0518685157738727e-05,
      "loss": 0.6992,
      "step": 557200
    },
    {
      "epoch": 5.899264772047576,
      "grad_norm": 3.9508092403411865,
      "learning_rate": 2.051603853482956e-05,
      "loss": 0.6872,
      "step": 557250
    },
    {
      "epoch": 5.899794093827579,
      "grad_norm": 4.59533166885376,
      "learning_rate": 2.0513391911920392e-05,
      "loss": 0.6966,
      "step": 557300
    },
    {
      "epoch": 5.900323415607582,
      "grad_norm": 4.875929355621338,
      "learning_rate": 2.0510745289011223e-05,
      "loss": 0.6904,
      "step": 557350
    },
    {
      "epoch": 5.900852737387585,
      "grad_norm": 4.581934928894043,
      "learning_rate": 2.0508098666102053e-05,
      "loss": 0.6865,
      "step": 557400
    },
    {
      "epoch": 5.901382059167589,
      "grad_norm": 4.540919303894043,
      "learning_rate": 2.0505452043192887e-05,
      "loss": 0.7021,
      "step": 557450
    },
    {
      "epoch": 5.901911380947592,
      "grad_norm": 4.824634075164795,
      "learning_rate": 2.0502805420283718e-05,
      "loss": 0.6998,
      "step": 557500
    },
    {
      "epoch": 5.901911380947592,
      "eval_loss": 0.4447477161884308,
      "eval_runtime": 46.7569,
      "eval_samples_per_second": 3591.554,
      "eval_steps_per_second": 448.96,
      "step": 557500
    },
    {
      "epoch": 5.902440702727596,
      "grad_norm": 4.709144592285156,
      "learning_rate": 2.0500158797374552e-05,
      "loss": 0.7025,
      "step": 557550
    },
    {
      "epoch": 5.9029700245075984,
      "grad_norm": 5.016477584838867,
      "learning_rate": 2.0497512174465383e-05,
      "loss": 0.6978,
      "step": 557600
    },
    {
      "epoch": 5.903499346287601,
      "grad_norm": 4.590195655822754,
      "learning_rate": 2.0494865551556217e-05,
      "loss": 0.6885,
      "step": 557650
    },
    {
      "epoch": 5.904028668067605,
      "grad_norm": 4.206212043762207,
      "learning_rate": 2.0492218928647048e-05,
      "loss": 0.6959,
      "step": 557700
    },
    {
      "epoch": 5.904557989847608,
      "grad_norm": 4.506666660308838,
      "learning_rate": 2.0489572305737882e-05,
      "loss": 0.6961,
      "step": 557750
    },
    {
      "epoch": 5.905087311627612,
      "grad_norm": 4.2162652015686035,
      "learning_rate": 2.0486925682828713e-05,
      "loss": 0.69,
      "step": 557800
    },
    {
      "epoch": 5.905616633407615,
      "grad_norm": 4.404255390167236,
      "learning_rate": 2.0484279059919547e-05,
      "loss": 0.6881,
      "step": 557850
    },
    {
      "epoch": 5.906145955187618,
      "grad_norm": 4.183110237121582,
      "learning_rate": 2.0481632437010377e-05,
      "loss": 0.6877,
      "step": 557900
    },
    {
      "epoch": 5.906675276967621,
      "grad_norm": 4.016669750213623,
      "learning_rate": 2.0478985814101208e-05,
      "loss": 0.6989,
      "step": 557950
    },
    {
      "epoch": 5.907204598747625,
      "grad_norm": 4.5574870109558105,
      "learning_rate": 2.047633919119204e-05,
      "loss": 0.6843,
      "step": 558000
    },
    {
      "epoch": 5.907204598747625,
      "eval_loss": 0.4430897533893585,
      "eval_runtime": 46.7279,
      "eval_samples_per_second": 3593.786,
      "eval_steps_per_second": 449.239,
      "step": 558000
    },
    {
      "epoch": 5.907733920527628,
      "grad_norm": 4.154240608215332,
      "learning_rate": 2.0473692568282873e-05,
      "loss": 0.6937,
      "step": 558050
    },
    {
      "epoch": 5.908263242307632,
      "grad_norm": 4.331332683563232,
      "learning_rate": 2.0471045945373704e-05,
      "loss": 0.6949,
      "step": 558100
    },
    {
      "epoch": 5.908792564087634,
      "grad_norm": 4.051344394683838,
      "learning_rate": 2.0468399322464538e-05,
      "loss": 0.6872,
      "step": 558150
    },
    {
      "epoch": 5.909321885867638,
      "grad_norm": 3.848503351211548,
      "learning_rate": 2.046575269955537e-05,
      "loss": 0.7044,
      "step": 558200
    },
    {
      "epoch": 5.909851207647641,
      "grad_norm": 4.27189302444458,
      "learning_rate": 2.04631060766462e-05,
      "loss": 0.6953,
      "step": 558250
    },
    {
      "epoch": 5.910380529427645,
      "grad_norm": 4.565333366394043,
      "learning_rate": 2.0460459453737033e-05,
      "loss": 0.6822,
      "step": 558300
    },
    {
      "epoch": 5.910909851207648,
      "grad_norm": 4.23451042175293,
      "learning_rate": 2.0457865763286048e-05,
      "loss": 0.687,
      "step": 558350
    },
    {
      "epoch": 5.9114391729876505,
      "grad_norm": 3.92324161529541,
      "learning_rate": 2.045521914037688e-05,
      "loss": 0.6917,
      "step": 558400
    },
    {
      "epoch": 5.911968494767654,
      "grad_norm": 4.34810209274292,
      "learning_rate": 2.0452572517467713e-05,
      "loss": 0.6938,
      "step": 558450
    },
    {
      "epoch": 5.912497816547657,
      "grad_norm": 4.399547100067139,
      "learning_rate": 2.0449925894558543e-05,
      "loss": 0.7142,
      "step": 558500
    },
    {
      "epoch": 5.912497816547657,
      "eval_loss": 0.44565778970718384,
      "eval_runtime": 46.8055,
      "eval_samples_per_second": 3587.826,
      "eval_steps_per_second": 448.494,
      "step": 558500
    },
    {
      "epoch": 5.913027138327661,
      "grad_norm": 4.538225173950195,
      "learning_rate": 2.0447279271649378e-05,
      "loss": 0.6951,
      "step": 558550
    },
    {
      "epoch": 5.913556460107664,
      "grad_norm": 4.447099685668945,
      "learning_rate": 2.0444632648740208e-05,
      "loss": 0.6825,
      "step": 558600
    },
    {
      "epoch": 5.9140857818876675,
      "grad_norm": 4.6768035888671875,
      "learning_rate": 2.0441986025831042e-05,
      "loss": 0.7026,
      "step": 558650
    },
    {
      "epoch": 5.91461510366767,
      "grad_norm": 4.204112529754639,
      "learning_rate": 2.0439339402921873e-05,
      "loss": 0.6981,
      "step": 558700
    },
    {
      "epoch": 5.915144425447674,
      "grad_norm": 4.46277379989624,
      "learning_rate": 2.0436692780012707e-05,
      "loss": 0.6911,
      "step": 558750
    },
    {
      "epoch": 5.915673747227677,
      "grad_norm": 4.554616928100586,
      "learning_rate": 2.0434046157103538e-05,
      "loss": 0.7,
      "step": 558800
    },
    {
      "epoch": 5.916203069007681,
      "grad_norm": 4.185798168182373,
      "learning_rate": 2.043139953419437e-05,
      "loss": 0.697,
      "step": 558850
    },
    {
      "epoch": 5.916732390787684,
      "grad_norm": 3.8994357585906982,
      "learning_rate": 2.0428752911285203e-05,
      "loss": 0.6999,
      "step": 558900
    },
    {
      "epoch": 5.917261712567687,
      "grad_norm": 4.4406609535217285,
      "learning_rate": 2.0426106288376033e-05,
      "loss": 0.6882,
      "step": 558950
    },
    {
      "epoch": 5.91779103434769,
      "grad_norm": 4.516353130340576,
      "learning_rate": 2.0423459665466864e-05,
      "loss": 0.6939,
      "step": 559000
    },
    {
      "epoch": 5.91779103434769,
      "eval_loss": 0.4441409409046173,
      "eval_runtime": 46.7535,
      "eval_samples_per_second": 3591.814,
      "eval_steps_per_second": 448.993,
      "step": 559000
    },
    {
      "epoch": 5.918320356127694,
      "grad_norm": 4.550894260406494,
      "learning_rate": 2.0420813042557695e-05,
      "loss": 0.6992,
      "step": 559050
    },
    {
      "epoch": 5.918849677907697,
      "grad_norm": 4.2000555992126465,
      "learning_rate": 2.041816641964853e-05,
      "loss": 0.6807,
      "step": 559100
    },
    {
      "epoch": 5.9193789996877,
      "grad_norm": 4.892614841461182,
      "learning_rate": 2.041551979673936e-05,
      "loss": 0.6934,
      "step": 559150
    },
    {
      "epoch": 5.9199083214677035,
      "grad_norm": 4.384646415710449,
      "learning_rate": 2.0412873173830194e-05,
      "loss": 0.7061,
      "step": 559200
    },
    {
      "epoch": 5.920437643247706,
      "grad_norm": 4.425642967224121,
      "learning_rate": 2.0410226550921024e-05,
      "loss": 0.6981,
      "step": 559250
    },
    {
      "epoch": 5.92096696502771,
      "grad_norm": 4.020823955535889,
      "learning_rate": 2.040757992801186e-05,
      "loss": 0.7003,
      "step": 559300
    },
    {
      "epoch": 5.921496286807713,
      "grad_norm": 4.16497278213501,
      "learning_rate": 2.040493330510269e-05,
      "loss": 0.7023,
      "step": 559350
    },
    {
      "epoch": 5.922025608587717,
      "grad_norm": 4.45682430267334,
      "learning_rate": 2.0402286682193523e-05,
      "loss": 0.6974,
      "step": 559400
    },
    {
      "epoch": 5.92255493036772,
      "grad_norm": 4.3544206619262695,
      "learning_rate": 2.0399640059284354e-05,
      "loss": 0.7034,
      "step": 559450
    },
    {
      "epoch": 5.923084252147723,
      "grad_norm": 4.502717018127441,
      "learning_rate": 2.0396993436375185e-05,
      "loss": 0.6964,
      "step": 559500
    },
    {
      "epoch": 5.923084252147723,
      "eval_loss": 0.44360679388046265,
      "eval_runtime": 46.7596,
      "eval_samples_per_second": 3591.352,
      "eval_steps_per_second": 448.935,
      "step": 559500
    },
    {
      "epoch": 5.923613573927726,
      "grad_norm": 5.101304054260254,
      "learning_rate": 2.0394346813466016e-05,
      "loss": 0.7025,
      "step": 559550
    },
    {
      "epoch": 5.92414289570773,
      "grad_norm": 4.332894325256348,
      "learning_rate": 2.039170019055685e-05,
      "loss": 0.6957,
      "step": 559600
    },
    {
      "epoch": 5.924672217487733,
      "grad_norm": 4.133885383605957,
      "learning_rate": 2.038905356764768e-05,
      "loss": 0.7047,
      "step": 559650
    },
    {
      "epoch": 5.925201539267737,
      "grad_norm": 4.5539374351501465,
      "learning_rate": 2.0386406944738514e-05,
      "loss": 0.698,
      "step": 559700
    },
    {
      "epoch": 5.9257308610477395,
      "grad_norm": 4.031770706176758,
      "learning_rate": 2.0383760321829345e-05,
      "loss": 0.6932,
      "step": 559750
    },
    {
      "epoch": 5.926260182827743,
      "grad_norm": 4.174530029296875,
      "learning_rate": 2.038111369892018e-05,
      "loss": 0.6906,
      "step": 559800
    },
    {
      "epoch": 5.926789504607746,
      "grad_norm": 4.53188943862915,
      "learning_rate": 2.037846707601101e-05,
      "loss": 0.6874,
      "step": 559850
    },
    {
      "epoch": 5.927318826387749,
      "grad_norm": 4.588999271392822,
      "learning_rate": 2.0375820453101844e-05,
      "loss": 0.6871,
      "step": 559900
    },
    {
      "epoch": 5.927848148167753,
      "grad_norm": 4.365550518035889,
      "learning_rate": 2.0373173830192675e-05,
      "loss": 0.6922,
      "step": 559950
    },
    {
      "epoch": 5.928377469947756,
      "grad_norm": 4.620739936828613,
      "learning_rate": 2.037052720728351e-05,
      "loss": 0.7004,
      "step": 560000
    },
    {
      "epoch": 5.928377469947756,
      "eval_loss": 0.44361621141433716,
      "eval_runtime": 46.6984,
      "eval_samples_per_second": 3596.052,
      "eval_steps_per_second": 449.523,
      "step": 560000
    },
    {
      "epoch": 5.928906791727759,
      "grad_norm": 4.148924350738525,
      "learning_rate": 2.036788058437434e-05,
      "loss": 0.6955,
      "step": 560050
    },
    {
      "epoch": 5.929436113507762,
      "grad_norm": 4.269687175750732,
      "learning_rate": 2.036523396146517e-05,
      "loss": 0.6877,
      "step": 560100
    },
    {
      "epoch": 5.929965435287766,
      "grad_norm": 4.287060737609863,
      "learning_rate": 2.0362587338556e-05,
      "loss": 0.6936,
      "step": 560150
    },
    {
      "epoch": 5.930494757067769,
      "grad_norm": 4.4449992179870605,
      "learning_rate": 2.0359940715646835e-05,
      "loss": 0.6916,
      "step": 560200
    },
    {
      "epoch": 5.931024078847773,
      "grad_norm": 4.813204288482666,
      "learning_rate": 2.0357294092737666e-05,
      "loss": 0.7093,
      "step": 560250
    },
    {
      "epoch": 5.9315534006277755,
      "grad_norm": 4.49713659286499,
      "learning_rate": 2.03546474698285e-05,
      "loss": 0.6863,
      "step": 560300
    },
    {
      "epoch": 5.932082722407779,
      "grad_norm": 4.513119220733643,
      "learning_rate": 2.0352053779377515e-05,
      "loss": 0.695,
      "step": 560350
    },
    {
      "epoch": 5.932612044187782,
      "grad_norm": 4.479430675506592,
      "learning_rate": 2.034940715646835e-05,
      "loss": 0.6947,
      "step": 560400
    },
    {
      "epoch": 5.933141365967786,
      "grad_norm": 4.060489177703857,
      "learning_rate": 2.034676053355918e-05,
      "loss": 0.6991,
      "step": 560450
    },
    {
      "epoch": 5.933670687747789,
      "grad_norm": 4.235899925231934,
      "learning_rate": 2.034411391065001e-05,
      "loss": 0.7018,
      "step": 560500
    },
    {
      "epoch": 5.933670687747789,
      "eval_loss": 0.4439030587673187,
      "eval_runtime": 46.8893,
      "eval_samples_per_second": 3581.418,
      "eval_steps_per_second": 447.693,
      "step": 560500
    },
    {
      "epoch": 5.9342000095277925,
      "grad_norm": 4.04332160949707,
      "learning_rate": 2.034146728774084e-05,
      "loss": 0.697,
      "step": 560550
    },
    {
      "epoch": 5.934729331307795,
      "grad_norm": 3.7906641960144043,
      "learning_rate": 2.0338820664831675e-05,
      "loss": 0.6744,
      "step": 560600
    },
    {
      "epoch": 5.935258653087798,
      "grad_norm": 4.711904048919678,
      "learning_rate": 2.0336174041922506e-05,
      "loss": 0.6975,
      "step": 560650
    },
    {
      "epoch": 5.935787974867802,
      "grad_norm": 4.200384140014648,
      "learning_rate": 2.033352741901334e-05,
      "loss": 0.7036,
      "step": 560700
    },
    {
      "epoch": 5.936317296647805,
      "grad_norm": 4.844570636749268,
      "learning_rate": 2.033088079610417e-05,
      "loss": 0.6867,
      "step": 560750
    },
    {
      "epoch": 5.936846618427809,
      "grad_norm": 4.2251505851745605,
      "learning_rate": 2.0328234173195005e-05,
      "loss": 0.7002,
      "step": 560800
    },
    {
      "epoch": 5.9373759402078115,
      "grad_norm": 4.119564056396484,
      "learning_rate": 2.0325587550285835e-05,
      "loss": 0.6984,
      "step": 560850
    },
    {
      "epoch": 5.937905261987815,
      "grad_norm": 4.414577960968018,
      "learning_rate": 2.032294092737667e-05,
      "loss": 0.6947,
      "step": 560900
    },
    {
      "epoch": 5.938434583767818,
      "grad_norm": 4.235754489898682,
      "learning_rate": 2.03202943044675e-05,
      "loss": 0.7022,
      "step": 560950
    },
    {
      "epoch": 5.938963905547822,
      "grad_norm": 5.015666484832764,
      "learning_rate": 2.0317647681558334e-05,
      "loss": 0.6926,
      "step": 561000
    },
    {
      "epoch": 5.938963905547822,
      "eval_loss": 0.4430962800979614,
      "eval_runtime": 46.7304,
      "eval_samples_per_second": 3593.594,
      "eval_steps_per_second": 449.215,
      "step": 561000
    },
    {
      "epoch": 5.939493227327825,
      "grad_norm": 4.426388263702393,
      "learning_rate": 2.0315001058649165e-05,
      "loss": 0.6879,
      "step": 561050
    },
    {
      "epoch": 5.9400225491078285,
      "grad_norm": 4.170758247375488,
      "learning_rate": 2.0312354435739996e-05,
      "loss": 0.6908,
      "step": 561100
    },
    {
      "epoch": 5.940551870887831,
      "grad_norm": 4.313577175140381,
      "learning_rate": 2.0309707812830826e-05,
      "loss": 0.6974,
      "step": 561150
    },
    {
      "epoch": 5.941081192667835,
      "grad_norm": 4.402998924255371,
      "learning_rate": 2.030706118992166e-05,
      "loss": 0.6891,
      "step": 561200
    },
    {
      "epoch": 5.941610514447838,
      "grad_norm": 4.5890889167785645,
      "learning_rate": 2.030441456701249e-05,
      "loss": 0.6941,
      "step": 561250
    },
    {
      "epoch": 5.942139836227842,
      "grad_norm": 3.888605833053589,
      "learning_rate": 2.0301767944103325e-05,
      "loss": 0.6949,
      "step": 561300
    },
    {
      "epoch": 5.942669158007845,
      "grad_norm": 4.633195400238037,
      "learning_rate": 2.0299121321194156e-05,
      "loss": 0.6845,
      "step": 561350
    },
    {
      "epoch": 5.943198479787847,
      "grad_norm": 4.0765814781188965,
      "learning_rate": 2.029647469828499e-05,
      "loss": 0.6901,
      "step": 561400
    },
    {
      "epoch": 5.943727801567851,
      "grad_norm": 4.388551712036133,
      "learning_rate": 2.029382807537582e-05,
      "loss": 0.6892,
      "step": 561450
    },
    {
      "epoch": 5.944257123347854,
      "grad_norm": 4.113868713378906,
      "learning_rate": 2.0291181452466655e-05,
      "loss": 0.6972,
      "step": 561500
    },
    {
      "epoch": 5.944257123347854,
      "eval_loss": 0.44318121671676636,
      "eval_runtime": 46.7771,
      "eval_samples_per_second": 3590.008,
      "eval_steps_per_second": 448.767,
      "step": 561500
    },
    {
      "epoch": 5.944786445127858,
      "grad_norm": 3.9171833992004395,
      "learning_rate": 2.0288534829557486e-05,
      "loss": 0.6943,
      "step": 561550
    },
    {
      "epoch": 5.945315766907861,
      "grad_norm": 4.6848554611206055,
      "learning_rate": 2.028588820664832e-05,
      "loss": 0.6982,
      "step": 561600
    },
    {
      "epoch": 5.945845088687864,
      "grad_norm": 4.1067795753479,
      "learning_rate": 2.028324158373915e-05,
      "loss": 0.6993,
      "step": 561650
    },
    {
      "epoch": 5.946374410467867,
      "grad_norm": 4.381786823272705,
      "learning_rate": 2.028059496082998e-05,
      "loss": 0.6857,
      "step": 561700
    },
    {
      "epoch": 5.946903732247871,
      "grad_norm": 4.146354675292969,
      "learning_rate": 2.0277948337920812e-05,
      "loss": 0.6947,
      "step": 561750
    },
    {
      "epoch": 5.947433054027874,
      "grad_norm": 3.9878695011138916,
      "learning_rate": 2.0275301715011646e-05,
      "loss": 0.6896,
      "step": 561800
    },
    {
      "epoch": 5.947962375807878,
      "grad_norm": 4.52567720413208,
      "learning_rate": 2.0272655092102477e-05,
      "loss": 0.7064,
      "step": 561850
    },
    {
      "epoch": 5.9484916975878805,
      "grad_norm": 4.6268391609191895,
      "learning_rate": 2.027000846919331e-05,
      "loss": 0.706,
      "step": 561900
    },
    {
      "epoch": 5.949021019367884,
      "grad_norm": 4.714138507843018,
      "learning_rate": 2.026736184628414e-05,
      "loss": 0.6929,
      "step": 561950
    },
    {
      "epoch": 5.949550341147887,
      "grad_norm": 4.458080768585205,
      "learning_rate": 2.0264715223374976e-05,
      "loss": 0.6926,
      "step": 562000
    },
    {
      "epoch": 5.949550341147887,
      "eval_loss": 0.44293615221977234,
      "eval_runtime": 46.971,
      "eval_samples_per_second": 3575.184,
      "eval_steps_per_second": 446.914,
      "step": 562000
    },
    {
      "epoch": 5.950079662927891,
      "grad_norm": 4.025094509124756,
      "learning_rate": 2.0262068600465806e-05,
      "loss": 0.6896,
      "step": 562050
    },
    {
      "epoch": 5.950608984707894,
      "grad_norm": 4.738860130310059,
      "learning_rate": 2.025942197755664e-05,
      "loss": 0.6956,
      "step": 562100
    },
    {
      "epoch": 5.951138306487897,
      "grad_norm": 4.03850793838501,
      "learning_rate": 2.025677535464747e-05,
      "loss": 0.6896,
      "step": 562150
    },
    {
      "epoch": 5.9516676282679,
      "grad_norm": 4.172580242156982,
      "learning_rate": 2.0254128731738302e-05,
      "loss": 0.6864,
      "step": 562200
    },
    {
      "epoch": 5.952196950047903,
      "grad_norm": 4.357670307159424,
      "learning_rate": 2.0251482108829132e-05,
      "loss": 0.685,
      "step": 562250
    },
    {
      "epoch": 5.952726271827907,
      "grad_norm": 4.440158843994141,
      "learning_rate": 2.0248835485919967e-05,
      "loss": 0.6989,
      "step": 562300
    },
    {
      "epoch": 5.95325559360791,
      "grad_norm": 4.490793228149414,
      "learning_rate": 2.024624179546898e-05,
      "loss": 0.6952,
      "step": 562350
    },
    {
      "epoch": 5.953784915387914,
      "grad_norm": 4.277433395385742,
      "learning_rate": 2.0243595172559815e-05,
      "loss": 0.6986,
      "step": 562400
    },
    {
      "epoch": 5.9543142371679165,
      "grad_norm": 4.35508918762207,
      "learning_rate": 2.0240948549650646e-05,
      "loss": 0.6861,
      "step": 562450
    },
    {
      "epoch": 5.95484355894792,
      "grad_norm": 4.378445625305176,
      "learning_rate": 2.023830192674148e-05,
      "loss": 0.6797,
      "step": 562500
    },
    {
      "epoch": 5.95484355894792,
      "eval_loss": 0.4428498446941376,
      "eval_runtime": 46.6802,
      "eval_samples_per_second": 3597.457,
      "eval_steps_per_second": 449.698,
      "step": 562500
    },
    {
      "epoch": 5.955372880727923,
      "grad_norm": 4.587734699249268,
      "learning_rate": 2.023565530383231e-05,
      "loss": 0.6869,
      "step": 562550
    },
    {
      "epoch": 5.955902202507927,
      "grad_norm": 4.259744167327881,
      "learning_rate": 2.0233008680923145e-05,
      "loss": 0.7003,
      "step": 562600
    },
    {
      "epoch": 5.95643152428793,
      "grad_norm": 3.88822078704834,
      "learning_rate": 2.0230362058013976e-05,
      "loss": 0.6967,
      "step": 562650
    },
    {
      "epoch": 5.9569608460679335,
      "grad_norm": 4.196060657501221,
      "learning_rate": 2.0227715435104806e-05,
      "loss": 0.6907,
      "step": 562700
    },
    {
      "epoch": 5.957490167847936,
      "grad_norm": 4.494045257568359,
      "learning_rate": 2.0225068812195637e-05,
      "loss": 0.6764,
      "step": 562750
    },
    {
      "epoch": 5.95801948962794,
      "grad_norm": 4.587255954742432,
      "learning_rate": 2.022242218928647e-05,
      "loss": 0.6934,
      "step": 562800
    },
    {
      "epoch": 5.958548811407943,
      "grad_norm": 4.167494297027588,
      "learning_rate": 2.0219775566377302e-05,
      "loss": 0.6859,
      "step": 562850
    },
    {
      "epoch": 5.959078133187946,
      "grad_norm": 4.327068328857422,
      "learning_rate": 2.0217128943468136e-05,
      "loss": 0.6817,
      "step": 562900
    },
    {
      "epoch": 5.95960745496795,
      "grad_norm": 4.51107931137085,
      "learning_rate": 2.0214482320558967e-05,
      "loss": 0.7021,
      "step": 562950
    },
    {
      "epoch": 5.9601367767479525,
      "grad_norm": 4.178167819976807,
      "learning_rate": 2.02118356976498e-05,
      "loss": 0.6971,
      "step": 563000
    },
    {
      "epoch": 5.9601367767479525,
      "eval_loss": 0.44335708022117615,
      "eval_runtime": 46.9163,
      "eval_samples_per_second": 3579.35,
      "eval_steps_per_second": 447.435,
      "step": 563000
    },
    {
      "epoch": 5.960666098527956,
      "grad_norm": 4.1201252937316895,
      "learning_rate": 2.020918907474063e-05,
      "loss": 0.6891,
      "step": 563050
    },
    {
      "epoch": 5.961195420307959,
      "grad_norm": 4.902907848358154,
      "learning_rate": 2.0206542451831466e-05,
      "loss": 0.701,
      "step": 563100
    },
    {
      "epoch": 5.961724742087963,
      "grad_norm": 4.441278457641602,
      "learning_rate": 2.0203895828922296e-05,
      "loss": 0.6826,
      "step": 563150
    },
    {
      "epoch": 5.962254063867966,
      "grad_norm": 4.44658899307251,
      "learning_rate": 2.0201249206013127e-05,
      "loss": 0.696,
      "step": 563200
    },
    {
      "epoch": 5.9627833856479695,
      "grad_norm": 4.4495673179626465,
      "learning_rate": 2.0198602583103958e-05,
      "loss": 0.6982,
      "step": 563250
    },
    {
      "epoch": 5.963312707427972,
      "grad_norm": 4.026116847991943,
      "learning_rate": 2.0195955960194792e-05,
      "loss": 0.686,
      "step": 563300
    },
    {
      "epoch": 5.963842029207976,
      "grad_norm": 4.3421101570129395,
      "learning_rate": 2.0193309337285623e-05,
      "loss": 0.6952,
      "step": 563350
    },
    {
      "epoch": 5.964371350987979,
      "grad_norm": 4.563168525695801,
      "learning_rate": 2.0190662714376457e-05,
      "loss": 0.685,
      "step": 563400
    },
    {
      "epoch": 5.964900672767983,
      "grad_norm": 4.507934093475342,
      "learning_rate": 2.0188016091467287e-05,
      "loss": 0.691,
      "step": 563450
    },
    {
      "epoch": 5.965429994547986,
      "grad_norm": 4.244112491607666,
      "learning_rate": 2.018536946855812e-05,
      "loss": 0.6771,
      "step": 563500
    },
    {
      "epoch": 5.965429994547986,
      "eval_loss": 0.4424765408039093,
      "eval_runtime": 46.8982,
      "eval_samples_per_second": 3580.732,
      "eval_steps_per_second": 447.608,
      "step": 563500
    },
    {
      "epoch": 5.965959316327989,
      "grad_norm": 4.1475701332092285,
      "learning_rate": 2.0182722845648952e-05,
      "loss": 0.6872,
      "step": 563550
    },
    {
      "epoch": 5.966488638107992,
      "grad_norm": 3.972025156021118,
      "learning_rate": 2.0180076222739786e-05,
      "loss": 0.6909,
      "step": 563600
    },
    {
      "epoch": 5.967017959887995,
      "grad_norm": 4.449506759643555,
      "learning_rate": 2.0177429599830617e-05,
      "loss": 0.6849,
      "step": 563650
    },
    {
      "epoch": 5.967547281667999,
      "grad_norm": 4.395899772644043,
      "learning_rate": 2.017478297692145e-05,
      "loss": 0.7041,
      "step": 563700
    },
    {
      "epoch": 5.968076603448002,
      "grad_norm": 4.089498043060303,
      "learning_rate": 2.0172136354012282e-05,
      "loss": 0.6758,
      "step": 563750
    },
    {
      "epoch": 5.9686059252280055,
      "grad_norm": 4.603067398071289,
      "learning_rate": 2.0169489731103113e-05,
      "loss": 0.6964,
      "step": 563800
    },
    {
      "epoch": 5.969135247008008,
      "grad_norm": 4.529253959655762,
      "learning_rate": 2.0166843108193943e-05,
      "loss": 0.6922,
      "step": 563850
    },
    {
      "epoch": 5.969664568788012,
      "grad_norm": 4.582313060760498,
      "learning_rate": 2.0164196485284777e-05,
      "loss": 0.6967,
      "step": 563900
    },
    {
      "epoch": 5.970193890568015,
      "grad_norm": 3.9300382137298584,
      "learning_rate": 2.0161549862375608e-05,
      "loss": 0.6907,
      "step": 563950
    },
    {
      "epoch": 5.970723212348019,
      "grad_norm": 4.133846282958984,
      "learning_rate": 2.0158903239466442e-05,
      "loss": 0.6927,
      "step": 564000
    },
    {
      "epoch": 5.970723212348019,
      "eval_loss": 0.4420626759529114,
      "eval_runtime": 46.7616,
      "eval_samples_per_second": 3591.194,
      "eval_steps_per_second": 448.915,
      "step": 564000
    },
    {
      "epoch": 5.971252534128022,
      "grad_norm": 4.5473856925964355,
      "learning_rate": 2.0156256616557273e-05,
      "loss": 0.6896,
      "step": 564050
    },
    {
      "epoch": 5.971781855908025,
      "grad_norm": 4.434336185455322,
      "learning_rate": 2.0153609993648107e-05,
      "loss": 0.6934,
      "step": 564100
    },
    {
      "epoch": 5.972311177688028,
      "grad_norm": 4.322371959686279,
      "learning_rate": 2.0150963370738938e-05,
      "loss": 0.6963,
      "step": 564150
    },
    {
      "epoch": 5.972840499468032,
      "grad_norm": 4.332165241241455,
      "learning_rate": 2.0148316747829772e-05,
      "loss": 0.6918,
      "step": 564200
    },
    {
      "epoch": 5.973369821248035,
      "grad_norm": 4.575845241546631,
      "learning_rate": 2.0145670124920603e-05,
      "loss": 0.6931,
      "step": 564250
    },
    {
      "epoch": 5.973899143028039,
      "grad_norm": 4.1927666664123535,
      "learning_rate": 2.0143023502011433e-05,
      "loss": 0.6862,
      "step": 564300
    },
    {
      "epoch": 5.9744284648080415,
      "grad_norm": 4.553806304931641,
      "learning_rate": 2.0140429811560448e-05,
      "loss": 0.7009,
      "step": 564350
    },
    {
      "epoch": 5.974957786588044,
      "grad_norm": 4.632988452911377,
      "learning_rate": 2.0137783188651282e-05,
      "loss": 0.681,
      "step": 564400
    },
    {
      "epoch": 5.975487108368048,
      "grad_norm": 4.520472049713135,
      "learning_rate": 2.0135136565742113e-05,
      "loss": 0.6816,
      "step": 564450
    },
    {
      "epoch": 5.976016430148051,
      "grad_norm": 4.433657169342041,
      "learning_rate": 2.0132489942832947e-05,
      "loss": 0.6854,
      "step": 564500
    },
    {
      "epoch": 5.976016430148051,
      "eval_loss": 0.4411616921424866,
      "eval_runtime": 46.6884,
      "eval_samples_per_second": 3596.824,
      "eval_steps_per_second": 449.619,
      "step": 564500
    },
    {
      "epoch": 5.976545751928055,
      "grad_norm": 4.98991584777832,
      "learning_rate": 2.0129843319923778e-05,
      "loss": 0.6801,
      "step": 564550
    },
    {
      "epoch": 5.977075073708058,
      "grad_norm": 4.419804573059082,
      "learning_rate": 2.012719669701461e-05,
      "loss": 0.6856,
      "step": 564600
    },
    {
      "epoch": 5.977604395488061,
      "grad_norm": 4.720583438873291,
      "learning_rate": 2.0124550074105442e-05,
      "loss": 0.6856,
      "step": 564650
    },
    {
      "epoch": 5.978133717268064,
      "grad_norm": 4.8828277587890625,
      "learning_rate": 2.0121903451196277e-05,
      "loss": 0.6888,
      "step": 564700
    },
    {
      "epoch": 5.978663039048068,
      "grad_norm": 4.223510265350342,
      "learning_rate": 2.0119256828287107e-05,
      "loss": 0.679,
      "step": 564750
    },
    {
      "epoch": 5.979192360828071,
      "grad_norm": 4.470578193664551,
      "learning_rate": 2.0116610205377938e-05,
      "loss": 0.6921,
      "step": 564800
    },
    {
      "epoch": 5.979721682608075,
      "grad_norm": 4.292503833770752,
      "learning_rate": 2.011396358246877e-05,
      "loss": 0.6965,
      "step": 564850
    },
    {
      "epoch": 5.980251004388077,
      "grad_norm": 4.1809186935424805,
      "learning_rate": 2.0111316959559603e-05,
      "loss": 0.6857,
      "step": 564900
    },
    {
      "epoch": 5.980780326168081,
      "grad_norm": 4.32341194152832,
      "learning_rate": 2.0108670336650433e-05,
      "loss": 0.695,
      "step": 564950
    },
    {
      "epoch": 5.981309647948084,
      "grad_norm": 4.520301342010498,
      "learning_rate": 2.0106023713741268e-05,
      "loss": 0.6891,
      "step": 565000
    },
    {
      "epoch": 5.981309647948084,
      "eval_loss": 0.4418274760246277,
      "eval_runtime": 46.75,
      "eval_samples_per_second": 3592.086,
      "eval_steps_per_second": 449.027,
      "step": 565000
    },
    {
      "epoch": 5.981838969728088,
      "grad_norm": 4.479206085205078,
      "learning_rate": 2.0103377090832098e-05,
      "loss": 0.6803,
      "step": 565050
    },
    {
      "epoch": 5.982368291508091,
      "grad_norm": 4.698097229003906,
      "learning_rate": 2.0100730467922932e-05,
      "loss": 0.7029,
      "step": 565100
    },
    {
      "epoch": 5.9828976132880936,
      "grad_norm": 4.17912483215332,
      "learning_rate": 2.0098083845013763e-05,
      "loss": 0.6899,
      "step": 565150
    },
    {
      "epoch": 5.983426935068097,
      "grad_norm": 4.529869556427002,
      "learning_rate": 2.0095437222104597e-05,
      "loss": 0.692,
      "step": 565200
    },
    {
      "epoch": 5.9839562568481,
      "grad_norm": 4.676811218261719,
      "learning_rate": 2.0092790599195428e-05,
      "loss": 0.6997,
      "step": 565250
    },
    {
      "epoch": 5.984485578628104,
      "grad_norm": 4.377990245819092,
      "learning_rate": 2.0090143976286262e-05,
      "loss": 0.7002,
      "step": 565300
    },
    {
      "epoch": 5.985014900408107,
      "grad_norm": 4.161646366119385,
      "learning_rate": 2.0087497353377093e-05,
      "loss": 0.6866,
      "step": 565350
    },
    {
      "epoch": 5.9855442221881106,
      "grad_norm": 4.250610828399658,
      "learning_rate": 2.0084850730467923e-05,
      "loss": 0.704,
      "step": 565400
    },
    {
      "epoch": 5.986073543968113,
      "grad_norm": 4.351803302764893,
      "learning_rate": 2.0082204107558754e-05,
      "loss": 0.6927,
      "step": 565450
    },
    {
      "epoch": 5.986602865748117,
      "grad_norm": 4.744795322418213,
      "learning_rate": 2.0079557484649588e-05,
      "loss": 0.6912,
      "step": 565500
    },
    {
      "epoch": 5.986602865748117,
      "eval_loss": 0.4417813718318939,
      "eval_runtime": 46.9421,
      "eval_samples_per_second": 3577.384,
      "eval_steps_per_second": 447.189,
      "step": 565500
    },
    {
      "epoch": 5.98713218752812,
      "grad_norm": 4.286568641662598,
      "learning_rate": 2.007691086174042e-05,
      "loss": 0.686,
      "step": 565550
    },
    {
      "epoch": 5.987661509308124,
      "grad_norm": 4.181120872497559,
      "learning_rate": 2.0074264238831253e-05,
      "loss": 0.6859,
      "step": 565600
    },
    {
      "epoch": 5.988190831088127,
      "grad_norm": 4.511133670806885,
      "learning_rate": 2.0071617615922084e-05,
      "loss": 0.6792,
      "step": 565650
    },
    {
      "epoch": 5.98872015286813,
      "grad_norm": 4.374300003051758,
      "learning_rate": 2.0068970993012918e-05,
      "loss": 0.6985,
      "step": 565700
    },
    {
      "epoch": 5.989249474648133,
      "grad_norm": 4.510392665863037,
      "learning_rate": 2.006632437010375e-05,
      "loss": 0.6971,
      "step": 565750
    },
    {
      "epoch": 5.989778796428137,
      "grad_norm": 4.037047863006592,
      "learning_rate": 2.0063677747194583e-05,
      "loss": 0.6953,
      "step": 565800
    },
    {
      "epoch": 5.99030811820814,
      "grad_norm": 4.416123390197754,
      "learning_rate": 2.0061031124285413e-05,
      "loss": 0.6928,
      "step": 565850
    },
    {
      "epoch": 5.990837439988143,
      "grad_norm": 4.211750507354736,
      "learning_rate": 2.0058384501376244e-05,
      "loss": 0.7052,
      "step": 565900
    },
    {
      "epoch": 5.9913667617681465,
      "grad_norm": 4.340874671936035,
      "learning_rate": 2.0055737878467075e-05,
      "loss": 0.6902,
      "step": 565950
    },
    {
      "epoch": 5.991896083548149,
      "grad_norm": 4.533592700958252,
      "learning_rate": 2.005309125555791e-05,
      "loss": 0.6866,
      "step": 566000
    },
    {
      "epoch": 5.991896083548149,
      "eval_loss": 0.441358745098114,
      "eval_runtime": 46.7173,
      "eval_samples_per_second": 3594.598,
      "eval_steps_per_second": 449.341,
      "step": 566000
    },
    {
      "epoch": 5.992425405328153,
      "grad_norm": 4.096522331237793,
      "learning_rate": 2.005044463264874e-05,
      "loss": 0.6893,
      "step": 566050
    },
    {
      "epoch": 5.992954727108156,
      "grad_norm": 4.196484565734863,
      "learning_rate": 2.0047798009739574e-05,
      "loss": 0.6824,
      "step": 566100
    },
    {
      "epoch": 5.99348404888816,
      "grad_norm": 4.336539268493652,
      "learning_rate": 2.0045151386830404e-05,
      "loss": 0.7031,
      "step": 566150
    },
    {
      "epoch": 5.994013370668163,
      "grad_norm": 4.137914657592773,
      "learning_rate": 2.0042557696379423e-05,
      "loss": 0.6977,
      "step": 566200
    },
    {
      "epoch": 5.994542692448166,
      "grad_norm": 4.814253807067871,
      "learning_rate": 2.0039911073470253e-05,
      "loss": 0.6856,
      "step": 566250
    },
    {
      "epoch": 5.995072014228169,
      "grad_norm": 4.14508056640625,
      "learning_rate": 2.0037264450561087e-05,
      "loss": 0.6937,
      "step": 566300
    },
    {
      "epoch": 5.995601336008173,
      "grad_norm": 4.411012649536133,
      "learning_rate": 2.0034617827651918e-05,
      "loss": 0.6851,
      "step": 566350
    },
    {
      "epoch": 5.996130657788176,
      "grad_norm": 4.006858825683594,
      "learning_rate": 2.003197120474275e-05,
      "loss": 0.6863,
      "step": 566400
    },
    {
      "epoch": 5.99665997956818,
      "grad_norm": 4.3984808921813965,
      "learning_rate": 2.002932458183358e-05,
      "loss": 0.7024,
      "step": 566450
    },
    {
      "epoch": 5.9971893013481825,
      "grad_norm": 4.352996826171875,
      "learning_rate": 2.0026677958924414e-05,
      "loss": 0.6915,
      "step": 566500
    },
    {
      "epoch": 5.9971893013481825,
      "eval_loss": 0.44257181882858276,
      "eval_runtime": 46.7253,
      "eval_samples_per_second": 3593.984,
      "eval_steps_per_second": 449.264,
      "step": 566500
    },
    {
      "epoch": 5.997718623128186,
      "grad_norm": 4.310006618499756,
      "learning_rate": 2.0024031336015244e-05,
      "loss": 0.6952,
      "step": 566550
    },
    {
      "epoch": 5.998247944908189,
      "grad_norm": 3.9207041263580322,
      "learning_rate": 2.002138471310608e-05,
      "loss": 0.69,
      "step": 566600
    },
    {
      "epoch": 5.998777266688192,
      "grad_norm": 4.35586404800415,
      "learning_rate": 2.001873809019691e-05,
      "loss": 0.6893,
      "step": 566650
    },
    {
      "epoch": 5.999306588468196,
      "grad_norm": 4.0718865394592285,
      "learning_rate": 2.0016091467287743e-05,
      "loss": 0.682,
      "step": 566700
    },
    {
      "epoch": 5.999835910248199,
      "grad_norm": 4.122807025909424,
      "learning_rate": 2.0013444844378574e-05,
      "loss": 0.6806,
      "step": 566750
    },
    {
      "epoch": 6.000359938810402,
      "grad_norm": 4.024821758270264,
      "learning_rate": 2.0010798221469408e-05,
      "loss": 0.6776,
      "step": 566800
    },
    {
      "epoch": 6.000889260590405,
      "grad_norm": 4.6680803298950195,
      "learning_rate": 2.000815159856024e-05,
      "loss": 0.6898,
      "step": 566850
    },
    {
      "epoch": 6.001418582370409,
      "grad_norm": 4.048699378967285,
      "learning_rate": 2.000550497565107e-05,
      "loss": 0.6846,
      "step": 566900
    },
    {
      "epoch": 6.001947904150412,
      "grad_norm": 4.6936798095703125,
      "learning_rate": 2.00028583527419e-05,
      "loss": 0.6871,
      "step": 566950
    },
    {
      "epoch": 6.0024772259304155,
      "grad_norm": 4.112196922302246,
      "learning_rate": 2.0000211729832734e-05,
      "loss": 0.6857,
      "step": 567000
    },
    {
      "epoch": 6.0024772259304155,
      "eval_loss": 0.4398006796836853,
      "eval_runtime": 46.6954,
      "eval_samples_per_second": 3596.284,
      "eval_steps_per_second": 449.552,
      "step": 567000
    },
    {
      "epoch": 6.003006547710418,
      "grad_norm": 4.813040733337402,
      "learning_rate": 1.9997565106923565e-05,
      "loss": 0.6968,
      "step": 567050
    },
    {
      "epoch": 6.003535869490422,
      "grad_norm": 4.499081134796143,
      "learning_rate": 1.99949184840144e-05,
      "loss": 0.68,
      "step": 567100
    },
    {
      "epoch": 6.004065191270425,
      "grad_norm": 4.399425029754639,
      "learning_rate": 1.999227186110523e-05,
      "loss": 0.6991,
      "step": 567150
    },
    {
      "epoch": 6.004594513050429,
      "grad_norm": 4.328185558319092,
      "learning_rate": 1.9989625238196064e-05,
      "loss": 0.677,
      "step": 567200
    },
    {
      "epoch": 6.005123834830432,
      "grad_norm": 4.102965354919434,
      "learning_rate": 1.9986978615286895e-05,
      "loss": 0.6849,
      "step": 567250
    },
    {
      "epoch": 6.005653156610435,
      "grad_norm": 4.766617298126221,
      "learning_rate": 1.998433199237773e-05,
      "loss": 0.6828,
      "step": 567300
    },
    {
      "epoch": 6.006182478390438,
      "grad_norm": 4.720361709594727,
      "learning_rate": 1.998168536946856e-05,
      "loss": 0.6983,
      "step": 567350
    },
    {
      "epoch": 6.006711800170442,
      "grad_norm": 4.5034871101379395,
      "learning_rate": 1.9979038746559393e-05,
      "loss": 0.6816,
      "step": 567400
    },
    {
      "epoch": 6.007241121950445,
      "grad_norm": 4.499335289001465,
      "learning_rate": 1.9976392123650224e-05,
      "loss": 0.6868,
      "step": 567450
    },
    {
      "epoch": 6.007770443730448,
      "grad_norm": 4.085210800170898,
      "learning_rate": 1.9973745500741055e-05,
      "loss": 0.6955,
      "step": 567500
    },
    {
      "epoch": 6.007770443730448,
      "eval_loss": 0.44019615650177,
      "eval_runtime": 46.7605,
      "eval_samples_per_second": 3591.277,
      "eval_steps_per_second": 448.926,
      "step": 567500
    },
    {
      "epoch": 6.0082997655104515,
      "grad_norm": 4.383159160614014,
      "learning_rate": 1.9971098877831886e-05,
      "loss": 0.7034,
      "step": 567550
    },
    {
      "epoch": 6.008829087290454,
      "grad_norm": 3.973568916320801,
      "learning_rate": 1.996845225492272e-05,
      "loss": 0.6923,
      "step": 567600
    },
    {
      "epoch": 6.009358409070458,
      "grad_norm": 4.367507457733154,
      "learning_rate": 1.996580563201355e-05,
      "loss": 0.6798,
      "step": 567650
    },
    {
      "epoch": 6.009887730850461,
      "grad_norm": 4.530691146850586,
      "learning_rate": 1.9963159009104385e-05,
      "loss": 0.6899,
      "step": 567700
    },
    {
      "epoch": 6.010417052630465,
      "grad_norm": 3.865328550338745,
      "learning_rate": 1.9960512386195215e-05,
      "loss": 0.6885,
      "step": 567750
    },
    {
      "epoch": 6.010946374410468,
      "grad_norm": 4.267277240753174,
      "learning_rate": 1.995786576328605e-05,
      "loss": 0.6837,
      "step": 567800
    },
    {
      "epoch": 6.011475696190471,
      "grad_norm": 4.530782222747803,
      "learning_rate": 1.995521914037688e-05,
      "loss": 0.6707,
      "step": 567850
    },
    {
      "epoch": 6.012005017970474,
      "grad_norm": 4.676555633544922,
      "learning_rate": 1.9952572517467714e-05,
      "loss": 0.6892,
      "step": 567900
    },
    {
      "epoch": 6.012534339750478,
      "grad_norm": 3.978764295578003,
      "learning_rate": 1.9949925894558545e-05,
      "loss": 0.6913,
      "step": 567950
    },
    {
      "epoch": 6.013063661530481,
      "grad_norm": 4.026329040527344,
      "learning_rate": 1.9947279271649376e-05,
      "loss": 0.6931,
      "step": 568000
    },
    {
      "epoch": 6.013063661530481,
      "eval_loss": 0.4406979978084564,
      "eval_runtime": 46.7074,
      "eval_samples_per_second": 3595.359,
      "eval_steps_per_second": 449.436,
      "step": 568000
    },
    {
      "epoch": 6.013592983310485,
      "grad_norm": 4.309658527374268,
      "learning_rate": 1.994463264874021e-05,
      "loss": 0.6997,
      "step": 568050
    },
    {
      "epoch": 6.0141223050904875,
      "grad_norm": 4.023979663848877,
      "learning_rate": 1.994198602583104e-05,
      "loss": 0.6822,
      "step": 568100
    },
    {
      "epoch": 6.014651626870491,
      "grad_norm": 3.930525302886963,
      "learning_rate": 1.993933940292187e-05,
      "loss": 0.6937,
      "step": 568150
    },
    {
      "epoch": 6.015180948650494,
      "grad_norm": 4.383278846740723,
      "learning_rate": 1.9936692780012705e-05,
      "loss": 0.6771,
      "step": 568200
    },
    {
      "epoch": 6.015710270430497,
      "grad_norm": 4.103165626525879,
      "learning_rate": 1.9934046157103536e-05,
      "loss": 0.6963,
      "step": 568250
    },
    {
      "epoch": 6.016239592210501,
      "grad_norm": 4.125873565673828,
      "learning_rate": 1.993139953419437e-05,
      "loss": 0.6827,
      "step": 568300
    },
    {
      "epoch": 6.016768913990504,
      "grad_norm": 4.4132914543151855,
      "learning_rate": 1.99287529112852e-05,
      "loss": 0.6934,
      "step": 568350
    },
    {
      "epoch": 6.017298235770507,
      "grad_norm": 4.560437202453613,
      "learning_rate": 1.9926106288376035e-05,
      "loss": 0.6888,
      "step": 568400
    },
    {
      "epoch": 6.01782755755051,
      "grad_norm": 4.379685878753662,
      "learning_rate": 1.9923459665466866e-05,
      "loss": 0.6753,
      "step": 568450
    },
    {
      "epoch": 6.018356879330514,
      "grad_norm": 4.490746021270752,
      "learning_rate": 1.99208130425577e-05,
      "loss": 0.6717,
      "step": 568500
    },
    {
      "epoch": 6.018356879330514,
      "eval_loss": 0.43954312801361084,
      "eval_runtime": 46.8937,
      "eval_samples_per_second": 3581.077,
      "eval_steps_per_second": 447.651,
      "step": 568500
    },
    {
      "epoch": 6.018886201110517,
      "grad_norm": 4.641060829162598,
      "learning_rate": 1.991816641964853e-05,
      "loss": 0.6886,
      "step": 568550
    },
    {
      "epoch": 6.019415522890521,
      "grad_norm": 4.548968315124512,
      "learning_rate": 1.991551979673936e-05,
      "loss": 0.687,
      "step": 568600
    },
    {
      "epoch": 6.0199448446705235,
      "grad_norm": 4.462634086608887,
      "learning_rate": 1.9912873173830192e-05,
      "loss": 0.6755,
      "step": 568650
    },
    {
      "epoch": 6.020474166450527,
      "grad_norm": 4.467024326324463,
      "learning_rate": 1.9910226550921026e-05,
      "loss": 0.6932,
      "step": 568700
    },
    {
      "epoch": 6.02100348823053,
      "grad_norm": 4.4811882972717285,
      "learning_rate": 1.9907579928011857e-05,
      "loss": 0.6947,
      "step": 568750
    },
    {
      "epoch": 6.021532810010534,
      "grad_norm": 4.775867462158203,
      "learning_rate": 1.990493330510269e-05,
      "loss": 0.6835,
      "step": 568800
    },
    {
      "epoch": 6.022062131790537,
      "grad_norm": 4.396549224853516,
      "learning_rate": 1.990228668219352e-05,
      "loss": 0.6783,
      "step": 568850
    },
    {
      "epoch": 6.0225914535705405,
      "grad_norm": 4.549607276916504,
      "learning_rate": 1.9899640059284355e-05,
      "loss": 0.7007,
      "step": 568900
    },
    {
      "epoch": 6.023120775350543,
      "grad_norm": 4.246057033538818,
      "learning_rate": 1.9896993436375186e-05,
      "loss": 0.6678,
      "step": 568950
    },
    {
      "epoch": 6.023650097130546,
      "grad_norm": 4.214745998382568,
      "learning_rate": 1.989434681346602e-05,
      "loss": 0.6743,
      "step": 569000
    },
    {
      "epoch": 6.023650097130546,
      "eval_loss": 0.4409307539463043,
      "eval_runtime": 46.718,
      "eval_samples_per_second": 3594.544,
      "eval_steps_per_second": 449.334,
      "step": 569000
    },
    {
      "epoch": 6.02417941891055,
      "grad_norm": 4.995954990386963,
      "learning_rate": 1.989170019055685e-05,
      "loss": 0.6854,
      "step": 569050
    },
    {
      "epoch": 6.024708740690553,
      "grad_norm": 4.513095855712891,
      "learning_rate": 1.9889053567647685e-05,
      "loss": 0.6851,
      "step": 569100
    },
    {
      "epoch": 6.025238062470557,
      "grad_norm": 4.387153625488281,
      "learning_rate": 1.9886406944738516e-05,
      "loss": 0.6882,
      "step": 569150
    },
    {
      "epoch": 6.0257673842505595,
      "grad_norm": 4.127532482147217,
      "learning_rate": 1.9883760321829347e-05,
      "loss": 0.6856,
      "step": 569200
    },
    {
      "epoch": 6.026296706030563,
      "grad_norm": 4.495281219482422,
      "learning_rate": 1.9881113698920177e-05,
      "loss": 0.6951,
      "step": 569250
    },
    {
      "epoch": 6.026826027810566,
      "grad_norm": 4.323101043701172,
      "learning_rate": 1.987846707601101e-05,
      "loss": 0.699,
      "step": 569300
    },
    {
      "epoch": 6.02735534959057,
      "grad_norm": 4.132328510284424,
      "learning_rate": 1.9875820453101842e-05,
      "loss": 0.6896,
      "step": 569350
    },
    {
      "epoch": 6.027884671370573,
      "grad_norm": 4.225967884063721,
      "learning_rate": 1.9873173830192676e-05,
      "loss": 0.696,
      "step": 569400
    },
    {
      "epoch": 6.0284139931505765,
      "grad_norm": 4.33400297164917,
      "learning_rate": 1.9870527207283507e-05,
      "loss": 0.6934,
      "step": 569450
    },
    {
      "epoch": 6.028943314930579,
      "grad_norm": 4.307099342346191,
      "learning_rate": 1.986788058437434e-05,
      "loss": 0.6849,
      "step": 569500
    },
    {
      "epoch": 6.028943314930579,
      "eval_loss": 0.43927398324012756,
      "eval_runtime": 46.6503,
      "eval_samples_per_second": 3599.765,
      "eval_steps_per_second": 449.987,
      "step": 569500
    },
    {
      "epoch": 6.029472636710583,
      "grad_norm": 3.931549310684204,
      "learning_rate": 1.986523396146517e-05,
      "loss": 0.6768,
      "step": 569550
    },
    {
      "epoch": 6.030001958490586,
      "grad_norm": 4.251130104064941,
      "learning_rate": 1.9862587338556006e-05,
      "loss": 0.685,
      "step": 569600
    },
    {
      "epoch": 6.03053128027059,
      "grad_norm": 4.392276287078857,
      "learning_rate": 1.9859940715646836e-05,
      "loss": 0.6836,
      "step": 569650
    },
    {
      "epoch": 6.031060602050593,
      "grad_norm": 4.554547309875488,
      "learning_rate": 1.9857294092737667e-05,
      "loss": 0.6786,
      "step": 569700
    },
    {
      "epoch": 6.0315899238305954,
      "grad_norm": 4.550883769989014,
      "learning_rate": 1.9854647469828498e-05,
      "loss": 0.6989,
      "step": 569750
    },
    {
      "epoch": 6.032119245610599,
      "grad_norm": 4.501216411590576,
      "learning_rate": 1.9852000846919332e-05,
      "loss": 0.6905,
      "step": 569800
    },
    {
      "epoch": 6.032648567390602,
      "grad_norm": 4.562084197998047,
      "learning_rate": 1.9849354224010163e-05,
      "loss": 0.6897,
      "step": 569850
    },
    {
      "epoch": 6.033177889170606,
      "grad_norm": 4.647520065307617,
      "learning_rate": 1.9846707601100997e-05,
      "loss": 0.6896,
      "step": 569900
    },
    {
      "epoch": 6.033707210950609,
      "grad_norm": 4.3531622886657715,
      "learning_rate": 1.9844060978191828e-05,
      "loss": 0.6842,
      "step": 569950
    },
    {
      "epoch": 6.0342365327306124,
      "grad_norm": 4.265176296234131,
      "learning_rate": 1.984141435528266e-05,
      "loss": 0.7105,
      "step": 570000
    },
    {
      "epoch": 6.0342365327306124,
      "eval_loss": 0.4412480294704437,
      "eval_runtime": 46.7436,
      "eval_samples_per_second": 3592.577,
      "eval_steps_per_second": 449.088,
      "step": 570000
    },
    {
      "epoch": 6.034765854510615,
      "grad_norm": 4.381361484527588,
      "learning_rate": 1.9838767732373492e-05,
      "loss": 0.6812,
      "step": 570050
    },
    {
      "epoch": 6.035295176290619,
      "grad_norm": 4.419617652893066,
      "learning_rate": 1.9836121109464326e-05,
      "loss": 0.6828,
      "step": 570100
    },
    {
      "epoch": 6.035824498070622,
      "grad_norm": 4.578431129455566,
      "learning_rate": 1.9833474486555157e-05,
      "loss": 0.6776,
      "step": 570150
    },
    {
      "epoch": 6.036353819850626,
      "grad_norm": 4.488367557525635,
      "learning_rate": 1.9830880796104172e-05,
      "loss": 0.6888,
      "step": 570200
    },
    {
      "epoch": 6.036883141630629,
      "grad_norm": 4.252301216125488,
      "learning_rate": 1.9828234173195003e-05,
      "loss": 0.6835,
      "step": 570250
    },
    {
      "epoch": 6.037412463410632,
      "grad_norm": 4.313953399658203,
      "learning_rate": 1.9825587550285837e-05,
      "loss": 0.6823,
      "step": 570300
    },
    {
      "epoch": 6.037941785190635,
      "grad_norm": 4.630578994750977,
      "learning_rate": 1.9822940927376667e-05,
      "loss": 0.6958,
      "step": 570350
    },
    {
      "epoch": 6.038471106970639,
      "grad_norm": 4.123923301696777,
      "learning_rate": 1.98202943044675e-05,
      "loss": 0.6749,
      "step": 570400
    },
    {
      "epoch": 6.039000428750642,
      "grad_norm": 4.5078229904174805,
      "learning_rate": 1.9817647681558332e-05,
      "loss": 0.6785,
      "step": 570450
    },
    {
      "epoch": 6.039529750530645,
      "grad_norm": 4.367307662963867,
      "learning_rate": 1.9815001058649166e-05,
      "loss": 0.688,
      "step": 570500
    },
    {
      "epoch": 6.039529750530645,
      "eval_loss": 0.4396872818470001,
      "eval_runtime": 46.7939,
      "eval_samples_per_second": 3588.712,
      "eval_steps_per_second": 448.605,
      "step": 570500
    },
    {
      "epoch": 6.040059072310648,
      "grad_norm": 4.415841579437256,
      "learning_rate": 1.9812354435739997e-05,
      "loss": 0.6826,
      "step": 570550
    },
    {
      "epoch": 6.040588394090651,
      "grad_norm": 4.836193084716797,
      "learning_rate": 1.980970781283083e-05,
      "loss": 0.6948,
      "step": 570600
    },
    {
      "epoch": 6.041117715870655,
      "grad_norm": 4.420752048492432,
      "learning_rate": 1.9807061189921662e-05,
      "loss": 0.6856,
      "step": 570650
    },
    {
      "epoch": 6.041647037650658,
      "grad_norm": 4.089151859283447,
      "learning_rate": 1.9804414567012493e-05,
      "loss": 0.6849,
      "step": 570700
    },
    {
      "epoch": 6.042176359430662,
      "grad_norm": 3.8799421787261963,
      "learning_rate": 1.9801767944103323e-05,
      "loss": 0.6754,
      "step": 570750
    },
    {
      "epoch": 6.0427056812106645,
      "grad_norm": 4.376240253448486,
      "learning_rate": 1.9799121321194157e-05,
      "loss": 0.6837,
      "step": 570800
    },
    {
      "epoch": 6.043235002990668,
      "grad_norm": 4.532247066497803,
      "learning_rate": 1.9796474698284988e-05,
      "loss": 0.6815,
      "step": 570850
    },
    {
      "epoch": 6.043764324770671,
      "grad_norm": 4.413787364959717,
      "learning_rate": 1.9793828075375822e-05,
      "loss": 0.6826,
      "step": 570900
    },
    {
      "epoch": 6.044293646550675,
      "grad_norm": 3.914640426635742,
      "learning_rate": 1.9791181452466653e-05,
      "loss": 0.6841,
      "step": 570950
    },
    {
      "epoch": 6.044822968330678,
      "grad_norm": 4.444878101348877,
      "learning_rate": 1.9788534829557487e-05,
      "loss": 0.684,
      "step": 571000
    },
    {
      "epoch": 6.044822968330678,
      "eval_loss": 0.43940839171409607,
      "eval_runtime": 46.78,
      "eval_samples_per_second": 3589.781,
      "eval_steps_per_second": 448.739,
      "step": 571000
    },
    {
      "epoch": 6.0453522901106815,
      "grad_norm": 4.1018500328063965,
      "learning_rate": 1.9785888206648318e-05,
      "loss": 0.6933,
      "step": 571050
    },
    {
      "epoch": 6.045881611890684,
      "grad_norm": 4.381345272064209,
      "learning_rate": 1.9783241583739152e-05,
      "loss": 0.6795,
      "step": 571100
    },
    {
      "epoch": 6.046410933670688,
      "grad_norm": 4.556371212005615,
      "learning_rate": 1.9780594960829983e-05,
      "loss": 0.688,
      "step": 571150
    },
    {
      "epoch": 6.046940255450691,
      "grad_norm": 3.894155740737915,
      "learning_rate": 1.9777948337920817e-05,
      "loss": 0.6871,
      "step": 571200
    },
    {
      "epoch": 6.047469577230694,
      "grad_norm": 4.079930305480957,
      "learning_rate": 1.9775301715011647e-05,
      "loss": 0.6858,
      "step": 571250
    },
    {
      "epoch": 6.047998899010698,
      "grad_norm": 3.940467357635498,
      "learning_rate": 1.9772655092102478e-05,
      "loss": 0.6847,
      "step": 571300
    },
    {
      "epoch": 6.0485282207907005,
      "grad_norm": 3.8231773376464844,
      "learning_rate": 1.977000846919331e-05,
      "loss": 0.6807,
      "step": 571350
    },
    {
      "epoch": 6.049057542570704,
      "grad_norm": 4.581838607788086,
      "learning_rate": 1.9767361846284143e-05,
      "loss": 0.6779,
      "step": 571400
    },
    {
      "epoch": 6.049586864350707,
      "grad_norm": 4.146119594573975,
      "learning_rate": 1.9764715223374974e-05,
      "loss": 0.6862,
      "step": 571450
    },
    {
      "epoch": 6.050116186130711,
      "grad_norm": 4.736896991729736,
      "learning_rate": 1.9762068600465808e-05,
      "loss": 0.6877,
      "step": 571500
    },
    {
      "epoch": 6.050116186130711,
      "eval_loss": 0.43900057673454285,
      "eval_runtime": 47.1254,
      "eval_samples_per_second": 3563.47,
      "eval_steps_per_second": 445.45,
      "step": 571500
    },
    {
      "epoch": 6.050645507910714,
      "grad_norm": 4.469282150268555,
      "learning_rate": 1.975942197755664e-05,
      "loss": 0.6902,
      "step": 571550
    },
    {
      "epoch": 6.0511748296907175,
      "grad_norm": 4.363553524017334,
      "learning_rate": 1.9756775354647472e-05,
      "loss": 0.6897,
      "step": 571600
    },
    {
      "epoch": 6.05170415147072,
      "grad_norm": 4.269186019897461,
      "learning_rate": 1.9754128731738303e-05,
      "loss": 0.6983,
      "step": 571650
    },
    {
      "epoch": 6.052233473250724,
      "grad_norm": 4.254805088043213,
      "learning_rate": 1.9751482108829137e-05,
      "loss": 0.6921,
      "step": 571700
    },
    {
      "epoch": 6.052762795030727,
      "grad_norm": 4.355597496032715,
      "learning_rate": 1.9748835485919968e-05,
      "loss": 0.6754,
      "step": 571750
    },
    {
      "epoch": 6.053292116810731,
      "grad_norm": 4.668277740478516,
      "learning_rate": 1.9746188863010802e-05,
      "loss": 0.6788,
      "step": 571800
    },
    {
      "epoch": 6.053821438590734,
      "grad_norm": 4.19558572769165,
      "learning_rate": 1.9743542240101633e-05,
      "loss": 0.686,
      "step": 571850
    },
    {
      "epoch": 6.054350760370737,
      "grad_norm": 4.181960582733154,
      "learning_rate": 1.9740895617192464e-05,
      "loss": 0.6767,
      "step": 571900
    },
    {
      "epoch": 6.05488008215074,
      "grad_norm": 4.319942951202393,
      "learning_rate": 1.9738248994283294e-05,
      "loss": 0.6815,
      "step": 571950
    },
    {
      "epoch": 6.055409403930743,
      "grad_norm": 4.153578758239746,
      "learning_rate": 1.973560237137413e-05,
      "loss": 0.6783,
      "step": 572000
    },
    {
      "epoch": 6.055409403930743,
      "eval_loss": 0.4396819472312927,
      "eval_runtime": 46.7501,
      "eval_samples_per_second": 3592.074,
      "eval_steps_per_second": 449.025,
      "step": 572000
    },
    {
      "epoch": 6.055938725710747,
      "grad_norm": 4.5021185874938965,
      "learning_rate": 1.973295574846496e-05,
      "loss": 0.7017,
      "step": 572050
    },
    {
      "epoch": 6.05646804749075,
      "grad_norm": 4.344376564025879,
      "learning_rate": 1.9730309125555793e-05,
      "loss": 0.6948,
      "step": 572100
    },
    {
      "epoch": 6.0569973692707535,
      "grad_norm": 4.229635238647461,
      "learning_rate": 1.9727662502646624e-05,
      "loss": 0.6741,
      "step": 572150
    },
    {
      "epoch": 6.057526691050756,
      "grad_norm": 4.051211833953857,
      "learning_rate": 1.9725068812195642e-05,
      "loss": 0.6902,
      "step": 572200
    },
    {
      "epoch": 6.05805601283076,
      "grad_norm": 4.640078544616699,
      "learning_rate": 1.9722422189286473e-05,
      "loss": 0.6986,
      "step": 572250
    },
    {
      "epoch": 6.058585334610763,
      "grad_norm": 4.4965643882751465,
      "learning_rate": 1.9719775566377303e-05,
      "loss": 0.6908,
      "step": 572300
    },
    {
      "epoch": 6.059114656390767,
      "grad_norm": 4.38396692276001,
      "learning_rate": 1.9717128943468134e-05,
      "loss": 0.6854,
      "step": 572350
    },
    {
      "epoch": 6.05964397817077,
      "grad_norm": 4.5120038986206055,
      "learning_rate": 1.9714482320558968e-05,
      "loss": 0.6908,
      "step": 572400
    },
    {
      "epoch": 6.060173299950773,
      "grad_norm": 4.588768005371094,
      "learning_rate": 1.97118356976498e-05,
      "loss": 0.6867,
      "step": 572450
    },
    {
      "epoch": 6.060702621730776,
      "grad_norm": 4.28743839263916,
      "learning_rate": 1.9709189074740633e-05,
      "loss": 0.67,
      "step": 572500
    },
    {
      "epoch": 6.060702621730776,
      "eval_loss": 0.4384683072566986,
      "eval_runtime": 46.7922,
      "eval_samples_per_second": 3588.847,
      "eval_steps_per_second": 448.622,
      "step": 572500
    },
    {
      "epoch": 6.06123194351078,
      "grad_norm": 4.382476806640625,
      "learning_rate": 1.9706542451831464e-05,
      "loss": 0.6958,
      "step": 572550
    },
    {
      "epoch": 6.061761265290783,
      "grad_norm": 4.440374374389648,
      "learning_rate": 1.9703895828922298e-05,
      "loss": 0.6948,
      "step": 572600
    },
    {
      "epoch": 6.062290587070787,
      "grad_norm": 4.360757827758789,
      "learning_rate": 1.970124920601313e-05,
      "loss": 0.6914,
      "step": 572650
    },
    {
      "epoch": 6.0628199088507895,
      "grad_norm": 4.468200206756592,
      "learning_rate": 1.9698602583103963e-05,
      "loss": 0.6796,
      "step": 572700
    },
    {
      "epoch": 6.063349230630792,
      "grad_norm": 4.859745025634766,
      "learning_rate": 1.9695955960194793e-05,
      "loss": 0.6838,
      "step": 572750
    },
    {
      "epoch": 6.063878552410796,
      "grad_norm": 4.378284931182861,
      "learning_rate": 1.9693309337285624e-05,
      "loss": 0.6914,
      "step": 572800
    },
    {
      "epoch": 6.064407874190799,
      "grad_norm": 4.098981857299805,
      "learning_rate": 1.9690662714376458e-05,
      "loss": 0.6847,
      "step": 572850
    },
    {
      "epoch": 6.064937195970803,
      "grad_norm": 3.9916834831237793,
      "learning_rate": 1.968801609146729e-05,
      "loss": 0.687,
      "step": 572900
    },
    {
      "epoch": 6.065466517750806,
      "grad_norm": 4.569443225860596,
      "learning_rate": 1.968536946855812e-05,
      "loss": 0.695,
      "step": 572950
    },
    {
      "epoch": 6.065995839530809,
      "grad_norm": 4.282810211181641,
      "learning_rate": 1.968272284564895e-05,
      "loss": 0.6768,
      "step": 573000
    },
    {
      "epoch": 6.065995839530809,
      "eval_loss": 0.43930599093437195,
      "eval_runtime": 46.7618,
      "eval_samples_per_second": 3591.176,
      "eval_steps_per_second": 448.913,
      "step": 573000
    },
    {
      "epoch": 6.066525161310812,
      "grad_norm": 4.568007946014404,
      "learning_rate": 1.9680076222739784e-05,
      "loss": 0.6862,
      "step": 573050
    },
    {
      "epoch": 6.067054483090816,
      "grad_norm": 4.834469795227051,
      "learning_rate": 1.9677429599830615e-05,
      "loss": 0.6723,
      "step": 573100
    },
    {
      "epoch": 6.067583804870819,
      "grad_norm": 4.710555076599121,
      "learning_rate": 1.967478297692145e-05,
      "loss": 0.6697,
      "step": 573150
    },
    {
      "epoch": 6.068113126650823,
      "grad_norm": 4.0548787117004395,
      "learning_rate": 1.967213635401228e-05,
      "loss": 0.6792,
      "step": 573200
    },
    {
      "epoch": 6.0686424484308255,
      "grad_norm": 4.517435550689697,
      "learning_rate": 1.9669489731103114e-05,
      "loss": 0.68,
      "step": 573250
    },
    {
      "epoch": 6.069171770210829,
      "grad_norm": 4.035017013549805,
      "learning_rate": 1.9666843108193945e-05,
      "loss": 0.6893,
      "step": 573300
    },
    {
      "epoch": 6.069701091990832,
      "grad_norm": 4.818398952484131,
      "learning_rate": 1.966419648528478e-05,
      "loss": 0.6982,
      "step": 573350
    },
    {
      "epoch": 6.070230413770836,
      "grad_norm": 4.476346015930176,
      "learning_rate": 1.966154986237561e-05,
      "loss": 0.6888,
      "step": 573400
    },
    {
      "epoch": 6.070759735550839,
      "grad_norm": 4.324986934661865,
      "learning_rate": 1.965890323946644e-05,
      "loss": 0.6795,
      "step": 573450
    },
    {
      "epoch": 6.071289057330842,
      "grad_norm": 4.330350875854492,
      "learning_rate": 1.965625661655727e-05,
      "loss": 0.6884,
      "step": 573500
    },
    {
      "epoch": 6.071289057330842,
      "eval_loss": 0.4381762444972992,
      "eval_runtime": 47.0312,
      "eval_samples_per_second": 3570.61,
      "eval_steps_per_second": 446.342,
      "step": 573500
    },
    {
      "epoch": 6.071818379110845,
      "grad_norm": 4.261615753173828,
      "learning_rate": 1.9653609993648105e-05,
      "loss": 0.6943,
      "step": 573550
    },
    {
      "epoch": 6.072347700890848,
      "grad_norm": 4.226328372955322,
      "learning_rate": 1.9650963370738936e-05,
      "loss": 0.684,
      "step": 573600
    },
    {
      "epoch": 6.072877022670852,
      "grad_norm": 3.855490207672119,
      "learning_rate": 1.964831674782977e-05,
      "loss": 0.6867,
      "step": 573650
    },
    {
      "epoch": 6.073406344450855,
      "grad_norm": 4.1653218269348145,
      "learning_rate": 1.96456701249206e-05,
      "loss": 0.6765,
      "step": 573700
    },
    {
      "epoch": 6.073935666230859,
      "grad_norm": 4.313581466674805,
      "learning_rate": 1.9643023502011435e-05,
      "loss": 0.692,
      "step": 573750
    },
    {
      "epoch": 6.074464988010861,
      "grad_norm": 4.123417377471924,
      "learning_rate": 1.9640376879102265e-05,
      "loss": 0.685,
      "step": 573800
    },
    {
      "epoch": 6.074994309790865,
      "grad_norm": 4.305220127105713,
      "learning_rate": 1.96377302561931e-05,
      "loss": 0.6762,
      "step": 573850
    },
    {
      "epoch": 6.075523631570868,
      "grad_norm": 3.86521577835083,
      "learning_rate": 1.963508363328393e-05,
      "loss": 0.6807,
      "step": 573900
    },
    {
      "epoch": 6.076052953350872,
      "grad_norm": 4.21755838394165,
      "learning_rate": 1.9632437010374764e-05,
      "loss": 0.675,
      "step": 573950
    },
    {
      "epoch": 6.076582275130875,
      "grad_norm": 4.298092365264893,
      "learning_rate": 1.9629790387465595e-05,
      "loss": 0.6869,
      "step": 574000
    },
    {
      "epoch": 6.076582275130875,
      "eval_loss": 0.43823984265327454,
      "eval_runtime": 46.7269,
      "eval_samples_per_second": 3593.864,
      "eval_steps_per_second": 449.249,
      "step": 574000
    },
    {
      "epoch": 6.077111596910878,
      "grad_norm": 4.455111026763916,
      "learning_rate": 1.9627143764556426e-05,
      "loss": 0.6782,
      "step": 574050
    },
    {
      "epoch": 6.077640918690881,
      "grad_norm": 4.650084018707275,
      "learning_rate": 1.9624497141647256e-05,
      "loss": 0.6807,
      "step": 574100
    },
    {
      "epoch": 6.078170240470885,
      "grad_norm": 4.216429710388184,
      "learning_rate": 1.962185051873809e-05,
      "loss": 0.6928,
      "step": 574150
    },
    {
      "epoch": 6.078699562250888,
      "grad_norm": 4.139990329742432,
      "learning_rate": 1.9619256828287105e-05,
      "loss": 0.6732,
      "step": 574200
    },
    {
      "epoch": 6.079228884030891,
      "grad_norm": 4.525851726531982,
      "learning_rate": 1.961661020537794e-05,
      "loss": 0.683,
      "step": 574250
    },
    {
      "epoch": 6.0797582058108945,
      "grad_norm": 4.223682880401611,
      "learning_rate": 1.961396358246877e-05,
      "loss": 0.693,
      "step": 574300
    },
    {
      "epoch": 6.080287527590897,
      "grad_norm": 4.05661678314209,
      "learning_rate": 1.9611316959559604e-05,
      "loss": 0.6867,
      "step": 574350
    },
    {
      "epoch": 6.080816849370901,
      "grad_norm": 4.487431526184082,
      "learning_rate": 1.9608670336650435e-05,
      "loss": 0.6842,
      "step": 574400
    },
    {
      "epoch": 6.081346171150904,
      "grad_norm": 4.6681365966796875,
      "learning_rate": 1.9606023713741266e-05,
      "loss": 0.6844,
      "step": 574450
    },
    {
      "epoch": 6.081875492930908,
      "grad_norm": 4.112815856933594,
      "learning_rate": 1.9603377090832096e-05,
      "loss": 0.6816,
      "step": 574500
    },
    {
      "epoch": 6.081875492930908,
      "eval_loss": 0.4385136663913727,
      "eval_runtime": 46.7516,
      "eval_samples_per_second": 3591.962,
      "eval_steps_per_second": 449.011,
      "step": 574500
    },
    {
      "epoch": 6.082404814710911,
      "grad_norm": 4.6019439697265625,
      "learning_rate": 1.960073046792293e-05,
      "loss": 0.6845,
      "step": 574550
    },
    {
      "epoch": 6.082934136490914,
      "grad_norm": 4.882138729095459,
      "learning_rate": 1.959808384501376e-05,
      "loss": 0.6866,
      "step": 574600
    },
    {
      "epoch": 6.083463458270917,
      "grad_norm": 4.61422061920166,
      "learning_rate": 1.9595437222104595e-05,
      "loss": 0.6905,
      "step": 574650
    },
    {
      "epoch": 6.083992780050921,
      "grad_norm": 4.328981876373291,
      "learning_rate": 1.9592790599195426e-05,
      "loss": 0.6839,
      "step": 574700
    },
    {
      "epoch": 6.084522101830924,
      "grad_norm": 4.390060901641846,
      "learning_rate": 1.959014397628626e-05,
      "loss": 0.7031,
      "step": 574750
    },
    {
      "epoch": 6.085051423610928,
      "grad_norm": 4.440860748291016,
      "learning_rate": 1.958749735337709e-05,
      "loss": 0.7003,
      "step": 574800
    },
    {
      "epoch": 6.0855807453909305,
      "grad_norm": 4.2335052490234375,
      "learning_rate": 1.9584850730467925e-05,
      "loss": 0.6794,
      "step": 574850
    },
    {
      "epoch": 6.086110067170934,
      "grad_norm": 4.179427146911621,
      "learning_rate": 1.9582204107558756e-05,
      "loss": 0.6881,
      "step": 574900
    },
    {
      "epoch": 6.086639388950937,
      "grad_norm": 4.267956733703613,
      "learning_rate": 1.957955748464959e-05,
      "loss": 0.6892,
      "step": 574950
    },
    {
      "epoch": 6.08716871073094,
      "grad_norm": 4.250978946685791,
      "learning_rate": 1.957691086174042e-05,
      "loss": 0.6898,
      "step": 575000
    },
    {
      "epoch": 6.08716871073094,
      "eval_loss": 0.43861979246139526,
      "eval_runtime": 46.7845,
      "eval_samples_per_second": 3589.438,
      "eval_steps_per_second": 448.696,
      "step": 575000
    },
    {
      "epoch": 6.087698032510944,
      "grad_norm": 4.584843158721924,
      "learning_rate": 1.957426423883125e-05,
      "loss": 0.6869,
      "step": 575050
    },
    {
      "epoch": 6.088227354290947,
      "grad_norm": 4.46365213394165,
      "learning_rate": 1.9571617615922082e-05,
      "loss": 0.6892,
      "step": 575100
    },
    {
      "epoch": 6.08875667607095,
      "grad_norm": 4.2571635246276855,
      "learning_rate": 1.9568970993012916e-05,
      "loss": 0.6878,
      "step": 575150
    },
    {
      "epoch": 6.089285997850953,
      "grad_norm": 4.717840194702148,
      "learning_rate": 1.9566324370103747e-05,
      "loss": 0.6852,
      "step": 575200
    },
    {
      "epoch": 6.089815319630957,
      "grad_norm": 4.145666122436523,
      "learning_rate": 1.956367774719458e-05,
      "loss": 0.6788,
      "step": 575250
    },
    {
      "epoch": 6.09034464141096,
      "grad_norm": 4.3877997398376465,
      "learning_rate": 1.956103112428541e-05,
      "loss": 0.6868,
      "step": 575300
    },
    {
      "epoch": 6.090873963190964,
      "grad_norm": 3.955829620361328,
      "learning_rate": 1.9558384501376245e-05,
      "loss": 0.6899,
      "step": 575350
    },
    {
      "epoch": 6.0914032849709665,
      "grad_norm": 4.153472423553467,
      "learning_rate": 1.9555737878467076e-05,
      "loss": 0.6967,
      "step": 575400
    },
    {
      "epoch": 6.09193260675097,
      "grad_norm": 4.3317060470581055,
      "learning_rate": 1.955309125555791e-05,
      "loss": 0.6712,
      "step": 575450
    },
    {
      "epoch": 6.092461928530973,
      "grad_norm": 4.241548538208008,
      "learning_rate": 1.955044463264874e-05,
      "loss": 0.6901,
      "step": 575500
    },
    {
      "epoch": 6.092461928530973,
      "eval_loss": 0.43885934352874756,
      "eval_runtime": 46.7193,
      "eval_samples_per_second": 3594.443,
      "eval_steps_per_second": 449.321,
      "step": 575500
    },
    {
      "epoch": 6.092991250310977,
      "grad_norm": 4.38823127746582,
      "learning_rate": 1.9547798009739575e-05,
      "loss": 0.6713,
      "step": 575550
    },
    {
      "epoch": 6.09352057209098,
      "grad_norm": 4.342033386230469,
      "learning_rate": 1.9545151386830406e-05,
      "loss": 0.6907,
      "step": 575600
    },
    {
      "epoch": 6.0940498938709835,
      "grad_norm": 4.054922580718994,
      "learning_rate": 1.9542504763921237e-05,
      "loss": 0.6748,
      "step": 575650
    },
    {
      "epoch": 6.094579215650986,
      "grad_norm": 4.4756951332092285,
      "learning_rate": 1.9539858141012067e-05,
      "loss": 0.6823,
      "step": 575700
    },
    {
      "epoch": 6.095108537430989,
      "grad_norm": 4.558066368103027,
      "learning_rate": 1.95372115181029e-05,
      "loss": 0.6841,
      "step": 575750
    },
    {
      "epoch": 6.095637859210993,
      "grad_norm": 4.119447231292725,
      "learning_rate": 1.9534564895193732e-05,
      "loss": 0.6818,
      "step": 575800
    },
    {
      "epoch": 6.096167180990996,
      "grad_norm": 4.211555480957031,
      "learning_rate": 1.9531918272284566e-05,
      "loss": 0.6804,
      "step": 575850
    },
    {
      "epoch": 6.096696502771,
      "grad_norm": 4.722624778747559,
      "learning_rate": 1.9529271649375397e-05,
      "loss": 0.6854,
      "step": 575900
    },
    {
      "epoch": 6.0972258245510025,
      "grad_norm": 4.162450790405273,
      "learning_rate": 1.952662502646623e-05,
      "loss": 0.6838,
      "step": 575950
    },
    {
      "epoch": 6.097755146331006,
      "grad_norm": 4.5181050300598145,
      "learning_rate": 1.952397840355706e-05,
      "loss": 0.6862,
      "step": 576000
    },
    {
      "epoch": 6.097755146331006,
      "eval_loss": 0.4380442798137665,
      "eval_runtime": 46.8032,
      "eval_samples_per_second": 3588.005,
      "eval_steps_per_second": 448.517,
      "step": 576000
    },
    {
      "epoch": 6.098284468111009,
      "grad_norm": 4.615711688995361,
      "learning_rate": 1.9521331780647896e-05,
      "loss": 0.6942,
      "step": 576050
    },
    {
      "epoch": 6.098813789891013,
      "grad_norm": 4.892730236053467,
      "learning_rate": 1.9518685157738726e-05,
      "loss": 0.6821,
      "step": 576100
    },
    {
      "epoch": 6.099343111671016,
      "grad_norm": 3.9736063480377197,
      "learning_rate": 1.9516038534829557e-05,
      "loss": 0.6804,
      "step": 576150
    },
    {
      "epoch": 6.0998724334510195,
      "grad_norm": 3.8597826957702637,
      "learning_rate": 1.9513444844378572e-05,
      "loss": 0.6723,
      "step": 576200
    },
    {
      "epoch": 6.100401755231022,
      "grad_norm": 4.662165641784668,
      "learning_rate": 1.9510798221469406e-05,
      "loss": 0.6861,
      "step": 576250
    },
    {
      "epoch": 6.100931077011026,
      "grad_norm": 4.912007808685303,
      "learning_rate": 1.9508151598560237e-05,
      "loss": 0.6822,
      "step": 576300
    },
    {
      "epoch": 6.101460398791029,
      "grad_norm": 4.049630641937256,
      "learning_rate": 1.950550497565107e-05,
      "loss": 0.6828,
      "step": 576350
    },
    {
      "epoch": 6.101989720571033,
      "grad_norm": 4.3769426345825195,
      "learning_rate": 1.95028583527419e-05,
      "loss": 0.6917,
      "step": 576400
    },
    {
      "epoch": 6.102519042351036,
      "grad_norm": 4.605941295623779,
      "learning_rate": 1.9500211729832736e-05,
      "loss": 0.6924,
      "step": 576450
    },
    {
      "epoch": 6.103048364131039,
      "grad_norm": 4.3160400390625,
      "learning_rate": 1.9497565106923566e-05,
      "loss": 0.6841,
      "step": 576500
    },
    {
      "epoch": 6.103048364131039,
      "eval_loss": 0.43767428398132324,
      "eval_runtime": 46.7458,
      "eval_samples_per_second": 3592.41,
      "eval_steps_per_second": 449.067,
      "step": 576500
    },
    {
      "epoch": 6.103577685911042,
      "grad_norm": 4.420497894287109,
      "learning_rate": 1.94949184840144e-05,
      "loss": 0.6838,
      "step": 576550
    },
    {
      "epoch": 6.104107007691045,
      "grad_norm": 4.395047664642334,
      "learning_rate": 1.949227186110523e-05,
      "loss": 0.6895,
      "step": 576600
    },
    {
      "epoch": 6.104636329471049,
      "grad_norm": 4.255283355712891,
      "learning_rate": 1.9489625238196062e-05,
      "loss": 0.6764,
      "step": 576650
    },
    {
      "epoch": 6.105165651251052,
      "grad_norm": 4.102219104766846,
      "learning_rate": 1.9486978615286893e-05,
      "loss": 0.685,
      "step": 576700
    },
    {
      "epoch": 6.1056949730310555,
      "grad_norm": 4.597545623779297,
      "learning_rate": 1.9484331992377727e-05,
      "loss": 0.6936,
      "step": 576750
    },
    {
      "epoch": 6.106224294811058,
      "grad_norm": 4.0147576332092285,
      "learning_rate": 1.9481685369468557e-05,
      "loss": 0.6705,
      "step": 576800
    },
    {
      "epoch": 6.106753616591062,
      "grad_norm": 4.649350166320801,
      "learning_rate": 1.947903874655939e-05,
      "loss": 0.6907,
      "step": 576850
    },
    {
      "epoch": 6.107282938371065,
      "grad_norm": 3.9881696701049805,
      "learning_rate": 1.9476392123650222e-05,
      "loss": 0.6816,
      "step": 576900
    },
    {
      "epoch": 6.107812260151069,
      "grad_norm": 4.235416889190674,
      "learning_rate": 1.9473745500741056e-05,
      "loss": 0.6856,
      "step": 576950
    },
    {
      "epoch": 6.108341581931072,
      "grad_norm": 4.421909332275391,
      "learning_rate": 1.9471098877831887e-05,
      "loss": 0.6868,
      "step": 577000
    },
    {
      "epoch": 6.108341581931072,
      "eval_loss": 0.4394308626651764,
      "eval_runtime": 46.7357,
      "eval_samples_per_second": 3593.185,
      "eval_steps_per_second": 449.164,
      "step": 577000
    },
    {
      "epoch": 6.108870903711075,
      "grad_norm": 4.9662089347839355,
      "learning_rate": 1.946845225492272e-05,
      "loss": 0.6915,
      "step": 577050
    },
    {
      "epoch": 6.109400225491078,
      "grad_norm": 4.124855041503906,
      "learning_rate": 1.9465805632013552e-05,
      "loss": 0.6774,
      "step": 577100
    },
    {
      "epoch": 6.109929547271082,
      "grad_norm": 4.463099956512451,
      "learning_rate": 1.9463159009104383e-05,
      "loss": 0.6762,
      "step": 577150
    },
    {
      "epoch": 6.110458869051085,
      "grad_norm": 4.22559118270874,
      "learning_rate": 1.9460512386195213e-05,
      "loss": 0.6849,
      "step": 577200
    },
    {
      "epoch": 6.110988190831089,
      "grad_norm": 4.280462265014648,
      "learning_rate": 1.9457865763286047e-05,
      "loss": 0.6823,
      "step": 577250
    },
    {
      "epoch": 6.111517512611091,
      "grad_norm": 4.3404340744018555,
      "learning_rate": 1.9455219140376878e-05,
      "loss": 0.6857,
      "step": 577300
    },
    {
      "epoch": 6.112046834391094,
      "grad_norm": 4.322110176086426,
      "learning_rate": 1.9452572517467712e-05,
      "loss": 0.6872,
      "step": 577350
    },
    {
      "epoch": 6.112576156171098,
      "grad_norm": 4.404664039611816,
      "learning_rate": 1.9449925894558543e-05,
      "loss": 0.6872,
      "step": 577400
    },
    {
      "epoch": 6.113105477951101,
      "grad_norm": 4.0243611335754395,
      "learning_rate": 1.9447279271649377e-05,
      "loss": 0.6945,
      "step": 577450
    },
    {
      "epoch": 6.113634799731105,
      "grad_norm": 4.3579206466674805,
      "learning_rate": 1.9444632648740208e-05,
      "loss": 0.7007,
      "step": 577500
    },
    {
      "epoch": 6.113634799731105,
      "eval_loss": 0.4393842816352844,
      "eval_runtime": 46.7593,
      "eval_samples_per_second": 3591.372,
      "eval_steps_per_second": 448.937,
      "step": 577500
    },
    {
      "epoch": 6.1141641215111076,
      "grad_norm": 4.428105354309082,
      "learning_rate": 1.9441986025831042e-05,
      "loss": 0.6831,
      "step": 577550
    },
    {
      "epoch": 6.114693443291111,
      "grad_norm": 3.6015729904174805,
      "learning_rate": 1.9439339402921872e-05,
      "loss": 0.6794,
      "step": 577600
    },
    {
      "epoch": 6.115222765071114,
      "grad_norm": 4.119934558868408,
      "learning_rate": 1.9436692780012707e-05,
      "loss": 0.6844,
      "step": 577650
    },
    {
      "epoch": 6.115752086851118,
      "grad_norm": 3.8954460620880127,
      "learning_rate": 1.9434046157103537e-05,
      "loss": 0.674,
      "step": 577700
    },
    {
      "epoch": 6.116281408631121,
      "grad_norm": 3.8990821838378906,
      "learning_rate": 1.9431399534194368e-05,
      "loss": 0.6833,
      "step": 577750
    },
    {
      "epoch": 6.1168107304111246,
      "grad_norm": 4.4199538230896,
      "learning_rate": 1.94287529112852e-05,
      "loss": 0.6935,
      "step": 577800
    },
    {
      "epoch": 6.117340052191127,
      "grad_norm": 4.078987121582031,
      "learning_rate": 1.9426106288376033e-05,
      "loss": 0.6855,
      "step": 577850
    },
    {
      "epoch": 6.117869373971131,
      "grad_norm": 4.70346212387085,
      "learning_rate": 1.9423459665466864e-05,
      "loss": 0.6866,
      "step": 577900
    },
    {
      "epoch": 6.118398695751134,
      "grad_norm": 4.806422710418701,
      "learning_rate": 1.9420813042557698e-05,
      "loss": 0.6822,
      "step": 577950
    },
    {
      "epoch": 6.118928017531138,
      "grad_norm": 4.436431407928467,
      "learning_rate": 1.941816641964853e-05,
      "loss": 0.6911,
      "step": 578000
    },
    {
      "epoch": 6.118928017531138,
      "eval_loss": 0.43840694427490234,
      "eval_runtime": 46.7114,
      "eval_samples_per_second": 3595.057,
      "eval_steps_per_second": 449.398,
      "step": 578000
    },
    {
      "epoch": 6.119457339311141,
      "grad_norm": 4.000133514404297,
      "learning_rate": 1.9415519796739362e-05,
      "loss": 0.6802,
      "step": 578050
    },
    {
      "epoch": 6.1199866610911435,
      "grad_norm": 4.434804916381836,
      "learning_rate": 1.9412873173830193e-05,
      "loss": 0.6851,
      "step": 578100
    },
    {
      "epoch": 6.120515982871147,
      "grad_norm": 4.141362190246582,
      "learning_rate": 1.9410226550921027e-05,
      "loss": 0.6846,
      "step": 578150
    },
    {
      "epoch": 6.12104530465115,
      "grad_norm": 4.283435821533203,
      "learning_rate": 1.9407579928011858e-05,
      "loss": 0.6823,
      "step": 578200
    },
    {
      "epoch": 6.121574626431154,
      "grad_norm": 4.430262565612793,
      "learning_rate": 1.9404986237560873e-05,
      "loss": 0.671,
      "step": 578250
    },
    {
      "epoch": 6.122103948211157,
      "grad_norm": 4.166438579559326,
      "learning_rate": 1.9402339614651703e-05,
      "loss": 0.686,
      "step": 578300
    },
    {
      "epoch": 6.1226332699911605,
      "grad_norm": 4.489336967468262,
      "learning_rate": 1.9399692991742537e-05,
      "loss": 0.6893,
      "step": 578350
    },
    {
      "epoch": 6.123162591771163,
      "grad_norm": 4.391878128051758,
      "learning_rate": 1.9397046368833368e-05,
      "loss": 0.6744,
      "step": 578400
    },
    {
      "epoch": 6.123691913551167,
      "grad_norm": 4.721766471862793,
      "learning_rate": 1.9394399745924202e-05,
      "loss": 0.6982,
      "step": 578450
    },
    {
      "epoch": 6.12422123533117,
      "grad_norm": 4.1398606300354,
      "learning_rate": 1.9391753123015033e-05,
      "loss": 0.6896,
      "step": 578500
    },
    {
      "epoch": 6.12422123533117,
      "eval_loss": 0.4384658634662628,
      "eval_runtime": 46.6911,
      "eval_samples_per_second": 3596.616,
      "eval_steps_per_second": 449.593,
      "step": 578500
    },
    {
      "epoch": 6.124750557111174,
      "grad_norm": 4.852245807647705,
      "learning_rate": 1.9389106500105867e-05,
      "loss": 0.6745,
      "step": 578550
    },
    {
      "epoch": 6.125279878891177,
      "grad_norm": 4.506004810333252,
      "learning_rate": 1.9386459877196698e-05,
      "loss": 0.6885,
      "step": 578600
    },
    {
      "epoch": 6.12580920067118,
      "grad_norm": 4.331029415130615,
      "learning_rate": 1.9383813254287532e-05,
      "loss": 0.6942,
      "step": 578650
    },
    {
      "epoch": 6.126338522451183,
      "grad_norm": 4.489260196685791,
      "learning_rate": 1.9381166631378363e-05,
      "loss": 0.6672,
      "step": 578700
    },
    {
      "epoch": 6.126867844231187,
      "grad_norm": 4.050885200500488,
      "learning_rate": 1.9378520008469193e-05,
      "loss": 0.6746,
      "step": 578750
    },
    {
      "epoch": 6.12739716601119,
      "grad_norm": 4.445056915283203,
      "learning_rate": 1.9375873385560024e-05,
      "loss": 0.68,
      "step": 578800
    },
    {
      "epoch": 6.127926487791193,
      "grad_norm": 4.567456245422363,
      "learning_rate": 1.9373226762650858e-05,
      "loss": 0.6816,
      "step": 578850
    },
    {
      "epoch": 6.1284558095711965,
      "grad_norm": 4.159653186798096,
      "learning_rate": 1.937058013974169e-05,
      "loss": 0.6831,
      "step": 578900
    },
    {
      "epoch": 6.128985131351199,
      "grad_norm": 4.444900989532471,
      "learning_rate": 1.9367933516832523e-05,
      "loss": 0.6937,
      "step": 578950
    },
    {
      "epoch": 6.129514453131203,
      "grad_norm": 4.267391204833984,
      "learning_rate": 1.9365286893923354e-05,
      "loss": 0.6839,
      "step": 579000
    },
    {
      "epoch": 6.129514453131203,
      "eval_loss": 0.43777358531951904,
      "eval_runtime": 46.7568,
      "eval_samples_per_second": 3591.562,
      "eval_steps_per_second": 448.961,
      "step": 579000
    },
    {
      "epoch": 6.130043774911206,
      "grad_norm": 4.648247241973877,
      "learning_rate": 1.9362640271014188e-05,
      "loss": 0.6792,
      "step": 579050
    },
    {
      "epoch": 6.13057309669121,
      "grad_norm": 4.567881107330322,
      "learning_rate": 1.935999364810502e-05,
      "loss": 0.6814,
      "step": 579100
    },
    {
      "epoch": 6.131102418471213,
      "grad_norm": 4.725907325744629,
      "learning_rate": 1.9357347025195853e-05,
      "loss": 0.6836,
      "step": 579150
    },
    {
      "epoch": 6.131631740251216,
      "grad_norm": 4.519711971282959,
      "learning_rate": 1.9354700402286683e-05,
      "loss": 0.6941,
      "step": 579200
    },
    {
      "epoch": 6.132161062031219,
      "grad_norm": 4.328429222106934,
      "learning_rate": 1.9352053779377517e-05,
      "loss": 0.6847,
      "step": 579250
    },
    {
      "epoch": 6.132690383811223,
      "grad_norm": 3.9735796451568604,
      "learning_rate": 1.9349407156468348e-05,
      "loss": 0.6767,
      "step": 579300
    },
    {
      "epoch": 6.133219705591226,
      "grad_norm": 4.428835868835449,
      "learning_rate": 1.934676053355918e-05,
      "loss": 0.686,
      "step": 579350
    },
    {
      "epoch": 6.13374902737123,
      "grad_norm": 4.406304359436035,
      "learning_rate": 1.934411391065001e-05,
      "loss": 0.6723,
      "step": 579400
    },
    {
      "epoch": 6.1342783491512325,
      "grad_norm": 4.671918869018555,
      "learning_rate": 1.9341467287740844e-05,
      "loss": 0.6794,
      "step": 579450
    },
    {
      "epoch": 6.134807670931236,
      "grad_norm": 4.428772926330566,
      "learning_rate": 1.9338820664831674e-05,
      "loss": 0.6786,
      "step": 579500
    },
    {
      "epoch": 6.134807670931236,
      "eval_loss": 0.43724358081817627,
      "eval_runtime": 46.7341,
      "eval_samples_per_second": 3593.307,
      "eval_steps_per_second": 449.179,
      "step": 579500
    },
    {
      "epoch": 6.135336992711239,
      "grad_norm": 4.6252593994140625,
      "learning_rate": 1.933617404192251e-05,
      "loss": 0.6852,
      "step": 579550
    },
    {
      "epoch": 6.135866314491242,
      "grad_norm": 4.601894855499268,
      "learning_rate": 1.933352741901334e-05,
      "loss": 0.6878,
      "step": 579600
    },
    {
      "epoch": 6.136395636271246,
      "grad_norm": 4.522091865539551,
      "learning_rate": 1.9330880796104173e-05,
      "loss": 0.6833,
      "step": 579650
    },
    {
      "epoch": 6.136924958051249,
      "grad_norm": 4.679802417755127,
      "learning_rate": 1.9328234173195004e-05,
      "loss": 0.6863,
      "step": 579700
    },
    {
      "epoch": 6.137454279831252,
      "grad_norm": 4.899872303009033,
      "learning_rate": 1.9325587550285838e-05,
      "loss": 0.6808,
      "step": 579750
    },
    {
      "epoch": 6.137983601611255,
      "grad_norm": 4.368759632110596,
      "learning_rate": 1.932294092737667e-05,
      "loss": 0.6806,
      "step": 579800
    },
    {
      "epoch": 6.138512923391259,
      "grad_norm": 4.59359884262085,
      "learning_rate": 1.93202943044675e-05,
      "loss": 0.6828,
      "step": 579850
    },
    {
      "epoch": 6.139042245171262,
      "grad_norm": 4.28466796875,
      "learning_rate": 1.931764768155833e-05,
      "loss": 0.6794,
      "step": 579900
    },
    {
      "epoch": 6.139571566951266,
      "grad_norm": 4.890055179595947,
      "learning_rate": 1.9315001058649164e-05,
      "loss": 0.6857,
      "step": 579950
    },
    {
      "epoch": 6.1401008887312685,
      "grad_norm": 4.415755271911621,
      "learning_rate": 1.9312354435739995e-05,
      "loss": 0.6795,
      "step": 580000
    },
    {
      "epoch": 6.1401008887312685,
      "eval_loss": 0.436810165643692,
      "eval_runtime": 46.7816,
      "eval_samples_per_second": 3589.659,
      "eval_steps_per_second": 448.723,
      "step": 580000
    },
    {
      "epoch": 6.140630210511272,
      "grad_norm": 4.217826843261719,
      "learning_rate": 1.930970781283083e-05,
      "loss": 0.6922,
      "step": 580050
    },
    {
      "epoch": 6.141159532291275,
      "grad_norm": 4.790558815002441,
      "learning_rate": 1.930706118992166e-05,
      "loss": 0.682,
      "step": 580100
    },
    {
      "epoch": 6.141688854071279,
      "grad_norm": 4.749856472015381,
      "learning_rate": 1.9304414567012494e-05,
      "loss": 0.6815,
      "step": 580150
    },
    {
      "epoch": 6.142218175851282,
      "grad_norm": 4.775634288787842,
      "learning_rate": 1.9301767944103325e-05,
      "loss": 0.6956,
      "step": 580200
    },
    {
      "epoch": 6.1427474976312855,
      "grad_norm": 4.4245781898498535,
      "learning_rate": 1.9299174253652343e-05,
      "loss": 0.6779,
      "step": 580250
    },
    {
      "epoch": 6.143276819411288,
      "grad_norm": 4.410077095031738,
      "learning_rate": 1.9296527630743173e-05,
      "loss": 0.6784,
      "step": 580300
    },
    {
      "epoch": 6.143806141191291,
      "grad_norm": 4.7521514892578125,
      "learning_rate": 1.9293881007834004e-05,
      "loss": 0.6865,
      "step": 580350
    },
    {
      "epoch": 6.144335462971295,
      "grad_norm": 4.356138706207275,
      "learning_rate": 1.9291234384924835e-05,
      "loss": 0.6756,
      "step": 580400
    },
    {
      "epoch": 6.144864784751298,
      "grad_norm": 4.770028114318848,
      "learning_rate": 1.928858776201567e-05,
      "loss": 0.6848,
      "step": 580450
    },
    {
      "epoch": 6.145394106531302,
      "grad_norm": 4.273303985595703,
      "learning_rate": 1.92859411391065e-05,
      "loss": 0.6862,
      "step": 580500
    },
    {
      "epoch": 6.145394106531302,
      "eval_loss": 0.43693986535072327,
      "eval_runtime": 46.6658,
      "eval_samples_per_second": 3598.569,
      "eval_steps_per_second": 449.837,
      "step": 580500
    },
    {
      "epoch": 6.1459234283113044,
      "grad_norm": 4.463829040527344,
      "learning_rate": 1.9283294516197334e-05,
      "loss": 0.6841,
      "step": 580550
    },
    {
      "epoch": 6.146452750091308,
      "grad_norm": 4.570183753967285,
      "learning_rate": 1.9280647893288165e-05,
      "loss": 0.667,
      "step": 580600
    },
    {
      "epoch": 6.146982071871311,
      "grad_norm": 4.305810451507568,
      "learning_rate": 1.9278001270379e-05,
      "loss": 0.6761,
      "step": 580650
    },
    {
      "epoch": 6.147511393651315,
      "grad_norm": 4.414796352386475,
      "learning_rate": 1.927535464746983e-05,
      "loss": 0.7012,
      "step": 580700
    },
    {
      "epoch": 6.148040715431318,
      "grad_norm": 4.619370460510254,
      "learning_rate": 1.9272708024560663e-05,
      "loss": 0.6894,
      "step": 580750
    },
    {
      "epoch": 6.1485700372113214,
      "grad_norm": 4.096587657928467,
      "learning_rate": 1.9270061401651494e-05,
      "loss": 0.6822,
      "step": 580800
    },
    {
      "epoch": 6.149099358991324,
      "grad_norm": 4.0602946281433105,
      "learning_rate": 1.9267414778742325e-05,
      "loss": 0.6696,
      "step": 580850
    },
    {
      "epoch": 6.149628680771328,
      "grad_norm": 4.361202239990234,
      "learning_rate": 1.9264768155833156e-05,
      "loss": 0.6875,
      "step": 580900
    },
    {
      "epoch": 6.150158002551331,
      "grad_norm": 4.468442916870117,
      "learning_rate": 1.926212153292399e-05,
      "loss": 0.6917,
      "step": 580950
    },
    {
      "epoch": 6.150687324331335,
      "grad_norm": 4.20046854019165,
      "learning_rate": 1.925947491001482e-05,
      "loss": 0.6804,
      "step": 581000
    },
    {
      "epoch": 6.150687324331335,
      "eval_loss": 0.4376542568206787,
      "eval_runtime": 46.7651,
      "eval_samples_per_second": 3590.925,
      "eval_steps_per_second": 448.882,
      "step": 581000
    },
    {
      "epoch": 6.151216646111338,
      "grad_norm": 4.104634761810303,
      "learning_rate": 1.9256828287105654e-05,
      "loss": 0.6816,
      "step": 581050
    },
    {
      "epoch": 6.15174596789134,
      "grad_norm": 4.547438144683838,
      "learning_rate": 1.9254181664196485e-05,
      "loss": 0.7028,
      "step": 581100
    },
    {
      "epoch": 6.152275289671344,
      "grad_norm": 4.3329291343688965,
      "learning_rate": 1.925153504128732e-05,
      "loss": 0.6889,
      "step": 581150
    },
    {
      "epoch": 6.152804611451347,
      "grad_norm": 4.24146842956543,
      "learning_rate": 1.924888841837815e-05,
      "loss": 0.6878,
      "step": 581200
    },
    {
      "epoch": 6.153333933231351,
      "grad_norm": 4.177306652069092,
      "learning_rate": 1.9246241795468984e-05,
      "loss": 0.687,
      "step": 581250
    },
    {
      "epoch": 6.153863255011354,
      "grad_norm": 4.36447286605835,
      "learning_rate": 1.9243595172559815e-05,
      "loss": 0.6746,
      "step": 581300
    },
    {
      "epoch": 6.154392576791357,
      "grad_norm": 4.156239032745361,
      "learning_rate": 1.924094854965065e-05,
      "loss": 0.6892,
      "step": 581350
    },
    {
      "epoch": 6.15492189857136,
      "grad_norm": 4.488298416137695,
      "learning_rate": 1.923830192674148e-05,
      "loss": 0.6879,
      "step": 581400
    },
    {
      "epoch": 6.155451220351364,
      "grad_norm": 3.995617151260376,
      "learning_rate": 1.923565530383231e-05,
      "loss": 0.687,
      "step": 581450
    },
    {
      "epoch": 6.155980542131367,
      "grad_norm": 4.431323051452637,
      "learning_rate": 1.923300868092314e-05,
      "loss": 0.6905,
      "step": 581500
    },
    {
      "epoch": 6.155980542131367,
      "eval_loss": 0.4367923140525818,
      "eval_runtime": 46.7367,
      "eval_samples_per_second": 3593.111,
      "eval_steps_per_second": 449.155,
      "step": 581500
    },
    {
      "epoch": 6.156509863911371,
      "grad_norm": 4.469010353088379,
      "learning_rate": 1.9230362058013975e-05,
      "loss": 0.6817,
      "step": 581550
    },
    {
      "epoch": 6.1570391856913735,
      "grad_norm": 4.939945220947266,
      "learning_rate": 1.9227715435104806e-05,
      "loss": 0.6862,
      "step": 581600
    },
    {
      "epoch": 6.157568507471377,
      "grad_norm": 4.700974464416504,
      "learning_rate": 1.922506881219564e-05,
      "loss": 0.679,
      "step": 581650
    },
    {
      "epoch": 6.15809782925138,
      "grad_norm": 4.5374531745910645,
      "learning_rate": 1.922242218928647e-05,
      "loss": 0.6762,
      "step": 581700
    },
    {
      "epoch": 6.158627151031384,
      "grad_norm": 4.485433101654053,
      "learning_rate": 1.9219775566377305e-05,
      "loss": 0.6897,
      "step": 581750
    },
    {
      "epoch": 6.159156472811387,
      "grad_norm": 4.515901565551758,
      "learning_rate": 1.9217128943468135e-05,
      "loss": 0.6849,
      "step": 581800
    },
    {
      "epoch": 6.15968579459139,
      "grad_norm": 4.358345985412598,
      "learning_rate": 1.921448232055897e-05,
      "loss": 0.68,
      "step": 581850
    },
    {
      "epoch": 6.160215116371393,
      "grad_norm": 4.07338285446167,
      "learning_rate": 1.92118356976498e-05,
      "loss": 0.6848,
      "step": 581900
    },
    {
      "epoch": 6.160744438151396,
      "grad_norm": 4.527368545532227,
      "learning_rate": 1.9209189074740634e-05,
      "loss": 0.679,
      "step": 581950
    },
    {
      "epoch": 6.1612737599314,
      "grad_norm": 4.264162063598633,
      "learning_rate": 1.9206542451831465e-05,
      "loss": 0.681,
      "step": 582000
    },
    {
      "epoch": 6.1612737599314,
      "eval_loss": 0.43668845295906067,
      "eval_runtime": 46.8054,
      "eval_samples_per_second": 3587.834,
      "eval_steps_per_second": 448.495,
      "step": 582000
    },
    {
      "epoch": 6.161803081711403,
      "grad_norm": 4.793644905090332,
      "learning_rate": 1.9203895828922296e-05,
      "loss": 0.6919,
      "step": 582050
    },
    {
      "epoch": 6.162332403491407,
      "grad_norm": 4.751699447631836,
      "learning_rate": 1.9201249206013127e-05,
      "loss": 0.6949,
      "step": 582100
    },
    {
      "epoch": 6.1628617252714095,
      "grad_norm": 4.435047626495361,
      "learning_rate": 1.919860258310396e-05,
      "loss": 0.6907,
      "step": 582150
    },
    {
      "epoch": 6.163391047051413,
      "grad_norm": 4.609485149383545,
      "learning_rate": 1.919595596019479e-05,
      "loss": 0.6814,
      "step": 582200
    },
    {
      "epoch": 6.163920368831416,
      "grad_norm": 4.2190961837768555,
      "learning_rate": 1.919336226974381e-05,
      "loss": 0.6832,
      "step": 582250
    },
    {
      "epoch": 6.16444969061142,
      "grad_norm": 4.246257781982422,
      "learning_rate": 1.919071564683464e-05,
      "loss": 0.6874,
      "step": 582300
    },
    {
      "epoch": 6.164979012391423,
      "grad_norm": 4.437809467315674,
      "learning_rate": 1.9188069023925474e-05,
      "loss": 0.6756,
      "step": 582350
    },
    {
      "epoch": 6.1655083341714265,
      "grad_norm": 4.4043192863464355,
      "learning_rate": 1.9185422401016305e-05,
      "loss": 0.6873,
      "step": 582400
    },
    {
      "epoch": 6.166037655951429,
      "grad_norm": 4.141417980194092,
      "learning_rate": 1.9182775778107136e-05,
      "loss": 0.6935,
      "step": 582450
    },
    {
      "epoch": 6.166566977731433,
      "grad_norm": 3.968290328979492,
      "learning_rate": 1.9180129155197966e-05,
      "loss": 0.6816,
      "step": 582500
    },
    {
      "epoch": 6.166566977731433,
      "eval_loss": 0.4367692172527313,
      "eval_runtime": 46.7004,
      "eval_samples_per_second": 3595.903,
      "eval_steps_per_second": 449.504,
      "step": 582500
    },
    {
      "epoch": 6.167096299511436,
      "grad_norm": 4.59089469909668,
      "learning_rate": 1.91774825322888e-05,
      "loss": 0.6899,
      "step": 582550
    },
    {
      "epoch": 6.167625621291439,
      "grad_norm": 4.446915149688721,
      "learning_rate": 1.917483590937963e-05,
      "loss": 0.6849,
      "step": 582600
    },
    {
      "epoch": 6.168154943071443,
      "grad_norm": 4.5688581466674805,
      "learning_rate": 1.9172189286470465e-05,
      "loss": 0.6864,
      "step": 582650
    },
    {
      "epoch": 6.1686842648514455,
      "grad_norm": 4.477950096130371,
      "learning_rate": 1.9169542663561296e-05,
      "loss": 0.6935,
      "step": 582700
    },
    {
      "epoch": 6.169213586631449,
      "grad_norm": 4.247628688812256,
      "learning_rate": 1.916689604065213e-05,
      "loss": 0.6839,
      "step": 582750
    },
    {
      "epoch": 6.169742908411452,
      "grad_norm": 4.150439262390137,
      "learning_rate": 1.916424941774296e-05,
      "loss": 0.6871,
      "step": 582800
    },
    {
      "epoch": 6.170272230191456,
      "grad_norm": 4.891258716583252,
      "learning_rate": 1.9161602794833795e-05,
      "loss": 0.687,
      "step": 582850
    },
    {
      "epoch": 6.170801551971459,
      "grad_norm": 4.076977729797363,
      "learning_rate": 1.9158956171924626e-05,
      "loss": 0.6896,
      "step": 582900
    },
    {
      "epoch": 6.1713308737514625,
      "grad_norm": 4.09487247467041,
      "learning_rate": 1.915630954901546e-05,
      "loss": 0.6914,
      "step": 582950
    },
    {
      "epoch": 6.171860195531465,
      "grad_norm": 4.441891670227051,
      "learning_rate": 1.915366292610629e-05,
      "loss": 0.6855,
      "step": 583000
    },
    {
      "epoch": 6.171860195531465,
      "eval_loss": 0.4362596571445465,
      "eval_runtime": 46.724,
      "eval_samples_per_second": 3594.085,
      "eval_steps_per_second": 449.277,
      "step": 583000
    },
    {
      "epoch": 6.172389517311469,
      "grad_norm": 4.060286998748779,
      "learning_rate": 1.915101630319712e-05,
      "loss": 0.6791,
      "step": 583050
    },
    {
      "epoch": 6.172918839091472,
      "grad_norm": 4.1592116355896,
      "learning_rate": 1.9148369680287952e-05,
      "loss": 0.6777,
      "step": 583100
    },
    {
      "epoch": 6.173448160871476,
      "grad_norm": 4.200424671173096,
      "learning_rate": 1.9145723057378786e-05,
      "loss": 0.6826,
      "step": 583150
    },
    {
      "epoch": 6.173977482651479,
      "grad_norm": 4.29748010635376,
      "learning_rate": 1.9143076434469617e-05,
      "loss": 0.6813,
      "step": 583200
    },
    {
      "epoch": 6.174506804431482,
      "grad_norm": 4.463554859161377,
      "learning_rate": 1.914042981156045e-05,
      "loss": 0.6835,
      "step": 583250
    },
    {
      "epoch": 6.175036126211485,
      "grad_norm": 4.465266227722168,
      "learning_rate": 1.913778318865128e-05,
      "loss": 0.6781,
      "step": 583300
    },
    {
      "epoch": 6.175565447991488,
      "grad_norm": 4.220462799072266,
      "learning_rate": 1.9135136565742116e-05,
      "loss": 0.6846,
      "step": 583350
    },
    {
      "epoch": 6.176094769771492,
      "grad_norm": 4.12161111831665,
      "learning_rate": 1.9132489942832946e-05,
      "loss": 0.6896,
      "step": 583400
    },
    {
      "epoch": 6.176624091551495,
      "grad_norm": 3.9057457447052,
      "learning_rate": 1.912984331992378e-05,
      "loss": 0.6845,
      "step": 583450
    },
    {
      "epoch": 6.1771534133314985,
      "grad_norm": 4.101088523864746,
      "learning_rate": 1.912719669701461e-05,
      "loss": 0.6903,
      "step": 583500
    },
    {
      "epoch": 6.1771534133314985,
      "eval_loss": 0.43705371022224426,
      "eval_runtime": 46.7739,
      "eval_samples_per_second": 3590.25,
      "eval_steps_per_second": 448.797,
      "step": 583500
    },
    {
      "epoch": 6.177682735111501,
      "grad_norm": 4.790175437927246,
      "learning_rate": 1.9124550074105442e-05,
      "loss": 0.6827,
      "step": 583550
    },
    {
      "epoch": 6.178212056891505,
      "grad_norm": 4.550824165344238,
      "learning_rate": 1.9121903451196273e-05,
      "loss": 0.6793,
      "step": 583600
    },
    {
      "epoch": 6.178741378671508,
      "grad_norm": 4.095766544342041,
      "learning_rate": 1.9119256828287107e-05,
      "loss": 0.6845,
      "step": 583650
    },
    {
      "epoch": 6.179270700451512,
      "grad_norm": 4.327889919281006,
      "learning_rate": 1.9116610205377937e-05,
      "loss": 0.68,
      "step": 583700
    },
    {
      "epoch": 6.179800022231515,
      "grad_norm": 4.267012596130371,
      "learning_rate": 1.911396358246877e-05,
      "loss": 0.6729,
      "step": 583750
    },
    {
      "epoch": 6.180329344011518,
      "grad_norm": 4.675942897796631,
      "learning_rate": 1.9111316959559602e-05,
      "loss": 0.6924,
      "step": 583800
    },
    {
      "epoch": 6.180858665791521,
      "grad_norm": 4.587552547454834,
      "learning_rate": 1.9108670336650436e-05,
      "loss": 0.6862,
      "step": 583850
    },
    {
      "epoch": 6.181387987571525,
      "grad_norm": 3.972015857696533,
      "learning_rate": 1.9106023713741267e-05,
      "loss": 0.6746,
      "step": 583900
    },
    {
      "epoch": 6.181917309351528,
      "grad_norm": 4.4589738845825195,
      "learning_rate": 1.91033770908321e-05,
      "loss": 0.6787,
      "step": 583950
    },
    {
      "epoch": 6.182446631131532,
      "grad_norm": 4.6577301025390625,
      "learning_rate": 1.9100730467922932e-05,
      "loss": 0.6814,
      "step": 584000
    },
    {
      "epoch": 6.182446631131532,
      "eval_loss": 0.4351517856121063,
      "eval_runtime": 46.7359,
      "eval_samples_per_second": 3593.171,
      "eval_steps_per_second": 449.162,
      "step": 584000
    },
    {
      "epoch": 6.1829759529115345,
      "grad_norm": 4.37685489654541,
      "learning_rate": 1.9098083845013766e-05,
      "loss": 0.6829,
      "step": 584050
    },
    {
      "epoch": 6.183505274691537,
      "grad_norm": 4.327080249786377,
      "learning_rate": 1.9095437222104597e-05,
      "loss": 0.6833,
      "step": 584100
    },
    {
      "epoch": 6.184034596471541,
      "grad_norm": 4.318370342254639,
      "learning_rate": 1.9092790599195427e-05,
      "loss": 0.7004,
      "step": 584150
    },
    {
      "epoch": 6.184563918251544,
      "grad_norm": 4.4433207511901855,
      "learning_rate": 1.9090143976286258e-05,
      "loss": 0.692,
      "step": 584200
    },
    {
      "epoch": 6.185093240031548,
      "grad_norm": 4.630367755889893,
      "learning_rate": 1.9087550285835276e-05,
      "loss": 0.6836,
      "step": 584250
    },
    {
      "epoch": 6.185622561811551,
      "grad_norm": 4.335150718688965,
      "learning_rate": 1.9084903662926107e-05,
      "loss": 0.6744,
      "step": 584300
    },
    {
      "epoch": 6.186151883591554,
      "grad_norm": 4.290302276611328,
      "learning_rate": 1.908225704001694e-05,
      "loss": 0.6827,
      "step": 584350
    },
    {
      "epoch": 6.186681205371557,
      "grad_norm": 4.425769329071045,
      "learning_rate": 1.907961041710777e-05,
      "loss": 0.6837,
      "step": 584400
    },
    {
      "epoch": 6.187210527151561,
      "grad_norm": 4.291320323944092,
      "learning_rate": 1.9076963794198606e-05,
      "loss": 0.6817,
      "step": 584450
    },
    {
      "epoch": 6.187739848931564,
      "grad_norm": 4.232458591461182,
      "learning_rate": 1.9074317171289436e-05,
      "loss": 0.6725,
      "step": 584500
    },
    {
      "epoch": 6.187739848931564,
      "eval_loss": 0.4365859627723694,
      "eval_runtime": 46.9801,
      "eval_samples_per_second": 3574.494,
      "eval_steps_per_second": 446.828,
      "step": 584500
    },
    {
      "epoch": 6.188269170711568,
      "grad_norm": 4.82570219039917,
      "learning_rate": 1.9071670548380267e-05,
      "loss": 0.6886,
      "step": 584550
    },
    {
      "epoch": 6.18879849249157,
      "grad_norm": 4.7266764640808105,
      "learning_rate": 1.9069023925471098e-05,
      "loss": 0.6912,
      "step": 584600
    },
    {
      "epoch": 6.189327814271574,
      "grad_norm": 3.946004629135132,
      "learning_rate": 1.9066377302561932e-05,
      "loss": 0.6754,
      "step": 584650
    },
    {
      "epoch": 6.189857136051577,
      "grad_norm": 4.157101154327393,
      "learning_rate": 1.9063730679652763e-05,
      "loss": 0.6853,
      "step": 584700
    },
    {
      "epoch": 6.190386457831581,
      "grad_norm": 4.266543865203857,
      "learning_rate": 1.9061084056743597e-05,
      "loss": 0.694,
      "step": 584750
    },
    {
      "epoch": 6.190915779611584,
      "grad_norm": 4.2956862449646,
      "learning_rate": 1.9058437433834427e-05,
      "loss": 0.678,
      "step": 584800
    },
    {
      "epoch": 6.1914451013915865,
      "grad_norm": 4.307930946350098,
      "learning_rate": 1.905579081092526e-05,
      "loss": 0.6663,
      "step": 584850
    },
    {
      "epoch": 6.19197442317159,
      "grad_norm": 4.091794490814209,
      "learning_rate": 1.9053197120474276e-05,
      "loss": 0.6773,
      "step": 584900
    },
    {
      "epoch": 6.192503744951593,
      "grad_norm": 4.320059299468994,
      "learning_rate": 1.905055049756511e-05,
      "loss": 0.6874,
      "step": 584950
    },
    {
      "epoch": 6.193033066731597,
      "grad_norm": 4.544826984405518,
      "learning_rate": 1.904790387465594e-05,
      "loss": 0.686,
      "step": 585000
    },
    {
      "epoch": 6.193033066731597,
      "eval_loss": 0.43563732504844666,
      "eval_runtime": 46.7514,
      "eval_samples_per_second": 3591.98,
      "eval_steps_per_second": 449.014,
      "step": 585000
    },
    {
      "epoch": 6.1935623885116,
      "grad_norm": 4.352158069610596,
      "learning_rate": 1.9045257251746772e-05,
      "loss": 0.6937,
      "step": 585050
    },
    {
      "epoch": 6.1940917102916035,
      "grad_norm": 4.177533149719238,
      "learning_rate": 1.9042610628837603e-05,
      "loss": 0.6834,
      "step": 585100
    },
    {
      "epoch": 6.194621032071606,
      "grad_norm": 4.450979232788086,
      "learning_rate": 1.9039964005928437e-05,
      "loss": 0.6818,
      "step": 585150
    },
    {
      "epoch": 6.19515035385161,
      "grad_norm": 4.0644426345825195,
      "learning_rate": 1.9037317383019267e-05,
      "loss": 0.6863,
      "step": 585200
    },
    {
      "epoch": 6.195679675631613,
      "grad_norm": 4.449988842010498,
      "learning_rate": 1.90346707601101e-05,
      "loss": 0.6732,
      "step": 585250
    },
    {
      "epoch": 6.196208997411617,
      "grad_norm": 4.488797664642334,
      "learning_rate": 1.9032024137200932e-05,
      "loss": 0.6737,
      "step": 585300
    },
    {
      "epoch": 6.19673831919162,
      "grad_norm": 4.3120646476745605,
      "learning_rate": 1.9029377514291766e-05,
      "loss": 0.68,
      "step": 585350
    },
    {
      "epoch": 6.197267640971623,
      "grad_norm": 4.472207546234131,
      "learning_rate": 1.9026730891382597e-05,
      "loss": 0.6727,
      "step": 585400
    },
    {
      "epoch": 6.197796962751626,
      "grad_norm": 4.220340251922607,
      "learning_rate": 1.902408426847343e-05,
      "loss": 0.6952,
      "step": 585450
    },
    {
      "epoch": 6.19832628453163,
      "grad_norm": 4.2816081047058105,
      "learning_rate": 1.9021437645564262e-05,
      "loss": 0.6757,
      "step": 585500
    },
    {
      "epoch": 6.19832628453163,
      "eval_loss": 0.43602100014686584,
      "eval_runtime": 46.7594,
      "eval_samples_per_second": 3591.365,
      "eval_steps_per_second": 448.937,
      "step": 585500
    },
    {
      "epoch": 6.198855606311633,
      "grad_norm": 4.297183513641357,
      "learning_rate": 1.9018791022655092e-05,
      "loss": 0.6837,
      "step": 585550
    },
    {
      "epoch": 6.199384928091636,
      "grad_norm": 4.466905117034912,
      "learning_rate": 1.9016144399745923e-05,
      "loss": 0.6898,
      "step": 585600
    },
    {
      "epoch": 6.1999142498716395,
      "grad_norm": 4.738924503326416,
      "learning_rate": 1.9013497776836757e-05,
      "loss": 0.68,
      "step": 585650
    },
    {
      "epoch": 6.200443571651642,
      "grad_norm": 4.180427551269531,
      "learning_rate": 1.9010851153927588e-05,
      "loss": 0.6829,
      "step": 585700
    },
    {
      "epoch": 6.200972893431646,
      "grad_norm": 4.740493297576904,
      "learning_rate": 1.9008204531018422e-05,
      "loss": 0.6836,
      "step": 585750
    },
    {
      "epoch": 6.201502215211649,
      "grad_norm": 4.0676069259643555,
      "learning_rate": 1.9005557908109253e-05,
      "loss": 0.6898,
      "step": 585800
    },
    {
      "epoch": 6.202031536991653,
      "grad_norm": 4.500609397888184,
      "learning_rate": 1.9002911285200087e-05,
      "loss": 0.6933,
      "step": 585850
    },
    {
      "epoch": 6.202560858771656,
      "grad_norm": 4.290510177612305,
      "learning_rate": 1.9000264662290918e-05,
      "loss": 0.694,
      "step": 585900
    },
    {
      "epoch": 6.203090180551659,
      "grad_norm": 4.637966156005859,
      "learning_rate": 1.8997618039381752e-05,
      "loss": 0.6816,
      "step": 585950
    },
    {
      "epoch": 6.203619502331662,
      "grad_norm": 4.528657913208008,
      "learning_rate": 1.8994971416472582e-05,
      "loss": 0.684,
      "step": 586000
    },
    {
      "epoch": 6.203619502331662,
      "eval_loss": 0.4358126223087311,
      "eval_runtime": 46.7719,
      "eval_samples_per_second": 3590.404,
      "eval_steps_per_second": 448.817,
      "step": 586000
    },
    {
      "epoch": 6.204148824111666,
      "grad_norm": 4.2820305824279785,
      "learning_rate": 1.8992324793563417e-05,
      "loss": 0.6752,
      "step": 586050
    },
    {
      "epoch": 6.204678145891669,
      "grad_norm": 4.182394504547119,
      "learning_rate": 1.8989678170654247e-05,
      "loss": 0.6873,
      "step": 586100
    },
    {
      "epoch": 6.205207467671673,
      "grad_norm": 4.224706172943115,
      "learning_rate": 1.8987031547745078e-05,
      "loss": 0.676,
      "step": 586150
    },
    {
      "epoch": 6.2057367894516755,
      "grad_norm": 4.528194904327393,
      "learning_rate": 1.898438492483591e-05,
      "loss": 0.6841,
      "step": 586200
    },
    {
      "epoch": 6.206266111231679,
      "grad_norm": 4.101372718811035,
      "learning_rate": 1.8981738301926743e-05,
      "loss": 0.6916,
      "step": 586250
    },
    {
      "epoch": 6.206795433011682,
      "grad_norm": 4.305522441864014,
      "learning_rate": 1.8979091679017573e-05,
      "loss": 0.6744,
      "step": 586300
    },
    {
      "epoch": 6.207324754791685,
      "grad_norm": 4.154487133026123,
      "learning_rate": 1.8976445056108408e-05,
      "loss": 0.6837,
      "step": 586350
    },
    {
      "epoch": 6.207854076571689,
      "grad_norm": 4.154056549072266,
      "learning_rate": 1.897379843319924e-05,
      "loss": 0.6798,
      "step": 586400
    },
    {
      "epoch": 6.208383398351692,
      "grad_norm": 4.627209186553955,
      "learning_rate": 1.8971151810290072e-05,
      "loss": 0.6715,
      "step": 586450
    },
    {
      "epoch": 6.208912720131695,
      "grad_norm": 3.901762008666992,
      "learning_rate": 1.8968505187380903e-05,
      "loss": 0.6828,
      "step": 586500
    },
    {
      "epoch": 6.208912720131695,
      "eval_loss": 0.4351023733615875,
      "eval_runtime": 46.6427,
      "eval_samples_per_second": 3600.347,
      "eval_steps_per_second": 450.059,
      "step": 586500
    },
    {
      "epoch": 6.209442041911698,
      "grad_norm": 4.0136284828186035,
      "learning_rate": 1.8965858564471737e-05,
      "loss": 0.6724,
      "step": 586550
    },
    {
      "epoch": 6.209971363691702,
      "grad_norm": 4.77439546585083,
      "learning_rate": 1.8963211941562568e-05,
      "loss": 0.6851,
      "step": 586600
    },
    {
      "epoch": 6.210500685471705,
      "grad_norm": 4.490446090698242,
      "learning_rate": 1.8960565318653402e-05,
      "loss": 0.6704,
      "step": 586650
    },
    {
      "epoch": 6.211030007251709,
      "grad_norm": 4.493582725524902,
      "learning_rate": 1.8957918695744233e-05,
      "loss": 0.68,
      "step": 586700
    },
    {
      "epoch": 6.2115593290317115,
      "grad_norm": 4.5757317543029785,
      "learning_rate": 1.8955272072835063e-05,
      "loss": 0.696,
      "step": 586750
    },
    {
      "epoch": 6.212088650811715,
      "grad_norm": 4.112203598022461,
      "learning_rate": 1.8952625449925894e-05,
      "loss": 0.6836,
      "step": 586800
    },
    {
      "epoch": 6.212617972591718,
      "grad_norm": 4.719144344329834,
      "learning_rate": 1.8949978827016728e-05,
      "loss": 0.6905,
      "step": 586850
    },
    {
      "epoch": 6.213147294371722,
      "grad_norm": 4.136831283569336,
      "learning_rate": 1.894733220410756e-05,
      "loss": 0.678,
      "step": 586900
    },
    {
      "epoch": 6.213676616151725,
      "grad_norm": 4.145571708679199,
      "learning_rate": 1.8944685581198393e-05,
      "loss": 0.6866,
      "step": 586950
    },
    {
      "epoch": 6.2142059379317285,
      "grad_norm": 4.399900913238525,
      "learning_rate": 1.8942038958289224e-05,
      "loss": 0.6872,
      "step": 587000
    },
    {
      "epoch": 6.2142059379317285,
      "eval_loss": 0.43569234013557434,
      "eval_runtime": 46.6994,
      "eval_samples_per_second": 3595.978,
      "eval_steps_per_second": 449.513,
      "step": 587000
    },
    {
      "epoch": 6.214735259711731,
      "grad_norm": 4.325924873352051,
      "learning_rate": 1.8939392335380058e-05,
      "loss": 0.675,
      "step": 587050
    },
    {
      "epoch": 6.215264581491734,
      "grad_norm": 3.9109930992126465,
      "learning_rate": 1.893674571247089e-05,
      "loss": 0.6745,
      "step": 587100
    },
    {
      "epoch": 6.215793903271738,
      "grad_norm": 4.153839111328125,
      "learning_rate": 1.8934099089561723e-05,
      "loss": 0.6669,
      "step": 587150
    },
    {
      "epoch": 6.216323225051741,
      "grad_norm": 4.319955825805664,
      "learning_rate": 1.8931452466652553e-05,
      "loss": 0.6791,
      "step": 587200
    },
    {
      "epoch": 6.216852546831745,
      "grad_norm": 4.430399417877197,
      "learning_rate": 1.8928805843743384e-05,
      "loss": 0.6882,
      "step": 587250
    },
    {
      "epoch": 6.2173818686117475,
      "grad_norm": 4.354365825653076,
      "learning_rate": 1.8926159220834215e-05,
      "loss": 0.6696,
      "step": 587300
    },
    {
      "epoch": 6.217911190391751,
      "grad_norm": 4.6340227127075195,
      "learning_rate": 1.8923512597925046e-05,
      "loss": 0.6868,
      "step": 587350
    },
    {
      "epoch": 6.218440512171754,
      "grad_norm": 4.442574977874756,
      "learning_rate": 1.892086597501588e-05,
      "loss": 0.6799,
      "step": 587400
    },
    {
      "epoch": 6.218969833951758,
      "grad_norm": 4.04455041885376,
      "learning_rate": 1.891821935210671e-05,
      "loss": 0.6813,
      "step": 587450
    },
    {
      "epoch": 6.219499155731761,
      "grad_norm": 3.9617083072662354,
      "learning_rate": 1.8915572729197544e-05,
      "loss": 0.6858,
      "step": 587500
    },
    {
      "epoch": 6.219499155731761,
      "eval_loss": 0.43473517894744873,
      "eval_runtime": 46.697,
      "eval_samples_per_second": 3596.161,
      "eval_steps_per_second": 449.536,
      "step": 587500
    },
    {
      "epoch": 6.2200284775117645,
      "grad_norm": 4.318308353424072,
      "learning_rate": 1.8912926106288375e-05,
      "loss": 0.6924,
      "step": 587550
    },
    {
      "epoch": 6.220557799291767,
      "grad_norm": 4.716030597686768,
      "learning_rate": 1.891027948337921e-05,
      "loss": 0.6869,
      "step": 587600
    },
    {
      "epoch": 6.221087121071771,
      "grad_norm": 4.177140712738037,
      "learning_rate": 1.890763286047004e-05,
      "loss": 0.6829,
      "step": 587650
    },
    {
      "epoch": 6.221616442851774,
      "grad_norm": 3.9854371547698975,
      "learning_rate": 1.8904986237560874e-05,
      "loss": 0.6811,
      "step": 587700
    },
    {
      "epoch": 6.222145764631778,
      "grad_norm": 4.18789005279541,
      "learning_rate": 1.8902339614651705e-05,
      "loss": 0.6918,
      "step": 587750
    },
    {
      "epoch": 6.222675086411781,
      "grad_norm": 4.364373683929443,
      "learning_rate": 1.889969299174254e-05,
      "loss": 0.6857,
      "step": 587800
    },
    {
      "epoch": 6.223204408191783,
      "grad_norm": 3.9735934734344482,
      "learning_rate": 1.889704636883337e-05,
      "loss": 0.6909,
      "step": 587850
    },
    {
      "epoch": 6.223733729971787,
      "grad_norm": 4.5330071449279785,
      "learning_rate": 1.88943997459242e-05,
      "loss": 0.6836,
      "step": 587900
    },
    {
      "epoch": 6.22426305175179,
      "grad_norm": 4.326857089996338,
      "learning_rate": 1.889175312301503e-05,
      "loss": 0.6754,
      "step": 587950
    },
    {
      "epoch": 6.224792373531794,
      "grad_norm": 4.651567459106445,
      "learning_rate": 1.8889106500105865e-05,
      "loss": 0.6819,
      "step": 588000
    },
    {
      "epoch": 6.224792373531794,
      "eval_loss": 0.43628203868865967,
      "eval_runtime": 46.7478,
      "eval_samples_per_second": 3592.255,
      "eval_steps_per_second": 449.048,
      "step": 588000
    },
    {
      "epoch": 6.225321695311797,
      "grad_norm": 3.9355316162109375,
      "learning_rate": 1.8886459877196696e-05,
      "loss": 0.6826,
      "step": 588050
    },
    {
      "epoch": 6.2258510170918,
      "grad_norm": 4.671745777130127,
      "learning_rate": 1.888381325428753e-05,
      "loss": 0.6744,
      "step": 588100
    },
    {
      "epoch": 6.226380338871803,
      "grad_norm": 4.02500057220459,
      "learning_rate": 1.888116663137836e-05,
      "loss": 0.6797,
      "step": 588150
    },
    {
      "epoch": 6.226909660651807,
      "grad_norm": 4.436553955078125,
      "learning_rate": 1.8878520008469195e-05,
      "loss": 0.6793,
      "step": 588200
    },
    {
      "epoch": 6.22743898243181,
      "grad_norm": 3.576249122619629,
      "learning_rate": 1.8875873385560025e-05,
      "loss": 0.6806,
      "step": 588250
    },
    {
      "epoch": 6.227968304211814,
      "grad_norm": 4.457632064819336,
      "learning_rate": 1.887322676265086e-05,
      "loss": 0.6894,
      "step": 588300
    },
    {
      "epoch": 6.2284976259918166,
      "grad_norm": 4.306576728820801,
      "learning_rate": 1.887058013974169e-05,
      "loss": 0.6791,
      "step": 588350
    },
    {
      "epoch": 6.22902694777182,
      "grad_norm": 4.708115100860596,
      "learning_rate": 1.8867933516832524e-05,
      "loss": 0.6918,
      "step": 588400
    },
    {
      "epoch": 6.229556269551823,
      "grad_norm": 4.685972213745117,
      "learning_rate": 1.8865286893923355e-05,
      "loss": 0.6729,
      "step": 588450
    },
    {
      "epoch": 6.230085591331827,
      "grad_norm": 4.129366874694824,
      "learning_rate": 1.8862640271014186e-05,
      "loss": 0.6799,
      "step": 588500
    },
    {
      "epoch": 6.230085591331827,
      "eval_loss": 0.4337586760520935,
      "eval_runtime": 46.7585,
      "eval_samples_per_second": 3591.433,
      "eval_steps_per_second": 448.945,
      "step": 588500
    },
    {
      "epoch": 6.23061491311183,
      "grad_norm": 4.329861164093018,
      "learning_rate": 1.8859993648105017e-05,
      "loss": 0.6822,
      "step": 588550
    },
    {
      "epoch": 6.231144234891833,
      "grad_norm": 4.658068656921387,
      "learning_rate": 1.885734702519585e-05,
      "loss": 0.6786,
      "step": 588600
    },
    {
      "epoch": 6.231673556671836,
      "grad_norm": 4.599173545837402,
      "learning_rate": 1.885470040228668e-05,
      "loss": 0.6954,
      "step": 588650
    },
    {
      "epoch": 6.232202878451839,
      "grad_norm": 5.007208347320557,
      "learning_rate": 1.8852053779377515e-05,
      "loss": 0.6756,
      "step": 588700
    },
    {
      "epoch": 6.232732200231843,
      "grad_norm": 4.889468669891357,
      "learning_rate": 1.8849407156468346e-05,
      "loss": 0.6959,
      "step": 588750
    },
    {
      "epoch": 6.233261522011846,
      "grad_norm": 4.731814861297607,
      "learning_rate": 1.884676053355918e-05,
      "loss": 0.6956,
      "step": 588800
    },
    {
      "epoch": 6.23379084379185,
      "grad_norm": 3.9546260833740234,
      "learning_rate": 1.884411391065001e-05,
      "loss": 0.6789,
      "step": 588850
    },
    {
      "epoch": 6.2343201655718525,
      "grad_norm": 4.706913471221924,
      "learning_rate": 1.8841520220199026e-05,
      "loss": 0.6869,
      "step": 588900
    },
    {
      "epoch": 6.234849487351856,
      "grad_norm": 4.307709693908691,
      "learning_rate": 1.8838873597289856e-05,
      "loss": 0.676,
      "step": 588950
    },
    {
      "epoch": 6.235378809131859,
      "grad_norm": 4.544735908508301,
      "learning_rate": 1.883622697438069e-05,
      "loss": 0.6836,
      "step": 589000
    },
    {
      "epoch": 6.235378809131859,
      "eval_loss": 0.4339379370212555,
      "eval_runtime": 46.7125,
      "eval_samples_per_second": 3594.969,
      "eval_steps_per_second": 449.387,
      "step": 589000
    },
    {
      "epoch": 6.235908130911863,
      "grad_norm": 4.495242595672607,
      "learning_rate": 1.883358035147152e-05,
      "loss": 0.6914,
      "step": 589050
    },
    {
      "epoch": 6.236437452691866,
      "grad_norm": 4.326381683349609,
      "learning_rate": 1.8830933728562355e-05,
      "loss": 0.6942,
      "step": 589100
    },
    {
      "epoch": 6.2369667744718695,
      "grad_norm": 4.760469436645508,
      "learning_rate": 1.8828287105653186e-05,
      "loss": 0.6807,
      "step": 589150
    },
    {
      "epoch": 6.237496096251872,
      "grad_norm": 4.565664291381836,
      "learning_rate": 1.882564048274402e-05,
      "loss": 0.6729,
      "step": 589200
    },
    {
      "epoch": 6.238025418031876,
      "grad_norm": 4.055473804473877,
      "learning_rate": 1.882299385983485e-05,
      "loss": 0.685,
      "step": 589250
    },
    {
      "epoch": 6.238554739811879,
      "grad_norm": 4.793406963348389,
      "learning_rate": 1.8820347236925685e-05,
      "loss": 0.6876,
      "step": 589300
    },
    {
      "epoch": 6.239084061591882,
      "grad_norm": 4.189855575561523,
      "learning_rate": 1.8817700614016516e-05,
      "loss": 0.6826,
      "step": 589350
    },
    {
      "epoch": 6.239613383371886,
      "grad_norm": 4.387242794036865,
      "learning_rate": 1.881505399110735e-05,
      "loss": 0.6856,
      "step": 589400
    },
    {
      "epoch": 6.2401427051518885,
      "grad_norm": 4.558340072631836,
      "learning_rate": 1.881240736819818e-05,
      "loss": 0.6784,
      "step": 589450
    },
    {
      "epoch": 6.240672026931892,
      "grad_norm": 4.686629772186279,
      "learning_rate": 1.880976074528901e-05,
      "loss": 0.6757,
      "step": 589500
    },
    {
      "epoch": 6.240672026931892,
      "eval_loss": 0.43465447425842285,
      "eval_runtime": 46.7566,
      "eval_samples_per_second": 3591.58,
      "eval_steps_per_second": 448.963,
      "step": 589500
    },
    {
      "epoch": 6.241201348711895,
      "grad_norm": 4.552947521209717,
      "learning_rate": 1.8807114122379842e-05,
      "loss": 0.6861,
      "step": 589550
    },
    {
      "epoch": 6.241730670491899,
      "grad_norm": 4.892829895019531,
      "learning_rate": 1.8804467499470676e-05,
      "loss": 0.6926,
      "step": 589600
    },
    {
      "epoch": 6.242259992271902,
      "grad_norm": 4.55228853225708,
      "learning_rate": 1.8801820876561507e-05,
      "loss": 0.6806,
      "step": 589650
    },
    {
      "epoch": 6.2427893140519055,
      "grad_norm": 4.477644920349121,
      "learning_rate": 1.879917425365234e-05,
      "loss": 0.6887,
      "step": 589700
    },
    {
      "epoch": 6.243318635831908,
      "grad_norm": 4.373290538787842,
      "learning_rate": 1.879652763074317e-05,
      "loss": 0.6945,
      "step": 589750
    },
    {
      "epoch": 6.243847957611912,
      "grad_norm": 4.687686443328857,
      "learning_rate": 1.8793881007834006e-05,
      "loss": 0.6834,
      "step": 589800
    },
    {
      "epoch": 6.244377279391915,
      "grad_norm": 4.374584197998047,
      "learning_rate": 1.8791234384924836e-05,
      "loss": 0.6722,
      "step": 589850
    },
    {
      "epoch": 6.244906601171919,
      "grad_norm": 4.100589275360107,
      "learning_rate": 1.878858776201567e-05,
      "loss": 0.6891,
      "step": 589900
    },
    {
      "epoch": 6.245435922951922,
      "grad_norm": 4.735658645629883,
      "learning_rate": 1.87859411391065e-05,
      "loss": 0.6867,
      "step": 589950
    },
    {
      "epoch": 6.245965244731925,
      "grad_norm": 4.1536455154418945,
      "learning_rate": 1.8783294516197332e-05,
      "loss": 0.6853,
      "step": 590000
    },
    {
      "epoch": 6.245965244731925,
      "eval_loss": 0.4343511760234833,
      "eval_runtime": 46.683,
      "eval_samples_per_second": 3597.242,
      "eval_steps_per_second": 449.671,
      "step": 590000
    },
    {
      "epoch": 6.246494566511928,
      "grad_norm": 4.2739410400390625,
      "learning_rate": 1.8780647893288163e-05,
      "loss": 0.6843,
      "step": 590050
    },
    {
      "epoch": 6.247023888291931,
      "grad_norm": 4.2183732986450195,
      "learning_rate": 1.8778001270378997e-05,
      "loss": 0.6868,
      "step": 590100
    },
    {
      "epoch": 6.247553210071935,
      "grad_norm": 4.446895599365234,
      "learning_rate": 1.8775354647469827e-05,
      "loss": 0.6826,
      "step": 590150
    },
    {
      "epoch": 6.248082531851938,
      "grad_norm": 4.111928462982178,
      "learning_rate": 1.877270802456066e-05,
      "loss": 0.6808,
      "step": 590200
    },
    {
      "epoch": 6.2486118536319415,
      "grad_norm": 4.943162441253662,
      "learning_rate": 1.8770061401651492e-05,
      "loss": 0.6883,
      "step": 590250
    },
    {
      "epoch": 6.249141175411944,
      "grad_norm": 3.8116040229797363,
      "learning_rate": 1.8767414778742326e-05,
      "loss": 0.6702,
      "step": 590300
    },
    {
      "epoch": 6.249670497191948,
      "grad_norm": 4.348069190979004,
      "learning_rate": 1.8764768155833157e-05,
      "loss": 0.6774,
      "step": 590350
    },
    {
      "epoch": 6.250199818971951,
      "grad_norm": 4.682300090789795,
      "learning_rate": 1.876212153292399e-05,
      "loss": 0.6936,
      "step": 590400
    },
    {
      "epoch": 6.250729140751955,
      "grad_norm": 4.463441371917725,
      "learning_rate": 1.8759474910014822e-05,
      "loss": 0.6918,
      "step": 590450
    },
    {
      "epoch": 6.251258462531958,
      "grad_norm": 3.9462976455688477,
      "learning_rate": 1.8756828287105656e-05,
      "loss": 0.6808,
      "step": 590500
    },
    {
      "epoch": 6.251258462531958,
      "eval_loss": 0.4338134229183197,
      "eval_runtime": 46.9018,
      "eval_samples_per_second": 3580.457,
      "eval_steps_per_second": 447.573,
      "step": 590500
    },
    {
      "epoch": 6.251787784311961,
      "grad_norm": 4.256103992462158,
      "learning_rate": 1.8754181664196487e-05,
      "loss": 0.6809,
      "step": 590550
    },
    {
      "epoch": 6.252317106091964,
      "grad_norm": 4.054590702056885,
      "learning_rate": 1.8751535041287317e-05,
      "loss": 0.674,
      "step": 590600
    },
    {
      "epoch": 6.252846427871968,
      "grad_norm": 4.3772101402282715,
      "learning_rate": 1.8748888418378148e-05,
      "loss": 0.676,
      "step": 590650
    },
    {
      "epoch": 6.253375749651971,
      "grad_norm": 4.3544087409973145,
      "learning_rate": 1.8746241795468982e-05,
      "loss": 0.6806,
      "step": 590700
    },
    {
      "epoch": 6.253905071431975,
      "grad_norm": 4.553146839141846,
      "learning_rate": 1.8743595172559813e-05,
      "loss": 0.6883,
      "step": 590750
    },
    {
      "epoch": 6.2544343932119775,
      "grad_norm": 4.341881275177002,
      "learning_rate": 1.8740948549650647e-05,
      "loss": 0.6829,
      "step": 590800
    },
    {
      "epoch": 6.25496371499198,
      "grad_norm": 3.928435802459717,
      "learning_rate": 1.8738301926741478e-05,
      "loss": 0.6795,
      "step": 590850
    },
    {
      "epoch": 6.255493036771984,
      "grad_norm": 4.039336681365967,
      "learning_rate": 1.8735708236290496e-05,
      "loss": 0.6714,
      "step": 590900
    },
    {
      "epoch": 6.256022358551987,
      "grad_norm": 4.362357139587402,
      "learning_rate": 1.8733061613381326e-05,
      "loss": 0.6752,
      "step": 590950
    },
    {
      "epoch": 6.256551680331991,
      "grad_norm": 4.368630886077881,
      "learning_rate": 1.8730414990472157e-05,
      "loss": 0.6794,
      "step": 591000
    },
    {
      "epoch": 6.256551680331991,
      "eval_loss": 0.43415266275405884,
      "eval_runtime": 46.7518,
      "eval_samples_per_second": 3591.946,
      "eval_steps_per_second": 449.009,
      "step": 591000
    },
    {
      "epoch": 6.257081002111994,
      "grad_norm": 3.9832513332366943,
      "learning_rate": 1.8727768367562988e-05,
      "loss": 0.6836,
      "step": 591050
    },
    {
      "epoch": 6.257610323891997,
      "grad_norm": 3.9763054847717285,
      "learning_rate": 1.8725121744653822e-05,
      "loss": 0.6806,
      "step": 591100
    },
    {
      "epoch": 6.258139645672,
      "grad_norm": 4.1932477951049805,
      "learning_rate": 1.8722475121744653e-05,
      "loss": 0.6808,
      "step": 591150
    },
    {
      "epoch": 6.258668967452004,
      "grad_norm": 4.397809982299805,
      "learning_rate": 1.8719828498835487e-05,
      "loss": 0.676,
      "step": 591200
    },
    {
      "epoch": 6.259198289232007,
      "grad_norm": 4.03441858291626,
      "learning_rate": 1.8717181875926317e-05,
      "loss": 0.6863,
      "step": 591250
    },
    {
      "epoch": 6.259727611012011,
      "grad_norm": 4.404317855834961,
      "learning_rate": 1.871453525301715e-05,
      "loss": 0.6817,
      "step": 591300
    },
    {
      "epoch": 6.2602569327920135,
      "grad_norm": 4.548236846923828,
      "learning_rate": 1.8711888630107982e-05,
      "loss": 0.6797,
      "step": 591350
    },
    {
      "epoch": 6.260786254572017,
      "grad_norm": 4.405901908874512,
      "learning_rate": 1.8709242007198816e-05,
      "loss": 0.6852,
      "step": 591400
    },
    {
      "epoch": 6.26131557635202,
      "grad_norm": 4.396435260772705,
      "learning_rate": 1.8706595384289647e-05,
      "loss": 0.6814,
      "step": 591450
    },
    {
      "epoch": 6.261844898132024,
      "grad_norm": 4.1797637939453125,
      "learning_rate": 1.870394876138048e-05,
      "loss": 0.6841,
      "step": 591500
    },
    {
      "epoch": 6.261844898132024,
      "eval_loss": 0.4358105957508087,
      "eval_runtime": 46.7747,
      "eval_samples_per_second": 3590.189,
      "eval_steps_per_second": 448.79,
      "step": 591500
    },
    {
      "epoch": 6.262374219912027,
      "grad_norm": 4.648866176605225,
      "learning_rate": 1.8701302138471312e-05,
      "loss": 0.6731,
      "step": 591550
    },
    {
      "epoch": 6.26290354169203,
      "grad_norm": 4.1538405418396,
      "learning_rate": 1.8698655515562143e-05,
      "loss": 0.6837,
      "step": 591600
    },
    {
      "epoch": 6.263432863472033,
      "grad_norm": 4.39203405380249,
      "learning_rate": 1.8696008892652973e-05,
      "loss": 0.6896,
      "step": 591650
    },
    {
      "epoch": 6.263962185252036,
      "grad_norm": 4.434788227081299,
      "learning_rate": 1.8693362269743807e-05,
      "loss": 0.681,
      "step": 591700
    },
    {
      "epoch": 6.26449150703204,
      "grad_norm": 4.4399261474609375,
      "learning_rate": 1.8690715646834638e-05,
      "loss": 0.6734,
      "step": 591750
    },
    {
      "epoch": 6.265020828812043,
      "grad_norm": 4.288234710693359,
      "learning_rate": 1.8688069023925472e-05,
      "loss": 0.6828,
      "step": 591800
    },
    {
      "epoch": 6.265550150592047,
      "grad_norm": 4.7012553215026855,
      "learning_rate": 1.8685422401016303e-05,
      "loss": 0.6846,
      "step": 591850
    },
    {
      "epoch": 6.266079472372049,
      "grad_norm": 4.323366165161133,
      "learning_rate": 1.8682775778107137e-05,
      "loss": 0.6888,
      "step": 591900
    },
    {
      "epoch": 6.266608794152053,
      "grad_norm": 4.465747356414795,
      "learning_rate": 1.8680129155197968e-05,
      "loss": 0.6858,
      "step": 591950
    },
    {
      "epoch": 6.267138115932056,
      "grad_norm": 4.464089870452881,
      "learning_rate": 1.8677482532288802e-05,
      "loss": 0.6826,
      "step": 592000
    },
    {
      "epoch": 6.267138115932056,
      "eval_loss": 0.4350293278694153,
      "eval_runtime": 47.6174,
      "eval_samples_per_second": 3526.653,
      "eval_steps_per_second": 440.847,
      "step": 592000
    },
    {
      "epoch": 6.26766743771206,
      "grad_norm": 4.498337745666504,
      "learning_rate": 1.8674835909379633e-05,
      "loss": 0.6701,
      "step": 592050
    },
    {
      "epoch": 6.268196759492063,
      "grad_norm": 4.150564670562744,
      "learning_rate": 1.8672189286470467e-05,
      "loss": 0.6734,
      "step": 592100
    },
    {
      "epoch": 6.268726081272066,
      "grad_norm": 4.391500949859619,
      "learning_rate": 1.8669542663561297e-05,
      "loss": 0.6834,
      "step": 592150
    },
    {
      "epoch": 6.269255403052069,
      "grad_norm": 4.432397365570068,
      "learning_rate": 1.8666896040652128e-05,
      "loss": 0.6779,
      "step": 592200
    },
    {
      "epoch": 6.269784724832073,
      "grad_norm": 4.274418830871582,
      "learning_rate": 1.866424941774296e-05,
      "loss": 0.6851,
      "step": 592250
    },
    {
      "epoch": 6.270314046612076,
      "grad_norm": 4.471070289611816,
      "learning_rate": 1.8661602794833793e-05,
      "loss": 0.6803,
      "step": 592300
    },
    {
      "epoch": 6.270843368392079,
      "grad_norm": 4.4873833656311035,
      "learning_rate": 1.8658956171924624e-05,
      "loss": 0.6719,
      "step": 592350
    },
    {
      "epoch": 6.2713726901720825,
      "grad_norm": 4.100337028503418,
      "learning_rate": 1.8656309549015458e-05,
      "loss": 0.679,
      "step": 592400
    },
    {
      "epoch": 6.271902011952085,
      "grad_norm": 4.481588840484619,
      "learning_rate": 1.865366292610629e-05,
      "loss": 0.6875,
      "step": 592450
    },
    {
      "epoch": 6.272431333732089,
      "grad_norm": 4.2976179122924805,
      "learning_rate": 1.8651016303197123e-05,
      "loss": 0.6774,
      "step": 592500
    },
    {
      "epoch": 6.272431333732089,
      "eval_loss": 0.43426814675331116,
      "eval_runtime": 47.8853,
      "eval_samples_per_second": 3506.923,
      "eval_steps_per_second": 438.381,
      "step": 592500
    },
    {
      "epoch": 6.272960655512092,
      "grad_norm": 4.2345380783081055,
      "learning_rate": 1.8648369680287953e-05,
      "loss": 0.6835,
      "step": 592550
    },
    {
      "epoch": 6.273489977292096,
      "grad_norm": 4.805232524871826,
      "learning_rate": 1.8645723057378787e-05,
      "loss": 0.6768,
      "step": 592600
    },
    {
      "epoch": 6.274019299072099,
      "grad_norm": 4.122167587280273,
      "learning_rate": 1.8643076434469618e-05,
      "loss": 0.6875,
      "step": 592650
    },
    {
      "epoch": 6.274548620852102,
      "grad_norm": 4.475671768188477,
      "learning_rate": 1.864042981156045e-05,
      "loss": 0.6875,
      "step": 592700
    },
    {
      "epoch": 6.275077942632105,
      "grad_norm": 4.593408107757568,
      "learning_rate": 1.863778318865128e-05,
      "loss": 0.6789,
      "step": 592750
    },
    {
      "epoch": 6.275607264412109,
      "grad_norm": 3.873406171798706,
      "learning_rate": 1.8635136565742114e-05,
      "loss": 0.6763,
      "step": 592800
    },
    {
      "epoch": 6.276136586192112,
      "grad_norm": 4.262577533721924,
      "learning_rate": 1.8632489942832944e-05,
      "loss": 0.6851,
      "step": 592850
    },
    {
      "epoch": 6.276665907972116,
      "grad_norm": 4.62876033782959,
      "learning_rate": 1.8629896252381962e-05,
      "loss": 0.6772,
      "step": 592900
    },
    {
      "epoch": 6.2771952297521185,
      "grad_norm": 4.1746039390563965,
      "learning_rate": 1.8627249629472793e-05,
      "loss": 0.6868,
      "step": 592950
    },
    {
      "epoch": 6.277724551532122,
      "grad_norm": 4.8316969871521,
      "learning_rate": 1.8624603006563627e-05,
      "loss": 0.6779,
      "step": 593000
    },
    {
      "epoch": 6.277724551532122,
      "eval_loss": 0.43305808305740356,
      "eval_runtime": 47.4865,
      "eval_samples_per_second": 3536.371,
      "eval_steps_per_second": 442.062,
      "step": 593000
    },
    {
      "epoch": 6.278253873312125,
      "grad_norm": 4.930455207824707,
      "learning_rate": 1.8621956383654458e-05,
      "loss": 0.6803,
      "step": 593050
    },
    {
      "epoch": 6.278783195092128,
      "grad_norm": 4.5547966957092285,
      "learning_rate": 1.8619309760745292e-05,
      "loss": 0.6933,
      "step": 593100
    },
    {
      "epoch": 6.279312516872132,
      "grad_norm": 4.139520168304443,
      "learning_rate": 1.8616663137836123e-05,
      "loss": 0.6885,
      "step": 593150
    },
    {
      "epoch": 6.279841838652135,
      "grad_norm": 4.545949935913086,
      "learning_rate": 1.8614016514926953e-05,
      "loss": 0.668,
      "step": 593200
    },
    {
      "epoch": 6.280371160432138,
      "grad_norm": 4.4111328125,
      "learning_rate": 1.8611369892017784e-05,
      "loss": 0.6807,
      "step": 593250
    },
    {
      "epoch": 6.280900482212141,
      "grad_norm": 4.191028594970703,
      "learning_rate": 1.8608723269108618e-05,
      "loss": 0.6933,
      "step": 593300
    },
    {
      "epoch": 6.281429803992145,
      "grad_norm": 4.286045074462891,
      "learning_rate": 1.860607664619945e-05,
      "loss": 0.6793,
      "step": 593350
    },
    {
      "epoch": 6.281959125772148,
      "grad_norm": 4.712400436401367,
      "learning_rate": 1.8603430023290283e-05,
      "loss": 0.6831,
      "step": 593400
    },
    {
      "epoch": 6.282488447552152,
      "grad_norm": 4.494184970855713,
      "learning_rate": 1.8600783400381114e-05,
      "loss": 0.6881,
      "step": 593450
    },
    {
      "epoch": 6.2830177693321545,
      "grad_norm": 4.442309856414795,
      "learning_rate": 1.8598136777471948e-05,
      "loss": 0.6805,
      "step": 593500
    },
    {
      "epoch": 6.2830177693321545,
      "eval_loss": 0.4345211386680603,
      "eval_runtime": 46.943,
      "eval_samples_per_second": 3577.315,
      "eval_steps_per_second": 447.18,
      "step": 593500
    },
    {
      "epoch": 6.283547091112158,
      "grad_norm": 4.463594436645508,
      "learning_rate": 1.859549015456278e-05,
      "loss": 0.7003,
      "step": 593550
    },
    {
      "epoch": 6.284076412892161,
      "grad_norm": 4.830715656280518,
      "learning_rate": 1.8592843531653613e-05,
      "loss": 0.676,
      "step": 593600
    },
    {
      "epoch": 6.284605734672165,
      "grad_norm": 4.46098518371582,
      "learning_rate": 1.8590196908744443e-05,
      "loss": 0.6812,
      "step": 593650
    },
    {
      "epoch": 6.285135056452168,
      "grad_norm": 4.50264310836792,
      "learning_rate": 1.8587550285835274e-05,
      "loss": 0.6999,
      "step": 593700
    },
    {
      "epoch": 6.2856643782321715,
      "grad_norm": 4.780759334564209,
      "learning_rate": 1.8584903662926105e-05,
      "loss": 0.6782,
      "step": 593750
    },
    {
      "epoch": 6.286193700012174,
      "grad_norm": 4.707104206085205,
      "learning_rate": 1.858225704001694e-05,
      "loss": 0.676,
      "step": 593800
    },
    {
      "epoch": 6.286723021792177,
      "grad_norm": 4.530978202819824,
      "learning_rate": 1.857961041710777e-05,
      "loss": 0.6827,
      "step": 593850
    },
    {
      "epoch": 6.287252343572181,
      "grad_norm": 4.488589763641357,
      "learning_rate": 1.8576963794198604e-05,
      "loss": 0.673,
      "step": 593900
    },
    {
      "epoch": 6.287781665352184,
      "grad_norm": 4.456994533538818,
      "learning_rate": 1.8574317171289434e-05,
      "loss": 0.6882,
      "step": 593950
    },
    {
      "epoch": 6.288310987132188,
      "grad_norm": 4.74409818649292,
      "learning_rate": 1.857167054838027e-05,
      "loss": 0.6822,
      "step": 594000
    },
    {
      "epoch": 6.288310987132188,
      "eval_loss": 0.4343283474445343,
      "eval_runtime": 46.7673,
      "eval_samples_per_second": 3590.753,
      "eval_steps_per_second": 448.86,
      "step": 594000
    },
    {
      "epoch": 6.2888403089121905,
      "grad_norm": 4.430140018463135,
      "learning_rate": 1.85690239254711e-05,
      "loss": 0.6874,
      "step": 594050
    },
    {
      "epoch": 6.289369630692194,
      "grad_norm": 3.887338399887085,
      "learning_rate": 1.8566377302561933e-05,
      "loss": 0.6736,
      "step": 594100
    },
    {
      "epoch": 6.289898952472197,
      "grad_norm": 4.860934734344482,
      "learning_rate": 1.8563730679652764e-05,
      "loss": 0.6917,
      "step": 594150
    },
    {
      "epoch": 6.290428274252201,
      "grad_norm": 4.319286346435547,
      "learning_rate": 1.8561084056743598e-05,
      "loss": 0.6881,
      "step": 594200
    },
    {
      "epoch": 6.290957596032204,
      "grad_norm": 4.384842395782471,
      "learning_rate": 1.855843743383443e-05,
      "loss": 0.6697,
      "step": 594250
    },
    {
      "epoch": 6.2914869178122075,
      "grad_norm": 4.713651657104492,
      "learning_rate": 1.855579081092526e-05,
      "loss": 0.6711,
      "step": 594300
    },
    {
      "epoch": 6.29201623959221,
      "grad_norm": 4.408679008483887,
      "learning_rate": 1.855314418801609e-05,
      "loss": 0.6717,
      "step": 594350
    },
    {
      "epoch": 6.292545561372214,
      "grad_norm": 4.247145175933838,
      "learning_rate": 1.8550497565106924e-05,
      "loss": 0.6949,
      "step": 594400
    },
    {
      "epoch": 6.293074883152217,
      "grad_norm": 3.8609535694122314,
      "learning_rate": 1.8547850942197755e-05,
      "loss": 0.69,
      "step": 594450
    },
    {
      "epoch": 6.293604204932221,
      "grad_norm": 4.844975471496582,
      "learning_rate": 1.854520431928859e-05,
      "loss": 0.6839,
      "step": 594500
    },
    {
      "epoch": 6.293604204932221,
      "eval_loss": 0.43323761224746704,
      "eval_runtime": 46.7162,
      "eval_samples_per_second": 3594.688,
      "eval_steps_per_second": 449.352,
      "step": 594500
    },
    {
      "epoch": 6.294133526712224,
      "grad_norm": 4.515087127685547,
      "learning_rate": 1.854255769637942e-05,
      "loss": 0.6727,
      "step": 594550
    },
    {
      "epoch": 6.2946628484922265,
      "grad_norm": 4.431923866271973,
      "learning_rate": 1.8539911073470254e-05,
      "loss": 0.6835,
      "step": 594600
    },
    {
      "epoch": 6.29519217027223,
      "grad_norm": 4.464583873748779,
      "learning_rate": 1.8537264450561085e-05,
      "loss": 0.6924,
      "step": 594650
    },
    {
      "epoch": 6.295721492052233,
      "grad_norm": 4.55025577545166,
      "learning_rate": 1.853461782765192e-05,
      "loss": 0.6874,
      "step": 594700
    },
    {
      "epoch": 6.296250813832237,
      "grad_norm": 4.592330455780029,
      "learning_rate": 1.853197120474275e-05,
      "loss": 0.6928,
      "step": 594750
    },
    {
      "epoch": 6.29678013561224,
      "grad_norm": 4.480359077453613,
      "learning_rate": 1.8529324581833584e-05,
      "loss": 0.6795,
      "step": 594800
    },
    {
      "epoch": 6.2973094573922435,
      "grad_norm": 4.268848419189453,
      "learning_rate": 1.8526677958924414e-05,
      "loss": 0.6776,
      "step": 594850
    },
    {
      "epoch": 6.297838779172246,
      "grad_norm": 4.378420352935791,
      "learning_rate": 1.8524031336015245e-05,
      "loss": 0.6917,
      "step": 594900
    },
    {
      "epoch": 6.29836810095225,
      "grad_norm": 4.55739688873291,
      "learning_rate": 1.852143764556426e-05,
      "loss": 0.6916,
      "step": 594950
    },
    {
      "epoch": 6.298897422732253,
      "grad_norm": 4.426009178161621,
      "learning_rate": 1.8518791022655094e-05,
      "loss": 0.6919,
      "step": 595000
    },
    {
      "epoch": 6.298897422732253,
      "eval_loss": 0.4333516061306,
      "eval_runtime": 46.8048,
      "eval_samples_per_second": 3587.878,
      "eval_steps_per_second": 448.501,
      "step": 595000
    },
    {
      "epoch": 6.299426744512257,
      "grad_norm": 4.6233930587768555,
      "learning_rate": 1.8516144399745925e-05,
      "loss": 0.6877,
      "step": 595050
    },
    {
      "epoch": 6.29995606629226,
      "grad_norm": 4.079779148101807,
      "learning_rate": 1.851349777683676e-05,
      "loss": 0.6802,
      "step": 595100
    },
    {
      "epoch": 6.300485388072263,
      "grad_norm": 4.136923789978027,
      "learning_rate": 1.851085115392759e-05,
      "loss": 0.6817,
      "step": 595150
    },
    {
      "epoch": 6.301014709852266,
      "grad_norm": 4.534754753112793,
      "learning_rate": 1.8508204531018424e-05,
      "loss": 0.6836,
      "step": 595200
    },
    {
      "epoch": 6.30154403163227,
      "grad_norm": 4.4858527183532715,
      "learning_rate": 1.8505557908109254e-05,
      "loss": 0.677,
      "step": 595250
    },
    {
      "epoch": 6.302073353412273,
      "grad_norm": 4.199837684631348,
      "learning_rate": 1.8502911285200085e-05,
      "loss": 0.6692,
      "step": 595300
    },
    {
      "epoch": 6.302602675192276,
      "grad_norm": 4.241311550140381,
      "learning_rate": 1.8500264662290916e-05,
      "loss": 0.6803,
      "step": 595350
    },
    {
      "epoch": 6.303131996972279,
      "grad_norm": 4.4780120849609375,
      "learning_rate": 1.849761803938175e-05,
      "loss": 0.6906,
      "step": 595400
    },
    {
      "epoch": 6.303661318752282,
      "grad_norm": 4.43203592300415,
      "learning_rate": 1.849497141647258e-05,
      "loss": 0.6948,
      "step": 595450
    },
    {
      "epoch": 6.304190640532286,
      "grad_norm": 4.27367639541626,
      "learning_rate": 1.8492324793563415e-05,
      "loss": 0.6918,
      "step": 595500
    },
    {
      "epoch": 6.304190640532286,
      "eval_loss": 0.43263721466064453,
      "eval_runtime": 46.8534,
      "eval_samples_per_second": 3584.158,
      "eval_steps_per_second": 448.036,
      "step": 595500
    },
    {
      "epoch": 6.304719962312289,
      "grad_norm": 4.267234802246094,
      "learning_rate": 1.8489678170654245e-05,
      "loss": 0.6769,
      "step": 595550
    },
    {
      "epoch": 6.305249284092293,
      "grad_norm": 4.252192497253418,
      "learning_rate": 1.848703154774508e-05,
      "loss": 0.665,
      "step": 595600
    },
    {
      "epoch": 6.3057786058722956,
      "grad_norm": 4.353640556335449,
      "learning_rate": 1.848438492483591e-05,
      "loss": 0.6663,
      "step": 595650
    },
    {
      "epoch": 6.306307927652299,
      "grad_norm": 4.728999614715576,
      "learning_rate": 1.8481738301926744e-05,
      "loss": 0.6732,
      "step": 595700
    },
    {
      "epoch": 6.306837249432302,
      "grad_norm": 4.08193302154541,
      "learning_rate": 1.8479091679017575e-05,
      "loss": 0.6811,
      "step": 595750
    },
    {
      "epoch": 6.307366571212306,
      "grad_norm": 4.135836124420166,
      "learning_rate": 1.847644505610841e-05,
      "loss": 0.6851,
      "step": 595800
    },
    {
      "epoch": 6.307895892992309,
      "grad_norm": 4.361605167388916,
      "learning_rate": 1.847379843319924e-05,
      "loss": 0.6689,
      "step": 595850
    },
    {
      "epoch": 6.3084252147723126,
      "grad_norm": 4.297917366027832,
      "learning_rate": 1.847115181029007e-05,
      "loss": 0.6647,
      "step": 595900
    },
    {
      "epoch": 6.308954536552315,
      "grad_norm": 4.282482147216797,
      "learning_rate": 1.84685051873809e-05,
      "loss": 0.6878,
      "step": 595950
    },
    {
      "epoch": 6.309483858332319,
      "grad_norm": 4.330411434173584,
      "learning_rate": 1.8465858564471735e-05,
      "loss": 0.6828,
      "step": 596000
    },
    {
      "epoch": 6.309483858332319,
      "eval_loss": 0.43210911750793457,
      "eval_runtime": 47.6918,
      "eval_samples_per_second": 3521.147,
      "eval_steps_per_second": 440.159,
      "step": 596000
    },
    {
      "epoch": 6.310013180112322,
      "grad_norm": 4.253600120544434,
      "learning_rate": 1.8463211941562566e-05,
      "loss": 0.6821,
      "step": 596050
    },
    {
      "epoch": 6.310542501892325,
      "grad_norm": 4.3008131980896,
      "learning_rate": 1.84605653186534e-05,
      "loss": 0.689,
      "step": 596100
    },
    {
      "epoch": 6.311071823672329,
      "grad_norm": 4.172405242919922,
      "learning_rate": 1.845791869574423e-05,
      "loss": 0.6757,
      "step": 596150
    },
    {
      "epoch": 6.3116011454523315,
      "grad_norm": 4.593110084533691,
      "learning_rate": 1.8455272072835065e-05,
      "loss": 0.6824,
      "step": 596200
    },
    {
      "epoch": 6.312130467232335,
      "grad_norm": 4.150666236877441,
      "learning_rate": 1.8452625449925896e-05,
      "loss": 0.673,
      "step": 596250
    },
    {
      "epoch": 6.312659789012338,
      "grad_norm": 4.027393817901611,
      "learning_rate": 1.844997882701673e-05,
      "loss": 0.6785,
      "step": 596300
    },
    {
      "epoch": 6.313189110792342,
      "grad_norm": 4.132978916168213,
      "learning_rate": 1.844733220410756e-05,
      "loss": 0.6864,
      "step": 596350
    },
    {
      "epoch": 6.313718432572345,
      "grad_norm": 4.575301170349121,
      "learning_rate": 1.844468558119839e-05,
      "loss": 0.6894,
      "step": 596400
    },
    {
      "epoch": 6.3142477543523485,
      "grad_norm": 4.334983825683594,
      "learning_rate": 1.8442038958289222e-05,
      "loss": 0.6708,
      "step": 596450
    },
    {
      "epoch": 6.314777076132351,
      "grad_norm": 4.209770202636719,
      "learning_rate": 1.8439392335380056e-05,
      "loss": 0.6697,
      "step": 596500
    },
    {
      "epoch": 6.314777076132351,
      "eval_loss": 0.4318479597568512,
      "eval_runtime": 47.7948,
      "eval_samples_per_second": 3513.562,
      "eval_steps_per_second": 439.211,
      "step": 596500
    },
    {
      "epoch": 6.315306397912355,
      "grad_norm": 4.75239896774292,
      "learning_rate": 1.8436745712470887e-05,
      "loss": 0.6814,
      "step": 596550
    },
    {
      "epoch": 6.315835719692358,
      "grad_norm": 4.591066837310791,
      "learning_rate": 1.843409908956172e-05,
      "loss": 0.6919,
      "step": 596600
    },
    {
      "epoch": 6.316365041472362,
      "grad_norm": 3.93424129486084,
      "learning_rate": 1.843145246665255e-05,
      "loss": 0.6818,
      "step": 596650
    },
    {
      "epoch": 6.316894363252365,
      "grad_norm": 4.649045467376709,
      "learning_rate": 1.8428805843743386e-05,
      "loss": 0.6893,
      "step": 596700
    },
    {
      "epoch": 6.317423685032368,
      "grad_norm": 4.7852349281311035,
      "learning_rate": 1.8426159220834216e-05,
      "loss": 0.6733,
      "step": 596750
    },
    {
      "epoch": 6.317953006812371,
      "grad_norm": 4.3475799560546875,
      "learning_rate": 1.842351259792505e-05,
      "loss": 0.6805,
      "step": 596800
    },
    {
      "epoch": 6.318482328592374,
      "grad_norm": 4.3396148681640625,
      "learning_rate": 1.842086597501588e-05,
      "loss": 0.6639,
      "step": 596850
    },
    {
      "epoch": 6.319011650372378,
      "grad_norm": 4.340033054351807,
      "learning_rate": 1.8418219352106715e-05,
      "loss": 0.6725,
      "step": 596900
    },
    {
      "epoch": 6.319540972152381,
      "grad_norm": 4.202295780181885,
      "learning_rate": 1.8415625661655726e-05,
      "loss": 0.6829,
      "step": 596950
    },
    {
      "epoch": 6.3200702939323845,
      "grad_norm": 4.271097660064697,
      "learning_rate": 1.841297903874656e-05,
      "loss": 0.6687,
      "step": 597000
    },
    {
      "epoch": 6.3200702939323845,
      "eval_loss": 0.43171489238739014,
      "eval_runtime": 47.6554,
      "eval_samples_per_second": 3523.839,
      "eval_steps_per_second": 440.496,
      "step": 597000
    },
    {
      "epoch": 6.320599615712387,
      "grad_norm": 4.381826400756836,
      "learning_rate": 1.841033241583739e-05,
      "loss": 0.6819,
      "step": 597050
    },
    {
      "epoch": 6.321128937492391,
      "grad_norm": 4.363125801086426,
      "learning_rate": 1.8407685792928225e-05,
      "loss": 0.6714,
      "step": 597100
    },
    {
      "epoch": 6.321658259272394,
      "grad_norm": 4.161073684692383,
      "learning_rate": 1.8405039170019056e-05,
      "loss": 0.6755,
      "step": 597150
    },
    {
      "epoch": 6.322187581052398,
      "grad_norm": 4.133835315704346,
      "learning_rate": 1.840239254710989e-05,
      "loss": 0.6799,
      "step": 597200
    },
    {
      "epoch": 6.322716902832401,
      "grad_norm": 4.362107753753662,
      "learning_rate": 1.839974592420072e-05,
      "loss": 0.6846,
      "step": 597250
    },
    {
      "epoch": 6.323246224612404,
      "grad_norm": 4.104330539703369,
      "learning_rate": 1.8397099301291555e-05,
      "loss": 0.6827,
      "step": 597300
    },
    {
      "epoch": 6.323775546392407,
      "grad_norm": 4.528436660766602,
      "learning_rate": 1.8394452678382386e-05,
      "loss": 0.6835,
      "step": 597350
    },
    {
      "epoch": 6.324304868172411,
      "grad_norm": 4.5631103515625,
      "learning_rate": 1.8391806055473216e-05,
      "loss": 0.6747,
      "step": 597400
    },
    {
      "epoch": 6.324834189952414,
      "grad_norm": 4.527922630310059,
      "learning_rate": 1.8389159432564047e-05,
      "loss": 0.6864,
      "step": 597450
    },
    {
      "epoch": 6.325363511732418,
      "grad_norm": 4.669660568237305,
      "learning_rate": 1.838651280965488e-05,
      "loss": 0.6791,
      "step": 597500
    },
    {
      "epoch": 6.325363511732418,
      "eval_loss": 0.4321693181991577,
      "eval_runtime": 48.2887,
      "eval_samples_per_second": 3477.622,
      "eval_steps_per_second": 434.718,
      "step": 597500
    },
    {
      "epoch": 6.3258928335124205,
      "grad_norm": 4.490869998931885,
      "learning_rate": 1.8383866186745712e-05,
      "loss": 0.6846,
      "step": 597550
    },
    {
      "epoch": 6.326422155292423,
      "grad_norm": 4.3228983879089355,
      "learning_rate": 1.8381219563836546e-05,
      "loss": 0.6865,
      "step": 597600
    },
    {
      "epoch": 6.326951477072427,
      "grad_norm": 4.668932914733887,
      "learning_rate": 1.8378572940927377e-05,
      "loss": 0.6922,
      "step": 597650
    },
    {
      "epoch": 6.32748079885243,
      "grad_norm": 4.405534744262695,
      "learning_rate": 1.837592631801821e-05,
      "loss": 0.674,
      "step": 597700
    },
    {
      "epoch": 6.328010120632434,
      "grad_norm": 4.5078444480896,
      "learning_rate": 1.837327969510904e-05,
      "loss": 0.6829,
      "step": 597750
    },
    {
      "epoch": 6.328539442412437,
      "grad_norm": 4.401468276977539,
      "learning_rate": 1.8370633072199876e-05,
      "loss": 0.6804,
      "step": 597800
    },
    {
      "epoch": 6.32906876419244,
      "grad_norm": 4.345709323883057,
      "learning_rate": 1.8367986449290706e-05,
      "loss": 0.68,
      "step": 597850
    },
    {
      "epoch": 6.329598085972443,
      "grad_norm": 4.53433084487915,
      "learning_rate": 1.836533982638154e-05,
      "loss": 0.6708,
      "step": 597900
    },
    {
      "epoch": 6.330127407752447,
      "grad_norm": 4.781256198883057,
      "learning_rate": 1.836269320347237e-05,
      "loss": 0.674,
      "step": 597950
    },
    {
      "epoch": 6.33065672953245,
      "grad_norm": 4.521572113037109,
      "learning_rate": 1.8360046580563202e-05,
      "loss": 0.6854,
      "step": 598000
    },
    {
      "epoch": 6.33065672953245,
      "eval_loss": 0.43388631939888,
      "eval_runtime": 47.9646,
      "eval_samples_per_second": 3501.127,
      "eval_steps_per_second": 437.656,
      "step": 598000
    },
    {
      "epoch": 6.331186051312454,
      "grad_norm": 4.342658042907715,
      "learning_rate": 1.8357399957654033e-05,
      "loss": 0.6706,
      "step": 598050
    },
    {
      "epoch": 6.3317153730924565,
      "grad_norm": 4.355007171630859,
      "learning_rate": 1.8354753334744867e-05,
      "loss": 0.6787,
      "step": 598100
    },
    {
      "epoch": 6.33224469487246,
      "grad_norm": 4.435887813568115,
      "learning_rate": 1.8352106711835697e-05,
      "loss": 0.6762,
      "step": 598150
    },
    {
      "epoch": 6.332774016652463,
      "grad_norm": 4.329265117645264,
      "learning_rate": 1.834946008892653e-05,
      "loss": 0.6972,
      "step": 598200
    },
    {
      "epoch": 6.333303338432467,
      "grad_norm": 4.231786251068115,
      "learning_rate": 1.8346813466017362e-05,
      "loss": 0.6747,
      "step": 598250
    },
    {
      "epoch": 6.33383266021247,
      "grad_norm": 4.252321243286133,
      "learning_rate": 1.8344166843108196e-05,
      "loss": 0.6768,
      "step": 598300
    },
    {
      "epoch": 6.334361981992473,
      "grad_norm": 4.604294300079346,
      "learning_rate": 1.8341520220199027e-05,
      "loss": 0.6747,
      "step": 598350
    },
    {
      "epoch": 6.334891303772476,
      "grad_norm": 4.364531517028809,
      "learning_rate": 1.833887359728986e-05,
      "loss": 0.6854,
      "step": 598400
    },
    {
      "epoch": 6.335420625552479,
      "grad_norm": 4.358306884765625,
      "learning_rate": 1.8336226974380692e-05,
      "loss": 0.6846,
      "step": 598450
    },
    {
      "epoch": 6.335949947332483,
      "grad_norm": 3.837263345718384,
      "learning_rate": 1.8333580351471526e-05,
      "loss": 0.6741,
      "step": 598500
    },
    {
      "epoch": 6.335949947332483,
      "eval_loss": 0.43260934948921204,
      "eval_runtime": 47.6991,
      "eval_samples_per_second": 3520.615,
      "eval_steps_per_second": 440.093,
      "step": 598500
    },
    {
      "epoch": 6.336479269112486,
      "grad_norm": 3.9694747924804688,
      "learning_rate": 1.8330933728562357e-05,
      "loss": 0.6824,
      "step": 598550
    },
    {
      "epoch": 6.33700859089249,
      "grad_norm": 4.184440612792969,
      "learning_rate": 1.8328287105653187e-05,
      "loss": 0.6778,
      "step": 598600
    },
    {
      "epoch": 6.3375379126724924,
      "grad_norm": 4.5885491371154785,
      "learning_rate": 1.8325640482744018e-05,
      "loss": 0.6875,
      "step": 598650
    },
    {
      "epoch": 6.338067234452496,
      "grad_norm": 4.436911106109619,
      "learning_rate": 1.8322993859834852e-05,
      "loss": 0.6905,
      "step": 598700
    },
    {
      "epoch": 6.338596556232499,
      "grad_norm": 4.017371654510498,
      "learning_rate": 1.8320347236925683e-05,
      "loss": 0.6803,
      "step": 598750
    },
    {
      "epoch": 6.339125878012503,
      "grad_norm": 4.37440824508667,
      "learning_rate": 1.8317700614016517e-05,
      "loss": 0.6731,
      "step": 598800
    },
    {
      "epoch": 6.339655199792506,
      "grad_norm": 4.372870445251465,
      "learning_rate": 1.8315053991107348e-05,
      "loss": 0.7041,
      "step": 598850
    },
    {
      "epoch": 6.3401845215725094,
      "grad_norm": 4.352954864501953,
      "learning_rate": 1.8312407368198182e-05,
      "loss": 0.6751,
      "step": 598900
    },
    {
      "epoch": 6.340713843352512,
      "grad_norm": 4.130377769470215,
      "learning_rate": 1.8309813677747197e-05,
      "loss": 0.6813,
      "step": 598950
    },
    {
      "epoch": 6.341243165132516,
      "grad_norm": 4.216946601867676,
      "learning_rate": 1.8307167054838027e-05,
      "loss": 0.6817,
      "step": 599000
    },
    {
      "epoch": 6.341243165132516,
      "eval_loss": 0.43108004331588745,
      "eval_runtime": 51.5257,
      "eval_samples_per_second": 3259.148,
      "eval_steps_per_second": 407.408,
      "step": 599000
    },
    {
      "epoch": 6.341772486912519,
      "grad_norm": 4.466277122497559,
      "learning_rate": 1.8304520431928858e-05,
      "loss": 0.6776,
      "step": 599050
    },
    {
      "epoch": 6.342301808692522,
      "grad_norm": 4.372814178466797,
      "learning_rate": 1.8301873809019692e-05,
      "loss": 0.6877,
      "step": 599100
    },
    {
      "epoch": 6.342831130472526,
      "grad_norm": 4.127172470092773,
      "learning_rate": 1.8299227186110523e-05,
      "loss": 0.6691,
      "step": 599150
    },
    {
      "epoch": 6.343360452252528,
      "grad_norm": 4.16396427154541,
      "learning_rate": 1.8296580563201357e-05,
      "loss": 0.6848,
      "step": 599200
    },
    {
      "epoch": 6.343889774032532,
      "grad_norm": 4.327478408813477,
      "learning_rate": 1.8293933940292188e-05,
      "loss": 0.6734,
      "step": 599250
    },
    {
      "epoch": 6.344419095812535,
      "grad_norm": 4.083958625793457,
      "learning_rate": 1.829128731738302e-05,
      "loss": 0.6792,
      "step": 599300
    },
    {
      "epoch": 6.344948417592539,
      "grad_norm": 4.059794902801514,
      "learning_rate": 1.8288640694473852e-05,
      "loss": 0.6711,
      "step": 599350
    },
    {
      "epoch": 6.345477739372542,
      "grad_norm": 4.2860870361328125,
      "learning_rate": 1.8285994071564686e-05,
      "loss": 0.6797,
      "step": 599400
    },
    {
      "epoch": 6.346007061152545,
      "grad_norm": 4.321290493011475,
      "learning_rate": 1.8283347448655517e-05,
      "loss": 0.6792,
      "step": 599450
    },
    {
      "epoch": 6.346536382932548,
      "grad_norm": 3.4643099308013916,
      "learning_rate": 1.828070082574635e-05,
      "loss": 0.6832,
      "step": 599500
    },
    {
      "epoch": 6.346536382932548,
      "eval_loss": 0.4316595494747162,
      "eval_runtime": 47.8466,
      "eval_samples_per_second": 3509.759,
      "eval_steps_per_second": 438.736,
      "step": 599500
    },
    {
      "epoch": 6.347065704712552,
      "grad_norm": 4.317803859710693,
      "learning_rate": 1.8278054202837182e-05,
      "loss": 0.6797,
      "step": 599550
    },
    {
      "epoch": 6.347595026492555,
      "grad_norm": 4.348446846008301,
      "learning_rate": 1.8275407579928013e-05,
      "loss": 0.6809,
      "step": 599600
    },
    {
      "epoch": 6.348124348272559,
      "grad_norm": 4.541398048400879,
      "learning_rate": 1.8272760957018843e-05,
      "loss": 0.6735,
      "step": 599650
    },
    {
      "epoch": 6.3486536700525615,
      "grad_norm": 4.313361167907715,
      "learning_rate": 1.8270114334109678e-05,
      "loss": 0.6865,
      "step": 599700
    },
    {
      "epoch": 6.349182991832565,
      "grad_norm": 4.97608757019043,
      "learning_rate": 1.8267467711200508e-05,
      "loss": 0.6833,
      "step": 599750
    },
    {
      "epoch": 6.349712313612568,
      "grad_norm": 4.219427585601807,
      "learning_rate": 1.8264821088291342e-05,
      "loss": 0.6838,
      "step": 599800
    },
    {
      "epoch": 6.350241635392571,
      "grad_norm": 4.49617862701416,
      "learning_rate": 1.8262174465382173e-05,
      "loss": 0.6811,
      "step": 599850
    },
    {
      "epoch": 6.350770957172575,
      "grad_norm": 4.488218784332275,
      "learning_rate": 1.8259527842473007e-05,
      "loss": 0.6748,
      "step": 599900
    },
    {
      "epoch": 6.351300278952578,
      "grad_norm": 4.831875801086426,
      "learning_rate": 1.8256881219563838e-05,
      "loss": 0.6928,
      "step": 599950
    },
    {
      "epoch": 6.351829600732581,
      "grad_norm": 4.498421669006348,
      "learning_rate": 1.8254234596654672e-05,
      "loss": 0.6688,
      "step": 600000
    },
    {
      "epoch": 6.351829600732581,
      "eval_loss": 0.4313620328903198,
      "eval_runtime": 47.5667,
      "eval_samples_per_second": 3530.413,
      "eval_steps_per_second": 441.317,
      "step": 600000
    },
    {
      "epoch": 6.352358922512584,
      "grad_norm": 4.411008358001709,
      "learning_rate": 1.8251587973745503e-05,
      "loss": 0.6847,
      "step": 600050
    },
    {
      "epoch": 6.352888244292588,
      "grad_norm": 4.449041843414307,
      "learning_rate": 1.8248941350836333e-05,
      "loss": 0.6832,
      "step": 600100
    },
    {
      "epoch": 6.353417566072591,
      "grad_norm": 3.785814046859741,
      "learning_rate": 1.8246294727927164e-05,
      "loss": 0.679,
      "step": 600150
    },
    {
      "epoch": 6.353946887852595,
      "grad_norm": 4.502241134643555,
      "learning_rate": 1.8243648105017998e-05,
      "loss": 0.6805,
      "step": 600200
    },
    {
      "epoch": 6.3544762096325975,
      "grad_norm": 4.554413795471191,
      "learning_rate": 1.824100148210883e-05,
      "loss": 0.6779,
      "step": 600250
    },
    {
      "epoch": 6.355005531412601,
      "grad_norm": 4.331860542297363,
      "learning_rate": 1.8238354859199663e-05,
      "loss": 0.682,
      "step": 600300
    },
    {
      "epoch": 6.355534853192604,
      "grad_norm": 4.5618181228637695,
      "learning_rate": 1.8235708236290494e-05,
      "loss": 0.6786,
      "step": 600350
    },
    {
      "epoch": 6.356064174972608,
      "grad_norm": 4.518310546875,
      "learning_rate": 1.8233061613381328e-05,
      "loss": 0.672,
      "step": 600400
    },
    {
      "epoch": 6.356593496752611,
      "grad_norm": 4.662890911102295,
      "learning_rate": 1.823041499047216e-05,
      "loss": 0.6737,
      "step": 600450
    },
    {
      "epoch": 6.3571228185326145,
      "grad_norm": 4.622037410736084,
      "learning_rate": 1.8227768367562993e-05,
      "loss": 0.6841,
      "step": 600500
    },
    {
      "epoch": 6.3571228185326145,
      "eval_loss": 0.4316801130771637,
      "eval_runtime": 47.3422,
      "eval_samples_per_second": 3547.15,
      "eval_steps_per_second": 443.41,
      "step": 600500
    },
    {
      "epoch": 6.357652140312617,
      "grad_norm": 4.736774921417236,
      "learning_rate": 1.8225121744653823e-05,
      "loss": 0.671,
      "step": 600550
    },
    {
      "epoch": 6.358181462092621,
      "grad_norm": 3.9405882358551025,
      "learning_rate": 1.8222475121744657e-05,
      "loss": 0.6888,
      "step": 600600
    },
    {
      "epoch": 6.358710783872624,
      "grad_norm": 4.5228166580200195,
      "learning_rate": 1.8219828498835488e-05,
      "loss": 0.6864,
      "step": 600650
    },
    {
      "epoch": 6.359240105652627,
      "grad_norm": 3.9937069416046143,
      "learning_rate": 1.821718187592632e-05,
      "loss": 0.6862,
      "step": 600700
    },
    {
      "epoch": 6.359769427432631,
      "grad_norm": 4.686410903930664,
      "learning_rate": 1.821453525301715e-05,
      "loss": 0.6762,
      "step": 600750
    },
    {
      "epoch": 6.3602987492126335,
      "grad_norm": 4.313321113586426,
      "learning_rate": 1.8211888630107984e-05,
      "loss": 0.6771,
      "step": 600800
    },
    {
      "epoch": 6.360828070992637,
      "grad_norm": 4.151371955871582,
      "learning_rate": 1.8209242007198814e-05,
      "loss": 0.676,
      "step": 600850
    },
    {
      "epoch": 6.36135739277264,
      "grad_norm": 4.042928218841553,
      "learning_rate": 1.820659538428965e-05,
      "loss": 0.6888,
      "step": 600900
    },
    {
      "epoch": 6.361886714552644,
      "grad_norm": 4.391849994659424,
      "learning_rate": 1.820394876138048e-05,
      "loss": 0.6915,
      "step": 600950
    },
    {
      "epoch": 6.362416036332647,
      "grad_norm": 4.251939296722412,
      "learning_rate": 1.8201355070929497e-05,
      "loss": 0.6718,
      "step": 601000
    },
    {
      "epoch": 6.362416036332647,
      "eval_loss": 0.43186214566230774,
      "eval_runtime": 47.4994,
      "eval_samples_per_second": 3535.416,
      "eval_steps_per_second": 441.943,
      "step": 601000
    },
    {
      "epoch": 6.3629453581126505,
      "grad_norm": 4.513548851013184,
      "learning_rate": 1.8198708448020328e-05,
      "loss": 0.6751,
      "step": 601050
    },
    {
      "epoch": 6.363474679892653,
      "grad_norm": 4.376217842102051,
      "learning_rate": 1.819606182511116e-05,
      "loss": 0.6844,
      "step": 601100
    },
    {
      "epoch": 6.364004001672657,
      "grad_norm": 4.174055099487305,
      "learning_rate": 1.819341520220199e-05,
      "loss": 0.6841,
      "step": 601150
    },
    {
      "epoch": 6.36453332345266,
      "grad_norm": 4.023837089538574,
      "learning_rate": 1.8190768579292824e-05,
      "loss": 0.6759,
      "step": 601200
    },
    {
      "epoch": 6.365062645232664,
      "grad_norm": 4.955557823181152,
      "learning_rate": 1.8188121956383654e-05,
      "loss": 0.6851,
      "step": 601250
    },
    {
      "epoch": 6.365591967012667,
      "grad_norm": 4.7888970375061035,
      "learning_rate": 1.818547533347449e-05,
      "loss": 0.6787,
      "step": 601300
    },
    {
      "epoch": 6.36612128879267,
      "grad_norm": 4.204967975616455,
      "learning_rate": 1.818282871056532e-05,
      "loss": 0.6822,
      "step": 601350
    },
    {
      "epoch": 6.366650610572673,
      "grad_norm": 4.266971111297607,
      "learning_rate": 1.8180182087656153e-05,
      "loss": 0.6757,
      "step": 601400
    },
    {
      "epoch": 6.367179932352677,
      "grad_norm": 4.285707950592041,
      "learning_rate": 1.8177535464746984e-05,
      "loss": 0.6837,
      "step": 601450
    },
    {
      "epoch": 6.36770925413268,
      "grad_norm": 4.594823360443115,
      "learning_rate": 1.8174888841837818e-05,
      "loss": 0.6819,
      "step": 601500
    },
    {
      "epoch": 6.36770925413268,
      "eval_loss": 0.43085142970085144,
      "eval_runtime": 47.9031,
      "eval_samples_per_second": 3505.622,
      "eval_steps_per_second": 438.218,
      "step": 601500
    },
    {
      "epoch": 6.368238575912683,
      "grad_norm": 4.457276344299316,
      "learning_rate": 1.817224221892865e-05,
      "loss": 0.6799,
      "step": 601550
    },
    {
      "epoch": 6.3687678976926865,
      "grad_norm": 4.36314058303833,
      "learning_rate": 1.8169595596019483e-05,
      "loss": 0.6687,
      "step": 601600
    },
    {
      "epoch": 6.369297219472689,
      "grad_norm": 4.330471038818359,
      "learning_rate": 1.8166948973110314e-05,
      "loss": 0.6621,
      "step": 601650
    },
    {
      "epoch": 6.369826541252693,
      "grad_norm": 4.262617588043213,
      "learning_rate": 1.8164302350201144e-05,
      "loss": 0.6861,
      "step": 601700
    },
    {
      "epoch": 6.370355863032696,
      "grad_norm": 4.369788646697998,
      "learning_rate": 1.8161655727291975e-05,
      "loss": 0.6767,
      "step": 601750
    },
    {
      "epoch": 6.3708851848127,
      "grad_norm": 4.364147186279297,
      "learning_rate": 1.815900910438281e-05,
      "loss": 0.6799,
      "step": 601800
    },
    {
      "epoch": 6.371414506592703,
      "grad_norm": 4.34553337097168,
      "learning_rate": 1.815636248147364e-05,
      "loss": 0.6902,
      "step": 601850
    },
    {
      "epoch": 6.371943828372706,
      "grad_norm": 4.376334190368652,
      "learning_rate": 1.8153715858564474e-05,
      "loss": 0.6702,
      "step": 601900
    },
    {
      "epoch": 6.372473150152709,
      "grad_norm": 4.290051460266113,
      "learning_rate": 1.8151069235655305e-05,
      "loss": 0.679,
      "step": 601950
    },
    {
      "epoch": 6.373002471932713,
      "grad_norm": 4.524321556091309,
      "learning_rate": 1.8148422612746135e-05,
      "loss": 0.694,
      "step": 602000
    },
    {
      "epoch": 6.373002471932713,
      "eval_loss": 0.43292465806007385,
      "eval_runtime": 47.3759,
      "eval_samples_per_second": 3544.626,
      "eval_steps_per_second": 443.094,
      "step": 602000
    },
    {
      "epoch": 6.373531793712716,
      "grad_norm": 4.272814750671387,
      "learning_rate": 1.814577598983697e-05,
      "loss": 0.6838,
      "step": 602050
    },
    {
      "epoch": 6.37406111549272,
      "grad_norm": 4.6123504638671875,
      "learning_rate": 1.81431293669278e-05,
      "loss": 0.6767,
      "step": 602100
    },
    {
      "epoch": 6.3745904372727225,
      "grad_norm": 4.31588888168335,
      "learning_rate": 1.8140482744018634e-05,
      "loss": 0.685,
      "step": 602150
    },
    {
      "epoch": 6.375119759052726,
      "grad_norm": 4.506766319274902,
      "learning_rate": 1.8137836121109465e-05,
      "loss": 0.6839,
      "step": 602200
    },
    {
      "epoch": 6.375649080832729,
      "grad_norm": 4.239051342010498,
      "learning_rate": 1.81351894982003e-05,
      "loss": 0.6733,
      "step": 602250
    },
    {
      "epoch": 6.376178402612732,
      "grad_norm": 4.2639546394348145,
      "learning_rate": 1.813254287529113e-05,
      "loss": 0.6747,
      "step": 602300
    },
    {
      "epoch": 6.376707724392736,
      "grad_norm": 4.463775157928467,
      "learning_rate": 1.812989625238196e-05,
      "loss": 0.6699,
      "step": 602350
    },
    {
      "epoch": 6.377237046172739,
      "grad_norm": 4.233579635620117,
      "learning_rate": 1.812724962947279e-05,
      "loss": 0.6851,
      "step": 602400
    },
    {
      "epoch": 6.377766367952742,
      "grad_norm": 4.669863700866699,
      "learning_rate": 1.8124603006563625e-05,
      "loss": 0.6754,
      "step": 602450
    },
    {
      "epoch": 6.378295689732745,
      "grad_norm": 4.291733264923096,
      "learning_rate": 1.8121956383654456e-05,
      "loss": 0.6817,
      "step": 602500
    },
    {
      "epoch": 6.378295689732745,
      "eval_loss": 0.43051472306251526,
      "eval_runtime": 47.4847,
      "eval_samples_per_second": 3536.505,
      "eval_steps_per_second": 442.079,
      "step": 602500
    },
    {
      "epoch": 6.378825011512749,
      "grad_norm": 4.441695690155029,
      "learning_rate": 1.811930976074529e-05,
      "loss": 0.68,
      "step": 602550
    },
    {
      "epoch": 6.379354333292752,
      "grad_norm": 4.308713436126709,
      "learning_rate": 1.811666313783612e-05,
      "loss": 0.674,
      "step": 602600
    },
    {
      "epoch": 6.379883655072756,
      "grad_norm": 4.231273651123047,
      "learning_rate": 1.8114016514926955e-05,
      "loss": 0.675,
      "step": 602650
    },
    {
      "epoch": 6.380412976852758,
      "grad_norm": 4.326711177825928,
      "learning_rate": 1.8111369892017786e-05,
      "loss": 0.6804,
      "step": 602700
    },
    {
      "epoch": 6.380942298632762,
      "grad_norm": 4.435274124145508,
      "learning_rate": 1.810872326910862e-05,
      "loss": 0.6725,
      "step": 602750
    },
    {
      "epoch": 6.381471620412765,
      "grad_norm": 4.391844272613525,
      "learning_rate": 1.810607664619945e-05,
      "loss": 0.6823,
      "step": 602800
    },
    {
      "epoch": 6.382000942192769,
      "grad_norm": 3.957387924194336,
      "learning_rate": 1.810343002329028e-05,
      "loss": 0.6845,
      "step": 602850
    },
    {
      "epoch": 6.382530263972772,
      "grad_norm": 4.214711666107178,
      "learning_rate": 1.8100783400381112e-05,
      "loss": 0.6892,
      "step": 602900
    },
    {
      "epoch": 6.383059585752775,
      "grad_norm": 4.914366722106934,
      "learning_rate": 1.8098136777471946e-05,
      "loss": 0.6723,
      "step": 602950
    },
    {
      "epoch": 6.383588907532778,
      "grad_norm": Infinity,
      "learning_rate": 1.809554308702096e-05,
      "loss": 0.6805,
      "step": 603000
    },
    {
      "epoch": 6.383588907532778,
      "eval_loss": 0.4299815595149994,
      "eval_runtime": 47.4895,
      "eval_samples_per_second": 3536.147,
      "eval_steps_per_second": 442.034,
      "step": 603000
    },
    {
      "epoch": 6.384118229312781,
      "grad_norm": 4.113061428070068,
      "learning_rate": 1.8092896464111795e-05,
      "loss": 0.6724,
      "step": 603050
    },
    {
      "epoch": 6.384647551092785,
      "grad_norm": 4.243625164031982,
      "learning_rate": 1.8090249841202625e-05,
      "loss": 0.6798,
      "step": 603100
    },
    {
      "epoch": 6.385176872872788,
      "grad_norm": 4.0868425369262695,
      "learning_rate": 1.808760321829346e-05,
      "loss": 0.6781,
      "step": 603150
    },
    {
      "epoch": 6.3857061946527915,
      "grad_norm": 4.274433612823486,
      "learning_rate": 1.808495659538429e-05,
      "loss": 0.6737,
      "step": 603200
    },
    {
      "epoch": 6.386235516432794,
      "grad_norm": 4.552984714508057,
      "learning_rate": 1.8082309972475124e-05,
      "loss": 0.679,
      "step": 603250
    },
    {
      "epoch": 6.386764838212798,
      "grad_norm": 4.3363728523254395,
      "learning_rate": 1.8079663349565955e-05,
      "loss": 0.6895,
      "step": 603300
    },
    {
      "epoch": 6.387294159992801,
      "grad_norm": 4.253902912139893,
      "learning_rate": 1.8077016726656786e-05,
      "loss": 0.6749,
      "step": 603350
    },
    {
      "epoch": 6.387823481772805,
      "grad_norm": 4.8339128494262695,
      "learning_rate": 1.8074370103747616e-05,
      "loss": 0.6785,
      "step": 603400
    },
    {
      "epoch": 6.388352803552808,
      "grad_norm": 4.357405185699463,
      "learning_rate": 1.807172348083845e-05,
      "loss": 0.6775,
      "step": 603450
    },
    {
      "epoch": 6.388882125332811,
      "grad_norm": 4.4910197257995605,
      "learning_rate": 1.806907685792928e-05,
      "loss": 0.6806,
      "step": 603500
    },
    {
      "epoch": 6.388882125332811,
      "eval_loss": 0.42960625886917114,
      "eval_runtime": 48.0596,
      "eval_samples_per_second": 3494.203,
      "eval_steps_per_second": 436.791,
      "step": 603500
    },
    {
      "epoch": 6.389411447112814,
      "grad_norm": 4.781642913818359,
      "learning_rate": 1.8066430235020115e-05,
      "loss": 0.6845,
      "step": 603550
    },
    {
      "epoch": 6.389940768892818,
      "grad_norm": 4.532765865325928,
      "learning_rate": 1.8063783612110946e-05,
      "loss": 0.6679,
      "step": 603600
    },
    {
      "epoch": 6.390470090672821,
      "grad_norm": 4.306238651275635,
      "learning_rate": 1.806113698920178e-05,
      "loss": 0.6915,
      "step": 603650
    },
    {
      "epoch": 6.390999412452825,
      "grad_norm": 4.3666911125183105,
      "learning_rate": 1.805849036629261e-05,
      "loss": 0.6736,
      "step": 603700
    },
    {
      "epoch": 6.3915287342328275,
      "grad_norm": 4.252663612365723,
      "learning_rate": 1.8055843743383445e-05,
      "loss": 0.6792,
      "step": 603750
    },
    {
      "epoch": 6.39205805601283,
      "grad_norm": 4.67133092880249,
      "learning_rate": 1.8053197120474276e-05,
      "loss": 0.6746,
      "step": 603800
    },
    {
      "epoch": 6.392587377792834,
      "grad_norm": 3.980147361755371,
      "learning_rate": 1.8050550497565106e-05,
      "loss": 0.6705,
      "step": 603850
    },
    {
      "epoch": 6.393116699572837,
      "grad_norm": 4.538884162902832,
      "learning_rate": 1.8047903874655937e-05,
      "loss": 0.6745,
      "step": 603900
    },
    {
      "epoch": 6.393646021352841,
      "grad_norm": 4.341554641723633,
      "learning_rate": 1.804525725174677e-05,
      "loss": 0.6872,
      "step": 603950
    },
    {
      "epoch": 6.394175343132844,
      "grad_norm": 4.530032157897949,
      "learning_rate": 1.8042610628837602e-05,
      "loss": 0.6585,
      "step": 604000
    },
    {
      "epoch": 6.394175343132844,
      "eval_loss": 0.43044722080230713,
      "eval_runtime": 47.9088,
      "eval_samples_per_second": 3505.202,
      "eval_steps_per_second": 438.166,
      "step": 604000
    },
    {
      "epoch": 6.394704664912847,
      "grad_norm": 4.101417064666748,
      "learning_rate": 1.8039964005928436e-05,
      "loss": 0.6863,
      "step": 604050
    },
    {
      "epoch": 6.39523398669285,
      "grad_norm": 4.780397415161133,
      "learning_rate": 1.8037317383019267e-05,
      "loss": 0.6695,
      "step": 604100
    },
    {
      "epoch": 6.395763308472854,
      "grad_norm": 4.363623142242432,
      "learning_rate": 1.80346707601101e-05,
      "loss": 0.6809,
      "step": 604150
    },
    {
      "epoch": 6.396292630252857,
      "grad_norm": 4.329980850219727,
      "learning_rate": 1.803202413720093e-05,
      "loss": 0.6754,
      "step": 604200
    },
    {
      "epoch": 6.396821952032861,
      "grad_norm": 4.426609516143799,
      "learning_rate": 1.8029377514291766e-05,
      "loss": 0.6678,
      "step": 604250
    },
    {
      "epoch": 6.3973512738128635,
      "grad_norm": 4.74868106842041,
      "learning_rate": 1.8026730891382596e-05,
      "loss": 0.6907,
      "step": 604300
    },
    {
      "epoch": 6.397880595592867,
      "grad_norm": 4.507885456085205,
      "learning_rate": 1.802408426847343e-05,
      "loss": 0.6831,
      "step": 604350
    },
    {
      "epoch": 6.39840991737287,
      "grad_norm": 4.241161823272705,
      "learning_rate": 1.802143764556426e-05,
      "loss": 0.6866,
      "step": 604400
    },
    {
      "epoch": 6.398939239152874,
      "grad_norm": 4.427691459655762,
      "learning_rate": 1.8018791022655092e-05,
      "loss": 0.6681,
      "step": 604450
    },
    {
      "epoch": 6.399468560932877,
      "grad_norm": 4.531696796417236,
      "learning_rate": 1.8016144399745923e-05,
      "loss": 0.6697,
      "step": 604500
    },
    {
      "epoch": 6.399468560932877,
      "eval_loss": 0.4314587414264679,
      "eval_runtime": 49.4286,
      "eval_samples_per_second": 3397.425,
      "eval_steps_per_second": 424.693,
      "step": 604500
    },
    {
      "epoch": 6.39999788271288,
      "grad_norm": 4.650148868560791,
      "learning_rate": 1.8013497776836757e-05,
      "loss": 0.6813,
      "step": 604550
    },
    {
      "epoch": 6.400527204492883,
      "grad_norm": 4.0968852043151855,
      "learning_rate": 1.8010851153927587e-05,
      "loss": 0.6671,
      "step": 604600
    },
    {
      "epoch": 6.401056526272886,
      "grad_norm": 4.187814712524414,
      "learning_rate": 1.800820453101842e-05,
      "loss": 0.6867,
      "step": 604650
    },
    {
      "epoch": 6.40158584805289,
      "grad_norm": 4.474934101104736,
      "learning_rate": 1.8005557908109252e-05,
      "loss": 0.6782,
      "step": 604700
    },
    {
      "epoch": 6.402115169832893,
      "grad_norm": 4.642857074737549,
      "learning_rate": 1.8002911285200086e-05,
      "loss": 0.6934,
      "step": 604750
    },
    {
      "epoch": 6.402644491612897,
      "grad_norm": 4.051533222198486,
      "learning_rate": 1.8000264662290917e-05,
      "loss": 0.6771,
      "step": 604800
    },
    {
      "epoch": 6.4031738133928995,
      "grad_norm": 4.331538677215576,
      "learning_rate": 1.799761803938175e-05,
      "loss": 0.6728,
      "step": 604850
    },
    {
      "epoch": 6.403703135172903,
      "grad_norm": 4.210245609283447,
      "learning_rate": 1.7994971416472582e-05,
      "loss": 0.6814,
      "step": 604900
    },
    {
      "epoch": 6.404232456952906,
      "grad_norm": 4.214890003204346,
      "learning_rate": 1.7992324793563416e-05,
      "loss": 0.6765,
      "step": 604950
    },
    {
      "epoch": 6.40476177873291,
      "grad_norm": 5.03086519241333,
      "learning_rate": 1.7989678170654247e-05,
      "loss": 0.6807,
      "step": 605000
    },
    {
      "epoch": 6.40476177873291,
      "eval_loss": 0.42940056324005127,
      "eval_runtime": 47.679,
      "eval_samples_per_second": 3522.093,
      "eval_steps_per_second": 440.277,
      "step": 605000
    },
    {
      "epoch": 6.405291100512913,
      "grad_norm": 4.621521949768066,
      "learning_rate": 1.798708448020326e-05,
      "loss": 0.6782,
      "step": 605050
    },
    {
      "epoch": 6.4058204222929165,
      "grad_norm": 4.316120147705078,
      "learning_rate": 1.7984437857294092e-05,
      "loss": 0.6837,
      "step": 605100
    },
    {
      "epoch": 6.406349744072919,
      "grad_norm": 4.645971298217773,
      "learning_rate": 1.7981791234384926e-05,
      "loss": 0.6749,
      "step": 605150
    },
    {
      "epoch": 6.406879065852923,
      "grad_norm": 4.203886032104492,
      "learning_rate": 1.7979144611475757e-05,
      "loss": 0.673,
      "step": 605200
    },
    {
      "epoch": 6.407408387632926,
      "grad_norm": 3.865034580230713,
      "learning_rate": 1.797649798856659e-05,
      "loss": 0.6799,
      "step": 605250
    },
    {
      "epoch": 6.407937709412929,
      "grad_norm": 4.489993095397949,
      "learning_rate": 1.7973851365657422e-05,
      "loss": 0.6711,
      "step": 605300
    },
    {
      "epoch": 6.408467031192933,
      "grad_norm": 4.375003814697266,
      "learning_rate": 1.7971204742748256e-05,
      "loss": 0.6848,
      "step": 605350
    },
    {
      "epoch": 6.4089963529729355,
      "grad_norm": 4.302110195159912,
      "learning_rate": 1.7968558119839087e-05,
      "loss": 0.6761,
      "step": 605400
    },
    {
      "epoch": 6.409525674752939,
      "grad_norm": 4.5320539474487305,
      "learning_rate": 1.7965911496929917e-05,
      "loss": 0.6705,
      "step": 605450
    },
    {
      "epoch": 6.410054996532942,
      "grad_norm": 4.3792338371276855,
      "learning_rate": 1.7963264874020748e-05,
      "loss": 0.6774,
      "step": 605500
    },
    {
      "epoch": 6.410054996532942,
      "eval_loss": 0.4293295443058014,
      "eval_runtime": 47.9567,
      "eval_samples_per_second": 3501.699,
      "eval_steps_per_second": 437.728,
      "step": 605500
    },
    {
      "epoch": 6.410584318312946,
      "grad_norm": 4.44033670425415,
      "learning_rate": 1.7960618251111582e-05,
      "loss": 0.6786,
      "step": 605550
    },
    {
      "epoch": 6.411113640092949,
      "grad_norm": 4.5098443031311035,
      "learning_rate": 1.7957971628202413e-05,
      "loss": 0.6704,
      "step": 605600
    },
    {
      "epoch": 6.4116429618729525,
      "grad_norm": 4.412513732910156,
      "learning_rate": 1.7955325005293247e-05,
      "loss": 0.6833,
      "step": 605650
    },
    {
      "epoch": 6.412172283652955,
      "grad_norm": 4.288719654083252,
      "learning_rate": 1.7952678382384078e-05,
      "loss": 0.6714,
      "step": 605700
    },
    {
      "epoch": 6.412701605432959,
      "grad_norm": 4.248841762542725,
      "learning_rate": 1.795003175947491e-05,
      "loss": 0.6715,
      "step": 605750
    },
    {
      "epoch": 6.413230927212962,
      "grad_norm": 3.7121899127960205,
      "learning_rate": 1.7947385136565742e-05,
      "loss": 0.6728,
      "step": 605800
    },
    {
      "epoch": 6.413760248992966,
      "grad_norm": 3.9831018447875977,
      "learning_rate": 1.7944738513656576e-05,
      "loss": 0.6736,
      "step": 605850
    },
    {
      "epoch": 6.414289570772969,
      "grad_norm": 4.338018894195557,
      "learning_rate": 1.7942091890747407e-05,
      "loss": 0.6797,
      "step": 605900
    },
    {
      "epoch": 6.414818892552972,
      "grad_norm": 4.343969821929932,
      "learning_rate": 1.793944526783824e-05,
      "loss": 0.6654,
      "step": 605950
    },
    {
      "epoch": 6.415348214332975,
      "grad_norm": 4.779961109161377,
      "learning_rate": 1.7936798644929072e-05,
      "loss": 0.6716,
      "step": 606000
    },
    {
      "epoch": 6.415348214332975,
      "eval_loss": 0.42939260601997375,
      "eval_runtime": 46.8586,
      "eval_samples_per_second": 3583.763,
      "eval_steps_per_second": 447.986,
      "step": 606000
    },
    {
      "epoch": 6.415877536112978,
      "grad_norm": 4.7148051261901855,
      "learning_rate": 1.7934152022019903e-05,
      "loss": 0.6775,
      "step": 606050
    },
    {
      "epoch": 6.416406857892982,
      "grad_norm": 4.798887252807617,
      "learning_rate": 1.7931505399110733e-05,
      "loss": 0.6847,
      "step": 606100
    },
    {
      "epoch": 6.416936179672985,
      "grad_norm": 4.549805641174316,
      "learning_rate": 1.7928858776201568e-05,
      "loss": 0.6751,
      "step": 606150
    },
    {
      "epoch": 6.417465501452988,
      "grad_norm": 4.515649318695068,
      "learning_rate": 1.7926212153292398e-05,
      "loss": 0.6819,
      "step": 606200
    },
    {
      "epoch": 6.417994823232991,
      "grad_norm": 4.528733253479004,
      "learning_rate": 1.7923565530383232e-05,
      "loss": 0.6664,
      "step": 606250
    },
    {
      "epoch": 6.418524145012995,
      "grad_norm": 4.431797027587891,
      "learning_rate": 1.7920918907474063e-05,
      "loss": 0.6725,
      "step": 606300
    },
    {
      "epoch": 6.419053466792998,
      "grad_norm": 4.462678909301758,
      "learning_rate": 1.7918272284564897e-05,
      "loss": 0.6691,
      "step": 606350
    },
    {
      "epoch": 6.419582788573002,
      "grad_norm": 4.382241725921631,
      "learning_rate": 1.7915625661655728e-05,
      "loss": 0.6769,
      "step": 606400
    },
    {
      "epoch": 6.4201121103530046,
      "grad_norm": 4.665210723876953,
      "learning_rate": 1.7912979038746562e-05,
      "loss": 0.6819,
      "step": 606450
    },
    {
      "epoch": 6.420641432133008,
      "grad_norm": 4.462583065032959,
      "learning_rate": 1.7910332415837393e-05,
      "loss": 0.6759,
      "step": 606500
    },
    {
      "epoch": 6.420641432133008,
      "eval_loss": 0.42879119515419006,
      "eval_runtime": 46.7901,
      "eval_samples_per_second": 3589.004,
      "eval_steps_per_second": 448.642,
      "step": 606500
    },
    {
      "epoch": 6.421170753913011,
      "grad_norm": 4.411778450012207,
      "learning_rate": 1.7907685792928223e-05,
      "loss": 0.6841,
      "step": 606550
    },
    {
      "epoch": 6.421700075693015,
      "grad_norm": 4.585607051849365,
      "learning_rate": 1.7905039170019054e-05,
      "loss": 0.6861,
      "step": 606600
    },
    {
      "epoch": 6.422229397473018,
      "grad_norm": 4.358397483825684,
      "learning_rate": 1.7902392547109888e-05,
      "loss": 0.6799,
      "step": 606650
    },
    {
      "epoch": 6.4227587192530216,
      "grad_norm": 4.395411491394043,
      "learning_rate": 1.789974592420072e-05,
      "loss": 0.6745,
      "step": 606700
    },
    {
      "epoch": 6.423288041033024,
      "grad_norm": 4.2211713790893555,
      "learning_rate": 1.7897099301291553e-05,
      "loss": 0.6771,
      "step": 606750
    },
    {
      "epoch": 6.423817362813027,
      "grad_norm": 4.293328762054443,
      "learning_rate": 1.7894452678382384e-05,
      "loss": 0.6854,
      "step": 606800
    },
    {
      "epoch": 6.424346684593031,
      "grad_norm": 4.353555202484131,
      "learning_rate": 1.7891806055473218e-05,
      "loss": 0.6743,
      "step": 606850
    },
    {
      "epoch": 6.424876006373034,
      "grad_norm": 4.599472522735596,
      "learning_rate": 1.788915943256405e-05,
      "loss": 0.6742,
      "step": 606900
    },
    {
      "epoch": 6.425405328153038,
      "grad_norm": 4.204769134521484,
      "learning_rate": 1.7886512809654883e-05,
      "loss": 0.6705,
      "step": 606950
    },
    {
      "epoch": 6.4259346499330405,
      "grad_norm": 3.5659749507904053,
      "learning_rate": 1.7883866186745713e-05,
      "loss": 0.6742,
      "step": 607000
    },
    {
      "epoch": 6.4259346499330405,
      "eval_loss": 0.4300859272480011,
      "eval_runtime": 46.9507,
      "eval_samples_per_second": 3576.73,
      "eval_steps_per_second": 447.107,
      "step": 607000
    },
    {
      "epoch": 6.426463971713044,
      "grad_norm": 4.314731121063232,
      "learning_rate": 1.7881272496294728e-05,
      "loss": 0.6813,
      "step": 607050
    },
    {
      "epoch": 6.426993293493047,
      "grad_norm": 4.749988555908203,
      "learning_rate": 1.787862587338556e-05,
      "loss": 0.6833,
      "step": 607100
    },
    {
      "epoch": 6.427522615273051,
      "grad_norm": 4.375094413757324,
      "learning_rate": 1.7875979250476393e-05,
      "loss": 0.677,
      "step": 607150
    },
    {
      "epoch": 6.428051937053054,
      "grad_norm": 4.430214881896973,
      "learning_rate": 1.7873332627567224e-05,
      "loss": 0.6802,
      "step": 607200
    },
    {
      "epoch": 6.4285812588330575,
      "grad_norm": 4.216742992401123,
      "learning_rate": 1.7870686004658058e-05,
      "loss": 0.6723,
      "step": 607250
    },
    {
      "epoch": 6.42911058061306,
      "grad_norm": 4.654829025268555,
      "learning_rate": 1.786803938174889e-05,
      "loss": 0.6787,
      "step": 607300
    },
    {
      "epoch": 6.429639902393064,
      "grad_norm": 4.410727024078369,
      "learning_rate": 1.7865392758839722e-05,
      "loss": 0.6684,
      "step": 607350
    },
    {
      "epoch": 6.430169224173067,
      "grad_norm": 4.71759033203125,
      "learning_rate": 1.7862746135930553e-05,
      "loss": 0.69,
      "step": 607400
    },
    {
      "epoch": 6.430698545953071,
      "grad_norm": 4.247018337249756,
      "learning_rate": 1.7860099513021387e-05,
      "loss": 0.6992,
      "step": 607450
    },
    {
      "epoch": 6.431227867733074,
      "grad_norm": 4.510994911193848,
      "learning_rate": 1.7857452890112218e-05,
      "loss": 0.6845,
      "step": 607500
    },
    {
      "epoch": 6.431227867733074,
      "eval_loss": 0.42960166931152344,
      "eval_runtime": 47.4042,
      "eval_samples_per_second": 3542.515,
      "eval_steps_per_second": 442.83,
      "step": 607500
    },
    {
      "epoch": 6.4317571895130765,
      "grad_norm": 4.478926658630371,
      "learning_rate": 1.785480626720305e-05,
      "loss": 0.6669,
      "step": 607550
    },
    {
      "epoch": 6.43228651129308,
      "grad_norm": 4.076328754425049,
      "learning_rate": 1.785215964429388e-05,
      "loss": 0.6669,
      "step": 607600
    },
    {
      "epoch": 6.432815833073083,
      "grad_norm": 4.50463342666626,
      "learning_rate": 1.7849513021384714e-05,
      "loss": 0.6819,
      "step": 607650
    },
    {
      "epoch": 6.433345154853087,
      "grad_norm": 4.195939540863037,
      "learning_rate": 1.7846866398475544e-05,
      "loss": 0.6678,
      "step": 607700
    },
    {
      "epoch": 6.43387447663309,
      "grad_norm": 4.408105850219727,
      "learning_rate": 1.784421977556638e-05,
      "loss": 0.6733,
      "step": 607750
    },
    {
      "epoch": 6.4344037984130935,
      "grad_norm": 4.491565227508545,
      "learning_rate": 1.784157315265721e-05,
      "loss": 0.6691,
      "step": 607800
    },
    {
      "epoch": 6.434933120193096,
      "grad_norm": 3.899979829788208,
      "learning_rate": 1.7838926529748043e-05,
      "loss": 0.6686,
      "step": 607850
    },
    {
      "epoch": 6.4354624419731,
      "grad_norm": 4.1434550285339355,
      "learning_rate": 1.7836279906838874e-05,
      "loss": 0.6723,
      "step": 607900
    },
    {
      "epoch": 6.435991763753103,
      "grad_norm": 4.607027530670166,
      "learning_rate": 1.7833633283929708e-05,
      "loss": 0.6885,
      "step": 607950
    },
    {
      "epoch": 6.436521085533107,
      "grad_norm": 4.594038963317871,
      "learning_rate": 1.783098666102054e-05,
      "loss": 0.6779,
      "step": 608000
    },
    {
      "epoch": 6.436521085533107,
      "eval_loss": 0.42895081639289856,
      "eval_runtime": 48.4262,
      "eval_samples_per_second": 3467.752,
      "eval_steps_per_second": 433.484,
      "step": 608000
    },
    {
      "epoch": 6.43705040731311,
      "grad_norm": 4.257808685302734,
      "learning_rate": 1.7828340038111373e-05,
      "loss": 0.6923,
      "step": 608050
    },
    {
      "epoch": 6.437579729093113,
      "grad_norm": 4.127819538116455,
      "learning_rate": 1.7825693415202203e-05,
      "loss": 0.676,
      "step": 608100
    },
    {
      "epoch": 6.438109050873116,
      "grad_norm": 4.357975006103516,
      "learning_rate": 1.7823046792293034e-05,
      "loss": 0.6714,
      "step": 608150
    },
    {
      "epoch": 6.43863837265312,
      "grad_norm": 4.325345516204834,
      "learning_rate": 1.7820400169383865e-05,
      "loss": 0.6829,
      "step": 608200
    },
    {
      "epoch": 6.439167694433123,
      "grad_norm": 4.220385551452637,
      "learning_rate": 1.78177535464747e-05,
      "loss": 0.676,
      "step": 608250
    },
    {
      "epoch": 6.439697016213126,
      "grad_norm": 4.555121898651123,
      "learning_rate": 1.781510692356553e-05,
      "loss": 0.6713,
      "step": 608300
    },
    {
      "epoch": 6.4402263379931295,
      "grad_norm": 4.468318939208984,
      "learning_rate": 1.7812460300656364e-05,
      "loss": 0.6759,
      "step": 608350
    },
    {
      "epoch": 6.440755659773132,
      "grad_norm": 4.09588098526001,
      "learning_rate": 1.7809813677747195e-05,
      "loss": 0.676,
      "step": 608400
    },
    {
      "epoch": 6.441284981553136,
      "grad_norm": 4.658634185791016,
      "learning_rate": 1.780716705483803e-05,
      "loss": 0.6803,
      "step": 608450
    },
    {
      "epoch": 6.441814303333139,
      "grad_norm": 4.458952903747559,
      "learning_rate": 1.780452043192886e-05,
      "loss": 0.6778,
      "step": 608500
    },
    {
      "epoch": 6.441814303333139,
      "eval_loss": 0.42898309230804443,
      "eval_runtime": 46.9191,
      "eval_samples_per_second": 3579.14,
      "eval_steps_per_second": 447.408,
      "step": 608500
    },
    {
      "epoch": 6.442343625113143,
      "grad_norm": 4.562417984008789,
      "learning_rate": 1.7801873809019693e-05,
      "loss": 0.6776,
      "step": 608550
    },
    {
      "epoch": 6.442872946893146,
      "grad_norm": 4.681647777557373,
      "learning_rate": 1.7799227186110524e-05,
      "loss": 0.6731,
      "step": 608600
    },
    {
      "epoch": 6.443402268673149,
      "grad_norm": 4.277453899383545,
      "learning_rate": 1.7796580563201358e-05,
      "loss": 0.6863,
      "step": 608650
    },
    {
      "epoch": 6.443931590453152,
      "grad_norm": 4.357072353363037,
      "learning_rate": 1.779393394029219e-05,
      "loss": 0.6586,
      "step": 608700
    },
    {
      "epoch": 6.444460912233156,
      "grad_norm": 4.427401065826416,
      "learning_rate": 1.779128731738302e-05,
      "loss": 0.6774,
      "step": 608750
    },
    {
      "epoch": 6.444990234013159,
      "grad_norm": 4.826183795928955,
      "learning_rate": 1.778864069447385e-05,
      "loss": 0.6723,
      "step": 608800
    },
    {
      "epoch": 6.445519555793163,
      "grad_norm": 5.067101955413818,
      "learning_rate": 1.7785994071564685e-05,
      "loss": 0.7012,
      "step": 608850
    },
    {
      "epoch": 6.4460488775731655,
      "grad_norm": 4.227309226989746,
      "learning_rate": 1.7783347448655515e-05,
      "loss": 0.6777,
      "step": 608900
    },
    {
      "epoch": 6.446578199353169,
      "grad_norm": 4.209497451782227,
      "learning_rate": 1.778070082574635e-05,
      "loss": 0.6713,
      "step": 608950
    },
    {
      "epoch": 6.447107521133172,
      "grad_norm": 4.3174309730529785,
      "learning_rate": 1.777805420283718e-05,
      "loss": 0.6824,
      "step": 609000
    },
    {
      "epoch": 6.447107521133172,
      "eval_loss": 0.4295462667942047,
      "eval_runtime": 46.7439,
      "eval_samples_per_second": 3592.557,
      "eval_steps_per_second": 449.086,
      "step": 609000
    },
    {
      "epoch": 6.447636842913175,
      "grad_norm": 4.595250606536865,
      "learning_rate": 1.7775460512386198e-05,
      "loss": 0.6908,
      "step": 609050
    },
    {
      "epoch": 6.448166164693179,
      "grad_norm": 4.640081882476807,
      "learning_rate": 1.777281388947703e-05,
      "loss": 0.6704,
      "step": 609100
    },
    {
      "epoch": 6.448695486473182,
      "grad_norm": 4.3266143798828125,
      "learning_rate": 1.777016726656786e-05,
      "loss": 0.6865,
      "step": 609150
    },
    {
      "epoch": 6.449224808253185,
      "grad_norm": 4.256147861480713,
      "learning_rate": 1.776752064365869e-05,
      "loss": 0.68,
      "step": 609200
    },
    {
      "epoch": 6.449754130033188,
      "grad_norm": 4.201725959777832,
      "learning_rate": 1.7764874020749524e-05,
      "loss": 0.6734,
      "step": 609250
    },
    {
      "epoch": 6.450283451813192,
      "grad_norm": 3.918935537338257,
      "learning_rate": 1.7762227397840355e-05,
      "loss": 0.6761,
      "step": 609300
    },
    {
      "epoch": 6.450812773593195,
      "grad_norm": 4.095130920410156,
      "learning_rate": 1.775958077493119e-05,
      "loss": 0.6796,
      "step": 609350
    },
    {
      "epoch": 6.451342095373199,
      "grad_norm": 4.213201522827148,
      "learning_rate": 1.775693415202202e-05,
      "loss": 0.6769,
      "step": 609400
    },
    {
      "epoch": 6.4518714171532014,
      "grad_norm": 4.845898628234863,
      "learning_rate": 1.7754287529112854e-05,
      "loss": 0.6832,
      "step": 609450
    },
    {
      "epoch": 6.452400738933205,
      "grad_norm": 4.466469764709473,
      "learning_rate": 1.7751640906203685e-05,
      "loss": 0.6748,
      "step": 609500
    },
    {
      "epoch": 6.452400738933205,
      "eval_loss": 0.42883166670799255,
      "eval_runtime": 46.8593,
      "eval_samples_per_second": 3583.71,
      "eval_steps_per_second": 447.98,
      "step": 609500
    },
    {
      "epoch": 6.452930060713208,
      "grad_norm": 4.547024726867676,
      "learning_rate": 1.774899428329452e-05,
      "loss": 0.6683,
      "step": 609550
    },
    {
      "epoch": 6.453459382493212,
      "grad_norm": 4.5995965003967285,
      "learning_rate": 1.774634766038535e-05,
      "loss": 0.6771,
      "step": 609600
    },
    {
      "epoch": 6.453988704273215,
      "grad_norm": 4.20173978805542,
      "learning_rate": 1.7743701037476184e-05,
      "loss": 0.6697,
      "step": 609650
    },
    {
      "epoch": 6.4545180260532184,
      "grad_norm": 4.550154209136963,
      "learning_rate": 1.7741054414567014e-05,
      "loss": 0.6748,
      "step": 609700
    },
    {
      "epoch": 6.455047347833221,
      "grad_norm": 4.410951137542725,
      "learning_rate": 1.7738407791657845e-05,
      "loss": 0.6716,
      "step": 609750
    },
    {
      "epoch": 6.455576669613224,
      "grad_norm": 4.439409255981445,
      "learning_rate": 1.7735761168748676e-05,
      "loss": 0.6817,
      "step": 609800
    },
    {
      "epoch": 6.456105991393228,
      "grad_norm": 4.169736385345459,
      "learning_rate": 1.773311454583951e-05,
      "loss": 0.6789,
      "step": 609850
    },
    {
      "epoch": 6.456635313173231,
      "grad_norm": 4.120486736297607,
      "learning_rate": 1.773046792293034e-05,
      "loss": 0.6739,
      "step": 609900
    },
    {
      "epoch": 6.457164634953235,
      "grad_norm": 4.519717216491699,
      "learning_rate": 1.7727821300021175e-05,
      "loss": 0.6648,
      "step": 609950
    },
    {
      "epoch": 6.457693956733237,
      "grad_norm": 4.6002678871154785,
      "learning_rate": 1.7725174677112005e-05,
      "loss": 0.6871,
      "step": 610000
    },
    {
      "epoch": 6.457693956733237,
      "eval_loss": 0.4278091490268707,
      "eval_runtime": 46.9395,
      "eval_samples_per_second": 3577.585,
      "eval_steps_per_second": 447.214,
      "step": 610000
    },
    {
      "epoch": 6.458223278513241,
      "grad_norm": 3.7471516132354736,
      "learning_rate": 1.772252805420284e-05,
      "loss": 0.6712,
      "step": 610050
    },
    {
      "epoch": 6.458752600293244,
      "grad_norm": 3.9814605712890625,
      "learning_rate": 1.771988143129367e-05,
      "loss": 0.6785,
      "step": 610100
    },
    {
      "epoch": 6.459281922073248,
      "grad_norm": 4.867879390716553,
      "learning_rate": 1.7717234808384504e-05,
      "loss": 0.6798,
      "step": 610150
    },
    {
      "epoch": 6.459811243853251,
      "grad_norm": 4.580167293548584,
      "learning_rate": 1.7714588185475335e-05,
      "loss": 0.6791,
      "step": 610200
    },
    {
      "epoch": 6.460340565633254,
      "grad_norm": 4.520374774932861,
      "learning_rate": 1.7711941562566166e-05,
      "loss": 0.6759,
      "step": 610250
    },
    {
      "epoch": 6.460869887413257,
      "grad_norm": 4.07009220123291,
      "learning_rate": 1.7709294939656996e-05,
      "loss": 0.6737,
      "step": 610300
    },
    {
      "epoch": 6.461399209193261,
      "grad_norm": 4.275392532348633,
      "learning_rate": 1.770664831674783e-05,
      "loss": 0.6766,
      "step": 610350
    },
    {
      "epoch": 6.461928530973264,
      "grad_norm": 4.282398223876953,
      "learning_rate": 1.770400169383866e-05,
      "loss": 0.6694,
      "step": 610400
    },
    {
      "epoch": 6.462457852753268,
      "grad_norm": 4.532771110534668,
      "learning_rate": 1.7701355070929495e-05,
      "loss": 0.6763,
      "step": 610450
    },
    {
      "epoch": 6.4629871745332705,
      "grad_norm": 4.16834831237793,
      "learning_rate": 1.7698708448020326e-05,
      "loss": 0.6816,
      "step": 610500
    },
    {
      "epoch": 6.4629871745332705,
      "eval_loss": 0.4274643361568451,
      "eval_runtime": 46.8947,
      "eval_samples_per_second": 3581.003,
      "eval_steps_per_second": 447.641,
      "step": 610500
    },
    {
      "epoch": 6.463516496313273,
      "grad_norm": 4.52116584777832,
      "learning_rate": 1.769606182511116e-05,
      "loss": 0.6704,
      "step": 610550
    },
    {
      "epoch": 6.464045818093277,
      "grad_norm": 4.154115200042725,
      "learning_rate": 1.769341520220199e-05,
      "loss": 0.6829,
      "step": 610600
    },
    {
      "epoch": 6.46457513987328,
      "grad_norm": 4.474549293518066,
      "learning_rate": 1.7690768579292825e-05,
      "loss": 0.6682,
      "step": 610650
    },
    {
      "epoch": 6.465104461653284,
      "grad_norm": 4.284069061279297,
      "learning_rate": 1.7688121956383656e-05,
      "loss": 0.6721,
      "step": 610700
    },
    {
      "epoch": 6.465633783433287,
      "grad_norm": 4.131875991821289,
      "learning_rate": 1.768547533347449e-05,
      "loss": 0.6816,
      "step": 610750
    },
    {
      "epoch": 6.46616310521329,
      "grad_norm": 4.4193596839904785,
      "learning_rate": 1.768282871056532e-05,
      "loss": 0.6859,
      "step": 610800
    },
    {
      "epoch": 6.466692426993293,
      "grad_norm": 3.8596813678741455,
      "learning_rate": 1.768018208765615e-05,
      "loss": 0.6637,
      "step": 610850
    },
    {
      "epoch": 6.467221748773297,
      "grad_norm": 4.43629789352417,
      "learning_rate": 1.7677535464746982e-05,
      "loss": 0.6753,
      "step": 610900
    },
    {
      "epoch": 6.4677510705533,
      "grad_norm": 4.18456506729126,
      "learning_rate": 1.7674888841837816e-05,
      "loss": 0.6655,
      "step": 610950
    },
    {
      "epoch": 6.468280392333304,
      "grad_norm": 4.65672492980957,
      "learning_rate": 1.7672242218928647e-05,
      "loss": 0.6693,
      "step": 611000
    },
    {
      "epoch": 6.468280392333304,
      "eval_loss": 0.4273286759853363,
      "eval_runtime": 46.7856,
      "eval_samples_per_second": 3589.353,
      "eval_steps_per_second": 448.685,
      "step": 611000
    },
    {
      "epoch": 6.4688097141133065,
      "grad_norm": 4.315918922424316,
      "learning_rate": 1.7669648528477665e-05,
      "loss": 0.6861,
      "step": 611050
    },
    {
      "epoch": 6.46933903589331,
      "grad_norm": 4.380171775817871,
      "learning_rate": 1.7667001905568496e-05,
      "loss": 0.6706,
      "step": 611100
    },
    {
      "epoch": 6.469868357673313,
      "grad_norm": 4.228999137878418,
      "learning_rate": 1.766435528265933e-05,
      "loss": 0.6838,
      "step": 611150
    },
    {
      "epoch": 6.470397679453317,
      "grad_norm": 4.2955193519592285,
      "learning_rate": 1.766170865975016e-05,
      "loss": 0.6647,
      "step": 611200
    },
    {
      "epoch": 6.47092700123332,
      "grad_norm": 4.679911136627197,
      "learning_rate": 1.765906203684099e-05,
      "loss": 0.6653,
      "step": 611250
    },
    {
      "epoch": 6.471456323013323,
      "grad_norm": 4.506352424621582,
      "learning_rate": 1.7656415413931822e-05,
      "loss": 0.6791,
      "step": 611300
    },
    {
      "epoch": 6.471985644793326,
      "grad_norm": 4.379616737365723,
      "learning_rate": 1.7653768791022656e-05,
      "loss": 0.6773,
      "step": 611350
    },
    {
      "epoch": 6.472514966573329,
      "grad_norm": 4.0551581382751465,
      "learning_rate": 1.7651122168113487e-05,
      "loss": 0.68,
      "step": 611400
    },
    {
      "epoch": 6.473044288353333,
      "grad_norm": 4.393827438354492,
      "learning_rate": 1.764847554520432e-05,
      "loss": 0.6657,
      "step": 611450
    },
    {
      "epoch": 6.473573610133336,
      "grad_norm": 4.093478679656982,
      "learning_rate": 1.764582892229515e-05,
      "loss": 0.6775,
      "step": 611500
    },
    {
      "epoch": 6.473573610133336,
      "eval_loss": 0.4275168478488922,
      "eval_runtime": 46.8422,
      "eval_samples_per_second": 3585.012,
      "eval_steps_per_second": 448.143,
      "step": 611500
    },
    {
      "epoch": 6.47410293191334,
      "grad_norm": 4.496925354003906,
      "learning_rate": 1.7643182299385985e-05,
      "loss": 0.6784,
      "step": 611550
    },
    {
      "epoch": 6.4746322536933425,
      "grad_norm": 4.370152950286865,
      "learning_rate": 1.7640535676476816e-05,
      "loss": 0.6908,
      "step": 611600
    },
    {
      "epoch": 6.475161575473346,
      "grad_norm": 4.407387733459473,
      "learning_rate": 1.763788905356765e-05,
      "loss": 0.677,
      "step": 611650
    },
    {
      "epoch": 6.475690897253349,
      "grad_norm": 4.209699630737305,
      "learning_rate": 1.763524243065848e-05,
      "loss": 0.6894,
      "step": 611700
    },
    {
      "epoch": 6.476220219033353,
      "grad_norm": 4.322762966156006,
      "learning_rate": 1.7632595807749315e-05,
      "loss": 0.6752,
      "step": 611750
    },
    {
      "epoch": 6.476749540813356,
      "grad_norm": 4.324594020843506,
      "learning_rate": 1.7629949184840146e-05,
      "loss": 0.6806,
      "step": 611800
    },
    {
      "epoch": 6.4772788625933595,
      "grad_norm": 4.183274745941162,
      "learning_rate": 1.7627302561930977e-05,
      "loss": 0.6695,
      "step": 611850
    },
    {
      "epoch": 6.477808184373362,
      "grad_norm": 4.077141284942627,
      "learning_rate": 1.7624655939021807e-05,
      "loss": 0.6706,
      "step": 611900
    },
    {
      "epoch": 6.478337506153366,
      "grad_norm": 4.7725958824157715,
      "learning_rate": 1.762200931611264e-05,
      "loss": 0.6884,
      "step": 611950
    },
    {
      "epoch": 6.478866827933369,
      "grad_norm": 4.138336181640625,
      "learning_rate": 1.7619362693203472e-05,
      "loss": 0.6681,
      "step": 612000
    },
    {
      "epoch": 6.478866827933369,
      "eval_loss": 0.4274505078792572,
      "eval_runtime": 46.9601,
      "eval_samples_per_second": 3576.012,
      "eval_steps_per_second": 447.018,
      "step": 612000
    },
    {
      "epoch": 6.479396149713372,
      "grad_norm": 4.2683916091918945,
      "learning_rate": 1.7616716070294306e-05,
      "loss": 0.6819,
      "step": 612050
    },
    {
      "epoch": 6.479925471493376,
      "grad_norm": 4.204387664794922,
      "learning_rate": 1.7614069447385137e-05,
      "loss": 0.6688,
      "step": 612100
    },
    {
      "epoch": 6.4804547932733785,
      "grad_norm": 4.256331920623779,
      "learning_rate": 1.761142282447597e-05,
      "loss": 0.6753,
      "step": 612150
    },
    {
      "epoch": 6.480984115053382,
      "grad_norm": 3.9682512283325195,
      "learning_rate": 1.76087762015668e-05,
      "loss": 0.6658,
      "step": 612200
    },
    {
      "epoch": 6.481513436833385,
      "grad_norm": 4.705880165100098,
      "learning_rate": 1.7606129578657636e-05,
      "loss": 0.6773,
      "step": 612250
    },
    {
      "epoch": 6.482042758613389,
      "grad_norm": 4.682264804840088,
      "learning_rate": 1.7603482955748466e-05,
      "loss": 0.6665,
      "step": 612300
    },
    {
      "epoch": 6.482572080393392,
      "grad_norm": 4.3535919189453125,
      "learning_rate": 1.76008363328393e-05,
      "loss": 0.6645,
      "step": 612350
    },
    {
      "epoch": 6.4831014021733955,
      "grad_norm": 4.851070404052734,
      "learning_rate": 1.759818970993013e-05,
      "loss": 0.6871,
      "step": 612400
    },
    {
      "epoch": 6.483630723953398,
      "grad_norm": 4.42794132232666,
      "learning_rate": 1.7595543087020962e-05,
      "loss": 0.6698,
      "step": 612450
    },
    {
      "epoch": 6.484160045733402,
      "grad_norm": 4.5495100021362305,
      "learning_rate": 1.7592896464111793e-05,
      "loss": 0.6871,
      "step": 612500
    },
    {
      "epoch": 6.484160045733402,
      "eval_loss": 0.4278118908405304,
      "eval_runtime": 46.8161,
      "eval_samples_per_second": 3587.017,
      "eval_steps_per_second": 448.393,
      "step": 612500
    },
    {
      "epoch": 6.484689367513405,
      "grad_norm": 4.311846733093262,
      "learning_rate": 1.7590249841202627e-05,
      "loss": 0.6812,
      "step": 612550
    },
    {
      "epoch": 6.485218689293409,
      "grad_norm": 4.557121753692627,
      "learning_rate": 1.7587603218293458e-05,
      "loss": 0.6759,
      "step": 612600
    },
    {
      "epoch": 6.485748011073412,
      "grad_norm": 4.672181129455566,
      "learning_rate": 1.758495659538429e-05,
      "loss": 0.6739,
      "step": 612650
    },
    {
      "epoch": 6.486277332853415,
      "grad_norm": 4.417174816131592,
      "learning_rate": 1.7582309972475122e-05,
      "loss": 0.6704,
      "step": 612700
    },
    {
      "epoch": 6.486806654633418,
      "grad_norm": 4.400829792022705,
      "learning_rate": 1.7579663349565956e-05,
      "loss": 0.6779,
      "step": 612750
    },
    {
      "epoch": 6.487335976413421,
      "grad_norm": 4.479039669036865,
      "learning_rate": 1.7577016726656787e-05,
      "loss": 0.6715,
      "step": 612800
    },
    {
      "epoch": 6.487865298193425,
      "grad_norm": 4.454505443572998,
      "learning_rate": 1.757437010374762e-05,
      "loss": 0.6686,
      "step": 612850
    },
    {
      "epoch": 6.488394619973428,
      "grad_norm": 4.63500452041626,
      "learning_rate": 1.7571723480838452e-05,
      "loss": 0.6691,
      "step": 612900
    },
    {
      "epoch": 6.4889239417534315,
      "grad_norm": 4.5742645263671875,
      "learning_rate": 1.7569076857929283e-05,
      "loss": 0.6651,
      "step": 612950
    },
    {
      "epoch": 6.489453263533434,
      "grad_norm": 4.264914035797119,
      "learning_rate": 1.7566430235020113e-05,
      "loss": 0.6776,
      "step": 613000
    },
    {
      "epoch": 6.489453263533434,
      "eval_loss": 0.42809033393859863,
      "eval_runtime": 46.8396,
      "eval_samples_per_second": 3585.212,
      "eval_steps_per_second": 448.168,
      "step": 613000
    },
    {
      "epoch": 6.489982585313438,
      "grad_norm": 4.4325456619262695,
      "learning_rate": 1.756383654456913e-05,
      "loss": 0.6766,
      "step": 613050
    },
    {
      "epoch": 6.490511907093441,
      "grad_norm": 4.102870464324951,
      "learning_rate": 1.7561189921659962e-05,
      "loss": 0.6806,
      "step": 613100
    },
    {
      "epoch": 6.491041228873445,
      "grad_norm": 4.889732360839844,
      "learning_rate": 1.7558543298750796e-05,
      "loss": 0.6793,
      "step": 613150
    },
    {
      "epoch": 6.491570550653448,
      "grad_norm": 4.4576592445373535,
      "learning_rate": 1.7555896675841627e-05,
      "loss": 0.694,
      "step": 613200
    },
    {
      "epoch": 6.492099872433451,
      "grad_norm": 3.985358238220215,
      "learning_rate": 1.755325005293246e-05,
      "loss": 0.6816,
      "step": 613250
    },
    {
      "epoch": 6.492629194213454,
      "grad_norm": 4.314654350280762,
      "learning_rate": 1.7550603430023292e-05,
      "loss": 0.6812,
      "step": 613300
    },
    {
      "epoch": 6.493158515993458,
      "grad_norm": 4.235013484954834,
      "learning_rate": 1.7547956807114126e-05,
      "loss": 0.6659,
      "step": 613350
    },
    {
      "epoch": 6.493687837773461,
      "grad_norm": 4.078455924987793,
      "learning_rate": 1.7545310184204957e-05,
      "loss": 0.6802,
      "step": 613400
    },
    {
      "epoch": 6.494217159553465,
      "grad_norm": 4.403238296508789,
      "learning_rate": 1.7542663561295787e-05,
      "loss": 0.6745,
      "step": 613450
    },
    {
      "epoch": 6.494746481333467,
      "grad_norm": 4.068026542663574,
      "learning_rate": 1.7540016938386618e-05,
      "loss": 0.6793,
      "step": 613500
    },
    {
      "epoch": 6.494746481333467,
      "eval_loss": 0.428022176027298,
      "eval_runtime": 47.2658,
      "eval_samples_per_second": 3552.885,
      "eval_steps_per_second": 444.127,
      "step": 613500
    },
    {
      "epoch": 6.49527580311347,
      "grad_norm": 4.661558628082275,
      "learning_rate": 1.7537370315477452e-05,
      "loss": 0.6757,
      "step": 613550
    },
    {
      "epoch": 6.495805124893474,
      "grad_norm": 5.0294647216796875,
      "learning_rate": 1.7534723692568283e-05,
      "loss": 0.6693,
      "step": 613600
    },
    {
      "epoch": 6.496334446673477,
      "grad_norm": 4.557163715362549,
      "learning_rate": 1.7532077069659117e-05,
      "loss": 0.6783,
      "step": 613650
    },
    {
      "epoch": 6.496863768453481,
      "grad_norm": 4.428122520446777,
      "learning_rate": 1.7529430446749948e-05,
      "loss": 0.6742,
      "step": 613700
    },
    {
      "epoch": 6.4973930902334835,
      "grad_norm": 4.464099884033203,
      "learning_rate": 1.7526783823840782e-05,
      "loss": 0.6848,
      "step": 613750
    },
    {
      "epoch": 6.497922412013487,
      "grad_norm": 4.271037578582764,
      "learning_rate": 1.7524137200931612e-05,
      "loss": 0.6642,
      "step": 613800
    },
    {
      "epoch": 6.49845173379349,
      "grad_norm": 4.423564910888672,
      "learning_rate": 1.7521490578022447e-05,
      "loss": 0.6631,
      "step": 613850
    },
    {
      "epoch": 6.498981055573494,
      "grad_norm": 4.496065616607666,
      "learning_rate": 1.7518843955113277e-05,
      "loss": 0.6668,
      "step": 613900
    },
    {
      "epoch": 6.499510377353497,
      "grad_norm": 4.4805989265441895,
      "learning_rate": 1.7516197332204108e-05,
      "loss": 0.6826,
      "step": 613950
    },
    {
      "epoch": 6.5000396991335005,
      "grad_norm": 4.68304967880249,
      "learning_rate": 1.751355070929494e-05,
      "loss": 0.685,
      "step": 614000
    },
    {
      "epoch": 6.5000396991335005,
      "eval_loss": 0.4279794692993164,
      "eval_runtime": 47.4307,
      "eval_samples_per_second": 3540.535,
      "eval_steps_per_second": 442.583,
      "step": 614000
    },
    {
      "epoch": 6.500569020913503,
      "grad_norm": 4.29290771484375,
      "learning_rate": 1.7510904086385773e-05,
      "loss": 0.6819,
      "step": 614050
    },
    {
      "epoch": 6.501098342693507,
      "grad_norm": 4.196840763092041,
      "learning_rate": 1.7508257463476604e-05,
      "loss": 0.6755,
      "step": 614100
    },
    {
      "epoch": 6.50162766447351,
      "grad_norm": 3.9996964931488037,
      "learning_rate": 1.7505610840567438e-05,
      "loss": 0.6818,
      "step": 614150
    },
    {
      "epoch": 6.502156986253514,
      "grad_norm": 4.174485206604004,
      "learning_rate": 1.750296421765827e-05,
      "loss": 0.6778,
      "step": 614200
    },
    {
      "epoch": 6.502686308033517,
      "grad_norm": 4.757930278778076,
      "learning_rate": 1.7500317594749102e-05,
      "loss": 0.6765,
      "step": 614250
    },
    {
      "epoch": 6.5032156298135195,
      "grad_norm": 4.254281044006348,
      "learning_rate": 1.7497670971839933e-05,
      "loss": 0.6747,
      "step": 614300
    },
    {
      "epoch": 6.503744951593523,
      "grad_norm": 4.5965094566345215,
      "learning_rate": 1.7495024348930767e-05,
      "loss": 0.6736,
      "step": 614350
    },
    {
      "epoch": 6.504274273373526,
      "grad_norm": 4.650603294372559,
      "learning_rate": 1.7492377726021598e-05,
      "loss": 0.6782,
      "step": 614400
    },
    {
      "epoch": 6.50480359515353,
      "grad_norm": 4.109636306762695,
      "learning_rate": 1.7489731103112432e-05,
      "loss": 0.6647,
      "step": 614450
    },
    {
      "epoch": 6.505332916933533,
      "grad_norm": 4.065937042236328,
      "learning_rate": 1.7487084480203263e-05,
      "loss": 0.6822,
      "step": 614500
    },
    {
      "epoch": 6.505332916933533,
      "eval_loss": 0.42795100808143616,
      "eval_runtime": 47.7975,
      "eval_samples_per_second": 3513.362,
      "eval_steps_per_second": 439.186,
      "step": 614500
    },
    {
      "epoch": 6.5058622387135365,
      "grad_norm": 4.344699382781982,
      "learning_rate": 1.7484437857294093e-05,
      "loss": 0.6753,
      "step": 614550
    },
    {
      "epoch": 6.506391560493539,
      "grad_norm": 4.412925720214844,
      "learning_rate": 1.7481791234384924e-05,
      "loss": 0.6691,
      "step": 614600
    },
    {
      "epoch": 6.506920882273543,
      "grad_norm": 4.711647033691406,
      "learning_rate": 1.7479144611475758e-05,
      "loss": 0.6706,
      "step": 614650
    },
    {
      "epoch": 6.507450204053546,
      "grad_norm": 5.061492919921875,
      "learning_rate": 1.747649798856659e-05,
      "loss": 0.6911,
      "step": 614700
    },
    {
      "epoch": 6.50797952583355,
      "grad_norm": 4.115842342376709,
      "learning_rate": 1.7473851365657423e-05,
      "loss": 0.6842,
      "step": 614750
    },
    {
      "epoch": 6.508508847613553,
      "grad_norm": 4.6406168937683105,
      "learning_rate": 1.7471204742748254e-05,
      "loss": 0.6747,
      "step": 614800
    },
    {
      "epoch": 6.509038169393556,
      "grad_norm": 4.785298824310303,
      "learning_rate": 1.7468558119839088e-05,
      "loss": 0.6762,
      "step": 614850
    },
    {
      "epoch": 6.509567491173559,
      "grad_norm": 4.217600345611572,
      "learning_rate": 1.746591149692992e-05,
      "loss": 0.6613,
      "step": 614900
    },
    {
      "epoch": 6.510096812953563,
      "grad_norm": 4.349330902099609,
      "learning_rate": 1.7463264874020753e-05,
      "loss": 0.6713,
      "step": 614950
    },
    {
      "epoch": 6.510626134733566,
      "grad_norm": 4.457983016967773,
      "learning_rate": 1.7460618251111583e-05,
      "loss": 0.6701,
      "step": 615000
    },
    {
      "epoch": 6.510626134733566,
      "eval_loss": 0.42815878987312317,
      "eval_runtime": 48.2275,
      "eval_samples_per_second": 3482.037,
      "eval_steps_per_second": 435.27,
      "step": 615000
    },
    {
      "epoch": 6.511155456513569,
      "grad_norm": Infinity,
      "learning_rate": 1.7458024560660598e-05,
      "loss": 0.6781,
      "step": 615050
    },
    {
      "epoch": 6.5116847782935725,
      "grad_norm": 4.89743709564209,
      "learning_rate": 1.745537793775143e-05,
      "loss": 0.6777,
      "step": 615100
    },
    {
      "epoch": 6.512214100073575,
      "grad_norm": 4.179226875305176,
      "learning_rate": 1.7452731314842263e-05,
      "loss": 0.6628,
      "step": 615150
    },
    {
      "epoch": 6.512743421853579,
      "grad_norm": 4.207746982574463,
      "learning_rate": 1.7450084691933094e-05,
      "loss": 0.6745,
      "step": 615200
    },
    {
      "epoch": 6.513272743633582,
      "grad_norm": 4.543846607208252,
      "learning_rate": 1.7447438069023928e-05,
      "loss": 0.6648,
      "step": 615250
    },
    {
      "epoch": 6.513802065413586,
      "grad_norm": 4.1388092041015625,
      "learning_rate": 1.744479144611476e-05,
      "loss": 0.6822,
      "step": 615300
    },
    {
      "epoch": 6.514331387193589,
      "grad_norm": 4.127807140350342,
      "learning_rate": 1.7442144823205593e-05,
      "loss": 0.6745,
      "step": 615350
    },
    {
      "epoch": 6.514860708973592,
      "grad_norm": 4.4065046310424805,
      "learning_rate": 1.7439498200296423e-05,
      "loss": 0.6758,
      "step": 615400
    },
    {
      "epoch": 6.515390030753595,
      "grad_norm": 4.258648872375488,
      "learning_rate": 1.7436851577387257e-05,
      "loss": 0.678,
      "step": 615450
    },
    {
      "epoch": 6.515919352533599,
      "grad_norm": 4.400176525115967,
      "learning_rate": 1.7434204954478088e-05,
      "loss": 0.6759,
      "step": 615500
    },
    {
      "epoch": 6.515919352533599,
      "eval_loss": 0.426943838596344,
      "eval_runtime": 47.8496,
      "eval_samples_per_second": 3509.535,
      "eval_steps_per_second": 438.708,
      "step": 615500
    },
    {
      "epoch": 6.516448674313602,
      "grad_norm": 4.189714431762695,
      "learning_rate": 1.743155833156892e-05,
      "loss": 0.6941,
      "step": 615550
    },
    {
      "epoch": 6.516977996093606,
      "grad_norm": 4.33315372467041,
      "learning_rate": 1.742891170865975e-05,
      "loss": 0.666,
      "step": 615600
    },
    {
      "epoch": 6.5175073178736085,
      "grad_norm": 4.556940078735352,
      "learning_rate": 1.7426265085750584e-05,
      "loss": 0.6832,
      "step": 615650
    },
    {
      "epoch": 6.518036639653612,
      "grad_norm": 4.2034807205200195,
      "learning_rate": 1.7423618462841414e-05,
      "loss": 0.687,
      "step": 615700
    },
    {
      "epoch": 6.518565961433615,
      "grad_norm": 4.448676586151123,
      "learning_rate": 1.742097183993225e-05,
      "loss": 0.683,
      "step": 615750
    },
    {
      "epoch": 6.519095283213618,
      "grad_norm": 4.589603900909424,
      "learning_rate": 1.741832521702308e-05,
      "loss": 0.6772,
      "step": 615800
    },
    {
      "epoch": 6.519624604993622,
      "grad_norm": 4.525043487548828,
      "learning_rate": 1.7415678594113913e-05,
      "loss": 0.6714,
      "step": 615850
    },
    {
      "epoch": 6.520153926773625,
      "grad_norm": 4.2485575675964355,
      "learning_rate": 1.7413031971204744e-05,
      "loss": 0.6661,
      "step": 615900
    },
    {
      "epoch": 6.520683248553628,
      "grad_norm": 4.0888800621032715,
      "learning_rate": 1.7410385348295578e-05,
      "loss": 0.6661,
      "step": 615950
    },
    {
      "epoch": 6.521212570333631,
      "grad_norm": 4.105300426483154,
      "learning_rate": 1.740773872538641e-05,
      "loss": 0.6803,
      "step": 616000
    },
    {
      "epoch": 6.521212570333631,
      "eval_loss": 0.4261828362941742,
      "eval_runtime": 46.954,
      "eval_samples_per_second": 3576.476,
      "eval_steps_per_second": 447.075,
      "step": 616000
    },
    {
      "epoch": 6.521741892113635,
      "grad_norm": 4.4647345542907715,
      "learning_rate": 1.7405092102477243e-05,
      "loss": 0.6609,
      "step": 616050
    },
    {
      "epoch": 6.522271213893638,
      "grad_norm": 4.283125877380371,
      "learning_rate": 1.7402445479568074e-05,
      "loss": 0.6537,
      "step": 616100
    },
    {
      "epoch": 6.522800535673642,
      "grad_norm": 4.174627780914307,
      "learning_rate": 1.7399798856658904e-05,
      "loss": 0.6733,
      "step": 616150
    },
    {
      "epoch": 6.5233298574536445,
      "grad_norm": 4.3664727210998535,
      "learning_rate": 1.7397152233749735e-05,
      "loss": 0.6872,
      "step": 616200
    },
    {
      "epoch": 6.523859179233648,
      "grad_norm": 4.555379390716553,
      "learning_rate": 1.739450561084057e-05,
      "loss": 0.6733,
      "step": 616250
    },
    {
      "epoch": 6.524388501013651,
      "grad_norm": 4.613277435302734,
      "learning_rate": 1.73918589879314e-05,
      "loss": 0.6785,
      "step": 616300
    },
    {
      "epoch": 6.524917822793655,
      "grad_norm": 4.505517482757568,
      "learning_rate": 1.7389212365022234e-05,
      "loss": 0.684,
      "step": 616350
    },
    {
      "epoch": 6.525447144573658,
      "grad_norm": 4.98654842376709,
      "learning_rate": 1.7386565742113065e-05,
      "loss": 0.6691,
      "step": 616400
    },
    {
      "epoch": 6.5259764663536615,
      "grad_norm": 4.511167049407959,
      "learning_rate": 1.73839191192039e-05,
      "loss": 0.673,
      "step": 616450
    },
    {
      "epoch": 6.526505788133664,
      "grad_norm": 4.556265354156494,
      "learning_rate": 1.738127249629473e-05,
      "loss": 0.6813,
      "step": 616500
    },
    {
      "epoch": 6.526505788133664,
      "eval_loss": 0.42732420563697815,
      "eval_runtime": 47.6888,
      "eval_samples_per_second": 3521.37,
      "eval_steps_per_second": 440.187,
      "step": 616500
    },
    {
      "epoch": 6.527035109913667,
      "grad_norm": 4.288684844970703,
      "learning_rate": 1.737862587338556e-05,
      "loss": 0.6763,
      "step": 616550
    },
    {
      "epoch": 6.527564431693671,
      "grad_norm": 4.1154632568359375,
      "learning_rate": 1.7375979250476394e-05,
      "loss": 0.6794,
      "step": 616600
    },
    {
      "epoch": 6.528093753473674,
      "grad_norm": 3.967949151992798,
      "learning_rate": 1.7373332627567225e-05,
      "loss": 0.6636,
      "step": 616650
    },
    {
      "epoch": 6.528623075253678,
      "grad_norm": 4.046848773956299,
      "learning_rate": 1.7370686004658056e-05,
      "loss": 0.6883,
      "step": 616700
    },
    {
      "epoch": 6.52915239703368,
      "grad_norm": 4.640467166900635,
      "learning_rate": 1.7368039381748886e-05,
      "loss": 0.6747,
      "step": 616750
    },
    {
      "epoch": 6.529681718813684,
      "grad_norm": 4.579062461853027,
      "learning_rate": 1.736539275883972e-05,
      "loss": 0.6748,
      "step": 616800
    },
    {
      "epoch": 6.530211040593687,
      "grad_norm": 4.486435890197754,
      "learning_rate": 1.736274613593055e-05,
      "loss": 0.6951,
      "step": 616850
    },
    {
      "epoch": 6.530740362373691,
      "grad_norm": 4.484524250030518,
      "learning_rate": 1.7360099513021385e-05,
      "loss": 0.6638,
      "step": 616900
    },
    {
      "epoch": 6.531269684153694,
      "grad_norm": 4.162887096405029,
      "learning_rate": 1.7357452890112216e-05,
      "loss": 0.6816,
      "step": 616950
    },
    {
      "epoch": 6.531799005933697,
      "grad_norm": 4.380582332611084,
      "learning_rate": 1.735480626720305e-05,
      "loss": 0.6705,
      "step": 617000
    },
    {
      "epoch": 6.531799005933697,
      "eval_loss": 0.42627763748168945,
      "eval_runtime": 48.1559,
      "eval_samples_per_second": 3487.213,
      "eval_steps_per_second": 435.917,
      "step": 617000
    },
    {
      "epoch": 6.5323283277137,
      "grad_norm": 3.9879682064056396,
      "learning_rate": 1.735215964429388e-05,
      "loss": 0.6721,
      "step": 617050
    },
    {
      "epoch": 6.532857649493704,
      "grad_norm": 4.7623162269592285,
      "learning_rate": 1.73495659538429e-05,
      "loss": 0.6779,
      "step": 617100
    },
    {
      "epoch": 6.533386971273707,
      "grad_norm": 4.800107479095459,
      "learning_rate": 1.734691933093373e-05,
      "loss": 0.6754,
      "step": 617150
    },
    {
      "epoch": 6.533916293053711,
      "grad_norm": 4.75716495513916,
      "learning_rate": 1.734427270802456e-05,
      "loss": 0.684,
      "step": 617200
    },
    {
      "epoch": 6.534445614833714,
      "grad_norm": 4.226846694946289,
      "learning_rate": 1.734162608511539e-05,
      "loss": 0.6731,
      "step": 617250
    },
    {
      "epoch": 6.534974936613716,
      "grad_norm": 4.4438605308532715,
      "learning_rate": 1.7338979462206225e-05,
      "loss": 0.6821,
      "step": 617300
    },
    {
      "epoch": 6.53550425839372,
      "grad_norm": 4.539255142211914,
      "learning_rate": 1.7336332839297056e-05,
      "loss": 0.6826,
      "step": 617350
    },
    {
      "epoch": 6.536033580173723,
      "grad_norm": 4.056374549865723,
      "learning_rate": 1.733368621638789e-05,
      "loss": 0.6649,
      "step": 617400
    },
    {
      "epoch": 6.536562901953727,
      "grad_norm": 4.527093410491943,
      "learning_rate": 1.733103959347872e-05,
      "loss": 0.6724,
      "step": 617450
    },
    {
      "epoch": 6.53709222373373,
      "grad_norm": 4.62792444229126,
      "learning_rate": 1.7328392970569555e-05,
      "loss": 0.6749,
      "step": 617500
    },
    {
      "epoch": 6.53709222373373,
      "eval_loss": 0.42681631445884705,
      "eval_runtime": 48.3168,
      "eval_samples_per_second": 3475.602,
      "eval_steps_per_second": 434.466,
      "step": 617500
    },
    {
      "epoch": 6.537621545513733,
      "grad_norm": 4.638722896575928,
      "learning_rate": 1.7325746347660386e-05,
      "loss": 0.6683,
      "step": 617550
    },
    {
      "epoch": 6.538150867293736,
      "grad_norm": 4.364147663116455,
      "learning_rate": 1.732309972475122e-05,
      "loss": 0.6745,
      "step": 617600
    },
    {
      "epoch": 6.53868018907374,
      "grad_norm": 4.144759178161621,
      "learning_rate": 1.732045310184205e-05,
      "loss": 0.6721,
      "step": 617650
    },
    {
      "epoch": 6.539209510853743,
      "grad_norm": 4.440250396728516,
      "learning_rate": 1.731780647893288e-05,
      "loss": 0.6764,
      "step": 617700
    },
    {
      "epoch": 6.539738832633747,
      "grad_norm": 4.160339832305908,
      "learning_rate": 1.7315159856023712e-05,
      "loss": 0.6917,
      "step": 617750
    },
    {
      "epoch": 6.5402681544137495,
      "grad_norm": 4.524567127227783,
      "learning_rate": 1.7312513233114546e-05,
      "loss": 0.6682,
      "step": 617800
    },
    {
      "epoch": 6.540797476193753,
      "grad_norm": 4.334843635559082,
      "learning_rate": 1.7309866610205377e-05,
      "loss": 0.6775,
      "step": 617850
    },
    {
      "epoch": 6.541326797973756,
      "grad_norm": 4.257632732391357,
      "learning_rate": 1.730721998729621e-05,
      "loss": 0.6707,
      "step": 617900
    },
    {
      "epoch": 6.54185611975376,
      "grad_norm": 3.969050407409668,
      "learning_rate": 1.730457336438704e-05,
      "loss": 0.6664,
      "step": 617950
    },
    {
      "epoch": 6.542385441533763,
      "grad_norm": 4.4184088706970215,
      "learning_rate": 1.7301926741477875e-05,
      "loss": 0.6647,
      "step": 618000
    },
    {
      "epoch": 6.542385441533763,
      "eval_loss": 0.42642921209335327,
      "eval_runtime": 47.2931,
      "eval_samples_per_second": 3550.836,
      "eval_steps_per_second": 443.87,
      "step": 618000
    },
    {
      "epoch": 6.542914763313766,
      "grad_norm": 4.575594425201416,
      "learning_rate": 1.7299280118568706e-05,
      "loss": 0.6928,
      "step": 618050
    },
    {
      "epoch": 6.543444085093769,
      "grad_norm": 4.366445064544678,
      "learning_rate": 1.729663349565954e-05,
      "loss": 0.6683,
      "step": 618100
    },
    {
      "epoch": 6.543973406873772,
      "grad_norm": 4.459834575653076,
      "learning_rate": 1.729398687275037e-05,
      "loss": 0.6723,
      "step": 618150
    },
    {
      "epoch": 6.544502728653776,
      "grad_norm": 4.478388786315918,
      "learning_rate": 1.7291340249841205e-05,
      "loss": 0.6774,
      "step": 618200
    },
    {
      "epoch": 6.545032050433779,
      "grad_norm": 3.9656827449798584,
      "learning_rate": 1.7288693626932036e-05,
      "loss": 0.6726,
      "step": 618250
    },
    {
      "epoch": 6.545561372213783,
      "grad_norm": 4.178956031799316,
      "learning_rate": 1.7286047004022867e-05,
      "loss": 0.683,
      "step": 618300
    },
    {
      "epoch": 6.5460906939937855,
      "grad_norm": 4.538276195526123,
      "learning_rate": 1.7283400381113697e-05,
      "loss": 0.6757,
      "step": 618350
    },
    {
      "epoch": 6.546620015773789,
      "grad_norm": 4.408261299133301,
      "learning_rate": 1.728075375820453e-05,
      "loss": 0.694,
      "step": 618400
    },
    {
      "epoch": 6.547149337553792,
      "grad_norm": 4.417553901672363,
      "learning_rate": 1.7278107135295362e-05,
      "loss": 0.6721,
      "step": 618450
    },
    {
      "epoch": 6.547678659333796,
      "grad_norm": 4.570526123046875,
      "learning_rate": 1.7275460512386196e-05,
      "loss": 0.6759,
      "step": 618500
    },
    {
      "epoch": 6.547678659333796,
      "eval_loss": 0.4252743422985077,
      "eval_runtime": 48.1326,
      "eval_samples_per_second": 3488.902,
      "eval_steps_per_second": 436.128,
      "step": 618500
    },
    {
      "epoch": 6.548207981113799,
      "grad_norm": 4.160332679748535,
      "learning_rate": 1.7272813889477027e-05,
      "loss": 0.6753,
      "step": 618550
    },
    {
      "epoch": 6.5487373028938025,
      "grad_norm": 4.1981611251831055,
      "learning_rate": 1.727016726656786e-05,
      "loss": 0.6738,
      "step": 618600
    },
    {
      "epoch": 6.549266624673805,
      "grad_norm": 4.2344889640808105,
      "learning_rate": 1.726752064365869e-05,
      "loss": 0.6595,
      "step": 618650
    },
    {
      "epoch": 6.549795946453809,
      "grad_norm": 4.2018208503723145,
      "learning_rate": 1.7264874020749526e-05,
      "loss": 0.6749,
      "step": 618700
    },
    {
      "epoch": 6.550325268233812,
      "grad_norm": 4.650057792663574,
      "learning_rate": 1.7262227397840356e-05,
      "loss": 0.6668,
      "step": 618750
    },
    {
      "epoch": 6.550854590013815,
      "grad_norm": 5.012465953826904,
      "learning_rate": 1.7259580774931187e-05,
      "loss": 0.6749,
      "step": 618800
    },
    {
      "epoch": 6.551383911793819,
      "grad_norm": 4.232985019683838,
      "learning_rate": 1.7256934152022018e-05,
      "loss": 0.6713,
      "step": 618850
    },
    {
      "epoch": 6.5519132335738215,
      "grad_norm": 4.233778953552246,
      "learning_rate": 1.7254287529112852e-05,
      "loss": 0.6771,
      "step": 618900
    },
    {
      "epoch": 6.552442555353825,
      "grad_norm": 4.510412216186523,
      "learning_rate": 1.7251640906203683e-05,
      "loss": 0.659,
      "step": 618950
    },
    {
      "epoch": 6.552971877133828,
      "grad_norm": 4.5134453773498535,
      "learning_rate": 1.7248994283294517e-05,
      "loss": 0.669,
      "step": 619000
    },
    {
      "epoch": 6.552971877133828,
      "eval_loss": 0.42533835768699646,
      "eval_runtime": 47.1212,
      "eval_samples_per_second": 3563.788,
      "eval_steps_per_second": 445.489,
      "step": 619000
    },
    {
      "epoch": 6.553501198913832,
      "grad_norm": 4.437395095825195,
      "learning_rate": 1.7246347660385348e-05,
      "loss": 0.6792,
      "step": 619050
    },
    {
      "epoch": 6.554030520693835,
      "grad_norm": 4.126227855682373,
      "learning_rate": 1.7243753969934366e-05,
      "loss": 0.6811,
      "step": 619100
    },
    {
      "epoch": 6.5545598424738385,
      "grad_norm": 4.153351783752441,
      "learning_rate": 1.7241107347025196e-05,
      "loss": 0.6772,
      "step": 619150
    },
    {
      "epoch": 6.555089164253841,
      "grad_norm": 4.427164077758789,
      "learning_rate": 1.723846072411603e-05,
      "loss": 0.6756,
      "step": 619200
    },
    {
      "epoch": 6.555618486033845,
      "grad_norm": 4.723897457122803,
      "learning_rate": 1.723581410120686e-05,
      "loss": 0.6672,
      "step": 619250
    },
    {
      "epoch": 6.556147807813848,
      "grad_norm": 4.568767070770264,
      "learning_rate": 1.7233167478297692e-05,
      "loss": 0.6714,
      "step": 619300
    },
    {
      "epoch": 6.556677129593852,
      "grad_norm": 4.251638412475586,
      "learning_rate": 1.7230520855388523e-05,
      "loss": 0.6783,
      "step": 619350
    },
    {
      "epoch": 6.557206451373855,
      "grad_norm": 4.652827262878418,
      "learning_rate": 1.7227874232479357e-05,
      "loss": 0.6767,
      "step": 619400
    },
    {
      "epoch": 6.557735773153858,
      "grad_norm": 4.506313323974609,
      "learning_rate": 1.7225227609570187e-05,
      "loss": 0.6728,
      "step": 619450
    },
    {
      "epoch": 6.558265094933861,
      "grad_norm": 4.613536834716797,
      "learning_rate": 1.722258098666102e-05,
      "loss": 0.6588,
      "step": 619500
    },
    {
      "epoch": 6.558265094933861,
      "eval_loss": 0.42553314566612244,
      "eval_runtime": 46.8635,
      "eval_samples_per_second": 3583.389,
      "eval_steps_per_second": 447.94,
      "step": 619500
    },
    {
      "epoch": 6.558794416713864,
      "grad_norm": 3.993933916091919,
      "learning_rate": 1.7219934363751852e-05,
      "loss": 0.6824,
      "step": 619550
    },
    {
      "epoch": 6.559323738493868,
      "grad_norm": 4.014967918395996,
      "learning_rate": 1.7217287740842686e-05,
      "loss": 0.6892,
      "step": 619600
    },
    {
      "epoch": 6.559853060273871,
      "grad_norm": 4.588229179382324,
      "learning_rate": 1.7214641117933517e-05,
      "loss": 0.6725,
      "step": 619650
    },
    {
      "epoch": 6.5603823820538745,
      "grad_norm": 4.9146409034729,
      "learning_rate": 1.721199449502435e-05,
      "loss": 0.6887,
      "step": 619700
    },
    {
      "epoch": 6.560911703833877,
      "grad_norm": 5.020264148712158,
      "learning_rate": 1.7209347872115182e-05,
      "loss": 0.6683,
      "step": 619750
    },
    {
      "epoch": 6.561441025613881,
      "grad_norm": 4.032546520233154,
      "learning_rate": 1.7206701249206016e-05,
      "loss": 0.671,
      "step": 619800
    },
    {
      "epoch": 6.561970347393884,
      "grad_norm": 4.306119441986084,
      "learning_rate": 1.7204054626296847e-05,
      "loss": 0.6532,
      "step": 619850
    },
    {
      "epoch": 6.562499669173888,
      "grad_norm": 4.405829429626465,
      "learning_rate": 1.7201408003387677e-05,
      "loss": 0.6722,
      "step": 619900
    },
    {
      "epoch": 6.563028990953891,
      "grad_norm": 4.440046310424805,
      "learning_rate": 1.7198761380478508e-05,
      "loss": 0.6671,
      "step": 619950
    },
    {
      "epoch": 6.563558312733894,
      "grad_norm": 4.29856014251709,
      "learning_rate": 1.7196114757569342e-05,
      "loss": 0.6794,
      "step": 620000
    },
    {
      "epoch": 6.563558312733894,
      "eval_loss": 0.42658576369285583,
      "eval_runtime": 47.2202,
      "eval_samples_per_second": 3556.317,
      "eval_steps_per_second": 444.556,
      "step": 620000
    },
    {
      "epoch": 6.564087634513897,
      "grad_norm": 4.625782489776611,
      "learning_rate": 1.7193521067118357e-05,
      "loss": 0.6688,
      "step": 620050
    },
    {
      "epoch": 6.564616956293901,
      "grad_norm": 4.199098587036133,
      "learning_rate": 1.719087444420919e-05,
      "loss": 0.675,
      "step": 620100
    },
    {
      "epoch": 6.565146278073904,
      "grad_norm": 4.637180328369141,
      "learning_rate": 1.718822782130002e-05,
      "loss": 0.6694,
      "step": 620150
    },
    {
      "epoch": 6.565675599853908,
      "grad_norm": 3.8982901573181152,
      "learning_rate": 1.7185581198390856e-05,
      "loss": 0.6716,
      "step": 620200
    },
    {
      "epoch": 6.5662049216339105,
      "grad_norm": 4.470502853393555,
      "learning_rate": 1.7182934575481686e-05,
      "loss": 0.6805,
      "step": 620250
    },
    {
      "epoch": 6.566734243413913,
      "grad_norm": 4.608402729034424,
      "learning_rate": 1.7180287952572517e-05,
      "loss": 0.6749,
      "step": 620300
    },
    {
      "epoch": 6.567263565193917,
      "grad_norm": 4.959207057952881,
      "learning_rate": 1.7177641329663348e-05,
      "loss": 0.6743,
      "step": 620350
    },
    {
      "epoch": 6.56779288697392,
      "grad_norm": 4.72354793548584,
      "learning_rate": 1.7174994706754182e-05,
      "loss": 0.678,
      "step": 620400
    },
    {
      "epoch": 6.568322208753924,
      "grad_norm": 4.192032337188721,
      "learning_rate": 1.7172348083845013e-05,
      "loss": 0.6664,
      "step": 620450
    },
    {
      "epoch": 6.568851530533927,
      "grad_norm": 4.139125347137451,
      "learning_rate": 1.7169701460935847e-05,
      "loss": 0.6695,
      "step": 620500
    },
    {
      "epoch": 6.568851530533927,
      "eval_loss": 0.4251854717731476,
      "eval_runtime": 47.4487,
      "eval_samples_per_second": 3539.191,
      "eval_steps_per_second": 442.415,
      "step": 620500
    },
    {
      "epoch": 6.56938085231393,
      "grad_norm": 4.7934346199035645,
      "learning_rate": 1.7167054838026678e-05,
      "loss": 0.6759,
      "step": 620550
    },
    {
      "epoch": 6.569910174093933,
      "grad_norm": 4.255514144897461,
      "learning_rate": 1.716440821511751e-05,
      "loss": 0.6685,
      "step": 620600
    },
    {
      "epoch": 6.570439495873937,
      "grad_norm": 4.267722129821777,
      "learning_rate": 1.7161761592208342e-05,
      "loss": 0.6626,
      "step": 620650
    },
    {
      "epoch": 6.57096881765394,
      "grad_norm": 4.478529930114746,
      "learning_rate": 1.7159114969299176e-05,
      "loss": 0.6808,
      "step": 620700
    },
    {
      "epoch": 6.571498139433944,
      "grad_norm": 4.287243843078613,
      "learning_rate": 1.7156468346390007e-05,
      "loss": 0.6773,
      "step": 620750
    },
    {
      "epoch": 6.572027461213946,
      "grad_norm": 4.663397789001465,
      "learning_rate": 1.715382172348084e-05,
      "loss": 0.6808,
      "step": 620800
    },
    {
      "epoch": 6.57255678299395,
      "grad_norm": 4.51068115234375,
      "learning_rate": 1.7151175100571672e-05,
      "loss": 0.6664,
      "step": 620850
    },
    {
      "epoch": 6.573086104773953,
      "grad_norm": 4.371604919433594,
      "learning_rate": 1.7148528477662503e-05,
      "loss": 0.679,
      "step": 620900
    },
    {
      "epoch": 6.573615426553957,
      "grad_norm": 4.527585983276367,
      "learning_rate": 1.7145881854753333e-05,
      "loss": 0.6787,
      "step": 620950
    },
    {
      "epoch": 6.57414474833396,
      "grad_norm": 4.637355804443359,
      "learning_rate": 1.7143235231844167e-05,
      "loss": 0.6873,
      "step": 621000
    },
    {
      "epoch": 6.57414474833396,
      "eval_loss": 0.42465144395828247,
      "eval_runtime": 47.512,
      "eval_samples_per_second": 3534.473,
      "eval_steps_per_second": 441.825,
      "step": 621000
    },
    {
      "epoch": 6.5746740701139625,
      "grad_norm": 4.235995769500732,
      "learning_rate": 1.7140588608934998e-05,
      "loss": 0.6763,
      "step": 621050
    },
    {
      "epoch": 6.575203391893966,
      "grad_norm": 3.853738307952881,
      "learning_rate": 1.7137941986025832e-05,
      "loss": 0.6689,
      "step": 621100
    },
    {
      "epoch": 6.575732713673969,
      "grad_norm": 4.258760929107666,
      "learning_rate": 1.7135295363116663e-05,
      "loss": 0.6753,
      "step": 621150
    },
    {
      "epoch": 6.576262035453973,
      "grad_norm": 4.555022239685059,
      "learning_rate": 1.7132648740207497e-05,
      "loss": 0.6739,
      "step": 621200
    },
    {
      "epoch": 6.576791357233976,
      "grad_norm": 3.9691600799560547,
      "learning_rate": 1.7130002117298328e-05,
      "loss": 0.6582,
      "step": 621250
    },
    {
      "epoch": 6.5773206790139795,
      "grad_norm": 4.61463737487793,
      "learning_rate": 1.7127355494389162e-05,
      "loss": 0.6823,
      "step": 621300
    },
    {
      "epoch": 6.577850000793982,
      "grad_norm": 4.572393417358398,
      "learning_rate": 1.7124708871479993e-05,
      "loss": 0.6767,
      "step": 621350
    },
    {
      "epoch": 6.578379322573986,
      "grad_norm": 4.613050937652588,
      "learning_rate": 1.7122062248570823e-05,
      "loss": 0.6769,
      "step": 621400
    },
    {
      "epoch": 6.578908644353989,
      "grad_norm": 4.217520236968994,
      "learning_rate": 1.7119415625661654e-05,
      "loss": 0.674,
      "step": 621450
    },
    {
      "epoch": 6.579437966133993,
      "grad_norm": 4.518544673919678,
      "learning_rate": 1.7116769002752488e-05,
      "loss": 0.6856,
      "step": 621500
    },
    {
      "epoch": 6.579437966133993,
      "eval_loss": 0.4254657030105591,
      "eval_runtime": 47.671,
      "eval_samples_per_second": 3522.687,
      "eval_steps_per_second": 440.352,
      "step": 621500
    },
    {
      "epoch": 6.579967287913996,
      "grad_norm": 4.453434944152832,
      "learning_rate": 1.711412237984332e-05,
      "loss": 0.6869,
      "step": 621550
    },
    {
      "epoch": 6.580496609693999,
      "grad_norm": 4.619351387023926,
      "learning_rate": 1.7111475756934153e-05,
      "loss": 0.667,
      "step": 621600
    },
    {
      "epoch": 6.581025931474002,
      "grad_norm": 4.189636707305908,
      "learning_rate": 1.7108829134024984e-05,
      "loss": 0.6827,
      "step": 621650
    },
    {
      "epoch": 6.581555253254006,
      "grad_norm": 4.610128879547119,
      "learning_rate": 1.7106182511115818e-05,
      "loss": 0.6679,
      "step": 621700
    },
    {
      "epoch": 6.582084575034009,
      "grad_norm": 4.345689296722412,
      "learning_rate": 1.710353588820665e-05,
      "loss": 0.6686,
      "step": 621750
    },
    {
      "epoch": 6.582613896814012,
      "grad_norm": 4.1203155517578125,
      "learning_rate": 1.7100889265297483e-05,
      "loss": 0.6764,
      "step": 621800
    },
    {
      "epoch": 6.5831432185940155,
      "grad_norm": 4.604404926300049,
      "learning_rate": 1.7098242642388313e-05,
      "loss": 0.6667,
      "step": 621850
    },
    {
      "epoch": 6.583672540374018,
      "grad_norm": 4.24346923828125,
      "learning_rate": 1.7095596019479147e-05,
      "loss": 0.6704,
      "step": 621900
    },
    {
      "epoch": 6.584201862154022,
      "grad_norm": 4.429946422576904,
      "learning_rate": 1.7092949396569978e-05,
      "loss": 0.6777,
      "step": 621950
    },
    {
      "epoch": 6.584731183934025,
      "grad_norm": 4.3216423988342285,
      "learning_rate": 1.709030277366081e-05,
      "loss": 0.6892,
      "step": 622000
    },
    {
      "epoch": 6.584731183934025,
      "eval_loss": 0.4259803593158722,
      "eval_runtime": 47.5151,
      "eval_samples_per_second": 3534.245,
      "eval_steps_per_second": 441.796,
      "step": 622000
    },
    {
      "epoch": 6.585260505714029,
      "grad_norm": 4.650384426116943,
      "learning_rate": 1.708765615075164e-05,
      "loss": 0.6682,
      "step": 622050
    },
    {
      "epoch": 6.585789827494032,
      "grad_norm": 4.583639144897461,
      "learning_rate": 1.7085009527842474e-05,
      "loss": 0.6735,
      "step": 622100
    },
    {
      "epoch": 6.586319149274035,
      "grad_norm": 5.15891170501709,
      "learning_rate": 1.7082362904933304e-05,
      "loss": 0.6729,
      "step": 622150
    },
    {
      "epoch": 6.586848471054038,
      "grad_norm": 4.435518741607666,
      "learning_rate": 1.707971628202414e-05,
      "loss": 0.6674,
      "step": 622200
    },
    {
      "epoch": 6.587377792834042,
      "grad_norm": 4.523876190185547,
      "learning_rate": 1.707706965911497e-05,
      "loss": 0.6753,
      "step": 622250
    },
    {
      "epoch": 6.587907114614045,
      "grad_norm": 4.061359882354736,
      "learning_rate": 1.7074423036205803e-05,
      "loss": 0.6619,
      "step": 622300
    },
    {
      "epoch": 6.588436436394049,
      "grad_norm": 4.4370551109313965,
      "learning_rate": 1.7071776413296634e-05,
      "loss": 0.6881,
      "step": 622350
    },
    {
      "epoch": 6.5889657581740515,
      "grad_norm": 4.324538230895996,
      "learning_rate": 1.7069129790387468e-05,
      "loss": 0.6722,
      "step": 622400
    },
    {
      "epoch": 6.589495079954055,
      "grad_norm": 3.982334613800049,
      "learning_rate": 1.70664831674783e-05,
      "loss": 0.6776,
      "step": 622450
    },
    {
      "epoch": 6.590024401734058,
      "grad_norm": 4.400211334228516,
      "learning_rate": 1.706383654456913e-05,
      "loss": 0.6709,
      "step": 622500
    },
    {
      "epoch": 6.590024401734058,
      "eval_loss": 0.4254858195781708,
      "eval_runtime": 47.2788,
      "eval_samples_per_second": 3551.908,
      "eval_steps_per_second": 444.004,
      "step": 622500
    },
    {
      "epoch": 6.590553723514061,
      "grad_norm": 4.499399662017822,
      "learning_rate": 1.706118992165996e-05,
      "loss": 0.6634,
      "step": 622550
    },
    {
      "epoch": 6.591083045294065,
      "grad_norm": 4.566691875457764,
      "learning_rate": 1.7058543298750794e-05,
      "loss": 0.667,
      "step": 622600
    },
    {
      "epoch": 6.591612367074068,
      "grad_norm": 4.850518226623535,
      "learning_rate": 1.7055896675841625e-05,
      "loss": 0.6655,
      "step": 622650
    },
    {
      "epoch": 6.592141688854071,
      "grad_norm": 4.517941951751709,
      "learning_rate": 1.705325005293246e-05,
      "loss": 0.666,
      "step": 622700
    },
    {
      "epoch": 6.592671010634074,
      "grad_norm": 4.172571182250977,
      "learning_rate": 1.705060343002329e-05,
      "loss": 0.6682,
      "step": 622750
    },
    {
      "epoch": 6.593200332414078,
      "grad_norm": 4.340474605560303,
      "learning_rate": 1.7047956807114124e-05,
      "loss": 0.6563,
      "step": 622800
    },
    {
      "epoch": 6.593729654194081,
      "grad_norm": 3.942142963409424,
      "learning_rate": 1.7045310184204955e-05,
      "loss": 0.6814,
      "step": 622850
    },
    {
      "epoch": 6.594258975974085,
      "grad_norm": 4.576756477355957,
      "learning_rate": 1.704266356129579e-05,
      "loss": 0.6696,
      "step": 622900
    },
    {
      "epoch": 6.5947882977540875,
      "grad_norm": 4.258907318115234,
      "learning_rate": 1.704001693838662e-05,
      "loss": 0.6789,
      "step": 622950
    },
    {
      "epoch": 6.595317619534091,
      "grad_norm": 4.314540863037109,
      "learning_rate": 1.7037370315477454e-05,
      "loss": 0.6836,
      "step": 623000
    },
    {
      "epoch": 6.595317619534091,
      "eval_loss": 0.42669233679771423,
      "eval_runtime": 47.3363,
      "eval_samples_per_second": 3547.595,
      "eval_steps_per_second": 443.465,
      "step": 623000
    },
    {
      "epoch": 6.595846941314094,
      "grad_norm": 4.278752326965332,
      "learning_rate": 1.7034723692568284e-05,
      "loss": 0.6755,
      "step": 623050
    },
    {
      "epoch": 6.596376263094098,
      "grad_norm": 4.4207329750061035,
      "learning_rate": 1.7032077069659115e-05,
      "loss": 0.6648,
      "step": 623100
    },
    {
      "epoch": 6.596905584874101,
      "grad_norm": 4.957753658294678,
      "learning_rate": 1.7029430446749946e-05,
      "loss": 0.6843,
      "step": 623150
    },
    {
      "epoch": 6.5974349066541045,
      "grad_norm": 4.545774459838867,
      "learning_rate": 1.702678382384078e-05,
      "loss": 0.6759,
      "step": 623200
    },
    {
      "epoch": 6.597964228434107,
      "grad_norm": 4.614213943481445,
      "learning_rate": 1.702413720093161e-05,
      "loss": 0.6717,
      "step": 623250
    },
    {
      "epoch": 6.59849355021411,
      "grad_norm": 4.380786895751953,
      "learning_rate": 1.7021490578022445e-05,
      "loss": 0.6723,
      "step": 623300
    },
    {
      "epoch": 6.599022871994114,
      "grad_norm": 4.489972114562988,
      "learning_rate": 1.7018843955113275e-05,
      "loss": 0.6737,
      "step": 623350
    },
    {
      "epoch": 6.599552193774117,
      "grad_norm": 4.639737129211426,
      "learning_rate": 1.701619733220411e-05,
      "loss": 0.6825,
      "step": 623400
    },
    {
      "epoch": 6.600081515554121,
      "grad_norm": 4.31690788269043,
      "learning_rate": 1.701355070929494e-05,
      "loss": 0.6799,
      "step": 623450
    },
    {
      "epoch": 6.6006108373341235,
      "grad_norm": 3.7556629180908203,
      "learning_rate": 1.7010904086385774e-05,
      "loss": 0.6683,
      "step": 623500
    },
    {
      "epoch": 6.6006108373341235,
      "eval_loss": 0.4249386489391327,
      "eval_runtime": 47.8165,
      "eval_samples_per_second": 3511.97,
      "eval_steps_per_second": 439.012,
      "step": 623500
    },
    {
      "epoch": 6.601140159114127,
      "grad_norm": 4.772704124450684,
      "learning_rate": 1.7008257463476605e-05,
      "loss": 0.6798,
      "step": 623550
    },
    {
      "epoch": 6.60166948089413,
      "grad_norm": 4.26502799987793,
      "learning_rate": 1.700561084056744e-05,
      "loss": 0.664,
      "step": 623600
    },
    {
      "epoch": 6.602198802674134,
      "grad_norm": 4.418829441070557,
      "learning_rate": 1.700296421765827e-05,
      "loss": 0.6659,
      "step": 623650
    },
    {
      "epoch": 6.602728124454137,
      "grad_norm": 4.520281791687012,
      "learning_rate": 1.70003175947491e-05,
      "loss": 0.6716,
      "step": 623700
    },
    {
      "epoch": 6.6032574462341405,
      "grad_norm": 4.84484338760376,
      "learning_rate": 1.699767097183993e-05,
      "loss": 0.6564,
      "step": 623750
    },
    {
      "epoch": 6.603786768014143,
      "grad_norm": 4.487687110900879,
      "learning_rate": 1.6995024348930765e-05,
      "loss": 0.6758,
      "step": 623800
    },
    {
      "epoch": 6.604316089794147,
      "grad_norm": 4.592519760131836,
      "learning_rate": 1.6992377726021596e-05,
      "loss": 0.6638,
      "step": 623850
    },
    {
      "epoch": 6.60484541157415,
      "grad_norm": 4.4637675285339355,
      "learning_rate": 1.698973110311243e-05,
      "loss": 0.6814,
      "step": 623900
    },
    {
      "epoch": 6.605374733354154,
      "grad_norm": 4.45484733581543,
      "learning_rate": 1.698708448020326e-05,
      "loss": 0.6728,
      "step": 623950
    },
    {
      "epoch": 6.605904055134157,
      "grad_norm": 4.694787979125977,
      "learning_rate": 1.6984437857294095e-05,
      "loss": 0.6808,
      "step": 624000
    },
    {
      "epoch": 6.605904055134157,
      "eval_loss": 0.426227867603302,
      "eval_runtime": 47.1008,
      "eval_samples_per_second": 3565.335,
      "eval_steps_per_second": 445.683,
      "step": 624000
    },
    {
      "epoch": 6.606433376914159,
      "grad_norm": 4.485570907592773,
      "learning_rate": 1.698184416684311e-05,
      "loss": 0.6751,
      "step": 624050
    },
    {
      "epoch": 6.606962698694163,
      "grad_norm": 4.598103046417236,
      "learning_rate": 1.697919754393394e-05,
      "loss": 0.6779,
      "step": 624100
    },
    {
      "epoch": 6.607492020474167,
      "grad_norm": 4.176927089691162,
      "learning_rate": 1.697655092102477e-05,
      "loss": 0.6568,
      "step": 624150
    },
    {
      "epoch": 6.60802134225417,
      "grad_norm": 4.134731769561768,
      "learning_rate": 1.6973904298115605e-05,
      "loss": 0.6797,
      "step": 624200
    },
    {
      "epoch": 6.608550664034173,
      "grad_norm": 4.616601467132568,
      "learning_rate": 1.6971257675206436e-05,
      "loss": 0.6852,
      "step": 624250
    },
    {
      "epoch": 6.609079985814176,
      "grad_norm": 4.530603408813477,
      "learning_rate": 1.696861105229727e-05,
      "loss": 0.6758,
      "step": 624300
    },
    {
      "epoch": 6.609609307594179,
      "grad_norm": 4.276971817016602,
      "learning_rate": 1.69659644293881e-05,
      "loss": 0.6734,
      "step": 624350
    },
    {
      "epoch": 6.610138629374183,
      "grad_norm": 4.953788757324219,
      "learning_rate": 1.6963317806478935e-05,
      "loss": 0.666,
      "step": 624400
    },
    {
      "epoch": 6.610667951154186,
      "grad_norm": 4.609860897064209,
      "learning_rate": 1.6960671183569765e-05,
      "loss": 0.6714,
      "step": 624450
    },
    {
      "epoch": 6.61119727293419,
      "grad_norm": 3.8691065311431885,
      "learning_rate": 1.69580245606606e-05,
      "loss": 0.6654,
      "step": 624500
    },
    {
      "epoch": 6.61119727293419,
      "eval_loss": 0.4245591461658478,
      "eval_runtime": 47.3317,
      "eval_samples_per_second": 3547.943,
      "eval_steps_per_second": 443.509,
      "step": 624500
    },
    {
      "epoch": 6.6117265947141926,
      "grad_norm": 4.819901943206787,
      "learning_rate": 1.695537793775143e-05,
      "loss": 0.6784,
      "step": 624550
    },
    {
      "epoch": 6.612255916494196,
      "grad_norm": 4.568972110748291,
      "learning_rate": 1.6952731314842264e-05,
      "loss": 0.6809,
      "step": 624600
    },
    {
      "epoch": 6.612785238274199,
      "grad_norm": 4.09896183013916,
      "learning_rate": 1.6950084691933095e-05,
      "loss": 0.6818,
      "step": 624650
    },
    {
      "epoch": 6.613314560054203,
      "grad_norm": 4.410251140594482,
      "learning_rate": 1.6947438069023926e-05,
      "loss": 0.6656,
      "step": 624700
    },
    {
      "epoch": 6.613843881834206,
      "grad_norm": 4.356250762939453,
      "learning_rate": 1.6944791446114757e-05,
      "loss": 0.6771,
      "step": 624750
    },
    {
      "epoch": 6.614373203614209,
      "grad_norm": 4.677408218383789,
      "learning_rate": 1.694214482320559e-05,
      "loss": 0.6662,
      "step": 624800
    },
    {
      "epoch": 6.614902525394212,
      "grad_norm": 3.808194398880005,
      "learning_rate": 1.693949820029642e-05,
      "loss": 0.6751,
      "step": 624850
    },
    {
      "epoch": 6.615431847174216,
      "grad_norm": 4.281660556793213,
      "learning_rate": 1.6936851577387255e-05,
      "loss": 0.6799,
      "step": 624900
    },
    {
      "epoch": 6.615961168954219,
      "grad_norm": 4.543650150299072,
      "learning_rate": 1.6934204954478086e-05,
      "loss": 0.6765,
      "step": 624950
    },
    {
      "epoch": 6.616490490734222,
      "grad_norm": 4.4677605628967285,
      "learning_rate": 1.693155833156892e-05,
      "loss": 0.6515,
      "step": 625000
    },
    {
      "epoch": 6.616490490734222,
      "eval_loss": 0.4240725636482239,
      "eval_runtime": 47.4533,
      "eval_samples_per_second": 3538.845,
      "eval_steps_per_second": 442.371,
      "step": 625000
    },
    {
      "epoch": 6.617019812514226,
      "grad_norm": 4.256494522094727,
      "learning_rate": 1.692891170865975e-05,
      "loss": 0.6749,
      "step": 625050
    },
    {
      "epoch": 6.6175491342942285,
      "grad_norm": 4.590553283691406,
      "learning_rate": 1.6926265085750585e-05,
      "loss": 0.6697,
      "step": 625100
    },
    {
      "epoch": 6.618078456074232,
      "grad_norm": 4.590072154998779,
      "learning_rate": 1.6923618462841416e-05,
      "loss": 0.6731,
      "step": 625150
    },
    {
      "epoch": 6.618607777854235,
      "grad_norm": 4.245994567871094,
      "learning_rate": 1.6920971839932246e-05,
      "loss": 0.6773,
      "step": 625200
    },
    {
      "epoch": 6.619137099634239,
      "grad_norm": 4.309891223907471,
      "learning_rate": 1.6918325217023077e-05,
      "loss": 0.669,
      "step": 625250
    },
    {
      "epoch": 6.619666421414242,
      "grad_norm": 4.241025924682617,
      "learning_rate": 1.691567859411391e-05,
      "loss": 0.6729,
      "step": 625300
    },
    {
      "epoch": 6.6201957431942455,
      "grad_norm": 4.3183817863464355,
      "learning_rate": 1.6913031971204742e-05,
      "loss": 0.6757,
      "step": 625350
    },
    {
      "epoch": 6.620725064974248,
      "grad_norm": 4.702385425567627,
      "learning_rate": 1.6910385348295576e-05,
      "loss": 0.6752,
      "step": 625400
    },
    {
      "epoch": 6.621254386754252,
      "grad_norm": 4.438638210296631,
      "learning_rate": 1.6907738725386407e-05,
      "loss": 0.6761,
      "step": 625450
    },
    {
      "epoch": 6.621783708534255,
      "grad_norm": 3.9373838901519775,
      "learning_rate": 1.690509210247724e-05,
      "loss": 0.676,
      "step": 625500
    },
    {
      "epoch": 6.621783708534255,
      "eval_loss": 0.42485493421554565,
      "eval_runtime": 47.5965,
      "eval_samples_per_second": 3528.201,
      "eval_steps_per_second": 441.041,
      "step": 625500
    },
    {
      "epoch": 6.622313030314258,
      "grad_norm": 4.3651347160339355,
      "learning_rate": 1.690244547956807e-05,
      "loss": 0.6737,
      "step": 625550
    },
    {
      "epoch": 6.622842352094262,
      "grad_norm": 4.122837066650391,
      "learning_rate": 1.6899798856658906e-05,
      "loss": 0.667,
      "step": 625600
    },
    {
      "epoch": 6.623371673874265,
      "grad_norm": 4.455951690673828,
      "learning_rate": 1.6897152233749736e-05,
      "loss": 0.6673,
      "step": 625650
    },
    {
      "epoch": 6.623900995654268,
      "grad_norm": 4.656922340393066,
      "learning_rate": 1.689450561084057e-05,
      "loss": 0.6676,
      "step": 625700
    },
    {
      "epoch": 6.624430317434271,
      "grad_norm": 4.185798645019531,
      "learning_rate": 1.68918589879314e-05,
      "loss": 0.6783,
      "step": 625750
    },
    {
      "epoch": 6.624959639214275,
      "grad_norm": 4.654684543609619,
      "learning_rate": 1.6889212365022232e-05,
      "loss": 0.6699,
      "step": 625800
    },
    {
      "epoch": 6.625488960994278,
      "grad_norm": 4.243707656860352,
      "learning_rate": 1.6886565742113063e-05,
      "loss": 0.6749,
      "step": 625850
    },
    {
      "epoch": 6.6260182827742815,
      "grad_norm": 4.252486228942871,
      "learning_rate": 1.6883919119203897e-05,
      "loss": 0.6687,
      "step": 625900
    },
    {
      "epoch": 6.626547604554284,
      "grad_norm": 4.723552703857422,
      "learning_rate": 1.6881272496294727e-05,
      "loss": 0.6626,
      "step": 625950
    },
    {
      "epoch": 6.627076926334288,
      "grad_norm": 4.805555820465088,
      "learning_rate": 1.687862587338556e-05,
      "loss": 0.6732,
      "step": 626000
    },
    {
      "epoch": 6.627076926334288,
      "eval_loss": 0.4245082437992096,
      "eval_runtime": 47.7086,
      "eval_samples_per_second": 3519.912,
      "eval_steps_per_second": 440.005,
      "step": 626000
    },
    {
      "epoch": 6.627606248114291,
      "grad_norm": 4.211170196533203,
      "learning_rate": 1.6876032182934576e-05,
      "loss": 0.67,
      "step": 626050
    },
    {
      "epoch": 6.628135569894295,
      "grad_norm": 4.959202289581299,
      "learning_rate": 1.687338556002541e-05,
      "loss": 0.6701,
      "step": 626100
    },
    {
      "epoch": 6.628664891674298,
      "grad_norm": 4.398980617523193,
      "learning_rate": 1.687073893711624e-05,
      "loss": 0.6726,
      "step": 626150
    },
    {
      "epoch": 6.629194213454301,
      "grad_norm": 4.491990089416504,
      "learning_rate": 1.6868092314207072e-05,
      "loss": 0.6805,
      "step": 626200
    },
    {
      "epoch": 6.629723535234304,
      "grad_norm": 4.712043285369873,
      "learning_rate": 1.6865445691297903e-05,
      "loss": 0.6717,
      "step": 626250
    },
    {
      "epoch": 6.630252857014307,
      "grad_norm": 4.3351054191589355,
      "learning_rate": 1.6862799068388737e-05,
      "loss": 0.681,
      "step": 626300
    },
    {
      "epoch": 6.630782178794311,
      "grad_norm": 4.389917850494385,
      "learning_rate": 1.6860152445479567e-05,
      "loss": 0.6652,
      "step": 626350
    },
    {
      "epoch": 6.631311500574315,
      "grad_norm": 4.017524719238281,
      "learning_rate": 1.68575058225704e-05,
      "loss": 0.6722,
      "step": 626400
    },
    {
      "epoch": 6.6318408223543175,
      "grad_norm": 4.424255847930908,
      "learning_rate": 1.6854859199661232e-05,
      "loss": 0.6796,
      "step": 626450
    },
    {
      "epoch": 6.63237014413432,
      "grad_norm": 4.534992218017578,
      "learning_rate": 1.6852212576752066e-05,
      "loss": 0.674,
      "step": 626500
    },
    {
      "epoch": 6.63237014413432,
      "eval_loss": 0.42429137229919434,
      "eval_runtime": 47.3624,
      "eval_samples_per_second": 3545.638,
      "eval_steps_per_second": 443.221,
      "step": 626500
    },
    {
      "epoch": 6.632899465914324,
      "grad_norm": 4.259702205657959,
      "learning_rate": 1.6849565953842897e-05,
      "loss": 0.6742,
      "step": 626550
    },
    {
      "epoch": 6.633428787694327,
      "grad_norm": 4.6789631843566895,
      "learning_rate": 1.684691933093373e-05,
      "loss": 0.6676,
      "step": 626600
    },
    {
      "epoch": 6.633958109474331,
      "grad_norm": 4.637245178222656,
      "learning_rate": 1.6844272708024562e-05,
      "loss": 0.6815,
      "step": 626650
    },
    {
      "epoch": 6.634487431254334,
      "grad_norm": 4.608500957489014,
      "learning_rate": 1.6841626085115396e-05,
      "loss": 0.6587,
      "step": 626700
    },
    {
      "epoch": 6.635016753034337,
      "grad_norm": 4.477344512939453,
      "learning_rate": 1.6838979462206227e-05,
      "loss": 0.6891,
      "step": 626750
    },
    {
      "epoch": 6.63554607481434,
      "grad_norm": 4.563759803771973,
      "learning_rate": 1.6836332839297057e-05,
      "loss": 0.6846,
      "step": 626800
    },
    {
      "epoch": 6.636075396594344,
      "grad_norm": 4.565154075622559,
      "learning_rate": 1.6833686216387888e-05,
      "loss": 0.6627,
      "step": 626850
    },
    {
      "epoch": 6.636604718374347,
      "grad_norm": 4.720300197601318,
      "learning_rate": 1.6831039593478722e-05,
      "loss": 0.6759,
      "step": 626900
    },
    {
      "epoch": 6.637134040154351,
      "grad_norm": 4.44592809677124,
      "learning_rate": 1.6828392970569553e-05,
      "loss": 0.6698,
      "step": 626950
    },
    {
      "epoch": 6.6376633619343535,
      "grad_norm": 3.7409508228302,
      "learning_rate": 1.6825746347660387e-05,
      "loss": 0.676,
      "step": 627000
    },
    {
      "epoch": 6.6376633619343535,
      "eval_loss": 0.42353758215904236,
      "eval_runtime": 47.1085,
      "eval_samples_per_second": 3564.752,
      "eval_steps_per_second": 445.61,
      "step": 627000
    },
    {
      "epoch": 6.638192683714356,
      "grad_norm": 4.533213138580322,
      "learning_rate": 1.6823099724751218e-05,
      "loss": 0.6635,
      "step": 627050
    },
    {
      "epoch": 6.63872200549436,
      "grad_norm": 4.889810562133789,
      "learning_rate": 1.6820453101842052e-05,
      "loss": 0.6835,
      "step": 627100
    },
    {
      "epoch": 6.639251327274364,
      "grad_norm": 4.026152610778809,
      "learning_rate": 1.6817806478932882e-05,
      "loss": 0.68,
      "step": 627150
    },
    {
      "epoch": 6.639780649054367,
      "grad_norm": 4.367005348205566,
      "learning_rate": 1.6815159856023717e-05,
      "loss": 0.6728,
      "step": 627200
    },
    {
      "epoch": 6.64030997083437,
      "grad_norm": 4.6372551918029785,
      "learning_rate": 1.6812513233114547e-05,
      "loss": 0.6747,
      "step": 627250
    },
    {
      "epoch": 6.640839292614373,
      "grad_norm": 4.540215015411377,
      "learning_rate": 1.680986661020538e-05,
      "loss": 0.6826,
      "step": 627300
    },
    {
      "epoch": 6.641368614394376,
      "grad_norm": 4.464234352111816,
      "learning_rate": 1.6807219987296212e-05,
      "loss": 0.669,
      "step": 627350
    },
    {
      "epoch": 6.64189793617438,
      "grad_norm": 4.21514892578125,
      "learning_rate": 1.6804573364387043e-05,
      "loss": 0.6792,
      "step": 627400
    },
    {
      "epoch": 6.642427257954383,
      "grad_norm": 4.854623317718506,
      "learning_rate": 1.6801926741477873e-05,
      "loss": 0.6702,
      "step": 627450
    },
    {
      "epoch": 6.642956579734387,
      "grad_norm": 4.310561656951904,
      "learning_rate": 1.6799280118568708e-05,
      "loss": 0.6645,
      "step": 627500
    },
    {
      "epoch": 6.642956579734387,
      "eval_loss": 0.4250093996524811,
      "eval_runtime": 47.3304,
      "eval_samples_per_second": 3548.039,
      "eval_steps_per_second": 443.521,
      "step": 627500
    },
    {
      "epoch": 6.6434859015143894,
      "grad_norm": 4.545976161956787,
      "learning_rate": 1.6796633495659538e-05,
      "loss": 0.6642,
      "step": 627550
    },
    {
      "epoch": 6.644015223294393,
      "grad_norm": 4.325502395629883,
      "learning_rate": 1.6793986872750372e-05,
      "loss": 0.6693,
      "step": 627600
    },
    {
      "epoch": 6.644544545074396,
      "grad_norm": 4.412733554840088,
      "learning_rate": 1.6791340249841203e-05,
      "loss": 0.672,
      "step": 627650
    },
    {
      "epoch": 6.6450738668544,
      "grad_norm": 4.37565279006958,
      "learning_rate": 1.6788693626932037e-05,
      "loss": 0.6697,
      "step": 627700
    },
    {
      "epoch": 6.645603188634403,
      "grad_norm": 4.226356506347656,
      "learning_rate": 1.6786047004022868e-05,
      "loss": 0.6728,
      "step": 627750
    },
    {
      "epoch": 6.646132510414406,
      "grad_norm": 4.300254821777344,
      "learning_rate": 1.6783400381113702e-05,
      "loss": 0.6789,
      "step": 627800
    },
    {
      "epoch": 6.646661832194409,
      "grad_norm": 4.594961643218994,
      "learning_rate": 1.6780753758204533e-05,
      "loss": 0.6768,
      "step": 627850
    },
    {
      "epoch": 6.647191153974413,
      "grad_norm": 4.583414077758789,
      "learning_rate": 1.6778107135295363e-05,
      "loss": 0.6796,
      "step": 627900
    },
    {
      "epoch": 6.647720475754416,
      "grad_norm": 4.559176921844482,
      "learning_rate": 1.6775460512386194e-05,
      "loss": 0.6849,
      "step": 627950
    },
    {
      "epoch": 6.648249797534419,
      "grad_norm": 4.6855034828186035,
      "learning_rate": 1.6772813889477028e-05,
      "loss": 0.6763,
      "step": 628000
    },
    {
      "epoch": 6.648249797534419,
      "eval_loss": 0.42462390661239624,
      "eval_runtime": 47.1115,
      "eval_samples_per_second": 3564.52,
      "eval_steps_per_second": 445.581,
      "step": 628000
    },
    {
      "epoch": 6.648779119314423,
      "grad_norm": 4.180058479309082,
      "learning_rate": 1.6770220199026043e-05,
      "loss": 0.6677,
      "step": 628050
    },
    {
      "epoch": 6.649308441094425,
      "grad_norm": 4.457047939300537,
      "learning_rate": 1.6767573576116877e-05,
      "loss": 0.681,
      "step": 628100
    },
    {
      "epoch": 6.649837762874429,
      "grad_norm": 4.51030969619751,
      "learning_rate": 1.6764926953207708e-05,
      "loss": 0.6696,
      "step": 628150
    },
    {
      "epoch": 6.650367084654432,
      "grad_norm": 4.6411614418029785,
      "learning_rate": 1.6762280330298542e-05,
      "loss": 0.6717,
      "step": 628200
    },
    {
      "epoch": 6.650896406434436,
      "grad_norm": 4.493698596954346,
      "learning_rate": 1.6759633707389373e-05,
      "loss": 0.6641,
      "step": 628250
    },
    {
      "epoch": 6.651425728214439,
      "grad_norm": 4.158082962036133,
      "learning_rate": 1.6756987084480207e-05,
      "loss": 0.6754,
      "step": 628300
    },
    {
      "epoch": 6.651955049994442,
      "grad_norm": 4.175336837768555,
      "learning_rate": 1.6754340461571037e-05,
      "loss": 0.6759,
      "step": 628350
    },
    {
      "epoch": 6.652484371774445,
      "grad_norm": 4.406700611114502,
      "learning_rate": 1.6751693838661868e-05,
      "loss": 0.6731,
      "step": 628400
    },
    {
      "epoch": 6.653013693554449,
      "grad_norm": 4.431291103363037,
      "learning_rate": 1.67490472157527e-05,
      "loss": 0.6639,
      "step": 628450
    },
    {
      "epoch": 6.653543015334452,
      "grad_norm": 4.283965110778809,
      "learning_rate": 1.6746400592843533e-05,
      "loss": 0.6795,
      "step": 628500
    },
    {
      "epoch": 6.653543015334452,
      "eval_loss": 0.4247904121875763,
      "eval_runtime": 47.0963,
      "eval_samples_per_second": 3565.674,
      "eval_steps_per_second": 445.725,
      "step": 628500
    },
    {
      "epoch": 6.654072337114455,
      "grad_norm": 4.164229869842529,
      "learning_rate": 1.6743753969934364e-05,
      "loss": 0.6734,
      "step": 628550
    },
    {
      "epoch": 6.6546016588944585,
      "grad_norm": 4.400290489196777,
      "learning_rate": 1.6741107347025198e-05,
      "loss": 0.6677,
      "step": 628600
    },
    {
      "epoch": 6.655130980674462,
      "grad_norm": 4.533042907714844,
      "learning_rate": 1.673846072411603e-05,
      "loss": 0.6687,
      "step": 628650
    },
    {
      "epoch": 6.655660302454465,
      "grad_norm": 4.863043785095215,
      "learning_rate": 1.6735814101206863e-05,
      "loss": 0.6691,
      "step": 628700
    },
    {
      "epoch": 6.656189624234468,
      "grad_norm": 4.278675079345703,
      "learning_rate": 1.6733167478297693e-05,
      "loss": 0.6652,
      "step": 628750
    },
    {
      "epoch": 6.656718946014472,
      "grad_norm": 4.2962799072265625,
      "learning_rate": 1.6730520855388527e-05,
      "loss": 0.6761,
      "step": 628800
    },
    {
      "epoch": 6.657248267794475,
      "grad_norm": 4.192469596862793,
      "learning_rate": 1.6727874232479358e-05,
      "loss": 0.6726,
      "step": 628850
    },
    {
      "epoch": 6.657777589574478,
      "grad_norm": 3.6799192428588867,
      "learning_rate": 1.672522760957019e-05,
      "loss": 0.6754,
      "step": 628900
    },
    {
      "epoch": 6.658306911354481,
      "grad_norm": 4.532303333282471,
      "learning_rate": 1.672258098666102e-05,
      "loss": 0.6757,
      "step": 628950
    },
    {
      "epoch": 6.658836233134485,
      "grad_norm": 4.32388162612915,
      "learning_rate": 1.6719934363751854e-05,
      "loss": 0.6761,
      "step": 629000
    },
    {
      "epoch": 6.658836233134485,
      "eval_loss": 0.42266684770584106,
      "eval_runtime": 47.1981,
      "eval_samples_per_second": 3557.98,
      "eval_steps_per_second": 444.763,
      "step": 629000
    },
    {
      "epoch": 6.659365554914488,
      "grad_norm": 4.587967395782471,
      "learning_rate": 1.6717287740842684e-05,
      "loss": 0.6696,
      "step": 629050
    },
    {
      "epoch": 6.659894876694492,
      "grad_norm": 4.816918849945068,
      "learning_rate": 1.671464111793352e-05,
      "loss": 0.6745,
      "step": 629100
    },
    {
      "epoch": 6.6604241984744945,
      "grad_norm": 4.238065242767334,
      "learning_rate": 1.671199449502435e-05,
      "loss": 0.6687,
      "step": 629150
    },
    {
      "epoch": 6.660953520254498,
      "grad_norm": 4.268529891967773,
      "learning_rate": 1.6709347872115183e-05,
      "loss": 0.6803,
      "step": 629200
    },
    {
      "epoch": 6.661482842034501,
      "grad_norm": 5.178915977478027,
      "learning_rate": 1.6706701249206014e-05,
      "loss": 0.6701,
      "step": 629250
    },
    {
      "epoch": 6.662012163814504,
      "grad_norm": 4.491837978363037,
      "learning_rate": 1.6704054626296848e-05,
      "loss": 0.6792,
      "step": 629300
    },
    {
      "epoch": 6.662541485594508,
      "grad_norm": 4.266661167144775,
      "learning_rate": 1.670140800338768e-05,
      "loss": 0.672,
      "step": 629350
    },
    {
      "epoch": 6.6630708073745115,
      "grad_norm": 4.117645263671875,
      "learning_rate": 1.6698761380478513e-05,
      "loss": 0.6828,
      "step": 629400
    },
    {
      "epoch": 6.663600129154514,
      "grad_norm": 4.350327968597412,
      "learning_rate": 1.6696114757569344e-05,
      "loss": 0.6686,
      "step": 629450
    },
    {
      "epoch": 6.664129450934517,
      "grad_norm": 4.679889678955078,
      "learning_rate": 1.6693468134660174e-05,
      "loss": 0.6747,
      "step": 629500
    },
    {
      "epoch": 6.664129450934517,
      "eval_loss": 0.42272132635116577,
      "eval_runtime": 47.5782,
      "eval_samples_per_second": 3529.561,
      "eval_steps_per_second": 441.211,
      "step": 629500
    },
    {
      "epoch": 6.664658772714521,
      "grad_norm": 4.7555975914001465,
      "learning_rate": 1.6690821511751005e-05,
      "loss": 0.6682,
      "step": 629550
    },
    {
      "epoch": 6.665188094494524,
      "grad_norm": 4.471691131591797,
      "learning_rate": 1.668817488884184e-05,
      "loss": 0.6844,
      "step": 629600
    },
    {
      "epoch": 6.665717416274528,
      "grad_norm": 4.027899265289307,
      "learning_rate": 1.668552826593267e-05,
      "loss": 0.6697,
      "step": 629650
    },
    {
      "epoch": 6.6662467380545305,
      "grad_norm": 4.38165807723999,
      "learning_rate": 1.6682881643023504e-05,
      "loss": 0.673,
      "step": 629700
    },
    {
      "epoch": 6.666776059834534,
      "grad_norm": 4.3212080001831055,
      "learning_rate": 1.6680235020114335e-05,
      "loss": 0.6873,
      "step": 629750
    },
    {
      "epoch": 6.667305381614537,
      "grad_norm": 4.349338531494141,
      "learning_rate": 1.667758839720517e-05,
      "loss": 0.6671,
      "step": 629800
    },
    {
      "epoch": 6.667834703394541,
      "grad_norm": 4.5857062339782715,
      "learning_rate": 1.6674941774296e-05,
      "loss": 0.6668,
      "step": 629850
    },
    {
      "epoch": 6.668364025174544,
      "grad_norm": 4.279148101806641,
      "learning_rate": 1.6672295151386833e-05,
      "loss": 0.6801,
      "step": 629900
    },
    {
      "epoch": 6.6688933469545475,
      "grad_norm": 4.26553201675415,
      "learning_rate": 1.6669648528477664e-05,
      "loss": 0.657,
      "step": 629950
    },
    {
      "epoch": 6.66942266873455,
      "grad_norm": 4.474243640899658,
      "learning_rate": 1.66670019055685e-05,
      "loss": 0.6781,
      "step": 630000
    },
    {
      "epoch": 6.66942266873455,
      "eval_loss": 0.42378726601600647,
      "eval_runtime": 47.3758,
      "eval_samples_per_second": 3544.638,
      "eval_steps_per_second": 443.096,
      "step": 630000
    },
    {
      "epoch": 6.669951990514553,
      "grad_norm": 4.2670674324035645,
      "learning_rate": 1.666440821511751e-05,
      "loss": 0.6818,
      "step": 630050
    },
    {
      "epoch": 6.670481312294557,
      "grad_norm": 4.047921657562256,
      "learning_rate": 1.6661761592208344e-05,
      "loss": 0.6789,
      "step": 630100
    },
    {
      "epoch": 6.671010634074561,
      "grad_norm": 4.412407875061035,
      "learning_rate": 1.6659114969299174e-05,
      "loss": 0.6674,
      "step": 630150
    },
    {
      "epoch": 6.671539955854564,
      "grad_norm": 4.476873874664307,
      "learning_rate": 1.665646834639001e-05,
      "loss": 0.6612,
      "step": 630200
    },
    {
      "epoch": 6.6720692776345665,
      "grad_norm": 4.192688465118408,
      "learning_rate": 1.665382172348084e-05,
      "loss": 0.6814,
      "step": 630250
    },
    {
      "epoch": 6.67259859941457,
      "grad_norm": 4.660384178161621,
      "learning_rate": 1.6651175100571673e-05,
      "loss": 0.6738,
      "step": 630300
    },
    {
      "epoch": 6.673127921194573,
      "grad_norm": 4.523194313049316,
      "learning_rate": 1.6648528477662504e-05,
      "loss": 0.6779,
      "step": 630350
    },
    {
      "epoch": 6.673657242974577,
      "grad_norm": 4.521939277648926,
      "learning_rate": 1.6645881854753338e-05,
      "loss": 0.6662,
      "step": 630400
    },
    {
      "epoch": 6.67418656475458,
      "grad_norm": 4.4773335456848145,
      "learning_rate": 1.664323523184417e-05,
      "loss": 0.6784,
      "step": 630450
    },
    {
      "epoch": 6.6747158865345835,
      "grad_norm": 4.613193988800049,
      "learning_rate": 1.6640588608935e-05,
      "loss": 0.6736,
      "step": 630500
    },
    {
      "epoch": 6.6747158865345835,
      "eval_loss": 0.4231764078140259,
      "eval_runtime": 47.1453,
      "eval_samples_per_second": 3561.963,
      "eval_steps_per_second": 445.261,
      "step": 630500
    },
    {
      "epoch": 6.675245208314586,
      "grad_norm": 4.571963310241699,
      "learning_rate": 1.663794198602583e-05,
      "loss": 0.6807,
      "step": 630550
    },
    {
      "epoch": 6.67577453009459,
      "grad_norm": 4.32239294052124,
      "learning_rate": 1.6635295363116664e-05,
      "loss": 0.6596,
      "step": 630600
    },
    {
      "epoch": 6.676303851874593,
      "grad_norm": 4.805631637573242,
      "learning_rate": 1.6632648740207495e-05,
      "loss": 0.6788,
      "step": 630650
    },
    {
      "epoch": 6.676833173654597,
      "grad_norm": 3.891240358352661,
      "learning_rate": 1.663000211729833e-05,
      "loss": 0.6794,
      "step": 630700
    },
    {
      "epoch": 6.6773624954346,
      "grad_norm": 4.595567226409912,
      "learning_rate": 1.662735549438916e-05,
      "loss": 0.6748,
      "step": 630750
    },
    {
      "epoch": 6.6778918172146025,
      "grad_norm": 4.411251068115234,
      "learning_rate": 1.6624708871479994e-05,
      "loss": 0.6775,
      "step": 630800
    },
    {
      "epoch": 6.678421138994606,
      "grad_norm": 4.512763023376465,
      "learning_rate": 1.6622062248570825e-05,
      "loss": 0.6663,
      "step": 630850
    },
    {
      "epoch": 6.67895046077461,
      "grad_norm": 4.465948104858398,
      "learning_rate": 1.661941562566166e-05,
      "loss": 0.6683,
      "step": 630900
    },
    {
      "epoch": 6.679479782554613,
      "grad_norm": 4.8222808837890625,
      "learning_rate": 1.661676900275249e-05,
      "loss": 0.6648,
      "step": 630950
    },
    {
      "epoch": 6.680009104334616,
      "grad_norm": 4.347815990447998,
      "learning_rate": 1.6614122379843324e-05,
      "loss": 0.6797,
      "step": 631000
    },
    {
      "epoch": 6.680009104334616,
      "eval_loss": 0.4227358102798462,
      "eval_runtime": 46.9201,
      "eval_samples_per_second": 3579.06,
      "eval_steps_per_second": 447.398,
      "step": 631000
    },
    {
      "epoch": 6.6805384261146195,
      "grad_norm": 4.34594202041626,
      "learning_rate": 1.6611475756934154e-05,
      "loss": 0.6623,
      "step": 631050
    },
    {
      "epoch": 6.681067747894622,
      "grad_norm": 4.161756992340088,
      "learning_rate": 1.6608829134024985e-05,
      "loss": 0.6714,
      "step": 631100
    },
    {
      "epoch": 6.681597069674626,
      "grad_norm": 4.260290622711182,
      "learning_rate": 1.6606182511115816e-05,
      "loss": 0.6788,
      "step": 631150
    },
    {
      "epoch": 6.682126391454629,
      "grad_norm": 4.201921463012695,
      "learning_rate": 1.6603535888206646e-05,
      "loss": 0.6737,
      "step": 631200
    },
    {
      "epoch": 6.682655713234633,
      "grad_norm": 4.058831214904785,
      "learning_rate": 1.660088926529748e-05,
      "loss": 0.6702,
      "step": 631250
    },
    {
      "epoch": 6.683185035014636,
      "grad_norm": 4.871471881866455,
      "learning_rate": 1.659824264238831e-05,
      "loss": 0.6717,
      "step": 631300
    },
    {
      "epoch": 6.683714356794639,
      "grad_norm": 4.542018413543701,
      "learning_rate": 1.6595596019479145e-05,
      "loss": 0.6752,
      "step": 631350
    },
    {
      "epoch": 6.684243678574642,
      "grad_norm": 4.346864700317383,
      "learning_rate": 1.6592949396569976e-05,
      "loss": 0.6622,
      "step": 631400
    },
    {
      "epoch": 6.684773000354646,
      "grad_norm": 4.587151527404785,
      "learning_rate": 1.659030277366081e-05,
      "loss": 0.6794,
      "step": 631450
    },
    {
      "epoch": 6.685302322134649,
      "grad_norm": 4.27704381942749,
      "learning_rate": 1.658765615075164e-05,
      "loss": 0.6656,
      "step": 631500
    },
    {
      "epoch": 6.685302322134649,
      "eval_loss": 0.42323610186576843,
      "eval_runtime": 47.0177,
      "eval_samples_per_second": 3571.632,
      "eval_steps_per_second": 446.47,
      "step": 631500
    },
    {
      "epoch": 6.685831643914652,
      "grad_norm": 4.519135475158691,
      "learning_rate": 1.6585009527842475e-05,
      "loss": 0.6761,
      "step": 631550
    },
    {
      "epoch": 6.686360965694655,
      "grad_norm": 4.302299976348877,
      "learning_rate": 1.6582362904933306e-05,
      "loss": 0.6869,
      "step": 631600
    },
    {
      "epoch": 6.686890287474659,
      "grad_norm": 4.309952259063721,
      "learning_rate": 1.6579716282024136e-05,
      "loss": 0.6721,
      "step": 631650
    },
    {
      "epoch": 6.687419609254662,
      "grad_norm": 4.6562957763671875,
      "learning_rate": 1.6577069659114967e-05,
      "loss": 0.6746,
      "step": 631700
    },
    {
      "epoch": 6.687948931034665,
      "grad_norm": 4.771438121795654,
      "learning_rate": 1.65744230362058e-05,
      "loss": 0.6832,
      "step": 631750
    },
    {
      "epoch": 6.688478252814669,
      "grad_norm": 4.563462734222412,
      "learning_rate": 1.6571776413296632e-05,
      "loss": 0.6774,
      "step": 631800
    },
    {
      "epoch": 6.6890075745946715,
      "grad_norm": 4.351071357727051,
      "learning_rate": 1.6569129790387466e-05,
      "loss": 0.6759,
      "step": 631850
    },
    {
      "epoch": 6.689536896374675,
      "grad_norm": 4.596795558929443,
      "learning_rate": 1.6566483167478297e-05,
      "loss": 0.6773,
      "step": 631900
    },
    {
      "epoch": 6.690066218154678,
      "grad_norm": 4.526018142700195,
      "learning_rate": 1.656383654456913e-05,
      "loss": 0.6659,
      "step": 631950
    },
    {
      "epoch": 6.690595539934682,
      "grad_norm": 4.579320430755615,
      "learning_rate": 1.656118992165996e-05,
      "loss": 0.6722,
      "step": 632000
    },
    {
      "epoch": 6.690595539934682,
      "eval_loss": 0.4219409227371216,
      "eval_runtime": 46.844,
      "eval_samples_per_second": 3584.88,
      "eval_steps_per_second": 448.126,
      "step": 632000
    },
    {
      "epoch": 6.691124861714685,
      "grad_norm": 4.233027935028076,
      "learning_rate": 1.655859623120898e-05,
      "loss": 0.6654,
      "step": 632050
    },
    {
      "epoch": 6.6916541834946885,
      "grad_norm": 4.245590686798096,
      "learning_rate": 1.655594960829981e-05,
      "loss": 0.6703,
      "step": 632100
    },
    {
      "epoch": 6.692183505274691,
      "grad_norm": 4.771515846252441,
      "learning_rate": 1.655330298539064e-05,
      "loss": 0.6844,
      "step": 632150
    },
    {
      "epoch": 6.692712827054695,
      "grad_norm": 4.089937686920166,
      "learning_rate": 1.6550656362481472e-05,
      "loss": 0.6693,
      "step": 632200
    },
    {
      "epoch": 6.693242148834698,
      "grad_norm": 4.576497554779053,
      "learning_rate": 1.6548009739572306e-05,
      "loss": 0.6787,
      "step": 632250
    },
    {
      "epoch": 6.693771470614701,
      "grad_norm": 4.527565956115723,
      "learning_rate": 1.6545363116663137e-05,
      "loss": 0.6617,
      "step": 632300
    },
    {
      "epoch": 6.694300792394705,
      "grad_norm": 4.604825973510742,
      "learning_rate": 1.654271649375397e-05,
      "loss": 0.6675,
      "step": 632350
    },
    {
      "epoch": 6.694830114174708,
      "grad_norm": 4.506864070892334,
      "learning_rate": 1.65400698708448e-05,
      "loss": 0.6607,
      "step": 632400
    },
    {
      "epoch": 6.695359435954711,
      "grad_norm": 4.459097385406494,
      "learning_rate": 1.6537423247935636e-05,
      "loss": 0.6748,
      "step": 632450
    },
    {
      "epoch": 6.695888757734714,
      "grad_norm": 4.628551959991455,
      "learning_rate": 1.6534776625026466e-05,
      "loss": 0.662,
      "step": 632500
    },
    {
      "epoch": 6.695888757734714,
      "eval_loss": 0.4220353960990906,
      "eval_runtime": 47.7907,
      "eval_samples_per_second": 3513.862,
      "eval_steps_per_second": 439.249,
      "step": 632500
    },
    {
      "epoch": 6.696418079514718,
      "grad_norm": 4.4384942054748535,
      "learning_rate": 1.65321300021173e-05,
      "loss": 0.6668,
      "step": 632550
    },
    {
      "epoch": 6.696947401294721,
      "grad_norm": 4.525851726531982,
      "learning_rate": 1.652948337920813e-05,
      "loss": 0.6654,
      "step": 632600
    },
    {
      "epoch": 6.6974767230747245,
      "grad_norm": 4.406285762786865,
      "learning_rate": 1.6526836756298962e-05,
      "loss": 0.6741,
      "step": 632650
    },
    {
      "epoch": 6.698006044854727,
      "grad_norm": 4.1448073387146,
      "learning_rate": 1.6524190133389792e-05,
      "loss": 0.6832,
      "step": 632700
    },
    {
      "epoch": 6.698535366634731,
      "grad_norm": 4.797469615936279,
      "learning_rate": 1.6521543510480627e-05,
      "loss": 0.6703,
      "step": 632750
    },
    {
      "epoch": 6.699064688414734,
      "grad_norm": 4.911571979522705,
      "learning_rate": 1.6518896887571457e-05,
      "loss": 0.6799,
      "step": 632800
    },
    {
      "epoch": 6.699594010194738,
      "grad_norm": 4.323792934417725,
      "learning_rate": 1.651625026466229e-05,
      "loss": 0.6714,
      "step": 632850
    },
    {
      "epoch": 6.700123331974741,
      "grad_norm": 4.670532703399658,
      "learning_rate": 1.6513603641753122e-05,
      "loss": 0.6699,
      "step": 632900
    },
    {
      "epoch": 6.700652653754744,
      "grad_norm": 4.563061237335205,
      "learning_rate": 1.6510957018843956e-05,
      "loss": 0.6727,
      "step": 632950
    },
    {
      "epoch": 6.701181975534747,
      "grad_norm": 4.63012170791626,
      "learning_rate": 1.6508310395934787e-05,
      "loss": 0.6806,
      "step": 633000
    },
    {
      "epoch": 6.701181975534747,
      "eval_loss": 0.42098647356033325,
      "eval_runtime": 47.8993,
      "eval_samples_per_second": 3505.896,
      "eval_steps_per_second": 438.253,
      "step": 633000
    },
    {
      "epoch": 6.70171129731475,
      "grad_norm": 4.537821292877197,
      "learning_rate": 1.650566377302562e-05,
      "loss": 0.677,
      "step": 633050
    },
    {
      "epoch": 6.702240619094754,
      "grad_norm": 4.143869400024414,
      "learning_rate": 1.6503017150116452e-05,
      "loss": 0.6767,
      "step": 633100
    },
    {
      "epoch": 6.702769940874758,
      "grad_norm": 4.430616855621338,
      "learning_rate": 1.6500370527207286e-05,
      "loss": 0.6592,
      "step": 633150
    },
    {
      "epoch": 6.7032992626547605,
      "grad_norm": 4.264241695404053,
      "learning_rate": 1.6497723904298117e-05,
      "loss": 0.6722,
      "step": 633200
    },
    {
      "epoch": 6.703828584434763,
      "grad_norm": 4.691174507141113,
      "learning_rate": 1.6495077281388947e-05,
      "loss": 0.6636,
      "step": 633250
    },
    {
      "epoch": 6.704357906214767,
      "grad_norm": 4.82556676864624,
      "learning_rate": 1.6492430658479778e-05,
      "loss": 0.6751,
      "step": 633300
    },
    {
      "epoch": 6.70488722799477,
      "grad_norm": 4.207268238067627,
      "learning_rate": 1.6489784035570612e-05,
      "loss": 0.6756,
      "step": 633350
    },
    {
      "epoch": 6.705416549774774,
      "grad_norm": 4.073286533355713,
      "learning_rate": 1.6487137412661443e-05,
      "loss": 0.6621,
      "step": 633400
    },
    {
      "epoch": 6.705945871554777,
      "grad_norm": 4.200526237487793,
      "learning_rate": 1.6484490789752277e-05,
      "loss": 0.6626,
      "step": 633450
    },
    {
      "epoch": 6.70647519333478,
      "grad_norm": 4.714020252227783,
      "learning_rate": 1.6481844166843108e-05,
      "loss": 0.6727,
      "step": 633500
    },
    {
      "epoch": 6.70647519333478,
      "eval_loss": 0.42253774404525757,
      "eval_runtime": 48.9255,
      "eval_samples_per_second": 3432.361,
      "eval_steps_per_second": 429.06,
      "step": 633500
    },
    {
      "epoch": 6.707004515114783,
      "grad_norm": 4.752542972564697,
      "learning_rate": 1.6479197543933942e-05,
      "loss": 0.6772,
      "step": 633550
    },
    {
      "epoch": 6.707533836894787,
      "grad_norm": 4.492583751678467,
      "learning_rate": 1.6476550921024772e-05,
      "loss": 0.6726,
      "step": 633600
    },
    {
      "epoch": 6.70806315867479,
      "grad_norm": 4.55320930480957,
      "learning_rate": 1.6473904298115607e-05,
      "loss": 0.6747,
      "step": 633650
    },
    {
      "epoch": 6.708592480454794,
      "grad_norm": 4.345030784606934,
      "learning_rate": 1.6471257675206437e-05,
      "loss": 0.6708,
      "step": 633700
    },
    {
      "epoch": 6.7091218022347965,
      "grad_norm": 4.5402512550354,
      "learning_rate": 1.646861105229727e-05,
      "loss": 0.6784,
      "step": 633750
    },
    {
      "epoch": 6.709651124014799,
      "grad_norm": 4.4524736404418945,
      "learning_rate": 1.6465964429388102e-05,
      "loss": 0.6687,
      "step": 633800
    },
    {
      "epoch": 6.710180445794803,
      "grad_norm": 4.502624988555908,
      "learning_rate": 1.6463317806478933e-05,
      "loss": 0.6593,
      "step": 633850
    },
    {
      "epoch": 6.710709767574807,
      "grad_norm": 4.454161167144775,
      "learning_rate": 1.6460671183569763e-05,
      "loss": 0.6678,
      "step": 633900
    },
    {
      "epoch": 6.71123908935481,
      "grad_norm": 4.725961208343506,
      "learning_rate": 1.6458024560660598e-05,
      "loss": 0.6578,
      "step": 633950
    },
    {
      "epoch": 6.711768411134813,
      "grad_norm": 4.1934614181518555,
      "learning_rate": 1.6455377937751428e-05,
      "loss": 0.6699,
      "step": 634000
    },
    {
      "epoch": 6.711768411134813,
      "eval_loss": 0.4232169985771179,
      "eval_runtime": 48.0806,
      "eval_samples_per_second": 3492.673,
      "eval_steps_per_second": 436.6,
      "step": 634000
    },
    {
      "epoch": 6.712297732914816,
      "grad_norm": 4.367435932159424,
      "learning_rate": 1.6452784247300446e-05,
      "loss": 0.6662,
      "step": 634050
    },
    {
      "epoch": 6.712827054694819,
      "grad_norm": 4.231690883636475,
      "learning_rate": 1.6450137624391277e-05,
      "loss": 0.6836,
      "step": 634100
    },
    {
      "epoch": 6.713356376474823,
      "grad_norm": 4.627364635467529,
      "learning_rate": 1.644749100148211e-05,
      "loss": 0.669,
      "step": 634150
    },
    {
      "epoch": 6.713885698254826,
      "grad_norm": 4.044534683227539,
      "learning_rate": 1.6444844378572942e-05,
      "loss": 0.6774,
      "step": 634200
    },
    {
      "epoch": 6.71441502003483,
      "grad_norm": 4.714566707611084,
      "learning_rate": 1.6442197755663773e-05,
      "loss": 0.6577,
      "step": 634250
    },
    {
      "epoch": 6.7149443418148325,
      "grad_norm": 4.128180503845215,
      "learning_rate": 1.6439551132754603e-05,
      "loss": 0.6573,
      "step": 634300
    },
    {
      "epoch": 6.715473663594836,
      "grad_norm": 4.567838191986084,
      "learning_rate": 1.6436904509845437e-05,
      "loss": 0.6693,
      "step": 634350
    },
    {
      "epoch": 6.716002985374839,
      "grad_norm": 4.431358814239502,
      "learning_rate": 1.6434257886936268e-05,
      "loss": 0.6688,
      "step": 634400
    },
    {
      "epoch": 6.716532307154843,
      "grad_norm": 4.493310928344727,
      "learning_rate": 1.6431611264027102e-05,
      "loss": 0.6887,
      "step": 634450
    },
    {
      "epoch": 6.717061628934846,
      "grad_norm": 4.484910011291504,
      "learning_rate": 1.6428964641117933e-05,
      "loss": 0.6722,
      "step": 634500
    },
    {
      "epoch": 6.717061628934846,
      "eval_loss": 0.4216165244579315,
      "eval_runtime": 47.3229,
      "eval_samples_per_second": 3548.599,
      "eval_steps_per_second": 443.591,
      "step": 634500
    },
    {
      "epoch": 6.717590950714849,
      "grad_norm": 4.402276039123535,
      "learning_rate": 1.6426318018208767e-05,
      "loss": 0.6697,
      "step": 634550
    },
    {
      "epoch": 6.718120272494852,
      "grad_norm": 4.511358737945557,
      "learning_rate": 1.6423671395299598e-05,
      "loss": 0.675,
      "step": 634600
    },
    {
      "epoch": 6.718649594274856,
      "grad_norm": 3.9567248821258545,
      "learning_rate": 1.6421024772390432e-05,
      "loss": 0.6661,
      "step": 634650
    },
    {
      "epoch": 6.719178916054859,
      "grad_norm": 4.250329494476318,
      "learning_rate": 1.6418378149481263e-05,
      "loss": 0.6717,
      "step": 634700
    },
    {
      "epoch": 6.719708237834862,
      "grad_norm": 4.493869304656982,
      "learning_rate": 1.6415731526572097e-05,
      "loss": 0.6705,
      "step": 634750
    },
    {
      "epoch": 6.720237559614866,
      "grad_norm": 4.38353157043457,
      "learning_rate": 1.6413084903662927e-05,
      "loss": 0.6706,
      "step": 634800
    },
    {
      "epoch": 6.720766881394868,
      "grad_norm": 4.396449565887451,
      "learning_rate": 1.6410438280753758e-05,
      "loss": 0.6787,
      "step": 634850
    },
    {
      "epoch": 6.721296203174872,
      "grad_norm": 4.422438144683838,
      "learning_rate": 1.640779165784459e-05,
      "loss": 0.6682,
      "step": 634900
    },
    {
      "epoch": 6.721825524954875,
      "grad_norm": 4.526956558227539,
      "learning_rate": 1.6405145034935423e-05,
      "loss": 0.6629,
      "step": 634950
    },
    {
      "epoch": 6.722354846734879,
      "grad_norm": 4.513936519622803,
      "learning_rate": 1.6402498412026254e-05,
      "loss": 0.6754,
      "step": 635000
    },
    {
      "epoch": 6.722354846734879,
      "eval_loss": 0.4211808741092682,
      "eval_runtime": 47.1827,
      "eval_samples_per_second": 3559.143,
      "eval_steps_per_second": 444.909,
      "step": 635000
    },
    {
      "epoch": 6.722884168514882,
      "grad_norm": 4.475933074951172,
      "learning_rate": 1.6399851789117088e-05,
      "loss": 0.6817,
      "step": 635050
    },
    {
      "epoch": 6.723413490294885,
      "grad_norm": 4.332275867462158,
      "learning_rate": 1.639720516620792e-05,
      "loss": 0.6682,
      "step": 635100
    },
    {
      "epoch": 6.723942812074888,
      "grad_norm": 4.212169647216797,
      "learning_rate": 1.6394558543298753e-05,
      "loss": 0.6695,
      "step": 635150
    },
    {
      "epoch": 6.724472133854892,
      "grad_norm": 4.5883026123046875,
      "learning_rate": 1.6391911920389583e-05,
      "loss": 0.6602,
      "step": 635200
    },
    {
      "epoch": 6.725001455634895,
      "grad_norm": 4.322671413421631,
      "learning_rate": 1.6389265297480417e-05,
      "loss": 0.6655,
      "step": 635250
    },
    {
      "epoch": 6.725530777414898,
      "grad_norm": 4.118393421173096,
      "learning_rate": 1.6386618674571248e-05,
      "loss": 0.6753,
      "step": 635300
    },
    {
      "epoch": 6.7260600991949016,
      "grad_norm": 4.532024383544922,
      "learning_rate": 1.638397205166208e-05,
      "loss": 0.6712,
      "step": 635350
    },
    {
      "epoch": 6.726589420974905,
      "grad_norm": 4.208863258361816,
      "learning_rate": 1.638132542875291e-05,
      "loss": 0.6645,
      "step": 635400
    },
    {
      "epoch": 6.727118742754908,
      "grad_norm": 4.560502052307129,
      "learning_rate": 1.6378678805843744e-05,
      "loss": 0.6652,
      "step": 635450
    },
    {
      "epoch": 6.727648064534911,
      "grad_norm": 4.194756031036377,
      "learning_rate": 1.6376032182934574e-05,
      "loss": 0.6566,
      "step": 635500
    },
    {
      "epoch": 6.727648064534911,
      "eval_loss": 0.42048636078834534,
      "eval_runtime": 47.8637,
      "eval_samples_per_second": 3508.507,
      "eval_steps_per_second": 438.579,
      "step": 635500
    },
    {
      "epoch": 6.728177386314915,
      "grad_norm": 4.8106584548950195,
      "learning_rate": 1.637338556002541e-05,
      "loss": 0.6813,
      "step": 635550
    },
    {
      "epoch": 6.728706708094918,
      "grad_norm": 4.439715385437012,
      "learning_rate": 1.637073893711624e-05,
      "loss": 0.6655,
      "step": 635600
    },
    {
      "epoch": 6.729236029874921,
      "grad_norm": 4.082335472106934,
      "learning_rate": 1.6368092314207073e-05,
      "loss": 0.693,
      "step": 635650
    },
    {
      "epoch": 6.729765351654924,
      "grad_norm": 4.479474067687988,
      "learning_rate": 1.6365445691297904e-05,
      "loss": 0.6651,
      "step": 635700
    },
    {
      "epoch": 6.730294673434928,
      "grad_norm": 4.3872294425964355,
      "learning_rate": 1.6362799068388738e-05,
      "loss": 0.6675,
      "step": 635750
    },
    {
      "epoch": 6.730823995214931,
      "grad_norm": 4.511876106262207,
      "learning_rate": 1.636015244547957e-05,
      "loss": 0.6782,
      "step": 635800
    },
    {
      "epoch": 6.731353316994935,
      "grad_norm": 3.9866302013397217,
      "learning_rate": 1.6357505822570403e-05,
      "loss": 0.6659,
      "step": 635850
    },
    {
      "epoch": 6.7318826387749375,
      "grad_norm": 4.230082035064697,
      "learning_rate": 1.6354859199661234e-05,
      "loss": 0.6728,
      "step": 635900
    },
    {
      "epoch": 6.732411960554941,
      "grad_norm": 5.017256259918213,
      "learning_rate": 1.6352212576752064e-05,
      "loss": 0.663,
      "step": 635950
    },
    {
      "epoch": 6.732941282334944,
      "grad_norm": 4.46488094329834,
      "learning_rate": 1.6349565953842895e-05,
      "loss": 0.6667,
      "step": 636000
    },
    {
      "epoch": 6.732941282334944,
      "eval_loss": 0.4213543236255646,
      "eval_runtime": 47.4292,
      "eval_samples_per_second": 3540.646,
      "eval_steps_per_second": 442.597,
      "step": 636000
    },
    {
      "epoch": 6.733470604114947,
      "grad_norm": 4.376903533935547,
      "learning_rate": 1.6346972263391913e-05,
      "loss": 0.6789,
      "step": 636050
    },
    {
      "epoch": 6.733999925894951,
      "grad_norm": 4.600386619567871,
      "learning_rate": 1.6344325640482744e-05,
      "loss": 0.676,
      "step": 636100
    },
    {
      "epoch": 6.7345292476749545,
      "grad_norm": 4.454606533050537,
      "learning_rate": 1.6341679017573578e-05,
      "loss": 0.6679,
      "step": 636150
    },
    {
      "epoch": 6.735058569454957,
      "grad_norm": 4.701916694641113,
      "learning_rate": 1.633903239466441e-05,
      "loss": 0.6653,
      "step": 636200
    },
    {
      "epoch": 6.73558789123496,
      "grad_norm": 4.127893447875977,
      "learning_rate": 1.6336385771755243e-05,
      "loss": 0.6738,
      "step": 636250
    },
    {
      "epoch": 6.736117213014964,
      "grad_norm": 4.529163360595703,
      "learning_rate": 1.6333739148846073e-05,
      "loss": 0.6677,
      "step": 636300
    },
    {
      "epoch": 6.736646534794967,
      "grad_norm": 4.596205234527588,
      "learning_rate": 1.6331092525936904e-05,
      "loss": 0.6728,
      "step": 636350
    },
    {
      "epoch": 6.737175856574971,
      "grad_norm": 3.955657720565796,
      "learning_rate": 1.6328445903027735e-05,
      "loss": 0.6539,
      "step": 636400
    },
    {
      "epoch": 6.7377051783549735,
      "grad_norm": 4.251112937927246,
      "learning_rate": 1.632579928011857e-05,
      "loss": 0.6688,
      "step": 636450
    },
    {
      "epoch": 6.738234500134977,
      "grad_norm": 4.559942722320557,
      "learning_rate": 1.63231526572094e-05,
      "loss": 0.6778,
      "step": 636500
    },
    {
      "epoch": 6.738234500134977,
      "eval_loss": 0.42177632451057434,
      "eval_runtime": 47.083,
      "eval_samples_per_second": 3566.683,
      "eval_steps_per_second": 445.851,
      "step": 636500
    },
    {
      "epoch": 6.73876382191498,
      "grad_norm": 4.482900142669678,
      "learning_rate": 1.6320506034300234e-05,
      "loss": 0.6791,
      "step": 636550
    },
    {
      "epoch": 6.739293143694984,
      "grad_norm": 4.534135818481445,
      "learning_rate": 1.6317859411391064e-05,
      "loss": 0.6691,
      "step": 636600
    },
    {
      "epoch": 6.739822465474987,
      "grad_norm": 4.622901916503906,
      "learning_rate": 1.63152127884819e-05,
      "loss": 0.6753,
      "step": 636650
    },
    {
      "epoch": 6.7403517872549905,
      "grad_norm": 4.559703826904297,
      "learning_rate": 1.631256616557273e-05,
      "loss": 0.6627,
      "step": 636700
    },
    {
      "epoch": 6.740881109034993,
      "grad_norm": 4.361227989196777,
      "learning_rate": 1.6309919542663563e-05,
      "loss": 0.6607,
      "step": 636750
    },
    {
      "epoch": 6.741410430814996,
      "grad_norm": 4.2500224113464355,
      "learning_rate": 1.6307272919754394e-05,
      "loss": 0.6676,
      "step": 636800
    },
    {
      "epoch": 6.741939752595,
      "grad_norm": 4.394876480102539,
      "learning_rate": 1.6304626296845228e-05,
      "loss": 0.6753,
      "step": 636850
    },
    {
      "epoch": 6.742469074375004,
      "grad_norm": 4.237515449523926,
      "learning_rate": 1.630197967393606e-05,
      "loss": 0.6626,
      "step": 636900
    },
    {
      "epoch": 6.742998396155007,
      "grad_norm": 4.465710163116455,
      "learning_rate": 1.629933305102689e-05,
      "loss": 0.6702,
      "step": 636950
    },
    {
      "epoch": 6.7435277179350095,
      "grad_norm": 4.333628177642822,
      "learning_rate": 1.629668642811772e-05,
      "loss": 0.6643,
      "step": 637000
    },
    {
      "epoch": 6.7435277179350095,
      "eval_loss": 0.4218076765537262,
      "eval_runtime": 47.4735,
      "eval_samples_per_second": 3537.343,
      "eval_steps_per_second": 442.184,
      "step": 637000
    },
    {
      "epoch": 6.744057039715013,
      "grad_norm": 4.603838920593262,
      "learning_rate": 1.6294039805208554e-05,
      "loss": 0.6625,
      "step": 637050
    },
    {
      "epoch": 6.744586361495016,
      "grad_norm": 4.43304967880249,
      "learning_rate": 1.6291393182299385e-05,
      "loss": 0.6764,
      "step": 637100
    },
    {
      "epoch": 6.74511568327502,
      "grad_norm": 4.002343654632568,
      "learning_rate": 1.628874655939022e-05,
      "loss": 0.6704,
      "step": 637150
    },
    {
      "epoch": 6.745645005055023,
      "grad_norm": 4.246581077575684,
      "learning_rate": 1.628609993648105e-05,
      "loss": 0.6754,
      "step": 637200
    },
    {
      "epoch": 6.7461743268350265,
      "grad_norm": 4.000646591186523,
      "learning_rate": 1.6283453313571884e-05,
      "loss": 0.6582,
      "step": 637250
    },
    {
      "epoch": 6.746703648615029,
      "grad_norm": 4.997451305389404,
      "learning_rate": 1.6280806690662715e-05,
      "loss": 0.6728,
      "step": 637300
    },
    {
      "epoch": 6.747232970395033,
      "grad_norm": 4.6040425300598145,
      "learning_rate": 1.627816006775355e-05,
      "loss": 0.6683,
      "step": 637350
    },
    {
      "epoch": 6.747762292175036,
      "grad_norm": 4.261005401611328,
      "learning_rate": 1.627551344484438e-05,
      "loss": 0.6688,
      "step": 637400
    },
    {
      "epoch": 6.74829161395504,
      "grad_norm": 4.79655647277832,
      "learning_rate": 1.6272866821935214e-05,
      "loss": 0.6773,
      "step": 637450
    },
    {
      "epoch": 6.748820935735043,
      "grad_norm": 4.938066482543945,
      "learning_rate": 1.6270220199026044e-05,
      "loss": 0.6557,
      "step": 637500
    },
    {
      "epoch": 6.748820935735043,
      "eval_loss": 0.42062437534332275,
      "eval_runtime": 47.7596,
      "eval_samples_per_second": 3516.149,
      "eval_steps_per_second": 439.534,
      "step": 637500
    },
    {
      "epoch": 6.749350257515046,
      "grad_norm": 4.281150817871094,
      "learning_rate": 1.6267573576116875e-05,
      "loss": 0.6679,
      "step": 637550
    },
    {
      "epoch": 6.749879579295049,
      "grad_norm": 3.9451277256011963,
      "learning_rate": 1.6264926953207706e-05,
      "loss": 0.6683,
      "step": 637600
    },
    {
      "epoch": 6.750408901075053,
      "grad_norm": 4.422649383544922,
      "learning_rate": 1.626228033029854e-05,
      "loss": 0.6704,
      "step": 637650
    },
    {
      "epoch": 6.750938222855056,
      "grad_norm": 4.379650115966797,
      "learning_rate": 1.625963370738937e-05,
      "loss": 0.6771,
      "step": 637700
    },
    {
      "epoch": 6.751467544635059,
      "grad_norm": 4.118716716766357,
      "learning_rate": 1.6256987084480205e-05,
      "loss": 0.666,
      "step": 637750
    },
    {
      "epoch": 6.7519968664150625,
      "grad_norm": 4.667392730712891,
      "learning_rate": 1.6254340461571035e-05,
      "loss": 0.668,
      "step": 637800
    },
    {
      "epoch": 6.752526188195065,
      "grad_norm": 4.004791259765625,
      "learning_rate": 1.625169383866187e-05,
      "loss": 0.6716,
      "step": 637850
    },
    {
      "epoch": 6.753055509975069,
      "grad_norm": 4.651211738586426,
      "learning_rate": 1.62490472157527e-05,
      "loss": 0.6723,
      "step": 637900
    },
    {
      "epoch": 6.753584831755072,
      "grad_norm": 4.631771564483643,
      "learning_rate": 1.6246400592843534e-05,
      "loss": 0.6723,
      "step": 637950
    },
    {
      "epoch": 6.754114153535076,
      "grad_norm": 4.4258928298950195,
      "learning_rate": 1.6243753969934365e-05,
      "loss": 0.6704,
      "step": 638000
    },
    {
      "epoch": 6.754114153535076,
      "eval_loss": 0.4209845960140228,
      "eval_runtime": 48.0645,
      "eval_samples_per_second": 3493.849,
      "eval_steps_per_second": 436.747,
      "step": 638000
    },
    {
      "epoch": 6.754643475315079,
      "grad_norm": 4.495579719543457,
      "learning_rate": 1.6241107347025196e-05,
      "loss": 0.6584,
      "step": 638050
    },
    {
      "epoch": 6.755172797095082,
      "grad_norm": 4.713590145111084,
      "learning_rate": 1.623851365657421e-05,
      "loss": 0.6581,
      "step": 638100
    },
    {
      "epoch": 6.755702118875085,
      "grad_norm": 4.74849271774292,
      "learning_rate": 1.6235867033665045e-05,
      "loss": 0.6752,
      "step": 638150
    },
    {
      "epoch": 6.756231440655089,
      "grad_norm": 4.488380432128906,
      "learning_rate": 1.6233220410755875e-05,
      "loss": 0.679,
      "step": 638200
    },
    {
      "epoch": 6.756760762435092,
      "grad_norm": 4.400097370147705,
      "learning_rate": 1.623057378784671e-05,
      "loss": 0.6677,
      "step": 638250
    },
    {
      "epoch": 6.757290084215096,
      "grad_norm": 4.245896816253662,
      "learning_rate": 1.622792716493754e-05,
      "loss": 0.6744,
      "step": 638300
    },
    {
      "epoch": 6.7578194059950984,
      "grad_norm": 4.296292781829834,
      "learning_rate": 1.6225280542028374e-05,
      "loss": 0.6662,
      "step": 638350
    },
    {
      "epoch": 6.758348727775102,
      "grad_norm": 4.942073345184326,
      "learning_rate": 1.6222633919119205e-05,
      "loss": 0.6645,
      "step": 638400
    },
    {
      "epoch": 6.758878049555105,
      "grad_norm": 4.13334846496582,
      "learning_rate": 1.621998729621004e-05,
      "loss": 0.6739,
      "step": 638450
    },
    {
      "epoch": 6.759407371335108,
      "grad_norm": 4.487013339996338,
      "learning_rate": 1.621734067330087e-05,
      "loss": 0.6683,
      "step": 638500
    },
    {
      "epoch": 6.759407371335108,
      "eval_loss": 0.4210500121116638,
      "eval_runtime": 46.8379,
      "eval_samples_per_second": 3585.347,
      "eval_steps_per_second": 448.184,
      "step": 638500
    },
    {
      "epoch": 6.759936693115112,
      "grad_norm": 4.390177249908447,
      "learning_rate": 1.62146940503917e-05,
      "loss": 0.6773,
      "step": 638550
    },
    {
      "epoch": 6.760466014895115,
      "grad_norm": 4.88252067565918,
      "learning_rate": 1.621204742748253e-05,
      "loss": 0.685,
      "step": 638600
    },
    {
      "epoch": 6.760995336675118,
      "grad_norm": 4.19503116607666,
      "learning_rate": 1.6209400804573365e-05,
      "loss": 0.6665,
      "step": 638650
    },
    {
      "epoch": 6.761524658455121,
      "grad_norm": 4.332684516906738,
      "learning_rate": 1.6206754181664196e-05,
      "loss": 0.6733,
      "step": 638700
    },
    {
      "epoch": 6.762053980235125,
      "grad_norm": 4.016059398651123,
      "learning_rate": 1.620410755875503e-05,
      "loss": 0.6607,
      "step": 638750
    },
    {
      "epoch": 6.762583302015128,
      "grad_norm": 4.2034382820129395,
      "learning_rate": 1.620146093584586e-05,
      "loss": 0.6664,
      "step": 638800
    },
    {
      "epoch": 6.763112623795132,
      "grad_norm": 4.4274187088012695,
      "learning_rate": 1.6198814312936695e-05,
      "loss": 0.6709,
      "step": 638850
    },
    {
      "epoch": 6.763641945575134,
      "grad_norm": 4.425468444824219,
      "learning_rate": 1.6196167690027526e-05,
      "loss": 0.6668,
      "step": 638900
    },
    {
      "epoch": 6.764171267355138,
      "grad_norm": 4.548639297485352,
      "learning_rate": 1.619352106711836e-05,
      "loss": 0.6614,
      "step": 638950
    },
    {
      "epoch": 6.764700589135141,
      "grad_norm": 4.404911994934082,
      "learning_rate": 1.619087444420919e-05,
      "loss": 0.6786,
      "step": 639000
    },
    {
      "epoch": 6.764700589135141,
      "eval_loss": 0.4213108718395233,
      "eval_runtime": 46.9123,
      "eval_samples_per_second": 3579.656,
      "eval_steps_per_second": 447.473,
      "step": 639000
    },
    {
      "epoch": 6.765229910915145,
      "grad_norm": 4.524755477905273,
      "learning_rate": 1.618822782130002e-05,
      "loss": 0.6686,
      "step": 639050
    },
    {
      "epoch": 6.765759232695148,
      "grad_norm": 4.314755916595459,
      "learning_rate": 1.6185581198390852e-05,
      "loss": 0.6655,
      "step": 639100
    },
    {
      "epoch": 6.766288554475151,
      "grad_norm": 4.107616901397705,
      "learning_rate": 1.6182934575481686e-05,
      "loss": 0.6747,
      "step": 639150
    },
    {
      "epoch": 6.766817876255154,
      "grad_norm": 4.2394795417785645,
      "learning_rate": 1.6180287952572517e-05,
      "loss": 0.6558,
      "step": 639200
    },
    {
      "epoch": 6.767347198035157,
      "grad_norm": 4.544135570526123,
      "learning_rate": 1.617764132966335e-05,
      "loss": 0.6608,
      "step": 639250
    },
    {
      "epoch": 6.767876519815161,
      "grad_norm": 4.485654354095459,
      "learning_rate": 1.617499470675418e-05,
      "loss": 0.6712,
      "step": 639300
    },
    {
      "epoch": 6.768405841595164,
      "grad_norm": 4.895658016204834,
      "learning_rate": 1.6172348083845016e-05,
      "loss": 0.6671,
      "step": 639350
    },
    {
      "epoch": 6.7689351633751675,
      "grad_norm": 4.213594913482666,
      "learning_rate": 1.6169701460935846e-05,
      "loss": 0.6813,
      "step": 639400
    },
    {
      "epoch": 6.76946448515517,
      "grad_norm": 4.589544773101807,
      "learning_rate": 1.616705483802668e-05,
      "loss": 0.6686,
      "step": 639450
    },
    {
      "epoch": 6.769993806935174,
      "grad_norm": 4.6714372634887695,
      "learning_rate": 1.616440821511751e-05,
      "loss": 0.6677,
      "step": 639500
    },
    {
      "epoch": 6.769993806935174,
      "eval_loss": 0.42022258043289185,
      "eval_runtime": 46.8755,
      "eval_samples_per_second": 3582.47,
      "eval_steps_per_second": 447.825,
      "step": 639500
    },
    {
      "epoch": 6.770523128715177,
      "grad_norm": 4.561277389526367,
      "learning_rate": 1.6161761592208345e-05,
      "loss": 0.6589,
      "step": 639550
    },
    {
      "epoch": 6.771052450495181,
      "grad_norm": 4.47689151763916,
      "learning_rate": 1.6159114969299176e-05,
      "loss": 0.6691,
      "step": 639600
    },
    {
      "epoch": 6.771581772275184,
      "grad_norm": 4.147237300872803,
      "learning_rate": 1.6156468346390007e-05,
      "loss": 0.6699,
      "step": 639650
    },
    {
      "epoch": 6.772111094055187,
      "grad_norm": 4.460827827453613,
      "learning_rate": 1.6153821723480837e-05,
      "loss": 0.6668,
      "step": 639700
    },
    {
      "epoch": 6.77264041583519,
      "grad_norm": 4.66478157043457,
      "learning_rate": 1.615117510057167e-05,
      "loss": 0.6643,
      "step": 639750
    },
    {
      "epoch": 6.773169737615194,
      "grad_norm": 4.137383460998535,
      "learning_rate": 1.6148528477662502e-05,
      "loss": 0.6669,
      "step": 639800
    },
    {
      "epoch": 6.773699059395197,
      "grad_norm": 3.995913028717041,
      "learning_rate": 1.6145881854753336e-05,
      "loss": 0.6753,
      "step": 639850
    },
    {
      "epoch": 6.774228381175201,
      "grad_norm": 4.637172222137451,
      "learning_rate": 1.6143235231844167e-05,
      "loss": 0.6626,
      "step": 639900
    },
    {
      "epoch": 6.7747577029552035,
      "grad_norm": 4.1905059814453125,
      "learning_rate": 1.6140588608935e-05,
      "loss": 0.6754,
      "step": 639950
    },
    {
      "epoch": 6.775287024735206,
      "grad_norm": 4.868559837341309,
      "learning_rate": 1.6137941986025832e-05,
      "loss": 0.6728,
      "step": 640000
    },
    {
      "epoch": 6.775287024735206,
      "eval_loss": 0.41973742842674255,
      "eval_runtime": 46.9565,
      "eval_samples_per_second": 3576.287,
      "eval_steps_per_second": 447.052,
      "step": 640000
    },
    {
      "epoch": 6.77581634651521,
      "grad_norm": 4.971223831176758,
      "learning_rate": 1.6135295363116666e-05,
      "loss": 0.6615,
      "step": 640050
    },
    {
      "epoch": 6.776345668295213,
      "grad_norm": 4.296589374542236,
      "learning_rate": 1.6132701672665677e-05,
      "loss": 0.6773,
      "step": 640100
    },
    {
      "epoch": 6.776874990075217,
      "grad_norm": 4.416090488433838,
      "learning_rate": 1.613005504975651e-05,
      "loss": 0.6674,
      "step": 640150
    },
    {
      "epoch": 6.77740431185522,
      "grad_norm": 4.693325042724609,
      "learning_rate": 1.6127408426847342e-05,
      "loss": 0.6788,
      "step": 640200
    },
    {
      "epoch": 6.777933633635223,
      "grad_norm": 5.167465686798096,
      "learning_rate": 1.6124761803938176e-05,
      "loss": 0.6687,
      "step": 640250
    },
    {
      "epoch": 6.778462955415226,
      "grad_norm": 3.970454692840576,
      "learning_rate": 1.6122115181029007e-05,
      "loss": 0.6684,
      "step": 640300
    },
    {
      "epoch": 6.77899227719523,
      "grad_norm": 4.1842827796936035,
      "learning_rate": 1.611946855811984e-05,
      "loss": 0.6584,
      "step": 640350
    },
    {
      "epoch": 6.779521598975233,
      "grad_norm": 4.1897125244140625,
      "learning_rate": 1.611682193521067e-05,
      "loss": 0.6577,
      "step": 640400
    },
    {
      "epoch": 6.780050920755237,
      "grad_norm": 4.083592891693115,
      "learning_rate": 1.6114175312301506e-05,
      "loss": 0.6558,
      "step": 640450
    },
    {
      "epoch": 6.7805802425352395,
      "grad_norm": 4.125319004058838,
      "learning_rate": 1.6111528689392336e-05,
      "loss": 0.6751,
      "step": 640500
    },
    {
      "epoch": 6.7805802425352395,
      "eval_loss": 0.4205526113510132,
      "eval_runtime": 47.067,
      "eval_samples_per_second": 3567.89,
      "eval_steps_per_second": 446.002,
      "step": 640500
    },
    {
      "epoch": 6.781109564315243,
      "grad_norm": 4.111732006072998,
      "learning_rate": 1.610888206648317e-05,
      "loss": 0.6688,
      "step": 640550
    },
    {
      "epoch": 6.781638886095246,
      "grad_norm": 4.059098243713379,
      "learning_rate": 1.6106235443574e-05,
      "loss": 0.6619,
      "step": 640600
    },
    {
      "epoch": 6.78216820787525,
      "grad_norm": 5.008653163909912,
      "learning_rate": 1.6103588820664832e-05,
      "loss": 0.6725,
      "step": 640650
    },
    {
      "epoch": 6.782697529655253,
      "grad_norm": 4.035219669342041,
      "learning_rate": 1.6100942197755663e-05,
      "loss": 0.6737,
      "step": 640700
    },
    {
      "epoch": 6.783226851435256,
      "grad_norm": 4.141206741333008,
      "learning_rate": 1.6098295574846497e-05,
      "loss": 0.6711,
      "step": 640750
    },
    {
      "epoch": 6.783756173215259,
      "grad_norm": 4.64762544631958,
      "learning_rate": 1.6095648951937327e-05,
      "loss": 0.6654,
      "step": 640800
    },
    {
      "epoch": 6.784285494995262,
      "grad_norm": 4.300771236419678,
      "learning_rate": 1.609300232902816e-05,
      "loss": 0.6846,
      "step": 640850
    },
    {
      "epoch": 6.784814816775266,
      "grad_norm": 4.1363067626953125,
      "learning_rate": 1.6090355706118992e-05,
      "loss": 0.6745,
      "step": 640900
    },
    {
      "epoch": 6.785344138555269,
      "grad_norm": 4.032557010650635,
      "learning_rate": 1.6087709083209826e-05,
      "loss": 0.6653,
      "step": 640950
    },
    {
      "epoch": 6.785873460335273,
      "grad_norm": 4.729909420013428,
      "learning_rate": 1.6085062460300657e-05,
      "loss": 0.6735,
      "step": 641000
    },
    {
      "epoch": 6.785873460335273,
      "eval_loss": 0.4208521246910095,
      "eval_runtime": 46.9067,
      "eval_samples_per_second": 3580.082,
      "eval_steps_per_second": 447.526,
      "step": 641000
    },
    {
      "epoch": 6.7864027821152755,
      "grad_norm": 4.349292278289795,
      "learning_rate": 1.608241583739149e-05,
      "loss": 0.6735,
      "step": 641050
    },
    {
      "epoch": 6.786932103895279,
      "grad_norm": 4.816778659820557,
      "learning_rate": 1.6079769214482322e-05,
      "loss": 0.6739,
      "step": 641100
    },
    {
      "epoch": 6.787461425675282,
      "grad_norm": 4.133995056152344,
      "learning_rate": 1.6077122591573156e-05,
      "loss": 0.6713,
      "step": 641150
    },
    {
      "epoch": 6.787990747455286,
      "grad_norm": 4.468861103057861,
      "learning_rate": 1.6074475968663987e-05,
      "loss": 0.6551,
      "step": 641200
    },
    {
      "epoch": 6.788520069235289,
      "grad_norm": 4.570475101470947,
      "learning_rate": 1.6071829345754817e-05,
      "loss": 0.6667,
      "step": 641250
    },
    {
      "epoch": 6.7890493910152925,
      "grad_norm": 4.409806728363037,
      "learning_rate": 1.6069182722845648e-05,
      "loss": 0.6625,
      "step": 641300
    },
    {
      "epoch": 6.789578712795295,
      "grad_norm": 4.056258201599121,
      "learning_rate": 1.6066536099936482e-05,
      "loss": 0.6634,
      "step": 641350
    },
    {
      "epoch": 6.790108034575299,
      "grad_norm": 4.379859447479248,
      "learning_rate": 1.6063889477027313e-05,
      "loss": 0.6704,
      "step": 641400
    },
    {
      "epoch": 6.790637356355302,
      "grad_norm": 4.247596740722656,
      "learning_rate": 1.6061242854118147e-05,
      "loss": 0.6712,
      "step": 641450
    },
    {
      "epoch": 6.791166678135305,
      "grad_norm": 4.313307285308838,
      "learning_rate": 1.6058596231208978e-05,
      "loss": 0.6652,
      "step": 641500
    },
    {
      "epoch": 6.791166678135305,
      "eval_loss": 0.4201160967350006,
      "eval_runtime": 47.0807,
      "eval_samples_per_second": 3566.858,
      "eval_steps_per_second": 445.873,
      "step": 641500
    },
    {
      "epoch": 6.791695999915309,
      "grad_norm": 4.567313194274902,
      "learning_rate": 1.6055949608299812e-05,
      "loss": 0.6551,
      "step": 641550
    },
    {
      "epoch": 6.7922253216953115,
      "grad_norm": 4.008532524108887,
      "learning_rate": 1.6053302985390643e-05,
      "loss": 0.6599,
      "step": 641600
    },
    {
      "epoch": 6.792754643475315,
      "grad_norm": 4.466139793395996,
      "learning_rate": 1.6050656362481477e-05,
      "loss": 0.6568,
      "step": 641650
    },
    {
      "epoch": 6.793283965255318,
      "grad_norm": 4.307358264923096,
      "learning_rate": 1.6048009739572307e-05,
      "loss": 0.6601,
      "step": 641700
    },
    {
      "epoch": 6.793813287035322,
      "grad_norm": 4.064266681671143,
      "learning_rate": 1.6045363116663138e-05,
      "loss": 0.6774,
      "step": 641750
    },
    {
      "epoch": 6.794342608815325,
      "grad_norm": 4.493032932281494,
      "learning_rate": 1.604271649375397e-05,
      "loss": 0.6771,
      "step": 641800
    },
    {
      "epoch": 6.7948719305953285,
      "grad_norm": 4.2353010177612305,
      "learning_rate": 1.6040069870844803e-05,
      "loss": 0.6776,
      "step": 641850
    },
    {
      "epoch": 6.795401252375331,
      "grad_norm": 4.460848331451416,
      "learning_rate": 1.6037423247935634e-05,
      "loss": 0.6775,
      "step": 641900
    },
    {
      "epoch": 6.795930574155335,
      "grad_norm": 4.234647750854492,
      "learning_rate": 1.6034776625026468e-05,
      "loss": 0.6738,
      "step": 641950
    },
    {
      "epoch": 6.796459895935338,
      "grad_norm": 4.105515480041504,
      "learning_rate": 1.60321300021173e-05,
      "loss": 0.6702,
      "step": 642000
    },
    {
      "epoch": 6.796459895935338,
      "eval_loss": 0.4197135269641876,
      "eval_runtime": 47.0289,
      "eval_samples_per_second": 3570.786,
      "eval_steps_per_second": 446.364,
      "step": 642000
    },
    {
      "epoch": 6.796989217715342,
      "grad_norm": 4.527700424194336,
      "learning_rate": 1.6029483379208132e-05,
      "loss": 0.6699,
      "step": 642050
    },
    {
      "epoch": 6.797518539495345,
      "grad_norm": 4.260315895080566,
      "learning_rate": 1.6026889688757147e-05,
      "loss": 0.6755,
      "step": 642100
    },
    {
      "epoch": 6.798047861275348,
      "grad_norm": 4.597041606903076,
      "learning_rate": 1.602424306584798e-05,
      "loss": 0.665,
      "step": 642150
    },
    {
      "epoch": 6.798577183055351,
      "grad_norm": 4.671072483062744,
      "learning_rate": 1.6021596442938812e-05,
      "loss": 0.6748,
      "step": 642200
    },
    {
      "epoch": 6.799106504835354,
      "grad_norm": 4.471102237701416,
      "learning_rate": 1.6018949820029643e-05,
      "loss": 0.6792,
      "step": 642250
    },
    {
      "epoch": 6.799635826615358,
      "grad_norm": 3.8375766277313232,
      "learning_rate": 1.6016303197120473e-05,
      "loss": 0.6607,
      "step": 642300
    },
    {
      "epoch": 6.800165148395361,
      "grad_norm": 4.084125518798828,
      "learning_rate": 1.6013656574211308e-05,
      "loss": 0.6624,
      "step": 642350
    },
    {
      "epoch": 6.800694470175364,
      "grad_norm": 4.31701135635376,
      "learning_rate": 1.6011009951302138e-05,
      "loss": 0.6692,
      "step": 642400
    },
    {
      "epoch": 6.801223791955367,
      "grad_norm": 4.220941543579102,
      "learning_rate": 1.6008363328392972e-05,
      "loss": 0.6606,
      "step": 642450
    },
    {
      "epoch": 6.801753113735371,
      "grad_norm": 4.858388423919678,
      "learning_rate": 1.6005716705483803e-05,
      "loss": 0.658,
      "step": 642500
    },
    {
      "epoch": 6.801753113735371,
      "eval_loss": 0.42066648602485657,
      "eval_runtime": 46.8886,
      "eval_samples_per_second": 3581.47,
      "eval_steps_per_second": 447.7,
      "step": 642500
    },
    {
      "epoch": 6.802282435515374,
      "grad_norm": 4.4210686683654785,
      "learning_rate": 1.6003070082574637e-05,
      "loss": 0.6596,
      "step": 642550
    },
    {
      "epoch": 6.802811757295378,
      "grad_norm": 4.728056907653809,
      "learning_rate": 1.6000423459665468e-05,
      "loss": 0.671,
      "step": 642600
    },
    {
      "epoch": 6.8033410790753805,
      "grad_norm": 4.842495918273926,
      "learning_rate": 1.5997776836756302e-05,
      "loss": 0.6689,
      "step": 642650
    },
    {
      "epoch": 6.803870400855384,
      "grad_norm": 4.440636157989502,
      "learning_rate": 1.5995130213847133e-05,
      "loss": 0.6709,
      "step": 642700
    },
    {
      "epoch": 6.804399722635387,
      "grad_norm": 4.4399590492248535,
      "learning_rate": 1.5992483590937963e-05,
      "loss": 0.6717,
      "step": 642750
    },
    {
      "epoch": 6.804929044415391,
      "grad_norm": 4.3726630210876465,
      "learning_rate": 1.5989836968028794e-05,
      "loss": 0.6686,
      "step": 642800
    },
    {
      "epoch": 6.805458366195394,
      "grad_norm": 4.730610370635986,
      "learning_rate": 1.5987190345119628e-05,
      "loss": 0.6758,
      "step": 642850
    },
    {
      "epoch": 6.8059876879753975,
      "grad_norm": 4.181499481201172,
      "learning_rate": 1.598454372221046e-05,
      "loss": 0.6705,
      "step": 642900
    },
    {
      "epoch": 6.8065170097554,
      "grad_norm": 4.29874849319458,
      "learning_rate": 1.5981897099301293e-05,
      "loss": 0.6732,
      "step": 642950
    },
    {
      "epoch": 6.807046331535403,
      "grad_norm": 4.0376410484313965,
      "learning_rate": 1.5979250476392124e-05,
      "loss": 0.6692,
      "step": 643000
    },
    {
      "epoch": 6.807046331535403,
      "eval_loss": 0.41998234391212463,
      "eval_runtime": 47.2534,
      "eval_samples_per_second": 3553.818,
      "eval_steps_per_second": 444.243,
      "step": 643000
    },
    {
      "epoch": 6.807575653315407,
      "grad_norm": 4.3972907066345215,
      "learning_rate": 1.5976603853482958e-05,
      "loss": 0.6695,
      "step": 643050
    },
    {
      "epoch": 6.80810497509541,
      "grad_norm": 4.453420639038086,
      "learning_rate": 1.597395723057379e-05,
      "loss": 0.6756,
      "step": 643100
    },
    {
      "epoch": 6.808634296875414,
      "grad_norm": 4.614824295043945,
      "learning_rate": 1.5971310607664623e-05,
      "loss": 0.6696,
      "step": 643150
    },
    {
      "epoch": 6.8091636186554165,
      "grad_norm": 4.770098686218262,
      "learning_rate": 1.5968663984755453e-05,
      "loss": 0.6814,
      "step": 643200
    },
    {
      "epoch": 6.80969294043542,
      "grad_norm": 4.809608459472656,
      "learning_rate": 1.5966017361846287e-05,
      "loss": 0.6692,
      "step": 643250
    },
    {
      "epoch": 6.810222262215423,
      "grad_norm": 4.865185737609863,
      "learning_rate": 1.5963370738937118e-05,
      "loss": 0.6573,
      "step": 643300
    },
    {
      "epoch": 6.810751583995427,
      "grad_norm": 4.538218021392822,
      "learning_rate": 1.596072411602795e-05,
      "loss": 0.6652,
      "step": 643350
    },
    {
      "epoch": 6.81128090577543,
      "grad_norm": 4.807331562042236,
      "learning_rate": 1.595807749311878e-05,
      "loss": 0.6584,
      "step": 643400
    },
    {
      "epoch": 6.8118102275554335,
      "grad_norm": 4.57269287109375,
      "learning_rate": 1.5955430870209614e-05,
      "loss": 0.6718,
      "step": 643450
    },
    {
      "epoch": 6.812339549335436,
      "grad_norm": 4.631631851196289,
      "learning_rate": 1.5952784247300444e-05,
      "loss": 0.6677,
      "step": 643500
    },
    {
      "epoch": 6.812339549335436,
      "eval_loss": 0.4197346866130829,
      "eval_runtime": 47.2863,
      "eval_samples_per_second": 3551.344,
      "eval_steps_per_second": 443.934,
      "step": 643500
    },
    {
      "epoch": 6.81286887111544,
      "grad_norm": 4.6284966468811035,
      "learning_rate": 1.595013762439128e-05,
      "loss": 0.6749,
      "step": 643550
    },
    {
      "epoch": 6.813398192895443,
      "grad_norm": 4.480973243713379,
      "learning_rate": 1.594749100148211e-05,
      "loss": 0.672,
      "step": 643600
    },
    {
      "epoch": 6.813927514675447,
      "grad_norm": 4.645829200744629,
      "learning_rate": 1.5944897311031127e-05,
      "loss": 0.662,
      "step": 643650
    },
    {
      "epoch": 6.81445683645545,
      "grad_norm": 4.699584007263184,
      "learning_rate": 1.5942250688121958e-05,
      "loss": 0.6656,
      "step": 643700
    },
    {
      "epoch": 6.8149861582354525,
      "grad_norm": 3.6025803089141846,
      "learning_rate": 1.593960406521279e-05,
      "loss": 0.6717,
      "step": 643750
    },
    {
      "epoch": 6.815515480015456,
      "grad_norm": 4.528472900390625,
      "learning_rate": 1.593695744230362e-05,
      "loss": 0.6648,
      "step": 643800
    },
    {
      "epoch": 6.816044801795459,
      "grad_norm": 4.263953685760498,
      "learning_rate": 1.5934310819394454e-05,
      "loss": 0.6731,
      "step": 643850
    },
    {
      "epoch": 6.816574123575463,
      "grad_norm": 3.9216651916503906,
      "learning_rate": 1.5931664196485284e-05,
      "loss": 0.6693,
      "step": 643900
    },
    {
      "epoch": 6.817103445355466,
      "grad_norm": 4.540822982788086,
      "learning_rate": 1.592901757357612e-05,
      "loss": 0.6766,
      "step": 643950
    },
    {
      "epoch": 6.8176327671354695,
      "grad_norm": 4.400981426239014,
      "learning_rate": 1.592637095066695e-05,
      "loss": 0.6706,
      "step": 644000
    },
    {
      "epoch": 6.8176327671354695,
      "eval_loss": 0.41849663853645325,
      "eval_runtime": 47.646,
      "eval_samples_per_second": 3524.534,
      "eval_steps_per_second": 440.583,
      "step": 644000
    },
    {
      "epoch": 6.818162088915472,
      "grad_norm": 4.511373519897461,
      "learning_rate": 1.5923724327757783e-05,
      "loss": 0.6749,
      "step": 644050
    },
    {
      "epoch": 6.818691410695476,
      "grad_norm": 4.511481761932373,
      "learning_rate": 1.5921077704848614e-05,
      "loss": 0.6605,
      "step": 644100
    },
    {
      "epoch": 6.819220732475479,
      "grad_norm": 4.389037132263184,
      "learning_rate": 1.5918431081939448e-05,
      "loss": 0.6768,
      "step": 644150
    },
    {
      "epoch": 6.819750054255483,
      "grad_norm": 4.5908589363098145,
      "learning_rate": 1.591578445903028e-05,
      "loss": 0.6701,
      "step": 644200
    },
    {
      "epoch": 6.820279376035486,
      "grad_norm": 4.4972357749938965,
      "learning_rate": 1.5913137836121113e-05,
      "loss": 0.6551,
      "step": 644250
    },
    {
      "epoch": 6.820808697815489,
      "grad_norm": 4.45552396774292,
      "learning_rate": 1.5910491213211943e-05,
      "loss": 0.67,
      "step": 644300
    },
    {
      "epoch": 6.821338019595492,
      "grad_norm": 4.324410438537598,
      "learning_rate": 1.5907844590302774e-05,
      "loss": 0.6737,
      "step": 644350
    },
    {
      "epoch": 6.821867341375496,
      "grad_norm": 4.87794828414917,
      "learning_rate": 1.5905197967393605e-05,
      "loss": 0.6755,
      "step": 644400
    },
    {
      "epoch": 6.822396663155499,
      "grad_norm": 4.529435634613037,
      "learning_rate": 1.590255134448444e-05,
      "loss": 0.671,
      "step": 644450
    },
    {
      "epoch": 6.822925984935502,
      "grad_norm": 4.592085838317871,
      "learning_rate": 1.589990472157527e-05,
      "loss": 0.6613,
      "step": 644500
    },
    {
      "epoch": 6.822925984935502,
      "eval_loss": 0.41903337836265564,
      "eval_runtime": 46.9743,
      "eval_samples_per_second": 3574.932,
      "eval_steps_per_second": 446.882,
      "step": 644500
    },
    {
      "epoch": 6.8234553067155055,
      "grad_norm": 4.608151912689209,
      "learning_rate": 1.5897258098666104e-05,
      "loss": 0.6617,
      "step": 644550
    },
    {
      "epoch": 6.823984628495508,
      "grad_norm": 4.320797920227051,
      "learning_rate": 1.5894611475756935e-05,
      "loss": 0.6611,
      "step": 644600
    },
    {
      "epoch": 6.824513950275512,
      "grad_norm": 4.388764381408691,
      "learning_rate": 1.589196485284777e-05,
      "loss": 0.6708,
      "step": 644650
    },
    {
      "epoch": 6.825043272055515,
      "grad_norm": 4.672486782073975,
      "learning_rate": 1.58893182299386e-05,
      "loss": 0.6548,
      "step": 644700
    },
    {
      "epoch": 6.825572593835519,
      "grad_norm": 4.414023399353027,
      "learning_rate": 1.5886671607029433e-05,
      "loss": 0.6665,
      "step": 644750
    },
    {
      "epoch": 6.826101915615522,
      "grad_norm": 4.551167964935303,
      "learning_rate": 1.5884024984120264e-05,
      "loss": 0.6684,
      "step": 644800
    },
    {
      "epoch": 6.826631237395525,
      "grad_norm": 4.33222770690918,
      "learning_rate": 1.5881378361211098e-05,
      "loss": 0.6641,
      "step": 644850
    },
    {
      "epoch": 6.827160559175528,
      "grad_norm": 4.165317058563232,
      "learning_rate": 1.587873173830193e-05,
      "loss": 0.6657,
      "step": 644900
    },
    {
      "epoch": 6.827689880955532,
      "grad_norm": 4.342216968536377,
      "learning_rate": 1.587608511539276e-05,
      "loss": 0.6677,
      "step": 644950
    },
    {
      "epoch": 6.828219202735535,
      "grad_norm": 4.758943557739258,
      "learning_rate": 1.587343849248359e-05,
      "loss": 0.6699,
      "step": 645000
    },
    {
      "epoch": 6.828219202735535,
      "eval_loss": 0.4186633229255676,
      "eval_runtime": 46.7383,
      "eval_samples_per_second": 3592.984,
      "eval_steps_per_second": 449.139,
      "step": 645000
    },
    {
      "epoch": 6.828748524515539,
      "grad_norm": 4.272646903991699,
      "learning_rate": 1.5870791869574424e-05,
      "loss": 0.6791,
      "step": 645050
    },
    {
      "epoch": 6.8292778462955415,
      "grad_norm": 4.767151355743408,
      "learning_rate": 1.5868145246665255e-05,
      "loss": 0.6749,
      "step": 645100
    },
    {
      "epoch": 6.829807168075545,
      "grad_norm": 4.332924842834473,
      "learning_rate": 1.586549862375609e-05,
      "loss": 0.6635,
      "step": 645150
    },
    {
      "epoch": 6.830336489855548,
      "grad_norm": 4.3897552490234375,
      "learning_rate": 1.586285200084692e-05,
      "loss": 0.669,
      "step": 645200
    },
    {
      "epoch": 6.830865811635551,
      "grad_norm": 4.233806133270264,
      "learning_rate": 1.5860205377937754e-05,
      "loss": 0.6803,
      "step": 645250
    },
    {
      "epoch": 6.831395133415555,
      "grad_norm": 4.504662036895752,
      "learning_rate": 1.5857558755028585e-05,
      "loss": 0.665,
      "step": 645300
    },
    {
      "epoch": 6.831924455195558,
      "grad_norm": 4.093145847320557,
      "learning_rate": 1.585491213211942e-05,
      "loss": 0.6668,
      "step": 645350
    },
    {
      "epoch": 6.832453776975561,
      "grad_norm": 4.92933988571167,
      "learning_rate": 1.585226550921025e-05,
      "loss": 0.67,
      "step": 645400
    },
    {
      "epoch": 6.832983098755564,
      "grad_norm": 4.502439498901367,
      "learning_rate": 1.584961888630108e-05,
      "loss": 0.6816,
      "step": 645450
    },
    {
      "epoch": 6.833512420535568,
      "grad_norm": 3.9964687824249268,
      "learning_rate": 1.584697226339191e-05,
      "loss": 0.6644,
      "step": 645500
    },
    {
      "epoch": 6.833512420535568,
      "eval_loss": 0.4190342128276825,
      "eval_runtime": 46.8883,
      "eval_samples_per_second": 3581.494,
      "eval_steps_per_second": 447.703,
      "step": 645500
    },
    {
      "epoch": 6.834041742315571,
      "grad_norm": 4.182729244232178,
      "learning_rate": 1.5844325640482745e-05,
      "loss": 0.6737,
      "step": 645550
    },
    {
      "epoch": 6.834571064095575,
      "grad_norm": 4.3419013023376465,
      "learning_rate": 1.5841679017573576e-05,
      "loss": 0.6595,
      "step": 645600
    },
    {
      "epoch": 6.8351003858755774,
      "grad_norm": 4.412703037261963,
      "learning_rate": 1.583903239466441e-05,
      "loss": 0.6716,
      "step": 645650
    },
    {
      "epoch": 6.835629707655581,
      "grad_norm": 4.489414691925049,
      "learning_rate": 1.583638577175524e-05,
      "loss": 0.6587,
      "step": 645700
    },
    {
      "epoch": 6.836159029435584,
      "grad_norm": 4.598642349243164,
      "learning_rate": 1.583373914884607e-05,
      "loss": 0.6739,
      "step": 645750
    },
    {
      "epoch": 6.836688351215588,
      "grad_norm": 4.537779331207275,
      "learning_rate": 1.5831092525936905e-05,
      "loss": 0.663,
      "step": 645800
    },
    {
      "epoch": 6.837217672995591,
      "grad_norm": 4.312497138977051,
      "learning_rate": 1.5828445903027736e-05,
      "loss": 0.6605,
      "step": 645850
    },
    {
      "epoch": 6.8377469947755944,
      "grad_norm": 4.68958854675293,
      "learning_rate": 1.582579928011857e-05,
      "loss": 0.6669,
      "step": 645900
    },
    {
      "epoch": 6.838276316555597,
      "grad_norm": 4.494724750518799,
      "learning_rate": 1.58231526572094e-05,
      "loss": 0.6729,
      "step": 645950
    },
    {
      "epoch": 6.8388056383356,
      "grad_norm": 4.3937764167785645,
      "learning_rate": 1.5820506034300235e-05,
      "loss": 0.6626,
      "step": 646000
    },
    {
      "epoch": 6.8388056383356,
      "eval_loss": 0.41877707839012146,
      "eval_runtime": 47.4246,
      "eval_samples_per_second": 3540.987,
      "eval_steps_per_second": 442.639,
      "step": 646000
    },
    {
      "epoch": 6.839334960115604,
      "grad_norm": 4.387901782989502,
      "learning_rate": 1.5817859411391066e-05,
      "loss": 0.6737,
      "step": 646050
    },
    {
      "epoch": 6.839864281895607,
      "grad_norm": 4.492458820343018,
      "learning_rate": 1.5815212788481897e-05,
      "loss": 0.6779,
      "step": 646100
    },
    {
      "epoch": 6.840393603675611,
      "grad_norm": 4.134439945220947,
      "learning_rate": 1.5812566165572727e-05,
      "loss": 0.6652,
      "step": 646150
    },
    {
      "epoch": 6.840922925455613,
      "grad_norm": 4.6105499267578125,
      "learning_rate": 1.580991954266356e-05,
      "loss": 0.672,
      "step": 646200
    },
    {
      "epoch": 6.841452247235617,
      "grad_norm": 4.9279985427856445,
      "learning_rate": 1.5807272919754392e-05,
      "loss": 0.6784,
      "step": 646250
    },
    {
      "epoch": 6.84198156901562,
      "grad_norm": 4.721018314361572,
      "learning_rate": 1.5804626296845226e-05,
      "loss": 0.6555,
      "step": 646300
    },
    {
      "epoch": 6.842510890795624,
      "grad_norm": 4.345307350158691,
      "learning_rate": 1.5801979673936057e-05,
      "loss": 0.6768,
      "step": 646350
    },
    {
      "epoch": 6.843040212575627,
      "grad_norm": 4.427140712738037,
      "learning_rate": 1.579933305102689e-05,
      "loss": 0.6669,
      "step": 646400
    },
    {
      "epoch": 6.84356953435563,
      "grad_norm": 4.651461124420166,
      "learning_rate": 1.579668642811772e-05,
      "loss": 0.6715,
      "step": 646450
    },
    {
      "epoch": 6.844098856135633,
      "grad_norm": 4.338451862335205,
      "learning_rate": 1.5794039805208556e-05,
      "loss": 0.6659,
      "step": 646500
    },
    {
      "epoch": 6.844098856135633,
      "eval_loss": 0.41954153776168823,
      "eval_runtime": 47.3544,
      "eval_samples_per_second": 3546.239,
      "eval_steps_per_second": 443.296,
      "step": 646500
    },
    {
      "epoch": 6.844628177915637,
      "grad_norm": 4.641823768615723,
      "learning_rate": 1.5791393182299387e-05,
      "loss": 0.6657,
      "step": 646550
    },
    {
      "epoch": 6.84515749969564,
      "grad_norm": 4.5640058517456055,
      "learning_rate": 1.578874655939022e-05,
      "loss": 0.6745,
      "step": 646600
    },
    {
      "epoch": 6.845686821475644,
      "grad_norm": 4.668061256408691,
      "learning_rate": 1.578609993648105e-05,
      "loss": 0.672,
      "step": 646650
    },
    {
      "epoch": 6.8462161432556465,
      "grad_norm": 4.686464309692383,
      "learning_rate": 1.5783453313571882e-05,
      "loss": 0.6675,
      "step": 646700
    },
    {
      "epoch": 6.846745465035649,
      "grad_norm": 4.4492926597595215,
      "learning_rate": 1.5780806690662713e-05,
      "loss": 0.6677,
      "step": 646750
    },
    {
      "epoch": 6.847274786815653,
      "grad_norm": 4.591381072998047,
      "learning_rate": 1.5778160067753547e-05,
      "loss": 0.6674,
      "step": 646800
    },
    {
      "epoch": 6.847804108595656,
      "grad_norm": 4.448659896850586,
      "learning_rate": 1.5775513444844378e-05,
      "loss": 0.6699,
      "step": 646850
    },
    {
      "epoch": 6.84833343037566,
      "grad_norm": 3.9345812797546387,
      "learning_rate": 1.577286682193521e-05,
      "loss": 0.6714,
      "step": 646900
    },
    {
      "epoch": 6.848862752155663,
      "grad_norm": 4.712343215942383,
      "learning_rate": 1.5770220199026042e-05,
      "loss": 0.6655,
      "step": 646950
    },
    {
      "epoch": 6.849392073935666,
      "grad_norm": 4.430892467498779,
      "learning_rate": 1.5767573576116876e-05,
      "loss": 0.66,
      "step": 647000
    },
    {
      "epoch": 6.849392073935666,
      "eval_loss": 0.4176008403301239,
      "eval_runtime": 47.0043,
      "eval_samples_per_second": 3572.651,
      "eval_steps_per_second": 446.597,
      "step": 647000
    },
    {
      "epoch": 6.849921395715669,
      "grad_norm": 4.34460973739624,
      "learning_rate": 1.5764926953207707e-05,
      "loss": 0.6644,
      "step": 647050
    },
    {
      "epoch": 6.850450717495673,
      "grad_norm": 4.599803447723389,
      "learning_rate": 1.576228033029854e-05,
      "loss": 0.6656,
      "step": 647100
    },
    {
      "epoch": 6.850980039275676,
      "grad_norm": 4.421070098876953,
      "learning_rate": 1.5759633707389372e-05,
      "loss": 0.6568,
      "step": 647150
    },
    {
      "epoch": 6.85150936105568,
      "grad_norm": 4.35795259475708,
      "learning_rate": 1.5756987084480203e-05,
      "loss": 0.6737,
      "step": 647200
    },
    {
      "epoch": 6.8520386828356825,
      "grad_norm": 4.52394437789917,
      "learning_rate": 1.5754340461571033e-05,
      "loss": 0.6675,
      "step": 647250
    },
    {
      "epoch": 6.852568004615686,
      "grad_norm": 4.693901062011719,
      "learning_rate": 1.5751693838661868e-05,
      "loss": 0.6632,
      "step": 647300
    },
    {
      "epoch": 6.853097326395689,
      "grad_norm": 4.7928948402404785,
      "learning_rate": 1.5749047215752698e-05,
      "loss": 0.6593,
      "step": 647350
    },
    {
      "epoch": 6.853626648175693,
      "grad_norm": 4.392481327056885,
      "learning_rate": 1.5746400592843532e-05,
      "loss": 0.6664,
      "step": 647400
    },
    {
      "epoch": 6.854155969955696,
      "grad_norm": 4.4884185791015625,
      "learning_rate": 1.5743753969934363e-05,
      "loss": 0.6631,
      "step": 647450
    },
    {
      "epoch": 6.854685291735699,
      "grad_norm": 4.348046779632568,
      "learning_rate": 1.5741107347025197e-05,
      "loss": 0.6645,
      "step": 647500
    },
    {
      "epoch": 6.854685291735699,
      "eval_loss": 0.4174509644508362,
      "eval_runtime": 46.8901,
      "eval_samples_per_second": 3581.352,
      "eval_steps_per_second": 447.685,
      "step": 647500
    },
    {
      "epoch": 6.855214613515702,
      "grad_norm": 4.703466892242432,
      "learning_rate": 1.5738460724116028e-05,
      "loss": 0.6744,
      "step": 647550
    },
    {
      "epoch": 6.855743935295705,
      "grad_norm": 4.340664863586426,
      "learning_rate": 1.5735814101206862e-05,
      "loss": 0.6649,
      "step": 647600
    },
    {
      "epoch": 6.856273257075709,
      "grad_norm": 4.237589359283447,
      "learning_rate": 1.5733220410755877e-05,
      "loss": 0.665,
      "step": 647650
    },
    {
      "epoch": 6.856802578855712,
      "grad_norm": 4.353917598724365,
      "learning_rate": 1.5730573787846707e-05,
      "loss": 0.6788,
      "step": 647700
    },
    {
      "epoch": 6.857331900635716,
      "grad_norm": 4.505311965942383,
      "learning_rate": 1.5727927164937538e-05,
      "loss": 0.6649,
      "step": 647750
    },
    {
      "epoch": 6.8578612224157185,
      "grad_norm": 4.550164222717285,
      "learning_rate": 1.5725280542028372e-05,
      "loss": 0.6547,
      "step": 647800
    },
    {
      "epoch": 6.858390544195722,
      "grad_norm": 4.355220317840576,
      "learning_rate": 1.5722633919119203e-05,
      "loss": 0.6785,
      "step": 647850
    },
    {
      "epoch": 6.858919865975725,
      "grad_norm": 4.403985023498535,
      "learning_rate": 1.5719987296210037e-05,
      "loss": 0.6636,
      "step": 647900
    },
    {
      "epoch": 6.859449187755729,
      "grad_norm": 4.422347068786621,
      "learning_rate": 1.5717340673300868e-05,
      "loss": 0.6774,
      "step": 647950
    },
    {
      "epoch": 6.859978509535732,
      "grad_norm": 4.5748610496521,
      "learning_rate": 1.5714694050391702e-05,
      "loss": 0.6701,
      "step": 648000
    },
    {
      "epoch": 6.859978509535732,
      "eval_loss": 0.4189848005771637,
      "eval_runtime": 46.7309,
      "eval_samples_per_second": 3593.554,
      "eval_steps_per_second": 449.21,
      "step": 648000
    },
    {
      "epoch": 6.8605078313157355,
      "grad_norm": 4.583884239196777,
      "learning_rate": 1.5712100359940717e-05,
      "loss": 0.6656,
      "step": 648050
    },
    {
      "epoch": 6.861037153095738,
      "grad_norm": 4.350285053253174,
      "learning_rate": 1.5709453737031547e-05,
      "loss": 0.6788,
      "step": 648100
    },
    {
      "epoch": 6.861566474875742,
      "grad_norm": 4.442902088165283,
      "learning_rate": 1.5706807114122378e-05,
      "loss": 0.6646,
      "step": 648150
    },
    {
      "epoch": 6.862095796655745,
      "grad_norm": 4.450887203216553,
      "learning_rate": 1.5704160491213212e-05,
      "loss": 0.6755,
      "step": 648200
    },
    {
      "epoch": 6.862625118435748,
      "grad_norm": 4.679563522338867,
      "learning_rate": 1.5701513868304043e-05,
      "loss": 0.6665,
      "step": 648250
    },
    {
      "epoch": 6.863154440215752,
      "grad_norm": 4.416076183319092,
      "learning_rate": 1.5698867245394877e-05,
      "loss": 0.6609,
      "step": 648300
    },
    {
      "epoch": 6.8636837619957545,
      "grad_norm": 4.491176128387451,
      "learning_rate": 1.5696220622485708e-05,
      "loss": 0.6697,
      "step": 648350
    },
    {
      "epoch": 6.864213083775758,
      "grad_norm": 4.081700801849365,
      "learning_rate": 1.569357399957654e-05,
      "loss": 0.6615,
      "step": 648400
    },
    {
      "epoch": 6.864742405555761,
      "grad_norm": 4.208892822265625,
      "learning_rate": 1.5690927376667372e-05,
      "loss": 0.6639,
      "step": 648450
    },
    {
      "epoch": 6.865271727335765,
      "grad_norm": 4.627597332000732,
      "learning_rate": 1.5688280753758206e-05,
      "loss": 0.6639,
      "step": 648500
    },
    {
      "epoch": 6.865271727335765,
      "eval_loss": 0.41848883032798767,
      "eval_runtime": 46.7098,
      "eval_samples_per_second": 3595.176,
      "eval_steps_per_second": 449.413,
      "step": 648500
    },
    {
      "epoch": 6.865801049115768,
      "grad_norm": 4.243861198425293,
      "learning_rate": 1.5685634130849037e-05,
      "loss": 0.6626,
      "step": 648550
    },
    {
      "epoch": 6.8663303708957715,
      "grad_norm": 4.531445503234863,
      "learning_rate": 1.568298750793987e-05,
      "loss": 0.6695,
      "step": 648600
    },
    {
      "epoch": 6.866859692675774,
      "grad_norm": 4.534975528717041,
      "learning_rate": 1.5680340885030702e-05,
      "loss": 0.6683,
      "step": 648650
    },
    {
      "epoch": 6.867389014455778,
      "grad_norm": 4.538872241973877,
      "learning_rate": 1.5677694262121533e-05,
      "loss": 0.6712,
      "step": 648700
    },
    {
      "epoch": 6.867918336235781,
      "grad_norm": 4.48564338684082,
      "learning_rate": 1.5675047639212363e-05,
      "loss": 0.6565,
      "step": 648750
    },
    {
      "epoch": 6.868447658015785,
      "grad_norm": 4.494284152984619,
      "learning_rate": 1.5672401016303198e-05,
      "loss": 0.6748,
      "step": 648800
    },
    {
      "epoch": 6.868976979795788,
      "grad_norm": 4.248690605163574,
      "learning_rate": 1.5669754393394028e-05,
      "loss": 0.6685,
      "step": 648850
    },
    {
      "epoch": 6.869506301575791,
      "grad_norm": 3.881513833999634,
      "learning_rate": 1.5667107770484862e-05,
      "loss": 0.6581,
      "step": 648900
    },
    {
      "epoch": 6.870035623355794,
      "grad_norm": 4.602941513061523,
      "learning_rate": 1.5664461147575693e-05,
      "loss": 0.6665,
      "step": 648950
    },
    {
      "epoch": 6.870564945135797,
      "grad_norm": 4.777841567993164,
      "learning_rate": 1.5661814524666527e-05,
      "loss": 0.668,
      "step": 649000
    },
    {
      "epoch": 6.870564945135797,
      "eval_loss": 0.4185125529766083,
      "eval_runtime": 47.1467,
      "eval_samples_per_second": 3561.859,
      "eval_steps_per_second": 445.248,
      "step": 649000
    },
    {
      "epoch": 6.871094266915801,
      "grad_norm": 4.379558086395264,
      "learning_rate": 1.5659167901757358e-05,
      "loss": 0.6587,
      "step": 649050
    },
    {
      "epoch": 6.871623588695804,
      "grad_norm": 4.373086929321289,
      "learning_rate": 1.5656521278848192e-05,
      "loss": 0.6671,
      "step": 649100
    },
    {
      "epoch": 6.8721529104758075,
      "grad_norm": 4.107865333557129,
      "learning_rate": 1.5653874655939023e-05,
      "loss": 0.6687,
      "step": 649150
    },
    {
      "epoch": 6.87268223225581,
      "grad_norm": 4.405172348022461,
      "learning_rate": 1.5651228033029853e-05,
      "loss": 0.6721,
      "step": 649200
    },
    {
      "epoch": 6.873211554035814,
      "grad_norm": 4.598385810852051,
      "learning_rate": 1.5648581410120684e-05,
      "loss": 0.68,
      "step": 649250
    },
    {
      "epoch": 6.873740875815817,
      "grad_norm": 4.727746963500977,
      "learning_rate": 1.5645934787211518e-05,
      "loss": 0.6622,
      "step": 649300
    },
    {
      "epoch": 6.874270197595821,
      "grad_norm": 4.33500337600708,
      "learning_rate": 1.564328816430235e-05,
      "loss": 0.6576,
      "step": 649350
    },
    {
      "epoch": 6.874799519375824,
      "grad_norm": 4.39467716217041,
      "learning_rate": 1.5640641541393183e-05,
      "loss": 0.6763,
      "step": 649400
    },
    {
      "epoch": 6.875328841155827,
      "grad_norm": 4.38625431060791,
      "learning_rate": 1.5637994918484014e-05,
      "loss": 0.6697,
      "step": 649450
    },
    {
      "epoch": 6.87585816293583,
      "grad_norm": 4.458857536315918,
      "learning_rate": 1.5635348295574848e-05,
      "loss": 0.6578,
      "step": 649500
    },
    {
      "epoch": 6.87585816293583,
      "eval_loss": 0.4171655476093292,
      "eval_runtime": 46.5991,
      "eval_samples_per_second": 3603.718,
      "eval_steps_per_second": 450.481,
      "step": 649500
    },
    {
      "epoch": 6.876387484715834,
      "grad_norm": 4.228154182434082,
      "learning_rate": 1.563270167266568e-05,
      "loss": 0.6671,
      "step": 649550
    },
    {
      "epoch": 6.876916806495837,
      "grad_norm": 3.9627697467803955,
      "learning_rate": 1.5630055049756513e-05,
      "loss": 0.6732,
      "step": 649600
    },
    {
      "epoch": 6.877446128275841,
      "grad_norm": 4.330803394317627,
      "learning_rate": 1.5627408426847343e-05,
      "loss": 0.6656,
      "step": 649650
    },
    {
      "epoch": 6.877975450055843,
      "grad_norm": 4.442728519439697,
      "learning_rate": 1.5624761803938177e-05,
      "loss": 0.6614,
      "step": 649700
    },
    {
      "epoch": 6.878504771835846,
      "grad_norm": 4.486247539520264,
      "learning_rate": 1.5622115181029008e-05,
      "loss": 0.6531,
      "step": 649750
    },
    {
      "epoch": 6.87903409361585,
      "grad_norm": 4.627760410308838,
      "learning_rate": 1.561946855811984e-05,
      "loss": 0.676,
      "step": 649800
    },
    {
      "epoch": 6.879563415395853,
      "grad_norm": 4.010137557983398,
      "learning_rate": 1.561682193521067e-05,
      "loss": 0.6666,
      "step": 649850
    },
    {
      "epoch": 6.880092737175857,
      "grad_norm": 4.228805065155029,
      "learning_rate": 1.5614175312301504e-05,
      "loss": 0.6726,
      "step": 649900
    },
    {
      "epoch": 6.8806220589558595,
      "grad_norm": 4.243369102478027,
      "learning_rate": 1.5611528689392334e-05,
      "loss": 0.6741,
      "step": 649950
    },
    {
      "epoch": 6.881151380735863,
      "grad_norm": 4.391299724578857,
      "learning_rate": 1.560888206648317e-05,
      "loss": 0.6659,
      "step": 650000
    },
    {
      "epoch": 6.881151380735863,
      "eval_loss": 0.4193504750728607,
      "eval_runtime": 46.6313,
      "eval_samples_per_second": 3601.231,
      "eval_steps_per_second": 450.17,
      "step": 650000
    },
    {
      "epoch": 6.881680702515866,
      "grad_norm": 4.046365737915039,
      "learning_rate": 1.5606235443574e-05,
      "loss": 0.6508,
      "step": 650050
    },
    {
      "epoch": 6.88221002429587,
      "grad_norm": 4.5554890632629395,
      "learning_rate": 1.5603588820664833e-05,
      "loss": 0.6694,
      "step": 650100
    },
    {
      "epoch": 6.882739346075873,
      "grad_norm": 4.209767818450928,
      "learning_rate": 1.5600942197755664e-05,
      "loss": 0.663,
      "step": 650150
    },
    {
      "epoch": 6.8832686678558765,
      "grad_norm": 4.1893744468688965,
      "learning_rate": 1.5598295574846498e-05,
      "loss": 0.6622,
      "step": 650200
    },
    {
      "epoch": 6.883797989635879,
      "grad_norm": 4.309393405914307,
      "learning_rate": 1.559564895193733e-05,
      "loss": 0.6653,
      "step": 650250
    },
    {
      "epoch": 6.884327311415883,
      "grad_norm": 4.972891807556152,
      "learning_rate": 1.5593002329028163e-05,
      "loss": 0.6665,
      "step": 650300
    },
    {
      "epoch": 6.884856633195886,
      "grad_norm": 4.170446872711182,
      "learning_rate": 1.5590355706118994e-05,
      "loss": 0.6666,
      "step": 650350
    },
    {
      "epoch": 6.88538595497589,
      "grad_norm": 4.44247579574585,
      "learning_rate": 1.5587709083209824e-05,
      "loss": 0.662,
      "step": 650400
    },
    {
      "epoch": 6.885915276755893,
      "grad_norm": 4.565720558166504,
      "learning_rate": 1.5585062460300655e-05,
      "loss": 0.6591,
      "step": 650450
    },
    {
      "epoch": 6.8864445985358955,
      "grad_norm": 4.679498672485352,
      "learning_rate": 1.558241583739149e-05,
      "loss": 0.6687,
      "step": 650500
    },
    {
      "epoch": 6.8864445985358955,
      "eval_loss": 0.41683417558670044,
      "eval_runtime": 46.6541,
      "eval_samples_per_second": 3599.471,
      "eval_steps_per_second": 449.95,
      "step": 650500
    },
    {
      "epoch": 6.886973920315899,
      "grad_norm": 3.6106934547424316,
      "learning_rate": 1.557976921448232e-05,
      "loss": 0.6739,
      "step": 650550
    },
    {
      "epoch": 6.887503242095902,
      "grad_norm": 4.634680271148682,
      "learning_rate": 1.5577122591573154e-05,
      "loss": 0.6734,
      "step": 650600
    },
    {
      "epoch": 6.888032563875906,
      "grad_norm": 4.777363300323486,
      "learning_rate": 1.5574475968663985e-05,
      "loss": 0.6704,
      "step": 650650
    },
    {
      "epoch": 6.888561885655909,
      "grad_norm": 4.392799377441406,
      "learning_rate": 1.557182934575482e-05,
      "loss": 0.6588,
      "step": 650700
    },
    {
      "epoch": 6.8890912074359125,
      "grad_norm": 4.704184532165527,
      "learning_rate": 1.556918272284565e-05,
      "loss": 0.6628,
      "step": 650750
    },
    {
      "epoch": 6.889620529215915,
      "grad_norm": 4.3218889236450195,
      "learning_rate": 1.5566536099936484e-05,
      "loss": 0.6672,
      "step": 650800
    },
    {
      "epoch": 6.890149850995919,
      "grad_norm": 4.7601847648620605,
      "learning_rate": 1.5563889477027314e-05,
      "loss": 0.6832,
      "step": 650850
    },
    {
      "epoch": 6.890679172775922,
      "grad_norm": 4.332266807556152,
      "learning_rate": 1.5561242854118145e-05,
      "loss": 0.6664,
      "step": 650900
    },
    {
      "epoch": 6.891208494555926,
      "grad_norm": 4.30238151550293,
      "learning_rate": 1.5558596231208976e-05,
      "loss": 0.6682,
      "step": 650950
    },
    {
      "epoch": 6.891737816335929,
      "grad_norm": 4.384937286376953,
      "learning_rate": 1.555594960829981e-05,
      "loss": 0.6723,
      "step": 651000
    },
    {
      "epoch": 6.891737816335929,
      "eval_loss": 0.41816040873527527,
      "eval_runtime": 46.5951,
      "eval_samples_per_second": 3604.024,
      "eval_steps_per_second": 450.519,
      "step": 651000
    },
    {
      "epoch": 6.892267138115932,
      "grad_norm": 4.610049247741699,
      "learning_rate": 1.555330298539064e-05,
      "loss": 0.6771,
      "step": 651050
    },
    {
      "epoch": 6.892796459895935,
      "grad_norm": 3.9357755184173584,
      "learning_rate": 1.5550656362481475e-05,
      "loss": 0.6715,
      "step": 651100
    },
    {
      "epoch": 6.893325781675939,
      "grad_norm": 4.686400890350342,
      "learning_rate": 1.5548009739572305e-05,
      "loss": 0.6737,
      "step": 651150
    },
    {
      "epoch": 6.893855103455942,
      "grad_norm": 4.555178642272949,
      "learning_rate": 1.554536311666314e-05,
      "loss": 0.6642,
      "step": 651200
    },
    {
      "epoch": 6.894384425235945,
      "grad_norm": 4.484546184539795,
      "learning_rate": 1.554271649375397e-05,
      "loss": 0.6661,
      "step": 651250
    },
    {
      "epoch": 6.8949137470159485,
      "grad_norm": 4.409889221191406,
      "learning_rate": 1.5540069870844804e-05,
      "loss": 0.6612,
      "step": 651300
    },
    {
      "epoch": 6.895443068795951,
      "grad_norm": 4.298835277557373,
      "learning_rate": 1.5537423247935635e-05,
      "loss": 0.6746,
      "step": 651350
    },
    {
      "epoch": 6.895972390575955,
      "grad_norm": 4.177879810333252,
      "learning_rate": 1.553477662502647e-05,
      "loss": 0.6653,
      "step": 651400
    },
    {
      "epoch": 6.896501712355958,
      "grad_norm": 4.431787967681885,
      "learning_rate": 1.55321300021173e-05,
      "loss": 0.6681,
      "step": 651450
    },
    {
      "epoch": 6.897031034135962,
      "grad_norm": 4.391295433044434,
      "learning_rate": 1.552948337920813e-05,
      "loss": 0.6601,
      "step": 651500
    },
    {
      "epoch": 6.897031034135962,
      "eval_loss": 0.41667529940605164,
      "eval_runtime": 46.7481,
      "eval_samples_per_second": 3592.23,
      "eval_steps_per_second": 449.045,
      "step": 651500
    },
    {
      "epoch": 6.897560355915965,
      "grad_norm": 4.058237075805664,
      "learning_rate": 1.552683675629896e-05,
      "loss": 0.6694,
      "step": 651550
    },
    {
      "epoch": 6.898089677695968,
      "grad_norm": 4.90288782119751,
      "learning_rate": 1.5524190133389795e-05,
      "loss": 0.663,
      "step": 651600
    },
    {
      "epoch": 6.898618999475971,
      "grad_norm": 4.468623638153076,
      "learning_rate": 1.5521543510480626e-05,
      "loss": 0.6757,
      "step": 651650
    },
    {
      "epoch": 6.899148321255975,
      "grad_norm": 4.336756229400635,
      "learning_rate": 1.551889688757146e-05,
      "loss": 0.674,
      "step": 651700
    },
    {
      "epoch": 6.899677643035978,
      "grad_norm": 4.249044418334961,
      "learning_rate": 1.551625026466229e-05,
      "loss": 0.6672,
      "step": 651750
    },
    {
      "epoch": 6.900206964815982,
      "grad_norm": 4.169439315795898,
      "learning_rate": 1.5513603641753125e-05,
      "loss": 0.6652,
      "step": 651800
    },
    {
      "epoch": 6.9007362865959845,
      "grad_norm": 4.852832794189453,
      "learning_rate": 1.5510957018843956e-05,
      "loss": 0.6753,
      "step": 651850
    },
    {
      "epoch": 6.901265608375988,
      "grad_norm": 4.244403839111328,
      "learning_rate": 1.550831039593479e-05,
      "loss": 0.6672,
      "step": 651900
    },
    {
      "epoch": 6.901794930155991,
      "grad_norm": 4.3645734786987305,
      "learning_rate": 1.550566377302562e-05,
      "loss": 0.6686,
      "step": 651950
    },
    {
      "epoch": 6.902324251935994,
      "grad_norm": 4.102739334106445,
      "learning_rate": 1.550301715011645e-05,
      "loss": 0.662,
      "step": 652000
    },
    {
      "epoch": 6.902324251935994,
      "eval_loss": 0.41678130626678467,
      "eval_runtime": 46.745,
      "eval_samples_per_second": 3592.472,
      "eval_steps_per_second": 449.075,
      "step": 652000
    },
    {
      "epoch": 6.902853573715998,
      "grad_norm": 4.584611892700195,
      "learning_rate": 1.5500423459665466e-05,
      "loss": 0.6608,
      "step": 652050
    },
    {
      "epoch": 6.903382895496001,
      "grad_norm": 4.262889385223389,
      "learning_rate": 1.54977768367563e-05,
      "loss": 0.6716,
      "step": 652100
    },
    {
      "epoch": 6.903912217276004,
      "grad_norm": 3.979902744293213,
      "learning_rate": 1.549513021384713e-05,
      "loss": 0.663,
      "step": 652150
    },
    {
      "epoch": 6.904441539056007,
      "grad_norm": 4.248793601989746,
      "learning_rate": 1.5492483590937965e-05,
      "loss": 0.6532,
      "step": 652200
    },
    {
      "epoch": 6.904970860836011,
      "grad_norm": 4.297410488128662,
      "learning_rate": 1.5489836968028795e-05,
      "loss": 0.6711,
      "step": 652250
    },
    {
      "epoch": 6.905500182616014,
      "grad_norm": 4.285048961639404,
      "learning_rate": 1.548719034511963e-05,
      "loss": 0.6674,
      "step": 652300
    },
    {
      "epoch": 6.906029504396018,
      "grad_norm": 4.623032093048096,
      "learning_rate": 1.548454372221046e-05,
      "loss": 0.6726,
      "step": 652350
    },
    {
      "epoch": 6.9065588261760205,
      "grad_norm": 4.173074722290039,
      "learning_rate": 1.5481897099301294e-05,
      "loss": 0.6675,
      "step": 652400
    },
    {
      "epoch": 6.907088147956024,
      "grad_norm": 4.7410149574279785,
      "learning_rate": 1.5479250476392125e-05,
      "loss": 0.6679,
      "step": 652450
    },
    {
      "epoch": 6.907617469736027,
      "grad_norm": 4.758009910583496,
      "learning_rate": 1.5476603853482956e-05,
      "loss": 0.6534,
      "step": 652500
    },
    {
      "epoch": 6.907617469736027,
      "eval_loss": 0.41731491684913635,
      "eval_runtime": 46.552,
      "eval_samples_per_second": 3607.366,
      "eval_steps_per_second": 450.937,
      "step": 652500
    },
    {
      "epoch": 6.908146791516031,
      "grad_norm": 4.769392967224121,
      "learning_rate": 1.5473957230573787e-05,
      "loss": 0.6643,
      "step": 652550
    },
    {
      "epoch": 6.908676113296034,
      "grad_norm": 4.472217082977295,
      "learning_rate": 1.547131060766462e-05,
      "loss": 0.6735,
      "step": 652600
    },
    {
      "epoch": 6.9092054350760375,
      "grad_norm": 4.523359298706055,
      "learning_rate": 1.546866398475545e-05,
      "loss": 0.6678,
      "step": 652650
    },
    {
      "epoch": 6.90973475685604,
      "grad_norm": 4.41523551940918,
      "learning_rate": 1.5466017361846285e-05,
      "loss": 0.6643,
      "step": 652700
    },
    {
      "epoch": 6.910264078636043,
      "grad_norm": 4.244960784912109,
      "learning_rate": 1.5463370738937116e-05,
      "loss": 0.6725,
      "step": 652750
    },
    {
      "epoch": 6.910793400416047,
      "grad_norm": 4.730831146240234,
      "learning_rate": 1.546072411602795e-05,
      "loss": 0.6597,
      "step": 652800
    },
    {
      "epoch": 6.91132272219605,
      "grad_norm": 4.663444995880127,
      "learning_rate": 1.545807749311878e-05,
      "loss": 0.6705,
      "step": 652850
    },
    {
      "epoch": 6.911852043976054,
      "grad_norm": 4.49891471862793,
      "learning_rate": 1.5455430870209615e-05,
      "loss": 0.6597,
      "step": 652900
    },
    {
      "epoch": 6.912381365756056,
      "grad_norm": 4.710911750793457,
      "learning_rate": 1.5452784247300446e-05,
      "loss": 0.6519,
      "step": 652950
    },
    {
      "epoch": 6.91291068753606,
      "grad_norm": 4.562417507171631,
      "learning_rate": 1.545013762439128e-05,
      "loss": 0.6584,
      "step": 653000
    },
    {
      "epoch": 6.91291068753606,
      "eval_loss": 0.4157119393348694,
      "eval_runtime": 46.7304,
      "eval_samples_per_second": 3593.591,
      "eval_steps_per_second": 449.215,
      "step": 653000
    },
    {
      "epoch": 6.913440009316063,
      "grad_norm": 4.48638916015625,
      "learning_rate": 1.544749100148211e-05,
      "loss": 0.6614,
      "step": 653050
    },
    {
      "epoch": 6.913969331096067,
      "grad_norm": 4.422682285308838,
      "learning_rate": 1.544484437857294e-05,
      "loss": 0.6805,
      "step": 653100
    },
    {
      "epoch": 6.91449865287607,
      "grad_norm": 4.205872535705566,
      "learning_rate": 1.5442197755663772e-05,
      "loss": 0.6697,
      "step": 653150
    },
    {
      "epoch": 6.915027974656073,
      "grad_norm": 4.561200141906738,
      "learning_rate": 1.5439551132754606e-05,
      "loss": 0.6743,
      "step": 653200
    },
    {
      "epoch": 6.915557296436076,
      "grad_norm": 4.253310203552246,
      "learning_rate": 1.5436904509845437e-05,
      "loss": 0.6716,
      "step": 653250
    },
    {
      "epoch": 6.91608661821608,
      "grad_norm": 4.636810302734375,
      "learning_rate": 1.543425788693627e-05,
      "loss": 0.6615,
      "step": 653300
    },
    {
      "epoch": 6.916615939996083,
      "grad_norm": 4.54148530960083,
      "learning_rate": 1.54316112640271e-05,
      "loss": 0.6597,
      "step": 653350
    },
    {
      "epoch": 6.917145261776087,
      "grad_norm": 4.076488494873047,
      "learning_rate": 1.5428964641117936e-05,
      "loss": 0.6761,
      "step": 653400
    },
    {
      "epoch": 6.9176745835560896,
      "grad_norm": 4.321920871734619,
      "learning_rate": 1.5426318018208766e-05,
      "loss": 0.6748,
      "step": 653450
    },
    {
      "epoch": 6.918203905336092,
      "grad_norm": 4.3753132820129395,
      "learning_rate": 1.54236713952996e-05,
      "loss": 0.6658,
      "step": 653500
    },
    {
      "epoch": 6.918203905336092,
      "eval_loss": 0.4168306589126587,
      "eval_runtime": 46.6335,
      "eval_samples_per_second": 3601.06,
      "eval_steps_per_second": 450.149,
      "step": 653500
    },
    {
      "epoch": 6.918733227116096,
      "grad_norm": 4.506534099578857,
      "learning_rate": 1.542102477239043e-05,
      "loss": 0.6755,
      "step": 653550
    },
    {
      "epoch": 6.919262548896099,
      "grad_norm": 4.412594318389893,
      "learning_rate": 1.5418378149481262e-05,
      "loss": 0.6761,
      "step": 653600
    },
    {
      "epoch": 6.919791870676103,
      "grad_norm": 4.338216781616211,
      "learning_rate": 1.5415731526572093e-05,
      "loss": 0.6708,
      "step": 653650
    },
    {
      "epoch": 6.920321192456106,
      "grad_norm": 4.185078144073486,
      "learning_rate": 1.5413084903662927e-05,
      "loss": 0.6657,
      "step": 653700
    },
    {
      "epoch": 6.920850514236109,
      "grad_norm": 4.336297512054443,
      "learning_rate": 1.5410438280753757e-05,
      "loss": 0.665,
      "step": 653750
    },
    {
      "epoch": 6.921379836016112,
      "grad_norm": 4.377185344696045,
      "learning_rate": 1.540779165784459e-05,
      "loss": 0.67,
      "step": 653800
    },
    {
      "epoch": 6.921909157796116,
      "grad_norm": 4.778010368347168,
      "learning_rate": 1.5405145034935422e-05,
      "loss": 0.6582,
      "step": 653850
    },
    {
      "epoch": 6.922438479576119,
      "grad_norm": 4.7994585037231445,
      "learning_rate": 1.5402498412026256e-05,
      "loss": 0.6745,
      "step": 653900
    },
    {
      "epoch": 6.922967801356123,
      "grad_norm": 4.6303558349609375,
      "learning_rate": 1.5399851789117087e-05,
      "loss": 0.6659,
      "step": 653950
    },
    {
      "epoch": 6.9234971231361255,
      "grad_norm": 4.394969940185547,
      "learning_rate": 1.539720516620792e-05,
      "loss": 0.669,
      "step": 654000
    },
    {
      "epoch": 6.9234971231361255,
      "eval_loss": 0.41691896319389343,
      "eval_runtime": 46.7598,
      "eval_samples_per_second": 3591.33,
      "eval_steps_per_second": 448.932,
      "step": 654000
    },
    {
      "epoch": 6.924026444916129,
      "grad_norm": 4.55632209777832,
      "learning_rate": 1.5394611475756936e-05,
      "loss": 0.6664,
      "step": 654050
    },
    {
      "epoch": 6.924555766696132,
      "grad_norm": 4.826627254486084,
      "learning_rate": 1.5391964852847767e-05,
      "loss": 0.6514,
      "step": 654100
    },
    {
      "epoch": 6.925085088476136,
      "grad_norm": 4.239461898803711,
      "learning_rate": 1.5389318229938597e-05,
      "loss": 0.6581,
      "step": 654150
    },
    {
      "epoch": 6.925614410256139,
      "grad_norm": 4.375378131866455,
      "learning_rate": 1.538667160702943e-05,
      "loss": 0.6649,
      "step": 654200
    },
    {
      "epoch": 6.926143732036142,
      "grad_norm": 4.205657958984375,
      "learning_rate": 1.5384024984120262e-05,
      "loss": 0.675,
      "step": 654250
    },
    {
      "epoch": 6.926673053816145,
      "grad_norm": 4.361592769622803,
      "learning_rate": 1.5381378361211096e-05,
      "loss": 0.6588,
      "step": 654300
    },
    {
      "epoch": 6.927202375596149,
      "grad_norm": 4.742730140686035,
      "learning_rate": 1.5378731738301927e-05,
      "loss": 0.6594,
      "step": 654350
    },
    {
      "epoch": 6.927731697376152,
      "grad_norm": 4.393182754516602,
      "learning_rate": 1.537608511539276e-05,
      "loss": 0.6691,
      "step": 654400
    },
    {
      "epoch": 6.928261019156155,
      "grad_norm": 4.397542476654053,
      "learning_rate": 1.5373438492483592e-05,
      "loss": 0.67,
      "step": 654450
    },
    {
      "epoch": 6.928790340936159,
      "grad_norm": 4.504838466644287,
      "learning_rate": 1.5370791869574426e-05,
      "loss": 0.6713,
      "step": 654500
    },
    {
      "epoch": 6.928790340936159,
      "eval_loss": 0.4169832766056061,
      "eval_runtime": 46.5973,
      "eval_samples_per_second": 3603.858,
      "eval_steps_per_second": 450.498,
      "step": 654500
    },
    {
      "epoch": 6.9293196627161615,
      "grad_norm": 4.450439453125,
      "learning_rate": 1.5368145246665257e-05,
      "loss": 0.6594,
      "step": 654550
    },
    {
      "epoch": 6.929848984496165,
      "grad_norm": 4.2557902336120605,
      "learning_rate": 1.5365498623756087e-05,
      "loss": 0.6613,
      "step": 654600
    },
    {
      "epoch": 6.930378306276168,
      "grad_norm": 4.766754627227783,
      "learning_rate": 1.5362852000846918e-05,
      "loss": 0.6535,
      "step": 654650
    },
    {
      "epoch": 6.930907628056172,
      "grad_norm": 4.295266628265381,
      "learning_rate": 1.5360205377937752e-05,
      "loss": 0.6616,
      "step": 654700
    },
    {
      "epoch": 6.931436949836175,
      "grad_norm": 4.475947856903076,
      "learning_rate": 1.5357558755028583e-05,
      "loss": 0.6652,
      "step": 654750
    },
    {
      "epoch": 6.9319662716161785,
      "grad_norm": 4.263341903686523,
      "learning_rate": 1.5354912132119417e-05,
      "loss": 0.6661,
      "step": 654800
    },
    {
      "epoch": 6.932495593396181,
      "grad_norm": 4.655749320983887,
      "learning_rate": 1.5352265509210248e-05,
      "loss": 0.6725,
      "step": 654850
    },
    {
      "epoch": 6.933024915176185,
      "grad_norm": 4.182747840881348,
      "learning_rate": 1.5349618886301082e-05,
      "loss": 0.6646,
      "step": 654900
    },
    {
      "epoch": 6.933554236956188,
      "grad_norm": 4.838125705718994,
      "learning_rate": 1.5346972263391912e-05,
      "loss": 0.6679,
      "step": 654950
    },
    {
      "epoch": 6.934083558736191,
      "grad_norm": 4.13981294631958,
      "learning_rate": 1.5344325640482747e-05,
      "loss": 0.6686,
      "step": 655000
    },
    {
      "epoch": 6.934083558736191,
      "eval_loss": 0.41640591621398926,
      "eval_runtime": 46.6196,
      "eval_samples_per_second": 3602.132,
      "eval_steps_per_second": 450.283,
      "step": 655000
    },
    {
      "epoch": 6.934612880516195,
      "grad_norm": 4.170051574707031,
      "learning_rate": 1.5341679017573577e-05,
      "loss": 0.6649,
      "step": 655050
    },
    {
      "epoch": 6.935142202296198,
      "grad_norm": 4.34118127822876,
      "learning_rate": 1.533903239466441e-05,
      "loss": 0.6661,
      "step": 655100
    },
    {
      "epoch": 6.935671524076201,
      "grad_norm": 4.366244792938232,
      "learning_rate": 1.5336385771755242e-05,
      "loss": 0.6628,
      "step": 655150
    },
    {
      "epoch": 6.936200845856204,
      "grad_norm": 4.441339015960693,
      "learning_rate": 1.5333739148846073e-05,
      "loss": 0.6761,
      "step": 655200
    },
    {
      "epoch": 6.936730167636208,
      "grad_norm": 4.4217329025268555,
      "learning_rate": 1.5331092525936904e-05,
      "loss": 0.6579,
      "step": 655250
    },
    {
      "epoch": 6.937259489416211,
      "grad_norm": 4.448257923126221,
      "learning_rate": 1.5328445903027738e-05,
      "loss": 0.6679,
      "step": 655300
    },
    {
      "epoch": 6.9377888111962145,
      "grad_norm": 4.293316841125488,
      "learning_rate": 1.532579928011857e-05,
      "loss": 0.6732,
      "step": 655350
    },
    {
      "epoch": 6.938318132976217,
      "grad_norm": 4.735957145690918,
      "learning_rate": 1.5323152657209402e-05,
      "loss": 0.6669,
      "step": 655400
    },
    {
      "epoch": 6.938847454756221,
      "grad_norm": 4.8249430656433105,
      "learning_rate": 1.5320506034300233e-05,
      "loss": 0.6629,
      "step": 655450
    },
    {
      "epoch": 6.939376776536224,
      "grad_norm": 4.463863849639893,
      "learning_rate": 1.5317859411391067e-05,
      "loss": 0.6708,
      "step": 655500
    },
    {
      "epoch": 6.939376776536224,
      "eval_loss": 0.41619765758514404,
      "eval_runtime": 46.8076,
      "eval_samples_per_second": 3587.669,
      "eval_steps_per_second": 448.475,
      "step": 655500
    },
    {
      "epoch": 6.939906098316228,
      "grad_norm": 4.772653579711914,
      "learning_rate": 1.5315212788481898e-05,
      "loss": 0.6728,
      "step": 655550
    },
    {
      "epoch": 6.940435420096231,
      "grad_norm": 4.555247783660889,
      "learning_rate": 1.5312566165572732e-05,
      "loss": 0.6616,
      "step": 655600
    },
    {
      "epoch": 6.940964741876234,
      "grad_norm": 4.537646770477295,
      "learning_rate": 1.5309919542663563e-05,
      "loss": 0.6726,
      "step": 655650
    },
    {
      "epoch": 6.941494063656237,
      "grad_norm": 4.176770210266113,
      "learning_rate": 1.5307272919754393e-05,
      "loss": 0.6611,
      "step": 655700
    },
    {
      "epoch": 6.94202338543624,
      "grad_norm": 4.681827068328857,
      "learning_rate": 1.5304626296845224e-05,
      "loss": 0.6597,
      "step": 655750
    },
    {
      "epoch": 6.942552707216244,
      "grad_norm": 4.209643840789795,
      "learning_rate": 1.5301979673936058e-05,
      "loss": 0.6655,
      "step": 655800
    },
    {
      "epoch": 6.943082028996248,
      "grad_norm": 4.336147785186768,
      "learning_rate": 1.529933305102689e-05,
      "loss": 0.669,
      "step": 655850
    },
    {
      "epoch": 6.9436113507762505,
      "grad_norm": 4.613357067108154,
      "learning_rate": 1.5296686428117723e-05,
      "loss": 0.6659,
      "step": 655900
    },
    {
      "epoch": 6.944140672556253,
      "grad_norm": 4.380459785461426,
      "learning_rate": 1.5294039805208554e-05,
      "loss": 0.6634,
      "step": 655950
    },
    {
      "epoch": 6.944669994336257,
      "grad_norm": 4.093654632568359,
      "learning_rate": 1.5291393182299388e-05,
      "loss": 0.6707,
      "step": 656000
    },
    {
      "epoch": 6.944669994336257,
      "eval_loss": 0.41679856181144714,
      "eval_runtime": 47.2988,
      "eval_samples_per_second": 3550.409,
      "eval_steps_per_second": 443.817,
      "step": 656000
    },
    {
      "epoch": 6.94519931611626,
      "grad_norm": 4.289324760437012,
      "learning_rate": 1.528874655939022e-05,
      "loss": 0.6608,
      "step": 656050
    },
    {
      "epoch": 6.945728637896264,
      "grad_norm": 4.691438674926758,
      "learning_rate": 1.5286152868939237e-05,
      "loss": 0.6687,
      "step": 656100
    },
    {
      "epoch": 6.946257959676267,
      "grad_norm": 4.133275985717773,
      "learning_rate": 1.5283506246030067e-05,
      "loss": 0.6657,
      "step": 656150
    },
    {
      "epoch": 6.94678728145627,
      "grad_norm": 4.547163486480713,
      "learning_rate": 1.5280859623120898e-05,
      "loss": 0.665,
      "step": 656200
    },
    {
      "epoch": 6.947316603236273,
      "grad_norm": 4.16483736038208,
      "learning_rate": 1.527821300021173e-05,
      "loss": 0.6571,
      "step": 656250
    },
    {
      "epoch": 6.947845925016277,
      "grad_norm": 4.070483207702637,
      "learning_rate": 1.5275566377302563e-05,
      "loss": 0.6616,
      "step": 656300
    },
    {
      "epoch": 6.94837524679628,
      "grad_norm": 4.652939796447754,
      "learning_rate": 1.5272919754393394e-05,
      "loss": 0.6738,
      "step": 656350
    },
    {
      "epoch": 6.948904568576284,
      "grad_norm": 4.432759761810303,
      "learning_rate": 1.5270273131484228e-05,
      "loss": 0.6662,
      "step": 656400
    },
    {
      "epoch": 6.9494338903562864,
      "grad_norm": 4.4444499015808105,
      "learning_rate": 1.526762650857506e-05,
      "loss": 0.6759,
      "step": 656450
    },
    {
      "epoch": 6.949963212136289,
      "grad_norm": 4.366731643676758,
      "learning_rate": 1.5264979885665893e-05,
      "loss": 0.675,
      "step": 656500
    },
    {
      "epoch": 6.949963212136289,
      "eval_loss": 0.41674381494522095,
      "eval_runtime": 47.6862,
      "eval_samples_per_second": 3521.562,
      "eval_steps_per_second": 440.211,
      "step": 656500
    },
    {
      "epoch": 6.950492533916293,
      "grad_norm": 4.116560459136963,
      "learning_rate": 1.5262333262756723e-05,
      "loss": 0.661,
      "step": 656550
    },
    {
      "epoch": 6.951021855696297,
      "grad_norm": 4.182863712310791,
      "learning_rate": 1.5259686639847557e-05,
      "loss": 0.6664,
      "step": 656600
    },
    {
      "epoch": 6.9515511774763,
      "grad_norm": 4.799915790557861,
      "learning_rate": 1.5257040016938386e-05,
      "loss": 0.6628,
      "step": 656650
    },
    {
      "epoch": 6.952080499256303,
      "grad_norm": 4.396597385406494,
      "learning_rate": 1.525439339402922e-05,
      "loss": 0.6755,
      "step": 656700
    },
    {
      "epoch": 6.952609821036306,
      "grad_norm": 4.698139667510986,
      "learning_rate": 1.5251746771120051e-05,
      "loss": 0.6699,
      "step": 656750
    },
    {
      "epoch": 6.953139142816309,
      "grad_norm": 4.772459030151367,
      "learning_rate": 1.5249100148210885e-05,
      "loss": 0.662,
      "step": 656800
    },
    {
      "epoch": 6.953668464596313,
      "grad_norm": 4.669183254241943,
      "learning_rate": 1.5246453525301716e-05,
      "loss": 0.6684,
      "step": 656850
    },
    {
      "epoch": 6.954197786376316,
      "grad_norm": 4.418955326080322,
      "learning_rate": 1.5243806902392548e-05,
      "loss": 0.6464,
      "step": 656900
    },
    {
      "epoch": 6.95472710815632,
      "grad_norm": 4.300073623657227,
      "learning_rate": 1.5241160279483379e-05,
      "loss": 0.6536,
      "step": 656950
    },
    {
      "epoch": 6.955256429936322,
      "grad_norm": 4.410913944244385,
      "learning_rate": 1.5238513656574213e-05,
      "loss": 0.6642,
      "step": 657000
    },
    {
      "epoch": 6.955256429936322,
      "eval_loss": 0.41549044847488403,
      "eval_runtime": 46.7827,
      "eval_samples_per_second": 3589.577,
      "eval_steps_per_second": 448.713,
      "step": 657000
    },
    {
      "epoch": 6.955785751716326,
      "grad_norm": 4.714421272277832,
      "learning_rate": 1.5235867033665044e-05,
      "loss": 0.679,
      "step": 657050
    },
    {
      "epoch": 6.956315073496329,
      "grad_norm": 4.873493671417236,
      "learning_rate": 1.5233220410755878e-05,
      "loss": 0.6569,
      "step": 657100
    },
    {
      "epoch": 6.956844395276333,
      "grad_norm": 4.17271614074707,
      "learning_rate": 1.5230573787846709e-05,
      "loss": 0.6654,
      "step": 657150
    },
    {
      "epoch": 6.957373717056336,
      "grad_norm": 4.684124946594238,
      "learning_rate": 1.5227927164937541e-05,
      "loss": 0.6704,
      "step": 657200
    },
    {
      "epoch": 6.9579030388363385,
      "grad_norm": 4.610507965087891,
      "learning_rate": 1.5225280542028372e-05,
      "loss": 0.678,
      "step": 657250
    },
    {
      "epoch": 6.958432360616342,
      "grad_norm": 4.490885257720947,
      "learning_rate": 1.5222633919119206e-05,
      "loss": 0.6682,
      "step": 657300
    },
    {
      "epoch": 6.958961682396346,
      "grad_norm": 4.466355323791504,
      "learning_rate": 1.5219987296210037e-05,
      "loss": 0.6548,
      "step": 657350
    },
    {
      "epoch": 6.959491004176349,
      "grad_norm": 4.153446197509766,
      "learning_rate": 1.521734067330087e-05,
      "loss": 0.6709,
      "step": 657400
    },
    {
      "epoch": 6.960020325956352,
      "grad_norm": 4.415397644042969,
      "learning_rate": 1.5214694050391702e-05,
      "loss": 0.6676,
      "step": 657450
    },
    {
      "epoch": 6.9605496477363555,
      "grad_norm": 4.4133100509643555,
      "learning_rate": 1.5212047427482534e-05,
      "loss": 0.6678,
      "step": 657500
    },
    {
      "epoch": 6.9605496477363555,
      "eval_loss": 0.41518858075141907,
      "eval_runtime": 46.6538,
      "eval_samples_per_second": 3599.489,
      "eval_steps_per_second": 449.952,
      "step": 657500
    },
    {
      "epoch": 6.961078969516358,
      "grad_norm": 4.2011847496032715,
      "learning_rate": 1.5209400804573365e-05,
      "loss": 0.6597,
      "step": 657550
    },
    {
      "epoch": 6.961608291296362,
      "grad_norm": 4.741667747497559,
      "learning_rate": 1.5206754181664199e-05,
      "loss": 0.6662,
      "step": 657600
    },
    {
      "epoch": 6.962137613076365,
      "grad_norm": 4.503098011016846,
      "learning_rate": 1.520410755875503e-05,
      "loss": 0.6634,
      "step": 657650
    },
    {
      "epoch": 6.962666934856369,
      "grad_norm": 4.236150741577148,
      "learning_rate": 1.5201460935845862e-05,
      "loss": 0.6663,
      "step": 657700
    },
    {
      "epoch": 6.963196256636372,
      "grad_norm": 4.198399543762207,
      "learning_rate": 1.5198814312936693e-05,
      "loss": 0.6629,
      "step": 657750
    },
    {
      "epoch": 6.963725578416375,
      "grad_norm": 5.184793472290039,
      "learning_rate": 1.5196167690027527e-05,
      "loss": 0.6506,
      "step": 657800
    },
    {
      "epoch": 6.964254900196378,
      "grad_norm": 4.39889669418335,
      "learning_rate": 1.5193521067118357e-05,
      "loss": 0.6752,
      "step": 657850
    },
    {
      "epoch": 6.964784221976382,
      "grad_norm": 4.352386474609375,
      "learning_rate": 1.5190874444209191e-05,
      "loss": 0.652,
      "step": 657900
    },
    {
      "epoch": 6.965313543756385,
      "grad_norm": 4.273991584777832,
      "learning_rate": 1.5188227821300022e-05,
      "loss": 0.6654,
      "step": 657950
    },
    {
      "epoch": 6.965842865536388,
      "grad_norm": 4.531702518463135,
      "learning_rate": 1.5185581198390855e-05,
      "loss": 0.6691,
      "step": 658000
    },
    {
      "epoch": 6.965842865536388,
      "eval_loss": 0.4154467284679413,
      "eval_runtime": 46.6772,
      "eval_samples_per_second": 3597.685,
      "eval_steps_per_second": 449.727,
      "step": 658000
    },
    {
      "epoch": 6.9663721873163915,
      "grad_norm": 4.8391499519348145,
      "learning_rate": 1.5182934575481685e-05,
      "loss": 0.6723,
      "step": 658050
    },
    {
      "epoch": 6.966901509096395,
      "grad_norm": 4.616931915283203,
      "learning_rate": 1.5180340885030703e-05,
      "loss": 0.6733,
      "step": 658100
    },
    {
      "epoch": 6.967430830876398,
      "grad_norm": 4.686500549316406,
      "learning_rate": 1.5177694262121534e-05,
      "loss": 0.6541,
      "step": 658150
    },
    {
      "epoch": 6.967960152656401,
      "grad_norm": 4.937288284301758,
      "learning_rate": 1.5175047639212367e-05,
      "loss": 0.6559,
      "step": 658200
    },
    {
      "epoch": 6.968489474436405,
      "grad_norm": 4.746987819671631,
      "learning_rate": 1.5172401016303197e-05,
      "loss": 0.6727,
      "step": 658250
    },
    {
      "epoch": 6.969018796216408,
      "grad_norm": 4.645262718200684,
      "learning_rate": 1.5169754393394031e-05,
      "loss": 0.6605,
      "step": 658300
    },
    {
      "epoch": 6.969548117996411,
      "grad_norm": 4.787669658660889,
      "learning_rate": 1.5167107770484862e-05,
      "loss": 0.6699,
      "step": 658350
    },
    {
      "epoch": 6.970077439776414,
      "grad_norm": 4.6163153648376465,
      "learning_rate": 1.5164461147575696e-05,
      "loss": 0.6631,
      "step": 658400
    },
    {
      "epoch": 6.970606761556418,
      "grad_norm": 4.264257431030273,
      "learning_rate": 1.5161814524666527e-05,
      "loss": 0.6674,
      "step": 658450
    },
    {
      "epoch": 6.971136083336421,
      "grad_norm": 4.248234272003174,
      "learning_rate": 1.515916790175736e-05,
      "loss": 0.6643,
      "step": 658500
    },
    {
      "epoch": 6.971136083336421,
      "eval_loss": 0.4154551029205322,
      "eval_runtime": 46.9202,
      "eval_samples_per_second": 3579.057,
      "eval_steps_per_second": 447.398,
      "step": 658500
    },
    {
      "epoch": 6.971665405116425,
      "grad_norm": 4.424864292144775,
      "learning_rate": 1.515652127884819e-05,
      "loss": 0.6604,
      "step": 658550
    },
    {
      "epoch": 6.9721947268964275,
      "grad_norm": 4.148809909820557,
      "learning_rate": 1.5153874655939024e-05,
      "loss": 0.6654,
      "step": 658600
    },
    {
      "epoch": 6.972724048676431,
      "grad_norm": 4.613994598388672,
      "learning_rate": 1.5151228033029855e-05,
      "loss": 0.6685,
      "step": 658650
    },
    {
      "epoch": 6.973253370456434,
      "grad_norm": 4.3055033683776855,
      "learning_rate": 1.5148581410120687e-05,
      "loss": 0.6674,
      "step": 658700
    },
    {
      "epoch": 6.973782692236437,
      "grad_norm": 4.299131393432617,
      "learning_rate": 1.5145934787211518e-05,
      "loss": 0.6585,
      "step": 658750
    },
    {
      "epoch": 6.974312014016441,
      "grad_norm": 4.408389568328857,
      "learning_rate": 1.5143288164302352e-05,
      "loss": 0.667,
      "step": 658800
    },
    {
      "epoch": 6.9748413357964445,
      "grad_norm": 4.509735107421875,
      "learning_rate": 1.5140641541393183e-05,
      "loss": 0.6627,
      "step": 658850
    },
    {
      "epoch": 6.975370657576447,
      "grad_norm": 4.482322692871094,
      "learning_rate": 1.5137994918484017e-05,
      "loss": 0.6737,
      "step": 658900
    },
    {
      "epoch": 6.97589997935645,
      "grad_norm": 4.453890323638916,
      "learning_rate": 1.5135348295574848e-05,
      "loss": 0.6623,
      "step": 658950
    },
    {
      "epoch": 6.976429301136454,
      "grad_norm": 4.483844757080078,
      "learning_rate": 1.513270167266568e-05,
      "loss": 0.67,
      "step": 659000
    },
    {
      "epoch": 6.976429301136454,
      "eval_loss": 0.41669216752052307,
      "eval_runtime": 48.2008,
      "eval_samples_per_second": 3483.966,
      "eval_steps_per_second": 435.511,
      "step": 659000
    },
    {
      "epoch": 6.976958622916457,
      "grad_norm": 4.33662223815918,
      "learning_rate": 1.513005504975651e-05,
      "loss": 0.6581,
      "step": 659050
    },
    {
      "epoch": 6.977487944696461,
      "grad_norm": 4.8042378425598145,
      "learning_rate": 1.5127408426847345e-05,
      "loss": 0.6585,
      "step": 659100
    },
    {
      "epoch": 6.9780172664764635,
      "grad_norm": 4.629833698272705,
      "learning_rate": 1.5124761803938175e-05,
      "loss": 0.6597,
      "step": 659150
    },
    {
      "epoch": 6.978546588256467,
      "grad_norm": 4.037563800811768,
      "learning_rate": 1.512211518102901e-05,
      "loss": 0.6736,
      "step": 659200
    },
    {
      "epoch": 6.97907591003647,
      "grad_norm": 4.054780006408691,
      "learning_rate": 1.511946855811984e-05,
      "loss": 0.6625,
      "step": 659250
    },
    {
      "epoch": 6.979605231816474,
      "grad_norm": 4.309281349182129,
      "learning_rate": 1.5116821935210673e-05,
      "loss": 0.6638,
      "step": 659300
    },
    {
      "epoch": 6.980134553596477,
      "grad_norm": 4.199143409729004,
      "learning_rate": 1.5114175312301503e-05,
      "loss": 0.6648,
      "step": 659350
    },
    {
      "epoch": 6.9806638753764805,
      "grad_norm": 4.440615177154541,
      "learning_rate": 1.5111528689392337e-05,
      "loss": 0.6574,
      "step": 659400
    },
    {
      "epoch": 6.981193197156483,
      "grad_norm": 4.3250274658203125,
      "learning_rate": 1.5108882066483168e-05,
      "loss": 0.6701,
      "step": 659450
    },
    {
      "epoch": 6.981722518936486,
      "grad_norm": 4.8179707527160645,
      "learning_rate": 1.5106235443574002e-05,
      "loss": 0.679,
      "step": 659500
    },
    {
      "epoch": 6.981722518936486,
      "eval_loss": 0.4156036078929901,
      "eval_runtime": 47.5023,
      "eval_samples_per_second": 3535.199,
      "eval_steps_per_second": 441.916,
      "step": 659500
    },
    {
      "epoch": 6.98225184071649,
      "grad_norm": 4.474246501922607,
      "learning_rate": 1.5103588820664833e-05,
      "loss": 0.6584,
      "step": 659550
    },
    {
      "epoch": 6.982781162496494,
      "grad_norm": 4.757815361022949,
      "learning_rate": 1.5100942197755665e-05,
      "loss": 0.6641,
      "step": 659600
    },
    {
      "epoch": 6.983310484276497,
      "grad_norm": 4.420154094696045,
      "learning_rate": 1.5098295574846496e-05,
      "loss": 0.6722,
      "step": 659650
    },
    {
      "epoch": 6.9838398060564995,
      "grad_norm": 4.014476776123047,
      "learning_rate": 1.5095648951937327e-05,
      "loss": 0.6624,
      "step": 659700
    },
    {
      "epoch": 6.984369127836503,
      "grad_norm": 4.690589427947998,
      "learning_rate": 1.5093002329028161e-05,
      "loss": 0.6622,
      "step": 659750
    },
    {
      "epoch": 6.984898449616506,
      "grad_norm": 4.501129627227783,
      "learning_rate": 1.5090355706118992e-05,
      "loss": 0.6677,
      "step": 659800
    },
    {
      "epoch": 6.98542777139651,
      "grad_norm": 4.4409637451171875,
      "learning_rate": 1.5087709083209826e-05,
      "loss": 0.6587,
      "step": 659850
    },
    {
      "epoch": 6.985957093176513,
      "grad_norm": 4.590677261352539,
      "learning_rate": 1.5085062460300656e-05,
      "loss": 0.6717,
      "step": 659900
    },
    {
      "epoch": 6.9864864149565165,
      "grad_norm": 4.696893215179443,
      "learning_rate": 1.5082415837391489e-05,
      "loss": 0.6579,
      "step": 659950
    },
    {
      "epoch": 6.987015736736519,
      "grad_norm": 4.309972763061523,
      "learning_rate": 1.507976921448232e-05,
      "loss": 0.6652,
      "step": 660000
    },
    {
      "epoch": 6.987015736736519,
      "eval_loss": 0.41492217779159546,
      "eval_runtime": 47.5103,
      "eval_samples_per_second": 3534.604,
      "eval_steps_per_second": 441.841,
      "step": 660000
    },
    {
      "epoch": 6.987545058516523,
      "grad_norm": 4.090878009796143,
      "learning_rate": 1.5077122591573154e-05,
      "loss": 0.6624,
      "step": 660050
    },
    {
      "epoch": 6.988074380296526,
      "grad_norm": 4.670903205871582,
      "learning_rate": 1.507452890112217e-05,
      "loss": 0.6709,
      "step": 660100
    },
    {
      "epoch": 6.98860370207653,
      "grad_norm": 4.49856424331665,
      "learning_rate": 1.5071882278213e-05,
      "loss": 0.6716,
      "step": 660150
    },
    {
      "epoch": 6.989133023856533,
      "grad_norm": 4.234768867492676,
      "learning_rate": 1.5069235655303835e-05,
      "loss": 0.673,
      "step": 660200
    },
    {
      "epoch": 6.989662345636535,
      "grad_norm": 4.470839977264404,
      "learning_rate": 1.5066589032394666e-05,
      "loss": 0.666,
      "step": 660250
    },
    {
      "epoch": 6.990191667416539,
      "grad_norm": 4.443173408508301,
      "learning_rate": 1.5063942409485496e-05,
      "loss": 0.6663,
      "step": 660300
    },
    {
      "epoch": 6.990720989196543,
      "grad_norm": 4.789242267608643,
      "learning_rate": 1.5061295786576329e-05,
      "loss": 0.6573,
      "step": 660350
    },
    {
      "epoch": 6.991250310976546,
      "grad_norm": 4.902241230010986,
      "learning_rate": 1.505864916366716e-05,
      "loss": 0.67,
      "step": 660400
    },
    {
      "epoch": 6.991779632756549,
      "grad_norm": 4.436792373657227,
      "learning_rate": 1.5056002540757994e-05,
      "loss": 0.6732,
      "step": 660450
    },
    {
      "epoch": 6.992308954536552,
      "grad_norm": 4.6958465576171875,
      "learning_rate": 1.5053355917848824e-05,
      "loss": 0.6589,
      "step": 660500
    },
    {
      "epoch": 6.992308954536552,
      "eval_loss": 0.4149642288684845,
      "eval_runtime": 47.411,
      "eval_samples_per_second": 3542.003,
      "eval_steps_per_second": 442.766,
      "step": 660500
    },
    {
      "epoch": 6.992838276316555,
      "grad_norm": 4.566025733947754,
      "learning_rate": 1.5050709294939658e-05,
      "loss": 0.6572,
      "step": 660550
    },
    {
      "epoch": 6.993367598096559,
      "grad_norm": 4.731334686279297,
      "learning_rate": 1.5048062672030489e-05,
      "loss": 0.6709,
      "step": 660600
    },
    {
      "epoch": 6.993896919876562,
      "grad_norm": 4.559074878692627,
      "learning_rate": 1.5045416049121321e-05,
      "loss": 0.6648,
      "step": 660650
    },
    {
      "epoch": 6.994426241656566,
      "grad_norm": 4.2504777908325195,
      "learning_rate": 1.5042769426212152e-05,
      "loss": 0.6635,
      "step": 660700
    },
    {
      "epoch": 6.9949555634365685,
      "grad_norm": 4.563831806182861,
      "learning_rate": 1.5040122803302986e-05,
      "loss": 0.6727,
      "step": 660750
    },
    {
      "epoch": 6.995484885216572,
      "grad_norm": 4.608771800994873,
      "learning_rate": 1.5037476180393817e-05,
      "loss": 0.6655,
      "step": 660800
    },
    {
      "epoch": 6.996014206996575,
      "grad_norm": 4.377259731292725,
      "learning_rate": 1.5034829557484651e-05,
      "loss": 0.6643,
      "step": 660850
    },
    {
      "epoch": 6.996543528776579,
      "grad_norm": 4.817881107330322,
      "learning_rate": 1.5032182934575482e-05,
      "loss": 0.6714,
      "step": 660900
    },
    {
      "epoch": 6.997072850556582,
      "grad_norm": 4.72922420501709,
      "learning_rate": 1.5029536311666314e-05,
      "loss": 0.6632,
      "step": 660950
    },
    {
      "epoch": 6.997602172336585,
      "grad_norm": 4.297962665557861,
      "learning_rate": 1.5026889688757145e-05,
      "loss": 0.6656,
      "step": 661000
    },
    {
      "epoch": 6.997602172336585,
      "eval_loss": 0.41560062766075134,
      "eval_runtime": 47.3227,
      "eval_samples_per_second": 3548.611,
      "eval_steps_per_second": 443.592,
      "step": 661000
    },
    {
      "epoch": 6.998131494116588,
      "grad_norm": 4.723409175872803,
      "learning_rate": 1.5024243065847979e-05,
      "loss": 0.6709,
      "step": 661050
    },
    {
      "epoch": 6.998660815896592,
      "grad_norm": 4.208432674407959,
      "learning_rate": 1.502159644293881e-05,
      "loss": 0.6562,
      "step": 661100
    },
    {
      "epoch": 6.999190137676595,
      "grad_norm": 4.745336055755615,
      "learning_rate": 1.5018949820029644e-05,
      "loss": 0.6684,
      "step": 661150
    },
    {
      "epoch": 6.999719459456598,
      "grad_norm": 4.686640739440918,
      "learning_rate": 1.5016303197120475e-05,
      "loss": 0.6613,
      "step": 661200
    },
    {
      "epoch": 7.000243488018802,
      "grad_norm": 4.182794570922852,
      "learning_rate": 1.5013656574211307e-05,
      "loss": 0.6585,
      "step": 661250
    },
    {
      "epoch": 7.0007728097988045,
      "grad_norm": 4.753096580505371,
      "learning_rate": 1.5011009951302138e-05,
      "loss": 0.6587,
      "step": 661300
    },
    {
      "epoch": 7.001302131578808,
      "grad_norm": 4.402101039886475,
      "learning_rate": 1.5008363328392972e-05,
      "loss": 0.6585,
      "step": 661350
    },
    {
      "epoch": 7.001831453358811,
      "grad_norm": 4.446073055267334,
      "learning_rate": 1.5005716705483802e-05,
      "loss": 0.6578,
      "step": 661400
    },
    {
      "epoch": 7.002360775138815,
      "grad_norm": 4.600724697113037,
      "learning_rate": 1.5003070082574635e-05,
      "loss": 0.6645,
      "step": 661450
    },
    {
      "epoch": 7.002890096918818,
      "grad_norm": 4.4202961921691895,
      "learning_rate": 1.5000423459665466e-05,
      "loss": 0.6592,
      "step": 661500
    },
    {
      "epoch": 7.002890096918818,
      "eval_loss": 0.41471534967422485,
      "eval_runtime": 46.7243,
      "eval_samples_per_second": 3594.062,
      "eval_steps_per_second": 449.274,
      "step": 661500
    },
    {
      "epoch": 7.0034194186988215,
      "grad_norm": 4.785245418548584,
      "learning_rate": 1.49977768367563e-05,
      "loss": 0.6652,
      "step": 661550
    },
    {
      "epoch": 7.003948740478824,
      "grad_norm": 4.622839450836182,
      "learning_rate": 1.499513021384713e-05,
      "loss": 0.6625,
      "step": 661600
    },
    {
      "epoch": 7.004478062258828,
      "grad_norm": 4.363363742828369,
      "learning_rate": 1.4992483590937964e-05,
      "loss": 0.6551,
      "step": 661650
    },
    {
      "epoch": 7.005007384038831,
      "grad_norm": 4.769050598144531,
      "learning_rate": 1.4989836968028795e-05,
      "loss": 0.6644,
      "step": 661700
    },
    {
      "epoch": 7.005536705818835,
      "grad_norm": 4.578297138214111,
      "learning_rate": 1.4987190345119628e-05,
      "loss": 0.6565,
      "step": 661750
    },
    {
      "epoch": 7.006066027598838,
      "grad_norm": 4.049755096435547,
      "learning_rate": 1.4984543722210458e-05,
      "loss": 0.6573,
      "step": 661800
    },
    {
      "epoch": 7.006595349378841,
      "grad_norm": 4.103302955627441,
      "learning_rate": 1.4981897099301292e-05,
      "loss": 0.6511,
      "step": 661850
    },
    {
      "epoch": 7.007124671158844,
      "grad_norm": 4.54764986038208,
      "learning_rate": 1.4979250476392123e-05,
      "loss": 0.6619,
      "step": 661900
    },
    {
      "epoch": 7.007653992938847,
      "grad_norm": 4.309762001037598,
      "learning_rate": 1.4976603853482957e-05,
      "loss": 0.661,
      "step": 661950
    },
    {
      "epoch": 7.008183314718851,
      "grad_norm": 4.610524654388428,
      "learning_rate": 1.4973957230573788e-05,
      "loss": 0.6704,
      "step": 662000
    },
    {
      "epoch": 7.008183314718851,
      "eval_loss": 0.4140138328075409,
      "eval_runtime": 46.8018,
      "eval_samples_per_second": 3588.107,
      "eval_steps_per_second": 448.529,
      "step": 662000
    },
    {
      "epoch": 7.008712636498854,
      "grad_norm": 4.2641754150390625,
      "learning_rate": 1.497131060766462e-05,
      "loss": 0.6752,
      "step": 662050
    },
    {
      "epoch": 7.009241958278857,
      "grad_norm": 4.742380142211914,
      "learning_rate": 1.4968716917213635e-05,
      "loss": 0.6647,
      "step": 662100
    },
    {
      "epoch": 7.00977128005886,
      "grad_norm": 4.392409801483154,
      "learning_rate": 1.4966070294304469e-05,
      "loss": 0.6639,
      "step": 662150
    },
    {
      "epoch": 7.010300601838864,
      "grad_norm": 4.379550933837891,
      "learning_rate": 1.49634236713953e-05,
      "loss": 0.6489,
      "step": 662200
    },
    {
      "epoch": 7.010829923618867,
      "grad_norm": 4.176843643188477,
      "learning_rate": 1.4960777048486132e-05,
      "loss": 0.6546,
      "step": 662250
    },
    {
      "epoch": 7.011359245398871,
      "grad_norm": 4.246420860290527,
      "learning_rate": 1.4958130425576963e-05,
      "loss": 0.6522,
      "step": 662300
    },
    {
      "epoch": 7.0118885671788735,
      "grad_norm": 4.780745983123779,
      "learning_rate": 1.4955483802667797e-05,
      "loss": 0.6741,
      "step": 662350
    },
    {
      "epoch": 7.012417888958877,
      "grad_norm": 4.050231456756592,
      "learning_rate": 1.4952837179758628e-05,
      "loss": 0.6608,
      "step": 662400
    },
    {
      "epoch": 7.01294721073888,
      "grad_norm": 4.41416072845459,
      "learning_rate": 1.495019055684946e-05,
      "loss": 0.6497,
      "step": 662450
    },
    {
      "epoch": 7.013476532518884,
      "grad_norm": 4.700114727020264,
      "learning_rate": 1.4947543933940291e-05,
      "loss": 0.6601,
      "step": 662500
    },
    {
      "epoch": 7.013476532518884,
      "eval_loss": 0.41438230872154236,
      "eval_runtime": 46.8594,
      "eval_samples_per_second": 3583.698,
      "eval_steps_per_second": 447.978,
      "step": 662500
    },
    {
      "epoch": 7.014005854298887,
      "grad_norm": 4.3608574867248535,
      "learning_rate": 1.4944897311031125e-05,
      "loss": 0.6613,
      "step": 662550
    },
    {
      "epoch": 7.0145351760788905,
      "grad_norm": 4.323401927947998,
      "learning_rate": 1.4942250688121956e-05,
      "loss": 0.6592,
      "step": 662600
    },
    {
      "epoch": 7.015064497858893,
      "grad_norm": 4.1114301681518555,
      "learning_rate": 1.493960406521279e-05,
      "loss": 0.6633,
      "step": 662650
    },
    {
      "epoch": 7.015593819638896,
      "grad_norm": 4.6038498878479,
      "learning_rate": 1.493695744230362e-05,
      "loss": 0.6742,
      "step": 662700
    },
    {
      "epoch": 7.0161231414189,
      "grad_norm": 4.438383102416992,
      "learning_rate": 1.4934310819394453e-05,
      "loss": 0.664,
      "step": 662750
    },
    {
      "epoch": 7.016652463198903,
      "grad_norm": 4.282803535461426,
      "learning_rate": 1.4931664196485284e-05,
      "loss": 0.6729,
      "step": 662800
    },
    {
      "epoch": 7.017181784978907,
      "grad_norm": 4.382914066314697,
      "learning_rate": 1.4929017573576118e-05,
      "loss": 0.6714,
      "step": 662850
    },
    {
      "epoch": 7.0177111067589095,
      "grad_norm": 3.8563284873962402,
      "learning_rate": 1.4926370950666948e-05,
      "loss": 0.6478,
      "step": 662900
    },
    {
      "epoch": 7.018240428538913,
      "grad_norm": 4.053443908691406,
      "learning_rate": 1.4923724327757783e-05,
      "loss": 0.6583,
      "step": 662950
    },
    {
      "epoch": 7.018769750318916,
      "grad_norm": 4.478448390960693,
      "learning_rate": 1.4921077704848613e-05,
      "loss": 0.6667,
      "step": 663000
    },
    {
      "epoch": 7.018769750318916,
      "eval_loss": 0.4143640995025635,
      "eval_runtime": 47.8429,
      "eval_samples_per_second": 3510.027,
      "eval_steps_per_second": 438.769,
      "step": 663000
    },
    {
      "epoch": 7.01929907209892,
      "grad_norm": 4.516490936279297,
      "learning_rate": 1.4918431081939446e-05,
      "loss": 0.6618,
      "step": 663050
    },
    {
      "epoch": 7.019828393878923,
      "grad_norm": 3.9415318965911865,
      "learning_rate": 1.4915784459030276e-05,
      "loss": 0.6633,
      "step": 663100
    },
    {
      "epoch": 7.0203577156589265,
      "grad_norm": 4.6381940841674805,
      "learning_rate": 1.491313783612111e-05,
      "loss": 0.6569,
      "step": 663150
    },
    {
      "epoch": 7.020887037438929,
      "grad_norm": 4.341254234313965,
      "learning_rate": 1.4910491213211941e-05,
      "loss": 0.6641,
      "step": 663200
    },
    {
      "epoch": 7.021416359218933,
      "grad_norm": 4.137578010559082,
      "learning_rate": 1.4907844590302775e-05,
      "loss": 0.662,
      "step": 663250
    },
    {
      "epoch": 7.021945680998936,
      "grad_norm": 4.741593360900879,
      "learning_rate": 1.4905197967393606e-05,
      "loss": 0.6553,
      "step": 663300
    },
    {
      "epoch": 7.02247500277894,
      "grad_norm": 4.710347652435303,
      "learning_rate": 1.4902551344484438e-05,
      "loss": 0.6535,
      "step": 663350
    },
    {
      "epoch": 7.023004324558943,
      "grad_norm": 4.243682384490967,
      "learning_rate": 1.4899904721575269e-05,
      "loss": 0.6652,
      "step": 663400
    },
    {
      "epoch": 7.0235336463389455,
      "grad_norm": 4.068661212921143,
      "learning_rate": 1.4897258098666103e-05,
      "loss": 0.655,
      "step": 663450
    },
    {
      "epoch": 7.024062968118949,
      "grad_norm": 4.414017677307129,
      "learning_rate": 1.4894611475756934e-05,
      "loss": 0.6531,
      "step": 663500
    },
    {
      "epoch": 7.024062968118949,
      "eval_loss": 0.4144206643104553,
      "eval_runtime": 46.69,
      "eval_samples_per_second": 3596.703,
      "eval_steps_per_second": 449.604,
      "step": 663500
    },
    {
      "epoch": 7.024592289898952,
      "grad_norm": 4.527901649475098,
      "learning_rate": 1.4891964852847768e-05,
      "loss": 0.6508,
      "step": 663550
    },
    {
      "epoch": 7.025121611678956,
      "grad_norm": 4.921234607696533,
      "learning_rate": 1.4889318229938599e-05,
      "loss": 0.6752,
      "step": 663600
    },
    {
      "epoch": 7.025650933458959,
      "grad_norm": 4.53092098236084,
      "learning_rate": 1.4886671607029431e-05,
      "loss": 0.6612,
      "step": 663650
    },
    {
      "epoch": 7.0261802552389625,
      "grad_norm": 4.5508599281311035,
      "learning_rate": 1.4884024984120262e-05,
      "loss": 0.6582,
      "step": 663700
    },
    {
      "epoch": 7.026709577018965,
      "grad_norm": 4.140183448791504,
      "learning_rate": 1.4881378361211096e-05,
      "loss": 0.6619,
      "step": 663750
    },
    {
      "epoch": 7.027238898798969,
      "grad_norm": 4.470216751098633,
      "learning_rate": 1.4878731738301927e-05,
      "loss": 0.6595,
      "step": 663800
    },
    {
      "epoch": 7.027768220578972,
      "grad_norm": 4.126825332641602,
      "learning_rate": 1.487608511539276e-05,
      "loss": 0.6483,
      "step": 663850
    },
    {
      "epoch": 7.028297542358976,
      "grad_norm": 4.236179828643799,
      "learning_rate": 1.4873438492483591e-05,
      "loss": 0.6652,
      "step": 663900
    },
    {
      "epoch": 7.028826864138979,
      "grad_norm": 4.530454158782959,
      "learning_rate": 1.4870791869574424e-05,
      "loss": 0.6651,
      "step": 663950
    },
    {
      "epoch": 7.029356185918982,
      "grad_norm": 4.338958263397217,
      "learning_rate": 1.4868145246665255e-05,
      "loss": 0.6627,
      "step": 664000
    },
    {
      "epoch": 7.029356185918982,
      "eval_loss": 0.4145871698856354,
      "eval_runtime": 46.7417,
      "eval_samples_per_second": 3592.724,
      "eval_steps_per_second": 449.107,
      "step": 664000
    },
    {
      "epoch": 7.029885507698985,
      "grad_norm": 4.1805524826049805,
      "learning_rate": 1.4865498623756089e-05,
      "loss": 0.6574,
      "step": 664050
    },
    {
      "epoch": 7.030414829478989,
      "grad_norm": 4.700011730194092,
      "learning_rate": 1.486285200084692e-05,
      "loss": 0.6441,
      "step": 664100
    },
    {
      "epoch": 7.030944151258992,
      "grad_norm": 4.586590766906738,
      "learning_rate": 1.4860258310395936e-05,
      "loss": 0.6663,
      "step": 664150
    },
    {
      "epoch": 7.031473473038995,
      "grad_norm": 4.819266319274902,
      "learning_rate": 1.4857611687486767e-05,
      "loss": 0.6566,
      "step": 664200
    },
    {
      "epoch": 7.0320027948189985,
      "grad_norm": 4.387720108032227,
      "learning_rate": 1.48549650645776e-05,
      "loss": 0.6637,
      "step": 664250
    },
    {
      "epoch": 7.032532116599001,
      "grad_norm": 4.107397079467773,
      "learning_rate": 1.4852318441668431e-05,
      "loss": 0.6619,
      "step": 664300
    },
    {
      "epoch": 7.033061438379005,
      "grad_norm": 4.336193561553955,
      "learning_rate": 1.4849671818759264e-05,
      "loss": 0.6583,
      "step": 664350
    },
    {
      "epoch": 7.033590760159008,
      "grad_norm": 4.699063777923584,
      "learning_rate": 1.4847025195850094e-05,
      "loss": 0.6618,
      "step": 664400
    },
    {
      "epoch": 7.034120081939012,
      "grad_norm": 4.3209309577941895,
      "learning_rate": 1.4844378572940929e-05,
      "loss": 0.6693,
      "step": 664450
    },
    {
      "epoch": 7.034649403719015,
      "grad_norm": 4.614543437957764,
      "learning_rate": 1.484173195003176e-05,
      "loss": 0.6555,
      "step": 664500
    },
    {
      "epoch": 7.034649403719015,
      "eval_loss": 0.4135414958000183,
      "eval_runtime": 46.4434,
      "eval_samples_per_second": 3615.796,
      "eval_steps_per_second": 451.991,
      "step": 664500
    },
    {
      "epoch": 7.035178725499018,
      "grad_norm": 4.454848289489746,
      "learning_rate": 1.4839085327122593e-05,
      "loss": 0.6609,
      "step": 664550
    },
    {
      "epoch": 7.035708047279021,
      "grad_norm": 4.003339767456055,
      "learning_rate": 1.4836438704213424e-05,
      "loss": 0.6489,
      "step": 664600
    },
    {
      "epoch": 7.036237369059025,
      "grad_norm": 4.284942626953125,
      "learning_rate": 1.4833792081304256e-05,
      "loss": 0.6601,
      "step": 664650
    },
    {
      "epoch": 7.036766690839028,
      "grad_norm": 4.230109691619873,
      "learning_rate": 1.4831145458395087e-05,
      "loss": 0.6469,
      "step": 664700
    },
    {
      "epoch": 7.037296012619032,
      "grad_norm": 4.790438652038574,
      "learning_rate": 1.4828498835485921e-05,
      "loss": 0.6709,
      "step": 664750
    },
    {
      "epoch": 7.0378253343990345,
      "grad_norm": 4.935598850250244,
      "learning_rate": 1.4825852212576752e-05,
      "loss": 0.6642,
      "step": 664800
    },
    {
      "epoch": 7.038354656179038,
      "grad_norm": 4.22140645980835,
      "learning_rate": 1.4823205589667586e-05,
      "loss": 0.6626,
      "step": 664850
    },
    {
      "epoch": 7.038883977959041,
      "grad_norm": 4.725918769836426,
      "learning_rate": 1.4820558966758417e-05,
      "loss": 0.6613,
      "step": 664900
    },
    {
      "epoch": 7.039413299739044,
      "grad_norm": 4.267512798309326,
      "learning_rate": 1.481791234384925e-05,
      "loss": 0.6638,
      "step": 664950
    },
    {
      "epoch": 7.039942621519048,
      "grad_norm": 4.257515907287598,
      "learning_rate": 1.481526572094008e-05,
      "loss": 0.6595,
      "step": 665000
    },
    {
      "epoch": 7.039942621519048,
      "eval_loss": 0.4140261113643646,
      "eval_runtime": 46.5052,
      "eval_samples_per_second": 3610.994,
      "eval_steps_per_second": 451.39,
      "step": 665000
    },
    {
      "epoch": 7.040471943299051,
      "grad_norm": 4.796934604644775,
      "learning_rate": 1.4812619098030914e-05,
      "loss": 0.6573,
      "step": 665050
    },
    {
      "epoch": 7.041001265079054,
      "grad_norm": 4.427351951599121,
      "learning_rate": 1.4809972475121745e-05,
      "loss": 0.6571,
      "step": 665100
    },
    {
      "epoch": 7.041530586859057,
      "grad_norm": 4.81017541885376,
      "learning_rate": 1.4807325852212577e-05,
      "loss": 0.6573,
      "step": 665150
    },
    {
      "epoch": 7.042059908639061,
      "grad_norm": 4.362213134765625,
      "learning_rate": 1.4804679229303408e-05,
      "loss": 0.6542,
      "step": 665200
    },
    {
      "epoch": 7.042589230419064,
      "grad_norm": 4.598365783691406,
      "learning_rate": 1.4802032606394242e-05,
      "loss": 0.6639,
      "step": 665250
    },
    {
      "epoch": 7.043118552199068,
      "grad_norm": 4.6853718757629395,
      "learning_rate": 1.4799385983485073e-05,
      "loss": 0.6531,
      "step": 665300
    },
    {
      "epoch": 7.04364787397907,
      "grad_norm": 4.683344841003418,
      "learning_rate": 1.4796739360575907e-05,
      "loss": 0.661,
      "step": 665350
    },
    {
      "epoch": 7.044177195759074,
      "grad_norm": 4.537569999694824,
      "learning_rate": 1.4794092737666738e-05,
      "loss": 0.67,
      "step": 665400
    },
    {
      "epoch": 7.044706517539077,
      "grad_norm": 4.2701802253723145,
      "learning_rate": 1.479144611475757e-05,
      "loss": 0.6597,
      "step": 665450
    },
    {
      "epoch": 7.045235839319081,
      "grad_norm": 4.6815924644470215,
      "learning_rate": 1.47887994918484e-05,
      "loss": 0.6559,
      "step": 665500
    },
    {
      "epoch": 7.045235839319081,
      "eval_loss": 0.4142623543739319,
      "eval_runtime": 46.762,
      "eval_samples_per_second": 3591.167,
      "eval_steps_per_second": 448.912,
      "step": 665500
    },
    {
      "epoch": 7.045765161099084,
      "grad_norm": 4.553589344024658,
      "learning_rate": 1.4786152868939235e-05,
      "loss": 0.6629,
      "step": 665550
    },
    {
      "epoch": 7.046294482879087,
      "grad_norm": 4.446694374084473,
      "learning_rate": 1.4783506246030065e-05,
      "loss": 0.6685,
      "step": 665600
    },
    {
      "epoch": 7.04682380465909,
      "grad_norm": 4.36301326751709,
      "learning_rate": 1.47808596231209e-05,
      "loss": 0.6575,
      "step": 665650
    },
    {
      "epoch": 7.047353126439093,
      "grad_norm": 4.702447891235352,
      "learning_rate": 1.477821300021173e-05,
      "loss": 0.6663,
      "step": 665700
    },
    {
      "epoch": 7.047882448219097,
      "grad_norm": 4.419005393981934,
      "learning_rate": 1.4775566377302563e-05,
      "loss": 0.6584,
      "step": 665750
    },
    {
      "epoch": 7.0484117699991,
      "grad_norm": 4.168516159057617,
      "learning_rate": 1.4772919754393393e-05,
      "loss": 0.6639,
      "step": 665800
    },
    {
      "epoch": 7.0489410917791036,
      "grad_norm": 4.626046180725098,
      "learning_rate": 1.4770273131484227e-05,
      "loss": 0.6658,
      "step": 665850
    },
    {
      "epoch": 7.049470413559106,
      "grad_norm": 4.460447311401367,
      "learning_rate": 1.4767626508575058e-05,
      "loss": 0.673,
      "step": 665900
    },
    {
      "epoch": 7.04999973533911,
      "grad_norm": 4.597391128540039,
      "learning_rate": 1.4764979885665892e-05,
      "loss": 0.6596,
      "step": 665950
    },
    {
      "epoch": 7.050529057119113,
      "grad_norm": 4.292102813720703,
      "learning_rate": 1.4762333262756723e-05,
      "loss": 0.6494,
      "step": 666000
    },
    {
      "epoch": 7.050529057119113,
      "eval_loss": 0.4133804738521576,
      "eval_runtime": 46.5836,
      "eval_samples_per_second": 3604.919,
      "eval_steps_per_second": 450.631,
      "step": 666000
    },
    {
      "epoch": 7.051058378899117,
      "grad_norm": 4.270120620727539,
      "learning_rate": 1.4759686639847555e-05,
      "loss": 0.6588,
      "step": 666050
    },
    {
      "epoch": 7.05158770067912,
      "grad_norm": 4.57716703414917,
      "learning_rate": 1.4757040016938386e-05,
      "loss": 0.6745,
      "step": 666100
    },
    {
      "epoch": 7.052117022459123,
      "grad_norm": 4.4629621505737305,
      "learning_rate": 1.4754446326487403e-05,
      "loss": 0.6613,
      "step": 666150
    },
    {
      "epoch": 7.052646344239126,
      "grad_norm": 4.220473289489746,
      "learning_rate": 1.4751799703578233e-05,
      "loss": 0.6691,
      "step": 666200
    },
    {
      "epoch": 7.05317566601913,
      "grad_norm": 4.323399066925049,
      "learning_rate": 1.4749153080669067e-05,
      "loss": 0.6705,
      "step": 666250
    },
    {
      "epoch": 7.053704987799133,
      "grad_norm": 4.048429012298584,
      "learning_rate": 1.4746506457759898e-05,
      "loss": 0.6628,
      "step": 666300
    },
    {
      "epoch": 7.054234309579137,
      "grad_norm": 4.899420738220215,
      "learning_rate": 1.4743859834850732e-05,
      "loss": 0.6613,
      "step": 666350
    },
    {
      "epoch": 7.0547636313591395,
      "grad_norm": 4.178525447845459,
      "learning_rate": 1.4741213211941563e-05,
      "loss": 0.6551,
      "step": 666400
    },
    {
      "epoch": 7.055292953139142,
      "grad_norm": 4.614521503448486,
      "learning_rate": 1.4738566589032395e-05,
      "loss": 0.6718,
      "step": 666450
    },
    {
      "epoch": 7.055822274919146,
      "grad_norm": 4.482399940490723,
      "learning_rate": 1.4735919966123226e-05,
      "loss": 0.6523,
      "step": 666500
    },
    {
      "epoch": 7.055822274919146,
      "eval_loss": 0.4137313663959503,
      "eval_runtime": 46.4229,
      "eval_samples_per_second": 3617.395,
      "eval_steps_per_second": 452.191,
      "step": 666500
    },
    {
      "epoch": 7.056351596699149,
      "grad_norm": 4.437877178192139,
      "learning_rate": 1.473327334321406e-05,
      "loss": 0.653,
      "step": 666550
    },
    {
      "epoch": 7.056880918479153,
      "grad_norm": 4.9777045249938965,
      "learning_rate": 1.473062672030489e-05,
      "loss": 0.6552,
      "step": 666600
    },
    {
      "epoch": 7.057410240259156,
      "grad_norm": 4.232525825500488,
      "learning_rate": 1.4727980097395725e-05,
      "loss": 0.6508,
      "step": 666650
    },
    {
      "epoch": 7.057939562039159,
      "grad_norm": 4.555388450622559,
      "learning_rate": 1.4725333474486556e-05,
      "loss": 0.6601,
      "step": 666700
    },
    {
      "epoch": 7.058468883819162,
      "grad_norm": 4.740337371826172,
      "learning_rate": 1.4722686851577388e-05,
      "loss": 0.6561,
      "step": 666750
    },
    {
      "epoch": 7.058998205599166,
      "grad_norm": 4.758585453033447,
      "learning_rate": 1.4720040228668219e-05,
      "loss": 0.6612,
      "step": 666800
    },
    {
      "epoch": 7.059527527379169,
      "grad_norm": 4.220231056213379,
      "learning_rate": 1.4717393605759053e-05,
      "loss": 0.665,
      "step": 666850
    },
    {
      "epoch": 7.060056849159173,
      "grad_norm": 4.473320960998535,
      "learning_rate": 1.4714746982849884e-05,
      "loss": 0.6706,
      "step": 666900
    },
    {
      "epoch": 7.0605861709391755,
      "grad_norm": 4.73814058303833,
      "learning_rate": 1.4712100359940718e-05,
      "loss": 0.6596,
      "step": 666950
    },
    {
      "epoch": 7.061115492719179,
      "grad_norm": 4.808725357055664,
      "learning_rate": 1.4709453737031548e-05,
      "loss": 0.6711,
      "step": 667000
    },
    {
      "epoch": 7.061115492719179,
      "eval_loss": 0.4128323197364807,
      "eval_runtime": 46.5168,
      "eval_samples_per_second": 3610.092,
      "eval_steps_per_second": 451.278,
      "step": 667000
    },
    {
      "epoch": 7.061644814499182,
      "grad_norm": 4.290061950683594,
      "learning_rate": 1.470680711412238e-05,
      "loss": 0.6679,
      "step": 667050
    },
    {
      "epoch": 7.062174136279186,
      "grad_norm": 4.135519027709961,
      "learning_rate": 1.4704160491213211e-05,
      "loss": 0.661,
      "step": 667100
    },
    {
      "epoch": 7.062703458059189,
      "grad_norm": 4.608026027679443,
      "learning_rate": 1.4701513868304046e-05,
      "loss": 0.6562,
      "step": 667150
    },
    {
      "epoch": 7.063232779839192,
      "grad_norm": 4.270599365234375,
      "learning_rate": 1.4698867245394876e-05,
      "loss": 0.6659,
      "step": 667200
    },
    {
      "epoch": 7.063762101619195,
      "grad_norm": 4.187163829803467,
      "learning_rate": 1.469622062248571e-05,
      "loss": 0.6491,
      "step": 667250
    },
    {
      "epoch": 7.064291423399198,
      "grad_norm": 4.674928188323975,
      "learning_rate": 1.4693573999576541e-05,
      "loss": 0.6636,
      "step": 667300
    },
    {
      "epoch": 7.064820745179202,
      "grad_norm": 4.885665416717529,
      "learning_rate": 1.4690927376667373e-05,
      "loss": 0.6549,
      "step": 667350
    },
    {
      "epoch": 7.065350066959205,
      "grad_norm": 4.515263080596924,
      "learning_rate": 1.4688280753758204e-05,
      "loss": 0.666,
      "step": 667400
    },
    {
      "epoch": 7.065879388739209,
      "grad_norm": 4.2260003089904785,
      "learning_rate": 1.4685634130849038e-05,
      "loss": 0.6545,
      "step": 667450
    },
    {
      "epoch": 7.0664087105192115,
      "grad_norm": 4.377190589904785,
      "learning_rate": 1.4682987507939869e-05,
      "loss": 0.6604,
      "step": 667500
    },
    {
      "epoch": 7.0664087105192115,
      "eval_loss": 0.4133583903312683,
      "eval_runtime": 46.8248,
      "eval_samples_per_second": 3586.351,
      "eval_steps_per_second": 448.31,
      "step": 667500
    },
    {
      "epoch": 7.066938032299215,
      "grad_norm": 4.736937999725342,
      "learning_rate": 1.4680340885030703e-05,
      "loss": 0.6732,
      "step": 667550
    },
    {
      "epoch": 7.067467354079218,
      "grad_norm": 4.482842922210693,
      "learning_rate": 1.4677694262121534e-05,
      "loss": 0.6587,
      "step": 667600
    },
    {
      "epoch": 7.067996675859222,
      "grad_norm": 4.289826393127441,
      "learning_rate": 1.4675047639212366e-05,
      "loss": 0.6468,
      "step": 667650
    },
    {
      "epoch": 7.068525997639225,
      "grad_norm": 4.604966640472412,
      "learning_rate": 1.4672401016303197e-05,
      "loss": 0.67,
      "step": 667700
    },
    {
      "epoch": 7.0690553194192285,
      "grad_norm": 4.185263633728027,
      "learning_rate": 1.4669754393394031e-05,
      "loss": 0.6499,
      "step": 667750
    },
    {
      "epoch": 7.069584641199231,
      "grad_norm": 4.468148231506348,
      "learning_rate": 1.4667107770484862e-05,
      "loss": 0.646,
      "step": 667800
    },
    {
      "epoch": 7.070113962979235,
      "grad_norm": 4.467811107635498,
      "learning_rate": 1.4664461147575694e-05,
      "loss": 0.6533,
      "step": 667850
    },
    {
      "epoch": 7.070643284759238,
      "grad_norm": 4.522204399108887,
      "learning_rate": 1.4661814524666525e-05,
      "loss": 0.6624,
      "step": 667900
    },
    {
      "epoch": 7.071172606539241,
      "grad_norm": 3.957115411758423,
      "learning_rate": 1.4659167901757359e-05,
      "loss": 0.6641,
      "step": 667950
    },
    {
      "epoch": 7.071701928319245,
      "grad_norm": 4.102015972137451,
      "learning_rate": 1.465652127884819e-05,
      "loss": 0.6471,
      "step": 668000
    },
    {
      "epoch": 7.071701928319245,
      "eval_loss": 0.4126591086387634,
      "eval_runtime": 46.4621,
      "eval_samples_per_second": 3614.34,
      "eval_steps_per_second": 451.809,
      "step": 668000
    },
    {
      "epoch": 7.0722312500992475,
      "grad_norm": 4.598767280578613,
      "learning_rate": 1.4653874655939024e-05,
      "loss": 0.6582,
      "step": 668050
    },
    {
      "epoch": 7.072760571879251,
      "grad_norm": 4.375391006469727,
      "learning_rate": 1.4651228033029854e-05,
      "loss": 0.6532,
      "step": 668100
    },
    {
      "epoch": 7.073289893659254,
      "grad_norm": 4.304008483886719,
      "learning_rate": 1.4648634342578871e-05,
      "loss": 0.6737,
      "step": 668150
    },
    {
      "epoch": 7.073819215439258,
      "grad_norm": 4.481655597686768,
      "learning_rate": 1.4645987719669702e-05,
      "loss": 0.6675,
      "step": 668200
    },
    {
      "epoch": 7.074348537219261,
      "grad_norm": 4.541194438934326,
      "learning_rate": 1.4643341096760536e-05,
      "loss": 0.6702,
      "step": 668250
    },
    {
      "epoch": 7.0748778589992645,
      "grad_norm": 4.531459808349609,
      "learning_rate": 1.4640694473851366e-05,
      "loss": 0.6572,
      "step": 668300
    },
    {
      "epoch": 7.075407180779267,
      "grad_norm": 4.2602996826171875,
      "learning_rate": 1.4638047850942199e-05,
      "loss": 0.6656,
      "step": 668350
    },
    {
      "epoch": 7.075936502559271,
      "grad_norm": 4.714108467102051,
      "learning_rate": 1.463540122803303e-05,
      "loss": 0.6571,
      "step": 668400
    },
    {
      "epoch": 7.076465824339274,
      "grad_norm": 4.643573760986328,
      "learning_rate": 1.4632754605123864e-05,
      "loss": 0.6595,
      "step": 668450
    },
    {
      "epoch": 7.076995146119278,
      "grad_norm": 3.916422128677368,
      "learning_rate": 1.4630107982214694e-05,
      "loss": 0.665,
      "step": 668500
    },
    {
      "epoch": 7.076995146119278,
      "eval_loss": 0.41332224011421204,
      "eval_runtime": 46.4802,
      "eval_samples_per_second": 3612.933,
      "eval_steps_per_second": 451.633,
      "step": 668500
    },
    {
      "epoch": 7.077524467899281,
      "grad_norm": 4.170755863189697,
      "learning_rate": 1.4627461359305528e-05,
      "loss": 0.6598,
      "step": 668550
    },
    {
      "epoch": 7.078053789679284,
      "grad_norm": 4.461061954498291,
      "learning_rate": 1.4624814736396359e-05,
      "loss": 0.6636,
      "step": 668600
    },
    {
      "epoch": 7.078583111459287,
      "grad_norm": 4.497015953063965,
      "learning_rate": 1.4622168113487192e-05,
      "loss": 0.6659,
      "step": 668650
    },
    {
      "epoch": 7.07911243323929,
      "grad_norm": 4.292120456695557,
      "learning_rate": 1.4619521490578022e-05,
      "loss": 0.6711,
      "step": 668700
    },
    {
      "epoch": 7.079641755019294,
      "grad_norm": 4.879794120788574,
      "learning_rate": 1.4616874867668856e-05,
      "loss": 0.6702,
      "step": 668750
    },
    {
      "epoch": 7.080171076799297,
      "grad_norm": 4.118964195251465,
      "learning_rate": 1.4614228244759687e-05,
      "loss": 0.654,
      "step": 668800
    },
    {
      "epoch": 7.0807003985793004,
      "grad_norm": 4.8069233894348145,
      "learning_rate": 1.461158162185052e-05,
      "loss": 0.6561,
      "step": 668850
    },
    {
      "epoch": 7.081229720359303,
      "grad_norm": 4.47157621383667,
      "learning_rate": 1.460893499894135e-05,
      "loss": 0.663,
      "step": 668900
    },
    {
      "epoch": 7.081759042139307,
      "grad_norm": 4.867089748382568,
      "learning_rate": 1.4606288376032184e-05,
      "loss": 0.6534,
      "step": 668950
    },
    {
      "epoch": 7.08228836391931,
      "grad_norm": 4.813032627105713,
      "learning_rate": 1.4603641753123015e-05,
      "loss": 0.6659,
      "step": 669000
    },
    {
      "epoch": 7.08228836391931,
      "eval_loss": 0.4125385582447052,
      "eval_runtime": 47.4204,
      "eval_samples_per_second": 3541.3,
      "eval_steps_per_second": 442.678,
      "step": 669000
    },
    {
      "epoch": 7.082817685699314,
      "grad_norm": 4.578987121582031,
      "learning_rate": 1.4600995130213849e-05,
      "loss": 0.6654,
      "step": 669050
    },
    {
      "epoch": 7.083347007479317,
      "grad_norm": 4.152286052703857,
      "learning_rate": 1.459834850730468e-05,
      "loss": 0.654,
      "step": 669100
    },
    {
      "epoch": 7.08387632925932,
      "grad_norm": 4.523746967315674,
      "learning_rate": 1.4595701884395512e-05,
      "loss": 0.6403,
      "step": 669150
    },
    {
      "epoch": 7.084405651039323,
      "grad_norm": 4.63433313369751,
      "learning_rate": 1.4593055261486343e-05,
      "loss": 0.6611,
      "step": 669200
    },
    {
      "epoch": 7.084934972819327,
      "grad_norm": 4.496603965759277,
      "learning_rate": 1.4590408638577177e-05,
      "loss": 0.6547,
      "step": 669250
    },
    {
      "epoch": 7.08546429459933,
      "grad_norm": 4.239340305328369,
      "learning_rate": 1.4587762015668008e-05,
      "loss": 0.6534,
      "step": 669300
    },
    {
      "epoch": 7.085993616379334,
      "grad_norm": 4.205054759979248,
      "learning_rate": 1.4585115392758842e-05,
      "loss": 0.6456,
      "step": 669350
    },
    {
      "epoch": 7.086522938159336,
      "grad_norm": 4.814754962921143,
      "learning_rate": 1.4582468769849673e-05,
      "loss": 0.6615,
      "step": 669400
    },
    {
      "epoch": 7.087052259939339,
      "grad_norm": 4.141522407531738,
      "learning_rate": 1.4579822146940505e-05,
      "loss": 0.6668,
      "step": 669450
    },
    {
      "epoch": 7.087581581719343,
      "grad_norm": 4.463987350463867,
      "learning_rate": 1.4577175524031336e-05,
      "loss": 0.6527,
      "step": 669500
    },
    {
      "epoch": 7.087581581719343,
      "eval_loss": 0.41304197907447815,
      "eval_runtime": 47.5977,
      "eval_samples_per_second": 3528.114,
      "eval_steps_per_second": 441.03,
      "step": 669500
    },
    {
      "epoch": 7.088110903499346,
      "grad_norm": 4.591468811035156,
      "learning_rate": 1.457452890112217e-05,
      "loss": 0.665,
      "step": 669550
    },
    {
      "epoch": 7.08864022527935,
      "grad_norm": 4.37481689453125,
      "learning_rate": 1.4571882278213e-05,
      "loss": 0.6689,
      "step": 669600
    },
    {
      "epoch": 7.0891695470593525,
      "grad_norm": 4.481932640075684,
      "learning_rate": 1.4569235655303835e-05,
      "loss": 0.6536,
      "step": 669650
    },
    {
      "epoch": 7.089698868839356,
      "grad_norm": 4.289446830749512,
      "learning_rate": 1.4566589032394665e-05,
      "loss": 0.6558,
      "step": 669700
    },
    {
      "epoch": 7.090228190619359,
      "grad_norm": 4.45254373550415,
      "learning_rate": 1.4563942409485498e-05,
      "loss": 0.6525,
      "step": 669750
    },
    {
      "epoch": 7.090757512399363,
      "grad_norm": 4.334482192993164,
      "learning_rate": 1.4561295786576328e-05,
      "loss": 0.6652,
      "step": 669800
    },
    {
      "epoch": 7.091286834179366,
      "grad_norm": 4.408713340759277,
      "learning_rate": 1.4558649163667163e-05,
      "loss": 0.6684,
      "step": 669850
    },
    {
      "epoch": 7.0918161559593695,
      "grad_norm": 3.899139881134033,
      "learning_rate": 1.4556002540757993e-05,
      "loss": 0.6517,
      "step": 669900
    },
    {
      "epoch": 7.092345477739372,
      "grad_norm": 4.692735195159912,
      "learning_rate": 1.4553355917848827e-05,
      "loss": 0.6667,
      "step": 669950
    },
    {
      "epoch": 7.092874799519376,
      "grad_norm": 4.025411605834961,
      "learning_rate": 1.4550709294939658e-05,
      "loss": 0.6538,
      "step": 670000
    },
    {
      "epoch": 7.092874799519376,
      "eval_loss": 0.41263216733932495,
      "eval_runtime": 47.0963,
      "eval_samples_per_second": 3565.676,
      "eval_steps_per_second": 445.725,
      "step": 670000
    },
    {
      "epoch": 7.093404121299379,
      "grad_norm": 4.029808521270752,
      "learning_rate": 1.454806267203049e-05,
      "loss": 0.646,
      "step": 670050
    },
    {
      "epoch": 7.093933443079383,
      "grad_norm": 4.241999626159668,
      "learning_rate": 1.4545416049121321e-05,
      "loss": 0.6586,
      "step": 670100
    },
    {
      "epoch": 7.094462764859386,
      "grad_norm": 4.659735202789307,
      "learning_rate": 1.4542822358670338e-05,
      "loss": 0.6656,
      "step": 670150
    },
    {
      "epoch": 7.0949920866393885,
      "grad_norm": 4.337559700012207,
      "learning_rate": 1.4540175735761168e-05,
      "loss": 0.6624,
      "step": 670200
    },
    {
      "epoch": 7.095521408419392,
      "grad_norm": 4.3913774490356445,
      "learning_rate": 1.4537529112852002e-05,
      "loss": 0.6691,
      "step": 670250
    },
    {
      "epoch": 7.096050730199395,
      "grad_norm": 4.599162578582764,
      "learning_rate": 1.4534882489942833e-05,
      "loss": 0.6654,
      "step": 670300
    },
    {
      "epoch": 7.096580051979399,
      "grad_norm": 4.2404022216796875,
      "learning_rate": 1.4532235867033667e-05,
      "loss": 0.6664,
      "step": 670350
    },
    {
      "epoch": 7.097109373759402,
      "grad_norm": 4.41060733795166,
      "learning_rate": 1.4529589244124498e-05,
      "loss": 0.6667,
      "step": 670400
    },
    {
      "epoch": 7.0976386955394055,
      "grad_norm": 4.7846527099609375,
      "learning_rate": 1.452694262121533e-05,
      "loss": 0.6693,
      "step": 670450
    },
    {
      "epoch": 7.098168017319408,
      "grad_norm": 4.164357662200928,
      "learning_rate": 1.4524295998306161e-05,
      "loss": 0.6595,
      "step": 670500
    },
    {
      "epoch": 7.098168017319408,
      "eval_loss": 0.4126540422439575,
      "eval_runtime": 46.7929,
      "eval_samples_per_second": 3588.795,
      "eval_steps_per_second": 448.615,
      "step": 670500
    },
    {
      "epoch": 7.098697339099412,
      "grad_norm": 3.9509549140930176,
      "learning_rate": 1.4521649375396995e-05,
      "loss": 0.6653,
      "step": 670550
    },
    {
      "epoch": 7.099226660879415,
      "grad_norm": 4.581382751464844,
      "learning_rate": 1.4519002752487826e-05,
      "loss": 0.6619,
      "step": 670600
    },
    {
      "epoch": 7.099755982659419,
      "grad_norm": 4.564737796783447,
      "learning_rate": 1.451635612957866e-05,
      "loss": 0.6589,
      "step": 670650
    },
    {
      "epoch": 7.100285304439422,
      "grad_norm": 4.619837760925293,
      "learning_rate": 1.451370950666949e-05,
      "loss": 0.6584,
      "step": 670700
    },
    {
      "epoch": 7.100814626219425,
      "grad_norm": 4.366358280181885,
      "learning_rate": 1.4511062883760323e-05,
      "loss": 0.6723,
      "step": 670750
    },
    {
      "epoch": 7.101343947999428,
      "grad_norm": 4.528993606567383,
      "learning_rate": 1.4508416260851154e-05,
      "loss": 0.6596,
      "step": 670800
    },
    {
      "epoch": 7.101873269779432,
      "grad_norm": 4.3662238121032715,
      "learning_rate": 1.4505769637941988e-05,
      "loss": 0.6617,
      "step": 670850
    },
    {
      "epoch": 7.102402591559435,
      "grad_norm": 4.234525680541992,
      "learning_rate": 1.4503123015032819e-05,
      "loss": 0.6741,
      "step": 670900
    },
    {
      "epoch": 7.102931913339438,
      "grad_norm": 4.71732234954834,
      "learning_rate": 1.4500476392123653e-05,
      "loss": 0.6535,
      "step": 670950
    },
    {
      "epoch": 7.1034612351194415,
      "grad_norm": 4.222590446472168,
      "learning_rate": 1.4497829769214483e-05,
      "loss": 0.6618,
      "step": 671000
    },
    {
      "epoch": 7.1034612351194415,
      "eval_loss": 0.41386324167251587,
      "eval_runtime": 46.991,
      "eval_samples_per_second": 3573.665,
      "eval_steps_per_second": 446.724,
      "step": 671000
    },
    {
      "epoch": 7.103990556899444,
      "grad_norm": 4.668604850769043,
      "learning_rate": 1.4495183146305316e-05,
      "loss": 0.6452,
      "step": 671050
    },
    {
      "epoch": 7.104519878679448,
      "grad_norm": 4.879627227783203,
      "learning_rate": 1.4492536523396146e-05,
      "loss": 0.6571,
      "step": 671100
    },
    {
      "epoch": 7.105049200459451,
      "grad_norm": 4.464175224304199,
      "learning_rate": 1.448988990048698e-05,
      "loss": 0.6608,
      "step": 671150
    },
    {
      "epoch": 7.105578522239455,
      "grad_norm": 4.279108047485352,
      "learning_rate": 1.4487243277577811e-05,
      "loss": 0.6601,
      "step": 671200
    },
    {
      "epoch": 7.106107844019458,
      "grad_norm": 4.511038780212402,
      "learning_rate": 1.4484596654668645e-05,
      "loss": 0.6642,
      "step": 671250
    },
    {
      "epoch": 7.106637165799461,
      "grad_norm": 4.746034622192383,
      "learning_rate": 1.4481950031759476e-05,
      "loss": 0.6522,
      "step": 671300
    },
    {
      "epoch": 7.107166487579464,
      "grad_norm": 4.411550998687744,
      "learning_rate": 1.4479303408850309e-05,
      "loss": 0.6519,
      "step": 671350
    },
    {
      "epoch": 7.107695809359468,
      "grad_norm": 4.507890701293945,
      "learning_rate": 1.447665678594114e-05,
      "loss": 0.6647,
      "step": 671400
    },
    {
      "epoch": 7.108225131139471,
      "grad_norm": 4.234639644622803,
      "learning_rate": 1.4474010163031973e-05,
      "loss": 0.6698,
      "step": 671450
    },
    {
      "epoch": 7.108754452919475,
      "grad_norm": 4.264348030090332,
      "learning_rate": 1.4471363540122804e-05,
      "loss": 0.6593,
      "step": 671500
    },
    {
      "epoch": 7.108754452919475,
      "eval_loss": 0.4127885401248932,
      "eval_runtime": 47.1791,
      "eval_samples_per_second": 3559.413,
      "eval_steps_per_second": 444.943,
      "step": 671500
    },
    {
      "epoch": 7.1092837746994775,
      "grad_norm": 4.41942834854126,
      "learning_rate": 1.4468716917213636e-05,
      "loss": 0.6605,
      "step": 671550
    },
    {
      "epoch": 7.109813096479481,
      "grad_norm": 4.712803840637207,
      "learning_rate": 1.4466070294304467e-05,
      "loss": 0.6614,
      "step": 671600
    },
    {
      "epoch": 7.110342418259484,
      "grad_norm": 4.644474029541016,
      "learning_rate": 1.4463423671395301e-05,
      "loss": 0.6608,
      "step": 671650
    },
    {
      "epoch": 7.110871740039487,
      "grad_norm": 4.422471523284912,
      "learning_rate": 1.4460777048486132e-05,
      "loss": 0.653,
      "step": 671700
    },
    {
      "epoch": 7.111401061819491,
      "grad_norm": 4.078002452850342,
      "learning_rate": 1.4458130425576966e-05,
      "loss": 0.6637,
      "step": 671750
    },
    {
      "epoch": 7.111930383599494,
      "grad_norm": 4.339742660522461,
      "learning_rate": 1.4455483802667797e-05,
      "loss": 0.6611,
      "step": 671800
    },
    {
      "epoch": 7.112459705379497,
      "grad_norm": 4.131690502166748,
      "learning_rate": 1.445283717975863e-05,
      "loss": 0.6568,
      "step": 671850
    },
    {
      "epoch": 7.1129890271595,
      "grad_norm": 4.570811748504639,
      "learning_rate": 1.445019055684946e-05,
      "loss": 0.6657,
      "step": 671900
    },
    {
      "epoch": 7.113518348939504,
      "grad_norm": 4.6265716552734375,
      "learning_rate": 1.4447543933940294e-05,
      "loss": 0.6688,
      "step": 671950
    },
    {
      "epoch": 7.114047670719507,
      "grad_norm": 4.662102222442627,
      "learning_rate": 1.4444897311031125e-05,
      "loss": 0.6565,
      "step": 672000
    },
    {
      "epoch": 7.114047670719507,
      "eval_loss": 0.4126664102077484,
      "eval_runtime": 47.0167,
      "eval_samples_per_second": 3571.707,
      "eval_steps_per_second": 446.479,
      "step": 672000
    },
    {
      "epoch": 7.114576992499511,
      "grad_norm": 4.61066198348999,
      "learning_rate": 1.4442250688121959e-05,
      "loss": 0.6619,
      "step": 672050
    },
    {
      "epoch": 7.1151063142795135,
      "grad_norm": 4.282546520233154,
      "learning_rate": 1.443960406521279e-05,
      "loss": 0.6584,
      "step": 672100
    },
    {
      "epoch": 7.115635636059517,
      "grad_norm": 4.154065132141113,
      "learning_rate": 1.4437010374761806e-05,
      "loss": 0.6639,
      "step": 672150
    },
    {
      "epoch": 7.11616495783952,
      "grad_norm": 4.183884143829346,
      "learning_rate": 1.4434363751852637e-05,
      "loss": 0.6592,
      "step": 672200
    },
    {
      "epoch": 7.116694279619524,
      "grad_norm": 4.651855945587158,
      "learning_rate": 1.443171712894347e-05,
      "loss": 0.6663,
      "step": 672250
    },
    {
      "epoch": 7.117223601399527,
      "grad_norm": 4.4378180503845215,
      "learning_rate": 1.4429070506034301e-05,
      "loss": 0.6651,
      "step": 672300
    },
    {
      "epoch": 7.1177529231795305,
      "grad_norm": 4.5904221534729,
      "learning_rate": 1.4426423883125134e-05,
      "loss": 0.6511,
      "step": 672350
    },
    {
      "epoch": 7.118282244959533,
      "grad_norm": 4.290958404541016,
      "learning_rate": 1.4423777260215965e-05,
      "loss": 0.6514,
      "step": 672400
    },
    {
      "epoch": 7.118811566739536,
      "grad_norm": 4.645071983337402,
      "learning_rate": 1.4421130637306799e-05,
      "loss": 0.6543,
      "step": 672450
    },
    {
      "epoch": 7.11934088851954,
      "grad_norm": 4.602258682250977,
      "learning_rate": 1.441848401439763e-05,
      "loss": 0.6548,
      "step": 672500
    },
    {
      "epoch": 7.11934088851954,
      "eval_loss": 0.41235774755477905,
      "eval_runtime": 46.9961,
      "eval_samples_per_second": 3573.278,
      "eval_steps_per_second": 446.676,
      "step": 672500
    },
    {
      "epoch": 7.119870210299543,
      "grad_norm": 4.156679630279541,
      "learning_rate": 1.4415837391488462e-05,
      "loss": 0.6644,
      "step": 672550
    },
    {
      "epoch": 7.120399532079547,
      "grad_norm": 4.118748188018799,
      "learning_rate": 1.4413190768579292e-05,
      "loss": 0.6581,
      "step": 672600
    },
    {
      "epoch": 7.120928853859549,
      "grad_norm": 4.943032741546631,
      "learning_rate": 1.4410544145670127e-05,
      "loss": 0.6554,
      "step": 672650
    },
    {
      "epoch": 7.121458175639553,
      "grad_norm": 4.85844612121582,
      "learning_rate": 1.4407897522760957e-05,
      "loss": 0.676,
      "step": 672700
    },
    {
      "epoch": 7.121987497419556,
      "grad_norm": 4.535256862640381,
      "learning_rate": 1.4405250899851791e-05,
      "loss": 0.6701,
      "step": 672750
    },
    {
      "epoch": 7.12251681919956,
      "grad_norm": 4.445535659790039,
      "learning_rate": 1.4402604276942622e-05,
      "loss": 0.6608,
      "step": 672800
    },
    {
      "epoch": 7.123046140979563,
      "grad_norm": 4.698390960693359,
      "learning_rate": 1.4399957654033455e-05,
      "loss": 0.6721,
      "step": 672850
    },
    {
      "epoch": 7.123575462759566,
      "grad_norm": 4.09761381149292,
      "learning_rate": 1.4397311031124285e-05,
      "loss": 0.6473,
      "step": 672900
    },
    {
      "epoch": 7.124104784539569,
      "grad_norm": 4.253385543823242,
      "learning_rate": 1.439466440821512e-05,
      "loss": 0.6495,
      "step": 672950
    },
    {
      "epoch": 7.124634106319573,
      "grad_norm": 4.512658596038818,
      "learning_rate": 1.439201778530595e-05,
      "loss": 0.6563,
      "step": 673000
    },
    {
      "epoch": 7.124634106319573,
      "eval_loss": 0.41308996081352234,
      "eval_runtime": 46.945,
      "eval_samples_per_second": 3577.166,
      "eval_steps_per_second": 447.162,
      "step": 673000
    },
    {
      "epoch": 7.125163428099576,
      "grad_norm": 4.687933921813965,
      "learning_rate": 1.4389371162396784e-05,
      "loss": 0.657,
      "step": 673050
    },
    {
      "epoch": 7.12569274987958,
      "grad_norm": 4.470496654510498,
      "learning_rate": 1.4386724539487615e-05,
      "loss": 0.6519,
      "step": 673100
    },
    {
      "epoch": 7.1262220716595825,
      "grad_norm": 4.234293460845947,
      "learning_rate": 1.4384077916578447e-05,
      "loss": 0.6559,
      "step": 673150
    },
    {
      "epoch": 7.126751393439585,
      "grad_norm": 4.474723815917969,
      "learning_rate": 1.4381431293669278e-05,
      "loss": 0.6497,
      "step": 673200
    },
    {
      "epoch": 7.127280715219589,
      "grad_norm": 4.408815383911133,
      "learning_rate": 1.4378784670760112e-05,
      "loss": 0.6513,
      "step": 673250
    },
    {
      "epoch": 7.127810036999592,
      "grad_norm": 4.32611608505249,
      "learning_rate": 1.4376138047850943e-05,
      "loss": 0.657,
      "step": 673300
    },
    {
      "epoch": 7.128339358779596,
      "grad_norm": 4.664252281188965,
      "learning_rate": 1.4373491424941777e-05,
      "loss": 0.6535,
      "step": 673350
    },
    {
      "epoch": 7.128868680559599,
      "grad_norm": 5.138969898223877,
      "learning_rate": 1.4370844802032608e-05,
      "loss": 0.6654,
      "step": 673400
    },
    {
      "epoch": 7.129398002339602,
      "grad_norm": 4.595728874206543,
      "learning_rate": 1.436819817912344e-05,
      "loss": 0.6644,
      "step": 673450
    },
    {
      "epoch": 7.129927324119605,
      "grad_norm": 4.694482326507568,
      "learning_rate": 1.436555155621427e-05,
      "loss": 0.6615,
      "step": 673500
    },
    {
      "epoch": 7.129927324119605,
      "eval_loss": 0.4118957221508026,
      "eval_runtime": 46.9031,
      "eval_samples_per_second": 3580.36,
      "eval_steps_per_second": 447.561,
      "step": 673500
    },
    {
      "epoch": 7.130456645899609,
      "grad_norm": 4.538621425628662,
      "learning_rate": 1.4362904933305105e-05,
      "loss": 0.6542,
      "step": 673550
    },
    {
      "epoch": 7.130985967679612,
      "grad_norm": 4.417675495147705,
      "learning_rate": 1.4360258310395936e-05,
      "loss": 0.6629,
      "step": 673600
    },
    {
      "epoch": 7.131515289459616,
      "grad_norm": 4.519200325012207,
      "learning_rate": 1.435761168748677e-05,
      "loss": 0.6703,
      "step": 673650
    },
    {
      "epoch": 7.1320446112396185,
      "grad_norm": 4.419406890869141,
      "learning_rate": 1.43549650645776e-05,
      "loss": 0.6676,
      "step": 673700
    },
    {
      "epoch": 7.132573933019622,
      "grad_norm": 4.452667713165283,
      "learning_rate": 1.4352318441668433e-05,
      "loss": 0.6494,
      "step": 673750
    },
    {
      "epoch": 7.133103254799625,
      "grad_norm": 4.401511192321777,
      "learning_rate": 1.4349671818759263e-05,
      "loss": 0.6688,
      "step": 673800
    },
    {
      "epoch": 7.133632576579629,
      "grad_norm": 4.546862602233887,
      "learning_rate": 1.4347025195850098e-05,
      "loss": 0.6681,
      "step": 673850
    },
    {
      "epoch": 7.134161898359632,
      "grad_norm": 4.419112205505371,
      "learning_rate": 1.4344378572940928e-05,
      "loss": 0.6561,
      "step": 673900
    },
    {
      "epoch": 7.134691220139635,
      "grad_norm": 4.147398948669434,
      "learning_rate": 1.434173195003176e-05,
      "loss": 0.6641,
      "step": 673950
    },
    {
      "epoch": 7.135220541919638,
      "grad_norm": 4.297330379486084,
      "learning_rate": 1.4339085327122591e-05,
      "loss": 0.6578,
      "step": 674000
    },
    {
      "epoch": 7.135220541919638,
      "eval_loss": 0.41091176867485046,
      "eval_runtime": 47.1217,
      "eval_samples_per_second": 3563.748,
      "eval_steps_per_second": 445.484,
      "step": 674000
    },
    {
      "epoch": 7.135749863699641,
      "grad_norm": 4.512006759643555,
      "learning_rate": 1.4336438704213425e-05,
      "loss": 0.6639,
      "step": 674050
    },
    {
      "epoch": 7.136279185479645,
      "grad_norm": 4.299039840698242,
      "learning_rate": 1.4333792081304256e-05,
      "loss": 0.6698,
      "step": 674100
    },
    {
      "epoch": 7.136808507259648,
      "grad_norm": 4.6230788230896,
      "learning_rate": 1.4331198390853273e-05,
      "loss": 0.6569,
      "step": 674150
    },
    {
      "epoch": 7.137337829039652,
      "grad_norm": 4.915511608123779,
      "learning_rate": 1.4328551767944103e-05,
      "loss": 0.6644,
      "step": 674200
    },
    {
      "epoch": 7.1378671508196545,
      "grad_norm": 4.234443664550781,
      "learning_rate": 1.4325905145034937e-05,
      "loss": 0.6618,
      "step": 674250
    },
    {
      "epoch": 7.138396472599658,
      "grad_norm": 4.373244285583496,
      "learning_rate": 1.4323258522125768e-05,
      "loss": 0.6562,
      "step": 674300
    },
    {
      "epoch": 7.138925794379661,
      "grad_norm": 4.325447082519531,
      "learning_rate": 1.4320611899216602e-05,
      "loss": 0.6553,
      "step": 674350
    },
    {
      "epoch": 7.139455116159665,
      "grad_norm": 4.387181758880615,
      "learning_rate": 1.4317965276307433e-05,
      "loss": 0.6573,
      "step": 674400
    },
    {
      "epoch": 7.139984437939668,
      "grad_norm": 4.856958389282227,
      "learning_rate": 1.4315318653398265e-05,
      "loss": 0.6433,
      "step": 674450
    },
    {
      "epoch": 7.1405137597196715,
      "grad_norm": 4.502995014190674,
      "learning_rate": 1.4312672030489096e-05,
      "loss": 0.6524,
      "step": 674500
    },
    {
      "epoch": 7.1405137597196715,
      "eval_loss": 0.411399245262146,
      "eval_runtime": 46.8688,
      "eval_samples_per_second": 3582.981,
      "eval_steps_per_second": 447.889,
      "step": 674500
    },
    {
      "epoch": 7.141043081499674,
      "grad_norm": 4.927850723266602,
      "learning_rate": 1.431002540757993e-05,
      "loss": 0.6552,
      "step": 674550
    },
    {
      "epoch": 7.141572403279678,
      "grad_norm": 4.214310646057129,
      "learning_rate": 1.4307378784670761e-05,
      "loss": 0.6592,
      "step": 674600
    },
    {
      "epoch": 7.142101725059681,
      "grad_norm": 4.427770614624023,
      "learning_rate": 1.4304732161761595e-05,
      "loss": 0.6615,
      "step": 674650
    },
    {
      "epoch": 7.142631046839684,
      "grad_norm": 4.7632269859313965,
      "learning_rate": 1.4302085538852426e-05,
      "loss": 0.6524,
      "step": 674700
    },
    {
      "epoch": 7.143160368619688,
      "grad_norm": 4.532310962677002,
      "learning_rate": 1.4299438915943258e-05,
      "loss": 0.661,
      "step": 674750
    },
    {
      "epoch": 7.1436896903996905,
      "grad_norm": 4.3217902183532715,
      "learning_rate": 1.4296792293034089e-05,
      "loss": 0.6564,
      "step": 674800
    },
    {
      "epoch": 7.144219012179694,
      "grad_norm": 4.372913360595703,
      "learning_rate": 1.4294145670124923e-05,
      "loss": 0.6516,
      "step": 674850
    },
    {
      "epoch": 7.144748333959697,
      "grad_norm": 4.2200188636779785,
      "learning_rate": 1.4291499047215754e-05,
      "loss": 0.652,
      "step": 674900
    },
    {
      "epoch": 7.145277655739701,
      "grad_norm": 4.566350936889648,
      "learning_rate": 1.4288852424306584e-05,
      "loss": 0.6655,
      "step": 674950
    },
    {
      "epoch": 7.145806977519704,
      "grad_norm": 4.767116069793701,
      "learning_rate": 1.4286205801397418e-05,
      "loss": 0.6602,
      "step": 675000
    },
    {
      "epoch": 7.145806977519704,
      "eval_loss": 0.41281643509864807,
      "eval_runtime": 46.5772,
      "eval_samples_per_second": 3605.409,
      "eval_steps_per_second": 450.692,
      "step": 675000
    },
    {
      "epoch": 7.1463362992997075,
      "grad_norm": 4.720273494720459,
      "learning_rate": 1.4283559178488249e-05,
      "loss": 0.6653,
      "step": 675050
    },
    {
      "epoch": 7.14686562107971,
      "grad_norm": 4.3109846115112305,
      "learning_rate": 1.4280912555579082e-05,
      "loss": 0.6575,
      "step": 675100
    },
    {
      "epoch": 7.147394942859714,
      "grad_norm": 4.2456817626953125,
      "learning_rate": 1.4278265932669912e-05,
      "loss": 0.6568,
      "step": 675150
    },
    {
      "epoch": 7.147924264639717,
      "grad_norm": 4.160152435302734,
      "learning_rate": 1.4275619309760746e-05,
      "loss": 0.6574,
      "step": 675200
    },
    {
      "epoch": 7.148453586419721,
      "grad_norm": 4.46134614944458,
      "learning_rate": 1.4272972686851577e-05,
      "loss": 0.6662,
      "step": 675250
    },
    {
      "epoch": 7.148982908199724,
      "grad_norm": 4.312588691711426,
      "learning_rate": 1.427032606394241e-05,
      "loss": 0.6546,
      "step": 675300
    },
    {
      "epoch": 7.149512229979727,
      "grad_norm": 4.0600056648254395,
      "learning_rate": 1.426767944103324e-05,
      "loss": 0.6627,
      "step": 675350
    },
    {
      "epoch": 7.15004155175973,
      "grad_norm": 4.118633270263672,
      "learning_rate": 1.4265032818124074e-05,
      "loss": 0.6502,
      "step": 675400
    },
    {
      "epoch": 7.150570873539733,
      "grad_norm": 4.783029079437256,
      "learning_rate": 1.4262386195214905e-05,
      "loss": 0.6611,
      "step": 675450
    },
    {
      "epoch": 7.151100195319737,
      "grad_norm": 4.7306365966796875,
      "learning_rate": 1.4259739572305739e-05,
      "loss": 0.6646,
      "step": 675500
    },
    {
      "epoch": 7.151100195319737,
      "eval_loss": 0.41152364015579224,
      "eval_runtime": 46.9728,
      "eval_samples_per_second": 3575.049,
      "eval_steps_per_second": 446.897,
      "step": 675500
    },
    {
      "epoch": 7.15162951709974,
      "grad_norm": 3.9470791816711426,
      "learning_rate": 1.425709294939657e-05,
      "loss": 0.6608,
      "step": 675550
    },
    {
      "epoch": 7.1521588388797435,
      "grad_norm": 4.65171480178833,
      "learning_rate": 1.4254446326487402e-05,
      "loss": 0.6708,
      "step": 675600
    },
    {
      "epoch": 7.152688160659746,
      "grad_norm": 4.162153720855713,
      "learning_rate": 1.4251799703578233e-05,
      "loss": 0.6618,
      "step": 675650
    },
    {
      "epoch": 7.15321748243975,
      "grad_norm": 3.9796252250671387,
      "learning_rate": 1.4249153080669067e-05,
      "loss": 0.652,
      "step": 675700
    },
    {
      "epoch": 7.153746804219753,
      "grad_norm": 3.9899120330810547,
      "learning_rate": 1.4246506457759898e-05,
      "loss": 0.6681,
      "step": 675750
    },
    {
      "epoch": 7.154276125999757,
      "grad_norm": 4.512125015258789,
      "learning_rate": 1.4243859834850732e-05,
      "loss": 0.6527,
      "step": 675800
    },
    {
      "epoch": 7.15480544777976,
      "grad_norm": 4.37648344039917,
      "learning_rate": 1.4241213211941563e-05,
      "loss": 0.6537,
      "step": 675850
    },
    {
      "epoch": 7.155334769559763,
      "grad_norm": 4.753432750701904,
      "learning_rate": 1.4238566589032395e-05,
      "loss": 0.6605,
      "step": 675900
    },
    {
      "epoch": 7.155864091339766,
      "grad_norm": 4.476968765258789,
      "learning_rate": 1.4235919966123226e-05,
      "loss": 0.6517,
      "step": 675950
    },
    {
      "epoch": 7.15639341311977,
      "grad_norm": 4.596348762512207,
      "learning_rate": 1.423327334321406e-05,
      "loss": 0.6665,
      "step": 676000
    },
    {
      "epoch": 7.15639341311977,
      "eval_loss": 0.41157644987106323,
      "eval_runtime": 46.5316,
      "eval_samples_per_second": 3608.946,
      "eval_steps_per_second": 451.134,
      "step": 676000
    },
    {
      "epoch": 7.156922734899773,
      "grad_norm": 4.534655570983887,
      "learning_rate": 1.423062672030489e-05,
      "loss": 0.665,
      "step": 676050
    },
    {
      "epoch": 7.157452056679777,
      "grad_norm": 4.296456336975098,
      "learning_rate": 1.4227980097395725e-05,
      "loss": 0.6533,
      "step": 676100
    },
    {
      "epoch": 7.157981378459779,
      "grad_norm": 4.21439266204834,
      "learning_rate": 1.4225386406944738e-05,
      "loss": 0.6574,
      "step": 676150
    },
    {
      "epoch": 7.158510700239782,
      "grad_norm": 4.491849899291992,
      "learning_rate": 1.4222739784035572e-05,
      "loss": 0.6554,
      "step": 676200
    },
    {
      "epoch": 7.159040022019786,
      "grad_norm": 4.42113733291626,
      "learning_rate": 1.4220093161126402e-05,
      "loss": 0.6581,
      "step": 676250
    },
    {
      "epoch": 7.159569343799789,
      "grad_norm": 4.590231418609619,
      "learning_rate": 1.4217446538217235e-05,
      "loss": 0.6594,
      "step": 676300
    },
    {
      "epoch": 7.160098665579793,
      "grad_norm": 4.640622615814209,
      "learning_rate": 1.4214799915308066e-05,
      "loss": 0.6617,
      "step": 676350
    },
    {
      "epoch": 7.1606279873597956,
      "grad_norm": 4.474470615386963,
      "learning_rate": 1.42121532923989e-05,
      "loss": 0.6469,
      "step": 676400
    },
    {
      "epoch": 7.161157309139799,
      "grad_norm": 4.388370990753174,
      "learning_rate": 1.420950666948973e-05,
      "loss": 0.6548,
      "step": 676450
    },
    {
      "epoch": 7.161686630919802,
      "grad_norm": 4.151818752288818,
      "learning_rate": 1.4206860046580564e-05,
      "loss": 0.6584,
      "step": 676500
    },
    {
      "epoch": 7.161686630919802,
      "eval_loss": 0.4120284616947174,
      "eval_runtime": 46.4652,
      "eval_samples_per_second": 3614.102,
      "eval_steps_per_second": 451.779,
      "step": 676500
    },
    {
      "epoch": 7.162215952699806,
      "grad_norm": 4.168543815612793,
      "learning_rate": 1.4204213423671395e-05,
      "loss": 0.6615,
      "step": 676550
    },
    {
      "epoch": 7.162745274479809,
      "grad_norm": 4.565148830413818,
      "learning_rate": 1.4201566800762228e-05,
      "loss": 0.6581,
      "step": 676600
    },
    {
      "epoch": 7.1632745962598126,
      "grad_norm": 4.35466194152832,
      "learning_rate": 1.4198920177853058e-05,
      "loss": 0.6504,
      "step": 676650
    },
    {
      "epoch": 7.163803918039815,
      "grad_norm": 5.0423688888549805,
      "learning_rate": 1.4196273554943892e-05,
      "loss": 0.664,
      "step": 676700
    },
    {
      "epoch": 7.164333239819819,
      "grad_norm": 4.669808864593506,
      "learning_rate": 1.4193626932034723e-05,
      "loss": 0.6572,
      "step": 676750
    },
    {
      "epoch": 7.164862561599822,
      "grad_norm": 4.105926990509033,
      "learning_rate": 1.4190980309125557e-05,
      "loss": 0.6513,
      "step": 676800
    },
    {
      "epoch": 7.165391883379826,
      "grad_norm": 4.2721076011657715,
      "learning_rate": 1.4188333686216388e-05,
      "loss": 0.653,
      "step": 676850
    },
    {
      "epoch": 7.165921205159829,
      "grad_norm": 4.491087913513184,
      "learning_rate": 1.418568706330722e-05,
      "loss": 0.6568,
      "step": 676900
    },
    {
      "epoch": 7.166450526939832,
      "grad_norm": 4.34721040725708,
      "learning_rate": 1.4183040440398051e-05,
      "loss": 0.6579,
      "step": 676950
    },
    {
      "epoch": 7.166979848719835,
      "grad_norm": 4.434943675994873,
      "learning_rate": 1.4180393817488885e-05,
      "loss": 0.6482,
      "step": 677000
    },
    {
      "epoch": 7.166979848719835,
      "eval_loss": 0.4112392067909241,
      "eval_runtime": 46.5567,
      "eval_samples_per_second": 3606.999,
      "eval_steps_per_second": 450.891,
      "step": 677000
    },
    {
      "epoch": 7.167509170499838,
      "grad_norm": 4.672883033752441,
      "learning_rate": 1.4177747194579716e-05,
      "loss": 0.6522,
      "step": 677050
    },
    {
      "epoch": 7.168038492279842,
      "grad_norm": 4.353557109832764,
      "learning_rate": 1.417510057167055e-05,
      "loss": 0.6579,
      "step": 677100
    },
    {
      "epoch": 7.168567814059845,
      "grad_norm": 4.105804920196533,
      "learning_rate": 1.417245394876138e-05,
      "loss": 0.6586,
      "step": 677150
    },
    {
      "epoch": 7.1690971358398485,
      "grad_norm": 4.510889053344727,
      "learning_rate": 1.4169807325852213e-05,
      "loss": 0.6621,
      "step": 677200
    },
    {
      "epoch": 7.169626457619851,
      "grad_norm": 4.417686462402344,
      "learning_rate": 1.4167160702943044e-05,
      "loss": 0.668,
      "step": 677250
    },
    {
      "epoch": 7.170155779399855,
      "grad_norm": 4.367871284484863,
      "learning_rate": 1.4164514080033878e-05,
      "loss": 0.6569,
      "step": 677300
    },
    {
      "epoch": 7.170685101179858,
      "grad_norm": 4.009060382843018,
      "learning_rate": 1.4161867457124709e-05,
      "loss": 0.6647,
      "step": 677350
    },
    {
      "epoch": 7.171214422959862,
      "grad_norm": 4.471267223358154,
      "learning_rate": 1.4159220834215543e-05,
      "loss": 0.6562,
      "step": 677400
    },
    {
      "epoch": 7.171743744739865,
      "grad_norm": 4.549273490905762,
      "learning_rate": 1.4156574211306373e-05,
      "loss": 0.649,
      "step": 677450
    },
    {
      "epoch": 7.172273066519868,
      "grad_norm": 4.728113651275635,
      "learning_rate": 1.4153927588397206e-05,
      "loss": 0.6488,
      "step": 677500
    },
    {
      "epoch": 7.172273066519868,
      "eval_loss": 0.41081273555755615,
      "eval_runtime": 46.5966,
      "eval_samples_per_second": 3603.914,
      "eval_steps_per_second": 450.505,
      "step": 677500
    },
    {
      "epoch": 7.172802388299871,
      "grad_norm": 4.24711799621582,
      "learning_rate": 1.4151280965488036e-05,
      "loss": 0.6548,
      "step": 677550
    },
    {
      "epoch": 7.173331710079875,
      "grad_norm": 4.566405773162842,
      "learning_rate": 1.414863434257887e-05,
      "loss": 0.66,
      "step": 677600
    },
    {
      "epoch": 7.173861031859878,
      "grad_norm": 3.7697877883911133,
      "learning_rate": 1.4145987719669701e-05,
      "loss": 0.6445,
      "step": 677650
    },
    {
      "epoch": 7.174390353639882,
      "grad_norm": 4.1087188720703125,
      "learning_rate": 1.4143341096760534e-05,
      "loss": 0.6621,
      "step": 677700
    },
    {
      "epoch": 7.1749196754198845,
      "grad_norm": 4.445789813995361,
      "learning_rate": 1.4140694473851364e-05,
      "loss": 0.6643,
      "step": 677750
    },
    {
      "epoch": 7.175448997199887,
      "grad_norm": 4.636843204498291,
      "learning_rate": 1.4138047850942199e-05,
      "loss": 0.657,
      "step": 677800
    },
    {
      "epoch": 7.175978318979891,
      "grad_norm": 4.337724685668945,
      "learning_rate": 1.413540122803303e-05,
      "loss": 0.6585,
      "step": 677850
    },
    {
      "epoch": 7.176507640759894,
      "grad_norm": 4.251559257507324,
      "learning_rate": 1.4132754605123863e-05,
      "loss": 0.6517,
      "step": 677900
    },
    {
      "epoch": 7.177036962539898,
      "grad_norm": 4.20793342590332,
      "learning_rate": 1.4130107982214694e-05,
      "loss": 0.649,
      "step": 677950
    },
    {
      "epoch": 7.177566284319901,
      "grad_norm": 4.682002544403076,
      "learning_rate": 1.4127461359305526e-05,
      "loss": 0.6576,
      "step": 678000
    },
    {
      "epoch": 7.177566284319901,
      "eval_loss": 0.4113306701183319,
      "eval_runtime": 46.7936,
      "eval_samples_per_second": 3588.742,
      "eval_steps_per_second": 448.609,
      "step": 678000
    },
    {
      "epoch": 7.178095606099904,
      "grad_norm": 4.976867198944092,
      "learning_rate": 1.4124814736396357e-05,
      "loss": 0.6578,
      "step": 678050
    },
    {
      "epoch": 7.178624927879907,
      "grad_norm": 4.605201244354248,
      "learning_rate": 1.4122168113487191e-05,
      "loss": 0.6528,
      "step": 678100
    },
    {
      "epoch": 7.179154249659911,
      "grad_norm": 4.444015026092529,
      "learning_rate": 1.4119574423036206e-05,
      "loss": 0.6505,
      "step": 678150
    },
    {
      "epoch": 7.179683571439914,
      "grad_norm": 4.609253883361816,
      "learning_rate": 1.4116927800127038e-05,
      "loss": 0.6712,
      "step": 678200
    },
    {
      "epoch": 7.180212893219918,
      "grad_norm": 4.323227405548096,
      "learning_rate": 1.4114281177217869e-05,
      "loss": 0.649,
      "step": 678250
    },
    {
      "epoch": 7.1807422149999205,
      "grad_norm": 4.979847431182861,
      "learning_rate": 1.4111634554308703e-05,
      "loss": 0.6635,
      "step": 678300
    },
    {
      "epoch": 7.181271536779924,
      "grad_norm": 3.902418613433838,
      "learning_rate": 1.4108987931399534e-05,
      "loss": 0.6593,
      "step": 678350
    },
    {
      "epoch": 7.181800858559927,
      "grad_norm": 4.643838405609131,
      "learning_rate": 1.4106341308490368e-05,
      "loss": 0.6723,
      "step": 678400
    },
    {
      "epoch": 7.182330180339931,
      "grad_norm": 4.568154335021973,
      "learning_rate": 1.4103694685581199e-05,
      "loss": 0.6603,
      "step": 678450
    },
    {
      "epoch": 7.182859502119934,
      "grad_norm": 4.246811389923096,
      "learning_rate": 1.4101048062672031e-05,
      "loss": 0.6589,
      "step": 678500
    },
    {
      "epoch": 7.182859502119934,
      "eval_loss": 0.4112667739391327,
      "eval_runtime": 46.7454,
      "eval_samples_per_second": 3592.436,
      "eval_steps_per_second": 449.071,
      "step": 678500
    },
    {
      "epoch": 7.183388823899937,
      "grad_norm": 4.38234281539917,
      "learning_rate": 1.4098401439762862e-05,
      "loss": 0.65,
      "step": 678550
    },
    {
      "epoch": 7.18391814567994,
      "grad_norm": 4.733282089233398,
      "learning_rate": 1.4095754816853696e-05,
      "loss": 0.6547,
      "step": 678600
    },
    {
      "epoch": 7.184447467459943,
      "grad_norm": 4.239779472351074,
      "learning_rate": 1.4093108193944527e-05,
      "loss": 0.6501,
      "step": 678650
    },
    {
      "epoch": 7.184976789239947,
      "grad_norm": 4.539705276489258,
      "learning_rate": 1.409046157103536e-05,
      "loss": 0.6648,
      "step": 678700
    },
    {
      "epoch": 7.18550611101995,
      "grad_norm": 4.7392988204956055,
      "learning_rate": 1.4087814948126191e-05,
      "loss": 0.6662,
      "step": 678750
    },
    {
      "epoch": 7.186035432799954,
      "grad_norm": 4.080986499786377,
      "learning_rate": 1.4085168325217024e-05,
      "loss": 0.6643,
      "step": 678800
    },
    {
      "epoch": 7.1865647545799565,
      "grad_norm": 4.557547092437744,
      "learning_rate": 1.4082521702307855e-05,
      "loss": 0.6609,
      "step": 678850
    },
    {
      "epoch": 7.18709407635996,
      "grad_norm": 4.778869152069092,
      "learning_rate": 1.4079875079398689e-05,
      "loss": 0.6609,
      "step": 678900
    },
    {
      "epoch": 7.187623398139963,
      "grad_norm": 4.1975507736206055,
      "learning_rate": 1.407722845648952e-05,
      "loss": 0.6637,
      "step": 678950
    },
    {
      "epoch": 7.188152719919967,
      "grad_norm": 4.326325416564941,
      "learning_rate": 1.4074581833580352e-05,
      "loss": 0.6716,
      "step": 679000
    },
    {
      "epoch": 7.188152719919967,
      "eval_loss": 0.41146984696388245,
      "eval_runtime": 46.5675,
      "eval_samples_per_second": 3606.165,
      "eval_steps_per_second": 450.787,
      "step": 679000
    },
    {
      "epoch": 7.18868204169997,
      "grad_norm": 4.085127830505371,
      "learning_rate": 1.4071935210671182e-05,
      "loss": 0.6638,
      "step": 679050
    },
    {
      "epoch": 7.1892113634799735,
      "grad_norm": 4.571400165557861,
      "learning_rate": 1.4069288587762017e-05,
      "loss": 0.6578,
      "step": 679100
    },
    {
      "epoch": 7.189740685259976,
      "grad_norm": 4.78856086730957,
      "learning_rate": 1.4066641964852847e-05,
      "loss": 0.6621,
      "step": 679150
    },
    {
      "epoch": 7.19027000703998,
      "grad_norm": 4.264883995056152,
      "learning_rate": 1.4063995341943681e-05,
      "loss": 0.6562,
      "step": 679200
    },
    {
      "epoch": 7.190799328819983,
      "grad_norm": 4.667057037353516,
      "learning_rate": 1.4061348719034512e-05,
      "loss": 0.6616,
      "step": 679250
    },
    {
      "epoch": 7.191328650599986,
      "grad_norm": 4.434878349304199,
      "learning_rate": 1.4058702096125345e-05,
      "loss": 0.662,
      "step": 679300
    },
    {
      "epoch": 7.19185797237999,
      "grad_norm": 4.419585704803467,
      "learning_rate": 1.4056055473216175e-05,
      "loss": 0.6621,
      "step": 679350
    },
    {
      "epoch": 7.1923872941599925,
      "grad_norm": 4.810268878936768,
      "learning_rate": 1.405340885030701e-05,
      "loss": 0.6527,
      "step": 679400
    },
    {
      "epoch": 7.192916615939996,
      "grad_norm": 4.243288993835449,
      "learning_rate": 1.405076222739784e-05,
      "loss": 0.655,
      "step": 679450
    },
    {
      "epoch": 7.193445937719999,
      "grad_norm": 4.269754409790039,
      "learning_rate": 1.4048115604488674e-05,
      "loss": 0.6574,
      "step": 679500
    },
    {
      "epoch": 7.193445937719999,
      "eval_loss": 0.41084226965904236,
      "eval_runtime": 46.4805,
      "eval_samples_per_second": 3612.915,
      "eval_steps_per_second": 451.631,
      "step": 679500
    },
    {
      "epoch": 7.193975259500003,
      "grad_norm": 4.258068561553955,
      "learning_rate": 1.4045468981579505e-05,
      "loss": 0.6652,
      "step": 679550
    },
    {
      "epoch": 7.194504581280006,
      "grad_norm": 4.159661293029785,
      "learning_rate": 1.4042822358670337e-05,
      "loss": 0.6533,
      "step": 679600
    },
    {
      "epoch": 7.1950339030600095,
      "grad_norm": 4.461897373199463,
      "learning_rate": 1.4040175735761168e-05,
      "loss": 0.6686,
      "step": 679650
    },
    {
      "epoch": 7.195563224840012,
      "grad_norm": 4.407235622406006,
      "learning_rate": 1.4037529112852002e-05,
      "loss": 0.6599,
      "step": 679700
    },
    {
      "epoch": 7.196092546620016,
      "grad_norm": 4.2452239990234375,
      "learning_rate": 1.4034882489942833e-05,
      "loss": 0.6535,
      "step": 679750
    },
    {
      "epoch": 7.196621868400019,
      "grad_norm": 4.464862823486328,
      "learning_rate": 1.4032235867033667e-05,
      "loss": 0.664,
      "step": 679800
    },
    {
      "epoch": 7.197151190180023,
      "grad_norm": 4.400121212005615,
      "learning_rate": 1.4029589244124498e-05,
      "loss": 0.6644,
      "step": 679850
    },
    {
      "epoch": 7.197680511960026,
      "grad_norm": 4.408404350280762,
      "learning_rate": 1.402694262121533e-05,
      "loss": 0.6618,
      "step": 679900
    },
    {
      "epoch": 7.198209833740029,
      "grad_norm": 4.764493465423584,
      "learning_rate": 1.402429599830616e-05,
      "loss": 0.66,
      "step": 679950
    },
    {
      "epoch": 7.198739155520032,
      "grad_norm": 4.679510593414307,
      "learning_rate": 1.4021649375396995e-05,
      "loss": 0.6617,
      "step": 680000
    },
    {
      "epoch": 7.198739155520032,
      "eval_loss": 0.410258412361145,
      "eval_runtime": 47.0731,
      "eval_samples_per_second": 3567.431,
      "eval_steps_per_second": 445.945,
      "step": 680000
    },
    {
      "epoch": 7.199268477300035,
      "grad_norm": 5.070207595825195,
      "learning_rate": 1.4019002752487826e-05,
      "loss": 0.671,
      "step": 680050
    },
    {
      "epoch": 7.199797799080039,
      "grad_norm": 4.83083963394165,
      "learning_rate": 1.401635612957866e-05,
      "loss": 0.6444,
      "step": 680100
    },
    {
      "epoch": 7.200327120860042,
      "grad_norm": 4.638994216918945,
      "learning_rate": 1.401370950666949e-05,
      "loss": 0.6646,
      "step": 680150
    },
    {
      "epoch": 7.200856442640045,
      "grad_norm": 4.70656156539917,
      "learning_rate": 1.4011115816218507e-05,
      "loss": 0.655,
      "step": 680200
    },
    {
      "epoch": 7.201385764420048,
      "grad_norm": 4.349240779876709,
      "learning_rate": 1.4008469193309337e-05,
      "loss": 0.6565,
      "step": 680250
    },
    {
      "epoch": 7.201915086200052,
      "grad_norm": 4.771953105926514,
      "learning_rate": 1.400582257040017e-05,
      "loss": 0.6598,
      "step": 680300
    },
    {
      "epoch": 7.202444407980055,
      "grad_norm": 4.302419662475586,
      "learning_rate": 1.4003175947491e-05,
      "loss": 0.6641,
      "step": 680350
    },
    {
      "epoch": 7.202973729760059,
      "grad_norm": 4.199752330780029,
      "learning_rate": 1.4000529324581835e-05,
      "loss": 0.6642,
      "step": 680400
    },
    {
      "epoch": 7.2035030515400615,
      "grad_norm": 4.4613037109375,
      "learning_rate": 1.3997882701672665e-05,
      "loss": 0.6546,
      "step": 680450
    },
    {
      "epoch": 7.204032373320065,
      "grad_norm": 4.453594207763672,
      "learning_rate": 1.39952360787635e-05,
      "loss": 0.6583,
      "step": 680500
    },
    {
      "epoch": 7.204032373320065,
      "eval_loss": 0.4108771085739136,
      "eval_runtime": 46.5144,
      "eval_samples_per_second": 3610.281,
      "eval_steps_per_second": 451.301,
      "step": 680500
    },
    {
      "epoch": 7.204561695100068,
      "grad_norm": 4.235729217529297,
      "learning_rate": 1.399258945585433e-05,
      "loss": 0.6567,
      "step": 680550
    },
    {
      "epoch": 7.205091016880072,
      "grad_norm": 4.488863468170166,
      "learning_rate": 1.3989942832945163e-05,
      "loss": 0.6616,
      "step": 680600
    },
    {
      "epoch": 7.205620338660075,
      "grad_norm": 4.574149131774902,
      "learning_rate": 1.3987296210035993e-05,
      "loss": 0.6675,
      "step": 680650
    },
    {
      "epoch": 7.2061496604400785,
      "grad_norm": 4.64164400100708,
      "learning_rate": 1.3984649587126827e-05,
      "loss": 0.6699,
      "step": 680700
    },
    {
      "epoch": 7.206678982220081,
      "grad_norm": 4.507750988006592,
      "learning_rate": 1.3982002964217658e-05,
      "loss": 0.6609,
      "step": 680750
    },
    {
      "epoch": 7.207208304000084,
      "grad_norm": 4.528862476348877,
      "learning_rate": 1.3979356341308492e-05,
      "loss": 0.6659,
      "step": 680800
    },
    {
      "epoch": 7.207737625780088,
      "grad_norm": 4.884795188903809,
      "learning_rate": 1.3976709718399323e-05,
      "loss": 0.6681,
      "step": 680850
    },
    {
      "epoch": 7.208266947560091,
      "grad_norm": 3.8623831272125244,
      "learning_rate": 1.3974063095490155e-05,
      "loss": 0.6504,
      "step": 680900
    },
    {
      "epoch": 7.208796269340095,
      "grad_norm": 4.86297082901001,
      "learning_rate": 1.3971416472580986e-05,
      "loss": 0.6508,
      "step": 680950
    },
    {
      "epoch": 7.2093255911200975,
      "grad_norm": 4.398671627044678,
      "learning_rate": 1.396876984967182e-05,
      "loss": 0.6643,
      "step": 681000
    },
    {
      "epoch": 7.2093255911200975,
      "eval_loss": 0.41137105226516724,
      "eval_runtime": 47.3959,
      "eval_samples_per_second": 3543.133,
      "eval_steps_per_second": 442.907,
      "step": 681000
    },
    {
      "epoch": 7.209854912900101,
      "grad_norm": 4.583332061767578,
      "learning_rate": 1.3966123226762651e-05,
      "loss": 0.6526,
      "step": 681050
    },
    {
      "epoch": 7.210384234680104,
      "grad_norm": 4.624683856964111,
      "learning_rate": 1.3963476603853485e-05,
      "loss": 0.6476,
      "step": 681100
    },
    {
      "epoch": 7.210913556460108,
      "grad_norm": 4.774924278259277,
      "learning_rate": 1.3960829980944316e-05,
      "loss": 0.6565,
      "step": 681150
    },
    {
      "epoch": 7.211442878240111,
      "grad_norm": 4.309479713439941,
      "learning_rate": 1.3958183358035148e-05,
      "loss": 0.6617,
      "step": 681200
    },
    {
      "epoch": 7.2119722000201145,
      "grad_norm": 4.4609694480896,
      "learning_rate": 1.3955536735125979e-05,
      "loss": 0.6532,
      "step": 681250
    },
    {
      "epoch": 7.212501521800117,
      "grad_norm": 4.155588150024414,
      "learning_rate": 1.3952890112216813e-05,
      "loss": 0.6547,
      "step": 681300
    },
    {
      "epoch": 7.213030843580121,
      "grad_norm": 4.588266849517822,
      "learning_rate": 1.3950243489307644e-05,
      "loss": 0.6523,
      "step": 681350
    },
    {
      "epoch": 7.213560165360124,
      "grad_norm": 4.33840799331665,
      "learning_rate": 1.3947596866398476e-05,
      "loss": 0.6527,
      "step": 681400
    },
    {
      "epoch": 7.214089487140128,
      "grad_norm": 4.394948959350586,
      "learning_rate": 1.3944950243489308e-05,
      "loss": 0.6677,
      "step": 681450
    },
    {
      "epoch": 7.214618808920131,
      "grad_norm": 4.63787317276001,
      "learning_rate": 1.394230362058014e-05,
      "loss": 0.6493,
      "step": 681500
    },
    {
      "epoch": 7.214618808920131,
      "eval_loss": 0.4107864797115326,
      "eval_runtime": 47.2131,
      "eval_samples_per_second": 3556.855,
      "eval_steps_per_second": 444.623,
      "step": 681500
    },
    {
      "epoch": 7.2151481307001335,
      "grad_norm": 4.263246536254883,
      "learning_rate": 1.3939656997670972e-05,
      "loss": 0.6608,
      "step": 681550
    },
    {
      "epoch": 7.215677452480137,
      "grad_norm": 4.862534046173096,
      "learning_rate": 1.3937010374761806e-05,
      "loss": 0.6672,
      "step": 681600
    },
    {
      "epoch": 7.21620677426014,
      "grad_norm": 4.480494022369385,
      "learning_rate": 1.3934363751852636e-05,
      "loss": 0.6596,
      "step": 681650
    },
    {
      "epoch": 7.216736096040144,
      "grad_norm": 4.159905910491943,
      "learning_rate": 1.3931717128943469e-05,
      "loss": 0.6581,
      "step": 681700
    },
    {
      "epoch": 7.217265417820147,
      "grad_norm": 4.337512016296387,
      "learning_rate": 1.39290705060343e-05,
      "loss": 0.6585,
      "step": 681750
    },
    {
      "epoch": 7.2177947396001505,
      "grad_norm": 4.651327133178711,
      "learning_rate": 1.3926423883125134e-05,
      "loss": 0.6652,
      "step": 681800
    },
    {
      "epoch": 7.218324061380153,
      "grad_norm": 4.2713117599487305,
      "learning_rate": 1.3923777260215964e-05,
      "loss": 0.6601,
      "step": 681850
    },
    {
      "epoch": 7.218853383160157,
      "grad_norm": 4.858393669128418,
      "learning_rate": 1.3921130637306798e-05,
      "loss": 0.6593,
      "step": 681900
    },
    {
      "epoch": 7.21938270494016,
      "grad_norm": 4.590953826904297,
      "learning_rate": 1.3918484014397629e-05,
      "loss": 0.6676,
      "step": 681950
    },
    {
      "epoch": 7.219912026720164,
      "grad_norm": 4.585324287414551,
      "learning_rate": 1.3915837391488461e-05,
      "loss": 0.6542,
      "step": 682000
    },
    {
      "epoch": 7.219912026720164,
      "eval_loss": 0.40953853726387024,
      "eval_runtime": 47.2533,
      "eval_samples_per_second": 3553.827,
      "eval_steps_per_second": 444.244,
      "step": 682000
    },
    {
      "epoch": 7.220441348500167,
      "grad_norm": 4.574784755706787,
      "learning_rate": 1.3913190768579292e-05,
      "loss": 0.6578,
      "step": 682050
    },
    {
      "epoch": 7.22097067028017,
      "grad_norm": 4.461762428283691,
      "learning_rate": 1.3910544145670126e-05,
      "loss": 0.6509,
      "step": 682100
    },
    {
      "epoch": 7.221499992060173,
      "grad_norm": 4.5791707038879395,
      "learning_rate": 1.3907897522760957e-05,
      "loss": 0.6659,
      "step": 682150
    },
    {
      "epoch": 7.222029313840177,
      "grad_norm": 4.720952987670898,
      "learning_rate": 1.3905303832309973e-05,
      "loss": 0.644,
      "step": 682200
    },
    {
      "epoch": 7.22255863562018,
      "grad_norm": 4.438758373260498,
      "learning_rate": 1.3902657209400804e-05,
      "loss": 0.6632,
      "step": 682250
    },
    {
      "epoch": 7.223087957400183,
      "grad_norm": 4.493856906890869,
      "learning_rate": 1.3900010586491638e-05,
      "loss": 0.6475,
      "step": 682300
    },
    {
      "epoch": 7.2236172791801865,
      "grad_norm": 4.227381706237793,
      "learning_rate": 1.3897363963582469e-05,
      "loss": 0.6505,
      "step": 682350
    },
    {
      "epoch": 7.224146600960189,
      "grad_norm": 4.30437707901001,
      "learning_rate": 1.3894717340673303e-05,
      "loss": 0.661,
      "step": 682400
    },
    {
      "epoch": 7.224675922740193,
      "grad_norm": 4.516795635223389,
      "learning_rate": 1.3892070717764134e-05,
      "loss": 0.6716,
      "step": 682450
    },
    {
      "epoch": 7.225205244520196,
      "grad_norm": 3.9599454402923584,
      "learning_rate": 1.3889424094854966e-05,
      "loss": 0.6541,
      "step": 682500
    },
    {
      "epoch": 7.225205244520196,
      "eval_loss": 0.41034188866615295,
      "eval_runtime": 47.7886,
      "eval_samples_per_second": 3514.019,
      "eval_steps_per_second": 439.268,
      "step": 682500
    },
    {
      "epoch": 7.2257345663002,
      "grad_norm": 4.14853048324585,
      "learning_rate": 1.3886777471945797e-05,
      "loss": 0.6479,
      "step": 682550
    },
    {
      "epoch": 7.226263888080203,
      "grad_norm": 4.862704753875732,
      "learning_rate": 1.3884130849036631e-05,
      "loss": 0.655,
      "step": 682600
    },
    {
      "epoch": 7.226793209860206,
      "grad_norm": 4.894402027130127,
      "learning_rate": 1.3881484226127462e-05,
      "loss": 0.6538,
      "step": 682650
    },
    {
      "epoch": 7.227322531640209,
      "grad_norm": 4.044347763061523,
      "learning_rate": 1.3878837603218294e-05,
      "loss": 0.6471,
      "step": 682700
    },
    {
      "epoch": 7.227851853420213,
      "grad_norm": 4.270594596862793,
      "learning_rate": 1.3876190980309125e-05,
      "loss": 0.6584,
      "step": 682750
    },
    {
      "epoch": 7.228381175200216,
      "grad_norm": 4.664913654327393,
      "learning_rate": 1.3873544357399959e-05,
      "loss": 0.6541,
      "step": 682800
    },
    {
      "epoch": 7.22891049698022,
      "grad_norm": 4.324924945831299,
      "learning_rate": 1.387089773449079e-05,
      "loss": 0.6534,
      "step": 682850
    },
    {
      "epoch": 7.2294398187602225,
      "grad_norm": 4.2454304695129395,
      "learning_rate": 1.3868251111581624e-05,
      "loss": 0.6508,
      "step": 682900
    },
    {
      "epoch": 7.229969140540226,
      "grad_norm": 4.678405284881592,
      "learning_rate": 1.3865604488672454e-05,
      "loss": 0.6514,
      "step": 682950
    },
    {
      "epoch": 7.230498462320229,
      "grad_norm": 4.81272554397583,
      "learning_rate": 1.3862957865763287e-05,
      "loss": 0.6522,
      "step": 683000
    },
    {
      "epoch": 7.230498462320229,
      "eval_loss": 0.4093378186225891,
      "eval_runtime": 46.9853,
      "eval_samples_per_second": 3574.095,
      "eval_steps_per_second": 446.778,
      "step": 683000
    },
    {
      "epoch": 7.231027784100232,
      "grad_norm": 4.469142913818359,
      "learning_rate": 1.3860311242854118e-05,
      "loss": 0.6648,
      "step": 683050
    },
    {
      "epoch": 7.231557105880236,
      "grad_norm": 4.562304973602295,
      "learning_rate": 1.3857664619944952e-05,
      "loss": 0.6719,
      "step": 683100
    },
    {
      "epoch": 7.232086427660239,
      "grad_norm": 4.550518989562988,
      "learning_rate": 1.3855017997035782e-05,
      "loss": 0.6643,
      "step": 683150
    },
    {
      "epoch": 7.232615749440242,
      "grad_norm": 4.547249794006348,
      "learning_rate": 1.3852371374126616e-05,
      "loss": 0.6715,
      "step": 683200
    },
    {
      "epoch": 7.233145071220245,
      "grad_norm": 4.021174907684326,
      "learning_rate": 1.3849724751217447e-05,
      "loss": 0.6488,
      "step": 683250
    },
    {
      "epoch": 7.233674393000249,
      "grad_norm": 4.907966613769531,
      "learning_rate": 1.384707812830828e-05,
      "loss": 0.6656,
      "step": 683300
    },
    {
      "epoch": 7.234203714780252,
      "grad_norm": 5.098718643188477,
      "learning_rate": 1.384443150539911e-05,
      "loss": 0.6605,
      "step": 683350
    },
    {
      "epoch": 7.234733036560256,
      "grad_norm": 5.1427202224731445,
      "learning_rate": 1.3841784882489944e-05,
      "loss": 0.6643,
      "step": 683400
    },
    {
      "epoch": 7.235262358340258,
      "grad_norm": 3.972627639770508,
      "learning_rate": 1.3839138259580775e-05,
      "loss": 0.6462,
      "step": 683450
    },
    {
      "epoch": 7.235791680120262,
      "grad_norm": 4.807486534118652,
      "learning_rate": 1.383649163667161e-05,
      "loss": 0.6602,
      "step": 683500
    },
    {
      "epoch": 7.235791680120262,
      "eval_loss": 0.4109387695789337,
      "eval_runtime": 46.5431,
      "eval_samples_per_second": 3608.057,
      "eval_steps_per_second": 451.023,
      "step": 683500
    },
    {
      "epoch": 7.236321001900265,
      "grad_norm": 4.688578128814697,
      "learning_rate": 1.383384501376244e-05,
      "loss": 0.6513,
      "step": 683550
    },
    {
      "epoch": 7.236850323680269,
      "grad_norm": 4.714338302612305,
      "learning_rate": 1.3831198390853272e-05,
      "loss": 0.6582,
      "step": 683600
    },
    {
      "epoch": 7.237379645460272,
      "grad_norm": 4.03282356262207,
      "learning_rate": 1.3828551767944103e-05,
      "loss": 0.6582,
      "step": 683650
    },
    {
      "epoch": 7.237908967240275,
      "grad_norm": 4.54639196395874,
      "learning_rate": 1.3825905145034937e-05,
      "loss": 0.6626,
      "step": 683700
    },
    {
      "epoch": 7.238438289020278,
      "grad_norm": 4.415948390960693,
      "learning_rate": 1.3823258522125768e-05,
      "loss": 0.6397,
      "step": 683750
    },
    {
      "epoch": 7.238967610800281,
      "grad_norm": 4.370954513549805,
      "learning_rate": 1.3820611899216602e-05,
      "loss": 0.6614,
      "step": 683800
    },
    {
      "epoch": 7.239496932580285,
      "grad_norm": 4.407206058502197,
      "learning_rate": 1.3817965276307433e-05,
      "loss": 0.6589,
      "step": 683850
    },
    {
      "epoch": 7.240026254360288,
      "grad_norm": 4.456470012664795,
      "learning_rate": 1.3815318653398265e-05,
      "loss": 0.6621,
      "step": 683900
    },
    {
      "epoch": 7.2405555761402915,
      "grad_norm": 4.677400588989258,
      "learning_rate": 1.3812672030489096e-05,
      "loss": 0.6544,
      "step": 683950
    },
    {
      "epoch": 7.241084897920294,
      "grad_norm": 4.931977272033691,
      "learning_rate": 1.381002540757993e-05,
      "loss": 0.6657,
      "step": 684000
    },
    {
      "epoch": 7.241084897920294,
      "eval_loss": 0.4097156226634979,
      "eval_runtime": 46.522,
      "eval_samples_per_second": 3609.688,
      "eval_steps_per_second": 451.227,
      "step": 684000
    },
    {
      "epoch": 7.241614219700298,
      "grad_norm": 4.980983734130859,
      "learning_rate": 1.380737878467076e-05,
      "loss": 0.6595,
      "step": 684050
    },
    {
      "epoch": 7.242143541480301,
      "grad_norm": 4.4113078117370605,
      "learning_rate": 1.3804732161761593e-05,
      "loss": 0.655,
      "step": 684100
    },
    {
      "epoch": 7.242672863260305,
      "grad_norm": 4.8889923095703125,
      "learning_rate": 1.3802085538852424e-05,
      "loss": 0.6598,
      "step": 684150
    },
    {
      "epoch": 7.243202185040308,
      "grad_norm": 4.432244300842285,
      "learning_rate": 1.3799491848401442e-05,
      "loss": 0.6689,
      "step": 684200
    },
    {
      "epoch": 7.243731506820311,
      "grad_norm": 4.337427616119385,
      "learning_rate": 1.3796845225492272e-05,
      "loss": 0.6589,
      "step": 684250
    },
    {
      "epoch": 7.244260828600314,
      "grad_norm": 4.260426044464111,
      "learning_rate": 1.3794198602583105e-05,
      "loss": 0.6619,
      "step": 684300
    },
    {
      "epoch": 7.244790150380318,
      "grad_norm": 4.319769382476807,
      "learning_rate": 1.3791551979673936e-05,
      "loss": 0.6578,
      "step": 684350
    },
    {
      "epoch": 7.245319472160321,
      "grad_norm": 4.477173328399658,
      "learning_rate": 1.378890535676477e-05,
      "loss": 0.6627,
      "step": 684400
    },
    {
      "epoch": 7.245848793940325,
      "grad_norm": 4.0885396003723145,
      "learning_rate": 1.37862587338556e-05,
      "loss": 0.6517,
      "step": 684450
    },
    {
      "epoch": 7.2463781157203275,
      "grad_norm": 4.120095729827881,
      "learning_rate": 1.3783612110946435e-05,
      "loss": 0.6522,
      "step": 684500
    },
    {
      "epoch": 7.2463781157203275,
      "eval_loss": 0.41022807359695435,
      "eval_runtime": 46.5088,
      "eval_samples_per_second": 3610.717,
      "eval_steps_per_second": 451.356,
      "step": 684500
    },
    {
      "epoch": 7.246907437500331,
      "grad_norm": 4.398900032043457,
      "learning_rate": 1.3780965488037265e-05,
      "loss": 0.6555,
      "step": 684550
    },
    {
      "epoch": 7.247436759280334,
      "grad_norm": 4.355193614959717,
      "learning_rate": 1.3778318865128098e-05,
      "loss": 0.663,
      "step": 684600
    },
    {
      "epoch": 7.247966081060337,
      "grad_norm": 4.463001728057861,
      "learning_rate": 1.3775672242218928e-05,
      "loss": 0.6562,
      "step": 684650
    },
    {
      "epoch": 7.248495402840341,
      "grad_norm": 4.385109901428223,
      "learning_rate": 1.3773025619309762e-05,
      "loss": 0.6553,
      "step": 684700
    },
    {
      "epoch": 7.249024724620344,
      "grad_norm": 4.000576019287109,
      "learning_rate": 1.3770378996400593e-05,
      "loss": 0.6556,
      "step": 684750
    },
    {
      "epoch": 7.249554046400347,
      "grad_norm": 4.4418134689331055,
      "learning_rate": 1.3767732373491427e-05,
      "loss": 0.665,
      "step": 684800
    },
    {
      "epoch": 7.25008336818035,
      "grad_norm": 4.3572187423706055,
      "learning_rate": 1.3765085750582258e-05,
      "loss": 0.6517,
      "step": 684850
    },
    {
      "epoch": 7.250612689960354,
      "grad_norm": 4.111932754516602,
      "learning_rate": 1.376243912767309e-05,
      "loss": 0.6512,
      "step": 684900
    },
    {
      "epoch": 7.251142011740357,
      "grad_norm": 4.273301124572754,
      "learning_rate": 1.3759792504763921e-05,
      "loss": 0.6652,
      "step": 684950
    },
    {
      "epoch": 7.251671333520361,
      "grad_norm": 3.982386589050293,
      "learning_rate": 1.3757145881854755e-05,
      "loss": 0.6616,
      "step": 685000
    },
    {
      "epoch": 7.251671333520361,
      "eval_loss": 0.4102634787559509,
      "eval_runtime": 48.1165,
      "eval_samples_per_second": 3490.074,
      "eval_steps_per_second": 436.275,
      "step": 685000
    },
    {
      "epoch": 7.2522006553003635,
      "grad_norm": 4.550736904144287,
      "learning_rate": 1.3754499258945586e-05,
      "loss": 0.6637,
      "step": 685050
    },
    {
      "epoch": 7.252729977080367,
      "grad_norm": 4.93590784072876,
      "learning_rate": 1.3751852636036418e-05,
      "loss": 0.6649,
      "step": 685100
    },
    {
      "epoch": 7.25325929886037,
      "grad_norm": 4.806260108947754,
      "learning_rate": 1.374920601312725e-05,
      "loss": 0.6423,
      "step": 685150
    },
    {
      "epoch": 7.253788620640374,
      "grad_norm": 4.543754577636719,
      "learning_rate": 1.3746559390218083e-05,
      "loss": 0.6614,
      "step": 685200
    },
    {
      "epoch": 7.254317942420377,
      "grad_norm": 4.81364631652832,
      "learning_rate": 1.3743912767308914e-05,
      "loss": 0.6487,
      "step": 685250
    },
    {
      "epoch": 7.2548472642003805,
      "grad_norm": 4.4459662437438965,
      "learning_rate": 1.3741266144399748e-05,
      "loss": 0.6491,
      "step": 685300
    },
    {
      "epoch": 7.255376585980383,
      "grad_norm": 4.750245094299316,
      "learning_rate": 1.3738619521490579e-05,
      "loss": 0.6517,
      "step": 685350
    },
    {
      "epoch": 7.255905907760386,
      "grad_norm": 4.2311787605285645,
      "learning_rate": 1.3735972898581411e-05,
      "loss": 0.6575,
      "step": 685400
    },
    {
      "epoch": 7.25643522954039,
      "grad_norm": 5.144537448883057,
      "learning_rate": 1.3733326275672242e-05,
      "loss": 0.6688,
      "step": 685450
    },
    {
      "epoch": 7.256964551320393,
      "grad_norm": 4.238658905029297,
      "learning_rate": 1.3730679652763076e-05,
      "loss": 0.6655,
      "step": 685500
    },
    {
      "epoch": 7.256964551320393,
      "eval_loss": 0.40926069021224976,
      "eval_runtime": 47.3729,
      "eval_samples_per_second": 3544.854,
      "eval_steps_per_second": 443.123,
      "step": 685500
    },
    {
      "epoch": 7.257493873100397,
      "grad_norm": 4.235424518585205,
      "learning_rate": 1.3728033029853907e-05,
      "loss": 0.646,
      "step": 685550
    },
    {
      "epoch": 7.2580231948803995,
      "grad_norm": 4.554302215576172,
      "learning_rate": 1.372538640694474e-05,
      "loss": 0.6635,
      "step": 685600
    },
    {
      "epoch": 7.258552516660403,
      "grad_norm": 4.318855285644531,
      "learning_rate": 1.3722739784035571e-05,
      "loss": 0.6511,
      "step": 685650
    },
    {
      "epoch": 7.259081838440406,
      "grad_norm": 4.600611686706543,
      "learning_rate": 1.3720093161126404e-05,
      "loss": 0.66,
      "step": 685700
    },
    {
      "epoch": 7.25961116022041,
      "grad_norm": 4.527735710144043,
      "learning_rate": 1.3717499470675419e-05,
      "loss": 0.6552,
      "step": 685750
    },
    {
      "epoch": 7.260140482000413,
      "grad_norm": 4.68776798248291,
      "learning_rate": 1.3714852847766253e-05,
      "loss": 0.6596,
      "step": 685800
    },
    {
      "epoch": 7.2606698037804165,
      "grad_norm": 4.110363960266113,
      "learning_rate": 1.3712206224857083e-05,
      "loss": 0.6508,
      "step": 685850
    },
    {
      "epoch": 7.261199125560419,
      "grad_norm": 4.642168045043945,
      "learning_rate": 1.3709559601947916e-05,
      "loss": 0.6478,
      "step": 685900
    },
    {
      "epoch": 7.261728447340423,
      "grad_norm": 4.863343715667725,
      "learning_rate": 1.3706912979038746e-05,
      "loss": 0.666,
      "step": 685950
    },
    {
      "epoch": 7.262257769120426,
      "grad_norm": 4.3458709716796875,
      "learning_rate": 1.370426635612958e-05,
      "loss": 0.6539,
      "step": 686000
    },
    {
      "epoch": 7.262257769120426,
      "eval_loss": 0.40945470333099365,
      "eval_runtime": 46.8506,
      "eval_samples_per_second": 3584.373,
      "eval_steps_per_second": 448.063,
      "step": 686000
    },
    {
      "epoch": 7.26278709090043,
      "grad_norm": 4.21749210357666,
      "learning_rate": 1.3701619733220411e-05,
      "loss": 0.6609,
      "step": 686050
    },
    {
      "epoch": 7.263316412680433,
      "grad_norm": 4.7047834396362305,
      "learning_rate": 1.3698973110311245e-05,
      "loss": 0.6567,
      "step": 686100
    },
    {
      "epoch": 7.2638457344604355,
      "grad_norm": 4.494366645812988,
      "learning_rate": 1.3696326487402076e-05,
      "loss": 0.6579,
      "step": 686150
    },
    {
      "epoch": 7.264375056240439,
      "grad_norm": 4.460284233093262,
      "learning_rate": 1.3693679864492908e-05,
      "loss": 0.6497,
      "step": 686200
    },
    {
      "epoch": 7.264904378020442,
      "grad_norm": 4.307521820068359,
      "learning_rate": 1.369103324158374e-05,
      "loss": 0.651,
      "step": 686250
    },
    {
      "epoch": 7.265433699800446,
      "grad_norm": 4.251468181610107,
      "learning_rate": 1.3688386618674573e-05,
      "loss": 0.6598,
      "step": 686300
    },
    {
      "epoch": 7.265963021580449,
      "grad_norm": 4.195022106170654,
      "learning_rate": 1.3685739995765404e-05,
      "loss": 0.658,
      "step": 686350
    },
    {
      "epoch": 7.2664923433604525,
      "grad_norm": 4.63209867477417,
      "learning_rate": 1.3683093372856236e-05,
      "loss": 0.6535,
      "step": 686400
    },
    {
      "epoch": 7.267021665140455,
      "grad_norm": 4.457833290100098,
      "learning_rate": 1.3680446749947067e-05,
      "loss": 0.6641,
      "step": 686450
    },
    {
      "epoch": 7.267550986920459,
      "grad_norm": 4.5102972984313965,
      "learning_rate": 1.3677800127037901e-05,
      "loss": 0.6557,
      "step": 686500
    },
    {
      "epoch": 7.267550986920459,
      "eval_loss": 0.40950265526771545,
      "eval_runtime": 46.8596,
      "eval_samples_per_second": 3583.683,
      "eval_steps_per_second": 447.976,
      "step": 686500
    },
    {
      "epoch": 7.268080308700462,
      "grad_norm": 4.452399253845215,
      "learning_rate": 1.3675153504128732e-05,
      "loss": 0.6597,
      "step": 686550
    },
    {
      "epoch": 7.268609630480466,
      "grad_norm": 4.802010536193848,
      "learning_rate": 1.3672506881219566e-05,
      "loss": 0.6543,
      "step": 686600
    },
    {
      "epoch": 7.269138952260469,
      "grad_norm": 4.602299690246582,
      "learning_rate": 1.3669860258310397e-05,
      "loss": 0.6567,
      "step": 686650
    },
    {
      "epoch": 7.269668274040472,
      "grad_norm": 4.685052394866943,
      "learning_rate": 1.3667213635401229e-05,
      "loss": 0.6731,
      "step": 686700
    },
    {
      "epoch": 7.270197595820475,
      "grad_norm": 4.483109474182129,
      "learning_rate": 1.366456701249206e-05,
      "loss": 0.6529,
      "step": 686750
    },
    {
      "epoch": 7.270726917600479,
      "grad_norm": 4.519389629364014,
      "learning_rate": 1.3661920389582894e-05,
      "loss": 0.6533,
      "step": 686800
    },
    {
      "epoch": 7.271256239380482,
      "grad_norm": 4.850531578063965,
      "learning_rate": 1.3659273766673725e-05,
      "loss": 0.6524,
      "step": 686850
    },
    {
      "epoch": 7.271785561160485,
      "grad_norm": 4.428175449371338,
      "learning_rate": 1.3656627143764559e-05,
      "loss": 0.6676,
      "step": 686900
    },
    {
      "epoch": 7.2723148829404884,
      "grad_norm": 4.582762718200684,
      "learning_rate": 1.365398052085539e-05,
      "loss": 0.6463,
      "step": 686950
    },
    {
      "epoch": 7.272844204720491,
      "grad_norm": 4.340299606323242,
      "learning_rate": 1.3651333897946222e-05,
      "loss": 0.6514,
      "step": 687000
    },
    {
      "epoch": 7.272844204720491,
      "eval_loss": 0.40840157866477966,
      "eval_runtime": 47.7398,
      "eval_samples_per_second": 3517.607,
      "eval_steps_per_second": 439.717,
      "step": 687000
    },
    {
      "epoch": 7.273373526500495,
      "grad_norm": 4.432886600494385,
      "learning_rate": 1.3648687275037053e-05,
      "loss": 0.6533,
      "step": 687050
    },
    {
      "epoch": 7.273902848280498,
      "grad_norm": 4.701609134674072,
      "learning_rate": 1.3646040652127887e-05,
      "loss": 0.6629,
      "step": 687100
    },
    {
      "epoch": 7.274432170060502,
      "grad_norm": 4.504367828369141,
      "learning_rate": 1.3643394029218717e-05,
      "loss": 0.6586,
      "step": 687150
    },
    {
      "epoch": 7.274961491840505,
      "grad_norm": 4.52092981338501,
      "learning_rate": 1.3640747406309551e-05,
      "loss": 0.6617,
      "step": 687200
    },
    {
      "epoch": 7.275490813620508,
      "grad_norm": 4.289580821990967,
      "learning_rate": 1.3638100783400382e-05,
      "loss": 0.6536,
      "step": 687250
    },
    {
      "epoch": 7.276020135400511,
      "grad_norm": 4.6161675453186035,
      "learning_rate": 1.3635454160491215e-05,
      "loss": 0.6596,
      "step": 687300
    },
    {
      "epoch": 7.276549457180515,
      "grad_norm": 4.608397960662842,
      "learning_rate": 1.3632807537582045e-05,
      "loss": 0.6553,
      "step": 687350
    },
    {
      "epoch": 7.277078778960518,
      "grad_norm": 4.575422286987305,
      "learning_rate": 1.363016091467288e-05,
      "loss": 0.662,
      "step": 687400
    },
    {
      "epoch": 7.277608100740522,
      "grad_norm": 4.121002674102783,
      "learning_rate": 1.362751429176371e-05,
      "loss": 0.6467,
      "step": 687450
    },
    {
      "epoch": 7.278137422520524,
      "grad_norm": 4.28119421005249,
      "learning_rate": 1.3624867668854544e-05,
      "loss": 0.6564,
      "step": 687500
    },
    {
      "epoch": 7.278137422520524,
      "eval_loss": 0.4095743000507355,
      "eval_runtime": 46.636,
      "eval_samples_per_second": 3600.868,
      "eval_steps_per_second": 450.125,
      "step": 687500
    },
    {
      "epoch": 7.278666744300528,
      "grad_norm": 4.1675310134887695,
      "learning_rate": 1.3622221045945375e-05,
      "loss": 0.6515,
      "step": 687550
    },
    {
      "epoch": 7.279196066080531,
      "grad_norm": 4.186278820037842,
      "learning_rate": 1.3619574423036207e-05,
      "loss": 0.6539,
      "step": 687600
    },
    {
      "epoch": 7.279725387860534,
      "grad_norm": 5.012588024139404,
      "learning_rate": 1.3616927800127038e-05,
      "loss": 0.655,
      "step": 687650
    },
    {
      "epoch": 7.280254709640538,
      "grad_norm": 4.011722564697266,
      "learning_rate": 1.3614281177217872e-05,
      "loss": 0.665,
      "step": 687700
    },
    {
      "epoch": 7.2807840314205405,
      "grad_norm": 4.680367469787598,
      "learning_rate": 1.3611634554308703e-05,
      "loss": 0.6584,
      "step": 687750
    },
    {
      "epoch": 7.281313353200544,
      "grad_norm": 4.573955059051514,
      "learning_rate": 1.3608987931399535e-05,
      "loss": 0.6548,
      "step": 687800
    },
    {
      "epoch": 7.281842674980547,
      "grad_norm": 4.437162399291992,
      "learning_rate": 1.3606341308490366e-05,
      "loss": 0.6585,
      "step": 687850
    },
    {
      "epoch": 7.282371996760551,
      "grad_norm": 4.5745463371276855,
      "learning_rate": 1.36036946855812e-05,
      "loss": 0.654,
      "step": 687900
    },
    {
      "epoch": 7.282901318540554,
      "grad_norm": 4.250133037567139,
      "learning_rate": 1.360104806267203e-05,
      "loss": 0.6559,
      "step": 687950
    },
    {
      "epoch": 7.2834306403205575,
      "grad_norm": 4.626062870025635,
      "learning_rate": 1.3598401439762865e-05,
      "loss": 0.6515,
      "step": 688000
    },
    {
      "epoch": 7.2834306403205575,
      "eval_loss": 0.40824514627456665,
      "eval_runtime": 46.5309,
      "eval_samples_per_second": 3608.999,
      "eval_steps_per_second": 451.141,
      "step": 688000
    },
    {
      "epoch": 7.28395996210056,
      "grad_norm": 4.572105407714844,
      "learning_rate": 1.3595754816853696e-05,
      "loss": 0.6596,
      "step": 688050
    },
    {
      "epoch": 7.284489283880564,
      "grad_norm": 4.529689788818359,
      "learning_rate": 1.3593108193944528e-05,
      "loss": 0.6488,
      "step": 688100
    },
    {
      "epoch": 7.285018605660567,
      "grad_norm": 4.5680623054504395,
      "learning_rate": 1.3590461571035359e-05,
      "loss": 0.6683,
      "step": 688150
    },
    {
      "epoch": 7.285547927440571,
      "grad_norm": 4.165226459503174,
      "learning_rate": 1.3587814948126193e-05,
      "loss": 0.6606,
      "step": 688200
    },
    {
      "epoch": 7.286077249220574,
      "grad_norm": 4.173739910125732,
      "learning_rate": 1.3585168325217024e-05,
      "loss": 0.6648,
      "step": 688250
    },
    {
      "epoch": 7.286606571000577,
      "grad_norm": 4.561232566833496,
      "learning_rate": 1.3582521702307858e-05,
      "loss": 0.6594,
      "step": 688300
    },
    {
      "epoch": 7.28713589278058,
      "grad_norm": 4.971189022064209,
      "learning_rate": 1.3579875079398688e-05,
      "loss": 0.6494,
      "step": 688350
    },
    {
      "epoch": 7.287665214560583,
      "grad_norm": 4.913223743438721,
      "learning_rate": 1.357722845648952e-05,
      "loss": 0.6592,
      "step": 688400
    },
    {
      "epoch": 7.288194536340587,
      "grad_norm": 4.714786052703857,
      "learning_rate": 1.3574581833580351e-05,
      "loss": 0.6646,
      "step": 688450
    },
    {
      "epoch": 7.28872385812059,
      "grad_norm": 4.076396942138672,
      "learning_rate": 1.3571935210671186e-05,
      "loss": 0.6561,
      "step": 688500
    },
    {
      "epoch": 7.28872385812059,
      "eval_loss": 0.40867358446121216,
      "eval_runtime": 46.581,
      "eval_samples_per_second": 3605.116,
      "eval_steps_per_second": 450.656,
      "step": 688500
    },
    {
      "epoch": 7.2892531799005935,
      "grad_norm": 4.3436150550842285,
      "learning_rate": 1.3569288587762016e-05,
      "loss": 0.6581,
      "step": 688550
    },
    {
      "epoch": 7.289782501680596,
      "grad_norm": 4.518987655639648,
      "learning_rate": 1.356664196485285e-05,
      "loss": 0.6678,
      "step": 688600
    },
    {
      "epoch": 7.2903118234606,
      "grad_norm": 4.3064866065979,
      "learning_rate": 1.3563995341943681e-05,
      "loss": 0.6534,
      "step": 688650
    },
    {
      "epoch": 7.290841145240603,
      "grad_norm": 4.698751926422119,
      "learning_rate": 1.3561348719034514e-05,
      "loss": 0.6539,
      "step": 688700
    },
    {
      "epoch": 7.291370467020607,
      "grad_norm": 4.741601943969727,
      "learning_rate": 1.3558702096125344e-05,
      "loss": 0.6525,
      "step": 688750
    },
    {
      "epoch": 7.29189978880061,
      "grad_norm": 4.697784423828125,
      "learning_rate": 1.3556055473216178e-05,
      "loss": 0.6602,
      "step": 688800
    },
    {
      "epoch": 7.292429110580613,
      "grad_norm": 4.785280227661133,
      "learning_rate": 1.3553408850307009e-05,
      "loss": 0.6419,
      "step": 688850
    },
    {
      "epoch": 7.292958432360616,
      "grad_norm": 4.478278636932373,
      "learning_rate": 1.355076222739784e-05,
      "loss": 0.6591,
      "step": 688900
    },
    {
      "epoch": 7.29348775414062,
      "grad_norm": 4.430609703063965,
      "learning_rate": 1.3548115604488674e-05,
      "loss": 0.657,
      "step": 688950
    },
    {
      "epoch": 7.294017075920623,
      "grad_norm": 4.460048675537109,
      "learning_rate": 1.3545468981579505e-05,
      "loss": 0.6572,
      "step": 689000
    },
    {
      "epoch": 7.294017075920623,
      "eval_loss": 0.41031092405319214,
      "eval_runtime": 46.57,
      "eval_samples_per_second": 3605.966,
      "eval_steps_per_second": 450.762,
      "step": 689000
    },
    {
      "epoch": 7.294546397700627,
      "grad_norm": 4.54490327835083,
      "learning_rate": 1.3542822358670337e-05,
      "loss": 0.6638,
      "step": 689050
    },
    {
      "epoch": 7.2950757194806295,
      "grad_norm": 4.377680778503418,
      "learning_rate": 1.3540175735761168e-05,
      "loss": 0.6588,
      "step": 689100
    },
    {
      "epoch": 7.295605041260632,
      "grad_norm": 4.274439811706543,
      "learning_rate": 1.3537529112852002e-05,
      "loss": 0.6632,
      "step": 689150
    },
    {
      "epoch": 7.296134363040636,
      "grad_norm": 4.556753635406494,
      "learning_rate": 1.3534882489942832e-05,
      "loss": 0.6579,
      "step": 689200
    },
    {
      "epoch": 7.296663684820639,
      "grad_norm": 4.505489349365234,
      "learning_rate": 1.3532235867033667e-05,
      "loss": 0.6561,
      "step": 689250
    },
    {
      "epoch": 7.297193006600643,
      "grad_norm": 4.4023518562316895,
      "learning_rate": 1.3529589244124497e-05,
      "loss": 0.6507,
      "step": 689300
    },
    {
      "epoch": 7.297722328380646,
      "grad_norm": 3.9273252487182617,
      "learning_rate": 1.352694262121533e-05,
      "loss": 0.6444,
      "step": 689350
    },
    {
      "epoch": 7.298251650160649,
      "grad_norm": 4.342301368713379,
      "learning_rate": 1.352429599830616e-05,
      "loss": 0.6622,
      "step": 689400
    },
    {
      "epoch": 7.298780971940652,
      "grad_norm": 4.492201805114746,
      "learning_rate": 1.3521649375396995e-05,
      "loss": 0.6523,
      "step": 689450
    },
    {
      "epoch": 7.299310293720656,
      "grad_norm": 4.8884687423706055,
      "learning_rate": 1.3519002752487825e-05,
      "loss": 0.6659,
      "step": 689500
    },
    {
      "epoch": 7.299310293720656,
      "eval_loss": 0.40916988253593445,
      "eval_runtime": 48.3403,
      "eval_samples_per_second": 3473.916,
      "eval_steps_per_second": 434.255,
      "step": 689500
    },
    {
      "epoch": 7.299839615500659,
      "grad_norm": 4.189074993133545,
      "learning_rate": 1.3516356129578658e-05,
      "loss": 0.6414,
      "step": 689550
    },
    {
      "epoch": 7.300368937280663,
      "grad_norm": 4.398744106292725,
      "learning_rate": 1.3513709506669488e-05,
      "loss": 0.6564,
      "step": 689600
    },
    {
      "epoch": 7.3008982590606655,
      "grad_norm": 4.550641059875488,
      "learning_rate": 1.3511062883760322e-05,
      "loss": 0.6623,
      "step": 689650
    },
    {
      "epoch": 7.301427580840669,
      "grad_norm": 4.603904724121094,
      "learning_rate": 1.3508416260851153e-05,
      "loss": 0.6561,
      "step": 689700
    },
    {
      "epoch": 7.301956902620672,
      "grad_norm": 4.610896110534668,
      "learning_rate": 1.350582257040017e-05,
      "loss": 0.6597,
      "step": 689750
    },
    {
      "epoch": 7.302486224400676,
      "grad_norm": 4.543701171875,
      "learning_rate": 1.3503175947491e-05,
      "loss": 0.6494,
      "step": 689800
    },
    {
      "epoch": 7.303015546180679,
      "grad_norm": 4.596752166748047,
      "learning_rate": 1.3500529324581834e-05,
      "loss": 0.6636,
      "step": 689850
    },
    {
      "epoch": 7.303544867960682,
      "grad_norm": 4.780828952789307,
      "learning_rate": 1.3497882701672665e-05,
      "loss": 0.667,
      "step": 689900
    },
    {
      "epoch": 7.304074189740685,
      "grad_norm": 4.787291526794434,
      "learning_rate": 1.34952360787635e-05,
      "loss": 0.6694,
      "step": 689950
    },
    {
      "epoch": 7.304603511520688,
      "grad_norm": 4.192182540893555,
      "learning_rate": 1.349258945585433e-05,
      "loss": 0.654,
      "step": 690000
    },
    {
      "epoch": 7.304603511520688,
      "eval_loss": 0.4080619513988495,
      "eval_runtime": 48.3703,
      "eval_samples_per_second": 3471.761,
      "eval_steps_per_second": 433.986,
      "step": 690000
    },
    {
      "epoch": 7.305132833300692,
      "grad_norm": 4.592154026031494,
      "learning_rate": 1.3489942832945162e-05,
      "loss": 0.6441,
      "step": 690050
    },
    {
      "epoch": 7.305662155080695,
      "grad_norm": 4.1181769371032715,
      "learning_rate": 1.3487296210035993e-05,
      "loss": 0.6582,
      "step": 690100
    },
    {
      "epoch": 7.306191476860699,
      "grad_norm": 4.372077941894531,
      "learning_rate": 1.3484649587126827e-05,
      "loss": 0.657,
      "step": 690150
    },
    {
      "epoch": 7.3067207986407015,
      "grad_norm": 4.5102925300598145,
      "learning_rate": 1.3482002964217658e-05,
      "loss": 0.6749,
      "step": 690200
    },
    {
      "epoch": 7.307250120420705,
      "grad_norm": 4.301499366760254,
      "learning_rate": 1.3479356341308492e-05,
      "loss": 0.6543,
      "step": 690250
    },
    {
      "epoch": 7.307779442200708,
      "grad_norm": 4.649161338806152,
      "learning_rate": 1.3476709718399323e-05,
      "loss": 0.6561,
      "step": 690300
    },
    {
      "epoch": 7.308308763980712,
      "grad_norm": 4.77476692199707,
      "learning_rate": 1.3474063095490155e-05,
      "loss": 0.6607,
      "step": 690350
    },
    {
      "epoch": 7.308838085760715,
      "grad_norm": 4.378435134887695,
      "learning_rate": 1.3471416472580986e-05,
      "loss": 0.6522,
      "step": 690400
    },
    {
      "epoch": 7.3093674075407185,
      "grad_norm": 4.649595737457275,
      "learning_rate": 1.346876984967182e-05,
      "loss": 0.6498,
      "step": 690450
    },
    {
      "epoch": 7.309896729320721,
      "grad_norm": 4.557941436767578,
      "learning_rate": 1.346612322676265e-05,
      "loss": 0.6567,
      "step": 690500
    },
    {
      "epoch": 7.309896729320721,
      "eval_loss": 0.40784063935279846,
      "eval_runtime": 47.5105,
      "eval_samples_per_second": 3534.587,
      "eval_steps_per_second": 441.839,
      "step": 690500
    },
    {
      "epoch": 7.310426051100725,
      "grad_norm": 4.14375638961792,
      "learning_rate": 1.3463476603853483e-05,
      "loss": 0.6569,
      "step": 690550
    },
    {
      "epoch": 7.310955372880728,
      "grad_norm": 4.386793613433838,
      "learning_rate": 1.3460829980944314e-05,
      "loss": 0.6698,
      "step": 690600
    },
    {
      "epoch": 7.311484694660731,
      "grad_norm": 4.533946990966797,
      "learning_rate": 1.3458183358035148e-05,
      "loss": 0.6699,
      "step": 690650
    },
    {
      "epoch": 7.312014016440735,
      "grad_norm": 4.235264301300049,
      "learning_rate": 1.3455536735125978e-05,
      "loss": 0.6571,
      "step": 690700
    },
    {
      "epoch": 7.312543338220737,
      "grad_norm": 4.460202693939209,
      "learning_rate": 1.3452890112216813e-05,
      "loss": 0.6618,
      "step": 690750
    },
    {
      "epoch": 7.313072660000741,
      "grad_norm": 4.990918159484863,
      "learning_rate": 1.3450243489307643e-05,
      "loss": 0.6597,
      "step": 690800
    },
    {
      "epoch": 7.313601981780744,
      "grad_norm": 4.66109037399292,
      "learning_rate": 1.3447596866398476e-05,
      "loss": 0.6534,
      "step": 690850
    },
    {
      "epoch": 7.314131303560748,
      "grad_norm": 4.0803608894348145,
      "learning_rate": 1.3444950243489306e-05,
      "loss": 0.656,
      "step": 690900
    },
    {
      "epoch": 7.314660625340751,
      "grad_norm": 4.564110279083252,
      "learning_rate": 1.344230362058014e-05,
      "loss": 0.6573,
      "step": 690950
    },
    {
      "epoch": 7.315189947120754,
      "grad_norm": 4.134589195251465,
      "learning_rate": 1.3439656997670971e-05,
      "loss": 0.6597,
      "step": 691000
    },
    {
      "epoch": 7.315189947120754,
      "eval_loss": 0.4088863730430603,
      "eval_runtime": 46.8045,
      "eval_samples_per_second": 3587.904,
      "eval_steps_per_second": 448.504,
      "step": 691000
    },
    {
      "epoch": 7.315719268900757,
      "grad_norm": 4.3702521324157715,
      "learning_rate": 1.3437010374761805e-05,
      "loss": 0.6653,
      "step": 691050
    },
    {
      "epoch": 7.316248590680761,
      "grad_norm": 5.006794452667236,
      "learning_rate": 1.3434363751852636e-05,
      "loss": 0.6489,
      "step": 691100
    },
    {
      "epoch": 7.316777912460764,
      "grad_norm": 4.01723051071167,
      "learning_rate": 1.3431717128943468e-05,
      "loss": 0.656,
      "step": 691150
    },
    {
      "epoch": 7.317307234240768,
      "grad_norm": 4.158987045288086,
      "learning_rate": 1.34290705060343e-05,
      "loss": 0.6698,
      "step": 691200
    },
    {
      "epoch": 7.3178365560207705,
      "grad_norm": 4.4071736335754395,
      "learning_rate": 1.3426423883125133e-05,
      "loss": 0.6447,
      "step": 691250
    },
    {
      "epoch": 7.318365877800774,
      "grad_norm": 3.9953136444091797,
      "learning_rate": 1.3423777260215964e-05,
      "loss": 0.6507,
      "step": 691300
    },
    {
      "epoch": 7.318895199580777,
      "grad_norm": 4.563764572143555,
      "learning_rate": 1.3421130637306798e-05,
      "loss": 0.6596,
      "step": 691350
    },
    {
      "epoch": 7.31942452136078,
      "grad_norm": 4.867680549621582,
      "learning_rate": 1.3418484014397629e-05,
      "loss": 0.6683,
      "step": 691400
    },
    {
      "epoch": 7.319953843140784,
      "grad_norm": 4.794388294219971,
      "learning_rate": 1.3415837391488461e-05,
      "loss": 0.6492,
      "step": 691450
    },
    {
      "epoch": 7.320483164920787,
      "grad_norm": 4.814506530761719,
      "learning_rate": 1.3413190768579292e-05,
      "loss": 0.6537,
      "step": 691500
    },
    {
      "epoch": 7.320483164920787,
      "eval_loss": 0.40806010365486145,
      "eval_runtime": 47.9253,
      "eval_samples_per_second": 3503.993,
      "eval_steps_per_second": 438.015,
      "step": 691500
    },
    {
      "epoch": 7.32101248670079,
      "grad_norm": 4.425379276275635,
      "learning_rate": 1.3410544145670126e-05,
      "loss": 0.6549,
      "step": 691550
    },
    {
      "epoch": 7.321541808480793,
      "grad_norm": 4.952877998352051,
      "learning_rate": 1.3407897522760957e-05,
      "loss": 0.6543,
      "step": 691600
    },
    {
      "epoch": 7.322071130260797,
      "grad_norm": 4.474166393280029,
      "learning_rate": 1.340525089985179e-05,
      "loss": 0.6602,
      "step": 691650
    },
    {
      "epoch": 7.3226004520408,
      "grad_norm": 4.446521282196045,
      "learning_rate": 1.3402604276942622e-05,
      "loss": 0.6567,
      "step": 691700
    },
    {
      "epoch": 7.323129773820804,
      "grad_norm": 4.262055397033691,
      "learning_rate": 1.3400010586491638e-05,
      "loss": 0.6514,
      "step": 691750
    },
    {
      "epoch": 7.3236590956008065,
      "grad_norm": 4.635308742523193,
      "learning_rate": 1.3397363963582469e-05,
      "loss": 0.6463,
      "step": 691800
    },
    {
      "epoch": 7.32418841738081,
      "grad_norm": 4.769753456115723,
      "learning_rate": 1.3394717340673301e-05,
      "loss": 0.6657,
      "step": 691850
    },
    {
      "epoch": 7.324717739160813,
      "grad_norm": 4.5758562088012695,
      "learning_rate": 1.3392070717764132e-05,
      "loss": 0.6523,
      "step": 691900
    },
    {
      "epoch": 7.325247060940817,
      "grad_norm": 4.541317939758301,
      "learning_rate": 1.3389424094854966e-05,
      "loss": 0.6454,
      "step": 691950
    },
    {
      "epoch": 7.32577638272082,
      "grad_norm": 4.106100082397461,
      "learning_rate": 1.3386777471945797e-05,
      "loss": 0.6495,
      "step": 692000
    },
    {
      "epoch": 7.32577638272082,
      "eval_loss": 0.40834909677505493,
      "eval_runtime": 48.4957,
      "eval_samples_per_second": 3462.779,
      "eval_steps_per_second": 432.863,
      "step": 692000
    },
    {
      "epoch": 7.3263057045008235,
      "grad_norm": 4.497256755828857,
      "learning_rate": 1.338413084903663e-05,
      "loss": 0.6634,
      "step": 692050
    },
    {
      "epoch": 7.326835026280826,
      "grad_norm": 4.728212833404541,
      "learning_rate": 1.3381484226127461e-05,
      "loss": 0.6533,
      "step": 692100
    },
    {
      "epoch": 7.327364348060829,
      "grad_norm": 4.657793045043945,
      "learning_rate": 1.3378837603218294e-05,
      "loss": 0.6619,
      "step": 692150
    },
    {
      "epoch": 7.327893669840833,
      "grad_norm": 4.0349440574646,
      "learning_rate": 1.3376190980309124e-05,
      "loss": 0.6501,
      "step": 692200
    },
    {
      "epoch": 7.328422991620836,
      "grad_norm": 4.5928521156311035,
      "learning_rate": 1.3373544357399959e-05,
      "loss": 0.648,
      "step": 692250
    },
    {
      "epoch": 7.32895231340084,
      "grad_norm": 4.25146484375,
      "learning_rate": 1.337089773449079e-05,
      "loss": 0.6629,
      "step": 692300
    },
    {
      "epoch": 7.3294816351808425,
      "grad_norm": 4.413228511810303,
      "learning_rate": 1.3368251111581623e-05,
      "loss": 0.6518,
      "step": 692350
    },
    {
      "epoch": 7.330010956960846,
      "grad_norm": 4.853608131408691,
      "learning_rate": 1.3365604488672454e-05,
      "loss": 0.6506,
      "step": 692400
    },
    {
      "epoch": 7.330540278740849,
      "grad_norm": 4.711048603057861,
      "learning_rate": 1.3362957865763287e-05,
      "loss": 0.658,
      "step": 692450
    },
    {
      "epoch": 7.331069600520853,
      "grad_norm": 4.511028289794922,
      "learning_rate": 1.3360311242854117e-05,
      "loss": 0.6579,
      "step": 692500
    },
    {
      "epoch": 7.331069600520853,
      "eval_loss": 0.40778297185897827,
      "eval_runtime": 47.988,
      "eval_samples_per_second": 3499.419,
      "eval_steps_per_second": 437.443,
      "step": 692500
    },
    {
      "epoch": 7.331598922300856,
      "grad_norm": 4.237062454223633,
      "learning_rate": 1.3357664619944951e-05,
      "loss": 0.6678,
      "step": 692550
    },
    {
      "epoch": 7.3321282440808595,
      "grad_norm": 4.519930362701416,
      "learning_rate": 1.3355017997035782e-05,
      "loss": 0.6436,
      "step": 692600
    },
    {
      "epoch": 7.332657565860862,
      "grad_norm": 4.530292510986328,
      "learning_rate": 1.3352371374126616e-05,
      "loss": 0.6392,
      "step": 692650
    },
    {
      "epoch": 7.333186887640866,
      "grad_norm": 4.2109785079956055,
      "learning_rate": 1.3349724751217447e-05,
      "loss": 0.6502,
      "step": 692700
    },
    {
      "epoch": 7.333716209420869,
      "grad_norm": 4.561074733734131,
      "learning_rate": 1.334707812830828e-05,
      "loss": 0.6618,
      "step": 692750
    },
    {
      "epoch": 7.334245531200873,
      "grad_norm": 4.921684741973877,
      "learning_rate": 1.334443150539911e-05,
      "loss": 0.6675,
      "step": 692800
    },
    {
      "epoch": 7.334774852980876,
      "grad_norm": 4.229778289794922,
      "learning_rate": 1.3341784882489944e-05,
      "loss": 0.6392,
      "step": 692850
    },
    {
      "epoch": 7.3353041747608785,
      "grad_norm": 4.234661102294922,
      "learning_rate": 1.3339138259580775e-05,
      "loss": 0.6588,
      "step": 692900
    },
    {
      "epoch": 7.335833496540882,
      "grad_norm": 4.015070915222168,
      "learning_rate": 1.3336491636671609e-05,
      "loss": 0.659,
      "step": 692950
    },
    {
      "epoch": 7.336362818320885,
      "grad_norm": 4.45693302154541,
      "learning_rate": 1.333384501376244e-05,
      "loss": 0.6594,
      "step": 693000
    },
    {
      "epoch": 7.336362818320885,
      "eval_loss": 0.40820351243019104,
      "eval_runtime": 46.547,
      "eval_samples_per_second": 3607.75,
      "eval_steps_per_second": 450.985,
      "step": 693000
    },
    {
      "epoch": 7.336892140100889,
      "grad_norm": 4.517324447631836,
      "learning_rate": 1.3331198390853272e-05,
      "loss": 0.6596,
      "step": 693050
    },
    {
      "epoch": 7.337421461880892,
      "grad_norm": 4.153736114501953,
      "learning_rate": 1.3328551767944103e-05,
      "loss": 0.6551,
      "step": 693100
    },
    {
      "epoch": 7.3379507836608955,
      "grad_norm": 4.635875701904297,
      "learning_rate": 1.3325905145034937e-05,
      "loss": 0.6641,
      "step": 693150
    },
    {
      "epoch": 7.338480105440898,
      "grad_norm": 4.695226669311523,
      "learning_rate": 1.3323258522125768e-05,
      "loss": 0.6541,
      "step": 693200
    },
    {
      "epoch": 7.339009427220902,
      "grad_norm": 4.290798187255859,
      "learning_rate": 1.33206118992166e-05,
      "loss": 0.6579,
      "step": 693250
    },
    {
      "epoch": 7.339538749000905,
      "grad_norm": 4.679015636444092,
      "learning_rate": 1.331796527630743e-05,
      "loss": 0.6684,
      "step": 693300
    },
    {
      "epoch": 7.340068070780909,
      "grad_norm": 4.452336311340332,
      "learning_rate": 1.3315318653398265e-05,
      "loss": 0.6525,
      "step": 693350
    },
    {
      "epoch": 7.340597392560912,
      "grad_norm": 4.451722145080566,
      "learning_rate": 1.3312672030489095e-05,
      "loss": 0.6487,
      "step": 693400
    },
    {
      "epoch": 7.341126714340915,
      "grad_norm": 4.4388227462768555,
      "learning_rate": 1.331002540757993e-05,
      "loss": 0.6579,
      "step": 693450
    },
    {
      "epoch": 7.341656036120918,
      "grad_norm": 4.50395393371582,
      "learning_rate": 1.330737878467076e-05,
      "loss": 0.6492,
      "step": 693500
    },
    {
      "epoch": 7.341656036120918,
      "eval_loss": 0.40797024965286255,
      "eval_runtime": 46.5273,
      "eval_samples_per_second": 3609.277,
      "eval_steps_per_second": 451.176,
      "step": 693500
    },
    {
      "epoch": 7.342185357900922,
      "grad_norm": 4.608204364776611,
      "learning_rate": 1.3304732161761593e-05,
      "loss": 0.6455,
      "step": 693550
    },
    {
      "epoch": 7.342714679680925,
      "grad_norm": 4.161794185638428,
      "learning_rate": 1.3302085538852423e-05,
      "loss": 0.6474,
      "step": 693600
    },
    {
      "epoch": 7.343244001460928,
      "grad_norm": 4.209745407104492,
      "learning_rate": 1.3299438915943257e-05,
      "loss": 0.6622,
      "step": 693650
    },
    {
      "epoch": 7.3437733232409315,
      "grad_norm": 4.438543796539307,
      "learning_rate": 1.3296792293034088e-05,
      "loss": 0.6542,
      "step": 693700
    },
    {
      "epoch": 7.344302645020934,
      "grad_norm": 4.521501064300537,
      "learning_rate": 1.3294198602583105e-05,
      "loss": 0.6493,
      "step": 693750
    },
    {
      "epoch": 7.344831966800938,
      "grad_norm": 4.501186847686768,
      "learning_rate": 1.3291551979673935e-05,
      "loss": 0.6625,
      "step": 693800
    },
    {
      "epoch": 7.345361288580941,
      "grad_norm": 4.489141941070557,
      "learning_rate": 1.328890535676477e-05,
      "loss": 0.6567,
      "step": 693850
    },
    {
      "epoch": 7.345890610360945,
      "grad_norm": 4.566344738006592,
      "learning_rate": 1.32862587338556e-05,
      "loss": 0.658,
      "step": 693900
    },
    {
      "epoch": 7.346419932140948,
      "grad_norm": 4.267467498779297,
      "learning_rate": 1.3283612110946434e-05,
      "loss": 0.6532,
      "step": 693950
    },
    {
      "epoch": 7.346949253920951,
      "grad_norm": 3.9181056022644043,
      "learning_rate": 1.3280965488037265e-05,
      "loss": 0.6599,
      "step": 694000
    },
    {
      "epoch": 7.346949253920951,
      "eval_loss": 0.40790432691574097,
      "eval_runtime": 46.5025,
      "eval_samples_per_second": 3611.205,
      "eval_steps_per_second": 451.417,
      "step": 694000
    },
    {
      "epoch": 7.347478575700954,
      "grad_norm": 4.339442253112793,
      "learning_rate": 1.3278318865128097e-05,
      "loss": 0.6629,
      "step": 694050
    },
    {
      "epoch": 7.348007897480958,
      "grad_norm": 4.3094940185546875,
      "learning_rate": 1.3275672242218928e-05,
      "loss": 0.6586,
      "step": 694100
    },
    {
      "epoch": 7.348537219260961,
      "grad_norm": 4.510765075683594,
      "learning_rate": 1.3273025619309762e-05,
      "loss": 0.6476,
      "step": 694150
    },
    {
      "epoch": 7.349066541040965,
      "grad_norm": 4.665252685546875,
      "learning_rate": 1.3270378996400593e-05,
      "loss": 0.6594,
      "step": 694200
    },
    {
      "epoch": 7.349595862820967,
      "grad_norm": 4.865769386291504,
      "learning_rate": 1.3267732373491425e-05,
      "loss": 0.6521,
      "step": 694250
    },
    {
      "epoch": 7.350125184600971,
      "grad_norm": 4.9027252197265625,
      "learning_rate": 1.3265085750582256e-05,
      "loss": 0.6568,
      "step": 694300
    },
    {
      "epoch": 7.350654506380974,
      "grad_norm": 4.756205081939697,
      "learning_rate": 1.326243912767309e-05,
      "loss": 0.6614,
      "step": 694350
    },
    {
      "epoch": 7.351183828160977,
      "grad_norm": 4.70967435836792,
      "learning_rate": 1.325979250476392e-05,
      "loss": 0.6508,
      "step": 694400
    },
    {
      "epoch": 7.351713149940981,
      "grad_norm": 4.363969802856445,
      "learning_rate": 1.3257145881854755e-05,
      "loss": 0.6562,
      "step": 694450
    },
    {
      "epoch": 7.3522424717209836,
      "grad_norm": 4.8785014152526855,
      "learning_rate": 1.3254499258945586e-05,
      "loss": 0.6495,
      "step": 694500
    },
    {
      "epoch": 7.3522424717209836,
      "eval_loss": 0.4075305163860321,
      "eval_runtime": 46.4266,
      "eval_samples_per_second": 3617.11,
      "eval_steps_per_second": 452.155,
      "step": 694500
    },
    {
      "epoch": 7.352771793500987,
      "grad_norm": 4.369241237640381,
      "learning_rate": 1.3251852636036418e-05,
      "loss": 0.6711,
      "step": 694550
    },
    {
      "epoch": 7.35330111528099,
      "grad_norm": 4.3674798011779785,
      "learning_rate": 1.3249206013127249e-05,
      "loss": 0.6583,
      "step": 694600
    },
    {
      "epoch": 7.353830437060994,
      "grad_norm": 4.557089805603027,
      "learning_rate": 1.3246559390218083e-05,
      "loss": 0.6682,
      "step": 694650
    },
    {
      "epoch": 7.354359758840997,
      "grad_norm": 4.06779670715332,
      "learning_rate": 1.3243912767308914e-05,
      "loss": 0.6624,
      "step": 694700
    },
    {
      "epoch": 7.3548890806210006,
      "grad_norm": 4.940791130065918,
      "learning_rate": 1.3241266144399748e-05,
      "loss": 0.6567,
      "step": 694750
    },
    {
      "epoch": 7.355418402401003,
      "grad_norm": 4.587807655334473,
      "learning_rate": 1.3238619521490578e-05,
      "loss": 0.6592,
      "step": 694800
    },
    {
      "epoch": 7.355947724181007,
      "grad_norm": 4.3269829750061035,
      "learning_rate": 1.323597289858141e-05,
      "loss": 0.6529,
      "step": 694850
    },
    {
      "epoch": 7.35647704596101,
      "grad_norm": 4.68026876449585,
      "learning_rate": 1.3233326275672241e-05,
      "loss": 0.6497,
      "step": 694900
    },
    {
      "epoch": 7.357006367741014,
      "grad_norm": 4.622245788574219,
      "learning_rate": 1.3230679652763076e-05,
      "loss": 0.6612,
      "step": 694950
    },
    {
      "epoch": 7.357535689521017,
      "grad_norm": 4.221856117248535,
      "learning_rate": 1.3228033029853906e-05,
      "loss": 0.6551,
      "step": 695000
    },
    {
      "epoch": 7.357535689521017,
      "eval_loss": 0.40898096561431885,
      "eval_runtime": 46.5077,
      "eval_samples_per_second": 3610.802,
      "eval_steps_per_second": 451.366,
      "step": 695000
    },
    {
      "epoch": 7.35806501130102,
      "grad_norm": 4.85391902923584,
      "learning_rate": 1.322538640694474e-05,
      "loss": 0.6672,
      "step": 695050
    },
    {
      "epoch": 7.358594333081023,
      "grad_norm": 4.174890518188477,
      "learning_rate": 1.3222739784035571e-05,
      "loss": 0.6512,
      "step": 695100
    },
    {
      "epoch": 7.359123654861026,
      "grad_norm": 4.358777046203613,
      "learning_rate": 1.3220093161126404e-05,
      "loss": 0.6572,
      "step": 695150
    },
    {
      "epoch": 7.35965297664103,
      "grad_norm": 4.415896892547607,
      "learning_rate": 1.3217446538217234e-05,
      "loss": 0.6632,
      "step": 695200
    },
    {
      "epoch": 7.360182298421033,
      "grad_norm": 4.612879276275635,
      "learning_rate": 1.3214799915308068e-05,
      "loss": 0.6593,
      "step": 695250
    },
    {
      "epoch": 7.3607116202010365,
      "grad_norm": 4.77869176864624,
      "learning_rate": 1.3212153292398899e-05,
      "loss": 0.6658,
      "step": 695300
    },
    {
      "epoch": 7.361240941981039,
      "grad_norm": 4.288164138793945,
      "learning_rate": 1.3209506669489733e-05,
      "loss": 0.6552,
      "step": 695350
    },
    {
      "epoch": 7.361770263761043,
      "grad_norm": 4.6031694412231445,
      "learning_rate": 1.3206860046580564e-05,
      "loss": 0.6534,
      "step": 695400
    },
    {
      "epoch": 7.362299585541046,
      "grad_norm": 4.745955467224121,
      "learning_rate": 1.3204213423671396e-05,
      "loss": 0.6484,
      "step": 695450
    },
    {
      "epoch": 7.36282890732105,
      "grad_norm": 4.610215663909912,
      "learning_rate": 1.3201566800762227e-05,
      "loss": 0.6581,
      "step": 695500
    },
    {
      "epoch": 7.36282890732105,
      "eval_loss": 0.40769144892692566,
      "eval_runtime": 46.5154,
      "eval_samples_per_second": 3610.205,
      "eval_steps_per_second": 451.292,
      "step": 695500
    },
    {
      "epoch": 7.363358229101053,
      "grad_norm": 4.234735488891602,
      "learning_rate": 1.3198920177853061e-05,
      "loss": 0.6548,
      "step": 695550
    },
    {
      "epoch": 7.363887550881056,
      "grad_norm": 4.730823040008545,
      "learning_rate": 1.3196273554943892e-05,
      "loss": 0.6518,
      "step": 695600
    },
    {
      "epoch": 7.364416872661059,
      "grad_norm": 4.647848129272461,
      "learning_rate": 1.3193626932034724e-05,
      "loss": 0.6509,
      "step": 695650
    },
    {
      "epoch": 7.364946194441063,
      "grad_norm": 4.372968673706055,
      "learning_rate": 1.3190980309125555e-05,
      "loss": 0.6528,
      "step": 695700
    },
    {
      "epoch": 7.365475516221066,
      "grad_norm": 4.124717712402344,
      "learning_rate": 1.3188386618674573e-05,
      "loss": 0.66,
      "step": 695750
    },
    {
      "epoch": 7.36600483800107,
      "grad_norm": 4.3795485496521,
      "learning_rate": 1.3185739995765404e-05,
      "loss": 0.6547,
      "step": 695800
    },
    {
      "epoch": 7.3665341597810725,
      "grad_norm": 4.527393341064453,
      "learning_rate": 1.3183093372856236e-05,
      "loss": 0.655,
      "step": 695850
    },
    {
      "epoch": 7.367063481561075,
      "grad_norm": 4.8718061447143555,
      "learning_rate": 1.3180446749947067e-05,
      "loss": 0.652,
      "step": 695900
    },
    {
      "epoch": 7.367592803341079,
      "grad_norm": 4.689883708953857,
      "learning_rate": 1.3177800127037901e-05,
      "loss": 0.6468,
      "step": 695950
    },
    {
      "epoch": 7.368122125121082,
      "grad_norm": 4.129220485687256,
      "learning_rate": 1.3175153504128732e-05,
      "loss": 0.6562,
      "step": 696000
    },
    {
      "epoch": 7.368122125121082,
      "eval_loss": 0.40742069482803345,
      "eval_runtime": 46.5305,
      "eval_samples_per_second": 3609.033,
      "eval_steps_per_second": 451.145,
      "step": 696000
    },
    {
      "epoch": 7.368651446901086,
      "grad_norm": 4.201254367828369,
      "learning_rate": 1.3172506881219566e-05,
      "loss": 0.6565,
      "step": 696050
    },
    {
      "epoch": 7.369180768681089,
      "grad_norm": 4.678464412689209,
      "learning_rate": 1.3169860258310396e-05,
      "loss": 0.6513,
      "step": 696100
    },
    {
      "epoch": 7.369710090461092,
      "grad_norm": 4.594119548797607,
      "learning_rate": 1.3167213635401229e-05,
      "loss": 0.6629,
      "step": 696150
    },
    {
      "epoch": 7.370239412241095,
      "grad_norm": 4.665538787841797,
      "learning_rate": 1.316456701249206e-05,
      "loss": 0.658,
      "step": 696200
    },
    {
      "epoch": 7.370768734021099,
      "grad_norm": 4.174034595489502,
      "learning_rate": 1.3161920389582894e-05,
      "loss": 0.6548,
      "step": 696250
    },
    {
      "epoch": 7.371298055801102,
      "grad_norm": 4.560092926025391,
      "learning_rate": 1.3159273766673724e-05,
      "loss": 0.656,
      "step": 696300
    },
    {
      "epoch": 7.371827377581106,
      "grad_norm": 4.3706488609313965,
      "learning_rate": 1.3156627143764558e-05,
      "loss": 0.6488,
      "step": 696350
    },
    {
      "epoch": 7.3723566993611085,
      "grad_norm": 4.679813861846924,
      "learning_rate": 1.315398052085539e-05,
      "loss": 0.6526,
      "step": 696400
    },
    {
      "epoch": 7.372886021141112,
      "grad_norm": 4.525970458984375,
      "learning_rate": 1.3151333897946222e-05,
      "loss": 0.6519,
      "step": 696450
    },
    {
      "epoch": 7.373415342921115,
      "grad_norm": 4.270092487335205,
      "learning_rate": 1.3148687275037052e-05,
      "loss": 0.661,
      "step": 696500
    },
    {
      "epoch": 7.373415342921115,
      "eval_loss": 0.4083971083164215,
      "eval_runtime": 46.5438,
      "eval_samples_per_second": 3607.996,
      "eval_steps_per_second": 451.016,
      "step": 696500
    },
    {
      "epoch": 7.373944664701119,
      "grad_norm": 4.329988479614258,
      "learning_rate": 1.3146040652127886e-05,
      "loss": 0.6544,
      "step": 696550
    },
    {
      "epoch": 7.374473986481122,
      "grad_norm": 4.414948463439941,
      "learning_rate": 1.3143394029218717e-05,
      "loss": 0.656,
      "step": 696600
    },
    {
      "epoch": 7.375003308261125,
      "grad_norm": 4.346622467041016,
      "learning_rate": 1.3140747406309551e-05,
      "loss": 0.6502,
      "step": 696650
    },
    {
      "epoch": 7.375532630041128,
      "grad_norm": 4.572569847106934,
      "learning_rate": 1.3138100783400382e-05,
      "loss": 0.6583,
      "step": 696700
    },
    {
      "epoch": 7.376061951821131,
      "grad_norm": 4.656126499176025,
      "learning_rate": 1.3135454160491214e-05,
      "loss": 0.6493,
      "step": 696750
    },
    {
      "epoch": 7.376591273601135,
      "grad_norm": 4.246035575866699,
      "learning_rate": 1.3132807537582045e-05,
      "loss": 0.6625,
      "step": 696800
    },
    {
      "epoch": 7.377120595381138,
      "grad_norm": 5.28574800491333,
      "learning_rate": 1.3130160914672879e-05,
      "loss": 0.6573,
      "step": 696850
    },
    {
      "epoch": 7.377649917161142,
      "grad_norm": 4.9463791847229,
      "learning_rate": 1.312751429176371e-05,
      "loss": 0.6525,
      "step": 696900
    },
    {
      "epoch": 7.3781792389411445,
      "grad_norm": 4.2368903160095215,
      "learning_rate": 1.3124867668854542e-05,
      "loss": 0.6562,
      "step": 696950
    },
    {
      "epoch": 7.378708560721148,
      "grad_norm": 4.617038726806641,
      "learning_rate": 1.3122221045945373e-05,
      "loss": 0.6585,
      "step": 697000
    },
    {
      "epoch": 7.378708560721148,
      "eval_loss": 0.40803617238998413,
      "eval_runtime": 46.5451,
      "eval_samples_per_second": 3607.898,
      "eval_steps_per_second": 451.003,
      "step": 697000
    },
    {
      "epoch": 7.379237882501151,
      "grad_norm": 4.508868217468262,
      "learning_rate": 1.3119574423036207e-05,
      "loss": 0.6568,
      "step": 697050
    },
    {
      "epoch": 7.379767204281155,
      "grad_norm": 4.331610679626465,
      "learning_rate": 1.3116927800127038e-05,
      "loss": 0.64,
      "step": 697100
    },
    {
      "epoch": 7.380296526061158,
      "grad_norm": 4.467740535736084,
      "learning_rate": 1.3114281177217872e-05,
      "loss": 0.6553,
      "step": 697150
    },
    {
      "epoch": 7.3808258478411615,
      "grad_norm": 4.387482643127441,
      "learning_rate": 1.3111634554308703e-05,
      "loss": 0.6565,
      "step": 697200
    },
    {
      "epoch": 7.381355169621164,
      "grad_norm": 5.126358509063721,
      "learning_rate": 1.3108987931399535e-05,
      "loss": 0.6551,
      "step": 697250
    },
    {
      "epoch": 7.381884491401168,
      "grad_norm": 4.378084182739258,
      "learning_rate": 1.3106341308490366e-05,
      "loss": 0.6543,
      "step": 697300
    },
    {
      "epoch": 7.382413813181171,
      "grad_norm": 4.50685453414917,
      "learning_rate": 1.31036946855812e-05,
      "loss": 0.6592,
      "step": 697350
    },
    {
      "epoch": 7.382943134961174,
      "grad_norm": 4.775802135467529,
      "learning_rate": 1.310104806267203e-05,
      "loss": 0.6595,
      "step": 697400
    },
    {
      "epoch": 7.383472456741178,
      "grad_norm": 5.0858283042907715,
      "learning_rate": 1.3098401439762865e-05,
      "loss": 0.6571,
      "step": 697450
    },
    {
      "epoch": 7.3840017785211804,
      "grad_norm": 4.398684024810791,
      "learning_rate": 1.3095754816853695e-05,
      "loss": 0.6492,
      "step": 697500
    },
    {
      "epoch": 7.3840017785211804,
      "eval_loss": 0.4060991704463959,
      "eval_runtime": 46.4731,
      "eval_samples_per_second": 3613.485,
      "eval_steps_per_second": 451.702,
      "step": 697500
    },
    {
      "epoch": 7.384531100301184,
      "grad_norm": 4.137542724609375,
      "learning_rate": 1.3093108193944528e-05,
      "loss": 0.6496,
      "step": 697550
    },
    {
      "epoch": 7.385060422081187,
      "grad_norm": 5.003629684448242,
      "learning_rate": 1.3090461571035358e-05,
      "loss": 0.6618,
      "step": 697600
    },
    {
      "epoch": 7.385589743861191,
      "grad_norm": 4.554204940795898,
      "learning_rate": 1.3087814948126193e-05,
      "loss": 0.6544,
      "step": 697650
    },
    {
      "epoch": 7.386119065641194,
      "grad_norm": 4.539019584655762,
      "learning_rate": 1.3085168325217023e-05,
      "loss": 0.6651,
      "step": 697700
    },
    {
      "epoch": 7.3866483874211974,
      "grad_norm": 5.0932207107543945,
      "learning_rate": 1.3082521702307857e-05,
      "loss": 0.6566,
      "step": 697750
    },
    {
      "epoch": 7.3871777092012,
      "grad_norm": 4.247267723083496,
      "learning_rate": 1.307992801185687e-05,
      "loss": 0.6436,
      "step": 697800
    },
    {
      "epoch": 7.387707030981204,
      "grad_norm": 4.607361793518066,
      "learning_rate": 1.3077281388947704e-05,
      "loss": 0.6419,
      "step": 697850
    },
    {
      "epoch": 7.388236352761207,
      "grad_norm": 4.349082946777344,
      "learning_rate": 1.3074634766038535e-05,
      "loss": 0.6557,
      "step": 697900
    },
    {
      "epoch": 7.388765674541211,
      "grad_norm": 4.715106010437012,
      "learning_rate": 1.3071988143129368e-05,
      "loss": 0.6524,
      "step": 697950
    },
    {
      "epoch": 7.389294996321214,
      "grad_norm": 4.338711261749268,
      "learning_rate": 1.3069341520220198e-05,
      "loss": 0.6606,
      "step": 698000
    },
    {
      "epoch": 7.389294996321214,
      "eval_loss": 0.40672197937965393,
      "eval_runtime": 46.4898,
      "eval_samples_per_second": 3612.19,
      "eval_steps_per_second": 451.54,
      "step": 698000
    },
    {
      "epoch": 7.389824318101217,
      "grad_norm": 4.845179080963135,
      "learning_rate": 1.3066694897311032e-05,
      "loss": 0.6567,
      "step": 698050
    },
    {
      "epoch": 7.39035363988122,
      "grad_norm": 4.987602233886719,
      "learning_rate": 1.3064048274401863e-05,
      "loss": 0.6554,
      "step": 698100
    },
    {
      "epoch": 7.390882961661223,
      "grad_norm": 4.473750591278076,
      "learning_rate": 1.3061401651492697e-05,
      "loss": 0.654,
      "step": 698150
    },
    {
      "epoch": 7.391412283441227,
      "grad_norm": 4.665283203125,
      "learning_rate": 1.3058755028583528e-05,
      "loss": 0.6571,
      "step": 698200
    },
    {
      "epoch": 7.39194160522123,
      "grad_norm": 4.520668029785156,
      "learning_rate": 1.305610840567436e-05,
      "loss": 0.6652,
      "step": 698250
    },
    {
      "epoch": 7.392470927001233,
      "grad_norm": 4.787233829498291,
      "learning_rate": 1.3053461782765191e-05,
      "loss": 0.6495,
      "step": 698300
    },
    {
      "epoch": 7.393000248781236,
      "grad_norm": 4.471968173980713,
      "learning_rate": 1.3050815159856025e-05,
      "loss": 0.6526,
      "step": 698350
    },
    {
      "epoch": 7.39352957056124,
      "grad_norm": 4.5101447105407715,
      "learning_rate": 1.3048168536946856e-05,
      "loss": 0.6632,
      "step": 698400
    },
    {
      "epoch": 7.394058892341243,
      "grad_norm": 4.375341892242432,
      "learning_rate": 1.304552191403769e-05,
      "loss": 0.6511,
      "step": 698450
    },
    {
      "epoch": 7.394588214121247,
      "grad_norm": 4.030713081359863,
      "learning_rate": 1.304287529112852e-05,
      "loss": 0.6568,
      "step": 698500
    },
    {
      "epoch": 7.394588214121247,
      "eval_loss": 0.4067588150501251,
      "eval_runtime": 46.5052,
      "eval_samples_per_second": 3610.995,
      "eval_steps_per_second": 451.39,
      "step": 698500
    },
    {
      "epoch": 7.3951175359012495,
      "grad_norm": 4.332178592681885,
      "learning_rate": 1.3040228668219353e-05,
      "loss": 0.652,
      "step": 698550
    },
    {
      "epoch": 7.395646857681253,
      "grad_norm": 4.163191318511963,
      "learning_rate": 1.3037582045310184e-05,
      "loss": 0.6583,
      "step": 698600
    },
    {
      "epoch": 7.396176179461256,
      "grad_norm": 4.84072208404541,
      "learning_rate": 1.3034935422401018e-05,
      "loss": 0.6517,
      "step": 698650
    },
    {
      "epoch": 7.39670550124126,
      "grad_norm": 4.378998279571533,
      "learning_rate": 1.3032288799491849e-05,
      "loss": 0.6643,
      "step": 698700
    },
    {
      "epoch": 7.397234823021263,
      "grad_norm": 4.630174160003662,
      "learning_rate": 1.3029642176582683e-05,
      "loss": 0.6537,
      "step": 698750
    },
    {
      "epoch": 7.3977641448012665,
      "grad_norm": 4.7281174659729,
      "learning_rate": 1.3026995553673513e-05,
      "loss": 0.6468,
      "step": 698800
    },
    {
      "epoch": 7.398293466581269,
      "grad_norm": 4.376202583312988,
      "learning_rate": 1.3024348930764346e-05,
      "loss": 0.6506,
      "step": 698850
    },
    {
      "epoch": 7.398822788361272,
      "grad_norm": 4.894957542419434,
      "learning_rate": 1.3021702307855177e-05,
      "loss": 0.6583,
      "step": 698900
    },
    {
      "epoch": 7.399352110141276,
      "grad_norm": 4.304445266723633,
      "learning_rate": 1.301905568494601e-05,
      "loss": 0.6529,
      "step": 698950
    },
    {
      "epoch": 7.399881431921279,
      "grad_norm": 4.713054656982422,
      "learning_rate": 1.3016409062036841e-05,
      "loss": 0.6601,
      "step": 699000
    },
    {
      "epoch": 7.399881431921279,
      "eval_loss": 0.4063932001590729,
      "eval_runtime": 46.437,
      "eval_samples_per_second": 3616.299,
      "eval_steps_per_second": 452.054,
      "step": 699000
    },
    {
      "epoch": 7.400410753701283,
      "grad_norm": 4.479298114776611,
      "learning_rate": 1.3013762439127675e-05,
      "loss": 0.6644,
      "step": 699050
    },
    {
      "epoch": 7.4009400754812855,
      "grad_norm": 4.876516819000244,
      "learning_rate": 1.3011115816218506e-05,
      "loss": 0.6451,
      "step": 699100
    },
    {
      "epoch": 7.401469397261289,
      "grad_norm": 4.553846836090088,
      "learning_rate": 1.3008469193309339e-05,
      "loss": 0.6594,
      "step": 699150
    },
    {
      "epoch": 7.401998719041292,
      "grad_norm": 4.475401878356934,
      "learning_rate": 1.300582257040017e-05,
      "loss": 0.6538,
      "step": 699200
    },
    {
      "epoch": 7.402528040821296,
      "grad_norm": 4.385424613952637,
      "learning_rate": 1.3003175947491003e-05,
      "loss": 0.648,
      "step": 699250
    },
    {
      "epoch": 7.403057362601299,
      "grad_norm": 4.266374588012695,
      "learning_rate": 1.3000529324581834e-05,
      "loss": 0.644,
      "step": 699300
    },
    {
      "epoch": 7.4035866843813025,
      "grad_norm": 4.648421764373779,
      "learning_rate": 1.2997882701672666e-05,
      "loss": 0.6484,
      "step": 699350
    },
    {
      "epoch": 7.404116006161305,
      "grad_norm": 4.5482988357543945,
      "learning_rate": 1.2995236078763497e-05,
      "loss": 0.6429,
      "step": 699400
    },
    {
      "epoch": 7.404645327941309,
      "grad_norm": 4.4105329513549805,
      "learning_rate": 1.2992589455854331e-05,
      "loss": 0.6656,
      "step": 699450
    },
    {
      "epoch": 7.405174649721312,
      "grad_norm": 4.610498905181885,
      "learning_rate": 1.2989942832945162e-05,
      "loss": 0.6463,
      "step": 699500
    },
    {
      "epoch": 7.405174649721312,
      "eval_loss": 0.4070139527320862,
      "eval_runtime": 46.7538,
      "eval_samples_per_second": 3591.792,
      "eval_steps_per_second": 448.99,
      "step": 699500
    },
    {
      "epoch": 7.405703971501316,
      "grad_norm": 4.720364570617676,
      "learning_rate": 1.2987296210035996e-05,
      "loss": 0.6487,
      "step": 699550
    },
    {
      "epoch": 7.406233293281319,
      "grad_norm": 4.99425745010376,
      "learning_rate": 1.2984649587126827e-05,
      "loss": 0.661,
      "step": 699600
    },
    {
      "epoch": 7.4067626150613215,
      "grad_norm": 4.768526077270508,
      "learning_rate": 1.298200296421766e-05,
      "loss": 0.6566,
      "step": 699650
    },
    {
      "epoch": 7.407291936841325,
      "grad_norm": 4.970571517944336,
      "learning_rate": 1.297935634130849e-05,
      "loss": 0.6548,
      "step": 699700
    },
    {
      "epoch": 7.407821258621328,
      "grad_norm": 4.569214344024658,
      "learning_rate": 1.2976709718399324e-05,
      "loss": 0.6525,
      "step": 699750
    },
    {
      "epoch": 7.408350580401332,
      "grad_norm": 4.609490871429443,
      "learning_rate": 1.2974116027948339e-05,
      "loss": 0.6563,
      "step": 699800
    },
    {
      "epoch": 7.408879902181335,
      "grad_norm": 4.573456764221191,
      "learning_rate": 1.2971469405039171e-05,
      "loss": 0.6575,
      "step": 699850
    },
    {
      "epoch": 7.4094092239613385,
      "grad_norm": 4.6986823081970215,
      "learning_rate": 1.2968822782130002e-05,
      "loss": 0.6652,
      "step": 699900
    },
    {
      "epoch": 7.409938545741341,
      "grad_norm": 4.213412284851074,
      "learning_rate": 1.2966176159220836e-05,
      "loss": 0.6574,
      "step": 699950
    },
    {
      "epoch": 7.410467867521345,
      "grad_norm": 4.239113807678223,
      "learning_rate": 1.2963529536311667e-05,
      "loss": 0.6496,
      "step": 700000
    },
    {
      "epoch": 7.410467867521345,
      "eval_loss": 0.40680086612701416,
      "eval_runtime": 46.696,
      "eval_samples_per_second": 3596.237,
      "eval_steps_per_second": 449.546,
      "step": 700000
    },
    {
      "epoch": 7.410997189301348,
      "grad_norm": 4.315703868865967,
      "learning_rate": 1.29608829134025e-05,
      "loss": 0.6599,
      "step": 700050
    },
    {
      "epoch": 7.411526511081352,
      "grad_norm": 4.451837062835693,
      "learning_rate": 1.2958236290493331e-05,
      "loss": 0.6466,
      "step": 700100
    },
    {
      "epoch": 7.412055832861355,
      "grad_norm": 4.003673076629639,
      "learning_rate": 1.2955589667584164e-05,
      "loss": 0.6637,
      "step": 700150
    },
    {
      "epoch": 7.412585154641358,
      "grad_norm": 4.12950325012207,
      "learning_rate": 1.2952943044674995e-05,
      "loss": 0.6616,
      "step": 700200
    },
    {
      "epoch": 7.413114476421361,
      "grad_norm": 4.466481685638428,
      "learning_rate": 1.2950296421765829e-05,
      "loss": 0.6585,
      "step": 700250
    },
    {
      "epoch": 7.413643798201365,
      "grad_norm": 4.686190128326416,
      "learning_rate": 1.294764979885666e-05,
      "loss": 0.6624,
      "step": 700300
    },
    {
      "epoch": 7.414173119981368,
      "grad_norm": 4.037252902984619,
      "learning_rate": 1.2945003175947494e-05,
      "loss": 0.6433,
      "step": 700350
    },
    {
      "epoch": 7.414702441761371,
      "grad_norm": 4.266096591949463,
      "learning_rate": 1.2942356553038324e-05,
      "loss": 0.6364,
      "step": 700400
    },
    {
      "epoch": 7.4152317635413745,
      "grad_norm": 4.5463457107543945,
      "learning_rate": 1.2939709930129157e-05,
      "loss": 0.6547,
      "step": 700450
    },
    {
      "epoch": 7.415761085321377,
      "grad_norm": 4.454056262969971,
      "learning_rate": 1.2937063307219987e-05,
      "loss": 0.6541,
      "step": 700500
    },
    {
      "epoch": 7.415761085321377,
      "eval_loss": 0.4063343405723572,
      "eval_runtime": 46.7059,
      "eval_samples_per_second": 3595.475,
      "eval_steps_per_second": 449.45,
      "step": 700500
    },
    {
      "epoch": 7.416290407101381,
      "grad_norm": 4.384415626525879,
      "learning_rate": 1.2934416684310821e-05,
      "loss": 0.6549,
      "step": 700550
    },
    {
      "epoch": 7.416819728881384,
      "grad_norm": 4.45462703704834,
      "learning_rate": 1.2931770061401652e-05,
      "loss": 0.6611,
      "step": 700600
    },
    {
      "epoch": 7.417349050661388,
      "grad_norm": 4.626404285430908,
      "learning_rate": 1.2929123438492485e-05,
      "loss": 0.6571,
      "step": 700650
    },
    {
      "epoch": 7.417878372441391,
      "grad_norm": 4.965709686279297,
      "learning_rate": 1.2926476815583315e-05,
      "loss": 0.6592,
      "step": 700700
    },
    {
      "epoch": 7.418407694221394,
      "grad_norm": 4.369700908660889,
      "learning_rate": 1.292383019267415e-05,
      "loss": 0.6518,
      "step": 700750
    },
    {
      "epoch": 7.418937016001397,
      "grad_norm": 4.733881950378418,
      "learning_rate": 1.292118356976498e-05,
      "loss": 0.6592,
      "step": 700800
    },
    {
      "epoch": 7.419466337781401,
      "grad_norm": 4.709796905517578,
      "learning_rate": 1.2918536946855814e-05,
      "loss": 0.6694,
      "step": 700850
    },
    {
      "epoch": 7.419995659561404,
      "grad_norm": 4.533379077911377,
      "learning_rate": 1.2915890323946645e-05,
      "loss": 0.6506,
      "step": 700900
    },
    {
      "epoch": 7.420524981341408,
      "grad_norm": 4.020270824432373,
      "learning_rate": 1.2913243701037477e-05,
      "loss": 0.6411,
      "step": 700950
    },
    {
      "epoch": 7.4210543031214105,
      "grad_norm": 4.606727600097656,
      "learning_rate": 1.2910597078128308e-05,
      "loss": 0.6606,
      "step": 701000
    },
    {
      "epoch": 7.4210543031214105,
      "eval_loss": 0.406404584646225,
      "eval_runtime": 46.6763,
      "eval_samples_per_second": 3597.758,
      "eval_steps_per_second": 449.736,
      "step": 701000
    },
    {
      "epoch": 7.421583624901414,
      "grad_norm": 4.592123508453369,
      "learning_rate": 1.2907950455219142e-05,
      "loss": 0.6516,
      "step": 701050
    },
    {
      "epoch": 7.422112946681417,
      "grad_norm": 4.696556091308594,
      "learning_rate": 1.2905303832309973e-05,
      "loss": 0.6541,
      "step": 701100
    },
    {
      "epoch": 7.42264226846142,
      "grad_norm": 4.596179962158203,
      "learning_rate": 1.2902657209400807e-05,
      "loss": 0.6469,
      "step": 701150
    },
    {
      "epoch": 7.423171590241424,
      "grad_norm": 4.047667980194092,
      "learning_rate": 1.2900010586491638e-05,
      "loss": 0.6514,
      "step": 701200
    },
    {
      "epoch": 7.423700912021427,
      "grad_norm": 4.601023197174072,
      "learning_rate": 1.289736396358247e-05,
      "loss": 0.658,
      "step": 701250
    },
    {
      "epoch": 7.42423023380143,
      "grad_norm": 4.772370338439941,
      "learning_rate": 1.28947173406733e-05,
      "loss": 0.6496,
      "step": 701300
    },
    {
      "epoch": 7.424759555581433,
      "grad_norm": 5.094232559204102,
      "learning_rate": 1.2892070717764135e-05,
      "loss": 0.6553,
      "step": 701350
    },
    {
      "epoch": 7.425288877361437,
      "grad_norm": 4.369164943695068,
      "learning_rate": 1.2889424094854966e-05,
      "loss": 0.6587,
      "step": 701400
    },
    {
      "epoch": 7.42581819914144,
      "grad_norm": 4.587568759918213,
      "learning_rate": 1.28867774719458e-05,
      "loss": 0.6573,
      "step": 701450
    },
    {
      "epoch": 7.426347520921444,
      "grad_norm": 4.6032328605651855,
      "learning_rate": 1.288413084903663e-05,
      "loss": 0.6647,
      "step": 701500
    },
    {
      "epoch": 7.426347520921444,
      "eval_loss": 0.40675467252731323,
      "eval_runtime": 46.7112,
      "eval_samples_per_second": 3595.07,
      "eval_steps_per_second": 449.4,
      "step": 701500
    },
    {
      "epoch": 7.426876842701446,
      "grad_norm": 4.476402759552002,
      "learning_rate": 1.2881484226127463e-05,
      "loss": 0.6648,
      "step": 701550
    },
    {
      "epoch": 7.42740616448145,
      "grad_norm": 5.249884128570557,
      "learning_rate": 1.2878837603218293e-05,
      "loss": 0.6613,
      "step": 701600
    },
    {
      "epoch": 7.427935486261453,
      "grad_norm": 4.692773818969727,
      "learning_rate": 1.2876190980309128e-05,
      "loss": 0.658,
      "step": 701650
    },
    {
      "epoch": 7.428464808041457,
      "grad_norm": 4.546658039093018,
      "learning_rate": 1.2873544357399958e-05,
      "loss": 0.6506,
      "step": 701700
    },
    {
      "epoch": 7.42899412982146,
      "grad_norm": 4.564551830291748,
      "learning_rate": 1.2870897734490792e-05,
      "loss": 0.6561,
      "step": 701750
    },
    {
      "epoch": 7.429523451601463,
      "grad_norm": 4.6296162605285645,
      "learning_rate": 1.2868304044039805e-05,
      "loss": 0.6547,
      "step": 701800
    },
    {
      "epoch": 7.430052773381466,
      "grad_norm": 4.662493705749512,
      "learning_rate": 1.286565742113064e-05,
      "loss": 0.667,
      "step": 701850
    },
    {
      "epoch": 7.430582095161469,
      "grad_norm": 4.542586803436279,
      "learning_rate": 1.286301079822147e-05,
      "loss": 0.6505,
      "step": 701900
    },
    {
      "epoch": 7.431111416941473,
      "grad_norm": 4.3579535484313965,
      "learning_rate": 1.2860364175312303e-05,
      "loss": 0.6617,
      "step": 701950
    },
    {
      "epoch": 7.431640738721476,
      "grad_norm": 4.9050822257995605,
      "learning_rate": 1.2857717552403133e-05,
      "loss": 0.6633,
      "step": 702000
    },
    {
      "epoch": 7.431640738721476,
      "eval_loss": 0.40603241324424744,
      "eval_runtime": 46.7271,
      "eval_samples_per_second": 3593.847,
      "eval_steps_per_second": 449.247,
      "step": 702000
    },
    {
      "epoch": 7.4321700605014795,
      "grad_norm": 4.619673252105713,
      "learning_rate": 1.2855070929493967e-05,
      "loss": 0.6516,
      "step": 702050
    },
    {
      "epoch": 7.432699382281482,
      "grad_norm": 4.081034183502197,
      "learning_rate": 1.2852424306584798e-05,
      "loss": 0.6609,
      "step": 702100
    },
    {
      "epoch": 7.433228704061486,
      "grad_norm": 4.5927019119262695,
      "learning_rate": 1.2849777683675632e-05,
      "loss": 0.6599,
      "step": 702150
    },
    {
      "epoch": 7.433758025841489,
      "grad_norm": 4.272315979003906,
      "learning_rate": 1.2847131060766463e-05,
      "loss": 0.6506,
      "step": 702200
    },
    {
      "epoch": 7.434287347621493,
      "grad_norm": 4.203253269195557,
      "learning_rate": 1.2844484437857295e-05,
      "loss": 0.6616,
      "step": 702250
    },
    {
      "epoch": 7.434816669401496,
      "grad_norm": 4.784918308258057,
      "learning_rate": 1.2841837814948126e-05,
      "loss": 0.6595,
      "step": 702300
    },
    {
      "epoch": 7.435345991181499,
      "grad_norm": 4.409877300262451,
      "learning_rate": 1.283919119203896e-05,
      "loss": 0.6626,
      "step": 702350
    },
    {
      "epoch": 7.435875312961502,
      "grad_norm": 4.746267795562744,
      "learning_rate": 1.2836544569129791e-05,
      "loss": 0.6661,
      "step": 702400
    },
    {
      "epoch": 7.436404634741506,
      "grad_norm": 4.036661148071289,
      "learning_rate": 1.2833897946220625e-05,
      "loss": 0.6517,
      "step": 702450
    },
    {
      "epoch": 7.436933956521509,
      "grad_norm": 4.708162307739258,
      "learning_rate": 1.2831251323311456e-05,
      "loss": 0.6514,
      "step": 702500
    },
    {
      "epoch": 7.436933956521509,
      "eval_loss": 0.4063686728477478,
      "eval_runtime": 46.7735,
      "eval_samples_per_second": 3590.279,
      "eval_steps_per_second": 448.801,
      "step": 702500
    },
    {
      "epoch": 7.437463278301513,
      "grad_norm": 4.973255157470703,
      "learning_rate": 1.2828604700402288e-05,
      "loss": 0.6585,
      "step": 702550
    },
    {
      "epoch": 7.4379926000815155,
      "grad_norm": 4.336305618286133,
      "learning_rate": 1.2825958077493119e-05,
      "loss": 0.6646,
      "step": 702600
    },
    {
      "epoch": 7.438521921861518,
      "grad_norm": 4.702297687530518,
      "learning_rate": 1.2823311454583953e-05,
      "loss": 0.6479,
      "step": 702650
    },
    {
      "epoch": 7.439051243641522,
      "grad_norm": 4.2957940101623535,
      "learning_rate": 1.2820664831674784e-05,
      "loss": 0.6541,
      "step": 702700
    },
    {
      "epoch": 7.439580565421525,
      "grad_norm": 4.294460296630859,
      "learning_rate": 1.2818018208765618e-05,
      "loss": 0.6594,
      "step": 702750
    },
    {
      "epoch": 7.440109887201529,
      "grad_norm": 4.046541690826416,
      "learning_rate": 1.2815371585856448e-05,
      "loss": 0.6558,
      "step": 702800
    },
    {
      "epoch": 7.440639208981532,
      "grad_norm": 4.511249542236328,
      "learning_rate": 1.2812724962947281e-05,
      "loss": 0.6538,
      "step": 702850
    },
    {
      "epoch": 7.441168530761535,
      "grad_norm": 4.6360554695129395,
      "learning_rate": 1.2810078340038112e-05,
      "loss": 0.6477,
      "step": 702900
    },
    {
      "epoch": 7.441697852541538,
      "grad_norm": 4.230559825897217,
      "learning_rate": 1.2807431717128946e-05,
      "loss": 0.6488,
      "step": 702950
    },
    {
      "epoch": 7.442227174321542,
      "grad_norm": 3.8535890579223633,
      "learning_rate": 1.2804785094219776e-05,
      "loss": 0.6515,
      "step": 703000
    },
    {
      "epoch": 7.442227174321542,
      "eval_loss": 0.40600115060806274,
      "eval_runtime": 46.7425,
      "eval_samples_per_second": 3592.66,
      "eval_steps_per_second": 449.099,
      "step": 703000
    },
    {
      "epoch": 7.442756496101545,
      "grad_norm": 4.401573181152344,
      "learning_rate": 1.2802138471310609e-05,
      "loss": 0.6486,
      "step": 703050
    },
    {
      "epoch": 7.443285817881549,
      "grad_norm": 4.329653739929199,
      "learning_rate": 1.279949184840144e-05,
      "loss": 0.6451,
      "step": 703100
    },
    {
      "epoch": 7.4438151396615515,
      "grad_norm": 4.652334213256836,
      "learning_rate": 1.2796845225492274e-05,
      "loss": 0.6484,
      "step": 703150
    },
    {
      "epoch": 7.444344461441555,
      "grad_norm": 4.495707035064697,
      "learning_rate": 1.2794198602583104e-05,
      "loss": 0.6604,
      "step": 703200
    },
    {
      "epoch": 7.444873783221558,
      "grad_norm": 4.872066497802734,
      "learning_rate": 1.2791551979673938e-05,
      "loss": 0.6522,
      "step": 703250
    },
    {
      "epoch": 7.445403105001562,
      "grad_norm": 4.490979194641113,
      "learning_rate": 1.2788905356764769e-05,
      "loss": 0.6607,
      "step": 703300
    },
    {
      "epoch": 7.445932426781565,
      "grad_norm": 4.610685348510742,
      "learning_rate": 1.2786258733855602e-05,
      "loss": 0.652,
      "step": 703350
    },
    {
      "epoch": 7.446461748561568,
      "grad_norm": 4.360357761383057,
      "learning_rate": 1.2783612110946432e-05,
      "loss": 0.6566,
      "step": 703400
    },
    {
      "epoch": 7.446991070341571,
      "grad_norm": 4.38469123840332,
      "learning_rate": 1.2780965488037263e-05,
      "loss": 0.6393,
      "step": 703450
    },
    {
      "epoch": 7.447520392121574,
      "grad_norm": 4.426019191741943,
      "learning_rate": 1.2778318865128097e-05,
      "loss": 0.649,
      "step": 703500
    },
    {
      "epoch": 7.447520392121574,
      "eval_loss": 0.40492379665374756,
      "eval_runtime": 46.6869,
      "eval_samples_per_second": 3596.942,
      "eval_steps_per_second": 449.634,
      "step": 703500
    },
    {
      "epoch": 7.448049713901578,
      "grad_norm": 4.269092082977295,
      "learning_rate": 1.2775672242218928e-05,
      "loss": 0.6418,
      "step": 703550
    },
    {
      "epoch": 7.448579035681581,
      "grad_norm": 4.462382793426514,
      "learning_rate": 1.2773025619309762e-05,
      "loss": 0.6633,
      "step": 703600
    },
    {
      "epoch": 7.449108357461585,
      "grad_norm": 4.848116874694824,
      "learning_rate": 1.2770378996400593e-05,
      "loss": 0.6521,
      "step": 703650
    },
    {
      "epoch": 7.4496376792415875,
      "grad_norm": 4.52202033996582,
      "learning_rate": 1.2767732373491425e-05,
      "loss": 0.6553,
      "step": 703700
    },
    {
      "epoch": 7.450167001021591,
      "grad_norm": 4.5747809410095215,
      "learning_rate": 1.2765085750582256e-05,
      "loss": 0.6563,
      "step": 703750
    },
    {
      "epoch": 7.450696322801594,
      "grad_norm": 4.7241010665893555,
      "learning_rate": 1.2762492060131274e-05,
      "loss": 0.6419,
      "step": 703800
    },
    {
      "epoch": 7.451225644581598,
      "grad_norm": 4.439428329467773,
      "learning_rate": 1.2759845437222106e-05,
      "loss": 0.6412,
      "step": 703850
    },
    {
      "epoch": 7.451754966361601,
      "grad_norm": 4.688747406005859,
      "learning_rate": 1.2757198814312937e-05,
      "loss": 0.6512,
      "step": 703900
    },
    {
      "epoch": 7.4522842881416045,
      "grad_norm": 4.687103748321533,
      "learning_rate": 1.2754552191403771e-05,
      "loss": 0.6485,
      "step": 703950
    },
    {
      "epoch": 7.452813609921607,
      "grad_norm": 4.249334812164307,
      "learning_rate": 1.2751905568494602e-05,
      "loss": 0.6484,
      "step": 704000
    },
    {
      "epoch": 7.452813609921607,
      "eval_loss": 0.4045552909374237,
      "eval_runtime": 46.7332,
      "eval_samples_per_second": 3593.375,
      "eval_steps_per_second": 449.188,
      "step": 704000
    },
    {
      "epoch": 7.453342931701611,
      "grad_norm": 4.430569171905518,
      "learning_rate": 1.2749258945585432e-05,
      "loss": 0.648,
      "step": 704050
    },
    {
      "epoch": 7.453872253481614,
      "grad_norm": 4.422477722167969,
      "learning_rate": 1.2746612322676267e-05,
      "loss": 0.6528,
      "step": 704100
    },
    {
      "epoch": 7.454401575261617,
      "grad_norm": 4.621706008911133,
      "learning_rate": 1.2743965699767097e-05,
      "loss": 0.662,
      "step": 704150
    },
    {
      "epoch": 7.454930897041621,
      "grad_norm": 4.249233722686768,
      "learning_rate": 1.274131907685793e-05,
      "loss": 0.6513,
      "step": 704200
    },
    {
      "epoch": 7.4554602188216235,
      "grad_norm": 4.3509979248046875,
      "learning_rate": 1.273867245394876e-05,
      "loss": 0.6648,
      "step": 704250
    },
    {
      "epoch": 7.455989540601627,
      "grad_norm": 4.595419883728027,
      "learning_rate": 1.2736025831039594e-05,
      "loss": 0.6648,
      "step": 704300
    },
    {
      "epoch": 7.45651886238163,
      "grad_norm": 4.960309028625488,
      "learning_rate": 1.2733379208130425e-05,
      "loss": 0.6576,
      "step": 704350
    },
    {
      "epoch": 7.457048184161634,
      "grad_norm": 4.5918755531311035,
      "learning_rate": 1.2730732585221258e-05,
      "loss": 0.6597,
      "step": 704400
    },
    {
      "epoch": 7.457577505941637,
      "grad_norm": 4.836697578430176,
      "learning_rate": 1.2728085962312088e-05,
      "loss": 0.6562,
      "step": 704450
    },
    {
      "epoch": 7.4581068277216405,
      "grad_norm": 5.0044426918029785,
      "learning_rate": 1.2725439339402922e-05,
      "loss": 0.6538,
      "step": 704500
    },
    {
      "epoch": 7.4581068277216405,
      "eval_loss": 0.4052857458591461,
      "eval_runtime": 46.7476,
      "eval_samples_per_second": 3592.266,
      "eval_steps_per_second": 449.049,
      "step": 704500
    },
    {
      "epoch": 7.458636149501643,
      "grad_norm": 4.344890117645264,
      "learning_rate": 1.2722792716493753e-05,
      "loss": 0.6478,
      "step": 704550
    },
    {
      "epoch": 7.459165471281647,
      "grad_norm": 4.641142845153809,
      "learning_rate": 1.2720146093584587e-05,
      "loss": 0.6537,
      "step": 704600
    },
    {
      "epoch": 7.45969479306165,
      "grad_norm": 4.572205066680908,
      "learning_rate": 1.2717499470675418e-05,
      "loss": 0.6625,
      "step": 704650
    },
    {
      "epoch": 7.460224114841654,
      "grad_norm": 4.74780797958374,
      "learning_rate": 1.271485284776625e-05,
      "loss": 0.6649,
      "step": 704700
    },
    {
      "epoch": 7.460753436621657,
      "grad_norm": 4.199174404144287,
      "learning_rate": 1.2712206224857081e-05,
      "loss": 0.6593,
      "step": 704750
    },
    {
      "epoch": 7.46128275840166,
      "grad_norm": 4.87857723236084,
      "learning_rate": 1.2709559601947915e-05,
      "loss": 0.6517,
      "step": 704800
    },
    {
      "epoch": 7.461812080181663,
      "grad_norm": 4.509043216705322,
      "learning_rate": 1.2706912979038746e-05,
      "loss": 0.6557,
      "step": 704850
    },
    {
      "epoch": 7.462341401961666,
      "grad_norm": 4.692819595336914,
      "learning_rate": 1.270426635612958e-05,
      "loss": 0.6583,
      "step": 704900
    },
    {
      "epoch": 7.46287072374167,
      "grad_norm": 4.714168548583984,
      "learning_rate": 1.270161973322041e-05,
      "loss": 0.6546,
      "step": 704950
    },
    {
      "epoch": 7.463400045521673,
      "grad_norm": 4.962543964385986,
      "learning_rate": 1.2698973110311243e-05,
      "loss": 0.6518,
      "step": 705000
    },
    {
      "epoch": 7.463400045521673,
      "eval_loss": 0.4045696258544922,
      "eval_runtime": 46.6747,
      "eval_samples_per_second": 3597.88,
      "eval_steps_per_second": 449.751,
      "step": 705000
    },
    {
      "epoch": 7.463929367301676,
      "grad_norm": 4.6510491371154785,
      "learning_rate": 1.2696326487402074e-05,
      "loss": 0.6478,
      "step": 705050
    },
    {
      "epoch": 7.464458689081679,
      "grad_norm": 4.429205417633057,
      "learning_rate": 1.2693679864492908e-05,
      "loss": 0.6535,
      "step": 705100
    },
    {
      "epoch": 7.464988010861683,
      "grad_norm": 4.2932586669921875,
      "learning_rate": 1.2691033241583739e-05,
      "loss": 0.6608,
      "step": 705150
    },
    {
      "epoch": 7.465517332641686,
      "grad_norm": 4.623435020446777,
      "learning_rate": 1.2688386618674573e-05,
      "loss": 0.6608,
      "step": 705200
    },
    {
      "epoch": 7.46604665442169,
      "grad_norm": 4.643712997436523,
      "learning_rate": 1.2685739995765403e-05,
      "loss": 0.6543,
      "step": 705250
    },
    {
      "epoch": 7.4665759762016926,
      "grad_norm": 4.3711771965026855,
      "learning_rate": 1.2683093372856236e-05,
      "loss": 0.657,
      "step": 705300
    },
    {
      "epoch": 7.467105297981696,
      "grad_norm": 4.521541595458984,
      "learning_rate": 1.2680446749947067e-05,
      "loss": 0.6603,
      "step": 705350
    },
    {
      "epoch": 7.467634619761699,
      "grad_norm": 4.516875743865967,
      "learning_rate": 1.26778001270379e-05,
      "loss": 0.664,
      "step": 705400
    },
    {
      "epoch": 7.468163941541703,
      "grad_norm": 4.522521018981934,
      "learning_rate": 1.2675153504128731e-05,
      "loss": 0.648,
      "step": 705450
    },
    {
      "epoch": 7.468693263321706,
      "grad_norm": 4.238663673400879,
      "learning_rate": 1.2672506881219565e-05,
      "loss": 0.6566,
      "step": 705500
    },
    {
      "epoch": 7.468693263321706,
      "eval_loss": 0.4057535231113434,
      "eval_runtime": 46.7136,
      "eval_samples_per_second": 3594.887,
      "eval_steps_per_second": 449.377,
      "step": 705500
    },
    {
      "epoch": 7.4692225851017096,
      "grad_norm": 4.168337821960449,
      "learning_rate": 1.2669860258310396e-05,
      "loss": 0.6441,
      "step": 705550
    },
    {
      "epoch": 7.469751906881712,
      "grad_norm": 4.345888614654541,
      "learning_rate": 1.2667213635401229e-05,
      "loss": 0.6594,
      "step": 705600
    },
    {
      "epoch": 7.470281228661715,
      "grad_norm": 4.739643096923828,
      "learning_rate": 1.266456701249206e-05,
      "loss": 0.6644,
      "step": 705650
    },
    {
      "epoch": 7.470810550441719,
      "grad_norm": 4.3591718673706055,
      "learning_rate": 1.2661920389582893e-05,
      "loss": 0.6585,
      "step": 705700
    },
    {
      "epoch": 7.471339872221722,
      "grad_norm": 4.451618194580078,
      "learning_rate": 1.2659273766673724e-05,
      "loss": 0.6524,
      "step": 705750
    },
    {
      "epoch": 7.471869194001726,
      "grad_norm": 4.459016799926758,
      "learning_rate": 1.265668007622274e-05,
      "loss": 0.6528,
      "step": 705800
    },
    {
      "epoch": 7.4723985157817285,
      "grad_norm": 4.569924831390381,
      "learning_rate": 1.2654033453313571e-05,
      "loss": 0.6529,
      "step": 705850
    },
    {
      "epoch": 7.472927837561732,
      "grad_norm": 4.6493706703186035,
      "learning_rate": 1.2651386830404405e-05,
      "loss": 0.6556,
      "step": 705900
    },
    {
      "epoch": 7.473457159341735,
      "grad_norm": 4.648195743560791,
      "learning_rate": 1.2648740207495236e-05,
      "loss": 0.6434,
      "step": 705950
    },
    {
      "epoch": 7.473986481121739,
      "grad_norm": 4.45670747756958,
      "learning_rate": 1.2646093584586068e-05,
      "loss": 0.6486,
      "step": 706000
    },
    {
      "epoch": 7.473986481121739,
      "eval_loss": 0.40520864725112915,
      "eval_runtime": 46.6831,
      "eval_samples_per_second": 3597.233,
      "eval_steps_per_second": 449.67,
      "step": 706000
    },
    {
      "epoch": 7.474515802901742,
      "grad_norm": 4.553828716278076,
      "learning_rate": 1.2643446961676899e-05,
      "loss": 0.6552,
      "step": 706050
    },
    {
      "epoch": 7.4750451246817455,
      "grad_norm": 4.331632614135742,
      "learning_rate": 1.2640800338767733e-05,
      "loss": 0.6467,
      "step": 706100
    },
    {
      "epoch": 7.475574446461748,
      "grad_norm": 4.592756748199463,
      "learning_rate": 1.2638153715858564e-05,
      "loss": 0.6599,
      "step": 706150
    },
    {
      "epoch": 7.476103768241752,
      "grad_norm": 4.349704265594482,
      "learning_rate": 1.2635507092949398e-05,
      "loss": 0.6567,
      "step": 706200
    },
    {
      "epoch": 7.476633090021755,
      "grad_norm": 5.011204242706299,
      "learning_rate": 1.2632860470040229e-05,
      "loss": 0.6519,
      "step": 706250
    },
    {
      "epoch": 7.477162411801759,
      "grad_norm": 4.6981096267700195,
      "learning_rate": 1.2630213847131061e-05,
      "loss": 0.6422,
      "step": 706300
    },
    {
      "epoch": 7.477691733581762,
      "grad_norm": 4.430237770080566,
      "learning_rate": 1.2627567224221892e-05,
      "loss": 0.6501,
      "step": 706350
    },
    {
      "epoch": 7.4782210553617645,
      "grad_norm": 4.494337558746338,
      "learning_rate": 1.2624920601312726e-05,
      "loss": 0.6542,
      "step": 706400
    },
    {
      "epoch": 7.478750377141768,
      "grad_norm": 5.04239559173584,
      "learning_rate": 1.2622273978403557e-05,
      "loss": 0.6576,
      "step": 706450
    },
    {
      "epoch": 7.479279698921771,
      "grad_norm": 4.204543113708496,
      "learning_rate": 1.261962735549439e-05,
      "loss": 0.6557,
      "step": 706500
    },
    {
      "epoch": 7.479279698921771,
      "eval_loss": 0.40524396300315857,
      "eval_runtime": 46.7415,
      "eval_samples_per_second": 3592.74,
      "eval_steps_per_second": 449.109,
      "step": 706500
    },
    {
      "epoch": 7.479809020701775,
      "grad_norm": 5.015673637390137,
      "learning_rate": 1.2616980732585221e-05,
      "loss": 0.6608,
      "step": 706550
    },
    {
      "epoch": 7.480338342481778,
      "grad_norm": 4.367175102233887,
      "learning_rate": 1.2614334109676054e-05,
      "loss": 0.6545,
      "step": 706600
    },
    {
      "epoch": 7.4808676642617815,
      "grad_norm": 4.612522602081299,
      "learning_rate": 1.2611687486766885e-05,
      "loss": 0.6651,
      "step": 706650
    },
    {
      "epoch": 7.481396986041784,
      "grad_norm": 4.4340033531188965,
      "learning_rate": 1.2609040863857719e-05,
      "loss": 0.644,
      "step": 706700
    },
    {
      "epoch": 7.481926307821788,
      "grad_norm": 4.406123161315918,
      "learning_rate": 1.260639424094855e-05,
      "loss": 0.6576,
      "step": 706750
    },
    {
      "epoch": 7.482455629601791,
      "grad_norm": 4.48383092880249,
      "learning_rate": 1.2603747618039382e-05,
      "loss": 0.6512,
      "step": 706800
    },
    {
      "epoch": 7.482984951381795,
      "grad_norm": 4.18402624130249,
      "learning_rate": 1.2601100995130213e-05,
      "loss": 0.6532,
      "step": 706850
    },
    {
      "epoch": 7.483514273161798,
      "grad_norm": 5.1149821281433105,
      "learning_rate": 1.2598454372221047e-05,
      "loss": 0.6558,
      "step": 706900
    },
    {
      "epoch": 7.484043594941801,
      "grad_norm": 4.766080856323242,
      "learning_rate": 1.2595807749311877e-05,
      "loss": 0.6552,
      "step": 706950
    },
    {
      "epoch": 7.484572916721804,
      "grad_norm": 4.5774641036987305,
      "learning_rate": 1.2593161126402711e-05,
      "loss": 0.6498,
      "step": 707000
    },
    {
      "epoch": 7.484572916721804,
      "eval_loss": 0.40544357895851135,
      "eval_runtime": 46.7112,
      "eval_samples_per_second": 3595.069,
      "eval_steps_per_second": 449.4,
      "step": 707000
    },
    {
      "epoch": 7.485102238501808,
      "grad_norm": 4.908918380737305,
      "learning_rate": 1.2590514503493542e-05,
      "loss": 0.6596,
      "step": 707050
    },
    {
      "epoch": 7.485631560281811,
      "grad_norm": 4.865298271179199,
      "learning_rate": 1.2587867880584375e-05,
      "loss": 0.6627,
      "step": 707100
    },
    {
      "epoch": 7.486160882061814,
      "grad_norm": 4.616746425628662,
      "learning_rate": 1.2585221257675205e-05,
      "loss": 0.6439,
      "step": 707150
    },
    {
      "epoch": 7.4866902038418175,
      "grad_norm": 4.60469388961792,
      "learning_rate": 1.258257463476604e-05,
      "loss": 0.6568,
      "step": 707200
    },
    {
      "epoch": 7.48721952562182,
      "grad_norm": 4.457921028137207,
      "learning_rate": 1.257992801185687e-05,
      "loss": 0.6446,
      "step": 707250
    },
    {
      "epoch": 7.487748847401824,
      "grad_norm": 4.751865386962891,
      "learning_rate": 1.2577281388947704e-05,
      "loss": 0.645,
      "step": 707300
    },
    {
      "epoch": 7.488278169181827,
      "grad_norm": 4.622072696685791,
      "learning_rate": 1.2574634766038535e-05,
      "loss": 0.6515,
      "step": 707350
    },
    {
      "epoch": 7.488807490961831,
      "grad_norm": 4.898053169250488,
      "learning_rate": 1.2571988143129367e-05,
      "loss": 0.6536,
      "step": 707400
    },
    {
      "epoch": 7.489336812741834,
      "grad_norm": 4.481550693511963,
      "learning_rate": 1.2569341520220198e-05,
      "loss": 0.6487,
      "step": 707450
    },
    {
      "epoch": 7.489866134521837,
      "grad_norm": 4.453693866729736,
      "learning_rate": 1.2566694897311032e-05,
      "loss": 0.6507,
      "step": 707500
    },
    {
      "epoch": 7.489866134521837,
      "eval_loss": 0.4051002860069275,
      "eval_runtime": 46.7847,
      "eval_samples_per_second": 3589.419,
      "eval_steps_per_second": 448.693,
      "step": 707500
    },
    {
      "epoch": 7.49039545630184,
      "grad_norm": 4.605103969573975,
      "learning_rate": 1.2564048274401863e-05,
      "loss": 0.6547,
      "step": 707550
    },
    {
      "epoch": 7.490924778081844,
      "grad_norm": 4.17871618270874,
      "learning_rate": 1.2561401651492697e-05,
      "loss": 0.6492,
      "step": 707600
    },
    {
      "epoch": 7.491454099861847,
      "grad_norm": 4.9617462158203125,
      "learning_rate": 1.2558755028583528e-05,
      "loss": 0.6551,
      "step": 707650
    },
    {
      "epoch": 7.491983421641851,
      "grad_norm": 4.881833076477051,
      "learning_rate": 1.255610840567436e-05,
      "loss": 0.673,
      "step": 707700
    },
    {
      "epoch": 7.4925127434218535,
      "grad_norm": 4.816853046417236,
      "learning_rate": 1.255346178276519e-05,
      "loss": 0.6416,
      "step": 707750
    },
    {
      "epoch": 7.493042065201857,
      "grad_norm": 4.729983329772949,
      "learning_rate": 1.2550815159856025e-05,
      "loss": 0.6589,
      "step": 707800
    },
    {
      "epoch": 7.49357138698186,
      "grad_norm": 4.901734828948975,
      "learning_rate": 1.254822146940504e-05,
      "loss": 0.6583,
      "step": 707850
    },
    {
      "epoch": 7.494100708761863,
      "grad_norm": 4.448907852172852,
      "learning_rate": 1.2545574846495872e-05,
      "loss": 0.6628,
      "step": 707900
    },
    {
      "epoch": 7.494630030541867,
      "grad_norm": 4.702548980712891,
      "learning_rate": 1.2542928223586703e-05,
      "loss": 0.6514,
      "step": 707950
    },
    {
      "epoch": 7.49515935232187,
      "grad_norm": 4.437008380889893,
      "learning_rate": 1.2540281600677537e-05,
      "loss": 0.6491,
      "step": 708000
    },
    {
      "epoch": 7.49515935232187,
      "eval_loss": 0.40520599484443665,
      "eval_runtime": 46.681,
      "eval_samples_per_second": 3597.392,
      "eval_steps_per_second": 449.69,
      "step": 708000
    },
    {
      "epoch": 7.495688674101873,
      "grad_norm": 4.755975246429443,
      "learning_rate": 1.2537634977768367e-05,
      "loss": 0.6526,
      "step": 708050
    },
    {
      "epoch": 7.496217995881876,
      "grad_norm": 4.649972438812256,
      "learning_rate": 1.25349883548592e-05,
      "loss": 0.6599,
      "step": 708100
    },
    {
      "epoch": 7.49674731766188,
      "grad_norm": 4.687446117401123,
      "learning_rate": 1.253234173195003e-05,
      "loss": 0.6436,
      "step": 708150
    },
    {
      "epoch": 7.497276639441883,
      "grad_norm": 4.622338771820068,
      "learning_rate": 1.2529695109040865e-05,
      "loss": 0.6503,
      "step": 708200
    },
    {
      "epoch": 7.497805961221887,
      "grad_norm": 4.55478572845459,
      "learning_rate": 1.2527048486131695e-05,
      "loss": 0.6552,
      "step": 708250
    },
    {
      "epoch": 7.4983352830018895,
      "grad_norm": 5.00632905960083,
      "learning_rate": 1.252440186322253e-05,
      "loss": 0.6581,
      "step": 708300
    },
    {
      "epoch": 7.498864604781893,
      "grad_norm": 4.5829691886901855,
      "learning_rate": 1.252175524031336e-05,
      "loss": 0.6553,
      "step": 708350
    },
    {
      "epoch": 7.499393926561896,
      "grad_norm": 4.694626808166504,
      "learning_rate": 1.2519108617404193e-05,
      "loss": 0.6519,
      "step": 708400
    },
    {
      "epoch": 7.4999232483419,
      "grad_norm": 4.371576309204102,
      "learning_rate": 1.2516461994495023e-05,
      "loss": 0.6482,
      "step": 708450
    },
    {
      "epoch": 7.500452570121903,
      "grad_norm": 4.633412837982178,
      "learning_rate": 1.2513815371585857e-05,
      "loss": 0.6506,
      "step": 708500
    },
    {
      "epoch": 7.500452570121903,
      "eval_loss": 0.40505725145339966,
      "eval_runtime": 46.7126,
      "eval_samples_per_second": 3594.965,
      "eval_steps_per_second": 449.387,
      "step": 708500
    },
    {
      "epoch": 7.5009818919019065,
      "grad_norm": 4.368834972381592,
      "learning_rate": 1.2511168748676688e-05,
      "loss": 0.6526,
      "step": 708550
    },
    {
      "epoch": 7.501511213681909,
      "grad_norm": 4.977768421173096,
      "learning_rate": 1.2508522125767522e-05,
      "loss": 0.6466,
      "step": 708600
    },
    {
      "epoch": 7.502040535461912,
      "grad_norm": 4.816629409790039,
      "learning_rate": 1.2505875502858353e-05,
      "loss": 0.6434,
      "step": 708650
    },
    {
      "epoch": 7.502569857241916,
      "grad_norm": 4.264555931091309,
      "learning_rate": 1.2503228879949185e-05,
      "loss": 0.6431,
      "step": 708700
    },
    {
      "epoch": 7.50309917902192,
      "grad_norm": 4.33226203918457,
      "learning_rate": 1.2500582257040016e-05,
      "loss": 0.64,
      "step": 708750
    },
    {
      "epoch": 7.503628500801923,
      "grad_norm": 4.269409656524658,
      "learning_rate": 1.249793563413085e-05,
      "loss": 0.6574,
      "step": 708800
    },
    {
      "epoch": 7.504157822581925,
      "grad_norm": 4.339325428009033,
      "learning_rate": 1.2495289011221683e-05,
      "loss": 0.6574,
      "step": 708850
    },
    {
      "epoch": 7.504687144361929,
      "grad_norm": 4.7154765129089355,
      "learning_rate": 1.2492642388312515e-05,
      "loss": 0.6578,
      "step": 708900
    },
    {
      "epoch": 7.505216466141932,
      "grad_norm": 4.368770122528076,
      "learning_rate": 1.2489995765403346e-05,
      "loss": 0.6528,
      "step": 708950
    },
    {
      "epoch": 7.505745787921936,
      "grad_norm": 4.076427936553955,
      "learning_rate": 1.2487349142494178e-05,
      "loss": 0.6541,
      "step": 709000
    },
    {
      "epoch": 7.505745787921936,
      "eval_loss": 0.40528973937034607,
      "eval_runtime": 46.7481,
      "eval_samples_per_second": 3592.235,
      "eval_steps_per_second": 449.045,
      "step": 709000
    },
    {
      "epoch": 7.506275109701939,
      "grad_norm": 3.855067729949951,
      "learning_rate": 1.248470251958501e-05,
      "loss": 0.6464,
      "step": 709050
    },
    {
      "epoch": 7.506804431481942,
      "grad_norm": 4.672600269317627,
      "learning_rate": 1.2482055896675843e-05,
      "loss": 0.6522,
      "step": 709100
    },
    {
      "epoch": 7.507333753261945,
      "grad_norm": 4.589107513427734,
      "learning_rate": 1.2479409273766675e-05,
      "loss": 0.6472,
      "step": 709150
    },
    {
      "epoch": 7.507863075041949,
      "grad_norm": 4.693238258361816,
      "learning_rate": 1.2476762650857508e-05,
      "loss": 0.6593,
      "step": 709200
    },
    {
      "epoch": 7.508392396821952,
      "grad_norm": 4.5263214111328125,
      "learning_rate": 1.2474116027948338e-05,
      "loss": 0.6487,
      "step": 709250
    },
    {
      "epoch": 7.508921718601956,
      "grad_norm": 5.101197719573975,
      "learning_rate": 1.2471469405039171e-05,
      "loss": 0.6597,
      "step": 709300
    },
    {
      "epoch": 7.5094510403819585,
      "grad_norm": 4.40872859954834,
      "learning_rate": 1.2468822782130003e-05,
      "loss": 0.6616,
      "step": 709350
    },
    {
      "epoch": 7.509980362161961,
      "grad_norm": 4.795355796813965,
      "learning_rate": 1.2466176159220836e-05,
      "loss": 0.6498,
      "step": 709400
    },
    {
      "epoch": 7.510509683941965,
      "grad_norm": 4.870850086212158,
      "learning_rate": 1.2463529536311668e-05,
      "loss": 0.6465,
      "step": 709450
    },
    {
      "epoch": 7.511039005721969,
      "grad_norm": 4.456411838531494,
      "learning_rate": 1.2460882913402499e-05,
      "loss": 0.649,
      "step": 709500
    },
    {
      "epoch": 7.511039005721969,
      "eval_loss": 0.40477123856544495,
      "eval_runtime": 46.8058,
      "eval_samples_per_second": 3587.805,
      "eval_steps_per_second": 448.492,
      "step": 709500
    },
    {
      "epoch": 7.511568327501972,
      "grad_norm": 4.826312065124512,
      "learning_rate": 1.2458236290493331e-05,
      "loss": 0.6691,
      "step": 709550
    },
    {
      "epoch": 7.512097649281975,
      "grad_norm": 4.3636155128479,
      "learning_rate": 1.2455589667584164e-05,
      "loss": 0.6522,
      "step": 709600
    },
    {
      "epoch": 7.512626971061978,
      "grad_norm": 4.0456366539001465,
      "learning_rate": 1.2452943044674996e-05,
      "loss": 0.6605,
      "step": 709650
    },
    {
      "epoch": 7.513156292841981,
      "grad_norm": 4.064249038696289,
      "learning_rate": 1.2450296421765828e-05,
      "loss": 0.6574,
      "step": 709700
    },
    {
      "epoch": 7.513685614621985,
      "grad_norm": 4.673178195953369,
      "learning_rate": 1.244764979885666e-05,
      "loss": 0.6483,
      "step": 709750
    },
    {
      "epoch": 7.514214936401988,
      "grad_norm": 4.363757610321045,
      "learning_rate": 1.2445003175947492e-05,
      "loss": 0.6495,
      "step": 709800
    },
    {
      "epoch": 7.514744258181992,
      "grad_norm": 4.57300329208374,
      "learning_rate": 1.2442409485496508e-05,
      "loss": 0.6588,
      "step": 709850
    },
    {
      "epoch": 7.5152735799619945,
      "grad_norm": 4.478408336639404,
      "learning_rate": 1.243976286258734e-05,
      "loss": 0.6534,
      "step": 709900
    },
    {
      "epoch": 7.515802901741998,
      "grad_norm": 4.54522705078125,
      "learning_rate": 1.2437116239678171e-05,
      "loss": 0.6515,
      "step": 709950
    },
    {
      "epoch": 7.516332223522001,
      "grad_norm": 4.664226055145264,
      "learning_rate": 1.2434469616769003e-05,
      "loss": 0.6576,
      "step": 710000
    },
    {
      "epoch": 7.516332223522001,
      "eval_loss": 0.4046368896961212,
      "eval_runtime": 46.8429,
      "eval_samples_per_second": 3584.965,
      "eval_steps_per_second": 448.137,
      "step": 710000
    },
    {
      "epoch": 7.516861545302005,
      "grad_norm": 4.817163944244385,
      "learning_rate": 1.2431822993859836e-05,
      "loss": 0.6569,
      "step": 710050
    },
    {
      "epoch": 7.517390867082008,
      "grad_norm": 4.604808330535889,
      "learning_rate": 1.2429176370950668e-05,
      "loss": 0.6438,
      "step": 710100
    },
    {
      "epoch": 7.517920188862011,
      "grad_norm": 4.540055751800537,
      "learning_rate": 1.24265297480415e-05,
      "loss": 0.6557,
      "step": 710150
    },
    {
      "epoch": 7.518449510642014,
      "grad_norm": 4.285672664642334,
      "learning_rate": 1.2423883125132333e-05,
      "loss": 0.6459,
      "step": 710200
    },
    {
      "epoch": 7.518978832422018,
      "grad_norm": 4.926615238189697,
      "learning_rate": 1.2421236502223164e-05,
      "loss": 0.6486,
      "step": 710250
    },
    {
      "epoch": 7.519508154202021,
      "grad_norm": 4.945080280303955,
      "learning_rate": 1.2418589879313996e-05,
      "loss": 0.6609,
      "step": 710300
    },
    {
      "epoch": 7.520037475982024,
      "grad_norm": 4.868917465209961,
      "learning_rate": 1.2415943256404829e-05,
      "loss": 0.6535,
      "step": 710350
    },
    {
      "epoch": 7.520566797762028,
      "grad_norm": 4.724514961242676,
      "learning_rate": 1.2413296633495661e-05,
      "loss": 0.6636,
      "step": 710400
    },
    {
      "epoch": 7.5210961195420305,
      "grad_norm": 4.879538536071777,
      "learning_rate": 1.2410650010586493e-05,
      "loss": 0.6528,
      "step": 710450
    },
    {
      "epoch": 7.521625441322034,
      "grad_norm": 4.8231425285339355,
      "learning_rate": 1.2408003387677324e-05,
      "loss": 0.6436,
      "step": 710500
    },
    {
      "epoch": 7.521625441322034,
      "eval_loss": 0.4040065109729767,
      "eval_runtime": 46.6763,
      "eval_samples_per_second": 3597.754,
      "eval_steps_per_second": 449.735,
      "step": 710500
    },
    {
      "epoch": 7.522154763102037,
      "grad_norm": 4.658939838409424,
      "learning_rate": 1.2405356764768157e-05,
      "loss": 0.6651,
      "step": 710550
    },
    {
      "epoch": 7.522684084882041,
      "grad_norm": 4.479683876037598,
      "learning_rate": 1.2402710141858989e-05,
      "loss": 0.66,
      "step": 710600
    },
    {
      "epoch": 7.523213406662044,
      "grad_norm": 4.1795244216918945,
      "learning_rate": 1.2400063518949821e-05,
      "loss": 0.6489,
      "step": 710650
    },
    {
      "epoch": 7.5237427284420475,
      "grad_norm": 4.0825958251953125,
      "learning_rate": 1.2397416896040654e-05,
      "loss": 0.6542,
      "step": 710700
    },
    {
      "epoch": 7.52427205022205,
      "grad_norm": 4.984871864318848,
      "learning_rate": 1.2394770273131486e-05,
      "loss": 0.6442,
      "step": 710750
    },
    {
      "epoch": 7.524801372002054,
      "grad_norm": 4.664668083190918,
      "learning_rate": 1.2392123650222317e-05,
      "loss": 0.6525,
      "step": 710800
    },
    {
      "epoch": 7.525330693782057,
      "grad_norm": 4.503207206726074,
      "learning_rate": 1.238947702731315e-05,
      "loss": 0.6493,
      "step": 710850
    },
    {
      "epoch": 7.52586001556206,
      "grad_norm": 4.268333911895752,
      "learning_rate": 1.2386830404403982e-05,
      "loss": 0.6453,
      "step": 710900
    },
    {
      "epoch": 7.526389337342064,
      "grad_norm": 4.70496940612793,
      "learning_rate": 1.2384183781494814e-05,
      "loss": 0.6529,
      "step": 710950
    },
    {
      "epoch": 7.526918659122067,
      "grad_norm": 4.659249782562256,
      "learning_rate": 1.2381537158585646e-05,
      "loss": 0.6468,
      "step": 711000
    },
    {
      "epoch": 7.526918659122067,
      "eval_loss": 0.4037209451198578,
      "eval_runtime": 46.5044,
      "eval_samples_per_second": 3611.054,
      "eval_steps_per_second": 451.398,
      "step": 711000
    },
    {
      "epoch": 7.52744798090207,
      "grad_norm": 4.91485071182251,
      "learning_rate": 1.2378890535676477e-05,
      "loss": 0.6409,
      "step": 711050
    },
    {
      "epoch": 7.527977302682073,
      "grad_norm": 4.636294841766357,
      "learning_rate": 1.237624391276731e-05,
      "loss": 0.6529,
      "step": 711100
    },
    {
      "epoch": 7.528506624462077,
      "grad_norm": 4.33963680267334,
      "learning_rate": 1.237359728985814e-05,
      "loss": 0.6419,
      "step": 711150
    },
    {
      "epoch": 7.52903594624208,
      "grad_norm": 4.8476433753967285,
      "learning_rate": 1.2370950666948973e-05,
      "loss": 0.6537,
      "step": 711200
    },
    {
      "epoch": 7.5295652680220835,
      "grad_norm": 4.4035234451293945,
      "learning_rate": 1.2368304044039805e-05,
      "loss": 0.6523,
      "step": 711250
    },
    {
      "epoch": 7.530094589802086,
      "grad_norm": 4.196110248565674,
      "learning_rate": 1.2365657421130638e-05,
      "loss": 0.6483,
      "step": 711300
    },
    {
      "epoch": 7.53062391158209,
      "grad_norm": 4.59710168838501,
      "learning_rate": 1.236301079822147e-05,
      "loss": 0.6468,
      "step": 711350
    },
    {
      "epoch": 7.531153233362093,
      "grad_norm": 4.262927055358887,
      "learning_rate": 1.23603641753123e-05,
      "loss": 0.6422,
      "step": 711400
    },
    {
      "epoch": 7.531682555142097,
      "grad_norm": 4.683391571044922,
      "learning_rate": 1.2357717552403133e-05,
      "loss": 0.6496,
      "step": 711450
    },
    {
      "epoch": 7.5322118769221,
      "grad_norm": 4.336688995361328,
      "learning_rate": 1.2355070929493965e-05,
      "loss": 0.638,
      "step": 711500
    },
    {
      "epoch": 7.5322118769221,
      "eval_loss": 0.4043819010257721,
      "eval_runtime": 46.5276,
      "eval_samples_per_second": 3609.253,
      "eval_steps_per_second": 451.173,
      "step": 711500
    },
    {
      "epoch": 7.532741198702103,
      "grad_norm": 4.071611404418945,
      "learning_rate": 1.2352424306584798e-05,
      "loss": 0.6483,
      "step": 711550
    },
    {
      "epoch": 7.533270520482106,
      "grad_norm": 4.609106540679932,
      "learning_rate": 1.234977768367563e-05,
      "loss": 0.6576,
      "step": 711600
    },
    {
      "epoch": 7.533799842262109,
      "grad_norm": 4.707931041717529,
      "learning_rate": 1.2347131060766463e-05,
      "loss": 0.6451,
      "step": 711650
    },
    {
      "epoch": 7.534329164042113,
      "grad_norm": 4.974883556365967,
      "learning_rate": 1.2344484437857293e-05,
      "loss": 0.6516,
      "step": 711700
    },
    {
      "epoch": 7.534858485822117,
      "grad_norm": 4.245491981506348,
      "learning_rate": 1.2341837814948126e-05,
      "loss": 0.654,
      "step": 711750
    },
    {
      "epoch": 7.5353878076021195,
      "grad_norm": 4.807524681091309,
      "learning_rate": 1.2339191192038958e-05,
      "loss": 0.6489,
      "step": 711800
    },
    {
      "epoch": 7.535917129382122,
      "grad_norm": 4.569262504577637,
      "learning_rate": 1.2336597501587973e-05,
      "loss": 0.6562,
      "step": 711850
    },
    {
      "epoch": 7.536446451162126,
      "grad_norm": 4.428133964538574,
      "learning_rate": 1.2333950878678805e-05,
      "loss": 0.649,
      "step": 711900
    },
    {
      "epoch": 7.536975772942129,
      "grad_norm": 4.590096950531006,
      "learning_rate": 1.2331304255769638e-05,
      "loss": 0.6436,
      "step": 711950
    },
    {
      "epoch": 7.537505094722133,
      "grad_norm": 4.709506511688232,
      "learning_rate": 1.232865763286047e-05,
      "loss": 0.6548,
      "step": 712000
    },
    {
      "epoch": 7.537505094722133,
      "eval_loss": 0.4041379392147064,
      "eval_runtime": 46.514,
      "eval_samples_per_second": 3610.311,
      "eval_steps_per_second": 451.305,
      "step": 712000
    },
    {
      "epoch": 7.538034416502136,
      "grad_norm": 4.534229278564453,
      "learning_rate": 1.2326011009951303e-05,
      "loss": 0.6508,
      "step": 712050
    },
    {
      "epoch": 7.538563738282139,
      "grad_norm": 4.681281089782715,
      "learning_rate": 1.2323364387042135e-05,
      "loss": 0.6498,
      "step": 712100
    },
    {
      "epoch": 7.539093060062142,
      "grad_norm": 4.488627910614014,
      "learning_rate": 1.2320717764132966e-05,
      "loss": 0.6558,
      "step": 712150
    },
    {
      "epoch": 7.539622381842146,
      "grad_norm": 4.736057281494141,
      "learning_rate": 1.2318071141223798e-05,
      "loss": 0.6474,
      "step": 712200
    },
    {
      "epoch": 7.540151703622149,
      "grad_norm": 4.523451328277588,
      "learning_rate": 1.231542451831463e-05,
      "loss": 0.657,
      "step": 712250
    },
    {
      "epoch": 7.540681025402153,
      "grad_norm": 4.275506496429443,
      "learning_rate": 1.2312777895405463e-05,
      "loss": 0.6423,
      "step": 712300
    },
    {
      "epoch": 7.541210347182155,
      "grad_norm": 4.523791313171387,
      "learning_rate": 1.2310131272496295e-05,
      "loss": 0.6612,
      "step": 712350
    },
    {
      "epoch": 7.541739668962158,
      "grad_norm": 4.391132831573486,
      "learning_rate": 1.2307484649587126e-05,
      "loss": 0.6432,
      "step": 712400
    },
    {
      "epoch": 7.542268990742162,
      "grad_norm": 4.57170295715332,
      "learning_rate": 1.2304838026677958e-05,
      "loss": 0.6492,
      "step": 712450
    },
    {
      "epoch": 7.542798312522166,
      "grad_norm": 4.796410083770752,
      "learning_rate": 1.230219140376879e-05,
      "loss": 0.6451,
      "step": 712500
    },
    {
      "epoch": 7.542798312522166,
      "eval_loss": 0.4039596915245056,
      "eval_runtime": 46.492,
      "eval_samples_per_second": 3612.017,
      "eval_steps_per_second": 451.518,
      "step": 712500
    },
    {
      "epoch": 7.543327634302169,
      "grad_norm": 4.100531101226807,
      "learning_rate": 1.2299544780859623e-05,
      "loss": 0.651,
      "step": 712550
    },
    {
      "epoch": 7.5438569560821715,
      "grad_norm": 4.731847286224365,
      "learning_rate": 1.2296898157950456e-05,
      "loss": 0.6529,
      "step": 712600
    },
    {
      "epoch": 7.544386277862175,
      "grad_norm": 4.470492839813232,
      "learning_rate": 1.2294251535041288e-05,
      "loss": 0.6414,
      "step": 712650
    },
    {
      "epoch": 7.544915599642178,
      "grad_norm": 4.883848190307617,
      "learning_rate": 1.2291604912132119e-05,
      "loss": 0.6567,
      "step": 712700
    },
    {
      "epoch": 7.545444921422182,
      "grad_norm": 4.098278999328613,
      "learning_rate": 1.2288958289222951e-05,
      "loss": 0.6482,
      "step": 712750
    },
    {
      "epoch": 7.545974243202185,
      "grad_norm": 4.382357120513916,
      "learning_rate": 1.2286311666313784e-05,
      "loss": 0.6511,
      "step": 712800
    },
    {
      "epoch": 7.5465035649821885,
      "grad_norm": 4.612000942230225,
      "learning_rate": 1.2283665043404616e-05,
      "loss": 0.6559,
      "step": 712850
    },
    {
      "epoch": 7.547032886762191,
      "grad_norm": 4.471203327178955,
      "learning_rate": 1.2281018420495448e-05,
      "loss": 0.652,
      "step": 712900
    },
    {
      "epoch": 7.547562208542195,
      "grad_norm": 4.6957855224609375,
      "learning_rate": 1.227837179758628e-05,
      "loss": 0.6416,
      "step": 712950
    },
    {
      "epoch": 7.548091530322198,
      "grad_norm": 4.864063739776611,
      "learning_rate": 1.2275725174677111e-05,
      "loss": 0.6532,
      "step": 713000
    },
    {
      "epoch": 7.548091530322198,
      "eval_loss": 0.40320882201194763,
      "eval_runtime": 46.4423,
      "eval_samples_per_second": 3615.886,
      "eval_steps_per_second": 452.002,
      "step": 713000
    },
    {
      "epoch": 7.548620852102202,
      "grad_norm": 4.480679035186768,
      "learning_rate": 1.2273078551767944e-05,
      "loss": 0.6442,
      "step": 713050
    },
    {
      "epoch": 7.549150173882205,
      "grad_norm": 3.892876386642456,
      "learning_rate": 1.2270431928858776e-05,
      "loss": 0.653,
      "step": 713100
    },
    {
      "epoch": 7.5496794956622075,
      "grad_norm": 4.1862053871154785,
      "learning_rate": 1.2267785305949609e-05,
      "loss": 0.6675,
      "step": 713150
    },
    {
      "epoch": 7.550208817442211,
      "grad_norm": 4.596724033355713,
      "learning_rate": 1.2265138683040441e-05,
      "loss": 0.6556,
      "step": 713200
    },
    {
      "epoch": 7.550738139222215,
      "grad_norm": 4.502723693847656,
      "learning_rate": 1.2262492060131272e-05,
      "loss": 0.6445,
      "step": 713250
    },
    {
      "epoch": 7.551267461002218,
      "grad_norm": 4.88067626953125,
      "learning_rate": 1.2259845437222104e-05,
      "loss": 0.6444,
      "step": 713300
    },
    {
      "epoch": 7.551796782782221,
      "grad_norm": 4.4649457931518555,
      "learning_rate": 1.2257198814312937e-05,
      "loss": 0.6567,
      "step": 713350
    },
    {
      "epoch": 7.5523261045622245,
      "grad_norm": 4.507687091827393,
      "learning_rate": 1.2254552191403769e-05,
      "loss": 0.6635,
      "step": 713400
    },
    {
      "epoch": 7.552855426342227,
      "grad_norm": 4.667267799377441,
      "learning_rate": 1.2251905568494601e-05,
      "loss": 0.6577,
      "step": 713450
    },
    {
      "epoch": 7.553384748122231,
      "grad_norm": 4.289698600769043,
      "learning_rate": 1.2249258945585434e-05,
      "loss": 0.6598,
      "step": 713500
    },
    {
      "epoch": 7.553384748122231,
      "eval_loss": 0.40485355257987976,
      "eval_runtime": 46.4769,
      "eval_samples_per_second": 3613.191,
      "eval_steps_per_second": 451.665,
      "step": 713500
    },
    {
      "epoch": 7.553914069902234,
      "grad_norm": 4.752278804779053,
      "learning_rate": 1.2246612322676265e-05,
      "loss": 0.6503,
      "step": 713550
    },
    {
      "epoch": 7.554443391682238,
      "grad_norm": 4.504839897155762,
      "learning_rate": 1.2243965699767097e-05,
      "loss": 0.6578,
      "step": 713600
    },
    {
      "epoch": 7.554972713462241,
      "grad_norm": 4.7122883796691895,
      "learning_rate": 1.224131907685793e-05,
      "loss": 0.6573,
      "step": 713650
    },
    {
      "epoch": 7.555502035242244,
      "grad_norm": 4.721872806549072,
      "learning_rate": 1.2238672453948762e-05,
      "loss": 0.655,
      "step": 713700
    },
    {
      "epoch": 7.556031357022247,
      "grad_norm": 4.588201999664307,
      "learning_rate": 1.2236025831039594e-05,
      "loss": 0.6591,
      "step": 713750
    },
    {
      "epoch": 7.556560678802251,
      "grad_norm": 4.885033130645752,
      "learning_rate": 1.2233379208130427e-05,
      "loss": 0.6644,
      "step": 713800
    },
    {
      "epoch": 7.557090000582254,
      "grad_norm": 4.905651092529297,
      "learning_rate": 1.2230785517679441e-05,
      "loss": 0.6513,
      "step": 713850
    },
    {
      "epoch": 7.557619322362257,
      "grad_norm": 4.374950408935547,
      "learning_rate": 1.2228138894770274e-05,
      "loss": 0.64,
      "step": 713900
    },
    {
      "epoch": 7.5581486441422605,
      "grad_norm": 4.662403106689453,
      "learning_rate": 1.2225492271861106e-05,
      "loss": 0.6622,
      "step": 713950
    },
    {
      "epoch": 7.558677965922264,
      "grad_norm": 4.442711353302002,
      "learning_rate": 1.2222845648951937e-05,
      "loss": 0.6468,
      "step": 714000
    },
    {
      "epoch": 7.558677965922264,
      "eval_loss": 0.40416449308395386,
      "eval_runtime": 46.5153,
      "eval_samples_per_second": 3610.207,
      "eval_steps_per_second": 451.292,
      "step": 714000
    },
    {
      "epoch": 7.559207287702267,
      "grad_norm": 4.881505489349365,
      "learning_rate": 1.222019902604277e-05,
      "loss": 0.6595,
      "step": 714050
    },
    {
      "epoch": 7.55973660948227,
      "grad_norm": 4.934954643249512,
      "learning_rate": 1.2217552403133602e-05,
      "loss": 0.6553,
      "step": 714100
    },
    {
      "epoch": 7.560265931262274,
      "grad_norm": 4.751424312591553,
      "learning_rate": 1.2214905780224434e-05,
      "loss": 0.652,
      "step": 714150
    },
    {
      "epoch": 7.560795253042277,
      "grad_norm": 4.4424967765808105,
      "learning_rate": 1.2212259157315266e-05,
      "loss": 0.6567,
      "step": 714200
    },
    {
      "epoch": 7.56132457482228,
      "grad_norm": 4.557841777801514,
      "learning_rate": 1.2209612534406097e-05,
      "loss": 0.6511,
      "step": 714250
    },
    {
      "epoch": 7.561853896602283,
      "grad_norm": 4.246062755584717,
      "learning_rate": 1.220696591149693e-05,
      "loss": 0.6536,
      "step": 714300
    },
    {
      "epoch": 7.562383218382287,
      "grad_norm": 4.329963207244873,
      "learning_rate": 1.2204319288587762e-05,
      "loss": 0.6513,
      "step": 714350
    },
    {
      "epoch": 7.56291254016229,
      "grad_norm": 4.663181781768799,
      "learning_rate": 1.2201672665678594e-05,
      "loss": 0.6419,
      "step": 714400
    },
    {
      "epoch": 7.563441861942294,
      "grad_norm": 4.282638072967529,
      "learning_rate": 1.2199026042769427e-05,
      "loss": 0.6615,
      "step": 714450
    },
    {
      "epoch": 7.5639711837222965,
      "grad_norm": 4.166118144989014,
      "learning_rate": 1.219637941986026e-05,
      "loss": 0.6657,
      "step": 714500
    },
    {
      "epoch": 7.5639711837222965,
      "eval_loss": 0.4030558168888092,
      "eval_runtime": 46.4476,
      "eval_samples_per_second": 3615.471,
      "eval_steps_per_second": 451.95,
      "step": 714500
    },
    {
      "epoch": 7.5645005055023,
      "grad_norm": 4.8351569175720215,
      "learning_rate": 1.219373279695109e-05,
      "loss": 0.642,
      "step": 714550
    },
    {
      "epoch": 7.565029827282303,
      "grad_norm": 4.4751458168029785,
      "learning_rate": 1.2191086174041922e-05,
      "loss": 0.64,
      "step": 714600
    },
    {
      "epoch": 7.565559149062306,
      "grad_norm": 4.006321430206299,
      "learning_rate": 1.2188439551132755e-05,
      "loss": 0.6491,
      "step": 714650
    },
    {
      "epoch": 7.56608847084231,
      "grad_norm": 4.598842620849609,
      "learning_rate": 1.2185792928223587e-05,
      "loss": 0.6507,
      "step": 714700
    },
    {
      "epoch": 7.5666177926223135,
      "grad_norm": 4.603378772735596,
      "learning_rate": 1.218314630531442e-05,
      "loss": 0.6472,
      "step": 714750
    },
    {
      "epoch": 7.567147114402316,
      "grad_norm": 4.755288600921631,
      "learning_rate": 1.2180499682405252e-05,
      "loss": 0.6523,
      "step": 714800
    },
    {
      "epoch": 7.567676436182319,
      "grad_norm": 4.201018810272217,
      "learning_rate": 1.2177853059496083e-05,
      "loss": 0.6522,
      "step": 714850
    },
    {
      "epoch": 7.568205757962323,
      "grad_norm": 4.287924289703369,
      "learning_rate": 1.2175206436586915e-05,
      "loss": 0.6585,
      "step": 714900
    },
    {
      "epoch": 7.568735079742326,
      "grad_norm": 4.611800670623779,
      "learning_rate": 1.2172559813677747e-05,
      "loss": 0.6491,
      "step": 714950
    },
    {
      "epoch": 7.56926440152233,
      "grad_norm": 4.112727165222168,
      "learning_rate": 1.216991319076858e-05,
      "loss": 0.6407,
      "step": 715000
    },
    {
      "epoch": 7.56926440152233,
      "eval_loss": 0.4024416208267212,
      "eval_runtime": 46.6425,
      "eval_samples_per_second": 3600.368,
      "eval_steps_per_second": 450.062,
      "step": 715000
    },
    {
      "epoch": 7.5697937233023325,
      "grad_norm": 4.816298007965088,
      "learning_rate": 1.2167266567859412e-05,
      "loss": 0.6646,
      "step": 715050
    },
    {
      "epoch": 7.570323045082336,
      "grad_norm": 4.6703290939331055,
      "learning_rate": 1.2164619944950243e-05,
      "loss": 0.6477,
      "step": 715100
    },
    {
      "epoch": 7.570852366862339,
      "grad_norm": 4.964442729949951,
      "learning_rate": 1.2161973322041075e-05,
      "loss": 0.6633,
      "step": 715150
    },
    {
      "epoch": 7.571381688642343,
      "grad_norm": 4.490464210510254,
      "learning_rate": 1.2159326699131908e-05,
      "loss": 0.6485,
      "step": 715200
    },
    {
      "epoch": 7.571911010422346,
      "grad_norm": 5.2036590576171875,
      "learning_rate": 1.215668007622274e-05,
      "loss": 0.6584,
      "step": 715250
    },
    {
      "epoch": 7.5724403322023495,
      "grad_norm": 4.0133957862854,
      "learning_rate": 1.2154033453313573e-05,
      "loss": 0.6439,
      "step": 715300
    },
    {
      "epoch": 7.572969653982352,
      "grad_norm": 4.84462308883667,
      "learning_rate": 1.2151386830404405e-05,
      "loss": 0.6486,
      "step": 715350
    },
    {
      "epoch": 7.573498975762355,
      "grad_norm": 4.4320292472839355,
      "learning_rate": 1.2148740207495236e-05,
      "loss": 0.6479,
      "step": 715400
    },
    {
      "epoch": 7.574028297542359,
      "grad_norm": 4.411409854888916,
      "learning_rate": 1.2146093584586068e-05,
      "loss": 0.6445,
      "step": 715450
    },
    {
      "epoch": 7.574557619322363,
      "grad_norm": 4.304878234863281,
      "learning_rate": 1.21434469616769e-05,
      "loss": 0.6574,
      "step": 715500
    },
    {
      "epoch": 7.574557619322363,
      "eval_loss": 0.4040907621383667,
      "eval_runtime": 46.5644,
      "eval_samples_per_second": 3606.401,
      "eval_steps_per_second": 450.816,
      "step": 715500
    },
    {
      "epoch": 7.575086941102366,
      "grad_norm": 4.198266506195068,
      "learning_rate": 1.2140800338767733e-05,
      "loss": 0.6461,
      "step": 715550
    },
    {
      "epoch": 7.5756162628823684,
      "grad_norm": 4.502388954162598,
      "learning_rate": 1.2138153715858565e-05,
      "loss": 0.6592,
      "step": 715600
    },
    {
      "epoch": 7.576145584662372,
      "grad_norm": 4.445279598236084,
      "learning_rate": 1.2135507092949398e-05,
      "loss": 0.6528,
      "step": 715650
    },
    {
      "epoch": 7.576674906442375,
      "grad_norm": 4.218469619750977,
      "learning_rate": 1.2132860470040228e-05,
      "loss": 0.6492,
      "step": 715700
    },
    {
      "epoch": 7.577204228222379,
      "grad_norm": 4.903266429901123,
      "learning_rate": 1.213021384713106e-05,
      "loss": 0.6448,
      "step": 715750
    },
    {
      "epoch": 7.577733550002382,
      "grad_norm": 4.46079683303833,
      "learning_rate": 1.2127567224221893e-05,
      "loss": 0.6503,
      "step": 715800
    },
    {
      "epoch": 7.5782628717823854,
      "grad_norm": 4.686829566955566,
      "learning_rate": 1.2124973533770908e-05,
      "loss": 0.6467,
      "step": 715850
    },
    {
      "epoch": 7.578792193562388,
      "grad_norm": 4.775138854980469,
      "learning_rate": 1.212232691086174e-05,
      "loss": 0.6567,
      "step": 715900
    },
    {
      "epoch": 7.579321515342392,
      "grad_norm": 3.9646689891815186,
      "learning_rate": 1.2119680287952573e-05,
      "loss": 0.6602,
      "step": 715950
    },
    {
      "epoch": 7.579850837122395,
      "grad_norm": 4.457036018371582,
      "learning_rate": 1.2117033665043405e-05,
      "loss": 0.6559,
      "step": 716000
    },
    {
      "epoch": 7.579850837122395,
      "eval_loss": 0.40333327651023865,
      "eval_runtime": 46.5173,
      "eval_samples_per_second": 3610.055,
      "eval_steps_per_second": 451.273,
      "step": 716000
    },
    {
      "epoch": 7.580380158902399,
      "grad_norm": 4.360802173614502,
      "learning_rate": 1.2114387042134238e-05,
      "loss": 0.6427,
      "step": 716050
    },
    {
      "epoch": 7.580909480682402,
      "grad_norm": 4.915583610534668,
      "learning_rate": 1.2111740419225068e-05,
      "loss": 0.6568,
      "step": 716100
    },
    {
      "epoch": 7.581438802462404,
      "grad_norm": 4.226315021514893,
      "learning_rate": 1.21090937963159e-05,
      "loss": 0.6559,
      "step": 716150
    },
    {
      "epoch": 7.581968124242408,
      "grad_norm": 4.659852981567383,
      "learning_rate": 1.2106447173406733e-05,
      "loss": 0.6557,
      "step": 716200
    },
    {
      "epoch": 7.582497446022412,
      "grad_norm": 4.765483379364014,
      "learning_rate": 1.2103800550497566e-05,
      "loss": 0.6412,
      "step": 716250
    },
    {
      "epoch": 7.583026767802415,
      "grad_norm": 4.063093662261963,
      "learning_rate": 1.2101153927588398e-05,
      "loss": 0.6505,
      "step": 716300
    },
    {
      "epoch": 7.583556089582418,
      "grad_norm": 4.5734100341796875,
      "learning_rate": 1.209850730467923e-05,
      "loss": 0.655,
      "step": 716350
    },
    {
      "epoch": 7.584085411362421,
      "grad_norm": 4.3254780769348145,
      "learning_rate": 1.2095860681770061e-05,
      "loss": 0.6523,
      "step": 716400
    },
    {
      "epoch": 7.584614733142424,
      "grad_norm": 4.589179515838623,
      "learning_rate": 1.2093214058860893e-05,
      "loss": 0.6546,
      "step": 716450
    },
    {
      "epoch": 7.585144054922428,
      "grad_norm": 4.341534614562988,
      "learning_rate": 1.2090567435951726e-05,
      "loss": 0.6492,
      "step": 716500
    },
    {
      "epoch": 7.585144054922428,
      "eval_loss": 0.40330770611763,
      "eval_runtime": 46.4329,
      "eval_samples_per_second": 3616.62,
      "eval_steps_per_second": 452.094,
      "step": 716500
    },
    {
      "epoch": 7.585673376702431,
      "grad_norm": 4.6858811378479,
      "learning_rate": 1.2087920813042558e-05,
      "loss": 0.6538,
      "step": 716550
    },
    {
      "epoch": 7.586202698482435,
      "grad_norm": 4.304747104644775,
      "learning_rate": 1.208527419013339e-05,
      "loss": 0.6525,
      "step": 716600
    },
    {
      "epoch": 7.5867320202624375,
      "grad_norm": 4.517350196838379,
      "learning_rate": 1.2082627567224223e-05,
      "loss": 0.6526,
      "step": 716650
    },
    {
      "epoch": 7.587261342042441,
      "grad_norm": 4.296554088592529,
      "learning_rate": 1.2079980944315054e-05,
      "loss": 0.648,
      "step": 716700
    },
    {
      "epoch": 7.587790663822444,
      "grad_norm": 4.341552734375,
      "learning_rate": 1.2077334321405886e-05,
      "loss": 0.6424,
      "step": 716750
    },
    {
      "epoch": 7.588319985602448,
      "grad_norm": 4.343838214874268,
      "learning_rate": 1.2074687698496719e-05,
      "loss": 0.6442,
      "step": 716800
    },
    {
      "epoch": 7.588849307382451,
      "grad_norm": 4.402442932128906,
      "learning_rate": 1.2072041075587551e-05,
      "loss": 0.6511,
      "step": 716850
    },
    {
      "epoch": 7.589378629162454,
      "grad_norm": 4.653226375579834,
      "learning_rate": 1.2069394452678383e-05,
      "loss": 0.6626,
      "step": 716900
    },
    {
      "epoch": 7.589907950942457,
      "grad_norm": 4.17616081237793,
      "learning_rate": 1.2066747829769214e-05,
      "loss": 0.6521,
      "step": 716950
    },
    {
      "epoch": 7.590437272722461,
      "grad_norm": 4.2647857666015625,
      "learning_rate": 1.2064101206860047e-05,
      "loss": 0.6495,
      "step": 717000
    },
    {
      "epoch": 7.590437272722461,
      "eval_loss": 0.4022365212440491,
      "eval_runtime": 46.4942,
      "eval_samples_per_second": 3611.845,
      "eval_steps_per_second": 451.497,
      "step": 717000
    },
    {
      "epoch": 7.590966594502464,
      "grad_norm": 4.86042594909668,
      "learning_rate": 1.2061454583950879e-05,
      "loss": 0.6577,
      "step": 717050
    },
    {
      "epoch": 7.591495916282467,
      "grad_norm": 4.180956840515137,
      "learning_rate": 1.2058807961041711e-05,
      "loss": 0.6582,
      "step": 717100
    },
    {
      "epoch": 7.592025238062471,
      "grad_norm": 4.725813865661621,
      "learning_rate": 1.2056161338132544e-05,
      "loss": 0.6498,
      "step": 717150
    },
    {
      "epoch": 7.5925545598424735,
      "grad_norm": 4.489110469818115,
      "learning_rate": 1.2053514715223376e-05,
      "loss": 0.6473,
      "step": 717200
    },
    {
      "epoch": 7.593083881622477,
      "grad_norm": 4.72512149810791,
      "learning_rate": 1.2050868092314207e-05,
      "loss": 0.6628,
      "step": 717250
    },
    {
      "epoch": 7.59361320340248,
      "grad_norm": 4.483269214630127,
      "learning_rate": 1.204822146940504e-05,
      "loss": 0.645,
      "step": 717300
    },
    {
      "epoch": 7.594142525182484,
      "grad_norm": 4.122775077819824,
      "learning_rate": 1.2045574846495872e-05,
      "loss": 0.6505,
      "step": 717350
    },
    {
      "epoch": 7.594671846962487,
      "grad_norm": 4.339600563049316,
      "learning_rate": 1.2042928223586704e-05,
      "loss": 0.6438,
      "step": 717400
    },
    {
      "epoch": 7.5952011687424905,
      "grad_norm": 4.5721940994262695,
      "learning_rate": 1.2040281600677536e-05,
      "loss": 0.6358,
      "step": 717450
    },
    {
      "epoch": 7.595730490522493,
      "grad_norm": 4.477541446685791,
      "learning_rate": 1.2037634977768369e-05,
      "loss": 0.6408,
      "step": 717500
    },
    {
      "epoch": 7.595730490522493,
      "eval_loss": 0.4021320641040802,
      "eval_runtime": 46.5302,
      "eval_samples_per_second": 3609.057,
      "eval_steps_per_second": 451.148,
      "step": 717500
    },
    {
      "epoch": 7.596259812302497,
      "grad_norm": 4.524890899658203,
      "learning_rate": 1.20349883548592e-05,
      "loss": 0.6554,
      "step": 717550
    },
    {
      "epoch": 7.5967891340825,
      "grad_norm": 4.316975116729736,
      "learning_rate": 1.2032341731950032e-05,
      "loss": 0.6415,
      "step": 717600
    },
    {
      "epoch": 7.597318455862504,
      "grad_norm": 4.190937519073486,
      "learning_rate": 1.2029695109040864e-05,
      "loss": 0.6484,
      "step": 717650
    },
    {
      "epoch": 7.597847777642507,
      "grad_norm": 4.2608642578125,
      "learning_rate": 1.2027048486131697e-05,
      "loss": 0.6548,
      "step": 717700
    },
    {
      "epoch": 7.59837709942251,
      "grad_norm": 4.5288166999816895,
      "learning_rate": 1.202440186322253e-05,
      "loss": 0.6544,
      "step": 717750
    },
    {
      "epoch": 7.598906421202513,
      "grad_norm": 4.820915222167969,
      "learning_rate": 1.202175524031336e-05,
      "loss": 0.6368,
      "step": 717800
    },
    {
      "epoch": 7.599435742982516,
      "grad_norm": 4.121441841125488,
      "learning_rate": 1.2019161549862376e-05,
      "loss": 0.6594,
      "step": 717850
    },
    {
      "epoch": 7.59996506476252,
      "grad_norm": 5.145689964294434,
      "learning_rate": 1.2016514926953209e-05,
      "loss": 0.6531,
      "step": 717900
    },
    {
      "epoch": 7.600494386542523,
      "grad_norm": 4.549347877502441,
      "learning_rate": 1.201386830404404e-05,
      "loss": 0.6604,
      "step": 717950
    },
    {
      "epoch": 7.6010237083225265,
      "grad_norm": 4.5518269538879395,
      "learning_rate": 1.2011221681134872e-05,
      "loss": 0.6491,
      "step": 718000
    },
    {
      "epoch": 7.6010237083225265,
      "eval_loss": 0.40258532762527466,
      "eval_runtime": 46.5225,
      "eval_samples_per_second": 3609.654,
      "eval_steps_per_second": 451.223,
      "step": 718000
    },
    {
      "epoch": 7.601553030102529,
      "grad_norm": 4.487548351287842,
      "learning_rate": 1.2008575058225704e-05,
      "loss": 0.6472,
      "step": 718050
    },
    {
      "epoch": 7.602082351882533,
      "grad_norm": 4.623503684997559,
      "learning_rate": 1.2005928435316537e-05,
      "loss": 0.6459,
      "step": 718100
    },
    {
      "epoch": 7.602611673662536,
      "grad_norm": 4.35893440246582,
      "learning_rate": 1.2003281812407369e-05,
      "loss": 0.6603,
      "step": 718150
    },
    {
      "epoch": 7.60314099544254,
      "grad_norm": 4.05627965927124,
      "learning_rate": 1.2000635189498201e-05,
      "loss": 0.651,
      "step": 718200
    },
    {
      "epoch": 7.603670317222543,
      "grad_norm": 4.869838237762451,
      "learning_rate": 1.1997988566589032e-05,
      "loss": 0.6403,
      "step": 718250
    },
    {
      "epoch": 7.604199639002546,
      "grad_norm": 3.9258105754852295,
      "learning_rate": 1.1995341943679865e-05,
      "loss": 0.6489,
      "step": 718300
    },
    {
      "epoch": 7.604728960782549,
      "grad_norm": 4.277868747711182,
      "learning_rate": 1.1992695320770697e-05,
      "loss": 0.6454,
      "step": 718350
    },
    {
      "epoch": 7.605258282562553,
      "grad_norm": 4.421970844268799,
      "learning_rate": 1.199004869786153e-05,
      "loss": 0.6584,
      "step": 718400
    },
    {
      "epoch": 7.605787604342556,
      "grad_norm": 4.698849201202393,
      "learning_rate": 1.1987402074952362e-05,
      "loss": 0.6495,
      "step": 718450
    },
    {
      "epoch": 7.60631692612256,
      "grad_norm": 4.139870643615723,
      "learning_rate": 1.1984755452043194e-05,
      "loss": 0.6568,
      "step": 718500
    },
    {
      "epoch": 7.60631692612256,
      "eval_loss": 0.40367624163627625,
      "eval_runtime": 46.4977,
      "eval_samples_per_second": 3611.574,
      "eval_steps_per_second": 451.463,
      "step": 718500
    },
    {
      "epoch": 7.6068462479025625,
      "grad_norm": 4.387135982513428,
      "learning_rate": 1.1982108829134025e-05,
      "loss": 0.6499,
      "step": 718550
    },
    {
      "epoch": 7.607375569682565,
      "grad_norm": 4.557770729064941,
      "learning_rate": 1.1979462206224857e-05,
      "loss": 0.6545,
      "step": 718600
    },
    {
      "epoch": 7.607904891462569,
      "grad_norm": 4.404334545135498,
      "learning_rate": 1.197681558331569e-05,
      "loss": 0.6543,
      "step": 718650
    },
    {
      "epoch": 7.608434213242572,
      "grad_norm": 4.6755595207214355,
      "learning_rate": 1.1974168960406522e-05,
      "loss": 0.6643,
      "step": 718700
    },
    {
      "epoch": 7.608963535022576,
      "grad_norm": 4.815088748931885,
      "learning_rate": 1.1971522337497355e-05,
      "loss": 0.6586,
      "step": 718750
    },
    {
      "epoch": 7.609492856802579,
      "grad_norm": 4.271382808685303,
      "learning_rate": 1.1968875714588185e-05,
      "loss": 0.6557,
      "step": 718800
    },
    {
      "epoch": 7.610022178582582,
      "grad_norm": 4.4919304847717285,
      "learning_rate": 1.1966229091679018e-05,
      "loss": 0.6588,
      "step": 718850
    },
    {
      "epoch": 7.610551500362585,
      "grad_norm": 4.31878137588501,
      "learning_rate": 1.196358246876985e-05,
      "loss": 0.6577,
      "step": 718900
    },
    {
      "epoch": 7.611080822142589,
      "grad_norm": 4.419215679168701,
      "learning_rate": 1.1960935845860682e-05,
      "loss": 0.6547,
      "step": 718950
    },
    {
      "epoch": 7.611610143922592,
      "grad_norm": 3.9409520626068115,
      "learning_rate": 1.1958289222951515e-05,
      "loss": 0.6449,
      "step": 719000
    },
    {
      "epoch": 7.611610143922592,
      "eval_loss": 0.40257254242897034,
      "eval_runtime": 46.4844,
      "eval_samples_per_second": 3612.608,
      "eval_steps_per_second": 451.592,
      "step": 719000
    },
    {
      "epoch": 7.612139465702596,
      "grad_norm": 4.491842746734619,
      "learning_rate": 1.1955642600042347e-05,
      "loss": 0.6571,
      "step": 719050
    },
    {
      "epoch": 7.6126687874825985,
      "grad_norm": 4.436435699462891,
      "learning_rate": 1.1952995977133178e-05,
      "loss": 0.6529,
      "step": 719100
    },
    {
      "epoch": 7.613198109262602,
      "grad_norm": 4.596435546875,
      "learning_rate": 1.195034935422401e-05,
      "loss": 0.6568,
      "step": 719150
    },
    {
      "epoch": 7.613727431042605,
      "grad_norm": 4.5316596031188965,
      "learning_rate": 1.1947702731314843e-05,
      "loss": 0.649,
      "step": 719200
    },
    {
      "epoch": 7.614256752822609,
      "grad_norm": 5.103446006774902,
      "learning_rate": 1.1945056108405675e-05,
      "loss": 0.647,
      "step": 719250
    },
    {
      "epoch": 7.614786074602612,
      "grad_norm": 4.663219928741455,
      "learning_rate": 1.1942409485496508e-05,
      "loss": 0.6476,
      "step": 719300
    },
    {
      "epoch": 7.615315396382615,
      "grad_norm": 4.642115116119385,
      "learning_rate": 1.193976286258734e-05,
      "loss": 0.6566,
      "step": 719350
    },
    {
      "epoch": 7.615844718162618,
      "grad_norm": 4.552806377410889,
      "learning_rate": 1.193711623967817e-05,
      "loss": 0.6484,
      "step": 719400
    },
    {
      "epoch": 7.616374039942621,
      "grad_norm": 4.30525541305542,
      "learning_rate": 1.1934469616769003e-05,
      "loss": 0.643,
      "step": 719450
    },
    {
      "epoch": 7.616903361722625,
      "grad_norm": 4.366015434265137,
      "learning_rate": 1.1931822993859836e-05,
      "loss": 0.6487,
      "step": 719500
    },
    {
      "epoch": 7.616903361722625,
      "eval_loss": 0.4022919833660126,
      "eval_runtime": 46.509,
      "eval_samples_per_second": 3610.699,
      "eval_steps_per_second": 451.354,
      "step": 719500
    },
    {
      "epoch": 7.617432683502628,
      "grad_norm": 4.418696880340576,
      "learning_rate": 1.1929176370950668e-05,
      "loss": 0.6542,
      "step": 719550
    },
    {
      "epoch": 7.617962005282632,
      "grad_norm": 4.392348766326904,
      "learning_rate": 1.19265297480415e-05,
      "loss": 0.6486,
      "step": 719600
    },
    {
      "epoch": 7.618491327062634,
      "grad_norm": 4.267222881317139,
      "learning_rate": 1.1923883125132331e-05,
      "loss": 0.6568,
      "step": 719650
    },
    {
      "epoch": 7.619020648842638,
      "grad_norm": 4.9705023765563965,
      "learning_rate": 1.1921236502223163e-05,
      "loss": 0.6464,
      "step": 719700
    },
    {
      "epoch": 7.619549970622641,
      "grad_norm": 4.306241512298584,
      "learning_rate": 1.1918589879313996e-05,
      "loss": 0.6504,
      "step": 719750
    },
    {
      "epoch": 7.620079292402645,
      "grad_norm": 4.408176898956299,
      "learning_rate": 1.1915943256404828e-05,
      "loss": 0.6401,
      "step": 719800
    },
    {
      "epoch": 7.620608614182648,
      "grad_norm": 4.839637279510498,
      "learning_rate": 1.1913349565953843e-05,
      "loss": 0.6554,
      "step": 719850
    },
    {
      "epoch": 7.621137935962651,
      "grad_norm": 4.270936489105225,
      "learning_rate": 1.1910702943044675e-05,
      "loss": 0.651,
      "step": 719900
    },
    {
      "epoch": 7.621667257742654,
      "grad_norm": 4.4846272468566895,
      "learning_rate": 1.1908056320135508e-05,
      "loss": 0.6524,
      "step": 719950
    },
    {
      "epoch": 7.622196579522658,
      "grad_norm": 4.388745307922363,
      "learning_rate": 1.190540969722634e-05,
      "loss": 0.641,
      "step": 720000
    },
    {
      "epoch": 7.622196579522658,
      "eval_loss": 0.4022814631462097,
      "eval_runtime": 46.3731,
      "eval_samples_per_second": 3621.277,
      "eval_steps_per_second": 452.676,
      "step": 720000
    },
    {
      "epoch": 7.622725901302661,
      "grad_norm": 4.092037200927734,
      "learning_rate": 1.1902763074317173e-05,
      "loss": 0.6529,
      "step": 720050
    },
    {
      "epoch": 7.623255223082664,
      "grad_norm": 4.306391716003418,
      "learning_rate": 1.1900116451408003e-05,
      "loss": 0.6449,
      "step": 720100
    },
    {
      "epoch": 7.6237845448626675,
      "grad_norm": 4.667200565338135,
      "learning_rate": 1.1897469828498836e-05,
      "loss": 0.6458,
      "step": 720150
    },
    {
      "epoch": 7.62431386664267,
      "grad_norm": 4.492833137512207,
      "learning_rate": 1.1894823205589668e-05,
      "loss": 0.6476,
      "step": 720200
    },
    {
      "epoch": 7.624843188422674,
      "grad_norm": 4.516141414642334,
      "learning_rate": 1.18921765826805e-05,
      "loss": 0.6553,
      "step": 720250
    },
    {
      "epoch": 7.625372510202677,
      "grad_norm": 4.4728875160217285,
      "learning_rate": 1.1889529959771333e-05,
      "loss": 0.6516,
      "step": 720300
    },
    {
      "epoch": 7.625901831982681,
      "grad_norm": 4.240310192108154,
      "learning_rate": 1.1886883336862165e-05,
      "loss": 0.6552,
      "step": 720350
    },
    {
      "epoch": 7.626431153762684,
      "grad_norm": 5.1619954109191895,
      "learning_rate": 1.1884236713952996e-05,
      "loss": 0.6475,
      "step": 720400
    },
    {
      "epoch": 7.626960475542687,
      "grad_norm": 4.729503154754639,
      "learning_rate": 1.1881590091043828e-05,
      "loss": 0.6553,
      "step": 720450
    },
    {
      "epoch": 7.62748979732269,
      "grad_norm": 4.393033504486084,
      "learning_rate": 1.1878943468134661e-05,
      "loss": 0.6392,
      "step": 720500
    },
    {
      "epoch": 7.62748979732269,
      "eval_loss": 0.4020357131958008,
      "eval_runtime": 46.5194,
      "eval_samples_per_second": 3609.894,
      "eval_steps_per_second": 451.253,
      "step": 720500
    },
    {
      "epoch": 7.628019119102694,
      "grad_norm": 4.83400821685791,
      "learning_rate": 1.1876296845225493e-05,
      "loss": 0.6402,
      "step": 720550
    },
    {
      "epoch": 7.628548440882697,
      "grad_norm": 4.479348182678223,
      "learning_rate": 1.1873650222316326e-05,
      "loss": 0.6488,
      "step": 720600
    },
    {
      "epoch": 7.629077762662701,
      "grad_norm": 4.445296287536621,
      "learning_rate": 1.1871003599407156e-05,
      "loss": 0.6558,
      "step": 720650
    },
    {
      "epoch": 7.6296070844427035,
      "grad_norm": 4.066791534423828,
      "learning_rate": 1.1868356976497989e-05,
      "loss": 0.6537,
      "step": 720700
    },
    {
      "epoch": 7.630136406222707,
      "grad_norm": 4.529666423797607,
      "learning_rate": 1.1865710353588821e-05,
      "loss": 0.6491,
      "step": 720750
    },
    {
      "epoch": 7.63066572800271,
      "grad_norm": 4.69246244430542,
      "learning_rate": 1.1863063730679654e-05,
      "loss": 0.6494,
      "step": 720800
    },
    {
      "epoch": 7.631195049782713,
      "grad_norm": 4.5656328201293945,
      "learning_rate": 1.1860417107770486e-05,
      "loss": 0.6615,
      "step": 720850
    },
    {
      "epoch": 7.631724371562717,
      "grad_norm": 4.572747707366943,
      "learning_rate": 1.1857770484861318e-05,
      "loss": 0.6439,
      "step": 720900
    },
    {
      "epoch": 7.63225369334272,
      "grad_norm": 4.379891395568848,
      "learning_rate": 1.185512386195215e-05,
      "loss": 0.6476,
      "step": 720950
    },
    {
      "epoch": 7.632783015122723,
      "grad_norm": 4.261277675628662,
      "learning_rate": 1.1852477239042982e-05,
      "loss": 0.6398,
      "step": 721000
    },
    {
      "epoch": 7.632783015122723,
      "eval_loss": 0.402115136384964,
      "eval_runtime": 46.4727,
      "eval_samples_per_second": 3613.519,
      "eval_steps_per_second": 451.706,
      "step": 721000
    },
    {
      "epoch": 7.633312336902726,
      "grad_norm": 4.6498188972473145,
      "learning_rate": 1.1849830616133814e-05,
      "loss": 0.648,
      "step": 721050
    },
    {
      "epoch": 7.63384165868273,
      "grad_norm": 4.461620330810547,
      "learning_rate": 1.1847183993224646e-05,
      "loss": 0.6449,
      "step": 721100
    },
    {
      "epoch": 7.634370980462733,
      "grad_norm": 4.572086334228516,
      "learning_rate": 1.1844537370315479e-05,
      "loss": 0.6484,
      "step": 721150
    },
    {
      "epoch": 7.634900302242737,
      "grad_norm": 4.481287002563477,
      "learning_rate": 1.1841890747406311e-05,
      "loss": 0.6506,
      "step": 721200
    },
    {
      "epoch": 7.6354296240227395,
      "grad_norm": 4.592207431793213,
      "learning_rate": 1.1839244124497142e-05,
      "loss": 0.6342,
      "step": 721250
    },
    {
      "epoch": 7.635958945802743,
      "grad_norm": 4.923111438751221,
      "learning_rate": 1.1836597501587974e-05,
      "loss": 0.659,
      "step": 721300
    },
    {
      "epoch": 7.636488267582746,
      "grad_norm": 4.814607620239258,
      "learning_rate": 1.1833950878678807e-05,
      "loss": 0.6518,
      "step": 721350
    },
    {
      "epoch": 7.63701758936275,
      "grad_norm": 4.323403835296631,
      "learning_rate": 1.1831304255769639e-05,
      "loss": 0.6553,
      "step": 721400
    },
    {
      "epoch": 7.637546911142753,
      "grad_norm": 4.740285396575928,
      "learning_rate": 1.1828657632860472e-05,
      "loss": 0.6544,
      "step": 721450
    },
    {
      "epoch": 7.6380762329227565,
      "grad_norm": 4.811343669891357,
      "learning_rate": 1.1826011009951302e-05,
      "loss": 0.6451,
      "step": 721500
    },
    {
      "epoch": 7.6380762329227565,
      "eval_loss": 0.4017564058303833,
      "eval_runtime": 46.4961,
      "eval_samples_per_second": 3611.702,
      "eval_steps_per_second": 451.479,
      "step": 721500
    },
    {
      "epoch": 7.638605554702759,
      "grad_norm": 4.554764747619629,
      "learning_rate": 1.1823364387042135e-05,
      "loss": 0.6638,
      "step": 721550
    },
    {
      "epoch": 7.639134876482762,
      "grad_norm": 4.580569267272949,
      "learning_rate": 1.1820717764132967e-05,
      "loss": 0.6615,
      "step": 721600
    },
    {
      "epoch": 7.639664198262766,
      "grad_norm": 4.434682369232178,
      "learning_rate": 1.18180711412238e-05,
      "loss": 0.644,
      "step": 721650
    },
    {
      "epoch": 7.640193520042769,
      "grad_norm": 4.4874114990234375,
      "learning_rate": 1.1815424518314632e-05,
      "loss": 0.6489,
      "step": 721700
    },
    {
      "epoch": 7.640722841822773,
      "grad_norm": 4.339498996734619,
      "learning_rate": 1.1812777895405464e-05,
      "loss": 0.6532,
      "step": 721750
    },
    {
      "epoch": 7.6412521636027755,
      "grad_norm": 4.646207809448242,
      "learning_rate": 1.1810131272496295e-05,
      "loss": 0.6539,
      "step": 721800
    },
    {
      "epoch": 7.641781485382779,
      "grad_norm": 4.530829906463623,
      "learning_rate": 1.1807537582045311e-05,
      "loss": 0.6529,
      "step": 721850
    },
    {
      "epoch": 7.642310807162782,
      "grad_norm": 4.406564235687256,
      "learning_rate": 1.1804890959136144e-05,
      "loss": 0.6544,
      "step": 721900
    },
    {
      "epoch": 7.642840128942786,
      "grad_norm": 4.360921859741211,
      "learning_rate": 1.1802244336226974e-05,
      "loss": 0.6497,
      "step": 721950
    },
    {
      "epoch": 7.643369450722789,
      "grad_norm": 4.545459747314453,
      "learning_rate": 1.1799597713317807e-05,
      "loss": 0.6457,
      "step": 722000
    },
    {
      "epoch": 7.643369450722789,
      "eval_loss": 0.40135249495506287,
      "eval_runtime": 46.4773,
      "eval_samples_per_second": 3613.165,
      "eval_steps_per_second": 451.662,
      "step": 722000
    },
    {
      "epoch": 7.6438987725027925,
      "grad_norm": 4.503400802612305,
      "learning_rate": 1.179695109040864e-05,
      "loss": 0.655,
      "step": 722050
    },
    {
      "epoch": 7.644428094282795,
      "grad_norm": 5.0382890701293945,
      "learning_rate": 1.1794304467499472e-05,
      "loss": 0.6588,
      "step": 722100
    },
    {
      "epoch": 7.644957416062799,
      "grad_norm": 4.458222389221191,
      "learning_rate": 1.1791657844590304e-05,
      "loss": 0.656,
      "step": 722150
    },
    {
      "epoch": 7.645486737842802,
      "grad_norm": 4.616653919219971,
      "learning_rate": 1.1789011221681137e-05,
      "loss": 0.6358,
      "step": 722200
    },
    {
      "epoch": 7.646016059622806,
      "grad_norm": 4.4171552658081055,
      "learning_rate": 1.1786364598771967e-05,
      "loss": 0.6408,
      "step": 722250
    },
    {
      "epoch": 7.646545381402809,
      "grad_norm": 4.332462787628174,
      "learning_rate": 1.17837179758628e-05,
      "loss": 0.6588,
      "step": 722300
    },
    {
      "epoch": 7.6470747031828115,
      "grad_norm": 4.656122207641602,
      "learning_rate": 1.1781071352953632e-05,
      "loss": 0.6639,
      "step": 722350
    },
    {
      "epoch": 7.647604024962815,
      "grad_norm": 4.550506591796875,
      "learning_rate": 1.1778424730044464e-05,
      "loss": 0.6522,
      "step": 722400
    },
    {
      "epoch": 7.648133346742818,
      "grad_norm": 4.370944976806641,
      "learning_rate": 1.1775778107135297e-05,
      "loss": 0.6426,
      "step": 722450
    },
    {
      "epoch": 7.648662668522822,
      "grad_norm": 4.847289562225342,
      "learning_rate": 1.1773131484226128e-05,
      "loss": 0.6433,
      "step": 722500
    },
    {
      "epoch": 7.648662668522822,
      "eval_loss": 0.40180256962776184,
      "eval_runtime": 46.4974,
      "eval_samples_per_second": 3611.599,
      "eval_steps_per_second": 451.466,
      "step": 722500
    },
    {
      "epoch": 7.649191990302825,
      "grad_norm": 4.821598529815674,
      "learning_rate": 1.177048486131696e-05,
      "loss": 0.6388,
      "step": 722550
    },
    {
      "epoch": 7.6497213120828285,
      "grad_norm": 4.5736188888549805,
      "learning_rate": 1.1767838238407792e-05,
      "loss": 0.6469,
      "step": 722600
    },
    {
      "epoch": 7.650250633862831,
      "grad_norm": 4.330205917358398,
      "learning_rate": 1.1765191615498625e-05,
      "loss": 0.6535,
      "step": 722650
    },
    {
      "epoch": 7.650779955642835,
      "grad_norm": 4.344802379608154,
      "learning_rate": 1.1762544992589457e-05,
      "loss": 0.6498,
      "step": 722700
    },
    {
      "epoch": 7.651309277422838,
      "grad_norm": 4.402859210968018,
      "learning_rate": 1.175989836968029e-05,
      "loss": 0.6432,
      "step": 722750
    },
    {
      "epoch": 7.651838599202842,
      "grad_norm": 4.409357070922852,
      "learning_rate": 1.175725174677112e-05,
      "loss": 0.6466,
      "step": 722800
    },
    {
      "epoch": 7.652367920982845,
      "grad_norm": 5.131836414337158,
      "learning_rate": 1.1754605123861953e-05,
      "loss": 0.6462,
      "step": 722850
    },
    {
      "epoch": 7.652897242762848,
      "grad_norm": 4.4224419593811035,
      "learning_rate": 1.1751958500952785e-05,
      "loss": 0.6423,
      "step": 722900
    },
    {
      "epoch": 7.653426564542851,
      "grad_norm": 4.878753185272217,
      "learning_rate": 1.1749311878043618e-05,
      "loss": 0.6599,
      "step": 722950
    },
    {
      "epoch": 7.653955886322855,
      "grad_norm": 4.6251959800720215,
      "learning_rate": 1.174666525513445e-05,
      "loss": 0.6462,
      "step": 723000
    },
    {
      "epoch": 7.653955886322855,
      "eval_loss": 0.40155160427093506,
      "eval_runtime": 46.4428,
      "eval_samples_per_second": 3615.842,
      "eval_steps_per_second": 451.996,
      "step": 723000
    },
    {
      "epoch": 7.654485208102858,
      "grad_norm": 4.924354553222656,
      "learning_rate": 1.1744018632225282e-05,
      "loss": 0.6601,
      "step": 723050
    },
    {
      "epoch": 7.655014529882861,
      "grad_norm": 4.339751720428467,
      "learning_rate": 1.1741372009316113e-05,
      "loss": 0.6573,
      "step": 723100
    },
    {
      "epoch": 7.655543851662864,
      "grad_norm": 4.705391883850098,
      "learning_rate": 1.1738725386406945e-05,
      "loss": 0.6455,
      "step": 723150
    },
    {
      "epoch": 7.656073173442867,
      "grad_norm": 4.297934055328369,
      "learning_rate": 1.1736078763497778e-05,
      "loss": 0.6538,
      "step": 723200
    },
    {
      "epoch": 7.656602495222871,
      "grad_norm": 4.817197799682617,
      "learning_rate": 1.173343214058861e-05,
      "loss": 0.6619,
      "step": 723250
    },
    {
      "epoch": 7.657131817002874,
      "grad_norm": 4.548290252685547,
      "learning_rate": 1.1730785517679443e-05,
      "loss": 0.6485,
      "step": 723300
    },
    {
      "epoch": 7.657661138782878,
      "grad_norm": 4.575638294219971,
      "learning_rate": 1.1728138894770273e-05,
      "loss": 0.6337,
      "step": 723350
    },
    {
      "epoch": 7.6581904605628806,
      "grad_norm": 4.606349945068359,
      "learning_rate": 1.1725492271861106e-05,
      "loss": 0.6558,
      "step": 723400
    },
    {
      "epoch": 7.658719782342884,
      "grad_norm": 4.719318866729736,
      "learning_rate": 1.1722845648951938e-05,
      "loss": 0.6607,
      "step": 723450
    },
    {
      "epoch": 7.659249104122887,
      "grad_norm": 4.6777167320251465,
      "learning_rate": 1.172019902604277e-05,
      "loss": 0.6467,
      "step": 723500
    },
    {
      "epoch": 7.659249104122887,
      "eval_loss": 0.4013737440109253,
      "eval_runtime": 46.5056,
      "eval_samples_per_second": 3610.963,
      "eval_steps_per_second": 451.387,
      "step": 723500
    },
    {
      "epoch": 7.659778425902891,
      "grad_norm": 4.604675769805908,
      "learning_rate": 1.1717552403133603e-05,
      "loss": 0.648,
      "step": 723550
    },
    {
      "epoch": 7.660307747682894,
      "grad_norm": 4.748629570007324,
      "learning_rate": 1.1714905780224435e-05,
      "loss": 0.648,
      "step": 723600
    },
    {
      "epoch": 7.6608370694628976,
      "grad_norm": 4.257106304168701,
      "learning_rate": 1.1712259157315266e-05,
      "loss": 0.6591,
      "step": 723650
    },
    {
      "epoch": 7.6613663912429,
      "grad_norm": 4.487686634063721,
      "learning_rate": 1.1709612534406099e-05,
      "loss": 0.6477,
      "step": 723700
    },
    {
      "epoch": 7.661895713022904,
      "grad_norm": 4.544958114624023,
      "learning_rate": 1.1706965911496931e-05,
      "loss": 0.6364,
      "step": 723750
    },
    {
      "epoch": 7.662425034802907,
      "grad_norm": 4.465651035308838,
      "learning_rate": 1.1704319288587763e-05,
      "loss": 0.653,
      "step": 723800
    },
    {
      "epoch": 7.66295435658291,
      "grad_norm": 4.655104637145996,
      "learning_rate": 1.1701672665678596e-05,
      "loss": 0.6437,
      "step": 723850
    },
    {
      "epoch": 7.663483678362914,
      "grad_norm": 4.26078462600708,
      "learning_rate": 1.169907897522761e-05,
      "loss": 0.6554,
      "step": 723900
    },
    {
      "epoch": 7.6640130001429165,
      "grad_norm": 4.468109607696533,
      "learning_rate": 1.1696432352318443e-05,
      "loss": 0.6539,
      "step": 723950
    },
    {
      "epoch": 7.66454232192292,
      "grad_norm": 4.348880290985107,
      "learning_rate": 1.1693785729409275e-05,
      "loss": 0.6387,
      "step": 724000
    },
    {
      "epoch": 7.66454232192292,
      "eval_loss": 0.4014129638671875,
      "eval_runtime": 46.5515,
      "eval_samples_per_second": 3607.406,
      "eval_steps_per_second": 450.942,
      "step": 724000
    },
    {
      "epoch": 7.665071643702923,
      "grad_norm": 4.369752407073975,
      "learning_rate": 1.1691139106500108e-05,
      "loss": 0.6596,
      "step": 724050
    },
    {
      "epoch": 7.665600965482927,
      "grad_norm": 4.815274715423584,
      "learning_rate": 1.1688492483590938e-05,
      "loss": 0.6486,
      "step": 724100
    },
    {
      "epoch": 7.66613028726293,
      "grad_norm": 4.479052543640137,
      "learning_rate": 1.168584586068177e-05,
      "loss": 0.647,
      "step": 724150
    },
    {
      "epoch": 7.6666596090429335,
      "grad_norm": 4.598507404327393,
      "learning_rate": 1.1683199237772603e-05,
      "loss": 0.6518,
      "step": 724200
    },
    {
      "epoch": 7.667188930822936,
      "grad_norm": 4.1987786293029785,
      "learning_rate": 1.1680552614863436e-05,
      "loss": 0.6524,
      "step": 724250
    },
    {
      "epoch": 7.66771825260294,
      "grad_norm": 4.230793476104736,
      "learning_rate": 1.1677905991954268e-05,
      "loss": 0.6383,
      "step": 724300
    },
    {
      "epoch": 7.668247574382943,
      "grad_norm": 4.632607460021973,
      "learning_rate": 1.1675259369045099e-05,
      "loss": 0.6409,
      "step": 724350
    },
    {
      "epoch": 7.668776896162947,
      "grad_norm": 4.213996410369873,
      "learning_rate": 1.1672612746135931e-05,
      "loss": 0.6565,
      "step": 724400
    },
    {
      "epoch": 7.66930621794295,
      "grad_norm": 4.270135402679443,
      "learning_rate": 1.1669966123226764e-05,
      "loss": 0.6526,
      "step": 724450
    },
    {
      "epoch": 7.669835539722953,
      "grad_norm": 4.112346649169922,
      "learning_rate": 1.1667319500317596e-05,
      "loss": 0.6401,
      "step": 724500
    },
    {
      "epoch": 7.669835539722953,
      "eval_loss": 0.4016282260417938,
      "eval_runtime": 46.485,
      "eval_samples_per_second": 3612.566,
      "eval_steps_per_second": 451.587,
      "step": 724500
    },
    {
      "epoch": 7.670364861502956,
      "grad_norm": 4.650848865509033,
      "learning_rate": 1.1664672877408428e-05,
      "loss": 0.6499,
      "step": 724550
    },
    {
      "epoch": 7.670894183282959,
      "grad_norm": 4.608489036560059,
      "learning_rate": 1.166202625449926e-05,
      "loss": 0.6564,
      "step": 724600
    },
    {
      "epoch": 7.671423505062963,
      "grad_norm": 4.4839396476745605,
      "learning_rate": 1.1659379631590091e-05,
      "loss": 0.658,
      "step": 724650
    },
    {
      "epoch": 7.671952826842966,
      "grad_norm": 4.650051593780518,
      "learning_rate": 1.1656733008680924e-05,
      "loss": 0.6527,
      "step": 724700
    },
    {
      "epoch": 7.6724821486229695,
      "grad_norm": 4.183751106262207,
      "learning_rate": 1.1654086385771756e-05,
      "loss": 0.6353,
      "step": 724750
    },
    {
      "epoch": 7.673011470402972,
      "grad_norm": 4.618245601654053,
      "learning_rate": 1.1651439762862589e-05,
      "loss": 0.6461,
      "step": 724800
    },
    {
      "epoch": 7.673540792182976,
      "grad_norm": 4.763848304748535,
      "learning_rate": 1.1648793139953421e-05,
      "loss": 0.6555,
      "step": 724850
    },
    {
      "epoch": 7.674070113962979,
      "grad_norm": 4.496953964233398,
      "learning_rate": 1.1646146517044253e-05,
      "loss": 0.6433,
      "step": 724900
    },
    {
      "epoch": 7.674599435742983,
      "grad_norm": 4.356179237365723,
      "learning_rate": 1.1643499894135084e-05,
      "loss": 0.6526,
      "step": 724950
    },
    {
      "epoch": 7.675128757522986,
      "grad_norm": 4.62563419342041,
      "learning_rate": 1.1640853271225917e-05,
      "loss": 0.6471,
      "step": 725000
    },
    {
      "epoch": 7.675128757522986,
      "eval_loss": 0.40149956941604614,
      "eval_runtime": 46.658,
      "eval_samples_per_second": 3599.171,
      "eval_steps_per_second": 449.912,
      "step": 725000
    },
    {
      "epoch": 7.675658079302989,
      "grad_norm": 4.2188873291015625,
      "learning_rate": 1.1638206648316749e-05,
      "loss": 0.6496,
      "step": 725050
    },
    {
      "epoch": 7.676187401082992,
      "grad_norm": 4.597362518310547,
      "learning_rate": 1.1635560025407581e-05,
      "loss": 0.6555,
      "step": 725100
    },
    {
      "epoch": 7.676716722862996,
      "grad_norm": 4.550827980041504,
      "learning_rate": 1.1632913402498414e-05,
      "loss": 0.6426,
      "step": 725150
    },
    {
      "epoch": 7.677246044642999,
      "grad_norm": 4.677882194519043,
      "learning_rate": 1.1630266779589245e-05,
      "loss": 0.6663,
      "step": 725200
    },
    {
      "epoch": 7.677775366423003,
      "grad_norm": 4.65657901763916,
      "learning_rate": 1.1627620156680077e-05,
      "loss": 0.6505,
      "step": 725250
    },
    {
      "epoch": 7.6783046882030055,
      "grad_norm": 4.372838973999023,
      "learning_rate": 1.162497353377091e-05,
      "loss": 0.6519,
      "step": 725300
    },
    {
      "epoch": 7.678834009983008,
      "grad_norm": 4.433797359466553,
      "learning_rate": 1.1622326910861742e-05,
      "loss": 0.6546,
      "step": 725350
    },
    {
      "epoch": 7.679363331763012,
      "grad_norm": 4.366214275360107,
      "learning_rate": 1.1619680287952574e-05,
      "loss": 0.6435,
      "step": 725400
    },
    {
      "epoch": 7.679892653543015,
      "grad_norm": 4.470276832580566,
      "learning_rate": 1.1617033665043407e-05,
      "loss": 0.657,
      "step": 725450
    },
    {
      "epoch": 7.680421975323019,
      "grad_norm": 4.553456783294678,
      "learning_rate": 1.1614387042134237e-05,
      "loss": 0.6467,
      "step": 725500
    },
    {
      "epoch": 7.680421975323019,
      "eval_loss": 0.40087902545928955,
      "eval_runtime": 46.5187,
      "eval_samples_per_second": 3609.947,
      "eval_steps_per_second": 451.259,
      "step": 725500
    },
    {
      "epoch": 7.680951297103022,
      "grad_norm": 4.331114292144775,
      "learning_rate": 1.161174041922507e-05,
      "loss": 0.6659,
      "step": 725550
    },
    {
      "epoch": 7.681480618883025,
      "grad_norm": 4.446120262145996,
      "learning_rate": 1.1609093796315902e-05,
      "loss": 0.635,
      "step": 725600
    },
    {
      "epoch": 7.682009940663028,
      "grad_norm": 4.303929328918457,
      "learning_rate": 1.1606447173406733e-05,
      "loss": 0.6561,
      "step": 725650
    },
    {
      "epoch": 7.682539262443032,
      "grad_norm": 4.757770538330078,
      "learning_rate": 1.1603800550497565e-05,
      "loss": 0.6354,
      "step": 725700
    },
    {
      "epoch": 7.683068584223035,
      "grad_norm": 4.447437763214111,
      "learning_rate": 1.1601153927588398e-05,
      "loss": 0.6454,
      "step": 725750
    },
    {
      "epoch": 7.683597906003039,
      "grad_norm": 4.428657054901123,
      "learning_rate": 1.159850730467923e-05,
      "loss": 0.648,
      "step": 725800
    },
    {
      "epoch": 7.6841272277830415,
      "grad_norm": 4.533764362335205,
      "learning_rate": 1.159586068177006e-05,
      "loss": 0.6394,
      "step": 725850
    },
    {
      "epoch": 7.684656549563045,
      "grad_norm": 4.538938522338867,
      "learning_rate": 1.1593266991319079e-05,
      "loss": 0.6529,
      "step": 725900
    },
    {
      "epoch": 7.685185871343048,
      "grad_norm": 4.543471336364746,
      "learning_rate": 1.1590673300868094e-05,
      "loss": 0.6448,
      "step": 725950
    },
    {
      "epoch": 7.685715193123052,
      "grad_norm": 4.549468040466309,
      "learning_rate": 1.1588026677958926e-05,
      "loss": 0.6378,
      "step": 726000
    },
    {
      "epoch": 7.685715193123052,
      "eval_loss": 0.40099647641181946,
      "eval_runtime": 46.5094,
      "eval_samples_per_second": 3610.666,
      "eval_steps_per_second": 451.349,
      "step": 726000
    },
    {
      "epoch": 7.686244514903055,
      "grad_norm": 5.05656623840332,
      "learning_rate": 1.1585380055049758e-05,
      "loss": 0.6481,
      "step": 726050
    },
    {
      "epoch": 7.686773836683058,
      "grad_norm": 4.50424337387085,
      "learning_rate": 1.1582733432140589e-05,
      "loss": 0.6576,
      "step": 726100
    },
    {
      "epoch": 7.687303158463061,
      "grad_norm": 4.6046600341796875,
      "learning_rate": 1.1580086809231421e-05,
      "loss": 0.6576,
      "step": 726150
    },
    {
      "epoch": 7.687832480243064,
      "grad_norm": 4.683929920196533,
      "learning_rate": 1.1577440186322254e-05,
      "loss": 0.6502,
      "step": 726200
    },
    {
      "epoch": 7.688361802023068,
      "grad_norm": 4.860213279724121,
      "learning_rate": 1.1574793563413086e-05,
      "loss": 0.6415,
      "step": 726250
    },
    {
      "epoch": 7.688891123803071,
      "grad_norm": 4.836575984954834,
      "learning_rate": 1.1572146940503919e-05,
      "loss": 0.6536,
      "step": 726300
    },
    {
      "epoch": 7.689420445583075,
      "grad_norm": 4.381490230560303,
      "learning_rate": 1.1569500317594751e-05,
      "loss": 0.6366,
      "step": 726350
    },
    {
      "epoch": 7.6899497673630774,
      "grad_norm": 4.7955546379089355,
      "learning_rate": 1.1566853694685582e-05,
      "loss": 0.636,
      "step": 726400
    },
    {
      "epoch": 7.690479089143081,
      "grad_norm": 4.970096111297607,
      "learning_rate": 1.1564207071776414e-05,
      "loss": 0.6487,
      "step": 726450
    },
    {
      "epoch": 7.691008410923084,
      "grad_norm": 4.459779262542725,
      "learning_rate": 1.1561560448867247e-05,
      "loss": 0.6506,
      "step": 726500
    },
    {
      "epoch": 7.691008410923084,
      "eval_loss": 0.4009082019329071,
      "eval_runtime": 46.5007,
      "eval_samples_per_second": 3611.346,
      "eval_steps_per_second": 451.434,
      "step": 726500
    },
    {
      "epoch": 7.691537732703088,
      "grad_norm": 4.525209903717041,
      "learning_rate": 1.1558913825958079e-05,
      "loss": 0.648,
      "step": 726550
    },
    {
      "epoch": 7.692067054483091,
      "grad_norm": 4.763922691345215,
      "learning_rate": 1.1556267203048911e-05,
      "loss": 0.6657,
      "step": 726600
    },
    {
      "epoch": 7.6925963762630944,
      "grad_norm": 4.6371612548828125,
      "learning_rate": 1.1553620580139742e-05,
      "loss": 0.6558,
      "step": 726650
    },
    {
      "epoch": 7.693125698043097,
      "grad_norm": 4.442513465881348,
      "learning_rate": 1.1550973957230575e-05,
      "loss": 0.6382,
      "step": 726700
    },
    {
      "epoch": 7.693655019823101,
      "grad_norm": 4.835926055908203,
      "learning_rate": 1.1548327334321407e-05,
      "loss": 0.6347,
      "step": 726750
    },
    {
      "epoch": 7.694184341603104,
      "grad_norm": 4.549248218536377,
      "learning_rate": 1.154568071141224e-05,
      "loss": 0.6458,
      "step": 726800
    },
    {
      "epoch": 7.694713663383107,
      "grad_norm": 4.190348148345947,
      "learning_rate": 1.154303408850307e-05,
      "loss": 0.6649,
      "step": 726850
    },
    {
      "epoch": 7.695242985163111,
      "grad_norm": 4.3195343017578125,
      "learning_rate": 1.1540387465593902e-05,
      "loss": 0.6532,
      "step": 726900
    },
    {
      "epoch": 7.695772306943113,
      "grad_norm": 4.936217308044434,
      "learning_rate": 1.1537740842684735e-05,
      "loss": 0.6526,
      "step": 726950
    },
    {
      "epoch": 7.696301628723117,
      "grad_norm": 4.436634540557861,
      "learning_rate": 1.1535094219775566e-05,
      "loss": 0.6474,
      "step": 727000
    },
    {
      "epoch": 7.696301628723117,
      "eval_loss": 0.40110912919044495,
      "eval_runtime": 46.5383,
      "eval_samples_per_second": 3608.429,
      "eval_steps_per_second": 451.07,
      "step": 727000
    },
    {
      "epoch": 7.69683095050312,
      "grad_norm": 4.432004928588867,
      "learning_rate": 1.1532447596866398e-05,
      "loss": 0.6462,
      "step": 727050
    },
    {
      "epoch": 7.697360272283124,
      "grad_norm": 4.552070140838623,
      "learning_rate": 1.152980097395723e-05,
      "loss": 0.6452,
      "step": 727100
    },
    {
      "epoch": 7.697889594063127,
      "grad_norm": 4.386034965515137,
      "learning_rate": 1.1527154351048063e-05,
      "loss": 0.6394,
      "step": 727150
    },
    {
      "epoch": 7.69841891584313,
      "grad_norm": 4.256535053253174,
      "learning_rate": 1.1524507728138895e-05,
      "loss": 0.6456,
      "step": 727200
    },
    {
      "epoch": 7.698948237623133,
      "grad_norm": 4.205948352813721,
      "learning_rate": 1.1521861105229728e-05,
      "loss": 0.6494,
      "step": 727250
    },
    {
      "epoch": 7.699477559403137,
      "grad_norm": 4.168026447296143,
      "learning_rate": 1.1519214482320558e-05,
      "loss": 0.6479,
      "step": 727300
    },
    {
      "epoch": 7.70000688118314,
      "grad_norm": 4.370913505554199,
      "learning_rate": 1.151656785941139e-05,
      "loss": 0.6513,
      "step": 727350
    },
    {
      "epoch": 7.700536202963144,
      "grad_norm": 4.2432050704956055,
      "learning_rate": 1.1513921236502223e-05,
      "loss": 0.6434,
      "step": 727400
    },
    {
      "epoch": 7.7010655247431465,
      "grad_norm": 4.789263725280762,
      "learning_rate": 1.1511274613593056e-05,
      "loss": 0.6469,
      "step": 727450
    },
    {
      "epoch": 7.70159484652315,
      "grad_norm": 4.48989200592041,
      "learning_rate": 1.1508627990683888e-05,
      "loss": 0.6448,
      "step": 727500
    },
    {
      "epoch": 7.70159484652315,
      "eval_loss": 0.40096837282180786,
      "eval_runtime": 46.4387,
      "eval_samples_per_second": 3616.162,
      "eval_steps_per_second": 452.036,
      "step": 727500
    },
    {
      "epoch": 7.702124168303153,
      "grad_norm": 5.11953067779541,
      "learning_rate": 1.1505981367774719e-05,
      "loss": 0.6576,
      "step": 727550
    },
    {
      "epoch": 7.702653490083156,
      "grad_norm": 4.292018890380859,
      "learning_rate": 1.1503334744865551e-05,
      "loss": 0.6517,
      "step": 727600
    },
    {
      "epoch": 7.70318281186316,
      "grad_norm": 4.5079474449157715,
      "learning_rate": 1.1500688121956383e-05,
      "loss": 0.6489,
      "step": 727650
    },
    {
      "epoch": 7.703712133643163,
      "grad_norm": 4.704603672027588,
      "learning_rate": 1.1498041499047216e-05,
      "loss": 0.6479,
      "step": 727700
    },
    {
      "epoch": 7.704241455423166,
      "grad_norm": 4.358015537261963,
      "learning_rate": 1.1495394876138048e-05,
      "loss": 0.6481,
      "step": 727750
    },
    {
      "epoch": 7.704770777203169,
      "grad_norm": 4.356663227081299,
      "learning_rate": 1.149274825322888e-05,
      "loss": 0.6491,
      "step": 727800
    },
    {
      "epoch": 7.705300098983173,
      "grad_norm": 4.784771919250488,
      "learning_rate": 1.1490101630319711e-05,
      "loss": 0.6517,
      "step": 727850
    },
    {
      "epoch": 7.705829420763176,
      "grad_norm": 4.45345401763916,
      "learning_rate": 1.1487455007410544e-05,
      "loss": 0.6558,
      "step": 727900
    },
    {
      "epoch": 7.70635874254318,
      "grad_norm": 4.507017135620117,
      "learning_rate": 1.1484808384501376e-05,
      "loss": 0.6461,
      "step": 727950
    },
    {
      "epoch": 7.7068880643231825,
      "grad_norm": 4.586397647857666,
      "learning_rate": 1.1482161761592209e-05,
      "loss": 0.656,
      "step": 728000
    },
    {
      "epoch": 7.7068880643231825,
      "eval_loss": 0.40074411034584045,
      "eval_runtime": 46.5678,
      "eval_samples_per_second": 3606.14,
      "eval_steps_per_second": 450.784,
      "step": 728000
    },
    {
      "epoch": 7.707417386103186,
      "grad_norm": 4.867498397827148,
      "learning_rate": 1.1479515138683041e-05,
      "loss": 0.6425,
      "step": 728050
    },
    {
      "epoch": 7.707946707883189,
      "grad_norm": 4.803855895996094,
      "learning_rate": 1.1476868515773872e-05,
      "loss": 0.6593,
      "step": 728100
    },
    {
      "epoch": 7.708476029663193,
      "grad_norm": 4.241705417633057,
      "learning_rate": 1.1474221892864704e-05,
      "loss": 0.6474,
      "step": 728150
    },
    {
      "epoch": 7.709005351443196,
      "grad_norm": 4.446663856506348,
      "learning_rate": 1.1471575269955537e-05,
      "loss": 0.6476,
      "step": 728200
    },
    {
      "epoch": 7.7095346732231995,
      "grad_norm": 4.348166465759277,
      "learning_rate": 1.1468928647046369e-05,
      "loss": 0.6455,
      "step": 728250
    },
    {
      "epoch": 7.710063995003202,
      "grad_norm": 4.609140872955322,
      "learning_rate": 1.1466282024137201e-05,
      "loss": 0.6459,
      "step": 728300
    },
    {
      "epoch": 7.710593316783205,
      "grad_norm": 4.332355499267578,
      "learning_rate": 1.1463635401228034e-05,
      "loss": 0.6454,
      "step": 728350
    },
    {
      "epoch": 7.711122638563209,
      "grad_norm": 4.54604434967041,
      "learning_rate": 1.1460988778318864e-05,
      "loss": 0.6563,
      "step": 728400
    },
    {
      "epoch": 7.711651960343212,
      "grad_norm": 4.163042068481445,
      "learning_rate": 1.1458342155409697e-05,
      "loss": 0.6468,
      "step": 728450
    },
    {
      "epoch": 7.712181282123216,
      "grad_norm": 4.189495086669922,
      "learning_rate": 1.145569553250053e-05,
      "loss": 0.6565,
      "step": 728500
    },
    {
      "epoch": 7.712181282123216,
      "eval_loss": 0.4003998935222626,
      "eval_runtime": 46.5175,
      "eval_samples_per_second": 3610.042,
      "eval_steps_per_second": 451.271,
      "step": 728500
    },
    {
      "epoch": 7.7127106039032185,
      "grad_norm": 4.44979190826416,
      "learning_rate": 1.1453048909591362e-05,
      "loss": 0.6491,
      "step": 728550
    },
    {
      "epoch": 7.713239925683222,
      "grad_norm": 4.408789157867432,
      "learning_rate": 1.1450402286682194e-05,
      "loss": 0.6515,
      "step": 728600
    },
    {
      "epoch": 7.713769247463225,
      "grad_norm": 4.235576152801514,
      "learning_rate": 1.1447755663773027e-05,
      "loss": 0.6479,
      "step": 728650
    },
    {
      "epoch": 7.714298569243229,
      "grad_norm": 4.743830680847168,
      "learning_rate": 1.1445109040863857e-05,
      "loss": 0.6492,
      "step": 728700
    },
    {
      "epoch": 7.714827891023232,
      "grad_norm": 4.8182759284973145,
      "learning_rate": 1.144246241795469e-05,
      "loss": 0.6347,
      "step": 728750
    },
    {
      "epoch": 7.7153572128032355,
      "grad_norm": 4.4579949378967285,
      "learning_rate": 1.1439815795045522e-05,
      "loss": 0.6299,
      "step": 728800
    },
    {
      "epoch": 7.715886534583238,
      "grad_norm": 4.241678714752197,
      "learning_rate": 1.1437169172136354e-05,
      "loss": 0.6458,
      "step": 728850
    },
    {
      "epoch": 7.716415856363242,
      "grad_norm": 4.468997955322266,
      "learning_rate": 1.1434522549227187e-05,
      "loss": 0.6435,
      "step": 728900
    },
    {
      "epoch": 7.716945178143245,
      "grad_norm": 4.523150444030762,
      "learning_rate": 1.1431875926318018e-05,
      "loss": 0.6521,
      "step": 728950
    },
    {
      "epoch": 7.717474499923249,
      "grad_norm": 4.158222675323486,
      "learning_rate": 1.142922930340885e-05,
      "loss": 0.6529,
      "step": 729000
    },
    {
      "epoch": 7.717474499923249,
      "eval_loss": 0.4009505808353424,
      "eval_runtime": 46.468,
      "eval_samples_per_second": 3613.886,
      "eval_steps_per_second": 451.752,
      "step": 729000
    },
    {
      "epoch": 7.718003821703252,
      "grad_norm": 4.585809707641602,
      "learning_rate": 1.1426582680499682e-05,
      "loss": 0.6469,
      "step": 729050
    },
    {
      "epoch": 7.7185331434832545,
      "grad_norm": 4.47927713394165,
      "learning_rate": 1.1423936057590515e-05,
      "loss": 0.6433,
      "step": 729100
    },
    {
      "epoch": 7.719062465263258,
      "grad_norm": 4.539666175842285,
      "learning_rate": 1.1421289434681347e-05,
      "loss": 0.6571,
      "step": 729150
    },
    {
      "epoch": 7.719591787043261,
      "grad_norm": 4.4290618896484375,
      "learning_rate": 1.141864281177218e-05,
      "loss": 0.649,
      "step": 729200
    },
    {
      "epoch": 7.720121108823265,
      "grad_norm": 4.33682918548584,
      "learning_rate": 1.141599618886301e-05,
      "loss": 0.6525,
      "step": 729250
    },
    {
      "epoch": 7.720650430603268,
      "grad_norm": 4.633725166320801,
      "learning_rate": 1.1413349565953843e-05,
      "loss": 0.6409,
      "step": 729300
    },
    {
      "epoch": 7.7211797523832715,
      "grad_norm": 4.404451847076416,
      "learning_rate": 1.1410702943044675e-05,
      "loss": 0.655,
      "step": 729350
    },
    {
      "epoch": 7.721709074163274,
      "grad_norm": 4.5809245109558105,
      "learning_rate": 1.1408056320135508e-05,
      "loss": 0.6508,
      "step": 729400
    },
    {
      "epoch": 7.722238395943278,
      "grad_norm": 4.328451156616211,
      "learning_rate": 1.140540969722634e-05,
      "loss": 0.6487,
      "step": 729450
    },
    {
      "epoch": 7.722767717723281,
      "grad_norm": 4.904952526092529,
      "learning_rate": 1.1402763074317172e-05,
      "loss": 0.6444,
      "step": 729500
    },
    {
      "epoch": 7.722767717723281,
      "eval_loss": 0.4011171758174896,
      "eval_runtime": 46.5237,
      "eval_samples_per_second": 3609.56,
      "eval_steps_per_second": 451.211,
      "step": 729500
    },
    {
      "epoch": 7.723297039503285,
      "grad_norm": 4.37246036529541,
      "learning_rate": 1.1400116451408003e-05,
      "loss": 0.6486,
      "step": 729550
    },
    {
      "epoch": 7.723826361283288,
      "grad_norm": 4.8497514724731445,
      "learning_rate": 1.1397469828498835e-05,
      "loss": 0.6489,
      "step": 729600
    },
    {
      "epoch": 7.724355683063291,
      "grad_norm": 4.1930952072143555,
      "learning_rate": 1.1394823205589668e-05,
      "loss": 0.6521,
      "step": 729650
    },
    {
      "epoch": 7.724885004843294,
      "grad_norm": 4.347925186157227,
      "learning_rate": 1.13921765826805e-05,
      "loss": 0.64,
      "step": 729700
    },
    {
      "epoch": 7.725414326623298,
      "grad_norm": 4.830285549163818,
      "learning_rate": 1.1389529959771333e-05,
      "loss": 0.6512,
      "step": 729750
    },
    {
      "epoch": 7.725943648403301,
      "grad_norm": 4.136788845062256,
      "learning_rate": 1.1386883336862163e-05,
      "loss": 0.6348,
      "step": 729800
    },
    {
      "epoch": 7.726472970183304,
      "grad_norm": 4.483119010925293,
      "learning_rate": 1.1384236713952996e-05,
      "loss": 0.6424,
      "step": 729850
    },
    {
      "epoch": 7.7270022919633075,
      "grad_norm": 4.246616840362549,
      "learning_rate": 1.1381590091043828e-05,
      "loss": 0.6481,
      "step": 729900
    },
    {
      "epoch": 7.72753161374331,
      "grad_norm": 4.4429097175598145,
      "learning_rate": 1.1378996400592843e-05,
      "loss": 0.6557,
      "step": 729950
    },
    {
      "epoch": 7.728060935523314,
      "grad_norm": 4.535492897033691,
      "learning_rate": 1.1376349777683675e-05,
      "loss": 0.6441,
      "step": 730000
    },
    {
      "epoch": 7.728060935523314,
      "eval_loss": 0.40054985880851746,
      "eval_runtime": 46.4623,
      "eval_samples_per_second": 3614.327,
      "eval_steps_per_second": 451.807,
      "step": 730000
    },
    {
      "epoch": 7.728590257303317,
      "grad_norm": 4.270036220550537,
      "learning_rate": 1.1373703154774508e-05,
      "loss": 0.6498,
      "step": 730050
    },
    {
      "epoch": 7.729119579083321,
      "grad_norm": 4.943228721618652,
      "learning_rate": 1.137105653186534e-05,
      "loss": 0.6612,
      "step": 730100
    },
    {
      "epoch": 7.729648900863324,
      "grad_norm": 4.7303786277771,
      "learning_rate": 1.1368409908956173e-05,
      "loss": 0.6516,
      "step": 730150
    },
    {
      "epoch": 7.730178222643327,
      "grad_norm": 4.786175727844238,
      "learning_rate": 1.1365763286047005e-05,
      "loss": 0.65,
      "step": 730200
    },
    {
      "epoch": 7.73070754442333,
      "grad_norm": 4.662778854370117,
      "learning_rate": 1.1363116663137836e-05,
      "loss": 0.6402,
      "step": 730250
    },
    {
      "epoch": 7.731236866203334,
      "grad_norm": 4.41058349609375,
      "learning_rate": 1.1360470040228668e-05,
      "loss": 0.6405,
      "step": 730300
    },
    {
      "epoch": 7.731766187983337,
      "grad_norm": 4.362601280212402,
      "learning_rate": 1.13578234173195e-05,
      "loss": 0.6509,
      "step": 730350
    },
    {
      "epoch": 7.732295509763341,
      "grad_norm": 4.732583999633789,
      "learning_rate": 1.1355176794410333e-05,
      "loss": 0.6498,
      "step": 730400
    },
    {
      "epoch": 7.732824831543343,
      "grad_norm": 4.282180309295654,
      "learning_rate": 1.1352530171501165e-05,
      "loss": 0.6561,
      "step": 730450
    },
    {
      "epoch": 7.733354153323347,
      "grad_norm": 4.303581237792969,
      "learning_rate": 1.1349883548591998e-05,
      "loss": 0.6586,
      "step": 730500
    },
    {
      "epoch": 7.733354153323347,
      "eval_loss": 0.40072426199913025,
      "eval_runtime": 46.446,
      "eval_samples_per_second": 3615.598,
      "eval_steps_per_second": 451.966,
      "step": 730500
    },
    {
      "epoch": 7.73388347510335,
      "grad_norm": 4.580377101898193,
      "learning_rate": 1.1347236925682828e-05,
      "loss": 0.6504,
      "step": 730550
    },
    {
      "epoch": 7.734412796883353,
      "grad_norm": 4.601037502288818,
      "learning_rate": 1.134459030277366e-05,
      "loss": 0.6433,
      "step": 730600
    },
    {
      "epoch": 7.734942118663357,
      "grad_norm": 4.4847893714904785,
      "learning_rate": 1.1341943679864493e-05,
      "loss": 0.6373,
      "step": 730650
    },
    {
      "epoch": 7.7354714404433595,
      "grad_norm": 4.374200344085693,
      "learning_rate": 1.1339297056955326e-05,
      "loss": 0.6353,
      "step": 730700
    },
    {
      "epoch": 7.736000762223363,
      "grad_norm": 4.578707695007324,
      "learning_rate": 1.1336650434046158e-05,
      "loss": 0.6427,
      "step": 730750
    },
    {
      "epoch": 7.736530084003366,
      "grad_norm": 4.3502020835876465,
      "learning_rate": 1.1334003811136989e-05,
      "loss": 0.6525,
      "step": 730800
    },
    {
      "epoch": 7.73705940578337,
      "grad_norm": 4.327585220336914,
      "learning_rate": 1.1331357188227821e-05,
      "loss": 0.6407,
      "step": 730850
    },
    {
      "epoch": 7.737588727563373,
      "grad_norm": 4.429703712463379,
      "learning_rate": 1.1328710565318654e-05,
      "loss": 0.6432,
      "step": 730900
    },
    {
      "epoch": 7.7381180493433765,
      "grad_norm": 4.90479850769043,
      "learning_rate": 1.1326063942409486e-05,
      "loss": 0.6378,
      "step": 730950
    },
    {
      "epoch": 7.738647371123379,
      "grad_norm": 5.055133819580078,
      "learning_rate": 1.1323417319500318e-05,
      "loss": 0.6503,
      "step": 731000
    },
    {
      "epoch": 7.738647371123379,
      "eval_loss": 0.3996637761592865,
      "eval_runtime": 46.5609,
      "eval_samples_per_second": 3606.676,
      "eval_steps_per_second": 450.851,
      "step": 731000
    },
    {
      "epoch": 7.739176692903383,
      "grad_norm": 4.551886558532715,
      "learning_rate": 1.132077069659115e-05,
      "loss": 0.6453,
      "step": 731050
    },
    {
      "epoch": 7.739706014683386,
      "grad_norm": 4.344323635101318,
      "learning_rate": 1.1318124073681981e-05,
      "loss": 0.6441,
      "step": 731100
    },
    {
      "epoch": 7.74023533646339,
      "grad_norm": 4.0629377365112305,
      "learning_rate": 1.1315477450772814e-05,
      "loss": 0.6529,
      "step": 731150
    },
    {
      "epoch": 7.740764658243393,
      "grad_norm": 4.531136989593506,
      "learning_rate": 1.1312830827863646e-05,
      "loss": 0.6496,
      "step": 731200
    },
    {
      "epoch": 7.741293980023396,
      "grad_norm": 4.295387268066406,
      "learning_rate": 1.1310184204954479e-05,
      "loss": 0.6397,
      "step": 731250
    },
    {
      "epoch": 7.741823301803399,
      "grad_norm": 4.6194047927856445,
      "learning_rate": 1.1307537582045311e-05,
      "loss": 0.6555,
      "step": 731300
    },
    {
      "epoch": 7.742352623583402,
      "grad_norm": 4.679731845855713,
      "learning_rate": 1.1304890959136143e-05,
      "loss": 0.6511,
      "step": 731350
    },
    {
      "epoch": 7.742881945363406,
      "grad_norm": 4.146636486053467,
      "learning_rate": 1.1302244336226974e-05,
      "loss": 0.6511,
      "step": 731400
    },
    {
      "epoch": 7.743411267143409,
      "grad_norm": 4.820809364318848,
      "learning_rate": 1.1299597713317807e-05,
      "loss": 0.6672,
      "step": 731450
    },
    {
      "epoch": 7.7439405889234125,
      "grad_norm": 4.988690376281738,
      "learning_rate": 1.1296951090408639e-05,
      "loss": 0.6403,
      "step": 731500
    },
    {
      "epoch": 7.7439405889234125,
      "eval_loss": 0.3997231125831604,
      "eval_runtime": 46.5518,
      "eval_samples_per_second": 3607.383,
      "eval_steps_per_second": 450.939,
      "step": 731500
    },
    {
      "epoch": 7.744469910703415,
      "grad_norm": 4.589550495147705,
      "learning_rate": 1.1294304467499471e-05,
      "loss": 0.6423,
      "step": 731550
    },
    {
      "epoch": 7.744999232483419,
      "grad_norm": 4.396689414978027,
      "learning_rate": 1.1291657844590304e-05,
      "loss": 0.653,
      "step": 731600
    },
    {
      "epoch": 7.745528554263422,
      "grad_norm": 4.338563442230225,
      "learning_rate": 1.1289011221681135e-05,
      "loss": 0.6459,
      "step": 731650
    },
    {
      "epoch": 7.746057876043426,
      "grad_norm": 4.535841941833496,
      "learning_rate": 1.1286364598771967e-05,
      "loss": 0.6622,
      "step": 731700
    },
    {
      "epoch": 7.746587197823429,
      "grad_norm": 4.290308475494385,
      "learning_rate": 1.12837179758628e-05,
      "loss": 0.6376,
      "step": 731750
    },
    {
      "epoch": 7.747116519603432,
      "grad_norm": 4.515192985534668,
      "learning_rate": 1.1281071352953632e-05,
      "loss": 0.641,
      "step": 731800
    },
    {
      "epoch": 7.747645841383435,
      "grad_norm": 4.47885799407959,
      "learning_rate": 1.1278424730044464e-05,
      "loss": 0.6527,
      "step": 731850
    },
    {
      "epoch": 7.748175163163439,
      "grad_norm": 4.431216716766357,
      "learning_rate": 1.1275778107135297e-05,
      "loss": 0.6376,
      "step": 731900
    },
    {
      "epoch": 7.748704484943442,
      "grad_norm": 4.1529107093811035,
      "learning_rate": 1.1273131484226127e-05,
      "loss": 0.6488,
      "step": 731950
    },
    {
      "epoch": 7.749233806723446,
      "grad_norm": 4.61934232711792,
      "learning_rate": 1.1270537793775144e-05,
      "loss": 0.6543,
      "step": 732000
    },
    {
      "epoch": 7.749233806723446,
      "eval_loss": 0.3991369307041168,
      "eval_runtime": 46.4705,
      "eval_samples_per_second": 3613.69,
      "eval_steps_per_second": 451.727,
      "step": 732000
    },
    {
      "epoch": 7.7497631285034485,
      "grad_norm": 4.910224914550781,
      "learning_rate": 1.1267891170865976e-05,
      "loss": 0.6463,
      "step": 732050
    },
    {
      "epoch": 7.750292450283451,
      "grad_norm": 4.2332353591918945,
      "learning_rate": 1.1265244547956807e-05,
      "loss": 0.6493,
      "step": 732100
    },
    {
      "epoch": 7.750821772063455,
      "grad_norm": 5.101043701171875,
      "learning_rate": 1.126259792504764e-05,
      "loss": 0.6518,
      "step": 732150
    },
    {
      "epoch": 7.751351093843458,
      "grad_norm": 4.308145046234131,
      "learning_rate": 1.1259951302138472e-05,
      "loss": 0.632,
      "step": 732200
    },
    {
      "epoch": 7.751880415623462,
      "grad_norm": 4.316260814666748,
      "learning_rate": 1.1257304679229304e-05,
      "loss": 0.6476,
      "step": 732250
    },
    {
      "epoch": 7.752409737403465,
      "grad_norm": 4.463432788848877,
      "learning_rate": 1.1254658056320136e-05,
      "loss": 0.6496,
      "step": 732300
    },
    {
      "epoch": 7.752939059183468,
      "grad_norm": 4.582590579986572,
      "learning_rate": 1.1252011433410969e-05,
      "loss": 0.6515,
      "step": 732350
    },
    {
      "epoch": 7.753468380963471,
      "grad_norm": 4.703754425048828,
      "learning_rate": 1.12493648105018e-05,
      "loss": 0.6474,
      "step": 732400
    },
    {
      "epoch": 7.753997702743475,
      "grad_norm": 4.480945587158203,
      "learning_rate": 1.1246718187592632e-05,
      "loss": 0.6541,
      "step": 732450
    },
    {
      "epoch": 7.754527024523478,
      "grad_norm": 3.9879260063171387,
      "learning_rate": 1.1244071564683464e-05,
      "loss": 0.6467,
      "step": 732500
    },
    {
      "epoch": 7.754527024523478,
      "eval_loss": 0.4005478620529175,
      "eval_runtime": 46.511,
      "eval_samples_per_second": 3610.541,
      "eval_steps_per_second": 451.334,
      "step": 732500
    },
    {
      "epoch": 7.755056346303482,
      "grad_norm": 4.66574764251709,
      "learning_rate": 1.1241424941774297e-05,
      "loss": 0.6398,
      "step": 732550
    },
    {
      "epoch": 7.7555856680834845,
      "grad_norm": 3.9740514755249023,
      "learning_rate": 1.123877831886513e-05,
      "loss": 0.6457,
      "step": 732600
    },
    {
      "epoch": 7.756114989863488,
      "grad_norm": 5.224237442016602,
      "learning_rate": 1.123613169595596e-05,
      "loss": 0.6434,
      "step": 732650
    },
    {
      "epoch": 7.756644311643491,
      "grad_norm": 4.57188606262207,
      "learning_rate": 1.1233485073046792e-05,
      "loss": 0.6467,
      "step": 732700
    },
    {
      "epoch": 7.757173633423495,
      "grad_norm": 4.748239040374756,
      "learning_rate": 1.1230838450137625e-05,
      "loss": 0.6647,
      "step": 732750
    },
    {
      "epoch": 7.757702955203498,
      "grad_norm": 4.292887210845947,
      "learning_rate": 1.1228191827228457e-05,
      "loss": 0.6575,
      "step": 732800
    },
    {
      "epoch": 7.758232276983501,
      "grad_norm": 4.540156364440918,
      "learning_rate": 1.122554520431929e-05,
      "loss": 0.65,
      "step": 732850
    },
    {
      "epoch": 7.758761598763504,
      "grad_norm": 4.725287437438965,
      "learning_rate": 1.1222898581410122e-05,
      "loss": 0.6408,
      "step": 732900
    },
    {
      "epoch": 7.759290920543507,
      "grad_norm": 4.316227912902832,
      "learning_rate": 1.1220251958500953e-05,
      "loss": 0.635,
      "step": 732950
    },
    {
      "epoch": 7.759820242323511,
      "grad_norm": 4.549136638641357,
      "learning_rate": 1.1217605335591785e-05,
      "loss": 0.6564,
      "step": 733000
    },
    {
      "epoch": 7.759820242323511,
      "eval_loss": 0.3994382917881012,
      "eval_runtime": 46.5051,
      "eval_samples_per_second": 3610.999,
      "eval_steps_per_second": 451.391,
      "step": 733000
    },
    {
      "epoch": 7.760349564103514,
      "grad_norm": 4.330414772033691,
      "learning_rate": 1.1214958712682617e-05,
      "loss": 0.6458,
      "step": 733050
    },
    {
      "epoch": 7.760878885883518,
      "grad_norm": 4.371236324310303,
      "learning_rate": 1.121231208977345e-05,
      "loss": 0.6458,
      "step": 733100
    },
    {
      "epoch": 7.7614082076635205,
      "grad_norm": 4.564012050628662,
      "learning_rate": 1.1209665466864282e-05,
      "loss": 0.6486,
      "step": 733150
    },
    {
      "epoch": 7.761937529443524,
      "grad_norm": 4.408271312713623,
      "learning_rate": 1.1207018843955115e-05,
      "loss": 0.6432,
      "step": 733200
    },
    {
      "epoch": 7.762466851223527,
      "grad_norm": 4.677921772003174,
      "learning_rate": 1.1204372221045945e-05,
      "loss": 0.6469,
      "step": 733250
    },
    {
      "epoch": 7.762996173003531,
      "grad_norm": 4.896300315856934,
      "learning_rate": 1.1201725598136778e-05,
      "loss": 0.6479,
      "step": 733300
    },
    {
      "epoch": 7.763525494783534,
      "grad_norm": 4.426692008972168,
      "learning_rate": 1.119907897522761e-05,
      "loss": 0.6496,
      "step": 733350
    },
    {
      "epoch": 7.7640548165635375,
      "grad_norm": 4.837464809417725,
      "learning_rate": 1.1196432352318443e-05,
      "loss": 0.6504,
      "step": 733400
    },
    {
      "epoch": 7.76458413834354,
      "grad_norm": 4.53818941116333,
      "learning_rate": 1.1193785729409275e-05,
      "loss": 0.6513,
      "step": 733450
    },
    {
      "epoch": 7.765113460123544,
      "grad_norm": 4.429346561431885,
      "learning_rate": 1.1191139106500106e-05,
      "loss": 0.644,
      "step": 733500
    },
    {
      "epoch": 7.765113460123544,
      "eval_loss": 0.39922329783439636,
      "eval_runtime": 46.4527,
      "eval_samples_per_second": 3615.071,
      "eval_steps_per_second": 451.9,
      "step": 733500
    },
    {
      "epoch": 7.765642781903547,
      "grad_norm": 4.790093421936035,
      "learning_rate": 1.1188492483590938e-05,
      "loss": 0.6478,
      "step": 733550
    },
    {
      "epoch": 7.76617210368355,
      "grad_norm": 4.512053489685059,
      "learning_rate": 1.118584586068177e-05,
      "loss": 0.6522,
      "step": 733600
    },
    {
      "epoch": 7.766701425463554,
      "grad_norm": 4.366999626159668,
      "learning_rate": 1.1183199237772603e-05,
      "loss": 0.6567,
      "step": 733650
    },
    {
      "epoch": 7.767230747243556,
      "grad_norm": 4.8297295570373535,
      "learning_rate": 1.1180552614863435e-05,
      "loss": 0.6451,
      "step": 733700
    },
    {
      "epoch": 7.76776006902356,
      "grad_norm": 4.152075290679932,
      "learning_rate": 1.1177905991954268e-05,
      "loss": 0.6597,
      "step": 733750
    },
    {
      "epoch": 7.768289390803563,
      "grad_norm": 4.664076328277588,
      "learning_rate": 1.1175259369045098e-05,
      "loss": 0.6499,
      "step": 733800
    },
    {
      "epoch": 7.768818712583567,
      "grad_norm": 4.4115824699401855,
      "learning_rate": 1.117261274613593e-05,
      "loss": 0.6414,
      "step": 733850
    },
    {
      "epoch": 7.76934803436357,
      "grad_norm": 5.112705707550049,
      "learning_rate": 1.1169966123226763e-05,
      "loss": 0.6492,
      "step": 733900
    },
    {
      "epoch": 7.769877356143573,
      "grad_norm": 4.8043670654296875,
      "learning_rate": 1.1167319500317596e-05,
      "loss": 0.6492,
      "step": 733950
    },
    {
      "epoch": 7.770406677923576,
      "grad_norm": 4.652146339416504,
      "learning_rate": 1.116472580986661e-05,
      "loss": 0.6544,
      "step": 734000
    },
    {
      "epoch": 7.770406677923576,
      "eval_loss": 0.3991830348968506,
      "eval_runtime": 46.7357,
      "eval_samples_per_second": 3593.187,
      "eval_steps_per_second": 449.164,
      "step": 734000
    },
    {
      "epoch": 7.77093599970358,
      "grad_norm": 4.358958721160889,
      "learning_rate": 1.1162079186957443e-05,
      "loss": 0.6537,
      "step": 734050
    },
    {
      "epoch": 7.771465321483583,
      "grad_norm": 4.416471004486084,
      "learning_rate": 1.1159432564048275e-05,
      "loss": 0.6442,
      "step": 734100
    },
    {
      "epoch": 7.771994643263587,
      "grad_norm": 4.197319030761719,
      "learning_rate": 1.1156785941139108e-05,
      "loss": 0.6478,
      "step": 734150
    },
    {
      "epoch": 7.7725239650435896,
      "grad_norm": 4.358656883239746,
      "learning_rate": 1.115413931822994e-05,
      "loss": 0.6517,
      "step": 734200
    },
    {
      "epoch": 7.773053286823593,
      "grad_norm": 4.659609794616699,
      "learning_rate": 1.115149269532077e-05,
      "loss": 0.6426,
      "step": 734250
    },
    {
      "epoch": 7.773582608603596,
      "grad_norm": 4.6088714599609375,
      "learning_rate": 1.1148846072411603e-05,
      "loss": 0.6517,
      "step": 734300
    },
    {
      "epoch": 7.774111930383599,
      "grad_norm": 4.31687593460083,
      "learning_rate": 1.1146199449502436e-05,
      "loss": 0.6398,
      "step": 734350
    },
    {
      "epoch": 7.774641252163603,
      "grad_norm": 4.576987266540527,
      "learning_rate": 1.1143552826593268e-05,
      "loss": 0.6501,
      "step": 734400
    },
    {
      "epoch": 7.7751705739436066,
      "grad_norm": 4.372951507568359,
      "learning_rate": 1.11409062036841e-05,
      "loss": 0.652,
      "step": 734450
    },
    {
      "epoch": 7.775699895723609,
      "grad_norm": 4.386165618896484,
      "learning_rate": 1.1138259580774931e-05,
      "loss": 0.6405,
      "step": 734500
    },
    {
      "epoch": 7.775699895723609,
      "eval_loss": 0.39925479888916016,
      "eval_runtime": 46.5444,
      "eval_samples_per_second": 3607.953,
      "eval_steps_per_second": 451.01,
      "step": 734500
    },
    {
      "epoch": 7.776229217503612,
      "grad_norm": 5.038137912750244,
      "learning_rate": 1.1135612957865763e-05,
      "loss": 0.6316,
      "step": 734550
    },
    {
      "epoch": 7.776758539283616,
      "grad_norm": 4.287876129150391,
      "learning_rate": 1.1132966334956596e-05,
      "loss": 0.6477,
      "step": 734600
    },
    {
      "epoch": 7.777287861063619,
      "grad_norm": 4.609628200531006,
      "learning_rate": 1.1130319712047428e-05,
      "loss": 0.647,
      "step": 734650
    },
    {
      "epoch": 7.777817182843623,
      "grad_norm": 4.624373912811279,
      "learning_rate": 1.112767308913826e-05,
      "loss": 0.6601,
      "step": 734700
    },
    {
      "epoch": 7.7783465046236255,
      "grad_norm": 4.374030590057373,
      "learning_rate": 1.1125026466229093e-05,
      "loss": 0.6543,
      "step": 734750
    },
    {
      "epoch": 7.778875826403629,
      "grad_norm": 4.302947521209717,
      "learning_rate": 1.1122379843319924e-05,
      "loss": 0.6609,
      "step": 734800
    },
    {
      "epoch": 7.779405148183632,
      "grad_norm": 4.9411725997924805,
      "learning_rate": 1.1119733220410756e-05,
      "loss": 0.6543,
      "step": 734850
    },
    {
      "epoch": 7.779934469963636,
      "grad_norm": 4.505657196044922,
      "learning_rate": 1.1117086597501589e-05,
      "loss": 0.6515,
      "step": 734900
    },
    {
      "epoch": 7.780463791743639,
      "grad_norm": 4.392788887023926,
      "learning_rate": 1.1114439974592421e-05,
      "loss": 0.6449,
      "step": 734950
    },
    {
      "epoch": 7.7809931135236425,
      "grad_norm": 4.81533670425415,
      "learning_rate": 1.1111793351683253e-05,
      "loss": 0.6398,
      "step": 735000
    },
    {
      "epoch": 7.7809931135236425,
      "eval_loss": 0.39920008182525635,
      "eval_runtime": 46.5237,
      "eval_samples_per_second": 3609.561,
      "eval_steps_per_second": 451.211,
      "step": 735000
    },
    {
      "epoch": 7.781522435303645,
      "grad_norm": 4.6357808113098145,
      "learning_rate": 1.1109146728774086e-05,
      "loss": 0.6395,
      "step": 735050
    },
    {
      "epoch": 7.782051757083648,
      "grad_norm": 4.496922016143799,
      "learning_rate": 1.1106500105864917e-05,
      "loss": 0.6481,
      "step": 735100
    },
    {
      "epoch": 7.782581078863652,
      "grad_norm": 4.614643096923828,
      "learning_rate": 1.1103853482955749e-05,
      "loss": 0.6384,
      "step": 735150
    },
    {
      "epoch": 7.783110400643656,
      "grad_norm": 4.442168235778809,
      "learning_rate": 1.1101206860046581e-05,
      "loss": 0.6492,
      "step": 735200
    },
    {
      "epoch": 7.783639722423659,
      "grad_norm": 4.432689189910889,
      "learning_rate": 1.1098560237137414e-05,
      "loss": 0.6463,
      "step": 735250
    },
    {
      "epoch": 7.7841690442036615,
      "grad_norm": 4.4386138916015625,
      "learning_rate": 1.1095913614228246e-05,
      "loss": 0.6468,
      "step": 735300
    },
    {
      "epoch": 7.784698365983665,
      "grad_norm": 4.566677093505859,
      "learning_rate": 1.1093266991319077e-05,
      "loss": 0.6542,
      "step": 735350
    },
    {
      "epoch": 7.785227687763668,
      "grad_norm": 4.65214204788208,
      "learning_rate": 1.109062036840991e-05,
      "loss": 0.6569,
      "step": 735400
    },
    {
      "epoch": 7.785757009543672,
      "grad_norm": 4.438011169433594,
      "learning_rate": 1.1087973745500742e-05,
      "loss": 0.644,
      "step": 735450
    },
    {
      "epoch": 7.786286331323675,
      "grad_norm": 4.496860980987549,
      "learning_rate": 1.1085327122591574e-05,
      "loss": 0.6402,
      "step": 735500
    },
    {
      "epoch": 7.786286331323675,
      "eval_loss": 0.3992879390716553,
      "eval_runtime": 46.4801,
      "eval_samples_per_second": 3612.942,
      "eval_steps_per_second": 451.634,
      "step": 735500
    },
    {
      "epoch": 7.7868156531036785,
      "grad_norm": 4.6190924644470215,
      "learning_rate": 1.1082680499682406e-05,
      "loss": 0.6473,
      "step": 735550
    },
    {
      "epoch": 7.787344974883681,
      "grad_norm": 4.445422649383545,
      "learning_rate": 1.1080033876773239e-05,
      "loss": 0.6411,
      "step": 735600
    },
    {
      "epoch": 7.787874296663685,
      "grad_norm": 5.1828765869140625,
      "learning_rate": 1.107738725386407e-05,
      "loss": 0.6392,
      "step": 735650
    },
    {
      "epoch": 7.788403618443688,
      "grad_norm": 4.825401782989502,
      "learning_rate": 1.1074740630954902e-05,
      "loss": 0.6578,
      "step": 735700
    },
    {
      "epoch": 7.788932940223692,
      "grad_norm": 4.334106922149658,
      "learning_rate": 1.1072094008045734e-05,
      "loss": 0.6384,
      "step": 735750
    },
    {
      "epoch": 7.789462262003695,
      "grad_norm": 4.313022136688232,
      "learning_rate": 1.1069447385136567e-05,
      "loss": 0.6526,
      "step": 735800
    },
    {
      "epoch": 7.7899915837836975,
      "grad_norm": 4.39457893371582,
      "learning_rate": 1.10668007622274e-05,
      "loss": 0.6452,
      "step": 735850
    },
    {
      "epoch": 7.790520905563701,
      "grad_norm": 4.537950038909912,
      "learning_rate": 1.106415413931823e-05,
      "loss": 0.6454,
      "step": 735900
    },
    {
      "epoch": 7.791050227343705,
      "grad_norm": 3.9287760257720947,
      "learning_rate": 1.1061507516409062e-05,
      "loss": 0.6418,
      "step": 735950
    },
    {
      "epoch": 7.791579549123708,
      "grad_norm": 4.169711112976074,
      "learning_rate": 1.1058913825958079e-05,
      "loss": 0.6397,
      "step": 736000
    },
    {
      "epoch": 7.791579549123708,
      "eval_loss": 0.3990142345428467,
      "eval_runtime": 46.4466,
      "eval_samples_per_second": 3615.55,
      "eval_steps_per_second": 451.96,
      "step": 736000
    },
    {
      "epoch": 7.792108870903711,
      "grad_norm": 4.742587089538574,
      "learning_rate": 1.1056267203048911e-05,
      "loss": 0.643,
      "step": 736050
    },
    {
      "epoch": 7.7926381926837145,
      "grad_norm": 4.067421913146973,
      "learning_rate": 1.1053620580139742e-05,
      "loss": 0.6506,
      "step": 736100
    },
    {
      "epoch": 7.793167514463717,
      "grad_norm": 4.15580415725708,
      "learning_rate": 1.1050973957230574e-05,
      "loss": 0.6538,
      "step": 736150
    },
    {
      "epoch": 7.793696836243721,
      "grad_norm": 4.580121994018555,
      "learning_rate": 1.1048327334321407e-05,
      "loss": 0.6492,
      "step": 736200
    },
    {
      "epoch": 7.794226158023724,
      "grad_norm": 4.492088794708252,
      "learning_rate": 1.1045680711412239e-05,
      "loss": 0.6523,
      "step": 736250
    },
    {
      "epoch": 7.794755479803728,
      "grad_norm": 4.138548374176025,
      "learning_rate": 1.1043034088503071e-05,
      "loss": 0.6525,
      "step": 736300
    },
    {
      "epoch": 7.795284801583731,
      "grad_norm": 4.056946277618408,
      "learning_rate": 1.1040387465593902e-05,
      "loss": 0.6442,
      "step": 736350
    },
    {
      "epoch": 7.795814123363734,
      "grad_norm": 4.298401355743408,
      "learning_rate": 1.1037740842684735e-05,
      "loss": 0.6492,
      "step": 736400
    },
    {
      "epoch": 7.796343445143737,
      "grad_norm": 4.789492607116699,
      "learning_rate": 1.1035094219775567e-05,
      "loss": 0.6409,
      "step": 736450
    },
    {
      "epoch": 7.796872766923741,
      "grad_norm": 4.731864929199219,
      "learning_rate": 1.10324475968664e-05,
      "loss": 0.6453,
      "step": 736500
    },
    {
      "epoch": 7.796872766923741,
      "eval_loss": 0.39854830503463745,
      "eval_runtime": 46.4412,
      "eval_samples_per_second": 3615.972,
      "eval_steps_per_second": 452.013,
      "step": 736500
    },
    {
      "epoch": 7.797402088703744,
      "grad_norm": 4.8177080154418945,
      "learning_rate": 1.1029800973957232e-05,
      "loss": 0.6403,
      "step": 736550
    },
    {
      "epoch": 7.797931410483747,
      "grad_norm": 4.406572341918945,
      "learning_rate": 1.1027154351048064e-05,
      "loss": 0.6354,
      "step": 736600
    },
    {
      "epoch": 7.7984607322637505,
      "grad_norm": 4.596752643585205,
      "learning_rate": 1.1024507728138895e-05,
      "loss": 0.6518,
      "step": 736650
    },
    {
      "epoch": 7.798990054043754,
      "grad_norm": 4.488276481628418,
      "learning_rate": 1.1021861105229727e-05,
      "loss": 0.6504,
      "step": 736700
    },
    {
      "epoch": 7.799519375823757,
      "grad_norm": 4.024287223815918,
      "learning_rate": 1.101921448232056e-05,
      "loss": 0.6427,
      "step": 736750
    },
    {
      "epoch": 7.80004869760376,
      "grad_norm": 4.1933817863464355,
      "learning_rate": 1.1016567859411392e-05,
      "loss": 0.6446,
      "step": 736800
    },
    {
      "epoch": 7.800578019383764,
      "grad_norm": 4.38304328918457,
      "learning_rate": 1.1013921236502225e-05,
      "loss": 0.6415,
      "step": 736850
    },
    {
      "epoch": 7.801107341163767,
      "grad_norm": 4.531752586364746,
      "learning_rate": 1.1011274613593057e-05,
      "loss": 0.6398,
      "step": 736900
    },
    {
      "epoch": 7.80163666294377,
      "grad_norm": 4.696816921234131,
      "learning_rate": 1.1008627990683888e-05,
      "loss": 0.6544,
      "step": 736950
    },
    {
      "epoch": 7.802165984723773,
      "grad_norm": 4.438706398010254,
      "learning_rate": 1.100598136777472e-05,
      "loss": 0.6532,
      "step": 737000
    },
    {
      "epoch": 7.802165984723773,
      "eval_loss": 0.3983035981655121,
      "eval_runtime": 46.4537,
      "eval_samples_per_second": 3614.994,
      "eval_steps_per_second": 451.89,
      "step": 737000
    },
    {
      "epoch": 7.802695306503777,
      "grad_norm": 4.828229904174805,
      "learning_rate": 1.1003334744865552e-05,
      "loss": 0.6325,
      "step": 737050
    },
    {
      "epoch": 7.80322462828378,
      "grad_norm": 4.3469343185424805,
      "learning_rate": 1.1000688121956385e-05,
      "loss": 0.6506,
      "step": 737100
    },
    {
      "epoch": 7.803753950063784,
      "grad_norm": 4.527920246124268,
      "learning_rate": 1.0998041499047217e-05,
      "loss": 0.6403,
      "step": 737150
    },
    {
      "epoch": 7.8042832718437865,
      "grad_norm": 4.354729652404785,
      "learning_rate": 1.0995394876138048e-05,
      "loss": 0.6486,
      "step": 737200
    },
    {
      "epoch": 7.80481259362379,
      "grad_norm": 4.272806644439697,
      "learning_rate": 1.099274825322888e-05,
      "loss": 0.646,
      "step": 737250
    },
    {
      "epoch": 7.805341915403793,
      "grad_norm": 4.2617878913879395,
      "learning_rate": 1.0990101630319713e-05,
      "loss": 0.6447,
      "step": 737300
    },
    {
      "epoch": 7.805871237183796,
      "grad_norm": 4.496375560760498,
      "learning_rate": 1.0987455007410545e-05,
      "loss": 0.646,
      "step": 737350
    },
    {
      "epoch": 7.8064005589638,
      "grad_norm": 4.692385673522949,
      "learning_rate": 1.0984808384501378e-05,
      "loss": 0.6419,
      "step": 737400
    },
    {
      "epoch": 7.8069298807438035,
      "grad_norm": 4.867621898651123,
      "learning_rate": 1.098216176159221e-05,
      "loss": 0.6537,
      "step": 737450
    },
    {
      "epoch": 7.807459202523806,
      "grad_norm": 4.546609401702881,
      "learning_rate": 1.097951513868304e-05,
      "loss": 0.6505,
      "step": 737500
    },
    {
      "epoch": 7.807459202523806,
      "eval_loss": 0.3983539342880249,
      "eval_runtime": 46.4578,
      "eval_samples_per_second": 3614.675,
      "eval_steps_per_second": 451.851,
      "step": 737500
    },
    {
      "epoch": 7.807988524303809,
      "grad_norm": 4.500380516052246,
      "learning_rate": 1.0976868515773873e-05,
      "loss": 0.6558,
      "step": 737550
    },
    {
      "epoch": 7.808517846083813,
      "grad_norm": 4.88397216796875,
      "learning_rate": 1.0974221892864706e-05,
      "loss": 0.6591,
      "step": 737600
    },
    {
      "epoch": 7.809047167863816,
      "grad_norm": 4.419459342956543,
      "learning_rate": 1.0971575269955538e-05,
      "loss": 0.6543,
      "step": 737650
    },
    {
      "epoch": 7.80957648964382,
      "grad_norm": 4.299395561218262,
      "learning_rate": 1.096892864704637e-05,
      "loss": 0.6364,
      "step": 737700
    },
    {
      "epoch": 7.810105811423822,
      "grad_norm": 4.618208408355713,
      "learning_rate": 1.0966282024137201e-05,
      "loss": 0.6571,
      "step": 737750
    },
    {
      "epoch": 7.810635133203826,
      "grad_norm": 4.673107147216797,
      "learning_rate": 1.0963635401228033e-05,
      "loss": 0.6445,
      "step": 737800
    },
    {
      "epoch": 7.811164454983829,
      "grad_norm": 4.220853328704834,
      "learning_rate": 1.0960988778318866e-05,
      "loss": 0.6503,
      "step": 737850
    },
    {
      "epoch": 7.811693776763833,
      "grad_norm": 4.1474480628967285,
      "learning_rate": 1.0958342155409698e-05,
      "loss": 0.6402,
      "step": 737900
    },
    {
      "epoch": 7.812223098543836,
      "grad_norm": 4.866185665130615,
      "learning_rate": 1.095569553250053e-05,
      "loss": 0.6468,
      "step": 737950
    },
    {
      "epoch": 7.812752420323839,
      "grad_norm": 4.461359977722168,
      "learning_rate": 1.0953101842049545e-05,
      "loss": 0.6443,
      "step": 738000
    },
    {
      "epoch": 7.812752420323839,
      "eval_loss": 0.3988583981990814,
      "eval_runtime": 46.4718,
      "eval_samples_per_second": 3613.59,
      "eval_steps_per_second": 451.715,
      "step": 738000
    },
    {
      "epoch": 7.813281742103842,
      "grad_norm": 4.741209983825684,
      "learning_rate": 1.0950455219140378e-05,
      "loss": 0.6374,
      "step": 738050
    },
    {
      "epoch": 7.813811063883845,
      "grad_norm": 4.643937587738037,
      "learning_rate": 1.094780859623121e-05,
      "loss": 0.6546,
      "step": 738100
    },
    {
      "epoch": 7.814340385663849,
      "grad_norm": 4.405671119689941,
      "learning_rate": 1.0945161973322043e-05,
      "loss": 0.6515,
      "step": 738150
    },
    {
      "epoch": 7.814869707443853,
      "grad_norm": 5.023279190063477,
      "learning_rate": 1.0942515350412873e-05,
      "loss": 0.6466,
      "step": 738200
    },
    {
      "epoch": 7.8153990292238555,
      "grad_norm": 4.938608169555664,
      "learning_rate": 1.0939868727503706e-05,
      "loss": 0.637,
      "step": 738250
    },
    {
      "epoch": 7.815928351003858,
      "grad_norm": 4.486950397491455,
      "learning_rate": 1.0937222104594538e-05,
      "loss": 0.6506,
      "step": 738300
    },
    {
      "epoch": 7.816457672783862,
      "grad_norm": 4.643665790557861,
      "learning_rate": 1.093457548168537e-05,
      "loss": 0.6585,
      "step": 738350
    },
    {
      "epoch": 7.816986994563865,
      "grad_norm": 4.7259440422058105,
      "learning_rate": 1.0931928858776203e-05,
      "loss": 0.6503,
      "step": 738400
    },
    {
      "epoch": 7.817516316343869,
      "grad_norm": 4.237912178039551,
      "learning_rate": 1.0929282235867035e-05,
      "loss": 0.6565,
      "step": 738450
    },
    {
      "epoch": 7.818045638123872,
      "grad_norm": 4.7708659172058105,
      "learning_rate": 1.0926635612957866e-05,
      "loss": 0.647,
      "step": 738500
    },
    {
      "epoch": 7.818045638123872,
      "eval_loss": 0.3984353542327881,
      "eval_runtime": 46.4515,
      "eval_samples_per_second": 3615.165,
      "eval_steps_per_second": 451.912,
      "step": 738500
    },
    {
      "epoch": 7.818574959903875,
      "grad_norm": 4.397587776184082,
      "learning_rate": 1.0923988990048698e-05,
      "loss": 0.6513,
      "step": 738550
    },
    {
      "epoch": 7.819104281683878,
      "grad_norm": 4.545159339904785,
      "learning_rate": 1.0921342367139531e-05,
      "loss": 0.6457,
      "step": 738600
    },
    {
      "epoch": 7.819633603463882,
      "grad_norm": 4.845886707305908,
      "learning_rate": 1.0918695744230363e-05,
      "loss": 0.6412,
      "step": 738650
    },
    {
      "epoch": 7.820162925243885,
      "grad_norm": 4.305141925811768,
      "learning_rate": 1.0916049121321196e-05,
      "loss": 0.6571,
      "step": 738700
    },
    {
      "epoch": 7.820692247023889,
      "grad_norm": 4.535303115844727,
      "learning_rate": 1.0913402498412028e-05,
      "loss": 0.6649,
      "step": 738750
    },
    {
      "epoch": 7.8212215688038915,
      "grad_norm": 4.70034122467041,
      "learning_rate": 1.0910755875502859e-05,
      "loss": 0.6436,
      "step": 738800
    },
    {
      "epoch": 7.821750890583894,
      "grad_norm": 4.4255499839782715,
      "learning_rate": 1.0908109252593691e-05,
      "loss": 0.6423,
      "step": 738850
    },
    {
      "epoch": 7.822280212363898,
      "grad_norm": 4.534303665161133,
      "learning_rate": 1.0905462629684524e-05,
      "loss": 0.6536,
      "step": 738900
    },
    {
      "epoch": 7.822809534143902,
      "grad_norm": 4.585580825805664,
      "learning_rate": 1.0902816006775356e-05,
      "loss": 0.6514,
      "step": 738950
    },
    {
      "epoch": 7.823338855923905,
      "grad_norm": 4.587421894073486,
      "learning_rate": 1.0900169383866188e-05,
      "loss": 0.6548,
      "step": 739000
    },
    {
      "epoch": 7.823338855923905,
      "eval_loss": 0.39865046739578247,
      "eval_runtime": 46.5374,
      "eval_samples_per_second": 3608.494,
      "eval_steps_per_second": 451.078,
      "step": 739000
    },
    {
      "epoch": 7.823868177703908,
      "grad_norm": 4.542733669281006,
      "learning_rate": 1.0897522760957019e-05,
      "loss": 0.6489,
      "step": 739050
    },
    {
      "epoch": 7.824397499483911,
      "grad_norm": 3.8413853645324707,
      "learning_rate": 1.0894876138047852e-05,
      "loss": 0.6369,
      "step": 739100
    },
    {
      "epoch": 7.824926821263914,
      "grad_norm": 4.771429538726807,
      "learning_rate": 1.0892229515138684e-05,
      "loss": 0.6481,
      "step": 739150
    },
    {
      "epoch": 7.825456143043918,
      "grad_norm": 4.519561767578125,
      "learning_rate": 1.0889582892229516e-05,
      "loss": 0.6368,
      "step": 739200
    },
    {
      "epoch": 7.825985464823921,
      "grad_norm": 4.311563491821289,
      "learning_rate": 1.0886936269320349e-05,
      "loss": 0.6496,
      "step": 739250
    },
    {
      "epoch": 7.826514786603925,
      "grad_norm": 4.899841785430908,
      "learning_rate": 1.0884289646411181e-05,
      "loss": 0.6396,
      "step": 739300
    },
    {
      "epoch": 7.8270441083839275,
      "grad_norm": 4.288493633270264,
      "learning_rate": 1.0881643023502012e-05,
      "loss": 0.6365,
      "step": 739350
    },
    {
      "epoch": 7.827573430163931,
      "grad_norm": 4.499764442443848,
      "learning_rate": 1.0878996400592844e-05,
      "loss": 0.6373,
      "step": 739400
    },
    {
      "epoch": 7.828102751943934,
      "grad_norm": 4.3899946212768555,
      "learning_rate": 1.0876349777683677e-05,
      "loss": 0.6524,
      "step": 739450
    },
    {
      "epoch": 7.828632073723938,
      "grad_norm": 4.122263431549072,
      "learning_rate": 1.0873703154774509e-05,
      "loss": 0.6464,
      "step": 739500
    },
    {
      "epoch": 7.828632073723938,
      "eval_loss": 0.3978954255580902,
      "eval_runtime": 46.4267,
      "eval_samples_per_second": 3617.101,
      "eval_steps_per_second": 452.154,
      "step": 739500
    },
    {
      "epoch": 7.829161395503941,
      "grad_norm": 4.536602973937988,
      "learning_rate": 1.0871056531865342e-05,
      "loss": 0.6418,
      "step": 739550
    },
    {
      "epoch": 7.829690717283944,
      "grad_norm": 4.52144193649292,
      "learning_rate": 1.0868409908956172e-05,
      "loss": 0.6552,
      "step": 739600
    },
    {
      "epoch": 7.830220039063947,
      "grad_norm": 4.955184459686279,
      "learning_rate": 1.0865763286047005e-05,
      "loss": 0.6574,
      "step": 739650
    },
    {
      "epoch": 7.830749360843951,
      "grad_norm": 4.314061641693115,
      "learning_rate": 1.0863116663137837e-05,
      "loss": 0.659,
      "step": 739700
    },
    {
      "epoch": 7.831278682623954,
      "grad_norm": 4.505685806274414,
      "learning_rate": 1.086047004022867e-05,
      "loss": 0.6516,
      "step": 739750
    },
    {
      "epoch": 7.831808004403957,
      "grad_norm": 4.44919490814209,
      "learning_rate": 1.0857823417319502e-05,
      "loss": 0.6534,
      "step": 739800
    },
    {
      "epoch": 7.832337326183961,
      "grad_norm": 4.744191646575928,
      "learning_rate": 1.0855176794410334e-05,
      "loss": 0.6482,
      "step": 739850
    },
    {
      "epoch": 7.8328666479639635,
      "grad_norm": 4.863032817840576,
      "learning_rate": 1.0852530171501165e-05,
      "loss": 0.6526,
      "step": 739900
    },
    {
      "epoch": 7.833395969743967,
      "grad_norm": 4.614846229553223,
      "learning_rate": 1.0849883548591997e-05,
      "loss": 0.6385,
      "step": 739950
    },
    {
      "epoch": 7.83392529152397,
      "grad_norm": 4.910752296447754,
      "learning_rate": 1.0847289858141014e-05,
      "loss": 0.6485,
      "step": 740000
    },
    {
      "epoch": 7.83392529152397,
      "eval_loss": 0.3980187177658081,
      "eval_runtime": 46.4816,
      "eval_samples_per_second": 3612.825,
      "eval_steps_per_second": 451.619,
      "step": 740000
    },
    {
      "epoch": 7.834454613303974,
      "grad_norm": 4.529862403869629,
      "learning_rate": 1.0844643235231844e-05,
      "loss": 0.6347,
      "step": 740050
    },
    {
      "epoch": 7.834983935083977,
      "grad_norm": 4.238399505615234,
      "learning_rate": 1.0841996612322677e-05,
      "loss": 0.6407,
      "step": 740100
    },
    {
      "epoch": 7.8355132568639805,
      "grad_norm": 4.3247456550598145,
      "learning_rate": 1.083934998941351e-05,
      "loss": 0.6486,
      "step": 740150
    },
    {
      "epoch": 7.836042578643983,
      "grad_norm": 4.426802635192871,
      "learning_rate": 1.0836703366504342e-05,
      "loss": 0.6312,
      "step": 740200
    },
    {
      "epoch": 7.836571900423987,
      "grad_norm": 4.410665988922119,
      "learning_rate": 1.0834056743595174e-05,
      "loss": 0.6381,
      "step": 740250
    },
    {
      "epoch": 7.83710122220399,
      "grad_norm": 4.6622114181518555,
      "learning_rate": 1.0831410120686007e-05,
      "loss": 0.6576,
      "step": 740300
    },
    {
      "epoch": 7.837630543983993,
      "grad_norm": 4.090481758117676,
      "learning_rate": 1.0828763497776837e-05,
      "loss": 0.642,
      "step": 740350
    },
    {
      "epoch": 7.838159865763997,
      "grad_norm": 4.648036479949951,
      "learning_rate": 1.082611687486767e-05,
      "loss": 0.6583,
      "step": 740400
    },
    {
      "epoch": 7.838689187544,
      "grad_norm": 4.652462959289551,
      "learning_rate": 1.0823470251958502e-05,
      "loss": 0.6514,
      "step": 740450
    },
    {
      "epoch": 7.839218509324003,
      "grad_norm": 4.815632343292236,
      "learning_rate": 1.0820823629049334e-05,
      "loss": 0.6495,
      "step": 740500
    },
    {
      "epoch": 7.839218509324003,
      "eval_loss": 0.39820852875709534,
      "eval_runtime": 46.4572,
      "eval_samples_per_second": 3614.723,
      "eval_steps_per_second": 451.856,
      "step": 740500
    },
    {
      "epoch": 7.839747831104006,
      "grad_norm": 4.225620269775391,
      "learning_rate": 1.0818177006140167e-05,
      "loss": 0.6447,
      "step": 740550
    },
    {
      "epoch": 7.84027715288401,
      "grad_norm": 4.250772476196289,
      "learning_rate": 1.0815530383231e-05,
      "loss": 0.6375,
      "step": 740600
    },
    {
      "epoch": 7.840806474664013,
      "grad_norm": 3.9057512283325195,
      "learning_rate": 1.081288376032183e-05,
      "loss": 0.6453,
      "step": 740650
    },
    {
      "epoch": 7.8413357964440165,
      "grad_norm": 4.664137840270996,
      "learning_rate": 1.0810237137412662e-05,
      "loss": 0.6485,
      "step": 740700
    },
    {
      "epoch": 7.841865118224019,
      "grad_norm": 4.821988105773926,
      "learning_rate": 1.0807590514503495e-05,
      "loss": 0.6532,
      "step": 740750
    },
    {
      "epoch": 7.842394440004023,
      "grad_norm": 4.758753776550293,
      "learning_rate": 1.0804943891594327e-05,
      "loss": 0.6539,
      "step": 740800
    },
    {
      "epoch": 7.842923761784026,
      "grad_norm": 3.848022699356079,
      "learning_rate": 1.0802297268685158e-05,
      "loss": 0.6422,
      "step": 740850
    },
    {
      "epoch": 7.84345308356403,
      "grad_norm": 4.790976047515869,
      "learning_rate": 1.079965064577599e-05,
      "loss": 0.6496,
      "step": 740900
    },
    {
      "epoch": 7.843982405344033,
      "grad_norm": 4.494446277618408,
      "learning_rate": 1.0797004022866821e-05,
      "loss": 0.6482,
      "step": 740950
    },
    {
      "epoch": 7.844511727124036,
      "grad_norm": 4.527462959289551,
      "learning_rate": 1.0794357399957653e-05,
      "loss": 0.6469,
      "step": 741000
    },
    {
      "epoch": 7.844511727124036,
      "eval_loss": 0.3975706100463867,
      "eval_runtime": 46.4974,
      "eval_samples_per_second": 3611.601,
      "eval_steps_per_second": 451.466,
      "step": 741000
    },
    {
      "epoch": 7.845041048904039,
      "grad_norm": 4.352112293243408,
      "learning_rate": 1.0791710777048486e-05,
      "loss": 0.6439,
      "step": 741050
    },
    {
      "epoch": 7.845570370684042,
      "grad_norm": 4.74495267868042,
      "learning_rate": 1.0789064154139318e-05,
      "loss": 0.6579,
      "step": 741100
    },
    {
      "epoch": 7.846099692464046,
      "grad_norm": 4.471790313720703,
      "learning_rate": 1.078641753123015e-05,
      "loss": 0.6437,
      "step": 741150
    },
    {
      "epoch": 7.84662901424405,
      "grad_norm": 5.1661376953125,
      "learning_rate": 1.0783770908320983e-05,
      "loss": 0.6541,
      "step": 741200
    },
    {
      "epoch": 7.847158336024052,
      "grad_norm": 4.709575653076172,
      "learning_rate": 1.0781124285411814e-05,
      "loss": 0.6616,
      "step": 741250
    },
    {
      "epoch": 7.847687657804055,
      "grad_norm": 4.504710674285889,
      "learning_rate": 1.0778477662502646e-05,
      "loss": 0.6474,
      "step": 741300
    },
    {
      "epoch": 7.848216979584059,
      "grad_norm": 4.507735729217529,
      "learning_rate": 1.0775831039593479e-05,
      "loss": 0.6506,
      "step": 741350
    },
    {
      "epoch": 7.848746301364062,
      "grad_norm": 4.680394649505615,
      "learning_rate": 1.0773184416684311e-05,
      "loss": 0.6439,
      "step": 741400
    },
    {
      "epoch": 7.849275623144066,
      "grad_norm": 4.460469722747803,
      "learning_rate": 1.0770537793775143e-05,
      "loss": 0.6492,
      "step": 741450
    },
    {
      "epoch": 7.8498049449240686,
      "grad_norm": 4.62797737121582,
      "learning_rate": 1.0767891170865974e-05,
      "loss": 0.6556,
      "step": 741500
    },
    {
      "epoch": 7.8498049449240686,
      "eval_loss": 0.39818432927131653,
      "eval_runtime": 46.4782,
      "eval_samples_per_second": 3613.088,
      "eval_steps_per_second": 451.652,
      "step": 741500
    },
    {
      "epoch": 7.850334266704072,
      "grad_norm": 4.621323585510254,
      "learning_rate": 1.0765244547956807e-05,
      "loss": 0.6438,
      "step": 741550
    },
    {
      "epoch": 7.850863588484075,
      "grad_norm": 3.978219509124756,
      "learning_rate": 1.0762597925047639e-05,
      "loss": 0.6388,
      "step": 741600
    },
    {
      "epoch": 7.851392910264079,
      "grad_norm": 4.916914463043213,
      "learning_rate": 1.0759951302138471e-05,
      "loss": 0.6514,
      "step": 741650
    },
    {
      "epoch": 7.851922232044082,
      "grad_norm": 4.062695503234863,
      "learning_rate": 1.0757304679229304e-05,
      "loss": 0.6393,
      "step": 741700
    },
    {
      "epoch": 7.8524515538240856,
      "grad_norm": 4.609070301055908,
      "learning_rate": 1.0754658056320136e-05,
      "loss": 0.6497,
      "step": 741750
    },
    {
      "epoch": 7.852980875604088,
      "grad_norm": 4.233199596405029,
      "learning_rate": 1.0752011433410967e-05,
      "loss": 0.6454,
      "step": 741800
    },
    {
      "epoch": 7.853510197384091,
      "grad_norm": 4.51969575881958,
      "learning_rate": 1.07493648105018e-05,
      "loss": 0.6433,
      "step": 741850
    },
    {
      "epoch": 7.854039519164095,
      "grad_norm": 4.7449846267700195,
      "learning_rate": 1.0746718187592632e-05,
      "loss": 0.6378,
      "step": 741900
    },
    {
      "epoch": 7.854568840944099,
      "grad_norm": 4.5033278465271,
      "learning_rate": 1.0744071564683464e-05,
      "loss": 0.6409,
      "step": 741950
    },
    {
      "epoch": 7.855098162724102,
      "grad_norm": 4.7710747718811035,
      "learning_rate": 1.0741477874232479e-05,
      "loss": 0.6503,
      "step": 742000
    },
    {
      "epoch": 7.855098162724102,
      "eval_loss": 0.3976791799068451,
      "eval_runtime": 46.4538,
      "eval_samples_per_second": 3614.991,
      "eval_steps_per_second": 451.89,
      "step": 742000
    },
    {
      "epoch": 7.8556274845041045,
      "grad_norm": 4.7157487869262695,
      "learning_rate": 1.0738831251323311e-05,
      "loss": 0.6391,
      "step": 742050
    },
    {
      "epoch": 7.856156806284108,
      "grad_norm": 4.486880302429199,
      "learning_rate": 1.0736184628414144e-05,
      "loss": 0.6413,
      "step": 742100
    },
    {
      "epoch": 7.856686128064111,
      "grad_norm": 4.764369964599609,
      "learning_rate": 1.0733538005504976e-05,
      "loss": 0.643,
      "step": 742150
    },
    {
      "epoch": 7.857215449844115,
      "grad_norm": 4.8871989250183105,
      "learning_rate": 1.0730891382595808e-05,
      "loss": 0.6627,
      "step": 742200
    },
    {
      "epoch": 7.857744771624118,
      "grad_norm": 4.023449897766113,
      "learning_rate": 1.0728244759686639e-05,
      "loss": 0.6501,
      "step": 742250
    },
    {
      "epoch": 7.8582740934041215,
      "grad_norm": 4.677505970001221,
      "learning_rate": 1.0725598136777472e-05,
      "loss": 0.6388,
      "step": 742300
    },
    {
      "epoch": 7.858803415184124,
      "grad_norm": 5.205766201019287,
      "learning_rate": 1.0722951513868304e-05,
      "loss": 0.6506,
      "step": 742350
    },
    {
      "epoch": 7.859332736964128,
      "grad_norm": 4.541924953460693,
      "learning_rate": 1.0720304890959136e-05,
      "loss": 0.6366,
      "step": 742400
    },
    {
      "epoch": 7.859862058744131,
      "grad_norm": 4.684950351715088,
      "learning_rate": 1.0717658268049969e-05,
      "loss": 0.6387,
      "step": 742450
    },
    {
      "epoch": 7.860391380524135,
      "grad_norm": 4.484522819519043,
      "learning_rate": 1.0715011645140801e-05,
      "loss": 0.6555,
      "step": 742500
    },
    {
      "epoch": 7.860391380524135,
      "eval_loss": 0.3983057141304016,
      "eval_runtime": 46.5207,
      "eval_samples_per_second": 3609.793,
      "eval_steps_per_second": 451.24,
      "step": 742500
    },
    {
      "epoch": 7.860920702304138,
      "grad_norm": 4.476616859436035,
      "learning_rate": 1.0712365022231632e-05,
      "loss": 0.6382,
      "step": 742550
    },
    {
      "epoch": 7.8614500240841405,
      "grad_norm": 4.543566703796387,
      "learning_rate": 1.0709718399322464e-05,
      "loss": 0.6368,
      "step": 742600
    },
    {
      "epoch": 7.861979345864144,
      "grad_norm": 4.562584400177002,
      "learning_rate": 1.0707071776413297e-05,
      "loss": 0.6379,
      "step": 742650
    },
    {
      "epoch": 7.862508667644148,
      "grad_norm": 4.0921101570129395,
      "learning_rate": 1.0704425153504129e-05,
      "loss": 0.6467,
      "step": 742700
    },
    {
      "epoch": 7.863037989424151,
      "grad_norm": 4.876901626586914,
      "learning_rate": 1.0701778530594961e-05,
      "loss": 0.6575,
      "step": 742750
    },
    {
      "epoch": 7.863567311204154,
      "grad_norm": 4.453163146972656,
      "learning_rate": 1.0699131907685792e-05,
      "loss": 0.6433,
      "step": 742800
    },
    {
      "epoch": 7.8640966329841575,
      "grad_norm": 4.404590606689453,
      "learning_rate": 1.0696485284776625e-05,
      "loss": 0.6558,
      "step": 742850
    },
    {
      "epoch": 7.86462595476416,
      "grad_norm": 4.739239692687988,
      "learning_rate": 1.0693838661867457e-05,
      "loss": 0.6463,
      "step": 742900
    },
    {
      "epoch": 7.865155276544164,
      "grad_norm": 4.129497528076172,
      "learning_rate": 1.069119203895829e-05,
      "loss": 0.6327,
      "step": 742950
    },
    {
      "epoch": 7.865684598324167,
      "grad_norm": 4.139290809631348,
      "learning_rate": 1.0688545416049122e-05,
      "loss": 0.6427,
      "step": 743000
    },
    {
      "epoch": 7.865684598324167,
      "eval_loss": 0.3984718322753906,
      "eval_runtime": 46.4952,
      "eval_samples_per_second": 3611.774,
      "eval_steps_per_second": 451.488,
      "step": 743000
    },
    {
      "epoch": 7.866213920104171,
      "grad_norm": 4.238523483276367,
      "learning_rate": 1.0685898793139954e-05,
      "loss": 0.6537,
      "step": 743050
    },
    {
      "epoch": 7.866743241884174,
      "grad_norm": 4.5663957595825195,
      "learning_rate": 1.0683252170230785e-05,
      "loss": 0.6435,
      "step": 743100
    },
    {
      "epoch": 7.867272563664177,
      "grad_norm": 4.78817081451416,
      "learning_rate": 1.0680605547321617e-05,
      "loss": 0.6518,
      "step": 743150
    },
    {
      "epoch": 7.86780188544418,
      "grad_norm": 4.051398277282715,
      "learning_rate": 1.067795892441245e-05,
      "loss": 0.6478,
      "step": 743200
    },
    {
      "epoch": 7.868331207224184,
      "grad_norm": 3.956346035003662,
      "learning_rate": 1.0675312301503282e-05,
      "loss": 0.641,
      "step": 743250
    },
    {
      "epoch": 7.868860529004187,
      "grad_norm": 4.327293872833252,
      "learning_rate": 1.0672665678594115e-05,
      "loss": 0.6398,
      "step": 743300
    },
    {
      "epoch": 7.86938985078419,
      "grad_norm": 4.737711429595947,
      "learning_rate": 1.0670019055684945e-05,
      "loss": 0.6245,
      "step": 743350
    },
    {
      "epoch": 7.8699191725641935,
      "grad_norm": 5.1194305419921875,
      "learning_rate": 1.0667372432775778e-05,
      "loss": 0.6448,
      "step": 743400
    },
    {
      "epoch": 7.870448494344197,
      "grad_norm": 4.4960246086120605,
      "learning_rate": 1.066472580986661e-05,
      "loss": 0.6549,
      "step": 743450
    },
    {
      "epoch": 7.8709778161242,
      "grad_norm": 4.692948341369629,
      "learning_rate": 1.0662079186957442e-05,
      "loss": 0.6509,
      "step": 743500
    },
    {
      "epoch": 7.8709778161242,
      "eval_loss": 0.3980135917663574,
      "eval_runtime": 46.4488,
      "eval_samples_per_second": 3615.382,
      "eval_steps_per_second": 451.939,
      "step": 743500
    },
    {
      "epoch": 7.871507137904203,
      "grad_norm": 4.715028762817383,
      "learning_rate": 1.0659432564048275e-05,
      "loss": 0.6707,
      "step": 743550
    },
    {
      "epoch": 7.872036459684207,
      "grad_norm": 4.577558517456055,
      "learning_rate": 1.0656785941139107e-05,
      "loss": 0.6357,
      "step": 743600
    },
    {
      "epoch": 7.87256578146421,
      "grad_norm": 4.783077716827393,
      "learning_rate": 1.0654139318229938e-05,
      "loss": 0.6455,
      "step": 743650
    },
    {
      "epoch": 7.873095103244213,
      "grad_norm": 4.299680709838867,
      "learning_rate": 1.065149269532077e-05,
      "loss": 0.6447,
      "step": 743700
    },
    {
      "epoch": 7.873624425024216,
      "grad_norm": 4.469051361083984,
      "learning_rate": 1.0648846072411603e-05,
      "loss": 0.6365,
      "step": 743750
    },
    {
      "epoch": 7.87415374680422,
      "grad_norm": 4.61977481842041,
      "learning_rate": 1.0646199449502435e-05,
      "loss": 0.6537,
      "step": 743800
    },
    {
      "epoch": 7.874683068584223,
      "grad_norm": 4.386186122894287,
      "learning_rate": 1.0643552826593268e-05,
      "loss": 0.6471,
      "step": 743850
    },
    {
      "epoch": 7.875212390364227,
      "grad_norm": 5.118495941162109,
      "learning_rate": 1.06409062036841e-05,
      "loss": 0.6502,
      "step": 743900
    },
    {
      "epoch": 7.8757417121442295,
      "grad_norm": 4.438897132873535,
      "learning_rate": 1.063825958077493e-05,
      "loss": 0.6391,
      "step": 743950
    },
    {
      "epoch": 7.876271033924233,
      "grad_norm": 4.533474445343018,
      "learning_rate": 1.0635665890323947e-05,
      "loss": 0.6472,
      "step": 744000
    },
    {
      "epoch": 7.876271033924233,
      "eval_loss": 0.397884726524353,
      "eval_runtime": 46.4555,
      "eval_samples_per_second": 3614.858,
      "eval_steps_per_second": 451.873,
      "step": 744000
    },
    {
      "epoch": 7.876800355704236,
      "grad_norm": 4.686819076538086,
      "learning_rate": 1.063301926741478e-05,
      "loss": 0.6503,
      "step": 744050
    },
    {
      "epoch": 7.877329677484239,
      "grad_norm": 4.484126567840576,
      "learning_rate": 1.063037264450561e-05,
      "loss": 0.6456,
      "step": 744100
    },
    {
      "epoch": 7.877858999264243,
      "grad_norm": 4.516653060913086,
      "learning_rate": 1.0627726021596443e-05,
      "loss": 0.6485,
      "step": 744150
    },
    {
      "epoch": 7.8783883210442465,
      "grad_norm": 4.626537799835205,
      "learning_rate": 1.0625079398687275e-05,
      "loss": 0.6463,
      "step": 744200
    },
    {
      "epoch": 7.878917642824249,
      "grad_norm": 4.869265556335449,
      "learning_rate": 1.0622432775778107e-05,
      "loss": 0.6432,
      "step": 744250
    },
    {
      "epoch": 7.879446964604252,
      "grad_norm": 4.566711902618408,
      "learning_rate": 1.061978615286894e-05,
      "loss": 0.6396,
      "step": 744300
    },
    {
      "epoch": 7.879976286384256,
      "grad_norm": 4.391150951385498,
      "learning_rate": 1.0617139529959772e-05,
      "loss": 0.6522,
      "step": 744350
    },
    {
      "epoch": 7.880505608164259,
      "grad_norm": 4.754738807678223,
      "learning_rate": 1.0614492907050603e-05,
      "loss": 0.6396,
      "step": 744400
    },
    {
      "epoch": 7.881034929944263,
      "grad_norm": 4.718864440917969,
      "learning_rate": 1.0611846284141435e-05,
      "loss": 0.6583,
      "step": 744450
    },
    {
      "epoch": 7.8815642517242654,
      "grad_norm": 4.995343208312988,
      "learning_rate": 1.0609199661232268e-05,
      "loss": 0.6427,
      "step": 744500
    },
    {
      "epoch": 7.8815642517242654,
      "eval_loss": 0.39767810702323914,
      "eval_runtime": 46.4516,
      "eval_samples_per_second": 3615.157,
      "eval_steps_per_second": 451.911,
      "step": 744500
    },
    {
      "epoch": 7.882093573504269,
      "grad_norm": 4.417433738708496,
      "learning_rate": 1.06065530383231e-05,
      "loss": 0.6521,
      "step": 744550
    },
    {
      "epoch": 7.882622895284272,
      "grad_norm": 4.620133876800537,
      "learning_rate": 1.0603906415413933e-05,
      "loss": 0.6419,
      "step": 744600
    },
    {
      "epoch": 7.883152217064276,
      "grad_norm": 4.443198204040527,
      "learning_rate": 1.0601259792504763e-05,
      "loss": 0.6385,
      "step": 744650
    },
    {
      "epoch": 7.883681538844279,
      "grad_norm": 4.231073379516602,
      "learning_rate": 1.0598613169595596e-05,
      "loss": 0.6397,
      "step": 744700
    },
    {
      "epoch": 7.8842108606242824,
      "grad_norm": 4.334615707397461,
      "learning_rate": 1.0595966546686428e-05,
      "loss": 0.6508,
      "step": 744750
    },
    {
      "epoch": 7.884740182404285,
      "grad_norm": 4.8070759773254395,
      "learning_rate": 1.059331992377726e-05,
      "loss": 0.6612,
      "step": 744800
    },
    {
      "epoch": 7.885269504184288,
      "grad_norm": 4.223409652709961,
      "learning_rate": 1.0590673300868093e-05,
      "loss": 0.6497,
      "step": 744850
    },
    {
      "epoch": 7.885798825964292,
      "grad_norm": 4.262160301208496,
      "learning_rate": 1.0588026677958925e-05,
      "loss": 0.6398,
      "step": 744900
    },
    {
      "epoch": 7.886328147744296,
      "grad_norm": 4.757502555847168,
      "learning_rate": 1.0585380055049756e-05,
      "loss": 0.6349,
      "step": 744950
    },
    {
      "epoch": 7.886857469524299,
      "grad_norm": 4.716972827911377,
      "learning_rate": 1.0582733432140588e-05,
      "loss": 0.662,
      "step": 745000
    },
    {
      "epoch": 7.886857469524299,
      "eval_loss": 0.396783709526062,
      "eval_runtime": 46.4583,
      "eval_samples_per_second": 3614.637,
      "eval_steps_per_second": 451.846,
      "step": 745000
    },
    {
      "epoch": 7.887386791304301,
      "grad_norm": 4.625892162322998,
      "learning_rate": 1.0580086809231421e-05,
      "loss": 0.6428,
      "step": 745050
    },
    {
      "epoch": 7.887916113084305,
      "grad_norm": 4.286265850067139,
      "learning_rate": 1.0577440186322253e-05,
      "loss": 0.6469,
      "step": 745100
    },
    {
      "epoch": 7.888445434864308,
      "grad_norm": 4.788952350616455,
      "learning_rate": 1.0574793563413086e-05,
      "loss": 0.6584,
      "step": 745150
    },
    {
      "epoch": 7.888974756644312,
      "grad_norm": 4.75255012512207,
      "learning_rate": 1.0572146940503916e-05,
      "loss": 0.6513,
      "step": 745200
    },
    {
      "epoch": 7.889504078424315,
      "grad_norm": 4.417269706726074,
      "learning_rate": 1.0569500317594749e-05,
      "loss": 0.6552,
      "step": 745250
    },
    {
      "epoch": 7.890033400204318,
      "grad_norm": 4.23809289932251,
      "learning_rate": 1.0566853694685581e-05,
      "loss": 0.6385,
      "step": 745300
    },
    {
      "epoch": 7.890562721984321,
      "grad_norm": 4.5113677978515625,
      "learning_rate": 1.0564207071776414e-05,
      "loss": 0.6443,
      "step": 745350
    },
    {
      "epoch": 7.891092043764325,
      "grad_norm": 4.322818279266357,
      "learning_rate": 1.0561560448867246e-05,
      "loss": 0.6448,
      "step": 745400
    },
    {
      "epoch": 7.891621365544328,
      "grad_norm": 4.171721935272217,
      "learning_rate": 1.0558913825958078e-05,
      "loss": 0.6448,
      "step": 745450
    },
    {
      "epoch": 7.892150687324332,
      "grad_norm": 4.88900899887085,
      "learning_rate": 1.0556267203048909e-05,
      "loss": 0.6473,
      "step": 745500
    },
    {
      "epoch": 7.892150687324332,
      "eval_loss": 0.3966043293476105,
      "eval_runtime": 46.4882,
      "eval_samples_per_second": 3612.318,
      "eval_steps_per_second": 451.556,
      "step": 745500
    },
    {
      "epoch": 7.8926800091043345,
      "grad_norm": 4.45735502243042,
      "learning_rate": 1.0553620580139742e-05,
      "loss": 0.6479,
      "step": 745550
    },
    {
      "epoch": 7.893209330884337,
      "grad_norm": 4.350701808929443,
      "learning_rate": 1.0550973957230574e-05,
      "loss": 0.6494,
      "step": 745600
    },
    {
      "epoch": 7.893738652664341,
      "grad_norm": 4.705628395080566,
      "learning_rate": 1.0548327334321406e-05,
      "loss": 0.6376,
      "step": 745650
    },
    {
      "epoch": 7.894267974444345,
      "grad_norm": 4.662216663360596,
      "learning_rate": 1.0545680711412239e-05,
      "loss": 0.6469,
      "step": 745700
    },
    {
      "epoch": 7.894797296224348,
      "grad_norm": 4.717799663543701,
      "learning_rate": 1.0543034088503071e-05,
      "loss": 0.6411,
      "step": 745750
    },
    {
      "epoch": 7.895326618004351,
      "grad_norm": 4.080052375793457,
      "learning_rate": 1.0540387465593902e-05,
      "loss": 0.6433,
      "step": 745800
    },
    {
      "epoch": 7.895855939784354,
      "grad_norm": 4.697121620178223,
      "learning_rate": 1.0537740842684734e-05,
      "loss": 0.633,
      "step": 745850
    },
    {
      "epoch": 7.896385261564357,
      "grad_norm": 4.305059909820557,
      "learning_rate": 1.0535094219775567e-05,
      "loss": 0.6494,
      "step": 745900
    },
    {
      "epoch": 7.896914583344361,
      "grad_norm": 3.9366722106933594,
      "learning_rate": 1.0532447596866399e-05,
      "loss": 0.6546,
      "step": 745950
    },
    {
      "epoch": 7.897443905124364,
      "grad_norm": 4.218451499938965,
      "learning_rate": 1.0529853906415414e-05,
      "loss": 0.6425,
      "step": 746000
    },
    {
      "epoch": 7.897443905124364,
      "eval_loss": 0.3972145617008209,
      "eval_runtime": 46.4861,
      "eval_samples_per_second": 3612.476,
      "eval_steps_per_second": 451.576,
      "step": 746000
    },
    {
      "epoch": 7.897973226904368,
      "grad_norm": 4.683299541473389,
      "learning_rate": 1.052726021596443e-05,
      "loss": 0.6532,
      "step": 746050
    },
    {
      "epoch": 7.8985025486843705,
      "grad_norm": 4.2536749839782715,
      "learning_rate": 1.0524613593055261e-05,
      "loss": 0.6337,
      "step": 746100
    },
    {
      "epoch": 7.899031870464374,
      "grad_norm": 4.652885437011719,
      "learning_rate": 1.0521966970146093e-05,
      "loss": 0.6508,
      "step": 746150
    },
    {
      "epoch": 7.899561192244377,
      "grad_norm": 4.684880256652832,
      "learning_rate": 1.0519320347236926e-05,
      "loss": 0.6492,
      "step": 746200
    },
    {
      "epoch": 7.900090514024381,
      "grad_norm": 4.611245155334473,
      "learning_rate": 1.0516673724327758e-05,
      "loss": 0.649,
      "step": 746250
    },
    {
      "epoch": 7.900619835804384,
      "grad_norm": 4.8767170906066895,
      "learning_rate": 1.051402710141859e-05,
      "loss": 0.6392,
      "step": 746300
    },
    {
      "epoch": 7.901149157584387,
      "grad_norm": 4.0714311599731445,
      "learning_rate": 1.0511380478509423e-05,
      "loss": 0.6425,
      "step": 746350
    },
    {
      "epoch": 7.90167847936439,
      "grad_norm": 4.580117225646973,
      "learning_rate": 1.0508733855600254e-05,
      "loss": 0.6566,
      "step": 746400
    },
    {
      "epoch": 7.902207801144394,
      "grad_norm": 4.922202110290527,
      "learning_rate": 1.0506087232691086e-05,
      "loss": 0.6497,
      "step": 746450
    },
    {
      "epoch": 7.902737122924397,
      "grad_norm": 4.190367698669434,
      "learning_rate": 1.0503440609781918e-05,
      "loss": 0.6372,
      "step": 746500
    },
    {
      "epoch": 7.902737122924397,
      "eval_loss": 0.3975600004196167,
      "eval_runtime": 46.429,
      "eval_samples_per_second": 3616.921,
      "eval_steps_per_second": 452.131,
      "step": 746500
    },
    {
      "epoch": 7.9032664447044,
      "grad_norm": 4.622454643249512,
      "learning_rate": 1.0500793986872751e-05,
      "loss": 0.6484,
      "step": 746550
    },
    {
      "epoch": 7.903795766484404,
      "grad_norm": 4.138157367706299,
      "learning_rate": 1.0498147363963583e-05,
      "loss": 0.6481,
      "step": 746600
    },
    {
      "epoch": 7.9043250882644065,
      "grad_norm": 4.3059306144714355,
      "learning_rate": 1.0495500741054414e-05,
      "loss": 0.6425,
      "step": 746650
    },
    {
      "epoch": 7.90485441004441,
      "grad_norm": 4.543462753295898,
      "learning_rate": 1.0492854118145246e-05,
      "loss": 0.6494,
      "step": 746700
    },
    {
      "epoch": 7.905383731824413,
      "grad_norm": 4.264639377593994,
      "learning_rate": 1.0490207495236079e-05,
      "loss": 0.645,
      "step": 746750
    },
    {
      "epoch": 7.905913053604417,
      "grad_norm": 4.655426979064941,
      "learning_rate": 1.0487560872326911e-05,
      "loss": 0.6422,
      "step": 746800
    },
    {
      "epoch": 7.90644237538442,
      "grad_norm": 4.715522766113281,
      "learning_rate": 1.0484914249417744e-05,
      "loss": 0.6452,
      "step": 746850
    },
    {
      "epoch": 7.9069716971644235,
      "grad_norm": 4.606956481933594,
      "learning_rate": 1.0482267626508576e-05,
      "loss": 0.6542,
      "step": 746900
    },
    {
      "epoch": 7.907501018944426,
      "grad_norm": 4.4058356285095215,
      "learning_rate": 1.0479621003599407e-05,
      "loss": 0.6297,
      "step": 746950
    },
    {
      "epoch": 7.90803034072443,
      "grad_norm": 4.286355972290039,
      "learning_rate": 1.0476974380690239e-05,
      "loss": 0.6416,
      "step": 747000
    },
    {
      "epoch": 7.90803034072443,
      "eval_loss": 0.39636245369911194,
      "eval_runtime": 46.4368,
      "eval_samples_per_second": 3616.313,
      "eval_steps_per_second": 452.055,
      "step": 747000
    },
    {
      "epoch": 7.908559662504433,
      "grad_norm": 4.4595465660095215,
      "learning_rate": 1.0474327757781072e-05,
      "loss": 0.6484,
      "step": 747050
    },
    {
      "epoch": 7.909088984284436,
      "grad_norm": 4.705144882202148,
      "learning_rate": 1.0471681134871904e-05,
      "loss": 0.6559,
      "step": 747100
    },
    {
      "epoch": 7.90961830606444,
      "grad_norm": 4.680882453918457,
      "learning_rate": 1.0469034511962736e-05,
      "loss": 0.6439,
      "step": 747150
    },
    {
      "epoch": 7.910147627844443,
      "grad_norm": 4.470460891723633,
      "learning_rate": 1.0466387889053569e-05,
      "loss": 0.6542,
      "step": 747200
    },
    {
      "epoch": 7.910676949624446,
      "grad_norm": 4.266892910003662,
      "learning_rate": 1.04637412661444e-05,
      "loss": 0.6407,
      "step": 747250
    },
    {
      "epoch": 7.911206271404449,
      "grad_norm": 4.778290748596191,
      "learning_rate": 1.0461094643235232e-05,
      "loss": 0.6427,
      "step": 747300
    },
    {
      "epoch": 7.911735593184453,
      "grad_norm": 4.238133907318115,
      "learning_rate": 1.0458448020326064e-05,
      "loss": 0.6483,
      "step": 747350
    },
    {
      "epoch": 7.912264914964456,
      "grad_norm": 4.180702209472656,
      "learning_rate": 1.0455801397416897e-05,
      "loss": 0.6568,
      "step": 747400
    },
    {
      "epoch": 7.9127942367444595,
      "grad_norm": 4.592857360839844,
      "learning_rate": 1.0453154774507729e-05,
      "loss": 0.6473,
      "step": 747450
    },
    {
      "epoch": 7.913323558524462,
      "grad_norm": 4.418071746826172,
      "learning_rate": 1.045050815159856e-05,
      "loss": 0.6338,
      "step": 747500
    },
    {
      "epoch": 7.913323558524462,
      "eval_loss": 0.39711353182792664,
      "eval_runtime": 46.555,
      "eval_samples_per_second": 3607.132,
      "eval_steps_per_second": 450.908,
      "step": 747500
    },
    {
      "epoch": 7.913852880304466,
      "grad_norm": 4.940360069274902,
      "learning_rate": 1.0447861528689392e-05,
      "loss": 0.6405,
      "step": 747550
    },
    {
      "epoch": 7.914382202084469,
      "grad_norm": 4.539767265319824,
      "learning_rate": 1.0445214905780225e-05,
      "loss": 0.6427,
      "step": 747600
    },
    {
      "epoch": 7.914911523864473,
      "grad_norm": 4.294050216674805,
      "learning_rate": 1.0442568282871057e-05,
      "loss": 0.641,
      "step": 747650
    },
    {
      "epoch": 7.915440845644476,
      "grad_norm": 4.902605056762695,
      "learning_rate": 1.043992165996189e-05,
      "loss": 0.6456,
      "step": 747700
    },
    {
      "epoch": 7.915970167424479,
      "grad_norm": 4.654628753662109,
      "learning_rate": 1.0437275037052722e-05,
      "loss": 0.6481,
      "step": 747750
    },
    {
      "epoch": 7.916499489204482,
      "grad_norm": 4.571282863616943,
      "learning_rate": 1.0434628414143553e-05,
      "loss": 0.6395,
      "step": 747800
    },
    {
      "epoch": 7.917028810984486,
      "grad_norm": 4.477108478546143,
      "learning_rate": 1.0431981791234385e-05,
      "loss": 0.6371,
      "step": 747850
    },
    {
      "epoch": 7.917558132764489,
      "grad_norm": 4.754590034484863,
      "learning_rate": 1.0429335168325217e-05,
      "loss": 0.6429,
      "step": 747900
    },
    {
      "epoch": 7.918087454544493,
      "grad_norm": 4.013422012329102,
      "learning_rate": 1.042668854541605e-05,
      "loss": 0.6567,
      "step": 747950
    },
    {
      "epoch": 7.9186167763244955,
      "grad_norm": 4.254734992980957,
      "learning_rate": 1.0424041922506882e-05,
      "loss": 0.6485,
      "step": 748000
    },
    {
      "epoch": 7.9186167763244955,
      "eval_loss": 0.3971818685531616,
      "eval_runtime": 46.5107,
      "eval_samples_per_second": 3610.568,
      "eval_steps_per_second": 451.337,
      "step": 748000
    },
    {
      "epoch": 7.919146098104498,
      "grad_norm": 5.042270660400391,
      "learning_rate": 1.0421395299597715e-05,
      "loss": 0.6464,
      "step": 748050
    },
    {
      "epoch": 7.919675419884502,
      "grad_norm": 4.532456398010254,
      "learning_rate": 1.0418748676688545e-05,
      "loss": 0.6433,
      "step": 748100
    },
    {
      "epoch": 7.920204741664505,
      "grad_norm": 4.782214164733887,
      "learning_rate": 1.0416102053779378e-05,
      "loss": 0.6385,
      "step": 748150
    },
    {
      "epoch": 7.920734063444509,
      "grad_norm": 4.490640640258789,
      "learning_rate": 1.041345543087021e-05,
      "loss": 0.637,
      "step": 748200
    },
    {
      "epoch": 7.921263385224512,
      "grad_norm": 4.153738021850586,
      "learning_rate": 1.0410808807961043e-05,
      "loss": 0.632,
      "step": 748250
    },
    {
      "epoch": 7.921792707004515,
      "grad_norm": 4.2966790199279785,
      "learning_rate": 1.0408162185051875e-05,
      "loss": 0.6403,
      "step": 748300
    },
    {
      "epoch": 7.922322028784518,
      "grad_norm": 4.9726881980896,
      "learning_rate": 1.0405515562142706e-05,
      "loss": 0.6499,
      "step": 748350
    },
    {
      "epoch": 7.922851350564522,
      "grad_norm": 4.609974384307861,
      "learning_rate": 1.0402868939233538e-05,
      "loss": 0.6506,
      "step": 748400
    },
    {
      "epoch": 7.923380672344525,
      "grad_norm": 4.312771797180176,
      "learning_rate": 1.040022231632437e-05,
      "loss": 0.6385,
      "step": 748450
    },
    {
      "epoch": 7.923909994124529,
      "grad_norm": 4.247281074523926,
      "learning_rate": 1.0397575693415203e-05,
      "loss": 0.6514,
      "step": 748500
    },
    {
      "epoch": 7.923909994124529,
      "eval_loss": 0.3965875506401062,
      "eval_runtime": 46.5107,
      "eval_samples_per_second": 3610.57,
      "eval_steps_per_second": 451.337,
      "step": 748500
    },
    {
      "epoch": 7.924439315904531,
      "grad_norm": 4.854249477386475,
      "learning_rate": 1.0394929070506035e-05,
      "loss": 0.6513,
      "step": 748550
    },
    {
      "epoch": 7.924968637684535,
      "grad_norm": 4.461885452270508,
      "learning_rate": 1.0392282447596868e-05,
      "loss": 0.6445,
      "step": 748600
    },
    {
      "epoch": 7.925497959464538,
      "grad_norm": 4.642853736877441,
      "learning_rate": 1.0389635824687698e-05,
      "loss": 0.6363,
      "step": 748650
    },
    {
      "epoch": 7.926027281244542,
      "grad_norm": 4.734633922576904,
      "learning_rate": 1.038698920177853e-05,
      "loss": 0.6452,
      "step": 748700
    },
    {
      "epoch": 7.926556603024545,
      "grad_norm": 4.379364490509033,
      "learning_rate": 1.0384342578869363e-05,
      "loss": 0.6503,
      "step": 748750
    },
    {
      "epoch": 7.9270859248045475,
      "grad_norm": 4.049870014190674,
      "learning_rate": 1.0381695955960196e-05,
      "loss": 0.6359,
      "step": 748800
    },
    {
      "epoch": 7.927615246584551,
      "grad_norm": 4.376165866851807,
      "learning_rate": 1.0379049333051028e-05,
      "loss": 0.6416,
      "step": 748850
    },
    {
      "epoch": 7.928144568364554,
      "grad_norm": 4.893569469451904,
      "learning_rate": 1.0376402710141859e-05,
      "loss": 0.6384,
      "step": 748900
    },
    {
      "epoch": 7.928673890144558,
      "grad_norm": 4.335928916931152,
      "learning_rate": 1.0373756087232691e-05,
      "loss": 0.6463,
      "step": 748950
    },
    {
      "epoch": 7.929203211924561,
      "grad_norm": 4.832723617553711,
      "learning_rate": 1.0371109464323524e-05,
      "loss": 0.6401,
      "step": 749000
    },
    {
      "epoch": 7.929203211924561,
      "eval_loss": 0.3960188925266266,
      "eval_runtime": 46.5281,
      "eval_samples_per_second": 3609.217,
      "eval_steps_per_second": 451.168,
      "step": 749000
    },
    {
      "epoch": 7.9297325337045645,
      "grad_norm": 4.201798439025879,
      "learning_rate": 1.0368462841414356e-05,
      "loss": 0.6343,
      "step": 749050
    },
    {
      "epoch": 7.930261855484567,
      "grad_norm": 4.449103355407715,
      "learning_rate": 1.0365816218505188e-05,
      "loss": 0.6418,
      "step": 749100
    },
    {
      "epoch": 7.930791177264571,
      "grad_norm": 4.517553806304932,
      "learning_rate": 1.036316959559602e-05,
      "loss": 0.6426,
      "step": 749150
    },
    {
      "epoch": 7.931320499044574,
      "grad_norm": 4.502628326416016,
      "learning_rate": 1.0360522972686851e-05,
      "loss": 0.649,
      "step": 749200
    },
    {
      "epoch": 7.931849820824578,
      "grad_norm": 4.663586616516113,
      "learning_rate": 1.0357876349777684e-05,
      "loss": 0.65,
      "step": 749250
    },
    {
      "epoch": 7.932379142604581,
      "grad_norm": 4.353604793548584,
      "learning_rate": 1.0355229726868516e-05,
      "loss": 0.6435,
      "step": 749300
    },
    {
      "epoch": 7.932908464384584,
      "grad_norm": 4.742740154266357,
      "learning_rate": 1.0352583103959349e-05,
      "loss": 0.6544,
      "step": 749350
    },
    {
      "epoch": 7.933437786164587,
      "grad_norm": 4.2858357429504395,
      "learning_rate": 1.0349936481050181e-05,
      "loss": 0.6463,
      "step": 749400
    },
    {
      "epoch": 7.933967107944591,
      "grad_norm": 4.5181050300598145,
      "learning_rate": 1.0347289858141013e-05,
      "loss": 0.6416,
      "step": 749450
    },
    {
      "epoch": 7.934496429724594,
      "grad_norm": 4.566009521484375,
      "learning_rate": 1.0344643235231844e-05,
      "loss": 0.6401,
      "step": 749500
    },
    {
      "epoch": 7.934496429724594,
      "eval_loss": 0.3964155912399292,
      "eval_runtime": 46.4754,
      "eval_samples_per_second": 3613.313,
      "eval_steps_per_second": 451.68,
      "step": 749500
    },
    {
      "epoch": 7.935025751504597,
      "grad_norm": 4.976776123046875,
      "learning_rate": 1.0341996612322677e-05,
      "loss": 0.6306,
      "step": 749550
    },
    {
      "epoch": 7.9355550732846005,
      "grad_norm": 4.661847114562988,
      "learning_rate": 1.0339349989413509e-05,
      "loss": 0.6458,
      "step": 749600
    },
    {
      "epoch": 7.936084395064603,
      "grad_norm": 4.850106239318848,
      "learning_rate": 1.0336703366504341e-05,
      "loss": 0.6459,
      "step": 749650
    },
    {
      "epoch": 7.936613716844607,
      "grad_norm": 4.165972709655762,
      "learning_rate": 1.0334056743595174e-05,
      "loss": 0.6334,
      "step": 749700
    },
    {
      "epoch": 7.93714303862461,
      "grad_norm": 4.8153815269470215,
      "learning_rate": 1.0331410120686005e-05,
      "loss": 0.6419,
      "step": 749750
    },
    {
      "epoch": 7.937672360404614,
      "grad_norm": 4.694444179534912,
      "learning_rate": 1.0328763497776837e-05,
      "loss": 0.6443,
      "step": 749800
    },
    {
      "epoch": 7.938201682184617,
      "grad_norm": 4.348147869110107,
      "learning_rate": 1.032611687486767e-05,
      "loss": 0.645,
      "step": 749850
    },
    {
      "epoch": 7.93873100396462,
      "grad_norm": 4.748807907104492,
      "learning_rate": 1.0323470251958502e-05,
      "loss": 0.6478,
      "step": 749900
    },
    {
      "epoch": 7.939260325744623,
      "grad_norm": 4.841161251068115,
      "learning_rate": 1.0320823629049334e-05,
      "loss": 0.6478,
      "step": 749950
    },
    {
      "epoch": 7.939789647524627,
      "grad_norm": 4.75557804107666,
      "learning_rate": 1.0318177006140167e-05,
      "loss": 0.6502,
      "step": 750000
    },
    {
      "epoch": 7.939789647524627,
      "eval_loss": 0.3960897922515869,
      "eval_runtime": 46.5004,
      "eval_samples_per_second": 3611.363,
      "eval_steps_per_second": 451.437,
      "step": 750000
    },
    {
      "epoch": 7.94031896930463,
      "grad_norm": 4.67994499206543,
      "learning_rate": 1.0315583315689181e-05,
      "loss": 0.6414,
      "step": 750050
    },
    {
      "epoch": 7.940848291084634,
      "grad_norm": 4.659230709075928,
      "learning_rate": 1.0312936692780014e-05,
      "loss": 0.6512,
      "step": 750100
    },
    {
      "epoch": 7.9413776128646365,
      "grad_norm": 4.300998210906982,
      "learning_rate": 1.0310290069870846e-05,
      "loss": 0.6553,
      "step": 750150
    },
    {
      "epoch": 7.94190693464464,
      "grad_norm": 4.4555253982543945,
      "learning_rate": 1.0307643446961677e-05,
      "loss": 0.6451,
      "step": 750200
    },
    {
      "epoch": 7.942436256424643,
      "grad_norm": 5.159444332122803,
      "learning_rate": 1.030499682405251e-05,
      "loss": 0.6404,
      "step": 750250
    },
    {
      "epoch": 7.942965578204646,
      "grad_norm": 4.762566089630127,
      "learning_rate": 1.0302350201143342e-05,
      "loss": 0.6352,
      "step": 750300
    },
    {
      "epoch": 7.94349489998465,
      "grad_norm": 5.097657203674316,
      "learning_rate": 1.0299703578234174e-05,
      "loss": 0.6475,
      "step": 750350
    },
    {
      "epoch": 7.944024221764653,
      "grad_norm": 4.5749077796936035,
      "learning_rate": 1.0297056955325006e-05,
      "loss": 0.6433,
      "step": 750400
    },
    {
      "epoch": 7.944553543544656,
      "grad_norm": 4.504647731781006,
      "learning_rate": 1.0294410332415839e-05,
      "loss": 0.6454,
      "step": 750450
    },
    {
      "epoch": 7.945082865324659,
      "grad_norm": 4.421720504760742,
      "learning_rate": 1.029176370950667e-05,
      "loss": 0.6469,
      "step": 750500
    },
    {
      "epoch": 7.945082865324659,
      "eval_loss": 0.39588114619255066,
      "eval_runtime": 46.5278,
      "eval_samples_per_second": 3609.24,
      "eval_steps_per_second": 451.171,
      "step": 750500
    },
    {
      "epoch": 7.945612187104663,
      "grad_norm": 4.704672336578369,
      "learning_rate": 1.0289117086597502e-05,
      "loss": 0.6473,
      "step": 750550
    },
    {
      "epoch": 7.946141508884666,
      "grad_norm": 4.823037624359131,
      "learning_rate": 1.0286470463688334e-05,
      "loss": 0.6453,
      "step": 750600
    },
    {
      "epoch": 7.94667083066467,
      "grad_norm": 4.277121543884277,
      "learning_rate": 1.0283823840779167e-05,
      "loss": 0.6406,
      "step": 750650
    },
    {
      "epoch": 7.9472001524446725,
      "grad_norm": 5.146113872528076,
      "learning_rate": 1.028117721787e-05,
      "loss": 0.6359,
      "step": 750700
    },
    {
      "epoch": 7.947729474224676,
      "grad_norm": 4.42456579208374,
      "learning_rate": 1.027853059496083e-05,
      "loss": 0.653,
      "step": 750750
    },
    {
      "epoch": 7.948258796004679,
      "grad_norm": 4.830938339233398,
      "learning_rate": 1.0275883972051662e-05,
      "loss": 0.6393,
      "step": 750800
    },
    {
      "epoch": 7.948788117784683,
      "grad_norm": 4.245737075805664,
      "learning_rate": 1.0273237349142495e-05,
      "loss": 0.6364,
      "step": 750850
    },
    {
      "epoch": 7.949317439564686,
      "grad_norm": 4.262068271636963,
      "learning_rate": 1.0270590726233327e-05,
      "loss": 0.6483,
      "step": 750900
    },
    {
      "epoch": 7.9498467613446895,
      "grad_norm": 4.9414448738098145,
      "learning_rate": 1.026794410332416e-05,
      "loss": 0.6482,
      "step": 750950
    },
    {
      "epoch": 7.950376083124692,
      "grad_norm": 4.548067569732666,
      "learning_rate": 1.0265297480414992e-05,
      "loss": 0.6469,
      "step": 751000
    },
    {
      "epoch": 7.950376083124692,
      "eval_loss": 0.3965913653373718,
      "eval_runtime": 46.5194,
      "eval_samples_per_second": 3609.892,
      "eval_steps_per_second": 451.253,
      "step": 751000
    },
    {
      "epoch": 7.950905404904695,
      "grad_norm": 4.475856781005859,
      "learning_rate": 1.0262650857505823e-05,
      "loss": 0.6447,
      "step": 751050
    },
    {
      "epoch": 7.951434726684699,
      "grad_norm": 4.745770454406738,
      "learning_rate": 1.0260004234596655e-05,
      "loss": 0.6353,
      "step": 751100
    },
    {
      "epoch": 7.951964048464702,
      "grad_norm": 4.616806507110596,
      "learning_rate": 1.0257357611687487e-05,
      "loss": 0.6409,
      "step": 751150
    },
    {
      "epoch": 7.952493370244706,
      "grad_norm": 4.475536823272705,
      "learning_rate": 1.025471098877832e-05,
      "loss": 0.64,
      "step": 751200
    },
    {
      "epoch": 7.9530226920247085,
      "grad_norm": 4.240366458892822,
      "learning_rate": 1.0252064365869152e-05,
      "loss": 0.6319,
      "step": 751250
    },
    {
      "epoch": 7.953552013804712,
      "grad_norm": 4.910166263580322,
      "learning_rate": 1.0249417742959985e-05,
      "loss": 0.6473,
      "step": 751300
    },
    {
      "epoch": 7.954081335584715,
      "grad_norm": 4.750297546386719,
      "learning_rate": 1.0246771120050815e-05,
      "loss": 0.6476,
      "step": 751350
    },
    {
      "epoch": 7.954610657364719,
      "grad_norm": 4.448774337768555,
      "learning_rate": 1.0244124497141648e-05,
      "loss": 0.6271,
      "step": 751400
    },
    {
      "epoch": 7.955139979144722,
      "grad_norm": 4.697511196136475,
      "learning_rate": 1.024147787423248e-05,
      "loss": 0.6386,
      "step": 751450
    },
    {
      "epoch": 7.9556693009247255,
      "grad_norm": 4.542464733123779,
      "learning_rate": 1.0238831251323313e-05,
      "loss": 0.6376,
      "step": 751500
    },
    {
      "epoch": 7.9556693009247255,
      "eval_loss": 0.39656591415405273,
      "eval_runtime": 46.5099,
      "eval_samples_per_second": 3610.629,
      "eval_steps_per_second": 451.345,
      "step": 751500
    },
    {
      "epoch": 7.956198622704728,
      "grad_norm": 4.544118404388428,
      "learning_rate": 1.0236184628414145e-05,
      "loss": 0.6496,
      "step": 751550
    },
    {
      "epoch": 7.956727944484732,
      "grad_norm": 4.009294509887695,
      "learning_rate": 1.0233538005504976e-05,
      "loss": 0.6588,
      "step": 751600
    },
    {
      "epoch": 7.957257266264735,
      "grad_norm": 4.458859443664551,
      "learning_rate": 1.0230891382595808e-05,
      "loss": 0.6592,
      "step": 751650
    },
    {
      "epoch": 7.957786588044739,
      "grad_norm": 4.474392890930176,
      "learning_rate": 1.022824475968664e-05,
      "loss": 0.6448,
      "step": 751700
    },
    {
      "epoch": 7.958315909824742,
      "grad_norm": 4.408717632293701,
      "learning_rate": 1.0225598136777473e-05,
      "loss": 0.654,
      "step": 751750
    },
    {
      "epoch": 7.958845231604744,
      "grad_norm": 4.486461162567139,
      "learning_rate": 1.0222951513868305e-05,
      "loss": 0.6368,
      "step": 751800
    },
    {
      "epoch": 7.959374553384748,
      "grad_norm": 4.7171220779418945,
      "learning_rate": 1.0220304890959138e-05,
      "loss": 0.6492,
      "step": 751850
    },
    {
      "epoch": 7.959903875164751,
      "grad_norm": 4.702508926391602,
      "learning_rate": 1.0217658268049968e-05,
      "loss": 0.6277,
      "step": 751900
    },
    {
      "epoch": 7.960433196944755,
      "grad_norm": 4.790826797485352,
      "learning_rate": 1.02150116451408e-05,
      "loss": 0.6533,
      "step": 751950
    },
    {
      "epoch": 7.960962518724758,
      "grad_norm": 4.621753215789795,
      "learning_rate": 1.0212365022231633e-05,
      "loss": 0.6634,
      "step": 752000
    },
    {
      "epoch": 7.960962518724758,
      "eval_loss": 0.3971698582172394,
      "eval_runtime": 46.5472,
      "eval_samples_per_second": 3607.733,
      "eval_steps_per_second": 450.983,
      "step": 752000
    },
    {
      "epoch": 7.961491840504761,
      "grad_norm": 4.415815353393555,
      "learning_rate": 1.0209771331780648e-05,
      "loss": 0.6391,
      "step": 752050
    },
    {
      "epoch": 7.962021162284764,
      "grad_norm": 4.232237339019775,
      "learning_rate": 1.020712470887148e-05,
      "loss": 0.6419,
      "step": 752100
    },
    {
      "epoch": 7.962550484064768,
      "grad_norm": 5.055591106414795,
      "learning_rate": 1.0204478085962313e-05,
      "loss": 0.641,
      "step": 752150
    },
    {
      "epoch": 7.963079805844771,
      "grad_norm": 4.7054057121276855,
      "learning_rate": 1.0201831463053145e-05,
      "loss": 0.64,
      "step": 752200
    },
    {
      "epoch": 7.963609127624775,
      "grad_norm": 4.216665744781494,
      "learning_rate": 1.0199184840143978e-05,
      "loss": 0.6474,
      "step": 752250
    },
    {
      "epoch": 7.9641384494047776,
      "grad_norm": 4.438216209411621,
      "learning_rate": 1.019653821723481e-05,
      "loss": 0.6441,
      "step": 752300
    },
    {
      "epoch": 7.964667771184781,
      "grad_norm": 4.2499284744262695,
      "learning_rate": 1.019389159432564e-05,
      "loss": 0.6435,
      "step": 752350
    },
    {
      "epoch": 7.965197092964784,
      "grad_norm": 4.4376220703125,
      "learning_rate": 1.0191244971416473e-05,
      "loss": 0.6293,
      "step": 752400
    },
    {
      "epoch": 7.965726414744788,
      "grad_norm": 4.452467918395996,
      "learning_rate": 1.0188598348507305e-05,
      "loss": 0.6488,
      "step": 752450
    },
    {
      "epoch": 7.966255736524791,
      "grad_norm": 4.535975456237793,
      "learning_rate": 1.0185951725598138e-05,
      "loss": 0.6423,
      "step": 752500
    },
    {
      "epoch": 7.966255736524791,
      "eval_loss": 0.39646193385124207,
      "eval_runtime": 46.5147,
      "eval_samples_per_second": 3610.253,
      "eval_steps_per_second": 451.298,
      "step": 752500
    },
    {
      "epoch": 7.966785058304794,
      "grad_norm": 4.216855525970459,
      "learning_rate": 1.018330510268897e-05,
      "loss": 0.6439,
      "step": 752550
    },
    {
      "epoch": 7.967314380084797,
      "grad_norm": 5.397080421447754,
      "learning_rate": 1.0180658479779801e-05,
      "loss": 0.6469,
      "step": 752600
    },
    {
      "epoch": 7.9678437018648,
      "grad_norm": 4.8833699226379395,
      "learning_rate": 1.0178011856870633e-05,
      "loss": 0.6452,
      "step": 752650
    },
    {
      "epoch": 7.968373023644804,
      "grad_norm": 4.250721454620361,
      "learning_rate": 1.0175365233961466e-05,
      "loss": 0.6416,
      "step": 752700
    },
    {
      "epoch": 7.968902345424807,
      "grad_norm": 4.332281112670898,
      "learning_rate": 1.0172718611052298e-05,
      "loss": 0.6455,
      "step": 752750
    },
    {
      "epoch": 7.969431667204811,
      "grad_norm": 4.782243728637695,
      "learning_rate": 1.017007198814313e-05,
      "loss": 0.644,
      "step": 752800
    },
    {
      "epoch": 7.9699609889848135,
      "grad_norm": 4.405746936798096,
      "learning_rate": 1.0167425365233963e-05,
      "loss": 0.646,
      "step": 752850
    },
    {
      "epoch": 7.970490310764817,
      "grad_norm": 4.484748840332031,
      "learning_rate": 1.0164778742324794e-05,
      "loss": 0.6366,
      "step": 752900
    },
    {
      "epoch": 7.97101963254482,
      "grad_norm": 4.730192184448242,
      "learning_rate": 1.0162132119415626e-05,
      "loss": 0.6344,
      "step": 752950
    },
    {
      "epoch": 7.971548954324824,
      "grad_norm": 4.819614410400391,
      "learning_rate": 1.0159485496506459e-05,
      "loss": 0.6469,
      "step": 753000
    },
    {
      "epoch": 7.971548954324824,
      "eval_loss": 0.3956935703754425,
      "eval_runtime": 46.4731,
      "eval_samples_per_second": 3613.485,
      "eval_steps_per_second": 451.702,
      "step": 753000
    },
    {
      "epoch": 7.972078276104827,
      "grad_norm": 4.333377361297607,
      "learning_rate": 1.0156838873597291e-05,
      "loss": 0.6459,
      "step": 753050
    },
    {
      "epoch": 7.9726075978848305,
      "grad_norm": 4.209201335906982,
      "learning_rate": 1.0154192250688123e-05,
      "loss": 0.6458,
      "step": 753100
    },
    {
      "epoch": 7.973136919664833,
      "grad_norm": 4.777851581573486,
      "learning_rate": 1.0151545627778956e-05,
      "loss": 0.6356,
      "step": 753150
    },
    {
      "epoch": 7.973666241444837,
      "grad_norm": 4.6705780029296875,
      "learning_rate": 1.0148899004869787e-05,
      "loss": 0.6404,
      "step": 753200
    },
    {
      "epoch": 7.97419556322484,
      "grad_norm": 4.687973976135254,
      "learning_rate": 1.0146252381960619e-05,
      "loss": 0.6452,
      "step": 753250
    },
    {
      "epoch": 7.974724885004843,
      "grad_norm": 4.9377665519714355,
      "learning_rate": 1.0143605759051451e-05,
      "loss": 0.6452,
      "step": 753300
    },
    {
      "epoch": 7.975254206784847,
      "grad_norm": 4.733612060546875,
      "learning_rate": 1.0140959136142284e-05,
      "loss": 0.6386,
      "step": 753350
    },
    {
      "epoch": 7.9757835285648495,
      "grad_norm": 4.794736862182617,
      "learning_rate": 1.0138312513233116e-05,
      "loss": 0.6482,
      "step": 753400
    },
    {
      "epoch": 7.976312850344853,
      "grad_norm": 4.581597805023193,
      "learning_rate": 1.0135665890323947e-05,
      "loss": 0.6348,
      "step": 753450
    },
    {
      "epoch": 7.976842172124856,
      "grad_norm": 4.608520030975342,
      "learning_rate": 1.013301926741478e-05,
      "loss": 0.6495,
      "step": 753500
    },
    {
      "epoch": 7.976842172124856,
      "eval_loss": 0.39575842022895813,
      "eval_runtime": 46.5014,
      "eval_samples_per_second": 3611.293,
      "eval_steps_per_second": 451.428,
      "step": 753500
    },
    {
      "epoch": 7.97737149390486,
      "grad_norm": 4.484529972076416,
      "learning_rate": 1.0130372644505612e-05,
      "loss": 0.6382,
      "step": 753550
    },
    {
      "epoch": 7.977900815684863,
      "grad_norm": 5.08059024810791,
      "learning_rate": 1.0127726021596444e-05,
      "loss": 0.6579,
      "step": 753600
    },
    {
      "epoch": 7.9784301374648665,
      "grad_norm": 4.509284496307373,
      "learning_rate": 1.0125079398687276e-05,
      "loss": 0.6507,
      "step": 753650
    },
    {
      "epoch": 7.978959459244869,
      "grad_norm": 4.062577247619629,
      "learning_rate": 1.0122432775778109e-05,
      "loss": 0.6404,
      "step": 753700
    },
    {
      "epoch": 7.979488781024873,
      "grad_norm": 4.4605183601379395,
      "learning_rate": 1.011978615286894e-05,
      "loss": 0.6415,
      "step": 753750
    },
    {
      "epoch": 7.980018102804876,
      "grad_norm": 4.581768035888672,
      "learning_rate": 1.0117139529959772e-05,
      "loss": 0.6502,
      "step": 753800
    },
    {
      "epoch": 7.98054742458488,
      "grad_norm": 4.445549488067627,
      "learning_rate": 1.0114492907050604e-05,
      "loss": 0.6501,
      "step": 753850
    },
    {
      "epoch": 7.981076746364883,
      "grad_norm": 4.461822986602783,
      "learning_rate": 1.0111846284141437e-05,
      "loss": 0.6363,
      "step": 753900
    },
    {
      "epoch": 7.981606068144886,
      "grad_norm": 4.669790744781494,
      "learning_rate": 1.010919966123227e-05,
      "loss": 0.651,
      "step": 753950
    },
    {
      "epoch": 7.982135389924889,
      "grad_norm": 4.707990646362305,
      "learning_rate": 1.0106553038323102e-05,
      "loss": 0.6432,
      "step": 754000
    },
    {
      "epoch": 7.982135389924889,
      "eval_loss": 0.39558205008506775,
      "eval_runtime": 46.4997,
      "eval_samples_per_second": 3611.418,
      "eval_steps_per_second": 451.443,
      "step": 754000
    },
    {
      "epoch": 7.982664711704892,
      "grad_norm": 4.514284133911133,
      "learning_rate": 1.0103959347872116e-05,
      "loss": 0.6442,
      "step": 754050
    },
    {
      "epoch": 7.983194033484896,
      "grad_norm": 4.732263088226318,
      "learning_rate": 1.0101312724962949e-05,
      "loss": 0.6363,
      "step": 754100
    },
    {
      "epoch": 7.983723355264899,
      "grad_norm": 4.475478649139404,
      "learning_rate": 1.0098666102053781e-05,
      "loss": 0.6568,
      "step": 754150
    },
    {
      "epoch": 7.9842526770449025,
      "grad_norm": 4.703408241271973,
      "learning_rate": 1.0096019479144612e-05,
      "loss": 0.6429,
      "step": 754200
    },
    {
      "epoch": 7.984781998824905,
      "grad_norm": 4.767763137817383,
      "learning_rate": 1.0093372856235444e-05,
      "loss": 0.6457,
      "step": 754250
    },
    {
      "epoch": 7.985311320604909,
      "grad_norm": 4.483640193939209,
      "learning_rate": 1.0090726233326277e-05,
      "loss": 0.6444,
      "step": 754300
    },
    {
      "epoch": 7.985840642384912,
      "grad_norm": 4.321990966796875,
      "learning_rate": 1.0088079610417109e-05,
      "loss": 0.6399,
      "step": 754350
    },
    {
      "epoch": 7.986369964164916,
      "grad_norm": 4.9143171310424805,
      "learning_rate": 1.0085432987507941e-05,
      "loss": 0.6541,
      "step": 754400
    },
    {
      "epoch": 7.986899285944919,
      "grad_norm": 4.815618991851807,
      "learning_rate": 1.0082786364598772e-05,
      "loss": 0.6371,
      "step": 754450
    },
    {
      "epoch": 7.987428607724922,
      "grad_norm": 4.257274627685547,
      "learning_rate": 1.0080139741689605e-05,
      "loss": 0.6507,
      "step": 754500
    },
    {
      "epoch": 7.987428607724922,
      "eval_loss": 0.3963777720928192,
      "eval_runtime": 46.4924,
      "eval_samples_per_second": 3611.989,
      "eval_steps_per_second": 451.515,
      "step": 754500
    },
    {
      "epoch": 7.987957929504925,
      "grad_norm": 4.319831848144531,
      "learning_rate": 1.0077493118780437e-05,
      "loss": 0.635,
      "step": 754550
    },
    {
      "epoch": 7.988487251284929,
      "grad_norm": 4.162193775177002,
      "learning_rate": 1.007484649587127e-05,
      "loss": 0.6428,
      "step": 754600
    },
    {
      "epoch": 7.989016573064932,
      "grad_norm": 4.397199630737305,
      "learning_rate": 1.0072199872962102e-05,
      "loss": 0.6402,
      "step": 754650
    },
    {
      "epoch": 7.989545894844936,
      "grad_norm": 4.498707294464111,
      "learning_rate": 1.0069553250052934e-05,
      "loss": 0.6446,
      "step": 754700
    },
    {
      "epoch": 7.9900752166249385,
      "grad_norm": 4.671851634979248,
      "learning_rate": 1.0066906627143765e-05,
      "loss": 0.6394,
      "step": 754750
    },
    {
      "epoch": 7.990604538404941,
      "grad_norm": 4.500344276428223,
      "learning_rate": 1.0064260004234597e-05,
      "loss": 0.6503,
      "step": 754800
    },
    {
      "epoch": 7.991133860184945,
      "grad_norm": 4.3409318923950195,
      "learning_rate": 1.006161338132543e-05,
      "loss": 0.6523,
      "step": 754850
    },
    {
      "epoch": 7.991663181964948,
      "grad_norm": 4.54749059677124,
      "learning_rate": 1.0058966758416262e-05,
      "loss": 0.6441,
      "step": 754900
    },
    {
      "epoch": 7.992192503744952,
      "grad_norm": 4.628174304962158,
      "learning_rate": 1.0056320135507095e-05,
      "loss": 0.6449,
      "step": 754950
    },
    {
      "epoch": 7.992721825524955,
      "grad_norm": 4.600612163543701,
      "learning_rate": 1.0053673512597927e-05,
      "loss": 0.6455,
      "step": 755000
    },
    {
      "epoch": 7.992721825524955,
      "eval_loss": 0.39555561542510986,
      "eval_runtime": 46.4489,
      "eval_samples_per_second": 3615.372,
      "eval_steps_per_second": 451.938,
      "step": 755000
    },
    {
      "epoch": 7.993251147304958,
      "grad_norm": 4.609742164611816,
      "learning_rate": 1.0051026889688758e-05,
      "loss": 0.6456,
      "step": 755050
    },
    {
      "epoch": 7.993780469084961,
      "grad_norm": 4.022800445556641,
      "learning_rate": 1.004838026677959e-05,
      "loss": 0.6408,
      "step": 755100
    },
    {
      "epoch": 7.994309790864965,
      "grad_norm": 4.11956262588501,
      "learning_rate": 1.0045733643870422e-05,
      "loss": 0.6329,
      "step": 755150
    },
    {
      "epoch": 7.994839112644968,
      "grad_norm": 4.244125843048096,
      "learning_rate": 1.0043087020961255e-05,
      "loss": 0.6352,
      "step": 755200
    },
    {
      "epoch": 7.995368434424972,
      "grad_norm": 4.022670745849609,
      "learning_rate": 1.0040440398052087e-05,
      "loss": 0.6453,
      "step": 755250
    },
    {
      "epoch": 7.9958977562049744,
      "grad_norm": 4.899624347686768,
      "learning_rate": 1.0037793775142918e-05,
      "loss": 0.6485,
      "step": 755300
    },
    {
      "epoch": 7.996427077984978,
      "grad_norm": 4.46415376663208,
      "learning_rate": 1.003514715223375e-05,
      "loss": 0.6343,
      "step": 755350
    },
    {
      "epoch": 7.996956399764981,
      "grad_norm": 4.146050930023193,
      "learning_rate": 1.0032500529324581e-05,
      "loss": 0.6424,
      "step": 755400
    },
    {
      "epoch": 7.997485721544985,
      "grad_norm": 4.318231582641602,
      "learning_rate": 1.0029853906415414e-05,
      "loss": 0.6513,
      "step": 755450
    },
    {
      "epoch": 7.998015043324988,
      "grad_norm": 4.417486667633057,
      "learning_rate": 1.0027207283506246e-05,
      "loss": 0.6375,
      "step": 755500
    },
    {
      "epoch": 7.998015043324988,
      "eval_loss": 0.3958376944065094,
      "eval_runtime": 46.4517,
      "eval_samples_per_second": 3615.156,
      "eval_steps_per_second": 451.911,
      "step": 755500
    },
    {
      "epoch": 7.998544365104991,
      "grad_norm": 4.511415004730225,
      "learning_rate": 1.0024560660597078e-05,
      "loss": 0.6553,
      "step": 755550
    },
    {
      "epoch": 7.999073686884994,
      "grad_norm": 4.412761211395264,
      "learning_rate": 1.002191403768791e-05,
      "loss": 0.6463,
      "step": 755600
    },
    {
      "epoch": 7.999603008664997,
      "grad_norm": 4.488222599029541,
      "learning_rate": 1.0019267414778741e-05,
      "loss": 0.6417,
      "step": 755650
    },
    {
      "epoch": 8.0001270372272,
      "grad_norm": 4.689743995666504,
      "learning_rate": 1.0016620791869574e-05,
      "loss": 0.6482,
      "step": 755700
    },
    {
      "epoch": 8.000656359007204,
      "grad_norm": 4.478700637817383,
      "learning_rate": 1.0013974168960406e-05,
      "loss": 0.6359,
      "step": 755750
    },
    {
      "epoch": 8.001185680787207,
      "grad_norm": 5.011195659637451,
      "learning_rate": 1.0011327546051239e-05,
      "loss": 0.6395,
      "step": 755800
    },
    {
      "epoch": 8.001715002567211,
      "grad_norm": 4.225140571594238,
      "learning_rate": 1.0008680923142071e-05,
      "loss": 0.6286,
      "step": 755850
    },
    {
      "epoch": 8.002244324347213,
      "grad_norm": 4.477843761444092,
      "learning_rate": 1.0006034300232903e-05,
      "loss": 0.643,
      "step": 755900
    },
    {
      "epoch": 8.002773646127217,
      "grad_norm": 4.226024150848389,
      "learning_rate": 1.0003387677323734e-05,
      "loss": 0.6457,
      "step": 755950
    },
    {
      "epoch": 8.00330296790722,
      "grad_norm": 4.683653354644775,
      "learning_rate": 1.0000741054414567e-05,
      "loss": 0.6389,
      "step": 756000
    },
    {
      "epoch": 8.00330296790722,
      "eval_loss": 0.3952304422855377,
      "eval_runtime": 46.4829,
      "eval_samples_per_second": 3612.724,
      "eval_steps_per_second": 451.607,
      "step": 756000
    },
    {
      "epoch": 8.003832289687224,
      "grad_norm": 4.3011322021484375,
      "learning_rate": 9.998094431505399e-06,
      "loss": 0.6449,
      "step": 756050
    },
    {
      "epoch": 8.004361611467226,
      "grad_norm": 4.6077680587768555,
      "learning_rate": 9.995500741054414e-06,
      "loss": 0.6545,
      "step": 756100
    },
    {
      "epoch": 8.00489093324723,
      "grad_norm": 4.098419189453125,
      "learning_rate": 9.992854118145246e-06,
      "loss": 0.6444,
      "step": 756150
    },
    {
      "epoch": 8.005420255027234,
      "grad_norm": 4.444079875946045,
      "learning_rate": 9.990207495236079e-06,
      "loss": 0.6372,
      "step": 756200
    },
    {
      "epoch": 8.005949576807238,
      "grad_norm": 4.5086283683776855,
      "learning_rate": 9.987560872326911e-06,
      "loss": 0.6293,
      "step": 756250
    },
    {
      "epoch": 8.00647889858724,
      "grad_norm": 3.987093925476074,
      "learning_rate": 9.984914249417743e-06,
      "loss": 0.6486,
      "step": 756300
    },
    {
      "epoch": 8.007008220367243,
      "grad_norm": 4.819012641906738,
      "learning_rate": 9.982267626508574e-06,
      "loss": 0.6461,
      "step": 756350
    },
    {
      "epoch": 8.007537542147247,
      "grad_norm": 4.456713676452637,
      "learning_rate": 9.979621003599406e-06,
      "loss": 0.6375,
      "step": 756400
    },
    {
      "epoch": 8.00806686392725,
      "grad_norm": 4.266129493713379,
      "learning_rate": 9.976974380690239e-06,
      "loss": 0.6305,
      "step": 756450
    },
    {
      "epoch": 8.008596185707253,
      "grad_norm": 4.502974510192871,
      "learning_rate": 9.974327757781071e-06,
      "loss": 0.6285,
      "step": 756500
    },
    {
      "epoch": 8.008596185707253,
      "eval_loss": 0.3945207893848419,
      "eval_runtime": 46.5427,
      "eval_samples_per_second": 3608.087,
      "eval_steps_per_second": 451.027,
      "step": 756500
    },
    {
      "epoch": 8.009125507487257,
      "grad_norm": 4.487737655639648,
      "learning_rate": 9.971681134871904e-06,
      "loss": 0.6231,
      "step": 756550
    },
    {
      "epoch": 8.00965482926726,
      "grad_norm": 4.892404079437256,
      "learning_rate": 9.969034511962736e-06,
      "loss": 0.6323,
      "step": 756600
    },
    {
      "epoch": 8.010184151047262,
      "grad_norm": 4.41427755355835,
      "learning_rate": 9.966387889053567e-06,
      "loss": 0.643,
      "step": 756650
    },
    {
      "epoch": 8.010713472827266,
      "grad_norm": 4.233696460723877,
      "learning_rate": 9.9637412661444e-06,
      "loss": 0.648,
      "step": 756700
    },
    {
      "epoch": 8.01124279460727,
      "grad_norm": 4.757851600646973,
      "learning_rate": 9.961094643235232e-06,
      "loss": 0.6335,
      "step": 756750
    },
    {
      "epoch": 8.011772116387274,
      "grad_norm": 4.606142520904541,
      "learning_rate": 9.958448020326064e-06,
      "loss": 0.6422,
      "step": 756800
    },
    {
      "epoch": 8.012301438167276,
      "grad_norm": 4.830999851226807,
      "learning_rate": 9.955801397416896e-06,
      "loss": 0.6401,
      "step": 756850
    },
    {
      "epoch": 8.01283075994728,
      "grad_norm": 4.740297317504883,
      "learning_rate": 9.953154774507729e-06,
      "loss": 0.6438,
      "step": 756900
    },
    {
      "epoch": 8.013360081727283,
      "grad_norm": 4.965721130371094,
      "learning_rate": 9.95050815159856e-06,
      "loss": 0.6378,
      "step": 756950
    },
    {
      "epoch": 8.013889403507287,
      "grad_norm": 4.248598575592041,
      "learning_rate": 9.947861528689392e-06,
      "loss": 0.6398,
      "step": 757000
    },
    {
      "epoch": 8.013889403507287,
      "eval_loss": 0.3950642943382263,
      "eval_runtime": 46.4956,
      "eval_samples_per_second": 3611.74,
      "eval_steps_per_second": 451.484,
      "step": 757000
    },
    {
      "epoch": 8.014418725287289,
      "grad_norm": 4.302732467651367,
      "learning_rate": 9.945214905780224e-06,
      "loss": 0.6446,
      "step": 757050
    },
    {
      "epoch": 8.014948047067293,
      "grad_norm": 4.786550521850586,
      "learning_rate": 9.942568282871057e-06,
      "loss": 0.6419,
      "step": 757100
    },
    {
      "epoch": 8.015477368847296,
      "grad_norm": 4.670341968536377,
      "learning_rate": 9.939921659961889e-06,
      "loss": 0.6399,
      "step": 757150
    },
    {
      "epoch": 8.016006690627298,
      "grad_norm": 4.4271721839904785,
      "learning_rate": 9.93727503705272e-06,
      "loss": 0.6509,
      "step": 757200
    },
    {
      "epoch": 8.016536012407302,
      "grad_norm": 4.868167877197266,
      "learning_rate": 9.934628414143552e-06,
      "loss": 0.6342,
      "step": 757250
    },
    {
      "epoch": 8.017065334187306,
      "grad_norm": 4.098247051239014,
      "learning_rate": 9.931981791234385e-06,
      "loss": 0.6473,
      "step": 757300
    },
    {
      "epoch": 8.01759465596731,
      "grad_norm": 4.532768726348877,
      "learning_rate": 9.929335168325217e-06,
      "loss": 0.6389,
      "step": 757350
    },
    {
      "epoch": 8.018123977747312,
      "grad_norm": 4.8156256675720215,
      "learning_rate": 9.92668854541605e-06,
      "loss": 0.6236,
      "step": 757400
    },
    {
      "epoch": 8.018653299527315,
      "grad_norm": 4.426516532897949,
      "learning_rate": 9.924041922506882e-06,
      "loss": 0.6427,
      "step": 757450
    },
    {
      "epoch": 8.01918262130732,
      "grad_norm": 4.444836616516113,
      "learning_rate": 9.921395299597713e-06,
      "loss": 0.6338,
      "step": 757500
    },
    {
      "epoch": 8.01918262130732,
      "eval_loss": 0.39471444487571716,
      "eval_runtime": 46.4449,
      "eval_samples_per_second": 3615.686,
      "eval_steps_per_second": 451.977,
      "step": 757500
    },
    {
      "epoch": 8.019711943087323,
      "grad_norm": 4.4467854499816895,
      "learning_rate": 9.918748676688545e-06,
      "loss": 0.6399,
      "step": 757550
    },
    {
      "epoch": 8.020241264867325,
      "grad_norm": 4.268954277038574,
      "learning_rate": 9.916102053779377e-06,
      "loss": 0.642,
      "step": 757600
    },
    {
      "epoch": 8.020770586647329,
      "grad_norm": 4.906091213226318,
      "learning_rate": 9.91345543087021e-06,
      "loss": 0.6332,
      "step": 757650
    },
    {
      "epoch": 8.021299908427332,
      "grad_norm": 4.359779357910156,
      "learning_rate": 9.910808807961042e-06,
      "loss": 0.6462,
      "step": 757700
    },
    {
      "epoch": 8.021829230207336,
      "grad_norm": 4.613298416137695,
      "learning_rate": 9.908162185051875e-06,
      "loss": 0.6379,
      "step": 757750
    },
    {
      "epoch": 8.022358551987338,
      "grad_norm": 4.3168721199035645,
      "learning_rate": 9.905515562142705e-06,
      "loss": 0.6362,
      "step": 757800
    },
    {
      "epoch": 8.022887873767342,
      "grad_norm": 4.923737049102783,
      "learning_rate": 9.902868939233538e-06,
      "loss": 0.6426,
      "step": 757850
    },
    {
      "epoch": 8.023417195547346,
      "grad_norm": 4.548628807067871,
      "learning_rate": 9.90022231632437e-06,
      "loss": 0.6423,
      "step": 757900
    },
    {
      "epoch": 8.023946517327348,
      "grad_norm": 4.8070902824401855,
      "learning_rate": 9.897575693415203e-06,
      "loss": 0.6404,
      "step": 757950
    },
    {
      "epoch": 8.024475839107351,
      "grad_norm": 4.397956371307373,
      "learning_rate": 9.894929070506035e-06,
      "loss": 0.6405,
      "step": 758000
    },
    {
      "epoch": 8.024475839107351,
      "eval_loss": 0.3944854736328125,
      "eval_runtime": 46.4857,
      "eval_samples_per_second": 3612.512,
      "eval_steps_per_second": 451.58,
      "step": 758000
    },
    {
      "epoch": 8.025005160887355,
      "grad_norm": 4.543542861938477,
      "learning_rate": 9.892282447596866e-06,
      "loss": 0.6441,
      "step": 758050
    },
    {
      "epoch": 8.025534482667359,
      "grad_norm": 4.8199872970581055,
      "learning_rate": 9.889688757145882e-06,
      "loss": 0.64,
      "step": 758100
    },
    {
      "epoch": 8.026063804447361,
      "grad_norm": 4.139459133148193,
      "learning_rate": 9.887042134236714e-06,
      "loss": 0.6347,
      "step": 758150
    },
    {
      "epoch": 8.026593126227365,
      "grad_norm": 4.00156831741333,
      "learning_rate": 9.884395511327547e-06,
      "loss": 0.6272,
      "step": 758200
    },
    {
      "epoch": 8.027122448007368,
      "grad_norm": 4.285330772399902,
      "learning_rate": 9.881748888418378e-06,
      "loss": 0.644,
      "step": 758250
    },
    {
      "epoch": 8.027651769787372,
      "grad_norm": 4.133424282073975,
      "learning_rate": 9.87910226550921e-06,
      "loss": 0.63,
      "step": 758300
    },
    {
      "epoch": 8.028181091567374,
      "grad_norm": 4.226015567779541,
      "learning_rate": 9.876455642600042e-06,
      "loss": 0.631,
      "step": 758350
    },
    {
      "epoch": 8.028710413347378,
      "grad_norm": 4.704733848571777,
      "learning_rate": 9.873809019690875e-06,
      "loss": 0.6482,
      "step": 758400
    },
    {
      "epoch": 8.029239735127382,
      "grad_norm": 4.481634140014648,
      "learning_rate": 9.871162396781707e-06,
      "loss": 0.6456,
      "step": 758450
    },
    {
      "epoch": 8.029769056907385,
      "grad_norm": 4.159437656402588,
      "learning_rate": 9.868515773872538e-06,
      "loss": 0.6401,
      "step": 758500
    },
    {
      "epoch": 8.029769056907385,
      "eval_loss": 0.3945128619670868,
      "eval_runtime": 46.4702,
      "eval_samples_per_second": 3613.712,
      "eval_steps_per_second": 451.73,
      "step": 758500
    },
    {
      "epoch": 8.030298378687387,
      "grad_norm": 4.610407829284668,
      "learning_rate": 9.86586915096337e-06,
      "loss": 0.6461,
      "step": 758550
    },
    {
      "epoch": 8.030827700467391,
      "grad_norm": 3.922264575958252,
      "learning_rate": 9.863222528054203e-06,
      "loss": 0.6377,
      "step": 758600
    },
    {
      "epoch": 8.031357022247395,
      "grad_norm": 4.654422760009766,
      "learning_rate": 9.860575905145035e-06,
      "loss": 0.6328,
      "step": 758650
    },
    {
      "epoch": 8.031886344027397,
      "grad_norm": 4.762187957763672,
      "learning_rate": 9.857929282235868e-06,
      "loss": 0.6407,
      "step": 758700
    },
    {
      "epoch": 8.0324156658074,
      "grad_norm": 4.6738057136535645,
      "learning_rate": 9.8552826593267e-06,
      "loss": 0.6408,
      "step": 758750
    },
    {
      "epoch": 8.032944987587404,
      "grad_norm": 4.633431911468506,
      "learning_rate": 9.85263603641753e-06,
      "loss": 0.6389,
      "step": 758800
    },
    {
      "epoch": 8.033474309367408,
      "grad_norm": 5.029872894287109,
      "learning_rate": 9.849989413508363e-06,
      "loss": 0.643,
      "step": 758850
    },
    {
      "epoch": 8.03400363114741,
      "grad_norm": 4.653684139251709,
      "learning_rate": 9.847342790599195e-06,
      "loss": 0.6413,
      "step": 758900
    },
    {
      "epoch": 8.034532952927414,
      "grad_norm": 4.420164585113525,
      "learning_rate": 9.844696167690028e-06,
      "loss": 0.6347,
      "step": 758950
    },
    {
      "epoch": 8.035062274707418,
      "grad_norm": 4.643458366394043,
      "learning_rate": 9.84204954478086e-06,
      "loss": 0.6281,
      "step": 759000
    },
    {
      "epoch": 8.035062274707418,
      "eval_loss": 0.39381080865859985,
      "eval_runtime": 46.4796,
      "eval_samples_per_second": 3612.983,
      "eval_steps_per_second": 451.639,
      "step": 759000
    },
    {
      "epoch": 8.035591596487421,
      "grad_norm": 5.128096580505371,
      "learning_rate": 9.839402921871691e-06,
      "loss": 0.6329,
      "step": 759050
    },
    {
      "epoch": 8.036120918267423,
      "grad_norm": 4.621333599090576,
      "learning_rate": 9.836756298962523e-06,
      "loss": 0.6365,
      "step": 759100
    },
    {
      "epoch": 8.036650240047427,
      "grad_norm": 4.3892927169799805,
      "learning_rate": 9.834109676053356e-06,
      "loss": 0.6445,
      "step": 759150
    },
    {
      "epoch": 8.03717956182743,
      "grad_norm": 4.984827518463135,
      "learning_rate": 9.831463053144188e-06,
      "loss": 0.6318,
      "step": 759200
    },
    {
      "epoch": 8.037708883607435,
      "grad_norm": 4.689864635467529,
      "learning_rate": 9.82881643023502e-06,
      "loss": 0.6454,
      "step": 759250
    },
    {
      "epoch": 8.038238205387437,
      "grad_norm": 4.704668998718262,
      "learning_rate": 9.826169807325853e-06,
      "loss": 0.6371,
      "step": 759300
    },
    {
      "epoch": 8.03876752716744,
      "grad_norm": 4.36480188369751,
      "learning_rate": 9.823523184416684e-06,
      "loss": 0.6394,
      "step": 759350
    },
    {
      "epoch": 8.039296848947444,
      "grad_norm": 4.906701564788818,
      "learning_rate": 9.820876561507516e-06,
      "loss": 0.6359,
      "step": 759400
    },
    {
      "epoch": 8.039826170727446,
      "grad_norm": 4.490993022918701,
      "learning_rate": 9.818229938598349e-06,
      "loss": 0.6401,
      "step": 759450
    },
    {
      "epoch": 8.04035549250745,
      "grad_norm": 4.899392127990723,
      "learning_rate": 9.815583315689181e-06,
      "loss": 0.6516,
      "step": 759500
    },
    {
      "epoch": 8.04035549250745,
      "eval_loss": 0.3943973183631897,
      "eval_runtime": 46.5096,
      "eval_samples_per_second": 3610.65,
      "eval_steps_per_second": 451.347,
      "step": 759500
    },
    {
      "epoch": 8.040884814287454,
      "grad_norm": 4.2347002029418945,
      "learning_rate": 9.812936692780013e-06,
      "loss": 0.6424,
      "step": 759550
    },
    {
      "epoch": 8.041414136067457,
      "grad_norm": 4.721780776977539,
      "learning_rate": 9.810290069870846e-06,
      "loss": 0.6443,
      "step": 759600
    },
    {
      "epoch": 8.04194345784746,
      "grad_norm": 4.645359992980957,
      "learning_rate": 9.807643446961676e-06,
      "loss": 0.6314,
      "step": 759650
    },
    {
      "epoch": 8.042472779627463,
      "grad_norm": 4.771711826324463,
      "learning_rate": 9.804996824052509e-06,
      "loss": 0.6315,
      "step": 759700
    },
    {
      "epoch": 8.043002101407467,
      "grad_norm": 4.295953750610352,
      "learning_rate": 9.802350201143341e-06,
      "loss": 0.6347,
      "step": 759750
    },
    {
      "epoch": 8.04353142318747,
      "grad_norm": 4.963820457458496,
      "learning_rate": 9.799703578234174e-06,
      "loss": 0.6457,
      "step": 759800
    },
    {
      "epoch": 8.044060744967473,
      "grad_norm": 4.94354772567749,
      "learning_rate": 9.797056955325006e-06,
      "loss": 0.6457,
      "step": 759850
    },
    {
      "epoch": 8.044590066747476,
      "grad_norm": 4.553493976593018,
      "learning_rate": 9.794410332415837e-06,
      "loss": 0.6259,
      "step": 759900
    },
    {
      "epoch": 8.04511938852748,
      "grad_norm": 4.896649360656738,
      "learning_rate": 9.79176370950667e-06,
      "loss": 0.6242,
      "step": 759950
    },
    {
      "epoch": 8.045648710307484,
      "grad_norm": 4.651816368103027,
      "learning_rate": 9.789117086597502e-06,
      "loss": 0.6368,
      "step": 760000
    },
    {
      "epoch": 8.045648710307484,
      "eval_loss": 0.39474716782569885,
      "eval_runtime": 46.4981,
      "eval_samples_per_second": 3611.544,
      "eval_steps_per_second": 451.459,
      "step": 760000
    },
    {
      "epoch": 8.046178032087486,
      "grad_norm": 4.301929473876953,
      "learning_rate": 9.786470463688334e-06,
      "loss": 0.6472,
      "step": 760050
    },
    {
      "epoch": 8.04670735386749,
      "grad_norm": 4.133627414703369,
      "learning_rate": 9.783876773237349e-06,
      "loss": 0.6323,
      "step": 760100
    },
    {
      "epoch": 8.047236675647493,
      "grad_norm": 4.386314392089844,
      "learning_rate": 9.781230150328181e-06,
      "loss": 0.6379,
      "step": 760150
    },
    {
      "epoch": 8.047765997427495,
      "grad_norm": 4.885636806488037,
      "learning_rate": 9.778583527419014e-06,
      "loss": 0.6372,
      "step": 760200
    },
    {
      "epoch": 8.048295319207499,
      "grad_norm": 4.5340375900268555,
      "learning_rate": 9.775936904509846e-06,
      "loss": 0.6464,
      "step": 760250
    },
    {
      "epoch": 8.048824640987503,
      "grad_norm": 4.856748580932617,
      "learning_rate": 9.773290281600678e-06,
      "loss": 0.6436,
      "step": 760300
    },
    {
      "epoch": 8.049353962767507,
      "grad_norm": 4.6183390617370605,
      "learning_rate": 9.770643658691509e-06,
      "loss": 0.6366,
      "step": 760350
    },
    {
      "epoch": 8.049883284547509,
      "grad_norm": 4.5793867111206055,
      "learning_rate": 9.767997035782341e-06,
      "loss": 0.64,
      "step": 760400
    },
    {
      "epoch": 8.050412606327512,
      "grad_norm": 4.525729179382324,
      "learning_rate": 9.765350412873174e-06,
      "loss": 0.6397,
      "step": 760450
    },
    {
      "epoch": 8.050941928107516,
      "grad_norm": 4.552398681640625,
      "learning_rate": 9.762703789964006e-06,
      "loss": 0.6359,
      "step": 760500
    },
    {
      "epoch": 8.050941928107516,
      "eval_loss": 0.3944219648838043,
      "eval_runtime": 46.4945,
      "eval_samples_per_second": 3611.825,
      "eval_steps_per_second": 451.494,
      "step": 760500
    },
    {
      "epoch": 8.05147124988752,
      "grad_norm": 4.625608921051025,
      "learning_rate": 9.760057167054839e-06,
      "loss": 0.6386,
      "step": 760550
    },
    {
      "epoch": 8.052000571667522,
      "grad_norm": 4.70547342300415,
      "learning_rate": 9.757410544145671e-06,
      "loss": 0.6506,
      "step": 760600
    },
    {
      "epoch": 8.052529893447526,
      "grad_norm": 4.2445502281188965,
      "learning_rate": 9.754763921236502e-06,
      "loss": 0.6327,
      "step": 760650
    },
    {
      "epoch": 8.05305921522753,
      "grad_norm": 4.783608913421631,
      "learning_rate": 9.752117298327334e-06,
      "loss": 0.6342,
      "step": 760700
    },
    {
      "epoch": 8.053588537007533,
      "grad_norm": 4.532594203948975,
      "learning_rate": 9.749470675418167e-06,
      "loss": 0.6493,
      "step": 760750
    },
    {
      "epoch": 8.054117858787535,
      "grad_norm": 4.594193935394287,
      "learning_rate": 9.746824052508999e-06,
      "loss": 0.6531,
      "step": 760800
    },
    {
      "epoch": 8.054647180567539,
      "grad_norm": 4.655381202697754,
      "learning_rate": 9.744177429599831e-06,
      "loss": 0.637,
      "step": 760850
    },
    {
      "epoch": 8.055176502347543,
      "grad_norm": 5.298853874206543,
      "learning_rate": 9.741530806690662e-06,
      "loss": 0.6451,
      "step": 760900
    },
    {
      "epoch": 8.055705824127545,
      "grad_norm": 4.834222793579102,
      "learning_rate": 9.738884183781495e-06,
      "loss": 0.6361,
      "step": 760950
    },
    {
      "epoch": 8.056235145907548,
      "grad_norm": 5.0883259773254395,
      "learning_rate": 9.736237560872327e-06,
      "loss": 0.6392,
      "step": 761000
    },
    {
      "epoch": 8.056235145907548,
      "eval_loss": 0.3933217525482178,
      "eval_runtime": 46.4679,
      "eval_samples_per_second": 3613.895,
      "eval_steps_per_second": 451.753,
      "step": 761000
    },
    {
      "epoch": 8.056764467687552,
      "grad_norm": 4.391430377960205,
      "learning_rate": 9.73359093796316e-06,
      "loss": 0.6396,
      "step": 761050
    },
    {
      "epoch": 8.057293789467556,
      "grad_norm": 4.475774765014648,
      "learning_rate": 9.730944315053992e-06,
      "loss": 0.6385,
      "step": 761100
    },
    {
      "epoch": 8.057823111247558,
      "grad_norm": 4.494403839111328,
      "learning_rate": 9.728297692144824e-06,
      "loss": 0.6397,
      "step": 761150
    },
    {
      "epoch": 8.058352433027562,
      "grad_norm": 4.525656700134277,
      "learning_rate": 9.725651069235655e-06,
      "loss": 0.6357,
      "step": 761200
    },
    {
      "epoch": 8.058881754807565,
      "grad_norm": 4.8497538566589355,
      "learning_rate": 9.723004446326487e-06,
      "loss": 0.6568,
      "step": 761250
    },
    {
      "epoch": 8.059411076587569,
      "grad_norm": 4.354671955108643,
      "learning_rate": 9.72035782341732e-06,
      "loss": 0.6356,
      "step": 761300
    },
    {
      "epoch": 8.059940398367571,
      "grad_norm": 4.916572093963623,
      "learning_rate": 9.717711200508152e-06,
      "loss": 0.6481,
      "step": 761350
    },
    {
      "epoch": 8.060469720147575,
      "grad_norm": 4.280721664428711,
      "learning_rate": 9.715064577598985e-06,
      "loss": 0.6401,
      "step": 761400
    },
    {
      "epoch": 8.060999041927579,
      "grad_norm": 4.59619665145874,
      "learning_rate": 9.712417954689817e-06,
      "loss": 0.6422,
      "step": 761450
    },
    {
      "epoch": 8.061528363707582,
      "grad_norm": 5.045414924621582,
      "learning_rate": 9.709771331780648e-06,
      "loss": 0.6428,
      "step": 761500
    },
    {
      "epoch": 8.061528363707582,
      "eval_loss": 0.394931435585022,
      "eval_runtime": 46.5321,
      "eval_samples_per_second": 3608.908,
      "eval_steps_per_second": 451.13,
      "step": 761500
    },
    {
      "epoch": 8.062057685487584,
      "grad_norm": 4.445843696594238,
      "learning_rate": 9.70712470887148e-06,
      "loss": 0.6342,
      "step": 761550
    },
    {
      "epoch": 8.062587007267588,
      "grad_norm": 4.541262149810791,
      "learning_rate": 9.704478085962312e-06,
      "loss": 0.6477,
      "step": 761600
    },
    {
      "epoch": 8.063116329047592,
      "grad_norm": 4.774236679077148,
      "learning_rate": 9.701831463053145e-06,
      "loss": 0.6498,
      "step": 761650
    },
    {
      "epoch": 8.063645650827594,
      "grad_norm": 4.3213396072387695,
      "learning_rate": 9.699184840143977e-06,
      "loss": 0.633,
      "step": 761700
    },
    {
      "epoch": 8.064174972607598,
      "grad_norm": 4.53670072555542,
      "learning_rate": 9.696538217234808e-06,
      "loss": 0.6496,
      "step": 761750
    },
    {
      "epoch": 8.064704294387601,
      "grad_norm": 4.380760192871094,
      "learning_rate": 9.69389159432564e-06,
      "loss": 0.6342,
      "step": 761800
    },
    {
      "epoch": 8.065233616167605,
      "grad_norm": 4.466181755065918,
      "learning_rate": 9.691244971416473e-06,
      "loss": 0.6452,
      "step": 761850
    },
    {
      "epoch": 8.065762937947607,
      "grad_norm": 4.442620754241943,
      "learning_rate": 9.688598348507305e-06,
      "loss": 0.6394,
      "step": 761900
    },
    {
      "epoch": 8.06629225972761,
      "grad_norm": 4.674114227294922,
      "learning_rate": 9.685951725598138e-06,
      "loss": 0.6414,
      "step": 761950
    },
    {
      "epoch": 8.066821581507615,
      "grad_norm": 4.272964954376221,
      "learning_rate": 9.68330510268897e-06,
      "loss": 0.6407,
      "step": 762000
    },
    {
      "epoch": 8.066821581507615,
      "eval_loss": 0.3941267728805542,
      "eval_runtime": 46.4099,
      "eval_samples_per_second": 3618.407,
      "eval_steps_per_second": 452.317,
      "step": 762000
    },
    {
      "epoch": 8.067350903287618,
      "grad_norm": 4.944334506988525,
      "learning_rate": 9.6806584797798e-06,
      "loss": 0.6438,
      "step": 762050
    },
    {
      "epoch": 8.06788022506762,
      "grad_norm": 4.5928449630737305,
      "learning_rate": 9.678064789328817e-06,
      "loss": 0.6555,
      "step": 762100
    },
    {
      "epoch": 8.068409546847624,
      "grad_norm": 4.982226848602295,
      "learning_rate": 9.67541816641965e-06,
      "loss": 0.6339,
      "step": 762150
    },
    {
      "epoch": 8.068938868627628,
      "grad_norm": 4.649210453033447,
      "learning_rate": 9.67277154351048e-06,
      "loss": 0.6369,
      "step": 762200
    },
    {
      "epoch": 8.069468190407632,
      "grad_norm": 4.6840925216674805,
      "learning_rate": 9.670124920601313e-06,
      "loss": 0.6309,
      "step": 762250
    },
    {
      "epoch": 8.069997512187634,
      "grad_norm": 4.715816020965576,
      "learning_rate": 9.667478297692145e-06,
      "loss": 0.6467,
      "step": 762300
    },
    {
      "epoch": 8.070526833967637,
      "grad_norm": 4.090597152709961,
      "learning_rate": 9.664831674782977e-06,
      "loss": 0.6393,
      "step": 762350
    },
    {
      "epoch": 8.071056155747641,
      "grad_norm": 4.811348915100098,
      "learning_rate": 9.66218505187381e-06,
      "loss": 0.6422,
      "step": 762400
    },
    {
      "epoch": 8.071585477527643,
      "grad_norm": 4.664212226867676,
      "learning_rate": 9.659538428964642e-06,
      "loss": 0.6316,
      "step": 762450
    },
    {
      "epoch": 8.072114799307647,
      "grad_norm": 4.153694152832031,
      "learning_rate": 9.656891806055473e-06,
      "loss": 0.6434,
      "step": 762500
    },
    {
      "epoch": 8.072114799307647,
      "eval_loss": 0.39435940980911255,
      "eval_runtime": 46.5236,
      "eval_samples_per_second": 3609.566,
      "eval_steps_per_second": 451.212,
      "step": 762500
    },
    {
      "epoch": 8.07264412108765,
      "grad_norm": 4.920633792877197,
      "learning_rate": 9.654245183146305e-06,
      "loss": 0.6324,
      "step": 762550
    },
    {
      "epoch": 8.073173442867654,
      "grad_norm": 4.295210838317871,
      "learning_rate": 9.651598560237138e-06,
      "loss": 0.6354,
      "step": 762600
    },
    {
      "epoch": 8.073702764647656,
      "grad_norm": 4.37418270111084,
      "learning_rate": 9.64895193732797e-06,
      "loss": 0.6543,
      "step": 762650
    },
    {
      "epoch": 8.07423208642766,
      "grad_norm": 4.6456499099731445,
      "learning_rate": 9.646305314418803e-06,
      "loss": 0.6367,
      "step": 762700
    },
    {
      "epoch": 8.074761408207664,
      "grad_norm": 4.133401393890381,
      "learning_rate": 9.643658691509633e-06,
      "loss": 0.644,
      "step": 762750
    },
    {
      "epoch": 8.075290729987668,
      "grad_norm": 4.729471683502197,
      "learning_rate": 9.641012068600466e-06,
      "loss": 0.6375,
      "step": 762800
    },
    {
      "epoch": 8.07582005176767,
      "grad_norm": 4.442929744720459,
      "learning_rate": 9.638365445691298e-06,
      "loss": 0.6527,
      "step": 762850
    },
    {
      "epoch": 8.076349373547673,
      "grad_norm": 4.822944641113281,
      "learning_rate": 9.63571882278213e-06,
      "loss": 0.639,
      "step": 762900
    },
    {
      "epoch": 8.076878695327677,
      "grad_norm": 4.567811489105225,
      "learning_rate": 9.633072199872963e-06,
      "loss": 0.6498,
      "step": 762950
    },
    {
      "epoch": 8.07740801710768,
      "grad_norm": 4.230302810668945,
      "learning_rate": 9.630425576963795e-06,
      "loss": 0.6372,
      "step": 763000
    },
    {
      "epoch": 8.07740801710768,
      "eval_loss": 0.3938744068145752,
      "eval_runtime": 46.4168,
      "eval_samples_per_second": 3617.872,
      "eval_steps_per_second": 452.25,
      "step": 763000
    },
    {
      "epoch": 8.077937338887683,
      "grad_norm": 4.487502574920654,
      "learning_rate": 9.627778954054626e-06,
      "loss": 0.6513,
      "step": 763050
    },
    {
      "epoch": 8.078466660667686,
      "grad_norm": 5.055052280426025,
      "learning_rate": 9.625132331145458e-06,
      "loss": 0.6453,
      "step": 763100
    },
    {
      "epoch": 8.07899598244769,
      "grad_norm": 4.892519474029541,
      "learning_rate": 9.622485708236291e-06,
      "loss": 0.63,
      "step": 763150
    },
    {
      "epoch": 8.079525304227692,
      "grad_norm": 4.213498592376709,
      "learning_rate": 9.619839085327123e-06,
      "loss": 0.6417,
      "step": 763200
    },
    {
      "epoch": 8.080054626007696,
      "grad_norm": 4.530184745788574,
      "learning_rate": 9.617192462417956e-06,
      "loss": 0.6388,
      "step": 763250
    },
    {
      "epoch": 8.0805839477877,
      "grad_norm": 4.528791427612305,
      "learning_rate": 9.614545839508788e-06,
      "loss": 0.6429,
      "step": 763300
    },
    {
      "epoch": 8.081113269567703,
      "grad_norm": 4.645702838897705,
      "learning_rate": 9.611899216599619e-06,
      "loss": 0.6306,
      "step": 763350
    },
    {
      "epoch": 8.081642591347705,
      "grad_norm": 4.344238758087158,
      "learning_rate": 9.609252593690451e-06,
      "loss": 0.6402,
      "step": 763400
    },
    {
      "epoch": 8.08217191312771,
      "grad_norm": 4.598743915557861,
      "learning_rate": 9.606605970781284e-06,
      "loss": 0.6291,
      "step": 763450
    },
    {
      "epoch": 8.082701234907713,
      "grad_norm": 4.966031551361084,
      "learning_rate": 9.603959347872116e-06,
      "loss": 0.635,
      "step": 763500
    },
    {
      "epoch": 8.082701234907713,
      "eval_loss": 0.393873929977417,
      "eval_runtime": 46.4521,
      "eval_samples_per_second": 3615.121,
      "eval_steps_per_second": 451.906,
      "step": 763500
    },
    {
      "epoch": 8.083230556687717,
      "grad_norm": 4.969424724578857,
      "learning_rate": 9.601312724962948e-06,
      "loss": 0.6415,
      "step": 763550
    },
    {
      "epoch": 8.083759878467719,
      "grad_norm": 4.429182052612305,
      "learning_rate": 9.598666102053779e-06,
      "loss": 0.6443,
      "step": 763600
    },
    {
      "epoch": 8.084289200247722,
      "grad_norm": 4.534343719482422,
      "learning_rate": 9.596019479144612e-06,
      "loss": 0.6423,
      "step": 763650
    },
    {
      "epoch": 8.084818522027726,
      "grad_norm": 4.583320617675781,
      "learning_rate": 9.593372856235444e-06,
      "loss": 0.6381,
      "step": 763700
    },
    {
      "epoch": 8.08534784380773,
      "grad_norm": 3.9528634548187256,
      "learning_rate": 9.590726233326276e-06,
      "loss": 0.6386,
      "step": 763750
    },
    {
      "epoch": 8.085877165587732,
      "grad_norm": 4.490630149841309,
      "learning_rate": 9.588079610417109e-06,
      "loss": 0.6417,
      "step": 763800
    },
    {
      "epoch": 8.086406487367736,
      "grad_norm": 4.364992141723633,
      "learning_rate": 9.585432987507941e-06,
      "loss": 0.6296,
      "step": 763850
    },
    {
      "epoch": 8.08693580914774,
      "grad_norm": 4.627274990081787,
      "learning_rate": 9.582786364598772e-06,
      "loss": 0.6402,
      "step": 763900
    },
    {
      "epoch": 8.087465130927741,
      "grad_norm": 4.51879358291626,
      "learning_rate": 9.580139741689604e-06,
      "loss": 0.6433,
      "step": 763950
    },
    {
      "epoch": 8.087994452707745,
      "grad_norm": 4.876502990722656,
      "learning_rate": 9.577493118780437e-06,
      "loss": 0.6471,
      "step": 764000
    },
    {
      "epoch": 8.087994452707745,
      "eval_loss": 0.39352256059646606,
      "eval_runtime": 46.4998,
      "eval_samples_per_second": 3611.412,
      "eval_steps_per_second": 451.443,
      "step": 764000
    },
    {
      "epoch": 8.088523774487749,
      "grad_norm": 4.312343597412109,
      "learning_rate": 9.574846495871269e-06,
      "loss": 0.6512,
      "step": 764050
    },
    {
      "epoch": 8.089053096267753,
      "grad_norm": 4.324471950531006,
      "learning_rate": 9.572252805420284e-06,
      "loss": 0.639,
      "step": 764100
    },
    {
      "epoch": 8.089582418047755,
      "grad_norm": 4.2932000160217285,
      "learning_rate": 9.569606182511116e-06,
      "loss": 0.6368,
      "step": 764150
    },
    {
      "epoch": 8.090111739827758,
      "grad_norm": 4.260549545288086,
      "learning_rate": 9.566959559601949e-06,
      "loss": 0.649,
      "step": 764200
    },
    {
      "epoch": 8.090641061607762,
      "grad_norm": 4.53863000869751,
      "learning_rate": 9.564312936692781e-06,
      "loss": 0.6373,
      "step": 764250
    },
    {
      "epoch": 8.091170383387766,
      "grad_norm": 4.505139350891113,
      "learning_rate": 9.561666313783613e-06,
      "loss": 0.638,
      "step": 764300
    },
    {
      "epoch": 8.091699705167768,
      "grad_norm": 4.279262542724609,
      "learning_rate": 9.559019690874444e-06,
      "loss": 0.6431,
      "step": 764350
    },
    {
      "epoch": 8.092229026947772,
      "grad_norm": 4.416182041168213,
      "learning_rate": 9.556373067965277e-06,
      "loss": 0.6409,
      "step": 764400
    },
    {
      "epoch": 8.092758348727775,
      "grad_norm": 4.092416763305664,
      "learning_rate": 9.553726445056109e-06,
      "loss": 0.6384,
      "step": 764450
    },
    {
      "epoch": 8.09328767050778,
      "grad_norm": 4.864838600158691,
      "learning_rate": 9.551079822146941e-06,
      "loss": 0.6332,
      "step": 764500
    },
    {
      "epoch": 8.09328767050778,
      "eval_loss": 0.39358797669410706,
      "eval_runtime": 46.463,
      "eval_samples_per_second": 3614.276,
      "eval_steps_per_second": 451.801,
      "step": 764500
    },
    {
      "epoch": 8.093816992287781,
      "grad_norm": 4.905313968658447,
      "learning_rate": 9.548433199237774e-06,
      "loss": 0.6353,
      "step": 764550
    },
    {
      "epoch": 8.094346314067785,
      "grad_norm": 4.676628112792969,
      "learning_rate": 9.545786576328604e-06,
      "loss": 0.639,
      "step": 764600
    },
    {
      "epoch": 8.094875635847789,
      "grad_norm": 4.551548004150391,
      "learning_rate": 9.543139953419437e-06,
      "loss": 0.638,
      "step": 764650
    },
    {
      "epoch": 8.09540495762779,
      "grad_norm": 4.479941368103027,
      "learning_rate": 9.54049333051027e-06,
      "loss": 0.6417,
      "step": 764700
    },
    {
      "epoch": 8.095934279407794,
      "grad_norm": 4.753757476806641,
      "learning_rate": 9.537846707601102e-06,
      "loss": 0.6342,
      "step": 764750
    },
    {
      "epoch": 8.096463601187798,
      "grad_norm": 4.576662540435791,
      "learning_rate": 9.535200084691934e-06,
      "loss": 0.6401,
      "step": 764800
    },
    {
      "epoch": 8.096992922967802,
      "grad_norm": 4.4108357429504395,
      "learning_rate": 9.532553461782767e-06,
      "loss": 0.6353,
      "step": 764850
    },
    {
      "epoch": 8.097522244747804,
      "grad_norm": 4.33636999130249,
      "learning_rate": 9.529906838873597e-06,
      "loss": 0.631,
      "step": 764900
    },
    {
      "epoch": 8.098051566527808,
      "grad_norm": 4.501407623291016,
      "learning_rate": 9.52726021596443e-06,
      "loss": 0.6431,
      "step": 764950
    },
    {
      "epoch": 8.098580888307811,
      "grad_norm": 4.991547584533691,
      "learning_rate": 9.524613593055262e-06,
      "loss": 0.6381,
      "step": 765000
    },
    {
      "epoch": 8.098580888307811,
      "eval_loss": 0.393697053194046,
      "eval_runtime": 46.4938,
      "eval_samples_per_second": 3611.882,
      "eval_steps_per_second": 451.501,
      "step": 765000
    },
    {
      "epoch": 8.099110210087815,
      "grad_norm": 4.778820991516113,
      "learning_rate": 9.521966970146094e-06,
      "loss": 0.6387,
      "step": 765050
    },
    {
      "epoch": 8.099639531867817,
      "grad_norm": 4.552370548248291,
      "learning_rate": 9.519320347236927e-06,
      "loss": 0.6404,
      "step": 765100
    },
    {
      "epoch": 8.100168853647821,
      "grad_norm": 4.463687419891357,
      "learning_rate": 9.51667372432776e-06,
      "loss": 0.6264,
      "step": 765150
    },
    {
      "epoch": 8.100698175427825,
      "grad_norm": 4.701844692230225,
      "learning_rate": 9.51402710141859e-06,
      "loss": 0.6364,
      "step": 765200
    },
    {
      "epoch": 8.101227497207828,
      "grad_norm": 4.462975025177002,
      "learning_rate": 9.511380478509422e-06,
      "loss": 0.6338,
      "step": 765250
    },
    {
      "epoch": 8.10175681898783,
      "grad_norm": 4.557999610900879,
      "learning_rate": 9.508733855600255e-06,
      "loss": 0.6369,
      "step": 765300
    },
    {
      "epoch": 8.102286140767834,
      "grad_norm": 4.974426746368408,
      "learning_rate": 9.506087232691087e-06,
      "loss": 0.6395,
      "step": 765350
    },
    {
      "epoch": 8.102815462547838,
      "grad_norm": 4.479532241821289,
      "learning_rate": 9.50344060978192e-06,
      "loss": 0.6523,
      "step": 765400
    },
    {
      "epoch": 8.10334478432784,
      "grad_norm": 4.327022075653076,
      "learning_rate": 9.50079398687275e-06,
      "loss": 0.6279,
      "step": 765450
    },
    {
      "epoch": 8.103874106107844,
      "grad_norm": 4.533385753631592,
      "learning_rate": 9.498147363963583e-06,
      "loss": 0.6367,
      "step": 765500
    },
    {
      "epoch": 8.103874106107844,
      "eval_loss": 0.39283955097198486,
      "eval_runtime": 46.4682,
      "eval_samples_per_second": 3613.872,
      "eval_steps_per_second": 451.75,
      "step": 765500
    },
    {
      "epoch": 8.104403427887847,
      "grad_norm": 4.312249660491943,
      "learning_rate": 9.495500741054415e-06,
      "loss": 0.6281,
      "step": 765550
    },
    {
      "epoch": 8.104932749667851,
      "grad_norm": 4.657563209533691,
      "learning_rate": 9.492854118145248e-06,
      "loss": 0.6307,
      "step": 765600
    },
    {
      "epoch": 8.105462071447853,
      "grad_norm": 4.771195411682129,
      "learning_rate": 9.49020749523608e-06,
      "loss": 0.64,
      "step": 765650
    },
    {
      "epoch": 8.105991393227857,
      "grad_norm": 4.493686199188232,
      "learning_rate": 9.487560872326912e-06,
      "loss": 0.6479,
      "step": 765700
    },
    {
      "epoch": 8.10652071500786,
      "grad_norm": 4.400123596191406,
      "learning_rate": 9.484914249417743e-06,
      "loss": 0.6521,
      "step": 765750
    },
    {
      "epoch": 8.107050036787864,
      "grad_norm": 3.898815393447876,
      "learning_rate": 9.482267626508575e-06,
      "loss": 0.6288,
      "step": 765800
    },
    {
      "epoch": 8.107579358567866,
      "grad_norm": 4.5766496658325195,
      "learning_rate": 9.479621003599408e-06,
      "loss": 0.6454,
      "step": 765850
    },
    {
      "epoch": 8.10810868034787,
      "grad_norm": 4.431222915649414,
      "learning_rate": 9.47697438069024e-06,
      "loss": 0.6388,
      "step": 765900
    },
    {
      "epoch": 8.108638002127874,
      "grad_norm": 4.851330757141113,
      "learning_rate": 9.474327757781073e-06,
      "loss": 0.6411,
      "step": 765950
    },
    {
      "epoch": 8.109167323907878,
      "grad_norm": 5.087292671203613,
      "learning_rate": 9.471681134871905e-06,
      "loss": 0.6452,
      "step": 766000
    },
    {
      "epoch": 8.109167323907878,
      "eval_loss": 0.39358723163604736,
      "eval_runtime": 46.4836,
      "eval_samples_per_second": 3612.674,
      "eval_steps_per_second": 451.6,
      "step": 766000
    },
    {
      "epoch": 8.10969664568788,
      "grad_norm": 4.404111862182617,
      "learning_rate": 9.469034511962736e-06,
      "loss": 0.6376,
      "step": 766050
    },
    {
      "epoch": 8.110225967467883,
      "grad_norm": 4.47321081161499,
      "learning_rate": 9.466387889053568e-06,
      "loss": 0.627,
      "step": 766100
    },
    {
      "epoch": 8.110755289247887,
      "grad_norm": 4.504082202911377,
      "learning_rate": 9.463794198602585e-06,
      "loss": 0.6449,
      "step": 766150
    },
    {
      "epoch": 8.11128461102789,
      "grad_norm": 4.237272262573242,
      "learning_rate": 9.461147575693415e-06,
      "loss": 0.6465,
      "step": 766200
    },
    {
      "epoch": 8.111813932807893,
      "grad_norm": 4.640537261962891,
      "learning_rate": 9.458500952784248e-06,
      "loss": 0.6335,
      "step": 766250
    },
    {
      "epoch": 8.112343254587897,
      "grad_norm": 4.6143107414245605,
      "learning_rate": 9.45585432987508e-06,
      "loss": 0.6514,
      "step": 766300
    },
    {
      "epoch": 8.1128725763679,
      "grad_norm": 4.677231788635254,
      "learning_rate": 9.453207706965913e-06,
      "loss": 0.6334,
      "step": 766350
    },
    {
      "epoch": 8.113401898147902,
      "grad_norm": 4.036345481872559,
      "learning_rate": 9.450561084056745e-06,
      "loss": 0.6279,
      "step": 766400
    },
    {
      "epoch": 8.113931219927906,
      "grad_norm": 4.743404865264893,
      "learning_rate": 9.447914461147576e-06,
      "loss": 0.6467,
      "step": 766450
    },
    {
      "epoch": 8.11446054170791,
      "grad_norm": 4.531536102294922,
      "learning_rate": 9.445267838238408e-06,
      "loss": 0.6438,
      "step": 766500
    },
    {
      "epoch": 8.11446054170791,
      "eval_loss": 0.39413580298423767,
      "eval_runtime": 46.6015,
      "eval_samples_per_second": 3603.533,
      "eval_steps_per_second": 450.458,
      "step": 766500
    },
    {
      "epoch": 8.114989863487914,
      "grad_norm": 4.017765998840332,
      "learning_rate": 9.44262121532924e-06,
      "loss": 0.6282,
      "step": 766550
    },
    {
      "epoch": 8.115519185267916,
      "grad_norm": 4.867903232574463,
      "learning_rate": 9.439974592420073e-06,
      "loss": 0.64,
      "step": 766600
    },
    {
      "epoch": 8.11604850704792,
      "grad_norm": 4.645280838012695,
      "learning_rate": 9.437327969510905e-06,
      "loss": 0.6386,
      "step": 766650
    },
    {
      "epoch": 8.116577828827923,
      "grad_norm": 4.373119831085205,
      "learning_rate": 9.434681346601738e-06,
      "loss": 0.6407,
      "step": 766700
    },
    {
      "epoch": 8.117107150607927,
      "grad_norm": 4.590184211730957,
      "learning_rate": 9.432034723692568e-06,
      "loss": 0.6275,
      "step": 766750
    },
    {
      "epoch": 8.117636472387929,
      "grad_norm": 4.585028171539307,
      "learning_rate": 9.4293881007834e-06,
      "loss": 0.6362,
      "step": 766800
    },
    {
      "epoch": 8.118165794167933,
      "grad_norm": 4.647043704986572,
      "learning_rate": 9.426741477874233e-06,
      "loss": 0.6437,
      "step": 766850
    },
    {
      "epoch": 8.118695115947936,
      "grad_norm": 4.8425397872924805,
      "learning_rate": 9.424094854965066e-06,
      "loss": 0.6354,
      "step": 766900
    },
    {
      "epoch": 8.119224437727938,
      "grad_norm": 4.162595748901367,
      "learning_rate": 9.421448232055898e-06,
      "loss": 0.6306,
      "step": 766950
    },
    {
      "epoch": 8.119753759507942,
      "grad_norm": 4.640427112579346,
      "learning_rate": 9.41880160914673e-06,
      "loss": 0.6378,
      "step": 767000
    },
    {
      "epoch": 8.119753759507942,
      "eval_loss": 0.3941045105457306,
      "eval_runtime": 46.47,
      "eval_samples_per_second": 3613.727,
      "eval_steps_per_second": 451.732,
      "step": 767000
    },
    {
      "epoch": 8.120283081287946,
      "grad_norm": 4.802505970001221,
      "learning_rate": 9.416154986237561e-06,
      "loss": 0.6373,
      "step": 767050
    },
    {
      "epoch": 8.12081240306795,
      "grad_norm": 5.017540454864502,
      "learning_rate": 9.413508363328394e-06,
      "loss": 0.6447,
      "step": 767100
    },
    {
      "epoch": 8.121341724847952,
      "grad_norm": 4.490420818328857,
      "learning_rate": 9.410861740419226e-06,
      "loss": 0.6413,
      "step": 767150
    },
    {
      "epoch": 8.121871046627955,
      "grad_norm": 4.280056953430176,
      "learning_rate": 9.408215117510058e-06,
      "loss": 0.6362,
      "step": 767200
    },
    {
      "epoch": 8.122400368407959,
      "grad_norm": 4.640720367431641,
      "learning_rate": 9.40556849460089e-06,
      "loss": 0.6355,
      "step": 767250
    },
    {
      "epoch": 8.122929690187963,
      "grad_norm": 4.507717132568359,
      "learning_rate": 9.402921871691721e-06,
      "loss": 0.6366,
      "step": 767300
    },
    {
      "epoch": 8.123459011967965,
      "grad_norm": 4.651538372039795,
      "learning_rate": 9.400275248782554e-06,
      "loss": 0.6348,
      "step": 767350
    },
    {
      "epoch": 8.123988333747969,
      "grad_norm": 4.256232738494873,
      "learning_rate": 9.397628625873386e-06,
      "loss": 0.6466,
      "step": 767400
    },
    {
      "epoch": 8.124517655527972,
      "grad_norm": 4.408466815948486,
      "learning_rate": 9.394982002964219e-06,
      "loss": 0.6264,
      "step": 767450
    },
    {
      "epoch": 8.125046977307976,
      "grad_norm": 4.851482391357422,
      "learning_rate": 9.392335380055051e-06,
      "loss": 0.6476,
      "step": 767500
    },
    {
      "epoch": 8.125046977307976,
      "eval_loss": 0.39335715770721436,
      "eval_runtime": 46.5333,
      "eval_samples_per_second": 3608.811,
      "eval_steps_per_second": 451.117,
      "step": 767500
    },
    {
      "epoch": 8.125576299087978,
      "grad_norm": 4.6878509521484375,
      "learning_rate": 9.389688757145883e-06,
      "loss": 0.6484,
      "step": 767550
    },
    {
      "epoch": 8.126105620867982,
      "grad_norm": 4.643283843994141,
      "learning_rate": 9.387042134236714e-06,
      "loss": 0.6555,
      "step": 767600
    },
    {
      "epoch": 8.126634942647986,
      "grad_norm": 4.451166152954102,
      "learning_rate": 9.384395511327547e-06,
      "loss": 0.6386,
      "step": 767650
    },
    {
      "epoch": 8.127164264427988,
      "grad_norm": 4.80692720413208,
      "learning_rate": 9.381748888418379e-06,
      "loss": 0.6426,
      "step": 767700
    },
    {
      "epoch": 8.127693586207991,
      "grad_norm": 4.546894073486328,
      "learning_rate": 9.379102265509211e-06,
      "loss": 0.6334,
      "step": 767750
    },
    {
      "epoch": 8.128222907987995,
      "grad_norm": 4.161050319671631,
      "learning_rate": 9.376455642600044e-06,
      "loss": 0.6519,
      "step": 767800
    },
    {
      "epoch": 8.128752229767999,
      "grad_norm": 4.695696830749512,
      "learning_rate": 9.373809019690876e-06,
      "loss": 0.6485,
      "step": 767850
    },
    {
      "epoch": 8.129281551548,
      "grad_norm": 4.496218681335449,
      "learning_rate": 9.371162396781707e-06,
      "loss": 0.6385,
      "step": 767900
    },
    {
      "epoch": 8.129810873328005,
      "grad_norm": 4.386775970458984,
      "learning_rate": 9.36851577387254e-06,
      "loss": 0.6376,
      "step": 767950
    },
    {
      "epoch": 8.130340195108008,
      "grad_norm": 4.474361419677734,
      "learning_rate": 9.365869150963372e-06,
      "loss": 0.6393,
      "step": 768000
    },
    {
      "epoch": 8.130340195108008,
      "eval_loss": 0.39350399374961853,
      "eval_runtime": 46.452,
      "eval_samples_per_second": 3615.126,
      "eval_steps_per_second": 451.907,
      "step": 768000
    },
    {
      "epoch": 8.130869516888012,
      "grad_norm": 4.3157219886779785,
      "learning_rate": 9.363222528054204e-06,
      "loss": 0.6376,
      "step": 768050
    },
    {
      "epoch": 8.131398838668014,
      "grad_norm": 4.726548671722412,
      "learning_rate": 9.360575905145037e-06,
      "loss": 0.646,
      "step": 768100
    },
    {
      "epoch": 8.131928160448018,
      "grad_norm": 5.062918186187744,
      "learning_rate": 9.357982214694051e-06,
      "loss": 0.6457,
      "step": 768150
    },
    {
      "epoch": 8.132457482228022,
      "grad_norm": 4.587334632873535,
      "learning_rate": 9.355335591784884e-06,
      "loss": 0.6224,
      "step": 768200
    },
    {
      "epoch": 8.132986804008025,
      "grad_norm": 4.653095722198486,
      "learning_rate": 9.352688968875716e-06,
      "loss": 0.6425,
      "step": 768250
    },
    {
      "epoch": 8.133516125788027,
      "grad_norm": 4.438612461090088,
      "learning_rate": 9.350042345966547e-06,
      "loss": 0.642,
      "step": 768300
    },
    {
      "epoch": 8.134045447568031,
      "grad_norm": 4.3846540451049805,
      "learning_rate": 9.34739572305738e-06,
      "loss": 0.6383,
      "step": 768350
    },
    {
      "epoch": 8.134574769348035,
      "grad_norm": 4.050980567932129,
      "learning_rate": 9.344749100148212e-06,
      "loss": 0.6425,
      "step": 768400
    },
    {
      "epoch": 8.135104091128037,
      "grad_norm": 4.89589262008667,
      "learning_rate": 9.342102477239044e-06,
      "loss": 0.6358,
      "step": 768450
    },
    {
      "epoch": 8.13563341290804,
      "grad_norm": 4.761752605438232,
      "learning_rate": 9.339455854329876e-06,
      "loss": 0.624,
      "step": 768500
    },
    {
      "epoch": 8.13563341290804,
      "eval_loss": 0.3930443823337555,
      "eval_runtime": 46.4644,
      "eval_samples_per_second": 3614.164,
      "eval_steps_per_second": 451.787,
      "step": 768500
    },
    {
      "epoch": 8.136162734688044,
      "grad_norm": 4.534792423248291,
      "learning_rate": 9.336809231420709e-06,
      "loss": 0.6523,
      "step": 768550
    },
    {
      "epoch": 8.136692056468048,
      "grad_norm": 4.4264445304870605,
      "learning_rate": 9.33416260851154e-06,
      "loss": 0.6423,
      "step": 768600
    },
    {
      "epoch": 8.13722137824805,
      "grad_norm": 4.734604835510254,
      "learning_rate": 9.331515985602372e-06,
      "loss": 0.6355,
      "step": 768650
    },
    {
      "epoch": 8.137750700028054,
      "grad_norm": 4.115352153778076,
      "learning_rate": 9.328869362693204e-06,
      "loss": 0.6453,
      "step": 768700
    },
    {
      "epoch": 8.138280021808058,
      "grad_norm": 4.698764324188232,
      "learning_rate": 9.326222739784037e-06,
      "loss": 0.643,
      "step": 768750
    },
    {
      "epoch": 8.138809343588061,
      "grad_norm": 4.382169723510742,
      "learning_rate": 9.323576116874869e-06,
      "loss": 0.6411,
      "step": 768800
    },
    {
      "epoch": 8.139338665368063,
      "grad_norm": 5.157798767089844,
      "learning_rate": 9.320929493965702e-06,
      "loss": 0.6297,
      "step": 768850
    },
    {
      "epoch": 8.139867987148067,
      "grad_norm": 4.951311111450195,
      "learning_rate": 9.318282871056532e-06,
      "loss": 0.643,
      "step": 768900
    },
    {
      "epoch": 8.14039730892807,
      "grad_norm": 4.868557453155518,
      "learning_rate": 9.315636248147365e-06,
      "loss": 0.6427,
      "step": 768950
    },
    {
      "epoch": 8.140926630708075,
      "grad_norm": 4.9151835441589355,
      "learning_rate": 9.312989625238197e-06,
      "loss": 0.637,
      "step": 769000
    },
    {
      "epoch": 8.140926630708075,
      "eval_loss": 0.3923132121562958,
      "eval_runtime": 46.4076,
      "eval_samples_per_second": 3618.585,
      "eval_steps_per_second": 452.339,
      "step": 769000
    },
    {
      "epoch": 8.141455952488077,
      "grad_norm": 4.6500959396362305,
      "learning_rate": 9.31034300232903e-06,
      "loss": 0.6442,
      "step": 769050
    },
    {
      "epoch": 8.14198527426808,
      "grad_norm": 4.435465335845947,
      "learning_rate": 9.307696379419862e-06,
      "loss": 0.6302,
      "step": 769100
    },
    {
      "epoch": 8.142514596048084,
      "grad_norm": 4.740881443023682,
      "learning_rate": 9.305049756510693e-06,
      "loss": 0.6451,
      "step": 769150
    },
    {
      "epoch": 8.143043917828086,
      "grad_norm": 4.44266414642334,
      "learning_rate": 9.302403133601525e-06,
      "loss": 0.6461,
      "step": 769200
    },
    {
      "epoch": 8.14357323960809,
      "grad_norm": 4.154836654663086,
      "learning_rate": 9.299756510692357e-06,
      "loss": 0.6429,
      "step": 769250
    },
    {
      "epoch": 8.144102561388094,
      "grad_norm": 4.417788028717041,
      "learning_rate": 9.29710988778319e-06,
      "loss": 0.6478,
      "step": 769300
    },
    {
      "epoch": 8.144631883168097,
      "grad_norm": 4.631531238555908,
      "learning_rate": 9.294463264874022e-06,
      "loss": 0.6333,
      "step": 769350
    },
    {
      "epoch": 8.1451612049481,
      "grad_norm": 4.223473072052002,
      "learning_rate": 9.291816641964855e-06,
      "loss": 0.6421,
      "step": 769400
    },
    {
      "epoch": 8.145690526728103,
      "grad_norm": 4.8220367431640625,
      "learning_rate": 9.289170019055685e-06,
      "loss": 0.6344,
      "step": 769450
    },
    {
      "epoch": 8.146219848508107,
      "grad_norm": 4.716633319854736,
      "learning_rate": 9.286523396146518e-06,
      "loss": 0.6387,
      "step": 769500
    },
    {
      "epoch": 8.146219848508107,
      "eval_loss": 0.39252814650535583,
      "eval_runtime": 46.4296,
      "eval_samples_per_second": 3616.874,
      "eval_steps_per_second": 452.125,
      "step": 769500
    },
    {
      "epoch": 8.14674917028811,
      "grad_norm": 4.819116115570068,
      "learning_rate": 9.28387677323735e-06,
      "loss": 0.6324,
      "step": 769550
    },
    {
      "epoch": 8.147278492068112,
      "grad_norm": 4.837324619293213,
      "learning_rate": 9.281230150328183e-06,
      "loss": 0.6347,
      "step": 769600
    },
    {
      "epoch": 8.147807813848116,
      "grad_norm": 4.502360820770264,
      "learning_rate": 9.278583527419015e-06,
      "loss": 0.6396,
      "step": 769650
    },
    {
      "epoch": 8.14833713562812,
      "grad_norm": 4.619776725769043,
      "learning_rate": 9.275936904509847e-06,
      "loss": 0.6433,
      "step": 769700
    },
    {
      "epoch": 8.148866457408124,
      "grad_norm": 4.601037979125977,
      "learning_rate": 9.273290281600678e-06,
      "loss": 0.6384,
      "step": 769750
    },
    {
      "epoch": 8.149395779188126,
      "grad_norm": 4.592579364776611,
      "learning_rate": 9.27064365869151e-06,
      "loss": 0.6394,
      "step": 769800
    },
    {
      "epoch": 8.14992510096813,
      "grad_norm": 4.880504131317139,
      "learning_rate": 9.267997035782343e-06,
      "loss": 0.6452,
      "step": 769850
    },
    {
      "epoch": 8.150454422748133,
      "grad_norm": 4.614853858947754,
      "learning_rate": 9.265350412873175e-06,
      "loss": 0.65,
      "step": 769900
    },
    {
      "epoch": 8.150983744528135,
      "grad_norm": 5.100149631500244,
      "learning_rate": 9.262703789964008e-06,
      "loss": 0.638,
      "step": 769950
    },
    {
      "epoch": 8.151513066308139,
      "grad_norm": 4.545016288757324,
      "learning_rate": 9.260057167054838e-06,
      "loss": 0.647,
      "step": 770000
    },
    {
      "epoch": 8.151513066308139,
      "eval_loss": 0.39232683181762695,
      "eval_runtime": 46.452,
      "eval_samples_per_second": 3615.129,
      "eval_steps_per_second": 451.907,
      "step": 770000
    },
    {
      "epoch": 8.152042388088143,
      "grad_norm": 4.385837554931641,
      "learning_rate": 9.257410544145669e-06,
      "loss": 0.6434,
      "step": 770050
    },
    {
      "epoch": 8.152571709868146,
      "grad_norm": 4.554249286651611,
      "learning_rate": 9.254763921236502e-06,
      "loss": 0.63,
      "step": 770100
    },
    {
      "epoch": 8.153101031648148,
      "grad_norm": 5.264060974121094,
      "learning_rate": 9.252170230785518e-06,
      "loss": 0.6424,
      "step": 770150
    },
    {
      "epoch": 8.153630353428152,
      "grad_norm": 4.897304058074951,
      "learning_rate": 9.24952360787635e-06,
      "loss": 0.6406,
      "step": 770200
    },
    {
      "epoch": 8.154159675208156,
      "grad_norm": 4.50430154800415,
      "learning_rate": 9.246876984967183e-06,
      "loss": 0.6343,
      "step": 770250
    },
    {
      "epoch": 8.15468899698816,
      "grad_norm": 4.883552074432373,
      "learning_rate": 9.244230362058015e-06,
      "loss": 0.635,
      "step": 770300
    },
    {
      "epoch": 8.155218318768162,
      "grad_norm": 4.476830005645752,
      "learning_rate": 9.241583739148848e-06,
      "loss": 0.6396,
      "step": 770350
    },
    {
      "epoch": 8.155747640548165,
      "grad_norm": 4.827061176300049,
      "learning_rate": 9.23893711623968e-06,
      "loss": 0.6496,
      "step": 770400
    },
    {
      "epoch": 8.15627696232817,
      "grad_norm": 4.668647289276123,
      "learning_rate": 9.23629049333051e-06,
      "loss": 0.6455,
      "step": 770450
    },
    {
      "epoch": 8.156806284108173,
      "grad_norm": 4.215256214141846,
      "learning_rate": 9.233643870421343e-06,
      "loss": 0.6376,
      "step": 770500
    },
    {
      "epoch": 8.156806284108173,
      "eval_loss": 0.3924736976623535,
      "eval_runtime": 46.5064,
      "eval_samples_per_second": 3610.902,
      "eval_steps_per_second": 451.379,
      "step": 770500
    },
    {
      "epoch": 8.157335605888175,
      "grad_norm": 4.633810520172119,
      "learning_rate": 9.230997247512175e-06,
      "loss": 0.6319,
      "step": 770550
    },
    {
      "epoch": 8.157864927668179,
      "grad_norm": 4.686535358428955,
      "learning_rate": 9.228350624603008e-06,
      "loss": 0.641,
      "step": 770600
    },
    {
      "epoch": 8.158394249448182,
      "grad_norm": 4.62129545211792,
      "learning_rate": 9.225704001693839e-06,
      "loss": 0.6495,
      "step": 770650
    },
    {
      "epoch": 8.158923571228184,
      "grad_norm": 4.994142055511475,
      "learning_rate": 9.223057378784671e-06,
      "loss": 0.6331,
      "step": 770700
    },
    {
      "epoch": 8.159452893008188,
      "grad_norm": 4.093644618988037,
      "learning_rate": 9.220410755875503e-06,
      "loss": 0.6451,
      "step": 770750
    },
    {
      "epoch": 8.159982214788192,
      "grad_norm": 4.716646671295166,
      "learning_rate": 9.217764132966334e-06,
      "loss": 0.6459,
      "step": 770800
    },
    {
      "epoch": 8.160511536568196,
      "grad_norm": 4.7921013832092285,
      "learning_rate": 9.215117510057167e-06,
      "loss": 0.642,
      "step": 770850
    },
    {
      "epoch": 8.161040858348198,
      "grad_norm": 4.215222358703613,
      "learning_rate": 9.212470887147999e-06,
      "loss": 0.6329,
      "step": 770900
    },
    {
      "epoch": 8.161570180128201,
      "grad_norm": 4.771279811859131,
      "learning_rate": 9.209824264238831e-06,
      "loss": 0.6445,
      "step": 770950
    },
    {
      "epoch": 8.162099501908205,
      "grad_norm": 4.173974514007568,
      "learning_rate": 9.207177641329664e-06,
      "loss": 0.6331,
      "step": 771000
    },
    {
      "epoch": 8.162099501908205,
      "eval_loss": 0.39281049370765686,
      "eval_runtime": 46.4061,
      "eval_samples_per_second": 3618.706,
      "eval_steps_per_second": 452.354,
      "step": 771000
    },
    {
      "epoch": 8.162628823688209,
      "grad_norm": 4.35588264465332,
      "learning_rate": 9.204531018420494e-06,
      "loss": 0.643,
      "step": 771050
    },
    {
      "epoch": 8.163158145468211,
      "grad_norm": 4.517874240875244,
      "learning_rate": 9.201884395511327e-06,
      "loss": 0.6503,
      "step": 771100
    },
    {
      "epoch": 8.163687467248215,
      "grad_norm": 4.57079553604126,
      "learning_rate": 9.19923777260216e-06,
      "loss": 0.6488,
      "step": 771150
    },
    {
      "epoch": 8.164216789028218,
      "grad_norm": 4.099898815155029,
      "learning_rate": 9.196591149692992e-06,
      "loss": 0.6274,
      "step": 771200
    },
    {
      "epoch": 8.164746110808222,
      "grad_norm": 4.423507213592529,
      "learning_rate": 9.193944526783824e-06,
      "loss": 0.6448,
      "step": 771250
    },
    {
      "epoch": 8.165275432588224,
      "grad_norm": 4.401998996734619,
      "learning_rate": 9.191297903874656e-06,
      "loss": 0.6321,
      "step": 771300
    },
    {
      "epoch": 8.165804754368228,
      "grad_norm": 4.492178916931152,
      "learning_rate": 9.188651280965487e-06,
      "loss": 0.6479,
      "step": 771350
    },
    {
      "epoch": 8.166334076148232,
      "grad_norm": 4.502416133880615,
      "learning_rate": 9.18600465805632e-06,
      "loss": 0.6338,
      "step": 771400
    },
    {
      "epoch": 8.166863397928234,
      "grad_norm": 4.641325950622559,
      "learning_rate": 9.183358035147152e-06,
      "loss": 0.6404,
      "step": 771450
    },
    {
      "epoch": 8.167392719708237,
      "grad_norm": 3.9136648178100586,
      "learning_rate": 9.180711412237984e-06,
      "loss": 0.6422,
      "step": 771500
    },
    {
      "epoch": 8.167392719708237,
      "eval_loss": 0.3930046558380127,
      "eval_runtime": 46.5408,
      "eval_samples_per_second": 3608.23,
      "eval_steps_per_second": 451.045,
      "step": 771500
    },
    {
      "epoch": 8.167922041488241,
      "grad_norm": 4.608095169067383,
      "learning_rate": 9.178064789328817e-06,
      "loss": 0.6333,
      "step": 771550
    },
    {
      "epoch": 8.168451363268245,
      "grad_norm": 4.711923599243164,
      "learning_rate": 9.17541816641965e-06,
      "loss": 0.6398,
      "step": 771600
    },
    {
      "epoch": 8.168980685048247,
      "grad_norm": 4.518829345703125,
      "learning_rate": 9.17277154351048e-06,
      "loss": 0.6413,
      "step": 771650
    },
    {
      "epoch": 8.16951000682825,
      "grad_norm": 4.403777122497559,
      "learning_rate": 9.170124920601312e-06,
      "loss": 0.6362,
      "step": 771700
    },
    {
      "epoch": 8.170039328608254,
      "grad_norm": 4.632645130157471,
      "learning_rate": 9.167478297692145e-06,
      "loss": 0.638,
      "step": 771750
    },
    {
      "epoch": 8.170568650388258,
      "grad_norm": 4.540132999420166,
      "learning_rate": 9.164831674782977e-06,
      "loss": 0.6458,
      "step": 771800
    },
    {
      "epoch": 8.17109797216826,
      "grad_norm": 4.237030506134033,
      "learning_rate": 9.16218505187381e-06,
      "loss": 0.6298,
      "step": 771850
    },
    {
      "epoch": 8.171627293948264,
      "grad_norm": 5.003887176513672,
      "learning_rate": 9.15953842896464e-06,
      "loss": 0.6415,
      "step": 771900
    },
    {
      "epoch": 8.172156615728268,
      "grad_norm": 4.75156307220459,
      "learning_rate": 9.156891806055473e-06,
      "loss": 0.645,
      "step": 771950
    },
    {
      "epoch": 8.172685937508271,
      "grad_norm": 4.27316427230835,
      "learning_rate": 9.154245183146305e-06,
      "loss": 0.6444,
      "step": 772000
    },
    {
      "epoch": 8.172685937508271,
      "eval_loss": 0.39261987805366516,
      "eval_runtime": 46.4404,
      "eval_samples_per_second": 3616.036,
      "eval_steps_per_second": 452.021,
      "step": 772000
    },
    {
      "epoch": 8.173215259288273,
      "grad_norm": 4.95504903793335,
      "learning_rate": 9.151598560237138e-06,
      "loss": 0.6441,
      "step": 772050
    },
    {
      "epoch": 8.173744581068277,
      "grad_norm": 4.848572254180908,
      "learning_rate": 9.14895193732797e-06,
      "loss": 0.6363,
      "step": 772100
    },
    {
      "epoch": 8.174273902848281,
      "grad_norm": 4.277288913726807,
      "learning_rate": 9.146358246876985e-06,
      "loss": 0.634,
      "step": 772150
    },
    {
      "epoch": 8.174803224628285,
      "grad_norm": 4.509621620178223,
      "learning_rate": 9.143711623967817e-06,
      "loss": 0.638,
      "step": 772200
    },
    {
      "epoch": 8.175332546408287,
      "grad_norm": 4.362329483032227,
      "learning_rate": 9.14106500105865e-06,
      "loss": 0.6373,
      "step": 772250
    },
    {
      "epoch": 8.17586186818829,
      "grad_norm": 5.035405158996582,
      "learning_rate": 9.138418378149482e-06,
      "loss": 0.6322,
      "step": 772300
    },
    {
      "epoch": 8.176391189968294,
      "grad_norm": 4.375096797943115,
      "learning_rate": 9.135771755240313e-06,
      "loss": 0.6459,
      "step": 772350
    },
    {
      "epoch": 8.176920511748296,
      "grad_norm": 4.857452392578125,
      "learning_rate": 9.133125132331145e-06,
      "loss": 0.6434,
      "step": 772400
    },
    {
      "epoch": 8.1774498335283,
      "grad_norm": 4.4840240478515625,
      "learning_rate": 9.130478509421977e-06,
      "loss": 0.6353,
      "step": 772450
    },
    {
      "epoch": 8.177979155308304,
      "grad_norm": 4.968411922454834,
      "learning_rate": 9.12783188651281e-06,
      "loss": 0.6475,
      "step": 772500
    },
    {
      "epoch": 8.177979155308304,
      "eval_loss": 0.39296483993530273,
      "eval_runtime": 46.5184,
      "eval_samples_per_second": 3609.972,
      "eval_steps_per_second": 451.263,
      "step": 772500
    },
    {
      "epoch": 8.178508477088307,
      "grad_norm": 4.2104811668396,
      "learning_rate": 9.125185263603642e-06,
      "loss": 0.6336,
      "step": 772550
    },
    {
      "epoch": 8.17903779886831,
      "grad_norm": 4.628727912902832,
      "learning_rate": 9.122538640694475e-06,
      "loss": 0.6491,
      "step": 772600
    },
    {
      "epoch": 8.179567120648313,
      "grad_norm": 4.3505659103393555,
      "learning_rate": 9.119892017785305e-06,
      "loss": 0.6304,
      "step": 772650
    },
    {
      "epoch": 8.180096442428317,
      "grad_norm": 4.616582870483398,
      "learning_rate": 9.117245394876138e-06,
      "loss": 0.6355,
      "step": 772700
    },
    {
      "epoch": 8.18062576420832,
      "grad_norm": 4.46517276763916,
      "learning_rate": 9.11459877196697e-06,
      "loss": 0.6385,
      "step": 772750
    },
    {
      "epoch": 8.181155085988323,
      "grad_norm": 4.397549629211426,
      "learning_rate": 9.111952149057803e-06,
      "loss": 0.6401,
      "step": 772800
    },
    {
      "epoch": 8.181684407768326,
      "grad_norm": 4.625840187072754,
      "learning_rate": 9.109305526148635e-06,
      "loss": 0.6403,
      "step": 772850
    },
    {
      "epoch": 8.18221372954833,
      "grad_norm": 4.580021381378174,
      "learning_rate": 9.106658903239466e-06,
      "loss": 0.6294,
      "step": 772900
    },
    {
      "epoch": 8.182743051328334,
      "grad_norm": 4.408844947814941,
      "learning_rate": 9.104012280330298e-06,
      "loss": 0.6355,
      "step": 772950
    },
    {
      "epoch": 8.183272373108336,
      "grad_norm": 4.805450439453125,
      "learning_rate": 9.10136565742113e-06,
      "loss": 0.6516,
      "step": 773000
    },
    {
      "epoch": 8.183272373108336,
      "eval_loss": 0.392521470785141,
      "eval_runtime": 46.4608,
      "eval_samples_per_second": 3614.445,
      "eval_steps_per_second": 451.822,
      "step": 773000
    },
    {
      "epoch": 8.18380169488834,
      "grad_norm": 4.447178363800049,
      "learning_rate": 9.098719034511963e-06,
      "loss": 0.6362,
      "step": 773050
    },
    {
      "epoch": 8.184331016668343,
      "grad_norm": 4.557436943054199,
      "learning_rate": 9.096072411602795e-06,
      "loss": 0.6376,
      "step": 773100
    },
    {
      "epoch": 8.184860338448345,
      "grad_norm": 4.480214595794678,
      "learning_rate": 9.093425788693628e-06,
      "loss": 0.6363,
      "step": 773150
    },
    {
      "epoch": 8.18538966022835,
      "grad_norm": 4.216263771057129,
      "learning_rate": 9.090779165784458e-06,
      "loss": 0.6373,
      "step": 773200
    },
    {
      "epoch": 8.185918982008353,
      "grad_norm": 4.570512771606445,
      "learning_rate": 9.08813254287529e-06,
      "loss": 0.6375,
      "step": 773250
    },
    {
      "epoch": 8.186448303788357,
      "grad_norm": 4.918441295623779,
      "learning_rate": 9.085485919966123e-06,
      "loss": 0.6461,
      "step": 773300
    },
    {
      "epoch": 8.186977625568359,
      "grad_norm": 4.770514488220215,
      "learning_rate": 9.082839297056956e-06,
      "loss": 0.6293,
      "step": 773350
    },
    {
      "epoch": 8.187506947348362,
      "grad_norm": 4.506557464599609,
      "learning_rate": 9.080192674147788e-06,
      "loss": 0.633,
      "step": 773400
    },
    {
      "epoch": 8.188036269128366,
      "grad_norm": 4.953312873840332,
      "learning_rate": 9.07754605123862e-06,
      "loss": 0.6388,
      "step": 773450
    },
    {
      "epoch": 8.18856559090837,
      "grad_norm": 4.643324375152588,
      "learning_rate": 9.074899428329451e-06,
      "loss": 0.6417,
      "step": 773500
    },
    {
      "epoch": 8.18856559090837,
      "eval_loss": 0.39254525303840637,
      "eval_runtime": 46.4496,
      "eval_samples_per_second": 3615.317,
      "eval_steps_per_second": 451.931,
      "step": 773500
    },
    {
      "epoch": 8.189094912688372,
      "grad_norm": 4.67929744720459,
      "learning_rate": 9.072252805420284e-06,
      "loss": 0.6297,
      "step": 773550
    },
    {
      "epoch": 8.189624234468376,
      "grad_norm": 4.650204181671143,
      "learning_rate": 9.069606182511116e-06,
      "loss": 0.6333,
      "step": 773600
    },
    {
      "epoch": 8.19015355624838,
      "grad_norm": 4.828303337097168,
      "learning_rate": 9.066959559601948e-06,
      "loss": 0.644,
      "step": 773650
    },
    {
      "epoch": 8.190682878028383,
      "grad_norm": 4.629876136779785,
      "learning_rate": 9.06431293669278e-06,
      "loss": 0.6362,
      "step": 773700
    },
    {
      "epoch": 8.191212199808385,
      "grad_norm": 4.427022933959961,
      "learning_rate": 9.061666313783611e-06,
      "loss": 0.6394,
      "step": 773750
    },
    {
      "epoch": 8.191741521588389,
      "grad_norm": 4.1403045654296875,
      "learning_rate": 9.059019690874444e-06,
      "loss": 0.6332,
      "step": 773800
    },
    {
      "epoch": 8.192270843368393,
      "grad_norm": 5.031985759735107,
      "learning_rate": 9.056373067965276e-06,
      "loss": 0.6465,
      "step": 773850
    },
    {
      "epoch": 8.192800165148395,
      "grad_norm": 4.240800380706787,
      "learning_rate": 9.053726445056109e-06,
      "loss": 0.6349,
      "step": 773900
    },
    {
      "epoch": 8.193329486928398,
      "grad_norm": 4.815377712249756,
      "learning_rate": 9.051079822146941e-06,
      "loss": 0.6478,
      "step": 773950
    },
    {
      "epoch": 8.193858808708402,
      "grad_norm": 4.356788158416748,
      "learning_rate": 9.048433199237773e-06,
      "loss": 0.6247,
      "step": 774000
    },
    {
      "epoch": 8.193858808708402,
      "eval_loss": 0.392095148563385,
      "eval_runtime": 46.4537,
      "eval_samples_per_second": 3614.997,
      "eval_steps_per_second": 451.891,
      "step": 774000
    },
    {
      "epoch": 8.194388130488406,
      "grad_norm": 4.342707633972168,
      "learning_rate": 9.045786576328604e-06,
      "loss": 0.6519,
      "step": 774050
    },
    {
      "epoch": 8.194917452268408,
      "grad_norm": 4.548214435577393,
      "learning_rate": 9.043139953419437e-06,
      "loss": 0.6362,
      "step": 774100
    },
    {
      "epoch": 8.195446774048412,
      "grad_norm": 4.693955898284912,
      "learning_rate": 9.040546262968453e-06,
      "loss": 0.6375,
      "step": 774150
    },
    {
      "epoch": 8.195976095828415,
      "grad_norm": 4.494078159332275,
      "learning_rate": 9.037899640059284e-06,
      "loss": 0.6404,
      "step": 774200
    },
    {
      "epoch": 8.196505417608419,
      "grad_norm": 4.387478828430176,
      "learning_rate": 9.035253017150116e-06,
      "loss": 0.636,
      "step": 774250
    },
    {
      "epoch": 8.197034739388421,
      "grad_norm": 4.560702323913574,
      "learning_rate": 9.032606394240949e-06,
      "loss": 0.6381,
      "step": 774300
    },
    {
      "epoch": 8.197564061168425,
      "grad_norm": 4.606577396392822,
      "learning_rate": 9.029959771331781e-06,
      "loss": 0.6549,
      "step": 774350
    },
    {
      "epoch": 8.198093382948429,
      "grad_norm": 4.584347248077393,
      "learning_rate": 9.027313148422613e-06,
      "loss": 0.631,
      "step": 774400
    },
    {
      "epoch": 8.198622704728432,
      "grad_norm": 4.659355640411377,
      "learning_rate": 9.024666525513446e-06,
      "loss": 0.6487,
      "step": 774450
    },
    {
      "epoch": 8.199152026508434,
      "grad_norm": 4.533468723297119,
      "learning_rate": 9.022019902604276e-06,
      "loss": 0.6498,
      "step": 774500
    },
    {
      "epoch": 8.199152026508434,
      "eval_loss": 0.39220884442329407,
      "eval_runtime": 46.5194,
      "eval_samples_per_second": 3609.895,
      "eval_steps_per_second": 451.253,
      "step": 774500
    },
    {
      "epoch": 8.199681348288438,
      "grad_norm": 4.567603588104248,
      "learning_rate": 9.019373279695109e-06,
      "loss": 0.6394,
      "step": 774550
    },
    {
      "epoch": 8.200210670068442,
      "grad_norm": 4.572311878204346,
      "learning_rate": 9.016726656785941e-06,
      "loss": 0.6378,
      "step": 774600
    },
    {
      "epoch": 8.200739991848444,
      "grad_norm": 4.551841735839844,
      "learning_rate": 9.014080033876774e-06,
      "loss": 0.6395,
      "step": 774650
    },
    {
      "epoch": 8.201269313628448,
      "grad_norm": 4.263465404510498,
      "learning_rate": 9.011433410967606e-06,
      "loss": 0.6461,
      "step": 774700
    },
    {
      "epoch": 8.201798635408451,
      "grad_norm": 4.26011323928833,
      "learning_rate": 9.008786788058437e-06,
      "loss": 0.6256,
      "step": 774750
    },
    {
      "epoch": 8.202327957188455,
      "grad_norm": 4.57393741607666,
      "learning_rate": 9.00614016514927e-06,
      "loss": 0.6434,
      "step": 774800
    },
    {
      "epoch": 8.202857278968457,
      "grad_norm": 4.506288528442383,
      "learning_rate": 9.003493542240102e-06,
      "loss": 0.6522,
      "step": 774850
    },
    {
      "epoch": 8.20338660074846,
      "grad_norm": 4.5016889572143555,
      "learning_rate": 9.000846919330934e-06,
      "loss": 0.6471,
      "step": 774900
    },
    {
      "epoch": 8.203915922528465,
      "grad_norm": 4.57594633102417,
      "learning_rate": 8.998200296421766e-06,
      "loss": 0.6375,
      "step": 774950
    },
    {
      "epoch": 8.204445244308468,
      "grad_norm": 4.987616062164307,
      "learning_rate": 8.995553673512599e-06,
      "loss": 0.6361,
      "step": 775000
    },
    {
      "epoch": 8.204445244308468,
      "eval_loss": 0.3918638825416565,
      "eval_runtime": 46.4773,
      "eval_samples_per_second": 3613.158,
      "eval_steps_per_second": 451.661,
      "step": 775000
    },
    {
      "epoch": 8.20497456608847,
      "grad_norm": 4.598114490509033,
      "learning_rate": 8.99290705060343e-06,
      "loss": 0.6382,
      "step": 775050
    },
    {
      "epoch": 8.205503887868474,
      "grad_norm": 4.736104488372803,
      "learning_rate": 8.990260427694262e-06,
      "loss": 0.6432,
      "step": 775100
    },
    {
      "epoch": 8.206033209648478,
      "grad_norm": 4.863307952880859,
      "learning_rate": 8.987613804785094e-06,
      "loss": 0.6428,
      "step": 775150
    },
    {
      "epoch": 8.206562531428482,
      "grad_norm": 4.4496073722839355,
      "learning_rate": 8.984967181875927e-06,
      "loss": 0.6445,
      "step": 775200
    },
    {
      "epoch": 8.207091853208484,
      "grad_norm": 4.442317485809326,
      "learning_rate": 8.982320558966759e-06,
      "loss": 0.6299,
      "step": 775250
    },
    {
      "epoch": 8.207621174988487,
      "grad_norm": 4.017886638641357,
      "learning_rate": 8.979673936057592e-06,
      "loss": 0.6423,
      "step": 775300
    },
    {
      "epoch": 8.208150496768491,
      "grad_norm": 5.443459510803223,
      "learning_rate": 8.977027313148422e-06,
      "loss": 0.6377,
      "step": 775350
    },
    {
      "epoch": 8.208679818548493,
      "grad_norm": 4.443927764892578,
      "learning_rate": 8.974380690239255e-06,
      "loss": 0.6384,
      "step": 775400
    },
    {
      "epoch": 8.209209140328497,
      "grad_norm": 4.776395320892334,
      "learning_rate": 8.971734067330087e-06,
      "loss": 0.6336,
      "step": 775450
    },
    {
      "epoch": 8.2097384621085,
      "grad_norm": 4.263376235961914,
      "learning_rate": 8.96908744442092e-06,
      "loss": 0.6376,
      "step": 775500
    },
    {
      "epoch": 8.2097384621085,
      "eval_loss": 0.39230719208717346,
      "eval_runtime": 46.5069,
      "eval_samples_per_second": 3610.863,
      "eval_steps_per_second": 451.374,
      "step": 775500
    },
    {
      "epoch": 8.210267783888504,
      "grad_norm": 4.200949668884277,
      "learning_rate": 8.966440821511752e-06,
      "loss": 0.6337,
      "step": 775550
    },
    {
      "epoch": 8.210797105668506,
      "grad_norm": 4.502714157104492,
      "learning_rate": 8.963794198602583e-06,
      "loss": 0.633,
      "step": 775600
    },
    {
      "epoch": 8.21132642744851,
      "grad_norm": 4.620988368988037,
      "learning_rate": 8.961147575693415e-06,
      "loss": 0.6391,
      "step": 775650
    },
    {
      "epoch": 8.211855749228514,
      "grad_norm": 4.406152725219727,
      "learning_rate": 8.958500952784247e-06,
      "loss": 0.6372,
      "step": 775700
    },
    {
      "epoch": 8.212385071008518,
      "grad_norm": 4.882810115814209,
      "learning_rate": 8.95585432987508e-06,
      "loss": 0.6416,
      "step": 775750
    },
    {
      "epoch": 8.21291439278852,
      "grad_norm": 4.6572136878967285,
      "learning_rate": 8.953207706965912e-06,
      "loss": 0.6323,
      "step": 775800
    },
    {
      "epoch": 8.213443714568523,
      "grad_norm": 4.401018142700195,
      "learning_rate": 8.950561084056745e-06,
      "loss": 0.6443,
      "step": 775850
    },
    {
      "epoch": 8.213973036348527,
      "grad_norm": 3.960228681564331,
      "learning_rate": 8.947914461147575e-06,
      "loss": 0.6454,
      "step": 775900
    },
    {
      "epoch": 8.21450235812853,
      "grad_norm": 4.60411262512207,
      "learning_rate": 8.945267838238408e-06,
      "loss": 0.6371,
      "step": 775950
    },
    {
      "epoch": 8.215031679908533,
      "grad_norm": 4.825489044189453,
      "learning_rate": 8.94262121532924e-06,
      "loss": 0.6418,
      "step": 776000
    },
    {
      "epoch": 8.215031679908533,
      "eval_loss": 0.39184829592704773,
      "eval_runtime": 46.4746,
      "eval_samples_per_second": 3613.373,
      "eval_steps_per_second": 451.688,
      "step": 776000
    },
    {
      "epoch": 8.215561001688537,
      "grad_norm": 4.016139030456543,
      "learning_rate": 8.939974592420073e-06,
      "loss": 0.6323,
      "step": 776050
    },
    {
      "epoch": 8.21609032346854,
      "grad_norm": 4.489879608154297,
      "learning_rate": 8.937327969510905e-06,
      "loss": 0.625,
      "step": 776100
    },
    {
      "epoch": 8.216619645248542,
      "grad_norm": 4.597011089324951,
      "learning_rate": 8.93473427905992e-06,
      "loss": 0.6399,
      "step": 776150
    },
    {
      "epoch": 8.217148967028546,
      "grad_norm": 4.613124370574951,
      "learning_rate": 8.932087656150752e-06,
      "loss": 0.6434,
      "step": 776200
    },
    {
      "epoch": 8.21767828880855,
      "grad_norm": 4.393673419952393,
      "learning_rate": 8.929441033241584e-06,
      "loss": 0.6421,
      "step": 776250
    },
    {
      "epoch": 8.218207610588554,
      "grad_norm": 4.403009414672852,
      "learning_rate": 8.926794410332417e-06,
      "loss": 0.6326,
      "step": 776300
    },
    {
      "epoch": 8.218736932368556,
      "grad_norm": 3.9402875900268555,
      "learning_rate": 8.924147787423248e-06,
      "loss": 0.6328,
      "step": 776350
    },
    {
      "epoch": 8.21926625414856,
      "grad_norm": 4.8000030517578125,
      "learning_rate": 8.92150116451408e-06,
      "loss": 0.6296,
      "step": 776400
    },
    {
      "epoch": 8.219795575928563,
      "grad_norm": 5.188515663146973,
      "learning_rate": 8.918854541604912e-06,
      "loss": 0.6371,
      "step": 776450
    },
    {
      "epoch": 8.220324897708567,
      "grad_norm": 5.216022491455078,
      "learning_rate": 8.916207918695745e-06,
      "loss": 0.6434,
      "step": 776500
    },
    {
      "epoch": 8.220324897708567,
      "eval_loss": 0.3910418450832367,
      "eval_runtime": 46.4834,
      "eval_samples_per_second": 3612.686,
      "eval_steps_per_second": 451.602,
      "step": 776500
    },
    {
      "epoch": 8.220854219488569,
      "grad_norm": 4.73947286605835,
      "learning_rate": 8.913561295786577e-06,
      "loss": 0.6507,
      "step": 776550
    },
    {
      "epoch": 8.221383541268573,
      "grad_norm": 4.244271278381348,
      "learning_rate": 8.910914672877408e-06,
      "loss": 0.6308,
      "step": 776600
    },
    {
      "epoch": 8.221912863048576,
      "grad_norm": 4.434065341949463,
      "learning_rate": 8.90826804996824e-06,
      "loss": 0.6395,
      "step": 776650
    },
    {
      "epoch": 8.22244218482858,
      "grad_norm": 4.393438816070557,
      "learning_rate": 8.905621427059073e-06,
      "loss": 0.6324,
      "step": 776700
    },
    {
      "epoch": 8.222971506608582,
      "grad_norm": 5.033477783203125,
      "learning_rate": 8.902974804149905e-06,
      "loss": 0.635,
      "step": 776750
    },
    {
      "epoch": 8.223500828388586,
      "grad_norm": 4.696384429931641,
      "learning_rate": 8.900328181240738e-06,
      "loss": 0.6428,
      "step": 776800
    },
    {
      "epoch": 8.22403015016859,
      "grad_norm": 4.220061302185059,
      "learning_rate": 8.89768155833157e-06,
      "loss": 0.6314,
      "step": 776850
    },
    {
      "epoch": 8.224559471948591,
      "grad_norm": 4.716641902923584,
      "learning_rate": 8.8950349354224e-06,
      "loss": 0.623,
      "step": 776900
    },
    {
      "epoch": 8.225088793728595,
      "grad_norm": 4.575526714324951,
      "learning_rate": 8.892388312513233e-06,
      "loss": 0.6295,
      "step": 776950
    },
    {
      "epoch": 8.225618115508599,
      "grad_norm": 4.947655200958252,
      "learning_rate": 8.889741689604065e-06,
      "loss": 0.6343,
      "step": 777000
    },
    {
      "epoch": 8.225618115508599,
      "eval_loss": 0.39178070425987244,
      "eval_runtime": 46.4349,
      "eval_samples_per_second": 3616.461,
      "eval_steps_per_second": 452.074,
      "step": 777000
    },
    {
      "epoch": 8.226147437288603,
      "grad_norm": 4.372743606567383,
      "learning_rate": 8.887095066694898e-06,
      "loss": 0.6312,
      "step": 777050
    },
    {
      "epoch": 8.226676759068605,
      "grad_norm": 4.021882057189941,
      "learning_rate": 8.88444844378573e-06,
      "loss": 0.6294,
      "step": 777100
    },
    {
      "epoch": 8.227206080848608,
      "grad_norm": 4.359367370605469,
      "learning_rate": 8.881801820876563e-06,
      "loss": 0.6399,
      "step": 777150
    },
    {
      "epoch": 8.227735402628612,
      "grad_norm": 4.76788854598999,
      "learning_rate": 8.879155197967393e-06,
      "loss": 0.6306,
      "step": 777200
    },
    {
      "epoch": 8.228264724408616,
      "grad_norm": 4.537193298339844,
      "learning_rate": 8.876508575058226e-06,
      "loss": 0.642,
      "step": 777250
    },
    {
      "epoch": 8.228794046188618,
      "grad_norm": 4.318483829498291,
      "learning_rate": 8.873861952149058e-06,
      "loss": 0.6353,
      "step": 777300
    },
    {
      "epoch": 8.229323367968622,
      "grad_norm": 4.47039794921875,
      "learning_rate": 8.87121532923989e-06,
      "loss": 0.6403,
      "step": 777350
    },
    {
      "epoch": 8.229852689748625,
      "grad_norm": 4.728181838989258,
      "learning_rate": 8.868568706330723e-06,
      "loss": 0.6336,
      "step": 777400
    },
    {
      "epoch": 8.23038201152863,
      "grad_norm": 4.6125288009643555,
      "learning_rate": 8.865922083421554e-06,
      "loss": 0.6367,
      "step": 777450
    },
    {
      "epoch": 8.230911333308631,
      "grad_norm": 4.606377124786377,
      "learning_rate": 8.863275460512386e-06,
      "loss": 0.644,
      "step": 777500
    },
    {
      "epoch": 8.230911333308631,
      "eval_loss": 0.3924320340156555,
      "eval_runtime": 46.5833,
      "eval_samples_per_second": 3604.942,
      "eval_steps_per_second": 450.634,
      "step": 777500
    },
    {
      "epoch": 8.231440655088635,
      "grad_norm": 4.758503437042236,
      "learning_rate": 8.860628837603219e-06,
      "loss": 0.6461,
      "step": 777550
    },
    {
      "epoch": 8.231969976868639,
      "grad_norm": 4.2811479568481445,
      "learning_rate": 8.857982214694051e-06,
      "loss": 0.6344,
      "step": 777600
    },
    {
      "epoch": 8.23249929864864,
      "grad_norm": 4.5695109367370605,
      "learning_rate": 8.855335591784883e-06,
      "loss": 0.6453,
      "step": 777650
    },
    {
      "epoch": 8.233028620428644,
      "grad_norm": 4.564854621887207,
      "learning_rate": 8.852688968875716e-06,
      "loss": 0.6458,
      "step": 777700
    },
    {
      "epoch": 8.233557942208648,
      "grad_norm": 4.688809394836426,
      "learning_rate": 8.850042345966546e-06,
      "loss": 0.6349,
      "step": 777750
    },
    {
      "epoch": 8.234087263988652,
      "grad_norm": 4.790590286254883,
      "learning_rate": 8.847395723057379e-06,
      "loss": 0.651,
      "step": 777800
    },
    {
      "epoch": 8.234616585768654,
      "grad_norm": 4.8423662185668945,
      "learning_rate": 8.844749100148211e-06,
      "loss": 0.6353,
      "step": 777850
    },
    {
      "epoch": 8.235145907548658,
      "grad_norm": 4.69546365737915,
      "learning_rate": 8.842102477239044e-06,
      "loss": 0.6355,
      "step": 777900
    },
    {
      "epoch": 8.235675229328661,
      "grad_norm": 4.470383167266846,
      "learning_rate": 8.839455854329876e-06,
      "loss": 0.6401,
      "step": 777950
    },
    {
      "epoch": 8.236204551108665,
      "grad_norm": 4.321215629577637,
      "learning_rate": 8.836809231420707e-06,
      "loss": 0.6315,
      "step": 778000
    },
    {
      "epoch": 8.236204551108665,
      "eval_loss": 0.39138033986091614,
      "eval_runtime": 46.4987,
      "eval_samples_per_second": 3611.5,
      "eval_steps_per_second": 451.454,
      "step": 778000
    },
    {
      "epoch": 8.236733872888667,
      "grad_norm": 4.186563491821289,
      "learning_rate": 8.83416260851154e-06,
      "loss": 0.6416,
      "step": 778050
    },
    {
      "epoch": 8.237263194668671,
      "grad_norm": 4.760532855987549,
      "learning_rate": 8.831515985602372e-06,
      "loss": 0.645,
      "step": 778100
    },
    {
      "epoch": 8.237792516448675,
      "grad_norm": 4.418959140777588,
      "learning_rate": 8.828922295151388e-06,
      "loss": 0.6351,
      "step": 778150
    },
    {
      "epoch": 8.238321838228678,
      "grad_norm": 4.103858947753906,
      "learning_rate": 8.826275672242219e-06,
      "loss": 0.6462,
      "step": 778200
    },
    {
      "epoch": 8.23885116000868,
      "grad_norm": 4.700800895690918,
      "learning_rate": 8.823629049333051e-06,
      "loss": 0.6381,
      "step": 778250
    },
    {
      "epoch": 8.239380481788684,
      "grad_norm": 5.007248401641846,
      "learning_rate": 8.820982426423884e-06,
      "loss": 0.6427,
      "step": 778300
    },
    {
      "epoch": 8.239909803568688,
      "grad_norm": 4.494410514831543,
      "learning_rate": 8.818335803514716e-06,
      "loss": 0.6395,
      "step": 778350
    },
    {
      "epoch": 8.24043912534869,
      "grad_norm": 4.53995418548584,
      "learning_rate": 8.815689180605548e-06,
      "loss": 0.6415,
      "step": 778400
    },
    {
      "epoch": 8.240968447128694,
      "grad_norm": 4.741080284118652,
      "learning_rate": 8.813042557696379e-06,
      "loss": 0.6348,
      "step": 778450
    },
    {
      "epoch": 8.241497768908697,
      "grad_norm": 4.466065883636475,
      "learning_rate": 8.810395934787211e-06,
      "loss": 0.6329,
      "step": 778500
    },
    {
      "epoch": 8.241497768908697,
      "eval_loss": 0.3910953402519226,
      "eval_runtime": 46.4996,
      "eval_samples_per_second": 3611.43,
      "eval_steps_per_second": 451.445,
      "step": 778500
    },
    {
      "epoch": 8.242027090688701,
      "grad_norm": 4.8391594886779785,
      "learning_rate": 8.807749311878044e-06,
      "loss": 0.6414,
      "step": 778550
    },
    {
      "epoch": 8.242556412468703,
      "grad_norm": 4.823892116546631,
      "learning_rate": 8.805102688968876e-06,
      "loss": 0.6339,
      "step": 778600
    },
    {
      "epoch": 8.243085734248707,
      "grad_norm": 4.495070457458496,
      "learning_rate": 8.802456066059709e-06,
      "loss": 0.6239,
      "step": 778650
    },
    {
      "epoch": 8.24361505602871,
      "grad_norm": 4.142090320587158,
      "learning_rate": 8.799809443150541e-06,
      "loss": 0.6341,
      "step": 778700
    },
    {
      "epoch": 8.244144377808714,
      "grad_norm": 4.471428394317627,
      "learning_rate": 8.797162820241372e-06,
      "loss": 0.6347,
      "step": 778750
    },
    {
      "epoch": 8.244673699588716,
      "grad_norm": 4.872534275054932,
      "learning_rate": 8.794516197332204e-06,
      "loss": 0.6285,
      "step": 778800
    },
    {
      "epoch": 8.24520302136872,
      "grad_norm": 4.859228134155273,
      "learning_rate": 8.791869574423037e-06,
      "loss": 0.6279,
      "step": 778850
    },
    {
      "epoch": 8.245732343148724,
      "grad_norm": 4.6999335289001465,
      "learning_rate": 8.789222951513869e-06,
      "loss": 0.6259,
      "step": 778900
    },
    {
      "epoch": 8.246261664928728,
      "grad_norm": 4.803278923034668,
      "learning_rate": 8.786576328604701e-06,
      "loss": 0.6356,
      "step": 778950
    },
    {
      "epoch": 8.24679098670873,
      "grad_norm": 4.609287738800049,
      "learning_rate": 8.783929705695534e-06,
      "loss": 0.645,
      "step": 779000
    },
    {
      "epoch": 8.24679098670873,
      "eval_loss": 0.3912361264228821,
      "eval_runtime": 46.5354,
      "eval_samples_per_second": 3608.647,
      "eval_steps_per_second": 451.097,
      "step": 779000
    },
    {
      "epoch": 8.247320308488733,
      "grad_norm": 4.5409650802612305,
      "learning_rate": 8.781283082786365e-06,
      "loss": 0.6367,
      "step": 779050
    },
    {
      "epoch": 8.247849630268737,
      "grad_norm": 4.070058345794678,
      "learning_rate": 8.778636459877197e-06,
      "loss": 0.6286,
      "step": 779100
    },
    {
      "epoch": 8.24837895204874,
      "grad_norm": 4.7458014488220215,
      "learning_rate": 8.77598983696803e-06,
      "loss": 0.6384,
      "step": 779150
    },
    {
      "epoch": 8.248908273828743,
      "grad_norm": 4.577569961547852,
      "learning_rate": 8.773343214058862e-06,
      "loss": 0.6516,
      "step": 779200
    },
    {
      "epoch": 8.249437595608747,
      "grad_norm": 4.467106819152832,
      "learning_rate": 8.770696591149694e-06,
      "loss": 0.6314,
      "step": 779250
    },
    {
      "epoch": 8.24996691738875,
      "grad_norm": 4.6998515129089355,
      "learning_rate": 8.768049968240525e-06,
      "loss": 0.641,
      "step": 779300
    },
    {
      "epoch": 8.250496239168752,
      "grad_norm": 4.814280986785889,
      "learning_rate": 8.765403345331357e-06,
      "loss": 0.6466,
      "step": 779350
    },
    {
      "epoch": 8.251025560948756,
      "grad_norm": 4.463013648986816,
      "learning_rate": 8.76275672242219e-06,
      "loss": 0.6295,
      "step": 779400
    },
    {
      "epoch": 8.25155488272876,
      "grad_norm": 4.959996223449707,
      "learning_rate": 8.760110099513022e-06,
      "loss": 0.6223,
      "step": 779450
    },
    {
      "epoch": 8.252084204508764,
      "grad_norm": 4.720287322998047,
      "learning_rate": 8.757463476603855e-06,
      "loss": 0.6362,
      "step": 779500
    },
    {
      "epoch": 8.252084204508764,
      "eval_loss": 0.39111804962158203,
      "eval_runtime": 46.5917,
      "eval_samples_per_second": 3604.293,
      "eval_steps_per_second": 450.553,
      "step": 779500
    },
    {
      "epoch": 8.252613526288766,
      "grad_norm": 4.610825538635254,
      "learning_rate": 8.754816853694687e-06,
      "loss": 0.6356,
      "step": 779550
    },
    {
      "epoch": 8.25314284806877,
      "grad_norm": 4.365769863128662,
      "learning_rate": 8.752170230785518e-06,
      "loss": 0.6444,
      "step": 779600
    },
    {
      "epoch": 8.253672169848773,
      "grad_norm": 4.564191818237305,
      "learning_rate": 8.749576540334534e-06,
      "loss": 0.6436,
      "step": 779650
    },
    {
      "epoch": 8.254201491628777,
      "grad_norm": 4.128092288970947,
      "learning_rate": 8.746929917425366e-06,
      "loss": 0.6332,
      "step": 779700
    },
    {
      "epoch": 8.254730813408779,
      "grad_norm": 4.775042533874512,
      "learning_rate": 8.744283294516197e-06,
      "loss": 0.6393,
      "step": 779750
    },
    {
      "epoch": 8.255260135188783,
      "grad_norm": 4.047672748565674,
      "learning_rate": 8.74163667160703e-06,
      "loss": 0.6473,
      "step": 779800
    },
    {
      "epoch": 8.255789456968786,
      "grad_norm": 4.961993217468262,
      "learning_rate": 8.738990048697862e-06,
      "loss": 0.6544,
      "step": 779850
    },
    {
      "epoch": 8.256318778748788,
      "grad_norm": 4.766286373138428,
      "learning_rate": 8.736343425788694e-06,
      "loss": 0.6435,
      "step": 779900
    },
    {
      "epoch": 8.256848100528792,
      "grad_norm": 4.571458339691162,
      "learning_rate": 8.733696802879527e-06,
      "loss": 0.6433,
      "step": 779950
    },
    {
      "epoch": 8.257377422308796,
      "grad_norm": 4.287083148956299,
      "learning_rate": 8.73105017997036e-06,
      "loss": 0.6438,
      "step": 780000
    },
    {
      "epoch": 8.257377422308796,
      "eval_loss": 0.3904503881931305,
      "eval_runtime": 46.4643,
      "eval_samples_per_second": 3614.172,
      "eval_steps_per_second": 451.788,
      "step": 780000
    },
    {
      "epoch": 8.2579067440888,
      "grad_norm": 4.227347373962402,
      "learning_rate": 8.72840355706119e-06,
      "loss": 0.6253,
      "step": 780050
    },
    {
      "epoch": 8.258436065868802,
      "grad_norm": 4.460445880889893,
      "learning_rate": 8.725756934152022e-06,
      "loss": 0.6371,
      "step": 780100
    },
    {
      "epoch": 8.258965387648805,
      "grad_norm": 4.599122047424316,
      "learning_rate": 8.723110311242855e-06,
      "loss": 0.6365,
      "step": 780150
    },
    {
      "epoch": 8.25949470942881,
      "grad_norm": 4.691572189331055,
      "learning_rate": 8.720463688333687e-06,
      "loss": 0.6281,
      "step": 780200
    },
    {
      "epoch": 8.260024031208813,
      "grad_norm": 4.601840019226074,
      "learning_rate": 8.71781706542452e-06,
      "loss": 0.6396,
      "step": 780250
    },
    {
      "epoch": 8.260553352988815,
      "grad_norm": 4.7121710777282715,
      "learning_rate": 8.71517044251535e-06,
      "loss": 0.6284,
      "step": 780300
    },
    {
      "epoch": 8.261082674768819,
      "grad_norm": 4.7350921630859375,
      "learning_rate": 8.712523819606183e-06,
      "loss": 0.6389,
      "step": 780350
    },
    {
      "epoch": 8.261611996548822,
      "grad_norm": 4.087859630584717,
      "learning_rate": 8.709877196697015e-06,
      "loss": 0.6322,
      "step": 780400
    },
    {
      "epoch": 8.262141318328826,
      "grad_norm": 4.706313133239746,
      "learning_rate": 8.707230573787847e-06,
      "loss": 0.6414,
      "step": 780450
    },
    {
      "epoch": 8.262670640108828,
      "grad_norm": 4.702118873596191,
      "learning_rate": 8.70458395087868e-06,
      "loss": 0.6353,
      "step": 780500
    },
    {
      "epoch": 8.262670640108828,
      "eval_loss": 0.39042580127716064,
      "eval_runtime": 46.4613,
      "eval_samples_per_second": 3614.405,
      "eval_steps_per_second": 451.817,
      "step": 780500
    },
    {
      "epoch": 8.263199961888832,
      "grad_norm": 4.515469074249268,
      "learning_rate": 8.701937327969512e-06,
      "loss": 0.6253,
      "step": 780550
    },
    {
      "epoch": 8.263729283668836,
      "grad_norm": 4.955524444580078,
      "learning_rate": 8.699290705060343e-06,
      "loss": 0.6428,
      "step": 780600
    },
    {
      "epoch": 8.264258605448838,
      "grad_norm": 4.3753509521484375,
      "learning_rate": 8.696644082151175e-06,
      "loss": 0.6325,
      "step": 780650
    },
    {
      "epoch": 8.264787927228841,
      "grad_norm": 4.629856586456299,
      "learning_rate": 8.693997459242008e-06,
      "loss": 0.6362,
      "step": 780700
    },
    {
      "epoch": 8.265317249008845,
      "grad_norm": 4.408934593200684,
      "learning_rate": 8.69135083633284e-06,
      "loss": 0.642,
      "step": 780750
    },
    {
      "epoch": 8.265846570788849,
      "grad_norm": 4.8127899169921875,
      "learning_rate": 8.688704213423673e-06,
      "loss": 0.6287,
      "step": 780800
    },
    {
      "epoch": 8.26637589256885,
      "grad_norm": 4.8145551681518555,
      "learning_rate": 8.686057590514505e-06,
      "loss": 0.6419,
      "step": 780850
    },
    {
      "epoch": 8.266905214348855,
      "grad_norm": 4.469444751739502,
      "learning_rate": 8.683410967605336e-06,
      "loss": 0.6399,
      "step": 780900
    },
    {
      "epoch": 8.267434536128858,
      "grad_norm": 4.318053722381592,
      "learning_rate": 8.680764344696168e-06,
      "loss": 0.637,
      "step": 780950
    },
    {
      "epoch": 8.267963857908862,
      "grad_norm": 4.58323335647583,
      "learning_rate": 8.678117721787e-06,
      "loss": 0.6388,
      "step": 781000
    },
    {
      "epoch": 8.267963857908862,
      "eval_loss": 0.39140620827674866,
      "eval_runtime": 46.4623,
      "eval_samples_per_second": 3614.332,
      "eval_steps_per_second": 451.808,
      "step": 781000
    },
    {
      "epoch": 8.268493179688864,
      "grad_norm": 4.482212543487549,
      "learning_rate": 8.675471098877833e-06,
      "loss": 0.637,
      "step": 781050
    },
    {
      "epoch": 8.269022501468868,
      "grad_norm": 4.694504737854004,
      "learning_rate": 8.672824475968665e-06,
      "loss": 0.6483,
      "step": 781100
    },
    {
      "epoch": 8.269551823248872,
      "grad_norm": 4.222848892211914,
      "learning_rate": 8.670177853059496e-06,
      "loss": 0.636,
      "step": 781150
    },
    {
      "epoch": 8.270081145028875,
      "grad_norm": 4.207646369934082,
      "learning_rate": 8.667531230150328e-06,
      "loss": 0.6384,
      "step": 781200
    },
    {
      "epoch": 8.270610466808877,
      "grad_norm": 4.4457526206970215,
      "learning_rate": 8.664884607241161e-06,
      "loss": 0.6343,
      "step": 781250
    },
    {
      "epoch": 8.271139788588881,
      "grad_norm": 4.824936389923096,
      "learning_rate": 8.662237984331993e-06,
      "loss": 0.6414,
      "step": 781300
    },
    {
      "epoch": 8.271669110368885,
      "grad_norm": 5.205129623413086,
      "learning_rate": 8.659591361422826e-06,
      "loss": 0.6441,
      "step": 781350
    },
    {
      "epoch": 8.272198432148887,
      "grad_norm": 4.822872638702393,
      "learning_rate": 8.656944738513658e-06,
      "loss": 0.644,
      "step": 781400
    },
    {
      "epoch": 8.27272775392889,
      "grad_norm": 4.762725830078125,
      "learning_rate": 8.654298115604489e-06,
      "loss": 0.6355,
      "step": 781450
    },
    {
      "epoch": 8.273257075708894,
      "grad_norm": 4.4582037925720215,
      "learning_rate": 8.651651492695321e-06,
      "loss": 0.6471,
      "step": 781500
    },
    {
      "epoch": 8.273257075708894,
      "eval_loss": 0.39147627353668213,
      "eval_runtime": 46.4398,
      "eval_samples_per_second": 3616.08,
      "eval_steps_per_second": 452.026,
      "step": 781500
    },
    {
      "epoch": 8.273786397488898,
      "grad_norm": 5.306647300720215,
      "learning_rate": 8.649004869786154e-06,
      "loss": 0.634,
      "step": 781550
    },
    {
      "epoch": 8.2743157192689,
      "grad_norm": 4.5836076736450195,
      "learning_rate": 8.646358246876986e-06,
      "loss": 0.6442,
      "step": 781600
    },
    {
      "epoch": 8.274845041048904,
      "grad_norm": 4.6824727058410645,
      "learning_rate": 8.643711623967818e-06,
      "loss": 0.6386,
      "step": 781650
    },
    {
      "epoch": 8.275374362828908,
      "grad_norm": 4.3556904792785645,
      "learning_rate": 8.641065001058649e-06,
      "loss": 0.6317,
      "step": 781700
    },
    {
      "epoch": 8.275903684608911,
      "grad_norm": 4.667961597442627,
      "learning_rate": 8.638418378149482e-06,
      "loss": 0.6415,
      "step": 781750
    },
    {
      "epoch": 8.276433006388913,
      "grad_norm": 4.3712968826293945,
      "learning_rate": 8.635771755240314e-06,
      "loss": 0.6349,
      "step": 781800
    },
    {
      "epoch": 8.276962328168917,
      "grad_norm": 4.465297222137451,
      "learning_rate": 8.633125132331146e-06,
      "loss": 0.6257,
      "step": 781850
    },
    {
      "epoch": 8.27749164994892,
      "grad_norm": 4.533015251159668,
      "learning_rate": 8.630478509421979e-06,
      "loss": 0.6398,
      "step": 781900
    },
    {
      "epoch": 8.278020971728925,
      "grad_norm": 4.876369953155518,
      "learning_rate": 8.627831886512811e-06,
      "loss": 0.6369,
      "step": 781950
    },
    {
      "epoch": 8.278550293508927,
      "grad_norm": 4.4059953689575195,
      "learning_rate": 8.625185263603642e-06,
      "loss": 0.6361,
      "step": 782000
    },
    {
      "epoch": 8.278550293508927,
      "eval_loss": 0.3912489712238312,
      "eval_runtime": 46.5433,
      "eval_samples_per_second": 3608.036,
      "eval_steps_per_second": 451.021,
      "step": 782000
    },
    {
      "epoch": 8.27907961528893,
      "grad_norm": 4.153768062591553,
      "learning_rate": 8.622538640694474e-06,
      "loss": 0.6398,
      "step": 782050
    },
    {
      "epoch": 8.279608937068934,
      "grad_norm": 4.6659770011901855,
      "learning_rate": 8.619892017785307e-06,
      "loss": 0.648,
      "step": 782100
    },
    {
      "epoch": 8.280138258848936,
      "grad_norm": 4.9704461097717285,
      "learning_rate": 8.617245394876139e-06,
      "loss": 0.6425,
      "step": 782150
    },
    {
      "epoch": 8.28066758062894,
      "grad_norm": 4.179082870483398,
      "learning_rate": 8.614598771966971e-06,
      "loss": 0.6459,
      "step": 782200
    },
    {
      "epoch": 8.281196902408944,
      "grad_norm": 4.2090983390808105,
      "learning_rate": 8.611952149057804e-06,
      "loss": 0.6303,
      "step": 782250
    },
    {
      "epoch": 8.281726224188947,
      "grad_norm": 4.76575231552124,
      "learning_rate": 8.609305526148635e-06,
      "loss": 0.6346,
      "step": 782300
    },
    {
      "epoch": 8.28225554596895,
      "grad_norm": 4.529106616973877,
      "learning_rate": 8.606658903239467e-06,
      "loss": 0.6452,
      "step": 782350
    },
    {
      "epoch": 8.282784867748953,
      "grad_norm": 4.778156757354736,
      "learning_rate": 8.6040122803303e-06,
      "loss": 0.6443,
      "step": 782400
    },
    {
      "epoch": 8.283314189528957,
      "grad_norm": 4.604624271392822,
      "learning_rate": 8.601365657421132e-06,
      "loss": 0.638,
      "step": 782450
    },
    {
      "epoch": 8.28384351130896,
      "grad_norm": 4.62111759185791,
      "learning_rate": 8.598719034511964e-06,
      "loss": 0.6453,
      "step": 782500
    },
    {
      "epoch": 8.28384351130896,
      "eval_loss": 0.39119648933410645,
      "eval_runtime": 46.4545,
      "eval_samples_per_second": 3614.933,
      "eval_steps_per_second": 451.883,
      "step": 782500
    },
    {
      "epoch": 8.284372833088963,
      "grad_norm": 4.661585330963135,
      "learning_rate": 8.596072411602795e-06,
      "loss": 0.6399,
      "step": 782550
    },
    {
      "epoch": 8.284902154868966,
      "grad_norm": 4.7200117111206055,
      "learning_rate": 8.593425788693627e-06,
      "loss": 0.6368,
      "step": 782600
    },
    {
      "epoch": 8.28543147664897,
      "grad_norm": 5.203007698059082,
      "learning_rate": 8.59077916578446e-06,
      "loss": 0.6535,
      "step": 782650
    },
    {
      "epoch": 8.285960798428974,
      "grad_norm": 4.627254962921143,
      "learning_rate": 8.588132542875292e-06,
      "loss": 0.6472,
      "step": 782700
    },
    {
      "epoch": 8.286490120208976,
      "grad_norm": 4.511713027954102,
      "learning_rate": 8.585485919966125e-06,
      "loss": 0.639,
      "step": 782750
    },
    {
      "epoch": 8.28701944198898,
      "grad_norm": 4.867933750152588,
      "learning_rate": 8.582839297056957e-06,
      "loss": 0.6421,
      "step": 782800
    },
    {
      "epoch": 8.287548763768983,
      "grad_norm": 4.213663101196289,
      "learning_rate": 8.580192674147788e-06,
      "loss": 0.6469,
      "step": 782850
    },
    {
      "epoch": 8.288078085548985,
      "grad_norm": 4.412078380584717,
      "learning_rate": 8.57754605123862e-06,
      "loss": 0.6223,
      "step": 782900
    },
    {
      "epoch": 8.288607407328989,
      "grad_norm": 4.661073207855225,
      "learning_rate": 8.574899428329453e-06,
      "loss": 0.6272,
      "step": 782950
    },
    {
      "epoch": 8.289136729108993,
      "grad_norm": 5.56776762008667,
      "learning_rate": 8.572252805420285e-06,
      "loss": 0.6439,
      "step": 783000
    },
    {
      "epoch": 8.289136729108993,
      "eval_loss": 0.39090776443481445,
      "eval_runtime": 46.6811,
      "eval_samples_per_second": 3597.387,
      "eval_steps_per_second": 449.689,
      "step": 783000
    },
    {
      "epoch": 8.289666050888997,
      "grad_norm": 4.8539958000183105,
      "learning_rate": 8.569606182511117e-06,
      "loss": 0.6421,
      "step": 783050
    },
    {
      "epoch": 8.290195372668999,
      "grad_norm": 4.823713302612305,
      "learning_rate": 8.56695955960195e-06,
      "loss": 0.6246,
      "step": 783100
    },
    {
      "epoch": 8.290724694449002,
      "grad_norm": 4.878623008728027,
      "learning_rate": 8.56431293669278e-06,
      "loss": 0.6376,
      "step": 783150
    },
    {
      "epoch": 8.291254016229006,
      "grad_norm": 4.625247478485107,
      "learning_rate": 8.561666313783613e-06,
      "loss": 0.6342,
      "step": 783200
    },
    {
      "epoch": 8.29178333800901,
      "grad_norm": 4.426170825958252,
      "learning_rate": 8.559019690874445e-06,
      "loss": 0.6217,
      "step": 783250
    },
    {
      "epoch": 8.292312659789012,
      "grad_norm": 4.640444278717041,
      "learning_rate": 8.556373067965278e-06,
      "loss": 0.6399,
      "step": 783300
    },
    {
      "epoch": 8.292841981569016,
      "grad_norm": 4.703329563140869,
      "learning_rate": 8.55372644505611e-06,
      "loss": 0.6296,
      "step": 783350
    },
    {
      "epoch": 8.29337130334902,
      "grad_norm": 4.3307366371154785,
      "learning_rate": 8.55107982214694e-06,
      "loss": 0.6313,
      "step": 783400
    },
    {
      "epoch": 8.293900625129023,
      "grad_norm": 4.707515716552734,
      "learning_rate": 8.548433199237773e-06,
      "loss": 0.6296,
      "step": 783450
    },
    {
      "epoch": 8.294429946909025,
      "grad_norm": 4.849574089050293,
      "learning_rate": 8.545786576328606e-06,
      "loss": 0.6344,
      "step": 783500
    },
    {
      "epoch": 8.294429946909025,
      "eval_loss": 0.3913544714450836,
      "eval_runtime": 46.4693,
      "eval_samples_per_second": 3613.783,
      "eval_steps_per_second": 451.739,
      "step": 783500
    },
    {
      "epoch": 8.294959268689029,
      "grad_norm": 4.370767116546631,
      "learning_rate": 8.543139953419438e-06,
      "loss": 0.6395,
      "step": 783550
    },
    {
      "epoch": 8.295488590469033,
      "grad_norm": 4.654520511627197,
      "learning_rate": 8.54049333051027e-06,
      "loss": 0.6346,
      "step": 783600
    },
    {
      "epoch": 8.296017912249035,
      "grad_norm": 4.515100479125977,
      "learning_rate": 8.537899640059285e-06,
      "loss": 0.638,
      "step": 783650
    },
    {
      "epoch": 8.296547234029038,
      "grad_norm": 4.384047985076904,
      "learning_rate": 8.535253017150118e-06,
      "loss": 0.6296,
      "step": 783700
    },
    {
      "epoch": 8.297076555809042,
      "grad_norm": 4.541866302490234,
      "learning_rate": 8.53260639424095e-06,
      "loss": 0.6285,
      "step": 783750
    },
    {
      "epoch": 8.297605877589046,
      "grad_norm": 4.565084457397461,
      "learning_rate": 8.529959771331782e-06,
      "loss": 0.6306,
      "step": 783800
    },
    {
      "epoch": 8.298135199369048,
      "grad_norm": 4.6987833976745605,
      "learning_rate": 8.527313148422613e-06,
      "loss": 0.632,
      "step": 783850
    },
    {
      "epoch": 8.298664521149052,
      "grad_norm": 4.602224349975586,
      "learning_rate": 8.524666525513445e-06,
      "loss": 0.6435,
      "step": 783900
    },
    {
      "epoch": 8.299193842929055,
      "grad_norm": 4.86248254776001,
      "learning_rate": 8.522019902604278e-06,
      "loss": 0.6356,
      "step": 783950
    },
    {
      "epoch": 8.299723164709059,
      "grad_norm": 4.675846099853516,
      "learning_rate": 8.51937327969511e-06,
      "loss": 0.6463,
      "step": 784000
    },
    {
      "epoch": 8.299723164709059,
      "eval_loss": 0.3904131054878235,
      "eval_runtime": 46.4356,
      "eval_samples_per_second": 3616.41,
      "eval_steps_per_second": 452.067,
      "step": 784000
    },
    {
      "epoch": 8.300252486489061,
      "grad_norm": 3.907593250274658,
      "learning_rate": 8.516726656785943e-06,
      "loss": 0.6387,
      "step": 784050
    },
    {
      "epoch": 8.300781808269065,
      "grad_norm": 4.839494228363037,
      "learning_rate": 8.514080033876775e-06,
      "loss": 0.6382,
      "step": 784100
    },
    {
      "epoch": 8.301311130049069,
      "grad_norm": 4.725564479827881,
      "learning_rate": 8.511433410967606e-06,
      "loss": 0.6399,
      "step": 784150
    },
    {
      "epoch": 8.301840451829072,
      "grad_norm": 4.799484729766846,
      "learning_rate": 8.508786788058438e-06,
      "loss": 0.6378,
      "step": 784200
    },
    {
      "epoch": 8.302369773609074,
      "grad_norm": 4.41037130355835,
      "learning_rate": 8.50614016514927e-06,
      "loss": 0.6452,
      "step": 784250
    },
    {
      "epoch": 8.302899095389078,
      "grad_norm": 4.996960163116455,
      "learning_rate": 8.503493542240103e-06,
      "loss": 0.6395,
      "step": 784300
    },
    {
      "epoch": 8.303428417169082,
      "grad_norm": 4.411837100982666,
      "learning_rate": 8.500846919330935e-06,
      "loss": 0.6253,
      "step": 784350
    },
    {
      "epoch": 8.303957738949084,
      "grad_norm": 4.453540325164795,
      "learning_rate": 8.498200296421766e-06,
      "loss": 0.6321,
      "step": 784400
    },
    {
      "epoch": 8.304487060729087,
      "grad_norm": 4.929046630859375,
      "learning_rate": 8.495553673512599e-06,
      "loss": 0.6317,
      "step": 784450
    },
    {
      "epoch": 8.305016382509091,
      "grad_norm": 4.486615180969238,
      "learning_rate": 8.492907050603431e-06,
      "loss": 0.6387,
      "step": 784500
    },
    {
      "epoch": 8.305016382509091,
      "eval_loss": 0.3896156847476959,
      "eval_runtime": 46.4942,
      "eval_samples_per_second": 3611.851,
      "eval_steps_per_second": 451.498,
      "step": 784500
    },
    {
      "epoch": 8.305545704289095,
      "grad_norm": 5.036101818084717,
      "learning_rate": 8.490260427694263e-06,
      "loss": 0.6336,
      "step": 784550
    },
    {
      "epoch": 8.306075026069097,
      "grad_norm": 4.8259782791137695,
      "learning_rate": 8.487613804785094e-06,
      "loss": 0.6378,
      "step": 784600
    },
    {
      "epoch": 8.3066043478491,
      "grad_norm": 4.631474494934082,
      "learning_rate": 8.484967181875926e-06,
      "loss": 0.6461,
      "step": 784650
    },
    {
      "epoch": 8.307133669629104,
      "grad_norm": 3.9400033950805664,
      "learning_rate": 8.482320558966759e-06,
      "loss": 0.6365,
      "step": 784700
    },
    {
      "epoch": 8.307662991409108,
      "grad_norm": 4.907822132110596,
      "learning_rate": 8.47967393605759e-06,
      "loss": 0.6268,
      "step": 784750
    },
    {
      "epoch": 8.30819231318911,
      "grad_norm": 4.828193664550781,
      "learning_rate": 8.477027313148422e-06,
      "loss": 0.6448,
      "step": 784800
    },
    {
      "epoch": 8.308721634969114,
      "grad_norm": 4.863250255584717,
      "learning_rate": 8.474380690239254e-06,
      "loss": 0.6438,
      "step": 784850
    },
    {
      "epoch": 8.309250956749118,
      "grad_norm": 5.123607158660889,
      "learning_rate": 8.471734067330087e-06,
      "loss": 0.6378,
      "step": 784900
    },
    {
      "epoch": 8.309780278529121,
      "grad_norm": 4.482992649078369,
      "learning_rate": 8.46908744442092e-06,
      "loss": 0.6411,
      "step": 784950
    },
    {
      "epoch": 8.310309600309123,
      "grad_norm": 4.8008575439453125,
      "learning_rate": 8.466440821511752e-06,
      "loss": 0.6351,
      "step": 785000
    },
    {
      "epoch": 8.310309600309123,
      "eval_loss": 0.3907952308654785,
      "eval_runtime": 46.4113,
      "eval_samples_per_second": 3618.301,
      "eval_steps_per_second": 452.304,
      "step": 785000
    },
    {
      "epoch": 8.310838922089127,
      "grad_norm": 4.890717506408691,
      "learning_rate": 8.463794198602582e-06,
      "loss": 0.6452,
      "step": 785050
    },
    {
      "epoch": 8.311368243869131,
      "grad_norm": 4.713827610015869,
      "learning_rate": 8.461147575693415e-06,
      "loss": 0.6368,
      "step": 785100
    },
    {
      "epoch": 8.311897565649133,
      "grad_norm": 4.784011363983154,
      "learning_rate": 8.458500952784247e-06,
      "loss": 0.6352,
      "step": 785150
    },
    {
      "epoch": 8.312426887429137,
      "grad_norm": 4.433027744293213,
      "learning_rate": 8.45585432987508e-06,
      "loss": 0.635,
      "step": 785200
    },
    {
      "epoch": 8.31295620920914,
      "grad_norm": 4.32454252243042,
      "learning_rate": 8.453207706965912e-06,
      "loss": 0.6435,
      "step": 785250
    },
    {
      "epoch": 8.313485530989144,
      "grad_norm": 4.570686340332031,
      "learning_rate": 8.450561084056743e-06,
      "loss": 0.646,
      "step": 785300
    },
    {
      "epoch": 8.314014852769146,
      "grad_norm": 5.001654148101807,
      "learning_rate": 8.447914461147575e-06,
      "loss": 0.6358,
      "step": 785350
    },
    {
      "epoch": 8.31454417454915,
      "grad_norm": 4.499990940093994,
      "learning_rate": 8.445267838238407e-06,
      "loss": 0.6405,
      "step": 785400
    },
    {
      "epoch": 8.315073496329154,
      "grad_norm": 4.286524772644043,
      "learning_rate": 8.44262121532924e-06,
      "loss": 0.6232,
      "step": 785450
    },
    {
      "epoch": 8.315602818109157,
      "grad_norm": 4.88953161239624,
      "learning_rate": 8.439974592420072e-06,
      "loss": 0.6404,
      "step": 785500
    },
    {
      "epoch": 8.315602818109157,
      "eval_loss": 0.39104145765304565,
      "eval_runtime": 46.5579,
      "eval_samples_per_second": 3606.91,
      "eval_steps_per_second": 450.88,
      "step": 785500
    },
    {
      "epoch": 8.31613213988916,
      "grad_norm": 4.665996074676514,
      "learning_rate": 8.437327969510905e-06,
      "loss": 0.6366,
      "step": 785550
    },
    {
      "epoch": 8.316661461669163,
      "grad_norm": 4.666338920593262,
      "learning_rate": 8.434681346601735e-06,
      "loss": 0.6311,
      "step": 785600
    },
    {
      "epoch": 8.317190783449167,
      "grad_norm": 4.384549140930176,
      "learning_rate": 8.432087656150752e-06,
      "loss": 0.638,
      "step": 785650
    },
    {
      "epoch": 8.31772010522917,
      "grad_norm": 5.212671756744385,
      "learning_rate": 8.429441033241584e-06,
      "loss": 0.6425,
      "step": 785700
    },
    {
      "epoch": 8.318249427009173,
      "grad_norm": 4.561104774475098,
      "learning_rate": 8.426794410332415e-06,
      "loss": 0.6416,
      "step": 785750
    },
    {
      "epoch": 8.318778748789176,
      "grad_norm": 4.757076740264893,
      "learning_rate": 8.424147787423247e-06,
      "loss": 0.6416,
      "step": 785800
    },
    {
      "epoch": 8.31930807056918,
      "grad_norm": 4.323934078216553,
      "learning_rate": 8.42150116451408e-06,
      "loss": 0.6416,
      "step": 785850
    },
    {
      "epoch": 8.319837392349182,
      "grad_norm": 4.677430629730225,
      "learning_rate": 8.418854541604912e-06,
      "loss": 0.6432,
      "step": 785900
    },
    {
      "epoch": 8.320366714129186,
      "grad_norm": 4.078158378601074,
      "learning_rate": 8.416207918695745e-06,
      "loss": 0.6356,
      "step": 785950
    },
    {
      "epoch": 8.32089603590919,
      "grad_norm": 4.799701690673828,
      "learning_rate": 8.413561295786577e-06,
      "loss": 0.6316,
      "step": 786000
    },
    {
      "epoch": 8.32089603590919,
      "eval_loss": 0.3901938199996948,
      "eval_runtime": 46.4984,
      "eval_samples_per_second": 3611.52,
      "eval_steps_per_second": 451.456,
      "step": 786000
    },
    {
      "epoch": 8.321425357689193,
      "grad_norm": 4.222051620483398,
      "learning_rate": 8.410914672877408e-06,
      "loss": 0.6241,
      "step": 786050
    },
    {
      "epoch": 8.321954679469195,
      "grad_norm": 4.57279109954834,
      "learning_rate": 8.40826804996824e-06,
      "loss": 0.6305,
      "step": 786100
    },
    {
      "epoch": 8.3224840012492,
      "grad_norm": 4.285221576690674,
      "learning_rate": 8.405621427059072e-06,
      "loss": 0.6409,
      "step": 786150
    },
    {
      "epoch": 8.323013323029203,
      "grad_norm": 4.5667829513549805,
      "learning_rate": 8.402974804149905e-06,
      "loss": 0.6361,
      "step": 786200
    },
    {
      "epoch": 8.323542644809207,
      "grad_norm": 4.334782600402832,
      "learning_rate": 8.400328181240737e-06,
      "loss": 0.6214,
      "step": 786250
    },
    {
      "epoch": 8.324071966589209,
      "grad_norm": 4.114008903503418,
      "learning_rate": 8.397681558331568e-06,
      "loss": 0.6348,
      "step": 786300
    },
    {
      "epoch": 8.324601288369212,
      "grad_norm": 4.929131984710693,
      "learning_rate": 8.3950349354224e-06,
      "loss": 0.6421,
      "step": 786350
    },
    {
      "epoch": 8.325130610149216,
      "grad_norm": 4.344400882720947,
      "learning_rate": 8.392388312513233e-06,
      "loss": 0.6421,
      "step": 786400
    },
    {
      "epoch": 8.32565993192922,
      "grad_norm": 4.9443535804748535,
      "learning_rate": 8.389741689604065e-06,
      "loss": 0.6308,
      "step": 786450
    },
    {
      "epoch": 8.326189253709222,
      "grad_norm": 4.923738956451416,
      "learning_rate": 8.387095066694898e-06,
      "loss": 0.6432,
      "step": 786500
    },
    {
      "epoch": 8.326189253709222,
      "eval_loss": 0.39050644636154175,
      "eval_runtime": 46.4649,
      "eval_samples_per_second": 3614.127,
      "eval_steps_per_second": 451.782,
      "step": 786500
    },
    {
      "epoch": 8.326718575489226,
      "grad_norm": 4.821501731872559,
      "learning_rate": 8.38444844378573e-06,
      "loss": 0.6439,
      "step": 786550
    },
    {
      "epoch": 8.32724789726923,
      "grad_norm": 4.636445045471191,
      "learning_rate": 8.38180182087656e-06,
      "loss": 0.6367,
      "step": 786600
    },
    {
      "epoch": 8.327777219049231,
      "grad_norm": 4.318636417388916,
      "learning_rate": 8.379155197967393e-06,
      "loss": 0.6354,
      "step": 786650
    },
    {
      "epoch": 8.328306540829235,
      "grad_norm": 4.576323509216309,
      "learning_rate": 8.376508575058226e-06,
      "loss": 0.6279,
      "step": 786700
    },
    {
      "epoch": 8.328835862609239,
      "grad_norm": 4.750942707061768,
      "learning_rate": 8.373861952149058e-06,
      "loss": 0.6401,
      "step": 786750
    },
    {
      "epoch": 8.329365184389243,
      "grad_norm": 4.437430381774902,
      "learning_rate": 8.37121532923989e-06,
      "loss": 0.6277,
      "step": 786800
    },
    {
      "epoch": 8.329894506169245,
      "grad_norm": 4.434600830078125,
      "learning_rate": 8.368568706330723e-06,
      "loss": 0.6367,
      "step": 786850
    },
    {
      "epoch": 8.330423827949248,
      "grad_norm": 4.532659530639648,
      "learning_rate": 8.365922083421553e-06,
      "loss": 0.6312,
      "step": 786900
    },
    {
      "epoch": 8.330953149729252,
      "grad_norm": 4.8603410720825195,
      "learning_rate": 8.363275460512386e-06,
      "loss": 0.6387,
      "step": 786950
    },
    {
      "epoch": 8.331482471509256,
      "grad_norm": 5.0092291831970215,
      "learning_rate": 8.360628837603218e-06,
      "loss": 0.6447,
      "step": 787000
    },
    {
      "epoch": 8.331482471509256,
      "eval_loss": 0.39059075713157654,
      "eval_runtime": 46.4287,
      "eval_samples_per_second": 3616.946,
      "eval_steps_per_second": 452.134,
      "step": 787000
    },
    {
      "epoch": 8.332011793289258,
      "grad_norm": 4.800633907318115,
      "learning_rate": 8.35798221469405e-06,
      "loss": 0.6469,
      "step": 787050
    },
    {
      "epoch": 8.332541115069262,
      "grad_norm": 4.183102130889893,
      "learning_rate": 8.355335591784883e-06,
      "loss": 0.6292,
      "step": 787100
    },
    {
      "epoch": 8.333070436849265,
      "grad_norm": 4.484714508056641,
      "learning_rate": 8.352688968875714e-06,
      "loss": 0.6502,
      "step": 787150
    },
    {
      "epoch": 8.33359975862927,
      "grad_norm": 4.971566677093506,
      "learning_rate": 8.350042345966546e-06,
      "loss": 0.6431,
      "step": 787200
    },
    {
      "epoch": 8.334129080409271,
      "grad_norm": 4.624453067779541,
      "learning_rate": 8.347395723057379e-06,
      "loss": 0.639,
      "step": 787250
    },
    {
      "epoch": 8.334658402189275,
      "grad_norm": 4.578484058380127,
      "learning_rate": 8.344749100148211e-06,
      "loss": 0.6378,
      "step": 787300
    },
    {
      "epoch": 8.335187723969279,
      "grad_norm": 4.592296123504639,
      "learning_rate": 8.342102477239043e-06,
      "loss": 0.6453,
      "step": 787350
    },
    {
      "epoch": 8.33571704574928,
      "grad_norm": 5.083807468414307,
      "learning_rate": 8.339455854329876e-06,
      "loss": 0.6426,
      "step": 787400
    },
    {
      "epoch": 8.336246367529284,
      "grad_norm": 4.246881484985352,
      "learning_rate": 8.336809231420707e-06,
      "loss": 0.6353,
      "step": 787450
    },
    {
      "epoch": 8.336775689309288,
      "grad_norm": 4.645823001861572,
      "learning_rate": 8.334162608511539e-06,
      "loss": 0.6291,
      "step": 787500
    },
    {
      "epoch": 8.336775689309288,
      "eval_loss": 0.39022698998451233,
      "eval_runtime": 46.4623,
      "eval_samples_per_second": 3614.326,
      "eval_steps_per_second": 451.807,
      "step": 787500
    },
    {
      "epoch": 8.337305011089292,
      "grad_norm": 4.7589192390441895,
      "learning_rate": 8.331515985602371e-06,
      "loss": 0.6439,
      "step": 787550
    },
    {
      "epoch": 8.337834332869294,
      "grad_norm": 4.8201165199279785,
      "learning_rate": 8.328869362693204e-06,
      "loss": 0.6317,
      "step": 787600
    },
    {
      "epoch": 8.338363654649298,
      "grad_norm": Infinity,
      "learning_rate": 8.326275672242218e-06,
      "loss": 0.6332,
      "step": 787650
    },
    {
      "epoch": 8.338892976429301,
      "grad_norm": 4.254781246185303,
      "learning_rate": 8.323629049333051e-06,
      "loss": 0.6408,
      "step": 787700
    },
    {
      "epoch": 8.339422298209305,
      "grad_norm": 4.579209804534912,
      "learning_rate": 8.320982426423883e-06,
      "loss": 0.6363,
      "step": 787750
    },
    {
      "epoch": 8.339951619989307,
      "grad_norm": 4.305746555328369,
      "learning_rate": 8.318335803514716e-06,
      "loss": 0.6399,
      "step": 787800
    },
    {
      "epoch": 8.34048094176931,
      "grad_norm": 4.8411359786987305,
      "learning_rate": 8.315689180605548e-06,
      "loss": 0.6295,
      "step": 787850
    },
    {
      "epoch": 8.341010263549315,
      "grad_norm": 4.47477388381958,
      "learning_rate": 8.313042557696379e-06,
      "loss": 0.6392,
      "step": 787900
    },
    {
      "epoch": 8.341539585329318,
      "grad_norm": 4.999330520629883,
      "learning_rate": 8.310395934787211e-06,
      "loss": 0.6348,
      "step": 787950
    },
    {
      "epoch": 8.34206890710932,
      "grad_norm": 4.353242874145508,
      "learning_rate": 8.307749311878044e-06,
      "loss": 0.6427,
      "step": 788000
    },
    {
      "epoch": 8.34206890710932,
      "eval_loss": 0.39027607440948486,
      "eval_runtime": 46.5302,
      "eval_samples_per_second": 3609.052,
      "eval_steps_per_second": 451.148,
      "step": 788000
    },
    {
      "epoch": 8.342598228889324,
      "grad_norm": 4.6385297775268555,
      "learning_rate": 8.305102688968876e-06,
      "loss": 0.636,
      "step": 788050
    },
    {
      "epoch": 8.343127550669328,
      "grad_norm": 4.795906066894531,
      "learning_rate": 8.302456066059708e-06,
      "loss": 0.6379,
      "step": 788100
    },
    {
      "epoch": 8.34365687244933,
      "grad_norm": 4.073408603668213,
      "learning_rate": 8.299809443150539e-06,
      "loss": 0.6243,
      "step": 788150
    },
    {
      "epoch": 8.344186194229334,
      "grad_norm": 5.165644645690918,
      "learning_rate": 8.297162820241372e-06,
      "loss": 0.6488,
      "step": 788200
    },
    {
      "epoch": 8.344715516009337,
      "grad_norm": 4.585714340209961,
      "learning_rate": 8.294516197332204e-06,
      "loss": 0.634,
      "step": 788250
    },
    {
      "epoch": 8.345244837789341,
      "grad_norm": 4.836217403411865,
      "learning_rate": 8.291869574423036e-06,
      "loss": 0.6426,
      "step": 788300
    },
    {
      "epoch": 8.345774159569343,
      "grad_norm": 4.472433090209961,
      "learning_rate": 8.289222951513869e-06,
      "loss": 0.6354,
      "step": 788350
    },
    {
      "epoch": 8.346303481349347,
      "grad_norm": 4.421857833862305,
      "learning_rate": 8.286576328604701e-06,
      "loss": 0.6385,
      "step": 788400
    },
    {
      "epoch": 8.34683280312935,
      "grad_norm": 4.327502250671387,
      "learning_rate": 8.283929705695532e-06,
      "loss": 0.6473,
      "step": 788450
    },
    {
      "epoch": 8.347362124909354,
      "grad_norm": 4.714291572570801,
      "learning_rate": 8.281283082786364e-06,
      "loss": 0.634,
      "step": 788500
    },
    {
      "epoch": 8.347362124909354,
      "eval_loss": 0.3902740478515625,
      "eval_runtime": 46.5011,
      "eval_samples_per_second": 3611.314,
      "eval_steps_per_second": 451.43,
      "step": 788500
    },
    {
      "epoch": 8.347891446689356,
      "grad_norm": 4.590811252593994,
      "learning_rate": 8.278636459877197e-06,
      "loss": 0.6362,
      "step": 788550
    },
    {
      "epoch": 8.34842076846936,
      "grad_norm": 4.351325035095215,
      "learning_rate": 8.275989836968029e-06,
      "loss": 0.6324,
      "step": 788600
    },
    {
      "epoch": 8.348950090249364,
      "grad_norm": 4.014160633087158,
      "learning_rate": 8.273343214058861e-06,
      "loss": 0.6303,
      "step": 788650
    },
    {
      "epoch": 8.349479412029368,
      "grad_norm": 4.710206031799316,
      "learning_rate": 8.270696591149694e-06,
      "loss": 0.6399,
      "step": 788700
    },
    {
      "epoch": 8.35000873380937,
      "grad_norm": 3.9735050201416016,
      "learning_rate": 8.268049968240525e-06,
      "loss": 0.6352,
      "step": 788750
    },
    {
      "epoch": 8.350538055589373,
      "grad_norm": 4.859617710113525,
      "learning_rate": 8.265456277789541e-06,
      "loss": 0.6291,
      "step": 788800
    },
    {
      "epoch": 8.351067377369377,
      "grad_norm": 4.6457648277282715,
      "learning_rate": 8.262809654880373e-06,
      "loss": 0.6327,
      "step": 788850
    },
    {
      "epoch": 8.351596699149379,
      "grad_norm": 4.63134765625,
      "learning_rate": 8.260163031971204e-06,
      "loss": 0.643,
      "step": 788900
    },
    {
      "epoch": 8.352126020929383,
      "grad_norm": 4.38779878616333,
      "learning_rate": 8.257516409062037e-06,
      "loss": 0.6319,
      "step": 788950
    },
    {
      "epoch": 8.352655342709387,
      "grad_norm": 4.539344787597656,
      "learning_rate": 8.254869786152869e-06,
      "loss": 0.6472,
      "step": 789000
    },
    {
      "epoch": 8.352655342709387,
      "eval_loss": 0.3911149799823761,
      "eval_runtime": 46.4944,
      "eval_samples_per_second": 3611.832,
      "eval_steps_per_second": 451.495,
      "step": 789000
    },
    {
      "epoch": 8.35318466448939,
      "grad_norm": 4.827871799468994,
      "learning_rate": 8.252223163243701e-06,
      "loss": 0.6326,
      "step": 789050
    },
    {
      "epoch": 8.353713986269392,
      "grad_norm": 4.30657958984375,
      "learning_rate": 8.249576540334534e-06,
      "loss": 0.641,
      "step": 789100
    },
    {
      "epoch": 8.354243308049396,
      "grad_norm": 4.608895778656006,
      "learning_rate": 8.246929917425364e-06,
      "loss": 0.6326,
      "step": 789150
    },
    {
      "epoch": 8.3547726298294,
      "grad_norm": 4.942032814025879,
      "learning_rate": 8.244283294516197e-06,
      "loss": 0.634,
      "step": 789200
    },
    {
      "epoch": 8.355301951609404,
      "grad_norm": 4.9782795906066895,
      "learning_rate": 8.24163667160703e-06,
      "loss": 0.6491,
      "step": 789250
    },
    {
      "epoch": 8.355831273389406,
      "grad_norm": 4.520495891571045,
      "learning_rate": 8.238990048697862e-06,
      "loss": 0.6302,
      "step": 789300
    },
    {
      "epoch": 8.35636059516941,
      "grad_norm": 4.378026485443115,
      "learning_rate": 8.236343425788694e-06,
      "loss": 0.634,
      "step": 789350
    },
    {
      "epoch": 8.356889916949413,
      "grad_norm": 4.804400444030762,
      "learning_rate": 8.233696802879526e-06,
      "loss": 0.635,
      "step": 789400
    },
    {
      "epoch": 8.357419238729417,
      "grad_norm": 5.006625652313232,
      "learning_rate": 8.231050179970357e-06,
      "loss": 0.6217,
      "step": 789450
    },
    {
      "epoch": 8.357948560509419,
      "grad_norm": 4.545747756958008,
      "learning_rate": 8.22840355706119e-06,
      "loss": 0.633,
      "step": 789500
    },
    {
      "epoch": 8.357948560509419,
      "eval_loss": 0.3898204565048218,
      "eval_runtime": 46.5477,
      "eval_samples_per_second": 3607.7,
      "eval_steps_per_second": 450.979,
      "step": 789500
    },
    {
      "epoch": 8.358477882289423,
      "grad_norm": 4.747410297393799,
      "learning_rate": 8.225756934152022e-06,
      "loss": 0.6341,
      "step": 789550
    },
    {
      "epoch": 8.359007204069426,
      "grad_norm": 5.156295299530029,
      "learning_rate": 8.223110311242854e-06,
      "loss": 0.6387,
      "step": 789600
    },
    {
      "epoch": 8.359536525849428,
      "grad_norm": 4.688225269317627,
      "learning_rate": 8.220463688333687e-06,
      "loss": 0.6303,
      "step": 789650
    },
    {
      "epoch": 8.360065847629432,
      "grad_norm": 4.217562675476074,
      "learning_rate": 8.21781706542452e-06,
      "loss": 0.6363,
      "step": 789700
    },
    {
      "epoch": 8.360595169409436,
      "grad_norm": 4.632173538208008,
      "learning_rate": 8.21517044251535e-06,
      "loss": 0.6302,
      "step": 789750
    },
    {
      "epoch": 8.36112449118944,
      "grad_norm": 4.680335521697998,
      "learning_rate": 8.212523819606182e-06,
      "loss": 0.6453,
      "step": 789800
    },
    {
      "epoch": 8.361653812969442,
      "grad_norm": 4.956468105316162,
      "learning_rate": 8.209877196697015e-06,
      "loss": 0.6432,
      "step": 789850
    },
    {
      "epoch": 8.362183134749445,
      "grad_norm": 4.746406555175781,
      "learning_rate": 8.207230573787847e-06,
      "loss": 0.6343,
      "step": 789900
    },
    {
      "epoch": 8.362712456529449,
      "grad_norm": 4.604976654052734,
      "learning_rate": 8.20458395087868e-06,
      "loss": 0.643,
      "step": 789950
    },
    {
      "epoch": 8.363241778309453,
      "grad_norm": 4.7148051261901855,
      "learning_rate": 8.20193732796951e-06,
      "loss": 0.6219,
      "step": 790000
    },
    {
      "epoch": 8.363241778309453,
      "eval_loss": 0.3894802927970886,
      "eval_runtime": 46.5009,
      "eval_samples_per_second": 3611.326,
      "eval_steps_per_second": 451.432,
      "step": 790000
    },
    {
      "epoch": 8.363771100089455,
      "grad_norm": 4.949527740478516,
      "learning_rate": 8.199290705060343e-06,
      "loss": 0.6439,
      "step": 790050
    },
    {
      "epoch": 8.364300421869459,
      "grad_norm": 4.495366096496582,
      "learning_rate": 8.196644082151175e-06,
      "loss": 0.6371,
      "step": 790100
    },
    {
      "epoch": 8.364829743649462,
      "grad_norm": 4.808781147003174,
      "learning_rate": 8.193997459242007e-06,
      "loss": 0.6347,
      "step": 790150
    },
    {
      "epoch": 8.365359065429466,
      "grad_norm": 5.065963268280029,
      "learning_rate": 8.19135083633284e-06,
      "loss": 0.6275,
      "step": 790200
    },
    {
      "epoch": 8.365888387209468,
      "grad_norm": 4.111913681030273,
      "learning_rate": 8.188704213423672e-06,
      "loss": 0.6275,
      "step": 790250
    },
    {
      "epoch": 8.366417708989472,
      "grad_norm": 4.024889945983887,
      "learning_rate": 8.186057590514503e-06,
      "loss": 0.6351,
      "step": 790300
    },
    {
      "epoch": 8.366947030769476,
      "grad_norm": 4.6953558921813965,
      "learning_rate": 8.183410967605335e-06,
      "loss": 0.6406,
      "step": 790350
    },
    {
      "epoch": 8.367476352549478,
      "grad_norm": 4.882518768310547,
      "learning_rate": 8.180764344696168e-06,
      "loss": 0.6412,
      "step": 790400
    },
    {
      "epoch": 8.368005674329481,
      "grad_norm": 5.059083461761475,
      "learning_rate": 8.178117721787e-06,
      "loss": 0.6251,
      "step": 790450
    },
    {
      "epoch": 8.368534996109485,
      "grad_norm": 4.052826881408691,
      "learning_rate": 8.175471098877833e-06,
      "loss": 0.633,
      "step": 790500
    },
    {
      "epoch": 8.368534996109485,
      "eval_loss": 0.3894565999507904,
      "eval_runtime": 46.4743,
      "eval_samples_per_second": 3613.393,
      "eval_steps_per_second": 451.69,
      "step": 790500
    },
    {
      "epoch": 8.369064317889489,
      "grad_norm": 4.546014785766602,
      "learning_rate": 8.172824475968665e-06,
      "loss": 0.6361,
      "step": 790550
    },
    {
      "epoch": 8.36959363966949,
      "grad_norm": 4.447874546051025,
      "learning_rate": 8.170177853059496e-06,
      "loss": 0.6259,
      "step": 790600
    },
    {
      "epoch": 8.370122961449495,
      "grad_norm": 4.539097785949707,
      "learning_rate": 8.167531230150328e-06,
      "loss": 0.6307,
      "step": 790650
    },
    {
      "epoch": 8.370652283229498,
      "grad_norm": 4.791313171386719,
      "learning_rate": 8.16488460724116e-06,
      "loss": 0.6381,
      "step": 790700
    },
    {
      "epoch": 8.371181605009502,
      "grad_norm": 4.699459552764893,
      "learning_rate": 8.162237984331993e-06,
      "loss": 0.6493,
      "step": 790750
    },
    {
      "epoch": 8.371710926789504,
      "grad_norm": 4.606829643249512,
      "learning_rate": 8.159591361422825e-06,
      "loss": 0.6556,
      "step": 790800
    },
    {
      "epoch": 8.372240248569508,
      "grad_norm": 4.537849426269531,
      "learning_rate": 8.156944738513656e-06,
      "loss": 0.6439,
      "step": 790850
    },
    {
      "epoch": 8.372769570349512,
      "grad_norm": 4.63598108291626,
      "learning_rate": 8.154298115604489e-06,
      "loss": 0.6273,
      "step": 790900
    },
    {
      "epoch": 8.373298892129515,
      "grad_norm": 4.597099781036377,
      "learning_rate": 8.151651492695321e-06,
      "loss": 0.6352,
      "step": 790950
    },
    {
      "epoch": 8.373828213909517,
      "grad_norm": 4.35233736038208,
      "learning_rate": 8.149004869786153e-06,
      "loss": 0.629,
      "step": 791000
    },
    {
      "epoch": 8.373828213909517,
      "eval_loss": 0.3896114230155945,
      "eval_runtime": 46.512,
      "eval_samples_per_second": 3610.47,
      "eval_steps_per_second": 451.325,
      "step": 791000
    },
    {
      "epoch": 8.374357535689521,
      "grad_norm": 4.932254314422607,
      "learning_rate": 8.146358246876986e-06,
      "loss": 0.6348,
      "step": 791050
    },
    {
      "epoch": 8.374886857469525,
      "grad_norm": 4.820384979248047,
      "learning_rate": 8.143711623967818e-06,
      "loss": 0.6459,
      "step": 791100
    },
    {
      "epoch": 8.375416179249527,
      "grad_norm": 4.5625224113464355,
      "learning_rate": 8.141065001058649e-06,
      "loss": 0.641,
      "step": 791150
    },
    {
      "epoch": 8.37594550102953,
      "grad_norm": 4.208012580871582,
      "learning_rate": 8.138418378149481e-06,
      "loss": 0.6356,
      "step": 791200
    },
    {
      "epoch": 8.376474822809534,
      "grad_norm": 4.794152736663818,
      "learning_rate": 8.135771755240314e-06,
      "loss": 0.643,
      "step": 791250
    },
    {
      "epoch": 8.377004144589538,
      "grad_norm": 4.1369805335998535,
      "learning_rate": 8.133125132331146e-06,
      "loss": 0.638,
      "step": 791300
    },
    {
      "epoch": 8.37753346636954,
      "grad_norm": 4.747556686401367,
      "learning_rate": 8.130478509421978e-06,
      "loss": 0.6279,
      "step": 791350
    },
    {
      "epoch": 8.378062788149544,
      "grad_norm": 4.952105522155762,
      "learning_rate": 8.127831886512811e-06,
      "loss": 0.6309,
      "step": 791400
    },
    {
      "epoch": 8.378592109929548,
      "grad_norm": 4.969558238983154,
      "learning_rate": 8.125185263603642e-06,
      "loss": 0.6381,
      "step": 791450
    },
    {
      "epoch": 8.379121431709551,
      "grad_norm": 5.077550411224365,
      "learning_rate": 8.122538640694474e-06,
      "loss": 0.6303,
      "step": 791500
    },
    {
      "epoch": 8.379121431709551,
      "eval_loss": 0.38910984992980957,
      "eval_runtime": 46.4687,
      "eval_samples_per_second": 3613.831,
      "eval_steps_per_second": 451.745,
      "step": 791500
    },
    {
      "epoch": 8.379650753489553,
      "grad_norm": 5.067365646362305,
      "learning_rate": 8.119892017785306e-06,
      "loss": 0.6386,
      "step": 791550
    },
    {
      "epoch": 8.380180075269557,
      "grad_norm": 4.806464672088623,
      "learning_rate": 8.117245394876139e-06,
      "loss": 0.6389,
      "step": 791600
    },
    {
      "epoch": 8.38070939704956,
      "grad_norm": 4.949047088623047,
      "learning_rate": 8.114598771966971e-06,
      "loss": 0.6367,
      "step": 791650
    },
    {
      "epoch": 8.381238718829565,
      "grad_norm": 4.472892761230469,
      "learning_rate": 8.111952149057802e-06,
      "loss": 0.6428,
      "step": 791700
    },
    {
      "epoch": 8.381768040609566,
      "grad_norm": 3.912001132965088,
      "learning_rate": 8.109305526148634e-06,
      "loss": 0.6411,
      "step": 791750
    },
    {
      "epoch": 8.38229736238957,
      "grad_norm": 4.705994606018066,
      "learning_rate": 8.106658903239467e-06,
      "loss": 0.6302,
      "step": 791800
    },
    {
      "epoch": 8.382826684169574,
      "grad_norm": 5.443375587463379,
      "learning_rate": 8.104012280330299e-06,
      "loss": 0.6329,
      "step": 791850
    },
    {
      "epoch": 8.383356005949576,
      "grad_norm": 4.459743499755859,
      "learning_rate": 8.101365657421132e-06,
      "loss": 0.6364,
      "step": 791900
    },
    {
      "epoch": 8.38388532772958,
      "grad_norm": 4.53117561340332,
      "learning_rate": 8.098719034511964e-06,
      "loss": 0.6421,
      "step": 791950
    },
    {
      "epoch": 8.384414649509583,
      "grad_norm": 4.914463996887207,
      "learning_rate": 8.096072411602795e-06,
      "loss": 0.6349,
      "step": 792000
    },
    {
      "epoch": 8.384414649509583,
      "eval_loss": 0.38905033469200134,
      "eval_runtime": 46.5123,
      "eval_samples_per_second": 3610.443,
      "eval_steps_per_second": 451.322,
      "step": 792000
    },
    {
      "epoch": 8.384943971289587,
      "grad_norm": 4.934455394744873,
      "learning_rate": 8.093425788693627e-06,
      "loss": 0.652,
      "step": 792050
    },
    {
      "epoch": 8.38547329306959,
      "grad_norm": 4.552479267120361,
      "learning_rate": 8.09077916578446e-06,
      "loss": 0.6326,
      "step": 792100
    },
    {
      "epoch": 8.386002614849593,
      "grad_norm": 4.876173973083496,
      "learning_rate": 8.088132542875292e-06,
      "loss": 0.639,
      "step": 792150
    },
    {
      "epoch": 8.386531936629597,
      "grad_norm": 4.19546365737915,
      "learning_rate": 8.085485919966124e-06,
      "loss": 0.6304,
      "step": 792200
    },
    {
      "epoch": 8.3870612584096,
      "grad_norm": 4.555760383605957,
      "learning_rate": 8.082839297056955e-06,
      "loss": 0.6341,
      "step": 792250
    },
    {
      "epoch": 8.387590580189602,
      "grad_norm": 4.7051825523376465,
      "learning_rate": 8.080192674147787e-06,
      "loss": 0.6339,
      "step": 792300
    },
    {
      "epoch": 8.388119901969606,
      "grad_norm": 4.518062591552734,
      "learning_rate": 8.07754605123862e-06,
      "loss": 0.6381,
      "step": 792350
    },
    {
      "epoch": 8.38864922374961,
      "grad_norm": 4.967070579528809,
      "learning_rate": 8.074899428329452e-06,
      "loss": 0.6418,
      "step": 792400
    },
    {
      "epoch": 8.389178545529614,
      "grad_norm": 5.090284824371338,
      "learning_rate": 8.072252805420285e-06,
      "loss": 0.6505,
      "step": 792450
    },
    {
      "epoch": 8.389707867309616,
      "grad_norm": 4.70893669128418,
      "learning_rate": 8.069606182511117e-06,
      "loss": 0.6362,
      "step": 792500
    },
    {
      "epoch": 8.389707867309616,
      "eval_loss": 0.3888521194458008,
      "eval_runtime": 46.5656,
      "eval_samples_per_second": 3606.31,
      "eval_steps_per_second": 450.805,
      "step": 792500
    },
    {
      "epoch": 8.39023718908962,
      "grad_norm": 4.832794666290283,
      "learning_rate": 8.066959559601948e-06,
      "loss": 0.6353,
      "step": 792550
    },
    {
      "epoch": 8.390766510869623,
      "grad_norm": 4.222977638244629,
      "learning_rate": 8.06431293669278e-06,
      "loss": 0.6327,
      "step": 792600
    },
    {
      "epoch": 8.391295832649625,
      "grad_norm": 5.1449971199035645,
      "learning_rate": 8.061666313783613e-06,
      "loss": 0.6458,
      "step": 792650
    },
    {
      "epoch": 8.391825154429629,
      "grad_norm": 4.871424674987793,
      "learning_rate": 8.059019690874445e-06,
      "loss": 0.639,
      "step": 792700
    },
    {
      "epoch": 8.392354476209633,
      "grad_norm": 4.590225696563721,
      "learning_rate": 8.056373067965277e-06,
      "loss": 0.6279,
      "step": 792750
    },
    {
      "epoch": 8.392883797989636,
      "grad_norm": 4.616271495819092,
      "learning_rate": 8.053779377514292e-06,
      "loss": 0.6345,
      "step": 792800
    },
    {
      "epoch": 8.393413119769638,
      "grad_norm": 4.61774206161499,
      "learning_rate": 8.051132754605124e-06,
      "loss": 0.6404,
      "step": 792850
    },
    {
      "epoch": 8.393942441549642,
      "grad_norm": 4.216751575469971,
      "learning_rate": 8.048486131695957e-06,
      "loss": 0.6388,
      "step": 792900
    },
    {
      "epoch": 8.394471763329646,
      "grad_norm": 4.485898971557617,
      "learning_rate": 8.04583950878679e-06,
      "loss": 0.6385,
      "step": 792950
    },
    {
      "epoch": 8.39500108510965,
      "grad_norm": 4.74330997467041,
      "learning_rate": 8.04319288587762e-06,
      "loss": 0.6426,
      "step": 793000
    },
    {
      "epoch": 8.39500108510965,
      "eval_loss": 0.3891887962818146,
      "eval_runtime": 46.5163,
      "eval_samples_per_second": 3610.13,
      "eval_steps_per_second": 451.282,
      "step": 793000
    },
    {
      "epoch": 8.395530406889652,
      "grad_norm": 4.676723957061768,
      "learning_rate": 8.040546262968452e-06,
      "loss": 0.6378,
      "step": 793050
    },
    {
      "epoch": 8.396059728669655,
      "grad_norm": 4.714140892028809,
      "learning_rate": 8.037899640059285e-06,
      "loss": 0.6326,
      "step": 793100
    },
    {
      "epoch": 8.39658905044966,
      "grad_norm": 4.949926853179932,
      "learning_rate": 8.035253017150117e-06,
      "loss": 0.6366,
      "step": 793150
    },
    {
      "epoch": 8.397118372229663,
      "grad_norm": 4.220546245574951,
      "learning_rate": 8.03260639424095e-06,
      "loss": 0.649,
      "step": 793200
    },
    {
      "epoch": 8.397647694009665,
      "grad_norm": 4.351393222808838,
      "learning_rate": 8.029959771331782e-06,
      "loss": 0.6365,
      "step": 793250
    },
    {
      "epoch": 8.398177015789669,
      "grad_norm": 5.01981258392334,
      "learning_rate": 8.027313148422613e-06,
      "loss": 0.6393,
      "step": 793300
    },
    {
      "epoch": 8.398706337569672,
      "grad_norm": 4.775460720062256,
      "learning_rate": 8.024666525513445e-06,
      "loss": 0.6314,
      "step": 793350
    },
    {
      "epoch": 8.399235659349674,
      "grad_norm": 4.700631141662598,
      "learning_rate": 8.022019902604278e-06,
      "loss": 0.6377,
      "step": 793400
    },
    {
      "epoch": 8.399764981129678,
      "grad_norm": 4.461541175842285,
      "learning_rate": 8.01937327969511e-06,
      "loss": 0.6429,
      "step": 793450
    },
    {
      "epoch": 8.400294302909682,
      "grad_norm": 4.345613956451416,
      "learning_rate": 8.016726656785942e-06,
      "loss": 0.6322,
      "step": 793500
    },
    {
      "epoch": 8.400294302909682,
      "eval_loss": 0.3888726532459259,
      "eval_runtime": 46.6097,
      "eval_samples_per_second": 3602.899,
      "eval_steps_per_second": 450.379,
      "step": 793500
    },
    {
      "epoch": 8.400823624689686,
      "grad_norm": 3.966139316558838,
      "learning_rate": 8.014080033876773e-06,
      "loss": 0.6294,
      "step": 793550
    },
    {
      "epoch": 8.401352946469688,
      "grad_norm": 4.359494209289551,
      "learning_rate": 8.011433410967605e-06,
      "loss": 0.6396,
      "step": 793600
    },
    {
      "epoch": 8.401882268249691,
      "grad_norm": 4.791966438293457,
      "learning_rate": 8.008786788058438e-06,
      "loss": 0.6359,
      "step": 793650
    },
    {
      "epoch": 8.402411590029695,
      "grad_norm": 4.324556827545166,
      "learning_rate": 8.00614016514927e-06,
      "loss": 0.6338,
      "step": 793700
    },
    {
      "epoch": 8.402940911809699,
      "grad_norm": 4.313961505889893,
      "learning_rate": 8.003493542240103e-06,
      "loss": 0.6289,
      "step": 793750
    },
    {
      "epoch": 8.403470233589701,
      "grad_norm": 4.486508369445801,
      "learning_rate": 8.000846919330935e-06,
      "loss": 0.6493,
      "step": 793800
    },
    {
      "epoch": 8.403999555369705,
      "grad_norm": 4.544310569763184,
      "learning_rate": 7.998200296421766e-06,
      "loss": 0.6353,
      "step": 793850
    },
    {
      "epoch": 8.404528877149708,
      "grad_norm": 4.328254699707031,
      "learning_rate": 7.995553673512598e-06,
      "loss": 0.6205,
      "step": 793900
    },
    {
      "epoch": 8.405058198929712,
      "grad_norm": 4.131504535675049,
      "learning_rate": 7.99290705060343e-06,
      "loss": 0.6351,
      "step": 793950
    },
    {
      "epoch": 8.405587520709714,
      "grad_norm": 4.462597846984863,
      "learning_rate": 7.990260427694263e-06,
      "loss": 0.6199,
      "step": 794000
    },
    {
      "epoch": 8.405587520709714,
      "eval_loss": 0.38908037543296814,
      "eval_runtime": 46.5426,
      "eval_samples_per_second": 3608.089,
      "eval_steps_per_second": 451.027,
      "step": 794000
    },
    {
      "epoch": 8.406116842489718,
      "grad_norm": 4.421778678894043,
      "learning_rate": 7.987613804785095e-06,
      "loss": 0.639,
      "step": 794050
    },
    {
      "epoch": 8.406646164269722,
      "grad_norm": 4.719503402709961,
      "learning_rate": 7.984967181875926e-06,
      "loss": 0.6441,
      "step": 794100
    },
    {
      "epoch": 8.407175486049724,
      "grad_norm": 4.996929168701172,
      "learning_rate": 7.982320558966759e-06,
      "loss": 0.6228,
      "step": 794150
    },
    {
      "epoch": 8.407704807829727,
      "grad_norm": 4.594552040100098,
      "learning_rate": 7.979673936057591e-06,
      "loss": 0.6338,
      "step": 794200
    },
    {
      "epoch": 8.408234129609731,
      "grad_norm": 4.640714168548584,
      "learning_rate": 7.977027313148423e-06,
      "loss": 0.6304,
      "step": 794250
    },
    {
      "epoch": 8.408763451389735,
      "grad_norm": 4.200045585632324,
      "learning_rate": 7.974380690239256e-06,
      "loss": 0.6254,
      "step": 794300
    },
    {
      "epoch": 8.409292773169737,
      "grad_norm": 4.597976207733154,
      "learning_rate": 7.971734067330088e-06,
      "loss": 0.6369,
      "step": 794350
    },
    {
      "epoch": 8.40982209494974,
      "grad_norm": 4.767002105712891,
      "learning_rate": 7.969087444420919e-06,
      "loss": 0.6195,
      "step": 794400
    },
    {
      "epoch": 8.410351416729744,
      "grad_norm": 4.79957389831543,
      "learning_rate": 7.966440821511751e-06,
      "loss": 0.6246,
      "step": 794450
    },
    {
      "epoch": 8.410880738509748,
      "grad_norm": 4.709751129150391,
      "learning_rate": 7.963794198602584e-06,
      "loss": 0.6441,
      "step": 794500
    },
    {
      "epoch": 8.410880738509748,
      "eval_loss": 0.38942408561706543,
      "eval_runtime": 46.5236,
      "eval_samples_per_second": 3609.563,
      "eval_steps_per_second": 451.211,
      "step": 794500
    },
    {
      "epoch": 8.41141006028975,
      "grad_norm": 4.739652156829834,
      "learning_rate": 7.961147575693416e-06,
      "loss": 0.6395,
      "step": 794550
    },
    {
      "epoch": 8.411939382069754,
      "grad_norm": 4.973596096038818,
      "learning_rate": 7.958500952784249e-06,
      "loss": 0.6453,
      "step": 794600
    },
    {
      "epoch": 8.412468703849758,
      "grad_norm": 4.537568092346191,
      "learning_rate": 7.955854329875081e-06,
      "loss": 0.6402,
      "step": 794650
    },
    {
      "epoch": 8.412998025629761,
      "grad_norm": 4.377408027648926,
      "learning_rate": 7.953207706965912e-06,
      "loss": 0.6436,
      "step": 794700
    },
    {
      "epoch": 8.413527347409763,
      "grad_norm": 4.2069878578186035,
      "learning_rate": 7.950561084056744e-06,
      "loss": 0.64,
      "step": 794750
    },
    {
      "epoch": 8.414056669189767,
      "grad_norm": 4.466297149658203,
      "learning_rate": 7.94796739360576e-06,
      "loss": 0.6468,
      "step": 794800
    },
    {
      "epoch": 8.414585990969771,
      "grad_norm": 4.654839038848877,
      "learning_rate": 7.945320770696591e-06,
      "loss": 0.6365,
      "step": 794850
    },
    {
      "epoch": 8.415115312749773,
      "grad_norm": 4.323620319366455,
      "learning_rate": 7.942674147787424e-06,
      "loss": 0.6372,
      "step": 794900
    },
    {
      "epoch": 8.415644634529777,
      "grad_norm": 4.251633167266846,
      "learning_rate": 7.940027524878256e-06,
      "loss": 0.6293,
      "step": 794950
    },
    {
      "epoch": 8.41617395630978,
      "grad_norm": 4.454064846038818,
      "learning_rate": 7.937380901969088e-06,
      "loss": 0.6428,
      "step": 795000
    },
    {
      "epoch": 8.41617395630978,
      "eval_loss": 0.389746755361557,
      "eval_runtime": 46.499,
      "eval_samples_per_second": 3611.479,
      "eval_steps_per_second": 451.451,
      "step": 795000
    },
    {
      "epoch": 8.416703278089784,
      "grad_norm": 4.565838813781738,
      "learning_rate": 7.93473427905992e-06,
      "loss": 0.6343,
      "step": 795050
    },
    {
      "epoch": 8.417232599869786,
      "grad_norm": 4.473510265350342,
      "learning_rate": 7.932087656150753e-06,
      "loss": 0.6407,
      "step": 795100
    },
    {
      "epoch": 8.41776192164979,
      "grad_norm": 4.009471893310547,
      "learning_rate": 7.929441033241584e-06,
      "loss": 0.6394,
      "step": 795150
    },
    {
      "epoch": 8.418291243429794,
      "grad_norm": 4.795482635498047,
      "learning_rate": 7.926794410332416e-06,
      "loss": 0.6151,
      "step": 795200
    },
    {
      "epoch": 8.418820565209797,
      "grad_norm": 4.27357816696167,
      "learning_rate": 7.924147787423249e-06,
      "loss": 0.6307,
      "step": 795250
    },
    {
      "epoch": 8.4193498869898,
      "grad_norm": 4.896505832672119,
      "learning_rate": 7.921501164514081e-06,
      "loss": 0.6422,
      "step": 795300
    },
    {
      "epoch": 8.419879208769803,
      "grad_norm": 4.2031049728393555,
      "learning_rate": 7.918854541604914e-06,
      "loss": 0.6387,
      "step": 795350
    },
    {
      "epoch": 8.420408530549807,
      "grad_norm": 4.345524787902832,
      "learning_rate": 7.916207918695744e-06,
      "loss": 0.6387,
      "step": 795400
    },
    {
      "epoch": 8.42093785232981,
      "grad_norm": 4.7178425788879395,
      "learning_rate": 7.913561295786577e-06,
      "loss": 0.6314,
      "step": 795450
    },
    {
      "epoch": 8.421467174109813,
      "grad_norm": 4.3709516525268555,
      "learning_rate": 7.910914672877409e-06,
      "loss": 0.626,
      "step": 795500
    },
    {
      "epoch": 8.421467174109813,
      "eval_loss": 0.38887831568717957,
      "eval_runtime": 46.5001,
      "eval_samples_per_second": 3611.393,
      "eval_steps_per_second": 451.44,
      "step": 795500
    },
    {
      "epoch": 8.421996495889816,
      "grad_norm": 4.069594383239746,
      "learning_rate": 7.908268049968241e-06,
      "loss": 0.6317,
      "step": 795550
    },
    {
      "epoch": 8.42252581766982,
      "grad_norm": 4.377946376800537,
      "learning_rate": 7.905621427059074e-06,
      "loss": 0.6325,
      "step": 795600
    },
    {
      "epoch": 8.423055139449822,
      "grad_norm": 3.9863908290863037,
      "learning_rate": 7.902974804149906e-06,
      "loss": 0.6328,
      "step": 795650
    },
    {
      "epoch": 8.423584461229826,
      "grad_norm": 4.513400554656982,
      "learning_rate": 7.900381113698921e-06,
      "loss": 0.6337,
      "step": 795700
    },
    {
      "epoch": 8.42411378300983,
      "grad_norm": 4.891988277435303,
      "learning_rate": 7.897734490789753e-06,
      "loss": 0.6369,
      "step": 795750
    },
    {
      "epoch": 8.424643104789833,
      "grad_norm": 4.601436138153076,
      "learning_rate": 7.895087867880586e-06,
      "loss": 0.6316,
      "step": 795800
    },
    {
      "epoch": 8.425172426569835,
      "grad_norm": 4.696682929992676,
      "learning_rate": 7.892441244971416e-06,
      "loss": 0.6416,
      "step": 795850
    },
    {
      "epoch": 8.425701748349839,
      "grad_norm": 4.4375152587890625,
      "learning_rate": 7.889794622062249e-06,
      "loss": 0.6351,
      "step": 795900
    },
    {
      "epoch": 8.426231070129843,
      "grad_norm": 4.55588436126709,
      "learning_rate": 7.887147999153081e-06,
      "loss": 0.6262,
      "step": 795950
    },
    {
      "epoch": 8.426760391909847,
      "grad_norm": 4.56545352935791,
      "learning_rate": 7.884501376243914e-06,
      "loss": 0.6304,
      "step": 796000
    },
    {
      "epoch": 8.426760391909847,
      "eval_loss": 0.38875290751457214,
      "eval_runtime": 46.4685,
      "eval_samples_per_second": 3613.842,
      "eval_steps_per_second": 451.746,
      "step": 796000
    },
    {
      "epoch": 8.427289713689849,
      "grad_norm": 4.374256610870361,
      "learning_rate": 7.881854753334746e-06,
      "loss": 0.6396,
      "step": 796050
    },
    {
      "epoch": 8.427819035469852,
      "grad_norm": 4.917799949645996,
      "learning_rate": 7.879208130425579e-06,
      "loss": 0.6445,
      "step": 796100
    },
    {
      "epoch": 8.428348357249856,
      "grad_norm": 4.440606594085693,
      "learning_rate": 7.87656150751641e-06,
      "loss": 0.6342,
      "step": 796150
    },
    {
      "epoch": 8.42887767902986,
      "grad_norm": 4.306778430938721,
      "learning_rate": 7.873914884607242e-06,
      "loss": 0.6278,
      "step": 796200
    },
    {
      "epoch": 8.429407000809862,
      "grad_norm": 4.333707809448242,
      "learning_rate": 7.871268261698074e-06,
      "loss": 0.6333,
      "step": 796250
    },
    {
      "epoch": 8.429936322589866,
      "grad_norm": 4.42509651184082,
      "learning_rate": 7.868621638788906e-06,
      "loss": 0.6347,
      "step": 796300
    },
    {
      "epoch": 8.43046564436987,
      "grad_norm": 4.31984806060791,
      "learning_rate": 7.865975015879739e-06,
      "loss": 0.6391,
      "step": 796350
    },
    {
      "epoch": 8.430994966149871,
      "grad_norm": 4.442580223083496,
      "learning_rate": 7.86332839297057e-06,
      "loss": 0.6408,
      "step": 796400
    },
    {
      "epoch": 8.431524287929875,
      "grad_norm": 4.497386455535889,
      "learning_rate": 7.860681770061402e-06,
      "loss": 0.6475,
      "step": 796450
    },
    {
      "epoch": 8.432053609709879,
      "grad_norm": 4.1641035079956055,
      "learning_rate": 7.858035147152234e-06,
      "loss": 0.6287,
      "step": 796500
    },
    {
      "epoch": 8.432053609709879,
      "eval_loss": 0.3885456919670105,
      "eval_runtime": 46.4962,
      "eval_samples_per_second": 3611.692,
      "eval_steps_per_second": 451.478,
      "step": 796500
    },
    {
      "epoch": 8.432582931489883,
      "grad_norm": 4.938187599182129,
      "learning_rate": 7.855388524243067e-06,
      "loss": 0.6375,
      "step": 796550
    },
    {
      "epoch": 8.433112253269885,
      "grad_norm": 4.5629563331604,
      "learning_rate": 7.8527419013339e-06,
      "loss": 0.6335,
      "step": 796600
    },
    {
      "epoch": 8.433641575049888,
      "grad_norm": 4.405409336090088,
      "learning_rate": 7.850095278424732e-06,
      "loss": 0.6394,
      "step": 796650
    },
    {
      "epoch": 8.434170896829892,
      "grad_norm": 4.945949077606201,
      "learning_rate": 7.847448655515562e-06,
      "loss": 0.6351,
      "step": 796700
    },
    {
      "epoch": 8.434700218609896,
      "grad_norm": 4.907393455505371,
      "learning_rate": 7.844802032606395e-06,
      "loss": 0.6497,
      "step": 796750
    },
    {
      "epoch": 8.435229540389898,
      "grad_norm": 4.581728458404541,
      "learning_rate": 7.842155409697227e-06,
      "loss": 0.6311,
      "step": 796800
    },
    {
      "epoch": 8.435758862169902,
      "grad_norm": 4.08160400390625,
      "learning_rate": 7.83950878678806e-06,
      "loss": 0.6345,
      "step": 796850
    },
    {
      "epoch": 8.436288183949905,
      "grad_norm": 4.89472770690918,
      "learning_rate": 7.836862163878892e-06,
      "loss": 0.6283,
      "step": 796900
    },
    {
      "epoch": 8.436817505729909,
      "grad_norm": 4.131467342376709,
      "learning_rate": 7.834215540969724e-06,
      "loss": 0.6431,
      "step": 796950
    },
    {
      "epoch": 8.437346827509911,
      "grad_norm": 4.859892845153809,
      "learning_rate": 7.831568918060555e-06,
      "loss": 0.6288,
      "step": 797000
    },
    {
      "epoch": 8.437346827509911,
      "eval_loss": 0.3891274333000183,
      "eval_runtime": 46.5517,
      "eval_samples_per_second": 3607.385,
      "eval_steps_per_second": 450.939,
      "step": 797000
    },
    {
      "epoch": 8.437876149289915,
      "grad_norm": 4.406052589416504,
      "learning_rate": 7.828922295151387e-06,
      "loss": 0.6349,
      "step": 797050
    },
    {
      "epoch": 8.438405471069919,
      "grad_norm": 4.412071228027344,
      "learning_rate": 7.82627567224222e-06,
      "loss": 0.6344,
      "step": 797100
    },
    {
      "epoch": 8.43893479284992,
      "grad_norm": 4.593149662017822,
      "learning_rate": 7.823629049333052e-06,
      "loss": 0.6391,
      "step": 797150
    },
    {
      "epoch": 8.439464114629924,
      "grad_norm": 4.5761308670043945,
      "learning_rate": 7.820982426423885e-06,
      "loss": 0.6432,
      "step": 797200
    },
    {
      "epoch": 8.439993436409928,
      "grad_norm": 4.4817094802856445,
      "learning_rate": 7.818335803514715e-06,
      "loss": 0.6417,
      "step": 797250
    },
    {
      "epoch": 8.440522758189932,
      "grad_norm": 4.851279258728027,
      "learning_rate": 7.815689180605548e-06,
      "loss": 0.6412,
      "step": 797300
    },
    {
      "epoch": 8.441052079969934,
      "grad_norm": 4.588666915893555,
      "learning_rate": 7.81304255769638e-06,
      "loss": 0.6444,
      "step": 797350
    },
    {
      "epoch": 8.441581401749938,
      "grad_norm": 4.705085277557373,
      "learning_rate": 7.810395934787213e-06,
      "loss": 0.6424,
      "step": 797400
    },
    {
      "epoch": 8.442110723529941,
      "grad_norm": 4.8819122314453125,
      "learning_rate": 7.807749311878045e-06,
      "loss": 0.6311,
      "step": 797450
    },
    {
      "epoch": 8.442640045309945,
      "grad_norm": 4.382946014404297,
      "learning_rate": 7.805102688968877e-06,
      "loss": 0.6382,
      "step": 797500
    },
    {
      "epoch": 8.442640045309945,
      "eval_loss": 0.38860419392585754,
      "eval_runtime": 46.4751,
      "eval_samples_per_second": 3613.33,
      "eval_steps_per_second": 451.682,
      "step": 797500
    },
    {
      "epoch": 8.443169367089947,
      "grad_norm": 4.259240627288818,
      "learning_rate": 7.802456066059708e-06,
      "loss": 0.6376,
      "step": 797550
    },
    {
      "epoch": 8.44369868886995,
      "grad_norm": 4.709397315979004,
      "learning_rate": 7.79980944315054e-06,
      "loss": 0.632,
      "step": 797600
    },
    {
      "epoch": 8.444228010649955,
      "grad_norm": 4.699024200439453,
      "learning_rate": 7.797162820241373e-06,
      "loss": 0.637,
      "step": 797650
    },
    {
      "epoch": 8.444757332429958,
      "grad_norm": 4.789346218109131,
      "learning_rate": 7.794516197332205e-06,
      "loss": 0.6265,
      "step": 797700
    },
    {
      "epoch": 8.44528665420996,
      "grad_norm": 5.041703701019287,
      "learning_rate": 7.791869574423038e-06,
      "loss": 0.6409,
      "step": 797750
    },
    {
      "epoch": 8.445815975989964,
      "grad_norm": 4.223601818084717,
      "learning_rate": 7.789222951513868e-06,
      "loss": 0.6285,
      "step": 797800
    },
    {
      "epoch": 8.446345297769968,
      "grad_norm": 4.409428119659424,
      "learning_rate": 7.786576328604701e-06,
      "loss": 0.6302,
      "step": 797850
    },
    {
      "epoch": 8.44687461954997,
      "grad_norm": 4.262751579284668,
      "learning_rate": 7.783929705695533e-06,
      "loss": 0.6476,
      "step": 797900
    },
    {
      "epoch": 8.447403941329974,
      "grad_norm": 4.717997074127197,
      "learning_rate": 7.781283082786366e-06,
      "loss": 0.6319,
      "step": 797950
    },
    {
      "epoch": 8.447933263109977,
      "grad_norm": 4.850857257843018,
      "learning_rate": 7.778636459877198e-06,
      "loss": 0.6402,
      "step": 798000
    },
    {
      "epoch": 8.447933263109977,
      "eval_loss": 0.3887709975242615,
      "eval_runtime": 46.3976,
      "eval_samples_per_second": 3619.366,
      "eval_steps_per_second": 452.437,
      "step": 798000
    },
    {
      "epoch": 8.448462584889981,
      "grad_norm": 4.57997989654541,
      "learning_rate": 7.77598983696803e-06,
      "loss": 0.6353,
      "step": 798050
    },
    {
      "epoch": 8.448991906669983,
      "grad_norm": 4.626562595367432,
      "learning_rate": 7.773343214058861e-06,
      "loss": 0.6402,
      "step": 798100
    },
    {
      "epoch": 8.449521228449987,
      "grad_norm": 4.5131659507751465,
      "learning_rate": 7.770696591149694e-06,
      "loss": 0.6259,
      "step": 798150
    },
    {
      "epoch": 8.45005055022999,
      "grad_norm": 4.568055629730225,
      "learning_rate": 7.768049968240526e-06,
      "loss": 0.6318,
      "step": 798200
    },
    {
      "epoch": 8.450579872009994,
      "grad_norm": 4.886924743652344,
      "learning_rate": 7.765403345331358e-06,
      "loss": 0.6493,
      "step": 798250
    },
    {
      "epoch": 8.451109193789996,
      "grad_norm": 4.721669673919678,
      "learning_rate": 7.76275672242219e-06,
      "loss": 0.6487,
      "step": 798300
    },
    {
      "epoch": 8.45163851557,
      "grad_norm": 4.4813995361328125,
      "learning_rate": 7.760110099513023e-06,
      "loss": 0.6252,
      "step": 798350
    },
    {
      "epoch": 8.452167837350004,
      "grad_norm": 4.420292377471924,
      "learning_rate": 7.757463476603854e-06,
      "loss": 0.6232,
      "step": 798400
    },
    {
      "epoch": 8.452697159130008,
      "grad_norm": 3.9609200954437256,
      "learning_rate": 7.754816853694686e-06,
      "loss": 0.6395,
      "step": 798450
    },
    {
      "epoch": 8.45322648091001,
      "grad_norm": 4.344001293182373,
      "learning_rate": 7.752170230785519e-06,
      "loss": 0.6389,
      "step": 798500
    },
    {
      "epoch": 8.45322648091001,
      "eval_loss": 0.38909268379211426,
      "eval_runtime": 46.5478,
      "eval_samples_per_second": 3607.688,
      "eval_steps_per_second": 450.977,
      "step": 798500
    },
    {
      "epoch": 8.453755802690013,
      "grad_norm": 4.511641025543213,
      "learning_rate": 7.74952360787635e-06,
      "loss": 0.6328,
      "step": 798550
    },
    {
      "epoch": 8.454285124470017,
      "grad_norm": 4.338119029998779,
      "learning_rate": 7.746876984967182e-06,
      "loss": 0.6497,
      "step": 798600
    },
    {
      "epoch": 8.454814446250019,
      "grad_norm": 4.717932224273682,
      "learning_rate": 7.744230362058014e-06,
      "loss": 0.6357,
      "step": 798650
    },
    {
      "epoch": 8.455343768030023,
      "grad_norm": 4.433177947998047,
      "learning_rate": 7.741583739148845e-06,
      "loss": 0.6331,
      "step": 798700
    },
    {
      "epoch": 8.455873089810026,
      "grad_norm": 4.474415302276611,
      "learning_rate": 7.738937116239677e-06,
      "loss": 0.6362,
      "step": 798750
    },
    {
      "epoch": 8.45640241159003,
      "grad_norm": 4.840249538421631,
      "learning_rate": 7.73629049333051e-06,
      "loss": 0.6365,
      "step": 798800
    },
    {
      "epoch": 8.456931733370032,
      "grad_norm": 4.366629600524902,
      "learning_rate": 7.733643870421342e-06,
      "loss": 0.6501,
      "step": 798850
    },
    {
      "epoch": 8.457461055150036,
      "grad_norm": 4.589475631713867,
      "learning_rate": 7.730997247512175e-06,
      "loss": 0.636,
      "step": 798900
    },
    {
      "epoch": 8.45799037693004,
      "grad_norm": 4.187017440795898,
      "learning_rate": 7.728350624603007e-06,
      "loss": 0.6305,
      "step": 798950
    },
    {
      "epoch": 8.458519698710043,
      "grad_norm": 4.955350875854492,
      "learning_rate": 7.725704001693838e-06,
      "loss": 0.6255,
      "step": 799000
    },
    {
      "epoch": 8.458519698710043,
      "eval_loss": 0.3878055214881897,
      "eval_runtime": 46.4604,
      "eval_samples_per_second": 3614.479,
      "eval_steps_per_second": 451.826,
      "step": 799000
    },
    {
      "epoch": 8.459049020490045,
      "grad_norm": 4.915765285491943,
      "learning_rate": 7.72305737878467e-06,
      "loss": 0.6395,
      "step": 799050
    },
    {
      "epoch": 8.45957834227005,
      "grad_norm": 4.676578044891357,
      "learning_rate": 7.720410755875503e-06,
      "loss": 0.6354,
      "step": 799100
    },
    {
      "epoch": 8.460107664050053,
      "grad_norm": 4.437924861907959,
      "learning_rate": 7.717764132966335e-06,
      "loss": 0.6323,
      "step": 799150
    },
    {
      "epoch": 8.460636985830057,
      "grad_norm": 4.822674751281738,
      "learning_rate": 7.715117510057167e-06,
      "loss": 0.6362,
      "step": 799200
    },
    {
      "epoch": 8.461166307610059,
      "grad_norm": 4.60523796081543,
      "learning_rate": 7.712470887148e-06,
      "loss": 0.6364,
      "step": 799250
    },
    {
      "epoch": 8.461695629390062,
      "grad_norm": 4.783113956451416,
      "learning_rate": 7.70982426423883e-06,
      "loss": 0.6237,
      "step": 799300
    },
    {
      "epoch": 8.462224951170066,
      "grad_norm": 4.315805912017822,
      "learning_rate": 7.707177641329663e-06,
      "loss": 0.6376,
      "step": 799350
    },
    {
      "epoch": 8.462754272950068,
      "grad_norm": 4.790876865386963,
      "learning_rate": 7.704531018420495e-06,
      "loss": 0.6359,
      "step": 799400
    },
    {
      "epoch": 8.463283594730072,
      "grad_norm": 4.837589740753174,
      "learning_rate": 7.701884395511328e-06,
      "loss": 0.6374,
      "step": 799450
    },
    {
      "epoch": 8.463812916510076,
      "grad_norm": 4.656554698944092,
      "learning_rate": 7.69923777260216e-06,
      "loss": 0.6323,
      "step": 799500
    },
    {
      "epoch": 8.463812916510076,
      "eval_loss": 0.38853177428245544,
      "eval_runtime": 46.5042,
      "eval_samples_per_second": 3611.075,
      "eval_steps_per_second": 451.401,
      "step": 799500
    },
    {
      "epoch": 8.46434223829008,
      "grad_norm": 4.6516523361206055,
      "learning_rate": 7.69659114969299e-06,
      "loss": 0.6388,
      "step": 799550
    },
    {
      "epoch": 8.464871560070081,
      "grad_norm": 4.395374298095703,
      "learning_rate": 7.693944526783823e-06,
      "loss": 0.6317,
      "step": 799600
    },
    {
      "epoch": 8.465400881850085,
      "grad_norm": 4.761799335479736,
      "learning_rate": 7.691297903874656e-06,
      "loss": 0.6337,
      "step": 799650
    },
    {
      "epoch": 8.465930203630089,
      "grad_norm": 4.815766334533691,
      "learning_rate": 7.68870421342367e-06,
      "loss": 0.6267,
      "step": 799700
    },
    {
      "epoch": 8.466459525410093,
      "grad_norm": 5.13297176361084,
      "learning_rate": 7.686057590514503e-06,
      "loss": 0.6414,
      "step": 799750
    },
    {
      "epoch": 8.466988847190095,
      "grad_norm": 4.931728839874268,
      "learning_rate": 7.683410967605335e-06,
      "loss": 0.6386,
      "step": 799800
    },
    {
      "epoch": 8.467518168970098,
      "grad_norm": 4.720481872558594,
      "learning_rate": 7.680764344696168e-06,
      "loss": 0.6418,
      "step": 799850
    },
    {
      "epoch": 8.468047490750102,
      "grad_norm": 4.852069854736328,
      "learning_rate": 7.678117721787e-06,
      "loss": 0.6327,
      "step": 799900
    },
    {
      "epoch": 8.468576812530106,
      "grad_norm": 4.604246139526367,
      "learning_rate": 7.675471098877832e-06,
      "loss": 0.637,
      "step": 799950
    },
    {
      "epoch": 8.469106134310108,
      "grad_norm": 4.795719146728516,
      "learning_rate": 7.672824475968663e-06,
      "loss": 0.6359,
      "step": 800000
    },
    {
      "epoch": 8.469106134310108,
      "eval_loss": 0.3885735273361206,
      "eval_runtime": 46.447,
      "eval_samples_per_second": 3615.518,
      "eval_steps_per_second": 451.956,
      "step": 800000
    },
    {
      "epoch": 8.469635456090112,
      "grad_norm": 4.5581955909729,
      "learning_rate": 7.670177853059495e-06,
      "loss": 0.6345,
      "step": 800050
    },
    {
      "epoch": 8.470164777870115,
      "grad_norm": 4.7150139808654785,
      "learning_rate": 7.667531230150328e-06,
      "loss": 0.6274,
      "step": 800100
    },
    {
      "epoch": 8.470694099650117,
      "grad_norm": 4.726944923400879,
      "learning_rate": 7.66488460724116e-06,
      "loss": 0.6419,
      "step": 800150
    },
    {
      "epoch": 8.471223421430121,
      "grad_norm": 4.49519157409668,
      "learning_rate": 7.662237984331993e-06,
      "loss": 0.635,
      "step": 800200
    },
    {
      "epoch": 8.471752743210125,
      "grad_norm": 4.795891761779785,
      "learning_rate": 7.659591361422825e-06,
      "loss": 0.6335,
      "step": 800250
    },
    {
      "epoch": 8.472282064990129,
      "grad_norm": 4.714668273925781,
      "learning_rate": 7.656944738513656e-06,
      "loss": 0.6285,
      "step": 800300
    },
    {
      "epoch": 8.47281138677013,
      "grad_norm": 4.68594217300415,
      "learning_rate": 7.654298115604488e-06,
      "loss": 0.6284,
      "step": 800350
    },
    {
      "epoch": 8.473340708550134,
      "grad_norm": 4.671046733856201,
      "learning_rate": 7.65165149269532e-06,
      "loss": 0.6363,
      "step": 800400
    },
    {
      "epoch": 8.473870030330138,
      "grad_norm": 4.489755630493164,
      "learning_rate": 7.649004869786153e-06,
      "loss": 0.6346,
      "step": 800450
    },
    {
      "epoch": 8.474399352110142,
      "grad_norm": 4.637678623199463,
      "learning_rate": 7.646358246876985e-06,
      "loss": 0.6304,
      "step": 800500
    },
    {
      "epoch": 8.474399352110142,
      "eval_loss": 0.3882675766944885,
      "eval_runtime": 46.5116,
      "eval_samples_per_second": 3610.499,
      "eval_steps_per_second": 451.329,
      "step": 800500
    },
    {
      "epoch": 8.474928673890144,
      "grad_norm": 4.343573570251465,
      "learning_rate": 7.643711623967816e-06,
      "loss": 0.6257,
      "step": 800550
    },
    {
      "epoch": 8.475457995670148,
      "grad_norm": 4.4524617195129395,
      "learning_rate": 7.641065001058649e-06,
      "loss": 0.6344,
      "step": 800600
    },
    {
      "epoch": 8.475987317450151,
      "grad_norm": 4.493553161621094,
      "learning_rate": 7.638418378149481e-06,
      "loss": 0.6295,
      "step": 800650
    },
    {
      "epoch": 8.476516639230155,
      "grad_norm": 4.105885982513428,
      "learning_rate": 7.635771755240313e-06,
      "loss": 0.6357,
      "step": 800700
    },
    {
      "epoch": 8.477045961010157,
      "grad_norm": 4.907051086425781,
      "learning_rate": 7.633125132331146e-06,
      "loss": 0.636,
      "step": 800750
    },
    {
      "epoch": 8.477575282790161,
      "grad_norm": 4.8666462898254395,
      "learning_rate": 7.630478509421978e-06,
      "loss": 0.6387,
      "step": 800800
    },
    {
      "epoch": 8.478104604570165,
      "grad_norm": 4.527429103851318,
      "learning_rate": 7.62783188651281e-06,
      "loss": 0.6316,
      "step": 800850
    },
    {
      "epoch": 8.478633926350167,
      "grad_norm": 4.486780166625977,
      "learning_rate": 7.625185263603641e-06,
      "loss": 0.6387,
      "step": 800900
    },
    {
      "epoch": 8.47916324813017,
      "grad_norm": 4.367599010467529,
      "learning_rate": 7.622538640694474e-06,
      "loss": 0.6349,
      "step": 800950
    },
    {
      "epoch": 8.479692569910174,
      "grad_norm": 4.837785243988037,
      "learning_rate": 7.619892017785306e-06,
      "loss": 0.6456,
      "step": 801000
    },
    {
      "epoch": 8.479692569910174,
      "eval_loss": 0.38852789998054504,
      "eval_runtime": 46.4406,
      "eval_samples_per_second": 3616.016,
      "eval_steps_per_second": 452.018,
      "step": 801000
    },
    {
      "epoch": 8.480221891690178,
      "grad_norm": 4.439248561859131,
      "learning_rate": 7.617245394876138e-06,
      "loss": 0.6408,
      "step": 801050
    },
    {
      "epoch": 8.48075121347018,
      "grad_norm": 4.518360614776611,
      "learning_rate": 7.61459877196697e-06,
      "loss": 0.6392,
      "step": 801100
    },
    {
      "epoch": 8.481280535250184,
      "grad_norm": 4.726573944091797,
      "learning_rate": 7.6119521490578025e-06,
      "loss": 0.6362,
      "step": 801150
    },
    {
      "epoch": 8.481809857030187,
      "grad_norm": 5.227261543273926,
      "learning_rate": 7.609305526148634e-06,
      "loss": 0.6354,
      "step": 801200
    },
    {
      "epoch": 8.482339178810191,
      "grad_norm": 4.6961870193481445,
      "learning_rate": 7.6066589032394664e-06,
      "loss": 0.6208,
      "step": 801250
    },
    {
      "epoch": 8.482868500590193,
      "grad_norm": 4.32057523727417,
      "learning_rate": 7.604012280330299e-06,
      "loss": 0.6265,
      "step": 801300
    },
    {
      "epoch": 8.483397822370197,
      "grad_norm": 4.650101661682129,
      "learning_rate": 7.60136565742113e-06,
      "loss": 0.6422,
      "step": 801350
    },
    {
      "epoch": 8.4839271441502,
      "grad_norm": 4.841621398925781,
      "learning_rate": 7.598719034511963e-06,
      "loss": 0.6382,
      "step": 801400
    },
    {
      "epoch": 8.484456465930204,
      "grad_norm": 4.424324035644531,
      "learning_rate": 7.596072411602795e-06,
      "loss": 0.6307,
      "step": 801450
    },
    {
      "epoch": 8.484985787710206,
      "grad_norm": 4.565516471862793,
      "learning_rate": 7.593425788693627e-06,
      "loss": 0.6425,
      "step": 801500
    },
    {
      "epoch": 8.484985787710206,
      "eval_loss": 0.3882596492767334,
      "eval_runtime": 46.4961,
      "eval_samples_per_second": 3611.697,
      "eval_steps_per_second": 451.478,
      "step": 801500
    },
    {
      "epoch": 8.48551510949021,
      "grad_norm": 4.7879180908203125,
      "learning_rate": 7.590779165784459e-06,
      "loss": 0.6293,
      "step": 801550
    },
    {
      "epoch": 8.486044431270214,
      "grad_norm": 4.615793704986572,
      "learning_rate": 7.588132542875291e-06,
      "loss": 0.6305,
      "step": 801600
    },
    {
      "epoch": 8.486573753050216,
      "grad_norm": 4.554262638092041,
      "learning_rate": 7.585485919966123e-06,
      "loss": 0.6415,
      "step": 801650
    },
    {
      "epoch": 8.48710307483022,
      "grad_norm": 4.564190864562988,
      "learning_rate": 7.582892229515139e-06,
      "loss": 0.6313,
      "step": 801700
    },
    {
      "epoch": 8.487632396610223,
      "grad_norm": 4.85061502456665,
      "learning_rate": 7.580245606605971e-06,
      "loss": 0.6412,
      "step": 801750
    },
    {
      "epoch": 8.488161718390227,
      "grad_norm": 4.434689521789551,
      "learning_rate": 7.577598983696803e-06,
      "loss": 0.6375,
      "step": 801800
    },
    {
      "epoch": 8.48869104017023,
      "grad_norm": 4.520951747894287,
      "learning_rate": 7.574952360787635e-06,
      "loss": 0.636,
      "step": 801850
    },
    {
      "epoch": 8.489220361950233,
      "grad_norm": 4.772994041442871,
      "learning_rate": 7.572305737878467e-06,
      "loss": 0.6335,
      "step": 801900
    },
    {
      "epoch": 8.489749683730237,
      "grad_norm": 4.577232837677002,
      "learning_rate": 7.569659114969299e-06,
      "loss": 0.6384,
      "step": 801950
    },
    {
      "epoch": 8.49027900551024,
      "grad_norm": 4.907343864440918,
      "learning_rate": 7.5670124920601314e-06,
      "loss": 0.6382,
      "step": 802000
    },
    {
      "epoch": 8.49027900551024,
      "eval_loss": 0.3872636556625366,
      "eval_runtime": 46.4037,
      "eval_samples_per_second": 3618.893,
      "eval_steps_per_second": 452.378,
      "step": 802000
    },
    {
      "epoch": 8.490808327290242,
      "grad_norm": 4.498936176300049,
      "learning_rate": 7.564365869150963e-06,
      "loss": 0.6374,
      "step": 802050
    },
    {
      "epoch": 8.491337649070246,
      "grad_norm": 4.9895453453063965,
      "learning_rate": 7.561719246241795e-06,
      "loss": 0.6331,
      "step": 802100
    },
    {
      "epoch": 8.49186697085025,
      "grad_norm": 4.164189338684082,
      "learning_rate": 7.559072623332628e-06,
      "loss": 0.6313,
      "step": 802150
    },
    {
      "epoch": 8.492396292630254,
      "grad_norm": 4.83225679397583,
      "learning_rate": 7.556426000423459e-06,
      "loss": 0.6445,
      "step": 802200
    },
    {
      "epoch": 8.492925614410256,
      "grad_norm": 4.955048084259033,
      "learning_rate": 7.553779377514292e-06,
      "loss": 0.6358,
      "step": 802250
    },
    {
      "epoch": 8.49345493619026,
      "grad_norm": 4.401681900024414,
      "learning_rate": 7.551132754605124e-06,
      "loss": 0.6283,
      "step": 802300
    },
    {
      "epoch": 8.493984257970263,
      "grad_norm": 5.115010738372803,
      "learning_rate": 7.548486131695956e-06,
      "loss": 0.6335,
      "step": 802350
    },
    {
      "epoch": 8.494513579750265,
      "grad_norm": 4.484121799468994,
      "learning_rate": 7.545839508786788e-06,
      "loss": 0.6263,
      "step": 802400
    },
    {
      "epoch": 8.495042901530269,
      "grad_norm": 4.619335174560547,
      "learning_rate": 7.5431928858776205e-06,
      "loss": 0.6263,
      "step": 802450
    },
    {
      "epoch": 8.495572223310273,
      "grad_norm": 4.843294143676758,
      "learning_rate": 7.540546262968452e-06,
      "loss": 0.6404,
      "step": 802500
    },
    {
      "epoch": 8.495572223310273,
      "eval_loss": 0.3876727223396301,
      "eval_runtime": 46.7733,
      "eval_samples_per_second": 3590.299,
      "eval_steps_per_second": 448.803,
      "step": 802500
    },
    {
      "epoch": 8.496101545090276,
      "grad_norm": 3.7952637672424316,
      "learning_rate": 7.5378996400592845e-06,
      "loss": 0.6356,
      "step": 802550
    },
    {
      "epoch": 8.496630866870278,
      "grad_norm": 4.557049751281738,
      "learning_rate": 7.535253017150117e-06,
      "loss": 0.6273,
      "step": 802600
    },
    {
      "epoch": 8.497160188650282,
      "grad_norm": 4.47894287109375,
      "learning_rate": 7.5326063942409485e-06,
      "loss": 0.6315,
      "step": 802650
    },
    {
      "epoch": 8.497689510430286,
      "grad_norm": 4.127631187438965,
      "learning_rate": 7.529959771331781e-06,
      "loss": 0.6342,
      "step": 802700
    },
    {
      "epoch": 8.49821883221029,
      "grad_norm": 5.0343828201293945,
      "learning_rate": 7.5273131484226124e-06,
      "loss": 0.6302,
      "step": 802750
    },
    {
      "epoch": 8.498748153990292,
      "grad_norm": 4.281808853149414,
      "learning_rate": 7.524666525513445e-06,
      "loss": 0.6414,
      "step": 802800
    },
    {
      "epoch": 8.499277475770295,
      "grad_norm": 4.9344892501831055,
      "learning_rate": 7.522019902604277e-06,
      "loss": 0.6186,
      "step": 802850
    },
    {
      "epoch": 8.499806797550299,
      "grad_norm": 4.500853538513184,
      "learning_rate": 7.519373279695109e-06,
      "loss": 0.6316,
      "step": 802900
    },
    {
      "epoch": 8.500336119330303,
      "grad_norm": 4.523655891418457,
      "learning_rate": 7.516726656785941e-06,
      "loss": 0.6378,
      "step": 802950
    },
    {
      "epoch": 8.500865441110305,
      "grad_norm": 4.402490139007568,
      "learning_rate": 7.514080033876774e-06,
      "loss": 0.6402,
      "step": 803000
    },
    {
      "epoch": 8.500865441110305,
      "eval_loss": 0.3877769410610199,
      "eval_runtime": 46.4932,
      "eval_samples_per_second": 3611.929,
      "eval_steps_per_second": 451.507,
      "step": 803000
    },
    {
      "epoch": 8.501394762890309,
      "grad_norm": 4.669288158416748,
      "learning_rate": 7.511433410967605e-06,
      "loss": 0.6228,
      "step": 803050
    },
    {
      "epoch": 8.501924084670312,
      "grad_norm": 5.005983352661133,
      "learning_rate": 7.508786788058438e-06,
      "loss": 0.6352,
      "step": 803100
    },
    {
      "epoch": 8.502453406450314,
      "grad_norm": 4.506053924560547,
      "learning_rate": 7.50614016514927e-06,
      "loss": 0.6455,
      "step": 803150
    },
    {
      "epoch": 8.502982728230318,
      "grad_norm": 4.411629676818848,
      "learning_rate": 7.5034935422401015e-06,
      "loss": 0.6346,
      "step": 803200
    },
    {
      "epoch": 8.503512050010322,
      "grad_norm": 4.898910999298096,
      "learning_rate": 7.500846919330934e-06,
      "loss": 0.6369,
      "step": 803250
    },
    {
      "epoch": 8.504041371790326,
      "grad_norm": 4.407536029815674,
      "learning_rate": 7.498200296421766e-06,
      "loss": 0.6236,
      "step": 803300
    },
    {
      "epoch": 8.504570693570328,
      "grad_norm": 4.4512200355529785,
      "learning_rate": 7.495553673512598e-06,
      "loss": 0.635,
      "step": 803350
    },
    {
      "epoch": 8.505100015350331,
      "grad_norm": 4.764097690582275,
      "learning_rate": 7.49290705060343e-06,
      "loss": 0.636,
      "step": 803400
    },
    {
      "epoch": 8.505629337130335,
      "grad_norm": 4.449514389038086,
      "learning_rate": 7.490260427694262e-06,
      "loss": 0.6215,
      "step": 803450
    },
    {
      "epoch": 8.506158658910339,
      "grad_norm": 4.157753944396973,
      "learning_rate": 7.487613804785094e-06,
      "loss": 0.6232,
      "step": 803500
    },
    {
      "epoch": 8.506158658910339,
      "eval_loss": 0.3869837522506714,
      "eval_runtime": 46.5083,
      "eval_samples_per_second": 3610.75,
      "eval_steps_per_second": 451.36,
      "step": 803500
    },
    {
      "epoch": 8.50668798069034,
      "grad_norm": 4.5794806480407715,
      "learning_rate": 7.484967181875927e-06,
      "loss": 0.6304,
      "step": 803550
    },
    {
      "epoch": 8.507217302470345,
      "grad_norm": 4.769874572753906,
      "learning_rate": 7.482320558966758e-06,
      "loss": 0.6359,
      "step": 803600
    },
    {
      "epoch": 8.507746624250348,
      "grad_norm": 4.606579780578613,
      "learning_rate": 7.479673936057591e-06,
      "loss": 0.6415,
      "step": 803650
    },
    {
      "epoch": 8.508275946030352,
      "grad_norm": 4.211284637451172,
      "learning_rate": 7.477080245606606e-06,
      "loss": 0.6444,
      "step": 803700
    },
    {
      "epoch": 8.508805267810354,
      "grad_norm": 4.504615306854248,
      "learning_rate": 7.474433622697438e-06,
      "loss": 0.6388,
      "step": 803750
    },
    {
      "epoch": 8.509334589590358,
      "grad_norm": 4.115386962890625,
      "learning_rate": 7.47178699978827e-06,
      "loss": 0.6217,
      "step": 803800
    },
    {
      "epoch": 8.509863911370362,
      "grad_norm": 4.418430805206299,
      "learning_rate": 7.469140376879103e-06,
      "loss": 0.6384,
      "step": 803850
    },
    {
      "epoch": 8.510393233150364,
      "grad_norm": 4.7655029296875,
      "learning_rate": 7.466493753969934e-06,
      "loss": 0.6331,
      "step": 803900
    },
    {
      "epoch": 8.510922554930367,
      "grad_norm": 4.715352535247803,
      "learning_rate": 7.4638471310607666e-06,
      "loss": 0.6226,
      "step": 803950
    },
    {
      "epoch": 8.511451876710371,
      "grad_norm": 4.697636127471924,
      "learning_rate": 7.461200508151599e-06,
      "loss": 0.6433,
      "step": 804000
    },
    {
      "epoch": 8.511451876710371,
      "eval_loss": 0.38800689578056335,
      "eval_runtime": 46.4516,
      "eval_samples_per_second": 3615.159,
      "eval_steps_per_second": 451.911,
      "step": 804000
    },
    {
      "epoch": 8.511981198490375,
      "grad_norm": 5.2639689445495605,
      "learning_rate": 7.4585538852424305e-06,
      "loss": 0.6395,
      "step": 804050
    },
    {
      "epoch": 8.512510520270377,
      "grad_norm": 4.299478054046631,
      "learning_rate": 7.455907262333263e-06,
      "loss": 0.6429,
      "step": 804100
    },
    {
      "epoch": 8.51303984205038,
      "grad_norm": 4.492944717407227,
      "learning_rate": 7.453260639424095e-06,
      "loss": 0.6406,
      "step": 804150
    },
    {
      "epoch": 8.513569163830384,
      "grad_norm": 4.803898811340332,
      "learning_rate": 7.450614016514927e-06,
      "loss": 0.6316,
      "step": 804200
    },
    {
      "epoch": 8.514098485610388,
      "grad_norm": 4.23980188369751,
      "learning_rate": 7.447967393605759e-06,
      "loss": 0.6266,
      "step": 804250
    },
    {
      "epoch": 8.51462780739039,
      "grad_norm": 4.681986331939697,
      "learning_rate": 7.445320770696592e-06,
      "loss": 0.628,
      "step": 804300
    },
    {
      "epoch": 8.515157129170394,
      "grad_norm": 4.461493492126465,
      "learning_rate": 7.442674147787423e-06,
      "loss": 0.6298,
      "step": 804350
    },
    {
      "epoch": 8.515686450950398,
      "grad_norm": 4.812449932098389,
      "learning_rate": 7.440027524878256e-06,
      "loss": 0.6305,
      "step": 804400
    },
    {
      "epoch": 8.516215772730401,
      "grad_norm": 5.123217582702637,
      "learning_rate": 7.437380901969088e-06,
      "loss": 0.6246,
      "step": 804450
    },
    {
      "epoch": 8.516745094510403,
      "grad_norm": 4.743155002593994,
      "learning_rate": 7.43473427905992e-06,
      "loss": 0.6288,
      "step": 804500
    },
    {
      "epoch": 8.516745094510403,
      "eval_loss": 0.3870924711227417,
      "eval_runtime": 46.5732,
      "eval_samples_per_second": 3605.722,
      "eval_steps_per_second": 450.731,
      "step": 804500
    },
    {
      "epoch": 8.517274416290407,
      "grad_norm": 4.559591770172119,
      "learning_rate": 7.432087656150752e-06,
      "loss": 0.6416,
      "step": 804550
    },
    {
      "epoch": 8.51780373807041,
      "grad_norm": 5.091190338134766,
      "learning_rate": 7.429441033241584e-06,
      "loss": 0.6355,
      "step": 804600
    },
    {
      "epoch": 8.518333059850413,
      "grad_norm": 4.51497220993042,
      "learning_rate": 7.426794410332416e-06,
      "loss": 0.632,
      "step": 804650
    },
    {
      "epoch": 8.518862381630417,
      "grad_norm": 4.849581718444824,
      "learning_rate": 7.424147787423248e-06,
      "loss": 0.6197,
      "step": 804700
    },
    {
      "epoch": 8.51939170341042,
      "grad_norm": 4.55161190032959,
      "learning_rate": 7.42150116451408e-06,
      "loss": 0.6353,
      "step": 804750
    },
    {
      "epoch": 8.519921025190424,
      "grad_norm": 4.9807281494140625,
      "learning_rate": 7.418854541604912e-06,
      "loss": 0.6439,
      "step": 804800
    },
    {
      "epoch": 8.520450346970426,
      "grad_norm": 4.922477722167969,
      "learning_rate": 7.416207918695745e-06,
      "loss": 0.6376,
      "step": 804850
    },
    {
      "epoch": 8.52097966875043,
      "grad_norm": 4.521143913269043,
      "learning_rate": 7.413561295786576e-06,
      "loss": 0.6375,
      "step": 804900
    },
    {
      "epoch": 8.521508990530434,
      "grad_norm": 4.665709495544434,
      "learning_rate": 7.410914672877409e-06,
      "loss": 0.6322,
      "step": 804950
    },
    {
      "epoch": 8.522038312310437,
      "grad_norm": 4.650302410125732,
      "learning_rate": 7.408268049968241e-06,
      "loss": 0.6275,
      "step": 805000
    },
    {
      "epoch": 8.522038312310437,
      "eval_loss": 0.3875323534011841,
      "eval_runtime": 46.605,
      "eval_samples_per_second": 3603.261,
      "eval_steps_per_second": 450.424,
      "step": 805000
    },
    {
      "epoch": 8.52256763409044,
      "grad_norm": 4.416711807250977,
      "learning_rate": 7.405621427059073e-06,
      "loss": 0.6395,
      "step": 805050
    },
    {
      "epoch": 8.523096955870443,
      "grad_norm": 4.923336505889893,
      "learning_rate": 7.402974804149905e-06,
      "loss": 0.6349,
      "step": 805100
    },
    {
      "epoch": 8.523626277650447,
      "grad_norm": 5.024984836578369,
      "learning_rate": 7.4003281812407375e-06,
      "loss": 0.632,
      "step": 805150
    },
    {
      "epoch": 8.52415559943045,
      "grad_norm": 4.6827073097229,
      "learning_rate": 7.397681558331569e-06,
      "loss": 0.6538,
      "step": 805200
    },
    {
      "epoch": 8.524684921210453,
      "grad_norm": 4.54596471786499,
      "learning_rate": 7.3950349354224015e-06,
      "loss": 0.6334,
      "step": 805250
    },
    {
      "epoch": 8.525214242990456,
      "grad_norm": 3.955636501312256,
      "learning_rate": 7.392388312513233e-06,
      "loss": 0.632,
      "step": 805300
    },
    {
      "epoch": 8.52574356477046,
      "grad_norm": 4.919871807098389,
      "learning_rate": 7.3897416896040654e-06,
      "loss": 0.6406,
      "step": 805350
    },
    {
      "epoch": 8.526272886550462,
      "grad_norm": 4.776069164276123,
      "learning_rate": 7.387095066694898e-06,
      "loss": 0.625,
      "step": 805400
    },
    {
      "epoch": 8.526802208330466,
      "grad_norm": 4.849540710449219,
      "learning_rate": 7.384448443785729e-06,
      "loss": 0.636,
      "step": 805450
    },
    {
      "epoch": 8.52733153011047,
      "grad_norm": 4.6533522605896,
      "learning_rate": 7.381801820876562e-06,
      "loss": 0.6358,
      "step": 805500
    },
    {
      "epoch": 8.52733153011047,
      "eval_loss": 0.38786250352859497,
      "eval_runtime": 46.4349,
      "eval_samples_per_second": 3616.458,
      "eval_steps_per_second": 452.073,
      "step": 805500
    },
    {
      "epoch": 8.527860851890473,
      "grad_norm": 4.854852199554443,
      "learning_rate": 7.379155197967394e-06,
      "loss": 0.631,
      "step": 805550
    },
    {
      "epoch": 8.528390173670475,
      "grad_norm": 4.312736988067627,
      "learning_rate": 7.376508575058226e-06,
      "loss": 0.6359,
      "step": 805600
    },
    {
      "epoch": 8.528919495450479,
      "grad_norm": 4.569718837738037,
      "learning_rate": 7.373861952149058e-06,
      "loss": 0.6425,
      "step": 805650
    },
    {
      "epoch": 8.529448817230483,
      "grad_norm": 5.169936180114746,
      "learning_rate": 7.371268261698074e-06,
      "loss": 0.6393,
      "step": 805700
    },
    {
      "epoch": 8.529978139010487,
      "grad_norm": 5.122638702392578,
      "learning_rate": 7.368621638788905e-06,
      "loss": 0.6389,
      "step": 805750
    },
    {
      "epoch": 8.530507460790488,
      "grad_norm": 4.318301677703857,
      "learning_rate": 7.365975015879738e-06,
      "loss": 0.6301,
      "step": 805800
    },
    {
      "epoch": 8.531036782570492,
      "grad_norm": 4.619073390960693,
      "learning_rate": 7.36332839297057e-06,
      "loss": 0.6336,
      "step": 805850
    },
    {
      "epoch": 8.531566104350496,
      "grad_norm": 4.558620452880859,
      "learning_rate": 7.360681770061402e-06,
      "loss": 0.6337,
      "step": 805900
    },
    {
      "epoch": 8.5320954261305,
      "grad_norm": 4.745121479034424,
      "learning_rate": 7.358035147152234e-06,
      "loss": 0.6267,
      "step": 805950
    },
    {
      "epoch": 8.532624747910502,
      "grad_norm": 4.521010398864746,
      "learning_rate": 7.3553885242430665e-06,
      "loss": 0.6362,
      "step": 806000
    },
    {
      "epoch": 8.532624747910502,
      "eval_loss": 0.38839060068130493,
      "eval_runtime": 46.5196,
      "eval_samples_per_second": 3609.878,
      "eval_steps_per_second": 451.251,
      "step": 806000
    },
    {
      "epoch": 8.533154069690505,
      "grad_norm": 4.455674648284912,
      "learning_rate": 7.352741901333898e-06,
      "loss": 0.6355,
      "step": 806050
    },
    {
      "epoch": 8.53368339147051,
      "grad_norm": 4.5494465827941895,
      "learning_rate": 7.3500952784247304e-06,
      "loss": 0.6375,
      "step": 806100
    },
    {
      "epoch": 8.534212713250511,
      "grad_norm": 4.866475582122803,
      "learning_rate": 7.347448655515563e-06,
      "loss": 0.6391,
      "step": 806150
    },
    {
      "epoch": 8.534742035030515,
      "grad_norm": 4.207690238952637,
      "learning_rate": 7.344802032606394e-06,
      "loss": 0.6372,
      "step": 806200
    },
    {
      "epoch": 8.535271356810519,
      "grad_norm": 4.496020793914795,
      "learning_rate": 7.34220834215541e-06,
      "loss": 0.6263,
      "step": 806250
    },
    {
      "epoch": 8.535800678590522,
      "grad_norm": 4.179009914398193,
      "learning_rate": 7.339561719246242e-06,
      "loss": 0.6333,
      "step": 806300
    },
    {
      "epoch": 8.536330000370524,
      "grad_norm": 4.541512966156006,
      "learning_rate": 7.336915096337074e-06,
      "loss": 0.6365,
      "step": 806350
    },
    {
      "epoch": 8.536859322150528,
      "grad_norm": 4.841923713684082,
      "learning_rate": 7.334268473427906e-06,
      "loss": 0.6328,
      "step": 806400
    },
    {
      "epoch": 8.537388643930532,
      "grad_norm": 4.161935806274414,
      "learning_rate": 7.331621850518739e-06,
      "loss": 0.6366,
      "step": 806450
    },
    {
      "epoch": 8.537917965710536,
      "grad_norm": 4.542636394500732,
      "learning_rate": 7.32897522760957e-06,
      "loss": 0.638,
      "step": 806500
    },
    {
      "epoch": 8.537917965710536,
      "eval_loss": 0.3869690001010895,
      "eval_runtime": 46.4537,
      "eval_samples_per_second": 3614.998,
      "eval_steps_per_second": 451.891,
      "step": 806500
    },
    {
      "epoch": 8.538447287490538,
      "grad_norm": 4.547482490539551,
      "learning_rate": 7.326328604700403e-06,
      "loss": 0.6325,
      "step": 806550
    },
    {
      "epoch": 8.538976609270541,
      "grad_norm": 4.452210903167725,
      "learning_rate": 7.323681981791235e-06,
      "loss": 0.6287,
      "step": 806600
    },
    {
      "epoch": 8.539505931050545,
      "grad_norm": 4.521687030792236,
      "learning_rate": 7.321035358882067e-06,
      "loss": 0.6299,
      "step": 806650
    },
    {
      "epoch": 8.540035252830549,
      "grad_norm": 4.036538124084473,
      "learning_rate": 7.318388735972899e-06,
      "loss": 0.6318,
      "step": 806700
    },
    {
      "epoch": 8.540564574610551,
      "grad_norm": 4.041162014007568,
      "learning_rate": 7.315742113063731e-06,
      "loss": 0.63,
      "step": 806750
    },
    {
      "epoch": 8.541093896390555,
      "grad_norm": 3.9140584468841553,
      "learning_rate": 7.313095490154563e-06,
      "loss": 0.6328,
      "step": 806800
    },
    {
      "epoch": 8.541623218170558,
      "grad_norm": 4.944718837738037,
      "learning_rate": 7.3104488672453954e-06,
      "loss": 0.6448,
      "step": 806850
    },
    {
      "epoch": 8.54215253995056,
      "grad_norm": 4.519272327423096,
      "learning_rate": 7.307802244336227e-06,
      "loss": 0.6217,
      "step": 806900
    },
    {
      "epoch": 8.542681861730564,
      "grad_norm": 4.922245025634766,
      "learning_rate": 7.305155621427059e-06,
      "loss": 0.6399,
      "step": 806950
    },
    {
      "epoch": 8.543211183510568,
      "grad_norm": 4.543416976928711,
      "learning_rate": 7.302508998517892e-06,
      "loss": 0.6333,
      "step": 807000
    },
    {
      "epoch": 8.543211183510568,
      "eval_loss": 0.38712480664253235,
      "eval_runtime": 46.4225,
      "eval_samples_per_second": 3617.423,
      "eval_steps_per_second": 452.194,
      "step": 807000
    },
    {
      "epoch": 8.543740505290572,
      "grad_norm": 4.7926859855651855,
      "learning_rate": 7.299862375608723e-06,
      "loss": 0.6228,
      "step": 807050
    },
    {
      "epoch": 8.544269827070574,
      "grad_norm": 4.594161033630371,
      "learning_rate": 7.297215752699556e-06,
      "loss": 0.6359,
      "step": 807100
    },
    {
      "epoch": 8.544799148850577,
      "grad_norm": 5.254598140716553,
      "learning_rate": 7.294569129790388e-06,
      "loss": 0.6412,
      "step": 807150
    },
    {
      "epoch": 8.545328470630581,
      "grad_norm": 4.479977607727051,
      "learning_rate": 7.29192250688122e-06,
      "loss": 0.639,
      "step": 807200
    },
    {
      "epoch": 8.545857792410585,
      "grad_norm": 4.716917991638184,
      "learning_rate": 7.289275883972052e-06,
      "loss": 0.639,
      "step": 807250
    },
    {
      "epoch": 8.546387114190587,
      "grad_norm": 4.717507362365723,
      "learning_rate": 7.2866292610628846e-06,
      "loss": 0.6306,
      "step": 807300
    },
    {
      "epoch": 8.54691643597059,
      "grad_norm": 4.239014625549316,
      "learning_rate": 7.283982638153716e-06,
      "loss": 0.6401,
      "step": 807350
    },
    {
      "epoch": 8.547445757750594,
      "grad_norm": 4.7861456871032715,
      "learning_rate": 7.2813360152445485e-06,
      "loss": 0.6331,
      "step": 807400
    },
    {
      "epoch": 8.547975079530598,
      "grad_norm": 4.810808181762695,
      "learning_rate": 7.27868939233538e-06,
      "loss": 0.6235,
      "step": 807450
    },
    {
      "epoch": 8.5485044013106,
      "grad_norm": 4.391485691070557,
      "learning_rate": 7.2760427694262125e-06,
      "loss": 0.6299,
      "step": 807500
    },
    {
      "epoch": 8.5485044013106,
      "eval_loss": 0.38661620020866394,
      "eval_runtime": 46.5397,
      "eval_samples_per_second": 3608.319,
      "eval_steps_per_second": 451.056,
      "step": 807500
    },
    {
      "epoch": 8.549033723090604,
      "grad_norm": 4.738150596618652,
      "learning_rate": 7.273396146517045e-06,
      "loss": 0.6367,
      "step": 807550
    },
    {
      "epoch": 8.549563044870608,
      "grad_norm": 4.312347412109375,
      "learning_rate": 7.2707495236078765e-06,
      "loss": 0.6299,
      "step": 807600
    },
    {
      "epoch": 8.55009236665061,
      "grad_norm": 4.102816581726074,
      "learning_rate": 7.268102900698709e-06,
      "loss": 0.6205,
      "step": 807650
    },
    {
      "epoch": 8.550621688430613,
      "grad_norm": 5.1342668533325195,
      "learning_rate": 7.265456277789541e-06,
      "loss": 0.6311,
      "step": 807700
    },
    {
      "epoch": 8.551151010210617,
      "grad_norm": 4.8054938316345215,
      "learning_rate": 7.262809654880373e-06,
      "loss": 0.6247,
      "step": 807750
    },
    {
      "epoch": 8.551680331990621,
      "grad_norm": 4.692060947418213,
      "learning_rate": 7.260163031971205e-06,
      "loss": 0.6401,
      "step": 807800
    },
    {
      "epoch": 8.552209653770623,
      "grad_norm": 4.153125762939453,
      "learning_rate": 7.257516409062038e-06,
      "loss": 0.6324,
      "step": 807850
    },
    {
      "epoch": 8.552738975550627,
      "grad_norm": 4.492334842681885,
      "learning_rate": 7.254869786152869e-06,
      "loss": 0.6338,
      "step": 807900
    },
    {
      "epoch": 8.55326829733063,
      "grad_norm": 4.414062976837158,
      "learning_rate": 7.252223163243702e-06,
      "loss": 0.6362,
      "step": 807950
    },
    {
      "epoch": 8.553797619110634,
      "grad_norm": 4.489995002746582,
      "learning_rate": 7.249576540334534e-06,
      "loss": 0.6429,
      "step": 808000
    },
    {
      "epoch": 8.553797619110634,
      "eval_loss": 0.3866196870803833,
      "eval_runtime": 46.4337,
      "eval_samples_per_second": 3616.553,
      "eval_steps_per_second": 452.085,
      "step": 808000
    },
    {
      "epoch": 8.554326940890636,
      "grad_norm": 4.449297904968262,
      "learning_rate": 7.2469299174253656e-06,
      "loss": 0.6359,
      "step": 808050
    },
    {
      "epoch": 8.55485626267064,
      "grad_norm": 5.028091907501221,
      "learning_rate": 7.244283294516198e-06,
      "loss": 0.6368,
      "step": 808100
    },
    {
      "epoch": 8.555385584450644,
      "grad_norm": 4.794905662536621,
      "learning_rate": 7.24163667160703e-06,
      "loss": 0.6354,
      "step": 808150
    },
    {
      "epoch": 8.555914906230647,
      "grad_norm": 4.41310453414917,
      "learning_rate": 7.238990048697862e-06,
      "loss": 0.6352,
      "step": 808200
    },
    {
      "epoch": 8.55644422801065,
      "grad_norm": 4.311078071594238,
      "learning_rate": 7.236343425788694e-06,
      "loss": 0.6293,
      "step": 808250
    },
    {
      "epoch": 8.556973549790653,
      "grad_norm": 4.610222816467285,
      "learning_rate": 7.233696802879526e-06,
      "loss": 0.6308,
      "step": 808300
    },
    {
      "epoch": 8.557502871570657,
      "grad_norm": 4.372405529022217,
      "learning_rate": 7.231050179970358e-06,
      "loss": 0.6404,
      "step": 808350
    },
    {
      "epoch": 8.558032193350659,
      "grad_norm": 4.854129314422607,
      "learning_rate": 7.228403557061191e-06,
      "loss": 0.6293,
      "step": 808400
    },
    {
      "epoch": 8.558561515130663,
      "grad_norm": 4.462373733520508,
      "learning_rate": 7.225756934152022e-06,
      "loss": 0.6333,
      "step": 808450
    },
    {
      "epoch": 8.559090836910666,
      "grad_norm": 4.6787848472595215,
      "learning_rate": 7.223110311242855e-06,
      "loss": 0.6323,
      "step": 808500
    },
    {
      "epoch": 8.559090836910666,
      "eval_loss": 0.38723835349082947,
      "eval_runtime": 46.4694,
      "eval_samples_per_second": 3613.78,
      "eval_steps_per_second": 451.739,
      "step": 808500
    },
    {
      "epoch": 8.55962015869067,
      "grad_norm": 4.445539474487305,
      "learning_rate": 7.220463688333687e-06,
      "loss": 0.6145,
      "step": 808550
    },
    {
      "epoch": 8.560149480470672,
      "grad_norm": 4.7151970863342285,
      "learning_rate": 7.217817065424519e-06,
      "loss": 0.6391,
      "step": 808600
    },
    {
      "epoch": 8.560678802250676,
      "grad_norm": 4.982493877410889,
      "learning_rate": 7.215170442515351e-06,
      "loss": 0.6339,
      "step": 808650
    },
    {
      "epoch": 8.56120812403068,
      "grad_norm": 4.569097518920898,
      "learning_rate": 7.2125238196061835e-06,
      "loss": 0.6303,
      "step": 808700
    },
    {
      "epoch": 8.561737445810683,
      "grad_norm": 4.66126823425293,
      "learning_rate": 7.209877196697015e-06,
      "loss": 0.6346,
      "step": 808750
    },
    {
      "epoch": 8.562266767590685,
      "grad_norm": 4.343484878540039,
      "learning_rate": 7.207230573787847e-06,
      "loss": 0.6252,
      "step": 808800
    },
    {
      "epoch": 8.56279608937069,
      "grad_norm": 4.311522006988525,
      "learning_rate": 7.20458395087868e-06,
      "loss": 0.6311,
      "step": 808850
    },
    {
      "epoch": 8.563325411150693,
      "grad_norm": 4.92824125289917,
      "learning_rate": 7.201937327969511e-06,
      "loss": 0.6216,
      "step": 808900
    },
    {
      "epoch": 8.563854732930697,
      "grad_norm": 4.898087024688721,
      "learning_rate": 7.199290705060344e-06,
      "loss": 0.6297,
      "step": 808950
    },
    {
      "epoch": 8.564384054710699,
      "grad_norm": 4.4837188720703125,
      "learning_rate": 7.196644082151175e-06,
      "loss": 0.6325,
      "step": 809000
    },
    {
      "epoch": 8.564384054710699,
      "eval_loss": 0.3867928981781006,
      "eval_runtime": 46.4769,
      "eval_samples_per_second": 3613.19,
      "eval_steps_per_second": 451.665,
      "step": 809000
    },
    {
      "epoch": 8.564913376490702,
      "grad_norm": 4.238432884216309,
      "learning_rate": 7.193997459242008e-06,
      "loss": 0.6417,
      "step": 809050
    },
    {
      "epoch": 8.565442698270706,
      "grad_norm": 4.942398548126221,
      "learning_rate": 7.19135083633284e-06,
      "loss": 0.6343,
      "step": 809100
    },
    {
      "epoch": 8.565972020050708,
      "grad_norm": 4.291932106018066,
      "learning_rate": 7.188704213423672e-06,
      "loss": 0.6346,
      "step": 809150
    },
    {
      "epoch": 8.566501341830712,
      "grad_norm": 4.842865467071533,
      "learning_rate": 7.186057590514504e-06,
      "loss": 0.6437,
      "step": 809200
    },
    {
      "epoch": 8.567030663610716,
      "grad_norm": 4.44924259185791,
      "learning_rate": 7.1834109676053365e-06,
      "loss": 0.6352,
      "step": 809250
    },
    {
      "epoch": 8.56755998539072,
      "grad_norm": 4.896952152252197,
      "learning_rate": 7.180764344696168e-06,
      "loss": 0.631,
      "step": 809300
    },
    {
      "epoch": 8.568089307170721,
      "grad_norm": 4.526160717010498,
      "learning_rate": 7.1781177217870005e-06,
      "loss": 0.6303,
      "step": 809350
    },
    {
      "epoch": 8.568618628950725,
      "grad_norm": 4.363013744354248,
      "learning_rate": 7.175471098877833e-06,
      "loss": 0.6376,
      "step": 809400
    },
    {
      "epoch": 8.569147950730729,
      "grad_norm": 4.461496829986572,
      "learning_rate": 7.1728244759686645e-06,
      "loss": 0.6417,
      "step": 809450
    },
    {
      "epoch": 8.569677272510733,
      "grad_norm": 4.408390998840332,
      "learning_rate": 7.170177853059497e-06,
      "loss": 0.633,
      "step": 809500
    },
    {
      "epoch": 8.569677272510733,
      "eval_loss": 0.3867645263671875,
      "eval_runtime": 46.4486,
      "eval_samples_per_second": 3615.393,
      "eval_steps_per_second": 451.94,
      "step": 809500
    },
    {
      "epoch": 8.570206594290735,
      "grad_norm": 4.538263320922852,
      "learning_rate": 7.167531230150329e-06,
      "loss": 0.6306,
      "step": 809550
    },
    {
      "epoch": 8.570735916070738,
      "grad_norm": 4.461403846740723,
      "learning_rate": 7.164884607241161e-06,
      "loss": 0.6322,
      "step": 809600
    },
    {
      "epoch": 8.571265237850742,
      "grad_norm": 4.234195709228516,
      "learning_rate": 7.162237984331993e-06,
      "loss": 0.6352,
      "step": 809650
    },
    {
      "epoch": 8.571794559630746,
      "grad_norm": 4.713258266448975,
      "learning_rate": 7.159591361422825e-06,
      "loss": 0.6357,
      "step": 809700
    },
    {
      "epoch": 8.572323881410748,
      "grad_norm": 4.511059761047363,
      "learning_rate": 7.156944738513657e-06,
      "loss": 0.6413,
      "step": 809750
    },
    {
      "epoch": 8.572853203190752,
      "grad_norm": 4.848270416259766,
      "learning_rate": 7.15429811560449e-06,
      "loss": 0.6387,
      "step": 809800
    },
    {
      "epoch": 8.573382524970755,
      "grad_norm": 4.723128318786621,
      "learning_rate": 7.151651492695321e-06,
      "loss": 0.6435,
      "step": 809850
    },
    {
      "epoch": 8.573911846750757,
      "grad_norm": 4.0521674156188965,
      "learning_rate": 7.1490048697861536e-06,
      "loss": 0.6259,
      "step": 809900
    },
    {
      "epoch": 8.574441168530761,
      "grad_norm": 4.725244998931885,
      "learning_rate": 7.146358246876986e-06,
      "loss": 0.6262,
      "step": 809950
    },
    {
      "epoch": 8.574970490310765,
      "grad_norm": 5.048657417297363,
      "learning_rate": 7.1437116239678175e-06,
      "loss": 0.6307,
      "step": 810000
    },
    {
      "epoch": 8.574970490310765,
      "eval_loss": 0.3877095878124237,
      "eval_runtime": 46.3945,
      "eval_samples_per_second": 3619.614,
      "eval_steps_per_second": 452.468,
      "step": 810000
    },
    {
      "epoch": 8.575499812090769,
      "grad_norm": 4.6516804695129395,
      "learning_rate": 7.14106500105865e-06,
      "loss": 0.6409,
      "step": 810050
    },
    {
      "epoch": 8.57602913387077,
      "grad_norm": 3.960080623626709,
      "learning_rate": 7.138418378149482e-06,
      "loss": 0.6303,
      "step": 810100
    },
    {
      "epoch": 8.576558455650774,
      "grad_norm": 4.6167683601379395,
      "learning_rate": 7.135771755240314e-06,
      "loss": 0.6259,
      "step": 810150
    },
    {
      "epoch": 8.577087777430778,
      "grad_norm": 4.938014030456543,
      "learning_rate": 7.133125132331146e-06,
      "loss": 0.6294,
      "step": 810200
    },
    {
      "epoch": 8.577617099210782,
      "grad_norm": 4.9433465003967285,
      "learning_rate": 7.130478509421979e-06,
      "loss": 0.6415,
      "step": 810250
    },
    {
      "epoch": 8.578146420990784,
      "grad_norm": 5.009932994842529,
      "learning_rate": 7.1278848189709934e-06,
      "loss": 0.6301,
      "step": 810300
    },
    {
      "epoch": 8.578675742770788,
      "grad_norm": 4.544065952301025,
      "learning_rate": 7.125238196061826e-06,
      "loss": 0.632,
      "step": 810350
    },
    {
      "epoch": 8.579205064550791,
      "grad_norm": 4.669864654541016,
      "learning_rate": 7.122591573152658e-06,
      "loss": 0.6413,
      "step": 810400
    },
    {
      "epoch": 8.579734386330795,
      "grad_norm": 4.453896522521973,
      "learning_rate": 7.11994495024349e-06,
      "loss": 0.6382,
      "step": 810450
    },
    {
      "epoch": 8.580263708110797,
      "grad_norm": 4.799323081970215,
      "learning_rate": 7.117298327334322e-06,
      "loss": 0.6361,
      "step": 810500
    },
    {
      "epoch": 8.580263708110797,
      "eval_loss": 0.3869570791721344,
      "eval_runtime": 46.4142,
      "eval_samples_per_second": 3618.076,
      "eval_steps_per_second": 452.276,
      "step": 810500
    },
    {
      "epoch": 8.5807930298908,
      "grad_norm": 5.0829620361328125,
      "learning_rate": 7.114651704425155e-06,
      "loss": 0.6234,
      "step": 810550
    },
    {
      "epoch": 8.581322351670805,
      "grad_norm": 4.485309600830078,
      "learning_rate": 7.112005081515986e-06,
      "loss": 0.6245,
      "step": 810600
    },
    {
      "epoch": 8.581851673450807,
      "grad_norm": 4.674686908721924,
      "learning_rate": 7.1093584586068186e-06,
      "loss": 0.625,
      "step": 810650
    },
    {
      "epoch": 8.58238099523081,
      "grad_norm": 4.468891620635986,
      "learning_rate": 7.106711835697651e-06,
      "loss": 0.6379,
      "step": 810700
    },
    {
      "epoch": 8.582910317010814,
      "grad_norm": 4.8014702796936035,
      "learning_rate": 7.1040652127884825e-06,
      "loss": 0.6316,
      "step": 810750
    },
    {
      "epoch": 8.583439638790818,
      "grad_norm": 4.505713939666748,
      "learning_rate": 7.101418589879315e-06,
      "loss": 0.6259,
      "step": 810800
    },
    {
      "epoch": 8.58396896057082,
      "grad_norm": 4.546411991119385,
      "learning_rate": 7.0987719669701465e-06,
      "loss": 0.6344,
      "step": 810850
    },
    {
      "epoch": 8.584498282350824,
      "grad_norm": 4.585038185119629,
      "learning_rate": 7.096125344060979e-06,
      "loss": 0.6423,
      "step": 810900
    },
    {
      "epoch": 8.585027604130827,
      "grad_norm": 4.3121113777160645,
      "learning_rate": 7.093478721151811e-06,
      "loss": 0.6412,
      "step": 810950
    },
    {
      "epoch": 8.585556925910831,
      "grad_norm": 4.357411861419678,
      "learning_rate": 7.090832098242643e-06,
      "loss": 0.6279,
      "step": 811000
    },
    {
      "epoch": 8.585556925910831,
      "eval_loss": 0.3865375816822052,
      "eval_runtime": 46.5809,
      "eval_samples_per_second": 3605.126,
      "eval_steps_per_second": 450.657,
      "step": 811000
    },
    {
      "epoch": 8.586086247690833,
      "grad_norm": 4.2613606452941895,
      "learning_rate": 7.088185475333475e-06,
      "loss": 0.6281,
      "step": 811050
    },
    {
      "epoch": 8.586615569470837,
      "grad_norm": 4.248748302459717,
      "learning_rate": 7.085538852424308e-06,
      "loss": 0.6415,
      "step": 811100
    },
    {
      "epoch": 8.58714489125084,
      "grad_norm": 4.582449436187744,
      "learning_rate": 7.082892229515139e-06,
      "loss": 0.626,
      "step": 811150
    },
    {
      "epoch": 8.587674213030844,
      "grad_norm": 4.572747230529785,
      "learning_rate": 7.080245606605972e-06,
      "loss": 0.6165,
      "step": 811200
    },
    {
      "epoch": 8.588203534810846,
      "grad_norm": 4.798278331756592,
      "learning_rate": 7.077598983696804e-06,
      "loss": 0.6261,
      "step": 811250
    },
    {
      "epoch": 8.58873285659085,
      "grad_norm": 4.973099708557129,
      "learning_rate": 7.074952360787636e-06,
      "loss": 0.6293,
      "step": 811300
    },
    {
      "epoch": 8.589262178370854,
      "grad_norm": 4.836566925048828,
      "learning_rate": 7.072305737878468e-06,
      "loss": 0.6303,
      "step": 811350
    },
    {
      "epoch": 8.589791500150856,
      "grad_norm": 4.311060905456543,
      "learning_rate": 7.0696591149693004e-06,
      "loss": 0.6328,
      "step": 811400
    },
    {
      "epoch": 8.59032082193086,
      "grad_norm": 4.615739822387695,
      "learning_rate": 7.067012492060132e-06,
      "loss": 0.6252,
      "step": 811450
    },
    {
      "epoch": 8.590850143710863,
      "grad_norm": 4.558919906616211,
      "learning_rate": 7.064365869150964e-06,
      "loss": 0.634,
      "step": 811500
    },
    {
      "epoch": 8.590850143710863,
      "eval_loss": 0.38646966218948364,
      "eval_runtime": 46.4548,
      "eval_samples_per_second": 3614.915,
      "eval_steps_per_second": 451.881,
      "step": 811500
    },
    {
      "epoch": 8.591379465490867,
      "grad_norm": 4.577510833740234,
      "learning_rate": 7.061719246241796e-06,
      "loss": 0.6249,
      "step": 811550
    },
    {
      "epoch": 8.591908787270869,
      "grad_norm": 4.749981880187988,
      "learning_rate": 7.059072623332628e-06,
      "loss": 0.6366,
      "step": 811600
    },
    {
      "epoch": 8.592438109050873,
      "grad_norm": 4.6752753257751465,
      "learning_rate": 7.056426000423461e-06,
      "loss": 0.6405,
      "step": 811650
    },
    {
      "epoch": 8.592967430830877,
      "grad_norm": 4.414145469665527,
      "learning_rate": 7.053779377514292e-06,
      "loss": 0.6228,
      "step": 811700
    },
    {
      "epoch": 8.59349675261088,
      "grad_norm": 4.724161148071289,
      "learning_rate": 7.051132754605125e-06,
      "loss": 0.6467,
      "step": 811750
    },
    {
      "epoch": 8.594026074390882,
      "grad_norm": 4.487093448638916,
      "learning_rate": 7.048486131695957e-06,
      "loss": 0.6265,
      "step": 811800
    },
    {
      "epoch": 8.594555396170886,
      "grad_norm": 4.367102146148682,
      "learning_rate": 7.045839508786789e-06,
      "loss": 0.6355,
      "step": 811850
    },
    {
      "epoch": 8.59508471795089,
      "grad_norm": 4.852210521697998,
      "learning_rate": 7.043192885877621e-06,
      "loss": 0.6342,
      "step": 811900
    },
    {
      "epoch": 8.595614039730894,
      "grad_norm": 5.00627326965332,
      "learning_rate": 7.0405462629684535e-06,
      "loss": 0.6472,
      "step": 811950
    },
    {
      "epoch": 8.596143361510896,
      "grad_norm": 4.549022674560547,
      "learning_rate": 7.037899640059285e-06,
      "loss": 0.6357,
      "step": 812000
    },
    {
      "epoch": 8.596143361510896,
      "eval_loss": 0.3866492509841919,
      "eval_runtime": 46.4904,
      "eval_samples_per_second": 3612.145,
      "eval_steps_per_second": 451.534,
      "step": 812000
    },
    {
      "epoch": 8.5966726832909,
      "grad_norm": 4.862726211547852,
      "learning_rate": 7.0352530171501175e-06,
      "loss": 0.6249,
      "step": 812050
    },
    {
      "epoch": 8.597202005070903,
      "grad_norm": 4.798627853393555,
      "learning_rate": 7.03260639424095e-06,
      "loss": 0.632,
      "step": 812100
    },
    {
      "epoch": 8.597731326850905,
      "grad_norm": 4.495224952697754,
      "learning_rate": 7.0299597713317814e-06,
      "loss": 0.6257,
      "step": 812150
    },
    {
      "epoch": 8.598260648630909,
      "grad_norm": 4.661375522613525,
      "learning_rate": 7.027313148422614e-06,
      "loss": 0.6275,
      "step": 812200
    },
    {
      "epoch": 8.598789970410913,
      "grad_norm": 5.273611545562744,
      "learning_rate": 7.024666525513446e-06,
      "loss": 0.6359,
      "step": 812250
    },
    {
      "epoch": 8.599319292190916,
      "grad_norm": 4.600818634033203,
      "learning_rate": 7.022072835062461e-06,
      "loss": 0.6281,
      "step": 812300
    },
    {
      "epoch": 8.599848613970918,
      "grad_norm": 4.02330207824707,
      "learning_rate": 7.019426212153293e-06,
      "loss": 0.6304,
      "step": 812350
    },
    {
      "epoch": 8.600377935750922,
      "grad_norm": 4.993074417114258,
      "learning_rate": 7.016779589244126e-06,
      "loss": 0.6333,
      "step": 812400
    },
    {
      "epoch": 8.600907257530926,
      "grad_norm": 5.084386348724365,
      "learning_rate": 7.014132966334957e-06,
      "loss": 0.6274,
      "step": 812450
    },
    {
      "epoch": 8.60143657931093,
      "grad_norm": 4.699691295623779,
      "learning_rate": 7.01148634342579e-06,
      "loss": 0.6292,
      "step": 812500
    },
    {
      "epoch": 8.60143657931093,
      "eval_loss": 0.38663139939308167,
      "eval_runtime": 46.5448,
      "eval_samples_per_second": 3607.923,
      "eval_steps_per_second": 451.006,
      "step": 812500
    },
    {
      "epoch": 8.601965901090932,
      "grad_norm": 4.489950180053711,
      "learning_rate": 7.008892652974805e-06,
      "loss": 0.6388,
      "step": 812550
    },
    {
      "epoch": 8.602495222870935,
      "grad_norm": 4.480720520019531,
      "learning_rate": 7.006246030065637e-06,
      "loss": 0.6143,
      "step": 812600
    },
    {
      "epoch": 8.603024544650939,
      "grad_norm": 4.639736175537109,
      "learning_rate": 7.003599407156469e-06,
      "loss": 0.6414,
      "step": 812650
    },
    {
      "epoch": 8.603553866430943,
      "grad_norm": 4.420085430145264,
      "learning_rate": 7.000952784247302e-06,
      "loss": 0.6388,
      "step": 812700
    },
    {
      "epoch": 8.604083188210945,
      "grad_norm": 4.648402690887451,
      "learning_rate": 6.998306161338133e-06,
      "loss": 0.6358,
      "step": 812750
    },
    {
      "epoch": 8.604612509990949,
      "grad_norm": 4.537879943847656,
      "learning_rate": 6.995659538428966e-06,
      "loss": 0.6279,
      "step": 812800
    },
    {
      "epoch": 8.605141831770952,
      "grad_norm": 5.01378870010376,
      "learning_rate": 6.993012915519798e-06,
      "loss": 0.6476,
      "step": 812850
    },
    {
      "epoch": 8.605671153550954,
      "grad_norm": 4.308791637420654,
      "learning_rate": 6.99036629261063e-06,
      "loss": 0.6288,
      "step": 812900
    },
    {
      "epoch": 8.606200475330958,
      "grad_norm": 4.50740909576416,
      "learning_rate": 6.987719669701462e-06,
      "loss": 0.6269,
      "step": 812950
    },
    {
      "epoch": 8.606729797110962,
      "grad_norm": 5.0331549644470215,
      "learning_rate": 6.9850730467922935e-06,
      "loss": 0.6409,
      "step": 813000
    },
    {
      "epoch": 8.606729797110962,
      "eval_loss": 0.38564711809158325,
      "eval_runtime": 46.5613,
      "eval_samples_per_second": 3606.644,
      "eval_steps_per_second": 450.847,
      "step": 813000
    },
    {
      "epoch": 8.607259118890966,
      "grad_norm": 4.902700901031494,
      "learning_rate": 6.982426423883126e-06,
      "loss": 0.6285,
      "step": 813050
    },
    {
      "epoch": 8.607788440670967,
      "grad_norm": 4.75773811340332,
      "learning_rate": 6.979779800973958e-06,
      "loss": 0.6366,
      "step": 813100
    },
    {
      "epoch": 8.608317762450971,
      "grad_norm": 4.390344142913818,
      "learning_rate": 6.97713317806479e-06,
      "loss": 0.6405,
      "step": 813150
    },
    {
      "epoch": 8.608847084230975,
      "grad_norm": 4.540093421936035,
      "learning_rate": 6.974486555155622e-06,
      "loss": 0.6355,
      "step": 813200
    },
    {
      "epoch": 8.609376406010979,
      "grad_norm": 4.54167366027832,
      "learning_rate": 6.971839932246455e-06,
      "loss": 0.6369,
      "step": 813250
    },
    {
      "epoch": 8.60990572779098,
      "grad_norm": 4.037215709686279,
      "learning_rate": 6.969193309337286e-06,
      "loss": 0.6405,
      "step": 813300
    },
    {
      "epoch": 8.610435049570984,
      "grad_norm": 4.716520309448242,
      "learning_rate": 6.966546686428119e-06,
      "loss": 0.6359,
      "step": 813350
    },
    {
      "epoch": 8.610964371350988,
      "grad_norm": 4.192854404449463,
      "learning_rate": 6.963900063518951e-06,
      "loss": 0.6338,
      "step": 813400
    },
    {
      "epoch": 8.611493693130992,
      "grad_norm": 4.594626426696777,
      "learning_rate": 6.961253440609783e-06,
      "loss": 0.6368,
      "step": 813450
    },
    {
      "epoch": 8.612023014910994,
      "grad_norm": 4.567145824432373,
      "learning_rate": 6.958606817700615e-06,
      "loss": 0.6387,
      "step": 813500
    },
    {
      "epoch": 8.612023014910994,
      "eval_loss": 0.38670894503593445,
      "eval_runtime": 46.4555,
      "eval_samples_per_second": 3614.855,
      "eval_steps_per_second": 451.873,
      "step": 813500
    },
    {
      "epoch": 8.612552336690998,
      "grad_norm": 4.791810989379883,
      "learning_rate": 6.9559601947914475e-06,
      "loss": 0.634,
      "step": 813550
    },
    {
      "epoch": 8.613081658471001,
      "grad_norm": 4.748692512512207,
      "learning_rate": 6.953313571882279e-06,
      "loss": 0.6225,
      "step": 813600
    },
    {
      "epoch": 8.613610980251003,
      "grad_norm": 4.439074993133545,
      "learning_rate": 6.9506669489731114e-06,
      "loss": 0.6304,
      "step": 813650
    },
    {
      "epoch": 8.614140302031007,
      "grad_norm": 4.692005634307861,
      "learning_rate": 6.948020326063944e-06,
      "loss": 0.6315,
      "step": 813700
    },
    {
      "epoch": 8.614669623811011,
      "grad_norm": 4.496101379394531,
      "learning_rate": 6.9453737031547746e-06,
      "loss": 0.6328,
      "step": 813750
    },
    {
      "epoch": 8.615198945591015,
      "grad_norm": 4.478613376617432,
      "learning_rate": 6.942727080245606e-06,
      "loss": 0.6297,
      "step": 813800
    },
    {
      "epoch": 8.615728267371017,
      "grad_norm": 5.101373672485352,
      "learning_rate": 6.9400804573364385e-06,
      "loss": 0.6195,
      "step": 813850
    },
    {
      "epoch": 8.61625758915102,
      "grad_norm": 4.6048102378845215,
      "learning_rate": 6.93743383442727e-06,
      "loss": 0.6334,
      "step": 813900
    },
    {
      "epoch": 8.616786910931024,
      "grad_norm": 4.869919300079346,
      "learning_rate": 6.9347872115181025e-06,
      "loss": 0.6345,
      "step": 813950
    },
    {
      "epoch": 8.617316232711028,
      "grad_norm": 4.204408645629883,
      "learning_rate": 6.932140588608935e-06,
      "loss": 0.6399,
      "step": 814000
    },
    {
      "epoch": 8.617316232711028,
      "eval_loss": 0.386427104473114,
      "eval_runtime": 46.4596,
      "eval_samples_per_second": 3614.538,
      "eval_steps_per_second": 451.833,
      "step": 814000
    },
    {
      "epoch": 8.61784555449103,
      "grad_norm": 4.382326126098633,
      "learning_rate": 6.9294939656997664e-06,
      "loss": 0.6396,
      "step": 814050
    },
    {
      "epoch": 8.618374876271034,
      "grad_norm": 4.4437642097473145,
      "learning_rate": 6.926847342790599e-06,
      "loss": 0.64,
      "step": 814100
    },
    {
      "epoch": 8.618904198051037,
      "grad_norm": 4.701035976409912,
      "learning_rate": 6.924200719881431e-06,
      "loss": 0.6309,
      "step": 814150
    },
    {
      "epoch": 8.619433519831041,
      "grad_norm": 4.627421855926514,
      "learning_rate": 6.921554096972263e-06,
      "loss": 0.6163,
      "step": 814200
    },
    {
      "epoch": 8.619962841611043,
      "grad_norm": 4.783473491668701,
      "learning_rate": 6.918907474063095e-06,
      "loss": 0.6388,
      "step": 814250
    },
    {
      "epoch": 8.620492163391047,
      "grad_norm": 5.004155158996582,
      "learning_rate": 6.916260851153928e-06,
      "loss": 0.6354,
      "step": 814300
    },
    {
      "epoch": 8.62102148517105,
      "grad_norm": 4.5942063331604,
      "learning_rate": 6.913614228244759e-06,
      "loss": 0.63,
      "step": 814350
    },
    {
      "epoch": 8.621550806951053,
      "grad_norm": 4.372076988220215,
      "learning_rate": 6.910967605335592e-06,
      "loss": 0.6248,
      "step": 814400
    },
    {
      "epoch": 8.622080128731056,
      "grad_norm": 4.547821998596191,
      "learning_rate": 6.908320982426424e-06,
      "loss": 0.6391,
      "step": 814450
    },
    {
      "epoch": 8.62260945051106,
      "grad_norm": 4.662153720855713,
      "learning_rate": 6.9056743595172556e-06,
      "loss": 0.6399,
      "step": 814500
    },
    {
      "epoch": 8.62260945051106,
      "eval_loss": 0.38621410727500916,
      "eval_runtime": 46.4449,
      "eval_samples_per_second": 3615.684,
      "eval_steps_per_second": 451.977,
      "step": 814500
    },
    {
      "epoch": 8.623138772291064,
      "grad_norm": 3.918468713760376,
      "learning_rate": 6.903027736608088e-06,
      "loss": 0.6398,
      "step": 814550
    },
    {
      "epoch": 8.623668094071066,
      "grad_norm": 4.480406284332275,
      "learning_rate": 6.9003811136989195e-06,
      "loss": 0.6325,
      "step": 814600
    },
    {
      "epoch": 8.62419741585107,
      "grad_norm": 4.907591819763184,
      "learning_rate": 6.897734490789752e-06,
      "loss": 0.633,
      "step": 814650
    },
    {
      "epoch": 8.624726737631073,
      "grad_norm": 4.731238842010498,
      "learning_rate": 6.895087867880584e-06,
      "loss": 0.6357,
      "step": 814700
    },
    {
      "epoch": 8.625256059411077,
      "grad_norm": 4.731301784515381,
      "learning_rate": 6.892441244971416e-06,
      "loss": 0.6342,
      "step": 814750
    },
    {
      "epoch": 8.62578538119108,
      "grad_norm": 5.094597339630127,
      "learning_rate": 6.889794622062248e-06,
      "loss": 0.6317,
      "step": 814800
    },
    {
      "epoch": 8.626314702971083,
      "grad_norm": 3.8045523166656494,
      "learning_rate": 6.887147999153081e-06,
      "loss": 0.6376,
      "step": 814850
    },
    {
      "epoch": 8.626844024751087,
      "grad_norm": 4.855902194976807,
      "learning_rate": 6.884501376243912e-06,
      "loss": 0.6274,
      "step": 814900
    },
    {
      "epoch": 8.62737334653109,
      "grad_norm": 4.786892414093018,
      "learning_rate": 6.881854753334745e-06,
      "loss": 0.6268,
      "step": 814950
    },
    {
      "epoch": 8.627902668311092,
      "grad_norm": 4.47943639755249,
      "learning_rate": 6.879208130425577e-06,
      "loss": 0.636,
      "step": 815000
    },
    {
      "epoch": 8.627902668311092,
      "eval_loss": 0.38563209772109985,
      "eval_runtime": 46.5624,
      "eval_samples_per_second": 3606.557,
      "eval_steps_per_second": 450.836,
      "step": 815000
    },
    {
      "epoch": 8.628431990091096,
      "grad_norm": 4.242086410522461,
      "learning_rate": 6.876561507516409e-06,
      "loss": 0.6353,
      "step": 815050
    },
    {
      "epoch": 8.6289613118711,
      "grad_norm": 4.735528945922852,
      "learning_rate": 6.873914884607241e-06,
      "loss": 0.6335,
      "step": 815100
    },
    {
      "epoch": 8.629490633651102,
      "grad_norm": 4.778646945953369,
      "learning_rate": 6.8712682616980734e-06,
      "loss": 0.6297,
      "step": 815150
    },
    {
      "epoch": 8.630019955431106,
      "grad_norm": 4.735126495361328,
      "learning_rate": 6.868621638788905e-06,
      "loss": 0.6362,
      "step": 815200
    },
    {
      "epoch": 8.63054927721111,
      "grad_norm": 4.918001651763916,
      "learning_rate": 6.865975015879737e-06,
      "loss": 0.6331,
      "step": 815250
    },
    {
      "epoch": 8.631078598991113,
      "grad_norm": 4.7937822341918945,
      "learning_rate": 6.86332839297057e-06,
      "loss": 0.6314,
      "step": 815300
    },
    {
      "epoch": 8.631607920771115,
      "grad_norm": 4.867367744445801,
      "learning_rate": 6.860681770061401e-06,
      "loss": 0.6394,
      "step": 815350
    },
    {
      "epoch": 8.632137242551119,
      "grad_norm": 4.549226760864258,
      "learning_rate": 6.858035147152234e-06,
      "loss": 0.6286,
      "step": 815400
    },
    {
      "epoch": 8.632666564331123,
      "grad_norm": 4.236802577972412,
      "learning_rate": 6.855388524243065e-06,
      "loss": 0.6284,
      "step": 815450
    },
    {
      "epoch": 8.633195886111126,
      "grad_norm": 4.765754699707031,
      "learning_rate": 6.852741901333898e-06,
      "loss": 0.6329,
      "step": 815500
    },
    {
      "epoch": 8.633195886111126,
      "eval_loss": 0.38551515340805054,
      "eval_runtime": 46.8952,
      "eval_samples_per_second": 3580.963,
      "eval_steps_per_second": 447.636,
      "step": 815500
    },
    {
      "epoch": 8.633725207891128,
      "grad_norm": 4.668986797332764,
      "learning_rate": 6.85009527842473e-06,
      "loss": 0.6262,
      "step": 815550
    },
    {
      "epoch": 8.634254529671132,
      "grad_norm": 4.722980499267578,
      "learning_rate": 6.847448655515562e-06,
      "loss": 0.6332,
      "step": 815600
    },
    {
      "epoch": 8.634783851451136,
      "grad_norm": 4.586642265319824,
      "learning_rate": 6.844802032606394e-06,
      "loss": 0.6347,
      "step": 815650
    },
    {
      "epoch": 8.63531317323114,
      "grad_norm": 4.424581050872803,
      "learning_rate": 6.8421554096972265e-06,
      "loss": 0.6272,
      "step": 815700
    },
    {
      "epoch": 8.635842495011142,
      "grad_norm": 4.55262565612793,
      "learning_rate": 6.839508786788058e-06,
      "loss": 0.6294,
      "step": 815750
    },
    {
      "epoch": 8.636371816791145,
      "grad_norm": 4.409729957580566,
      "learning_rate": 6.8368621638788905e-06,
      "loss": 0.6287,
      "step": 815800
    },
    {
      "epoch": 8.63690113857115,
      "grad_norm": 4.825273036956787,
      "learning_rate": 6.834215540969723e-06,
      "loss": 0.6338,
      "step": 815850
    },
    {
      "epoch": 8.637430460351151,
      "grad_norm": 4.742934703826904,
      "learning_rate": 6.8315689180605545e-06,
      "loss": 0.6418,
      "step": 815900
    },
    {
      "epoch": 8.637959782131155,
      "grad_norm": 4.800802707672119,
      "learning_rate": 6.828922295151387e-06,
      "loss": 0.6239,
      "step": 815950
    },
    {
      "epoch": 8.638489103911159,
      "grad_norm": 4.510303497314453,
      "learning_rate": 6.826275672242219e-06,
      "loss": 0.628,
      "step": 816000
    },
    {
      "epoch": 8.638489103911159,
      "eval_loss": 0.38567620515823364,
      "eval_runtime": 46.4981,
      "eval_samples_per_second": 3611.546,
      "eval_steps_per_second": 451.459,
      "step": 816000
    },
    {
      "epoch": 8.639018425691162,
      "grad_norm": 4.423611164093018,
      "learning_rate": 6.823629049333051e-06,
      "loss": 0.6264,
      "step": 816050
    },
    {
      "epoch": 8.639547747471164,
      "grad_norm": 4.342902660369873,
      "learning_rate": 6.820982426423883e-06,
      "loss": 0.6282,
      "step": 816100
    },
    {
      "epoch": 8.640077069251168,
      "grad_norm": 4.070620059967041,
      "learning_rate": 6.818335803514715e-06,
      "loss": 0.6343,
      "step": 816150
    },
    {
      "epoch": 8.640606391031172,
      "grad_norm": 4.504936218261719,
      "learning_rate": 6.815689180605547e-06,
      "loss": 0.6288,
      "step": 816200
    },
    {
      "epoch": 8.641135712811176,
      "grad_norm": 4.990687847137451,
      "learning_rate": 6.81304255769638e-06,
      "loss": 0.6169,
      "step": 816250
    },
    {
      "epoch": 8.641665034591178,
      "grad_norm": 4.7951340675354,
      "learning_rate": 6.810395934787211e-06,
      "loss": 0.6329,
      "step": 816300
    },
    {
      "epoch": 8.642194356371181,
      "grad_norm": 4.2538957595825195,
      "learning_rate": 6.8077493118780436e-06,
      "loss": 0.6269,
      "step": 816350
    },
    {
      "epoch": 8.642723678151185,
      "grad_norm": 4.65425968170166,
      "learning_rate": 6.805102688968876e-06,
      "loss": 0.6369,
      "step": 816400
    },
    {
      "epoch": 8.643252999931189,
      "grad_norm": 4.677586555480957,
      "learning_rate": 6.8024560660597075e-06,
      "loss": 0.6309,
      "step": 816450
    },
    {
      "epoch": 8.64378232171119,
      "grad_norm": 4.521543025970459,
      "learning_rate": 6.79980944315054e-06,
      "loss": 0.6301,
      "step": 816500
    },
    {
      "epoch": 8.64378232171119,
      "eval_loss": 0.38622695207595825,
      "eval_runtime": 46.6381,
      "eval_samples_per_second": 3600.701,
      "eval_steps_per_second": 450.104,
      "step": 816500
    },
    {
      "epoch": 8.644311643491195,
      "grad_norm": 4.807117938995361,
      "learning_rate": 6.7972157526995555e-06,
      "loss": 0.6388,
      "step": 816550
    },
    {
      "epoch": 8.644840965271198,
      "grad_norm": 4.32794713973999,
      "learning_rate": 6.794569129790387e-06,
      "loss": 0.6406,
      "step": 816600
    },
    {
      "epoch": 8.6453702870512,
      "grad_norm": 4.374213695526123,
      "learning_rate": 6.7919225068812195e-06,
      "loss": 0.6235,
      "step": 816650
    },
    {
      "epoch": 8.645899608831204,
      "grad_norm": 4.679921627044678,
      "learning_rate": 6.789275883972052e-06,
      "loss": 0.6388,
      "step": 816700
    },
    {
      "epoch": 8.646428930611208,
      "grad_norm": 4.880344390869141,
      "learning_rate": 6.786629261062883e-06,
      "loss": 0.6251,
      "step": 816750
    },
    {
      "epoch": 8.646958252391212,
      "grad_norm": 5.060520648956299,
      "learning_rate": 6.783982638153716e-06,
      "loss": 0.6346,
      "step": 816800
    },
    {
      "epoch": 8.647487574171214,
      "grad_norm": 4.112850189208984,
      "learning_rate": 6.781336015244548e-06,
      "loss": 0.6306,
      "step": 816850
    },
    {
      "epoch": 8.648016895951217,
      "grad_norm": 4.424304962158203,
      "learning_rate": 6.77868939233538e-06,
      "loss": 0.6293,
      "step": 816900
    },
    {
      "epoch": 8.648546217731221,
      "grad_norm": 4.968868732452393,
      "learning_rate": 6.776042769426212e-06,
      "loss": 0.634,
      "step": 816950
    },
    {
      "epoch": 8.649075539511225,
      "grad_norm": 4.450497150421143,
      "learning_rate": 6.773396146517045e-06,
      "loss": 0.6262,
      "step": 817000
    },
    {
      "epoch": 8.649075539511225,
      "eval_loss": 0.38603901863098145,
      "eval_runtime": 46.8924,
      "eval_samples_per_second": 3581.176,
      "eval_steps_per_second": 447.663,
      "step": 817000
    },
    {
      "epoch": 8.649604861291227,
      "grad_norm": 4.8027215003967285,
      "learning_rate": 6.770749523607876e-06,
      "loss": 0.6525,
      "step": 817050
    },
    {
      "epoch": 8.65013418307123,
      "grad_norm": 4.956660270690918,
      "learning_rate": 6.7681029006987086e-06,
      "loss": 0.6394,
      "step": 817100
    },
    {
      "epoch": 8.650663504851234,
      "grad_norm": 4.48829460144043,
      "learning_rate": 6.765456277789541e-06,
      "loss": 0.6303,
      "step": 817150
    },
    {
      "epoch": 8.651192826631238,
      "grad_norm": 4.9726033210754395,
      "learning_rate": 6.7628096548803725e-06,
      "loss": 0.6348,
      "step": 817200
    },
    {
      "epoch": 8.65172214841124,
      "grad_norm": 4.277422904968262,
      "learning_rate": 6.760163031971205e-06,
      "loss": 0.6386,
      "step": 817250
    },
    {
      "epoch": 8.652251470191244,
      "grad_norm": 4.464637279510498,
      "learning_rate": 6.7575164090620365e-06,
      "loss": 0.6265,
      "step": 817300
    },
    {
      "epoch": 8.652780791971248,
      "grad_norm": 4.587246894836426,
      "learning_rate": 6.754869786152869e-06,
      "loss": 0.6432,
      "step": 817350
    },
    {
      "epoch": 8.65331011375125,
      "grad_norm": 4.46865701675415,
      "learning_rate": 6.752223163243701e-06,
      "loss": 0.6319,
      "step": 817400
    },
    {
      "epoch": 8.653839435531253,
      "grad_norm": 4.603851318359375,
      "learning_rate": 6.749576540334533e-06,
      "loss": 0.6337,
      "step": 817450
    },
    {
      "epoch": 8.654368757311257,
      "grad_norm": 4.709869861602783,
      "learning_rate": 6.746929917425365e-06,
      "loss": 0.6357,
      "step": 817500
    },
    {
      "epoch": 8.654368757311257,
      "eval_loss": 0.38596048951148987,
      "eval_runtime": 46.5783,
      "eval_samples_per_second": 3605.327,
      "eval_steps_per_second": 450.682,
      "step": 817500
    },
    {
      "epoch": 8.65489807909126,
      "grad_norm": 4.981253623962402,
      "learning_rate": 6.744283294516198e-06,
      "loss": 0.633,
      "step": 817550
    },
    {
      "epoch": 8.655427400871263,
      "grad_norm": 4.699683666229248,
      "learning_rate": 6.741636671607029e-06,
      "loss": 0.639,
      "step": 817600
    },
    {
      "epoch": 8.655956722651267,
      "grad_norm": 4.871801853179932,
      "learning_rate": 6.738990048697862e-06,
      "loss": 0.641,
      "step": 817650
    },
    {
      "epoch": 8.65648604443127,
      "grad_norm": 4.899469375610352,
      "learning_rate": 6.736343425788694e-06,
      "loss": 0.629,
      "step": 817700
    },
    {
      "epoch": 8.657015366211274,
      "grad_norm": 4.784066200256348,
      "learning_rate": 6.733696802879526e-06,
      "loss": 0.6199,
      "step": 817750
    },
    {
      "epoch": 8.657544687991276,
      "grad_norm": 4.372983455657959,
      "learning_rate": 6.731050179970358e-06,
      "loss": 0.6301,
      "step": 817800
    },
    {
      "epoch": 8.65807400977128,
      "grad_norm": 4.801101207733154,
      "learning_rate": 6.72840355706119e-06,
      "loss": 0.6266,
      "step": 817850
    },
    {
      "epoch": 8.658603331551284,
      "grad_norm": 4.4957756996154785,
      "learning_rate": 6.725756934152022e-06,
      "loss": 0.6361,
      "step": 817900
    },
    {
      "epoch": 8.659132653331287,
      "grad_norm": 4.61680269241333,
      "learning_rate": 6.723110311242854e-06,
      "loss": 0.6411,
      "step": 817950
    },
    {
      "epoch": 8.65966197511129,
      "grad_norm": 4.452892780303955,
      "learning_rate": 6.720463688333686e-06,
      "loss": 0.6339,
      "step": 818000
    },
    {
      "epoch": 8.65966197511129,
      "eval_loss": 0.38569942116737366,
      "eval_runtime": 46.5549,
      "eval_samples_per_second": 3607.14,
      "eval_steps_per_second": 450.909,
      "step": 818000
    },
    {
      "epoch": 8.660191296891293,
      "grad_norm": 4.973042011260986,
      "learning_rate": 6.717817065424518e-06,
      "loss": 0.6363,
      "step": 818050
    },
    {
      "epoch": 8.660720618671297,
      "grad_norm": 4.659643173217773,
      "learning_rate": 6.715170442515351e-06,
      "loss": 0.6122,
      "step": 818100
    },
    {
      "epoch": 8.661249940451299,
      "grad_norm": 4.611629009246826,
      "learning_rate": 6.712523819606182e-06,
      "loss": 0.6213,
      "step": 818150
    },
    {
      "epoch": 8.661779262231303,
      "grad_norm": 4.570089817047119,
      "learning_rate": 6.709877196697015e-06,
      "loss": 0.6338,
      "step": 818200
    },
    {
      "epoch": 8.662308584011306,
      "grad_norm": 4.6545257568359375,
      "learning_rate": 6.707230573787847e-06,
      "loss": 0.6346,
      "step": 818250
    },
    {
      "epoch": 8.66283790579131,
      "grad_norm": 4.521225452423096,
      "learning_rate": 6.704583950878679e-06,
      "loss": 0.6395,
      "step": 818300
    },
    {
      "epoch": 8.663367227571312,
      "grad_norm": 4.464206695556641,
      "learning_rate": 6.701937327969511e-06,
      "loss": 0.6327,
      "step": 818350
    },
    {
      "epoch": 8.663896549351316,
      "grad_norm": 4.326110363006592,
      "learning_rate": 6.6992907050603435e-06,
      "loss": 0.6246,
      "step": 818400
    },
    {
      "epoch": 8.66442587113132,
      "grad_norm": 4.498790740966797,
      "learning_rate": 6.696644082151175e-06,
      "loss": 0.6371,
      "step": 818450
    },
    {
      "epoch": 8.664955192911323,
      "grad_norm": 4.700716972351074,
      "learning_rate": 6.6939974592420075e-06,
      "loss": 0.6342,
      "step": 818500
    },
    {
      "epoch": 8.664955192911323,
      "eval_loss": 0.3858506977558136,
      "eval_runtime": 46.4819,
      "eval_samples_per_second": 3612.808,
      "eval_steps_per_second": 451.617,
      "step": 818500
    },
    {
      "epoch": 8.665484514691325,
      "grad_norm": 4.6988911628723145,
      "learning_rate": 6.691403768791023e-06,
      "loss": 0.6406,
      "step": 818550
    },
    {
      "epoch": 8.666013836471329,
      "grad_norm": 4.626895427703857,
      "learning_rate": 6.6887571458818546e-06,
      "loss": 0.634,
      "step": 818600
    },
    {
      "epoch": 8.666543158251333,
      "grad_norm": 4.613462448120117,
      "learning_rate": 6.686110522972687e-06,
      "loss": 0.6242,
      "step": 818650
    },
    {
      "epoch": 8.667072480031337,
      "grad_norm": 4.291652679443359,
      "learning_rate": 6.683463900063519e-06,
      "loss": 0.6405,
      "step": 818700
    },
    {
      "epoch": 8.667601801811339,
      "grad_norm": 4.692503452301025,
      "learning_rate": 6.680817277154351e-06,
      "loss": 0.6323,
      "step": 818750
    },
    {
      "epoch": 8.668131123591342,
      "grad_norm": 4.330719470977783,
      "learning_rate": 6.678170654245183e-06,
      "loss": 0.6358,
      "step": 818800
    },
    {
      "epoch": 8.668660445371346,
      "grad_norm": 4.480231285095215,
      "learning_rate": 6.675524031336016e-06,
      "loss": 0.6315,
      "step": 818850
    },
    {
      "epoch": 8.669189767151348,
      "grad_norm": 4.259708404541016,
      "learning_rate": 6.672877408426847e-06,
      "loss": 0.6332,
      "step": 818900
    },
    {
      "epoch": 8.669719088931352,
      "grad_norm": 4.202790260314941,
      "learning_rate": 6.67023078551768e-06,
      "loss": 0.6368,
      "step": 818950
    },
    {
      "epoch": 8.670248410711356,
      "grad_norm": 4.818950653076172,
      "learning_rate": 6.667584162608512e-06,
      "loss": 0.6291,
      "step": 819000
    },
    {
      "epoch": 8.670248410711356,
      "eval_loss": 0.38560691475868225,
      "eval_runtime": 46.4924,
      "eval_samples_per_second": 3611.988,
      "eval_steps_per_second": 451.515,
      "step": 819000
    },
    {
      "epoch": 8.67077773249136,
      "grad_norm": 4.538512706756592,
      "learning_rate": 6.664937539699344e-06,
      "loss": 0.6314,
      "step": 819050
    },
    {
      "epoch": 8.671307054271361,
      "grad_norm": 4.329655647277832,
      "learning_rate": 6.662290916790176e-06,
      "loss": 0.6371,
      "step": 819100
    },
    {
      "epoch": 8.671836376051365,
      "grad_norm": 4.782247066497803,
      "learning_rate": 6.659644293881008e-06,
      "loss": 0.6196,
      "step": 819150
    },
    {
      "epoch": 8.672365697831369,
      "grad_norm": 4.923791408538818,
      "learning_rate": 6.65699767097184e-06,
      "loss": 0.6253,
      "step": 819200
    },
    {
      "epoch": 8.672895019611373,
      "grad_norm": 4.379114151000977,
      "learning_rate": 6.6543510480626725e-06,
      "loss": 0.6421,
      "step": 819250
    },
    {
      "epoch": 8.673424341391375,
      "grad_norm": 5.114243030548096,
      "learning_rate": 6.651704425153504e-06,
      "loss": 0.6325,
      "step": 819300
    },
    {
      "epoch": 8.673953663171378,
      "grad_norm": 4.882009506225586,
      "learning_rate": 6.6490578022443364e-06,
      "loss": 0.6384,
      "step": 819350
    },
    {
      "epoch": 8.674482984951382,
      "grad_norm": 4.655368328094482,
      "learning_rate": 6.646411179335169e-06,
      "loss": 0.6255,
      "step": 819400
    },
    {
      "epoch": 8.675012306731386,
      "grad_norm": 4.9586567878723145,
      "learning_rate": 6.643764556426e-06,
      "loss": 0.6431,
      "step": 819450
    },
    {
      "epoch": 8.675541628511388,
      "grad_norm": 4.4158711433410645,
      "learning_rate": 6.641117933516833e-06,
      "loss": 0.636,
      "step": 819500
    },
    {
      "epoch": 8.675541628511388,
      "eval_loss": 0.3853274881839752,
      "eval_runtime": 46.5994,
      "eval_samples_per_second": 3603.697,
      "eval_steps_per_second": 450.478,
      "step": 819500
    },
    {
      "epoch": 8.676070950291392,
      "grad_norm": 4.716559886932373,
      "learning_rate": 6.638471310607665e-06,
      "loss": 0.6341,
      "step": 819550
    },
    {
      "epoch": 8.676600272071395,
      "grad_norm": 4.48531436920166,
      "learning_rate": 6.635824687698497e-06,
      "loss": 0.6313,
      "step": 819600
    },
    {
      "epoch": 8.677129593851397,
      "grad_norm": 4.534587860107422,
      "learning_rate": 6.633178064789329e-06,
      "loss": 0.6257,
      "step": 819650
    },
    {
      "epoch": 8.677658915631401,
      "grad_norm": 4.764215469360352,
      "learning_rate": 6.6305314418801616e-06,
      "loss": 0.6323,
      "step": 819700
    },
    {
      "epoch": 8.678188237411405,
      "grad_norm": 4.779242038726807,
      "learning_rate": 6.627884818970993e-06,
      "loss": 0.6409,
      "step": 819750
    },
    {
      "epoch": 8.678717559191409,
      "grad_norm": 4.974888324737549,
      "learning_rate": 6.6252381960618255e-06,
      "loss": 0.6265,
      "step": 819800
    },
    {
      "epoch": 8.67924688097141,
      "grad_norm": 4.648018836975098,
      "learning_rate": 6.622591573152657e-06,
      "loss": 0.6313,
      "step": 819850
    },
    {
      "epoch": 8.679776202751414,
      "grad_norm": 4.995319843292236,
      "learning_rate": 6.6199449502434895e-06,
      "loss": 0.6357,
      "step": 819900
    },
    {
      "epoch": 8.680305524531418,
      "grad_norm": 4.430054664611816,
      "learning_rate": 6.617298327334322e-06,
      "loss": 0.6523,
      "step": 819950
    },
    {
      "epoch": 8.680834846311422,
      "grad_norm": 4.422478199005127,
      "learning_rate": 6.6146517044251535e-06,
      "loss": 0.632,
      "step": 820000
    },
    {
      "epoch": 8.680834846311422,
      "eval_loss": 0.3861154615879059,
      "eval_runtime": 46.5476,
      "eval_samples_per_second": 3607.704,
      "eval_steps_per_second": 450.979,
      "step": 820000
    },
    {
      "epoch": 8.681364168091424,
      "grad_norm": 4.487397193908691,
      "learning_rate": 6.612005081515986e-06,
      "loss": 0.6255,
      "step": 820050
    },
    {
      "epoch": 8.681893489871428,
      "grad_norm": 4.63690185546875,
      "learning_rate": 6.609358458606818e-06,
      "loss": 0.6326,
      "step": 820100
    },
    {
      "epoch": 8.682422811651431,
      "grad_norm": 4.185854911804199,
      "learning_rate": 6.60671183569765e-06,
      "loss": 0.6316,
      "step": 820150
    },
    {
      "epoch": 8.682952133431435,
      "grad_norm": 4.727741241455078,
      "learning_rate": 6.604065212788482e-06,
      "loss": 0.6358,
      "step": 820200
    },
    {
      "epoch": 8.683481455211437,
      "grad_norm": 5.034658432006836,
      "learning_rate": 6.601418589879315e-06,
      "loss": 0.6342,
      "step": 820250
    },
    {
      "epoch": 8.68401077699144,
      "grad_norm": 4.86704683303833,
      "learning_rate": 6.598771966970146e-06,
      "loss": 0.6233,
      "step": 820300
    },
    {
      "epoch": 8.684540098771445,
      "grad_norm": 4.852062225341797,
      "learning_rate": 6.596125344060979e-06,
      "loss": 0.6325,
      "step": 820350
    },
    {
      "epoch": 8.685069420551448,
      "grad_norm": 4.449084758758545,
      "learning_rate": 6.593478721151811e-06,
      "loss": 0.6378,
      "step": 820400
    },
    {
      "epoch": 8.68559874233145,
      "grad_norm": 5.0000786781311035,
      "learning_rate": 6.590832098242643e-06,
      "loss": 0.6158,
      "step": 820450
    },
    {
      "epoch": 8.686128064111454,
      "grad_norm": 4.447092056274414,
      "learning_rate": 6.588185475333475e-06,
      "loss": 0.6346,
      "step": 820500
    },
    {
      "epoch": 8.686128064111454,
      "eval_loss": 0.3849177658557892,
      "eval_runtime": 46.501,
      "eval_samples_per_second": 3611.319,
      "eval_steps_per_second": 451.431,
      "step": 820500
    },
    {
      "epoch": 8.686657385891458,
      "grad_norm": 4.303225040435791,
      "learning_rate": 6.5855917848824905e-06,
      "loss": 0.6355,
      "step": 820550
    },
    {
      "epoch": 8.68718670767146,
      "grad_norm": 4.365594387054443,
      "learning_rate": 6.582945161973322e-06,
      "loss": 0.6309,
      "step": 820600
    },
    {
      "epoch": 8.687716029451463,
      "grad_norm": 4.44064474105835,
      "learning_rate": 6.5802985390641545e-06,
      "loss": 0.6167,
      "step": 820650
    },
    {
      "epoch": 8.688245351231467,
      "grad_norm": 4.233484745025635,
      "learning_rate": 6.577651916154987e-06,
      "loss": 0.6304,
      "step": 820700
    },
    {
      "epoch": 8.688774673011471,
      "grad_norm": 4.8219218254089355,
      "learning_rate": 6.5750052932458185e-06,
      "loss": 0.6282,
      "step": 820750
    },
    {
      "epoch": 8.689303994791473,
      "grad_norm": 4.463217258453369,
      "learning_rate": 6.572358670336651e-06,
      "loss": 0.6357,
      "step": 820800
    },
    {
      "epoch": 8.689833316571477,
      "grad_norm": 4.525487422943115,
      "learning_rate": 6.569712047427483e-06,
      "loss": 0.6418,
      "step": 820850
    },
    {
      "epoch": 8.69036263835148,
      "grad_norm": 4.456234931945801,
      "learning_rate": 6.567065424518315e-06,
      "loss": 0.6291,
      "step": 820900
    },
    {
      "epoch": 8.690891960131484,
      "grad_norm": 5.11622428894043,
      "learning_rate": 6.564418801609147e-06,
      "loss": 0.6338,
      "step": 820950
    },
    {
      "epoch": 8.691421281911486,
      "grad_norm": 4.720433712005615,
      "learning_rate": 6.561772178699979e-06,
      "loss": 0.6311,
      "step": 821000
    },
    {
      "epoch": 8.691421281911486,
      "eval_loss": 0.38473790884017944,
      "eval_runtime": 46.7004,
      "eval_samples_per_second": 3595.897,
      "eval_steps_per_second": 449.503,
      "step": 821000
    },
    {
      "epoch": 8.69195060369149,
      "grad_norm": 4.631674289703369,
      "learning_rate": 6.559125555790811e-06,
      "loss": 0.6367,
      "step": 821050
    },
    {
      "epoch": 8.692479925471494,
      "grad_norm": 4.425400733947754,
      "learning_rate": 6.556478932881644e-06,
      "loss": 0.6247,
      "step": 821100
    },
    {
      "epoch": 8.693009247251497,
      "grad_norm": 4.5298848152160645,
      "learning_rate": 6.553832309972475e-06,
      "loss": 0.6309,
      "step": 821150
    },
    {
      "epoch": 8.6935385690315,
      "grad_norm": 4.728200912475586,
      "learning_rate": 6.551185687063308e-06,
      "loss": 0.6361,
      "step": 821200
    },
    {
      "epoch": 8.694067890811503,
      "grad_norm": 4.835037708282471,
      "learning_rate": 6.54853906415414e-06,
      "loss": 0.6301,
      "step": 821250
    },
    {
      "epoch": 8.694597212591507,
      "grad_norm": 4.926015853881836,
      "learning_rate": 6.5458924412449715e-06,
      "loss": 0.6199,
      "step": 821300
    },
    {
      "epoch": 8.695126534371509,
      "grad_norm": 4.160984516143799,
      "learning_rate": 6.543245818335804e-06,
      "loss": 0.6249,
      "step": 821350
    },
    {
      "epoch": 8.695655856151513,
      "grad_norm": 4.614178657531738,
      "learning_rate": 6.540599195426636e-06,
      "loss": 0.6314,
      "step": 821400
    },
    {
      "epoch": 8.696185177931516,
      "grad_norm": 4.06198263168335,
      "learning_rate": 6.537952572517468e-06,
      "loss": 0.6322,
      "step": 821450
    },
    {
      "epoch": 8.69671449971152,
      "grad_norm": 4.138128280639648,
      "learning_rate": 6.5353059496083e-06,
      "loss": 0.6354,
      "step": 821500
    },
    {
      "epoch": 8.69671449971152,
      "eval_loss": 0.38471901416778564,
      "eval_runtime": 46.5007,
      "eval_samples_per_second": 3611.341,
      "eval_steps_per_second": 451.434,
      "step": 821500
    },
    {
      "epoch": 8.697243821491522,
      "grad_norm": 4.713482856750488,
      "learning_rate": 6.532659326699133e-06,
      "loss": 0.6296,
      "step": 821550
    },
    {
      "epoch": 8.697773143271526,
      "grad_norm": 4.609667778015137,
      "learning_rate": 6.530012703789964e-06,
      "loss": 0.6526,
      "step": 821600
    },
    {
      "epoch": 8.69830246505153,
      "grad_norm": 4.47674036026001,
      "learning_rate": 6.527366080880797e-06,
      "loss": 0.6332,
      "step": 821650
    },
    {
      "epoch": 8.698831786831533,
      "grad_norm": 4.424927234649658,
      "learning_rate": 6.524719457971628e-06,
      "loss": 0.6318,
      "step": 821700
    },
    {
      "epoch": 8.699361108611535,
      "grad_norm": 5.078980922698975,
      "learning_rate": 6.522072835062461e-06,
      "loss": 0.6366,
      "step": 821750
    },
    {
      "epoch": 8.69989043039154,
      "grad_norm": 4.371811389923096,
      "learning_rate": 6.519426212153293e-06,
      "loss": 0.6303,
      "step": 821800
    },
    {
      "epoch": 8.700419752171543,
      "grad_norm": 4.439877033233643,
      "learning_rate": 6.516779589244125e-06,
      "loss": 0.6292,
      "step": 821850
    },
    {
      "epoch": 8.700949073951547,
      "grad_norm": 4.934816837310791,
      "learning_rate": 6.514132966334957e-06,
      "loss": 0.6322,
      "step": 821900
    },
    {
      "epoch": 8.701478395731549,
      "grad_norm": 4.491267204284668,
      "learning_rate": 6.5114863434257894e-06,
      "loss": 0.6357,
      "step": 821950
    },
    {
      "epoch": 8.702007717511552,
      "grad_norm": 4.479695796966553,
      "learning_rate": 6.508839720516621e-06,
      "loss": 0.6379,
      "step": 822000
    },
    {
      "epoch": 8.702007717511552,
      "eval_loss": 0.38498252630233765,
      "eval_runtime": 46.5675,
      "eval_samples_per_second": 3606.166,
      "eval_steps_per_second": 450.787,
      "step": 822000
    },
    {
      "epoch": 8.702537039291556,
      "grad_norm": 4.548392295837402,
      "learning_rate": 6.506193097607453e-06,
      "loss": 0.624,
      "step": 822050
    },
    {
      "epoch": 8.70306636107156,
      "grad_norm": 4.305271625518799,
      "learning_rate": 6.503546474698286e-06,
      "loss": 0.6334,
      "step": 822100
    },
    {
      "epoch": 8.703595682851562,
      "grad_norm": 4.416243553161621,
      "learning_rate": 6.500899851789117e-06,
      "loss": 0.6226,
      "step": 822150
    },
    {
      "epoch": 8.704125004631566,
      "grad_norm": 4.6756272315979,
      "learning_rate": 6.49825322887995e-06,
      "loss": 0.6256,
      "step": 822200
    },
    {
      "epoch": 8.70465432641157,
      "grad_norm": 4.676658630371094,
      "learning_rate": 6.495606605970782e-06,
      "loss": 0.6317,
      "step": 822250
    },
    {
      "epoch": 8.705183648191571,
      "grad_norm": 4.538527488708496,
      "learning_rate": 6.492959983061614e-06,
      "loss": 0.6389,
      "step": 822300
    },
    {
      "epoch": 8.705712969971575,
      "grad_norm": 4.5808939933776855,
      "learning_rate": 6.490313360152446e-06,
      "loss": 0.619,
      "step": 822350
    },
    {
      "epoch": 8.706242291751579,
      "grad_norm": 4.775719165802002,
      "learning_rate": 6.487666737243278e-06,
      "loss": 0.628,
      "step": 822400
    },
    {
      "epoch": 8.706771613531583,
      "grad_norm": 4.541717052459717,
      "learning_rate": 6.48502011433411e-06,
      "loss": 0.6187,
      "step": 822450
    },
    {
      "epoch": 8.707300935311585,
      "grad_norm": 4.781984329223633,
      "learning_rate": 6.4823734914249425e-06,
      "loss": 0.6339,
      "step": 822500
    },
    {
      "epoch": 8.707300935311585,
      "eval_loss": 0.38522762060165405,
      "eval_runtime": 46.5018,
      "eval_samples_per_second": 3611.255,
      "eval_steps_per_second": 451.423,
      "step": 822500
    },
    {
      "epoch": 8.707830257091588,
      "grad_norm": 4.470252990722656,
      "learning_rate": 6.479726868515774e-06,
      "loss": 0.6343,
      "step": 822550
    },
    {
      "epoch": 8.708359578871592,
      "grad_norm": 4.326685905456543,
      "learning_rate": 6.47713317806479e-06,
      "loss": 0.6353,
      "step": 822600
    },
    {
      "epoch": 8.708888900651596,
      "grad_norm": 4.7482829093933105,
      "learning_rate": 6.474486555155622e-06,
      "loss": 0.6217,
      "step": 822650
    },
    {
      "epoch": 8.709418222431598,
      "grad_norm": 4.727681636810303,
      "learning_rate": 6.4718399322464544e-06,
      "loss": 0.6388,
      "step": 822700
    },
    {
      "epoch": 8.709947544211602,
      "grad_norm": 4.623438835144043,
      "learning_rate": 6.469193309337286e-06,
      "loss": 0.6209,
      "step": 822750
    },
    {
      "epoch": 8.710476865991605,
      "grad_norm": 4.781137466430664,
      "learning_rate": 6.466546686428118e-06,
      "loss": 0.6227,
      "step": 822800
    },
    {
      "epoch": 8.71100618777161,
      "grad_norm": 4.763431072235107,
      "learning_rate": 6.46390006351895e-06,
      "loss": 0.6308,
      "step": 822850
    },
    {
      "epoch": 8.711535509551611,
      "grad_norm": 4.799968242645264,
      "learning_rate": 6.461253440609782e-06,
      "loss": 0.6348,
      "step": 822900
    },
    {
      "epoch": 8.712064831331615,
      "grad_norm": 4.40158224105835,
      "learning_rate": 6.458606817700615e-06,
      "loss": 0.6299,
      "step": 822950
    },
    {
      "epoch": 8.712594153111619,
      "grad_norm": 4.646602630615234,
      "learning_rate": 6.455960194791446e-06,
      "loss": 0.6218,
      "step": 823000
    },
    {
      "epoch": 8.712594153111619,
      "eval_loss": 0.38479581475257874,
      "eval_runtime": 46.474,
      "eval_samples_per_second": 3613.419,
      "eval_steps_per_second": 451.694,
      "step": 823000
    },
    {
      "epoch": 8.71312347489162,
      "grad_norm": 4.5080389976501465,
      "learning_rate": 6.453313571882279e-06,
      "loss": 0.634,
      "step": 823050
    },
    {
      "epoch": 8.713652796671624,
      "grad_norm": 5.064999580383301,
      "learning_rate": 6.450666948973111e-06,
      "loss": 0.6297,
      "step": 823100
    },
    {
      "epoch": 8.714182118451628,
      "grad_norm": 4.577924728393555,
      "learning_rate": 6.448020326063943e-06,
      "loss": 0.6354,
      "step": 823150
    },
    {
      "epoch": 8.714711440231632,
      "grad_norm": 4.782574653625488,
      "learning_rate": 6.445373703154775e-06,
      "loss": 0.6303,
      "step": 823200
    },
    {
      "epoch": 8.715240762011634,
      "grad_norm": 4.71185302734375,
      "learning_rate": 6.4427270802456075e-06,
      "loss": 0.6359,
      "step": 823250
    },
    {
      "epoch": 8.715770083791638,
      "grad_norm": 4.821152210235596,
      "learning_rate": 6.440080457336439e-06,
      "loss": 0.6177,
      "step": 823300
    },
    {
      "epoch": 8.716299405571641,
      "grad_norm": 4.776628017425537,
      "learning_rate": 6.4374338344272715e-06,
      "loss": 0.6355,
      "step": 823350
    },
    {
      "epoch": 8.716828727351645,
      "grad_norm": 4.646042823791504,
      "learning_rate": 6.434787211518104e-06,
      "loss": 0.6338,
      "step": 823400
    },
    {
      "epoch": 8.717358049131647,
      "grad_norm": 4.48245906829834,
      "learning_rate": 6.4321405886089354e-06,
      "loss": 0.6375,
      "step": 823450
    },
    {
      "epoch": 8.717887370911651,
      "grad_norm": 4.724505424499512,
      "learning_rate": 6.429493965699768e-06,
      "loss": 0.6204,
      "step": 823500
    },
    {
      "epoch": 8.717887370911651,
      "eval_loss": 0.38430291414260864,
      "eval_runtime": 46.5557,
      "eval_samples_per_second": 3607.074,
      "eval_steps_per_second": 450.9,
      "step": 823500
    },
    {
      "epoch": 8.718416692691655,
      "grad_norm": 4.909996509552002,
      "learning_rate": 6.426847342790599e-06,
      "loss": 0.6375,
      "step": 823550
    },
    {
      "epoch": 8.718946014471658,
      "grad_norm": 4.3718037605285645,
      "learning_rate": 6.424200719881432e-06,
      "loss": 0.627,
      "step": 823600
    },
    {
      "epoch": 8.71947533625166,
      "grad_norm": 4.496548652648926,
      "learning_rate": 6.421554096972264e-06,
      "loss": 0.6394,
      "step": 823650
    },
    {
      "epoch": 8.720004658031664,
      "grad_norm": 4.328454971313477,
      "learning_rate": 6.418907474063096e-06,
      "loss": 0.6244,
      "step": 823700
    },
    {
      "epoch": 8.720533979811668,
      "grad_norm": 4.526684284210205,
      "learning_rate": 6.416260851153928e-06,
      "loss": 0.6323,
      "step": 823750
    },
    {
      "epoch": 8.72106330159167,
      "grad_norm": 4.5347137451171875,
      "learning_rate": 6.413614228244761e-06,
      "loss": 0.6408,
      "step": 823800
    },
    {
      "epoch": 8.721592623371674,
      "grad_norm": 4.292174339294434,
      "learning_rate": 6.410967605335592e-06,
      "loss": 0.6253,
      "step": 823850
    },
    {
      "epoch": 8.722121945151677,
      "grad_norm": 4.642070770263672,
      "learning_rate": 6.4083209824264246e-06,
      "loss": 0.6216,
      "step": 823900
    },
    {
      "epoch": 8.722651266931681,
      "grad_norm": 4.892261505126953,
      "learning_rate": 6.405674359517257e-06,
      "loss": 0.64,
      "step": 823950
    },
    {
      "epoch": 8.723180588711683,
      "grad_norm": 3.877358913421631,
      "learning_rate": 6.4030277366080885e-06,
      "loss": 0.6309,
      "step": 824000
    },
    {
      "epoch": 8.723180588711683,
      "eval_loss": 0.38474762439727783,
      "eval_runtime": 46.5417,
      "eval_samples_per_second": 3608.162,
      "eval_steps_per_second": 451.036,
      "step": 824000
    },
    {
      "epoch": 8.723709910491687,
      "grad_norm": 5.083712577819824,
      "learning_rate": 6.400381113698921e-06,
      "loss": 0.6296,
      "step": 824050
    },
    {
      "epoch": 8.72423923227169,
      "grad_norm": 4.5572590827941895,
      "learning_rate": 6.397734490789753e-06,
      "loss": 0.6241,
      "step": 824100
    },
    {
      "epoch": 8.724768554051694,
      "grad_norm": 4.576549530029297,
      "learning_rate": 6.395087867880585e-06,
      "loss": 0.6241,
      "step": 824150
    },
    {
      "epoch": 8.725297875831696,
      "grad_norm": 5.06259298324585,
      "learning_rate": 6.392441244971417e-06,
      "loss": 0.6422,
      "step": 824200
    },
    {
      "epoch": 8.7258271976117,
      "grad_norm": 4.846489906311035,
      "learning_rate": 6.389794622062249e-06,
      "loss": 0.6324,
      "step": 824250
    },
    {
      "epoch": 8.726356519391704,
      "grad_norm": 4.395627498626709,
      "learning_rate": 6.387147999153081e-06,
      "loss": 0.6261,
      "step": 824300
    },
    {
      "epoch": 8.726885841171708,
      "grad_norm": 4.494261264801025,
      "learning_rate": 6.384501376243914e-06,
      "loss": 0.621,
      "step": 824350
    },
    {
      "epoch": 8.72741516295171,
      "grad_norm": 4.714911937713623,
      "learning_rate": 6.381854753334745e-06,
      "loss": 0.6296,
      "step": 824400
    },
    {
      "epoch": 8.727944484731713,
      "grad_norm": 4.865659713745117,
      "learning_rate": 6.379208130425578e-06,
      "loss": 0.6343,
      "step": 824450
    },
    {
      "epoch": 8.728473806511717,
      "grad_norm": 4.981709003448486,
      "learning_rate": 6.37656150751641e-06,
      "loss": 0.624,
      "step": 824500
    },
    {
      "epoch": 8.728473806511717,
      "eval_loss": 0.3848990499973297,
      "eval_runtime": 46.5216,
      "eval_samples_per_second": 3609.722,
      "eval_steps_per_second": 451.231,
      "step": 824500
    },
    {
      "epoch": 8.729003128291719,
      "grad_norm": 4.52154541015625,
      "learning_rate": 6.373914884607242e-06,
      "loss": 0.6233,
      "step": 824550
    },
    {
      "epoch": 8.729532450071723,
      "grad_norm": 4.602921009063721,
      "learning_rate": 6.371321194156257e-06,
      "loss": 0.6398,
      "step": 824600
    },
    {
      "epoch": 8.730061771851727,
      "grad_norm": 4.703742980957031,
      "learning_rate": 6.3686745712470896e-06,
      "loss": 0.6293,
      "step": 824650
    },
    {
      "epoch": 8.73059109363173,
      "grad_norm": 4.394862174987793,
      "learning_rate": 6.366027948337921e-06,
      "loss": 0.6296,
      "step": 824700
    },
    {
      "epoch": 8.731120415411732,
      "grad_norm": 4.847177982330322,
      "learning_rate": 6.3633813254287535e-06,
      "loss": 0.6271,
      "step": 824750
    },
    {
      "epoch": 8.731649737191736,
      "grad_norm": 4.857093334197998,
      "learning_rate": 6.360787634977769e-06,
      "loss": 0.6355,
      "step": 824800
    },
    {
      "epoch": 8.73217905897174,
      "grad_norm": 4.4107441902160645,
      "learning_rate": 6.3581410120686015e-06,
      "loss": 0.6276,
      "step": 824850
    },
    {
      "epoch": 8.732708380751744,
      "grad_norm": 4.844119071960449,
      "learning_rate": 6.355494389159433e-06,
      "loss": 0.6269,
      "step": 824900
    },
    {
      "epoch": 8.733237702531746,
      "grad_norm": 4.457167625427246,
      "learning_rate": 6.3528477662502654e-06,
      "loss": 0.6348,
      "step": 824950
    },
    {
      "epoch": 8.73376702431175,
      "grad_norm": 4.685156345367432,
      "learning_rate": 6.350201143341097e-06,
      "loss": 0.6368,
      "step": 825000
    },
    {
      "epoch": 8.73376702431175,
      "eval_loss": 0.38445526361465454,
      "eval_runtime": 46.5737,
      "eval_samples_per_second": 3605.685,
      "eval_steps_per_second": 450.727,
      "step": 825000
    },
    {
      "epoch": 8.734296346091753,
      "grad_norm": 4.533973693847656,
      "learning_rate": 6.347554520431929e-06,
      "loss": 0.6479,
      "step": 825050
    },
    {
      "epoch": 8.734825667871757,
      "grad_norm": 4.277439117431641,
      "learning_rate": 6.344907897522762e-06,
      "loss": 0.6266,
      "step": 825100
    },
    {
      "epoch": 8.735354989651759,
      "grad_norm": 4.683048725128174,
      "learning_rate": 6.342261274613593e-06,
      "loss": 0.624,
      "step": 825150
    },
    {
      "epoch": 8.735884311431763,
      "grad_norm": 4.604698181152344,
      "learning_rate": 6.339614651704426e-06,
      "loss": 0.629,
      "step": 825200
    },
    {
      "epoch": 8.736413633211766,
      "grad_norm": 4.771957874298096,
      "learning_rate": 6.336968028795258e-06,
      "loss": 0.6353,
      "step": 825250
    },
    {
      "epoch": 8.736942954991768,
      "grad_norm": 4.513509750366211,
      "learning_rate": 6.33432140588609e-06,
      "loss": 0.6246,
      "step": 825300
    },
    {
      "epoch": 8.737472276771772,
      "grad_norm": 4.992615222930908,
      "learning_rate": 6.331674782976922e-06,
      "loss": 0.629,
      "step": 825350
    },
    {
      "epoch": 8.738001598551776,
      "grad_norm": 4.94865608215332,
      "learning_rate": 6.3290281600677546e-06,
      "loss": 0.6352,
      "step": 825400
    },
    {
      "epoch": 8.73853092033178,
      "grad_norm": 4.6395344734191895,
      "learning_rate": 6.326381537158586e-06,
      "loss": 0.6263,
      "step": 825450
    },
    {
      "epoch": 8.739060242111782,
      "grad_norm": 4.5378007888793945,
      "learning_rate": 6.3237349142494185e-06,
      "loss": 0.641,
      "step": 825500
    },
    {
      "epoch": 8.739060242111782,
      "eval_loss": 0.3842770755290985,
      "eval_runtime": 46.5257,
      "eval_samples_per_second": 3609.406,
      "eval_steps_per_second": 451.192,
      "step": 825500
    },
    {
      "epoch": 8.739589563891785,
      "grad_norm": 4.65386962890625,
      "learning_rate": 6.321088291340251e-06,
      "loss": 0.6367,
      "step": 825550
    },
    {
      "epoch": 8.740118885671789,
      "grad_norm": 4.867969989776611,
      "learning_rate": 6.3184416684310825e-06,
      "loss": 0.6325,
      "step": 825600
    },
    {
      "epoch": 8.740648207451793,
      "grad_norm": 4.934625148773193,
      "learning_rate": 6.315795045521915e-06,
      "loss": 0.6222,
      "step": 825650
    },
    {
      "epoch": 8.741177529231795,
      "grad_norm": 4.811688423156738,
      "learning_rate": 6.3131484226127464e-06,
      "loss": 0.6258,
      "step": 825700
    },
    {
      "epoch": 8.741706851011799,
      "grad_norm": 4.336426734924316,
      "learning_rate": 6.310501799703579e-06,
      "loss": 0.6209,
      "step": 825750
    },
    {
      "epoch": 8.742236172791802,
      "grad_norm": 4.27506160736084,
      "learning_rate": 6.307855176794411e-06,
      "loss": 0.6326,
      "step": 825800
    },
    {
      "epoch": 8.742765494571806,
      "grad_norm": 5.041553497314453,
      "learning_rate": 6.305208553885243e-06,
      "loss": 0.6357,
      "step": 825850
    },
    {
      "epoch": 8.743294816351808,
      "grad_norm": 4.215530872344971,
      "learning_rate": 6.302561930976075e-06,
      "loss": 0.6352,
      "step": 825900
    },
    {
      "epoch": 8.743824138131812,
      "grad_norm": 4.7826247215271,
      "learning_rate": 6.299915308066908e-06,
      "loss": 0.6399,
      "step": 825950
    },
    {
      "epoch": 8.744353459911816,
      "grad_norm": 4.847812175750732,
      "learning_rate": 6.297268685157739e-06,
      "loss": 0.6313,
      "step": 826000
    },
    {
      "epoch": 8.744353459911816,
      "eval_loss": 0.3850288689136505,
      "eval_runtime": 46.6002,
      "eval_samples_per_second": 3603.632,
      "eval_steps_per_second": 450.47,
      "step": 826000
    },
    {
      "epoch": 8.744882781691818,
      "grad_norm": 4.882928848266602,
      "learning_rate": 6.294622062248572e-06,
      "loss": 0.6357,
      "step": 826050
    },
    {
      "epoch": 8.745412103471821,
      "grad_norm": 4.791349411010742,
      "learning_rate": 6.291975439339404e-06,
      "loss": 0.6243,
      "step": 826100
    },
    {
      "epoch": 8.745941425251825,
      "grad_norm": 4.658479690551758,
      "learning_rate": 6.2893288164302356e-06,
      "loss": 0.6329,
      "step": 826150
    },
    {
      "epoch": 8.746470747031829,
      "grad_norm": 4.209475040435791,
      "learning_rate": 6.286682193521068e-06,
      "loss": 0.6291,
      "step": 826200
    },
    {
      "epoch": 8.74700006881183,
      "grad_norm": 4.27936315536499,
      "learning_rate": 6.2840355706119e-06,
      "loss": 0.617,
      "step": 826250
    },
    {
      "epoch": 8.747529390591835,
      "grad_norm": 4.775017738342285,
      "learning_rate": 6.281388947702732e-06,
      "loss": 0.6381,
      "step": 826300
    },
    {
      "epoch": 8.748058712371838,
      "grad_norm": 4.765499591827393,
      "learning_rate": 6.278742324793564e-06,
      "loss": 0.629,
      "step": 826350
    },
    {
      "epoch": 8.748588034151842,
      "grad_norm": 4.144872188568115,
      "learning_rate": 6.276095701884397e-06,
      "loss": 0.626,
      "step": 826400
    },
    {
      "epoch": 8.749117355931844,
      "grad_norm": 4.828563690185547,
      "learning_rate": 6.273449078975228e-06,
      "loss": 0.6187,
      "step": 826450
    },
    {
      "epoch": 8.749646677711848,
      "grad_norm": 4.278113842010498,
      "learning_rate": 6.270802456066061e-06,
      "loss": 0.632,
      "step": 826500
    },
    {
      "epoch": 8.749646677711848,
      "eval_loss": 0.3840515911579132,
      "eval_runtime": 46.6185,
      "eval_samples_per_second": 3602.217,
      "eval_steps_per_second": 450.293,
      "step": 826500
    },
    {
      "epoch": 8.750175999491852,
      "grad_norm": 4.475388526916504,
      "learning_rate": 6.268155833156892e-06,
      "loss": 0.627,
      "step": 826550
    },
    {
      "epoch": 8.750705321271855,
      "grad_norm": 4.696277618408203,
      "learning_rate": 6.265509210247725e-06,
      "loss": 0.6388,
      "step": 826600
    },
    {
      "epoch": 8.751234643051857,
      "grad_norm": 4.729340553283691,
      "learning_rate": 6.262862587338557e-06,
      "loss": 0.6334,
      "step": 826650
    },
    {
      "epoch": 8.751763964831861,
      "grad_norm": 4.6769866943359375,
      "learning_rate": 6.260215964429389e-06,
      "loss": 0.6386,
      "step": 826700
    },
    {
      "epoch": 8.752293286611865,
      "grad_norm": 4.751238822937012,
      "learning_rate": 6.257569341520221e-06,
      "loss": 0.6243,
      "step": 826750
    },
    {
      "epoch": 8.752822608391867,
      "grad_norm": 4.887567043304443,
      "learning_rate": 6.2549227186110534e-06,
      "loss": 0.6345,
      "step": 826800
    },
    {
      "epoch": 8.75335193017187,
      "grad_norm": 4.450830936431885,
      "learning_rate": 6.252276095701885e-06,
      "loss": 0.6242,
      "step": 826850
    },
    {
      "epoch": 8.753881251951874,
      "grad_norm": 4.249283313751221,
      "learning_rate": 6.2496294727927166e-06,
      "loss": 0.6396,
      "step": 826900
    },
    {
      "epoch": 8.754410573731878,
      "grad_norm": 4.65273380279541,
      "learning_rate": 6.246982849883549e-06,
      "loss": 0.6325,
      "step": 826950
    },
    {
      "epoch": 8.75493989551188,
      "grad_norm": 4.5416364669799805,
      "learning_rate": 6.2443362269743805e-06,
      "loss": 0.6215,
      "step": 827000
    },
    {
      "epoch": 8.75493989551188,
      "eval_loss": 0.3840973377227783,
      "eval_runtime": 46.5512,
      "eval_samples_per_second": 3607.429,
      "eval_steps_per_second": 450.945,
      "step": 827000
    },
    {
      "epoch": 8.755469217291884,
      "grad_norm": 5.0057759284973145,
      "learning_rate": 6.241689604065213e-06,
      "loss": 0.6197,
      "step": 827050
    },
    {
      "epoch": 8.755998539071888,
      "grad_norm": 5.021080017089844,
      "learning_rate": 6.239042981156045e-06,
      "loss": 0.627,
      "step": 827100
    },
    {
      "epoch": 8.756527860851891,
      "grad_norm": 4.368756294250488,
      "learning_rate": 6.236396358246877e-06,
      "loss": 0.6375,
      "step": 827150
    },
    {
      "epoch": 8.757057182631893,
      "grad_norm": 4.868619441986084,
      "learning_rate": 6.233749735337709e-06,
      "loss": 0.633,
      "step": 827200
    },
    {
      "epoch": 8.757586504411897,
      "grad_norm": 4.407767295837402,
      "learning_rate": 6.231103112428542e-06,
      "loss": 0.6307,
      "step": 827250
    },
    {
      "epoch": 8.7581158261919,
      "grad_norm": 4.634040355682373,
      "learning_rate": 6.228456489519373e-06,
      "loss": 0.6349,
      "step": 827300
    },
    {
      "epoch": 8.758645147971905,
      "grad_norm": 4.658929347991943,
      "learning_rate": 6.225809866610206e-06,
      "loss": 0.6333,
      "step": 827350
    },
    {
      "epoch": 8.759174469751906,
      "grad_norm": 4.865865707397461,
      "learning_rate": 6.223163243701038e-06,
      "loss": 0.6367,
      "step": 827400
    },
    {
      "epoch": 8.75970379153191,
      "grad_norm": 4.865902900695801,
      "learning_rate": 6.22051662079187e-06,
      "loss": 0.6225,
      "step": 827450
    },
    {
      "epoch": 8.760233113311914,
      "grad_norm": 4.212939739227295,
      "learning_rate": 6.217869997882702e-06,
      "loss": 0.6262,
      "step": 827500
    },
    {
      "epoch": 8.760233113311914,
      "eval_loss": 0.3848015069961548,
      "eval_runtime": 46.5219,
      "eval_samples_per_second": 3609.695,
      "eval_steps_per_second": 451.228,
      "step": 827500
    },
    {
      "epoch": 8.760762435091916,
      "grad_norm": 4.602471828460693,
      "learning_rate": 6.2152233749735345e-06,
      "loss": 0.6334,
      "step": 827550
    },
    {
      "epoch": 8.76129175687192,
      "grad_norm": 4.779176712036133,
      "learning_rate": 6.212576752064366e-06,
      "loss": 0.639,
      "step": 827600
    },
    {
      "epoch": 8.761821078651924,
      "grad_norm": 4.547082424163818,
      "learning_rate": 6.209930129155198e-06,
      "loss": 0.6132,
      "step": 827650
    },
    {
      "epoch": 8.762350400431927,
      "grad_norm": 4.846652984619141,
      "learning_rate": 6.20728350624603e-06,
      "loss": 0.6217,
      "step": 827700
    },
    {
      "epoch": 8.76287972221193,
      "grad_norm": 4.139946460723877,
      "learning_rate": 6.204636883336862e-06,
      "loss": 0.6323,
      "step": 827750
    },
    {
      "epoch": 8.763409043991933,
      "grad_norm": 5.091824531555176,
      "learning_rate": 6.201990260427695e-06,
      "loss": 0.6343,
      "step": 827800
    },
    {
      "epoch": 8.763938365771937,
      "grad_norm": 4.937067031860352,
      "learning_rate": 6.199343637518526e-06,
      "loss": 0.6387,
      "step": 827850
    },
    {
      "epoch": 8.76446768755194,
      "grad_norm": 4.626423358917236,
      "learning_rate": 6.196697014609359e-06,
      "loss": 0.6174,
      "step": 827900
    },
    {
      "epoch": 8.764997009331942,
      "grad_norm": 4.5928120613098145,
      "learning_rate": 6.194050391700191e-06,
      "loss": 0.6416,
      "step": 827950
    },
    {
      "epoch": 8.765526331111946,
      "grad_norm": 4.846288681030273,
      "learning_rate": 6.191403768791023e-06,
      "loss": 0.6386,
      "step": 828000
    },
    {
      "epoch": 8.765526331111946,
      "eval_loss": 0.38436347246170044,
      "eval_runtime": 46.4965,
      "eval_samples_per_second": 3611.671,
      "eval_steps_per_second": 451.475,
      "step": 828000
    },
    {
      "epoch": 8.76605565289195,
      "grad_norm": 4.747246265411377,
      "learning_rate": 6.188757145881855e-06,
      "loss": 0.634,
      "step": 828050
    },
    {
      "epoch": 8.766584974671954,
      "grad_norm": 4.389588356018066,
      "learning_rate": 6.1861105229726875e-06,
      "loss": 0.6402,
      "step": 828100
    },
    {
      "epoch": 8.767114296451956,
      "grad_norm": 5.2840070724487305,
      "learning_rate": 6.183463900063519e-06,
      "loss": 0.6363,
      "step": 828150
    },
    {
      "epoch": 8.76764361823196,
      "grad_norm": 4.813984394073486,
      "learning_rate": 6.1808172771543515e-06,
      "loss": 0.631,
      "step": 828200
    },
    {
      "epoch": 8.768172940011963,
      "grad_norm": 4.375041484832764,
      "learning_rate": 6.178170654245184e-06,
      "loss": 0.6311,
      "step": 828250
    },
    {
      "epoch": 8.768702261791965,
      "grad_norm": 4.603927135467529,
      "learning_rate": 6.1755240313360155e-06,
      "loss": 0.6395,
      "step": 828300
    },
    {
      "epoch": 8.769231583571969,
      "grad_norm": 4.409940242767334,
      "learning_rate": 6.172877408426848e-06,
      "loss": 0.6388,
      "step": 828350
    },
    {
      "epoch": 8.769760905351973,
      "grad_norm": 4.765993118286133,
      "learning_rate": 6.1702307855176794e-06,
      "loss": 0.6304,
      "step": 828400
    },
    {
      "epoch": 8.770290227131976,
      "grad_norm": 4.8426690101623535,
      "learning_rate": 6.167584162608512e-06,
      "loss": 0.6304,
      "step": 828450
    },
    {
      "epoch": 8.770819548911978,
      "grad_norm": 3.9961650371551514,
      "learning_rate": 6.164937539699344e-06,
      "loss": 0.6275,
      "step": 828500
    },
    {
      "epoch": 8.770819548911978,
      "eval_loss": 0.38411158323287964,
      "eval_runtime": 46.5406,
      "eval_samples_per_second": 3608.248,
      "eval_steps_per_second": 451.047,
      "step": 828500
    },
    {
      "epoch": 8.771348870691982,
      "grad_norm": 4.6808342933654785,
      "learning_rate": 6.162290916790176e-06,
      "loss": 0.6281,
      "step": 828550
    },
    {
      "epoch": 8.771878192471986,
      "grad_norm": 4.95125675201416,
      "learning_rate": 6.159644293881008e-06,
      "loss": 0.628,
      "step": 828600
    },
    {
      "epoch": 8.77240751425199,
      "grad_norm": 4.320471286773682,
      "learning_rate": 6.156997670971841e-06,
      "loss": 0.622,
      "step": 828650
    },
    {
      "epoch": 8.772936836031992,
      "grad_norm": 4.298452854156494,
      "learning_rate": 6.154351048062672e-06,
      "loss": 0.6438,
      "step": 828700
    },
    {
      "epoch": 8.773466157811995,
      "grad_norm": 4.305765628814697,
      "learning_rate": 6.1517044251535046e-06,
      "loss": 0.6223,
      "step": 828750
    },
    {
      "epoch": 8.773995479592,
      "grad_norm": 4.822975158691406,
      "learning_rate": 6.14911073470252e-06,
      "loss": 0.6247,
      "step": 828800
    },
    {
      "epoch": 8.774524801372003,
      "grad_norm": 4.215210437774658,
      "learning_rate": 6.146464111793352e-06,
      "loss": 0.6381,
      "step": 828850
    },
    {
      "epoch": 8.775054123152005,
      "grad_norm": 4.945267200469971,
      "learning_rate": 6.143817488884184e-06,
      "loss": 0.6346,
      "step": 828900
    },
    {
      "epoch": 8.775583444932009,
      "grad_norm": 4.997420787811279,
      "learning_rate": 6.1411708659750165e-06,
      "loss": 0.6281,
      "step": 828950
    },
    {
      "epoch": 8.776112766712012,
      "grad_norm": 4.65139627456665,
      "learning_rate": 6.138524243065848e-06,
      "loss": 0.6379,
      "step": 829000
    },
    {
      "epoch": 8.776112766712012,
      "eval_loss": 0.3842356204986572,
      "eval_runtime": 46.4536,
      "eval_samples_per_second": 3615.008,
      "eval_steps_per_second": 451.892,
      "step": 829000
    },
    {
      "epoch": 8.776642088492014,
      "grad_norm": 4.614367485046387,
      "learning_rate": 6.1358776201566805e-06,
      "loss": 0.6264,
      "step": 829050
    },
    {
      "epoch": 8.777171410272018,
      "grad_norm": 4.408080101013184,
      "learning_rate": 6.133230997247513e-06,
      "loss": 0.6273,
      "step": 829100
    },
    {
      "epoch": 8.777700732052022,
      "grad_norm": 4.601870059967041,
      "learning_rate": 6.1305843743383444e-06,
      "loss": 0.6278,
      "step": 829150
    },
    {
      "epoch": 8.778230053832026,
      "grad_norm": 4.585299968719482,
      "learning_rate": 6.127937751429177e-06,
      "loss": 0.6344,
      "step": 829200
    },
    {
      "epoch": 8.778759375612028,
      "grad_norm": 4.543540954589844,
      "learning_rate": 6.125291128520009e-06,
      "loss": 0.634,
      "step": 829250
    },
    {
      "epoch": 8.779288697392031,
      "grad_norm": 4.994420051574707,
      "learning_rate": 6.122644505610841e-06,
      "loss": 0.6301,
      "step": 829300
    },
    {
      "epoch": 8.779818019172035,
      "grad_norm": 4.618942737579346,
      "learning_rate": 6.119997882701673e-06,
      "loss": 0.6324,
      "step": 829350
    },
    {
      "epoch": 8.780347340952039,
      "grad_norm": 4.413451671600342,
      "learning_rate": 6.117351259792506e-06,
      "loss": 0.626,
      "step": 829400
    },
    {
      "epoch": 8.780876662732041,
      "grad_norm": 4.176030158996582,
      "learning_rate": 6.114704636883337e-06,
      "loss": 0.6283,
      "step": 829450
    },
    {
      "epoch": 8.781405984512045,
      "grad_norm": 4.786070346832275,
      "learning_rate": 6.1120580139741696e-06,
      "loss": 0.6271,
      "step": 829500
    },
    {
      "epoch": 8.781405984512045,
      "eval_loss": 0.38346391916275024,
      "eval_runtime": 46.627,
      "eval_samples_per_second": 3601.56,
      "eval_steps_per_second": 450.211,
      "step": 829500
    },
    {
      "epoch": 8.781935306292048,
      "grad_norm": 4.207762718200684,
      "learning_rate": 6.109411391065001e-06,
      "loss": 0.6304,
      "step": 829550
    },
    {
      "epoch": 8.782464628072052,
      "grad_norm": 4.435837745666504,
      "learning_rate": 6.1067647681558335e-06,
      "loss": 0.6208,
      "step": 829600
    },
    {
      "epoch": 8.782993949852054,
      "grad_norm": 4.707910060882568,
      "learning_rate": 6.104118145246666e-06,
      "loss": 0.6321,
      "step": 829650
    },
    {
      "epoch": 8.783523271632058,
      "grad_norm": 4.535946846008301,
      "learning_rate": 6.1014715223374975e-06,
      "loss": 0.6363,
      "step": 829700
    },
    {
      "epoch": 8.784052593412062,
      "grad_norm": 4.462289810180664,
      "learning_rate": 6.09882489942833e-06,
      "loss": 0.6448,
      "step": 829750
    },
    {
      "epoch": 8.784581915192064,
      "grad_norm": 4.895868301391602,
      "learning_rate": 6.096178276519162e-06,
      "loss": 0.6328,
      "step": 829800
    },
    {
      "epoch": 8.785111236972067,
      "grad_norm": 4.782144069671631,
      "learning_rate": 6.093531653609994e-06,
      "loss": 0.6382,
      "step": 829850
    },
    {
      "epoch": 8.785640558752071,
      "grad_norm": 4.502710819244385,
      "learning_rate": 6.090885030700826e-06,
      "loss": 0.6454,
      "step": 829900
    },
    {
      "epoch": 8.786169880532075,
      "grad_norm": 4.340516090393066,
      "learning_rate": 6.088238407791659e-06,
      "loss": 0.6305,
      "step": 829950
    },
    {
      "epoch": 8.786699202312077,
      "grad_norm": 4.418699264526367,
      "learning_rate": 6.08559178488249e-06,
      "loss": 0.6307,
      "step": 830000
    },
    {
      "epoch": 8.786699202312077,
      "eval_loss": 0.38416430354118347,
      "eval_runtime": 46.5122,
      "eval_samples_per_second": 3610.45,
      "eval_steps_per_second": 451.322,
      "step": 830000
    },
    {
      "epoch": 8.78722852409208,
      "grad_norm": 4.915265083312988,
      "learning_rate": 6.082945161973323e-06,
      "loss": 0.6334,
      "step": 830050
    },
    {
      "epoch": 8.787757845872084,
      "grad_norm": 4.66621208190918,
      "learning_rate": 6.080298539064155e-06,
      "loss": 0.6325,
      "step": 830100
    },
    {
      "epoch": 8.788287167652088,
      "grad_norm": 4.8000264167785645,
      "learning_rate": 6.077651916154987e-06,
      "loss": 0.6281,
      "step": 830150
    },
    {
      "epoch": 8.78881648943209,
      "grad_norm": 4.989981174468994,
      "learning_rate": 6.075005293245819e-06,
      "loss": 0.6336,
      "step": 830200
    },
    {
      "epoch": 8.789345811212094,
      "grad_norm": 4.709188938140869,
      "learning_rate": 6.072358670336651e-06,
      "loss": 0.6469,
      "step": 830250
    },
    {
      "epoch": 8.789875132992098,
      "grad_norm": 4.534093856811523,
      "learning_rate": 6.069712047427483e-06,
      "loss": 0.6269,
      "step": 830300
    },
    {
      "epoch": 8.790404454772101,
      "grad_norm": 4.783968448638916,
      "learning_rate": 6.067065424518315e-06,
      "loss": 0.6295,
      "step": 830350
    },
    {
      "epoch": 8.790933776552103,
      "grad_norm": 4.8279829025268555,
      "learning_rate": 6.064418801609147e-06,
      "loss": 0.6338,
      "step": 830400
    },
    {
      "epoch": 8.791463098332107,
      "grad_norm": 4.8168463706970215,
      "learning_rate": 6.061772178699979e-06,
      "loss": 0.6365,
      "step": 830450
    },
    {
      "epoch": 8.791992420112111,
      "grad_norm": 4.701237201690674,
      "learning_rate": 6.059125555790812e-06,
      "loss": 0.6253,
      "step": 830500
    },
    {
      "epoch": 8.791992420112111,
      "eval_loss": 0.3835543096065521,
      "eval_runtime": 46.5458,
      "eval_samples_per_second": 3607.842,
      "eval_steps_per_second": 450.996,
      "step": 830500
    },
    {
      "epoch": 8.792521741892113,
      "grad_norm": 4.931910037994385,
      "learning_rate": 6.056478932881643e-06,
      "loss": 0.638,
      "step": 830550
    },
    {
      "epoch": 8.793051063672117,
      "grad_norm": 4.77620792388916,
      "learning_rate": 6.053832309972476e-06,
      "loss": 0.6235,
      "step": 830600
    },
    {
      "epoch": 8.79358038545212,
      "grad_norm": 4.708909034729004,
      "learning_rate": 6.051185687063308e-06,
      "loss": 0.6328,
      "step": 830650
    },
    {
      "epoch": 8.794109707232124,
      "grad_norm": 4.696451663970947,
      "learning_rate": 6.04853906415414e-06,
      "loss": 0.6397,
      "step": 830700
    },
    {
      "epoch": 8.794639029012126,
      "grad_norm": 4.2552361488342285,
      "learning_rate": 6.045892441244972e-06,
      "loss": 0.6267,
      "step": 830750
    },
    {
      "epoch": 8.79516835079213,
      "grad_norm": 4.4511332511901855,
      "learning_rate": 6.043298750793988e-06,
      "loss": 0.6269,
      "step": 830800
    },
    {
      "epoch": 8.795697672572134,
      "grad_norm": 4.550529479980469,
      "learning_rate": 6.040652127884819e-06,
      "loss": 0.6222,
      "step": 830850
    },
    {
      "epoch": 8.796226994352137,
      "grad_norm": 4.678107261657715,
      "learning_rate": 6.038005504975652e-06,
      "loss": 0.6317,
      "step": 830900
    },
    {
      "epoch": 8.79675631613214,
      "grad_norm": 4.307141304016113,
      "learning_rate": 6.035358882066484e-06,
      "loss": 0.6372,
      "step": 830950
    },
    {
      "epoch": 8.797285637912143,
      "grad_norm": 4.381840705871582,
      "learning_rate": 6.032712259157316e-06,
      "loss": 0.6318,
      "step": 831000
    },
    {
      "epoch": 8.797285637912143,
      "eval_loss": 0.3836844563484192,
      "eval_runtime": 46.4055,
      "eval_samples_per_second": 3618.755,
      "eval_steps_per_second": 452.361,
      "step": 831000
    },
    {
      "epoch": 8.797814959692147,
      "grad_norm": 4.105660915374756,
      "learning_rate": 6.030065636248148e-06,
      "loss": 0.6187,
      "step": 831050
    },
    {
      "epoch": 8.79834428147215,
      "grad_norm": 4.648423671722412,
      "learning_rate": 6.02741901333898e-06,
      "loss": 0.6295,
      "step": 831100
    },
    {
      "epoch": 8.798873603252153,
      "grad_norm": 4.709063529968262,
      "learning_rate": 6.024772390429812e-06,
      "loss": 0.6345,
      "step": 831150
    },
    {
      "epoch": 8.799402925032156,
      "grad_norm": 4.353960990905762,
      "learning_rate": 6.022125767520644e-06,
      "loss": 0.6413,
      "step": 831200
    },
    {
      "epoch": 8.79993224681216,
      "grad_norm": 4.682303428649902,
      "learning_rate": 6.019479144611477e-06,
      "loss": 0.6147,
      "step": 831250
    },
    {
      "epoch": 8.800461568592162,
      "grad_norm": 4.207831859588623,
      "learning_rate": 6.016832521702308e-06,
      "loss": 0.6337,
      "step": 831300
    },
    {
      "epoch": 8.800990890372166,
      "grad_norm": 4.711258411407471,
      "learning_rate": 6.014185898793141e-06,
      "loss": 0.6304,
      "step": 831350
    },
    {
      "epoch": 8.80152021215217,
      "grad_norm": 4.871789455413818,
      "learning_rate": 6.011539275883972e-06,
      "loss": 0.6337,
      "step": 831400
    },
    {
      "epoch": 8.802049533932173,
      "grad_norm": 4.623205184936523,
      "learning_rate": 6.008892652974805e-06,
      "loss": 0.6215,
      "step": 831450
    },
    {
      "epoch": 8.802578855712175,
      "grad_norm": 4.774415016174316,
      "learning_rate": 6.006246030065637e-06,
      "loss": 0.6229,
      "step": 831500
    },
    {
      "epoch": 8.802578855712175,
      "eval_loss": 0.38424673676490784,
      "eval_runtime": 46.4681,
      "eval_samples_per_second": 3613.877,
      "eval_steps_per_second": 451.751,
      "step": 831500
    },
    {
      "epoch": 8.803108177492179,
      "grad_norm": 4.55430793762207,
      "learning_rate": 6.003599407156469e-06,
      "loss": 0.6305,
      "step": 831550
    },
    {
      "epoch": 8.803637499272183,
      "grad_norm": 4.942543029785156,
      "learning_rate": 6.0009527842473e-06,
      "loss": 0.6302,
      "step": 831600
    },
    {
      "epoch": 8.804166821052187,
      "grad_norm": 4.290399074554443,
      "learning_rate": 5.998306161338133e-06,
      "loss": 0.627,
      "step": 831650
    },
    {
      "epoch": 8.804696142832189,
      "grad_norm": 4.631702899932861,
      "learning_rate": 5.995659538428965e-06,
      "loss": 0.6267,
      "step": 831700
    },
    {
      "epoch": 8.805225464612192,
      "grad_norm": 5.287657260894775,
      "learning_rate": 5.993012915519797e-06,
      "loss": 0.6394,
      "step": 831750
    },
    {
      "epoch": 8.805754786392196,
      "grad_norm": 4.879122257232666,
      "learning_rate": 5.990366292610629e-06,
      "loss": 0.6253,
      "step": 831800
    },
    {
      "epoch": 8.8062841081722,
      "grad_norm": 4.730075836181641,
      "learning_rate": 5.9877196697014606e-06,
      "loss": 0.625,
      "step": 831850
    },
    {
      "epoch": 8.806813429952202,
      "grad_norm": 4.595179080963135,
      "learning_rate": 5.985073046792293e-06,
      "loss": 0.6269,
      "step": 831900
    },
    {
      "epoch": 8.807342751732206,
      "grad_norm": 4.7918806076049805,
      "learning_rate": 5.982426423883125e-06,
      "loss": 0.6286,
      "step": 831950
    },
    {
      "epoch": 8.80787207351221,
      "grad_norm": 4.1133198738098145,
      "learning_rate": 5.979779800973957e-06,
      "loss": 0.6297,
      "step": 832000
    },
    {
      "epoch": 8.80787207351221,
      "eval_loss": 0.38312825560569763,
      "eval_runtime": 46.4477,
      "eval_samples_per_second": 3615.461,
      "eval_steps_per_second": 451.949,
      "step": 832000
    },
    {
      "epoch": 8.808401395292211,
      "grad_norm": 4.7981977462768555,
      "learning_rate": 5.977133178064789e-06,
      "loss": 0.6267,
      "step": 832050
    },
    {
      "epoch": 8.808930717072215,
      "grad_norm": 4.734334945678711,
      "learning_rate": 5.974486555155622e-06,
      "loss": 0.6278,
      "step": 832100
    },
    {
      "epoch": 8.809460038852219,
      "grad_norm": 4.6584792137146,
      "learning_rate": 5.971839932246453e-06,
      "loss": 0.6339,
      "step": 832150
    },
    {
      "epoch": 8.809989360632223,
      "grad_norm": 4.823434829711914,
      "learning_rate": 5.969193309337286e-06,
      "loss": 0.6257,
      "step": 832200
    },
    {
      "epoch": 8.810518682412225,
      "grad_norm": 4.504095077514648,
      "learning_rate": 5.966546686428118e-06,
      "loss": 0.6221,
      "step": 832250
    },
    {
      "epoch": 8.811048004192228,
      "grad_norm": 5.056121349334717,
      "learning_rate": 5.96390006351895e-06,
      "loss": 0.6295,
      "step": 832300
    },
    {
      "epoch": 8.811577325972232,
      "grad_norm": 4.866472244262695,
      "learning_rate": 5.961253440609782e-06,
      "loss": 0.6349,
      "step": 832350
    },
    {
      "epoch": 8.812106647752236,
      "grad_norm": 5.344042778015137,
      "learning_rate": 5.9586068177006145e-06,
      "loss": 0.636,
      "step": 832400
    },
    {
      "epoch": 8.812635969532238,
      "grad_norm": 4.641035556793213,
      "learning_rate": 5.955960194791446e-06,
      "loss": 0.621,
      "step": 832450
    },
    {
      "epoch": 8.813165291312242,
      "grad_norm": 4.694105625152588,
      "learning_rate": 5.9533135718822784e-06,
      "loss": 0.627,
      "step": 832500
    },
    {
      "epoch": 8.813165291312242,
      "eval_loss": 0.38330256938934326,
      "eval_runtime": 46.4896,
      "eval_samples_per_second": 3612.204,
      "eval_steps_per_second": 451.542,
      "step": 832500
    },
    {
      "epoch": 8.813694613092245,
      "grad_norm": 4.159923076629639,
      "learning_rate": 5.95066694897311e-06,
      "loss": 0.6243,
      "step": 832550
    },
    {
      "epoch": 8.814223934872249,
      "grad_norm": 4.3332343101501465,
      "learning_rate": 5.948020326063942e-06,
      "loss": 0.6367,
      "step": 832600
    },
    {
      "epoch": 8.814753256652251,
      "grad_norm": 4.389279842376709,
      "learning_rate": 5.945373703154775e-06,
      "loss": 0.6314,
      "step": 832650
    },
    {
      "epoch": 8.815282578432255,
      "grad_norm": 4.627951145172119,
      "learning_rate": 5.942727080245606e-06,
      "loss": 0.6259,
      "step": 832700
    },
    {
      "epoch": 8.815811900212259,
      "grad_norm": 4.87641716003418,
      "learning_rate": 5.940080457336439e-06,
      "loss": 0.6338,
      "step": 832750
    },
    {
      "epoch": 8.81634122199226,
      "grad_norm": 4.11876106262207,
      "learning_rate": 5.937486766885454e-06,
      "loss": 0.641,
      "step": 832800
    },
    {
      "epoch": 8.816870543772264,
      "grad_norm": 4.884832859039307,
      "learning_rate": 5.934840143976286e-06,
      "loss": 0.6317,
      "step": 832850
    },
    {
      "epoch": 8.817399865552268,
      "grad_norm": 4.313386917114258,
      "learning_rate": 5.932193521067118e-06,
      "loss": 0.6306,
      "step": 832900
    },
    {
      "epoch": 8.817929187332272,
      "grad_norm": 4.146262168884277,
      "learning_rate": 5.929546898157951e-06,
      "loss": 0.6236,
      "step": 832950
    },
    {
      "epoch": 8.818458509112274,
      "grad_norm": 5.017650604248047,
      "learning_rate": 5.926900275248782e-06,
      "loss": 0.6243,
      "step": 833000
    },
    {
      "epoch": 8.818458509112274,
      "eval_loss": 0.38334617018699646,
      "eval_runtime": 46.4983,
      "eval_samples_per_second": 3611.527,
      "eval_steps_per_second": 451.457,
      "step": 833000
    },
    {
      "epoch": 8.818987830892278,
      "grad_norm": 4.817634582519531,
      "learning_rate": 5.924253652339615e-06,
      "loss": 0.6229,
      "step": 833050
    },
    {
      "epoch": 8.819517152672281,
      "grad_norm": 4.639469146728516,
      "learning_rate": 5.921607029430447e-06,
      "loss": 0.6314,
      "step": 833100
    },
    {
      "epoch": 8.820046474452285,
      "grad_norm": 4.786077499389648,
      "learning_rate": 5.918960406521279e-06,
      "loss": 0.6254,
      "step": 833150
    },
    {
      "epoch": 8.820575796232287,
      "grad_norm": 4.434822082519531,
      "learning_rate": 5.916313783612111e-06,
      "loss": 0.6332,
      "step": 833200
    },
    {
      "epoch": 8.82110511801229,
      "grad_norm": 4.6663336753845215,
      "learning_rate": 5.9136671607029434e-06,
      "loss": 0.6434,
      "step": 833250
    },
    {
      "epoch": 8.821634439792295,
      "grad_norm": 4.864665508270264,
      "learning_rate": 5.911020537793775e-06,
      "loss": 0.626,
      "step": 833300
    },
    {
      "epoch": 8.822163761572298,
      "grad_norm": 4.869898319244385,
      "learning_rate": 5.908373914884607e-06,
      "loss": 0.6261,
      "step": 833350
    },
    {
      "epoch": 8.8226930833523,
      "grad_norm": 4.928646087646484,
      "learning_rate": 5.90572729197544e-06,
      "loss": 0.6267,
      "step": 833400
    },
    {
      "epoch": 8.823222405132304,
      "grad_norm": 4.584640979766846,
      "learning_rate": 5.903080669066271e-06,
      "loss": 0.6271,
      "step": 833450
    },
    {
      "epoch": 8.823751726912308,
      "grad_norm": 5.045319080352783,
      "learning_rate": 5.900434046157104e-06,
      "loss": 0.6301,
      "step": 833500
    },
    {
      "epoch": 8.823751726912308,
      "eval_loss": 0.38366982340812683,
      "eval_runtime": 46.4486,
      "eval_samples_per_second": 3615.396,
      "eval_steps_per_second": 451.941,
      "step": 833500
    },
    {
      "epoch": 8.82428104869231,
      "grad_norm": 4.664379119873047,
      "learning_rate": 5.897787423247936e-06,
      "loss": 0.6414,
      "step": 833550
    },
    {
      "epoch": 8.824810370472314,
      "grad_norm": 4.415800094604492,
      "learning_rate": 5.895140800338768e-06,
      "loss": 0.6263,
      "step": 833600
    },
    {
      "epoch": 8.825339692252317,
      "grad_norm": 4.300755023956299,
      "learning_rate": 5.8924941774296e-06,
      "loss": 0.6204,
      "step": 833650
    },
    {
      "epoch": 8.825869014032321,
      "grad_norm": 4.7553911209106445,
      "learning_rate": 5.889847554520432e-06,
      "loss": 0.6446,
      "step": 833700
    },
    {
      "epoch": 8.826398335812323,
      "grad_norm": 4.596461772918701,
      "learning_rate": 5.887200931611264e-06,
      "loss": 0.6289,
      "step": 833750
    },
    {
      "epoch": 8.826927657592327,
      "grad_norm": 4.573236465454102,
      "learning_rate": 5.8845543087020965e-06,
      "loss": 0.6325,
      "step": 833800
    },
    {
      "epoch": 8.82745697937233,
      "grad_norm": 4.759209156036377,
      "learning_rate": 5.881907685792928e-06,
      "loss": 0.6359,
      "step": 833850
    },
    {
      "epoch": 8.827986301152334,
      "grad_norm": 4.265406608581543,
      "learning_rate": 5.8792610628837605e-06,
      "loss": 0.6318,
      "step": 833900
    },
    {
      "epoch": 8.828515622932336,
      "grad_norm": 4.638101577758789,
      "learning_rate": 5.876614439974593e-06,
      "loss": 0.6341,
      "step": 833950
    },
    {
      "epoch": 8.82904494471234,
      "grad_norm": 4.735323905944824,
      "learning_rate": 5.8739678170654244e-06,
      "loss": 0.6307,
      "step": 834000
    },
    {
      "epoch": 8.82904494471234,
      "eval_loss": 0.3835102915763855,
      "eval_runtime": 46.4562,
      "eval_samples_per_second": 3614.8,
      "eval_steps_per_second": 451.866,
      "step": 834000
    },
    {
      "epoch": 8.829574266492344,
      "grad_norm": 5.149838447570801,
      "learning_rate": 5.871321194156257e-06,
      "loss": 0.6226,
      "step": 834050
    },
    {
      "epoch": 8.830103588272348,
      "grad_norm": 4.282173156738281,
      "learning_rate": 5.868674571247089e-06,
      "loss": 0.6435,
      "step": 834100
    },
    {
      "epoch": 8.83063291005235,
      "grad_norm": 4.804662227630615,
      "learning_rate": 5.866027948337921e-06,
      "loss": 0.6378,
      "step": 834150
    },
    {
      "epoch": 8.831162231832353,
      "grad_norm": 4.713803768157959,
      "learning_rate": 5.863381325428753e-06,
      "loss": 0.6325,
      "step": 834200
    },
    {
      "epoch": 8.831691553612357,
      "grad_norm": 4.5911784172058105,
      "learning_rate": 5.860734702519586e-06,
      "loss": 0.6255,
      "step": 834250
    },
    {
      "epoch": 8.832220875392359,
      "grad_norm": 4.741418838500977,
      "learning_rate": 5.858088079610417e-06,
      "loss": 0.6304,
      "step": 834300
    },
    {
      "epoch": 8.832750197172363,
      "grad_norm": 4.9024882316589355,
      "learning_rate": 5.85544145670125e-06,
      "loss": 0.638,
      "step": 834350
    },
    {
      "epoch": 8.833279518952367,
      "grad_norm": 4.8518829345703125,
      "learning_rate": 5.852794833792081e-06,
      "loss": 0.6312,
      "step": 834400
    },
    {
      "epoch": 8.83380884073237,
      "grad_norm": 4.645590305328369,
      "learning_rate": 5.8501482108829136e-06,
      "loss": 0.6285,
      "step": 834450
    },
    {
      "epoch": 8.834338162512372,
      "grad_norm": 4.916382789611816,
      "learning_rate": 5.847501587973746e-06,
      "loss": 0.6451,
      "step": 834500
    },
    {
      "epoch": 8.834338162512372,
      "eval_loss": 0.38416096568107605,
      "eval_runtime": 46.5062,
      "eval_samples_per_second": 3610.918,
      "eval_steps_per_second": 451.381,
      "step": 834500
    },
    {
      "epoch": 8.834867484292376,
      "grad_norm": 4.432897090911865,
      "learning_rate": 5.8448549650645775e-06,
      "loss": 0.6207,
      "step": 834550
    },
    {
      "epoch": 8.83539680607238,
      "grad_norm": 4.9215593338012695,
      "learning_rate": 5.84220834215541e-06,
      "loss": 0.6318,
      "step": 834600
    },
    {
      "epoch": 8.835926127852384,
      "grad_norm": 4.8174967765808105,
      "learning_rate": 5.839561719246242e-06,
      "loss": 0.6272,
      "step": 834650
    },
    {
      "epoch": 8.836455449632385,
      "grad_norm": 4.423253059387207,
      "learning_rate": 5.836915096337074e-06,
      "loss": 0.6233,
      "step": 834700
    },
    {
      "epoch": 8.83698477141239,
      "grad_norm": 4.994146823883057,
      "learning_rate": 5.834268473427906e-06,
      "loss": 0.6325,
      "step": 834750
    },
    {
      "epoch": 8.837514093192393,
      "grad_norm": 4.722038269042969,
      "learning_rate": 5.831621850518739e-06,
      "loss": 0.6206,
      "step": 834800
    },
    {
      "epoch": 8.838043414972397,
      "grad_norm": 5.149981498718262,
      "learning_rate": 5.829028160067753e-06,
      "loss": 0.6207,
      "step": 834850
    },
    {
      "epoch": 8.838572736752399,
      "grad_norm": 4.4100141525268555,
      "learning_rate": 5.826381537158586e-06,
      "loss": 0.6289,
      "step": 834900
    },
    {
      "epoch": 8.839102058532402,
      "grad_norm": 4.655281066894531,
      "learning_rate": 5.823734914249418e-06,
      "loss": 0.6247,
      "step": 834950
    },
    {
      "epoch": 8.839631380312406,
      "grad_norm": 4.8501691818237305,
      "learning_rate": 5.82108829134025e-06,
      "loss": 0.6255,
      "step": 835000
    },
    {
      "epoch": 8.839631380312406,
      "eval_loss": 0.38280338048934937,
      "eval_runtime": 46.4907,
      "eval_samples_per_second": 3612.122,
      "eval_steps_per_second": 451.531,
      "step": 835000
    },
    {
      "epoch": 8.840160702092408,
      "grad_norm": 4.54724645614624,
      "learning_rate": 5.818441668431082e-06,
      "loss": 0.6355,
      "step": 835050
    },
    {
      "epoch": 8.840690023872412,
      "grad_norm": 4.2882256507873535,
      "learning_rate": 5.815795045521915e-06,
      "loss": 0.6341,
      "step": 835100
    },
    {
      "epoch": 8.841219345652416,
      "grad_norm": 4.757662773132324,
      "learning_rate": 5.813148422612746e-06,
      "loss": 0.6386,
      "step": 835150
    },
    {
      "epoch": 8.84174866743242,
      "grad_norm": 4.5517659187316895,
      "learning_rate": 5.8105017997035786e-06,
      "loss": 0.6311,
      "step": 835200
    },
    {
      "epoch": 8.842277989212421,
      "grad_norm": 5.128424644470215,
      "learning_rate": 5.807855176794411e-06,
      "loss": 0.6197,
      "step": 835250
    },
    {
      "epoch": 8.842807310992425,
      "grad_norm": 5.16084098815918,
      "learning_rate": 5.8052085538852425e-06,
      "loss": 0.6327,
      "step": 835300
    },
    {
      "epoch": 8.843336632772429,
      "grad_norm": 4.650930881500244,
      "learning_rate": 5.802561930976075e-06,
      "loss": 0.635,
      "step": 835350
    },
    {
      "epoch": 8.843865954552433,
      "grad_norm": 4.331286430358887,
      "learning_rate": 5.799915308066907e-06,
      "loss": 0.6294,
      "step": 835400
    },
    {
      "epoch": 8.844395276332435,
      "grad_norm": 4.499261856079102,
      "learning_rate": 5.797268685157739e-06,
      "loss": 0.6318,
      "step": 835450
    },
    {
      "epoch": 8.844924598112438,
      "grad_norm": 4.8704071044921875,
      "learning_rate": 5.794622062248571e-06,
      "loss": 0.6225,
      "step": 835500
    },
    {
      "epoch": 8.844924598112438,
      "eval_loss": 0.3834756910800934,
      "eval_runtime": 46.5011,
      "eval_samples_per_second": 3611.311,
      "eval_steps_per_second": 451.43,
      "step": 835500
    },
    {
      "epoch": 8.845453919892442,
      "grad_norm": 4.915424346923828,
      "learning_rate": 5.791975439339403e-06,
      "loss": 0.6309,
      "step": 835550
    },
    {
      "epoch": 8.845983241672446,
      "grad_norm": 4.669983386993408,
      "learning_rate": 5.789328816430235e-06,
      "loss": 0.6459,
      "step": 835600
    },
    {
      "epoch": 8.846512563452448,
      "grad_norm": 4.726770401000977,
      "learning_rate": 5.786682193521068e-06,
      "loss": 0.6322,
      "step": 835650
    },
    {
      "epoch": 8.847041885232452,
      "grad_norm": 4.597452163696289,
      "learning_rate": 5.784035570611899e-06,
      "loss": 0.6308,
      "step": 835700
    },
    {
      "epoch": 8.847571207012455,
      "grad_norm": 4.752681255340576,
      "learning_rate": 5.781388947702732e-06,
      "loss": 0.631,
      "step": 835750
    },
    {
      "epoch": 8.848100528792457,
      "grad_norm": 4.3935370445251465,
      "learning_rate": 5.778742324793564e-06,
      "loss": 0.6294,
      "step": 835800
    },
    {
      "epoch": 8.848629850572461,
      "grad_norm": 4.7742509841918945,
      "learning_rate": 5.776095701884396e-06,
      "loss": 0.6431,
      "step": 835850
    },
    {
      "epoch": 8.849159172352465,
      "grad_norm": 4.756289482116699,
      "learning_rate": 5.773449078975228e-06,
      "loss": 0.6192,
      "step": 835900
    },
    {
      "epoch": 8.849688494132469,
      "grad_norm": 4.88674783706665,
      "learning_rate": 5.77080245606606e-06,
      "loss": 0.6326,
      "step": 835950
    },
    {
      "epoch": 8.85021781591247,
      "grad_norm": 4.465888023376465,
      "learning_rate": 5.768155833156892e-06,
      "loss": 0.6296,
      "step": 836000
    },
    {
      "epoch": 8.85021781591247,
      "eval_loss": 0.3828086256980896,
      "eval_runtime": 46.5196,
      "eval_samples_per_second": 3609.879,
      "eval_steps_per_second": 451.251,
      "step": 836000
    },
    {
      "epoch": 8.850747137692474,
      "grad_norm": 4.769088268280029,
      "learning_rate": 5.765509210247724e-06,
      "loss": 0.6306,
      "step": 836050
    },
    {
      "epoch": 8.851276459472478,
      "grad_norm": 4.538463592529297,
      "learning_rate": 5.762862587338557e-06,
      "loss": 0.6338,
      "step": 836100
    },
    {
      "epoch": 8.851805781252482,
      "grad_norm": 4.818358421325684,
      "learning_rate": 5.760215964429388e-06,
      "loss": 0.629,
      "step": 836150
    },
    {
      "epoch": 8.852335103032484,
      "grad_norm": 4.922540664672852,
      "learning_rate": 5.757569341520221e-06,
      "loss": 0.6384,
      "step": 836200
    },
    {
      "epoch": 8.852864424812488,
      "grad_norm": 4.736893653869629,
      "learning_rate": 5.754922718611052e-06,
      "loss": 0.6299,
      "step": 836250
    },
    {
      "epoch": 8.853393746592491,
      "grad_norm": 4.826914310455322,
      "learning_rate": 5.752276095701885e-06,
      "loss": 0.6359,
      "step": 836300
    },
    {
      "epoch": 8.853923068372495,
      "grad_norm": 4.242312431335449,
      "learning_rate": 5.749629472792717e-06,
      "loss": 0.6268,
      "step": 836350
    },
    {
      "epoch": 8.854452390152497,
      "grad_norm": 4.981204032897949,
      "learning_rate": 5.746982849883549e-06,
      "loss": 0.626,
      "step": 836400
    },
    {
      "epoch": 8.854981711932501,
      "grad_norm": 4.273687362670898,
      "learning_rate": 5.744336226974381e-06,
      "loss": 0.6369,
      "step": 836450
    },
    {
      "epoch": 8.855511033712505,
      "grad_norm": 4.80888032913208,
      "learning_rate": 5.7416896040652135e-06,
      "loss": 0.6227,
      "step": 836500
    },
    {
      "epoch": 8.855511033712505,
      "eval_loss": 0.38236039876937866,
      "eval_runtime": 46.4848,
      "eval_samples_per_second": 3612.576,
      "eval_steps_per_second": 451.588,
      "step": 836500
    },
    {
      "epoch": 8.856040355492507,
      "grad_norm": 4.668671131134033,
      "learning_rate": 5.739042981156045e-06,
      "loss": 0.6268,
      "step": 836550
    },
    {
      "epoch": 8.85656967727251,
      "grad_norm": 4.973944664001465,
      "learning_rate": 5.7363963582468775e-06,
      "loss": 0.6413,
      "step": 836600
    },
    {
      "epoch": 8.857098999052514,
      "grad_norm": 4.410888195037842,
      "learning_rate": 5.73374973533771e-06,
      "loss": 0.6295,
      "step": 836650
    },
    {
      "epoch": 8.857628320832518,
      "grad_norm": 4.289041996002197,
      "learning_rate": 5.731103112428541e-06,
      "loss": 0.6282,
      "step": 836700
    },
    {
      "epoch": 8.85815764261252,
      "grad_norm": 4.781968593597412,
      "learning_rate": 5.728456489519374e-06,
      "loss": 0.6318,
      "step": 836750
    },
    {
      "epoch": 8.858686964392524,
      "grad_norm": 4.745480060577393,
      "learning_rate": 5.725809866610206e-06,
      "loss": 0.6254,
      "step": 836800
    },
    {
      "epoch": 8.859216286172527,
      "grad_norm": 4.766896724700928,
      "learning_rate": 5.723216176159221e-06,
      "loss": 0.6324,
      "step": 836850
    },
    {
      "epoch": 8.859745607952531,
      "grad_norm": 4.647122859954834,
      "learning_rate": 5.720569553250053e-06,
      "loss": 0.6342,
      "step": 836900
    },
    {
      "epoch": 8.860274929732533,
      "grad_norm": 4.504891395568848,
      "learning_rate": 5.717922930340886e-06,
      "loss": 0.6337,
      "step": 836950
    },
    {
      "epoch": 8.860804251512537,
      "grad_norm": 4.986682891845703,
      "learning_rate": 5.715276307431717e-06,
      "loss": 0.6349,
      "step": 837000
    },
    {
      "epoch": 8.860804251512537,
      "eval_loss": 0.3827266991138458,
      "eval_runtime": 46.4148,
      "eval_samples_per_second": 3618.031,
      "eval_steps_per_second": 452.27,
      "step": 837000
    },
    {
      "epoch": 8.86133357329254,
      "grad_norm": 4.787983417510986,
      "learning_rate": 5.71262968452255e-06,
      "loss": 0.6179,
      "step": 837050
    },
    {
      "epoch": 8.861862895072544,
      "grad_norm": 4.608855247497559,
      "learning_rate": 5.709983061613382e-06,
      "loss": 0.623,
      "step": 837100
    },
    {
      "epoch": 8.862392216852546,
      "grad_norm": 4.265589237213135,
      "learning_rate": 5.707336438704214e-06,
      "loss": 0.6193,
      "step": 837150
    },
    {
      "epoch": 8.86292153863255,
      "grad_norm": 4.719913482666016,
      "learning_rate": 5.704689815795046e-06,
      "loss": 0.6266,
      "step": 837200
    },
    {
      "epoch": 8.863450860412554,
      "grad_norm": 4.48284912109375,
      "learning_rate": 5.7020431928858785e-06,
      "loss": 0.6334,
      "step": 837250
    },
    {
      "epoch": 8.863980182192556,
      "grad_norm": 4.390824794769287,
      "learning_rate": 5.69939656997671e-06,
      "loss": 0.6325,
      "step": 837300
    },
    {
      "epoch": 8.86450950397256,
      "grad_norm": 4.975067138671875,
      "learning_rate": 5.6967499470675425e-06,
      "loss": 0.6232,
      "step": 837350
    },
    {
      "epoch": 8.865038825752563,
      "grad_norm": 5.213969707489014,
      "learning_rate": 5.694103324158374e-06,
      "loss": 0.6285,
      "step": 837400
    },
    {
      "epoch": 8.865568147532567,
      "grad_norm": 5.108728885650635,
      "learning_rate": 5.691456701249206e-06,
      "loss": 0.6279,
      "step": 837450
    },
    {
      "epoch": 8.86609746931257,
      "grad_norm": 4.465536117553711,
      "learning_rate": 5.688810078340039e-06,
      "loss": 0.6243,
      "step": 837500
    },
    {
      "epoch": 8.86609746931257,
      "eval_loss": 0.38186588883399963,
      "eval_runtime": 46.566,
      "eval_samples_per_second": 3606.279,
      "eval_steps_per_second": 450.801,
      "step": 837500
    },
    {
      "epoch": 8.866626791092573,
      "grad_norm": 4.532639980316162,
      "learning_rate": 5.68616345543087e-06,
      "loss": 0.635,
      "step": 837550
    },
    {
      "epoch": 8.867156112872577,
      "grad_norm": 4.252449989318848,
      "learning_rate": 5.683516832521703e-06,
      "loss": 0.6339,
      "step": 837600
    },
    {
      "epoch": 8.86768543465258,
      "grad_norm": 5.074974060058594,
      "learning_rate": 5.680870209612535e-06,
      "loss": 0.6387,
      "step": 837650
    },
    {
      "epoch": 8.868214756432582,
      "grad_norm": 4.806646823883057,
      "learning_rate": 5.678223586703367e-06,
      "loss": 0.6247,
      "step": 837700
    },
    {
      "epoch": 8.868744078212586,
      "grad_norm": 4.742410182952881,
      "learning_rate": 5.675576963794199e-06,
      "loss": 0.6302,
      "step": 837750
    },
    {
      "epoch": 8.86927339999259,
      "grad_norm": 4.467642307281494,
      "learning_rate": 5.6729303408850316e-06,
      "loss": 0.6258,
      "step": 837800
    },
    {
      "epoch": 8.869802721772594,
      "grad_norm": 4.548092842102051,
      "learning_rate": 5.670283717975863e-06,
      "loss": 0.6264,
      "step": 837850
    },
    {
      "epoch": 8.870332043552596,
      "grad_norm": 4.540305137634277,
      "learning_rate": 5.6676370950666955e-06,
      "loss": 0.6308,
      "step": 837900
    },
    {
      "epoch": 8.8708613653326,
      "grad_norm": 4.536128997802734,
      "learning_rate": 5.665043404615711e-06,
      "loss": 0.6422,
      "step": 837950
    },
    {
      "epoch": 8.871390687112603,
      "grad_norm": 4.740733623504639,
      "learning_rate": 5.662396781706543e-06,
      "loss": 0.6282,
      "step": 838000
    },
    {
      "epoch": 8.871390687112603,
      "eval_loss": 0.38290926814079285,
      "eval_runtime": 46.5267,
      "eval_samples_per_second": 3609.322,
      "eval_steps_per_second": 451.181,
      "step": 838000
    },
    {
      "epoch": 8.871920008892605,
      "grad_norm": 4.406928062438965,
      "learning_rate": 5.659750158797375e-06,
      "loss": 0.6274,
      "step": 838050
    },
    {
      "epoch": 8.872449330672609,
      "grad_norm": 4.062078952789307,
      "learning_rate": 5.6571035358882075e-06,
      "loss": 0.633,
      "step": 838100
    },
    {
      "epoch": 8.872978652452613,
      "grad_norm": 4.893796920776367,
      "learning_rate": 5.654456912979039e-06,
      "loss": 0.6342,
      "step": 838150
    },
    {
      "epoch": 8.873507974232616,
      "grad_norm": 5.134529113769531,
      "learning_rate": 5.651810290069871e-06,
      "loss": 0.6262,
      "step": 838200
    },
    {
      "epoch": 8.874037296012618,
      "grad_norm": 4.8153204917907715,
      "learning_rate": 5.649163667160704e-06,
      "loss": 0.6336,
      "step": 838250
    },
    {
      "epoch": 8.874566617792622,
      "grad_norm": 4.437378883361816,
      "learning_rate": 5.646517044251535e-06,
      "loss": 0.6336,
      "step": 838300
    },
    {
      "epoch": 8.875095939572626,
      "grad_norm": 4.487059593200684,
      "learning_rate": 5.643870421342368e-06,
      "loss": 0.6262,
      "step": 838350
    },
    {
      "epoch": 8.87562526135263,
      "grad_norm": 4.428308963775635,
      "learning_rate": 5.641223798433199e-06,
      "loss": 0.6215,
      "step": 838400
    },
    {
      "epoch": 8.876154583132632,
      "grad_norm": 4.764610290527344,
      "learning_rate": 5.638577175524032e-06,
      "loss": 0.6295,
      "step": 838450
    },
    {
      "epoch": 8.876683904912635,
      "grad_norm": 4.41664981842041,
      "learning_rate": 5.635930552614864e-06,
      "loss": 0.6276,
      "step": 838500
    },
    {
      "epoch": 8.876683904912635,
      "eval_loss": 0.3824273645877838,
      "eval_runtime": 46.4294,
      "eval_samples_per_second": 3616.891,
      "eval_steps_per_second": 452.127,
      "step": 838500
    },
    {
      "epoch": 8.87721322669264,
      "grad_norm": 4.654541969299316,
      "learning_rate": 5.633283929705696e-06,
      "loss": 0.6277,
      "step": 838550
    },
    {
      "epoch": 8.877742548472643,
      "grad_norm": 4.381019592285156,
      "learning_rate": 5.630637306796528e-06,
      "loss": 0.6301,
      "step": 838600
    },
    {
      "epoch": 8.878271870252645,
      "grad_norm": 4.611179351806641,
      "learning_rate": 5.6279906838873605e-06,
      "loss": 0.6301,
      "step": 838650
    },
    {
      "epoch": 8.878801192032649,
      "grad_norm": 4.789729595184326,
      "learning_rate": 5.625344060978192e-06,
      "loss": 0.6309,
      "step": 838700
    },
    {
      "epoch": 8.879330513812652,
      "grad_norm": 4.250790119171143,
      "learning_rate": 5.6226974380690245e-06,
      "loss": 0.6242,
      "step": 838750
    },
    {
      "epoch": 8.879859835592654,
      "grad_norm": 4.467718124389648,
      "learning_rate": 5.620050815159857e-06,
      "loss": 0.6212,
      "step": 838800
    },
    {
      "epoch": 8.880389157372658,
      "grad_norm": 4.769751071929932,
      "learning_rate": 5.6174041922506885e-06,
      "loss": 0.6251,
      "step": 838850
    },
    {
      "epoch": 8.880918479152662,
      "grad_norm": 5.032405853271484,
      "learning_rate": 5.614757569341521e-06,
      "loss": 0.6321,
      "step": 838900
    },
    {
      "epoch": 8.881447800932666,
      "grad_norm": 4.181657791137695,
      "learning_rate": 5.612110946432353e-06,
      "loss": 0.6323,
      "step": 838950
    },
    {
      "epoch": 8.881977122712668,
      "grad_norm": 4.987107276916504,
      "learning_rate": 5.609464323523185e-06,
      "loss": 0.6219,
      "step": 839000
    },
    {
      "epoch": 8.881977122712668,
      "eval_loss": 0.38256821036338806,
      "eval_runtime": 46.4995,
      "eval_samples_per_second": 3611.434,
      "eval_steps_per_second": 451.445,
      "step": 839000
    },
    {
      "epoch": 8.882506444492671,
      "grad_norm": 4.759142875671387,
      "learning_rate": 5.606817700614017e-06,
      "loss": 0.6339,
      "step": 839050
    },
    {
      "epoch": 8.883035766272675,
      "grad_norm": 4.634497165679932,
      "learning_rate": 5.60417107770485e-06,
      "loss": 0.6188,
      "step": 839100
    },
    {
      "epoch": 8.883565088052679,
      "grad_norm": 4.542755126953125,
      "learning_rate": 5.60152445479568e-06,
      "loss": 0.624,
      "step": 839150
    },
    {
      "epoch": 8.88409440983268,
      "grad_norm": 4.9983601570129395,
      "learning_rate": 5.598877831886513e-06,
      "loss": 0.6375,
      "step": 839200
    },
    {
      "epoch": 8.884623731612685,
      "grad_norm": 4.747903823852539,
      "learning_rate": 5.596231208977345e-06,
      "loss": 0.6277,
      "step": 839250
    },
    {
      "epoch": 8.885153053392688,
      "grad_norm": 4.682465076446533,
      "learning_rate": 5.593584586068177e-06,
      "loss": 0.623,
      "step": 839300
    },
    {
      "epoch": 8.885682375172692,
      "grad_norm": 5.293827533721924,
      "learning_rate": 5.590937963159009e-06,
      "loss": 0.6399,
      "step": 839350
    },
    {
      "epoch": 8.886211696952694,
      "grad_norm": 4.320395469665527,
      "learning_rate": 5.5882913402498415e-06,
      "loss": 0.6382,
      "step": 839400
    },
    {
      "epoch": 8.886741018732698,
      "grad_norm": 4.920505523681641,
      "learning_rate": 5.585644717340673e-06,
      "loss": 0.6412,
      "step": 839450
    },
    {
      "epoch": 8.887270340512702,
      "grad_norm": 4.804539680480957,
      "learning_rate": 5.5829980944315055e-06,
      "loss": 0.6238,
      "step": 839500
    },
    {
      "epoch": 8.887270340512702,
      "eval_loss": 0.38306933641433716,
      "eval_runtime": 46.493,
      "eval_samples_per_second": 3611.938,
      "eval_steps_per_second": 451.508,
      "step": 839500
    },
    {
      "epoch": 8.887799662292704,
      "grad_norm": 4.790429592132568,
      "learning_rate": 5.580351471522337e-06,
      "loss": 0.6383,
      "step": 839550
    },
    {
      "epoch": 8.888328984072707,
      "grad_norm": 4.060436725616455,
      "learning_rate": 5.5777048486131695e-06,
      "loss": 0.6204,
      "step": 839600
    },
    {
      "epoch": 8.888858305852711,
      "grad_norm": 4.2156219482421875,
      "learning_rate": 5.575058225704002e-06,
      "loss": 0.6264,
      "step": 839650
    },
    {
      "epoch": 8.889387627632715,
      "grad_norm": 4.499087810516357,
      "learning_rate": 5.5724116027948334e-06,
      "loss": 0.6246,
      "step": 839700
    },
    {
      "epoch": 8.889916949412717,
      "grad_norm": 4.323051452636719,
      "learning_rate": 5.569764979885666e-06,
      "loss": 0.6306,
      "step": 839750
    },
    {
      "epoch": 8.89044627119272,
      "grad_norm": 4.468323707580566,
      "learning_rate": 5.567118356976498e-06,
      "loss": 0.6311,
      "step": 839800
    },
    {
      "epoch": 8.890975592972724,
      "grad_norm": 4.5090837478637695,
      "learning_rate": 5.56447173406733e-06,
      "loss": 0.6181,
      "step": 839850
    },
    {
      "epoch": 8.891504914752728,
      "grad_norm": 5.416351795196533,
      "learning_rate": 5.561825111158162e-06,
      "loss": 0.6295,
      "step": 839900
    },
    {
      "epoch": 8.89203423653273,
      "grad_norm": 4.141539096832275,
      "learning_rate": 5.559178488248995e-06,
      "loss": 0.6274,
      "step": 839950
    },
    {
      "epoch": 8.892563558312734,
      "grad_norm": 4.971120834350586,
      "learning_rate": 5.556531865339826e-06,
      "loss": 0.6235,
      "step": 840000
    },
    {
      "epoch": 8.892563558312734,
      "eval_loss": 0.38254642486572266,
      "eval_runtime": 46.4823,
      "eval_samples_per_second": 3612.769,
      "eval_steps_per_second": 451.612,
      "step": 840000
    },
    {
      "epoch": 8.893092880092738,
      "grad_norm": 4.715826511383057,
      "learning_rate": 5.553885242430659e-06,
      "loss": 0.631,
      "step": 840050
    },
    {
      "epoch": 8.893622201872741,
      "grad_norm": 4.585133075714111,
      "learning_rate": 5.551238619521491e-06,
      "loss": 0.6322,
      "step": 840100
    },
    {
      "epoch": 8.894151523652743,
      "grad_norm": 4.168482780456543,
      "learning_rate": 5.5485919966123225e-06,
      "loss": 0.6232,
      "step": 840150
    },
    {
      "epoch": 8.894680845432747,
      "grad_norm": 4.456918716430664,
      "learning_rate": 5.545945373703155e-06,
      "loss": 0.6451,
      "step": 840200
    },
    {
      "epoch": 8.89521016721275,
      "grad_norm": 5.314884662628174,
      "learning_rate": 5.543298750793987e-06,
      "loss": 0.6515,
      "step": 840250
    },
    {
      "epoch": 8.895739488992753,
      "grad_norm": 4.916669845581055,
      "learning_rate": 5.540652127884819e-06,
      "loss": 0.6257,
      "step": 840300
    },
    {
      "epoch": 8.896268810772757,
      "grad_norm": 4.421614170074463,
      "learning_rate": 5.5380584374338345e-06,
      "loss": 0.6302,
      "step": 840350
    },
    {
      "epoch": 8.89679813255276,
      "grad_norm": 4.977803707122803,
      "learning_rate": 5.535411814524667e-06,
      "loss": 0.6297,
      "step": 840400
    },
    {
      "epoch": 8.897327454332764,
      "grad_norm": 4.679569721221924,
      "learning_rate": 5.5327651916154984e-06,
      "loss": 0.6257,
      "step": 840450
    },
    {
      "epoch": 8.897856776112766,
      "grad_norm": 4.593123912811279,
      "learning_rate": 5.530118568706331e-06,
      "loss": 0.6278,
      "step": 840500
    },
    {
      "epoch": 8.897856776112766,
      "eval_loss": 0.3825046420097351,
      "eval_runtime": 46.5275,
      "eval_samples_per_second": 3609.261,
      "eval_steps_per_second": 451.174,
      "step": 840500
    },
    {
      "epoch": 8.89838609789277,
      "grad_norm": 4.799005508422852,
      "learning_rate": 5.527471945797163e-06,
      "loss": 0.6164,
      "step": 840550
    },
    {
      "epoch": 8.898915419672774,
      "grad_norm": 4.715667247772217,
      "learning_rate": 5.524825322887995e-06,
      "loss": 0.6421,
      "step": 840600
    },
    {
      "epoch": 8.899444741452777,
      "grad_norm": 4.908699035644531,
      "learning_rate": 5.522178699978827e-06,
      "loss": 0.6342,
      "step": 840650
    },
    {
      "epoch": 8.89997406323278,
      "grad_norm": 4.414456844329834,
      "learning_rate": 5.519532077069659e-06,
      "loss": 0.6288,
      "step": 840700
    },
    {
      "epoch": 8.900503385012783,
      "grad_norm": 4.413511753082275,
      "learning_rate": 5.516885454160491e-06,
      "loss": 0.6276,
      "step": 840750
    },
    {
      "epoch": 8.901032706792787,
      "grad_norm": 4.603870868682861,
      "learning_rate": 5.514238831251324e-06,
      "loss": 0.6184,
      "step": 840800
    },
    {
      "epoch": 8.90156202857279,
      "grad_norm": 4.568220138549805,
      "learning_rate": 5.511592208342155e-06,
      "loss": 0.64,
      "step": 840850
    },
    {
      "epoch": 8.902091350352793,
      "grad_norm": 4.833334922790527,
      "learning_rate": 5.5089455854329875e-06,
      "loss": 0.6221,
      "step": 840900
    },
    {
      "epoch": 8.902620672132796,
      "grad_norm": 4.608765125274658,
      "learning_rate": 5.50629896252382e-06,
      "loss": 0.6238,
      "step": 840950
    },
    {
      "epoch": 8.9031499939128,
      "grad_norm": 4.864304065704346,
      "learning_rate": 5.5036523396146515e-06,
      "loss": 0.6155,
      "step": 841000
    },
    {
      "epoch": 8.9031499939128,
      "eval_loss": 0.3813247084617615,
      "eval_runtime": 46.5124,
      "eval_samples_per_second": 3610.436,
      "eval_steps_per_second": 451.321,
      "step": 841000
    },
    {
      "epoch": 8.903679315692802,
      "grad_norm": 4.550968647003174,
      "learning_rate": 5.501005716705484e-06,
      "loss": 0.6306,
      "step": 841050
    },
    {
      "epoch": 8.904208637472806,
      "grad_norm": 4.74814510345459,
      "learning_rate": 5.498359093796316e-06,
      "loss": 0.6266,
      "step": 841100
    },
    {
      "epoch": 8.90473795925281,
      "grad_norm": 4.487771511077881,
      "learning_rate": 5.495712470887148e-06,
      "loss": 0.6287,
      "step": 841150
    },
    {
      "epoch": 8.905267281032813,
      "grad_norm": 4.445925235748291,
      "learning_rate": 5.49306584797798e-06,
      "loss": 0.6381,
      "step": 841200
    },
    {
      "epoch": 8.905796602812815,
      "grad_norm": 4.839406490325928,
      "learning_rate": 5.490419225068813e-06,
      "loss": 0.6252,
      "step": 841250
    },
    {
      "epoch": 8.906325924592819,
      "grad_norm": 4.3538432121276855,
      "learning_rate": 5.487772602159644e-06,
      "loss": 0.63,
      "step": 841300
    },
    {
      "epoch": 8.906855246372823,
      "grad_norm": 4.565277576446533,
      "learning_rate": 5.485125979250477e-06,
      "loss": 0.6338,
      "step": 841350
    },
    {
      "epoch": 8.907384568152827,
      "grad_norm": 4.3173828125,
      "learning_rate": 5.482479356341308e-06,
      "loss": 0.6296,
      "step": 841400
    },
    {
      "epoch": 8.907913889932829,
      "grad_norm": 4.74619197845459,
      "learning_rate": 5.479832733432141e-06,
      "loss": 0.6318,
      "step": 841450
    },
    {
      "epoch": 8.908443211712832,
      "grad_norm": 4.569276332855225,
      "learning_rate": 5.477186110522973e-06,
      "loss": 0.627,
      "step": 841500
    },
    {
      "epoch": 8.908443211712832,
      "eval_loss": 0.3816145360469818,
      "eval_runtime": 46.5483,
      "eval_samples_per_second": 3607.652,
      "eval_steps_per_second": 450.973,
      "step": 841500
    },
    {
      "epoch": 8.908972533492836,
      "grad_norm": 4.688570022583008,
      "learning_rate": 5.474539487613805e-06,
      "loss": 0.6347,
      "step": 841550
    },
    {
      "epoch": 8.90950185527284,
      "grad_norm": 4.915903091430664,
      "learning_rate": 5.471892864704637e-06,
      "loss": 0.6352,
      "step": 841600
    },
    {
      "epoch": 8.910031177052842,
      "grad_norm": 4.2522358894348145,
      "learning_rate": 5.469246241795469e-06,
      "loss": 0.6302,
      "step": 841650
    },
    {
      "epoch": 8.910560498832846,
      "grad_norm": 4.564201354980469,
      "learning_rate": 5.466599618886301e-06,
      "loss": 0.6256,
      "step": 841700
    },
    {
      "epoch": 8.91108982061285,
      "grad_norm": 4.664394855499268,
      "learning_rate": 5.463952995977133e-06,
      "loss": 0.6369,
      "step": 841750
    },
    {
      "epoch": 8.911619142392851,
      "grad_norm": 4.612961769104004,
      "learning_rate": 5.461306373067966e-06,
      "loss": 0.6287,
      "step": 841800
    },
    {
      "epoch": 8.912148464172855,
      "grad_norm": 5.116419792175293,
      "learning_rate": 5.458659750158797e-06,
      "loss": 0.6386,
      "step": 841850
    },
    {
      "epoch": 8.912677785952859,
      "grad_norm": 4.3912811279296875,
      "learning_rate": 5.45601312724963e-06,
      "loss": 0.6184,
      "step": 841900
    },
    {
      "epoch": 8.913207107732863,
      "grad_norm": 4.831226348876953,
      "learning_rate": 5.453366504340462e-06,
      "loss": 0.6343,
      "step": 841950
    },
    {
      "epoch": 8.913736429512864,
      "grad_norm": 4.799702167510986,
      "learning_rate": 5.450719881431294e-06,
      "loss": 0.6281,
      "step": 842000
    },
    {
      "epoch": 8.913736429512864,
      "eval_loss": 0.3819149434566498,
      "eval_runtime": 46.6358,
      "eval_samples_per_second": 3600.885,
      "eval_steps_per_second": 450.127,
      "step": 842000
    },
    {
      "epoch": 8.914265751292868,
      "grad_norm": 4.606351375579834,
      "learning_rate": 5.448073258522126e-06,
      "loss": 0.6223,
      "step": 842050
    },
    {
      "epoch": 8.914795073072872,
      "grad_norm": 4.662092685699463,
      "learning_rate": 5.4454266356129585e-06,
      "loss": 0.6254,
      "step": 842100
    },
    {
      "epoch": 8.915324394852876,
      "grad_norm": 4.597044467926025,
      "learning_rate": 5.44278001270379e-06,
      "loss": 0.6234,
      "step": 842150
    },
    {
      "epoch": 8.915853716632878,
      "grad_norm": 4.437833309173584,
      "learning_rate": 5.4401333897946225e-06,
      "loss": 0.6286,
      "step": 842200
    },
    {
      "epoch": 8.916383038412881,
      "grad_norm": 4.537563323974609,
      "learning_rate": 5.437486766885454e-06,
      "loss": 0.6323,
      "step": 842250
    },
    {
      "epoch": 8.916912360192885,
      "grad_norm": 4.677378177642822,
      "learning_rate": 5.4348401439762864e-06,
      "loss": 0.623,
      "step": 842300
    },
    {
      "epoch": 8.917441681972889,
      "grad_norm": 4.630372524261475,
      "learning_rate": 5.432193521067119e-06,
      "loss": 0.6401,
      "step": 842350
    },
    {
      "epoch": 8.917971003752891,
      "grad_norm": 4.891300678253174,
      "learning_rate": 5.42954689815795e-06,
      "loss": 0.6318,
      "step": 842400
    },
    {
      "epoch": 8.918500325532895,
      "grad_norm": 4.921111583709717,
      "learning_rate": 5.426900275248783e-06,
      "loss": 0.6362,
      "step": 842450
    },
    {
      "epoch": 8.919029647312898,
      "grad_norm": 4.55397891998291,
      "learning_rate": 5.424253652339615e-06,
      "loss": 0.6387,
      "step": 842500
    },
    {
      "epoch": 8.919029647312898,
      "eval_loss": 0.38253435492515564,
      "eval_runtime": 46.5584,
      "eval_samples_per_second": 3606.864,
      "eval_steps_per_second": 450.874,
      "step": 842500
    },
    {
      "epoch": 8.9195589690929,
      "grad_norm": 4.432424068450928,
      "learning_rate": 5.421607029430447e-06,
      "loss": 0.6332,
      "step": 842550
    },
    {
      "epoch": 8.920088290872904,
      "grad_norm": 4.364151954650879,
      "learning_rate": 5.418960406521279e-06,
      "loss": 0.6373,
      "step": 842600
    },
    {
      "epoch": 8.920617612652908,
      "grad_norm": 4.344147205352783,
      "learning_rate": 5.416313783612112e-06,
      "loss": 0.6301,
      "step": 842650
    },
    {
      "epoch": 8.921146934432912,
      "grad_norm": 4.568081855773926,
      "learning_rate": 5.413667160702943e-06,
      "loss": 0.6249,
      "step": 842700
    },
    {
      "epoch": 8.921676256212914,
      "grad_norm": 5.043910503387451,
      "learning_rate": 5.4110205377937756e-06,
      "loss": 0.6311,
      "step": 842750
    },
    {
      "epoch": 8.922205577992917,
      "grad_norm": 4.337831497192383,
      "learning_rate": 5.408373914884608e-06,
      "loss": 0.6355,
      "step": 842800
    },
    {
      "epoch": 8.922734899772921,
      "grad_norm": 4.427189826965332,
      "learning_rate": 5.4057272919754395e-06,
      "loss": 0.6251,
      "step": 842850
    },
    {
      "epoch": 8.923264221552925,
      "grad_norm": 4.7327094078063965,
      "learning_rate": 5.403080669066272e-06,
      "loss": 0.6173,
      "step": 842900
    },
    {
      "epoch": 8.923793543332927,
      "grad_norm": 4.71011209487915,
      "learning_rate": 5.4004340461571035e-06,
      "loss": 0.6291,
      "step": 842950
    },
    {
      "epoch": 8.92432286511293,
      "grad_norm": 4.67318868637085,
      "learning_rate": 5.397787423247936e-06,
      "loss": 0.6233,
      "step": 843000
    },
    {
      "epoch": 8.92432286511293,
      "eval_loss": 0.38193371891975403,
      "eval_runtime": 46.454,
      "eval_samples_per_second": 3614.973,
      "eval_steps_per_second": 451.888,
      "step": 843000
    },
    {
      "epoch": 8.924852186892934,
      "grad_norm": 4.329514026641846,
      "learning_rate": 5.395140800338768e-06,
      "loss": 0.6357,
      "step": 843050
    },
    {
      "epoch": 8.925381508672938,
      "grad_norm": 4.546424388885498,
      "learning_rate": 5.3924941774296e-06,
      "loss": 0.6277,
      "step": 843100
    },
    {
      "epoch": 8.92591083045294,
      "grad_norm": 4.492308139801025,
      "learning_rate": 5.389847554520432e-06,
      "loss": 0.6248,
      "step": 843150
    },
    {
      "epoch": 8.926440152232944,
      "grad_norm": 4.485710144042969,
      "learning_rate": 5.387200931611265e-06,
      "loss": 0.6271,
      "step": 843200
    },
    {
      "epoch": 8.926969474012948,
      "grad_norm": 4.742648124694824,
      "learning_rate": 5.384554308702096e-06,
      "loss": 0.6274,
      "step": 843250
    },
    {
      "epoch": 8.92749879579295,
      "grad_norm": 4.853438377380371,
      "learning_rate": 5.381907685792929e-06,
      "loss": 0.6324,
      "step": 843300
    },
    {
      "epoch": 8.928028117572953,
      "grad_norm": 4.546560287475586,
      "learning_rate": 5.379261062883761e-06,
      "loss": 0.6206,
      "step": 843350
    },
    {
      "epoch": 8.928557439352957,
      "grad_norm": 4.3698554039001465,
      "learning_rate": 5.376614439974593e-06,
      "loss": 0.6332,
      "step": 843400
    },
    {
      "epoch": 8.929086761132961,
      "grad_norm": 4.586378574371338,
      "learning_rate": 5.373967817065425e-06,
      "loss": 0.6356,
      "step": 843450
    },
    {
      "epoch": 8.929616082912963,
      "grad_norm": 4.587352752685547,
      "learning_rate": 5.371321194156257e-06,
      "loss": 0.6419,
      "step": 843500
    },
    {
      "epoch": 8.929616082912963,
      "eval_loss": 0.38192880153656006,
      "eval_runtime": 46.4325,
      "eval_samples_per_second": 3616.649,
      "eval_steps_per_second": 452.097,
      "step": 843500
    },
    {
      "epoch": 8.930145404692967,
      "grad_norm": 4.492700099945068,
      "learning_rate": 5.368674571247089e-06,
      "loss": 0.6315,
      "step": 843550
    },
    {
      "epoch": 8.93067472647297,
      "grad_norm": 4.570479393005371,
      "learning_rate": 5.366027948337921e-06,
      "loss": 0.6233,
      "step": 843600
    },
    {
      "epoch": 8.931204048252974,
      "grad_norm": 4.3382649421691895,
      "learning_rate": 5.363381325428754e-06,
      "loss": 0.6363,
      "step": 843650
    },
    {
      "epoch": 8.931733370032976,
      "grad_norm": 5.030790328979492,
      "learning_rate": 5.360734702519585e-06,
      "loss": 0.6274,
      "step": 843700
    },
    {
      "epoch": 8.93226269181298,
      "grad_norm": 4.67173957824707,
      "learning_rate": 5.358088079610418e-06,
      "loss": 0.6253,
      "step": 843750
    },
    {
      "epoch": 8.932792013592984,
      "grad_norm": 4.192096710205078,
      "learning_rate": 5.355441456701249e-06,
      "loss": 0.6227,
      "step": 843800
    },
    {
      "epoch": 8.933321335372987,
      "grad_norm": 4.159437656402588,
      "learning_rate": 5.352794833792082e-06,
      "loss": 0.6206,
      "step": 843850
    },
    {
      "epoch": 8.93385065715299,
      "grad_norm": 4.758802890777588,
      "learning_rate": 5.350148210882914e-06,
      "loss": 0.6344,
      "step": 843900
    },
    {
      "epoch": 8.934379978932993,
      "grad_norm": 4.854851722717285,
      "learning_rate": 5.347501587973746e-06,
      "loss": 0.6317,
      "step": 843950
    },
    {
      "epoch": 8.934909300712997,
      "grad_norm": 5.0875020027160645,
      "learning_rate": 5.344854965064578e-06,
      "loss": 0.6373,
      "step": 844000
    },
    {
      "epoch": 8.934909300712997,
      "eval_loss": 0.3814500868320465,
      "eval_runtime": 46.4619,
      "eval_samples_per_second": 3614.361,
      "eval_steps_per_second": 451.811,
      "step": 844000
    },
    {
      "epoch": 8.935438622492999,
      "grad_norm": 4.579963684082031,
      "learning_rate": 5.3422083421554105e-06,
      "loss": 0.6277,
      "step": 844050
    },
    {
      "epoch": 8.935967944273003,
      "grad_norm": 5.224242687225342,
      "learning_rate": 5.339561719246242e-06,
      "loss": 0.6322,
      "step": 844100
    },
    {
      "epoch": 8.936497266053006,
      "grad_norm": 4.490993499755859,
      "learning_rate": 5.3369150963370744e-06,
      "loss": 0.6302,
      "step": 844150
    },
    {
      "epoch": 8.93702658783301,
      "grad_norm": 4.637631893157959,
      "learning_rate": 5.334268473427907e-06,
      "loss": 0.6227,
      "step": 844200
    },
    {
      "epoch": 8.937555909613012,
      "grad_norm": 4.358561038970947,
      "learning_rate": 5.331621850518738e-06,
      "loss": 0.6276,
      "step": 844250
    },
    {
      "epoch": 8.938085231393016,
      "grad_norm": 4.878026485443115,
      "learning_rate": 5.328975227609571e-06,
      "loss": 0.6257,
      "step": 844300
    },
    {
      "epoch": 8.93861455317302,
      "grad_norm": 4.21347188949585,
      "learning_rate": 5.326381537158586e-06,
      "loss": 0.6202,
      "step": 844350
    },
    {
      "epoch": 8.939143874953023,
      "grad_norm": 5.425238609313965,
      "learning_rate": 5.323734914249418e-06,
      "loss": 0.6454,
      "step": 844400
    },
    {
      "epoch": 8.939673196733025,
      "grad_norm": 5.042641639709473,
      "learning_rate": 5.32108829134025e-06,
      "loss": 0.6309,
      "step": 844450
    },
    {
      "epoch": 8.94020251851303,
      "grad_norm": 4.282987117767334,
      "learning_rate": 5.318441668431083e-06,
      "loss": 0.6271,
      "step": 844500
    },
    {
      "epoch": 8.94020251851303,
      "eval_loss": 0.3818124532699585,
      "eval_runtime": 46.4585,
      "eval_samples_per_second": 3614.628,
      "eval_steps_per_second": 451.845,
      "step": 844500
    },
    {
      "epoch": 8.940731840293033,
      "grad_norm": 4.432338237762451,
      "learning_rate": 5.315795045521914e-06,
      "loss": 0.6325,
      "step": 844550
    },
    {
      "epoch": 8.941261162073037,
      "grad_norm": 4.456295967102051,
      "learning_rate": 5.313148422612747e-06,
      "loss": 0.6215,
      "step": 844600
    },
    {
      "epoch": 8.941790483853039,
      "grad_norm": 4.810654163360596,
      "learning_rate": 5.310501799703579e-06,
      "loss": 0.6218,
      "step": 844650
    },
    {
      "epoch": 8.942319805633042,
      "grad_norm": 4.612507343292236,
      "learning_rate": 5.307855176794411e-06,
      "loss": 0.6236,
      "step": 844700
    },
    {
      "epoch": 8.942849127413046,
      "grad_norm": 4.294724464416504,
      "learning_rate": 5.305208553885243e-06,
      "loss": 0.632,
      "step": 844750
    },
    {
      "epoch": 8.943378449193048,
      "grad_norm": 4.584832191467285,
      "learning_rate": 5.302561930976075e-06,
      "loss": 0.6286,
      "step": 844800
    },
    {
      "epoch": 8.943907770973052,
      "grad_norm": 5.054141998291016,
      "learning_rate": 5.299915308066907e-06,
      "loss": 0.6303,
      "step": 844850
    },
    {
      "epoch": 8.944437092753056,
      "grad_norm": 4.868541717529297,
      "learning_rate": 5.2972686851577394e-06,
      "loss": 0.6256,
      "step": 844900
    },
    {
      "epoch": 8.94496641453306,
      "grad_norm": 4.593629360198975,
      "learning_rate": 5.294622062248571e-06,
      "loss": 0.632,
      "step": 844950
    },
    {
      "epoch": 8.945495736313061,
      "grad_norm": 4.990962028503418,
      "learning_rate": 5.291975439339403e-06,
      "loss": 0.622,
      "step": 845000
    },
    {
      "epoch": 8.945495736313061,
      "eval_loss": 0.3822394907474518,
      "eval_runtime": 46.5088,
      "eval_samples_per_second": 3610.718,
      "eval_steps_per_second": 451.356,
      "step": 845000
    },
    {
      "epoch": 8.946025058093065,
      "grad_norm": 4.678302764892578,
      "learning_rate": 5.289328816430236e-06,
      "loss": 0.6245,
      "step": 845050
    },
    {
      "epoch": 8.946554379873069,
      "grad_norm": 4.747462272644043,
      "learning_rate": 5.286682193521067e-06,
      "loss": 0.6316,
      "step": 845100
    },
    {
      "epoch": 8.947083701653073,
      "grad_norm": 4.494369029998779,
      "learning_rate": 5.2840355706119e-06,
      "loss": 0.6246,
      "step": 845150
    },
    {
      "epoch": 8.947613023433075,
      "grad_norm": 5.017329216003418,
      "learning_rate": 5.281388947702732e-06,
      "loss": 0.628,
      "step": 845200
    },
    {
      "epoch": 8.948142345213078,
      "grad_norm": 4.7733073234558105,
      "learning_rate": 5.278742324793564e-06,
      "loss": 0.6287,
      "step": 845250
    },
    {
      "epoch": 8.948671666993082,
      "grad_norm": 5.022088527679443,
      "learning_rate": 5.276095701884396e-06,
      "loss": 0.6491,
      "step": 845300
    },
    {
      "epoch": 8.949200988773086,
      "grad_norm": 4.829833984375,
      "learning_rate": 5.2734490789752286e-06,
      "loss": 0.6308,
      "step": 845350
    },
    {
      "epoch": 8.949730310553088,
      "grad_norm": 5.014870643615723,
      "learning_rate": 5.27080245606606e-06,
      "loss": 0.6286,
      "step": 845400
    },
    {
      "epoch": 8.950259632333092,
      "grad_norm": 4.7943902015686035,
      "learning_rate": 5.2681558331568925e-06,
      "loss": 0.6332,
      "step": 845450
    },
    {
      "epoch": 8.950788954113095,
      "grad_norm": 4.965732574462891,
      "learning_rate": 5.265509210247724e-06,
      "loss": 0.6235,
      "step": 845500
    },
    {
      "epoch": 8.950788954113095,
      "eval_loss": 0.3817622661590576,
      "eval_runtime": 46.4792,
      "eval_samples_per_second": 3613.014,
      "eval_steps_per_second": 451.643,
      "step": 845500
    },
    {
      "epoch": 8.951318275893097,
      "grad_norm": 4.635618686676025,
      "learning_rate": 5.262862587338556e-06,
      "loss": 0.6356,
      "step": 845550
    },
    {
      "epoch": 8.951847597673101,
      "grad_norm": 4.951818466186523,
      "learning_rate": 5.260215964429388e-06,
      "loss": 0.6238,
      "step": 845600
    },
    {
      "epoch": 8.952376919453105,
      "grad_norm": 4.749390602111816,
      "learning_rate": 5.2575693415202205e-06,
      "loss": 0.6324,
      "step": 845650
    },
    {
      "epoch": 8.952906241233109,
      "grad_norm": 4.9322896003723145,
      "learning_rate": 5.254922718611052e-06,
      "loss": 0.6407,
      "step": 845700
    },
    {
      "epoch": 8.95343556301311,
      "grad_norm": 4.6397294998168945,
      "learning_rate": 5.252276095701884e-06,
      "loss": 0.6193,
      "step": 845750
    },
    {
      "epoch": 8.953964884793114,
      "grad_norm": 4.644547462463379,
      "learning_rate": 5.249629472792717e-06,
      "loss": 0.6357,
      "step": 845800
    },
    {
      "epoch": 8.954494206573118,
      "grad_norm": 4.568100929260254,
      "learning_rate": 5.246982849883548e-06,
      "loss": 0.6391,
      "step": 845850
    },
    {
      "epoch": 8.955023528353122,
      "grad_norm": 4.64183235168457,
      "learning_rate": 5.244336226974381e-06,
      "loss": 0.6239,
      "step": 845900
    },
    {
      "epoch": 8.955552850133124,
      "grad_norm": 4.563486099243164,
      "learning_rate": 5.241689604065212e-06,
      "loss": 0.6343,
      "step": 845950
    },
    {
      "epoch": 8.956082171913128,
      "grad_norm": 5.052674293518066,
      "learning_rate": 5.239042981156045e-06,
      "loss": 0.6286,
      "step": 846000
    },
    {
      "epoch": 8.956082171913128,
      "eval_loss": 0.3815179169178009,
      "eval_runtime": 46.4261,
      "eval_samples_per_second": 3617.148,
      "eval_steps_per_second": 452.16,
      "step": 846000
    },
    {
      "epoch": 8.956611493693131,
      "grad_norm": 4.626883029937744,
      "learning_rate": 5.236396358246877e-06,
      "loss": 0.6371,
      "step": 846050
    },
    {
      "epoch": 8.957140815473135,
      "grad_norm": 5.163090705871582,
      "learning_rate": 5.233749735337709e-06,
      "loss": 0.6293,
      "step": 846100
    },
    {
      "epoch": 8.957670137253137,
      "grad_norm": 4.575453281402588,
      "learning_rate": 5.231103112428541e-06,
      "loss": 0.6338,
      "step": 846150
    },
    {
      "epoch": 8.95819945903314,
      "grad_norm": 5.149033546447754,
      "learning_rate": 5.2284564895193735e-06,
      "loss": 0.6356,
      "step": 846200
    },
    {
      "epoch": 8.958728780813145,
      "grad_norm": 4.643966197967529,
      "learning_rate": 5.225809866610205e-06,
      "loss": 0.6352,
      "step": 846250
    },
    {
      "epoch": 8.959258102593147,
      "grad_norm": 4.4749956130981445,
      "learning_rate": 5.2231632437010375e-06,
      "loss": 0.6282,
      "step": 846300
    },
    {
      "epoch": 8.95978742437315,
      "grad_norm": 4.553954601287842,
      "learning_rate": 5.220569553250053e-06,
      "loss": 0.632,
      "step": 846350
    },
    {
      "epoch": 8.960316746153154,
      "grad_norm": 4.689632892608643,
      "learning_rate": 5.217922930340885e-06,
      "loss": 0.6377,
      "step": 846400
    },
    {
      "epoch": 8.960846067933158,
      "grad_norm": 5.018474578857422,
      "learning_rate": 5.215276307431717e-06,
      "loss": 0.6309,
      "step": 846450
    },
    {
      "epoch": 8.96137538971316,
      "grad_norm": 4.909636497497559,
      "learning_rate": 5.212629684522549e-06,
      "loss": 0.6348,
      "step": 846500
    },
    {
      "epoch": 8.96137538971316,
      "eval_loss": 0.3817177712917328,
      "eval_runtime": 46.5081,
      "eval_samples_per_second": 3610.766,
      "eval_steps_per_second": 451.362,
      "step": 846500
    },
    {
      "epoch": 8.961904711493164,
      "grad_norm": 4.84687614440918,
      "learning_rate": 5.209983061613381e-06,
      "loss": 0.6145,
      "step": 846550
    },
    {
      "epoch": 8.962434033273167,
      "grad_norm": 4.947817802429199,
      "learning_rate": 5.207336438704213e-06,
      "loss": 0.6124,
      "step": 846600
    },
    {
      "epoch": 8.962963355053171,
      "grad_norm": 4.701788425445557,
      "learning_rate": 5.204689815795046e-06,
      "loss": 0.6179,
      "step": 846650
    },
    {
      "epoch": 8.963492676833173,
      "grad_norm": 4.395744800567627,
      "learning_rate": 5.202043192885877e-06,
      "loss": 0.625,
      "step": 846700
    },
    {
      "epoch": 8.964021998613177,
      "grad_norm": 4.495199203491211,
      "learning_rate": 5.19939656997671e-06,
      "loss": 0.6292,
      "step": 846750
    },
    {
      "epoch": 8.96455132039318,
      "grad_norm": 4.8951263427734375,
      "learning_rate": 5.196749947067542e-06,
      "loss": 0.6351,
      "step": 846800
    },
    {
      "epoch": 8.965080642173184,
      "grad_norm": 4.731380939483643,
      "learning_rate": 5.194103324158374e-06,
      "loss": 0.6187,
      "step": 846850
    },
    {
      "epoch": 8.965609963953186,
      "grad_norm": 4.376023292541504,
      "learning_rate": 5.191456701249206e-06,
      "loss": 0.6203,
      "step": 846900
    },
    {
      "epoch": 8.96613928573319,
      "grad_norm": 4.123359680175781,
      "learning_rate": 5.1888100783400385e-06,
      "loss": 0.6156,
      "step": 846950
    },
    {
      "epoch": 8.966668607513194,
      "grad_norm": 4.452480792999268,
      "learning_rate": 5.18616345543087e-06,
      "loss": 0.6214,
      "step": 847000
    },
    {
      "epoch": 8.966668607513194,
      "eval_loss": 0.38124772906303406,
      "eval_runtime": 46.5181,
      "eval_samples_per_second": 3609.992,
      "eval_steps_per_second": 451.265,
      "step": 847000
    },
    {
      "epoch": 8.967197929293196,
      "grad_norm": 4.283952236175537,
      "learning_rate": 5.1835168325217025e-06,
      "loss": 0.6185,
      "step": 847050
    },
    {
      "epoch": 8.9677272510732,
      "grad_norm": 4.463393211364746,
      "learning_rate": 5.180870209612534e-06,
      "loss": 0.6233,
      "step": 847100
    },
    {
      "epoch": 8.968256572853203,
      "grad_norm": 4.630971431732178,
      "learning_rate": 5.1782235867033665e-06,
      "loss": 0.6244,
      "step": 847150
    },
    {
      "epoch": 8.968785894633207,
      "grad_norm": 5.074113368988037,
      "learning_rate": 5.175576963794199e-06,
      "loss": 0.6263,
      "step": 847200
    },
    {
      "epoch": 8.969315216413209,
      "grad_norm": 4.570949077606201,
      "learning_rate": 5.1729303408850304e-06,
      "loss": 0.6322,
      "step": 847250
    },
    {
      "epoch": 8.969844538193213,
      "grad_norm": 4.345883369445801,
      "learning_rate": 5.170283717975863e-06,
      "loss": 0.6441,
      "step": 847300
    },
    {
      "epoch": 8.970373859973217,
      "grad_norm": 4.3940253257751465,
      "learning_rate": 5.167637095066695e-06,
      "loss": 0.6263,
      "step": 847350
    },
    {
      "epoch": 8.97090318175322,
      "grad_norm": 4.574072360992432,
      "learning_rate": 5.164990472157527e-06,
      "loss": 0.6296,
      "step": 847400
    },
    {
      "epoch": 8.971432503533222,
      "grad_norm": 4.549519062042236,
      "learning_rate": 5.162343849248359e-06,
      "loss": 0.6345,
      "step": 847450
    },
    {
      "epoch": 8.971961825313226,
      "grad_norm": 4.336755752563477,
      "learning_rate": 5.159697226339192e-06,
      "loss": 0.629,
      "step": 847500
    },
    {
      "epoch": 8.971961825313226,
      "eval_loss": 0.3818093538284302,
      "eval_runtime": 46.4231,
      "eval_samples_per_second": 3617.379,
      "eval_steps_per_second": 452.189,
      "step": 847500
    },
    {
      "epoch": 8.97249114709323,
      "grad_norm": 4.926136493682861,
      "learning_rate": 5.157050603430023e-06,
      "loss": 0.6284,
      "step": 847550
    },
    {
      "epoch": 8.973020468873234,
      "grad_norm": 4.837670803070068,
      "learning_rate": 5.1544039805208556e-06,
      "loss": 0.6321,
      "step": 847600
    },
    {
      "epoch": 8.973549790653236,
      "grad_norm": 4.69260311126709,
      "learning_rate": 5.151757357611688e-06,
      "loss": 0.6345,
      "step": 847650
    },
    {
      "epoch": 8.97407911243324,
      "grad_norm": 4.604122638702393,
      "learning_rate": 5.1491107347025195e-06,
      "loss": 0.629,
      "step": 847700
    },
    {
      "epoch": 8.974608434213243,
      "grad_norm": 4.508882522583008,
      "learning_rate": 5.146464111793352e-06,
      "loss": 0.6251,
      "step": 847750
    },
    {
      "epoch": 8.975137755993245,
      "grad_norm": 4.603330612182617,
      "learning_rate": 5.1438174888841835e-06,
      "loss": 0.6343,
      "step": 847800
    },
    {
      "epoch": 8.975667077773249,
      "grad_norm": 4.664026260375977,
      "learning_rate": 5.141170865975016e-06,
      "loss": 0.6333,
      "step": 847850
    },
    {
      "epoch": 8.976196399553253,
      "grad_norm": 4.688724994659424,
      "learning_rate": 5.138524243065848e-06,
      "loss": 0.6352,
      "step": 847900
    },
    {
      "epoch": 8.976725721333256,
      "grad_norm": 4.625537395477295,
      "learning_rate": 5.13587762015668e-06,
      "loss": 0.6226,
      "step": 847950
    },
    {
      "epoch": 8.977255043113258,
      "grad_norm": 4.599609375,
      "learning_rate": 5.133230997247512e-06,
      "loss": 0.6278,
      "step": 848000
    },
    {
      "epoch": 8.977255043113258,
      "eval_loss": 0.3816927373409271,
      "eval_runtime": 46.4568,
      "eval_samples_per_second": 3614.76,
      "eval_steps_per_second": 451.861,
      "step": 848000
    },
    {
      "epoch": 8.977784364893262,
      "grad_norm": 4.4715447425842285,
      "learning_rate": 5.130584374338345e-06,
      "loss": 0.6302,
      "step": 848050
    },
    {
      "epoch": 8.978313686673266,
      "grad_norm": 4.883996486663818,
      "learning_rate": 5.127937751429176e-06,
      "loss": 0.6314,
      "step": 848100
    },
    {
      "epoch": 8.97884300845327,
      "grad_norm": 4.603970050811768,
      "learning_rate": 5.125291128520009e-06,
      "loss": 0.6201,
      "step": 848150
    },
    {
      "epoch": 8.979372330233272,
      "grad_norm": 4.501923561096191,
      "learning_rate": 5.122644505610841e-06,
      "loss": 0.62,
      "step": 848200
    },
    {
      "epoch": 8.979901652013275,
      "grad_norm": 4.694490432739258,
      "learning_rate": 5.119997882701673e-06,
      "loss": 0.6238,
      "step": 848250
    },
    {
      "epoch": 8.980430973793279,
      "grad_norm": 4.711843013763428,
      "learning_rate": 5.117351259792505e-06,
      "loss": 0.6258,
      "step": 848300
    },
    {
      "epoch": 8.980960295573283,
      "grad_norm": 4.83240270614624,
      "learning_rate": 5.1147575693415206e-06,
      "loss": 0.6296,
      "step": 848350
    },
    {
      "epoch": 8.981489617353285,
      "grad_norm": 4.210444927215576,
      "learning_rate": 5.112110946432352e-06,
      "loss": 0.6273,
      "step": 848400
    },
    {
      "epoch": 8.982018939133289,
      "grad_norm": 4.6724348068237305,
      "learning_rate": 5.1094643235231845e-06,
      "loss": 0.6289,
      "step": 848450
    },
    {
      "epoch": 8.982548260913292,
      "grad_norm": 4.474752426147461,
      "learning_rate": 5.106817700614017e-06,
      "loss": 0.6389,
      "step": 848500
    },
    {
      "epoch": 8.982548260913292,
      "eval_loss": 0.38117608428001404,
      "eval_runtime": 46.4356,
      "eval_samples_per_second": 3616.406,
      "eval_steps_per_second": 452.067,
      "step": 848500
    },
    {
      "epoch": 8.983077582693294,
      "grad_norm": 4.763004779815674,
      "learning_rate": 5.1041710777048485e-06,
      "loss": 0.6363,
      "step": 848550
    },
    {
      "epoch": 8.983606904473298,
      "grad_norm": 4.2996625900268555,
      "learning_rate": 5.101524454795681e-06,
      "loss": 0.6265,
      "step": 848600
    },
    {
      "epoch": 8.984136226253302,
      "grad_norm": 4.368515968322754,
      "learning_rate": 5.098877831886513e-06,
      "loss": 0.6444,
      "step": 848650
    },
    {
      "epoch": 8.984665548033306,
      "grad_norm": 4.372609615325928,
      "learning_rate": 5.096231208977345e-06,
      "loss": 0.6221,
      "step": 848700
    },
    {
      "epoch": 8.985194869813308,
      "grad_norm": 4.915044784545898,
      "learning_rate": 5.093584586068177e-06,
      "loss": 0.6266,
      "step": 848750
    },
    {
      "epoch": 8.985724191593311,
      "grad_norm": 4.600132942199707,
      "learning_rate": 5.09093796315901e-06,
      "loss": 0.6256,
      "step": 848800
    },
    {
      "epoch": 8.986253513373315,
      "grad_norm": 4.754253387451172,
      "learning_rate": 5.088291340249841e-06,
      "loss": 0.6225,
      "step": 848850
    },
    {
      "epoch": 8.986782835153319,
      "grad_norm": 4.424620628356934,
      "learning_rate": 5.085644717340674e-06,
      "loss": 0.6292,
      "step": 848900
    },
    {
      "epoch": 8.98731215693332,
      "grad_norm": 4.551993370056152,
      "learning_rate": 5.082998094431505e-06,
      "loss": 0.6192,
      "step": 848950
    },
    {
      "epoch": 8.987841478713325,
      "grad_norm": 5.179201602935791,
      "learning_rate": 5.080351471522338e-06,
      "loss": 0.6404,
      "step": 849000
    },
    {
      "epoch": 8.987841478713325,
      "eval_loss": 0.3817159831523895,
      "eval_runtime": 46.4691,
      "eval_samples_per_second": 3613.796,
      "eval_steps_per_second": 451.741,
      "step": 849000
    },
    {
      "epoch": 8.988370800493328,
      "grad_norm": 4.703484535217285,
      "learning_rate": 5.07770484861317e-06,
      "loss": 0.6362,
      "step": 849050
    },
    {
      "epoch": 8.988900122273332,
      "grad_norm": 4.502859592437744,
      "learning_rate": 5.075058225704002e-06,
      "loss": 0.642,
      "step": 849100
    },
    {
      "epoch": 8.989429444053334,
      "grad_norm": 4.654438495635986,
      "learning_rate": 5.072411602794834e-06,
      "loss": 0.6372,
      "step": 849150
    },
    {
      "epoch": 8.989958765833338,
      "grad_norm": 4.44593620300293,
      "learning_rate": 5.069764979885666e-06,
      "loss": 0.6314,
      "step": 849200
    },
    {
      "epoch": 8.990488087613342,
      "grad_norm": 4.322621822357178,
      "learning_rate": 5.067118356976498e-06,
      "loss": 0.628,
      "step": 849250
    },
    {
      "epoch": 8.991017409393343,
      "grad_norm": 4.563497543334961,
      "learning_rate": 5.06447173406733e-06,
      "loss": 0.6342,
      "step": 849300
    },
    {
      "epoch": 8.991546731173347,
      "grad_norm": 4.3554463386535645,
      "learning_rate": 5.061825111158163e-06,
      "loss": 0.6346,
      "step": 849350
    },
    {
      "epoch": 8.992076052953351,
      "grad_norm": 4.222068786621094,
      "learning_rate": 5.059178488248994e-06,
      "loss": 0.6237,
      "step": 849400
    },
    {
      "epoch": 8.992605374733355,
      "grad_norm": 4.303872585296631,
      "learning_rate": 5.056531865339827e-06,
      "loss": 0.6243,
      "step": 849450
    },
    {
      "epoch": 8.993134696513357,
      "grad_norm": 4.277383804321289,
      "learning_rate": 5.053885242430659e-06,
      "loss": 0.6227,
      "step": 849500
    },
    {
      "epoch": 8.993134696513357,
      "eval_loss": 0.38102319836616516,
      "eval_runtime": 46.5024,
      "eval_samples_per_second": 3611.21,
      "eval_steps_per_second": 451.417,
      "step": 849500
    },
    {
      "epoch": 8.99366401829336,
      "grad_norm": 5.096375465393066,
      "learning_rate": 5.051238619521491e-06,
      "loss": 0.6249,
      "step": 849550
    },
    {
      "epoch": 8.994193340073364,
      "grad_norm": 4.975811004638672,
      "learning_rate": 5.048591996612323e-06,
      "loss": 0.6298,
      "step": 849600
    },
    {
      "epoch": 8.994722661853368,
      "grad_norm": 4.813176155090332,
      "learning_rate": 5.045945373703155e-06,
      "loss": 0.6178,
      "step": 849650
    },
    {
      "epoch": 8.99525198363337,
      "grad_norm": 4.803305149078369,
      "learning_rate": 5.043298750793987e-06,
      "loss": 0.6323,
      "step": 849700
    },
    {
      "epoch": 8.995781305413374,
      "grad_norm": 4.351830959320068,
      "learning_rate": 5.0406521278848195e-06,
      "loss": 0.6178,
      "step": 849750
    },
    {
      "epoch": 8.996310627193377,
      "grad_norm": 4.328810214996338,
      "learning_rate": 5.038005504975651e-06,
      "loss": 0.6355,
      "step": 849800
    },
    {
      "epoch": 8.996839948973381,
      "grad_norm": 4.633578777313232,
      "learning_rate": 5.0353588820664834e-06,
      "loss": 0.6324,
      "step": 849850
    },
    {
      "epoch": 8.997369270753383,
      "grad_norm": 4.439827919006348,
      "learning_rate": 5.032712259157316e-06,
      "loss": 0.6251,
      "step": 849900
    },
    {
      "epoch": 8.997898592533387,
      "grad_norm": 4.74936056137085,
      "learning_rate": 5.030065636248147e-06,
      "loss": 0.6291,
      "step": 849950
    },
    {
      "epoch": 8.99842791431339,
      "grad_norm": 4.649730682373047,
      "learning_rate": 5.02741901333898e-06,
      "loss": 0.624,
      "step": 850000
    },
    {
      "epoch": 8.99842791431339,
      "eval_loss": 0.38098999857902527,
      "eval_runtime": 46.4655,
      "eval_samples_per_second": 3614.079,
      "eval_steps_per_second": 451.776,
      "step": 850000
    },
    {
      "epoch": 8.998957236093393,
      "grad_norm": 4.782647609710693,
      "learning_rate": 5.024772390429812e-06,
      "loss": 0.625,
      "step": 850050
    },
    {
      "epoch": 8.999486557873396,
      "grad_norm": 4.740460395812988,
      "learning_rate": 5.022125767520644e-06,
      "loss": 0.6284,
      "step": 850100
    },
    {
      "epoch": 9.0000105864356,
      "grad_norm": 4.920650959014893,
      "learning_rate": 5.019479144611476e-06,
      "loss": 0.626,
      "step": 850150
    },
    {
      "epoch": 9.000539908215604,
      "grad_norm": 4.584323406219482,
      "learning_rate": 5.016832521702309e-06,
      "loss": 0.632,
      "step": 850200
    },
    {
      "epoch": 9.001069229995606,
      "grad_norm": 4.480442523956299,
      "learning_rate": 5.01418589879314e-06,
      "loss": 0.6179,
      "step": 850250
    },
    {
      "epoch": 9.00159855177561,
      "grad_norm": 4.466875076293945,
      "learning_rate": 5.0115392758839725e-06,
      "loss": 0.6327,
      "step": 850300
    },
    {
      "epoch": 9.002127873555613,
      "grad_norm": 4.504110813140869,
      "learning_rate": 5.008945585432988e-06,
      "loss": 0.6144,
      "step": 850350
    },
    {
      "epoch": 9.002657195335617,
      "grad_norm": 4.715968132019043,
      "learning_rate": 5.00629896252382e-06,
      "loss": 0.6247,
      "step": 850400
    },
    {
      "epoch": 9.00318651711562,
      "grad_norm": 4.685126781463623,
      "learning_rate": 5.003652339614652e-06,
      "loss": 0.6311,
      "step": 850450
    },
    {
      "epoch": 9.003715838895623,
      "grad_norm": 4.808382034301758,
      "learning_rate": 5.0010057167054845e-06,
      "loss": 0.6197,
      "step": 850500
    },
    {
      "epoch": 9.003715838895623,
      "eval_loss": 0.38104379177093506,
      "eval_runtime": 46.5717,
      "eval_samples_per_second": 3605.841,
      "eval_steps_per_second": 450.746,
      "step": 850500
    },
    {
      "epoch": 9.004245160675627,
      "grad_norm": 4.563454627990723,
      "learning_rate": 4.998359093796316e-06,
      "loss": 0.6159,
      "step": 850550
    },
    {
      "epoch": 9.00477448245563,
      "grad_norm": 4.508941650390625,
      "learning_rate": 4.9957124708871484e-06,
      "loss": 0.6247,
      "step": 850600
    },
    {
      "epoch": 9.005303804235632,
      "grad_norm": 4.503861427307129,
      "learning_rate": 4.993065847977981e-06,
      "loss": 0.6333,
      "step": 850650
    },
    {
      "epoch": 9.005833126015636,
      "grad_norm": 4.531644344329834,
      "learning_rate": 4.990419225068812e-06,
      "loss": 0.6085,
      "step": 850700
    },
    {
      "epoch": 9.00636244779564,
      "grad_norm": 4.994392395019531,
      "learning_rate": 4.987772602159645e-06,
      "loss": 0.6387,
      "step": 850750
    },
    {
      "epoch": 9.006891769575642,
      "grad_norm": 4.587959289550781,
      "learning_rate": 4.985125979250476e-06,
      "loss": 0.6245,
      "step": 850800
    },
    {
      "epoch": 9.007421091355646,
      "grad_norm": 4.508461952209473,
      "learning_rate": 4.982479356341309e-06,
      "loss": 0.6326,
      "step": 850850
    },
    {
      "epoch": 9.00795041313565,
      "grad_norm": 5.01740837097168,
      "learning_rate": 4.979832733432141e-06,
      "loss": 0.6327,
      "step": 850900
    },
    {
      "epoch": 9.008479734915653,
      "grad_norm": 4.75882625579834,
      "learning_rate": 4.977186110522973e-06,
      "loss": 0.6199,
      "step": 850950
    },
    {
      "epoch": 9.009009056695655,
      "grad_norm": 4.80239200592041,
      "learning_rate": 4.974539487613805e-06,
      "loss": 0.6214,
      "step": 851000
    },
    {
      "epoch": 9.009009056695655,
      "eval_loss": 0.3817185163497925,
      "eval_runtime": 46.5348,
      "eval_samples_per_second": 3608.696,
      "eval_steps_per_second": 451.103,
      "step": 851000
    },
    {
      "epoch": 9.009538378475659,
      "grad_norm": 4.690138816833496,
      "learning_rate": 4.9718928647046375e-06,
      "loss": 0.6166,
      "step": 851050
    },
    {
      "epoch": 9.010067700255663,
      "grad_norm": 4.817243576049805,
      "learning_rate": 4.969246241795469e-06,
      "loss": 0.6215,
      "step": 851100
    },
    {
      "epoch": 9.010597022035666,
      "grad_norm": 4.656113624572754,
      "learning_rate": 4.9665996188863015e-06,
      "loss": 0.6223,
      "step": 851150
    },
    {
      "epoch": 9.011126343815668,
      "grad_norm": 4.329807758331299,
      "learning_rate": 4.963952995977134e-06,
      "loss": 0.6221,
      "step": 851200
    },
    {
      "epoch": 9.011655665595672,
      "grad_norm": 4.381196975708008,
      "learning_rate": 4.9613063730679655e-06,
      "loss": 0.6249,
      "step": 851250
    },
    {
      "epoch": 9.012184987375676,
      "grad_norm": 4.526900291442871,
      "learning_rate": 4.958659750158798e-06,
      "loss": 0.6189,
      "step": 851300
    },
    {
      "epoch": 9.01271430915568,
      "grad_norm": 4.50153112411499,
      "learning_rate": 4.95601312724963e-06,
      "loss": 0.6215,
      "step": 851350
    },
    {
      "epoch": 9.013243630935682,
      "grad_norm": 4.143549919128418,
      "learning_rate": 4.953366504340462e-06,
      "loss": 0.6084,
      "step": 851400
    },
    {
      "epoch": 9.013772952715685,
      "grad_norm": 4.628210544586182,
      "learning_rate": 4.950719881431294e-06,
      "loss": 0.6366,
      "step": 851450
    },
    {
      "epoch": 9.014302274495689,
      "grad_norm": 4.971210956573486,
      "learning_rate": 4.948073258522126e-06,
      "loss": 0.6245,
      "step": 851500
    },
    {
      "epoch": 9.014302274495689,
      "eval_loss": 0.3809773623943329,
      "eval_runtime": 46.4867,
      "eval_samples_per_second": 3612.432,
      "eval_steps_per_second": 451.57,
      "step": 851500
    },
    {
      "epoch": 9.014831596275691,
      "grad_norm": 4.392789840698242,
      "learning_rate": 4.945426635612958e-06,
      "loss": 0.6151,
      "step": 851550
    },
    {
      "epoch": 9.015360918055695,
      "grad_norm": 4.51845121383667,
      "learning_rate": 4.942780012703791e-06,
      "loss": 0.621,
      "step": 851600
    },
    {
      "epoch": 9.015890239835699,
      "grad_norm": 4.360613822937012,
      "learning_rate": 4.940133389794622e-06,
      "loss": 0.613,
      "step": 851650
    },
    {
      "epoch": 9.016419561615702,
      "grad_norm": 4.468272686004639,
      "learning_rate": 4.937486766885455e-06,
      "loss": 0.6314,
      "step": 851700
    },
    {
      "epoch": 9.016948883395704,
      "grad_norm": 4.501920223236084,
      "learning_rate": 4.934840143976287e-06,
      "loss": 0.6232,
      "step": 851750
    },
    {
      "epoch": 9.017478205175708,
      "grad_norm": 4.677862644195557,
      "learning_rate": 4.9321935210671185e-06,
      "loss": 0.6227,
      "step": 851800
    },
    {
      "epoch": 9.018007526955712,
      "grad_norm": 4.241340160369873,
      "learning_rate": 4.929546898157951e-06,
      "loss": 0.6302,
      "step": 851850
    },
    {
      "epoch": 9.018536848735716,
      "grad_norm": 4.394003868103027,
      "learning_rate": 4.926900275248783e-06,
      "loss": 0.6279,
      "step": 851900
    },
    {
      "epoch": 9.019066170515718,
      "grad_norm": 4.4867730140686035,
      "learning_rate": 4.924253652339615e-06,
      "loss": 0.6291,
      "step": 851950
    },
    {
      "epoch": 9.019595492295721,
      "grad_norm": 4.825723648071289,
      "learning_rate": 4.921607029430447e-06,
      "loss": 0.6289,
      "step": 852000
    },
    {
      "epoch": 9.019595492295721,
      "eval_loss": 0.38082876801490784,
      "eval_runtime": 46.4983,
      "eval_samples_per_second": 3611.53,
      "eval_steps_per_second": 451.457,
      "step": 852000
    },
    {
      "epoch": 9.020124814075725,
      "grad_norm": 4.353021621704102,
      "learning_rate": 4.91896040652128e-06,
      "loss": 0.6215,
      "step": 852050
    },
    {
      "epoch": 9.020654135855729,
      "grad_norm": 4.39297342300415,
      "learning_rate": 4.916313783612111e-06,
      "loss": 0.6336,
      "step": 852100
    },
    {
      "epoch": 9.02118345763573,
      "grad_norm": 4.6873459815979,
      "learning_rate": 4.913667160702944e-06,
      "loss": 0.6226,
      "step": 852150
    },
    {
      "epoch": 9.021712779415735,
      "grad_norm": 4.783636569976807,
      "learning_rate": 4.911020537793776e-06,
      "loss": 0.6252,
      "step": 852200
    },
    {
      "epoch": 9.022242101195738,
      "grad_norm": 4.784800052642822,
      "learning_rate": 4.908373914884608e-06,
      "loss": 0.6246,
      "step": 852250
    },
    {
      "epoch": 9.02277142297574,
      "grad_norm": 4.616942405700684,
      "learning_rate": 4.90572729197544e-06,
      "loss": 0.6208,
      "step": 852300
    },
    {
      "epoch": 9.023300744755744,
      "grad_norm": 4.475376605987549,
      "learning_rate": 4.903133601524456e-06,
      "loss": 0.6243,
      "step": 852350
    },
    {
      "epoch": 9.023830066535748,
      "grad_norm": 4.365683078765869,
      "learning_rate": 4.900486978615287e-06,
      "loss": 0.6299,
      "step": 852400
    },
    {
      "epoch": 9.024359388315752,
      "grad_norm": 4.434950828552246,
      "learning_rate": 4.89784035570612e-06,
      "loss": 0.6207,
      "step": 852450
    },
    {
      "epoch": 9.024888710095754,
      "grad_norm": 4.326904296875,
      "learning_rate": 4.895193732796952e-06,
      "loss": 0.6277,
      "step": 852500
    },
    {
      "epoch": 9.024888710095754,
      "eval_loss": 0.3809908330440521,
      "eval_runtime": 46.5254,
      "eval_samples_per_second": 3609.422,
      "eval_steps_per_second": 451.194,
      "step": 852500
    },
    {
      "epoch": 9.025418031875757,
      "grad_norm": 4.5487284660339355,
      "learning_rate": 4.8925471098877836e-06,
      "loss": 0.6179,
      "step": 852550
    },
    {
      "epoch": 9.025947353655761,
      "grad_norm": 4.863379955291748,
      "learning_rate": 4.889900486978616e-06,
      "loss": 0.6248,
      "step": 852600
    },
    {
      "epoch": 9.026476675435765,
      "grad_norm": 5.085598945617676,
      "learning_rate": 4.8872538640694475e-06,
      "loss": 0.6265,
      "step": 852650
    },
    {
      "epoch": 9.027005997215767,
      "grad_norm": 4.8034987449646,
      "learning_rate": 4.88460724116028e-06,
      "loss": 0.6169,
      "step": 852700
    },
    {
      "epoch": 9.02753531899577,
      "grad_norm": 4.594027042388916,
      "learning_rate": 4.881960618251112e-06,
      "loss": 0.6075,
      "step": 852750
    },
    {
      "epoch": 9.028064640775774,
      "grad_norm": 4.574734210968018,
      "learning_rate": 4.879313995341944e-06,
      "loss": 0.6224,
      "step": 852800
    },
    {
      "epoch": 9.028593962555778,
      "grad_norm": 4.552887916564941,
      "learning_rate": 4.876667372432776e-06,
      "loss": 0.6318,
      "step": 852850
    },
    {
      "epoch": 9.02912328433578,
      "grad_norm": 4.890467643737793,
      "learning_rate": 4.874020749523609e-06,
      "loss": 0.632,
      "step": 852900
    },
    {
      "epoch": 9.029652606115784,
      "grad_norm": 4.727046489715576,
      "learning_rate": 4.87137412661444e-06,
      "loss": 0.6316,
      "step": 852950
    },
    {
      "epoch": 9.030181927895788,
      "grad_norm": 4.3866424560546875,
      "learning_rate": 4.868727503705273e-06,
      "loss": 0.6273,
      "step": 853000
    },
    {
      "epoch": 9.030181927895788,
      "eval_loss": 0.38053998351097107,
      "eval_runtime": 46.3818,
      "eval_samples_per_second": 3620.605,
      "eval_steps_per_second": 452.592,
      "step": 853000
    },
    {
      "epoch": 9.03071124967579,
      "grad_norm": 4.805426597595215,
      "learning_rate": 4.866080880796105e-06,
      "loss": 0.626,
      "step": 853050
    },
    {
      "epoch": 9.031240571455793,
      "grad_norm": 4.5934271812438965,
      "learning_rate": 4.863434257886936e-06,
      "loss": 0.6231,
      "step": 853100
    },
    {
      "epoch": 9.031769893235797,
      "grad_norm": 4.340877532958984,
      "learning_rate": 4.860787634977768e-06,
      "loss": 0.6241,
      "step": 853150
    },
    {
      "epoch": 9.0322992150158,
      "grad_norm": 4.497051239013672,
      "learning_rate": 4.858141012068601e-06,
      "loss": 0.6219,
      "step": 853200
    },
    {
      "epoch": 9.032828536795803,
      "grad_norm": 4.821721076965332,
      "learning_rate": 4.855494389159432e-06,
      "loss": 0.631,
      "step": 853250
    },
    {
      "epoch": 9.033357858575807,
      "grad_norm": 4.290646553039551,
      "learning_rate": 4.8528477662502646e-06,
      "loss": 0.6285,
      "step": 853300
    },
    {
      "epoch": 9.03388718035581,
      "grad_norm": 4.687821865081787,
      "learning_rate": 4.850201143341097e-06,
      "loss": 0.6261,
      "step": 853350
    },
    {
      "epoch": 9.034416502135814,
      "grad_norm": 4.237066268920898,
      "learning_rate": 4.8475545204319285e-06,
      "loss": 0.6222,
      "step": 853400
    },
    {
      "epoch": 9.034945823915816,
      "grad_norm": 4.711435317993164,
      "learning_rate": 4.844907897522761e-06,
      "loss": 0.6247,
      "step": 853450
    },
    {
      "epoch": 9.03547514569582,
      "grad_norm": 4.528620719909668,
      "learning_rate": 4.842261274613593e-06,
      "loss": 0.6344,
      "step": 853500
    },
    {
      "epoch": 9.03547514569582,
      "eval_loss": 0.3810105323791504,
      "eval_runtime": 46.5024,
      "eval_samples_per_second": 3611.21,
      "eval_steps_per_second": 451.417,
      "step": 853500
    },
    {
      "epoch": 9.036004467475824,
      "grad_norm": 4.292782306671143,
      "learning_rate": 4.839614651704425e-06,
      "loss": 0.6245,
      "step": 853550
    },
    {
      "epoch": 9.036533789255827,
      "grad_norm": 4.384402751922607,
      "learning_rate": 4.836968028795257e-06,
      "loss": 0.6213,
      "step": 853600
    },
    {
      "epoch": 9.03706311103583,
      "grad_norm": 3.9974095821380615,
      "learning_rate": 4.83432140588609e-06,
      "loss": 0.6258,
      "step": 853650
    },
    {
      "epoch": 9.037592432815833,
      "grad_norm": 4.410129070281982,
      "learning_rate": 4.831674782976921e-06,
      "loss": 0.6272,
      "step": 853700
    },
    {
      "epoch": 9.038121754595837,
      "grad_norm": 4.834413051605225,
      "learning_rate": 4.829028160067754e-06,
      "loss": 0.6317,
      "step": 853750
    },
    {
      "epoch": 9.038651076375839,
      "grad_norm": 4.444408893585205,
      "learning_rate": 4.826381537158585e-06,
      "loss": 0.6378,
      "step": 853800
    },
    {
      "epoch": 9.039180398155843,
      "grad_norm": 4.76741361618042,
      "learning_rate": 4.823734914249418e-06,
      "loss": 0.6218,
      "step": 853850
    },
    {
      "epoch": 9.039709719935846,
      "grad_norm": 4.647629261016846,
      "learning_rate": 4.82108829134025e-06,
      "loss": 0.6258,
      "step": 853900
    },
    {
      "epoch": 9.04023904171585,
      "grad_norm": 4.677496433258057,
      "learning_rate": 4.818441668431082e-06,
      "loss": 0.6192,
      "step": 853950
    },
    {
      "epoch": 9.040768363495852,
      "grad_norm": 4.689783573150635,
      "learning_rate": 4.815795045521914e-06,
      "loss": 0.6279,
      "step": 854000
    },
    {
      "epoch": 9.040768363495852,
      "eval_loss": 0.38057973980903625,
      "eval_runtime": 46.4448,
      "eval_samples_per_second": 3615.69,
      "eval_steps_per_second": 451.977,
      "step": 854000
    },
    {
      "epoch": 9.041297685275856,
      "grad_norm": 4.292347431182861,
      "learning_rate": 4.813148422612746e-06,
      "loss": 0.6272,
      "step": 854050
    },
    {
      "epoch": 9.04182700705586,
      "grad_norm": 4.368961811065674,
      "learning_rate": 4.810501799703578e-06,
      "loss": 0.6133,
      "step": 854100
    },
    {
      "epoch": 9.042356328835863,
      "grad_norm": 4.0565338134765625,
      "learning_rate": 4.80785517679441e-06,
      "loss": 0.6146,
      "step": 854150
    },
    {
      "epoch": 9.042885650615865,
      "grad_norm": 4.758318901062012,
      "learning_rate": 4.805208553885243e-06,
      "loss": 0.6257,
      "step": 854200
    },
    {
      "epoch": 9.043414972395869,
      "grad_norm": 4.696361541748047,
      "learning_rate": 4.802561930976074e-06,
      "loss": 0.6359,
      "step": 854250
    },
    {
      "epoch": 9.043944294175873,
      "grad_norm": 4.563755989074707,
      "learning_rate": 4.799915308066907e-06,
      "loss": 0.6462,
      "step": 854300
    },
    {
      "epoch": 9.044473615955877,
      "grad_norm": 4.652090549468994,
      "learning_rate": 4.797268685157739e-06,
      "loss": 0.623,
      "step": 854350
    },
    {
      "epoch": 9.045002937735878,
      "grad_norm": 4.577030181884766,
      "learning_rate": 4.794674994706754e-06,
      "loss": 0.6221,
      "step": 854400
    },
    {
      "epoch": 9.045532259515882,
      "grad_norm": 4.354890823364258,
      "learning_rate": 4.792028371797586e-06,
      "loss": 0.6144,
      "step": 854450
    },
    {
      "epoch": 9.046061581295886,
      "grad_norm": 4.639078617095947,
      "learning_rate": 4.789381748888419e-06,
      "loss": 0.6114,
      "step": 854500
    },
    {
      "epoch": 9.046061581295886,
      "eval_loss": 0.38029390573501587,
      "eval_runtime": 46.4738,
      "eval_samples_per_second": 3613.43,
      "eval_steps_per_second": 451.695,
      "step": 854500
    },
    {
      "epoch": 9.046590903075888,
      "grad_norm": 4.693718910217285,
      "learning_rate": 4.78673512597925e-06,
      "loss": 0.6366,
      "step": 854550
    },
    {
      "epoch": 9.047120224855892,
      "grad_norm": 4.083237171173096,
      "learning_rate": 4.784088503070083e-06,
      "loss": 0.6107,
      "step": 854600
    },
    {
      "epoch": 9.047649546635895,
      "grad_norm": 4.224356651306152,
      "learning_rate": 4.781441880160915e-06,
      "loss": 0.621,
      "step": 854650
    },
    {
      "epoch": 9.0481788684159,
      "grad_norm": 5.14303731918335,
      "learning_rate": 4.778795257251747e-06,
      "loss": 0.6197,
      "step": 854700
    },
    {
      "epoch": 9.048708190195901,
      "grad_norm": 4.906386375427246,
      "learning_rate": 4.776148634342579e-06,
      "loss": 0.6256,
      "step": 854750
    },
    {
      "epoch": 9.049237511975905,
      "grad_norm": 4.683009624481201,
      "learning_rate": 4.773502011433411e-06,
      "loss": 0.6277,
      "step": 854800
    },
    {
      "epoch": 9.049766833755909,
      "grad_norm": 4.691953659057617,
      "learning_rate": 4.770855388524243e-06,
      "loss": 0.6234,
      "step": 854850
    },
    {
      "epoch": 9.050296155535912,
      "grad_norm": 4.987854957580566,
      "learning_rate": 4.768208765615075e-06,
      "loss": 0.6398,
      "step": 854900
    },
    {
      "epoch": 9.050825477315914,
      "grad_norm": 4.480409145355225,
      "learning_rate": 4.765562142705907e-06,
      "loss": 0.6312,
      "step": 854950
    },
    {
      "epoch": 9.051354799095918,
      "grad_norm": 4.7820234298706055,
      "learning_rate": 4.762915519796739e-06,
      "loss": 0.6288,
      "step": 855000
    },
    {
      "epoch": 9.051354799095918,
      "eval_loss": 0.38120654225349426,
      "eval_runtime": 46.4575,
      "eval_samples_per_second": 3614.703,
      "eval_steps_per_second": 451.854,
      "step": 855000
    },
    {
      "epoch": 9.051884120875922,
      "grad_norm": 4.589739799499512,
      "learning_rate": 4.760268896887572e-06,
      "loss": 0.6313,
      "step": 855050
    },
    {
      "epoch": 9.052413442655926,
      "grad_norm": 4.677824974060059,
      "learning_rate": 4.757622273978403e-06,
      "loss": 0.6298,
      "step": 855100
    },
    {
      "epoch": 9.052942764435928,
      "grad_norm": 4.8400187492370605,
      "learning_rate": 4.754975651069236e-06,
      "loss": 0.6305,
      "step": 855150
    },
    {
      "epoch": 9.053472086215931,
      "grad_norm": 4.476521015167236,
      "learning_rate": 4.752329028160068e-06,
      "loss": 0.622,
      "step": 855200
    },
    {
      "epoch": 9.054001407995935,
      "grad_norm": 4.51854133605957,
      "learning_rate": 4.7496824052509e-06,
      "loss": 0.6239,
      "step": 855250
    },
    {
      "epoch": 9.054530729775937,
      "grad_norm": 4.953158855438232,
      "learning_rate": 4.747035782341732e-06,
      "loss": 0.6234,
      "step": 855300
    },
    {
      "epoch": 9.055060051555941,
      "grad_norm": 4.6107635498046875,
      "learning_rate": 4.7443891594325645e-06,
      "loss": 0.6123,
      "step": 855350
    },
    {
      "epoch": 9.055589373335945,
      "grad_norm": 5.048244953155518,
      "learning_rate": 4.741742536523396e-06,
      "loss": 0.626,
      "step": 855400
    },
    {
      "epoch": 9.056118695115948,
      "grad_norm": 4.625926971435547,
      "learning_rate": 4.7390959136142285e-06,
      "loss": 0.6295,
      "step": 855450
    },
    {
      "epoch": 9.05664801689595,
      "grad_norm": 4.500638484954834,
      "learning_rate": 4.736449290705061e-06,
      "loss": 0.6125,
      "step": 855500
    },
    {
      "epoch": 9.05664801689595,
      "eval_loss": 0.38012954592704773,
      "eval_runtime": 46.4926,
      "eval_samples_per_second": 3611.971,
      "eval_steps_per_second": 451.512,
      "step": 855500
    },
    {
      "epoch": 9.057177338675954,
      "grad_norm": 4.7931294441223145,
      "learning_rate": 4.733802667795892e-06,
      "loss": 0.621,
      "step": 855550
    },
    {
      "epoch": 9.057706660455958,
      "grad_norm": 5.129309177398682,
      "learning_rate": 4.731156044886725e-06,
      "loss": 0.6266,
      "step": 855600
    },
    {
      "epoch": 9.058235982235962,
      "grad_norm": 4.82062292098999,
      "learning_rate": 4.728509421977556e-06,
      "loss": 0.6264,
      "step": 855650
    },
    {
      "epoch": 9.058765304015964,
      "grad_norm": 4.834300994873047,
      "learning_rate": 4.725862799068389e-06,
      "loss": 0.6234,
      "step": 855700
    },
    {
      "epoch": 9.059294625795967,
      "grad_norm": 4.581221580505371,
      "learning_rate": 4.723216176159221e-06,
      "loss": 0.615,
      "step": 855750
    },
    {
      "epoch": 9.059823947575971,
      "grad_norm": 4.419009208679199,
      "learning_rate": 4.720569553250053e-06,
      "loss": 0.6189,
      "step": 855800
    },
    {
      "epoch": 9.060353269355975,
      "grad_norm": 4.668188571929932,
      "learning_rate": 4.717922930340885e-06,
      "loss": 0.6282,
      "step": 855850
    },
    {
      "epoch": 9.060882591135977,
      "grad_norm": 4.680952548980713,
      "learning_rate": 4.7152763074317176e-06,
      "loss": 0.6135,
      "step": 855900
    },
    {
      "epoch": 9.06141191291598,
      "grad_norm": 4.7847394943237305,
      "learning_rate": 4.712629684522549e-06,
      "loss": 0.6153,
      "step": 855950
    },
    {
      "epoch": 9.061941234695984,
      "grad_norm": 4.353952884674072,
      "learning_rate": 4.7099830616133815e-06,
      "loss": 0.6253,
      "step": 856000
    },
    {
      "epoch": 9.061941234695984,
      "eval_loss": 0.38020452857017517,
      "eval_runtime": 46.502,
      "eval_samples_per_second": 3611.243,
      "eval_steps_per_second": 451.422,
      "step": 856000
    },
    {
      "epoch": 9.062470556475986,
      "grad_norm": 4.790470123291016,
      "learning_rate": 4.707336438704214e-06,
      "loss": 0.6304,
      "step": 856050
    },
    {
      "epoch": 9.06299987825599,
      "grad_norm": 4.961874961853027,
      "learning_rate": 4.7046898157950455e-06,
      "loss": 0.6248,
      "step": 856100
    },
    {
      "epoch": 9.063529200035994,
      "grad_norm": 4.270816802978516,
      "learning_rate": 4.702043192885878e-06,
      "loss": 0.6295,
      "step": 856150
    },
    {
      "epoch": 9.064058521815998,
      "grad_norm": 5.2763671875,
      "learning_rate": 4.69939656997671e-06,
      "loss": 0.622,
      "step": 856200
    },
    {
      "epoch": 9.064587843596,
      "grad_norm": 4.6787428855896,
      "learning_rate": 4.696749947067542e-06,
      "loss": 0.6304,
      "step": 856250
    },
    {
      "epoch": 9.065117165376003,
      "grad_norm": 4.8176655769348145,
      "learning_rate": 4.694103324158374e-06,
      "loss": 0.6208,
      "step": 856300
    },
    {
      "epoch": 9.065646487156007,
      "grad_norm": 4.796689987182617,
      "learning_rate": 4.691456701249206e-06,
      "loss": 0.6218,
      "step": 856350
    },
    {
      "epoch": 9.066175808936011,
      "grad_norm": 4.430953025817871,
      "learning_rate": 4.688863010798221e-06,
      "loss": 0.6298,
      "step": 856400
    },
    {
      "epoch": 9.066705130716013,
      "grad_norm": 4.730192184448242,
      "learning_rate": 4.686216387889054e-06,
      "loss": 0.6213,
      "step": 856450
    },
    {
      "epoch": 9.067234452496017,
      "grad_norm": 4.610264778137207,
      "learning_rate": 4.683569764979886e-06,
      "loss": 0.6254,
      "step": 856500
    },
    {
      "epoch": 9.067234452496017,
      "eval_loss": 0.38012757897377014,
      "eval_runtime": 46.7038,
      "eval_samples_per_second": 3595.638,
      "eval_steps_per_second": 449.471,
      "step": 856500
    },
    {
      "epoch": 9.06776377427602,
      "grad_norm": 4.587947368621826,
      "learning_rate": 4.680923142070718e-06,
      "loss": 0.6188,
      "step": 856550
    },
    {
      "epoch": 9.068293096056024,
      "grad_norm": 4.350674152374268,
      "learning_rate": 4.67827651916155e-06,
      "loss": 0.6288,
      "step": 856600
    },
    {
      "epoch": 9.068822417836026,
      "grad_norm": 4.5557098388671875,
      "learning_rate": 4.6756298962523826e-06,
      "loss": 0.6351,
      "step": 856650
    },
    {
      "epoch": 9.06935173961603,
      "grad_norm": 4.696262836456299,
      "learning_rate": 4.672983273343214e-06,
      "loss": 0.6285,
      "step": 856700
    },
    {
      "epoch": 9.069881061396034,
      "grad_norm": 4.589293479919434,
      "learning_rate": 4.6703366504340465e-06,
      "loss": 0.6213,
      "step": 856750
    },
    {
      "epoch": 9.070410383176036,
      "grad_norm": 4.495299816131592,
      "learning_rate": 4.667690027524878e-06,
      "loss": 0.6253,
      "step": 856800
    },
    {
      "epoch": 9.07093970495604,
      "grad_norm": 4.639854907989502,
      "learning_rate": 4.6650434046157105e-06,
      "loss": 0.6124,
      "step": 856850
    },
    {
      "epoch": 9.071469026736043,
      "grad_norm": 4.6885905265808105,
      "learning_rate": 4.662396781706543e-06,
      "loss": 0.6278,
      "step": 856900
    },
    {
      "epoch": 9.071998348516047,
      "grad_norm": 4.530185222625732,
      "learning_rate": 4.6597501587973745e-06,
      "loss": 0.6276,
      "step": 856950
    },
    {
      "epoch": 9.072527670296049,
      "grad_norm": 4.301689147949219,
      "learning_rate": 4.657103535888207e-06,
      "loss": 0.6335,
      "step": 857000
    },
    {
      "epoch": 9.072527670296049,
      "eval_loss": 0.379976361989975,
      "eval_runtime": 46.458,
      "eval_samples_per_second": 3614.665,
      "eval_steps_per_second": 451.849,
      "step": 857000
    },
    {
      "epoch": 9.073056992076053,
      "grad_norm": 4.086099147796631,
      "learning_rate": 4.654456912979039e-06,
      "loss": 0.6276,
      "step": 857050
    },
    {
      "epoch": 9.073586313856056,
      "grad_norm": 4.682025909423828,
      "learning_rate": 4.651810290069871e-06,
      "loss": 0.6244,
      "step": 857100
    },
    {
      "epoch": 9.07411563563606,
      "grad_norm": 4.918087005615234,
      "learning_rate": 4.649163667160703e-06,
      "loss": 0.6303,
      "step": 857150
    },
    {
      "epoch": 9.074644957416062,
      "grad_norm": 4.219066619873047,
      "learning_rate": 4.646517044251536e-06,
      "loss": 0.6345,
      "step": 857200
    },
    {
      "epoch": 9.075174279196066,
      "grad_norm": 4.310669422149658,
      "learning_rate": 4.643870421342367e-06,
      "loss": 0.6141,
      "step": 857250
    },
    {
      "epoch": 9.07570360097607,
      "grad_norm": 4.617166042327881,
      "learning_rate": 4.6412237984332e-06,
      "loss": 0.614,
      "step": 857300
    },
    {
      "epoch": 9.076232922756073,
      "grad_norm": 4.573653697967529,
      "learning_rate": 4.638577175524032e-06,
      "loss": 0.6286,
      "step": 857350
    },
    {
      "epoch": 9.076762244536075,
      "grad_norm": 4.369746685028076,
      "learning_rate": 4.6359305526148636e-06,
      "loss": 0.6205,
      "step": 857400
    },
    {
      "epoch": 9.07729156631608,
      "grad_norm": 4.790319919586182,
      "learning_rate": 4.633283929705696e-06,
      "loss": 0.6292,
      "step": 857450
    },
    {
      "epoch": 9.077820888096083,
      "grad_norm": 4.319826602935791,
      "learning_rate": 4.6306373067965275e-06,
      "loss": 0.6167,
      "step": 857500
    },
    {
      "epoch": 9.077820888096083,
      "eval_loss": 0.38046562671661377,
      "eval_runtime": 46.54,
      "eval_samples_per_second": 3608.297,
      "eval_steps_per_second": 451.053,
      "step": 857500
    },
    {
      "epoch": 9.078350209876087,
      "grad_norm": 5.096309185028076,
      "learning_rate": 4.62799068388736e-06,
      "loss": 0.6245,
      "step": 857550
    },
    {
      "epoch": 9.078879531656089,
      "grad_norm": 4.422910213470459,
      "learning_rate": 4.625344060978192e-06,
      "loss": 0.6251,
      "step": 857600
    },
    {
      "epoch": 9.079408853436092,
      "grad_norm": 4.626015663146973,
      "learning_rate": 4.622697438069024e-06,
      "loss": 0.6275,
      "step": 857650
    },
    {
      "epoch": 9.079938175216096,
      "grad_norm": 4.590458869934082,
      "learning_rate": 4.620050815159856e-06,
      "loss": 0.6197,
      "step": 857700
    },
    {
      "epoch": 9.080467496996098,
      "grad_norm": 4.388294219970703,
      "learning_rate": 4.617404192250689e-06,
      "loss": 0.6288,
      "step": 857750
    },
    {
      "epoch": 9.080996818776102,
      "grad_norm": 4.463828086853027,
      "learning_rate": 4.61475756934152e-06,
      "loss": 0.6414,
      "step": 857800
    },
    {
      "epoch": 9.081526140556106,
      "grad_norm": 4.19514799118042,
      "learning_rate": 4.612110946432353e-06,
      "loss": 0.6238,
      "step": 857850
    },
    {
      "epoch": 9.08205546233611,
      "grad_norm": 4.8190717697143555,
      "learning_rate": 4.609464323523185e-06,
      "loss": 0.6304,
      "step": 857900
    },
    {
      "epoch": 9.082584784116111,
      "grad_norm": 4.857362270355225,
      "learning_rate": 4.606817700614017e-06,
      "loss": 0.627,
      "step": 857950
    },
    {
      "epoch": 9.083114105896115,
      "grad_norm": 4.633346080780029,
      "learning_rate": 4.604171077704849e-06,
      "loss": 0.618,
      "step": 858000
    },
    {
      "epoch": 9.083114105896115,
      "eval_loss": 0.38015514612197876,
      "eval_runtime": 46.4763,
      "eval_samples_per_second": 3613.236,
      "eval_steps_per_second": 451.671,
      "step": 858000
    },
    {
      "epoch": 9.083643427676119,
      "grad_norm": 4.967531681060791,
      "learning_rate": 4.6015244547956815e-06,
      "loss": 0.6213,
      "step": 858050
    },
    {
      "epoch": 9.084172749456123,
      "grad_norm": 4.935038089752197,
      "learning_rate": 4.598877831886513e-06,
      "loss": 0.6294,
      "step": 858100
    },
    {
      "epoch": 9.084702071236125,
      "grad_norm": 4.5647783279418945,
      "learning_rate": 4.5962312089773454e-06,
      "loss": 0.6256,
      "step": 858150
    },
    {
      "epoch": 9.085231393016128,
      "grad_norm": 4.769289493560791,
      "learning_rate": 4.593584586068177e-06,
      "loss": 0.6244,
      "step": 858200
    },
    {
      "epoch": 9.085760714796132,
      "grad_norm": 4.97348165512085,
      "learning_rate": 4.590937963159009e-06,
      "loss": 0.6149,
      "step": 858250
    },
    {
      "epoch": 9.086290036576136,
      "grad_norm": 4.930251598358154,
      "learning_rate": 4.588291340249842e-06,
      "loss": 0.6311,
      "step": 858300
    },
    {
      "epoch": 9.086819358356138,
      "grad_norm": 4.251403331756592,
      "learning_rate": 4.585644717340673e-06,
      "loss": 0.6299,
      "step": 858350
    },
    {
      "epoch": 9.087348680136142,
      "grad_norm": 4.460885047912598,
      "learning_rate": 4.583051026889689e-06,
      "loss": 0.6298,
      "step": 858400
    },
    {
      "epoch": 9.087878001916145,
      "grad_norm": 4.376866340637207,
      "learning_rate": 4.580404403980521e-06,
      "loss": 0.6236,
      "step": 858450
    },
    {
      "epoch": 9.088407323696147,
      "grad_norm": 4.967990875244141,
      "learning_rate": 4.577757781071354e-06,
      "loss": 0.6292,
      "step": 858500
    },
    {
      "epoch": 9.088407323696147,
      "eval_loss": 0.37988123297691345,
      "eval_runtime": 46.533,
      "eval_samples_per_second": 3608.836,
      "eval_steps_per_second": 451.121,
      "step": 858500
    },
    {
      "epoch": 9.088936645476151,
      "grad_norm": 4.709936141967773,
      "learning_rate": 4.575111158162185e-06,
      "loss": 0.6215,
      "step": 858550
    },
    {
      "epoch": 9.089465967256155,
      "grad_norm": 4.288220405578613,
      "learning_rate": 4.572464535253018e-06,
      "loss": 0.6226,
      "step": 858600
    },
    {
      "epoch": 9.089995289036159,
      "grad_norm": 4.542027950286865,
      "learning_rate": 4.569817912343849e-06,
      "loss": 0.6196,
      "step": 858650
    },
    {
      "epoch": 9.09052461081616,
      "grad_norm": 4.455021381378174,
      "learning_rate": 4.567171289434682e-06,
      "loss": 0.6224,
      "step": 858700
    },
    {
      "epoch": 9.091053932596164,
      "grad_norm": 4.564481735229492,
      "learning_rate": 4.564524666525514e-06,
      "loss": 0.6222,
      "step": 858750
    },
    {
      "epoch": 9.091583254376168,
      "grad_norm": 5.083411693572998,
      "learning_rate": 4.561878043616346e-06,
      "loss": 0.6257,
      "step": 858800
    },
    {
      "epoch": 9.092112576156172,
      "grad_norm": 4.8021159172058105,
      "learning_rate": 4.559231420707178e-06,
      "loss": 0.6276,
      "step": 858850
    },
    {
      "epoch": 9.092641897936174,
      "grad_norm": 4.480823993682861,
      "learning_rate": 4.5565847977980104e-06,
      "loss": 0.6238,
      "step": 858900
    },
    {
      "epoch": 9.093171219716178,
      "grad_norm": 4.627233982086182,
      "learning_rate": 4.553938174888842e-06,
      "loss": 0.6291,
      "step": 858950
    },
    {
      "epoch": 9.093700541496181,
      "grad_norm": 4.450479507446289,
      "learning_rate": 4.551291551979674e-06,
      "loss": 0.6187,
      "step": 859000
    },
    {
      "epoch": 9.093700541496181,
      "eval_loss": 0.3800235688686371,
      "eval_runtime": 46.5907,
      "eval_samples_per_second": 3604.369,
      "eval_steps_per_second": 450.562,
      "step": 859000
    },
    {
      "epoch": 9.094229863276185,
      "grad_norm": 4.508153438568115,
      "learning_rate": 4.548644929070507e-06,
      "loss": 0.6261,
      "step": 859050
    },
    {
      "epoch": 9.094759185056187,
      "grad_norm": 4.8902482986450195,
      "learning_rate": 4.545998306161338e-06,
      "loss": 0.6286,
      "step": 859100
    },
    {
      "epoch": 9.09528850683619,
      "grad_norm": 4.423098564147949,
      "learning_rate": 4.543351683252171e-06,
      "loss": 0.6334,
      "step": 859150
    },
    {
      "epoch": 9.095817828616195,
      "grad_norm": 5.186718463897705,
      "learning_rate": 4.540705060343003e-06,
      "loss": 0.6345,
      "step": 859200
    },
    {
      "epoch": 9.096347150396197,
      "grad_norm": 4.717160701751709,
      "learning_rate": 4.538058437433835e-06,
      "loss": 0.6325,
      "step": 859250
    },
    {
      "epoch": 9.0968764721762,
      "grad_norm": 4.283050060272217,
      "learning_rate": 4.535411814524667e-06,
      "loss": 0.617,
      "step": 859300
    },
    {
      "epoch": 9.097405793956204,
      "grad_norm": 4.540374755859375,
      "learning_rate": 4.532765191615499e-06,
      "loss": 0.6128,
      "step": 859350
    },
    {
      "epoch": 9.097935115736208,
      "grad_norm": 4.644674301147461,
      "learning_rate": 4.530118568706331e-06,
      "loss": 0.6284,
      "step": 859400
    },
    {
      "epoch": 9.09846443751621,
      "grad_norm": 5.015370845794678,
      "learning_rate": 4.5274719457971635e-06,
      "loss": 0.618,
      "step": 859450
    },
    {
      "epoch": 9.098993759296214,
      "grad_norm": 4.748959064483643,
      "learning_rate": 4.524825322887995e-06,
      "loss": 0.6262,
      "step": 859500
    },
    {
      "epoch": 9.098993759296214,
      "eval_loss": 0.380180299282074,
      "eval_runtime": 46.5008,
      "eval_samples_per_second": 3611.337,
      "eval_steps_per_second": 451.433,
      "step": 859500
    },
    {
      "epoch": 9.099523081076217,
      "grad_norm": 4.854741096496582,
      "learning_rate": 4.5221786999788275e-06,
      "loss": 0.6266,
      "step": 859550
    },
    {
      "epoch": 9.100052402856221,
      "grad_norm": 4.328052520751953,
      "learning_rate": 4.51953207706966e-06,
      "loss": 0.6069,
      "step": 859600
    },
    {
      "epoch": 9.100581724636223,
      "grad_norm": 4.884947776794434,
      "learning_rate": 4.5168854541604914e-06,
      "loss": 0.6075,
      "step": 859650
    },
    {
      "epoch": 9.101111046416227,
      "grad_norm": 4.745212078094482,
      "learning_rate": 4.514238831251324e-06,
      "loss": 0.6237,
      "step": 859700
    },
    {
      "epoch": 9.10164036819623,
      "grad_norm": 4.38517427444458,
      "learning_rate": 4.511592208342156e-06,
      "loss": 0.6255,
      "step": 859750
    },
    {
      "epoch": 9.102169689976234,
      "grad_norm": 4.890622138977051,
      "learning_rate": 4.508945585432988e-06,
      "loss": 0.64,
      "step": 859800
    },
    {
      "epoch": 9.102699011756236,
      "grad_norm": 4.49953556060791,
      "learning_rate": 4.50629896252382e-06,
      "loss": 0.6212,
      "step": 859850
    },
    {
      "epoch": 9.10322833353624,
      "grad_norm": 5.096166133880615,
      "learning_rate": 4.503652339614653e-06,
      "loss": 0.6249,
      "step": 859900
    },
    {
      "epoch": 9.103757655316244,
      "grad_norm": 4.5210652351379395,
      "learning_rate": 4.501005716705484e-06,
      "loss": 0.626,
      "step": 859950
    },
    {
      "epoch": 9.104286977096246,
      "grad_norm": 4.683029651641846,
      "learning_rate": 4.4984120262545e-06,
      "loss": 0.6234,
      "step": 860000
    },
    {
      "epoch": 9.104286977096246,
      "eval_loss": 0.3798414170742035,
      "eval_runtime": 46.528,
      "eval_samples_per_second": 3609.227,
      "eval_steps_per_second": 451.169,
      "step": 860000
    },
    {
      "epoch": 9.10481629887625,
      "grad_norm": 4.5774054527282715,
      "learning_rate": 4.495765403345332e-06,
      "loss": 0.6233,
      "step": 860050
    },
    {
      "epoch": 9.105345620656253,
      "grad_norm": 4.605930328369141,
      "learning_rate": 4.493118780436164e-06,
      "loss": 0.6291,
      "step": 860100
    },
    {
      "epoch": 9.105874942436257,
      "grad_norm": 5.0356879234313965,
      "learning_rate": 4.490472157526996e-06,
      "loss": 0.6332,
      "step": 860150
    },
    {
      "epoch": 9.106404264216259,
      "grad_norm": 4.868714809417725,
      "learning_rate": 4.4878255346178285e-06,
      "loss": 0.6255,
      "step": 860200
    },
    {
      "epoch": 9.106933585996263,
      "grad_norm": 4.393896579742432,
      "learning_rate": 4.48517891170866e-06,
      "loss": 0.6331,
      "step": 860250
    },
    {
      "epoch": 9.107462907776267,
      "grad_norm": 4.342921733856201,
      "learning_rate": 4.4825322887994925e-06,
      "loss": 0.6228,
      "step": 860300
    },
    {
      "epoch": 9.10799222955627,
      "grad_norm": 4.516611576080322,
      "learning_rate": 4.479885665890325e-06,
      "loss": 0.6271,
      "step": 860350
    },
    {
      "epoch": 9.108521551336272,
      "grad_norm": 4.610964298248291,
      "learning_rate": 4.4772390429811564e-06,
      "loss": 0.6193,
      "step": 860400
    },
    {
      "epoch": 9.109050873116276,
      "grad_norm": 4.494202136993408,
      "learning_rate": 4.474592420071989e-06,
      "loss": 0.6257,
      "step": 860450
    },
    {
      "epoch": 9.10958019489628,
      "grad_norm": 4.668498516082764,
      "learning_rate": 4.47194579716282e-06,
      "loss": 0.624,
      "step": 860500
    },
    {
      "epoch": 9.10958019489628,
      "eval_loss": 0.3802747130393982,
      "eval_runtime": 46.4462,
      "eval_samples_per_second": 3615.585,
      "eval_steps_per_second": 451.964,
      "step": 860500
    },
    {
      "epoch": 9.110109516676284,
      "grad_norm": 4.385502815246582,
      "learning_rate": 4.469299174253653e-06,
      "loss": 0.6211,
      "step": 860550
    },
    {
      "epoch": 9.110638838456286,
      "grad_norm": 4.967283248901367,
      "learning_rate": 4.466652551344485e-06,
      "loss": 0.6229,
      "step": 860600
    },
    {
      "epoch": 9.11116816023629,
      "grad_norm": 4.5996503829956055,
      "learning_rate": 4.464005928435317e-06,
      "loss": 0.6244,
      "step": 860650
    },
    {
      "epoch": 9.111697482016293,
      "grad_norm": 4.653539657592773,
      "learning_rate": 4.461359305526148e-06,
      "loss": 0.6257,
      "step": 860700
    },
    {
      "epoch": 9.112226803796295,
      "grad_norm": 4.5074944496154785,
      "learning_rate": 4.458712682616981e-06,
      "loss": 0.6136,
      "step": 860750
    },
    {
      "epoch": 9.112756125576299,
      "grad_norm": 4.987571716308594,
      "learning_rate": 4.456066059707812e-06,
      "loss": 0.6217,
      "step": 860800
    },
    {
      "epoch": 9.113285447356303,
      "grad_norm": 5.0125226974487305,
      "learning_rate": 4.453419436798645e-06,
      "loss": 0.6325,
      "step": 860850
    },
    {
      "epoch": 9.113814769136306,
      "grad_norm": 4.458490371704102,
      "learning_rate": 4.450772813889477e-06,
      "loss": 0.625,
      "step": 860900
    },
    {
      "epoch": 9.114344090916308,
      "grad_norm": 4.666903495788574,
      "learning_rate": 4.448126190980309e-06,
      "loss": 0.6345,
      "step": 860950
    },
    {
      "epoch": 9.114873412696312,
      "grad_norm": 4.41886568069458,
      "learning_rate": 4.445479568071141e-06,
      "loss": 0.6205,
      "step": 861000
    },
    {
      "epoch": 9.114873412696312,
      "eval_loss": 0.3799430727958679,
      "eval_runtime": 46.4325,
      "eval_samples_per_second": 3616.651,
      "eval_steps_per_second": 452.098,
      "step": 861000
    },
    {
      "epoch": 9.115402734476316,
      "grad_norm": 4.9332451820373535,
      "learning_rate": 4.4428329451619735e-06,
      "loss": 0.6183,
      "step": 861050
    },
    {
      "epoch": 9.11593205625632,
      "grad_norm": 5.171578884124756,
      "learning_rate": 4.440186322252805e-06,
      "loss": 0.6395,
      "step": 861100
    },
    {
      "epoch": 9.116461378036322,
      "grad_norm": 4.120087146759033,
      "learning_rate": 4.4375396993436374e-06,
      "loss": 0.6242,
      "step": 861150
    },
    {
      "epoch": 9.116990699816325,
      "grad_norm": 4.5262980461120605,
      "learning_rate": 4.43489307643447e-06,
      "loss": 0.6191,
      "step": 861200
    },
    {
      "epoch": 9.117520021596329,
      "grad_norm": 4.630021095275879,
      "learning_rate": 4.432246453525301e-06,
      "loss": 0.6199,
      "step": 861250
    },
    {
      "epoch": 9.118049343376333,
      "grad_norm": 4.442079067230225,
      "learning_rate": 4.429599830616134e-06,
      "loss": 0.6191,
      "step": 861300
    },
    {
      "epoch": 9.118578665156335,
      "grad_norm": 4.443520545959473,
      "learning_rate": 4.426953207706966e-06,
      "loss": 0.6248,
      "step": 861350
    },
    {
      "epoch": 9.119107986936339,
      "grad_norm": 4.428750514984131,
      "learning_rate": 4.424306584797798e-06,
      "loss": 0.621,
      "step": 861400
    },
    {
      "epoch": 9.119637308716342,
      "grad_norm": 4.99722146987915,
      "learning_rate": 4.42165996188863e-06,
      "loss": 0.6217,
      "step": 861450
    },
    {
      "epoch": 9.120166630496344,
      "grad_norm": 4.7538933753967285,
      "learning_rate": 4.419013338979463e-06,
      "loss": 0.6271,
      "step": 861500
    },
    {
      "epoch": 9.120166630496344,
      "eval_loss": 0.3801674544811249,
      "eval_runtime": 46.4557,
      "eval_samples_per_second": 3614.844,
      "eval_steps_per_second": 451.872,
      "step": 861500
    },
    {
      "epoch": 9.120695952276348,
      "grad_norm": 5.1309733390808105,
      "learning_rate": 4.416366716070294e-06,
      "loss": 0.6231,
      "step": 861550
    },
    {
      "epoch": 9.121225274056352,
      "grad_norm": 4.825705528259277,
      "learning_rate": 4.4137200931611266e-06,
      "loss": 0.6302,
      "step": 861600
    },
    {
      "epoch": 9.121754595836356,
      "grad_norm": 4.2921271324157715,
      "learning_rate": 4.411073470251958e-06,
      "loss": 0.6257,
      "step": 861650
    },
    {
      "epoch": 9.122283917616357,
      "grad_norm": 4.846342086791992,
      "learning_rate": 4.4084268473427905e-06,
      "loss": 0.6176,
      "step": 861700
    },
    {
      "epoch": 9.122813239396361,
      "grad_norm": 4.380916595458984,
      "learning_rate": 4.405780224433623e-06,
      "loss": 0.6235,
      "step": 861750
    },
    {
      "epoch": 9.123342561176365,
      "grad_norm": 4.807011604309082,
      "learning_rate": 4.4031336015244545e-06,
      "loss": 0.624,
      "step": 861800
    },
    {
      "epoch": 9.123871882956369,
      "grad_norm": 4.850602149963379,
      "learning_rate": 4.400486978615287e-06,
      "loss": 0.6105,
      "step": 861850
    },
    {
      "epoch": 9.12440120473637,
      "grad_norm": 4.718857765197754,
      "learning_rate": 4.397840355706119e-06,
      "loss": 0.619,
      "step": 861900
    },
    {
      "epoch": 9.124930526516374,
      "grad_norm": 4.440683364868164,
      "learning_rate": 4.395193732796951e-06,
      "loss": 0.6198,
      "step": 861950
    },
    {
      "epoch": 9.125459848296378,
      "grad_norm": 4.664697170257568,
      "learning_rate": 4.392547109887783e-06,
      "loss": 0.6369,
      "step": 862000
    },
    {
      "epoch": 9.125459848296378,
      "eval_loss": 0.37968289852142334,
      "eval_runtime": 46.4699,
      "eval_samples_per_second": 3613.734,
      "eval_steps_per_second": 451.733,
      "step": 862000
    },
    {
      "epoch": 9.125989170076382,
      "grad_norm": 4.492807388305664,
      "learning_rate": 4.389900486978616e-06,
      "loss": 0.6273,
      "step": 862050
    },
    {
      "epoch": 9.126518491856384,
      "grad_norm": 4.251913547515869,
      "learning_rate": 4.387253864069447e-06,
      "loss": 0.6259,
      "step": 862100
    },
    {
      "epoch": 9.127047813636388,
      "grad_norm": 4.592465400695801,
      "learning_rate": 4.38460724116028e-06,
      "loss": 0.6187,
      "step": 862150
    },
    {
      "epoch": 9.127577135416391,
      "grad_norm": 4.669778347015381,
      "learning_rate": 4.381960618251112e-06,
      "loss": 0.6115,
      "step": 862200
    },
    {
      "epoch": 9.128106457196393,
      "grad_norm": 4.843379020690918,
      "learning_rate": 4.379313995341944e-06,
      "loss": 0.6299,
      "step": 862250
    },
    {
      "epoch": 9.128635778976397,
      "grad_norm": 4.41900110244751,
      "learning_rate": 4.376667372432776e-06,
      "loss": 0.623,
      "step": 862300
    },
    {
      "epoch": 9.129165100756401,
      "grad_norm": 4.684080123901367,
      "learning_rate": 4.3740207495236076e-06,
      "loss": 0.6252,
      "step": 862350
    },
    {
      "epoch": 9.129694422536405,
      "grad_norm": 4.535759925842285,
      "learning_rate": 4.37137412661444e-06,
      "loss": 0.6209,
      "step": 862400
    },
    {
      "epoch": 9.130223744316407,
      "grad_norm": 4.747922897338867,
      "learning_rate": 4.368727503705272e-06,
      "loss": 0.622,
      "step": 862450
    },
    {
      "epoch": 9.13075306609641,
      "grad_norm": 4.603445529937744,
      "learning_rate": 4.366080880796104e-06,
      "loss": 0.6247,
      "step": 862500
    },
    {
      "epoch": 9.13075306609641,
      "eval_loss": 0.37951499223709106,
      "eval_runtime": 46.5798,
      "eval_samples_per_second": 3605.212,
      "eval_steps_per_second": 450.668,
      "step": 862500
    },
    {
      "epoch": 9.131282387876414,
      "grad_norm": 4.4789958000183105,
      "learning_rate": 4.363434257886936e-06,
      "loss": 0.6244,
      "step": 862550
    },
    {
      "epoch": 9.131811709656418,
      "grad_norm": 4.575657844543457,
      "learning_rate": 4.360787634977769e-06,
      "loss": 0.6298,
      "step": 862600
    },
    {
      "epoch": 9.13234103143642,
      "grad_norm": 4.6037211418151855,
      "learning_rate": 4.3581410120686e-06,
      "loss": 0.631,
      "step": 862650
    },
    {
      "epoch": 9.132870353216424,
      "grad_norm": 5.107213020324707,
      "learning_rate": 4.355494389159433e-06,
      "loss": 0.6458,
      "step": 862700
    },
    {
      "epoch": 9.133399674996427,
      "grad_norm": 4.653939247131348,
      "learning_rate": 4.352847766250265e-06,
      "loss": 0.6321,
      "step": 862750
    },
    {
      "epoch": 9.133928996776431,
      "grad_norm": 4.620728492736816,
      "learning_rate": 4.350201143341097e-06,
      "loss": 0.6281,
      "step": 862800
    },
    {
      "epoch": 9.134458318556433,
      "grad_norm": 4.5488128662109375,
      "learning_rate": 4.347554520431929e-06,
      "loss": 0.6177,
      "step": 862850
    },
    {
      "epoch": 9.134987640336437,
      "grad_norm": 4.747202396392822,
      "learning_rate": 4.3449078975227615e-06,
      "loss": 0.6234,
      "step": 862900
    },
    {
      "epoch": 9.13551696211644,
      "grad_norm": 4.8616204261779785,
      "learning_rate": 4.342261274613593e-06,
      "loss": 0.6234,
      "step": 862950
    },
    {
      "epoch": 9.136046283896443,
      "grad_norm": 4.866855144500732,
      "learning_rate": 4.3396146517044254e-06,
      "loss": 0.6296,
      "step": 863000
    },
    {
      "epoch": 9.136046283896443,
      "eval_loss": 0.3793348968029022,
      "eval_runtime": 46.4617,
      "eval_samples_per_second": 3614.378,
      "eval_steps_per_second": 451.813,
      "step": 863000
    },
    {
      "epoch": 9.136575605676446,
      "grad_norm": 4.1440043449401855,
      "learning_rate": 4.336968028795258e-06,
      "loss": 0.6225,
      "step": 863050
    },
    {
      "epoch": 9.13710492745645,
      "grad_norm": 4.663089275360107,
      "learning_rate": 4.334321405886089e-06,
      "loss": 0.6339,
      "step": 863100
    },
    {
      "epoch": 9.137634249236454,
      "grad_norm": 4.457891464233398,
      "learning_rate": 4.331674782976922e-06,
      "loss": 0.616,
      "step": 863150
    },
    {
      "epoch": 9.138163571016456,
      "grad_norm": 5.007160663604736,
      "learning_rate": 4.329028160067753e-06,
      "loss": 0.6249,
      "step": 863200
    },
    {
      "epoch": 9.13869289279646,
      "grad_norm": 4.97732400894165,
      "learning_rate": 4.326381537158586e-06,
      "loss": 0.6223,
      "step": 863250
    },
    {
      "epoch": 9.139222214576463,
      "grad_norm": 5.138978004455566,
      "learning_rate": 4.323734914249418e-06,
      "loss": 0.6278,
      "step": 863300
    },
    {
      "epoch": 9.139751536356467,
      "grad_norm": 4.285049915313721,
      "learning_rate": 4.32108829134025e-06,
      "loss": 0.6217,
      "step": 863350
    },
    {
      "epoch": 9.14028085813647,
      "grad_norm": 4.165647983551025,
      "learning_rate": 4.318441668431082e-06,
      "loss": 0.6198,
      "step": 863400
    },
    {
      "epoch": 9.140810179916473,
      "grad_norm": 5.0305867195129395,
      "learning_rate": 4.315847977980098e-06,
      "loss": 0.6223,
      "step": 863450
    },
    {
      "epoch": 9.141339501696477,
      "grad_norm": 4.511390686035156,
      "learning_rate": 4.313201355070929e-06,
      "loss": 0.6256,
      "step": 863500
    },
    {
      "epoch": 9.141339501696477,
      "eval_loss": 0.3794392943382263,
      "eval_runtime": 46.5207,
      "eval_samples_per_second": 3609.795,
      "eval_steps_per_second": 451.24,
      "step": 863500
    },
    {
      "epoch": 9.14186882347648,
      "grad_norm": 4.489001750946045,
      "learning_rate": 4.310554732161762e-06,
      "loss": 0.6131,
      "step": 863550
    },
    {
      "epoch": 9.142398145256482,
      "grad_norm": 5.208439826965332,
      "learning_rate": 4.307908109252594e-06,
      "loss": 0.6225,
      "step": 863600
    },
    {
      "epoch": 9.142927467036486,
      "grad_norm": 4.883333683013916,
      "learning_rate": 4.305261486343426e-06,
      "loss": 0.6232,
      "step": 863650
    },
    {
      "epoch": 9.14345678881649,
      "grad_norm": 4.992710113525391,
      "learning_rate": 4.302614863434258e-06,
      "loss": 0.6188,
      "step": 863700
    },
    {
      "epoch": 9.143986110596492,
      "grad_norm": 4.901430130004883,
      "learning_rate": 4.2999682405250904e-06,
      "loss": 0.623,
      "step": 863750
    },
    {
      "epoch": 9.144515432376496,
      "grad_norm": 4.713939189910889,
      "learning_rate": 4.297321617615922e-06,
      "loss": 0.6245,
      "step": 863800
    },
    {
      "epoch": 9.1450447541565,
      "grad_norm": 4.653850078582764,
      "learning_rate": 4.294674994706754e-06,
      "loss": 0.6312,
      "step": 863850
    },
    {
      "epoch": 9.145574075936503,
      "grad_norm": 4.632244110107422,
      "learning_rate": 4.292028371797587e-06,
      "loss": 0.6106,
      "step": 863900
    },
    {
      "epoch": 9.146103397716505,
      "grad_norm": 4.252503871917725,
      "learning_rate": 4.289381748888418e-06,
      "loss": 0.6266,
      "step": 863950
    },
    {
      "epoch": 9.146632719496509,
      "grad_norm": 4.650263786315918,
      "learning_rate": 4.286735125979251e-06,
      "loss": 0.6168,
      "step": 864000
    },
    {
      "epoch": 9.146632719496509,
      "eval_loss": 0.3791704475879669,
      "eval_runtime": 46.5191,
      "eval_samples_per_second": 3609.916,
      "eval_steps_per_second": 451.256,
      "step": 864000
    },
    {
      "epoch": 9.147162041276513,
      "grad_norm": 4.702215671539307,
      "learning_rate": 4.284088503070083e-06,
      "loss": 0.6245,
      "step": 864050
    },
    {
      "epoch": 9.147691363056516,
      "grad_norm": 4.889627933502197,
      "learning_rate": 4.281441880160915e-06,
      "loss": 0.6242,
      "step": 864100
    },
    {
      "epoch": 9.148220684836518,
      "grad_norm": 4.671429634094238,
      "learning_rate": 4.278795257251747e-06,
      "loss": 0.629,
      "step": 864150
    },
    {
      "epoch": 9.148750006616522,
      "grad_norm": 4.419614791870117,
      "learning_rate": 4.276148634342579e-06,
      "loss": 0.6334,
      "step": 864200
    },
    {
      "epoch": 9.149279328396526,
      "grad_norm": 4.495156764984131,
      "learning_rate": 4.273502011433411e-06,
      "loss": 0.6222,
      "step": 864250
    },
    {
      "epoch": 9.14980865017653,
      "grad_norm": 4.327956199645996,
      "learning_rate": 4.2708553885242435e-06,
      "loss": 0.634,
      "step": 864300
    },
    {
      "epoch": 9.150337971956532,
      "grad_norm": 4.653629779815674,
      "learning_rate": 4.268208765615075e-06,
      "loss": 0.623,
      "step": 864350
    },
    {
      "epoch": 9.150867293736535,
      "grad_norm": 4.413087844848633,
      "learning_rate": 4.2655621427059075e-06,
      "loss": 0.6291,
      "step": 864400
    },
    {
      "epoch": 9.15139661551654,
      "grad_norm": 4.703101634979248,
      "learning_rate": 4.26291551979674e-06,
      "loss": 0.6308,
      "step": 864450
    },
    {
      "epoch": 9.151925937296541,
      "grad_norm": 4.656938552856445,
      "learning_rate": 4.2602688968875715e-06,
      "loss": 0.628,
      "step": 864500
    },
    {
      "epoch": 9.151925937296541,
      "eval_loss": 0.379975289106369,
      "eval_runtime": 46.4741,
      "eval_samples_per_second": 3613.407,
      "eval_steps_per_second": 451.692,
      "step": 864500
    },
    {
      "epoch": 9.152455259076545,
      "grad_norm": 4.375566482543945,
      "learning_rate": 4.257622273978404e-06,
      "loss": 0.6215,
      "step": 864550
    },
    {
      "epoch": 9.152984580856549,
      "grad_norm": 4.712798118591309,
      "learning_rate": 4.254975651069236e-06,
      "loss": 0.6298,
      "step": 864600
    },
    {
      "epoch": 9.153513902636552,
      "grad_norm": 5.27607536315918,
      "learning_rate": 4.252329028160068e-06,
      "loss": 0.6329,
      "step": 864650
    },
    {
      "epoch": 9.154043224416554,
      "grad_norm": 4.653008937835693,
      "learning_rate": 4.2496824052509e-06,
      "loss": 0.6267,
      "step": 864700
    },
    {
      "epoch": 9.154572546196558,
      "grad_norm": 4.346675395965576,
      "learning_rate": 4.247035782341733e-06,
      "loss": 0.6199,
      "step": 864750
    },
    {
      "epoch": 9.155101867976562,
      "grad_norm": 4.446576118469238,
      "learning_rate": 4.244389159432564e-06,
      "loss": 0.6309,
      "step": 864800
    },
    {
      "epoch": 9.155631189756566,
      "grad_norm": 4.918712615966797,
      "learning_rate": 4.241742536523397e-06,
      "loss": 0.6259,
      "step": 864850
    },
    {
      "epoch": 9.156160511536568,
      "grad_norm": 4.58805513381958,
      "learning_rate": 4.239095913614229e-06,
      "loss": 0.6212,
      "step": 864900
    },
    {
      "epoch": 9.156689833316571,
      "grad_norm": 4.48253059387207,
      "learning_rate": 4.2364492907050606e-06,
      "loss": 0.6206,
      "step": 864950
    },
    {
      "epoch": 9.157219155096575,
      "grad_norm": 4.8488593101501465,
      "learning_rate": 4.233802667795893e-06,
      "loss": 0.6362,
      "step": 865000
    },
    {
      "epoch": 9.157219155096575,
      "eval_loss": 0.3797217607498169,
      "eval_runtime": 46.5272,
      "eval_samples_per_second": 3609.284,
      "eval_steps_per_second": 451.177,
      "step": 865000
    },
    {
      "epoch": 9.157748476876579,
      "grad_norm": 5.03304386138916,
      "learning_rate": 4.2311560448867245e-06,
      "loss": 0.6235,
      "step": 865050
    },
    {
      "epoch": 9.15827779865658,
      "grad_norm": 5.083939552307129,
      "learning_rate": 4.228509421977557e-06,
      "loss": 0.6128,
      "step": 865100
    },
    {
      "epoch": 9.158807120436585,
      "grad_norm": 4.201862812042236,
      "learning_rate": 4.225862799068389e-06,
      "loss": 0.6228,
      "step": 865150
    },
    {
      "epoch": 9.159336442216588,
      "grad_norm": 4.737468719482422,
      "learning_rate": 4.223216176159221e-06,
      "loss": 0.6223,
      "step": 865200
    },
    {
      "epoch": 9.15986576399659,
      "grad_norm": 4.7491655349731445,
      "learning_rate": 4.220569553250053e-06,
      "loss": 0.6258,
      "step": 865250
    },
    {
      "epoch": 9.160395085776594,
      "grad_norm": 4.596640586853027,
      "learning_rate": 4.217922930340886e-06,
      "loss": 0.6235,
      "step": 865300
    },
    {
      "epoch": 9.160924407556598,
      "grad_norm": 4.859038829803467,
      "learning_rate": 4.215276307431717e-06,
      "loss": 0.6219,
      "step": 865350
    },
    {
      "epoch": 9.161453729336602,
      "grad_norm": 4.559299945831299,
      "learning_rate": 4.21262968452255e-06,
      "loss": 0.6345,
      "step": 865400
    },
    {
      "epoch": 9.161983051116604,
      "grad_norm": 4.70246696472168,
      "learning_rate": 4.209983061613382e-06,
      "loss": 0.6189,
      "step": 865450
    },
    {
      "epoch": 9.162512372896607,
      "grad_norm": 4.6518449783325195,
      "learning_rate": 4.207336438704214e-06,
      "loss": 0.6182,
      "step": 865500
    },
    {
      "epoch": 9.162512372896607,
      "eval_loss": 0.3792557716369629,
      "eval_runtime": 46.4564,
      "eval_samples_per_second": 3614.79,
      "eval_steps_per_second": 451.865,
      "step": 865500
    },
    {
      "epoch": 9.163041694676611,
      "grad_norm": 4.719706058502197,
      "learning_rate": 4.204689815795046e-06,
      "loss": 0.6211,
      "step": 865550
    },
    {
      "epoch": 9.163571016456615,
      "grad_norm": 4.664847373962402,
      "learning_rate": 4.2020431928858785e-06,
      "loss": 0.6361,
      "step": 865600
    },
    {
      "epoch": 9.164100338236617,
      "grad_norm": 4.478909492492676,
      "learning_rate": 4.19939656997671e-06,
      "loss": 0.6205,
      "step": 865650
    },
    {
      "epoch": 9.16462966001662,
      "grad_norm": 4.307525634765625,
      "learning_rate": 4.196749947067542e-06,
      "loss": 0.6212,
      "step": 865700
    },
    {
      "epoch": 9.165158981796624,
      "grad_norm": 4.606740951538086,
      "learning_rate": 4.194103324158374e-06,
      "loss": 0.6248,
      "step": 865750
    },
    {
      "epoch": 9.165688303576628,
      "grad_norm": 4.466113090515137,
      "learning_rate": 4.191456701249206e-06,
      "loss": 0.6257,
      "step": 865800
    },
    {
      "epoch": 9.16621762535663,
      "grad_norm": 4.856822490692139,
      "learning_rate": 4.188810078340039e-06,
      "loss": 0.6316,
      "step": 865850
    },
    {
      "epoch": 9.166746947136634,
      "grad_norm": 4.668178558349609,
      "learning_rate": 4.18616345543087e-06,
      "loss": 0.6241,
      "step": 865900
    },
    {
      "epoch": 9.167276268916638,
      "grad_norm": 4.548659324645996,
      "learning_rate": 4.183516832521703e-06,
      "loss": 0.6224,
      "step": 865950
    },
    {
      "epoch": 9.16780559069664,
      "grad_norm": 4.795701026916504,
      "learning_rate": 4.180923142070718e-06,
      "loss": 0.6295,
      "step": 866000
    },
    {
      "epoch": 9.16780559069664,
      "eval_loss": 0.37904009222984314,
      "eval_runtime": 46.5805,
      "eval_samples_per_second": 3605.156,
      "eval_steps_per_second": 450.661,
      "step": 866000
    },
    {
      "epoch": 9.168334912476643,
      "grad_norm": 4.625136852264404,
      "learning_rate": 4.17827651916155e-06,
      "loss": 0.6215,
      "step": 866050
    },
    {
      "epoch": 9.168864234256647,
      "grad_norm": 4.605766773223877,
      "learning_rate": 4.175629896252382e-06,
      "loss": 0.6155,
      "step": 866100
    },
    {
      "epoch": 9.16939355603665,
      "grad_norm": 4.8776421546936035,
      "learning_rate": 4.172983273343215e-06,
      "loss": 0.6224,
      "step": 866150
    },
    {
      "epoch": 9.169922877816653,
      "grad_norm": 4.840278148651123,
      "learning_rate": 4.170336650434046e-06,
      "loss": 0.6248,
      "step": 866200
    },
    {
      "epoch": 9.170452199596657,
      "grad_norm": 4.628324508666992,
      "learning_rate": 4.167690027524879e-06,
      "loss": 0.6148,
      "step": 866250
    },
    {
      "epoch": 9.17098152137666,
      "grad_norm": 4.341984748840332,
      "learning_rate": 4.165043404615711e-06,
      "loss": 0.6251,
      "step": 866300
    },
    {
      "epoch": 9.171510843156664,
      "grad_norm": 4.654258728027344,
      "learning_rate": 4.162396781706543e-06,
      "loss": 0.6116,
      "step": 866350
    },
    {
      "epoch": 9.172040164936666,
      "grad_norm": 5.0835723876953125,
      "learning_rate": 4.159750158797375e-06,
      "loss": 0.6298,
      "step": 866400
    },
    {
      "epoch": 9.17256948671667,
      "grad_norm": 4.368741512298584,
      "learning_rate": 4.157103535888207e-06,
      "loss": 0.6193,
      "step": 866450
    },
    {
      "epoch": 9.173098808496674,
      "grad_norm": 5.030642032623291,
      "learning_rate": 4.154456912979039e-06,
      "loss": 0.6236,
      "step": 866500
    },
    {
      "epoch": 9.173098808496674,
      "eval_loss": 0.3793517053127289,
      "eval_runtime": 46.6047,
      "eval_samples_per_second": 3603.282,
      "eval_steps_per_second": 450.426,
      "step": 866500
    },
    {
      "epoch": 9.173628130276677,
      "grad_norm": 4.941697597503662,
      "learning_rate": 4.151810290069871e-06,
      "loss": 0.6211,
      "step": 866550
    },
    {
      "epoch": 9.17415745205668,
      "grad_norm": 4.507066249847412,
      "learning_rate": 4.149163667160704e-06,
      "loss": 0.6172,
      "step": 866600
    },
    {
      "epoch": 9.174686773836683,
      "grad_norm": 4.4465508460998535,
      "learning_rate": 4.146517044251535e-06,
      "loss": 0.6212,
      "step": 866650
    },
    {
      "epoch": 9.175216095616687,
      "grad_norm": 4.467845439910889,
      "learning_rate": 4.143870421342368e-06,
      "loss": 0.6212,
      "step": 866700
    },
    {
      "epoch": 9.175745417396689,
      "grad_norm": 4.975453853607178,
      "learning_rate": 4.1412237984332e-06,
      "loss": 0.6288,
      "step": 866750
    },
    {
      "epoch": 9.176274739176693,
      "grad_norm": 4.761158466339111,
      "learning_rate": 4.138577175524032e-06,
      "loss": 0.61,
      "step": 866800
    },
    {
      "epoch": 9.176804060956696,
      "grad_norm": 4.407745361328125,
      "learning_rate": 4.135930552614864e-06,
      "loss": 0.6145,
      "step": 866850
    },
    {
      "epoch": 9.1773333827367,
      "grad_norm": 4.496103286743164,
      "learning_rate": 4.133283929705696e-06,
      "loss": 0.6311,
      "step": 866900
    },
    {
      "epoch": 9.177862704516702,
      "grad_norm": 5.111358642578125,
      "learning_rate": 4.130637306796528e-06,
      "loss": 0.617,
      "step": 866950
    },
    {
      "epoch": 9.178392026296706,
      "grad_norm": 5.0862650871276855,
      "learning_rate": 4.1279906838873605e-06,
      "loss": 0.611,
      "step": 867000
    },
    {
      "epoch": 9.178392026296706,
      "eval_loss": 0.3788321614265442,
      "eval_runtime": 46.5681,
      "eval_samples_per_second": 3606.119,
      "eval_steps_per_second": 450.781,
      "step": 867000
    },
    {
      "epoch": 9.17892134807671,
      "grad_norm": 4.474215984344482,
      "learning_rate": 4.125344060978192e-06,
      "loss": 0.6276,
      "step": 867050
    },
    {
      "epoch": 9.179450669856713,
      "grad_norm": 4.793243885040283,
      "learning_rate": 4.122697438069024e-06,
      "loss": 0.6257,
      "step": 867100
    },
    {
      "epoch": 9.179979991636715,
      "grad_norm": 4.269415855407715,
      "learning_rate": 4.120050815159856e-06,
      "loss": 0.6294,
      "step": 867150
    },
    {
      "epoch": 9.180509313416719,
      "grad_norm": 4.818483829498291,
      "learning_rate": 4.1174041922506876e-06,
      "loss": 0.616,
      "step": 867200
    },
    {
      "epoch": 9.181038635196723,
      "grad_norm": 4.93881368637085,
      "learning_rate": 4.11475756934152e-06,
      "loss": 0.6202,
      "step": 867250
    },
    {
      "epoch": 9.181567956976727,
      "grad_norm": 4.1034345626831055,
      "learning_rate": 4.112110946432352e-06,
      "loss": 0.6228,
      "step": 867300
    },
    {
      "epoch": 9.182097278756729,
      "grad_norm": 4.761873245239258,
      "learning_rate": 4.109464323523184e-06,
      "loss": 0.6207,
      "step": 867350
    },
    {
      "epoch": 9.182626600536732,
      "grad_norm": 4.603365421295166,
      "learning_rate": 4.106817700614016e-06,
      "loss": 0.6293,
      "step": 867400
    },
    {
      "epoch": 9.183155922316736,
      "grad_norm": 4.514057636260986,
      "learning_rate": 4.104171077704849e-06,
      "loss": 0.6234,
      "step": 867450
    },
    {
      "epoch": 9.183685244096738,
      "grad_norm": 4.854559421539307,
      "learning_rate": 4.10152445479568e-06,
      "loss": 0.6232,
      "step": 867500
    },
    {
      "epoch": 9.183685244096738,
      "eval_loss": 0.37916654348373413,
      "eval_runtime": 46.5817,
      "eval_samples_per_second": 3605.067,
      "eval_steps_per_second": 450.649,
      "step": 867500
    },
    {
      "epoch": 9.184214565876742,
      "grad_norm": 4.348419666290283,
      "learning_rate": 4.098877831886513e-06,
      "loss": 0.6114,
      "step": 867550
    },
    {
      "epoch": 9.184743887656746,
      "grad_norm": 4.925363540649414,
      "learning_rate": 4.096231208977345e-06,
      "loss": 0.6212,
      "step": 867600
    },
    {
      "epoch": 9.18527320943675,
      "grad_norm": 4.634645462036133,
      "learning_rate": 4.093584586068177e-06,
      "loss": 0.6175,
      "step": 867650
    },
    {
      "epoch": 9.185802531216751,
      "grad_norm": 4.44844388961792,
      "learning_rate": 4.090937963159009e-06,
      "loss": 0.6218,
      "step": 867700
    },
    {
      "epoch": 9.186331852996755,
      "grad_norm": 4.641194820404053,
      "learning_rate": 4.0882913402498415e-06,
      "loss": 0.6187,
      "step": 867750
    },
    {
      "epoch": 9.186861174776759,
      "grad_norm": 5.177646636962891,
      "learning_rate": 4.085644717340673e-06,
      "loss": 0.6169,
      "step": 867800
    },
    {
      "epoch": 9.187390496556763,
      "grad_norm": 4.532384395599365,
      "learning_rate": 4.0829980944315055e-06,
      "loss": 0.6221,
      "step": 867850
    },
    {
      "epoch": 9.187919818336765,
      "grad_norm": 4.767524719238281,
      "learning_rate": 4.080351471522338e-06,
      "loss": 0.6393,
      "step": 867900
    },
    {
      "epoch": 9.188449140116768,
      "grad_norm": 4.6542229652404785,
      "learning_rate": 4.0777048486131694e-06,
      "loss": 0.6237,
      "step": 867950
    },
    {
      "epoch": 9.188978461896772,
      "grad_norm": 5.223028182983398,
      "learning_rate": 4.075058225704002e-06,
      "loss": 0.6374,
      "step": 868000
    },
    {
      "epoch": 9.188978461896772,
      "eval_loss": 0.3788049519062042,
      "eval_runtime": 46.5042,
      "eval_samples_per_second": 3611.074,
      "eval_steps_per_second": 451.4,
      "step": 868000
    },
    {
      "epoch": 9.189507783676776,
      "grad_norm": 5.272610664367676,
      "learning_rate": 4.072411602794833e-06,
      "loss": 0.634,
      "step": 868050
    },
    {
      "epoch": 9.190037105456778,
      "grad_norm": 4.6507568359375,
      "learning_rate": 4.069764979885666e-06,
      "loss": 0.6302,
      "step": 868100
    },
    {
      "epoch": 9.190566427236782,
      "grad_norm": 4.442495346069336,
      "learning_rate": 4.067118356976498e-06,
      "loss": 0.6332,
      "step": 868150
    },
    {
      "epoch": 9.191095749016785,
      "grad_norm": 5.0324296951293945,
      "learning_rate": 4.06447173406733e-06,
      "loss": 0.6178,
      "step": 868200
    },
    {
      "epoch": 9.191625070796787,
      "grad_norm": 5.03618860244751,
      "learning_rate": 4.061825111158162e-06,
      "loss": 0.6249,
      "step": 868250
    },
    {
      "epoch": 9.192154392576791,
      "grad_norm": 4.393751621246338,
      "learning_rate": 4.0591784882489946e-06,
      "loss": 0.6182,
      "step": 868300
    },
    {
      "epoch": 9.192683714356795,
      "grad_norm": 5.141965866088867,
      "learning_rate": 4.056531865339826e-06,
      "loss": 0.6345,
      "step": 868350
    },
    {
      "epoch": 9.193213036136799,
      "grad_norm": 4.44600772857666,
      "learning_rate": 4.0538852424306585e-06,
      "loss": 0.6215,
      "step": 868400
    },
    {
      "epoch": 9.1937423579168,
      "grad_norm": 4.809098243713379,
      "learning_rate": 4.051238619521491e-06,
      "loss": 0.6294,
      "step": 868450
    },
    {
      "epoch": 9.194271679696804,
      "grad_norm": 4.440895080566406,
      "learning_rate": 4.0485919966123225e-06,
      "loss": 0.6237,
      "step": 868500
    },
    {
      "epoch": 9.194271679696804,
      "eval_loss": 0.37881627678871155,
      "eval_runtime": 46.9406,
      "eval_samples_per_second": 3577.499,
      "eval_steps_per_second": 447.203,
      "step": 868500
    },
    {
      "epoch": 9.194801001476808,
      "grad_norm": 4.912905693054199,
      "learning_rate": 4.045945373703155e-06,
      "loss": 0.634,
      "step": 868550
    },
    {
      "epoch": 9.195330323256812,
      "grad_norm": 4.925800323486328,
      "learning_rate": 4.043298750793987e-06,
      "loss": 0.6153,
      "step": 868600
    },
    {
      "epoch": 9.195859645036814,
      "grad_norm": 4.9255876541137695,
      "learning_rate": 4.040652127884819e-06,
      "loss": 0.6189,
      "step": 868650
    },
    {
      "epoch": 9.196388966816818,
      "grad_norm": 4.612174987792969,
      "learning_rate": 4.038005504975651e-06,
      "loss": 0.6084,
      "step": 868700
    },
    {
      "epoch": 9.196918288596821,
      "grad_norm": 5.008281707763672,
      "learning_rate": 4.035358882066483e-06,
      "loss": 0.6259,
      "step": 868750
    },
    {
      "epoch": 9.197447610376825,
      "grad_norm": 4.933567523956299,
      "learning_rate": 4.032712259157315e-06,
      "loss": 0.6306,
      "step": 868800
    },
    {
      "epoch": 9.197976932156827,
      "grad_norm": 4.601334571838379,
      "learning_rate": 4.030065636248148e-06,
      "loss": 0.6179,
      "step": 868850
    },
    {
      "epoch": 9.19850625393683,
      "grad_norm": 4.516506195068359,
      "learning_rate": 4.027419013338979e-06,
      "loss": 0.6154,
      "step": 868900
    },
    {
      "epoch": 9.199035575716835,
      "grad_norm": 4.567155838012695,
      "learning_rate": 4.024772390429812e-06,
      "loss": 0.6226,
      "step": 868950
    },
    {
      "epoch": 9.199564897496836,
      "grad_norm": 4.877050399780273,
      "learning_rate": 4.022125767520644e-06,
      "loss": 0.6309,
      "step": 869000
    },
    {
      "epoch": 9.199564897496836,
      "eval_loss": 0.3791893422603607,
      "eval_runtime": 46.5338,
      "eval_samples_per_second": 3608.773,
      "eval_steps_per_second": 451.113,
      "step": 869000
    },
    {
      "epoch": 9.20009421927684,
      "grad_norm": 4.44858980178833,
      "learning_rate": 4.019532077069659e-06,
      "loss": 0.6275,
      "step": 869050
    },
    {
      "epoch": 9.200623541056844,
      "grad_norm": 4.722134590148926,
      "learning_rate": 4.016885454160491e-06,
      "loss": 0.6136,
      "step": 869100
    },
    {
      "epoch": 9.201152862836848,
      "grad_norm": 4.790258407592773,
      "learning_rate": 4.0142388312513235e-06,
      "loss": 0.6269,
      "step": 869150
    },
    {
      "epoch": 9.20168218461685,
      "grad_norm": 5.002742767333984,
      "learning_rate": 4.011592208342155e-06,
      "loss": 0.6194,
      "step": 869200
    },
    {
      "epoch": 9.202211506396853,
      "grad_norm": 4.578651428222656,
      "learning_rate": 4.0089455854329875e-06,
      "loss": 0.6303,
      "step": 869250
    },
    {
      "epoch": 9.202740828176857,
      "grad_norm": 4.193932056427002,
      "learning_rate": 4.00629896252382e-06,
      "loss": 0.6083,
      "step": 869300
    },
    {
      "epoch": 9.203270149956861,
      "grad_norm": 4.4830756187438965,
      "learning_rate": 4.0036523396146515e-06,
      "loss": 0.613,
      "step": 869350
    },
    {
      "epoch": 9.203799471736863,
      "grad_norm": 4.588392734527588,
      "learning_rate": 4.001005716705484e-06,
      "loss": 0.6147,
      "step": 869400
    },
    {
      "epoch": 9.204328793516867,
      "grad_norm": 4.2234954833984375,
      "learning_rate": 3.998359093796316e-06,
      "loss": 0.6306,
      "step": 869450
    },
    {
      "epoch": 9.20485811529687,
      "grad_norm": 4.871737957000732,
      "learning_rate": 3.995712470887148e-06,
      "loss": 0.6237,
      "step": 869500
    },
    {
      "epoch": 9.20485811529687,
      "eval_loss": 0.3787001967430115,
      "eval_runtime": 46.4612,
      "eval_samples_per_second": 3614.417,
      "eval_steps_per_second": 451.818,
      "step": 869500
    },
    {
      "epoch": 9.205387437076874,
      "grad_norm": 4.486057281494141,
      "learning_rate": 3.99306584797798e-06,
      "loss": 0.633,
      "step": 869550
    },
    {
      "epoch": 9.205916758856876,
      "grad_norm": 4.5413031578063965,
      "learning_rate": 3.990419225068813e-06,
      "loss": 0.6332,
      "step": 869600
    },
    {
      "epoch": 9.20644608063688,
      "grad_norm": 4.615225791931152,
      "learning_rate": 3.987772602159644e-06,
      "loss": 0.6272,
      "step": 869650
    },
    {
      "epoch": 9.206975402416884,
      "grad_norm": 4.296964645385742,
      "learning_rate": 3.985125979250477e-06,
      "loss": 0.6231,
      "step": 869700
    },
    {
      "epoch": 9.207504724196886,
      "grad_norm": 4.959567070007324,
      "learning_rate": 3.982479356341309e-06,
      "loss": 0.6353,
      "step": 869750
    },
    {
      "epoch": 9.20803404597689,
      "grad_norm": 4.655036449432373,
      "learning_rate": 3.979832733432141e-06,
      "loss": 0.6162,
      "step": 869800
    },
    {
      "epoch": 9.208563367756893,
      "grad_norm": 4.415830612182617,
      "learning_rate": 3.977186110522973e-06,
      "loss": 0.625,
      "step": 869850
    },
    {
      "epoch": 9.209092689536897,
      "grad_norm": 5.024192810058594,
      "learning_rate": 3.9745394876138045e-06,
      "loss": 0.6257,
      "step": 869900
    },
    {
      "epoch": 9.209622011316899,
      "grad_norm": 4.71705436706543,
      "learning_rate": 3.971892864704637e-06,
      "loss": 0.6235,
      "step": 869950
    },
    {
      "epoch": 9.210151333096903,
      "grad_norm": 4.481335163116455,
      "learning_rate": 3.969246241795469e-06,
      "loss": 0.6316,
      "step": 870000
    },
    {
      "epoch": 9.210151333096903,
      "eval_loss": 0.3789421319961548,
      "eval_runtime": 46.5205,
      "eval_samples_per_second": 3609.808,
      "eval_steps_per_second": 451.242,
      "step": 870000
    },
    {
      "epoch": 9.210680654876906,
      "grad_norm": 4.596678256988525,
      "learning_rate": 3.966599618886301e-06,
      "loss": 0.6227,
      "step": 870050
    },
    {
      "epoch": 9.21120997665691,
      "grad_norm": 4.283538818359375,
      "learning_rate": 3.963952995977133e-06,
      "loss": 0.6251,
      "step": 870100
    },
    {
      "epoch": 9.211739298436912,
      "grad_norm": 4.919125556945801,
      "learning_rate": 3.961306373067966e-06,
      "loss": 0.6303,
      "step": 870150
    },
    {
      "epoch": 9.212268620216916,
      "grad_norm": 4.532257556915283,
      "learning_rate": 3.958659750158797e-06,
      "loss": 0.6177,
      "step": 870200
    },
    {
      "epoch": 9.21279794199692,
      "grad_norm": 4.373571872711182,
      "learning_rate": 3.95601312724963e-06,
      "loss": 0.6196,
      "step": 870250
    },
    {
      "epoch": 9.213327263776923,
      "grad_norm": 4.72255277633667,
      "learning_rate": 3.953366504340462e-06,
      "loss": 0.6209,
      "step": 870300
    },
    {
      "epoch": 9.213856585556925,
      "grad_norm": 4.4024810791015625,
      "learning_rate": 3.950719881431294e-06,
      "loss": 0.6318,
      "step": 870350
    },
    {
      "epoch": 9.21438590733693,
      "grad_norm": 4.320350170135498,
      "learning_rate": 3.948073258522126e-06,
      "loss": 0.6092,
      "step": 870400
    },
    {
      "epoch": 9.214915229116933,
      "grad_norm": 4.693566799163818,
      "learning_rate": 3.9454266356129585e-06,
      "loss": 0.6144,
      "step": 870450
    },
    {
      "epoch": 9.215444550896935,
      "grad_norm": 4.918407917022705,
      "learning_rate": 3.94278001270379e-06,
      "loss": 0.621,
      "step": 870500
    },
    {
      "epoch": 9.215444550896935,
      "eval_loss": 0.3778722584247589,
      "eval_runtime": 46.506,
      "eval_samples_per_second": 3610.931,
      "eval_steps_per_second": 451.383,
      "step": 870500
    },
    {
      "epoch": 9.215973872676939,
      "grad_norm": 4.109989166259766,
      "learning_rate": 3.9401333897946224e-06,
      "loss": 0.6249,
      "step": 870550
    },
    {
      "epoch": 9.216503194456942,
      "grad_norm": 4.103916168212891,
      "learning_rate": 3.937486766885454e-06,
      "loss": 0.6228,
      "step": 870600
    },
    {
      "epoch": 9.217032516236946,
      "grad_norm": 4.788778781890869,
      "learning_rate": 3.934840143976286e-06,
      "loss": 0.6192,
      "step": 870650
    },
    {
      "epoch": 9.217561838016948,
      "grad_norm": 4.458364486694336,
      "learning_rate": 3.932193521067119e-06,
      "loss": 0.6373,
      "step": 870700
    },
    {
      "epoch": 9.218091159796952,
      "grad_norm": 4.7776641845703125,
      "learning_rate": 3.92954689815795e-06,
      "loss": 0.6181,
      "step": 870750
    },
    {
      "epoch": 9.218620481576956,
      "grad_norm": 5.308682441711426,
      "learning_rate": 3.926900275248783e-06,
      "loss": 0.6265,
      "step": 870800
    },
    {
      "epoch": 9.21914980335696,
      "grad_norm": 4.686793327331543,
      "learning_rate": 3.924253652339615e-06,
      "loss": 0.62,
      "step": 870850
    },
    {
      "epoch": 9.219679125136961,
      "grad_norm": 5.1174421310424805,
      "learning_rate": 3.921607029430447e-06,
      "loss": 0.627,
      "step": 870900
    },
    {
      "epoch": 9.220208446916965,
      "grad_norm": 4.862180233001709,
      "learning_rate": 3.918960406521279e-06,
      "loss": 0.6231,
      "step": 870950
    },
    {
      "epoch": 9.220737768696969,
      "grad_norm": 4.244533061981201,
      "learning_rate": 3.9163137836121115e-06,
      "loss": 0.6312,
      "step": 871000
    },
    {
      "epoch": 9.220737768696969,
      "eval_loss": 0.3781481683254242,
      "eval_runtime": 46.5151,
      "eval_samples_per_second": 3610.223,
      "eval_steps_per_second": 451.294,
      "step": 871000
    },
    {
      "epoch": 9.221267090476973,
      "grad_norm": 4.628775119781494,
      "learning_rate": 3.913667160702943e-06,
      "loss": 0.6203,
      "step": 871050
    },
    {
      "epoch": 9.221796412256975,
      "grad_norm": 4.582837104797363,
      "learning_rate": 3.9110205377937755e-06,
      "loss": 0.6221,
      "step": 871100
    },
    {
      "epoch": 9.222325734036978,
      "grad_norm": 5.088212013244629,
      "learning_rate": 3.908373914884608e-06,
      "loss": 0.6165,
      "step": 871150
    },
    {
      "epoch": 9.222855055816982,
      "grad_norm": 4.6258392333984375,
      "learning_rate": 3.9057272919754395e-06,
      "loss": 0.6214,
      "step": 871200
    },
    {
      "epoch": 9.223384377596984,
      "grad_norm": 4.9309401512146,
      "learning_rate": 3.903080669066272e-06,
      "loss": 0.6195,
      "step": 871250
    },
    {
      "epoch": 9.223913699376988,
      "grad_norm": 4.7805986404418945,
      "learning_rate": 3.900434046157104e-06,
      "loss": 0.621,
      "step": 871300
    },
    {
      "epoch": 9.224443021156992,
      "grad_norm": 4.572787284851074,
      "learning_rate": 3.897787423247936e-06,
      "loss": 0.6204,
      "step": 871350
    },
    {
      "epoch": 9.224972342936995,
      "grad_norm": 4.303048133850098,
      "learning_rate": 3.895140800338768e-06,
      "loss": 0.6182,
      "step": 871400
    },
    {
      "epoch": 9.225501664716997,
      "grad_norm": 4.692523002624512,
      "learning_rate": 3.8924941774296e-06,
      "loss": 0.636,
      "step": 871450
    },
    {
      "epoch": 9.226030986497001,
      "grad_norm": 4.46854305267334,
      "learning_rate": 3.889847554520432e-06,
      "loss": 0.6257,
      "step": 871500
    },
    {
      "epoch": 9.226030986497001,
      "eval_loss": 0.37835466861724854,
      "eval_runtime": 46.4633,
      "eval_samples_per_second": 3614.247,
      "eval_steps_per_second": 451.797,
      "step": 871500
    },
    {
      "epoch": 9.226560308277005,
      "grad_norm": 4.395506858825684,
      "learning_rate": 3.887200931611265e-06,
      "loss": 0.6253,
      "step": 871550
    },
    {
      "epoch": 9.227089630057009,
      "grad_norm": 4.364841938018799,
      "learning_rate": 3.884554308702096e-06,
      "loss": 0.6265,
      "step": 871600
    },
    {
      "epoch": 9.22761895183701,
      "grad_norm": 4.766726493835449,
      "learning_rate": 3.881907685792929e-06,
      "loss": 0.6121,
      "step": 871650
    },
    {
      "epoch": 9.228148273617014,
      "grad_norm": 5.109332084655762,
      "learning_rate": 3.879261062883761e-06,
      "loss": 0.628,
      "step": 871700
    },
    {
      "epoch": 9.228677595397018,
      "grad_norm": 4.494990825653076,
      "learning_rate": 3.8766144399745926e-06,
      "loss": 0.6163,
      "step": 871750
    },
    {
      "epoch": 9.229206917177022,
      "grad_norm": 4.221708297729492,
      "learning_rate": 3.873967817065425e-06,
      "loss": 0.625,
      "step": 871800
    },
    {
      "epoch": 9.229736238957024,
      "grad_norm": 4.323131084442139,
      "learning_rate": 3.871321194156257e-06,
      "loss": 0.6185,
      "step": 871850
    },
    {
      "epoch": 9.230265560737028,
      "grad_norm": 4.760958671569824,
      "learning_rate": 3.868674571247089e-06,
      "loss": 0.6248,
      "step": 871900
    },
    {
      "epoch": 9.230794882517031,
      "grad_norm": 4.936727523803711,
      "learning_rate": 3.866027948337921e-06,
      "loss": 0.6312,
      "step": 871950
    },
    {
      "epoch": 9.231324204297033,
      "grad_norm": 4.282960414886475,
      "learning_rate": 3.863381325428754e-06,
      "loss": 0.6156,
      "step": 872000
    },
    {
      "epoch": 9.231324204297033,
      "eval_loss": 0.37846839427948,
      "eval_runtime": 46.5383,
      "eval_samples_per_second": 3608.429,
      "eval_steps_per_second": 451.07,
      "step": 872000
    },
    {
      "epoch": 9.231853526077037,
      "grad_norm": 4.412237167358398,
      "learning_rate": 3.860734702519585e-06,
      "loss": 0.6289,
      "step": 872050
    },
    {
      "epoch": 9.23238284785704,
      "grad_norm": 4.711201190948486,
      "learning_rate": 3.858088079610418e-06,
      "loss": 0.6212,
      "step": 872100
    },
    {
      "epoch": 9.232912169637045,
      "grad_norm": 4.314835548400879,
      "learning_rate": 3.855441456701249e-06,
      "loss": 0.6162,
      "step": 872150
    },
    {
      "epoch": 9.233441491417047,
      "grad_norm": 4.578835487365723,
      "learning_rate": 3.852794833792082e-06,
      "loss": 0.6234,
      "step": 872200
    },
    {
      "epoch": 9.23397081319705,
      "grad_norm": 4.421177864074707,
      "learning_rate": 3.850148210882914e-06,
      "loss": 0.6282,
      "step": 872250
    },
    {
      "epoch": 9.234500134977054,
      "grad_norm": 4.325532913208008,
      "learning_rate": 3.847501587973746e-06,
      "loss": 0.628,
      "step": 872300
    },
    {
      "epoch": 9.235029456757058,
      "grad_norm": 4.687599182128906,
      "learning_rate": 3.844854965064578e-06,
      "loss": 0.6069,
      "step": 872350
    },
    {
      "epoch": 9.23555877853706,
      "grad_norm": 4.729984283447266,
      "learning_rate": 3.8422083421554104e-06,
      "loss": 0.6345,
      "step": 872400
    },
    {
      "epoch": 9.236088100317064,
      "grad_norm": 4.642753601074219,
      "learning_rate": 3.839561719246242e-06,
      "loss": 0.6309,
      "step": 872450
    },
    {
      "epoch": 9.236617422097067,
      "grad_norm": 5.106466770172119,
      "learning_rate": 3.836915096337074e-06,
      "loss": 0.6179,
      "step": 872500
    },
    {
      "epoch": 9.236617422097067,
      "eval_loss": 0.3787761330604553,
      "eval_runtime": 46.4457,
      "eval_samples_per_second": 3615.619,
      "eval_steps_per_second": 451.969,
      "step": 872500
    },
    {
      "epoch": 9.237146743877071,
      "grad_norm": 4.441830635070801,
      "learning_rate": 3.834268473427907e-06,
      "loss": 0.6257,
      "step": 872550
    },
    {
      "epoch": 9.237676065657073,
      "grad_norm": 4.764875888824463,
      "learning_rate": 3.831621850518738e-06,
      "loss": 0.623,
      "step": 872600
    },
    {
      "epoch": 9.238205387437077,
      "grad_norm": 4.845033645629883,
      "learning_rate": 3.828975227609571e-06,
      "loss": 0.6122,
      "step": 872650
    },
    {
      "epoch": 9.23873470921708,
      "grad_norm": 4.808496475219727,
      "learning_rate": 3.826328604700403e-06,
      "loss": 0.6415,
      "step": 872700
    },
    {
      "epoch": 9.239264030997083,
      "grad_norm": 5.200493335723877,
      "learning_rate": 3.823681981791235e-06,
      "loss": 0.621,
      "step": 872750
    },
    {
      "epoch": 9.239793352777086,
      "grad_norm": 4.5141777992248535,
      "learning_rate": 3.821035358882067e-06,
      "loss": 0.63,
      "step": 872800
    },
    {
      "epoch": 9.24032267455709,
      "grad_norm": 4.124625205993652,
      "learning_rate": 3.818388735972899e-06,
      "loss": 0.6317,
      "step": 872850
    },
    {
      "epoch": 9.240851996337094,
      "grad_norm": 4.756552219390869,
      "learning_rate": 3.81574211306373e-06,
      "loss": 0.6305,
      "step": 872900
    },
    {
      "epoch": 9.241381318117096,
      "grad_norm": 4.284150123596191,
      "learning_rate": 3.8130954901545627e-06,
      "loss": 0.6127,
      "step": 872950
    },
    {
      "epoch": 9.2419106398971,
      "grad_norm": 4.60466194152832,
      "learning_rate": 3.8104488672453947e-06,
      "loss": 0.633,
      "step": 873000
    },
    {
      "epoch": 9.2419106398971,
      "eval_loss": 0.3787931501865387,
      "eval_runtime": 46.4998,
      "eval_samples_per_second": 3611.41,
      "eval_steps_per_second": 451.442,
      "step": 873000
    },
    {
      "epoch": 9.242439961677103,
      "grad_norm": 4.216845512390137,
      "learning_rate": 3.8078551767944106e-06,
      "loss": 0.6169,
      "step": 873050
    },
    {
      "epoch": 9.242969283457107,
      "grad_norm": 4.163155555725098,
      "learning_rate": 3.805208553885243e-06,
      "loss": 0.6172,
      "step": 873100
    },
    {
      "epoch": 9.243498605237109,
      "grad_norm": 4.766416072845459,
      "learning_rate": 3.802561930976075e-06,
      "loss": 0.6184,
      "step": 873150
    },
    {
      "epoch": 9.244027927017113,
      "grad_norm": 5.289614200592041,
      "learning_rate": 3.799915308066907e-06,
      "loss": 0.6224,
      "step": 873200
    },
    {
      "epoch": 9.244557248797117,
      "grad_norm": 4.618564605712891,
      "learning_rate": 3.7972686851577394e-06,
      "loss": 0.6092,
      "step": 873250
    },
    {
      "epoch": 9.24508657057712,
      "grad_norm": 4.707377910614014,
      "learning_rate": 3.7946220622485714e-06,
      "loss": 0.6329,
      "step": 873300
    },
    {
      "epoch": 9.245615892357122,
      "grad_norm": 4.840732574462891,
      "learning_rate": 3.7919754393394034e-06,
      "loss": 0.6214,
      "step": 873350
    },
    {
      "epoch": 9.246145214137126,
      "grad_norm": 4.474935054779053,
      "learning_rate": 3.7893288164302354e-06,
      "loss": 0.615,
      "step": 873400
    },
    {
      "epoch": 9.24667453591713,
      "grad_norm": 4.879150867462158,
      "learning_rate": 3.786682193521067e-06,
      "loss": 0.6273,
      "step": 873450
    },
    {
      "epoch": 9.247203857697132,
      "grad_norm": 4.2123613357543945,
      "learning_rate": 3.784035570611899e-06,
      "loss": 0.6279,
      "step": 873500
    },
    {
      "epoch": 9.247203857697132,
      "eval_loss": 0.3786475956439972,
      "eval_runtime": 46.5235,
      "eval_samples_per_second": 3609.571,
      "eval_steps_per_second": 451.213,
      "step": 873500
    },
    {
      "epoch": 9.247733179477136,
      "grad_norm": 4.559500217437744,
      "learning_rate": 3.7813889477027313e-06,
      "loss": 0.6313,
      "step": 873550
    },
    {
      "epoch": 9.24826250125714,
      "grad_norm": 4.709444046020508,
      "learning_rate": 3.7787423247935633e-06,
      "loss": 0.6269,
      "step": 873600
    },
    {
      "epoch": 9.248791823037143,
      "grad_norm": 4.707884788513184,
      "learning_rate": 3.7760957018843953e-06,
      "loss": 0.623,
      "step": 873650
    },
    {
      "epoch": 9.249321144817145,
      "grad_norm": 4.8248372077941895,
      "learning_rate": 3.7734490789752277e-06,
      "loss": 0.6244,
      "step": 873700
    },
    {
      "epoch": 9.249850466597149,
      "grad_norm": 4.723755359649658,
      "learning_rate": 3.7708024560660597e-06,
      "loss": 0.626,
      "step": 873750
    },
    {
      "epoch": 9.250379788377153,
      "grad_norm": 4.766228675842285,
      "learning_rate": 3.7681558331568916e-06,
      "loss": 0.624,
      "step": 873800
    },
    {
      "epoch": 9.250909110157156,
      "grad_norm": 5.0223188400268555,
      "learning_rate": 3.7655092102477236e-06,
      "loss": 0.6266,
      "step": 873850
    },
    {
      "epoch": 9.251438431937158,
      "grad_norm": 5.095324516296387,
      "learning_rate": 3.762862587338556e-06,
      "loss": 0.6246,
      "step": 873900
    },
    {
      "epoch": 9.251967753717162,
      "grad_norm": 4.721468925476074,
      "learning_rate": 3.760215964429388e-06,
      "loss": 0.6146,
      "step": 873950
    },
    {
      "epoch": 9.252497075497166,
      "grad_norm": 4.633162498474121,
      "learning_rate": 3.75756934152022e-06,
      "loss": 0.6285,
      "step": 874000
    },
    {
      "epoch": 9.252497075497166,
      "eval_loss": 0.37867632508277893,
      "eval_runtime": 46.4895,
      "eval_samples_per_second": 3612.214,
      "eval_steps_per_second": 451.543,
      "step": 874000
    },
    {
      "epoch": 9.25302639727717,
      "grad_norm": 4.972940921783447,
      "learning_rate": 3.7549227186110524e-06,
      "loss": 0.628,
      "step": 874050
    },
    {
      "epoch": 9.253555719057172,
      "grad_norm": 4.716020107269287,
      "learning_rate": 3.7522760957018844e-06,
      "loss": 0.6183,
      "step": 874100
    },
    {
      "epoch": 9.254085040837175,
      "grad_norm": 4.607817649841309,
      "learning_rate": 3.7496294727927164e-06,
      "loss": 0.6239,
      "step": 874150
    },
    {
      "epoch": 9.254614362617179,
      "grad_norm": 4.866867542266846,
      "learning_rate": 3.7469828498835483e-06,
      "loss": 0.6249,
      "step": 874200
    },
    {
      "epoch": 9.255143684397181,
      "grad_norm": 4.884178638458252,
      "learning_rate": 3.7443362269743807e-06,
      "loss": 0.6202,
      "step": 874250
    },
    {
      "epoch": 9.255673006177185,
      "grad_norm": 4.485440254211426,
      "learning_rate": 3.7416896040652127e-06,
      "loss": 0.6174,
      "step": 874300
    },
    {
      "epoch": 9.256202327957189,
      "grad_norm": 4.538954734802246,
      "learning_rate": 3.7390429811560447e-06,
      "loss": 0.6157,
      "step": 874350
    },
    {
      "epoch": 9.256731649737192,
      "grad_norm": 4.762535095214844,
      "learning_rate": 3.736396358246877e-06,
      "loss": 0.6177,
      "step": 874400
    },
    {
      "epoch": 9.257260971517194,
      "grad_norm": 4.04307746887207,
      "learning_rate": 3.733749735337709e-06,
      "loss": 0.621,
      "step": 874450
    },
    {
      "epoch": 9.257790293297198,
      "grad_norm": 4.771644592285156,
      "learning_rate": 3.731103112428541e-06,
      "loss": 0.6247,
      "step": 874500
    },
    {
      "epoch": 9.257790293297198,
      "eval_loss": 0.3780735433101654,
      "eval_runtime": 46.483,
      "eval_samples_per_second": 3612.715,
      "eval_steps_per_second": 451.606,
      "step": 874500
    },
    {
      "epoch": 9.258319615077202,
      "grad_norm": 4.217266082763672,
      "learning_rate": 3.728456489519373e-06,
      "loss": 0.6259,
      "step": 874550
    },
    {
      "epoch": 9.258848936857206,
      "grad_norm": 4.570516109466553,
      "learning_rate": 3.7258098666102055e-06,
      "loss": 0.6324,
      "step": 874600
    },
    {
      "epoch": 9.259378258637208,
      "grad_norm": 4.727407455444336,
      "learning_rate": 3.7231632437010375e-06,
      "loss": 0.6174,
      "step": 874650
    },
    {
      "epoch": 9.259907580417211,
      "grad_norm": 5.017700672149658,
      "learning_rate": 3.7205166207918694e-06,
      "loss": 0.6146,
      "step": 874700
    },
    {
      "epoch": 9.260436902197215,
      "grad_norm": 4.374181270599365,
      "learning_rate": 3.717869997882702e-06,
      "loss": 0.6291,
      "step": 874750
    },
    {
      "epoch": 9.260966223977219,
      "grad_norm": 4.640005111694336,
      "learning_rate": 3.715223374973534e-06,
      "loss": 0.6277,
      "step": 874800
    },
    {
      "epoch": 9.26149554575722,
      "grad_norm": 4.656359672546387,
      "learning_rate": 3.712576752064366e-06,
      "loss": 0.6215,
      "step": 874850
    },
    {
      "epoch": 9.262024867537225,
      "grad_norm": 4.565366268157959,
      "learning_rate": 3.709930129155198e-06,
      "loss": 0.6185,
      "step": 874900
    },
    {
      "epoch": 9.262554189317228,
      "grad_norm": 4.479018211364746,
      "learning_rate": 3.70728350624603e-06,
      "loss": 0.6277,
      "step": 874950
    },
    {
      "epoch": 9.26308351109723,
      "grad_norm": 4.438231945037842,
      "learning_rate": 3.704636883336862e-06,
      "loss": 0.6247,
      "step": 875000
    },
    {
      "epoch": 9.26308351109723,
      "eval_loss": 0.37801238894462585,
      "eval_runtime": 46.5194,
      "eval_samples_per_second": 3609.89,
      "eval_steps_per_second": 451.252,
      "step": 875000
    },
    {
      "epoch": 9.263612832877234,
      "grad_norm": Infinity,
      "learning_rate": 3.7020431928858777e-06,
      "loss": 0.617,
      "step": 875050
    },
    {
      "epoch": 9.264142154657238,
      "grad_norm": 4.440601825714111,
      "learning_rate": 3.6993965699767097e-06,
      "loss": 0.6198,
      "step": 875100
    },
    {
      "epoch": 9.264671476437242,
      "grad_norm": 4.235823631286621,
      "learning_rate": 3.6967499470675417e-06,
      "loss": 0.626,
      "step": 875150
    },
    {
      "epoch": 9.265200798217244,
      "grad_norm": 4.427652835845947,
      "learning_rate": 3.694103324158374e-06,
      "loss": 0.6189,
      "step": 875200
    },
    {
      "epoch": 9.265730119997247,
      "grad_norm": 4.992314338684082,
      "learning_rate": 3.691456701249206e-06,
      "loss": 0.6242,
      "step": 875250
    },
    {
      "epoch": 9.266259441777251,
      "grad_norm": 5.294645309448242,
      "learning_rate": 3.688810078340038e-06,
      "loss": 0.6194,
      "step": 875300
    },
    {
      "epoch": 9.266788763557255,
      "grad_norm": 4.683839797973633,
      "learning_rate": 3.68616345543087e-06,
      "loss": 0.634,
      "step": 875350
    },
    {
      "epoch": 9.267318085337257,
      "grad_norm": 4.701834201812744,
      "learning_rate": 3.6835168325217025e-06,
      "loss": 0.6313,
      "step": 875400
    },
    {
      "epoch": 9.26784740711726,
      "grad_norm": 4.7606940269470215,
      "learning_rate": 3.6808702096125344e-06,
      "loss": 0.6161,
      "step": 875450
    },
    {
      "epoch": 9.268376728897264,
      "grad_norm": 4.899702548980713,
      "learning_rate": 3.6782235867033664e-06,
      "loss": 0.6303,
      "step": 875500
    },
    {
      "epoch": 9.268376728897264,
      "eval_loss": 0.3787045180797577,
      "eval_runtime": 46.5378,
      "eval_samples_per_second": 3608.461,
      "eval_steps_per_second": 451.074,
      "step": 875500
    },
    {
      "epoch": 9.268906050677268,
      "grad_norm": 4.3082756996154785,
      "learning_rate": 3.675576963794199e-06,
      "loss": 0.6232,
      "step": 875550
    },
    {
      "epoch": 9.26943537245727,
      "grad_norm": 4.3040971755981445,
      "learning_rate": 3.672930340885031e-06,
      "loss": 0.6255,
      "step": 875600
    },
    {
      "epoch": 9.269964694237274,
      "grad_norm": 4.538209438323975,
      "learning_rate": 3.670283717975863e-06,
      "loss": 0.6248,
      "step": 875650
    },
    {
      "epoch": 9.270494016017278,
      "grad_norm": 4.651318550109863,
      "learning_rate": 3.6676370950666948e-06,
      "loss": 0.6274,
      "step": 875700
    },
    {
      "epoch": 9.27102333779728,
      "grad_norm": 4.498311519622803,
      "learning_rate": 3.664990472157527e-06,
      "loss": 0.629,
      "step": 875750
    },
    {
      "epoch": 9.271552659577283,
      "grad_norm": 4.097602844238281,
      "learning_rate": 3.662343849248359e-06,
      "loss": 0.6184,
      "step": 875800
    },
    {
      "epoch": 9.272081981357287,
      "grad_norm": 4.510237693786621,
      "learning_rate": 3.659697226339191e-06,
      "loss": 0.6069,
      "step": 875850
    },
    {
      "epoch": 9.27261130313729,
      "grad_norm": 4.395780563354492,
      "learning_rate": 3.6570506034300236e-06,
      "loss": 0.6254,
      "step": 875900
    },
    {
      "epoch": 9.273140624917293,
      "grad_norm": 4.439701080322266,
      "learning_rate": 3.6544039805208555e-06,
      "loss": 0.6245,
      "step": 875950
    },
    {
      "epoch": 9.273669946697296,
      "grad_norm": 4.842207908630371,
      "learning_rate": 3.6517573576116875e-06,
      "loss": 0.6242,
      "step": 876000
    },
    {
      "epoch": 9.273669946697296,
      "eval_loss": 0.3780430257320404,
      "eval_runtime": 46.5191,
      "eval_samples_per_second": 3609.913,
      "eval_steps_per_second": 451.255,
      "step": 876000
    },
    {
      "epoch": 9.2741992684773,
      "grad_norm": 4.705868244171143,
      "learning_rate": 3.6491107347025195e-06,
      "loss": 0.6273,
      "step": 876050
    },
    {
      "epoch": 9.274728590257304,
      "grad_norm": 4.686882972717285,
      "learning_rate": 3.646464111793352e-06,
      "loss": 0.6258,
      "step": 876100
    },
    {
      "epoch": 9.275257912037306,
      "grad_norm": 4.362184524536133,
      "learning_rate": 3.643817488884184e-06,
      "loss": 0.6181,
      "step": 876150
    },
    {
      "epoch": 9.27578723381731,
      "grad_norm": 4.715292930603027,
      "learning_rate": 3.641170865975016e-06,
      "loss": 0.6182,
      "step": 876200
    },
    {
      "epoch": 9.276316555597313,
      "grad_norm": 4.905835151672363,
      "learning_rate": 3.6385771755240314e-06,
      "loss": 0.6198,
      "step": 876250
    },
    {
      "epoch": 9.276845877377317,
      "grad_norm": 4.415853023529053,
      "learning_rate": 3.6359305526148634e-06,
      "loss": 0.6133,
      "step": 876300
    },
    {
      "epoch": 9.27737519915732,
      "grad_norm": 4.780311107635498,
      "learning_rate": 3.6332839297056954e-06,
      "loss": 0.6274,
      "step": 876350
    },
    {
      "epoch": 9.277904520937323,
      "grad_norm": 4.598390102386475,
      "learning_rate": 3.630637306796528e-06,
      "loss": 0.6227,
      "step": 876400
    },
    {
      "epoch": 9.278433842717327,
      "grad_norm": 4.019053936004639,
      "learning_rate": 3.6279906838873598e-06,
      "loss": 0.6148,
      "step": 876450
    },
    {
      "epoch": 9.278963164497329,
      "grad_norm": 4.644403457641602,
      "learning_rate": 3.6253440609781918e-06,
      "loss": 0.6189,
      "step": 876500
    },
    {
      "epoch": 9.278963164497329,
      "eval_loss": 0.37811824679374695,
      "eval_runtime": 46.5911,
      "eval_samples_per_second": 3604.338,
      "eval_steps_per_second": 450.558,
      "step": 876500
    },
    {
      "epoch": 9.279492486277332,
      "grad_norm": 4.749475002288818,
      "learning_rate": 3.622697438069024e-06,
      "loss": 0.6106,
      "step": 876550
    },
    {
      "epoch": 9.280021808057336,
      "grad_norm": 4.615445137023926,
      "learning_rate": 3.620050815159856e-06,
      "loss": 0.6219,
      "step": 876600
    },
    {
      "epoch": 9.28055112983734,
      "grad_norm": 5.203391075134277,
      "learning_rate": 3.617404192250688e-06,
      "loss": 0.6245,
      "step": 876650
    },
    {
      "epoch": 9.281080451617342,
      "grad_norm": 4.4273176193237305,
      "learning_rate": 3.6147575693415205e-06,
      "loss": 0.6244,
      "step": 876700
    },
    {
      "epoch": 9.281609773397346,
      "grad_norm": 4.604747772216797,
      "learning_rate": 3.6121109464323525e-06,
      "loss": 0.6133,
      "step": 876750
    },
    {
      "epoch": 9.28213909517735,
      "grad_norm": 4.530107021331787,
      "learning_rate": 3.6094643235231845e-06,
      "loss": 0.6258,
      "step": 876800
    },
    {
      "epoch": 9.282668416957353,
      "grad_norm": 4.685254096984863,
      "learning_rate": 3.6068177006140165e-06,
      "loss": 0.6355,
      "step": 876850
    },
    {
      "epoch": 9.283197738737355,
      "grad_norm": 4.4635725021362305,
      "learning_rate": 3.604171077704849e-06,
      "loss": 0.6328,
      "step": 876900
    },
    {
      "epoch": 9.283727060517359,
      "grad_norm": 4.315442085266113,
      "learning_rate": 3.601524454795681e-06,
      "loss": 0.622,
      "step": 876950
    },
    {
      "epoch": 9.284256382297363,
      "grad_norm": 4.928982734680176,
      "learning_rate": 3.598877831886513e-06,
      "loss": 0.6247,
      "step": 877000
    },
    {
      "epoch": 9.284256382297363,
      "eval_loss": 0.3783222734928131,
      "eval_runtime": 46.484,
      "eval_samples_per_second": 3612.645,
      "eval_steps_per_second": 451.597,
      "step": 877000
    },
    {
      "epoch": 9.284785704077366,
      "grad_norm": 4.697481155395508,
      "learning_rate": 3.5962312089773453e-06,
      "loss": 0.6196,
      "step": 877050
    },
    {
      "epoch": 9.285315025857368,
      "grad_norm": 4.621762275695801,
      "learning_rate": 3.5935845860681772e-06,
      "loss": 0.6231,
      "step": 877100
    },
    {
      "epoch": 9.285844347637372,
      "grad_norm": 4.751129627227783,
      "learning_rate": 3.5909379631590092e-06,
      "loss": 0.6247,
      "step": 877150
    },
    {
      "epoch": 9.286373669417376,
      "grad_norm": 4.499925136566162,
      "learning_rate": 3.588291340249841e-06,
      "loss": 0.6199,
      "step": 877200
    },
    {
      "epoch": 9.286902991197378,
      "grad_norm": 4.565752983093262,
      "learning_rate": 3.5856447173406736e-06,
      "loss": 0.6208,
      "step": 877250
    },
    {
      "epoch": 9.287432312977382,
      "grad_norm": 4.732980728149414,
      "learning_rate": 3.5829980944315056e-06,
      "loss": 0.6166,
      "step": 877300
    },
    {
      "epoch": 9.287961634757385,
      "grad_norm": 4.251925945281982,
      "learning_rate": 3.5803514715223376e-06,
      "loss": 0.618,
      "step": 877350
    },
    {
      "epoch": 9.28849095653739,
      "grad_norm": 4.6532206535339355,
      "learning_rate": 3.57770484861317e-06,
      "loss": 0.622,
      "step": 877400
    },
    {
      "epoch": 9.289020278317391,
      "grad_norm": 4.9816460609436035,
      "learning_rate": 3.575058225704002e-06,
      "loss": 0.6212,
      "step": 877450
    },
    {
      "epoch": 9.289549600097395,
      "grad_norm": 4.72515344619751,
      "learning_rate": 3.572411602794834e-06,
      "loss": 0.6185,
      "step": 877500
    },
    {
      "epoch": 9.289549600097395,
      "eval_loss": 0.37766918540000916,
      "eval_runtime": 46.4252,
      "eval_samples_per_second": 3617.22,
      "eval_steps_per_second": 452.169,
      "step": 877500
    },
    {
      "epoch": 9.290078921877399,
      "grad_norm": 4.581767559051514,
      "learning_rate": 3.569764979885666e-06,
      "loss": 0.6221,
      "step": 877550
    },
    {
      "epoch": 9.290608243657402,
      "grad_norm": 4.640103816986084,
      "learning_rate": 3.5671183569764983e-06,
      "loss": 0.6277,
      "step": 877600
    },
    {
      "epoch": 9.291137565437404,
      "grad_norm": 4.731707572937012,
      "learning_rate": 3.5644717340673303e-06,
      "loss": 0.6285,
      "step": 877650
    },
    {
      "epoch": 9.291666887217408,
      "grad_norm": 4.88637113571167,
      "learning_rate": 3.5618251111581623e-06,
      "loss": 0.6306,
      "step": 877700
    },
    {
      "epoch": 9.292196208997412,
      "grad_norm": 4.587239742279053,
      "learning_rate": 3.5591784882489947e-06,
      "loss": 0.6222,
      "step": 877750
    },
    {
      "epoch": 9.292725530777416,
      "grad_norm": 4.575951099395752,
      "learning_rate": 3.5565318653398267e-06,
      "loss": 0.6273,
      "step": 877800
    },
    {
      "epoch": 9.293254852557418,
      "grad_norm": 4.6027960777282715,
      "learning_rate": 3.5538852424306587e-06,
      "loss": 0.6138,
      "step": 877850
    },
    {
      "epoch": 9.293784174337421,
      "grad_norm": 4.36326789855957,
      "learning_rate": 3.5512386195214907e-06,
      "loss": 0.6165,
      "step": 877900
    },
    {
      "epoch": 9.294313496117425,
      "grad_norm": 4.429065704345703,
      "learning_rate": 3.548591996612323e-06,
      "loss": 0.6284,
      "step": 877950
    },
    {
      "epoch": 9.294842817897427,
      "grad_norm": 4.42160701751709,
      "learning_rate": 3.545945373703155e-06,
      "loss": 0.6152,
      "step": 878000
    },
    {
      "epoch": 9.294842817897427,
      "eval_loss": 0.3778187334537506,
      "eval_runtime": 46.4696,
      "eval_samples_per_second": 3613.758,
      "eval_steps_per_second": 451.736,
      "step": 878000
    },
    {
      "epoch": 9.295372139677431,
      "grad_norm": 4.563974380493164,
      "learning_rate": 3.543298750793987e-06,
      "loss": 0.6308,
      "step": 878050
    },
    {
      "epoch": 9.295901461457435,
      "grad_norm": 4.769423484802246,
      "learning_rate": 3.5406521278848194e-06,
      "loss": 0.615,
      "step": 878100
    },
    {
      "epoch": 9.296430783237438,
      "grad_norm": 4.818160057067871,
      "learning_rate": 3.5380055049756514e-06,
      "loss": 0.6145,
      "step": 878150
    },
    {
      "epoch": 9.29696010501744,
      "grad_norm": 4.540404319763184,
      "learning_rate": 3.5353588820664834e-06,
      "loss": 0.624,
      "step": 878200
    },
    {
      "epoch": 9.297489426797444,
      "grad_norm": 4.946621894836426,
      "learning_rate": 3.5327122591573154e-06,
      "loss": 0.6298,
      "step": 878250
    },
    {
      "epoch": 9.298018748577448,
      "grad_norm": 3.9981625080108643,
      "learning_rate": 3.5300656362481478e-06,
      "loss": 0.6132,
      "step": 878300
    },
    {
      "epoch": 9.298548070357452,
      "grad_norm": 4.690768718719482,
      "learning_rate": 3.5274190133389798e-06,
      "loss": 0.6247,
      "step": 878350
    },
    {
      "epoch": 9.299077392137454,
      "grad_norm": 4.477712154388428,
      "learning_rate": 3.5247723904298117e-06,
      "loss": 0.6236,
      "step": 878400
    },
    {
      "epoch": 9.299606713917457,
      "grad_norm": 4.516566276550293,
      "learning_rate": 3.522125767520644e-06,
      "loss": 0.6157,
      "step": 878450
    },
    {
      "epoch": 9.300136035697461,
      "grad_norm": 4.833972930908203,
      "learning_rate": 3.519479144611476e-06,
      "loss": 0.6238,
      "step": 878500
    },
    {
      "epoch": 9.300136035697461,
      "eval_loss": 0.3778407573699951,
      "eval_runtime": 46.4553,
      "eval_samples_per_second": 3614.876,
      "eval_steps_per_second": 451.876,
      "step": 878500
    },
    {
      "epoch": 9.300665357477465,
      "grad_norm": 4.6785149574279785,
      "learning_rate": 3.516832521702308e-06,
      "loss": 0.6245,
      "step": 878550
    },
    {
      "epoch": 9.301194679257467,
      "grad_norm": 4.439977645874023,
      "learning_rate": 3.51418589879314e-06,
      "loss": 0.6295,
      "step": 878600
    },
    {
      "epoch": 9.30172400103747,
      "grad_norm": 4.596184253692627,
      "learning_rate": 3.5115392758839725e-06,
      "loss": 0.6286,
      "step": 878650
    },
    {
      "epoch": 9.302253322817474,
      "grad_norm": 4.393723964691162,
      "learning_rate": 3.5088926529748045e-06,
      "loss": 0.6106,
      "step": 878700
    },
    {
      "epoch": 9.302782644597478,
      "grad_norm": 4.443780422210693,
      "learning_rate": 3.5062460300656365e-06,
      "loss": 0.6247,
      "step": 878750
    },
    {
      "epoch": 9.30331196637748,
      "grad_norm": 4.1024088859558105,
      "learning_rate": 3.503599407156469e-06,
      "loss": 0.6198,
      "step": 878800
    },
    {
      "epoch": 9.303841288157484,
      "grad_norm": 4.616848945617676,
      "learning_rate": 3.500952784247301e-06,
      "loss": 0.6168,
      "step": 878850
    },
    {
      "epoch": 9.304370609937488,
      "grad_norm": 4.902257919311523,
      "learning_rate": 3.498306161338133e-06,
      "loss": 0.6276,
      "step": 878900
    },
    {
      "epoch": 9.30489993171749,
      "grad_norm": 4.2990336418151855,
      "learning_rate": 3.4956595384289652e-06,
      "loss": 0.6226,
      "step": 878950
    },
    {
      "epoch": 9.305429253497493,
      "grad_norm": 4.523316383361816,
      "learning_rate": 3.4930129155197972e-06,
      "loss": 0.6263,
      "step": 879000
    },
    {
      "epoch": 9.305429253497493,
      "eval_loss": 0.3774212896823883,
      "eval_runtime": 46.5105,
      "eval_samples_per_second": 3610.583,
      "eval_steps_per_second": 451.339,
      "step": 879000
    },
    {
      "epoch": 9.305958575277497,
      "grad_norm": 4.718347549438477,
      "learning_rate": 3.490366292610629e-06,
      "loss": 0.6272,
      "step": 879050
    },
    {
      "epoch": 9.306487897057501,
      "grad_norm": 4.782975196838379,
      "learning_rate": 3.487719669701461e-06,
      "loss": 0.6239,
      "step": 879100
    },
    {
      "epoch": 9.307017218837503,
      "grad_norm": 4.889039993286133,
      "learning_rate": 3.4850730467922936e-06,
      "loss": 0.6247,
      "step": 879150
    },
    {
      "epoch": 9.307546540617507,
      "grad_norm": 5.266021251678467,
      "learning_rate": 3.4824264238831256e-06,
      "loss": 0.6253,
      "step": 879200
    },
    {
      "epoch": 9.30807586239751,
      "grad_norm": 4.673577785491943,
      "learning_rate": 3.4797798009739576e-06,
      "loss": 0.6254,
      "step": 879250
    },
    {
      "epoch": 9.308605184177514,
      "grad_norm": 5.208747386932373,
      "learning_rate": 3.47713317806479e-06,
      "loss": 0.6393,
      "step": 879300
    },
    {
      "epoch": 9.309134505957516,
      "grad_norm": 4.237302780151367,
      "learning_rate": 3.474486555155622e-06,
      "loss": 0.6273,
      "step": 879350
    },
    {
      "epoch": 9.30966382773752,
      "grad_norm": 4.598825454711914,
      "learning_rate": 3.471839932246454e-06,
      "loss": 0.6078,
      "step": 879400
    },
    {
      "epoch": 9.310193149517524,
      "grad_norm": 4.926474571228027,
      "learning_rate": 3.469193309337286e-06,
      "loss": 0.6264,
      "step": 879450
    },
    {
      "epoch": 9.310722471297527,
      "grad_norm": 5.270336627960205,
      "learning_rate": 3.4665466864281183e-06,
      "loss": 0.6233,
      "step": 879500
    },
    {
      "epoch": 9.310722471297527,
      "eval_loss": 0.3777949810028076,
      "eval_runtime": 46.4829,
      "eval_samples_per_second": 3612.725,
      "eval_steps_per_second": 451.607,
      "step": 879500
    },
    {
      "epoch": 9.31125179307753,
      "grad_norm": 4.525565147399902,
      "learning_rate": 3.4639000635189503e-06,
      "loss": 0.617,
      "step": 879550
    },
    {
      "epoch": 9.311781114857533,
      "grad_norm": 4.790771007537842,
      "learning_rate": 3.4612534406097823e-06,
      "loss": 0.6264,
      "step": 879600
    },
    {
      "epoch": 9.312310436637537,
      "grad_norm": 4.682920455932617,
      "learning_rate": 3.4586068177006147e-06,
      "loss": 0.6261,
      "step": 879650
    },
    {
      "epoch": 9.312839758417539,
      "grad_norm": 4.657175064086914,
      "learning_rate": 3.4559601947914467e-06,
      "loss": 0.6105,
      "step": 879700
    },
    {
      "epoch": 9.313369080197543,
      "grad_norm": 4.716131210327148,
      "learning_rate": 3.4533135718822787e-06,
      "loss": 0.6319,
      "step": 879750
    },
    {
      "epoch": 9.313898401977546,
      "grad_norm": 4.702990531921387,
      "learning_rate": 3.4506669489731102e-06,
      "loss": 0.6236,
      "step": 879800
    },
    {
      "epoch": 9.31442772375755,
      "grad_norm": 4.080443859100342,
      "learning_rate": 3.448020326063942e-06,
      "loss": 0.6196,
      "step": 879850
    },
    {
      "epoch": 9.314957045537552,
      "grad_norm": 4.441523551940918,
      "learning_rate": 3.445373703154774e-06,
      "loss": 0.6133,
      "step": 879900
    },
    {
      "epoch": 9.315486367317556,
      "grad_norm": 5.074727535247803,
      "learning_rate": 3.4427270802456066e-06,
      "loss": 0.619,
      "step": 879950
    },
    {
      "epoch": 9.31601568909756,
      "grad_norm": 4.433114051818848,
      "learning_rate": 3.4400804573364386e-06,
      "loss": 0.6152,
      "step": 880000
    },
    {
      "epoch": 9.31601568909756,
      "eval_loss": 0.37763410806655884,
      "eval_runtime": 46.6092,
      "eval_samples_per_second": 3602.937,
      "eval_steps_per_second": 450.383,
      "step": 880000
    },
    {
      "epoch": 9.316545010877563,
      "grad_norm": 4.877434730529785,
      "learning_rate": 3.4374338344272706e-06,
      "loss": 0.6175,
      "step": 880050
    },
    {
      "epoch": 9.317074332657565,
      "grad_norm": 4.554422378540039,
      "learning_rate": 3.434787211518103e-06,
      "loss": 0.6189,
      "step": 880100
    },
    {
      "epoch": 9.317603654437569,
      "grad_norm": 4.962705612182617,
      "learning_rate": 3.432140588608935e-06,
      "loss": 0.6178,
      "step": 880150
    },
    {
      "epoch": 9.318132976217573,
      "grad_norm": 4.439283847808838,
      "learning_rate": 3.429493965699767e-06,
      "loss": 0.6251,
      "step": 880200
    },
    {
      "epoch": 9.318662297997577,
      "grad_norm": 4.352593421936035,
      "learning_rate": 3.426900275248783e-06,
      "loss": 0.6209,
      "step": 880250
    },
    {
      "epoch": 9.319191619777579,
      "grad_norm": 4.526506423950195,
      "learning_rate": 3.4242536523396153e-06,
      "loss": 0.6246,
      "step": 880300
    },
    {
      "epoch": 9.319720941557582,
      "grad_norm": 4.492583751678467,
      "learning_rate": 3.4216070294304473e-06,
      "loss": 0.6288,
      "step": 880350
    },
    {
      "epoch": 9.320250263337586,
      "grad_norm": 4.439602851867676,
      "learning_rate": 3.4189604065212793e-06,
      "loss": 0.6155,
      "step": 880400
    },
    {
      "epoch": 9.320779585117588,
      "grad_norm": 4.881056308746338,
      "learning_rate": 3.416313783612111e-06,
      "loss": 0.6132,
      "step": 880450
    },
    {
      "epoch": 9.321308906897592,
      "grad_norm": 4.1238603591918945,
      "learning_rate": 3.413667160702943e-06,
      "loss": 0.6374,
      "step": 880500
    },
    {
      "epoch": 9.321308906897592,
      "eval_loss": 0.37779858708381653,
      "eval_runtime": 46.5831,
      "eval_samples_per_second": 3604.958,
      "eval_steps_per_second": 450.636,
      "step": 880500
    },
    {
      "epoch": 9.321838228677596,
      "grad_norm": 4.3222336769104,
      "learning_rate": 3.411020537793775e-06,
      "loss": 0.6257,
      "step": 880550
    },
    {
      "epoch": 9.3223675504576,
      "grad_norm": 4.8246612548828125,
      "learning_rate": 3.408373914884607e-06,
      "loss": 0.6202,
      "step": 880600
    },
    {
      "epoch": 9.322896872237601,
      "grad_norm": 4.471482276916504,
      "learning_rate": 3.405727291975439e-06,
      "loss": 0.6112,
      "step": 880650
    },
    {
      "epoch": 9.323426194017605,
      "grad_norm": 4.763808727264404,
      "learning_rate": 3.403080669066271e-06,
      "loss": 0.6145,
      "step": 880700
    },
    {
      "epoch": 9.323955515797609,
      "grad_norm": 4.840803623199463,
      "learning_rate": 3.4004340461571036e-06,
      "loss": 0.6334,
      "step": 880750
    },
    {
      "epoch": 9.324484837577613,
      "grad_norm": 4.356540679931641,
      "learning_rate": 3.3977874232479356e-06,
      "loss": 0.6217,
      "step": 880800
    },
    {
      "epoch": 9.325014159357615,
      "grad_norm": 4.563873291015625,
      "learning_rate": 3.3951408003387675e-06,
      "loss": 0.6165,
      "step": 880850
    },
    {
      "epoch": 9.325543481137618,
      "grad_norm": 4.585593223571777,
      "learning_rate": 3.3924941774295995e-06,
      "loss": 0.624,
      "step": 880900
    },
    {
      "epoch": 9.326072802917622,
      "grad_norm": 5.069591999053955,
      "learning_rate": 3.389847554520432e-06,
      "loss": 0.6304,
      "step": 880950
    },
    {
      "epoch": 9.326602124697626,
      "grad_norm": 4.7984819412231445,
      "learning_rate": 3.387200931611264e-06,
      "loss": 0.6231,
      "step": 881000
    },
    {
      "epoch": 9.326602124697626,
      "eval_loss": 0.3775371015071869,
      "eval_runtime": 46.4768,
      "eval_samples_per_second": 3613.201,
      "eval_steps_per_second": 451.666,
      "step": 881000
    },
    {
      "epoch": 9.327131446477628,
      "grad_norm": 4.687938213348389,
      "learning_rate": 3.384554308702096e-06,
      "loss": 0.6216,
      "step": 881050
    },
    {
      "epoch": 9.327660768257632,
      "grad_norm": 4.75531005859375,
      "learning_rate": 3.3819076857929283e-06,
      "loss": 0.6267,
      "step": 881100
    },
    {
      "epoch": 9.328190090037635,
      "grad_norm": 4.820199489593506,
      "learning_rate": 3.3792610628837603e-06,
      "loss": 0.6193,
      "step": 881150
    },
    {
      "epoch": 9.328719411817637,
      "grad_norm": 4.712620258331299,
      "learning_rate": 3.3766144399745923e-06,
      "loss": 0.6201,
      "step": 881200
    },
    {
      "epoch": 9.329248733597641,
      "grad_norm": 4.603017807006836,
      "learning_rate": 3.3739678170654242e-06,
      "loss": 0.6248,
      "step": 881250
    },
    {
      "epoch": 9.329778055377645,
      "grad_norm": 4.8826904296875,
      "learning_rate": 3.3713211941562566e-06,
      "loss": 0.6213,
      "step": 881300
    },
    {
      "epoch": 9.330307377157649,
      "grad_norm": 4.988090991973877,
      "learning_rate": 3.3686745712470886e-06,
      "loss": 0.6252,
      "step": 881350
    },
    {
      "epoch": 9.33083669893765,
      "grad_norm": 4.703266143798828,
      "learning_rate": 3.3660279483379206e-06,
      "loss": 0.6262,
      "step": 881400
    },
    {
      "epoch": 9.331366020717654,
      "grad_norm": 4.511835098266602,
      "learning_rate": 3.363381325428753e-06,
      "loss": 0.6149,
      "step": 881450
    },
    {
      "epoch": 9.331895342497658,
      "grad_norm": 4.744379043579102,
      "learning_rate": 3.360734702519585e-06,
      "loss": 0.6267,
      "step": 881500
    },
    {
      "epoch": 9.331895342497658,
      "eval_loss": 0.3780340552330017,
      "eval_runtime": 46.4674,
      "eval_samples_per_second": 3613.929,
      "eval_steps_per_second": 451.757,
      "step": 881500
    },
    {
      "epoch": 9.332424664277662,
      "grad_norm": 4.138061046600342,
      "learning_rate": 3.358088079610417e-06,
      "loss": 0.633,
      "step": 881550
    },
    {
      "epoch": 9.332953986057664,
      "grad_norm": 4.456874847412109,
      "learning_rate": 3.3554414567012494e-06,
      "loss": 0.6159,
      "step": 881600
    },
    {
      "epoch": 9.333483307837668,
      "grad_norm": 4.950987815856934,
      "learning_rate": 3.3527948337920814e-06,
      "loss": 0.6368,
      "step": 881650
    },
    {
      "epoch": 9.334012629617671,
      "grad_norm": 4.56303071975708,
      "learning_rate": 3.3501482108829134e-06,
      "loss": 0.6265,
      "step": 881700
    },
    {
      "epoch": 9.334541951397675,
      "grad_norm": 4.7331037521362305,
      "learning_rate": 3.3475015879737453e-06,
      "loss": 0.6169,
      "step": 881750
    },
    {
      "epoch": 9.335071273177677,
      "grad_norm": 4.6345953941345215,
      "learning_rate": 3.3448549650645777e-06,
      "loss": 0.6146,
      "step": 881800
    },
    {
      "epoch": 9.33560059495768,
      "grad_norm": 4.9145283699035645,
      "learning_rate": 3.3422083421554097e-06,
      "loss": 0.6236,
      "step": 881850
    },
    {
      "epoch": 9.336129916737685,
      "grad_norm": 4.718037128448486,
      "learning_rate": 3.3395617192462417e-06,
      "loss": 0.6074,
      "step": 881900
    },
    {
      "epoch": 9.336659238517687,
      "grad_norm": 4.865390777587891,
      "learning_rate": 3.336915096337074e-06,
      "loss": 0.6227,
      "step": 881950
    },
    {
      "epoch": 9.33718856029769,
      "grad_norm": 4.386183261871338,
      "learning_rate": 3.334268473427906e-06,
      "loss": 0.6218,
      "step": 882000
    },
    {
      "epoch": 9.33718856029769,
      "eval_loss": 0.37752246856689453,
      "eval_runtime": 46.5508,
      "eval_samples_per_second": 3607.459,
      "eval_steps_per_second": 450.949,
      "step": 882000
    },
    {
      "epoch": 9.337717882077694,
      "grad_norm": 4.547651767730713,
      "learning_rate": 3.331621850518738e-06,
      "loss": 0.613,
      "step": 882050
    },
    {
      "epoch": 9.338247203857698,
      "grad_norm": 4.773848056793213,
      "learning_rate": 3.32897522760957e-06,
      "loss": 0.6279,
      "step": 882100
    },
    {
      "epoch": 9.3387765256377,
      "grad_norm": 4.916708469390869,
      "learning_rate": 3.3263286047004025e-06,
      "loss": 0.6261,
      "step": 882150
    },
    {
      "epoch": 9.339305847417704,
      "grad_norm": 4.48430871963501,
      "learning_rate": 3.3236819817912344e-06,
      "loss": 0.617,
      "step": 882200
    },
    {
      "epoch": 9.339835169197707,
      "grad_norm": 4.469167232513428,
      "learning_rate": 3.32108829134025e-06,
      "loss": 0.6395,
      "step": 882250
    },
    {
      "epoch": 9.340364490977711,
      "grad_norm": 4.475925922393799,
      "learning_rate": 3.318441668431082e-06,
      "loss": 0.6204,
      "step": 882300
    },
    {
      "epoch": 9.340893812757713,
      "grad_norm": 4.477064609527588,
      "learning_rate": 3.315795045521914e-06,
      "loss": 0.616,
      "step": 882350
    },
    {
      "epoch": 9.341423134537717,
      "grad_norm": 4.458321571350098,
      "learning_rate": 3.313148422612746e-06,
      "loss": 0.6325,
      "step": 882400
    },
    {
      "epoch": 9.34195245631772,
      "grad_norm": 5.238557815551758,
      "learning_rate": 3.3105017997035784e-06,
      "loss": 0.6172,
      "step": 882450
    },
    {
      "epoch": 9.342481778097724,
      "grad_norm": 4.743469715118408,
      "learning_rate": 3.3078551767944103e-06,
      "loss": 0.6172,
      "step": 882500
    },
    {
      "epoch": 9.342481778097724,
      "eval_loss": 0.3776930868625641,
      "eval_runtime": 46.5214,
      "eval_samples_per_second": 3609.735,
      "eval_steps_per_second": 451.233,
      "step": 882500
    },
    {
      "epoch": 9.343011099877726,
      "grad_norm": 4.911684513092041,
      "learning_rate": 3.3052085538852423e-06,
      "loss": 0.6206,
      "step": 882550
    },
    {
      "epoch": 9.34354042165773,
      "grad_norm": 4.4107255935668945,
      "learning_rate": 3.3025619309760747e-06,
      "loss": 0.6189,
      "step": 882600
    },
    {
      "epoch": 9.344069743437734,
      "grad_norm": 4.603094577789307,
      "learning_rate": 3.2999153080669067e-06,
      "loss": 0.6125,
      "step": 882650
    },
    {
      "epoch": 9.344599065217736,
      "grad_norm": 4.3689680099487305,
      "learning_rate": 3.2972686851577387e-06,
      "loss": 0.6167,
      "step": 882700
    },
    {
      "epoch": 9.34512838699774,
      "grad_norm": 4.534614562988281,
      "learning_rate": 3.2946220622485707e-06,
      "loss": 0.6319,
      "step": 882750
    },
    {
      "epoch": 9.345657708777743,
      "grad_norm": 4.608916282653809,
      "learning_rate": 3.291975439339403e-06,
      "loss": 0.6239,
      "step": 882800
    },
    {
      "epoch": 9.346187030557747,
      "grad_norm": 4.165440559387207,
      "learning_rate": 3.289381748888418e-06,
      "loss": 0.6301,
      "step": 882850
    },
    {
      "epoch": 9.346716352337749,
      "grad_norm": 4.872348785400391,
      "learning_rate": 3.2867351259792506e-06,
      "loss": 0.6206,
      "step": 882900
    },
    {
      "epoch": 9.347245674117753,
      "grad_norm": 4.509642124176025,
      "learning_rate": 3.2840885030700826e-06,
      "loss": 0.6213,
      "step": 882950
    },
    {
      "epoch": 9.347774995897757,
      "grad_norm": 5.1232805252075195,
      "learning_rate": 3.2814418801609146e-06,
      "loss": 0.619,
      "step": 883000
    },
    {
      "epoch": 9.347774995897757,
      "eval_loss": 0.37740984559059143,
      "eval_runtime": 46.5164,
      "eval_samples_per_second": 3610.122,
      "eval_steps_per_second": 451.281,
      "step": 883000
    },
    {
      "epoch": 9.34830431767776,
      "grad_norm": 4.636209964752197,
      "learning_rate": 3.2787952572517466e-06,
      "loss": 0.6291,
      "step": 883050
    },
    {
      "epoch": 9.348833639457762,
      "grad_norm": 4.3855791091918945,
      "learning_rate": 3.276148634342579e-06,
      "loss": 0.6287,
      "step": 883100
    },
    {
      "epoch": 9.349362961237766,
      "grad_norm": 4.793722629547119,
      "learning_rate": 3.273502011433411e-06,
      "loss": 0.6255,
      "step": 883150
    },
    {
      "epoch": 9.34989228301777,
      "grad_norm": 4.25275182723999,
      "learning_rate": 3.270855388524243e-06,
      "loss": 0.6267,
      "step": 883200
    },
    {
      "epoch": 9.350421604797774,
      "grad_norm": 4.896143436431885,
      "learning_rate": 3.2682087656150753e-06,
      "loss": 0.6197,
      "step": 883250
    },
    {
      "epoch": 9.350950926577775,
      "grad_norm": 4.337701320648193,
      "learning_rate": 3.2655621427059073e-06,
      "loss": 0.6183,
      "step": 883300
    },
    {
      "epoch": 9.35148024835778,
      "grad_norm": 4.786094665527344,
      "learning_rate": 3.2629155197967393e-06,
      "loss": 0.6182,
      "step": 883350
    },
    {
      "epoch": 9.352009570137783,
      "grad_norm": 4.572144031524658,
      "learning_rate": 3.2602688968875717e-06,
      "loss": 0.6196,
      "step": 883400
    },
    {
      "epoch": 9.352538891917785,
      "grad_norm": 4.3819260597229,
      "learning_rate": 3.2576222739784037e-06,
      "loss": 0.6196,
      "step": 883450
    },
    {
      "epoch": 9.353068213697789,
      "grad_norm": 4.3664398193359375,
      "learning_rate": 3.2549756510692357e-06,
      "loss": 0.6222,
      "step": 883500
    },
    {
      "epoch": 9.353068213697789,
      "eval_loss": 0.37739089131355286,
      "eval_runtime": 46.4373,
      "eval_samples_per_second": 3616.271,
      "eval_steps_per_second": 452.05,
      "step": 883500
    },
    {
      "epoch": 9.353597535477792,
      "grad_norm": 4.783595085144043,
      "learning_rate": 3.2523290281600677e-06,
      "loss": 0.6251,
      "step": 883550
    },
    {
      "epoch": 9.354126857257796,
      "grad_norm": 5.113645553588867,
      "learning_rate": 3.2496824052509e-06,
      "loss": 0.6198,
      "step": 883600
    },
    {
      "epoch": 9.354656179037798,
      "grad_norm": 4.438260555267334,
      "learning_rate": 3.247035782341732e-06,
      "loss": 0.6294,
      "step": 883650
    },
    {
      "epoch": 9.355185500817802,
      "grad_norm": 5.2631683349609375,
      "learning_rate": 3.244389159432564e-06,
      "loss": 0.6257,
      "step": 883700
    },
    {
      "epoch": 9.355714822597806,
      "grad_norm": 4.342845916748047,
      "learning_rate": 3.2417425365233964e-06,
      "loss": 0.6151,
      "step": 883750
    },
    {
      "epoch": 9.35624414437781,
      "grad_norm": 4.462092876434326,
      "learning_rate": 3.2390959136142284e-06,
      "loss": 0.6214,
      "step": 883800
    },
    {
      "epoch": 9.356773466157811,
      "grad_norm": 4.7166523933410645,
      "learning_rate": 3.2364492907050604e-06,
      "loss": 0.6257,
      "step": 883850
    },
    {
      "epoch": 9.357302787937815,
      "grad_norm": 4.455509185791016,
      "learning_rate": 3.2338026677958924e-06,
      "loss": 0.6234,
      "step": 883900
    },
    {
      "epoch": 9.357832109717819,
      "grad_norm": 4.516049861907959,
      "learning_rate": 3.2311560448867248e-06,
      "loss": 0.6199,
      "step": 883950
    },
    {
      "epoch": 9.358361431497823,
      "grad_norm": 4.676673412322998,
      "learning_rate": 3.2285094219775568e-06,
      "loss": 0.621,
      "step": 884000
    },
    {
      "epoch": 9.358361431497823,
      "eval_loss": 0.37730374932289124,
      "eval_runtime": 46.4914,
      "eval_samples_per_second": 3612.068,
      "eval_steps_per_second": 451.525,
      "step": 884000
    },
    {
      "epoch": 9.358890753277825,
      "grad_norm": 4.843295574188232,
      "learning_rate": 3.2258627990683887e-06,
      "loss": 0.6223,
      "step": 884050
    },
    {
      "epoch": 9.359420075057828,
      "grad_norm": 4.688845634460449,
      "learning_rate": 3.223216176159221e-06,
      "loss": 0.6214,
      "step": 884100
    },
    {
      "epoch": 9.359949396837832,
      "grad_norm": 4.734012126922607,
      "learning_rate": 3.220569553250053e-06,
      "loss": 0.6205,
      "step": 884150
    },
    {
      "epoch": 9.360478718617834,
      "grad_norm": 4.986998081207275,
      "learning_rate": 3.217922930340885e-06,
      "loss": 0.6254,
      "step": 884200
    },
    {
      "epoch": 9.361008040397838,
      "grad_norm": 4.220849514007568,
      "learning_rate": 3.215276307431717e-06,
      "loss": 0.6301,
      "step": 884250
    },
    {
      "epoch": 9.361537362177842,
      "grad_norm": 4.999541759490967,
      "learning_rate": 3.2126296845225495e-06,
      "loss": 0.6378,
      "step": 884300
    },
    {
      "epoch": 9.362066683957845,
      "grad_norm": 4.817483901977539,
      "learning_rate": 3.2099830616133815e-06,
      "loss": 0.6272,
      "step": 884350
    },
    {
      "epoch": 9.362596005737847,
      "grad_norm": 4.536635398864746,
      "learning_rate": 3.2073364387042135e-06,
      "loss": 0.6107,
      "step": 884400
    },
    {
      "epoch": 9.363125327517851,
      "grad_norm": 4.910282611846924,
      "learning_rate": 3.204689815795046e-06,
      "loss": 0.6303,
      "step": 884450
    },
    {
      "epoch": 9.363654649297855,
      "grad_norm": 4.684659004211426,
      "learning_rate": 3.202043192885878e-06,
      "loss": 0.6185,
      "step": 884500
    },
    {
      "epoch": 9.363654649297855,
      "eval_loss": 0.3772287666797638,
      "eval_runtime": 46.6833,
      "eval_samples_per_second": 3597.219,
      "eval_steps_per_second": 449.668,
      "step": 884500
    },
    {
      "epoch": 9.364183971077859,
      "grad_norm": 4.533550262451172,
      "learning_rate": 3.19939656997671e-06,
      "loss": 0.6159,
      "step": 884550
    },
    {
      "epoch": 9.36471329285786,
      "grad_norm": 4.416392803192139,
      "learning_rate": 3.196749947067542e-06,
      "loss": 0.6174,
      "step": 884600
    },
    {
      "epoch": 9.365242614637864,
      "grad_norm": 4.581380367279053,
      "learning_rate": 3.1941033241583742e-06,
      "loss": 0.6149,
      "step": 884650
    },
    {
      "epoch": 9.365771936417868,
      "grad_norm": 4.714706897735596,
      "learning_rate": 3.1914567012492062e-06,
      "loss": 0.6275,
      "step": 884700
    },
    {
      "epoch": 9.366301258197872,
      "grad_norm": 4.820221900939941,
      "learning_rate": 3.188810078340038e-06,
      "loss": 0.6316,
      "step": 884750
    },
    {
      "epoch": 9.366830579977874,
      "grad_norm": 4.537561893463135,
      "learning_rate": 3.1861634554308706e-06,
      "loss": 0.616,
      "step": 884800
    },
    {
      "epoch": 9.367359901757878,
      "grad_norm": 4.42812442779541,
      "learning_rate": 3.1835168325217026e-06,
      "loss": 0.6263,
      "step": 884850
    },
    {
      "epoch": 9.367889223537881,
      "grad_norm": 4.69655179977417,
      "learning_rate": 3.1808702096125346e-06,
      "loss": 0.6204,
      "step": 884900
    },
    {
      "epoch": 9.368418545317883,
      "grad_norm": 4.856907367706299,
      "learning_rate": 3.1782235867033665e-06,
      "loss": 0.6289,
      "step": 884950
    },
    {
      "epoch": 9.368947867097887,
      "grad_norm": 4.327805519104004,
      "learning_rate": 3.175576963794199e-06,
      "loss": 0.6173,
      "step": 885000
    },
    {
      "epoch": 9.368947867097887,
      "eval_loss": 0.3773953914642334,
      "eval_runtime": 46.5012,
      "eval_samples_per_second": 3611.301,
      "eval_steps_per_second": 451.429,
      "step": 885000
    },
    {
      "epoch": 9.369477188877891,
      "grad_norm": 4.5435614585876465,
      "learning_rate": 3.172930340885031e-06,
      "loss": 0.6116,
      "step": 885050
    },
    {
      "epoch": 9.370006510657895,
      "grad_norm": 4.604992866516113,
      "learning_rate": 3.170283717975863e-06,
      "loss": 0.617,
      "step": 885100
    },
    {
      "epoch": 9.370535832437897,
      "grad_norm": 4.3646368980407715,
      "learning_rate": 3.1676370950666953e-06,
      "loss": 0.6231,
      "step": 885150
    },
    {
      "epoch": 9.3710651542179,
      "grad_norm": 4.532669544219971,
      "learning_rate": 3.1649904721575273e-06,
      "loss": 0.6245,
      "step": 885200
    },
    {
      "epoch": 9.371594475997904,
      "grad_norm": 4.998809814453125,
      "learning_rate": 3.1623438492483593e-06,
      "loss": 0.6254,
      "step": 885250
    },
    {
      "epoch": 9.372123797777908,
      "grad_norm": 4.873973369598389,
      "learning_rate": 3.1596972263391917e-06,
      "loss": 0.6316,
      "step": 885300
    },
    {
      "epoch": 9.37265311955791,
      "grad_norm": 4.258720397949219,
      "learning_rate": 3.1570506034300237e-06,
      "loss": 0.6208,
      "step": 885350
    },
    {
      "epoch": 9.373182441337914,
      "grad_norm": 5.480170249938965,
      "learning_rate": 3.1544039805208557e-06,
      "loss": 0.6272,
      "step": 885400
    },
    {
      "epoch": 9.373711763117917,
      "grad_norm": 4.374601364135742,
      "learning_rate": 3.1517573576116876e-06,
      "loss": 0.6231,
      "step": 885450
    },
    {
      "epoch": 9.374241084897921,
      "grad_norm": 4.678127288818359,
      "learning_rate": 3.14911073470252e-06,
      "loss": 0.6256,
      "step": 885500
    },
    {
      "epoch": 9.374241084897921,
      "eval_loss": 0.37771496176719666,
      "eval_runtime": 46.5446,
      "eval_samples_per_second": 3607.937,
      "eval_steps_per_second": 451.008,
      "step": 885500
    },
    {
      "epoch": 9.374770406677923,
      "grad_norm": 5.041460990905762,
      "learning_rate": 3.146464111793352e-06,
      "loss": 0.6207,
      "step": 885550
    },
    {
      "epoch": 9.375299728457927,
      "grad_norm": 4.503024101257324,
      "learning_rate": 3.143817488884184e-06,
      "loss": 0.6223,
      "step": 885600
    },
    {
      "epoch": 9.37582905023793,
      "grad_norm": 4.596179485321045,
      "learning_rate": 3.1411708659750164e-06,
      "loss": 0.6255,
      "step": 885650
    },
    {
      "epoch": 9.376358372017933,
      "grad_norm": 4.5590500831604,
      "learning_rate": 3.1385242430658484e-06,
      "loss": 0.6087,
      "step": 885700
    },
    {
      "epoch": 9.376887693797936,
      "grad_norm": 4.572854995727539,
      "learning_rate": 3.1358776201566804e-06,
      "loss": 0.6131,
      "step": 885750
    },
    {
      "epoch": 9.37741701557794,
      "grad_norm": 4.294109344482422,
      "learning_rate": 3.1332309972475124e-06,
      "loss": 0.6126,
      "step": 885800
    },
    {
      "epoch": 9.377946337357944,
      "grad_norm": 4.309421062469482,
      "learning_rate": 3.1305843743383448e-06,
      "loss": 0.6267,
      "step": 885850
    },
    {
      "epoch": 9.378475659137946,
      "grad_norm": 4.7082977294921875,
      "learning_rate": 3.1279377514291768e-06,
      "loss": 0.6271,
      "step": 885900
    },
    {
      "epoch": 9.37900498091795,
      "grad_norm": 4.442171096801758,
      "learning_rate": 3.1252911285200087e-06,
      "loss": 0.6333,
      "step": 885950
    },
    {
      "epoch": 9.379534302697953,
      "grad_norm": 4.755815505981445,
      "learning_rate": 3.1226445056108407e-06,
      "loss": 0.6276,
      "step": 886000
    },
    {
      "epoch": 9.379534302697953,
      "eval_loss": 0.3776737451553345,
      "eval_runtime": 46.9408,
      "eval_samples_per_second": 3577.482,
      "eval_steps_per_second": 447.201,
      "step": 886000
    },
    {
      "epoch": 9.380063624477957,
      "grad_norm": 4.720427989959717,
      "learning_rate": 3.1199978827016727e-06,
      "loss": 0.627,
      "step": 886050
    },
    {
      "epoch": 9.38059294625796,
      "grad_norm": 4.586280345916748,
      "learning_rate": 3.1173512597925047e-06,
      "loss": 0.6186,
      "step": 886100
    },
    {
      "epoch": 9.381122268037963,
      "grad_norm": 4.633512496948242,
      "learning_rate": 3.114704636883337e-06,
      "loss": 0.628,
      "step": 886150
    },
    {
      "epoch": 9.381651589817967,
      "grad_norm": 4.373484134674072,
      "learning_rate": 3.112058013974169e-06,
      "loss": 0.6142,
      "step": 886200
    },
    {
      "epoch": 9.38218091159797,
      "grad_norm": 4.788548946380615,
      "learning_rate": 3.109411391065001e-06,
      "loss": 0.6199,
      "step": 886250
    },
    {
      "epoch": 9.382710233377972,
      "grad_norm": 4.795863628387451,
      "learning_rate": 3.106764768155833e-06,
      "loss": 0.6242,
      "step": 886300
    },
    {
      "epoch": 9.383239555157976,
      "grad_norm": 5.409213542938232,
      "learning_rate": 3.1041181452466654e-06,
      "loss": 0.6265,
      "step": 886350
    },
    {
      "epoch": 9.38376887693798,
      "grad_norm": 4.564129829406738,
      "learning_rate": 3.1014715223374974e-06,
      "loss": 0.6212,
      "step": 886400
    },
    {
      "epoch": 9.384298198717982,
      "grad_norm": 4.547084808349609,
      "learning_rate": 3.0988248994283294e-06,
      "loss": 0.622,
      "step": 886450
    },
    {
      "epoch": 9.384827520497986,
      "grad_norm": 4.599459171295166,
      "learning_rate": 3.096178276519162e-06,
      "loss": 0.6208,
      "step": 886500
    },
    {
      "epoch": 9.384827520497986,
      "eval_loss": 0.37678518891334534,
      "eval_runtime": 46.4878,
      "eval_samples_per_second": 3612.345,
      "eval_steps_per_second": 451.559,
      "step": 886500
    },
    {
      "epoch": 9.38535684227799,
      "grad_norm": 4.628222942352295,
      "learning_rate": 3.093531653609994e-06,
      "loss": 0.6369,
      "step": 886550
    },
    {
      "epoch": 9.385886164057993,
      "grad_norm": 5.088184833526611,
      "learning_rate": 3.0908850307008258e-06,
      "loss": 0.6303,
      "step": 886600
    },
    {
      "epoch": 9.386415485837995,
      "grad_norm": 4.5808234214782715,
      "learning_rate": 3.088238407791658e-06,
      "loss": 0.6218,
      "step": 886650
    },
    {
      "epoch": 9.386944807617999,
      "grad_norm": 4.562501907348633,
      "learning_rate": 3.08559178488249e-06,
      "loss": 0.6048,
      "step": 886700
    },
    {
      "epoch": 9.387474129398003,
      "grad_norm": 4.209802150726318,
      "learning_rate": 3.082945161973322e-06,
      "loss": 0.6132,
      "step": 886750
    },
    {
      "epoch": 9.388003451178006,
      "grad_norm": 5.013705730438232,
      "learning_rate": 3.080298539064154e-06,
      "loss": 0.6364,
      "step": 886800
    },
    {
      "epoch": 9.388532772958008,
      "grad_norm": 4.866179943084717,
      "learning_rate": 3.0777048486131697e-06,
      "loss": 0.6124,
      "step": 886850
    },
    {
      "epoch": 9.389062094738012,
      "grad_norm": 4.648382663726807,
      "learning_rate": 3.0750582257040017e-06,
      "loss": 0.6075,
      "step": 886900
    },
    {
      "epoch": 9.389591416518016,
      "grad_norm": 5.4075846672058105,
      "learning_rate": 3.072411602794834e-06,
      "loss": 0.6169,
      "step": 886950
    },
    {
      "epoch": 9.39012073829802,
      "grad_norm": 4.632690906524658,
      "learning_rate": 3.069764979885666e-06,
      "loss": 0.623,
      "step": 887000
    },
    {
      "epoch": 9.39012073829802,
      "eval_loss": 0.3770088255405426,
      "eval_runtime": 46.6318,
      "eval_samples_per_second": 3601.188,
      "eval_steps_per_second": 450.165,
      "step": 887000
    },
    {
      "epoch": 9.390650060078022,
      "grad_norm": 4.835673809051514,
      "learning_rate": 3.067171289434681e-06,
      "loss": 0.6105,
      "step": 887050
    },
    {
      "epoch": 9.391179381858025,
      "grad_norm": 5.091145038604736,
      "learning_rate": 3.0645246665255136e-06,
      "loss": 0.6227,
      "step": 887100
    },
    {
      "epoch": 9.39170870363803,
      "grad_norm": 4.632553577423096,
      "learning_rate": 3.0618780436163456e-06,
      "loss": 0.6168,
      "step": 887150
    },
    {
      "epoch": 9.392238025418031,
      "grad_norm": 4.803491115570068,
      "learning_rate": 3.0592314207071776e-06,
      "loss": 0.6316,
      "step": 887200
    },
    {
      "epoch": 9.392767347198035,
      "grad_norm": 4.866758346557617,
      "learning_rate": 3.05658479779801e-06,
      "loss": 0.62,
      "step": 887250
    },
    {
      "epoch": 9.393296668978039,
      "grad_norm": 5.219491481781006,
      "learning_rate": 3.053938174888842e-06,
      "loss": 0.6264,
      "step": 887300
    },
    {
      "epoch": 9.393825990758042,
      "grad_norm": 4.145533084869385,
      "learning_rate": 3.051291551979674e-06,
      "loss": 0.6246,
      "step": 887350
    },
    {
      "epoch": 9.394355312538044,
      "grad_norm": 4.1431989669799805,
      "learning_rate": 3.048644929070506e-06,
      "loss": 0.616,
      "step": 887400
    },
    {
      "epoch": 9.394884634318048,
      "grad_norm": 4.7732014656066895,
      "learning_rate": 3.0459983061613383e-06,
      "loss": 0.6213,
      "step": 887450
    },
    {
      "epoch": 9.395413956098052,
      "grad_norm": 4.658923149108887,
      "learning_rate": 3.0433516832521703e-06,
      "loss": 0.6183,
      "step": 887500
    },
    {
      "epoch": 9.395413956098052,
      "eval_loss": 0.3769592344760895,
      "eval_runtime": 46.4995,
      "eval_samples_per_second": 3611.435,
      "eval_steps_per_second": 451.446,
      "step": 887500
    },
    {
      "epoch": 9.395943277878056,
      "grad_norm": 4.843742847442627,
      "learning_rate": 3.0407050603430023e-06,
      "loss": 0.6193,
      "step": 887550
    },
    {
      "epoch": 9.396472599658058,
      "grad_norm": 4.455556869506836,
      "learning_rate": 3.0380584374338347e-06,
      "loss": 0.6294,
      "step": 887600
    },
    {
      "epoch": 9.397001921438061,
      "grad_norm": 4.3716959953308105,
      "learning_rate": 3.0354118145246667e-06,
      "loss": 0.616,
      "step": 887650
    },
    {
      "epoch": 9.397531243218065,
      "grad_norm": 4.605114459991455,
      "learning_rate": 3.0327651916154987e-06,
      "loss": 0.6265,
      "step": 887700
    },
    {
      "epoch": 9.398060564998069,
      "grad_norm": 5.031522274017334,
      "learning_rate": 3.0301185687063306e-06,
      "loss": 0.6179,
      "step": 887750
    },
    {
      "epoch": 9.39858988677807,
      "grad_norm": 5.034595012664795,
      "learning_rate": 3.027471945797163e-06,
      "loss": 0.626,
      "step": 887800
    },
    {
      "epoch": 9.399119208558075,
      "grad_norm": 4.799563884735107,
      "learning_rate": 3.024825322887995e-06,
      "loss": 0.6273,
      "step": 887850
    },
    {
      "epoch": 9.399648530338078,
      "grad_norm": 4.575229644775391,
      "learning_rate": 3.022178699978827e-06,
      "loss": 0.6133,
      "step": 887900
    },
    {
      "epoch": 9.40017785211808,
      "grad_norm": 4.802439212799072,
      "learning_rate": 3.0195320770696594e-06,
      "loss": 0.6273,
      "step": 887950
    },
    {
      "epoch": 9.400707173898084,
      "grad_norm": 4.659022808074951,
      "learning_rate": 3.0168854541604914e-06,
      "loss": 0.6185,
      "step": 888000
    },
    {
      "epoch": 9.400707173898084,
      "eval_loss": 0.37718987464904785,
      "eval_runtime": 46.5197,
      "eval_samples_per_second": 3609.869,
      "eval_steps_per_second": 451.25,
      "step": 888000
    },
    {
      "epoch": 9.401236495678088,
      "grad_norm": 4.705782413482666,
      "learning_rate": 3.0142388312513234e-06,
      "loss": 0.6185,
      "step": 888050
    },
    {
      "epoch": 9.401765817458092,
      "grad_norm": 4.596451759338379,
      "learning_rate": 3.0115922083421554e-06,
      "loss": 0.6254,
      "step": 888100
    },
    {
      "epoch": 9.402295139238094,
      "grad_norm": 4.835406303405762,
      "learning_rate": 3.0089455854329878e-06,
      "loss": 0.6174,
      "step": 888150
    },
    {
      "epoch": 9.402824461018097,
      "grad_norm": 4.5533857345581055,
      "learning_rate": 3.0062989625238197e-06,
      "loss": 0.6242,
      "step": 888200
    },
    {
      "epoch": 9.403353782798101,
      "grad_norm": 4.508453845977783,
      "learning_rate": 3.0036523396146517e-06,
      "loss": 0.6188,
      "step": 888250
    },
    {
      "epoch": 9.403883104578105,
      "grad_norm": 4.625293254852295,
      "learning_rate": 3.001005716705484e-06,
      "loss": 0.6229,
      "step": 888300
    },
    {
      "epoch": 9.404412426358107,
      "grad_norm": 4.669679641723633,
      "learning_rate": 2.998359093796316e-06,
      "loss": 0.6235,
      "step": 888350
    },
    {
      "epoch": 9.40494174813811,
      "grad_norm": 4.500948905944824,
      "learning_rate": 2.995712470887148e-06,
      "loss": 0.6174,
      "step": 888400
    },
    {
      "epoch": 9.405471069918114,
      "grad_norm": 4.827215671539307,
      "learning_rate": 2.9930658479779805e-06,
      "loss": 0.614,
      "step": 888450
    },
    {
      "epoch": 9.406000391698118,
      "grad_norm": 4.376901626586914,
      "learning_rate": 2.9904192250688125e-06,
      "loss": 0.6177,
      "step": 888500
    },
    {
      "epoch": 9.406000391698118,
      "eval_loss": 0.37699028849601746,
      "eval_runtime": 46.8464,
      "eval_samples_per_second": 3584.695,
      "eval_steps_per_second": 448.103,
      "step": 888500
    },
    {
      "epoch": 9.40652971347812,
      "grad_norm": 4.354579925537109,
      "learning_rate": 2.9877726021596445e-06,
      "loss": 0.6198,
      "step": 888550
    },
    {
      "epoch": 9.407059035258124,
      "grad_norm": 4.763465404510498,
      "learning_rate": 2.9851259792504765e-06,
      "loss": 0.6248,
      "step": 888600
    },
    {
      "epoch": 9.407588357038128,
      "grad_norm": 5.011619567871094,
      "learning_rate": 2.982479356341309e-06,
      "loss": 0.6269,
      "step": 888650
    },
    {
      "epoch": 9.40811767881813,
      "grad_norm": 4.2999138832092285,
      "learning_rate": 2.979832733432141e-06,
      "loss": 0.6184,
      "step": 888700
    },
    {
      "epoch": 9.408647000598133,
      "grad_norm": 4.577530384063721,
      "learning_rate": 2.977186110522973e-06,
      "loss": 0.6197,
      "step": 888750
    },
    {
      "epoch": 9.409176322378137,
      "grad_norm": 4.9312334060668945,
      "learning_rate": 2.9745394876138052e-06,
      "loss": 0.6145,
      "step": 888800
    },
    {
      "epoch": 9.40970564415814,
      "grad_norm": 4.351410388946533,
      "learning_rate": 2.971892864704637e-06,
      "loss": 0.6292,
      "step": 888850
    },
    {
      "epoch": 9.410234965938143,
      "grad_norm": 4.485166072845459,
      "learning_rate": 2.969246241795469e-06,
      "loss": 0.6196,
      "step": 888900
    },
    {
      "epoch": 9.410764287718147,
      "grad_norm": 4.918643951416016,
      "learning_rate": 2.966599618886301e-06,
      "loss": 0.6206,
      "step": 888950
    },
    {
      "epoch": 9.41129360949815,
      "grad_norm": 4.399148941040039,
      "learning_rate": 2.9639529959771336e-06,
      "loss": 0.6138,
      "step": 889000
    },
    {
      "epoch": 9.41129360949815,
      "eval_loss": 0.3766309916973114,
      "eval_runtime": 46.7196,
      "eval_samples_per_second": 3594.421,
      "eval_steps_per_second": 449.319,
      "step": 889000
    },
    {
      "epoch": 9.411822931278154,
      "grad_norm": 5.119743824005127,
      "learning_rate": 2.9613063730679656e-06,
      "loss": 0.6237,
      "step": 889050
    },
    {
      "epoch": 9.412352253058156,
      "grad_norm": 4.973933696746826,
      "learning_rate": 2.9586597501587975e-06,
      "loss": 0.6148,
      "step": 889100
    },
    {
      "epoch": 9.41288157483816,
      "grad_norm": 4.868291854858398,
      "learning_rate": 2.95601312724963e-06,
      "loss": 0.6302,
      "step": 889150
    },
    {
      "epoch": 9.413410896618164,
      "grad_norm": 4.405329704284668,
      "learning_rate": 2.953366504340462e-06,
      "loss": 0.6219,
      "step": 889200
    },
    {
      "epoch": 9.413940218398167,
      "grad_norm": 4.3482584953308105,
      "learning_rate": 2.950719881431294e-06,
      "loss": 0.6174,
      "step": 889250
    },
    {
      "epoch": 9.41446954017817,
      "grad_norm": 4.528353691101074,
      "learning_rate": 2.948073258522126e-06,
      "loss": 0.621,
      "step": 889300
    },
    {
      "epoch": 9.414998861958173,
      "grad_norm": 4.92843770980835,
      "learning_rate": 2.945426635612958e-06,
      "loss": 0.6181,
      "step": 889350
    },
    {
      "epoch": 9.415528183738177,
      "grad_norm": 4.416881084442139,
      "learning_rate": 2.94278001270379e-06,
      "loss": 0.6311,
      "step": 889400
    },
    {
      "epoch": 9.416057505518179,
      "grad_norm": 4.579313278198242,
      "learning_rate": 2.940133389794622e-06,
      "loss": 0.6224,
      "step": 889450
    },
    {
      "epoch": 9.416586827298183,
      "grad_norm": 4.459275722503662,
      "learning_rate": 2.9374867668854543e-06,
      "loss": 0.6278,
      "step": 889500
    },
    {
      "epoch": 9.416586827298183,
      "eval_loss": 0.3766080141067505,
      "eval_runtime": 46.5455,
      "eval_samples_per_second": 3607.869,
      "eval_steps_per_second": 451.0,
      "step": 889500
    },
    {
      "epoch": 9.417116149078186,
      "grad_norm": 4.476409912109375,
      "learning_rate": 2.9348401439762862e-06,
      "loss": 0.6315,
      "step": 889550
    },
    {
      "epoch": 9.41764547085819,
      "grad_norm": 4.440021514892578,
      "learning_rate": 2.9321935210671182e-06,
      "loss": 0.6283,
      "step": 889600
    },
    {
      "epoch": 9.418174792638192,
      "grad_norm": 4.540497303009033,
      "learning_rate": 2.9295468981579506e-06,
      "loss": 0.6175,
      "step": 889650
    },
    {
      "epoch": 9.418704114418196,
      "grad_norm": 4.997742176055908,
      "learning_rate": 2.9269002752487826e-06,
      "loss": 0.6276,
      "step": 889700
    },
    {
      "epoch": 9.4192334361982,
      "grad_norm": 4.6433587074279785,
      "learning_rate": 2.9242536523396146e-06,
      "loss": 0.612,
      "step": 889750
    },
    {
      "epoch": 9.419762757978203,
      "grad_norm": 4.462170600891113,
      "learning_rate": 2.921607029430447e-06,
      "loss": 0.6285,
      "step": 889800
    },
    {
      "epoch": 9.420292079758205,
      "grad_norm": 4.944484710693359,
      "learning_rate": 2.918960406521279e-06,
      "loss": 0.6319,
      "step": 889850
    },
    {
      "epoch": 9.420821401538209,
      "grad_norm": 4.3835015296936035,
      "learning_rate": 2.916313783612111e-06,
      "loss": 0.6189,
      "step": 889900
    },
    {
      "epoch": 9.421350723318213,
      "grad_norm": 4.848328113555908,
      "learning_rate": 2.913667160702943e-06,
      "loss": 0.6193,
      "step": 889950
    },
    {
      "epoch": 9.421880045098217,
      "grad_norm": 4.717892646789551,
      "learning_rate": 2.9110205377937753e-06,
      "loss": 0.617,
      "step": 890000
    },
    {
      "epoch": 9.421880045098217,
      "eval_loss": 0.3768584430217743,
      "eval_runtime": 46.5342,
      "eval_samples_per_second": 3608.74,
      "eval_steps_per_second": 451.109,
      "step": 890000
    },
    {
      "epoch": 9.422409366878219,
      "grad_norm": 4.8992156982421875,
      "learning_rate": 2.9083739148846073e-06,
      "loss": 0.6286,
      "step": 890050
    },
    {
      "epoch": 9.422938688658222,
      "grad_norm": 4.636980056762695,
      "learning_rate": 2.9057272919754393e-06,
      "loss": 0.6269,
      "step": 890100
    },
    {
      "epoch": 9.423468010438226,
      "grad_norm": 4.636525630950928,
      "learning_rate": 2.9030806690662717e-06,
      "loss": 0.6248,
      "step": 890150
    },
    {
      "epoch": 9.423997332218228,
      "grad_norm": 4.589677810668945,
      "learning_rate": 2.9004340461571037e-06,
      "loss": 0.6205,
      "step": 890200
    },
    {
      "epoch": 9.424526653998232,
      "grad_norm": 4.9914164543151855,
      "learning_rate": 2.8977874232479357e-06,
      "loss": 0.6168,
      "step": 890250
    },
    {
      "epoch": 9.425055975778236,
      "grad_norm": 4.50715970993042,
      "learning_rate": 2.8951408003387677e-06,
      "loss": 0.6249,
      "step": 890300
    },
    {
      "epoch": 9.42558529755824,
      "grad_norm": 4.710012435913086,
      "learning_rate": 2.8924941774296e-06,
      "loss": 0.6218,
      "step": 890350
    },
    {
      "epoch": 9.426114619338241,
      "grad_norm": 4.922373294830322,
      "learning_rate": 2.889900486978615e-06,
      "loss": 0.6185,
      "step": 890400
    },
    {
      "epoch": 9.426643941118245,
      "grad_norm": 4.5571770668029785,
      "learning_rate": 2.8872538640694476e-06,
      "loss": 0.6274,
      "step": 890450
    },
    {
      "epoch": 9.427173262898249,
      "grad_norm": 4.115337371826172,
      "learning_rate": 2.8846072411602796e-06,
      "loss": 0.6176,
      "step": 890500
    },
    {
      "epoch": 9.427173262898249,
      "eval_loss": 0.37687253952026367,
      "eval_runtime": 46.9524,
      "eval_samples_per_second": 3576.6,
      "eval_steps_per_second": 447.091,
      "step": 890500
    },
    {
      "epoch": 9.427702584678253,
      "grad_norm": 4.408768653869629,
      "learning_rate": 2.8819606182511116e-06,
      "loss": 0.6247,
      "step": 890550
    },
    {
      "epoch": 9.428231906458254,
      "grad_norm": 5.077070236206055,
      "learning_rate": 2.8793139953419436e-06,
      "loss": 0.6228,
      "step": 890600
    },
    {
      "epoch": 9.428761228238258,
      "grad_norm": 4.301514625549316,
      "learning_rate": 2.876667372432776e-06,
      "loss": 0.6214,
      "step": 890650
    },
    {
      "epoch": 9.429290550018262,
      "grad_norm": 4.312952995300293,
      "learning_rate": 2.874020749523608e-06,
      "loss": 0.6277,
      "step": 890700
    },
    {
      "epoch": 9.429819871798266,
      "grad_norm": 5.108469486236572,
      "learning_rate": 2.87137412661444e-06,
      "loss": 0.6138,
      "step": 890750
    },
    {
      "epoch": 9.430349193578268,
      "grad_norm": 4.850362300872803,
      "learning_rate": 2.8687275037052723e-06,
      "loss": 0.6262,
      "step": 890800
    },
    {
      "epoch": 9.430878515358271,
      "grad_norm": 4.65686559677124,
      "learning_rate": 2.8660808807961043e-06,
      "loss": 0.6225,
      "step": 890850
    },
    {
      "epoch": 9.431407837138275,
      "grad_norm": 4.748959064483643,
      "learning_rate": 2.8634342578869363e-06,
      "loss": 0.615,
      "step": 890900
    },
    {
      "epoch": 9.431937158918277,
      "grad_norm": 4.3842034339904785,
      "learning_rate": 2.8607876349777683e-06,
      "loss": 0.6219,
      "step": 890950
    },
    {
      "epoch": 9.432466480698281,
      "grad_norm": 4.871008396148682,
      "learning_rate": 2.8581410120686007e-06,
      "loss": 0.6174,
      "step": 891000
    },
    {
      "epoch": 9.432466480698281,
      "eval_loss": 0.3767423927783966,
      "eval_runtime": 46.714,
      "eval_samples_per_second": 3594.853,
      "eval_steps_per_second": 449.373,
      "step": 891000
    },
    {
      "epoch": 9.432995802478285,
      "grad_norm": 4.469638347625732,
      "learning_rate": 2.8554943891594327e-06,
      "loss": 0.6222,
      "step": 891050
    },
    {
      "epoch": 9.433525124258288,
      "grad_norm": 4.169651031494141,
      "learning_rate": 2.8528477662502646e-06,
      "loss": 0.6178,
      "step": 891100
    },
    {
      "epoch": 9.43405444603829,
      "grad_norm": 4.079422950744629,
      "learning_rate": 2.850201143341097e-06,
      "loss": 0.6224,
      "step": 891150
    },
    {
      "epoch": 9.434583767818294,
      "grad_norm": 4.563027858734131,
      "learning_rate": 2.847554520431929e-06,
      "loss": 0.6167,
      "step": 891200
    },
    {
      "epoch": 9.435113089598298,
      "grad_norm": 4.820206642150879,
      "learning_rate": 2.844907897522761e-06,
      "loss": 0.6233,
      "step": 891250
    },
    {
      "epoch": 9.435642411378302,
      "grad_norm": 4.7454962730407715,
      "learning_rate": 2.842261274613593e-06,
      "loss": 0.6159,
      "step": 891300
    },
    {
      "epoch": 9.436171733158304,
      "grad_norm": 4.464008808135986,
      "learning_rate": 2.8396146517044254e-06,
      "loss": 0.6185,
      "step": 891350
    },
    {
      "epoch": 9.436701054938307,
      "grad_norm": 5.332880973815918,
      "learning_rate": 2.8369680287952574e-06,
      "loss": 0.6182,
      "step": 891400
    },
    {
      "epoch": 9.437230376718311,
      "grad_norm": 4.68768310546875,
      "learning_rate": 2.8343214058860894e-06,
      "loss": 0.6144,
      "step": 891450
    },
    {
      "epoch": 9.437759698498315,
      "grad_norm": 4.77784538269043,
      "learning_rate": 2.8316747829769218e-06,
      "loss": 0.6224,
      "step": 891500
    },
    {
      "epoch": 9.437759698498315,
      "eval_loss": 0.3768787086009979,
      "eval_runtime": 46.7113,
      "eval_samples_per_second": 3595.064,
      "eval_steps_per_second": 449.399,
      "step": 891500
    },
    {
      "epoch": 9.438289020278317,
      "grad_norm": 4.425477981567383,
      "learning_rate": 2.8290281600677538e-06,
      "loss": 0.6318,
      "step": 891550
    },
    {
      "epoch": 9.43881834205832,
      "grad_norm": 5.00436544418335,
      "learning_rate": 2.8263815371585857e-06,
      "loss": 0.6213,
      "step": 891600
    },
    {
      "epoch": 9.439347663838324,
      "grad_norm": 4.685870170593262,
      "learning_rate": 2.823734914249418e-06,
      "loss": 0.6293,
      "step": 891650
    },
    {
      "epoch": 9.439876985618326,
      "grad_norm": 4.456097602844238,
      "learning_rate": 2.82108829134025e-06,
      "loss": 0.615,
      "step": 891700
    },
    {
      "epoch": 9.44040630739833,
      "grad_norm": 4.6795220375061035,
      "learning_rate": 2.818441668431082e-06,
      "loss": 0.6076,
      "step": 891750
    },
    {
      "epoch": 9.440935629178334,
      "grad_norm": 4.564249515533447,
      "learning_rate": 2.815795045521914e-06,
      "loss": 0.6233,
      "step": 891800
    },
    {
      "epoch": 9.441464950958338,
      "grad_norm": 4.673129558563232,
      "learning_rate": 2.8131484226127465e-06,
      "loss": 0.6238,
      "step": 891850
    },
    {
      "epoch": 9.44199427273834,
      "grad_norm": 4.420511245727539,
      "learning_rate": 2.8105017997035785e-06,
      "loss": 0.6327,
      "step": 891900
    },
    {
      "epoch": 9.442523594518343,
      "grad_norm": 4.01786470413208,
      "learning_rate": 2.8078551767944105e-06,
      "loss": 0.6282,
      "step": 891950
    },
    {
      "epoch": 9.443052916298347,
      "grad_norm": 4.594005584716797,
      "learning_rate": 2.805208553885243e-06,
      "loss": 0.6155,
      "step": 892000
    },
    {
      "epoch": 9.443052916298347,
      "eval_loss": 0.3765774667263031,
      "eval_runtime": 46.6557,
      "eval_samples_per_second": 3599.343,
      "eval_steps_per_second": 449.934,
      "step": 892000
    },
    {
      "epoch": 9.443582238078351,
      "grad_norm": 4.564127445220947,
      "learning_rate": 2.802561930976075e-06,
      "loss": 0.6124,
      "step": 892050
    },
    {
      "epoch": 9.444111559858353,
      "grad_norm": 4.813260555267334,
      "learning_rate": 2.799915308066907e-06,
      "loss": 0.6184,
      "step": 892100
    },
    {
      "epoch": 9.444640881638357,
      "grad_norm": 4.2972636222839355,
      "learning_rate": 2.797268685157739e-06,
      "loss": 0.6166,
      "step": 892150
    },
    {
      "epoch": 9.44517020341836,
      "grad_norm": 4.044161319732666,
      "learning_rate": 2.7946220622485712e-06,
      "loss": 0.6287,
      "step": 892200
    },
    {
      "epoch": 9.445699525198364,
      "grad_norm": 4.733349800109863,
      "learning_rate": 2.791975439339403e-06,
      "loss": 0.6246,
      "step": 892250
    },
    {
      "epoch": 9.446228846978366,
      "grad_norm": 4.706993579864502,
      "learning_rate": 2.789328816430235e-06,
      "loss": 0.6277,
      "step": 892300
    },
    {
      "epoch": 9.44675816875837,
      "grad_norm": 5.132752895355225,
      "learning_rate": 2.7866821935210676e-06,
      "loss": 0.6222,
      "step": 892350
    },
    {
      "epoch": 9.447287490538374,
      "grad_norm": 4.889102458953857,
      "learning_rate": 2.7840355706118996e-06,
      "loss": 0.6078,
      "step": 892400
    },
    {
      "epoch": 9.447816812318376,
      "grad_norm": 4.648057460784912,
      "learning_rate": 2.7813889477027316e-06,
      "loss": 0.6181,
      "step": 892450
    },
    {
      "epoch": 9.44834613409838,
      "grad_norm": 4.658792972564697,
      "learning_rate": 2.7787423247935635e-06,
      "loss": 0.6427,
      "step": 892500
    },
    {
      "epoch": 9.44834613409838,
      "eval_loss": 0.3768157362937927,
      "eval_runtime": 46.7221,
      "eval_samples_per_second": 3594.231,
      "eval_steps_per_second": 449.295,
      "step": 892500
    },
    {
      "epoch": 9.448875455878383,
      "grad_norm": 4.505384922027588,
      "learning_rate": 2.7760957018843955e-06,
      "loss": 0.6273,
      "step": 892550
    },
    {
      "epoch": 9.449404777658387,
      "grad_norm": 4.178704261779785,
      "learning_rate": 2.7734490789752275e-06,
      "loss": 0.6193,
      "step": 892600
    },
    {
      "epoch": 9.449934099438389,
      "grad_norm": 4.716533184051514,
      "learning_rate": 2.7708024560660595e-06,
      "loss": 0.6266,
      "step": 892650
    },
    {
      "epoch": 9.450463421218393,
      "grad_norm": 4.7537641525268555,
      "learning_rate": 2.768155833156892e-06,
      "loss": 0.6202,
      "step": 892700
    },
    {
      "epoch": 9.450992742998396,
      "grad_norm": 4.713696479797363,
      "learning_rate": 2.765509210247724e-06,
      "loss": 0.6199,
      "step": 892750
    },
    {
      "epoch": 9.4515220647784,
      "grad_norm": 4.384887218475342,
      "learning_rate": 2.762862587338556e-06,
      "loss": 0.6175,
      "step": 892800
    },
    {
      "epoch": 9.452051386558402,
      "grad_norm": 4.276158809661865,
      "learning_rate": 2.7602159644293883e-06,
      "loss": 0.613,
      "step": 892850
    },
    {
      "epoch": 9.452580708338406,
      "grad_norm": 4.603010654449463,
      "learning_rate": 2.7575693415202202e-06,
      "loss": 0.623,
      "step": 892900
    },
    {
      "epoch": 9.45311003011841,
      "grad_norm": 4.837351322174072,
      "learning_rate": 2.7549227186110522e-06,
      "loss": 0.6259,
      "step": 892950
    },
    {
      "epoch": 9.453639351898413,
      "grad_norm": 4.9122233390808105,
      "learning_rate": 2.7522760957018846e-06,
      "loss": 0.6214,
      "step": 893000
    },
    {
      "epoch": 9.453639351898413,
      "eval_loss": 0.3766813576221466,
      "eval_runtime": 46.6852,
      "eval_samples_per_second": 3597.068,
      "eval_steps_per_second": 449.65,
      "step": 893000
    },
    {
      "epoch": 9.454168673678415,
      "grad_norm": 5.115238189697266,
      "learning_rate": 2.7496294727927166e-06,
      "loss": 0.6142,
      "step": 893050
    },
    {
      "epoch": 9.45469799545842,
      "grad_norm": 4.705517768859863,
      "learning_rate": 2.7469828498835486e-06,
      "loss": 0.6222,
      "step": 893100
    },
    {
      "epoch": 9.455227317238423,
      "grad_norm": 4.783830165863037,
      "learning_rate": 2.7443362269743806e-06,
      "loss": 0.618,
      "step": 893150
    },
    {
      "epoch": 9.455756639018425,
      "grad_norm": 4.153295993804932,
      "learning_rate": 2.741689604065213e-06,
      "loss": 0.6199,
      "step": 893200
    },
    {
      "epoch": 9.456285960798429,
      "grad_norm": 4.318950176239014,
      "learning_rate": 2.739042981156045e-06,
      "loss": 0.6131,
      "step": 893250
    },
    {
      "epoch": 9.456815282578432,
      "grad_norm": 4.941910743713379,
      "learning_rate": 2.736396358246877e-06,
      "loss": 0.6217,
      "step": 893300
    },
    {
      "epoch": 9.457344604358436,
      "grad_norm": 4.6315717697143555,
      "learning_rate": 2.7337497353377094e-06,
      "loss": 0.6274,
      "step": 893350
    },
    {
      "epoch": 9.457873926138438,
      "grad_norm": 4.096832275390625,
      "learning_rate": 2.7311031124285413e-06,
      "loss": 0.6271,
      "step": 893400
    },
    {
      "epoch": 9.458403247918442,
      "grad_norm": 4.615584373474121,
      "learning_rate": 2.7284564895193733e-06,
      "loss": 0.611,
      "step": 893450
    },
    {
      "epoch": 9.458932569698446,
      "grad_norm": 4.792201519012451,
      "learning_rate": 2.7258098666102053e-06,
      "loss": 0.6218,
      "step": 893500
    },
    {
      "epoch": 9.458932569698446,
      "eval_loss": 0.37632229924201965,
      "eval_runtime": 46.5198,
      "eval_samples_per_second": 3609.859,
      "eval_steps_per_second": 451.249,
      "step": 893500
    },
    {
      "epoch": 9.45946189147845,
      "grad_norm": 4.514530658721924,
      "learning_rate": 2.7231632437010377e-06,
      "loss": 0.6251,
      "step": 893550
    },
    {
      "epoch": 9.459991213258451,
      "grad_norm": 4.561646461486816,
      "learning_rate": 2.7205166207918697e-06,
      "loss": 0.6183,
      "step": 893600
    },
    {
      "epoch": 9.460520535038455,
      "grad_norm": 4.534130096435547,
      "learning_rate": 2.7178699978827017e-06,
      "loss": 0.6163,
      "step": 893650
    },
    {
      "epoch": 9.461049856818459,
      "grad_norm": 5.028388023376465,
      "learning_rate": 2.715223374973534e-06,
      "loss": 0.6159,
      "step": 893700
    },
    {
      "epoch": 9.461579178598463,
      "grad_norm": 4.870119571685791,
      "learning_rate": 2.712576752064366e-06,
      "loss": 0.6218,
      "step": 893750
    },
    {
      "epoch": 9.462108500378465,
      "grad_norm": 4.7297797203063965,
      "learning_rate": 2.709930129155198e-06,
      "loss": 0.6206,
      "step": 893800
    },
    {
      "epoch": 9.462637822158468,
      "grad_norm": 4.896780490875244,
      "learning_rate": 2.70728350624603e-06,
      "loss": 0.6164,
      "step": 893850
    },
    {
      "epoch": 9.463167143938472,
      "grad_norm": 5.145594120025635,
      "learning_rate": 2.7046368833368624e-06,
      "loss": 0.6179,
      "step": 893900
    },
    {
      "epoch": 9.463696465718474,
      "grad_norm": 4.402995586395264,
      "learning_rate": 2.7019902604276944e-06,
      "loss": 0.6137,
      "step": 893950
    },
    {
      "epoch": 9.464225787498478,
      "grad_norm": 4.6929521560668945,
      "learning_rate": 2.6993436375185264e-06,
      "loss": 0.6245,
      "step": 894000
    },
    {
      "epoch": 9.464225787498478,
      "eval_loss": 0.37630966305732727,
      "eval_runtime": 46.4643,
      "eval_samples_per_second": 3614.17,
      "eval_steps_per_second": 451.787,
      "step": 894000
    },
    {
      "epoch": 9.464755109278482,
      "grad_norm": 5.010106563568115,
      "learning_rate": 2.696697014609359e-06,
      "loss": 0.6311,
      "step": 894050
    },
    {
      "epoch": 9.465284431058485,
      "grad_norm": 4.730873107910156,
      "learning_rate": 2.694050391700191e-06,
      "loss": 0.6139,
      "step": 894100
    },
    {
      "epoch": 9.465813752838487,
      "grad_norm": 4.440767765045166,
      "learning_rate": 2.6914037687910228e-06,
      "loss": 0.6128,
      "step": 894150
    },
    {
      "epoch": 9.466343074618491,
      "grad_norm": 4.393893241882324,
      "learning_rate": 2.6887571458818548e-06,
      "loss": 0.6102,
      "step": 894200
    },
    {
      "epoch": 9.466872396398495,
      "grad_norm": 4.765764236450195,
      "learning_rate": 2.686110522972687e-06,
      "loss": 0.629,
      "step": 894250
    },
    {
      "epoch": 9.467401718178499,
      "grad_norm": 4.462777137756348,
      "learning_rate": 2.683463900063519e-06,
      "loss": 0.6137,
      "step": 894300
    },
    {
      "epoch": 9.4679310399585,
      "grad_norm": 5.133793354034424,
      "learning_rate": 2.680817277154351e-06,
      "loss": 0.6077,
      "step": 894350
    },
    {
      "epoch": 9.468460361738504,
      "grad_norm": 4.500423908233643,
      "learning_rate": 2.6782235867033667e-06,
      "loss": 0.6242,
      "step": 894400
    },
    {
      "epoch": 9.468989683518508,
      "grad_norm": 4.362659454345703,
      "learning_rate": 2.6755769637941987e-06,
      "loss": 0.6145,
      "step": 894450
    },
    {
      "epoch": 9.469519005298512,
      "grad_norm": 4.567424774169922,
      "learning_rate": 2.6729303408850306e-06,
      "loss": 0.6246,
      "step": 894500
    },
    {
      "epoch": 9.469519005298512,
      "eval_loss": 0.3767877221107483,
      "eval_runtime": 46.3919,
      "eval_samples_per_second": 3619.813,
      "eval_steps_per_second": 452.493,
      "step": 894500
    },
    {
      "epoch": 9.470048327078514,
      "grad_norm": 4.327369213104248,
      "learning_rate": 2.670283717975863e-06,
      "loss": 0.6009,
      "step": 894550
    },
    {
      "epoch": 9.470577648858518,
      "grad_norm": 4.979910373687744,
      "learning_rate": 2.667637095066695e-06,
      "loss": 0.6279,
      "step": 894600
    },
    {
      "epoch": 9.471106970638521,
      "grad_norm": 4.769134044647217,
      "learning_rate": 2.664990472157527e-06,
      "loss": 0.6084,
      "step": 894650
    },
    {
      "epoch": 9.471636292418523,
      "grad_norm": 5.115008354187012,
      "learning_rate": 2.6623438492483594e-06,
      "loss": 0.6381,
      "step": 894700
    },
    {
      "epoch": 9.472165614198527,
      "grad_norm": 4.442082405090332,
      "learning_rate": 2.6596972263391914e-06,
      "loss": 0.6258,
      "step": 894750
    },
    {
      "epoch": 9.47269493597853,
      "grad_norm": 5.062517166137695,
      "learning_rate": 2.6570506034300234e-06,
      "loss": 0.6292,
      "step": 894800
    },
    {
      "epoch": 9.473224257758535,
      "grad_norm": 4.466619491577148,
      "learning_rate": 2.654403980520856e-06,
      "loss": 0.6179,
      "step": 894850
    },
    {
      "epoch": 9.473753579538537,
      "grad_norm": 4.5485734939575195,
      "learning_rate": 2.6517573576116878e-06,
      "loss": 0.6225,
      "step": 894900
    },
    {
      "epoch": 9.47428290131854,
      "grad_norm": 4.703993797302246,
      "learning_rate": 2.6491107347025198e-06,
      "loss": 0.6226,
      "step": 894950
    },
    {
      "epoch": 9.474812223098544,
      "grad_norm": 4.588272571563721,
      "learning_rate": 2.6464641117933517e-06,
      "loss": 0.6248,
      "step": 895000
    },
    {
      "epoch": 9.474812223098544,
      "eval_loss": 0.3765847384929657,
      "eval_runtime": 46.4233,
      "eval_samples_per_second": 3617.367,
      "eval_steps_per_second": 452.187,
      "step": 895000
    },
    {
      "epoch": 9.475341544878548,
      "grad_norm": 4.449058532714844,
      "learning_rate": 2.643817488884184e-06,
      "loss": 0.6191,
      "step": 895050
    },
    {
      "epoch": 9.47587086665855,
      "grad_norm": 4.951261043548584,
      "learning_rate": 2.641170865975016e-06,
      "loss": 0.6116,
      "step": 895100
    },
    {
      "epoch": 9.476400188438554,
      "grad_norm": 5.324881076812744,
      "learning_rate": 2.638524243065848e-06,
      "loss": 0.6269,
      "step": 895150
    },
    {
      "epoch": 9.476929510218557,
      "grad_norm": 5.275550842285156,
      "learning_rate": 2.6358776201566805e-06,
      "loss": 0.6223,
      "step": 895200
    },
    {
      "epoch": 9.477458831998561,
      "grad_norm": 4.365057945251465,
      "learning_rate": 2.6332309972475125e-06,
      "loss": 0.6122,
      "step": 895250
    },
    {
      "epoch": 9.477988153778563,
      "grad_norm": 4.68918514251709,
      "learning_rate": 2.6305843743383445e-06,
      "loss": 0.6206,
      "step": 895300
    },
    {
      "epoch": 9.478517475558567,
      "grad_norm": 5.050436973571777,
      "learning_rate": 2.6279377514291765e-06,
      "loss": 0.6157,
      "step": 895350
    },
    {
      "epoch": 9.47904679733857,
      "grad_norm": 4.322159290313721,
      "learning_rate": 2.625291128520009e-06,
      "loss": 0.6065,
      "step": 895400
    },
    {
      "epoch": 9.479576119118573,
      "grad_norm": 4.776274681091309,
      "learning_rate": 2.622644505610841e-06,
      "loss": 0.6117,
      "step": 895450
    },
    {
      "epoch": 9.480105440898576,
      "grad_norm": 4.440507888793945,
      "learning_rate": 2.619997882701673e-06,
      "loss": 0.6235,
      "step": 895500
    },
    {
      "epoch": 9.480105440898576,
      "eval_loss": 0.37617677450180054,
      "eval_runtime": 46.5237,
      "eval_samples_per_second": 3609.558,
      "eval_steps_per_second": 451.211,
      "step": 895500
    },
    {
      "epoch": 9.48063476267858,
      "grad_norm": 4.118553161621094,
      "learning_rate": 2.6173512597925052e-06,
      "loss": 0.6143,
      "step": 895550
    },
    {
      "epoch": 9.481164084458584,
      "grad_norm": 4.603471279144287,
      "learning_rate": 2.6147046368833372e-06,
      "loss": 0.6234,
      "step": 895600
    },
    {
      "epoch": 9.481693406238586,
      "grad_norm": 4.903791427612305,
      "learning_rate": 2.612058013974169e-06,
      "loss": 0.6186,
      "step": 895650
    },
    {
      "epoch": 9.48222272801859,
      "grad_norm": 4.3112993240356445,
      "learning_rate": 2.609411391065001e-06,
      "loss": 0.6229,
      "step": 895700
    },
    {
      "epoch": 9.482752049798593,
      "grad_norm": 4.811161041259766,
      "learning_rate": 2.606764768155833e-06,
      "loss": 0.6249,
      "step": 895750
    },
    {
      "epoch": 9.483281371578597,
      "grad_norm": 4.370132923126221,
      "learning_rate": 2.604118145246665e-06,
      "loss": 0.6239,
      "step": 895800
    },
    {
      "epoch": 9.483810693358599,
      "grad_norm": 4.583066940307617,
      "learning_rate": 2.601471522337497e-06,
      "loss": 0.6341,
      "step": 895850
    },
    {
      "epoch": 9.484340015138603,
      "grad_norm": 4.551215171813965,
      "learning_rate": 2.5988248994283295e-06,
      "loss": 0.626,
      "step": 895900
    },
    {
      "epoch": 9.484869336918607,
      "grad_norm": 5.046912670135498,
      "learning_rate": 2.5961782765191615e-06,
      "loss": 0.624,
      "step": 895950
    },
    {
      "epoch": 9.48539865869861,
      "grad_norm": 4.266983985900879,
      "learning_rate": 2.5935316536099935e-06,
      "loss": 0.6254,
      "step": 896000
    },
    {
      "epoch": 9.48539865869861,
      "eval_loss": 0.3761727809906006,
      "eval_runtime": 46.51,
      "eval_samples_per_second": 3610.621,
      "eval_steps_per_second": 451.344,
      "step": 896000
    },
    {
      "epoch": 9.485927980478612,
      "grad_norm": 4.625373363494873,
      "learning_rate": 2.590885030700826e-06,
      "loss": 0.6245,
      "step": 896050
    },
    {
      "epoch": 9.486457302258616,
      "grad_norm": 4.674438953399658,
      "learning_rate": 2.588238407791658e-06,
      "loss": 0.6195,
      "step": 896100
    },
    {
      "epoch": 9.48698662403862,
      "grad_norm": 4.4606781005859375,
      "learning_rate": 2.58559178488249e-06,
      "loss": 0.6288,
      "step": 896150
    },
    {
      "epoch": 9.487515945818622,
      "grad_norm": 4.4453911781311035,
      "learning_rate": 2.582945161973322e-06,
      "loss": 0.6232,
      "step": 896200
    },
    {
      "epoch": 9.488045267598626,
      "grad_norm": 4.662506580352783,
      "learning_rate": 2.5802985390641543e-06,
      "loss": 0.6153,
      "step": 896250
    },
    {
      "epoch": 9.48857458937863,
      "grad_norm": 4.360939979553223,
      "learning_rate": 2.5776519161549862e-06,
      "loss": 0.6238,
      "step": 896300
    },
    {
      "epoch": 9.489103911158633,
      "grad_norm": 4.754262447357178,
      "learning_rate": 2.5750052932458182e-06,
      "loss": 0.6139,
      "step": 896350
    },
    {
      "epoch": 9.489633232938635,
      "grad_norm": 4.350132942199707,
      "learning_rate": 2.5724116027948338e-06,
      "loss": 0.6247,
      "step": 896400
    },
    {
      "epoch": 9.490162554718639,
      "grad_norm": 4.84759521484375,
      "learning_rate": 2.5697649798856658e-06,
      "loss": 0.6219,
      "step": 896450
    },
    {
      "epoch": 9.490691876498643,
      "grad_norm": 4.8609113693237305,
      "learning_rate": 2.567118356976498e-06,
      "loss": 0.6223,
      "step": 896500
    },
    {
      "epoch": 9.490691876498643,
      "eval_loss": 0.3761989176273346,
      "eval_runtime": 46.466,
      "eval_samples_per_second": 3614.038,
      "eval_steps_per_second": 451.771,
      "step": 896500
    },
    {
      "epoch": 9.491221198278646,
      "grad_norm": 4.987287521362305,
      "learning_rate": 2.56447173406733e-06,
      "loss": 0.6217,
      "step": 896550
    },
    {
      "epoch": 9.491750520058648,
      "grad_norm": 5.038326740264893,
      "learning_rate": 2.561825111158162e-06,
      "loss": 0.6212,
      "step": 896600
    },
    {
      "epoch": 9.492279841838652,
      "grad_norm": 4.791366100311279,
      "learning_rate": 2.559178488248994e-06,
      "loss": 0.6198,
      "step": 896650
    },
    {
      "epoch": 9.492809163618656,
      "grad_norm": 4.968420028686523,
      "learning_rate": 2.5565318653398265e-06,
      "loss": 0.625,
      "step": 896700
    },
    {
      "epoch": 9.49333848539866,
      "grad_norm": 4.485602855682373,
      "learning_rate": 2.5538852424306585e-06,
      "loss": 0.6185,
      "step": 896750
    },
    {
      "epoch": 9.493867807178662,
      "grad_norm": 4.68672513961792,
      "learning_rate": 2.5512386195214905e-06,
      "loss": 0.6332,
      "step": 896800
    },
    {
      "epoch": 9.494397128958665,
      "grad_norm": 4.689244270324707,
      "learning_rate": 2.548591996612323e-06,
      "loss": 0.6228,
      "step": 896850
    },
    {
      "epoch": 9.494926450738669,
      "grad_norm": 4.851221084594727,
      "learning_rate": 2.545945373703155e-06,
      "loss": 0.6219,
      "step": 896900
    },
    {
      "epoch": 9.495455772518671,
      "grad_norm": 4.861340045928955,
      "learning_rate": 2.543298750793987e-06,
      "loss": 0.6079,
      "step": 896950
    },
    {
      "epoch": 9.495985094298675,
      "grad_norm": 4.7999162673950195,
      "learning_rate": 2.540652127884819e-06,
      "loss": 0.6293,
      "step": 897000
    },
    {
      "epoch": 9.495985094298675,
      "eval_loss": 0.37639856338500977,
      "eval_runtime": 46.4307,
      "eval_samples_per_second": 3616.788,
      "eval_steps_per_second": 452.115,
      "step": 897000
    },
    {
      "epoch": 9.496514416078679,
      "grad_norm": 4.697669982910156,
      "learning_rate": 2.5380055049756512e-06,
      "loss": 0.6235,
      "step": 897050
    },
    {
      "epoch": 9.497043737858682,
      "grad_norm": 4.845280170440674,
      "learning_rate": 2.5353588820664832e-06,
      "loss": 0.6254,
      "step": 897100
    },
    {
      "epoch": 9.497573059638684,
      "grad_norm": 4.986902236938477,
      "learning_rate": 2.532712259157315e-06,
      "loss": 0.6084,
      "step": 897150
    },
    {
      "epoch": 9.498102381418688,
      "grad_norm": 4.708965301513672,
      "learning_rate": 2.5300656362481476e-06,
      "loss": 0.6139,
      "step": 897200
    },
    {
      "epoch": 9.498631703198692,
      "grad_norm": 5.038090229034424,
      "learning_rate": 2.5274190133389796e-06,
      "loss": 0.6146,
      "step": 897250
    },
    {
      "epoch": 9.499161024978696,
      "grad_norm": 4.6814751625061035,
      "learning_rate": 2.5247723904298116e-06,
      "loss": 0.6138,
      "step": 897300
    },
    {
      "epoch": 9.499690346758698,
      "grad_norm": 4.703854560852051,
      "learning_rate": 2.5221257675206436e-06,
      "loss": 0.6338,
      "step": 897350
    },
    {
      "epoch": 9.500219668538701,
      "grad_norm": 4.904579162597656,
      "learning_rate": 2.519479144611476e-06,
      "loss": 0.6204,
      "step": 897400
    },
    {
      "epoch": 9.500748990318705,
      "grad_norm": 4.97072172164917,
      "learning_rate": 2.516832521702308e-06,
      "loss": 0.6134,
      "step": 897450
    },
    {
      "epoch": 9.501278312098709,
      "grad_norm": 4.476672172546387,
      "learning_rate": 2.51418589879314e-06,
      "loss": 0.6288,
      "step": 897500
    },
    {
      "epoch": 9.501278312098709,
      "eval_loss": 0.3760365843772888,
      "eval_runtime": 46.4755,
      "eval_samples_per_second": 3613.301,
      "eval_steps_per_second": 451.679,
      "step": 897500
    },
    {
      "epoch": 9.50180763387871,
      "grad_norm": 4.4562296867370605,
      "learning_rate": 2.5115392758839723e-06,
      "loss": 0.6235,
      "step": 897550
    },
    {
      "epoch": 9.502336955658715,
      "grad_norm": 4.663581848144531,
      "learning_rate": 2.5088926529748043e-06,
      "loss": 0.6214,
      "step": 897600
    },
    {
      "epoch": 9.502866277438718,
      "grad_norm": 5.261765003204346,
      "learning_rate": 2.5062460300656363e-06,
      "loss": 0.6138,
      "step": 897650
    },
    {
      "epoch": 9.50339559921872,
      "grad_norm": 4.569919586181641,
      "learning_rate": 2.5035994071564683e-06,
      "loss": 0.6306,
      "step": 897700
    },
    {
      "epoch": 9.503924920998724,
      "grad_norm": 4.7746806144714355,
      "learning_rate": 2.5009527842473007e-06,
      "loss": 0.6296,
      "step": 897750
    },
    {
      "epoch": 9.504454242778728,
      "grad_norm": 4.423844337463379,
      "learning_rate": 2.4983061613381327e-06,
      "loss": 0.6163,
      "step": 897800
    },
    {
      "epoch": 9.504983564558732,
      "grad_norm": 4.721635341644287,
      "learning_rate": 2.4956595384289647e-06,
      "loss": 0.6074,
      "step": 897850
    },
    {
      "epoch": 9.505512886338733,
      "grad_norm": 4.94513463973999,
      "learning_rate": 2.493012915519797e-06,
      "loss": 0.62,
      "step": 897900
    },
    {
      "epoch": 9.506042208118737,
      "grad_norm": 4.33073616027832,
      "learning_rate": 2.490366292610629e-06,
      "loss": 0.6144,
      "step": 897950
    },
    {
      "epoch": 9.506571529898741,
      "grad_norm": 5.015573024749756,
      "learning_rate": 2.487719669701461e-06,
      "loss": 0.627,
      "step": 898000
    },
    {
      "epoch": 9.506571529898741,
      "eval_loss": 0.3761424720287323,
      "eval_runtime": 46.4907,
      "eval_samples_per_second": 3612.119,
      "eval_steps_per_second": 451.531,
      "step": 898000
    },
    {
      "epoch": 9.507100851678745,
      "grad_norm": 4.298144340515137,
      "learning_rate": 2.485073046792293e-06,
      "loss": 0.6263,
      "step": 898050
    },
    {
      "epoch": 9.507630173458747,
      "grad_norm": 4.675117492675781,
      "learning_rate": 2.4824264238831254e-06,
      "loss": 0.6198,
      "step": 898100
    },
    {
      "epoch": 9.50815949523875,
      "grad_norm": 4.647241592407227,
      "learning_rate": 2.4797798009739574e-06,
      "loss": 0.6234,
      "step": 898150
    },
    {
      "epoch": 9.508688817018754,
      "grad_norm": 4.643552303314209,
      "learning_rate": 2.4771331780647894e-06,
      "loss": 0.6246,
      "step": 898200
    },
    {
      "epoch": 9.509218138798758,
      "grad_norm": 4.251007080078125,
      "learning_rate": 2.4744865551556218e-06,
      "loss": 0.6208,
      "step": 898250
    },
    {
      "epoch": 9.50974746057876,
      "grad_norm": 4.878931522369385,
      "learning_rate": 2.4718399322464538e-06,
      "loss": 0.6279,
      "step": 898300
    },
    {
      "epoch": 9.510276782358764,
      "grad_norm": 4.416770935058594,
      "learning_rate": 2.4691933093372857e-06,
      "loss": 0.6271,
      "step": 898350
    },
    {
      "epoch": 9.510806104138767,
      "grad_norm": 4.212691783905029,
      "learning_rate": 2.4665996188863013e-06,
      "loss": 0.6198,
      "step": 898400
    },
    {
      "epoch": 9.51133542591877,
      "grad_norm": 4.518651008605957,
      "learning_rate": 2.4639529959771333e-06,
      "loss": 0.6189,
      "step": 898450
    },
    {
      "epoch": 9.511864747698773,
      "grad_norm": 4.489753246307373,
      "learning_rate": 2.4613063730679653e-06,
      "loss": 0.6169,
      "step": 898500
    },
    {
      "epoch": 9.511864747698773,
      "eval_loss": 0.37604832649230957,
      "eval_runtime": 46.4259,
      "eval_samples_per_second": 3617.165,
      "eval_steps_per_second": 452.162,
      "step": 898500
    },
    {
      "epoch": 9.512394069478777,
      "grad_norm": 4.9523162841796875,
      "learning_rate": 2.4586597501587977e-06,
      "loss": 0.6228,
      "step": 898550
    },
    {
      "epoch": 9.51292339125878,
      "grad_norm": 4.893167018890381,
      "learning_rate": 2.4560131272496297e-06,
      "loss": 0.6263,
      "step": 898600
    },
    {
      "epoch": 9.513452713038783,
      "grad_norm": 5.17065954208374,
      "learning_rate": 2.4533665043404616e-06,
      "loss": 0.6185,
      "step": 898650
    },
    {
      "epoch": 9.513982034818786,
      "grad_norm": 4.763646602630615,
      "learning_rate": 2.450719881431294e-06,
      "loss": 0.6214,
      "step": 898700
    },
    {
      "epoch": 9.51451135659879,
      "grad_norm": 4.269328594207764,
      "learning_rate": 2.448073258522126e-06,
      "loss": 0.6191,
      "step": 898750
    },
    {
      "epoch": 9.515040678378794,
      "grad_norm": 4.998796463012695,
      "learning_rate": 2.445426635612958e-06,
      "loss": 0.6194,
      "step": 898800
    },
    {
      "epoch": 9.515570000158796,
      "grad_norm": 4.762948989868164,
      "learning_rate": 2.44278001270379e-06,
      "loss": 0.6141,
      "step": 898850
    },
    {
      "epoch": 9.5160993219388,
      "grad_norm": 5.030580997467041,
      "learning_rate": 2.4401333897946224e-06,
      "loss": 0.6177,
      "step": 898900
    },
    {
      "epoch": 9.516628643718803,
      "grad_norm": 4.6161580085754395,
      "learning_rate": 2.4374867668854544e-06,
      "loss": 0.6277,
      "step": 898950
    },
    {
      "epoch": 9.517157965498807,
      "grad_norm": 4.794557094573975,
      "learning_rate": 2.4348401439762864e-06,
      "loss": 0.6332,
      "step": 899000
    },
    {
      "epoch": 9.517157965498807,
      "eval_loss": 0.37606003880500793,
      "eval_runtime": 46.4048,
      "eval_samples_per_second": 3618.806,
      "eval_steps_per_second": 452.367,
      "step": 899000
    },
    {
      "epoch": 9.51768728727881,
      "grad_norm": 4.839211463928223,
      "learning_rate": 2.4321935210671188e-06,
      "loss": 0.6289,
      "step": 899050
    },
    {
      "epoch": 9.518216609058813,
      "grad_norm": 4.38277530670166,
      "learning_rate": 2.4295468981579508e-06,
      "loss": 0.614,
      "step": 899100
    },
    {
      "epoch": 9.518745930838817,
      "grad_norm": 4.770789623260498,
      "learning_rate": 2.4269002752487827e-06,
      "loss": 0.6178,
      "step": 899150
    },
    {
      "epoch": 9.519275252618819,
      "grad_norm": 4.534575462341309,
      "learning_rate": 2.4242536523396147e-06,
      "loss": 0.6159,
      "step": 899200
    },
    {
      "epoch": 9.519804574398822,
      "grad_norm": 4.444132328033447,
      "learning_rate": 2.421607029430447e-06,
      "loss": 0.6264,
      "step": 899250
    },
    {
      "epoch": 9.520333896178826,
      "grad_norm": 4.652275562286377,
      "learning_rate": 2.418960406521279e-06,
      "loss": 0.6285,
      "step": 899300
    },
    {
      "epoch": 9.52086321795883,
      "grad_norm": 4.732446193695068,
      "learning_rate": 2.416313783612111e-06,
      "loss": 0.6252,
      "step": 899350
    },
    {
      "epoch": 9.521392539738832,
      "grad_norm": 4.588380336761475,
      "learning_rate": 2.4136671607029435e-06,
      "loss": 0.6256,
      "step": 899400
    },
    {
      "epoch": 9.521921861518836,
      "grad_norm": 5.016172885894775,
      "learning_rate": 2.4110205377937755e-06,
      "loss": 0.6176,
      "step": 899450
    },
    {
      "epoch": 9.52245118329884,
      "grad_norm": 4.287642002105713,
      "learning_rate": 2.408373914884607e-06,
      "loss": 0.5951,
      "step": 899500
    },
    {
      "epoch": 9.52245118329884,
      "eval_loss": 0.375956267118454,
      "eval_runtime": 46.4747,
      "eval_samples_per_second": 3613.362,
      "eval_steps_per_second": 451.686,
      "step": 899500
    },
    {
      "epoch": 9.522980505078843,
      "grad_norm": 4.869844913482666,
      "learning_rate": 2.4057272919754394e-06,
      "loss": 0.629,
      "step": 899550
    },
    {
      "epoch": 9.523509826858845,
      "grad_norm": 4.707749366760254,
      "learning_rate": 2.4030806690662714e-06,
      "loss": 0.6127,
      "step": 899600
    },
    {
      "epoch": 9.524039148638849,
      "grad_norm": 4.606472015380859,
      "learning_rate": 2.4004340461571034e-06,
      "loss": 0.6169,
      "step": 899650
    },
    {
      "epoch": 9.524568470418853,
      "grad_norm": 4.4934892654418945,
      "learning_rate": 2.397787423247936e-06,
      "loss": 0.6241,
      "step": 899700
    },
    {
      "epoch": 9.525097792198856,
      "grad_norm": 4.190939903259277,
      "learning_rate": 2.395140800338768e-06,
      "loss": 0.6297,
      "step": 899750
    },
    {
      "epoch": 9.525627113978858,
      "grad_norm": 4.537383079528809,
      "learning_rate": 2.3924941774295998e-06,
      "loss": 0.6163,
      "step": 899800
    },
    {
      "epoch": 9.526156435758862,
      "grad_norm": 4.79330587387085,
      "learning_rate": 2.3898475545204318e-06,
      "loss": 0.6181,
      "step": 899850
    },
    {
      "epoch": 9.526685757538866,
      "grad_norm": 4.671152591705322,
      "learning_rate": 2.387200931611264e-06,
      "loss": 0.629,
      "step": 899900
    },
    {
      "epoch": 9.527215079318868,
      "grad_norm": 4.273743152618408,
      "learning_rate": 2.384554308702096e-06,
      "loss": 0.6165,
      "step": 899950
    },
    {
      "epoch": 9.527744401098872,
      "grad_norm": 4.678938388824463,
      "learning_rate": 2.381907685792928e-06,
      "loss": 0.6242,
      "step": 900000
    },
    {
      "epoch": 9.527744401098872,
      "eval_loss": 0.37607425451278687,
      "eval_runtime": 46.421,
      "eval_samples_per_second": 3617.548,
      "eval_steps_per_second": 452.21,
      "step": 900000
    },
    {
      "epoch": 9.528273722878875,
      "grad_norm": 4.3499040603637695,
      "learning_rate": 2.3792610628837605e-06,
      "loss": 0.6313,
      "step": 900050
    },
    {
      "epoch": 9.52880304465888,
      "grad_norm": 4.841809272766113,
      "learning_rate": 2.3766144399745925e-06,
      "loss": 0.6375,
      "step": 900100
    },
    {
      "epoch": 9.529332366438881,
      "grad_norm": 4.604355812072754,
      "learning_rate": 2.3739678170654245e-06,
      "loss": 0.6139,
      "step": 900150
    },
    {
      "epoch": 9.529861688218885,
      "grad_norm": 4.562147617340088,
      "learning_rate": 2.3713211941562565e-06,
      "loss": 0.6164,
      "step": 900200
    },
    {
      "epoch": 9.530391009998889,
      "grad_norm": 4.895631790161133,
      "learning_rate": 2.368674571247089e-06,
      "loss": 0.6139,
      "step": 900250
    },
    {
      "epoch": 9.530920331778892,
      "grad_norm": 4.586895942687988,
      "learning_rate": 2.366027948337921e-06,
      "loss": 0.6285,
      "step": 900300
    },
    {
      "epoch": 9.531449653558894,
      "grad_norm": 4.8528218269348145,
      "learning_rate": 2.363381325428753e-06,
      "loss": 0.6231,
      "step": 900350
    },
    {
      "epoch": 9.531978975338898,
      "grad_norm": 4.695283889770508,
      "learning_rate": 2.3607876349777684e-06,
      "loss": 0.6178,
      "step": 900400
    },
    {
      "epoch": 9.532508297118902,
      "grad_norm": 4.859739780426025,
      "learning_rate": 2.3581410120686004e-06,
      "loss": 0.6211,
      "step": 900450
    },
    {
      "epoch": 9.533037618898906,
      "grad_norm": 5.229638576507568,
      "learning_rate": 2.3554943891594324e-06,
      "loss": 0.6321,
      "step": 900500
    },
    {
      "epoch": 9.533037618898906,
      "eval_loss": 0.37610870599746704,
      "eval_runtime": 46.4265,
      "eval_samples_per_second": 3617.114,
      "eval_steps_per_second": 452.155,
      "step": 900500
    },
    {
      "epoch": 9.533566940678908,
      "grad_norm": 4.498528480529785,
      "learning_rate": 2.3528477662502648e-06,
      "loss": 0.6104,
      "step": 900550
    },
    {
      "epoch": 9.534096262458911,
      "grad_norm": 4.6833815574646,
      "learning_rate": 2.3502011433410968e-06,
      "loss": 0.621,
      "step": 900600
    },
    {
      "epoch": 9.534625584238915,
      "grad_norm": 4.571200847625732,
      "learning_rate": 2.3475545204319287e-06,
      "loss": 0.6291,
      "step": 900650
    },
    {
      "epoch": 9.535154906018917,
      "grad_norm": 3.8742542266845703,
      "learning_rate": 2.344907897522761e-06,
      "loss": 0.6084,
      "step": 900700
    },
    {
      "epoch": 9.53568422779892,
      "grad_norm": 4.241318702697754,
      "learning_rate": 2.342261274613593e-06,
      "loss": 0.6168,
      "step": 900750
    },
    {
      "epoch": 9.536213549578925,
      "grad_norm": 4.749767303466797,
      "learning_rate": 2.339614651704425e-06,
      "loss": 0.6283,
      "step": 900800
    },
    {
      "epoch": 9.536742871358928,
      "grad_norm": 4.498726844787598,
      "learning_rate": 2.336968028795257e-06,
      "loss": 0.6192,
      "step": 900850
    },
    {
      "epoch": 9.53727219313893,
      "grad_norm": 4.674312591552734,
      "learning_rate": 2.3343214058860895e-06,
      "loss": 0.6199,
      "step": 900900
    },
    {
      "epoch": 9.537801514918934,
      "grad_norm": 4.582030296325684,
      "learning_rate": 2.3316747829769215e-06,
      "loss": 0.6159,
      "step": 900950
    },
    {
      "epoch": 9.538330836698938,
      "grad_norm": 4.200220108032227,
      "learning_rate": 2.3290281600677535e-06,
      "loss": 0.6055,
      "step": 901000
    },
    {
      "epoch": 9.538330836698938,
      "eval_loss": 0.37574800848960876,
      "eval_runtime": 46.4227,
      "eval_samples_per_second": 3617.411,
      "eval_steps_per_second": 452.192,
      "step": 901000
    },
    {
      "epoch": 9.538860158478942,
      "grad_norm": 5.386075019836426,
      "learning_rate": 2.326381537158586e-06,
      "loss": 0.6144,
      "step": 901050
    },
    {
      "epoch": 9.539389480258944,
      "grad_norm": 5.375055313110352,
      "learning_rate": 2.323734914249418e-06,
      "loss": 0.6258,
      "step": 901100
    },
    {
      "epoch": 9.539918802038947,
      "grad_norm": 4.899899005889893,
      "learning_rate": 2.32108829134025e-06,
      "loss": 0.6217,
      "step": 901150
    },
    {
      "epoch": 9.540448123818951,
      "grad_norm": 4.369251728057861,
      "learning_rate": 2.318441668431082e-06,
      "loss": 0.624,
      "step": 901200
    },
    {
      "epoch": 9.540977445598955,
      "grad_norm": 4.572061538696289,
      "learning_rate": 2.3157950455219142e-06,
      "loss": 0.618,
      "step": 901250
    },
    {
      "epoch": 9.541506767378957,
      "grad_norm": 4.732234477996826,
      "learning_rate": 2.313148422612746e-06,
      "loss": 0.626,
      "step": 901300
    },
    {
      "epoch": 9.54203608915896,
      "grad_norm": 4.941795349121094,
      "learning_rate": 2.310501799703578e-06,
      "loss": 0.6189,
      "step": 901350
    },
    {
      "epoch": 9.542565410938964,
      "grad_norm": 4.389776706695557,
      "learning_rate": 2.3078551767944106e-06,
      "loss": 0.6226,
      "step": 901400
    },
    {
      "epoch": 9.543094732718966,
      "grad_norm": 5.125667095184326,
      "learning_rate": 2.3052085538852426e-06,
      "loss": 0.6298,
      "step": 901450
    },
    {
      "epoch": 9.54362405449897,
      "grad_norm": 4.700372695922852,
      "learning_rate": 2.3025619309760746e-06,
      "loss": 0.6197,
      "step": 901500
    },
    {
      "epoch": 9.54362405449897,
      "eval_loss": 0.3757873773574829,
      "eval_runtime": 46.676,
      "eval_samples_per_second": 3597.781,
      "eval_steps_per_second": 449.739,
      "step": 901500
    },
    {
      "epoch": 9.544153376278974,
      "grad_norm": 5.048617839813232,
      "learning_rate": 2.299915308066907e-06,
      "loss": 0.6139,
      "step": 901550
    },
    {
      "epoch": 9.544682698058978,
      "grad_norm": 4.333725452423096,
      "learning_rate": 2.297268685157739e-06,
      "loss": 0.6225,
      "step": 901600
    },
    {
      "epoch": 9.54521201983898,
      "grad_norm": 4.887805461883545,
      "learning_rate": 2.294622062248571e-06,
      "loss": 0.6273,
      "step": 901650
    },
    {
      "epoch": 9.545741341618983,
      "grad_norm": 4.947834014892578,
      "learning_rate": 2.291975439339403e-06,
      "loss": 0.6238,
      "step": 901700
    },
    {
      "epoch": 9.546270663398987,
      "grad_norm": 4.580926895141602,
      "learning_rate": 2.2893288164302353e-06,
      "loss": 0.6066,
      "step": 901750
    },
    {
      "epoch": 9.54679998517899,
      "grad_norm": 4.763606548309326,
      "learning_rate": 2.2866821935210673e-06,
      "loss": 0.6136,
      "step": 901800
    },
    {
      "epoch": 9.547329306958993,
      "grad_norm": 4.969951152801514,
      "learning_rate": 2.2840355706118993e-06,
      "loss": 0.6127,
      "step": 901850
    },
    {
      "epoch": 9.547858628738997,
      "grad_norm": 4.416195392608643,
      "learning_rate": 2.2813889477027317e-06,
      "loss": 0.629,
      "step": 901900
    },
    {
      "epoch": 9.548387950519,
      "grad_norm": 4.627413749694824,
      "learning_rate": 2.2787423247935637e-06,
      "loss": 0.6187,
      "step": 901950
    },
    {
      "epoch": 9.548917272299004,
      "grad_norm": 4.475907802581787,
      "learning_rate": 2.2760957018843957e-06,
      "loss": 0.6138,
      "step": 902000
    },
    {
      "epoch": 9.548917272299004,
      "eval_loss": 0.37566009163856506,
      "eval_runtime": 46.5575,
      "eval_samples_per_second": 3606.935,
      "eval_steps_per_second": 450.883,
      "step": 902000
    },
    {
      "epoch": 9.549446594079006,
      "grad_norm": 4.306342124938965,
      "learning_rate": 2.2734490789752276e-06,
      "loss": 0.6096,
      "step": 902050
    },
    {
      "epoch": 9.54997591585901,
      "grad_norm": 4.504432678222656,
      "learning_rate": 2.27080245606606e-06,
      "loss": 0.6264,
      "step": 902100
    },
    {
      "epoch": 9.550505237639014,
      "grad_norm": 4.8859052658081055,
      "learning_rate": 2.268155833156892e-06,
      "loss": 0.6263,
      "step": 902150
    },
    {
      "epoch": 9.551034559419016,
      "grad_norm": 4.523554801940918,
      "learning_rate": 2.265509210247724e-06,
      "loss": 0.6178,
      "step": 902200
    },
    {
      "epoch": 9.55156388119902,
      "grad_norm": 4.8445305824279785,
      "learning_rate": 2.2628625873385564e-06,
      "loss": 0.6164,
      "step": 902250
    },
    {
      "epoch": 9.552093202979023,
      "grad_norm": 4.693392753601074,
      "learning_rate": 2.2602159644293884e-06,
      "loss": 0.6089,
      "step": 902300
    },
    {
      "epoch": 9.552622524759027,
      "grad_norm": 4.43897819519043,
      "learning_rate": 2.2575693415202204e-06,
      "loss": 0.6162,
      "step": 902350
    },
    {
      "epoch": 9.553151846539029,
      "grad_norm": 4.637246608734131,
      "learning_rate": 2.254975651069236e-06,
      "loss": 0.6129,
      "step": 902400
    },
    {
      "epoch": 9.553681168319033,
      "grad_norm": 4.498747825622559,
      "learning_rate": 2.252329028160068e-06,
      "loss": 0.6221,
      "step": 902450
    },
    {
      "epoch": 9.554210490099036,
      "grad_norm": 5.016310691833496,
      "learning_rate": 2.2496824052509e-06,
      "loss": 0.6185,
      "step": 902500
    },
    {
      "epoch": 9.554210490099036,
      "eval_loss": 0.3751736581325531,
      "eval_runtime": 46.635,
      "eval_samples_per_second": 3600.946,
      "eval_steps_per_second": 450.134,
      "step": 902500
    },
    {
      "epoch": 9.55473981187904,
      "grad_norm": 4.621003150939941,
      "learning_rate": 2.2470357823417323e-06,
      "loss": 0.6208,
      "step": 902550
    },
    {
      "epoch": 9.555269133659042,
      "grad_norm": 5.078727722167969,
      "learning_rate": 2.2443891594325643e-06,
      "loss": 0.6258,
      "step": 902600
    },
    {
      "epoch": 9.555798455439046,
      "grad_norm": 4.70772123336792,
      "learning_rate": 2.2417425365233963e-06,
      "loss": 0.6151,
      "step": 902650
    },
    {
      "epoch": 9.55632777721905,
      "grad_norm": 4.3879194259643555,
      "learning_rate": 2.2390959136142282e-06,
      "loss": 0.6235,
      "step": 902700
    },
    {
      "epoch": 9.556857098999053,
      "grad_norm": 4.7770304679870605,
      "learning_rate": 2.2364492907050607e-06,
      "loss": 0.623,
      "step": 902750
    },
    {
      "epoch": 9.557386420779055,
      "grad_norm": 4.747986793518066,
      "learning_rate": 2.2338026677958926e-06,
      "loss": 0.6134,
      "step": 902800
    },
    {
      "epoch": 9.557915742559059,
      "grad_norm": 4.830290794372559,
      "learning_rate": 2.2311560448867246e-06,
      "loss": 0.6143,
      "step": 902850
    },
    {
      "epoch": 9.558445064339063,
      "grad_norm": 4.713762283325195,
      "learning_rate": 2.228509421977557e-06,
      "loss": 0.6275,
      "step": 902900
    },
    {
      "epoch": 9.558974386119065,
      "grad_norm": 4.321844577789307,
      "learning_rate": 2.225862799068389e-06,
      "loss": 0.613,
      "step": 902950
    },
    {
      "epoch": 9.559503707899069,
      "grad_norm": 4.690393447875977,
      "learning_rate": 2.223216176159221e-06,
      "loss": 0.6267,
      "step": 903000
    },
    {
      "epoch": 9.559503707899069,
      "eval_loss": 0.3755345642566681,
      "eval_runtime": 46.5365,
      "eval_samples_per_second": 3608.568,
      "eval_steps_per_second": 451.087,
      "step": 903000
    },
    {
      "epoch": 9.560033029679072,
      "grad_norm": 4.899415969848633,
      "learning_rate": 2.2205695532500534e-06,
      "loss": 0.6183,
      "step": 903050
    },
    {
      "epoch": 9.560562351459076,
      "grad_norm": 4.9447736740112305,
      "learning_rate": 2.2179229303408854e-06,
      "loss": 0.621,
      "step": 903100
    },
    {
      "epoch": 9.561091673239078,
      "grad_norm": 4.288134574890137,
      "learning_rate": 2.2152763074317174e-06,
      "loss": 0.627,
      "step": 903150
    },
    {
      "epoch": 9.561620995019082,
      "grad_norm": 4.575954914093018,
      "learning_rate": 2.2126296845225493e-06,
      "loss": 0.6079,
      "step": 903200
    },
    {
      "epoch": 9.562150316799086,
      "grad_norm": 4.522431373596191,
      "learning_rate": 2.2099830616133817e-06,
      "loss": 0.6293,
      "step": 903250
    },
    {
      "epoch": 9.56267963857909,
      "grad_norm": 4.472792148590088,
      "learning_rate": 2.2073364387042133e-06,
      "loss": 0.6227,
      "step": 903300
    },
    {
      "epoch": 9.563208960359091,
      "grad_norm": 4.459808826446533,
      "learning_rate": 2.2046898157950453e-06,
      "loss": 0.6152,
      "step": 903350
    },
    {
      "epoch": 9.563738282139095,
      "grad_norm": 4.911103248596191,
      "learning_rate": 2.2020431928858777e-06,
      "loss": 0.6232,
      "step": 903400
    },
    {
      "epoch": 9.564267603919099,
      "grad_norm": 4.863519668579102,
      "learning_rate": 2.1993965699767097e-06,
      "loss": 0.6178,
      "step": 903450
    },
    {
      "epoch": 9.564796925699103,
      "grad_norm": 5.18107795715332,
      "learning_rate": 2.1967499470675417e-06,
      "loss": 0.6186,
      "step": 903500
    },
    {
      "epoch": 9.564796925699103,
      "eval_loss": 0.37533631920814514,
      "eval_runtime": 46.4742,
      "eval_samples_per_second": 3613.405,
      "eval_steps_per_second": 451.692,
      "step": 903500
    },
    {
      "epoch": 9.565326247479105,
      "grad_norm": 4.411523342132568,
      "learning_rate": 2.194103324158374e-06,
      "loss": 0.6195,
      "step": 903550
    },
    {
      "epoch": 9.565855569259108,
      "grad_norm": 5.195474624633789,
      "learning_rate": 2.191456701249206e-06,
      "loss": 0.615,
      "step": 903600
    },
    {
      "epoch": 9.566384891039112,
      "grad_norm": 4.731855392456055,
      "learning_rate": 2.188810078340038e-06,
      "loss": 0.6162,
      "step": 903650
    },
    {
      "epoch": 9.566914212819114,
      "grad_norm": 5.046133041381836,
      "learning_rate": 2.18616345543087e-06,
      "loss": 0.631,
      "step": 903700
    },
    {
      "epoch": 9.567443534599118,
      "grad_norm": 4.84761905670166,
      "learning_rate": 2.1835168325217024e-06,
      "loss": 0.6351,
      "step": 903750
    },
    {
      "epoch": 9.567972856379122,
      "grad_norm": 4.523601531982422,
      "learning_rate": 2.1808702096125344e-06,
      "loss": 0.6194,
      "step": 903800
    },
    {
      "epoch": 9.568502178159125,
      "grad_norm": 4.452184200286865,
      "learning_rate": 2.1782235867033664e-06,
      "loss": 0.6233,
      "step": 903850
    },
    {
      "epoch": 9.569031499939127,
      "grad_norm": 4.79280948638916,
      "learning_rate": 2.175576963794199e-06,
      "loss": 0.6206,
      "step": 903900
    },
    {
      "epoch": 9.569560821719131,
      "grad_norm": 4.749186992645264,
      "learning_rate": 2.1729303408850308e-06,
      "loss": 0.6183,
      "step": 903950
    },
    {
      "epoch": 9.570090143499135,
      "grad_norm": 4.290725231170654,
      "learning_rate": 2.1702837179758628e-06,
      "loss": 0.6157,
      "step": 904000
    },
    {
      "epoch": 9.570090143499135,
      "eval_loss": 0.37555360794067383,
      "eval_runtime": 46.6006,
      "eval_samples_per_second": 3603.6,
      "eval_steps_per_second": 450.466,
      "step": 904000
    },
    {
      "epoch": 9.570619465279139,
      "grad_norm": 4.007104873657227,
      "learning_rate": 2.1676370950666947e-06,
      "loss": 0.6156,
      "step": 904050
    },
    {
      "epoch": 9.57114878705914,
      "grad_norm": 4.495169162750244,
      "learning_rate": 2.164990472157527e-06,
      "loss": 0.6258,
      "step": 904100
    },
    {
      "epoch": 9.571678108839144,
      "grad_norm": 4.558547019958496,
      "learning_rate": 2.162343849248359e-06,
      "loss": 0.6221,
      "step": 904150
    },
    {
      "epoch": 9.572207430619148,
      "grad_norm": 4.839430332183838,
      "learning_rate": 2.159697226339191e-06,
      "loss": 0.6123,
      "step": 904200
    },
    {
      "epoch": 9.572736752399152,
      "grad_norm": 4.525267124176025,
      "learning_rate": 2.1570506034300235e-06,
      "loss": 0.62,
      "step": 904250
    },
    {
      "epoch": 9.573266074179154,
      "grad_norm": 4.6239142417907715,
      "learning_rate": 2.1544039805208555e-06,
      "loss": 0.6225,
      "step": 904300
    },
    {
      "epoch": 9.573795395959158,
      "grad_norm": 5.026406764984131,
      "learning_rate": 2.1517573576116875e-06,
      "loss": 0.6187,
      "step": 904350
    },
    {
      "epoch": 9.574324717739161,
      "grad_norm": 4.766109466552734,
      "learning_rate": 2.1491107347025195e-06,
      "loss": 0.6311,
      "step": 904400
    },
    {
      "epoch": 9.574854039519163,
      "grad_norm": 4.520169734954834,
      "learning_rate": 2.146517044251535e-06,
      "loss": 0.6242,
      "step": 904450
    },
    {
      "epoch": 9.575383361299167,
      "grad_norm": 4.410629749298096,
      "learning_rate": 2.143870421342367e-06,
      "loss": 0.6147,
      "step": 904500
    },
    {
      "epoch": 9.575383361299167,
      "eval_loss": 0.37565627694129944,
      "eval_runtime": 46.4776,
      "eval_samples_per_second": 3613.139,
      "eval_steps_per_second": 451.659,
      "step": 904500
    },
    {
      "epoch": 9.57591268307917,
      "grad_norm": 4.545080661773682,
      "learning_rate": 2.1412237984331994e-06,
      "loss": 0.6212,
      "step": 904550
    },
    {
      "epoch": 9.576442004859175,
      "grad_norm": 4.474037170410156,
      "learning_rate": 2.1385771755240314e-06,
      "loss": 0.6344,
      "step": 904600
    },
    {
      "epoch": 9.576971326639176,
      "grad_norm": 4.397855758666992,
      "learning_rate": 2.1359305526148634e-06,
      "loss": 0.623,
      "step": 904650
    },
    {
      "epoch": 9.57750064841918,
      "grad_norm": 4.580642223358154,
      "learning_rate": 2.1332839297056958e-06,
      "loss": 0.6198,
      "step": 904700
    },
    {
      "epoch": 9.578029970199184,
      "grad_norm": 4.804661750793457,
      "learning_rate": 2.1306373067965278e-06,
      "loss": 0.623,
      "step": 904750
    },
    {
      "epoch": 9.578559291979188,
      "grad_norm": 4.578615188598633,
      "learning_rate": 2.1279906838873597e-06,
      "loss": 0.6226,
      "step": 904800
    },
    {
      "epoch": 9.57908861375919,
      "grad_norm": 4.748204231262207,
      "learning_rate": 2.1253440609781917e-06,
      "loss": 0.6122,
      "step": 904850
    },
    {
      "epoch": 9.579617935539193,
      "grad_norm": 5.043004035949707,
      "learning_rate": 2.122697438069024e-06,
      "loss": 0.6349,
      "step": 904900
    },
    {
      "epoch": 9.580147257319197,
      "grad_norm": 4.2370500564575195,
      "learning_rate": 2.120050815159856e-06,
      "loss": 0.621,
      "step": 904950
    },
    {
      "epoch": 9.580676579099201,
      "grad_norm": 4.583988189697266,
      "learning_rate": 2.117404192250688e-06,
      "loss": 0.6072,
      "step": 905000
    },
    {
      "epoch": 9.580676579099201,
      "eval_loss": 0.3753048777580261,
      "eval_runtime": 46.5248,
      "eval_samples_per_second": 3609.473,
      "eval_steps_per_second": 451.2,
      "step": 905000
    },
    {
      "epoch": 9.581205900879203,
      "grad_norm": 4.622602939605713,
      "learning_rate": 2.1147575693415205e-06,
      "loss": 0.6195,
      "step": 905050
    },
    {
      "epoch": 9.581735222659207,
      "grad_norm": 4.955915451049805,
      "learning_rate": 2.1121109464323525e-06,
      "loss": 0.626,
      "step": 905100
    },
    {
      "epoch": 9.58226454443921,
      "grad_norm": 4.5318284034729,
      "learning_rate": 2.1094643235231845e-06,
      "loss": 0.6249,
      "step": 905150
    },
    {
      "epoch": 9.582793866219212,
      "grad_norm": 4.775264739990234,
      "learning_rate": 2.1068177006140164e-06,
      "loss": 0.616,
      "step": 905200
    },
    {
      "epoch": 9.583323187999216,
      "grad_norm": 4.943020820617676,
      "learning_rate": 2.104171077704849e-06,
      "loss": 0.6222,
      "step": 905250
    },
    {
      "epoch": 9.58385250977922,
      "grad_norm": 4.568540096282959,
      "learning_rate": 2.101524454795681e-06,
      "loss": 0.6084,
      "step": 905300
    },
    {
      "epoch": 9.584381831559224,
      "grad_norm": 4.763560771942139,
      "learning_rate": 2.098877831886513e-06,
      "loss": 0.6164,
      "step": 905350
    },
    {
      "epoch": 9.584911153339226,
      "grad_norm": 4.672526836395264,
      "learning_rate": 2.0962312089773452e-06,
      "loss": 0.6199,
      "step": 905400
    },
    {
      "epoch": 9.58544047511923,
      "grad_norm": 4.490742206573486,
      "learning_rate": 2.093584586068177e-06,
      "loss": 0.624,
      "step": 905450
    },
    {
      "epoch": 9.585969796899233,
      "grad_norm": 5.167847156524658,
      "learning_rate": 2.090937963159009e-06,
      "loss": 0.6168,
      "step": 905500
    },
    {
      "epoch": 9.585969796899233,
      "eval_loss": 0.3750185966491699,
      "eval_runtime": 46.5336,
      "eval_samples_per_second": 3608.793,
      "eval_steps_per_second": 451.115,
      "step": 905500
    },
    {
      "epoch": 9.586499118679237,
      "grad_norm": 4.412365436553955,
      "learning_rate": 2.088291340249841e-06,
      "loss": 0.6193,
      "step": 905550
    },
    {
      "epoch": 9.587028440459239,
      "grad_norm": 4.925889015197754,
      "learning_rate": 2.0856447173406736e-06,
      "loss": 0.6097,
      "step": 905600
    },
    {
      "epoch": 9.587557762239243,
      "grad_norm": 4.497527122497559,
      "learning_rate": 2.0829980944315056e-06,
      "loss": 0.6152,
      "step": 905650
    },
    {
      "epoch": 9.588087084019246,
      "grad_norm": 4.044430255889893,
      "learning_rate": 2.0803514715223375e-06,
      "loss": 0.6253,
      "step": 905700
    },
    {
      "epoch": 9.58861640579925,
      "grad_norm": 4.729324817657471,
      "learning_rate": 2.07770484861317e-06,
      "loss": 0.621,
      "step": 905750
    },
    {
      "epoch": 9.589145727579252,
      "grad_norm": 4.839946269989014,
      "learning_rate": 2.075111158162185e-06,
      "loss": 0.6139,
      "step": 905800
    },
    {
      "epoch": 9.589675049359256,
      "grad_norm": 4.264915943145752,
      "learning_rate": 2.072464535253017e-06,
      "loss": 0.6323,
      "step": 905850
    },
    {
      "epoch": 9.59020437113926,
      "grad_norm": 4.6549272537231445,
      "learning_rate": 2.0698179123438495e-06,
      "loss": 0.615,
      "step": 905900
    },
    {
      "epoch": 9.590733692919262,
      "grad_norm": 4.578219890594482,
      "learning_rate": 2.0671712894346814e-06,
      "loss": 0.6184,
      "step": 905950
    },
    {
      "epoch": 9.591263014699265,
      "grad_norm": 4.770789623260498,
      "learning_rate": 2.0645246665255134e-06,
      "loss": 0.6293,
      "step": 906000
    },
    {
      "epoch": 9.591263014699265,
      "eval_loss": 0.3754305839538574,
      "eval_runtime": 46.5059,
      "eval_samples_per_second": 3610.942,
      "eval_steps_per_second": 451.384,
      "step": 906000
    },
    {
      "epoch": 9.59179233647927,
      "grad_norm": 4.775075912475586,
      "learning_rate": 2.061878043616346e-06,
      "loss": 0.629,
      "step": 906050
    },
    {
      "epoch": 9.592321658259273,
      "grad_norm": 4.939990043640137,
      "learning_rate": 2.059231420707178e-06,
      "loss": 0.6143,
      "step": 906100
    },
    {
      "epoch": 9.592850980039275,
      "grad_norm": 4.645346164703369,
      "learning_rate": 2.05658479779801e-06,
      "loss": 0.6155,
      "step": 906150
    },
    {
      "epoch": 9.593380301819279,
      "grad_norm": 4.89937162399292,
      "learning_rate": 2.053938174888842e-06,
      "loss": 0.6179,
      "step": 906200
    },
    {
      "epoch": 9.593909623599282,
      "grad_norm": 4.612124919891357,
      "learning_rate": 2.051291551979674e-06,
      "loss": 0.6185,
      "step": 906250
    },
    {
      "epoch": 9.594438945379286,
      "grad_norm": 4.9533562660217285,
      "learning_rate": 2.048644929070506e-06,
      "loss": 0.6147,
      "step": 906300
    },
    {
      "epoch": 9.594968267159288,
      "grad_norm": 4.753731727600098,
      "learning_rate": 2.045998306161338e-06,
      "loss": 0.6217,
      "step": 906350
    },
    {
      "epoch": 9.595497588939292,
      "grad_norm": 4.584592819213867,
      "learning_rate": 2.0433516832521706e-06,
      "loss": 0.6131,
      "step": 906400
    },
    {
      "epoch": 9.596026910719296,
      "grad_norm": 4.558190822601318,
      "learning_rate": 2.0407050603430025e-06,
      "loss": 0.6205,
      "step": 906450
    },
    {
      "epoch": 9.5965562324993,
      "grad_norm": 4.5050482749938965,
      "learning_rate": 2.0380584374338345e-06,
      "loss": 0.6039,
      "step": 906500
    },
    {
      "epoch": 9.5965562324993,
      "eval_loss": 0.37522274255752563,
      "eval_runtime": 46.468,
      "eval_samples_per_second": 3613.887,
      "eval_steps_per_second": 451.752,
      "step": 906500
    },
    {
      "epoch": 9.597085554279301,
      "grad_norm": 4.976562976837158,
      "learning_rate": 2.035411814524667e-06,
      "loss": 0.6202,
      "step": 906550
    },
    {
      "epoch": 9.597614876059305,
      "grad_norm": 4.2548828125,
      "learning_rate": 2.032765191615499e-06,
      "loss": 0.6095,
      "step": 906600
    },
    {
      "epoch": 9.598144197839309,
      "grad_norm": 4.932370185852051,
      "learning_rate": 2.030118568706331e-06,
      "loss": 0.6234,
      "step": 906650
    },
    {
      "epoch": 9.598673519619311,
      "grad_norm": 3.960219144821167,
      "learning_rate": 2.027471945797163e-06,
      "loss": 0.6213,
      "step": 906700
    },
    {
      "epoch": 9.599202841399315,
      "grad_norm": 4.892669677734375,
      "learning_rate": 2.0248253228879953e-06,
      "loss": 0.6272,
      "step": 906750
    },
    {
      "epoch": 9.599732163179318,
      "grad_norm": 4.797903537750244,
      "learning_rate": 2.0221786999788273e-06,
      "loss": 0.6183,
      "step": 906800
    },
    {
      "epoch": 9.600261484959322,
      "grad_norm": 4.7246928215026855,
      "learning_rate": 2.0195320770696592e-06,
      "loss": 0.6222,
      "step": 906850
    },
    {
      "epoch": 9.600790806739324,
      "grad_norm": 4.632323741912842,
      "learning_rate": 2.0168854541604917e-06,
      "loss": 0.6182,
      "step": 906900
    },
    {
      "epoch": 9.601320128519328,
      "grad_norm": 4.619508266448975,
      "learning_rate": 2.0142388312513236e-06,
      "loss": 0.6055,
      "step": 906950
    },
    {
      "epoch": 9.601849450299332,
      "grad_norm": 4.923076629638672,
      "learning_rate": 2.0115922083421556e-06,
      "loss": 0.6218,
      "step": 907000
    },
    {
      "epoch": 9.601849450299332,
      "eval_loss": 0.3749143183231354,
      "eval_runtime": 46.5264,
      "eval_samples_per_second": 3609.346,
      "eval_steps_per_second": 451.184,
      "step": 907000
    },
    {
      "epoch": 9.602378772079335,
      "grad_norm": 4.828181266784668,
      "learning_rate": 2.0089455854329876e-06,
      "loss": 0.6168,
      "step": 907050
    },
    {
      "epoch": 9.602908093859337,
      "grad_norm": 4.561172008514404,
      "learning_rate": 2.0062989625238196e-06,
      "loss": 0.6201,
      "step": 907100
    },
    {
      "epoch": 9.603437415639341,
      "grad_norm": 4.810248851776123,
      "learning_rate": 2.0036523396146516e-06,
      "loss": 0.6252,
      "step": 907150
    },
    {
      "epoch": 9.603966737419345,
      "grad_norm": 4.891845226287842,
      "learning_rate": 2.0010057167054835e-06,
      "loss": 0.6188,
      "step": 907200
    },
    {
      "epoch": 9.604496059199349,
      "grad_norm": 4.641077518463135,
      "learning_rate": 1.998359093796316e-06,
      "loss": 0.6185,
      "step": 907250
    },
    {
      "epoch": 9.60502538097935,
      "grad_norm": 5.050161361694336,
      "learning_rate": 1.995712470887148e-06,
      "loss": 0.616,
      "step": 907300
    },
    {
      "epoch": 9.605554702759354,
      "grad_norm": 4.847704887390137,
      "learning_rate": 1.99306584797798e-06,
      "loss": 0.6332,
      "step": 907350
    },
    {
      "epoch": 9.606084024539358,
      "grad_norm": 4.183444499969482,
      "learning_rate": 1.9904192250688123e-06,
      "loss": 0.6153,
      "step": 907400
    },
    {
      "epoch": 9.60661334631936,
      "grad_norm": 4.633771896362305,
      "learning_rate": 1.9877726021596443e-06,
      "loss": 0.6117,
      "step": 907450
    },
    {
      "epoch": 9.607142668099364,
      "grad_norm": 4.577464580535889,
      "learning_rate": 1.9851259792504763e-06,
      "loss": 0.6091,
      "step": 907500
    },
    {
      "epoch": 9.607142668099364,
      "eval_loss": 0.3748839199542999,
      "eval_runtime": 46.5044,
      "eval_samples_per_second": 3611.057,
      "eval_steps_per_second": 451.398,
      "step": 907500
    },
    {
      "epoch": 9.607671989879368,
      "grad_norm": 4.936374664306641,
      "learning_rate": 1.9824793563413083e-06,
      "loss": 0.623,
      "step": 907550
    },
    {
      "epoch": 9.608201311659371,
      "grad_norm": 4.734622001647949,
      "learning_rate": 1.9798327334321407e-06,
      "loss": 0.6328,
      "step": 907600
    },
    {
      "epoch": 9.608730633439373,
      "grad_norm": 4.579731464385986,
      "learning_rate": 1.9771861105229727e-06,
      "loss": 0.6228,
      "step": 907650
    },
    {
      "epoch": 9.609259955219377,
      "grad_norm": 4.358263969421387,
      "learning_rate": 1.9745394876138046e-06,
      "loss": 0.6147,
      "step": 907700
    },
    {
      "epoch": 9.609789276999381,
      "grad_norm": 4.161110877990723,
      "learning_rate": 1.971892864704637e-06,
      "loss": 0.6226,
      "step": 907750
    },
    {
      "epoch": 9.610318598779385,
      "grad_norm": 4.845061302185059,
      "learning_rate": 1.969246241795469e-06,
      "loss": 0.6192,
      "step": 907800
    },
    {
      "epoch": 9.610847920559387,
      "grad_norm": 4.774913311004639,
      "learning_rate": 1.966599618886301e-06,
      "loss": 0.617,
      "step": 907850
    },
    {
      "epoch": 9.61137724233939,
      "grad_norm": 4.796130657196045,
      "learning_rate": 1.9639529959771334e-06,
      "loss": 0.6231,
      "step": 907900
    },
    {
      "epoch": 9.611906564119394,
      "grad_norm": 4.4942755699157715,
      "learning_rate": 1.9613063730679654e-06,
      "loss": 0.6219,
      "step": 907950
    },
    {
      "epoch": 9.612435885899398,
      "grad_norm": 4.886841773986816,
      "learning_rate": 1.9586597501587974e-06,
      "loss": 0.6188,
      "step": 908000
    },
    {
      "epoch": 9.612435885899398,
      "eval_loss": 0.3751698434352875,
      "eval_runtime": 46.4505,
      "eval_samples_per_second": 3615.249,
      "eval_steps_per_second": 451.922,
      "step": 908000
    },
    {
      "epoch": 9.6129652076794,
      "grad_norm": 4.570921897888184,
      "learning_rate": 1.9560131272496294e-06,
      "loss": 0.6161,
      "step": 908050
    },
    {
      "epoch": 9.613494529459404,
      "grad_norm": 4.663399696350098,
      "learning_rate": 1.9533665043404618e-06,
      "loss": 0.6274,
      "step": 908100
    },
    {
      "epoch": 9.614023851239407,
      "grad_norm": 4.563159942626953,
      "learning_rate": 1.9507198814312938e-06,
      "loss": 0.6155,
      "step": 908150
    },
    {
      "epoch": 9.61455317301941,
      "grad_norm": 4.906478404998779,
      "learning_rate": 1.9480732585221257e-06,
      "loss": 0.6268,
      "step": 908200
    },
    {
      "epoch": 9.615082494799413,
      "grad_norm": 4.445123672485352,
      "learning_rate": 1.945426635612958e-06,
      "loss": 0.6193,
      "step": 908250
    },
    {
      "epoch": 9.615611816579417,
      "grad_norm": 5.192096710205078,
      "learning_rate": 1.94278001270379e-06,
      "loss": 0.6292,
      "step": 908300
    },
    {
      "epoch": 9.61614113835942,
      "grad_norm": 4.613987445831299,
      "learning_rate": 1.940133389794622e-06,
      "loss": 0.6217,
      "step": 908350
    },
    {
      "epoch": 9.616670460139423,
      "grad_norm": 4.56967830657959,
      "learning_rate": 1.937486766885454e-06,
      "loss": 0.619,
      "step": 908400
    },
    {
      "epoch": 9.617199781919426,
      "grad_norm": 4.599862098693848,
      "learning_rate": 1.9348401439762865e-06,
      "loss": 0.6237,
      "step": 908450
    },
    {
      "epoch": 9.61772910369943,
      "grad_norm": 4.5886311531066895,
      "learning_rate": 1.9321935210671185e-06,
      "loss": 0.6149,
      "step": 908500
    },
    {
      "epoch": 9.61772910369943,
      "eval_loss": 0.37530967593193054,
      "eval_runtime": 46.5006,
      "eval_samples_per_second": 3611.353,
      "eval_steps_per_second": 451.435,
      "step": 908500
    },
    {
      "epoch": 9.618258425479434,
      "grad_norm": 4.831256866455078,
      "learning_rate": 1.9295468981579505e-06,
      "loss": 0.6127,
      "step": 908550
    },
    {
      "epoch": 9.618787747259436,
      "grad_norm": 4.3990397453308105,
      "learning_rate": 1.926900275248783e-06,
      "loss": 0.6341,
      "step": 908600
    },
    {
      "epoch": 9.61931706903944,
      "grad_norm": 4.501909255981445,
      "learning_rate": 1.924253652339615e-06,
      "loss": 0.6105,
      "step": 908650
    },
    {
      "epoch": 9.619846390819443,
      "grad_norm": 4.683574199676514,
      "learning_rate": 1.921607029430447e-06,
      "loss": 0.6103,
      "step": 908700
    },
    {
      "epoch": 9.620375712599447,
      "grad_norm": 4.362100124359131,
      "learning_rate": 1.918960406521279e-06,
      "loss": 0.6295,
      "step": 908750
    },
    {
      "epoch": 9.620905034379449,
      "grad_norm": 4.888190269470215,
      "learning_rate": 1.9163137836121112e-06,
      "loss": 0.6116,
      "step": 908800
    },
    {
      "epoch": 9.621434356159453,
      "grad_norm": 4.500058650970459,
      "learning_rate": 1.913667160702943e-06,
      "loss": 0.6233,
      "step": 908850
    },
    {
      "epoch": 9.621963677939457,
      "grad_norm": 4.343278884887695,
      "learning_rate": 1.911020537793775e-06,
      "loss": 0.6185,
      "step": 908900
    },
    {
      "epoch": 9.622492999719459,
      "grad_norm": 4.7433600425720215,
      "learning_rate": 1.9083739148846076e-06,
      "loss": 0.6302,
      "step": 908950
    },
    {
      "epoch": 9.623022321499462,
      "grad_norm": 4.234030246734619,
      "learning_rate": 1.9057272919754396e-06,
      "loss": 0.6156,
      "step": 909000
    },
    {
      "epoch": 9.623022321499462,
      "eval_loss": 0.37515580654144287,
      "eval_runtime": 46.7022,
      "eval_samples_per_second": 3595.765,
      "eval_steps_per_second": 449.487,
      "step": 909000
    },
    {
      "epoch": 9.623551643279466,
      "grad_norm": 4.208983421325684,
      "learning_rate": 1.9030806690662716e-06,
      "loss": 0.6204,
      "step": 909050
    },
    {
      "epoch": 9.62408096505947,
      "grad_norm": 4.632447719573975,
      "learning_rate": 1.9004340461571037e-06,
      "loss": 0.6119,
      "step": 909100
    },
    {
      "epoch": 9.624610286839472,
      "grad_norm": 5.078561782836914,
      "learning_rate": 1.897787423247936e-06,
      "loss": 0.623,
      "step": 909150
    },
    {
      "epoch": 9.625139608619476,
      "grad_norm": 4.92014741897583,
      "learning_rate": 1.895140800338768e-06,
      "loss": 0.6203,
      "step": 909200
    },
    {
      "epoch": 9.62566893039948,
      "grad_norm": 4.553122520446777,
      "learning_rate": 1.8924941774296001e-06,
      "loss": 0.6313,
      "step": 909250
    },
    {
      "epoch": 9.626198252179483,
      "grad_norm": 4.871755599975586,
      "learning_rate": 1.889847554520432e-06,
      "loss": 0.6264,
      "step": 909300
    },
    {
      "epoch": 9.626727573959485,
      "grad_norm": 4.037442207336426,
      "learning_rate": 1.8872009316112643e-06,
      "loss": 0.6217,
      "step": 909350
    },
    {
      "epoch": 9.627256895739489,
      "grad_norm": 4.462279319763184,
      "learning_rate": 1.8845543087020963e-06,
      "loss": 0.6205,
      "step": 909400
    },
    {
      "epoch": 9.627786217519493,
      "grad_norm": 4.411355495452881,
      "learning_rate": 1.8819076857929285e-06,
      "loss": 0.6231,
      "step": 909450
    },
    {
      "epoch": 9.628315539299496,
      "grad_norm": 4.477369785308838,
      "learning_rate": 1.8792610628837607e-06,
      "loss": 0.6212,
      "step": 909500
    },
    {
      "epoch": 9.628315539299496,
      "eval_loss": 0.3747909665107727,
      "eval_runtime": 46.512,
      "eval_samples_per_second": 3610.47,
      "eval_steps_per_second": 451.325,
      "step": 909500
    },
    {
      "epoch": 9.628844861079498,
      "grad_norm": 4.894913196563721,
      "learning_rate": 1.8766144399745926e-06,
      "loss": 0.6165,
      "step": 909550
    },
    {
      "epoch": 9.629374182859502,
      "grad_norm": 4.580368995666504,
      "learning_rate": 1.8739678170654248e-06,
      "loss": 0.6067,
      "step": 909600
    },
    {
      "epoch": 9.629903504639506,
      "grad_norm": 4.909585475921631,
      "learning_rate": 1.8713211941562566e-06,
      "loss": 0.6269,
      "step": 909650
    },
    {
      "epoch": 9.630432826419508,
      "grad_norm": 4.640444755554199,
      "learning_rate": 1.8686745712470886e-06,
      "loss": 0.6099,
      "step": 909700
    },
    {
      "epoch": 9.630962148199512,
      "grad_norm": 4.938699245452881,
      "learning_rate": 1.8660279483379208e-06,
      "loss": 0.6148,
      "step": 909750
    },
    {
      "epoch": 9.631491469979515,
      "grad_norm": 4.649502277374268,
      "learning_rate": 1.8634342578869366e-06,
      "loss": 0.6125,
      "step": 909800
    },
    {
      "epoch": 9.632020791759519,
      "grad_norm": 5.065188407897949,
      "learning_rate": 1.8607876349777685e-06,
      "loss": 0.6244,
      "step": 909850
    },
    {
      "epoch": 9.632550113539521,
      "grad_norm": 4.317399024963379,
      "learning_rate": 1.8581410120686007e-06,
      "loss": 0.6094,
      "step": 909900
    },
    {
      "epoch": 9.633079435319525,
      "grad_norm": 5.33772611618042,
      "learning_rate": 1.8554943891594327e-06,
      "loss": 0.6211,
      "step": 909950
    },
    {
      "epoch": 9.633608757099529,
      "grad_norm": 4.728066921234131,
      "learning_rate": 1.852847766250265e-06,
      "loss": 0.6131,
      "step": 910000
    },
    {
      "epoch": 9.633608757099529,
      "eval_loss": 0.3745344877243042,
      "eval_runtime": 46.4671,
      "eval_samples_per_second": 3613.958,
      "eval_steps_per_second": 451.761,
      "step": 910000
    },
    {
      "epoch": 9.634138078879532,
      "grad_norm": 4.636904239654541,
      "learning_rate": 1.850201143341097e-06,
      "loss": 0.6232,
      "step": 910050
    },
    {
      "epoch": 9.634667400659534,
      "grad_norm": 4.273693084716797,
      "learning_rate": 1.847554520431929e-06,
      "loss": 0.6217,
      "step": 910100
    },
    {
      "epoch": 9.635196722439538,
      "grad_norm": 5.076930522918701,
      "learning_rate": 1.8449078975227613e-06,
      "loss": 0.6244,
      "step": 910150
    },
    {
      "epoch": 9.635726044219542,
      "grad_norm": 4.259868621826172,
      "learning_rate": 1.8422612746135933e-06,
      "loss": 0.6148,
      "step": 910200
    },
    {
      "epoch": 9.636255365999546,
      "grad_norm": 4.329319000244141,
      "learning_rate": 1.839614651704425e-06,
      "loss": 0.6126,
      "step": 910250
    },
    {
      "epoch": 9.636784687779548,
      "grad_norm": 4.580290794372559,
      "learning_rate": 1.8369680287952572e-06,
      "loss": 0.627,
      "step": 910300
    },
    {
      "epoch": 9.637314009559551,
      "grad_norm": 4.582237720489502,
      "learning_rate": 1.8343214058860892e-06,
      "loss": 0.6276,
      "step": 910350
    },
    {
      "epoch": 9.637843331339555,
      "grad_norm": 4.2645649909973145,
      "learning_rate": 1.8316747829769214e-06,
      "loss": 0.6101,
      "step": 910400
    },
    {
      "epoch": 9.638372653119557,
      "grad_norm": 4.63365364074707,
      "learning_rate": 1.8290281600677536e-06,
      "loss": 0.631,
      "step": 910450
    },
    {
      "epoch": 9.63890197489956,
      "grad_norm": 4.913097858428955,
      "learning_rate": 1.8263815371585856e-06,
      "loss": 0.6251,
      "step": 910500
    },
    {
      "epoch": 9.63890197489956,
      "eval_loss": 0.3751828074455261,
      "eval_runtime": 46.5153,
      "eval_samples_per_second": 3610.211,
      "eval_steps_per_second": 451.292,
      "step": 910500
    },
    {
      "epoch": 9.639431296679565,
      "grad_norm": 4.5379133224487305,
      "learning_rate": 1.8237349142494178e-06,
      "loss": 0.6246,
      "step": 910550
    },
    {
      "epoch": 9.639960618459568,
      "grad_norm": 4.603912830352783,
      "learning_rate": 1.8210882913402498e-06,
      "loss": 0.6194,
      "step": 910600
    },
    {
      "epoch": 9.64048994023957,
      "grad_norm": 4.462057590484619,
      "learning_rate": 1.818441668431082e-06,
      "loss": 0.6266,
      "step": 910650
    },
    {
      "epoch": 9.641019262019574,
      "grad_norm": 4.556429386138916,
      "learning_rate": 1.815795045521914e-06,
      "loss": 0.6289,
      "step": 910700
    },
    {
      "epoch": 9.641548583799578,
      "grad_norm": 4.329026222229004,
      "learning_rate": 1.8131484226127461e-06,
      "loss": 0.6203,
      "step": 910750
    },
    {
      "epoch": 9.642077905579582,
      "grad_norm": 4.9713521003723145,
      "learning_rate": 1.8105017997035783e-06,
      "loss": 0.6258,
      "step": 910800
    },
    {
      "epoch": 9.642607227359584,
      "grad_norm": 4.508240222930908,
      "learning_rate": 1.8078551767944103e-06,
      "loss": 0.6239,
      "step": 910850
    },
    {
      "epoch": 9.643136549139587,
      "grad_norm": 4.04740571975708,
      "learning_rate": 1.8052085538852425e-06,
      "loss": 0.6198,
      "step": 910900
    },
    {
      "epoch": 9.643665870919591,
      "grad_norm": 4.727339744567871,
      "learning_rate": 1.8025619309760745e-06,
      "loss": 0.6192,
      "step": 910950
    },
    {
      "epoch": 9.644195192699595,
      "grad_norm": 5.2043657302856445,
      "learning_rate": 1.7999153080669067e-06,
      "loss": 0.6237,
      "step": 911000
    },
    {
      "epoch": 9.644195192699595,
      "eval_loss": 0.375169575214386,
      "eval_runtime": 46.4939,
      "eval_samples_per_second": 3611.872,
      "eval_steps_per_second": 451.5,
      "step": 911000
    },
    {
      "epoch": 9.644724514479597,
      "grad_norm": 4.556696891784668,
      "learning_rate": 1.7972686851577387e-06,
      "loss": 0.6184,
      "step": 911050
    },
    {
      "epoch": 9.6452538362596,
      "grad_norm": 4.491517543792725,
      "learning_rate": 1.7946220622485708e-06,
      "loss": 0.6305,
      "step": 911100
    },
    {
      "epoch": 9.645783158039604,
      "grad_norm": 4.63611364364624,
      "learning_rate": 1.791975439339403e-06,
      "loss": 0.6251,
      "step": 911150
    },
    {
      "epoch": 9.646312479819606,
      "grad_norm": 4.56655740737915,
      "learning_rate": 1.789328816430235e-06,
      "loss": 0.6104,
      "step": 911200
    },
    {
      "epoch": 9.64684180159961,
      "grad_norm": 4.606018543243408,
      "learning_rate": 1.7866821935210672e-06,
      "loss": 0.6166,
      "step": 911250
    },
    {
      "epoch": 9.647371123379614,
      "grad_norm": 4.267241477966309,
      "learning_rate": 1.7840355706118992e-06,
      "loss": 0.6079,
      "step": 911300
    },
    {
      "epoch": 9.647900445159618,
      "grad_norm": 4.933594703674316,
      "learning_rate": 1.7813889477027314e-06,
      "loss": 0.6134,
      "step": 911350
    },
    {
      "epoch": 9.64842976693962,
      "grad_norm": 5.108495235443115,
      "learning_rate": 1.7787423247935634e-06,
      "loss": 0.6218,
      "step": 911400
    },
    {
      "epoch": 9.648959088719623,
      "grad_norm": 4.443251609802246,
      "learning_rate": 1.7760957018843956e-06,
      "loss": 0.6165,
      "step": 911450
    },
    {
      "epoch": 9.649488410499627,
      "grad_norm": 4.865872383117676,
      "learning_rate": 1.7734490789752278e-06,
      "loss": 0.6043,
      "step": 911500
    },
    {
      "epoch": 9.649488410499627,
      "eval_loss": 0.37490564584732056,
      "eval_runtime": 46.5001,
      "eval_samples_per_second": 3611.387,
      "eval_steps_per_second": 451.44,
      "step": 911500
    },
    {
      "epoch": 9.65001773227963,
      "grad_norm": 4.5245184898376465,
      "learning_rate": 1.7708024560660597e-06,
      "loss": 0.6189,
      "step": 911550
    },
    {
      "epoch": 9.650547054059633,
      "grad_norm": 4.680723667144775,
      "learning_rate": 1.768155833156892e-06,
      "loss": 0.6229,
      "step": 911600
    },
    {
      "epoch": 9.651076375839637,
      "grad_norm": 4.369363307952881,
      "learning_rate": 1.765509210247724e-06,
      "loss": 0.6114,
      "step": 911650
    },
    {
      "epoch": 9.65160569761964,
      "grad_norm": 4.495922088623047,
      "learning_rate": 1.7628625873385561e-06,
      "loss": 0.6137,
      "step": 911700
    },
    {
      "epoch": 9.652135019399644,
      "grad_norm": 4.929510593414307,
      "learning_rate": 1.7602159644293883e-06,
      "loss": 0.617,
      "step": 911750
    },
    {
      "epoch": 9.652664341179646,
      "grad_norm": 4.312166213989258,
      "learning_rate": 1.7576222739784037e-06,
      "loss": 0.6263,
      "step": 911800
    },
    {
      "epoch": 9.65319366295965,
      "grad_norm": 4.9064741134643555,
      "learning_rate": 1.7549756510692356e-06,
      "loss": 0.6228,
      "step": 911850
    },
    {
      "epoch": 9.653722984739654,
      "grad_norm": 4.223030090332031,
      "learning_rate": 1.7523290281600678e-06,
      "loss": 0.6254,
      "step": 911900
    },
    {
      "epoch": 9.654252306519655,
      "grad_norm": 4.6283650398254395,
      "learning_rate": 1.7496824052508998e-06,
      "loss": 0.6159,
      "step": 911950
    },
    {
      "epoch": 9.65478162829966,
      "grad_norm": 4.678290843963623,
      "learning_rate": 1.747035782341732e-06,
      "loss": 0.6152,
      "step": 912000
    },
    {
      "epoch": 9.65478162829966,
      "eval_loss": 0.3749275505542755,
      "eval_runtime": 46.4501,
      "eval_samples_per_second": 3615.281,
      "eval_steps_per_second": 451.926,
      "step": 912000
    },
    {
      "epoch": 9.655310950079663,
      "grad_norm": 4.494685173034668,
      "learning_rate": 1.7443891594325642e-06,
      "loss": 0.6142,
      "step": 912050
    },
    {
      "epoch": 9.655840271859667,
      "grad_norm": 4.7940192222595215,
      "learning_rate": 1.7417425365233962e-06,
      "loss": 0.6259,
      "step": 912100
    },
    {
      "epoch": 9.656369593639669,
      "grad_norm": 4.239931583404541,
      "learning_rate": 1.7390959136142284e-06,
      "loss": 0.622,
      "step": 912150
    },
    {
      "epoch": 9.656898915419672,
      "grad_norm": 4.447599411010742,
      "learning_rate": 1.7364492907050604e-06,
      "loss": 0.6147,
      "step": 912200
    },
    {
      "epoch": 9.657428237199676,
      "grad_norm": 4.477758884429932,
      "learning_rate": 1.7338026677958926e-06,
      "loss": 0.6255,
      "step": 912250
    },
    {
      "epoch": 9.65795755897968,
      "grad_norm": 4.679305553436279,
      "learning_rate": 1.7311560448867247e-06,
      "loss": 0.6122,
      "step": 912300
    },
    {
      "epoch": 9.658486880759682,
      "grad_norm": 4.951542377471924,
      "learning_rate": 1.7285094219775567e-06,
      "loss": 0.6135,
      "step": 912350
    },
    {
      "epoch": 9.659016202539686,
      "grad_norm": 4.481548309326172,
      "learning_rate": 1.725862799068389e-06,
      "loss": 0.6273,
      "step": 912400
    },
    {
      "epoch": 9.65954552431969,
      "grad_norm": 4.821005344390869,
      "learning_rate": 1.723216176159221e-06,
      "loss": 0.616,
      "step": 912450
    },
    {
      "epoch": 9.660074846099693,
      "grad_norm": 4.226292133331299,
      "learning_rate": 1.720569553250053e-06,
      "loss": 0.6255,
      "step": 912500
    },
    {
      "epoch": 9.660074846099693,
      "eval_loss": 0.3746831715106964,
      "eval_runtime": 46.5126,
      "eval_samples_per_second": 3610.421,
      "eval_steps_per_second": 451.319,
      "step": 912500
    },
    {
      "epoch": 9.660604167879695,
      "grad_norm": 4.782142639160156,
      "learning_rate": 1.717922930340885e-06,
      "loss": 0.6223,
      "step": 912550
    },
    {
      "epoch": 9.661133489659699,
      "grad_norm": 4.6020283699035645,
      "learning_rate": 1.7152763074317173e-06,
      "loss": 0.6313,
      "step": 912600
    },
    {
      "epoch": 9.661662811439703,
      "grad_norm": 4.621024131774902,
      "learning_rate": 1.7126296845225495e-06,
      "loss": 0.6185,
      "step": 912650
    },
    {
      "epoch": 9.662192133219705,
      "grad_norm": 4.969460964202881,
      "learning_rate": 1.7099830616133815e-06,
      "loss": 0.6275,
      "step": 912700
    },
    {
      "epoch": 9.662721454999708,
      "grad_norm": 5.037931442260742,
      "learning_rate": 1.7073364387042136e-06,
      "loss": 0.627,
      "step": 912750
    },
    {
      "epoch": 9.663250776779712,
      "grad_norm": 4.715879440307617,
      "learning_rate": 1.7046898157950456e-06,
      "loss": 0.6205,
      "step": 912800
    },
    {
      "epoch": 9.663780098559716,
      "grad_norm": 4.596776485443115,
      "learning_rate": 1.7020431928858778e-06,
      "loss": 0.6221,
      "step": 912850
    },
    {
      "epoch": 9.664309420339718,
      "grad_norm": 5.216878890991211,
      "learning_rate": 1.6993965699767098e-06,
      "loss": 0.6207,
      "step": 912900
    },
    {
      "epoch": 9.664838742119722,
      "grad_norm": 5.047736644744873,
      "learning_rate": 1.696749947067542e-06,
      "loss": 0.6273,
      "step": 912950
    },
    {
      "epoch": 9.665368063899725,
      "grad_norm": 5.546154022216797,
      "learning_rate": 1.6941033241583742e-06,
      "loss": 0.6192,
      "step": 913000
    },
    {
      "epoch": 9.665368063899725,
      "eval_loss": 0.37495189905166626,
      "eval_runtime": 46.5237,
      "eval_samples_per_second": 3609.556,
      "eval_steps_per_second": 451.211,
      "step": 913000
    },
    {
      "epoch": 9.66589738567973,
      "grad_norm": 4.315793991088867,
      "learning_rate": 1.6914567012492062e-06,
      "loss": 0.6177,
      "step": 913050
    },
    {
      "epoch": 9.666426707459731,
      "grad_norm": 4.929086208343506,
      "learning_rate": 1.6888100783400384e-06,
      "loss": 0.6288,
      "step": 913100
    },
    {
      "epoch": 9.666956029239735,
      "grad_norm": 4.714494705200195,
      "learning_rate": 1.6861634554308704e-06,
      "loss": 0.6221,
      "step": 913150
    },
    {
      "epoch": 9.667485351019739,
      "grad_norm": 4.986361980438232,
      "learning_rate": 1.6835168325217025e-06,
      "loss": 0.6119,
      "step": 913200
    },
    {
      "epoch": 9.668014672799742,
      "grad_norm": 4.631290435791016,
      "learning_rate": 1.6808702096125347e-06,
      "loss": 0.6115,
      "step": 913250
    },
    {
      "epoch": 9.668543994579744,
      "grad_norm": 4.689974308013916,
      "learning_rate": 1.6782235867033667e-06,
      "loss": 0.6164,
      "step": 913300
    },
    {
      "epoch": 9.669073316359748,
      "grad_norm": 4.057246208190918,
      "learning_rate": 1.675576963794199e-06,
      "loss": 0.6164,
      "step": 913350
    },
    {
      "epoch": 9.669602638139752,
      "grad_norm": 4.783387184143066,
      "learning_rate": 1.672930340885031e-06,
      "loss": 0.6138,
      "step": 913400
    },
    {
      "epoch": 9.670131959919754,
      "grad_norm": 4.534460544586182,
      "learning_rate": 1.6702837179758627e-06,
      "loss": 0.6245,
      "step": 913450
    },
    {
      "epoch": 9.670661281699758,
      "grad_norm": 4.773332595825195,
      "learning_rate": 1.6676370950666949e-06,
      "loss": 0.6139,
      "step": 913500
    },
    {
      "epoch": 9.670661281699758,
      "eval_loss": 0.37466564774513245,
      "eval_runtime": 46.5104,
      "eval_samples_per_second": 3610.586,
      "eval_steps_per_second": 451.339,
      "step": 913500
    },
    {
      "epoch": 9.671190603479761,
      "grad_norm": 5.038122177124023,
      "learning_rate": 1.6649904721575268e-06,
      "loss": 0.6073,
      "step": 913550
    },
    {
      "epoch": 9.671719925259765,
      "grad_norm": 4.329143524169922,
      "learning_rate": 1.662343849248359e-06,
      "loss": 0.6141,
      "step": 913600
    },
    {
      "epoch": 9.672249247039767,
      "grad_norm": 4.662880897521973,
      "learning_rate": 1.659697226339191e-06,
      "loss": 0.6223,
      "step": 913650
    },
    {
      "epoch": 9.672778568819771,
      "grad_norm": 4.7142791748046875,
      "learning_rate": 1.6570506034300232e-06,
      "loss": 0.6163,
      "step": 913700
    },
    {
      "epoch": 9.673307890599775,
      "grad_norm": 5.2073163986206055,
      "learning_rate": 1.6544039805208554e-06,
      "loss": 0.622,
      "step": 913750
    },
    {
      "epoch": 9.673837212379778,
      "grad_norm": 4.848484516143799,
      "learning_rate": 1.651810290069871e-06,
      "loss": 0.6292,
      "step": 913800
    },
    {
      "epoch": 9.67436653415978,
      "grad_norm": 4.798759460449219,
      "learning_rate": 1.6491636671607032e-06,
      "loss": 0.6051,
      "step": 913850
    },
    {
      "epoch": 9.674895855939784,
      "grad_norm": 4.386883735656738,
      "learning_rate": 1.6465170442515354e-06,
      "loss": 0.6164,
      "step": 913900
    },
    {
      "epoch": 9.675425177719788,
      "grad_norm": 4.750322341918945,
      "learning_rate": 1.6438704213423673e-06,
      "loss": 0.6181,
      "step": 913950
    },
    {
      "epoch": 9.675954499499792,
      "grad_norm": 4.5279622077941895,
      "learning_rate": 1.6412237984331995e-06,
      "loss": 0.6197,
      "step": 914000
    },
    {
      "epoch": 9.675954499499792,
      "eval_loss": 0.37449216842651367,
      "eval_runtime": 46.5089,
      "eval_samples_per_second": 3610.704,
      "eval_steps_per_second": 451.354,
      "step": 914000
    },
    {
      "epoch": 9.676483821279794,
      "grad_norm": 4.654094696044922,
      "learning_rate": 1.6385771755240313e-06,
      "loss": 0.6185,
      "step": 914050
    },
    {
      "epoch": 9.677013143059797,
      "grad_norm": 3.9908790588378906,
      "learning_rate": 1.6359305526148633e-06,
      "loss": 0.6135,
      "step": 914100
    },
    {
      "epoch": 9.677542464839801,
      "grad_norm": 4.353736400604248,
      "learning_rate": 1.6332839297056955e-06,
      "loss": 0.6128,
      "step": 914150
    },
    {
      "epoch": 9.678071786619803,
      "grad_norm": 4.580410957336426,
      "learning_rate": 1.6306373067965275e-06,
      "loss": 0.6163,
      "step": 914200
    },
    {
      "epoch": 9.678601108399807,
      "grad_norm": 4.5484161376953125,
      "learning_rate": 1.6279906838873597e-06,
      "loss": 0.6242,
      "step": 914250
    },
    {
      "epoch": 9.67913043017981,
      "grad_norm": 4.950569152832031,
      "learning_rate": 1.6253440609781918e-06,
      "loss": 0.6289,
      "step": 914300
    },
    {
      "epoch": 9.679659751959814,
      "grad_norm": 4.8776044845581055,
      "learning_rate": 1.6226974380690238e-06,
      "loss": 0.6227,
      "step": 914350
    },
    {
      "epoch": 9.680189073739816,
      "grad_norm": 4.525400638580322,
      "learning_rate": 1.620050815159856e-06,
      "loss": 0.6222,
      "step": 914400
    },
    {
      "epoch": 9.68071839551982,
      "grad_norm": 4.899857997894287,
      "learning_rate": 1.617404192250688e-06,
      "loss": 0.6083,
      "step": 914450
    },
    {
      "epoch": 9.681247717299824,
      "grad_norm": 4.556116104125977,
      "learning_rate": 1.6147575693415202e-06,
      "loss": 0.6242,
      "step": 914500
    },
    {
      "epoch": 9.681247717299824,
      "eval_loss": 0.3744705617427826,
      "eval_runtime": 46.4107,
      "eval_samples_per_second": 3618.344,
      "eval_steps_per_second": 452.309,
      "step": 914500
    },
    {
      "epoch": 9.681777039079828,
      "grad_norm": 4.462342262268066,
      "learning_rate": 1.6121109464323524e-06,
      "loss": 0.6132,
      "step": 914550
    },
    {
      "epoch": 9.68230636085983,
      "grad_norm": 4.7202067375183105,
      "learning_rate": 1.6094643235231844e-06,
      "loss": 0.6191,
      "step": 914600
    },
    {
      "epoch": 9.682835682639833,
      "grad_norm": 4.491277694702148,
      "learning_rate": 1.6068177006140166e-06,
      "loss": 0.6234,
      "step": 914650
    },
    {
      "epoch": 9.683365004419837,
      "grad_norm": 4.541704177856445,
      "learning_rate": 1.6041710777048486e-06,
      "loss": 0.6204,
      "step": 914700
    },
    {
      "epoch": 9.683894326199841,
      "grad_norm": 4.107412338256836,
      "learning_rate": 1.6015244547956807e-06,
      "loss": 0.6214,
      "step": 914750
    },
    {
      "epoch": 9.684423647979843,
      "grad_norm": 4.863004207611084,
      "learning_rate": 1.5988778318865127e-06,
      "loss": 0.6087,
      "step": 914800
    },
    {
      "epoch": 9.684952969759847,
      "grad_norm": 5.069172382354736,
      "learning_rate": 1.596231208977345e-06,
      "loss": 0.6195,
      "step": 914850
    },
    {
      "epoch": 9.68548229153985,
      "grad_norm": 4.161447048187256,
      "learning_rate": 1.5935845860681771e-06,
      "loss": 0.6171,
      "step": 914900
    },
    {
      "epoch": 9.686011613319852,
      "grad_norm": 4.3794169425964355,
      "learning_rate": 1.590937963159009e-06,
      "loss": 0.6158,
      "step": 914950
    },
    {
      "epoch": 9.686540935099856,
      "grad_norm": 4.477304458618164,
      "learning_rate": 1.5882913402498413e-06,
      "loss": 0.6181,
      "step": 915000
    },
    {
      "epoch": 9.686540935099856,
      "eval_loss": 0.3748401403427124,
      "eval_runtime": 46.4744,
      "eval_samples_per_second": 3613.386,
      "eval_steps_per_second": 451.689,
      "step": 915000
    },
    {
      "epoch": 9.68707025687986,
      "grad_norm": 4.367578029632568,
      "learning_rate": 1.5856447173406733e-06,
      "loss": 0.6043,
      "step": 915050
    },
    {
      "epoch": 9.687599578659864,
      "grad_norm": 4.334905624389648,
      "learning_rate": 1.5829980944315055e-06,
      "loss": 0.6128,
      "step": 915100
    },
    {
      "epoch": 9.688128900439866,
      "grad_norm": 4.541969299316406,
      "learning_rate": 1.5803514715223375e-06,
      "loss": 0.6227,
      "step": 915150
    },
    {
      "epoch": 9.68865822221987,
      "grad_norm": 4.687250137329102,
      "learning_rate": 1.5777048486131696e-06,
      "loss": 0.6155,
      "step": 915200
    },
    {
      "epoch": 9.689187543999873,
      "grad_norm": 4.781740665435791,
      "learning_rate": 1.5750582257040018e-06,
      "loss": 0.629,
      "step": 915250
    },
    {
      "epoch": 9.689716865779877,
      "grad_norm": 5.278401851654053,
      "learning_rate": 1.5724116027948338e-06,
      "loss": 0.6234,
      "step": 915300
    },
    {
      "epoch": 9.690246187559879,
      "grad_norm": 5.050934791564941,
      "learning_rate": 1.569764979885666e-06,
      "loss": 0.6181,
      "step": 915350
    },
    {
      "epoch": 9.690775509339883,
      "grad_norm": 4.331793785095215,
      "learning_rate": 1.567118356976498e-06,
      "loss": 0.629,
      "step": 915400
    },
    {
      "epoch": 9.691304831119886,
      "grad_norm": 4.6759843826293945,
      "learning_rate": 1.5644717340673302e-06,
      "loss": 0.6132,
      "step": 915450
    },
    {
      "epoch": 9.69183415289989,
      "grad_norm": 4.728874683380127,
      "learning_rate": 1.5618251111581622e-06,
      "loss": 0.6271,
      "step": 915500
    },
    {
      "epoch": 9.69183415289989,
      "eval_loss": 0.374622106552124,
      "eval_runtime": 46.4481,
      "eval_samples_per_second": 3615.436,
      "eval_steps_per_second": 451.946,
      "step": 915500
    },
    {
      "epoch": 9.692363474679892,
      "grad_norm": 4.481217384338379,
      "learning_rate": 1.5591784882489944e-06,
      "loss": 0.6123,
      "step": 915550
    },
    {
      "epoch": 9.692892796459896,
      "grad_norm": 4.854893207550049,
      "learning_rate": 1.5565318653398266e-06,
      "loss": 0.6175,
      "step": 915600
    },
    {
      "epoch": 9.6934221182399,
      "grad_norm": 4.790607452392578,
      "learning_rate": 1.5538852424306585e-06,
      "loss": 0.6163,
      "step": 915650
    },
    {
      "epoch": 9.693951440019902,
      "grad_norm": 4.869851589202881,
      "learning_rate": 1.5512386195214907e-06,
      "loss": 0.6196,
      "step": 915700
    },
    {
      "epoch": 9.694480761799905,
      "grad_norm": 4.167014122009277,
      "learning_rate": 1.5485919966123227e-06,
      "loss": 0.6298,
      "step": 915750
    },
    {
      "epoch": 9.69501008357991,
      "grad_norm": 4.21303129196167,
      "learning_rate": 1.5459983061613383e-06,
      "loss": 0.6072,
      "step": 915800
    },
    {
      "epoch": 9.695539405359913,
      "grad_norm": 4.687983989715576,
      "learning_rate": 1.5433516832521703e-06,
      "loss": 0.6239,
      "step": 915850
    },
    {
      "epoch": 9.696068727139915,
      "grad_norm": 4.165517807006836,
      "learning_rate": 1.5407050603430025e-06,
      "loss": 0.6171,
      "step": 915900
    },
    {
      "epoch": 9.696598048919919,
      "grad_norm": 4.680145263671875,
      "learning_rate": 1.5380584374338344e-06,
      "loss": 0.6299,
      "step": 915950
    },
    {
      "epoch": 9.697127370699922,
      "grad_norm": 4.86920166015625,
      "learning_rate": 1.5354118145246666e-06,
      "loss": 0.612,
      "step": 916000
    },
    {
      "epoch": 9.697127370699922,
      "eval_loss": 0.37474939227104187,
      "eval_runtime": 46.5322,
      "eval_samples_per_second": 3608.897,
      "eval_steps_per_second": 451.128,
      "step": 916000
    },
    {
      "epoch": 9.697656692479926,
      "grad_norm": 4.646600246429443,
      "learning_rate": 1.5327651916154986e-06,
      "loss": 0.6167,
      "step": 916050
    },
    {
      "epoch": 9.698186014259928,
      "grad_norm": 4.505115509033203,
      "learning_rate": 1.5301185687063308e-06,
      "loss": 0.6252,
      "step": 916100
    },
    {
      "epoch": 9.698715336039932,
      "grad_norm": 4.416574478149414,
      "learning_rate": 1.527471945797163e-06,
      "loss": 0.6306,
      "step": 916150
    },
    {
      "epoch": 9.699244657819936,
      "grad_norm": 4.329524993896484,
      "learning_rate": 1.524825322887995e-06,
      "loss": 0.6317,
      "step": 916200
    },
    {
      "epoch": 9.69977397959994,
      "grad_norm": 4.50295352935791,
      "learning_rate": 1.5221786999788272e-06,
      "loss": 0.6227,
      "step": 916250
    },
    {
      "epoch": 9.700303301379941,
      "grad_norm": 4.677363872528076,
      "learning_rate": 1.5195320770696592e-06,
      "loss": 0.6171,
      "step": 916300
    },
    {
      "epoch": 9.700832623159945,
      "grad_norm": 4.372371673583984,
      "learning_rate": 1.5168854541604914e-06,
      "loss": 0.6302,
      "step": 916350
    },
    {
      "epoch": 9.701361944939949,
      "grad_norm": 4.707621097564697,
      "learning_rate": 1.5142388312513235e-06,
      "loss": 0.6245,
      "step": 916400
    },
    {
      "epoch": 9.70189126671995,
      "grad_norm": 4.415484428405762,
      "learning_rate": 1.5115922083421555e-06,
      "loss": 0.6145,
      "step": 916450
    },
    {
      "epoch": 9.702420588499955,
      "grad_norm": 4.577462673187256,
      "learning_rate": 1.5089455854329877e-06,
      "loss": 0.6228,
      "step": 916500
    },
    {
      "epoch": 9.702420588499955,
      "eval_loss": 0.37496182322502136,
      "eval_runtime": 46.4935,
      "eval_samples_per_second": 3611.902,
      "eval_steps_per_second": 451.504,
      "step": 916500
    },
    {
      "epoch": 9.702949910279958,
      "grad_norm": 4.723922252655029,
      "learning_rate": 1.5062989625238197e-06,
      "loss": 0.6208,
      "step": 916550
    },
    {
      "epoch": 9.703479232059962,
      "grad_norm": 4.951976299285889,
      "learning_rate": 1.5036523396146517e-06,
      "loss": 0.6129,
      "step": 916600
    },
    {
      "epoch": 9.704008553839964,
      "grad_norm": 4.747562408447266,
      "learning_rate": 1.5010057167054839e-06,
      "loss": 0.6141,
      "step": 916650
    },
    {
      "epoch": 9.704537875619968,
      "grad_norm": 4.109506607055664,
      "learning_rate": 1.4983590937963159e-06,
      "loss": 0.622,
      "step": 916700
    },
    {
      "epoch": 9.705067197399972,
      "grad_norm": 4.794447898864746,
      "learning_rate": 1.495712470887148e-06,
      "loss": 0.6229,
      "step": 916750
    },
    {
      "epoch": 9.705596519179975,
      "grad_norm": 5.258961200714111,
      "learning_rate": 1.49306584797798e-06,
      "loss": 0.6184,
      "step": 916800
    },
    {
      "epoch": 9.706125840959977,
      "grad_norm": 4.672708988189697,
      "learning_rate": 1.4904192250688122e-06,
      "loss": 0.6184,
      "step": 916850
    },
    {
      "epoch": 9.706655162739981,
      "grad_norm": 4.926464557647705,
      "learning_rate": 1.4877726021596442e-06,
      "loss": 0.625,
      "step": 916900
    },
    {
      "epoch": 9.707184484519985,
      "grad_norm": 4.564475059509277,
      "learning_rate": 1.4851259792504764e-06,
      "loss": 0.6286,
      "step": 916950
    },
    {
      "epoch": 9.707713806299989,
      "grad_norm": 4.56026029586792,
      "learning_rate": 1.4824793563413086e-06,
      "loss": 0.6251,
      "step": 917000
    },
    {
      "epoch": 9.707713806299989,
      "eval_loss": 0.3747469484806061,
      "eval_runtime": 46.5639,
      "eval_samples_per_second": 3606.444,
      "eval_steps_per_second": 450.822,
      "step": 917000
    },
    {
      "epoch": 9.70824312807999,
      "grad_norm": 4.742775917053223,
      "learning_rate": 1.4798327334321406e-06,
      "loss": 0.6126,
      "step": 917050
    },
    {
      "epoch": 9.708772449859994,
      "grad_norm": 4.6202521324157715,
      "learning_rate": 1.4771861105229728e-06,
      "loss": 0.6253,
      "step": 917100
    },
    {
      "epoch": 9.709301771639998,
      "grad_norm": 4.052305698394775,
      "learning_rate": 1.4745394876138048e-06,
      "loss": 0.6186,
      "step": 917150
    },
    {
      "epoch": 9.70983109342,
      "grad_norm": 4.540064811706543,
      "learning_rate": 1.471892864704637e-06,
      "loss": 0.6224,
      "step": 917200
    },
    {
      "epoch": 9.710360415200004,
      "grad_norm": 3.997441530227661,
      "learning_rate": 1.4692462417954692e-06,
      "loss": 0.6228,
      "step": 917250
    },
    {
      "epoch": 9.710889736980008,
      "grad_norm": 4.912102222442627,
      "learning_rate": 1.4665996188863011e-06,
      "loss": 0.6189,
      "step": 917300
    },
    {
      "epoch": 9.711419058760011,
      "grad_norm": 4.217126369476318,
      "learning_rate": 1.4639529959771333e-06,
      "loss": 0.6103,
      "step": 917350
    },
    {
      "epoch": 9.711948380540013,
      "grad_norm": 4.698313236236572,
      "learning_rate": 1.4613063730679653e-06,
      "loss": 0.6159,
      "step": 917400
    },
    {
      "epoch": 9.712477702320017,
      "grad_norm": 4.725216388702393,
      "learning_rate": 1.4586597501587975e-06,
      "loss": 0.6171,
      "step": 917450
    },
    {
      "epoch": 9.71300702410002,
      "grad_norm": 4.360251426696777,
      "learning_rate": 1.4560131272496295e-06,
      "loss": 0.6066,
      "step": 917500
    },
    {
      "epoch": 9.71300702410002,
      "eval_loss": 0.3747069239616394,
      "eval_runtime": 46.5459,
      "eval_samples_per_second": 3607.834,
      "eval_steps_per_second": 450.995,
      "step": 917500
    },
    {
      "epoch": 9.713536345880025,
      "grad_norm": 4.827993392944336,
      "learning_rate": 1.4533665043404617e-06,
      "loss": 0.6225,
      "step": 917550
    },
    {
      "epoch": 9.714065667660027,
      "grad_norm": 4.614464282989502,
      "learning_rate": 1.4507198814312939e-06,
      "loss": 0.6274,
      "step": 917600
    },
    {
      "epoch": 9.71459498944003,
      "grad_norm": 4.512834548950195,
      "learning_rate": 1.4480732585221259e-06,
      "loss": 0.6163,
      "step": 917650
    },
    {
      "epoch": 9.715124311220034,
      "grad_norm": 4.316078186035156,
      "learning_rate": 1.445426635612958e-06,
      "loss": 0.6189,
      "step": 917700
    },
    {
      "epoch": 9.715653633000038,
      "grad_norm": 4.444091796875,
      "learning_rate": 1.44278001270379e-06,
      "loss": 0.6106,
      "step": 917750
    },
    {
      "epoch": 9.71618295478004,
      "grad_norm": 4.5144195556640625,
      "learning_rate": 1.4401863222528054e-06,
      "loss": 0.625,
      "step": 917800
    },
    {
      "epoch": 9.716712276560044,
      "grad_norm": 4.4513630867004395,
      "learning_rate": 1.4375396993436376e-06,
      "loss": 0.6092,
      "step": 917850
    },
    {
      "epoch": 9.717241598340047,
      "grad_norm": 4.480355262756348,
      "learning_rate": 1.4348930764344698e-06,
      "loss": 0.6148,
      "step": 917900
    },
    {
      "epoch": 9.71777092012005,
      "grad_norm": 4.63612699508667,
      "learning_rate": 1.4322464535253018e-06,
      "loss": 0.6298,
      "step": 917950
    },
    {
      "epoch": 9.718300241900053,
      "grad_norm": 4.167973518371582,
      "learning_rate": 1.429599830616134e-06,
      "loss": 0.6038,
      "step": 918000
    },
    {
      "epoch": 9.718300241900053,
      "eval_loss": 0.37421080470085144,
      "eval_runtime": 46.5444,
      "eval_samples_per_second": 3607.956,
      "eval_steps_per_second": 451.011,
      "step": 918000
    },
    {
      "epoch": 9.718829563680057,
      "grad_norm": 4.846852779388428,
      "learning_rate": 1.426953207706966e-06,
      "loss": 0.622,
      "step": 918050
    },
    {
      "epoch": 9.71935888546006,
      "grad_norm": 4.599812984466553,
      "learning_rate": 1.4243065847977981e-06,
      "loss": 0.6144,
      "step": 918100
    },
    {
      "epoch": 9.719888207240063,
      "grad_norm": 4.813052177429199,
      "learning_rate": 1.4216599618886303e-06,
      "loss": 0.6179,
      "step": 918150
    },
    {
      "epoch": 9.720417529020066,
      "grad_norm": 4.503475189208984,
      "learning_rate": 1.4190133389794623e-06,
      "loss": 0.6151,
      "step": 918200
    },
    {
      "epoch": 9.72094685080007,
      "grad_norm": 4.4409356117248535,
      "learning_rate": 1.4163667160702945e-06,
      "loss": 0.6148,
      "step": 918250
    },
    {
      "epoch": 9.721476172580074,
      "grad_norm": 4.738335132598877,
      "learning_rate": 1.4137200931611265e-06,
      "loss": 0.6184,
      "step": 918300
    },
    {
      "epoch": 9.722005494360076,
      "grad_norm": 4.675835132598877,
      "learning_rate": 1.4110734702519587e-06,
      "loss": 0.6169,
      "step": 918350
    },
    {
      "epoch": 9.72253481614008,
      "grad_norm": 4.5458984375,
      "learning_rate": 1.4084268473427907e-06,
      "loss": 0.6298,
      "step": 918400
    },
    {
      "epoch": 9.723064137920083,
      "grad_norm": 4.690485954284668,
      "learning_rate": 1.4057802244336228e-06,
      "loss": 0.624,
      "step": 918450
    },
    {
      "epoch": 9.723593459700087,
      "grad_norm": 4.342665195465088,
      "learning_rate": 1.4031336015244548e-06,
      "loss": 0.614,
      "step": 918500
    },
    {
      "epoch": 9.723593459700087,
      "eval_loss": 0.3742597997188568,
      "eval_runtime": 46.8028,
      "eval_samples_per_second": 3588.033,
      "eval_steps_per_second": 448.52,
      "step": 918500
    },
    {
      "epoch": 9.724122781480089,
      "grad_norm": 4.914271831512451,
      "learning_rate": 1.4004869786152868e-06,
      "loss": 0.6075,
      "step": 918550
    },
    {
      "epoch": 9.724652103260093,
      "grad_norm": 5.168817043304443,
      "learning_rate": 1.397840355706119e-06,
      "loss": 0.6061,
      "step": 918600
    },
    {
      "epoch": 9.725181425040097,
      "grad_norm": 4.473613262176514,
      "learning_rate": 1.395193732796951e-06,
      "loss": 0.6101,
      "step": 918650
    },
    {
      "epoch": 9.725710746820099,
      "grad_norm": 4.347141742706299,
      "learning_rate": 1.3925471098877832e-06,
      "loss": 0.6261,
      "step": 918700
    },
    {
      "epoch": 9.726240068600102,
      "grad_norm": 4.899767875671387,
      "learning_rate": 1.3899004869786154e-06,
      "loss": 0.6176,
      "step": 918750
    },
    {
      "epoch": 9.726769390380106,
      "grad_norm": 5.054244518280029,
      "learning_rate": 1.3872538640694474e-06,
      "loss": 0.6047,
      "step": 918800
    },
    {
      "epoch": 9.72729871216011,
      "grad_norm": 4.229909420013428,
      "learning_rate": 1.3846072411602796e-06,
      "loss": 0.6118,
      "step": 918850
    },
    {
      "epoch": 9.727828033940112,
      "grad_norm": 4.640029430389404,
      "learning_rate": 1.3819606182511115e-06,
      "loss": 0.6242,
      "step": 918900
    },
    {
      "epoch": 9.728357355720116,
      "grad_norm": 4.600573539733887,
      "learning_rate": 1.3793139953419437e-06,
      "loss": 0.617,
      "step": 918950
    },
    {
      "epoch": 9.72888667750012,
      "grad_norm": 4.387801170349121,
      "learning_rate": 1.376667372432776e-06,
      "loss": 0.6076,
      "step": 919000
    },
    {
      "epoch": 9.72888667750012,
      "eval_loss": 0.3742928206920624,
      "eval_runtime": 46.5369,
      "eval_samples_per_second": 3608.534,
      "eval_steps_per_second": 451.083,
      "step": 919000
    },
    {
      "epoch": 9.729415999280123,
      "grad_norm": 4.165726184844971,
      "learning_rate": 1.374020749523608e-06,
      "loss": 0.6164,
      "step": 919050
    },
    {
      "epoch": 9.729945321060125,
      "grad_norm": 4.911399841308594,
      "learning_rate": 1.37137412661444e-06,
      "loss": 0.6118,
      "step": 919100
    },
    {
      "epoch": 9.730474642840129,
      "grad_norm": 4.841719150543213,
      "learning_rate": 1.368727503705272e-06,
      "loss": 0.6289,
      "step": 919150
    },
    {
      "epoch": 9.731003964620133,
      "grad_norm": 4.249668121337891,
      "learning_rate": 1.3660808807961043e-06,
      "loss": 0.6165,
      "step": 919200
    },
    {
      "epoch": 9.731533286400136,
      "grad_norm": 4.732390403747559,
      "learning_rate": 1.3634342578869363e-06,
      "loss": 0.6202,
      "step": 919250
    },
    {
      "epoch": 9.732062608180138,
      "grad_norm": 4.246600151062012,
      "learning_rate": 1.3607876349777685e-06,
      "loss": 0.616,
      "step": 919300
    },
    {
      "epoch": 9.732591929960142,
      "grad_norm": 4.467437267303467,
      "learning_rate": 1.3581410120686006e-06,
      "loss": 0.6202,
      "step": 919350
    },
    {
      "epoch": 9.733121251740146,
      "grad_norm": 4.700955867767334,
      "learning_rate": 1.3554943891594326e-06,
      "loss": 0.6188,
      "step": 919400
    },
    {
      "epoch": 9.733650573520148,
      "grad_norm": 4.734559059143066,
      "learning_rate": 1.3528477662502648e-06,
      "loss": 0.6137,
      "step": 919450
    },
    {
      "epoch": 9.734179895300151,
      "grad_norm": 4.521997451782227,
      "learning_rate": 1.3502011433410968e-06,
      "loss": 0.6173,
      "step": 919500
    },
    {
      "epoch": 9.734179895300151,
      "eval_loss": 0.3744518458843231,
      "eval_runtime": 46.5744,
      "eval_samples_per_second": 3605.626,
      "eval_steps_per_second": 450.719,
      "step": 919500
    },
    {
      "epoch": 9.734709217080155,
      "grad_norm": 4.761990070343018,
      "learning_rate": 1.347554520431929e-06,
      "loss": 0.6269,
      "step": 919550
    },
    {
      "epoch": 9.735238538860159,
      "grad_norm": 4.426686763763428,
      "learning_rate": 1.344907897522761e-06,
      "loss": 0.6219,
      "step": 919600
    },
    {
      "epoch": 9.735767860640161,
      "grad_norm": 4.487826347351074,
      "learning_rate": 1.3422612746135932e-06,
      "loss": 0.6175,
      "step": 919650
    },
    {
      "epoch": 9.736297182420165,
      "grad_norm": 4.322411060333252,
      "learning_rate": 1.3396146517044254e-06,
      "loss": 0.6227,
      "step": 919700
    },
    {
      "epoch": 9.736826504200168,
      "grad_norm": 4.953224182128906,
      "learning_rate": 1.3369680287952574e-06,
      "loss": 0.6128,
      "step": 919750
    },
    {
      "epoch": 9.737355825980172,
      "grad_norm": 4.759857177734375,
      "learning_rate": 1.3343743383442727e-06,
      "loss": 0.6153,
      "step": 919800
    },
    {
      "epoch": 9.737885147760174,
      "grad_norm": 5.576034069061279,
      "learning_rate": 1.3317277154351049e-06,
      "loss": 0.6317,
      "step": 919850
    },
    {
      "epoch": 9.738414469540178,
      "grad_norm": 5.307729721069336,
      "learning_rate": 1.329081092525937e-06,
      "loss": 0.6156,
      "step": 919900
    },
    {
      "epoch": 9.738943791320182,
      "grad_norm": 4.915457725524902,
      "learning_rate": 1.326434469616769e-06,
      "loss": 0.6146,
      "step": 919950
    },
    {
      "epoch": 9.739473113100185,
      "grad_norm": 4.308720111846924,
      "learning_rate": 1.3237878467076013e-06,
      "loss": 0.6158,
      "step": 920000
    },
    {
      "epoch": 9.739473113100185,
      "eval_loss": 0.37396687269210815,
      "eval_runtime": 46.5713,
      "eval_samples_per_second": 3605.866,
      "eval_steps_per_second": 450.749,
      "step": 920000
    },
    {
      "epoch": 9.740002434880187,
      "grad_norm": 4.7345428466796875,
      "learning_rate": 1.3211412237984332e-06,
      "loss": 0.6202,
      "step": 920050
    },
    {
      "epoch": 9.740531756660191,
      "grad_norm": 4.514227867126465,
      "learning_rate": 1.3184946008892654e-06,
      "loss": 0.6219,
      "step": 920100
    },
    {
      "epoch": 9.741061078440195,
      "grad_norm": 4.254215717315674,
      "learning_rate": 1.3158479779800974e-06,
      "loss": 0.6177,
      "step": 920150
    },
    {
      "epoch": 9.741590400220197,
      "grad_norm": 4.418865203857422,
      "learning_rate": 1.3132013550709296e-06,
      "loss": 0.6302,
      "step": 920200
    },
    {
      "epoch": 9.7421197220002,
      "grad_norm": 4.86434268951416,
      "learning_rate": 1.3105547321617618e-06,
      "loss": 0.6108,
      "step": 920250
    },
    {
      "epoch": 9.742649043780204,
      "grad_norm": 4.670314788818359,
      "learning_rate": 1.3079081092525938e-06,
      "loss": 0.6257,
      "step": 920300
    },
    {
      "epoch": 9.743178365560208,
      "grad_norm": 4.416610240936279,
      "learning_rate": 1.305261486343426e-06,
      "loss": 0.6232,
      "step": 920350
    },
    {
      "epoch": 9.74370768734021,
      "grad_norm": 4.716350078582764,
      "learning_rate": 1.302614863434258e-06,
      "loss": 0.6203,
      "step": 920400
    },
    {
      "epoch": 9.744237009120214,
      "grad_norm": 4.586087703704834,
      "learning_rate": 1.29996824052509e-06,
      "loss": 0.6161,
      "step": 920450
    },
    {
      "epoch": 9.744766330900218,
      "grad_norm": 4.6488237380981445,
      "learning_rate": 1.2973216176159221e-06,
      "loss": 0.6027,
      "step": 920500
    },
    {
      "epoch": 9.744766330900218,
      "eval_loss": 0.3741338849067688,
      "eval_runtime": 46.5477,
      "eval_samples_per_second": 3607.7,
      "eval_steps_per_second": 450.979,
      "step": 920500
    },
    {
      "epoch": 9.745295652680221,
      "grad_norm": 4.765319347381592,
      "learning_rate": 1.2946749947067541e-06,
      "loss": 0.6161,
      "step": 920550
    },
    {
      "epoch": 9.745824974460223,
      "grad_norm": 4.950516700744629,
      "learning_rate": 1.2920283717975863e-06,
      "loss": 0.6257,
      "step": 920600
    },
    {
      "epoch": 9.746354296240227,
      "grad_norm": 4.8683037757873535,
      "learning_rate": 1.2893817488884183e-06,
      "loss": 0.6148,
      "step": 920650
    },
    {
      "epoch": 9.746883618020231,
      "grad_norm": 4.610332012176514,
      "learning_rate": 1.2867351259792505e-06,
      "loss": 0.6241,
      "step": 920700
    },
    {
      "epoch": 9.747412939800235,
      "grad_norm": 4.949480056762695,
      "learning_rate": 1.2840885030700827e-06,
      "loss": 0.6088,
      "step": 920750
    },
    {
      "epoch": 9.747942261580237,
      "grad_norm": 5.051668167114258,
      "learning_rate": 1.2814418801609147e-06,
      "loss": 0.6255,
      "step": 920800
    },
    {
      "epoch": 9.74847158336024,
      "grad_norm": 4.94303560256958,
      "learning_rate": 1.2787952572517469e-06,
      "loss": 0.6166,
      "step": 920850
    },
    {
      "epoch": 9.749000905140244,
      "grad_norm": 4.757382392883301,
      "learning_rate": 1.2761486343425788e-06,
      "loss": 0.611,
      "step": 920900
    },
    {
      "epoch": 9.749530226920246,
      "grad_norm": 4.393050670623779,
      "learning_rate": 1.273502011433411e-06,
      "loss": 0.6245,
      "step": 920950
    },
    {
      "epoch": 9.75005954870025,
      "grad_norm": 5.20527458190918,
      "learning_rate": 1.270855388524243e-06,
      "loss": 0.6161,
      "step": 921000
    },
    {
      "epoch": 9.75005954870025,
      "eval_loss": 0.37406644225120544,
      "eval_runtime": 46.5174,
      "eval_samples_per_second": 3610.046,
      "eval_steps_per_second": 451.272,
      "step": 921000
    },
    {
      "epoch": 9.750588870480254,
      "grad_norm": 4.569324016571045,
      "learning_rate": 1.2682087656150752e-06,
      "loss": 0.6124,
      "step": 921050
    },
    {
      "epoch": 9.751118192260257,
      "grad_norm": 4.968732833862305,
      "learning_rate": 1.2655621427059074e-06,
      "loss": 0.6176,
      "step": 921100
    },
    {
      "epoch": 9.75164751404026,
      "grad_norm": 4.502474784851074,
      "learning_rate": 1.2629155197967394e-06,
      "loss": 0.6186,
      "step": 921150
    },
    {
      "epoch": 9.752176835820263,
      "grad_norm": 4.701252460479736,
      "learning_rate": 1.2602688968875716e-06,
      "loss": 0.6247,
      "step": 921200
    },
    {
      "epoch": 9.752706157600267,
      "grad_norm": 4.4511284828186035,
      "learning_rate": 1.2576222739784036e-06,
      "loss": 0.6165,
      "step": 921250
    },
    {
      "epoch": 9.75323547938027,
      "grad_norm": 4.693369388580322,
      "learning_rate": 1.2549756510692358e-06,
      "loss": 0.6178,
      "step": 921300
    },
    {
      "epoch": 9.753764801160273,
      "grad_norm": 4.327445983886719,
      "learning_rate": 1.252329028160068e-06,
      "loss": 0.6085,
      "step": 921350
    },
    {
      "epoch": 9.754294122940276,
      "grad_norm": 4.820408344268799,
      "learning_rate": 1.2496824052509e-06,
      "loss": 0.6145,
      "step": 921400
    },
    {
      "epoch": 9.75482344472028,
      "grad_norm": 4.74143648147583,
      "learning_rate": 1.2470357823417321e-06,
      "loss": 0.6321,
      "step": 921450
    },
    {
      "epoch": 9.755352766500284,
      "grad_norm": 4.966537952423096,
      "learning_rate": 1.2443891594325641e-06,
      "loss": 0.6176,
      "step": 921500
    },
    {
      "epoch": 9.755352766500284,
      "eval_loss": 0.3738478124141693,
      "eval_runtime": 46.5941,
      "eval_samples_per_second": 3604.103,
      "eval_steps_per_second": 450.529,
      "step": 921500
    },
    {
      "epoch": 9.755882088280286,
      "grad_norm": 4.729342937469482,
      "learning_rate": 1.2417425365233963e-06,
      "loss": 0.6254,
      "step": 921550
    },
    {
      "epoch": 9.75641141006029,
      "grad_norm": 4.9724884033203125,
      "learning_rate": 1.2390959136142283e-06,
      "loss": 0.626,
      "step": 921600
    },
    {
      "epoch": 9.756940731840293,
      "grad_norm": 4.6431450843811035,
      "learning_rate": 1.2364492907050605e-06,
      "loss": 0.6088,
      "step": 921650
    },
    {
      "epoch": 9.757470053620295,
      "grad_norm": 4.438537120819092,
      "learning_rate": 1.2338026677958925e-06,
      "loss": 0.6147,
      "step": 921700
    },
    {
      "epoch": 9.7579993754003,
      "grad_norm": 4.643154621124268,
      "learning_rate": 1.2311560448867245e-06,
      "loss": 0.619,
      "step": 921750
    },
    {
      "epoch": 9.758528697180303,
      "grad_norm": 4.589848041534424,
      "learning_rate": 1.22856235443574e-06,
      "loss": 0.6155,
      "step": 921800
    },
    {
      "epoch": 9.759058018960307,
      "grad_norm": 4.62876558303833,
      "learning_rate": 1.2259157315265722e-06,
      "loss": 0.6174,
      "step": 921850
    },
    {
      "epoch": 9.759587340740309,
      "grad_norm": 4.900541305541992,
      "learning_rate": 1.2232691086174042e-06,
      "loss": 0.6207,
      "step": 921900
    },
    {
      "epoch": 9.760116662520312,
      "grad_norm": 4.3632493019104,
      "learning_rate": 1.2206224857082364e-06,
      "loss": 0.6115,
      "step": 921950
    },
    {
      "epoch": 9.760645984300316,
      "grad_norm": 5.43997049331665,
      "learning_rate": 1.2180287952572517e-06,
      "loss": 0.6189,
      "step": 922000
    },
    {
      "epoch": 9.760645984300316,
      "eval_loss": 0.3739924132823944,
      "eval_runtime": 46.494,
      "eval_samples_per_second": 3611.865,
      "eval_steps_per_second": 451.499,
      "step": 922000
    },
    {
      "epoch": 9.76117530608032,
      "grad_norm": 4.371604919433594,
      "learning_rate": 1.215382172348084e-06,
      "loss": 0.6118,
      "step": 922050
    },
    {
      "epoch": 9.761704627860322,
      "grad_norm": 4.37712287902832,
      "learning_rate": 1.212735549438916e-06,
      "loss": 0.6072,
      "step": 922100
    },
    {
      "epoch": 9.762233949640326,
      "grad_norm": 4.795546054840088,
      "learning_rate": 1.210088926529748e-06,
      "loss": 0.6213,
      "step": 922150
    },
    {
      "epoch": 9.76276327142033,
      "grad_norm": 4.424403667449951,
      "learning_rate": 1.2074423036205803e-06,
      "loss": 0.6215,
      "step": 922200
    },
    {
      "epoch": 9.763292593200333,
      "grad_norm": 4.5146636962890625,
      "learning_rate": 1.2047956807114123e-06,
      "loss": 0.6168,
      "step": 922250
    },
    {
      "epoch": 9.763821914980335,
      "grad_norm": 4.677109241485596,
      "learning_rate": 1.2021490578022445e-06,
      "loss": 0.6149,
      "step": 922300
    },
    {
      "epoch": 9.764351236760339,
      "grad_norm": 4.625548839569092,
      "learning_rate": 1.1995024348930764e-06,
      "loss": 0.614,
      "step": 922350
    },
    {
      "epoch": 9.764880558540343,
      "grad_norm": 4.4749040603637695,
      "learning_rate": 1.1968558119839086e-06,
      "loss": 0.6185,
      "step": 922400
    },
    {
      "epoch": 9.765409880320345,
      "grad_norm": 4.478694915771484,
      "learning_rate": 1.1942091890747406e-06,
      "loss": 0.6173,
      "step": 922450
    },
    {
      "epoch": 9.765939202100348,
      "grad_norm": 5.1767988204956055,
      "learning_rate": 1.1915625661655728e-06,
      "loss": 0.6104,
      "step": 922500
    },
    {
      "epoch": 9.765939202100348,
      "eval_loss": 0.37392500042915344,
      "eval_runtime": 46.5199,
      "eval_samples_per_second": 3609.852,
      "eval_steps_per_second": 451.248,
      "step": 922500
    },
    {
      "epoch": 9.766468523880352,
      "grad_norm": 4.587010860443115,
      "learning_rate": 1.188915943256405e-06,
      "loss": 0.6242,
      "step": 922550
    },
    {
      "epoch": 9.766997845660356,
      "grad_norm": 4.296025276184082,
      "learning_rate": 1.186269320347237e-06,
      "loss": 0.6085,
      "step": 922600
    },
    {
      "epoch": 9.767527167440358,
      "grad_norm": 4.2718610763549805,
      "learning_rate": 1.1836226974380692e-06,
      "loss": 0.6161,
      "step": 922650
    },
    {
      "epoch": 9.768056489220362,
      "grad_norm": 4.79546594619751,
      "learning_rate": 1.1809760745289012e-06,
      "loss": 0.613,
      "step": 922700
    },
    {
      "epoch": 9.768585811000365,
      "grad_norm": 4.8203606605529785,
      "learning_rate": 1.1783294516197334e-06,
      "loss": 0.6114,
      "step": 922750
    },
    {
      "epoch": 9.76911513278037,
      "grad_norm": 5.152791500091553,
      "learning_rate": 1.1756828287105653e-06,
      "loss": 0.6115,
      "step": 922800
    },
    {
      "epoch": 9.769644454560371,
      "grad_norm": 4.795123100280762,
      "learning_rate": 1.1730362058013975e-06,
      "loss": 0.606,
      "step": 922850
    },
    {
      "epoch": 9.770173776340375,
      "grad_norm": 4.69660758972168,
      "learning_rate": 1.1703895828922297e-06,
      "loss": 0.614,
      "step": 922900
    },
    {
      "epoch": 9.770703098120379,
      "grad_norm": 4.923258304595947,
      "learning_rate": 1.1677429599830615e-06,
      "loss": 0.6353,
      "step": 922950
    },
    {
      "epoch": 9.771232419900382,
      "grad_norm": 4.212076663970947,
      "learning_rate": 1.1650963370738937e-06,
      "loss": 0.6074,
      "step": 923000
    },
    {
      "epoch": 9.771232419900382,
      "eval_loss": 0.3738937973976135,
      "eval_runtime": 46.5189,
      "eval_samples_per_second": 3609.932,
      "eval_steps_per_second": 451.258,
      "step": 923000
    },
    {
      "epoch": 9.771761741680384,
      "grad_norm": 4.876852989196777,
      "learning_rate": 1.1624497141647259e-06,
      "loss": 0.62,
      "step": 923050
    },
    {
      "epoch": 9.772291063460388,
      "grad_norm": 4.881604194641113,
      "learning_rate": 1.1598030912555579e-06,
      "loss": 0.6241,
      "step": 923100
    },
    {
      "epoch": 9.772820385240392,
      "grad_norm": 4.537364959716797,
      "learning_rate": 1.15715646834639e-06,
      "loss": 0.611,
      "step": 923150
    },
    {
      "epoch": 9.773349707020394,
      "grad_norm": 5.063054084777832,
      "learning_rate": 1.154509845437222e-06,
      "loss": 0.6342,
      "step": 923200
    },
    {
      "epoch": 9.773879028800398,
      "grad_norm": 3.9049301147460938,
      "learning_rate": 1.1518632225280542e-06,
      "loss": 0.6239,
      "step": 923250
    },
    {
      "epoch": 9.774408350580401,
      "grad_norm": 4.799127101898193,
      "learning_rate": 1.1492165996188862e-06,
      "loss": 0.6257,
      "step": 923300
    },
    {
      "epoch": 9.774937672360405,
      "grad_norm": 4.818212985992432,
      "learning_rate": 1.1465699767097184e-06,
      "loss": 0.6123,
      "step": 923350
    },
    {
      "epoch": 9.775466994140407,
      "grad_norm": 4.479668617248535,
      "learning_rate": 1.1439233538005506e-06,
      "loss": 0.6183,
      "step": 923400
    },
    {
      "epoch": 9.77599631592041,
      "grad_norm": 4.5367045402526855,
      "learning_rate": 1.1412767308913826e-06,
      "loss": 0.6081,
      "step": 923450
    },
    {
      "epoch": 9.776525637700415,
      "grad_norm": 5.157851219177246,
      "learning_rate": 1.1386301079822148e-06,
      "loss": 0.6152,
      "step": 923500
    },
    {
      "epoch": 9.776525637700415,
      "eval_loss": 0.3736741840839386,
      "eval_runtime": 46.8837,
      "eval_samples_per_second": 3581.841,
      "eval_steps_per_second": 447.746,
      "step": 923500
    },
    {
      "epoch": 9.777054959480418,
      "grad_norm": 4.502503395080566,
      "learning_rate": 1.1359834850730468e-06,
      "loss": 0.6171,
      "step": 923550
    },
    {
      "epoch": 9.77758428126042,
      "grad_norm": 5.203182697296143,
      "learning_rate": 1.133336862163879e-06,
      "loss": 0.6328,
      "step": 923600
    },
    {
      "epoch": 9.778113603040424,
      "grad_norm": 4.714385509490967,
      "learning_rate": 1.1306902392547112e-06,
      "loss": 0.6191,
      "step": 923650
    },
    {
      "epoch": 9.778642924820428,
      "grad_norm": 4.835147857666016,
      "learning_rate": 1.1280436163455431e-06,
      "loss": 0.6177,
      "step": 923700
    },
    {
      "epoch": 9.779172246600432,
      "grad_norm": 4.908812999725342,
      "learning_rate": 1.1253969934363753e-06,
      "loss": 0.6174,
      "step": 923750
    },
    {
      "epoch": 9.779701568380434,
      "grad_norm": 4.451998233795166,
      "learning_rate": 1.1227503705272073e-06,
      "loss": 0.6223,
      "step": 923800
    },
    {
      "epoch": 9.780230890160437,
      "grad_norm": 4.473484516143799,
      "learning_rate": 1.1201037476180395e-06,
      "loss": 0.6286,
      "step": 923850
    },
    {
      "epoch": 9.780760211940441,
      "grad_norm": 5.094479560852051,
      "learning_rate": 1.1174571247088715e-06,
      "loss": 0.609,
      "step": 923900
    },
    {
      "epoch": 9.781289533720443,
      "grad_norm": 4.421978950500488,
      "learning_rate": 1.1148105017997037e-06,
      "loss": 0.6204,
      "step": 923950
    },
    {
      "epoch": 9.781818855500447,
      "grad_norm": 4.984560966491699,
      "learning_rate": 1.1121638788905359e-06,
      "loss": 0.612,
      "step": 924000
    },
    {
      "epoch": 9.781818855500447,
      "eval_loss": 0.3739699721336365,
      "eval_runtime": 46.6064,
      "eval_samples_per_second": 3603.15,
      "eval_steps_per_second": 450.41,
      "step": 924000
    },
    {
      "epoch": 9.78234817728045,
      "grad_norm": 4.607608795166016,
      "learning_rate": 1.1095172559813679e-06,
      "loss": 0.621,
      "step": 924050
    },
    {
      "epoch": 9.782877499060454,
      "grad_norm": 4.436699390411377,
      "learning_rate": 1.1068706330722e-06,
      "loss": 0.6274,
      "step": 924100
    },
    {
      "epoch": 9.783406820840456,
      "grad_norm": 5.100130081176758,
      "learning_rate": 1.104224010163032e-06,
      "loss": 0.6225,
      "step": 924150
    },
    {
      "epoch": 9.78393614262046,
      "grad_norm": 4.952793598175049,
      "learning_rate": 1.101577387253864e-06,
      "loss": 0.6208,
      "step": 924200
    },
    {
      "epoch": 9.784465464400464,
      "grad_norm": 4.434244632720947,
      "learning_rate": 1.0989307643446962e-06,
      "loss": 0.6223,
      "step": 924250
    },
    {
      "epoch": 9.784994786180468,
      "grad_norm": 4.886922836303711,
      "learning_rate": 1.0962841414355282e-06,
      "loss": 0.6186,
      "step": 924300
    },
    {
      "epoch": 9.78552410796047,
      "grad_norm": 4.8084845542907715,
      "learning_rate": 1.0936375185263604e-06,
      "loss": 0.6215,
      "step": 924350
    },
    {
      "epoch": 9.786053429740473,
      "grad_norm": 4.766470909118652,
      "learning_rate": 1.0909908956171924e-06,
      "loss": 0.6262,
      "step": 924400
    },
    {
      "epoch": 9.786582751520477,
      "grad_norm": 4.9276018142700195,
      "learning_rate": 1.0883442727080246e-06,
      "loss": 0.6229,
      "step": 924450
    },
    {
      "epoch": 9.78711207330048,
      "grad_norm": 5.0423407554626465,
      "learning_rate": 1.0856976497988568e-06,
      "loss": 0.6254,
      "step": 924500
    },
    {
      "epoch": 9.78711207330048,
      "eval_loss": 0.37409237027168274,
      "eval_runtime": 46.5488,
      "eval_samples_per_second": 3607.614,
      "eval_steps_per_second": 450.968,
      "step": 924500
    },
    {
      "epoch": 9.787641395080483,
      "grad_norm": 5.261361598968506,
      "learning_rate": 1.0830510268896887e-06,
      "loss": 0.6157,
      "step": 924550
    },
    {
      "epoch": 9.788170716860487,
      "grad_norm": 5.341963768005371,
      "learning_rate": 1.080404403980521e-06,
      "loss": 0.6188,
      "step": 924600
    },
    {
      "epoch": 9.78870003864049,
      "grad_norm": 4.894310474395752,
      "learning_rate": 1.077757781071353e-06,
      "loss": 0.6091,
      "step": 924650
    },
    {
      "epoch": 9.789229360420492,
      "grad_norm": 4.372671127319336,
      "learning_rate": 1.0751111581621851e-06,
      "loss": 0.6111,
      "step": 924700
    },
    {
      "epoch": 9.789758682200496,
      "grad_norm": 4.781657695770264,
      "learning_rate": 1.072464535253017e-06,
      "loss": 0.6166,
      "step": 924750
    },
    {
      "epoch": 9.7902880039805,
      "grad_norm": 4.658414363861084,
      "learning_rate": 1.0698179123438493e-06,
      "loss": 0.6169,
      "step": 924800
    },
    {
      "epoch": 9.790817325760504,
      "grad_norm": 3.984529495239258,
      "learning_rate": 1.0671712894346815e-06,
      "loss": 0.6137,
      "step": 924850
    },
    {
      "epoch": 9.791346647540506,
      "grad_norm": 4.817621231079102,
      "learning_rate": 1.0645246665255135e-06,
      "loss": 0.627,
      "step": 924900
    },
    {
      "epoch": 9.79187596932051,
      "grad_norm": 4.8356499671936035,
      "learning_rate": 1.0618780436163457e-06,
      "loss": 0.6219,
      "step": 924950
    },
    {
      "epoch": 9.792405291100513,
      "grad_norm": 4.853000164031982,
      "learning_rate": 1.0592314207071776e-06,
      "loss": 0.6185,
      "step": 925000
    },
    {
      "epoch": 9.792405291100513,
      "eval_loss": 0.3742469549179077,
      "eval_runtime": 46.7383,
      "eval_samples_per_second": 3592.985,
      "eval_steps_per_second": 449.139,
      "step": 925000
    },
    {
      "epoch": 9.792934612880517,
      "grad_norm": 4.567884922027588,
      "learning_rate": 1.0565847977980098e-06,
      "loss": 0.6129,
      "step": 925050
    },
    {
      "epoch": 9.793463934660519,
      "grad_norm": 4.914151191711426,
      "learning_rate": 1.0539381748888418e-06,
      "loss": 0.6345,
      "step": 925100
    },
    {
      "epoch": 9.793993256440523,
      "grad_norm": 4.792616367340088,
      "learning_rate": 1.051291551979674e-06,
      "loss": 0.6099,
      "step": 925150
    },
    {
      "epoch": 9.794522578220526,
      "grad_norm": 5.216616630554199,
      "learning_rate": 1.0486449290705062e-06,
      "loss": 0.6193,
      "step": 925200
    },
    {
      "epoch": 9.79505190000053,
      "grad_norm": 4.748982906341553,
      "learning_rate": 1.0459983061613382e-06,
      "loss": 0.6166,
      "step": 925250
    },
    {
      "epoch": 9.795581221780532,
      "grad_norm": 4.524771213531494,
      "learning_rate": 1.0433516832521704e-06,
      "loss": 0.6223,
      "step": 925300
    },
    {
      "epoch": 9.796110543560536,
      "grad_norm": 4.874495983123779,
      "learning_rate": 1.0407050603430024e-06,
      "loss": 0.6224,
      "step": 925350
    },
    {
      "epoch": 9.79663986534054,
      "grad_norm": 4.539829730987549,
      "learning_rate": 1.0380584374338346e-06,
      "loss": 0.6166,
      "step": 925400
    },
    {
      "epoch": 9.797169187120542,
      "grad_norm": 4.784095287322998,
      "learning_rate": 1.0354118145246668e-06,
      "loss": 0.6173,
      "step": 925450
    },
    {
      "epoch": 9.797698508900545,
      "grad_norm": 4.570013523101807,
      "learning_rate": 1.0327651916154985e-06,
      "loss": 0.6242,
      "step": 925500
    },
    {
      "epoch": 9.797698508900545,
      "eval_loss": 0.3740706443786621,
      "eval_runtime": 46.5435,
      "eval_samples_per_second": 3608.026,
      "eval_steps_per_second": 451.019,
      "step": 925500
    },
    {
      "epoch": 9.798227830680549,
      "grad_norm": 4.477725505828857,
      "learning_rate": 1.0301185687063307e-06,
      "loss": 0.6198,
      "step": 925550
    },
    {
      "epoch": 9.798757152460553,
      "grad_norm": 4.8882598876953125,
      "learning_rate": 1.0274719457971627e-06,
      "loss": 0.6194,
      "step": 925600
    },
    {
      "epoch": 9.799286474240555,
      "grad_norm": 4.696974277496338,
      "learning_rate": 1.024825322887995e-06,
      "loss": 0.6215,
      "step": 925650
    },
    {
      "epoch": 9.799815796020559,
      "grad_norm": 4.541239261627197,
      "learning_rate": 1.022178699978827e-06,
      "loss": 0.624,
      "step": 925700
    },
    {
      "epoch": 9.800345117800562,
      "grad_norm": 4.250430107116699,
      "learning_rate": 1.019532077069659e-06,
      "loss": 0.6071,
      "step": 925750
    },
    {
      "epoch": 9.800874439580566,
      "grad_norm": 4.875787734985352,
      "learning_rate": 1.0168854541604913e-06,
      "loss": 0.625,
      "step": 925800
    },
    {
      "epoch": 9.801403761360568,
      "grad_norm": 4.6794891357421875,
      "learning_rate": 1.0142388312513233e-06,
      "loss": 0.6075,
      "step": 925850
    },
    {
      "epoch": 9.801933083140572,
      "grad_norm": 4.651834487915039,
      "learning_rate": 1.0115922083421554e-06,
      "loss": 0.6217,
      "step": 925900
    },
    {
      "epoch": 9.802462404920576,
      "grad_norm": 4.190814971923828,
      "learning_rate": 1.0089455854329874e-06,
      "loss": 0.623,
      "step": 925950
    },
    {
      "epoch": 9.80299172670058,
      "grad_norm": 4.8916850090026855,
      "learning_rate": 1.0062989625238196e-06,
      "loss": 0.614,
      "step": 926000
    },
    {
      "epoch": 9.80299172670058,
      "eval_loss": 0.3737562894821167,
      "eval_runtime": 46.4928,
      "eval_samples_per_second": 3611.958,
      "eval_steps_per_second": 451.511,
      "step": 926000
    },
    {
      "epoch": 9.803521048480581,
      "grad_norm": 4.558448314666748,
      "learning_rate": 1.0037052720728352e-06,
      "loss": 0.6155,
      "step": 926050
    },
    {
      "epoch": 9.804050370260585,
      "grad_norm": 4.175949573516846,
      "learning_rate": 1.0010586491636672e-06,
      "loss": 0.6214,
      "step": 926100
    },
    {
      "epoch": 9.804579692040589,
      "grad_norm": 4.736935615539551,
      "learning_rate": 9.984120262544991e-07,
      "loss": 0.6272,
      "step": 926150
    },
    {
      "epoch": 9.80510901382059,
      "grad_norm": 4.54736328125,
      "learning_rate": 9.957654033453313e-07,
      "loss": 0.6163,
      "step": 926200
    },
    {
      "epoch": 9.805638335600595,
      "grad_norm": 4.546139717102051,
      "learning_rate": 9.931187804361635e-07,
      "loss": 0.6258,
      "step": 926250
    },
    {
      "epoch": 9.806167657380598,
      "grad_norm": 4.790271759033203,
      "learning_rate": 9.904721575269955e-07,
      "loss": 0.6133,
      "step": 926300
    },
    {
      "epoch": 9.806696979160602,
      "grad_norm": 4.827771186828613,
      "learning_rate": 9.878255346178277e-07,
      "loss": 0.6115,
      "step": 926350
    },
    {
      "epoch": 9.807226300940604,
      "grad_norm": 4.972311019897461,
      "learning_rate": 9.851789117086597e-07,
      "loss": 0.6215,
      "step": 926400
    },
    {
      "epoch": 9.807755622720608,
      "grad_norm": 4.70510721206665,
      "learning_rate": 9.825322887994919e-07,
      "loss": 0.615,
      "step": 926450
    },
    {
      "epoch": 9.808284944500612,
      "grad_norm": 4.846350193023682,
      "learning_rate": 9.798856658903239e-07,
      "loss": 0.6183,
      "step": 926500
    },
    {
      "epoch": 9.808284944500612,
      "eval_loss": 0.3738146424293518,
      "eval_runtime": 46.4773,
      "eval_samples_per_second": 3613.162,
      "eval_steps_per_second": 451.661,
      "step": 926500
    },
    {
      "epoch": 9.808814266280615,
      "grad_norm": 4.620067119598389,
      "learning_rate": 9.77239042981156e-07,
      "loss": 0.611,
      "step": 926550
    },
    {
      "epoch": 9.809343588060617,
      "grad_norm": 4.673370361328125,
      "learning_rate": 9.745924200719883e-07,
      "loss": 0.6216,
      "step": 926600
    },
    {
      "epoch": 9.809872909840621,
      "grad_norm": 4.539267063140869,
      "learning_rate": 9.719457971628202e-07,
      "loss": 0.6079,
      "step": 926650
    },
    {
      "epoch": 9.810402231620625,
      "grad_norm": 4.487610340118408,
      "learning_rate": 9.692991742536524e-07,
      "loss": 0.6281,
      "step": 926700
    },
    {
      "epoch": 9.810931553400629,
      "grad_norm": 4.299735069274902,
      "learning_rate": 9.666525513444844e-07,
      "loss": 0.6243,
      "step": 926750
    },
    {
      "epoch": 9.81146087518063,
      "grad_norm": 3.986536741256714,
      "learning_rate": 9.640059284353166e-07,
      "loss": 0.6116,
      "step": 926800
    },
    {
      "epoch": 9.811990196960634,
      "grad_norm": 4.5445427894592285,
      "learning_rate": 9.613593055261486e-07,
      "loss": 0.6157,
      "step": 926850
    },
    {
      "epoch": 9.812519518740638,
      "grad_norm": 4.3868255615234375,
      "learning_rate": 9.587126826169808e-07,
      "loss": 0.6225,
      "step": 926900
    },
    {
      "epoch": 9.81304884052064,
      "grad_norm": 4.679690837860107,
      "learning_rate": 9.56066059707813e-07,
      "loss": 0.6409,
      "step": 926950
    },
    {
      "epoch": 9.813578162300644,
      "grad_norm": 4.5742974281311035,
      "learning_rate": 9.53419436798645e-07,
      "loss": 0.6183,
      "step": 927000
    },
    {
      "epoch": 9.813578162300644,
      "eval_loss": 0.3738825023174286,
      "eval_runtime": 46.5053,
      "eval_samples_per_second": 3610.986,
      "eval_steps_per_second": 451.389,
      "step": 927000
    },
    {
      "epoch": 9.814107484080647,
      "grad_norm": 4.344459533691406,
      "learning_rate": 9.507728138894772e-07,
      "loss": 0.6261,
      "step": 927050
    },
    {
      "epoch": 9.814636805860651,
      "grad_norm": 4.691960334777832,
      "learning_rate": 9.481261909803092e-07,
      "loss": 0.6197,
      "step": 927100
    },
    {
      "epoch": 9.815166127640653,
      "grad_norm": 4.512759208679199,
      "learning_rate": 9.454795680711413e-07,
      "loss": 0.6216,
      "step": 927150
    },
    {
      "epoch": 9.815695449420657,
      "grad_norm": 4.825786113739014,
      "learning_rate": 9.428329451619734e-07,
      "loss": 0.6089,
      "step": 927200
    },
    {
      "epoch": 9.81622477120066,
      "grad_norm": 4.826486110687256,
      "learning_rate": 9.401863222528055e-07,
      "loss": 0.6134,
      "step": 927250
    },
    {
      "epoch": 9.816754092980664,
      "grad_norm": 4.351814270019531,
      "learning_rate": 9.375396993436376e-07,
      "loss": 0.6261,
      "step": 927300
    },
    {
      "epoch": 9.817283414760666,
      "grad_norm": 4.776158809661865,
      "learning_rate": 9.348930764344698e-07,
      "loss": 0.6278,
      "step": 927350
    },
    {
      "epoch": 9.81781273654067,
      "grad_norm": 4.484311103820801,
      "learning_rate": 9.322464535253017e-07,
      "loss": 0.6122,
      "step": 927400
    },
    {
      "epoch": 9.818342058320674,
      "grad_norm": 4.953902244567871,
      "learning_rate": 9.295998306161338e-07,
      "loss": 0.6295,
      "step": 927450
    },
    {
      "epoch": 9.818871380100678,
      "grad_norm": 5.046263217926025,
      "learning_rate": 9.269532077069658e-07,
      "loss": 0.6179,
      "step": 927500
    },
    {
      "epoch": 9.818871380100678,
      "eval_loss": 0.3739013373851776,
      "eval_runtime": 46.5266,
      "eval_samples_per_second": 3609.334,
      "eval_steps_per_second": 451.183,
      "step": 927500
    },
    {
      "epoch": 9.81940070188068,
      "grad_norm": 5.075521945953369,
      "learning_rate": 9.24306584797798e-07,
      "loss": 0.6159,
      "step": 927550
    },
    {
      "epoch": 9.819930023660683,
      "grad_norm": 4.401238441467285,
      "learning_rate": 9.216599618886301e-07,
      "loss": 0.6124,
      "step": 927600
    },
    {
      "epoch": 9.820459345440687,
      "grad_norm": 5.2110066413879395,
      "learning_rate": 9.190133389794622e-07,
      "loss": 0.6142,
      "step": 927650
    },
    {
      "epoch": 9.82098866722069,
      "grad_norm": 4.4851393699646,
      "learning_rate": 9.163667160702943e-07,
      "loss": 0.6149,
      "step": 927700
    },
    {
      "epoch": 9.821517989000693,
      "grad_norm": 4.778995037078857,
      "learning_rate": 9.137200931611264e-07,
      "loss": 0.6188,
      "step": 927750
    },
    {
      "epoch": 9.822047310780697,
      "grad_norm": 4.573957443237305,
      "learning_rate": 9.110734702519585e-07,
      "loss": 0.6198,
      "step": 927800
    },
    {
      "epoch": 9.8225766325607,
      "grad_norm": 4.49100923538208,
      "learning_rate": 9.084268473427906e-07,
      "loss": 0.6152,
      "step": 927850
    },
    {
      "epoch": 9.823105954340702,
      "grad_norm": 4.513728618621826,
      "learning_rate": 9.057802244336228e-07,
      "loss": 0.6131,
      "step": 927900
    },
    {
      "epoch": 9.823635276120706,
      "grad_norm": 4.552241802215576,
      "learning_rate": 9.031336015244548e-07,
      "loss": 0.6109,
      "step": 927950
    },
    {
      "epoch": 9.82416459790071,
      "grad_norm": 4.370370864868164,
      "learning_rate": 9.004869786152869e-07,
      "loss": 0.6261,
      "step": 928000
    },
    {
      "epoch": 9.82416459790071,
      "eval_loss": 0.373745858669281,
      "eval_runtime": 46.5412,
      "eval_samples_per_second": 3608.2,
      "eval_steps_per_second": 451.041,
      "step": 928000
    },
    {
      "epoch": 9.824693919680714,
      "grad_norm": 4.339727878570557,
      "learning_rate": 8.978932881643023e-07,
      "loss": 0.6154,
      "step": 928050
    },
    {
      "epoch": 9.825223241460716,
      "grad_norm": 4.606788635253906,
      "learning_rate": 8.952466652551344e-07,
      "loss": 0.6198,
      "step": 928100
    },
    {
      "epoch": 9.82575256324072,
      "grad_norm": 4.639175891876221,
      "learning_rate": 8.926000423459666e-07,
      "loss": 0.6127,
      "step": 928150
    },
    {
      "epoch": 9.826281885020723,
      "grad_norm": 4.54917049407959,
      "learning_rate": 8.899534194367987e-07,
      "loss": 0.6038,
      "step": 928200
    },
    {
      "epoch": 9.826811206800727,
      "grad_norm": 4.956095218658447,
      "learning_rate": 8.873067965276307e-07,
      "loss": 0.6236,
      "step": 928250
    },
    {
      "epoch": 9.827340528580729,
      "grad_norm": 4.183495998382568,
      "learning_rate": 8.846601736184628e-07,
      "loss": 0.6106,
      "step": 928300
    },
    {
      "epoch": 9.827869850360733,
      "grad_norm": 4.594521999359131,
      "learning_rate": 8.820135507092949e-07,
      "loss": 0.6254,
      "step": 928350
    },
    {
      "epoch": 9.828399172140736,
      "grad_norm": 4.731340408325195,
      "learning_rate": 8.79366927800127e-07,
      "loss": 0.6043,
      "step": 928400
    },
    {
      "epoch": 9.828928493920738,
      "grad_norm": 4.8983893394470215,
      "learning_rate": 8.767203048909592e-07,
      "loss": 0.622,
      "step": 928450
    },
    {
      "epoch": 9.829457815700742,
      "grad_norm": 4.540202617645264,
      "learning_rate": 8.740736819817913e-07,
      "loss": 0.609,
      "step": 928500
    },
    {
      "epoch": 9.829457815700742,
      "eval_loss": 0.3737766444683075,
      "eval_runtime": 46.4819,
      "eval_samples_per_second": 3612.803,
      "eval_steps_per_second": 451.617,
      "step": 928500
    },
    {
      "epoch": 9.829987137480746,
      "grad_norm": 4.447973728179932,
      "learning_rate": 8.714270590726234e-07,
      "loss": 0.6262,
      "step": 928550
    },
    {
      "epoch": 9.83051645926075,
      "grad_norm": 4.830338478088379,
      "learning_rate": 8.687804361634555e-07,
      "loss": 0.6215,
      "step": 928600
    },
    {
      "epoch": 9.831045781040752,
      "grad_norm": 4.58554220199585,
      "learning_rate": 8.661338132542876e-07,
      "loss": 0.6196,
      "step": 928650
    },
    {
      "epoch": 9.831575102820755,
      "grad_norm": 4.205914497375488,
      "learning_rate": 8.634871903451196e-07,
      "loss": 0.6177,
      "step": 928700
    },
    {
      "epoch": 9.83210442460076,
      "grad_norm": 4.936895847320557,
      "learning_rate": 8.608405674359518e-07,
      "loss": 0.6124,
      "step": 928750
    },
    {
      "epoch": 9.832633746380763,
      "grad_norm": 4.78381872177124,
      "learning_rate": 8.581939445267839e-07,
      "loss": 0.6111,
      "step": 928800
    },
    {
      "epoch": 9.833163068160765,
      "grad_norm": 5.274291515350342,
      "learning_rate": 8.55547321617616e-07,
      "loss": 0.6242,
      "step": 928850
    },
    {
      "epoch": 9.833692389940769,
      "grad_norm": 5.494823455810547,
      "learning_rate": 8.529006987084481e-07,
      "loss": 0.6302,
      "step": 928900
    },
    {
      "epoch": 9.834221711720772,
      "grad_norm": 4.70259428024292,
      "learning_rate": 8.502540757992802e-07,
      "loss": 0.6162,
      "step": 928950
    },
    {
      "epoch": 9.834751033500776,
      "grad_norm": 4.444201469421387,
      "learning_rate": 8.476074528901123e-07,
      "loss": 0.6223,
      "step": 929000
    },
    {
      "epoch": 9.834751033500776,
      "eval_loss": 0.3736704885959625,
      "eval_runtime": 46.4436,
      "eval_samples_per_second": 3615.781,
      "eval_steps_per_second": 451.989,
      "step": 929000
    },
    {
      "epoch": 9.835280355280778,
      "grad_norm": 4.763588905334473,
      "learning_rate": 8.449608299809444e-07,
      "loss": 0.6233,
      "step": 929050
    },
    {
      "epoch": 9.835809677060782,
      "grad_norm": 4.839568614959717,
      "learning_rate": 8.423142070717766e-07,
      "loss": 0.625,
      "step": 929100
    },
    {
      "epoch": 9.836338998840786,
      "grad_norm": 4.5748090744018555,
      "learning_rate": 8.396675841626086e-07,
      "loss": 0.6205,
      "step": 929150
    },
    {
      "epoch": 9.836868320620788,
      "grad_norm": 4.331343650817871,
      "learning_rate": 8.370209612534407e-07,
      "loss": 0.608,
      "step": 929200
    },
    {
      "epoch": 9.837397642400791,
      "grad_norm": 4.6706719398498535,
      "learning_rate": 8.343743383442728e-07,
      "loss": 0.621,
      "step": 929250
    },
    {
      "epoch": 9.837926964180795,
      "grad_norm": 4.993180751800537,
      "learning_rate": 8.317277154351048e-07,
      "loss": 0.6286,
      "step": 929300
    },
    {
      "epoch": 9.838456285960799,
      "grad_norm": 4.965202808380127,
      "learning_rate": 8.290810925259369e-07,
      "loss": 0.6235,
      "step": 929350
    },
    {
      "epoch": 9.8389856077408,
      "grad_norm": 4.493574142456055,
      "learning_rate": 8.26434469616769e-07,
      "loss": 0.6124,
      "step": 929400
    },
    {
      "epoch": 9.839514929520805,
      "grad_norm": 4.389928817749023,
      "learning_rate": 8.237878467076011e-07,
      "loss": 0.6152,
      "step": 929450
    },
    {
      "epoch": 9.840044251300808,
      "grad_norm": 4.749685764312744,
      "learning_rate": 8.211412237984332e-07,
      "loss": 0.6276,
      "step": 929500
    },
    {
      "epoch": 9.840044251300808,
      "eval_loss": 0.37356218695640564,
      "eval_runtime": 46.534,
      "eval_samples_per_second": 3608.756,
      "eval_steps_per_second": 451.111,
      "step": 929500
    },
    {
      "epoch": 9.840573573080812,
      "grad_norm": 5.038747310638428,
      "learning_rate": 8.184946008892652e-07,
      "loss": 0.6282,
      "step": 929550
    },
    {
      "epoch": 9.841102894860814,
      "grad_norm": 4.490084171295166,
      "learning_rate": 8.158479779800974e-07,
      "loss": 0.613,
      "step": 929600
    },
    {
      "epoch": 9.841632216640818,
      "grad_norm": 4.403350830078125,
      "learning_rate": 8.132013550709295e-07,
      "loss": 0.6265,
      "step": 929650
    },
    {
      "epoch": 9.842161538420822,
      "grad_norm": 4.492899417877197,
      "learning_rate": 8.105547321617616e-07,
      "loss": 0.6153,
      "step": 929700
    },
    {
      "epoch": 9.842690860200825,
      "grad_norm": 4.425887107849121,
      "learning_rate": 8.079081092525937e-07,
      "loss": 0.6148,
      "step": 929750
    },
    {
      "epoch": 9.843220181980827,
      "grad_norm": 4.9608283042907715,
      "learning_rate": 8.052614863434258e-07,
      "loss": 0.6028,
      "step": 929800
    },
    {
      "epoch": 9.843749503760831,
      "grad_norm": 4.852069854736328,
      "learning_rate": 8.026148634342579e-07,
      "loss": 0.6124,
      "step": 929850
    },
    {
      "epoch": 9.844278825540835,
      "grad_norm": 4.616488456726074,
      "learning_rate": 7.9996824052509e-07,
      "loss": 0.6103,
      "step": 929900
    },
    {
      "epoch": 9.844808147320839,
      "grad_norm": 4.883191108703613,
      "learning_rate": 7.973216176159222e-07,
      "loss": 0.6246,
      "step": 929950
    },
    {
      "epoch": 9.84533746910084,
      "grad_norm": 4.381685256958008,
      "learning_rate": 7.946749947067543e-07,
      "loss": 0.6193,
      "step": 930000
    },
    {
      "epoch": 9.84533746910084,
      "eval_loss": 0.37360692024230957,
      "eval_runtime": 46.4161,
      "eval_samples_per_second": 3617.923,
      "eval_steps_per_second": 452.257,
      "step": 930000
    },
    {
      "epoch": 9.845866790880844,
      "grad_norm": 4.885616302490234,
      "learning_rate": 7.920813042557696e-07,
      "loss": 0.6193,
      "step": 930050
    },
    {
      "epoch": 9.846396112660848,
      "grad_norm": 4.849594593048096,
      "learning_rate": 7.894346813466017e-07,
      "loss": 0.6229,
      "step": 930100
    },
    {
      "epoch": 9.84692543444085,
      "grad_norm": 4.890673637390137,
      "learning_rate": 7.867880584374338e-07,
      "loss": 0.6219,
      "step": 930150
    },
    {
      "epoch": 9.847454756220854,
      "grad_norm": 4.991997718811035,
      "learning_rate": 7.84141435528266e-07,
      "loss": 0.6226,
      "step": 930200
    },
    {
      "epoch": 9.847984078000858,
      "grad_norm": 3.9903361797332764,
      "learning_rate": 7.81494812619098e-07,
      "loss": 0.6234,
      "step": 930250
    },
    {
      "epoch": 9.848513399780861,
      "grad_norm": 4.775938510894775,
      "learning_rate": 7.788481897099301e-07,
      "loss": 0.6229,
      "step": 930300
    },
    {
      "epoch": 9.849042721560863,
      "grad_norm": 4.829817295074463,
      "learning_rate": 7.762015668007622e-07,
      "loss": 0.6143,
      "step": 930350
    },
    {
      "epoch": 9.849572043340867,
      "grad_norm": 4.467492580413818,
      "learning_rate": 7.735549438915943e-07,
      "loss": 0.6038,
      "step": 930400
    },
    {
      "epoch": 9.85010136512087,
      "grad_norm": 5.073861598968506,
      "learning_rate": 7.709083209824264e-07,
      "loss": 0.6266,
      "step": 930450
    },
    {
      "epoch": 9.850630686900875,
      "grad_norm": 5.2205352783203125,
      "learning_rate": 7.682616980732586e-07,
      "loss": 0.6096,
      "step": 930500
    },
    {
      "epoch": 9.850630686900875,
      "eval_loss": 0.3734869360923767,
      "eval_runtime": 46.4295,
      "eval_samples_per_second": 3616.884,
      "eval_steps_per_second": 452.127,
      "step": 930500
    },
    {
      "epoch": 9.851160008680877,
      "grad_norm": 4.032259941101074,
      "learning_rate": 7.656150751640907e-07,
      "loss": 0.6186,
      "step": 930550
    },
    {
      "epoch": 9.85168933046088,
      "grad_norm": 5.051087379455566,
      "learning_rate": 7.629684522549228e-07,
      "loss": 0.603,
      "step": 930600
    },
    {
      "epoch": 9.852218652240884,
      "grad_norm": 5.319580554962158,
      "learning_rate": 7.603218293457549e-07,
      "loss": 0.6276,
      "step": 930650
    },
    {
      "epoch": 9.852747974020888,
      "grad_norm": 5.16030216217041,
      "learning_rate": 7.57675206436587e-07,
      "loss": 0.6184,
      "step": 930700
    },
    {
      "epoch": 9.85327729580089,
      "grad_norm": 4.531435489654541,
      "learning_rate": 7.55028583527419e-07,
      "loss": 0.6255,
      "step": 930750
    },
    {
      "epoch": 9.853806617580894,
      "grad_norm": 4.824277877807617,
      "learning_rate": 7.523819606182512e-07,
      "loss": 0.6185,
      "step": 930800
    },
    {
      "epoch": 9.854335939360897,
      "grad_norm": 4.937254428863525,
      "learning_rate": 7.497353377090833e-07,
      "loss": 0.6231,
      "step": 930850
    },
    {
      "epoch": 9.8548652611409,
      "grad_norm": 4.742501735687256,
      "learning_rate": 7.470887147999153e-07,
      "loss": 0.6221,
      "step": 930900
    },
    {
      "epoch": 9.855394582920903,
      "grad_norm": 4.5550103187561035,
      "learning_rate": 7.444420918907474e-07,
      "loss": 0.6222,
      "step": 930950
    },
    {
      "epoch": 9.855923904700907,
      "grad_norm": 4.747467994689941,
      "learning_rate": 7.417954689815795e-07,
      "loss": 0.6157,
      "step": 931000
    },
    {
      "epoch": 9.855923904700907,
      "eval_loss": 0.3736448287963867,
      "eval_runtime": 46.4173,
      "eval_samples_per_second": 3617.829,
      "eval_steps_per_second": 452.245,
      "step": 931000
    },
    {
      "epoch": 9.85645322648091,
      "grad_norm": 4.164582252502441,
      "learning_rate": 7.391488460724116e-07,
      "loss": 0.615,
      "step": 931050
    },
    {
      "epoch": 9.856982548260913,
      "grad_norm": 4.446208477020264,
      "learning_rate": 7.365022231632438e-07,
      "loss": 0.6186,
      "step": 931100
    },
    {
      "epoch": 9.857511870040916,
      "grad_norm": 4.545721530914307,
      "learning_rate": 7.338556002540759e-07,
      "loss": 0.6087,
      "step": 931150
    },
    {
      "epoch": 9.85804119182092,
      "grad_norm": 4.196794509887695,
      "learning_rate": 7.312089773449079e-07,
      "loss": 0.6186,
      "step": 931200
    },
    {
      "epoch": 9.858570513600924,
      "grad_norm": 4.693439483642578,
      "learning_rate": 7.2856235443574e-07,
      "loss": 0.6214,
      "step": 931250
    },
    {
      "epoch": 9.859099835380926,
      "grad_norm": 4.413984298706055,
      "learning_rate": 7.259157315265721e-07,
      "loss": 0.6179,
      "step": 931300
    },
    {
      "epoch": 9.85962915716093,
      "grad_norm": 4.705012798309326,
      "learning_rate": 7.232691086174042e-07,
      "loss": 0.6177,
      "step": 931350
    },
    {
      "epoch": 9.860158478940933,
      "grad_norm": 4.615414142608643,
      "learning_rate": 7.206224857082364e-07,
      "loss": 0.6114,
      "step": 931400
    },
    {
      "epoch": 9.860687800720937,
      "grad_norm": 4.724401473999023,
      "learning_rate": 7.179758627990685e-07,
      "loss": 0.6026,
      "step": 931450
    },
    {
      "epoch": 9.861217122500939,
      "grad_norm": 5.005373001098633,
      "learning_rate": 7.153292398899005e-07,
      "loss": 0.616,
      "step": 931500
    },
    {
      "epoch": 9.861217122500939,
      "eval_loss": 0.37352317571640015,
      "eval_runtime": 46.4539,
      "eval_samples_per_second": 3614.98,
      "eval_steps_per_second": 451.889,
      "step": 931500
    },
    {
      "epoch": 9.861746444280943,
      "grad_norm": 4.889093399047852,
      "learning_rate": 7.126826169807326e-07,
      "loss": 0.6239,
      "step": 931550
    },
    {
      "epoch": 9.862275766060947,
      "grad_norm": 4.471327304840088,
      "learning_rate": 7.100359940715646e-07,
      "loss": 0.6243,
      "step": 931600
    },
    {
      "epoch": 9.862805087840949,
      "grad_norm": 5.072474479675293,
      "learning_rate": 7.073893711623968e-07,
      "loss": 0.6296,
      "step": 931650
    },
    {
      "epoch": 9.863334409620952,
      "grad_norm": 4.396835803985596,
      "learning_rate": 7.047427482532289e-07,
      "loss": 0.6222,
      "step": 931700
    },
    {
      "epoch": 9.863863731400956,
      "grad_norm": 4.657288074493408,
      "learning_rate": 7.021490578022444e-07,
      "loss": 0.6178,
      "step": 931750
    },
    {
      "epoch": 9.86439305318096,
      "grad_norm": 4.732025146484375,
      "learning_rate": 6.995024348930765e-07,
      "loss": 0.616,
      "step": 931800
    },
    {
      "epoch": 9.864922374960962,
      "grad_norm": 4.542253017425537,
      "learning_rate": 6.968558119839086e-07,
      "loss": 0.6222,
      "step": 931850
    },
    {
      "epoch": 9.865451696740966,
      "grad_norm": 4.472775936126709,
      "learning_rate": 6.942091890747406e-07,
      "loss": 0.6138,
      "step": 931900
    },
    {
      "epoch": 9.86598101852097,
      "grad_norm": 4.288439750671387,
      "learning_rate": 6.915625661655727e-07,
      "loss": 0.6156,
      "step": 931950
    },
    {
      "epoch": 9.866510340300973,
      "grad_norm": 4.970592498779297,
      "learning_rate": 6.889159432564049e-07,
      "loss": 0.627,
      "step": 932000
    },
    {
      "epoch": 9.866510340300973,
      "eval_loss": 0.37353408336639404,
      "eval_runtime": 46.4499,
      "eval_samples_per_second": 3615.289,
      "eval_steps_per_second": 451.927,
      "step": 932000
    },
    {
      "epoch": 9.867039662080975,
      "grad_norm": 4.80475378036499,
      "learning_rate": 6.86269320347237e-07,
      "loss": 0.6203,
      "step": 932050
    },
    {
      "epoch": 9.867568983860979,
      "grad_norm": 4.9077348709106445,
      "learning_rate": 6.836226974380691e-07,
      "loss": 0.6228,
      "step": 932100
    },
    {
      "epoch": 9.868098305640983,
      "grad_norm": 4.331902027130127,
      "learning_rate": 6.809760745289011e-07,
      "loss": 0.6043,
      "step": 932150
    },
    {
      "epoch": 9.868627627420986,
      "grad_norm": 4.478207111358643,
      "learning_rate": 6.783294516197332e-07,
      "loss": 0.617,
      "step": 932200
    },
    {
      "epoch": 9.869156949200988,
      "grad_norm": 4.422099590301514,
      "learning_rate": 6.756828287105654e-07,
      "loss": 0.6214,
      "step": 932250
    },
    {
      "epoch": 9.869686270980992,
      "grad_norm": 4.836231708526611,
      "learning_rate": 6.730362058013975e-07,
      "loss": 0.602,
      "step": 932300
    },
    {
      "epoch": 9.870215592760996,
      "grad_norm": 4.992692470550537,
      "learning_rate": 6.703895828922295e-07,
      "loss": 0.6279,
      "step": 932350
    },
    {
      "epoch": 9.870744914541,
      "grad_norm": 4.5591278076171875,
      "learning_rate": 6.677429599830616e-07,
      "loss": 0.6077,
      "step": 932400
    },
    {
      "epoch": 9.871274236321002,
      "grad_norm": 4.929044246673584,
      "learning_rate": 6.650963370738937e-07,
      "loss": 0.6124,
      "step": 932450
    },
    {
      "epoch": 9.871803558101005,
      "grad_norm": 4.4458231925964355,
      "learning_rate": 6.624497141647258e-07,
      "loss": 0.6083,
      "step": 932500
    },
    {
      "epoch": 9.871803558101005,
      "eval_loss": 0.37348413467407227,
      "eval_runtime": 46.4639,
      "eval_samples_per_second": 3614.206,
      "eval_steps_per_second": 451.792,
      "step": 932500
    },
    {
      "epoch": 9.872332879881009,
      "grad_norm": 4.527674674987793,
      "learning_rate": 6.59803091255558e-07,
      "loss": 0.6213,
      "step": 932550
    },
    {
      "epoch": 9.872862201661011,
      "grad_norm": 4.687724590301514,
      "learning_rate": 6.571564683463901e-07,
      "loss": 0.6202,
      "step": 932600
    },
    {
      "epoch": 9.873391523441015,
      "grad_norm": 4.680500030517578,
      "learning_rate": 6.545098454372222e-07,
      "loss": 0.6121,
      "step": 932650
    },
    {
      "epoch": 9.873920845221019,
      "grad_norm": 4.9546284675598145,
      "learning_rate": 6.518632225280543e-07,
      "loss": 0.6225,
      "step": 932700
    },
    {
      "epoch": 9.874450167001022,
      "grad_norm": 4.478308200836182,
      "learning_rate": 6.492165996188864e-07,
      "loss": 0.6122,
      "step": 932750
    },
    {
      "epoch": 9.874979488781024,
      "grad_norm": 4.64857292175293,
      "learning_rate": 6.465699767097184e-07,
      "loss": 0.6272,
      "step": 932800
    },
    {
      "epoch": 9.875508810561028,
      "grad_norm": 4.8489484786987305,
      "learning_rate": 6.439233538005505e-07,
      "loss": 0.6244,
      "step": 932850
    },
    {
      "epoch": 9.876038132341032,
      "grad_norm": 4.4348063468933105,
      "learning_rate": 6.412767308913826e-07,
      "loss": 0.6101,
      "step": 932900
    },
    {
      "epoch": 9.876567454121036,
      "grad_norm": 4.435031414031982,
      "learning_rate": 6.386301079822147e-07,
      "loss": 0.6162,
      "step": 932950
    },
    {
      "epoch": 9.877096775901038,
      "grad_norm": 5.455415725708008,
      "learning_rate": 6.359834850730468e-07,
      "loss": 0.6214,
      "step": 933000
    },
    {
      "epoch": 9.877096775901038,
      "eval_loss": 0.3734780251979828,
      "eval_runtime": 46.466,
      "eval_samples_per_second": 3614.044,
      "eval_steps_per_second": 451.772,
      "step": 933000
    },
    {
      "epoch": 9.877626097681041,
      "grad_norm": 4.400952339172363,
      "learning_rate": 6.333368621638789e-07,
      "loss": 0.6066,
      "step": 933050
    },
    {
      "epoch": 9.878155419461045,
      "grad_norm": 4.6006927490234375,
      "learning_rate": 6.30690239254711e-07,
      "loss": 0.6301,
      "step": 933100
    },
    {
      "epoch": 9.878684741241049,
      "grad_norm": 4.270512580871582,
      "learning_rate": 6.280436163455432e-07,
      "loss": 0.6183,
      "step": 933150
    },
    {
      "epoch": 9.87921406302105,
      "grad_norm": 4.154986381530762,
      "learning_rate": 6.253969934363753e-07,
      "loss": 0.6181,
      "step": 933200
    },
    {
      "epoch": 9.879743384801055,
      "grad_norm": 4.382432460784912,
      "learning_rate": 6.227503705272073e-07,
      "loss": 0.6149,
      "step": 933250
    },
    {
      "epoch": 9.880272706581058,
      "grad_norm": 5.197818279266357,
      "learning_rate": 6.201037476180394e-07,
      "loss": 0.6172,
      "step": 933300
    },
    {
      "epoch": 9.88080202836106,
      "grad_norm": 4.880760192871094,
      "learning_rate": 6.174571247088715e-07,
      "loss": 0.6237,
      "step": 933350
    },
    {
      "epoch": 9.881331350141064,
      "grad_norm": 4.6448822021484375,
      "learning_rate": 6.148105017997036e-07,
      "loss": 0.629,
      "step": 933400
    },
    {
      "epoch": 9.881860671921068,
      "grad_norm": 4.310266017913818,
      "learning_rate": 6.121638788905357e-07,
      "loss": 0.6121,
      "step": 933450
    },
    {
      "epoch": 9.882389993701072,
      "grad_norm": 4.693395614624023,
      "learning_rate": 6.095172559813678e-07,
      "loss": 0.6126,
      "step": 933500
    },
    {
      "epoch": 9.882389993701072,
      "eval_loss": 0.37339264154434204,
      "eval_runtime": 46.4247,
      "eval_samples_per_second": 3617.255,
      "eval_steps_per_second": 452.173,
      "step": 933500
    },
    {
      "epoch": 9.882919315481073,
      "grad_norm": 4.810797214508057,
      "learning_rate": 6.068706330721999e-07,
      "loss": 0.6237,
      "step": 933550
    },
    {
      "epoch": 9.883448637261077,
      "grad_norm": 4.967119216918945,
      "learning_rate": 6.04224010163032e-07,
      "loss": 0.6146,
      "step": 933600
    },
    {
      "epoch": 9.883977959041081,
      "grad_norm": 4.908971786499023,
      "learning_rate": 6.01577387253864e-07,
      "loss": 0.6157,
      "step": 933650
    },
    {
      "epoch": 9.884507280821085,
      "grad_norm": 4.409801959991455,
      "learning_rate": 5.989307643446962e-07,
      "loss": 0.6165,
      "step": 933700
    },
    {
      "epoch": 9.885036602601087,
      "grad_norm": 4.206611633300781,
      "learning_rate": 5.962841414355283e-07,
      "loss": 0.6134,
      "step": 933750
    },
    {
      "epoch": 9.88556592438109,
      "grad_norm": 4.665655136108398,
      "learning_rate": 5.936375185263604e-07,
      "loss": 0.6228,
      "step": 933800
    },
    {
      "epoch": 9.886095246161094,
      "grad_norm": 4.734320640563965,
      "learning_rate": 5.909908956171925e-07,
      "loss": 0.6173,
      "step": 933850
    },
    {
      "epoch": 9.886624567941098,
      "grad_norm": 4.395980358123779,
      "learning_rate": 5.883442727080246e-07,
      "loss": 0.6126,
      "step": 933900
    },
    {
      "epoch": 9.8871538897211,
      "grad_norm": 4.447957992553711,
      "learning_rate": 5.856976497988567e-07,
      "loss": 0.6193,
      "step": 933950
    },
    {
      "epoch": 9.887683211501104,
      "grad_norm": 4.979702472686768,
      "learning_rate": 5.830510268896888e-07,
      "loss": 0.6177,
      "step": 934000
    },
    {
      "epoch": 9.887683211501104,
      "eval_loss": 0.37345537543296814,
      "eval_runtime": 46.5228,
      "eval_samples_per_second": 3609.629,
      "eval_steps_per_second": 451.22,
      "step": 934000
    },
    {
      "epoch": 9.888212533281107,
      "grad_norm": 4.412391662597656,
      "learning_rate": 5.804044039805209e-07,
      "loss": 0.6081,
      "step": 934050
    },
    {
      "epoch": 9.88874185506111,
      "grad_norm": 4.721763610839844,
      "learning_rate": 5.77757781071353e-07,
      "loss": 0.6185,
      "step": 934100
    },
    {
      "epoch": 9.889271176841113,
      "grad_norm": 4.48455286026001,
      "learning_rate": 5.75111158162185e-07,
      "loss": 0.6264,
      "step": 934150
    },
    {
      "epoch": 9.889800498621117,
      "grad_norm": 4.38735818862915,
      "learning_rate": 5.724645352530171e-07,
      "loss": 0.6136,
      "step": 934200
    },
    {
      "epoch": 9.89032982040112,
      "grad_norm": 4.587900638580322,
      "learning_rate": 5.698179123438492e-07,
      "loss": 0.6114,
      "step": 934250
    },
    {
      "epoch": 9.890859142181123,
      "grad_norm": 4.9535040855407715,
      "learning_rate": 5.671712894346814e-07,
      "loss": 0.6257,
      "step": 934300
    },
    {
      "epoch": 9.891388463961126,
      "grad_norm": 4.384387016296387,
      "learning_rate": 5.645246665255135e-07,
      "loss": 0.6202,
      "step": 934350
    },
    {
      "epoch": 9.89191778574113,
      "grad_norm": 4.552942276000977,
      "learning_rate": 5.618780436163456e-07,
      "loss": 0.6157,
      "step": 934400
    },
    {
      "epoch": 9.892447107521134,
      "grad_norm": 4.973605155944824,
      "learning_rate": 5.592314207071777e-07,
      "loss": 0.6286,
      "step": 934450
    },
    {
      "epoch": 9.892976429301136,
      "grad_norm": 4.498077869415283,
      "learning_rate": 5.565847977980098e-07,
      "loss": 0.6098,
      "step": 934500
    },
    {
      "epoch": 9.892976429301136,
      "eval_loss": 0.3734318017959595,
      "eval_runtime": 46.563,
      "eval_samples_per_second": 3606.509,
      "eval_steps_per_second": 450.83,
      "step": 934500
    },
    {
      "epoch": 9.89350575108114,
      "grad_norm": 5.26944637298584,
      "learning_rate": 5.539381748888418e-07,
      "loss": 0.6111,
      "step": 934550
    },
    {
      "epoch": 9.894035072861143,
      "grad_norm": 4.378553867340088,
      "learning_rate": 5.51291551979674e-07,
      "loss": 0.6159,
      "step": 934600
    },
    {
      "epoch": 9.894564394641147,
      "grad_norm": 4.746433734893799,
      "learning_rate": 5.486449290705061e-07,
      "loss": 0.6143,
      "step": 934650
    },
    {
      "epoch": 9.89509371642115,
      "grad_norm": 4.423202991485596,
      "learning_rate": 5.459983061613381e-07,
      "loss": 0.6146,
      "step": 934700
    },
    {
      "epoch": 9.895623038201153,
      "grad_norm": 4.437534809112549,
      "learning_rate": 5.433516832521702e-07,
      "loss": 0.6208,
      "step": 934750
    },
    {
      "epoch": 9.896152359981157,
      "grad_norm": 4.529347896575928,
      "learning_rate": 5.407050603430023e-07,
      "loss": 0.614,
      "step": 934800
    },
    {
      "epoch": 9.896681681761159,
      "grad_norm": 4.443145275115967,
      "learning_rate": 5.380584374338345e-07,
      "loss": 0.6105,
      "step": 934850
    },
    {
      "epoch": 9.897211003541162,
      "grad_norm": 4.227534770965576,
      "learning_rate": 5.354118145246666e-07,
      "loss": 0.6087,
      "step": 934900
    },
    {
      "epoch": 9.897740325321166,
      "grad_norm": 4.920412063598633,
      "learning_rate": 5.327651916154987e-07,
      "loss": 0.6259,
      "step": 934950
    },
    {
      "epoch": 9.89826964710117,
      "grad_norm": 4.629980564117432,
      "learning_rate": 5.301185687063307e-07,
      "loss": 0.6248,
      "step": 935000
    },
    {
      "epoch": 9.89826964710117,
      "eval_loss": 0.3733774721622467,
      "eval_runtime": 46.5192,
      "eval_samples_per_second": 3609.905,
      "eval_steps_per_second": 451.254,
      "step": 935000
    },
    {
      "epoch": 9.898798968881172,
      "grad_norm": 4.736262321472168,
      "learning_rate": 5.274719457971628e-07,
      "loss": 0.6177,
      "step": 935050
    },
    {
      "epoch": 9.899328290661176,
      "grad_norm": 4.585631370544434,
      "learning_rate": 5.248253228879949e-07,
      "loss": 0.6166,
      "step": 935100
    },
    {
      "epoch": 9.89985761244118,
      "grad_norm": 4.734321594238281,
      "learning_rate": 5.22178699978827e-07,
      "loss": 0.627,
      "step": 935150
    },
    {
      "epoch": 9.900386934221183,
      "grad_norm": 4.097735404968262,
      "learning_rate": 5.195320770696592e-07,
      "loss": 0.6085,
      "step": 935200
    },
    {
      "epoch": 9.900916256001185,
      "grad_norm": 4.515817642211914,
      "learning_rate": 5.168854541604913e-07,
      "loss": 0.6174,
      "step": 935250
    },
    {
      "epoch": 9.901445577781189,
      "grad_norm": 4.566098690032959,
      "learning_rate": 5.142388312513234e-07,
      "loss": 0.6191,
      "step": 935300
    },
    {
      "epoch": 9.901974899561193,
      "grad_norm": 4.246944427490234,
      "learning_rate": 5.115922083421554e-07,
      "loss": 0.627,
      "step": 935350
    },
    {
      "epoch": 9.902504221341196,
      "grad_norm": 4.857122898101807,
      "learning_rate": 5.089455854329875e-07,
      "loss": 0.6167,
      "step": 935400
    },
    {
      "epoch": 9.903033543121198,
      "grad_norm": 4.54794979095459,
      "learning_rate": 5.062989625238196e-07,
      "loss": 0.6257,
      "step": 935450
    },
    {
      "epoch": 9.903562864901202,
      "grad_norm": 5.1297831535339355,
      "learning_rate": 5.036523396146517e-07,
      "loss": 0.6175,
      "step": 935500
    },
    {
      "epoch": 9.903562864901202,
      "eval_loss": 0.373407244682312,
      "eval_runtime": 46.8092,
      "eval_samples_per_second": 3587.545,
      "eval_steps_per_second": 448.459,
      "step": 935500
    },
    {
      "epoch": 9.904092186681206,
      "grad_norm": 4.702045917510986,
      "learning_rate": 5.010057167054838e-07,
      "loss": 0.6078,
      "step": 935550
    },
    {
      "epoch": 9.904621508461208,
      "grad_norm": 4.608837127685547,
      "learning_rate": 4.983590937963159e-07,
      "loss": 0.6078,
      "step": 935600
    },
    {
      "epoch": 9.905150830241212,
      "grad_norm": 4.678664684295654,
      "learning_rate": 4.95712470887148e-07,
      "loss": 0.6148,
      "step": 935650
    },
    {
      "epoch": 9.905680152021215,
      "grad_norm": 4.493288516998291,
      "learning_rate": 4.930658479779801e-07,
      "loss": 0.6135,
      "step": 935700
    },
    {
      "epoch": 9.90620947380122,
      "grad_norm": 4.589621543884277,
      "learning_rate": 4.904721575269956e-07,
      "loss": 0.6091,
      "step": 935750
    },
    {
      "epoch": 9.906738795581221,
      "grad_norm": 4.423686504364014,
      "learning_rate": 4.878255346178277e-07,
      "loss": 0.6086,
      "step": 935800
    },
    {
      "epoch": 9.907268117361225,
      "grad_norm": 5.17395544052124,
      "learning_rate": 4.851789117086598e-07,
      "loss": 0.6257,
      "step": 935850
    },
    {
      "epoch": 9.907797439141229,
      "grad_norm": 4.6750168800354,
      "learning_rate": 4.825322887994919e-07,
      "loss": 0.6174,
      "step": 935900
    },
    {
      "epoch": 9.908326760921232,
      "grad_norm": 4.452174663543701,
      "learning_rate": 4.798856658903239e-07,
      "loss": 0.6128,
      "step": 935950
    },
    {
      "epoch": 9.908856082701234,
      "grad_norm": 4.87167501449585,
      "learning_rate": 4.772390429811561e-07,
      "loss": 0.6095,
      "step": 936000
    },
    {
      "epoch": 9.908856082701234,
      "eval_loss": 0.37328383326530457,
      "eval_runtime": 46.5295,
      "eval_samples_per_second": 3609.109,
      "eval_steps_per_second": 451.155,
      "step": 936000
    },
    {
      "epoch": 9.909385404481238,
      "grad_norm": 4.842939376831055,
      "learning_rate": 4.745924200719881e-07,
      "loss": 0.6103,
      "step": 936050
    },
    {
      "epoch": 9.909914726261242,
      "grad_norm": 4.783201217651367,
      "learning_rate": 4.7194579716282026e-07,
      "loss": 0.6148,
      "step": 936100
    },
    {
      "epoch": 9.910444048041246,
      "grad_norm": 4.138451099395752,
      "learning_rate": 4.6929917425365235e-07,
      "loss": 0.6235,
      "step": 936150
    },
    {
      "epoch": 9.910973369821248,
      "grad_norm": 4.783055782318115,
      "learning_rate": 4.6665255134448444e-07,
      "loss": 0.6235,
      "step": 936200
    },
    {
      "epoch": 9.911502691601251,
      "grad_norm": 4.825855255126953,
      "learning_rate": 4.640059284353166e-07,
      "loss": 0.5996,
      "step": 936250
    },
    {
      "epoch": 9.912032013381255,
      "grad_norm": 4.369814395904541,
      "learning_rate": 4.6135930552614867e-07,
      "loss": 0.6161,
      "step": 936300
    },
    {
      "epoch": 9.912561335161257,
      "grad_norm": 4.819140911102295,
      "learning_rate": 4.5871268261698075e-07,
      "loss": 0.6083,
      "step": 936350
    },
    {
      "epoch": 9.913090656941261,
      "grad_norm": 4.548781871795654,
      "learning_rate": 4.560660597078129e-07,
      "loss": 0.6134,
      "step": 936400
    },
    {
      "epoch": 9.913619978721265,
      "grad_norm": 4.589131832122803,
      "learning_rate": 4.53419436798645e-07,
      "loss": 0.6148,
      "step": 936450
    },
    {
      "epoch": 9.914149300501268,
      "grad_norm": 4.927265644073486,
      "learning_rate": 4.5077281388947707e-07,
      "loss": 0.6086,
      "step": 936500
    },
    {
      "epoch": 9.914149300501268,
      "eval_loss": 0.3731182813644409,
      "eval_runtime": 46.5085,
      "eval_samples_per_second": 3610.741,
      "eval_steps_per_second": 451.359,
      "step": 936500
    },
    {
      "epoch": 9.91467862228127,
      "grad_norm": 4.64946174621582,
      "learning_rate": 4.4812619098030916e-07,
      "loss": 0.6149,
      "step": 936550
    },
    {
      "epoch": 9.915207944061274,
      "grad_norm": 4.433017253875732,
      "learning_rate": 4.454795680711412e-07,
      "loss": 0.6074,
      "step": 936600
    },
    {
      "epoch": 9.915737265841278,
      "grad_norm": 4.813826084136963,
      "learning_rate": 4.428329451619733e-07,
      "loss": 0.6214,
      "step": 936650
    },
    {
      "epoch": 9.916266587621282,
      "grad_norm": 4.8347063064575195,
      "learning_rate": 4.401863222528054e-07,
      "loss": 0.6173,
      "step": 936700
    },
    {
      "epoch": 9.916795909401284,
      "grad_norm": 5.252914905548096,
      "learning_rate": 4.375396993436375e-07,
      "loss": 0.6119,
      "step": 936750
    },
    {
      "epoch": 9.917325231181287,
      "grad_norm": 4.787091255187988,
      "learning_rate": 4.348930764344696e-07,
      "loss": 0.6329,
      "step": 936800
    },
    {
      "epoch": 9.917854552961291,
      "grad_norm": 4.235669136047363,
      "learning_rate": 4.3224645352530174e-07,
      "loss": 0.6093,
      "step": 936850
    },
    {
      "epoch": 9.918383874741295,
      "grad_norm": 5.159398555755615,
      "learning_rate": 4.2959983061613383e-07,
      "loss": 0.6136,
      "step": 936900
    },
    {
      "epoch": 9.918913196521297,
      "grad_norm": 4.638427734375,
      "learning_rate": 4.269532077069659e-07,
      "loss": 0.6123,
      "step": 936950
    },
    {
      "epoch": 9.9194425183013,
      "grad_norm": 4.6441426277160645,
      "learning_rate": 4.2430658479779806e-07,
      "loss": 0.6095,
      "step": 937000
    },
    {
      "epoch": 9.9194425183013,
      "eval_loss": 0.3731982111930847,
      "eval_runtime": 46.5056,
      "eval_samples_per_second": 3610.959,
      "eval_steps_per_second": 451.386,
      "step": 937000
    },
    {
      "epoch": 9.919971840081304,
      "grad_norm": 4.930607318878174,
      "learning_rate": 4.2165996188863015e-07,
      "loss": 0.6141,
      "step": 937050
    },
    {
      "epoch": 9.920501161861306,
      "grad_norm": 4.802171230316162,
      "learning_rate": 4.1901333897946224e-07,
      "loss": 0.623,
      "step": 937100
    },
    {
      "epoch": 9.92103048364131,
      "grad_norm": 4.683485507965088,
      "learning_rate": 4.163667160702944e-07,
      "loss": 0.6218,
      "step": 937150
    },
    {
      "epoch": 9.921559805421314,
      "grad_norm": 4.411999225616455,
      "learning_rate": 4.1372009316112647e-07,
      "loss": 0.6136,
      "step": 937200
    },
    {
      "epoch": 9.922089127201318,
      "grad_norm": 5.228460311889648,
      "learning_rate": 4.110734702519585e-07,
      "loss": 0.6174,
      "step": 937250
    },
    {
      "epoch": 9.92261844898132,
      "grad_norm": 4.162470817565918,
      "learning_rate": 4.084268473427906e-07,
      "loss": 0.6201,
      "step": 937300
    },
    {
      "epoch": 9.923147770761323,
      "grad_norm": 4.8439717292785645,
      "learning_rate": 4.057802244336227e-07,
      "loss": 0.6106,
      "step": 937350
    },
    {
      "epoch": 9.923677092541327,
      "grad_norm": 4.443674087524414,
      "learning_rate": 4.031336015244548e-07,
      "loss": 0.6167,
      "step": 937400
    },
    {
      "epoch": 9.92420641432133,
      "grad_norm": 4.5516886711120605,
      "learning_rate": 4.004869786152869e-07,
      "loss": 0.6107,
      "step": 937450
    },
    {
      "epoch": 9.924735736101333,
      "grad_norm": 4.347614765167236,
      "learning_rate": 3.97840355706119e-07,
      "loss": 0.6222,
      "step": 937500
    },
    {
      "epoch": 9.924735736101333,
      "eval_loss": 0.3732604682445526,
      "eval_runtime": 46.5099,
      "eval_samples_per_second": 3610.628,
      "eval_steps_per_second": 451.345,
      "step": 937500
    },
    {
      "epoch": 9.925265057881337,
      "grad_norm": 4.8914995193481445,
      "learning_rate": 3.951937327969511e-07,
      "loss": 0.6221,
      "step": 937550
    },
    {
      "epoch": 9.92579437966134,
      "grad_norm": 4.471816539764404,
      "learning_rate": 3.925471098877832e-07,
      "loss": 0.6177,
      "step": 937600
    },
    {
      "epoch": 9.926323701441344,
      "grad_norm": 5.100523471832275,
      "learning_rate": 3.899004869786153e-07,
      "loss": 0.6098,
      "step": 937650
    },
    {
      "epoch": 9.926853023221346,
      "grad_norm": 4.591905117034912,
      "learning_rate": 3.872538640694474e-07,
      "loss": 0.6181,
      "step": 937700
    },
    {
      "epoch": 9.92738234500135,
      "grad_norm": 4.2958879470825195,
      "learning_rate": 3.847131060766462e-07,
      "loss": 0.6152,
      "step": 937750
    },
    {
      "epoch": 9.927911666781354,
      "grad_norm": 4.8658671379089355,
      "learning_rate": 3.820664831674783e-07,
      "loss": 0.6137,
      "step": 937800
    },
    {
      "epoch": 9.928440988561356,
      "grad_norm": 4.480046272277832,
      "learning_rate": 3.7941986025831044e-07,
      "loss": 0.6125,
      "step": 937850
    },
    {
      "epoch": 9.92897031034136,
      "grad_norm": 4.712718963623047,
      "learning_rate": 3.7677323734914253e-07,
      "loss": 0.6159,
      "step": 937900
    },
    {
      "epoch": 9.929499632121363,
      "grad_norm": 4.6613688468933105,
      "learning_rate": 3.741266144399746e-07,
      "loss": 0.6324,
      "step": 937950
    },
    {
      "epoch": 9.930028953901367,
      "grad_norm": 4.632752895355225,
      "learning_rate": 3.714799915308067e-07,
      "loss": 0.6242,
      "step": 938000
    },
    {
      "epoch": 9.930028953901367,
      "eval_loss": 0.37332168221473694,
      "eval_runtime": 46.5347,
      "eval_samples_per_second": 3608.705,
      "eval_steps_per_second": 451.104,
      "step": 938000
    },
    {
      "epoch": 9.930558275681369,
      "grad_norm": 4.659621715545654,
      "learning_rate": 3.688333686216388e-07,
      "loss": 0.6271,
      "step": 938050
    },
    {
      "epoch": 9.931087597461373,
      "grad_norm": 4.288304805755615,
      "learning_rate": 3.661867457124709e-07,
      "loss": 0.6153,
      "step": 938100
    },
    {
      "epoch": 9.931616919241376,
      "grad_norm": 4.639456748962402,
      "learning_rate": 3.63540122803303e-07,
      "loss": 0.6225,
      "step": 938150
    },
    {
      "epoch": 9.93214624102138,
      "grad_norm": 4.750992774963379,
      "learning_rate": 3.608934998941351e-07,
      "loss": 0.6124,
      "step": 938200
    },
    {
      "epoch": 9.932675562801382,
      "grad_norm": 4.514328956604004,
      "learning_rate": 3.582468769849672e-07,
      "loss": 0.6109,
      "step": 938250
    },
    {
      "epoch": 9.933204884581386,
      "grad_norm": 4.415769577026367,
      "learning_rate": 3.556002540757993e-07,
      "loss": 0.6169,
      "step": 938300
    },
    {
      "epoch": 9.93373420636139,
      "grad_norm": 4.576672077178955,
      "learning_rate": 3.529536311666314e-07,
      "loss": 0.619,
      "step": 938350
    },
    {
      "epoch": 9.934263528141393,
      "grad_norm": 4.65300989151001,
      "learning_rate": 3.5030700825746346e-07,
      "loss": 0.6119,
      "step": 938400
    },
    {
      "epoch": 9.934792849921395,
      "grad_norm": 4.580974578857422,
      "learning_rate": 3.476603853482956e-07,
      "loss": 0.6092,
      "step": 938450
    },
    {
      "epoch": 9.935322171701399,
      "grad_norm": 4.413954257965088,
      "learning_rate": 3.450137624391277e-07,
      "loss": 0.6139,
      "step": 938500
    },
    {
      "epoch": 9.935322171701399,
      "eval_loss": 0.3732494115829468,
      "eval_runtime": 46.5153,
      "eval_samples_per_second": 3610.213,
      "eval_steps_per_second": 451.293,
      "step": 938500
    },
    {
      "epoch": 9.935851493481403,
      "grad_norm": 4.714638710021973,
      "learning_rate": 3.423671395299598e-07,
      "loss": 0.6151,
      "step": 938550
    },
    {
      "epoch": 9.936380815261405,
      "grad_norm": 5.244487762451172,
      "learning_rate": 3.397205166207919e-07,
      "loss": 0.6136,
      "step": 938600
    },
    {
      "epoch": 9.936910137041409,
      "grad_norm": 4.506290435791016,
      "learning_rate": 3.3707389371162396e-07,
      "loss": 0.6061,
      "step": 938650
    },
    {
      "epoch": 9.937439458821412,
      "grad_norm": 4.583981037139893,
      "learning_rate": 3.3442727080245605e-07,
      "loss": 0.6197,
      "step": 938700
    },
    {
      "epoch": 9.937968780601416,
      "grad_norm": 4.842591762542725,
      "learning_rate": 3.317806478932882e-07,
      "loss": 0.6085,
      "step": 938750
    },
    {
      "epoch": 9.938498102381418,
      "grad_norm": 4.347733020782471,
      "learning_rate": 3.291340249841203e-07,
      "loss": 0.6194,
      "step": 938800
    },
    {
      "epoch": 9.939027424161422,
      "grad_norm": 4.613394737243652,
      "learning_rate": 3.2648740207495236e-07,
      "loss": 0.6257,
      "step": 938850
    },
    {
      "epoch": 9.939556745941426,
      "grad_norm": 4.789487361907959,
      "learning_rate": 3.238407791657845e-07,
      "loss": 0.6051,
      "step": 938900
    },
    {
      "epoch": 9.94008606772143,
      "grad_norm": 4.527021884918213,
      "learning_rate": 3.2119415625661654e-07,
      "loss": 0.6333,
      "step": 938950
    },
    {
      "epoch": 9.940615389501431,
      "grad_norm": 4.975710391998291,
      "learning_rate": 3.185475333474487e-07,
      "loss": 0.6011,
      "step": 939000
    },
    {
      "epoch": 9.940615389501431,
      "eval_loss": 0.37319543957710266,
      "eval_runtime": 46.4971,
      "eval_samples_per_second": 3611.622,
      "eval_steps_per_second": 451.469,
      "step": 939000
    },
    {
      "epoch": 9.941144711281435,
      "grad_norm": 4.533073425292969,
      "learning_rate": 3.1590091043828077e-07,
      "loss": 0.6149,
      "step": 939050
    },
    {
      "epoch": 9.941674033061439,
      "grad_norm": 4.834747791290283,
      "learning_rate": 3.1325428752911286e-07,
      "loss": 0.6213,
      "step": 939100
    },
    {
      "epoch": 9.942203354841443,
      "grad_norm": 4.937719345092773,
      "learning_rate": 3.1060766461994495e-07,
      "loss": 0.6213,
      "step": 939150
    },
    {
      "epoch": 9.942732676621445,
      "grad_norm": 4.50689697265625,
      "learning_rate": 3.079610417107771e-07,
      "loss": 0.6149,
      "step": 939200
    },
    {
      "epoch": 9.943261998401448,
      "grad_norm": 5.057582855224609,
      "learning_rate": 3.053144188016092e-07,
      "loss": 0.62,
      "step": 939250
    },
    {
      "epoch": 9.943791320181452,
      "grad_norm": 4.737020492553711,
      "learning_rate": 3.0266779589244126e-07,
      "loss": 0.6119,
      "step": 939300
    },
    {
      "epoch": 9.944320641961454,
      "grad_norm": 4.838205337524414,
      "learning_rate": 3.0002117298327335e-07,
      "loss": 0.6102,
      "step": 939350
    },
    {
      "epoch": 9.944849963741458,
      "grad_norm": 4.76758337020874,
      "learning_rate": 2.9737455007410544e-07,
      "loss": 0.6133,
      "step": 939400
    },
    {
      "epoch": 9.945379285521462,
      "grad_norm": 4.74262809753418,
      "learning_rate": 2.947279271649376e-07,
      "loss": 0.6054,
      "step": 939450
    },
    {
      "epoch": 9.945908607301465,
      "grad_norm": 4.728328704833984,
      "learning_rate": 2.9208130425576967e-07,
      "loss": 0.6166,
      "step": 939500
    },
    {
      "epoch": 9.945908607301465,
      "eval_loss": 0.37329375743865967,
      "eval_runtime": 46.4762,
      "eval_samples_per_second": 3613.246,
      "eval_steps_per_second": 451.672,
      "step": 939500
    },
    {
      "epoch": 9.946437929081467,
      "grad_norm": 4.4092793464660645,
      "learning_rate": 2.8943468134660176e-07,
      "loss": 0.6193,
      "step": 939550
    },
    {
      "epoch": 9.946967250861471,
      "grad_norm": 4.408344268798828,
      "learning_rate": 2.8678805843743385e-07,
      "loss": 0.6215,
      "step": 939600
    },
    {
      "epoch": 9.947496572641475,
      "grad_norm": 4.389200210571289,
      "learning_rate": 2.8414143552826593e-07,
      "loss": 0.6178,
      "step": 939650
    },
    {
      "epoch": 9.948025894421479,
      "grad_norm": 4.599647521972656,
      "learning_rate": 2.81494812619098e-07,
      "loss": 0.6221,
      "step": 939700
    },
    {
      "epoch": 9.94855521620148,
      "grad_norm": 4.889767646789551,
      "learning_rate": 2.7884818970993016e-07,
      "loss": 0.6153,
      "step": 939750
    },
    {
      "epoch": 9.949084537981484,
      "grad_norm": 4.774405002593994,
      "learning_rate": 2.7620156680076225e-07,
      "loss": 0.6259,
      "step": 939800
    },
    {
      "epoch": 9.949613859761488,
      "grad_norm": 4.475503921508789,
      "learning_rate": 2.7355494389159434e-07,
      "loss": 0.6107,
      "step": 939850
    },
    {
      "epoch": 9.950143181541492,
      "grad_norm": 4.756964683532715,
      "learning_rate": 2.709083209824265e-07,
      "loss": 0.6123,
      "step": 939900
    },
    {
      "epoch": 9.950672503321494,
      "grad_norm": 4.705483436584473,
      "learning_rate": 2.682616980732585e-07,
      "loss": 0.614,
      "step": 939950
    },
    {
      "epoch": 9.951201825101498,
      "grad_norm": 4.7019243240356445,
      "learning_rate": 2.656150751640906e-07,
      "loss": 0.6148,
      "step": 940000
    },
    {
      "epoch": 9.951201825101498,
      "eval_loss": 0.3733065724372864,
      "eval_runtime": 46.5311,
      "eval_samples_per_second": 3608.982,
      "eval_steps_per_second": 451.139,
      "step": 940000
    },
    {
      "epoch": 9.951731146881501,
      "grad_norm": 4.754997253417969,
      "learning_rate": 2.6296845225492275e-07,
      "loss": 0.6156,
      "step": 940050
    },
    {
      "epoch": 9.952260468661503,
      "grad_norm": 4.403406620025635,
      "learning_rate": 2.6032182934575483e-07,
      "loss": 0.6137,
      "step": 940100
    },
    {
      "epoch": 9.952789790441507,
      "grad_norm": 4.727240562438965,
      "learning_rate": 2.576752064365869e-07,
      "loss": 0.6153,
      "step": 940150
    },
    {
      "epoch": 9.95331911222151,
      "grad_norm": 4.557339668273926,
      "learning_rate": 2.5502858352741906e-07,
      "loss": 0.6217,
      "step": 940200
    },
    {
      "epoch": 9.953848434001515,
      "grad_norm": 5.263223648071289,
      "learning_rate": 2.523819606182511e-07,
      "loss": 0.6046,
      "step": 940250
    },
    {
      "epoch": 9.954377755781517,
      "grad_norm": 4.314789295196533,
      "learning_rate": 2.497353377090832e-07,
      "loss": 0.6065,
      "step": 940300
    },
    {
      "epoch": 9.95490707756152,
      "grad_norm": 5.329423904418945,
      "learning_rate": 2.4708871479991533e-07,
      "loss": 0.6305,
      "step": 940350
    },
    {
      "epoch": 9.955436399341524,
      "grad_norm": 4.705920219421387,
      "learning_rate": 2.444420918907474e-07,
      "loss": 0.621,
      "step": 940400
    },
    {
      "epoch": 9.955965721121528,
      "grad_norm": 4.934019088745117,
      "learning_rate": 2.417954689815795e-07,
      "loss": 0.6145,
      "step": 940450
    },
    {
      "epoch": 9.95649504290153,
      "grad_norm": 4.5735297203063965,
      "learning_rate": 2.3914884607241165e-07,
      "loss": 0.6165,
      "step": 940500
    },
    {
      "epoch": 9.95649504290153,
      "eval_loss": 0.3732941448688507,
      "eval_runtime": 46.5064,
      "eval_samples_per_second": 3610.9,
      "eval_steps_per_second": 451.379,
      "step": 940500
    },
    {
      "epoch": 9.957024364681534,
      "grad_norm": 4.803186416625977,
      "learning_rate": 2.3650222316324368e-07,
      "loss": 0.6218,
      "step": 940550
    },
    {
      "epoch": 9.957553686461537,
      "grad_norm": 3.987874984741211,
      "learning_rate": 2.338556002540758e-07,
      "loss": 0.6072,
      "step": 940600
    },
    {
      "epoch": 9.958083008241541,
      "grad_norm": 4.562950611114502,
      "learning_rate": 2.312089773449079e-07,
      "loss": 0.6255,
      "step": 940650
    },
    {
      "epoch": 9.958612330021543,
      "grad_norm": 4.617526531219482,
      "learning_rate": 2.2856235443574e-07,
      "loss": 0.6234,
      "step": 940700
    },
    {
      "epoch": 9.959141651801547,
      "grad_norm": 5.084132194519043,
      "learning_rate": 2.2591573152657211e-07,
      "loss": 0.6175,
      "step": 940750
    },
    {
      "epoch": 9.95967097358155,
      "grad_norm": 4.797342300415039,
      "learning_rate": 2.2326910861740423e-07,
      "loss": 0.6171,
      "step": 940800
    },
    {
      "epoch": 9.960200295361552,
      "grad_norm": 4.849951267242432,
      "learning_rate": 2.2062248570823632e-07,
      "loss": 0.6116,
      "step": 940850
    },
    {
      "epoch": 9.960729617141556,
      "grad_norm": 4.503003120422363,
      "learning_rate": 2.1797586279906838e-07,
      "loss": 0.6218,
      "step": 940900
    },
    {
      "epoch": 9.96125893892156,
      "grad_norm": 4.480524063110352,
      "learning_rate": 2.153292398899005e-07,
      "loss": 0.6112,
      "step": 940950
    },
    {
      "epoch": 9.961788260701564,
      "grad_norm": 4.7850189208984375,
      "learning_rate": 2.1268261698073258e-07,
      "loss": 0.6168,
      "step": 941000
    },
    {
      "epoch": 9.961788260701564,
      "eval_loss": 0.37322181463241577,
      "eval_runtime": 46.4724,
      "eval_samples_per_second": 3613.545,
      "eval_steps_per_second": 451.709,
      "step": 941000
    },
    {
      "epoch": 9.962317582481566,
      "grad_norm": 4.673477649688721,
      "learning_rate": 2.100359940715647e-07,
      "loss": 0.6177,
      "step": 941050
    },
    {
      "epoch": 9.96284690426157,
      "grad_norm": 4.40938138961792,
      "learning_rate": 2.073893711623968e-07,
      "loss": 0.6144,
      "step": 941100
    },
    {
      "epoch": 9.963376226041573,
      "grad_norm": 4.69760799407959,
      "learning_rate": 2.047427482532289e-07,
      "loss": 0.615,
      "step": 941150
    },
    {
      "epoch": 9.963905547821577,
      "grad_norm": 4.326941967010498,
      "learning_rate": 2.0209612534406096e-07,
      "loss": 0.6093,
      "step": 941200
    },
    {
      "epoch": 9.964434869601579,
      "grad_norm": 4.108495235443115,
      "learning_rate": 1.9944950243489308e-07,
      "loss": 0.6127,
      "step": 941250
    },
    {
      "epoch": 9.964964191381583,
      "grad_norm": 4.73455810546875,
      "learning_rate": 1.968028795257252e-07,
      "loss": 0.615,
      "step": 941300
    },
    {
      "epoch": 9.965493513161586,
      "grad_norm": 4.742302894592285,
      "learning_rate": 1.9415625661655728e-07,
      "loss": 0.6296,
      "step": 941350
    },
    {
      "epoch": 9.96602283494159,
      "grad_norm": 5.007462501525879,
      "learning_rate": 1.915096337073894e-07,
      "loss": 0.6087,
      "step": 941400
    },
    {
      "epoch": 9.966552156721592,
      "grad_norm": 4.400713920593262,
      "learning_rate": 1.8886301079822148e-07,
      "loss": 0.6139,
      "step": 941450
    },
    {
      "epoch": 9.967081478501596,
      "grad_norm": 4.832564353942871,
      "learning_rate": 1.8621638788905357e-07,
      "loss": 0.6164,
      "step": 941500
    },
    {
      "epoch": 9.967081478501596,
      "eval_loss": 0.3731820285320282,
      "eval_runtime": 46.5402,
      "eval_samples_per_second": 3608.276,
      "eval_steps_per_second": 451.051,
      "step": 941500
    },
    {
      "epoch": 9.9676108002816,
      "grad_norm": 5.2732038497924805,
      "learning_rate": 1.8356976497988568e-07,
      "loss": 0.608,
      "step": 941550
    },
    {
      "epoch": 9.968140122061602,
      "grad_norm": 5.270110607147217,
      "learning_rate": 1.8092314207071777e-07,
      "loss": 0.6145,
      "step": 941600
    },
    {
      "epoch": 9.968669443841605,
      "grad_norm": 5.032614707946777,
      "learning_rate": 1.7827651916154986e-07,
      "loss": 0.6223,
      "step": 941650
    },
    {
      "epoch": 9.96919876562161,
      "grad_norm": 5.053983211517334,
      "learning_rate": 1.7562989625238197e-07,
      "loss": 0.6164,
      "step": 941700
    },
    {
      "epoch": 9.969728087401613,
      "grad_norm": 4.481025218963623,
      "learning_rate": 1.7303620580139742e-07,
      "loss": 0.6187,
      "step": 941750
    },
    {
      "epoch": 9.970257409181615,
      "grad_norm": 4.376795768737793,
      "learning_rate": 1.703895828922295e-07,
      "loss": 0.6113,
      "step": 941800
    },
    {
      "epoch": 9.970786730961619,
      "grad_norm": 4.6809611320495605,
      "learning_rate": 1.6774295998306163e-07,
      "loss": 0.6132,
      "step": 941850
    },
    {
      "epoch": 9.971316052741622,
      "grad_norm": 4.904414176940918,
      "learning_rate": 1.6509633707389371e-07,
      "loss": 0.6161,
      "step": 941900
    },
    {
      "epoch": 9.971845374521626,
      "grad_norm": 4.619542121887207,
      "learning_rate": 1.624497141647258e-07,
      "loss": 0.6112,
      "step": 941950
    },
    {
      "epoch": 9.972374696301628,
      "grad_norm": 4.777292251586914,
      "learning_rate": 1.5980309125555792e-07,
      "loss": 0.6229,
      "step": 942000
    },
    {
      "epoch": 9.972374696301628,
      "eval_loss": 0.37314721941947937,
      "eval_runtime": 46.4989,
      "eval_samples_per_second": 3611.486,
      "eval_steps_per_second": 451.452,
      "step": 942000
    },
    {
      "epoch": 9.972904018081632,
      "grad_norm": 4.629304885864258,
      "learning_rate": 1.5715646834639e-07,
      "loss": 0.6138,
      "step": 942050
    },
    {
      "epoch": 9.973433339861636,
      "grad_norm": 4.647879600524902,
      "learning_rate": 1.5450984543722212e-07,
      "loss": 0.6144,
      "step": 942100
    },
    {
      "epoch": 9.97396266164164,
      "grad_norm": 4.855958461761475,
      "learning_rate": 1.518632225280542e-07,
      "loss": 0.6222,
      "step": 942150
    },
    {
      "epoch": 9.974491983421641,
      "grad_norm": 4.339095592498779,
      "learning_rate": 1.4921659961888632e-07,
      "loss": 0.6219,
      "step": 942200
    },
    {
      "epoch": 9.975021305201645,
      "grad_norm": 4.33075475692749,
      "learning_rate": 1.465699767097184e-07,
      "loss": 0.6216,
      "step": 942250
    },
    {
      "epoch": 9.975550626981649,
      "grad_norm": 4.363731861114502,
      "learning_rate": 1.439233538005505e-07,
      "loss": 0.6114,
      "step": 942300
    },
    {
      "epoch": 9.976079948761651,
      "grad_norm": 5.361462116241455,
      "learning_rate": 1.4127673089138261e-07,
      "loss": 0.6258,
      "step": 942350
    },
    {
      "epoch": 9.976609270541655,
      "grad_norm": 4.7531962394714355,
      "learning_rate": 1.386301079822147e-07,
      "loss": 0.6231,
      "step": 942400
    },
    {
      "epoch": 9.977138592321658,
      "grad_norm": 4.717652320861816,
      "learning_rate": 1.359834850730468e-07,
      "loss": 0.6207,
      "step": 942450
    },
    {
      "epoch": 9.977667914101662,
      "grad_norm": 4.812778949737549,
      "learning_rate": 1.333368621638789e-07,
      "loss": 0.6187,
      "step": 942500
    },
    {
      "epoch": 9.977667914101662,
      "eval_loss": 0.3731454610824585,
      "eval_runtime": 46.6164,
      "eval_samples_per_second": 3602.383,
      "eval_steps_per_second": 450.314,
      "step": 942500
    },
    {
      "epoch": 9.978197235881664,
      "grad_norm": 4.580633163452148,
      "learning_rate": 1.30690239254711e-07,
      "loss": 0.6034,
      "step": 942550
    },
    {
      "epoch": 9.978726557661668,
      "grad_norm": 4.604588508605957,
      "learning_rate": 1.2804361634554308e-07,
      "loss": 0.6119,
      "step": 942600
    },
    {
      "epoch": 9.979255879441672,
      "grad_norm": 4.509209632873535,
      "learning_rate": 1.253969934363752e-07,
      "loss": 0.6261,
      "step": 942650
    },
    {
      "epoch": 9.979785201221675,
      "grad_norm": 4.833061218261719,
      "learning_rate": 1.2275037052720729e-07,
      "loss": 0.6284,
      "step": 942700
    },
    {
      "epoch": 9.980314523001677,
      "grad_norm": 4.225119113922119,
      "learning_rate": 1.2010374761803937e-07,
      "loss": 0.6148,
      "step": 942750
    },
    {
      "epoch": 9.980843844781681,
      "grad_norm": 5.304731369018555,
      "learning_rate": 1.1745712470887149e-07,
      "loss": 0.6237,
      "step": 942800
    },
    {
      "epoch": 9.981373166561685,
      "grad_norm": 4.34768533706665,
      "learning_rate": 1.1481050179970358e-07,
      "loss": 0.6029,
      "step": 942850
    },
    {
      "epoch": 9.981902488341689,
      "grad_norm": 4.891236305236816,
      "learning_rate": 1.1216387889053568e-07,
      "loss": 0.6162,
      "step": 942900
    },
    {
      "epoch": 9.98243181012169,
      "grad_norm": 5.218212127685547,
      "learning_rate": 1.0951725598136778e-07,
      "loss": 0.6177,
      "step": 942950
    },
    {
      "epoch": 9.982961131901694,
      "grad_norm": 4.994673252105713,
      "learning_rate": 1.068706330721999e-07,
      "loss": 0.6212,
      "step": 943000
    },
    {
      "epoch": 9.982961131901694,
      "eval_loss": 0.37315014004707336,
      "eval_runtime": 46.548,
      "eval_samples_per_second": 3607.672,
      "eval_steps_per_second": 450.975,
      "step": 943000
    },
    {
      "epoch": 9.983490453681698,
      "grad_norm": 4.91986608505249,
      "learning_rate": 1.0422401016303197e-07,
      "loss": 0.6193,
      "step": 943050
    },
    {
      "epoch": 9.9840197754617,
      "grad_norm": 4.333620071411133,
      "learning_rate": 1.0157738725386407e-07,
      "loss": 0.6162,
      "step": 943100
    },
    {
      "epoch": 9.984549097241704,
      "grad_norm": 4.765122413635254,
      "learning_rate": 9.893076434469619e-08,
      "loss": 0.6103,
      "step": 943150
    },
    {
      "epoch": 9.985078419021708,
      "grad_norm": 4.657260894775391,
      "learning_rate": 9.628414143552827e-08,
      "loss": 0.6158,
      "step": 943200
    },
    {
      "epoch": 9.985607740801711,
      "grad_norm": 4.8211870193481445,
      "learning_rate": 9.363751852636037e-08,
      "loss": 0.61,
      "step": 943250
    },
    {
      "epoch": 9.986137062581713,
      "grad_norm": 4.9804582595825195,
      "learning_rate": 9.099089561719246e-08,
      "loss": 0.6182,
      "step": 943300
    },
    {
      "epoch": 9.986666384361717,
      "grad_norm": 4.948568344116211,
      "learning_rate": 8.834427270802456e-08,
      "loss": 0.6252,
      "step": 943350
    },
    {
      "epoch": 9.987195706141721,
      "grad_norm": 4.342264652252197,
      "learning_rate": 8.569764979885667e-08,
      "loss": 0.6111,
      "step": 943400
    },
    {
      "epoch": 9.987725027921725,
      "grad_norm": 4.82127046585083,
      "learning_rate": 8.305102688968875e-08,
      "loss": 0.6183,
      "step": 943450
    },
    {
      "epoch": 9.988254349701727,
      "grad_norm": 4.444093704223633,
      "learning_rate": 8.040440398052086e-08,
      "loss": 0.6207,
      "step": 943500
    },
    {
      "epoch": 9.988254349701727,
      "eval_loss": 0.37313270568847656,
      "eval_runtime": 46.5602,
      "eval_samples_per_second": 3606.726,
      "eval_steps_per_second": 450.857,
      "step": 943500
    },
    {
      "epoch": 9.98878367148173,
      "grad_norm": 4.488277435302734,
      "learning_rate": 7.775778107135296e-08,
      "loss": 0.6197,
      "step": 943550
    },
    {
      "epoch": 9.989312993261734,
      "grad_norm": 4.532571315765381,
      "learning_rate": 7.511115816218506e-08,
      "loss": 0.6222,
      "step": 943600
    },
    {
      "epoch": 9.989842315041738,
      "grad_norm": 4.858343601226807,
      "learning_rate": 7.246453525301716e-08,
      "loss": 0.6111,
      "step": 943650
    },
    {
      "epoch": 9.99037163682174,
      "grad_norm": 4.691305637359619,
      "learning_rate": 6.981791234384925e-08,
      "loss": 0.6214,
      "step": 943700
    },
    {
      "epoch": 9.990900958601744,
      "grad_norm": 4.394631385803223,
      "learning_rate": 6.72242218928647e-08,
      "loss": 0.6191,
      "step": 943750
    },
    {
      "epoch": 9.991430280381747,
      "grad_norm": 4.834790229797363,
      "learning_rate": 6.457759898369681e-08,
      "loss": 0.6216,
      "step": 943800
    },
    {
      "epoch": 9.99195960216175,
      "grad_norm": 5.202487468719482,
      "learning_rate": 6.19309760745289e-08,
      "loss": 0.6182,
      "step": 943850
    },
    {
      "epoch": 9.992488923941753,
      "grad_norm": 4.620576858520508,
      "learning_rate": 5.928435316536101e-08,
      "loss": 0.6251,
      "step": 943900
    },
    {
      "epoch": 9.993018245721757,
      "grad_norm": 4.486616134643555,
      "learning_rate": 5.66377302561931e-08,
      "loss": 0.6232,
      "step": 943950
    },
    {
      "epoch": 9.99354756750176,
      "grad_norm": 4.872467517852783,
      "learning_rate": 5.39911073470252e-08,
      "loss": 0.6175,
      "step": 944000
    },
    {
      "epoch": 9.99354756750176,
      "eval_loss": 0.37314078211784363,
      "eval_runtime": 46.5338,
      "eval_samples_per_second": 3608.778,
      "eval_steps_per_second": 451.113,
      "step": 944000
    },
    {
      "epoch": 9.994076889281763,
      "grad_norm": 4.4525065422058105,
      "learning_rate": 5.13444844378573e-08,
      "loss": 0.63,
      "step": 944050
    },
    {
      "epoch": 9.994606211061766,
      "grad_norm": 4.6309380531311035,
      "learning_rate": 4.8697861528689394e-08,
      "loss": 0.6242,
      "step": 944100
    },
    {
      "epoch": 9.99513553284177,
      "grad_norm": 4.501950740814209,
      "learning_rate": 4.6051238619521495e-08,
      "loss": 0.6261,
      "step": 944150
    },
    {
      "epoch": 9.995664854621774,
      "grad_norm": 4.734158515930176,
      "learning_rate": 4.340461571035359e-08,
      "loss": 0.6044,
      "step": 944200
    },
    {
      "epoch": 9.996194176401776,
      "grad_norm": 4.4535722732543945,
      "learning_rate": 4.0757992801185685e-08,
      "loss": 0.6134,
      "step": 944250
    },
    {
      "epoch": 9.99672349818178,
      "grad_norm": 4.854546546936035,
      "learning_rate": 3.8111369892017787e-08,
      "loss": 0.6122,
      "step": 944300
    },
    {
      "epoch": 9.997252819961783,
      "grad_norm": 4.832460880279541,
      "learning_rate": 3.546474698284989e-08,
      "loss": 0.6264,
      "step": 944350
    },
    {
      "epoch": 9.997782141741787,
      "grad_norm": 4.4327898025512695,
      "learning_rate": 3.281812407368198e-08,
      "loss": 0.6137,
      "step": 944400
    },
    {
      "epoch": 9.99831146352179,
      "grad_norm": 4.188878536224365,
      "learning_rate": 3.017150116451408e-08,
      "loss": 0.6211,
      "step": 944450
    },
    {
      "epoch": 9.998840785301793,
      "grad_norm": 4.288905620574951,
      "learning_rate": 2.752487825534618e-08,
      "loss": 0.6082,
      "step": 944500
    },
    {
      "epoch": 9.998840785301793,
      "eval_loss": 0.3731400966644287,
      "eval_runtime": 46.6445,
      "eval_samples_per_second": 3600.21,
      "eval_steps_per_second": 450.042,
      "step": 944500
    }
  ],
  "logging_steps": 50,
  "max_steps": 944600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.750069256801485e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
