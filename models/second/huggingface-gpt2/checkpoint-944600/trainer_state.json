{
  "best_metric": 0.28783300518989563,
  "best_model_checkpoint": "./models/second/huggingface-gpt2/checkpoint-942500",
  "epoch": 9.9999523610398,
  "eval_steps": 500,
  "global_step": 944600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005293217800032818,
      "grad_norm": 13.327535629272461,
      "learning_rate": 2.6466229091679017e-07,
      "loss": 5.0354,
      "step": 50
    },
    {
      "epoch": 0.0010586435600065636,
      "grad_norm": 11.99586009979248,
      "learning_rate": 5.293245818335803e-07,
      "loss": 4.9134,
      "step": 100
    },
    {
      "epoch": 0.0015879653400098454,
      "grad_norm": 9.132969856262207,
      "learning_rate": 7.939868727503706e-07,
      "loss": 4.6568,
      "step": 150
    },
    {
      "epoch": 0.0021172871200131273,
      "grad_norm": 6.133437156677246,
      "learning_rate": 1.0586491636671607e-06,
      "loss": 4.3539,
      "step": 200
    },
    {
      "epoch": 0.002646608900016409,
      "grad_norm": 4.650659084320068,
      "learning_rate": 1.323311454583951e-06,
      "loss": 4.1191,
      "step": 250
    },
    {
      "epoch": 0.0031759306800196907,
      "grad_norm": 4.0181450843811035,
      "learning_rate": 1.5879737455007411e-06,
      "loss": 3.9604,
      "step": 300
    },
    {
      "epoch": 0.0037052524600229724,
      "grad_norm": 3.864668846130371,
      "learning_rate": 1.8526360364175313e-06,
      "loss": 3.8186,
      "step": 350
    },
    {
      "epoch": 0.004234574240026255,
      "grad_norm": 4.276557922363281,
      "learning_rate": 2.1172983273343214e-06,
      "loss": 3.7056,
      "step": 400
    },
    {
      "epoch": 0.004763896020029536,
      "grad_norm": 3.742126941680908,
      "learning_rate": 2.3819606182511117e-06,
      "loss": 3.6023,
      "step": 450
    },
    {
      "epoch": 0.005293217800032818,
      "grad_norm": 3.6183462142944336,
      "learning_rate": 2.646622909167902e-06,
      "loss": 3.5202,
      "step": 500
    },
    {
      "epoch": 0.005293217800032818,
      "eval_loss": 3.488035202026367,
      "eval_runtime": 47.4595,
      "eval_samples_per_second": 3538.389,
      "eval_steps_per_second": 442.314,
      "step": 500
    },
    {
      "epoch": 0.0058225395800361,
      "grad_norm": 3.502920389175415,
      "learning_rate": 2.911285200084692e-06,
      "loss": 3.4592,
      "step": 550
    },
    {
      "epoch": 0.006351861360039381,
      "grad_norm": 3.3861005306243896,
      "learning_rate": 3.1759474910014823e-06,
      "loss": 3.3732,
      "step": 600
    },
    {
      "epoch": 0.006881183140042663,
      "grad_norm": 3.878573417663574,
      "learning_rate": 3.440609781918272e-06,
      "loss": 3.2943,
      "step": 650
    },
    {
      "epoch": 0.007410504920045945,
      "grad_norm": 3.4336023330688477,
      "learning_rate": 3.7052720728350625e-06,
      "loss": 3.234,
      "step": 700
    },
    {
      "epoch": 0.007939826700049227,
      "grad_norm": 3.4207069873809814,
      "learning_rate": 3.969934363751853e-06,
      "loss": 3.1769,
      "step": 750
    },
    {
      "epoch": 0.00846914848005251,
      "grad_norm": 3.46062970161438,
      "learning_rate": 4.234596654668643e-06,
      "loss": 3.1437,
      "step": 800
    },
    {
      "epoch": 0.008998470260055791,
      "grad_norm": 3.746537208557129,
      "learning_rate": 4.499258945585433e-06,
      "loss": 3.0747,
      "step": 850
    },
    {
      "epoch": 0.009527792040059073,
      "grad_norm": 3.457939624786377,
      "learning_rate": 4.763921236502223e-06,
      "loss": 3.0474,
      "step": 900
    },
    {
      "epoch": 0.010057113820062354,
      "grad_norm": 3.8416783809661865,
      "learning_rate": 5.028583527419013e-06,
      "loss": 2.9496,
      "step": 950
    },
    {
      "epoch": 0.010586435600065636,
      "grad_norm": 3.1327924728393555,
      "learning_rate": 5.293245818335804e-06,
      "loss": 2.9241,
      "step": 1000
    },
    {
      "epoch": 0.010586435600065636,
      "eval_loss": 2.893115997314453,
      "eval_runtime": 47.1529,
      "eval_samples_per_second": 3561.39,
      "eval_steps_per_second": 445.19,
      "step": 1000
    },
    {
      "epoch": 0.011115757380068918,
      "grad_norm": 3.090102434158325,
      "learning_rate": 5.557908109252593e-06,
      "loss": 2.8635,
      "step": 1050
    },
    {
      "epoch": 0.0116450791600722,
      "grad_norm": 2.834216594696045,
      "learning_rate": 5.822570400169384e-06,
      "loss": 2.8145,
      "step": 1100
    },
    {
      "epoch": 0.012174400940075481,
      "grad_norm": 2.8574576377868652,
      "learning_rate": 6.087232691086175e-06,
      "loss": 2.781,
      "step": 1150
    },
    {
      "epoch": 0.012703722720078763,
      "grad_norm": 3.0630075931549072,
      "learning_rate": 6.3518949820029645e-06,
      "loss": 2.7076,
      "step": 1200
    },
    {
      "epoch": 0.013233044500082045,
      "grad_norm": 2.6683223247528076,
      "learning_rate": 6.6165572729197544e-06,
      "loss": 2.6824,
      "step": 1250
    },
    {
      "epoch": 0.013762366280085326,
      "grad_norm": 2.7936959266662598,
      "learning_rate": 6.881219563836544e-06,
      "loss": 2.63,
      "step": 1300
    },
    {
      "epoch": 0.014291688060088608,
      "grad_norm": 3.607034206390381,
      "learning_rate": 7.145881854753335e-06,
      "loss": 2.568,
      "step": 1350
    },
    {
      "epoch": 0.01482100984009189,
      "grad_norm": 2.8182647228240967,
      "learning_rate": 7.410544145670125e-06,
      "loss": 2.5328,
      "step": 1400
    },
    {
      "epoch": 0.015350331620095171,
      "grad_norm": 2.7661983966827393,
      "learning_rate": 7.675206436586916e-06,
      "loss": 2.492,
      "step": 1450
    },
    {
      "epoch": 0.015879653400098455,
      "grad_norm": 3.1548728942871094,
      "learning_rate": 7.939868727503706e-06,
      "loss": 2.4751,
      "step": 1500
    },
    {
      "epoch": 0.015879653400098455,
      "eval_loss": 2.454906940460205,
      "eval_runtime": 47.3505,
      "eval_samples_per_second": 3546.527,
      "eval_steps_per_second": 443.332,
      "step": 1500
    },
    {
      "epoch": 0.016408975180101735,
      "grad_norm": 2.702364444732666,
      "learning_rate": 8.204531018420496e-06,
      "loss": 2.4557,
      "step": 1550
    },
    {
      "epoch": 0.01693829696010502,
      "grad_norm": 3.0747790336608887,
      "learning_rate": 8.469193309337285e-06,
      "loss": 2.4025,
      "step": 1600
    },
    {
      "epoch": 0.0174676187401083,
      "grad_norm": 2.4544599056243896,
      "learning_rate": 8.733855600254075e-06,
      "loss": 2.3767,
      "step": 1650
    },
    {
      "epoch": 0.017996940520111582,
      "grad_norm": 3.574652671813965,
      "learning_rate": 8.998517891170865e-06,
      "loss": 2.3556,
      "step": 1700
    },
    {
      "epoch": 0.01852626230011486,
      "grad_norm": 3.1668343544006348,
      "learning_rate": 9.263180182087657e-06,
      "loss": 2.3157,
      "step": 1750
    },
    {
      "epoch": 0.019055584080118145,
      "grad_norm": 3.0451979637145996,
      "learning_rate": 9.527842473004447e-06,
      "loss": 2.2857,
      "step": 1800
    },
    {
      "epoch": 0.019584905860121425,
      "grad_norm": 2.543513298034668,
      "learning_rate": 9.792504763921237e-06,
      "loss": 2.2802,
      "step": 1850
    },
    {
      "epoch": 0.02011422764012471,
      "grad_norm": 2.7169532775878906,
      "learning_rate": 1.0057167054838027e-05,
      "loss": 2.2637,
      "step": 1900
    },
    {
      "epoch": 0.02064354942012799,
      "grad_norm": 2.81728196144104,
      "learning_rate": 1.0321829345754817e-05,
      "loss": 2.2583,
      "step": 1950
    },
    {
      "epoch": 0.021172871200131272,
      "grad_norm": 2.754110097885132,
      "learning_rate": 1.0586491636671608e-05,
      "loss": 2.264,
      "step": 2000
    },
    {
      "epoch": 0.021172871200131272,
      "eval_loss": 2.2303829193115234,
      "eval_runtime": 47.2,
      "eval_samples_per_second": 3557.838,
      "eval_steps_per_second": 444.746,
      "step": 2000
    },
    {
      "epoch": 0.021702192980134552,
      "grad_norm": 2.4423158168792725,
      "learning_rate": 1.0851153927588398e-05,
      "loss": 2.2184,
      "step": 2050
    },
    {
      "epoch": 0.022231514760137835,
      "grad_norm": 3.1599128246307373,
      "learning_rate": 1.1115816218505186e-05,
      "loss": 2.1964,
      "step": 2100
    },
    {
      "epoch": 0.02276083654014112,
      "grad_norm": 3.020643472671509,
      "learning_rate": 1.1380478509421978e-05,
      "loss": 2.1962,
      "step": 2150
    },
    {
      "epoch": 0.0232901583201444,
      "grad_norm": 2.353205919265747,
      "learning_rate": 1.1645140800338768e-05,
      "loss": 2.199,
      "step": 2200
    },
    {
      "epoch": 0.023819480100147682,
      "grad_norm": 2.8176913261413574,
      "learning_rate": 1.190980309125556e-05,
      "loss": 2.1403,
      "step": 2250
    },
    {
      "epoch": 0.024348801880150962,
      "grad_norm": 2.2325682640075684,
      "learning_rate": 1.217446538217235e-05,
      "loss": 2.1426,
      "step": 2300
    },
    {
      "epoch": 0.024878123660154246,
      "grad_norm": 2.66265869140625,
      "learning_rate": 1.2439127673089137e-05,
      "loss": 2.1201,
      "step": 2350
    },
    {
      "epoch": 0.025407445440157526,
      "grad_norm": 2.7309811115264893,
      "learning_rate": 1.2703789964005929e-05,
      "loss": 2.1384,
      "step": 2400
    },
    {
      "epoch": 0.02593676722016081,
      "grad_norm": 2.25777006149292,
      "learning_rate": 1.2968452254922719e-05,
      "loss": 2.1094,
      "step": 2450
    },
    {
      "epoch": 0.02646608900016409,
      "grad_norm": 2.2438864707946777,
      "learning_rate": 1.3233114545839509e-05,
      "loss": 2.1011,
      "step": 2500
    },
    {
      "epoch": 0.02646608900016409,
      "eval_loss": 2.1216115951538086,
      "eval_runtime": 47.2436,
      "eval_samples_per_second": 3554.559,
      "eval_steps_per_second": 444.336,
      "step": 2500
    },
    {
      "epoch": 0.026995410780167373,
      "grad_norm": 3.064242124557495,
      "learning_rate": 1.3497776836756299e-05,
      "loss": 2.0965,
      "step": 2550
    },
    {
      "epoch": 0.027524732560170653,
      "grad_norm": 2.4252288341522217,
      "learning_rate": 1.3762439127673089e-05,
      "loss": 2.0894,
      "step": 2600
    },
    {
      "epoch": 0.028054054340173936,
      "grad_norm": 2.3533382415771484,
      "learning_rate": 1.402710141858988e-05,
      "loss": 2.0988,
      "step": 2650
    },
    {
      "epoch": 0.028583376120177216,
      "grad_norm": 2.3387484550476074,
      "learning_rate": 1.429176370950667e-05,
      "loss": 2.0665,
      "step": 2700
    },
    {
      "epoch": 0.0291126979001805,
      "grad_norm": 2.881202220916748,
      "learning_rate": 1.4556426000423458e-05,
      "loss": 2.063,
      "step": 2750
    },
    {
      "epoch": 0.02964201968018378,
      "grad_norm": 2.626636266708374,
      "learning_rate": 1.482108829134025e-05,
      "loss": 2.0603,
      "step": 2800
    },
    {
      "epoch": 0.030171341460187063,
      "grad_norm": 2.463238000869751,
      "learning_rate": 1.508575058225704e-05,
      "loss": 2.0664,
      "step": 2850
    },
    {
      "epoch": 0.030700663240190343,
      "grad_norm": 2.8637495040893555,
      "learning_rate": 1.535041287317383e-05,
      "loss": 2.0575,
      "step": 2900
    },
    {
      "epoch": 0.031229985020193626,
      "grad_norm": 2.765871286392212,
      "learning_rate": 1.561507516409062e-05,
      "loss": 2.0414,
      "step": 2950
    },
    {
      "epoch": 0.03175930680019691,
      "grad_norm": 2.413134813308716,
      "learning_rate": 1.587973745500741e-05,
      "loss": 2.0437,
      "step": 3000
    },
    {
      "epoch": 0.03175930680019691,
      "eval_loss": 2.060875654220581,
      "eval_runtime": 47.494,
      "eval_samples_per_second": 3535.818,
      "eval_steps_per_second": 441.993,
      "step": 3000
    },
    {
      "epoch": 0.032288628580200186,
      "grad_norm": 2.253441333770752,
      "learning_rate": 1.61443997459242e-05,
      "loss": 2.0371,
      "step": 3050
    },
    {
      "epoch": 0.03281795036020347,
      "grad_norm": 2.528228282928467,
      "learning_rate": 1.640906203684099e-05,
      "loss": 2.0418,
      "step": 3100
    },
    {
      "epoch": 0.03334727214020675,
      "grad_norm": 2.417325496673584,
      "learning_rate": 1.667372432775778e-05,
      "loss": 2.0249,
      "step": 3150
    },
    {
      "epoch": 0.03387659392021004,
      "grad_norm": 2.825263500213623,
      "learning_rate": 1.693838661867457e-05,
      "loss": 2.0338,
      "step": 3200
    },
    {
      "epoch": 0.03440591570021332,
      "grad_norm": 2.2833895683288574,
      "learning_rate": 1.7203048909591364e-05,
      "loss": 2.0275,
      "step": 3250
    },
    {
      "epoch": 0.0349352374802166,
      "grad_norm": 2.555863380432129,
      "learning_rate": 1.746771120050815e-05,
      "loss": 2.004,
      "step": 3300
    },
    {
      "epoch": 0.03546455926021988,
      "grad_norm": 2.690603733062744,
      "learning_rate": 1.773237349142494e-05,
      "loss": 2.0196,
      "step": 3350
    },
    {
      "epoch": 0.035993881040223163,
      "grad_norm": 2.4464340209960938,
      "learning_rate": 1.799703578234173e-05,
      "loss": 1.9949,
      "step": 3400
    },
    {
      "epoch": 0.03652320282022645,
      "grad_norm": 2.4886155128479004,
      "learning_rate": 1.826169807325852e-05,
      "loss": 2.016,
      "step": 3450
    },
    {
      "epoch": 0.03705252460022972,
      "grad_norm": 2.6017377376556396,
      "learning_rate": 1.8526360364175314e-05,
      "loss": 2.0051,
      "step": 3500
    },
    {
      "epoch": 0.03705252460022972,
      "eval_loss": 2.018789529800415,
      "eval_runtime": 47.1571,
      "eval_samples_per_second": 3561.078,
      "eval_steps_per_second": 445.151,
      "step": 3500
    },
    {
      "epoch": 0.03758184638023301,
      "grad_norm": 2.6897029876708984,
      "learning_rate": 1.8791022655092104e-05,
      "loss": 2.0168,
      "step": 3550
    },
    {
      "epoch": 0.03811116816023629,
      "grad_norm": 2.8564205169677734,
      "learning_rate": 1.9055684946008894e-05,
      "loss": 1.9868,
      "step": 3600
    },
    {
      "epoch": 0.038640489940239574,
      "grad_norm": 2.273420810699463,
      "learning_rate": 1.9320347236925684e-05,
      "loss": 2.0365,
      "step": 3650
    },
    {
      "epoch": 0.03916981172024285,
      "grad_norm": 2.5667176246643066,
      "learning_rate": 1.9585009527842473e-05,
      "loss": 1.9767,
      "step": 3700
    },
    {
      "epoch": 0.039699133500246134,
      "grad_norm": 2.55414080619812,
      "learning_rate": 1.9849671818759263e-05,
      "loss": 1.9856,
      "step": 3750
    },
    {
      "epoch": 0.04022845528024942,
      "grad_norm": 2.612440586090088,
      "learning_rate": 2.0114334109676053e-05,
      "loss": 1.9581,
      "step": 3800
    },
    {
      "epoch": 0.0407577770602527,
      "grad_norm": 2.6376967430114746,
      "learning_rate": 2.0378996400592843e-05,
      "loss": 2.0039,
      "step": 3850
    },
    {
      "epoch": 0.04128709884025598,
      "grad_norm": 2.118089437484741,
      "learning_rate": 2.0643658691509633e-05,
      "loss": 1.9931,
      "step": 3900
    },
    {
      "epoch": 0.04181642062025926,
      "grad_norm": 2.183565139770508,
      "learning_rate": 2.0908320982426423e-05,
      "loss": 1.9798,
      "step": 3950
    },
    {
      "epoch": 0.042345742400262544,
      "grad_norm": 2.8595666885375977,
      "learning_rate": 2.1172983273343216e-05,
      "loss": 1.986,
      "step": 4000
    },
    {
      "epoch": 0.042345742400262544,
      "eval_loss": 1.9927034378051758,
      "eval_runtime": 47.112,
      "eval_samples_per_second": 3564.484,
      "eval_steps_per_second": 445.576,
      "step": 4000
    },
    {
      "epoch": 0.04287506418026583,
      "grad_norm": 2.3293190002441406,
      "learning_rate": 2.1437645564260006e-05,
      "loss": 1.966,
      "step": 4050
    },
    {
      "epoch": 0.043404385960269104,
      "grad_norm": 2.355640411376953,
      "learning_rate": 2.1702307855176796e-05,
      "loss": 1.9676,
      "step": 4100
    },
    {
      "epoch": 0.04393370774027239,
      "grad_norm": 2.51493239402771,
      "learning_rate": 2.1966970146093586e-05,
      "loss": 1.9627,
      "step": 4150
    },
    {
      "epoch": 0.04446302952027567,
      "grad_norm": 2.010878086090088,
      "learning_rate": 2.2231632437010372e-05,
      "loss": 1.9589,
      "step": 4200
    },
    {
      "epoch": 0.044992351300278954,
      "grad_norm": 2.9191620349884033,
      "learning_rate": 2.2496294727927166e-05,
      "loss": 1.9653,
      "step": 4250
    },
    {
      "epoch": 0.04552167308028224,
      "grad_norm": 2.2551684379577637,
      "learning_rate": 2.2760957018843956e-05,
      "loss": 1.9771,
      "step": 4300
    },
    {
      "epoch": 0.046050994860285514,
      "grad_norm": 2.27020525932312,
      "learning_rate": 2.3025619309760746e-05,
      "loss": 1.9661,
      "step": 4350
    },
    {
      "epoch": 0.0465803166402888,
      "grad_norm": 2.019622325897217,
      "learning_rate": 2.3290281600677535e-05,
      "loss": 1.9401,
      "step": 4400
    },
    {
      "epoch": 0.04710963842029208,
      "grad_norm": 2.4465134143829346,
      "learning_rate": 2.3554943891594325e-05,
      "loss": 1.9428,
      "step": 4450
    },
    {
      "epoch": 0.047638960200295365,
      "grad_norm": 2.504423141479492,
      "learning_rate": 2.381960618251112e-05,
      "loss": 1.9321,
      "step": 4500
    },
    {
      "epoch": 0.047638960200295365,
      "eval_loss": 1.966475248336792,
      "eval_runtime": 47.3481,
      "eval_samples_per_second": 3546.711,
      "eval_steps_per_second": 443.355,
      "step": 4500
    },
    {
      "epoch": 0.04816828198029864,
      "grad_norm": 2.0894620418548584,
      "learning_rate": 2.408426847342791e-05,
      "loss": 1.9635,
      "step": 4550
    },
    {
      "epoch": 0.048697603760301925,
      "grad_norm": 2.2745022773742676,
      "learning_rate": 2.43489307643447e-05,
      "loss": 1.9599,
      "step": 4600
    },
    {
      "epoch": 0.04922692554030521,
      "grad_norm": 2.5232579708099365,
      "learning_rate": 2.4613593055261485e-05,
      "loss": 1.961,
      "step": 4650
    },
    {
      "epoch": 0.04975624732030849,
      "grad_norm": 2.299896001815796,
      "learning_rate": 2.4878255346178275e-05,
      "loss": 1.9646,
      "step": 4700
    },
    {
      "epoch": 0.05028556910031177,
      "grad_norm": 2.3800339698791504,
      "learning_rate": 2.5142917637095068e-05,
      "loss": 1.973,
      "step": 4750
    },
    {
      "epoch": 0.05081489088031505,
      "grad_norm": 2.2726261615753174,
      "learning_rate": 2.5407579928011858e-05,
      "loss": 1.944,
      "step": 4800
    },
    {
      "epoch": 0.051344212660318335,
      "grad_norm": 2.007843255996704,
      "learning_rate": 2.5672242218928648e-05,
      "loss": 1.9359,
      "step": 4850
    },
    {
      "epoch": 0.05187353444032162,
      "grad_norm": 2.729782819747925,
      "learning_rate": 2.5936904509845438e-05,
      "loss": 1.9199,
      "step": 4900
    },
    {
      "epoch": 0.052402856220324895,
      "grad_norm": 2.207836389541626,
      "learning_rate": 2.6201566800762228e-05,
      "loss": 1.9299,
      "step": 4950
    },
    {
      "epoch": 0.05293217800032818,
      "grad_norm": 2.2067694664001465,
      "learning_rate": 2.6466229091679018e-05,
      "loss": 1.9174,
      "step": 5000
    },
    {
      "epoch": 0.05293217800032818,
      "eval_loss": 1.9458867311477661,
      "eval_runtime": 47.1309,
      "eval_samples_per_second": 3563.052,
      "eval_steps_per_second": 445.397,
      "step": 5000
    },
    {
      "epoch": 0.05346149978033146,
      "grad_norm": 2.413890838623047,
      "learning_rate": 2.673089138259581e-05,
      "loss": 1.9282,
      "step": 5050
    },
    {
      "epoch": 0.053990821560334745,
      "grad_norm": 2.2362871170043945,
      "learning_rate": 2.6995553673512598e-05,
      "loss": 1.9336,
      "step": 5100
    },
    {
      "epoch": 0.05452014334033802,
      "grad_norm": 2.543964385986328,
      "learning_rate": 2.7260215964429387e-05,
      "loss": 1.9223,
      "step": 5150
    },
    {
      "epoch": 0.055049465120341305,
      "grad_norm": 2.149662971496582,
      "learning_rate": 2.7524878255346177e-05,
      "loss": 1.9402,
      "step": 5200
    },
    {
      "epoch": 0.05557878690034459,
      "grad_norm": 2.081566333770752,
      "learning_rate": 2.7789540546262967e-05,
      "loss": 1.9372,
      "step": 5250
    },
    {
      "epoch": 0.05610810868034787,
      "grad_norm": 2.1972100734710693,
      "learning_rate": 2.805420283717976e-05,
      "loss": 1.9321,
      "step": 5300
    },
    {
      "epoch": 0.056637430460351156,
      "grad_norm": 2.1110270023345947,
      "learning_rate": 2.831886512809655e-05,
      "loss": 1.9141,
      "step": 5350
    },
    {
      "epoch": 0.05716675224035443,
      "grad_norm": 2.175973892211914,
      "learning_rate": 2.858352741901334e-05,
      "loss": 1.9142,
      "step": 5400
    },
    {
      "epoch": 0.057696074020357715,
      "grad_norm": 2.233384132385254,
      "learning_rate": 2.884818970993013e-05,
      "loss": 1.9431,
      "step": 5450
    },
    {
      "epoch": 0.058225395800361,
      "grad_norm": 2.5231823921203613,
      "learning_rate": 2.9112852000846917e-05,
      "loss": 1.9382,
      "step": 5500
    },
    {
      "epoch": 0.058225395800361,
      "eval_loss": 1.9352617263793945,
      "eval_runtime": 47.2267,
      "eval_samples_per_second": 3555.829,
      "eval_steps_per_second": 444.494,
      "step": 5500
    },
    {
      "epoch": 0.05875471758036428,
      "grad_norm": 2.150653600692749,
      "learning_rate": 2.937751429176371e-05,
      "loss": 1.9193,
      "step": 5550
    },
    {
      "epoch": 0.05928403936036756,
      "grad_norm": 2.2149622440338135,
      "learning_rate": 2.96421765826805e-05,
      "loss": 1.9019,
      "step": 5600
    },
    {
      "epoch": 0.05981336114037084,
      "grad_norm": 2.471040964126587,
      "learning_rate": 2.990683887359729e-05,
      "loss": 1.9173,
      "step": 5650
    },
    {
      "epoch": 0.060342682920374126,
      "grad_norm": 2.337329864501953,
      "learning_rate": 3.017150116451408e-05,
      "loss": 1.9029,
      "step": 5700
    },
    {
      "epoch": 0.06087200470037741,
      "grad_norm": 2.1794910430908203,
      "learning_rate": 3.043616345543087e-05,
      "loss": 1.9042,
      "step": 5750
    },
    {
      "epoch": 0.061401326480380686,
      "grad_norm": 2.335200071334839,
      "learning_rate": 3.070082574634766e-05,
      "loss": 1.8892,
      "step": 5800
    },
    {
      "epoch": 0.06193064826038397,
      "grad_norm": 2.00254487991333,
      "learning_rate": 3.096548803726445e-05,
      "loss": 1.9031,
      "step": 5850
    },
    {
      "epoch": 0.06245997004038725,
      "grad_norm": 2.054858684539795,
      "learning_rate": 3.123015032818124e-05,
      "loss": 1.895,
      "step": 5900
    },
    {
      "epoch": 0.06298929182039054,
      "grad_norm": 2.620255947113037,
      "learning_rate": 3.1494812619098036e-05,
      "loss": 1.9013,
      "step": 5950
    },
    {
      "epoch": 0.06351861360039382,
      "grad_norm": 2.126687526702881,
      "learning_rate": 3.175947491001482e-05,
      "loss": 1.8888,
      "step": 6000
    },
    {
      "epoch": 0.06351861360039382,
      "eval_loss": 1.912047266960144,
      "eval_runtime": 47.1304,
      "eval_samples_per_second": 3563.094,
      "eval_steps_per_second": 445.403,
      "step": 6000
    },
    {
      "epoch": 0.0640479353803971,
      "grad_norm": 1.9615020751953125,
      "learning_rate": 3.2024137200931616e-05,
      "loss": 1.8975,
      "step": 6050
    },
    {
      "epoch": 0.06457725716040037,
      "grad_norm": 2.1452910900115967,
      "learning_rate": 3.22887994918484e-05,
      "loss": 1.891,
      "step": 6100
    },
    {
      "epoch": 0.06510657894040366,
      "grad_norm": 2.3506314754486084,
      "learning_rate": 3.2553461782765196e-05,
      "loss": 1.8777,
      "step": 6150
    },
    {
      "epoch": 0.06563590072040694,
      "grad_norm": 2.3094584941864014,
      "learning_rate": 3.281812407368198e-05,
      "loss": 1.8898,
      "step": 6200
    },
    {
      "epoch": 0.06616522250041022,
      "grad_norm": 2.870391845703125,
      "learning_rate": 3.308278636459877e-05,
      "loss": 1.892,
      "step": 6250
    },
    {
      "epoch": 0.0666945442804135,
      "grad_norm": 2.1331145763397217,
      "learning_rate": 3.334744865551556e-05,
      "loss": 1.9002,
      "step": 6300
    },
    {
      "epoch": 0.06722386606041679,
      "grad_norm": 1.981507658958435,
      "learning_rate": 3.361211094643235e-05,
      "loss": 1.8872,
      "step": 6350
    },
    {
      "epoch": 0.06775318784042007,
      "grad_norm": 2.6080410480499268,
      "learning_rate": 3.387677323734914e-05,
      "loss": 1.8805,
      "step": 6400
    },
    {
      "epoch": 0.06828250962042336,
      "grad_norm": 2.122544050216675,
      "learning_rate": 3.4141435528265935e-05,
      "loss": 1.8852,
      "step": 6450
    },
    {
      "epoch": 0.06881183140042664,
      "grad_norm": 2.293020248413086,
      "learning_rate": 3.440609781918273e-05,
      "loss": 1.8865,
      "step": 6500
    },
    {
      "epoch": 0.06881183140042664,
      "eval_loss": 1.891922950744629,
      "eval_runtime": 47.0789,
      "eval_samples_per_second": 3566.991,
      "eval_steps_per_second": 445.89,
      "step": 6500
    },
    {
      "epoch": 0.06934115318042991,
      "grad_norm": 2.1571543216705322,
      "learning_rate": 3.4670760110099515e-05,
      "loss": 1.8714,
      "step": 6550
    },
    {
      "epoch": 0.0698704749604332,
      "grad_norm": 2.112917423248291,
      "learning_rate": 3.49354224010163e-05,
      "loss": 1.8802,
      "step": 6600
    },
    {
      "epoch": 0.07039979674043648,
      "grad_norm": 1.9888075590133667,
      "learning_rate": 3.5200084691933095e-05,
      "loss": 1.8904,
      "step": 6650
    },
    {
      "epoch": 0.07092911852043976,
      "grad_norm": 2.1307413578033447,
      "learning_rate": 3.546474698284988e-05,
      "loss": 1.9026,
      "step": 6700
    },
    {
      "epoch": 0.07145844030044304,
      "grad_norm": 2.26363468170166,
      "learning_rate": 3.5729409273766675e-05,
      "loss": 1.8615,
      "step": 6750
    },
    {
      "epoch": 0.07198776208044633,
      "grad_norm": 2.0151801109313965,
      "learning_rate": 3.599407156468346e-05,
      "loss": 1.8954,
      "step": 6800
    },
    {
      "epoch": 0.07251708386044961,
      "grad_norm": 2.04575777053833,
      "learning_rate": 3.6258733855600254e-05,
      "loss": 1.8833,
      "step": 6850
    },
    {
      "epoch": 0.0730464056404529,
      "grad_norm": 2.0416274070739746,
      "learning_rate": 3.652339614651704e-05,
      "loss": 1.8726,
      "step": 6900
    },
    {
      "epoch": 0.07357572742045616,
      "grad_norm": 2.118227481842041,
      "learning_rate": 3.678805843743384e-05,
      "loss": 1.8698,
      "step": 6950
    },
    {
      "epoch": 0.07410504920045945,
      "grad_norm": 2.192324638366699,
      "learning_rate": 3.705272072835063e-05,
      "loss": 1.8495,
      "step": 7000
    },
    {
      "epoch": 0.07410504920045945,
      "eval_loss": 1.8766014575958252,
      "eval_runtime": 47.7749,
      "eval_samples_per_second": 3515.029,
      "eval_steps_per_second": 439.394,
      "step": 7000
    },
    {
      "epoch": 0.07463437098046273,
      "grad_norm": 2.2173500061035156,
      "learning_rate": 3.7317383019267414e-05,
      "loss": 1.8756,
      "step": 7050
    },
    {
      "epoch": 0.07516369276046601,
      "grad_norm": 2.2692127227783203,
      "learning_rate": 3.758204531018421e-05,
      "loss": 1.8907,
      "step": 7100
    },
    {
      "epoch": 0.0756930145404693,
      "grad_norm": 2.0019617080688477,
      "learning_rate": 3.7846707601100994e-05,
      "loss": 1.8884,
      "step": 7150
    },
    {
      "epoch": 0.07622233632047258,
      "grad_norm": 2.6216232776641846,
      "learning_rate": 3.811136989201779e-05,
      "loss": 1.861,
      "step": 7200
    },
    {
      "epoch": 0.07675165810047586,
      "grad_norm": 2.1092751026153564,
      "learning_rate": 3.8376032182934574e-05,
      "loss": 1.8582,
      "step": 7250
    },
    {
      "epoch": 0.07728097988047915,
      "grad_norm": 2.024174451828003,
      "learning_rate": 3.864069447385137e-05,
      "loss": 1.8482,
      "step": 7300
    },
    {
      "epoch": 0.07781030166048242,
      "grad_norm": 2.5606093406677246,
      "learning_rate": 3.8905356764768154e-05,
      "loss": 1.8553,
      "step": 7350
    },
    {
      "epoch": 0.0783396234404857,
      "grad_norm": 2.1288082599639893,
      "learning_rate": 3.917001905568495e-05,
      "loss": 1.8658,
      "step": 7400
    },
    {
      "epoch": 0.07886894522048898,
      "grad_norm": 2.0684540271759033,
      "learning_rate": 3.943468134660174e-05,
      "loss": 1.8641,
      "step": 7450
    },
    {
      "epoch": 0.07939826700049227,
      "grad_norm": 2.3710544109344482,
      "learning_rate": 3.969934363751853e-05,
      "loss": 1.8601,
      "step": 7500
    },
    {
      "epoch": 0.07939826700049227,
      "eval_loss": 1.8568209409713745,
      "eval_runtime": 47.4201,
      "eval_samples_per_second": 3541.322,
      "eval_steps_per_second": 442.681,
      "step": 7500
    },
    {
      "epoch": 0.07992758878049555,
      "grad_norm": 2.1808948516845703,
      "learning_rate": 3.996400592843532e-05,
      "loss": 1.8276,
      "step": 7550
    },
    {
      "epoch": 0.08045691056049883,
      "grad_norm": 2.5049192905426025,
      "learning_rate": 4.0228668219352106e-05,
      "loss": 1.8253,
      "step": 7600
    },
    {
      "epoch": 0.08098623234050212,
      "grad_norm": 2.5520405769348145,
      "learning_rate": 4.04933305102689e-05,
      "loss": 1.8392,
      "step": 7650
    },
    {
      "epoch": 0.0815155541205054,
      "grad_norm": 1.95558500289917,
      "learning_rate": 4.0757992801185686e-05,
      "loss": 1.8596,
      "step": 7700
    },
    {
      "epoch": 0.08204487590050868,
      "grad_norm": 2.1878530979156494,
      "learning_rate": 4.102265509210248e-05,
      "loss": 1.8493,
      "step": 7750
    },
    {
      "epoch": 0.08257419768051195,
      "grad_norm": 2.3967337608337402,
      "learning_rate": 4.1287317383019266e-05,
      "loss": 1.8387,
      "step": 7800
    },
    {
      "epoch": 0.08310351946051524,
      "grad_norm": 2.2984061241149902,
      "learning_rate": 4.155197967393606e-05,
      "loss": 1.8315,
      "step": 7850
    },
    {
      "epoch": 0.08363284124051852,
      "grad_norm": 2.111091136932373,
      "learning_rate": 4.1816641964852846e-05,
      "loss": 1.8299,
      "step": 7900
    },
    {
      "epoch": 0.0841621630205218,
      "grad_norm": 2.4549951553344727,
      "learning_rate": 4.208130425576963e-05,
      "loss": 1.8463,
      "step": 7950
    },
    {
      "epoch": 0.08469148480052509,
      "grad_norm": 2.2471845149993896,
      "learning_rate": 4.234596654668643e-05,
      "loss": 1.7906,
      "step": 8000
    },
    {
      "epoch": 0.08469148480052509,
      "eval_loss": 1.8369580507278442,
      "eval_runtime": 46.804,
      "eval_samples_per_second": 3587.943,
      "eval_steps_per_second": 448.509,
      "step": 8000
    },
    {
      "epoch": 0.08522080658052837,
      "grad_norm": 2.161545515060425,
      "learning_rate": 4.260533559178488e-05,
      "loss": 1.8262,
      "step": 8050
    },
    {
      "epoch": 0.08575012836053165,
      "grad_norm": 2.498903512954712,
      "learning_rate": 4.2869997882701674e-05,
      "loss": 1.8505,
      "step": 8100
    },
    {
      "epoch": 0.08627945014053494,
      "grad_norm": 2.3218257427215576,
      "learning_rate": 4.313466017361847e-05,
      "loss": 1.8249,
      "step": 8150
    },
    {
      "epoch": 0.08680877192053821,
      "grad_norm": 2.050226926803589,
      "learning_rate": 4.3399322464535254e-05,
      "loss": 1.8434,
      "step": 8200
    },
    {
      "epoch": 0.08733809370054149,
      "grad_norm": 2.157871723175049,
      "learning_rate": 4.366398475545205e-05,
      "loss": 1.8338,
      "step": 8250
    },
    {
      "epoch": 0.08786741548054477,
      "grad_norm": 2.0912554264068604,
      "learning_rate": 4.392864704636883e-05,
      "loss": 1.8049,
      "step": 8300
    },
    {
      "epoch": 0.08839673726054806,
      "grad_norm": 2.074110984802246,
      "learning_rate": 4.419330933728563e-05,
      "loss": 1.8386,
      "step": 8350
    },
    {
      "epoch": 0.08892605904055134,
      "grad_norm": 2.0712130069732666,
      "learning_rate": 4.445797162820241e-05,
      "loss": 1.8133,
      "step": 8400
    },
    {
      "epoch": 0.08945538082055463,
      "grad_norm": 2.1352813243865967,
      "learning_rate": 4.47226339191192e-05,
      "loss": 1.8324,
      "step": 8450
    },
    {
      "epoch": 0.08998470260055791,
      "grad_norm": 2.153841733932495,
      "learning_rate": 4.498729621003599e-05,
      "loss": 1.8065,
      "step": 8500
    },
    {
      "epoch": 0.08998470260055791,
      "eval_loss": 1.8035848140716553,
      "eval_runtime": 46.7768,
      "eval_samples_per_second": 3590.025,
      "eval_steps_per_second": 448.769,
      "step": 8500
    },
    {
      "epoch": 0.09051402438056119,
      "grad_norm": 2.419482469558716,
      "learning_rate": 4.525195850095278e-05,
      "loss": 1.8182,
      "step": 8550
    },
    {
      "epoch": 0.09104334616056448,
      "grad_norm": 2.218991756439209,
      "learning_rate": 4.551662079186958e-05,
      "loss": 1.8086,
      "step": 8600
    },
    {
      "epoch": 0.09157266794056775,
      "grad_norm": 2.283573865890503,
      "learning_rate": 4.5781283082786366e-05,
      "loss": 1.7896,
      "step": 8650
    },
    {
      "epoch": 0.09210198972057103,
      "grad_norm": 2.220665693283081,
      "learning_rate": 4.604594537370316e-05,
      "loss": 1.7851,
      "step": 8700
    },
    {
      "epoch": 0.09263131150057431,
      "grad_norm": 2.1625397205352783,
      "learning_rate": 4.6310607664619946e-05,
      "loss": 1.8115,
      "step": 8750
    },
    {
      "epoch": 0.0931606332805776,
      "grad_norm": 2.351741075515747,
      "learning_rate": 4.657526995553674e-05,
      "loss": 1.7943,
      "step": 8800
    },
    {
      "epoch": 0.09368995506058088,
      "grad_norm": 2.169060468673706,
      "learning_rate": 4.6839932246453526e-05,
      "loss": 1.8024,
      "step": 8850
    },
    {
      "epoch": 0.09421927684058416,
      "grad_norm": 2.5202910900115967,
      "learning_rate": 4.710459453737031e-05,
      "loss": 1.8073,
      "step": 8900
    },
    {
      "epoch": 0.09474859862058745,
      "grad_norm": 2.069213628768921,
      "learning_rate": 4.7369256828287106e-05,
      "loss": 1.7984,
      "step": 8950
    },
    {
      "epoch": 0.09527792040059073,
      "grad_norm": 2.0297064781188965,
      "learning_rate": 4.763391911920389e-05,
      "loss": 1.8009,
      "step": 9000
    },
    {
      "epoch": 0.09527792040059073,
      "eval_loss": 1.7791988849639893,
      "eval_runtime": 46.7556,
      "eval_samples_per_second": 3591.653,
      "eval_steps_per_second": 448.973,
      "step": 9000
    },
    {
      "epoch": 0.095807242180594,
      "grad_norm": 2.298400640487671,
      "learning_rate": 4.7898581410120685e-05,
      "loss": 1.8044,
      "step": 9050
    },
    {
      "epoch": 0.09633656396059728,
      "grad_norm": 2.0142242908477783,
      "learning_rate": 4.816324370103748e-05,
      "loss": 1.7772,
      "step": 9100
    },
    {
      "epoch": 0.09686588574060057,
      "grad_norm": 2.2162468433380127,
      "learning_rate": 4.842790599195427e-05,
      "loss": 1.7596,
      "step": 9150
    },
    {
      "epoch": 0.09739520752060385,
      "grad_norm": 2.2180519104003906,
      "learning_rate": 4.869256828287106e-05,
      "loss": 1.7794,
      "step": 9200
    },
    {
      "epoch": 0.09792452930060713,
      "grad_norm": 2.065720319747925,
      "learning_rate": 4.895723057378785e-05,
      "loss": 1.7808,
      "step": 9250
    },
    {
      "epoch": 0.09845385108061042,
      "grad_norm": 2.31825590133667,
      "learning_rate": 4.922189286470464e-05,
      "loss": 1.7772,
      "step": 9300
    },
    {
      "epoch": 0.0989831728606137,
      "grad_norm": 2.1647088527679443,
      "learning_rate": 4.9486555155621425e-05,
      "loss": 1.7854,
      "step": 9350
    },
    {
      "epoch": 0.09951249464061698,
      "grad_norm": 2.2411723136901855,
      "learning_rate": 4.975121744653822e-05,
      "loss": 1.7625,
      "step": 9400
    },
    {
      "epoch": 0.10004181642062025,
      "grad_norm": 2.1007986068725586,
      "learning_rate": 5.0015879737455005e-05,
      "loss": 1.7628,
      "step": 9450
    },
    {
      "epoch": 0.10057113820062354,
      "grad_norm": 2.3001046180725098,
      "learning_rate": 5.02805420283718e-05,
      "loss": 1.7842,
      "step": 9500
    },
    {
      "epoch": 0.10057113820062354,
      "eval_loss": 1.7579933404922485,
      "eval_runtime": 46.7518,
      "eval_samples_per_second": 3591.95,
      "eval_steps_per_second": 449.01,
      "step": 9500
    },
    {
      "epoch": 0.10110045998062682,
      "grad_norm": 2.332216739654541,
      "learning_rate": 5.0545204319288584e-05,
      "loss": 1.7941,
      "step": 9550
    },
    {
      "epoch": 0.1016297817606301,
      "grad_norm": 2.415754795074463,
      "learning_rate": 5.080986661020538e-05,
      "loss": 1.76,
      "step": 9600
    },
    {
      "epoch": 0.10215910354063339,
      "grad_norm": 2.2312917709350586,
      "learning_rate": 5.107452890112217e-05,
      "loss": 1.76,
      "step": 9650
    },
    {
      "epoch": 0.10268842532063667,
      "grad_norm": 2.2022340297698975,
      "learning_rate": 5.1339191192038964e-05,
      "loss": 1.767,
      "step": 9700
    },
    {
      "epoch": 0.10321774710063995,
      "grad_norm": 2.3738794326782227,
      "learning_rate": 5.160385348295575e-05,
      "loss": 1.749,
      "step": 9750
    },
    {
      "epoch": 0.10374706888064324,
      "grad_norm": 2.0982303619384766,
      "learning_rate": 5.186851577387254e-05,
      "loss": 1.741,
      "step": 9800
    },
    {
      "epoch": 0.10427639066064652,
      "grad_norm": 2.0197982788085938,
      "learning_rate": 5.213317806478933e-05,
      "loss": 1.7328,
      "step": 9850
    },
    {
      "epoch": 0.10480571244064979,
      "grad_norm": 2.338992118835449,
      "learning_rate": 5.239784035570612e-05,
      "loss": 1.7561,
      "step": 9900
    },
    {
      "epoch": 0.10533503422065307,
      "grad_norm": 2.3164117336273193,
      "learning_rate": 5.266250264662291e-05,
      "loss": 1.7538,
      "step": 9950
    },
    {
      "epoch": 0.10586435600065636,
      "grad_norm": 2.103163480758667,
      "learning_rate": 5.29271649375397e-05,
      "loss": 1.7629,
      "step": 10000
    },
    {
      "epoch": 0.10586435600065636,
      "eval_loss": 1.7273991107940674,
      "eval_runtime": 46.6881,
      "eval_samples_per_second": 3596.848,
      "eval_steps_per_second": 449.622,
      "step": 10000
    },
    {
      "epoch": 0.10639367778065964,
      "grad_norm": 2.160858392715454,
      "learning_rate": 5.319182722845649e-05,
      "loss": 1.7425,
      "step": 10050
    },
    {
      "epoch": 0.10692299956066292,
      "grad_norm": 2.345184326171875,
      "learning_rate": 5.345648951937328e-05,
      "loss": 1.7315,
      "step": 10100
    },
    {
      "epoch": 0.10745232134066621,
      "grad_norm": 2.130197525024414,
      "learning_rate": 5.371585856447173e-05,
      "loss": 1.7578,
      "step": 10150
    },
    {
      "epoch": 0.10798164312066949,
      "grad_norm": 2.1279308795928955,
      "learning_rate": 5.3980520855388525e-05,
      "loss": 1.7322,
      "step": 10200
    },
    {
      "epoch": 0.10851096490067277,
      "grad_norm": 2.2424914836883545,
      "learning_rate": 5.424518314630532e-05,
      "loss": 1.741,
      "step": 10250
    },
    {
      "epoch": 0.10904028668067604,
      "grad_norm": 2.1681065559387207,
      "learning_rate": 5.450984543722211e-05,
      "loss": 1.7509,
      "step": 10300
    },
    {
      "epoch": 0.10956960846067933,
      "grad_norm": 2.0816495418548584,
      "learning_rate": 5.47745077281389e-05,
      "loss": 1.7584,
      "step": 10350
    },
    {
      "epoch": 0.11009893024068261,
      "grad_norm": 2.246028423309326,
      "learning_rate": 5.5039170019055684e-05,
      "loss": 1.7263,
      "step": 10400
    },
    {
      "epoch": 0.1106282520206859,
      "grad_norm": 2.301323652267456,
      "learning_rate": 5.530383230997248e-05,
      "loss": 1.72,
      "step": 10450
    },
    {
      "epoch": 0.11115757380068918,
      "grad_norm": 2.06302809715271,
      "learning_rate": 5.5568494600889264e-05,
      "loss": 1.7508,
      "step": 10500
    },
    {
      "epoch": 0.11115757380068918,
      "eval_loss": 1.704856514930725,
      "eval_runtime": 46.765,
      "eval_samples_per_second": 3590.932,
      "eval_steps_per_second": 448.883,
      "step": 10500
    },
    {
      "epoch": 0.11168689558069246,
      "grad_norm": 2.3188281059265137,
      "learning_rate": 5.583315689180606e-05,
      "loss": 1.7334,
      "step": 10550
    },
    {
      "epoch": 0.11221621736069574,
      "grad_norm": 2.312810182571411,
      "learning_rate": 5.6097819182722844e-05,
      "loss": 1.7271,
      "step": 10600
    },
    {
      "epoch": 0.11274553914069903,
      "grad_norm": 2.1500234603881836,
      "learning_rate": 5.636248147363964e-05,
      "loss": 1.7377,
      "step": 10650
    },
    {
      "epoch": 0.11327486092070231,
      "grad_norm": 2.1561708450317383,
      "learning_rate": 5.6627143764556424e-05,
      "loss": 1.7238,
      "step": 10700
    },
    {
      "epoch": 0.11380418270070558,
      "grad_norm": 2.0475876331329346,
      "learning_rate": 5.6891806055473224e-05,
      "loss": 1.7252,
      "step": 10750
    },
    {
      "epoch": 0.11433350448070886,
      "grad_norm": 2.150355577468872,
      "learning_rate": 5.715646834639001e-05,
      "loss": 1.7402,
      "step": 10800
    },
    {
      "epoch": 0.11486282626071215,
      "grad_norm": 2.1430649757385254,
      "learning_rate": 5.74211306373068e-05,
      "loss": 1.7192,
      "step": 10850
    },
    {
      "epoch": 0.11539214804071543,
      "grad_norm": 2.250500440597534,
      "learning_rate": 5.768579292822359e-05,
      "loss": 1.7144,
      "step": 10900
    },
    {
      "epoch": 0.11592146982071871,
      "grad_norm": 1.977102279663086,
      "learning_rate": 5.795045521914038e-05,
      "loss": 1.7073,
      "step": 10950
    },
    {
      "epoch": 0.116450791600722,
      "grad_norm": 2.356100559234619,
      "learning_rate": 5.821511751005717e-05,
      "loss": 1.7142,
      "step": 11000
    },
    {
      "epoch": 0.116450791600722,
      "eval_loss": 1.6908241510391235,
      "eval_runtime": 46.7486,
      "eval_samples_per_second": 3592.194,
      "eval_steps_per_second": 449.04,
      "step": 11000
    },
    {
      "epoch": 0.11698011338072528,
      "grad_norm": 2.163802146911621,
      "learning_rate": 5.8479779800973957e-05,
      "loss": 1.735,
      "step": 11050
    },
    {
      "epoch": 0.11750943516072856,
      "grad_norm": 2.1386590003967285,
      "learning_rate": 5.874444209189075e-05,
      "loss": 1.7146,
      "step": 11100
    },
    {
      "epoch": 0.11803875694073183,
      "grad_norm": 2.270538330078125,
      "learning_rate": 5.9009104382807536e-05,
      "loss": 1.7077,
      "step": 11150
    },
    {
      "epoch": 0.11856807872073512,
      "grad_norm": 2.053825616836548,
      "learning_rate": 5.927376667372432e-05,
      "loss": 1.7119,
      "step": 11200
    },
    {
      "epoch": 0.1190974005007384,
      "grad_norm": 2.24832820892334,
      "learning_rate": 5.953842896464112e-05,
      "loss": 1.7054,
      "step": 11250
    },
    {
      "epoch": 0.11962672228074168,
      "grad_norm": 2.106459617614746,
      "learning_rate": 5.980309125555791e-05,
      "loss": 1.696,
      "step": 11300
    },
    {
      "epoch": 0.12015604406074497,
      "grad_norm": 2.151865243911743,
      "learning_rate": 6.00677535464747e-05,
      "loss": 1.7003,
      "step": 11350
    },
    {
      "epoch": 0.12068536584074825,
      "grad_norm": 2.4114627838134766,
      "learning_rate": 6.033241583739149e-05,
      "loss": 1.7234,
      "step": 11400
    },
    {
      "epoch": 0.12121468762075154,
      "grad_norm": 2.113598346710205,
      "learning_rate": 6.059707812830828e-05,
      "loss": 1.7052,
      "step": 11450
    },
    {
      "epoch": 0.12174400940075482,
      "grad_norm": 2.0777180194854736,
      "learning_rate": 6.086174041922507e-05,
      "loss": 1.7086,
      "step": 11500
    },
    {
      "epoch": 0.12174400940075482,
      "eval_loss": 1.6732372045516968,
      "eval_runtime": 46.7316,
      "eval_samples_per_second": 3593.497,
      "eval_steps_per_second": 449.203,
      "step": 11500
    },
    {
      "epoch": 0.12227333118075809,
      "grad_norm": 2.2257933616638184,
      "learning_rate": 6.112640271014186e-05,
      "loss": 1.7099,
      "step": 11550
    },
    {
      "epoch": 0.12280265296076137,
      "grad_norm": 2.231684446334839,
      "learning_rate": 6.139106500105865e-05,
      "loss": 1.7174,
      "step": 11600
    },
    {
      "epoch": 0.12333197474076465,
      "grad_norm": 2.3091986179351807,
      "learning_rate": 6.165572729197544e-05,
      "loss": 1.7092,
      "step": 11650
    },
    {
      "epoch": 0.12386129652076794,
      "grad_norm": 2.2880947589874268,
      "learning_rate": 6.192038958289222e-05,
      "loss": 1.7009,
      "step": 11700
    },
    {
      "epoch": 0.12439061830077122,
      "grad_norm": 2.1499571800231934,
      "learning_rate": 6.218505187380902e-05,
      "loss": 1.6849,
      "step": 11750
    },
    {
      "epoch": 0.1249199400807745,
      "grad_norm": 2.194214344024658,
      "learning_rate": 6.244971416472581e-05,
      "loss": 1.7029,
      "step": 11800
    },
    {
      "epoch": 0.1254492618607778,
      "grad_norm": 2.510394811630249,
      "learning_rate": 6.27143764556426e-05,
      "loss": 1.6997,
      "step": 11850
    },
    {
      "epoch": 0.12597858364078107,
      "grad_norm": 2.2231462001800537,
      "learning_rate": 6.297903874655938e-05,
      "loss": 1.6987,
      "step": 11900
    },
    {
      "epoch": 0.12650790542078436,
      "grad_norm": 2.3093860149383545,
      "learning_rate": 6.324370103747617e-05,
      "loss": 1.7014,
      "step": 11950
    },
    {
      "epoch": 0.12703722720078764,
      "grad_norm": 2.049990177154541,
      "learning_rate": 6.350836332839297e-05,
      "loss": 1.7032,
      "step": 12000
    },
    {
      "epoch": 0.12703722720078764,
      "eval_loss": 1.6524064540863037,
      "eval_runtime": 46.7942,
      "eval_samples_per_second": 3588.696,
      "eval_steps_per_second": 448.603,
      "step": 12000
    },
    {
      "epoch": 0.12756654898079092,
      "grad_norm": 2.015069007873535,
      "learning_rate": 6.377302561930978e-05,
      "loss": 1.7073,
      "step": 12050
    },
    {
      "epoch": 0.1280958707607942,
      "grad_norm": 2.0289723873138428,
      "learning_rate": 6.403768791022655e-05,
      "loss": 1.6846,
      "step": 12100
    },
    {
      "epoch": 0.1286251925407975,
      "grad_norm": 2.003512382507324,
      "learning_rate": 6.4297056955325e-05,
      "loss": 1.6682,
      "step": 12150
    },
    {
      "epoch": 0.12915451432080075,
      "grad_norm": 1.9927337169647217,
      "learning_rate": 6.45617192462418e-05,
      "loss": 1.6734,
      "step": 12200
    },
    {
      "epoch": 0.12968383610080403,
      "grad_norm": 1.9284098148345947,
      "learning_rate": 6.482638153715859e-05,
      "loss": 1.7001,
      "step": 12250
    },
    {
      "epoch": 0.1302131578808073,
      "grad_norm": 2.1193199157714844,
      "learning_rate": 6.509104382807537e-05,
      "loss": 1.6591,
      "step": 12300
    },
    {
      "epoch": 0.1307424796608106,
      "grad_norm": 2.0164499282836914,
      "learning_rate": 6.535570611899216e-05,
      "loss": 1.6916,
      "step": 12350
    },
    {
      "epoch": 0.13127180144081388,
      "grad_norm": 2.101799249649048,
      "learning_rate": 6.562036840990896e-05,
      "loss": 1.6888,
      "step": 12400
    },
    {
      "epoch": 0.13180112322081716,
      "grad_norm": 2.2823493480682373,
      "learning_rate": 6.588503070082575e-05,
      "loss": 1.6572,
      "step": 12450
    },
    {
      "epoch": 0.13233044500082045,
      "grad_norm": 1.9717265367507935,
      "learning_rate": 6.614969299174253e-05,
      "loss": 1.6793,
      "step": 12500
    },
    {
      "epoch": 0.13233044500082045,
      "eval_loss": 1.6461108922958374,
      "eval_runtime": 46.8637,
      "eval_samples_per_second": 3583.372,
      "eval_steps_per_second": 447.938,
      "step": 12500
    },
    {
      "epoch": 0.13285976678082373,
      "grad_norm": 2.0261478424072266,
      "learning_rate": 6.641435528265932e-05,
      "loss": 1.6967,
      "step": 12550
    },
    {
      "epoch": 0.133389088560827,
      "grad_norm": 1.9328668117523193,
      "learning_rate": 6.667901757357612e-05,
      "loss": 1.6718,
      "step": 12600
    },
    {
      "epoch": 0.1339184103408303,
      "grad_norm": 2.4459595680236816,
      "learning_rate": 6.694367986449291e-05,
      "loss": 1.6659,
      "step": 12650
    },
    {
      "epoch": 0.13444773212083358,
      "grad_norm": 2.0143394470214844,
      "learning_rate": 6.72083421554097e-05,
      "loss": 1.6568,
      "step": 12700
    },
    {
      "epoch": 0.13497705390083686,
      "grad_norm": 2.1515402793884277,
      "learning_rate": 6.74730044463265e-05,
      "loss": 1.6565,
      "step": 12750
    },
    {
      "epoch": 0.13550637568084015,
      "grad_norm": 2.205190658569336,
      "learning_rate": 6.773766673724329e-05,
      "loss": 1.692,
      "step": 12800
    },
    {
      "epoch": 0.13603569746084343,
      "grad_norm": 2.113224506378174,
      "learning_rate": 6.800232902816007e-05,
      "loss": 1.6727,
      "step": 12850
    },
    {
      "epoch": 0.1365650192408467,
      "grad_norm": 2.0633299350738525,
      "learning_rate": 6.826699131907686e-05,
      "loss": 1.6965,
      "step": 12900
    },
    {
      "epoch": 0.13709434102085,
      "grad_norm": 2.209289312362671,
      "learning_rate": 6.853165360999365e-05,
      "loss": 1.667,
      "step": 12950
    },
    {
      "epoch": 0.13762366280085328,
      "grad_norm": 2.0452449321746826,
      "learning_rate": 6.879631590091045e-05,
      "loss": 1.6678,
      "step": 13000
    },
    {
      "epoch": 0.13762366280085328,
      "eval_loss": 1.6303691864013672,
      "eval_runtime": 46.7998,
      "eval_samples_per_second": 3588.265,
      "eval_steps_per_second": 448.549,
      "step": 13000
    },
    {
      "epoch": 0.13815298458085654,
      "grad_norm": 2.318547248840332,
      "learning_rate": 6.906097819182723e-05,
      "loss": 1.6818,
      "step": 13050
    },
    {
      "epoch": 0.13868230636085982,
      "grad_norm": 2.0322234630584717,
      "learning_rate": 6.932564048274402e-05,
      "loss": 1.6823,
      "step": 13100
    },
    {
      "epoch": 0.1392116281408631,
      "grad_norm": 2.1346077919006348,
      "learning_rate": 6.959030277366081e-05,
      "loss": 1.64,
      "step": 13150
    },
    {
      "epoch": 0.1397409499208664,
      "grad_norm": 2.135118246078491,
      "learning_rate": 6.98549650645776e-05,
      "loss": 1.6579,
      "step": 13200
    },
    {
      "epoch": 0.14027027170086967,
      "grad_norm": 2.2299861907958984,
      "learning_rate": 7.011962735549439e-05,
      "loss": 1.6522,
      "step": 13250
    },
    {
      "epoch": 0.14079959348087295,
      "grad_norm": 1.85285484790802,
      "learning_rate": 7.038428964641118e-05,
      "loss": 1.663,
      "step": 13300
    },
    {
      "epoch": 0.14132891526087624,
      "grad_norm": 2.2228071689605713,
      "learning_rate": 7.064895193732797e-05,
      "loss": 1.6594,
      "step": 13350
    },
    {
      "epoch": 0.14185823704087952,
      "grad_norm": 1.9513410329818726,
      "learning_rate": 7.091361422824475e-05,
      "loss": 1.6536,
      "step": 13400
    },
    {
      "epoch": 0.1423875588208828,
      "grad_norm": 2.0475857257843018,
      "learning_rate": 7.117827651916155e-05,
      "loss": 1.6516,
      "step": 13450
    },
    {
      "epoch": 0.1429168806008861,
      "grad_norm": 1.9491533041000366,
      "learning_rate": 7.144293881007834e-05,
      "loss": 1.6366,
      "step": 13500
    },
    {
      "epoch": 0.1429168806008861,
      "eval_loss": 1.6178113222122192,
      "eval_runtime": 46.7959,
      "eval_samples_per_second": 3588.559,
      "eval_steps_per_second": 448.586,
      "step": 13500
    },
    {
      "epoch": 0.14344620238088937,
      "grad_norm": 2.093886375427246,
      "learning_rate": 7.170760110099512e-05,
      "loss": 1.6655,
      "step": 13550
    },
    {
      "epoch": 0.14397552416089265,
      "grad_norm": 2.0485076904296875,
      "learning_rate": 7.197226339191191e-05,
      "loss": 1.6362,
      "step": 13600
    },
    {
      "epoch": 0.14450484594089594,
      "grad_norm": 2.2814877033233643,
      "learning_rate": 7.22369256828287e-05,
      "loss": 1.6567,
      "step": 13650
    },
    {
      "epoch": 0.14503416772089922,
      "grad_norm": 2.1334593296051025,
      "learning_rate": 7.250158797374551e-05,
      "loss": 1.6558,
      "step": 13700
    },
    {
      "epoch": 0.1455634895009025,
      "grad_norm": 2.150653600692749,
      "learning_rate": 7.27662502646623e-05,
      "loss": 1.6457,
      "step": 13750
    },
    {
      "epoch": 0.1460928112809058,
      "grad_norm": 1.9952127933502197,
      "learning_rate": 7.303091255557909e-05,
      "loss": 1.6582,
      "step": 13800
    },
    {
      "epoch": 0.14662213306090904,
      "grad_norm": 1.9582926034927368,
      "learning_rate": 7.329557484649588e-05,
      "loss": 1.6382,
      "step": 13850
    },
    {
      "epoch": 0.14715145484091233,
      "grad_norm": 1.9792066812515259,
      "learning_rate": 7.356023713741267e-05,
      "loss": 1.6585,
      "step": 13900
    },
    {
      "epoch": 0.1476807766209156,
      "grad_norm": 2.0752933025360107,
      "learning_rate": 7.382489942832945e-05,
      "loss": 1.6332,
      "step": 13950
    },
    {
      "epoch": 0.1482100984009189,
      "grad_norm": 2.1103434562683105,
      "learning_rate": 7.408956171924625e-05,
      "loss": 1.6381,
      "step": 14000
    },
    {
      "epoch": 0.1482100984009189,
      "eval_loss": 1.6086243391036987,
      "eval_runtime": 46.7859,
      "eval_samples_per_second": 3589.333,
      "eval_steps_per_second": 448.683,
      "step": 14000
    },
    {
      "epoch": 0.14873942018092218,
      "grad_norm": 1.8862953186035156,
      "learning_rate": 7.435422401016304e-05,
      "loss": 1.6379,
      "step": 14050
    },
    {
      "epoch": 0.14926874196092546,
      "grad_norm": 1.9030566215515137,
      "learning_rate": 7.461888630107982e-05,
      "loss": 1.6474,
      "step": 14100
    },
    {
      "epoch": 0.14979806374092874,
      "grad_norm": 2.03975772857666,
      "learning_rate": 7.488354859199661e-05,
      "loss": 1.6407,
      "step": 14150
    },
    {
      "epoch": 0.15032738552093203,
      "grad_norm": 1.9076263904571533,
      "learning_rate": 7.51482108829134e-05,
      "loss": 1.6212,
      "step": 14200
    },
    {
      "epoch": 0.1508567073009353,
      "grad_norm": 2.076399564743042,
      "learning_rate": 7.54128731738302e-05,
      "loss": 1.6345,
      "step": 14250
    },
    {
      "epoch": 0.1513860290809386,
      "grad_norm": 1.7194430828094482,
      "learning_rate": 7.567753546474698e-05,
      "loss": 1.644,
      "step": 14300
    },
    {
      "epoch": 0.15191535086094188,
      "grad_norm": 2.1275060176849365,
      "learning_rate": 7.594219775566377e-05,
      "loss": 1.6342,
      "step": 14350
    },
    {
      "epoch": 0.15244467264094516,
      "grad_norm": 2.25392484664917,
      "learning_rate": 7.620686004658057e-05,
      "loss": 1.64,
      "step": 14400
    },
    {
      "epoch": 0.15297399442094844,
      "grad_norm": 2.083526849746704,
      "learning_rate": 7.646622909167903e-05,
      "loss": 1.6301,
      "step": 14450
    },
    {
      "epoch": 0.15350331620095173,
      "grad_norm": 1.8181028366088867,
      "learning_rate": 7.67308913825958e-05,
      "loss": 1.6352,
      "step": 14500
    },
    {
      "epoch": 0.15350331620095173,
      "eval_loss": 1.6006470918655396,
      "eval_runtime": 46.7995,
      "eval_samples_per_second": 3588.288,
      "eval_steps_per_second": 448.552,
      "step": 14500
    },
    {
      "epoch": 0.154032637980955,
      "grad_norm": 2.191240072250366,
      "learning_rate": 7.69955536735126e-05,
      "loss": 1.6423,
      "step": 14550
    },
    {
      "epoch": 0.1545619597609583,
      "grad_norm": 1.6370609998703003,
      "learning_rate": 7.72602159644294e-05,
      "loss": 1.6457,
      "step": 14600
    },
    {
      "epoch": 0.15509128154096158,
      "grad_norm": 2.0167620182037354,
      "learning_rate": 7.752487825534619e-05,
      "loss": 1.6289,
      "step": 14650
    },
    {
      "epoch": 0.15562060332096483,
      "grad_norm": 1.9185290336608887,
      "learning_rate": 7.778954054626297e-05,
      "loss": 1.6268,
      "step": 14700
    },
    {
      "epoch": 0.15614992510096812,
      "grad_norm": 1.8984851837158203,
      "learning_rate": 7.805420283717976e-05,
      "loss": 1.6386,
      "step": 14750
    },
    {
      "epoch": 0.1566792468809714,
      "grad_norm": 2.179826021194458,
      "learning_rate": 7.831886512809655e-05,
      "loss": 1.6247,
      "step": 14800
    },
    {
      "epoch": 0.15720856866097468,
      "grad_norm": 2.1069929599761963,
      "learning_rate": 7.858352741901335e-05,
      "loss": 1.6111,
      "step": 14850
    },
    {
      "epoch": 0.15773789044097797,
      "grad_norm": 2.0271353721618652,
      "learning_rate": 7.884818970993013e-05,
      "loss": 1.6538,
      "step": 14900
    },
    {
      "epoch": 0.15826721222098125,
      "grad_norm": 2.0527052879333496,
      "learning_rate": 7.911285200084692e-05,
      "loss": 1.6218,
      "step": 14950
    },
    {
      "epoch": 0.15879653400098453,
      "grad_norm": 1.9493300914764404,
      "learning_rate": 7.937751429176371e-05,
      "loss": 1.6198,
      "step": 15000
    },
    {
      "epoch": 0.15879653400098453,
      "eval_loss": 1.5887274742126465,
      "eval_runtime": 46.7629,
      "eval_samples_per_second": 3591.092,
      "eval_steps_per_second": 448.903,
      "step": 15000
    },
    {
      "epoch": 0.15932585578098782,
      "grad_norm": 2.0378732681274414,
      "learning_rate": 7.964217658268049e-05,
      "loss": 1.5975,
      "step": 15050
    },
    {
      "epoch": 0.1598551775609911,
      "grad_norm": 1.6942028999328613,
      "learning_rate": 7.990683887359729e-05,
      "loss": 1.6298,
      "step": 15100
    },
    {
      "epoch": 0.16038449934099439,
      "grad_norm": 2.1013529300689697,
      "learning_rate": 8.017150116451408e-05,
      "loss": 1.611,
      "step": 15150
    },
    {
      "epoch": 0.16091382112099767,
      "grad_norm": 1.8853625059127808,
      "learning_rate": 8.043616345543087e-05,
      "loss": 1.6012,
      "step": 15200
    },
    {
      "epoch": 0.16144314290100095,
      "grad_norm": 1.891361117362976,
      "learning_rate": 8.070082574634765e-05,
      "loss": 1.6212,
      "step": 15250
    },
    {
      "epoch": 0.16197246468100424,
      "grad_norm": 1.828661561012268,
      "learning_rate": 8.096548803726445e-05,
      "loss": 1.5953,
      "step": 15300
    },
    {
      "epoch": 0.16250178646100752,
      "grad_norm": 1.8596454858779907,
      "learning_rate": 8.123015032818125e-05,
      "loss": 1.6097,
      "step": 15350
    },
    {
      "epoch": 0.1630311082410108,
      "grad_norm": 1.9665411710739136,
      "learning_rate": 8.149481261909803e-05,
      "loss": 1.6111,
      "step": 15400
    },
    {
      "epoch": 0.16356043002101409,
      "grad_norm": 1.8163602352142334,
      "learning_rate": 8.175947491001483e-05,
      "loss": 1.6194,
      "step": 15450
    },
    {
      "epoch": 0.16408975180101737,
      "grad_norm": 1.7911362648010254,
      "learning_rate": 8.202413720093162e-05,
      "loss": 1.5921,
      "step": 15500
    },
    {
      "epoch": 0.16408975180101737,
      "eval_loss": 1.5818296670913696,
      "eval_runtime": 46.7617,
      "eval_samples_per_second": 3591.184,
      "eval_steps_per_second": 448.914,
      "step": 15500
    },
    {
      "epoch": 0.16461907358102063,
      "grad_norm": 1.7696033716201782,
      "learning_rate": 8.228879949184841e-05,
      "loss": 1.593,
      "step": 15550
    },
    {
      "epoch": 0.1651483953610239,
      "grad_norm": 1.9241983890533447,
      "learning_rate": 8.255346178276519e-05,
      "loss": 1.5937,
      "step": 15600
    },
    {
      "epoch": 0.1656777171410272,
      "grad_norm": 1.940861701965332,
      "learning_rate": 8.281812407368198e-05,
      "loss": 1.628,
      "step": 15650
    },
    {
      "epoch": 0.16620703892103048,
      "grad_norm": 1.8042141199111938,
      "learning_rate": 8.308278636459878e-05,
      "loss": 1.6119,
      "step": 15700
    },
    {
      "epoch": 0.16673636070103376,
      "grad_norm": 1.9342912435531616,
      "learning_rate": 8.334744865551557e-05,
      "loss": 1.6045,
      "step": 15750
    },
    {
      "epoch": 0.16726568248103704,
      "grad_norm": 2.01877498626709,
      "learning_rate": 8.361211094643235e-05,
      "loss": 1.611,
      "step": 15800
    },
    {
      "epoch": 0.16779500426104033,
      "grad_norm": 1.840650200843811,
      "learning_rate": 8.387677323734914e-05,
      "loss": 1.6033,
      "step": 15850
    },
    {
      "epoch": 0.1683243260410436,
      "grad_norm": 1.8381402492523193,
      "learning_rate": 8.414143552826594e-05,
      "loss": 1.6001,
      "step": 15900
    },
    {
      "epoch": 0.1688536478210469,
      "grad_norm": 1.8800419569015503,
      "learning_rate": 8.440609781918272e-05,
      "loss": 1.6037,
      "step": 15950
    },
    {
      "epoch": 0.16938296960105018,
      "grad_norm": 1.8915917873382568,
      "learning_rate": 8.467076011009951e-05,
      "loss": 1.6285,
      "step": 16000
    },
    {
      "epoch": 0.16938296960105018,
      "eval_loss": 1.5690240859985352,
      "eval_runtime": 46.8477,
      "eval_samples_per_second": 3584.596,
      "eval_steps_per_second": 448.09,
      "step": 16000
    },
    {
      "epoch": 0.16991229138105346,
      "grad_norm": 1.8670316934585571,
      "learning_rate": 8.49354224010163e-05,
      "loss": 1.6044,
      "step": 16050
    },
    {
      "epoch": 0.17044161316105674,
      "grad_norm": 1.7573590278625488,
      "learning_rate": 8.52000846919331e-05,
      "loss": 1.5929,
      "step": 16100
    },
    {
      "epoch": 0.17097093494106003,
      "grad_norm": 2.0983452796936035,
      "learning_rate": 8.546474698284988e-05,
      "loss": 1.5884,
      "step": 16150
    },
    {
      "epoch": 0.1715002567210633,
      "grad_norm": 1.974396824836731,
      "learning_rate": 8.572940927376667e-05,
      "loss": 1.624,
      "step": 16200
    },
    {
      "epoch": 0.1720295785010666,
      "grad_norm": 1.9677146673202515,
      "learning_rate": 8.599407156468346e-05,
      "loss": 1.6033,
      "step": 16250
    },
    {
      "epoch": 0.17255890028106988,
      "grad_norm": 1.862444519996643,
      "learning_rate": 8.625873385560024e-05,
      "loss": 1.6113,
      "step": 16300
    },
    {
      "epoch": 0.17308822206107316,
      "grad_norm": 1.9441859722137451,
      "learning_rate": 8.652339614651705e-05,
      "loss": 1.5964,
      "step": 16350
    },
    {
      "epoch": 0.17361754384107642,
      "grad_norm": 1.9227042198181152,
      "learning_rate": 8.678805843743384e-05,
      "loss": 1.5941,
      "step": 16400
    },
    {
      "epoch": 0.1741468656210797,
      "grad_norm": 1.6701925992965698,
      "learning_rate": 8.705272072835064e-05,
      "loss": 1.5798,
      "step": 16450
    },
    {
      "epoch": 0.17467618740108298,
      "grad_norm": 1.9326180219650269,
      "learning_rate": 8.731738301926742e-05,
      "loss": 1.6054,
      "step": 16500
    },
    {
      "epoch": 0.17467618740108298,
      "eval_loss": 1.5606869459152222,
      "eval_runtime": 46.7441,
      "eval_samples_per_second": 3592.541,
      "eval_steps_per_second": 449.084,
      "step": 16500
    },
    {
      "epoch": 0.17520550918108627,
      "grad_norm": 1.6571860313415527,
      "learning_rate": 8.758204531018421e-05,
      "loss": 1.6092,
      "step": 16550
    },
    {
      "epoch": 0.17573483096108955,
      "grad_norm": 1.7717467546463013,
      "learning_rate": 8.7846707601101e-05,
      "loss": 1.5849,
      "step": 16600
    },
    {
      "epoch": 0.17626415274109283,
      "grad_norm": 1.7698553800582886,
      "learning_rate": 8.81113698920178e-05,
      "loss": 1.573,
      "step": 16650
    },
    {
      "epoch": 0.17679347452109612,
      "grad_norm": 1.8313288688659668,
      "learning_rate": 8.837603218293458e-05,
      "loss": 1.6258,
      "step": 16700
    },
    {
      "epoch": 0.1773227963010994,
      "grad_norm": 1.7853420972824097,
      "learning_rate": 8.864069447385137e-05,
      "loss": 1.5872,
      "step": 16750
    },
    {
      "epoch": 0.17785211808110268,
      "grad_norm": 1.8974108695983887,
      "learning_rate": 8.890535676476816e-05,
      "loss": 1.5821,
      "step": 16800
    },
    {
      "epoch": 0.17838143986110597,
      "grad_norm": 1.7563813924789429,
      "learning_rate": 8.917001905568494e-05,
      "loss": 1.5865,
      "step": 16850
    },
    {
      "epoch": 0.17891076164110925,
      "grad_norm": 1.9180775880813599,
      "learning_rate": 8.943468134660174e-05,
      "loss": 1.5718,
      "step": 16900
    },
    {
      "epoch": 0.17944008342111253,
      "grad_norm": 1.9214013814926147,
      "learning_rate": 8.969934363751853e-05,
      "loss": 1.58,
      "step": 16950
    },
    {
      "epoch": 0.17996940520111582,
      "grad_norm": 1.86180579662323,
      "learning_rate": 8.996400592843532e-05,
      "loss": 1.5785,
      "step": 17000
    },
    {
      "epoch": 0.17996940520111582,
      "eval_loss": 1.5507341623306274,
      "eval_runtime": 46.7809,
      "eval_samples_per_second": 3589.711,
      "eval_steps_per_second": 448.73,
      "step": 17000
    },
    {
      "epoch": 0.1804987269811191,
      "grad_norm": 1.9048130512237549,
      "learning_rate": 9.02286682193521e-05,
      "loss": 1.5816,
      "step": 17050
    },
    {
      "epoch": 0.18102804876112238,
      "grad_norm": 1.8064771890640259,
      "learning_rate": 9.04933305102689e-05,
      "loss": 1.5874,
      "step": 17100
    },
    {
      "epoch": 0.18155737054112567,
      "grad_norm": 1.8701751232147217,
      "learning_rate": 9.075799280118569e-05,
      "loss": 1.5784,
      "step": 17150
    },
    {
      "epoch": 0.18208669232112895,
      "grad_norm": 1.6955397129058838,
      "learning_rate": 9.102265509210247e-05,
      "loss": 1.5851,
      "step": 17200
    },
    {
      "epoch": 0.1826160141011322,
      "grad_norm": 1.8600690364837646,
      "learning_rate": 9.128731738301926e-05,
      "loss": 1.5904,
      "step": 17250
    },
    {
      "epoch": 0.1831453358811355,
      "grad_norm": 1.831654667854309,
      "learning_rate": 9.154668642811772e-05,
      "loss": 1.5745,
      "step": 17300
    },
    {
      "epoch": 0.18367465766113877,
      "grad_norm": 1.6505752801895142,
      "learning_rate": 9.181134871903452e-05,
      "loss": 1.5506,
      "step": 17350
    },
    {
      "epoch": 0.18420397944114206,
      "grad_norm": 1.6702966690063477,
      "learning_rate": 9.207601100995131e-05,
      "loss": 1.5731,
      "step": 17400
    },
    {
      "epoch": 0.18473330122114534,
      "grad_norm": 1.6987096071243286,
      "learning_rate": 9.234067330086809e-05,
      "loss": 1.5781,
      "step": 17450
    },
    {
      "epoch": 0.18526262300114862,
      "grad_norm": 1.914947271347046,
      "learning_rate": 9.260533559178488e-05,
      "loss": 1.586,
      "step": 17500
    },
    {
      "epoch": 0.18526262300114862,
      "eval_loss": 1.5456746816635132,
      "eval_runtime": 46.7532,
      "eval_samples_per_second": 3591.837,
      "eval_steps_per_second": 448.996,
      "step": 17500
    },
    {
      "epoch": 0.1857919447811519,
      "grad_norm": 1.876530408859253,
      "learning_rate": 9.286999788270168e-05,
      "loss": 1.5684,
      "step": 17550
    },
    {
      "epoch": 0.1863212665611552,
      "grad_norm": 1.6933746337890625,
      "learning_rate": 9.313466017361847e-05,
      "loss": 1.5643,
      "step": 17600
    },
    {
      "epoch": 0.18685058834115847,
      "grad_norm": 1.9429861307144165,
      "learning_rate": 9.339932246453525e-05,
      "loss": 1.5578,
      "step": 17650
    },
    {
      "epoch": 0.18737991012116176,
      "grad_norm": 1.7862176895141602,
      "learning_rate": 9.366398475545204e-05,
      "loss": 1.5794,
      "step": 17700
    },
    {
      "epoch": 0.18790923190116504,
      "grad_norm": 1.6871529817581177,
      "learning_rate": 9.392864704636884e-05,
      "loss": 1.5869,
      "step": 17750
    },
    {
      "epoch": 0.18843855368116832,
      "grad_norm": 1.6035600900650024,
      "learning_rate": 9.419330933728562e-05,
      "loss": 1.5573,
      "step": 17800
    },
    {
      "epoch": 0.1889678754611716,
      "grad_norm": 1.8712737560272217,
      "learning_rate": 9.445797162820241e-05,
      "loss": 1.5974,
      "step": 17850
    },
    {
      "epoch": 0.1894971972411749,
      "grad_norm": 1.7654598951339722,
      "learning_rate": 9.47226339191192e-05,
      "loss": 1.5762,
      "step": 17900
    },
    {
      "epoch": 0.19002651902117818,
      "grad_norm": 1.8081656694412231,
      "learning_rate": 9.4987296210036e-05,
      "loss": 1.5738,
      "step": 17950
    },
    {
      "epoch": 0.19055584080118146,
      "grad_norm": 1.564217209815979,
      "learning_rate": 9.525195850095279e-05,
      "loss": 1.5862,
      "step": 18000
    },
    {
      "epoch": 0.19055584080118146,
      "eval_loss": 1.5350937843322754,
      "eval_runtime": 46.7984,
      "eval_samples_per_second": 3588.369,
      "eval_steps_per_second": 448.562,
      "step": 18000
    },
    {
      "epoch": 0.19108516258118471,
      "grad_norm": 1.8533939123153687,
      "learning_rate": 9.551662079186958e-05,
      "loss": 1.553,
      "step": 18050
    },
    {
      "epoch": 0.191614484361188,
      "grad_norm": 1.9375340938568115,
      "learning_rate": 9.578128308278638e-05,
      "loss": 1.5564,
      "step": 18100
    },
    {
      "epoch": 0.19214380614119128,
      "grad_norm": 1.5779919624328613,
      "learning_rate": 9.604594537370315e-05,
      "loss": 1.5543,
      "step": 18150
    },
    {
      "epoch": 0.19267312792119456,
      "grad_norm": 1.7407196760177612,
      "learning_rate": 9.631060766461995e-05,
      "loss": 1.5748,
      "step": 18200
    },
    {
      "epoch": 0.19320244970119785,
      "grad_norm": 1.8253003358840942,
      "learning_rate": 9.657526995553674e-05,
      "loss": 1.5971,
      "step": 18250
    },
    {
      "epoch": 0.19373177148120113,
      "grad_norm": 1.6912147998809814,
      "learning_rate": 9.683993224645353e-05,
      "loss": 1.5529,
      "step": 18300
    },
    {
      "epoch": 0.19426109326120442,
      "grad_norm": 1.598337173461914,
      "learning_rate": 9.710459453737031e-05,
      "loss": 1.5622,
      "step": 18350
    },
    {
      "epoch": 0.1947904150412077,
      "grad_norm": 1.6851874589920044,
      "learning_rate": 9.736925682828711e-05,
      "loss": 1.5504,
      "step": 18400
    },
    {
      "epoch": 0.19531973682121098,
      "grad_norm": 1.708540678024292,
      "learning_rate": 9.76339191192039e-05,
      "loss": 1.5732,
      "step": 18450
    },
    {
      "epoch": 0.19584905860121427,
      "grad_norm": 1.778003215789795,
      "learning_rate": 9.78985814101207e-05,
      "loss": 1.5472,
      "step": 18500
    },
    {
      "epoch": 0.19584905860121427,
      "eval_loss": 1.5319161415100098,
      "eval_runtime": 46.7916,
      "eval_samples_per_second": 3588.889,
      "eval_steps_per_second": 448.627,
      "step": 18500
    },
    {
      "epoch": 0.19637838038121755,
      "grad_norm": 1.690834879875183,
      "learning_rate": 9.816324370103747e-05,
      "loss": 1.575,
      "step": 18550
    },
    {
      "epoch": 0.19690770216122083,
      "grad_norm": 1.5786422491073608,
      "learning_rate": 9.842790599195427e-05,
      "loss": 1.549,
      "step": 18600
    },
    {
      "epoch": 0.19743702394122412,
      "grad_norm": 1.6676393747329712,
      "learning_rate": 9.869256828287106e-05,
      "loss": 1.5633,
      "step": 18650
    },
    {
      "epoch": 0.1979663457212274,
      "grad_norm": 1.7320023775100708,
      "learning_rate": 9.895723057378784e-05,
      "loss": 1.5536,
      "step": 18700
    },
    {
      "epoch": 0.19849566750123068,
      "grad_norm": 1.7483375072479248,
      "learning_rate": 9.922189286470463e-05,
      "loss": 1.5494,
      "step": 18750
    },
    {
      "epoch": 0.19902498928123397,
      "grad_norm": 1.6588895320892334,
      "learning_rate": 9.948655515562143e-05,
      "loss": 1.5217,
      "step": 18800
    },
    {
      "epoch": 0.19955431106123725,
      "grad_norm": 1.6547876596450806,
      "learning_rate": 9.975121744653822e-05,
      "loss": 1.5671,
      "step": 18850
    },
    {
      "epoch": 0.2000836328412405,
      "grad_norm": 1.6752099990844727,
      "learning_rate": 0.000100015879737455,
      "loss": 1.5619,
      "step": 18900
    },
    {
      "epoch": 0.2006129546212438,
      "grad_norm": 1.7604938745498657,
      "learning_rate": 0.0001002805420283718,
      "loss": 1.5436,
      "step": 18950
    },
    {
      "epoch": 0.20114227640124707,
      "grad_norm": 1.7330073118209839,
      "learning_rate": 0.0001005452043192886,
      "loss": 1.5605,
      "step": 19000
    },
    {
      "epoch": 0.20114227640124707,
      "eval_loss": 1.53005051612854,
      "eval_runtime": 46.8038,
      "eval_samples_per_second": 3587.958,
      "eval_steps_per_second": 448.511,
      "step": 19000
    },
    {
      "epoch": 0.20167159818125036,
      "grad_norm": 1.6400200128555298,
      "learning_rate": 0.00010080986661020538,
      "loss": 1.5487,
      "step": 19050
    },
    {
      "epoch": 0.20220091996125364,
      "grad_norm": 1.7939358949661255,
      "learning_rate": 0.00010107452890112217,
      "loss": 1.553,
      "step": 19100
    },
    {
      "epoch": 0.20273024174125692,
      "grad_norm": 1.551107406616211,
      "learning_rate": 0.00010133919119203897,
      "loss": 1.5466,
      "step": 19150
    },
    {
      "epoch": 0.2032595635212602,
      "grad_norm": 1.6430555582046509,
      "learning_rate": 0.00010160385348295576,
      "loss": 1.5285,
      "step": 19200
    },
    {
      "epoch": 0.2037888853012635,
      "grad_norm": 1.6655417680740356,
      "learning_rate": 0.00010186851577387254,
      "loss": 1.545,
      "step": 19250
    },
    {
      "epoch": 0.20431820708126677,
      "grad_norm": 1.4813461303710938,
      "learning_rate": 0.00010213317806478933,
      "loss": 1.5325,
      "step": 19300
    },
    {
      "epoch": 0.20484752886127006,
      "grad_norm": 1.5538932085037231,
      "learning_rate": 0.00010239784035570613,
      "loss": 1.5478,
      "step": 19350
    },
    {
      "epoch": 0.20537685064127334,
      "grad_norm": 1.6386512517929077,
      "learning_rate": 0.00010266250264662292,
      "loss": 1.544,
      "step": 19400
    },
    {
      "epoch": 0.20590617242127662,
      "grad_norm": 1.5077089071273804,
      "learning_rate": 0.0001029271649375397,
      "loss": 1.538,
      "step": 19450
    },
    {
      "epoch": 0.2064354942012799,
      "grad_norm": 1.6181480884552002,
      "learning_rate": 0.00010319182722845649,
      "loss": 1.5398,
      "step": 19500
    },
    {
      "epoch": 0.2064354942012799,
      "eval_loss": 1.51860511302948,
      "eval_runtime": 46.7735,
      "eval_samples_per_second": 3590.283,
      "eval_steps_per_second": 448.801,
      "step": 19500
    },
    {
      "epoch": 0.2069648159812832,
      "grad_norm": 1.9861671924591064,
      "learning_rate": 0.00010345648951937329,
      "loss": 1.5458,
      "step": 19550
    },
    {
      "epoch": 0.20749413776128647,
      "grad_norm": 1.5604106187820435,
      "learning_rate": 0.00010372115181029007,
      "loss": 1.5421,
      "step": 19600
    },
    {
      "epoch": 0.20802345954128976,
      "grad_norm": 1.5355960130691528,
      "learning_rate": 0.00010398581410120686,
      "loss": 1.5364,
      "step": 19650
    },
    {
      "epoch": 0.20855278132129304,
      "grad_norm": 1.7192941904067993,
      "learning_rate": 0.00010425047639212365,
      "loss": 1.5444,
      "step": 19700
    },
    {
      "epoch": 0.2090821031012963,
      "grad_norm": 1.3991613388061523,
      "learning_rate": 0.00010451513868304045,
      "loss": 1.5221,
      "step": 19750
    },
    {
      "epoch": 0.20961142488129958,
      "grad_norm": 1.464908480644226,
      "learning_rate": 0.00010477980097395723,
      "loss": 1.53,
      "step": 19800
    },
    {
      "epoch": 0.21014074666130286,
      "grad_norm": 1.6266769170761108,
      "learning_rate": 0.00010504446326487402,
      "loss": 1.559,
      "step": 19850
    },
    {
      "epoch": 0.21067006844130615,
      "grad_norm": 1.5890319347381592,
      "learning_rate": 0.00010530912555579081,
      "loss": 1.5476,
      "step": 19900
    },
    {
      "epoch": 0.21119939022130943,
      "grad_norm": 1.496151328086853,
      "learning_rate": 0.00010557378784670759,
      "loss": 1.5476,
      "step": 19950
    },
    {
      "epoch": 0.2117287120013127,
      "grad_norm": 1.6697516441345215,
      "learning_rate": 0.00010583845013762438,
      "loss": 1.5419,
      "step": 20000
    },
    {
      "epoch": 0.2117287120013127,
      "eval_loss": 1.5204066038131714,
      "eval_runtime": 46.7494,
      "eval_samples_per_second": 3592.135,
      "eval_steps_per_second": 449.033,
      "step": 20000
    },
    {
      "epoch": 0.212258033781316,
      "grad_norm": 1.4877784252166748,
      "learning_rate": 0.00010610311242854119,
      "loss": 1.5142,
      "step": 20050
    },
    {
      "epoch": 0.21278735556131928,
      "grad_norm": 1.6842975616455078,
      "learning_rate": 0.00010636777471945799,
      "loss": 1.5488,
      "step": 20100
    },
    {
      "epoch": 0.21331667734132256,
      "grad_norm": 1.5456047058105469,
      "learning_rate": 0.00010663243701037476,
      "loss": 1.5246,
      "step": 20150
    },
    {
      "epoch": 0.21384599912132585,
      "grad_norm": 1.4186944961547852,
      "learning_rate": 0.00010689709930129156,
      "loss": 1.5366,
      "step": 20200
    },
    {
      "epoch": 0.21437532090132913,
      "grad_norm": 1.7050249576568604,
      "learning_rate": 0.00010716176159220835,
      "loss": 1.5308,
      "step": 20250
    },
    {
      "epoch": 0.21490464268133241,
      "grad_norm": 1.6962302923202515,
      "learning_rate": 0.00010742642388312513,
      "loss": 1.5299,
      "step": 20300
    },
    {
      "epoch": 0.2154339644613357,
      "grad_norm": 1.6786410808563232,
      "learning_rate": 0.00010769108617404192,
      "loss": 1.5694,
      "step": 20350
    },
    {
      "epoch": 0.21596328624133898,
      "grad_norm": 1.5175045728683472,
      "learning_rate": 0.00010795574846495872,
      "loss": 1.5374,
      "step": 20400
    },
    {
      "epoch": 0.21649260802134226,
      "grad_norm": 1.768113374710083,
      "learning_rate": 0.00010822041075587551,
      "loss": 1.5289,
      "step": 20450
    },
    {
      "epoch": 0.21702192980134555,
      "grad_norm": 1.5480808019638062,
      "learning_rate": 0.00010848507304679229,
      "loss": 1.5211,
      "step": 20500
    },
    {
      "epoch": 0.21702192980134555,
      "eval_loss": 1.5066711902618408,
      "eval_runtime": 46.6941,
      "eval_samples_per_second": 3596.385,
      "eval_steps_per_second": 449.564,
      "step": 20500
    },
    {
      "epoch": 0.21755125158134883,
      "grad_norm": 1.427180528640747,
      "learning_rate": 0.00010874973533770908,
      "loss": 1.5401,
      "step": 20550
    },
    {
      "epoch": 0.2180805733613521,
      "grad_norm": 1.496476411819458,
      "learning_rate": 0.00010901439762862588,
      "loss": 1.5272,
      "step": 20600
    },
    {
      "epoch": 0.21860989514135537,
      "grad_norm": 1.452725887298584,
      "learning_rate": 0.00010927905991954267,
      "loss": 1.4974,
      "step": 20650
    },
    {
      "epoch": 0.21913921692135865,
      "grad_norm": 1.5760178565979004,
      "learning_rate": 0.00010954372221045945,
      "loss": 1.5505,
      "step": 20700
    },
    {
      "epoch": 0.21966853870136194,
      "grad_norm": 1.6460448503494263,
      "learning_rate": 0.00010980838450137624,
      "loss": 1.5342,
      "step": 20750
    },
    {
      "epoch": 0.22019786048136522,
      "grad_norm": 1.5555102825164795,
      "learning_rate": 0.00011007304679229304,
      "loss": 1.5307,
      "step": 20800
    },
    {
      "epoch": 0.2207271822613685,
      "grad_norm": 1.6128417253494263,
      "learning_rate": 0.0001103324158373915,
      "loss": 1.5238,
      "step": 20850
    },
    {
      "epoch": 0.2212565040413718,
      "grad_norm": 1.438050389289856,
      "learning_rate": 0.00011059707812830828,
      "loss": 1.5374,
      "step": 20900
    },
    {
      "epoch": 0.22178582582137507,
      "grad_norm": 1.4263672828674316,
      "learning_rate": 0.00011086174041922507,
      "loss": 1.504,
      "step": 20950
    },
    {
      "epoch": 0.22231514760137835,
      "grad_norm": 1.5855282545089722,
      "learning_rate": 0.00011112640271014186,
      "loss": 1.5231,
      "step": 21000
    },
    {
      "epoch": 0.22231514760137835,
      "eval_loss": 1.5023528337478638,
      "eval_runtime": 46.7696,
      "eval_samples_per_second": 3590.582,
      "eval_steps_per_second": 448.839,
      "step": 21000
    },
    {
      "epoch": 0.22284446938138164,
      "grad_norm": 1.3769086599349976,
      "learning_rate": 0.00011139106500105866,
      "loss": 1.5142,
      "step": 21050
    },
    {
      "epoch": 0.22337379116138492,
      "grad_norm": 1.5995510816574097,
      "learning_rate": 0.00011165572729197544,
      "loss": 1.5187,
      "step": 21100
    },
    {
      "epoch": 0.2239031129413882,
      "grad_norm": 1.6331290006637573,
      "learning_rate": 0.00011192038958289223,
      "loss": 1.5379,
      "step": 21150
    },
    {
      "epoch": 0.2244324347213915,
      "grad_norm": 1.456502914428711,
      "learning_rate": 0.00011218505187380902,
      "loss": 1.5091,
      "step": 21200
    },
    {
      "epoch": 0.22496175650139477,
      "grad_norm": 1.441112756729126,
      "learning_rate": 0.00011244971416472582,
      "loss": 1.5348,
      "step": 21250
    },
    {
      "epoch": 0.22549107828139806,
      "grad_norm": 1.6336320638656616,
      "learning_rate": 0.0001127143764556426,
      "loss": 1.5366,
      "step": 21300
    },
    {
      "epoch": 0.22602040006140134,
      "grad_norm": 1.374483346939087,
      "learning_rate": 0.00011297903874655939,
      "loss": 1.5191,
      "step": 21350
    },
    {
      "epoch": 0.22654972184140462,
      "grad_norm": 1.5086004734039307,
      "learning_rate": 0.00011324370103747618,
      "loss": 1.5159,
      "step": 21400
    },
    {
      "epoch": 0.22707904362140788,
      "grad_norm": 1.3553800582885742,
      "learning_rate": 0.00011350836332839296,
      "loss": 1.5047,
      "step": 21450
    },
    {
      "epoch": 0.22760836540141116,
      "grad_norm": 1.5265761613845825,
      "learning_rate": 0.00011377302561930976,
      "loss": 1.4974,
      "step": 21500
    },
    {
      "epoch": 0.22760836540141116,
      "eval_loss": 1.4982646703720093,
      "eval_runtime": 46.7873,
      "eval_samples_per_second": 3589.225,
      "eval_steps_per_second": 448.669,
      "step": 21500
    },
    {
      "epoch": 0.22813768718141444,
      "grad_norm": 1.3468726873397827,
      "learning_rate": 0.00011403768791022655,
      "loss": 1.5234,
      "step": 21550
    },
    {
      "epoch": 0.22866700896141773,
      "grad_norm": 1.4721949100494385,
      "learning_rate": 0.00011430235020114334,
      "loss": 1.5031,
      "step": 21600
    },
    {
      "epoch": 0.229196330741421,
      "grad_norm": 1.3656028509140015,
      "learning_rate": 0.00011456701249206012,
      "loss": 1.5315,
      "step": 21650
    },
    {
      "epoch": 0.2297256525214243,
      "grad_norm": 1.5092517137527466,
      "learning_rate": 0.00011483167478297693,
      "loss": 1.5138,
      "step": 21700
    },
    {
      "epoch": 0.23025497430142758,
      "grad_norm": 1.422721266746521,
      "learning_rate": 0.00011509633707389372,
      "loss": 1.5291,
      "step": 21750
    },
    {
      "epoch": 0.23078429608143086,
      "grad_norm": 1.5718141794204712,
      "learning_rate": 0.0001153609993648105,
      "loss": 1.5089,
      "step": 21800
    },
    {
      "epoch": 0.23131361786143415,
      "grad_norm": 1.5518499612808228,
      "learning_rate": 0.0001156256616557273,
      "loss": 1.5297,
      "step": 21850
    },
    {
      "epoch": 0.23184293964143743,
      "grad_norm": 1.2601972818374634,
      "learning_rate": 0.00011589032394664409,
      "loss": 1.5173,
      "step": 21900
    },
    {
      "epoch": 0.2323722614214407,
      "grad_norm": 1.543717622756958,
      "learning_rate": 0.00011615498623756088,
      "loss": 1.5202,
      "step": 21950
    },
    {
      "epoch": 0.232901583201444,
      "grad_norm": 1.4447717666625977,
      "learning_rate": 0.00011641964852847766,
      "loss": 1.5007,
      "step": 22000
    },
    {
      "epoch": 0.232901583201444,
      "eval_loss": 1.4968533515930176,
      "eval_runtime": 46.7567,
      "eval_samples_per_second": 3591.573,
      "eval_steps_per_second": 448.963,
      "step": 22000
    },
    {
      "epoch": 0.23343090498144728,
      "grad_norm": 1.4239575862884521,
      "learning_rate": 0.00011668431081939446,
      "loss": 1.5205,
      "step": 22050
    },
    {
      "epoch": 0.23396022676145056,
      "grad_norm": 1.4087234735488892,
      "learning_rate": 0.00011694897311031125,
      "loss": 1.5301,
      "step": 22100
    },
    {
      "epoch": 0.23448954854145385,
      "grad_norm": 1.5751525163650513,
      "learning_rate": 0.00011721363540122803,
      "loss": 1.5238,
      "step": 22150
    },
    {
      "epoch": 0.23501887032145713,
      "grad_norm": 1.4603902101516724,
      "learning_rate": 0.00011747829769214482,
      "loss": 1.5191,
      "step": 22200
    },
    {
      "epoch": 0.23554819210146039,
      "grad_norm": 1.5345546007156372,
      "learning_rate": 0.00011774295998306162,
      "loss": 1.5103,
      "step": 22250
    },
    {
      "epoch": 0.23607751388146367,
      "grad_norm": 1.3751672506332397,
      "learning_rate": 0.00011800762227397841,
      "loss": 1.5088,
      "step": 22300
    },
    {
      "epoch": 0.23660683566146695,
      "grad_norm": 1.391882300376892,
      "learning_rate": 0.00011827228456489519,
      "loss": 1.4915,
      "step": 22350
    },
    {
      "epoch": 0.23713615744147024,
      "grad_norm": 1.4473457336425781,
      "learning_rate": 0.00011853694685581198,
      "loss": 1.5205,
      "step": 22400
    },
    {
      "epoch": 0.23766547922147352,
      "grad_norm": 1.4254380464553833,
      "learning_rate": 0.00011880160914672878,
      "loss": 1.5287,
      "step": 22450
    },
    {
      "epoch": 0.2381948010014768,
      "grad_norm": 1.5060458183288574,
      "learning_rate": 0.00011906627143764557,
      "loss": 1.4904,
      "step": 22500
    },
    {
      "epoch": 0.2381948010014768,
      "eval_loss": 1.488341212272644,
      "eval_runtime": 46.7881,
      "eval_samples_per_second": 3589.164,
      "eval_steps_per_second": 448.662,
      "step": 22500
    },
    {
      "epoch": 0.23872412278148009,
      "grad_norm": 1.2570029497146606,
      "learning_rate": 0.00011933093372856235,
      "loss": 1.5044,
      "step": 22550
    },
    {
      "epoch": 0.23925344456148337,
      "grad_norm": 1.4267241954803467,
      "learning_rate": 0.00011959559601947914,
      "loss": 1.4964,
      "step": 22600
    },
    {
      "epoch": 0.23978276634148665,
      "grad_norm": 1.515157699584961,
      "learning_rate": 0.00011986025831039594,
      "loss": 1.5125,
      "step": 22650
    },
    {
      "epoch": 0.24031208812148994,
      "grad_norm": 1.5582596063613892,
      "learning_rate": 0.00012012492060131273,
      "loss": 1.5177,
      "step": 22700
    },
    {
      "epoch": 0.24084140990149322,
      "grad_norm": 1.3921594619750977,
      "learning_rate": 0.00012038958289222952,
      "loss": 1.5203,
      "step": 22750
    },
    {
      "epoch": 0.2413707316814965,
      "grad_norm": 1.3994240760803223,
      "learning_rate": 0.00012065424518314631,
      "loss": 1.4849,
      "step": 22800
    },
    {
      "epoch": 0.2419000534614998,
      "grad_norm": 1.3977447748184204,
      "learning_rate": 0.00012091890747406311,
      "loss": 1.5085,
      "step": 22850
    },
    {
      "epoch": 0.24242937524150307,
      "grad_norm": 1.367842435836792,
      "learning_rate": 0.00012118356976497989,
      "loss": 1.4837,
      "step": 22900
    },
    {
      "epoch": 0.24295869702150635,
      "grad_norm": 1.4025031328201294,
      "learning_rate": 0.00012144823205589668,
      "loss": 1.5021,
      "step": 22950
    },
    {
      "epoch": 0.24348801880150964,
      "grad_norm": 1.3685181140899658,
      "learning_rate": 0.00012171289434681347,
      "loss": 1.4918,
      "step": 23000
    },
    {
      "epoch": 0.24348801880150964,
      "eval_loss": 1.4874130487442017,
      "eval_runtime": 46.7491,
      "eval_samples_per_second": 3592.156,
      "eval_steps_per_second": 449.036,
      "step": 23000
    },
    {
      "epoch": 0.24401734058151292,
      "grad_norm": 1.3751606941223145,
      "learning_rate": 0.00012197755663773025,
      "loss": 1.5169,
      "step": 23050
    },
    {
      "epoch": 0.24454666236151618,
      "grad_norm": 1.458528995513916,
      "learning_rate": 0.00012224221892864705,
      "loss": 1.4854,
      "step": 23100
    },
    {
      "epoch": 0.24507598414151946,
      "grad_norm": 1.4083837270736694,
      "learning_rate": 0.00012250688121956383,
      "loss": 1.4949,
      "step": 23150
    },
    {
      "epoch": 0.24560530592152274,
      "grad_norm": 1.3723598718643188,
      "learning_rate": 0.00012277154351048063,
      "loss": 1.5127,
      "step": 23200
    },
    {
      "epoch": 0.24613462770152603,
      "grad_norm": 1.35433828830719,
      "learning_rate": 0.00012303620580139741,
      "loss": 1.483,
      "step": 23250
    },
    {
      "epoch": 0.2466639494815293,
      "grad_norm": 1.409183144569397,
      "learning_rate": 0.00012330086809231422,
      "loss": 1.4849,
      "step": 23300
    },
    {
      "epoch": 0.2471932712615326,
      "grad_norm": 1.3231966495513916,
      "learning_rate": 0.000123565530383231,
      "loss": 1.5045,
      "step": 23350
    },
    {
      "epoch": 0.24772259304153588,
      "grad_norm": 1.39167320728302,
      "learning_rate": 0.00012383019267414778,
      "loss": 1.4854,
      "step": 23400
    },
    {
      "epoch": 0.24825191482153916,
      "grad_norm": 1.4052232503890991,
      "learning_rate": 0.0001240948549650646,
      "loss": 1.4909,
      "step": 23450
    },
    {
      "epoch": 0.24878123660154244,
      "grad_norm": 1.5400651693344116,
      "learning_rate": 0.00012435951725598137,
      "loss": 1.5222,
      "step": 23500
    },
    {
      "epoch": 0.24878123660154244,
      "eval_loss": 1.4800660610198975,
      "eval_runtime": 46.7655,
      "eval_samples_per_second": 3590.893,
      "eval_steps_per_second": 448.878,
      "step": 23500
    },
    {
      "epoch": 0.24931055838154573,
      "grad_norm": 1.3096178770065308,
      "learning_rate": 0.00012462417954689815,
      "loss": 1.5071,
      "step": 23550
    },
    {
      "epoch": 0.249839880161549,
      "grad_norm": 1.3499119281768799,
      "learning_rate": 0.00012488884183781495,
      "loss": 1.5177,
      "step": 23600
    },
    {
      "epoch": 0.25036920194155227,
      "grad_norm": 1.5368080139160156,
      "learning_rate": 0.00012515350412873176,
      "loss": 1.5136,
      "step": 23650
    },
    {
      "epoch": 0.2508985237215556,
      "grad_norm": 1.2744344472885132,
      "learning_rate": 0.00012541816641964854,
      "loss": 1.501,
      "step": 23700
    },
    {
      "epoch": 0.25142784550155883,
      "grad_norm": 1.373579978942871,
      "learning_rate": 0.00012568282871056532,
      "loss": 1.499,
      "step": 23750
    },
    {
      "epoch": 0.25195716728156214,
      "grad_norm": 1.362734079360962,
      "learning_rate": 0.00012594749100148213,
      "loss": 1.4851,
      "step": 23800
    },
    {
      "epoch": 0.2524864890615654,
      "grad_norm": 1.3524712324142456,
      "learning_rate": 0.0001262121532923989,
      "loss": 1.4967,
      "step": 23850
    },
    {
      "epoch": 0.2530158108415687,
      "grad_norm": 1.4550026655197144,
      "learning_rate": 0.00012647681558331569,
      "loss": 1.4824,
      "step": 23900
    },
    {
      "epoch": 0.25354513262157197,
      "grad_norm": 1.4793487787246704,
      "learning_rate": 0.0001267414778742325,
      "loss": 1.504,
      "step": 23950
    },
    {
      "epoch": 0.2540744544015753,
      "grad_norm": 1.4087504148483276,
      "learning_rate": 0.00012700614016514927,
      "loss": 1.4993,
      "step": 24000
    },
    {
      "epoch": 0.2540744544015753,
      "eval_loss": 1.4759280681610107,
      "eval_runtime": 46.7723,
      "eval_samples_per_second": 3590.37,
      "eval_steps_per_second": 448.812,
      "step": 24000
    },
    {
      "epoch": 0.25460377618157853,
      "grad_norm": 1.2920621633529663,
      "learning_rate": 0.00012727080245606605,
      "loss": 1.516,
      "step": 24050
    },
    {
      "epoch": 0.25513309796158185,
      "grad_norm": 1.4397467374801636,
      "learning_rate": 0.00012753546474698286,
      "loss": 1.4822,
      "step": 24100
    },
    {
      "epoch": 0.2556624197415851,
      "grad_norm": 1.3792649507522583,
      "learning_rate": 0.00012780012703789964,
      "loss": 1.4958,
      "step": 24150
    },
    {
      "epoch": 0.2561917415215884,
      "grad_norm": 1.2002485990524292,
      "learning_rate": 0.00012806478932881645,
      "loss": 1.4942,
      "step": 24200
    },
    {
      "epoch": 0.25672106330159167,
      "grad_norm": 1.3579920530319214,
      "learning_rate": 0.00012832945161973323,
      "loss": 1.4951,
      "step": 24250
    },
    {
      "epoch": 0.257250385081595,
      "grad_norm": 1.3671894073486328,
      "learning_rate": 0.00012859411391065,
      "loss": 1.4929,
      "step": 24300
    },
    {
      "epoch": 0.25777970686159823,
      "grad_norm": 1.31754469871521,
      "learning_rate": 0.0001288587762015668,
      "loss": 1.4928,
      "step": 24350
    },
    {
      "epoch": 0.2583090286416015,
      "grad_norm": 1.367777943611145,
      "learning_rate": 0.0001291234384924836,
      "loss": 1.4757,
      "step": 24400
    },
    {
      "epoch": 0.2588383504216048,
      "grad_norm": 1.3633854389190674,
      "learning_rate": 0.00012938810078340037,
      "loss": 1.5038,
      "step": 24450
    },
    {
      "epoch": 0.25936767220160806,
      "grad_norm": 1.3373427391052246,
      "learning_rate": 0.00012965276307431718,
      "loss": 1.492,
      "step": 24500
    },
    {
      "epoch": 0.25936767220160806,
      "eval_loss": 1.4733281135559082,
      "eval_runtime": 46.7575,
      "eval_samples_per_second": 3591.509,
      "eval_steps_per_second": 448.955,
      "step": 24500
    },
    {
      "epoch": 0.25989699398161137,
      "grad_norm": 1.3172813653945923,
      "learning_rate": 0.00012991742536523396,
      "loss": 1.4915,
      "step": 24550
    },
    {
      "epoch": 0.2604263157616146,
      "grad_norm": 1.2464390993118286,
      "learning_rate": 0.00013018208765615074,
      "loss": 1.486,
      "step": 24600
    },
    {
      "epoch": 0.26095563754161794,
      "grad_norm": 1.3251653909683228,
      "learning_rate": 0.00013044674994706754,
      "loss": 1.5105,
      "step": 24650
    },
    {
      "epoch": 0.2614849593216212,
      "grad_norm": 1.2651101350784302,
      "learning_rate": 0.00013071141223798432,
      "loss": 1.4879,
      "step": 24700
    },
    {
      "epoch": 0.2620142811016245,
      "grad_norm": 1.1510003805160522,
      "learning_rate": 0.00013097607452890113,
      "loss": 1.4992,
      "step": 24750
    },
    {
      "epoch": 0.26254360288162776,
      "grad_norm": 1.3303141593933105,
      "learning_rate": 0.00013123544357399958,
      "loss": 1.501,
      "step": 24800
    },
    {
      "epoch": 0.26307292466163107,
      "grad_norm": 1.3563103675842285,
      "learning_rate": 0.00013150010586491636,
      "loss": 1.4691,
      "step": 24850
    },
    {
      "epoch": 0.2636022464416343,
      "grad_norm": 1.2416105270385742,
      "learning_rate": 0.00013176476815583317,
      "loss": 1.4888,
      "step": 24900
    },
    {
      "epoch": 0.26413156822163764,
      "grad_norm": 1.2582634687423706,
      "learning_rate": 0.00013202943044674995,
      "loss": 1.4861,
      "step": 24950
    },
    {
      "epoch": 0.2646608900016409,
      "grad_norm": 1.334625482559204,
      "learning_rate": 0.00013229409273766673,
      "loss": 1.4784,
      "step": 25000
    },
    {
      "epoch": 0.2646608900016409,
      "eval_loss": 1.468955636024475,
      "eval_runtime": 46.7562,
      "eval_samples_per_second": 3591.609,
      "eval_steps_per_second": 448.967,
      "step": 25000
    },
    {
      "epoch": 0.2651902117816442,
      "grad_norm": 1.2941861152648926,
      "learning_rate": 0.00013255875502858353,
      "loss": 1.4743,
      "step": 25050
    },
    {
      "epoch": 0.26571953356164746,
      "grad_norm": 1.3653672933578491,
      "learning_rate": 0.0001328234173195003,
      "loss": 1.4938,
      "step": 25100
    },
    {
      "epoch": 0.26624885534165077,
      "grad_norm": 1.1980700492858887,
      "learning_rate": 0.00013308807961041712,
      "loss": 1.4983,
      "step": 25150
    },
    {
      "epoch": 0.266778177121654,
      "grad_norm": 1.5098176002502441,
      "learning_rate": 0.0001333527419013339,
      "loss": 1.4607,
      "step": 25200
    },
    {
      "epoch": 0.2673074989016573,
      "grad_norm": 1.2438366413116455,
      "learning_rate": 0.00013361740419225068,
      "loss": 1.472,
      "step": 25250
    },
    {
      "epoch": 0.2678368206816606,
      "grad_norm": 1.3364839553833008,
      "learning_rate": 0.00013388206648316749,
      "loss": 1.4517,
      "step": 25300
    },
    {
      "epoch": 0.26836614246166385,
      "grad_norm": 1.3338677883148193,
      "learning_rate": 0.00013414672877408427,
      "loss": 1.4872,
      "step": 25350
    },
    {
      "epoch": 0.26889546424166716,
      "grad_norm": 1.1153396368026733,
      "learning_rate": 0.00013441139106500104,
      "loss": 1.4708,
      "step": 25400
    },
    {
      "epoch": 0.2694247860216704,
      "grad_norm": 1.1588282585144043,
      "learning_rate": 0.00013467605335591785,
      "loss": 1.4831,
      "step": 25450
    },
    {
      "epoch": 0.2699541078016737,
      "grad_norm": 1.227898120880127,
      "learning_rate": 0.00013494071564683463,
      "loss": 1.4892,
      "step": 25500
    },
    {
      "epoch": 0.2699541078016737,
      "eval_loss": 1.4650107622146606,
      "eval_runtime": 46.7334,
      "eval_samples_per_second": 3593.36,
      "eval_steps_per_second": 449.186,
      "step": 25500
    },
    {
      "epoch": 0.270483429581677,
      "grad_norm": 1.4286463260650635,
      "learning_rate": 0.0001352053779377514,
      "loss": 1.4779,
      "step": 25550
    },
    {
      "epoch": 0.2710127513616803,
      "grad_norm": 1.158756136894226,
      "learning_rate": 0.00013547004022866822,
      "loss": 1.4719,
      "step": 25600
    },
    {
      "epoch": 0.27154207314168355,
      "grad_norm": 1.266563892364502,
      "learning_rate": 0.000135734702519585,
      "loss": 1.4853,
      "step": 25650
    },
    {
      "epoch": 0.27207139492168686,
      "grad_norm": 1.4988694190979004,
      "learning_rate": 0.0001359993648105018,
      "loss": 1.4811,
      "step": 25700
    },
    {
      "epoch": 0.2726007167016901,
      "grad_norm": 1.334333062171936,
      "learning_rate": 0.00013626402710141858,
      "loss": 1.4889,
      "step": 25750
    },
    {
      "epoch": 0.2731300384816934,
      "grad_norm": 1.3049263954162598,
      "learning_rate": 0.00013652868939233536,
      "loss": 1.4864,
      "step": 25800
    },
    {
      "epoch": 0.2736593602616967,
      "grad_norm": 1.162194013595581,
      "learning_rate": 0.00013679335168325217,
      "loss": 1.5026,
      "step": 25850
    },
    {
      "epoch": 0.2741886820417,
      "grad_norm": 1.2975444793701172,
      "learning_rate": 0.00013705801397416898,
      "loss": 1.4941,
      "step": 25900
    },
    {
      "epoch": 0.27471800382170325,
      "grad_norm": 1.3980801105499268,
      "learning_rate": 0.00013732267626508576,
      "loss": 1.4661,
      "step": 25950
    },
    {
      "epoch": 0.27524732560170656,
      "grad_norm": 1.2294775247573853,
      "learning_rate": 0.00013758733855600256,
      "loss": 1.493,
      "step": 26000
    },
    {
      "epoch": 0.27524732560170656,
      "eval_loss": 1.4608367681503296,
      "eval_runtime": 46.7348,
      "eval_samples_per_second": 3593.256,
      "eval_steps_per_second": 449.173,
      "step": 26000
    },
    {
      "epoch": 0.2757766473817098,
      "grad_norm": 1.2483850717544556,
      "learning_rate": 0.00013785200084691934,
      "loss": 1.5068,
      "step": 26050
    },
    {
      "epoch": 0.27630596916171307,
      "grad_norm": 1.154944896697998,
      "learning_rate": 0.00013811666313783612,
      "loss": 1.4835,
      "step": 26100
    },
    {
      "epoch": 0.2768352909417164,
      "grad_norm": 1.2306783199310303,
      "learning_rate": 0.00013838132542875293,
      "loss": 1.4784,
      "step": 26150
    },
    {
      "epoch": 0.27736461272171964,
      "grad_norm": 1.391182780265808,
      "learning_rate": 0.0001386459877196697,
      "loss": 1.4869,
      "step": 26200
    },
    {
      "epoch": 0.27789393450172295,
      "grad_norm": 1.3091535568237305,
      "learning_rate": 0.0001389106500105865,
      "loss": 1.498,
      "step": 26250
    },
    {
      "epoch": 0.2784232562817262,
      "grad_norm": 1.228614330291748,
      "learning_rate": 0.0001391753123015033,
      "loss": 1.47,
      "step": 26300
    },
    {
      "epoch": 0.2789525780617295,
      "grad_norm": 1.2903753519058228,
      "learning_rate": 0.00013943997459242008,
      "loss": 1.4535,
      "step": 26350
    },
    {
      "epoch": 0.2794818998417328,
      "grad_norm": 1.1334763765335083,
      "learning_rate": 0.00013970463688333688,
      "loss": 1.4623,
      "step": 26400
    },
    {
      "epoch": 0.2800112216217361,
      "grad_norm": 1.1863656044006348,
      "learning_rate": 0.00013996929917425366,
      "loss": 1.4561,
      "step": 26450
    },
    {
      "epoch": 0.28054054340173934,
      "grad_norm": 1.4389662742614746,
      "learning_rate": 0.00014023396146517044,
      "loss": 1.4633,
      "step": 26500
    },
    {
      "epoch": 0.28054054340173934,
      "eval_loss": 1.460692048072815,
      "eval_runtime": 46.7061,
      "eval_samples_per_second": 3595.463,
      "eval_steps_per_second": 449.449,
      "step": 26500
    },
    {
      "epoch": 0.28106986518174265,
      "grad_norm": 1.2347415685653687,
      "learning_rate": 0.00014049862375608725,
      "loss": 1.4651,
      "step": 26550
    },
    {
      "epoch": 0.2815991869617459,
      "grad_norm": 1.2384649515151978,
      "learning_rate": 0.00014076328604700403,
      "loss": 1.4716,
      "step": 26600
    },
    {
      "epoch": 0.2821285087417492,
      "grad_norm": 1.2341521978378296,
      "learning_rate": 0.0001410279483379208,
      "loss": 1.4828,
      "step": 26650
    },
    {
      "epoch": 0.2826578305217525,
      "grad_norm": 1.195273995399475,
      "learning_rate": 0.00014129261062883762,
      "loss": 1.4815,
      "step": 26700
    },
    {
      "epoch": 0.2831871523017558,
      "grad_norm": 1.3841516971588135,
      "learning_rate": 0.0001415572729197544,
      "loss": 1.4636,
      "step": 26750
    },
    {
      "epoch": 0.28371647408175904,
      "grad_norm": 1.2090001106262207,
      "learning_rate": 0.00014182193521067118,
      "loss": 1.4676,
      "step": 26800
    },
    {
      "epoch": 0.28424579586176235,
      "grad_norm": 1.3406753540039062,
      "learning_rate": 0.00014208659750158798,
      "loss": 1.4813,
      "step": 26850
    },
    {
      "epoch": 0.2847751176417656,
      "grad_norm": 1.1635724306106567,
      "learning_rate": 0.00014235125979250476,
      "loss": 1.4641,
      "step": 26900
    },
    {
      "epoch": 0.28530443942176886,
      "grad_norm": 1.2875561714172363,
      "learning_rate": 0.00014261592208342157,
      "loss": 1.4702,
      "step": 26950
    },
    {
      "epoch": 0.2858337612017722,
      "grad_norm": 1.2080633640289307,
      "learning_rate": 0.00014287529112852002,
      "loss": 1.4892,
      "step": 27000
    },
    {
      "epoch": 0.2858337612017722,
      "eval_loss": 1.4569144248962402,
      "eval_runtime": 46.7314,
      "eval_samples_per_second": 3593.519,
      "eval_steps_per_second": 449.206,
      "step": 27000
    },
    {
      "epoch": 0.28636308298177543,
      "grad_norm": 1.1846367120742798,
      "learning_rate": 0.0001431399534194368,
      "loss": 1.4593,
      "step": 27050
    },
    {
      "epoch": 0.28689240476177874,
      "grad_norm": 1.117276668548584,
      "learning_rate": 0.0001434046157103536,
      "loss": 1.4772,
      "step": 27100
    },
    {
      "epoch": 0.287421726541782,
      "grad_norm": 1.3437426090240479,
      "learning_rate": 0.00014366927800127038,
      "loss": 1.4592,
      "step": 27150
    },
    {
      "epoch": 0.2879510483217853,
      "grad_norm": 1.2857576608657837,
      "learning_rate": 0.00014393394029218716,
      "loss": 1.4581,
      "step": 27200
    },
    {
      "epoch": 0.28848037010178856,
      "grad_norm": 1.184267282485962,
      "learning_rate": 0.00014419860258310397,
      "loss": 1.4629,
      "step": 27250
    },
    {
      "epoch": 0.2890096918817919,
      "grad_norm": 1.2994649410247803,
      "learning_rate": 0.00014446326487402075,
      "loss": 1.4621,
      "step": 27300
    },
    {
      "epoch": 0.28953901366179513,
      "grad_norm": 1.1759960651397705,
      "learning_rate": 0.00014472792716493756,
      "loss": 1.4869,
      "step": 27350
    },
    {
      "epoch": 0.29006833544179844,
      "grad_norm": 1.1862176656723022,
      "learning_rate": 0.00014499258945585434,
      "loss": 1.4892,
      "step": 27400
    },
    {
      "epoch": 0.2905976572218017,
      "grad_norm": 1.3080382347106934,
      "learning_rate": 0.00014525725174677112,
      "loss": 1.4867,
      "step": 27450
    },
    {
      "epoch": 0.291126979001805,
      "grad_norm": 1.177139401435852,
      "learning_rate": 0.00014552191403768792,
      "loss": 1.4968,
      "step": 27500
    },
    {
      "epoch": 0.291126979001805,
      "eval_loss": 1.4483877420425415,
      "eval_runtime": 46.843,
      "eval_samples_per_second": 3584.952,
      "eval_steps_per_second": 448.135,
      "step": 27500
    },
    {
      "epoch": 0.29165630078180826,
      "grad_norm": 1.1304619312286377,
      "learning_rate": 0.0001457865763286047,
      "loss": 1.4556,
      "step": 27550
    },
    {
      "epoch": 0.2921856225618116,
      "grad_norm": 1.2015273571014404,
      "learning_rate": 0.00014605123861952148,
      "loss": 1.4449,
      "step": 27600
    },
    {
      "epoch": 0.29271494434181483,
      "grad_norm": 1.1402791738510132,
      "learning_rate": 0.0001463159009104383,
      "loss": 1.4794,
      "step": 27650
    },
    {
      "epoch": 0.2932442661218181,
      "grad_norm": 1.2818437814712524,
      "learning_rate": 0.00014658056320135507,
      "loss": 1.4659,
      "step": 27700
    },
    {
      "epoch": 0.2937735879018214,
      "grad_norm": 1.147481918334961,
      "learning_rate": 0.00014684522549227185,
      "loss": 1.4643,
      "step": 27750
    },
    {
      "epoch": 0.29430290968182465,
      "grad_norm": 1.2585978507995605,
      "learning_rate": 0.00014710988778318866,
      "loss": 1.4648,
      "step": 27800
    },
    {
      "epoch": 0.29483223146182796,
      "grad_norm": 1.2274447679519653,
      "learning_rate": 0.00014737455007410544,
      "loss": 1.4551,
      "step": 27850
    },
    {
      "epoch": 0.2953615532418312,
      "grad_norm": 1.2543615102767944,
      "learning_rate": 0.00014763921236502224,
      "loss": 1.4624,
      "step": 27900
    },
    {
      "epoch": 0.29589087502183453,
      "grad_norm": 1.3728928565979004,
      "learning_rate": 0.00014790387465593902,
      "loss": 1.4621,
      "step": 27950
    },
    {
      "epoch": 0.2964201968018378,
      "grad_norm": 1.18184494972229,
      "learning_rate": 0.0001481685369468558,
      "loss": 1.4502,
      "step": 28000
    },
    {
      "epoch": 0.2964201968018378,
      "eval_loss": 1.4480202198028564,
      "eval_runtime": 46.7623,
      "eval_samples_per_second": 3591.14,
      "eval_steps_per_second": 448.909,
      "step": 28000
    },
    {
      "epoch": 0.2969495185818411,
      "grad_norm": 1.2829707860946655,
      "learning_rate": 0.0001484331992377726,
      "loss": 1.4803,
      "step": 28050
    },
    {
      "epoch": 0.29747884036184435,
      "grad_norm": 1.218626618385315,
      "learning_rate": 0.0001486978615286894,
      "loss": 1.449,
      "step": 28100
    },
    {
      "epoch": 0.29800816214184767,
      "grad_norm": 1.2788363695144653,
      "learning_rate": 0.00014896252381960617,
      "loss": 1.459,
      "step": 28150
    },
    {
      "epoch": 0.2985374839218509,
      "grad_norm": 1.2826873064041138,
      "learning_rate": 0.00014922718611052297,
      "loss": 1.4441,
      "step": 28200
    },
    {
      "epoch": 0.29906680570185423,
      "grad_norm": 1.2734869718551636,
      "learning_rate": 0.00014949184840143975,
      "loss": 1.4524,
      "step": 28250
    },
    {
      "epoch": 0.2995961274818575,
      "grad_norm": 1.2127200365066528,
      "learning_rate": 0.00014975651069235653,
      "loss": 1.4741,
      "step": 28300
    },
    {
      "epoch": 0.3001254492618608,
      "grad_norm": 1.1753742694854736,
      "learning_rate": 0.00015002117298327334,
      "loss": 1.4558,
      "step": 28350
    },
    {
      "epoch": 0.30065477104186406,
      "grad_norm": 1.2565295696258545,
      "learning_rate": 0.00015028583527419012,
      "loss": 1.4574,
      "step": 28400
    },
    {
      "epoch": 0.30118409282186737,
      "grad_norm": 1.1561768054962158,
      "learning_rate": 0.0001505504975651069,
      "loss": 1.4717,
      "step": 28450
    },
    {
      "epoch": 0.3017134146018706,
      "grad_norm": 1.1004751920700073,
      "learning_rate": 0.0001508151598560237,
      "loss": 1.4583,
      "step": 28500
    },
    {
      "epoch": 0.3017134146018706,
      "eval_loss": 1.4456064701080322,
      "eval_runtime": 46.7418,
      "eval_samples_per_second": 3592.712,
      "eval_steps_per_second": 449.105,
      "step": 28500
    },
    {
      "epoch": 0.3022427363818739,
      "grad_norm": 1.0749424695968628,
      "learning_rate": 0.0001510798221469405,
      "loss": 1.461,
      "step": 28550
    },
    {
      "epoch": 0.3027720581618772,
      "grad_norm": 1.311895489692688,
      "learning_rate": 0.00015134448443785732,
      "loss": 1.459,
      "step": 28600
    },
    {
      "epoch": 0.30330137994188044,
      "grad_norm": 1.134775996208191,
      "learning_rate": 0.0001516091467287741,
      "loss": 1.4667,
      "step": 28650
    },
    {
      "epoch": 0.30383070172188376,
      "grad_norm": 1.2050760984420776,
      "learning_rate": 0.00015187380901969088,
      "loss": 1.435,
      "step": 28700
    },
    {
      "epoch": 0.304360023501887,
      "grad_norm": 1.3657169342041016,
      "learning_rate": 0.0001521384713106077,
      "loss": 1.4591,
      "step": 28750
    },
    {
      "epoch": 0.3048893452818903,
      "grad_norm": 1.2175649404525757,
      "learning_rate": 0.00015240313360152447,
      "loss": 1.4602,
      "step": 28800
    },
    {
      "epoch": 0.3054186670618936,
      "grad_norm": 1.2750380039215088,
      "learning_rate": 0.00015266779589244125,
      "loss": 1.4631,
      "step": 28850
    },
    {
      "epoch": 0.3059479888418969,
      "grad_norm": 1.2567400932312012,
      "learning_rate": 0.00015293245818335805,
      "loss": 1.4385,
      "step": 28900
    },
    {
      "epoch": 0.30647731062190015,
      "grad_norm": 1.307323932647705,
      "learning_rate": 0.00015319712047427483,
      "loss": 1.4376,
      "step": 28950
    },
    {
      "epoch": 0.30700663240190346,
      "grad_norm": 1.2666231393814087,
      "learning_rate": 0.0001534617827651916,
      "loss": 1.4692,
      "step": 29000
    },
    {
      "epoch": 0.30700663240190346,
      "eval_loss": 1.4360781908035278,
      "eval_runtime": 46.8201,
      "eval_samples_per_second": 3586.711,
      "eval_steps_per_second": 448.355,
      "step": 29000
    },
    {
      "epoch": 0.3075359541819067,
      "grad_norm": 1.179957389831543,
      "learning_rate": 0.00015372644505610842,
      "loss": 1.4576,
      "step": 29050
    },
    {
      "epoch": 0.30806527596191,
      "grad_norm": 1.3103331327438354,
      "learning_rate": 0.0001539911073470252,
      "loss": 1.4414,
      "step": 29100
    },
    {
      "epoch": 0.3085945977419133,
      "grad_norm": 1.2110053300857544,
      "learning_rate": 0.000154255769637942,
      "loss": 1.468,
      "step": 29150
    },
    {
      "epoch": 0.3091239195219166,
      "grad_norm": 1.0822710990905762,
      "learning_rate": 0.0001545204319288588,
      "loss": 1.4546,
      "step": 29200
    },
    {
      "epoch": 0.30965324130191985,
      "grad_norm": 1.1906801462173462,
      "learning_rate": 0.00015478509421977557,
      "loss": 1.4539,
      "step": 29250
    },
    {
      "epoch": 0.31018256308192316,
      "grad_norm": 1.2208349704742432,
      "learning_rate": 0.00015504975651069237,
      "loss": 1.4469,
      "step": 29300
    },
    {
      "epoch": 0.3107118848619264,
      "grad_norm": 1.1481950283050537,
      "learning_rate": 0.00015531441880160915,
      "loss": 1.463,
      "step": 29350
    },
    {
      "epoch": 0.31124120664192967,
      "grad_norm": 1.1072746515274048,
      "learning_rate": 0.00015557378784670763,
      "loss": 1.4601,
      "step": 29400
    },
    {
      "epoch": 0.311770528421933,
      "grad_norm": 1.2503578662872314,
      "learning_rate": 0.0001558384501376244,
      "loss": 1.4571,
      "step": 29450
    },
    {
      "epoch": 0.31229985020193624,
      "grad_norm": 1.120880126953125,
      "learning_rate": 0.0001561031124285412,
      "loss": 1.4468,
      "step": 29500
    },
    {
      "epoch": 0.31229985020193624,
      "eval_loss": 1.4348595142364502,
      "eval_runtime": 46.7946,
      "eval_samples_per_second": 3588.659,
      "eval_steps_per_second": 448.598,
      "step": 29500
    },
    {
      "epoch": 0.31282917198193955,
      "grad_norm": 1.4068704843521118,
      "learning_rate": 0.000156367774719458,
      "loss": 1.465,
      "step": 29550
    },
    {
      "epoch": 0.3133584937619428,
      "grad_norm": 1.1423381567001343,
      "learning_rate": 0.00015663243701037477,
      "loss": 1.4464,
      "step": 29600
    },
    {
      "epoch": 0.3138878155419461,
      "grad_norm": 1.2207342386245728,
      "learning_rate": 0.00015689709930129155,
      "loss": 1.4636,
      "step": 29650
    },
    {
      "epoch": 0.31441713732194937,
      "grad_norm": 1.097951889038086,
      "learning_rate": 0.00015716176159220836,
      "loss": 1.4431,
      "step": 29700
    },
    {
      "epoch": 0.3149464591019527,
      "grad_norm": 1.2617357969284058,
      "learning_rate": 0.00015742642388312514,
      "loss": 1.4312,
      "step": 29750
    },
    {
      "epoch": 0.31547578088195594,
      "grad_norm": 1.1097092628479004,
      "learning_rate": 0.00015769108617404192,
      "loss": 1.4424,
      "step": 29800
    },
    {
      "epoch": 0.31600510266195925,
      "grad_norm": 1.1947530508041382,
      "learning_rate": 0.00015795574846495873,
      "loss": 1.444,
      "step": 29850
    },
    {
      "epoch": 0.3165344244419625,
      "grad_norm": 1.1726380586624146,
      "learning_rate": 0.0001582204107558755,
      "loss": 1.4501,
      "step": 29900
    },
    {
      "epoch": 0.3170637462219658,
      "grad_norm": 1.145131230354309,
      "learning_rate": 0.00015848507304679229,
      "loss": 1.4294,
      "step": 29950
    },
    {
      "epoch": 0.31759306800196907,
      "grad_norm": 1.115541696548462,
      "learning_rate": 0.0001587497353377091,
      "loss": 1.4496,
      "step": 30000
    },
    {
      "epoch": 0.31759306800196907,
      "eval_loss": 1.4324895143508911,
      "eval_runtime": 46.7841,
      "eval_samples_per_second": 3589.471,
      "eval_steps_per_second": 448.7,
      "step": 30000
    },
    {
      "epoch": 0.3181223897819724,
      "grad_norm": 1.1876471042633057,
      "learning_rate": 0.00015901439762862587,
      "loss": 1.4427,
      "step": 30050
    },
    {
      "epoch": 0.31865171156197564,
      "grad_norm": 1.1826337575912476,
      "learning_rate": 0.00015927905991954268,
      "loss": 1.4518,
      "step": 30100
    },
    {
      "epoch": 0.31918103334197895,
      "grad_norm": 1.1567522287368774,
      "learning_rate": 0.00015954372221045946,
      "loss": 1.4446,
      "step": 30150
    },
    {
      "epoch": 0.3197103551219822,
      "grad_norm": 1.2441720962524414,
      "learning_rate": 0.00015980838450137624,
      "loss": 1.4636,
      "step": 30200
    },
    {
      "epoch": 0.32023967690198546,
      "grad_norm": 1.1907436847686768,
      "learning_rate": 0.00016007304679229305,
      "loss": 1.4482,
      "step": 30250
    },
    {
      "epoch": 0.32076899868198877,
      "grad_norm": 1.114358901977539,
      "learning_rate": 0.00016033770908320983,
      "loss": 1.4304,
      "step": 30300
    },
    {
      "epoch": 0.321298320461992,
      "grad_norm": 1.1507843732833862,
      "learning_rate": 0.0001606023713741266,
      "loss": 1.4398,
      "step": 30350
    },
    {
      "epoch": 0.32182764224199534,
      "grad_norm": 1.2570548057556152,
      "learning_rate": 0.0001608670336650434,
      "loss": 1.4526,
      "step": 30400
    },
    {
      "epoch": 0.3223569640219986,
      "grad_norm": 1.2338041067123413,
      "learning_rate": 0.0001611316959559602,
      "loss": 1.4539,
      "step": 30450
    },
    {
      "epoch": 0.3228862858020019,
      "grad_norm": 1.186164379119873,
      "learning_rate": 0.00016139635824687697,
      "loss": 1.4358,
      "step": 30500
    },
    {
      "epoch": 0.3228862858020019,
      "eval_loss": 1.4300260543823242,
      "eval_runtime": 46.735,
      "eval_samples_per_second": 3593.241,
      "eval_steps_per_second": 449.171,
      "step": 30500
    },
    {
      "epoch": 0.32341560758200516,
      "grad_norm": 1.1243071556091309,
      "learning_rate": 0.00016166102053779378,
      "loss": 1.4276,
      "step": 30550
    },
    {
      "epoch": 0.32394492936200847,
      "grad_norm": 1.1813480854034424,
      "learning_rate": 0.00016192568282871056,
      "loss": 1.4597,
      "step": 30600
    },
    {
      "epoch": 0.3244742511420117,
      "grad_norm": 1.187445044517517,
      "learning_rate": 0.00016219034511962737,
      "loss": 1.4358,
      "step": 30650
    },
    {
      "epoch": 0.32500357292201504,
      "grad_norm": 1.3105332851409912,
      "learning_rate": 0.00016245500741054415,
      "loss": 1.4423,
      "step": 30700
    },
    {
      "epoch": 0.3255328947020183,
      "grad_norm": 1.13364577293396,
      "learning_rate": 0.00016271966970146092,
      "loss": 1.4323,
      "step": 30750
    },
    {
      "epoch": 0.3260622164820216,
      "grad_norm": 1.1610044240951538,
      "learning_rate": 0.00016298433199237773,
      "loss": 1.4396,
      "step": 30800
    },
    {
      "epoch": 0.32659153826202486,
      "grad_norm": 1.1113208532333374,
      "learning_rate": 0.0001632489942832945,
      "loss": 1.4531,
      "step": 30850
    },
    {
      "epoch": 0.32712086004202817,
      "grad_norm": 1.1405260562896729,
      "learning_rate": 0.0001635136565742113,
      "loss": 1.4427,
      "step": 30900
    },
    {
      "epoch": 0.3276501818220314,
      "grad_norm": 1.0982495546340942,
      "learning_rate": 0.0001637783188651281,
      "loss": 1.43,
      "step": 30950
    },
    {
      "epoch": 0.32817950360203474,
      "grad_norm": 0.964747965335846,
      "learning_rate": 0.00016404298115604488,
      "loss": 1.4431,
      "step": 31000
    },
    {
      "epoch": 0.32817950360203474,
      "eval_loss": 1.423618197441101,
      "eval_runtime": 46.7747,
      "eval_samples_per_second": 3590.19,
      "eval_steps_per_second": 448.79,
      "step": 31000
    },
    {
      "epoch": 0.328708825382038,
      "grad_norm": 1.2623258829116821,
      "learning_rate": 0.00016430764344696166,
      "loss": 1.43,
      "step": 31050
    },
    {
      "epoch": 0.32923814716204125,
      "grad_norm": 1.1127017736434937,
      "learning_rate": 0.00016457230573787846,
      "loss": 1.4358,
      "step": 31100
    },
    {
      "epoch": 0.32976746894204456,
      "grad_norm": 1.1973379850387573,
      "learning_rate": 0.00016483696802879524,
      "loss": 1.4365,
      "step": 31150
    },
    {
      "epoch": 0.3302967907220478,
      "grad_norm": 1.100714087486267,
      "learning_rate": 0.00016510163031971202,
      "loss": 1.4631,
      "step": 31200
    },
    {
      "epoch": 0.33082611250205113,
      "grad_norm": 1.1056987047195435,
      "learning_rate": 0.00016536629261062886,
      "loss": 1.4403,
      "step": 31250
    },
    {
      "epoch": 0.3313554342820544,
      "grad_norm": 1.0739434957504272,
      "learning_rate": 0.00016563095490154564,
      "loss": 1.4325,
      "step": 31300
    },
    {
      "epoch": 0.3318847560620577,
      "grad_norm": 1.2098597288131714,
      "learning_rate": 0.00016589561719246244,
      "loss": 1.4602,
      "step": 31350
    },
    {
      "epoch": 0.33241407784206095,
      "grad_norm": 1.0913304090499878,
      "learning_rate": 0.00016616027948337922,
      "loss": 1.4294,
      "step": 31400
    },
    {
      "epoch": 0.33294339962206426,
      "grad_norm": 1.2305513620376587,
      "learning_rate": 0.000166424941774296,
      "loss": 1.4386,
      "step": 31450
    },
    {
      "epoch": 0.3334727214020675,
      "grad_norm": 0.9843225479125977,
      "learning_rate": 0.0001666896040652128,
      "loss": 1.4117,
      "step": 31500
    },
    {
      "epoch": 0.3334727214020675,
      "eval_loss": 1.4236496686935425,
      "eval_runtime": 46.789,
      "eval_samples_per_second": 3589.092,
      "eval_steps_per_second": 448.653,
      "step": 31500
    },
    {
      "epoch": 0.33400204318207083,
      "grad_norm": 1.1508885622024536,
      "learning_rate": 0.0001669542663561296,
      "loss": 1.4372,
      "step": 31550
    },
    {
      "epoch": 0.3345313649620741,
      "grad_norm": 1.0731745958328247,
      "learning_rate": 0.00016721892864704637,
      "loss": 1.4163,
      "step": 31600
    },
    {
      "epoch": 0.3350606867420774,
      "grad_norm": 1.1507726907730103,
      "learning_rate": 0.00016748359093796318,
      "loss": 1.4451,
      "step": 31650
    },
    {
      "epoch": 0.33559000852208065,
      "grad_norm": 1.1476057767868042,
      "learning_rate": 0.0001677429599830616,
      "loss": 1.4461,
      "step": 31700
    },
    {
      "epoch": 0.33611933030208396,
      "grad_norm": 1.2292193174362183,
      "learning_rate": 0.0001680076222739784,
      "loss": 1.4212,
      "step": 31750
    },
    {
      "epoch": 0.3366486520820872,
      "grad_norm": 1.0279327630996704,
      "learning_rate": 0.00016827228456489518,
      "loss": 1.4135,
      "step": 31800
    },
    {
      "epoch": 0.33717797386209053,
      "grad_norm": 1.0251703262329102,
      "learning_rate": 0.000168536946855812,
      "loss": 1.4281,
      "step": 31850
    },
    {
      "epoch": 0.3377072956420938,
      "grad_norm": 1.2124416828155518,
      "learning_rate": 0.0001688016091467288,
      "loss": 1.4146,
      "step": 31900
    },
    {
      "epoch": 0.33823661742209704,
      "grad_norm": 1.1702114343643188,
      "learning_rate": 0.00016906627143764558,
      "loss": 1.4523,
      "step": 31950
    },
    {
      "epoch": 0.33876593920210035,
      "grad_norm": 1.0913602113723755,
      "learning_rate": 0.00016933093372856236,
      "loss": 1.4386,
      "step": 32000
    },
    {
      "epoch": 0.33876593920210035,
      "eval_loss": 1.4164053201675415,
      "eval_runtime": 46.8042,
      "eval_samples_per_second": 3587.924,
      "eval_steps_per_second": 448.507,
      "step": 32000
    },
    {
      "epoch": 0.3392952609821036,
      "grad_norm": 1.2898452281951904,
      "learning_rate": 0.00016959559601947916,
      "loss": 1.4022,
      "step": 32050
    },
    {
      "epoch": 0.3398245827621069,
      "grad_norm": 1.1861296892166138,
      "learning_rate": 0.00016986025831039594,
      "loss": 1.4185,
      "step": 32100
    },
    {
      "epoch": 0.3403539045421102,
      "grad_norm": 1.1096421480178833,
      "learning_rate": 0.00017012492060131275,
      "loss": 1.4437,
      "step": 32150
    },
    {
      "epoch": 0.3408832263221135,
      "grad_norm": 1.1165611743927002,
      "learning_rate": 0.00017038958289222953,
      "loss": 1.4472,
      "step": 32200
    },
    {
      "epoch": 0.34141254810211674,
      "grad_norm": 1.0565133094787598,
      "learning_rate": 0.0001706542451831463,
      "loss": 1.4361,
      "step": 32250
    },
    {
      "epoch": 0.34194186988212005,
      "grad_norm": 1.3305364847183228,
      "learning_rate": 0.00017091890747406312,
      "loss": 1.4144,
      "step": 32300
    },
    {
      "epoch": 0.3424711916621233,
      "grad_norm": 1.0100566148757935,
      "learning_rate": 0.0001711835697649799,
      "loss": 1.4526,
      "step": 32350
    },
    {
      "epoch": 0.3430005134421266,
      "grad_norm": 1.1049175262451172,
      "learning_rate": 0.00017144823205589668,
      "loss": 1.4388,
      "step": 32400
    },
    {
      "epoch": 0.3435298352221299,
      "grad_norm": 1.1275314092636108,
      "learning_rate": 0.00017171289434681348,
      "loss": 1.4346,
      "step": 32450
    },
    {
      "epoch": 0.3440591570021332,
      "grad_norm": 1.0424638986587524,
      "learning_rate": 0.00017197755663773026,
      "loss": 1.4067,
      "step": 32500
    },
    {
      "epoch": 0.3440591570021332,
      "eval_loss": 1.4134923219680786,
      "eval_runtime": 46.7722,
      "eval_samples_per_second": 3590.382,
      "eval_steps_per_second": 448.814,
      "step": 32500
    },
    {
      "epoch": 0.34458847878213644,
      "grad_norm": 1.095751166343689,
      "learning_rate": 0.00017224221892864704,
      "loss": 1.4203,
      "step": 32550
    },
    {
      "epoch": 0.34511780056213975,
      "grad_norm": 1.2423161268234253,
      "learning_rate": 0.00017250688121956385,
      "loss": 1.4322,
      "step": 32600
    },
    {
      "epoch": 0.345647122342143,
      "grad_norm": 1.1208571195602417,
      "learning_rate": 0.00017277154351048063,
      "loss": 1.4337,
      "step": 32650
    },
    {
      "epoch": 0.3461764441221463,
      "grad_norm": 1.1522146463394165,
      "learning_rate": 0.0001730362058013974,
      "loss": 1.4249,
      "step": 32700
    },
    {
      "epoch": 0.3467057659021496,
      "grad_norm": 1.1163220405578613,
      "learning_rate": 0.00017330086809231422,
      "loss": 1.4071,
      "step": 32750
    },
    {
      "epoch": 0.34723508768215283,
      "grad_norm": 1.1447243690490723,
      "learning_rate": 0.000173565530383231,
      "loss": 1.4346,
      "step": 32800
    },
    {
      "epoch": 0.34776440946215614,
      "grad_norm": 1.0552482604980469,
      "learning_rate": 0.0001738301926741478,
      "loss": 1.4296,
      "step": 32850
    },
    {
      "epoch": 0.3482937312421594,
      "grad_norm": 1.020530343055725,
      "learning_rate": 0.00017409485496506458,
      "loss": 1.414,
      "step": 32900
    },
    {
      "epoch": 0.3488230530221627,
      "grad_norm": 1.11557936668396,
      "learning_rate": 0.00017435951725598136,
      "loss": 1.4282,
      "step": 32950
    },
    {
      "epoch": 0.34935237480216597,
      "grad_norm": 1.11138916015625,
      "learning_rate": 0.00017462417954689817,
      "loss": 1.435,
      "step": 33000
    },
    {
      "epoch": 0.34935237480216597,
      "eval_loss": 1.4107671976089478,
      "eval_runtime": 46.7099,
      "eval_samples_per_second": 3595.168,
      "eval_steps_per_second": 449.412,
      "step": 33000
    },
    {
      "epoch": 0.3498816965821693,
      "grad_norm": 1.193679928779602,
      "learning_rate": 0.00017488884183781495,
      "loss": 1.4229,
      "step": 33050
    },
    {
      "epoch": 0.35041101836217253,
      "grad_norm": 1.0968257188796997,
      "learning_rate": 0.00017515350412873173,
      "loss": 1.4123,
      "step": 33100
    },
    {
      "epoch": 0.35094034014217584,
      "grad_norm": 1.0982586145401,
      "learning_rate": 0.00017541816641964854,
      "loss": 1.4165,
      "step": 33150
    },
    {
      "epoch": 0.3514696619221791,
      "grad_norm": 1.0612497329711914,
      "learning_rate": 0.00017568282871056532,
      "loss": 1.4335,
      "step": 33200
    },
    {
      "epoch": 0.3519989837021824,
      "grad_norm": 1.0442383289337158,
      "learning_rate": 0.0001759474910014821,
      "loss": 1.4365,
      "step": 33250
    },
    {
      "epoch": 0.35252830548218567,
      "grad_norm": 1.0335408449172974,
      "learning_rate": 0.0001762121532923989,
      "loss": 1.4369,
      "step": 33300
    },
    {
      "epoch": 0.353057627262189,
      "grad_norm": 1.113939642906189,
      "learning_rate": 0.00017647681558331568,
      "loss": 1.4135,
      "step": 33350
    },
    {
      "epoch": 0.35358694904219223,
      "grad_norm": 1.0880438089370728,
      "learning_rate": 0.0001767414778742325,
      "loss": 1.4179,
      "step": 33400
    },
    {
      "epoch": 0.35411627082219554,
      "grad_norm": 1.0809556245803833,
      "learning_rate": 0.00017700614016514927,
      "loss": 1.4428,
      "step": 33450
    },
    {
      "epoch": 0.3546455926021988,
      "grad_norm": 1.0917768478393555,
      "learning_rate": 0.00017727080245606605,
      "loss": 1.4244,
      "step": 33500
    },
    {
      "epoch": 0.3546455926021988,
      "eval_loss": 1.4090378284454346,
      "eval_runtime": 46.7581,
      "eval_samples_per_second": 3591.46,
      "eval_steps_per_second": 448.949,
      "step": 33500
    },
    {
      "epoch": 0.3551749143822021,
      "grad_norm": 1.1438015699386597,
      "learning_rate": 0.00017753546474698285,
      "loss": 1.4344,
      "step": 33550
    },
    {
      "epoch": 0.35570423616220537,
      "grad_norm": 1.11936354637146,
      "learning_rate": 0.00017780012703789963,
      "loss": 1.435,
      "step": 33600
    },
    {
      "epoch": 0.3562335579422086,
      "grad_norm": 1.0721594095230103,
      "learning_rate": 0.00017806478932881641,
      "loss": 1.4009,
      "step": 33650
    },
    {
      "epoch": 0.35676287972221193,
      "grad_norm": 1.1576493978500366,
      "learning_rate": 0.00017832945161973322,
      "loss": 1.4301,
      "step": 33700
    },
    {
      "epoch": 0.3572922015022152,
      "grad_norm": 1.184545874595642,
      "learning_rate": 0.00017859411391065,
      "loss": 1.4387,
      "step": 33750
    },
    {
      "epoch": 0.3578215232822185,
      "grad_norm": 1.0977238416671753,
      "learning_rate": 0.00017885877620156678,
      "loss": 1.4003,
      "step": 33800
    },
    {
      "epoch": 0.35835084506222176,
      "grad_norm": 1.0745168924331665,
      "learning_rate": 0.0001791234384924836,
      "loss": 1.4283,
      "step": 33850
    },
    {
      "epoch": 0.35888016684222507,
      "grad_norm": 1.0374882221221924,
      "learning_rate": 0.0001793881007834004,
      "loss": 1.4019,
      "step": 33900
    },
    {
      "epoch": 0.3594094886222283,
      "grad_norm": 1.1537288427352905,
      "learning_rate": 0.0001796527630743172,
      "loss": 1.4258,
      "step": 33950
    },
    {
      "epoch": 0.35993881040223163,
      "grad_norm": 1.1012300252914429,
      "learning_rate": 0.00017991742536523398,
      "loss": 1.3953,
      "step": 34000
    },
    {
      "epoch": 0.35993881040223163,
      "eval_loss": 1.4025341272354126,
      "eval_runtime": 46.8138,
      "eval_samples_per_second": 3587.187,
      "eval_steps_per_second": 448.414,
      "step": 34000
    },
    {
      "epoch": 0.3604681321822349,
      "grad_norm": 1.0282856225967407,
      "learning_rate": 0.00018018208765615076,
      "loss": 1.4211,
      "step": 34050
    },
    {
      "epoch": 0.3609974539622382,
      "grad_norm": 1.051612138748169,
      "learning_rate": 0.00018044674994706757,
      "loss": 1.4002,
      "step": 34100
    },
    {
      "epoch": 0.36152677574224146,
      "grad_norm": 1.1943845748901367,
      "learning_rate": 0.00018071141223798435,
      "loss": 1.4215,
      "step": 34150
    },
    {
      "epoch": 0.36205609752224477,
      "grad_norm": 1.1261645555496216,
      "learning_rate": 0.00018097607452890113,
      "loss": 1.4314,
      "step": 34200
    },
    {
      "epoch": 0.362585419302248,
      "grad_norm": 1.1538059711456299,
      "learning_rate": 0.00018124073681981793,
      "loss": 1.4064,
      "step": 34250
    },
    {
      "epoch": 0.36311474108225134,
      "grad_norm": 1.0641056299209595,
      "learning_rate": 0.00018150539911073471,
      "loss": 1.4135,
      "step": 34300
    },
    {
      "epoch": 0.3636440628622546,
      "grad_norm": 0.990630030632019,
      "learning_rate": 0.0001817700614016515,
      "loss": 1.4098,
      "step": 34350
    },
    {
      "epoch": 0.3641733846422579,
      "grad_norm": 1.0369495153427124,
      "learning_rate": 0.0001820347236925683,
      "loss": 1.4014,
      "step": 34400
    },
    {
      "epoch": 0.36470270642226116,
      "grad_norm": 1.1109524965286255,
      "learning_rate": 0.00018229938598348508,
      "loss": 1.4254,
      "step": 34450
    },
    {
      "epoch": 0.3652320282022644,
      "grad_norm": 0.9917434453964233,
      "learning_rate": 0.00018256404827440186,
      "loss": 1.4206,
      "step": 34500
    },
    {
      "epoch": 0.3652320282022644,
      "eval_loss": 1.40231454372406,
      "eval_runtime": 46.8031,
      "eval_samples_per_second": 3588.008,
      "eval_steps_per_second": 448.517,
      "step": 34500
    },
    {
      "epoch": 0.3657613499822677,
      "grad_norm": 1.1370409727096558,
      "learning_rate": 0.00018282871056531867,
      "loss": 1.4286,
      "step": 34550
    },
    {
      "epoch": 0.366290671762271,
      "grad_norm": 1.0310128927230835,
      "learning_rate": 0.00018309337285623545,
      "loss": 1.408,
      "step": 34600
    },
    {
      "epoch": 0.3668199935422743,
      "grad_norm": 1.00511634349823,
      "learning_rate": 0.00018335803514715225,
      "loss": 1.4337,
      "step": 34650
    },
    {
      "epoch": 0.36734931532227755,
      "grad_norm": 1.0202006101608276,
      "learning_rate": 0.00018362269743806903,
      "loss": 1.4013,
      "step": 34700
    },
    {
      "epoch": 0.36787863710228086,
      "grad_norm": 1.018291711807251,
      "learning_rate": 0.0001838873597289858,
      "loss": 1.4327,
      "step": 34750
    },
    {
      "epoch": 0.3684079588822841,
      "grad_norm": 1.1703083515167236,
      "learning_rate": 0.00018415202201990262,
      "loss": 1.4277,
      "step": 34800
    },
    {
      "epoch": 0.3689372806622874,
      "grad_norm": 1.0943952798843384,
      "learning_rate": 0.0001844166843108194,
      "loss": 1.4021,
      "step": 34850
    },
    {
      "epoch": 0.3694666024422907,
      "grad_norm": 1.1893919706344604,
      "learning_rate": 0.00018468134660173618,
      "loss": 1.4001,
      "step": 34900
    },
    {
      "epoch": 0.369995924222294,
      "grad_norm": 1.0350971221923828,
      "learning_rate": 0.00018494600889265299,
      "loss": 1.4046,
      "step": 34950
    },
    {
      "epoch": 0.37052524600229725,
      "grad_norm": 1.1004043817520142,
      "learning_rate": 0.00018521067118356977,
      "loss": 1.43,
      "step": 35000
    },
    {
      "epoch": 0.37052524600229725,
      "eval_loss": 1.3954064846038818,
      "eval_runtime": 46.8401,
      "eval_samples_per_second": 3585.174,
      "eval_steps_per_second": 448.163,
      "step": 35000
    },
    {
      "epoch": 0.37105456778230056,
      "grad_norm": 1.1208851337432861,
      "learning_rate": 0.00018547533347448655,
      "loss": 1.4208,
      "step": 35050
    },
    {
      "epoch": 0.3715838895623038,
      "grad_norm": 1.0563565492630005,
      "learning_rate": 0.00018573999576540335,
      "loss": 1.4165,
      "step": 35100
    },
    {
      "epoch": 0.3721132113423071,
      "grad_norm": 1.1348366737365723,
      "learning_rate": 0.00018600465805632013,
      "loss": 1.4291,
      "step": 35150
    },
    {
      "epoch": 0.3726425331223104,
      "grad_norm": 1.1067711114883423,
      "learning_rate": 0.00018626932034723694,
      "loss": 1.4162,
      "step": 35200
    },
    {
      "epoch": 0.37317185490231364,
      "grad_norm": 1.0163829326629639,
      "learning_rate": 0.00018653398263815372,
      "loss": 1.4047,
      "step": 35250
    },
    {
      "epoch": 0.37370117668231695,
      "grad_norm": 1.0699882507324219,
      "learning_rate": 0.0001867986449290705,
      "loss": 1.4284,
      "step": 35300
    },
    {
      "epoch": 0.3742304984623202,
      "grad_norm": 1.0199592113494873,
      "learning_rate": 0.0001870633072199873,
      "loss": 1.3955,
      "step": 35350
    },
    {
      "epoch": 0.3747598202423235,
      "grad_norm": 1.0952744483947754,
      "learning_rate": 0.00018732796951090408,
      "loss": 1.4058,
      "step": 35400
    },
    {
      "epoch": 0.37528914202232677,
      "grad_norm": 1.1065146923065186,
      "learning_rate": 0.00018759263180182086,
      "loss": 1.4118,
      "step": 35450
    },
    {
      "epoch": 0.3758184638023301,
      "grad_norm": 1.0921151638031006,
      "learning_rate": 0.00018785729409273767,
      "loss": 1.3771,
      "step": 35500
    },
    {
      "epoch": 0.3758184638023301,
      "eval_loss": 1.3919494152069092,
      "eval_runtime": 46.8364,
      "eval_samples_per_second": 3585.459,
      "eval_steps_per_second": 448.198,
      "step": 35500
    },
    {
      "epoch": 0.37634778558233334,
      "grad_norm": 1.1004502773284912,
      "learning_rate": 0.00018811666313783612,
      "loss": 1.4258,
      "step": 35550
    },
    {
      "epoch": 0.37687710736233665,
      "grad_norm": 1.0326552391052246,
      "learning_rate": 0.00018838132542875293,
      "loss": 1.4106,
      "step": 35600
    },
    {
      "epoch": 0.3774064291423399,
      "grad_norm": 1.0925854444503784,
      "learning_rate": 0.0001886459877196697,
      "loss": 1.3854,
      "step": 35650
    },
    {
      "epoch": 0.3779357509223432,
      "grad_norm": 0.9516707062721252,
      "learning_rate": 0.00018891065001058649,
      "loss": 1.3844,
      "step": 35700
    },
    {
      "epoch": 0.37846507270234647,
      "grad_norm": 1.0592609643936157,
      "learning_rate": 0.0001891753123015033,
      "loss": 1.4175,
      "step": 35750
    },
    {
      "epoch": 0.3789943944823498,
      "grad_norm": 1.0934630632400513,
      "learning_rate": 0.00018943997459242007,
      "loss": 1.395,
      "step": 35800
    },
    {
      "epoch": 0.37952371626235304,
      "grad_norm": 1.158176302909851,
      "learning_rate": 0.00018970463688333685,
      "loss": 1.4098,
      "step": 35850
    },
    {
      "epoch": 0.38005303804235635,
      "grad_norm": 1.071915864944458,
      "learning_rate": 0.00018996929917425366,
      "loss": 1.4031,
      "step": 35900
    },
    {
      "epoch": 0.3805823598223596,
      "grad_norm": 1.17958402633667,
      "learning_rate": 0.00019023396146517044,
      "loss": 1.4022,
      "step": 35950
    },
    {
      "epoch": 0.3811116816023629,
      "grad_norm": 1.0391579866409302,
      "learning_rate": 0.00019049862375608722,
      "loss": 1.439,
      "step": 36000
    },
    {
      "epoch": 0.3811116816023629,
      "eval_loss": 1.3894296884536743,
      "eval_runtime": 46.738,
      "eval_samples_per_second": 3593.009,
      "eval_steps_per_second": 449.142,
      "step": 36000
    },
    {
      "epoch": 0.3816410033823662,
      "grad_norm": 1.0381174087524414,
      "learning_rate": 0.00019076328604700403,
      "loss": 1.3939,
      "step": 36050
    },
    {
      "epoch": 0.38217032516236943,
      "grad_norm": 0.9680981040000916,
      "learning_rate": 0.0001910279483379208,
      "loss": 1.4132,
      "step": 36100
    },
    {
      "epoch": 0.38269964694237274,
      "grad_norm": 1.0851662158966064,
      "learning_rate": 0.0001912926106288376,
      "loss": 1.4213,
      "step": 36150
    },
    {
      "epoch": 0.383228968722376,
      "grad_norm": 1.1424914598464966,
      "learning_rate": 0.0001915572729197544,
      "loss": 1.3833,
      "step": 36200
    },
    {
      "epoch": 0.3837582905023793,
      "grad_norm": 0.950283944606781,
      "learning_rate": 0.00019182193521067117,
      "loss": 1.4069,
      "step": 36250
    },
    {
      "epoch": 0.38428761228238256,
      "grad_norm": 1.0143556594848633,
      "learning_rate": 0.00019208659750158798,
      "loss": 1.4282,
      "step": 36300
    },
    {
      "epoch": 0.3848169340623859,
      "grad_norm": 1.0860878229141235,
      "learning_rate": 0.00019235125979250476,
      "loss": 1.4081,
      "step": 36350
    },
    {
      "epoch": 0.38534625584238913,
      "grad_norm": 1.1004393100738525,
      "learning_rate": 0.00019261592208342154,
      "loss": 1.4074,
      "step": 36400
    },
    {
      "epoch": 0.38587557762239244,
      "grad_norm": 1.0305756330490112,
      "learning_rate": 0.00019288058437433834,
      "loss": 1.4035,
      "step": 36450
    },
    {
      "epoch": 0.3864048994023957,
      "grad_norm": 1.0021851062774658,
      "learning_rate": 0.00019314524666525512,
      "loss": 1.4091,
      "step": 36500
    },
    {
      "epoch": 0.3864048994023957,
      "eval_loss": 1.3857494592666626,
      "eval_runtime": 46.7604,
      "eval_samples_per_second": 3591.288,
      "eval_steps_per_second": 448.927,
      "step": 36500
    },
    {
      "epoch": 0.386934221182399,
      "grad_norm": 1.1222341060638428,
      "learning_rate": 0.0001934099089561719,
      "loss": 1.39,
      "step": 36550
    },
    {
      "epoch": 0.38746354296240226,
      "grad_norm": 1.1438308954238892,
      "learning_rate": 0.00019367457124708874,
      "loss": 1.4059,
      "step": 36600
    },
    {
      "epoch": 0.3879928647424056,
      "grad_norm": 1.036138653755188,
      "learning_rate": 0.00019393923353800552,
      "loss": 1.3935,
      "step": 36650
    },
    {
      "epoch": 0.38852218652240883,
      "grad_norm": 1.2286996841430664,
      "learning_rate": 0.00019420389582892232,
      "loss": 1.3866,
      "step": 36700
    },
    {
      "epoch": 0.38905150830241214,
      "grad_norm": 1.045691728591919,
      "learning_rate": 0.0001944685581198391,
      "loss": 1.3991,
      "step": 36750
    },
    {
      "epoch": 0.3895808300824154,
      "grad_norm": 0.99689120054245,
      "learning_rate": 0.00019473322041075588,
      "loss": 1.3871,
      "step": 36800
    },
    {
      "epoch": 0.3901101518624187,
      "grad_norm": 1.0908806324005127,
      "learning_rate": 0.0001949978827016727,
      "loss": 1.3973,
      "step": 36850
    },
    {
      "epoch": 0.39063947364242196,
      "grad_norm": 1.1681668758392334,
      "learning_rate": 0.00019526254499258947,
      "loss": 1.415,
      "step": 36900
    },
    {
      "epoch": 0.3911687954224252,
      "grad_norm": 1.047533631324768,
      "learning_rate": 0.00019552720728350625,
      "loss": 1.3971,
      "step": 36950
    },
    {
      "epoch": 0.39169811720242853,
      "grad_norm": 1.157406210899353,
      "learning_rate": 0.00019579186957442306,
      "loss": 1.3826,
      "step": 37000
    },
    {
      "epoch": 0.39169811720242853,
      "eval_loss": 1.3835029602050781,
      "eval_runtime": 46.8497,
      "eval_samples_per_second": 3584.441,
      "eval_steps_per_second": 448.071,
      "step": 37000
    },
    {
      "epoch": 0.3922274389824318,
      "grad_norm": 1.055732011795044,
      "learning_rate": 0.00019605653186533984,
      "loss": 1.3921,
      "step": 37050
    },
    {
      "epoch": 0.3927567607624351,
      "grad_norm": 1.1938438415527344,
      "learning_rate": 0.00019632119415625662,
      "loss": 1.3858,
      "step": 37100
    },
    {
      "epoch": 0.39328608254243835,
      "grad_norm": 0.965620219707489,
      "learning_rate": 0.00019658585644717342,
      "loss": 1.3976,
      "step": 37150
    },
    {
      "epoch": 0.39381540432244166,
      "grad_norm": 1.0864477157592773,
      "learning_rate": 0.0001968505187380902,
      "loss": 1.4025,
      "step": 37200
    },
    {
      "epoch": 0.3943447261024449,
      "grad_norm": 1.050731897354126,
      "learning_rate": 0.00019711518102900698,
      "loss": 1.3864,
      "step": 37250
    },
    {
      "epoch": 0.39487404788244823,
      "grad_norm": 1.06094229221344,
      "learning_rate": 0.0001973798433199238,
      "loss": 1.3966,
      "step": 37300
    },
    {
      "epoch": 0.3954033696624515,
      "grad_norm": 1.1042197942733765,
      "learning_rate": 0.00019764450561084057,
      "loss": 1.4049,
      "step": 37350
    },
    {
      "epoch": 0.3959326914424548,
      "grad_norm": 1.1537415981292725,
      "learning_rate": 0.00019790916790175738,
      "loss": 1.3897,
      "step": 37400
    },
    {
      "epoch": 0.39646201322245805,
      "grad_norm": 1.1330312490463257,
      "learning_rate": 0.00019817383019267416,
      "loss": 1.4,
      "step": 37450
    },
    {
      "epoch": 0.39699133500246137,
      "grad_norm": 0.9709594249725342,
      "learning_rate": 0.00019843849248359094,
      "loss": 1.3838,
      "step": 37500
    },
    {
      "epoch": 0.39699133500246137,
      "eval_loss": 1.3806660175323486,
      "eval_runtime": 46.8121,
      "eval_samples_per_second": 3587.319,
      "eval_steps_per_second": 448.431,
      "step": 37500
    },
    {
      "epoch": 0.3975206567824646,
      "grad_norm": 1.10761559009552,
      "learning_rate": 0.00019870315477450774,
      "loss": 1.4031,
      "step": 37550
    },
    {
      "epoch": 0.39804997856246793,
      "grad_norm": 1.0595060586929321,
      "learning_rate": 0.00019896781706542452,
      "loss": 1.3655,
      "step": 37600
    },
    {
      "epoch": 0.3985793003424712,
      "grad_norm": 1.1888302564620972,
      "learning_rate": 0.0001992324793563413,
      "loss": 1.4059,
      "step": 37650
    },
    {
      "epoch": 0.3991086221224745,
      "grad_norm": 1.0130033493041992,
      "learning_rate": 0.0001994971416472581,
      "loss": 1.3739,
      "step": 37700
    },
    {
      "epoch": 0.39963794390247775,
      "grad_norm": 1.0187686681747437,
      "learning_rate": 0.0001997618039381749,
      "loss": 1.4061,
      "step": 37750
    },
    {
      "epoch": 0.400167265682481,
      "grad_norm": 1.0236544609069824,
      "learning_rate": 0.00020002646622909167,
      "loss": 1.4036,
      "step": 37800
    },
    {
      "epoch": 0.4006965874624843,
      "grad_norm": 1.0137598514556885,
      "learning_rate": 0.00020029112852000848,
      "loss": 1.3718,
      "step": 37850
    },
    {
      "epoch": 0.4012259092424876,
      "grad_norm": 1.0915473699569702,
      "learning_rate": 0.00020055579081092526,
      "loss": 1.3996,
      "step": 37900
    },
    {
      "epoch": 0.4017552310224909,
      "grad_norm": 1.1359670162200928,
      "learning_rate": 0.00020082045310184206,
      "loss": 1.3868,
      "step": 37950
    },
    {
      "epoch": 0.40228455280249414,
      "grad_norm": 1.0310020446777344,
      "learning_rate": 0.00020108511539275884,
      "loss": 1.3884,
      "step": 38000
    },
    {
      "epoch": 0.40228455280249414,
      "eval_loss": 1.3743568658828735,
      "eval_runtime": 46.7151,
      "eval_samples_per_second": 3594.772,
      "eval_steps_per_second": 449.363,
      "step": 38000
    },
    {
      "epoch": 0.40281387458249746,
      "grad_norm": 1.0315074920654297,
      "learning_rate": 0.00020134977768367562,
      "loss": 1.3818,
      "step": 38050
    },
    {
      "epoch": 0.4033431963625007,
      "grad_norm": 1.1051286458969116,
      "learning_rate": 0.00020161443997459243,
      "loss": 1.4186,
      "step": 38100
    },
    {
      "epoch": 0.403872518142504,
      "grad_norm": 1.0059911012649536,
      "learning_rate": 0.0002018791022655092,
      "loss": 1.3801,
      "step": 38150
    },
    {
      "epoch": 0.4044018399225073,
      "grad_norm": 1.097684621810913,
      "learning_rate": 0.000202143764556426,
      "loss": 1.3782,
      "step": 38200
    },
    {
      "epoch": 0.4049311617025106,
      "grad_norm": 1.1053040027618408,
      "learning_rate": 0.0002024084268473428,
      "loss": 1.3785,
      "step": 38250
    },
    {
      "epoch": 0.40546048348251384,
      "grad_norm": 1.0031651258468628,
      "learning_rate": 0.00020267308913825957,
      "loss": 1.382,
      "step": 38300
    },
    {
      "epoch": 0.40598980526251716,
      "grad_norm": 0.9932684302330017,
      "learning_rate": 0.00020293775142917635,
      "loss": 1.3949,
      "step": 38350
    },
    {
      "epoch": 0.4065191270425204,
      "grad_norm": 1.0679683685302734,
      "learning_rate": 0.00020320241372009316,
      "loss": 1.3883,
      "step": 38400
    },
    {
      "epoch": 0.4070484488225237,
      "grad_norm": 0.9981836676597595,
      "learning_rate": 0.00020346707601100994,
      "loss": 1.3774,
      "step": 38450
    },
    {
      "epoch": 0.407577770602527,
      "grad_norm": 0.9665042161941528,
      "learning_rate": 0.00020373173830192672,
      "loss": 1.3724,
      "step": 38500
    },
    {
      "epoch": 0.407577770602527,
      "eval_loss": 1.3726675510406494,
      "eval_runtime": 46.7508,
      "eval_samples_per_second": 3592.024,
      "eval_steps_per_second": 449.019,
      "step": 38500
    },
    {
      "epoch": 0.4081070923825303,
      "grad_norm": 1.0659018754959106,
      "learning_rate": 0.00020399640059284353,
      "loss": 1.3848,
      "step": 38550
    },
    {
      "epoch": 0.40863641416253355,
      "grad_norm": 0.9819056391716003,
      "learning_rate": 0.0002042610628837603,
      "loss": 1.3792,
      "step": 38600
    },
    {
      "epoch": 0.4091657359425368,
      "grad_norm": 1.0636210441589355,
      "learning_rate": 0.00020452572517467714,
      "loss": 1.3982,
      "step": 38650
    },
    {
      "epoch": 0.4096950577225401,
      "grad_norm": 0.9641637802124023,
      "learning_rate": 0.00020479038746559392,
      "loss": 1.4055,
      "step": 38700
    },
    {
      "epoch": 0.41022437950254337,
      "grad_norm": 1.010474681854248,
      "learning_rate": 0.0002050550497565107,
      "loss": 1.3701,
      "step": 38750
    },
    {
      "epoch": 0.4107537012825467,
      "grad_norm": 0.9765045642852783,
      "learning_rate": 0.0002053197120474275,
      "loss": 1.3867,
      "step": 38800
    },
    {
      "epoch": 0.41128302306254994,
      "grad_norm": 1.0113459825515747,
      "learning_rate": 0.0002055843743383443,
      "loss": 1.4114,
      "step": 38850
    },
    {
      "epoch": 0.41181234484255325,
      "grad_norm": 1.0868384838104248,
      "learning_rate": 0.00020584903662926107,
      "loss": 1.3894,
      "step": 38900
    },
    {
      "epoch": 0.4123416666225565,
      "grad_norm": 1.1269018650054932,
      "learning_rate": 0.00020611369892017787,
      "loss": 1.4058,
      "step": 38950
    },
    {
      "epoch": 0.4128709884025598,
      "grad_norm": 0.9609367251396179,
      "learning_rate": 0.00020637836121109465,
      "loss": 1.3873,
      "step": 39000
    },
    {
      "epoch": 0.4128709884025598,
      "eval_loss": 1.3677600622177124,
      "eval_runtime": 46.7026,
      "eval_samples_per_second": 3595.729,
      "eval_steps_per_second": 449.482,
      "step": 39000
    },
    {
      "epoch": 0.41340031018256307,
      "grad_norm": 0.9992966651916504,
      "learning_rate": 0.00020664302350201143,
      "loss": 1.3652,
      "step": 39050
    },
    {
      "epoch": 0.4139296319625664,
      "grad_norm": 1.0526230335235596,
      "learning_rate": 0.00020690239254710988,
      "loss": 1.3921,
      "step": 39100
    },
    {
      "epoch": 0.41445895374256964,
      "grad_norm": 1.0079683065414429,
      "learning_rate": 0.00020716705483802666,
      "loss": 1.3974,
      "step": 39150
    },
    {
      "epoch": 0.41498827552257295,
      "grad_norm": 1.0786352157592773,
      "learning_rate": 0.00020743171712894347,
      "loss": 1.3802,
      "step": 39200
    },
    {
      "epoch": 0.4155175973025762,
      "grad_norm": 1.0740212202072144,
      "learning_rate": 0.00020769637941986027,
      "loss": 1.3688,
      "step": 39250
    },
    {
      "epoch": 0.4160469190825795,
      "grad_norm": 1.1009700298309326,
      "learning_rate": 0.00020796104171077705,
      "loss": 1.3902,
      "step": 39300
    },
    {
      "epoch": 0.41657624086258277,
      "grad_norm": 1.0532915592193604,
      "learning_rate": 0.00020822570400169386,
      "loss": 1.4006,
      "step": 39350
    },
    {
      "epoch": 0.4171055626425861,
      "grad_norm": 1.0794141292572021,
      "learning_rate": 0.00020849036629261064,
      "loss": 1.3786,
      "step": 39400
    },
    {
      "epoch": 0.41763488442258934,
      "grad_norm": 0.9357675313949585,
      "learning_rate": 0.00020875502858352745,
      "loss": 1.3695,
      "step": 39450
    },
    {
      "epoch": 0.4181642062025926,
      "grad_norm": 1.0331659317016602,
      "learning_rate": 0.00020901969087444423,
      "loss": 1.3676,
      "step": 39500
    },
    {
      "epoch": 0.4181642062025926,
      "eval_loss": 1.3648600578308105,
      "eval_runtime": 46.7877,
      "eval_samples_per_second": 3589.191,
      "eval_steps_per_second": 448.665,
      "step": 39500
    },
    {
      "epoch": 0.4186935279825959,
      "grad_norm": 1.0317933559417725,
      "learning_rate": 0.000209284353165361,
      "loss": 1.3987,
      "step": 39550
    },
    {
      "epoch": 0.41922284976259916,
      "grad_norm": 1.0067658424377441,
      "learning_rate": 0.00020954901545627781,
      "loss": 1.3661,
      "step": 39600
    },
    {
      "epoch": 0.41975217154260247,
      "grad_norm": 1.03380286693573,
      "learning_rate": 0.0002098136777471946,
      "loss": 1.372,
      "step": 39650
    },
    {
      "epoch": 0.4202814933226057,
      "grad_norm": 1.0849950313568115,
      "learning_rate": 0.00021007834003811137,
      "loss": 1.3882,
      "step": 39700
    },
    {
      "epoch": 0.42081081510260904,
      "grad_norm": 1.0580320358276367,
      "learning_rate": 0.00021034300232902818,
      "loss": 1.4011,
      "step": 39750
    },
    {
      "epoch": 0.4213401368826123,
      "grad_norm": 1.0237705707550049,
      "learning_rate": 0.00021060766461994496,
      "loss": 1.386,
      "step": 39800
    },
    {
      "epoch": 0.4218694586626156,
      "grad_norm": 1.0031945705413818,
      "learning_rate": 0.00021087232691086174,
      "loss": 1.3788,
      "step": 39850
    },
    {
      "epoch": 0.42239878044261886,
      "grad_norm": 1.0033785104751587,
      "learning_rate": 0.00021113698920177855,
      "loss": 1.3747,
      "step": 39900
    },
    {
      "epoch": 0.42292810222262217,
      "grad_norm": 1.043522834777832,
      "learning_rate": 0.00021140165149269533,
      "loss": 1.3963,
      "step": 39950
    },
    {
      "epoch": 0.4234574240026254,
      "grad_norm": 1.0555589199066162,
      "learning_rate": 0.0002116663137836121,
      "loss": 1.3657,
      "step": 40000
    },
    {
      "epoch": 0.4234574240026254,
      "eval_loss": 1.3607828617095947,
      "eval_runtime": 46.8072,
      "eval_samples_per_second": 3587.699,
      "eval_steps_per_second": 448.478,
      "step": 40000
    },
    {
      "epoch": 0.42398674578262874,
      "grad_norm": 0.9323732852935791,
      "learning_rate": 0.0002119309760745289,
      "loss": 1.3588,
      "step": 40050
    },
    {
      "epoch": 0.424516067562632,
      "grad_norm": 1.1800665855407715,
      "learning_rate": 0.0002121956383654457,
      "loss": 1.4044,
      "step": 40100
    },
    {
      "epoch": 0.4250453893426353,
      "grad_norm": 1.0326579809188843,
      "learning_rate": 0.0002124603006563625,
      "loss": 1.4035,
      "step": 40150
    },
    {
      "epoch": 0.42557471112263856,
      "grad_norm": 1.1121608018875122,
      "learning_rate": 0.00021272496294727928,
      "loss": 1.391,
      "step": 40200
    },
    {
      "epoch": 0.42610403290264187,
      "grad_norm": 1.0359529256820679,
      "learning_rate": 0.00021298962523819606,
      "loss": 1.3797,
      "step": 40250
    },
    {
      "epoch": 0.4266333546826451,
      "grad_norm": 1.1448545455932617,
      "learning_rate": 0.00021325428752911287,
      "loss": 1.3616,
      "step": 40300
    },
    {
      "epoch": 0.4271626764626484,
      "grad_norm": 1.0193791389465332,
      "learning_rate": 0.00021351894982002965,
      "loss": 1.3515,
      "step": 40350
    },
    {
      "epoch": 0.4276919982426517,
      "grad_norm": 1.0072649717330933,
      "learning_rate": 0.00021378361211094643,
      "loss": 1.3625,
      "step": 40400
    },
    {
      "epoch": 0.42822132002265495,
      "grad_norm": 1.0243499279022217,
      "learning_rate": 0.00021404827440186323,
      "loss": 1.3612,
      "step": 40450
    },
    {
      "epoch": 0.42875064180265826,
      "grad_norm": 0.940746545791626,
      "learning_rate": 0.00021431293669278,
      "loss": 1.3609,
      "step": 40500
    },
    {
      "epoch": 0.42875064180265826,
      "eval_loss": 1.3562679290771484,
      "eval_runtime": 46.7713,
      "eval_samples_per_second": 3590.452,
      "eval_steps_per_second": 448.823,
      "step": 40500
    },
    {
      "epoch": 0.4292799635826615,
      "grad_norm": 0.9436851739883423,
      "learning_rate": 0.0002145775989836968,
      "loss": 1.3554,
      "step": 40550
    },
    {
      "epoch": 0.42980928536266483,
      "grad_norm": 0.9184657335281372,
      "learning_rate": 0.0002148422612746136,
      "loss": 1.3848,
      "step": 40600
    },
    {
      "epoch": 0.4303386071426681,
      "grad_norm": 1.1494181156158447,
      "learning_rate": 0.00021510692356553038,
      "loss": 1.3798,
      "step": 40650
    },
    {
      "epoch": 0.4308679289226714,
      "grad_norm": 1.061000943183899,
      "learning_rate": 0.00021537158585644719,
      "loss": 1.3669,
      "step": 40700
    },
    {
      "epoch": 0.43139725070267465,
      "grad_norm": 1.06192147731781,
      "learning_rate": 0.00021563624814736396,
      "loss": 1.3661,
      "step": 40750
    },
    {
      "epoch": 0.43192657248267796,
      "grad_norm": 1.056588053703308,
      "learning_rate": 0.00021590091043828074,
      "loss": 1.3749,
      "step": 40800
    },
    {
      "epoch": 0.4324558942626812,
      "grad_norm": 1.054360270500183,
      "learning_rate": 0.00021616557272919755,
      "loss": 1.3939,
      "step": 40850
    },
    {
      "epoch": 0.43298521604268453,
      "grad_norm": 1.0517621040344238,
      "learning_rate": 0.00021643023502011433,
      "loss": 1.3609,
      "step": 40900
    },
    {
      "epoch": 0.4335145378226878,
      "grad_norm": 0.9704340100288391,
      "learning_rate": 0.0002166948973110311,
      "loss": 1.3634,
      "step": 40950
    },
    {
      "epoch": 0.4340438596026911,
      "grad_norm": 1.0459620952606201,
      "learning_rate": 0.00021695955960194792,
      "loss": 1.3792,
      "step": 41000
    },
    {
      "epoch": 0.4340438596026911,
      "eval_loss": 1.352169394493103,
      "eval_runtime": 46.8091,
      "eval_samples_per_second": 3587.547,
      "eval_steps_per_second": 448.459,
      "step": 41000
    },
    {
      "epoch": 0.43457318138269435,
      "grad_norm": 1.0832722187042236,
      "learning_rate": 0.0002172242218928647,
      "loss": 1.3467,
      "step": 41050
    },
    {
      "epoch": 0.43510250316269766,
      "grad_norm": 1.157022476196289,
      "learning_rate": 0.00021748888418378148,
      "loss": 1.367,
      "step": 41100
    },
    {
      "epoch": 0.4356318249427009,
      "grad_norm": 0.9578778147697449,
      "learning_rate": 0.00021775354647469828,
      "loss": 1.3768,
      "step": 41150
    },
    {
      "epoch": 0.4361611467227042,
      "grad_norm": 1.1468300819396973,
      "learning_rate": 0.00021801820876561506,
      "loss": 1.3749,
      "step": 41200
    },
    {
      "epoch": 0.4366904685027075,
      "grad_norm": 1.1162283420562744,
      "learning_rate": 0.00021828287105653184,
      "loss": 1.3618,
      "step": 41250
    },
    {
      "epoch": 0.43721979028271074,
      "grad_norm": 1.047200083732605,
      "learning_rate": 0.00021854753334744868,
      "loss": 1.3852,
      "step": 41300
    },
    {
      "epoch": 0.43774911206271405,
      "grad_norm": 0.995498538017273,
      "learning_rate": 0.0002188069023925471,
      "loss": 1.3759,
      "step": 41350
    },
    {
      "epoch": 0.4382784338427173,
      "grad_norm": 1.1312788724899292,
      "learning_rate": 0.0002190715646834639,
      "loss": 1.3799,
      "step": 41400
    },
    {
      "epoch": 0.4388077556227206,
      "grad_norm": 0.9735302329063416,
      "learning_rate": 0.00021933622697438069,
      "loss": 1.3619,
      "step": 41450
    },
    {
      "epoch": 0.4393370774027239,
      "grad_norm": 1.0445319414138794,
      "learning_rate": 0.00021960088926529746,
      "loss": 1.3691,
      "step": 41500
    },
    {
      "epoch": 0.4393370774027239,
      "eval_loss": 1.3494850397109985,
      "eval_runtime": 46.72,
      "eval_samples_per_second": 3594.39,
      "eval_steps_per_second": 449.315,
      "step": 41500
    },
    {
      "epoch": 0.4398663991827272,
      "grad_norm": 0.9623885750770569,
      "learning_rate": 0.00021986555155621427,
      "loss": 1.3557,
      "step": 41550
    },
    {
      "epoch": 0.44039572096273044,
      "grad_norm": 0.9663008451461792,
      "learning_rate": 0.00022013021384713105,
      "loss": 1.3917,
      "step": 41600
    },
    {
      "epoch": 0.44092504274273375,
      "grad_norm": 0.9603924751281738,
      "learning_rate": 0.00022039487613804786,
      "loss": 1.3686,
      "step": 41650
    },
    {
      "epoch": 0.441454364522737,
      "grad_norm": 0.9894352555274963,
      "learning_rate": 0.00022065953842896464,
      "loss": 1.3666,
      "step": 41700
    },
    {
      "epoch": 0.4419836863027403,
      "grad_norm": 1.0447940826416016,
      "learning_rate": 0.00022092420071988142,
      "loss": 1.3696,
      "step": 41750
    },
    {
      "epoch": 0.4425130080827436,
      "grad_norm": 1.0905784368515015,
      "learning_rate": 0.00022118886301079822,
      "loss": 1.3729,
      "step": 41800
    },
    {
      "epoch": 0.4430423298627469,
      "grad_norm": 1.042129397392273,
      "learning_rate": 0.000221453525301715,
      "loss": 1.358,
      "step": 41850
    },
    {
      "epoch": 0.44357165164275014,
      "grad_norm": 1.0661871433258057,
      "learning_rate": 0.00022171818759263178,
      "loss": 1.383,
      "step": 41900
    },
    {
      "epoch": 0.44410097342275345,
      "grad_norm": 1.0868765115737915,
      "learning_rate": 0.00022198284988354862,
      "loss": 1.3869,
      "step": 41950
    },
    {
      "epoch": 0.4446302952027567,
      "grad_norm": 1.0840809345245361,
      "learning_rate": 0.0002222475121744654,
      "loss": 1.3677,
      "step": 42000
    },
    {
      "epoch": 0.4446302952027567,
      "eval_loss": 1.3463619947433472,
      "eval_runtime": 46.744,
      "eval_samples_per_second": 3592.544,
      "eval_steps_per_second": 449.084,
      "step": 42000
    },
    {
      "epoch": 0.44515961698275996,
      "grad_norm": 0.9924417734146118,
      "learning_rate": 0.00022251217446538218,
      "loss": 1.3819,
      "step": 42050
    },
    {
      "epoch": 0.4456889387627633,
      "grad_norm": 1.0652399063110352,
      "learning_rate": 0.00022277683675629898,
      "loss": 1.3756,
      "step": 42100
    },
    {
      "epoch": 0.44621826054276653,
      "grad_norm": 1.0289891958236694,
      "learning_rate": 0.00022304149904721576,
      "loss": 1.3703,
      "step": 42150
    },
    {
      "epoch": 0.44674758232276984,
      "grad_norm": 1.2098907232284546,
      "learning_rate": 0.00022330616133813254,
      "loss": 1.3473,
      "step": 42200
    },
    {
      "epoch": 0.4472769041027731,
      "grad_norm": 1.1098166704177856,
      "learning_rate": 0.00022357082362904935,
      "loss": 1.412,
      "step": 42250
    },
    {
      "epoch": 0.4478062258827764,
      "grad_norm": 0.9852575659751892,
      "learning_rate": 0.00022383548591996613,
      "loss": 1.3684,
      "step": 42300
    },
    {
      "epoch": 0.44833554766277967,
      "grad_norm": 1.0816538333892822,
      "learning_rate": 0.00022410014821088294,
      "loss": 1.3738,
      "step": 42350
    },
    {
      "epoch": 0.448864869442783,
      "grad_norm": 1.007748007774353,
      "learning_rate": 0.00022436481050179972,
      "loss": 1.3456,
      "step": 42400
    },
    {
      "epoch": 0.44939419122278623,
      "grad_norm": 1.0173149108886719,
      "learning_rate": 0.0002246294727927165,
      "loss": 1.373,
      "step": 42450
    },
    {
      "epoch": 0.44992351300278954,
      "grad_norm": 1.0456205606460571,
      "learning_rate": 0.0002248941350836333,
      "loss": 1.3657,
      "step": 42500
    },
    {
      "epoch": 0.44992351300278954,
      "eval_loss": 1.3424147367477417,
      "eval_runtime": 46.7563,
      "eval_samples_per_second": 3591.602,
      "eval_steps_per_second": 448.966,
      "step": 42500
    },
    {
      "epoch": 0.4504528347827928,
      "grad_norm": 1.0001031160354614,
      "learning_rate": 0.00022515879737455008,
      "loss": 1.374,
      "step": 42550
    },
    {
      "epoch": 0.4509821565627961,
      "grad_norm": 1.010597586631775,
      "learning_rate": 0.00022542345966546686,
      "loss": 1.3703,
      "step": 42600
    },
    {
      "epoch": 0.45151147834279937,
      "grad_norm": 1.0241334438323975,
      "learning_rate": 0.00022568812195638367,
      "loss": 1.3528,
      "step": 42650
    },
    {
      "epoch": 0.4520408001228027,
      "grad_norm": 1.0707720518112183,
      "learning_rate": 0.00022595278424730045,
      "loss": 1.3733,
      "step": 42700
    },
    {
      "epoch": 0.45257012190280593,
      "grad_norm": 1.0618199110031128,
      "learning_rate": 0.00022621744653821723,
      "loss": 1.3704,
      "step": 42750
    },
    {
      "epoch": 0.45309944368280924,
      "grad_norm": 1.1059131622314453,
      "learning_rate": 0.00022648210882913404,
      "loss": 1.3656,
      "step": 42800
    },
    {
      "epoch": 0.4536287654628125,
      "grad_norm": 1.110371708869934,
      "learning_rate": 0.00022674677112005082,
      "loss": 1.3651,
      "step": 42850
    },
    {
      "epoch": 0.45415808724281576,
      "grad_norm": 1.4708865880966187,
      "learning_rate": 0.00022701143341096762,
      "loss": 1.3537,
      "step": 42900
    },
    {
      "epoch": 0.45468740902281907,
      "grad_norm": 0.9723821878433228,
      "learning_rate": 0.0002272760957018844,
      "loss": 1.3587,
      "step": 42950
    },
    {
      "epoch": 0.4552167308028223,
      "grad_norm": 0.9890206456184387,
      "learning_rate": 0.00022754075799280118,
      "loss": 1.3598,
      "step": 43000
    },
    {
      "epoch": 0.4552167308028223,
      "eval_loss": 1.3392035961151123,
      "eval_runtime": 46.7431,
      "eval_samples_per_second": 3592.613,
      "eval_steps_per_second": 449.093,
      "step": 43000
    },
    {
      "epoch": 0.45574605258282563,
      "grad_norm": 0.9917110800743103,
      "learning_rate": 0.000227805420283718,
      "loss": 1.3519,
      "step": 43050
    },
    {
      "epoch": 0.4562753743628289,
      "grad_norm": 1.0611252784729004,
      "learning_rate": 0.00022807008257463477,
      "loss": 1.3613,
      "step": 43100
    },
    {
      "epoch": 0.4568046961428322,
      "grad_norm": 0.925584077835083,
      "learning_rate": 0.00022833474486555155,
      "loss": 1.3467,
      "step": 43150
    },
    {
      "epoch": 0.45733401792283546,
      "grad_norm": 0.8815200924873352,
      "learning_rate": 0.00022859940715646836,
      "loss": 1.3592,
      "step": 43200
    },
    {
      "epoch": 0.45786333970283877,
      "grad_norm": 1.0420339107513428,
      "learning_rate": 0.00022886406944738514,
      "loss": 1.348,
      "step": 43250
    },
    {
      "epoch": 0.458392661482842,
      "grad_norm": 1.0094975233078003,
      "learning_rate": 0.00022912873173830192,
      "loss": 1.3497,
      "step": 43300
    },
    {
      "epoch": 0.45892198326284533,
      "grad_norm": 1.0673002004623413,
      "learning_rate": 0.00022939339402921872,
      "loss": 1.3588,
      "step": 43350
    },
    {
      "epoch": 0.4594513050428486,
      "grad_norm": 1.076146125793457,
      "learning_rate": 0.0002296580563201355,
      "loss": 1.3444,
      "step": 43400
    },
    {
      "epoch": 0.4599806268228519,
      "grad_norm": 1.0431357622146606,
      "learning_rate": 0.0002299227186110523,
      "loss": 1.3544,
      "step": 43450
    },
    {
      "epoch": 0.46050994860285516,
      "grad_norm": 1.0466388463974,
      "learning_rate": 0.00023018208765615076,
      "loss": 1.3721,
      "step": 43500
    },
    {
      "epoch": 0.46050994860285516,
      "eval_loss": 1.334075927734375,
      "eval_runtime": 46.762,
      "eval_samples_per_second": 3591.16,
      "eval_steps_per_second": 448.911,
      "step": 43500
    },
    {
      "epoch": 0.46103927038285847,
      "grad_norm": 1.0079851150512695,
      "learning_rate": 0.00023044674994706754,
      "loss": 1.3349,
      "step": 43550
    },
    {
      "epoch": 0.4615685921628617,
      "grad_norm": 0.9848505258560181,
      "learning_rate": 0.00023071141223798434,
      "loss": 1.3701,
      "step": 43600
    },
    {
      "epoch": 0.462097913942865,
      "grad_norm": 0.9590371251106262,
      "learning_rate": 0.00023097607452890112,
      "loss": 1.3373,
      "step": 43650
    },
    {
      "epoch": 0.4626272357228683,
      "grad_norm": 1.0869858264923096,
      "learning_rate": 0.0002312407368198179,
      "loss": 1.334,
      "step": 43700
    },
    {
      "epoch": 0.46315655750287155,
      "grad_norm": 0.988281786441803,
      "learning_rate": 0.0002315053991107347,
      "loss": 1.366,
      "step": 43750
    },
    {
      "epoch": 0.46368587928287486,
      "grad_norm": 0.9450811147689819,
      "learning_rate": 0.0002317700614016515,
      "loss": 1.3508,
      "step": 43800
    },
    {
      "epoch": 0.4642152010628781,
      "grad_norm": 0.9221528768539429,
      "learning_rate": 0.0002320347236925683,
      "loss": 1.3546,
      "step": 43850
    },
    {
      "epoch": 0.4647445228428814,
      "grad_norm": 0.9407765865325928,
      "learning_rate": 0.00023229938598348508,
      "loss": 1.3476,
      "step": 43900
    },
    {
      "epoch": 0.4652738446228847,
      "grad_norm": 1.0435428619384766,
      "learning_rate": 0.00023256404827440186,
      "loss": 1.3458,
      "step": 43950
    },
    {
      "epoch": 0.465803166402888,
      "grad_norm": 0.9154748320579529,
      "learning_rate": 0.00023282871056531866,
      "loss": 1.381,
      "step": 44000
    },
    {
      "epoch": 0.465803166402888,
      "eval_loss": 1.3317251205444336,
      "eval_runtime": 46.7652,
      "eval_samples_per_second": 3590.915,
      "eval_steps_per_second": 448.88,
      "step": 44000
    },
    {
      "epoch": 0.46633248818289125,
      "grad_norm": 1.0108217000961304,
      "learning_rate": 0.00023309337285623544,
      "loss": 1.373,
      "step": 44050
    },
    {
      "epoch": 0.46686180996289456,
      "grad_norm": 1.052322506904602,
      "learning_rate": 0.00023335803514715222,
      "loss": 1.3498,
      "step": 44100
    },
    {
      "epoch": 0.4673911317428978,
      "grad_norm": 1.042384147644043,
      "learning_rate": 0.00023362269743806903,
      "loss": 1.3491,
      "step": 44150
    },
    {
      "epoch": 0.4679204535229011,
      "grad_norm": 0.8630908131599426,
      "learning_rate": 0.0002338873597289858,
      "loss": 1.3537,
      "step": 44200
    },
    {
      "epoch": 0.4684497753029044,
      "grad_norm": 0.9835524559020996,
      "learning_rate": 0.0002341520220199026,
      "loss": 1.3436,
      "step": 44250
    },
    {
      "epoch": 0.4689790970829077,
      "grad_norm": 0.9393505454063416,
      "learning_rate": 0.0002344166843108194,
      "loss": 1.3535,
      "step": 44300
    },
    {
      "epoch": 0.46950841886291095,
      "grad_norm": 1.0367316007614136,
      "learning_rate": 0.00023468134660173617,
      "loss": 1.3555,
      "step": 44350
    },
    {
      "epoch": 0.47003774064291426,
      "grad_norm": 1.0540497303009033,
      "learning_rate": 0.00023494600889265298,
      "loss": 1.3406,
      "step": 44400
    },
    {
      "epoch": 0.4705670624229175,
      "grad_norm": 1.0351723432540894,
      "learning_rate": 0.00023521067118356976,
      "loss": 1.3437,
      "step": 44450
    },
    {
      "epoch": 0.47109638420292077,
      "grad_norm": 1.0258861780166626,
      "learning_rate": 0.00023547533347448654,
      "loss": 1.361,
      "step": 44500
    },
    {
      "epoch": 0.47109638420292077,
      "eval_loss": 1.3248544931411743,
      "eval_runtime": 46.6915,
      "eval_samples_per_second": 3596.586,
      "eval_steps_per_second": 449.589,
      "step": 44500
    },
    {
      "epoch": 0.4716257059829241,
      "grad_norm": 0.9952123761177063,
      "learning_rate": 0.00023573999576540335,
      "loss": 1.3593,
      "step": 44550
    },
    {
      "epoch": 0.47215502776292734,
      "grad_norm": 1.0521961450576782,
      "learning_rate": 0.00023600465805632015,
      "loss": 1.3404,
      "step": 44600
    },
    {
      "epoch": 0.47268434954293065,
      "grad_norm": 0.9402496814727783,
      "learning_rate": 0.00023626932034723693,
      "loss": 1.3495,
      "step": 44650
    },
    {
      "epoch": 0.4732136713229339,
      "grad_norm": 1.0061819553375244,
      "learning_rate": 0.00023653398263815374,
      "loss": 1.3278,
      "step": 44700
    },
    {
      "epoch": 0.4737429931029372,
      "grad_norm": 0.9440220594406128,
      "learning_rate": 0.00023679864492907052,
      "loss": 1.3462,
      "step": 44750
    },
    {
      "epoch": 0.47427231488294047,
      "grad_norm": 0.9789949059486389,
      "learning_rate": 0.0002370633072199873,
      "loss": 1.3393,
      "step": 44800
    },
    {
      "epoch": 0.4748016366629438,
      "grad_norm": 1.0165735483169556,
      "learning_rate": 0.0002373279695109041,
      "loss": 1.3433,
      "step": 44850
    },
    {
      "epoch": 0.47533095844294704,
      "grad_norm": 1.0013617277145386,
      "learning_rate": 0.0002375926318018209,
      "loss": 1.3495,
      "step": 44900
    },
    {
      "epoch": 0.47586028022295035,
      "grad_norm": 0.989213228225708,
      "learning_rate": 0.00023785729409273767,
      "loss": 1.3556,
      "step": 44950
    },
    {
      "epoch": 0.4763896020029536,
      "grad_norm": 1.0574731826782227,
      "learning_rate": 0.00023812195638365447,
      "loss": 1.3643,
      "step": 45000
    },
    {
      "epoch": 0.4763896020029536,
      "eval_loss": 1.3245214223861694,
      "eval_runtime": 46.7671,
      "eval_samples_per_second": 3590.775,
      "eval_steps_per_second": 448.863,
      "step": 45000
    },
    {
      "epoch": 0.4769189237829569,
      "grad_norm": 1.1287299394607544,
      "learning_rate": 0.00023838661867457125,
      "loss": 1.3403,
      "step": 45050
    },
    {
      "epoch": 0.47744824556296017,
      "grad_norm": 1.028759479522705,
      "learning_rate": 0.00023865128096548806,
      "loss": 1.3481,
      "step": 45100
    },
    {
      "epoch": 0.4779775673429635,
      "grad_norm": 1.0793702602386475,
      "learning_rate": 0.00023891594325640484,
      "loss": 1.3722,
      "step": 45150
    },
    {
      "epoch": 0.47850688912296674,
      "grad_norm": 1.0336401462554932,
      "learning_rate": 0.00023918060554732162,
      "loss": 1.3434,
      "step": 45200
    },
    {
      "epoch": 0.47903621090297005,
      "grad_norm": 0.9676080942153931,
      "learning_rate": 0.00023944526783823843,
      "loss": 1.3411,
      "step": 45250
    },
    {
      "epoch": 0.4795655326829733,
      "grad_norm": 0.972732663154602,
      "learning_rate": 0.0002397099301291552,
      "loss": 1.3462,
      "step": 45300
    },
    {
      "epoch": 0.48009485446297656,
      "grad_norm": 1.0679187774658203,
      "learning_rate": 0.00023997459242007199,
      "loss": 1.3333,
      "step": 45350
    },
    {
      "epoch": 0.4806241762429799,
      "grad_norm": 0.9638656973838806,
      "learning_rate": 0.0002402392547109888,
      "loss": 1.3396,
      "step": 45400
    },
    {
      "epoch": 0.48115349802298313,
      "grad_norm": 1.0327694416046143,
      "learning_rate": 0.00024050391700190557,
      "loss": 1.3572,
      "step": 45450
    },
    {
      "epoch": 0.48168281980298644,
      "grad_norm": 0.9834762811660767,
      "learning_rate": 0.00024076328604700405,
      "loss": 1.3341,
      "step": 45500
    },
    {
      "epoch": 0.48168281980298644,
      "eval_loss": 1.3228257894515991,
      "eval_runtime": 46.8063,
      "eval_samples_per_second": 3587.762,
      "eval_steps_per_second": 448.486,
      "step": 45500
    },
    {
      "epoch": 0.4822121415829897,
      "grad_norm": 1.075933575630188,
      "learning_rate": 0.00024102794833792083,
      "loss": 1.3455,
      "step": 45550
    },
    {
      "epoch": 0.482741463362993,
      "grad_norm": 0.9830586910247803,
      "learning_rate": 0.0002412926106288376,
      "loss": 1.3415,
      "step": 45600
    },
    {
      "epoch": 0.48327078514299626,
      "grad_norm": 0.972416341304779,
      "learning_rate": 0.00024155727291975441,
      "loss": 1.3142,
      "step": 45650
    },
    {
      "epoch": 0.4838001069229996,
      "grad_norm": 1.14089035987854,
      "learning_rate": 0.0002418219352106712,
      "loss": 1.3414,
      "step": 45700
    },
    {
      "epoch": 0.48432942870300283,
      "grad_norm": 1.0894341468811035,
      "learning_rate": 0.00024208659750158797,
      "loss": 1.3425,
      "step": 45750
    },
    {
      "epoch": 0.48485875048300614,
      "grad_norm": 0.9550580382347107,
      "learning_rate": 0.00024235125979250478,
      "loss": 1.3324,
      "step": 45800
    },
    {
      "epoch": 0.4853880722630094,
      "grad_norm": 0.9958351850509644,
      "learning_rate": 0.00024261592208342156,
      "loss": 1.3446,
      "step": 45850
    },
    {
      "epoch": 0.4859173940430127,
      "grad_norm": 1.0436824560165405,
      "learning_rate": 0.00024288058437433834,
      "loss": 1.354,
      "step": 45900
    },
    {
      "epoch": 0.48644671582301596,
      "grad_norm": 0.9750409126281738,
      "learning_rate": 0.00024314524666525515,
      "loss": 1.3272,
      "step": 45950
    },
    {
      "epoch": 0.4869760376030193,
      "grad_norm": 0.973522961139679,
      "learning_rate": 0.00024340990895617193,
      "loss": 1.3358,
      "step": 46000
    },
    {
      "epoch": 0.4869760376030193,
      "eval_loss": 1.3159338235855103,
      "eval_runtime": 46.8018,
      "eval_samples_per_second": 3588.111,
      "eval_steps_per_second": 448.53,
      "step": 46000
    },
    {
      "epoch": 0.48750535938302253,
      "grad_norm": 0.9599478244781494,
      "learning_rate": 0.00024367457124708873,
      "loss": 1.3517,
      "step": 46050
    },
    {
      "epoch": 0.48803468116302584,
      "grad_norm": 0.9793923497200012,
      "learning_rate": 0.0002439392335380055,
      "loss": 1.3256,
      "step": 46100
    },
    {
      "epoch": 0.4885640029430291,
      "grad_norm": 1.1146676540374756,
      "learning_rate": 0.0002442038958289223,
      "loss": 1.322,
      "step": 46150
    },
    {
      "epoch": 0.48909332472303235,
      "grad_norm": 1.0480844974517822,
      "learning_rate": 0.0002444685581198391,
      "loss": 1.3332,
      "step": 46200
    },
    {
      "epoch": 0.48962264650303566,
      "grad_norm": 1.0008348226547241,
      "learning_rate": 0.0002447332204107559,
      "loss": 1.3498,
      "step": 46250
    },
    {
      "epoch": 0.4901519682830389,
      "grad_norm": 1.0371170043945312,
      "learning_rate": 0.00024499788270167266,
      "loss": 1.3473,
      "step": 46300
    },
    {
      "epoch": 0.49068129006304223,
      "grad_norm": 1.1420572996139526,
      "learning_rate": 0.00024526254499258947,
      "loss": 1.35,
      "step": 46350
    },
    {
      "epoch": 0.4912106118430455,
      "grad_norm": 1.0219959020614624,
      "learning_rate": 0.0002455272072835063,
      "loss": 1.32,
      "step": 46400
    },
    {
      "epoch": 0.4917399336230488,
      "grad_norm": 1.0544102191925049,
      "learning_rate": 0.000245791869574423,
      "loss": 1.3421,
      "step": 46450
    },
    {
      "epoch": 0.49226925540305205,
      "grad_norm": 0.9059445858001709,
      "learning_rate": 0.00024605653186533983,
      "loss": 1.3232,
      "step": 46500
    },
    {
      "epoch": 0.49226925540305205,
      "eval_loss": 1.3121368885040283,
      "eval_runtime": 46.8485,
      "eval_samples_per_second": 3584.537,
      "eval_steps_per_second": 448.083,
      "step": 46500
    },
    {
      "epoch": 0.49279857718305536,
      "grad_norm": 1.0530571937561035,
      "learning_rate": 0.00024632119415625664,
      "loss": 1.3512,
      "step": 46550
    },
    {
      "epoch": 0.4933278989630586,
      "grad_norm": 1.1443569660186768,
      "learning_rate": 0.0002465858564471734,
      "loss": 1.3269,
      "step": 46600
    },
    {
      "epoch": 0.49385722074306193,
      "grad_norm": 0.9366532564163208,
      "learning_rate": 0.0002468505187380902,
      "loss": 1.3276,
      "step": 46650
    },
    {
      "epoch": 0.4943865425230652,
      "grad_norm": 0.9886336922645569,
      "learning_rate": 0.000247115181029007,
      "loss": 1.3482,
      "step": 46700
    },
    {
      "epoch": 0.4949158643030685,
      "grad_norm": 0.9964176416397095,
      "learning_rate": 0.00024737984331992376,
      "loss": 1.3467,
      "step": 46750
    },
    {
      "epoch": 0.49544518608307175,
      "grad_norm": 0.9206998348236084,
      "learning_rate": 0.00024764450561084057,
      "loss": 1.3256,
      "step": 46800
    },
    {
      "epoch": 0.49597450786307506,
      "grad_norm": 1.0107988119125366,
      "learning_rate": 0.00024790916790175737,
      "loss": 1.3246,
      "step": 46850
    },
    {
      "epoch": 0.4965038296430783,
      "grad_norm": 1.04896080493927,
      "learning_rate": 0.0002481738301926741,
      "loss": 1.3218,
      "step": 46900
    },
    {
      "epoch": 0.49703315142308163,
      "grad_norm": 0.9614107012748718,
      "learning_rate": 0.00024843849248359093,
      "loss": 1.3317,
      "step": 46950
    },
    {
      "epoch": 0.4975624732030849,
      "grad_norm": 0.9811059832572937,
      "learning_rate": 0.00024870315477450774,
      "loss": 1.3275,
      "step": 47000
    },
    {
      "epoch": 0.4975624732030849,
      "eval_loss": 1.3095425367355347,
      "eval_runtime": 46.7209,
      "eval_samples_per_second": 3594.326,
      "eval_steps_per_second": 449.307,
      "step": 47000
    },
    {
      "epoch": 0.49809179498308814,
      "grad_norm": 0.8786454796791077,
      "learning_rate": 0.0002489678170654245,
      "loss": 1.3527,
      "step": 47050
    },
    {
      "epoch": 0.49862111676309145,
      "grad_norm": 0.9946854710578918,
      "learning_rate": 0.0002492324793563413,
      "loss": 1.3535,
      "step": 47100
    },
    {
      "epoch": 0.4991504385430947,
      "grad_norm": 1.0568983554840088,
      "learning_rate": 0.0002494971416472581,
      "loss": 1.3204,
      "step": 47150
    },
    {
      "epoch": 0.499679760323098,
      "grad_norm": 0.9594821929931641,
      "learning_rate": 0.00024976180393817486,
      "loss": 1.3328,
      "step": 47200
    },
    {
      "epoch": 0.5002090821031013,
      "grad_norm": 0.945955753326416,
      "learning_rate": 0.0002500264662290917,
      "loss": 1.338,
      "step": 47250
    },
    {
      "epoch": 0.5007384038831045,
      "grad_norm": 1.0160274505615234,
      "learning_rate": 0.00025029112852000847,
      "loss": 1.3111,
      "step": 47300
    },
    {
      "epoch": 0.5012677256631078,
      "grad_norm": 1.0420081615447998,
      "learning_rate": 0.0002505557908109253,
      "loss": 1.3235,
      "step": 47350
    },
    {
      "epoch": 0.5017970474431112,
      "grad_norm": 1.0158330202102661,
      "learning_rate": 0.00025082045310184203,
      "loss": 1.3327,
      "step": 47400
    },
    {
      "epoch": 0.5023263692231145,
      "grad_norm": 0.9767031073570251,
      "learning_rate": 0.00025108511539275884,
      "loss": 1.3378,
      "step": 47450
    },
    {
      "epoch": 0.5028556910031177,
      "grad_norm": 1.0179122686386108,
      "learning_rate": 0.00025134977768367564,
      "loss": 1.3256,
      "step": 47500
    },
    {
      "epoch": 0.5028556910031177,
      "eval_loss": 1.301214337348938,
      "eval_runtime": 46.7528,
      "eval_samples_per_second": 3591.869,
      "eval_steps_per_second": 449.0,
      "step": 47500
    },
    {
      "epoch": 0.503385012783121,
      "grad_norm": 0.9938287734985352,
      "learning_rate": 0.0002516091467287741,
      "loss": 1.335,
      "step": 47550
    },
    {
      "epoch": 0.5039143345631243,
      "grad_norm": 1.0770525932312012,
      "learning_rate": 0.00025187380901969087,
      "loss": 1.3271,
      "step": 47600
    },
    {
      "epoch": 0.5044436563431276,
      "grad_norm": 1.0077121257781982,
      "learning_rate": 0.0002521384713106077,
      "loss": 1.3368,
      "step": 47650
    },
    {
      "epoch": 0.5049729781231308,
      "grad_norm": 1.0549685955047607,
      "learning_rate": 0.00025240313360152443,
      "loss": 1.3121,
      "step": 47700
    },
    {
      "epoch": 0.5055022999031341,
      "grad_norm": 0.9207723736763,
      "learning_rate": 0.0002526677958924413,
      "loss": 1.3208,
      "step": 47750
    },
    {
      "epoch": 0.5060316216831374,
      "grad_norm": 0.932598888874054,
      "learning_rate": 0.00025293245818335805,
      "loss": 1.3127,
      "step": 47800
    },
    {
      "epoch": 0.5065609434631406,
      "grad_norm": 1.0228254795074463,
      "learning_rate": 0.00025319712047427485,
      "loss": 1.3281,
      "step": 47850
    },
    {
      "epoch": 0.5070902652431439,
      "grad_norm": 1.066323161125183,
      "learning_rate": 0.0002534617827651916,
      "loss": 1.3256,
      "step": 47900
    },
    {
      "epoch": 0.5076195870231472,
      "grad_norm": 1.081089735031128,
      "learning_rate": 0.0002537264450561084,
      "loss": 1.3293,
      "step": 47950
    },
    {
      "epoch": 0.5081489088031506,
      "grad_norm": 1.050999641418457,
      "learning_rate": 0.00025399110734702516,
      "loss": 1.321,
      "step": 48000
    },
    {
      "epoch": 0.5081489088031506,
      "eval_loss": 1.3014805316925049,
      "eval_runtime": 46.6902,
      "eval_samples_per_second": 3596.685,
      "eval_steps_per_second": 449.602,
      "step": 48000
    },
    {
      "epoch": 0.5086782305831538,
      "grad_norm": 0.987300455570221,
      "learning_rate": 0.000254255769637942,
      "loss": 1.3188,
      "step": 48050
    },
    {
      "epoch": 0.5092075523631571,
      "grad_norm": 0.9855123162269592,
      "learning_rate": 0.0002545204319288588,
      "loss": 1.2965,
      "step": 48100
    },
    {
      "epoch": 0.5097368741431604,
      "grad_norm": 1.0414483547210693,
      "learning_rate": 0.0002547850942197756,
      "loss": 1.3315,
      "step": 48150
    },
    {
      "epoch": 0.5102661959231637,
      "grad_norm": 1.0635850429534912,
      "learning_rate": 0.00025504975651069234,
      "loss": 1.3181,
      "step": 48200
    },
    {
      "epoch": 0.5107955177031669,
      "grad_norm": 0.9947777986526489,
      "learning_rate": 0.00025531441880160914,
      "loss": 1.3219,
      "step": 48250
    },
    {
      "epoch": 0.5113248394831702,
      "grad_norm": 1.0034343004226685,
      "learning_rate": 0.0002555790810925259,
      "loss": 1.3346,
      "step": 48300
    },
    {
      "epoch": 0.5118541612631735,
      "grad_norm": 1.0191032886505127,
      "learning_rate": 0.00025584374338344276,
      "loss": 1.3085,
      "step": 48350
    },
    {
      "epoch": 0.5123834830431768,
      "grad_norm": 0.9993306398391724,
      "learning_rate": 0.0002561084056743595,
      "loss": 1.3227,
      "step": 48400
    },
    {
      "epoch": 0.51291280482318,
      "grad_norm": 1.0654734373092651,
      "learning_rate": 0.0002563730679652763,
      "loss": 1.3313,
      "step": 48450
    },
    {
      "epoch": 0.5134421266031833,
      "grad_norm": 0.9644051790237427,
      "learning_rate": 0.00025663773025619307,
      "loss": 1.3124,
      "step": 48500
    },
    {
      "epoch": 0.5134421266031833,
      "eval_loss": 1.2959873676300049,
      "eval_runtime": 46.7875,
      "eval_samples_per_second": 3589.208,
      "eval_steps_per_second": 448.667,
      "step": 48500
    },
    {
      "epoch": 0.5139714483831866,
      "grad_norm": 0.9728120565414429,
      "learning_rate": 0.0002569023925471099,
      "loss": 1.2993,
      "step": 48550
    },
    {
      "epoch": 0.51450077016319,
      "grad_norm": 1.024842381477356,
      "learning_rate": 0.0002571670548380267,
      "loss": 1.2976,
      "step": 48600
    },
    {
      "epoch": 0.5150300919431932,
      "grad_norm": 0.9350396394729614,
      "learning_rate": 0.0002574317171289435,
      "loss": 1.3232,
      "step": 48650
    },
    {
      "epoch": 0.5155594137231965,
      "grad_norm": 0.9686723947525024,
      "learning_rate": 0.00025769637941986024,
      "loss": 1.2912,
      "step": 48700
    },
    {
      "epoch": 0.5160887355031998,
      "grad_norm": 1.108198642730713,
      "learning_rate": 0.00025796104171077705,
      "loss": 1.3063,
      "step": 48750
    },
    {
      "epoch": 0.516618057283203,
      "grad_norm": 0.9719573259353638,
      "learning_rate": 0.0002582257040016938,
      "loss": 1.3378,
      "step": 48800
    },
    {
      "epoch": 0.5171473790632063,
      "grad_norm": 0.956623911857605,
      "learning_rate": 0.0002584903662926106,
      "loss": 1.325,
      "step": 48850
    },
    {
      "epoch": 0.5176767008432096,
      "grad_norm": 1.1790651082992554,
      "learning_rate": 0.00025875502858352747,
      "loss": 1.3357,
      "step": 48900
    },
    {
      "epoch": 0.5182060226232129,
      "grad_norm": 1.0514012575149536,
      "learning_rate": 0.0002590196908744442,
      "loss": 1.3062,
      "step": 48950
    },
    {
      "epoch": 0.5187353444032161,
      "grad_norm": 1.0537090301513672,
      "learning_rate": 0.00025928435316536103,
      "loss": 1.3188,
      "step": 49000
    },
    {
      "epoch": 0.5187353444032161,
      "eval_loss": 1.2938332557678223,
      "eval_runtime": 46.7134,
      "eval_samples_per_second": 3594.899,
      "eval_steps_per_second": 449.378,
      "step": 49000
    },
    {
      "epoch": 0.5192646661832194,
      "grad_norm": 1.0422569513320923,
      "learning_rate": 0.0002595490154562778,
      "loss": 1.325,
      "step": 49050
    },
    {
      "epoch": 0.5197939879632227,
      "grad_norm": 1.1999825239181519,
      "learning_rate": 0.0002598136777471946,
      "loss": 1.3176,
      "step": 49100
    },
    {
      "epoch": 0.520323309743226,
      "grad_norm": 1.0588550567626953,
      "learning_rate": 0.0002600783400381114,
      "loss": 1.3111,
      "step": 49150
    },
    {
      "epoch": 0.5208526315232292,
      "grad_norm": 1.1023017168045044,
      "learning_rate": 0.0002603430023290282,
      "loss": 1.3272,
      "step": 49200
    },
    {
      "epoch": 0.5213819533032326,
      "grad_norm": 1.052655577659607,
      "learning_rate": 0.00026060766461994496,
      "loss": 1.3341,
      "step": 49250
    },
    {
      "epoch": 0.5219112750832359,
      "grad_norm": 0.9569703936576843,
      "learning_rate": 0.00026087232691086176,
      "loss": 1.3235,
      "step": 49300
    },
    {
      "epoch": 0.5224405968632392,
      "grad_norm": 1.0648913383483887,
      "learning_rate": 0.0002611369892017785,
      "loss": 1.3046,
      "step": 49350
    },
    {
      "epoch": 0.5229699186432424,
      "grad_norm": 1.0371938943862915,
      "learning_rate": 0.0002614016514926953,
      "loss": 1.3065,
      "step": 49400
    },
    {
      "epoch": 0.5234992404232457,
      "grad_norm": 0.9544269442558289,
      "learning_rate": 0.00026166631378361213,
      "loss": 1.3049,
      "step": 49450
    },
    {
      "epoch": 0.524028562203249,
      "grad_norm": 1.0736576318740845,
      "learning_rate": 0.00026193097607452894,
      "loss": 1.3337,
      "step": 49500
    },
    {
      "epoch": 0.524028562203249,
      "eval_loss": 1.2866625785827637,
      "eval_runtime": 46.7782,
      "eval_samples_per_second": 3589.92,
      "eval_steps_per_second": 448.756,
      "step": 49500
    },
    {
      "epoch": 0.5245578839832522,
      "grad_norm": 1.0686836242675781,
      "learning_rate": 0.0002621956383654457,
      "loss": 1.3085,
      "step": 49550
    },
    {
      "epoch": 0.5250872057632555,
      "grad_norm": 1.0677868127822876,
      "learning_rate": 0.00026245500741054416,
      "loss": 1.3265,
      "step": 49600
    },
    {
      "epoch": 0.5256165275432588,
      "grad_norm": 1.0582420825958252,
      "learning_rate": 0.0002627196697014609,
      "loss": 1.3049,
      "step": 49650
    },
    {
      "epoch": 0.5261458493232621,
      "grad_norm": 1.0626354217529297,
      "learning_rate": 0.0002629843319923778,
      "loss": 1.3265,
      "step": 49700
    },
    {
      "epoch": 0.5266751711032653,
      "grad_norm": 0.9634941816329956,
      "learning_rate": 0.00026324899428329453,
      "loss": 1.3146,
      "step": 49750
    },
    {
      "epoch": 0.5272044928832686,
      "grad_norm": 1.0418483018875122,
      "learning_rate": 0.00026351365657421134,
      "loss": 1.3124,
      "step": 49800
    },
    {
      "epoch": 0.527733814663272,
      "grad_norm": 0.9535608291625977,
      "learning_rate": 0.0002637783188651281,
      "loss": 1.3002,
      "step": 49850
    },
    {
      "epoch": 0.5282631364432753,
      "grad_norm": 1.0701441764831543,
      "learning_rate": 0.0002640429811560449,
      "loss": 1.3134,
      "step": 49900
    },
    {
      "epoch": 0.5287924582232785,
      "grad_norm": 0.9937403798103333,
      "learning_rate": 0.0002643076434469617,
      "loss": 1.3162,
      "step": 49950
    },
    {
      "epoch": 0.5293217800032818,
      "grad_norm": 0.9687849879264832,
      "learning_rate": 0.0002645723057378785,
      "loss": 1.2941,
      "step": 50000
    },
    {
      "epoch": 0.5293217800032818,
      "eval_loss": 1.2836863994598389,
      "eval_runtime": 46.7665,
      "eval_samples_per_second": 3590.816,
      "eval_steps_per_second": 448.868,
      "step": 50000
    },
    {
      "epoch": 0.5298511017832851,
      "grad_norm": 1.0738111734390259,
      "learning_rate": 0.00026483696802879526,
      "loss": 1.3223,
      "step": 50050
    },
    {
      "epoch": 0.5303804235632884,
      "grad_norm": 1.0371661186218262,
      "learning_rate": 0.00026510163031971207,
      "loss": 1.2998,
      "step": 50100
    },
    {
      "epoch": 0.5309097453432916,
      "grad_norm": 1.0554258823394775,
      "learning_rate": 0.0002653662926106288,
      "loss": 1.3128,
      "step": 50150
    },
    {
      "epoch": 0.5314390671232949,
      "grad_norm": 1.0628613233566284,
      "learning_rate": 0.00026563095490154563,
      "loss": 1.2969,
      "step": 50200
    },
    {
      "epoch": 0.5319683889032982,
      "grad_norm": 0.9941333532333374,
      "learning_rate": 0.00026589561719246244,
      "loss": 1.3149,
      "step": 50250
    },
    {
      "epoch": 0.5324977106833015,
      "grad_norm": 0.8981298804283142,
      "learning_rate": 0.00026616027948337924,
      "loss": 1.3021,
      "step": 50300
    },
    {
      "epoch": 0.5330270324633047,
      "grad_norm": 0.9351850152015686,
      "learning_rate": 0.000266424941774296,
      "loss": 1.3027,
      "step": 50350
    },
    {
      "epoch": 0.533556354243308,
      "grad_norm": 1.0219215154647827,
      "learning_rate": 0.0002666896040652128,
      "loss": 1.2977,
      "step": 50400
    },
    {
      "epoch": 0.5340856760233114,
      "grad_norm": 1.07499098777771,
      "learning_rate": 0.00026695426635612955,
      "loss": 1.3089,
      "step": 50450
    },
    {
      "epoch": 0.5346149978033146,
      "grad_norm": 1.0301283597946167,
      "learning_rate": 0.0002672189286470464,
      "loss": 1.3196,
      "step": 50500
    },
    {
      "epoch": 0.5346149978033146,
      "eval_loss": 1.281463861465454,
      "eval_runtime": 46.7081,
      "eval_samples_per_second": 3595.312,
      "eval_steps_per_second": 449.43,
      "step": 50500
    },
    {
      "epoch": 0.5351443195833179,
      "grad_norm": 1.1160731315612793,
      "learning_rate": 0.00026748359093796317,
      "loss": 1.2977,
      "step": 50550
    },
    {
      "epoch": 0.5356736413633212,
      "grad_norm": 1.0299346446990967,
      "learning_rate": 0.00026774825322888,
      "loss": 1.295,
      "step": 50600
    },
    {
      "epoch": 0.5362029631433245,
      "grad_norm": 1.0015002489089966,
      "learning_rate": 0.00026801291551979673,
      "loss": 1.3059,
      "step": 50650
    },
    {
      "epoch": 0.5367322849233277,
      "grad_norm": 0.9596492648124695,
      "learning_rate": 0.00026827757781071353,
      "loss": 1.3169,
      "step": 50700
    },
    {
      "epoch": 0.537261606703331,
      "grad_norm": 0.9731830358505249,
      "learning_rate": 0.0002685422401016303,
      "loss": 1.2982,
      "step": 50750
    },
    {
      "epoch": 0.5377909284833343,
      "grad_norm": 1.1649625301361084,
      "learning_rate": 0.00026880690239254715,
      "loss": 1.3018,
      "step": 50800
    },
    {
      "epoch": 0.5383202502633376,
      "grad_norm": 1.041294813156128,
      "learning_rate": 0.0002690715646834639,
      "loss": 1.2821,
      "step": 50850
    },
    {
      "epoch": 0.5388495720433408,
      "grad_norm": 1.0152708292007446,
      "learning_rate": 0.0002693362269743807,
      "loss": 1.3052,
      "step": 50900
    },
    {
      "epoch": 0.5393788938233441,
      "grad_norm": 1.008738398551941,
      "learning_rate": 0.00026960088926529746,
      "loss": 1.2979,
      "step": 50950
    },
    {
      "epoch": 0.5399082156033475,
      "grad_norm": 1.0212430953979492,
      "learning_rate": 0.00026986555155621427,
      "loss": 1.307,
      "step": 51000
    },
    {
      "epoch": 0.5399082156033475,
      "eval_loss": 1.2747868299484253,
      "eval_runtime": 46.7812,
      "eval_samples_per_second": 3589.692,
      "eval_steps_per_second": 448.727,
      "step": 51000
    },
    {
      "epoch": 0.5404375373833508,
      "grad_norm": 0.9610665440559387,
      "learning_rate": 0.000270130213847131,
      "loss": 1.2992,
      "step": 51050
    },
    {
      "epoch": 0.540966859163354,
      "grad_norm": 1.124027967453003,
      "learning_rate": 0.0002703948761380479,
      "loss": 1.2966,
      "step": 51100
    },
    {
      "epoch": 0.5414961809433573,
      "grad_norm": 1.044956088066101,
      "learning_rate": 0.00027065953842896463,
      "loss": 1.32,
      "step": 51150
    },
    {
      "epoch": 0.5420255027233606,
      "grad_norm": 1.1242209672927856,
      "learning_rate": 0.00027092420071988144,
      "loss": 1.3031,
      "step": 51200
    },
    {
      "epoch": 0.5425548245033638,
      "grad_norm": 1.0157140493392944,
      "learning_rate": 0.0002711888630107982,
      "loss": 1.2867,
      "step": 51250
    },
    {
      "epoch": 0.5430841462833671,
      "grad_norm": 0.9371163249015808,
      "learning_rate": 0.000271453525301715,
      "loss": 1.3122,
      "step": 51300
    },
    {
      "epoch": 0.5436134680633704,
      "grad_norm": 0.9833083152770996,
      "learning_rate": 0.0002717181875926318,
      "loss": 1.3224,
      "step": 51350
    },
    {
      "epoch": 0.5441427898433737,
      "grad_norm": 0.9846370220184326,
      "learning_rate": 0.0002719828498835486,
      "loss": 1.3027,
      "step": 51400
    },
    {
      "epoch": 0.5446721116233769,
      "grad_norm": 1.0207408666610718,
      "learning_rate": 0.00027224751217446537,
      "loss": 1.3215,
      "step": 51450
    },
    {
      "epoch": 0.5452014334033802,
      "grad_norm": 1.0366532802581787,
      "learning_rate": 0.0002725121744653822,
      "loss": 1.3149,
      "step": 51500
    },
    {
      "epoch": 0.5452014334033802,
      "eval_loss": 1.2737611532211304,
      "eval_runtime": 46.747,
      "eval_samples_per_second": 3592.318,
      "eval_steps_per_second": 449.056,
      "step": 51500
    },
    {
      "epoch": 0.5457307551833835,
      "grad_norm": 0.9994709491729736,
      "learning_rate": 0.0002727768367562989,
      "loss": 1.2866,
      "step": 51550
    },
    {
      "epoch": 0.5462600769633869,
      "grad_norm": 1.0362348556518555,
      "learning_rate": 0.00027303620580139746,
      "loss": 1.2806,
      "step": 51600
    },
    {
      "epoch": 0.54678939874339,
      "grad_norm": 1.0769548416137695,
      "learning_rate": 0.0002733008680923142,
      "loss": 1.297,
      "step": 51650
    },
    {
      "epoch": 0.5473187205233934,
      "grad_norm": 0.9891548156738281,
      "learning_rate": 0.000273565530383231,
      "loss": 1.3076,
      "step": 51700
    },
    {
      "epoch": 0.5478480423033967,
      "grad_norm": 0.9094017148017883,
      "learning_rate": 0.00027383019267414777,
      "loss": 1.3119,
      "step": 51750
    },
    {
      "epoch": 0.5483773640834,
      "grad_norm": 0.9858952164649963,
      "learning_rate": 0.0002740948549650646,
      "loss": 1.3145,
      "step": 51800
    },
    {
      "epoch": 0.5489066858634032,
      "grad_norm": 0.941991925239563,
      "learning_rate": 0.0002743595172559813,
      "loss": 1.3101,
      "step": 51850
    },
    {
      "epoch": 0.5494360076434065,
      "grad_norm": 1.0519148111343384,
      "learning_rate": 0.0002746241795468982,
      "loss": 1.3015,
      "step": 51900
    },
    {
      "epoch": 0.5499653294234098,
      "grad_norm": 1.0433694124221802,
      "learning_rate": 0.00027488884183781494,
      "loss": 1.3114,
      "step": 51950
    },
    {
      "epoch": 0.5504946512034131,
      "grad_norm": 0.9538258910179138,
      "learning_rate": 0.00027515350412873175,
      "loss": 1.323,
      "step": 52000
    },
    {
      "epoch": 0.5504946512034131,
      "eval_loss": 1.2688344717025757,
      "eval_runtime": 46.7892,
      "eval_samples_per_second": 3589.076,
      "eval_steps_per_second": 448.651,
      "step": 52000
    },
    {
      "epoch": 0.5510239729834163,
      "grad_norm": 1.0431259870529175,
      "learning_rate": 0.0002754181664196485,
      "loss": 1.3081,
      "step": 52050
    },
    {
      "epoch": 0.5515532947634196,
      "grad_norm": 1.0298100709915161,
      "learning_rate": 0.0002756828287105653,
      "loss": 1.2789,
      "step": 52100
    },
    {
      "epoch": 0.5520826165434229,
      "grad_norm": 1.0607705116271973,
      "learning_rate": 0.0002759474910014821,
      "loss": 1.3003,
      "step": 52150
    },
    {
      "epoch": 0.5526119383234261,
      "grad_norm": 0.8957108855247498,
      "learning_rate": 0.0002762121532923989,
      "loss": 1.3156,
      "step": 52200
    },
    {
      "epoch": 0.5531412601034295,
      "grad_norm": 1.025702953338623,
      "learning_rate": 0.00027647681558331573,
      "loss": 1.3083,
      "step": 52250
    },
    {
      "epoch": 0.5536705818834328,
      "grad_norm": 1.0055348873138428,
      "learning_rate": 0.0002767414778742325,
      "loss": 1.3048,
      "step": 52300
    },
    {
      "epoch": 0.5541999036634361,
      "grad_norm": 0.9865642189979553,
      "learning_rate": 0.0002770061401651493,
      "loss": 1.308,
      "step": 52350
    },
    {
      "epoch": 0.5547292254434393,
      "grad_norm": 0.9593037962913513,
      "learning_rate": 0.00027727080245606604,
      "loss": 1.2843,
      "step": 52400
    },
    {
      "epoch": 0.5552585472234426,
      "grad_norm": 0.9697381854057312,
      "learning_rate": 0.0002775354647469829,
      "loss": 1.3098,
      "step": 52450
    },
    {
      "epoch": 0.5557878690034459,
      "grad_norm": 0.9884251356124878,
      "learning_rate": 0.00027780012703789965,
      "loss": 1.3121,
      "step": 52500
    },
    {
      "epoch": 0.5557878690034459,
      "eval_loss": 1.265130877494812,
      "eval_runtime": 46.7068,
      "eval_samples_per_second": 3595.406,
      "eval_steps_per_second": 449.442,
      "step": 52500
    },
    {
      "epoch": 0.5563171907834492,
      "grad_norm": 1.0449341535568237,
      "learning_rate": 0.00027806478932881646,
      "loss": 1.3007,
      "step": 52550
    },
    {
      "epoch": 0.5568465125634524,
      "grad_norm": 0.9911653995513916,
      "learning_rate": 0.0002783294516197332,
      "loss": 1.3132,
      "step": 52600
    },
    {
      "epoch": 0.5573758343434557,
      "grad_norm": 1.0383965969085693,
      "learning_rate": 0.00027859411391065,
      "loss": 1.3141,
      "step": 52650
    },
    {
      "epoch": 0.557905156123459,
      "grad_norm": 1.002510905265808,
      "learning_rate": 0.0002788587762015668,
      "loss": 1.2893,
      "step": 52700
    },
    {
      "epoch": 0.5584344779034623,
      "grad_norm": 0.9943110942840576,
      "learning_rate": 0.00027912343849248363,
      "loss": 1.3242,
      "step": 52750
    },
    {
      "epoch": 0.5589637996834655,
      "grad_norm": 0.9843693971633911,
      "learning_rate": 0.0002793881007834004,
      "loss": 1.3038,
      "step": 52800
    },
    {
      "epoch": 0.5594931214634689,
      "grad_norm": 0.9961802363395691,
      "learning_rate": 0.0002796527630743172,
      "loss": 1.2874,
      "step": 52850
    },
    {
      "epoch": 0.5600224432434722,
      "grad_norm": 1.0679268836975098,
      "learning_rate": 0.00027991742536523395,
      "loss": 1.2995,
      "step": 52900
    },
    {
      "epoch": 0.5605517650234754,
      "grad_norm": 0.9550262093544006,
      "learning_rate": 0.00028018208765615075,
      "loss": 1.2934,
      "step": 52950
    },
    {
      "epoch": 0.5610810868034787,
      "grad_norm": 1.1188998222351074,
      "learning_rate": 0.00028044674994706756,
      "loss": 1.2817,
      "step": 53000
    },
    {
      "epoch": 0.5610810868034787,
      "eval_loss": 1.2626755237579346,
      "eval_runtime": 46.6738,
      "eval_samples_per_second": 3597.948,
      "eval_steps_per_second": 449.76,
      "step": 53000
    },
    {
      "epoch": 0.561610408583482,
      "grad_norm": 0.9422969818115234,
      "learning_rate": 0.00028071141223798437,
      "loss": 1.2747,
      "step": 53050
    },
    {
      "epoch": 0.5621397303634853,
      "grad_norm": 0.9365777969360352,
      "learning_rate": 0.0002809760745289011,
      "loss": 1.3039,
      "step": 53100
    },
    {
      "epoch": 0.5626690521434885,
      "grad_norm": 1.0606942176818848,
      "learning_rate": 0.0002812407368198179,
      "loss": 1.2907,
      "step": 53150
    },
    {
      "epoch": 0.5631983739234918,
      "grad_norm": 0.9602625370025635,
      "learning_rate": 0.0002815053991107347,
      "loss": 1.3114,
      "step": 53200
    },
    {
      "epoch": 0.5637276957034951,
      "grad_norm": 1.1011375188827515,
      "learning_rate": 0.00028177006140165154,
      "loss": 1.2917,
      "step": 53250
    },
    {
      "epoch": 0.5642570174834984,
      "grad_norm": 0.9574454426765442,
      "learning_rate": 0.0002820347236925683,
      "loss": 1.2985,
      "step": 53300
    },
    {
      "epoch": 0.5647863392635016,
      "grad_norm": 1.0038504600524902,
      "learning_rate": 0.0002822993859834851,
      "loss": 1.2584,
      "step": 53350
    },
    {
      "epoch": 0.565315661043505,
      "grad_norm": 1.0158222913742065,
      "learning_rate": 0.00028256404827440185,
      "loss": 1.2916,
      "step": 53400
    },
    {
      "epoch": 0.5658449828235083,
      "grad_norm": 1.1246707439422607,
      "learning_rate": 0.00028282871056531866,
      "loss": 1.3021,
      "step": 53450
    },
    {
      "epoch": 0.5663743046035116,
      "grad_norm": 1.0119366645812988,
      "learning_rate": 0.0002830933728562354,
      "loss": 1.2918,
      "step": 53500
    },
    {
      "epoch": 0.5663743046035116,
      "eval_loss": 1.2581562995910645,
      "eval_runtime": 46.6936,
      "eval_samples_per_second": 3596.424,
      "eval_steps_per_second": 449.569,
      "step": 53500
    },
    {
      "epoch": 0.5669036263835148,
      "grad_norm": 0.9370118975639343,
      "learning_rate": 0.00028335803514715227,
      "loss": 1.2908,
      "step": 53550
    },
    {
      "epoch": 0.5674329481635181,
      "grad_norm": 0.9965866208076477,
      "learning_rate": 0.0002836174041922507,
      "loss": 1.2873,
      "step": 53600
    },
    {
      "epoch": 0.5679622699435214,
      "grad_norm": 1.0730326175689697,
      "learning_rate": 0.0002838820664831675,
      "loss": 1.2566,
      "step": 53650
    },
    {
      "epoch": 0.5684915917235247,
      "grad_norm": 0.9280703663825989,
      "learning_rate": 0.00028414672877408425,
      "loss": 1.2794,
      "step": 53700
    },
    {
      "epoch": 0.5690209135035279,
      "grad_norm": 0.9665449857711792,
      "learning_rate": 0.00028441139106500106,
      "loss": 1.2768,
      "step": 53750
    },
    {
      "epoch": 0.5695502352835312,
      "grad_norm": 0.9579423666000366,
      "learning_rate": 0.00028467605335591787,
      "loss": 1.2934,
      "step": 53800
    },
    {
      "epoch": 0.5700795570635345,
      "grad_norm": 0.9787367582321167,
      "learning_rate": 0.00028494071564683467,
      "loss": 1.2743,
      "step": 53850
    },
    {
      "epoch": 0.5706088788435377,
      "grad_norm": 0.9670658111572266,
      "learning_rate": 0.0002852053779377514,
      "loss": 1.2809,
      "step": 53900
    },
    {
      "epoch": 0.571138200623541,
      "grad_norm": 1.039251685142517,
      "learning_rate": 0.00028547004022866823,
      "loss": 1.2644,
      "step": 53950
    },
    {
      "epoch": 0.5716675224035443,
      "grad_norm": 0.8838510513305664,
      "learning_rate": 0.000285734702519585,
      "loss": 1.3025,
      "step": 54000
    },
    {
      "epoch": 0.5716675224035443,
      "eval_loss": 1.2524367570877075,
      "eval_runtime": 46.8111,
      "eval_samples_per_second": 3587.395,
      "eval_steps_per_second": 448.44,
      "step": 54000
    },
    {
      "epoch": 0.5721968441835477,
      "grad_norm": 0.9788823127746582,
      "learning_rate": 0.0002859993648105018,
      "loss": 1.2765,
      "step": 54050
    },
    {
      "epoch": 0.5727261659635509,
      "grad_norm": 1.008402705192566,
      "learning_rate": 0.0002862640271014186,
      "loss": 1.3016,
      "step": 54100
    },
    {
      "epoch": 0.5732554877435542,
      "grad_norm": 0.9441934823989868,
      "learning_rate": 0.0002865286893923354,
      "loss": 1.2739,
      "step": 54150
    },
    {
      "epoch": 0.5737848095235575,
      "grad_norm": 1.0757362842559814,
      "learning_rate": 0.00028679335168325216,
      "loss": 1.2741,
      "step": 54200
    },
    {
      "epoch": 0.5743141313035608,
      "grad_norm": 1.057265043258667,
      "learning_rate": 0.00028705801397416896,
      "loss": 1.2754,
      "step": 54250
    },
    {
      "epoch": 0.574843453083564,
      "grad_norm": 0.8997939825057983,
      "learning_rate": 0.0002873226762650857,
      "loss": 1.2939,
      "step": 54300
    },
    {
      "epoch": 0.5753727748635673,
      "grad_norm": 1.169475793838501,
      "learning_rate": 0.0002875873385560026,
      "loss": 1.2721,
      "step": 54350
    },
    {
      "epoch": 0.5759020966435706,
      "grad_norm": 1.0624021291732788,
      "learning_rate": 0.00028785200084691933,
      "loss": 1.2945,
      "step": 54400
    },
    {
      "epoch": 0.5764314184235739,
      "grad_norm": 1.0096728801727295,
      "learning_rate": 0.00028811666313783614,
      "loss": 1.2984,
      "step": 54450
    },
    {
      "epoch": 0.5769607402035771,
      "grad_norm": 1.0591466426849365,
      "learning_rate": 0.0002883813254287529,
      "loss": 1.2879,
      "step": 54500
    },
    {
      "epoch": 0.5769607402035771,
      "eval_loss": 1.2490113973617554,
      "eval_runtime": 46.6707,
      "eval_samples_per_second": 3598.187,
      "eval_steps_per_second": 449.789,
      "step": 54500
    },
    {
      "epoch": 0.5774900619835804,
      "grad_norm": 0.8841232657432556,
      "learning_rate": 0.0002886459877196697,
      "loss": 1.2795,
      "step": 54550
    },
    {
      "epoch": 0.5780193837635837,
      "grad_norm": 1.0829205513000488,
      "learning_rate": 0.00028891065001058645,
      "loss": 1.2588,
      "step": 54600
    },
    {
      "epoch": 0.578548705543587,
      "grad_norm": 1.0621072053909302,
      "learning_rate": 0.0002891753123015033,
      "loss": 1.2902,
      "step": 54650
    },
    {
      "epoch": 0.5790780273235903,
      "grad_norm": 1.0101892948150635,
      "learning_rate": 0.00028943997459242006,
      "loss": 1.2983,
      "step": 54700
    },
    {
      "epoch": 0.5796073491035936,
      "grad_norm": 1.052712082862854,
      "learning_rate": 0.00028970463688333687,
      "loss": 1.2822,
      "step": 54750
    },
    {
      "epoch": 0.5801366708835969,
      "grad_norm": 0.9804359674453735,
      "learning_rate": 0.0002899692991742536,
      "loss": 1.2793,
      "step": 54800
    },
    {
      "epoch": 0.5806659926636001,
      "grad_norm": 1.0199276208877563,
      "learning_rate": 0.00029023396146517043,
      "loss": 1.2749,
      "step": 54850
    },
    {
      "epoch": 0.5811953144436034,
      "grad_norm": 1.0565211772918701,
      "learning_rate": 0.0002904986237560873,
      "loss": 1.293,
      "step": 54900
    },
    {
      "epoch": 0.5817246362236067,
      "grad_norm": 1.0328640937805176,
      "learning_rate": 0.00029076328604700404,
      "loss": 1.3012,
      "step": 54950
    },
    {
      "epoch": 0.58225395800361,
      "grad_norm": 1.1737523078918457,
      "learning_rate": 0.00029102794833792085,
      "loss": 1.2786,
      "step": 55000
    },
    {
      "epoch": 0.58225395800361,
      "eval_loss": 1.2436842918395996,
      "eval_runtime": 46.7281,
      "eval_samples_per_second": 3593.766,
      "eval_steps_per_second": 449.237,
      "step": 55000
    },
    {
      "epoch": 0.5827832797836132,
      "grad_norm": 1.0257986783981323,
      "learning_rate": 0.0002912926106288376,
      "loss": 1.2722,
      "step": 55050
    },
    {
      "epoch": 0.5833126015636165,
      "grad_norm": 0.9880107641220093,
      "learning_rate": 0.0002915572729197544,
      "loss": 1.2871,
      "step": 55100
    },
    {
      "epoch": 0.5838419233436198,
      "grad_norm": 1.0325802564620972,
      "learning_rate": 0.00029182193521067116,
      "loss": 1.2963,
      "step": 55150
    },
    {
      "epoch": 0.5843712451236232,
      "grad_norm": 0.9531276822090149,
      "learning_rate": 0.000292086597501588,
      "loss": 1.2834,
      "step": 55200
    },
    {
      "epoch": 0.5849005669036264,
      "grad_norm": 1.0895205736160278,
      "learning_rate": 0.0002923512597925048,
      "loss": 1.2915,
      "step": 55250
    },
    {
      "epoch": 0.5854298886836297,
      "grad_norm": 1.0340917110443115,
      "learning_rate": 0.0002926159220834216,
      "loss": 1.2897,
      "step": 55300
    },
    {
      "epoch": 0.585959210463633,
      "grad_norm": 1.0290857553482056,
      "learning_rate": 0.00029288058437433834,
      "loss": 1.2885,
      "step": 55350
    },
    {
      "epoch": 0.5864885322436362,
      "grad_norm": 1.0433932542800903,
      "learning_rate": 0.00029314524666525514,
      "loss": 1.2752,
      "step": 55400
    },
    {
      "epoch": 0.5870178540236395,
      "grad_norm": 1.0831166505813599,
      "learning_rate": 0.00029340990895617195,
      "loss": 1.2974,
      "step": 55450
    },
    {
      "epoch": 0.5875471758036428,
      "grad_norm": 0.9405544996261597,
      "learning_rate": 0.00029367457124708876,
      "loss": 1.2847,
      "step": 55500
    },
    {
      "epoch": 0.5875471758036428,
      "eval_loss": 1.2407360076904297,
      "eval_runtime": 46.7858,
      "eval_samples_per_second": 3589.336,
      "eval_steps_per_second": 448.683,
      "step": 55500
    },
    {
      "epoch": 0.5880764975836461,
      "grad_norm": 1.0012415647506714,
      "learning_rate": 0.0002939392335380055,
      "loss": 1.2811,
      "step": 55550
    },
    {
      "epoch": 0.5886058193636493,
      "grad_norm": 1.0098414421081543,
      "learning_rate": 0.000294198602583104,
      "loss": 1.2695,
      "step": 55600
    },
    {
      "epoch": 0.5891351411436526,
      "grad_norm": 1.037259578704834,
      "learning_rate": 0.00029446326487402074,
      "loss": 1.2521,
      "step": 55650
    },
    {
      "epoch": 0.5896644629236559,
      "grad_norm": 1.0640277862548828,
      "learning_rate": 0.00029472792716493754,
      "loss": 1.2774,
      "step": 55700
    },
    {
      "epoch": 0.5901937847036592,
      "grad_norm": 1.009394645690918,
      "learning_rate": 0.00029499258945585435,
      "loss": 1.2861,
      "step": 55750
    },
    {
      "epoch": 0.5907231064836624,
      "grad_norm": 1.0037940740585327,
      "learning_rate": 0.00029525725174677116,
      "loss": 1.272,
      "step": 55800
    },
    {
      "epoch": 0.5912524282636658,
      "grad_norm": 0.9873290657997131,
      "learning_rate": 0.0002955219140376879,
      "loss": 1.2666,
      "step": 55850
    },
    {
      "epoch": 0.5917817500436691,
      "grad_norm": 0.9637012481689453,
      "learning_rate": 0.0002957865763286047,
      "loss": 1.2782,
      "step": 55900
    },
    {
      "epoch": 0.5923110718236724,
      "grad_norm": 1.010892629623413,
      "learning_rate": 0.00029605123861952147,
      "loss": 1.2786,
      "step": 55950
    },
    {
      "epoch": 0.5928403936036756,
      "grad_norm": 1.0976210832595825,
      "learning_rate": 0.00029631590091043833,
      "loss": 1.2642,
      "step": 56000
    },
    {
      "epoch": 0.5928403936036756,
      "eval_loss": 1.2352641820907593,
      "eval_runtime": 46.8064,
      "eval_samples_per_second": 3587.756,
      "eval_steps_per_second": 448.485,
      "step": 56000
    },
    {
      "epoch": 0.5933697153836789,
      "grad_norm": 0.9459072351455688,
      "learning_rate": 0.0002965805632013551,
      "loss": 1.2694,
      "step": 56050
    },
    {
      "epoch": 0.5938990371636822,
      "grad_norm": 1.0275335311889648,
      "learning_rate": 0.0002968452254922719,
      "loss": 1.2861,
      "step": 56100
    },
    {
      "epoch": 0.5944283589436855,
      "grad_norm": 1.0232244729995728,
      "learning_rate": 0.00029710988778318864,
      "loss": 1.3016,
      "step": 56150
    },
    {
      "epoch": 0.5949576807236887,
      "grad_norm": 1.0004093647003174,
      "learning_rate": 0.00029737455007410545,
      "loss": 1.238,
      "step": 56200
    },
    {
      "epoch": 0.595487002503692,
      "grad_norm": 1.1253478527069092,
      "learning_rate": 0.0002976392123650222,
      "loss": 1.2583,
      "step": 56250
    },
    {
      "epoch": 0.5960163242836953,
      "grad_norm": 1.0098719596862793,
      "learning_rate": 0.00029790387465593906,
      "loss": 1.2745,
      "step": 56300
    },
    {
      "epoch": 0.5965456460636985,
      "grad_norm": 0.999376654624939,
      "learning_rate": 0.0002981685369468558,
      "loss": 1.2585,
      "step": 56350
    },
    {
      "epoch": 0.5970749678437018,
      "grad_norm": 1.1074011325836182,
      "learning_rate": 0.0002984331992377726,
      "loss": 1.2558,
      "step": 56400
    },
    {
      "epoch": 0.5976042896237052,
      "grad_norm": 0.9683098793029785,
      "learning_rate": 0.0002986978615286894,
      "loss": 1.288,
      "step": 56450
    },
    {
      "epoch": 0.5981336114037085,
      "grad_norm": 1.0830589532852173,
      "learning_rate": 0.0002989625238196062,
      "loss": 1.2598,
      "step": 56500
    },
    {
      "epoch": 0.5981336114037085,
      "eval_loss": 1.2315523624420166,
      "eval_runtime": 46.8793,
      "eval_samples_per_second": 3582.178,
      "eval_steps_per_second": 447.788,
      "step": 56500
    },
    {
      "epoch": 0.5986629331837117,
      "grad_norm": 1.0875067710876465,
      "learning_rate": 0.000299227186110523,
      "loss": 1.2561,
      "step": 56550
    },
    {
      "epoch": 0.599192254963715,
      "grad_norm": 1.014801025390625,
      "learning_rate": 0.0002994918484014398,
      "loss": 1.2683,
      "step": 56600
    },
    {
      "epoch": 0.5997215767437183,
      "grad_norm": 1.1074340343475342,
      "learning_rate": 0.00029975651069235655,
      "loss": 1.2832,
      "step": 56650
    },
    {
      "epoch": 0.6002508985237216,
      "grad_norm": 1.0428794622421265,
      "learning_rate": 0.00030002117298327336,
      "loss": 1.2915,
      "step": 56700
    },
    {
      "epoch": 0.6007802203037248,
      "grad_norm": 1.052965760231018,
      "learning_rate": 0.0003002858352741901,
      "loss": 1.256,
      "step": 56750
    },
    {
      "epoch": 0.6013095420837281,
      "grad_norm": 1.0669387578964233,
      "learning_rate": 0.0003005504975651069,
      "loss": 1.266,
      "step": 56800
    },
    {
      "epoch": 0.6018388638637314,
      "grad_norm": 1.050924301147461,
      "learning_rate": 0.0003008151598560237,
      "loss": 1.2779,
      "step": 56850
    },
    {
      "epoch": 0.6023681856437347,
      "grad_norm": 1.1113282442092896,
      "learning_rate": 0.00030107982214694053,
      "loss": 1.2739,
      "step": 56900
    },
    {
      "epoch": 0.6028975074237379,
      "grad_norm": 1.0200817584991455,
      "learning_rate": 0.0003013444844378573,
      "loss": 1.2649,
      "step": 56950
    },
    {
      "epoch": 0.6034268292037412,
      "grad_norm": 1.1168231964111328,
      "learning_rate": 0.0003016091467287741,
      "loss": 1.2624,
      "step": 57000
    },
    {
      "epoch": 0.6034268292037412,
      "eval_loss": 1.2292068004608154,
      "eval_runtime": 46.7302,
      "eval_samples_per_second": 3593.606,
      "eval_steps_per_second": 449.217,
      "step": 57000
    },
    {
      "epoch": 0.6039561509837446,
      "grad_norm": 1.0980077981948853,
      "learning_rate": 0.00030187380901969084,
      "loss": 1.2638,
      "step": 57050
    },
    {
      "epoch": 0.6044854727637478,
      "grad_norm": 1.0284234285354614,
      "learning_rate": 0.0003021384713106077,
      "loss": 1.2704,
      "step": 57100
    },
    {
      "epoch": 0.6050147945437511,
      "grad_norm": 1.009322166442871,
      "learning_rate": 0.00030240313360152445,
      "loss": 1.2702,
      "step": 57150
    },
    {
      "epoch": 0.6055441163237544,
      "grad_norm": 1.0237438678741455,
      "learning_rate": 0.00030266779589244126,
      "loss": 1.2668,
      "step": 57200
    },
    {
      "epoch": 0.6060734381037577,
      "grad_norm": 0.9546453952789307,
      "learning_rate": 0.000302932458183358,
      "loss": 1.2796,
      "step": 57250
    },
    {
      "epoch": 0.6066027598837609,
      "grad_norm": 1.0003502368927002,
      "learning_rate": 0.0003031971204742748,
      "loss": 1.2659,
      "step": 57300
    },
    {
      "epoch": 0.6071320816637642,
      "grad_norm": 1.0211777687072754,
      "learning_rate": 0.0003034617827651916,
      "loss": 1.2822,
      "step": 57350
    },
    {
      "epoch": 0.6076614034437675,
      "grad_norm": 1.040160894393921,
      "learning_rate": 0.00030372644505610843,
      "loss": 1.2677,
      "step": 57400
    },
    {
      "epoch": 0.6081907252237708,
      "grad_norm": 1.0093456506729126,
      "learning_rate": 0.0003039911073470252,
      "loss": 1.2704,
      "step": 57450
    },
    {
      "epoch": 0.608720047003774,
      "grad_norm": 1.0772913694381714,
      "learning_rate": 0.000304255769637942,
      "loss": 1.2535,
      "step": 57500
    },
    {
      "epoch": 0.608720047003774,
      "eval_loss": 1.2298862934112549,
      "eval_runtime": 46.7411,
      "eval_samples_per_second": 3592.766,
      "eval_steps_per_second": 449.112,
      "step": 57500
    },
    {
      "epoch": 0.6092493687837773,
      "grad_norm": 0.9578158855438232,
      "learning_rate": 0.0003045204319288588,
      "loss": 1.2779,
      "step": 57550
    },
    {
      "epoch": 0.6097786905637806,
      "grad_norm": 1.16240656375885,
      "learning_rate": 0.0003047798009739572,
      "loss": 1.2714,
      "step": 57600
    },
    {
      "epoch": 0.610308012343784,
      "grad_norm": 1.0722150802612305,
      "learning_rate": 0.00030504446326487403,
      "loss": 1.2725,
      "step": 57650
    },
    {
      "epoch": 0.6108373341237872,
      "grad_norm": 0.951624870300293,
      "learning_rate": 0.00030530912555579084,
      "loss": 1.2603,
      "step": 57700
    },
    {
      "epoch": 0.6113666559037905,
      "grad_norm": 0.9782586097717285,
      "learning_rate": 0.0003055737878467076,
      "loss": 1.2571,
      "step": 57750
    },
    {
      "epoch": 0.6118959776837938,
      "grad_norm": 1.0274080038070679,
      "learning_rate": 0.0003058384501376244,
      "loss": 1.2569,
      "step": 57800
    },
    {
      "epoch": 0.6124252994637971,
      "grad_norm": 0.9775658845901489,
      "learning_rate": 0.00030610311242854115,
      "loss": 1.2509,
      "step": 57850
    },
    {
      "epoch": 0.6129546212438003,
      "grad_norm": 0.9753893613815308,
      "learning_rate": 0.000306367774719458,
      "loss": 1.2638,
      "step": 57900
    },
    {
      "epoch": 0.6134839430238036,
      "grad_norm": 1.0071749687194824,
      "learning_rate": 0.00030663243701037476,
      "loss": 1.2601,
      "step": 57950
    },
    {
      "epoch": 0.6140132648038069,
      "grad_norm": 0.9359657168388367,
      "learning_rate": 0.00030689709930129157,
      "loss": 1.2641,
      "step": 58000
    },
    {
      "epoch": 0.6140132648038069,
      "eval_loss": 1.2227939367294312,
      "eval_runtime": 46.8045,
      "eval_samples_per_second": 3587.904,
      "eval_steps_per_second": 448.504,
      "step": 58000
    },
    {
      "epoch": 0.6145425865838101,
      "grad_norm": 1.0756762027740479,
      "learning_rate": 0.0003071617615922083,
      "loss": 1.2515,
      "step": 58050
    },
    {
      "epoch": 0.6150719083638134,
      "grad_norm": 1.0114095211029053,
      "learning_rate": 0.00030742642388312513,
      "loss": 1.2519,
      "step": 58100
    },
    {
      "epoch": 0.6156012301438167,
      "grad_norm": 0.9999772310256958,
      "learning_rate": 0.00030769108617404193,
      "loss": 1.2699,
      "step": 58150
    },
    {
      "epoch": 0.61613055192382,
      "grad_norm": 0.916481614112854,
      "learning_rate": 0.00030795574846495874,
      "loss": 1.2575,
      "step": 58200
    },
    {
      "epoch": 0.6166598737038232,
      "grad_norm": 0.9325781464576721,
      "learning_rate": 0.00030822041075587555,
      "loss": 1.2614,
      "step": 58250
    },
    {
      "epoch": 0.6171891954838266,
      "grad_norm": 1.0331664085388184,
      "learning_rate": 0.0003084850730467923,
      "loss": 1.2692,
      "step": 58300
    },
    {
      "epoch": 0.6177185172638299,
      "grad_norm": 0.9925732016563416,
      "learning_rate": 0.0003087497353377091,
      "loss": 1.2602,
      "step": 58350
    },
    {
      "epoch": 0.6182478390438332,
      "grad_norm": 0.9534504413604736,
      "learning_rate": 0.00030900910438280753,
      "loss": 1.266,
      "step": 58400
    },
    {
      "epoch": 0.6187771608238364,
      "grad_norm": 1.0226662158966064,
      "learning_rate": 0.00030927376667372433,
      "loss": 1.2614,
      "step": 58450
    },
    {
      "epoch": 0.6193064826038397,
      "grad_norm": 1.1123958826065063,
      "learning_rate": 0.00030953842896464114,
      "loss": 1.2757,
      "step": 58500
    },
    {
      "epoch": 0.6193064826038397,
      "eval_loss": 1.2168941497802734,
      "eval_runtime": 46.7401,
      "eval_samples_per_second": 3592.85,
      "eval_steps_per_second": 449.122,
      "step": 58500
    },
    {
      "epoch": 0.619835804383843,
      "grad_norm": 0.9654085040092468,
      "learning_rate": 0.0003098030912555579,
      "loss": 1.2619,
      "step": 58550
    },
    {
      "epoch": 0.6203651261638463,
      "grad_norm": 1.005995750427246,
      "learning_rate": 0.0003100677535464747,
      "loss": 1.2487,
      "step": 58600
    },
    {
      "epoch": 0.6208944479438495,
      "grad_norm": 1.0047738552093506,
      "learning_rate": 0.00031033241583739145,
      "loss": 1.2759,
      "step": 58650
    },
    {
      "epoch": 0.6214237697238528,
      "grad_norm": 0.9501695036888123,
      "learning_rate": 0.00031059707812830826,
      "loss": 1.2703,
      "step": 58700
    },
    {
      "epoch": 0.6219530915038561,
      "grad_norm": 0.9537940621376038,
      "learning_rate": 0.00031086174041922507,
      "loss": 1.279,
      "step": 58750
    },
    {
      "epoch": 0.6224824132838593,
      "grad_norm": 1.020389437675476,
      "learning_rate": 0.0003111264027101419,
      "loss": 1.2577,
      "step": 58800
    },
    {
      "epoch": 0.6230117350638626,
      "grad_norm": 1.0473116636276245,
      "learning_rate": 0.0003113910650010587,
      "loss": 1.2702,
      "step": 58850
    },
    {
      "epoch": 0.623541056843866,
      "grad_norm": 0.976280927658081,
      "learning_rate": 0.00031165572729197543,
      "loss": 1.2631,
      "step": 58900
    },
    {
      "epoch": 0.6240703786238693,
      "grad_norm": 1.1179662942886353,
      "learning_rate": 0.00031192038958289224,
      "loss": 1.2588,
      "step": 58950
    },
    {
      "epoch": 0.6245997004038725,
      "grad_norm": 1.0614635944366455,
      "learning_rate": 0.00031218505187380905,
      "loss": 1.2762,
      "step": 59000
    },
    {
      "epoch": 0.6245997004038725,
      "eval_loss": 1.2151391506195068,
      "eval_runtime": 46.7972,
      "eval_samples_per_second": 3588.46,
      "eval_steps_per_second": 448.574,
      "step": 59000
    },
    {
      "epoch": 0.6251290221838758,
      "grad_norm": 1.0555959939956665,
      "learning_rate": 0.00031244971416472585,
      "loss": 1.252,
      "step": 59050
    },
    {
      "epoch": 0.6256583439638791,
      "grad_norm": 1.0577412843704224,
      "learning_rate": 0.0003127143764556426,
      "loss": 1.2746,
      "step": 59100
    },
    {
      "epoch": 0.6261876657438824,
      "grad_norm": 1.0790027379989624,
      "learning_rate": 0.0003129790387465594,
      "loss": 1.2569,
      "step": 59150
    },
    {
      "epoch": 0.6267169875238856,
      "grad_norm": 1.0899349451065063,
      "learning_rate": 0.00031324370103747617,
      "loss": 1.2524,
      "step": 59200
    },
    {
      "epoch": 0.6272463093038889,
      "grad_norm": 0.9449329376220703,
      "learning_rate": 0.000313508363328393,
      "loss": 1.2503,
      "step": 59250
    },
    {
      "epoch": 0.6277756310838922,
      "grad_norm": 0.9956844449043274,
      "learning_rate": 0.0003137730256193098,
      "loss": 1.2417,
      "step": 59300
    },
    {
      "epoch": 0.6283049528638955,
      "grad_norm": 0.9379155039787292,
      "learning_rate": 0.0003140376879102266,
      "loss": 1.2332,
      "step": 59350
    },
    {
      "epoch": 0.6288342746438987,
      "grad_norm": 1.049944519996643,
      "learning_rate": 0.00031430235020114334,
      "loss": 1.2634,
      "step": 59400
    },
    {
      "epoch": 0.629363596423902,
      "grad_norm": 1.0451802015304565,
      "learning_rate": 0.00031456701249206015,
      "loss": 1.2363,
      "step": 59450
    },
    {
      "epoch": 0.6298929182039054,
      "grad_norm": 1.0203107595443726,
      "learning_rate": 0.0003148316747829769,
      "loss": 1.2424,
      "step": 59500
    },
    {
      "epoch": 0.6298929182039054,
      "eval_loss": 1.2094593048095703,
      "eval_runtime": 46.7283,
      "eval_samples_per_second": 3593.751,
      "eval_steps_per_second": 449.235,
      "step": 59500
    },
    {
      "epoch": 0.6304222399839087,
      "grad_norm": 0.9694146513938904,
      "learning_rate": 0.00031509633707389376,
      "loss": 1.2596,
      "step": 59550
    },
    {
      "epoch": 0.6309515617639119,
      "grad_norm": 0.9693857431411743,
      "learning_rate": 0.0003153609993648105,
      "loss": 1.2467,
      "step": 59600
    },
    {
      "epoch": 0.6314808835439152,
      "grad_norm": 1.1081693172454834,
      "learning_rate": 0.0003156256616557273,
      "loss": 1.2571,
      "step": 59650
    },
    {
      "epoch": 0.6320102053239185,
      "grad_norm": 0.9559197425842285,
      "learning_rate": 0.00031589032394664407,
      "loss": 1.2646,
      "step": 59700
    },
    {
      "epoch": 0.6325395271039217,
      "grad_norm": 1.0641735792160034,
      "learning_rate": 0.0003161549862375609,
      "loss": 1.2667,
      "step": 59750
    },
    {
      "epoch": 0.633068848883925,
      "grad_norm": 1.070419430732727,
      "learning_rate": 0.00031641964852847763,
      "loss": 1.2566,
      "step": 59800
    },
    {
      "epoch": 0.6335981706639283,
      "grad_norm": 1.0448150634765625,
      "learning_rate": 0.0003166843108193945,
      "loss": 1.2516,
      "step": 59850
    },
    {
      "epoch": 0.6341274924439316,
      "grad_norm": 0.9728895425796509,
      "learning_rate": 0.00031694897311031125,
      "loss": 1.2445,
      "step": 59900
    },
    {
      "epoch": 0.6346568142239348,
      "grad_norm": 0.9603291749954224,
      "learning_rate": 0.00031721363540122805,
      "loss": 1.28,
      "step": 59950
    },
    {
      "epoch": 0.6351861360039381,
      "grad_norm": 1.0799951553344727,
      "learning_rate": 0.0003174782976921448,
      "loss": 1.2509,
      "step": 60000
    },
    {
      "epoch": 0.6351861360039381,
      "eval_loss": 1.2060703039169312,
      "eval_runtime": 46.804,
      "eval_samples_per_second": 3587.94,
      "eval_steps_per_second": 448.509,
      "step": 60000
    },
    {
      "epoch": 0.6357154577839415,
      "grad_norm": 0.9682593941688538,
      "learning_rate": 0.0003177429599830616,
      "loss": 1.2507,
      "step": 60050
    },
    {
      "epoch": 0.6362447795639448,
      "grad_norm": 0.9930353760719299,
      "learning_rate": 0.0003180076222739784,
      "loss": 1.2446,
      "step": 60100
    },
    {
      "epoch": 0.636774101343948,
      "grad_norm": 1.0465415716171265,
      "learning_rate": 0.0003182722845648952,
      "loss": 1.2499,
      "step": 60150
    },
    {
      "epoch": 0.6373034231239513,
      "grad_norm": 1.0073986053466797,
      "learning_rate": 0.000318536946855812,
      "loss": 1.2564,
      "step": 60200
    },
    {
      "epoch": 0.6378327449039546,
      "grad_norm": 0.9853379130363464,
      "learning_rate": 0.0003188016091467288,
      "loss": 1.2503,
      "step": 60250
    },
    {
      "epoch": 0.6383620666839579,
      "grad_norm": 1.1099191904067993,
      "learning_rate": 0.00031906627143764554,
      "loss": 1.2305,
      "step": 60300
    },
    {
      "epoch": 0.6388913884639611,
      "grad_norm": 1.0693193674087524,
      "learning_rate": 0.00031933093372856234,
      "loss": 1.2555,
      "step": 60350
    },
    {
      "epoch": 0.6394207102439644,
      "grad_norm": 1.0118364095687866,
      "learning_rate": 0.00031959559601947915,
      "loss": 1.2501,
      "step": 60400
    },
    {
      "epoch": 0.6399500320239677,
      "grad_norm": 0.9487820863723755,
      "learning_rate": 0.00031986025831039596,
      "loss": 1.2517,
      "step": 60450
    },
    {
      "epoch": 0.6404793538039709,
      "grad_norm": 0.9553707242012024,
      "learning_rate": 0.0003201249206013127,
      "loss": 1.2354,
      "step": 60500
    },
    {
      "epoch": 0.6404793538039709,
      "eval_loss": 1.2039717435836792,
      "eval_runtime": 46.7215,
      "eval_samples_per_second": 3594.28,
      "eval_steps_per_second": 449.301,
      "step": 60500
    },
    {
      "epoch": 0.6410086755839742,
      "grad_norm": 0.9748067259788513,
      "learning_rate": 0.0003203895828922295,
      "loss": 1.2608,
      "step": 60550
    },
    {
      "epoch": 0.6415379973639775,
      "grad_norm": 0.998817503452301,
      "learning_rate": 0.00032065424518314627,
      "loss": 1.2469,
      "step": 60600
    },
    {
      "epoch": 0.6420673191439809,
      "grad_norm": 1.029799461364746,
      "learning_rate": 0.0003209189074740631,
      "loss": 1.2493,
      "step": 60650
    },
    {
      "epoch": 0.642596640923984,
      "grad_norm": 1.0030453205108643,
      "learning_rate": 0.0003211835697649799,
      "loss": 1.2444,
      "step": 60700
    },
    {
      "epoch": 0.6431259627039874,
      "grad_norm": 0.8938592672348022,
      "learning_rate": 0.0003214482320558967,
      "loss": 1.2439,
      "step": 60750
    },
    {
      "epoch": 0.6436552844839907,
      "grad_norm": 0.9810761213302612,
      "learning_rate": 0.00032171289434681344,
      "loss": 1.2566,
      "step": 60800
    },
    {
      "epoch": 0.644184606263994,
      "grad_norm": 1.0691932439804077,
      "learning_rate": 0.00032197755663773025,
      "loss": 1.2301,
      "step": 60850
    },
    {
      "epoch": 0.6447139280439972,
      "grad_norm": 1.0456151962280273,
      "learning_rate": 0.00032224221892864706,
      "loss": 1.225,
      "step": 60900
    },
    {
      "epoch": 0.6452432498240005,
      "grad_norm": 1.0776634216308594,
      "learning_rate": 0.00032250688121956386,
      "loss": 1.235,
      "step": 60950
    },
    {
      "epoch": 0.6457725716040038,
      "grad_norm": 1.0768378973007202,
      "learning_rate": 0.00032277154351048067,
      "loss": 1.238,
      "step": 61000
    },
    {
      "epoch": 0.6457725716040038,
      "eval_loss": 1.1976925134658813,
      "eval_runtime": 46.7589,
      "eval_samples_per_second": 3591.405,
      "eval_steps_per_second": 448.942,
      "step": 61000
    },
    {
      "epoch": 0.6463018933840071,
      "grad_norm": 0.9361666440963745,
      "learning_rate": 0.0003230362058013974,
      "loss": 1.2443,
      "step": 61050
    },
    {
      "epoch": 0.6468312151640103,
      "grad_norm": 0.9847081303596497,
      "learning_rate": 0.00032330086809231423,
      "loss": 1.219,
      "step": 61100
    },
    {
      "epoch": 0.6473605369440136,
      "grad_norm": 0.9483428001403809,
      "learning_rate": 0.000323565530383231,
      "loss": 1.2534,
      "step": 61150
    },
    {
      "epoch": 0.6478898587240169,
      "grad_norm": 1.1146750450134277,
      "learning_rate": 0.0003238301926741478,
      "loss": 1.2347,
      "step": 61200
    },
    {
      "epoch": 0.6484191805040203,
      "grad_norm": 1.1257046461105347,
      "learning_rate": 0.0003240948549650646,
      "loss": 1.2328,
      "step": 61250
    },
    {
      "epoch": 0.6489485022840235,
      "grad_norm": 1.1914103031158447,
      "learning_rate": 0.0003243595172559814,
      "loss": 1.2511,
      "step": 61300
    },
    {
      "epoch": 0.6494778240640268,
      "grad_norm": 1.0385633707046509,
      "learning_rate": 0.00032462417954689816,
      "loss": 1.2512,
      "step": 61350
    },
    {
      "epoch": 0.6500071458440301,
      "grad_norm": 1.0372761487960815,
      "learning_rate": 0.00032488884183781496,
      "loss": 1.2493,
      "step": 61400
    },
    {
      "epoch": 0.6505364676240333,
      "grad_norm": 0.9942750930786133,
      "learning_rate": 0.0003251535041287317,
      "loss": 1.2581,
      "step": 61450
    },
    {
      "epoch": 0.6510657894040366,
      "grad_norm": 0.9802799224853516,
      "learning_rate": 0.0003254181664196486,
      "loss": 1.2551,
      "step": 61500
    },
    {
      "epoch": 0.6510657894040366,
      "eval_loss": 1.1928462982177734,
      "eval_runtime": 46.7721,
      "eval_samples_per_second": 3590.391,
      "eval_steps_per_second": 448.815,
      "step": 61500
    },
    {
      "epoch": 0.6515951111840399,
      "grad_norm": 0.969706654548645,
      "learning_rate": 0.00032568282871056533,
      "loss": 1.2469,
      "step": 61550
    },
    {
      "epoch": 0.6521244329640432,
      "grad_norm": 0.9736951589584351,
      "learning_rate": 0.00032594749100148214,
      "loss": 1.2369,
      "step": 61600
    },
    {
      "epoch": 0.6526537547440464,
      "grad_norm": 1.015636682510376,
      "learning_rate": 0.0003262121532923989,
      "loss": 1.2365,
      "step": 61650
    },
    {
      "epoch": 0.6531830765240497,
      "grad_norm": 1.0395160913467407,
      "learning_rate": 0.0003264768155833157,
      "loss": 1.2435,
      "step": 61700
    },
    {
      "epoch": 0.653712398304053,
      "grad_norm": 1.0038788318634033,
      "learning_rate": 0.00032674147787423245,
      "loss": 1.2381,
      "step": 61750
    },
    {
      "epoch": 0.6542417200840563,
      "grad_norm": 1.0217279195785522,
      "learning_rate": 0.0003270061401651493,
      "loss": 1.2345,
      "step": 61800
    },
    {
      "epoch": 0.6547710418640595,
      "grad_norm": 1.0772411823272705,
      "learning_rate": 0.00032727080245606606,
      "loss": 1.2312,
      "step": 61850
    },
    {
      "epoch": 0.6553003636440629,
      "grad_norm": 1.0248987674713135,
      "learning_rate": 0.00032753546474698287,
      "loss": 1.2574,
      "step": 61900
    },
    {
      "epoch": 0.6558296854240662,
      "grad_norm": 0.9841017127037048,
      "learning_rate": 0.0003278001270378996,
      "loss": 1.2436,
      "step": 61950
    },
    {
      "epoch": 0.6563590072040695,
      "grad_norm": 1.0501070022583008,
      "learning_rate": 0.00032806478932881643,
      "loss": 1.245,
      "step": 62000
    },
    {
      "epoch": 0.6563590072040695,
      "eval_loss": 1.192882776260376,
      "eval_runtime": 46.7811,
      "eval_samples_per_second": 3589.701,
      "eval_steps_per_second": 448.729,
      "step": 62000
    },
    {
      "epoch": 0.6568883289840727,
      "grad_norm": 0.9055423140525818,
      "learning_rate": 0.00032832945161973324,
      "loss": 1.2362,
      "step": 62050
    },
    {
      "epoch": 0.657417650764076,
      "grad_norm": 1.0497972965240479,
      "learning_rate": 0.00032859411391065004,
      "loss": 1.2183,
      "step": 62100
    },
    {
      "epoch": 0.6579469725440793,
      "grad_norm": 0.9560127258300781,
      "learning_rate": 0.0003288587762015668,
      "loss": 1.2373,
      "step": 62150
    },
    {
      "epoch": 0.6584762943240825,
      "grad_norm": 0.9899009466171265,
      "learning_rate": 0.0003291234384924836,
      "loss": 1.2355,
      "step": 62200
    },
    {
      "epoch": 0.6590056161040858,
      "grad_norm": 1.1128180027008057,
      "learning_rate": 0.00032938810078340035,
      "loss": 1.2132,
      "step": 62250
    },
    {
      "epoch": 0.6595349378840891,
      "grad_norm": 1.0252423286437988,
      "learning_rate": 0.00032965276307431716,
      "loss": 1.2483,
      "step": 62300
    },
    {
      "epoch": 0.6600642596640924,
      "grad_norm": 1.0335185527801514,
      "learning_rate": 0.00032991742536523397,
      "loss": 1.2496,
      "step": 62350
    },
    {
      "epoch": 0.6605935814440956,
      "grad_norm": 0.9617182612419128,
      "learning_rate": 0.0003301820876561508,
      "loss": 1.2385,
      "step": 62400
    },
    {
      "epoch": 0.661122903224099,
      "grad_norm": 1.0593669414520264,
      "learning_rate": 0.0003304414567012492,
      "loss": 1.2191,
      "step": 62450
    },
    {
      "epoch": 0.6616522250041023,
      "grad_norm": 1.0537216663360596,
      "learning_rate": 0.000330706118992166,
      "loss": 1.2235,
      "step": 62500
    },
    {
      "epoch": 0.6616522250041023,
      "eval_loss": 1.1875905990600586,
      "eval_runtime": 46.7897,
      "eval_samples_per_second": 3589.036,
      "eval_steps_per_second": 448.646,
      "step": 62500
    },
    {
      "epoch": 0.6621815467841056,
      "grad_norm": 1.0297214984893799,
      "learning_rate": 0.00033097078128308276,
      "loss": 1.2153,
      "step": 62550
    },
    {
      "epoch": 0.6627108685641088,
      "grad_norm": 0.9515287280082703,
      "learning_rate": 0.0003312354435739996,
      "loss": 1.2428,
      "step": 62600
    },
    {
      "epoch": 0.6632401903441121,
      "grad_norm": 1.1208616495132446,
      "learning_rate": 0.00033150010586491637,
      "loss": 1.2217,
      "step": 62650
    },
    {
      "epoch": 0.6637695121241154,
      "grad_norm": 1.0546797513961792,
      "learning_rate": 0.0003317647681558332,
      "loss": 1.2515,
      "step": 62700
    },
    {
      "epoch": 0.6642988339041187,
      "grad_norm": 1.039968729019165,
      "learning_rate": 0.00033202943044674993,
      "loss": 1.2196,
      "step": 62750
    },
    {
      "epoch": 0.6648281556841219,
      "grad_norm": 0.9904885292053223,
      "learning_rate": 0.00033229409273766674,
      "loss": 1.2585,
      "step": 62800
    },
    {
      "epoch": 0.6653574774641252,
      "grad_norm": 1.0297300815582275,
      "learning_rate": 0.00033255875502858354,
      "loss": 1.2304,
      "step": 62850
    },
    {
      "epoch": 0.6658867992441285,
      "grad_norm": 0.9954892992973328,
      "learning_rate": 0.00033282341731950035,
      "loss": 1.237,
      "step": 62900
    },
    {
      "epoch": 0.6664161210241317,
      "grad_norm": 0.9555904865264893,
      "learning_rate": 0.0003330880796104171,
      "loss": 1.2238,
      "step": 62950
    },
    {
      "epoch": 0.666945442804135,
      "grad_norm": 1.0700771808624268,
      "learning_rate": 0.0003333527419013339,
      "loss": 1.2332,
      "step": 63000
    },
    {
      "epoch": 0.666945442804135,
      "eval_loss": 1.186293125152588,
      "eval_runtime": 46.7359,
      "eval_samples_per_second": 3593.168,
      "eval_steps_per_second": 449.162,
      "step": 63000
    },
    {
      "epoch": 0.6674747645841383,
      "grad_norm": 1.0000253915786743,
      "learning_rate": 0.00033361740419225066,
      "loss": 1.2202,
      "step": 63050
    },
    {
      "epoch": 0.6680040863641417,
      "grad_norm": 1.0215089321136475,
      "learning_rate": 0.00033388206648316747,
      "loss": 1.2401,
      "step": 63100
    },
    {
      "epoch": 0.6685334081441449,
      "grad_norm": 0.9585689902305603,
      "learning_rate": 0.0003341467287740843,
      "loss": 1.2343,
      "step": 63150
    },
    {
      "epoch": 0.6690627299241482,
      "grad_norm": 1.0284003019332886,
      "learning_rate": 0.0003344113910650011,
      "loss": 1.2298,
      "step": 63200
    },
    {
      "epoch": 0.6695920517041515,
      "grad_norm": 1.088866949081421,
      "learning_rate": 0.00033467605335591783,
      "loss": 1.2198,
      "step": 63250
    },
    {
      "epoch": 0.6701213734841548,
      "grad_norm": 1.0715724229812622,
      "learning_rate": 0.00033494071564683464,
      "loss": 1.2511,
      "step": 63300
    },
    {
      "epoch": 0.670650695264158,
      "grad_norm": 0.990380585193634,
      "learning_rate": 0.0003352053779377514,
      "loss": 1.2292,
      "step": 63350
    },
    {
      "epoch": 0.6711800170441613,
      "grad_norm": 1.0297346115112305,
      "learning_rate": 0.0003354700402286682,
      "loss": 1.2389,
      "step": 63400
    },
    {
      "epoch": 0.6717093388241646,
      "grad_norm": 1.0044581890106201,
      "learning_rate": 0.000335734702519585,
      "loss": 1.2199,
      "step": 63450
    },
    {
      "epoch": 0.6722386606041679,
      "grad_norm": 1.0607675313949585,
      "learning_rate": 0.0003359993648105018,
      "loss": 1.2212,
      "step": 63500
    },
    {
      "epoch": 0.6722386606041679,
      "eval_loss": 1.1796669960021973,
      "eval_runtime": 46.702,
      "eval_samples_per_second": 3595.774,
      "eval_steps_per_second": 449.488,
      "step": 63500
    },
    {
      "epoch": 0.6727679823841711,
      "grad_norm": 1.0286189317703247,
      "learning_rate": 0.0003362640271014186,
      "loss": 1.2632,
      "step": 63550
    },
    {
      "epoch": 0.6732973041641744,
      "grad_norm": 1.0490081310272217,
      "learning_rate": 0.0003365286893923354,
      "loss": 1.2267,
      "step": 63600
    },
    {
      "epoch": 0.6738266259441777,
      "grad_norm": 1.0503846406936646,
      "learning_rate": 0.0003367933516832522,
      "loss": 1.2286,
      "step": 63650
    },
    {
      "epoch": 0.6743559477241811,
      "grad_norm": 1.0191078186035156,
      "learning_rate": 0.000337058013974169,
      "loss": 1.2185,
      "step": 63700
    },
    {
      "epoch": 0.6748852695041843,
      "grad_norm": 0.9716078042984009,
      "learning_rate": 0.0003373226762650858,
      "loss": 1.2347,
      "step": 63750
    },
    {
      "epoch": 0.6754145912841876,
      "grad_norm": 0.997477114200592,
      "learning_rate": 0.00033758733855600255,
      "loss": 1.2318,
      "step": 63800
    },
    {
      "epoch": 0.6759439130641909,
      "grad_norm": 1.0196324586868286,
      "learning_rate": 0.00033785200084691935,
      "loss": 1.2422,
      "step": 63850
    },
    {
      "epoch": 0.6764732348441941,
      "grad_norm": 0.9257553219795227,
      "learning_rate": 0.0003381166631378361,
      "loss": 1.2205,
      "step": 63900
    },
    {
      "epoch": 0.6770025566241974,
      "grad_norm": 1.116511344909668,
      "learning_rate": 0.0003383813254287529,
      "loss": 1.2148,
      "step": 63950
    },
    {
      "epoch": 0.6775318784042007,
      "grad_norm": 1.063441276550293,
      "learning_rate": 0.0003386459877196697,
      "loss": 1.2359,
      "step": 64000
    },
    {
      "epoch": 0.6775318784042007,
      "eval_loss": 1.176932454109192,
      "eval_runtime": 46.671,
      "eval_samples_per_second": 3598.164,
      "eval_steps_per_second": 449.787,
      "step": 64000
    },
    {
      "epoch": 0.678061200184204,
      "grad_norm": 1.0470080375671387,
      "learning_rate": 0.0003389106500105865,
      "loss": 1.2379,
      "step": 64050
    },
    {
      "epoch": 0.6785905219642072,
      "grad_norm": 1.011560082435608,
      "learning_rate": 0.0003391753123015033,
      "loss": 1.2144,
      "step": 64100
    },
    {
      "epoch": 0.6791198437442105,
      "grad_norm": 1.01368248462677,
      "learning_rate": 0.0003394399745924201,
      "loss": 1.2165,
      "step": 64150
    },
    {
      "epoch": 0.6796491655242138,
      "grad_norm": 1.0306721925735474,
      "learning_rate": 0.00033970463688333684,
      "loss": 1.2332,
      "step": 64200
    },
    {
      "epoch": 0.6801784873042171,
      "grad_norm": 0.9648314118385315,
      "learning_rate": 0.0003399692991742537,
      "loss": 1.2411,
      "step": 64250
    },
    {
      "epoch": 0.6807078090842203,
      "grad_norm": 0.9897753596305847,
      "learning_rate": 0.00034023396146517045,
      "loss": 1.2264,
      "step": 64300
    },
    {
      "epoch": 0.6812371308642237,
      "grad_norm": 0.9923961758613586,
      "learning_rate": 0.00034049862375608726,
      "loss": 1.23,
      "step": 64350
    },
    {
      "epoch": 0.681766452644227,
      "grad_norm": 0.9056737422943115,
      "learning_rate": 0.000340763286047004,
      "loss": 1.2357,
      "step": 64400
    },
    {
      "epoch": 0.6822957744242303,
      "grad_norm": 0.960433304309845,
      "learning_rate": 0.0003410226550921025,
      "loss": 1.2323,
      "step": 64450
    },
    {
      "epoch": 0.6828250962042335,
      "grad_norm": 1.138606071472168,
      "learning_rate": 0.00034128202413720096,
      "loss": 1.2255,
      "step": 64500
    },
    {
      "epoch": 0.6828250962042335,
      "eval_loss": 1.175290584564209,
      "eval_runtime": 46.7036,
      "eval_samples_per_second": 3595.657,
      "eval_steps_per_second": 449.473,
      "step": 64500
    },
    {
      "epoch": 0.6833544179842368,
      "grad_norm": 1.0111069679260254,
      "learning_rate": 0.0003415466864281177,
      "loss": 1.2264,
      "step": 64550
    },
    {
      "epoch": 0.6838837397642401,
      "grad_norm": 1.032902479171753,
      "learning_rate": 0.0003418113487190345,
      "loss": 1.2327,
      "step": 64600
    },
    {
      "epoch": 0.6844130615442433,
      "grad_norm": 1.1594120264053345,
      "learning_rate": 0.0003420760110099513,
      "loss": 1.2349,
      "step": 64650
    },
    {
      "epoch": 0.6849423833242466,
      "grad_norm": 0.9758554697036743,
      "learning_rate": 0.0003423406733008681,
      "loss": 1.2342,
      "step": 64700
    },
    {
      "epoch": 0.6854717051042499,
      "grad_norm": 1.0141732692718506,
      "learning_rate": 0.00034260533559178494,
      "loss": 1.2242,
      "step": 64750
    },
    {
      "epoch": 0.6860010268842532,
      "grad_norm": 1.0924526453018188,
      "learning_rate": 0.0003428699978827017,
      "loss": 1.2313,
      "step": 64800
    },
    {
      "epoch": 0.6865303486642564,
      "grad_norm": 1.0450117588043213,
      "learning_rate": 0.0003431346601736185,
      "loss": 1.2053,
      "step": 64850
    },
    {
      "epoch": 0.6870596704442598,
      "grad_norm": 1.019623875617981,
      "learning_rate": 0.00034339932246453525,
      "loss": 1.2173,
      "step": 64900
    },
    {
      "epoch": 0.6875889922242631,
      "grad_norm": 1.0764477252960205,
      "learning_rate": 0.00034366398475545206,
      "loss": 1.2333,
      "step": 64950
    },
    {
      "epoch": 0.6881183140042664,
      "grad_norm": 1.0450870990753174,
      "learning_rate": 0.0003439286470463688,
      "loss": 1.2179,
      "step": 65000
    },
    {
      "epoch": 0.6881183140042664,
      "eval_loss": 1.1692637205123901,
      "eval_runtime": 46.6813,
      "eval_samples_per_second": 3597.375,
      "eval_steps_per_second": 449.688,
      "step": 65000
    },
    {
      "epoch": 0.6886476357842696,
      "grad_norm": 1.0757147073745728,
      "learning_rate": 0.0003441933093372857,
      "loss": 1.2185,
      "step": 65050
    },
    {
      "epoch": 0.6891769575642729,
      "grad_norm": 0.9414359331130981,
      "learning_rate": 0.00034445797162820243,
      "loss": 1.2137,
      "step": 65100
    },
    {
      "epoch": 0.6897062793442762,
      "grad_norm": 1.1090360879898071,
      "learning_rate": 0.00034472263391911923,
      "loss": 1.2262,
      "step": 65150
    },
    {
      "epoch": 0.6902356011242795,
      "grad_norm": 0.9947628378868103,
      "learning_rate": 0.000344987296210036,
      "loss": 1.2455,
      "step": 65200
    },
    {
      "epoch": 0.6907649229042827,
      "grad_norm": 1.0365878343582153,
      "learning_rate": 0.0003452519585009528,
      "loss": 1.2009,
      "step": 65250
    },
    {
      "epoch": 0.691294244684286,
      "grad_norm": 0.9579599499702454,
      "learning_rate": 0.0003455166207918696,
      "loss": 1.2024,
      "step": 65300
    },
    {
      "epoch": 0.6918235664642893,
      "grad_norm": 0.9716187119483948,
      "learning_rate": 0.0003457812830827864,
      "loss": 1.2154,
      "step": 65350
    },
    {
      "epoch": 0.6923528882442926,
      "grad_norm": 1.017247200012207,
      "learning_rate": 0.00034604594537370316,
      "loss": 1.2331,
      "step": 65400
    },
    {
      "epoch": 0.6928822100242958,
      "grad_norm": 0.9933050274848938,
      "learning_rate": 0.00034631060766461997,
      "loss": 1.2021,
      "step": 65450
    },
    {
      "epoch": 0.6934115318042992,
      "grad_norm": 1.0113942623138428,
      "learning_rate": 0.0003465752699555367,
      "loss": 1.2233,
      "step": 65500
    },
    {
      "epoch": 0.6934115318042992,
      "eval_loss": 1.167435884475708,
      "eval_runtime": 46.7351,
      "eval_samples_per_second": 3593.23,
      "eval_steps_per_second": 449.17,
      "step": 65500
    },
    {
      "epoch": 0.6939408535843025,
      "grad_norm": 0.9635971188545227,
      "learning_rate": 0.0003468399322464535,
      "loss": 1.2141,
      "step": 65550
    },
    {
      "epoch": 0.6944701753643057,
      "grad_norm": 0.9402442574501038,
      "learning_rate": 0.00034710459453737033,
      "loss": 1.2315,
      "step": 65600
    },
    {
      "epoch": 0.694999497144309,
      "grad_norm": 1.0033491849899292,
      "learning_rate": 0.00034736925682828714,
      "loss": 1.2294,
      "step": 65650
    },
    {
      "epoch": 0.6955288189243123,
      "grad_norm": 0.9706270694732666,
      "learning_rate": 0.0003476339191192039,
      "loss": 1.2158,
      "step": 65700
    },
    {
      "epoch": 0.6960581407043156,
      "grad_norm": 1.1448403596878052,
      "learning_rate": 0.0003478985814101207,
      "loss": 1.2245,
      "step": 65750
    },
    {
      "epoch": 0.6965874624843188,
      "grad_norm": 1.0268793106079102,
      "learning_rate": 0.00034816324370103745,
      "loss": 1.236,
      "step": 65800
    },
    {
      "epoch": 0.6971167842643221,
      "grad_norm": 1.0160611867904663,
      "learning_rate": 0.00034842790599195426,
      "loss": 1.2223,
      "step": 65850
    },
    {
      "epoch": 0.6976461060443254,
      "grad_norm": 0.9067732691764832,
      "learning_rate": 0.00034869256828287107,
      "loss": 1.2059,
      "step": 65900
    },
    {
      "epoch": 0.6981754278243287,
      "grad_norm": 1.0354584455490112,
      "learning_rate": 0.00034895723057378787,
      "loss": 1.2193,
      "step": 65950
    },
    {
      "epoch": 0.6987047496043319,
      "grad_norm": 1.0045220851898193,
      "learning_rate": 0.0003492218928647046,
      "loss": 1.2188,
      "step": 66000
    },
    {
      "epoch": 0.6987047496043319,
      "eval_loss": 1.1647647619247437,
      "eval_runtime": 46.7368,
      "eval_samples_per_second": 3593.104,
      "eval_steps_per_second": 449.154,
      "step": 66000
    },
    {
      "epoch": 0.6992340713843352,
      "grad_norm": 1.0169950723648071,
      "learning_rate": 0.00034948655515562143,
      "loss": 1.2152,
      "step": 66050
    },
    {
      "epoch": 0.6997633931643386,
      "grad_norm": 1.0724385976791382,
      "learning_rate": 0.0003497512174465382,
      "loss": 1.2096,
      "step": 66100
    },
    {
      "epoch": 0.7002927149443419,
      "grad_norm": 1.0046355724334717,
      "learning_rate": 0.00035001587973745505,
      "loss": 1.2155,
      "step": 66150
    },
    {
      "epoch": 0.7008220367243451,
      "grad_norm": 1.0312061309814453,
      "learning_rate": 0.0003502805420283718,
      "loss": 1.2164,
      "step": 66200
    },
    {
      "epoch": 0.7013513585043484,
      "grad_norm": 1.1111812591552734,
      "learning_rate": 0.0003505452043192886,
      "loss": 1.2031,
      "step": 66250
    },
    {
      "epoch": 0.7018806802843517,
      "grad_norm": 0.9832885265350342,
      "learning_rate": 0.00035080986661020536,
      "loss": 1.1973,
      "step": 66300
    },
    {
      "epoch": 0.7024100020643549,
      "grad_norm": 1.0416752099990845,
      "learning_rate": 0.00035107452890112217,
      "loss": 1.2177,
      "step": 66350
    },
    {
      "epoch": 0.7029393238443582,
      "grad_norm": 0.9945166110992432,
      "learning_rate": 0.0003513391911920389,
      "loss": 1.201,
      "step": 66400
    },
    {
      "epoch": 0.7034686456243615,
      "grad_norm": 0.9935473203659058,
      "learning_rate": 0.0003516038534829558,
      "loss": 1.2118,
      "step": 66450
    },
    {
      "epoch": 0.7039979674043648,
      "grad_norm": 1.0765206813812256,
      "learning_rate": 0.00035186851577387253,
      "loss": 1.2307,
      "step": 66500
    },
    {
      "epoch": 0.7039979674043648,
      "eval_loss": 1.1613731384277344,
      "eval_runtime": 46.722,
      "eval_samples_per_second": 3594.235,
      "eval_steps_per_second": 449.295,
      "step": 66500
    },
    {
      "epoch": 0.704527289184368,
      "grad_norm": 0.9884920716285706,
      "learning_rate": 0.00035213317806478934,
      "loss": 1.2088,
      "step": 66550
    },
    {
      "epoch": 0.7050566109643713,
      "grad_norm": 0.9487307667732239,
      "learning_rate": 0.0003523978403557061,
      "loss": 1.2099,
      "step": 66600
    },
    {
      "epoch": 0.7055859327443746,
      "grad_norm": 1.0294911861419678,
      "learning_rate": 0.0003526625026466229,
      "loss": 1.1993,
      "step": 66650
    },
    {
      "epoch": 0.706115254524378,
      "grad_norm": 0.9047572612762451,
      "learning_rate": 0.0003529271649375397,
      "loss": 1.2139,
      "step": 66700
    },
    {
      "epoch": 0.7066445763043812,
      "grad_norm": 0.9400704503059387,
      "learning_rate": 0.0003531918272284565,
      "loss": 1.2368,
      "step": 66750
    },
    {
      "epoch": 0.7071738980843845,
      "grad_norm": 1.0458476543426514,
      "learning_rate": 0.0003534564895193733,
      "loss": 1.1948,
      "step": 66800
    },
    {
      "epoch": 0.7077032198643878,
      "grad_norm": 0.9136669635772705,
      "learning_rate": 0.00035372115181029007,
      "loss": 1.2331,
      "step": 66850
    },
    {
      "epoch": 0.7082325416443911,
      "grad_norm": 0.9206039905548096,
      "learning_rate": 0.0003539858141012069,
      "loss": 1.1954,
      "step": 66900
    },
    {
      "epoch": 0.7087618634243943,
      "grad_norm": 1.010498046875,
      "learning_rate": 0.00035425047639212363,
      "loss": 1.1948,
      "step": 66950
    },
    {
      "epoch": 0.7092911852043976,
      "grad_norm": 0.9366586804389954,
      "learning_rate": 0.0003545151386830405,
      "loss": 1.2019,
      "step": 67000
    },
    {
      "epoch": 0.7092911852043976,
      "eval_loss": 1.1549092531204224,
      "eval_runtime": 46.7597,
      "eval_samples_per_second": 3591.339,
      "eval_steps_per_second": 448.933,
      "step": 67000
    },
    {
      "epoch": 0.7098205069844009,
      "grad_norm": 1.014696478843689,
      "learning_rate": 0.00035477980097395724,
      "loss": 1.2348,
      "step": 67050
    },
    {
      "epoch": 0.7103498287644042,
      "grad_norm": 1.1429110765457153,
      "learning_rate": 0.00035504446326487405,
      "loss": 1.1934,
      "step": 67100
    },
    {
      "epoch": 0.7108791505444074,
      "grad_norm": 0.9916418790817261,
      "learning_rate": 0.0003553091255557908,
      "loss": 1.2107,
      "step": 67150
    },
    {
      "epoch": 0.7114084723244107,
      "grad_norm": 1.078578233718872,
      "learning_rate": 0.0003555737878467076,
      "loss": 1.2071,
      "step": 67200
    },
    {
      "epoch": 0.711937794104414,
      "grad_norm": 0.9390097260475159,
      "learning_rate": 0.0003558384501376244,
      "loss": 1.2099,
      "step": 67250
    },
    {
      "epoch": 0.7124671158844172,
      "grad_norm": 0.9773759841918945,
      "learning_rate": 0.0003561031124285412,
      "loss": 1.2104,
      "step": 67300
    },
    {
      "epoch": 0.7129964376644206,
      "grad_norm": 1.140346646308899,
      "learning_rate": 0.000356367774719458,
      "loss": 1.2167,
      "step": 67350
    },
    {
      "epoch": 0.7135257594444239,
      "grad_norm": 0.9576178789138794,
      "learning_rate": 0.0003566324370103748,
      "loss": 1.2054,
      "step": 67400
    },
    {
      "epoch": 0.7140550812244272,
      "grad_norm": 0.8836578726768494,
      "learning_rate": 0.00035689709930129154,
      "loss": 1.2061,
      "step": 67450
    },
    {
      "epoch": 0.7145844030044304,
      "grad_norm": 0.9194674491882324,
      "learning_rate": 0.00035716176159220834,
      "loss": 1.2015,
      "step": 67500
    },
    {
      "epoch": 0.7145844030044304,
      "eval_loss": 1.1516075134277344,
      "eval_runtime": 46.7796,
      "eval_samples_per_second": 3589.814,
      "eval_steps_per_second": 448.743,
      "step": 67500
    },
    {
      "epoch": 0.7151137247844337,
      "grad_norm": 1.0711932182312012,
      "learning_rate": 0.00035742642388312515,
      "loss": 1.2166,
      "step": 67550
    },
    {
      "epoch": 0.715643046564437,
      "grad_norm": 0.9644209742546082,
      "learning_rate": 0.0003576857929282236,
      "loss": 1.2118,
      "step": 67600
    },
    {
      "epoch": 0.7161723683444403,
      "grad_norm": 0.9488652944564819,
      "learning_rate": 0.0003579504552191404,
      "loss": 1.2121,
      "step": 67650
    },
    {
      "epoch": 0.7167016901244435,
      "grad_norm": 1.0134618282318115,
      "learning_rate": 0.0003582151175100572,
      "loss": 1.2004,
      "step": 67700
    },
    {
      "epoch": 0.7172310119044468,
      "grad_norm": 1.0338603258132935,
      "learning_rate": 0.00035847977980097394,
      "loss": 1.1964,
      "step": 67750
    },
    {
      "epoch": 0.7177603336844501,
      "grad_norm": 0.9596098065376282,
      "learning_rate": 0.0003587444420918908,
      "loss": 1.2004,
      "step": 67800
    },
    {
      "epoch": 0.7182896554644534,
      "grad_norm": 1.0529738664627075,
      "learning_rate": 0.00035900910438280755,
      "loss": 1.213,
      "step": 67850
    },
    {
      "epoch": 0.7188189772444566,
      "grad_norm": 0.9444717168807983,
      "learning_rate": 0.00035927376667372436,
      "loss": 1.1919,
      "step": 67900
    },
    {
      "epoch": 0.71934829902446,
      "grad_norm": 1.076730728149414,
      "learning_rate": 0.0003595384289646411,
      "loss": 1.2049,
      "step": 67950
    },
    {
      "epoch": 0.7198776208044633,
      "grad_norm": 0.9834928512573242,
      "learning_rate": 0.0003598030912555579,
      "loss": 1.2176,
      "step": 68000
    },
    {
      "epoch": 0.7198776208044633,
      "eval_loss": 1.147286057472229,
      "eval_runtime": 46.799,
      "eval_samples_per_second": 3588.327,
      "eval_steps_per_second": 448.557,
      "step": 68000
    },
    {
      "epoch": 0.7204069425844665,
      "grad_norm": 1.0572587251663208,
      "learning_rate": 0.00036006775354647467,
      "loss": 1.2038,
      "step": 68050
    },
    {
      "epoch": 0.7209362643644698,
      "grad_norm": 0.9652099609375,
      "learning_rate": 0.00036033241583739153,
      "loss": 1.2092,
      "step": 68100
    },
    {
      "epoch": 0.7214655861444731,
      "grad_norm": 0.9450715780258179,
      "learning_rate": 0.0003605970781283083,
      "loss": 1.2163,
      "step": 68150
    },
    {
      "epoch": 0.7219949079244764,
      "grad_norm": 0.9594315886497498,
      "learning_rate": 0.0003608617404192251,
      "loss": 1.2097,
      "step": 68200
    },
    {
      "epoch": 0.7225242297044796,
      "grad_norm": 0.9667185544967651,
      "learning_rate": 0.00036112640271014184,
      "loss": 1.206,
      "step": 68250
    },
    {
      "epoch": 0.7230535514844829,
      "grad_norm": 0.9592924118041992,
      "learning_rate": 0.00036139106500105865,
      "loss": 1.1999,
      "step": 68300
    },
    {
      "epoch": 0.7235828732644862,
      "grad_norm": 1.0220041275024414,
      "learning_rate": 0.00036165572729197546,
      "loss": 1.2149,
      "step": 68350
    },
    {
      "epoch": 0.7241121950444895,
      "grad_norm": 0.9754964709281921,
      "learning_rate": 0.00036192038958289226,
      "loss": 1.2202,
      "step": 68400
    },
    {
      "epoch": 0.7246415168244927,
      "grad_norm": 1.026052474975586,
      "learning_rate": 0.000362185051873809,
      "loss": 1.1832,
      "step": 68450
    },
    {
      "epoch": 0.725170838604496,
      "grad_norm": 1.018397569656372,
      "learning_rate": 0.0003624497141647258,
      "loss": 1.2141,
      "step": 68500
    },
    {
      "epoch": 0.725170838604496,
      "eval_loss": 1.145796537399292,
      "eval_runtime": 46.7193,
      "eval_samples_per_second": 3594.444,
      "eval_steps_per_second": 449.322,
      "step": 68500
    },
    {
      "epoch": 0.7257001603844994,
      "grad_norm": 1.0512230396270752,
      "learning_rate": 0.0003627143764556426,
      "loss": 1.2046,
      "step": 68550
    },
    {
      "epoch": 0.7262294821645027,
      "grad_norm": 0.9072049260139465,
      "learning_rate": 0.0003629790387465594,
      "loss": 1.2137,
      "step": 68600
    },
    {
      "epoch": 0.7267588039445059,
      "grad_norm": 1.0284785032272339,
      "learning_rate": 0.0003632437010374762,
      "loss": 1.2098,
      "step": 68650
    },
    {
      "epoch": 0.7272881257245092,
      "grad_norm": 1.0289536714553833,
      "learning_rate": 0.000363508363328393,
      "loss": 1.2035,
      "step": 68700
    },
    {
      "epoch": 0.7278174475045125,
      "grad_norm": 0.9204810857772827,
      "learning_rate": 0.00036377302561930975,
      "loss": 1.2197,
      "step": 68750
    },
    {
      "epoch": 0.7283467692845158,
      "grad_norm": 0.9945620894432068,
      "learning_rate": 0.00036403768791022656,
      "loss": 1.2371,
      "step": 68800
    },
    {
      "epoch": 0.728876091064519,
      "grad_norm": 1.0055058002471924,
      "learning_rate": 0.0003643023502011433,
      "loss": 1.1989,
      "step": 68850
    },
    {
      "epoch": 0.7294054128445223,
      "grad_norm": 1.018339991569519,
      "learning_rate": 0.00036456701249206017,
      "loss": 1.2006,
      "step": 68900
    },
    {
      "epoch": 0.7299347346245256,
      "grad_norm": 0.9871960282325745,
      "learning_rate": 0.0003648316747829769,
      "loss": 1.1957,
      "step": 68950
    },
    {
      "epoch": 0.7304640564045288,
      "grad_norm": 0.9972211718559265,
      "learning_rate": 0.00036509633707389373,
      "loss": 1.2052,
      "step": 69000
    },
    {
      "epoch": 0.7304640564045288,
      "eval_loss": 1.1412110328674316,
      "eval_runtime": 46.8079,
      "eval_samples_per_second": 3587.641,
      "eval_steps_per_second": 448.471,
      "step": 69000
    },
    {
      "epoch": 0.7309933781845321,
      "grad_norm": 0.9802393317222595,
      "learning_rate": 0.0003653609993648105,
      "loss": 1.1969,
      "step": 69050
    },
    {
      "epoch": 0.7315226999645354,
      "grad_norm": 1.0059481859207153,
      "learning_rate": 0.0003656256616557273,
      "loss": 1.2122,
      "step": 69100
    },
    {
      "epoch": 0.7320520217445388,
      "grad_norm": 1.0263618230819702,
      "learning_rate": 0.00036589032394664404,
      "loss": 1.1967,
      "step": 69150
    },
    {
      "epoch": 0.732581343524542,
      "grad_norm": 1.0630314350128174,
      "learning_rate": 0.0003661549862375609,
      "loss": 1.205,
      "step": 69200
    },
    {
      "epoch": 0.7331106653045453,
      "grad_norm": 1.0381922721862793,
      "learning_rate": 0.00036641964852847765,
      "loss": 1.2101,
      "step": 69250
    },
    {
      "epoch": 0.7336399870845486,
      "grad_norm": 0.940207839012146,
      "learning_rate": 0.00036668431081939446,
      "loss": 1.1877,
      "step": 69300
    },
    {
      "epoch": 0.7341693088645519,
      "grad_norm": 1.0404586791992188,
      "learning_rate": 0.0003669489731103112,
      "loss": 1.1816,
      "step": 69350
    },
    {
      "epoch": 0.7346986306445551,
      "grad_norm": 0.9787036776542664,
      "learning_rate": 0.000367213635401228,
      "loss": 1.197,
      "step": 69400
    },
    {
      "epoch": 0.7352279524245584,
      "grad_norm": 1.1264872550964355,
      "learning_rate": 0.0003674782976921449,
      "loss": 1.19,
      "step": 69450
    },
    {
      "epoch": 0.7357572742045617,
      "grad_norm": 1.135193109512329,
      "learning_rate": 0.00036774295998306163,
      "loss": 1.2022,
      "step": 69500
    },
    {
      "epoch": 0.7357572742045617,
      "eval_loss": 1.137939214706421,
      "eval_runtime": 46.8013,
      "eval_samples_per_second": 3588.145,
      "eval_steps_per_second": 448.534,
      "step": 69500
    },
    {
      "epoch": 0.736286595984565,
      "grad_norm": 1.0494384765625,
      "learning_rate": 0.00036800762227397844,
      "loss": 1.1971,
      "step": 69550
    },
    {
      "epoch": 0.7368159177645682,
      "grad_norm": 0.9316354990005493,
      "learning_rate": 0.0003682722845648952,
      "loss": 1.206,
      "step": 69600
    },
    {
      "epoch": 0.7373452395445715,
      "grad_norm": 1.106412649154663,
      "learning_rate": 0.000368536946855812,
      "loss": 1.1799,
      "step": 69650
    },
    {
      "epoch": 0.7378745613245749,
      "grad_norm": 1.0075163841247559,
      "learning_rate": 0.00036880160914672875,
      "loss": 1.2208,
      "step": 69700
    },
    {
      "epoch": 0.738403883104578,
      "grad_norm": 1.048546314239502,
      "learning_rate": 0.0003690662714376456,
      "loss": 1.2038,
      "step": 69750
    },
    {
      "epoch": 0.7389332048845814,
      "grad_norm": 1.0172675848007202,
      "learning_rate": 0.00036933093372856237,
      "loss": 1.1945,
      "step": 69800
    },
    {
      "epoch": 0.7394625266645847,
      "grad_norm": 1.0180506706237793,
      "learning_rate": 0.0003695955960194792,
      "loss": 1.1824,
      "step": 69850
    },
    {
      "epoch": 0.739991848444588,
      "grad_norm": 0.9877271056175232,
      "learning_rate": 0.0003698602583103959,
      "loss": 1.204,
      "step": 69900
    },
    {
      "epoch": 0.7405211702245912,
      "grad_norm": 1.070670247077942,
      "learning_rate": 0.00037012492060131273,
      "loss": 1.1921,
      "step": 69950
    },
    {
      "epoch": 0.7410504920045945,
      "grad_norm": 1.0194473266601562,
      "learning_rate": 0.00037038958289222954,
      "loss": 1.1861,
      "step": 70000
    },
    {
      "epoch": 0.7410504920045945,
      "eval_loss": 1.1355448961257935,
      "eval_runtime": 46.6802,
      "eval_samples_per_second": 3597.455,
      "eval_steps_per_second": 449.698,
      "step": 70000
    },
    {
      "epoch": 0.7415798137845978,
      "grad_norm": 1.0220850706100464,
      "learning_rate": 0.00037065424518314635,
      "loss": 1.1864,
      "step": 70050
    },
    {
      "epoch": 0.7421091355646011,
      "grad_norm": 0.9885451197624207,
      "learning_rate": 0.0003709189074740631,
      "loss": 1.2006,
      "step": 70100
    },
    {
      "epoch": 0.7426384573446043,
      "grad_norm": 1.092851161956787,
      "learning_rate": 0.0003711835697649799,
      "loss": 1.2173,
      "step": 70150
    },
    {
      "epoch": 0.7431677791246076,
      "grad_norm": 1.0026746988296509,
      "learning_rate": 0.00037144823205589666,
      "loss": 1.1767,
      "step": 70200
    },
    {
      "epoch": 0.7436971009046109,
      "grad_norm": 0.8519437313079834,
      "learning_rate": 0.00037171289434681347,
      "loss": 1.2066,
      "step": 70250
    },
    {
      "epoch": 0.7442264226846143,
      "grad_norm": 0.978497326374054,
      "learning_rate": 0.0003719775566377303,
      "loss": 1.2079,
      "step": 70300
    },
    {
      "epoch": 0.7447557444646175,
      "grad_norm": 1.164036750793457,
      "learning_rate": 0.0003722422189286471,
      "loss": 1.1719,
      "step": 70350
    },
    {
      "epoch": 0.7452850662446208,
      "grad_norm": 0.9938055276870728,
      "learning_rate": 0.00037250688121956383,
      "loss": 1.2082,
      "step": 70400
    },
    {
      "epoch": 0.7458143880246241,
      "grad_norm": 0.9670868515968323,
      "learning_rate": 0.00037277154351048064,
      "loss": 1.1929,
      "step": 70450
    },
    {
      "epoch": 0.7463437098046273,
      "grad_norm": 1.0467981100082397,
      "learning_rate": 0.0003730362058013974,
      "loss": 1.1876,
      "step": 70500
    },
    {
      "epoch": 0.7463437098046273,
      "eval_loss": 1.1364624500274658,
      "eval_runtime": 46.7615,
      "eval_samples_per_second": 3591.205,
      "eval_steps_per_second": 448.917,
      "step": 70500
    },
    {
      "epoch": 0.7468730315846306,
      "grad_norm": 0.9907596707344055,
      "learning_rate": 0.00037330086809231425,
      "loss": 1.1947,
      "step": 70550
    },
    {
      "epoch": 0.7474023533646339,
      "grad_norm": 0.959499716758728,
      "learning_rate": 0.000373565530383231,
      "loss": 1.1967,
      "step": 70600
    },
    {
      "epoch": 0.7479316751446372,
      "grad_norm": 1.0143260955810547,
      "learning_rate": 0.0003738301926741478,
      "loss": 1.1871,
      "step": 70650
    },
    {
      "epoch": 0.7484609969246404,
      "grad_norm": 1.1382962465286255,
      "learning_rate": 0.00037409485496506457,
      "loss": 1.186,
      "step": 70700
    },
    {
      "epoch": 0.7489903187046437,
      "grad_norm": 1.0706454515457153,
      "learning_rate": 0.00037435951725598137,
      "loss": 1.1806,
      "step": 70750
    },
    {
      "epoch": 0.749519640484647,
      "grad_norm": 0.9660337567329407,
      "learning_rate": 0.0003746241795468981,
      "loss": 1.1938,
      "step": 70800
    },
    {
      "epoch": 0.7500489622646503,
      "grad_norm": 1.038845181465149,
      "learning_rate": 0.000374888841837815,
      "loss": 1.1984,
      "step": 70850
    },
    {
      "epoch": 0.7505782840446535,
      "grad_norm": 0.996152937412262,
      "learning_rate": 0.0003751482108829134,
      "loss": 1.1851,
      "step": 70900
    },
    {
      "epoch": 0.7511076058246569,
      "grad_norm": 1.1168367862701416,
      "learning_rate": 0.0003754128731738302,
      "loss": 1.199,
      "step": 70950
    },
    {
      "epoch": 0.7516369276046602,
      "grad_norm": 1.083242416381836,
      "learning_rate": 0.00037567753546474697,
      "loss": 1.1834,
      "step": 71000
    },
    {
      "epoch": 0.7516369276046602,
      "eval_loss": 1.1305686235427856,
      "eval_runtime": 46.7675,
      "eval_samples_per_second": 3590.744,
      "eval_steps_per_second": 448.859,
      "step": 71000
    },
    {
      "epoch": 0.7521662493846635,
      "grad_norm": 1.046905755996704,
      "learning_rate": 0.0003759421977556638,
      "loss": 1.1945,
      "step": 71050
    },
    {
      "epoch": 0.7526955711646667,
      "grad_norm": 0.9816144704818726,
      "learning_rate": 0.0003762068600465806,
      "loss": 1.1844,
      "step": 71100
    },
    {
      "epoch": 0.75322489294467,
      "grad_norm": 0.9844371676445007,
      "learning_rate": 0.0003764715223374974,
      "loss": 1.1918,
      "step": 71150
    },
    {
      "epoch": 0.7537542147246733,
      "grad_norm": 1.0721440315246582,
      "learning_rate": 0.00037673618462841414,
      "loss": 1.1885,
      "step": 71200
    },
    {
      "epoch": 0.7542835365046766,
      "grad_norm": 0.9830920696258545,
      "learning_rate": 0.00037700084691933095,
      "loss": 1.1563,
      "step": 71250
    },
    {
      "epoch": 0.7548128582846798,
      "grad_norm": 1.0193321704864502,
      "learning_rate": 0.0003772655092102477,
      "loss": 1.1745,
      "step": 71300
    },
    {
      "epoch": 0.7553421800646831,
      "grad_norm": 1.0068246126174927,
      "learning_rate": 0.0003775301715011645,
      "loss": 1.1789,
      "step": 71350
    },
    {
      "epoch": 0.7558715018446864,
      "grad_norm": 0.9787341356277466,
      "learning_rate": 0.0003777948337920813,
      "loss": 1.1934,
      "step": 71400
    },
    {
      "epoch": 0.7564008236246896,
      "grad_norm": 1.1262420415878296,
      "learning_rate": 0.0003780594960829981,
      "loss": 1.1916,
      "step": 71450
    },
    {
      "epoch": 0.7569301454046929,
      "grad_norm": 0.8824657797813416,
      "learning_rate": 0.00037832415837391487,
      "loss": 1.1898,
      "step": 71500
    },
    {
      "epoch": 0.7569301454046929,
      "eval_loss": 1.1251057386398315,
      "eval_runtime": 46.733,
      "eval_samples_per_second": 3593.394,
      "eval_steps_per_second": 449.19,
      "step": 71500
    },
    {
      "epoch": 0.7574594671846963,
      "grad_norm": 1.035779356956482,
      "learning_rate": 0.0003785888206648317,
      "loss": 1.1876,
      "step": 71550
    },
    {
      "epoch": 0.7579887889646996,
      "grad_norm": 0.9842568039894104,
      "learning_rate": 0.00037885348295574843,
      "loss": 1.1775,
      "step": 71600
    },
    {
      "epoch": 0.7585181107447028,
      "grad_norm": 0.8995360732078552,
      "learning_rate": 0.0003791181452466653,
      "loss": 1.2019,
      "step": 71650
    },
    {
      "epoch": 0.7590474325247061,
      "grad_norm": 1.041298747062683,
      "learning_rate": 0.00037938280753758205,
      "loss": 1.195,
      "step": 71700
    },
    {
      "epoch": 0.7595767543047094,
      "grad_norm": 0.9577966928482056,
      "learning_rate": 0.00037964746982849885,
      "loss": 1.1853,
      "step": 71750
    },
    {
      "epoch": 0.7601060760847127,
      "grad_norm": 0.8987401127815247,
      "learning_rate": 0.0003799121321194156,
      "loss": 1.1834,
      "step": 71800
    },
    {
      "epoch": 0.7606353978647159,
      "grad_norm": 0.921195924282074,
      "learning_rate": 0.0003801767944103324,
      "loss": 1.1832,
      "step": 71850
    },
    {
      "epoch": 0.7611647196447192,
      "grad_norm": 0.994200587272644,
      "learning_rate": 0.00038044145670124916,
      "loss": 1.1924,
      "step": 71900
    },
    {
      "epoch": 0.7616940414247225,
      "grad_norm": 0.9478771090507507,
      "learning_rate": 0.000380706118992166,
      "loss": 1.2003,
      "step": 71950
    },
    {
      "epoch": 0.7622233632047258,
      "grad_norm": 0.9318498969078064,
      "learning_rate": 0.0003809707812830828,
      "loss": 1.1935,
      "step": 72000
    },
    {
      "epoch": 0.7622233632047258,
      "eval_loss": 1.1242140531539917,
      "eval_runtime": 46.7513,
      "eval_samples_per_second": 3591.982,
      "eval_steps_per_second": 449.014,
      "step": 72000
    },
    {
      "epoch": 0.762752684984729,
      "grad_norm": 0.9656499028205872,
      "learning_rate": 0.0003812354435739996,
      "loss": 1.1911,
      "step": 72050
    },
    {
      "epoch": 0.7632820067647323,
      "grad_norm": 0.9378816485404968,
      "learning_rate": 0.00038150010586491634,
      "loss": 1.1849,
      "step": 72100
    },
    {
      "epoch": 0.7638113285447357,
      "grad_norm": 1.0225496292114258,
      "learning_rate": 0.00038176476815583314,
      "loss": 1.1945,
      "step": 72150
    },
    {
      "epoch": 0.7643406503247389,
      "grad_norm": 0.9793043732643127,
      "learning_rate": 0.00038202943044675,
      "loss": 1.1871,
      "step": 72200
    },
    {
      "epoch": 0.7648699721047422,
      "grad_norm": 0.9752119779586792,
      "learning_rate": 0.00038229409273766676,
      "loss": 1.1983,
      "step": 72250
    },
    {
      "epoch": 0.7653992938847455,
      "grad_norm": 0.9863235950469971,
      "learning_rate": 0.00038255875502858356,
      "loss": 1.1688,
      "step": 72300
    },
    {
      "epoch": 0.7659286156647488,
      "grad_norm": 1.063896656036377,
      "learning_rate": 0.0003828234173195003,
      "loss": 1.1724,
      "step": 72350
    },
    {
      "epoch": 0.766457937444752,
      "grad_norm": 0.9165943264961243,
      "learning_rate": 0.0003830880796104171,
      "loss": 1.2074,
      "step": 72400
    },
    {
      "epoch": 0.7669872592247553,
      "grad_norm": 0.9972857236862183,
      "learning_rate": 0.0003833527419013339,
      "loss": 1.1828,
      "step": 72450
    },
    {
      "epoch": 0.7675165810047586,
      "grad_norm": 0.9421667456626892,
      "learning_rate": 0.00038361740419225074,
      "loss": 1.1829,
      "step": 72500
    },
    {
      "epoch": 0.7675165810047586,
      "eval_loss": 1.125137448310852,
      "eval_runtime": 46.7944,
      "eval_samples_per_second": 3588.679,
      "eval_steps_per_second": 448.601,
      "step": 72500
    },
    {
      "epoch": 0.7680459027847619,
      "grad_norm": 1.04420006275177,
      "learning_rate": 0.0003838820664831675,
      "loss": 1.1784,
      "step": 72550
    },
    {
      "epoch": 0.7685752245647651,
      "grad_norm": 0.920826256275177,
      "learning_rate": 0.0003841467287740843,
      "loss": 1.1833,
      "step": 72600
    },
    {
      "epoch": 0.7691045463447684,
      "grad_norm": 0.9570294618606567,
      "learning_rate": 0.00038441139106500105,
      "loss": 1.2069,
      "step": 72650
    },
    {
      "epoch": 0.7696338681247717,
      "grad_norm": 0.9329081773757935,
      "learning_rate": 0.00038467605335591786,
      "loss": 1.1715,
      "step": 72700
    },
    {
      "epoch": 0.7701631899047751,
      "grad_norm": 1.0656083822250366,
      "learning_rate": 0.00038494071564683466,
      "loss": 1.184,
      "step": 72750
    },
    {
      "epoch": 0.7706925116847783,
      "grad_norm": 1.0391292572021484,
      "learning_rate": 0.00038520537793775147,
      "loss": 1.1891,
      "step": 72800
    },
    {
      "epoch": 0.7712218334647816,
      "grad_norm": 1.043667197227478,
      "learning_rate": 0.0003854700402286682,
      "loss": 1.1934,
      "step": 72850
    },
    {
      "epoch": 0.7717511552447849,
      "grad_norm": 0.9617579579353333,
      "learning_rate": 0.00038573470251958503,
      "loss": 1.1719,
      "step": 72900
    },
    {
      "epoch": 0.7722804770247882,
      "grad_norm": 1.0788605213165283,
      "learning_rate": 0.0003859993648105018,
      "loss": 1.2036,
      "step": 72950
    },
    {
      "epoch": 0.7728097988047914,
      "grad_norm": 0.9591352939605713,
      "learning_rate": 0.0003862640271014186,
      "loss": 1.1928,
      "step": 73000
    },
    {
      "epoch": 0.7728097988047914,
      "eval_loss": 1.11725652217865,
      "eval_runtime": 46.7631,
      "eval_samples_per_second": 3591.081,
      "eval_steps_per_second": 448.901,
      "step": 73000
    },
    {
      "epoch": 0.7733391205847947,
      "grad_norm": 0.9441090822219849,
      "learning_rate": 0.0003865286893923354,
      "loss": 1.1956,
      "step": 73050
    },
    {
      "epoch": 0.773868442364798,
      "grad_norm": 0.9855941534042358,
      "learning_rate": 0.0003867933516832522,
      "loss": 1.1601,
      "step": 73100
    },
    {
      "epoch": 0.7743977641448012,
      "grad_norm": 0.9224605560302734,
      "learning_rate": 0.00038705801397416896,
      "loss": 1.1711,
      "step": 73150
    },
    {
      "epoch": 0.7749270859248045,
      "grad_norm": 0.9544202089309692,
      "learning_rate": 0.00038732267626508576,
      "loss": 1.1766,
      "step": 73200
    },
    {
      "epoch": 0.7754564077048078,
      "grad_norm": 0.9764596819877625,
      "learning_rate": 0.0003875873385560025,
      "loss": 1.1815,
      "step": 73250
    },
    {
      "epoch": 0.7759857294848111,
      "grad_norm": 0.9689934849739075,
      "learning_rate": 0.0003878520008469194,
      "loss": 1.1831,
      "step": 73300
    },
    {
      "epoch": 0.7765150512648143,
      "grad_norm": 0.9997932314872742,
      "learning_rate": 0.00038811666313783613,
      "loss": 1.1792,
      "step": 73350
    },
    {
      "epoch": 0.7770443730448177,
      "grad_norm": 1.0247528553009033,
      "learning_rate": 0.00038838132542875294,
      "loss": 1.1913,
      "step": 73400
    },
    {
      "epoch": 0.777573694824821,
      "grad_norm": 1.0264675617218018,
      "learning_rate": 0.00038864069447385136,
      "loss": 1.1742,
      "step": 73450
    },
    {
      "epoch": 0.7781030166048243,
      "grad_norm": 0.9827975034713745,
      "learning_rate": 0.00038890535676476816,
      "loss": 1.17,
      "step": 73500
    },
    {
      "epoch": 0.7781030166048243,
      "eval_loss": 1.1148546934127808,
      "eval_runtime": 46.7956,
      "eval_samples_per_second": 3588.586,
      "eval_steps_per_second": 448.589,
      "step": 73500
    },
    {
      "epoch": 0.7786323383848275,
      "grad_norm": 1.0756146907806396,
      "learning_rate": 0.0003891700190556849,
      "loss": 1.1746,
      "step": 73550
    },
    {
      "epoch": 0.7791616601648308,
      "grad_norm": 1.0162287950515747,
      "learning_rate": 0.0003894346813466018,
      "loss": 1.1643,
      "step": 73600
    },
    {
      "epoch": 0.7796909819448341,
      "grad_norm": 0.9826894998550415,
      "learning_rate": 0.00038969934363751853,
      "loss": 1.2003,
      "step": 73650
    },
    {
      "epoch": 0.7802203037248374,
      "grad_norm": 0.9788916707038879,
      "learning_rate": 0.00038996400592843534,
      "loss": 1.1827,
      "step": 73700
    },
    {
      "epoch": 0.7807496255048406,
      "grad_norm": 0.9879522919654846,
      "learning_rate": 0.0003902286682193521,
      "loss": 1.1824,
      "step": 73750
    },
    {
      "epoch": 0.7812789472848439,
      "grad_norm": 1.0818620920181274,
      "learning_rate": 0.0003904933305102689,
      "loss": 1.1994,
      "step": 73800
    },
    {
      "epoch": 0.7818082690648472,
      "grad_norm": 0.9852380156517029,
      "learning_rate": 0.0003907579928011857,
      "loss": 1.1924,
      "step": 73850
    },
    {
      "epoch": 0.7823375908448504,
      "grad_norm": 1.0366895198822021,
      "learning_rate": 0.0003910226550921025,
      "loss": 1.1796,
      "step": 73900
    },
    {
      "epoch": 0.7828669126248538,
      "grad_norm": 0.8925954103469849,
      "learning_rate": 0.00039128731738301926,
      "loss": 1.1696,
      "step": 73950
    },
    {
      "epoch": 0.7833962344048571,
      "grad_norm": 1.1201122999191284,
      "learning_rate": 0.00039155197967393607,
      "loss": 1.1927,
      "step": 74000
    },
    {
      "epoch": 0.7833962344048571,
      "eval_loss": 1.1087020635604858,
      "eval_runtime": 46.7439,
      "eval_samples_per_second": 3592.551,
      "eval_steps_per_second": 449.085,
      "step": 74000
    },
    {
      "epoch": 0.7839255561848604,
      "grad_norm": 0.9856873750686646,
      "learning_rate": 0.0003918166419648528,
      "loss": 1.166,
      "step": 74050
    },
    {
      "epoch": 0.7844548779648636,
      "grad_norm": 0.9826335310935974,
      "learning_rate": 0.00039208130425576963,
      "loss": 1.1726,
      "step": 74100
    },
    {
      "epoch": 0.7849841997448669,
      "grad_norm": 0.998417317867279,
      "learning_rate": 0.00039234596654668644,
      "loss": 1.1692,
      "step": 74150
    },
    {
      "epoch": 0.7855135215248702,
      "grad_norm": 1.004143238067627,
      "learning_rate": 0.00039261062883760324,
      "loss": 1.1898,
      "step": 74200
    },
    {
      "epoch": 0.7860428433048735,
      "grad_norm": 1.1335608959197998,
      "learning_rate": 0.00039287529112852,
      "loss": 1.1727,
      "step": 74250
    },
    {
      "epoch": 0.7865721650848767,
      "grad_norm": 1.0047160387039185,
      "learning_rate": 0.0003931399534194368,
      "loss": 1.1756,
      "step": 74300
    },
    {
      "epoch": 0.78710148686488,
      "grad_norm": 1.0296788215637207,
      "learning_rate": 0.00039340461571035355,
      "loss": 1.1594,
      "step": 74350
    },
    {
      "epoch": 0.7876308086448833,
      "grad_norm": 0.9124757647514343,
      "learning_rate": 0.0003936692780012704,
      "loss": 1.1914,
      "step": 74400
    },
    {
      "epoch": 0.7881601304248866,
      "grad_norm": 0.9495723843574524,
      "learning_rate": 0.00039393394029218717,
      "loss": 1.1905,
      "step": 74450
    },
    {
      "epoch": 0.7886894522048898,
      "grad_norm": 0.9013792872428894,
      "learning_rate": 0.000394198602583104,
      "loss": 1.1607,
      "step": 74500
    },
    {
      "epoch": 0.7886894522048898,
      "eval_loss": 1.110175609588623,
      "eval_runtime": 46.8614,
      "eval_samples_per_second": 3583.545,
      "eval_steps_per_second": 447.959,
      "step": 74500
    },
    {
      "epoch": 0.7892187739848932,
      "grad_norm": 1.0162055492401123,
      "learning_rate": 0.00039446326487402073,
      "loss": 1.1812,
      "step": 74550
    },
    {
      "epoch": 0.7897480957648965,
      "grad_norm": 1.089572787284851,
      "learning_rate": 0.00039472792716493753,
      "loss": 1.168,
      "step": 74600
    },
    {
      "epoch": 0.7902774175448998,
      "grad_norm": 1.0125452280044556,
      "learning_rate": 0.0003949925894558543,
      "loss": 1.1686,
      "step": 74650
    },
    {
      "epoch": 0.790806739324903,
      "grad_norm": 1.0252668857574463,
      "learning_rate": 0.00039525725174677115,
      "loss": 1.173,
      "step": 74700
    },
    {
      "epoch": 0.7913360611049063,
      "grad_norm": 0.9547531604766846,
      "learning_rate": 0.0003955219140376879,
      "loss": 1.1746,
      "step": 74750
    },
    {
      "epoch": 0.7918653828849096,
      "grad_norm": 0.8989037871360779,
      "learning_rate": 0.0003957865763286047,
      "loss": 1.1705,
      "step": 74800
    },
    {
      "epoch": 0.7923947046649128,
      "grad_norm": 1.0256919860839844,
      "learning_rate": 0.0003960512386195215,
      "loss": 1.181,
      "step": 74850
    },
    {
      "epoch": 0.7929240264449161,
      "grad_norm": 1.0162272453308105,
      "learning_rate": 0.00039631590091043827,
      "loss": 1.1767,
      "step": 74900
    },
    {
      "epoch": 0.7934533482249194,
      "grad_norm": 1.0599727630615234,
      "learning_rate": 0.00039658056320135513,
      "loss": 1.1781,
      "step": 74950
    },
    {
      "epoch": 0.7939826700049227,
      "grad_norm": 0.9770488142967224,
      "learning_rate": 0.0003968452254922719,
      "loss": 1.1729,
      "step": 75000
    },
    {
      "epoch": 0.7939826700049227,
      "eval_loss": 1.1046401262283325,
      "eval_runtime": 46.747,
      "eval_samples_per_second": 3592.318,
      "eval_steps_per_second": 449.056,
      "step": 75000
    },
    {
      "epoch": 0.7945119917849259,
      "grad_norm": 0.9580260515213013,
      "learning_rate": 0.0003971098877831887,
      "loss": 1.1767,
      "step": 75050
    },
    {
      "epoch": 0.7950413135649292,
      "grad_norm": 0.8680956959724426,
      "learning_rate": 0.00039737455007410544,
      "loss": 1.1828,
      "step": 75100
    },
    {
      "epoch": 0.7955706353449326,
      "grad_norm": 1.0058932304382324,
      "learning_rate": 0.00039763921236502225,
      "loss": 1.1636,
      "step": 75150
    },
    {
      "epoch": 0.7960999571249359,
      "grad_norm": 0.9354141354560852,
      "learning_rate": 0.000397903874655939,
      "loss": 1.1775,
      "step": 75200
    },
    {
      "epoch": 0.7966292789049391,
      "grad_norm": 0.9074972867965698,
      "learning_rate": 0.00039816853694685586,
      "loss": 1.1821,
      "step": 75250
    },
    {
      "epoch": 0.7971586006849424,
      "grad_norm": 0.9251845479011536,
      "learning_rate": 0.0003984331992377726,
      "loss": 1.1614,
      "step": 75300
    },
    {
      "epoch": 0.7976879224649457,
      "grad_norm": 0.9545717835426331,
      "learning_rate": 0.0003986978615286894,
      "loss": 1.1616,
      "step": 75350
    },
    {
      "epoch": 0.798217244244949,
      "grad_norm": 0.960486114025116,
      "learning_rate": 0.0003989625238196062,
      "loss": 1.1649,
      "step": 75400
    },
    {
      "epoch": 0.7987465660249522,
      "grad_norm": 0.9286866188049316,
      "learning_rate": 0.000399227186110523,
      "loss": 1.1704,
      "step": 75450
    },
    {
      "epoch": 0.7992758878049555,
      "grad_norm": 0.9321677684783936,
      "learning_rate": 0.0003994918484014398,
      "loss": 1.1607,
      "step": 75500
    },
    {
      "epoch": 0.7992758878049555,
      "eval_loss": 1.099492073059082,
      "eval_runtime": 46.8311,
      "eval_samples_per_second": 3585.865,
      "eval_steps_per_second": 448.249,
      "step": 75500
    },
    {
      "epoch": 0.7998052095849588,
      "grad_norm": 1.151969313621521,
      "learning_rate": 0.0003997565106923566,
      "loss": 1.1829,
      "step": 75550
    },
    {
      "epoch": 0.800334531364962,
      "grad_norm": 0.9138340353965759,
      "learning_rate": 0.00040002117298327335,
      "loss": 1.1718,
      "step": 75600
    },
    {
      "epoch": 0.8008638531449653,
      "grad_norm": 0.9998078346252441,
      "learning_rate": 0.00040028583527419015,
      "loss": 1.1618,
      "step": 75650
    },
    {
      "epoch": 0.8013931749249686,
      "grad_norm": 1.0243630409240723,
      "learning_rate": 0.0004005504975651069,
      "loss": 1.1497,
      "step": 75700
    },
    {
      "epoch": 0.801922496704972,
      "grad_norm": 0.9088348746299744,
      "learning_rate": 0.0004008151598560237,
      "loss": 1.1839,
      "step": 75750
    },
    {
      "epoch": 0.8024518184849752,
      "grad_norm": 0.9855707883834839,
      "learning_rate": 0.0004010798221469405,
      "loss": 1.1648,
      "step": 75800
    },
    {
      "epoch": 0.8029811402649785,
      "grad_norm": 1.0216213464736938,
      "learning_rate": 0.0004013444844378573,
      "loss": 1.1749,
      "step": 75850
    },
    {
      "epoch": 0.8035104620449818,
      "grad_norm": 1.0108051300048828,
      "learning_rate": 0.0004016091467287741,
      "loss": 1.171,
      "step": 75900
    },
    {
      "epoch": 0.8040397838249851,
      "grad_norm": 0.9855718016624451,
      "learning_rate": 0.00040186851577387255,
      "loss": 1.1616,
      "step": 75950
    },
    {
      "epoch": 0.8045691056049883,
      "grad_norm": 0.9457220435142517,
      "learning_rate": 0.0004021331780647893,
      "loss": 1.1608,
      "step": 76000
    },
    {
      "epoch": 0.8045691056049883,
      "eval_loss": 1.097405195236206,
      "eval_runtime": 46.9352,
      "eval_samples_per_second": 3577.908,
      "eval_steps_per_second": 447.255,
      "step": 76000
    },
    {
      "epoch": 0.8050984273849916,
      "grad_norm": 0.9770976901054382,
      "learning_rate": 0.00040239784035570617,
      "loss": 1.1771,
      "step": 76050
    },
    {
      "epoch": 0.8056277491649949,
      "grad_norm": 1.0360057353973389,
      "learning_rate": 0.0004026625026466229,
      "loss": 1.1697,
      "step": 76100
    },
    {
      "epoch": 0.8061570709449982,
      "grad_norm": 0.9747665524482727,
      "learning_rate": 0.00040292716493753973,
      "loss": 1.1786,
      "step": 76150
    },
    {
      "epoch": 0.8066863927250014,
      "grad_norm": 0.915227472782135,
      "learning_rate": 0.0004031918272284565,
      "loss": 1.1792,
      "step": 76200
    },
    {
      "epoch": 0.8072157145050047,
      "grad_norm": 0.9029131531715393,
      "learning_rate": 0.0004034564895193733,
      "loss": 1.1828,
      "step": 76250
    },
    {
      "epoch": 0.807745036285008,
      "grad_norm": 1.0474108457565308,
      "learning_rate": 0.00040372115181029004,
      "loss": 1.1778,
      "step": 76300
    },
    {
      "epoch": 0.8082743580650114,
      "grad_norm": 0.985346794128418,
      "learning_rate": 0.0004039858141012069,
      "loss": 1.1639,
      "step": 76350
    },
    {
      "epoch": 0.8088036798450146,
      "grad_norm": 0.9940318465232849,
      "learning_rate": 0.00040425047639212365,
      "loss": 1.1845,
      "step": 76400
    },
    {
      "epoch": 0.8093330016250179,
      "grad_norm": 1.110729694366455,
      "learning_rate": 0.00040451513868304046,
      "loss": 1.1807,
      "step": 76450
    },
    {
      "epoch": 0.8098623234050212,
      "grad_norm": 0.893844723701477,
      "learning_rate": 0.0004047798009739572,
      "loss": 1.1626,
      "step": 76500
    },
    {
      "epoch": 0.8098623234050212,
      "eval_loss": 1.0932224988937378,
      "eval_runtime": 46.8398,
      "eval_samples_per_second": 3585.202,
      "eval_steps_per_second": 448.166,
      "step": 76500
    },
    {
      "epoch": 0.8103916451850244,
      "grad_norm": 0.9179695248603821,
      "learning_rate": 0.000405044463264874,
      "loss": 1.1761,
      "step": 76550
    },
    {
      "epoch": 0.8109209669650277,
      "grad_norm": 1.0126316547393799,
      "learning_rate": 0.0004053091255557908,
      "loss": 1.1625,
      "step": 76600
    },
    {
      "epoch": 0.811450288745031,
      "grad_norm": 1.0139451026916504,
      "learning_rate": 0.00040557378784670763,
      "loss": 1.1857,
      "step": 76650
    },
    {
      "epoch": 0.8119796105250343,
      "grad_norm": 0.9369503259658813,
      "learning_rate": 0.0004058384501376244,
      "loss": 1.1829,
      "step": 76700
    },
    {
      "epoch": 0.8125089323050375,
      "grad_norm": 1.006075382232666,
      "learning_rate": 0.0004061031124285412,
      "loss": 1.1519,
      "step": 76750
    },
    {
      "epoch": 0.8130382540850408,
      "grad_norm": 0.9025729894638062,
      "learning_rate": 0.00040636777471945795,
      "loss": 1.1692,
      "step": 76800
    },
    {
      "epoch": 0.8135675758650441,
      "grad_norm": 0.9617576003074646,
      "learning_rate": 0.00040663243701037475,
      "loss": 1.1765,
      "step": 76850
    },
    {
      "epoch": 0.8140968976450474,
      "grad_norm": 1.0044533014297485,
      "learning_rate": 0.00040689709930129156,
      "loss": 1.1422,
      "step": 76900
    },
    {
      "epoch": 0.8146262194250506,
      "grad_norm": 1.0160387754440308,
      "learning_rate": 0.00040716176159220837,
      "loss": 1.1606,
      "step": 76950
    },
    {
      "epoch": 0.815155541205054,
      "grad_norm": 1.0686907768249512,
      "learning_rate": 0.0004074264238831251,
      "loss": 1.1706,
      "step": 77000
    },
    {
      "epoch": 0.815155541205054,
      "eval_loss": 1.0911428928375244,
      "eval_runtime": 46.7895,
      "eval_samples_per_second": 3589.051,
      "eval_steps_per_second": 448.647,
      "step": 77000
    },
    {
      "epoch": 0.8156848629850573,
      "grad_norm": 0.9888260960578918,
      "learning_rate": 0.0004076910861740419,
      "loss": 1.144,
      "step": 77050
    },
    {
      "epoch": 0.8162141847650606,
      "grad_norm": 1.0333091020584106,
      "learning_rate": 0.0004079557484649587,
      "loss": 1.1602,
      "step": 77100
    },
    {
      "epoch": 0.8167435065450638,
      "grad_norm": 0.9341543912887573,
      "learning_rate": 0.00040822041075587554,
      "loss": 1.1767,
      "step": 77150
    },
    {
      "epoch": 0.8172728283250671,
      "grad_norm": 0.9619970917701721,
      "learning_rate": 0.0004084850730467923,
      "loss": 1.1707,
      "step": 77200
    },
    {
      "epoch": 0.8178021501050704,
      "grad_norm": 1.00751531124115,
      "learning_rate": 0.0004087497353377091,
      "loss": 1.1699,
      "step": 77250
    },
    {
      "epoch": 0.8183314718850736,
      "grad_norm": 1.0504618883132935,
      "learning_rate": 0.00040901439762862585,
      "loss": 1.1701,
      "step": 77300
    },
    {
      "epoch": 0.8188607936650769,
      "grad_norm": 0.998642086982727,
      "learning_rate": 0.00040927905991954266,
      "loss": 1.1751,
      "step": 77350
    },
    {
      "epoch": 0.8193901154450802,
      "grad_norm": 0.920257568359375,
      "learning_rate": 0.0004095437222104594,
      "loss": 1.18,
      "step": 77400
    },
    {
      "epoch": 0.8199194372250835,
      "grad_norm": 0.9645189642906189,
      "learning_rate": 0.00040980838450137627,
      "loss": 1.1547,
      "step": 77450
    },
    {
      "epoch": 0.8204487590050867,
      "grad_norm": 0.9201644062995911,
      "learning_rate": 0.0004100730467922931,
      "loss": 1.1803,
      "step": 77500
    },
    {
      "epoch": 0.8204487590050867,
      "eval_loss": 1.0894302129745483,
      "eval_runtime": 46.7667,
      "eval_samples_per_second": 3590.801,
      "eval_steps_per_second": 448.866,
      "step": 77500
    },
    {
      "epoch": 0.82097808078509,
      "grad_norm": 1.0019315481185913,
      "learning_rate": 0.00041033770908320983,
      "loss": 1.1461,
      "step": 77550
    },
    {
      "epoch": 0.8215074025650934,
      "grad_norm": 0.9213038682937622,
      "learning_rate": 0.00041060237137412664,
      "loss": 1.1712,
      "step": 77600
    },
    {
      "epoch": 0.8220367243450967,
      "grad_norm": 0.9795243740081787,
      "learning_rate": 0.0004108670336650434,
      "loss": 1.1606,
      "step": 77650
    },
    {
      "epoch": 0.8225660461250999,
      "grad_norm": 0.9464125633239746,
      "learning_rate": 0.00041113169595596025,
      "loss": 1.1603,
      "step": 77700
    },
    {
      "epoch": 0.8230953679051032,
      "grad_norm": 0.9761998653411865,
      "learning_rate": 0.000411396358246877,
      "loss": 1.1605,
      "step": 77750
    },
    {
      "epoch": 0.8236246896851065,
      "grad_norm": 0.8797469735145569,
      "learning_rate": 0.0004116610205377938,
      "loss": 1.162,
      "step": 77800
    },
    {
      "epoch": 0.8241540114651098,
      "grad_norm": 0.9154205918312073,
      "learning_rate": 0.00041192568282871056,
      "loss": 1.1467,
      "step": 77850
    },
    {
      "epoch": 0.824683333245113,
      "grad_norm": 0.9650333523750305,
      "learning_rate": 0.00041219034511962737,
      "loss": 1.1463,
      "step": 77900
    },
    {
      "epoch": 0.8252126550251163,
      "grad_norm": 0.8142804503440857,
      "learning_rate": 0.0004124550074105441,
      "loss": 1.1671,
      "step": 77950
    },
    {
      "epoch": 0.8257419768051196,
      "grad_norm": 0.9556732773780823,
      "learning_rate": 0.000412719669701461,
      "loss": 1.1537,
      "step": 78000
    },
    {
      "epoch": 0.8257419768051196,
      "eval_loss": 1.0840786695480347,
      "eval_runtime": 46.7913,
      "eval_samples_per_second": 3588.916,
      "eval_steps_per_second": 448.631,
      "step": 78000
    },
    {
      "epoch": 0.8262712985851229,
      "grad_norm": 0.9635249972343445,
      "learning_rate": 0.00041298433199237774,
      "loss": 1.1824,
      "step": 78050
    },
    {
      "epoch": 0.8268006203651261,
      "grad_norm": 0.8967465758323669,
      "learning_rate": 0.00041324899428329454,
      "loss": 1.1549,
      "step": 78100
    },
    {
      "epoch": 0.8273299421451294,
      "grad_norm": 0.9613205790519714,
      "learning_rate": 0.0004135136565742113,
      "loss": 1.1596,
      "step": 78150
    },
    {
      "epoch": 0.8278592639251328,
      "grad_norm": 1.0799782276153564,
      "learning_rate": 0.0004137783188651281,
      "loss": 1.1512,
      "step": 78200
    },
    {
      "epoch": 0.828388585705136,
      "grad_norm": 1.0028027296066284,
      "learning_rate": 0.0004140429811560449,
      "loss": 1.1729,
      "step": 78250
    },
    {
      "epoch": 0.8289179074851393,
      "grad_norm": 1.0228660106658936,
      "learning_rate": 0.0004143076434469617,
      "loss": 1.159,
      "step": 78300
    },
    {
      "epoch": 0.8294472292651426,
      "grad_norm": 0.9384295344352722,
      "learning_rate": 0.00041457230573787847,
      "loss": 1.1445,
      "step": 78350
    },
    {
      "epoch": 0.8299765510451459,
      "grad_norm": 0.9131424427032471,
      "learning_rate": 0.0004148369680287953,
      "loss": 1.1544,
      "step": 78400
    },
    {
      "epoch": 0.8305058728251491,
      "grad_norm": 0.9976226091384888,
      "learning_rate": 0.00041510163031971203,
      "loss": 1.1582,
      "step": 78450
    },
    {
      "epoch": 0.8310351946051524,
      "grad_norm": 0.931973934173584,
      "learning_rate": 0.00041536629261062884,
      "loss": 1.1607,
      "step": 78500
    },
    {
      "epoch": 0.8310351946051524,
      "eval_loss": 1.0839194059371948,
      "eval_runtime": 46.7237,
      "eval_samples_per_second": 3594.104,
      "eval_steps_per_second": 449.279,
      "step": 78500
    },
    {
      "epoch": 0.8315645163851557,
      "grad_norm": 0.9514365196228027,
      "learning_rate": 0.00041563095490154564,
      "loss": 1.1605,
      "step": 78550
    },
    {
      "epoch": 0.832093838165159,
      "grad_norm": 0.9873310923576355,
      "learning_rate": 0.00041589561719246245,
      "loss": 1.1372,
      "step": 78600
    },
    {
      "epoch": 0.8326231599451622,
      "grad_norm": 1.0623044967651367,
      "learning_rate": 0.0004161602794833792,
      "loss": 1.1382,
      "step": 78650
    },
    {
      "epoch": 0.8331524817251655,
      "grad_norm": 0.8709690570831299,
      "learning_rate": 0.000416424941774296,
      "loss": 1.1584,
      "step": 78700
    },
    {
      "epoch": 0.8336818035051689,
      "grad_norm": 1.013666033744812,
      "learning_rate": 0.00041668960406521276,
      "loss": 1.1428,
      "step": 78750
    },
    {
      "epoch": 0.8342111252851722,
      "grad_norm": 1.0766862630844116,
      "learning_rate": 0.0004169542663561296,
      "loss": 1.1656,
      "step": 78800
    },
    {
      "epoch": 0.8347404470651754,
      "grad_norm": 0.9616497755050659,
      "learning_rate": 0.0004172189286470464,
      "loss": 1.1487,
      "step": 78850
    },
    {
      "epoch": 0.8352697688451787,
      "grad_norm": 0.9070534706115723,
      "learning_rate": 0.0004174835909379632,
      "loss": 1.1348,
      "step": 78900
    },
    {
      "epoch": 0.835799090625182,
      "grad_norm": 0.9686040878295898,
      "learning_rate": 0.00041774825322887993,
      "loss": 1.1485,
      "step": 78950
    },
    {
      "epoch": 0.8363284124051852,
      "grad_norm": 0.8868078589439392,
      "learning_rate": 0.00041801291551979674,
      "loss": 1.1601,
      "step": 79000
    },
    {
      "epoch": 0.8363284124051852,
      "eval_loss": 1.0808695554733276,
      "eval_runtime": 46.8314,
      "eval_samples_per_second": 3585.843,
      "eval_steps_per_second": 448.246,
      "step": 79000
    },
    {
      "epoch": 0.8368577341851885,
      "grad_norm": 1.120559811592102,
      "learning_rate": 0.0004182775778107135,
      "loss": 1.1706,
      "step": 79050
    },
    {
      "epoch": 0.8373870559651918,
      "grad_norm": 0.9742100834846497,
      "learning_rate": 0.00041854224010163036,
      "loss": 1.167,
      "step": 79100
    },
    {
      "epoch": 0.8379163777451951,
      "grad_norm": 0.9163135290145874,
      "learning_rate": 0.0004188069023925471,
      "loss": 1.1592,
      "step": 79150
    },
    {
      "epoch": 0.8384456995251983,
      "grad_norm": 0.8495098352432251,
      "learning_rate": 0.0004190715646834639,
      "loss": 1.1674,
      "step": 79200
    },
    {
      "epoch": 0.8389750213052016,
      "grad_norm": 0.844695508480072,
      "learning_rate": 0.00041933622697438067,
      "loss": 1.1507,
      "step": 79250
    },
    {
      "epoch": 0.8395043430852049,
      "grad_norm": 0.9704714417457581,
      "learning_rate": 0.0004196008892652975,
      "loss": 1.1348,
      "step": 79300
    },
    {
      "epoch": 0.8400336648652083,
      "grad_norm": 0.9497544765472412,
      "learning_rate": 0.0004198655515562142,
      "loss": 1.1503,
      "step": 79350
    },
    {
      "epoch": 0.8405629866452115,
      "grad_norm": 0.982483446598053,
      "learning_rate": 0.0004201302138471311,
      "loss": 1.1437,
      "step": 79400
    },
    {
      "epoch": 0.8410923084252148,
      "grad_norm": 0.9246386885643005,
      "learning_rate": 0.00042039487613804784,
      "loss": 1.1538,
      "step": 79450
    },
    {
      "epoch": 0.8416216302052181,
      "grad_norm": 0.9482228755950928,
      "learning_rate": 0.00042065953842896465,
      "loss": 1.1649,
      "step": 79500
    },
    {
      "epoch": 0.8416216302052181,
      "eval_loss": 1.0776242017745972,
      "eval_runtime": 46.7479,
      "eval_samples_per_second": 3592.248,
      "eval_steps_per_second": 449.047,
      "step": 79500
    },
    {
      "epoch": 0.8421509519852214,
      "grad_norm": 0.9753419756889343,
      "learning_rate": 0.00042092420071988145,
      "loss": 1.1674,
      "step": 79550
    },
    {
      "epoch": 0.8426802737652246,
      "grad_norm": 0.99880051612854,
      "learning_rate": 0.0004211888630107982,
      "loss": 1.1602,
      "step": 79600
    },
    {
      "epoch": 0.8432095955452279,
      "grad_norm": 0.9137631058692932,
      "learning_rate": 0.00042145352530171507,
      "loss": 1.1509,
      "step": 79650
    },
    {
      "epoch": 0.8437389173252312,
      "grad_norm": 0.9559160470962524,
      "learning_rate": 0.0004217181875926318,
      "loss": 1.1288,
      "step": 79700
    },
    {
      "epoch": 0.8442682391052344,
      "grad_norm": 1.0704199075698853,
      "learning_rate": 0.00042198284988354863,
      "loss": 1.1557,
      "step": 79750
    },
    {
      "epoch": 0.8447975608852377,
      "grad_norm": 0.9094926118850708,
      "learning_rate": 0.0004222475121744654,
      "loss": 1.1523,
      "step": 79800
    },
    {
      "epoch": 0.845326882665241,
      "grad_norm": 1.020423173904419,
      "learning_rate": 0.0004225121744653822,
      "loss": 1.1533,
      "step": 79850
    },
    {
      "epoch": 0.8458562044452443,
      "grad_norm": 0.9462448954582214,
      "learning_rate": 0.00042277683675629894,
      "loss": 1.1498,
      "step": 79900
    },
    {
      "epoch": 0.8463855262252475,
      "grad_norm": 0.9185398817062378,
      "learning_rate": 0.0004230414990472158,
      "loss": 1.1406,
      "step": 79950
    },
    {
      "epoch": 0.8469148480052509,
      "grad_norm": 0.9799256920814514,
      "learning_rate": 0.0004233008680923142,
      "loss": 1.1662,
      "step": 80000
    },
    {
      "epoch": 0.8469148480052509,
      "eval_loss": 1.0751229524612427,
      "eval_runtime": 46.7836,
      "eval_samples_per_second": 3589.507,
      "eval_steps_per_second": 448.704,
      "step": 80000
    },
    {
      "epoch": 0.8474441697852542,
      "grad_norm": 1.066315770149231,
      "learning_rate": 0.000423565530383231,
      "loss": 1.1703,
      "step": 80050
    },
    {
      "epoch": 0.8479734915652575,
      "grad_norm": 0.984711766242981,
      "learning_rate": 0.0004238301926741478,
      "loss": 1.1623,
      "step": 80100
    },
    {
      "epoch": 0.8485028133452607,
      "grad_norm": 0.9967517256736755,
      "learning_rate": 0.0004240948549650646,
      "loss": 1.1635,
      "step": 80150
    },
    {
      "epoch": 0.849032135125264,
      "grad_norm": 0.958301842212677,
      "learning_rate": 0.0004243595172559814,
      "loss": 1.1563,
      "step": 80200
    },
    {
      "epoch": 0.8495614569052673,
      "grad_norm": 0.9230239391326904,
      "learning_rate": 0.0004246241795468982,
      "loss": 1.1412,
      "step": 80250
    },
    {
      "epoch": 0.8500907786852706,
      "grad_norm": 0.9757201075553894,
      "learning_rate": 0.00042488884183781495,
      "loss": 1.1478,
      "step": 80300
    },
    {
      "epoch": 0.8506201004652738,
      "grad_norm": 0.9658325910568237,
      "learning_rate": 0.00042515350412873176,
      "loss": 1.155,
      "step": 80350
    },
    {
      "epoch": 0.8511494222452771,
      "grad_norm": 1.028527855873108,
      "learning_rate": 0.0004254181664196485,
      "loss": 1.1543,
      "step": 80400
    },
    {
      "epoch": 0.8516787440252804,
      "grad_norm": 0.9211080074310303,
      "learning_rate": 0.0004256828287105654,
      "loss": 1.1531,
      "step": 80450
    },
    {
      "epoch": 0.8522080658052837,
      "grad_norm": 1.0523978471755981,
      "learning_rate": 0.00042594749100148213,
      "loss": 1.1619,
      "step": 80500
    },
    {
      "epoch": 0.8522080658052837,
      "eval_loss": 1.0742743015289307,
      "eval_runtime": 46.7817,
      "eval_samples_per_second": 3589.652,
      "eval_steps_per_second": 448.723,
      "step": 80500
    },
    {
      "epoch": 0.8527373875852869,
      "grad_norm": 1.0685231685638428,
      "learning_rate": 0.00042621215329239893,
      "loss": 1.1542,
      "step": 80550
    },
    {
      "epoch": 0.8532667093652903,
      "grad_norm": 0.9479187726974487,
      "learning_rate": 0.0004264768155833157,
      "loss": 1.1535,
      "step": 80600
    },
    {
      "epoch": 0.8537960311452936,
      "grad_norm": 0.960000216960907,
      "learning_rate": 0.0004267414778742325,
      "loss": 1.1433,
      "step": 80650
    },
    {
      "epoch": 0.8543253529252968,
      "grad_norm": 0.9095754027366638,
      "learning_rate": 0.00042700614016514925,
      "loss": 1.1417,
      "step": 80700
    },
    {
      "epoch": 0.8548546747053001,
      "grad_norm": 0.8921100497245789,
      "learning_rate": 0.0004272708024560661,
      "loss": 1.1338,
      "step": 80750
    },
    {
      "epoch": 0.8553839964853034,
      "grad_norm": 1.041954517364502,
      "learning_rate": 0.00042753546474698286,
      "loss": 1.1416,
      "step": 80800
    },
    {
      "epoch": 0.8559133182653067,
      "grad_norm": 0.8548012971878052,
      "learning_rate": 0.00042780012703789967,
      "loss": 1.1615,
      "step": 80850
    },
    {
      "epoch": 0.8564426400453099,
      "grad_norm": 0.9459101557731628,
      "learning_rate": 0.0004280647893288164,
      "loss": 1.1474,
      "step": 80900
    },
    {
      "epoch": 0.8569719618253132,
      "grad_norm": 0.9578098058700562,
      "learning_rate": 0.0004283294516197332,
      "loss": 1.1436,
      "step": 80950
    },
    {
      "epoch": 0.8575012836053165,
      "grad_norm": 0.9275949597358704,
      "learning_rate": 0.00042859411391065003,
      "loss": 1.1454,
      "step": 81000
    },
    {
      "epoch": 0.8575012836053165,
      "eval_loss": 1.0724289417266846,
      "eval_runtime": 46.7431,
      "eval_samples_per_second": 3592.618,
      "eval_steps_per_second": 449.093,
      "step": 81000
    },
    {
      "epoch": 0.8580306053853198,
      "grad_norm": 0.9950217604637146,
      "learning_rate": 0.00042885877620156684,
      "loss": 1.1369,
      "step": 81050
    },
    {
      "epoch": 0.858559927165323,
      "grad_norm": 0.9948289394378662,
      "learning_rate": 0.0004291234384924836,
      "loss": 1.1357,
      "step": 81100
    },
    {
      "epoch": 0.8590892489453263,
      "grad_norm": 0.9384676218032837,
      "learning_rate": 0.0004293881007834004,
      "loss": 1.1481,
      "step": 81150
    },
    {
      "epoch": 0.8596185707253297,
      "grad_norm": 1.0800557136535645,
      "learning_rate": 0.00042965276307431715,
      "loss": 1.1626,
      "step": 81200
    },
    {
      "epoch": 0.860147892505333,
      "grad_norm": 0.9587424993515015,
      "learning_rate": 0.00042991742536523396,
      "loss": 1.1264,
      "step": 81250
    },
    {
      "epoch": 0.8606772142853362,
      "grad_norm": 0.9544450640678406,
      "learning_rate": 0.00043018208765615077,
      "loss": 1.1738,
      "step": 81300
    },
    {
      "epoch": 0.8612065360653395,
      "grad_norm": 0.9237359166145325,
      "learning_rate": 0.00043044674994706757,
      "loss": 1.1476,
      "step": 81350
    },
    {
      "epoch": 0.8617358578453428,
      "grad_norm": 1.005654215812683,
      "learning_rate": 0.0004307114122379843,
      "loss": 1.1296,
      "step": 81400
    },
    {
      "epoch": 0.862265179625346,
      "grad_norm": 0.9661707878112793,
      "learning_rate": 0.00043097607452890113,
      "loss": 1.1277,
      "step": 81450
    },
    {
      "epoch": 0.8627945014053493,
      "grad_norm": 0.976585865020752,
      "learning_rate": 0.0004312407368198179,
      "loss": 1.1623,
      "step": 81500
    },
    {
      "epoch": 0.8627945014053493,
      "eval_loss": 1.064895510673523,
      "eval_runtime": 46.7016,
      "eval_samples_per_second": 3595.81,
      "eval_steps_per_second": 449.492,
      "step": 81500
    },
    {
      "epoch": 0.8633238231853526,
      "grad_norm": 0.9185889959335327,
      "learning_rate": 0.00043150539911073475,
      "loss": 1.1517,
      "step": 81550
    },
    {
      "epoch": 0.8638531449653559,
      "grad_norm": 0.9048147201538086,
      "learning_rate": 0.0004317700614016515,
      "loss": 1.1408,
      "step": 81600
    },
    {
      "epoch": 0.8643824667453591,
      "grad_norm": 0.8985114693641663,
      "learning_rate": 0.0004320347236925683,
      "loss": 1.1624,
      "step": 81650
    },
    {
      "epoch": 0.8649117885253624,
      "grad_norm": 0.9428784847259521,
      "learning_rate": 0.00043229938598348506,
      "loss": 1.1407,
      "step": 81700
    },
    {
      "epoch": 0.8654411103053657,
      "grad_norm": 0.8960122466087341,
      "learning_rate": 0.00043256404827440186,
      "loss": 1.1427,
      "step": 81750
    },
    {
      "epoch": 0.8659704320853691,
      "grad_norm": 0.9591039419174194,
      "learning_rate": 0.0004328287105653186,
      "loss": 1.1482,
      "step": 81800
    },
    {
      "epoch": 0.8664997538653723,
      "grad_norm": 0.8678992390632629,
      "learning_rate": 0.0004330933728562355,
      "loss": 1.1542,
      "step": 81850
    },
    {
      "epoch": 0.8670290756453756,
      "grad_norm": 0.958520770072937,
      "learning_rate": 0.00043335803514715223,
      "loss": 1.1264,
      "step": 81900
    },
    {
      "epoch": 0.8675583974253789,
      "grad_norm": 0.9313967823982239,
      "learning_rate": 0.00043362269743806904,
      "loss": 1.1618,
      "step": 81950
    },
    {
      "epoch": 0.8680877192053822,
      "grad_norm": 1.0521702766418457,
      "learning_rate": 0.00043388206648316746,
      "loss": 1.1229,
      "step": 82000
    },
    {
      "epoch": 0.8680877192053822,
      "eval_loss": 1.062590479850769,
      "eval_runtime": 46.7943,
      "eval_samples_per_second": 3588.687,
      "eval_steps_per_second": 448.602,
      "step": 82000
    },
    {
      "epoch": 0.8686170409853854,
      "grad_norm": 0.9148378372192383,
      "learning_rate": 0.00043414672877408427,
      "loss": 1.1458,
      "step": 82050
    },
    {
      "epoch": 0.8691463627653887,
      "grad_norm": 0.9396401047706604,
      "learning_rate": 0.00043441139106500107,
      "loss": 1.1463,
      "step": 82100
    },
    {
      "epoch": 0.869675684545392,
      "grad_norm": 0.9837103486061096,
      "learning_rate": 0.0004346760533559179,
      "loss": 1.143,
      "step": 82150
    },
    {
      "epoch": 0.8702050063253953,
      "grad_norm": 0.9374459385871887,
      "learning_rate": 0.00043494071564683463,
      "loss": 1.1283,
      "step": 82200
    },
    {
      "epoch": 0.8707343281053985,
      "grad_norm": 0.9324235916137695,
      "learning_rate": 0.00043520537793775144,
      "loss": 1.1302,
      "step": 82250
    },
    {
      "epoch": 0.8712636498854018,
      "grad_norm": 0.9403324723243713,
      "learning_rate": 0.0004354700402286682,
      "loss": 1.1385,
      "step": 82300
    },
    {
      "epoch": 0.8717929716654051,
      "grad_norm": 0.999893069267273,
      "learning_rate": 0.000435734702519585,
      "loss": 1.1555,
      "step": 82350
    },
    {
      "epoch": 0.8723222934454083,
      "grad_norm": 1.0716549158096313,
      "learning_rate": 0.0004359993648105018,
      "loss": 1.1377,
      "step": 82400
    },
    {
      "epoch": 0.8728516152254117,
      "grad_norm": 0.8957657814025879,
      "learning_rate": 0.0004362640271014186,
      "loss": 1.1187,
      "step": 82450
    },
    {
      "epoch": 0.873380937005415,
      "grad_norm": 0.9034764766693115,
      "learning_rate": 0.00043652868939233536,
      "loss": 1.1448,
      "step": 82500
    },
    {
      "epoch": 0.873380937005415,
      "eval_loss": 1.0635472536087036,
      "eval_runtime": 46.7757,
      "eval_samples_per_second": 3590.114,
      "eval_steps_per_second": 448.78,
      "step": 82500
    },
    {
      "epoch": 0.8739102587854183,
      "grad_norm": 0.9856154322624207,
      "learning_rate": 0.00043679335168325217,
      "loss": 1.1339,
      "step": 82550
    },
    {
      "epoch": 0.8744395805654215,
      "grad_norm": 1.015520453453064,
      "learning_rate": 0.0004370580139741689,
      "loss": 1.1457,
      "step": 82600
    },
    {
      "epoch": 0.8749689023454248,
      "grad_norm": 0.8598728179931641,
      "learning_rate": 0.0004373226762650858,
      "loss": 1.1582,
      "step": 82650
    },
    {
      "epoch": 0.8754982241254281,
      "grad_norm": 1.053473949432373,
      "learning_rate": 0.00043758733855600254,
      "loss": 1.1459,
      "step": 82700
    },
    {
      "epoch": 0.8760275459054314,
      "grad_norm": 0.9714133739471436,
      "learning_rate": 0.00043785200084691934,
      "loss": 1.134,
      "step": 82750
    },
    {
      "epoch": 0.8765568676854346,
      "grad_norm": 0.9154432415962219,
      "learning_rate": 0.00043811666313783615,
      "loss": 1.1171,
      "step": 82800
    },
    {
      "epoch": 0.8770861894654379,
      "grad_norm": 0.9888828992843628,
      "learning_rate": 0.0004383813254287529,
      "loss": 1.1431,
      "step": 82850
    },
    {
      "epoch": 0.8776155112454412,
      "grad_norm": 1.0127233266830444,
      "learning_rate": 0.0004386459877196697,
      "loss": 1.1457,
      "step": 82900
    },
    {
      "epoch": 0.8781448330254445,
      "grad_norm": 0.9221625328063965,
      "learning_rate": 0.0004389106500105865,
      "loss": 1.1394,
      "step": 82950
    },
    {
      "epoch": 0.8786741548054477,
      "grad_norm": 0.8956946730613708,
      "learning_rate": 0.0004391753123015033,
      "loss": 1.1256,
      "step": 83000
    },
    {
      "epoch": 0.8786741548054477,
      "eval_loss": 1.0591977834701538,
      "eval_runtime": 46.8425,
      "eval_samples_per_second": 3584.995,
      "eval_steps_per_second": 448.14,
      "step": 83000
    },
    {
      "epoch": 0.8792034765854511,
      "grad_norm": 0.9244242310523987,
      "learning_rate": 0.0004394399745924201,
      "loss": 1.1449,
      "step": 83050
    },
    {
      "epoch": 0.8797327983654544,
      "grad_norm": 0.8762140274047852,
      "learning_rate": 0.0004397046368833369,
      "loss": 1.1224,
      "step": 83100
    },
    {
      "epoch": 0.8802621201454576,
      "grad_norm": 0.9026201963424683,
      "learning_rate": 0.00043996929917425364,
      "loss": 1.1273,
      "step": 83150
    },
    {
      "epoch": 0.8807914419254609,
      "grad_norm": 0.9533647298812866,
      "learning_rate": 0.0004402339614651705,
      "loss": 1.146,
      "step": 83200
    },
    {
      "epoch": 0.8813207637054642,
      "grad_norm": 1.16028892993927,
      "learning_rate": 0.00044049862375608725,
      "loss": 1.1257,
      "step": 83250
    },
    {
      "epoch": 0.8818500854854675,
      "grad_norm": 0.8896175026893616,
      "learning_rate": 0.00044076328604700406,
      "loss": 1.1442,
      "step": 83300
    },
    {
      "epoch": 0.8823794072654707,
      "grad_norm": 0.904447615146637,
      "learning_rate": 0.0004410279483379208,
      "loss": 1.1314,
      "step": 83350
    },
    {
      "epoch": 0.882908729045474,
      "grad_norm": 0.9082408547401428,
      "learning_rate": 0.0004412926106288376,
      "loss": 1.1271,
      "step": 83400
    },
    {
      "epoch": 0.8834380508254773,
      "grad_norm": 0.9664207696914673,
      "learning_rate": 0.00044155727291975437,
      "loss": 1.134,
      "step": 83450
    },
    {
      "epoch": 0.8839673726054806,
      "grad_norm": 0.9521979689598083,
      "learning_rate": 0.00044182193521067123,
      "loss": 1.1382,
      "step": 83500
    },
    {
      "epoch": 0.8839673726054806,
      "eval_loss": 1.0538256168365479,
      "eval_runtime": 46.7903,
      "eval_samples_per_second": 3588.993,
      "eval_steps_per_second": 448.64,
      "step": 83500
    },
    {
      "epoch": 0.8844966943854838,
      "grad_norm": 0.9378475546836853,
      "learning_rate": 0.000442086597501588,
      "loss": 1.1395,
      "step": 83550
    },
    {
      "epoch": 0.8850260161654872,
      "grad_norm": 0.9935441613197327,
      "learning_rate": 0.0004423512597925048,
      "loss": 1.152,
      "step": 83600
    },
    {
      "epoch": 0.8855553379454905,
      "grad_norm": 0.951820969581604,
      "learning_rate": 0.00044261592208342154,
      "loss": 1.1496,
      "step": 83650
    },
    {
      "epoch": 0.8860846597254938,
      "grad_norm": 0.9252126216888428,
      "learning_rate": 0.00044288058437433835,
      "loss": 1.1309,
      "step": 83700
    },
    {
      "epoch": 0.886613981505497,
      "grad_norm": 1.0219972133636475,
      "learning_rate": 0.00044314524666525516,
      "loss": 1.1326,
      "step": 83750
    },
    {
      "epoch": 0.8871433032855003,
      "grad_norm": 0.9692725539207458,
      "learning_rate": 0.00044340990895617196,
      "loss": 1.1415,
      "step": 83800
    },
    {
      "epoch": 0.8876726250655036,
      "grad_norm": 0.9723856449127197,
      "learning_rate": 0.0004436745712470887,
      "loss": 1.1456,
      "step": 83850
    },
    {
      "epoch": 0.8882019468455069,
      "grad_norm": 0.9194416999816895,
      "learning_rate": 0.0004439392335380055,
      "loss": 1.1427,
      "step": 83900
    },
    {
      "epoch": 0.8887312686255101,
      "grad_norm": 0.9915862083435059,
      "learning_rate": 0.0004442038958289223,
      "loss": 1.1509,
      "step": 83950
    },
    {
      "epoch": 0.8892605904055134,
      "grad_norm": 1.0231106281280518,
      "learning_rate": 0.0004444632648740208,
      "loss": 1.135,
      "step": 84000
    },
    {
      "epoch": 0.8892605904055134,
      "eval_loss": 1.0498520135879517,
      "eval_runtime": 46.7107,
      "eval_samples_per_second": 3595.111,
      "eval_steps_per_second": 449.405,
      "step": 84000
    },
    {
      "epoch": 0.8897899121855167,
      "grad_norm": 0.995075523853302,
      "learning_rate": 0.00044472792716493756,
      "loss": 1.1348,
      "step": 84050
    },
    {
      "epoch": 0.8903192339655199,
      "grad_norm": 0.952046811580658,
      "learning_rate": 0.00044499258945585436,
      "loss": 1.1653,
      "step": 84100
    },
    {
      "epoch": 0.8908485557455232,
      "grad_norm": 0.9737132787704468,
      "learning_rate": 0.0004452572517467711,
      "loss": 1.1351,
      "step": 84150
    },
    {
      "epoch": 0.8913778775255266,
      "grad_norm": 0.9322331547737122,
      "learning_rate": 0.0004455219140376879,
      "loss": 1.1487,
      "step": 84200
    },
    {
      "epoch": 0.8919071993055299,
      "grad_norm": 0.9193778038024902,
      "learning_rate": 0.0004457865763286047,
      "loss": 1.1112,
      "step": 84250
    },
    {
      "epoch": 0.8924365210855331,
      "grad_norm": 0.9050836563110352,
      "learning_rate": 0.00044605123861952154,
      "loss": 1.1402,
      "step": 84300
    },
    {
      "epoch": 0.8929658428655364,
      "grad_norm": 0.9295579195022583,
      "learning_rate": 0.0004463159009104383,
      "loss": 1.1234,
      "step": 84350
    },
    {
      "epoch": 0.8934951646455397,
      "grad_norm": 0.96186763048172,
      "learning_rate": 0.0004465805632013551,
      "loss": 1.1324,
      "step": 84400
    },
    {
      "epoch": 0.894024486425543,
      "grad_norm": 0.9409224390983582,
      "learning_rate": 0.00044684522549227185,
      "loss": 1.1299,
      "step": 84450
    },
    {
      "epoch": 0.8945538082055462,
      "grad_norm": 0.908923864364624,
      "learning_rate": 0.00044710988778318866,
      "loss": 1.1389,
      "step": 84500
    },
    {
      "epoch": 0.8945538082055462,
      "eval_loss": 1.0494270324707031,
      "eval_runtime": 46.852,
      "eval_samples_per_second": 3584.265,
      "eval_steps_per_second": 448.049,
      "step": 84500
    },
    {
      "epoch": 0.8950831299855495,
      "grad_norm": 0.9007051587104797,
      "learning_rate": 0.0004473745500741054,
      "loss": 1.1355,
      "step": 84550
    },
    {
      "epoch": 0.8956124517655528,
      "grad_norm": 0.990279495716095,
      "learning_rate": 0.00044763921236502227,
      "loss": 1.1549,
      "step": 84600
    },
    {
      "epoch": 0.8961417735455561,
      "grad_norm": 0.8916187286376953,
      "learning_rate": 0.000447903874655939,
      "loss": 1.1339,
      "step": 84650
    },
    {
      "epoch": 0.8966710953255593,
      "grad_norm": 0.91227787733078,
      "learning_rate": 0.00044816853694685583,
      "loss": 1.1404,
      "step": 84700
    },
    {
      "epoch": 0.8972004171055626,
      "grad_norm": 0.9733366370201111,
      "learning_rate": 0.0004484331992377726,
      "loss": 1.1365,
      "step": 84750
    },
    {
      "epoch": 0.897729738885566,
      "grad_norm": 0.9155610799789429,
      "learning_rate": 0.0004486978615286894,
      "loss": 1.1261,
      "step": 84800
    },
    {
      "epoch": 0.8982590606655692,
      "grad_norm": 0.9017289280891418,
      "learning_rate": 0.0004489625238196062,
      "loss": 1.1429,
      "step": 84850
    },
    {
      "epoch": 0.8987883824455725,
      "grad_norm": 0.9051501154899597,
      "learning_rate": 0.000449227186110523,
      "loss": 1.1289,
      "step": 84900
    },
    {
      "epoch": 0.8993177042255758,
      "grad_norm": 1.1229547262191772,
      "learning_rate": 0.00044949184840143976,
      "loss": 1.1233,
      "step": 84950
    },
    {
      "epoch": 0.8998470260055791,
      "grad_norm": 0.9185437560081482,
      "learning_rate": 0.00044975651069235656,
      "loss": 1.1251,
      "step": 85000
    },
    {
      "epoch": 0.8998470260055791,
      "eval_loss": 1.0486550331115723,
      "eval_runtime": 46.7419,
      "eval_samples_per_second": 3592.711,
      "eval_steps_per_second": 449.105,
      "step": 85000
    },
    {
      "epoch": 0.9003763477855823,
      "grad_norm": 1.0157192945480347,
      "learning_rate": 0.0004500211729832733,
      "loss": 1.1312,
      "step": 85050
    },
    {
      "epoch": 0.9009056695655856,
      "grad_norm": 0.9666147232055664,
      "learning_rate": 0.0004502858352741901,
      "loss": 1.1285,
      "step": 85100
    },
    {
      "epoch": 0.9014349913455889,
      "grad_norm": 0.969510018825531,
      "learning_rate": 0.00045055049756510693,
      "loss": 1.1481,
      "step": 85150
    },
    {
      "epoch": 0.9019643131255922,
      "grad_norm": 1.0003254413604736,
      "learning_rate": 0.00045081515985602374,
      "loss": 1.1216,
      "step": 85200
    },
    {
      "epoch": 0.9024936349055954,
      "grad_norm": 0.9577475190162659,
      "learning_rate": 0.0004510798221469405,
      "loss": 1.1206,
      "step": 85250
    },
    {
      "epoch": 0.9030229566855987,
      "grad_norm": 0.984376847743988,
      "learning_rate": 0.0004513444844378573,
      "loss": 1.147,
      "step": 85300
    },
    {
      "epoch": 0.903552278465602,
      "grad_norm": 0.9626569151878357,
      "learning_rate": 0.00045160914672877405,
      "loss": 1.1433,
      "step": 85350
    },
    {
      "epoch": 0.9040816002456054,
      "grad_norm": 0.9219070076942444,
      "learning_rate": 0.0004518738090196909,
      "loss": 1.1313,
      "step": 85400
    },
    {
      "epoch": 0.9046109220256086,
      "grad_norm": 0.9798258543014526,
      "learning_rate": 0.00045213847131060766,
      "loss": 1.1178,
      "step": 85450
    },
    {
      "epoch": 0.9051402438056119,
      "grad_norm": 0.8769108057022095,
      "learning_rate": 0.00045240313360152447,
      "loss": 1.1298,
      "step": 85500
    },
    {
      "epoch": 0.9051402438056119,
      "eval_loss": 1.0465617179870605,
      "eval_runtime": 46.8009,
      "eval_samples_per_second": 3588.178,
      "eval_steps_per_second": 448.538,
      "step": 85500
    },
    {
      "epoch": 0.9056695655856152,
      "grad_norm": 0.9293339252471924,
      "learning_rate": 0.0004526677958924413,
      "loss": 1.122,
      "step": 85550
    },
    {
      "epoch": 0.9061988873656185,
      "grad_norm": 0.9045292735099792,
      "learning_rate": 0.00045293245818335803,
      "loss": 1.1311,
      "step": 85600
    },
    {
      "epoch": 0.9067282091456217,
      "grad_norm": 0.9431077837944031,
      "learning_rate": 0.00045319712047427483,
      "loss": 1.1362,
      "step": 85650
    },
    {
      "epoch": 0.907257530925625,
      "grad_norm": 0.9290808439254761,
      "learning_rate": 0.00045346178276519164,
      "loss": 1.131,
      "step": 85700
    },
    {
      "epoch": 0.9077868527056283,
      "grad_norm": 0.919910728931427,
      "learning_rate": 0.00045372644505610845,
      "loss": 1.1216,
      "step": 85750
    },
    {
      "epoch": 0.9083161744856315,
      "grad_norm": 0.9742030501365662,
      "learning_rate": 0.0004539911073470252,
      "loss": 1.1264,
      "step": 85800
    },
    {
      "epoch": 0.9088454962656348,
      "grad_norm": 0.8210871815681458,
      "learning_rate": 0.000454255769637942,
      "loss": 1.1323,
      "step": 85850
    },
    {
      "epoch": 0.9093748180456381,
      "grad_norm": 1.028747320175171,
      "learning_rate": 0.00045452043192885876,
      "loss": 1.1244,
      "step": 85900
    },
    {
      "epoch": 0.9099041398256414,
      "grad_norm": 0.9648101329803467,
      "learning_rate": 0.0004547850942197756,
      "loss": 1.1157,
      "step": 85950
    },
    {
      "epoch": 0.9104334616056446,
      "grad_norm": 0.9730079174041748,
      "learning_rate": 0.0004550497565106924,
      "loss": 1.1182,
      "step": 86000
    },
    {
      "epoch": 0.9104334616056446,
      "eval_loss": 1.0388503074645996,
      "eval_runtime": 46.7623,
      "eval_samples_per_second": 3591.141,
      "eval_steps_per_second": 448.909,
      "step": 86000
    },
    {
      "epoch": 0.910962783385648,
      "grad_norm": 0.8969720005989075,
      "learning_rate": 0.0004553091255557908,
      "loss": 1.129,
      "step": 86050
    },
    {
      "epoch": 0.9114921051656513,
      "grad_norm": 0.902022123336792,
      "learning_rate": 0.0004555737878467076,
      "loss": 1.1423,
      "step": 86100
    },
    {
      "epoch": 0.9120214269456546,
      "grad_norm": 0.8689268827438354,
      "learning_rate": 0.0004558384501376244,
      "loss": 1.1333,
      "step": 86150
    },
    {
      "epoch": 0.9125507487256578,
      "grad_norm": 0.9552074074745178,
      "learning_rate": 0.0004561031124285412,
      "loss": 1.1361,
      "step": 86200
    },
    {
      "epoch": 0.9130800705056611,
      "grad_norm": 0.9218306541442871,
      "learning_rate": 0.000456367774719458,
      "loss": 1.1601,
      "step": 86250
    },
    {
      "epoch": 0.9136093922856644,
      "grad_norm": 1.0276464223861694,
      "learning_rate": 0.0004566324370103748,
      "loss": 1.1372,
      "step": 86300
    },
    {
      "epoch": 0.9141387140656677,
      "grad_norm": 0.9757161736488342,
      "learning_rate": 0.0004568970993012916,
      "loss": 1.1135,
      "step": 86350
    },
    {
      "epoch": 0.9146680358456709,
      "grad_norm": 1.0001015663146973,
      "learning_rate": 0.00045716176159220833,
      "loss": 1.1227,
      "step": 86400
    },
    {
      "epoch": 0.9151973576256742,
      "grad_norm": 0.9553539156913757,
      "learning_rate": 0.00045742642388312514,
      "loss": 1.1342,
      "step": 86450
    },
    {
      "epoch": 0.9157266794056775,
      "grad_norm": 0.944253146648407,
      "learning_rate": 0.00045769108617404195,
      "loss": 1.1214,
      "step": 86500
    },
    {
      "epoch": 0.9157266794056775,
      "eval_loss": 1.0387451648712158,
      "eval_runtime": 46.6992,
      "eval_samples_per_second": 3595.996,
      "eval_steps_per_second": 449.516,
      "step": 86500
    },
    {
      "epoch": 0.9162560011856807,
      "grad_norm": 0.9074612855911255,
      "learning_rate": 0.00045795574846495875,
      "loss": 1.1276,
      "step": 86550
    },
    {
      "epoch": 0.916785322965684,
      "grad_norm": 1.0133401155471802,
      "learning_rate": 0.0004582204107558755,
      "loss": 1.1316,
      "step": 86600
    },
    {
      "epoch": 0.9173146447456874,
      "grad_norm": 1.0074838399887085,
      "learning_rate": 0.0004584850730467923,
      "loss": 1.1252,
      "step": 86650
    },
    {
      "epoch": 0.9178439665256907,
      "grad_norm": 0.9750067591667175,
      "learning_rate": 0.00045874973533770907,
      "loss": 1.127,
      "step": 86700
    },
    {
      "epoch": 0.9183732883056939,
      "grad_norm": 0.9909957051277161,
      "learning_rate": 0.00045901439762862593,
      "loss": 1.1275,
      "step": 86750
    },
    {
      "epoch": 0.9189026100856972,
      "grad_norm": 0.9793978929519653,
      "learning_rate": 0.0004592790599195427,
      "loss": 1.145,
      "step": 86800
    },
    {
      "epoch": 0.9194319318657005,
      "grad_norm": 0.9315019249916077,
      "learning_rate": 0.0004595437222104595,
      "loss": 1.1252,
      "step": 86850
    },
    {
      "epoch": 0.9199612536457038,
      "grad_norm": 0.9334002733230591,
      "learning_rate": 0.00045980838450137624,
      "loss": 1.1291,
      "step": 86900
    },
    {
      "epoch": 0.920490575425707,
      "grad_norm": 1.0765784978866577,
      "learning_rate": 0.00046007304679229305,
      "loss": 1.1232,
      "step": 86950
    },
    {
      "epoch": 0.9210198972057103,
      "grad_norm": 0.9064945578575134,
      "learning_rate": 0.0004603377090832098,
      "loss": 1.126,
      "step": 87000
    },
    {
      "epoch": 0.9210198972057103,
      "eval_loss": 1.0362601280212402,
      "eval_runtime": 46.7664,
      "eval_samples_per_second": 3590.829,
      "eval_steps_per_second": 448.87,
      "step": 87000
    },
    {
      "epoch": 0.9215492189857136,
      "grad_norm": 0.9720485806465149,
      "learning_rate": 0.00046060237137412666,
      "loss": 1.1203,
      "step": 87050
    },
    {
      "epoch": 0.9220785407657169,
      "grad_norm": 0.9099822044372559,
      "learning_rate": 0.0004608670336650434,
      "loss": 1.1326,
      "step": 87100
    },
    {
      "epoch": 0.9226078625457201,
      "grad_norm": 0.8788437843322754,
      "learning_rate": 0.0004611316959559602,
      "loss": 1.1194,
      "step": 87150
    },
    {
      "epoch": 0.9231371843257234,
      "grad_norm": 0.9242592453956604,
      "learning_rate": 0.00046139635824687697,
      "loss": 1.1178,
      "step": 87200
    },
    {
      "epoch": 0.9236665061057268,
      "grad_norm": 1.010781168937683,
      "learning_rate": 0.0004616610205377938,
      "loss": 1.1152,
      "step": 87250
    },
    {
      "epoch": 0.92419582788573,
      "grad_norm": 0.919719934463501,
      "learning_rate": 0.00046192568282871053,
      "loss": 1.1329,
      "step": 87300
    },
    {
      "epoch": 0.9247251496657333,
      "grad_norm": 1.0068187713623047,
      "learning_rate": 0.00046218505187380906,
      "loss": 1.1284,
      "step": 87350
    },
    {
      "epoch": 0.9252544714457366,
      "grad_norm": 0.8204857110977173,
      "learning_rate": 0.0004624497141647258,
      "loss": 1.1198,
      "step": 87400
    },
    {
      "epoch": 0.9257837932257399,
      "grad_norm": 1.0675301551818848,
      "learning_rate": 0.0004627143764556426,
      "loss": 1.1145,
      "step": 87450
    },
    {
      "epoch": 0.9263131150057431,
      "grad_norm": 1.0133029222488403,
      "learning_rate": 0.0004629790387465594,
      "loss": 1.1128,
      "step": 87500
    },
    {
      "epoch": 0.9263131150057431,
      "eval_loss": 1.035906195640564,
      "eval_runtime": 46.9233,
      "eval_samples_per_second": 3578.817,
      "eval_steps_per_second": 447.368,
      "step": 87500
    },
    {
      "epoch": 0.9268424367857464,
      "grad_norm": 0.9024893045425415,
      "learning_rate": 0.0004632437010374762,
      "loss": 1.1125,
      "step": 87550
    },
    {
      "epoch": 0.9273717585657497,
      "grad_norm": 0.8979990482330322,
      "learning_rate": 0.000463508363328393,
      "loss": 1.138,
      "step": 87600
    },
    {
      "epoch": 0.927901080345753,
      "grad_norm": 0.9391050934791565,
      "learning_rate": 0.0004637730256193098,
      "loss": 1.1122,
      "step": 87650
    },
    {
      "epoch": 0.9284304021257562,
      "grad_norm": 0.916864275932312,
      "learning_rate": 0.00046403768791022655,
      "loss": 1.1478,
      "step": 87700
    },
    {
      "epoch": 0.9289597239057595,
      "grad_norm": 1.0039851665496826,
      "learning_rate": 0.00046430235020114335,
      "loss": 1.1213,
      "step": 87750
    },
    {
      "epoch": 0.9294890456857628,
      "grad_norm": 0.935003399848938,
      "learning_rate": 0.0004645670124920601,
      "loss": 1.1251,
      "step": 87800
    },
    {
      "epoch": 0.9300183674657662,
      "grad_norm": 0.8157650828361511,
      "learning_rate": 0.00046483167478297697,
      "loss": 1.1449,
      "step": 87850
    },
    {
      "epoch": 0.9305476892457694,
      "grad_norm": 0.9980546236038208,
      "learning_rate": 0.0004650963370738937,
      "loss": 1.1147,
      "step": 87900
    },
    {
      "epoch": 0.9310770110257727,
      "grad_norm": 1.0836830139160156,
      "learning_rate": 0.0004653609993648105,
      "loss": 1.1127,
      "step": 87950
    },
    {
      "epoch": 0.931606332805776,
      "grad_norm": 1.0506420135498047,
      "learning_rate": 0.0004656256616557273,
      "loss": 1.1145,
      "step": 88000
    },
    {
      "epoch": 0.931606332805776,
      "eval_loss": 1.03235924243927,
      "eval_runtime": 46.8357,
      "eval_samples_per_second": 3585.51,
      "eval_steps_per_second": 448.205,
      "step": 88000
    },
    {
      "epoch": 0.9321356545857793,
      "grad_norm": 0.9107609391212463,
      "learning_rate": 0.0004658903239466441,
      "loss": 1.1031,
      "step": 88050
    },
    {
      "epoch": 0.9326649763657825,
      "grad_norm": 0.9216429591178894,
      "learning_rate": 0.00046615498623756084,
      "loss": 1.1332,
      "step": 88100
    },
    {
      "epoch": 0.9331942981457858,
      "grad_norm": 0.8135203719139099,
      "learning_rate": 0.0004664196485284777,
      "loss": 1.1424,
      "step": 88150
    },
    {
      "epoch": 0.9337236199257891,
      "grad_norm": 0.987537145614624,
      "learning_rate": 0.00046668431081939445,
      "loss": 1.1275,
      "step": 88200
    },
    {
      "epoch": 0.9342529417057923,
      "grad_norm": 0.9016706347465515,
      "learning_rate": 0.00046694897311031126,
      "loss": 1.1053,
      "step": 88250
    },
    {
      "epoch": 0.9347822634857956,
      "grad_norm": 0.9420362114906311,
      "learning_rate": 0.000467213635401228,
      "loss": 1.1204,
      "step": 88300
    },
    {
      "epoch": 0.9353115852657989,
      "grad_norm": 0.9151188135147095,
      "learning_rate": 0.0004674782976921448,
      "loss": 1.1233,
      "step": 88350
    },
    {
      "epoch": 0.9358409070458023,
      "grad_norm": 0.9101884961128235,
      "learning_rate": 0.0004677429599830616,
      "loss": 1.1349,
      "step": 88400
    },
    {
      "epoch": 0.9363702288258055,
      "grad_norm": 0.8645592927932739,
      "learning_rate": 0.00046800762227397843,
      "loss": 1.1156,
      "step": 88450
    },
    {
      "epoch": 0.9368995506058088,
      "grad_norm": 0.9161430597305298,
      "learning_rate": 0.0004682722845648952,
      "loss": 1.1161,
      "step": 88500
    },
    {
      "epoch": 0.9368995506058088,
      "eval_loss": 1.0311906337738037,
      "eval_runtime": 46.7108,
      "eval_samples_per_second": 3595.097,
      "eval_steps_per_second": 449.403,
      "step": 88500
    },
    {
      "epoch": 0.9374288723858121,
      "grad_norm": 0.8763760328292847,
      "learning_rate": 0.000468536946855812,
      "loss": 1.1272,
      "step": 88550
    },
    {
      "epoch": 0.9379581941658154,
      "grad_norm": 0.8787983059883118,
      "learning_rate": 0.00046880160914672874,
      "loss": 1.112,
      "step": 88600
    },
    {
      "epoch": 0.9384875159458186,
      "grad_norm": 0.9470075964927673,
      "learning_rate": 0.00046906627143764555,
      "loss": 1.1159,
      "step": 88650
    },
    {
      "epoch": 0.9390168377258219,
      "grad_norm": 0.9205231070518494,
      "learning_rate": 0.00046933093372856236,
      "loss": 1.0854,
      "step": 88700
    },
    {
      "epoch": 0.9395461595058252,
      "grad_norm": 0.9479773640632629,
      "learning_rate": 0.00046959559601947917,
      "loss": 1.1193,
      "step": 88750
    },
    {
      "epoch": 0.9400754812858285,
      "grad_norm": 0.8936817646026611,
      "learning_rate": 0.00046986025831039597,
      "loss": 1.1222,
      "step": 88800
    },
    {
      "epoch": 0.9406048030658317,
      "grad_norm": 0.9528663754463196,
      "learning_rate": 0.0004701249206013127,
      "loss": 1.1327,
      "step": 88850
    },
    {
      "epoch": 0.941134124845835,
      "grad_norm": 0.9149631261825562,
      "learning_rate": 0.00047038958289222953,
      "loss": 1.1276,
      "step": 88900
    },
    {
      "epoch": 0.9416634466258383,
      "grad_norm": 0.918572187423706,
      "learning_rate": 0.00047065424518314634,
      "loss": 1.111,
      "step": 88950
    },
    {
      "epoch": 0.9421927684058415,
      "grad_norm": 0.8706077337265015,
      "learning_rate": 0.00047091890747406315,
      "loss": 1.121,
      "step": 89000
    },
    {
      "epoch": 0.9421927684058415,
      "eval_loss": 1.02920401096344,
      "eval_runtime": 46.8111,
      "eval_samples_per_second": 3587.396,
      "eval_steps_per_second": 448.441,
      "step": 89000
    },
    {
      "epoch": 0.9427220901858449,
      "grad_norm": 0.8784782886505127,
      "learning_rate": 0.0004711835697649799,
      "loss": 1.1219,
      "step": 89050
    },
    {
      "epoch": 0.9432514119658482,
      "grad_norm": 0.8563218116760254,
      "learning_rate": 0.0004714482320558967,
      "loss": 1.1085,
      "step": 89100
    },
    {
      "epoch": 0.9437807337458515,
      "grad_norm": 0.9246044754981995,
      "learning_rate": 0.00047171289434681346,
      "loss": 1.1358,
      "step": 89150
    },
    {
      "epoch": 0.9443100555258547,
      "grad_norm": 0.9625068306922913,
      "learning_rate": 0.00047197755663773026,
      "loss": 1.1178,
      "step": 89200
    },
    {
      "epoch": 0.944839377305858,
      "grad_norm": 0.8773888945579529,
      "learning_rate": 0.00047224221892864707,
      "loss": 1.1244,
      "step": 89250
    },
    {
      "epoch": 0.9453686990858613,
      "grad_norm": 0.9169941544532776,
      "learning_rate": 0.0004725068812195639,
      "loss": 1.1228,
      "step": 89300
    },
    {
      "epoch": 0.9458980208658646,
      "grad_norm": 0.8494044542312622,
      "learning_rate": 0.00047277154351048063,
      "loss": 1.1282,
      "step": 89350
    },
    {
      "epoch": 0.9464273426458678,
      "grad_norm": 0.8999509811401367,
      "learning_rate": 0.00047303620580139744,
      "loss": 1.1151,
      "step": 89400
    },
    {
      "epoch": 0.9469566644258711,
      "grad_norm": 0.822525143623352,
      "learning_rate": 0.0004733008680923142,
      "loss": 1.1094,
      "step": 89450
    },
    {
      "epoch": 0.9474859862058744,
      "grad_norm": 0.953050971031189,
      "learning_rate": 0.00047356553038323105,
      "loss": 1.0966,
      "step": 89500
    },
    {
      "epoch": 0.9474859862058744,
      "eval_loss": 1.026753306388855,
      "eval_runtime": 46.7459,
      "eval_samples_per_second": 3592.402,
      "eval_steps_per_second": 449.066,
      "step": 89500
    },
    {
      "epoch": 0.9480153079858777,
      "grad_norm": 1.024519443511963,
      "learning_rate": 0.0004738301926741478,
      "loss": 1.1156,
      "step": 89550
    },
    {
      "epoch": 0.9485446297658809,
      "grad_norm": 0.9653565287590027,
      "learning_rate": 0.0004740948549650646,
      "loss": 1.1059,
      "step": 89600
    },
    {
      "epoch": 0.9490739515458843,
      "grad_norm": 0.8790062665939331,
      "learning_rate": 0.00047435951725598136,
      "loss": 1.1103,
      "step": 89650
    },
    {
      "epoch": 0.9496032733258876,
      "grad_norm": 0.8590484261512756,
      "learning_rate": 0.00047462417954689817,
      "loss": 1.1107,
      "step": 89700
    },
    {
      "epoch": 0.9501325951058909,
      "grad_norm": 0.8684212565422058,
      "learning_rate": 0.0004748888418378149,
      "loss": 1.1222,
      "step": 89750
    },
    {
      "epoch": 0.9506619168858941,
      "grad_norm": 0.8804898858070374,
      "learning_rate": 0.0004751535041287318,
      "loss": 1.1238,
      "step": 89800
    },
    {
      "epoch": 0.9511912386658974,
      "grad_norm": 0.9942615628242493,
      "learning_rate": 0.00047541816641964854,
      "loss": 1.1178,
      "step": 89850
    },
    {
      "epoch": 0.9517205604459007,
      "grad_norm": 0.983207643032074,
      "learning_rate": 0.00047568282871056534,
      "loss": 1.1245,
      "step": 89900
    },
    {
      "epoch": 0.9522498822259039,
      "grad_norm": 0.8808591961860657,
      "learning_rate": 0.0004759474910014821,
      "loss": 1.1239,
      "step": 89950
    },
    {
      "epoch": 0.9527792040059072,
      "grad_norm": 0.9460931420326233,
      "learning_rate": 0.0004762121532923989,
      "loss": 1.1218,
      "step": 90000
    },
    {
      "epoch": 0.9527792040059072,
      "eval_loss": 1.026275396347046,
      "eval_runtime": 46.755,
      "eval_samples_per_second": 3591.701,
      "eval_steps_per_second": 448.979,
      "step": 90000
    },
    {
      "epoch": 0.9533085257859105,
      "grad_norm": 0.9022354483604431,
      "learning_rate": 0.00047647681558331566,
      "loss": 1.1249,
      "step": 90050
    },
    {
      "epoch": 0.9538378475659138,
      "grad_norm": 0.9446997046470642,
      "learning_rate": 0.0004767414778742325,
      "loss": 1.1204,
      "step": 90100
    },
    {
      "epoch": 0.954367169345917,
      "grad_norm": 0.8529118299484253,
      "learning_rate": 0.00047700614016514927,
      "loss": 1.1098,
      "step": 90150
    },
    {
      "epoch": 0.9548964911259203,
      "grad_norm": 0.9543572068214417,
      "learning_rate": 0.0004772708024560661,
      "loss": 1.1449,
      "step": 90200
    },
    {
      "epoch": 0.9554258129059237,
      "grad_norm": 0.9043518304824829,
      "learning_rate": 0.00047753546474698283,
      "loss": 1.1164,
      "step": 90250
    },
    {
      "epoch": 0.955955134685927,
      "grad_norm": 1.071572184562683,
      "learning_rate": 0.00047780012703789964,
      "loss": 1.0925,
      "step": 90300
    },
    {
      "epoch": 0.9564844564659302,
      "grad_norm": 0.9717413783073425,
      "learning_rate": 0.00047806478932881644,
      "loss": 1.1156,
      "step": 90350
    },
    {
      "epoch": 0.9570137782459335,
      "grad_norm": 0.9642631411552429,
      "learning_rate": 0.00047832945161973325,
      "loss": 1.1202,
      "step": 90400
    },
    {
      "epoch": 0.9575431000259368,
      "grad_norm": 0.9185963869094849,
      "learning_rate": 0.00047859411391065,
      "loss": 1.1246,
      "step": 90450
    },
    {
      "epoch": 0.9580724218059401,
      "grad_norm": 0.8444983959197998,
      "learning_rate": 0.0004788587762015668,
      "loss": 1.0849,
      "step": 90500
    },
    {
      "epoch": 0.9580724218059401,
      "eval_loss": 1.0192577838897705,
      "eval_runtime": 46.7592,
      "eval_samples_per_second": 3591.378,
      "eval_steps_per_second": 448.938,
      "step": 90500
    },
    {
      "epoch": 0.9586017435859433,
      "grad_norm": 0.9355332851409912,
      "learning_rate": 0.00047912343849248356,
      "loss": 1.0982,
      "step": 90550
    },
    {
      "epoch": 0.9591310653659466,
      "grad_norm": 1.0407146215438843,
      "learning_rate": 0.00047938810078340037,
      "loss": 1.1012,
      "step": 90600
    },
    {
      "epoch": 0.9596603871459499,
      "grad_norm": 0.8696514368057251,
      "learning_rate": 0.0004796527630743172,
      "loss": 1.1174,
      "step": 90650
    },
    {
      "epoch": 0.9601897089259531,
      "grad_norm": 0.8128880262374878,
      "learning_rate": 0.000479917425365234,
      "loss": 1.1199,
      "step": 90700
    },
    {
      "epoch": 0.9607190307059564,
      "grad_norm": 0.9208272099494934,
      "learning_rate": 0.00048018208765615073,
      "loss": 1.1226,
      "step": 90750
    },
    {
      "epoch": 0.9612483524859597,
      "grad_norm": 0.8505280613899231,
      "learning_rate": 0.00048044674994706754,
      "loss": 1.1213,
      "step": 90800
    },
    {
      "epoch": 0.9617776742659631,
      "grad_norm": 0.9154881238937378,
      "learning_rate": 0.00048071141223798435,
      "loss": 1.1275,
      "step": 90850
    },
    {
      "epoch": 0.9623069960459663,
      "grad_norm": 0.8967435359954834,
      "learning_rate": 0.00048097607452890116,
      "loss": 1.1267,
      "step": 90900
    },
    {
      "epoch": 0.9628363178259696,
      "grad_norm": 0.90098637342453,
      "learning_rate": 0.00048124073681981796,
      "loss": 1.1061,
      "step": 90950
    },
    {
      "epoch": 0.9633656396059729,
      "grad_norm": 0.9508609771728516,
      "learning_rate": 0.0004815053991107347,
      "loss": 1.1166,
      "step": 91000
    },
    {
      "epoch": 0.9633656396059729,
      "eval_loss": 1.0189189910888672,
      "eval_runtime": 46.7856,
      "eval_samples_per_second": 3589.355,
      "eval_steps_per_second": 448.685,
      "step": 91000
    },
    {
      "epoch": 0.9638949613859762,
      "grad_norm": 0.9255415797233582,
      "learning_rate": 0.0004817700614016515,
      "loss": 1.1265,
      "step": 91050
    },
    {
      "epoch": 0.9644242831659794,
      "grad_norm": 0.9318537712097168,
      "learning_rate": 0.0004820347236925683,
      "loss": 1.0962,
      "step": 91100
    },
    {
      "epoch": 0.9649536049459827,
      "grad_norm": 0.8762551546096802,
      "learning_rate": 0.0004822993859834851,
      "loss": 1.1289,
      "step": 91150
    },
    {
      "epoch": 0.965482926725986,
      "grad_norm": 0.9238367676734924,
      "learning_rate": 0.0004825640482744019,
      "loss": 1.1106,
      "step": 91200
    },
    {
      "epoch": 0.9660122485059893,
      "grad_norm": 0.8408565521240234,
      "learning_rate": 0.0004828287105653187,
      "loss": 1.1098,
      "step": 91250
    },
    {
      "epoch": 0.9665415702859925,
      "grad_norm": 0.9078213572502136,
      "learning_rate": 0.00048309337285623545,
      "loss": 1.1242,
      "step": 91300
    },
    {
      "epoch": 0.9670708920659958,
      "grad_norm": 0.8859490156173706,
      "learning_rate": 0.00048335274190133387,
      "loss": 1.1087,
      "step": 91350
    },
    {
      "epoch": 0.9676002138459991,
      "grad_norm": 0.9500763416290283,
      "learning_rate": 0.0004836174041922507,
      "loss": 1.1002,
      "step": 91400
    },
    {
      "epoch": 0.9681295356260025,
      "grad_norm": 0.9360416531562805,
      "learning_rate": 0.00048388206648316754,
      "loss": 1.1206,
      "step": 91450
    },
    {
      "epoch": 0.9686588574060057,
      "grad_norm": 0.9321821331977844,
      "learning_rate": 0.0004841467287740843,
      "loss": 1.1054,
      "step": 91500
    },
    {
      "epoch": 0.9686588574060057,
      "eval_loss": 1.0133750438690186,
      "eval_runtime": 46.7517,
      "eval_samples_per_second": 3591.956,
      "eval_steps_per_second": 449.011,
      "step": 91500
    },
    {
      "epoch": 0.969188179186009,
      "grad_norm": 0.9165966510772705,
      "learning_rate": 0.0004844113910650011,
      "loss": 1.1053,
      "step": 91550
    },
    {
      "epoch": 0.9697175009660123,
      "grad_norm": 0.9259300827980042,
      "learning_rate": 0.00048467605335591785,
      "loss": 1.0991,
      "step": 91600
    },
    {
      "epoch": 0.9702468227460155,
      "grad_norm": 0.8762983083724976,
      "learning_rate": 0.00048494071564683465,
      "loss": 1.1178,
      "step": 91650
    },
    {
      "epoch": 0.9707761445260188,
      "grad_norm": 0.894108772277832,
      "learning_rate": 0.00048520537793775146,
      "loss": 1.108,
      "step": 91700
    },
    {
      "epoch": 0.9713054663060221,
      "grad_norm": 0.8402701020240784,
      "learning_rate": 0.00048547004022866827,
      "loss": 1.1021,
      "step": 91750
    },
    {
      "epoch": 0.9718347880860254,
      "grad_norm": 0.8667780160903931,
      "learning_rate": 0.000485734702519585,
      "loss": 1.103,
      "step": 91800
    },
    {
      "epoch": 0.9723641098660286,
      "grad_norm": 0.9612612724304199,
      "learning_rate": 0.00048599936481050183,
      "loss": 1.1011,
      "step": 91850
    },
    {
      "epoch": 0.9728934316460319,
      "grad_norm": 0.9237189888954163,
      "learning_rate": 0.0004862640271014186,
      "loss": 1.1059,
      "step": 91900
    },
    {
      "epoch": 0.9734227534260352,
      "grad_norm": 0.862451434135437,
      "learning_rate": 0.0004865286893923354,
      "loss": 1.1136,
      "step": 91950
    },
    {
      "epoch": 0.9739520752060385,
      "grad_norm": 0.8638797998428345,
      "learning_rate": 0.0004867933516832522,
      "loss": 1.1271,
      "step": 92000
    },
    {
      "epoch": 0.9739520752060385,
      "eval_loss": 1.0132452249526978,
      "eval_runtime": 46.7624,
      "eval_samples_per_second": 3591.137,
      "eval_steps_per_second": 448.908,
      "step": 92000
    },
    {
      "epoch": 0.9744813969860417,
      "grad_norm": 0.7952830791473389,
      "learning_rate": 0.000487058013974169,
      "loss": 1.0974,
      "step": 92050
    },
    {
      "epoch": 0.9750107187660451,
      "grad_norm": 0.9503257870674133,
      "learning_rate": 0.00048732267626508575,
      "loss": 1.0827,
      "step": 92100
    },
    {
      "epoch": 0.9755400405460484,
      "grad_norm": 0.8519055843353271,
      "learning_rate": 0.00048758733855600256,
      "loss": 1.1042,
      "step": 92150
    },
    {
      "epoch": 0.9760693623260517,
      "grad_norm": 0.9007790684700012,
      "learning_rate": 0.0004878520008469193,
      "loss": 1.1066,
      "step": 92200
    },
    {
      "epoch": 0.9765986841060549,
      "grad_norm": 0.9855297207832336,
      "learning_rate": 0.0004881166631378362,
      "loss": 1.0997,
      "step": 92250
    },
    {
      "epoch": 0.9771280058860582,
      "grad_norm": 0.9021557569503784,
      "learning_rate": 0.0004883813254287529,
      "loss": 1.1262,
      "step": 92300
    },
    {
      "epoch": 0.9776573276660615,
      "grad_norm": 0.9984906911849976,
      "learning_rate": 0.0004886459877196697,
      "loss": 1.1132,
      "step": 92350
    },
    {
      "epoch": 0.9781866494460647,
      "grad_norm": 0.9893971681594849,
      "learning_rate": 0.0004889106500105865,
      "loss": 1.1052,
      "step": 92400
    },
    {
      "epoch": 0.978715971226068,
      "grad_norm": 0.9254412055015564,
      "learning_rate": 0.0004891753123015033,
      "loss": 1.1076,
      "step": 92450
    },
    {
      "epoch": 0.9792452930060713,
      "grad_norm": 0.9551966190338135,
      "learning_rate": 0.00048943997459242,
      "loss": 1.1088,
      "step": 92500
    },
    {
      "epoch": 0.9792452930060713,
      "eval_loss": 1.0115975141525269,
      "eval_runtime": 46.8348,
      "eval_samples_per_second": 3585.581,
      "eval_steps_per_second": 448.214,
      "step": 92500
    },
    {
      "epoch": 0.9797746147860746,
      "grad_norm": 0.9405438303947449,
      "learning_rate": 0.0004897046368833369,
      "loss": 1.103,
      "step": 92550
    },
    {
      "epoch": 0.9803039365660778,
      "grad_norm": 0.8567606806755066,
      "learning_rate": 0.0004899692991742537,
      "loss": 1.0978,
      "step": 92600
    },
    {
      "epoch": 0.9808332583460811,
      "grad_norm": 0.9977881908416748,
      "learning_rate": 0.0004902339614651705,
      "loss": 1.1104,
      "step": 92650
    },
    {
      "epoch": 0.9813625801260845,
      "grad_norm": 0.9287759065628052,
      "learning_rate": 0.0004904986237560873,
      "loss": 1.1167,
      "step": 92700
    },
    {
      "epoch": 0.9818919019060878,
      "grad_norm": 0.8898882865905762,
      "learning_rate": 0.0004907632860470041,
      "loss": 1.089,
      "step": 92750
    },
    {
      "epoch": 0.982421223686091,
      "grad_norm": 0.9244901537895203,
      "learning_rate": 0.0004910279483379208,
      "loss": 1.1048,
      "step": 92800
    },
    {
      "epoch": 0.9829505454660943,
      "grad_norm": 0.9012295007705688,
      "learning_rate": 0.0004912926106288376,
      "loss": 1.1022,
      "step": 92850
    },
    {
      "epoch": 0.9834798672460976,
      "grad_norm": 0.8577268123626709,
      "learning_rate": 0.0004915572729197544,
      "loss": 1.0964,
      "step": 92900
    },
    {
      "epoch": 0.9840091890261009,
      "grad_norm": 0.9185602068901062,
      "learning_rate": 0.0004918219352106712,
      "loss": 1.0982,
      "step": 92950
    },
    {
      "epoch": 0.9845385108061041,
      "grad_norm": 0.886278510093689,
      "learning_rate": 0.000492086597501588,
      "loss": 1.0846,
      "step": 93000
    },
    {
      "epoch": 0.9845385108061041,
      "eval_loss": 1.0061352252960205,
      "eval_runtime": 46.7084,
      "eval_samples_per_second": 3595.282,
      "eval_steps_per_second": 449.426,
      "step": 93000
    },
    {
      "epoch": 0.9850678325861074,
      "grad_norm": 0.9718820452690125,
      "learning_rate": 0.0004923512597925048,
      "loss": 1.0941,
      "step": 93050
    },
    {
      "epoch": 0.9855971543661107,
      "grad_norm": 0.8119185566902161,
      "learning_rate": 0.0004926159220834215,
      "loss": 1.0843,
      "step": 93100
    },
    {
      "epoch": 0.986126476146114,
      "grad_norm": 0.9057713747024536,
      "learning_rate": 0.0004928805843743383,
      "loss": 1.107,
      "step": 93150
    },
    {
      "epoch": 0.9866557979261172,
      "grad_norm": 0.9509076476097107,
      "learning_rate": 0.0004931452466652551,
      "loss": 1.1062,
      "step": 93200
    },
    {
      "epoch": 0.9871851197061206,
      "grad_norm": 0.9219775199890137,
      "learning_rate": 0.0004934099089561719,
      "loss": 1.1151,
      "step": 93250
    },
    {
      "epoch": 0.9877144414861239,
      "grad_norm": 0.9298778176307678,
      "learning_rate": 0.0004936745712470887,
      "loss": 1.0858,
      "step": 93300
    },
    {
      "epoch": 0.9882437632661271,
      "grad_norm": 0.8986598253250122,
      "learning_rate": 0.0004939339402921872,
      "loss": 1.0989,
      "step": 93350
    },
    {
      "epoch": 0.9887730850461304,
      "grad_norm": 0.882940948009491,
      "learning_rate": 0.0004941986025831039,
      "loss": 1.0882,
      "step": 93400
    },
    {
      "epoch": 0.9893024068261337,
      "grad_norm": 0.8966530561447144,
      "learning_rate": 0.0004944632648740207,
      "loss": 1.1201,
      "step": 93450
    },
    {
      "epoch": 0.989831728606137,
      "grad_norm": 0.9009073376655579,
      "learning_rate": 0.0004947279271649375,
      "loss": 1.1126,
      "step": 93500
    },
    {
      "epoch": 0.989831728606137,
      "eval_loss": 1.0062042474746704,
      "eval_runtime": 46.8435,
      "eval_samples_per_second": 3584.913,
      "eval_steps_per_second": 448.13,
      "step": 93500
    },
    {
      "epoch": 0.9903610503861402,
      "grad_norm": 0.9006644487380981,
      "learning_rate": 0.0004949925894558543,
      "loss": 1.1299,
      "step": 93550
    },
    {
      "epoch": 0.9908903721661435,
      "grad_norm": 0.9021791815757751,
      "learning_rate": 0.0004952572517467711,
      "loss": 1.1009,
      "step": 93600
    },
    {
      "epoch": 0.9914196939461468,
      "grad_norm": 0.7905541062355042,
      "learning_rate": 0.000495521914037688,
      "loss": 1.1211,
      "step": 93650
    },
    {
      "epoch": 0.9919490157261501,
      "grad_norm": 1.0120885372161865,
      "learning_rate": 0.0004957865763286046,
      "loss": 1.0957,
      "step": 93700
    },
    {
      "epoch": 0.9924783375061533,
      "grad_norm": 0.9025769829750061,
      "learning_rate": 0.0004960512386195215,
      "loss": 1.0931,
      "step": 93750
    },
    {
      "epoch": 0.9930076592861566,
      "grad_norm": 0.9384981393814087,
      "learning_rate": 0.0004963159009104383,
      "loss": 1.1043,
      "step": 93800
    },
    {
      "epoch": 0.99353698106616,
      "grad_norm": 0.789828896522522,
      "learning_rate": 0.0004965805632013551,
      "loss": 1.1012,
      "step": 93850
    },
    {
      "epoch": 0.9940663028461633,
      "grad_norm": 0.892826497554779,
      "learning_rate": 0.0004968452254922719,
      "loss": 1.0915,
      "step": 93900
    },
    {
      "epoch": 0.9945956246261665,
      "grad_norm": 0.836455225944519,
      "learning_rate": 0.0004971098877831887,
      "loss": 1.1186,
      "step": 93950
    },
    {
      "epoch": 0.9951249464061698,
      "grad_norm": 0.8322932720184326,
      "learning_rate": 0.0004973745500741054,
      "loss": 1.0887,
      "step": 94000
    },
    {
      "epoch": 0.9951249464061698,
      "eval_loss": 1.0084553956985474,
      "eval_runtime": 46.8228,
      "eval_samples_per_second": 3586.504,
      "eval_steps_per_second": 448.329,
      "step": 94000
    },
    {
      "epoch": 0.9956542681861731,
      "grad_norm": 0.8532626628875732,
      "learning_rate": 0.0004976392123650223,
      "loss": 1.0909,
      "step": 94050
    },
    {
      "epoch": 0.9961835899661763,
      "grad_norm": 0.8373833298683167,
      "learning_rate": 0.0004979038746559391,
      "loss": 1.112,
      "step": 94100
    },
    {
      "epoch": 0.9967129117461796,
      "grad_norm": 0.9064791798591614,
      "learning_rate": 0.0004981632437010375,
      "loss": 1.1093,
      "step": 94150
    },
    {
      "epoch": 0.9972422335261829,
      "grad_norm": 0.790530264377594,
      "learning_rate": 0.0004984279059919543,
      "loss": 1.0932,
      "step": 94200
    },
    {
      "epoch": 0.9977715553061862,
      "grad_norm": 0.9826334714889526,
      "learning_rate": 0.0004986925682828711,
      "loss": 1.0719,
      "step": 94250
    },
    {
      "epoch": 0.9983008770861894,
      "grad_norm": 0.8706977367401123,
      "learning_rate": 0.0004989572305737879,
      "loss": 1.0742,
      "step": 94300
    },
    {
      "epoch": 0.9988301988661927,
      "grad_norm": 0.8939778208732605,
      "learning_rate": 0.0004992218928647047,
      "loss": 1.0882,
      "step": 94350
    },
    {
      "epoch": 0.999359520646196,
      "grad_norm": 0.9898223280906677,
      "learning_rate": 0.0004994865551556214,
      "loss": 1.1064,
      "step": 94400
    },
    {
      "epoch": 0.9998888424261994,
      "grad_norm": 0.9007563591003418,
      "learning_rate": 0.0004997512174465382,
      "loss": 1.0827,
      "step": 94450
    },
    {
      "epoch": 1.0004128709884026,
      "grad_norm": 0.9685214757919312,
      "learning_rate": 0.0004999999999846372,
      "loss": 1.112,
      "step": 94500
    },
    {
      "epoch": 1.0004128709884026,
      "eval_loss": 1.0041182041168213,
      "eval_runtime": 46.7572,
      "eval_samples_per_second": 3591.534,
      "eval_steps_per_second": 448.958,
      "step": 94500
    },
    {
      "epoch": 1.000942192768406,
      "grad_norm": 0.8765151500701904,
      "learning_rate": 0.0004999999952050886,
      "loss": 1.0934,
      "step": 94550
    },
    {
      "epoch": 1.0014715145484092,
      "grad_norm": 0.9423183798789978,
      "learning_rate": 0.0004999999818906317,
      "loss": 1.0896,
      "step": 94600
    },
    {
      "epoch": 1.0020008363284123,
      "grad_norm": 0.933296799659729,
      "learning_rate": 0.0004999999600412673,
      "loss": 1.0898,
      "step": 94650
    },
    {
      "epoch": 1.0025301581084156,
      "grad_norm": 0.8952080011367798,
      "learning_rate": 0.0004999999296569958,
      "loss": 1.0863,
      "step": 94700
    },
    {
      "epoch": 1.003059479888419,
      "grad_norm": 0.8179261684417725,
      "learning_rate": 0.0004999998907378184,
      "loss": 1.0893,
      "step": 94750
    },
    {
      "epoch": 1.0035888016684222,
      "grad_norm": 0.8439605832099915,
      "learning_rate": 0.0004999998432837365,
      "loss": 1.0889,
      "step": 94800
    },
    {
      "epoch": 1.0041181234484255,
      "grad_norm": 0.9453271627426147,
      "learning_rate": 0.0004999997872947515,
      "loss": 1.0958,
      "step": 94850
    },
    {
      "epoch": 1.0046474452284289,
      "grad_norm": 0.9316121339797974,
      "learning_rate": 0.0004999997227708656,
      "loss": 1.0615,
      "step": 94900
    },
    {
      "epoch": 1.0051767670084322,
      "grad_norm": 0.8599679470062256,
      "learning_rate": 0.0004999996497120807,
      "loss": 1.0899,
      "step": 94950
    },
    {
      "epoch": 1.0057060887884355,
      "grad_norm": 0.8707223534584045,
      "learning_rate": 0.0004999995681183995,
      "loss": 1.1225,
      "step": 95000
    },
    {
      "epoch": 1.0057060887884355,
      "eval_loss": 0.9999315142631531,
      "eval_runtime": 46.6487,
      "eval_samples_per_second": 3599.887,
      "eval_steps_per_second": 450.002,
      "step": 95000
    },
    {
      "epoch": 1.0062354105684386,
      "grad_norm": 0.9628055095672607,
      "learning_rate": 0.0004999994779898248,
      "loss": 1.0964,
      "step": 95050
    },
    {
      "epoch": 1.0067647323484419,
      "grad_norm": 0.9148367047309875,
      "learning_rate": 0.0004999993793263595,
      "loss": 1.0831,
      "step": 95100
    },
    {
      "epoch": 1.0072940541284452,
      "grad_norm": 0.8791923522949219,
      "learning_rate": 0.0004999992721280072,
      "loss": 1.0938,
      "step": 95150
    },
    {
      "epoch": 1.0078233759084485,
      "grad_norm": 0.9080961346626282,
      "learning_rate": 0.0004999991563947714,
      "loss": 1.0956,
      "step": 95200
    },
    {
      "epoch": 1.0083526976884518,
      "grad_norm": 0.8909618854522705,
      "learning_rate": 0.0004999990321266559,
      "loss": 1.0891,
      "step": 95250
    },
    {
      "epoch": 1.0088820194684551,
      "grad_norm": 0.8729913234710693,
      "learning_rate": 0.0004999988993236654,
      "loss": 1.088,
      "step": 95300
    },
    {
      "epoch": 1.0094113412484584,
      "grad_norm": 0.867834746837616,
      "learning_rate": 0.000499998757985804,
      "loss": 1.0854,
      "step": 95350
    },
    {
      "epoch": 1.0099406630284615,
      "grad_norm": 0.9317255020141602,
      "learning_rate": 0.0004999986081130767,
      "loss": 1.0884,
      "step": 95400
    },
    {
      "epoch": 1.0104699848084648,
      "grad_norm": 0.8338453769683838,
      "learning_rate": 0.0004999984497054886,
      "loss": 1.081,
      "step": 95450
    },
    {
      "epoch": 1.0109993065884681,
      "grad_norm": 0.8609000444412231,
      "learning_rate": 0.0004999982827630453,
      "loss": 1.1045,
      "step": 95500
    },
    {
      "epoch": 1.0109993065884681,
      "eval_loss": 0.9986599683761597,
      "eval_runtime": 46.7499,
      "eval_samples_per_second": 3592.093,
      "eval_steps_per_second": 449.028,
      "step": 95500
    },
    {
      "epoch": 1.0115286283684715,
      "grad_norm": 0.8978766798973083,
      "learning_rate": 0.0004999981072857521,
      "loss": 1.084,
      "step": 95550
    },
    {
      "epoch": 1.0120579501484748,
      "grad_norm": 0.9425036907196045,
      "learning_rate": 0.0004999979232736153,
      "loss": 1.1026,
      "step": 95600
    },
    {
      "epoch": 1.012587271928478,
      "grad_norm": 0.9283761382102966,
      "learning_rate": 0.000499997730726641,
      "loss": 1.0823,
      "step": 95650
    },
    {
      "epoch": 1.0131165937084814,
      "grad_norm": 0.9495131969451904,
      "learning_rate": 0.0004999975296448359,
      "loss": 1.0991,
      "step": 95700
    },
    {
      "epoch": 1.0136459154884847,
      "grad_norm": 0.844437301158905,
      "learning_rate": 0.0004999973200282067,
      "loss": 1.0872,
      "step": 95750
    },
    {
      "epoch": 1.0141752372684878,
      "grad_norm": 0.8924964666366577,
      "learning_rate": 0.0004999971018767608,
      "loss": 1.0775,
      "step": 95800
    },
    {
      "epoch": 1.014704559048491,
      "grad_norm": 0.7823826670646667,
      "learning_rate": 0.0004999968751905056,
      "loss": 1.0966,
      "step": 95850
    },
    {
      "epoch": 1.0152338808284944,
      "grad_norm": 0.899766206741333,
      "learning_rate": 0.0004999966399694487,
      "loss": 1.0913,
      "step": 95900
    },
    {
      "epoch": 1.0157632026084977,
      "grad_norm": 0.9107276797294617,
      "learning_rate": 0.0004999963962135981,
      "loss": 1.0771,
      "step": 95950
    },
    {
      "epoch": 1.016292524388501,
      "grad_norm": 0.9078578352928162,
      "learning_rate": 0.0004999961439229624,
      "loss": 1.1013,
      "step": 96000
    },
    {
      "epoch": 1.016292524388501,
      "eval_loss": 0.9968668818473816,
      "eval_runtime": 46.7818,
      "eval_samples_per_second": 3589.645,
      "eval_steps_per_second": 448.722,
      "step": 96000
    },
    {
      "epoch": 1.0168218461685044,
      "grad_norm": 0.8262457251548767,
      "learning_rate": 0.0004999958830975499,
      "loss": 1.0841,
      "step": 96050
    },
    {
      "epoch": 1.0173511679485077,
      "grad_norm": 0.7508571743965149,
      "learning_rate": 0.0004999956137373697,
      "loss": 1.0865,
      "step": 96100
    },
    {
      "epoch": 1.0178804897285108,
      "grad_norm": 0.8794434070587158,
      "learning_rate": 0.0004999953358424308,
      "loss": 1.1006,
      "step": 96150
    },
    {
      "epoch": 1.018409811508514,
      "grad_norm": 0.8574548959732056,
      "learning_rate": 0.000499995049412743,
      "loss": 1.0897,
      "step": 96200
    },
    {
      "epoch": 1.0189391332885174,
      "grad_norm": 1.0103520154953003,
      "learning_rate": 0.0004999947544483158,
      "loss": 1.0756,
      "step": 96250
    },
    {
      "epoch": 1.0194684550685207,
      "grad_norm": 0.8774346709251404,
      "learning_rate": 0.0004999944509491593,
      "loss": 1.0962,
      "step": 96300
    },
    {
      "epoch": 1.019997776848524,
      "grad_norm": 0.9237242341041565,
      "learning_rate": 0.000499994138915284,
      "loss": 1.0858,
      "step": 96350
    },
    {
      "epoch": 1.0205270986285273,
      "grad_norm": 0.8503943681716919,
      "learning_rate": 0.0004999938183467005,
      "loss": 1.0918,
      "step": 96400
    },
    {
      "epoch": 1.0210564204085306,
      "grad_norm": 0.8907366394996643,
      "learning_rate": 0.0004999934892434197,
      "loss": 1.1013,
      "step": 96450
    },
    {
      "epoch": 1.021585742188534,
      "grad_norm": 0.9635056853294373,
      "learning_rate": 0.0004999931516054529,
      "loss": 1.0855,
      "step": 96500
    },
    {
      "epoch": 1.021585742188534,
      "eval_loss": 0.9872106313705444,
      "eval_runtime": 46.7655,
      "eval_samples_per_second": 3590.892,
      "eval_steps_per_second": 448.878,
      "step": 96500
    },
    {
      "epoch": 1.022115063968537,
      "grad_norm": 0.8735851645469666,
      "learning_rate": 0.0004999928054328116,
      "loss": 1.0895,
      "step": 96550
    },
    {
      "epoch": 1.0226443857485403,
      "grad_norm": 0.8934060335159302,
      "learning_rate": 0.0004999924507255075,
      "loss": 1.0798,
      "step": 96600
    },
    {
      "epoch": 1.0231737075285436,
      "grad_norm": 0.980116605758667,
      "learning_rate": 0.0004999920874835528,
      "loss": 1.0841,
      "step": 96650
    },
    {
      "epoch": 1.023703029308547,
      "grad_norm": 1.0116095542907715,
      "learning_rate": 0.00049999171570696,
      "loss": 1.0706,
      "step": 96700
    },
    {
      "epoch": 1.0242323510885503,
      "grad_norm": 0.8797202110290527,
      "learning_rate": 0.0004999913353957418,
      "loss": 1.081,
      "step": 96750
    },
    {
      "epoch": 1.0247616728685536,
      "grad_norm": 0.9712081551551819,
      "learning_rate": 0.000499990946549911,
      "loss": 1.0722,
      "step": 96800
    },
    {
      "epoch": 1.0252909946485569,
      "grad_norm": 0.9065375328063965,
      "learning_rate": 0.0004999905491694808,
      "loss": 1.0947,
      "step": 96850
    },
    {
      "epoch": 1.0258203164285602,
      "grad_norm": 0.9497565627098083,
      "learning_rate": 0.0004999901432544651,
      "loss": 1.0901,
      "step": 96900
    },
    {
      "epoch": 1.0263496382085633,
      "grad_norm": 0.8571012020111084,
      "learning_rate": 0.0004999897288048776,
      "loss": 1.0934,
      "step": 96950
    },
    {
      "epoch": 1.0268789599885666,
      "grad_norm": 0.8678987622261047,
      "learning_rate": 0.0004999893058207324,
      "loss": 1.0788,
      "step": 97000
    },
    {
      "epoch": 1.0268789599885666,
      "eval_loss": 0.9841622114181519,
      "eval_runtime": 46.6756,
      "eval_samples_per_second": 3597.809,
      "eval_steps_per_second": 449.742,
      "step": 97000
    },
    {
      "epoch": 1.02740828176857,
      "grad_norm": 0.9304518699645996,
      "learning_rate": 0.000499988874302044,
      "loss": 1.0658,
      "step": 97050
    },
    {
      "epoch": 1.0279376035485732,
      "grad_norm": 0.9297101497650146,
      "learning_rate": 0.0004999884342488271,
      "loss": 1.0894,
      "step": 97100
    },
    {
      "epoch": 1.0284669253285765,
      "grad_norm": 0.8284627199172974,
      "learning_rate": 0.0004999879856610968,
      "loss": 1.0835,
      "step": 97150
    },
    {
      "epoch": 1.0289962471085798,
      "grad_norm": 0.9243485927581787,
      "learning_rate": 0.0004999875285388683,
      "loss": 1.0812,
      "step": 97200
    },
    {
      "epoch": 1.0295255688885832,
      "grad_norm": 0.9120311737060547,
      "learning_rate": 0.0004999870628821572,
      "loss": 1.0801,
      "step": 97250
    },
    {
      "epoch": 1.0300548906685862,
      "grad_norm": 0.8949268460273743,
      "learning_rate": 0.0004999865886909795,
      "loss": 1.0808,
      "step": 97300
    },
    {
      "epoch": 1.0305842124485896,
      "grad_norm": 0.8760030269622803,
      "learning_rate": 0.0004999861059653513,
      "loss": 1.0884,
      "step": 97350
    },
    {
      "epoch": 1.0311135342285929,
      "grad_norm": 0.8322051763534546,
      "learning_rate": 0.0004999856147052893,
      "loss": 1.0958,
      "step": 97400
    },
    {
      "epoch": 1.0316428560085962,
      "grad_norm": 0.7779411673545837,
      "learning_rate": 0.0004999851149108099,
      "loss": 1.0728,
      "step": 97450
    },
    {
      "epoch": 1.0321721777885995,
      "grad_norm": 0.8421660661697388,
      "learning_rate": 0.0004999846065819304,
      "loss": 1.1008,
      "step": 97500
    },
    {
      "epoch": 1.0321721777885995,
      "eval_loss": 0.9847581386566162,
      "eval_runtime": 46.7251,
      "eval_samples_per_second": 3594.002,
      "eval_steps_per_second": 449.266,
      "step": 97500
    },
    {
      "epoch": 1.0327014995686028,
      "grad_norm": 0.8590327501296997,
      "learning_rate": 0.0004999840897186681,
      "loss": 1.113,
      "step": 97550
    },
    {
      "epoch": 1.033230821348606,
      "grad_norm": 0.9284404516220093,
      "learning_rate": 0.0004999835643210407,
      "loss": 1.0977,
      "step": 97600
    },
    {
      "epoch": 1.0337601431286094,
      "grad_norm": 0.9064840078353882,
      "learning_rate": 0.0004999830303890661,
      "loss": 1.0759,
      "step": 97650
    },
    {
      "epoch": 1.0342894649086125,
      "grad_norm": 0.8831956386566162,
      "learning_rate": 0.0004999824879227625,
      "loss": 1.0843,
      "step": 97700
    },
    {
      "epoch": 1.0348187866886158,
      "grad_norm": 0.9465065002441406,
      "learning_rate": 0.0004999819369221484,
      "loss": 1.0868,
      "step": 97750
    },
    {
      "epoch": 1.0353481084686191,
      "grad_norm": 0.844390869140625,
      "learning_rate": 0.0004999813773872427,
      "loss": 1.069,
      "step": 97800
    },
    {
      "epoch": 1.0358774302486224,
      "grad_norm": 0.9257649779319763,
      "learning_rate": 0.0004999808093180644,
      "loss": 1.0635,
      "step": 97850
    },
    {
      "epoch": 1.0364067520286258,
      "grad_norm": 0.932636022567749,
      "learning_rate": 0.000499980232714633,
      "loss": 1.104,
      "step": 97900
    },
    {
      "epoch": 1.036936073808629,
      "grad_norm": 0.8923158645629883,
      "learning_rate": 0.0004999796475769681,
      "loss": 1.0899,
      "step": 97950
    },
    {
      "epoch": 1.0374653955886324,
      "grad_norm": 0.878422200679779,
      "learning_rate": 0.0004999790539050898,
      "loss": 1.0925,
      "step": 98000
    },
    {
      "epoch": 1.0374653955886324,
      "eval_loss": 0.9796106219291687,
      "eval_runtime": 46.7841,
      "eval_samples_per_second": 3589.47,
      "eval_steps_per_second": 448.7,
      "step": 98000
    },
    {
      "epoch": 1.0379947173686355,
      "grad_norm": 0.9847097396850586,
      "learning_rate": 0.0004999784516990181,
      "loss": 1.0782,
      "step": 98050
    },
    {
      "epoch": 1.0385240391486388,
      "grad_norm": 0.9561029076576233,
      "learning_rate": 0.0004999778409587739,
      "loss": 1.0821,
      "step": 98100
    },
    {
      "epoch": 1.039053360928642,
      "grad_norm": 0.9045130610466003,
      "learning_rate": 0.0004999772216843779,
      "loss": 1.0845,
      "step": 98150
    },
    {
      "epoch": 1.0395826827086454,
      "grad_norm": 0.8767481446266174,
      "learning_rate": 0.000499976606515656,
      "loss": 1.0811,
      "step": 98200
    },
    {
      "epoch": 1.0401120044886487,
      "grad_norm": 0.8404450416564941,
      "learning_rate": 0.000499975970343702,
      "loss": 1.0577,
      "step": 98250
    },
    {
      "epoch": 1.040641326268652,
      "grad_norm": 0.899203896522522,
      "learning_rate": 0.00049997532563766,
      "loss": 1.0687,
      "step": 98300
    },
    {
      "epoch": 1.0411706480486553,
      "grad_norm": 0.9153154492378235,
      "learning_rate": 0.0004999746723975522,
      "loss": 1.0831,
      "step": 98350
    },
    {
      "epoch": 1.0416999698286586,
      "grad_norm": 0.8554068207740784,
      "learning_rate": 0.0004999740106234006,
      "loss": 1.0836,
      "step": 98400
    },
    {
      "epoch": 1.0422292916086617,
      "grad_norm": 0.842259407043457,
      "learning_rate": 0.0004999733403152281,
      "loss": 1.0804,
      "step": 98450
    },
    {
      "epoch": 1.042758613388665,
      "grad_norm": 0.927833080291748,
      "learning_rate": 0.0004999726614730572,
      "loss": 1.0939,
      "step": 98500
    },
    {
      "epoch": 1.042758613388665,
      "eval_loss": 0.9785113334655762,
      "eval_runtime": 46.7615,
      "eval_samples_per_second": 3591.206,
      "eval_steps_per_second": 448.917,
      "step": 98500
    },
    {
      "epoch": 1.0432879351686684,
      "grad_norm": 0.8074291348457336,
      "learning_rate": 0.0004999719740969115,
      "loss": 1.074,
      "step": 98550
    },
    {
      "epoch": 1.0438172569486717,
      "grad_norm": 0.8752051591873169,
      "learning_rate": 0.0004999712781868142,
      "loss": 1.0661,
      "step": 98600
    },
    {
      "epoch": 1.044346578728675,
      "grad_norm": 0.8831691741943359,
      "learning_rate": 0.0004999705737427893,
      "loss": 1.0951,
      "step": 98650
    },
    {
      "epoch": 1.0448759005086783,
      "grad_norm": 0.991870641708374,
      "learning_rate": 0.0004999698607648605,
      "loss": 1.0745,
      "step": 98700
    },
    {
      "epoch": 1.0454052222886816,
      "grad_norm": 0.9223774075508118,
      "learning_rate": 0.0004999691392530524,
      "loss": 1.0709,
      "step": 98750
    },
    {
      "epoch": 1.0459345440686847,
      "grad_norm": 0.8526180386543274,
      "learning_rate": 0.0004999684092073895,
      "loss": 1.0573,
      "step": 98800
    },
    {
      "epoch": 1.046463865848688,
      "grad_norm": 0.9648099541664124,
      "learning_rate": 0.0004999676706278968,
      "loss": 1.0666,
      "step": 98850
    },
    {
      "epoch": 1.0469931876286913,
      "grad_norm": 0.8742839097976685,
      "learning_rate": 0.0004999669235145996,
      "loss": 1.0809,
      "step": 98900
    },
    {
      "epoch": 1.0475225094086946,
      "grad_norm": 0.8875707387924194,
      "learning_rate": 0.0004999661678675233,
      "loss": 1.0651,
      "step": 98950
    },
    {
      "epoch": 1.048051831188698,
      "grad_norm": 0.9789919853210449,
      "learning_rate": 0.0004999654036866936,
      "loss": 1.0839,
      "step": 99000
    },
    {
      "epoch": 1.048051831188698,
      "eval_loss": 0.9739387035369873,
      "eval_runtime": 46.7588,
      "eval_samples_per_second": 3591.412,
      "eval_steps_per_second": 448.942,
      "step": 99000
    },
    {
      "epoch": 1.0485811529687012,
      "grad_norm": 0.9306657314300537,
      "learning_rate": 0.0004999646309721367,
      "loss": 1.0824,
      "step": 99050
    },
    {
      "epoch": 1.0491104747487046,
      "grad_norm": 0.8465214967727661,
      "learning_rate": 0.000499963849723879,
      "loss": 1.0689,
      "step": 99100
    },
    {
      "epoch": 1.0496397965287079,
      "grad_norm": 0.9838635325431824,
      "learning_rate": 0.0004999630599419471,
      "loss": 1.0874,
      "step": 99150
    },
    {
      "epoch": 1.050169118308711,
      "grad_norm": 0.8376416563987732,
      "learning_rate": 0.0004999622616263681,
      "loss": 1.0833,
      "step": 99200
    },
    {
      "epoch": 1.0506984400887143,
      "grad_norm": 0.9389929175376892,
      "learning_rate": 0.000499961454777169,
      "loss": 1.0552,
      "step": 99250
    },
    {
      "epoch": 1.0512277618687176,
      "grad_norm": 0.9299985766410828,
      "learning_rate": 0.0004999606393943776,
      "loss": 1.0544,
      "step": 99300
    },
    {
      "epoch": 1.051757083648721,
      "grad_norm": 0.809759795665741,
      "learning_rate": 0.0004999598154780217,
      "loss": 1.0736,
      "step": 99350
    },
    {
      "epoch": 1.0522864054287242,
      "grad_norm": 1.004084825515747,
      "learning_rate": 0.0004999589830281294,
      "loss": 1.071,
      "step": 99400
    },
    {
      "epoch": 1.0528157272087275,
      "grad_norm": 0.8229905962944031,
      "learning_rate": 0.000499958142044729,
      "loss": 1.0665,
      "step": 99450
    },
    {
      "epoch": 1.0533450489887308,
      "grad_norm": 0.8792645335197449,
      "learning_rate": 0.0004999572925278493,
      "loss": 1.0758,
      "step": 99500
    },
    {
      "epoch": 1.0533450489887308,
      "eval_loss": 0.9732710719108582,
      "eval_runtime": 46.722,
      "eval_samples_per_second": 3594.239,
      "eval_steps_per_second": 449.296,
      "step": 99500
    },
    {
      "epoch": 1.053874370768734,
      "grad_norm": 0.9159563183784485,
      "learning_rate": 0.0004999564344775193,
      "loss": 1.0879,
      "step": 99550
    },
    {
      "epoch": 1.0544036925487372,
      "grad_norm": 0.9473055005073547,
      "learning_rate": 0.0004999555678937683,
      "loss": 1.0681,
      "step": 99600
    },
    {
      "epoch": 1.0549330143287405,
      "grad_norm": 0.8348639607429504,
      "learning_rate": 0.0004999546927766258,
      "loss": 1.0566,
      "step": 99650
    },
    {
      "epoch": 1.0554623361087438,
      "grad_norm": 0.9023173451423645,
      "learning_rate": 0.0004999538091261219,
      "loss": 1.0543,
      "step": 99700
    },
    {
      "epoch": 1.0559916578887472,
      "grad_norm": 0.8711936473846436,
      "learning_rate": 0.0004999529169422867,
      "loss": 1.0672,
      "step": 99750
    },
    {
      "epoch": 1.0565209796687505,
      "grad_norm": 0.862472653388977,
      "learning_rate": 0.0004999520162251504,
      "loss": 1.0626,
      "step": 99800
    },
    {
      "epoch": 1.0570503014487538,
      "grad_norm": 0.9283909201622009,
      "learning_rate": 0.000499951106974744,
      "loss": 1.074,
      "step": 99850
    },
    {
      "epoch": 1.057579623228757,
      "grad_norm": 0.8199389576911926,
      "learning_rate": 0.0004999501891910983,
      "loss": 1.0792,
      "step": 99900
    },
    {
      "epoch": 1.0581089450087602,
      "grad_norm": 0.9531506896018982,
      "learning_rate": 0.000499949262874245,
      "loss": 1.0657,
      "step": 99950
    },
    {
      "epoch": 1.0586382667887635,
      "grad_norm": 0.8301124572753906,
      "learning_rate": 0.0004999483280242155,
      "loss": 1.0688,
      "step": 100000
    },
    {
      "epoch": 1.0586382667887635,
      "eval_loss": 0.9695159196853638,
      "eval_runtime": 46.728,
      "eval_samples_per_second": 3593.775,
      "eval_steps_per_second": 449.238,
      "step": 100000
    },
    {
      "epoch": 1.0591675885687668,
      "grad_norm": 0.8146520853042603,
      "learning_rate": 0.0004999473846410418,
      "loss": 1.0616,
      "step": 100050
    },
    {
      "epoch": 1.0596969103487701,
      "grad_norm": 0.8303499817848206,
      "learning_rate": 0.000499946432724756,
      "loss": 1.0722,
      "step": 100100
    },
    {
      "epoch": 1.0602262321287734,
      "grad_norm": 0.9167277812957764,
      "learning_rate": 0.0004999454722753907,
      "loss": 1.0782,
      "step": 100150
    },
    {
      "epoch": 1.0607555539087767,
      "grad_norm": 0.8900007605552673,
      "learning_rate": 0.0004999445227562505,
      "loss": 1.0715,
      "step": 100200
    },
    {
      "epoch": 1.06128487568878,
      "grad_norm": 0.79692143201828,
      "learning_rate": 0.0004999435454114846,
      "loss": 1.0709,
      "step": 100250
    },
    {
      "epoch": 1.0618141974687831,
      "grad_norm": 0.9284615516662598,
      "learning_rate": 0.0004999425595337378,
      "loss": 1.079,
      "step": 100300
    },
    {
      "epoch": 1.0623435192487864,
      "grad_norm": 0.9236597418785095,
      "learning_rate": 0.0004999415651230437,
      "loss": 1.072,
      "step": 100350
    },
    {
      "epoch": 1.0628728410287898,
      "grad_norm": 0.8467054963111877,
      "learning_rate": 0.0004999405621794362,
      "loss": 1.0566,
      "step": 100400
    },
    {
      "epoch": 1.063402162808793,
      "grad_norm": 0.8737403154373169,
      "learning_rate": 0.0004999395507029495,
      "loss": 1.0965,
      "step": 100450
    },
    {
      "epoch": 1.0639314845887964,
      "grad_norm": 0.9905330538749695,
      "learning_rate": 0.0004999385306936183,
      "loss": 1.0673,
      "step": 100500
    },
    {
      "epoch": 1.0639314845887964,
      "eval_loss": 0.9653515219688416,
      "eval_runtime": 46.8392,
      "eval_samples_per_second": 3585.246,
      "eval_steps_per_second": 448.172,
      "step": 100500
    },
    {
      "epoch": 1.0644608063687997,
      "grad_norm": 0.9202916622161865,
      "learning_rate": 0.0004999375021514773,
      "loss": 1.0621,
      "step": 100550
    },
    {
      "epoch": 1.064990128148803,
      "grad_norm": 0.9422109723091125,
      "learning_rate": 0.0004999364650765617,
      "loss": 1.0802,
      "step": 100600
    },
    {
      "epoch": 1.0655194499288063,
      "grad_norm": 0.7947072982788086,
      "learning_rate": 0.0004999354194689067,
      "loss": 1.0669,
      "step": 100650
    },
    {
      "epoch": 1.0660487717088094,
      "grad_norm": 0.8129028081893921,
      "learning_rate": 0.0004999343653285483,
      "loss": 1.0535,
      "step": 100700
    },
    {
      "epoch": 1.0665780934888127,
      "grad_norm": 0.9459350109100342,
      "learning_rate": 0.0004999333026555222,
      "loss": 1.034,
      "step": 100750
    },
    {
      "epoch": 1.067107415268816,
      "grad_norm": 0.862963080406189,
      "learning_rate": 0.0004999322314498648,
      "loss": 1.0744,
      "step": 100800
    },
    {
      "epoch": 1.0676367370488193,
      "grad_norm": 0.8477186560630798,
      "learning_rate": 0.0004999311517116128,
      "loss": 1.0509,
      "step": 100850
    },
    {
      "epoch": 1.0681660588288227,
      "grad_norm": 0.8969301581382751,
      "learning_rate": 0.0004999300634408028,
      "loss": 1.069,
      "step": 100900
    },
    {
      "epoch": 1.068695380608826,
      "grad_norm": 1.0221456289291382,
      "learning_rate": 0.0004999289666374722,
      "loss": 1.0748,
      "step": 100950
    },
    {
      "epoch": 1.0692247023888293,
      "grad_norm": 0.9209437370300293,
      "learning_rate": 0.0004999278613016583,
      "loss": 1.0602,
      "step": 101000
    },
    {
      "epoch": 1.0692247023888293,
      "eval_loss": 0.959205687046051,
      "eval_runtime": 46.7451,
      "eval_samples_per_second": 3592.461,
      "eval_steps_per_second": 449.074,
      "step": 101000
    },
    {
      "epoch": 1.0697540241688324,
      "grad_norm": 0.8488098382949829,
      "learning_rate": 0.0004999267474333988,
      "loss": 1.0671,
      "step": 101050
    },
    {
      "epoch": 1.0702833459488357,
      "grad_norm": 0.9038369655609131,
      "learning_rate": 0.000499925625032732,
      "loss": 1.0736,
      "step": 101100
    },
    {
      "epoch": 1.070812667728839,
      "grad_norm": 0.8756781816482544,
      "learning_rate": 0.0004999244940996958,
      "loss": 1.0745,
      "step": 101150
    },
    {
      "epoch": 1.0713419895088423,
      "grad_norm": 0.9346184730529785,
      "learning_rate": 0.0004999233546343292,
      "loss": 1.0695,
      "step": 101200
    },
    {
      "epoch": 1.0718713112888456,
      "grad_norm": 0.9185295701026917,
      "learning_rate": 0.0004999222066366709,
      "loss": 1.0673,
      "step": 101250
    },
    {
      "epoch": 1.072400633068849,
      "grad_norm": 0.8908816576004028,
      "learning_rate": 0.0004999210501067601,
      "loss": 1.0728,
      "step": 101300
    },
    {
      "epoch": 1.0729299548488522,
      "grad_norm": 0.7736466526985168,
      "learning_rate": 0.0004999198850446362,
      "loss": 1.0613,
      "step": 101350
    },
    {
      "epoch": 1.0734592766288555,
      "grad_norm": 0.9311177134513855,
      "learning_rate": 0.0004999187114503392,
      "loss": 1.0656,
      "step": 101400
    },
    {
      "epoch": 1.0739885984088586,
      "grad_norm": 0.8785151243209839,
      "learning_rate": 0.000499917529323909,
      "loss": 1.0662,
      "step": 101450
    },
    {
      "epoch": 1.074517920188862,
      "grad_norm": 0.8621217608451843,
      "learning_rate": 0.000499916338665386,
      "loss": 1.0756,
      "step": 101500
    },
    {
      "epoch": 1.074517920188862,
      "eval_loss": 0.9568111300468445,
      "eval_runtime": 46.7627,
      "eval_samples_per_second": 3591.114,
      "eval_steps_per_second": 448.905,
      "step": 101500
    },
    {
      "epoch": 1.0750472419688653,
      "grad_norm": 0.9106897711753845,
      "learning_rate": 0.0004999151394748109,
      "loss": 1.071,
      "step": 101550
    },
    {
      "epoch": 1.0755765637488686,
      "grad_norm": 0.8685281872749329,
      "learning_rate": 0.0004999139317522246,
      "loss": 1.065,
      "step": 101600
    },
    {
      "epoch": 1.0761058855288719,
      "grad_norm": 0.9261921644210815,
      "learning_rate": 0.0004999127154976682,
      "loss": 1.0748,
      "step": 101650
    },
    {
      "epoch": 1.0766352073088752,
      "grad_norm": 0.9392543435096741,
      "learning_rate": 0.0004999114907111835,
      "loss": 1.0657,
      "step": 101700
    },
    {
      "epoch": 1.0771645290888785,
      "grad_norm": 0.8363684415817261,
      "learning_rate": 0.000499910257392812,
      "loss": 1.0676,
      "step": 101750
    },
    {
      "epoch": 1.0776938508688816,
      "grad_norm": 0.9305437803268433,
      "learning_rate": 0.0004999090155425961,
      "loss": 1.0506,
      "step": 101800
    },
    {
      "epoch": 1.078223172648885,
      "grad_norm": 0.859172523021698,
      "learning_rate": 0.000499907765160578,
      "loss": 1.064,
      "step": 101850
    },
    {
      "epoch": 1.0787524944288882,
      "grad_norm": 0.9777531027793884,
      "learning_rate": 0.0004999065062468005,
      "loss": 1.0443,
      "step": 101900
    },
    {
      "epoch": 1.0792818162088915,
      "grad_norm": 0.9021552801132202,
      "learning_rate": 0.0004999052388013065,
      "loss": 1.0474,
      "step": 101950
    },
    {
      "epoch": 1.0798111379888948,
      "grad_norm": 0.905273973941803,
      "learning_rate": 0.0004999039628241392,
      "loss": 1.0687,
      "step": 102000
    },
    {
      "epoch": 1.0798111379888948,
      "eval_loss": 0.95783531665802,
      "eval_runtime": 46.7346,
      "eval_samples_per_second": 3593.271,
      "eval_steps_per_second": 449.175,
      "step": 102000
    },
    {
      "epoch": 1.0803404597688981,
      "grad_norm": 0.8051391243934631,
      "learning_rate": 0.0004999026783153424,
      "loss": 1.0735,
      "step": 102050
    },
    {
      "epoch": 1.0808697815489015,
      "grad_norm": 0.8404805064201355,
      "learning_rate": 0.0004999013852749597,
      "loss": 1.066,
      "step": 102100
    },
    {
      "epoch": 1.0813991033289048,
      "grad_norm": 0.8127329349517822,
      "learning_rate": 0.0004999000837030355,
      "loss": 1.0499,
      "step": 102150
    },
    {
      "epoch": 1.0819284251089079,
      "grad_norm": 0.8905640840530396,
      "learning_rate": 0.000499898773599614,
      "loss": 1.0746,
      "step": 102200
    },
    {
      "epoch": 1.0824577468889112,
      "grad_norm": 0.8971083760261536,
      "learning_rate": 0.0004998974814210454,
      "loss": 1.0595,
      "step": 102250
    },
    {
      "epoch": 1.0829870686689145,
      "grad_norm": 0.882116436958313,
      "learning_rate": 0.0004998961544253916,
      "loss": 1.0834,
      "step": 102300
    },
    {
      "epoch": 1.0835163904489178,
      "grad_norm": 0.9753401279449463,
      "learning_rate": 0.0004998948188983749,
      "loss": 1.0624,
      "step": 102350
    },
    {
      "epoch": 1.084045712228921,
      "grad_norm": 0.8725584745407104,
      "learning_rate": 0.0004998934748400405,
      "loss": 1.0469,
      "step": 102400
    },
    {
      "epoch": 1.0845750340089244,
      "grad_norm": 0.7740786671638489,
      "learning_rate": 0.0004998921222504346,
      "loss": 1.0597,
      "step": 102450
    },
    {
      "epoch": 1.0851043557889277,
      "grad_norm": 0.9253658652305603,
      "learning_rate": 0.0004998907611296034,
      "loss": 1.0718,
      "step": 102500
    },
    {
      "epoch": 1.0851043557889277,
      "eval_loss": 0.9576367139816284,
      "eval_runtime": 46.717,
      "eval_samples_per_second": 3594.62,
      "eval_steps_per_second": 449.344,
      "step": 102500
    },
    {
      "epoch": 1.085633677568931,
      "grad_norm": 0.842667281627655,
      "learning_rate": 0.0004998893914775932,
      "loss": 1.0778,
      "step": 102550
    },
    {
      "epoch": 1.0861629993489341,
      "grad_norm": 0.7993026375770569,
      "learning_rate": 0.0004998880132944508,
      "loss": 1.0651,
      "step": 102600
    },
    {
      "epoch": 1.0866923211289374,
      "grad_norm": 0.9279971122741699,
      "learning_rate": 0.0004998866265802233,
      "loss": 1.0496,
      "step": 102650
    },
    {
      "epoch": 1.0872216429089407,
      "grad_norm": 0.939436137676239,
      "learning_rate": 0.000499885231334958,
      "loss": 1.068,
      "step": 102700
    },
    {
      "epoch": 1.087750964688944,
      "grad_norm": 0.8627026081085205,
      "learning_rate": 0.0004998838275587026,
      "loss": 1.0578,
      "step": 102750
    },
    {
      "epoch": 1.0882802864689474,
      "grad_norm": 0.915796160697937,
      "learning_rate": 0.0004998824152515048,
      "loss": 1.0744,
      "step": 102800
    },
    {
      "epoch": 1.0888096082489507,
      "grad_norm": 0.9162267446517944,
      "learning_rate": 0.0004998809944134131,
      "loss": 1.0659,
      "step": 102850
    },
    {
      "epoch": 1.089338930028954,
      "grad_norm": 0.9203485250473022,
      "learning_rate": 0.0004998795650444759,
      "loss": 1.0498,
      "step": 102900
    },
    {
      "epoch": 1.0898682518089573,
      "grad_norm": 0.7738641500473022,
      "learning_rate": 0.000499878127144742,
      "loss": 1.0498,
      "step": 102950
    },
    {
      "epoch": 1.0903975735889604,
      "grad_norm": 0.8107326626777649,
      "learning_rate": 0.0004998766807142604,
      "loss": 1.0333,
      "step": 103000
    },
    {
      "epoch": 1.0903975735889604,
      "eval_loss": 0.9503441452980042,
      "eval_runtime": 46.7898,
      "eval_samples_per_second": 3589.032,
      "eval_steps_per_second": 448.645,
      "step": 103000
    },
    {
      "epoch": 1.0909268953689637,
      "grad_norm": 0.9496166110038757,
      "learning_rate": 0.0004998752257530806,
      "loss": 1.0445,
      "step": 103050
    },
    {
      "epoch": 1.091456217148967,
      "grad_norm": 0.8612014055252075,
      "learning_rate": 0.0004998737622612522,
      "loss": 1.0333,
      "step": 103100
    },
    {
      "epoch": 1.0919855389289703,
      "grad_norm": 0.8126342296600342,
      "learning_rate": 0.0004998722902388253,
      "loss": 1.0702,
      "step": 103150
    },
    {
      "epoch": 1.0925148607089736,
      "grad_norm": 0.8560132384300232,
      "learning_rate": 0.00049987080968585,
      "loss": 1.0405,
      "step": 103200
    },
    {
      "epoch": 1.093044182488977,
      "grad_norm": 0.9130649566650391,
      "learning_rate": 0.0004998693206023769,
      "loss": 1.0572,
      "step": 103250
    },
    {
      "epoch": 1.0935735042689803,
      "grad_norm": 0.8480051159858704,
      "learning_rate": 0.0004998678229884568,
      "loss": 1.0546,
      "step": 103300
    },
    {
      "epoch": 1.0941028260489833,
      "grad_norm": 0.9532070159912109,
      "learning_rate": 0.0004998663168441408,
      "loss": 1.058,
      "step": 103350
    },
    {
      "epoch": 1.0946321478289867,
      "grad_norm": 0.9248425364494324,
      "learning_rate": 0.0004998648021694805,
      "loss": 1.0619,
      "step": 103400
    },
    {
      "epoch": 1.09516146960899,
      "grad_norm": 0.8889198303222656,
      "learning_rate": 0.0004998632789645274,
      "loss": 1.037,
      "step": 103450
    },
    {
      "epoch": 1.0956907913889933,
      "grad_norm": 0.804562509059906,
      "learning_rate": 0.0004998617472293337,
      "loss": 1.0662,
      "step": 103500
    },
    {
      "epoch": 1.0956907913889933,
      "eval_loss": 0.9487345218658447,
      "eval_runtime": 46.7026,
      "eval_samples_per_second": 3595.732,
      "eval_steps_per_second": 449.483,
      "step": 103500
    },
    {
      "epoch": 1.0962201131689966,
      "grad_norm": 0.8295753598213196,
      "learning_rate": 0.0004998602069639515,
      "loss": 1.0513,
      "step": 103550
    },
    {
      "epoch": 1.096749434949,
      "grad_norm": 0.8792895078659058,
      "learning_rate": 0.0004998586581684335,
      "loss": 1.0493,
      "step": 103600
    },
    {
      "epoch": 1.0972787567290032,
      "grad_norm": 0.7683837413787842,
      "learning_rate": 0.0004998571008428325,
      "loss": 1.0457,
      "step": 103650
    },
    {
      "epoch": 1.0978080785090065,
      "grad_norm": 0.9256107211112976,
      "learning_rate": 0.0004998555349872018,
      "loss": 1.0378,
      "step": 103700
    },
    {
      "epoch": 1.0983374002890096,
      "grad_norm": 0.8285589218139648,
      "learning_rate": 0.0004998539606015948,
      "loss": 1.068,
      "step": 103750
    },
    {
      "epoch": 1.098866722069013,
      "grad_norm": 0.8866128921508789,
      "learning_rate": 0.000499852377686065,
      "loss": 1.0493,
      "step": 103800
    },
    {
      "epoch": 1.0993960438490162,
      "grad_norm": 0.9111691117286682,
      "learning_rate": 0.0004998507862406668,
      "loss": 1.0515,
      "step": 103850
    },
    {
      "epoch": 1.0999253656290195,
      "grad_norm": 0.8496351838111877,
      "learning_rate": 0.0004998491862654544,
      "loss": 1.0265,
      "step": 103900
    },
    {
      "epoch": 1.1004546874090229,
      "grad_norm": 0.9433345198631287,
      "learning_rate": 0.0004998475777604822,
      "loss": 1.0659,
      "step": 103950
    },
    {
      "epoch": 1.1009840091890262,
      "grad_norm": 0.931257426738739,
      "learning_rate": 0.0004998459607258056,
      "loss": 1.0519,
      "step": 104000
    },
    {
      "epoch": 1.1009840091890262,
      "eval_loss": 0.9437603950500488,
      "eval_runtime": 46.8076,
      "eval_samples_per_second": 3587.668,
      "eval_steps_per_second": 448.475,
      "step": 104000
    },
    {
      "epoch": 1.1015133309690295,
      "grad_norm": 0.8726123571395874,
      "learning_rate": 0.0004998443351614795,
      "loss": 1.0506,
      "step": 104050
    },
    {
      "epoch": 1.1020426527490326,
      "grad_norm": 0.9291183352470398,
      "learning_rate": 0.0004998427010675593,
      "loss": 1.037,
      "step": 104100
    },
    {
      "epoch": 1.1025719745290359,
      "grad_norm": 0.8912520408630371,
      "learning_rate": 0.000499841058444101,
      "loss": 1.0201,
      "step": 104150
    },
    {
      "epoch": 1.1031012963090392,
      "grad_norm": 0.8820238709449768,
      "learning_rate": 0.0004998394072911605,
      "loss": 1.0508,
      "step": 104200
    },
    {
      "epoch": 1.1036306180890425,
      "grad_norm": 0.7877170443534851,
      "learning_rate": 0.0004998377808860297,
      "loss": 1.0408,
      "step": 104250
    },
    {
      "epoch": 1.1041599398690458,
      "grad_norm": 0.8064412474632263,
      "learning_rate": 0.0004998361128448813,
      "loss": 1.0413,
      "step": 104300
    },
    {
      "epoch": 1.1046892616490491,
      "grad_norm": 0.9263851642608643,
      "learning_rate": 0.0004998344362744196,
      "loss": 1.0525,
      "step": 104350
    },
    {
      "epoch": 1.1052185834290524,
      "grad_norm": 0.9234600067138672,
      "learning_rate": 0.0004998327511747018,
      "loss": 1.0467,
      "step": 104400
    },
    {
      "epoch": 1.1057479052090557,
      "grad_norm": 0.8515931367874146,
      "learning_rate": 0.0004998310575457856,
      "loss": 1.0385,
      "step": 104450
    },
    {
      "epoch": 1.1062772269890588,
      "grad_norm": 0.9491861462593079,
      "learning_rate": 0.0004998293553877287,
      "loss": 1.057,
      "step": 104500
    },
    {
      "epoch": 1.1062772269890588,
      "eval_loss": 0.9418011903762817,
      "eval_runtime": 46.7388,
      "eval_samples_per_second": 3592.944,
      "eval_steps_per_second": 449.134,
      "step": 104500
    },
    {
      "epoch": 1.1068065487690621,
      "grad_norm": 0.8796927332878113,
      "learning_rate": 0.0004998276447005891,
      "loss": 1.0725,
      "step": 104550
    },
    {
      "epoch": 1.1073358705490655,
      "grad_norm": 0.8596900105476379,
      "learning_rate": 0.0004998259254844255,
      "loss": 1.0606,
      "step": 104600
    },
    {
      "epoch": 1.1078651923290688,
      "grad_norm": 0.8069815039634705,
      "learning_rate": 0.0004998241977392965,
      "loss": 1.051,
      "step": 104650
    },
    {
      "epoch": 1.108394514109072,
      "grad_norm": 0.9295576214790344,
      "learning_rate": 0.0004998224614652608,
      "loss": 1.033,
      "step": 104700
    },
    {
      "epoch": 1.1089238358890754,
      "grad_norm": 0.8913846015930176,
      "learning_rate": 0.000499820716662378,
      "loss": 1.0399,
      "step": 104750
    },
    {
      "epoch": 1.1094531576690787,
      "grad_norm": 0.8753532767295837,
      "learning_rate": 0.0004998189633307075,
      "loss": 1.0524,
      "step": 104800
    },
    {
      "epoch": 1.1099824794490818,
      "grad_norm": 0.8872460722923279,
      "learning_rate": 0.0004998172014703091,
      "loss": 1.0631,
      "step": 104850
    },
    {
      "epoch": 1.110511801229085,
      "grad_norm": 0.9006024599075317,
      "learning_rate": 0.0004998154310812433,
      "loss": 1.0489,
      "step": 104900
    },
    {
      "epoch": 1.1110411230090884,
      "grad_norm": 0.856636106967926,
      "learning_rate": 0.0004998136521635702,
      "loss": 1.0419,
      "step": 104950
    },
    {
      "epoch": 1.1115704447890917,
      "grad_norm": 0.9414250254631042,
      "learning_rate": 0.0004998118647173506,
      "loss": 1.0619,
      "step": 105000
    },
    {
      "epoch": 1.1115704447890917,
      "eval_loss": 0.940555989742279,
      "eval_runtime": 46.8097,
      "eval_samples_per_second": 3587.507,
      "eval_steps_per_second": 448.454,
      "step": 105000
    },
    {
      "epoch": 1.112099766569095,
      "grad_norm": 0.8496819734573364,
      "learning_rate": 0.0004998100687426455,
      "loss": 1.0517,
      "step": 105050
    },
    {
      "epoch": 1.1126290883490983,
      "grad_norm": 0.889393150806427,
      "learning_rate": 0.0004998082642395165,
      "loss": 1.0505,
      "step": 105100
    },
    {
      "epoch": 1.1131584101291017,
      "grad_norm": 0.950130045413971,
      "learning_rate": 0.0004998064512080247,
      "loss": 1.0363,
      "step": 105150
    },
    {
      "epoch": 1.113687731909105,
      "grad_norm": 0.8976086974143982,
      "learning_rate": 0.0004998046296482324,
      "loss": 1.0379,
      "step": 105200
    },
    {
      "epoch": 1.114217053689108,
      "grad_norm": 0.8599693179130554,
      "learning_rate": 0.0004998027995602017,
      "loss": 1.0417,
      "step": 105250
    },
    {
      "epoch": 1.1147463754691114,
      "grad_norm": 0.880263090133667,
      "learning_rate": 0.000499800960943995,
      "loss": 1.041,
      "step": 105300
    },
    {
      "epoch": 1.1152756972491147,
      "grad_norm": 0.8301604986190796,
      "learning_rate": 0.000499799113799675,
      "loss": 1.0267,
      "step": 105350
    },
    {
      "epoch": 1.115805019029118,
      "grad_norm": 0.8906338214874268,
      "learning_rate": 0.000499797258127305,
      "loss": 1.0324,
      "step": 105400
    },
    {
      "epoch": 1.1163343408091213,
      "grad_norm": 0.8642338514328003,
      "learning_rate": 0.0004997953939269482,
      "loss": 1.0562,
      "step": 105450
    },
    {
      "epoch": 1.1168636625891246,
      "grad_norm": 0.9222559928894043,
      "learning_rate": 0.0004997935211986682,
      "loss": 1.0415,
      "step": 105500
    },
    {
      "epoch": 1.1168636625891246,
      "eval_loss": 0.9364370703697205,
      "eval_runtime": 46.7403,
      "eval_samples_per_second": 3592.828,
      "eval_steps_per_second": 449.119,
      "step": 105500
    },
    {
      "epoch": 1.117392984369128,
      "grad_norm": 0.9113327860832214,
      "learning_rate": 0.000499791639942529,
      "loss": 1.0439,
      "step": 105550
    },
    {
      "epoch": 1.117922306149131,
      "grad_norm": 0.8749047517776489,
      "learning_rate": 0.0004997897501585948,
      "loss": 1.0402,
      "step": 105600
    },
    {
      "epoch": 1.1184516279291343,
      "grad_norm": 0.8439335227012634,
      "learning_rate": 0.0004997878518469303,
      "loss": 1.0349,
      "step": 105650
    },
    {
      "epoch": 1.1189809497091376,
      "grad_norm": 0.8241628408432007,
      "learning_rate": 0.0004997859450076,
      "loss": 1.044,
      "step": 105700
    },
    {
      "epoch": 1.119510271489141,
      "grad_norm": 0.921882152557373,
      "learning_rate": 0.0004997840296406691,
      "loss": 1.0327,
      "step": 105750
    },
    {
      "epoch": 1.1200395932691443,
      "grad_norm": 0.9577875733375549,
      "learning_rate": 0.0004997821057462032,
      "loss": 1.0826,
      "step": 105800
    },
    {
      "epoch": 1.1205689150491476,
      "grad_norm": 0.9280028939247131,
      "learning_rate": 0.0004997801733242676,
      "loss": 1.0521,
      "step": 105850
    },
    {
      "epoch": 1.1210982368291509,
      "grad_norm": 0.8930134773254395,
      "learning_rate": 0.0004997782323749287,
      "loss": 1.0394,
      "step": 105900
    },
    {
      "epoch": 1.1216275586091542,
      "grad_norm": 0.9965606331825256,
      "learning_rate": 0.0004997762828982524,
      "loss": 1.0364,
      "step": 105950
    },
    {
      "epoch": 1.1221568803891573,
      "grad_norm": 0.8214365839958191,
      "learning_rate": 0.0004997743248943055,
      "loss": 1.0372,
      "step": 106000
    },
    {
      "epoch": 1.1221568803891573,
      "eval_loss": 0.9328001141548157,
      "eval_runtime": 46.8014,
      "eval_samples_per_second": 3588.141,
      "eval_steps_per_second": 448.534,
      "step": 106000
    },
    {
      "epoch": 1.1226862021691606,
      "grad_norm": 0.8826332092285156,
      "learning_rate": 0.0004997723583631547,
      "loss": 1.0444,
      "step": 106050
    },
    {
      "epoch": 1.123215523949164,
      "grad_norm": 0.8468538522720337,
      "learning_rate": 0.0004997703833048672,
      "loss": 1.0313,
      "step": 106100
    },
    {
      "epoch": 1.1237448457291672,
      "grad_norm": 0.8674399852752686,
      "learning_rate": 0.0004997683997195104,
      "loss": 1.0566,
      "step": 106150
    },
    {
      "epoch": 1.1242741675091705,
      "grad_norm": 0.8652322292327881,
      "learning_rate": 0.000499766407607152,
      "loss": 1.0446,
      "step": 106200
    },
    {
      "epoch": 1.1248034892891738,
      "grad_norm": 0.7588506937026978,
      "learning_rate": 0.0004997644470642095,
      "loss": 1.0342,
      "step": 106250
    },
    {
      "epoch": 1.1253328110691772,
      "grad_norm": 0.9533407092094421,
      "learning_rate": 0.0004997624380685891,
      "loss": 1.0351,
      "step": 106300
    },
    {
      "epoch": 1.1258621328491802,
      "grad_norm": 0.9385863542556763,
      "learning_rate": 0.0004997604205461704,
      "loss": 1.0384,
      "step": 106350
    },
    {
      "epoch": 1.1263914546291836,
      "grad_norm": 1.0146514177322388,
      "learning_rate": 0.0004997583944970226,
      "loss": 1.0203,
      "step": 106400
    },
    {
      "epoch": 1.1269207764091869,
      "grad_norm": 0.9471427798271179,
      "learning_rate": 0.000499756359921215,
      "loss": 1.0304,
      "step": 106450
    },
    {
      "epoch": 1.1274500981891902,
      "grad_norm": 0.8825026154518127,
      "learning_rate": 0.0004997543168188167,
      "loss": 1.037,
      "step": 106500
    },
    {
      "epoch": 1.1274500981891902,
      "eval_loss": 0.9264225363731384,
      "eval_runtime": 46.822,
      "eval_samples_per_second": 3586.564,
      "eval_steps_per_second": 448.337,
      "step": 106500
    },
    {
      "epoch": 1.1279794199691935,
      "grad_norm": 0.847389817237854,
      "learning_rate": 0.0004997522651898977,
      "loss": 1.0375,
      "step": 106550
    },
    {
      "epoch": 1.1285087417491968,
      "grad_norm": 0.8014298677444458,
      "learning_rate": 0.0004997502050345279,
      "loss": 1.045,
      "step": 106600
    },
    {
      "epoch": 1.1290380635292,
      "grad_norm": 0.964074969291687,
      "learning_rate": 0.0004997481363527778,
      "loss": 1.0505,
      "step": 106650
    },
    {
      "epoch": 1.1295673853092034,
      "grad_norm": 0.9050287008285522,
      "learning_rate": 0.0004997460591447177,
      "loss": 1.0375,
      "step": 106700
    },
    {
      "epoch": 1.1300967070892065,
      "grad_norm": 0.9368373155593872,
      "learning_rate": 0.0004997439734104189,
      "loss": 1.0325,
      "step": 106750
    },
    {
      "epoch": 1.1306260288692098,
      "grad_norm": 0.8843327760696411,
      "learning_rate": 0.0004997418791499524,
      "loss": 1.06,
      "step": 106800
    },
    {
      "epoch": 1.1311553506492131,
      "grad_norm": 0.8694649338722229,
      "learning_rate": 0.0004997397763633897,
      "loss": 1.0453,
      "step": 106850
    },
    {
      "epoch": 1.1316846724292164,
      "grad_norm": 0.8009021878242493,
      "learning_rate": 0.0004997376650508027,
      "loss": 1.0124,
      "step": 106900
    },
    {
      "epoch": 1.1322139942092198,
      "grad_norm": 0.9231789112091064,
      "learning_rate": 0.0004997355452122634,
      "loss": 1.0495,
      "step": 106950
    },
    {
      "epoch": 1.132743315989223,
      "grad_norm": 0.7450538277626038,
      "learning_rate": 0.0004997334168478441,
      "loss": 1.042,
      "step": 107000
    },
    {
      "epoch": 1.132743315989223,
      "eval_loss": 0.928118109703064,
      "eval_runtime": 46.817,
      "eval_samples_per_second": 3586.945,
      "eval_steps_per_second": 448.384,
      "step": 107000
    },
    {
      "epoch": 1.1332726377692264,
      "grad_norm": 0.9141377210617065,
      "learning_rate": 0.0004997312799576176,
      "loss": 1.0411,
      "step": 107050
    },
    {
      "epoch": 1.1338019595492295,
      "grad_norm": 0.8330197334289551,
      "learning_rate": 0.0004997291345416568,
      "loss": 1.0468,
      "step": 107100
    },
    {
      "epoch": 1.1343312813292328,
      "grad_norm": 0.8977432250976562,
      "learning_rate": 0.000499726980600035,
      "loss": 1.0371,
      "step": 107150
    },
    {
      "epoch": 1.134860603109236,
      "grad_norm": 0.8201136589050293,
      "learning_rate": 0.0004997248181328255,
      "loss": 1.0418,
      "step": 107200
    },
    {
      "epoch": 1.1353899248892394,
      "grad_norm": 0.9298213124275208,
      "learning_rate": 0.0004997226471401023,
      "loss": 1.0579,
      "step": 107250
    },
    {
      "epoch": 1.1359192466692427,
      "grad_norm": 0.9240947365760803,
      "learning_rate": 0.0004997204676219396,
      "loss": 1.0391,
      "step": 107300
    },
    {
      "epoch": 1.136448568449246,
      "grad_norm": 0.8498980402946472,
      "learning_rate": 0.0004997182795784118,
      "loss": 1.0254,
      "step": 107350
    },
    {
      "epoch": 1.1369778902292493,
      "grad_norm": 0.8734449744224548,
      "learning_rate": 0.0004997160830095933,
      "loss": 1.0273,
      "step": 107400
    },
    {
      "epoch": 1.1375072120092526,
      "grad_norm": 0.8506470918655396,
      "learning_rate": 0.0004997138779155594,
      "loss": 1.0208,
      "step": 107450
    },
    {
      "epoch": 1.1380365337892557,
      "grad_norm": 0.8546017408370972,
      "learning_rate": 0.0004997116642963854,
      "loss": 1.0142,
      "step": 107500
    },
    {
      "epoch": 1.1380365337892557,
      "eval_loss": 0.9233129024505615,
      "eval_runtime": 46.8053,
      "eval_samples_per_second": 3587.844,
      "eval_steps_per_second": 448.497,
      "step": 107500
    },
    {
      "epoch": 1.138565855569259,
      "grad_norm": 0.8631120324134827,
      "learning_rate": 0.0004997094421521467,
      "loss": 1.0291,
      "step": 107550
    },
    {
      "epoch": 1.1390951773492624,
      "grad_norm": 0.8565917015075684,
      "learning_rate": 0.0004997072114829191,
      "loss": 1.0255,
      "step": 107600
    },
    {
      "epoch": 1.1396244991292657,
      "grad_norm": 0.9895427823066711,
      "learning_rate": 0.000499704972288779,
      "loss": 1.0404,
      "step": 107650
    },
    {
      "epoch": 1.140153820909269,
      "grad_norm": 0.8121927380561829,
      "learning_rate": 0.0004997027245698027,
      "loss": 1.0389,
      "step": 107700
    },
    {
      "epoch": 1.1406831426892723,
      "grad_norm": 0.8063798546791077,
      "learning_rate": 0.0004997004683260669,
      "loss": 1.0223,
      "step": 107750
    },
    {
      "epoch": 1.1412124644692756,
      "grad_norm": 0.948701024055481,
      "learning_rate": 0.0004996982035576487,
      "loss": 1.0458,
      "step": 107800
    },
    {
      "epoch": 1.1417417862492787,
      "grad_norm": 0.9150106906890869,
      "learning_rate": 0.0004996959302646254,
      "loss": 1.0208,
      "step": 107850
    },
    {
      "epoch": 1.142271108029282,
      "grad_norm": 0.9282128214836121,
      "learning_rate": 0.0004996936484470747,
      "loss": 1.0601,
      "step": 107900
    },
    {
      "epoch": 1.1428004298092853,
      "grad_norm": 0.8516324758529663,
      "learning_rate": 0.0004996913581050744,
      "loss": 1.0359,
      "step": 107950
    },
    {
      "epoch": 1.1433297515892886,
      "grad_norm": 0.9112682342529297,
      "learning_rate": 0.0004996890592387027,
      "loss": 1.0414,
      "step": 108000
    },
    {
      "epoch": 1.1433297515892886,
      "eval_loss": 0.9221949577331543,
      "eval_runtime": 46.8461,
      "eval_samples_per_second": 3584.715,
      "eval_steps_per_second": 448.105,
      "step": 108000
    },
    {
      "epoch": 1.143859073369292,
      "grad_norm": 0.7502726316452026,
      "learning_rate": 0.000499686751848038,
      "loss": 1.0526,
      "step": 108050
    },
    {
      "epoch": 1.1443883951492952,
      "grad_norm": 0.8649260401725769,
      "learning_rate": 0.0004996844359331593,
      "loss": 1.0466,
      "step": 108100
    },
    {
      "epoch": 1.1449177169292986,
      "grad_norm": 0.9713262319564819,
      "learning_rate": 0.0004996821114941454,
      "loss": 1.0484,
      "step": 108150
    },
    {
      "epoch": 1.1454470387093019,
      "grad_norm": 0.96943199634552,
      "learning_rate": 0.0004996797785310758,
      "loss": 1.0274,
      "step": 108200
    },
    {
      "epoch": 1.145976360489305,
      "grad_norm": 0.8180297613143921,
      "learning_rate": 0.0004996774370440302,
      "loss": 1.0356,
      "step": 108250
    },
    {
      "epoch": 1.1465056822693083,
      "grad_norm": 0.8353510499000549,
      "learning_rate": 0.0004996751341168409,
      "loss": 1.0301,
      "step": 108300
    },
    {
      "epoch": 1.1470350040493116,
      "grad_norm": 0.8295706510543823,
      "learning_rate": 0.0004996727757525588,
      "loss": 1.0296,
      "step": 108350
    },
    {
      "epoch": 1.147564325829315,
      "grad_norm": 0.8875696063041687,
      "learning_rate": 0.0004996704088645396,
      "loss": 1.038,
      "step": 108400
    },
    {
      "epoch": 1.1480936476093182,
      "grad_norm": 1.0212687253952026,
      "learning_rate": 0.0004996680334528643,
      "loss": 1.0411,
      "step": 108450
    },
    {
      "epoch": 1.1486229693893215,
      "grad_norm": 0.9229699373245239,
      "learning_rate": 0.0004996656495176138,
      "loss": 1.0424,
      "step": 108500
    },
    {
      "epoch": 1.1486229693893215,
      "eval_loss": 0.9196479916572571,
      "eval_runtime": 46.8481,
      "eval_samples_per_second": 3584.566,
      "eval_steps_per_second": 448.087,
      "step": 108500
    },
    {
      "epoch": 1.1491522911693248,
      "grad_norm": 0.7596287727355957,
      "learning_rate": 0.0004996632570588697,
      "loss": 1.0294,
      "step": 108550
    },
    {
      "epoch": 1.149681612949328,
      "grad_norm": 0.9218653440475464,
      "learning_rate": 0.0004996608560767135,
      "loss": 1.0242,
      "step": 108600
    },
    {
      "epoch": 1.1502109347293312,
      "grad_norm": 0.8827550411224365,
      "learning_rate": 0.0004996584465712272,
      "loss": 1.0407,
      "step": 108650
    },
    {
      "epoch": 1.1507402565093345,
      "grad_norm": 0.9180728793144226,
      "learning_rate": 0.0004996560285424931,
      "loss": 1.0245,
      "step": 108700
    },
    {
      "epoch": 1.1512695782893378,
      "grad_norm": 0.779299795627594,
      "learning_rate": 0.0004996536019905938,
      "loss": 1.0273,
      "step": 108750
    },
    {
      "epoch": 1.1517989000693412,
      "grad_norm": 0.8977614045143127,
      "learning_rate": 0.0004996511669156121,
      "loss": 1.0113,
      "step": 108800
    },
    {
      "epoch": 1.1523282218493445,
      "grad_norm": 0.76668781042099,
      "learning_rate": 0.0004996487233176312,
      "loss": 1.0209,
      "step": 108850
    },
    {
      "epoch": 1.1528575436293478,
      "grad_norm": 0.8250520825386047,
      "learning_rate": 0.0004996462711967342,
      "loss": 1.0275,
      "step": 108900
    },
    {
      "epoch": 1.153386865409351,
      "grad_norm": 0.8914416432380676,
      "learning_rate": 0.0004996438105530053,
      "loss": 1.0519,
      "step": 108950
    },
    {
      "epoch": 1.1539161871893544,
      "grad_norm": 0.8576323986053467,
      "learning_rate": 0.0004996413413865281,
      "loss": 1.0022,
      "step": 109000
    },
    {
      "epoch": 1.1539161871893544,
      "eval_loss": 0.9137181639671326,
      "eval_runtime": 46.9306,
      "eval_samples_per_second": 3578.26,
      "eval_steps_per_second": 447.298,
      "step": 109000
    },
    {
      "epoch": 1.1544455089693575,
      "grad_norm": 0.8408291935920715,
      "learning_rate": 0.000499638863697387,
      "loss": 1.0299,
      "step": 109050
    },
    {
      "epoch": 1.1549748307493608,
      "grad_norm": 0.9001376032829285,
      "learning_rate": 0.0004996363774856668,
      "loss": 1.0372,
      "step": 109100
    },
    {
      "epoch": 1.1555041525293641,
      "grad_norm": 0.8897679448127747,
      "learning_rate": 0.0004996338827514522,
      "loss": 1.0337,
      "step": 109150
    },
    {
      "epoch": 1.1560334743093674,
      "grad_norm": 0.8727008700370789,
      "learning_rate": 0.0004996313794948283,
      "loss": 1.0329,
      "step": 109200
    },
    {
      "epoch": 1.1565627960893707,
      "grad_norm": 0.8927278518676758,
      "learning_rate": 0.0004996288677158808,
      "loss": 1.0468,
      "step": 109250
    },
    {
      "epoch": 1.157092117869374,
      "grad_norm": 0.8512272834777832,
      "learning_rate": 0.0004996263474146952,
      "loss": 1.0384,
      "step": 109300
    },
    {
      "epoch": 1.1576214396493771,
      "grad_norm": 0.8812863826751709,
      "learning_rate": 0.0004996238185913576,
      "loss": 1.0298,
      "step": 109350
    },
    {
      "epoch": 1.1581507614293804,
      "grad_norm": 0.8863905668258667,
      "learning_rate": 0.0004996212812459545,
      "loss": 1.0051,
      "step": 109400
    },
    {
      "epoch": 1.1586800832093838,
      "grad_norm": 0.8242185115814209,
      "learning_rate": 0.0004996187353785723,
      "loss": 1.0434,
      "step": 109450
    },
    {
      "epoch": 1.159209404989387,
      "grad_norm": 0.9162521362304688,
      "learning_rate": 0.0004996161809892981,
      "loss": 1.0121,
      "step": 109500
    },
    {
      "epoch": 1.159209404989387,
      "eval_loss": 0.9083801507949829,
      "eval_runtime": 46.9458,
      "eval_samples_per_second": 3577.102,
      "eval_steps_per_second": 447.154,
      "step": 109500
    },
    {
      "epoch": 1.1597387267693904,
      "grad_norm": 0.9531998038291931,
      "learning_rate": 0.000499613618078219,
      "loss": 1.0276,
      "step": 109550
    },
    {
      "epoch": 1.1602680485493937,
      "grad_norm": 0.9620596170425415,
      "learning_rate": 0.0004996110466454226,
      "loss": 1.0315,
      "step": 109600
    },
    {
      "epoch": 1.160797370329397,
      "grad_norm": 0.9589582681655884,
      "learning_rate": 0.0004996084666909965,
      "loss": 1.0303,
      "step": 109650
    },
    {
      "epoch": 1.1613266921094003,
      "grad_norm": 0.8114360570907593,
      "learning_rate": 0.000499605878215029,
      "loss": 1.0026,
      "step": 109700
    },
    {
      "epoch": 1.1618560138894036,
      "grad_norm": 0.9035800695419312,
      "learning_rate": 0.0004996032812176083,
      "loss": 1.0341,
      "step": 109750
    },
    {
      "epoch": 1.1623853356694067,
      "grad_norm": 0.8084819316864014,
      "learning_rate": 0.0004996006756988231,
      "loss": 1.0182,
      "step": 109800
    },
    {
      "epoch": 1.16291465744941,
      "grad_norm": 0.8535900712013245,
      "learning_rate": 0.0004995980616587623,
      "loss": 1.0332,
      "step": 109850
    },
    {
      "epoch": 1.1634439792294133,
      "grad_norm": 0.8609711527824402,
      "learning_rate": 0.0004995954390975152,
      "loss": 1.0321,
      "step": 109900
    },
    {
      "epoch": 1.1639733010094166,
      "grad_norm": 0.8775877952575684,
      "learning_rate": 0.0004995928080151715,
      "loss": 1.0436,
      "step": 109950
    },
    {
      "epoch": 1.16450262278942,
      "grad_norm": 0.8930417895317078,
      "learning_rate": 0.0004995901684118208,
      "loss": 1.0342,
      "step": 110000
    },
    {
      "epoch": 1.16450262278942,
      "eval_loss": 0.9067893624305725,
      "eval_runtime": 46.8605,
      "eval_samples_per_second": 3583.617,
      "eval_steps_per_second": 447.968,
      "step": 110000
    },
    {
      "epoch": 1.1650319445694233,
      "grad_norm": 0.9003604650497437,
      "learning_rate": 0.0004995875202875533,
      "loss": 1.0211,
      "step": 110050
    },
    {
      "epoch": 1.1655612663494264,
      "grad_norm": 0.7941272258758545,
      "learning_rate": 0.0004995848636424594,
      "loss": 1.0344,
      "step": 110100
    },
    {
      "epoch": 1.1660905881294297,
      "grad_norm": 0.8354885578155518,
      "learning_rate": 0.0004995821984766297,
      "loss": 1.0247,
      "step": 110150
    },
    {
      "epoch": 1.166619909909433,
      "grad_norm": 0.9090385437011719,
      "learning_rate": 0.0004995795247901553,
      "loss": 1.0216,
      "step": 110200
    },
    {
      "epoch": 1.1671492316894363,
      "grad_norm": 0.9484313130378723,
      "learning_rate": 0.0004995768425831276,
      "loss": 1.0327,
      "step": 110250
    },
    {
      "epoch": 1.1676785534694396,
      "grad_norm": 0.9289126396179199,
      "learning_rate": 0.0004995741518556379,
      "loss": 1.0152,
      "step": 110300
    },
    {
      "epoch": 1.168207875249443,
      "grad_norm": 0.9338936805725098,
      "learning_rate": 0.0004995714526077782,
      "loss": 1.0103,
      "step": 110350
    },
    {
      "epoch": 1.1687371970294462,
      "grad_norm": 0.9007090330123901,
      "learning_rate": 0.0004995687448396406,
      "loss": 1.0336,
      "step": 110400
    },
    {
      "epoch": 1.1692665188094495,
      "grad_norm": 1.029759168624878,
      "learning_rate": 0.0004995660285513176,
      "loss": 1.0215,
      "step": 110450
    },
    {
      "epoch": 1.1697958405894529,
      "grad_norm": 0.9091730117797852,
      "learning_rate": 0.0004995633037429019,
      "loss": 1.021,
      "step": 110500
    },
    {
      "epoch": 1.1697958405894529,
      "eval_loss": 0.9070855379104614,
      "eval_runtime": 46.7753,
      "eval_samples_per_second": 3590.145,
      "eval_steps_per_second": 448.784,
      "step": 110500
    },
    {
      "epoch": 1.170325162369456,
      "grad_norm": 0.8946425318717957,
      "learning_rate": 0.0004995605704144866,
      "loss": 1.0228,
      "step": 110550
    },
    {
      "epoch": 1.1708544841494593,
      "grad_norm": 0.9604650139808655,
      "learning_rate": 0.000499557828566165,
      "loss": 1.0217,
      "step": 110600
    },
    {
      "epoch": 1.1713838059294626,
      "grad_norm": 0.9007952213287354,
      "learning_rate": 0.0004995551332888867,
      "loss": 1.0201,
      "step": 110650
    },
    {
      "epoch": 1.1719131277094659,
      "grad_norm": 0.919520378112793,
      "learning_rate": 0.0004995523745714268,
      "loss": 1.0376,
      "step": 110700
    },
    {
      "epoch": 1.1724424494894692,
      "grad_norm": 0.9691012501716614,
      "learning_rate": 0.0004995496073343405,
      "loss": 1.0302,
      "step": 110750
    },
    {
      "epoch": 1.1729717712694725,
      "grad_norm": 0.8516190052032471,
      "learning_rate": 0.0004995468315777221,
      "loss": 1.034,
      "step": 110800
    },
    {
      "epoch": 1.1735010930494756,
      "grad_norm": 0.8631696105003357,
      "learning_rate": 0.0004995440473016663,
      "loss": 1.0263,
      "step": 110850
    },
    {
      "epoch": 1.174030414829479,
      "grad_norm": 0.89963299036026,
      "learning_rate": 0.0004995412545062683,
      "loss": 1.0137,
      "step": 110900
    },
    {
      "epoch": 1.1745597366094822,
      "grad_norm": 0.7903314232826233,
      "learning_rate": 0.0004995384531916233,
      "loss": 1.0001,
      "step": 110950
    },
    {
      "epoch": 1.1750890583894855,
      "grad_norm": 0.9217109084129333,
      "learning_rate": 0.0004995356433578271,
      "loss": 1.014,
      "step": 111000
    },
    {
      "epoch": 1.1750890583894855,
      "eval_loss": 0.9021599292755127,
      "eval_runtime": 46.801,
      "eval_samples_per_second": 3588.168,
      "eval_steps_per_second": 448.537,
      "step": 111000
    },
    {
      "epoch": 1.1756183801694888,
      "grad_norm": 0.8568618893623352,
      "learning_rate": 0.0004995328250049756,
      "loss": 1.0252,
      "step": 111050
    },
    {
      "epoch": 1.1761477019494921,
      "grad_norm": 0.8448590040206909,
      "learning_rate": 0.000499529998133165,
      "loss": 1.0143,
      "step": 111100
    },
    {
      "epoch": 1.1766770237294955,
      "grad_norm": 0.8711405396461487,
      "learning_rate": 0.0004995271627424916,
      "loss": 1.013,
      "step": 111150
    },
    {
      "epoch": 1.1772063455094988,
      "grad_norm": 0.7527994513511658,
      "learning_rate": 0.0004995243188330525,
      "loss": 1.0134,
      "step": 111200
    },
    {
      "epoch": 1.177735667289502,
      "grad_norm": 0.9891350269317627,
      "learning_rate": 0.0004995214664049446,
      "loss": 0.9954,
      "step": 111250
    },
    {
      "epoch": 1.1782649890695052,
      "grad_norm": 0.8882182240486145,
      "learning_rate": 0.0004995186054582653,
      "loss": 1.0143,
      "step": 111300
    },
    {
      "epoch": 1.1787943108495085,
      "grad_norm": 0.8988556265830994,
      "learning_rate": 0.0004995157359931124,
      "loss": 1.011,
      "step": 111350
    },
    {
      "epoch": 1.1793236326295118,
      "grad_norm": 0.8681945204734802,
      "learning_rate": 0.0004995128580095838,
      "loss": 1.0263,
      "step": 111400
    },
    {
      "epoch": 1.179852954409515,
      "grad_norm": 0.9452704191207886,
      "learning_rate": 0.0004995099715077777,
      "loss": 1.0518,
      "step": 111450
    },
    {
      "epoch": 1.1803822761895184,
      "grad_norm": 0.8616917133331299,
      "learning_rate": 0.0004995070764877927,
      "loss": 1.0104,
      "step": 111500
    },
    {
      "epoch": 1.1803822761895184,
      "eval_loss": 0.9083724617958069,
      "eval_runtime": 46.7967,
      "eval_samples_per_second": 3588.501,
      "eval_steps_per_second": 448.579,
      "step": 111500
    },
    {
      "epoch": 1.1809115979695217,
      "grad_norm": 0.7788267135620117,
      "learning_rate": 0.0004995041729497276,
      "loss": 1.0209,
      "step": 111550
    },
    {
      "epoch": 1.1814409197495248,
      "grad_norm": 0.8459413647651672,
      "learning_rate": 0.0004995012608936815,
      "loss": 1.0392,
      "step": 111600
    },
    {
      "epoch": 1.1819702415295281,
      "grad_norm": 0.9004979133605957,
      "learning_rate": 0.000499498340319754,
      "loss": 1.0311,
      "step": 111650
    },
    {
      "epoch": 1.1824995633095314,
      "grad_norm": 0.7996748089790344,
      "learning_rate": 0.0004994954112280444,
      "loss": 1.0213,
      "step": 111700
    },
    {
      "epoch": 1.1830288850895347,
      "grad_norm": 0.946051836013794,
      "learning_rate": 0.0004994924736186532,
      "loss": 1.0396,
      "step": 111750
    },
    {
      "epoch": 1.183558206869538,
      "grad_norm": 0.8971690535545349,
      "learning_rate": 0.0004994895274916803,
      "loss": 1.0128,
      "step": 111800
    },
    {
      "epoch": 1.1840875286495414,
      "grad_norm": 0.8647034168243408,
      "learning_rate": 0.0004994865728472265,
      "loss": 1.0149,
      "step": 111850
    },
    {
      "epoch": 1.1846168504295447,
      "grad_norm": 0.9209829568862915,
      "learning_rate": 0.0004994836096853927,
      "loss": 1.018,
      "step": 111900
    },
    {
      "epoch": 1.185146172209548,
      "grad_norm": 0.8342591524124146,
      "learning_rate": 0.0004994806380062798,
      "loss": 1.008,
      "step": 111950
    },
    {
      "epoch": 1.1856754939895513,
      "grad_norm": 0.8728947043418884,
      "learning_rate": 0.0004994776578099894,
      "loss": 1.0193,
      "step": 112000
    },
    {
      "epoch": 1.1856754939895513,
      "eval_loss": 0.8990607857704163,
      "eval_runtime": 46.8523,
      "eval_samples_per_second": 3584.243,
      "eval_steps_per_second": 448.046,
      "step": 112000
    },
    {
      "epoch": 1.1862048157695544,
      "grad_norm": 0.8208035826683044,
      "learning_rate": 0.0004994746690966235,
      "loss": 1.0137,
      "step": 112050
    },
    {
      "epoch": 1.1867341375495577,
      "grad_norm": 0.8408169746398926,
      "learning_rate": 0.0004994716718662837,
      "loss": 1.0403,
      "step": 112100
    },
    {
      "epoch": 1.187263459329561,
      "grad_norm": 0.973870575428009,
      "learning_rate": 0.0004994686661190724,
      "loss": 1.0279,
      "step": 112150
    },
    {
      "epoch": 1.1877927811095643,
      "grad_norm": 0.8646720051765442,
      "learning_rate": 0.0004994656518550925,
      "loss": 1.0045,
      "step": 112200
    },
    {
      "epoch": 1.1883221028895676,
      "grad_norm": 0.9340278506278992,
      "learning_rate": 0.0004994626290744467,
      "loss": 1.0081,
      "step": 112250
    },
    {
      "epoch": 1.188851424669571,
      "grad_norm": 0.8626007437705994,
      "learning_rate": 0.0004994595977772382,
      "loss": 1.02,
      "step": 112300
    },
    {
      "epoch": 1.1893807464495743,
      "grad_norm": 0.8716694116592407,
      "learning_rate": 0.0004994565579635705,
      "loss": 1.0191,
      "step": 112350
    },
    {
      "epoch": 1.1899100682295773,
      "grad_norm": 0.8040950298309326,
      "learning_rate": 0.0004994535096335475,
      "loss": 0.9987,
      "step": 112400
    },
    {
      "epoch": 1.1904393900095807,
      "grad_norm": 0.8784286379814148,
      "learning_rate": 0.0004994504527872731,
      "loss": 1.0235,
      "step": 112450
    },
    {
      "epoch": 1.190968711789584,
      "grad_norm": 0.8091720342636108,
      "learning_rate": 0.0004994473874248517,
      "loss": 1.0126,
      "step": 112500
    },
    {
      "epoch": 1.190968711789584,
      "eval_loss": 0.896873414516449,
      "eval_runtime": 46.8275,
      "eval_samples_per_second": 3586.14,
      "eval_steps_per_second": 448.283,
      "step": 112500
    },
    {
      "epoch": 1.1914980335695873,
      "grad_norm": 0.7799761295318604,
      "learning_rate": 0.000499444313546388,
      "loss": 0.9967,
      "step": 112550
    },
    {
      "epoch": 1.1920273553495906,
      "grad_norm": 0.8896204829216003,
      "learning_rate": 0.0004994412311519869,
      "loss": 1.029,
      "step": 112600
    },
    {
      "epoch": 1.192556677129594,
      "grad_norm": 0.7904506325721741,
      "learning_rate": 0.0004994381402417537,
      "loss": 1.0104,
      "step": 112650
    },
    {
      "epoch": 1.1930859989095972,
      "grad_norm": 0.9057765007019043,
      "learning_rate": 0.0004994351028877665,
      "loss": 1.0181,
      "step": 112700
    },
    {
      "epoch": 1.1936153206896005,
      "grad_norm": 0.8915640115737915,
      "learning_rate": 0.0004994319951164972,
      "loss": 1.0061,
      "step": 112750
    },
    {
      "epoch": 1.1941446424696036,
      "grad_norm": 0.9925639629364014,
      "learning_rate": 0.000499428878829711,
      "loss": 1.0107,
      "step": 112800
    },
    {
      "epoch": 1.194673964249607,
      "grad_norm": 0.9135754108428955,
      "learning_rate": 0.0004994257540275144,
      "loss": 1.012,
      "step": 112850
    },
    {
      "epoch": 1.1952032860296102,
      "grad_norm": 0.8953136205673218,
      "learning_rate": 0.0004994226207100141,
      "loss": 1.0105,
      "step": 112900
    },
    {
      "epoch": 1.1957326078096135,
      "grad_norm": 0.947603702545166,
      "learning_rate": 0.0004994194788773169,
      "loss": 1.0197,
      "step": 112950
    },
    {
      "epoch": 1.1962619295896169,
      "grad_norm": 0.9450071454048157,
      "learning_rate": 0.0004994163285295302,
      "loss": 1.0152,
      "step": 113000
    },
    {
      "epoch": 1.1962619295896169,
      "eval_loss": 0.8943049907684326,
      "eval_runtime": 46.8204,
      "eval_samples_per_second": 3586.681,
      "eval_steps_per_second": 448.351,
      "step": 113000
    },
    {
      "epoch": 1.1967912513696202,
      "grad_norm": 0.9334853291511536,
      "learning_rate": 0.0004994131696667615,
      "loss": 0.9989,
      "step": 113050
    },
    {
      "epoch": 1.1973205731496235,
      "grad_norm": 0.8597784638404846,
      "learning_rate": 0.0004994100022891187,
      "loss": 1.0116,
      "step": 113100
    },
    {
      "epoch": 1.1978498949296266,
      "grad_norm": 0.8336459398269653,
      "learning_rate": 0.0004994068263967099,
      "loss": 1.0072,
      "step": 113150
    },
    {
      "epoch": 1.1983792167096299,
      "grad_norm": 0.9389498829841614,
      "learning_rate": 0.0004994036419896435,
      "loss": 1.0192,
      "step": 113200
    },
    {
      "epoch": 1.1989085384896332,
      "grad_norm": 0.879889190196991,
      "learning_rate": 0.0004994004490680282,
      "loss": 1.0082,
      "step": 113250
    },
    {
      "epoch": 1.1994378602696365,
      "grad_norm": 0.7840119004249573,
      "learning_rate": 0.000499397247631973,
      "loss": 1.0204,
      "step": 113300
    },
    {
      "epoch": 1.1999671820496398,
      "grad_norm": 0.8390173316001892,
      "learning_rate": 0.0004993940376815874,
      "loss": 1.0247,
      "step": 113350
    },
    {
      "epoch": 1.2004965038296431,
      "grad_norm": 0.8270166516304016,
      "learning_rate": 0.0004993908192169807,
      "loss": 1.0215,
      "step": 113400
    },
    {
      "epoch": 1.2010258256096464,
      "grad_norm": 0.8705251812934875,
      "learning_rate": 0.0004993875922382628,
      "loss": 1.0164,
      "step": 113450
    },
    {
      "epoch": 1.2015551473896497,
      "grad_norm": 0.9035300612449646,
      "learning_rate": 0.0004993843567455441,
      "loss": 1.0081,
      "step": 113500
    },
    {
      "epoch": 1.2015551473896497,
      "eval_loss": 0.8915220499038696,
      "eval_runtime": 46.9579,
      "eval_samples_per_second": 3576.186,
      "eval_steps_per_second": 447.039,
      "step": 113500
    },
    {
      "epoch": 1.2020844691696528,
      "grad_norm": 0.8198367357254028,
      "learning_rate": 0.0004993811127389349,
      "loss": 1.0214,
      "step": 113550
    },
    {
      "epoch": 1.2026137909496561,
      "grad_norm": 0.8427003026008606,
      "learning_rate": 0.0004993778602185459,
      "loss": 1.0147,
      "step": 113600
    },
    {
      "epoch": 1.2031431127296595,
      "grad_norm": 0.8584383726119995,
      "learning_rate": 0.0004993745991844883,
      "loss": 0.9987,
      "step": 113650
    },
    {
      "epoch": 1.2036724345096628,
      "grad_norm": 0.9558970332145691,
      "learning_rate": 0.0004993713296368732,
      "loss": 1.0175,
      "step": 113700
    },
    {
      "epoch": 1.204201756289666,
      "grad_norm": 0.8919420838356018,
      "learning_rate": 0.0004993680515758124,
      "loss": 0.9953,
      "step": 113750
    },
    {
      "epoch": 1.2047310780696694,
      "grad_norm": 0.8286592960357666,
      "learning_rate": 0.0004993647650014179,
      "loss": 0.9941,
      "step": 113800
    },
    {
      "epoch": 1.2052603998496727,
      "grad_norm": 0.953772783279419,
      "learning_rate": 0.0004993614699138017,
      "loss": 1.011,
      "step": 113850
    },
    {
      "epoch": 1.2057897216296758,
      "grad_norm": 0.8895803689956665,
      "learning_rate": 0.0004993581663130764,
      "loss": 1.0383,
      "step": 113900
    },
    {
      "epoch": 1.206319043409679,
      "grad_norm": 0.908669114112854,
      "learning_rate": 0.0004993548541993546,
      "loss": 1.0065,
      "step": 113950
    },
    {
      "epoch": 1.2068483651896824,
      "grad_norm": 0.804150402545929,
      "learning_rate": 0.0004993515335727497,
      "loss": 1.014,
      "step": 114000
    },
    {
      "epoch": 1.2068483651896824,
      "eval_loss": 0.8901469111442566,
      "eval_runtime": 46.8229,
      "eval_samples_per_second": 3586.497,
      "eval_steps_per_second": 448.328,
      "step": 114000
    },
    {
      "epoch": 1.2073776869696857,
      "grad_norm": 0.9905886054039001,
      "learning_rate": 0.0004993482044333748,
      "loss": 0.9968,
      "step": 114050
    },
    {
      "epoch": 1.207907008749689,
      "grad_norm": 0.9043799638748169,
      "learning_rate": 0.0004993448667813437,
      "loss": 1.0092,
      "step": 114100
    },
    {
      "epoch": 1.2084363305296923,
      "grad_norm": 0.9251449108123779,
      "learning_rate": 0.0004993415206167703,
      "loss": 1.0076,
      "step": 114150
    },
    {
      "epoch": 1.2089656523096957,
      "grad_norm": 0.8629209995269775,
      "learning_rate": 0.0004993381659397688,
      "loss": 0.9941,
      "step": 114200
    },
    {
      "epoch": 1.209494974089699,
      "grad_norm": 0.8759520053863525,
      "learning_rate": 0.0004993348027504537,
      "loss": 1.0179,
      "step": 114250
    },
    {
      "epoch": 1.210024295869702,
      "grad_norm": 0.8946111798286438,
      "learning_rate": 0.0004993314310489399,
      "loss": 1.0004,
      "step": 114300
    },
    {
      "epoch": 1.2105536176497054,
      "grad_norm": 0.9483357667922974,
      "learning_rate": 0.0004993280508353426,
      "loss": 0.9898,
      "step": 114350
    },
    {
      "epoch": 1.2110829394297087,
      "grad_norm": 0.9296706318855286,
      "learning_rate": 0.000499324662109777,
      "loss": 1.0275,
      "step": 114400
    },
    {
      "epoch": 1.211612261209712,
      "grad_norm": 0.9236528873443604,
      "learning_rate": 0.0004993212648723588,
      "loss": 1.0039,
      "step": 114450
    },
    {
      "epoch": 1.2121415829897153,
      "grad_norm": 0.9197582006454468,
      "learning_rate": 0.0004993178591232042,
      "loss": 1.009,
      "step": 114500
    },
    {
      "epoch": 1.2121415829897153,
      "eval_loss": 0.8874636888504028,
      "eval_runtime": 46.9209,
      "eval_samples_per_second": 3579.003,
      "eval_steps_per_second": 447.391,
      "step": 114500
    },
    {
      "epoch": 1.2126709047697186,
      "grad_norm": 0.8346025347709656,
      "learning_rate": 0.0004993144448624293,
      "loss": 1.0162,
      "step": 114550
    },
    {
      "epoch": 1.213200226549722,
      "grad_norm": 0.9039405584335327,
      "learning_rate": 0.0004993110220901506,
      "loss": 1.0307,
      "step": 114600
    },
    {
      "epoch": 1.213729548329725,
      "grad_norm": 0.8952855467796326,
      "learning_rate": 0.0004993075908064851,
      "loss": 1.0048,
      "step": 114650
    },
    {
      "epoch": 1.2142588701097283,
      "grad_norm": 0.8480716347694397,
      "learning_rate": 0.0004993042198908581,
      "loss": 1.0136,
      "step": 114700
    },
    {
      "epoch": 1.2147881918897316,
      "grad_norm": 0.9104435443878174,
      "learning_rate": 0.0004993007717549925,
      "loss": 1.015,
      "step": 114750
    },
    {
      "epoch": 1.215317513669735,
      "grad_norm": 0.8473331332206726,
      "learning_rate": 0.00049929731510809,
      "loss": 1.0092,
      "step": 114800
    },
    {
      "epoch": 1.2158468354497383,
      "grad_norm": 0.9018368124961853,
      "learning_rate": 0.0004992938499502685,
      "loss": 0.9951,
      "step": 114850
    },
    {
      "epoch": 1.2163761572297416,
      "grad_norm": 0.8652557730674744,
      "learning_rate": 0.0004992903762816465,
      "loss": 1.0088,
      "step": 114900
    },
    {
      "epoch": 1.2169054790097449,
      "grad_norm": 0.8227794766426086,
      "learning_rate": 0.0004992868941023423,
      "loss": 1.0101,
      "step": 114950
    },
    {
      "epoch": 1.2174348007897482,
      "grad_norm": 0.9455897808074951,
      "learning_rate": 0.0004992834034124752,
      "loss": 1.0149,
      "step": 115000
    },
    {
      "epoch": 1.2174348007897482,
      "eval_loss": 0.8843809366226196,
      "eval_runtime": 46.8177,
      "eval_samples_per_second": 3586.893,
      "eval_steps_per_second": 448.378,
      "step": 115000
    },
    {
      "epoch": 1.2179641225697513,
      "grad_norm": 0.8612624406814575,
      "learning_rate": 0.0004992799042121638,
      "loss": 1.0171,
      "step": 115050
    },
    {
      "epoch": 1.2184934443497546,
      "grad_norm": 0.819988489151001,
      "learning_rate": 0.0004992763965015282,
      "loss": 1.0047,
      "step": 115100
    },
    {
      "epoch": 1.219022766129758,
      "grad_norm": 0.8731096386909485,
      "learning_rate": 0.0004992728802806877,
      "loss": 0.9982,
      "step": 115150
    },
    {
      "epoch": 1.2195520879097612,
      "grad_norm": 0.8226299285888672,
      "learning_rate": 0.0004992693555497625,
      "loss": 1.0155,
      "step": 115200
    },
    {
      "epoch": 1.2200814096897645,
      "grad_norm": 0.9064512252807617,
      "learning_rate": 0.0004992658223088729,
      "loss": 1.0027,
      "step": 115250
    },
    {
      "epoch": 1.2206107314697678,
      "grad_norm": 0.8967424631118774,
      "learning_rate": 0.0004992622805581396,
      "loss": 1.0039,
      "step": 115300
    },
    {
      "epoch": 1.2211400532497712,
      "grad_norm": 0.8264062404632568,
      "learning_rate": 0.0004992587302976835,
      "loss": 1.0095,
      "step": 115350
    },
    {
      "epoch": 1.2216693750297742,
      "grad_norm": 0.762915849685669,
      "learning_rate": 0.0004992551715276255,
      "loss": 1.0019,
      "step": 115400
    },
    {
      "epoch": 1.2221986968097776,
      "grad_norm": 0.8999019265174866,
      "learning_rate": 0.0004992516042480876,
      "loss": 1.0118,
      "step": 115450
    },
    {
      "epoch": 1.2227280185897809,
      "grad_norm": 0.9645323157310486,
      "learning_rate": 0.0004992480284591913,
      "loss": 0.9997,
      "step": 115500
    },
    {
      "epoch": 1.2227280185897809,
      "eval_loss": 0.8826006650924683,
      "eval_runtime": 46.8301,
      "eval_samples_per_second": 3585.941,
      "eval_steps_per_second": 448.259,
      "step": 115500
    },
    {
      "epoch": 1.2232573403697842,
      "grad_norm": 0.9118640422821045,
      "learning_rate": 0.0004992444441610588,
      "loss": 1.0104,
      "step": 115550
    },
    {
      "epoch": 1.2237866621497875,
      "grad_norm": 0.8150995373725891,
      "learning_rate": 0.0004992408513538122,
      "loss": 0.996,
      "step": 115600
    },
    {
      "epoch": 1.2243159839297908,
      "grad_norm": 0.8280022740364075,
      "learning_rate": 0.0004992372500375744,
      "loss": 0.9947,
      "step": 115650
    },
    {
      "epoch": 1.224845305709794,
      "grad_norm": 0.9140384793281555,
      "learning_rate": 0.0004992336402124683,
      "loss": 1.0034,
      "step": 115700
    },
    {
      "epoch": 1.2253746274897974,
      "grad_norm": 0.7996530532836914,
      "learning_rate": 0.0004992300218786171,
      "loss": 1.0074,
      "step": 115750
    },
    {
      "epoch": 1.2259039492698005,
      "grad_norm": 0.8460230231285095,
      "learning_rate": 0.0004992263950361444,
      "loss": 0.9984,
      "step": 115800
    },
    {
      "epoch": 1.2264332710498038,
      "grad_norm": 0.7821682095527649,
      "learning_rate": 0.000499222759685174,
      "loss": 0.9967,
      "step": 115850
    },
    {
      "epoch": 1.2269625928298071,
      "grad_norm": 0.832541286945343,
      "learning_rate": 0.00049921911582583,
      "loss": 1.0136,
      "step": 115900
    },
    {
      "epoch": 1.2274919146098104,
      "grad_norm": 0.8378150463104248,
      "learning_rate": 0.0004992154634582368,
      "loss": 1.0089,
      "step": 115950
    },
    {
      "epoch": 1.2280212363898138,
      "grad_norm": 0.9623870253562927,
      "learning_rate": 0.000499211802582519,
      "loss": 0.9928,
      "step": 116000
    },
    {
      "epoch": 1.2280212363898138,
      "eval_loss": 0.8725743889808655,
      "eval_runtime": 46.8183,
      "eval_samples_per_second": 3586.844,
      "eval_steps_per_second": 448.372,
      "step": 116000
    },
    {
      "epoch": 1.228550558169817,
      "grad_norm": 0.8407173752784729,
      "learning_rate": 0.0004992081331988016,
      "loss": 1.016,
      "step": 116050
    },
    {
      "epoch": 1.2290798799498204,
      "grad_norm": 0.799317479133606,
      "learning_rate": 0.0004992044553072101,
      "loss": 0.9961,
      "step": 116100
    },
    {
      "epoch": 1.2296092017298235,
      "grad_norm": 0.9226611256599426,
      "learning_rate": 0.0004992007689078697,
      "loss": 1.009,
      "step": 116150
    },
    {
      "epoch": 1.2301385235098268,
      "grad_norm": 0.8665615916252136,
      "learning_rate": 0.0004991970740009065,
      "loss": 1.0184,
      "step": 116200
    },
    {
      "epoch": 1.23066784528983,
      "grad_norm": 0.775735080242157,
      "learning_rate": 0.0004991933705864466,
      "loss": 0.993,
      "step": 116250
    },
    {
      "epoch": 1.2311971670698334,
      "grad_norm": 0.8619183301925659,
      "learning_rate": 0.0004991896586646164,
      "loss": 1.0119,
      "step": 116300
    },
    {
      "epoch": 1.2317264888498367,
      "grad_norm": 0.9290663599967957,
      "learning_rate": 0.0004991859382355427,
      "loss": 1.0077,
      "step": 116350
    },
    {
      "epoch": 1.23225581062984,
      "grad_norm": 0.8918001651763916,
      "learning_rate": 0.0004991822092993524,
      "loss": 0.982,
      "step": 116400
    },
    {
      "epoch": 1.2327851324098433,
      "grad_norm": 0.9955422282218933,
      "learning_rate": 0.0004991784718561729,
      "loss": 1.0168,
      "step": 116450
    },
    {
      "epoch": 1.2333144541898466,
      "grad_norm": 0.760254979133606,
      "learning_rate": 0.0004991747259061318,
      "loss": 0.9863,
      "step": 116500
    },
    {
      "epoch": 1.2333144541898466,
      "eval_loss": 0.8728739023208618,
      "eval_runtime": 46.8172,
      "eval_samples_per_second": 3586.929,
      "eval_steps_per_second": 448.382,
      "step": 116500
    },
    {
      "epoch": 1.23384377596985,
      "grad_norm": 0.8635483384132385,
      "learning_rate": 0.0004991709714493569,
      "loss": 1.0107,
      "step": 116550
    },
    {
      "epoch": 1.234373097749853,
      "grad_norm": 0.8949643969535828,
      "learning_rate": 0.0004991672084859763,
      "loss": 0.9941,
      "step": 116600
    },
    {
      "epoch": 1.2349024195298564,
      "grad_norm": 0.8157879710197449,
      "learning_rate": 0.0004991634370161187,
      "loss": 1.0102,
      "step": 116650
    },
    {
      "epoch": 1.2354317413098597,
      "grad_norm": 0.8670288920402527,
      "learning_rate": 0.0004991596570399127,
      "loss": 1.0089,
      "step": 116700
    },
    {
      "epoch": 1.235961063089863,
      "grad_norm": 0.8259453177452087,
      "learning_rate": 0.0004991558685574874,
      "loss": 1.0095,
      "step": 116750
    },
    {
      "epoch": 1.2364903848698663,
      "grad_norm": 0.9396064281463623,
      "learning_rate": 0.0004991520715689721,
      "loss": 0.9887,
      "step": 116800
    },
    {
      "epoch": 1.2370197066498696,
      "grad_norm": 0.9288630485534668,
      "learning_rate": 0.0004991483422677436,
      "loss": 0.9888,
      "step": 116850
    },
    {
      "epoch": 1.2375490284298727,
      "grad_norm": 0.8124237656593323,
      "learning_rate": 0.0004991445284375529,
      "loss": 1.0139,
      "step": 116900
    },
    {
      "epoch": 1.238078350209876,
      "grad_norm": 0.9783995747566223,
      "learning_rate": 0.0004991407061016593,
      "loss": 1.0098,
      "step": 116950
    },
    {
      "epoch": 1.2386076719898793,
      "grad_norm": 0.7926446199417114,
      "learning_rate": 0.0004991368752601934,
      "loss": 0.9861,
      "step": 117000
    },
    {
      "epoch": 1.2386076719898793,
      "eval_loss": 0.8738942742347717,
      "eval_runtime": 46.7368,
      "eval_samples_per_second": 3593.099,
      "eval_steps_per_second": 449.153,
      "step": 117000
    },
    {
      "epoch": 1.2391369937698826,
      "grad_norm": 0.852369487285614,
      "learning_rate": 0.0004991330359132859,
      "loss": 0.9998,
      "step": 117050
    },
    {
      "epoch": 1.239666315549886,
      "grad_norm": 0.9212186932563782,
      "learning_rate": 0.000499129188061068,
      "loss": 0.9719,
      "step": 117100
    },
    {
      "epoch": 1.2401956373298892,
      "grad_norm": 0.8456434607505798,
      "learning_rate": 0.000499125331703671,
      "loss": 0.999,
      "step": 117150
    },
    {
      "epoch": 1.2407249591098926,
      "grad_norm": 0.8209339380264282,
      "learning_rate": 0.0004991214668412265,
      "loss": 0.9988,
      "step": 117200
    },
    {
      "epoch": 1.2412542808898959,
      "grad_norm": 0.9712432622909546,
      "learning_rate": 0.0004991175934738665,
      "loss": 1.0109,
      "step": 117250
    },
    {
      "epoch": 1.2417836026698992,
      "grad_norm": 0.8410804271697998,
      "learning_rate": 0.0004991137116017231,
      "loss": 1.0015,
      "step": 117300
    },
    {
      "epoch": 1.2423129244499023,
      "grad_norm": 0.8878301978111267,
      "learning_rate": 0.0004991098212249291,
      "loss": 1.009,
      "step": 117350
    },
    {
      "epoch": 1.2428422462299056,
      "grad_norm": 0.8731576204299927,
      "learning_rate": 0.0004991059223436171,
      "loss": 1.0042,
      "step": 117400
    },
    {
      "epoch": 1.243371568009909,
      "grad_norm": 0.8494111895561218,
      "learning_rate": 0.0004991020149579203,
      "loss": 0.9882,
      "step": 117450
    },
    {
      "epoch": 1.2439008897899122,
      "grad_norm": 0.8742976188659668,
      "learning_rate": 0.0004990980990679722,
      "loss": 0.9985,
      "step": 117500
    },
    {
      "epoch": 1.2439008897899122,
      "eval_loss": 0.8693655729293823,
      "eval_runtime": 46.7915,
      "eval_samples_per_second": 3588.901,
      "eval_steps_per_second": 448.629,
      "step": 117500
    },
    {
      "epoch": 1.2444302115699155,
      "grad_norm": 0.842400312423706,
      "learning_rate": 0.000499094174673906,
      "loss": 1.0071,
      "step": 117550
    },
    {
      "epoch": 1.2449595333499188,
      "grad_norm": 0.7770165801048279,
      "learning_rate": 0.0004990902417758563,
      "loss": 0.9828,
      "step": 117600
    },
    {
      "epoch": 1.245488855129922,
      "grad_norm": 0.856741726398468,
      "learning_rate": 0.000499086300373957,
      "loss": 1.0052,
      "step": 117650
    },
    {
      "epoch": 1.2460181769099252,
      "grad_norm": 0.9288490414619446,
      "learning_rate": 0.0004990823504683428,
      "loss": 1.0132,
      "step": 117700
    },
    {
      "epoch": 1.2465474986899285,
      "grad_norm": 0.832783579826355,
      "learning_rate": 0.0004990783920591484,
      "loss": 0.9975,
      "step": 117750
    },
    {
      "epoch": 1.2470768204699318,
      "grad_norm": 0.9114430546760559,
      "learning_rate": 0.0004990744251465092,
      "loss": 1.0008,
      "step": 117800
    },
    {
      "epoch": 1.2476061422499352,
      "grad_norm": 0.833156943321228,
      "learning_rate": 0.0004990704497305604,
      "loss": 0.9892,
      "step": 117850
    },
    {
      "epoch": 1.2481354640299385,
      "grad_norm": 0.834052562713623,
      "learning_rate": 0.0004990664658114378,
      "loss": 1.0008,
      "step": 117900
    },
    {
      "epoch": 1.2486647858099418,
      "grad_norm": 0.7929224371910095,
      "learning_rate": 0.0004990624733892773,
      "loss": 0.9884,
      "step": 117950
    },
    {
      "epoch": 1.249194107589945,
      "grad_norm": 0.8936432600021362,
      "learning_rate": 0.0004990584724642155,
      "loss": 0.986,
      "step": 118000
    },
    {
      "epoch": 1.249194107589945,
      "eval_loss": 0.869628369808197,
      "eval_runtime": 46.7539,
      "eval_samples_per_second": 3591.787,
      "eval_steps_per_second": 448.989,
      "step": 118000
    },
    {
      "epoch": 1.2497234293699484,
      "grad_norm": 0.8510515093803406,
      "learning_rate": 0.0004990544630363886,
      "loss": 1.0026,
      "step": 118050
    },
    {
      "epoch": 1.2502527511499515,
      "grad_norm": 0.8722116351127625,
      "learning_rate": 0.0004990504451059338,
      "loss": 1.0006,
      "step": 118100
    },
    {
      "epoch": 1.2507820729299548,
      "grad_norm": 0.8381201028823853,
      "learning_rate": 0.000499046418672988,
      "loss": 1.0078,
      "step": 118150
    },
    {
      "epoch": 1.2513113947099581,
      "grad_norm": 0.9174805879592896,
      "learning_rate": 0.000499042383737689,
      "loss": 0.9967,
      "step": 118200
    },
    {
      "epoch": 1.2518407164899614,
      "grad_norm": 0.854802668094635,
      "learning_rate": 0.0004990383403001741,
      "loss": 0.9912,
      "step": 118250
    },
    {
      "epoch": 1.2523700382699647,
      "grad_norm": 0.9017914533615112,
      "learning_rate": 0.0004990342883605818,
      "loss": 0.989,
      "step": 118300
    },
    {
      "epoch": 1.252899360049968,
      "grad_norm": 0.8755068778991699,
      "learning_rate": 0.0004990302279190502,
      "loss": 0.9949,
      "step": 118350
    },
    {
      "epoch": 1.2534286818299711,
      "grad_norm": 0.9146993160247803,
      "learning_rate": 0.0004990261589757179,
      "loss": 0.9959,
      "step": 118400
    },
    {
      "epoch": 1.2539580036099744,
      "grad_norm": 0.8969585299491882,
      "learning_rate": 0.0004990220815307238,
      "loss": 0.9861,
      "step": 118450
    },
    {
      "epoch": 1.2544873253899778,
      "grad_norm": 0.8158464431762695,
      "learning_rate": 0.0004990179955842072,
      "loss": 0.9938,
      "step": 118500
    },
    {
      "epoch": 1.2544873253899778,
      "eval_loss": 0.8695681691169739,
      "eval_runtime": 46.7926,
      "eval_samples_per_second": 3588.815,
      "eval_steps_per_second": 448.618,
      "step": 118500
    },
    {
      "epoch": 1.255016647169981,
      "grad_norm": 0.8668920993804932,
      "learning_rate": 0.0004990139011363076,
      "loss": 0.9985,
      "step": 118550
    },
    {
      "epoch": 1.2555459689499844,
      "grad_norm": 0.8722243309020996,
      "learning_rate": 0.0004990097981871647,
      "loss": 0.9981,
      "step": 118600
    },
    {
      "epoch": 1.2560752907299877,
      "grad_norm": 0.9036475419998169,
      "learning_rate": 0.0004990056867369187,
      "loss": 0.9947,
      "step": 118650
    },
    {
      "epoch": 1.256604612509991,
      "grad_norm": 0.8842248916625977,
      "learning_rate": 0.0004990015667857098,
      "loss": 0.9765,
      "step": 118700
    },
    {
      "epoch": 1.2571339342899943,
      "grad_norm": 0.7835907340049744,
      "learning_rate": 0.0004989974383336788,
      "loss": 0.994,
      "step": 118750
    },
    {
      "epoch": 1.2576632560699976,
      "grad_norm": 0.9258401393890381,
      "learning_rate": 0.0004989933013809664,
      "loss": 0.9893,
      "step": 118800
    },
    {
      "epoch": 1.2581925778500007,
      "grad_norm": 0.9436124563217163,
      "learning_rate": 0.0004989891559277142,
      "loss": 1.0056,
      "step": 118850
    },
    {
      "epoch": 1.258721899630004,
      "grad_norm": 0.8962510824203491,
      "learning_rate": 0.0004989850019740635,
      "loss": 0.9958,
      "step": 118900
    },
    {
      "epoch": 1.2592512214100073,
      "grad_norm": 0.890621542930603,
      "learning_rate": 0.0004989809228525358,
      "loss": 1.0052,
      "step": 118950
    },
    {
      "epoch": 1.2597805431900106,
      "grad_norm": 0.8222649097442627,
      "learning_rate": 0.0004989767520685147,
      "loss": 0.9945,
      "step": 119000
    },
    {
      "epoch": 1.2597805431900106,
      "eval_loss": 0.8663935661315918,
      "eval_runtime": 46.7975,
      "eval_samples_per_second": 3588.437,
      "eval_steps_per_second": 448.571,
      "step": 119000
    },
    {
      "epoch": 1.260309864970014,
      "grad_norm": 0.9439399838447571,
      "learning_rate": 0.0004989725727845187,
      "loss": 1.0016,
      "step": 119050
    },
    {
      "epoch": 1.2608391867500173,
      "grad_norm": 0.8039493560791016,
      "learning_rate": 0.0004989683850006903,
      "loss": 0.9875,
      "step": 119100
    },
    {
      "epoch": 1.2613685085300204,
      "grad_norm": 0.9570218920707703,
      "learning_rate": 0.0004989641887171725,
      "loss": 1.0002,
      "step": 119150
    },
    {
      "epoch": 1.2618978303100237,
      "grad_norm": 0.8952481746673584,
      "learning_rate": 0.0004989599839341087,
      "loss": 1.0196,
      "step": 119200
    },
    {
      "epoch": 1.262427152090027,
      "grad_norm": 0.8200473785400391,
      "learning_rate": 0.0004989557706516423,
      "loss": 0.9914,
      "step": 119250
    },
    {
      "epoch": 1.2629564738700303,
      "grad_norm": 0.9278497099876404,
      "learning_rate": 0.0004989515488699172,
      "loss": 0.9946,
      "step": 119300
    },
    {
      "epoch": 1.2634857956500336,
      "grad_norm": 0.8236282467842102,
      "learning_rate": 0.0004989473185890774,
      "loss": 0.993,
      "step": 119350
    },
    {
      "epoch": 1.264015117430037,
      "grad_norm": 0.8506109118461609,
      "learning_rate": 0.0004989430798092677,
      "loss": 0.9959,
      "step": 119400
    },
    {
      "epoch": 1.2645444392100402,
      "grad_norm": 0.8729108572006226,
      "learning_rate": 0.0004989388325306324,
      "loss": 0.9959,
      "step": 119450
    },
    {
      "epoch": 1.2650737609900435,
      "grad_norm": 0.881639838218689,
      "learning_rate": 0.0004989345767533167,
      "loss": 1.0059,
      "step": 119500
    },
    {
      "epoch": 1.2650737609900435,
      "eval_loss": 0.8626880645751953,
      "eval_runtime": 46.8557,
      "eval_samples_per_second": 3583.984,
      "eval_steps_per_second": 448.014,
      "step": 119500
    },
    {
      "epoch": 1.2656030827700468,
      "grad_norm": 0.8072580695152283,
      "learning_rate": 0.0004989303124774657,
      "loss": 0.9961,
      "step": 119550
    },
    {
      "epoch": 1.26613240455005,
      "grad_norm": 0.7790585160255432,
      "learning_rate": 0.0004989260397032252,
      "loss": 1.001,
      "step": 119600
    },
    {
      "epoch": 1.2666617263300533,
      "grad_norm": 0.8858896493911743,
      "learning_rate": 0.0004989217584307411,
      "loss": 0.983,
      "step": 119650
    },
    {
      "epoch": 1.2671910481100566,
      "grad_norm": 0.9290274381637573,
      "learning_rate": 0.0004989174686601594,
      "loss": 0.9981,
      "step": 119700
    },
    {
      "epoch": 1.2677203698900599,
      "grad_norm": 0.8456922769546509,
      "learning_rate": 0.0004989131703916266,
      "loss": 0.9888,
      "step": 119750
    },
    {
      "epoch": 1.2682496916700632,
      "grad_norm": 0.9039419293403625,
      "learning_rate": 0.0004989088636252894,
      "loss": 0.9861,
      "step": 119800
    },
    {
      "epoch": 1.2687790134500665,
      "grad_norm": 0.8277771472930908,
      "learning_rate": 0.000498904548361295,
      "loss": 0.9755,
      "step": 119850
    },
    {
      "epoch": 1.2693083352300696,
      "grad_norm": 0.8462793231010437,
      "learning_rate": 0.0004989002245997905,
      "loss": 0.9878,
      "step": 119900
    },
    {
      "epoch": 1.269837657010073,
      "grad_norm": 0.835237979888916,
      "learning_rate": 0.0004988958923409237,
      "loss": 0.9925,
      "step": 119950
    },
    {
      "epoch": 1.2703669787900762,
      "grad_norm": 0.8873925805091858,
      "learning_rate": 0.0004988915515848423,
      "loss": 1.0078,
      "step": 120000
    },
    {
      "epoch": 1.2703669787900762,
      "eval_loss": 0.8565057516098022,
      "eval_runtime": 46.7703,
      "eval_samples_per_second": 3590.526,
      "eval_steps_per_second": 448.832,
      "step": 120000
    },
    {
      "epoch": 1.2708963005700795,
      "grad_norm": 0.9046040177345276,
      "learning_rate": 0.0004988872023316946,
      "loss": 0.9872,
      "step": 120050
    },
    {
      "epoch": 1.2714256223500828,
      "grad_norm": 0.8427685499191284,
      "learning_rate": 0.0004988828445816292,
      "loss": 0.9929,
      "step": 120100
    },
    {
      "epoch": 1.2719549441300861,
      "grad_norm": 0.8501623868942261,
      "learning_rate": 0.0004988784783347948,
      "loss": 0.9893,
      "step": 120150
    },
    {
      "epoch": 1.2724842659100895,
      "grad_norm": 0.8822485208511353,
      "learning_rate": 0.0004988741035913402,
      "loss": 0.9882,
      "step": 120200
    },
    {
      "epoch": 1.2730135876900928,
      "grad_norm": 0.8827032446861267,
      "learning_rate": 0.0004988697203514152,
      "loss": 0.9881,
      "step": 120250
    },
    {
      "epoch": 1.273542909470096,
      "grad_norm": 0.8379425406455994,
      "learning_rate": 0.0004988653286151691,
      "loss": 0.9984,
      "step": 120300
    },
    {
      "epoch": 1.2740722312500994,
      "grad_norm": 0.9370198845863342,
      "learning_rate": 0.000498860928382752,
      "loss": 0.9862,
      "step": 120350
    },
    {
      "epoch": 1.2746015530301025,
      "grad_norm": 0.8672593832015991,
      "learning_rate": 0.000498856519654314,
      "loss": 0.9841,
      "step": 120400
    },
    {
      "epoch": 1.2751308748101058,
      "grad_norm": 0.8080891966819763,
      "learning_rate": 0.0004988521024300058,
      "loss": 1.0019,
      "step": 120450
    },
    {
      "epoch": 1.275660196590109,
      "grad_norm": 0.9333109855651855,
      "learning_rate": 0.000498847676709978,
      "loss": 0.9881,
      "step": 120500
    },
    {
      "epoch": 1.275660196590109,
      "eval_loss": 0.8551510572433472,
      "eval_runtime": 46.7355,
      "eval_samples_per_second": 3593.197,
      "eval_steps_per_second": 449.166,
      "step": 120500
    },
    {
      "epoch": 1.2761895183701124,
      "grad_norm": 0.7613270282745361,
      "learning_rate": 0.0004988432424943818,
      "loss": 0.975,
      "step": 120550
    },
    {
      "epoch": 1.2767188401501157,
      "grad_norm": 0.9800189137458801,
      "learning_rate": 0.0004988387997833686,
      "loss": 0.9785,
      "step": 120600
    },
    {
      "epoch": 1.2772481619301188,
      "grad_norm": 1.0165835618972778,
      "learning_rate": 0.00049883434857709,
      "loss": 0.976,
      "step": 120650
    },
    {
      "epoch": 1.2777774837101221,
      "grad_norm": 0.8501834869384766,
      "learning_rate": 0.000498829888875698,
      "loss": 0.9825,
      "step": 120700
    },
    {
      "epoch": 1.2783068054901254,
      "grad_norm": 0.8027515411376953,
      "learning_rate": 0.0004988254206793448,
      "loss": 0.9814,
      "step": 120750
    },
    {
      "epoch": 1.2788361272701287,
      "grad_norm": 0.8537547588348389,
      "learning_rate": 0.0004988209439881831,
      "loss": 0.9955,
      "step": 120800
    },
    {
      "epoch": 1.279365449050132,
      "grad_norm": 0.8260888457298279,
      "learning_rate": 0.0004988164588023655,
      "loss": 0.9771,
      "step": 120850
    },
    {
      "epoch": 1.2798947708301354,
      "grad_norm": 0.7725456357002258,
      "learning_rate": 0.0004988119651220453,
      "loss": 0.9973,
      "step": 120900
    },
    {
      "epoch": 1.2804240926101387,
      "grad_norm": 0.9200680255889893,
      "learning_rate": 0.0004988074629473758,
      "loss": 0.9869,
      "step": 120950
    },
    {
      "epoch": 1.280953414390142,
      "grad_norm": 0.9293133616447449,
      "learning_rate": 0.0004988029522785109,
      "loss": 0.9691,
      "step": 121000
    },
    {
      "epoch": 1.280953414390142,
      "eval_loss": 0.8574302792549133,
      "eval_runtime": 46.7926,
      "eval_samples_per_second": 3588.816,
      "eval_steps_per_second": 448.618,
      "step": 121000
    },
    {
      "epoch": 1.2814827361701453,
      "grad_norm": 0.9587814807891846,
      "learning_rate": 0.0004987984331156044,
      "loss": 0.9697,
      "step": 121050
    },
    {
      "epoch": 1.2820120579501486,
      "grad_norm": 0.8300947546958923,
      "learning_rate": 0.0004987939054588107,
      "loss": 0.9788,
      "step": 121100
    },
    {
      "epoch": 1.2825413797301517,
      "grad_norm": 0.8309838771820068,
      "learning_rate": 0.0004987893693082842,
      "loss": 0.9882,
      "step": 121150
    },
    {
      "epoch": 1.283070701510155,
      "grad_norm": 0.792688250541687,
      "learning_rate": 0.0004987848246641799,
      "loss": 0.9868,
      "step": 121200
    },
    {
      "epoch": 1.2836000232901583,
      "grad_norm": 0.8078988790512085,
      "learning_rate": 0.0004987802715266529,
      "loss": 0.9823,
      "step": 121250
    },
    {
      "epoch": 1.2841293450701616,
      "grad_norm": 0.861005425453186,
      "learning_rate": 0.0004987757098958587,
      "loss": 0.9837,
      "step": 121300
    },
    {
      "epoch": 1.284658666850165,
      "grad_norm": 0.8948714137077332,
      "learning_rate": 0.000498771139771953,
      "loss": 0.9902,
      "step": 121350
    },
    {
      "epoch": 1.285187988630168,
      "grad_norm": 0.8080693483352661,
      "learning_rate": 0.0004987665611550918,
      "loss": 0.9768,
      "step": 121400
    },
    {
      "epoch": 1.2857173104101713,
      "grad_norm": 0.9043797850608826,
      "learning_rate": 0.0004987619740454315,
      "loss": 0.9729,
      "step": 121450
    },
    {
      "epoch": 1.2862466321901747,
      "grad_norm": 0.8357524275779724,
      "learning_rate": 0.0004987573784431287,
      "loss": 0.9705,
      "step": 121500
    },
    {
      "epoch": 1.2862466321901747,
      "eval_loss": 0.8551182746887207,
      "eval_runtime": 46.7316,
      "eval_samples_per_second": 3593.499,
      "eval_steps_per_second": 449.203,
      "step": 121500
    },
    {
      "epoch": 1.286775953970178,
      "grad_norm": 0.8965744376182556,
      "learning_rate": 0.00049875277434834,
      "loss": 0.9573,
      "step": 121550
    },
    {
      "epoch": 1.2873052757501813,
      "grad_norm": 0.8345509171485901,
      "learning_rate": 0.0004987481617612229,
      "loss": 0.9877,
      "step": 121600
    },
    {
      "epoch": 1.2878345975301846,
      "grad_norm": 0.9233186841011047,
      "learning_rate": 0.0004987435406819348,
      "loss": 0.9809,
      "step": 121650
    },
    {
      "epoch": 1.288363919310188,
      "grad_norm": 0.9311771988868713,
      "learning_rate": 0.0004987389111106335,
      "loss": 0.9575,
      "step": 121700
    },
    {
      "epoch": 1.2888932410901912,
      "grad_norm": 0.8188281059265137,
      "learning_rate": 0.000498734273047477,
      "loss": 0.9778,
      "step": 121750
    },
    {
      "epoch": 1.2894225628701945,
      "grad_norm": 0.8635557889938354,
      "learning_rate": 0.0004987296264926236,
      "loss": 1.0017,
      "step": 121800
    },
    {
      "epoch": 1.2899518846501978,
      "grad_norm": 0.8958401083946228,
      "learning_rate": 0.0004987249714462319,
      "loss": 0.9895,
      "step": 121850
    },
    {
      "epoch": 1.290481206430201,
      "grad_norm": 0.8090478777885437,
      "learning_rate": 0.000498720307908461,
      "loss": 0.9523,
      "step": 121900
    },
    {
      "epoch": 1.2910105282102042,
      "grad_norm": 0.9606305360794067,
      "learning_rate": 0.00049871563587947,
      "loss": 0.9685,
      "step": 121950
    },
    {
      "epoch": 1.2915398499902075,
      "grad_norm": 0.9006468057632446,
      "learning_rate": 0.0004987109553594184,
      "loss": 0.9722,
      "step": 122000
    },
    {
      "epoch": 1.2915398499902075,
      "eval_loss": 0.8537437319755554,
      "eval_runtime": 46.7742,
      "eval_samples_per_second": 3590.227,
      "eval_steps_per_second": 448.794,
      "step": 122000
    },
    {
      "epoch": 1.2920691717702109,
      "grad_norm": 0.8850790858268738,
      "learning_rate": 0.0004987063602118947,
      "loss": 0.9929,
      "step": 122050
    },
    {
      "epoch": 1.2925984935502142,
      "grad_norm": 1.0164395570755005,
      "learning_rate": 0.0004987016628800148,
      "loss": 0.9741,
      "step": 122100
    },
    {
      "epoch": 1.2931278153302173,
      "grad_norm": 0.7981029748916626,
      "learning_rate": 0.0004986969570575513,
      "loss": 0.9806,
      "step": 122150
    },
    {
      "epoch": 1.2936571371102206,
      "grad_norm": 0.7736337780952454,
      "learning_rate": 0.000498692242744665,
      "loss": 0.9751,
      "step": 122200
    },
    {
      "epoch": 1.2941864588902239,
      "grad_norm": 0.8202388286590576,
      "learning_rate": 0.0004986875199415166,
      "loss": 0.9827,
      "step": 122250
    },
    {
      "epoch": 1.2947157806702272,
      "grad_norm": 0.8442569971084595,
      "learning_rate": 0.0004986827886482676,
      "loss": 0.9856,
      "step": 122300
    },
    {
      "epoch": 1.2952451024502305,
      "grad_norm": 0.9421643018722534,
      "learning_rate": 0.0004986780488650793,
      "loss": 0.9683,
      "step": 122350
    },
    {
      "epoch": 1.2957744242302338,
      "grad_norm": 0.8469049334526062,
      "learning_rate": 0.0004986733005921137,
      "loss": 0.966,
      "step": 122400
    },
    {
      "epoch": 1.2963037460102371,
      "grad_norm": 0.8775754570960999,
      "learning_rate": 0.0004986685438295328,
      "loss": 0.9745,
      "step": 122450
    },
    {
      "epoch": 1.2968330677902404,
      "grad_norm": 0.8500836491584778,
      "learning_rate": 0.0004986637785774989,
      "loss": 0.9784,
      "step": 122500
    },
    {
      "epoch": 1.2968330677902404,
      "eval_loss": 0.8502848744392395,
      "eval_runtime": 46.7578,
      "eval_samples_per_second": 3591.485,
      "eval_steps_per_second": 448.952,
      "step": 122500
    },
    {
      "epoch": 1.2973623895702437,
      "grad_norm": 1.0082082748413086,
      "learning_rate": 0.0004986590048361749,
      "loss": 0.965,
      "step": 122550
    },
    {
      "epoch": 1.297891711350247,
      "grad_norm": 0.8227005004882812,
      "learning_rate": 0.0004986542226057235,
      "loss": 0.9737,
      "step": 122600
    },
    {
      "epoch": 1.2984210331302501,
      "grad_norm": 0.8559206128120422,
      "learning_rate": 0.0004986494318863083,
      "loss": 0.9871,
      "step": 122650
    },
    {
      "epoch": 1.2989503549102535,
      "grad_norm": 0.8443984985351562,
      "learning_rate": 0.0004986446326780927,
      "loss": 0.98,
      "step": 122700
    },
    {
      "epoch": 1.2994796766902568,
      "grad_norm": 0.7993547320365906,
      "learning_rate": 0.0004986398249812405,
      "loss": 0.982,
      "step": 122750
    },
    {
      "epoch": 1.30000899847026,
      "grad_norm": 0.8425277471542358,
      "learning_rate": 0.0004986350087959158,
      "loss": 0.9804,
      "step": 122800
    },
    {
      "epoch": 1.3005383202502634,
      "grad_norm": 0.8880361914634705,
      "learning_rate": 0.0004986301841222831,
      "loss": 0.9803,
      "step": 122850
    },
    {
      "epoch": 1.3010676420302667,
      "grad_norm": 0.9622201919555664,
      "learning_rate": 0.0004986253509605071,
      "loss": 0.9763,
      "step": 122900
    },
    {
      "epoch": 1.3015969638102698,
      "grad_norm": 0.9036365151405334,
      "learning_rate": 0.0004986205093107528,
      "loss": 0.9672,
      "step": 122950
    },
    {
      "epoch": 1.302126285590273,
      "grad_norm": 0.879543662071228,
      "learning_rate": 0.0004986156591731855,
      "loss": 0.9922,
      "step": 123000
    },
    {
      "epoch": 1.302126285590273,
      "eval_loss": 0.8492053151130676,
      "eval_runtime": 46.8048,
      "eval_samples_per_second": 3587.877,
      "eval_steps_per_second": 448.501,
      "step": 123000
    },
    {
      "epoch": 1.3026556073702764,
      "grad_norm": 0.8821497559547424,
      "learning_rate": 0.0004986108005479708,
      "loss": 0.9643,
      "step": 123050
    },
    {
      "epoch": 1.3031849291502797,
      "grad_norm": 0.8218783140182495,
      "learning_rate": 0.0004986059334352744,
      "loss": 0.988,
      "step": 123100
    },
    {
      "epoch": 1.303714250930283,
      "grad_norm": 0.8237724304199219,
      "learning_rate": 0.0004986010578352628,
      "loss": 0.9762,
      "step": 123150
    },
    {
      "epoch": 1.3042435727102863,
      "grad_norm": 0.8066244721412659,
      "learning_rate": 0.0004985961737481022,
      "loss": 0.9787,
      "step": 123200
    },
    {
      "epoch": 1.3047728944902897,
      "grad_norm": 0.9082939624786377,
      "learning_rate": 0.0004985912811739595,
      "loss": 0.9797,
      "step": 123250
    },
    {
      "epoch": 1.305302216270293,
      "grad_norm": 0.8898575901985168,
      "learning_rate": 0.0004985863801130015,
      "loss": 0.9882,
      "step": 123300
    },
    {
      "epoch": 1.3058315380502963,
      "grad_norm": 0.8643063902854919,
      "learning_rate": 0.0004985814705653956,
      "loss": 0.9766,
      "step": 123350
    },
    {
      "epoch": 1.3063608598302994,
      "grad_norm": 0.7892298102378845,
      "learning_rate": 0.0004985765525313095,
      "loss": 0.9571,
      "step": 123400
    },
    {
      "epoch": 1.3068901816103027,
      "grad_norm": 0.880244791507721,
      "learning_rate": 0.0004985716260109111,
      "loss": 0.9645,
      "step": 123450
    },
    {
      "epoch": 1.307419503390306,
      "grad_norm": 0.7859582304954529,
      "learning_rate": 0.0004985666910043686,
      "loss": 0.9797,
      "step": 123500
    },
    {
      "epoch": 1.307419503390306,
      "eval_loss": 0.8472513556480408,
      "eval_runtime": 46.819,
      "eval_samples_per_second": 3586.791,
      "eval_steps_per_second": 448.365,
      "step": 123500
    },
    {
      "epoch": 1.3079488251703093,
      "grad_norm": 0.8567472100257874,
      "learning_rate": 0.0004985617475118503,
      "loss": 0.9816,
      "step": 123550
    },
    {
      "epoch": 1.3084781469503126,
      "grad_norm": 0.8031386733055115,
      "learning_rate": 0.0004985567955335252,
      "loss": 0.9871,
      "step": 123600
    },
    {
      "epoch": 1.309007468730316,
      "grad_norm": 0.8465593457221985,
      "learning_rate": 0.0004985518350695622,
      "loss": 0.9886,
      "step": 123650
    },
    {
      "epoch": 1.309536790510319,
      "grad_norm": 0.94948810338974,
      "learning_rate": 0.0004985468661201307,
      "loss": 0.971,
      "step": 123700
    },
    {
      "epoch": 1.3100661122903223,
      "grad_norm": 0.9376298189163208,
      "learning_rate": 0.0004985418886854004,
      "loss": 0.9851,
      "step": 123750
    },
    {
      "epoch": 1.3105954340703256,
      "grad_norm": 0.8325823545455933,
      "learning_rate": 0.0004985369027655411,
      "loss": 0.9603,
      "step": 123800
    },
    {
      "epoch": 1.311124755850329,
      "grad_norm": 0.853404700756073,
      "learning_rate": 0.0004985319083607231,
      "loss": 0.985,
      "step": 123850
    },
    {
      "epoch": 1.3116540776303323,
      "grad_norm": 0.8397623896598816,
      "learning_rate": 0.0004985269054711169,
      "loss": 0.9512,
      "step": 123900
    },
    {
      "epoch": 1.3121833994103356,
      "grad_norm": 0.8513116836547852,
      "learning_rate": 0.0004985218940968933,
      "loss": 0.9931,
      "step": 123950
    },
    {
      "epoch": 1.3127127211903389,
      "grad_norm": 0.8488753437995911,
      "learning_rate": 0.0004985168742382234,
      "loss": 0.9823,
      "step": 124000
    },
    {
      "epoch": 1.3127127211903389,
      "eval_loss": 0.8415034413337708,
      "eval_runtime": 46.8057,
      "eval_samples_per_second": 3587.81,
      "eval_steps_per_second": 448.492,
      "step": 124000
    },
    {
      "epoch": 1.3132420429703422,
      "grad_norm": 0.7964093685150146,
      "learning_rate": 0.0004985118458952785,
      "loss": 0.9824,
      "step": 124050
    },
    {
      "epoch": 1.3137713647503455,
      "grad_norm": 0.8912460207939148,
      "learning_rate": 0.0004985068090682304,
      "loss": 0.9935,
      "step": 124100
    },
    {
      "epoch": 1.3143006865303486,
      "grad_norm": 0.7819578647613525,
      "learning_rate": 0.000498501763757251,
      "loss": 0.9779,
      "step": 124150
    },
    {
      "epoch": 1.314830008310352,
      "grad_norm": 0.8392660617828369,
      "learning_rate": 0.0004984967099625124,
      "loss": 0.9691,
      "step": 124200
    },
    {
      "epoch": 1.3153593300903552,
      "grad_norm": 0.9356849789619446,
      "learning_rate": 0.0004984916476841873,
      "loss": 0.9692,
      "step": 124250
    },
    {
      "epoch": 1.3158886518703585,
      "grad_norm": 0.8336297869682312,
      "learning_rate": 0.0004984865769224484,
      "loss": 0.97,
      "step": 124300
    },
    {
      "epoch": 1.3164179736503618,
      "grad_norm": 0.9720431566238403,
      "learning_rate": 0.0004984814976774691,
      "loss": 0.9834,
      "step": 124350
    },
    {
      "epoch": 1.3169472954303652,
      "grad_norm": 0.8388112783432007,
      "learning_rate": 0.0004984764099494225,
      "loss": 0.9918,
      "step": 124400
    },
    {
      "epoch": 1.3174766172103682,
      "grad_norm": 0.9032678604125977,
      "learning_rate": 0.0004984713137384824,
      "loss": 0.9993,
      "step": 124450
    },
    {
      "epoch": 1.3180059389903716,
      "grad_norm": 0.7773078083992004,
      "learning_rate": 0.0004984663112218254,
      "loss": 0.9798,
      "step": 124500
    },
    {
      "epoch": 1.3180059389903716,
      "eval_loss": 0.8428570628166199,
      "eval_runtime": 46.7858,
      "eval_samples_per_second": 3589.334,
      "eval_steps_per_second": 448.683,
      "step": 124500
    },
    {
      "epoch": 1.3185352607703749,
      "grad_norm": 0.7980418801307678,
      "learning_rate": 0.0004984611982152697,
      "loss": 0.9696,
      "step": 124550
    },
    {
      "epoch": 1.3190645825503782,
      "grad_norm": 0.8979528546333313,
      "learning_rate": 0.0004984560767263398,
      "loss": 0.984,
      "step": 124600
    },
    {
      "epoch": 1.3195939043303815,
      "grad_norm": 0.8484184741973877,
      "learning_rate": 0.0004984509467552105,
      "loss": 0.961,
      "step": 124650
    },
    {
      "epoch": 1.3201232261103848,
      "grad_norm": 0.9028404951095581,
      "learning_rate": 0.0004984458083020572,
      "loss": 0.9711,
      "step": 124700
    },
    {
      "epoch": 1.320652547890388,
      "grad_norm": 0.8440081477165222,
      "learning_rate": 0.0004984406613670548,
      "loss": 0.9677,
      "step": 124750
    },
    {
      "epoch": 1.3211818696703914,
      "grad_norm": 0.8863824605941772,
      "learning_rate": 0.0004984355059503796,
      "loss": 0.9559,
      "step": 124800
    },
    {
      "epoch": 1.3217111914503947,
      "grad_norm": 0.9082460999488831,
      "learning_rate": 0.0004984303420522072,
      "loss": 0.9823,
      "step": 124850
    },
    {
      "epoch": 1.3222405132303978,
      "grad_norm": 0.8263005018234253,
      "learning_rate": 0.0004984251696727141,
      "loss": 0.9653,
      "step": 124900
    },
    {
      "epoch": 1.3227698350104011,
      "grad_norm": 0.8565595746040344,
      "learning_rate": 0.0004984199888120768,
      "loss": 0.9652,
      "step": 124950
    },
    {
      "epoch": 1.3232991567904044,
      "grad_norm": 0.9050332903862,
      "learning_rate": 0.0004984147994704721,
      "loss": 0.9658,
      "step": 125000
    },
    {
      "epoch": 1.3232991567904044,
      "eval_loss": 0.8370347619056702,
      "eval_runtime": 46.8479,
      "eval_samples_per_second": 3584.576,
      "eval_steps_per_second": 448.088,
      "step": 125000
    },
    {
      "epoch": 1.3238284785704078,
      "grad_norm": 0.8779200911521912,
      "learning_rate": 0.0004984096016480774,
      "loss": 0.961,
      "step": 125050
    },
    {
      "epoch": 1.324357800350411,
      "grad_norm": 0.9064682126045227,
      "learning_rate": 0.0004984043953450699,
      "loss": 0.9671,
      "step": 125100
    },
    {
      "epoch": 1.3248871221304144,
      "grad_norm": 0.8158370852470398,
      "learning_rate": 0.0004983991805616275,
      "loss": 0.9928,
      "step": 125150
    },
    {
      "epoch": 1.3254164439104175,
      "grad_norm": 0.8663182854652405,
      "learning_rate": 0.0004983939572979282,
      "loss": 0.9755,
      "step": 125200
    },
    {
      "epoch": 1.3259457656904208,
      "grad_norm": 0.8184667229652405,
      "learning_rate": 0.0004983887255541502,
      "loss": 0.9794,
      "step": 125250
    },
    {
      "epoch": 1.326475087470424,
      "grad_norm": 0.9388671517372131,
      "learning_rate": 0.0004983834853304721,
      "loss": 0.979,
      "step": 125300
    },
    {
      "epoch": 1.3270044092504274,
      "grad_norm": 0.8677646517753601,
      "learning_rate": 0.0004983782366270731,
      "loss": 0.9727,
      "step": 125350
    },
    {
      "epoch": 1.3275337310304307,
      "grad_norm": 0.7992708683013916,
      "learning_rate": 0.0004983729794441322,
      "loss": 0.958,
      "step": 125400
    },
    {
      "epoch": 1.328063052810434,
      "grad_norm": 0.9095050096511841,
      "learning_rate": 0.0004983677137818288,
      "loss": 0.9817,
      "step": 125450
    },
    {
      "epoch": 1.3285923745904373,
      "grad_norm": 0.8359653353691101,
      "learning_rate": 0.0004983624396403427,
      "loss": 0.9779,
      "step": 125500
    },
    {
      "epoch": 1.3285923745904373,
      "eval_loss": 0.8366491794586182,
      "eval_runtime": 46.7789,
      "eval_samples_per_second": 3589.863,
      "eval_steps_per_second": 448.749,
      "step": 125500
    },
    {
      "epoch": 1.3291216963704406,
      "grad_norm": 0.8218521475791931,
      "learning_rate": 0.0004983571570198541,
      "loss": 0.9842,
      "step": 125550
    },
    {
      "epoch": 1.329651018150444,
      "grad_norm": 0.8994307518005371,
      "learning_rate": 0.0004983518659205431,
      "loss": 0.9718,
      "step": 125600
    },
    {
      "epoch": 1.330180339930447,
      "grad_norm": 0.7606327533721924,
      "learning_rate": 0.0004983465663425905,
      "loss": 0.9556,
      "step": 125650
    },
    {
      "epoch": 1.3307096617104504,
      "grad_norm": 0.8209853768348694,
      "learning_rate": 0.0004983412582861774,
      "loss": 0.9643,
      "step": 125700
    },
    {
      "epoch": 1.3312389834904537,
      "grad_norm": 0.9765639305114746,
      "learning_rate": 0.0004983359417514847,
      "loss": 0.9816,
      "step": 125750
    },
    {
      "epoch": 1.331768305270457,
      "grad_norm": 0.8710009455680847,
      "learning_rate": 0.0004983306167386939,
      "loss": 0.9709,
      "step": 125800
    },
    {
      "epoch": 1.3322976270504603,
      "grad_norm": 0.9124577045440674,
      "learning_rate": 0.0004983252832479871,
      "loss": 0.9689,
      "step": 125850
    },
    {
      "epoch": 1.3328269488304636,
      "grad_norm": 0.7803526520729065,
      "learning_rate": 0.0004983199412795461,
      "loss": 0.9758,
      "step": 125900
    },
    {
      "epoch": 1.3333562706104667,
      "grad_norm": 0.9131565093994141,
      "learning_rate": 0.0004983145908335533,
      "loss": 0.9626,
      "step": 125950
    },
    {
      "epoch": 1.33388559239047,
      "grad_norm": 0.8193476796150208,
      "learning_rate": 0.0004983092319101916,
      "loss": 0.9725,
      "step": 126000
    },
    {
      "epoch": 1.33388559239047,
      "eval_loss": 0.8409507274627686,
      "eval_runtime": 46.776,
      "eval_samples_per_second": 3590.086,
      "eval_steps_per_second": 448.777,
      "step": 126000
    },
    {
      "epoch": 1.3344149141704733,
      "grad_norm": 0.833279550075531,
      "learning_rate": 0.0004983038645096437,
      "loss": 0.9769,
      "step": 126050
    },
    {
      "epoch": 1.3349442359504766,
      "grad_norm": 0.8895654678344727,
      "learning_rate": 0.0004982984886320929,
      "loss": 0.9759,
      "step": 126100
    },
    {
      "epoch": 1.33547355773048,
      "grad_norm": 0.875668466091156,
      "learning_rate": 0.0004982931042777229,
      "loss": 0.9767,
      "step": 126150
    },
    {
      "epoch": 1.3360028795104832,
      "grad_norm": 0.841046154499054,
      "learning_rate": 0.0004982877114467172,
      "loss": 0.9683,
      "step": 126200
    },
    {
      "epoch": 1.3365322012904866,
      "grad_norm": 0.8912737369537354,
      "learning_rate": 0.0004982823101392603,
      "loss": 0.9718,
      "step": 126250
    },
    {
      "epoch": 1.3370615230704899,
      "grad_norm": 0.8743035793304443,
      "learning_rate": 0.0004982769003555362,
      "loss": 0.9651,
      "step": 126300
    },
    {
      "epoch": 1.3375908448504932,
      "grad_norm": 0.8710632920265198,
      "learning_rate": 0.0004982714820957298,
      "loss": 0.9853,
      "step": 126350
    },
    {
      "epoch": 1.3381201666304963,
      "grad_norm": 0.8934242725372314,
      "learning_rate": 0.0004982660553600262,
      "loss": 0.9644,
      "step": 126400
    },
    {
      "epoch": 1.3386494884104996,
      "grad_norm": 0.899438738822937,
      "learning_rate": 0.0004982606201486102,
      "loss": 0.972,
      "step": 126450
    },
    {
      "epoch": 1.3391788101905029,
      "grad_norm": 0.8630706667900085,
      "learning_rate": 0.0004982551764616679,
      "loss": 0.971,
      "step": 126500
    },
    {
      "epoch": 1.3391788101905029,
      "eval_loss": 0.8345113396644592,
      "eval_runtime": 46.8417,
      "eval_samples_per_second": 3585.056,
      "eval_steps_per_second": 448.148,
      "step": 126500
    },
    {
      "epoch": 1.3397081319705062,
      "grad_norm": 0.8514692187309265,
      "learning_rate": 0.000498249724299385,
      "loss": 0.9655,
      "step": 126550
    },
    {
      "epoch": 1.3402374537505095,
      "grad_norm": 0.9218048453330994,
      "learning_rate": 0.0004982442636619474,
      "loss": 0.9641,
      "step": 126600
    },
    {
      "epoch": 1.3407667755305128,
      "grad_norm": 0.8892293572425842,
      "learning_rate": 0.0004982387945495417,
      "loss": 0.9894,
      "step": 126650
    },
    {
      "epoch": 1.341296097310516,
      "grad_norm": 0.8703711628913879,
      "learning_rate": 0.0004982333169623547,
      "loss": 0.9635,
      "step": 126700
    },
    {
      "epoch": 1.3418254190905192,
      "grad_norm": 0.8797411322593689,
      "learning_rate": 0.0004982278309005732,
      "loss": 0.9572,
      "step": 126750
    },
    {
      "epoch": 1.3423547408705225,
      "grad_norm": 0.8537412881851196,
      "learning_rate": 0.0004982223363643847,
      "loss": 0.9917,
      "step": 126800
    },
    {
      "epoch": 1.3428840626505258,
      "grad_norm": 0.8422664403915405,
      "learning_rate": 0.0004982168333539765,
      "loss": 0.9547,
      "step": 126850
    },
    {
      "epoch": 1.3434133844305292,
      "grad_norm": 0.9120126962661743,
      "learning_rate": 0.0004982113218695368,
      "loss": 0.9949,
      "step": 126900
    },
    {
      "epoch": 1.3439427062105325,
      "grad_norm": 0.8970181345939636,
      "learning_rate": 0.0004982058019112535,
      "loss": 0.9709,
      "step": 126950
    },
    {
      "epoch": 1.3444720279905358,
      "grad_norm": 0.8880140781402588,
      "learning_rate": 0.0004982002734793152,
      "loss": 0.9728,
      "step": 127000
    },
    {
      "epoch": 1.3444720279905358,
      "eval_loss": 0.8286558985710144,
      "eval_runtime": 46.8046,
      "eval_samples_per_second": 3587.897,
      "eval_steps_per_second": 448.503,
      "step": 127000
    },
    {
      "epoch": 1.345001349770539,
      "grad_norm": 0.8253323435783386,
      "learning_rate": 0.0004981948473950574,
      "loss": 0.9833,
      "step": 127050
    },
    {
      "epoch": 1.3455306715505424,
      "grad_norm": 0.9110295176506042,
      "learning_rate": 0.0004981893021858391,
      "loss": 0.9668,
      "step": 127100
    },
    {
      "epoch": 1.3460599933305455,
      "grad_norm": 1.0082505941390991,
      "learning_rate": 0.0004981837485035291,
      "loss": 0.9586,
      "step": 127150
    },
    {
      "epoch": 1.3465893151105488,
      "grad_norm": 0.8886207342147827,
      "learning_rate": 0.000498178186348317,
      "loss": 0.9806,
      "step": 127200
    },
    {
      "epoch": 1.3471186368905521,
      "grad_norm": 0.9585338234901428,
      "learning_rate": 0.0004981726157203926,
      "loss": 0.9446,
      "step": 127250
    },
    {
      "epoch": 1.3476479586705554,
      "grad_norm": 0.9188724756240845,
      "learning_rate": 0.0004981670366199461,
      "loss": 0.9678,
      "step": 127300
    },
    {
      "epoch": 1.3481772804505587,
      "grad_norm": 0.834161102771759,
      "learning_rate": 0.0004981614490471679,
      "loss": 0.9585,
      "step": 127350
    },
    {
      "epoch": 1.348706602230562,
      "grad_norm": 0.9437099695205688,
      "learning_rate": 0.000498155853002249,
      "loss": 0.9655,
      "step": 127400
    },
    {
      "epoch": 1.3492359240105651,
      "grad_norm": 0.8736440539360046,
      "learning_rate": 0.0004981502484853802,
      "loss": 0.9658,
      "step": 127450
    },
    {
      "epoch": 1.3497652457905684,
      "grad_norm": 0.8680801391601562,
      "learning_rate": 0.0004981446354967529,
      "loss": 0.9735,
      "step": 127500
    },
    {
      "epoch": 1.3497652457905684,
      "eval_loss": 0.8274601697921753,
      "eval_runtime": 46.7828,
      "eval_samples_per_second": 3589.565,
      "eval_steps_per_second": 448.712,
      "step": 127500
    },
    {
      "epoch": 1.3502945675705718,
      "grad_norm": 0.9001654982566833,
      "learning_rate": 0.0004981390140365589,
      "loss": 0.984,
      "step": 127550
    },
    {
      "epoch": 1.350823889350575,
      "grad_norm": 0.8452230095863342,
      "learning_rate": 0.0004981333841049898,
      "loss": 0.9762,
      "step": 127600
    },
    {
      "epoch": 1.3513532111305784,
      "grad_norm": 0.8172594308853149,
      "learning_rate": 0.000498127745702238,
      "loss": 0.9644,
      "step": 127650
    },
    {
      "epoch": 1.3518825329105817,
      "grad_norm": 0.901791512966156,
      "learning_rate": 0.000498122098828496,
      "loss": 0.9667,
      "step": 127700
    },
    {
      "epoch": 1.352411854690585,
      "grad_norm": 0.8005537986755371,
      "learning_rate": 0.0004981164434839565,
      "loss": 0.9548,
      "step": 127750
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 0.9034044146537781,
      "learning_rate": 0.0004981107796688127,
      "loss": 0.973,
      "step": 127800
    },
    {
      "epoch": 1.3534704982505916,
      "grad_norm": 0.9441192150115967,
      "learning_rate": 0.0004981051073832578,
      "loss": 0.965,
      "step": 127850
    },
    {
      "epoch": 1.353999820030595,
      "grad_norm": 0.8583622574806213,
      "learning_rate": 0.0004980994266274855,
      "loss": 0.9647,
      "step": 127900
    },
    {
      "epoch": 1.354529141810598,
      "grad_norm": 0.9007599353790283,
      "learning_rate": 0.0004980937374016899,
      "loss": 0.9712,
      "step": 127950
    },
    {
      "epoch": 1.3550584635906013,
      "grad_norm": 0.8500162363052368,
      "learning_rate": 0.0004980880397060649,
      "loss": 0.9542,
      "step": 128000
    },
    {
      "epoch": 1.3550584635906013,
      "eval_loss": 0.8256285190582275,
      "eval_runtime": 46.7421,
      "eval_samples_per_second": 3592.692,
      "eval_steps_per_second": 449.103,
      "step": 128000
    },
    {
      "epoch": 1.3555877853706046,
      "grad_norm": 0.8388031125068665,
      "learning_rate": 0.0004980823335408053,
      "loss": 0.9667,
      "step": 128050
    },
    {
      "epoch": 1.356117107150608,
      "grad_norm": 0.8470049500465393,
      "learning_rate": 0.0004980766189061058,
      "loss": 0.9669,
      "step": 128100
    },
    {
      "epoch": 1.3566464289306113,
      "grad_norm": 0.9497362375259399,
      "learning_rate": 0.0004980708958021615,
      "loss": 0.982,
      "step": 128150
    },
    {
      "epoch": 1.3571757507106144,
      "grad_norm": 0.8565757870674133,
      "learning_rate": 0.0004980651642291678,
      "loss": 0.9566,
      "step": 128200
    },
    {
      "epoch": 1.3577050724906177,
      "grad_norm": 0.949442982673645,
      "learning_rate": 0.0004980594241873204,
      "loss": 0.9526,
      "step": 128250
    },
    {
      "epoch": 1.358234394270621,
      "grad_norm": 0.8814300298690796,
      "learning_rate": 0.0004980536756768152,
      "loss": 0.9487,
      "step": 128300
    },
    {
      "epoch": 1.3587637160506243,
      "grad_norm": 0.8793205618858337,
      "learning_rate": 0.0004980479186978485,
      "loss": 0.9478,
      "step": 128350
    },
    {
      "epoch": 1.3592930378306276,
      "grad_norm": 0.9141949415206909,
      "learning_rate": 0.0004980421532506168,
      "loss": 0.9604,
      "step": 128400
    },
    {
      "epoch": 1.359822359610631,
      "grad_norm": 0.892562210559845,
      "learning_rate": 0.0004980363793353169,
      "loss": 0.967,
      "step": 128450
    },
    {
      "epoch": 1.3603516813906342,
      "grad_norm": 0.9267396330833435,
      "learning_rate": 0.0004980305969521461,
      "loss": 0.9711,
      "step": 128500
    },
    {
      "epoch": 1.3603516813906342,
      "eval_loss": 0.8244853615760803,
      "eval_runtime": 46.7792,
      "eval_samples_per_second": 3589.844,
      "eval_steps_per_second": 448.747,
      "step": 128500
    },
    {
      "epoch": 1.3608810031706375,
      "grad_norm": 0.7876973748207092,
      "learning_rate": 0.0004980248061013017,
      "loss": 0.9596,
      "step": 128550
    },
    {
      "epoch": 1.3614103249506408,
      "grad_norm": 0.9087393879890442,
      "learning_rate": 0.0004980190067829813,
      "loss": 0.9705,
      "step": 128600
    },
    {
      "epoch": 1.3619396467306442,
      "grad_norm": 0.8390234708786011,
      "learning_rate": 0.000498013198997383,
      "loss": 0.9726,
      "step": 128650
    },
    {
      "epoch": 1.3624689685106472,
      "grad_norm": 0.8973149061203003,
      "learning_rate": 0.000498007382744705,
      "loss": 0.976,
      "step": 128700
    },
    {
      "epoch": 1.3629982902906506,
      "grad_norm": 0.917570173740387,
      "learning_rate": 0.0004980015580251459,
      "loss": 0.9645,
      "step": 128750
    },
    {
      "epoch": 1.3635276120706539,
      "grad_norm": 0.7845287322998047,
      "learning_rate": 0.0004979957248389046,
      "loss": 0.974,
      "step": 128800
    },
    {
      "epoch": 1.3640569338506572,
      "grad_norm": 0.8997674584388733,
      "learning_rate": 0.0004979898831861802,
      "loss": 0.9786,
      "step": 128850
    },
    {
      "epoch": 1.3645862556306605,
      "grad_norm": 0.8899086713790894,
      "learning_rate": 0.0004979840330671722,
      "loss": 0.9629,
      "step": 128900
    },
    {
      "epoch": 1.3651155774106636,
      "grad_norm": 0.8787902593612671,
      "learning_rate": 0.0004979781744820802,
      "loss": 0.9604,
      "step": 128950
    },
    {
      "epoch": 1.365644899190667,
      "grad_norm": 0.882321834564209,
      "learning_rate": 0.0004979723074311042,
      "loss": 0.9653,
      "step": 129000
    },
    {
      "epoch": 1.365644899190667,
      "eval_loss": 0.8210875391960144,
      "eval_runtime": 46.7129,
      "eval_samples_per_second": 3594.938,
      "eval_steps_per_second": 449.383,
      "step": 129000
    },
    {
      "epoch": 1.3661742209706702,
      "grad_norm": 0.9459611773490906,
      "learning_rate": 0.0004979664319144446,
      "loss": 0.9635,
      "step": 129050
    },
    {
      "epoch": 1.3667035427506735,
      "grad_norm": 0.921920120716095,
      "learning_rate": 0.000497960547932302,
      "loss": 0.9584,
      "step": 129100
    },
    {
      "epoch": 1.3672328645306768,
      "grad_norm": 0.8606648445129395,
      "learning_rate": 0.0004979546554848772,
      "loss": 0.958,
      "step": 129150
    },
    {
      "epoch": 1.3677621863106801,
      "grad_norm": 0.8449075818061829,
      "learning_rate": 0.0004979487545723714,
      "loss": 0.9575,
      "step": 129200
    },
    {
      "epoch": 1.3682915080906835,
      "grad_norm": 0.9011518359184265,
      "learning_rate": 0.0004979428451949861,
      "loss": 0.9564,
      "step": 129250
    },
    {
      "epoch": 1.3688208298706868,
      "grad_norm": 0.8661218285560608,
      "learning_rate": 0.0004979369273529229,
      "loss": 0.9558,
      "step": 129300
    },
    {
      "epoch": 1.36935015165069,
      "grad_norm": 0.8145736455917358,
      "learning_rate": 0.000497931001046384,
      "loss": 0.9495,
      "step": 129350
    },
    {
      "epoch": 1.3698794734306934,
      "grad_norm": 0.8865575194358826,
      "learning_rate": 0.0004979250662755716,
      "loss": 0.9496,
      "step": 129400
    },
    {
      "epoch": 1.3704087952106965,
      "grad_norm": 0.8741602301597595,
      "learning_rate": 0.0004979191230406884,
      "loss": 0.9727,
      "step": 129450
    },
    {
      "epoch": 1.3709381169906998,
      "grad_norm": 0.8386735320091248,
      "learning_rate": 0.0004979131713419373,
      "loss": 0.9567,
      "step": 129500
    },
    {
      "epoch": 1.3709381169906998,
      "eval_loss": 0.8222439289093018,
      "eval_runtime": 46.8042,
      "eval_samples_per_second": 3587.925,
      "eval_steps_per_second": 448.507,
      "step": 129500
    },
    {
      "epoch": 1.371467438770703,
      "grad_norm": 0.866794228553772,
      "learning_rate": 0.0004979072111795213,
      "loss": 0.9672,
      "step": 129550
    },
    {
      "epoch": 1.3719967605507064,
      "grad_norm": 0.9562146067619324,
      "learning_rate": 0.0004979012425536442,
      "loss": 0.9662,
      "step": 129600
    },
    {
      "epoch": 1.3725260823307097,
      "grad_norm": 0.8964427709579468,
      "learning_rate": 0.0004978953850892307,
      "loss": 0.9529,
      "step": 129650
    },
    {
      "epoch": 1.3730554041107128,
      "grad_norm": 0.818620502948761,
      "learning_rate": 0.0004978893997063018,
      "loss": 0.957,
      "step": 129700
    },
    {
      "epoch": 1.3735847258907161,
      "grad_norm": 0.9181476831436157,
      "learning_rate": 0.0004978834058605194,
      "loss": 0.9497,
      "step": 129750
    },
    {
      "epoch": 1.3741140476707194,
      "grad_norm": 0.8663604259490967,
      "learning_rate": 0.0004978774035520886,
      "loss": 0.9599,
      "step": 129800
    },
    {
      "epoch": 1.3746433694507227,
      "grad_norm": 0.8616359233856201,
      "learning_rate": 0.0004978713927812142,
      "loss": 0.9519,
      "step": 129850
    },
    {
      "epoch": 1.375172691230726,
      "grad_norm": 0.9386124610900879,
      "learning_rate": 0.0004978653735481012,
      "loss": 0.9598,
      "step": 129900
    },
    {
      "epoch": 1.3757020130107294,
      "grad_norm": 0.9607113599777222,
      "learning_rate": 0.0004978593458529553,
      "loss": 0.9735,
      "step": 129950
    },
    {
      "epoch": 1.3762313347907327,
      "grad_norm": 0.8782463669776917,
      "learning_rate": 0.0004978533096959823,
      "loss": 0.9617,
      "step": 130000
    },
    {
      "epoch": 1.3762313347907327,
      "eval_loss": 0.8172793984413147,
      "eval_runtime": 46.9054,
      "eval_samples_per_second": 3580.181,
      "eval_steps_per_second": 447.539,
      "step": 130000
    },
    {
      "epoch": 1.376760656570736,
      "grad_norm": 0.7455675601959229,
      "learning_rate": 0.0004978472650773883,
      "loss": 0.9698,
      "step": 130050
    },
    {
      "epoch": 1.3772899783507393,
      "grad_norm": 0.820411205291748,
      "learning_rate": 0.0004978412119973793,
      "loss": 0.9674,
      "step": 130100
    },
    {
      "epoch": 1.3778193001307426,
      "grad_norm": 1.0069186687469482,
      "learning_rate": 0.0004978351504561624,
      "loss": 0.9489,
      "step": 130150
    },
    {
      "epoch": 1.3783486219107457,
      "grad_norm": 0.895819365978241,
      "learning_rate": 0.0004978290804539443,
      "loss": 0.9769,
      "step": 130200
    },
    {
      "epoch": 1.378877943690749,
      "grad_norm": 0.8208510875701904,
      "learning_rate": 0.0004978230019909323,
      "loss": 0.9702,
      "step": 130250
    },
    {
      "epoch": 1.3794072654707523,
      "grad_norm": 0.8527746796607971,
      "learning_rate": 0.0004978169150673339,
      "loss": 0.9548,
      "step": 130300
    },
    {
      "epoch": 1.3799365872507556,
      "grad_norm": 0.9483092427253723,
      "learning_rate": 0.0004978108196833569,
      "loss": 0.9549,
      "step": 130350
    },
    {
      "epoch": 1.380465909030759,
      "grad_norm": 0.8700151443481445,
      "learning_rate": 0.0004978047158392093,
      "loss": 0.9496,
      "step": 130400
    },
    {
      "epoch": 1.3809952308107623,
      "grad_norm": 0.8847988247871399,
      "learning_rate": 0.0004977986035350996,
      "loss": 0.9562,
      "step": 130450
    },
    {
      "epoch": 1.3815245525907653,
      "grad_norm": 0.8265483379364014,
      "learning_rate": 0.0004977924827712366,
      "loss": 0.9499,
      "step": 130500
    },
    {
      "epoch": 1.3815245525907653,
      "eval_loss": 0.8147213459014893,
      "eval_runtime": 46.784,
      "eval_samples_per_second": 3589.473,
      "eval_steps_per_second": 448.7,
      "step": 130500
    },
    {
      "epoch": 1.3820538743707687,
      "grad_norm": 0.8253188729286194,
      "learning_rate": 0.000497786353547829,
      "loss": 0.9449,
      "step": 130550
    },
    {
      "epoch": 1.382583196150772,
      "grad_norm": 0.9927408695220947,
      "learning_rate": 0.0004977802158650862,
      "loss": 0.9611,
      "step": 130600
    },
    {
      "epoch": 1.3831125179307753,
      "grad_norm": 0.9175574779510498,
      "learning_rate": 0.0004977740697232177,
      "loss": 0.9455,
      "step": 130650
    },
    {
      "epoch": 1.3836418397107786,
      "grad_norm": 0.9092074632644653,
      "learning_rate": 0.0004977679151224333,
      "loss": 0.9505,
      "step": 130700
    },
    {
      "epoch": 1.384171161490782,
      "grad_norm": 0.9547020792961121,
      "learning_rate": 0.0004977617520629432,
      "loss": 0.9407,
      "step": 130750
    },
    {
      "epoch": 1.3847004832707852,
      "grad_norm": 0.8539783358573914,
      "learning_rate": 0.0004977555805449577,
      "loss": 0.9435,
      "step": 130800
    },
    {
      "epoch": 1.3852298050507885,
      "grad_norm": 0.864048421382904,
      "learning_rate": 0.0004977494005686875,
      "loss": 0.9797,
      "step": 130850
    },
    {
      "epoch": 1.3857591268307918,
      "grad_norm": 0.9547899961471558,
      "learning_rate": 0.0004977432121343437,
      "loss": 0.9719,
      "step": 130900
    },
    {
      "epoch": 1.386288448610795,
      "grad_norm": 0.8667541742324829,
      "learning_rate": 0.0004977370152421376,
      "loss": 0.9602,
      "step": 130950
    },
    {
      "epoch": 1.3868177703907982,
      "grad_norm": 0.8368728160858154,
      "learning_rate": 0.0004977308098922805,
      "loss": 0.956,
      "step": 131000
    },
    {
      "epoch": 1.3868177703907982,
      "eval_loss": 0.8147653341293335,
      "eval_runtime": 46.7954,
      "eval_samples_per_second": 3588.599,
      "eval_steps_per_second": 448.591,
      "step": 131000
    },
    {
      "epoch": 1.3873470921708015,
      "grad_norm": 0.9320807456970215,
      "learning_rate": 0.0004977245960849844,
      "loss": 0.922,
      "step": 131050
    },
    {
      "epoch": 1.3878764139508049,
      "grad_norm": 0.8443337082862854,
      "learning_rate": 0.0004977183738204615,
      "loss": 0.9401,
      "step": 131100
    },
    {
      "epoch": 1.3884057357308082,
      "grad_norm": 0.8602299690246582,
      "learning_rate": 0.0004977121430989241,
      "loss": 0.9488,
      "step": 131150
    },
    {
      "epoch": 1.3889350575108115,
      "grad_norm": 0.8677955865859985,
      "learning_rate": 0.0004977059039205851,
      "loss": 0.9475,
      "step": 131200
    },
    {
      "epoch": 1.3894643792908146,
      "grad_norm": 0.8423739671707153,
      "learning_rate": 0.0004976996562856572,
      "loss": 0.9552,
      "step": 131250
    },
    {
      "epoch": 1.3899937010708179,
      "grad_norm": 0.8907985687255859,
      "learning_rate": 0.000497693400194354,
      "loss": 0.9469,
      "step": 131300
    },
    {
      "epoch": 1.3905230228508212,
      "grad_norm": 0.8795140385627747,
      "learning_rate": 0.0004976871356468889,
      "loss": 0.9624,
      "step": 131350
    },
    {
      "epoch": 1.3910523446308245,
      "grad_norm": 0.9128067493438721,
      "learning_rate": 0.0004976808626434759,
      "loss": 0.958,
      "step": 131400
    },
    {
      "epoch": 1.3915816664108278,
      "grad_norm": 0.8699430227279663,
      "learning_rate": 0.0004976745811843291,
      "loss": 0.963,
      "step": 131450
    },
    {
      "epoch": 1.3921109881908311,
      "grad_norm": 0.8347312211990356,
      "learning_rate": 0.0004976682912696628,
      "loss": 0.9337,
      "step": 131500
    },
    {
      "epoch": 1.3921109881908311,
      "eval_loss": 0.8086600303649902,
      "eval_runtime": 46.6614,
      "eval_samples_per_second": 3598.903,
      "eval_steps_per_second": 449.879,
      "step": 131500
    },
    {
      "epoch": 1.3926403099708344,
      "grad_norm": 0.9640282988548279,
      "learning_rate": 0.000497661992899692,
      "loss": 0.9509,
      "step": 131550
    },
    {
      "epoch": 1.3931696317508377,
      "grad_norm": 0.8367284536361694,
      "learning_rate": 0.0004976556860746315,
      "loss": 0.9432,
      "step": 131600
    },
    {
      "epoch": 1.393698953530841,
      "grad_norm": 0.8278836607933044,
      "learning_rate": 0.0004976493707946968,
      "loss": 0.9447,
      "step": 131650
    },
    {
      "epoch": 1.3942282753108441,
      "grad_norm": 0.8225952982902527,
      "learning_rate": 0.0004976430470601033,
      "loss": 0.9574,
      "step": 131700
    },
    {
      "epoch": 1.3947575970908475,
      "grad_norm": 0.9379119873046875,
      "learning_rate": 0.0004976367148710669,
      "loss": 0.9426,
      "step": 131750
    },
    {
      "epoch": 1.3952869188708508,
      "grad_norm": 0.8529806733131409,
      "learning_rate": 0.0004976303742278041,
      "loss": 0.9493,
      "step": 131800
    },
    {
      "epoch": 1.395816240650854,
      "grad_norm": 0.9182521104812622,
      "learning_rate": 0.000497624025130531,
      "loss": 0.9586,
      "step": 131850
    },
    {
      "epoch": 1.3963455624308574,
      "grad_norm": 0.8690300583839417,
      "learning_rate": 0.0004976176675794646,
      "loss": 0.9383,
      "step": 131900
    },
    {
      "epoch": 1.3968748842108607,
      "grad_norm": 0.8862254023551941,
      "learning_rate": 0.0004976113015748218,
      "loss": 0.9691,
      "step": 131950
    },
    {
      "epoch": 1.3974042059908638,
      "grad_norm": 0.9310730695724487,
      "learning_rate": 0.00049760492711682,
      "loss": 0.9353,
      "step": 132000
    },
    {
      "epoch": 1.3974042059908638,
      "eval_loss": 0.8051106929779053,
      "eval_runtime": 46.7487,
      "eval_samples_per_second": 3592.188,
      "eval_steps_per_second": 449.039,
      "step": 132000
    },
    {
      "epoch": 1.397933527770867,
      "grad_norm": 0.8302215337753296,
      "learning_rate": 0.0004975985442056766,
      "loss": 0.9683,
      "step": 132050
    },
    {
      "epoch": 1.3984628495508704,
      "grad_norm": 0.7959840893745422,
      "learning_rate": 0.00049759215284161,
      "loss": 0.955,
      "step": 132100
    },
    {
      "epoch": 1.3989921713308737,
      "grad_norm": 0.9622946977615356,
      "learning_rate": 0.0004975857530248378,
      "loss": 0.9388,
      "step": 132150
    },
    {
      "epoch": 1.399521493110877,
      "grad_norm": 0.8596135377883911,
      "learning_rate": 0.0004975793447555791,
      "loss": 0.9516,
      "step": 132200
    },
    {
      "epoch": 1.4000508148908803,
      "grad_norm": 0.9276080131530762,
      "learning_rate": 0.0004975729280340521,
      "loss": 0.9606,
      "step": 132250
    },
    {
      "epoch": 1.4005801366708837,
      "grad_norm": 0.8182846307754517,
      "learning_rate": 0.0004975665028604763,
      "loss": 0.954,
      "step": 132300
    },
    {
      "epoch": 1.401109458450887,
      "grad_norm": 0.8709080219268799,
      "learning_rate": 0.0004975600692350708,
      "loss": 0.9521,
      "step": 132350
    },
    {
      "epoch": 1.4016387802308903,
      "grad_norm": 0.8773309588432312,
      "learning_rate": 0.0004975536271580554,
      "loss": 0.9449,
      "step": 132400
    },
    {
      "epoch": 1.4021681020108934,
      "grad_norm": 0.894968569278717,
      "learning_rate": 0.0004975471766296499,
      "loss": 0.9398,
      "step": 132450
    },
    {
      "epoch": 1.4026974237908967,
      "grad_norm": 0.8710548877716064,
      "learning_rate": 0.0004975407176500745,
      "loss": 0.9643,
      "step": 132500
    },
    {
      "epoch": 1.4026974237908967,
      "eval_loss": 0.8046546578407288,
      "eval_runtime": 46.8036,
      "eval_samples_per_second": 3587.973,
      "eval_steps_per_second": 448.513,
      "step": 132500
    },
    {
      "epoch": 1.4032267455709,
      "grad_norm": 0.931298017501831,
      "learning_rate": 0.0004975342502195499,
      "loss": 0.9502,
      "step": 132550
    },
    {
      "epoch": 1.4037560673509033,
      "grad_norm": 0.892963707447052,
      "learning_rate": 0.0004975277743382968,
      "loss": 0.944,
      "step": 132600
    },
    {
      "epoch": 1.4042853891309066,
      "grad_norm": 0.8412942290306091,
      "learning_rate": 0.0004975212900065363,
      "loss": 0.9618,
      "step": 132650
    },
    {
      "epoch": 1.40481471091091,
      "grad_norm": 0.9074766039848328,
      "learning_rate": 0.0004975147972244896,
      "loss": 0.9433,
      "step": 132700
    },
    {
      "epoch": 1.405344032690913,
      "grad_norm": 0.7553728222846985,
      "learning_rate": 0.0004975082959923785,
      "loss": 0.9508,
      "step": 132750
    },
    {
      "epoch": 1.4058733544709163,
      "grad_norm": 0.8948279023170471,
      "learning_rate": 0.000497501786310425,
      "loss": 0.9552,
      "step": 132800
    },
    {
      "epoch": 1.4064026762509196,
      "grad_norm": 0.8614630699157715,
      "learning_rate": 0.0004974952681788512,
      "loss": 0.9711,
      "step": 132850
    },
    {
      "epoch": 1.406931998030923,
      "grad_norm": 0.94084632396698,
      "learning_rate": 0.0004974887415978798,
      "loss": 0.9565,
      "step": 132900
    },
    {
      "epoch": 1.4074613198109263,
      "grad_norm": 0.9500294327735901,
      "learning_rate": 0.0004974822065677336,
      "loss": 0.9556,
      "step": 132950
    },
    {
      "epoch": 1.4079906415909296,
      "grad_norm": 0.8727981448173523,
      "learning_rate": 0.0004974756630886355,
      "loss": 0.9665,
      "step": 133000
    },
    {
      "epoch": 1.4079906415909296,
      "eval_loss": 0.8045443892478943,
      "eval_runtime": 46.6682,
      "eval_samples_per_second": 3598.38,
      "eval_steps_per_second": 449.814,
      "step": 133000
    },
    {
      "epoch": 1.4085199633709329,
      "grad_norm": 0.8662503957748413,
      "learning_rate": 0.000497469111160809,
      "loss": 0.944,
      "step": 133050
    },
    {
      "epoch": 1.4090492851509362,
      "grad_norm": 0.8849254250526428,
      "learning_rate": 0.0004974625507844779,
      "loss": 0.964,
      "step": 133100
    },
    {
      "epoch": 1.4095786069309395,
      "grad_norm": 0.8988520503044128,
      "learning_rate": 0.0004974559819598661,
      "loss": 0.9549,
      "step": 133150
    },
    {
      "epoch": 1.4101079287109426,
      "grad_norm": 0.9765348434448242,
      "learning_rate": 0.0004974494046871977,
      "loss": 0.947,
      "step": 133200
    },
    {
      "epoch": 1.410637250490946,
      "grad_norm": 0.8877848982810974,
      "learning_rate": 0.0004974428189666974,
      "loss": 0.9507,
      "step": 133250
    },
    {
      "epoch": 1.4111665722709492,
      "grad_norm": 0.792604386806488,
      "learning_rate": 0.0004974362247985901,
      "loss": 0.9356,
      "step": 133300
    },
    {
      "epoch": 1.4116958940509525,
      "grad_norm": 0.8741458058357239,
      "learning_rate": 0.0004974296221831007,
      "loss": 0.9527,
      "step": 133350
    },
    {
      "epoch": 1.4122252158309558,
      "grad_norm": 0.9353567361831665,
      "learning_rate": 0.0004974230111204548,
      "loss": 0.9461,
      "step": 133400
    },
    {
      "epoch": 1.4127545376109591,
      "grad_norm": 0.8749846816062927,
      "learning_rate": 0.0004974165240838481,
      "loss": 0.9656,
      "step": 133450
    },
    {
      "epoch": 1.4132838593909622,
      "grad_norm": 0.8440501093864441,
      "learning_rate": 0.0004974098962964984,
      "loss": 0.9491,
      "step": 133500
    },
    {
      "epoch": 1.4132838593909622,
      "eval_loss": 0.8019245266914368,
      "eval_runtime": 46.7044,
      "eval_samples_per_second": 3595.589,
      "eval_steps_per_second": 449.465,
      "step": 133500
    },
    {
      "epoch": 1.4138131811709655,
      "grad_norm": 0.8016914129257202,
      "learning_rate": 0.0004974032600626655,
      "loss": 0.9485,
      "step": 133550
    },
    {
      "epoch": 1.4143425029509689,
      "grad_norm": 0.8695046901702881,
      "learning_rate": 0.000497396615382576,
      "loss": 0.9539,
      "step": 133600
    },
    {
      "epoch": 1.4148718247309722,
      "grad_norm": 0.841343343257904,
      "learning_rate": 0.0004973899622564569,
      "loss": 0.9538,
      "step": 133650
    },
    {
      "epoch": 1.4154011465109755,
      "grad_norm": 0.7386435866355896,
      "learning_rate": 0.0004973833006845352,
      "loss": 0.9531,
      "step": 133700
    },
    {
      "epoch": 1.4159304682909788,
      "grad_norm": 0.8511297702789307,
      "learning_rate": 0.0004973766306670383,
      "loss": 0.9336,
      "step": 133750
    },
    {
      "epoch": 1.416459790070982,
      "grad_norm": 0.8477075695991516,
      "learning_rate": 0.000497369952204194,
      "loss": 0.9424,
      "step": 133800
    },
    {
      "epoch": 1.4169891118509854,
      "grad_norm": 0.8575665354728699,
      "learning_rate": 0.0004973632652962302,
      "loss": 0.9676,
      "step": 133850
    },
    {
      "epoch": 1.4175184336309887,
      "grad_norm": 0.8495833277702332,
      "learning_rate": 0.0004973565699433753,
      "loss": 0.9514,
      "step": 133900
    },
    {
      "epoch": 1.4180477554109918,
      "grad_norm": 0.7887924909591675,
      "learning_rate": 0.0004973498661458577,
      "loss": 0.9643,
      "step": 133950
    },
    {
      "epoch": 1.4185770771909951,
      "grad_norm": 0.8801023960113525,
      "learning_rate": 0.0004973431539039065,
      "loss": 0.9477,
      "step": 134000
    },
    {
      "epoch": 1.4185770771909951,
      "eval_loss": 0.7992743253707886,
      "eval_runtime": 46.7825,
      "eval_samples_per_second": 3589.591,
      "eval_steps_per_second": 448.715,
      "step": 134000
    },
    {
      "epoch": 1.4191063989709984,
      "grad_norm": 0.9598865509033203,
      "learning_rate": 0.0004973364332177507,
      "loss": 0.9667,
      "step": 134050
    },
    {
      "epoch": 1.4196357207510018,
      "grad_norm": 0.7838722467422485,
      "learning_rate": 0.0004973297040876197,
      "loss": 0.9671,
      "step": 134100
    },
    {
      "epoch": 1.420165042531005,
      "grad_norm": 0.8483617901802063,
      "learning_rate": 0.0004973229665137434,
      "loss": 0.9477,
      "step": 134150
    },
    {
      "epoch": 1.4206943643110084,
      "grad_norm": 0.9129160046577454,
      "learning_rate": 0.0004973162204963517,
      "loss": 0.9366,
      "step": 134200
    },
    {
      "epoch": 1.4212236860910115,
      "grad_norm": 0.7830910682678223,
      "learning_rate": 0.0004973094660356749,
      "loss": 0.9252,
      "step": 134250
    },
    {
      "epoch": 1.4217530078710148,
      "grad_norm": 0.7838413715362549,
      "learning_rate": 0.0004973027031319437,
      "loss": 0.944,
      "step": 134300
    },
    {
      "epoch": 1.422282329651018,
      "grad_norm": 0.9583613872528076,
      "learning_rate": 0.0004972959317853889,
      "loss": 0.9422,
      "step": 134350
    },
    {
      "epoch": 1.4228116514310214,
      "grad_norm": 0.8776893019676208,
      "learning_rate": 0.0004972891519962416,
      "loss": 0.9663,
      "step": 134400
    },
    {
      "epoch": 1.4233409732110247,
      "grad_norm": 0.9556734561920166,
      "learning_rate": 0.0004972823637647334,
      "loss": 0.9389,
      "step": 134450
    },
    {
      "epoch": 1.423870294991028,
      "grad_norm": 0.8653216361999512,
      "learning_rate": 0.000497275567091096,
      "loss": 0.9405,
      "step": 134500
    },
    {
      "epoch": 1.423870294991028,
      "eval_loss": 0.8003439903259277,
      "eval_runtime": 46.783,
      "eval_samples_per_second": 3589.554,
      "eval_steps_per_second": 448.71,
      "step": 134500
    },
    {
      "epoch": 1.4243996167710313,
      "grad_norm": 0.8797321915626526,
      "learning_rate": 0.0004972687619755614,
      "loss": 0.9581,
      "step": 134550
    },
    {
      "epoch": 1.4249289385510346,
      "grad_norm": 0.906007707118988,
      "learning_rate": 0.000497261948418362,
      "loss": 0.9439,
      "step": 134600
    },
    {
      "epoch": 1.425458260331038,
      "grad_norm": 0.802337110042572,
      "learning_rate": 0.0004972551264197302,
      "loss": 0.9341,
      "step": 134650
    },
    {
      "epoch": 1.425987582111041,
      "grad_norm": 0.8207817673683167,
      "learning_rate": 0.0004972482959798993,
      "loss": 0.9418,
      "step": 134700
    },
    {
      "epoch": 1.4265169038910444,
      "grad_norm": 0.9170407056808472,
      "learning_rate": 0.0004972414570991021,
      "loss": 0.9407,
      "step": 134750
    },
    {
      "epoch": 1.4270462256710477,
      "grad_norm": 0.8891139626502991,
      "learning_rate": 0.0004972346097775723,
      "loss": 0.9563,
      "step": 134800
    },
    {
      "epoch": 1.427575547451051,
      "grad_norm": 0.7170935869216919,
      "learning_rate": 0.0004972277540155435,
      "loss": 0.9445,
      "step": 134850
    },
    {
      "epoch": 1.4281048692310543,
      "grad_norm": 0.7662716507911682,
      "learning_rate": 0.0004972208898132499,
      "loss": 0.936,
      "step": 134900
    },
    {
      "epoch": 1.4286341910110576,
      "grad_norm": 0.9421641230583191,
      "learning_rate": 0.0004972140171709259,
      "loss": 0.9352,
      "step": 134950
    },
    {
      "epoch": 1.4291635127910607,
      "grad_norm": 0.8520375490188599,
      "learning_rate": 0.0004972071360888059,
      "loss": 0.934,
      "step": 135000
    },
    {
      "epoch": 1.4291635127910607,
      "eval_loss": 0.7971504330635071,
      "eval_runtime": 46.7425,
      "eval_samples_per_second": 3592.661,
      "eval_steps_per_second": 449.099,
      "step": 135000
    },
    {
      "epoch": 1.429692834571064,
      "grad_norm": 0.8879482746124268,
      "learning_rate": 0.0004972002465671248,
      "loss": 0.9642,
      "step": 135050
    },
    {
      "epoch": 1.4302221563510673,
      "grad_norm": 0.8577318787574768,
      "learning_rate": 0.0004971933486061182,
      "loss": 0.9461,
      "step": 135100
    },
    {
      "epoch": 1.4307514781310706,
      "grad_norm": 0.8621661067008972,
      "learning_rate": 0.0004971864422060212,
      "loss": 0.9426,
      "step": 135150
    },
    {
      "epoch": 1.431280799911074,
      "grad_norm": 0.9284698367118835,
      "learning_rate": 0.0004971795273670698,
      "loss": 0.9479,
      "step": 135200
    },
    {
      "epoch": 1.4318101216910772,
      "grad_norm": 0.8363346457481384,
      "learning_rate": 0.0004971726040894998,
      "loss": 0.9389,
      "step": 135250
    },
    {
      "epoch": 1.4323394434710806,
      "grad_norm": 0.8513762950897217,
      "learning_rate": 0.0004971656723735478,
      "loss": 0.9442,
      "step": 135300
    },
    {
      "epoch": 1.4328687652510839,
      "grad_norm": 0.8353561162948608,
      "learning_rate": 0.0004971587322194505,
      "loss": 0.9624,
      "step": 135350
    },
    {
      "epoch": 1.4333980870310872,
      "grad_norm": 0.8551821708679199,
      "learning_rate": 0.0004971517836274448,
      "loss": 0.9387,
      "step": 135400
    },
    {
      "epoch": 1.4339274088110905,
      "grad_norm": 0.961439311504364,
      "learning_rate": 0.0004971448265977676,
      "loss": 0.9377,
      "step": 135450
    },
    {
      "epoch": 1.4344567305910936,
      "grad_norm": 0.9065198302268982,
      "learning_rate": 0.0004971378611306568,
      "loss": 0.9362,
      "step": 135500
    },
    {
      "epoch": 1.4344567305910936,
      "eval_loss": 0.793787956237793,
      "eval_runtime": 46.7689,
      "eval_samples_per_second": 3590.636,
      "eval_steps_per_second": 448.846,
      "step": 135500
    },
    {
      "epoch": 1.4349860523710969,
      "grad_norm": 0.8596575856208801,
      "learning_rate": 0.00049713088722635,
      "loss": 0.9338,
      "step": 135550
    },
    {
      "epoch": 1.4355153741511002,
      "grad_norm": 0.9153915047645569,
      "learning_rate": 0.0004971239048850854,
      "loss": 0.9303,
      "step": 135600
    },
    {
      "epoch": 1.4360446959311035,
      "grad_norm": 0.8360865116119385,
      "learning_rate": 0.0004971169141071013,
      "loss": 0.9327,
      "step": 135650
    },
    {
      "epoch": 1.4365740177111068,
      "grad_norm": 0.8477411270141602,
      "learning_rate": 0.0004971099148926364,
      "loss": 0.9159,
      "step": 135700
    },
    {
      "epoch": 1.43710333949111,
      "grad_norm": 0.850823163986206,
      "learning_rate": 0.0004971029072419296,
      "loss": 0.9211,
      "step": 135750
    },
    {
      "epoch": 1.4376326612711132,
      "grad_norm": 0.8527826070785522,
      "learning_rate": 0.0004970958911552202,
      "loss": 0.9369,
      "step": 135800
    },
    {
      "epoch": 1.4381619830511165,
      "grad_norm": 0.8962118625640869,
      "learning_rate": 0.0004970888666327477,
      "loss": 0.9353,
      "step": 135850
    },
    {
      "epoch": 1.4386913048311198,
      "grad_norm": 0.8531832695007324,
      "learning_rate": 0.0004970818336747519,
      "loss": 0.9445,
      "step": 135900
    },
    {
      "epoch": 1.4392206266111232,
      "grad_norm": 0.883705198764801,
      "learning_rate": 0.0004970747922814729,
      "loss": 0.9336,
      "step": 135950
    },
    {
      "epoch": 1.4397499483911265,
      "grad_norm": 0.8785067200660706,
      "learning_rate": 0.0004970677424531511,
      "loss": 0.9343,
      "step": 136000
    },
    {
      "epoch": 1.4397499483911265,
      "eval_loss": 0.7932348847389221,
      "eval_runtime": 46.7448,
      "eval_samples_per_second": 3592.482,
      "eval_steps_per_second": 449.076,
      "step": 136000
    },
    {
      "epoch": 1.4402792701711298,
      "grad_norm": 0.9042478203773499,
      "learning_rate": 0.0004970606841900271,
      "loss": 0.9343,
      "step": 136050
    },
    {
      "epoch": 1.440808591951133,
      "grad_norm": 0.8867876529693604,
      "learning_rate": 0.0004970536174923421,
      "loss": 0.9351,
      "step": 136100
    },
    {
      "epoch": 1.4413379137311364,
      "grad_norm": 0.8817614912986755,
      "learning_rate": 0.0004970465423603371,
      "loss": 0.9382,
      "step": 136150
    },
    {
      "epoch": 1.4418672355111397,
      "grad_norm": 0.9224734902381897,
      "learning_rate": 0.0004970394587942538,
      "loss": 0.9351,
      "step": 136200
    },
    {
      "epoch": 1.4423965572911428,
      "grad_norm": 0.796358585357666,
      "learning_rate": 0.000497032366794334,
      "loss": 0.9464,
      "step": 136250
    },
    {
      "epoch": 1.4429258790711461,
      "grad_norm": 0.8630716800689697,
      "learning_rate": 0.0004970252663608197,
      "loss": 0.9416,
      "step": 136300
    },
    {
      "epoch": 1.4434552008511494,
      "grad_norm": 0.9047448635101318,
      "learning_rate": 0.0004970181574939534,
      "loss": 0.9151,
      "step": 136350
    },
    {
      "epoch": 1.4439845226311527,
      "grad_norm": 0.8513253927230835,
      "learning_rate": 0.0004970110401939779,
      "loss": 0.9446,
      "step": 136400
    },
    {
      "epoch": 1.444513844411156,
      "grad_norm": 0.9090933799743652,
      "learning_rate": 0.000497003914461136,
      "loss": 0.9322,
      "step": 136450
    },
    {
      "epoch": 1.4450431661911591,
      "grad_norm": 0.9325775504112244,
      "learning_rate": 0.000496996780295671,
      "loss": 0.9207,
      "step": 136500
    },
    {
      "epoch": 1.4450431661911591,
      "eval_loss": 0.7928400039672852,
      "eval_runtime": 46.7864,
      "eval_samples_per_second": 3589.294,
      "eval_steps_per_second": 448.678,
      "step": 136500
    },
    {
      "epoch": 1.4455724879711624,
      "grad_norm": 0.7018840909004211,
      "learning_rate": 0.0004969896376978267,
      "loss": 0.9192,
      "step": 136550
    },
    {
      "epoch": 1.4461018097511658,
      "grad_norm": 0.870996356010437,
      "learning_rate": 0.0004969824866678466,
      "loss": 0.9362,
      "step": 136600
    },
    {
      "epoch": 1.446631131531169,
      "grad_norm": 0.8349561095237732,
      "learning_rate": 0.000496975327205975,
      "loss": 0.9239,
      "step": 136650
    },
    {
      "epoch": 1.4471604533111724,
      "grad_norm": 0.909683346748352,
      "learning_rate": 0.0004969681593124563,
      "loss": 0.9406,
      "step": 136700
    },
    {
      "epoch": 1.4476897750911757,
      "grad_norm": 0.8612464666366577,
      "learning_rate": 0.0004969609829875352,
      "loss": 0.9519,
      "step": 136750
    },
    {
      "epoch": 1.448219096871179,
      "grad_norm": 0.8570812344551086,
      "learning_rate": 0.0004969537982314568,
      "loss": 0.9289,
      "step": 136800
    },
    {
      "epoch": 1.4487484186511823,
      "grad_norm": 0.8622503280639648,
      "learning_rate": 0.0004969466050444662,
      "loss": 0.9182,
      "step": 136850
    },
    {
      "epoch": 1.4492777404311856,
      "grad_norm": 1.0056170225143433,
      "learning_rate": 0.0004969394034268091,
      "loss": 0.9337,
      "step": 136900
    },
    {
      "epoch": 1.449807062211189,
      "grad_norm": 0.8581110835075378,
      "learning_rate": 0.0004969321933787313,
      "loss": 0.9336,
      "step": 136950
    },
    {
      "epoch": 1.450336383991192,
      "grad_norm": 0.8541524410247803,
      "learning_rate": 0.0004969249749004791,
      "loss": 0.9379,
      "step": 137000
    },
    {
      "epoch": 1.450336383991192,
      "eval_loss": 0.7926862239837646,
      "eval_runtime": 46.7134,
      "eval_samples_per_second": 3594.899,
      "eval_steps_per_second": 449.378,
      "step": 137000
    },
    {
      "epoch": 1.4508657057711953,
      "grad_norm": 0.8823630213737488,
      "learning_rate": 0.0004969177479922987,
      "loss": 0.9385,
      "step": 137050
    },
    {
      "epoch": 1.4513950275511986,
      "grad_norm": 0.837421178817749,
      "learning_rate": 0.0004969105126544368,
      "loss": 0.9496,
      "step": 137100
    },
    {
      "epoch": 1.451924349331202,
      "grad_norm": 0.8603866100311279,
      "learning_rate": 0.0004969032688871408,
      "loss": 0.9274,
      "step": 137150
    },
    {
      "epoch": 1.4524536711112053,
      "grad_norm": 0.9395528435707092,
      "learning_rate": 0.0004968960166906577,
      "loss": 0.9386,
      "step": 137200
    },
    {
      "epoch": 1.4529829928912084,
      "grad_norm": 0.8796736001968384,
      "learning_rate": 0.0004968887560652351,
      "loss": 0.9493,
      "step": 137250
    },
    {
      "epoch": 1.4535123146712117,
      "grad_norm": 0.8968333601951599,
      "learning_rate": 0.0004968814870111209,
      "loss": 0.937,
      "step": 137300
    },
    {
      "epoch": 1.454041636451215,
      "grad_norm": 0.8966491222381592,
      "learning_rate": 0.0004968742095285632,
      "loss": 0.9414,
      "step": 137350
    },
    {
      "epoch": 1.4545709582312183,
      "grad_norm": 0.9160173535346985,
      "learning_rate": 0.0004968669236178107,
      "loss": 0.9384,
      "step": 137400
    },
    {
      "epoch": 1.4551002800112216,
      "grad_norm": 0.7816548943519592,
      "learning_rate": 0.000496859775248478,
      "loss": 0.9272,
      "step": 137450
    },
    {
      "epoch": 1.455629601791225,
      "grad_norm": 0.8848097920417786,
      "learning_rate": 0.0004968524726506336,
      "loss": 0.913,
      "step": 137500
    },
    {
      "epoch": 1.455629601791225,
      "eval_loss": 0.7901918888092041,
      "eval_runtime": 46.7591,
      "eval_samples_per_second": 3591.384,
      "eval_steps_per_second": 448.939,
      "step": 137500
    },
    {
      "epoch": 1.4561589235712282,
      "grad_norm": 0.9054579138755798,
      "learning_rate": 0.0004968451616253362,
      "loss": 0.9375,
      "step": 137550
    },
    {
      "epoch": 1.4566882453512315,
      "grad_norm": 0.8765457272529602,
      "learning_rate": 0.0004968378421728355,
      "loss": 0.9373,
      "step": 137600
    },
    {
      "epoch": 1.4572175671312348,
      "grad_norm": 0.8664029836654663,
      "learning_rate": 0.0004968305142933813,
      "loss": 0.9414,
      "step": 137650
    },
    {
      "epoch": 1.4577468889112382,
      "grad_norm": 0.8824769258499146,
      "learning_rate": 0.000496823177987224,
      "loss": 0.9505,
      "step": 137700
    },
    {
      "epoch": 1.4582762106912412,
      "grad_norm": 0.8692070841789246,
      "learning_rate": 0.0004968158332546138,
      "loss": 0.9255,
      "step": 137750
    },
    {
      "epoch": 1.4588055324712446,
      "grad_norm": 0.9265245795249939,
      "learning_rate": 0.0004968084800958016,
      "loss": 0.9459,
      "step": 137800
    },
    {
      "epoch": 1.4593348542512479,
      "grad_norm": 0.870056688785553,
      "learning_rate": 0.0004968011185110385,
      "loss": 0.9259,
      "step": 137850
    },
    {
      "epoch": 1.4598641760312512,
      "grad_norm": 0.9886060357093811,
      "learning_rate": 0.0004967937485005757,
      "loss": 0.9455,
      "step": 137900
    },
    {
      "epoch": 1.4603934978112545,
      "grad_norm": 0.8179478049278259,
      "learning_rate": 0.0004967863700646647,
      "loss": 0.9351,
      "step": 137950
    },
    {
      "epoch": 1.4609228195912578,
      "grad_norm": 0.83826744556427,
      "learning_rate": 0.0004967789832035578,
      "loss": 0.9263,
      "step": 138000
    },
    {
      "epoch": 1.4609228195912578,
      "eval_loss": 0.7888159155845642,
      "eval_runtime": 46.5786,
      "eval_samples_per_second": 3605.307,
      "eval_steps_per_second": 450.68,
      "step": 138000
    },
    {
      "epoch": 1.461452141371261,
      "grad_norm": 0.8659202456474304,
      "learning_rate": 0.0004967715879175067,
      "loss": 0.9182,
      "step": 138050
    },
    {
      "epoch": 1.4619814631512642,
      "grad_norm": 0.7592623233795166,
      "learning_rate": 0.0004967641842067641,
      "loss": 0.9435,
      "step": 138100
    },
    {
      "epoch": 1.4625107849312675,
      "grad_norm": 0.8079145550727844,
      "learning_rate": 0.0004967567720715828,
      "loss": 0.9445,
      "step": 138150
    },
    {
      "epoch": 1.4630401067112708,
      "grad_norm": 0.8642439246177673,
      "learning_rate": 0.0004967493515122158,
      "loss": 0.9332,
      "step": 138200
    },
    {
      "epoch": 1.4635694284912741,
      "grad_norm": 0.8938217163085938,
      "learning_rate": 0.0004967419225289164,
      "loss": 0.9302,
      "step": 138250
    },
    {
      "epoch": 1.4640987502712774,
      "grad_norm": 0.8465824723243713,
      "learning_rate": 0.0004967344851219383,
      "loss": 0.9347,
      "step": 138300
    },
    {
      "epoch": 1.4646280720512808,
      "grad_norm": 0.942886471748352,
      "learning_rate": 0.0004967270392915353,
      "loss": 0.9303,
      "step": 138350
    },
    {
      "epoch": 1.465157393831284,
      "grad_norm": 0.879891574382782,
      "learning_rate": 0.0004967195850379617,
      "loss": 0.9453,
      "step": 138400
    },
    {
      "epoch": 1.4656867156112874,
      "grad_norm": 0.800597071647644,
      "learning_rate": 0.000496712122361472,
      "loss": 0.943,
      "step": 138450
    },
    {
      "epoch": 1.4662160373912905,
      "grad_norm": 0.8375964760780334,
      "learning_rate": 0.0004967046512623208,
      "loss": 0.9429,
      "step": 138500
    },
    {
      "epoch": 1.4662160373912905,
      "eval_loss": 0.7927160859107971,
      "eval_runtime": 46.7395,
      "eval_samples_per_second": 3592.896,
      "eval_steps_per_second": 449.128,
      "step": 138500
    },
    {
      "epoch": 1.4667453591712938,
      "grad_norm": 0.9246331453323364,
      "learning_rate": 0.0004966971717407634,
      "loss": 0.9277,
      "step": 138550
    },
    {
      "epoch": 1.467274680951297,
      "grad_norm": 0.8224939107894897,
      "learning_rate": 0.000496689683797055,
      "loss": 0.9255,
      "step": 138600
    },
    {
      "epoch": 1.4678040027313004,
      "grad_norm": 0.9004435539245605,
      "learning_rate": 0.0004966821874314512,
      "loss": 0.9335,
      "step": 138650
    },
    {
      "epoch": 1.4683333245113037,
      "grad_norm": 0.9525852203369141,
      "learning_rate": 0.0004966746826442081,
      "loss": 0.9291,
      "step": 138700
    },
    {
      "epoch": 1.468862646291307,
      "grad_norm": 0.9222309589385986,
      "learning_rate": 0.0004966671694355818,
      "loss": 0.9248,
      "step": 138750
    },
    {
      "epoch": 1.4693919680713101,
      "grad_norm": 0.7843241095542908,
      "learning_rate": 0.0004966596478058287,
      "loss": 0.9303,
      "step": 138800
    },
    {
      "epoch": 1.4699212898513134,
      "grad_norm": 0.8835071325302124,
      "learning_rate": 0.0004966521177552056,
      "loss": 0.937,
      "step": 138850
    },
    {
      "epoch": 1.4704506116313167,
      "grad_norm": 0.9157657623291016,
      "learning_rate": 0.0004966445792839699,
      "loss": 0.9296,
      "step": 138900
    },
    {
      "epoch": 1.47097993341132,
      "grad_norm": 0.9576064348220825,
      "learning_rate": 0.0004966370323923786,
      "loss": 0.9465,
      "step": 138950
    },
    {
      "epoch": 1.4715092551913234,
      "grad_norm": 0.9426153302192688,
      "learning_rate": 0.0004966294770806895,
      "loss": 0.9402,
      "step": 139000
    },
    {
      "epoch": 1.4715092551913234,
      "eval_loss": 0.7845131754875183,
      "eval_runtime": 46.8039,
      "eval_samples_per_second": 3587.949,
      "eval_steps_per_second": 448.51,
      "step": 139000
    },
    {
      "epoch": 1.4720385769713267,
      "grad_norm": 0.7846216559410095,
      "learning_rate": 0.0004966219133491605,
      "loss": 0.9383,
      "step": 139050
    },
    {
      "epoch": 1.47256789875133,
      "grad_norm": 0.8657860159873962,
      "learning_rate": 0.0004966143411980497,
      "loss": 0.9384,
      "step": 139100
    },
    {
      "epoch": 1.4730972205313333,
      "grad_norm": 0.9110967516899109,
      "learning_rate": 0.0004966067606276158,
      "loss": 0.9282,
      "step": 139150
    },
    {
      "epoch": 1.4736265423113366,
      "grad_norm": 0.8983190059661865,
      "learning_rate": 0.0004965991716381176,
      "loss": 0.9247,
      "step": 139200
    },
    {
      "epoch": 1.4741558640913397,
      "grad_norm": 0.9437798261642456,
      "learning_rate": 0.0004965915742298141,
      "loss": 0.9236,
      "step": 139250
    },
    {
      "epoch": 1.474685185871343,
      "grad_norm": 0.7801681756973267,
      "learning_rate": 0.0004965839684029646,
      "loss": 0.9286,
      "step": 139300
    },
    {
      "epoch": 1.4752145076513463,
      "grad_norm": 0.840446412563324,
      "learning_rate": 0.0004965763541578289,
      "loss": 0.9475,
      "step": 139350
    },
    {
      "epoch": 1.4757438294313496,
      "grad_norm": 0.9550991058349609,
      "learning_rate": 0.000496568731494667,
      "loss": 0.9288,
      "step": 139400
    },
    {
      "epoch": 1.476273151211353,
      "grad_norm": 0.8504354953765869,
      "learning_rate": 0.0004965612531178499,
      "loss": 0.9243,
      "step": 139450
    },
    {
      "epoch": 1.4768024729913563,
      "grad_norm": 0.8376665711402893,
      "learning_rate": 0.0004965536137877638,
      "loss": 0.9235,
      "step": 139500
    },
    {
      "epoch": 1.4768024729913563,
      "eval_loss": 0.7849715352058411,
      "eval_runtime": 46.736,
      "eval_samples_per_second": 3593.164,
      "eval_steps_per_second": 449.162,
      "step": 139500
    },
    {
      "epoch": 1.4773317947713593,
      "grad_norm": 0.9091359972953796,
      "learning_rate": 0.0004965459660404278,
      "loss": 0.9351,
      "step": 139550
    },
    {
      "epoch": 1.4778611165513627,
      "grad_norm": 0.840566873550415,
      "learning_rate": 0.000496538309876103,
      "loss": 0.9213,
      "step": 139600
    },
    {
      "epoch": 1.478390438331366,
      "grad_norm": 0.8734099268913269,
      "learning_rate": 0.0004965306452950507,
      "loss": 0.9322,
      "step": 139650
    },
    {
      "epoch": 1.4789197601113693,
      "grad_norm": 0.8074774742126465,
      "learning_rate": 0.0004965229722975325,
      "loss": 0.9293,
      "step": 139700
    },
    {
      "epoch": 1.4794490818913726,
      "grad_norm": 0.9681313037872314,
      "learning_rate": 0.0004965152908838105,
      "loss": 0.9349,
      "step": 139750
    },
    {
      "epoch": 1.479978403671376,
      "grad_norm": 0.8004913330078125,
      "learning_rate": 0.0004965076010541469,
      "loss": 0.9389,
      "step": 139800
    },
    {
      "epoch": 1.4805077254513792,
      "grad_norm": 0.8449894189834595,
      "learning_rate": 0.0004964999028088041,
      "loss": 0.9411,
      "step": 139850
    },
    {
      "epoch": 1.4810370472313825,
      "grad_norm": 0.8875339031219482,
      "learning_rate": 0.000496492196148045,
      "loss": 0.9315,
      "step": 139900
    },
    {
      "epoch": 1.4815663690113858,
      "grad_norm": 0.9907575249671936,
      "learning_rate": 0.0004964844810721328,
      "loss": 0.9296,
      "step": 139950
    },
    {
      "epoch": 1.482095690791389,
      "grad_norm": 0.9411177635192871,
      "learning_rate": 0.0004964767575813308,
      "loss": 0.9238,
      "step": 140000
    },
    {
      "epoch": 1.482095690791389,
      "eval_loss": 0.7805440425872803,
      "eval_runtime": 46.765,
      "eval_samples_per_second": 3590.934,
      "eval_steps_per_second": 448.883,
      "step": 140000
    },
    {
      "epoch": 1.4826250125713922,
      "grad_norm": 0.8673130869865417,
      "learning_rate": 0.0004964690256759028,
      "loss": 0.9534,
      "step": 140050
    },
    {
      "epoch": 1.4831543343513955,
      "grad_norm": 0.9671460390090942,
      "learning_rate": 0.0004964612853561126,
      "loss": 0.9388,
      "step": 140100
    },
    {
      "epoch": 1.4836836561313989,
      "grad_norm": 0.9686567187309265,
      "learning_rate": 0.0004964535366222244,
      "loss": 0.9354,
      "step": 140150
    },
    {
      "epoch": 1.4842129779114022,
      "grad_norm": 0.8690959215164185,
      "learning_rate": 0.0004964457794745028,
      "loss": 0.928,
      "step": 140200
    },
    {
      "epoch": 1.4847422996914055,
      "grad_norm": 0.8512026071548462,
      "learning_rate": 0.0004964380139132129,
      "loss": 0.9251,
      "step": 140250
    },
    {
      "epoch": 1.4852716214714086,
      "grad_norm": 0.8352779150009155,
      "learning_rate": 0.0004964302399386194,
      "loss": 0.9358,
      "step": 140300
    },
    {
      "epoch": 1.4858009432514119,
      "grad_norm": 0.8770182132720947,
      "learning_rate": 0.0004964224575509879,
      "loss": 0.9304,
      "step": 140350
    },
    {
      "epoch": 1.4863302650314152,
      "grad_norm": 0.9180259108543396,
      "learning_rate": 0.0004964146667505841,
      "loss": 0.9229,
      "step": 140400
    },
    {
      "epoch": 1.4868595868114185,
      "grad_norm": 0.8070781230926514,
      "learning_rate": 0.0004964068675376741,
      "loss": 0.9386,
      "step": 140450
    },
    {
      "epoch": 1.4873889085914218,
      "grad_norm": 0.833436906337738,
      "learning_rate": 0.0004963990599125237,
      "loss": 0.9148,
      "step": 140500
    },
    {
      "epoch": 1.4873889085914218,
      "eval_loss": 0.7804787755012512,
      "eval_runtime": 46.7452,
      "eval_samples_per_second": 3592.455,
      "eval_steps_per_second": 449.073,
      "step": 140500
    },
    {
      "epoch": 1.4879182303714251,
      "grad_norm": 0.919270396232605,
      "learning_rate": 0.0004963912438754,
      "loss": 0.9194,
      "step": 140550
    },
    {
      "epoch": 1.4884475521514284,
      "grad_norm": 0.9359005093574524,
      "learning_rate": 0.0004963834194265695,
      "loss": 0.9136,
      "step": 140600
    },
    {
      "epoch": 1.4889768739314317,
      "grad_norm": 0.8983825445175171,
      "learning_rate": 0.0004963755865662994,
      "loss": 0.9363,
      "step": 140650
    },
    {
      "epoch": 1.489506195711435,
      "grad_norm": 0.8855263590812683,
      "learning_rate": 0.0004963677452948572,
      "loss": 0.9407,
      "step": 140700
    },
    {
      "epoch": 1.4900355174914381,
      "grad_norm": 0.8048914670944214,
      "learning_rate": 0.0004963598956125105,
      "loss": 0.922,
      "step": 140750
    },
    {
      "epoch": 1.4905648392714415,
      "grad_norm": 0.8011574745178223,
      "learning_rate": 0.0004963520375195274,
      "loss": 0.9302,
      "step": 140800
    },
    {
      "epoch": 1.4910941610514448,
      "grad_norm": 0.8514389991760254,
      "learning_rate": 0.000496344171016176,
      "loss": 0.9349,
      "step": 140850
    },
    {
      "epoch": 1.491623482831448,
      "grad_norm": 0.8261381983757019,
      "learning_rate": 0.0004963362961027249,
      "loss": 0.9245,
      "step": 140900
    },
    {
      "epoch": 1.4921528046114514,
      "grad_norm": 0.8506892323493958,
      "learning_rate": 0.0004963284127794431,
      "loss": 0.9141,
      "step": 140950
    },
    {
      "epoch": 1.4926821263914547,
      "grad_norm": 0.9416581392288208,
      "learning_rate": 0.0004963205210465995,
      "loss": 0.9268,
      "step": 141000
    },
    {
      "epoch": 1.4926821263914547,
      "eval_loss": 0.7729485034942627,
      "eval_runtime": 46.7273,
      "eval_samples_per_second": 3593.833,
      "eval_steps_per_second": 449.245,
      "step": 141000
    },
    {
      "epoch": 1.4932114481714578,
      "grad_norm": 0.8468901515007019,
      "learning_rate": 0.0004963126209044637,
      "loss": 0.9433,
      "step": 141050
    },
    {
      "epoch": 1.493740769951461,
      "grad_norm": 0.8263190984725952,
      "learning_rate": 0.0004963047123533054,
      "loss": 0.9211,
      "step": 141100
    },
    {
      "epoch": 1.4942700917314644,
      "grad_norm": 0.8781084418296814,
      "learning_rate": 0.0004962967953933945,
      "loss": 0.9256,
      "step": 141150
    },
    {
      "epoch": 1.4947994135114677,
      "grad_norm": 0.8500106334686279,
      "learning_rate": 0.0004962890286147706,
      "loss": 0.9181,
      "step": 141200
    },
    {
      "epoch": 1.495328735291471,
      "grad_norm": 0.8970314264297485,
      "learning_rate": 0.0004962810950063274,
      "loss": 0.9375,
      "step": 141250
    },
    {
      "epoch": 1.4958580570714743,
      "grad_norm": 0.8426451683044434,
      "learning_rate": 0.0004962731529899378,
      "loss": 0.9221,
      "step": 141300
    },
    {
      "epoch": 1.4963873788514777,
      "grad_norm": 0.9559012055397034,
      "learning_rate": 0.0004962652025658731,
      "loss": 0.9064,
      "step": 141350
    },
    {
      "epoch": 1.496916700631481,
      "grad_norm": 0.8542969226837158,
      "learning_rate": 0.0004962572437344048,
      "loss": 0.9279,
      "step": 141400
    },
    {
      "epoch": 1.4974460224114843,
      "grad_norm": 0.9038242101669312,
      "learning_rate": 0.0004962492764958044,
      "loss": 0.9322,
      "step": 141450
    },
    {
      "epoch": 1.4979753441914874,
      "grad_norm": 0.8728011846542358,
      "learning_rate": 0.0004962413008503441,
      "loss": 0.9063,
      "step": 141500
    },
    {
      "epoch": 1.4979753441914874,
      "eval_loss": 0.7728337645530701,
      "eval_runtime": 46.7561,
      "eval_samples_per_second": 3591.62,
      "eval_steps_per_second": 448.969,
      "step": 141500
    },
    {
      "epoch": 1.4985046659714907,
      "grad_norm": 0.8357283473014832,
      "learning_rate": 0.000496233316798296,
      "loss": 0.9417,
      "step": 141550
    },
    {
      "epoch": 1.499033987751494,
      "grad_norm": 0.902548611164093,
      "learning_rate": 0.0004962253243399329,
      "loss": 0.9305,
      "step": 141600
    },
    {
      "epoch": 1.4995633095314973,
      "grad_norm": 0.8352957367897034,
      "learning_rate": 0.0004962173234755275,
      "loss": 0.9261,
      "step": 141650
    },
    {
      "epoch": 1.5000926313115006,
      "grad_norm": 0.8816277980804443,
      "learning_rate": 0.0004962093142053529,
      "loss": 0.9273,
      "step": 141700
    },
    {
      "epoch": 1.5006219530915037,
      "grad_norm": 0.9023546576499939,
      "learning_rate": 0.0004962012965296826,
      "loss": 0.9024,
      "step": 141750
    },
    {
      "epoch": 1.501151274871507,
      "grad_norm": 0.838451623916626,
      "learning_rate": 0.0004961932704487903,
      "loss": 0.9211,
      "step": 141800
    },
    {
      "epoch": 1.5016805966515103,
      "grad_norm": 0.876854658126831,
      "learning_rate": 0.0004961852359629501,
      "loss": 0.9278,
      "step": 141850
    },
    {
      "epoch": 1.5022099184315136,
      "grad_norm": 0.9247975945472717,
      "learning_rate": 0.0004961771930724363,
      "loss": 0.9385,
      "step": 141900
    },
    {
      "epoch": 1.502739240211517,
      "grad_norm": 0.947272539138794,
      "learning_rate": 0.0004961691417775234,
      "loss": 0.9228,
      "step": 141950
    },
    {
      "epoch": 1.5032685619915203,
      "grad_norm": 0.8516001105308533,
      "learning_rate": 0.0004961610820784862,
      "loss": 0.9147,
      "step": 142000
    },
    {
      "epoch": 1.5032685619915203,
      "eval_loss": 0.7772198915481567,
      "eval_runtime": 46.7642,
      "eval_samples_per_second": 3590.998,
      "eval_steps_per_second": 448.891,
      "step": 142000
    },
    {
      "epoch": 1.5037978837715236,
      "grad_norm": 0.922309398651123,
      "learning_rate": 0.0004961530139755999,
      "loss": 0.9462,
      "step": 142050
    },
    {
      "epoch": 1.5043272055515269,
      "grad_norm": 0.8398197889328003,
      "learning_rate": 0.00049614493746914,
      "loss": 0.9262,
      "step": 142100
    },
    {
      "epoch": 1.5048565273315302,
      "grad_norm": 1.0023372173309326,
      "learning_rate": 0.0004961368525593822,
      "loss": 0.9216,
      "step": 142150
    },
    {
      "epoch": 1.5053858491115335,
      "grad_norm": 0.9328835010528564,
      "learning_rate": 0.0004961287592466026,
      "loss": 0.9132,
      "step": 142200
    },
    {
      "epoch": 1.5059151708915368,
      "grad_norm": 0.8703658580780029,
      "learning_rate": 0.0004961206575310774,
      "loss": 0.9172,
      "step": 142250
    },
    {
      "epoch": 1.50644449267154,
      "grad_norm": 0.8292330503463745,
      "learning_rate": 0.0004961125474130832,
      "loss": 0.9297,
      "step": 142300
    },
    {
      "epoch": 1.5069738144515432,
      "grad_norm": 0.8775182962417603,
      "learning_rate": 0.0004961044288928969,
      "loss": 0.9274,
      "step": 142350
    },
    {
      "epoch": 1.5075031362315465,
      "grad_norm": 0.9049081206321716,
      "learning_rate": 0.0004960963019707957,
      "loss": 0.9236,
      "step": 142400
    },
    {
      "epoch": 1.5080324580115498,
      "grad_norm": 0.8176854252815247,
      "learning_rate": 0.0004960881666470569,
      "loss": 0.9309,
      "step": 142450
    },
    {
      "epoch": 1.508561779791553,
      "grad_norm": 0.7890289425849915,
      "learning_rate": 0.0004960800229219584,
      "loss": 0.924,
      "step": 142500
    },
    {
      "epoch": 1.508561779791553,
      "eval_loss": 0.772781252861023,
      "eval_runtime": 46.7107,
      "eval_samples_per_second": 3595.108,
      "eval_steps_per_second": 449.405,
      "step": 142500
    },
    {
      "epoch": 1.5090911015715562,
      "grad_norm": 0.9641101360321045,
      "learning_rate": 0.0004960718707957782,
      "loss": 0.9265,
      "step": 142550
    },
    {
      "epoch": 1.5096204233515595,
      "grad_norm": 0.8815242648124695,
      "learning_rate": 0.0004960637102687944,
      "loss": 0.9323,
      "step": 142600
    },
    {
      "epoch": 1.5101497451315629,
      "grad_norm": 0.8694698214530945,
      "learning_rate": 0.0004960555413412859,
      "loss": 0.9286,
      "step": 142650
    },
    {
      "epoch": 1.5106790669115662,
      "grad_norm": 0.842686116695404,
      "learning_rate": 0.0004960473640135316,
      "loss": 0.9281,
      "step": 142700
    },
    {
      "epoch": 1.5112083886915695,
      "grad_norm": 0.8149994015693665,
      "learning_rate": 0.0004960391782858104,
      "loss": 0.9223,
      "step": 142750
    },
    {
      "epoch": 1.5117377104715728,
      "grad_norm": 0.9160458445549011,
      "learning_rate": 0.0004960309841584019,
      "loss": 0.925,
      "step": 142800
    },
    {
      "epoch": 1.512267032251576,
      "grad_norm": 0.9112150073051453,
      "learning_rate": 0.0004960227816315857,
      "loss": 0.9258,
      "step": 142850
    },
    {
      "epoch": 1.5127963540315794,
      "grad_norm": 0.8046944737434387,
      "learning_rate": 0.0004960145707056421,
      "loss": 0.9264,
      "step": 142900
    },
    {
      "epoch": 1.5133256758115827,
      "grad_norm": 0.8634594082832336,
      "learning_rate": 0.0004960063513808512,
      "loss": 0.9308,
      "step": 142950
    },
    {
      "epoch": 1.513854997591586,
      "grad_norm": 0.8710047006607056,
      "learning_rate": 0.0004959981236574937,
      "loss": 0.9318,
      "step": 143000
    },
    {
      "epoch": 1.513854997591586,
      "eval_loss": 0.7674378156661987,
      "eval_runtime": 46.733,
      "eval_samples_per_second": 3593.394,
      "eval_steps_per_second": 449.19,
      "step": 143000
    },
    {
      "epoch": 1.5143843193715893,
      "grad_norm": 0.8547808527946472,
      "learning_rate": 0.0004959898875358505,
      "loss": 0.919,
      "step": 143050
    },
    {
      "epoch": 1.5149136411515924,
      "grad_norm": 0.9664608240127563,
      "learning_rate": 0.0004959816430162028,
      "loss": 0.9312,
      "step": 143100
    },
    {
      "epoch": 1.5154429629315957,
      "grad_norm": 0.8394542932510376,
      "learning_rate": 0.000495973390098832,
      "loss": 0.9269,
      "step": 143150
    },
    {
      "epoch": 1.515972284711599,
      "grad_norm": 0.9572217464447021,
      "learning_rate": 0.0004959651287840198,
      "loss": 0.9049,
      "step": 143200
    },
    {
      "epoch": 1.5165016064916021,
      "grad_norm": 0.7809703946113586,
      "learning_rate": 0.0004959568590720484,
      "loss": 0.9232,
      "step": 143250
    },
    {
      "epoch": 1.5170309282716055,
      "grad_norm": 0.9050204157829285,
      "learning_rate": 0.0004959485809631999,
      "loss": 0.914,
      "step": 143300
    },
    {
      "epoch": 1.5175602500516088,
      "grad_norm": 0.838482141494751,
      "learning_rate": 0.0004959402944577573,
      "loss": 0.9171,
      "step": 143350
    },
    {
      "epoch": 1.518089571831612,
      "grad_norm": 0.8725671172142029,
      "learning_rate": 0.000495931999556003,
      "loss": 0.9211,
      "step": 143400
    },
    {
      "epoch": 1.5186188936116154,
      "grad_norm": 0.8887137770652771,
      "learning_rate": 0.0004959236962582205,
      "loss": 0.9432,
      "step": 143450
    },
    {
      "epoch": 1.5191482153916187,
      "grad_norm": 0.9275686740875244,
      "learning_rate": 0.0004959153845646932,
      "loss": 0.9148,
      "step": 143500
    },
    {
      "epoch": 1.5191482153916187,
      "eval_loss": 0.7702425122261047,
      "eval_runtime": 46.7093,
      "eval_samples_per_second": 3595.213,
      "eval_steps_per_second": 449.418,
      "step": 143500
    },
    {
      "epoch": 1.519677537171622,
      "grad_norm": 0.8824595808982849,
      "learning_rate": 0.0004959070644757048,
      "loss": 0.8964,
      "step": 143550
    },
    {
      "epoch": 1.5202068589516253,
      "grad_norm": 0.9269651174545288,
      "learning_rate": 0.0004958987359915395,
      "loss": 0.9197,
      "step": 143600
    },
    {
      "epoch": 1.5207361807316286,
      "grad_norm": 0.9126190543174744,
      "learning_rate": 0.0004958903991124815,
      "loss": 0.913,
      "step": 143650
    },
    {
      "epoch": 1.521265502511632,
      "grad_norm": 0.7667455077171326,
      "learning_rate": 0.0004958820538388155,
      "loss": 0.9239,
      "step": 143700
    },
    {
      "epoch": 1.5217948242916353,
      "grad_norm": 0.9012948870658875,
      "learning_rate": 0.0004958737001708262,
      "loss": 0.9199,
      "step": 143750
    },
    {
      "epoch": 1.5223241460716386,
      "grad_norm": 0.9067404270172119,
      "learning_rate": 0.000495865338108799,
      "loss": 0.9344,
      "step": 143800
    },
    {
      "epoch": 1.5228534678516417,
      "grad_norm": 0.8871791362762451,
      "learning_rate": 0.0004958569676530195,
      "loss": 0.9241,
      "step": 143850
    },
    {
      "epoch": 1.523382789631645,
      "grad_norm": 0.8753677010536194,
      "learning_rate": 0.0004958485888037731,
      "loss": 0.9185,
      "step": 143900
    },
    {
      "epoch": 1.5239121114116483,
      "grad_norm": 0.968727171421051,
      "learning_rate": 0.0004958402015613462,
      "loss": 0.9539,
      "step": 143950
    },
    {
      "epoch": 1.5244414331916514,
      "grad_norm": 0.8238311409950256,
      "learning_rate": 0.0004958318059260249,
      "loss": 0.9043,
      "step": 144000
    },
    {
      "epoch": 1.5244414331916514,
      "eval_loss": 0.7675252556800842,
      "eval_runtime": 46.757,
      "eval_samples_per_second": 3591.55,
      "eval_steps_per_second": 448.96,
      "step": 144000
    },
    {
      "epoch": 1.5249707549716547,
      "grad_norm": 0.906124472618103,
      "learning_rate": 0.0004958234018980958,
      "loss": 0.9011,
      "step": 144050
    },
    {
      "epoch": 1.525500076751658,
      "grad_norm": 0.9093517661094666,
      "learning_rate": 0.000495814989477846,
      "loss": 0.914,
      "step": 144100
    },
    {
      "epoch": 1.5260293985316613,
      "grad_norm": 0.9060434103012085,
      "learning_rate": 0.0004958065686655627,
      "loss": 0.9175,
      "step": 144150
    },
    {
      "epoch": 1.5265587203116646,
      "grad_norm": 0.8350555300712585,
      "learning_rate": 0.0004957981394615332,
      "loss": 0.929,
      "step": 144200
    },
    {
      "epoch": 1.527088042091668,
      "grad_norm": 0.8606418371200562,
      "learning_rate": 0.0004957897018660454,
      "loss": 0.9092,
      "step": 144250
    },
    {
      "epoch": 1.5276173638716712,
      "grad_norm": 0.9037478566169739,
      "learning_rate": 0.0004957812558793872,
      "loss": 0.9294,
      "step": 144300
    },
    {
      "epoch": 1.5281466856516746,
      "grad_norm": 0.8254870772361755,
      "learning_rate": 0.0004957728015018472,
      "loss": 0.919,
      "step": 144350
    },
    {
      "epoch": 1.5286760074316779,
      "grad_norm": 0.8214415907859802,
      "learning_rate": 0.0004957643387337138,
      "loss": 0.9064,
      "step": 144400
    },
    {
      "epoch": 1.5292053292116812,
      "grad_norm": 0.8113574385643005,
      "learning_rate": 0.000495755867575276,
      "loss": 0.9253,
      "step": 144450
    },
    {
      "epoch": 1.5297346509916845,
      "grad_norm": 1.0061308145523071,
      "learning_rate": 0.0004957473880268231,
      "loss": 0.927,
      "step": 144500
    },
    {
      "epoch": 1.5297346509916845,
      "eval_loss": 0.7691563963890076,
      "eval_runtime": 46.7922,
      "eval_samples_per_second": 3588.843,
      "eval_steps_per_second": 448.621,
      "step": 144500
    },
    {
      "epoch": 1.5302639727716878,
      "grad_norm": 0.83791184425354,
      "learning_rate": 0.0004957389000886444,
      "loss": 0.9167,
      "step": 144550
    },
    {
      "epoch": 1.5307932945516909,
      "grad_norm": 0.8969817161560059,
      "learning_rate": 0.0004957304037610298,
      "loss": 0.9169,
      "step": 144600
    },
    {
      "epoch": 1.5313226163316942,
      "grad_norm": 0.9227214455604553,
      "learning_rate": 0.0004957218990442694,
      "loss": 0.9336,
      "step": 144650
    },
    {
      "epoch": 1.5318519381116975,
      "grad_norm": 0.8684019446372986,
      "learning_rate": 0.0004957133859386535,
      "loss": 0.9304,
      "step": 144700
    },
    {
      "epoch": 1.5323812598917006,
      "grad_norm": 0.8593600988388062,
      "learning_rate": 0.0004957048644444726,
      "loss": 0.926,
      "step": 144750
    },
    {
      "epoch": 1.532910581671704,
      "grad_norm": 0.9065805077552795,
      "learning_rate": 0.0004956963345620179,
      "loss": 0.9126,
      "step": 144800
    },
    {
      "epoch": 1.5334399034517072,
      "grad_norm": 0.852847695350647,
      "learning_rate": 0.0004956877962915803,
      "loss": 0.9187,
      "step": 144850
    },
    {
      "epoch": 1.5339692252317105,
      "grad_norm": 0.8032529354095459,
      "learning_rate": 0.0004956792496334515,
      "loss": 0.9174,
      "step": 144900
    },
    {
      "epoch": 1.5344985470117138,
      "grad_norm": 0.7984119057655334,
      "learning_rate": 0.0004956706945879232,
      "loss": 0.9176,
      "step": 144950
    },
    {
      "epoch": 1.5350278687917172,
      "grad_norm": 0.8697257041931152,
      "learning_rate": 0.0004956621311552875,
      "loss": 0.9183,
      "step": 145000
    },
    {
      "epoch": 1.5350278687917172,
      "eval_loss": 0.7626925706863403,
      "eval_runtime": 46.7588,
      "eval_samples_per_second": 3591.407,
      "eval_steps_per_second": 448.942,
      "step": 145000
    },
    {
      "epoch": 1.5355571905717205,
      "grad_norm": 0.9137267470359802,
      "learning_rate": 0.0004956535593358366,
      "loss": 0.9097,
      "step": 145050
    },
    {
      "epoch": 1.5360865123517238,
      "grad_norm": 0.8858558535575867,
      "learning_rate": 0.0004956449791298635,
      "loss": 0.9376,
      "step": 145100
    },
    {
      "epoch": 1.536615834131727,
      "grad_norm": 0.8237768411636353,
      "learning_rate": 0.0004956363905376607,
      "loss": 0.9197,
      "step": 145150
    },
    {
      "epoch": 1.5371451559117304,
      "grad_norm": 0.869705855846405,
      "learning_rate": 0.0004956279655812648,
      "loss": 0.929,
      "step": 145200
    },
    {
      "epoch": 1.5376744776917337,
      "grad_norm": 0.8090142607688904,
      "learning_rate": 0.000495619360385193,
      "loss": 0.925,
      "step": 145250
    },
    {
      "epoch": 1.538203799471737,
      "grad_norm": 0.8580687642097473,
      "learning_rate": 0.0004956107468037663,
      "loss": 0.9159,
      "step": 145300
    },
    {
      "epoch": 1.53873312125174,
      "grad_norm": 0.8565168380737305,
      "learning_rate": 0.0004956021248372788,
      "loss": 0.9086,
      "step": 145350
    },
    {
      "epoch": 1.5392624430317434,
      "grad_norm": 1.0057787895202637,
      "learning_rate": 0.0004955934944860248,
      "loss": 0.9084,
      "step": 145400
    },
    {
      "epoch": 1.5397917648117467,
      "grad_norm": 0.9329745173454285,
      "learning_rate": 0.0004955848557502989,
      "loss": 0.9044,
      "step": 145450
    },
    {
      "epoch": 1.54032108659175,
      "grad_norm": 0.9033946990966797,
      "learning_rate": 0.0004955762086303963,
      "loss": 0.9281,
      "step": 145500
    },
    {
      "epoch": 1.54032108659175,
      "eval_loss": 0.7621561288833618,
      "eval_runtime": 46.794,
      "eval_samples_per_second": 3588.711,
      "eval_steps_per_second": 448.605,
      "step": 145500
    },
    {
      "epoch": 1.5408504083717531,
      "grad_norm": 0.7582818865776062,
      "learning_rate": 0.0004955675531266118,
      "loss": 0.9233,
      "step": 145550
    },
    {
      "epoch": 1.5413797301517564,
      "grad_norm": 0.9182335138320923,
      "learning_rate": 0.0004955588892392413,
      "loss": 0.9144,
      "step": 145600
    },
    {
      "epoch": 1.5419090519317598,
      "grad_norm": 0.8744200468063354,
      "learning_rate": 0.0004955502169685801,
      "loss": 0.9059,
      "step": 145650
    },
    {
      "epoch": 1.542438373711763,
      "grad_norm": 0.8963993787765503,
      "learning_rate": 0.0004955415363149248,
      "loss": 0.9264,
      "step": 145700
    },
    {
      "epoch": 1.5429676954917664,
      "grad_norm": 0.8835583925247192,
      "learning_rate": 0.0004955328472785714,
      "loss": 0.9113,
      "step": 145750
    },
    {
      "epoch": 1.5434970172717697,
      "grad_norm": 0.9366907477378845,
      "learning_rate": 0.0004955241498598166,
      "loss": 0.922,
      "step": 145800
    },
    {
      "epoch": 1.544026339051773,
      "grad_norm": 0.9043514728546143,
      "learning_rate": 0.0004955154440589574,
      "loss": 0.9095,
      "step": 145850
    },
    {
      "epoch": 1.5445556608317763,
      "grad_norm": 0.9272380471229553,
      "learning_rate": 0.000495506729876291,
      "loss": 0.9112,
      "step": 145900
    },
    {
      "epoch": 1.5450849826117796,
      "grad_norm": 0.8336758613586426,
      "learning_rate": 0.0004954980073121148,
      "loss": 0.9227,
      "step": 145950
    },
    {
      "epoch": 1.545614304391783,
      "grad_norm": 0.7794897556304932,
      "learning_rate": 0.0004954892763667268,
      "loss": 0.9198,
      "step": 146000
    },
    {
      "epoch": 1.545614304391783,
      "eval_loss": 0.7582632303237915,
      "eval_runtime": 46.8047,
      "eval_samples_per_second": 3587.89,
      "eval_steps_per_second": 448.502,
      "step": 146000
    },
    {
      "epoch": 1.5461436261717862,
      "grad_norm": 0.8779584169387817,
      "learning_rate": 0.0004954805370404248,
      "loss": 0.8919,
      "step": 146050
    },
    {
      "epoch": 1.5466729479517893,
      "grad_norm": 0.7928263545036316,
      "learning_rate": 0.0004954717893335073,
      "loss": 0.9054,
      "step": 146100
    },
    {
      "epoch": 1.5472022697317926,
      "grad_norm": 0.8870363831520081,
      "learning_rate": 0.000495463033246273,
      "loss": 0.9163,
      "step": 146150
    },
    {
      "epoch": 1.547731591511796,
      "grad_norm": 0.835584282875061,
      "learning_rate": 0.0004954542687790208,
      "loss": 0.9117,
      "step": 146200
    },
    {
      "epoch": 1.5482609132917993,
      "grad_norm": 0.8854529857635498,
      "learning_rate": 0.0004954454959320499,
      "loss": 0.9192,
      "step": 146250
    },
    {
      "epoch": 1.5487902350718024,
      "grad_norm": 0.9152503609657288,
      "learning_rate": 0.0004954367147056597,
      "loss": 0.9127,
      "step": 146300
    },
    {
      "epoch": 1.5493195568518057,
      "grad_norm": 0.7396624088287354,
      "learning_rate": 0.0004954279251001501,
      "loss": 0.9228,
      "step": 146350
    },
    {
      "epoch": 1.549848878631809,
      "grad_norm": 0.9171761274337769,
      "learning_rate": 0.0004954191271158211,
      "loss": 0.9201,
      "step": 146400
    },
    {
      "epoch": 1.5503782004118123,
      "grad_norm": 0.842051088809967,
      "learning_rate": 0.0004954103207529732,
      "loss": 0.9111,
      "step": 146450
    },
    {
      "epoch": 1.5509075221918156,
      "grad_norm": 0.9269602298736572,
      "learning_rate": 0.0004954015060119069,
      "loss": 0.8981,
      "step": 146500
    },
    {
      "epoch": 1.5509075221918156,
      "eval_loss": 0.758672297000885,
      "eval_runtime": 46.7609,
      "eval_samples_per_second": 3591.251,
      "eval_steps_per_second": 448.922,
      "step": 146500
    },
    {
      "epoch": 1.551436843971819,
      "grad_norm": 0.9069274663925171,
      "learning_rate": 0.0004953926828929232,
      "loss": 0.9079,
      "step": 146550
    },
    {
      "epoch": 1.5519661657518222,
      "grad_norm": 0.8830956816673279,
      "learning_rate": 0.0004953838513963233,
      "loss": 0.8964,
      "step": 146600
    },
    {
      "epoch": 1.5524954875318255,
      "grad_norm": 0.8842385411262512,
      "learning_rate": 0.0004953750115224086,
      "loss": 0.9231,
      "step": 146650
    },
    {
      "epoch": 1.5530248093118288,
      "grad_norm": 0.886121928691864,
      "learning_rate": 0.0004953661632714811,
      "loss": 0.9041,
      "step": 146700
    },
    {
      "epoch": 1.5535541310918322,
      "grad_norm": 0.9589534997940063,
      "learning_rate": 0.0004953573066438427,
      "loss": 0.9106,
      "step": 146750
    },
    {
      "epoch": 1.5540834528718355,
      "grad_norm": 0.84083092212677,
      "learning_rate": 0.000495348441639796,
      "loss": 0.9157,
      "step": 146800
    },
    {
      "epoch": 1.5546127746518386,
      "grad_norm": 0.8449596762657166,
      "learning_rate": 0.0004953395682596432,
      "loss": 0.9158,
      "step": 146850
    },
    {
      "epoch": 1.5551420964318419,
      "grad_norm": 0.8303372859954834,
      "learning_rate": 0.0004953306865036878,
      "loss": 0.9127,
      "step": 146900
    },
    {
      "epoch": 1.5556714182118452,
      "grad_norm": 0.8959460854530334,
      "learning_rate": 0.0004953217963722325,
      "loss": 0.912,
      "step": 146950
    },
    {
      "epoch": 1.5562007399918485,
      "grad_norm": 0.8521134853363037,
      "learning_rate": 0.0004953128978655812,
      "loss": 0.9364,
      "step": 147000
    },
    {
      "epoch": 1.5562007399918485,
      "eval_loss": 0.7579036355018616,
      "eval_runtime": 46.7994,
      "eval_samples_per_second": 3588.297,
      "eval_steps_per_second": 448.553,
      "step": 147000
    },
    {
      "epoch": 1.5567300617718516,
      "grad_norm": 0.8974913954734802,
      "learning_rate": 0.0004953039909840374,
      "loss": 0.8992,
      "step": 147050
    },
    {
      "epoch": 1.557259383551855,
      "grad_norm": 0.883522629737854,
      "learning_rate": 0.0004952950757279056,
      "loss": 0.9264,
      "step": 147100
    },
    {
      "epoch": 1.5577887053318582,
      "grad_norm": 0.8580906987190247,
      "learning_rate": 0.0004952861520974896,
      "loss": 0.9126,
      "step": 147150
    },
    {
      "epoch": 1.5583180271118615,
      "grad_norm": 0.9165557026863098,
      "learning_rate": 0.0004952773988152453,
      "loss": 0.9258,
      "step": 147200
    },
    {
      "epoch": 1.5588473488918648,
      "grad_norm": 0.8666826486587524,
      "learning_rate": 0.0004952684586046462,
      "loss": 0.9179,
      "step": 147250
    },
    {
      "epoch": 1.5593766706718681,
      "grad_norm": 0.8812898993492126,
      "learning_rate": 0.000495259510020672,
      "loss": 0.889,
      "step": 147300
    },
    {
      "epoch": 1.5599059924518714,
      "grad_norm": 0.7986096143722534,
      "learning_rate": 0.000495250553063628,
      "loss": 0.9061,
      "step": 147350
    },
    {
      "epoch": 1.5604353142318748,
      "grad_norm": 0.8911749720573425,
      "learning_rate": 0.00049524158773382,
      "loss": 0.9013,
      "step": 147400
    },
    {
      "epoch": 1.560964636011878,
      "grad_norm": 0.8843409419059753,
      "learning_rate": 0.0004952326140315543,
      "loss": 0.8878,
      "step": 147450
    },
    {
      "epoch": 1.5614939577918814,
      "grad_norm": 0.9033204317092896,
      "learning_rate": 0.0004952236319571369,
      "loss": 0.9141,
      "step": 147500
    },
    {
      "epoch": 1.5614939577918814,
      "eval_loss": 0.7568702101707458,
      "eval_runtime": 46.7499,
      "eval_samples_per_second": 3592.093,
      "eval_steps_per_second": 449.028,
      "step": 147500
    },
    {
      "epoch": 1.5620232795718847,
      "grad_norm": 0.9809408783912659,
      "learning_rate": 0.0004952146415108747,
      "loss": 0.911,
      "step": 147550
    },
    {
      "epoch": 1.5625526013518878,
      "grad_norm": 0.9235997796058655,
      "learning_rate": 0.0004952058227514698,
      "loss": 0.9116,
      "step": 147600
    },
    {
      "epoch": 1.563081923131891,
      "grad_norm": 0.8314932584762573,
      "learning_rate": 0.0004951968157298606,
      "loss": 0.9102,
      "step": 147650
    },
    {
      "epoch": 1.5636112449118944,
      "grad_norm": 0.9059358239173889,
      "learning_rate": 0.0004951878003373219,
      "loss": 0.9083,
      "step": 147700
    },
    {
      "epoch": 1.5641405666918977,
      "grad_norm": 0.958577036857605,
      "learning_rate": 0.0004951787765741617,
      "loss": 0.9153,
      "step": 147750
    },
    {
      "epoch": 1.5646698884719008,
      "grad_norm": 0.994182825088501,
      "learning_rate": 0.0004951697444406881,
      "loss": 0.9172,
      "step": 147800
    },
    {
      "epoch": 1.5651992102519041,
      "grad_norm": 0.9215150475502014,
      "learning_rate": 0.0004951607039372092,
      "loss": 0.9137,
      "step": 147850
    },
    {
      "epoch": 1.5657285320319074,
      "grad_norm": 0.8418970704078674,
      "learning_rate": 0.0004951516550640339,
      "loss": 0.9042,
      "step": 147900
    },
    {
      "epoch": 1.5662578538119107,
      "grad_norm": 0.792090892791748,
      "learning_rate": 0.0004951425978214709,
      "loss": 0.9259,
      "step": 147950
    },
    {
      "epoch": 1.566787175591914,
      "grad_norm": 0.8933773636817932,
      "learning_rate": 0.0004951335322098296,
      "loss": 0.8991,
      "step": 148000
    },
    {
      "epoch": 1.566787175591914,
      "eval_loss": 0.7584206461906433,
      "eval_runtime": 46.8406,
      "eval_samples_per_second": 3585.137,
      "eval_steps_per_second": 448.158,
      "step": 148000
    },
    {
      "epoch": 1.5673164973719174,
      "grad_norm": 0.8336026668548584,
      "learning_rate": 0.0004951244582294194,
      "loss": 0.9085,
      "step": 148050
    },
    {
      "epoch": 1.5678458191519207,
      "grad_norm": 0.874289333820343,
      "learning_rate": 0.00049511537588055,
      "loss": 0.9255,
      "step": 148100
    },
    {
      "epoch": 1.568375140931924,
      "grad_norm": 0.9154319763183594,
      "learning_rate": 0.0004951062851635316,
      "loss": 0.9169,
      "step": 148150
    },
    {
      "epoch": 1.5689044627119273,
      "grad_norm": 0.8604795932769775,
      "learning_rate": 0.0004950971860786745,
      "loss": 0.9025,
      "step": 148200
    },
    {
      "epoch": 1.5694337844919306,
      "grad_norm": 0.9447089433670044,
      "learning_rate": 0.0004950880786262895,
      "loss": 0.9094,
      "step": 148250
    },
    {
      "epoch": 1.569963106271934,
      "grad_norm": 0.8590853214263916,
      "learning_rate": 0.0004950789628066872,
      "loss": 0.9188,
      "step": 148300
    },
    {
      "epoch": 1.570492428051937,
      "grad_norm": 0.8902451395988464,
      "learning_rate": 0.000495069838620179,
      "loss": 0.9168,
      "step": 148350
    },
    {
      "epoch": 1.5710217498319403,
      "grad_norm": 0.8721399307250977,
      "learning_rate": 0.0004950607060670765,
      "loss": 0.9279,
      "step": 148400
    },
    {
      "epoch": 1.5715510716119436,
      "grad_norm": 0.885915219783783,
      "learning_rate": 0.0004950515651476913,
      "loss": 0.9196,
      "step": 148450
    },
    {
      "epoch": 1.572080393391947,
      "grad_norm": 0.915818452835083,
      "learning_rate": 0.0004950424158623356,
      "loss": 0.8988,
      "step": 148500
    },
    {
      "epoch": 1.572080393391947,
      "eval_loss": 0.7520014643669128,
      "eval_runtime": 46.8406,
      "eval_samples_per_second": 3585.141,
      "eval_steps_per_second": 448.159,
      "step": 148500
    },
    {
      "epoch": 1.57260971517195,
      "grad_norm": 0.8432757258415222,
      "learning_rate": 0.0004950332582113215,
      "loss": 0.9212,
      "step": 148550
    },
    {
      "epoch": 1.5731390369519533,
      "grad_norm": 0.9563475847244263,
      "learning_rate": 0.000495024092194962,
      "loss": 0.9129,
      "step": 148600
    },
    {
      "epoch": 1.5736683587319567,
      "grad_norm": 0.9143876433372498,
      "learning_rate": 0.0004950149178135698,
      "loss": 0.9045,
      "step": 148650
    },
    {
      "epoch": 1.57419768051196,
      "grad_norm": 0.9461647868156433,
      "learning_rate": 0.0004950057350674583,
      "loss": 0.921,
      "step": 148700
    },
    {
      "epoch": 1.5747270022919633,
      "grad_norm": 0.8936066031455994,
      "learning_rate": 0.0004949965439569406,
      "loss": 0.9193,
      "step": 148750
    },
    {
      "epoch": 1.5752563240719666,
      "grad_norm": 0.7546511292457581,
      "learning_rate": 0.0004949873444823309,
      "loss": 0.912,
      "step": 148800
    },
    {
      "epoch": 1.57578564585197,
      "grad_norm": 0.851249098777771,
      "learning_rate": 0.0004949781366439431,
      "loss": 0.9074,
      "step": 148850
    },
    {
      "epoch": 1.5763149676319732,
      "grad_norm": 0.8457630276679993,
      "learning_rate": 0.0004949689204420915,
      "loss": 0.9057,
      "step": 148900
    },
    {
      "epoch": 1.5768442894119765,
      "grad_norm": 0.9251179099082947,
      "learning_rate": 0.0004949596958770909,
      "loss": 0.8909,
      "step": 148950
    },
    {
      "epoch": 1.5773736111919798,
      "grad_norm": 0.8806889653205872,
      "learning_rate": 0.000494950462949256,
      "loss": 0.906,
      "step": 149000
    },
    {
      "epoch": 1.5773736111919798,
      "eval_loss": 0.7559914588928223,
      "eval_runtime": 46.7639,
      "eval_samples_per_second": 3591.017,
      "eval_steps_per_second": 448.893,
      "step": 149000
    },
    {
      "epoch": 1.5779029329719831,
      "grad_norm": 0.8929829597473145,
      "learning_rate": 0.0004949412216589022,
      "loss": 0.8999,
      "step": 149050
    },
    {
      "epoch": 1.5784322547519862,
      "grad_norm": 0.8692018389701843,
      "learning_rate": 0.0004949319720063449,
      "loss": 0.9178,
      "step": 149100
    },
    {
      "epoch": 1.5789615765319895,
      "grad_norm": 0.8455721139907837,
      "learning_rate": 0.0004949227139919,
      "loss": 0.9014,
      "step": 149150
    },
    {
      "epoch": 1.5794908983119929,
      "grad_norm": 0.8534737825393677,
      "learning_rate": 0.0004949134476158833,
      "loss": 0.9135,
      "step": 149200
    },
    {
      "epoch": 1.5800202200919962,
      "grad_norm": 0.8981738090515137,
      "learning_rate": 0.0004949041728786114,
      "loss": 0.913,
      "step": 149250
    },
    {
      "epoch": 1.5805495418719993,
      "grad_norm": 0.813310444355011,
      "learning_rate": 0.0004948948897804008,
      "loss": 0.9025,
      "step": 149300
    },
    {
      "epoch": 1.5810788636520026,
      "grad_norm": 0.9219993352890015,
      "learning_rate": 0.0004948855983215685,
      "loss": 0.9065,
      "step": 149350
    },
    {
      "epoch": 1.5816081854320059,
      "grad_norm": 0.9231289029121399,
      "learning_rate": 0.0004948762985024318,
      "loss": 0.9046,
      "step": 149400
    },
    {
      "epoch": 1.5821375072120092,
      "grad_norm": 0.8712746500968933,
      "learning_rate": 0.000494866990323308,
      "loss": 0.9217,
      "step": 149450
    },
    {
      "epoch": 1.5826668289920125,
      "grad_norm": 0.871367335319519,
      "learning_rate": 0.0004948576737845149,
      "loss": 0.8967,
      "step": 149500
    },
    {
      "epoch": 1.5826668289920125,
      "eval_loss": 0.7482390999794006,
      "eval_runtime": 46.7732,
      "eval_samples_per_second": 3590.306,
      "eval_steps_per_second": 448.804,
      "step": 149500
    },
    {
      "epoch": 1.5831961507720158,
      "grad_norm": 0.9340376853942871,
      "learning_rate": 0.0004948483488863706,
      "loss": 0.8994,
      "step": 149550
    },
    {
      "epoch": 1.5837254725520191,
      "grad_norm": 0.8876127600669861,
      "learning_rate": 0.0004948390156291935,
      "loss": 0.9087,
      "step": 149600
    },
    {
      "epoch": 1.5842547943320224,
      "grad_norm": 0.9458996057510376,
      "learning_rate": 0.0004948296740133022,
      "loss": 0.9043,
      "step": 149650
    },
    {
      "epoch": 1.5847841161120257,
      "grad_norm": 0.7959750294685364,
      "learning_rate": 0.0004948203240390157,
      "loss": 0.91,
      "step": 149700
    },
    {
      "epoch": 1.585313437892029,
      "grad_norm": 0.8518323302268982,
      "learning_rate": 0.0004948109657066529,
      "loss": 0.8989,
      "step": 149750
    },
    {
      "epoch": 1.5858427596720324,
      "grad_norm": 0.8448508381843567,
      "learning_rate": 0.0004948015990165338,
      "loss": 0.9161,
      "step": 149800
    },
    {
      "epoch": 1.5863720814520355,
      "grad_norm": 0.8805105090141296,
      "learning_rate": 0.0004947922239689777,
      "loss": 0.9159,
      "step": 149850
    },
    {
      "epoch": 1.5869014032320388,
      "grad_norm": 0.9039450883865356,
      "learning_rate": 0.0004947828405643049,
      "loss": 0.9175,
      "step": 149900
    },
    {
      "epoch": 1.587430725012042,
      "grad_norm": 0.8694248795509338,
      "learning_rate": 0.0004947734488028357,
      "loss": 0.9017,
      "step": 149950
    },
    {
      "epoch": 1.5879600467920454,
      "grad_norm": 0.9566618204116821,
      "learning_rate": 0.0004947640486848907,
      "loss": 0.9175,
      "step": 150000
    },
    {
      "epoch": 1.5879600467920454,
      "eval_loss": 0.7478898167610168,
      "eval_runtime": 46.775,
      "eval_samples_per_second": 3590.166,
      "eval_steps_per_second": 448.787,
      "step": 150000
    },
    {
      "epoch": 1.5884893685720485,
      "grad_norm": 0.9155949354171753,
      "learning_rate": 0.0004947546402107909,
      "loss": 0.8987,
      "step": 150050
    },
    {
      "epoch": 1.5890186903520518,
      "grad_norm": 0.9202787280082703,
      "learning_rate": 0.0004947452233808573,
      "loss": 0.911,
      "step": 150100
    },
    {
      "epoch": 1.589548012132055,
      "grad_norm": 0.8751621842384338,
      "learning_rate": 0.0004947357981954117,
      "loss": 0.904,
      "step": 150150
    },
    {
      "epoch": 1.5900773339120584,
      "grad_norm": 0.8641214370727539,
      "learning_rate": 0.0004947263646547757,
      "loss": 0.9091,
      "step": 150200
    },
    {
      "epoch": 1.5906066556920617,
      "grad_norm": 0.8276512026786804,
      "learning_rate": 0.0004947169227592713,
      "loss": 0.8926,
      "step": 150250
    },
    {
      "epoch": 1.591135977472065,
      "grad_norm": 0.8690083026885986,
      "learning_rate": 0.0004947074725092209,
      "loss": 0.8978,
      "step": 150300
    },
    {
      "epoch": 1.5916652992520683,
      "grad_norm": 0.8981937170028687,
      "learning_rate": 0.0004946980139049471,
      "loss": 0.9013,
      "step": 150350
    },
    {
      "epoch": 1.5921946210320717,
      "grad_norm": 0.8545955419540405,
      "learning_rate": 0.0004946885469467729,
      "loss": 0.9046,
      "step": 150400
    },
    {
      "epoch": 1.592723942812075,
      "grad_norm": 0.8712809681892395,
      "learning_rate": 0.0004946790716350214,
      "loss": 0.9029,
      "step": 150450
    },
    {
      "epoch": 1.5932532645920783,
      "grad_norm": 0.894144594669342,
      "learning_rate": 0.0004946695879700162,
      "loss": 0.9164,
      "step": 150500
    },
    {
      "epoch": 1.5932532645920783,
      "eval_loss": 0.7457922101020813,
      "eval_runtime": 46.8215,
      "eval_samples_per_second": 3586.598,
      "eval_steps_per_second": 448.341,
      "step": 150500
    },
    {
      "epoch": 1.5937825863720816,
      "grad_norm": 0.8909485936164856,
      "learning_rate": 0.000494660095952081,
      "loss": 0.9074,
      "step": 150550
    },
    {
      "epoch": 1.594311908152085,
      "grad_norm": 0.9369853734970093,
      "learning_rate": 0.0004946505955815397,
      "loss": 0.9151,
      "step": 150600
    },
    {
      "epoch": 1.594841229932088,
      "grad_norm": 0.8753412365913391,
      "learning_rate": 0.0004946410868587169,
      "loss": 0.8996,
      "step": 150650
    },
    {
      "epoch": 1.5953705517120913,
      "grad_norm": 0.9396008849143982,
      "learning_rate": 0.0004946315697839371,
      "loss": 0.9009,
      "step": 150700
    },
    {
      "epoch": 1.5958998734920946,
      "grad_norm": 0.8567162752151489,
      "learning_rate": 0.0004946220443575253,
      "loss": 0.9036,
      "step": 150750
    },
    {
      "epoch": 1.5964291952720977,
      "grad_norm": 0.7603954076766968,
      "learning_rate": 0.0004946125105798065,
      "loss": 0.9092,
      "step": 150800
    },
    {
      "epoch": 1.596958517052101,
      "grad_norm": 0.909417986869812,
      "learning_rate": 0.0004946029684511064,
      "loss": 0.9041,
      "step": 150850
    },
    {
      "epoch": 1.5974878388321043,
      "grad_norm": 0.8389068245887756,
      "learning_rate": 0.0004945934179717506,
      "loss": 0.8882,
      "step": 150900
    },
    {
      "epoch": 1.5980171606121076,
      "grad_norm": 0.9132410287857056,
      "learning_rate": 0.0004945838591420653,
      "loss": 0.8886,
      "step": 150950
    },
    {
      "epoch": 1.598546482392111,
      "grad_norm": 0.8374978303909302,
      "learning_rate": 0.0004945742919623766,
      "loss": 0.8917,
      "step": 151000
    },
    {
      "epoch": 1.598546482392111,
      "eval_loss": 0.746726393699646,
      "eval_runtime": 46.8927,
      "eval_samples_per_second": 3581.154,
      "eval_steps_per_second": 447.66,
      "step": 151000
    },
    {
      "epoch": 1.5990758041721143,
      "grad_norm": 0.8066322207450867,
      "learning_rate": 0.0004945647164330113,
      "loss": 0.8839,
      "step": 151050
    },
    {
      "epoch": 1.5996051259521176,
      "grad_norm": 0.8853625655174255,
      "learning_rate": 0.0004945551325542964,
      "loss": 0.9111,
      "step": 151100
    },
    {
      "epoch": 1.6001344477321209,
      "grad_norm": 0.8301093578338623,
      "learning_rate": 0.0004945455403265589,
      "loss": 0.9119,
      "step": 151150
    },
    {
      "epoch": 1.6006637695121242,
      "grad_norm": 0.8422414660453796,
      "learning_rate": 0.0004945359397501262,
      "loss": 0.9078,
      "step": 151200
    },
    {
      "epoch": 1.6011930912921275,
      "grad_norm": 0.9955244660377502,
      "learning_rate": 0.0004945263308253263,
      "loss": 0.9029,
      "step": 151250
    },
    {
      "epoch": 1.6017224130721308,
      "grad_norm": 0.914527952671051,
      "learning_rate": 0.0004945167135524871,
      "loss": 0.8947,
      "step": 151300
    },
    {
      "epoch": 1.6022517348521341,
      "grad_norm": 0.9006553292274475,
      "learning_rate": 0.0004945070879319371,
      "loss": 0.894,
      "step": 151350
    },
    {
      "epoch": 1.6027810566321372,
      "grad_norm": 0.7878187298774719,
      "learning_rate": 0.0004944974539640047,
      "loss": 0.9175,
      "step": 151400
    },
    {
      "epoch": 1.6033103784121405,
      "grad_norm": 0.8490282893180847,
      "learning_rate": 0.0004944878116490189,
      "loss": 0.9027,
      "step": 151450
    },
    {
      "epoch": 1.6038397001921438,
      "grad_norm": 0.8648599982261658,
      "learning_rate": 0.0004944781609873089,
      "loss": 0.9122,
      "step": 151500
    },
    {
      "epoch": 1.6038397001921438,
      "eval_loss": 0.7477997541427612,
      "eval_runtime": 46.7311,
      "eval_samples_per_second": 3593.54,
      "eval_steps_per_second": 449.209,
      "step": 151500
    },
    {
      "epoch": 1.604369021972147,
      "grad_norm": 0.82118159532547,
      "learning_rate": 0.0004944685019792042,
      "loss": 0.8989,
      "step": 151550
    },
    {
      "epoch": 1.6048983437521502,
      "grad_norm": 0.8610228896141052,
      "learning_rate": 0.0004944590280539071,
      "loss": 0.8823,
      "step": 151600
    },
    {
      "epoch": 1.6054276655321535,
      "grad_norm": 0.8462211489677429,
      "learning_rate": 0.0004944493525209138,
      "loss": 0.8889,
      "step": 151650
    },
    {
      "epoch": 1.6059569873121569,
      "grad_norm": 0.8754566311836243,
      "learning_rate": 0.0004944396686425093,
      "loss": 0.9131,
      "step": 151700
    },
    {
      "epoch": 1.6064863090921602,
      "grad_norm": 0.8870270848274231,
      "learning_rate": 0.0004944299764190241,
      "loss": 0.8904,
      "step": 151750
    },
    {
      "epoch": 1.6070156308721635,
      "grad_norm": 0.8211067318916321,
      "learning_rate": 0.0004944202758507892,
      "loss": 0.908,
      "step": 151800
    },
    {
      "epoch": 1.6075449526521668,
      "grad_norm": 0.9621334671974182,
      "learning_rate": 0.0004944105669381357,
      "loss": 0.9161,
      "step": 151850
    },
    {
      "epoch": 1.60807427443217,
      "grad_norm": 0.8894376158714294,
      "learning_rate": 0.000494400849681395,
      "loss": 0.9095,
      "step": 151900
    },
    {
      "epoch": 1.6086035962121734,
      "grad_norm": 0.8177424073219299,
      "learning_rate": 0.000494391124080899,
      "loss": 0.9165,
      "step": 151950
    },
    {
      "epoch": 1.6091329179921767,
      "grad_norm": 0.8379103541374207,
      "learning_rate": 0.0004943813901369797,
      "loss": 0.9185,
      "step": 152000
    },
    {
      "epoch": 1.6091329179921767,
      "eval_loss": 0.7435271143913269,
      "eval_runtime": 46.7583,
      "eval_samples_per_second": 3591.446,
      "eval_steps_per_second": 448.947,
      "step": 152000
    },
    {
      "epoch": 1.60966223977218,
      "grad_norm": 0.8455438017845154,
      "learning_rate": 0.0004943716478499694,
      "loss": 0.9047,
      "step": 152050
    },
    {
      "epoch": 1.6101915615521833,
      "grad_norm": 0.944543719291687,
      "learning_rate": 0.0004943618972202005,
      "loss": 0.9192,
      "step": 152100
    },
    {
      "epoch": 1.6107208833321864,
      "grad_norm": 0.8706507682800293,
      "learning_rate": 0.0004943521382480061,
      "loss": 0.8946,
      "step": 152150
    },
    {
      "epoch": 1.6112502051121897,
      "grad_norm": 0.9577684998512268,
      "learning_rate": 0.0004943423709337193,
      "loss": 0.9123,
      "step": 152200
    },
    {
      "epoch": 1.611779526892193,
      "grad_norm": 1.0092809200286865,
      "learning_rate": 0.0004943325952776737,
      "loss": 0.938,
      "step": 152250
    },
    {
      "epoch": 1.6123088486721961,
      "grad_norm": 0.8849959373474121,
      "learning_rate": 0.0004943228112802028,
      "loss": 0.9176,
      "step": 152300
    },
    {
      "epoch": 1.6128381704521995,
      "grad_norm": 0.9626144766807556,
      "learning_rate": 0.0004943130189416407,
      "loss": 0.9161,
      "step": 152350
    },
    {
      "epoch": 1.6133674922322028,
      "grad_norm": 0.8141531944274902,
      "learning_rate": 0.0004943032182623218,
      "loss": 0.9062,
      "step": 152400
    },
    {
      "epoch": 1.613896814012206,
      "grad_norm": 0.7808447480201721,
      "learning_rate": 0.0004942934092425806,
      "loss": 0.9031,
      "step": 152450
    },
    {
      "epoch": 1.6144261357922094,
      "grad_norm": 0.875543475151062,
      "learning_rate": 0.000494283591882752,
      "loss": 0.9008,
      "step": 152500
    },
    {
      "epoch": 1.6144261357922094,
      "eval_loss": 0.7388782501220703,
      "eval_runtime": 46.8068,
      "eval_samples_per_second": 3587.724,
      "eval_steps_per_second": 448.482,
      "step": 152500
    },
    {
      "epoch": 1.6149554575722127,
      "grad_norm": 0.8882980942726135,
      "learning_rate": 0.0004942737661831712,
      "loss": 0.9093,
      "step": 152550
    },
    {
      "epoch": 1.615484779352216,
      "grad_norm": 0.8335720896720886,
      "learning_rate": 0.0004942639321441736,
      "loss": 0.8852,
      "step": 152600
    },
    {
      "epoch": 1.6160141011322193,
      "grad_norm": 0.8915187120437622,
      "learning_rate": 0.0004942540897660949,
      "loss": 0.9057,
      "step": 152650
    },
    {
      "epoch": 1.6165434229122226,
      "grad_norm": 0.9442718625068665,
      "learning_rate": 0.0004942442390492711,
      "loss": 0.9009,
      "step": 152700
    },
    {
      "epoch": 1.617072744692226,
      "grad_norm": 0.8513363003730774,
      "learning_rate": 0.0004942343799940386,
      "loss": 0.898,
      "step": 152750
    },
    {
      "epoch": 1.6176020664722293,
      "grad_norm": 0.8894805908203125,
      "learning_rate": 0.000494224512600734,
      "loss": 0.8824,
      "step": 152800
    },
    {
      "epoch": 1.6181313882522326,
      "grad_norm": 0.9198963046073914,
      "learning_rate": 0.000494214636869694,
      "loss": 0.897,
      "step": 152850
    },
    {
      "epoch": 1.6186607100322357,
      "grad_norm": 1.011083722114563,
      "learning_rate": 0.0004942047528012559,
      "loss": 0.8985,
      "step": 152900
    },
    {
      "epoch": 1.619190031812239,
      "grad_norm": 0.8787724375724792,
      "learning_rate": 0.0004941948603957571,
      "loss": 0.8969,
      "step": 152950
    },
    {
      "epoch": 1.6197193535922423,
      "grad_norm": 0.8559862971305847,
      "learning_rate": 0.0004941849596535354,
      "loss": 0.8984,
      "step": 153000
    },
    {
      "epoch": 1.6197193535922423,
      "eval_loss": 0.7374029755592346,
      "eval_runtime": 46.8319,
      "eval_samples_per_second": 3585.802,
      "eval_steps_per_second": 448.241,
      "step": 153000
    },
    {
      "epoch": 1.6202486753722456,
      "grad_norm": 0.7690208554267883,
      "learning_rate": 0.0004941750505749286,
      "loss": 0.8898,
      "step": 153050
    },
    {
      "epoch": 1.6207779971522487,
      "grad_norm": 0.8920838236808777,
      "learning_rate": 0.0004941651331602752,
      "loss": 0.8949,
      "step": 153100
    },
    {
      "epoch": 1.621307318932252,
      "grad_norm": 0.9736460447311401,
      "learning_rate": 0.0004941552074099137,
      "loss": 0.9015,
      "step": 153150
    },
    {
      "epoch": 1.6218366407122553,
      "grad_norm": 0.8762272596359253,
      "learning_rate": 0.0004941452733241829,
      "loss": 0.9083,
      "step": 153200
    },
    {
      "epoch": 1.6223659624922586,
      "grad_norm": 0.85353684425354,
      "learning_rate": 0.0004941353309034221,
      "loss": 0.9048,
      "step": 153250
    },
    {
      "epoch": 1.622895284272262,
      "grad_norm": 0.9008265733718872,
      "learning_rate": 0.0004941253801479706,
      "loss": 0.8954,
      "step": 153300
    },
    {
      "epoch": 1.6234246060522652,
      "grad_norm": 0.8429715037345886,
      "learning_rate": 0.0004941154210581682,
      "loss": 0.898,
      "step": 153350
    },
    {
      "epoch": 1.6239539278322686,
      "grad_norm": 0.8959670066833496,
      "learning_rate": 0.0004941054536343548,
      "loss": 0.8898,
      "step": 153400
    },
    {
      "epoch": 1.6244832496122719,
      "grad_norm": 0.8472394943237305,
      "learning_rate": 0.0004940954778768707,
      "loss": 0.9012,
      "step": 153450
    },
    {
      "epoch": 1.6250125713922752,
      "grad_norm": 0.7960472106933594,
      "learning_rate": 0.0004940854937860565,
      "loss": 0.9095,
      "step": 153500
    },
    {
      "epoch": 1.6250125713922752,
      "eval_loss": 0.737846851348877,
      "eval_runtime": 46.8818,
      "eval_samples_per_second": 3581.986,
      "eval_steps_per_second": 447.764,
      "step": 153500
    },
    {
      "epoch": 1.6255418931722785,
      "grad_norm": 0.9308024048805237,
      "learning_rate": 0.0004940755013622531,
      "loss": 0.9031,
      "step": 153550
    },
    {
      "epoch": 1.6260712149522818,
      "grad_norm": Infinity,
      "learning_rate": 0.0004940657007025884,
      "loss": 0.9055,
      "step": 153600
    },
    {
      "epoch": 1.6266005367322849,
      "grad_norm": 0.8871858716011047,
      "learning_rate": 0.0004940556917804729,
      "loss": 0.8889,
      "step": 153650
    },
    {
      "epoch": 1.6271298585122882,
      "grad_norm": 0.9544010758399963,
      "learning_rate": 0.0004940456745263857,
      "loss": 0.8942,
      "step": 153700
    },
    {
      "epoch": 1.6276591802922915,
      "grad_norm": 0.8829418420791626,
      "learning_rate": 0.0004940356489406687,
      "loss": 0.893,
      "step": 153750
    },
    {
      "epoch": 1.6281885020722948,
      "grad_norm": 0.8705961108207703,
      "learning_rate": 0.0004940256150236641,
      "loss": 0.8832,
      "step": 153800
    },
    {
      "epoch": 1.628717823852298,
      "grad_norm": 0.780634880065918,
      "learning_rate": 0.0004940155727757145,
      "loss": 0.9168,
      "step": 153850
    },
    {
      "epoch": 1.6292471456323012,
      "grad_norm": 0.8258827328681946,
      "learning_rate": 0.0004940055221971627,
      "loss": 0.905,
      "step": 153900
    },
    {
      "epoch": 1.6297764674123045,
      "grad_norm": 0.8641484975814819,
      "learning_rate": 0.0004939954632883519,
      "loss": 0.8913,
      "step": 153950
    },
    {
      "epoch": 1.6303057891923078,
      "grad_norm": 0.8619887232780457,
      "learning_rate": 0.0004939853960496254,
      "loss": 0.9027,
      "step": 154000
    },
    {
      "epoch": 1.6303057891923078,
      "eval_loss": 0.7380136251449585,
      "eval_runtime": 46.8232,
      "eval_samples_per_second": 3586.47,
      "eval_steps_per_second": 448.325,
      "step": 154000
    },
    {
      "epoch": 1.6308351109723112,
      "grad_norm": 0.9478198885917664,
      "learning_rate": 0.0004939753204813271,
      "loss": 0.897,
      "step": 154050
    },
    {
      "epoch": 1.6313644327523145,
      "grad_norm": 0.8372937440872192,
      "learning_rate": 0.0004939652365838007,
      "loss": 0.8902,
      "step": 154100
    },
    {
      "epoch": 1.6318937545323178,
      "grad_norm": 0.8709593415260315,
      "learning_rate": 0.0004939551443573906,
      "loss": 0.8946,
      "step": 154150
    },
    {
      "epoch": 1.632423076312321,
      "grad_norm": 0.8810882568359375,
      "learning_rate": 0.0004939450438024415,
      "loss": 0.9091,
      "step": 154200
    },
    {
      "epoch": 1.6329523980923244,
      "grad_norm": 0.8680195808410645,
      "learning_rate": 0.0004939349349192978,
      "loss": 0.9028,
      "step": 154250
    },
    {
      "epoch": 1.6334817198723277,
      "grad_norm": 0.8702091574668884,
      "learning_rate": 0.0004939248177083051,
      "loss": 0.902,
      "step": 154300
    },
    {
      "epoch": 1.634011041652331,
      "grad_norm": 0.9581660628318787,
      "learning_rate": 0.0004939146921698085,
      "loss": 0.8918,
      "step": 154350
    },
    {
      "epoch": 1.634540363432334,
      "grad_norm": 0.8743544816970825,
      "learning_rate": 0.0004939045583041539,
      "loss": 0.9048,
      "step": 154400
    },
    {
      "epoch": 1.6350696852123374,
      "grad_norm": 0.8316466212272644,
      "learning_rate": 0.0004938944161116869,
      "loss": 0.9012,
      "step": 154450
    },
    {
      "epoch": 1.6355990069923407,
      "grad_norm": 0.8525981903076172,
      "learning_rate": 0.000493884265592754,
      "loss": 0.8904,
      "step": 154500
    },
    {
      "epoch": 1.6355990069923407,
      "eval_loss": 0.7356078028678894,
      "eval_runtime": 46.7436,
      "eval_samples_per_second": 3592.58,
      "eval_steps_per_second": 449.089,
      "step": 154500
    },
    {
      "epoch": 1.636128328772344,
      "grad_norm": 0.8460497260093689,
      "learning_rate": 0.0004938741067477019,
      "loss": 0.9037,
      "step": 154550
    },
    {
      "epoch": 1.6366576505523471,
      "grad_norm": 0.8852691054344177,
      "learning_rate": 0.0004938639395768771,
      "loss": 0.8833,
      "step": 154600
    },
    {
      "epoch": 1.6371869723323504,
      "grad_norm": 0.9403866529464722,
      "learning_rate": 0.0004938537640806268,
      "loss": 0.9048,
      "step": 154650
    },
    {
      "epoch": 1.6377162941123538,
      "grad_norm": 0.840224027633667,
      "learning_rate": 0.0004938435802592985,
      "loss": 0.8918,
      "step": 154700
    },
    {
      "epoch": 1.638245615892357,
      "grad_norm": 0.9593801498413086,
      "learning_rate": 0.0004938333881132398,
      "loss": 0.8989,
      "step": 154750
    },
    {
      "epoch": 1.6387749376723604,
      "grad_norm": 0.8352744579315186,
      "learning_rate": 0.0004938231876427987,
      "loss": 0.9,
      "step": 154800
    },
    {
      "epoch": 1.6393042594523637,
      "grad_norm": 0.8915121555328369,
      "learning_rate": 0.0004938129788483233,
      "loss": 0.8806,
      "step": 154850
    },
    {
      "epoch": 1.639833581232367,
      "grad_norm": 0.8989301323890686,
      "learning_rate": 0.0004938027617301622,
      "loss": 0.9139,
      "step": 154900
    },
    {
      "epoch": 1.6403629030123703,
      "grad_norm": 0.8473864793777466,
      "learning_rate": 0.0004937925362886644,
      "loss": 0.8951,
      "step": 154950
    },
    {
      "epoch": 1.6408922247923736,
      "grad_norm": 0.9430022239685059,
      "learning_rate": 0.0004937823025241787,
      "loss": 0.8915,
      "step": 155000
    },
    {
      "epoch": 1.6408922247923736,
      "eval_loss": 0.7316977977752686,
      "eval_runtime": 46.7274,
      "eval_samples_per_second": 3593.821,
      "eval_steps_per_second": 449.244,
      "step": 155000
    },
    {
      "epoch": 1.641421546572377,
      "grad_norm": 0.8102303147315979,
      "learning_rate": 0.0004937720604370546,
      "loss": 0.9045,
      "step": 155050
    },
    {
      "epoch": 1.6419508683523802,
      "grad_norm": 0.8752638697624207,
      "learning_rate": 0.0004937618100276416,
      "loss": 0.8997,
      "step": 155100
    },
    {
      "epoch": 1.6424801901323833,
      "grad_norm": 0.8164257407188416,
      "learning_rate": 0.00049375155129629,
      "loss": 0.9072,
      "step": 155150
    },
    {
      "epoch": 1.6430095119123866,
      "grad_norm": 0.8888565897941589,
      "learning_rate": 0.0004937412842433499,
      "loss": 0.9132,
      "step": 155200
    },
    {
      "epoch": 1.64353883369239,
      "grad_norm": 0.9368033409118652,
      "learning_rate": 0.0004937310088691716,
      "loss": 0.9105,
      "step": 155250
    },
    {
      "epoch": 1.6440681554723933,
      "grad_norm": 0.8510404825210571,
      "learning_rate": 0.000493720725174106,
      "loss": 0.8894,
      "step": 155300
    },
    {
      "epoch": 1.6445974772523964,
      "grad_norm": 0.8494124412536621,
      "learning_rate": 0.0004937104331585044,
      "loss": 0.8944,
      "step": 155350
    },
    {
      "epoch": 1.6451267990323997,
      "grad_norm": 0.9151971340179443,
      "learning_rate": 0.0004937001328227179,
      "loss": 0.8939,
      "step": 155400
    },
    {
      "epoch": 1.645656120812403,
      "grad_norm": 0.9126988649368286,
      "learning_rate": 0.0004936898241670981,
      "loss": 0.9232,
      "step": 155450
    },
    {
      "epoch": 1.6461854425924063,
      "grad_norm": 0.6834323406219482,
      "learning_rate": 0.0004936795071919973,
      "loss": 0.8826,
      "step": 155500
    },
    {
      "epoch": 1.6461854425924063,
      "eval_loss": 0.7321256995201111,
      "eval_runtime": 46.8423,
      "eval_samples_per_second": 3585.011,
      "eval_steps_per_second": 448.142,
      "step": 155500
    },
    {
      "epoch": 1.6467147643724096,
      "grad_norm": 0.9173672199249268,
      "learning_rate": 0.0004936691818977674,
      "loss": 0.9037,
      "step": 155550
    },
    {
      "epoch": 1.647244086152413,
      "grad_norm": 0.857420802116394,
      "learning_rate": 0.000493658848284761,
      "loss": 0.9028,
      "step": 155600
    },
    {
      "epoch": 1.6477734079324162,
      "grad_norm": 0.949823796749115,
      "learning_rate": 0.0004936487132734777,
      "loss": 0.88,
      "step": 155650
    },
    {
      "epoch": 1.6483027297124195,
      "grad_norm": 0.9268084168434143,
      "learning_rate": 0.0004936383631903349,
      "loss": 0.9077,
      "step": 155700
    },
    {
      "epoch": 1.6488320514924228,
      "grad_norm": 0.8368730545043945,
      "learning_rate": 0.0004936280047894677,
      "loss": 0.8946,
      "step": 155750
    },
    {
      "epoch": 1.6493613732724262,
      "grad_norm": 0.9172242879867554,
      "learning_rate": 0.0004936176380712298,
      "loss": 0.9044,
      "step": 155800
    },
    {
      "epoch": 1.6498906950524295,
      "grad_norm": 0.9030377864837646,
      "learning_rate": 0.000493607263035975,
      "loss": 0.9049,
      "step": 155850
    },
    {
      "epoch": 1.6504200168324326,
      "grad_norm": 0.8363768458366394,
      "learning_rate": 0.0004935968796840576,
      "loss": 0.9008,
      "step": 155900
    },
    {
      "epoch": 1.6509493386124359,
      "grad_norm": 0.8703566789627075,
      "learning_rate": 0.0004935864880158321,
      "loss": 0.8967,
      "step": 155950
    },
    {
      "epoch": 1.6514786603924392,
      "grad_norm": 0.827974259853363,
      "learning_rate": 0.0004935760880316533,
      "loss": 0.8939,
      "step": 156000
    },
    {
      "epoch": 1.6514786603924392,
      "eval_loss": 0.7331708073616028,
      "eval_runtime": 46.7472,
      "eval_samples_per_second": 3592.299,
      "eval_steps_per_second": 449.053,
      "step": 156000
    },
    {
      "epoch": 1.6520079821724425,
      "grad_norm": 0.8359800577163696,
      "learning_rate": 0.0004935656797318761,
      "loss": 0.8992,
      "step": 156050
    },
    {
      "epoch": 1.6525373039524456,
      "grad_norm": 0.8732494115829468,
      "learning_rate": 0.0004935552631168559,
      "loss": 0.8828,
      "step": 156100
    },
    {
      "epoch": 1.653066625732449,
      "grad_norm": 0.9023323655128479,
      "learning_rate": 0.0004935448381869484,
      "loss": 0.8809,
      "step": 156150
    },
    {
      "epoch": 1.6535959475124522,
      "grad_norm": 0.832784116268158,
      "learning_rate": 0.0004935344049425093,
      "loss": 0.8962,
      "step": 156200
    },
    {
      "epoch": 1.6541252692924555,
      "grad_norm": 0.8674915432929993,
      "learning_rate": 0.0004935239633838951,
      "loss": 0.8992,
      "step": 156250
    },
    {
      "epoch": 1.6546545910724588,
      "grad_norm": 0.9049209952354431,
      "learning_rate": 0.000493513513511462,
      "loss": 0.8833,
      "step": 156300
    },
    {
      "epoch": 1.6551839128524621,
      "grad_norm": 0.9185763597488403,
      "learning_rate": 0.0004935030553255669,
      "loss": 0.8896,
      "step": 156350
    },
    {
      "epoch": 1.6557132346324654,
      "grad_norm": 0.8781156539916992,
      "learning_rate": 0.0004934925888265668,
      "loss": 0.8866,
      "step": 156400
    },
    {
      "epoch": 1.6562425564124688,
      "grad_norm": 0.8257239460945129,
      "learning_rate": 0.000493482114014819,
      "loss": 0.8741,
      "step": 156450
    },
    {
      "epoch": 1.656771878192472,
      "grad_norm": 0.8790472745895386,
      "learning_rate": 0.0004934716308906812,
      "loss": 0.8995,
      "step": 156500
    },
    {
      "epoch": 1.656771878192472,
      "eval_loss": 0.7282317876815796,
      "eval_runtime": 46.7719,
      "eval_samples_per_second": 3590.406,
      "eval_steps_per_second": 448.817,
      "step": 156500
    },
    {
      "epoch": 1.6573011999724754,
      "grad_norm": 0.8892159461975098,
      "learning_rate": 0.0004934611394545111,
      "loss": 0.89,
      "step": 156550
    },
    {
      "epoch": 1.6578305217524787,
      "grad_norm": 0.8398892879486084,
      "learning_rate": 0.000493450639706667,
      "loss": 0.889,
      "step": 156600
    },
    {
      "epoch": 1.6583598435324818,
      "grad_norm": 0.7943071722984314,
      "learning_rate": 0.0004934401316475073,
      "loss": 0.9027,
      "step": 156650
    },
    {
      "epoch": 1.658889165312485,
      "grad_norm": 0.9211865067481995,
      "learning_rate": 0.0004934296152773909,
      "loss": 0.8989,
      "step": 156700
    },
    {
      "epoch": 1.6594184870924884,
      "grad_norm": 0.8896953463554382,
      "learning_rate": 0.0004934190905966767,
      "loss": 0.8787,
      "step": 156750
    },
    {
      "epoch": 1.6599478088724917,
      "grad_norm": 0.9366312623023987,
      "learning_rate": 0.0004934085576057239,
      "loss": 0.9018,
      "step": 156800
    },
    {
      "epoch": 1.6604771306524948,
      "grad_norm": 0.7938204407691956,
      "learning_rate": 0.0004933980163048924,
      "loss": 0.88,
      "step": 156850
    },
    {
      "epoch": 1.6610064524324981,
      "grad_norm": 0.8876704573631287,
      "learning_rate": 0.0004933874666945417,
      "loss": 0.8906,
      "step": 156900
    },
    {
      "epoch": 1.6615357742125014,
      "grad_norm": 0.9456403255462646,
      "learning_rate": 0.0004933769087750322,
      "loss": 0.9055,
      "step": 156950
    },
    {
      "epoch": 1.6620650959925047,
      "grad_norm": 0.7802818417549133,
      "learning_rate": 0.0004933663425467243,
      "loss": 0.8984,
      "step": 157000
    },
    {
      "epoch": 1.6620650959925047,
      "eval_loss": 0.7265111207962036,
      "eval_runtime": 46.667,
      "eval_samples_per_second": 3598.475,
      "eval_steps_per_second": 449.825,
      "step": 157000
    },
    {
      "epoch": 1.662594417772508,
      "grad_norm": 0.8529987931251526,
      "learning_rate": 0.0004933557680099788,
      "loss": 0.8977,
      "step": 157050
    },
    {
      "epoch": 1.6631237395525114,
      "grad_norm": 0.8684144616127014,
      "learning_rate": 0.0004933451851651565,
      "loss": 0.8895,
      "step": 157100
    },
    {
      "epoch": 1.6636530613325147,
      "grad_norm": 0.8498132824897766,
      "learning_rate": 0.0004933345940126188,
      "loss": 0.8907,
      "step": 157150
    },
    {
      "epoch": 1.664182383112518,
      "grad_norm": 0.852292001247406,
      "learning_rate": 0.0004933239945527274,
      "loss": 0.8898,
      "step": 157200
    },
    {
      "epoch": 1.6647117048925213,
      "grad_norm": 0.8179717063903809,
      "learning_rate": 0.0004933133867858441,
      "loss": 0.8964,
      "step": 157250
    },
    {
      "epoch": 1.6652410266725246,
      "grad_norm": 0.8211309909820557,
      "learning_rate": 0.000493302770712331,
      "loss": 0.8921,
      "step": 157300
    },
    {
      "epoch": 1.665770348452528,
      "grad_norm": 0.900493860244751,
      "learning_rate": 0.0004932921463325505,
      "loss": 0.8864,
      "step": 157350
    },
    {
      "epoch": 1.666299670232531,
      "grad_norm": 0.8655205368995667,
      "learning_rate": 0.0004932815136468652,
      "loss": 0.8971,
      "step": 157400
    },
    {
      "epoch": 1.6668289920125343,
      "grad_norm": 0.8846848011016846,
      "learning_rate": 0.0004932708726556385,
      "loss": 0.8951,
      "step": 157450
    },
    {
      "epoch": 1.6673583137925376,
      "grad_norm": 0.9471672177314758,
      "learning_rate": 0.0004932602233592333,
      "loss": 0.8836,
      "step": 157500
    },
    {
      "epoch": 1.6673583137925376,
      "eval_loss": 0.726729691028595,
      "eval_runtime": 46.7939,
      "eval_samples_per_second": 3588.719,
      "eval_steps_per_second": 448.606,
      "step": 157500
    },
    {
      "epoch": 1.667887635572541,
      "grad_norm": 1.0092096328735352,
      "learning_rate": 0.0004932495657580133,
      "loss": 0.893,
      "step": 157550
    },
    {
      "epoch": 1.668416957352544,
      "grad_norm": 0.8308538198471069,
      "learning_rate": 0.0004932388998523423,
      "loss": 0.8894,
      "step": 157600
    },
    {
      "epoch": 1.6689462791325473,
      "grad_norm": 0.8410559296607971,
      "learning_rate": 0.0004932284392081573,
      "loss": 0.8817,
      "step": 157650
    },
    {
      "epoch": 1.6694756009125507,
      "grad_norm": 0.9063525199890137,
      "learning_rate": 0.000493217756860748,
      "loss": 0.8768,
      "step": 157700
    },
    {
      "epoch": 1.670004922692554,
      "grad_norm": 0.8423691391944885,
      "learning_rate": 0.0004932070662099735,
      "loss": 0.885,
      "step": 157750
    },
    {
      "epoch": 1.6705342444725573,
      "grad_norm": 0.9004262685775757,
      "learning_rate": 0.0004931963672561992,
      "loss": 0.8967,
      "step": 157800
    },
    {
      "epoch": 1.6710635662525606,
      "grad_norm": 0.8180184364318848,
      "learning_rate": 0.0004931856599997899,
      "loss": 0.8955,
      "step": 157850
    },
    {
      "epoch": 1.671592888032564,
      "grad_norm": 0.9649295806884766,
      "learning_rate": 0.0004931749444411116,
      "loss": 0.8833,
      "step": 157900
    },
    {
      "epoch": 1.6721222098125672,
      "grad_norm": 0.9249062538146973,
      "learning_rate": 0.0004931642205805296,
      "loss": 0.8838,
      "step": 157950
    },
    {
      "epoch": 1.6726515315925705,
      "grad_norm": 0.8573929667472839,
      "learning_rate": 0.0004931534884184105,
      "loss": 0.8974,
      "step": 158000
    },
    {
      "epoch": 1.6726515315925705,
      "eval_loss": 0.7277404069900513,
      "eval_runtime": 46.8158,
      "eval_samples_per_second": 3587.035,
      "eval_steps_per_second": 448.395,
      "step": 158000
    },
    {
      "epoch": 1.6731808533725738,
      "grad_norm": 0.9097502827644348,
      "learning_rate": 0.0004931427479551203,
      "loss": 0.8901,
      "step": 158050
    },
    {
      "epoch": 1.6737101751525771,
      "grad_norm": 0.8105211853981018,
      "learning_rate": 0.000493131999191026,
      "loss": 0.9043,
      "step": 158100
    },
    {
      "epoch": 1.6742394969325805,
      "grad_norm": 0.8424819707870483,
      "learning_rate": 0.0004931212421264943,
      "loss": 0.8827,
      "step": 158150
    },
    {
      "epoch": 1.6747688187125835,
      "grad_norm": 0.7950196266174316,
      "learning_rate": 0.0004931104767618926,
      "loss": 0.8839,
      "step": 158200
    },
    {
      "epoch": 1.6752981404925869,
      "grad_norm": 0.8575901389122009,
      "learning_rate": 0.0004930997030975885,
      "loss": 0.8947,
      "step": 158250
    },
    {
      "epoch": 1.6758274622725902,
      "grad_norm": 0.8174535036087036,
      "learning_rate": 0.0004930889211339495,
      "loss": 0.9032,
      "step": 158300
    },
    {
      "epoch": 1.6763567840525933,
      "grad_norm": 0.7974517345428467,
      "learning_rate": 0.000493078130871344,
      "loss": 0.8777,
      "step": 158350
    },
    {
      "epoch": 1.6768861058325966,
      "grad_norm": 0.8441628217697144,
      "learning_rate": 0.0004930673323101403,
      "loss": 0.8889,
      "step": 158400
    },
    {
      "epoch": 1.6774154276125999,
      "grad_norm": 0.9599893689155579,
      "learning_rate": 0.0004930565254507069,
      "loss": 0.9034,
      "step": 158450
    },
    {
      "epoch": 1.6779447493926032,
      "grad_norm": 0.9825186133384705,
      "learning_rate": 0.0004930457102934129,
      "loss": 0.9095,
      "step": 158500
    },
    {
      "epoch": 1.6779447493926032,
      "eval_loss": 0.7229166030883789,
      "eval_runtime": 46.7296,
      "eval_samples_per_second": 3593.654,
      "eval_steps_per_second": 449.223,
      "step": 158500
    },
    {
      "epoch": 1.6784740711726065,
      "grad_norm": 0.8237999081611633,
      "learning_rate": 0.0004930348868386274,
      "loss": 0.8871,
      "step": 158550
    },
    {
      "epoch": 1.6790033929526098,
      "grad_norm": 0.8327826857566833,
      "learning_rate": 0.0004930240550867201,
      "loss": 0.9089,
      "step": 158600
    },
    {
      "epoch": 1.6795327147326131,
      "grad_norm": 0.8133341073989868,
      "learning_rate": 0.0004930132150380606,
      "loss": 0.8627,
      "step": 158650
    },
    {
      "epoch": 1.6800620365126164,
      "grad_norm": 0.9075598120689392,
      "learning_rate": 0.0004930023666930192,
      "loss": 0.881,
      "step": 158700
    },
    {
      "epoch": 1.6805913582926197,
      "grad_norm": 0.8922809958457947,
      "learning_rate": 0.0004929915100519661,
      "loss": 0.8818,
      "step": 158750
    },
    {
      "epoch": 1.681120680072623,
      "grad_norm": 0.8326449394226074,
      "learning_rate": 0.0004929806451152718,
      "loss": 0.8934,
      "step": 158800
    },
    {
      "epoch": 1.6816500018526264,
      "grad_norm": 0.8364112377166748,
      "learning_rate": 0.0004929697718833076,
      "loss": 0.8677,
      "step": 158850
    },
    {
      "epoch": 1.6821793236326297,
      "grad_norm": 0.8240217566490173,
      "learning_rate": 0.0004929588903564443,
      "loss": 0.8952,
      "step": 158900
    },
    {
      "epoch": 1.6827086454126328,
      "grad_norm": 0.8600974678993225,
      "learning_rate": 0.0004929480005350538,
      "loss": 0.8842,
      "step": 158950
    },
    {
      "epoch": 1.683237967192636,
      "grad_norm": 0.9532859325408936,
      "learning_rate": 0.0004929371024195075,
      "loss": 0.8828,
      "step": 159000
    },
    {
      "epoch": 1.683237967192636,
      "eval_loss": 0.7228413820266724,
      "eval_runtime": 46.7891,
      "eval_samples_per_second": 3589.081,
      "eval_steps_per_second": 448.651,
      "step": 159000
    },
    {
      "epoch": 1.6837672889726394,
      "grad_norm": 0.8710033297538757,
      "learning_rate": 0.0004929261960101777,
      "loss": 0.8897,
      "step": 159050
    },
    {
      "epoch": 1.6842966107526425,
      "grad_norm": 0.9058519601821899,
      "learning_rate": 0.0004929152813074366,
      "loss": 0.8744,
      "step": 159100
    },
    {
      "epoch": 1.6848259325326458,
      "grad_norm": 0.9088682532310486,
      "learning_rate": 0.0004929043583116568,
      "loss": 0.8759,
      "step": 159150
    },
    {
      "epoch": 1.685355254312649,
      "grad_norm": 0.8865511417388916,
      "learning_rate": 0.0004928934270232114,
      "loss": 0.8953,
      "step": 159200
    },
    {
      "epoch": 1.6858845760926524,
      "grad_norm": 0.865305483341217,
      "learning_rate": 0.0004928824874424735,
      "loss": 0.8881,
      "step": 159250
    },
    {
      "epoch": 1.6864138978726557,
      "grad_norm": 0.8936654329299927,
      "learning_rate": 0.0004928715395698165,
      "loss": 0.8824,
      "step": 159300
    },
    {
      "epoch": 1.686943219652659,
      "grad_norm": 0.8433822989463806,
      "learning_rate": 0.0004928605834056142,
      "loss": 0.8922,
      "step": 159350
    },
    {
      "epoch": 1.6874725414326623,
      "grad_norm": 0.7827453017234802,
      "learning_rate": 0.0004928496189502407,
      "loss": 0.8888,
      "step": 159400
    },
    {
      "epoch": 1.6880018632126657,
      "grad_norm": 0.9199913144111633,
      "learning_rate": 0.0004928386462040703,
      "loss": 0.8786,
      "step": 159450
    },
    {
      "epoch": 1.688531184992669,
      "grad_norm": 0.8863245248794556,
      "learning_rate": 0.0004928276651674775,
      "loss": 0.9009,
      "step": 159500
    },
    {
      "epoch": 1.688531184992669,
      "eval_loss": 0.7229914665222168,
      "eval_runtime": 46.8071,
      "eval_samples_per_second": 3587.701,
      "eval_steps_per_second": 448.479,
      "step": 159500
    },
    {
      "epoch": 1.6890605067726723,
      "grad_norm": 0.8112524151802063,
      "learning_rate": 0.0004928166758408373,
      "loss": 0.8763,
      "step": 159550
    },
    {
      "epoch": 1.6895898285526756,
      "grad_norm": 0.9462752938270569,
      "learning_rate": 0.0004928056782245248,
      "loss": 0.8924,
      "step": 159600
    },
    {
      "epoch": 1.690119150332679,
      "grad_norm": 0.8060770034790039,
      "learning_rate": 0.0004927946723189156,
      "loss": 0.874,
      "step": 159650
    },
    {
      "epoch": 1.690648472112682,
      "grad_norm": 0.885856032371521,
      "learning_rate": 0.0004927838784895048,
      "loss": 0.8863,
      "step": 159700
    },
    {
      "epoch": 1.6911777938926853,
      "grad_norm": 0.9486399292945862,
      "learning_rate": 0.0004927728561721966,
      "loss": 0.8938,
      "step": 159750
    },
    {
      "epoch": 1.6917071156726886,
      "grad_norm": 0.8176364898681641,
      "learning_rate": 0.0004927618255667121,
      "loss": 0.8756,
      "step": 159800
    },
    {
      "epoch": 1.6922364374526917,
      "grad_norm": 0.890785813331604,
      "learning_rate": 0.000492750786673428,
      "loss": 0.8826,
      "step": 159850
    },
    {
      "epoch": 1.692765759232695,
      "grad_norm": 0.8915440440177917,
      "learning_rate": 0.000492739739492721,
      "loss": 0.8939,
      "step": 159900
    },
    {
      "epoch": 1.6932950810126983,
      "grad_norm": 0.8679283261299133,
      "learning_rate": 0.0004927286840249684,
      "loss": 0.8791,
      "step": 159950
    },
    {
      "epoch": 1.6938244027927016,
      "grad_norm": 0.8734382390975952,
      "learning_rate": 0.0004927176202705474,
      "loss": 0.8748,
      "step": 160000
    },
    {
      "epoch": 1.6938244027927016,
      "eval_loss": 0.7187055349349976,
      "eval_runtime": 46.7685,
      "eval_samples_per_second": 3590.668,
      "eval_steps_per_second": 448.85,
      "step": 160000
    },
    {
      "epoch": 1.694353724572705,
      "grad_norm": 1.004037857055664,
      "learning_rate": 0.000492706548229836,
      "loss": 0.8917,
      "step": 160050
    },
    {
      "epoch": 1.6948830463527083,
      "grad_norm": 0.8534108400344849,
      "learning_rate": 0.000492695467903212,
      "loss": 0.8867,
      "step": 160100
    },
    {
      "epoch": 1.6954123681327116,
      "grad_norm": 0.8560268878936768,
      "learning_rate": 0.0004926843792910536,
      "loss": 0.888,
      "step": 160150
    },
    {
      "epoch": 1.6959416899127149,
      "grad_norm": 0.9505655169487,
      "learning_rate": 0.0004926732823937397,
      "loss": 0.8715,
      "step": 160200
    },
    {
      "epoch": 1.6964710116927182,
      "grad_norm": 0.8900208473205566,
      "learning_rate": 0.0004926621772116488,
      "loss": 0.8846,
      "step": 160250
    },
    {
      "epoch": 1.6970003334727215,
      "grad_norm": 0.8664935827255249,
      "learning_rate": 0.0004926510637451602,
      "loss": 0.8788,
      "step": 160300
    },
    {
      "epoch": 1.6975296552527248,
      "grad_norm": 0.9649021625518799,
      "learning_rate": 0.0004926399419946533,
      "loss": 0.8905,
      "step": 160350
    },
    {
      "epoch": 1.6980589770327281,
      "grad_norm": 0.8796548247337341,
      "learning_rate": 0.0004926288119605078,
      "loss": 0.8932,
      "step": 160400
    },
    {
      "epoch": 1.6985882988127312,
      "grad_norm": 0.8642149567604065,
      "learning_rate": 0.0004926176736431035,
      "loss": 0.8858,
      "step": 160450
    },
    {
      "epoch": 1.6991176205927345,
      "grad_norm": 0.8207988142967224,
      "learning_rate": 0.000492606527042821,
      "loss": 0.9008,
      "step": 160500
    },
    {
      "epoch": 1.6991176205927345,
      "eval_loss": 0.7182241082191467,
      "eval_runtime": 46.8086,
      "eval_samples_per_second": 3587.585,
      "eval_steps_per_second": 448.464,
      "step": 160500
    },
    {
      "epoch": 1.6996469423727378,
      "grad_norm": 0.9782408475875854,
      "learning_rate": 0.0004925953721600405,
      "loss": 0.8762,
      "step": 160550
    },
    {
      "epoch": 1.7001762641527411,
      "grad_norm": 0.9363563060760498,
      "learning_rate": 0.000492584208995143,
      "loss": 0.8791,
      "step": 160600
    },
    {
      "epoch": 1.7007055859327442,
      "grad_norm": 0.8659082651138306,
      "learning_rate": 0.0004925730375485096,
      "loss": 0.8815,
      "step": 160650
    },
    {
      "epoch": 1.7012349077127475,
      "grad_norm": 0.8546370267868042,
      "learning_rate": 0.0004925618578205215,
      "loss": 0.8883,
      "step": 160700
    },
    {
      "epoch": 1.7017642294927509,
      "grad_norm": 0.9332518577575684,
      "learning_rate": 0.0004925506698115607,
      "loss": 0.8832,
      "step": 160750
    },
    {
      "epoch": 1.7022935512727542,
      "grad_norm": 0.835972011089325,
      "learning_rate": 0.000492539473522009,
      "loss": 0.8784,
      "step": 160800
    },
    {
      "epoch": 1.7028228730527575,
      "grad_norm": 0.8836917877197266,
      "learning_rate": 0.0004925282689522486,
      "loss": 0.8821,
      "step": 160850
    },
    {
      "epoch": 1.7033521948327608,
      "grad_norm": 0.9205976724624634,
      "learning_rate": 0.0004925170561026619,
      "loss": 0.88,
      "step": 160900
    },
    {
      "epoch": 1.703881516612764,
      "grad_norm": 0.9225972294807434,
      "learning_rate": 0.000492505834973632,
      "loss": 0.8825,
      "step": 160950
    },
    {
      "epoch": 1.7044108383927674,
      "grad_norm": 0.8719931244850159,
      "learning_rate": 0.0004924946055655418,
      "loss": 0.8821,
      "step": 161000
    },
    {
      "epoch": 1.7044108383927674,
      "eval_loss": 0.7238283157348633,
      "eval_runtime": 46.7541,
      "eval_samples_per_second": 3591.772,
      "eval_steps_per_second": 448.988,
      "step": 161000
    },
    {
      "epoch": 1.7049401601727707,
      "grad_norm": 0.8322274684906006,
      "learning_rate": 0.0004924833678787747,
      "loss": 0.868,
      "step": 161050
    },
    {
      "epoch": 1.705469481952774,
      "grad_norm": 0.9493255019187927,
      "learning_rate": 0.0004924721219137144,
      "loss": 0.8833,
      "step": 161100
    },
    {
      "epoch": 1.7059988037327773,
      "grad_norm": 0.8445821404457092,
      "learning_rate": 0.0004924608676707446,
      "loss": 0.8957,
      "step": 161150
    },
    {
      "epoch": 1.7065281255127804,
      "grad_norm": 0.8062529563903809,
      "learning_rate": 0.0004924496051502498,
      "loss": 0.8801,
      "step": 161200
    },
    {
      "epoch": 1.7070574472927837,
      "grad_norm": 0.964765727519989,
      "learning_rate": 0.0004924383343526144,
      "loss": 0.888,
      "step": 161250
    },
    {
      "epoch": 1.707586769072787,
      "grad_norm": 0.8885103464126587,
      "learning_rate": 0.0004924270552782232,
      "loss": 0.8845,
      "step": 161300
    },
    {
      "epoch": 1.7081160908527904,
      "grad_norm": 0.8902907967567444,
      "learning_rate": 0.0004924157679274613,
      "loss": 0.8787,
      "step": 161350
    },
    {
      "epoch": 1.7086454126327935,
      "grad_norm": 0.859153687953949,
      "learning_rate": 0.0004924044723007138,
      "loss": 0.8927,
      "step": 161400
    },
    {
      "epoch": 1.7091747344127968,
      "grad_norm": 0.9529643058776855,
      "learning_rate": 0.0004923931683983667,
      "loss": 0.8704,
      "step": 161450
    },
    {
      "epoch": 1.7097040561928,
      "grad_norm": 0.7699009776115417,
      "learning_rate": 0.0004923818562208057,
      "loss": 0.8868,
      "step": 161500
    },
    {
      "epoch": 1.7097040561928,
      "eval_loss": 0.7187713980674744,
      "eval_runtime": 46.8098,
      "eval_samples_per_second": 3587.5,
      "eval_steps_per_second": 448.454,
      "step": 161500
    },
    {
      "epoch": 1.7102333779728034,
      "grad_norm": 0.9738792777061462,
      "learning_rate": 0.0004923705357684169,
      "loss": 0.8844,
      "step": 161550
    },
    {
      "epoch": 1.7107626997528067,
      "grad_norm": 0.894547700881958,
      "learning_rate": 0.0004923592070415869,
      "loss": 0.8754,
      "step": 161600
    },
    {
      "epoch": 1.71129202153281,
      "grad_norm": 0.8432180285453796,
      "learning_rate": 0.0004923478700407025,
      "loss": 0.8749,
      "step": 161650
    },
    {
      "epoch": 1.7118213433128133,
      "grad_norm": 0.8431225419044495,
      "learning_rate": 0.0004923367517527213,
      "loss": 0.8792,
      "step": 161700
    },
    {
      "epoch": 1.7123506650928166,
      "grad_norm": 0.8995724320411682,
      "learning_rate": 0.0004923253983703512,
      "loss": 0.8767,
      "step": 161750
    },
    {
      "epoch": 1.71287998687282,
      "grad_norm": 0.868852436542511,
      "learning_rate": 0.0004923140367150809,
      "loss": 0.8959,
      "step": 161800
    },
    {
      "epoch": 1.7134093086528233,
      "grad_norm": 0.8250607848167419,
      "learning_rate": 0.0004923026667872982,
      "loss": 0.8622,
      "step": 161850
    },
    {
      "epoch": 1.7139386304328266,
      "grad_norm": 0.8256616592407227,
      "learning_rate": 0.0004922912885873915,
      "loss": 0.8778,
      "step": 161900
    },
    {
      "epoch": 1.7144679522128297,
      "grad_norm": 0.7909384369850159,
      "learning_rate": 0.0004922799021157489,
      "loss": 0.8998,
      "step": 161950
    },
    {
      "epoch": 1.714997273992833,
      "grad_norm": 0.8785325288772583,
      "learning_rate": 0.0004922685073727594,
      "loss": 0.8784,
      "step": 162000
    },
    {
      "epoch": 1.714997273992833,
      "eval_loss": 0.7202747464179993,
      "eval_runtime": 46.773,
      "eval_samples_per_second": 3590.322,
      "eval_steps_per_second": 448.806,
      "step": 162000
    },
    {
      "epoch": 1.7155265957728363,
      "grad_norm": 0.8964853882789612,
      "learning_rate": 0.0004922571043588118,
      "loss": 0.871,
      "step": 162050
    },
    {
      "epoch": 1.7160559175528396,
      "grad_norm": 0.9550156593322754,
      "learning_rate": 0.0004922456930742955,
      "loss": 0.8778,
      "step": 162100
    },
    {
      "epoch": 1.7165852393328427,
      "grad_norm": 0.9391708970069885,
      "learning_rate": 0.0004922342735196002,
      "loss": 0.8744,
      "step": 162150
    },
    {
      "epoch": 1.717114561112846,
      "grad_norm": 0.9043038487434387,
      "learning_rate": 0.0004922228456951156,
      "loss": 0.8873,
      "step": 162200
    },
    {
      "epoch": 1.7176438828928493,
      "grad_norm": 0.863877534866333,
      "learning_rate": 0.0004922114096012318,
      "loss": 0.8835,
      "step": 162250
    },
    {
      "epoch": 1.7181732046728526,
      "grad_norm": 0.8837355971336365,
      "learning_rate": 0.0004921999652383394,
      "loss": 0.8927,
      "step": 162300
    },
    {
      "epoch": 1.718702526452856,
      "grad_norm": 0.9421501159667969,
      "learning_rate": 0.0004921885126068289,
      "loss": 0.8925,
      "step": 162350
    },
    {
      "epoch": 1.7192318482328592,
      "grad_norm": 0.9304547309875488,
      "learning_rate": 0.0004921770517070915,
      "loss": 0.8828,
      "step": 162400
    },
    {
      "epoch": 1.7197611700128626,
      "grad_norm": 0.9362210035324097,
      "learning_rate": 0.0004921655825395184,
      "loss": 0.9068,
      "step": 162450
    },
    {
      "epoch": 1.7202904917928659,
      "grad_norm": 0.8562605977058411,
      "learning_rate": 0.000492154105104501,
      "loss": 0.8882,
      "step": 162500
    },
    {
      "epoch": 1.7202904917928659,
      "eval_loss": 0.7138376235961914,
      "eval_runtime": 46.8192,
      "eval_samples_per_second": 3586.779,
      "eval_steps_per_second": 448.363,
      "step": 162500
    },
    {
      "epoch": 1.7208198135728692,
      "grad_norm": 0.875987708568573,
      "learning_rate": 0.0004921426194024314,
      "loss": 0.8781,
      "step": 162550
    },
    {
      "epoch": 1.7213491353528725,
      "grad_norm": 0.8655014038085938,
      "learning_rate": 0.0004921311254337014,
      "loss": 0.8731,
      "step": 162600
    },
    {
      "epoch": 1.7218784571328758,
      "grad_norm": 0.8055956959724426,
      "learning_rate": 0.0004921196231987038,
      "loss": 0.8962,
      "step": 162650
    },
    {
      "epoch": 1.7224077789128789,
      "grad_norm": 0.8689740300178528,
      "learning_rate": 0.0004921081126978309,
      "loss": 0.8844,
      "step": 162700
    },
    {
      "epoch": 1.7229371006928822,
      "grad_norm": 0.7725933194160461,
      "learning_rate": 0.0004920965939314758,
      "loss": 0.8909,
      "step": 162750
    },
    {
      "epoch": 1.7234664224728855,
      "grad_norm": 0.8631274104118347,
      "learning_rate": 0.0004920850669000318,
      "loss": 0.8945,
      "step": 162800
    },
    {
      "epoch": 1.7239957442528888,
      "grad_norm": 0.9060338139533997,
      "learning_rate": 0.0004920735316038924,
      "loss": 0.8823,
      "step": 162850
    },
    {
      "epoch": 1.724525066032892,
      "grad_norm": 0.8366474509239197,
      "learning_rate": 0.0004920619880434514,
      "loss": 0.8674,
      "step": 162900
    },
    {
      "epoch": 1.7250543878128952,
      "grad_norm": 0.951319694519043,
      "learning_rate": 0.000492050436219103,
      "loss": 0.8834,
      "step": 162950
    },
    {
      "epoch": 1.7255837095928985,
      "grad_norm": 0.8251236081123352,
      "learning_rate": 0.0004920388761312414,
      "loss": 0.8843,
      "step": 163000
    },
    {
      "epoch": 1.7255837095928985,
      "eval_loss": 0.7138932347297668,
      "eval_runtime": 46.8245,
      "eval_samples_per_second": 3586.37,
      "eval_steps_per_second": 448.312,
      "step": 163000
    },
    {
      "epoch": 1.7261130313729018,
      "grad_norm": 0.914687991142273,
      "learning_rate": 0.0004920273077802614,
      "loss": 0.8695,
      "step": 163050
    },
    {
      "epoch": 1.7266423531529052,
      "grad_norm": 0.9186050295829773,
      "learning_rate": 0.0004920157311665578,
      "loss": 0.8761,
      "step": 163100
    },
    {
      "epoch": 1.7271716749329085,
      "grad_norm": 0.8794407844543457,
      "learning_rate": 0.0004920041462905259,
      "loss": 0.886,
      "step": 163150
    },
    {
      "epoch": 1.7277009967129118,
      "grad_norm": 0.9447944164276123,
      "learning_rate": 0.0004919925531525612,
      "loss": 0.875,
      "step": 163200
    },
    {
      "epoch": 1.728230318492915,
      "grad_norm": 0.8227225542068481,
      "learning_rate": 0.0004919809517530595,
      "loss": 0.8824,
      "step": 163250
    },
    {
      "epoch": 1.7287596402729184,
      "grad_norm": 0.8160343170166016,
      "learning_rate": 0.0004919693420924169,
      "loss": 0.8726,
      "step": 163300
    },
    {
      "epoch": 1.7292889620529217,
      "grad_norm": 0.9010189175605774,
      "learning_rate": 0.0004919577241710296,
      "loss": 0.8907,
      "step": 163350
    },
    {
      "epoch": 1.729818283832925,
      "grad_norm": 0.8850541114807129,
      "learning_rate": 0.0004919460979892944,
      "loss": 0.8752,
      "step": 163400
    },
    {
      "epoch": 1.730347605612928,
      "grad_norm": 0.9247840642929077,
      "learning_rate": 0.000491934463547608,
      "loss": 0.8764,
      "step": 163450
    },
    {
      "epoch": 1.7308769273929314,
      "grad_norm": 0.9676181077957153,
      "learning_rate": 0.000491922820846368,
      "loss": 0.8927,
      "step": 163500
    },
    {
      "epoch": 1.7308769273929314,
      "eval_loss": 0.7106803059577942,
      "eval_runtime": 46.8881,
      "eval_samples_per_second": 3581.506,
      "eval_steps_per_second": 447.704,
      "step": 163500
    },
    {
      "epoch": 1.7314062491729347,
      "grad_norm": 0.7926726341247559,
      "learning_rate": 0.0004919111698859714,
      "loss": 0.8753,
      "step": 163550
    },
    {
      "epoch": 1.731935570952938,
      "grad_norm": 0.9773980975151062,
      "learning_rate": 0.0004918995106668163,
      "loss": 0.8704,
      "step": 163600
    },
    {
      "epoch": 1.7324648927329411,
      "grad_norm": 0.899657666683197,
      "learning_rate": 0.0004918878431893006,
      "loss": 0.8952,
      "step": 163650
    },
    {
      "epoch": 1.7329942145129444,
      "grad_norm": 1.016019582748413,
      "learning_rate": 0.0004918761674538227,
      "loss": 0.8716,
      "step": 163700
    },
    {
      "epoch": 1.7335235362929478,
      "grad_norm": 0.8167807459831238,
      "learning_rate": 0.000491864483460781,
      "loss": 0.8685,
      "step": 163750
    },
    {
      "epoch": 1.734052858072951,
      "grad_norm": 0.907918393611908,
      "learning_rate": 0.0004918530251364964,
      "loss": 0.8828,
      "step": 163800
    },
    {
      "epoch": 1.7345821798529544,
      "grad_norm": 0.9904168844223022,
      "learning_rate": 0.0004918413247946558,
      "loss": 0.8651,
      "step": 163850
    },
    {
      "epoch": 1.7351115016329577,
      "grad_norm": 0.8772863149642944,
      "learning_rate": 0.000491829616196441,
      "loss": 0.8724,
      "step": 163900
    },
    {
      "epoch": 1.735640823412961,
      "grad_norm": 0.889726996421814,
      "learning_rate": 0.000491817899342252,
      "loss": 0.8774,
      "step": 163950
    },
    {
      "epoch": 1.7361701451929643,
      "grad_norm": 0.8410751819610596,
      "learning_rate": 0.0004918061742324884,
      "loss": 0.8673,
      "step": 164000
    },
    {
      "epoch": 1.7361701451929643,
      "eval_loss": 0.7129630446434021,
      "eval_runtime": 46.782,
      "eval_samples_per_second": 3589.628,
      "eval_steps_per_second": 448.719,
      "step": 164000
    },
    {
      "epoch": 1.7366994669729676,
      "grad_norm": 0.817904531955719,
      "learning_rate": 0.0004917944408675507,
      "loss": 0.8717,
      "step": 164050
    },
    {
      "epoch": 1.737228788752971,
      "grad_norm": 0.9542942047119141,
      "learning_rate": 0.0004917826992478396,
      "loss": 0.8795,
      "step": 164100
    },
    {
      "epoch": 1.7377581105329742,
      "grad_norm": 0.889793872833252,
      "learning_rate": 0.0004917709493737558,
      "loss": 0.8941,
      "step": 164150
    },
    {
      "epoch": 1.7382874323129773,
      "grad_norm": 0.9299458861351013,
      "learning_rate": 0.0004917591912457003,
      "loss": 0.8816,
      "step": 164200
    },
    {
      "epoch": 1.7388167540929806,
      "grad_norm": 0.8503648638725281,
      "learning_rate": 0.0004917474248640749,
      "loss": 0.8764,
      "step": 164250
    },
    {
      "epoch": 1.739346075872984,
      "grad_norm": 0.9065133929252625,
      "learning_rate": 0.0004917356502292809,
      "loss": 0.8779,
      "step": 164300
    },
    {
      "epoch": 1.7398753976529873,
      "grad_norm": 0.8971751928329468,
      "learning_rate": 0.0004917238673417205,
      "loss": 0.8793,
      "step": 164350
    },
    {
      "epoch": 1.7404047194329904,
      "grad_norm": 0.9536455869674683,
      "learning_rate": 0.0004917120762017959,
      "loss": 0.8627,
      "step": 164400
    },
    {
      "epoch": 1.7409340412129937,
      "grad_norm": 0.7723919749259949,
      "learning_rate": 0.0004917002768099097,
      "loss": 0.8626,
      "step": 164450
    },
    {
      "epoch": 1.741463362992997,
      "grad_norm": 0.8944703936576843,
      "learning_rate": 0.0004916884691664647,
      "loss": 0.8881,
      "step": 164500
    },
    {
      "epoch": 1.741463362992997,
      "eval_loss": 0.7126765847206116,
      "eval_runtime": 46.7179,
      "eval_samples_per_second": 3594.554,
      "eval_steps_per_second": 449.335,
      "step": 164500
    },
    {
      "epoch": 1.7419926847730003,
      "grad_norm": 0.9818046689033508,
      "learning_rate": 0.0004916766532718639,
      "loss": 0.8706,
      "step": 164550
    },
    {
      "epoch": 1.7425220065530036,
      "grad_norm": 0.876280665397644,
      "learning_rate": 0.0004916648291265109,
      "loss": 0.8788,
      "step": 164600
    },
    {
      "epoch": 1.743051328333007,
      "grad_norm": 0.7948130965232849,
      "learning_rate": 0.0004916529967308092,
      "loss": 0.8811,
      "step": 164650
    },
    {
      "epoch": 1.7435806501130102,
      "grad_norm": 0.9127575159072876,
      "learning_rate": 0.0004916411560851629,
      "loss": 0.8793,
      "step": 164700
    },
    {
      "epoch": 1.7441099718930135,
      "grad_norm": 0.889624834060669,
      "learning_rate": 0.0004916293071899761,
      "loss": 0.8519,
      "step": 164750
    },
    {
      "epoch": 1.7446392936730168,
      "grad_norm": 0.8134217262268066,
      "learning_rate": 0.0004916174500456534,
      "loss": 0.8609,
      "step": 164800
    },
    {
      "epoch": 1.7451686154530202,
      "grad_norm": 0.882757306098938,
      "learning_rate": 0.0004916055846525994,
      "loss": 0.8723,
      "step": 164850
    },
    {
      "epoch": 1.7456979372330235,
      "grad_norm": 0.9035722017288208,
      "learning_rate": 0.0004915937110112195,
      "loss": 0.8755,
      "step": 164900
    },
    {
      "epoch": 1.7462272590130266,
      "grad_norm": 0.8816247582435608,
      "learning_rate": 0.000491581829121919,
      "loss": 0.8838,
      "step": 164950
    },
    {
      "epoch": 1.7467565807930299,
      "grad_norm": 0.9148899912834167,
      "learning_rate": 0.0004915699389851033,
      "loss": 0.8776,
      "step": 165000
    },
    {
      "epoch": 1.7467565807930299,
      "eval_loss": 0.7090807557106018,
      "eval_runtime": 46.7561,
      "eval_samples_per_second": 3591.614,
      "eval_steps_per_second": 448.968,
      "step": 165000
    },
    {
      "epoch": 1.7472859025730332,
      "grad_norm": 0.8472991585731506,
      "learning_rate": 0.0004915580406011785,
      "loss": 0.863,
      "step": 165050
    },
    {
      "epoch": 1.7478152243530365,
      "grad_norm": 0.9634751081466675,
      "learning_rate": 0.0004915461339705507,
      "loss": 0.8812,
      "step": 165100
    },
    {
      "epoch": 1.7483445461330396,
      "grad_norm": 0.8693431615829468,
      "learning_rate": 0.0004915342190936267,
      "loss": 0.8732,
      "step": 165150
    },
    {
      "epoch": 1.748873867913043,
      "grad_norm": 0.8657675981521606,
      "learning_rate": 0.0004915222959708128,
      "loss": 0.8741,
      "step": 165200
    },
    {
      "epoch": 1.7494031896930462,
      "grad_norm": 0.9101801514625549,
      "learning_rate": 0.0004915103646025164,
      "loss": 0.8649,
      "step": 165250
    },
    {
      "epoch": 1.7499325114730495,
      "grad_norm": 0.9208343029022217,
      "learning_rate": 0.0004914984249891447,
      "loss": 0.8784,
      "step": 165300
    },
    {
      "epoch": 1.7504618332530528,
      "grad_norm": 0.9020551443099976,
      "learning_rate": 0.0004914864771311054,
      "loss": 0.8767,
      "step": 165350
    },
    {
      "epoch": 1.7509911550330561,
      "grad_norm": 0.9186652898788452,
      "learning_rate": 0.0004914745210288062,
      "loss": 0.8914,
      "step": 165400
    },
    {
      "epoch": 1.7515204768130594,
      "grad_norm": 0.9686907529830933,
      "learning_rate": 0.0004914625566826556,
      "loss": 0.886,
      "step": 165450
    },
    {
      "epoch": 1.7520497985930628,
      "grad_norm": 0.8575824499130249,
      "learning_rate": 0.0004914505840930617,
      "loss": 0.8797,
      "step": 165500
    },
    {
      "epoch": 1.7520497985930628,
      "eval_loss": 0.7090407609939575,
      "eval_runtime": 46.7831,
      "eval_samples_per_second": 3589.545,
      "eval_steps_per_second": 448.709,
      "step": 165500
    },
    {
      "epoch": 1.752579120373066,
      "grad_norm": 0.8380921483039856,
      "learning_rate": 0.0004914386032604335,
      "loss": 0.8839,
      "step": 165550
    },
    {
      "epoch": 1.7531084421530694,
      "grad_norm": 0.8931159377098083,
      "learning_rate": 0.00049142661418518,
      "loss": 0.8743,
      "step": 165600
    },
    {
      "epoch": 1.7536377639330727,
      "grad_norm": 0.8797661662101746,
      "learning_rate": 0.0004914146168677103,
      "loss": 0.8806,
      "step": 165650
    },
    {
      "epoch": 1.754167085713076,
      "grad_norm": 1.0106786489486694,
      "learning_rate": 0.0004914026113084342,
      "loss": 0.8735,
      "step": 165700
    },
    {
      "epoch": 1.754696407493079,
      "grad_norm": 0.9332058429718018,
      "learning_rate": 0.0004913905975077613,
      "loss": 0.8812,
      "step": 165750
    },
    {
      "epoch": 1.7552257292730824,
      "grad_norm": 0.8909460306167603,
      "learning_rate": 0.0004913785754661022,
      "loss": 0.8682,
      "step": 165800
    },
    {
      "epoch": 1.7557550510530857,
      "grad_norm": 0.7922852039337158,
      "learning_rate": 0.0004913667858702666,
      "loss": 0.8763,
      "step": 165850
    },
    {
      "epoch": 1.7562843728330888,
      "grad_norm": 0.8452345132827759,
      "learning_rate": 0.0004913547475126652,
      "loss": 0.8777,
      "step": 165900
    },
    {
      "epoch": 1.7568136946130921,
      "grad_norm": 0.876031219959259,
      "learning_rate": 0.0004913427009153014,
      "loss": 0.8763,
      "step": 165950
    },
    {
      "epoch": 1.7573430163930954,
      "grad_norm": 0.9241526126861572,
      "learning_rate": 0.0004913306460785861,
      "loss": 0.8785,
      "step": 166000
    },
    {
      "epoch": 1.7573430163930954,
      "eval_loss": 0.7071133852005005,
      "eval_runtime": 46.7275,
      "eval_samples_per_second": 3593.814,
      "eval_steps_per_second": 449.243,
      "step": 166000
    },
    {
      "epoch": 1.7578723381730987,
      "grad_norm": 0.928104043006897,
      "learning_rate": 0.0004913185830029312,
      "loss": 0.8721,
      "step": 166050
    },
    {
      "epoch": 1.758401659953102,
      "grad_norm": 0.8870218992233276,
      "learning_rate": 0.0004913065116887483,
      "loss": 0.8745,
      "step": 166100
    },
    {
      "epoch": 1.7589309817331054,
      "grad_norm": 0.8429047465324402,
      "learning_rate": 0.0004912944321364496,
      "loss": 0.8603,
      "step": 166150
    },
    {
      "epoch": 1.7594603035131087,
      "grad_norm": 0.882235586643219,
      "learning_rate": 0.0004912823443464475,
      "loss": 0.8673,
      "step": 166200
    },
    {
      "epoch": 1.759989625293112,
      "grad_norm": 0.9256581664085388,
      "learning_rate": 0.0004912702483191547,
      "loss": 0.8789,
      "step": 166250
    },
    {
      "epoch": 1.7605189470731153,
      "grad_norm": 0.9406282305717468,
      "learning_rate": 0.000491258144054984,
      "loss": 0.8796,
      "step": 166300
    },
    {
      "epoch": 1.7610482688531186,
      "grad_norm": 0.925284206867218,
      "learning_rate": 0.0004912460315543488,
      "loss": 0.8834,
      "step": 166350
    },
    {
      "epoch": 1.761577590633122,
      "grad_norm": 0.8491851687431335,
      "learning_rate": 0.0004912339108176626,
      "loss": 0.8796,
      "step": 166400
    },
    {
      "epoch": 1.7621069124131252,
      "grad_norm": 0.850807249546051,
      "learning_rate": 0.000491221781845339,
      "loss": 0.8699,
      "step": 166450
    },
    {
      "epoch": 1.7626362341931283,
      "grad_norm": 0.8230345249176025,
      "learning_rate": 0.0004912096446377924,
      "loss": 0.8793,
      "step": 166500
    },
    {
      "epoch": 1.7626362341931283,
      "eval_loss": 0.704513669013977,
      "eval_runtime": 46.7484,
      "eval_samples_per_second": 3592.208,
      "eval_steps_per_second": 449.042,
      "step": 166500
    },
    {
      "epoch": 1.7631655559731316,
      "grad_norm": 0.8577049970626831,
      "learning_rate": 0.000491197499195437,
      "loss": 0.8763,
      "step": 166550
    },
    {
      "epoch": 1.763694877753135,
      "grad_norm": 0.9202590584754944,
      "learning_rate": 0.0004911853455186873,
      "loss": 0.8725,
      "step": 166600
    },
    {
      "epoch": 1.764224199533138,
      "grad_norm": 1.0105069875717163,
      "learning_rate": 0.0004911731836079585,
      "loss": 0.8627,
      "step": 166650
    },
    {
      "epoch": 1.7647535213131413,
      "grad_norm": 0.9420235753059387,
      "learning_rate": 0.0004911610134636656,
      "loss": 0.8577,
      "step": 166700
    },
    {
      "epoch": 1.7652828430931446,
      "grad_norm": 0.9015654921531677,
      "learning_rate": 0.0004911488350862241,
      "loss": 0.8594,
      "step": 166750
    },
    {
      "epoch": 1.765812164873148,
      "grad_norm": 0.8696056604385376,
      "learning_rate": 0.0004911366484760497,
      "loss": 0.8666,
      "step": 166800
    },
    {
      "epoch": 1.7663414866531513,
      "grad_norm": 0.8203408122062683,
      "learning_rate": 0.0004911244536335588,
      "loss": 0.8659,
      "step": 166850
    },
    {
      "epoch": 1.7668708084331546,
      "grad_norm": 0.8870846629142761,
      "learning_rate": 0.0004911122505591673,
      "loss": 0.8673,
      "step": 166900
    },
    {
      "epoch": 1.767400130213158,
      "grad_norm": 0.9858773350715637,
      "learning_rate": 0.0004911000392532922,
      "loss": 0.8691,
      "step": 166950
    },
    {
      "epoch": 1.7679294519931612,
      "grad_norm": 0.7949567437171936,
      "learning_rate": 0.00049108781971635,
      "loss": 0.865,
      "step": 167000
    },
    {
      "epoch": 1.7679294519931612,
      "eval_loss": 0.7024163603782654,
      "eval_runtime": 46.7821,
      "eval_samples_per_second": 3589.621,
      "eval_steps_per_second": 448.719,
      "step": 167000
    },
    {
      "epoch": 1.7684587737731645,
      "grad_norm": 0.8380022048950195,
      "learning_rate": 0.000491075591948758,
      "loss": 0.8852,
      "step": 167050
    },
    {
      "epoch": 1.7689880955531678,
      "grad_norm": 0.9285749793052673,
      "learning_rate": 0.0004910633559509339,
      "loss": 0.8808,
      "step": 167100
    },
    {
      "epoch": 1.7695174173331711,
      "grad_norm": 0.8721461892127991,
      "learning_rate": 0.0004910511117232951,
      "loss": 0.8751,
      "step": 167150
    },
    {
      "epoch": 1.7700467391131744,
      "grad_norm": 0.9196916222572327,
      "learning_rate": 0.0004910388592662598,
      "loss": 0.8661,
      "step": 167200
    },
    {
      "epoch": 1.7705760608931775,
      "grad_norm": 0.8248645663261414,
      "learning_rate": 0.0004910265985802462,
      "loss": 0.8763,
      "step": 167250
    },
    {
      "epoch": 1.7711053826731809,
      "grad_norm": 0.9597086310386658,
      "learning_rate": 0.0004910143296656729,
      "loss": 0.8787,
      "step": 167300
    },
    {
      "epoch": 1.7716347044531842,
      "grad_norm": 0.8432199954986572,
      "learning_rate": 0.0004910020525229589,
      "loss": 0.8722,
      "step": 167350
    },
    {
      "epoch": 1.7721640262331873,
      "grad_norm": 0.8809313178062439,
      "learning_rate": 0.0004909897671525231,
      "loss": 0.8747,
      "step": 167400
    },
    {
      "epoch": 1.7726933480131906,
      "grad_norm": 0.8087000250816345,
      "learning_rate": 0.0004909774735547851,
      "loss": 0.8908,
      "step": 167450
    },
    {
      "epoch": 1.7732226697931939,
      "grad_norm": 0.8649592995643616,
      "learning_rate": 0.0004909651717301645,
      "loss": 0.8825,
      "step": 167500
    },
    {
      "epoch": 1.7732226697931939,
      "eval_loss": 0.6979435086250305,
      "eval_runtime": 46.7264,
      "eval_samples_per_second": 3593.902,
      "eval_steps_per_second": 449.254,
      "step": 167500
    },
    {
      "epoch": 1.7737519915731972,
      "grad_norm": 0.7749015688896179,
      "learning_rate": 0.0004909528616790813,
      "loss": 0.8575,
      "step": 167550
    },
    {
      "epoch": 1.7742813133532005,
      "grad_norm": 0.9751331806182861,
      "learning_rate": 0.0004909405434019557,
      "loss": 0.8726,
      "step": 167600
    },
    {
      "epoch": 1.7748106351332038,
      "grad_norm": 0.8691196441650391,
      "learning_rate": 0.0004909282168992084,
      "loss": 0.8722,
      "step": 167650
    },
    {
      "epoch": 1.7753399569132071,
      "grad_norm": 0.9358083605766296,
      "learning_rate": 0.0004909158821712602,
      "loss": 0.8736,
      "step": 167700
    },
    {
      "epoch": 1.7758692786932104,
      "grad_norm": 0.9126379489898682,
      "learning_rate": 0.000490903539218532,
      "loss": 0.8752,
      "step": 167750
    },
    {
      "epoch": 1.7763986004732137,
      "grad_norm": 0.8745730519294739,
      "learning_rate": 0.0004908911880414454,
      "loss": 0.8753,
      "step": 167800
    },
    {
      "epoch": 1.776927922253217,
      "grad_norm": 0.8382083177566528,
      "learning_rate": 0.0004908790759090342,
      "loss": 0.8764,
      "step": 167850
    },
    {
      "epoch": 1.7774572440332204,
      "grad_norm": 0.9187783598899841,
      "learning_rate": 0.0004908667084489621,
      "loss": 0.8785,
      "step": 167900
    },
    {
      "epoch": 1.7779865658132237,
      "grad_norm": 0.9222813844680786,
      "learning_rate": 0.0004908543327657889,
      "loss": 0.8629,
      "step": 167950
    },
    {
      "epoch": 1.7785158875932268,
      "grad_norm": 0.8508503437042236,
      "learning_rate": 0.000490841948859937,
      "loss": 0.8757,
      "step": 168000
    },
    {
      "epoch": 1.7785158875932268,
      "eval_loss": 0.7030638456344604,
      "eval_runtime": 46.8249,
      "eval_samples_per_second": 3586.338,
      "eval_steps_per_second": 448.308,
      "step": 168000
    },
    {
      "epoch": 1.77904520937323,
      "grad_norm": 0.983550488948822,
      "learning_rate": 0.0004908295567318293,
      "loss": 0.8604,
      "step": 168050
    },
    {
      "epoch": 1.7795745311532334,
      "grad_norm": 0.852654218673706,
      "learning_rate": 0.0004908171563818889,
      "loss": 0.862,
      "step": 168100
    },
    {
      "epoch": 1.7801038529332367,
      "grad_norm": 0.884574294090271,
      "learning_rate": 0.0004908047478105391,
      "loss": 0.8604,
      "step": 168150
    },
    {
      "epoch": 1.7806331747132398,
      "grad_norm": 0.8757594227790833,
      "learning_rate": 0.0004907923310182036,
      "loss": 0.8769,
      "step": 168200
    },
    {
      "epoch": 1.781162496493243,
      "grad_norm": 0.7561733722686768,
      "learning_rate": 0.0004907799060053061,
      "loss": 0.876,
      "step": 168250
    },
    {
      "epoch": 1.7816918182732464,
      "grad_norm": 0.8270337581634521,
      "learning_rate": 0.000490767472772271,
      "loss": 0.8636,
      "step": 168300
    },
    {
      "epoch": 1.7822211400532497,
      "grad_norm": 0.8539989590644836,
      "learning_rate": 0.0004907550313195227,
      "loss": 0.8676,
      "step": 168350
    },
    {
      "epoch": 1.782750461833253,
      "grad_norm": 0.9434435963630676,
      "learning_rate": 0.0004907425816474859,
      "loss": 0.8592,
      "step": 168400
    },
    {
      "epoch": 1.7832797836132563,
      "grad_norm": 0.8347811102867126,
      "learning_rate": 0.0004907301237565856,
      "loss": 0.8634,
      "step": 168450
    },
    {
      "epoch": 1.7838091053932597,
      "grad_norm": 0.8436352610588074,
      "learning_rate": 0.0004907176576472472,
      "loss": 0.8741,
      "step": 168500
    },
    {
      "epoch": 1.7838091053932597,
      "eval_loss": 0.702574610710144,
      "eval_runtime": 46.6774,
      "eval_samples_per_second": 3597.676,
      "eval_steps_per_second": 449.726,
      "step": 168500
    },
    {
      "epoch": 1.784338427173263,
      "grad_norm": 0.8443349003791809,
      "learning_rate": 0.0004907051833198962,
      "loss": 0.8699,
      "step": 168550
    },
    {
      "epoch": 1.7848677489532663,
      "grad_norm": 0.9063668251037598,
      "learning_rate": 0.0004906927007749585,
      "loss": 0.8796,
      "step": 168600
    },
    {
      "epoch": 1.7853970707332696,
      "grad_norm": 0.9333796501159668,
      "learning_rate": 0.0004906802100128604,
      "loss": 0.8719,
      "step": 168650
    },
    {
      "epoch": 1.785926392513273,
      "grad_norm": 0.8609647154808044,
      "learning_rate": 0.0004906677110340281,
      "loss": 0.8865,
      "step": 168700
    },
    {
      "epoch": 1.786455714293276,
      "grad_norm": 0.8454821705818176,
      "learning_rate": 0.0004906552038388884,
      "loss": 0.8639,
      "step": 168750
    },
    {
      "epoch": 1.7869850360732793,
      "grad_norm": 0.9031498432159424,
      "learning_rate": 0.0004906426884278683,
      "loss": 0.8578,
      "step": 168800
    },
    {
      "epoch": 1.7875143578532826,
      "grad_norm": 0.9300803542137146,
      "learning_rate": 0.0004906301648013951,
      "loss": 0.8504,
      "step": 168850
    },
    {
      "epoch": 1.788043679633286,
      "grad_norm": 0.8562518358230591,
      "learning_rate": 0.0004906176329598964,
      "loss": 0.8584,
      "step": 168900
    },
    {
      "epoch": 1.788573001413289,
      "grad_norm": 0.9269290566444397,
      "learning_rate": 0.0004906050929037997,
      "loss": 0.8686,
      "step": 168950
    },
    {
      "epoch": 1.7891023231932923,
      "grad_norm": 0.8941401839256287,
      "learning_rate": 0.0004905925446335337,
      "loss": 0.8769,
      "step": 169000
    },
    {
      "epoch": 1.7891023231932923,
      "eval_loss": 0.6982111930847168,
      "eval_runtime": 46.7734,
      "eval_samples_per_second": 3590.285,
      "eval_steps_per_second": 448.802,
      "step": 169000
    },
    {
      "epoch": 1.7896316449732956,
      "grad_norm": 0.853397011756897,
      "learning_rate": 0.0004905799881495262,
      "loss": 0.8716,
      "step": 169050
    },
    {
      "epoch": 1.790160966753299,
      "grad_norm": 0.9620480537414551,
      "learning_rate": 0.0004905674234522063,
      "loss": 0.8586,
      "step": 169100
    },
    {
      "epoch": 1.7906902885333023,
      "grad_norm": 0.879595935344696,
      "learning_rate": 0.0004905548505420026,
      "loss": 0.8656,
      "step": 169150
    },
    {
      "epoch": 1.7912196103133056,
      "grad_norm": 0.9336001873016357,
      "learning_rate": 0.0004905422694193448,
      "loss": 0.8658,
      "step": 169200
    },
    {
      "epoch": 1.7917489320933089,
      "grad_norm": 0.8595922589302063,
      "learning_rate": 0.0004905296800846619,
      "loss": 0.8844,
      "step": 169250
    },
    {
      "epoch": 1.7922782538733122,
      "grad_norm": 0.8000441193580627,
      "learning_rate": 0.000490517082538384,
      "loss": 0.853,
      "step": 169300
    },
    {
      "epoch": 1.7928075756533155,
      "grad_norm": 0.9591267704963684,
      "learning_rate": 0.0004905044767809412,
      "loss": 0.8573,
      "step": 169350
    },
    {
      "epoch": 1.7933368974333188,
      "grad_norm": 0.824958086013794,
      "learning_rate": 0.0004904918628127637,
      "loss": 0.8747,
      "step": 169400
    },
    {
      "epoch": 1.7938662192133221,
      "grad_norm": 0.8847252130508423,
      "learning_rate": 0.0004904792406342822,
      "loss": 0.8757,
      "step": 169450
    },
    {
      "epoch": 1.7943955409933252,
      "grad_norm": 0.8832353353500366,
      "learning_rate": 0.0004904666102459275,
      "loss": 0.8796,
      "step": 169500
    },
    {
      "epoch": 1.7943955409933252,
      "eval_loss": 0.699067234992981,
      "eval_runtime": 46.7938,
      "eval_samples_per_second": 3588.727,
      "eval_steps_per_second": 448.607,
      "step": 169500
    },
    {
      "epoch": 1.7949248627733285,
      "grad_norm": 0.7645460963249207,
      "learning_rate": 0.0004904539716481311,
      "loss": 0.8615,
      "step": 169550
    },
    {
      "epoch": 1.7954541845533318,
      "grad_norm": 0.8925110101699829,
      "learning_rate": 0.0004904413248413242,
      "loss": 0.8621,
      "step": 169600
    },
    {
      "epoch": 1.7959835063333351,
      "grad_norm": 0.9465000629425049,
      "learning_rate": 0.0004904286698259387,
      "loss": 0.8571,
      "step": 169650
    },
    {
      "epoch": 1.7965128281133382,
      "grad_norm": 0.8657183051109314,
      "learning_rate": 0.0004904160066024066,
      "loss": 0.8842,
      "step": 169700
    },
    {
      "epoch": 1.7970421498933415,
      "grad_norm": 0.9096059799194336,
      "learning_rate": 0.0004904033351711601,
      "loss": 0.8763,
      "step": 169750
    },
    {
      "epoch": 1.7975714716733449,
      "grad_norm": 0.8128745555877686,
      "learning_rate": 0.0004903906555326319,
      "loss": 0.8738,
      "step": 169800
    },
    {
      "epoch": 1.7981007934533482,
      "grad_norm": 0.8366248607635498,
      "learning_rate": 0.000490377967687255,
      "loss": 0.8591,
      "step": 169850
    },
    {
      "epoch": 1.7986301152333515,
      "grad_norm": 1.0627034902572632,
      "learning_rate": 0.0004903655256369183,
      "loss": 0.8581,
      "step": 169900
    },
    {
      "epoch": 1.7991594370133548,
      "grad_norm": 0.9375423789024353,
      "learning_rate": 0.0004903528215432589,
      "loss": 0.8632,
      "step": 169950
    },
    {
      "epoch": 1.799688758793358,
      "grad_norm": 0.8357094526290894,
      "learning_rate": 0.0004903401092440422,
      "loss": 0.8851,
      "step": 170000
    },
    {
      "epoch": 1.799688758793358,
      "eval_loss": 0.6986677646636963,
      "eval_runtime": 46.7612,
      "eval_samples_per_second": 3591.228,
      "eval_steps_per_second": 448.92,
      "step": 170000
    },
    {
      "epoch": 1.8002180805733614,
      "grad_norm": 0.873450756072998,
      "learning_rate": 0.0004903273887397024,
      "loss": 0.8882,
      "step": 170050
    },
    {
      "epoch": 1.8007474023533647,
      "grad_norm": 0.776614785194397,
      "learning_rate": 0.0004903146600306737,
      "loss": 0.8556,
      "step": 170100
    },
    {
      "epoch": 1.801276724133368,
      "grad_norm": 0.8247567415237427,
      "learning_rate": 0.0004903019231173906,
      "loss": 0.8646,
      "step": 170150
    },
    {
      "epoch": 1.8018060459133713,
      "grad_norm": 0.8513947129249573,
      "learning_rate": 0.000490289178000288,
      "loss": 0.8629,
      "step": 170200
    },
    {
      "epoch": 1.8023353676933744,
      "grad_norm": 0.9254823327064514,
      "learning_rate": 0.000490276424679801,
      "loss": 0.8759,
      "step": 170250
    },
    {
      "epoch": 1.8028646894733777,
      "grad_norm": 0.8135215640068054,
      "learning_rate": 0.0004902636631563649,
      "loss": 0.8686,
      "step": 170300
    },
    {
      "epoch": 1.803394011253381,
      "grad_norm": 0.8956213593482971,
      "learning_rate": 0.0004902508934304155,
      "loss": 0.8814,
      "step": 170350
    },
    {
      "epoch": 1.8039233330333844,
      "grad_norm": 0.9171635508537292,
      "learning_rate": 0.0004902381155023887,
      "loss": 0.8677,
      "step": 170400
    },
    {
      "epoch": 1.8044526548133875,
      "grad_norm": 0.8000496029853821,
      "learning_rate": 0.0004902253293727208,
      "loss": 0.8735,
      "step": 170450
    },
    {
      "epoch": 1.8049819765933908,
      "grad_norm": 0.8930761814117432,
      "learning_rate": 0.0004902125350418482,
      "loss": 0.8681,
      "step": 170500
    },
    {
      "epoch": 1.8049819765933908,
      "eval_loss": 0.6950623989105225,
      "eval_runtime": 46.6889,
      "eval_samples_per_second": 3596.789,
      "eval_steps_per_second": 449.615,
      "step": 170500
    },
    {
      "epoch": 1.805511298373394,
      "grad_norm": 0.8840646147727966,
      "learning_rate": 0.0004901997325102077,
      "loss": 0.8771,
      "step": 170550
    },
    {
      "epoch": 1.8060406201533974,
      "grad_norm": 0.8849859833717346,
      "learning_rate": 0.0004901869217782365,
      "loss": 0.8583,
      "step": 170600
    },
    {
      "epoch": 1.8065699419334007,
      "grad_norm": 0.8746247291564941,
      "learning_rate": 0.0004901741028463718,
      "loss": 0.8512,
      "step": 170650
    },
    {
      "epoch": 1.807099263713404,
      "grad_norm": 0.8898013234138489,
      "learning_rate": 0.0004901612757150515,
      "loss": 0.8736,
      "step": 170700
    },
    {
      "epoch": 1.8076285854934073,
      "grad_norm": 0.9555509686470032,
      "learning_rate": 0.0004901484403847132,
      "loss": 0.8695,
      "step": 170750
    },
    {
      "epoch": 1.8081579072734106,
      "grad_norm": 0.8949161767959595,
      "learning_rate": 0.0004901355968557952,
      "loss": 0.8766,
      "step": 170800
    },
    {
      "epoch": 1.808687229053414,
      "grad_norm": 0.9281350374221802,
      "learning_rate": 0.000490122745128736,
      "loss": 0.8716,
      "step": 170850
    },
    {
      "epoch": 1.8092165508334173,
      "grad_norm": 0.9232163429260254,
      "learning_rate": 0.0004901098852039743,
      "loss": 0.8587,
      "step": 170900
    },
    {
      "epoch": 1.8097458726134206,
      "grad_norm": 0.9093007445335388,
      "learning_rate": 0.0004900970170819492,
      "loss": 0.8673,
      "step": 170950
    },
    {
      "epoch": 1.8102751943934237,
      "grad_norm": 0.8904637098312378,
      "learning_rate": 0.0004900841407631001,
      "loss": 0.871,
      "step": 171000
    },
    {
      "epoch": 1.8102751943934237,
      "eval_loss": 0.6914188265800476,
      "eval_runtime": 46.7855,
      "eval_samples_per_second": 3589.361,
      "eval_steps_per_second": 448.686,
      "step": 171000
    },
    {
      "epoch": 1.810804516173427,
      "grad_norm": 0.888139009475708,
      "learning_rate": 0.0004900712562478664,
      "loss": 0.8642,
      "step": 171050
    },
    {
      "epoch": 1.8113338379534303,
      "grad_norm": 0.9658150672912598,
      "learning_rate": 0.000490058363536688,
      "loss": 0.8651,
      "step": 171100
    },
    {
      "epoch": 1.8118631597334336,
      "grad_norm": 0.7975895404815674,
      "learning_rate": 0.0004900454626300052,
      "loss": 0.8677,
      "step": 171150
    },
    {
      "epoch": 1.8123924815134367,
      "grad_norm": 0.9321463108062744,
      "learning_rate": 0.0004900325535282582,
      "loss": 0.8664,
      "step": 171200
    },
    {
      "epoch": 1.81292180329344,
      "grad_norm": 0.8245563507080078,
      "learning_rate": 0.0004900196362318881,
      "loss": 0.8629,
      "step": 171250
    },
    {
      "epoch": 1.8134511250734433,
      "grad_norm": 0.8708282113075256,
      "learning_rate": 0.0004900067107413354,
      "loss": 0.8652,
      "step": 171300
    },
    {
      "epoch": 1.8139804468534466,
      "grad_norm": 0.9421404004096985,
      "learning_rate": 0.0004899937770570417,
      "loss": 0.8679,
      "step": 171350
    },
    {
      "epoch": 1.81450976863345,
      "grad_norm": 0.9197649359703064,
      "learning_rate": 0.0004899808351794485,
      "loss": 0.8629,
      "step": 171400
    },
    {
      "epoch": 1.8150390904134532,
      "grad_norm": 0.8829345703125,
      "learning_rate": 0.0004899678851089976,
      "loss": 0.8576,
      "step": 171450
    },
    {
      "epoch": 1.8155684121934565,
      "grad_norm": 0.8938177824020386,
      "learning_rate": 0.0004899549268461311,
      "loss": 0.8521,
      "step": 171500
    },
    {
      "epoch": 1.8155684121934565,
      "eval_loss": 0.6940782070159912,
      "eval_runtime": 46.8525,
      "eval_samples_per_second": 3584.225,
      "eval_steps_per_second": 448.044,
      "step": 171500
    },
    {
      "epoch": 1.8160977339734599,
      "grad_norm": 0.8945884108543396,
      "learning_rate": 0.0004899419603912914,
      "loss": 0.8614,
      "step": 171550
    },
    {
      "epoch": 1.8166270557534632,
      "grad_norm": 0.8302927017211914,
      "learning_rate": 0.0004899289857449211,
      "loss": 0.8603,
      "step": 171600
    },
    {
      "epoch": 1.8171563775334665,
      "grad_norm": 0.9168539047241211,
      "learning_rate": 0.0004899160029074633,
      "loss": 0.8591,
      "step": 171650
    },
    {
      "epoch": 1.8176856993134698,
      "grad_norm": 0.9204575419425964,
      "learning_rate": 0.0004899030118793611,
      "loss": 0.8626,
      "step": 171700
    },
    {
      "epoch": 1.8182150210934729,
      "grad_norm": 0.9258608222007751,
      "learning_rate": 0.0004898900126610581,
      "loss": 0.8612,
      "step": 171750
    },
    {
      "epoch": 1.8187443428734762,
      "grad_norm": 0.8592893481254578,
      "learning_rate": 0.0004898770052529979,
      "loss": 0.8764,
      "step": 171800
    },
    {
      "epoch": 1.8192736646534795,
      "grad_norm": 0.93010014295578,
      "learning_rate": 0.0004898639896556248,
      "loss": 0.8703,
      "step": 171850
    },
    {
      "epoch": 1.8198029864334828,
      "grad_norm": 0.8124525547027588,
      "learning_rate": 0.000489851226425356,
      "loss": 0.8586,
      "step": 171900
    },
    {
      "epoch": 1.820332308213486,
      "grad_norm": 0.8569565415382385,
      "learning_rate": 0.0004898381946144545,
      "loss": 0.8556,
      "step": 171950
    },
    {
      "epoch": 1.8208616299934892,
      "grad_norm": 0.9669764041900635,
      "learning_rate": 0.0004898251546155649,
      "loss": 0.8657,
      "step": 172000
    },
    {
      "epoch": 1.8208616299934892,
      "eval_loss": 0.6924527883529663,
      "eval_runtime": 46.8787,
      "eval_samples_per_second": 3582.222,
      "eval_steps_per_second": 447.794,
      "step": 172000
    },
    {
      "epoch": 1.8213909517734925,
      "grad_norm": 0.8911471962928772,
      "learning_rate": 0.0004898121064291324,
      "loss": 0.8505,
      "step": 172050
    },
    {
      "epoch": 1.8219202735534958,
      "grad_norm": 0.877822995185852,
      "learning_rate": 0.0004897990500556025,
      "loss": 0.8565,
      "step": 172100
    },
    {
      "epoch": 1.8224495953334992,
      "grad_norm": 0.9595075845718384,
      "learning_rate": 0.0004897859854954212,
      "loss": 0.8609,
      "step": 172150
    },
    {
      "epoch": 1.8229789171135025,
      "grad_norm": 0.8806365132331848,
      "learning_rate": 0.0004897729127490341,
      "loss": 0.8724,
      "step": 172200
    },
    {
      "epoch": 1.8235082388935058,
      "grad_norm": 0.9419656991958618,
      "learning_rate": 0.0004897598318168878,
      "loss": 0.8701,
      "step": 172250
    },
    {
      "epoch": 1.824037560673509,
      "grad_norm": 0.8747316598892212,
      "learning_rate": 0.0004897467426994288,
      "loss": 0.8653,
      "step": 172300
    },
    {
      "epoch": 1.8245668824535124,
      "grad_norm": 0.8735344409942627,
      "learning_rate": 0.0004897336453971038,
      "loss": 0.8708,
      "step": 172350
    },
    {
      "epoch": 1.8250962042335157,
      "grad_norm": 0.9622202515602112,
      "learning_rate": 0.0004897205399103601,
      "loss": 0.8443,
      "step": 172400
    },
    {
      "epoch": 1.825625526013519,
      "grad_norm": 0.9014040231704712,
      "learning_rate": 0.0004897074262396452,
      "loss": 0.8617,
      "step": 172450
    },
    {
      "epoch": 1.826154847793522,
      "grad_norm": 0.9037727117538452,
      "learning_rate": 0.0004896943043854066,
      "loss": 0.8749,
      "step": 172500
    },
    {
      "epoch": 1.826154847793522,
      "eval_loss": 0.6909127235412598,
      "eval_runtime": 46.6906,
      "eval_samples_per_second": 3596.658,
      "eval_steps_per_second": 449.598,
      "step": 172500
    },
    {
      "epoch": 1.8266841695735254,
      "grad_norm": 0.8905820250511169,
      "learning_rate": 0.0004896811743480923,
      "loss": 0.8716,
      "step": 172550
    },
    {
      "epoch": 1.8272134913535287,
      "grad_norm": 0.8276104927062988,
      "learning_rate": 0.0004896680361281506,
      "loss": 0.8634,
      "step": 172600
    },
    {
      "epoch": 1.827742813133532,
      "grad_norm": 0.8749249577522278,
      "learning_rate": 0.0004896548897260301,
      "loss": 0.8555,
      "step": 172650
    },
    {
      "epoch": 1.8282721349135351,
      "grad_norm": 0.9900726675987244,
      "learning_rate": 0.0004896417351421796,
      "loss": 0.8561,
      "step": 172700
    },
    {
      "epoch": 1.8288014566935384,
      "grad_norm": 0.919427752494812,
      "learning_rate": 0.0004896285723770481,
      "loss": 0.8448,
      "step": 172750
    },
    {
      "epoch": 1.8293307784735418,
      "grad_norm": 0.8775259256362915,
      "learning_rate": 0.000489615401431085,
      "loss": 0.836,
      "step": 172800
    },
    {
      "epoch": 1.829860100253545,
      "grad_norm": 0.8217467069625854,
      "learning_rate": 0.0004896022223047399,
      "loss": 0.8685,
      "step": 172850
    },
    {
      "epoch": 1.8303894220335484,
      "grad_norm": 0.9244306087493896,
      "learning_rate": 0.000489589034998463,
      "loss": 0.8528,
      "step": 172900
    },
    {
      "epoch": 1.8309187438135517,
      "grad_norm": 0.8799041509628296,
      "learning_rate": 0.0004895758395127042,
      "loss": 0.8681,
      "step": 172950
    },
    {
      "epoch": 1.831448065593555,
      "grad_norm": 0.8442471027374268,
      "learning_rate": 0.0004895626358479141,
      "loss": 0.8688,
      "step": 173000
    },
    {
      "epoch": 1.831448065593555,
      "eval_loss": 0.6918154954910278,
      "eval_runtime": 46.6888,
      "eval_samples_per_second": 3596.793,
      "eval_steps_per_second": 449.615,
      "step": 173000
    },
    {
      "epoch": 1.8319773873735583,
      "grad_norm": 0.8837658166885376,
      "learning_rate": 0.0004895494240045434,
      "loss": 0.8568,
      "step": 173050
    },
    {
      "epoch": 1.8325067091535616,
      "grad_norm": 0.8551214337348938,
      "learning_rate": 0.0004895362039830433,
      "loss": 0.8671,
      "step": 173100
    },
    {
      "epoch": 1.833036030933565,
      "grad_norm": 0.8437561988830566,
      "learning_rate": 0.0004895229757838651,
      "loss": 0.8642,
      "step": 173150
    },
    {
      "epoch": 1.8335653527135682,
      "grad_norm": 0.9533300995826721,
      "learning_rate": 0.0004895097394074602,
      "loss": 0.8722,
      "step": 173200
    },
    {
      "epoch": 1.8340946744935716,
      "grad_norm": 0.8852192163467407,
      "learning_rate": 0.0004894964948542808,
      "loss": 0.8776,
      "step": 173250
    },
    {
      "epoch": 1.8346239962735746,
      "grad_norm": 0.8636810779571533,
      "learning_rate": 0.0004894832421247788,
      "loss": 0.8483,
      "step": 173300
    },
    {
      "epoch": 1.835153318053578,
      "grad_norm": 0.7802118062973022,
      "learning_rate": 0.0004894699812194068,
      "loss": 0.8478,
      "step": 173350
    },
    {
      "epoch": 1.8356826398335813,
      "grad_norm": 0.8189865350723267,
      "learning_rate": 0.0004894567121386174,
      "loss": 0.8653,
      "step": 173400
    },
    {
      "epoch": 1.8362119616135844,
      "grad_norm": 0.8844152688980103,
      "learning_rate": 0.0004894434348828637,
      "loss": 0.8463,
      "step": 173450
    },
    {
      "epoch": 1.8367412833935877,
      "grad_norm": 0.8342517614364624,
      "learning_rate": 0.0004894301494525989,
      "loss": 0.8597,
      "step": 173500
    },
    {
      "epoch": 1.8367412833935877,
      "eval_loss": 0.6868424415588379,
      "eval_runtime": 46.7848,
      "eval_samples_per_second": 3589.417,
      "eval_steps_per_second": 448.693,
      "step": 173500
    },
    {
      "epoch": 1.837270605173591,
      "grad_norm": 0.865352988243103,
      "learning_rate": 0.0004894168558482767,
      "loss": 0.8543,
      "step": 173550
    },
    {
      "epoch": 1.8377999269535943,
      "grad_norm": 0.814298152923584,
      "learning_rate": 0.0004894035540703507,
      "loss": 0.8604,
      "step": 173600
    },
    {
      "epoch": 1.8383292487335976,
      "grad_norm": 0.8904048204421997,
      "learning_rate": 0.0004893902441192753,
      "loss": 0.8668,
      "step": 173650
    },
    {
      "epoch": 1.838858570513601,
      "grad_norm": 0.9104036092758179,
      "learning_rate": 0.0004893769259955047,
      "loss": 0.8698,
      "step": 173700
    },
    {
      "epoch": 1.8393878922936042,
      "grad_norm": 0.8321543335914612,
      "learning_rate": 0.0004893635996994937,
      "loss": 0.8539,
      "step": 173750
    },
    {
      "epoch": 1.8399172140736075,
      "grad_norm": 0.8102163076400757,
      "learning_rate": 0.0004893502652316971,
      "loss": 0.8571,
      "step": 173800
    },
    {
      "epoch": 1.8404465358536108,
      "grad_norm": 1.0084269046783447,
      "learning_rate": 0.0004893369225925702,
      "loss": 0.875,
      "step": 173850
    },
    {
      "epoch": 1.8409758576336142,
      "grad_norm": 0.8562384247779846,
      "learning_rate": 0.0004893235717825686,
      "loss": 0.8675,
      "step": 173900
    },
    {
      "epoch": 1.8415051794136175,
      "grad_norm": 0.8999698162078857,
      "learning_rate": 0.0004893104800618237,
      "loss": 0.8547,
      "step": 173950
    },
    {
      "epoch": 1.8420345011936208,
      "grad_norm": 0.8595839738845825,
      "learning_rate": 0.000489297113074835,
      "loss": 0.8643,
      "step": 174000
    },
    {
      "epoch": 1.8420345011936208,
      "eval_loss": 0.6876632571220398,
      "eval_runtime": 46.7059,
      "eval_samples_per_second": 3595.477,
      "eval_steps_per_second": 449.451,
      "step": 174000
    },
    {
      "epoch": 1.8425638229736239,
      "grad_norm": 0.9253560304641724,
      "learning_rate": 0.0004892837379183306,
      "loss": 0.8498,
      "step": 174050
    },
    {
      "epoch": 1.8430931447536272,
      "grad_norm": 0.8827594518661499,
      "learning_rate": 0.0004892703545927671,
      "loss": 0.8584,
      "step": 174100
    },
    {
      "epoch": 1.8436224665336305,
      "grad_norm": 0.8210685849189758,
      "learning_rate": 0.0004892569630986016,
      "loss": 0.8473,
      "step": 174150
    },
    {
      "epoch": 1.8441517883136336,
      "grad_norm": 0.8835607767105103,
      "learning_rate": 0.000489243563436291,
      "loss": 0.8724,
      "step": 174200
    },
    {
      "epoch": 1.8446811100936369,
      "grad_norm": 0.815778374671936,
      "learning_rate": 0.0004892301556062929,
      "loss": 0.8627,
      "step": 174250
    },
    {
      "epoch": 1.8452104318736402,
      "grad_norm": 0.9105529189109802,
      "learning_rate": 0.0004892167396090651,
      "loss": 0.8572,
      "step": 174300
    },
    {
      "epoch": 1.8457397536536435,
      "grad_norm": 0.872959315776825,
      "learning_rate": 0.0004892033154450655,
      "loss": 0.8629,
      "step": 174350
    },
    {
      "epoch": 1.8462690754336468,
      "grad_norm": 0.9451736211776733,
      "learning_rate": 0.0004891898831147523,
      "loss": 0.858,
      "step": 174400
    },
    {
      "epoch": 1.8467983972136501,
      "grad_norm": 0.9025329947471619,
      "learning_rate": 0.0004891764426185844,
      "loss": 0.8648,
      "step": 174450
    },
    {
      "epoch": 1.8473277189936534,
      "grad_norm": 0.8477168083190918,
      "learning_rate": 0.0004891629939570204,
      "loss": 0.8632,
      "step": 174500
    },
    {
      "epoch": 1.8473277189936534,
      "eval_loss": 0.6888091564178467,
      "eval_runtime": 46.7197,
      "eval_samples_per_second": 3594.417,
      "eval_steps_per_second": 449.318,
      "step": 174500
    },
    {
      "epoch": 1.8478570407736568,
      "grad_norm": 0.9438422918319702,
      "learning_rate": 0.0004891495371305196,
      "loss": 0.8527,
      "step": 174550
    },
    {
      "epoch": 1.84838636255366,
      "grad_norm": 0.9062034487724304,
      "learning_rate": 0.0004891360721395411,
      "loss": 0.8644,
      "step": 174600
    },
    {
      "epoch": 1.8489156843336634,
      "grad_norm": 0.8665179014205933,
      "learning_rate": 0.0004891225989845449,
      "loss": 0.8533,
      "step": 174650
    },
    {
      "epoch": 1.8494450061136667,
      "grad_norm": 0.8215044140815735,
      "learning_rate": 0.0004891091176659908,
      "loss": 0.8679,
      "step": 174700
    },
    {
      "epoch": 1.84997432789367,
      "grad_norm": 0.9336442947387695,
      "learning_rate": 0.0004890956281843392,
      "loss": 0.8585,
      "step": 174750
    },
    {
      "epoch": 1.850503649673673,
      "grad_norm": 0.8399487137794495,
      "learning_rate": 0.0004890821305400506,
      "loss": 0.8472,
      "step": 174800
    },
    {
      "epoch": 1.8510329714536764,
      "grad_norm": 0.8440215587615967,
      "learning_rate": 0.0004890686247335857,
      "loss": 0.8563,
      "step": 174850
    },
    {
      "epoch": 1.8515622932336797,
      "grad_norm": 0.8533197641372681,
      "learning_rate": 0.0004890551107654056,
      "loss": 0.8514,
      "step": 174900
    },
    {
      "epoch": 1.8520916150136828,
      "grad_norm": 0.8843728303909302,
      "learning_rate": 0.0004890415886359716,
      "loss": 0.849,
      "step": 174950
    },
    {
      "epoch": 1.8526209367936861,
      "grad_norm": 0.8892160058021545,
      "learning_rate": 0.0004890280583457455,
      "loss": 0.8589,
      "step": 175000
    },
    {
      "epoch": 1.8526209367936861,
      "eval_loss": 0.6898897886276245,
      "eval_runtime": 46.728,
      "eval_samples_per_second": 3593.779,
      "eval_steps_per_second": 449.238,
      "step": 175000
    },
    {
      "epoch": 1.8531502585736894,
      "grad_norm": 0.8618237972259521,
      "learning_rate": 0.0004890145198951891,
      "loss": 0.8447,
      "step": 175050
    },
    {
      "epoch": 1.8536795803536927,
      "grad_norm": 0.938450038433075,
      "learning_rate": 0.0004890009732847648,
      "loss": 0.8648,
      "step": 175100
    },
    {
      "epoch": 1.854208902133696,
      "grad_norm": 0.9133846759796143,
      "learning_rate": 0.0004889874185149349,
      "loss": 0.868,
      "step": 175150
    },
    {
      "epoch": 1.8547382239136994,
      "grad_norm": 0.8294448852539062,
      "learning_rate": 0.000488973855586162,
      "loss": 0.8476,
      "step": 175200
    },
    {
      "epoch": 1.8552675456937027,
      "grad_norm": 0.8897272944450378,
      "learning_rate": 0.0004889602844989095,
      "loss": 0.8454,
      "step": 175250
    },
    {
      "epoch": 1.855796867473706,
      "grad_norm": 0.8968755602836609,
      "learning_rate": 0.0004889467052536404,
      "loss": 0.8537,
      "step": 175300
    },
    {
      "epoch": 1.8563261892537093,
      "grad_norm": 0.8763326406478882,
      "learning_rate": 0.0004889331178508185,
      "loss": 0.857,
      "step": 175350
    },
    {
      "epoch": 1.8568555110337126,
      "grad_norm": 0.9107447266578674,
      "learning_rate": 0.0004889195222909076,
      "loss": 0.8683,
      "step": 175400
    },
    {
      "epoch": 1.857384832813716,
      "grad_norm": 0.8989375233650208,
      "learning_rate": 0.0004889059185743717,
      "loss": 0.8665,
      "step": 175450
    },
    {
      "epoch": 1.8579141545937192,
      "grad_norm": 0.881206214427948,
      "learning_rate": 0.0004888923067016754,
      "loss": 0.8429,
      "step": 175500
    },
    {
      "epoch": 1.8579141545937192,
      "eval_loss": 0.6839891672134399,
      "eval_runtime": 46.8112,
      "eval_samples_per_second": 3587.392,
      "eval_steps_per_second": 448.44,
      "step": 175500
    },
    {
      "epoch": 1.8584434763737223,
      "grad_norm": 0.8552803993225098,
      "learning_rate": 0.0004888786866732834,
      "loss": 0.8568,
      "step": 175550
    },
    {
      "epoch": 1.8589727981537256,
      "grad_norm": 0.7928631901741028,
      "learning_rate": 0.0004888650584896607,
      "loss": 0.8541,
      "step": 175600
    },
    {
      "epoch": 1.859502119933729,
      "grad_norm": 0.9136598706245422,
      "learning_rate": 0.0004888514221512724,
      "loss": 0.8522,
      "step": 175650
    },
    {
      "epoch": 1.8600314417137322,
      "grad_norm": 0.8964895009994507,
      "learning_rate": 0.0004888377776585842,
      "loss": 0.8607,
      "step": 175700
    },
    {
      "epoch": 1.8605607634937353,
      "grad_norm": 0.8415040373802185,
      "learning_rate": 0.0004888241250120619,
      "loss": 0.8559,
      "step": 175750
    },
    {
      "epoch": 1.8610900852737386,
      "grad_norm": 0.788701593875885,
      "learning_rate": 0.0004888104642121714,
      "loss": 0.8562,
      "step": 175800
    },
    {
      "epoch": 1.861619407053742,
      "grad_norm": 0.7658094167709351,
      "learning_rate": 0.0004887967952593794,
      "loss": 0.8586,
      "step": 175850
    },
    {
      "epoch": 1.8621487288337453,
      "grad_norm": 0.8504328727722168,
      "learning_rate": 0.0004887831181541523,
      "loss": 0.8667,
      "step": 175900
    },
    {
      "epoch": 1.8626780506137486,
      "grad_norm": 0.8602257370948792,
      "learning_rate": 0.0004887697066819872,
      "loss": 0.8582,
      "step": 175950
    },
    {
      "epoch": 1.863207372393752,
      "grad_norm": 0.8981655836105347,
      "learning_rate": 0.0004887560134363168,
      "loss": 0.8643,
      "step": 176000
    },
    {
      "epoch": 1.863207372393752,
      "eval_loss": 0.6821280121803284,
      "eval_runtime": 46.6949,
      "eval_samples_per_second": 3596.321,
      "eval_steps_per_second": 449.556,
      "step": 176000
    },
    {
      "epoch": 1.8637366941737552,
      "grad_norm": 0.9362284541130066,
      "learning_rate": 0.0004887423120396034,
      "loss": 0.8619,
      "step": 176050
    },
    {
      "epoch": 1.8642660159537585,
      "grad_norm": 0.9071072936058044,
      "learning_rate": 0.0004887286024923151,
      "loss": 0.8679,
      "step": 176100
    },
    {
      "epoch": 1.8647953377337618,
      "grad_norm": 0.8303109407424927,
      "learning_rate": 0.0004887148847949197,
      "loss": 0.8625,
      "step": 176150
    },
    {
      "epoch": 1.8653246595137651,
      "grad_norm": 0.8949772715568542,
      "learning_rate": 0.0004887011589478859,
      "loss": 0.8606,
      "step": 176200
    },
    {
      "epoch": 1.8658539812937684,
      "grad_norm": 0.9794789552688599,
      "learning_rate": 0.000488687424951682,
      "loss": 0.8591,
      "step": 176250
    },
    {
      "epoch": 1.8663833030737715,
      "grad_norm": 0.9255671501159668,
      "learning_rate": 0.000488673682806777,
      "loss": 0.8505,
      "step": 176300
    },
    {
      "epoch": 1.8669126248537748,
      "grad_norm": 0.8805864453315735,
      "learning_rate": 0.0004886599325136399,
      "loss": 0.8498,
      "step": 176350
    },
    {
      "epoch": 1.8674419466337782,
      "grad_norm": 0.9568973183631897,
      "learning_rate": 0.0004886461740727403,
      "loss": 0.8433,
      "step": 176400
    },
    {
      "epoch": 1.8679712684137815,
      "grad_norm": 0.8947448134422302,
      "learning_rate": 0.0004886324074845479,
      "loss": 0.8461,
      "step": 176450
    },
    {
      "epoch": 1.8685005901937846,
      "grad_norm": 0.8565750122070312,
      "learning_rate": 0.0004886186327495325,
      "loss": 0.8638,
      "step": 176500
    },
    {
      "epoch": 1.8685005901937846,
      "eval_loss": 0.681698203086853,
      "eval_runtime": 46.7661,
      "eval_samples_per_second": 3590.853,
      "eval_steps_per_second": 448.873,
      "step": 176500
    },
    {
      "epoch": 1.8690299119737879,
      "grad_norm": 0.7820823192596436,
      "learning_rate": 0.0004886048498681645,
      "loss": 0.8763,
      "step": 176550
    },
    {
      "epoch": 1.8695592337537912,
      "grad_norm": 0.7895533442497253,
      "learning_rate": 0.0004885910588409145,
      "loss": 0.8596,
      "step": 176600
    },
    {
      "epoch": 1.8700885555337945,
      "grad_norm": 1.0264809131622314,
      "learning_rate": 0.0004885772596682532,
      "loss": 0.8549,
      "step": 176650
    },
    {
      "epoch": 1.8706178773137978,
      "grad_norm": 0.8653923273086548,
      "learning_rate": 0.0004885634523506517,
      "loss": 0.8569,
      "step": 176700
    },
    {
      "epoch": 1.8711471990938011,
      "grad_norm": 0.8491479158401489,
      "learning_rate": 0.0004885496368885816,
      "loss": 0.8442,
      "step": 176750
    },
    {
      "epoch": 1.8716765208738044,
      "grad_norm": 0.875126838684082,
      "learning_rate": 0.0004885358132825143,
      "loss": 0.8553,
      "step": 176800
    },
    {
      "epoch": 1.8722058426538077,
      "grad_norm": 0.8026578426361084,
      "learning_rate": 0.0004885219815329217,
      "loss": 0.8397,
      "step": 176850
    },
    {
      "epoch": 1.872735164433811,
      "grad_norm": 1.0082603693008423,
      "learning_rate": 0.0004885081416402762,
      "loss": 0.8516,
      "step": 176900
    },
    {
      "epoch": 1.8732644862138144,
      "grad_norm": 0.9044157266616821,
      "learning_rate": 0.0004884942936050502,
      "loss": 0.8624,
      "step": 176950
    },
    {
      "epoch": 1.8737938079938177,
      "grad_norm": 0.8912869691848755,
      "learning_rate": 0.0004884804374277166,
      "loss": 0.8515,
      "step": 177000
    },
    {
      "epoch": 1.8737938079938177,
      "eval_loss": 0.6802550554275513,
      "eval_runtime": 46.7606,
      "eval_samples_per_second": 3591.274,
      "eval_steps_per_second": 448.925,
      "step": 177000
    },
    {
      "epoch": 1.8743231297738208,
      "grad_norm": 0.9194077849388123,
      "learning_rate": 0.0004884665731087482,
      "loss": 0.8503,
      "step": 177050
    },
    {
      "epoch": 1.874852451553824,
      "grad_norm": 0.8535574674606323,
      "learning_rate": 0.0004884527006486186,
      "loss": 0.8628,
      "step": 177100
    },
    {
      "epoch": 1.8753817733338274,
      "grad_norm": 0.9515561461448669,
      "learning_rate": 0.000488438820047801,
      "loss": 0.8608,
      "step": 177150
    },
    {
      "epoch": 1.8759110951138307,
      "grad_norm": 0.9291776418685913,
      "learning_rate": 0.0004884249313067697,
      "loss": 0.847,
      "step": 177200
    },
    {
      "epoch": 1.8764404168938338,
      "grad_norm": 0.8786005973815918,
      "learning_rate": 0.0004884110344259986,
      "loss": 0.8509,
      "step": 177250
    },
    {
      "epoch": 1.876969738673837,
      "grad_norm": 0.9274904727935791,
      "learning_rate": 0.0004883971294059624,
      "loss": 0.8737,
      "step": 177300
    },
    {
      "epoch": 1.8774990604538404,
      "grad_norm": 0.9278721809387207,
      "learning_rate": 0.0004883832162471354,
      "loss": 0.8444,
      "step": 177350
    },
    {
      "epoch": 1.8780283822338437,
      "grad_norm": 0.8642470240592957,
      "learning_rate": 0.0004883692949499929,
      "loss": 0.8526,
      "step": 177400
    },
    {
      "epoch": 1.878557704013847,
      "grad_norm": 0.9342378973960876,
      "learning_rate": 0.0004883553655150102,
      "loss": 0.8397,
      "step": 177450
    },
    {
      "epoch": 1.8790870257938503,
      "grad_norm": 0.8413633704185486,
      "learning_rate": 0.0004883414279426626,
      "loss": 0.8534,
      "step": 177500
    },
    {
      "epoch": 1.8790870257938503,
      "eval_loss": 0.6818181276321411,
      "eval_runtime": 46.7913,
      "eval_samples_per_second": 3588.915,
      "eval_steps_per_second": 448.63,
      "step": 177500
    },
    {
      "epoch": 1.8796163475738537,
      "grad_norm": 0.8863496780395508,
      "learning_rate": 0.0004883274822334261,
      "loss": 0.8597,
      "step": 177550
    },
    {
      "epoch": 1.880145669353857,
      "grad_norm": 0.8201161026954651,
      "learning_rate": 0.0004883135283877768,
      "loss": 0.8563,
      "step": 177600
    },
    {
      "epoch": 1.8806749911338603,
      "grad_norm": 0.8690872192382812,
      "learning_rate": 0.000488299566406191,
      "loss": 0.8552,
      "step": 177650
    },
    {
      "epoch": 1.8812043129138636,
      "grad_norm": 0.8097617030143738,
      "learning_rate": 0.0004882855962891455,
      "loss": 0.8648,
      "step": 177700
    },
    {
      "epoch": 1.881733634693867,
      "grad_norm": 0.859688937664032,
      "learning_rate": 0.00048827161803711696,
      "loss": 0.8354,
      "step": 177750
    },
    {
      "epoch": 1.88226295647387,
      "grad_norm": 0.8467727303504944,
      "learning_rate": 0.0004882576316505829,
      "loss": 0.849,
      "step": 177800
    },
    {
      "epoch": 1.8827922782538733,
      "grad_norm": 0.927731454372406,
      "learning_rate": 0.00048824363713002064,
      "loss": 0.8551,
      "step": 177850
    },
    {
      "epoch": 1.8833216000338766,
      "grad_norm": 0.8733764290809631,
      "learning_rate": 0.0004882296344759079,
      "loss": 0.8429,
      "step": 177900
    },
    {
      "epoch": 1.88385092181388,
      "grad_norm": 0.8437395691871643,
      "learning_rate": 0.0004882159039841676,
      "loss": 0.8701,
      "step": 177950
    },
    {
      "epoch": 1.884380243593883,
      "grad_norm": 0.9982997179031372,
      "learning_rate": 0.0004882018852270357,
      "loss": 0.8341,
      "step": 178000
    },
    {
      "epoch": 1.884380243593883,
      "eval_loss": 0.6789490580558777,
      "eval_runtime": 46.7271,
      "eval_samples_per_second": 3593.844,
      "eval_steps_per_second": 449.247,
      "step": 178000
    },
    {
      "epoch": 1.8849095653738863,
      "grad_norm": 0.8316501975059509,
      "learning_rate": 0.00048818785833777884,
      "loss": 0.8688,
      "step": 178050
    },
    {
      "epoch": 1.8854388871538896,
      "grad_norm": 0.8728927969932556,
      "learning_rate": 0.00048817382331687583,
      "loss": 0.8702,
      "step": 178100
    },
    {
      "epoch": 1.885968208933893,
      "grad_norm": 0.8640275001525879,
      "learning_rate": 0.0004881597801648059,
      "loss": 0.8407,
      "step": 178150
    },
    {
      "epoch": 1.8864975307138963,
      "grad_norm": 0.906227707862854,
      "learning_rate": 0.00048814572888204836,
      "loss": 0.8573,
      "step": 178200
    },
    {
      "epoch": 1.8870268524938996,
      "grad_norm": 0.8801650404930115,
      "learning_rate": 0.0004881316694690829,
      "loss": 0.8429,
      "step": 178250
    },
    {
      "epoch": 1.8875561742739029,
      "grad_norm": 0.795343816280365,
      "learning_rate": 0.00048811760192638963,
      "loss": 0.8467,
      "step": 178300
    },
    {
      "epoch": 1.8880854960539062,
      "grad_norm": 0.7906941175460815,
      "learning_rate": 0.0004881035262544488,
      "loss": 0.8644,
      "step": 178350
    },
    {
      "epoch": 1.8886148178339095,
      "grad_norm": 0.8006380796432495,
      "learning_rate": 0.0004880894424537409,
      "loss": 0.8464,
      "step": 178400
    },
    {
      "epoch": 1.8891441396139128,
      "grad_norm": 0.8698516488075256,
      "learning_rate": 0.00048807535052474674,
      "loss": 0.8571,
      "step": 178450
    },
    {
      "epoch": 1.8896734613939161,
      "grad_norm": 0.8179951310157776,
      "learning_rate": 0.0004880612504679474,
      "loss": 0.8477,
      "step": 178500
    },
    {
      "epoch": 1.8896734613939161,
      "eval_loss": 0.6792861819267273,
      "eval_runtime": 46.7802,
      "eval_samples_per_second": 3589.768,
      "eval_steps_per_second": 448.737,
      "step": 178500
    },
    {
      "epoch": 1.8902027831739192,
      "grad_norm": 0.825311541557312,
      "learning_rate": 0.0004880471422838243,
      "loss": 0.8461,
      "step": 178550
    },
    {
      "epoch": 1.8907321049539225,
      "grad_norm": 0.8590722680091858,
      "learning_rate": 0.0004880330259728591,
      "loss": 0.8455,
      "step": 178600
    },
    {
      "epoch": 1.8912614267339258,
      "grad_norm": 0.8969038724899292,
      "learning_rate": 0.0004880189015355336,
      "loss": 0.8431,
      "step": 178650
    },
    {
      "epoch": 1.8917907485139291,
      "grad_norm": 0.9288548231124878,
      "learning_rate": 0.00048800476897233015,
      "loss": 0.854,
      "step": 178700
    },
    {
      "epoch": 1.8923200702939322,
      "grad_norm": 0.8358885049819946,
      "learning_rate": 0.0004879906282837312,
      "loss": 0.849,
      "step": 178750
    },
    {
      "epoch": 1.8928493920739355,
      "grad_norm": 0.9308934807777405,
      "learning_rate": 0.0004879764794702194,
      "loss": 0.8567,
      "step": 178800
    },
    {
      "epoch": 1.8933787138539389,
      "grad_norm": 0.8621746301651001,
      "learning_rate": 0.0004879623225322779,
      "loss": 0.8616,
      "step": 178850
    },
    {
      "epoch": 1.8939080356339422,
      "grad_norm": 0.8911550641059875,
      "learning_rate": 0.00048794815747039,
      "loss": 0.845,
      "step": 178900
    },
    {
      "epoch": 1.8944373574139455,
      "grad_norm": 0.8640624284744263,
      "learning_rate": 0.00048793398428503934,
      "loss": 0.8578,
      "step": 178950
    },
    {
      "epoch": 1.8949666791939488,
      "grad_norm": 0.7960239052772522,
      "learning_rate": 0.00048791980297670955,
      "loss": 0.8446,
      "step": 179000
    },
    {
      "epoch": 1.8949666791939488,
      "eval_loss": 0.6779524683952332,
      "eval_runtime": 46.7564,
      "eval_samples_per_second": 3591.592,
      "eval_steps_per_second": 448.965,
      "step": 179000
    },
    {
      "epoch": 1.895496000973952,
      "grad_norm": 0.8945245146751404,
      "learning_rate": 0.000487905613545885,
      "loss": 0.8406,
      "step": 179050
    },
    {
      "epoch": 1.8960253227539554,
      "grad_norm": 0.9037657976150513,
      "learning_rate": 0.00048789141599305013,
      "loss": 0.8627,
      "step": 179100
    },
    {
      "epoch": 1.8965546445339587,
      "grad_norm": 0.871401309967041,
      "learning_rate": 0.00048787721031868955,
      "loss": 0.8457,
      "step": 179150
    },
    {
      "epoch": 1.897083966313962,
      "grad_norm": 0.8071839213371277,
      "learning_rate": 0.0004878629965232882,
      "loss": 0.8476,
      "step": 179200
    },
    {
      "epoch": 1.8976132880939653,
      "grad_norm": 0.8332396149635315,
      "learning_rate": 0.00048784877460733133,
      "loss": 0.8501,
      "step": 179250
    },
    {
      "epoch": 1.8981426098739684,
      "grad_norm": 0.8479477167129517,
      "learning_rate": 0.0004878345445713046,
      "loss": 0.8405,
      "step": 179300
    },
    {
      "epoch": 1.8986719316539717,
      "grad_norm": 0.9215230345726013,
      "learning_rate": 0.00048782030641569374,
      "loss": 0.8492,
      "step": 179350
    },
    {
      "epoch": 1.899201253433975,
      "grad_norm": 0.8499724864959717,
      "learning_rate": 0.00048780606014098483,
      "loss": 0.85,
      "step": 179400
    },
    {
      "epoch": 1.8997305752139784,
      "grad_norm": 0.964797854423523,
      "learning_rate": 0.00048779180574766423,
      "loss": 0.8537,
      "step": 179450
    },
    {
      "epoch": 1.9002598969939815,
      "grad_norm": 0.875788152217865,
      "learning_rate": 0.0004877775432362186,
      "loss": 0.859,
      "step": 179500
    },
    {
      "epoch": 1.9002598969939815,
      "eval_loss": 0.6739171743392944,
      "eval_runtime": 46.8326,
      "eval_samples_per_second": 3585.75,
      "eval_steps_per_second": 448.235,
      "step": 179500
    },
    {
      "epoch": 1.9007892187739848,
      "grad_norm": 0.8629047274589539,
      "learning_rate": 0.0004877632726071349,
      "loss": 0.8523,
      "step": 179550
    },
    {
      "epoch": 1.901318540553988,
      "grad_norm": 0.9274157881736755,
      "learning_rate": 0.0004877489938609002,
      "loss": 0.8534,
      "step": 179600
    },
    {
      "epoch": 1.9018478623339914,
      "grad_norm": 0.9411352872848511,
      "learning_rate": 0.00048773470699800206,
      "loss": 0.8591,
      "step": 179650
    },
    {
      "epoch": 1.9023771841139947,
      "grad_norm": 0.8566989302635193,
      "learning_rate": 0.0004877204120189281,
      "loss": 0.8401,
      "step": 179700
    },
    {
      "epoch": 1.902906505893998,
      "grad_norm": 0.8498231768608093,
      "learning_rate": 0.0004877061089241667,
      "loss": 0.8539,
      "step": 179750
    },
    {
      "epoch": 1.9034358276740013,
      "grad_norm": 0.974728524684906,
      "learning_rate": 0.0004876917977142057,
      "loss": 0.8588,
      "step": 179800
    },
    {
      "epoch": 1.9039651494540046,
      "grad_norm": 0.8564126491546631,
      "learning_rate": 0.000487677478389534,
      "loss": 0.8557,
      "step": 179850
    },
    {
      "epoch": 1.904494471234008,
      "grad_norm": 0.8958724737167358,
      "learning_rate": 0.0004876631509506403,
      "loss": 0.8668,
      "step": 179900
    },
    {
      "epoch": 1.9050237930140113,
      "grad_norm": 0.9412524700164795,
      "learning_rate": 0.0004876488153980138,
      "loss": 0.8471,
      "step": 179950
    },
    {
      "epoch": 1.9055531147940146,
      "grad_norm": 0.8975366950035095,
      "learning_rate": 0.00048763475868496796,
      "loss": 0.845,
      "step": 180000
    },
    {
      "epoch": 1.9055531147940146,
      "eval_loss": 0.6741266846656799,
      "eval_runtime": 46.7726,
      "eval_samples_per_second": 3590.351,
      "eval_steps_per_second": 448.81,
      "step": 180000
    },
    {
      "epoch": 1.9060824365740177,
      "grad_norm": 0.8813307881355286,
      "learning_rate": 0.0004876204070685946,
      "loss": 0.8426,
      "step": 180050
    },
    {
      "epoch": 1.906611758354021,
      "grad_norm": 0.9288029074668884,
      "learning_rate": 0.00048760604733994774,
      "loss": 0.8451,
      "step": 180100
    },
    {
      "epoch": 1.9071410801340243,
      "grad_norm": 0.9672184586524963,
      "learning_rate": 0.0004875916794995175,
      "loss": 0.8658,
      "step": 180150
    },
    {
      "epoch": 1.9076704019140276,
      "grad_norm": 0.815416693687439,
      "learning_rate": 0.0004875773035477945,
      "loss": 0.8437,
      "step": 180200
    },
    {
      "epoch": 1.9081997236940307,
      "grad_norm": 1.0124448537826538,
      "learning_rate": 0.00048756291948526953,
      "loss": 0.8629,
      "step": 180250
    },
    {
      "epoch": 1.908729045474034,
      "grad_norm": 0.8148291110992432,
      "learning_rate": 0.00048754852731243355,
      "loss": 0.842,
      "step": 180300
    },
    {
      "epoch": 1.9092583672540373,
      "grad_norm": 0.8360118865966797,
      "learning_rate": 0.00048753412702977794,
      "loss": 0.8463,
      "step": 180350
    },
    {
      "epoch": 1.9097876890340406,
      "grad_norm": 0.8226436972618103,
      "learning_rate": 0.0004875197186377944,
      "loss": 0.8467,
      "step": 180400
    },
    {
      "epoch": 1.910317010814044,
      "grad_norm": 0.870623767375946,
      "learning_rate": 0.00048750530213697473,
      "loss": 0.8542,
      "step": 180450
    },
    {
      "epoch": 1.9108463325940472,
      "grad_norm": 0.8684234023094177,
      "learning_rate": 0.00048749087752781125,
      "loss": 0.8632,
      "step": 180500
    },
    {
      "epoch": 1.9108463325940472,
      "eval_loss": 0.6767690777778625,
      "eval_runtime": 46.6876,
      "eval_samples_per_second": 3596.885,
      "eval_steps_per_second": 449.627,
      "step": 180500
    },
    {
      "epoch": 1.9113756543740505,
      "grad_norm": 0.9301179647445679,
      "learning_rate": 0.00048747644481079625,
      "loss": 0.8595,
      "step": 180550
    },
    {
      "epoch": 1.9119049761540539,
      "grad_norm": 0.812950849533081,
      "learning_rate": 0.0004874620039864225,
      "loss": 0.8623,
      "step": 180600
    },
    {
      "epoch": 1.9124342979340572,
      "grad_norm": 0.8304184675216675,
      "learning_rate": 0.00048744755505518303,
      "loss": 0.8506,
      "step": 180650
    },
    {
      "epoch": 1.9129636197140605,
      "grad_norm": 0.8839876055717468,
      "learning_rate": 0.00048743309801757106,
      "loss": 0.8646,
      "step": 180700
    },
    {
      "epoch": 1.9134929414940638,
      "grad_norm": 0.9021177291870117,
      "learning_rate": 0.0004874186328740803,
      "loss": 0.8464,
      "step": 180750
    },
    {
      "epoch": 1.914022263274067,
      "grad_norm": 0.9030479788780212,
      "learning_rate": 0.00048740415962520437,
      "loss": 0.8498,
      "step": 180800
    },
    {
      "epoch": 1.9145515850540702,
      "grad_norm": 0.8384758830070496,
      "learning_rate": 0.0004873896782714375,
      "loss": 0.8443,
      "step": 180850
    },
    {
      "epoch": 1.9150809068340735,
      "grad_norm": 0.9523873329162598,
      "learning_rate": 0.0004873751888132742,
      "loss": 0.8518,
      "step": 180900
    },
    {
      "epoch": 1.9156102286140768,
      "grad_norm": 0.9123749732971191,
      "learning_rate": 0.00048736069125120894,
      "loss": 0.8428,
      "step": 180950
    },
    {
      "epoch": 1.91613955039408,
      "grad_norm": 0.8910820484161377,
      "learning_rate": 0.0004873461855857367,
      "loss": 0.8426,
      "step": 181000
    },
    {
      "epoch": 1.91613955039408,
      "eval_loss": 0.6727140545845032,
      "eval_runtime": 46.7337,
      "eval_samples_per_second": 3593.339,
      "eval_steps_per_second": 449.183,
      "step": 181000
    },
    {
      "epoch": 1.9166688721740832,
      "grad_norm": 0.8015173077583313,
      "learning_rate": 0.00048733167181735275,
      "loss": 0.8639,
      "step": 181050
    },
    {
      "epoch": 1.9171981939540865,
      "grad_norm": 0.9029384851455688,
      "learning_rate": 0.00048731714994655265,
      "loss": 0.8458,
      "step": 181100
    },
    {
      "epoch": 1.9177275157340898,
      "grad_norm": 0.860413134098053,
      "learning_rate": 0.000487302619973832,
      "loss": 0.8497,
      "step": 181150
    },
    {
      "epoch": 1.9182568375140931,
      "grad_norm": 0.8084837198257446,
      "learning_rate": 0.00048728808189968685,
      "loss": 0.8324,
      "step": 181200
    },
    {
      "epoch": 1.9187861592940965,
      "grad_norm": 0.9186989068984985,
      "learning_rate": 0.00048727353572461374,
      "loss": 0.8491,
      "step": 181250
    },
    {
      "epoch": 1.9193154810740998,
      "grad_norm": 1.0149288177490234,
      "learning_rate": 0.00048725898144910907,
      "loss": 0.8524,
      "step": 181300
    },
    {
      "epoch": 1.919844802854103,
      "grad_norm": 1.0448031425476074,
      "learning_rate": 0.00048724441907366977,
      "loss": 0.8516,
      "step": 181350
    },
    {
      "epoch": 1.9203741246341064,
      "grad_norm": 0.9290783405303955,
      "learning_rate": 0.0004872298485987931,
      "loss": 0.8359,
      "step": 181400
    },
    {
      "epoch": 1.9209034464141097,
      "grad_norm": 0.8524571061134338,
      "learning_rate": 0.0004872152700249763,
      "loss": 0.854,
      "step": 181450
    },
    {
      "epoch": 1.921432768194113,
      "grad_norm": 0.921783447265625,
      "learning_rate": 0.00048720068335271726,
      "loss": 0.8408,
      "step": 181500
    },
    {
      "epoch": 1.921432768194113,
      "eval_loss": 0.6713259816169739,
      "eval_runtime": 46.7515,
      "eval_samples_per_second": 3591.969,
      "eval_steps_per_second": 449.012,
      "step": 181500
    },
    {
      "epoch": 1.9219620899741163,
      "grad_norm": 0.839041531085968,
      "learning_rate": 0.0004871860885825139,
      "loss": 0.8396,
      "step": 181550
    },
    {
      "epoch": 1.9224914117541194,
      "grad_norm": 0.9103938341140747,
      "learning_rate": 0.0004871714857148644,
      "loss": 0.8623,
      "step": 181600
    },
    {
      "epoch": 1.9230207335341227,
      "grad_norm": 0.9529293179512024,
      "learning_rate": 0.0004871568747502673,
      "loss": 0.8457,
      "step": 181650
    },
    {
      "epoch": 1.923550055314126,
      "grad_norm": 0.8623515367507935,
      "learning_rate": 0.00048714225568922156,
      "loss": 0.8605,
      "step": 181700
    },
    {
      "epoch": 1.9240793770941291,
      "grad_norm": 1.0156103372573853,
      "learning_rate": 0.0004871276285322261,
      "loss": 0.8479,
      "step": 181750
    },
    {
      "epoch": 1.9246086988741324,
      "grad_norm": 0.825487494468689,
      "learning_rate": 0.00048711299327978047,
      "loss": 0.8443,
      "step": 181800
    },
    {
      "epoch": 1.9251380206541358,
      "grad_norm": 0.8233916163444519,
      "learning_rate": 0.00048709834993238417,
      "loss": 0.8601,
      "step": 181850
    },
    {
      "epoch": 1.925667342434139,
      "grad_norm": 0.9231919646263123,
      "learning_rate": 0.00048708369849053714,
      "loss": 0.8563,
      "step": 181900
    },
    {
      "epoch": 1.9261966642141424,
      "grad_norm": 0.9667401909828186,
      "learning_rate": 0.00048706903895473963,
      "loss": 0.8455,
      "step": 181950
    },
    {
      "epoch": 1.9267259859941457,
      "grad_norm": 0.8248474597930908,
      "learning_rate": 0.000487054371325492,
      "loss": 0.8274,
      "step": 182000
    },
    {
      "epoch": 1.9267259859941457,
      "eval_loss": 0.6689677834510803,
      "eval_runtime": 46.7555,
      "eval_samples_per_second": 3591.663,
      "eval_steps_per_second": 448.974,
      "step": 182000
    },
    {
      "epoch": 1.927255307774149,
      "grad_norm": 0.9320594668388367,
      "learning_rate": 0.00048703998919704674,
      "loss": 0.8452,
      "step": 182050
    },
    {
      "epoch": 1.9277846295541523,
      "grad_norm": 0.8545616865158081,
      "learning_rate": 0.00048702530554424565,
      "loss": 0.8503,
      "step": 182100
    },
    {
      "epoch": 1.9283139513341556,
      "grad_norm": 0.7908721566200256,
      "learning_rate": 0.00048701061379948754,
      "loss": 0.8355,
      "step": 182150
    },
    {
      "epoch": 1.928843273114159,
      "grad_norm": 0.8804884552955627,
      "learning_rate": 0.000486995913963274,
      "loss": 0.838,
      "step": 182200
    },
    {
      "epoch": 1.9293725948941622,
      "grad_norm": 0.8467993140220642,
      "learning_rate": 0.00048698120603610684,
      "loss": 0.8486,
      "step": 182250
    },
    {
      "epoch": 1.9299019166741656,
      "grad_norm": 0.8873708248138428,
      "learning_rate": 0.00048696649001848827,
      "loss": 0.8572,
      "step": 182300
    },
    {
      "epoch": 1.9304312384541686,
      "grad_norm": 0.9000380039215088,
      "learning_rate": 0.0004869517659109206,
      "loss": 0.8642,
      "step": 182350
    },
    {
      "epoch": 1.930960560234172,
      "grad_norm": 0.9257256984710693,
      "learning_rate": 0.0004869370337139065,
      "loss": 0.8569,
      "step": 182400
    },
    {
      "epoch": 1.9314898820141753,
      "grad_norm": 0.8347530364990234,
      "learning_rate": 0.000486922293427949,
      "loss": 0.847,
      "step": 182450
    },
    {
      "epoch": 1.9320192037941786,
      "grad_norm": 0.8477530479431152,
      "learning_rate": 0.0004869075450535513,
      "loss": 0.8516,
      "step": 182500
    },
    {
      "epoch": 1.9320192037941786,
      "eval_loss": 0.6671644449234009,
      "eval_runtime": 46.712,
      "eval_samples_per_second": 3595.011,
      "eval_steps_per_second": 449.392,
      "step": 182500
    },
    {
      "epoch": 1.9325485255741817,
      "grad_norm": 0.8484902381896973,
      "learning_rate": 0.0004868927885912169,
      "loss": 0.8535,
      "step": 182550
    },
    {
      "epoch": 1.933077847354185,
      "grad_norm": 0.9046626687049866,
      "learning_rate": 0.0004868780240414496,
      "loss": 0.8445,
      "step": 182600
    },
    {
      "epoch": 1.9336071691341883,
      "grad_norm": 0.8749536275863647,
      "learning_rate": 0.0004868632514047534,
      "loss": 0.8333,
      "step": 182650
    },
    {
      "epoch": 1.9341364909141916,
      "grad_norm": 0.9593390822410583,
      "learning_rate": 0.0004868484706816326,
      "loss": 0.8142,
      "step": 182700
    },
    {
      "epoch": 1.934665812694195,
      "grad_norm": 0.9307284951210022,
      "learning_rate": 0.000486833681872592,
      "loss": 0.8385,
      "step": 182750
    },
    {
      "epoch": 1.9351951344741982,
      "grad_norm": 0.9653209447860718,
      "learning_rate": 0.0004868188849781363,
      "loss": 0.8662,
      "step": 182800
    },
    {
      "epoch": 1.9357244562542015,
      "grad_norm": 0.9823971390724182,
      "learning_rate": 0.00048680407999877076,
      "loss": 0.8535,
      "step": 182850
    },
    {
      "epoch": 1.9362537780342048,
      "grad_norm": 0.9743821620941162,
      "learning_rate": 0.0004867892669350007,
      "loss": 0.8399,
      "step": 182900
    },
    {
      "epoch": 1.9367830998142082,
      "grad_norm": 0.9350197315216064,
      "learning_rate": 0.0004867744457873319,
      "loss": 0.8566,
      "step": 182950
    },
    {
      "epoch": 1.9373124215942115,
      "grad_norm": 0.90486741065979,
      "learning_rate": 0.0004867596165562704,
      "loss": 0.8521,
      "step": 183000
    },
    {
      "epoch": 1.9373124215942115,
      "eval_loss": 0.6708002090454102,
      "eval_runtime": 46.7396,
      "eval_samples_per_second": 3592.882,
      "eval_steps_per_second": 449.126,
      "step": 183000
    },
    {
      "epoch": 1.9378417433742148,
      "grad_norm": 0.844603419303894,
      "learning_rate": 0.0004867447792423224,
      "loss": 0.8357,
      "step": 183050
    },
    {
      "epoch": 1.9383710651542179,
      "grad_norm": 0.9215402603149414,
      "learning_rate": 0.0004867299338459945,
      "loss": 0.8449,
      "step": 183100
    },
    {
      "epoch": 1.9389003869342212,
      "grad_norm": 0.9533738493919373,
      "learning_rate": 0.00048671508036779345,
      "loss": 0.8556,
      "step": 183150
    },
    {
      "epoch": 1.9394297087142245,
      "grad_norm": 0.8863371014595032,
      "learning_rate": 0.0004867002188082263,
      "loss": 0.8383,
      "step": 183200
    },
    {
      "epoch": 1.9399590304942278,
      "grad_norm": 0.974033772945404,
      "learning_rate": 0.0004866853491678006,
      "loss": 0.843,
      "step": 183250
    },
    {
      "epoch": 1.9404883522742309,
      "grad_norm": 0.8443132638931274,
      "learning_rate": 0.0004866704714470238,
      "loss": 0.838,
      "step": 183300
    },
    {
      "epoch": 1.9410176740542342,
      "grad_norm": 0.9323188066482544,
      "learning_rate": 0.000486655585646404,
      "loss": 0.8566,
      "step": 183350
    },
    {
      "epoch": 1.9415469958342375,
      "grad_norm": 0.8808592557907104,
      "learning_rate": 0.0004866406917664492,
      "loss": 0.8525,
      "step": 183400
    },
    {
      "epoch": 1.9420763176142408,
      "grad_norm": 0.9152014255523682,
      "learning_rate": 0.000486625789807668,
      "loss": 0.85,
      "step": 183450
    },
    {
      "epoch": 1.9426056393942441,
      "grad_norm": 0.8706947565078735,
      "learning_rate": 0.00048661087977056917,
      "loss": 0.8567,
      "step": 183500
    },
    {
      "epoch": 1.9426056393942441,
      "eval_loss": 0.6670023202896118,
      "eval_runtime": 46.749,
      "eval_samples_per_second": 3592.161,
      "eval_steps_per_second": 449.036,
      "step": 183500
    },
    {
      "epoch": 1.9431349611742474,
      "grad_norm": 0.8988420367240906,
      "learning_rate": 0.0004865959616556616,
      "loss": 0.8365,
      "step": 183550
    },
    {
      "epoch": 1.9436642829542508,
      "grad_norm": 0.8170850872993469,
      "learning_rate": 0.0004865810354634547,
      "loss": 0.8382,
      "step": 183600
    },
    {
      "epoch": 1.944193604734254,
      "grad_norm": 0.9514535665512085,
      "learning_rate": 0.000486566101194458,
      "loss": 0.8155,
      "step": 183650
    },
    {
      "epoch": 1.9447229265142574,
      "grad_norm": 0.8642349243164062,
      "learning_rate": 0.00048655115884918136,
      "loss": 0.8436,
      "step": 183700
    },
    {
      "epoch": 1.9452522482942607,
      "grad_norm": 0.8527349233627319,
      "learning_rate": 0.00048653620842813497,
      "loss": 0.8329,
      "step": 183750
    },
    {
      "epoch": 1.945781570074264,
      "grad_norm": 0.9060080051422119,
      "learning_rate": 0.0004865212499318291,
      "loss": 0.8426,
      "step": 183800
    },
    {
      "epoch": 1.946310891854267,
      "grad_norm": 0.9568066000938416,
      "learning_rate": 0.0004865062833607745,
      "loss": 0.8588,
      "step": 183850
    },
    {
      "epoch": 1.9468402136342704,
      "grad_norm": 1.0316040515899658,
      "learning_rate": 0.0004864913087154822,
      "loss": 0.8385,
      "step": 183900
    },
    {
      "epoch": 1.9473695354142737,
      "grad_norm": 0.8967093825340271,
      "learning_rate": 0.0004864763259964633,
      "loss": 0.8602,
      "step": 183950
    },
    {
      "epoch": 1.947898857194277,
      "grad_norm": 0.9152122139930725,
      "learning_rate": 0.0004864613352042293,
      "loss": 0.8266,
      "step": 184000
    },
    {
      "epoch": 1.947898857194277,
      "eval_loss": 0.6686882376670837,
      "eval_runtime": 46.728,
      "eval_samples_per_second": 3593.775,
      "eval_steps_per_second": 449.238,
      "step": 184000
    },
    {
      "epoch": 1.9484281789742801,
      "grad_norm": 0.9108256101608276,
      "learning_rate": 0.00048644663639570005,
      "loss": 0.845,
      "step": 184050
    },
    {
      "epoch": 1.9489575007542834,
      "grad_norm": 0.8965887427330017,
      "learning_rate": 0.00048643162962001043,
      "loss": 0.8323,
      "step": 184100
    },
    {
      "epoch": 1.9494868225342867,
      "grad_norm": 0.8974222540855408,
      "learning_rate": 0.00048641661477263166,
      "loss": 0.8478,
      "step": 184150
    },
    {
      "epoch": 1.95001614431429,
      "grad_norm": 0.9268253445625305,
      "learning_rate": 0.0004864015918540764,
      "loss": 0.8469,
      "step": 184200
    },
    {
      "epoch": 1.9505454660942934,
      "grad_norm": 0.8885644674301147,
      "learning_rate": 0.00048638656086485743,
      "loss": 0.8472,
      "step": 184250
    },
    {
      "epoch": 1.9510747878742967,
      "grad_norm": 0.9327669739723206,
      "learning_rate": 0.00048637152180548807,
      "loss": 0.8571,
      "step": 184300
    },
    {
      "epoch": 1.9516041096543,
      "grad_norm": 0.9373223781585693,
      "learning_rate": 0.00048635647467648157,
      "loss": 0.8418,
      "step": 184350
    },
    {
      "epoch": 1.9521334314343033,
      "grad_norm": 0.9526798129081726,
      "learning_rate": 0.00048634141947835174,
      "loss": 0.8391,
      "step": 184400
    },
    {
      "epoch": 1.9526627532143066,
      "grad_norm": 0.9098303318023682,
      "learning_rate": 0.0004863263562116125,
      "loss": 0.8439,
      "step": 184450
    },
    {
      "epoch": 1.95319207499431,
      "grad_norm": 0.8308441042900085,
      "learning_rate": 0.0004863112848767781,
      "loss": 0.8373,
      "step": 184500
    },
    {
      "epoch": 1.95319207499431,
      "eval_loss": 0.6631319522857666,
      "eval_runtime": 46.6775,
      "eval_samples_per_second": 3597.663,
      "eval_steps_per_second": 449.724,
      "step": 184500
    },
    {
      "epoch": 1.9537213967743132,
      "grad_norm": 0.9256866574287415,
      "learning_rate": 0.0004862962054743632,
      "loss": 0.8309,
      "step": 184550
    },
    {
      "epoch": 1.9542507185543163,
      "grad_norm": 0.834998369216919,
      "learning_rate": 0.00048628111800488237,
      "loss": 0.8385,
      "step": 184600
    },
    {
      "epoch": 1.9547800403343196,
      "grad_norm": 0.9519749879837036,
      "learning_rate": 0.000486266022468851,
      "loss": 0.8405,
      "step": 184650
    },
    {
      "epoch": 1.955309362114323,
      "grad_norm": 0.8679369688034058,
      "learning_rate": 0.0004862509188667841,
      "loss": 0.8504,
      "step": 184700
    },
    {
      "epoch": 1.9558386838943262,
      "grad_norm": 0.7792118191719055,
      "learning_rate": 0.0004862358071991976,
      "loss": 0.8401,
      "step": 184750
    },
    {
      "epoch": 1.9563680056743293,
      "grad_norm": 0.9069870114326477,
      "learning_rate": 0.0004862206874666072,
      "loss": 0.8543,
      "step": 184800
    },
    {
      "epoch": 1.9568973274543326,
      "grad_norm": 0.9198316931724548,
      "learning_rate": 0.00048620555966952917,
      "loss": 0.847,
      "step": 184850
    },
    {
      "epoch": 1.957426649234336,
      "grad_norm": 0.8087560534477234,
      "learning_rate": 0.00048619042380848,
      "loss": 0.8464,
      "step": 184900
    },
    {
      "epoch": 1.9579559710143393,
      "grad_norm": 0.8476545810699463,
      "learning_rate": 0.0004861752798839764,
      "loss": 0.847,
      "step": 184950
    },
    {
      "epoch": 1.9584852927943426,
      "grad_norm": 0.912783145904541,
      "learning_rate": 0.00048616012789653523,
      "loss": 0.8363,
      "step": 185000
    },
    {
      "epoch": 1.9584852927943426,
      "eval_loss": 0.6635465025901794,
      "eval_runtime": 46.6931,
      "eval_samples_per_second": 3596.462,
      "eval_steps_per_second": 449.574,
      "step": 185000
    },
    {
      "epoch": 1.959014614574346,
      "grad_norm": 0.9961621165275574,
      "learning_rate": 0.000486144967846674,
      "loss": 0.8526,
      "step": 185050
    },
    {
      "epoch": 1.9595439363543492,
      "grad_norm": 1.0240113735198975,
      "learning_rate": 0.00048612979973491015,
      "loss": 0.8285,
      "step": 185100
    },
    {
      "epoch": 1.9600732581343525,
      "grad_norm": 0.883239209651947,
      "learning_rate": 0.0004861146235617616,
      "loss": 0.8326,
      "step": 185150
    },
    {
      "epoch": 1.9606025799143558,
      "grad_norm": 0.9236016273498535,
      "learning_rate": 0.0004860994393277463,
      "loss": 0.8533,
      "step": 185200
    },
    {
      "epoch": 1.9611319016943591,
      "grad_norm": 0.8591846823692322,
      "learning_rate": 0.0004860842470333827,
      "loss": 0.8362,
      "step": 185250
    },
    {
      "epoch": 1.9616612234743624,
      "grad_norm": 0.90267014503479,
      "learning_rate": 0.0004860690466791896,
      "loss": 0.8415,
      "step": 185300
    },
    {
      "epoch": 1.9621905452543655,
      "grad_norm": 0.9080142378807068,
      "learning_rate": 0.0004860538382656858,
      "loss": 0.8435,
      "step": 185350
    },
    {
      "epoch": 1.9627198670343688,
      "grad_norm": 0.8230438828468323,
      "learning_rate": 0.0004860386217933905,
      "loss": 0.8382,
      "step": 185400
    },
    {
      "epoch": 1.9632491888143722,
      "grad_norm": 0.8875045776367188,
      "learning_rate": 0.0004860233972628232,
      "loss": 0.8468,
      "step": 185450
    },
    {
      "epoch": 1.9637785105943755,
      "grad_norm": 0.8618667125701904,
      "learning_rate": 0.0004860081646745037,
      "loss": 0.8343,
      "step": 185500
    },
    {
      "epoch": 1.9637785105943755,
      "eval_loss": 0.6604682207107544,
      "eval_runtime": 46.724,
      "eval_samples_per_second": 3594.087,
      "eval_steps_per_second": 449.277,
      "step": 185500
    },
    {
      "epoch": 1.9643078323743786,
      "grad_norm": 0.9427306056022644,
      "learning_rate": 0.000485992924028952,
      "loss": 0.8353,
      "step": 185550
    },
    {
      "epoch": 1.9648371541543819,
      "grad_norm": 0.9325933456420898,
      "learning_rate": 0.00048597767532668846,
      "loss": 0.8248,
      "step": 185600
    },
    {
      "epoch": 1.9653664759343852,
      "grad_norm": 0.8799854516983032,
      "learning_rate": 0.0004859624185682336,
      "loss": 0.835,
      "step": 185650
    },
    {
      "epoch": 1.9658957977143885,
      "grad_norm": 0.9050565958023071,
      "learning_rate": 0.0004859471537541083,
      "loss": 0.8435,
      "step": 185700
    },
    {
      "epoch": 1.9664251194943918,
      "grad_norm": 0.8594574928283691,
      "learning_rate": 0.0004859318808848337,
      "loss": 0.8455,
      "step": 185750
    },
    {
      "epoch": 1.9669544412743951,
      "grad_norm": 0.9288020133972168,
      "learning_rate": 0.0004859165999609312,
      "loss": 0.8468,
      "step": 185800
    },
    {
      "epoch": 1.9674837630543984,
      "grad_norm": 0.887184202671051,
      "learning_rate": 0.0004859013109829226,
      "loss": 0.8345,
      "step": 185850
    },
    {
      "epoch": 1.9680130848344017,
      "grad_norm": 0.8869261741638184,
      "learning_rate": 0.0004858860139513296,
      "loss": 0.8438,
      "step": 185900
    },
    {
      "epoch": 1.968542406614405,
      "grad_norm": 0.9374385476112366,
      "learning_rate": 0.00048587070886667473,
      "loss": 0.8567,
      "step": 185950
    },
    {
      "epoch": 1.9690717283944084,
      "grad_norm": 1.0330663919448853,
      "learning_rate": 0.0004858553957294802,
      "loss": 0.8384,
      "step": 186000
    },
    {
      "epoch": 1.9690717283944084,
      "eval_loss": 0.6602081060409546,
      "eval_runtime": 46.7342,
      "eval_samples_per_second": 3593.3,
      "eval_steps_per_second": 449.179,
      "step": 186000
    },
    {
      "epoch": 1.9696010501744117,
      "grad_norm": 0.9757534861564636,
      "learning_rate": 0.0004858400745402691,
      "loss": 0.8514,
      "step": 186050
    },
    {
      "epoch": 1.9701303719544148,
      "grad_norm": 0.8002815842628479,
      "learning_rate": 0.00048582505196327966,
      "loss": 0.8341,
      "step": 186100
    },
    {
      "epoch": 1.970659693734418,
      "grad_norm": 0.9204899072647095,
      "learning_rate": 0.0004858097148326188,
      "loss": 0.8471,
      "step": 186150
    },
    {
      "epoch": 1.9711890155144214,
      "grad_norm": 0.8451798558235168,
      "learning_rate": 0.0004857943696515008,
      "loss": 0.8462,
      "step": 186200
    },
    {
      "epoch": 1.9717183372944247,
      "grad_norm": 0.8893258571624756,
      "learning_rate": 0.0004857790164204495,
      "loss": 0.8321,
      "step": 186250
    },
    {
      "epoch": 1.9722476590744278,
      "grad_norm": 0.9731652736663818,
      "learning_rate": 0.000485763655139989,
      "loss": 0.8385,
      "step": 186300
    },
    {
      "epoch": 1.972776980854431,
      "grad_norm": 0.9492601156234741,
      "learning_rate": 0.0004857482858106438,
      "loss": 0.845,
      "step": 186350
    },
    {
      "epoch": 1.9733063026344344,
      "grad_norm": 0.9788131713867188,
      "learning_rate": 0.0004857329084329386,
      "loss": 0.8351,
      "step": 186400
    },
    {
      "epoch": 1.9738356244144377,
      "grad_norm": 0.8883556723594666,
      "learning_rate": 0.00048571752300739833,
      "loss": 0.8514,
      "step": 186450
    },
    {
      "epoch": 1.974364946194441,
      "grad_norm": 0.8459339737892151,
      "learning_rate": 0.0004857021295345483,
      "loss": 0.8358,
      "step": 186500
    },
    {
      "epoch": 1.974364946194441,
      "eval_loss": 0.6655412912368774,
      "eval_runtime": 46.7601,
      "eval_samples_per_second": 3591.309,
      "eval_steps_per_second": 448.93,
      "step": 186500
    },
    {
      "epoch": 1.9748942679744443,
      "grad_norm": 0.8009687066078186,
      "learning_rate": 0.00048568672801491396,
      "loss": 0.8452,
      "step": 186550
    },
    {
      "epoch": 1.9754235897544477,
      "grad_norm": 0.8010996580123901,
      "learning_rate": 0.00048567131844902124,
      "loss": 0.8364,
      "step": 186600
    },
    {
      "epoch": 1.975952911534451,
      "grad_norm": 0.8554328083992004,
      "learning_rate": 0.0004856559008373961,
      "loss": 0.8375,
      "step": 186650
    },
    {
      "epoch": 1.9764822333144543,
      "grad_norm": 0.9440015554428101,
      "learning_rate": 0.0004856404751805649,
      "loss": 0.8441,
      "step": 186700
    },
    {
      "epoch": 1.9770115550944576,
      "grad_norm": 0.9269425868988037,
      "learning_rate": 0.0004856250414790543,
      "loss": 0.8368,
      "step": 186750
    },
    {
      "epoch": 1.977540876874461,
      "grad_norm": 0.9222485423088074,
      "learning_rate": 0.00048560959973339117,
      "loss": 0.848,
      "step": 186800
    },
    {
      "epoch": 1.978070198654464,
      "grad_norm": 0.848333477973938,
      "learning_rate": 0.00048559414994410276,
      "loss": 0.8528,
      "step": 186850
    },
    {
      "epoch": 1.9785995204344673,
      "grad_norm": 0.8287101984024048,
      "learning_rate": 0.0004855786921117165,
      "loss": 0.842,
      "step": 186900
    },
    {
      "epoch": 1.9791288422144706,
      "grad_norm": 0.9842905402183533,
      "learning_rate": 0.00048556322623676007,
      "loss": 0.835,
      "step": 186950
    },
    {
      "epoch": 1.979658163994474,
      "grad_norm": 1.0300146341323853,
      "learning_rate": 0.00048554775231976147,
      "loss": 0.8377,
      "step": 187000
    },
    {
      "epoch": 1.979658163994474,
      "eval_loss": 0.6598390936851501,
      "eval_runtime": 46.7992,
      "eval_samples_per_second": 3588.312,
      "eval_steps_per_second": 448.555,
      "step": 187000
    },
    {
      "epoch": 1.980187485774477,
      "grad_norm": 0.9437257647514343,
      "learning_rate": 0.00048553227036124896,
      "loss": 0.8523,
      "step": 187050
    },
    {
      "epoch": 1.9807168075544803,
      "grad_norm": 0.7961574196815491,
      "learning_rate": 0.0004855167803617512,
      "loss": 0.8288,
      "step": 187100
    },
    {
      "epoch": 1.9812461293344836,
      "grad_norm": 0.8773442506790161,
      "learning_rate": 0.0004855012823217968,
      "loss": 0.8386,
      "step": 187150
    },
    {
      "epoch": 1.981775451114487,
      "grad_norm": 0.9014909267425537,
      "learning_rate": 0.00048548577624191516,
      "loss": 0.8526,
      "step": 187200
    },
    {
      "epoch": 1.9823047728944903,
      "grad_norm": 0.8707835078239441,
      "learning_rate": 0.00048547026212263534,
      "loss": 0.8369,
      "step": 187250
    },
    {
      "epoch": 1.9828340946744936,
      "grad_norm": 0.9061770439147949,
      "learning_rate": 0.0004854547399644872,
      "loss": 0.8359,
      "step": 187300
    },
    {
      "epoch": 1.9833634164544969,
      "grad_norm": 0.8950493335723877,
      "learning_rate": 0.00048543920976800055,
      "loss": 0.837,
      "step": 187350
    },
    {
      "epoch": 1.9838927382345002,
      "grad_norm": 0.8847927451133728,
      "learning_rate": 0.00048542367153370567,
      "loss": 0.8476,
      "step": 187400
    },
    {
      "epoch": 1.9844220600145035,
      "grad_norm": 0.8238982558250427,
      "learning_rate": 0.0004854081252621329,
      "loss": 0.8318,
      "step": 187450
    },
    {
      "epoch": 1.9849513817945068,
      "grad_norm": 0.9216398000717163,
      "learning_rate": 0.00048539257095381316,
      "loss": 0.8349,
      "step": 187500
    },
    {
      "epoch": 1.9849513817945068,
      "eval_loss": 0.6631014347076416,
      "eval_runtime": 46.7372,
      "eval_samples_per_second": 3593.066,
      "eval_steps_per_second": 449.149,
      "step": 187500
    },
    {
      "epoch": 1.9854807035745101,
      "grad_norm": 0.8949928283691406,
      "learning_rate": 0.0004853770086092773,
      "loss": 0.8448,
      "step": 187550
    },
    {
      "epoch": 1.9860100253545132,
      "grad_norm": 0.8780747056007385,
      "learning_rate": 0.00048536143822905674,
      "loss": 0.8359,
      "step": 187600
    },
    {
      "epoch": 1.9865393471345165,
      "grad_norm": 0.8709767460823059,
      "learning_rate": 0.00048534585981368296,
      "loss": 0.8411,
      "step": 187650
    },
    {
      "epoch": 1.9870686689145198,
      "grad_norm": 0.8519793748855591,
      "learning_rate": 0.0004853302733636878,
      "loss": 0.8297,
      "step": 187700
    },
    {
      "epoch": 1.9875979906945231,
      "grad_norm": 0.8107172846794128,
      "learning_rate": 0.00048531467887960356,
      "loss": 0.8337,
      "step": 187750
    },
    {
      "epoch": 1.9881273124745262,
      "grad_norm": 0.8605427742004395,
      "learning_rate": 0.00048529907636196234,
      "loss": 0.8326,
      "step": 187800
    },
    {
      "epoch": 1.9886566342545295,
      "grad_norm": 0.8539203405380249,
      "learning_rate": 0.000485283465811297,
      "loss": 0.8384,
      "step": 187850
    },
    {
      "epoch": 1.9891859560345329,
      "grad_norm": 0.8756691813468933,
      "learning_rate": 0.00048526784722814045,
      "loss": 0.8458,
      "step": 187900
    },
    {
      "epoch": 1.9897152778145362,
      "grad_norm": 0.8847789764404297,
      "learning_rate": 0.0004852522206130259,
      "loss": 0.8369,
      "step": 187950
    },
    {
      "epoch": 1.9902445995945395,
      "grad_norm": 0.939441442489624,
      "learning_rate": 0.00048523658596648665,
      "loss": 0.8528,
      "step": 188000
    },
    {
      "epoch": 1.9902445995945395,
      "eval_loss": 0.6606976389884949,
      "eval_runtime": 46.7322,
      "eval_samples_per_second": 3593.452,
      "eval_steps_per_second": 449.198,
      "step": 188000
    },
    {
      "epoch": 1.9907739213745428,
      "grad_norm": 0.874517560005188,
      "learning_rate": 0.0004852209432890568,
      "loss": 0.8355,
      "step": 188050
    },
    {
      "epoch": 1.991303243154546,
      "grad_norm": 0.8910775780677795,
      "learning_rate": 0.00048520529258127014,
      "loss": 0.8399,
      "step": 188100
    },
    {
      "epoch": 1.9918325649345494,
      "grad_norm": 0.845042884349823,
      "learning_rate": 0.00048518994709710204,
      "loss": 0.8324,
      "step": 188150
    },
    {
      "epoch": 1.9923618867145527,
      "grad_norm": 0.842376708984375,
      "learning_rate": 0.00048517428049078565,
      "loss": 0.843,
      "step": 188200
    },
    {
      "epoch": 1.992891208494556,
      "grad_norm": 0.95850670337677,
      "learning_rate": 0.0004851586058557056,
      "loss": 0.8217,
      "step": 188250
    },
    {
      "epoch": 1.9934205302745593,
      "grad_norm": 0.8795773386955261,
      "learning_rate": 0.0004851429231923969,
      "loss": 0.8389,
      "step": 188300
    },
    {
      "epoch": 1.9939498520545627,
      "grad_norm": 0.8797818422317505,
      "learning_rate": 0.0004851272325013951,
      "loss": 0.8328,
      "step": 188350
    },
    {
      "epoch": 1.9944791738345657,
      "grad_norm": 0.9461666345596313,
      "learning_rate": 0.0004851115337832358,
      "loss": 0.8445,
      "step": 188400
    },
    {
      "epoch": 1.995008495614569,
      "grad_norm": 0.8274168968200684,
      "learning_rate": 0.0004850958270384549,
      "loss": 0.8395,
      "step": 188450
    },
    {
      "epoch": 1.9955378173945724,
      "grad_norm": 0.9298205375671387,
      "learning_rate": 0.00048508011226758876,
      "loss": 0.8353,
      "step": 188500
    },
    {
      "epoch": 1.9955378173945724,
      "eval_loss": 0.6569989323616028,
      "eval_runtime": 46.6671,
      "eval_samples_per_second": 3598.469,
      "eval_steps_per_second": 449.825,
      "step": 188500
    },
    {
      "epoch": 1.9960671391745755,
      "grad_norm": 0.8892353773117065,
      "learning_rate": 0.0004850643894711738,
      "loss": 0.8193,
      "step": 188550
    },
    {
      "epoch": 1.9965964609545788,
      "grad_norm": 0.9088172912597656,
      "learning_rate": 0.0004850486586497468,
      "loss": 0.814,
      "step": 188600
    },
    {
      "epoch": 1.997125782734582,
      "grad_norm": 0.8659005165100098,
      "learning_rate": 0.00048503291980384473,
      "loss": 0.8337,
      "step": 188650
    },
    {
      "epoch": 1.9976551045145854,
      "grad_norm": 0.9345417618751526,
      "learning_rate": 0.000485017172934005,
      "loss": 0.8321,
      "step": 188700
    },
    {
      "epoch": 1.9981844262945887,
      "grad_norm": 0.9516407251358032,
      "learning_rate": 0.0004850014180407652,
      "loss": 0.8384,
      "step": 188750
    },
    {
      "epoch": 1.998713748074592,
      "grad_norm": 0.8673548102378845,
      "learning_rate": 0.00048498565512466313,
      "loss": 0.8467,
      "step": 188800
    },
    {
      "epoch": 1.9992430698545953,
      "grad_norm": 0.8226494193077087,
      "learning_rate": 0.000484969884186237,
      "loss": 0.8336,
      "step": 188850
    },
    {
      "epoch": 1.9997723916345986,
      "grad_norm": 0.8875371217727661,
      "learning_rate": 0.0004849541052260252,
      "loss": 0.8579,
      "step": 188900
    },
    {
      "epoch": 2.000296420196802,
      "grad_norm": 0.8598702549934387,
      "learning_rate": 0.0004849383182445664,
      "loss": 0.8168,
      "step": 188950
    },
    {
      "epoch": 2.000825741976805,
      "grad_norm": 0.9194342494010925,
      "learning_rate": 0.0004849225232423996,
      "loss": 0.8274,
      "step": 189000
    },
    {
      "epoch": 2.000825741976805,
      "eval_loss": 0.6563777327537537,
      "eval_runtime": 46.7236,
      "eval_samples_per_second": 3594.115,
      "eval_steps_per_second": 449.28,
      "step": 189000
    },
    {
      "epoch": 2.0013550637568085,
      "grad_norm": 0.941582977771759,
      "learning_rate": 0.000484906720220064,
      "loss": 0.8247,
      "step": 189050
    },
    {
      "epoch": 2.001884385536812,
      "grad_norm": 0.9252254962921143,
      "learning_rate": 0.0004848909091780991,
      "loss": 0.8367,
      "step": 189100
    },
    {
      "epoch": 2.002413707316815,
      "grad_norm": 1.007771372795105,
      "learning_rate": 0.0004848750901170448,
      "loss": 0.8349,
      "step": 189150
    },
    {
      "epoch": 2.0029430290968184,
      "grad_norm": 0.9258381724357605,
      "learning_rate": 0.0004848592630374409,
      "loss": 0.8242,
      "step": 189200
    },
    {
      "epoch": 2.0034723508768217,
      "grad_norm": 0.992125928401947,
      "learning_rate": 0.00048484342793982804,
      "loss": 0.8403,
      "step": 189250
    },
    {
      "epoch": 2.0040016726568246,
      "grad_norm": 0.9197382926940918,
      "learning_rate": 0.0004848275848247466,
      "loss": 0.818,
      "step": 189300
    },
    {
      "epoch": 2.004530994436828,
      "grad_norm": 0.855189859867096,
      "learning_rate": 0.00048481173369273756,
      "loss": 0.8423,
      "step": 189350
    },
    {
      "epoch": 2.0050603162168312,
      "grad_norm": 0.8775806427001953,
      "learning_rate": 0.00048479587454434205,
      "loss": 0.8185,
      "step": 189400
    },
    {
      "epoch": 2.0055896379968345,
      "grad_norm": 0.9790375828742981,
      "learning_rate": 0.00048478000738010144,
      "loss": 0.8377,
      "step": 189450
    },
    {
      "epoch": 2.006118959776838,
      "grad_norm": 0.9110092520713806,
      "learning_rate": 0.00048476413220055746,
      "loss": 0.8217,
      "step": 189500
    },
    {
      "epoch": 2.006118959776838,
      "eval_loss": 0.6589473485946655,
      "eval_runtime": 46.7377,
      "eval_samples_per_second": 3593.032,
      "eval_steps_per_second": 449.145,
      "step": 189500
    },
    {
      "epoch": 2.006648281556841,
      "grad_norm": 0.860995352268219,
      "learning_rate": 0.00048474824900625226,
      "loss": 0.8046,
      "step": 189550
    },
    {
      "epoch": 2.0071776033368445,
      "grad_norm": 0.9748105406761169,
      "learning_rate": 0.0004847323577977278,
      "loss": 0.829,
      "step": 189600
    },
    {
      "epoch": 2.007706925116848,
      "grad_norm": 0.9595338702201843,
      "learning_rate": 0.0004847164585755268,
      "loss": 0.8382,
      "step": 189650
    },
    {
      "epoch": 2.008236246896851,
      "grad_norm": 0.8623219132423401,
      "learning_rate": 0.0004847005513401919,
      "loss": 0.8263,
      "step": 189700
    },
    {
      "epoch": 2.0087655686768544,
      "grad_norm": 0.9265828132629395,
      "learning_rate": 0.0004846846360922663,
      "loss": 0.8392,
      "step": 189750
    },
    {
      "epoch": 2.0092948904568577,
      "grad_norm": 0.9085410237312317,
      "learning_rate": 0.0004846687128322933,
      "loss": 0.8409,
      "step": 189800
    },
    {
      "epoch": 2.009824212236861,
      "grad_norm": 0.8264102339744568,
      "learning_rate": 0.00048465278156081647,
      "loss": 0.8264,
      "step": 189850
    },
    {
      "epoch": 2.0103535340168643,
      "grad_norm": 0.8980054259300232,
      "learning_rate": 0.0004846368422783798,
      "loss": 0.8352,
      "step": 189900
    },
    {
      "epoch": 2.0108828557968677,
      "grad_norm": 0.8647884726524353,
      "learning_rate": 0.0004846208949855273,
      "loss": 0.8308,
      "step": 189950
    },
    {
      "epoch": 2.011412177576871,
      "grad_norm": 0.970242977142334,
      "learning_rate": 0.00048460493968280354,
      "loss": 0.8276,
      "step": 190000
    },
    {
      "epoch": 2.011412177576871,
      "eval_loss": 0.6553952693939209,
      "eval_runtime": 46.7099,
      "eval_samples_per_second": 3595.168,
      "eval_steps_per_second": 449.412,
      "step": 190000
    },
    {
      "epoch": 2.011941499356874,
      "grad_norm": 0.8618841767311096,
      "learning_rate": 0.00048458897637075317,
      "loss": 0.83,
      "step": 190050
    },
    {
      "epoch": 2.012470821136877,
      "grad_norm": 0.9391464591026306,
      "learning_rate": 0.00048457300504992117,
      "loss": 0.8081,
      "step": 190100
    },
    {
      "epoch": 2.0130001429168805,
      "grad_norm": 0.7967210412025452,
      "learning_rate": 0.00048455702572085285,
      "loss": 0.8357,
      "step": 190150
    },
    {
      "epoch": 2.0135294646968838,
      "grad_norm": 1.005982756614685,
      "learning_rate": 0.00048454135820930066,
      "loss": 0.823,
      "step": 190200
    },
    {
      "epoch": 2.014058786476887,
      "grad_norm": 0.838782548904419,
      "learning_rate": 0.00048452536302553403,
      "loss": 0.8248,
      "step": 190250
    },
    {
      "epoch": 2.0145881082568904,
      "grad_norm": 0.9408521056175232,
      "learning_rate": 0.00048450935983515743,
      "loss": 0.8215,
      "step": 190300
    },
    {
      "epoch": 2.0151174300368937,
      "grad_norm": 0.8601163029670715,
      "learning_rate": 0.00048449334863871735,
      "loss": 0.8337,
      "step": 190350
    },
    {
      "epoch": 2.015646751816897,
      "grad_norm": 0.8951792120933533,
      "learning_rate": 0.00048447732943676035,
      "loss": 0.8462,
      "step": 190400
    },
    {
      "epoch": 2.0161760735969003,
      "grad_norm": 0.9265273213386536,
      "learning_rate": 0.00048446130222983333,
      "loss": 0.8179,
      "step": 190450
    },
    {
      "epoch": 2.0167053953769036,
      "grad_norm": 0.9741508364677429,
      "learning_rate": 0.00048444526701848335,
      "loss": 0.8285,
      "step": 190500
    },
    {
      "epoch": 2.0167053953769036,
      "eval_loss": 0.6571445465087891,
      "eval_runtime": 46.7688,
      "eval_samples_per_second": 3590.64,
      "eval_steps_per_second": 448.846,
      "step": 190500
    },
    {
      "epoch": 2.017234717156907,
      "grad_norm": 0.8623780012130737,
      "learning_rate": 0.00048442922380325797,
      "loss": 0.8125,
      "step": 190550
    },
    {
      "epoch": 2.0177640389369103,
      "grad_norm": 0.8613967299461365,
      "learning_rate": 0.00048441317258470494,
      "loss": 0.828,
      "step": 190600
    },
    {
      "epoch": 2.0182933607169136,
      "grad_norm": 0.8021978735923767,
      "learning_rate": 0.00048439711336337204,
      "loss": 0.8422,
      "step": 190650
    },
    {
      "epoch": 2.018822682496917,
      "grad_norm": 0.8772805333137512,
      "learning_rate": 0.0004843810461398077,
      "loss": 0.8255,
      "step": 190700
    },
    {
      "epoch": 2.01935200427692,
      "grad_norm": 0.8193714618682861,
      "learning_rate": 0.00048436497091456043,
      "loss": 0.8248,
      "step": 190750
    },
    {
      "epoch": 2.019881326056923,
      "grad_norm": 0.8615049719810486,
      "learning_rate": 0.00048434888768817904,
      "loss": 0.8182,
      "step": 190800
    },
    {
      "epoch": 2.0204106478369264,
      "grad_norm": 0.8045768141746521,
      "learning_rate": 0.00048433279646121254,
      "loss": 0.8235,
      "step": 190850
    },
    {
      "epoch": 2.0209399696169297,
      "grad_norm": 0.8966596126556396,
      "learning_rate": 0.00048431669723421024,
      "loss": 0.8162,
      "step": 190900
    },
    {
      "epoch": 2.021469291396933,
      "grad_norm": 0.8594428896903992,
      "learning_rate": 0.0004843005900077219,
      "loss": 0.8209,
      "step": 190950
    },
    {
      "epoch": 2.0219986131769363,
      "grad_norm": 0.9403397440910339,
      "learning_rate": 0.0004842844747822973,
      "loss": 0.8307,
      "step": 191000
    },
    {
      "epoch": 2.0219986131769363,
      "eval_loss": 0.6542449593544006,
      "eval_runtime": 46.7406,
      "eval_samples_per_second": 3592.807,
      "eval_steps_per_second": 449.117,
      "step": 191000
    },
    {
      "epoch": 2.0225279349569396,
      "grad_norm": 0.8733064532279968,
      "learning_rate": 0.0004842683515584867,
      "loss": 0.8218,
      "step": 191050
    },
    {
      "epoch": 2.023057256736943,
      "grad_norm": 0.8128774762153625,
      "learning_rate": 0.00048425222033684047,
      "loss": 0.838,
      "step": 191100
    },
    {
      "epoch": 2.0235865785169462,
      "grad_norm": 0.9093989729881287,
      "learning_rate": 0.00048423608111790935,
      "loss": 0.8297,
      "step": 191150
    },
    {
      "epoch": 2.0241159002969495,
      "grad_norm": 0.9501854181289673,
      "learning_rate": 0.00048421993390224436,
      "loss": 0.8386,
      "step": 191200
    },
    {
      "epoch": 2.024645222076953,
      "grad_norm": 0.8747401237487793,
      "learning_rate": 0.00048420377869039667,
      "loss": 0.8418,
      "step": 191250
    },
    {
      "epoch": 2.025174543856956,
      "grad_norm": 0.861886739730835,
      "learning_rate": 0.0004841876154829179,
      "loss": 0.8292,
      "step": 191300
    },
    {
      "epoch": 2.0257038656369595,
      "grad_norm": 0.9752936363220215,
      "learning_rate": 0.00048417144428035977,
      "loss": 0.8284,
      "step": 191350
    },
    {
      "epoch": 2.026233187416963,
      "grad_norm": 0.8885644674301147,
      "learning_rate": 0.00048415526508327445,
      "loss": 0.8436,
      "step": 191400
    },
    {
      "epoch": 2.026762509196966,
      "grad_norm": 0.9172626733779907,
      "learning_rate": 0.00048413907789221424,
      "loss": 0.8298,
      "step": 191450
    },
    {
      "epoch": 2.0272918309769694,
      "grad_norm": 0.9278278350830078,
      "learning_rate": 0.0004841228827077318,
      "loss": 0.8396,
      "step": 191500
    },
    {
      "epoch": 2.0272918309769694,
      "eval_loss": 0.6557064056396484,
      "eval_runtime": 46.7312,
      "eval_samples_per_second": 3593.532,
      "eval_steps_per_second": 449.208,
      "step": 191500
    },
    {
      "epoch": 2.0278211527569723,
      "grad_norm": 0.9043773412704468,
      "learning_rate": 0.00048410667953038003,
      "loss": 0.8126,
      "step": 191550
    },
    {
      "epoch": 2.0283504745369756,
      "grad_norm": 0.9382721781730652,
      "learning_rate": 0.00048409046836071204,
      "loss": 0.83,
      "step": 191600
    },
    {
      "epoch": 2.028879796316979,
      "grad_norm": 0.9323835968971252,
      "learning_rate": 0.00048407424919928136,
      "loss": 0.8482,
      "step": 191650
    },
    {
      "epoch": 2.029409118096982,
      "grad_norm": 0.8592758178710938,
      "learning_rate": 0.0004840580220466415,
      "loss": 0.8336,
      "step": 191700
    },
    {
      "epoch": 2.0299384398769855,
      "grad_norm": 0.9402234554290771,
      "learning_rate": 0.0004840417869033468,
      "loss": 0.8361,
      "step": 191750
    },
    {
      "epoch": 2.030467761656989,
      "grad_norm": 0.9220717549324036,
      "learning_rate": 0.00048402554376995123,
      "loss": 0.8339,
      "step": 191800
    },
    {
      "epoch": 2.030997083436992,
      "grad_norm": 0.8124584555625916,
      "learning_rate": 0.0004840092926470094,
      "loss": 0.8153,
      "step": 191850
    },
    {
      "epoch": 2.0315264052169955,
      "grad_norm": 0.9484931230545044,
      "learning_rate": 0.0004839930335350762,
      "loss": 0.8465,
      "step": 191900
    },
    {
      "epoch": 2.0320557269969988,
      "grad_norm": 0.9390538930892944,
      "learning_rate": 0.0004839767664347066,
      "loss": 0.8281,
      "step": 191950
    },
    {
      "epoch": 2.032585048777002,
      "grad_norm": 0.8617382049560547,
      "learning_rate": 0.00048396049134645606,
      "loss": 0.8374,
      "step": 192000
    },
    {
      "epoch": 2.032585048777002,
      "eval_loss": 0.6530647277832031,
      "eval_runtime": 46.659,
      "eval_samples_per_second": 3599.089,
      "eval_steps_per_second": 449.902,
      "step": 192000
    },
    {
      "epoch": 2.0331143705570054,
      "grad_norm": 0.9146631956100464,
      "learning_rate": 0.00048394420827088013,
      "loss": 0.822,
      "step": 192050
    },
    {
      "epoch": 2.0336436923370087,
      "grad_norm": 0.9479286074638367,
      "learning_rate": 0.0004839279172085347,
      "loss": 0.8272,
      "step": 192100
    },
    {
      "epoch": 2.034173014117012,
      "grad_norm": 0.9171090722084045,
      "learning_rate": 0.00048391161815997596,
      "loss": 0.8352,
      "step": 192150
    },
    {
      "epoch": 2.0347023358970153,
      "grad_norm": 0.9142614006996155,
      "learning_rate": 0.0004838953111257604,
      "loss": 0.8232,
      "step": 192200
    },
    {
      "epoch": 2.0352316576770186,
      "grad_norm": 0.8645891547203064,
      "learning_rate": 0.0004838789961064447,
      "loss": 0.8229,
      "step": 192250
    },
    {
      "epoch": 2.0357609794570215,
      "grad_norm": 0.8728799223899841,
      "learning_rate": 0.0004838626731025858,
      "loss": 0.8299,
      "step": 192300
    },
    {
      "epoch": 2.036290301237025,
      "grad_norm": 0.9097310304641724,
      "learning_rate": 0.000483846342114741,
      "loss": 0.822,
      "step": 192350
    },
    {
      "epoch": 2.036819623017028,
      "grad_norm": 0.9155136942863464,
      "learning_rate": 0.00048383033000112737,
      "loss": 0.8455,
      "step": 192400
    },
    {
      "epoch": 2.0373489447970314,
      "grad_norm": 0.8396084308624268,
      "learning_rate": 0.0004838139832066356,
      "loss": 0.8362,
      "step": 192450
    },
    {
      "epoch": 2.0378782665770347,
      "grad_norm": 0.931376039981842,
      "learning_rate": 0.00048379762842982023,
      "loss": 0.8381,
      "step": 192500
    },
    {
      "epoch": 2.0378782665770347,
      "eval_loss": 0.6485957503318787,
      "eval_runtime": 46.8403,
      "eval_samples_per_second": 3585.159,
      "eval_steps_per_second": 448.161,
      "step": 192500
    },
    {
      "epoch": 2.038407588357038,
      "grad_norm": 0.9862783551216125,
      "learning_rate": 0.0004837812656712396,
      "loss": 0.8366,
      "step": 192550
    },
    {
      "epoch": 2.0389369101370414,
      "grad_norm": 0.9531692862510681,
      "learning_rate": 0.00048376489493145227,
      "loss": 0.818,
      "step": 192600
    },
    {
      "epoch": 2.0394662319170447,
      "grad_norm": 0.8933022618293762,
      "learning_rate": 0.0004837485162110171,
      "loss": 0.8144,
      "step": 192650
    },
    {
      "epoch": 2.039995553697048,
      "grad_norm": 0.8784175515174866,
      "learning_rate": 0.0004837321295104934,
      "loss": 0.8374,
      "step": 192700
    },
    {
      "epoch": 2.0405248754770513,
      "grad_norm": 0.8299590349197388,
      "learning_rate": 0.0004837157348304404,
      "loss": 0.8227,
      "step": 192750
    },
    {
      "epoch": 2.0410541972570546,
      "grad_norm": 0.8155520558357239,
      "learning_rate": 0.00048369933217141806,
      "loss": 0.837,
      "step": 192800
    },
    {
      "epoch": 2.041583519037058,
      "grad_norm": 0.951744556427002,
      "learning_rate": 0.0004836829215339862,
      "loss": 0.8264,
      "step": 192850
    },
    {
      "epoch": 2.0421128408170612,
      "grad_norm": 0.8925893306732178,
      "learning_rate": 0.000483666502918705,
      "loss": 0.8367,
      "step": 192900
    },
    {
      "epoch": 2.0426421625970645,
      "grad_norm": 0.8459944128990173,
      "learning_rate": 0.00048365007632613516,
      "loss": 0.8413,
      "step": 192950
    },
    {
      "epoch": 2.043171484377068,
      "grad_norm": 0.9066274166107178,
      "learning_rate": 0.0004836336417568374,
      "loss": 0.8341,
      "step": 193000
    },
    {
      "epoch": 2.043171484377068,
      "eval_loss": 0.6479470133781433,
      "eval_runtime": 46.977,
      "eval_samples_per_second": 3574.726,
      "eval_steps_per_second": 446.857,
      "step": 193000
    },
    {
      "epoch": 2.043700806157071,
      "grad_norm": 0.9983361959457397,
      "learning_rate": 0.0004836171992113728,
      "loss": 0.8241,
      "step": 193050
    },
    {
      "epoch": 2.044230127937074,
      "grad_norm": 0.8861634135246277,
      "learning_rate": 0.00048360074869030267,
      "loss": 0.8231,
      "step": 193100
    },
    {
      "epoch": 2.0447594497170773,
      "grad_norm": 0.9035338759422302,
      "learning_rate": 0.0004835842901941887,
      "loss": 0.8224,
      "step": 193150
    },
    {
      "epoch": 2.0452887714970807,
      "grad_norm": 0.8100996017456055,
      "learning_rate": 0.00048356782372359266,
      "loss": 0.8167,
      "step": 193200
    },
    {
      "epoch": 2.045818093277084,
      "grad_norm": 0.8936430811882019,
      "learning_rate": 0.00048355134927907683,
      "loss": 0.8261,
      "step": 193250
    },
    {
      "epoch": 2.0463474150570873,
      "grad_norm": 0.8940921425819397,
      "learning_rate": 0.0004835348668612035,
      "loss": 0.8163,
      "step": 193300
    },
    {
      "epoch": 2.0468767368370906,
      "grad_norm": 0.8658183813095093,
      "learning_rate": 0.0004835183764705356,
      "loss": 0.8343,
      "step": 193350
    },
    {
      "epoch": 2.047406058617094,
      "grad_norm": 0.9339635372161865,
      "learning_rate": 0.0004835018781076359,
      "loss": 0.825,
      "step": 193400
    },
    {
      "epoch": 2.047935380397097,
      "grad_norm": 0.885596752166748,
      "learning_rate": 0.0004834853717730677,
      "loss": 0.8284,
      "step": 193450
    },
    {
      "epoch": 2.0484647021771005,
      "grad_norm": 0.8785460591316223,
      "learning_rate": 0.00048346885746739453,
      "loss": 0.817,
      "step": 193500
    },
    {
      "epoch": 2.0484647021771005,
      "eval_loss": 0.6474496722221375,
      "eval_runtime": 46.8142,
      "eval_samples_per_second": 3587.161,
      "eval_steps_per_second": 448.411,
      "step": 193500
    },
    {
      "epoch": 2.048994023957104,
      "grad_norm": 0.9685205817222595,
      "learning_rate": 0.0004834523351911802,
      "loss": 0.8305,
      "step": 193550
    },
    {
      "epoch": 2.049523345737107,
      "grad_norm": 0.8858783841133118,
      "learning_rate": 0.0004834358049449888,
      "loss": 0.8269,
      "step": 193600
    },
    {
      "epoch": 2.0500526675171105,
      "grad_norm": 1.031095266342163,
      "learning_rate": 0.0004834192667293846,
      "loss": 0.8245,
      "step": 193650
    },
    {
      "epoch": 2.0505819892971138,
      "grad_norm": 0.9725126028060913,
      "learning_rate": 0.0004834027205449322,
      "loss": 0.8403,
      "step": 193700
    },
    {
      "epoch": 2.051111311077117,
      "grad_norm": 0.9199798703193665,
      "learning_rate": 0.00048338616639219655,
      "loss": 0.8217,
      "step": 193750
    },
    {
      "epoch": 2.0516406328571204,
      "grad_norm": 0.8439134359359741,
      "learning_rate": 0.0004833696042717428,
      "loss": 0.823,
      "step": 193800
    },
    {
      "epoch": 2.0521699546371233,
      "grad_norm": 0.9629091620445251,
      "learning_rate": 0.0004833530341841363,
      "loss": 0.8273,
      "step": 193850
    },
    {
      "epoch": 2.0526992764171266,
      "grad_norm": 0.8476642370223999,
      "learning_rate": 0.0004833364561299428,
      "loss": 0.8251,
      "step": 193900
    },
    {
      "epoch": 2.05322859819713,
      "grad_norm": 0.8958854675292969,
      "learning_rate": 0.0004833198701097283,
      "loss": 0.8179,
      "step": 193950
    },
    {
      "epoch": 2.053757919977133,
      "grad_norm": 0.8942142724990845,
      "learning_rate": 0.000483303276124059,
      "loss": 0.8243,
      "step": 194000
    },
    {
      "epoch": 2.053757919977133,
      "eval_loss": 0.6484280824661255,
      "eval_runtime": 46.8107,
      "eval_samples_per_second": 3587.425,
      "eval_steps_per_second": 448.444,
      "step": 194000
    },
    {
      "epoch": 2.0542872417571365,
      "grad_norm": 0.8602163791656494,
      "learning_rate": 0.00048328667417350135,
      "loss": 0.826,
      "step": 194050
    },
    {
      "epoch": 2.05481656353714,
      "grad_norm": 0.8733275532722473,
      "learning_rate": 0.0004832700642586223,
      "loss": 0.8238,
      "step": 194100
    },
    {
      "epoch": 2.055345885317143,
      "grad_norm": 0.8826441764831543,
      "learning_rate": 0.0004832534463799887,
      "loss": 0.825,
      "step": 194150
    },
    {
      "epoch": 2.0558752070971464,
      "grad_norm": 0.849399983882904,
      "learning_rate": 0.00048323682053816807,
      "loss": 0.8372,
      "step": 194200
    },
    {
      "epoch": 2.0564045288771498,
      "grad_norm": 0.8526654839515686,
      "learning_rate": 0.00048322018673372784,
      "loss": 0.8063,
      "step": 194250
    },
    {
      "epoch": 2.056933850657153,
      "grad_norm": 1.0015478134155273,
      "learning_rate": 0.0004832035449672361,
      "loss": 0.8277,
      "step": 194300
    },
    {
      "epoch": 2.0574631724371564,
      "grad_norm": 0.8598800301551819,
      "learning_rate": 0.00048318689523926074,
      "loss": 0.832,
      "step": 194350
    },
    {
      "epoch": 2.0579924942171597,
      "grad_norm": 0.9091888070106506,
      "learning_rate": 0.00048317057078216144,
      "loss": 0.8217,
      "step": 194400
    },
    {
      "epoch": 2.058521815997163,
      "grad_norm": 0.9796402454376221,
      "learning_rate": 0.00048315390529212593,
      "loss": 0.8334,
      "step": 194450
    },
    {
      "epoch": 2.0590511377771663,
      "grad_norm": 0.8708540201187134,
      "learning_rate": 0.0004831372318423016,
      "loss": 0.8398,
      "step": 194500
    },
    {
      "epoch": 2.0590511377771663,
      "eval_loss": 0.6479616761207581,
      "eval_runtime": 46.7789,
      "eval_samples_per_second": 3589.867,
      "eval_steps_per_second": 448.749,
      "step": 194500
    },
    {
      "epoch": 2.0595804595571696,
      "grad_norm": 0.8657196760177612,
      "learning_rate": 0.00048312055043325775,
      "loss": 0.819,
      "step": 194550
    },
    {
      "epoch": 2.0601097813371725,
      "grad_norm": 1.0096838474273682,
      "learning_rate": 0.0004831038610655638,
      "loss": 0.8229,
      "step": 194600
    },
    {
      "epoch": 2.060639103117176,
      "grad_norm": 0.9042538404464722,
      "learning_rate": 0.00048308716373978957,
      "loss": 0.8198,
      "step": 194650
    },
    {
      "epoch": 2.061168424897179,
      "grad_norm": 0.8900327682495117,
      "learning_rate": 0.00048307045845650496,
      "loss": 0.7982,
      "step": 194700
    },
    {
      "epoch": 2.0616977466771824,
      "grad_norm": 0.8322824239730835,
      "learning_rate": 0.0004830537452162804,
      "loss": 0.8294,
      "step": 194750
    },
    {
      "epoch": 2.0622270684571857,
      "grad_norm": 0.9849105477333069,
      "learning_rate": 0.00048303702401968643,
      "loss": 0.8344,
      "step": 194800
    },
    {
      "epoch": 2.062756390237189,
      "grad_norm": 0.8625307083129883,
      "learning_rate": 0.0004830202948672939,
      "loss": 0.822,
      "step": 194850
    },
    {
      "epoch": 2.0632857120171924,
      "grad_norm": 0.8680405616760254,
      "learning_rate": 0.00048300355775967403,
      "loss": 0.8303,
      "step": 194900
    },
    {
      "epoch": 2.0638150337971957,
      "grad_norm": 0.846442699432373,
      "learning_rate": 0.0004829868126973981,
      "loss": 0.8359,
      "step": 194950
    },
    {
      "epoch": 2.064344355577199,
      "grad_norm": 0.9109647274017334,
      "learning_rate": 0.00048297005968103794,
      "loss": 0.8343,
      "step": 195000
    },
    {
      "epoch": 2.064344355577199,
      "eval_loss": 0.6476395130157471,
      "eval_runtime": 46.8066,
      "eval_samples_per_second": 3587.742,
      "eval_steps_per_second": 448.484,
      "step": 195000
    },
    {
      "epoch": 2.0648736773572023,
      "grad_norm": 0.938003420829773,
      "learning_rate": 0.00048295329871116523,
      "loss": 0.8166,
      "step": 195050
    },
    {
      "epoch": 2.0654029991372056,
      "grad_norm": 0.8865101933479309,
      "learning_rate": 0.0004829365297883524,
      "loss": 0.8114,
      "step": 195100
    },
    {
      "epoch": 2.065932320917209,
      "grad_norm": 0.895910918712616,
      "learning_rate": 0.0004829197529131719,
      "loss": 0.811,
      "step": 195150
    },
    {
      "epoch": 2.066461642697212,
      "grad_norm": 0.8742433190345764,
      "learning_rate": 0.0004829029680861964,
      "loss": 0.833,
      "step": 195200
    },
    {
      "epoch": 2.0669909644772155,
      "grad_norm": 0.8531402945518494,
      "learning_rate": 0.00048288617530799905,
      "loss": 0.8332,
      "step": 195250
    },
    {
      "epoch": 2.067520286257219,
      "grad_norm": 0.7879319787025452,
      "learning_rate": 0.00048286937457915304,
      "loss": 0.8135,
      "step": 195300
    },
    {
      "epoch": 2.0680496080372217,
      "grad_norm": 0.931425929069519,
      "learning_rate": 0.000482852565900232,
      "loss": 0.8178,
      "step": 195350
    },
    {
      "epoch": 2.068578929817225,
      "grad_norm": 0.7901609539985657,
      "learning_rate": 0.0004828357492718097,
      "loss": 0.8184,
      "step": 195400
    },
    {
      "epoch": 2.0691082515972283,
      "grad_norm": 0.829217255115509,
      "learning_rate": 0.0004828189246944603,
      "loss": 0.8238,
      "step": 195450
    },
    {
      "epoch": 2.0696375733772316,
      "grad_norm": 0.92728191614151,
      "learning_rate": 0.0004828020921687583,
      "loss": 0.836,
      "step": 195500
    },
    {
      "epoch": 2.0696375733772316,
      "eval_loss": 0.646649181842804,
      "eval_runtime": 46.8136,
      "eval_samples_per_second": 3587.206,
      "eval_steps_per_second": 448.417,
      "step": 195500
    },
    {
      "epoch": 2.070166895157235,
      "grad_norm": 0.9596874117851257,
      "learning_rate": 0.0004827852516952782,
      "loss": 0.831,
      "step": 195550
    },
    {
      "epoch": 2.0706962169372383,
      "grad_norm": 0.8959265947341919,
      "learning_rate": 0.000482768403274595,
      "loss": 0.8176,
      "step": 195600
    },
    {
      "epoch": 2.0712255387172416,
      "grad_norm": 0.8829478025436401,
      "learning_rate": 0.00048275154690728385,
      "loss": 0.8143,
      "step": 195650
    },
    {
      "epoch": 2.071754860497245,
      "grad_norm": 0.8929151892662048,
      "learning_rate": 0.0004827346825939202,
      "loss": 0.821,
      "step": 195700
    },
    {
      "epoch": 2.072284182277248,
      "grad_norm": 0.8841869235038757,
      "learning_rate": 0.00048271781033507993,
      "loss": 0.8181,
      "step": 195750
    },
    {
      "epoch": 2.0728135040572515,
      "grad_norm": 0.9370173811912537,
      "learning_rate": 0.00048270093013133894,
      "loss": 0.8419,
      "step": 195800
    },
    {
      "epoch": 2.073342825837255,
      "grad_norm": 1.0061570405960083,
      "learning_rate": 0.00048268404198327356,
      "loss": 0.8345,
      "step": 195850
    },
    {
      "epoch": 2.073872147617258,
      "grad_norm": 0.9448676705360413,
      "learning_rate": 0.0004826671458914602,
      "loss": 0.8253,
      "step": 195900
    },
    {
      "epoch": 2.0744014693972614,
      "grad_norm": 0.8791658878326416,
      "learning_rate": 0.0004826502418564759,
      "loss": 0.8221,
      "step": 195950
    },
    {
      "epoch": 2.0749307911772648,
      "grad_norm": 0.9074287414550781,
      "learning_rate": 0.0004826333298788977,
      "loss": 0.8176,
      "step": 196000
    },
    {
      "epoch": 2.0749307911772648,
      "eval_loss": 0.6443620920181274,
      "eval_runtime": 46.7916,
      "eval_samples_per_second": 3588.896,
      "eval_steps_per_second": 448.628,
      "step": 196000
    },
    {
      "epoch": 2.075460112957268,
      "grad_norm": 0.9206311106681824,
      "learning_rate": 0.0004826164099593029,
      "loss": 0.8175,
      "step": 196050
    },
    {
      "epoch": 2.075989434737271,
      "grad_norm": 0.875652551651001,
      "learning_rate": 0.0004825994820982691,
      "loss": 0.8394,
      "step": 196100
    },
    {
      "epoch": 2.0765187565172742,
      "grad_norm": 0.9678249359130859,
      "learning_rate": 0.00048258254629637436,
      "loss": 0.8114,
      "step": 196150
    },
    {
      "epoch": 2.0770480782972776,
      "grad_norm": 0.9190174341201782,
      "learning_rate": 0.0004825656025541968,
      "loss": 0.8262,
      "step": 196200
    },
    {
      "epoch": 2.077577400077281,
      "grad_norm": 0.8487446904182434,
      "learning_rate": 0.00048254865087231483,
      "loss": 0.8333,
      "step": 196250
    },
    {
      "epoch": 2.078106721857284,
      "grad_norm": 0.8805947303771973,
      "learning_rate": 0.0004825316912513072,
      "loss": 0.8158,
      "step": 196300
    },
    {
      "epoch": 2.0786360436372875,
      "grad_norm": 0.8625051379203796,
      "learning_rate": 0.0004825147236917529,
      "loss": 0.8256,
      "step": 196350
    },
    {
      "epoch": 2.079165365417291,
      "grad_norm": 0.925141453742981,
      "learning_rate": 0.0004824977481942312,
      "loss": 0.8203,
      "step": 196400
    },
    {
      "epoch": 2.079694687197294,
      "grad_norm": 0.9080007076263428,
      "learning_rate": 0.0004824811045058025,
      "loss": 0.8093,
      "step": 196450
    },
    {
      "epoch": 2.0802240089772974,
      "grad_norm": 0.8838536143302917,
      "learning_rate": 0.0004824641132928155,
      "loss": 0.8167,
      "step": 196500
    },
    {
      "epoch": 2.0802240089772974,
      "eval_loss": 0.6445196866989136,
      "eval_runtime": 46.7145,
      "eval_samples_per_second": 3594.817,
      "eval_steps_per_second": 449.368,
      "step": 196500
    },
    {
      "epoch": 2.0807533307573007,
      "grad_norm": 0.8675485253334045,
      "learning_rate": 0.0004824471141435888,
      "loss": 0.8292,
      "step": 196550
    },
    {
      "epoch": 2.081282652537304,
      "grad_norm": 0.9656076431274414,
      "learning_rate": 0.00048243010705870283,
      "loss": 0.8348,
      "step": 196600
    },
    {
      "epoch": 2.0818119743173074,
      "grad_norm": 0.8944408893585205,
      "learning_rate": 0.0004824130920387383,
      "loss": 0.8169,
      "step": 196650
    },
    {
      "epoch": 2.0823412960973107,
      "grad_norm": 0.9009115099906921,
      "learning_rate": 0.00048239606908427607,
      "loss": 0.8264,
      "step": 196700
    },
    {
      "epoch": 2.082870617877314,
      "grad_norm": 0.915818452835083,
      "learning_rate": 0.00048237903819589725,
      "loss": 0.8175,
      "step": 196750
    },
    {
      "epoch": 2.0833999396573173,
      "grad_norm": 0.8983848094940186,
      "learning_rate": 0.0004823619993741833,
      "loss": 0.8182,
      "step": 196800
    },
    {
      "epoch": 2.08392926143732,
      "grad_norm": 0.8489192724227905,
      "learning_rate": 0.0004823449526197159,
      "loss": 0.8233,
      "step": 196850
    },
    {
      "epoch": 2.0844585832173235,
      "grad_norm": 0.9838069677352905,
      "learning_rate": 0.000482327897933077,
      "loss": 0.8371,
      "step": 196900
    },
    {
      "epoch": 2.084987904997327,
      "grad_norm": 0.886372983455658,
      "learning_rate": 0.0004823108353148489,
      "loss": 0.8339,
      "step": 196950
    },
    {
      "epoch": 2.08551722677733,
      "grad_norm": 0.9261566996574402,
      "learning_rate": 0.000482293764765614,
      "loss": 0.8225,
      "step": 197000
    },
    {
      "epoch": 2.08551722677733,
      "eval_loss": 0.643764317035675,
      "eval_runtime": 46.7601,
      "eval_samples_per_second": 3591.308,
      "eval_steps_per_second": 448.93,
      "step": 197000
    },
    {
      "epoch": 2.0860465485573334,
      "grad_norm": 0.9572606086730957,
      "learning_rate": 0.0004822766862859553,
      "loss": 0.8336,
      "step": 197050
    },
    {
      "epoch": 2.0865758703373367,
      "grad_norm": 0.918693482875824,
      "learning_rate": 0.0004822595998764556,
      "loss": 0.8153,
      "step": 197100
    },
    {
      "epoch": 2.08710519211734,
      "grad_norm": 0.9406833052635193,
      "learning_rate": 0.0004822425055376984,
      "loss": 0.8192,
      "step": 197150
    },
    {
      "epoch": 2.0876345138973433,
      "grad_norm": 0.8911606073379517,
      "learning_rate": 0.00048222540327026725,
      "loss": 0.827,
      "step": 197200
    },
    {
      "epoch": 2.0881638356773466,
      "grad_norm": 0.8277309536933899,
      "learning_rate": 0.00048220829307474603,
      "loss": 0.8251,
      "step": 197250
    },
    {
      "epoch": 2.08869315745735,
      "grad_norm": 0.8317062258720398,
      "learning_rate": 0.0004821911749517187,
      "loss": 0.8239,
      "step": 197300
    },
    {
      "epoch": 2.0892224792373533,
      "grad_norm": 0.8487277030944824,
      "learning_rate": 0.00048217404890177,
      "loss": 0.8317,
      "step": 197350
    },
    {
      "epoch": 2.0897518010173566,
      "grad_norm": 0.9024025201797485,
      "learning_rate": 0.00048215691492548425,
      "loss": 0.8245,
      "step": 197400
    },
    {
      "epoch": 2.09028112279736,
      "grad_norm": 0.8695269227027893,
      "learning_rate": 0.00048213977302344666,
      "loss": 0.825,
      "step": 197450
    },
    {
      "epoch": 2.090810444577363,
      "grad_norm": 0.8707292675971985,
      "learning_rate": 0.0004821226231962423,
      "loss": 0.8143,
      "step": 197500
    },
    {
      "epoch": 2.090810444577363,
      "eval_loss": 0.6393786072731018,
      "eval_runtime": 46.7268,
      "eval_samples_per_second": 3593.867,
      "eval_steps_per_second": 449.249,
      "step": 197500
    },
    {
      "epoch": 2.0913397663573665,
      "grad_norm": 0.9097269177436829,
      "learning_rate": 0.0004821054654444567,
      "loss": 0.8163,
      "step": 197550
    },
    {
      "epoch": 2.0918690881373694,
      "grad_norm": 0.9465508460998535,
      "learning_rate": 0.0004820882997686757,
      "loss": 0.8307,
      "step": 197600
    },
    {
      "epoch": 2.0923984099173727,
      "grad_norm": 0.8609848618507385,
      "learning_rate": 0.0004820711261694852,
      "loss": 0.8241,
      "step": 197650
    },
    {
      "epoch": 2.092927731697376,
      "grad_norm": 0.9160270690917969,
      "learning_rate": 0.0004820539446474716,
      "loss": 0.824,
      "step": 197700
    },
    {
      "epoch": 2.0934570534773793,
      "grad_norm": 0.828910768032074,
      "learning_rate": 0.00048203675520322144,
      "loss": 0.8198,
      "step": 197750
    },
    {
      "epoch": 2.0939863752573826,
      "grad_norm": 0.8473241329193115,
      "learning_rate": 0.00048201955783732156,
      "loss": 0.8294,
      "step": 197800
    },
    {
      "epoch": 2.094515697037386,
      "grad_norm": 0.964508593082428,
      "learning_rate": 0.000482002352550359,
      "loss": 0.8082,
      "step": 197850
    },
    {
      "epoch": 2.0950450188173892,
      "grad_norm": 0.9385359883308411,
      "learning_rate": 0.00048198513934292125,
      "loss": 0.8152,
      "step": 197900
    },
    {
      "epoch": 2.0955743405973926,
      "grad_norm": 0.9012103080749512,
      "learning_rate": 0.0004819679182155959,
      "loss": 0.8284,
      "step": 197950
    },
    {
      "epoch": 2.096103662377396,
      "grad_norm": 0.8294023275375366,
      "learning_rate": 0.000481950689168971,
      "loss": 0.827,
      "step": 198000
    },
    {
      "epoch": 2.096103662377396,
      "eval_loss": 0.6409361362457275,
      "eval_runtime": 46.7747,
      "eval_samples_per_second": 3590.186,
      "eval_steps_per_second": 448.789,
      "step": 198000
    },
    {
      "epoch": 2.096632984157399,
      "grad_norm": 0.804642915725708,
      "learning_rate": 0.0004819334522036345,
      "loss": 0.8193,
      "step": 198050
    },
    {
      "epoch": 2.0971623059374025,
      "grad_norm": 0.9364619255065918,
      "learning_rate": 0.00048191620732017506,
      "loss": 0.822,
      "step": 198100
    },
    {
      "epoch": 2.097691627717406,
      "grad_norm": 0.8133552670478821,
      "learning_rate": 0.0004818989545191814,
      "loss": 0.8135,
      "step": 198150
    },
    {
      "epoch": 2.098220949497409,
      "grad_norm": 0.9294988512992859,
      "learning_rate": 0.0004818816938012424,
      "loss": 0.8189,
      "step": 198200
    },
    {
      "epoch": 2.0987502712774124,
      "grad_norm": 0.8298755288124084,
      "learning_rate": 0.00048186442516694747,
      "loss": 0.8099,
      "step": 198250
    },
    {
      "epoch": 2.0992795930574157,
      "grad_norm": 0.9812980890274048,
      "learning_rate": 0.00048184714861688603,
      "loss": 0.8136,
      "step": 198300
    },
    {
      "epoch": 2.0998089148374186,
      "grad_norm": 0.8798835873603821,
      "learning_rate": 0.00048182986415164805,
      "loss": 0.8401,
      "step": 198350
    },
    {
      "epoch": 2.100338236617422,
      "grad_norm": 0.9759865999221802,
      "learning_rate": 0.0004818125717718235,
      "loss": 0.8223,
      "step": 198400
    },
    {
      "epoch": 2.1008675583974252,
      "grad_norm": 0.8462492227554321,
      "learning_rate": 0.0004817952714780027,
      "loss": 0.8329,
      "step": 198450
    },
    {
      "epoch": 2.1013968801774285,
      "grad_norm": 0.8764936923980713,
      "learning_rate": 0.0004817783095124685,
      "loss": 0.8313,
      "step": 198500
    },
    {
      "epoch": 2.1013968801774285,
      "eval_loss": 0.640654981136322,
      "eval_runtime": 46.7776,
      "eval_samples_per_second": 3589.969,
      "eval_steps_per_second": 448.762,
      "step": 198500
    },
    {
      "epoch": 2.101926201957432,
      "grad_norm": 0.8951382637023926,
      "learning_rate": 0.00048176099355067806,
      "loss": 0.8176,
      "step": 198550
    },
    {
      "epoch": 2.102455523737435,
      "grad_norm": 0.8795984983444214,
      "learning_rate": 0.00048174366967665216,
      "loss": 0.8301,
      "step": 198600
    },
    {
      "epoch": 2.1029848455174385,
      "grad_norm": 0.8659758567810059,
      "learning_rate": 0.00048172633789098253,
      "loss": 0.8162,
      "step": 198650
    },
    {
      "epoch": 2.103514167297442,
      "grad_norm": 0.9389098286628723,
      "learning_rate": 0.0004817089981942606,
      "loss": 0.8177,
      "step": 198700
    },
    {
      "epoch": 2.104043489077445,
      "grad_norm": 0.9050627946853638,
      "learning_rate": 0.00048169165058707853,
      "loss": 0.8132,
      "step": 198750
    },
    {
      "epoch": 2.1045728108574484,
      "grad_norm": 0.8471753001213074,
      "learning_rate": 0.0004816742950700285,
      "loss": 0.8254,
      "step": 198800
    },
    {
      "epoch": 2.1051021326374517,
      "grad_norm": 0.918285608291626,
      "learning_rate": 0.0004816569316437029,
      "loss": 0.8204,
      "step": 198850
    },
    {
      "epoch": 2.105631454417455,
      "grad_norm": 0.9858067035675049,
      "learning_rate": 0.00048163956030869464,
      "loss": 0.8159,
      "step": 198900
    },
    {
      "epoch": 2.1061607761974583,
      "grad_norm": 0.9312682151794434,
      "learning_rate": 0.0004816221810655967,
      "loss": 0.8241,
      "step": 198950
    },
    {
      "epoch": 2.1066900979774617,
      "grad_norm": 0.9034222960472107,
      "learning_rate": 0.00048160479391500254,
      "loss": 0.8182,
      "step": 199000
    },
    {
      "epoch": 2.1066900979774617,
      "eval_loss": 0.6418388485908508,
      "eval_runtime": 46.6583,
      "eval_samples_per_second": 3599.142,
      "eval_steps_per_second": 449.909,
      "step": 199000
    },
    {
      "epoch": 2.107219419757465,
      "grad_norm": 0.9644543528556824,
      "learning_rate": 0.0004815873988575057,
      "loss": 0.8324,
      "step": 199050
    },
    {
      "epoch": 2.107748741537468,
      "grad_norm": 0.8008366227149963,
      "learning_rate": 0.00048156999589369986,
      "loss": 0.8161,
      "step": 199100
    },
    {
      "epoch": 2.108278063317471,
      "grad_norm": 0.9666559100151062,
      "learning_rate": 0.00048155258502417933,
      "loss": 0.8229,
      "step": 199150
    },
    {
      "epoch": 2.1088073850974745,
      "grad_norm": 0.8187839984893799,
      "learning_rate": 0.0004815351662495385,
      "loss": 0.8145,
      "step": 199200
    },
    {
      "epoch": 2.1093367068774778,
      "grad_norm": 0.9033799767494202,
      "learning_rate": 0.000481517739570372,
      "loss": 0.8166,
      "step": 199250
    },
    {
      "epoch": 2.109866028657481,
      "grad_norm": 0.9045411348342896,
      "learning_rate": 0.0004815003049872747,
      "loss": 0.8078,
      "step": 199300
    },
    {
      "epoch": 2.1103953504374844,
      "grad_norm": 0.9121889472007751,
      "learning_rate": 0.000481482862500842,
      "loss": 0.8297,
      "step": 199350
    },
    {
      "epoch": 2.1109246722174877,
      "grad_norm": 0.900233805179596,
      "learning_rate": 0.0004814654121116692,
      "loss": 0.8157,
      "step": 199400
    },
    {
      "epoch": 2.111453993997491,
      "grad_norm": 1.0091750621795654,
      "learning_rate": 0.0004814479538203521,
      "loss": 0.8038,
      "step": 199450
    },
    {
      "epoch": 2.1119833157774943,
      "grad_norm": 0.81992506980896,
      "learning_rate": 0.0004814304876274868,
      "loss": 0.8082,
      "step": 199500
    },
    {
      "epoch": 2.1119833157774943,
      "eval_loss": 0.6436285972595215,
      "eval_runtime": 46.795,
      "eval_samples_per_second": 3588.63,
      "eval_steps_per_second": 448.595,
      "step": 199500
    },
    {
      "epoch": 2.1125126375574976,
      "grad_norm": 0.9475784301757812,
      "learning_rate": 0.0004814130135336695,
      "loss": 0.8254,
      "step": 199550
    },
    {
      "epoch": 2.113041959337501,
      "grad_norm": 0.9874224662780762,
      "learning_rate": 0.0004813955315394968,
      "loss": 0.8024,
      "step": 199600
    },
    {
      "epoch": 2.1135712811175043,
      "grad_norm": 0.8915802836418152,
      "learning_rate": 0.00048137804164556555,
      "loss": 0.8205,
      "step": 199650
    },
    {
      "epoch": 2.1141006028975076,
      "grad_norm": 0.8671532273292542,
      "learning_rate": 0.0004813605438524727,
      "loss": 0.8063,
      "step": 199700
    },
    {
      "epoch": 2.114629924677511,
      "grad_norm": 0.8456262946128845,
      "learning_rate": 0.00048134303816081583,
      "loss": 0.832,
      "step": 199750
    },
    {
      "epoch": 2.115159246457514,
      "grad_norm": 0.919657289981842,
      "learning_rate": 0.0004813255245711924,
      "loss": 0.8237,
      "step": 199800
    },
    {
      "epoch": 2.115688568237517,
      "grad_norm": 0.8402767777442932,
      "learning_rate": 0.0004813080030842005,
      "loss": 0.8144,
      "step": 199850
    },
    {
      "epoch": 2.1162178900175204,
      "grad_norm": 0.8412505984306335,
      "learning_rate": 0.0004812904737004381,
      "loss": 0.8261,
      "step": 199900
    },
    {
      "epoch": 2.1167472117975237,
      "grad_norm": 0.8949867486953735,
      "learning_rate": 0.00048127293642050384,
      "loss": 0.8189,
      "step": 199950
    },
    {
      "epoch": 2.117276533577527,
      "grad_norm": 0.9122088551521301,
      "learning_rate": 0.0004812553912449963,
      "loss": 0.823,
      "step": 200000
    },
    {
      "epoch": 2.117276533577527,
      "eval_loss": 0.6424902677536011,
      "eval_runtime": 46.7362,
      "eval_samples_per_second": 3593.142,
      "eval_steps_per_second": 449.159,
      "step": 200000
    },
    {
      "epoch": 2.1178058553575303,
      "grad_norm": 0.8401444554328918,
      "learning_rate": 0.0004812378381745145,
      "loss": 0.8077,
      "step": 200050
    },
    {
      "epoch": 2.1183351771375336,
      "grad_norm": 0.8081273436546326,
      "learning_rate": 0.00048122027720965777,
      "loss": 0.8218,
      "step": 200100
    },
    {
      "epoch": 2.118864498917537,
      "grad_norm": 0.8708726167678833,
      "learning_rate": 0.00048120270835102553,
      "loss": 0.831,
      "step": 200150
    },
    {
      "epoch": 2.1193938206975402,
      "grad_norm": 0.8376401662826538,
      "learning_rate": 0.0004811851315992176,
      "loss": 0.8313,
      "step": 200200
    },
    {
      "epoch": 2.1199231424775435,
      "grad_norm": 0.9126967191696167,
      "learning_rate": 0.00048116754695483414,
      "loss": 0.8277,
      "step": 200250
    },
    {
      "epoch": 2.120452464257547,
      "grad_norm": 0.9623178839683533,
      "learning_rate": 0.0004811499544184753,
      "loss": 0.8247,
      "step": 200300
    },
    {
      "epoch": 2.12098178603755,
      "grad_norm": 0.9184342622756958,
      "learning_rate": 0.00048113235399074183,
      "loss": 0.8138,
      "step": 200350
    },
    {
      "epoch": 2.1215111078175535,
      "grad_norm": 0.9583885669708252,
      "learning_rate": 0.00048111474567223456,
      "loss": 0.8192,
      "step": 200400
    },
    {
      "epoch": 2.122040429597557,
      "grad_norm": 0.8969520330429077,
      "learning_rate": 0.00048109712946355467,
      "loss": 0.8121,
      "step": 200450
    },
    {
      "epoch": 2.12256975137756,
      "grad_norm": 0.9242019653320312,
      "learning_rate": 0.00048107950536530346,
      "loss": 0.8308,
      "step": 200500
    },
    {
      "epoch": 2.12256975137756,
      "eval_loss": 0.6406680941581726,
      "eval_runtime": 46.8021,
      "eval_samples_per_second": 3588.088,
      "eval_steps_per_second": 448.527,
      "step": 200500
    },
    {
      "epoch": 2.1230990731575634,
      "grad_norm": 0.9440340995788574,
      "learning_rate": 0.00048106222609513516,
      "loss": 0.8225,
      "step": 200550
    },
    {
      "epoch": 2.1236283949375663,
      "grad_norm": 0.9561806321144104,
      "learning_rate": 0.0004810445863773083,
      "loss": 0.8152,
      "step": 200600
    },
    {
      "epoch": 2.1241577167175696,
      "grad_norm": 0.8464859127998352,
      "learning_rate": 0.0004810269387717039,
      "loss": 0.8233,
      "step": 200650
    },
    {
      "epoch": 2.124687038497573,
      "grad_norm": 0.9012778997421265,
      "learning_rate": 0.0004810092832789246,
      "loss": 0.8052,
      "step": 200700
    },
    {
      "epoch": 2.125216360277576,
      "grad_norm": 0.9290256500244141,
      "learning_rate": 0.0004809916198995731,
      "loss": 0.8221,
      "step": 200750
    },
    {
      "epoch": 2.1257456820575795,
      "grad_norm": 0.9655693173408508,
      "learning_rate": 0.00048097394863425236,
      "loss": 0.8109,
      "step": 200800
    },
    {
      "epoch": 2.126275003837583,
      "grad_norm": 0.879118025302887,
      "learning_rate": 0.0004809562694835657,
      "loss": 0.8209,
      "step": 200850
    },
    {
      "epoch": 2.126804325617586,
      "grad_norm": 0.9877293705940247,
      "learning_rate": 0.00048093858244811685,
      "loss": 0.8335,
      "step": 200900
    },
    {
      "epoch": 2.1273336473975895,
      "grad_norm": 0.9353458881378174,
      "learning_rate": 0.00048092088752850937,
      "loss": 0.8137,
      "step": 200950
    },
    {
      "epoch": 2.1278629691775928,
      "grad_norm": 0.9453133344650269,
      "learning_rate": 0.0004809031847253475,
      "loss": 0.8164,
      "step": 201000
    },
    {
      "epoch": 2.1278629691775928,
      "eval_loss": 0.6346007585525513,
      "eval_runtime": 46.7858,
      "eval_samples_per_second": 3589.334,
      "eval_steps_per_second": 448.683,
      "step": 201000
    },
    {
      "epoch": 2.128392290957596,
      "grad_norm": 0.8704291582107544,
      "learning_rate": 0.00048088547403923556,
      "loss": 0.8291,
      "step": 201050
    },
    {
      "epoch": 2.1289216127375994,
      "grad_norm": 0.9458346962928772,
      "learning_rate": 0.0004808677554707782,
      "loss": 0.8256,
      "step": 201100
    },
    {
      "epoch": 2.1294509345176027,
      "grad_norm": 0.8832550644874573,
      "learning_rate": 0.0004808500290205804,
      "loss": 0.8191,
      "step": 201150
    },
    {
      "epoch": 2.129980256297606,
      "grad_norm": 0.9193081855773926,
      "learning_rate": 0.0004808322946892473,
      "loss": 0.8112,
      "step": 201200
    },
    {
      "epoch": 2.1305095780776093,
      "grad_norm": 0.9044916033744812,
      "learning_rate": 0.0004808145524773842,
      "loss": 0.8117,
      "step": 201250
    },
    {
      "epoch": 2.1310388998576126,
      "grad_norm": 0.8622363209724426,
      "learning_rate": 0.00048079680238559695,
      "loss": 0.8257,
      "step": 201300
    },
    {
      "epoch": 2.1315682216376155,
      "grad_norm": 0.9460174441337585,
      "learning_rate": 0.0004807790444144916,
      "loss": 0.8089,
      "step": 201350
    },
    {
      "epoch": 2.132097543417619,
      "grad_norm": 0.9222117066383362,
      "learning_rate": 0.0004807612785646742,
      "loss": 0.8081,
      "step": 201400
    },
    {
      "epoch": 2.132626865197622,
      "grad_norm": 0.9650996923446655,
      "learning_rate": 0.00048074350483675145,
      "loss": 0.8187,
      "step": 201450
    },
    {
      "epoch": 2.1331561869776254,
      "grad_norm": 0.9338889718055725,
      "learning_rate": 0.00048072572323133007,
      "loss": 0.8224,
      "step": 201500
    },
    {
      "epoch": 2.1331561869776254,
      "eval_loss": 0.6402882933616638,
      "eval_runtime": 46.7264,
      "eval_samples_per_second": 3593.898,
      "eval_steps_per_second": 449.253,
      "step": 201500
    },
    {
      "epoch": 2.1336855087576287,
      "grad_norm": 1.02823805809021,
      "learning_rate": 0.0004807079337490171,
      "loss": 0.8234,
      "step": 201550
    },
    {
      "epoch": 2.134214830537632,
      "grad_norm": 0.8994200825691223,
      "learning_rate": 0.0004806901363904199,
      "loss": 0.8214,
      "step": 201600
    },
    {
      "epoch": 2.1347441523176354,
      "grad_norm": 0.9306831955909729,
      "learning_rate": 0.00048067233115614593,
      "loss": 0.8205,
      "step": 201650
    },
    {
      "epoch": 2.1352734740976387,
      "grad_norm": 0.859609842300415,
      "learning_rate": 0.0004806545180468033,
      "loss": 0.8207,
      "step": 201700
    },
    {
      "epoch": 2.135802795877642,
      "grad_norm": 0.9768680930137634,
      "learning_rate": 0.00048063669706299993,
      "loss": 0.8134,
      "step": 201750
    },
    {
      "epoch": 2.1363321176576453,
      "grad_norm": 1.0145719051361084,
      "learning_rate": 0.0004806188682053444,
      "loss": 0.824,
      "step": 201800
    },
    {
      "epoch": 2.1368614394376486,
      "grad_norm": 0.8724139928817749,
      "learning_rate": 0.0004806010314744452,
      "loss": 0.8234,
      "step": 201850
    },
    {
      "epoch": 2.137390761217652,
      "grad_norm": 1.019713282585144,
      "learning_rate": 0.00048058318687091146,
      "loss": 0.829,
      "step": 201900
    },
    {
      "epoch": 2.1379200829976552,
      "grad_norm": 0.8484900593757629,
      "learning_rate": 0.0004805653343953522,
      "loss": 0.8199,
      "step": 201950
    },
    {
      "epoch": 2.1384494047776585,
      "grad_norm": 0.8420283794403076,
      "learning_rate": 0.000480547474048377,
      "loss": 0.8058,
      "step": 202000
    },
    {
      "epoch": 2.1384494047776585,
      "eval_loss": 0.6355483531951904,
      "eval_runtime": 46.7893,
      "eval_samples_per_second": 3589.072,
      "eval_steps_per_second": 448.65,
      "step": 202000
    },
    {
      "epoch": 2.138978726557662,
      "grad_norm": 0.8299446702003479,
      "learning_rate": 0.0004805296058305956,
      "loss": 0.8028,
      "step": 202050
    },
    {
      "epoch": 2.1395080483376647,
      "grad_norm": 0.9270418882369995,
      "learning_rate": 0.000480511729742618,
      "loss": 0.8014,
      "step": 202100
    },
    {
      "epoch": 2.140037370117668,
      "grad_norm": 0.8870910406112671,
      "learning_rate": 0.00048049384578505443,
      "loss": 0.8297,
      "step": 202150
    },
    {
      "epoch": 2.1405666918976713,
      "grad_norm": 0.8389093279838562,
      "learning_rate": 0.00048047595395851554,
      "loss": 0.8223,
      "step": 202200
    },
    {
      "epoch": 2.1410960136776747,
      "grad_norm": 0.8809993863105774,
      "learning_rate": 0.0004804580542636121,
      "loss": 0.8013,
      "step": 202250
    },
    {
      "epoch": 2.141625335457678,
      "grad_norm": 0.8554298281669617,
      "learning_rate": 0.00048044014670095526,
      "loss": 0.8122,
      "step": 202300
    },
    {
      "epoch": 2.1421546572376813,
      "grad_norm": 0.8364497423171997,
      "learning_rate": 0.00048042223127115624,
      "loss": 0.7982,
      "step": 202350
    },
    {
      "epoch": 2.1426839790176846,
      "grad_norm": 0.8194851875305176,
      "learning_rate": 0.0004804043079748268,
      "loss": 0.8126,
      "step": 202400
    },
    {
      "epoch": 2.143213300797688,
      "grad_norm": 0.886577308177948,
      "learning_rate": 0.00048038637681257877,
      "loss": 0.8173,
      "step": 202450
    },
    {
      "epoch": 2.143742622577691,
      "grad_norm": 0.7743595838546753,
      "learning_rate": 0.00048036843778502433,
      "loss": 0.8073,
      "step": 202500
    },
    {
      "epoch": 2.143742622577691,
      "eval_loss": 0.633286714553833,
      "eval_runtime": 46.7617,
      "eval_samples_per_second": 3591.19,
      "eval_steps_per_second": 448.915,
      "step": 202500
    },
    {
      "epoch": 2.1442719443576945,
      "grad_norm": 0.896270751953125,
      "learning_rate": 0.00048035049089277586,
      "loss": 0.8238,
      "step": 202550
    },
    {
      "epoch": 2.144801266137698,
      "grad_norm": 0.9438390731811523,
      "learning_rate": 0.0004803328953086368,
      "loss": 0.8172,
      "step": 202600
    },
    {
      "epoch": 2.145330587917701,
      "grad_norm": 0.9004952311515808,
      "learning_rate": 0.00048031493284610214,
      "loss": 0.8046,
      "step": 202650
    },
    {
      "epoch": 2.1458599096977045,
      "grad_norm": 0.8318813443183899,
      "learning_rate": 0.00048029696252070014,
      "loss": 0.8096,
      "step": 202700
    },
    {
      "epoch": 2.1463892314777078,
      "grad_norm": 0.8774933815002441,
      "learning_rate": 0.00048027898433304427,
      "loss": 0.8307,
      "step": 202750
    },
    {
      "epoch": 2.146918553257711,
      "grad_norm": 0.94856858253479,
      "learning_rate": 0.00048026099828374835,
      "loss": 0.8173,
      "step": 202800
    },
    {
      "epoch": 2.147447875037714,
      "grad_norm": 0.9264309406280518,
      "learning_rate": 0.0004802430043734264,
      "loss": 0.8257,
      "step": 202850
    },
    {
      "epoch": 2.1479771968177173,
      "grad_norm": 0.9741788506507874,
      "learning_rate": 0.0004802250026026928,
      "loss": 0.8285,
      "step": 202900
    },
    {
      "epoch": 2.1485065185977206,
      "grad_norm": 1.0085793733596802,
      "learning_rate": 0.0004802069929721619,
      "loss": 0.8099,
      "step": 202950
    },
    {
      "epoch": 2.149035840377724,
      "grad_norm": 0.9707781672477722,
      "learning_rate": 0.00048018897548244877,
      "loss": 0.8214,
      "step": 203000
    },
    {
      "epoch": 2.149035840377724,
      "eval_loss": 0.6339855194091797,
      "eval_runtime": 46.7863,
      "eval_samples_per_second": 3589.297,
      "eval_steps_per_second": 448.678,
      "step": 203000
    },
    {
      "epoch": 2.149565162157727,
      "grad_norm": 0.8158387541770935,
      "learning_rate": 0.0004801709501341684,
      "loss": 0.8073,
      "step": 203050
    },
    {
      "epoch": 2.1500944839377305,
      "grad_norm": 0.9261143803596497,
      "learning_rate": 0.0004801529169279362,
      "loss": 0.8126,
      "step": 203100
    },
    {
      "epoch": 2.150623805717734,
      "grad_norm": 0.7954632639884949,
      "learning_rate": 0.00048013487586436786,
      "loss": 0.8101,
      "step": 203150
    },
    {
      "epoch": 2.151153127497737,
      "grad_norm": 0.8937203884124756,
      "learning_rate": 0.0004801168269440793,
      "loss": 0.8281,
      "step": 203200
    },
    {
      "epoch": 2.1516824492777404,
      "grad_norm": 0.9718729257583618,
      "learning_rate": 0.00048009877016768655,
      "loss": 0.8062,
      "step": 203250
    },
    {
      "epoch": 2.1522117710577437,
      "grad_norm": 0.898929238319397,
      "learning_rate": 0.0004800807055358062,
      "loss": 0.8137,
      "step": 203300
    },
    {
      "epoch": 2.152741092837747,
      "grad_norm": 0.866010844707489,
      "learning_rate": 0.000480062633049055,
      "loss": 0.8296,
      "step": 203350
    },
    {
      "epoch": 2.1532704146177504,
      "grad_norm": 0.8572380542755127,
      "learning_rate": 0.0004800445527080498,
      "loss": 0.8132,
      "step": 203400
    },
    {
      "epoch": 2.1537997363977537,
      "grad_norm": 0.8343744277954102,
      "learning_rate": 0.00048002646451340803,
      "loss": 0.8003,
      "step": 203450
    },
    {
      "epoch": 2.154329058177757,
      "grad_norm": 0.9536138772964478,
      "learning_rate": 0.00048000836846574704,
      "loss": 0.8147,
      "step": 203500
    },
    {
      "epoch": 2.154329058177757,
      "eval_loss": 0.6313738822937012,
      "eval_runtime": 46.7516,
      "eval_samples_per_second": 3591.965,
      "eval_steps_per_second": 449.012,
      "step": 203500
    },
    {
      "epoch": 2.1548583799577603,
      "grad_norm": 0.7902745604515076,
      "learning_rate": 0.00047999026456568475,
      "loss": 0.8089,
      "step": 203550
    },
    {
      "epoch": 2.155387701737763,
      "grad_norm": 0.9784932136535645,
      "learning_rate": 0.0004799721528138392,
      "loss": 0.8179,
      "step": 203600
    },
    {
      "epoch": 2.1559170235177665,
      "grad_norm": 0.8137436509132385,
      "learning_rate": 0.00047995403321082867,
      "loss": 0.8076,
      "step": 203650
    },
    {
      "epoch": 2.15644634529777,
      "grad_norm": 0.9641439914703369,
      "learning_rate": 0.0004799359057572718,
      "loss": 0.8195,
      "step": 203700
    },
    {
      "epoch": 2.156975667077773,
      "grad_norm": 0.8356702923774719,
      "learning_rate": 0.0004799177704537873,
      "loss": 0.8139,
      "step": 203750
    },
    {
      "epoch": 2.1575049888577764,
      "grad_norm": 0.8362191915512085,
      "learning_rate": 0.00047989962730099456,
      "loss": 0.812,
      "step": 203800
    },
    {
      "epoch": 2.1580343106377797,
      "grad_norm": 1.049329400062561,
      "learning_rate": 0.00047988147629951283,
      "loss": 0.8121,
      "step": 203850
    },
    {
      "epoch": 2.158563632417783,
      "grad_norm": 0.9473854899406433,
      "learning_rate": 0.0004798633174499618,
      "loss": 0.8315,
      "step": 203900
    },
    {
      "epoch": 2.1590929541977864,
      "grad_norm": 0.9247158169746399,
      "learning_rate": 0.00047984515075296145,
      "loss": 0.8213,
      "step": 203950
    },
    {
      "epoch": 2.1596222759777897,
      "grad_norm": 0.8390603065490723,
      "learning_rate": 0.0004798269762091319,
      "loss": 0.805,
      "step": 204000
    },
    {
      "epoch": 2.1596222759777897,
      "eval_loss": 0.631921112537384,
      "eval_runtime": 46.8149,
      "eval_samples_per_second": 3587.103,
      "eval_steps_per_second": 448.404,
      "step": 204000
    },
    {
      "epoch": 2.160151597757793,
      "grad_norm": 0.9035137891769409,
      "learning_rate": 0.0004798087938190937,
      "loss": 0.8271,
      "step": 204050
    },
    {
      "epoch": 2.1606809195377963,
      "grad_norm": 0.9309693574905396,
      "learning_rate": 0.0004797906035834675,
      "loss": 0.8262,
      "step": 204100
    },
    {
      "epoch": 2.1612102413177996,
      "grad_norm": 0.9354948401451111,
      "learning_rate": 0.00047977240550287444,
      "loss": 0.8117,
      "step": 204150
    },
    {
      "epoch": 2.161739563097803,
      "grad_norm": 0.956522524356842,
      "learning_rate": 0.0004797541995779357,
      "loss": 0.8172,
      "step": 204200
    },
    {
      "epoch": 2.162268884877806,
      "grad_norm": 0.8487063050270081,
      "learning_rate": 0.0004797359858092729,
      "loss": 0.8061,
      "step": 204250
    },
    {
      "epoch": 2.1627982066578095,
      "grad_norm": 0.8975250124931335,
      "learning_rate": 0.0004797177641975077,
      "loss": 0.825,
      "step": 204300
    },
    {
      "epoch": 2.1633275284378124,
      "grad_norm": 0.8224611878395081,
      "learning_rate": 0.00047969953474326235,
      "loss": 0.8186,
      "step": 204350
    },
    {
      "epoch": 2.1638568502178157,
      "grad_norm": 0.8409307599067688,
      "learning_rate": 0.00047968129744715906,
      "loss": 0.8057,
      "step": 204400
    },
    {
      "epoch": 2.164386171997819,
      "grad_norm": 0.9529443383216858,
      "learning_rate": 0.00047966305230982056,
      "loss": 0.8241,
      "step": 204450
    },
    {
      "epoch": 2.1649154937778223,
      "grad_norm": 0.9090027213096619,
      "learning_rate": 0.0004796447993318696,
      "loss": 0.807,
      "step": 204500
    },
    {
      "epoch": 2.1649154937778223,
      "eval_loss": 0.6338900327682495,
      "eval_runtime": 46.7603,
      "eval_samples_per_second": 3591.292,
      "eval_steps_per_second": 448.928,
      "step": 204500
    },
    {
      "epoch": 2.1654448155578256,
      "grad_norm": 0.9808184504508972,
      "learning_rate": 0.00047962653851392944,
      "loss": 0.805,
      "step": 204550
    },
    {
      "epoch": 2.165974137337829,
      "grad_norm": 0.9012149572372437,
      "learning_rate": 0.00047960826985662356,
      "loss": 0.8168,
      "step": 204600
    },
    {
      "epoch": 2.1665034591178323,
      "grad_norm": 0.8893542289733887,
      "learning_rate": 0.0004795899933605755,
      "loss": 0.815,
      "step": 204650
    },
    {
      "epoch": 2.1670327808978356,
      "grad_norm": 0.9119790196418762,
      "learning_rate": 0.0004795720747899021,
      "loss": 0.801,
      "step": 204700
    },
    {
      "epoch": 2.167562102677839,
      "grad_norm": 0.9296590685844421,
      "learning_rate": 0.00047955378277498564,
      "loss": 0.8178,
      "step": 204750
    },
    {
      "epoch": 2.168091424457842,
      "grad_norm": 0.8983762264251709,
      "learning_rate": 0.0004795354829231873,
      "loss": 0.8223,
      "step": 204800
    },
    {
      "epoch": 2.1686207462378455,
      "grad_norm": 0.8913716077804565,
      "learning_rate": 0.00047951717523513163,
      "loss": 0.8103,
      "step": 204850
    },
    {
      "epoch": 2.169150068017849,
      "grad_norm": 0.9479175806045532,
      "learning_rate": 0.0004794988597114439,
      "loss": 0.8157,
      "step": 204900
    },
    {
      "epoch": 2.169679389797852,
      "grad_norm": 0.9647665023803711,
      "learning_rate": 0.0004794805363527491,
      "loss": 0.8026,
      "step": 204950
    },
    {
      "epoch": 2.1702087115778554,
      "grad_norm": 0.9369251132011414,
      "learning_rate": 0.0004794622051596731,
      "loss": 0.8138,
      "step": 205000
    },
    {
      "epoch": 2.1702087115778554,
      "eval_loss": 0.6281726360321045,
      "eval_runtime": 46.7559,
      "eval_samples_per_second": 3591.632,
      "eval_steps_per_second": 448.97,
      "step": 205000
    },
    {
      "epoch": 2.1707380333578588,
      "grad_norm": 0.9631725549697876,
      "learning_rate": 0.0004794438661328415,
      "loss": 0.8295,
      "step": 205050
    },
    {
      "epoch": 2.171267355137862,
      "grad_norm": 0.9436911940574646,
      "learning_rate": 0.0004794255192728805,
      "loss": 0.8209,
      "step": 205100
    },
    {
      "epoch": 2.171796676917865,
      "grad_norm": 0.9529138803482056,
      "learning_rate": 0.00047940716458041646,
      "loss": 0.8154,
      "step": 205150
    },
    {
      "epoch": 2.1723259986978682,
      "grad_norm": 0.9411219358444214,
      "learning_rate": 0.0004793888020560758,
      "loss": 0.8087,
      "step": 205200
    },
    {
      "epoch": 2.1728553204778716,
      "grad_norm": 0.9295026659965515,
      "learning_rate": 0.00047937043170048565,
      "loss": 0.825,
      "step": 205250
    },
    {
      "epoch": 2.173384642257875,
      "grad_norm": 0.9338518977165222,
      "learning_rate": 0.00047935205351427315,
      "loss": 0.8152,
      "step": 205300
    },
    {
      "epoch": 2.173913964037878,
      "grad_norm": 0.8066281080245972,
      "learning_rate": 0.0004793336674980656,
      "loss": 0.8063,
      "step": 205350
    },
    {
      "epoch": 2.1744432858178815,
      "grad_norm": 0.8466202616691589,
      "learning_rate": 0.00047931527365249066,
      "loss": 0.8276,
      "step": 205400
    },
    {
      "epoch": 2.174972607597885,
      "grad_norm": 0.9482319951057434,
      "learning_rate": 0.0004792968719781765,
      "loss": 0.8095,
      "step": 205450
    },
    {
      "epoch": 2.175501929377888,
      "grad_norm": 1.0168449878692627,
      "learning_rate": 0.00047927846247575114,
      "loss": 0.8197,
      "step": 205500
    },
    {
      "epoch": 2.175501929377888,
      "eval_loss": 0.6329703330993652,
      "eval_runtime": 46.7795,
      "eval_samples_per_second": 3589.823,
      "eval_steps_per_second": 448.744,
      "step": 205500
    },
    {
      "epoch": 2.1760312511578914,
      "grad_norm": 0.8505871295928955,
      "learning_rate": 0.0004792600451458432,
      "loss": 0.8218,
      "step": 205550
    },
    {
      "epoch": 2.1765605729378947,
      "grad_norm": 0.8069176077842712,
      "learning_rate": 0.00047924161998908133,
      "loss": 0.805,
      "step": 205600
    },
    {
      "epoch": 2.177089894717898,
      "grad_norm": 0.8786027431488037,
      "learning_rate": 0.00047922318700609467,
      "loss": 0.8124,
      "step": 205650
    },
    {
      "epoch": 2.1776192164979014,
      "grad_norm": 0.8752927184104919,
      "learning_rate": 0.00047920474619751253,
      "loss": 0.799,
      "step": 205700
    },
    {
      "epoch": 2.1781485382779047,
      "grad_norm": 0.973940372467041,
      "learning_rate": 0.00047918629756396434,
      "loss": 0.8203,
      "step": 205750
    },
    {
      "epoch": 2.178677860057908,
      "grad_norm": 0.9115375876426697,
      "learning_rate": 0.00047916784110608004,
      "loss": 0.8154,
      "step": 205800
    },
    {
      "epoch": 2.1792071818379113,
      "grad_norm": 0.9276083707809448,
      "learning_rate": 0.0004791493768244897,
      "loss": 0.8021,
      "step": 205850
    },
    {
      "epoch": 2.1797365036179146,
      "grad_norm": 0.8741300106048584,
      "learning_rate": 0.00047913090471982366,
      "loss": 0.8176,
      "step": 205900
    },
    {
      "epoch": 2.1802658253979175,
      "grad_norm": 0.8712339997291565,
      "learning_rate": 0.0004791124247927126,
      "loss": 0.804,
      "step": 205950
    },
    {
      "epoch": 2.180795147177921,
      "grad_norm": 0.7901608347892761,
      "learning_rate": 0.0004790939370437873,
      "loss": 0.8085,
      "step": 206000
    },
    {
      "epoch": 2.180795147177921,
      "eval_loss": 0.6307841539382935,
      "eval_runtime": 46.774,
      "eval_samples_per_second": 3590.245,
      "eval_steps_per_second": 448.797,
      "step": 206000
    },
    {
      "epoch": 2.181324468957924,
      "grad_norm": 0.8111229538917542,
      "learning_rate": 0.00047907544147367904,
      "loss": 0.8,
      "step": 206050
    },
    {
      "epoch": 2.1818537907379274,
      "grad_norm": 0.8904402256011963,
      "learning_rate": 0.0004790569380830192,
      "loss": 0.7966,
      "step": 206100
    },
    {
      "epoch": 2.1823831125179307,
      "grad_norm": 0.8648057579994202,
      "learning_rate": 0.0004790384268724395,
      "loss": 0.8074,
      "step": 206150
    },
    {
      "epoch": 2.182912434297934,
      "grad_norm": 0.8755772709846497,
      "learning_rate": 0.00047901990784257197,
      "loss": 0.8196,
      "step": 206200
    },
    {
      "epoch": 2.1834417560779373,
      "grad_norm": 0.8838644623756409,
      "learning_rate": 0.0004790013809940487,
      "loss": 0.8138,
      "step": 206250
    },
    {
      "epoch": 2.1839710778579406,
      "grad_norm": 0.8736459612846375,
      "learning_rate": 0.0004789828463275023,
      "loss": 0.8054,
      "step": 206300
    },
    {
      "epoch": 2.184500399637944,
      "grad_norm": 0.9252663254737854,
      "learning_rate": 0.00047896430384356556,
      "loss": 0.8193,
      "step": 206350
    },
    {
      "epoch": 2.1850297214179473,
      "grad_norm": 0.9427408576011658,
      "learning_rate": 0.0004789457535428714,
      "loss": 0.8093,
      "step": 206400
    },
    {
      "epoch": 2.1855590431979506,
      "grad_norm": 0.9274985194206238,
      "learning_rate": 0.00047892719542605314,
      "loss": 0.8031,
      "step": 206450
    },
    {
      "epoch": 2.186088364977954,
      "grad_norm": 0.906160831451416,
      "learning_rate": 0.0004789086294937444,
      "loss": 0.813,
      "step": 206500
    },
    {
      "epoch": 2.186088364977954,
      "eval_loss": 0.623878002166748,
      "eval_runtime": 46.7335,
      "eval_samples_per_second": 3593.351,
      "eval_steps_per_second": 449.185,
      "step": 206500
    },
    {
      "epoch": 2.186617686757957,
      "grad_norm": 0.9979835152626038,
      "learning_rate": 0.00047889005574657906,
      "loss": 0.8119,
      "step": 206550
    },
    {
      "epoch": 2.1871470085379605,
      "grad_norm": 0.8915354013442993,
      "learning_rate": 0.00047887147418519113,
      "loss": 0.8105,
      "step": 206600
    },
    {
      "epoch": 2.187676330317964,
      "grad_norm": 0.992518961429596,
      "learning_rate": 0.00047885288481021494,
      "loss": 0.8144,
      "step": 206650
    },
    {
      "epoch": 2.1882056520979667,
      "grad_norm": 0.8991438746452332,
      "learning_rate": 0.00047883428762228534,
      "loss": 0.8036,
      "step": 206700
    },
    {
      "epoch": 2.18873497387797,
      "grad_norm": 0.950311005115509,
      "learning_rate": 0.00047881568262203697,
      "loss": 0.8225,
      "step": 206750
    },
    {
      "epoch": 2.1892642956579733,
      "grad_norm": 0.9176640510559082,
      "learning_rate": 0.0004787974421428941,
      "loss": 0.7979,
      "step": 206800
    },
    {
      "epoch": 2.1897936174379766,
      "grad_norm": 0.921679675579071,
      "learning_rate": 0.00047877882167612895,
      "loss": 0.8074,
      "step": 206850
    },
    {
      "epoch": 2.19032293921798,
      "grad_norm": 0.8711233735084534,
      "learning_rate": 0.00047876019339893874,
      "loss": 0.7954,
      "step": 206900
    },
    {
      "epoch": 2.1908522609979832,
      "grad_norm": 0.9244964122772217,
      "learning_rate": 0.00047874155731195947,
      "loss": 0.8134,
      "step": 206950
    },
    {
      "epoch": 2.1913815827779866,
      "grad_norm": 0.8986746072769165,
      "learning_rate": 0.0004787229134158272,
      "loss": 0.8135,
      "step": 207000
    },
    {
      "epoch": 2.1913815827779866,
      "eval_loss": 0.6262340545654297,
      "eval_runtime": 46.7615,
      "eval_samples_per_second": 3591.203,
      "eval_steps_per_second": 448.916,
      "step": 207000
    },
    {
      "epoch": 2.19191090455799,
      "grad_norm": 0.861509382724762,
      "learning_rate": 0.00047870426171117865,
      "loss": 0.812,
      "step": 207050
    },
    {
      "epoch": 2.192440226337993,
      "grad_norm": 0.9021127820014954,
      "learning_rate": 0.00047868560219865044,
      "loss": 0.8243,
      "step": 207100
    },
    {
      "epoch": 2.1929695481179965,
      "grad_norm": 0.9463604092597961,
      "learning_rate": 0.0004786669348788796,
      "loss": 0.8017,
      "step": 207150
    },
    {
      "epoch": 2.193498869898,
      "grad_norm": 0.9185434579849243,
      "learning_rate": 0.0004786482597525035,
      "loss": 0.8157,
      "step": 207200
    },
    {
      "epoch": 2.194028191678003,
      "grad_norm": 0.9420922994613647,
      "learning_rate": 0.0004786295768201596,
      "loss": 0.8148,
      "step": 207250
    },
    {
      "epoch": 2.1945575134580064,
      "grad_norm": 0.971332848072052,
      "learning_rate": 0.00047861088608248595,
      "loss": 0.808,
      "step": 207300
    },
    {
      "epoch": 2.1950868352380097,
      "grad_norm": 0.8413309454917908,
      "learning_rate": 0.00047859218754012033,
      "loss": 0.8297,
      "step": 207350
    },
    {
      "epoch": 2.195616157018013,
      "grad_norm": 0.8299444317817688,
      "learning_rate": 0.00047857348119370135,
      "loss": 0.8065,
      "step": 207400
    },
    {
      "epoch": 2.196145478798016,
      "grad_norm": 0.9522690773010254,
      "learning_rate": 0.00047855476704386756,
      "loss": 0.8121,
      "step": 207450
    },
    {
      "epoch": 2.1966748005780192,
      "grad_norm": 0.8565384149551392,
      "learning_rate": 0.0004785360450912578,
      "loss": 0.7959,
      "step": 207500
    },
    {
      "epoch": 2.1966748005780192,
      "eval_loss": 0.6271841526031494,
      "eval_runtime": 46.7267,
      "eval_samples_per_second": 3593.874,
      "eval_steps_per_second": 449.25,
      "step": 207500
    },
    {
      "epoch": 2.1972041223580225,
      "grad_norm": 0.8865793347358704,
      "learning_rate": 0.0004785173153365113,
      "loss": 0.8177,
      "step": 207550
    },
    {
      "epoch": 2.197733444138026,
      "grad_norm": 0.835534393787384,
      "learning_rate": 0.0004784985777802675,
      "loss": 0.8078,
      "step": 207600
    },
    {
      "epoch": 2.198262765918029,
      "grad_norm": 0.962323784828186,
      "learning_rate": 0.00047847983242316596,
      "loss": 0.8229,
      "step": 207650
    },
    {
      "epoch": 2.1987920876980325,
      "grad_norm": 0.8716649413108826,
      "learning_rate": 0.0004784610792658468,
      "loss": 0.8194,
      "step": 207700
    },
    {
      "epoch": 2.199321409478036,
      "grad_norm": 0.7827264070510864,
      "learning_rate": 0.00047844231830895015,
      "loss": 0.8149,
      "step": 207750
    },
    {
      "epoch": 2.199850731258039,
      "grad_norm": 0.8578439950942993,
      "learning_rate": 0.0004784235495531165,
      "loss": 0.8137,
      "step": 207800
    },
    {
      "epoch": 2.2003800530380424,
      "grad_norm": 0.8398563265800476,
      "learning_rate": 0.00047840477299898663,
      "loss": 0.8088,
      "step": 207850
    },
    {
      "epoch": 2.2009093748180457,
      "grad_norm": 0.8870508074760437,
      "learning_rate": 0.00047838598864720166,
      "loss": 0.8026,
      "step": 207900
    },
    {
      "epoch": 2.201438696598049,
      "grad_norm": 0.8686975836753845,
      "learning_rate": 0.0004783671964984028,
      "loss": 0.811,
      "step": 207950
    },
    {
      "epoch": 2.2019680183780523,
      "grad_norm": 1.0182045698165894,
      "learning_rate": 0.0004783483965532315,
      "loss": 0.8018,
      "step": 208000
    },
    {
      "epoch": 2.2019680183780523,
      "eval_loss": 0.6224259734153748,
      "eval_runtime": 46.7331,
      "eval_samples_per_second": 3593.384,
      "eval_steps_per_second": 449.189,
      "step": 208000
    },
    {
      "epoch": 2.2024973401580556,
      "grad_norm": 0.8751512765884399,
      "learning_rate": 0.0004783295888123298,
      "loss": 0.8117,
      "step": 208050
    },
    {
      "epoch": 2.203026661938059,
      "grad_norm": 0.8465481996536255,
      "learning_rate": 0.0004783107732763396,
      "loss": 0.8308,
      "step": 208100
    },
    {
      "epoch": 2.2035559837180623,
      "grad_norm": 0.9183144569396973,
      "learning_rate": 0.0004782919499459033,
      "loss": 0.8034,
      "step": 208150
    },
    {
      "epoch": 2.204085305498065,
      "grad_norm": 0.8303865194320679,
      "learning_rate": 0.0004782731188216637,
      "loss": 0.8196,
      "step": 208200
    },
    {
      "epoch": 2.2046146272780685,
      "grad_norm": 0.9726731777191162,
      "learning_rate": 0.0004782542799042634,
      "loss": 0.8095,
      "step": 208250
    },
    {
      "epoch": 2.2051439490580718,
      "grad_norm": 0.891075074672699,
      "learning_rate": 0.0004782354331943457,
      "loss": 0.8141,
      "step": 208300
    },
    {
      "epoch": 2.205673270838075,
      "grad_norm": 0.8616198897361755,
      "learning_rate": 0.00047821657869255406,
      "loss": 0.8136,
      "step": 208350
    },
    {
      "epoch": 2.2062025926180784,
      "grad_norm": 0.829028844833374,
      "learning_rate": 0.0004781977163995321,
      "loss": 0.795,
      "step": 208400
    },
    {
      "epoch": 2.2067319143980817,
      "grad_norm": 0.8873185515403748,
      "learning_rate": 0.00047817884631592386,
      "loss": 0.8096,
      "step": 208450
    },
    {
      "epoch": 2.207261236178085,
      "grad_norm": 0.9008066058158875,
      "learning_rate": 0.0004781599684423734,
      "loss": 0.8087,
      "step": 208500
    },
    {
      "epoch": 2.207261236178085,
      "eval_loss": 0.6277263760566711,
      "eval_runtime": 46.7947,
      "eval_samples_per_second": 3588.652,
      "eval_steps_per_second": 448.598,
      "step": 208500
    },
    {
      "epoch": 2.2077905579580883,
      "grad_norm": 0.9016951322555542,
      "learning_rate": 0.00047814108277952533,
      "loss": 0.811,
      "step": 208550
    },
    {
      "epoch": 2.2083198797380916,
      "grad_norm": 0.9141557216644287,
      "learning_rate": 0.0004781221893280244,
      "loss": 0.8132,
      "step": 208600
    },
    {
      "epoch": 2.208849201518095,
      "grad_norm": 0.9345206022262573,
      "learning_rate": 0.0004781032880885155,
      "loss": 0.8041,
      "step": 208650
    },
    {
      "epoch": 2.2093785232980983,
      "grad_norm": 0.9868102669715881,
      "learning_rate": 0.00047808437906164404,
      "loss": 0.8346,
      "step": 208700
    },
    {
      "epoch": 2.2099078450781016,
      "grad_norm": 0.8886350393295288,
      "learning_rate": 0.0004780654622480556,
      "loss": 0.8122,
      "step": 208750
    },
    {
      "epoch": 2.210437166858105,
      "grad_norm": 0.9111126065254211,
      "learning_rate": 0.0004780465376483958,
      "loss": 0.7977,
      "step": 208800
    },
    {
      "epoch": 2.210966488638108,
      "grad_norm": 0.9471650123596191,
      "learning_rate": 0.00047802798398730555,
      "loss": 0.8076,
      "step": 208850
    },
    {
      "epoch": 2.2114958104181115,
      "grad_norm": 0.890767514705658,
      "learning_rate": 0.00047800904397313107,
      "loss": 0.8176,
      "step": 208900
    },
    {
      "epoch": 2.2120251321981144,
      "grad_norm": 0.9928736090660095,
      "learning_rate": 0.00047799009617481146,
      "loss": 0.8232,
      "step": 208950
    },
    {
      "epoch": 2.2125544539781177,
      "grad_norm": 0.8310492634773254,
      "learning_rate": 0.00047797114059299357,
      "loss": 0.8165,
      "step": 209000
    },
    {
      "epoch": 2.2125544539781177,
      "eval_loss": 0.6255356669425964,
      "eval_runtime": 46.6724,
      "eval_samples_per_second": 3598.057,
      "eval_steps_per_second": 449.773,
      "step": 209000
    },
    {
      "epoch": 2.213083775758121,
      "grad_norm": 0.8788560032844543,
      "learning_rate": 0.00047795217722832454,
      "loss": 0.808,
      "step": 209050
    },
    {
      "epoch": 2.2136130975381243,
      "grad_norm": 0.9085614085197449,
      "learning_rate": 0.00047793320608145176,
      "loss": 0.8028,
      "step": 209100
    },
    {
      "epoch": 2.2141424193181276,
      "grad_norm": 0.8830627202987671,
      "learning_rate": 0.0004779142271530229,
      "loss": 0.799,
      "step": 209150
    },
    {
      "epoch": 2.214671741098131,
      "grad_norm": 0.889885425567627,
      "learning_rate": 0.000477895240443686,
      "loss": 0.806,
      "step": 209200
    },
    {
      "epoch": 2.2152010628781342,
      "grad_norm": 0.9270780682563782,
      "learning_rate": 0.0004778762459540891,
      "loss": 0.792,
      "step": 209250
    },
    {
      "epoch": 2.2157303846581375,
      "grad_norm": 0.8104616403579712,
      "learning_rate": 0.0004778572436848807,
      "loss": 0.8076,
      "step": 209300
    },
    {
      "epoch": 2.216259706438141,
      "grad_norm": 0.9209787845611572,
      "learning_rate": 0.00047783823363670966,
      "loss": 0.8068,
      "step": 209350
    },
    {
      "epoch": 2.216789028218144,
      "grad_norm": 1.0031235218048096,
      "learning_rate": 0.0004778192158102248,
      "loss": 0.8217,
      "step": 209400
    },
    {
      "epoch": 2.2173183499981475,
      "grad_norm": 0.8645867705345154,
      "learning_rate": 0.0004778001902060755,
      "loss": 0.7964,
      "step": 209450
    },
    {
      "epoch": 2.217847671778151,
      "grad_norm": 0.8710213303565979,
      "learning_rate": 0.0004777811568249113,
      "loss": 0.7986,
      "step": 209500
    },
    {
      "epoch": 2.217847671778151,
      "eval_loss": 0.6245876550674438,
      "eval_runtime": 46.7526,
      "eval_samples_per_second": 3591.886,
      "eval_steps_per_second": 449.002,
      "step": 209500
    },
    {
      "epoch": 2.218376993558154,
      "grad_norm": 0.9431130886077881,
      "learning_rate": 0.0004777621156673818,
      "loss": 0.7984,
      "step": 209550
    },
    {
      "epoch": 2.2189063153381574,
      "grad_norm": 0.9537584185600281,
      "learning_rate": 0.00047774306673413735,
      "loss": 0.8184,
      "step": 209600
    },
    {
      "epoch": 2.2194356371181607,
      "grad_norm": 0.8727585077285767,
      "learning_rate": 0.00047772401002582805,
      "loss": 0.8125,
      "step": 209650
    },
    {
      "epoch": 2.2199649588981636,
      "grad_norm": 0.9389255046844482,
      "learning_rate": 0.00047770494554310455,
      "loss": 0.8001,
      "step": 209700
    },
    {
      "epoch": 2.220494280678167,
      "grad_norm": 0.9650012850761414,
      "learning_rate": 0.0004776858732866177,
      "loss": 0.7957,
      "step": 209750
    },
    {
      "epoch": 2.22102360245817,
      "grad_norm": 0.9211475849151611,
      "learning_rate": 0.0004776667932570188,
      "loss": 0.8101,
      "step": 209800
    },
    {
      "epoch": 2.2215529242381735,
      "grad_norm": 0.8953306674957275,
      "learning_rate": 0.00047764770545495887,
      "loss": 0.7966,
      "step": 209850
    },
    {
      "epoch": 2.222082246018177,
      "grad_norm": 0.8637160658836365,
      "learning_rate": 0.0004776286098810899,
      "loss": 0.8028,
      "step": 209900
    },
    {
      "epoch": 2.22261156779818,
      "grad_norm": 0.9944068789482117,
      "learning_rate": 0.0004776095065360636,
      "loss": 0.8177,
      "step": 209950
    },
    {
      "epoch": 2.2231408895781835,
      "grad_norm": 0.937042236328125,
      "learning_rate": 0.0004775903954205322,
      "loss": 0.8134,
      "step": 210000
    },
    {
      "epoch": 2.2231408895781835,
      "eval_loss": 0.6243855953216553,
      "eval_runtime": 46.7522,
      "eval_samples_per_second": 3591.917,
      "eval_steps_per_second": 449.006,
      "step": 210000
    },
    {
      "epoch": 2.2236702113581868,
      "grad_norm": 0.9307417869567871,
      "learning_rate": 0.0004775712765351482,
      "loss": 0.8006,
      "step": 210050
    },
    {
      "epoch": 2.22419953313819,
      "grad_norm": 0.9322777986526489,
      "learning_rate": 0.0004775521498805643,
      "loss": 0.8138,
      "step": 210100
    },
    {
      "epoch": 2.2247288549181934,
      "grad_norm": 0.9160513281822205,
      "learning_rate": 0.00047753301545743344,
      "loss": 0.796,
      "step": 210150
    },
    {
      "epoch": 2.2252581766981967,
      "grad_norm": 0.9623757600784302,
      "learning_rate": 0.00047751387326640883,
      "loss": 0.8212,
      "step": 210200
    },
    {
      "epoch": 2.2257874984782,
      "grad_norm": 0.8565338850021362,
      "learning_rate": 0.00047749472330814414,
      "loss": 0.8095,
      "step": 210250
    },
    {
      "epoch": 2.2263168202582033,
      "grad_norm": 0.8929024934768677,
      "learning_rate": 0.0004774755655832929,
      "loss": 0.8022,
      "step": 210300
    },
    {
      "epoch": 2.2268461420382066,
      "grad_norm": 0.7812752723693848,
      "learning_rate": 0.0004774564000925093,
      "loss": 0.8047,
      "step": 210350
    },
    {
      "epoch": 2.22737546381821,
      "grad_norm": 0.8441065549850464,
      "learning_rate": 0.00047743722683644767,
      "loss": 0.7956,
      "step": 210400
    },
    {
      "epoch": 2.227904785598213,
      "grad_norm": 0.8617134094238281,
      "learning_rate": 0.00047741804581576255,
      "loss": 0.8009,
      "step": 210450
    },
    {
      "epoch": 2.228434107378216,
      "grad_norm": 0.9226464629173279,
      "learning_rate": 0.0004773988570311087,
      "loss": 0.8085,
      "step": 210500
    },
    {
      "epoch": 2.228434107378216,
      "eval_loss": 0.6267052292823792,
      "eval_runtime": 46.7231,
      "eval_samples_per_second": 3594.151,
      "eval_steps_per_second": 449.285,
      "step": 210500
    },
    {
      "epoch": 2.2289634291582194,
      "grad_norm": 0.8526345491409302,
      "learning_rate": 0.00047737966048314127,
      "loss": 0.7933,
      "step": 210550
    },
    {
      "epoch": 2.2294927509382227,
      "grad_norm": 0.8229122757911682,
      "learning_rate": 0.00047736045617251564,
      "loss": 0.8056,
      "step": 210600
    },
    {
      "epoch": 2.230022072718226,
      "grad_norm": 0.9511691331863403,
      "learning_rate": 0.0004773412440998873,
      "loss": 0.8001,
      "step": 210650
    },
    {
      "epoch": 2.2305513944982294,
      "grad_norm": 0.9362461566925049,
      "learning_rate": 0.00047732202426591244,
      "loss": 0.8055,
      "step": 210700
    },
    {
      "epoch": 2.2310807162782327,
      "grad_norm": 0.9263225197792053,
      "learning_rate": 0.00047730279667124696,
      "loss": 0.8071,
      "step": 210750
    },
    {
      "epoch": 2.231610038058236,
      "grad_norm": 0.9076798558235168,
      "learning_rate": 0.0004772835613165474,
      "loss": 0.8165,
      "step": 210800
    },
    {
      "epoch": 2.2321393598382393,
      "grad_norm": 0.8573198318481445,
      "learning_rate": 0.0004772643182024703,
      "loss": 0.7935,
      "step": 210850
    },
    {
      "epoch": 2.2326686816182426,
      "grad_norm": 0.9955106973648071,
      "learning_rate": 0.0004772450673296728,
      "loss": 0.8102,
      "step": 210900
    },
    {
      "epoch": 2.233198003398246,
      "grad_norm": 0.9191807508468628,
      "learning_rate": 0.00047722619394745405,
      "loss": 0.7998,
      "step": 210950
    },
    {
      "epoch": 2.2337273251782492,
      "grad_norm": 0.9064479470252991,
      "learning_rate": 0.00047720692771432917,
      "loss": 0.8015,
      "step": 211000
    },
    {
      "epoch": 2.2337273251782492,
      "eval_loss": 0.6220279335975647,
      "eval_runtime": 46.6615,
      "eval_samples_per_second": 3598.901,
      "eval_steps_per_second": 449.879,
      "step": 211000
    },
    {
      "epoch": 2.2342566469582525,
      "grad_norm": 0.8501535654067993,
      "learning_rate": 0.00047718765372444313,
      "loss": 0.8041,
      "step": 211050
    },
    {
      "epoch": 2.234785968738256,
      "grad_norm": 0.8072959184646606,
      "learning_rate": 0.0004771683719784539,
      "loss": 0.809,
      "step": 211100
    },
    {
      "epoch": 2.235315290518259,
      "grad_norm": 0.8974311947822571,
      "learning_rate": 0.0004771490824770197,
      "loss": 0.8028,
      "step": 211150
    },
    {
      "epoch": 2.235844612298262,
      "grad_norm": 0.8991398811340332,
      "learning_rate": 0.0004771297852207992,
      "loss": 0.8054,
      "step": 211200
    },
    {
      "epoch": 2.2363739340782653,
      "grad_norm": 0.8409492373466492,
      "learning_rate": 0.0004771104802104511,
      "loss": 0.7988,
      "step": 211250
    },
    {
      "epoch": 2.2369032558582687,
      "grad_norm": 0.8667699098587036,
      "learning_rate": 0.00047709116744663454,
      "loss": 0.8202,
      "step": 211300
    },
    {
      "epoch": 2.237432577638272,
      "grad_norm": 0.9140464067459106,
      "learning_rate": 0.00047707184693000884,
      "loss": 0.8165,
      "step": 211350
    },
    {
      "epoch": 2.2379618994182753,
      "grad_norm": 0.863009512424469,
      "learning_rate": 0.0004770525186612334,
      "loss": 0.803,
      "step": 211400
    },
    {
      "epoch": 2.2384912211982786,
      "grad_norm": 0.9775769114494324,
      "learning_rate": 0.0004770331826409684,
      "loss": 0.7984,
      "step": 211450
    },
    {
      "epoch": 2.239020542978282,
      "grad_norm": 0.9304951429367065,
      "learning_rate": 0.0004770138388698738,
      "loss": 0.8078,
      "step": 211500
    },
    {
      "epoch": 2.239020542978282,
      "eval_loss": 0.6217030882835388,
      "eval_runtime": 46.7136,
      "eval_samples_per_second": 3594.886,
      "eval_steps_per_second": 449.377,
      "step": 211500
    },
    {
      "epoch": 2.239549864758285,
      "grad_norm": 0.9608259797096252,
      "learning_rate": 0.0004769944873486099,
      "loss": 0.8195,
      "step": 211550
    },
    {
      "epoch": 2.2400791865382885,
      "grad_norm": 0.8934268355369568,
      "learning_rate": 0.0004769751280778375,
      "loss": 0.811,
      "step": 211600
    },
    {
      "epoch": 2.240608508318292,
      "grad_norm": 0.9255860447883606,
      "learning_rate": 0.00047695576105821747,
      "loss": 0.815,
      "step": 211650
    },
    {
      "epoch": 2.241137830098295,
      "grad_norm": 1.069765329360962,
      "learning_rate": 0.00047693638629041097,
      "loss": 0.7998,
      "step": 211700
    },
    {
      "epoch": 2.2416671518782985,
      "grad_norm": 0.8859947919845581,
      "learning_rate": 0.0004769170037750795,
      "loss": 0.8102,
      "step": 211750
    },
    {
      "epoch": 2.2421964736583018,
      "grad_norm": 0.9678333401679993,
      "learning_rate": 0.00047689761351288475,
      "loss": 0.8093,
      "step": 211800
    },
    {
      "epoch": 2.242725795438305,
      "grad_norm": 0.9104726910591125,
      "learning_rate": 0.00047687821550448863,
      "loss": 0.8012,
      "step": 211850
    },
    {
      "epoch": 2.2432551172183084,
      "grad_norm": 0.9038659930229187,
      "learning_rate": 0.00047685880975055354,
      "loss": 0.8016,
      "step": 211900
    },
    {
      "epoch": 2.2437844389983113,
      "grad_norm": 0.9116804599761963,
      "learning_rate": 0.00047683939625174177,
      "loss": 0.8033,
      "step": 211950
    },
    {
      "epoch": 2.2443137607783146,
      "grad_norm": 0.8775364756584167,
      "learning_rate": 0.0004768199750087162,
      "loss": 0.7938,
      "step": 212000
    },
    {
      "epoch": 2.2443137607783146,
      "eval_loss": 0.6181060075759888,
      "eval_runtime": 46.7742,
      "eval_samples_per_second": 3590.23,
      "eval_steps_per_second": 448.795,
      "step": 212000
    },
    {
      "epoch": 2.244843082558318,
      "grad_norm": 0.9338504076004028,
      "learning_rate": 0.00047680054602214,
      "loss": 0.8002,
      "step": 212050
    },
    {
      "epoch": 2.245372404338321,
      "grad_norm": 0.8633981347084045,
      "learning_rate": 0.00047678110929267616,
      "loss": 0.8004,
      "step": 212100
    },
    {
      "epoch": 2.2459017261183245,
      "grad_norm": 0.8862125277519226,
      "learning_rate": 0.00047676166482098854,
      "loss": 0.7938,
      "step": 212150
    },
    {
      "epoch": 2.246431047898328,
      "grad_norm": 0.9585325121879578,
      "learning_rate": 0.0004767422126077408,
      "loss": 0.8055,
      "step": 212200
    },
    {
      "epoch": 2.246960369678331,
      "grad_norm": 0.9102528691291809,
      "learning_rate": 0.0004767227526535971,
      "loss": 0.7988,
      "step": 212250
    },
    {
      "epoch": 2.2474896914583344,
      "grad_norm": 0.8742362260818481,
      "learning_rate": 0.0004767032849592218,
      "loss": 0.8152,
      "step": 212300
    },
    {
      "epoch": 2.2480190132383377,
      "grad_norm": 0.7909150719642639,
      "learning_rate": 0.0004766838095252794,
      "loss": 0.7967,
      "step": 212350
    },
    {
      "epoch": 2.248548335018341,
      "grad_norm": 0.8700685501098633,
      "learning_rate": 0.00047666432635243495,
      "loss": 0.7997,
      "step": 212400
    },
    {
      "epoch": 2.2490776567983444,
      "grad_norm": 0.8788574934005737,
      "learning_rate": 0.0004766448354413535,
      "loss": 0.797,
      "step": 212450
    },
    {
      "epoch": 2.2496069785783477,
      "grad_norm": 0.8913918137550354,
      "learning_rate": 0.0004766253367927005,
      "loss": 0.8034,
      "step": 212500
    },
    {
      "epoch": 2.2496069785783477,
      "eval_loss": 0.6172472834587097,
      "eval_runtime": 46.7307,
      "eval_samples_per_second": 3593.568,
      "eval_steps_per_second": 449.212,
      "step": 212500
    },
    {
      "epoch": 2.250136300358351,
      "grad_norm": 0.7749385237693787,
      "learning_rate": 0.0004766058304071416,
      "loss": 0.8117,
      "step": 212550
    },
    {
      "epoch": 2.2506656221383543,
      "grad_norm": 0.9113646149635315,
      "learning_rate": 0.0004765863162853428,
      "loss": 0.8063,
      "step": 212600
    },
    {
      "epoch": 2.2511949439183576,
      "grad_norm": 0.9161816835403442,
      "learning_rate": 0.0004765667944279702,
      "loss": 0.8031,
      "step": 212650
    },
    {
      "epoch": 2.2517242656983605,
      "grad_norm": 0.9861610531806946,
      "learning_rate": 0.00047654726483569034,
      "loss": 0.8015,
      "step": 212700
    },
    {
      "epoch": 2.252253587478364,
      "grad_norm": 0.963621973991394,
      "learning_rate": 0.00047652772750916996,
      "loss": 0.7999,
      "step": 212750
    },
    {
      "epoch": 2.252782909258367,
      "grad_norm": 1.0192662477493286,
      "learning_rate": 0.00047650818244907603,
      "loss": 0.784,
      "step": 212800
    },
    {
      "epoch": 2.2533122310383704,
      "grad_norm": 1.0000942945480347,
      "learning_rate": 0.0004764886296560759,
      "loss": 0.8217,
      "step": 212850
    },
    {
      "epoch": 2.2538415528183737,
      "grad_norm": 0.8388368487358093,
      "learning_rate": 0.0004764690691308369,
      "loss": 0.8061,
      "step": 212900
    },
    {
      "epoch": 2.254370874598377,
      "grad_norm": 0.9168955683708191,
      "learning_rate": 0.0004764495008740269,
      "loss": 0.7896,
      "step": 212950
    },
    {
      "epoch": 2.2549001963783804,
      "grad_norm": 0.9665777087211609,
      "learning_rate": 0.0004764299248863141,
      "loss": 0.7939,
      "step": 213000
    },
    {
      "epoch": 2.2549001963783804,
      "eval_loss": 0.6180890202522278,
      "eval_runtime": 46.7317,
      "eval_samples_per_second": 3593.494,
      "eval_steps_per_second": 449.203,
      "step": 213000
    },
    {
      "epoch": 2.2554295181583837,
      "grad_norm": 0.9321711659431458,
      "learning_rate": 0.00047641073291847756,
      "loss": 0.8046,
      "step": 213050
    },
    {
      "epoch": 2.255958839938387,
      "grad_norm": 0.945438027381897,
      "learning_rate": 0.0004763911416255489,
      "loss": 0.8201,
      "step": 213100
    },
    {
      "epoch": 2.2564881617183903,
      "grad_norm": 0.9635494947433472,
      "learning_rate": 0.0004763715426037097,
      "loss": 0.8128,
      "step": 213150
    },
    {
      "epoch": 2.2570174834983936,
      "grad_norm": 0.9662154912948608,
      "learning_rate": 0.00047635193585362904,
      "loss": 0.8135,
      "step": 213200
    },
    {
      "epoch": 2.257546805278397,
      "grad_norm": 1.0325042009353638,
      "learning_rate": 0.0004763323213759763,
      "loss": 0.8013,
      "step": 213250
    },
    {
      "epoch": 2.2580761270584,
      "grad_norm": 0.8861340284347534,
      "learning_rate": 0.00047631269917142107,
      "loss": 0.8055,
      "step": 213300
    },
    {
      "epoch": 2.2586054488384035,
      "grad_norm": 0.9498699307441711,
      "learning_rate": 0.00047629306924063333,
      "loss": 0.8038,
      "step": 213350
    },
    {
      "epoch": 2.259134770618407,
      "grad_norm": 0.9540978670120239,
      "learning_rate": 0.00047627343158428316,
      "loss": 0.8079,
      "step": 213400
    },
    {
      "epoch": 2.2596640923984097,
      "grad_norm": 0.926214337348938,
      "learning_rate": 0.00047625378620304103,
      "loss": 0.8045,
      "step": 213450
    },
    {
      "epoch": 2.260193414178413,
      "grad_norm": 0.9859682321548462,
      "learning_rate": 0.0004762341330975777,
      "loss": 0.799,
      "step": 213500
    },
    {
      "epoch": 2.260193414178413,
      "eval_loss": 0.6180621385574341,
      "eval_runtime": 46.7785,
      "eval_samples_per_second": 3589.899,
      "eval_steps_per_second": 448.753,
      "step": 213500
    },
    {
      "epoch": 2.2607227359584163,
      "grad_norm": 0.9765872359275818,
      "learning_rate": 0.00047621447226856397,
      "loss": 0.8101,
      "step": 213550
    },
    {
      "epoch": 2.2612520577384196,
      "grad_norm": 0.8913989663124084,
      "learning_rate": 0.0004761948037166711,
      "loss": 0.7997,
      "step": 213600
    },
    {
      "epoch": 2.261781379518423,
      "grad_norm": 0.9139604568481445,
      "learning_rate": 0.0004761751274425706,
      "loss": 0.8041,
      "step": 213650
    },
    {
      "epoch": 2.2623107012984263,
      "grad_norm": 0.9382502436637878,
      "learning_rate": 0.0004761554434469342,
      "loss": 0.8067,
      "step": 213700
    },
    {
      "epoch": 2.2628400230784296,
      "grad_norm": 0.915972888469696,
      "learning_rate": 0.0004761357517304339,
      "loss": 0.8084,
      "step": 213750
    },
    {
      "epoch": 2.263369344858433,
      "grad_norm": 0.9946889281272888,
      "learning_rate": 0.000476116052293742,
      "loss": 0.8093,
      "step": 213800
    },
    {
      "epoch": 2.263898666638436,
      "grad_norm": 0.8513433337211609,
      "learning_rate": 0.000476096345137531,
      "loss": 0.8044,
      "step": 213850
    },
    {
      "epoch": 2.2644279884184395,
      "grad_norm": 0.9021784067153931,
      "learning_rate": 0.0004760766302624736,
      "loss": 0.8179,
      "step": 213900
    },
    {
      "epoch": 2.264957310198443,
      "grad_norm": 0.9287652373313904,
      "learning_rate": 0.000476056907669243,
      "loss": 0.8067,
      "step": 213950
    },
    {
      "epoch": 2.265486631978446,
      "grad_norm": 0.8765013813972473,
      "learning_rate": 0.0004760371773585125,
      "loss": 0.7976,
      "step": 214000
    },
    {
      "epoch": 2.265486631978446,
      "eval_loss": 0.6154308319091797,
      "eval_runtime": 46.8818,
      "eval_samples_per_second": 3581.983,
      "eval_steps_per_second": 447.764,
      "step": 214000
    },
    {
      "epoch": 2.2660159537584494,
      "grad_norm": 0.8747231364250183,
      "learning_rate": 0.00047601743933095564,
      "loss": 0.8087,
      "step": 214050
    },
    {
      "epoch": 2.2665452755384528,
      "grad_norm": 0.8890218138694763,
      "learning_rate": 0.0004759976935872463,
      "loss": 0.7824,
      "step": 214100
    },
    {
      "epoch": 2.267074597318456,
      "grad_norm": 0.901298999786377,
      "learning_rate": 0.0004759779401280586,
      "loss": 0.8165,
      "step": 214150
    },
    {
      "epoch": 2.267603919098459,
      "grad_norm": 0.8782655000686646,
      "learning_rate": 0.0004759581789540669,
      "loss": 0.8196,
      "step": 214200
    },
    {
      "epoch": 2.2681332408784622,
      "grad_norm": 0.9249533414840698,
      "learning_rate": 0.00047593841006594585,
      "loss": 0.8076,
      "step": 214250
    },
    {
      "epoch": 2.2686625626584656,
      "grad_norm": 0.9430422186851501,
      "learning_rate": 0.00047591863346437035,
      "loss": 0.798,
      "step": 214300
    },
    {
      "epoch": 2.269191884438469,
      "grad_norm": 0.8607937693595886,
      "learning_rate": 0.0004758988491500155,
      "loss": 0.7964,
      "step": 214350
    },
    {
      "epoch": 2.269721206218472,
      "grad_norm": 0.874504566192627,
      "learning_rate": 0.0004758790571235568,
      "loss": 0.8049,
      "step": 214400
    },
    {
      "epoch": 2.2702505279984755,
      "grad_norm": 0.9281677007675171,
      "learning_rate": 0.00047585925738566993,
      "loss": 0.797,
      "step": 214450
    },
    {
      "epoch": 2.270779849778479,
      "grad_norm": 0.9268397688865662,
      "learning_rate": 0.00047583944993703087,
      "loss": 0.7906,
      "step": 214500
    },
    {
      "epoch": 2.270779849778479,
      "eval_loss": 0.6167524456977844,
      "eval_runtime": 46.8499,
      "eval_samples_per_second": 3584.426,
      "eval_steps_per_second": 448.069,
      "step": 214500
    },
    {
      "epoch": 2.271309171558482,
      "grad_norm": 0.9159491062164307,
      "learning_rate": 0.0004758196347783158,
      "loss": 0.804,
      "step": 214550
    },
    {
      "epoch": 2.2718384933384854,
      "grad_norm": 0.9115449786186218,
      "learning_rate": 0.00047579981191020124,
      "loss": 0.7956,
      "step": 214600
    },
    {
      "epoch": 2.2723678151184887,
      "grad_norm": 0.8639035820960999,
      "learning_rate": 0.00047577998133336387,
      "loss": 0.7998,
      "step": 214650
    },
    {
      "epoch": 2.272897136898492,
      "grad_norm": 0.9347543120384216,
      "learning_rate": 0.00047576014304848076,
      "loss": 0.8116,
      "step": 214700
    },
    {
      "epoch": 2.2734264586784954,
      "grad_norm": 0.8667251467704773,
      "learning_rate": 0.0004757402970562291,
      "loss": 0.8061,
      "step": 214750
    },
    {
      "epoch": 2.2739557804584987,
      "grad_norm": 0.9156843423843384,
      "learning_rate": 0.0004757204433572866,
      "loss": 0.8069,
      "step": 214800
    },
    {
      "epoch": 2.274485102238502,
      "grad_norm": 0.9154789447784424,
      "learning_rate": 0.0004757005819523309,
      "loss": 0.8172,
      "step": 214850
    },
    {
      "epoch": 2.2750144240185053,
      "grad_norm": 0.8818456530570984,
      "learning_rate": 0.0004756807128420401,
      "loss": 0.7932,
      "step": 214900
    },
    {
      "epoch": 2.275543745798508,
      "grad_norm": 0.8454349637031555,
      "learning_rate": 0.00047566083602709253,
      "loss": 0.8088,
      "step": 214950
    },
    {
      "epoch": 2.2760730675785115,
      "grad_norm": 0.8856368064880371,
      "learning_rate": 0.00047564095150816674,
      "loss": 0.8137,
      "step": 215000
    },
    {
      "epoch": 2.2760730675785115,
      "eval_loss": 0.6146847605705261,
      "eval_runtime": 46.887,
      "eval_samples_per_second": 3581.594,
      "eval_steps_per_second": 447.715,
      "step": 215000
    },
    {
      "epoch": 2.2766023893585148,
      "grad_norm": 0.889725923538208,
      "learning_rate": 0.0004756210592859416,
      "loss": 0.7993,
      "step": 215050
    },
    {
      "epoch": 2.277131711138518,
      "grad_norm": 0.934271514415741,
      "learning_rate": 0.0004756015574350745,
      "loss": 0.824,
      "step": 215100
    },
    {
      "epoch": 2.2776610329185214,
      "grad_norm": 0.8569375276565552,
      "learning_rate": 0.0004755816499623205,
      "loss": 0.81,
      "step": 215150
    },
    {
      "epoch": 2.2781903546985247,
      "grad_norm": 0.9707742929458618,
      "learning_rate": 0.0004755617347882917,
      "loss": 0.803,
      "step": 215200
    },
    {
      "epoch": 2.278719676478528,
      "grad_norm": 0.926164984703064,
      "learning_rate": 0.000475541811913668,
      "loss": 0.799,
      "step": 215250
    },
    {
      "epoch": 2.2792489982585313,
      "grad_norm": 0.8954142332077026,
      "learning_rate": 0.00047552188133912957,
      "loss": 0.8113,
      "step": 215300
    },
    {
      "epoch": 2.2797783200385346,
      "grad_norm": 0.9124211072921753,
      "learning_rate": 0.0004755019430653568,
      "loss": 0.807,
      "step": 215350
    },
    {
      "epoch": 2.280307641818538,
      "grad_norm": 0.8423799872398376,
      "learning_rate": 0.0004754819970930304,
      "loss": 0.8026,
      "step": 215400
    },
    {
      "epoch": 2.2808369635985413,
      "grad_norm": 0.9679311513900757,
      "learning_rate": 0.00047546204342283126,
      "loss": 0.809,
      "step": 215450
    },
    {
      "epoch": 2.2813662853785446,
      "grad_norm": 0.9682021141052246,
      "learning_rate": 0.0004754420820554407,
      "loss": 0.8061,
      "step": 215500
    },
    {
      "epoch": 2.2813662853785446,
      "eval_loss": 0.6132388710975647,
      "eval_runtime": 46.8444,
      "eval_samples_per_second": 3584.848,
      "eval_steps_per_second": 448.122,
      "step": 215500
    },
    {
      "epoch": 2.281895607158548,
      "grad_norm": 0.9361517429351807,
      "learning_rate": 0.00047542211299154015,
      "loss": 0.8168,
      "step": 215550
    },
    {
      "epoch": 2.282424928938551,
      "grad_norm": 0.837689220905304,
      "learning_rate": 0.00047540213623181135,
      "loss": 0.8089,
      "step": 215600
    },
    {
      "epoch": 2.2829542507185545,
      "grad_norm": 0.9403656125068665,
      "learning_rate": 0.00047538215177693623,
      "loss": 0.8079,
      "step": 215650
    },
    {
      "epoch": 2.2834835724985574,
      "grad_norm": 0.89329594373703,
      "learning_rate": 0.0004753621596275971,
      "loss": 0.793,
      "step": 215700
    },
    {
      "epoch": 2.2840128942785607,
      "grad_norm": 0.8009539842605591,
      "learning_rate": 0.00047534215978447647,
      "loss": 0.8034,
      "step": 215750
    },
    {
      "epoch": 2.284542216058564,
      "grad_norm": 0.8980734944343567,
      "learning_rate": 0.00047532215224825727,
      "loss": 0.8061,
      "step": 215800
    },
    {
      "epoch": 2.2850715378385673,
      "grad_norm": 0.9159832000732422,
      "learning_rate": 0.0004753021370196223,
      "loss": 0.8048,
      "step": 215850
    },
    {
      "epoch": 2.2856008596185706,
      "grad_norm": 0.9193938970565796,
      "learning_rate": 0.00047528211409925505,
      "loss": 0.7971,
      "step": 215900
    },
    {
      "epoch": 2.286130181398574,
      "grad_norm": 0.9167519807815552,
      "learning_rate": 0.00047526208348783904,
      "loss": 0.8168,
      "step": 215950
    },
    {
      "epoch": 2.2866595031785772,
      "grad_norm": 0.9040221571922302,
      "learning_rate": 0.0004752420451860581,
      "loss": 0.7928,
      "step": 216000
    },
    {
      "epoch": 2.2866595031785772,
      "eval_loss": 0.6162238121032715,
      "eval_runtime": 46.8287,
      "eval_samples_per_second": 3586.051,
      "eval_steps_per_second": 448.272,
      "step": 216000
    },
    {
      "epoch": 2.2871888249585806,
      "grad_norm": 0.9052408337593079,
      "learning_rate": 0.0004752219991945964,
      "loss": 0.8152,
      "step": 216050
    },
    {
      "epoch": 2.287718146738584,
      "grad_norm": 0.7953581213951111,
      "learning_rate": 0.00047520194551413814,
      "loss": 0.795,
      "step": 216100
    },
    {
      "epoch": 2.288247468518587,
      "grad_norm": 0.9640072584152222,
      "learning_rate": 0.0004751818841453681,
      "loss": 0.8069,
      "step": 216150
    },
    {
      "epoch": 2.2887767902985905,
      "grad_norm": 1.015467882156372,
      "learning_rate": 0.0004751618150889712,
      "loss": 0.7913,
      "step": 216200
    },
    {
      "epoch": 2.289306112078594,
      "grad_norm": 1.0023068189620972,
      "learning_rate": 0.0004751417383456324,
      "loss": 0.7957,
      "step": 216250
    },
    {
      "epoch": 2.289835433858597,
      "grad_norm": 0.9182496666908264,
      "learning_rate": 0.0004751216539160372,
      "loss": 0.8112,
      "step": 216300
    },
    {
      "epoch": 2.2903647556386004,
      "grad_norm": 1.006952166557312,
      "learning_rate": 0.0004751015618008714,
      "loss": 0.8065,
      "step": 216350
    },
    {
      "epoch": 2.2908940774186037,
      "grad_norm": 0.7992024421691895,
      "learning_rate": 0.0004750814620008208,
      "loss": 0.8117,
      "step": 216400
    },
    {
      "epoch": 2.2914233991986066,
      "grad_norm": 0.8723312020301819,
      "learning_rate": 0.00047506135451657163,
      "loss": 0.7848,
      "step": 216450
    },
    {
      "epoch": 2.29195272097861,
      "grad_norm": 0.9355488419532776,
      "learning_rate": 0.00047504123934881035,
      "loss": 0.7991,
      "step": 216500
    },
    {
      "epoch": 2.29195272097861,
      "eval_loss": 0.6122531890869141,
      "eval_runtime": 46.8403,
      "eval_samples_per_second": 3585.157,
      "eval_steps_per_second": 448.161,
      "step": 216500
    },
    {
      "epoch": 2.2924820427586132,
      "grad_norm": 0.8835433721542358,
      "learning_rate": 0.00047502111649822367,
      "loss": 0.8019,
      "step": 216550
    },
    {
      "epoch": 2.2930113645386165,
      "grad_norm": 0.896014928817749,
      "learning_rate": 0.0004750009859654986,
      "loss": 0.7887,
      "step": 216600
    },
    {
      "epoch": 2.29354068631862,
      "grad_norm": 0.8279396295547485,
      "learning_rate": 0.0004749808477513224,
      "loss": 0.7838,
      "step": 216650
    },
    {
      "epoch": 2.294070008098623,
      "grad_norm": 0.8996099233627319,
      "learning_rate": 0.00047496070185638255,
      "loss": 0.8006,
      "step": 216700
    },
    {
      "epoch": 2.2945993298786265,
      "grad_norm": 0.8806161880493164,
      "learning_rate": 0.0004749405482813669,
      "loss": 0.7988,
      "step": 216750
    },
    {
      "epoch": 2.29512865165863,
      "grad_norm": 0.8934552669525146,
      "learning_rate": 0.00047492038702696336,
      "loss": 0.8071,
      "step": 216800
    },
    {
      "epoch": 2.295657973438633,
      "grad_norm": 0.8861938714981079,
      "learning_rate": 0.0004749002180938603,
      "loss": 0.7942,
      "step": 216850
    },
    {
      "epoch": 2.2961872952186364,
      "grad_norm": 0.9216464757919312,
      "learning_rate": 0.00047488004148274634,
      "loss": 0.8134,
      "step": 216900
    },
    {
      "epoch": 2.2967166169986397,
      "grad_norm": 0.9500000476837158,
      "learning_rate": 0.0004748598571943101,
      "loss": 0.8028,
      "step": 216950
    },
    {
      "epoch": 2.297245938778643,
      "grad_norm": 0.9133980870246887,
      "learning_rate": 0.00047483966522924095,
      "loss": 0.7897,
      "step": 217000
    },
    {
      "epoch": 2.297245938778643,
      "eval_loss": 0.6132514476776123,
      "eval_runtime": 46.752,
      "eval_samples_per_second": 3591.935,
      "eval_steps_per_second": 449.008,
      "step": 217000
    },
    {
      "epoch": 2.2977752605586463,
      "grad_norm": 0.902036726474762,
      "learning_rate": 0.000474819465588228,
      "loss": 0.8107,
      "step": 217050
    },
    {
      "epoch": 2.2983045823386496,
      "grad_norm": 0.8034504652023315,
      "learning_rate": 0.0004747996624934994,
      "loss": 0.7918,
      "step": 217100
    },
    {
      "epoch": 2.298833904118653,
      "grad_norm": 0.8853028416633606,
      "learning_rate": 0.0004747794476561526,
      "loss": 0.7988,
      "step": 217150
    },
    {
      "epoch": 2.299363225898656,
      "grad_norm": 0.8583212494850159,
      "learning_rate": 0.000474759225144918,
      "loss": 0.8012,
      "step": 217200
    },
    {
      "epoch": 2.2998925476786596,
      "grad_norm": 0.892619252204895,
      "learning_rate": 0.0004747389949604858,
      "loss": 0.7948,
      "step": 217250
    },
    {
      "epoch": 2.3004218694586624,
      "grad_norm": 0.9253267049789429,
      "learning_rate": 0.00047471875710354674,
      "loss": 0.8165,
      "step": 217300
    },
    {
      "epoch": 2.3009511912386658,
      "grad_norm": 0.9039416313171387,
      "learning_rate": 0.00047469851157479177,
      "loss": 0.8228,
      "step": 217350
    },
    {
      "epoch": 2.301480513018669,
      "grad_norm": 0.8573392033576965,
      "learning_rate": 0.000474678258374912,
      "loss": 0.8025,
      "step": 217400
    },
    {
      "epoch": 2.3020098347986724,
      "grad_norm": 0.735282838344574,
      "learning_rate": 0.00047465799750459885,
      "loss": 0.8054,
      "step": 217450
    },
    {
      "epoch": 2.3025391565786757,
      "grad_norm": 0.9019036293029785,
      "learning_rate": 0.00047463772896454414,
      "loss": 0.8094,
      "step": 217500
    },
    {
      "epoch": 2.3025391565786757,
      "eval_loss": 0.6106682419776917,
      "eval_runtime": 46.8174,
      "eval_samples_per_second": 3586.914,
      "eval_steps_per_second": 448.38,
      "step": 217500
    },
    {
      "epoch": 2.303068478358679,
      "grad_norm": 0.9662856459617615,
      "learning_rate": 0.0004746174527554397,
      "loss": 0.7889,
      "step": 217550
    },
    {
      "epoch": 2.3035978001386823,
      "grad_norm": 0.9692597389221191,
      "learning_rate": 0.0004745971688779778,
      "loss": 0.7886,
      "step": 217600
    },
    {
      "epoch": 2.3041271219186856,
      "grad_norm": 0.9629518389701843,
      "learning_rate": 0.00047457687733285094,
      "loss": 0.809,
      "step": 217650
    },
    {
      "epoch": 2.304656443698689,
      "grad_norm": 0.9303768277168274,
      "learning_rate": 0.0004745565781207518,
      "loss": 0.7974,
      "step": 217700
    },
    {
      "epoch": 2.3051857654786923,
      "grad_norm": 0.8136096596717834,
      "learning_rate": 0.00047453627124237346,
      "loss": 0.805,
      "step": 217750
    },
    {
      "epoch": 2.3057150872586956,
      "grad_norm": 0.8769297003746033,
      "learning_rate": 0.0004745159566984092,
      "loss": 0.8002,
      "step": 217800
    },
    {
      "epoch": 2.306244409038699,
      "grad_norm": 0.8559973239898682,
      "learning_rate": 0.00047449563448955244,
      "loss": 0.7975,
      "step": 217850
    },
    {
      "epoch": 2.306773730818702,
      "grad_norm": 0.837496280670166,
      "learning_rate": 0.00047447530461649715,
      "loss": 0.7928,
      "step": 217900
    },
    {
      "epoch": 2.307303052598705,
      "grad_norm": 0.8612076640129089,
      "learning_rate": 0.0004744549670799372,
      "loss": 0.8009,
      "step": 217950
    },
    {
      "epoch": 2.307832374378709,
      "grad_norm": 0.9952797889709473,
      "learning_rate": 0.0004744346218805671,
      "loss": 0.7995,
      "step": 218000
    },
    {
      "epoch": 2.307832374378709,
      "eval_loss": 0.6110304594039917,
      "eval_runtime": 46.7835,
      "eval_samples_per_second": 3589.515,
      "eval_steps_per_second": 448.705,
      "step": 218000
    },
    {
      "epoch": 2.3083616961587117,
      "grad_norm": 0.9179230332374573,
      "learning_rate": 0.0004744142690190812,
      "loss": 0.7927,
      "step": 218050
    },
    {
      "epoch": 2.308891017938715,
      "grad_norm": 0.9236602783203125,
      "learning_rate": 0.0004743939084961745,
      "loss": 0.8174,
      "step": 218100
    },
    {
      "epoch": 2.3094203397187183,
      "grad_norm": 0.9449709057807922,
      "learning_rate": 0.00047437354031254204,
      "loss": 0.7975,
      "step": 218150
    },
    {
      "epoch": 2.3099496614987216,
      "grad_norm": 0.9125803709030151,
      "learning_rate": 0.0004743531644688792,
      "loss": 0.7911,
      "step": 218200
    },
    {
      "epoch": 2.310478983278725,
      "grad_norm": 0.9306867718696594,
      "learning_rate": 0.00047433278096588164,
      "loss": 0.7921,
      "step": 218250
    },
    {
      "epoch": 2.3110083050587282,
      "grad_norm": 0.8598804473876953,
      "learning_rate": 0.0004743123898042452,
      "loss": 0.795,
      "step": 218300
    },
    {
      "epoch": 2.3115376268387315,
      "grad_norm": 0.8540438413619995,
      "learning_rate": 0.000474291990984666,
      "loss": 0.7952,
      "step": 218350
    },
    {
      "epoch": 2.312066948618735,
      "grad_norm": 0.844912588596344,
      "learning_rate": 0.0004742715845078406,
      "loss": 0.8066,
      "step": 218400
    },
    {
      "epoch": 2.312596270398738,
      "grad_norm": 0.9098124504089355,
      "learning_rate": 0.00047425117037446543,
      "loss": 0.8002,
      "step": 218450
    },
    {
      "epoch": 2.3131255921787415,
      "grad_norm": 0.8822125196456909,
      "learning_rate": 0.00047423074858523754,
      "loss": 0.7993,
      "step": 218500
    },
    {
      "epoch": 2.3131255921787415,
      "eval_loss": 0.6133185625076294,
      "eval_runtime": 46.7975,
      "eval_samples_per_second": 3588.441,
      "eval_steps_per_second": 448.571,
      "step": 218500
    },
    {
      "epoch": 2.313654913958745,
      "grad_norm": 0.8540992736816406,
      "learning_rate": 0.00047421031914085423,
      "loss": 0.8219,
      "step": 218550
    },
    {
      "epoch": 2.314184235738748,
      "grad_norm": 0.9708830714225769,
      "learning_rate": 0.00047418988204201275,
      "loss": 0.7938,
      "step": 218600
    },
    {
      "epoch": 2.3147135575187514,
      "grad_norm": 0.9900920987129211,
      "learning_rate": 0.000474169437289411,
      "loss": 0.7765,
      "step": 218650
    },
    {
      "epoch": 2.3152428792987543,
      "grad_norm": 0.8288969993591309,
      "learning_rate": 0.0004741489848837468,
      "loss": 0.8042,
      "step": 218700
    },
    {
      "epoch": 2.315772201078758,
      "grad_norm": 0.9199753999710083,
      "learning_rate": 0.0004741285248257185,
      "loss": 0.7994,
      "step": 218750
    },
    {
      "epoch": 2.316301522858761,
      "grad_norm": 0.9383374452590942,
      "learning_rate": 0.0004741080571160246,
      "loss": 0.7845,
      "step": 218800
    },
    {
      "epoch": 2.316830844638764,
      "grad_norm": 0.9522022604942322,
      "learning_rate": 0.0004740875817553637,
      "loss": 0.7918,
      "step": 218850
    },
    {
      "epoch": 2.3173601664187675,
      "grad_norm": 0.8166509866714478,
      "learning_rate": 0.00047406709874443505,
      "loss": 0.7974,
      "step": 218900
    },
    {
      "epoch": 2.317889488198771,
      "grad_norm": 0.8727307915687561,
      "learning_rate": 0.00047404660808393774,
      "loss": 0.7923,
      "step": 218950
    },
    {
      "epoch": 2.318418809978774,
      "grad_norm": 0.9528635144233704,
      "learning_rate": 0.0004740261097745715,
      "loss": 0.7732,
      "step": 219000
    },
    {
      "epoch": 2.318418809978774,
      "eval_loss": 0.6082364320755005,
      "eval_runtime": 46.7903,
      "eval_samples_per_second": 3588.992,
      "eval_steps_per_second": 448.64,
      "step": 219000
    },
    {
      "epoch": 2.3189481317587775,
      "grad_norm": 0.8109923005104065,
      "learning_rate": 0.0004740056038170359,
      "loss": 0.7823,
      "step": 219050
    },
    {
      "epoch": 2.3194774535387808,
      "grad_norm": 0.8352981805801392,
      "learning_rate": 0.00047398509021203127,
      "loss": 0.8089,
      "step": 219100
    },
    {
      "epoch": 2.320006775318784,
      "grad_norm": 0.8821276426315308,
      "learning_rate": 0.00047396456896025776,
      "loss": 0.7959,
      "step": 219150
    },
    {
      "epoch": 2.3205360970987874,
      "grad_norm": 0.9345331192016602,
      "learning_rate": 0.00047394404006241596,
      "loss": 0.7866,
      "step": 219200
    },
    {
      "epoch": 2.3210654188787907,
      "grad_norm": 0.8508266806602478,
      "learning_rate": 0.00047392350351920675,
      "loss": 0.805,
      "step": 219250
    },
    {
      "epoch": 2.321594740658794,
      "grad_norm": 0.9469751119613647,
      "learning_rate": 0.0004739033702900021,
      "loss": 0.8054,
      "step": 219300
    },
    {
      "epoch": 2.3221240624387973,
      "grad_norm": 0.8392431735992432,
      "learning_rate": 0.0004738828186110341,
      "loss": 0.808,
      "step": 219350
    },
    {
      "epoch": 2.3226533842188006,
      "grad_norm": 0.899671733379364,
      "learning_rate": 0.0004738622592887888,
      "loss": 0.811,
      "step": 219400
    },
    {
      "epoch": 2.3231827059988035,
      "grad_norm": 0.9741580486297607,
      "learning_rate": 0.00047384169232396814,
      "loss": 0.804,
      "step": 219450
    },
    {
      "epoch": 2.3237120277788073,
      "grad_norm": 0.8590615391731262,
      "learning_rate": 0.0004738211177172741,
      "loss": 0.8016,
      "step": 219500
    },
    {
      "epoch": 2.3237120277788073,
      "eval_loss": 0.6073054075241089,
      "eval_runtime": 46.7804,
      "eval_samples_per_second": 3589.755,
      "eval_steps_per_second": 448.735,
      "step": 219500
    },
    {
      "epoch": 2.32424134955881,
      "grad_norm": 0.8604862093925476,
      "learning_rate": 0.0004738005354694093,
      "loss": 0.7945,
      "step": 219550
    },
    {
      "epoch": 2.3247706713388134,
      "grad_norm": 0.9600186347961426,
      "learning_rate": 0.0004737799455810762,
      "loss": 0.7961,
      "step": 219600
    },
    {
      "epoch": 2.3252999931188167,
      "grad_norm": 0.8646154999732971,
      "learning_rate": 0.0004737593480529778,
      "loss": 0.8068,
      "step": 219650
    },
    {
      "epoch": 2.32582931489882,
      "grad_norm": 0.9749768376350403,
      "learning_rate": 0.0004737387428858174,
      "loss": 0.8015,
      "step": 219700
    },
    {
      "epoch": 2.3263586366788234,
      "grad_norm": 0.9510635137557983,
      "learning_rate": 0.00047371813008029835,
      "loss": 0.7995,
      "step": 219750
    },
    {
      "epoch": 2.3268879584588267,
      "grad_norm": 0.8439449071884155,
      "learning_rate": 0.00047369750963712436,
      "loss": 0.8146,
      "step": 219800
    },
    {
      "epoch": 2.32741728023883,
      "grad_norm": 0.9432432651519775,
      "learning_rate": 0.0004736768815569995,
      "loss": 0.7926,
      "step": 219850
    },
    {
      "epoch": 2.3279466020188333,
      "grad_norm": 0.8322489857673645,
      "learning_rate": 0.00047365624584062784,
      "loss": 0.8008,
      "step": 219900
    },
    {
      "epoch": 2.3284759237988366,
      "grad_norm": 0.9910594820976257,
      "learning_rate": 0.00047363560248871406,
      "loss": 0.7916,
      "step": 219950
    },
    {
      "epoch": 2.32900524557884,
      "grad_norm": 0.8950614929199219,
      "learning_rate": 0.00047361495150196275,
      "loss": 0.7896,
      "step": 220000
    },
    {
      "epoch": 2.32900524557884,
      "eval_loss": 0.6096111536026001,
      "eval_runtime": 46.8309,
      "eval_samples_per_second": 3585.88,
      "eval_steps_per_second": 448.251,
      "step": 220000
    },
    {
      "epoch": 2.3295345673588432,
      "grad_norm": 0.930474042892456,
      "learning_rate": 0.000473594292881079,
      "loss": 0.8079,
      "step": 220050
    },
    {
      "epoch": 2.3300638891388465,
      "grad_norm": 0.9670558571815491,
      "learning_rate": 0.0004735736266267682,
      "loss": 0.7915,
      "step": 220100
    },
    {
      "epoch": 2.33059321091885,
      "grad_norm": 0.9494659900665283,
      "learning_rate": 0.0004735529527397357,
      "loss": 0.7851,
      "step": 220150
    },
    {
      "epoch": 2.3311225326988527,
      "grad_norm": 0.8391996026039124,
      "learning_rate": 0.0004735322712206874,
      "loss": 0.7983,
      "step": 220200
    },
    {
      "epoch": 2.3316518544788565,
      "grad_norm": 0.8288529515266418,
      "learning_rate": 0.0004735115820703293,
      "loss": 0.7979,
      "step": 220250
    },
    {
      "epoch": 2.3321811762588593,
      "grad_norm": 0.9429174661636353,
      "learning_rate": 0.00047349088528936777,
      "loss": 0.801,
      "step": 220300
    },
    {
      "epoch": 2.3327104980388627,
      "grad_norm": 0.8601976633071899,
      "learning_rate": 0.0004734701808785094,
      "loss": 0.7962,
      "step": 220350
    },
    {
      "epoch": 2.333239819818866,
      "grad_norm": 0.9495255947113037,
      "learning_rate": 0.00047344946883846103,
      "loss": 0.7985,
      "step": 220400
    },
    {
      "epoch": 2.3337691415988693,
      "grad_norm": 0.8661751747131348,
      "learning_rate": 0.00047342874916992973,
      "loss": 0.8055,
      "step": 220450
    },
    {
      "epoch": 2.3342984633788726,
      "grad_norm": 0.9294444918632507,
      "learning_rate": 0.00047340802187362285,
      "loss": 0.7862,
      "step": 220500
    },
    {
      "epoch": 2.3342984633788726,
      "eval_loss": 0.6091014742851257,
      "eval_runtime": 46.7634,
      "eval_samples_per_second": 3591.055,
      "eval_steps_per_second": 448.898,
      "step": 220500
    },
    {
      "epoch": 2.334827785158876,
      "grad_norm": 0.9407292604446411,
      "learning_rate": 0.00047338728695024804,
      "loss": 0.7991,
      "step": 220550
    },
    {
      "epoch": 2.335357106938879,
      "grad_norm": 0.8563601970672607,
      "learning_rate": 0.0004733665444005132,
      "loss": 0.7874,
      "step": 220600
    },
    {
      "epoch": 2.3358864287188825,
      "grad_norm": 1.0102653503417969,
      "learning_rate": 0.00047334579422512644,
      "loss": 0.8048,
      "step": 220650
    },
    {
      "epoch": 2.336415750498886,
      "grad_norm": 0.8562785983085632,
      "learning_rate": 0.0004733250364247962,
      "loss": 0.7964,
      "step": 220700
    },
    {
      "epoch": 2.336945072278889,
      "grad_norm": 0.9052565693855286,
      "learning_rate": 0.00047330427100023107,
      "loss": 0.7994,
      "step": 220750
    },
    {
      "epoch": 2.3374743940588925,
      "grad_norm": 0.855036735534668,
      "learning_rate": 0.00047328349795214,
      "loss": 0.8256,
      "step": 220800
    },
    {
      "epoch": 2.3380037158388958,
      "grad_norm": 0.8878644108772278,
      "learning_rate": 0.00047326271728123225,
      "loss": 0.7913,
      "step": 220850
    },
    {
      "epoch": 2.338533037618899,
      "grad_norm": 0.9405088424682617,
      "learning_rate": 0.0004732419289882172,
      "loss": 0.7952,
      "step": 220900
    },
    {
      "epoch": 2.339062359398902,
      "grad_norm": 0.9260468482971191,
      "learning_rate": 0.00047322113307380454,
      "loss": 0.8098,
      "step": 220950
    },
    {
      "epoch": 2.3395916811789057,
      "grad_norm": 0.9199790358543396,
      "learning_rate": 0.0004732003295387043,
      "loss": 0.7977,
      "step": 221000
    },
    {
      "epoch": 2.3395916811789057,
      "eval_loss": 0.6090827584266663,
      "eval_runtime": 46.8286,
      "eval_samples_per_second": 3586.057,
      "eval_steps_per_second": 448.273,
      "step": 221000
    },
    {
      "epoch": 2.3401210029589086,
      "grad_norm": 0.9815475344657898,
      "learning_rate": 0.0004731795183836267,
      "loss": 0.8077,
      "step": 221050
    },
    {
      "epoch": 2.340650324738912,
      "grad_norm": 0.9002581834793091,
      "learning_rate": 0.0004731586996092821,
      "loss": 0.8042,
      "step": 221100
    },
    {
      "epoch": 2.341179646518915,
      "grad_norm": 0.9287401437759399,
      "learning_rate": 0.00047313787321638136,
      "loss": 0.8069,
      "step": 221150
    },
    {
      "epoch": 2.3417089682989185,
      "grad_norm": 0.8783060908317566,
      "learning_rate": 0.00047311703920563554,
      "loss": 0.7852,
      "step": 221200
    },
    {
      "epoch": 2.342238290078922,
      "grad_norm": 0.9376782178878784,
      "learning_rate": 0.00047309619757775575,
      "loss": 0.7876,
      "step": 221250
    },
    {
      "epoch": 2.342767611858925,
      "grad_norm": 0.8748493790626526,
      "learning_rate": 0.00047307576539297604,
      "loss": 0.8018,
      "step": 221300
    },
    {
      "epoch": 2.3432969336389284,
      "grad_norm": 0.884818434715271,
      "learning_rate": 0.0004730549086852705,
      "loss": 0.8071,
      "step": 221350
    },
    {
      "epoch": 2.3438262554189317,
      "grad_norm": 0.8865165114402771,
      "learning_rate": 0.00047303404436255226,
      "loss": 0.7948,
      "step": 221400
    },
    {
      "epoch": 2.344355577198935,
      "grad_norm": 0.9668654799461365,
      "learning_rate": 0.0004730131724255335,
      "loss": 0.797,
      "step": 221450
    },
    {
      "epoch": 2.3448848989789384,
      "grad_norm": 0.8777245879173279,
      "learning_rate": 0.0004729922928749268,
      "loss": 0.8016,
      "step": 221500
    },
    {
      "epoch": 2.3448848989789384,
      "eval_loss": 0.6090844869613647,
      "eval_runtime": 46.7566,
      "eval_samples_per_second": 3591.577,
      "eval_steps_per_second": 448.963,
      "step": 221500
    },
    {
      "epoch": 2.3454142207589417,
      "grad_norm": 0.9266408085823059,
      "learning_rate": 0.0004729714057114451,
      "loss": 0.7938,
      "step": 221550
    },
    {
      "epoch": 2.345943542538945,
      "grad_norm": 0.9569845199584961,
      "learning_rate": 0.00047295051093580135,
      "loss": 0.7779,
      "step": 221600
    },
    {
      "epoch": 2.3464728643189483,
      "grad_norm": 0.7892946600914001,
      "learning_rate": 0.0004729296085487088,
      "loss": 0.805,
      "step": 221650
    },
    {
      "epoch": 2.347002186098951,
      "grad_norm": 0.9745076894760132,
      "learning_rate": 0.00047290869855088133,
      "loss": 0.782,
      "step": 221700
    },
    {
      "epoch": 2.347531507878955,
      "grad_norm": 0.8964519500732422,
      "learning_rate": 0.00047288778094303253,
      "loss": 0.7828,
      "step": 221750
    },
    {
      "epoch": 2.348060829658958,
      "grad_norm": 0.8954593539237976,
      "learning_rate": 0.0004728668557258767,
      "loss": 0.7943,
      "step": 221800
    },
    {
      "epoch": 2.348590151438961,
      "grad_norm": 0.949240505695343,
      "learning_rate": 0.0004728459229001281,
      "loss": 0.8108,
      "step": 221850
    },
    {
      "epoch": 2.3491194732189644,
      "grad_norm": 0.8899560570716858,
      "learning_rate": 0.0004728249824665015,
      "loss": 0.787,
      "step": 221900
    },
    {
      "epoch": 2.3496487949989677,
      "grad_norm": 0.9039623737335205,
      "learning_rate": 0.00047280403442571164,
      "loss": 0.7919,
      "step": 221950
    },
    {
      "epoch": 2.350178116778971,
      "grad_norm": 0.8735800981521606,
      "learning_rate": 0.00047278307877847376,
      "loss": 0.7956,
      "step": 222000
    },
    {
      "epoch": 2.350178116778971,
      "eval_loss": 0.6088102459907532,
      "eval_runtime": 46.7882,
      "eval_samples_per_second": 3589.15,
      "eval_steps_per_second": 448.66,
      "step": 222000
    },
    {
      "epoch": 2.3507074385589743,
      "grad_norm": 0.8193434476852417,
      "learning_rate": 0.0004727621155255033,
      "loss": 0.7959,
      "step": 222050
    },
    {
      "epoch": 2.3512367603389777,
      "grad_norm": 0.9848571419715881,
      "learning_rate": 0.00047274114466751597,
      "loss": 0.8095,
      "step": 222100
    },
    {
      "epoch": 2.351766082118981,
      "grad_norm": 0.9002127051353455,
      "learning_rate": 0.0004727201662052275,
      "loss": 0.795,
      "step": 222150
    },
    {
      "epoch": 2.3522954038989843,
      "grad_norm": 0.8482967615127563,
      "learning_rate": 0.0004726991801393543,
      "loss": 0.7973,
      "step": 222200
    },
    {
      "epoch": 2.3528247256789876,
      "grad_norm": 0.945434033870697,
      "learning_rate": 0.0004726781864706128,
      "loss": 0.8006,
      "step": 222250
    },
    {
      "epoch": 2.353354047458991,
      "grad_norm": 1.0309048891067505,
      "learning_rate": 0.0004726571851997197,
      "loss": 0.8,
      "step": 222300
    },
    {
      "epoch": 2.353883369238994,
      "grad_norm": 0.9261558055877686,
      "learning_rate": 0.0004726361763273919,
      "loss": 0.7974,
      "step": 222350
    },
    {
      "epoch": 2.3544126910189975,
      "grad_norm": 0.8882055282592773,
      "learning_rate": 0.0004726151598543467,
      "loss": 0.7997,
      "step": 222400
    },
    {
      "epoch": 2.3549420127990004,
      "grad_norm": 0.8821225762367249,
      "learning_rate": 0.00047259413578130163,
      "loss": 0.7992,
      "step": 222450
    },
    {
      "epoch": 2.355471334579004,
      "grad_norm": 0.9395198225975037,
      "learning_rate": 0.0004725731041089743,
      "loss": 0.7883,
      "step": 222500
    },
    {
      "epoch": 2.355471334579004,
      "eval_loss": 0.6074392795562744,
      "eval_runtime": 46.7255,
      "eval_samples_per_second": 3593.971,
      "eval_steps_per_second": 449.262,
      "step": 222500
    },
    {
      "epoch": 2.356000656359007,
      "grad_norm": 0.8685466647148132,
      "learning_rate": 0.00047255206483808287,
      "loss": 0.7986,
      "step": 222550
    },
    {
      "epoch": 2.3565299781390103,
      "grad_norm": 0.8341619372367859,
      "learning_rate": 0.0004725310179693456,
      "loss": 0.7988,
      "step": 222600
    },
    {
      "epoch": 2.3570592999190136,
      "grad_norm": 0.9053277969360352,
      "learning_rate": 0.00047250996350348096,
      "loss": 0.7861,
      "step": 222650
    },
    {
      "epoch": 2.357588621699017,
      "grad_norm": 0.9423511624336243,
      "learning_rate": 0.0004724889014412078,
      "loss": 0.8121,
      "step": 222700
    },
    {
      "epoch": 2.3581179434790203,
      "grad_norm": 0.9250903725624084,
      "learning_rate": 0.00047246783178324505,
      "loss": 0.784,
      "step": 222750
    },
    {
      "epoch": 2.3586472652590236,
      "grad_norm": 0.9403319358825684,
      "learning_rate": 0.00047244675453031215,
      "loss": 0.7927,
      "step": 222800
    },
    {
      "epoch": 2.359176587039027,
      "grad_norm": 0.8980112075805664,
      "learning_rate": 0.0004724256696831287,
      "loss": 0.8029,
      "step": 222850
    },
    {
      "epoch": 2.35970590881903,
      "grad_norm": 0.8304218649864197,
      "learning_rate": 0.00047240457724241435,
      "loss": 0.7961,
      "step": 222900
    },
    {
      "epoch": 2.3602352305990335,
      "grad_norm": 0.7456269860267639,
      "learning_rate": 0.0004723834772088894,
      "loss": 0.7885,
      "step": 222950
    },
    {
      "epoch": 2.360764552379037,
      "grad_norm": 0.9506320357322693,
      "learning_rate": 0.0004723623695832741,
      "loss": 0.7998,
      "step": 223000
    },
    {
      "epoch": 2.360764552379037,
      "eval_loss": 0.6057937741279602,
      "eval_runtime": 46.7718,
      "eval_samples_per_second": 3590.415,
      "eval_steps_per_second": 448.818,
      "step": 223000
    },
    {
      "epoch": 2.36129387415904,
      "grad_norm": 0.8898894786834717,
      "learning_rate": 0.0004723412543662889,
      "loss": 0.788,
      "step": 223050
    },
    {
      "epoch": 2.3618231959390434,
      "grad_norm": 0.9194847345352173,
      "learning_rate": 0.00047232013155865495,
      "loss": 0.7915,
      "step": 223100
    },
    {
      "epoch": 2.3623525177190468,
      "grad_norm": 0.9541802406311035,
      "learning_rate": 0.0004722990011610933,
      "loss": 0.7976,
      "step": 223150
    },
    {
      "epoch": 2.3628818394990496,
      "grad_norm": 0.8617965579032898,
      "learning_rate": 0.00047227786317432515,
      "loss": 0.792,
      "step": 223200
    },
    {
      "epoch": 2.3634111612790534,
      "grad_norm": 0.9773034453392029,
      "learning_rate": 0.0004722567175990723,
      "loss": 0.7946,
      "step": 223250
    },
    {
      "epoch": 2.3639404830590562,
      "grad_norm": 0.9176291823387146,
      "learning_rate": 0.00047223556443605664,
      "loss": 0.8139,
      "step": 223300
    },
    {
      "epoch": 2.3644698048390596,
      "grad_norm": 0.9725921154022217,
      "learning_rate": 0.0004722144036860003,
      "loss": 0.7709,
      "step": 223350
    },
    {
      "epoch": 2.364999126619063,
      "grad_norm": 0.8926225900650024,
      "learning_rate": 0.00047219323534962573,
      "loss": 0.7903,
      "step": 223400
    },
    {
      "epoch": 2.365528448399066,
      "grad_norm": 0.931486964225769,
      "learning_rate": 0.0004721720594276556,
      "loss": 0.771,
      "step": 223450
    },
    {
      "epoch": 2.3660577701790695,
      "grad_norm": 1.0765131711959839,
      "learning_rate": 0.0004721512996652767,
      "loss": 0.7867,
      "step": 223500
    },
    {
      "epoch": 2.3660577701790695,
      "eval_loss": 0.6033870577812195,
      "eval_runtime": 46.7641,
      "eval_samples_per_second": 3591.004,
      "eval_steps_per_second": 448.892,
      "step": 223500
    },
    {
      "epoch": 2.366587091959073,
      "grad_norm": 0.8998130559921265,
      "learning_rate": 0.0004721301087259604,
      "loss": 0.8017,
      "step": 223550
    },
    {
      "epoch": 2.367116413739076,
      "grad_norm": 0.9229530096054077,
      "learning_rate": 0.0004721089102032036,
      "loss": 0.7948,
      "step": 223600
    },
    {
      "epoch": 2.3676457355190794,
      "grad_norm": 0.86317378282547,
      "learning_rate": 0.00047208770409773015,
      "loss": 0.8014,
      "step": 223650
    },
    {
      "epoch": 2.3681750572990827,
      "grad_norm": 1.0079083442687988,
      "learning_rate": 0.0004720664904102638,
      "loss": 0.809,
      "step": 223700
    },
    {
      "epoch": 2.368704379079086,
      "grad_norm": 0.9278551340103149,
      "learning_rate": 0.00047204526914152903,
      "loss": 0.8077,
      "step": 223750
    },
    {
      "epoch": 2.3692337008590894,
      "grad_norm": 0.9508714079856873,
      "learning_rate": 0.0004720240402922502,
      "loss": 0.792,
      "step": 223800
    },
    {
      "epoch": 2.3697630226390927,
      "grad_norm": 0.956152081489563,
      "learning_rate": 0.000472002803863152,
      "loss": 0.7771,
      "step": 223850
    },
    {
      "epoch": 2.370292344419096,
      "grad_norm": 1.0114679336547852,
      "learning_rate": 0.0004719815598549595,
      "loss": 0.7957,
      "step": 223900
    },
    {
      "epoch": 2.3708216661990993,
      "grad_norm": 0.8743845224380493,
      "learning_rate": 0.00047196030826839795,
      "loss": 0.7908,
      "step": 223950
    },
    {
      "epoch": 2.3713509879791026,
      "grad_norm": 0.7926626205444336,
      "learning_rate": 0.00047193904910419293,
      "loss": 0.7707,
      "step": 224000
    },
    {
      "epoch": 2.3713509879791026,
      "eval_loss": 0.6043281555175781,
      "eval_runtime": 46.8415,
      "eval_samples_per_second": 3585.07,
      "eval_steps_per_second": 448.15,
      "step": 224000
    },
    {
      "epoch": 2.3718803097591055,
      "grad_norm": 0.8993619680404663,
      "learning_rate": 0.00047191778236307014,
      "loss": 0.795,
      "step": 224050
    },
    {
      "epoch": 2.3724096315391088,
      "grad_norm": 0.7805770039558411,
      "learning_rate": 0.00047189650804575566,
      "loss": 0.7954,
      "step": 224100
    },
    {
      "epoch": 2.372938953319112,
      "grad_norm": 0.9014633297920227,
      "learning_rate": 0.00047187522615297576,
      "loss": 0.7994,
      "step": 224150
    },
    {
      "epoch": 2.3734682750991154,
      "grad_norm": 0.8178023099899292,
      "learning_rate": 0.00047185393668545695,
      "loss": 0.7925,
      "step": 224200
    },
    {
      "epoch": 2.3739975968791187,
      "grad_norm": 1.0485023260116577,
      "learning_rate": 0.0004718326396439262,
      "loss": 0.7916,
      "step": 224250
    },
    {
      "epoch": 2.374526918659122,
      "grad_norm": 0.9153783321380615,
      "learning_rate": 0.00047181133502911045,
      "loss": 0.7984,
      "step": 224300
    },
    {
      "epoch": 2.3750562404391253,
      "grad_norm": 0.8670676946640015,
      "learning_rate": 0.00047179002284173705,
      "loss": 0.7759,
      "step": 224350
    },
    {
      "epoch": 2.3755855622191286,
      "grad_norm": 0.9524396061897278,
      "learning_rate": 0.0004717687030825336,
      "loss": 0.798,
      "step": 224400
    },
    {
      "epoch": 2.376114883999132,
      "grad_norm": 0.8672022819519043,
      "learning_rate": 0.00047174737575222806,
      "loss": 0.7876,
      "step": 224450
    },
    {
      "epoch": 2.3766442057791353,
      "grad_norm": 0.9217908978462219,
      "learning_rate": 0.00047172604085154833,
      "loss": 0.79,
      "step": 224500
    },
    {
      "epoch": 2.3766442057791353,
      "eval_loss": 0.6027722954750061,
      "eval_runtime": 46.8116,
      "eval_samples_per_second": 3587.362,
      "eval_steps_per_second": 448.436,
      "step": 224500
    },
    {
      "epoch": 2.3771735275591386,
      "grad_norm": 0.90850430727005,
      "learning_rate": 0.0004717046983812229,
      "loss": 0.8031,
      "step": 224550
    },
    {
      "epoch": 2.377702849339142,
      "grad_norm": 0.7510606050491333,
      "learning_rate": 0.00047168334834198035,
      "loss": 0.7778,
      "step": 224600
    },
    {
      "epoch": 2.378232171119145,
      "grad_norm": 0.929782509803772,
      "learning_rate": 0.00047166199073454964,
      "loss": 0.7937,
      "step": 224650
    },
    {
      "epoch": 2.3787614928991485,
      "grad_norm": 0.8959710001945496,
      "learning_rate": 0.00047164062555965985,
      "loss": 0.8004,
      "step": 224700
    },
    {
      "epoch": 2.379290814679152,
      "grad_norm": 0.9034547805786133,
      "learning_rate": 0.00047161925281804043,
      "loss": 0.7818,
      "step": 224750
    },
    {
      "epoch": 2.3798201364591547,
      "grad_norm": 0.9917256236076355,
      "learning_rate": 0.00047159787251042093,
      "loss": 0.7908,
      "step": 224800
    },
    {
      "epoch": 2.380349458239158,
      "grad_norm": 0.9034386873245239,
      "learning_rate": 0.00047157648463753136,
      "loss": 0.8016,
      "step": 224850
    },
    {
      "epoch": 2.3808787800191613,
      "grad_norm": 0.9798728227615356,
      "learning_rate": 0.0004715550892001018,
      "loss": 0.8068,
      "step": 224900
    },
    {
      "epoch": 2.3814081017991646,
      "grad_norm": 0.8848959803581238,
      "learning_rate": 0.0004715336861988628,
      "loss": 0.7776,
      "step": 224950
    },
    {
      "epoch": 2.381937423579168,
      "grad_norm": 0.9110778570175171,
      "learning_rate": 0.000471512275634545,
      "loss": 0.7847,
      "step": 225000
    },
    {
      "epoch": 2.381937423579168,
      "eval_loss": 0.6005199551582336,
      "eval_runtime": 46.8085,
      "eval_samples_per_second": 3587.594,
      "eval_steps_per_second": 448.465,
      "step": 225000
    },
    {
      "epoch": 2.3824667453591712,
      "grad_norm": 0.940885066986084,
      "learning_rate": 0.00047149085750787935,
      "loss": 0.7894,
      "step": 225050
    },
    {
      "epoch": 2.3829960671391746,
      "grad_norm": 0.8674424886703491,
      "learning_rate": 0.00047146943181959703,
      "loss": 0.7894,
      "step": 225100
    },
    {
      "epoch": 2.383525388919178,
      "grad_norm": 0.9231784343719482,
      "learning_rate": 0.0004714479985704295,
      "loss": 0.8008,
      "step": 225150
    },
    {
      "epoch": 2.384054710699181,
      "grad_norm": 1.031890869140625,
      "learning_rate": 0.00047142655776110867,
      "loss": 0.7991,
      "step": 225200
    },
    {
      "epoch": 2.3845840324791845,
      "grad_norm": 0.8043060302734375,
      "learning_rate": 0.0004714051093923662,
      "loss": 0.7803,
      "step": 225250
    },
    {
      "epoch": 2.385113354259188,
      "grad_norm": 1.0069602727890015,
      "learning_rate": 0.0004713836534649346,
      "loss": 0.7938,
      "step": 225300
    },
    {
      "epoch": 2.385642676039191,
      "grad_norm": 1.0241382122039795,
      "learning_rate": 0.00047136218997954616,
      "loss": 0.7943,
      "step": 225350
    },
    {
      "epoch": 2.3861719978191944,
      "grad_norm": 0.8591536283493042,
      "learning_rate": 0.00047134071893693375,
      "loss": 0.8059,
      "step": 225400
    },
    {
      "epoch": 2.3867013195991977,
      "grad_norm": 0.9544144868850708,
      "learning_rate": 0.00047131924033783047,
      "loss": 0.7883,
      "step": 225450
    },
    {
      "epoch": 2.387230641379201,
      "grad_norm": 0.8031305074691772,
      "learning_rate": 0.0004712977541829694,
      "loss": 0.7898,
      "step": 225500
    },
    {
      "epoch": 2.387230641379201,
      "eval_loss": 0.6034693121910095,
      "eval_runtime": 46.7126,
      "eval_samples_per_second": 3594.964,
      "eval_steps_per_second": 449.387,
      "step": 225500
    },
    {
      "epoch": 2.387759963159204,
      "grad_norm": 0.9215275049209595,
      "learning_rate": 0.0004712766904213164,
      "loss": 0.7966,
      "step": 225550
    },
    {
      "epoch": 2.3882892849392072,
      "grad_norm": 0.920866847038269,
      "learning_rate": 0.0004712551893082194,
      "loss": 0.7873,
      "step": 225600
    },
    {
      "epoch": 2.3888186067192105,
      "grad_norm": 0.9393987059593201,
      "learning_rate": 0.00047123368064155136,
      "loss": 0.8013,
      "step": 225650
    },
    {
      "epoch": 2.389347928499214,
      "grad_norm": 0.8452086448669434,
      "learning_rate": 0.00047121216442204666,
      "loss": 0.7922,
      "step": 225700
    },
    {
      "epoch": 2.389877250279217,
      "grad_norm": 0.960929811000824,
      "learning_rate": 0.00047119064065043984,
      "loss": 0.7939,
      "step": 225750
    },
    {
      "epoch": 2.3904065720592205,
      "grad_norm": 0.8706188797950745,
      "learning_rate": 0.00047116910932746555,
      "loss": 0.7927,
      "step": 225800
    },
    {
      "epoch": 2.390935893839224,
      "grad_norm": 0.9060139656066895,
      "learning_rate": 0.00047114757045385906,
      "loss": 0.7874,
      "step": 225850
    },
    {
      "epoch": 2.391465215619227,
      "grad_norm": 0.8694563508033752,
      "learning_rate": 0.00047112602403035555,
      "loss": 0.8055,
      "step": 225900
    },
    {
      "epoch": 2.3919945373992304,
      "grad_norm": 0.9277560114860535,
      "learning_rate": 0.00047110447005769076,
      "loss": 0.7905,
      "step": 225950
    },
    {
      "epoch": 2.3925238591792337,
      "grad_norm": 0.9125356674194336,
      "learning_rate": 0.00047108290853660034,
      "loss": 0.7796,
      "step": 226000
    },
    {
      "epoch": 2.3925238591792337,
      "eval_loss": 0.6011802554130554,
      "eval_runtime": 46.8184,
      "eval_samples_per_second": 3586.839,
      "eval_steps_per_second": 448.371,
      "step": 226000
    },
    {
      "epoch": 2.393053180959237,
      "grad_norm": 0.8722221255302429,
      "learning_rate": 0.0004710613394678206,
      "loss": 0.789,
      "step": 226050
    },
    {
      "epoch": 2.3935825027392403,
      "grad_norm": 0.9528512358665466,
      "learning_rate": 0.00047103976285208773,
      "loss": 0.7901,
      "step": 226100
    },
    {
      "epoch": 2.3941118245192436,
      "grad_norm": 0.992669403553009,
      "learning_rate": 0.00047101817869013845,
      "loss": 0.7786,
      "step": 226150
    },
    {
      "epoch": 2.394641146299247,
      "grad_norm": 1.021670937538147,
      "learning_rate": 0.0004709965869827096,
      "loss": 0.7854,
      "step": 226200
    },
    {
      "epoch": 2.3951704680792503,
      "grad_norm": 0.8614935874938965,
      "learning_rate": 0.0004709749877305384,
      "loss": 0.7833,
      "step": 226250
    },
    {
      "epoch": 2.395699789859253,
      "grad_norm": 0.990299642086029,
      "learning_rate": 0.00047095338093436205,
      "loss": 0.7914,
      "step": 226300
    },
    {
      "epoch": 2.3962291116392564,
      "grad_norm": 0.8891026973724365,
      "learning_rate": 0.0004709317665949183,
      "loss": 0.7729,
      "step": 226350
    },
    {
      "epoch": 2.3967584334192598,
      "grad_norm": 0.8444347977638245,
      "learning_rate": 0.00047091014471294513,
      "loss": 0.7773,
      "step": 226400
    },
    {
      "epoch": 2.397287755199263,
      "grad_norm": 0.8462802767753601,
      "learning_rate": 0.00047088851528918066,
      "loss": 0.7965,
      "step": 226450
    },
    {
      "epoch": 2.3978170769792664,
      "grad_norm": 0.9018811583518982,
      "learning_rate": 0.00047086687832436323,
      "loss": 0.7969,
      "step": 226500
    },
    {
      "epoch": 2.3978170769792664,
      "eval_loss": 0.6001925468444824,
      "eval_runtime": 46.7829,
      "eval_samples_per_second": 3589.556,
      "eval_steps_per_second": 448.711,
      "step": 226500
    },
    {
      "epoch": 2.3983463987592697,
      "grad_norm": 0.8744211196899414,
      "learning_rate": 0.0004708452338192316,
      "loss": 0.781,
      "step": 226550
    },
    {
      "epoch": 2.398875720539273,
      "grad_norm": 0.8873500227928162,
      "learning_rate": 0.00047082358177452465,
      "loss": 0.7834,
      "step": 226600
    },
    {
      "epoch": 2.3994050423192763,
      "grad_norm": 0.9575974345207214,
      "learning_rate": 0.00047080192219098164,
      "loss": 0.786,
      "step": 226650
    },
    {
      "epoch": 2.3999343640992796,
      "grad_norm": 0.8181800842285156,
      "learning_rate": 0.00047078025506934197,
      "loss": 0.7892,
      "step": 226700
    },
    {
      "epoch": 2.400463685879283,
      "grad_norm": 0.894051194190979,
      "learning_rate": 0.0004707585804103454,
      "loss": 0.7758,
      "step": 226750
    },
    {
      "epoch": 2.4009930076592862,
      "grad_norm": 0.8487194180488586,
      "learning_rate": 0.00047073689821473173,
      "loss": 0.7844,
      "step": 226800
    },
    {
      "epoch": 2.4015223294392896,
      "grad_norm": 0.9240298271179199,
      "learning_rate": 0.0004707152084832414,
      "loss": 0.7816,
      "step": 226850
    },
    {
      "epoch": 2.402051651219293,
      "grad_norm": 0.793418824672699,
      "learning_rate": 0.0004706935112166148,
      "loss": 0.7794,
      "step": 226900
    },
    {
      "epoch": 2.402580972999296,
      "grad_norm": 0.9191033244132996,
      "learning_rate": 0.00047067180641559265,
      "loss": 0.7807,
      "step": 226950
    },
    {
      "epoch": 2.4031102947792995,
      "grad_norm": 0.8166018724441528,
      "learning_rate": 0.000470650094080916,
      "loss": 0.8063,
      "step": 227000
    },
    {
      "epoch": 2.4031102947792995,
      "eval_loss": 0.598471999168396,
      "eval_runtime": 46.8846,
      "eval_samples_per_second": 3581.776,
      "eval_steps_per_second": 447.738,
      "step": 227000
    },
    {
      "epoch": 2.4036396165593024,
      "grad_norm": 0.8592450618743896,
      "learning_rate": 0.0004706283742133259,
      "loss": 0.7997,
      "step": 227050
    },
    {
      "epoch": 2.4041689383393057,
      "grad_norm": 0.8605660796165466,
      "learning_rate": 0.0004706066468135642,
      "loss": 0.7817,
      "step": 227100
    },
    {
      "epoch": 2.404698260119309,
      "grad_norm": 0.8941078782081604,
      "learning_rate": 0.0004705849118823724,
      "loss": 0.7953,
      "step": 227150
    },
    {
      "epoch": 2.4052275818993123,
      "grad_norm": 0.8856669068336487,
      "learning_rate": 0.0004705631694204926,
      "loss": 0.781,
      "step": 227200
    },
    {
      "epoch": 2.4057569036793156,
      "grad_norm": 0.917331874370575,
      "learning_rate": 0.00047054141942866714,
      "loss": 0.7753,
      "step": 227250
    },
    {
      "epoch": 2.406286225459319,
      "grad_norm": 0.8094035983085632,
      "learning_rate": 0.00047051966190763853,
      "loss": 0.7889,
      "step": 227300
    },
    {
      "epoch": 2.4068155472393222,
      "grad_norm": 0.8424936532974243,
      "learning_rate": 0.00047049789685814944,
      "loss": 0.7951,
      "step": 227350
    },
    {
      "epoch": 2.4073448690193255,
      "grad_norm": 0.9274370670318604,
      "learning_rate": 0.000470476124280943,
      "loss": 0.7795,
      "step": 227400
    },
    {
      "epoch": 2.407874190799329,
      "grad_norm": 0.8425066471099854,
      "learning_rate": 0.0004704543441767626,
      "loss": 0.7791,
      "step": 227450
    },
    {
      "epoch": 2.408403512579332,
      "grad_norm": 1.0022549629211426,
      "learning_rate": 0.00047043255654635177,
      "loss": 0.7807,
      "step": 227500
    },
    {
      "epoch": 2.408403512579332,
      "eval_loss": 0.6012776494026184,
      "eval_runtime": 46.6932,
      "eval_samples_per_second": 3596.452,
      "eval_steps_per_second": 449.573,
      "step": 227500
    },
    {
      "epoch": 2.4089328343593355,
      "grad_norm": 0.9498032927513123,
      "learning_rate": 0.00047041119736731716,
      "loss": 0.7986,
      "step": 227550
    },
    {
      "epoch": 2.409462156139339,
      "grad_norm": 0.8767170906066895,
      "learning_rate": 0.0004703893948371646,
      "loss": 0.791,
      "step": 227600
    },
    {
      "epoch": 2.409991477919342,
      "grad_norm": 0.9499720335006714,
      "learning_rate": 0.000470367584782999,
      "loss": 0.7946,
      "step": 227650
    },
    {
      "epoch": 2.4105207996993454,
      "grad_norm": 0.8336271643638611,
      "learning_rate": 0.0004703457672055648,
      "loss": 0.7811,
      "step": 227700
    },
    {
      "epoch": 2.4110501214793487,
      "grad_norm": 0.8678798675537109,
      "learning_rate": 0.00047032394210560704,
      "loss": 0.7926,
      "step": 227750
    },
    {
      "epoch": 2.4115794432593516,
      "grad_norm": 0.935004472732544,
      "learning_rate": 0.00047030210948387056,
      "loss": 0.784,
      "step": 227800
    },
    {
      "epoch": 2.412108765039355,
      "grad_norm": 0.9151350259780884,
      "learning_rate": 0.0004702802693411009,
      "loss": 0.7768,
      "step": 227850
    },
    {
      "epoch": 2.412638086819358,
      "grad_norm": 0.949463427066803,
      "learning_rate": 0.00047025842167804365,
      "loss": 0.7886,
      "step": 227900
    },
    {
      "epoch": 2.4131674085993615,
      "grad_norm": 0.8971259593963623,
      "learning_rate": 0.00047023656649544464,
      "loss": 0.7805,
      "step": 227950
    },
    {
      "epoch": 2.413696730379365,
      "grad_norm": 0.9274460673332214,
      "learning_rate": 0.00047021470379405005,
      "loss": 0.7918,
      "step": 228000
    },
    {
      "epoch": 2.413696730379365,
      "eval_loss": 0.6001725792884827,
      "eval_runtime": 46.7864,
      "eval_samples_per_second": 3589.288,
      "eval_steps_per_second": 448.677,
      "step": 228000
    },
    {
      "epoch": 2.414226052159368,
      "grad_norm": 0.8759511709213257,
      "learning_rate": 0.00047019283357460623,
      "loss": 0.7875,
      "step": 228050
    },
    {
      "epoch": 2.4147553739393715,
      "grad_norm": 0.9226122498512268,
      "learning_rate": 0.0004701709558378598,
      "loss": 0.7817,
      "step": 228100
    },
    {
      "epoch": 2.4152846957193748,
      "grad_norm": 0.9142709374427795,
      "learning_rate": 0.0004701490705845577,
      "loss": 0.7943,
      "step": 228150
    },
    {
      "epoch": 2.415814017499378,
      "grad_norm": 0.8942803144454956,
      "learning_rate": 0.00047012717781544713,
      "loss": 0.7922,
      "step": 228200
    },
    {
      "epoch": 2.4163433392793814,
      "grad_norm": 0.8758383989334106,
      "learning_rate": 0.0004701052775312753,
      "loss": 0.7878,
      "step": 228250
    },
    {
      "epoch": 2.4168726610593847,
      "grad_norm": 0.9165672659873962,
      "learning_rate": 0.0004700833697327901,
      "loss": 0.811,
      "step": 228300
    },
    {
      "epoch": 2.417401982839388,
      "grad_norm": 0.8824561834335327,
      "learning_rate": 0.0004700614544207394,
      "loss": 0.7891,
      "step": 228350
    },
    {
      "epoch": 2.4179313046193913,
      "grad_norm": 0.864627480506897,
      "learning_rate": 0.00047003953159587133,
      "loss": 0.7902,
      "step": 228400
    },
    {
      "epoch": 2.4184606263993946,
      "grad_norm": 0.9239266514778137,
      "learning_rate": 0.0004700176012589343,
      "loss": 0.7921,
      "step": 228450
    },
    {
      "epoch": 2.418989948179398,
      "grad_norm": 0.945970892906189,
      "learning_rate": 0.00046999566341067705,
      "loss": 0.7878,
      "step": 228500
    },
    {
      "epoch": 2.418989948179398,
      "eval_loss": 0.5962238907814026,
      "eval_runtime": 46.8261,
      "eval_samples_per_second": 3586.245,
      "eval_steps_per_second": 448.297,
      "step": 228500
    },
    {
      "epoch": 2.419519269959401,
      "grad_norm": 0.8589385151863098,
      "learning_rate": 0.00046997371805184855,
      "loss": 0.7853,
      "step": 228550
    },
    {
      "epoch": 2.420048591739404,
      "grad_norm": 0.9157503247261047,
      "learning_rate": 0.000469951765183198,
      "loss": 0.7986,
      "step": 228600
    },
    {
      "epoch": 2.4205779135194074,
      "grad_norm": 0.8459895253181458,
      "learning_rate": 0.0004699298048054749,
      "loss": 0.786,
      "step": 228650
    },
    {
      "epoch": 2.4211072352994107,
      "grad_norm": 0.9028716683387756,
      "learning_rate": 0.0004699078369194288,
      "loss": 0.7946,
      "step": 228700
    },
    {
      "epoch": 2.421636557079414,
      "grad_norm": 0.9678755402565002,
      "learning_rate": 0.0004698858615258099,
      "loss": 0.7907,
      "step": 228750
    },
    {
      "epoch": 2.4221658788594174,
      "grad_norm": 0.7982744574546814,
      "learning_rate": 0.0004698638786253683,
      "loss": 0.7828,
      "step": 228800
    },
    {
      "epoch": 2.4226952006394207,
      "grad_norm": 0.8951895833015442,
      "learning_rate": 0.00046984188821885456,
      "loss": 0.7804,
      "step": 228850
    },
    {
      "epoch": 2.423224522419424,
      "grad_norm": 0.9601086378097534,
      "learning_rate": 0.0004698198903070193,
      "loss": 0.7993,
      "step": 228900
    },
    {
      "epoch": 2.4237538441994273,
      "grad_norm": 0.9238774180412292,
      "learning_rate": 0.0004697978848906137,
      "loss": 0.786,
      "step": 228950
    },
    {
      "epoch": 2.4242831659794306,
      "grad_norm": 1.0281202793121338,
      "learning_rate": 0.00046977587197038887,
      "loss": 0.7861,
      "step": 229000
    },
    {
      "epoch": 2.4242831659794306,
      "eval_loss": 0.5958385467529297,
      "eval_runtime": 46.8622,
      "eval_samples_per_second": 3583.486,
      "eval_steps_per_second": 447.952,
      "step": 229000
    },
    {
      "epoch": 2.424812487759434,
      "grad_norm": 0.9459568858146667,
      "learning_rate": 0.00046975385154709635,
      "loss": 0.7867,
      "step": 229050
    },
    {
      "epoch": 2.4253418095394372,
      "grad_norm": 0.8631563186645508,
      "learning_rate": 0.00046973182362148794,
      "loss": 0.7842,
      "step": 229100
    },
    {
      "epoch": 2.4258711313194405,
      "grad_norm": 0.8496306538581848,
      "learning_rate": 0.00046970978819431565,
      "loss": 0.7732,
      "step": 229150
    },
    {
      "epoch": 2.426400453099444,
      "grad_norm": 0.8290314078330994,
      "learning_rate": 0.0004696877452663317,
      "loss": 0.7889,
      "step": 229200
    },
    {
      "epoch": 2.426929774879447,
      "grad_norm": 0.8939858078956604,
      "learning_rate": 0.0004696656948382888,
      "loss": 0.7794,
      "step": 229250
    },
    {
      "epoch": 2.42745909665945,
      "grad_norm": 0.9308485984802246,
      "learning_rate": 0.0004696436369109396,
      "loss": 0.7895,
      "step": 229300
    },
    {
      "epoch": 2.4279884184394533,
      "grad_norm": 0.926703929901123,
      "learning_rate": 0.0004696215714850372,
      "loss": 0.7779,
      "step": 229350
    },
    {
      "epoch": 2.4285177402194567,
      "grad_norm": 0.877353310585022,
      "learning_rate": 0.00046959949856133486,
      "loss": 0.7877,
      "step": 229400
    },
    {
      "epoch": 2.42904706199946,
      "grad_norm": 0.9999551177024841,
      "learning_rate": 0.0004695774181405862,
      "loss": 0.7877,
      "step": 229450
    },
    {
      "epoch": 2.4295763837794633,
      "grad_norm": 0.8639994859695435,
      "learning_rate": 0.0004695553302235451,
      "loss": 0.7842,
      "step": 229500
    },
    {
      "epoch": 2.4295763837794633,
      "eval_loss": 0.5959863662719727,
      "eval_runtime": 46.7687,
      "eval_samples_per_second": 3590.649,
      "eval_steps_per_second": 448.847,
      "step": 229500
    },
    {
      "epoch": 2.4301057055594666,
      "grad_norm": 0.8891416788101196,
      "learning_rate": 0.00046953323481096544,
      "loss": 0.7841,
      "step": 229550
    },
    {
      "epoch": 2.43063502733947,
      "grad_norm": 0.8087998628616333,
      "learning_rate": 0.00046951157403519295,
      "loss": 0.7819,
      "step": 229600
    },
    {
      "epoch": 2.431164349119473,
      "grad_norm": 0.9526116251945496,
      "learning_rate": 0.00046948946378367283,
      "loss": 0.7813,
      "step": 229650
    },
    {
      "epoch": 2.4316936708994765,
      "grad_norm": 0.9842097163200378,
      "learning_rate": 0.0004694673460388629,
      "loss": 0.7821,
      "step": 229700
    },
    {
      "epoch": 2.43222299267948,
      "grad_norm": 0.8637698292732239,
      "learning_rate": 0.0004694452208015183,
      "loss": 0.7849,
      "step": 229750
    },
    {
      "epoch": 2.432752314459483,
      "grad_norm": 0.9137561321258545,
      "learning_rate": 0.00046942308807239433,
      "loss": 0.7975,
      "step": 229800
    },
    {
      "epoch": 2.4332816362394865,
      "grad_norm": 1.0288830995559692,
      "learning_rate": 0.00046940094785224664,
      "loss": 0.7953,
      "step": 229850
    },
    {
      "epoch": 2.4338109580194898,
      "grad_norm": 0.9261361956596375,
      "learning_rate": 0.000469378800141831,
      "loss": 0.7982,
      "step": 229900
    },
    {
      "epoch": 2.434340279799493,
      "grad_norm": 0.8631402254104614,
      "learning_rate": 0.0004693566449419036,
      "loss": 0.7773,
      "step": 229950
    },
    {
      "epoch": 2.4348696015794964,
      "grad_norm": 0.8676074743270874,
      "learning_rate": 0.0004693344822532207,
      "loss": 0.78,
      "step": 230000
    },
    {
      "epoch": 2.4348696015794964,
      "eval_loss": 0.5968169569969177,
      "eval_runtime": 46.8543,
      "eval_samples_per_second": 3584.089,
      "eval_steps_per_second": 448.027,
      "step": 230000
    },
    {
      "epoch": 2.4353989233594993,
      "grad_norm": 0.8852081298828125,
      "learning_rate": 0.00046931231207653914,
      "loss": 0.7912,
      "step": 230050
    },
    {
      "epoch": 2.4359282451395026,
      "grad_norm": 0.9224011301994324,
      "learning_rate": 0.00046929013441261567,
      "loss": 0.7813,
      "step": 230100
    },
    {
      "epoch": 2.436457566919506,
      "grad_norm": 0.8417444825172424,
      "learning_rate": 0.0004692679492622074,
      "loss": 0.7888,
      "step": 230150
    },
    {
      "epoch": 2.436986888699509,
      "grad_norm": 0.9668108224868774,
      "learning_rate": 0.0004692457566260717,
      "loss": 0.7892,
      "step": 230200
    },
    {
      "epoch": 2.4375162104795125,
      "grad_norm": 0.8609145283699036,
      "learning_rate": 0.00046922355650496635,
      "loss": 0.7835,
      "step": 230250
    },
    {
      "epoch": 2.438045532259516,
      "grad_norm": 1.0093594789505005,
      "learning_rate": 0.00046920134889964917,
      "loss": 0.7973,
      "step": 230300
    },
    {
      "epoch": 2.438574854039519,
      "grad_norm": 0.916583776473999,
      "learning_rate": 0.0004691791338108783,
      "loss": 0.7889,
      "step": 230350
    },
    {
      "epoch": 2.4391041758195224,
      "grad_norm": 0.8183906674385071,
      "learning_rate": 0.0004691569112394122,
      "loss": 0.7989,
      "step": 230400
    },
    {
      "epoch": 2.4396334975995257,
      "grad_norm": 0.8942133784294128,
      "learning_rate": 0.0004691346811860096,
      "loss": 0.8093,
      "step": 230450
    },
    {
      "epoch": 2.440162819379529,
      "grad_norm": 0.9610601663589478,
      "learning_rate": 0.00046911244365142917,
      "loss": 0.782,
      "step": 230500
    },
    {
      "epoch": 2.440162819379529,
      "eval_loss": 0.5967567563056946,
      "eval_runtime": 46.7616,
      "eval_samples_per_second": 3591.198,
      "eval_steps_per_second": 448.916,
      "step": 230500
    },
    {
      "epoch": 2.4406921411595324,
      "grad_norm": 0.8856902122497559,
      "learning_rate": 0.00046909019863643035,
      "loss": 0.7734,
      "step": 230550
    },
    {
      "epoch": 2.4412214629395357,
      "grad_norm": 0.9790846705436707,
      "learning_rate": 0.0004690679461417725,
      "loss": 0.7964,
      "step": 230600
    },
    {
      "epoch": 2.441750784719539,
      "grad_norm": 0.9231495261192322,
      "learning_rate": 0.00046904568616821537,
      "loss": 0.7787,
      "step": 230650
    },
    {
      "epoch": 2.4422801064995423,
      "grad_norm": 0.8846719264984131,
      "learning_rate": 0.00046902341871651876,
      "loss": 0.808,
      "step": 230700
    },
    {
      "epoch": 2.4428094282795456,
      "grad_norm": 0.8394474387168884,
      "learning_rate": 0.0004690011437874431,
      "loss": 0.789,
      "step": 230750
    },
    {
      "epoch": 2.4433387500595485,
      "grad_norm": 0.9309812784194946,
      "learning_rate": 0.00046897886138174853,
      "loss": 0.7823,
      "step": 230800
    },
    {
      "epoch": 2.443868071839552,
      "grad_norm": 0.9287012815475464,
      "learning_rate": 0.00046895657150019604,
      "loss": 0.7867,
      "step": 230850
    },
    {
      "epoch": 2.444397393619555,
      "grad_norm": 0.877450704574585,
      "learning_rate": 0.0004689342741435465,
      "loss": 0.7968,
      "step": 230900
    },
    {
      "epoch": 2.4449267153995584,
      "grad_norm": 0.9197292327880859,
      "learning_rate": 0.00046891196931256107,
      "loss": 0.7834,
      "step": 230950
    },
    {
      "epoch": 2.4454560371795617,
      "grad_norm": 0.9673423767089844,
      "learning_rate": 0.00046888965700800134,
      "loss": 0.7906,
      "step": 231000
    },
    {
      "epoch": 2.4454560371795617,
      "eval_loss": 0.5948219895362854,
      "eval_runtime": 46.8692,
      "eval_samples_per_second": 3582.948,
      "eval_steps_per_second": 447.884,
      "step": 231000
    },
    {
      "epoch": 2.445985358959565,
      "grad_norm": 0.8748868703842163,
      "learning_rate": 0.00046886733723062904,
      "loss": 0.7925,
      "step": 231050
    },
    {
      "epoch": 2.4465146807395683,
      "grad_norm": 0.9342154860496521,
      "learning_rate": 0.00046884500998120603,
      "loss": 0.7887,
      "step": 231100
    },
    {
      "epoch": 2.4470440025195717,
      "grad_norm": 0.9094802737236023,
      "learning_rate": 0.0004688226752604947,
      "loss": 0.7847,
      "step": 231150
    },
    {
      "epoch": 2.447573324299575,
      "grad_norm": 0.926011323928833,
      "learning_rate": 0.00046880033306925746,
      "loss": 0.7933,
      "step": 231200
    },
    {
      "epoch": 2.4481026460795783,
      "grad_norm": 0.9223727583885193,
      "learning_rate": 0.0004687779834082571,
      "loss": 0.787,
      "step": 231250
    },
    {
      "epoch": 2.4486319678595816,
      "grad_norm": 0.8752749562263489,
      "learning_rate": 0.00046875562627825664,
      "loss": 0.7854,
      "step": 231300
    },
    {
      "epoch": 2.449161289639585,
      "grad_norm": 0.865899920463562,
      "learning_rate": 0.0004687332616800193,
      "loss": 0.7808,
      "step": 231350
    },
    {
      "epoch": 2.449690611419588,
      "grad_norm": 0.8857828974723816,
      "learning_rate": 0.0004687108896143086,
      "loss": 0.7763,
      "step": 231400
    },
    {
      "epoch": 2.4502199331995915,
      "grad_norm": 0.8805017471313477,
      "learning_rate": 0.00046868851008188833,
      "loss": 0.7877,
      "step": 231450
    },
    {
      "epoch": 2.450749254979595,
      "grad_norm": 0.9247006773948669,
      "learning_rate": 0.00046866612308352256,
      "loss": 0.7815,
      "step": 231500
    },
    {
      "epoch": 2.450749254979595,
      "eval_loss": 0.5954575538635254,
      "eval_runtime": 46.8294,
      "eval_samples_per_second": 3585.997,
      "eval_steps_per_second": 448.266,
      "step": 231500
    },
    {
      "epoch": 2.4512785767595977,
      "grad_norm": 0.8983752727508545,
      "learning_rate": 0.0004686437286199756,
      "loss": 0.7758,
      "step": 231550
    },
    {
      "epoch": 2.451807898539601,
      "grad_norm": 0.9205979704856873,
      "learning_rate": 0.00046862132669201183,
      "loss": 0.7758,
      "step": 231600
    },
    {
      "epoch": 2.4523372203196043,
      "grad_norm": 1.0214927196502686,
      "learning_rate": 0.0004685993655613674,
      "loss": 0.8055,
      "step": 231650
    },
    {
      "epoch": 2.4528665420996076,
      "grad_norm": 0.8359851241111755,
      "learning_rate": 0.0004685769488561151,
      "loss": 0.7868,
      "step": 231700
    },
    {
      "epoch": 2.453395863879611,
      "grad_norm": 0.9823356866836548,
      "learning_rate": 0.00046855452468872594,
      "loss": 0.7946,
      "step": 231750
    },
    {
      "epoch": 2.4539251856596143,
      "grad_norm": 0.8398945927619934,
      "learning_rate": 0.00046853209305996546,
      "loss": 0.7778,
      "step": 231800
    },
    {
      "epoch": 2.4544545074396176,
      "grad_norm": 0.9623323082923889,
      "learning_rate": 0.00046850965397059944,
      "loss": 0.7873,
      "step": 231850
    },
    {
      "epoch": 2.454983829219621,
      "grad_norm": 0.9442442059516907,
      "learning_rate": 0.00046848720742139404,
      "loss": 0.7837,
      "step": 231900
    },
    {
      "epoch": 2.455513150999624,
      "grad_norm": 0.8658567070960999,
      "learning_rate": 0.00046846475341311546,
      "loss": 0.7949,
      "step": 231950
    },
    {
      "epoch": 2.4560424727796275,
      "grad_norm": 0.7944162487983704,
      "learning_rate": 0.0004684422919465304,
      "loss": 0.7858,
      "step": 232000
    },
    {
      "epoch": 2.4560424727796275,
      "eval_loss": 0.5944097638130188,
      "eval_runtime": 46.8616,
      "eval_samples_per_second": 3583.533,
      "eval_steps_per_second": 447.958,
      "step": 232000
    },
    {
      "epoch": 2.456571794559631,
      "grad_norm": 0.9077028036117554,
      "learning_rate": 0.00046841982302240546,
      "loss": 0.795,
      "step": 232050
    },
    {
      "epoch": 2.457101116339634,
      "grad_norm": 0.8918553590774536,
      "learning_rate": 0.00046839734664150804,
      "loss": 0.7867,
      "step": 232100
    },
    {
      "epoch": 2.4576304381196374,
      "grad_norm": 0.8575214743614197,
      "learning_rate": 0.0004683748628046052,
      "loss": 0.789,
      "step": 232150
    },
    {
      "epoch": 2.4581597598996408,
      "grad_norm": 0.9218063354492188,
      "learning_rate": 0.00046835237151246457,
      "loss": 0.7822,
      "step": 232200
    },
    {
      "epoch": 2.458689081679644,
      "grad_norm": 0.9133501648902893,
      "learning_rate": 0.00046832987276585413,
      "loss": 0.7644,
      "step": 232250
    },
    {
      "epoch": 2.459218403459647,
      "grad_norm": 0.9911307692527771,
      "learning_rate": 0.0004683073665655419,
      "loss": 0.7768,
      "step": 232300
    },
    {
      "epoch": 2.4597477252396507,
      "grad_norm": 0.9685964584350586,
      "learning_rate": 0.0004682848529122962,
      "loss": 0.7758,
      "step": 232350
    },
    {
      "epoch": 2.4602770470196536,
      "grad_norm": 0.9604349732398987,
      "learning_rate": 0.00046826233180688573,
      "loss": 0.7892,
      "step": 232400
    },
    {
      "epoch": 2.460806368799657,
      "grad_norm": 0.9238482713699341,
      "learning_rate": 0.0004682398032500793,
      "loss": 0.7877,
      "step": 232450
    },
    {
      "epoch": 2.46133569057966,
      "grad_norm": 0.9804748296737671,
      "learning_rate": 0.00046821726724264603,
      "loss": 0.7824,
      "step": 232500
    },
    {
      "epoch": 2.46133569057966,
      "eval_loss": 0.5963785648345947,
      "eval_runtime": 46.7914,
      "eval_samples_per_second": 3588.909,
      "eval_steps_per_second": 448.63,
      "step": 232500
    },
    {
      "epoch": 2.4618650123596635,
      "grad_norm": 1.0643659830093384,
      "learning_rate": 0.00046819472378535523,
      "loss": 0.8061,
      "step": 232550
    },
    {
      "epoch": 2.462394334139667,
      "grad_norm": 0.8170474767684937,
      "learning_rate": 0.00046817217287897664,
      "loss": 0.7781,
      "step": 232600
    },
    {
      "epoch": 2.46292365591967,
      "grad_norm": 0.9781174063682556,
      "learning_rate": 0.00046814961452427994,
      "loss": 0.7736,
      "step": 232650
    },
    {
      "epoch": 2.4634529776996734,
      "grad_norm": 1.0139011144638062,
      "learning_rate": 0.00046812704872203556,
      "loss": 0.7697,
      "step": 232700
    },
    {
      "epoch": 2.4639822994796767,
      "grad_norm": 0.9901769757270813,
      "learning_rate": 0.00046810447547301367,
      "loss": 0.7839,
      "step": 232750
    },
    {
      "epoch": 2.46451162125968,
      "grad_norm": 0.8854855895042419,
      "learning_rate": 0.000468081894777985,
      "loss": 0.7922,
      "step": 232800
    },
    {
      "epoch": 2.4650409430396834,
      "grad_norm": 0.8375742435455322,
      "learning_rate": 0.00046805930663772037,
      "loss": 0.787,
      "step": 232850
    },
    {
      "epoch": 2.4655702648196867,
      "grad_norm": 0.9467391967773438,
      "learning_rate": 0.0004680367110529911,
      "loss": 0.7716,
      "step": 232900
    },
    {
      "epoch": 2.46609958659969,
      "grad_norm": 0.9058461785316467,
      "learning_rate": 0.00046801410802456834,
      "loss": 0.7853,
      "step": 232950
    },
    {
      "epoch": 2.4666289083796933,
      "grad_norm": 0.9301018714904785,
      "learning_rate": 0.00046799149755322395,
      "loss": 0.7836,
      "step": 233000
    },
    {
      "epoch": 2.4666289083796933,
      "eval_loss": 0.5933797359466553,
      "eval_runtime": 46.7303,
      "eval_samples_per_second": 3593.6,
      "eval_steps_per_second": 449.216,
      "step": 233000
    },
    {
      "epoch": 2.467158230159696,
      "grad_norm": 0.8642438650131226,
      "learning_rate": 0.0004679688796397298,
      "loss": 0.7794,
      "step": 233050
    },
    {
      "epoch": 2.4676875519397,
      "grad_norm": 0.8903690576553345,
      "learning_rate": 0.000467946254284858,
      "loss": 0.7826,
      "step": 233100
    },
    {
      "epoch": 2.4682168737197028,
      "grad_norm": 0.9148862957954407,
      "learning_rate": 0.000467923621489381,
      "loss": 0.7792,
      "step": 233150
    },
    {
      "epoch": 2.468746195499706,
      "grad_norm": 0.9251586198806763,
      "learning_rate": 0.0004679009812540715,
      "loss": 0.7798,
      "step": 233200
    },
    {
      "epoch": 2.4692755172797094,
      "grad_norm": 0.9368115067481995,
      "learning_rate": 0.00046787833357970246,
      "loss": 0.7945,
      "step": 233250
    },
    {
      "epoch": 2.4698048390597127,
      "grad_norm": 0.9653710126876831,
      "learning_rate": 0.0004678556784670469,
      "loss": 0.784,
      "step": 233300
    },
    {
      "epoch": 2.470334160839716,
      "grad_norm": 0.9620276093482971,
      "learning_rate": 0.00046783301591687846,
      "loss": 0.7801,
      "step": 233350
    },
    {
      "epoch": 2.4708634826197193,
      "grad_norm": 0.8305547833442688,
      "learning_rate": 0.00046781034592997074,
      "loss": 0.7843,
      "step": 233400
    },
    {
      "epoch": 2.4713928043997226,
      "grad_norm": 0.9447110891342163,
      "learning_rate": 0.00046778766850709766,
      "loss": 0.7904,
      "step": 233450
    },
    {
      "epoch": 2.471922126179726,
      "grad_norm": 0.8383280634880066,
      "learning_rate": 0.00046776498364903344,
      "loss": 0.7906,
      "step": 233500
    },
    {
      "epoch": 2.471922126179726,
      "eval_loss": 0.59697425365448,
      "eval_runtime": 46.8552,
      "eval_samples_per_second": 3584.018,
      "eval_steps_per_second": 448.018,
      "step": 233500
    },
    {
      "epoch": 2.4724514479597293,
      "grad_norm": 0.9672610759735107,
      "learning_rate": 0.0004677422913565526,
      "loss": 0.7838,
      "step": 233550
    },
    {
      "epoch": 2.4729807697397326,
      "grad_norm": 0.9137459397315979,
      "learning_rate": 0.00046771959163042977,
      "loss": 0.7832,
      "step": 233600
    },
    {
      "epoch": 2.473510091519736,
      "grad_norm": 0.9913182258605957,
      "learning_rate": 0.00046769733868745676,
      "loss": 0.7805,
      "step": 233650
    },
    {
      "epoch": 2.474039413299739,
      "grad_norm": 0.9844109416007996,
      "learning_rate": 0.00046767462424500937,
      "loss": 0.7843,
      "step": 233700
    },
    {
      "epoch": 2.4745687350797425,
      "grad_norm": 0.8963857293128967,
      "learning_rate": 0.0004676519023712301,
      "loss": 0.783,
      "step": 233750
    },
    {
      "epoch": 2.4750980568597454,
      "grad_norm": 0.9195718765258789,
      "learning_rate": 0.00046762917306689475,
      "loss": 0.7959,
      "step": 233800
    },
    {
      "epoch": 2.475627378639749,
      "grad_norm": 0.909431517124176,
      "learning_rate": 0.00046760643633277923,
      "loss": 0.775,
      "step": 233850
    },
    {
      "epoch": 2.476156700419752,
      "grad_norm": 0.9353265762329102,
      "learning_rate": 0.00046758369216965974,
      "loss": 0.7776,
      "step": 233900
    },
    {
      "epoch": 2.4766860221997553,
      "grad_norm": 0.939913809299469,
      "learning_rate": 0.0004675609405783128,
      "loss": 0.79,
      "step": 233950
    },
    {
      "epoch": 2.4772153439797586,
      "grad_norm": 0.8567177057266235,
      "learning_rate": 0.0004675381815595151,
      "loss": 0.7825,
      "step": 234000
    },
    {
      "epoch": 2.4772153439797586,
      "eval_loss": 0.5897423028945923,
      "eval_runtime": 46.7999,
      "eval_samples_per_second": 3588.258,
      "eval_steps_per_second": 448.548,
      "step": 234000
    },
    {
      "epoch": 2.477744665759762,
      "grad_norm": 0.9128608107566833,
      "learning_rate": 0.0004675154151140437,
      "loss": 0.783,
      "step": 234050
    },
    {
      "epoch": 2.4782739875397652,
      "grad_norm": 0.9328153729438782,
      "learning_rate": 0.0004674926412426759,
      "loss": 0.7906,
      "step": 234100
    },
    {
      "epoch": 2.4788033093197686,
      "grad_norm": 0.9368743896484375,
      "learning_rate": 0.00046746985994618894,
      "loss": 0.7793,
      "step": 234150
    },
    {
      "epoch": 2.479332631099772,
      "grad_norm": 0.9128175377845764,
      "learning_rate": 0.0004674470712253608,
      "loss": 0.7902,
      "step": 234200
    },
    {
      "epoch": 2.479861952879775,
      "grad_norm": 0.8782726526260376,
      "learning_rate": 0.0004674242750809694,
      "loss": 0.7802,
      "step": 234250
    },
    {
      "epoch": 2.4803912746597785,
      "grad_norm": 0.9356184601783752,
      "learning_rate": 0.00046740147151379296,
      "loss": 0.7842,
      "step": 234300
    },
    {
      "epoch": 2.480920596439782,
      "grad_norm": 0.9615370631217957,
      "learning_rate": 0.00046737866052460995,
      "loss": 0.793,
      "step": 234350
    },
    {
      "epoch": 2.481449918219785,
      "grad_norm": 0.8269410729408264,
      "learning_rate": 0.00046735584211419936,
      "loss": 0.7932,
      "step": 234400
    },
    {
      "epoch": 2.4819792399997884,
      "grad_norm": 0.9135339856147766,
      "learning_rate": 0.0004673330162833399,
      "loss": 0.7802,
      "step": 234450
    },
    {
      "epoch": 2.4825085617797917,
      "grad_norm": 0.8936983346939087,
      "learning_rate": 0.000467310183032811,
      "loss": 0.787,
      "step": 234500
    },
    {
      "epoch": 2.4825085617797917,
      "eval_loss": 0.5923574566841125,
      "eval_runtime": 46.623,
      "eval_samples_per_second": 3601.873,
      "eval_steps_per_second": 450.25,
      "step": 234500
    },
    {
      "epoch": 2.4830378835597946,
      "grad_norm": 0.9510985612869263,
      "learning_rate": 0.00046728734236339207,
      "loss": 0.7852,
      "step": 234550
    },
    {
      "epoch": 2.4835672053397984,
      "grad_norm": 0.9858837723731995,
      "learning_rate": 0.0004672644942758631,
      "loss": 0.7896,
      "step": 234600
    },
    {
      "epoch": 2.4840965271198012,
      "grad_norm": 1.0152487754821777,
      "learning_rate": 0.0004672416387710039,
      "loss": 0.7825,
      "step": 234650
    },
    {
      "epoch": 2.4846258488998045,
      "grad_norm": 0.9898006916046143,
      "learning_rate": 0.00046721877584959484,
      "loss": 0.7818,
      "step": 234700
    },
    {
      "epoch": 2.485155170679808,
      "grad_norm": 0.8930513262748718,
      "learning_rate": 0.0004671959055124164,
      "loss": 0.7749,
      "step": 234750
    },
    {
      "epoch": 2.485684492459811,
      "grad_norm": 1.0031660795211792,
      "learning_rate": 0.00046717302776024943,
      "loss": 0.7837,
      "step": 234800
    },
    {
      "epoch": 2.4862138142398145,
      "grad_norm": 0.9563231468200684,
      "learning_rate": 0.00046715014259387497,
      "loss": 0.7725,
      "step": 234850
    },
    {
      "epoch": 2.486743136019818,
      "grad_norm": 0.9395561218261719,
      "learning_rate": 0.0004671272500140742,
      "loss": 0.7791,
      "step": 234900
    },
    {
      "epoch": 2.487272457799821,
      "grad_norm": 0.9537433385848999,
      "learning_rate": 0.00046710435002162885,
      "loss": 0.7864,
      "step": 234950
    },
    {
      "epoch": 2.4878017795798244,
      "grad_norm": 0.9225140810012817,
      "learning_rate": 0.00046708144261732056,
      "loss": 0.7747,
      "step": 235000
    },
    {
      "epoch": 2.4878017795798244,
      "eval_loss": 0.590858519077301,
      "eval_runtime": 46.7511,
      "eval_samples_per_second": 3591.997,
      "eval_steps_per_second": 449.016,
      "step": 235000
    },
    {
      "epoch": 2.4883311013598277,
      "grad_norm": 0.8486591577529907,
      "learning_rate": 0.00046705852780193135,
      "loss": 0.7763,
      "step": 235050
    },
    {
      "epoch": 2.488860423139831,
      "grad_norm": 0.9170401692390442,
      "learning_rate": 0.0004670356055762437,
      "loss": 0.7694,
      "step": 235100
    },
    {
      "epoch": 2.4893897449198343,
      "grad_norm": 0.8280332684516907,
      "learning_rate": 0.00046701267594104006,
      "loss": 0.7899,
      "step": 235150
    },
    {
      "epoch": 2.4899190666998376,
      "grad_norm": 0.8061175346374512,
      "learning_rate": 0.00046698973889710324,
      "loss": 0.7848,
      "step": 235200
    },
    {
      "epoch": 2.490448388479841,
      "grad_norm": 0.9225197434425354,
      "learning_rate": 0.0004669667944452163,
      "loss": 0.7809,
      "step": 235250
    },
    {
      "epoch": 2.490977710259844,
      "grad_norm": 0.9648988842964172,
      "learning_rate": 0.0004669438425861626,
      "loss": 0.7861,
      "step": 235300
    },
    {
      "epoch": 2.4915070320398476,
      "grad_norm": 0.9711494445800781,
      "learning_rate": 0.00046692088332072565,
      "loss": 0.7555,
      "step": 235350
    },
    {
      "epoch": 2.4920363538198504,
      "grad_norm": 0.9144424200057983,
      "learning_rate": 0.0004668979166496893,
      "loss": 0.7721,
      "step": 235400
    },
    {
      "epoch": 2.4925656755998538,
      "grad_norm": 0.925308883190155,
      "learning_rate": 0.0004668749425738376,
      "loss": 0.787,
      "step": 235450
    },
    {
      "epoch": 2.493094997379857,
      "grad_norm": 0.8922135829925537,
      "learning_rate": 0.00046685196109395497,
      "loss": 0.7796,
      "step": 235500
    },
    {
      "epoch": 2.493094997379857,
      "eval_loss": 0.5878719091415405,
      "eval_runtime": 46.8991,
      "eval_samples_per_second": 3580.669,
      "eval_steps_per_second": 447.6,
      "step": 235500
    },
    {
      "epoch": 2.4936243191598604,
      "grad_norm": 0.9134227633476257,
      "learning_rate": 0.00046682897221082587,
      "loss": 0.7921,
      "step": 235550
    },
    {
      "epoch": 2.4941536409398637,
      "grad_norm": 0.9030106663703918,
      "learning_rate": 0.0004668059759252351,
      "loss": 0.7948,
      "step": 235600
    },
    {
      "epoch": 2.494682962719867,
      "grad_norm": 0.9433400630950928,
      "learning_rate": 0.0004667829722379679,
      "loss": 0.7731,
      "step": 235650
    },
    {
      "epoch": 2.4952122844998703,
      "grad_norm": 0.9765023589134216,
      "learning_rate": 0.00046675996114980956,
      "loss": 0.7684,
      "step": 235700
    },
    {
      "epoch": 2.4957416062798736,
      "grad_norm": 0.9208607077598572,
      "learning_rate": 0.00046673740310382685,
      "loss": 0.7904,
      "step": 235750
    },
    {
      "epoch": 2.496270928059877,
      "grad_norm": 0.9736815690994263,
      "learning_rate": 0.00046671437736422187,
      "loss": 0.788,
      "step": 235800
    },
    {
      "epoch": 2.4968002498398802,
      "grad_norm": 0.883704423904419,
      "learning_rate": 0.0004666913442260675,
      "loss": 0.7729,
      "step": 235850
    },
    {
      "epoch": 2.4973295716198836,
      "grad_norm": 0.9473665952682495,
      "learning_rate": 0.0004666683036901501,
      "loss": 0.7897,
      "step": 235900
    },
    {
      "epoch": 2.497858893399887,
      "grad_norm": 0.9905039668083191,
      "learning_rate": 0.0004666452557572563,
      "loss": 0.7901,
      "step": 235950
    },
    {
      "epoch": 2.49838821517989,
      "grad_norm": 0.9379740953445435,
      "learning_rate": 0.00046662220042817295,
      "loss": 0.7757,
      "step": 236000
    },
    {
      "epoch": 2.49838821517989,
      "eval_loss": 0.5901390910148621,
      "eval_runtime": 46.8374,
      "eval_samples_per_second": 3585.383,
      "eval_steps_per_second": 448.189,
      "step": 236000
    },
    {
      "epoch": 2.498917536959893,
      "grad_norm": 1.015925407409668,
      "learning_rate": 0.000466599137703687,
      "loss": 0.7852,
      "step": 236050
    },
    {
      "epoch": 2.499446858739897,
      "grad_norm": 0.8805522918701172,
      "learning_rate": 0.00046657606758458605,
      "loss": 0.7809,
      "step": 236100
    },
    {
      "epoch": 2.4999761805198997,
      "grad_norm": 0.9151357412338257,
      "learning_rate": 0.00046655299007165754,
      "loss": 0.7749,
      "step": 236150
    },
    {
      "epoch": 2.500505502299903,
      "grad_norm": 0.8891462683677673,
      "learning_rate": 0.0004665299051656894,
      "loss": 0.7768,
      "step": 236200
    },
    {
      "epoch": 2.5010348240799063,
      "grad_norm": 0.8011460900306702,
      "learning_rate": 0.0004665068128674697,
      "loss": 0.7987,
      "step": 236250
    },
    {
      "epoch": 2.5015641458599096,
      "grad_norm": 0.9090681076049805,
      "learning_rate": 0.0004664837131777867,
      "loss": 0.7715,
      "step": 236300
    },
    {
      "epoch": 2.502093467639913,
      "grad_norm": 0.9380741119384766,
      "learning_rate": 0.0004664606060974292,
      "loss": 0.7994,
      "step": 236350
    },
    {
      "epoch": 2.5026227894199162,
      "grad_norm": 0.8315206170082092,
      "learning_rate": 0.000466437491627186,
      "loss": 0.7743,
      "step": 236400
    },
    {
      "epoch": 2.5031521111999195,
      "grad_norm": 0.8512702584266663,
      "learning_rate": 0.00046641436976784624,
      "loss": 0.7833,
      "step": 236450
    },
    {
      "epoch": 2.503681432979923,
      "grad_norm": 0.9339083433151245,
      "learning_rate": 0.0004663912405201992,
      "loss": 0.7782,
      "step": 236500
    },
    {
      "epoch": 2.503681432979923,
      "eval_loss": 0.5890946984291077,
      "eval_runtime": 46.7779,
      "eval_samples_per_second": 3589.942,
      "eval_steps_per_second": 448.759,
      "step": 236500
    },
    {
      "epoch": 2.504210754759926,
      "grad_norm": 0.9031597971916199,
      "learning_rate": 0.00046636810388503457,
      "loss": 0.7943,
      "step": 236550
    },
    {
      "epoch": 2.5047400765399295,
      "grad_norm": 0.8280391693115234,
      "learning_rate": 0.0004663449598631423,
      "loss": 0.7868,
      "step": 236600
    },
    {
      "epoch": 2.505269398319933,
      "grad_norm": 0.9134976267814636,
      "learning_rate": 0.00046632180845531236,
      "loss": 0.7725,
      "step": 236650
    },
    {
      "epoch": 2.505798720099936,
      "grad_norm": 0.9100406765937805,
      "learning_rate": 0.00046629864966233524,
      "loss": 0.769,
      "step": 236700
    },
    {
      "epoch": 2.5063280418799394,
      "grad_norm": 0.8741035461425781,
      "learning_rate": 0.0004662754834850016,
      "loss": 0.7808,
      "step": 236750
    },
    {
      "epoch": 2.5068573636599423,
      "grad_norm": 0.8521112203598022,
      "learning_rate": 0.0004662523099241023,
      "loss": 0.7751,
      "step": 236800
    },
    {
      "epoch": 2.507386685439946,
      "grad_norm": 1.0266923904418945,
      "learning_rate": 0.00046622912898042836,
      "loss": 0.7723,
      "step": 236850
    },
    {
      "epoch": 2.507916007219949,
      "grad_norm": 0.8754998445510864,
      "learning_rate": 0.0004662059406547712,
      "loss": 0.7858,
      "step": 236900
    },
    {
      "epoch": 2.508445328999952,
      "grad_norm": 0.9493929147720337,
      "learning_rate": 0.0004661827449479226,
      "loss": 0.7747,
      "step": 236950
    },
    {
      "epoch": 2.5089746507799555,
      "grad_norm": 0.8489065766334534,
      "learning_rate": 0.0004661595418606744,
      "loss": 0.7882,
      "step": 237000
    },
    {
      "epoch": 2.5089746507799555,
      "eval_loss": 0.5881321430206299,
      "eval_runtime": 46.8084,
      "eval_samples_per_second": 3587.607,
      "eval_steps_per_second": 448.467,
      "step": 237000
    },
    {
      "epoch": 2.509503972559959,
      "grad_norm": 0.8955827951431274,
      "learning_rate": 0.0004661363313938186,
      "loss": 0.7863,
      "step": 237050
    },
    {
      "epoch": 2.510033294339962,
      "grad_norm": 0.8874934911727905,
      "learning_rate": 0.0004661131135481478,
      "loss": 0.7804,
      "step": 237100
    },
    {
      "epoch": 2.5105626161199655,
      "grad_norm": 0.9694650173187256,
      "learning_rate": 0.00046608988832445457,
      "loss": 0.7783,
      "step": 237150
    },
    {
      "epoch": 2.5110919378999688,
      "grad_norm": 0.8748766779899597,
      "learning_rate": 0.0004660666557235318,
      "loss": 0.7808,
      "step": 237200
    },
    {
      "epoch": 2.511621259679972,
      "grad_norm": 0.9235759377479553,
      "learning_rate": 0.0004660434157461726,
      "loss": 0.7843,
      "step": 237250
    },
    {
      "epoch": 2.5121505814599754,
      "grad_norm": 0.8075043559074402,
      "learning_rate": 0.0004660201683931705,
      "loss": 0.792,
      "step": 237300
    },
    {
      "epoch": 2.5126799032399787,
      "grad_norm": 0.966189444065094,
      "learning_rate": 0.00046599691366531895,
      "loss": 0.7754,
      "step": 237350
    },
    {
      "epoch": 2.513209225019982,
      "grad_norm": 0.8920543789863586,
      "learning_rate": 0.0004659736515634121,
      "loss": 0.7672,
      "step": 237400
    },
    {
      "epoch": 2.5137385467999853,
      "grad_norm": 0.9639536738395691,
      "learning_rate": 0.00046595038208824393,
      "loss": 0.7615,
      "step": 237450
    },
    {
      "epoch": 2.5142678685799886,
      "grad_norm": 0.8597738146781921,
      "learning_rate": 0.00046592710524060886,
      "loss": 0.7836,
      "step": 237500
    },
    {
      "epoch": 2.5142678685799886,
      "eval_loss": 0.5895341634750366,
      "eval_runtime": 46.8745,
      "eval_samples_per_second": 3582.546,
      "eval_steps_per_second": 447.834,
      "step": 237500
    },
    {
      "epoch": 2.5147971903599915,
      "grad_norm": 0.8959498405456543,
      "learning_rate": 0.0004659038210213017,
      "loss": 0.7796,
      "step": 237550
    },
    {
      "epoch": 2.5153265121399953,
      "grad_norm": 0.845317542552948,
      "learning_rate": 0.0004658805294311172,
      "loss": 0.7817,
      "step": 237600
    },
    {
      "epoch": 2.515855833919998,
      "grad_norm": 0.9177173376083374,
      "learning_rate": 0.0004658572304708507,
      "loss": 0.7772,
      "step": 237650
    },
    {
      "epoch": 2.5163851557000014,
      "grad_norm": 0.8967516422271729,
      "learning_rate": 0.0004658339241412974,
      "loss": 0.7909,
      "step": 237700
    },
    {
      "epoch": 2.5169144774800047,
      "grad_norm": 0.9318233132362366,
      "learning_rate": 0.00046581061044325317,
      "loss": 0.7819,
      "step": 237750
    },
    {
      "epoch": 2.517443799260008,
      "grad_norm": 0.9351630210876465,
      "learning_rate": 0.00046578775587102685,
      "loss": 0.7636,
      "step": 237800
    },
    {
      "epoch": 2.5179731210400114,
      "grad_norm": 0.935278058052063,
      "learning_rate": 0.00046576442758571875,
      "loss": 0.7883,
      "step": 237850
    },
    {
      "epoch": 2.5185024428200147,
      "grad_norm": 0.9036008715629578,
      "learning_rate": 0.00046574109193429225,
      "loss": 0.782,
      "step": 237900
    },
    {
      "epoch": 2.519031764600018,
      "grad_norm": 1.0969319343566895,
      "learning_rate": 0.0004657177489175439,
      "loss": 0.7887,
      "step": 237950
    },
    {
      "epoch": 2.5195610863800213,
      "grad_norm": 0.9666690230369568,
      "learning_rate": 0.00046569439853627083,
      "loss": 0.7842,
      "step": 238000
    },
    {
      "epoch": 2.5195610863800213,
      "eval_loss": 0.5842762589454651,
      "eval_runtime": 46.7673,
      "eval_samples_per_second": 3590.753,
      "eval_steps_per_second": 448.86,
      "step": 238000
    },
    {
      "epoch": 2.5200904081600246,
      "grad_norm": 0.9411033391952515,
      "learning_rate": 0.00046567104079126996,
      "loss": 0.7731,
      "step": 238050
    },
    {
      "epoch": 2.520619729940028,
      "grad_norm": 0.8348350524902344,
      "learning_rate": 0.000465647675683339,
      "loss": 0.7734,
      "step": 238100
    },
    {
      "epoch": 2.5211490517200312,
      "grad_norm": 0.885337233543396,
      "learning_rate": 0.00046562430321327544,
      "loss": 0.8002,
      "step": 238150
    },
    {
      "epoch": 2.5216783735000345,
      "grad_norm": 0.9025696516036987,
      "learning_rate": 0.0004656009233818772,
      "loss": 0.7679,
      "step": 238200
    },
    {
      "epoch": 2.522207695280038,
      "grad_norm": 0.8835226893424988,
      "learning_rate": 0.0004655775361899425,
      "loss": 0.7731,
      "step": 238250
    },
    {
      "epoch": 2.5227370170600407,
      "grad_norm": 0.9166116118431091,
      "learning_rate": 0.0004655541416382698,
      "loss": 0.7784,
      "step": 238300
    },
    {
      "epoch": 2.5232663388400445,
      "grad_norm": 0.9610504508018494,
      "learning_rate": 0.00046553073972765773,
      "loss": 0.7614,
      "step": 238350
    },
    {
      "epoch": 2.5237956606200473,
      "grad_norm": 0.8317027688026428,
      "learning_rate": 0.00046550733045890524,
      "loss": 0.7636,
      "step": 238400
    },
    {
      "epoch": 2.5243249824000507,
      "grad_norm": 0.9200006127357483,
      "learning_rate": 0.00046548391383281166,
      "loss": 0.7766,
      "step": 238450
    },
    {
      "epoch": 2.524854304180054,
      "grad_norm": 0.921536922454834,
      "learning_rate": 0.00046546048985017616,
      "loss": 0.7779,
      "step": 238500
    },
    {
      "epoch": 2.524854304180054,
      "eval_loss": 0.5870549082756042,
      "eval_runtime": 46.7615,
      "eval_samples_per_second": 3591.2,
      "eval_steps_per_second": 448.916,
      "step": 238500
    },
    {
      "epoch": 2.5253836259600573,
      "grad_norm": 0.8810759782791138,
      "learning_rate": 0.00046543705851179857,
      "loss": 0.7555,
      "step": 238550
    },
    {
      "epoch": 2.5259129477400606,
      "grad_norm": 0.8502280712127686,
      "learning_rate": 0.00046541361981847885,
      "loss": 0.7795,
      "step": 238600
    },
    {
      "epoch": 2.526442269520064,
      "grad_norm": 0.9062439203262329,
      "learning_rate": 0.0004653901737710171,
      "loss": 0.7965,
      "step": 238650
    },
    {
      "epoch": 2.526971591300067,
      "grad_norm": 0.8466407060623169,
      "learning_rate": 0.0004653667203702138,
      "loss": 0.7821,
      "step": 238700
    },
    {
      "epoch": 2.5275009130800705,
      "grad_norm": 0.8836910724639893,
      "learning_rate": 0.0004653432596168697,
      "loss": 0.7813,
      "step": 238750
    },
    {
      "epoch": 2.528030234860074,
      "grad_norm": 0.8224593997001648,
      "learning_rate": 0.00046531979151178565,
      "loss": 0.7839,
      "step": 238800
    },
    {
      "epoch": 2.528559556640077,
      "grad_norm": 0.9699813723564148,
      "learning_rate": 0.00046529631605576297,
      "loss": 0.7823,
      "step": 238850
    },
    {
      "epoch": 2.5290888784200805,
      "grad_norm": 0.8441027402877808,
      "learning_rate": 0.0004652728332496029,
      "loss": 0.7677,
      "step": 238900
    },
    {
      "epoch": 2.5296182002000838,
      "grad_norm": 0.8942602872848511,
      "learning_rate": 0.0004652493430941073,
      "loss": 0.7817,
      "step": 238950
    },
    {
      "epoch": 2.530147521980087,
      "grad_norm": 1.0018490552902222,
      "learning_rate": 0.0004652258455900781,
      "loss": 0.7561,
      "step": 239000
    },
    {
      "epoch": 2.530147521980087,
      "eval_loss": 0.5843747854232788,
      "eval_runtime": 46.8159,
      "eval_samples_per_second": 3587.028,
      "eval_steps_per_second": 448.395,
      "step": 239000
    },
    {
      "epoch": 2.53067684376009,
      "grad_norm": 0.9132161736488342,
      "learning_rate": 0.00046520234073831745,
      "loss": 0.7829,
      "step": 239050
    },
    {
      "epoch": 2.5312061655400937,
      "grad_norm": 0.8695586323738098,
      "learning_rate": 0.00046517882853962776,
      "loss": 0.7898,
      "step": 239100
    },
    {
      "epoch": 2.5317354873200966,
      "grad_norm": 0.921852707862854,
      "learning_rate": 0.00046515530899481186,
      "loss": 0.7847,
      "step": 239150
    },
    {
      "epoch": 2.5322648091001,
      "grad_norm": 0.8616015911102295,
      "learning_rate": 0.00046513178210467256,
      "loss": 0.7793,
      "step": 239200
    },
    {
      "epoch": 2.532794130880103,
      "grad_norm": 0.9434979557991028,
      "learning_rate": 0.0004651082478700131,
      "loss": 0.7826,
      "step": 239250
    },
    {
      "epoch": 2.5333234526601065,
      "grad_norm": 0.8781416416168213,
      "learning_rate": 0.00046508470629163704,
      "loss": 0.7766,
      "step": 239300
    },
    {
      "epoch": 2.53385277444011,
      "grad_norm": 0.9364991784095764,
      "learning_rate": 0.0004650611573703479,
      "loss": 0.7674,
      "step": 239350
    },
    {
      "epoch": 2.534382096220113,
      "grad_norm": 0.9919881224632263,
      "learning_rate": 0.0004650376011069497,
      "loss": 0.7717,
      "step": 239400
    },
    {
      "epoch": 2.5349114180001164,
      "grad_norm": 0.8919011950492859,
      "learning_rate": 0.0004650140375022467,
      "loss": 0.7949,
      "step": 239450
    },
    {
      "epoch": 2.5354407397801197,
      "grad_norm": 0.9641457796096802,
      "learning_rate": 0.00046499046655704336,
      "loss": 0.7612,
      "step": 239500
    },
    {
      "epoch": 2.5354407397801197,
      "eval_loss": 0.585552990436554,
      "eval_runtime": 46.7949,
      "eval_samples_per_second": 3588.641,
      "eval_steps_per_second": 448.596,
      "step": 239500
    },
    {
      "epoch": 2.535970061560123,
      "grad_norm": 1.0194270610809326,
      "learning_rate": 0.0004649668882721443,
      "loss": 0.7767,
      "step": 239550
    },
    {
      "epoch": 2.5364993833401264,
      "grad_norm": 0.9293691515922546,
      "learning_rate": 0.0004649433026483545,
      "loss": 0.7793,
      "step": 239600
    },
    {
      "epoch": 2.5370287051201297,
      "grad_norm": 0.8397637009620667,
      "learning_rate": 0.0004649197096864791,
      "loss": 0.7691,
      "step": 239650
    },
    {
      "epoch": 2.537558026900133,
      "grad_norm": 0.8953042030334473,
      "learning_rate": 0.00046489610938732376,
      "loss": 0.7967,
      "step": 239700
    },
    {
      "epoch": 2.5380873486801363,
      "grad_norm": 0.8859738707542419,
      "learning_rate": 0.00046487250175169403,
      "loss": 0.7879,
      "step": 239750
    },
    {
      "epoch": 2.538616670460139,
      "grad_norm": 0.9211149215698242,
      "learning_rate": 0.0004648488867803958,
      "loss": 0.7963,
      "step": 239800
    },
    {
      "epoch": 2.539145992240143,
      "grad_norm": 0.9815938472747803,
      "learning_rate": 0.00046482526447423546,
      "loss": 0.7807,
      "step": 239850
    },
    {
      "epoch": 2.539675314020146,
      "grad_norm": 0.9412165880203247,
      "learning_rate": 0.0004648016348340194,
      "loss": 0.7751,
      "step": 239900
    },
    {
      "epoch": 2.540204635800149,
      "grad_norm": 0.9336742758750916,
      "learning_rate": 0.00046477847067188417,
      "loss": 0.7911,
      "step": 239950
    },
    {
      "epoch": 2.5407339575801524,
      "grad_norm": 0.9361435174942017,
      "learning_rate": 0.00046475482651261784,
      "loss": 0.7652,
      "step": 240000
    },
    {
      "epoch": 2.5407339575801524,
      "eval_loss": 0.5868997573852539,
      "eval_runtime": 46.8047,
      "eval_samples_per_second": 3587.888,
      "eval_steps_per_second": 448.502,
      "step": 240000
    },
    {
      "epoch": 2.5412632793601557,
      "grad_norm": 0.8674139976501465,
      "learning_rate": 0.00046473117502170055,
      "loss": 0.7705,
      "step": 240050
    },
    {
      "epoch": 2.541792601140159,
      "grad_norm": 0.8936324715614319,
      "learning_rate": 0.0004647075161999397,
      "loss": 0.7873,
      "step": 240100
    },
    {
      "epoch": 2.5423219229201623,
      "grad_norm": 0.9674849510192871,
      "learning_rate": 0.00046468385004814296,
      "loss": 0.7746,
      "step": 240150
    },
    {
      "epoch": 2.5428512447001657,
      "grad_norm": 0.9340515732765198,
      "learning_rate": 0.00046466017656711833,
      "loss": 0.7724,
      "step": 240200
    },
    {
      "epoch": 2.543380566480169,
      "grad_norm": 0.8865541219711304,
      "learning_rate": 0.000464636495757674,
      "loss": 0.7873,
      "step": 240250
    },
    {
      "epoch": 2.5439098882601723,
      "grad_norm": 0.8187180757522583,
      "learning_rate": 0.0004646128076206184,
      "loss": 0.7753,
      "step": 240300
    },
    {
      "epoch": 2.5444392100401756,
      "grad_norm": 0.93059903383255,
      "learning_rate": 0.00046458911215676023,
      "loss": 0.7663,
      "step": 240350
    },
    {
      "epoch": 2.544968531820179,
      "grad_norm": 0.9231080412864685,
      "learning_rate": 0.0004645654093669085,
      "loss": 0.7838,
      "step": 240400
    },
    {
      "epoch": 2.545497853600182,
      "grad_norm": 0.9119470715522766,
      "learning_rate": 0.0004645416992518724,
      "loss": 0.7658,
      "step": 240450
    },
    {
      "epoch": 2.5460271753801855,
      "grad_norm": 0.8853235244750977,
      "learning_rate": 0.0004645179818124613,
      "loss": 0.7905,
      "step": 240500
    },
    {
      "epoch": 2.5460271753801855,
      "eval_loss": 0.5838518738746643,
      "eval_runtime": 46.7722,
      "eval_samples_per_second": 3590.38,
      "eval_steps_per_second": 448.814,
      "step": 240500
    },
    {
      "epoch": 2.5465564971601884,
      "grad_norm": 0.9423431754112244,
      "learning_rate": 0.0004644942570494851,
      "loss": 0.7733,
      "step": 240550
    },
    {
      "epoch": 2.547085818940192,
      "grad_norm": 0.9017845392227173,
      "learning_rate": 0.00046447052496375354,
      "loss": 0.769,
      "step": 240600
    },
    {
      "epoch": 2.547615140720195,
      "grad_norm": 0.9490717053413391,
      "learning_rate": 0.00046444678555607687,
      "loss": 0.7846,
      "step": 240650
    },
    {
      "epoch": 2.5481444625001988,
      "grad_norm": 0.9887502789497375,
      "learning_rate": 0.00046442303882726567,
      "loss": 0.7822,
      "step": 240700
    },
    {
      "epoch": 2.5486737842802016,
      "grad_norm": 0.9656769633293152,
      "learning_rate": 0.00046439928477813054,
      "loss": 0.7777,
      "step": 240750
    },
    {
      "epoch": 2.549203106060205,
      "grad_norm": 0.7592954039573669,
      "learning_rate": 0.0004643755234094824,
      "loss": 0.7705,
      "step": 240800
    },
    {
      "epoch": 2.5497324278402083,
      "grad_norm": 0.9680227637290955,
      "learning_rate": 0.0004643517547221326,
      "loss": 0.7952,
      "step": 240850
    },
    {
      "epoch": 2.5502617496202116,
      "grad_norm": 0.9335955381393433,
      "learning_rate": 0.00046432797871689247,
      "loss": 0.776,
      "step": 240900
    },
    {
      "epoch": 2.550791071400215,
      "grad_norm": 0.8185662031173706,
      "learning_rate": 0.00046430419539457375,
      "loss": 0.7761,
      "step": 240950
    },
    {
      "epoch": 2.551320393180218,
      "grad_norm": 0.902410089969635,
      "learning_rate": 0.00046428040475598835,
      "loss": 0.7595,
      "step": 241000
    },
    {
      "epoch": 2.551320393180218,
      "eval_loss": 0.5824258327484131,
      "eval_runtime": 46.7696,
      "eval_samples_per_second": 3590.577,
      "eval_steps_per_second": 448.838,
      "step": 241000
    },
    {
      "epoch": 2.5518497149602215,
      "grad_norm": 0.8765920996665955,
      "learning_rate": 0.0004642566068019486,
      "loss": 0.7804,
      "step": 241050
    },
    {
      "epoch": 2.552379036740225,
      "grad_norm": 0.8822428584098816,
      "learning_rate": 0.0004642328015332668,
      "loss": 0.7722,
      "step": 241100
    },
    {
      "epoch": 2.552908358520228,
      "grad_norm": 0.9506847262382507,
      "learning_rate": 0.0004642089889507558,
      "loss": 0.7853,
      "step": 241150
    },
    {
      "epoch": 2.5534376803002314,
      "grad_norm": 0.8513384461402893,
      "learning_rate": 0.0004641851690552284,
      "loss": 0.766,
      "step": 241200
    },
    {
      "epoch": 2.5539670020802347,
      "grad_norm": 0.9235040545463562,
      "learning_rate": 0.00046416134184749794,
      "loss": 0.7857,
      "step": 241250
    },
    {
      "epoch": 2.5544963238602376,
      "grad_norm": 0.8848482966423035,
      "learning_rate": 0.0004641375073283777,
      "loss": 0.7685,
      "step": 241300
    },
    {
      "epoch": 2.5550256456402414,
      "grad_norm": 0.8502820134162903,
      "learning_rate": 0.0004641136654986816,
      "loss": 0.7827,
      "step": 241350
    },
    {
      "epoch": 2.5555549674202442,
      "grad_norm": 0.9230495095252991,
      "learning_rate": 0.00046408981635922343,
      "loss": 0.7748,
      "step": 241400
    },
    {
      "epoch": 2.556084289200248,
      "grad_norm": 0.899707019329071,
      "learning_rate": 0.00046406595991081744,
      "loss": 0.7628,
      "step": 241450
    },
    {
      "epoch": 2.556613610980251,
      "grad_norm": 0.8831067085266113,
      "learning_rate": 0.0004640420961542782,
      "loss": 0.7841,
      "step": 241500
    },
    {
      "epoch": 2.556613610980251,
      "eval_loss": 0.5847586393356323,
      "eval_runtime": 46.8501,
      "eval_samples_per_second": 3584.411,
      "eval_steps_per_second": 448.067,
      "step": 241500
    },
    {
      "epoch": 2.557142932760254,
      "grad_norm": 0.9474664330482483,
      "learning_rate": 0.0004640182250904201,
      "loss": 0.7739,
      "step": 241550
    },
    {
      "epoch": 2.5576722545402575,
      "grad_norm": 0.8964762687683105,
      "learning_rate": 0.00046399434672005844,
      "loss": 0.7716,
      "step": 241600
    },
    {
      "epoch": 2.558201576320261,
      "grad_norm": 0.8486580848693848,
      "learning_rate": 0.0004639704610440082,
      "loss": 0.7682,
      "step": 241650
    },
    {
      "epoch": 2.558730898100264,
      "grad_norm": 0.913504958152771,
      "learning_rate": 0.00046394656806308487,
      "loss": 0.7886,
      "step": 241700
    },
    {
      "epoch": 2.5592602198802674,
      "grad_norm": 0.9560613632202148,
      "learning_rate": 0.0004639226677781042,
      "loss": 0.7674,
      "step": 241750
    },
    {
      "epoch": 2.5597895416602707,
      "grad_norm": 0.9346758127212524,
      "learning_rate": 0.0004638987601898822,
      "loss": 0.7581,
      "step": 241800
    },
    {
      "epoch": 2.560318863440274,
      "grad_norm": 0.8124003410339355,
      "learning_rate": 0.0004638748452992349,
      "loss": 0.7572,
      "step": 241850
    },
    {
      "epoch": 2.5608481852202774,
      "grad_norm": 0.9401114583015442,
      "learning_rate": 0.00046385092310697874,
      "loss": 0.7705,
      "step": 241900
    },
    {
      "epoch": 2.5613775070002807,
      "grad_norm": 0.9680494070053101,
      "learning_rate": 0.000463827472275334,
      "loss": 0.7679,
      "step": 241950
    },
    {
      "epoch": 2.561906828780284,
      "grad_norm": 0.9154129028320312,
      "learning_rate": 0.0004638035356283022,
      "loss": 0.7696,
      "step": 242000
    },
    {
      "epoch": 2.561906828780284,
      "eval_loss": 0.5847046375274658,
      "eval_runtime": 46.8149,
      "eval_samples_per_second": 3587.105,
      "eval_steps_per_second": 448.404,
      "step": 242000
    },
    {
      "epoch": 2.562436150560287,
      "grad_norm": 0.8512870073318481,
      "learning_rate": 0.00046377959168209605,
      "loss": 0.7752,
      "step": 242050
    },
    {
      "epoch": 2.5629654723402906,
      "grad_norm": 0.9220482707023621,
      "learning_rate": 0.000463755640437533,
      "loss": 0.7744,
      "step": 242100
    },
    {
      "epoch": 2.5634947941202935,
      "grad_norm": 0.9224117994308472,
      "learning_rate": 0.0004637316818954309,
      "loss": 0.7798,
      "step": 242150
    },
    {
      "epoch": 2.564024115900297,
      "grad_norm": 0.9642385244369507,
      "learning_rate": 0.0004637077160566075,
      "loss": 0.7696,
      "step": 242200
    },
    {
      "epoch": 2.5645534376803,
      "grad_norm": 0.9209965467453003,
      "learning_rate": 0.000463683742921881,
      "loss": 0.7873,
      "step": 242250
    },
    {
      "epoch": 2.5650827594603034,
      "grad_norm": 0.9512249231338501,
      "learning_rate": 0.00046365976249206997,
      "loss": 0.7691,
      "step": 242300
    },
    {
      "epoch": 2.5656120812403067,
      "grad_norm": 0.8625302314758301,
      "learning_rate": 0.00046363577476799304,
      "loss": 0.7754,
      "step": 242350
    },
    {
      "epoch": 2.56614140302031,
      "grad_norm": 0.8868582844734192,
      "learning_rate": 0.00046361177975046895,
      "loss": 0.7636,
      "step": 242400
    },
    {
      "epoch": 2.5666707248003133,
      "grad_norm": 0.9473877549171448,
      "learning_rate": 0.00046358777744031715,
      "loss": 0.7854,
      "step": 242450
    },
    {
      "epoch": 2.5672000465803166,
      "grad_norm": 0.8631000518798828,
      "learning_rate": 0.000463563767838357,
      "loss": 0.7704,
      "step": 242500
    },
    {
      "epoch": 2.5672000465803166,
      "eval_loss": 0.5825210213661194,
      "eval_runtime": 46.8305,
      "eval_samples_per_second": 3585.91,
      "eval_steps_per_second": 448.255,
      "step": 242500
    },
    {
      "epoch": 2.56772936836032,
      "grad_norm": 0.8884280920028687,
      "learning_rate": 0.000463539750945408,
      "loss": 0.7864,
      "step": 242550
    },
    {
      "epoch": 2.5682586901403233,
      "grad_norm": 0.8461834788322449,
      "learning_rate": 0.0004635157267622903,
      "loss": 0.7709,
      "step": 242600
    },
    {
      "epoch": 2.5687880119203266,
      "grad_norm": 0.8365990519523621,
      "learning_rate": 0.000463491695289824,
      "loss": 0.7941,
      "step": 242650
    },
    {
      "epoch": 2.56931733370033,
      "grad_norm": 0.8545438051223755,
      "learning_rate": 0.00046346765652882947,
      "loss": 0.7851,
      "step": 242700
    },
    {
      "epoch": 2.569846655480333,
      "grad_norm": 1.0271788835525513,
      "learning_rate": 0.0004634436104801275,
      "loss": 0.7699,
      "step": 242750
    },
    {
      "epoch": 2.570375977260336,
      "grad_norm": 0.9706615209579468,
      "learning_rate": 0.00046341955714453885,
      "loss": 0.7842,
      "step": 242800
    },
    {
      "epoch": 2.57090529904034,
      "grad_norm": 0.8579307794570923,
      "learning_rate": 0.00046339549652288495,
      "loss": 0.7783,
      "step": 242850
    },
    {
      "epoch": 2.5714346208203427,
      "grad_norm": 0.8524089455604553,
      "learning_rate": 0.0004633714286159869,
      "loss": 0.7699,
      "step": 242900
    },
    {
      "epoch": 2.5719639426003464,
      "grad_norm": 0.8668378591537476,
      "learning_rate": 0.0004633473534246666,
      "loss": 0.7771,
      "step": 242950
    },
    {
      "epoch": 2.5724932643803493,
      "grad_norm": 0.9261796474456787,
      "learning_rate": 0.00046332327094974584,
      "loss": 0.7707,
      "step": 243000
    },
    {
      "epoch": 2.5724932643803493,
      "eval_loss": 0.5788384079933167,
      "eval_runtime": 46.8904,
      "eval_samples_per_second": 3581.327,
      "eval_steps_per_second": 447.682,
      "step": 243000
    },
    {
      "epoch": 2.5730225861603526,
      "grad_norm": 0.7993507981300354,
      "learning_rate": 0.00046329918119204696,
      "loss": 0.7682,
      "step": 243050
    },
    {
      "epoch": 2.573551907940356,
      "grad_norm": 0.9496297836303711,
      "learning_rate": 0.00046327508415239217,
      "loss": 0.7843,
      "step": 243100
    },
    {
      "epoch": 2.5740812297203592,
      "grad_norm": 1.033190131187439,
      "learning_rate": 0.00046325097983160427,
      "loss": 0.7829,
      "step": 243150
    },
    {
      "epoch": 2.5746105515003626,
      "grad_norm": 0.8890410661697388,
      "learning_rate": 0.00046322686823050606,
      "loss": 0.7576,
      "step": 243200
    },
    {
      "epoch": 2.575139873280366,
      "grad_norm": 0.8390870094299316,
      "learning_rate": 0.0004632027493499208,
      "loss": 0.7806,
      "step": 243250
    },
    {
      "epoch": 2.575669195060369,
      "grad_norm": 0.9038076996803284,
      "learning_rate": 0.0004631786231906718,
      "loss": 0.7876,
      "step": 243300
    },
    {
      "epoch": 2.5761985168403725,
      "grad_norm": 0.9200758337974548,
      "learning_rate": 0.0004631544897535829,
      "loss": 0.773,
      "step": 243350
    },
    {
      "epoch": 2.576727838620376,
      "grad_norm": 0.8007097840309143,
      "learning_rate": 0.00046313034903947784,
      "loss": 0.7747,
      "step": 243400
    },
    {
      "epoch": 2.577257160400379,
      "grad_norm": 0.9232457876205444,
      "learning_rate": 0.0004631062010491809,
      "loss": 0.7657,
      "step": 243450
    },
    {
      "epoch": 2.5777864821803824,
      "grad_norm": 0.9389773011207581,
      "learning_rate": 0.0004630820457835163,
      "loss": 0.7842,
      "step": 243500
    },
    {
      "epoch": 2.5777864821803824,
      "eval_loss": 0.5827251076698303,
      "eval_runtime": 46.8639,
      "eval_samples_per_second": 3583.356,
      "eval_steps_per_second": 447.935,
      "step": 243500
    },
    {
      "epoch": 2.5783158039603853,
      "grad_norm": 0.9279384016990662,
      "learning_rate": 0.0004630578832433089,
      "loss": 0.7661,
      "step": 243550
    },
    {
      "epoch": 2.578845125740389,
      "grad_norm": 0.9486768841743469,
      "learning_rate": 0.0004630337134293834,
      "loss": 0.7831,
      "step": 243600
    },
    {
      "epoch": 2.579374447520392,
      "grad_norm": 0.9514543414115906,
      "learning_rate": 0.00046300953634256515,
      "loss": 0.7831,
      "step": 243650
    },
    {
      "epoch": 2.5799037693003957,
      "grad_norm": 0.8658318519592285,
      "learning_rate": 0.00046298535198367936,
      "loss": 0.7898,
      "step": 243700
    },
    {
      "epoch": 2.5804330910803985,
      "grad_norm": 0.8821523785591125,
      "learning_rate": 0.00046296116035355185,
      "loss": 0.7787,
      "step": 243750
    },
    {
      "epoch": 2.580962412860402,
      "grad_norm": 0.8642784953117371,
      "learning_rate": 0.00046293696145300835,
      "loss": 0.769,
      "step": 243800
    },
    {
      "epoch": 2.581491734640405,
      "grad_norm": 0.9891212582588196,
      "learning_rate": 0.00046291275528287514,
      "loss": 0.7656,
      "step": 243850
    },
    {
      "epoch": 2.5820210564204085,
      "grad_norm": 0.9479790925979614,
      "learning_rate": 0.0004628885418439785,
      "loss": 0.7609,
      "step": 243900
    },
    {
      "epoch": 2.582550378200412,
      "grad_norm": 0.9402400255203247,
      "learning_rate": 0.0004628643211371451,
      "loss": 0.7732,
      "step": 243950
    },
    {
      "epoch": 2.583079699980415,
      "grad_norm": 0.9078455567359924,
      "learning_rate": 0.0004628405777938931,
      "loss": 0.7765,
      "step": 244000
    },
    {
      "epoch": 2.583079699980415,
      "eval_loss": 0.5809957981109619,
      "eval_runtime": 46.8453,
      "eval_samples_per_second": 3584.781,
      "eval_steps_per_second": 448.114,
      "step": 244000
    },
    {
      "epoch": 2.5836090217604184,
      "grad_norm": 0.9656923413276672,
      "learning_rate": 0.0004628163426989847,
      "loss": 0.7743,
      "step": 244050
    },
    {
      "epoch": 2.5841383435404217,
      "grad_norm": 0.9041317701339722,
      "learning_rate": 0.0004627921003386044,
      "loss": 0.7602,
      "step": 244100
    },
    {
      "epoch": 2.584667665320425,
      "grad_norm": 0.868726909160614,
      "learning_rate": 0.00046276785071357987,
      "loss": 0.7803,
      "step": 244150
    },
    {
      "epoch": 2.5851969871004283,
      "grad_norm": 0.9582882523536682,
      "learning_rate": 0.0004627435938247389,
      "loss": 0.7706,
      "step": 244200
    },
    {
      "epoch": 2.5857263088804316,
      "grad_norm": 0.8803585171699524,
      "learning_rate": 0.00046271932967290963,
      "loss": 0.777,
      "step": 244250
    },
    {
      "epoch": 2.5862556306604345,
      "grad_norm": 0.9191219806671143,
      "learning_rate": 0.00046269505825892053,
      "loss": 0.7711,
      "step": 244300
    },
    {
      "epoch": 2.5867849524404383,
      "grad_norm": 1.092890739440918,
      "learning_rate": 0.00046267077958360014,
      "loss": 0.7727,
      "step": 244350
    },
    {
      "epoch": 2.587314274220441,
      "grad_norm": 0.8782129287719727,
      "learning_rate": 0.0004626464936477773,
      "loss": 0.7736,
      "step": 244400
    },
    {
      "epoch": 2.587843596000445,
      "grad_norm": 0.9746371507644653,
      "learning_rate": 0.00046262220045228123,
      "loss": 0.7682,
      "step": 244450
    },
    {
      "epoch": 2.5883729177804478,
      "grad_norm": 0.7934709191322327,
      "learning_rate": 0.0004625978999979411,
      "loss": 0.7661,
      "step": 244500
    },
    {
      "epoch": 2.5883729177804478,
      "eval_loss": 0.5821292996406555,
      "eval_runtime": 46.7877,
      "eval_samples_per_second": 3589.189,
      "eval_steps_per_second": 448.665,
      "step": 244500
    },
    {
      "epoch": 2.588902239560451,
      "grad_norm": 0.9074083566665649,
      "learning_rate": 0.0004625735922855867,
      "loss": 0.7728,
      "step": 244550
    },
    {
      "epoch": 2.5894315613404544,
      "grad_norm": 0.9802318811416626,
      "learning_rate": 0.00046254927731604776,
      "loss": 0.7669,
      "step": 244600
    },
    {
      "epoch": 2.5899608831204577,
      "grad_norm": 0.8946985602378845,
      "learning_rate": 0.00046252495509015444,
      "loss": 0.7764,
      "step": 244650
    },
    {
      "epoch": 2.590490204900461,
      "grad_norm": 0.8447086811065674,
      "learning_rate": 0.0004625006256087372,
      "loss": 0.7759,
      "step": 244700
    },
    {
      "epoch": 2.5910195266804643,
      "grad_norm": 0.9648988842964172,
      "learning_rate": 0.0004624762888726264,
      "loss": 0.7617,
      "step": 244750
    },
    {
      "epoch": 2.5915488484604676,
      "grad_norm": 0.9638596177101135,
      "learning_rate": 0.00046245194488265314,
      "loss": 0.7613,
      "step": 244800
    },
    {
      "epoch": 2.592078170240471,
      "grad_norm": 0.9473760724067688,
      "learning_rate": 0.00046242759363964835,
      "loss": 0.7572,
      "step": 244850
    },
    {
      "epoch": 2.5926074920204742,
      "grad_norm": 0.9880784153938293,
      "learning_rate": 0.00046240323514444337,
      "loss": 0.7966,
      "step": 244900
    },
    {
      "epoch": 2.5931368138004776,
      "grad_norm": 0.9205732345581055,
      "learning_rate": 0.00046237886939786994,
      "loss": 0.7731,
      "step": 244950
    },
    {
      "epoch": 2.593666135580481,
      "grad_norm": 0.8784798979759216,
      "learning_rate": 0.0004623544964007598,
      "loss": 0.7771,
      "step": 245000
    },
    {
      "epoch": 2.593666135580481,
      "eval_loss": 0.5780794620513916,
      "eval_runtime": 46.9012,
      "eval_samples_per_second": 3580.502,
      "eval_steps_per_second": 447.579,
      "step": 245000
    },
    {
      "epoch": 2.5941954573604837,
      "grad_norm": 0.9534255266189575,
      "learning_rate": 0.0004623301161539449,
      "loss": 0.7771,
      "step": 245050
    },
    {
      "epoch": 2.5947247791404875,
      "grad_norm": 0.8398470282554626,
      "learning_rate": 0.00046230572865825774,
      "loss": 0.7712,
      "step": 245100
    },
    {
      "epoch": 2.5952541009204904,
      "grad_norm": 0.9184614419937134,
      "learning_rate": 0.000462281333914531,
      "loss": 0.7685,
      "step": 245150
    },
    {
      "epoch": 2.595783422700494,
      "grad_norm": 0.817710816860199,
      "learning_rate": 0.0004622569319235972,
      "loss": 0.7767,
      "step": 245200
    },
    {
      "epoch": 2.596312744480497,
      "grad_norm": 0.9431205987930298,
      "learning_rate": 0.0004622325226862897,
      "loss": 0.7785,
      "step": 245250
    },
    {
      "epoch": 2.5968420662605003,
      "grad_norm": 0.9457480907440186,
      "learning_rate": 0.0004622081062034417,
      "loss": 0.7729,
      "step": 245300
    },
    {
      "epoch": 2.5973713880405036,
      "grad_norm": 0.9992610812187195,
      "learning_rate": 0.0004621836824758867,
      "loss": 0.7721,
      "step": 245350
    },
    {
      "epoch": 2.597900709820507,
      "grad_norm": 0.9424388408660889,
      "learning_rate": 0.00046215925150445866,
      "loss": 0.7743,
      "step": 245400
    },
    {
      "epoch": 2.5984300316005102,
      "grad_norm": 1.0282920598983765,
      "learning_rate": 0.0004621348132899915,
      "loss": 0.7827,
      "step": 245450
    },
    {
      "epoch": 2.5989593533805135,
      "grad_norm": 1.0273418426513672,
      "learning_rate": 0.00046211036783331974,
      "loss": 0.7891,
      "step": 245500
    },
    {
      "epoch": 2.5989593533805135,
      "eval_loss": 0.5779804587364197,
      "eval_runtime": 46.801,
      "eval_samples_per_second": 3588.172,
      "eval_steps_per_second": 448.538,
      "step": 245500
    },
    {
      "epoch": 2.599488675160517,
      "grad_norm": 0.8541297316551208,
      "learning_rate": 0.00046208591513527777,
      "loss": 0.7713,
      "step": 245550
    },
    {
      "epoch": 2.60001799694052,
      "grad_norm": 0.8790011405944824,
      "learning_rate": 0.0004620614551967004,
      "loss": 0.7723,
      "step": 245600
    },
    {
      "epoch": 2.6005473187205235,
      "grad_norm": 0.9008607864379883,
      "learning_rate": 0.00046203698801842275,
      "loss": 0.7786,
      "step": 245650
    },
    {
      "epoch": 2.601076640500527,
      "grad_norm": 0.8777544498443604,
      "learning_rate": 0.00046201251360128003,
      "loss": 0.7757,
      "step": 245700
    },
    {
      "epoch": 2.60160596228053,
      "grad_norm": 0.8956553339958191,
      "learning_rate": 0.00046198803194610796,
      "loss": 0.7753,
      "step": 245750
    },
    {
      "epoch": 2.6021352840605334,
      "grad_norm": 0.8394490480422974,
      "learning_rate": 0.00046196354305374213,
      "loss": 0.7646,
      "step": 245800
    },
    {
      "epoch": 2.6026646058405367,
      "grad_norm": 0.9374092817306519,
      "learning_rate": 0.0004619390469250187,
      "loss": 0.765,
      "step": 245850
    },
    {
      "epoch": 2.6031939276205396,
      "grad_norm": 0.9319484829902649,
      "learning_rate": 0.00046191454356077393,
      "loss": 0.772,
      "step": 245900
    },
    {
      "epoch": 2.6037232494005433,
      "grad_norm": 0.9322860836982727,
      "learning_rate": 0.0004618900329618444,
      "loss": 0.7723,
      "step": 245950
    },
    {
      "epoch": 2.604252571180546,
      "grad_norm": 1.0381149053573608,
      "learning_rate": 0.0004618660055566086,
      "loss": 0.7625,
      "step": 246000
    },
    {
      "epoch": 2.604252571180546,
      "eval_loss": 0.5765222311019897,
      "eval_runtime": 46.8357,
      "eval_samples_per_second": 3585.512,
      "eval_steps_per_second": 448.205,
      "step": 246000
    },
    {
      "epoch": 2.6047818929605495,
      "grad_norm": 0.873200535774231,
      "learning_rate": 0.0004618414806354721,
      "loss": 0.7524,
      "step": 246050
    },
    {
      "epoch": 2.605311214740553,
      "grad_norm": 0.909331202507019,
      "learning_rate": 0.0004618169484821451,
      "loss": 0.7725,
      "step": 246100
    },
    {
      "epoch": 2.605840536520556,
      "grad_norm": 0.8876988887786865,
      "learning_rate": 0.00046179240909746515,
      "loss": 0.769,
      "step": 246150
    },
    {
      "epoch": 2.6063698583005595,
      "grad_norm": 0.93199223279953,
      "learning_rate": 0.00046176786248227004,
      "loss": 0.7664,
      "step": 246200
    },
    {
      "epoch": 2.6068991800805628,
      "grad_norm": 0.8797788619995117,
      "learning_rate": 0.0004617433086373978,
      "loss": 0.7671,
      "step": 246250
    },
    {
      "epoch": 2.607428501860566,
      "grad_norm": 1.0541561841964722,
      "learning_rate": 0.0004617187475636866,
      "loss": 0.776,
      "step": 246300
    },
    {
      "epoch": 2.6079578236405694,
      "grad_norm": 0.862501859664917,
      "learning_rate": 0.00046169417926197496,
      "loss": 0.7556,
      "step": 246350
    },
    {
      "epoch": 2.6084871454205727,
      "grad_norm": 0.9412334561347961,
      "learning_rate": 0.00046166960373310176,
      "loss": 0.7521,
      "step": 246400
    },
    {
      "epoch": 2.609016467200576,
      "grad_norm": 0.9870790839195251,
      "learning_rate": 0.00046164502097790594,
      "loss": 0.7763,
      "step": 246450
    },
    {
      "epoch": 2.6095457889805793,
      "grad_norm": 0.9140291810035706,
      "learning_rate": 0.00046162043099722667,
      "loss": 0.7715,
      "step": 246500
    },
    {
      "epoch": 2.6095457889805793,
      "eval_loss": 0.5771561861038208,
      "eval_runtime": 46.8642,
      "eval_samples_per_second": 3583.33,
      "eval_steps_per_second": 447.932,
      "step": 246500
    },
    {
      "epoch": 2.6100751107605826,
      "grad_norm": 0.8726395964622498,
      "learning_rate": 0.0004615958337919035,
      "loss": 0.7728,
      "step": 246550
    },
    {
      "epoch": 2.610604432540586,
      "grad_norm": 0.9293073415756226,
      "learning_rate": 0.0004615712293627762,
      "loss": 0.776,
      "step": 246600
    },
    {
      "epoch": 2.611133754320589,
      "grad_norm": 0.9314107894897461,
      "learning_rate": 0.00046154661771068465,
      "loss": 0.7772,
      "step": 246650
    },
    {
      "epoch": 2.6116630761005926,
      "grad_norm": 0.8822612166404724,
      "learning_rate": 0.00046152199883646916,
      "loss": 0.7915,
      "step": 246700
    },
    {
      "epoch": 2.6121923978805954,
      "grad_norm": 0.9732854962348938,
      "learning_rate": 0.00046149737274097025,
      "loss": 0.7825,
      "step": 246750
    },
    {
      "epoch": 2.6127217196605987,
      "grad_norm": 0.9054760932922363,
      "learning_rate": 0.0004614727394250286,
      "loss": 0.7573,
      "step": 246800
    },
    {
      "epoch": 2.613251041440602,
      "grad_norm": 0.8617081046104431,
      "learning_rate": 0.00046144809888948513,
      "loss": 0.759,
      "step": 246850
    },
    {
      "epoch": 2.6137803632206054,
      "grad_norm": 0.9228234887123108,
      "learning_rate": 0.0004614234511351812,
      "loss": 0.7689,
      "step": 246900
    },
    {
      "epoch": 2.6143096850006087,
      "grad_norm": 0.8902450203895569,
      "learning_rate": 0.0004613987961629581,
      "loss": 0.7797,
      "step": 246950
    },
    {
      "epoch": 2.614839006780612,
      "grad_norm": 0.8974385261535645,
      "learning_rate": 0.0004613741339736577,
      "loss": 0.7821,
      "step": 247000
    },
    {
      "epoch": 2.614839006780612,
      "eval_loss": 0.5774328112602234,
      "eval_runtime": 46.8634,
      "eval_samples_per_second": 3583.395,
      "eval_steps_per_second": 447.94,
      "step": 247000
    },
    {
      "epoch": 2.6153683285606153,
      "grad_norm": 0.8206336498260498,
      "learning_rate": 0.0004613494645681218,
      "loss": 0.7731,
      "step": 247050
    },
    {
      "epoch": 2.6158976503406186,
      "grad_norm": 0.8930264115333557,
      "learning_rate": 0.0004613247879471928,
      "loss": 0.7627,
      "step": 247100
    },
    {
      "epoch": 2.616426972120622,
      "grad_norm": 0.8953091502189636,
      "learning_rate": 0.00046130010411171295,
      "loss": 0.7728,
      "step": 247150
    },
    {
      "epoch": 2.6169562939006252,
      "grad_norm": 0.9718055129051208,
      "learning_rate": 0.0004612754130625251,
      "loss": 0.7813,
      "step": 247200
    },
    {
      "epoch": 2.6174856156806285,
      "grad_norm": 0.956696093082428,
      "learning_rate": 0.00046125071480047203,
      "loss": 0.7774,
      "step": 247250
    },
    {
      "epoch": 2.618014937460632,
      "grad_norm": 0.848494827747345,
      "learning_rate": 0.00046122600932639715,
      "loss": 0.7592,
      "step": 247300
    },
    {
      "epoch": 2.618544259240635,
      "grad_norm": 0.8449971675872803,
      "learning_rate": 0.0004612012966411437,
      "loss": 0.7611,
      "step": 247350
    },
    {
      "epoch": 2.619073581020638,
      "grad_norm": 0.9506772756576538,
      "learning_rate": 0.00046117657674555544,
      "loss": 0.7689,
      "step": 247400
    },
    {
      "epoch": 2.619602902800642,
      "grad_norm": 0.8983175158500671,
      "learning_rate": 0.0004611518496404763,
      "loss": 0.7717,
      "step": 247450
    },
    {
      "epoch": 2.6201322245806447,
      "grad_norm": 0.8962312340736389,
      "learning_rate": 0.0004611271153267505,
      "loss": 0.752,
      "step": 247500
    },
    {
      "epoch": 2.6201322245806447,
      "eval_loss": 0.5748733282089233,
      "eval_runtime": 46.7463,
      "eval_samples_per_second": 3592.37,
      "eval_steps_per_second": 449.062,
      "step": 247500
    },
    {
      "epoch": 2.620661546360648,
      "grad_norm": 0.991260290145874,
      "learning_rate": 0.00046110237380522236,
      "loss": 0.7745,
      "step": 247550
    },
    {
      "epoch": 2.6211908681406513,
      "grad_norm": 0.9663848280906677,
      "learning_rate": 0.0004610776250767367,
      "loss": 0.762,
      "step": 247600
    },
    {
      "epoch": 2.6217201899206546,
      "grad_norm": 0.966795802116394,
      "learning_rate": 0.0004610528691421382,
      "loss": 0.7689,
      "step": 247650
    },
    {
      "epoch": 2.622249511700658,
      "grad_norm": 0.8886972665786743,
      "learning_rate": 0.00046102810600227216,
      "loss": 0.7599,
      "step": 247700
    },
    {
      "epoch": 2.622778833480661,
      "grad_norm": 0.8460150361061096,
      "learning_rate": 0.000461003335657984,
      "loss": 0.762,
      "step": 247750
    },
    {
      "epoch": 2.6233081552606645,
      "grad_norm": 0.9211412072181702,
      "learning_rate": 0.00046097855811011933,
      "loss": 0.7734,
      "step": 247800
    },
    {
      "epoch": 2.623837477040668,
      "grad_norm": 0.887417733669281,
      "learning_rate": 0.00046095377335952416,
      "loss": 0.7621,
      "step": 247850
    },
    {
      "epoch": 2.624366798820671,
      "grad_norm": 0.9851418733596802,
      "learning_rate": 0.00046092898140704443,
      "loss": 0.7623,
      "step": 247900
    },
    {
      "epoch": 2.6248961206006745,
      "grad_norm": 0.9719426035881042,
      "learning_rate": 0.00046090418225352666,
      "loss": 0.7634,
      "step": 247950
    },
    {
      "epoch": 2.6254254423806778,
      "grad_norm": 0.9005927443504333,
      "learning_rate": 0.00046087937589981743,
      "loss": 0.7683,
      "step": 248000
    },
    {
      "epoch": 2.6254254423806778,
      "eval_loss": 0.5793841481208801,
      "eval_runtime": 46.8147,
      "eval_samples_per_second": 3587.121,
      "eval_steps_per_second": 448.406,
      "step": 248000
    },
    {
      "epoch": 2.625954764160681,
      "grad_norm": 0.9723910093307495,
      "learning_rate": 0.0004608545623467637,
      "loss": 0.7768,
      "step": 248050
    },
    {
      "epoch": 2.6264840859406844,
      "grad_norm": 0.8250631093978882,
      "learning_rate": 0.00046082974159521254,
      "loss": 0.7568,
      "step": 248100
    },
    {
      "epoch": 2.6270134077206873,
      "grad_norm": 0.9638000726699829,
      "learning_rate": 0.0004608049136460112,
      "loss": 0.7866,
      "step": 248150
    },
    {
      "epoch": 2.627542729500691,
      "grad_norm": 0.9610815048217773,
      "learning_rate": 0.00046078057527345077,
      "loss": 0.7685,
      "step": 248200
    },
    {
      "epoch": 2.628072051280694,
      "grad_norm": 0.9602699279785156,
      "learning_rate": 0.0004607557330754033,
      "loss": 0.7712,
      "step": 248250
    },
    {
      "epoch": 2.628601373060697,
      "grad_norm": 0.8770932555198669,
      "learning_rate": 0.0004607308836822324,
      "loss": 0.7746,
      "step": 248300
    },
    {
      "epoch": 2.6291306948407005,
      "grad_norm": 1.0031334161758423,
      "learning_rate": 0.0004607060270947864,
      "loss": 0.7702,
      "step": 248350
    },
    {
      "epoch": 2.629660016620704,
      "grad_norm": 0.9289020299911499,
      "learning_rate": 0.00046068116331391383,
      "loss": 0.7702,
      "step": 248400
    },
    {
      "epoch": 2.630189338400707,
      "grad_norm": 0.9675833582878113,
      "learning_rate": 0.0004606562923404637,
      "loss": 0.7666,
      "step": 248450
    },
    {
      "epoch": 2.6307186601807104,
      "grad_norm": 0.8962618112564087,
      "learning_rate": 0.00046063141417528497,
      "loss": 0.7889,
      "step": 248500
    },
    {
      "epoch": 2.6307186601807104,
      "eval_loss": 0.5791027545928955,
      "eval_runtime": 46.7539,
      "eval_samples_per_second": 3591.79,
      "eval_steps_per_second": 448.99,
      "step": 248500
    },
    {
      "epoch": 2.6312479819607137,
      "grad_norm": 0.9133133888244629,
      "learning_rate": 0.00046060652881922703,
      "loss": 0.7617,
      "step": 248550
    },
    {
      "epoch": 2.631777303740717,
      "grad_norm": 0.9901071786880493,
      "learning_rate": 0.00046058163627313943,
      "loss": 0.7615,
      "step": 248600
    },
    {
      "epoch": 2.6323066255207204,
      "grad_norm": 0.8217364549636841,
      "learning_rate": 0.000460556736537872,
      "loss": 0.7714,
      "step": 248650
    },
    {
      "epoch": 2.6328359473007237,
      "grad_norm": 0.9084864854812622,
      "learning_rate": 0.0004605318296142748,
      "loss": 0.7704,
      "step": 248700
    },
    {
      "epoch": 2.633365269080727,
      "grad_norm": 0.947594940662384,
      "learning_rate": 0.0004605069155031981,
      "loss": 0.7712,
      "step": 248750
    },
    {
      "epoch": 2.6338945908607303,
      "grad_norm": 0.8662772178649902,
      "learning_rate": 0.0004604819942054926,
      "loss": 0.7653,
      "step": 248800
    },
    {
      "epoch": 2.6344239126407336,
      "grad_norm": 0.9927806258201599,
      "learning_rate": 0.00046045706572200894,
      "loss": 0.7653,
      "step": 248850
    },
    {
      "epoch": 2.6349532344207365,
      "grad_norm": 0.9107300043106079,
      "learning_rate": 0.0004604321300535983,
      "loss": 0.7576,
      "step": 248900
    },
    {
      "epoch": 2.6354825562007402,
      "grad_norm": 0.9298058748245239,
      "learning_rate": 0.00046040718720111184,
      "loss": 0.7657,
      "step": 248950
    },
    {
      "epoch": 2.636011877980743,
      "grad_norm": 0.827614426612854,
      "learning_rate": 0.00046038223716540115,
      "loss": 0.7608,
      "step": 249000
    },
    {
      "epoch": 2.636011877980743,
      "eval_loss": 0.5754885077476501,
      "eval_runtime": 46.8857,
      "eval_samples_per_second": 3581.688,
      "eval_steps_per_second": 447.727,
      "step": 249000
    },
    {
      "epoch": 2.6365411997607464,
      "grad_norm": 0.9436665773391724,
      "learning_rate": 0.00046035727994731815,
      "loss": 0.7822,
      "step": 249050
    },
    {
      "epoch": 2.6370705215407497,
      "grad_norm": 0.87412428855896,
      "learning_rate": 0.00046033231554771473,
      "loss": 0.7635,
      "step": 249100
    },
    {
      "epoch": 2.637599843320753,
      "grad_norm": 0.8733575940132141,
      "learning_rate": 0.0004603073439674431,
      "loss": 0.7732,
      "step": 249150
    },
    {
      "epoch": 2.6381291651007563,
      "grad_norm": 0.9873417019844055,
      "learning_rate": 0.000460282365207356,
      "loss": 0.773,
      "step": 249200
    },
    {
      "epoch": 2.6386584868807597,
      "grad_norm": 1.0426828861236572,
      "learning_rate": 0.00046025737926830605,
      "loss": 0.7666,
      "step": 249250
    },
    {
      "epoch": 2.639187808660763,
      "grad_norm": 0.9359248280525208,
      "learning_rate": 0.0004602323861511462,
      "loss": 0.7659,
      "step": 249300
    },
    {
      "epoch": 2.6397171304407663,
      "grad_norm": 1.0071649551391602,
      "learning_rate": 0.00046020738585672983,
      "loss": 0.7505,
      "step": 249350
    },
    {
      "epoch": 2.6402464522207696,
      "grad_norm": 0.9714268445968628,
      "learning_rate": 0.0004601823783859104,
      "loss": 0.7729,
      "step": 249400
    },
    {
      "epoch": 2.640775774000773,
      "grad_norm": 0.989479124546051,
      "learning_rate": 0.0004601573637395416,
      "loss": 0.7827,
      "step": 249450
    },
    {
      "epoch": 2.641305095780776,
      "grad_norm": 0.8926212191581726,
      "learning_rate": 0.00046013234191847756,
      "loss": 0.7568,
      "step": 249500
    },
    {
      "epoch": 2.641305095780776,
      "eval_loss": 0.5737288594245911,
      "eval_runtime": 46.8368,
      "eval_samples_per_second": 3585.431,
      "eval_steps_per_second": 448.195,
      "step": 249500
    },
    {
      "epoch": 2.6418344175607795,
      "grad_norm": 0.8591580390930176,
      "learning_rate": 0.00046010731292357243,
      "loss": 0.783,
      "step": 249550
    },
    {
      "epoch": 2.642363739340783,
      "grad_norm": 0.8405996561050415,
      "learning_rate": 0.00046008227675568066,
      "loss": 0.7617,
      "step": 249600
    },
    {
      "epoch": 2.6428930611207857,
      "grad_norm": 1.0090372562408447,
      "learning_rate": 0.00046005723341565696,
      "loss": 0.771,
      "step": 249650
    },
    {
      "epoch": 2.6434223829007895,
      "grad_norm": 0.8847382068634033,
      "learning_rate": 0.00046003218290435646,
      "loss": 0.7605,
      "step": 249700
    },
    {
      "epoch": 2.6439517046807923,
      "grad_norm": 0.8949915170669556,
      "learning_rate": 0.00046000712522263414,
      "loss": 0.7674,
      "step": 249750
    },
    {
      "epoch": 2.6444810264607956,
      "grad_norm": 0.8454416990280151,
      "learning_rate": 0.0004599820603713457,
      "loss": 0.7723,
      "step": 249800
    },
    {
      "epoch": 2.645010348240799,
      "grad_norm": 1.0088053941726685,
      "learning_rate": 0.00045995698835134665,
      "loss": 0.7652,
      "step": 249850
    },
    {
      "epoch": 2.6455396700208023,
      "grad_norm": 0.927212655544281,
      "learning_rate": 0.00045993190916349304,
      "loss": 0.7746,
      "step": 249900
    },
    {
      "epoch": 2.6460689918008056,
      "grad_norm": 0.8735023736953735,
      "learning_rate": 0.00045990682280864104,
      "loss": 0.7756,
      "step": 249950
    },
    {
      "epoch": 2.646598313580809,
      "grad_norm": 0.8603096604347229,
      "learning_rate": 0.000459881729287647,
      "loss": 0.775,
      "step": 250000
    },
    {
      "epoch": 2.646598313580809,
      "eval_loss": 0.5730935335159302,
      "eval_runtime": 46.7593,
      "eval_samples_per_second": 3591.374,
      "eval_steps_per_second": 448.938,
      "step": 250000
    },
    {
      "epoch": 2.647127635360812,
      "grad_norm": 0.9850928783416748,
      "learning_rate": 0.00045985662860136787,
      "loss": 0.7598,
      "step": 250050
    },
    {
      "epoch": 2.6476569571408155,
      "grad_norm": 0.8957922458648682,
      "learning_rate": 0.00045983152075066027,
      "loss": 0.774,
      "step": 250100
    },
    {
      "epoch": 2.648186278920819,
      "grad_norm": 0.9464642405509949,
      "learning_rate": 0.00045980640573638155,
      "loss": 0.76,
      "step": 250150
    },
    {
      "epoch": 2.648715600700822,
      "grad_norm": 0.8553556203842163,
      "learning_rate": 0.0004597812835593891,
      "loss": 0.7665,
      "step": 250200
    },
    {
      "epoch": 2.6492449224808254,
      "grad_norm": 0.8913500905036926,
      "learning_rate": 0.0004597561542205405,
      "loss": 0.7569,
      "step": 250250
    },
    {
      "epoch": 2.6497742442608287,
      "grad_norm": 0.9017824530601501,
      "learning_rate": 0.0004597310177206938,
      "loss": 0.7663,
      "step": 250300
    },
    {
      "epoch": 2.650303566040832,
      "grad_norm": 0.9435566067695618,
      "learning_rate": 0.0004597058740607071,
      "loss": 0.7665,
      "step": 250350
    },
    {
      "epoch": 2.650832887820835,
      "grad_norm": 0.8137343525886536,
      "learning_rate": 0.00045968122632797945,
      "loss": 0.7791,
      "step": 250400
    },
    {
      "epoch": 2.6513622096008387,
      "grad_norm": 0.9724806547164917,
      "learning_rate": 0.0004596560684934481,
      "loss": 0.7732,
      "step": 250450
    },
    {
      "epoch": 2.6518915313808415,
      "grad_norm": 0.7970695495605469,
      "learning_rate": 0.0004596309035013355,
      "loss": 0.7718,
      "step": 250500
    },
    {
      "epoch": 2.6518915313808415,
      "eval_loss": 0.5762677192687988,
      "eval_runtime": 46.8178,
      "eval_samples_per_second": 3586.885,
      "eval_steps_per_second": 448.377,
      "step": 250500
    },
    {
      "epoch": 2.652420853160845,
      "grad_norm": 0.8819705247879028,
      "learning_rate": 0.0004596057313525006,
      "loss": 0.7742,
      "step": 250550
    },
    {
      "epoch": 2.652950174940848,
      "grad_norm": 0.800231397151947,
      "learning_rate": 0.00045958055204780305,
      "loss": 0.7847,
      "step": 250600
    },
    {
      "epoch": 2.6534794967208515,
      "grad_norm": 0.9100946187973022,
      "learning_rate": 0.00045955536558810227,
      "loss": 0.7641,
      "step": 250650
    },
    {
      "epoch": 2.654008818500855,
      "grad_norm": 0.8949838280677795,
      "learning_rate": 0.00045953017197425817,
      "loss": 0.7712,
      "step": 250700
    },
    {
      "epoch": 2.654538140280858,
      "grad_norm": 0.8651447892189026,
      "learning_rate": 0.0004595049712071308,
      "loss": 0.7656,
      "step": 250750
    },
    {
      "epoch": 2.6550674620608614,
      "grad_norm": 0.9403283596038818,
      "learning_rate": 0.00045947976328758054,
      "loss": 0.742,
      "step": 250800
    },
    {
      "epoch": 2.6555967838408647,
      "grad_norm": 0.8196633458137512,
      "learning_rate": 0.000459454548216468,
      "loss": 0.7593,
      "step": 250850
    },
    {
      "epoch": 2.656126105620868,
      "grad_norm": 0.8134927749633789,
      "learning_rate": 0.0004594293259946541,
      "loss": 0.7553,
      "step": 250900
    },
    {
      "epoch": 2.6566554274008713,
      "grad_norm": 0.9639232158660889,
      "learning_rate": 0.00045940409662299976,
      "loss": 0.7654,
      "step": 250950
    },
    {
      "epoch": 2.6571847491808747,
      "grad_norm": 0.9633243680000305,
      "learning_rate": 0.0004593788601023663,
      "loss": 0.7638,
      "step": 251000
    },
    {
      "epoch": 2.6571847491808747,
      "eval_loss": 0.5699190497398376,
      "eval_runtime": 46.8585,
      "eval_samples_per_second": 3583.765,
      "eval_steps_per_second": 447.987,
      "step": 251000
    },
    {
      "epoch": 2.657714070960878,
      "grad_norm": 0.934992790222168,
      "learning_rate": 0.0004593536164336154,
      "loss": 0.7767,
      "step": 251050
    },
    {
      "epoch": 2.6582433927408813,
      "grad_norm": 0.9046514630317688,
      "learning_rate": 0.00045932836561760884,
      "loss": 0.777,
      "step": 251100
    },
    {
      "epoch": 2.658772714520884,
      "grad_norm": 0.8772452473640442,
      "learning_rate": 0.0004593031076552086,
      "loss": 0.772,
      "step": 251150
    },
    {
      "epoch": 2.659302036300888,
      "grad_norm": 0.8736557960510254,
      "learning_rate": 0.000459277842547277,
      "loss": 0.7523,
      "step": 251200
    },
    {
      "epoch": 2.6598313580808908,
      "grad_norm": 0.8794101476669312,
      "learning_rate": 0.0004592525702946766,
      "loss": 0.7705,
      "step": 251250
    },
    {
      "epoch": 2.660360679860894,
      "grad_norm": 0.9421746134757996,
      "learning_rate": 0.0004592272908982702,
      "loss": 0.7702,
      "step": 251300
    },
    {
      "epoch": 2.6608900016408974,
      "grad_norm": 0.9008156657218933,
      "learning_rate": 0.0004592020043589209,
      "loss": 0.7846,
      "step": 251350
    },
    {
      "epoch": 2.6614193234209007,
      "grad_norm": 0.8562629818916321,
      "learning_rate": 0.0004591767106774918,
      "loss": 0.7691,
      "step": 251400
    },
    {
      "epoch": 2.661948645200904,
      "grad_norm": 0.9434412717819214,
      "learning_rate": 0.0004591514098548466,
      "loss": 0.7684,
      "step": 251450
    },
    {
      "epoch": 2.6624779669809073,
      "grad_norm": 0.9496011734008789,
      "learning_rate": 0.0004591261018918489,
      "loss": 0.7619,
      "step": 251500
    },
    {
      "epoch": 2.6624779669809073,
      "eval_loss": 0.5725921988487244,
      "eval_runtime": 46.8371,
      "eval_samples_per_second": 3585.404,
      "eval_steps_per_second": 448.191,
      "step": 251500
    },
    {
      "epoch": 2.6630072887609106,
      "grad_norm": 1.0260820388793945,
      "learning_rate": 0.0004591007867893627,
      "loss": 0.7625,
      "step": 251550
    },
    {
      "epoch": 2.663536610540914,
      "grad_norm": 0.9444285035133362,
      "learning_rate": 0.0004590754645482525,
      "loss": 0.7755,
      "step": 251600
    },
    {
      "epoch": 2.6640659323209173,
      "grad_norm": 0.877209484577179,
      "learning_rate": 0.00045905013516938254,
      "loss": 0.7666,
      "step": 251650
    },
    {
      "epoch": 2.6645952541009206,
      "grad_norm": 0.909414529800415,
      "learning_rate": 0.0004590247986536176,
      "loss": 0.7702,
      "step": 251700
    },
    {
      "epoch": 2.665124575880924,
      "grad_norm": 0.9417293667793274,
      "learning_rate": 0.0004589994550018227,
      "loss": 0.7712,
      "step": 251750
    },
    {
      "epoch": 2.665653897660927,
      "grad_norm": 0.9694765210151672,
      "learning_rate": 0.00045897410421486315,
      "loss": 0.7662,
      "step": 251800
    },
    {
      "epoch": 2.6661832194409305,
      "grad_norm": 0.9099129438400269,
      "learning_rate": 0.0004589487462936042,
      "loss": 0.7757,
      "step": 251850
    },
    {
      "epoch": 2.6667125412209334,
      "grad_norm": 0.870426595211029,
      "learning_rate": 0.0004589233812389118,
      "loss": 0.7714,
      "step": 251900
    },
    {
      "epoch": 2.667241863000937,
      "grad_norm": 0.910529375076294,
      "learning_rate": 0.00045889800905165164,
      "loss": 0.7729,
      "step": 251950
    },
    {
      "epoch": 2.66777118478094,
      "grad_norm": 1.0055814981460571,
      "learning_rate": 0.0004588726297326902,
      "loss": 0.7859,
      "step": 252000
    },
    {
      "epoch": 2.66777118478094,
      "eval_loss": 0.5730180740356445,
      "eval_runtime": 46.8266,
      "eval_samples_per_second": 3586.21,
      "eval_steps_per_second": 448.292,
      "step": 252000
    },
    {
      "epoch": 2.6683005065609433,
      "grad_norm": 0.9302129745483398,
      "learning_rate": 0.00045884724328289363,
      "loss": 0.7516,
      "step": 252050
    },
    {
      "epoch": 2.6688298283409466,
      "grad_norm": 0.9200196266174316,
      "learning_rate": 0.0004588218497031289,
      "loss": 0.77,
      "step": 252100
    },
    {
      "epoch": 2.66935915012095,
      "grad_norm": 0.9086043834686279,
      "learning_rate": 0.00045879644899426275,
      "loss": 0.7659,
      "step": 252150
    },
    {
      "epoch": 2.6698884719009532,
      "grad_norm": 0.8630170226097107,
      "learning_rate": 0.0004587710411571624,
      "loss": 0.7696,
      "step": 252200
    },
    {
      "epoch": 2.6704177936809566,
      "grad_norm": 0.9464215636253357,
      "learning_rate": 0.00045874562619269534,
      "loss": 0.7674,
      "step": 252250
    },
    {
      "epoch": 2.67094711546096,
      "grad_norm": 0.9012574553489685,
      "learning_rate": 0.0004587202041017291,
      "loss": 0.7701,
      "step": 252300
    },
    {
      "epoch": 2.671476437240963,
      "grad_norm": 0.8285256624221802,
      "learning_rate": 0.00045869477488513153,
      "loss": 0.7745,
      "step": 252350
    },
    {
      "epoch": 2.6720057590209665,
      "grad_norm": 1.0148348808288574,
      "learning_rate": 0.000458669338543771,
      "loss": 0.7614,
      "step": 252400
    },
    {
      "epoch": 2.67253508080097,
      "grad_norm": 0.8685863018035889,
      "learning_rate": 0.0004586444040176295,
      "loss": 0.7682,
      "step": 252450
    },
    {
      "epoch": 2.673064402580973,
      "grad_norm": 0.8979908227920532,
      "learning_rate": 0.0004586189535718002,
      "loss": 0.7674,
      "step": 252500
    },
    {
      "epoch": 2.673064402580973,
      "eval_loss": 0.5703927278518677,
      "eval_runtime": 46.8554,
      "eval_samples_per_second": 3584.008,
      "eval_steps_per_second": 448.017,
      "step": 252500
    },
    {
      "epoch": 2.6735937243609764,
      "grad_norm": 1.0552332401275635,
      "learning_rate": 0.00045859349600379634,
      "loss": 0.7602,
      "step": 252550
    },
    {
      "epoch": 2.6741230461409797,
      "grad_norm": 0.924399733543396,
      "learning_rate": 0.00045856803131448705,
      "loss": 0.7646,
      "step": 252600
    },
    {
      "epoch": 2.6746523679209826,
      "grad_norm": 0.8747146725654602,
      "learning_rate": 0.0004585425595047417,
      "loss": 0.777,
      "step": 252650
    },
    {
      "epoch": 2.6751816897009864,
      "grad_norm": 0.8972654938697815,
      "learning_rate": 0.0004585170805754297,
      "loss": 0.7635,
      "step": 252700
    },
    {
      "epoch": 2.675711011480989,
      "grad_norm": 0.8828042149543762,
      "learning_rate": 0.00045849159452742116,
      "loss": 0.7697,
      "step": 252750
    },
    {
      "epoch": 2.6762403332609925,
      "grad_norm": 0.8336027264595032,
      "learning_rate": 0.00045846610136158605,
      "loss": 0.7571,
      "step": 252800
    },
    {
      "epoch": 2.676769655040996,
      "grad_norm": 0.9847211837768555,
      "learning_rate": 0.00045844060107879466,
      "loss": 0.7632,
      "step": 252850
    },
    {
      "epoch": 2.677298976820999,
      "grad_norm": 0.939238429069519,
      "learning_rate": 0.00045841509367991755,
      "loss": 0.7622,
      "step": 252900
    },
    {
      "epoch": 2.6778282986010025,
      "grad_norm": 0.9030537009239197,
      "learning_rate": 0.00045838957916582567,
      "loss": 0.761,
      "step": 252950
    },
    {
      "epoch": 2.6783576203810058,
      "grad_norm": 0.9664579629898071,
      "learning_rate": 0.0004583640575373899,
      "loss": 0.7563,
      "step": 253000
    },
    {
      "epoch": 2.6783576203810058,
      "eval_loss": 0.5707119703292847,
      "eval_runtime": 46.7842,
      "eval_samples_per_second": 3589.457,
      "eval_steps_per_second": 448.698,
      "step": 253000
    },
    {
      "epoch": 2.678886942161009,
      "grad_norm": 0.9452174305915833,
      "learning_rate": 0.00045833852879548166,
      "loss": 0.7508,
      "step": 253050
    },
    {
      "epoch": 2.6794162639410124,
      "grad_norm": 0.8284553289413452,
      "learning_rate": 0.0004583129929409725,
      "loss": 0.782,
      "step": 253100
    },
    {
      "epoch": 2.6799455857210157,
      "grad_norm": 0.8468209505081177,
      "learning_rate": 0.00045828744997473405,
      "loss": 0.7768,
      "step": 253150
    },
    {
      "epoch": 2.680474907501019,
      "grad_norm": 0.9880785942077637,
      "learning_rate": 0.00045826189989763857,
      "loss": 0.7841,
      "step": 253200
    },
    {
      "epoch": 2.6810042292810223,
      "grad_norm": 1.0355582237243652,
      "learning_rate": 0.00045823634271055806,
      "loss": 0.7697,
      "step": 253250
    },
    {
      "epoch": 2.6815335510610256,
      "grad_norm": 0.9333813786506653,
      "learning_rate": 0.0004582107784143653,
      "loss": 0.7719,
      "step": 253300
    },
    {
      "epoch": 2.682062872841029,
      "grad_norm": 0.8923082947731018,
      "learning_rate": 0.0004581852070099328,
      "loss": 0.7672,
      "step": 253350
    },
    {
      "epoch": 2.682592194621032,
      "grad_norm": 0.9791749715805054,
      "learning_rate": 0.0004581596284981339,
      "loss": 0.7617,
      "step": 253400
    },
    {
      "epoch": 2.6831215164010356,
      "grad_norm": 0.9495792984962463,
      "learning_rate": 0.0004581340428798414,
      "loss": 0.7762,
      "step": 253450
    },
    {
      "epoch": 2.6836508381810384,
      "grad_norm": 0.884377121925354,
      "learning_rate": 0.0004581084501559291,
      "loss": 0.7526,
      "step": 253500
    },
    {
      "epoch": 2.6836508381810384,
      "eval_loss": 0.5736930966377258,
      "eval_runtime": 46.8113,
      "eval_samples_per_second": 3587.384,
      "eval_steps_per_second": 448.439,
      "step": 253500
    },
    {
      "epoch": 2.6841801599610418,
      "grad_norm": 0.9180301427841187,
      "learning_rate": 0.00045808285032727063,
      "loss": 0.7766,
      "step": 253550
    },
    {
      "epoch": 2.684709481741045,
      "grad_norm": 0.9251775145530701,
      "learning_rate": 0.00045805724339473996,
      "loss": 0.7731,
      "step": 253600
    },
    {
      "epoch": 2.6852388035210484,
      "grad_norm": 0.9801978468894958,
      "learning_rate": 0.00045803162935921125,
      "loss": 0.7605,
      "step": 253650
    },
    {
      "epoch": 2.6857681253010517,
      "grad_norm": 0.8141907453536987,
      "learning_rate": 0.0004580060082215591,
      "loss": 0.7665,
      "step": 253700
    },
    {
      "epoch": 2.686297447081055,
      "grad_norm": 0.9385071396827698,
      "learning_rate": 0.00045798037998265805,
      "loss": 0.7641,
      "step": 253750
    },
    {
      "epoch": 2.6868267688610583,
      "grad_norm": 0.9308224320411682,
      "learning_rate": 0.00045795474464338314,
      "loss": 0.7692,
      "step": 253800
    },
    {
      "epoch": 2.6873560906410616,
      "grad_norm": 1.0240072011947632,
      "learning_rate": 0.0004579291022046095,
      "loss": 0.7622,
      "step": 253850
    },
    {
      "epoch": 2.687885412421065,
      "grad_norm": 0.8682945966720581,
      "learning_rate": 0.00045790345266721253,
      "loss": 0.7633,
      "step": 253900
    },
    {
      "epoch": 2.6884147342010682,
      "grad_norm": 0.885726273059845,
      "learning_rate": 0.00045787779603206804,
      "loss": 0.7608,
      "step": 253950
    },
    {
      "epoch": 2.6889440559810716,
      "grad_norm": 0.8475411534309387,
      "learning_rate": 0.00045785213230005174,
      "loss": 0.7563,
      "step": 254000
    },
    {
      "epoch": 2.6889440559810716,
      "eval_loss": 0.5702332258224487,
      "eval_runtime": 46.8358,
      "eval_samples_per_second": 3585.503,
      "eval_steps_per_second": 448.204,
      "step": 254000
    },
    {
      "epoch": 2.689473377761075,
      "grad_norm": 0.9445204734802246,
      "learning_rate": 0.0004578264614720399,
      "loss": 0.7488,
      "step": 254050
    },
    {
      "epoch": 2.690002699541078,
      "grad_norm": 0.8424654006958008,
      "learning_rate": 0.0004578007835489089,
      "loss": 0.7668,
      "step": 254100
    },
    {
      "epoch": 2.690532021321081,
      "grad_norm": 0.912914514541626,
      "learning_rate": 0.00045777509853153525,
      "loss": 0.7623,
      "step": 254150
    },
    {
      "epoch": 2.691061343101085,
      "grad_norm": 0.8921496272087097,
      "learning_rate": 0.000457749406420796,
      "loss": 0.7592,
      "step": 254200
    },
    {
      "epoch": 2.6915906648810877,
      "grad_norm": 0.9503680467605591,
      "learning_rate": 0.0004577237072175683,
      "loss": 0.775,
      "step": 254250
    },
    {
      "epoch": 2.692119986661091,
      "grad_norm": 0.8481307625770569,
      "learning_rate": 0.00045769800092272927,
      "loss": 0.7759,
      "step": 254300
    },
    {
      "epoch": 2.6926493084410943,
      "grad_norm": 0.8173128962516785,
      "learning_rate": 0.00045767228753715674,
      "loss": 0.7573,
      "step": 254350
    },
    {
      "epoch": 2.6931786302210976,
      "grad_norm": 0.9015728831291199,
      "learning_rate": 0.0004576465670617285,
      "loss": 0.7728,
      "step": 254400
    },
    {
      "epoch": 2.693707952001101,
      "grad_norm": 0.9518148303031921,
      "learning_rate": 0.00045762083949732257,
      "loss": 0.7697,
      "step": 254450
    },
    {
      "epoch": 2.6942372737811042,
      "grad_norm": 0.9212262630462646,
      "learning_rate": 0.0004575956196073251,
      "loss": 0.7696,
      "step": 254500
    },
    {
      "epoch": 2.6942372737811042,
      "eval_loss": 0.5702075958251953,
      "eval_runtime": 46.7453,
      "eval_samples_per_second": 3592.444,
      "eval_steps_per_second": 449.072,
      "step": 254500
    },
    {
      "epoch": 2.6947665955611075,
      "grad_norm": 0.9406660795211792,
      "learning_rate": 0.0004575698780093349,
      "loss": 0.756,
      "step": 254550
    },
    {
      "epoch": 2.695295917341111,
      "grad_norm": 0.877277672290802,
      "learning_rate": 0.00045754412932498523,
      "loss": 0.7649,
      "step": 254600
    },
    {
      "epoch": 2.695825239121114,
      "grad_norm": 0.9374147057533264,
      "learning_rate": 0.00045751837355515504,
      "loss": 0.7676,
      "step": 254650
    },
    {
      "epoch": 2.6963545609011175,
      "grad_norm": 0.8825996518135071,
      "learning_rate": 0.00045749261070072376,
      "loss": 0.7644,
      "step": 254700
    },
    {
      "epoch": 2.696883882681121,
      "grad_norm": 0.9854451417922974,
      "learning_rate": 0.0004574668407625708,
      "loss": 0.7786,
      "step": 254750
    },
    {
      "epoch": 2.697413204461124,
      "grad_norm": 1.01381254196167,
      "learning_rate": 0.000457441063741576,
      "loss": 0.7616,
      "step": 254800
    },
    {
      "epoch": 2.6979425262411274,
      "grad_norm": 0.8609418869018555,
      "learning_rate": 0.0004574152796386193,
      "loss": 0.7665,
      "step": 254850
    },
    {
      "epoch": 2.6984718480211303,
      "grad_norm": 0.932508647441864,
      "learning_rate": 0.0004573894884545811,
      "loss": 0.7668,
      "step": 254900
    },
    {
      "epoch": 2.699001169801134,
      "grad_norm": 0.9633793234825134,
      "learning_rate": 0.00045736369019034175,
      "loss": 0.7879,
      "step": 254950
    },
    {
      "epoch": 2.699530491581137,
      "grad_norm": 0.9632471799850464,
      "learning_rate": 0.0004573378848467821,
      "loss": 0.7669,
      "step": 255000
    },
    {
      "epoch": 2.699530491581137,
      "eval_loss": 0.5671725869178772,
      "eval_runtime": 46.8472,
      "eval_samples_per_second": 3584.629,
      "eval_steps_per_second": 448.095,
      "step": 255000
    },
    {
      "epoch": 2.7000598133611406,
      "grad_norm": 0.9681175947189331,
      "learning_rate": 0.0004573120724247831,
      "loss": 0.755,
      "step": 255050
    },
    {
      "epoch": 2.7005891351411435,
      "grad_norm": 0.9147297143936157,
      "learning_rate": 0.00045728625292522596,
      "loss": 0.7591,
      "step": 255100
    },
    {
      "epoch": 2.701118456921147,
      "grad_norm": 0.851168155670166,
      "learning_rate": 0.0004572604263489922,
      "loss": 0.7631,
      "step": 255150
    },
    {
      "epoch": 2.70164777870115,
      "grad_norm": 0.8995298743247986,
      "learning_rate": 0.00045723459269696344,
      "loss": 0.7586,
      "step": 255200
    },
    {
      "epoch": 2.7021771004811534,
      "grad_norm": 0.9217143058776855,
      "learning_rate": 0.00045720875197002175,
      "loss": 0.7748,
      "step": 255250
    },
    {
      "epoch": 2.7027064222611568,
      "grad_norm": 0.8796650171279907,
      "learning_rate": 0.0004571829041690493,
      "loss": 0.7538,
      "step": 255300
    },
    {
      "epoch": 2.70323574404116,
      "grad_norm": 0.8393569588661194,
      "learning_rate": 0.00045715704929492836,
      "loss": 0.7673,
      "step": 255350
    },
    {
      "epoch": 2.7037650658211634,
      "grad_norm": 0.867983341217041,
      "learning_rate": 0.00045713118734854173,
      "loss": 0.7585,
      "step": 255400
    },
    {
      "epoch": 2.7042943876011667,
      "grad_norm": 0.9357102513313293,
      "learning_rate": 0.0004571053183307724,
      "loss": 0.7633,
      "step": 255450
    },
    {
      "epoch": 2.70482370938117,
      "grad_norm": 0.962361752986908,
      "learning_rate": 0.00045707944224250346,
      "loss": 0.7596,
      "step": 255500
    },
    {
      "epoch": 2.70482370938117,
      "eval_loss": 0.5676887631416321,
      "eval_runtime": 46.7933,
      "eval_samples_per_second": 3588.764,
      "eval_steps_per_second": 448.612,
      "step": 255500
    },
    {
      "epoch": 2.7053530311611733,
      "grad_norm": 0.9229382872581482,
      "learning_rate": 0.0004570535590846183,
      "loss": 0.7534,
      "step": 255550
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 1.0574461221694946,
      "learning_rate": 0.00045702766885800055,
      "loss": 0.7651,
      "step": 255600
    },
    {
      "epoch": 2.7064116747211795,
      "grad_norm": 0.9875370860099792,
      "learning_rate": 0.00045700177156353416,
      "loss": 0.769,
      "step": 255650
    },
    {
      "epoch": 2.7069409965011832,
      "grad_norm": 0.8840324878692627,
      "learning_rate": 0.00045697586720210313,
      "loss": 0.7612,
      "step": 255700
    },
    {
      "epoch": 2.707470318281186,
      "grad_norm": 0.9255844354629517,
      "learning_rate": 0.0004569499557745919,
      "loss": 0.7788,
      "step": 255750
    },
    {
      "epoch": 2.70799964006119,
      "grad_norm": 0.8231413960456848,
      "learning_rate": 0.00045692403728188514,
      "loss": 0.7623,
      "step": 255800
    },
    {
      "epoch": 2.7085289618411927,
      "grad_norm": 0.944341778755188,
      "learning_rate": 0.0004568981117248676,
      "loss": 0.7625,
      "step": 255850
    },
    {
      "epoch": 2.709058283621196,
      "grad_norm": 0.8993381261825562,
      "learning_rate": 0.00045687217910442437,
      "loss": 0.7633,
      "step": 255900
    },
    {
      "epoch": 2.7095876054011994,
      "grad_norm": 0.9814538955688477,
      "learning_rate": 0.00045684623942144085,
      "loss": 0.7601,
      "step": 255950
    },
    {
      "epoch": 2.7101169271812027,
      "grad_norm": 1.02820885181427,
      "learning_rate": 0.0004568202926768026,
      "loss": 0.7839,
      "step": 256000
    },
    {
      "epoch": 2.7101169271812027,
      "eval_loss": 0.5659200549125671,
      "eval_runtime": 46.8433,
      "eval_samples_per_second": 3584.932,
      "eval_steps_per_second": 448.133,
      "step": 256000
    },
    {
      "epoch": 2.710646248961206,
      "grad_norm": 0.9488318562507629,
      "learning_rate": 0.00045679433887139536,
      "loss": 0.755,
      "step": 256050
    },
    {
      "epoch": 2.7111755707412093,
      "grad_norm": 0.8656653165817261,
      "learning_rate": 0.0004567683780061053,
      "loss": 0.7621,
      "step": 256100
    },
    {
      "epoch": 2.7117048925212126,
      "grad_norm": 0.9850897789001465,
      "learning_rate": 0.00045674241008181854,
      "loss": 0.7616,
      "step": 256150
    },
    {
      "epoch": 2.712234214301216,
      "grad_norm": 0.9952206611633301,
      "learning_rate": 0.0004567164350994218,
      "loss": 0.7801,
      "step": 256200
    },
    {
      "epoch": 2.7127635360812192,
      "grad_norm": 0.9127472639083862,
      "learning_rate": 0.00045669045305980174,
      "loss": 0.7523,
      "step": 256250
    },
    {
      "epoch": 2.7132928578612225,
      "grad_norm": 0.9459616541862488,
      "learning_rate": 0.00045666446396384544,
      "loss": 0.7571,
      "step": 256300
    },
    {
      "epoch": 2.713822179641226,
      "grad_norm": 0.9725959897041321,
      "learning_rate": 0.00045663846781244014,
      "loss": 0.776,
      "step": 256350
    },
    {
      "epoch": 2.7143515014212287,
      "grad_norm": 1.0475748777389526,
      "learning_rate": 0.00045661246460647326,
      "loss": 0.7633,
      "step": 256400
    },
    {
      "epoch": 2.7148808232012325,
      "grad_norm": 0.9368988871574402,
      "learning_rate": 0.00045658645434683265,
      "loss": 0.7779,
      "step": 256450
    },
    {
      "epoch": 2.7154101449812353,
      "grad_norm": 0.96116042137146,
      "learning_rate": 0.0004565604370344063,
      "loss": 0.7681,
      "step": 256500
    },
    {
      "epoch": 2.7154101449812353,
      "eval_loss": 0.5656011700630188,
      "eval_runtime": 46.8047,
      "eval_samples_per_second": 3587.887,
      "eval_steps_per_second": 448.502,
      "step": 256500
    },
    {
      "epoch": 2.715939466761239,
      "grad_norm": 0.8731433153152466,
      "learning_rate": 0.00045653493322647166,
      "loss": 0.7635,
      "step": 256550
    },
    {
      "epoch": 2.716468788541242,
      "grad_norm": 0.91321861743927,
      "learning_rate": 0.0004565089019521501,
      "loss": 0.7641,
      "step": 256600
    },
    {
      "epoch": 2.7169981103212453,
      "grad_norm": 0.9328582286834717,
      "learning_rate": 0.00045648286362769033,
      "loss": 0.7723,
      "step": 256650
    },
    {
      "epoch": 2.7175274321012486,
      "grad_norm": 0.8498837947845459,
      "learning_rate": 0.00045645681825398133,
      "loss": 0.7719,
      "step": 256700
    },
    {
      "epoch": 2.718056753881252,
      "grad_norm": 0.8058111667633057,
      "learning_rate": 0.00045643076583191223,
      "loss": 0.7663,
      "step": 256750
    },
    {
      "epoch": 2.718586075661255,
      "grad_norm": 0.8456999659538269,
      "learning_rate": 0.0004564047063623725,
      "loss": 0.7479,
      "step": 256800
    },
    {
      "epoch": 2.7191153974412585,
      "grad_norm": 0.8672779202461243,
      "learning_rate": 0.0004563786398462519,
      "loss": 0.7495,
      "step": 256850
    },
    {
      "epoch": 2.719644719221262,
      "grad_norm": 0.9695810079574585,
      "learning_rate": 0.0004563525662844401,
      "loss": 0.7722,
      "step": 256900
    },
    {
      "epoch": 2.720174041001265,
      "grad_norm": 0.9733231067657471,
      "learning_rate": 0.00045632648567782744,
      "loss": 0.7562,
      "step": 256950
    },
    {
      "epoch": 2.7207033627812685,
      "grad_norm": 0.9584257006645203,
      "learning_rate": 0.0004563003980273042,
      "loss": 0.754,
      "step": 257000
    },
    {
      "epoch": 2.7207033627812685,
      "eval_loss": 0.5641900300979614,
      "eval_runtime": 46.7922,
      "eval_samples_per_second": 3588.846,
      "eval_steps_per_second": 448.622,
      "step": 257000
    },
    {
      "epoch": 2.7212326845612718,
      "grad_norm": 0.9467955827713013,
      "learning_rate": 0.000456274303333761,
      "loss": 0.7712,
      "step": 257050
    },
    {
      "epoch": 2.721762006341275,
      "grad_norm": 0.8958085775375366,
      "learning_rate": 0.0004562482015980888,
      "loss": 0.761,
      "step": 257100
    },
    {
      "epoch": 2.722291328121278,
      "grad_norm": 0.9976171851158142,
      "learning_rate": 0.00045622209282117853,
      "loss": 0.7688,
      "step": 257150
    },
    {
      "epoch": 2.7228206499012817,
      "grad_norm": 0.9020511507987976,
      "learning_rate": 0.0004561959770039218,
      "loss": 0.7693,
      "step": 257200
    },
    {
      "epoch": 2.7233499716812846,
      "grad_norm": 0.8460410833358765,
      "learning_rate": 0.0004561698541472099,
      "loss": 0.7635,
      "step": 257250
    },
    {
      "epoch": 2.7238792934612883,
      "grad_norm": 0.8694203495979309,
      "learning_rate": 0.00045614372425193485,
      "loss": 0.7544,
      "step": 257300
    },
    {
      "epoch": 2.724408615241291,
      "grad_norm": 1.0049000978469849,
      "learning_rate": 0.0004561175873189886,
      "loss": 0.7634,
      "step": 257350
    },
    {
      "epoch": 2.7249379370212945,
      "grad_norm": 1.0657199621200562,
      "learning_rate": 0.00045609144334926355,
      "loss": 0.7624,
      "step": 257400
    },
    {
      "epoch": 2.725467258801298,
      "grad_norm": 0.8694975972175598,
      "learning_rate": 0.00045606529234365223,
      "loss": 0.7688,
      "step": 257450
    },
    {
      "epoch": 2.725996580581301,
      "grad_norm": 0.9954065680503845,
      "learning_rate": 0.00045603913430304735,
      "loss": 0.7649,
      "step": 257500
    },
    {
      "epoch": 2.725996580581301,
      "eval_loss": 0.570626974105835,
      "eval_runtime": 46.823,
      "eval_samples_per_second": 3586.487,
      "eval_steps_per_second": 448.327,
      "step": 257500
    },
    {
      "epoch": 2.7265259023613044,
      "grad_norm": 0.9326767921447754,
      "learning_rate": 0.000456012969228342,
      "loss": 0.7768,
      "step": 257550
    },
    {
      "epoch": 2.7270552241413077,
      "grad_norm": 0.967339813709259,
      "learning_rate": 0.00045598679712042947,
      "loss": 0.7555,
      "step": 257600
    },
    {
      "epoch": 2.727584545921311,
      "grad_norm": 0.884290874004364,
      "learning_rate": 0.00045596061798020324,
      "loss": 0.7605,
      "step": 257650
    },
    {
      "epoch": 2.7281138677013144,
      "grad_norm": 0.9126117825508118,
      "learning_rate": 0.00045593443180855697,
      "loss": 0.7555,
      "step": 257700
    },
    {
      "epoch": 2.7286431894813177,
      "grad_norm": 1.0303668975830078,
      "learning_rate": 0.0004559082386063848,
      "loss": 0.7621,
      "step": 257750
    },
    {
      "epoch": 2.729172511261321,
      "grad_norm": 0.9637320041656494,
      "learning_rate": 0.00045588203837458087,
      "loss": 0.753,
      "step": 257800
    },
    {
      "epoch": 2.7297018330413243,
      "grad_norm": 1.0834683179855347,
      "learning_rate": 0.0004558558311140396,
      "loss": 0.7498,
      "step": 257850
    },
    {
      "epoch": 2.730231154821327,
      "grad_norm": 0.8923792243003845,
      "learning_rate": 0.00045582961682565575,
      "loss": 0.7581,
      "step": 257900
    },
    {
      "epoch": 2.730760476601331,
      "grad_norm": 0.8954473733901978,
      "learning_rate": 0.0004558033955103244,
      "loss": 0.7629,
      "step": 257950
    },
    {
      "epoch": 2.731289798381334,
      "grad_norm": 0.976452112197876,
      "learning_rate": 0.0004557771671689404,
      "loss": 0.7542,
      "step": 258000
    },
    {
      "epoch": 2.731289798381334,
      "eval_loss": 0.5642713308334351,
      "eval_runtime": 46.8555,
      "eval_samples_per_second": 3583.994,
      "eval_steps_per_second": 448.015,
      "step": 258000
    },
    {
      "epoch": 2.7318191201613375,
      "grad_norm": 0.896832287311554,
      "learning_rate": 0.0004557509318023995,
      "loss": 0.7723,
      "step": 258050
    },
    {
      "epoch": 2.7323484419413404,
      "grad_norm": 0.907508134841919,
      "learning_rate": 0.0004557246894115972,
      "loss": 0.7646,
      "step": 258100
    },
    {
      "epoch": 2.7328777637213437,
      "grad_norm": 0.8516595363616943,
      "learning_rate": 0.00045569843999742954,
      "loss": 0.773,
      "step": 258150
    },
    {
      "epoch": 2.733407085501347,
      "grad_norm": 0.9309577345848083,
      "learning_rate": 0.0004556721835607925,
      "loss": 0.7786,
      "step": 258200
    },
    {
      "epoch": 2.7339364072813503,
      "grad_norm": 0.8991547226905823,
      "learning_rate": 0.0004556459201025825,
      "loss": 0.7646,
      "step": 258250
    },
    {
      "epoch": 2.7344657290613537,
      "grad_norm": 0.9286292791366577,
      "learning_rate": 0.0004556196496236963,
      "loss": 0.7564,
      "step": 258300
    },
    {
      "epoch": 2.734995050841357,
      "grad_norm": 0.9117931723594666,
      "learning_rate": 0.0004555933721250306,
      "loss": 0.7693,
      "step": 258350
    },
    {
      "epoch": 2.7355243726213603,
      "grad_norm": 0.9637767672538757,
      "learning_rate": 0.00045556708760748267,
      "loss": 0.7738,
      "step": 258400
    },
    {
      "epoch": 2.7360536944013636,
      "grad_norm": 0.9287840127944946,
      "learning_rate": 0.00045554079607194967,
      "loss": 0.7708,
      "step": 258450
    },
    {
      "epoch": 2.736583016181367,
      "grad_norm": 0.8792869448661804,
      "learning_rate": 0.0004555144975193293,
      "loss": 0.7619,
      "step": 258500
    },
    {
      "epoch": 2.736583016181367,
      "eval_loss": 0.5661382079124451,
      "eval_runtime": 46.7842,
      "eval_samples_per_second": 3589.458,
      "eval_steps_per_second": 448.698,
      "step": 258500
    },
    {
      "epoch": 2.73711233796137,
      "grad_norm": 0.9460561275482178,
      "learning_rate": 0.0004554881919505194,
      "loss": 0.7555,
      "step": 258550
    },
    {
      "epoch": 2.7376416597413735,
      "grad_norm": 0.8750278353691101,
      "learning_rate": 0.00045546240568684394,
      "loss": 0.773,
      "step": 258600
    },
    {
      "epoch": 2.7381709815213764,
      "grad_norm": 0.9340724945068359,
      "learning_rate": 0.00045543608622862833,
      "loss": 0.766,
      "step": 258650
    },
    {
      "epoch": 2.73870030330138,
      "grad_norm": 0.9216595888137817,
      "learning_rate": 0.0004554097597569001,
      "loss": 0.754,
      "step": 258700
    },
    {
      "epoch": 2.739229625081383,
      "grad_norm": 0.9123044610023499,
      "learning_rate": 0.00045538342627255796,
      "loss": 0.7557,
      "step": 258750
    },
    {
      "epoch": 2.7397589468613868,
      "grad_norm": 0.9330013394355774,
      "learning_rate": 0.00045535708577650096,
      "loss": 0.7635,
      "step": 258800
    },
    {
      "epoch": 2.7402882686413896,
      "grad_norm": 0.881801187992096,
      "learning_rate": 0.0004553307382696285,
      "loss": 0.7577,
      "step": 258850
    },
    {
      "epoch": 2.740817590421393,
      "grad_norm": 0.9622759222984314,
      "learning_rate": 0.0004553043837528398,
      "loss": 0.7639,
      "step": 258900
    },
    {
      "epoch": 2.7413469122013963,
      "grad_norm": 0.8802405595779419,
      "learning_rate": 0.00045527802222703476,
      "loss": 0.7589,
      "step": 258950
    },
    {
      "epoch": 2.7418762339813996,
      "grad_norm": 0.9044885039329529,
      "learning_rate": 0.00045525165369311325,
      "loss": 0.7682,
      "step": 259000
    },
    {
      "epoch": 2.7418762339813996,
      "eval_loss": 0.560467004776001,
      "eval_runtime": 46.7254,
      "eval_samples_per_second": 3593.976,
      "eval_steps_per_second": 449.263,
      "step": 259000
    },
    {
      "epoch": 2.742405555761403,
      "grad_norm": 0.9091519117355347,
      "learning_rate": 0.0004552252781519757,
      "loss": 0.7653,
      "step": 259050
    },
    {
      "epoch": 2.742934877541406,
      "grad_norm": 0.8809993267059326,
      "learning_rate": 0.0004551988956045223,
      "loss": 0.7572,
      "step": 259100
    },
    {
      "epoch": 2.7434641993214095,
      "grad_norm": 0.8767798542976379,
      "learning_rate": 0.0004551725060516539,
      "loss": 0.7688,
      "step": 259150
    },
    {
      "epoch": 2.743993521101413,
      "grad_norm": 0.897709846496582,
      "learning_rate": 0.0004551461094942715,
      "loss": 0.7697,
      "step": 259200
    },
    {
      "epoch": 2.744522842881416,
      "grad_norm": 0.9234012365341187,
      "learning_rate": 0.000455119705933276,
      "loss": 0.7468,
      "step": 259250
    },
    {
      "epoch": 2.7450521646614194,
      "grad_norm": 0.9781632423400879,
      "learning_rate": 0.00045509329536956903,
      "loss": 0.748,
      "step": 259300
    },
    {
      "epoch": 2.7455814864414227,
      "grad_norm": 0.9280604720115662,
      "learning_rate": 0.00045506687780405217,
      "loss": 0.7536,
      "step": 259350
    },
    {
      "epoch": 2.7461108082214256,
      "grad_norm": 0.9365865588188171,
      "learning_rate": 0.0004550404532376273,
      "loss": 0.763,
      "step": 259400
    },
    {
      "epoch": 2.7466401300014294,
      "grad_norm": 0.9184763431549072,
      "learning_rate": 0.0004550140216711965,
      "loss": 0.7655,
      "step": 259450
    },
    {
      "epoch": 2.7471694517814322,
      "grad_norm": 0.808135986328125,
      "learning_rate": 0.0004549875831056623,
      "loss": 0.7578,
      "step": 259500
    },
    {
      "epoch": 2.7471694517814322,
      "eval_loss": 0.5632230043411255,
      "eval_runtime": 46.868,
      "eval_samples_per_second": 3583.045,
      "eval_steps_per_second": 447.897,
      "step": 259500
    },
    {
      "epoch": 2.747698773561436,
      "grad_norm": 0.896729588508606,
      "learning_rate": 0.00045496113754192716,
      "loss": 0.7591,
      "step": 259550
    },
    {
      "epoch": 2.748228095341439,
      "grad_norm": 0.9303597807884216,
      "learning_rate": 0.00045493468498089383,
      "loss": 0.7698,
      "step": 259600
    },
    {
      "epoch": 2.748757417121442,
      "grad_norm": 0.8621039390563965,
      "learning_rate": 0.00045490822542346566,
      "loss": 0.7578,
      "step": 259650
    },
    {
      "epoch": 2.7492867389014455,
      "grad_norm": 0.8668245077133179,
      "learning_rate": 0.00045488175887054575,
      "loss": 0.7579,
      "step": 259700
    },
    {
      "epoch": 2.749816060681449,
      "grad_norm": 0.8885913491249084,
      "learning_rate": 0.00045485528532303776,
      "loss": 0.7608,
      "step": 259750
    },
    {
      "epoch": 2.750345382461452,
      "grad_norm": 0.872772216796875,
      "learning_rate": 0.00045482880478184544,
      "loss": 0.7637,
      "step": 259800
    },
    {
      "epoch": 2.7508747042414554,
      "grad_norm": 0.8822914958000183,
      "learning_rate": 0.00045480231724787286,
      "loss": 0.7603,
      "step": 259850
    },
    {
      "epoch": 2.7514040260214587,
      "grad_norm": 0.9375269412994385,
      "learning_rate": 0.0004547758227220243,
      "loss": 0.7528,
      "step": 259900
    },
    {
      "epoch": 2.751933347801462,
      "grad_norm": 0.939261794090271,
      "learning_rate": 0.0004547493212052042,
      "loss": 0.7625,
      "step": 259950
    },
    {
      "epoch": 2.7524626695814653,
      "grad_norm": 0.9605021476745605,
      "learning_rate": 0.0004547228126983174,
      "loss": 0.7669,
      "step": 260000
    },
    {
      "epoch": 2.7524626695814653,
      "eval_loss": 0.5637000203132629,
      "eval_runtime": 46.803,
      "eval_samples_per_second": 3588.02,
      "eval_steps_per_second": 448.519,
      "step": 260000
    },
    {
      "epoch": 2.7529919913614687,
      "grad_norm": 0.9621586203575134,
      "learning_rate": 0.0004546962972022688,
      "loss": 0.7677,
      "step": 260050
    },
    {
      "epoch": 2.753521313141472,
      "grad_norm": 0.9907926321029663,
      "learning_rate": 0.0004546697747179637,
      "loss": 0.7515,
      "step": 260100
    },
    {
      "epoch": 2.754050634921475,
      "grad_norm": 0.8471060395240784,
      "learning_rate": 0.0004546432452463076,
      "loss": 0.7747,
      "step": 260150
    },
    {
      "epoch": 2.7545799567014786,
      "grad_norm": 0.9231572151184082,
      "learning_rate": 0.00045461670878820616,
      "loss": 0.7509,
      "step": 260200
    },
    {
      "epoch": 2.7551092784814815,
      "grad_norm": 0.9980965256690979,
      "learning_rate": 0.00045459016534456524,
      "loss": 0.7575,
      "step": 260250
    },
    {
      "epoch": 2.755638600261485,
      "grad_norm": 0.8879261016845703,
      "learning_rate": 0.0004545636149162912,
      "loss": 0.7743,
      "step": 260300
    },
    {
      "epoch": 2.756167922041488,
      "grad_norm": 0.9399625062942505,
      "learning_rate": 0.0004545370575042903,
      "loss": 0.7641,
      "step": 260350
    },
    {
      "epoch": 2.7566972438214914,
      "grad_norm": 0.8427020907402039,
      "learning_rate": 0.00045451049310946936,
      "loss": 0.7661,
      "step": 260400
    },
    {
      "epoch": 2.7572265656014947,
      "grad_norm": 0.9771683812141418,
      "learning_rate": 0.0004544839217327351,
      "loss": 0.7605,
      "step": 260450
    },
    {
      "epoch": 2.757755887381498,
      "grad_norm": 0.9194497466087341,
      "learning_rate": 0.0004544573433749948,
      "loss": 0.7656,
      "step": 260500
    },
    {
      "epoch": 2.757755887381498,
      "eval_loss": 0.5624698996543884,
      "eval_runtime": 46.8689,
      "eval_samples_per_second": 3582.975,
      "eval_steps_per_second": 447.888,
      "step": 260500
    },
    {
      "epoch": 2.7582852091615013,
      "grad_norm": 0.9972579479217529,
      "learning_rate": 0.00045443075803715575,
      "loss": 0.753,
      "step": 260550
    },
    {
      "epoch": 2.7588145309415046,
      "grad_norm": 0.9076142311096191,
      "learning_rate": 0.00045440416572012555,
      "loss": 0.7566,
      "step": 260600
    },
    {
      "epoch": 2.759343852721508,
      "grad_norm": 1.01237154006958,
      "learning_rate": 0.0004543775664248121,
      "loss": 0.7593,
      "step": 260650
    },
    {
      "epoch": 2.7598731745015113,
      "grad_norm": 0.9297758340835571,
      "learning_rate": 0.0004543509601521235,
      "loss": 0.7511,
      "step": 260700
    },
    {
      "epoch": 2.7604024962815146,
      "grad_norm": 0.8878214359283447,
      "learning_rate": 0.00045432434690296814,
      "loss": 0.7714,
      "step": 260750
    },
    {
      "epoch": 2.760931818061518,
      "grad_norm": 0.9753687977790833,
      "learning_rate": 0.00045429772667825445,
      "loss": 0.7493,
      "step": 260800
    },
    {
      "epoch": 2.761461139841521,
      "grad_norm": 0.9332022070884705,
      "learning_rate": 0.00045427109947889134,
      "loss": 0.7536,
      "step": 260850
    },
    {
      "epoch": 2.7619904616215245,
      "grad_norm": 0.9083845019340515,
      "learning_rate": 0.0004542449980575866,
      "loss": 0.7704,
      "step": 260900
    },
    {
      "epoch": 2.762519783401528,
      "grad_norm": 0.9628630876541138,
      "learning_rate": 0.0004542183570510996,
      "loss": 0.7812,
      "step": 260950
    },
    {
      "epoch": 2.7630491051815307,
      "grad_norm": 0.8712400794029236,
      "learning_rate": 0.00045419170907267276,
      "loss": 0.7521,
      "step": 261000
    },
    {
      "epoch": 2.7630491051815307,
      "eval_loss": 0.5585317611694336,
      "eval_runtime": 46.7877,
      "eval_samples_per_second": 3589.19,
      "eval_steps_per_second": 448.665,
      "step": 261000
    },
    {
      "epoch": 2.7635784269615344,
      "grad_norm": 0.9114975929260254,
      "learning_rate": 0.0004541650541232159,
      "loss": 0.7644,
      "step": 261050
    },
    {
      "epoch": 2.7641077487415373,
      "grad_norm": 0.9739205837249756,
      "learning_rate": 0.00045413839220363896,
      "loss": 0.7654,
      "step": 261100
    },
    {
      "epoch": 2.7646370705215406,
      "grad_norm": 1.0015482902526855,
      "learning_rate": 0.0004541117233148522,
      "loss": 0.7525,
      "step": 261150
    },
    {
      "epoch": 2.765166392301544,
      "grad_norm": 0.8793013095855713,
      "learning_rate": 0.00045408504745776603,
      "loss": 0.769,
      "step": 261200
    },
    {
      "epoch": 2.7656957140815472,
      "grad_norm": 0.9151006937026978,
      "learning_rate": 0.00045405836463329114,
      "loss": 0.77,
      "step": 261250
    },
    {
      "epoch": 2.7662250358615506,
      "grad_norm": 1.0054113864898682,
      "learning_rate": 0.00045403167484233856,
      "loss": 0.7629,
      "step": 261300
    },
    {
      "epoch": 2.766754357641554,
      "grad_norm": 0.954270601272583,
      "learning_rate": 0.0004540049780858194,
      "loss": 0.7521,
      "step": 261350
    },
    {
      "epoch": 2.767283679421557,
      "grad_norm": 0.9254149198532104,
      "learning_rate": 0.0004539782743646451,
      "loss": 0.7534,
      "step": 261400
    },
    {
      "epoch": 2.7678130012015605,
      "grad_norm": 0.9971495270729065,
      "learning_rate": 0.0004539515636797274,
      "loss": 0.762,
      "step": 261450
    },
    {
      "epoch": 2.768342322981564,
      "grad_norm": 0.9627190232276917,
      "learning_rate": 0.00045392484603197806,
      "loss": 0.752,
      "step": 261500
    },
    {
      "epoch": 2.768342322981564,
      "eval_loss": 0.5590957999229431,
      "eval_runtime": 46.8162,
      "eval_samples_per_second": 3587.008,
      "eval_steps_per_second": 448.392,
      "step": 261500
    },
    {
      "epoch": 2.768871644761567,
      "grad_norm": 0.9209994673728943,
      "learning_rate": 0.00045389812142230927,
      "loss": 0.7614,
      "step": 261550
    },
    {
      "epoch": 2.7694009665415704,
      "grad_norm": 0.9565548300743103,
      "learning_rate": 0.00045387138985163346,
      "loss": 0.7519,
      "step": 261600
    },
    {
      "epoch": 2.7699302883215737,
      "grad_norm": 0.8418442010879517,
      "learning_rate": 0.00045384465132086303,
      "loss": 0.7579,
      "step": 261650
    },
    {
      "epoch": 2.770459610101577,
      "grad_norm": 0.9421668648719788,
      "learning_rate": 0.0004538179058309111,
      "loss": 0.7662,
      "step": 261700
    },
    {
      "epoch": 2.77098893188158,
      "grad_norm": 0.8013993501663208,
      "learning_rate": 0.0004537911533826905,
      "loss": 0.7462,
      "step": 261750
    },
    {
      "epoch": 2.7715182536615837,
      "grad_norm": 0.8689724802970886,
      "learning_rate": 0.0004537643939771147,
      "loss": 0.7805,
      "step": 261800
    },
    {
      "epoch": 2.7720475754415865,
      "grad_norm": 0.9554393887519836,
      "learning_rate": 0.0004537376276150972,
      "loss": 0.7739,
      "step": 261850
    },
    {
      "epoch": 2.77257689722159,
      "grad_norm": 0.8651775121688843,
      "learning_rate": 0.0004537108542975519,
      "loss": 0.7601,
      "step": 261900
    },
    {
      "epoch": 2.773106219001593,
      "grad_norm": 0.9630709290504456,
      "learning_rate": 0.0004536840740253927,
      "loss": 0.7435,
      "step": 261950
    },
    {
      "epoch": 2.7736355407815965,
      "grad_norm": 0.9348300695419312,
      "learning_rate": 0.0004536572867995339,
      "loss": 0.7427,
      "step": 262000
    },
    {
      "epoch": 2.7736355407815965,
      "eval_loss": 0.5593215823173523,
      "eval_runtime": 46.7818,
      "eval_samples_per_second": 3589.648,
      "eval_steps_per_second": 448.722,
      "step": 262000
    },
    {
      "epoch": 2.7741648625615998,
      "grad_norm": 0.9005184173583984,
      "learning_rate": 0.00045363049262088994,
      "loss": 0.7693,
      "step": 262050
    },
    {
      "epoch": 2.774694184341603,
      "grad_norm": 0.9928180575370789,
      "learning_rate": 0.0004536036914903757,
      "loss": 0.7564,
      "step": 262100
    },
    {
      "epoch": 2.7752235061216064,
      "grad_norm": 0.8684099316596985,
      "learning_rate": 0.0004535768834089061,
      "loss": 0.7631,
      "step": 262150
    },
    {
      "epoch": 2.7757528279016097,
      "grad_norm": 0.9427487254142761,
      "learning_rate": 0.00045355006837739646,
      "loss": 0.7554,
      "step": 262200
    },
    {
      "epoch": 2.776282149681613,
      "grad_norm": 0.8724877238273621,
      "learning_rate": 0.000453523246396762,
      "loss": 0.7461,
      "step": 262250
    },
    {
      "epoch": 2.7768114714616163,
      "grad_norm": 0.9025291204452515,
      "learning_rate": 0.0004534964174679186,
      "loss": 0.7603,
      "step": 262300
    },
    {
      "epoch": 2.7773407932416196,
      "grad_norm": 0.869646430015564,
      "learning_rate": 0.00045346958159178213,
      "loss": 0.7375,
      "step": 262350
    },
    {
      "epoch": 2.777870115021623,
      "grad_norm": 0.922753632068634,
      "learning_rate": 0.00045344273876926877,
      "loss": 0.7528,
      "step": 262400
    },
    {
      "epoch": 2.7783994368016263,
      "grad_norm": 0.8704828023910522,
      "learning_rate": 0.0004534158890012949,
      "loss": 0.772,
      "step": 262450
    },
    {
      "epoch": 2.778928758581629,
      "grad_norm": 0.8688459992408752,
      "learning_rate": 0.00045338903228877723,
      "loss": 0.7641,
      "step": 262500
    },
    {
      "epoch": 2.778928758581629,
      "eval_loss": 0.5657867193222046,
      "eval_runtime": 46.818,
      "eval_samples_per_second": 3586.867,
      "eval_steps_per_second": 448.374,
      "step": 262500
    },
    {
      "epoch": 2.779458080361633,
      "grad_norm": 0.8439990282058716,
      "learning_rate": 0.00045336216863263256,
      "loss": 0.7571,
      "step": 262550
    },
    {
      "epoch": 2.7799874021416358,
      "grad_norm": 0.9010390043258667,
      "learning_rate": 0.000453335298033778,
      "loss": 0.7633,
      "step": 262600
    },
    {
      "epoch": 2.780516723921639,
      "grad_norm": 0.9073858261108398,
      "learning_rate": 0.000453308420493131,
      "loss": 0.7616,
      "step": 262650
    },
    {
      "epoch": 2.7810460457016424,
      "grad_norm": 0.9084360599517822,
      "learning_rate": 0.00045328153601160905,
      "loss": 0.7691,
      "step": 262700
    },
    {
      "epoch": 2.7815753674816457,
      "grad_norm": 0.9105144739151001,
      "learning_rate": 0.00045325464459013,
      "loss": 0.772,
      "step": 262750
    },
    {
      "epoch": 2.782104689261649,
      "grad_norm": 0.8035064935684204,
      "learning_rate": 0.00045322774622961196,
      "loss": 0.7584,
      "step": 262800
    },
    {
      "epoch": 2.7826340110416523,
      "grad_norm": 0.8595903515815735,
      "learning_rate": 0.0004532008409309732,
      "loss": 0.7554,
      "step": 262850
    },
    {
      "epoch": 2.7831633328216556,
      "grad_norm": 0.9636496901512146,
      "learning_rate": 0.0004531739286951322,
      "loss": 0.7578,
      "step": 262900
    },
    {
      "epoch": 2.783692654601659,
      "grad_norm": 0.8674519658088684,
      "learning_rate": 0.00045314754797441995,
      "loss": 0.7558,
      "step": 262950
    },
    {
      "epoch": 2.7842219763816622,
      "grad_norm": 0.9124942421913147,
      "learning_rate": 0.0004531206220056294,
      "loss": 0.7628,
      "step": 263000
    },
    {
      "epoch": 2.7842219763816622,
      "eval_loss": 0.5576251745223999,
      "eval_runtime": 46.7862,
      "eval_samples_per_second": 3589.305,
      "eval_steps_per_second": 448.679,
      "step": 263000
    },
    {
      "epoch": 2.7847512981616656,
      "grad_norm": 0.9302324056625366,
      "learning_rate": 0.0004530936891023754,
      "loss": 0.7707,
      "step": 263050
    },
    {
      "epoch": 2.785280619941669,
      "grad_norm": 0.875695526599884,
      "learning_rate": 0.0004530667492655773,
      "loss": 0.7526,
      "step": 263100
    },
    {
      "epoch": 2.785809941721672,
      "grad_norm": 0.9091410040855408,
      "learning_rate": 0.00045303980249615484,
      "loss": 0.7514,
      "step": 263150
    },
    {
      "epoch": 2.7863392635016755,
      "grad_norm": 0.7840673327445984,
      "learning_rate": 0.0004530128487950279,
      "loss": 0.7527,
      "step": 263200
    },
    {
      "epoch": 2.7868685852816784,
      "grad_norm": 0.9923617839813232,
      "learning_rate": 0.00045298588816311693,
      "loss": 0.7629,
      "step": 263250
    },
    {
      "epoch": 2.787397907061682,
      "grad_norm": 0.8801649212837219,
      "learning_rate": 0.000452958920601342,
      "loss": 0.7686,
      "step": 263300
    },
    {
      "epoch": 2.787927228841685,
      "grad_norm": 0.856803297996521,
      "learning_rate": 0.0004529319461106241,
      "loss": 0.7594,
      "step": 263350
    },
    {
      "epoch": 2.7884565506216883,
      "grad_norm": 0.937039852142334,
      "learning_rate": 0.0004529049646918839,
      "loss": 0.7555,
      "step": 263400
    },
    {
      "epoch": 2.7889858724016916,
      "grad_norm": 0.9402806162834167,
      "learning_rate": 0.00045287797634604266,
      "loss": 0.7616,
      "step": 263450
    },
    {
      "epoch": 2.789515194181695,
      "grad_norm": 0.9648076295852661,
      "learning_rate": 0.0004528509810740217,
      "loss": 0.7552,
      "step": 263500
    },
    {
      "epoch": 2.789515194181695,
      "eval_loss": 0.5604732632637024,
      "eval_runtime": 46.7782,
      "eval_samples_per_second": 3589.922,
      "eval_steps_per_second": 448.756,
      "step": 263500
    },
    {
      "epoch": 2.7900445159616982,
      "grad_norm": 0.9084430932998657,
      "learning_rate": 0.00045282397887674267,
      "loss": 0.7576,
      "step": 263550
    },
    {
      "epoch": 2.7905738377417015,
      "grad_norm": 0.9726356863975525,
      "learning_rate": 0.0004527969697551273,
      "loss": 0.752,
      "step": 263600
    },
    {
      "epoch": 2.791103159521705,
      "grad_norm": 0.8905085325241089,
      "learning_rate": 0.0004527699537100978,
      "loss": 0.7601,
      "step": 263650
    },
    {
      "epoch": 2.791632481301708,
      "grad_norm": 0.9111749529838562,
      "learning_rate": 0.00045274293074257644,
      "loss": 0.7625,
      "step": 263700
    },
    {
      "epoch": 2.7921618030817115,
      "grad_norm": 0.8792513608932495,
      "learning_rate": 0.0004527159008534858,
      "loss": 0.7646,
      "step": 263750
    },
    {
      "epoch": 2.792691124861715,
      "grad_norm": 0.8792306780815125,
      "learning_rate": 0.00045268886404374863,
      "loss": 0.7743,
      "step": 263800
    },
    {
      "epoch": 2.793220446641718,
      "grad_norm": 0.9645464420318604,
      "learning_rate": 0.00045266182031428805,
      "loss": 0.7562,
      "step": 263850
    },
    {
      "epoch": 2.7937497684217214,
      "grad_norm": 0.9325474500656128,
      "learning_rate": 0.00045263476966602714,
      "loss": 0.7585,
      "step": 263900
    },
    {
      "epoch": 2.7942790902017247,
      "grad_norm": 0.9929415583610535,
      "learning_rate": 0.0004526077120998895,
      "loss": 0.7591,
      "step": 263950
    },
    {
      "epoch": 2.7948084119817276,
      "grad_norm": 0.9700114130973816,
      "learning_rate": 0.00045258064761679895,
      "loss": 0.7564,
      "step": 264000
    },
    {
      "epoch": 2.7948084119817276,
      "eval_loss": 0.556521475315094,
      "eval_runtime": 46.8529,
      "eval_samples_per_second": 3584.193,
      "eval_steps_per_second": 448.04,
      "step": 264000
    },
    {
      "epoch": 2.7953377337617313,
      "grad_norm": 0.9793872237205505,
      "learning_rate": 0.0004525535762176793,
      "loss": 0.7632,
      "step": 264050
    },
    {
      "epoch": 2.795867055541734,
      "grad_norm": 0.8388285636901855,
      "learning_rate": 0.00045252649790345503,
      "loss": 0.7395,
      "step": 264100
    },
    {
      "epoch": 2.7963963773217375,
      "grad_norm": 0.9291736483573914,
      "learning_rate": 0.00045249941267505025,
      "loss": 0.7584,
      "step": 264150
    },
    {
      "epoch": 2.796925699101741,
      "grad_norm": 0.8831802010536194,
      "learning_rate": 0.00045247232053338975,
      "loss": 0.7469,
      "step": 264200
    },
    {
      "epoch": 2.797455020881744,
      "grad_norm": 0.9445236921310425,
      "learning_rate": 0.0004524452214793986,
      "loss": 0.7784,
      "step": 264250
    },
    {
      "epoch": 2.7979843426617474,
      "grad_norm": 0.8769875168800354,
      "learning_rate": 0.0004524181155140017,
      "loss": 0.762,
      "step": 264300
    },
    {
      "epoch": 2.7985136644417508,
      "grad_norm": 0.9983562231063843,
      "learning_rate": 0.00045239100263812465,
      "loss": 0.7632,
      "step": 264350
    },
    {
      "epoch": 2.799042986221754,
      "grad_norm": 0.9990386366844177,
      "learning_rate": 0.000452363882852693,
      "loss": 0.7654,
      "step": 264400
    },
    {
      "epoch": 2.7995723080017574,
      "grad_norm": 0.9075110554695129,
      "learning_rate": 0.0004523367561586326,
      "loss": 0.7468,
      "step": 264450
    },
    {
      "epoch": 2.8001016297817607,
      "grad_norm": 0.9589584469795227,
      "learning_rate": 0.0004523096225568695,
      "loss": 0.7533,
      "step": 264500
    },
    {
      "epoch": 2.8001016297817607,
      "eval_loss": 0.5562734007835388,
      "eval_runtime": 46.8062,
      "eval_samples_per_second": 3587.776,
      "eval_steps_per_second": 448.488,
      "step": 264500
    },
    {
      "epoch": 2.800630951561764,
      "grad_norm": 0.9176828265190125,
      "learning_rate": 0.0004522824820483301,
      "loss": 0.7407,
      "step": 264550
    },
    {
      "epoch": 2.8011602733417673,
      "grad_norm": 0.922010600566864,
      "learning_rate": 0.000452255334633941,
      "loss": 0.751,
      "step": 264600
    },
    {
      "epoch": 2.8016895951217706,
      "grad_norm": 0.9302801489830017,
      "learning_rate": 0.00045222818031462894,
      "loss": 0.7484,
      "step": 264650
    },
    {
      "epoch": 2.802218916901774,
      "grad_norm": 0.9054710268974304,
      "learning_rate": 0.0004522010190913209,
      "loss": 0.758,
      "step": 264700
    },
    {
      "epoch": 2.802748238681777,
      "grad_norm": 0.9150042533874512,
      "learning_rate": 0.0004521738509649443,
      "loss": 0.7585,
      "step": 264750
    },
    {
      "epoch": 2.8032775604617806,
      "grad_norm": 0.9377402067184448,
      "learning_rate": 0.00045214667593642657,
      "loss": 0.7637,
      "step": 264800
    },
    {
      "epoch": 2.8038068822417834,
      "grad_norm": 1.0189751386642456,
      "learning_rate": 0.00045211949400669537,
      "loss": 0.7614,
      "step": 264850
    },
    {
      "epoch": 2.8043362040217867,
      "grad_norm": 0.9347050786018372,
      "learning_rate": 0.00045209230517667887,
      "loss": 0.7381,
      "step": 264900
    },
    {
      "epoch": 2.80486552580179,
      "grad_norm": 0.8624457120895386,
      "learning_rate": 0.0004520651094473051,
      "loss": 0.7429,
      "step": 264950
    },
    {
      "epoch": 2.8053948475817934,
      "grad_norm": 0.8852372169494629,
      "learning_rate": 0.00045203790681950265,
      "loss": 0.7337,
      "step": 265000
    },
    {
      "epoch": 2.8053948475817934,
      "eval_loss": 0.5554777383804321,
      "eval_runtime": 46.9114,
      "eval_samples_per_second": 3579.725,
      "eval_steps_per_second": 447.482,
      "step": 265000
    },
    {
      "epoch": 2.8059241693617967,
      "grad_norm": 0.9438725709915161,
      "learning_rate": 0.00045201069729420017,
      "loss": 0.7708,
      "step": 265050
    },
    {
      "epoch": 2.8064534911418,
      "grad_norm": 0.984645426273346,
      "learning_rate": 0.00045198348087232654,
      "loss": 0.7605,
      "step": 265100
    },
    {
      "epoch": 2.8069828129218033,
      "grad_norm": 0.9156654477119446,
      "learning_rate": 0.00045195680208873256,
      "loss": 0.7477,
      "step": 265150
    },
    {
      "epoch": 2.8075121347018066,
      "grad_norm": 0.8290337920188904,
      "learning_rate": 0.0004519295720143896,
      "loss": 0.7455,
      "step": 265200
    },
    {
      "epoch": 2.80804145648181,
      "grad_norm": 0.9509196281433105,
      "learning_rate": 0.000451902335046245,
      "loss": 0.763,
      "step": 265250
    },
    {
      "epoch": 2.8085707782618132,
      "grad_norm": 1.0497045516967773,
      "learning_rate": 0.0004518750911852289,
      "loss": 0.7559,
      "step": 265300
    },
    {
      "epoch": 2.8091001000418165,
      "grad_norm": 1.0024586915969849,
      "learning_rate": 0.000451847840432271,
      "loss": 0.7493,
      "step": 265350
    },
    {
      "epoch": 2.80962942182182,
      "grad_norm": 1.0143790245056152,
      "learning_rate": 0.00045182058278830196,
      "loss": 0.7544,
      "step": 265400
    },
    {
      "epoch": 2.810158743601823,
      "grad_norm": 0.9444725513458252,
      "learning_rate": 0.0004517933182542523,
      "loss": 0.7668,
      "step": 265450
    },
    {
      "epoch": 2.810688065381826,
      "grad_norm": 0.8519709706306458,
      "learning_rate": 0.0004517660468310527,
      "loss": 0.7679,
      "step": 265500
    },
    {
      "epoch": 2.810688065381826,
      "eval_loss": 0.5600703954696655,
      "eval_runtime": 46.8506,
      "eval_samples_per_second": 3584.37,
      "eval_steps_per_second": 448.062,
      "step": 265500
    },
    {
      "epoch": 2.81121738716183,
      "grad_norm": 0.8810498118400574,
      "learning_rate": 0.00045173876851963425,
      "loss": 0.7597,
      "step": 265550
    },
    {
      "epoch": 2.8117467089418327,
      "grad_norm": 0.9193583130836487,
      "learning_rate": 0.0004517114833209282,
      "loss": 0.7592,
      "step": 265600
    },
    {
      "epoch": 2.812276030721836,
      "grad_norm": 0.7835119962692261,
      "learning_rate": 0.0004516841912358661,
      "loss": 0.7504,
      "step": 265650
    },
    {
      "epoch": 2.8128053525018393,
      "grad_norm": 0.9257134795188904,
      "learning_rate": 0.0004516568922653798,
      "loss": 0.7666,
      "step": 265700
    },
    {
      "epoch": 2.8133346742818426,
      "grad_norm": 0.8989125490188599,
      "learning_rate": 0.000451629586410401,
      "loss": 0.7604,
      "step": 265750
    },
    {
      "epoch": 2.813863996061846,
      "grad_norm": 0.8925703763961792,
      "learning_rate": 0.00045160227367186214,
      "loss": 0.7484,
      "step": 265800
    },
    {
      "epoch": 2.814393317841849,
      "grad_norm": 0.9822964072227478,
      "learning_rate": 0.00045157495405069554,
      "loss": 0.758,
      "step": 265850
    },
    {
      "epoch": 2.8149226396218525,
      "grad_norm": 0.9337536096572876,
      "learning_rate": 0.00045154762754783396,
      "loss": 0.7331,
      "step": 265900
    },
    {
      "epoch": 2.815451961401856,
      "grad_norm": 0.7948376536369324,
      "learning_rate": 0.0004515202941642103,
      "loss": 0.7343,
      "step": 265950
    },
    {
      "epoch": 2.815981283181859,
      "grad_norm": 0.8550633192062378,
      "learning_rate": 0.0004514929539007577,
      "loss": 0.7466,
      "step": 266000
    },
    {
      "epoch": 2.815981283181859,
      "eval_loss": 0.5579798221588135,
      "eval_runtime": 46.7864,
      "eval_samples_per_second": 3589.293,
      "eval_steps_per_second": 448.678,
      "step": 266000
    },
    {
      "epoch": 2.8165106049618625,
      "grad_norm": 0.8515167832374573,
      "learning_rate": 0.00045146560675840954,
      "loss": 0.7511,
      "step": 266050
    },
    {
      "epoch": 2.8170399267418658,
      "grad_norm": 0.9287703037261963,
      "learning_rate": 0.00045143825273809946,
      "loss": 0.7671,
      "step": 266100
    },
    {
      "epoch": 2.817569248521869,
      "grad_norm": 0.9521700143814087,
      "learning_rate": 0.00045141089184076136,
      "loss": 0.7582,
      "step": 266150
    },
    {
      "epoch": 2.8180985703018724,
      "grad_norm": 0.8451664447784424,
      "learning_rate": 0.00045138352406732916,
      "loss": 0.7558,
      "step": 266200
    },
    {
      "epoch": 2.8186278920818753,
      "grad_norm": 0.9373894929885864,
      "learning_rate": 0.00045135614941873735,
      "loss": 0.7535,
      "step": 266250
    },
    {
      "epoch": 2.819157213861879,
      "grad_norm": 0.9576112627983093,
      "learning_rate": 0.0004513287678959205,
      "loss": 0.7495,
      "step": 266300
    },
    {
      "epoch": 2.819686535641882,
      "grad_norm": 0.9558482766151428,
      "learning_rate": 0.00045130137949981334,
      "loss": 0.7466,
      "step": 266350
    },
    {
      "epoch": 2.820215857421885,
      "grad_norm": 0.9802302122116089,
      "learning_rate": 0.00045127398423135085,
      "loss": 0.7497,
      "step": 266400
    },
    {
      "epoch": 2.8207451792018885,
      "grad_norm": 0.9457708597183228,
      "learning_rate": 0.0004512465820914684,
      "loss": 0.7505,
      "step": 266450
    },
    {
      "epoch": 2.821274500981892,
      "grad_norm": 0.9135108590126038,
      "learning_rate": 0.00045121917308110136,
      "loss": 0.7527,
      "step": 266500
    },
    {
      "epoch": 2.821274500981892,
      "eval_loss": 0.5560246706008911,
      "eval_runtime": 46.7363,
      "eval_samples_per_second": 3593.142,
      "eval_steps_per_second": 449.159,
      "step": 266500
    },
    {
      "epoch": 2.821803822761895,
      "grad_norm": 0.9585849642753601,
      "learning_rate": 0.00045119175720118563,
      "loss": 0.7425,
      "step": 266550
    },
    {
      "epoch": 2.8223331445418984,
      "grad_norm": 0.8910502195358276,
      "learning_rate": 0.00045116433445265713,
      "loss": 0.7534,
      "step": 266600
    },
    {
      "epoch": 2.8228624663219017,
      "grad_norm": 0.9694392681121826,
      "learning_rate": 0.00045113690483645195,
      "loss": 0.7547,
      "step": 266650
    },
    {
      "epoch": 2.823391788101905,
      "grad_norm": 0.9333494305610657,
      "learning_rate": 0.00045110946835350663,
      "loss": 0.758,
      "step": 266700
    },
    {
      "epoch": 2.8239211098819084,
      "grad_norm": 0.8507365584373474,
      "learning_rate": 0.0004510820250047578,
      "loss": 0.7453,
      "step": 266750
    },
    {
      "epoch": 2.8244504316619117,
      "grad_norm": 1.0363537073135376,
      "learning_rate": 0.0004510545747911424,
      "loss": 0.7618,
      "step": 266800
    },
    {
      "epoch": 2.824979753441915,
      "grad_norm": 0.8703142404556274,
      "learning_rate": 0.00045102711771359755,
      "loss": 0.7588,
      "step": 266850
    },
    {
      "epoch": 2.8255090752219183,
      "grad_norm": 1.0106265544891357,
      "learning_rate": 0.00045099965377306064,
      "loss": 0.7503,
      "step": 266900
    },
    {
      "epoch": 2.8260383970019216,
      "grad_norm": 1.0183627605438232,
      "learning_rate": 0.00045097218297046924,
      "loss": 0.7422,
      "step": 266950
    },
    {
      "epoch": 2.8265677187819245,
      "grad_norm": 0.9888163208961487,
      "learning_rate": 0.00045094470530676123,
      "loss": 0.7659,
      "step": 267000
    },
    {
      "epoch": 2.8265677187819245,
      "eval_loss": 0.5586349368095398,
      "eval_runtime": 46.8198,
      "eval_samples_per_second": 3586.729,
      "eval_steps_per_second": 448.357,
      "step": 267000
    },
    {
      "epoch": 2.8270970405619282,
      "grad_norm": 0.942031979560852,
      "learning_rate": 0.0004509172207828747,
      "loss": 0.7563,
      "step": 267050
    },
    {
      "epoch": 2.827626362341931,
      "grad_norm": 0.8919972777366638,
      "learning_rate": 0.0004508897293997478,
      "loss": 0.7579,
      "step": 267100
    },
    {
      "epoch": 2.8281556841219344,
      "grad_norm": 0.9543507099151611,
      "learning_rate": 0.00045086278119035324,
      "loss": 0.766,
      "step": 267150
    },
    {
      "epoch": 2.8286850059019377,
      "grad_norm": 0.9650015830993652,
      "learning_rate": 0.0004508352762286999,
      "loss": 0.7621,
      "step": 267200
    },
    {
      "epoch": 2.829214327681941,
      "grad_norm": 0.8486603498458862,
      "learning_rate": 0.0004508077644106039,
      "loss": 0.752,
      "step": 267250
    },
    {
      "epoch": 2.8297436494619443,
      "grad_norm": 0.8287493586540222,
      "learning_rate": 0.0004507802457370045,
      "loss": 0.7532,
      "step": 267300
    },
    {
      "epoch": 2.8302729712419477,
      "grad_norm": 0.8612727522850037,
      "learning_rate": 0.00045075272020884103,
      "loss": 0.7607,
      "step": 267350
    },
    {
      "epoch": 2.830802293021951,
      "grad_norm": 0.8748313188552856,
      "learning_rate": 0.0004507251878270534,
      "loss": 0.7525,
      "step": 267400
    },
    {
      "epoch": 2.8313316148019543,
      "grad_norm": 0.921423614025116,
      "learning_rate": 0.00045069764859258146,
      "loss": 0.7543,
      "step": 267450
    },
    {
      "epoch": 2.8318609365819576,
      "grad_norm": 0.9775660634040833,
      "learning_rate": 0.0004506701025063654,
      "loss": 0.7624,
      "step": 267500
    },
    {
      "epoch": 2.8318609365819576,
      "eval_loss": 0.5554892420768738,
      "eval_runtime": 46.7312,
      "eval_samples_per_second": 3593.53,
      "eval_steps_per_second": 449.207,
      "step": 267500
    },
    {
      "epoch": 2.832390258361961,
      "grad_norm": 1.0134565830230713,
      "learning_rate": 0.00045064254956934567,
      "loss": 0.7327,
      "step": 267550
    },
    {
      "epoch": 2.832919580141964,
      "grad_norm": 0.8839812874794006,
      "learning_rate": 0.00045061498978246286,
      "loss": 0.7631,
      "step": 267600
    },
    {
      "epoch": 2.8334489019219675,
      "grad_norm": 0.903259813785553,
      "learning_rate": 0.0004505874231466578,
      "loss": 0.7552,
      "step": 267650
    },
    {
      "epoch": 2.833978223701971,
      "grad_norm": 0.9309394955635071,
      "learning_rate": 0.0004505598496628718,
      "loss": 0.7604,
      "step": 267700
    },
    {
      "epoch": 2.8345075454819737,
      "grad_norm": 0.9361869692802429,
      "learning_rate": 0.00045053226933204594,
      "loss": 0.7608,
      "step": 267750
    },
    {
      "epoch": 2.8350368672619775,
      "grad_norm": 0.9587193727493286,
      "learning_rate": 0.00045050468215512206,
      "loss": 0.7395,
      "step": 267800
    },
    {
      "epoch": 2.8355661890419803,
      "grad_norm": 0.9553067088127136,
      "learning_rate": 0.00045047708813304184,
      "loss": 0.7534,
      "step": 267850
    },
    {
      "epoch": 2.8360955108219836,
      "grad_norm": 0.9738426804542542,
      "learning_rate": 0.00045044948726674736,
      "loss": 0.7429,
      "step": 267900
    },
    {
      "epoch": 2.836624832601987,
      "grad_norm": 1.0131926536560059,
      "learning_rate": 0.00045042187955718083,
      "loss": 0.753,
      "step": 267950
    },
    {
      "epoch": 2.8371541543819903,
      "grad_norm": 0.913021445274353,
      "learning_rate": 0.0004503942650052849,
      "loss": 0.7448,
      "step": 268000
    },
    {
      "epoch": 2.8371541543819903,
      "eval_loss": 0.5536932349205017,
      "eval_runtime": 46.7867,
      "eval_samples_per_second": 3589.268,
      "eval_steps_per_second": 448.675,
      "step": 268000
    },
    {
      "epoch": 2.8376834761619936,
      "grad_norm": 0.9304742813110352,
      "learning_rate": 0.0004503666436120023,
      "loss": 0.766,
      "step": 268050
    },
    {
      "epoch": 2.838212797941997,
      "grad_norm": 0.9117258787155151,
      "learning_rate": 0.0004503390153782759,
      "loss": 0.7644,
      "step": 268100
    },
    {
      "epoch": 2.838742119722,
      "grad_norm": 0.8447468876838684,
      "learning_rate": 0.000450311380305049,
      "loss": 0.7607,
      "step": 268150
    },
    {
      "epoch": 2.8392714415020035,
      "grad_norm": 0.9980150461196899,
      "learning_rate": 0.00045028373839326504,
      "loss": 0.7374,
      "step": 268200
    },
    {
      "epoch": 2.839800763282007,
      "grad_norm": 0.9198492765426636,
      "learning_rate": 0.00045025608964386764,
      "loss": 0.7469,
      "step": 268250
    },
    {
      "epoch": 2.84033008506201,
      "grad_norm": 0.9480980634689331,
      "learning_rate": 0.0004502284340578009,
      "loss": 0.7325,
      "step": 268300
    },
    {
      "epoch": 2.8408594068420134,
      "grad_norm": 0.9684231877326965,
      "learning_rate": 0.0004502007716360088,
      "loss": 0.7487,
      "step": 268350
    },
    {
      "epoch": 2.8413887286220167,
      "grad_norm": 0.9042636752128601,
      "learning_rate": 0.00045017310237943577,
      "loss": 0.7659,
      "step": 268400
    },
    {
      "epoch": 2.84191805040202,
      "grad_norm": 0.9510135650634766,
      "learning_rate": 0.0004501454262890264,
      "loss": 0.7484,
      "step": 268450
    },
    {
      "epoch": 2.842447372182023,
      "grad_norm": 0.8485443592071533,
      "learning_rate": 0.0004501177433657256,
      "loss": 0.7564,
      "step": 268500
    },
    {
      "epoch": 2.842447372182023,
      "eval_loss": 0.5583566427230835,
      "eval_runtime": 46.7996,
      "eval_samples_per_second": 3588.279,
      "eval_steps_per_second": 448.551,
      "step": 268500
    },
    {
      "epoch": 2.8429766939620267,
      "grad_norm": 0.9059637188911438,
      "learning_rate": 0.0004500900536104785,
      "loss": 0.7506,
      "step": 268550
    },
    {
      "epoch": 2.8435060157420295,
      "grad_norm": 1.057294487953186,
      "learning_rate": 0.00045006235702423026,
      "loss": 0.75,
      "step": 268600
    },
    {
      "epoch": 2.844035337522033,
      "grad_norm": 0.8993697762489319,
      "learning_rate": 0.0004500346536079266,
      "loss": 0.7557,
      "step": 268650
    },
    {
      "epoch": 2.844564659302036,
      "grad_norm": 0.9035708904266357,
      "learning_rate": 0.0004500069433625132,
      "loss": 0.742,
      "step": 268700
    },
    {
      "epoch": 2.8450939810820395,
      "grad_norm": 0.9678329229354858,
      "learning_rate": 0.0004499792262889361,
      "loss": 0.7535,
      "step": 268750
    },
    {
      "epoch": 2.845623302862043,
      "grad_norm": 0.9234225749969482,
      "learning_rate": 0.00044995150238814153,
      "loss": 0.7474,
      "step": 268800
    },
    {
      "epoch": 2.846152624642046,
      "grad_norm": 0.9115274548530579,
      "learning_rate": 0.000449923771661076,
      "loss": 0.754,
      "step": 268850
    },
    {
      "epoch": 2.8466819464220494,
      "grad_norm": 0.9947783946990967,
      "learning_rate": 0.0004498960341086863,
      "loss": 0.7511,
      "step": 268900
    },
    {
      "epoch": 2.8472112682020527,
      "grad_norm": 0.9667028784751892,
      "learning_rate": 0.00044986828973191925,
      "loss": 0.7684,
      "step": 268950
    },
    {
      "epoch": 2.847740589982056,
      "grad_norm": 0.991875171661377,
      "learning_rate": 0.000449840538531722,
      "loss": 0.7649,
      "step": 269000
    },
    {
      "epoch": 2.847740589982056,
      "eval_loss": 0.5555047392845154,
      "eval_runtime": 46.8697,
      "eval_samples_per_second": 3582.911,
      "eval_steps_per_second": 447.88,
      "step": 269000
    },
    {
      "epoch": 2.8482699117620593,
      "grad_norm": 0.922358512878418,
      "learning_rate": 0.00044981278050904217,
      "loss": 0.7427,
      "step": 269050
    },
    {
      "epoch": 2.8487992335420627,
      "grad_norm": 0.964715301990509,
      "learning_rate": 0.0004497850156648273,
      "loss": 0.7528,
      "step": 269100
    },
    {
      "epoch": 2.849328555322066,
      "grad_norm": 1.0494270324707031,
      "learning_rate": 0.0004497577995001569,
      "loss": 0.7577,
      "step": 269150
    },
    {
      "epoch": 2.8498578771020693,
      "grad_norm": 1.02420973777771,
      "learning_rate": 0.00044973002115209924,
      "loss": 0.7658,
      "step": 269200
    },
    {
      "epoch": 2.850387198882072,
      "grad_norm": 1.0099060535430908,
      "learning_rate": 0.00044970223598533193,
      "loss": 0.7436,
      "step": 269250
    },
    {
      "epoch": 2.850916520662076,
      "grad_norm": 0.9536489844322205,
      "learning_rate": 0.0004496744440008035,
      "loss": 0.7693,
      "step": 269300
    },
    {
      "epoch": 2.8514458424420788,
      "grad_norm": 1.0297348499298096,
      "learning_rate": 0.00044964664519946286,
      "loss": 0.7677,
      "step": 269350
    },
    {
      "epoch": 2.851975164222082,
      "grad_norm": 0.919654130935669,
      "learning_rate": 0.0004496188395822589,
      "loss": 0.7484,
      "step": 269400
    },
    {
      "epoch": 2.8525044860020854,
      "grad_norm": 0.9095795750617981,
      "learning_rate": 0.000449591027150141,
      "loss": 0.7508,
      "step": 269450
    },
    {
      "epoch": 2.8530338077820887,
      "grad_norm": 0.8711047768592834,
      "learning_rate": 0.0004495632079040586,
      "loss": 0.7516,
      "step": 269500
    },
    {
      "epoch": 2.8530338077820887,
      "eval_loss": 0.5552825927734375,
      "eval_runtime": 46.8377,
      "eval_samples_per_second": 3585.361,
      "eval_steps_per_second": 448.186,
      "step": 269500
    },
    {
      "epoch": 2.853563129562092,
      "grad_norm": 0.8708457946777344,
      "learning_rate": 0.00044953538184496145,
      "loss": 0.7576,
      "step": 269550
    },
    {
      "epoch": 2.8540924513420953,
      "grad_norm": 0.95182204246521,
      "learning_rate": 0.0004495075489737996,
      "loss": 0.755,
      "step": 269600
    },
    {
      "epoch": 2.8546217731220986,
      "grad_norm": 0.8905316591262817,
      "learning_rate": 0.00044947970929152316,
      "loss": 0.7488,
      "step": 269650
    },
    {
      "epoch": 2.855151094902102,
      "grad_norm": 0.9718894362449646,
      "learning_rate": 0.0004494518627990826,
      "loss": 0.746,
      "step": 269700
    },
    {
      "epoch": 2.8556804166821053,
      "grad_norm": 0.9758222699165344,
      "learning_rate": 0.00044942400949742864,
      "loss": 0.7495,
      "step": 269750
    },
    {
      "epoch": 2.8562097384621086,
      "grad_norm": 0.95402592420578,
      "learning_rate": 0.00044939614938751204,
      "loss": 0.7587,
      "step": 269800
    },
    {
      "epoch": 2.856739060242112,
      "grad_norm": 0.9415829181671143,
      "learning_rate": 0.0004493682824702841,
      "loss": 0.7503,
      "step": 269850
    },
    {
      "epoch": 2.857268382022115,
      "grad_norm": 0.8815816044807434,
      "learning_rate": 0.00044934040874669605,
      "loss": 0.7472,
      "step": 269900
    },
    {
      "epoch": 2.8577977038021185,
      "grad_norm": 1.0368558168411255,
      "learning_rate": 0.0004493125282176996,
      "loss": 0.7617,
      "step": 269950
    },
    {
      "epoch": 2.8583270255821214,
      "grad_norm": 0.9584400057792664,
      "learning_rate": 0.0004492846408842466,
      "loss": 0.7583,
      "step": 270000
    },
    {
      "epoch": 2.8583270255821214,
      "eval_loss": 0.5539456009864807,
      "eval_runtime": 46.881,
      "eval_samples_per_second": 3582.046,
      "eval_steps_per_second": 447.772,
      "step": 270000
    },
    {
      "epoch": 2.858856347362125,
      "grad_norm": 0.9970991611480713,
      "learning_rate": 0.0004492567467472889,
      "loss": 0.7519,
      "step": 270050
    },
    {
      "epoch": 2.859385669142128,
      "grad_norm": 0.9505898356437683,
      "learning_rate": 0.000449228845807779,
      "loss": 0.7517,
      "step": 270100
    },
    {
      "epoch": 2.8599149909221318,
      "grad_norm": 0.9473838806152344,
      "learning_rate": 0.0004492009380666694,
      "loss": 0.7497,
      "step": 270150
    },
    {
      "epoch": 2.8604443127021346,
      "grad_norm": 0.9900186061859131,
      "learning_rate": 0.00044917302352491284,
      "loss": 0.747,
      "step": 270200
    },
    {
      "epoch": 2.860973634482138,
      "grad_norm": 0.9236159324645996,
      "learning_rate": 0.0004491451021834623,
      "loss": 0.7564,
      "step": 270250
    },
    {
      "epoch": 2.8615029562621412,
      "grad_norm": 0.9963868856430054,
      "learning_rate": 0.00044911717404327097,
      "loss": 0.7617,
      "step": 270300
    },
    {
      "epoch": 2.8620322780421446,
      "grad_norm": 0.8647940158843994,
      "learning_rate": 0.0004490892391052923,
      "loss": 0.7443,
      "step": 270350
    },
    {
      "epoch": 2.862561599822148,
      "grad_norm": 0.9001048803329468,
      "learning_rate": 0.0004490612973704801,
      "loss": 0.7645,
      "step": 270400
    },
    {
      "epoch": 2.863090921602151,
      "grad_norm": 0.9677464365959167,
      "learning_rate": 0.0004490333488397882,
      "loss": 0.7544,
      "step": 270450
    },
    {
      "epoch": 2.8636202433821545,
      "grad_norm": 0.8910185098648071,
      "learning_rate": 0.00044900539351417067,
      "loss": 0.7412,
      "step": 270500
    },
    {
      "epoch": 2.8636202433821545,
      "eval_loss": 0.553041398525238,
      "eval_runtime": 46.8107,
      "eval_samples_per_second": 3587.427,
      "eval_steps_per_second": 448.444,
      "step": 270500
    },
    {
      "epoch": 2.864149565162158,
      "grad_norm": 0.8605179190635681,
      "learning_rate": 0.00044897743139458215,
      "loss": 0.7594,
      "step": 270550
    },
    {
      "epoch": 2.864678886942161,
      "grad_norm": 1.0145272016525269,
      "learning_rate": 0.000448949462481977,
      "loss": 0.7412,
      "step": 270600
    },
    {
      "epoch": 2.8652082087221644,
      "grad_norm": 0.9199165105819702,
      "learning_rate": 0.00044892148677731016,
      "loss": 0.7551,
      "step": 270650
    },
    {
      "epoch": 2.8657375305021677,
      "grad_norm": 0.93524169921875,
      "learning_rate": 0.00044889350428153673,
      "loss": 0.7588,
      "step": 270700
    },
    {
      "epoch": 2.8662668522821706,
      "grad_norm": 0.8400014042854309,
      "learning_rate": 0.000448865514995612,
      "loss": 0.7467,
      "step": 270750
    },
    {
      "epoch": 2.8667961740621744,
      "grad_norm": 0.8944639563560486,
      "learning_rate": 0.00044883751892049154,
      "loss": 0.7376,
      "step": 270800
    },
    {
      "epoch": 2.867325495842177,
      "grad_norm": 0.9113448262214661,
      "learning_rate": 0.00044880951605713105,
      "loss": 0.7456,
      "step": 270850
    },
    {
      "epoch": 2.867854817622181,
      "grad_norm": 0.8328149914741516,
      "learning_rate": 0.0004487815064064866,
      "loss": 0.7305,
      "step": 270900
    },
    {
      "epoch": 2.868384139402184,
      "grad_norm": 0.9017413854598999,
      "learning_rate": 0.0004487534899695145,
      "loss": 0.7463,
      "step": 270950
    },
    {
      "epoch": 2.868913461182187,
      "grad_norm": 0.8780402541160583,
      "learning_rate": 0.00044872546674717105,
      "loss": 0.7434,
      "step": 271000
    },
    {
      "epoch": 2.868913461182187,
      "eval_loss": 0.5513981580734253,
      "eval_runtime": 46.9215,
      "eval_samples_per_second": 3578.953,
      "eval_steps_per_second": 447.385,
      "step": 271000
    },
    {
      "epoch": 2.8694427829621905,
      "grad_norm": 0.9441894888877869,
      "learning_rate": 0.00044869743674041317,
      "loss": 0.7489,
      "step": 271050
    },
    {
      "epoch": 2.8699721047421938,
      "grad_norm": 0.8343092203140259,
      "learning_rate": 0.00044866939995019764,
      "loss": 0.7434,
      "step": 271100
    },
    {
      "epoch": 2.870501426522197,
      "grad_norm": 0.8335480093955994,
      "learning_rate": 0.00044864135637748156,
      "loss": 0.7487,
      "step": 271150
    },
    {
      "epoch": 2.8710307483022004,
      "grad_norm": 0.915516197681427,
      "learning_rate": 0.0004486133060232225,
      "loss": 0.7433,
      "step": 271200
    },
    {
      "epoch": 2.8715600700822037,
      "grad_norm": 0.8966647982597351,
      "learning_rate": 0.00044858524888837794,
      "loss": 0.7544,
      "step": 271250
    },
    {
      "epoch": 2.872089391862207,
      "grad_norm": 0.9657577276229858,
      "learning_rate": 0.00044855774631862944,
      "loss": 0.7493,
      "step": 271300
    },
    {
      "epoch": 2.8726187136422103,
      "grad_norm": 0.9276759028434753,
      "learning_rate": 0.00044852967576105185,
      "loss": 0.7538,
      "step": 271350
    },
    {
      "epoch": 2.8731480354222136,
      "grad_norm": 0.943851113319397,
      "learning_rate": 0.000448501598425744,
      "loss": 0.7382,
      "step": 271400
    },
    {
      "epoch": 2.873677357202217,
      "grad_norm": 0.9758642315864563,
      "learning_rate": 0.00044847351431366437,
      "loss": 0.7515,
      "step": 271450
    },
    {
      "epoch": 2.87420667898222,
      "grad_norm": 1.0171293020248413,
      "learning_rate": 0.0004484454234257717,
      "loss": 0.7552,
      "step": 271500
    },
    {
      "epoch": 2.87420667898222,
      "eval_loss": 0.5548664331436157,
      "eval_runtime": 46.8069,
      "eval_samples_per_second": 3587.716,
      "eval_steps_per_second": 448.481,
      "step": 271500
    },
    {
      "epoch": 2.8747360007622236,
      "grad_norm": 0.9559430480003357,
      "learning_rate": 0.00044841732576302506,
      "loss": 0.7612,
      "step": 271550
    },
    {
      "epoch": 2.8752653225422264,
      "grad_norm": 0.8226752877235413,
      "learning_rate": 0.0004483892213263837,
      "loss": 0.7363,
      "step": 271600
    },
    {
      "epoch": 2.87579464432223,
      "grad_norm": 1.0368304252624512,
      "learning_rate": 0.00044836111011680715,
      "loss": 0.7545,
      "step": 271650
    },
    {
      "epoch": 2.876323966102233,
      "grad_norm": 0.8656997084617615,
      "learning_rate": 0.00044833299213525494,
      "loss": 0.7387,
      "step": 271700
    },
    {
      "epoch": 2.8768532878822364,
      "grad_norm": 0.9276111125946045,
      "learning_rate": 0.00044830486738268717,
      "loss": 0.7427,
      "step": 271750
    },
    {
      "epoch": 2.8773826096622397,
      "grad_norm": 0.8803420066833496,
      "learning_rate": 0.0004482767358600639,
      "loss": 0.7536,
      "step": 271800
    },
    {
      "epoch": 2.877911931442243,
      "grad_norm": 1.1369335651397705,
      "learning_rate": 0.00044824859756834566,
      "loss": 0.7519,
      "step": 271850
    },
    {
      "epoch": 2.8784412532222463,
      "grad_norm": 1.032531976699829,
      "learning_rate": 0.00044822045250849296,
      "loss": 0.7581,
      "step": 271900
    },
    {
      "epoch": 2.8789705750022496,
      "grad_norm": 0.8955458402633667,
      "learning_rate": 0.00044819230068146674,
      "loss": 0.736,
      "step": 271950
    },
    {
      "epoch": 2.879499896782253,
      "grad_norm": 0.9755237102508545,
      "learning_rate": 0.000448164142088228,
      "loss": 0.7439,
      "step": 272000
    },
    {
      "epoch": 2.879499896782253,
      "eval_loss": 0.5524243712425232,
      "eval_runtime": 46.823,
      "eval_samples_per_second": 3586.483,
      "eval_steps_per_second": 448.326,
      "step": 272000
    },
    {
      "epoch": 2.8800292185622562,
      "grad_norm": 0.9212559461593628,
      "learning_rate": 0.00044813597672973816,
      "loss": 0.7535,
      "step": 272050
    },
    {
      "epoch": 2.8805585403422596,
      "grad_norm": 0.9556899070739746,
      "learning_rate": 0.00044810780460695875,
      "loss": 0.752,
      "step": 272100
    },
    {
      "epoch": 2.881087862122263,
      "grad_norm": 0.9758777618408203,
      "learning_rate": 0.0004480796257208515,
      "loss": 0.7441,
      "step": 272150
    },
    {
      "epoch": 2.881617183902266,
      "grad_norm": 0.856161892414093,
      "learning_rate": 0.00044805144007237853,
      "loss": 0.7534,
      "step": 272200
    },
    {
      "epoch": 2.882146505682269,
      "grad_norm": 0.9887334108352661,
      "learning_rate": 0.00044802324766250203,
      "loss": 0.743,
      "step": 272250
    },
    {
      "epoch": 2.882675827462273,
      "grad_norm": 0.9107711315155029,
      "learning_rate": 0.0004479950484921844,
      "loss": 0.7505,
      "step": 272300
    },
    {
      "epoch": 2.8832051492422757,
      "grad_norm": 0.8394872546195984,
      "learning_rate": 0.0004479668425623885,
      "loss": 0.7465,
      "step": 272350
    },
    {
      "epoch": 2.8837344710222794,
      "grad_norm": 0.8793121576309204,
      "learning_rate": 0.0004479386298740772,
      "loss": 0.7445,
      "step": 272400
    },
    {
      "epoch": 2.8842637928022823,
      "grad_norm": 0.9281151294708252,
      "learning_rate": 0.00044791041042821364,
      "loss": 0.7398,
      "step": 272450
    },
    {
      "epoch": 2.8847931145822856,
      "grad_norm": 0.8297578692436218,
      "learning_rate": 0.0004478821842257612,
      "loss": 0.7399,
      "step": 272500
    },
    {
      "epoch": 2.8847931145822856,
      "eval_loss": 0.5505420565605164,
      "eval_runtime": 46.7836,
      "eval_samples_per_second": 3589.506,
      "eval_steps_per_second": 448.704,
      "step": 272500
    },
    {
      "epoch": 2.885322436362289,
      "grad_norm": 0.9329918026924133,
      "learning_rate": 0.0004478539512676836,
      "loss": 0.7597,
      "step": 272550
    },
    {
      "epoch": 2.8858517581422922,
      "grad_norm": 0.9808287024497986,
      "learning_rate": 0.0004478257115549447,
      "loss": 0.7525,
      "step": 272600
    },
    {
      "epoch": 2.8863810799222955,
      "grad_norm": 0.9149489998817444,
      "learning_rate": 0.00044779746508850855,
      "loss": 0.7354,
      "step": 272650
    },
    {
      "epoch": 2.886910401702299,
      "grad_norm": 0.990349292755127,
      "learning_rate": 0.0004477692118693395,
      "loss": 0.7505,
      "step": 272700
    },
    {
      "epoch": 2.887439723482302,
      "grad_norm": 0.9128198027610779,
      "learning_rate": 0.000447740951898402,
      "loss": 0.7343,
      "step": 272750
    },
    {
      "epoch": 2.8879690452623055,
      "grad_norm": 0.9525861144065857,
      "learning_rate": 0.00044771268517666097,
      "loss": 0.7637,
      "step": 272800
    },
    {
      "epoch": 2.888498367042309,
      "grad_norm": 1.0568921566009521,
      "learning_rate": 0.00044768441170508144,
      "loss": 0.7601,
      "step": 272850
    },
    {
      "epoch": 2.889027688822312,
      "grad_norm": 1.0159881114959717,
      "learning_rate": 0.00044765613148462847,
      "loss": 0.7482,
      "step": 272900
    },
    {
      "epoch": 2.8895570106023154,
      "grad_norm": 0.8420661091804504,
      "learning_rate": 0.00044762784451626776,
      "loss": 0.7716,
      "step": 272950
    },
    {
      "epoch": 2.8900863323823183,
      "grad_norm": 0.8937633633613586,
      "learning_rate": 0.00044759955080096486,
      "loss": 0.7621,
      "step": 273000
    },
    {
      "epoch": 2.8900863323823183,
      "eval_loss": 0.5513686537742615,
      "eval_runtime": 46.7709,
      "eval_samples_per_second": 3590.477,
      "eval_steps_per_second": 448.826,
      "step": 273000
    },
    {
      "epoch": 2.890615654162322,
      "grad_norm": 0.911666750907898,
      "learning_rate": 0.00044757125033968584,
      "loss": 0.7432,
      "step": 273050
    },
    {
      "epoch": 2.891144975942325,
      "grad_norm": 0.8718910813331604,
      "learning_rate": 0.00044754294313339673,
      "loss": 0.7478,
      "step": 273100
    },
    {
      "epoch": 2.8916742977223286,
      "grad_norm": 0.902090311050415,
      "learning_rate": 0.000447514629183064,
      "loss": 0.7583,
      "step": 273150
    },
    {
      "epoch": 2.8922036195023315,
      "grad_norm": 0.9100751876831055,
      "learning_rate": 0.0004474863084896542,
      "loss": 0.7378,
      "step": 273200
    },
    {
      "epoch": 2.892732941282335,
      "grad_norm": 0.8764469027519226,
      "learning_rate": 0.00044745798105413437,
      "loss": 0.748,
      "step": 273250
    },
    {
      "epoch": 2.893262263062338,
      "grad_norm": 0.9236265420913696,
      "learning_rate": 0.0004474296468774714,
      "loss": 0.7497,
      "step": 273300
    },
    {
      "epoch": 2.8937915848423414,
      "grad_norm": 0.8266156911849976,
      "learning_rate": 0.00044740187284501696,
      "loss": 0.7653,
      "step": 273350
    },
    {
      "epoch": 2.8943209066223448,
      "grad_norm": 0.9205431342124939,
      "learning_rate": 0.0004473735253237448,
      "loss": 0.747,
      "step": 273400
    },
    {
      "epoch": 2.894850228402348,
      "grad_norm": 0.891559898853302,
      "learning_rate": 0.0004473451710642128,
      "loss": 0.7447,
      "step": 273450
    },
    {
      "epoch": 2.8953795501823514,
      "grad_norm": 0.8955004811286926,
      "learning_rate": 0.00044731681006738905,
      "loss": 0.7578,
      "step": 273500
    },
    {
      "epoch": 2.8953795501823514,
      "eval_loss": 0.5486897230148315,
      "eval_runtime": 46.7765,
      "eval_samples_per_second": 3590.052,
      "eval_steps_per_second": 448.772,
      "step": 273500
    },
    {
      "epoch": 2.8959088719623547,
      "grad_norm": 0.9382553100585938,
      "learning_rate": 0.00044728844233424183,
      "loss": 0.7559,
      "step": 273550
    },
    {
      "epoch": 2.896438193742358,
      "grad_norm": 0.8309670090675354,
      "learning_rate": 0.00044726006786573945,
      "loss": 0.7544,
      "step": 273600
    },
    {
      "epoch": 2.8969675155223613,
      "grad_norm": 0.9245926737785339,
      "learning_rate": 0.00044723168666285074,
      "loss": 0.748,
      "step": 273650
    },
    {
      "epoch": 2.8974968373023646,
      "grad_norm": 0.8938334584236145,
      "learning_rate": 0.00044720329872654466,
      "loss": 0.7439,
      "step": 273700
    },
    {
      "epoch": 2.8980261590823675,
      "grad_norm": 0.9632346630096436,
      "learning_rate": 0.00044717490405779016,
      "loss": 0.7522,
      "step": 273750
    },
    {
      "epoch": 2.8985554808623712,
      "grad_norm": 1.0418416261672974,
      "learning_rate": 0.00044714650265755684,
      "loss": 0.7571,
      "step": 273800
    },
    {
      "epoch": 2.899084802642374,
      "grad_norm": 0.8965394496917725,
      "learning_rate": 0.0004471180945268142,
      "loss": 0.7442,
      "step": 273850
    },
    {
      "epoch": 2.899614124422378,
      "grad_norm": 0.9324911832809448,
      "learning_rate": 0.000447089679666532,
      "loss": 0.7401,
      "step": 273900
    },
    {
      "epoch": 2.9001434462023807,
      "grad_norm": 0.9512504935264587,
      "learning_rate": 0.00044706125807768054,
      "loss": 0.7436,
      "step": 273950
    },
    {
      "epoch": 2.900672767982384,
      "grad_norm": 0.8740434050559998,
      "learning_rate": 0.0004470328297612299,
      "loss": 0.7382,
      "step": 274000
    },
    {
      "epoch": 2.900672767982384,
      "eval_loss": 0.5488940477371216,
      "eval_runtime": 46.8072,
      "eval_samples_per_second": 3587.696,
      "eval_steps_per_second": 448.478,
      "step": 274000
    },
    {
      "epoch": 2.9012020897623874,
      "grad_norm": 0.9039411544799805,
      "learning_rate": 0.00044700439471815083,
      "loss": 0.7582,
      "step": 274050
    },
    {
      "epoch": 2.9017314115423907,
      "grad_norm": 0.9092867970466614,
      "learning_rate": 0.00044697595294941394,
      "loss": 0.7537,
      "step": 274100
    },
    {
      "epoch": 2.902260733322394,
      "grad_norm": 1.028990387916565,
      "learning_rate": 0.0004469475044559902,
      "loss": 0.757,
      "step": 274150
    },
    {
      "epoch": 2.9027900551023973,
      "grad_norm": 1.0136587619781494,
      "learning_rate": 0.00044691904923885095,
      "loss": 0.7497,
      "step": 274200
    },
    {
      "epoch": 2.9033193768824006,
      "grad_norm": 0.8686681389808655,
      "learning_rate": 0.0004468905872989675,
      "loss": 0.7505,
      "step": 274250
    },
    {
      "epoch": 2.903848698662404,
      "grad_norm": 0.9077396988868713,
      "learning_rate": 0.00044686211863731164,
      "loss": 0.7514,
      "step": 274300
    },
    {
      "epoch": 2.9043780204424072,
      "grad_norm": 0.9387935400009155,
      "learning_rate": 0.0004468336432548553,
      "loss": 0.7547,
      "step": 274350
    },
    {
      "epoch": 2.9049073422224105,
      "grad_norm": 0.9816247820854187,
      "learning_rate": 0.00044680516115257055,
      "loss": 0.7443,
      "step": 274400
    },
    {
      "epoch": 2.905436664002414,
      "grad_norm": 0.9465148448944092,
      "learning_rate": 0.0004467766723314297,
      "loss": 0.7483,
      "step": 274450
    },
    {
      "epoch": 2.9059659857824167,
      "grad_norm": 0.9920167326927185,
      "learning_rate": 0.0004467481767924055,
      "loss": 0.751,
      "step": 274500
    },
    {
      "epoch": 2.9059659857824167,
      "eval_loss": 0.5491014122962952,
      "eval_runtime": 46.7895,
      "eval_samples_per_second": 3589.049,
      "eval_steps_per_second": 448.647,
      "step": 274500
    },
    {
      "epoch": 2.9064953075624205,
      "grad_norm": 1.022592544555664,
      "learning_rate": 0.00044671967453647067,
      "loss": 0.7429,
      "step": 274550
    },
    {
      "epoch": 2.9070246293424233,
      "grad_norm": 0.95945143699646,
      "learning_rate": 0.0004466911655645983,
      "loss": 0.7451,
      "step": 274600
    },
    {
      "epoch": 2.907553951122427,
      "grad_norm": 0.9845417737960815,
      "learning_rate": 0.0004466626498777616,
      "loss": 0.747,
      "step": 274650
    },
    {
      "epoch": 2.90808327290243,
      "grad_norm": 0.9579126834869385,
      "learning_rate": 0.0004466341274769343,
      "loss": 0.758,
      "step": 274700
    },
    {
      "epoch": 2.9086125946824333,
      "grad_norm": 0.9289582967758179,
      "learning_rate": 0.0004466055983630899,
      "loss": 0.7514,
      "step": 274750
    },
    {
      "epoch": 2.9091419164624366,
      "grad_norm": 0.8749585747718811,
      "learning_rate": 0.00044657706253720255,
      "loss": 0.7352,
      "step": 274800
    },
    {
      "epoch": 2.90967123824244,
      "grad_norm": 0.9246610403060913,
      "learning_rate": 0.00044654852000024627,
      "loss": 0.7647,
      "step": 274850
    },
    {
      "epoch": 2.910200560022443,
      "grad_norm": 1.0028674602508545,
      "learning_rate": 0.0004465199707531957,
      "loss": 0.7665,
      "step": 274900
    },
    {
      "epoch": 2.9107298818024465,
      "grad_norm": 0.9685224294662476,
      "learning_rate": 0.00044649141479702537,
      "loss": 0.7552,
      "step": 274950
    },
    {
      "epoch": 2.91125920358245,
      "grad_norm": 0.8657469749450684,
      "learning_rate": 0.00044646285213271016,
      "loss": 0.7674,
      "step": 275000
    },
    {
      "epoch": 2.91125920358245,
      "eval_loss": 0.5461156964302063,
      "eval_runtime": 46.7856,
      "eval_samples_per_second": 3589.356,
      "eval_steps_per_second": 448.685,
      "step": 275000
    },
    {
      "epoch": 2.911788525362453,
      "grad_norm": 0.9144799113273621,
      "learning_rate": 0.00044643428276122524,
      "loss": 0.755,
      "step": 275050
    },
    {
      "epoch": 2.9123178471424565,
      "grad_norm": 0.9860501885414124,
      "learning_rate": 0.00044640570668354597,
      "loss": 0.7506,
      "step": 275100
    },
    {
      "epoch": 2.9128471689224598,
      "grad_norm": 0.8874910473823547,
      "learning_rate": 0.0004463771239006479,
      "loss": 0.7541,
      "step": 275150
    },
    {
      "epoch": 2.913376490702463,
      "grad_norm": 0.8450997471809387,
      "learning_rate": 0.0004463485344135069,
      "loss": 0.7415,
      "step": 275200
    },
    {
      "epoch": 2.913905812482466,
      "grad_norm": 0.8830885887145996,
      "learning_rate": 0.0004463199382230988,
      "loss": 0.7486,
      "step": 275250
    },
    {
      "epoch": 2.9144351342624697,
      "grad_norm": 0.8986836671829224,
      "learning_rate": 0.00044629133533040014,
      "loss": 0.7423,
      "step": 275300
    },
    {
      "epoch": 2.9149644560424726,
      "grad_norm": 1.0157843828201294,
      "learning_rate": 0.0004462632979939341,
      "loss": 0.7422,
      "step": 275350
    },
    {
      "epoch": 2.9154937778224763,
      "grad_norm": 0.9532848000526428,
      "learning_rate": 0.00044623468183358086,
      "loss": 0.7431,
      "step": 275400
    },
    {
      "epoch": 2.916023099602479,
      "grad_norm": 1.0302271842956543,
      "learning_rate": 0.00044620605897384755,
      "loss": 0.7382,
      "step": 275450
    },
    {
      "epoch": 2.9165524213824825,
      "grad_norm": 1.0285404920578003,
      "learning_rate": 0.0004461774294157114,
      "loss": 0.7436,
      "step": 275500
    },
    {
      "epoch": 2.9165524213824825,
      "eval_loss": 0.5469021797180176,
      "eval_runtime": 46.8418,
      "eval_samples_per_second": 3585.046,
      "eval_steps_per_second": 448.147,
      "step": 275500
    },
    {
      "epoch": 2.917081743162486,
      "grad_norm": 0.9124765992164612,
      "learning_rate": 0.00044614879316014964,
      "loss": 0.7485,
      "step": 275550
    },
    {
      "epoch": 2.917611064942489,
      "grad_norm": 1.0122716426849365,
      "learning_rate": 0.00044612015020814013,
      "loss": 0.7498,
      "step": 275600
    },
    {
      "epoch": 2.9181403867224924,
      "grad_norm": 0.975742518901825,
      "learning_rate": 0.0004460915005606606,
      "loss": 0.742,
      "step": 275650
    },
    {
      "epoch": 2.9186697085024957,
      "grad_norm": 0.9444471001625061,
      "learning_rate": 0.00044606284421868915,
      "loss": 0.7445,
      "step": 275700
    },
    {
      "epoch": 2.919199030282499,
      "grad_norm": 0.9227027893066406,
      "learning_rate": 0.00044603418118320407,
      "loss": 0.743,
      "step": 275750
    },
    {
      "epoch": 2.9197283520625024,
      "grad_norm": 0.9973523616790771,
      "learning_rate": 0.000446005511455184,
      "loss": 0.7284,
      "step": 275800
    },
    {
      "epoch": 2.9202576738425057,
      "grad_norm": 0.9681777358055115,
      "learning_rate": 0.0004459768350356076,
      "loss": 0.7316,
      "step": 275850
    },
    {
      "epoch": 2.920786995622509,
      "grad_norm": 0.8864873051643372,
      "learning_rate": 0.00044594815192545393,
      "loss": 0.744,
      "step": 275900
    },
    {
      "epoch": 2.9213163174025123,
      "grad_norm": 0.8920198678970337,
      "learning_rate": 0.0004459194621257022,
      "loss": 0.7459,
      "step": 275950
    },
    {
      "epoch": 2.9218456391825156,
      "grad_norm": 0.8895467519760132,
      "learning_rate": 0.0004458907656373319,
      "loss": 0.7464,
      "step": 276000
    },
    {
      "epoch": 2.9218456391825156,
      "eval_loss": 0.5494011044502258,
      "eval_runtime": 46.8328,
      "eval_samples_per_second": 3585.733,
      "eval_steps_per_second": 448.233,
      "step": 276000
    },
    {
      "epoch": 2.922374960962519,
      "grad_norm": 0.8382431864738464,
      "learning_rate": 0.00044586206246132273,
      "loss": 0.7338,
      "step": 276050
    },
    {
      "epoch": 2.922904282742522,
      "grad_norm": 1.017734169960022,
      "learning_rate": 0.00044583335259865456,
      "loss": 0.7563,
      "step": 276100
    },
    {
      "epoch": 2.9234336045225255,
      "grad_norm": 0.9134939908981323,
      "learning_rate": 0.00044580463605030753,
      "loss": 0.7445,
      "step": 276150
    },
    {
      "epoch": 2.9239629263025284,
      "grad_norm": 0.9565309286117554,
      "learning_rate": 0.000445775912817262,
      "loss": 0.7522,
      "step": 276200
    },
    {
      "epoch": 2.9244922480825317,
      "grad_norm": 0.9108923077583313,
      "learning_rate": 0.00044574718290049876,
      "loss": 0.7522,
      "step": 276250
    },
    {
      "epoch": 2.925021569862535,
      "grad_norm": 0.9189150333404541,
      "learning_rate": 0.00044571844630099833,
      "loss": 0.7435,
      "step": 276300
    },
    {
      "epoch": 2.9255508916425383,
      "grad_norm": 0.9180486798286438,
      "learning_rate": 0.000445689703019742,
      "loss": 0.7454,
      "step": 276350
    },
    {
      "epoch": 2.9260802134225417,
      "grad_norm": 0.9229053854942322,
      "learning_rate": 0.00044566095305771094,
      "loss": 0.7403,
      "step": 276400
    },
    {
      "epoch": 2.926609535202545,
      "grad_norm": 1.0037105083465576,
      "learning_rate": 0.0004456321964158867,
      "loss": 0.7614,
      "step": 276450
    },
    {
      "epoch": 2.9271388569825483,
      "grad_norm": 0.9203286170959473,
      "learning_rate": 0.0004456034330952511,
      "loss": 0.7548,
      "step": 276500
    },
    {
      "epoch": 2.9271388569825483,
      "eval_loss": 0.5460996627807617,
      "eval_runtime": 46.8241,
      "eval_samples_per_second": 3586.399,
      "eval_steps_per_second": 448.316,
      "step": 276500
    },
    {
      "epoch": 2.9276681787625516,
      "grad_norm": 0.9647954702377319,
      "learning_rate": 0.00044557466309678594,
      "loss": 0.7474,
      "step": 276550
    },
    {
      "epoch": 2.928197500542555,
      "grad_norm": 1.0120887756347656,
      "learning_rate": 0.00044554588642147354,
      "loss": 0.7503,
      "step": 276600
    },
    {
      "epoch": 2.928726822322558,
      "grad_norm": 0.8870813846588135,
      "learning_rate": 0.00044551710307029626,
      "loss": 0.7467,
      "step": 276650
    },
    {
      "epoch": 2.9292561441025615,
      "grad_norm": 0.9958745241165161,
      "learning_rate": 0.0004454883130442368,
      "loss": 0.7524,
      "step": 276700
    },
    {
      "epoch": 2.929785465882565,
      "grad_norm": 0.9134730696678162,
      "learning_rate": 0.00044545951634427804,
      "loss": 0.749,
      "step": 276750
    },
    {
      "epoch": 2.930314787662568,
      "grad_norm": 1.0224727392196655,
      "learning_rate": 0.000445430712971403,
      "loss": 0.7438,
      "step": 276800
    },
    {
      "epoch": 2.930844109442571,
      "grad_norm": 0.8935605883598328,
      "learning_rate": 0.0004454019029265952,
      "loss": 0.7463,
      "step": 276850
    },
    {
      "epoch": 2.9313734312225748,
      "grad_norm": 0.9631600975990295,
      "learning_rate": 0.00044537308621083805,
      "loss": 0.7488,
      "step": 276900
    },
    {
      "epoch": 2.9319027530025776,
      "grad_norm": 0.8998500108718872,
      "learning_rate": 0.00044534426282511543,
      "loss": 0.7329,
      "step": 276950
    },
    {
      "epoch": 2.932432074782581,
      "grad_norm": 0.8889597058296204,
      "learning_rate": 0.00044531543277041125,
      "loss": 0.7479,
      "step": 277000
    },
    {
      "epoch": 2.932432074782581,
      "eval_loss": 0.5472089052200317,
      "eval_runtime": 46.8089,
      "eval_samples_per_second": 3587.569,
      "eval_steps_per_second": 448.462,
      "step": 277000
    },
    {
      "epoch": 2.9329613965625843,
      "grad_norm": 0.9573007225990295,
      "learning_rate": 0.0004452865960477098,
      "loss": 0.7487,
      "step": 277050
    },
    {
      "epoch": 2.9334907183425876,
      "grad_norm": 1.0000965595245361,
      "learning_rate": 0.0004452577526579957,
      "loss": 0.7364,
      "step": 277100
    },
    {
      "epoch": 2.934020040122591,
      "grad_norm": 0.9897961020469666,
      "learning_rate": 0.00044522890260225345,
      "loss": 0.755,
      "step": 277150
    },
    {
      "epoch": 2.934549361902594,
      "grad_norm": 1.0144107341766357,
      "learning_rate": 0.0004452000458814681,
      "loss": 0.7423,
      "step": 277200
    },
    {
      "epoch": 2.9350786836825975,
      "grad_norm": 0.9300424456596375,
      "learning_rate": 0.0004451711824966247,
      "loss": 0.7566,
      "step": 277250
    },
    {
      "epoch": 2.935608005462601,
      "grad_norm": 0.9007642865180969,
      "learning_rate": 0.00044514231244870877,
      "loss": 0.7533,
      "step": 277300
    },
    {
      "epoch": 2.936137327242604,
      "grad_norm": 0.8618318438529968,
      "learning_rate": 0.0004451134357387059,
      "loss": 0.7315,
      "step": 277350
    },
    {
      "epoch": 2.9366666490226074,
      "grad_norm": 1.0149798393249512,
      "learning_rate": 0.00044508513010029627,
      "loss": 0.7437,
      "step": 277400
    },
    {
      "epoch": 2.9371959708026107,
      "grad_norm": 0.9103691577911377,
      "learning_rate": 0.0004450562402022698,
      "loss": 0.7476,
      "step": 277450
    },
    {
      "epoch": 2.937725292582614,
      "grad_norm": 0.9018702507019043,
      "learning_rate": 0.00044502734364509477,
      "loss": 0.7413,
      "step": 277500
    },
    {
      "epoch": 2.937725292582614,
      "eval_loss": 0.5450639128684998,
      "eval_runtime": 46.807,
      "eval_samples_per_second": 3587.712,
      "eval_steps_per_second": 448.48,
      "step": 277500
    },
    {
      "epoch": 2.9382546143626174,
      "grad_norm": 0.8888173699378967,
      "learning_rate": 0.00044499844042975777,
      "loss": 0.748,
      "step": 277550
    },
    {
      "epoch": 2.9387839361426202,
      "grad_norm": 0.9165136814117432,
      "learning_rate": 0.0004449695305572455,
      "loss": 0.7443,
      "step": 277600
    },
    {
      "epoch": 2.939313257922624,
      "grad_norm": 1.0221377611160278,
      "learning_rate": 0.0004449406140285451,
      "loss": 0.7382,
      "step": 277650
    },
    {
      "epoch": 2.939842579702627,
      "grad_norm": 0.9184905290603638,
      "learning_rate": 0.0004449116908446435,
      "loss": 0.7475,
      "step": 277700
    },
    {
      "epoch": 2.94037190148263,
      "grad_norm": 0.8509435653686523,
      "learning_rate": 0.00044488276100652826,
      "loss": 0.7492,
      "step": 277750
    },
    {
      "epoch": 2.9409012232626335,
      "grad_norm": 0.9345398545265198,
      "learning_rate": 0.0004448538245151871,
      "loss": 0.7491,
      "step": 277800
    },
    {
      "epoch": 2.941430545042637,
      "grad_norm": 0.9904628396034241,
      "learning_rate": 0.00044482488137160777,
      "loss": 0.7376,
      "step": 277850
    },
    {
      "epoch": 2.94195986682264,
      "grad_norm": 0.870182991027832,
      "learning_rate": 0.00044479593157677845,
      "loss": 0.7442,
      "step": 277900
    },
    {
      "epoch": 2.9424891886026434,
      "grad_norm": 0.9223380088806152,
      "learning_rate": 0.00044476697513168745,
      "loss": 0.7522,
      "step": 277950
    },
    {
      "epoch": 2.9430185103826467,
      "grad_norm": 0.8725703954696655,
      "learning_rate": 0.0004447380120373234,
      "loss": 0.7427,
      "step": 278000
    },
    {
      "epoch": 2.9430185103826467,
      "eval_loss": 0.5440098643302917,
      "eval_runtime": 46.8086,
      "eval_samples_per_second": 3587.586,
      "eval_steps_per_second": 448.464,
      "step": 278000
    },
    {
      "epoch": 2.94354783216265,
      "grad_norm": 0.8212389349937439,
      "learning_rate": 0.000444709042294675,
      "loss": 0.7448,
      "step": 278050
    },
    {
      "epoch": 2.9440771539426533,
      "grad_norm": 0.946414053440094,
      "learning_rate": 0.0004446800659047313,
      "loss": 0.7502,
      "step": 278100
    },
    {
      "epoch": 2.9446064757226567,
      "grad_norm": 0.9042037725448608,
      "learning_rate": 0.00044465108286848156,
      "loss": 0.7476,
      "step": 278150
    },
    {
      "epoch": 2.94513579750266,
      "grad_norm": 0.9494085311889648,
      "learning_rate": 0.0004446220931869152,
      "loss": 0.749,
      "step": 278200
    },
    {
      "epoch": 2.9456651192826633,
      "grad_norm": 0.9382199048995972,
      "learning_rate": 0.000444593096861022,
      "loss": 0.753,
      "step": 278250
    },
    {
      "epoch": 2.9461944410626666,
      "grad_norm": 0.934564471244812,
      "learning_rate": 0.0004445640938917918,
      "loss": 0.7424,
      "step": 278300
    },
    {
      "epoch": 2.9467237628426695,
      "grad_norm": 1.0648155212402344,
      "learning_rate": 0.00044453508428021483,
      "loss": 0.7512,
      "step": 278350
    },
    {
      "epoch": 2.947253084622673,
      "grad_norm": 0.9713596701622009,
      "learning_rate": 0.00044450606802728146,
      "loss": 0.7533,
      "step": 278400
    },
    {
      "epoch": 2.947782406402676,
      "grad_norm": 0.9569420218467712,
      "learning_rate": 0.00044447704513398214,
      "loss": 0.7331,
      "step": 278450
    },
    {
      "epoch": 2.9483117281826794,
      "grad_norm": 0.9484384059906006,
      "learning_rate": 0.00044444801560130785,
      "loss": 0.7487,
      "step": 278500
    },
    {
      "epoch": 2.9483117281826794,
      "eval_loss": 0.5433359742164612,
      "eval_runtime": 46.9929,
      "eval_samples_per_second": 3573.516,
      "eval_steps_per_second": 446.706,
      "step": 278500
    },
    {
      "epoch": 2.9488410499626827,
      "grad_norm": 0.8226826786994934,
      "learning_rate": 0.00044441897943024966,
      "loss": 0.748,
      "step": 278550
    },
    {
      "epoch": 2.949370371742686,
      "grad_norm": 0.8790886402130127,
      "learning_rate": 0.00044438993662179884,
      "loss": 0.7326,
      "step": 278600
    },
    {
      "epoch": 2.9498996935226893,
      "grad_norm": 0.9728649854660034,
      "learning_rate": 0.00044436088717694685,
      "loss": 0.7354,
      "step": 278650
    },
    {
      "epoch": 2.9504290153026926,
      "grad_norm": 0.9084465503692627,
      "learning_rate": 0.00044433183109668546,
      "loss": 0.7493,
      "step": 278700
    },
    {
      "epoch": 2.950958337082696,
      "grad_norm": 0.9416359066963196,
      "learning_rate": 0.0004443027683820066,
      "loss": 0.7499,
      "step": 278750
    },
    {
      "epoch": 2.9514876588626993,
      "grad_norm": 0.894271969795227,
      "learning_rate": 0.00044427369903390245,
      "loss": 0.7517,
      "step": 278800
    },
    {
      "epoch": 2.9520169806427026,
      "grad_norm": 0.921631395816803,
      "learning_rate": 0.00044424462305336557,
      "loss": 0.7398,
      "step": 278850
    },
    {
      "epoch": 2.952546302422706,
      "grad_norm": 0.9886452555656433,
      "learning_rate": 0.00044421554044138845,
      "loss": 0.7523,
      "step": 278900
    },
    {
      "epoch": 2.953075624202709,
      "grad_norm": 0.8164511322975159,
      "learning_rate": 0.00044418645119896394,
      "loss": 0.7534,
      "step": 278950
    },
    {
      "epoch": 2.9536049459827125,
      "grad_norm": 0.9499724507331848,
      "learning_rate": 0.0004441573553270853,
      "loss": 0.7409,
      "step": 279000
    },
    {
      "epoch": 2.9536049459827125,
      "eval_loss": 0.5451416373252869,
      "eval_runtime": 46.9044,
      "eval_samples_per_second": 3580.263,
      "eval_steps_per_second": 447.549,
      "step": 279000
    },
    {
      "epoch": 2.954134267762716,
      "grad_norm": 0.9153518676757812,
      "learning_rate": 0.0004441282528267457,
      "loss": 0.7446,
      "step": 279050
    },
    {
      "epoch": 2.9546635895427187,
      "grad_norm": 0.9918819069862366,
      "learning_rate": 0.00044409914369893875,
      "loss": 0.7318,
      "step": 279100
    },
    {
      "epoch": 2.9551929113227224,
      "grad_norm": 0.9035195112228394,
      "learning_rate": 0.0004440700279446582,
      "loss": 0.7361,
      "step": 279150
    },
    {
      "epoch": 2.9557222331027253,
      "grad_norm": 0.9197220802307129,
      "learning_rate": 0.0004440409055648981,
      "loss": 0.7504,
      "step": 279200
    },
    {
      "epoch": 2.9562515548827286,
      "grad_norm": 0.9829733967781067,
      "learning_rate": 0.00044401177656065266,
      "loss": 0.748,
      "step": 279250
    },
    {
      "epoch": 2.956780876662732,
      "grad_norm": 0.8369490504264832,
      "learning_rate": 0.00044398264093291627,
      "loss": 0.734,
      "step": 279300
    },
    {
      "epoch": 2.9573101984427352,
      "grad_norm": 0.9126352071762085,
      "learning_rate": 0.0004439534986826837,
      "loss": 0.7563,
      "step": 279350
    },
    {
      "epoch": 2.9578395202227385,
      "grad_norm": 0.9345511198043823,
      "learning_rate": 0.0004439243498109498,
      "loss": 0.7369,
      "step": 279400
    },
    {
      "epoch": 2.958368842002742,
      "grad_norm": 0.9060384035110474,
      "learning_rate": 0.0004438951943187097,
      "loss": 0.7363,
      "step": 279450
    },
    {
      "epoch": 2.958898163782745,
      "grad_norm": 0.8912213444709778,
      "learning_rate": 0.00044386603220695884,
      "loss": 0.7514,
      "step": 279500
    },
    {
      "epoch": 2.958898163782745,
      "eval_loss": 0.5463331341743469,
      "eval_runtime": 46.8505,
      "eval_samples_per_second": 3584.379,
      "eval_steps_per_second": 448.063,
      "step": 279500
    },
    {
      "epoch": 2.9594274855627485,
      "grad_norm": 0.8562350273132324,
      "learning_rate": 0.00044383686347669273,
      "loss": 0.7444,
      "step": 279550
    },
    {
      "epoch": 2.959956807342752,
      "grad_norm": 1.0700935125350952,
      "learning_rate": 0.00044380827170070806,
      "loss": 0.7475,
      "step": 279600
    },
    {
      "epoch": 2.960486129122755,
      "grad_norm": 0.9685263633728027,
      "learning_rate": 0.00044377908986871983,
      "loss": 0.7549,
      "step": 279650
    },
    {
      "epoch": 2.9610154509027584,
      "grad_norm": 0.9535108804702759,
      "learning_rate": 0.0004437499014211845,
      "loss": 0.7541,
      "step": 279700
    },
    {
      "epoch": 2.9615447726827617,
      "grad_norm": 0.9960382580757141,
      "learning_rate": 0.00044372070635909853,
      "loss": 0.7284,
      "step": 279750
    },
    {
      "epoch": 2.962074094462765,
      "grad_norm": 0.9544455409049988,
      "learning_rate": 0.0004436915046834588,
      "loss": 0.7484,
      "step": 279800
    },
    {
      "epoch": 2.962603416242768,
      "grad_norm": 0.924423098564148,
      "learning_rate": 0.00044366229639526206,
      "loss": 0.7309,
      "step": 279850
    },
    {
      "epoch": 2.9631327380227717,
      "grad_norm": 0.9454172849655151,
      "learning_rate": 0.0004436330814955056,
      "loss": 0.7589,
      "step": 279900
    },
    {
      "epoch": 2.9636620598027745,
      "grad_norm": 1.0019640922546387,
      "learning_rate": 0.00044360385998518673,
      "loss": 0.7479,
      "step": 279950
    },
    {
      "epoch": 2.964191381582778,
      "grad_norm": 0.9542968273162842,
      "learning_rate": 0.00044357463186530305,
      "loss": 0.7442,
      "step": 280000
    },
    {
      "epoch": 2.964191381582778,
      "eval_loss": 0.541800320148468,
      "eval_runtime": 46.8559,
      "eval_samples_per_second": 3583.969,
      "eval_steps_per_second": 448.012,
      "step": 280000
    },
    {
      "epoch": 2.964720703362781,
      "grad_norm": 0.9218693971633911,
      "learning_rate": 0.0004435453971368525,
      "loss": 0.7379,
      "step": 280050
    },
    {
      "epoch": 2.9652500251427845,
      "grad_norm": 0.8444242477416992,
      "learning_rate": 0.000443516155800833,
      "loss": 0.739,
      "step": 280100
    },
    {
      "epoch": 2.9657793469227878,
      "grad_norm": 0.8485341668128967,
      "learning_rate": 0.0004434869078582429,
      "loss": 0.7373,
      "step": 280150
    },
    {
      "epoch": 2.966308668702791,
      "grad_norm": 0.9775921702384949,
      "learning_rate": 0.0004434576533100808,
      "loss": 0.7515,
      "step": 280200
    },
    {
      "epoch": 2.9668379904827944,
      "grad_norm": 0.9665367603302002,
      "learning_rate": 0.00044342839215734533,
      "loss": 0.74,
      "step": 280250
    },
    {
      "epoch": 2.9673673122627977,
      "grad_norm": 0.9072951078414917,
      "learning_rate": 0.00044339912440103545,
      "loss": 0.7435,
      "step": 280300
    },
    {
      "epoch": 2.967896634042801,
      "grad_norm": 0.9101911187171936,
      "learning_rate": 0.0004433698500421505,
      "loss": 0.7429,
      "step": 280350
    },
    {
      "epoch": 2.9684259558228043,
      "grad_norm": 0.9759681224822998,
      "learning_rate": 0.0004433405690816896,
      "loss": 0.7425,
      "step": 280400
    },
    {
      "epoch": 2.9689552776028076,
      "grad_norm": 0.9802366495132446,
      "learning_rate": 0.0004433112815206527,
      "loss": 0.7495,
      "step": 280450
    },
    {
      "epoch": 2.969484599382811,
      "grad_norm": 0.9271864891052246,
      "learning_rate": 0.00044328198736003955,
      "loss": 0.7452,
      "step": 280500
    },
    {
      "epoch": 2.969484599382811,
      "eval_loss": 0.5431285500526428,
      "eval_runtime": 46.842,
      "eval_samples_per_second": 3585.034,
      "eval_steps_per_second": 448.145,
      "step": 280500
    },
    {
      "epoch": 2.9700139211628143,
      "grad_norm": 0.9384115934371948,
      "learning_rate": 0.0004432526866008503,
      "loss": 0.7523,
      "step": 280550
    },
    {
      "epoch": 2.970543242942817,
      "grad_norm": 0.8887982964515686,
      "learning_rate": 0.00044322337924408505,
      "loss": 0.7537,
      "step": 280600
    },
    {
      "epoch": 2.971072564722821,
      "grad_norm": 1.0088818073272705,
      "learning_rate": 0.0004431940652907446,
      "loss": 0.7488,
      "step": 280650
    },
    {
      "epoch": 2.9716018865028238,
      "grad_norm": 0.9074984788894653,
      "learning_rate": 0.0004431647447418295,
      "loss": 0.7305,
      "step": 280700
    },
    {
      "epoch": 2.972131208282827,
      "grad_norm": 0.8729921579360962,
      "learning_rate": 0.000443135417598341,
      "loss": 0.7442,
      "step": 280750
    },
    {
      "epoch": 2.9726605300628304,
      "grad_norm": 0.9929454922676086,
      "learning_rate": 0.0004431060838612801,
      "loss": 0.7387,
      "step": 280800
    },
    {
      "epoch": 2.9731898518428337,
      "grad_norm": 0.9973365664482117,
      "learning_rate": 0.0004430767435316483,
      "loss": 0.7371,
      "step": 280850
    },
    {
      "epoch": 2.973719173622837,
      "grad_norm": 0.8565338850021362,
      "learning_rate": 0.00044304739661044735,
      "loss": 0.7371,
      "step": 280900
    },
    {
      "epoch": 2.9742484954028403,
      "grad_norm": 0.9349876046180725,
      "learning_rate": 0.00044301804309867897,
      "loss": 0.7423,
      "step": 280950
    },
    {
      "epoch": 2.9747778171828436,
      "grad_norm": 0.9474101066589355,
      "learning_rate": 0.00044298868299734554,
      "loss": 0.7388,
      "step": 281000
    },
    {
      "epoch": 2.9747778171828436,
      "eval_loss": 0.5446969866752625,
      "eval_runtime": 46.7817,
      "eval_samples_per_second": 3589.65,
      "eval_steps_per_second": 448.722,
      "step": 281000
    },
    {
      "epoch": 2.975307138962847,
      "grad_norm": 0.9503059983253479,
      "learning_rate": 0.00044295931630744913,
      "loss": 0.7532,
      "step": 281050
    },
    {
      "epoch": 2.9758364607428502,
      "grad_norm": 0.8608439564704895,
      "learning_rate": 0.0004429299430299925,
      "loss": 0.7381,
      "step": 281100
    },
    {
      "epoch": 2.9763657825228536,
      "grad_norm": 0.9083091616630554,
      "learning_rate": 0.00044290056316597824,
      "loss": 0.7372,
      "step": 281150
    },
    {
      "epoch": 2.976895104302857,
      "grad_norm": 0.8896799087524414,
      "learning_rate": 0.00044287117671640964,
      "loss": 0.7478,
      "step": 281200
    },
    {
      "epoch": 2.97742442608286,
      "grad_norm": 0.898253321647644,
      "learning_rate": 0.00044284178368228977,
      "loss": 0.7427,
      "step": 281250
    },
    {
      "epoch": 2.9779537478628635,
      "grad_norm": 0.9096723198890686,
      "learning_rate": 0.0004428123840646221,
      "loss": 0.7442,
      "step": 281300
    },
    {
      "epoch": 2.9784830696428664,
      "grad_norm": 0.9018622040748596,
      "learning_rate": 0.00044278297786441034,
      "loss": 0.7493,
      "step": 281350
    },
    {
      "epoch": 2.97901239142287,
      "grad_norm": 0.9366388320922852,
      "learning_rate": 0.0004427535650826584,
      "loss": 0.7355,
      "step": 281400
    },
    {
      "epoch": 2.979541713202873,
      "grad_norm": 0.9400257468223572,
      "learning_rate": 0.0004427241457203705,
      "loss": 0.7549,
      "step": 281450
    },
    {
      "epoch": 2.9800710349828763,
      "grad_norm": 0.9622491598129272,
      "learning_rate": 0.00044269471977855093,
      "loss": 0.7382,
      "step": 281500
    },
    {
      "epoch": 2.9800710349828763,
      "eval_loss": 0.5429090857505798,
      "eval_runtime": 46.84,
      "eval_samples_per_second": 3585.187,
      "eval_steps_per_second": 448.164,
      "step": 281500
    },
    {
      "epoch": 2.9806003567628796,
      "grad_norm": 0.968166708946228,
      "learning_rate": 0.0004426652872582043,
      "loss": 0.7621,
      "step": 281550
    },
    {
      "epoch": 2.981129678542883,
      "grad_norm": 0.9050853252410889,
      "learning_rate": 0.00044263584816033535,
      "loss": 0.7518,
      "step": 281600
    },
    {
      "epoch": 2.981659000322886,
      "grad_norm": 0.8812987804412842,
      "learning_rate": 0.00044260640248594926,
      "loss": 0.7344,
      "step": 281650
    },
    {
      "epoch": 2.9821883221028895,
      "grad_norm": 1.0356736183166504,
      "learning_rate": 0.0004425769502360512,
      "loss": 0.7556,
      "step": 281700
    },
    {
      "epoch": 2.982717643882893,
      "grad_norm": 0.8918394446372986,
      "learning_rate": 0.00044254749141164673,
      "loss": 0.7513,
      "step": 281750
    },
    {
      "epoch": 2.983246965662896,
      "grad_norm": 0.9627615809440613,
      "learning_rate": 0.00044251861538611336,
      "loss": 0.741,
      "step": 281800
    },
    {
      "epoch": 2.9837762874428995,
      "grad_norm": 0.9446011185646057,
      "learning_rate": 0.0004424891435471533,
      "loss": 0.7366,
      "step": 281850
    },
    {
      "epoch": 2.9843056092229028,
      "grad_norm": 0.9583054780960083,
      "learning_rate": 0.0004424596651366846,
      "loss": 0.7439,
      "step": 281900
    },
    {
      "epoch": 2.984834931002906,
      "grad_norm": 0.9218555092811584,
      "learning_rate": 0.0004424301801557133,
      "loss": 0.7464,
      "step": 281950
    },
    {
      "epoch": 2.9853642527829094,
      "grad_norm": 0.9179697036743164,
      "learning_rate": 0.0004424006886052464,
      "loss": 0.7443,
      "step": 282000
    },
    {
      "epoch": 2.9853642527829094,
      "eval_loss": 0.5432524085044861,
      "eval_runtime": 46.9104,
      "eval_samples_per_second": 3579.804,
      "eval_steps_per_second": 447.491,
      "step": 282000
    },
    {
      "epoch": 2.9858935745629127,
      "grad_norm": 0.9687191843986511,
      "learning_rate": 0.00044237119048629053,
      "loss": 0.7456,
      "step": 282050
    },
    {
      "epoch": 2.9864228963429156,
      "grad_norm": 1.0005793571472168,
      "learning_rate": 0.00044234168579985274,
      "loss": 0.7405,
      "step": 282100
    },
    {
      "epoch": 2.9869522181229193,
      "grad_norm": 0.9257119297981262,
      "learning_rate": 0.0004423121745469403,
      "loss": 0.7559,
      "step": 282150
    },
    {
      "epoch": 2.987481539902922,
      "grad_norm": 0.9857224822044373,
      "learning_rate": 0.0004422826567285608,
      "loss": 0.7501,
      "step": 282200
    },
    {
      "epoch": 2.9880108616829255,
      "grad_norm": 0.9133673310279846,
      "learning_rate": 0.00044225313234572193,
      "loss": 0.7496,
      "step": 282250
    },
    {
      "epoch": 2.988540183462929,
      "grad_norm": 0.8382063508033752,
      "learning_rate": 0.0004422236013994316,
      "loss": 0.7425,
      "step": 282300
    },
    {
      "epoch": 2.989069505242932,
      "grad_norm": 0.9578269720077515,
      "learning_rate": 0.00044219406389069805,
      "loss": 0.7453,
      "step": 282350
    },
    {
      "epoch": 2.9895988270229354,
      "grad_norm": 1.0146785974502563,
      "learning_rate": 0.0004421645198205296,
      "loss": 0.7524,
      "step": 282400
    },
    {
      "epoch": 2.9901281488029388,
      "grad_norm": 0.9349549412727356,
      "learning_rate": 0.0004421349691899349,
      "loss": 0.7402,
      "step": 282450
    },
    {
      "epoch": 2.990657470582942,
      "grad_norm": 0.9681506156921387,
      "learning_rate": 0.0004421054119999228,
      "loss": 0.7461,
      "step": 282500
    },
    {
      "epoch": 2.990657470582942,
      "eval_loss": 0.5404471158981323,
      "eval_runtime": 46.8938,
      "eval_samples_per_second": 3581.074,
      "eval_steps_per_second": 447.65,
      "step": 282500
    },
    {
      "epoch": 2.9911867923629454,
      "grad_norm": 0.9561527967453003,
      "learning_rate": 0.0004420758482515025,
      "loss": 0.7454,
      "step": 282550
    },
    {
      "epoch": 2.9917161141429487,
      "grad_norm": 0.9035086631774902,
      "learning_rate": 0.0004420462779456831,
      "loss": 0.746,
      "step": 282600
    },
    {
      "epoch": 2.992245435922952,
      "grad_norm": 0.8750035166740417,
      "learning_rate": 0.00044201670108347425,
      "loss": 0.7411,
      "step": 282650
    },
    {
      "epoch": 2.9927747577029553,
      "grad_norm": 0.9376567006111145,
      "learning_rate": 0.0004419871176658856,
      "loss": 0.7547,
      "step": 282700
    },
    {
      "epoch": 2.9933040794829586,
      "grad_norm": 0.9624151587486267,
      "learning_rate": 0.00044195752769392717,
      "loss": 0.754,
      "step": 282750
    },
    {
      "epoch": 2.993833401262962,
      "grad_norm": 0.8991819620132446,
      "learning_rate": 0.00044192793116860907,
      "loss": 0.7192,
      "step": 282800
    },
    {
      "epoch": 2.994362723042965,
      "grad_norm": 0.8576734066009521,
      "learning_rate": 0.00044189832809094187,
      "loss": 0.7386,
      "step": 282850
    },
    {
      "epoch": 2.9948920448229686,
      "grad_norm": 0.8558012843132019,
      "learning_rate": 0.00044186871846193615,
      "loss": 0.7613,
      "step": 282900
    },
    {
      "epoch": 2.9954213666029714,
      "grad_norm": 0.8976514935493469,
      "learning_rate": 0.0004418391022826027,
      "loss": 0.7454,
      "step": 282950
    },
    {
      "epoch": 2.9959506883829747,
      "grad_norm": 0.9612805843353271,
      "learning_rate": 0.0004418094795539527,
      "loss": 0.7457,
      "step": 283000
    },
    {
      "epoch": 2.9959506883829747,
      "eval_loss": 0.5404255390167236,
      "eval_runtime": 46.8515,
      "eval_samples_per_second": 3584.302,
      "eval_steps_per_second": 448.054,
      "step": 283000
    },
    {
      "epoch": 2.996480010162978,
      "grad_norm": 0.9717360138893127,
      "learning_rate": 0.0004417798502769974,
      "loss": 0.749,
      "step": 283050
    },
    {
      "epoch": 2.9970093319429814,
      "grad_norm": 0.9254293441772461,
      "learning_rate": 0.00044175021445274834,
      "loss": 0.7312,
      "step": 283100
    },
    {
      "epoch": 2.9975386537229847,
      "grad_norm": 0.9489811062812805,
      "learning_rate": 0.0004417205720822172,
      "loss": 0.7382,
      "step": 283150
    },
    {
      "epoch": 2.998067975502988,
      "grad_norm": 0.8986642956733704,
      "learning_rate": 0.00044169092316641615,
      "loss": 0.7289,
      "step": 283200
    },
    {
      "epoch": 2.9985972972829913,
      "grad_norm": 0.8977892398834229,
      "learning_rate": 0.0004416612677063572,
      "loss": 0.7527,
      "step": 283250
    },
    {
      "epoch": 2.9991266190629946,
      "grad_norm": 1.0830990076065063,
      "learning_rate": 0.0004416316057030529,
      "loss": 0.7435,
      "step": 283300
    },
    {
      "epoch": 2.999655940842998,
      "grad_norm": 0.8770040273666382,
      "learning_rate": 0.00044160193715751583,
      "loss": 0.7413,
      "step": 283350
    },
    {
      "epoch": 3.000179969405201,
      "grad_norm": 0.9565626382827759,
      "learning_rate": 0.00044157226207075897,
      "loss": 0.7448,
      "step": 283400
    },
    {
      "epoch": 3.0007092911852045,
      "grad_norm": 0.9423290491104126,
      "learning_rate": 0.0004415425804437953,
      "loss": 0.7453,
      "step": 283450
    },
    {
      "epoch": 3.0012386129652078,
      "grad_norm": 0.8439348340034485,
      "learning_rate": 0.0004415128922776382,
      "loss": 0.7328,
      "step": 283500
    },
    {
      "epoch": 3.0012386129652078,
      "eval_loss": 0.5392642021179199,
      "eval_runtime": 46.8673,
      "eval_samples_per_second": 3583.098,
      "eval_steps_per_second": 447.903,
      "step": 283500
    },
    {
      "epoch": 3.001767934745211,
      "grad_norm": 0.9701187014579773,
      "learning_rate": 0.00044148319757330115,
      "loss": 0.7438,
      "step": 283550
    },
    {
      "epoch": 3.0022972565252144,
      "grad_norm": 0.8907928466796875,
      "learning_rate": 0.000441453496331798,
      "loss": 0.7217,
      "step": 283600
    },
    {
      "epoch": 3.0028265783052177,
      "grad_norm": 1.0383213758468628,
      "learning_rate": 0.00044142378855414264,
      "loss": 0.752,
      "step": 283650
    },
    {
      "epoch": 3.003355900085221,
      "grad_norm": 0.9059298634529114,
      "learning_rate": 0.00044139407424134935,
      "loss": 0.7531,
      "step": 283700
    },
    {
      "epoch": 3.003885221865224,
      "grad_norm": 0.8390018939971924,
      "learning_rate": 0.0004413643533944326,
      "loss": 0.7235,
      "step": 283750
    },
    {
      "epoch": 3.004414543645227,
      "grad_norm": 0.8626374006271362,
      "learning_rate": 0.00044133462601440697,
      "loss": 0.737,
      "step": 283800
    },
    {
      "epoch": 3.0049438654252305,
      "grad_norm": 0.9855251908302307,
      "learning_rate": 0.00044130548684453774,
      "loss": 0.7368,
      "step": 283850
    },
    {
      "epoch": 3.005473187205234,
      "grad_norm": 0.9506783485412598,
      "learning_rate": 0.00044127574653195104,
      "loss": 0.7472,
      "step": 283900
    },
    {
      "epoch": 3.006002508985237,
      "grad_norm": 0.8833898305892944,
      "learning_rate": 0.00044124599968928035,
      "loss": 0.7308,
      "step": 283950
    },
    {
      "epoch": 3.0065318307652404,
      "grad_norm": 0.8973027467727661,
      "learning_rate": 0.0004412162463175414,
      "loss": 0.7447,
      "step": 284000
    },
    {
      "epoch": 3.0065318307652404,
      "eval_loss": 0.5410707592964172,
      "eval_runtime": 46.8461,
      "eval_samples_per_second": 3584.715,
      "eval_steps_per_second": 448.105,
      "step": 284000
    },
    {
      "epoch": 3.0070611525452438,
      "grad_norm": 0.87896329164505,
      "learning_rate": 0.0004411864864177499,
      "loss": 0.7523,
      "step": 284050
    },
    {
      "epoch": 3.007590474325247,
      "grad_norm": 0.9168000817298889,
      "learning_rate": 0.000441156719990922,
      "loss": 0.7296,
      "step": 284100
    },
    {
      "epoch": 3.0081197961052504,
      "grad_norm": 0.8855535387992859,
      "learning_rate": 0.00044112694703807363,
      "loss": 0.7374,
      "step": 284150
    },
    {
      "epoch": 3.0086491178852537,
      "grad_norm": 0.9256375432014465,
      "learning_rate": 0.00044109716756022144,
      "loss": 0.74,
      "step": 284200
    },
    {
      "epoch": 3.009178439665257,
      "grad_norm": 1.0275696516036987,
      "learning_rate": 0.0004410673815583821,
      "loss": 0.7509,
      "step": 284250
    },
    {
      "epoch": 3.0097077614452603,
      "grad_norm": 0.9486094117164612,
      "learning_rate": 0.0004410375890335724,
      "loss": 0.7324,
      "step": 284300
    },
    {
      "epoch": 3.0102370832252636,
      "grad_norm": 0.9292178750038147,
      "learning_rate": 0.0004410077899868094,
      "loss": 0.7444,
      "step": 284350
    },
    {
      "epoch": 3.010766405005267,
      "grad_norm": 0.8718186616897583,
      "learning_rate": 0.0004409779844191105,
      "loss": 0.741,
      "step": 284400
    },
    {
      "epoch": 3.0112957267852702,
      "grad_norm": 1.0005265474319458,
      "learning_rate": 0.0004409481723314933,
      "loss": 0.7345,
      "step": 284450
    },
    {
      "epoch": 3.011825048565273,
      "grad_norm": 0.9915794134140015,
      "learning_rate": 0.0004409183537249756,
      "loss": 0.741,
      "step": 284500
    },
    {
      "epoch": 3.011825048565273,
      "eval_loss": 0.5404397249221802,
      "eval_runtime": 46.8698,
      "eval_samples_per_second": 3582.904,
      "eval_steps_per_second": 447.879,
      "step": 284500
    },
    {
      "epoch": 3.0123543703452764,
      "grad_norm": 1.025410771369934,
      "learning_rate": 0.00044088852860057516,
      "loss": 0.7385,
      "step": 284550
    },
    {
      "epoch": 3.0128836921252797,
      "grad_norm": 0.8970988392829895,
      "learning_rate": 0.00044085869695931044,
      "loss": 0.7398,
      "step": 284600
    },
    {
      "epoch": 3.013413013905283,
      "grad_norm": 1.0576359033584595,
      "learning_rate": 0.0004408288588021998,
      "loss": 0.7435,
      "step": 284650
    },
    {
      "epoch": 3.0139423356852864,
      "grad_norm": 0.9615554213523865,
      "learning_rate": 0.0004407990141302619,
      "loss": 0.7368,
      "step": 284700
    },
    {
      "epoch": 3.0144716574652897,
      "grad_norm": 0.9342678189277649,
      "learning_rate": 0.0004407691629445156,
      "loss": 0.7324,
      "step": 284750
    },
    {
      "epoch": 3.015000979245293,
      "grad_norm": 0.910186767578125,
      "learning_rate": 0.0004407393052459802,
      "loss": 0.7376,
      "step": 284800
    },
    {
      "epoch": 3.0155303010252963,
      "grad_norm": 0.8565733432769775,
      "learning_rate": 0.0004407094410356747,
      "loss": 0.7272,
      "step": 284850
    },
    {
      "epoch": 3.0160596228052996,
      "grad_norm": 0.954758882522583,
      "learning_rate": 0.0004406795703146188,
      "loss": 0.7256,
      "step": 284900
    },
    {
      "epoch": 3.016588944585303,
      "grad_norm": 0.8288285732269287,
      "learning_rate": 0.0004406496930838324,
      "loss": 0.7376,
      "step": 284950
    },
    {
      "epoch": 3.0171182663653062,
      "grad_norm": 0.8615229725837708,
      "learning_rate": 0.00044061980934433537,
      "loss": 0.7408,
      "step": 285000
    },
    {
      "epoch": 3.0171182663653062,
      "eval_loss": 0.5392404198646545,
      "eval_runtime": 46.8531,
      "eval_samples_per_second": 3584.179,
      "eval_steps_per_second": 448.038,
      "step": 285000
    },
    {
      "epoch": 3.0176475881453095,
      "grad_norm": 0.9274173378944397,
      "learning_rate": 0.00044058991909714796,
      "loss": 0.7468,
      "step": 285050
    },
    {
      "epoch": 3.018176909925313,
      "grad_norm": 0.9353461861610413,
      "learning_rate": 0.0004405600223432906,
      "loss": 0.7338,
      "step": 285100
    },
    {
      "epoch": 3.018706231705316,
      "grad_norm": 0.8817136883735657,
      "learning_rate": 0.0004405301190837839,
      "loss": 0.7289,
      "step": 285150
    },
    {
      "epoch": 3.0192355534853195,
      "grad_norm": 0.9683058261871338,
      "learning_rate": 0.00044050020931964894,
      "loss": 0.7297,
      "step": 285200
    },
    {
      "epoch": 3.0197648752653223,
      "grad_norm": 0.8691233992576599,
      "learning_rate": 0.0004404702930519067,
      "loss": 0.7334,
      "step": 285250
    },
    {
      "epoch": 3.0202941970453256,
      "grad_norm": 1.014804720878601,
      "learning_rate": 0.00044044037028157835,
      "loss": 0.7184,
      "step": 285300
    },
    {
      "epoch": 3.020823518825329,
      "grad_norm": 0.9111910462379456,
      "learning_rate": 0.0004404104410096857,
      "loss": 0.7355,
      "step": 285350
    },
    {
      "epoch": 3.0213528406053323,
      "grad_norm": 0.8644565939903259,
      "learning_rate": 0.0004403805052372504,
      "loss": 0.7351,
      "step": 285400
    },
    {
      "epoch": 3.0218821623853356,
      "grad_norm": 0.9216263294219971,
      "learning_rate": 0.0004403505629652945,
      "loss": 0.7307,
      "step": 285450
    },
    {
      "epoch": 3.022411484165339,
      "grad_norm": 0.9654911756515503,
      "learning_rate": 0.00044032061419484013,
      "loss": 0.7312,
      "step": 285500
    },
    {
      "epoch": 3.022411484165339,
      "eval_loss": 0.5412812829017639,
      "eval_runtime": 46.7647,
      "eval_samples_per_second": 3590.957,
      "eval_steps_per_second": 448.886,
      "step": 285500
    },
    {
      "epoch": 3.022940805945342,
      "grad_norm": 0.9450129866600037,
      "learning_rate": 0.0004402906589269099,
      "loss": 0.7442,
      "step": 285550
    },
    {
      "epoch": 3.0234701277253455,
      "grad_norm": 0.8603518009185791,
      "learning_rate": 0.00044026069716252627,
      "loss": 0.7156,
      "step": 285600
    },
    {
      "epoch": 3.023999449505349,
      "grad_norm": 1.0285899639129639,
      "learning_rate": 0.0004402307289027123,
      "loss": 0.7407,
      "step": 285650
    },
    {
      "epoch": 3.024528771285352,
      "grad_norm": 0.8817272186279297,
      "learning_rate": 0.0004402007541484909,
      "loss": 0.7201,
      "step": 285700
    },
    {
      "epoch": 3.0250580930653554,
      "grad_norm": 0.8825114965438843,
      "learning_rate": 0.0004401707729008856,
      "loss": 0.7417,
      "step": 285750
    },
    {
      "epoch": 3.0255874148453588,
      "grad_norm": 0.9585926532745361,
      "learning_rate": 0.00044014078516091984,
      "loss": 0.7313,
      "step": 285800
    },
    {
      "epoch": 3.026116736625362,
      "grad_norm": 0.980270266532898,
      "learning_rate": 0.0004401107909296174,
      "loss": 0.7366,
      "step": 285850
    },
    {
      "epoch": 3.0266460584053654,
      "grad_norm": 0.9310904145240784,
      "learning_rate": 0.0004400807902080022,
      "loss": 0.7237,
      "step": 285900
    },
    {
      "epoch": 3.0271753801853687,
      "grad_norm": 1.039461374282837,
      "learning_rate": 0.00044005078299709857,
      "loss": 0.718,
      "step": 285950
    },
    {
      "epoch": 3.0277047019653716,
      "grad_norm": 0.9768942594528198,
      "learning_rate": 0.00044002136963549265,
      "loss": 0.7401,
      "step": 286000
    },
    {
      "epoch": 3.0277047019653716,
      "eval_loss": 0.5412606596946716,
      "eval_runtime": 46.8256,
      "eval_samples_per_second": 3586.283,
      "eval_steps_per_second": 448.301,
      "step": 286000
    },
    {
      "epoch": 3.028234023745375,
      "grad_norm": 0.8575850129127502,
      "learning_rate": 0.00043999134957882035,
      "loss": 0.7363,
      "step": 286050
    },
    {
      "epoch": 3.028763345525378,
      "grad_norm": 0.9868930578231812,
      "learning_rate": 0.0004399613230359131,
      "loss": 0.7434,
      "step": 286100
    },
    {
      "epoch": 3.0292926673053815,
      "grad_norm": 1.0085701942443848,
      "learning_rate": 0.00043993129000779595,
      "loss": 0.7439,
      "step": 286150
    },
    {
      "epoch": 3.029821989085385,
      "grad_norm": 1.00241219997406,
      "learning_rate": 0.0004399012504954942,
      "loss": 0.7468,
      "step": 286200
    },
    {
      "epoch": 3.030351310865388,
      "grad_norm": 0.9775829315185547,
      "learning_rate": 0.0004398712045000334,
      "loss": 0.7472,
      "step": 286250
    },
    {
      "epoch": 3.0308806326453914,
      "grad_norm": 0.9150921702384949,
      "learning_rate": 0.0004398411520224393,
      "loss": 0.7249,
      "step": 286300
    },
    {
      "epoch": 3.0314099544253947,
      "grad_norm": 0.8830819725990295,
      "learning_rate": 0.0004398110930637379,
      "loss": 0.735,
      "step": 286350
    },
    {
      "epoch": 3.031939276205398,
      "grad_norm": 0.9792884588241577,
      "learning_rate": 0.0004397810276249554,
      "loss": 0.7354,
      "step": 286400
    },
    {
      "epoch": 3.0324685979854014,
      "grad_norm": 1.0303752422332764,
      "learning_rate": 0.0004397509557071182,
      "loss": 0.7379,
      "step": 286450
    },
    {
      "epoch": 3.0329979197654047,
      "grad_norm": 0.9739937782287598,
      "learning_rate": 0.000439720877311253,
      "loss": 0.7494,
      "step": 286500
    },
    {
      "epoch": 3.0329979197654047,
      "eval_loss": 0.5369840860366821,
      "eval_runtime": 46.7856,
      "eval_samples_per_second": 3589.355,
      "eval_steps_per_second": 448.685,
      "step": 286500
    },
    {
      "epoch": 3.033527241545408,
      "grad_norm": 0.8764111995697021,
      "learning_rate": 0.0004396907924383866,
      "loss": 0.732,
      "step": 286550
    },
    {
      "epoch": 3.0340565633254113,
      "grad_norm": 0.8542008399963379,
      "learning_rate": 0.0004396607010895461,
      "loss": 0.7245,
      "step": 286600
    },
    {
      "epoch": 3.0345858851054146,
      "grad_norm": 0.9640468955039978,
      "learning_rate": 0.00043963060326575884,
      "loss": 0.7349,
      "step": 286650
    },
    {
      "epoch": 3.035115206885418,
      "grad_norm": 0.9483156204223633,
      "learning_rate": 0.0004396004989680523,
      "loss": 0.7356,
      "step": 286700
    },
    {
      "epoch": 3.035644528665421,
      "grad_norm": 1.0276740789413452,
      "learning_rate": 0.0004395703881974543,
      "loss": 0.7449,
      "step": 286750
    },
    {
      "epoch": 3.036173850445424,
      "grad_norm": 0.920870840549469,
      "learning_rate": 0.0004395402709549927,
      "loss": 0.7375,
      "step": 286800
    },
    {
      "epoch": 3.0367031722254274,
      "grad_norm": 0.9773640632629395,
      "learning_rate": 0.00043951014724169583,
      "loss": 0.7242,
      "step": 286850
    },
    {
      "epoch": 3.0372324940054307,
      "grad_norm": 0.8843969106674194,
      "learning_rate": 0.0004394800170585921,
      "loss": 0.7221,
      "step": 286900
    },
    {
      "epoch": 3.037761815785434,
      "grad_norm": 0.9873782992362976,
      "learning_rate": 0.00043944988040670995,
      "loss": 0.7341,
      "step": 286950
    },
    {
      "epoch": 3.0382911375654373,
      "grad_norm": 0.89926677942276,
      "learning_rate": 0.0004394197372870784,
      "loss": 0.7362,
      "step": 287000
    },
    {
      "epoch": 3.0382911375654373,
      "eval_loss": 0.5399380326271057,
      "eval_runtime": 46.7874,
      "eval_samples_per_second": 3589.212,
      "eval_steps_per_second": 448.668,
      "step": 287000
    },
    {
      "epoch": 3.0388204593454406,
      "grad_norm": 0.9690974950790405,
      "learning_rate": 0.00043938958770072645,
      "loss": 0.7272,
      "step": 287050
    },
    {
      "epoch": 3.039349781125444,
      "grad_norm": 0.9152618050575256,
      "learning_rate": 0.00043935943164868355,
      "loss": 0.729,
      "step": 287100
    },
    {
      "epoch": 3.0398791029054473,
      "grad_norm": 0.9266253113746643,
      "learning_rate": 0.00043932926913197904,
      "loss": 0.7225,
      "step": 287150
    },
    {
      "epoch": 3.0404084246854506,
      "grad_norm": 0.9547414183616638,
      "learning_rate": 0.00043929910015164266,
      "loss": 0.7404,
      "step": 287200
    },
    {
      "epoch": 3.040937746465454,
      "grad_norm": 0.8446775674819946,
      "learning_rate": 0.0004392689247087045,
      "loss": 0.729,
      "step": 287250
    },
    {
      "epoch": 3.041467068245457,
      "grad_norm": 0.9271816611289978,
      "learning_rate": 0.0004392387428041946,
      "loss": 0.729,
      "step": 287300
    },
    {
      "epoch": 3.0419963900254605,
      "grad_norm": 0.8854818344116211,
      "learning_rate": 0.00043920855443914343,
      "loss": 0.7356,
      "step": 287350
    },
    {
      "epoch": 3.042525711805464,
      "grad_norm": 0.8913711905479431,
      "learning_rate": 0.00043917835961458163,
      "loss": 0.7336,
      "step": 287400
    },
    {
      "epoch": 3.043055033585467,
      "grad_norm": 0.8991073369979858,
      "learning_rate": 0.00043914815833154004,
      "loss": 0.7325,
      "step": 287450
    },
    {
      "epoch": 3.04358435536547,
      "grad_norm": 0.9226232767105103,
      "learning_rate": 0.00043911795059104966,
      "loss": 0.7378,
      "step": 287500
    },
    {
      "epoch": 3.04358435536547,
      "eval_loss": 0.5395886898040771,
      "eval_runtime": 46.852,
      "eval_samples_per_second": 3584.267,
      "eval_steps_per_second": 448.049,
      "step": 287500
    },
    {
      "epoch": 3.0441136771454733,
      "grad_norm": 0.9425764679908752,
      "learning_rate": 0.0004390877363941418,
      "loss": 0.7412,
      "step": 287550
    },
    {
      "epoch": 3.0446429989254766,
      "grad_norm": 0.9612979888916016,
      "learning_rate": 0.00043905751574184796,
      "loss": 0.7397,
      "step": 287600
    },
    {
      "epoch": 3.04517232070548,
      "grad_norm": 0.8795854449272156,
      "learning_rate": 0.00043902728863519987,
      "loss": 0.7283,
      "step": 287650
    },
    {
      "epoch": 3.0457016424854833,
      "grad_norm": 1.001590609550476,
      "learning_rate": 0.0004389970550752295,
      "loss": 0.7326,
      "step": 287700
    },
    {
      "epoch": 3.0462309642654866,
      "grad_norm": 0.9876541495323181,
      "learning_rate": 0.00043896681506296894,
      "loss": 0.7454,
      "step": 287750
    },
    {
      "epoch": 3.04676028604549,
      "grad_norm": 0.8989989757537842,
      "learning_rate": 0.00043893656859945063,
      "loss": 0.7362,
      "step": 287800
    },
    {
      "epoch": 3.047289607825493,
      "grad_norm": 0.8993496894836426,
      "learning_rate": 0.00043890631568570715,
      "loss": 0.7493,
      "step": 287850
    },
    {
      "epoch": 3.0478189296054965,
      "grad_norm": 1.0445730686187744,
      "learning_rate": 0.0004388760563227713,
      "loss": 0.738,
      "step": 287900
    },
    {
      "epoch": 3.0483482513855,
      "grad_norm": 0.8222042322158813,
      "learning_rate": 0.0004388457905116763,
      "loss": 0.7387,
      "step": 287950
    },
    {
      "epoch": 3.048877573165503,
      "grad_norm": 0.9096007347106934,
      "learning_rate": 0.00043881612376179467,
      "loss": 0.738,
      "step": 288000
    },
    {
      "epoch": 3.048877573165503,
      "eval_loss": 0.536512017250061,
      "eval_runtime": 46.8247,
      "eval_samples_per_second": 3586.358,
      "eval_steps_per_second": 448.311,
      "step": 288000
    },
    {
      "epoch": 3.0494068949455064,
      "grad_norm": 0.9598349928855896,
      "learning_rate": 0.00043878584518639274,
      "loss": 0.748,
      "step": 288050
    },
    {
      "epoch": 3.0499362167255097,
      "grad_norm": 0.9432545900344849,
      "learning_rate": 0.00043875556016591125,
      "loss": 0.7194,
      "step": 288100
    },
    {
      "epoch": 3.050465538505513,
      "grad_norm": 0.9534692764282227,
      "learning_rate": 0.00043872526870138417,
      "loss": 0.746,
      "step": 288150
    },
    {
      "epoch": 3.0509948602855164,
      "grad_norm": 0.9842408299446106,
      "learning_rate": 0.00043869497079384565,
      "loss": 0.7333,
      "step": 288200
    },
    {
      "epoch": 3.0515241820655197,
      "grad_norm": 0.9758425354957581,
      "learning_rate": 0.00043866466644433,
      "loss": 0.7409,
      "step": 288250
    },
    {
      "epoch": 3.0520535038455225,
      "grad_norm": 0.9121555089950562,
      "learning_rate": 0.00043863435565387183,
      "loss": 0.734,
      "step": 288300
    },
    {
      "epoch": 3.052582825625526,
      "grad_norm": 0.9486806392669678,
      "learning_rate": 0.00043860403842350596,
      "loss": 0.7355,
      "step": 288350
    },
    {
      "epoch": 3.053112147405529,
      "grad_norm": 0.9015882611274719,
      "learning_rate": 0.0004385737147542673,
      "loss": 0.7459,
      "step": 288400
    },
    {
      "epoch": 3.0536414691855325,
      "grad_norm": 0.9616504907608032,
      "learning_rate": 0.0004385433846471913,
      "loss": 0.7267,
      "step": 288450
    },
    {
      "epoch": 3.054170790965536,
      "grad_norm": 0.9902986288070679,
      "learning_rate": 0.0004385130481033133,
      "loss": 0.7335,
      "step": 288500
    },
    {
      "epoch": 3.054170790965536,
      "eval_loss": 0.5333116054534912,
      "eval_runtime": 46.7991,
      "eval_samples_per_second": 3588.313,
      "eval_steps_per_second": 448.555,
      "step": 288500
    },
    {
      "epoch": 3.054700112745539,
      "grad_norm": 0.9334709048271179,
      "learning_rate": 0.00043848270512366884,
      "loss": 0.7252,
      "step": 288550
    },
    {
      "epoch": 3.0552294345255424,
      "grad_norm": 0.9333123564720154,
      "learning_rate": 0.0004384523557092941,
      "loss": 0.7246,
      "step": 288600
    },
    {
      "epoch": 3.0557587563055457,
      "grad_norm": 0.9609778523445129,
      "learning_rate": 0.00043842199986122494,
      "loss": 0.7347,
      "step": 288650
    },
    {
      "epoch": 3.056288078085549,
      "grad_norm": 0.9705793857574463,
      "learning_rate": 0.00043839163758049784,
      "loss": 0.7397,
      "step": 288700
    },
    {
      "epoch": 3.0568173998655523,
      "grad_norm": 0.918257474899292,
      "learning_rate": 0.00043836126886814933,
      "loss": 0.7418,
      "step": 288750
    },
    {
      "epoch": 3.0573467216455557,
      "grad_norm": 0.9384095072746277,
      "learning_rate": 0.0004383308937252162,
      "loss": 0.7314,
      "step": 288800
    },
    {
      "epoch": 3.057876043425559,
      "grad_norm": 0.9755362868309021,
      "learning_rate": 0.00043830051215273534,
      "loss": 0.7291,
      "step": 288850
    },
    {
      "epoch": 3.0584053652055623,
      "grad_norm": 0.9660087823867798,
      "learning_rate": 0.00043827012415174416,
      "loss": 0.7288,
      "step": 288900
    },
    {
      "epoch": 3.0589346869855656,
      "grad_norm": 0.9240554571151733,
      "learning_rate": 0.00043823972972327995,
      "loss": 0.7209,
      "step": 288950
    },
    {
      "epoch": 3.059464008765569,
      "grad_norm": 0.9017689824104309,
      "learning_rate": 0.0004382093288683804,
      "loss": 0.7486,
      "step": 289000
    },
    {
      "epoch": 3.059464008765569,
      "eval_loss": 0.5381922125816345,
      "eval_runtime": 46.8204,
      "eval_samples_per_second": 3586.685,
      "eval_steps_per_second": 448.352,
      "step": 289000
    },
    {
      "epoch": 3.0599933305455718,
      "grad_norm": 0.833736777305603,
      "learning_rate": 0.00043817892158808336,
      "loss": 0.746,
      "step": 289050
    },
    {
      "epoch": 3.060522652325575,
      "grad_norm": 1.0109326839447021,
      "learning_rate": 0.00043814850788342696,
      "loss": 0.7253,
      "step": 289100
    },
    {
      "epoch": 3.0610519741055784,
      "grad_norm": 0.8618054986000061,
      "learning_rate": 0.00043811808775544954,
      "loss": 0.731,
      "step": 289150
    },
    {
      "epoch": 3.0615812958855817,
      "grad_norm": 0.8116680979728699,
      "learning_rate": 0.00043808766120518954,
      "loss": 0.7526,
      "step": 289200
    },
    {
      "epoch": 3.062110617665585,
      "grad_norm": 0.8678234219551086,
      "learning_rate": 0.0004380572282336858,
      "loss": 0.7385,
      "step": 289250
    },
    {
      "epoch": 3.0626399394455883,
      "grad_norm": 0.9844681620597839,
      "learning_rate": 0.00043802678884197725,
      "loss": 0.7206,
      "step": 289300
    },
    {
      "epoch": 3.0631692612255916,
      "grad_norm": 0.9044308662414551,
      "learning_rate": 0.00043799634303110316,
      "loss": 0.7293,
      "step": 289350
    },
    {
      "epoch": 3.063698583005595,
      "grad_norm": 1.0447254180908203,
      "learning_rate": 0.0004379658908021027,
      "loss": 0.7237,
      "step": 289400
    },
    {
      "epoch": 3.0642279047855983,
      "grad_norm": 0.9788016676902771,
      "learning_rate": 0.0004379354321560158,
      "loss": 0.7323,
      "step": 289450
    },
    {
      "epoch": 3.0647572265656016,
      "grad_norm": 1.050464153289795,
      "learning_rate": 0.0004379049670938821,
      "loss": 0.7298,
      "step": 289500
    },
    {
      "epoch": 3.0647572265656016,
      "eval_loss": 0.5348368883132935,
      "eval_runtime": 46.8054,
      "eval_samples_per_second": 3587.832,
      "eval_steps_per_second": 448.495,
      "step": 289500
    },
    {
      "epoch": 3.065286548345605,
      "grad_norm": 0.9334766268730164,
      "learning_rate": 0.00043787449561674175,
      "loss": 0.7296,
      "step": 289550
    },
    {
      "epoch": 3.065815870125608,
      "grad_norm": 0.9099162817001343,
      "learning_rate": 0.0004378440177256351,
      "loss": 0.7276,
      "step": 289600
    },
    {
      "epoch": 3.0663451919056115,
      "grad_norm": 0.8608538508415222,
      "learning_rate": 0.00043781353342160247,
      "loss": 0.7251,
      "step": 289650
    },
    {
      "epoch": 3.066874513685615,
      "grad_norm": 0.8466284275054932,
      "learning_rate": 0.0004377830427056847,
      "loss": 0.73,
      "step": 289700
    },
    {
      "epoch": 3.067403835465618,
      "grad_norm": 0.9413948059082031,
      "learning_rate": 0.00043775254557892277,
      "loss": 0.7327,
      "step": 289750
    },
    {
      "epoch": 3.067933157245621,
      "grad_norm": 0.9529135823249817,
      "learning_rate": 0.00043772204204235775,
      "loss": 0.7394,
      "step": 289800
    },
    {
      "epoch": 3.0684624790256243,
      "grad_norm": 0.8803059458732605,
      "learning_rate": 0.0004376915320970311,
      "loss": 0.7297,
      "step": 289850
    },
    {
      "epoch": 3.0689918008056276,
      "grad_norm": 0.8398128747940063,
      "learning_rate": 0.0004376610157439843,
      "loss": 0.7256,
      "step": 289900
    },
    {
      "epoch": 3.069521122585631,
      "grad_norm": 0.9832459688186646,
      "learning_rate": 0.00043763049298425926,
      "loss": 0.7386,
      "step": 289950
    },
    {
      "epoch": 3.0700504443656342,
      "grad_norm": 0.9501321911811829,
      "learning_rate": 0.0004375999638188981,
      "loss": 0.7372,
      "step": 290000
    },
    {
      "epoch": 3.0700504443656342,
      "eval_loss": 0.5377244353294373,
      "eval_runtime": 46.8221,
      "eval_samples_per_second": 3586.551,
      "eval_steps_per_second": 448.335,
      "step": 290000
    },
    {
      "epoch": 3.0705797661456375,
      "grad_norm": 0.9298372268676758,
      "learning_rate": 0.0004375694282489429,
      "loss": 0.7224,
      "step": 290050
    },
    {
      "epoch": 3.071109087925641,
      "grad_norm": 1.0113152265548706,
      "learning_rate": 0.0004375388862754362,
      "loss": 0.7338,
      "step": 290100
    },
    {
      "epoch": 3.071638409705644,
      "grad_norm": 0.944926917552948,
      "learning_rate": 0.00043750894892967884,
      "loss": 0.741,
      "step": 290150
    },
    {
      "epoch": 3.0721677314856475,
      "grad_norm": 0.9651760458946228,
      "learning_rate": 0.00043747839428021665,
      "loss": 0.7351,
      "step": 290200
    },
    {
      "epoch": 3.072697053265651,
      "grad_norm": 0.9697668552398682,
      "learning_rate": 0.00043744783323031075,
      "loss": 0.732,
      "step": 290250
    },
    {
      "epoch": 3.073226375045654,
      "grad_norm": 0.969886064529419,
      "learning_rate": 0.0004374172657810045,
      "loss": 0.7303,
      "step": 290300
    },
    {
      "epoch": 3.0737556968256574,
      "grad_norm": 1.011217713356018,
      "learning_rate": 0.0004373866919333417,
      "loss": 0.7413,
      "step": 290350
    },
    {
      "epoch": 3.0742850186056607,
      "grad_norm": 0.8804752826690674,
      "learning_rate": 0.0004373561116883658,
      "loss": 0.7439,
      "step": 290400
    },
    {
      "epoch": 3.074814340385664,
      "grad_norm": 0.9570300579071045,
      "learning_rate": 0.000437325525047121,
      "loss": 0.7279,
      "step": 290450
    },
    {
      "epoch": 3.0753436621656673,
      "grad_norm": 0.9563131332397461,
      "learning_rate": 0.0004372949320106515,
      "loss": 0.7345,
      "step": 290500
    },
    {
      "epoch": 3.0753436621656673,
      "eval_loss": 0.5330113768577576,
      "eval_runtime": 46.9273,
      "eval_samples_per_second": 3578.515,
      "eval_steps_per_second": 447.33,
      "step": 290500
    },
    {
      "epoch": 3.07587298394567,
      "grad_norm": 0.9760550260543823,
      "learning_rate": 0.0004372643325800017,
      "loss": 0.7272,
      "step": 290550
    },
    {
      "epoch": 3.0764023057256735,
      "grad_norm": 0.8925489783287048,
      "learning_rate": 0.00043723372675621633,
      "loss": 0.7384,
      "step": 290600
    },
    {
      "epoch": 3.076931627505677,
      "grad_norm": 0.8732435703277588,
      "learning_rate": 0.00043720311454034004,
      "loss": 0.738,
      "step": 290650
    },
    {
      "epoch": 3.07746094928568,
      "grad_norm": 0.9504793882369995,
      "learning_rate": 0.00043717249593341824,
      "loss": 0.7348,
      "step": 290700
    },
    {
      "epoch": 3.0779902710656835,
      "grad_norm": 0.9062842130661011,
      "learning_rate": 0.00043714187093649593,
      "loss": 0.7172,
      "step": 290750
    },
    {
      "epoch": 3.0785195928456868,
      "grad_norm": 0.999653160572052,
      "learning_rate": 0.0004371112395506189,
      "loss": 0.7349,
      "step": 290800
    },
    {
      "epoch": 3.07904891462569,
      "grad_norm": 0.9242513179779053,
      "learning_rate": 0.00043708060177683275,
      "loss": 0.7359,
      "step": 290850
    },
    {
      "epoch": 3.0795782364056934,
      "grad_norm": 0.8928990364074707,
      "learning_rate": 0.00043704995761618335,
      "loss": 0.7408,
      "step": 290900
    },
    {
      "epoch": 3.0801075581856967,
      "grad_norm": 0.9105784296989441,
      "learning_rate": 0.0004370193070697171,
      "loss": 0.727,
      "step": 290950
    },
    {
      "epoch": 3.0806368799657,
      "grad_norm": 0.9466453194618225,
      "learning_rate": 0.0004369886501384803,
      "loss": 0.7341,
      "step": 291000
    },
    {
      "epoch": 3.0806368799657,
      "eval_loss": 0.5337716937065125,
      "eval_runtime": 46.8797,
      "eval_samples_per_second": 3582.146,
      "eval_steps_per_second": 447.784,
      "step": 291000
    },
    {
      "epoch": 3.0811662017457033,
      "grad_norm": 0.9368612766265869,
      "learning_rate": 0.0004369579868235195,
      "loss": 0.7297,
      "step": 291050
    },
    {
      "epoch": 3.0816955235257066,
      "grad_norm": 1.0368789434432983,
      "learning_rate": 0.00043692731712588164,
      "loss": 0.7391,
      "step": 291100
    },
    {
      "epoch": 3.08222484530571,
      "grad_norm": 1.0349009037017822,
      "learning_rate": 0.00043689664104661367,
      "loss": 0.7332,
      "step": 291150
    },
    {
      "epoch": 3.0827541670857133,
      "grad_norm": 0.8884444236755371,
      "learning_rate": 0.000436865958586763,
      "loss": 0.7348,
      "step": 291200
    },
    {
      "epoch": 3.0832834888657166,
      "grad_norm": 0.9925234913825989,
      "learning_rate": 0.000436835269747377,
      "loss": 0.7315,
      "step": 291250
    },
    {
      "epoch": 3.0838128106457194,
      "grad_norm": 0.9453228712081909,
      "learning_rate": 0.0004368045745295034,
      "loss": 0.7351,
      "step": 291300
    },
    {
      "epoch": 3.0843421324257227,
      "grad_norm": 0.9051522612571716,
      "learning_rate": 0.00043677387293419016,
      "loss": 0.7282,
      "step": 291350
    },
    {
      "epoch": 3.084871454205726,
      "grad_norm": 0.9304608702659607,
      "learning_rate": 0.00043674316496248537,
      "loss": 0.7272,
      "step": 291400
    },
    {
      "epoch": 3.0854007759857294,
      "grad_norm": 0.8880490064620972,
      "learning_rate": 0.0004367124506154374,
      "loss": 0.7321,
      "step": 291450
    },
    {
      "epoch": 3.0859300977657327,
      "grad_norm": 0.8804534077644348,
      "learning_rate": 0.00043668172989409483,
      "loss": 0.7441,
      "step": 291500
    },
    {
      "epoch": 3.0859300977657327,
      "eval_loss": 0.5364559888839722,
      "eval_runtime": 46.8228,
      "eval_samples_per_second": 3586.497,
      "eval_steps_per_second": 448.328,
      "step": 291500
    },
    {
      "epoch": 3.086459419545736,
      "grad_norm": 0.9237375259399414,
      "learning_rate": 0.00043665100279950653,
      "loss": 0.7544,
      "step": 291550
    },
    {
      "epoch": 3.0869887413257393,
      "grad_norm": 0.8494709134101868,
      "learning_rate": 0.00043662026933272136,
      "loss": 0.7468,
      "step": 291600
    },
    {
      "epoch": 3.0875180631057426,
      "grad_norm": 1.003690242767334,
      "learning_rate": 0.0004365895294947887,
      "loss": 0.7362,
      "step": 291650
    },
    {
      "epoch": 3.088047384885746,
      "grad_norm": 0.9674455523490906,
      "learning_rate": 0.00043655878328675797,
      "loss": 0.7417,
      "step": 291700
    },
    {
      "epoch": 3.0885767066657492,
      "grad_norm": 0.8314943909645081,
      "learning_rate": 0.0004365280307096787,
      "loss": 0.7332,
      "step": 291750
    },
    {
      "epoch": 3.0891060284457525,
      "grad_norm": 1.0382766723632812,
      "learning_rate": 0.00043649727176460094,
      "loss": 0.7199,
      "step": 291800
    },
    {
      "epoch": 3.089635350225756,
      "grad_norm": 0.9172874093055725,
      "learning_rate": 0.0004364665064525747,
      "loss": 0.7382,
      "step": 291850
    },
    {
      "epoch": 3.090164672005759,
      "grad_norm": 1.0524539947509766,
      "learning_rate": 0.0004364357347746503,
      "loss": 0.7262,
      "step": 291900
    },
    {
      "epoch": 3.0906939937857625,
      "grad_norm": 0.9875723123550415,
      "learning_rate": 0.0004364049567318783,
      "loss": 0.7249,
      "step": 291950
    },
    {
      "epoch": 3.091223315565766,
      "grad_norm": 0.8528405427932739,
      "learning_rate": 0.00043637417232530946,
      "loss": 0.7256,
      "step": 292000
    },
    {
      "epoch": 3.091223315565766,
      "eval_loss": 0.5342217087745667,
      "eval_runtime": 46.8277,
      "eval_samples_per_second": 3586.126,
      "eval_steps_per_second": 448.282,
      "step": 292000
    },
    {
      "epoch": 3.0917526373457687,
      "grad_norm": 0.9515958428382874,
      "learning_rate": 0.00043634338155599476,
      "loss": 0.7394,
      "step": 292050
    },
    {
      "epoch": 3.092281959125772,
      "grad_norm": 0.8931542634963989,
      "learning_rate": 0.00043631258442498525,
      "loss": 0.7175,
      "step": 292100
    },
    {
      "epoch": 3.0928112809057753,
      "grad_norm": 1.0375310182571411,
      "learning_rate": 0.000436282397065493,
      "loss": 0.7384,
      "step": 292150
    },
    {
      "epoch": 3.0933406026857786,
      "grad_norm": 0.9720278382301331,
      "learning_rate": 0.0004362515873414301,
      "loss": 0.7315,
      "step": 292200
    },
    {
      "epoch": 3.093869924465782,
      "grad_norm": 0.9102926254272461,
      "learning_rate": 0.0004362207712588063,
      "loss": 0.7363,
      "step": 292250
    },
    {
      "epoch": 3.094399246245785,
      "grad_norm": 0.9684603810310364,
      "learning_rate": 0.00043618994881867366,
      "loss": 0.7378,
      "step": 292300
    },
    {
      "epoch": 3.0949285680257885,
      "grad_norm": 0.9520753622055054,
      "learning_rate": 0.0004361591200220845,
      "loss": 0.7336,
      "step": 292350
    },
    {
      "epoch": 3.095457889805792,
      "grad_norm": 0.9366393089294434,
      "learning_rate": 0.00043612828487009115,
      "loss": 0.7334,
      "step": 292400
    },
    {
      "epoch": 3.095987211585795,
      "grad_norm": 0.8832495212554932,
      "learning_rate": 0.00043609744336374647,
      "loss": 0.7348,
      "step": 292450
    },
    {
      "epoch": 3.0965165333657985,
      "grad_norm": 0.9491845369338989,
      "learning_rate": 0.0004360665955041033,
      "loss": 0.7302,
      "step": 292500
    },
    {
      "epoch": 3.0965165333657985,
      "eval_loss": 0.5348895192146301,
      "eval_runtime": 46.8949,
      "eval_samples_per_second": 3580.985,
      "eval_steps_per_second": 447.639,
      "step": 292500
    },
    {
      "epoch": 3.0970458551458018,
      "grad_norm": 0.9490373730659485,
      "learning_rate": 0.00043603574129221477,
      "loss": 0.7349,
      "step": 292550
    },
    {
      "epoch": 3.097575176925805,
      "grad_norm": 0.9241983294487,
      "learning_rate": 0.00043600488072913435,
      "loss": 0.7378,
      "step": 292600
    },
    {
      "epoch": 3.0981044987058084,
      "grad_norm": 0.9692721366882324,
      "learning_rate": 0.0004359740138159154,
      "loss": 0.7442,
      "step": 292650
    },
    {
      "epoch": 3.0986338204858117,
      "grad_norm": 1.0241576433181763,
      "learning_rate": 0.00043594314055361193,
      "loss": 0.7287,
      "step": 292700
    },
    {
      "epoch": 3.099163142265815,
      "grad_norm": 0.9847997426986694,
      "learning_rate": 0.00043591226094327783,
      "loss": 0.7254,
      "step": 292750
    },
    {
      "epoch": 3.099692464045818,
      "grad_norm": 0.9732995629310608,
      "learning_rate": 0.00043588137498596724,
      "loss": 0.743,
      "step": 292800
    },
    {
      "epoch": 3.100221785825821,
      "grad_norm": 0.9819604754447937,
      "learning_rate": 0.00043585048268273476,
      "loss": 0.737,
      "step": 292850
    },
    {
      "epoch": 3.1007511076058245,
      "grad_norm": 0.9794604182243347,
      "learning_rate": 0.00043581958403463494,
      "loss": 0.7455,
      "step": 292900
    },
    {
      "epoch": 3.101280429385828,
      "grad_norm": 0.9179513454437256,
      "learning_rate": 0.00043578867904272265,
      "loss": 0.7235,
      "step": 292950
    },
    {
      "epoch": 3.101809751165831,
      "grad_norm": 0.9512487053871155,
      "learning_rate": 0.000435757767708053,
      "loss": 0.729,
      "step": 293000
    },
    {
      "epoch": 3.101809751165831,
      "eval_loss": 0.533157467842102,
      "eval_runtime": 46.7665,
      "eval_samples_per_second": 3590.817,
      "eval_steps_per_second": 448.868,
      "step": 293000
    },
    {
      "epoch": 3.1023390729458344,
      "grad_norm": 0.9540148973464966,
      "learning_rate": 0.00043572685003168127,
      "loss": 0.7367,
      "step": 293050
    },
    {
      "epoch": 3.1028683947258378,
      "grad_norm": 0.9856671690940857,
      "learning_rate": 0.000435695926014663,
      "loss": 0.7227,
      "step": 293100
    },
    {
      "epoch": 3.103397716505841,
      "grad_norm": 0.9123055338859558,
      "learning_rate": 0.00043566499565805394,
      "loss": 0.7365,
      "step": 293150
    },
    {
      "epoch": 3.1039270382858444,
      "grad_norm": 0.9606226682662964,
      "learning_rate": 0.00043563405896291003,
      "loss": 0.7348,
      "step": 293200
    },
    {
      "epoch": 3.1044563600658477,
      "grad_norm": 0.963982105255127,
      "learning_rate": 0.0004356031159302874,
      "loss": 0.7359,
      "step": 293250
    },
    {
      "epoch": 3.104985681845851,
      "grad_norm": 0.9443276524543762,
      "learning_rate": 0.00043557216656124246,
      "loss": 0.7186,
      "step": 293300
    },
    {
      "epoch": 3.1055150036258543,
      "grad_norm": 0.9372474551200867,
      "learning_rate": 0.00043554121085683184,
      "loss": 0.7405,
      "step": 293350
    },
    {
      "epoch": 3.1060443254058576,
      "grad_norm": 0.9681665897369385,
      "learning_rate": 0.0004355102488181123,
      "loss": 0.7139,
      "step": 293400
    },
    {
      "epoch": 3.106573647185861,
      "grad_norm": 0.9093801975250244,
      "learning_rate": 0.0004354792804461408,
      "loss": 0.7289,
      "step": 293450
    },
    {
      "epoch": 3.1071029689658642,
      "grad_norm": 0.9444941878318787,
      "learning_rate": 0.0004354483057419748,
      "loss": 0.7253,
      "step": 293500
    },
    {
      "epoch": 3.1071029689658642,
      "eval_loss": 0.5314192771911621,
      "eval_runtime": 46.8167,
      "eval_samples_per_second": 3586.968,
      "eval_steps_per_second": 448.387,
      "step": 293500
    },
    {
      "epoch": 3.107632290745867,
      "grad_norm": 0.9451042413711548,
      "learning_rate": 0.0004354173247066717,
      "loss": 0.7431,
      "step": 293550
    },
    {
      "epoch": 3.1081616125258704,
      "grad_norm": 0.8382267951965332,
      "learning_rate": 0.0004353863373412891,
      "loss": 0.7221,
      "step": 293600
    },
    {
      "epoch": 3.1086909343058737,
      "grad_norm": 0.9913444519042969,
      "learning_rate": 0.0004353553436468849,
      "loss": 0.7358,
      "step": 293650
    },
    {
      "epoch": 3.109220256085877,
      "grad_norm": 1.0412143468856812,
      "learning_rate": 0.00043532434362451725,
      "loss": 0.736,
      "step": 293700
    },
    {
      "epoch": 3.1097495778658804,
      "grad_norm": 0.8728792667388916,
      "learning_rate": 0.00043529333727524447,
      "loss": 0.7319,
      "step": 293750
    },
    {
      "epoch": 3.1102788996458837,
      "grad_norm": 0.8535080552101135,
      "learning_rate": 0.0004352623246001251,
      "loss": 0.7263,
      "step": 293800
    },
    {
      "epoch": 3.110808221425887,
      "grad_norm": 1.0273454189300537,
      "learning_rate": 0.0004352313056002179,
      "loss": 0.728,
      "step": 293850
    },
    {
      "epoch": 3.1113375432058903,
      "grad_norm": 0.9293040037155151,
      "learning_rate": 0.0004352002802765819,
      "loss": 0.7219,
      "step": 293900
    },
    {
      "epoch": 3.1118668649858936,
      "grad_norm": 0.9271683692932129,
      "learning_rate": 0.00043516924863027626,
      "loss": 0.7286,
      "step": 293950
    },
    {
      "epoch": 3.112396186765897,
      "grad_norm": 1.0222914218902588,
      "learning_rate": 0.0004351382106623604,
      "loss": 0.7315,
      "step": 294000
    },
    {
      "epoch": 3.112396186765897,
      "eval_loss": 0.5332016944885254,
      "eval_runtime": 46.8012,
      "eval_samples_per_second": 3588.16,
      "eval_steps_per_second": 448.536,
      "step": 294000
    },
    {
      "epoch": 3.1129255085459,
      "grad_norm": 0.9968972206115723,
      "learning_rate": 0.0004351071663738938,
      "loss": 0.7302,
      "step": 294050
    },
    {
      "epoch": 3.1134548303259035,
      "grad_norm": 1.0196670293807983,
      "learning_rate": 0.00043507611576593656,
      "loss": 0.7154,
      "step": 294100
    },
    {
      "epoch": 3.113984152105907,
      "grad_norm": 0.9589504599571228,
      "learning_rate": 0.0004350450588395485,
      "loss": 0.728,
      "step": 294150
    },
    {
      "epoch": 3.11451347388591,
      "grad_norm": 0.9076552391052246,
      "learning_rate": 0.00043501399559579005,
      "loss": 0.7278,
      "step": 294200
    },
    {
      "epoch": 3.1150427956659135,
      "grad_norm": 0.8966193199157715,
      "learning_rate": 0.0004349829260357217,
      "loss": 0.7305,
      "step": 294250
    },
    {
      "epoch": 3.1155721174459163,
      "grad_norm": 0.9310628771781921,
      "learning_rate": 0.0004349518501604039,
      "loss": 0.7264,
      "step": 294300
    },
    {
      "epoch": 3.1161014392259196,
      "grad_norm": 0.9583860635757446,
      "learning_rate": 0.00043492138967656023,
      "loss": 0.7506,
      "step": 294350
    },
    {
      "epoch": 3.116630761005923,
      "grad_norm": 0.9697360992431641,
      "learning_rate": 0.0004348903013001792,
      "loss": 0.7265,
      "step": 294400
    },
    {
      "epoch": 3.1171600827859263,
      "grad_norm": 0.9534218907356262,
      "learning_rate": 0.0004348592066117111,
      "loss": 0.7354,
      "step": 294450
    },
    {
      "epoch": 3.1176894045659296,
      "grad_norm": 0.9620773792266846,
      "learning_rate": 0.00043482810561221744,
      "loss": 0.7339,
      "step": 294500
    },
    {
      "epoch": 3.1176894045659296,
      "eval_loss": 0.5294967293739319,
      "eval_runtime": 46.7948,
      "eval_samples_per_second": 3588.648,
      "eval_steps_per_second": 448.597,
      "step": 294500
    },
    {
      "epoch": 3.118218726345933,
      "grad_norm": 0.9248921275138855,
      "learning_rate": 0.00043479699830276,
      "loss": 0.7355,
      "step": 294550
    },
    {
      "epoch": 3.118748048125936,
      "grad_norm": 1.0367240905761719,
      "learning_rate": 0.00043476588468440087,
      "loss": 0.7353,
      "step": 294600
    },
    {
      "epoch": 3.1192773699059395,
      "grad_norm": 0.9026072025299072,
      "learning_rate": 0.0004347347647582022,
      "loss": 0.7272,
      "step": 294650
    },
    {
      "epoch": 3.119806691685943,
      "grad_norm": 1.0082899332046509,
      "learning_rate": 0.0004347036385252264,
      "loss": 0.7474,
      "step": 294700
    },
    {
      "epoch": 3.120336013465946,
      "grad_norm": 0.9548470377922058,
      "learning_rate": 0.0004346725059865361,
      "loss": 0.721,
      "step": 294750
    },
    {
      "epoch": 3.1208653352459494,
      "grad_norm": 0.9488580822944641,
      "learning_rate": 0.00043464136714319414,
      "loss": 0.733,
      "step": 294800
    },
    {
      "epoch": 3.1213946570259528,
      "grad_norm": 0.9189572930335999,
      "learning_rate": 0.00043461022199626364,
      "loss": 0.725,
      "step": 294850
    },
    {
      "epoch": 3.121923978805956,
      "grad_norm": 0.9688790440559387,
      "learning_rate": 0.0004345790705468079,
      "loss": 0.7242,
      "step": 294900
    },
    {
      "epoch": 3.1224533005859594,
      "grad_norm": 0.937243640422821,
      "learning_rate": 0.0004345479127958904,
      "loss": 0.7251,
      "step": 294950
    },
    {
      "epoch": 3.1229826223659627,
      "grad_norm": 1.0216753482818604,
      "learning_rate": 0.00043451674874457483,
      "loss": 0.7248,
      "step": 295000
    },
    {
      "epoch": 3.1229826223659627,
      "eval_loss": 0.5320665240287781,
      "eval_runtime": 46.8541,
      "eval_samples_per_second": 3584.106,
      "eval_steps_per_second": 448.029,
      "step": 295000
    },
    {
      "epoch": 3.1235119441459656,
      "grad_norm": 0.9410470128059387,
      "learning_rate": 0.0004344855783939251,
      "loss": 0.7316,
      "step": 295050
    },
    {
      "epoch": 3.124041265925969,
      "grad_norm": 0.9192118644714355,
      "learning_rate": 0.0004344544017450054,
      "loss": 0.7312,
      "step": 295100
    },
    {
      "epoch": 3.124570587705972,
      "grad_norm": 0.9730243682861328,
      "learning_rate": 0.00043442321879888,
      "loss": 0.7396,
      "step": 295150
    },
    {
      "epoch": 3.1250999094859755,
      "grad_norm": 0.8579378724098206,
      "learning_rate": 0.00043439202955661364,
      "loss": 0.7301,
      "step": 295200
    },
    {
      "epoch": 3.125629231265979,
      "grad_norm": 0.9320093989372253,
      "learning_rate": 0.00043436083401927097,
      "loss": 0.7291,
      "step": 295250
    },
    {
      "epoch": 3.126158553045982,
      "grad_norm": 0.9330787062644958,
      "learning_rate": 0.00043432963218791704,
      "loss": 0.7287,
      "step": 295300
    },
    {
      "epoch": 3.1266878748259854,
      "grad_norm": 1.0232549905776978,
      "learning_rate": 0.0004342984240636171,
      "loss": 0.7278,
      "step": 295350
    },
    {
      "epoch": 3.1272171966059887,
      "grad_norm": 0.8401159644126892,
      "learning_rate": 0.00043426720964743646,
      "loss": 0.7218,
      "step": 295400
    },
    {
      "epoch": 3.127746518385992,
      "grad_norm": 0.9321014881134033,
      "learning_rate": 0.000434235988940441,
      "loss": 0.7479,
      "step": 295450
    },
    {
      "epoch": 3.1282758401659954,
      "grad_norm": 0.9541034698486328,
      "learning_rate": 0.00043420476194369633,
      "loss": 0.7257,
      "step": 295500
    },
    {
      "epoch": 3.1282758401659954,
      "eval_loss": 0.5301943421363831,
      "eval_runtime": 46.845,
      "eval_samples_per_second": 3584.799,
      "eval_steps_per_second": 448.116,
      "step": 295500
    },
    {
      "epoch": 3.1288051619459987,
      "grad_norm": 0.9649587869644165,
      "learning_rate": 0.0004341735286582687,
      "loss": 0.7316,
      "step": 295550
    },
    {
      "epoch": 3.129334483726002,
      "grad_norm": 0.9465067982673645,
      "learning_rate": 0.00043414228908522434,
      "loss": 0.7337,
      "step": 295600
    },
    {
      "epoch": 3.1298638055060053,
      "grad_norm": 1.0218510627746582,
      "learning_rate": 0.00043411104322562977,
      "loss": 0.73,
      "step": 295650
    },
    {
      "epoch": 3.1303931272860086,
      "grad_norm": 0.9030359983444214,
      "learning_rate": 0.0004340797910805517,
      "loss": 0.7154,
      "step": 295700
    },
    {
      "epoch": 3.130922449066012,
      "grad_norm": 0.8615480065345764,
      "learning_rate": 0.000434048532651057,
      "loss": 0.7304,
      "step": 295750
    },
    {
      "epoch": 3.131451770846015,
      "grad_norm": 0.9414710402488708,
      "learning_rate": 0.00043401726793821293,
      "loss": 0.729,
      "step": 295800
    },
    {
      "epoch": 3.131981092626018,
      "grad_norm": 0.9336801767349243,
      "learning_rate": 0.00043398599694308696,
      "loss": 0.735,
      "step": 295850
    },
    {
      "epoch": 3.1325104144060214,
      "grad_norm": 1.0587984323501587,
      "learning_rate": 0.0004339547196667464,
      "loss": 0.7207,
      "step": 295900
    },
    {
      "epoch": 3.1330397361860247,
      "grad_norm": 0.9080792665481567,
      "learning_rate": 0.00043392343611025914,
      "loss": 0.723,
      "step": 295950
    },
    {
      "epoch": 3.133569057966028,
      "grad_norm": 1.028425693511963,
      "learning_rate": 0.00043389214627469327,
      "loss": 0.7241,
      "step": 296000
    },
    {
      "epoch": 3.133569057966028,
      "eval_loss": 0.5272930860519409,
      "eval_runtime": 46.7802,
      "eval_samples_per_second": 3589.77,
      "eval_steps_per_second": 448.737,
      "step": 296000
    },
    {
      "epoch": 3.1340983797460313,
      "grad_norm": 0.9803749322891235,
      "learning_rate": 0.00043386085016111696,
      "loss": 0.7422,
      "step": 296050
    },
    {
      "epoch": 3.1346277015260346,
      "grad_norm": 0.9791492223739624,
      "learning_rate": 0.0004338295477705987,
      "loss": 0.7385,
      "step": 296100
    },
    {
      "epoch": 3.135157023306038,
      "grad_norm": 0.9068487882614136,
      "learning_rate": 0.000433798239104207,
      "loss": 0.7224,
      "step": 296150
    },
    {
      "epoch": 3.1356863450860413,
      "grad_norm": 1.0284136533737183,
      "learning_rate": 0.0004337669241630109,
      "loss": 0.7297,
      "step": 296200
    },
    {
      "epoch": 3.1362156668660446,
      "grad_norm": 0.968880295753479,
      "learning_rate": 0.00043373560294807936,
      "loss": 0.7417,
      "step": 296250
    },
    {
      "epoch": 3.136744988646048,
      "grad_norm": 0.9048550128936768,
      "learning_rate": 0.00043370427546048177,
      "loss": 0.7326,
      "step": 296300
    },
    {
      "epoch": 3.137274310426051,
      "grad_norm": 0.7910419702529907,
      "learning_rate": 0.00043367356843792616,
      "loss": 0.7309,
      "step": 296350
    },
    {
      "epoch": 3.1378036322060545,
      "grad_norm": 0.9517282843589783,
      "learning_rate": 0.0004336422285336051,
      "loss": 0.7434,
      "step": 296400
    },
    {
      "epoch": 3.138332953986058,
      "grad_norm": 0.9216118454933167,
      "learning_rate": 0.0004336108823598058,
      "loss": 0.7328,
      "step": 296450
    },
    {
      "epoch": 3.138862275766061,
      "grad_norm": 0.9215307235717773,
      "learning_rate": 0.0004335795299175982,
      "loss": 0.7332,
      "step": 296500
    },
    {
      "epoch": 3.138862275766061,
      "eval_loss": 0.5308147072792053,
      "eval_runtime": 46.9066,
      "eval_samples_per_second": 3580.097,
      "eval_steps_per_second": 447.528,
      "step": 296500
    },
    {
      "epoch": 3.139391597546064,
      "grad_norm": 0.9883162379264832,
      "learning_rate": 0.00043354817120805285,
      "loss": 0.7456,
      "step": 296550
    },
    {
      "epoch": 3.1399209193260673,
      "grad_norm": 1.0217877626419067,
      "learning_rate": 0.0004335168062322402,
      "loss": 0.7365,
      "step": 296600
    },
    {
      "epoch": 3.1404502411060706,
      "grad_norm": 0.9642842411994934,
      "learning_rate": 0.0004334854349912312,
      "loss": 0.728,
      "step": 296650
    },
    {
      "epoch": 3.140979562886074,
      "grad_norm": 0.9555227160453796,
      "learning_rate": 0.00043345405748609656,
      "loss": 0.727,
      "step": 296700
    },
    {
      "epoch": 3.1415088846660773,
      "grad_norm": 0.9556313753128052,
      "learning_rate": 0.00043342267371790784,
      "loss": 0.7323,
      "step": 296750
    },
    {
      "epoch": 3.1420382064460806,
      "grad_norm": 0.8690732717514038,
      "learning_rate": 0.0004333912836877362,
      "loss": 0.7314,
      "step": 296800
    },
    {
      "epoch": 3.142567528226084,
      "grad_norm": 1.0081082582473755,
      "learning_rate": 0.0004333598873966534,
      "loss": 0.7339,
      "step": 296850
    },
    {
      "epoch": 3.143096850006087,
      "grad_norm": 1.0213063955307007,
      "learning_rate": 0.0004333284848457314,
      "loss": 0.7297,
      "step": 296900
    },
    {
      "epoch": 3.1436261717860905,
      "grad_norm": 0.9950887560844421,
      "learning_rate": 0.00043329707603604207,
      "loss": 0.7244,
      "step": 296950
    },
    {
      "epoch": 3.144155493566094,
      "grad_norm": 0.9843860268592834,
      "learning_rate": 0.0004332656609686578,
      "loss": 0.7389,
      "step": 297000
    },
    {
      "epoch": 3.144155493566094,
      "eval_loss": 0.5289053320884705,
      "eval_runtime": 46.7303,
      "eval_samples_per_second": 3593.599,
      "eval_steps_per_second": 449.216,
      "step": 297000
    },
    {
      "epoch": 3.144684815346097,
      "grad_norm": 0.9167391061782837,
      "learning_rate": 0.000433234239644651,
      "loss": 0.7375,
      "step": 297050
    },
    {
      "epoch": 3.1452141371261004,
      "grad_norm": 0.8846587538719177,
      "learning_rate": 0.0004332028120650946,
      "loss": 0.7275,
      "step": 297100
    },
    {
      "epoch": 3.1457434589061037,
      "grad_norm": 0.9704901576042175,
      "learning_rate": 0.0004331713782310613,
      "loss": 0.7176,
      "step": 297150
    },
    {
      "epoch": 3.146272780686107,
      "grad_norm": 0.9800319075584412,
      "learning_rate": 0.00043313993814362434,
      "loss": 0.7154,
      "step": 297200
    },
    {
      "epoch": 3.1468021024661104,
      "grad_norm": 0.964924156665802,
      "learning_rate": 0.0004331084918038571,
      "loss": 0.7216,
      "step": 297250
    },
    {
      "epoch": 3.1473314242461132,
      "grad_norm": 0.8526060581207275,
      "learning_rate": 0.00043307703921283304,
      "loss": 0.7205,
      "step": 297300
    },
    {
      "epoch": 3.1478607460261165,
      "grad_norm": 1.02554452419281,
      "learning_rate": 0.000433045580371626,
      "loss": 0.7249,
      "step": 297350
    },
    {
      "epoch": 3.14839006780612,
      "grad_norm": 0.9390082955360413,
      "learning_rate": 0.00043301411528131,
      "loss": 0.7413,
      "step": 297400
    },
    {
      "epoch": 3.148919389586123,
      "grad_norm": 0.9705070853233337,
      "learning_rate": 0.0004329826439429592,
      "loss": 0.7393,
      "step": 297450
    },
    {
      "epoch": 3.1494487113661265,
      "grad_norm": 0.9338818192481995,
      "learning_rate": 0.0004329511663576481,
      "loss": 0.7259,
      "step": 297500
    },
    {
      "epoch": 3.1494487113661265,
      "eval_loss": 0.5312817096710205,
      "eval_runtime": 46.8179,
      "eval_samples_per_second": 3586.873,
      "eval_steps_per_second": 448.375,
      "step": 297500
    },
    {
      "epoch": 3.14997803314613,
      "grad_norm": 1.0230828523635864,
      "learning_rate": 0.0004329196825264512,
      "loss": 0.744,
      "step": 297550
    },
    {
      "epoch": 3.150507354926133,
      "grad_norm": 1.0366747379302979,
      "learning_rate": 0.00043288819245044353,
      "loss": 0.7285,
      "step": 297600
    },
    {
      "epoch": 3.1510366767061364,
      "grad_norm": 0.9991675615310669,
      "learning_rate": 0.0004328566961306999,
      "loss": 0.7167,
      "step": 297650
    },
    {
      "epoch": 3.1515659984861397,
      "grad_norm": 0.9777438044548035,
      "learning_rate": 0.00043282519356829585,
      "loss": 0.7161,
      "step": 297700
    },
    {
      "epoch": 3.152095320266143,
      "grad_norm": 0.8505279421806335,
      "learning_rate": 0.0004327936847643067,
      "loss": 0.7248,
      "step": 297750
    },
    {
      "epoch": 3.1526246420461463,
      "grad_norm": 0.8586411476135254,
      "learning_rate": 0.0004327621697198082,
      "loss": 0.7413,
      "step": 297800
    },
    {
      "epoch": 3.1531539638261497,
      "grad_norm": 0.9463775157928467,
      "learning_rate": 0.00043273064843587616,
      "loss": 0.7192,
      "step": 297850
    },
    {
      "epoch": 3.153683285606153,
      "grad_norm": 0.9274206161499023,
      "learning_rate": 0.00043269912091358685,
      "loss": 0.7378,
      "step": 297900
    },
    {
      "epoch": 3.1542126073861563,
      "grad_norm": 0.9603210091590881,
      "learning_rate": 0.0004326675871540167,
      "loss": 0.7261,
      "step": 297950
    },
    {
      "epoch": 3.1547419291661596,
      "grad_norm": 0.9818819761276245,
      "learning_rate": 0.0004326360471582419,
      "loss": 0.733,
      "step": 298000
    },
    {
      "epoch": 3.1547419291661596,
      "eval_loss": 0.5273494720458984,
      "eval_runtime": 46.7828,
      "eval_samples_per_second": 3589.569,
      "eval_steps_per_second": 448.712,
      "step": 298000
    },
    {
      "epoch": 3.1552712509461625,
      "grad_norm": 0.854592502117157,
      "learning_rate": 0.00043260450092733955,
      "loss": 0.7197,
      "step": 298050
    },
    {
      "epoch": 3.1558005727261658,
      "grad_norm": 0.9851652383804321,
      "learning_rate": 0.0004325729484623865,
      "loss": 0.7167,
      "step": 298100
    },
    {
      "epoch": 3.156329894506169,
      "grad_norm": 0.8673139810562134,
      "learning_rate": 0.0004325413897644599,
      "loss": 0.7266,
      "step": 298150
    },
    {
      "epoch": 3.1568592162861724,
      "grad_norm": 1.0244274139404297,
      "learning_rate": 0.0004325098248346372,
      "loss": 0.7346,
      "step": 298200
    },
    {
      "epoch": 3.1573885380661757,
      "grad_norm": 0.9900596737861633,
      "learning_rate": 0.00043247825367399606,
      "loss": 0.7309,
      "step": 298250
    },
    {
      "epoch": 3.157917859846179,
      "grad_norm": 0.9762663245201111,
      "learning_rate": 0.00043244667628361425,
      "loss": 0.727,
      "step": 298300
    },
    {
      "epoch": 3.1584471816261823,
      "grad_norm": 0.9236321449279785,
      "learning_rate": 0.0004324157243979846,
      "loss": 0.7417,
      "step": 298350
    },
    {
      "epoch": 3.1589765034061856,
      "grad_norm": 0.840737521648407,
      "learning_rate": 0.00043238413467589686,
      "loss": 0.7093,
      "step": 298400
    },
    {
      "epoch": 3.159505825186189,
      "grad_norm": 0.9285415410995483,
      "learning_rate": 0.00043235253872728175,
      "loss": 0.7411,
      "step": 298450
    },
    {
      "epoch": 3.1600351469661923,
      "grad_norm": 0.9168815612792969,
      "learning_rate": 0.0004323209365532178,
      "loss": 0.7244,
      "step": 298500
    },
    {
      "epoch": 3.1600351469661923,
      "eval_loss": 0.5263315439224243,
      "eval_runtime": 46.9514,
      "eval_samples_per_second": 3576.681,
      "eval_steps_per_second": 447.101,
      "step": 298500
    },
    {
      "epoch": 3.1605644687461956,
      "grad_norm": 0.85494065284729,
      "learning_rate": 0.0004322893281547839,
      "loss": 0.7331,
      "step": 298550
    },
    {
      "epoch": 3.161093790526199,
      "grad_norm": 1.0147998332977295,
      "learning_rate": 0.00043225771353305926,
      "loss": 0.7279,
      "step": 298600
    },
    {
      "epoch": 3.161623112306202,
      "grad_norm": 1.0011017322540283,
      "learning_rate": 0.00043222609268912305,
      "loss": 0.7305,
      "step": 298650
    },
    {
      "epoch": 3.1621524340862055,
      "grad_norm": 0.9859614372253418,
      "learning_rate": 0.00043219446562405494,
      "loss": 0.7362,
      "step": 298700
    },
    {
      "epoch": 3.162681755866209,
      "grad_norm": 0.9653573036193848,
      "learning_rate": 0.0004321628323389345,
      "loss": 0.7099,
      "step": 298750
    },
    {
      "epoch": 3.1632110776462117,
      "grad_norm": 0.9885940551757812,
      "learning_rate": 0.0004321311928348419,
      "loss": 0.729,
      "step": 298800
    },
    {
      "epoch": 3.163740399426215,
      "grad_norm": 0.9809750318527222,
      "learning_rate": 0.00043209954711285705,
      "loss": 0.7405,
      "step": 298850
    },
    {
      "epoch": 3.1642697212062183,
      "grad_norm": 1.0628381967544556,
      "learning_rate": 0.00043206789517406054,
      "loss": 0.7242,
      "step": 298900
    },
    {
      "epoch": 3.1647990429862216,
      "grad_norm": 0.9962750673294067,
      "learning_rate": 0.00043203623701953275,
      "loss": 0.7271,
      "step": 298950
    },
    {
      "epoch": 3.165328364766225,
      "grad_norm": 0.9209165573120117,
      "learning_rate": 0.00043200457265035465,
      "loss": 0.7179,
      "step": 299000
    },
    {
      "epoch": 3.165328364766225,
      "eval_loss": 0.5266216993331909,
      "eval_runtime": 46.8625,
      "eval_samples_per_second": 3583.461,
      "eval_steps_per_second": 447.949,
      "step": 299000
    },
    {
      "epoch": 3.1658576865462282,
      "grad_norm": 0.9696816802024841,
      "learning_rate": 0.0004319729020676072,
      "loss": 0.7299,
      "step": 299050
    },
    {
      "epoch": 3.1663870083262315,
      "grad_norm": 0.8614600300788879,
      "learning_rate": 0.0004319412252723716,
      "loss": 0.7308,
      "step": 299100
    },
    {
      "epoch": 3.166916330106235,
      "grad_norm": 0.96658855676651,
      "learning_rate": 0.0004319095422657293,
      "loss": 0.73,
      "step": 299150
    },
    {
      "epoch": 3.167445651886238,
      "grad_norm": 0.9042307734489441,
      "learning_rate": 0.00043187785304876194,
      "loss": 0.739,
      "step": 299200
    },
    {
      "epoch": 3.1679749736662415,
      "grad_norm": 0.9805361032485962,
      "learning_rate": 0.00043184615762255135,
      "loss": 0.7176,
      "step": 299250
    },
    {
      "epoch": 3.168504295446245,
      "grad_norm": 1.0332752466201782,
      "learning_rate": 0.0004318144559881797,
      "loss": 0.7444,
      "step": 299300
    },
    {
      "epoch": 3.169033617226248,
      "grad_norm": 0.9236083030700684,
      "learning_rate": 0.0004317827481467291,
      "loss": 0.7223,
      "step": 299350
    },
    {
      "epoch": 3.1695629390062514,
      "grad_norm": 0.7980550527572632,
      "learning_rate": 0.0004317510340992822,
      "loss": 0.7148,
      "step": 299400
    },
    {
      "epoch": 3.1700922607862547,
      "grad_norm": 0.9326514601707458,
      "learning_rate": 0.00043171931384692165,
      "loss": 0.7151,
      "step": 299450
    },
    {
      "epoch": 3.170621582566258,
      "grad_norm": 0.885735809803009,
      "learning_rate": 0.00043168758739073034,
      "loss": 0.7291,
      "step": 299500
    },
    {
      "epoch": 3.170621582566258,
      "eval_loss": 0.5267295241355896,
      "eval_runtime": 46.7726,
      "eval_samples_per_second": 3590.351,
      "eval_steps_per_second": 448.81,
      "step": 299500
    },
    {
      "epoch": 3.171150904346261,
      "grad_norm": 0.8940473198890686,
      "learning_rate": 0.0004316558547317915,
      "loss": 0.7383,
      "step": 299550
    },
    {
      "epoch": 3.171680226126264,
      "grad_norm": 0.8651536107063293,
      "learning_rate": 0.0004316241158711883,
      "loss": 0.7333,
      "step": 299600
    },
    {
      "epoch": 3.1722095479062675,
      "grad_norm": 0.9401500225067139,
      "learning_rate": 0.00043159237081000446,
      "loss": 0.7257,
      "step": 299650
    },
    {
      "epoch": 3.172738869686271,
      "grad_norm": 0.9761089086532593,
      "learning_rate": 0.0004315606195493237,
      "loss": 0.7286,
      "step": 299700
    },
    {
      "epoch": 3.173268191466274,
      "grad_norm": 0.9765439033508301,
      "learning_rate": 0.0004315288620902299,
      "loss": 0.7241,
      "step": 299750
    },
    {
      "epoch": 3.1737975132462775,
      "grad_norm": 0.924195408821106,
      "learning_rate": 0.00043149709843380736,
      "loss": 0.7261,
      "step": 299800
    },
    {
      "epoch": 3.1743268350262808,
      "grad_norm": 0.8592538833618164,
      "learning_rate": 0.00043146532858114045,
      "loss": 0.73,
      "step": 299850
    },
    {
      "epoch": 3.174856156806284,
      "grad_norm": 1.0004068613052368,
      "learning_rate": 0.00043143355253331375,
      "loss": 0.7328,
      "step": 299900
    },
    {
      "epoch": 3.1753854785862874,
      "grad_norm": 0.9837016463279724,
      "learning_rate": 0.00043140177029141213,
      "loss": 0.7264,
      "step": 299950
    },
    {
      "epoch": 3.1759148003662907,
      "grad_norm": 1.0216912031173706,
      "learning_rate": 0.0004313699818565206,
      "loss": 0.7148,
      "step": 300000
    },
    {
      "epoch": 3.1759148003662907,
      "eval_loss": 0.5267136693000793,
      "eval_runtime": 46.7554,
      "eval_samples_per_second": 3591.672,
      "eval_steps_per_second": 448.975,
      "step": 300000
    },
    {
      "epoch": 3.176444122146294,
      "grad_norm": 0.9060611724853516,
      "learning_rate": 0.0004313381872297244,
      "loss": 0.7331,
      "step": 300050
    },
    {
      "epoch": 3.1769734439262973,
      "grad_norm": 1.0781536102294922,
      "learning_rate": 0.00043130638641210897,
      "loss": 0.7259,
      "step": 300100
    },
    {
      "epoch": 3.1775027657063006,
      "grad_norm": 0.8773695826530457,
      "learning_rate": 0.00043127457940476,
      "loss": 0.728,
      "step": 300150
    },
    {
      "epoch": 3.178032087486304,
      "grad_norm": 0.9371361136436462,
      "learning_rate": 0.00043124276620876346,
      "loss": 0.7467,
      "step": 300200
    },
    {
      "epoch": 3.1785614092663073,
      "grad_norm": 0.8690993189811707,
      "learning_rate": 0.0004312109468252052,
      "loss": 0.7249,
      "step": 300250
    },
    {
      "epoch": 3.1790907310463106,
      "grad_norm": 1.0509079694747925,
      "learning_rate": 0.00043117912125517177,
      "loss": 0.7341,
      "step": 300300
    },
    {
      "epoch": 3.1796200528263134,
      "grad_norm": 1.0585649013519287,
      "learning_rate": 0.0004311472894997496,
      "loss": 0.7179,
      "step": 300350
    },
    {
      "epoch": 3.1801493746063167,
      "grad_norm": 0.9519858956336975,
      "learning_rate": 0.00043111608837941896,
      "loss": 0.7208,
      "step": 300400
    },
    {
      "epoch": 3.18067869638632,
      "grad_norm": 1.087803602218628,
      "learning_rate": 0.0004310842443801333,
      "loss": 0.7279,
      "step": 300450
    },
    {
      "epoch": 3.1812080181663234,
      "grad_norm": 1.0264222621917725,
      "learning_rate": 0.0004310523941986979,
      "loss": 0.7343,
      "step": 300500
    },
    {
      "epoch": 3.1812080181663234,
      "eval_loss": 0.5282813906669617,
      "eval_runtime": 46.8667,
      "eval_samples_per_second": 3583.144,
      "eval_steps_per_second": 447.909,
      "step": 300500
    },
    {
      "epoch": 3.1817373399463267,
      "grad_norm": 1.0329664945602417,
      "learning_rate": 0.0004310205378362002,
      "loss": 0.7131,
      "step": 300550
    },
    {
      "epoch": 3.18226666172633,
      "grad_norm": 0.9646565318107605,
      "learning_rate": 0.00043098867529372777,
      "loss": 0.7166,
      "step": 300600
    },
    {
      "epoch": 3.1827959835063333,
      "grad_norm": 0.9864605069160461,
      "learning_rate": 0.0004309568065723682,
      "loss": 0.7322,
      "step": 300650
    },
    {
      "epoch": 3.1833253052863366,
      "grad_norm": 1.0086112022399902,
      "learning_rate": 0.00043092493167320973,
      "loss": 0.7291,
      "step": 300700
    },
    {
      "epoch": 3.18385462706634,
      "grad_norm": 0.9261261224746704,
      "learning_rate": 0.0004308930505973404,
      "loss": 0.7181,
      "step": 300750
    },
    {
      "epoch": 3.1843839488463432,
      "grad_norm": 0.8805964589118958,
      "learning_rate": 0.00043086116334584867,
      "loss": 0.7193,
      "step": 300800
    },
    {
      "epoch": 3.1849132706263465,
      "grad_norm": 1.0644361972808838,
      "learning_rate": 0.0004308292699198232,
      "loss": 0.7334,
      "step": 300850
    },
    {
      "epoch": 3.18544259240635,
      "grad_norm": 0.8820030689239502,
      "learning_rate": 0.0004307973703203527,
      "loss": 0.7271,
      "step": 300900
    },
    {
      "epoch": 3.185971914186353,
      "grad_norm": 0.9967679381370544,
      "learning_rate": 0.00043076546454852633,
      "loss": 0.7358,
      "step": 300950
    },
    {
      "epoch": 3.1865012359663565,
      "grad_norm": 0.9906867146492004,
      "learning_rate": 0.0004307335526054333,
      "loss": 0.7347,
      "step": 301000
    },
    {
      "epoch": 3.1865012359663565,
      "eval_loss": 0.5257236361503601,
      "eval_runtime": 46.7581,
      "eval_samples_per_second": 3591.467,
      "eval_steps_per_second": 448.949,
      "step": 301000
    },
    {
      "epoch": 3.18703055774636,
      "grad_norm": 0.8881768584251404,
      "learning_rate": 0.00043070163449216304,
      "loss": 0.7376,
      "step": 301050
    },
    {
      "epoch": 3.187559879526363,
      "grad_norm": 0.942234456539154,
      "learning_rate": 0.00043066971020980525,
      "loss": 0.7375,
      "step": 301100
    },
    {
      "epoch": 3.188089201306366,
      "grad_norm": 0.9200259447097778,
      "learning_rate": 0.00043063777975944987,
      "loss": 0.7203,
      "step": 301150
    },
    {
      "epoch": 3.1886185230863693,
      "grad_norm": 0.8730711340904236,
      "learning_rate": 0.00043060584314218685,
      "loss": 0.7123,
      "step": 301200
    },
    {
      "epoch": 3.1891478448663726,
      "grad_norm": 0.9569881558418274,
      "learning_rate": 0.0004305739003591066,
      "loss": 0.7161,
      "step": 301250
    },
    {
      "epoch": 3.189677166646376,
      "grad_norm": 0.8297739624977112,
      "learning_rate": 0.0004305419514112997,
      "loss": 0.7281,
      "step": 301300
    },
    {
      "epoch": 3.190206488426379,
      "grad_norm": 0.8567334413528442,
      "learning_rate": 0.00043050999629985667,
      "loss": 0.7172,
      "step": 301350
    },
    {
      "epoch": 3.1907358102063825,
      "grad_norm": 0.9494068622589111,
      "learning_rate": 0.00043047803502586863,
      "loss": 0.7342,
      "step": 301400
    },
    {
      "epoch": 3.191265131986386,
      "grad_norm": 0.9182607531547546,
      "learning_rate": 0.00043044606759042666,
      "loss": 0.7319,
      "step": 301450
    },
    {
      "epoch": 3.191794453766389,
      "grad_norm": 0.9851666688919067,
      "learning_rate": 0.0004304140939946221,
      "loss": 0.7136,
      "step": 301500
    },
    {
      "epoch": 3.191794453766389,
      "eval_loss": 0.5245201587677002,
      "eval_runtime": 46.7689,
      "eval_samples_per_second": 3590.633,
      "eval_steps_per_second": 448.845,
      "step": 301500
    },
    {
      "epoch": 3.1923237755463925,
      "grad_norm": 0.8722553253173828,
      "learning_rate": 0.0004303821142395465,
      "loss": 0.7233,
      "step": 301550
    },
    {
      "epoch": 3.1928530973263958,
      "grad_norm": 0.906181275844574,
      "learning_rate": 0.0004303501283262918,
      "loss": 0.7389,
      "step": 301600
    },
    {
      "epoch": 3.193382419106399,
      "grad_norm": 0.9961919784545898,
      "learning_rate": 0.00043031813625594973,
      "loss": 0.7381,
      "step": 301650
    },
    {
      "epoch": 3.1939117408864024,
      "grad_norm": 0.9442358016967773,
      "learning_rate": 0.0004302861380296127,
      "loss": 0.7086,
      "step": 301700
    },
    {
      "epoch": 3.1944410626664057,
      "grad_norm": 1.0292184352874756,
      "learning_rate": 0.00043025413364837294,
      "loss": 0.7287,
      "step": 301750
    },
    {
      "epoch": 3.194970384446409,
      "grad_norm": 0.9530372619628906,
      "learning_rate": 0.0004302221231133233,
      "loss": 0.7283,
      "step": 301800
    },
    {
      "epoch": 3.1954997062264123,
      "grad_norm": 0.965954065322876,
      "learning_rate": 0.00043019010642555636,
      "loss": 0.726,
      "step": 301850
    },
    {
      "epoch": 3.196029028006415,
      "grad_norm": 0.8450389504432678,
      "learning_rate": 0.0004301580835861653,
      "loss": 0.7309,
      "step": 301900
    },
    {
      "epoch": 3.1965583497864185,
      "grad_norm": 0.9176873564720154,
      "learning_rate": 0.0004301260545962434,
      "loss": 0.7303,
      "step": 301950
    },
    {
      "epoch": 3.197087671566422,
      "grad_norm": 0.9094803333282471,
      "learning_rate": 0.00043009401945688397,
      "loss": 0.7275,
      "step": 302000
    },
    {
      "epoch": 3.197087671566422,
      "eval_loss": 0.5248717069625854,
      "eval_runtime": 46.7802,
      "eval_samples_per_second": 3589.766,
      "eval_steps_per_second": 448.737,
      "step": 302000
    },
    {
      "epoch": 3.197616993346425,
      "grad_norm": 0.9719076752662659,
      "learning_rate": 0.00043006197816918083,
      "loss": 0.7307,
      "step": 302050
    },
    {
      "epoch": 3.1981463151264284,
      "grad_norm": 1.014480471611023,
      "learning_rate": 0.0004300299307342277,
      "loss": 0.7344,
      "step": 302100
    },
    {
      "epoch": 3.1986756369064318,
      "grad_norm": 1.0192636251449585,
      "learning_rate": 0.00042999787715311885,
      "loss": 0.7355,
      "step": 302150
    },
    {
      "epoch": 3.199204958686435,
      "grad_norm": 1.0048478841781616,
      "learning_rate": 0.0004299658174269484,
      "loss": 0.7187,
      "step": 302200
    },
    {
      "epoch": 3.1997342804664384,
      "grad_norm": 0.9030017256736755,
      "learning_rate": 0.00042993375155681105,
      "loss": 0.7275,
      "step": 302250
    },
    {
      "epoch": 3.2002636022464417,
      "grad_norm": 1.054292917251587,
      "learning_rate": 0.00042990167954380133,
      "loss": 0.7138,
      "step": 302300
    },
    {
      "epoch": 3.200792924026445,
      "grad_norm": 0.9201138019561768,
      "learning_rate": 0.0004298696013890143,
      "loss": 0.7309,
      "step": 302350
    },
    {
      "epoch": 3.2013222458064483,
      "grad_norm": 0.9998786449432373,
      "learning_rate": 0.00042983751709354504,
      "loss": 0.7425,
      "step": 302400
    },
    {
      "epoch": 3.2018515675864516,
      "grad_norm": 1.0266302824020386,
      "learning_rate": 0.0004298060685273508,
      "loss": 0.7348,
      "step": 302450
    },
    {
      "epoch": 3.202380889366455,
      "grad_norm": 0.9847843050956726,
      "learning_rate": 0.00042977461406572856,
      "loss": 0.745,
      "step": 302500
    },
    {
      "epoch": 3.202380889366455,
      "eval_loss": 0.5231624245643616,
      "eval_runtime": 46.7517,
      "eval_samples_per_second": 3591.957,
      "eval_steps_per_second": 449.011,
      "step": 302500
    },
    {
      "epoch": 3.2029102111464582,
      "grad_norm": 0.9424688220024109,
      "learning_rate": 0.00042974251160026025,
      "loss": 0.7227,
      "step": 302550
    },
    {
      "epoch": 3.2034395329264616,
      "grad_norm": 0.8453953266143799,
      "learning_rate": 0.00042971040299844855,
      "loss": 0.7349,
      "step": 302600
    },
    {
      "epoch": 3.2039688547064644,
      "grad_norm": 0.8959172964096069,
      "learning_rate": 0.00042967828826138965,
      "loss": 0.7222,
      "step": 302650
    },
    {
      "epoch": 3.2044981764864677,
      "grad_norm": 0.9557943940162659,
      "learning_rate": 0.0004296461673901798,
      "loss": 0.731,
      "step": 302700
    },
    {
      "epoch": 3.205027498266471,
      "grad_norm": 0.9213868379592896,
      "learning_rate": 0.0004296140403859158,
      "loss": 0.7206,
      "step": 302750
    },
    {
      "epoch": 3.2055568200464744,
      "grad_norm": 0.9329443573951721,
      "learning_rate": 0.0004295819072496942,
      "loss": 0.7327,
      "step": 302800
    },
    {
      "epoch": 3.2060861418264777,
      "grad_norm": 0.8295032978057861,
      "learning_rate": 0.0004295497679826122,
      "loss": 0.7158,
      "step": 302850
    },
    {
      "epoch": 3.206615463606481,
      "grad_norm": 1.0310994386672974,
      "learning_rate": 0.000429517622585767,
      "loss": 0.7421,
      "step": 302900
    },
    {
      "epoch": 3.2071447853864843,
      "grad_norm": 0.9937390685081482,
      "learning_rate": 0.0004294854710602559,
      "loss": 0.7229,
      "step": 302950
    },
    {
      "epoch": 3.2076741071664876,
      "grad_norm": 0.9093216061592102,
      "learning_rate": 0.0004294533134071767,
      "loss": 0.7293,
      "step": 303000
    },
    {
      "epoch": 3.2076741071664876,
      "eval_loss": 0.5229641795158386,
      "eval_runtime": 46.8284,
      "eval_samples_per_second": 3586.071,
      "eval_steps_per_second": 448.275,
      "step": 303000
    },
    {
      "epoch": 3.208203428946491,
      "grad_norm": 0.8919548392295837,
      "learning_rate": 0.0004294211496276272,
      "loss": 0.7357,
      "step": 303050
    },
    {
      "epoch": 3.208732750726494,
      "grad_norm": 0.9872113466262817,
      "learning_rate": 0.0004293889797227055,
      "loss": 0.7271,
      "step": 303100
    },
    {
      "epoch": 3.2092620725064975,
      "grad_norm": 0.8847253322601318,
      "learning_rate": 0.0004293568036935098,
      "loss": 0.7287,
      "step": 303150
    },
    {
      "epoch": 3.209791394286501,
      "grad_norm": 0.959782063961029,
      "learning_rate": 0.00042932462154113857,
      "loss": 0.7256,
      "step": 303200
    },
    {
      "epoch": 3.210320716066504,
      "grad_norm": 0.9058552384376526,
      "learning_rate": 0.00042929243326669055,
      "loss": 0.7236,
      "step": 303250
    },
    {
      "epoch": 3.2108500378465075,
      "grad_norm": 1.042891263961792,
      "learning_rate": 0.0004292602388712645,
      "loss": 0.7158,
      "step": 303300
    },
    {
      "epoch": 3.2113793596265108,
      "grad_norm": 0.9421837329864502,
      "learning_rate": 0.0004292280383559598,
      "loss": 0.7278,
      "step": 303350
    },
    {
      "epoch": 3.2119086814065136,
      "grad_norm": 0.9957162141799927,
      "learning_rate": 0.0004291958317218755,
      "loss": 0.7314,
      "step": 303400
    },
    {
      "epoch": 3.212438003186517,
      "grad_norm": 0.8988178372383118,
      "learning_rate": 0.00042916361897011126,
      "loss": 0.729,
      "step": 303450
    },
    {
      "epoch": 3.2129673249665203,
      "grad_norm": 0.9399730563163757,
      "learning_rate": 0.0004291314001017668,
      "loss": 0.7363,
      "step": 303500
    },
    {
      "epoch": 3.2129673249665203,
      "eval_loss": 0.5273048281669617,
      "eval_runtime": 46.8255,
      "eval_samples_per_second": 3586.293,
      "eval_steps_per_second": 448.303,
      "step": 303500
    },
    {
      "epoch": 3.2134966467465236,
      "grad_norm": 0.8423506617546082,
      "learning_rate": 0.000429099175117942,
      "loss": 0.7229,
      "step": 303550
    },
    {
      "epoch": 3.214025968526527,
      "grad_norm": 0.8927874565124512,
      "learning_rate": 0.00042906694401973703,
      "loss": 0.7151,
      "step": 303600
    },
    {
      "epoch": 3.21455529030653,
      "grad_norm": 0.9829966425895691,
      "learning_rate": 0.0004290347068082523,
      "loss": 0.7469,
      "step": 303650
    },
    {
      "epoch": 3.2150846120865335,
      "grad_norm": 1.0166065692901611,
      "learning_rate": 0.0004290024634845883,
      "loss": 0.71,
      "step": 303700
    },
    {
      "epoch": 3.215613933866537,
      "grad_norm": 0.9438753724098206,
      "learning_rate": 0.00042897021404984586,
      "loss": 0.7315,
      "step": 303750
    },
    {
      "epoch": 3.21614325564654,
      "grad_norm": 0.8790868520736694,
      "learning_rate": 0.00042893795850512597,
      "loss": 0.7285,
      "step": 303800
    },
    {
      "epoch": 3.2166725774265434,
      "grad_norm": 0.8837114572525024,
      "learning_rate": 0.0004289056968515298,
      "loss": 0.7215,
      "step": 303850
    },
    {
      "epoch": 3.2172018992065468,
      "grad_norm": 0.9039007425308228,
      "learning_rate": 0.0004288734290901587,
      "loss": 0.7244,
      "step": 303900
    },
    {
      "epoch": 3.21773122098655,
      "grad_norm": 0.8405110239982605,
      "learning_rate": 0.00042884115522211436,
      "loss": 0.7275,
      "step": 303950
    },
    {
      "epoch": 3.2182605427665534,
      "grad_norm": 0.8988651037216187,
      "learning_rate": 0.00042880887524849855,
      "loss": 0.7263,
      "step": 304000
    },
    {
      "epoch": 3.2182605427665534,
      "eval_loss": 0.5222400426864624,
      "eval_runtime": 46.7787,
      "eval_samples_per_second": 3589.883,
      "eval_steps_per_second": 448.751,
      "step": 304000
    },
    {
      "epoch": 3.2187898645465567,
      "grad_norm": 0.9221883416175842,
      "learning_rate": 0.00042877658917041343,
      "loss": 0.7197,
      "step": 304050
    },
    {
      "epoch": 3.21931918632656,
      "grad_norm": 0.8349799513816833,
      "learning_rate": 0.000428744296988961,
      "loss": 0.7181,
      "step": 304100
    },
    {
      "epoch": 3.219848508106563,
      "grad_norm": 0.9216134548187256,
      "learning_rate": 0.0004287119987052438,
      "loss": 0.7247,
      "step": 304150
    },
    {
      "epoch": 3.220377829886566,
      "grad_norm": 0.9230207204818726,
      "learning_rate": 0.00042867969432036456,
      "loss": 0.7321,
      "step": 304200
    },
    {
      "epoch": 3.2209071516665695,
      "grad_norm": 1.021652102470398,
      "learning_rate": 0.0004286473838354261,
      "loss": 0.7348,
      "step": 304250
    },
    {
      "epoch": 3.221436473446573,
      "grad_norm": 0.9013320803642273,
      "learning_rate": 0.0004286150672515314,
      "loss": 0.7356,
      "step": 304300
    },
    {
      "epoch": 3.221965795226576,
      "grad_norm": 0.9092602729797363,
      "learning_rate": 0.0004285827445697839,
      "loss": 0.717,
      "step": 304350
    },
    {
      "epoch": 3.2224951170065794,
      "grad_norm": 1.0306378602981567,
      "learning_rate": 0.00042855041579128696,
      "loss": 0.7409,
      "step": 304400
    },
    {
      "epoch": 3.2230244387865827,
      "grad_norm": 0.8899543285369873,
      "learning_rate": 0.00042851808091714426,
      "loss": 0.7105,
      "step": 304450
    },
    {
      "epoch": 3.223553760566586,
      "grad_norm": 0.9482320547103882,
      "learning_rate": 0.00042848573994845986,
      "loss": 0.73,
      "step": 304500
    },
    {
      "epoch": 3.223553760566586,
      "eval_loss": 0.5241138339042664,
      "eval_runtime": 46.8554,
      "eval_samples_per_second": 3584.009,
      "eval_steps_per_second": 448.017,
      "step": 304500
    },
    {
      "epoch": 3.2240830823465894,
      "grad_norm": 1.0770094394683838,
      "learning_rate": 0.0004284533928863377,
      "loss": 0.7191,
      "step": 304550
    },
    {
      "epoch": 3.2246124041265927,
      "grad_norm": 1.0127183198928833,
      "learning_rate": 0.00042842103973188213,
      "loss": 0.725,
      "step": 304600
    },
    {
      "epoch": 3.225141725906596,
      "grad_norm": 0.8673811554908752,
      "learning_rate": 0.00042838868048619764,
      "loss": 0.7262,
      "step": 304650
    },
    {
      "epoch": 3.2256710476865993,
      "grad_norm": 0.9331643581390381,
      "learning_rate": 0.0004283563151503891,
      "loss": 0.716,
      "step": 304700
    },
    {
      "epoch": 3.2262003694666026,
      "grad_norm": 0.9042484164237976,
      "learning_rate": 0.0004283239437255614,
      "loss": 0.7106,
      "step": 304750
    },
    {
      "epoch": 3.226729691246606,
      "grad_norm": 0.9205659627914429,
      "learning_rate": 0.0004282915662128196,
      "loss": 0.7261,
      "step": 304800
    },
    {
      "epoch": 3.2272590130266092,
      "grad_norm": 1.0130046606063843,
      "learning_rate": 0.00042825918261326913,
      "loss": 0.7318,
      "step": 304850
    },
    {
      "epoch": 3.227788334806612,
      "grad_norm": 1.0014920234680176,
      "learning_rate": 0.0004282267929280156,
      "loss": 0.7265,
      "step": 304900
    },
    {
      "epoch": 3.2283176565866154,
      "grad_norm": 0.9717660546302795,
      "learning_rate": 0.00042819439715816466,
      "loss": 0.7291,
      "step": 304950
    },
    {
      "epoch": 3.2288469783666187,
      "grad_norm": 0.9099677801132202,
      "learning_rate": 0.0004281619953048224,
      "loss": 0.7345,
      "step": 305000
    },
    {
      "epoch": 3.2288469783666187,
      "eval_loss": 0.5236145257949829,
      "eval_runtime": 46.8224,
      "eval_samples_per_second": 3586.534,
      "eval_steps_per_second": 448.333,
      "step": 305000
    },
    {
      "epoch": 3.229376300146622,
      "grad_norm": 0.9623588919639587,
      "learning_rate": 0.0004281295873690948,
      "loss": 0.729,
      "step": 305050
    },
    {
      "epoch": 3.2299056219266253,
      "grad_norm": 0.9914649724960327,
      "learning_rate": 0.00042809717335208855,
      "loss": 0.7262,
      "step": 305100
    },
    {
      "epoch": 3.2304349437066286,
      "grad_norm": 0.83882737159729,
      "learning_rate": 0.00042806475325491013,
      "loss": 0.7311,
      "step": 305150
    },
    {
      "epoch": 3.230964265486632,
      "grad_norm": 0.9925165772438049,
      "learning_rate": 0.0004280323270786663,
      "loss": 0.7225,
      "step": 305200
    },
    {
      "epoch": 3.2314935872666353,
      "grad_norm": 0.9412732124328613,
      "learning_rate": 0.0004279998948244641,
      "loss": 0.7254,
      "step": 305250
    },
    {
      "epoch": 3.2320229090466386,
      "grad_norm": 0.9105764627456665,
      "learning_rate": 0.00042796745649341085,
      "loss": 0.7215,
      "step": 305300
    },
    {
      "epoch": 3.232552230826642,
      "grad_norm": 1.0168555974960327,
      "learning_rate": 0.0004279350120866138,
      "loss": 0.7135,
      "step": 305350
    },
    {
      "epoch": 3.233081552606645,
      "grad_norm": 0.9253019094467163,
      "learning_rate": 0.00042790256160518073,
      "loss": 0.7104,
      "step": 305400
    },
    {
      "epoch": 3.2336108743866485,
      "grad_norm": 0.9686881899833679,
      "learning_rate": 0.00042787010505021945,
      "loss": 0.7264,
      "step": 305450
    },
    {
      "epoch": 3.234140196166652,
      "grad_norm": 0.9790669083595276,
      "learning_rate": 0.00042783764242283805,
      "loss": 0.7277,
      "step": 305500
    },
    {
      "epoch": 3.234140196166652,
      "eval_loss": 0.5214771628379822,
      "eval_runtime": 46.9015,
      "eval_samples_per_second": 3580.48,
      "eval_steps_per_second": 447.576,
      "step": 305500
    },
    {
      "epoch": 3.234669517946655,
      "grad_norm": 1.0053194761276245,
      "learning_rate": 0.00042780517372414473,
      "loss": 0.7065,
      "step": 305550
    },
    {
      "epoch": 3.2351988397266584,
      "grad_norm": 1.0248128175735474,
      "learning_rate": 0.00042777269895524794,
      "loss": 0.7185,
      "step": 305600
    },
    {
      "epoch": 3.2357281615066613,
      "grad_norm": 0.9771183729171753,
      "learning_rate": 0.0004277402181172565,
      "loss": 0.7169,
      "step": 305650
    },
    {
      "epoch": 3.2362574832866646,
      "grad_norm": 0.9233970642089844,
      "learning_rate": 0.0004277077312112791,
      "loss": 0.7179,
      "step": 305700
    },
    {
      "epoch": 3.236786805066668,
      "grad_norm": 0.9317229390144348,
      "learning_rate": 0.000427675238238425,
      "loss": 0.7147,
      "step": 305750
    },
    {
      "epoch": 3.2373161268466712,
      "grad_norm": 0.9650688767433167,
      "learning_rate": 0.00042764273919980347,
      "loss": 0.7263,
      "step": 305800
    },
    {
      "epoch": 3.2378454486266746,
      "grad_norm": 0.9775320291519165,
      "learning_rate": 0.0004276102340965239,
      "loss": 0.7328,
      "step": 305850
    },
    {
      "epoch": 3.238374770406678,
      "grad_norm": 0.9524067044258118,
      "learning_rate": 0.00042757772292969604,
      "loss": 0.7336,
      "step": 305900
    },
    {
      "epoch": 3.238904092186681,
      "grad_norm": 0.9388605952262878,
      "learning_rate": 0.0004275452057004299,
      "loss": 0.7108,
      "step": 305950
    },
    {
      "epoch": 3.2394334139666845,
      "grad_norm": 0.8361089825630188,
      "learning_rate": 0.0004275126824098355,
      "loss": 0.7147,
      "step": 306000
    },
    {
      "epoch": 3.2394334139666845,
      "eval_loss": 0.523400068283081,
      "eval_runtime": 46.7874,
      "eval_samples_per_second": 3589.213,
      "eval_steps_per_second": 448.668,
      "step": 306000
    },
    {
      "epoch": 3.239962735746688,
      "grad_norm": 0.9790382981300354,
      "learning_rate": 0.00042748015305902335,
      "loss": 0.7348,
      "step": 306050
    },
    {
      "epoch": 3.240492057526691,
      "grad_norm": 1.0242637395858765,
      "learning_rate": 0.00042744761764910375,
      "loss": 0.7375,
      "step": 306100
    },
    {
      "epoch": 3.2410213793066944,
      "grad_norm": 0.8613222241401672,
      "learning_rate": 0.0004274150761811876,
      "loss": 0.7277,
      "step": 306150
    },
    {
      "epoch": 3.2415507010866977,
      "grad_norm": 0.9330040216445923,
      "learning_rate": 0.0004273825286563858,
      "loss": 0.7107,
      "step": 306200
    },
    {
      "epoch": 3.242080022866701,
      "grad_norm": 0.8766728043556213,
      "learning_rate": 0.00042734997507580953,
      "loss": 0.7223,
      "step": 306250
    },
    {
      "epoch": 3.2426093446467044,
      "grad_norm": 0.8372586369514465,
      "learning_rate": 0.0004273174154405701,
      "loss": 0.7236,
      "step": 306300
    },
    {
      "epoch": 3.2431386664267077,
      "grad_norm": 1.0137240886688232,
      "learning_rate": 0.0004272848497517792,
      "loss": 0.7342,
      "step": 306350
    },
    {
      "epoch": 3.2436679882067105,
      "grad_norm": 0.9522691369056702,
      "learning_rate": 0.0004272522780105485,
      "loss": 0.7065,
      "step": 306400
    },
    {
      "epoch": 3.244197309986714,
      "grad_norm": 0.9340022206306458,
      "learning_rate": 0.00042721970021799004,
      "loss": 0.7236,
      "step": 306450
    },
    {
      "epoch": 3.244726631766717,
      "grad_norm": 1.0286426544189453,
      "learning_rate": 0.00042718776811135646,
      "loss": 0.7228,
      "step": 306500
    },
    {
      "epoch": 3.244726631766717,
      "eval_loss": 0.5235103368759155,
      "eval_runtime": 46.8139,
      "eval_samples_per_second": 3587.184,
      "eval_steps_per_second": 448.414,
      "step": 306500
    },
    {
      "epoch": 3.2452559535467205,
      "grad_norm": 0.9263560175895691,
      "learning_rate": 0.00042715517834045045,
      "loss": 0.7319,
      "step": 306550
    },
    {
      "epoch": 3.245785275326724,
      "grad_norm": 0.9710476994514465,
      "learning_rate": 0.0004271225825215316,
      "loss": 0.729,
      "step": 306600
    },
    {
      "epoch": 3.246314597106727,
      "grad_norm": 0.9106960296630859,
      "learning_rate": 0.0004270899806557128,
      "loss": 0.7227,
      "step": 306650
    },
    {
      "epoch": 3.2468439188867304,
      "grad_norm": 0.9122905731201172,
      "learning_rate": 0.00042705737274410696,
      "loss": 0.7295,
      "step": 306700
    },
    {
      "epoch": 3.2473732406667337,
      "grad_norm": 0.8543201088905334,
      "learning_rate": 0.0004270247587878273,
      "loss": 0.7155,
      "step": 306750
    },
    {
      "epoch": 3.247902562446737,
      "grad_norm": 0.9213590621948242,
      "learning_rate": 0.00042699213878798735,
      "loss": 0.7335,
      "step": 306800
    },
    {
      "epoch": 3.2484318842267403,
      "grad_norm": 0.8664325475692749,
      "learning_rate": 0.00042695951274570064,
      "loss": 0.7268,
      "step": 306850
    },
    {
      "epoch": 3.2489612060067437,
      "grad_norm": 1.0529769659042358,
      "learning_rate": 0.0004269268806620812,
      "loss": 0.7073,
      "step": 306900
    },
    {
      "epoch": 3.249490527786747,
      "grad_norm": 0.8532153964042664,
      "learning_rate": 0.00042689424253824284,
      "loss": 0.7346,
      "step": 306950
    },
    {
      "epoch": 3.2500198495667503,
      "grad_norm": 0.9756917357444763,
      "learning_rate": 0.00042686159837529994,
      "loss": 0.7352,
      "step": 307000
    },
    {
      "epoch": 3.2500198495667503,
      "eval_loss": 0.5248268246650696,
      "eval_runtime": 46.817,
      "eval_samples_per_second": 3586.944,
      "eval_steps_per_second": 448.384,
      "step": 307000
    },
    {
      "epoch": 3.2505491713467536,
      "grad_norm": 0.9844083189964294,
      "learning_rate": 0.0004268289481743669,
      "loss": 0.7273,
      "step": 307050
    },
    {
      "epoch": 3.251078493126757,
      "grad_norm": 0.8722477555274963,
      "learning_rate": 0.00042679629193655843,
      "loss": 0.7274,
      "step": 307100
    },
    {
      "epoch": 3.2516078149067598,
      "grad_norm": 0.9398342967033386,
      "learning_rate": 0.00042676362966298937,
      "loss": 0.7246,
      "step": 307150
    },
    {
      "epoch": 3.252137136686763,
      "grad_norm": 0.9016435146331787,
      "learning_rate": 0.00042673096135477487,
      "loss": 0.7191,
      "step": 307200
    },
    {
      "epoch": 3.2526664584667664,
      "grad_norm": 0.9676339030265808,
      "learning_rate": 0.00042669828701303014,
      "loss": 0.7182,
      "step": 307250
    },
    {
      "epoch": 3.2531957802467697,
      "grad_norm": 1.007675290107727,
      "learning_rate": 0.00042666560663887066,
      "loss": 0.7286,
      "step": 307300
    },
    {
      "epoch": 3.253725102026773,
      "grad_norm": 0.9658170938491821,
      "learning_rate": 0.00042663292023341223,
      "loss": 0.7201,
      "step": 307350
    },
    {
      "epoch": 3.2542544238067763,
      "grad_norm": 0.9535443782806396,
      "learning_rate": 0.0004266002277977706,
      "loss": 0.7234,
      "step": 307400
    },
    {
      "epoch": 3.2547837455867796,
      "grad_norm": 0.9298152923583984,
      "learning_rate": 0.000426567529333062,
      "loss": 0.7324,
      "step": 307450
    },
    {
      "epoch": 3.255313067366783,
      "grad_norm": 0.8696056604385376,
      "learning_rate": 0.00042653482484040275,
      "loss": 0.7199,
      "step": 307500
    },
    {
      "epoch": 3.255313067366783,
      "eval_loss": 0.5208076238632202,
      "eval_runtime": 46.805,
      "eval_samples_per_second": 3587.862,
      "eval_steps_per_second": 448.499,
      "step": 307500
    },
    {
      "epoch": 3.2558423891467863,
      "grad_norm": 0.9532510042190552,
      "learning_rate": 0.00042650211432090923,
      "loss": 0.729,
      "step": 307550
    },
    {
      "epoch": 3.2563717109267896,
      "grad_norm": 0.9875615239143372,
      "learning_rate": 0.00042646939777569835,
      "loss": 0.724,
      "step": 307600
    },
    {
      "epoch": 3.256901032706793,
      "grad_norm": 0.994665801525116,
      "learning_rate": 0.0004264366752058869,
      "loss": 0.7115,
      "step": 307650
    },
    {
      "epoch": 3.257430354486796,
      "grad_norm": 0.7925934791564941,
      "learning_rate": 0.0004264039466125921,
      "loss": 0.7276,
      "step": 307700
    },
    {
      "epoch": 3.2579596762667995,
      "grad_norm": 0.9656875729560852,
      "learning_rate": 0.0004263712119969312,
      "loss": 0.7228,
      "step": 307750
    },
    {
      "epoch": 3.258488998046803,
      "grad_norm": 0.9603283405303955,
      "learning_rate": 0.0004263384713600218,
      "loss": 0.7304,
      "step": 307800
    },
    {
      "epoch": 3.259018319826806,
      "grad_norm": 0.9078249931335449,
      "learning_rate": 0.00042630572470298174,
      "loss": 0.7138,
      "step": 307850
    },
    {
      "epoch": 3.259547641606809,
      "grad_norm": 0.8066339492797852,
      "learning_rate": 0.00042627297202692884,
      "loss": 0.7351,
      "step": 307900
    },
    {
      "epoch": 3.2600769633868123,
      "grad_norm": 0.997628927230835,
      "learning_rate": 0.00042624021333298136,
      "loss": 0.7254,
      "step": 307950
    },
    {
      "epoch": 3.2606062851668156,
      "grad_norm": 0.9778198003768921,
      "learning_rate": 0.00042620744862225757,
      "loss": 0.7303,
      "step": 308000
    },
    {
      "epoch": 3.2606062851668156,
      "eval_loss": 0.5207836627960205,
      "eval_runtime": 46.8382,
      "eval_samples_per_second": 3585.32,
      "eval_steps_per_second": 448.181,
      "step": 308000
    },
    {
      "epoch": 3.261135606946819,
      "grad_norm": 0.9108240604400635,
      "learning_rate": 0.0004261746778958762,
      "loss": 0.7162,
      "step": 308050
    },
    {
      "epoch": 3.2616649287268222,
      "grad_norm": 0.9482632279396057,
      "learning_rate": 0.0004261419011549558,
      "loss": 0.7207,
      "step": 308100
    },
    {
      "epoch": 3.2621942505068255,
      "grad_norm": 0.916279137134552,
      "learning_rate": 0.0004261091184006156,
      "loss": 0.7256,
      "step": 308150
    },
    {
      "epoch": 3.262723572286829,
      "grad_norm": 0.9143273830413818,
      "learning_rate": 0.0004260763296339746,
      "loss": 0.7295,
      "step": 308200
    },
    {
      "epoch": 3.263252894066832,
      "grad_norm": 0.908061683177948,
      "learning_rate": 0.00042604353485615234,
      "loss": 0.7288,
      "step": 308250
    },
    {
      "epoch": 3.2637822158468355,
      "grad_norm": 0.9688076376914978,
      "learning_rate": 0.0004260107340682684,
      "loss": 0.7192,
      "step": 308300
    },
    {
      "epoch": 3.264311537626839,
      "grad_norm": 0.9707650542259216,
      "learning_rate": 0.0004259779272714425,
      "loss": 0.7184,
      "step": 308350
    },
    {
      "epoch": 3.264840859406842,
      "grad_norm": 0.9374209642410278,
      "learning_rate": 0.00042594511446679466,
      "loss": 0.7212,
      "step": 308400
    },
    {
      "epoch": 3.2653701811868454,
      "grad_norm": 0.9397133588790894,
      "learning_rate": 0.0004259122956554452,
      "loss": 0.7181,
      "step": 308450
    },
    {
      "epoch": 3.2658995029668487,
      "grad_norm": 0.9279643893241882,
      "learning_rate": 0.00042587947083851444,
      "loss": 0.7249,
      "step": 308500
    },
    {
      "epoch": 3.2658995029668487,
      "eval_loss": 0.5180960297584534,
      "eval_runtime": 46.7895,
      "eval_samples_per_second": 3589.053,
      "eval_steps_per_second": 448.648,
      "step": 308500
    },
    {
      "epoch": 3.266428824746852,
      "grad_norm": 1.0313072204589844,
      "learning_rate": 0.0004258472966923874,
      "loss": 0.716,
      "step": 308550
    },
    {
      "epoch": 3.2669581465268553,
      "grad_norm": 0.8996995687484741,
      "learning_rate": 0.00042581445998771204,
      "loss": 0.7247,
      "step": 308600
    },
    {
      "epoch": 3.267487468306858,
      "grad_norm": 0.9699691534042358,
      "learning_rate": 0.00042578161728079546,
      "loss": 0.7266,
      "step": 308650
    },
    {
      "epoch": 3.2680167900868615,
      "grad_norm": 0.890842616558075,
      "learning_rate": 0.00042574876857275903,
      "loss": 0.7253,
      "step": 308700
    },
    {
      "epoch": 3.268546111866865,
      "grad_norm": 1.0421675443649292,
      "learning_rate": 0.000425715913864724,
      "loss": 0.7308,
      "step": 308750
    },
    {
      "epoch": 3.269075433646868,
      "grad_norm": 1.0505307912826538,
      "learning_rate": 0.0004256830531578121,
      "loss": 0.7124,
      "step": 308800
    },
    {
      "epoch": 3.2696047554268715,
      "grad_norm": 0.943936288356781,
      "learning_rate": 0.00042565018645314526,
      "loss": 0.7244,
      "step": 308850
    },
    {
      "epoch": 3.2701340772068748,
      "grad_norm": 0.9840201735496521,
      "learning_rate": 0.0004256173137518454,
      "loss": 0.7131,
      "step": 308900
    },
    {
      "epoch": 3.270663398986878,
      "grad_norm": 0.9764274954795837,
      "learning_rate": 0.000425584435055035,
      "loss": 0.7115,
      "step": 308950
    },
    {
      "epoch": 3.2711927207668814,
      "grad_norm": 0.9292436242103577,
      "learning_rate": 0.0004255515503638362,
      "loss": 0.7263,
      "step": 309000
    },
    {
      "epoch": 3.2711927207668814,
      "eval_loss": 0.5208632946014404,
      "eval_runtime": 46.9002,
      "eval_samples_per_second": 3580.581,
      "eval_steps_per_second": 447.589,
      "step": 309000
    },
    {
      "epoch": 3.2717220425468847,
      "grad_norm": 0.9699928164482117,
      "learning_rate": 0.000425518659679372,
      "loss": 0.7139,
      "step": 309050
    },
    {
      "epoch": 3.272251364326888,
      "grad_norm": 0.9960846900939941,
      "learning_rate": 0.00042548576300276505,
      "loss": 0.7258,
      "step": 309100
    },
    {
      "epoch": 3.2727806861068913,
      "grad_norm": 0.8653177618980408,
      "learning_rate": 0.0004254528603351385,
      "loss": 0.7377,
      "step": 309150
    },
    {
      "epoch": 3.2733100078868946,
      "grad_norm": 0.9681638479232788,
      "learning_rate": 0.0004254199516776157,
      "loss": 0.7205,
      "step": 309200
    },
    {
      "epoch": 3.273839329666898,
      "grad_norm": 0.8623010516166687,
      "learning_rate": 0.00042538703703131996,
      "loss": 0.7253,
      "step": 309250
    },
    {
      "epoch": 3.2743686514469013,
      "grad_norm": 1.0449469089508057,
      "learning_rate": 0.00042535411639737527,
      "loss": 0.7421,
      "step": 309300
    },
    {
      "epoch": 3.2748979732269046,
      "grad_norm": 0.9814271926879883,
      "learning_rate": 0.0004253211897769053,
      "loss": 0.7159,
      "step": 309350
    },
    {
      "epoch": 3.2754272950069074,
      "grad_norm": 0.958527684211731,
      "learning_rate": 0.00042528825717103415,
      "loss": 0.7228,
      "step": 309400
    },
    {
      "epoch": 3.2759566167869107,
      "grad_norm": 0.9498675465583801,
      "learning_rate": 0.00042525531858088615,
      "loss": 0.7158,
      "step": 309450
    },
    {
      "epoch": 3.276485938566914,
      "grad_norm": 0.8577057719230652,
      "learning_rate": 0.000425222374007586,
      "loss": 0.7171,
      "step": 309500
    },
    {
      "epoch": 3.276485938566914,
      "eval_loss": 0.5201779007911682,
      "eval_runtime": 46.8757,
      "eval_samples_per_second": 3582.45,
      "eval_steps_per_second": 447.822,
      "step": 309500
    },
    {
      "epoch": 3.2770152603469174,
      "grad_norm": 0.847152829170227,
      "learning_rate": 0.00042518942345225815,
      "loss": 0.7144,
      "step": 309550
    },
    {
      "epoch": 3.2775445821269207,
      "grad_norm": 1.0008264780044556,
      "learning_rate": 0.00042515646691602764,
      "loss": 0.7295,
      "step": 309600
    },
    {
      "epoch": 3.278073903906924,
      "grad_norm": 0.9335014224052429,
      "learning_rate": 0.0004251235044000196,
      "loss": 0.708,
      "step": 309650
    },
    {
      "epoch": 3.2786032256869273,
      "grad_norm": 1.021113395690918,
      "learning_rate": 0.0004250905359053594,
      "loss": 0.7085,
      "step": 309700
    },
    {
      "epoch": 3.2791325474669306,
      "grad_norm": 0.9637823104858398,
      "learning_rate": 0.0004250575614331724,
      "loss": 0.7141,
      "step": 309750
    },
    {
      "epoch": 3.279661869246934,
      "grad_norm": 0.9481371641159058,
      "learning_rate": 0.0004250245809845845,
      "loss": 0.6997,
      "step": 309800
    },
    {
      "epoch": 3.2801911910269372,
      "grad_norm": 0.9689473509788513,
      "learning_rate": 0.00042499159456072167,
      "loss": 0.717,
      "step": 309850
    },
    {
      "epoch": 3.2807205128069405,
      "grad_norm": 0.9035894274711609,
      "learning_rate": 0.0004249586021627099,
      "loss": 0.7398,
      "step": 309900
    },
    {
      "epoch": 3.281249834586944,
      "grad_norm": 1.0182280540466309,
      "learning_rate": 0.00042492560379167566,
      "loss": 0.7419,
      "step": 309950
    },
    {
      "epoch": 3.281779156366947,
      "grad_norm": 0.937629759311676,
      "learning_rate": 0.0004248925994487455,
      "loss": 0.7394,
      "step": 310000
    },
    {
      "epoch": 3.281779156366947,
      "eval_loss": 0.5214539766311646,
      "eval_runtime": 46.8343,
      "eval_samples_per_second": 3585.619,
      "eval_steps_per_second": 448.218,
      "step": 310000
    },
    {
      "epoch": 3.2823084781469505,
      "grad_norm": 0.918922483921051,
      "learning_rate": 0.000424859589135046,
      "loss": 0.7184,
      "step": 310050
    },
    {
      "epoch": 3.282837799926954,
      "grad_norm": 0.9239321351051331,
      "learning_rate": 0.00042482657285170433,
      "loss": 0.7153,
      "step": 310100
    },
    {
      "epoch": 3.2833671217069567,
      "grad_norm": 0.9262968301773071,
      "learning_rate": 0.0004247935505998476,
      "loss": 0.7307,
      "step": 310150
    },
    {
      "epoch": 3.28389644348696,
      "grad_norm": 0.907174825668335,
      "learning_rate": 0.0004247605223806031,
      "loss": 0.7159,
      "step": 310200
    },
    {
      "epoch": 3.2844257652669633,
      "grad_norm": 0.9555460810661316,
      "learning_rate": 0.0004247274881950985,
      "loss": 0.7188,
      "step": 310250
    },
    {
      "epoch": 3.2849550870469666,
      "grad_norm": 1.0178276300430298,
      "learning_rate": 0.0004246944480444615,
      "loss": 0.7219,
      "step": 310300
    },
    {
      "epoch": 3.28548440882697,
      "grad_norm": 0.9349965453147888,
      "learning_rate": 0.00042466140192982016,
      "loss": 0.7274,
      "step": 310350
    },
    {
      "epoch": 3.286013730606973,
      "grad_norm": 0.8970245122909546,
      "learning_rate": 0.0004246283498523026,
      "loss": 0.7173,
      "step": 310400
    },
    {
      "epoch": 3.2865430523869765,
      "grad_norm": 1.0747674703598022,
      "learning_rate": 0.00042459529181303716,
      "loss": 0.7322,
      "step": 310450
    },
    {
      "epoch": 3.28707237416698,
      "grad_norm": 0.9491183757781982,
      "learning_rate": 0.0004245622278131526,
      "loss": 0.7275,
      "step": 310500
    },
    {
      "epoch": 3.28707237416698,
      "eval_loss": 0.5177271366119385,
      "eval_runtime": 46.8417,
      "eval_samples_per_second": 3585.054,
      "eval_steps_per_second": 448.148,
      "step": 310500
    },
    {
      "epoch": 3.287601695946983,
      "grad_norm": 0.9873321056365967,
      "learning_rate": 0.00042452915785377745,
      "loss": 0.7288,
      "step": 310550
    },
    {
      "epoch": 3.2881310177269865,
      "grad_norm": 0.9281325340270996,
      "learning_rate": 0.00042449608193604097,
      "loss": 0.7238,
      "step": 310600
    },
    {
      "epoch": 3.2886603395069898,
      "grad_norm": 0.8943493962287903,
      "learning_rate": 0.00042446366175694517,
      "loss": 0.7275,
      "step": 310650
    },
    {
      "epoch": 3.289189661286993,
      "grad_norm": 0.9634299278259277,
      "learning_rate": 0.0004244305740449845,
      "loss": 0.7093,
      "step": 310700
    },
    {
      "epoch": 3.2897189830669964,
      "grad_norm": 0.953866720199585,
      "learning_rate": 0.0004243974803780281,
      "loss": 0.7159,
      "step": 310750
    },
    {
      "epoch": 3.2902483048469997,
      "grad_norm": 0.9759274125099182,
      "learning_rate": 0.00042436438075720565,
      "loss": 0.7256,
      "step": 310800
    },
    {
      "epoch": 3.290777626627003,
      "grad_norm": 0.8684066534042358,
      "learning_rate": 0.0004243312751836472,
      "loss": 0.7249,
      "step": 310850
    },
    {
      "epoch": 3.291306948407006,
      "grad_norm": 0.9868682622909546,
      "learning_rate": 0.00042429816365848296,
      "loss": 0.7198,
      "step": 310900
    },
    {
      "epoch": 3.291836270187009,
      "grad_norm": 1.0900577306747437,
      "learning_rate": 0.0004242650461828433,
      "loss": 0.7164,
      "step": 310950
    },
    {
      "epoch": 3.2923655919670125,
      "grad_norm": 0.9557571411132812,
      "learning_rate": 0.0004242319227578589,
      "loss": 0.7275,
      "step": 311000
    },
    {
      "epoch": 3.2923655919670125,
      "eval_loss": 0.519726574420929,
      "eval_runtime": 46.8822,
      "eval_samples_per_second": 3581.953,
      "eval_steps_per_second": 447.76,
      "step": 311000
    },
    {
      "epoch": 3.292894913747016,
      "grad_norm": 0.8495224714279175,
      "learning_rate": 0.0004241987933846605,
      "loss": 0.7217,
      "step": 311050
    },
    {
      "epoch": 3.293424235527019,
      "grad_norm": 0.8748948574066162,
      "learning_rate": 0.00042416565806437925,
      "loss": 0.7211,
      "step": 311100
    },
    {
      "epoch": 3.2939535573070224,
      "grad_norm": 0.9425345063209534,
      "learning_rate": 0.00042413251679814624,
      "loss": 0.7301,
      "step": 311150
    },
    {
      "epoch": 3.2944828790870258,
      "grad_norm": 0.9128934144973755,
      "learning_rate": 0.000424099369587093,
      "loss": 0.7127,
      "step": 311200
    },
    {
      "epoch": 3.295012200867029,
      "grad_norm": 1.011051893234253,
      "learning_rate": 0.0004240662164323511,
      "loss": 0.7151,
      "step": 311250
    },
    {
      "epoch": 3.2955415226470324,
      "grad_norm": 0.9828227758407593,
      "learning_rate": 0.0004240330573350525,
      "loss": 0.724,
      "step": 311300
    },
    {
      "epoch": 3.2960708444270357,
      "grad_norm": 1.0011959075927734,
      "learning_rate": 0.00042399989229632905,
      "loss": 0.7289,
      "step": 311350
    },
    {
      "epoch": 3.296600166207039,
      "grad_norm": 1.0019830465316772,
      "learning_rate": 0.0004239667213173132,
      "loss": 0.715,
      "step": 311400
    },
    {
      "epoch": 3.2971294879870423,
      "grad_norm": 0.9896689653396606,
      "learning_rate": 0.0004239335443991372,
      "loss": 0.7109,
      "step": 311450
    },
    {
      "epoch": 3.2976588097670456,
      "grad_norm": 0.8916558623313904,
      "learning_rate": 0.0004239003615429338,
      "loss": 0.7262,
      "step": 311500
    },
    {
      "epoch": 3.2976588097670456,
      "eval_loss": 0.518845796585083,
      "eval_runtime": 46.7915,
      "eval_samples_per_second": 3588.902,
      "eval_steps_per_second": 448.629,
      "step": 311500
    },
    {
      "epoch": 3.298188131547049,
      "grad_norm": 0.9510995745658875,
      "learning_rate": 0.0004238671727498358,
      "loss": 0.7324,
      "step": 311550
    },
    {
      "epoch": 3.2987174533270522,
      "grad_norm": 1.01270592212677,
      "learning_rate": 0.0004238339780209763,
      "loss": 0.7305,
      "step": 311600
    },
    {
      "epoch": 3.299246775107055,
      "grad_norm": 0.8590604662895203,
      "learning_rate": 0.00042380077735748855,
      "loss": 0.7266,
      "step": 311650
    },
    {
      "epoch": 3.2997760968870584,
      "grad_norm": 0.935632586479187,
      "learning_rate": 0.000423767570760506,
      "loss": 0.7179,
      "step": 311700
    },
    {
      "epoch": 3.3003054186670617,
      "grad_norm": 0.9526102542877197,
      "learning_rate": 0.00042373435823116234,
      "loss": 0.7097,
      "step": 311750
    },
    {
      "epoch": 3.300834740447065,
      "grad_norm": 0.921062707901001,
      "learning_rate": 0.0004237011397705914,
      "loss": 0.7228,
      "step": 311800
    },
    {
      "epoch": 3.3013640622270684,
      "grad_norm": 0.9621599912643433,
      "learning_rate": 0.0004236679153799272,
      "loss": 0.7277,
      "step": 311850
    },
    {
      "epoch": 3.3018933840070717,
      "grad_norm": 0.9384936094284058,
      "learning_rate": 0.0004236346850603041,
      "loss": 0.71,
      "step": 311900
    },
    {
      "epoch": 3.302422705787075,
      "grad_norm": 0.9948737025260925,
      "learning_rate": 0.0004236014488128566,
      "loss": 0.7217,
      "step": 311950
    },
    {
      "epoch": 3.3029520275670783,
      "grad_norm": 0.8576254844665527,
      "learning_rate": 0.00042356820663871914,
      "loss": 0.7252,
      "step": 312000
    },
    {
      "epoch": 3.3029520275670783,
      "eval_loss": 0.5181980133056641,
      "eval_runtime": 46.7676,
      "eval_samples_per_second": 3590.733,
      "eval_steps_per_second": 448.858,
      "step": 312000
    },
    {
      "epoch": 3.3034813493470816,
      "grad_norm": 0.9391433596611023,
      "learning_rate": 0.0004235349585390269,
      "loss": 0.7233,
      "step": 312050
    },
    {
      "epoch": 3.304010671127085,
      "grad_norm": 0.9773328304290771,
      "learning_rate": 0.0004235017045149148,
      "loss": 0.7129,
      "step": 312100
    },
    {
      "epoch": 3.304539992907088,
      "grad_norm": 0.9827244877815247,
      "learning_rate": 0.00042346844456751803,
      "loss": 0.7128,
      "step": 312150
    },
    {
      "epoch": 3.3050693146870915,
      "grad_norm": 0.9661635756492615,
      "learning_rate": 0.0004234351786979723,
      "loss": 0.7222,
      "step": 312200
    },
    {
      "epoch": 3.305598636467095,
      "grad_norm": 0.9317324757575989,
      "learning_rate": 0.0004234019069074131,
      "loss": 0.7314,
      "step": 312250
    },
    {
      "epoch": 3.306127958247098,
      "grad_norm": 0.9360659718513489,
      "learning_rate": 0.00042336862919697645,
      "loss": 0.7136,
      "step": 312300
    },
    {
      "epoch": 3.3066572800271015,
      "grad_norm": 0.9573933482170105,
      "learning_rate": 0.0004233353455677983,
      "loss": 0.7169,
      "step": 312350
    },
    {
      "epoch": 3.3071866018071043,
      "grad_norm": 1.0030510425567627,
      "learning_rate": 0.0004233020560210151,
      "loss": 0.7059,
      "step": 312400
    },
    {
      "epoch": 3.307715923587108,
      "grad_norm": 0.9299524426460266,
      "learning_rate": 0.0004232687605577632,
      "loss": 0.7062,
      "step": 312450
    },
    {
      "epoch": 3.308245245367111,
      "grad_norm": 1.0787014961242676,
      "learning_rate": 0.00042323545917917943,
      "loss": 0.7197,
      "step": 312500
    },
    {
      "epoch": 3.308245245367111,
      "eval_loss": 0.5153569579124451,
      "eval_runtime": 46.8386,
      "eval_samples_per_second": 3585.292,
      "eval_steps_per_second": 448.178,
      "step": 312500
    },
    {
      "epoch": 3.3087745671471143,
      "grad_norm": 0.9757447838783264,
      "learning_rate": 0.00042320215188640056,
      "loss": 0.7295,
      "step": 312550
    },
    {
      "epoch": 3.3093038889271176,
      "grad_norm": 0.9585561752319336,
      "learning_rate": 0.00042316883868056377,
      "loss": 0.7162,
      "step": 312600
    },
    {
      "epoch": 3.309833210707121,
      "grad_norm": 1.025777816772461,
      "learning_rate": 0.0004231355195628064,
      "loss": 0.7223,
      "step": 312650
    },
    {
      "epoch": 3.310362532487124,
      "grad_norm": 0.8964396715164185,
      "learning_rate": 0.0004231021945342658,
      "loss": 0.7204,
      "step": 312700
    },
    {
      "epoch": 3.3108918542671275,
      "grad_norm": 1.1113085746765137,
      "learning_rate": 0.00042306886359607976,
      "loss": 0.7216,
      "step": 312750
    },
    {
      "epoch": 3.311421176047131,
      "grad_norm": 1.039244294166565,
      "learning_rate": 0.0004230355267493862,
      "loss": 0.7277,
      "step": 312800
    },
    {
      "epoch": 3.311950497827134,
      "grad_norm": 0.9474906921386719,
      "learning_rate": 0.00042300285090828937,
      "loss": 0.721,
      "step": 312850
    },
    {
      "epoch": 3.3124798196071374,
      "grad_norm": 0.892401933670044,
      "learning_rate": 0.00042296950236610876,
      "loss": 0.7203,
      "step": 312900
    },
    {
      "epoch": 3.3130091413871408,
      "grad_norm": 0.9248688220977783,
      "learning_rate": 0.00042293614791881273,
      "loss": 0.7287,
      "step": 312950
    },
    {
      "epoch": 3.313538463167144,
      "grad_norm": 0.8993173837661743,
      "learning_rate": 0.00042290278756754006,
      "loss": 0.7137,
      "step": 313000
    },
    {
      "epoch": 3.313538463167144,
      "eval_loss": 0.5179426074028015,
      "eval_runtime": 46.7969,
      "eval_samples_per_second": 3588.485,
      "eval_steps_per_second": 448.577,
      "step": 313000
    },
    {
      "epoch": 3.3140677849471474,
      "grad_norm": 0.894014835357666,
      "learning_rate": 0.00042286942131342965,
      "loss": 0.7269,
      "step": 313050
    },
    {
      "epoch": 3.3145971067271507,
      "grad_norm": 1.1259403228759766,
      "learning_rate": 0.0004228360491576206,
      "loss": 0.7182,
      "step": 313100
    },
    {
      "epoch": 3.3151264285071536,
      "grad_norm": 0.9190765023231506,
      "learning_rate": 0.00042280267110125216,
      "loss": 0.719,
      "step": 313150
    },
    {
      "epoch": 3.3156557502871573,
      "grad_norm": 0.8768216371536255,
      "learning_rate": 0.0004227692871454639,
      "loss": 0.7222,
      "step": 313200
    },
    {
      "epoch": 3.31618507206716,
      "grad_norm": 0.955488383769989,
      "learning_rate": 0.00042273589729139563,
      "loss": 0.7186,
      "step": 313250
    },
    {
      "epoch": 3.3167143938471635,
      "grad_norm": 1.00888991355896,
      "learning_rate": 0.00042270250154018715,
      "loss": 0.7282,
      "step": 313300
    },
    {
      "epoch": 3.317243715627167,
      "grad_norm": 1.033104658126831,
      "learning_rate": 0.0004226690998929785,
      "loss": 0.73,
      "step": 313350
    },
    {
      "epoch": 3.31777303740717,
      "grad_norm": 0.9233338832855225,
      "learning_rate": 0.00042263569235091025,
      "loss": 0.7148,
      "step": 313400
    },
    {
      "epoch": 3.3183023591871734,
      "grad_norm": 0.9963880777359009,
      "learning_rate": 0.0004226022789151227,
      "loss": 0.7159,
      "step": 313450
    },
    {
      "epoch": 3.3188316809671767,
      "grad_norm": 1.0284043550491333,
      "learning_rate": 0.00042256885958675666,
      "loss": 0.7126,
      "step": 313500
    },
    {
      "epoch": 3.3188316809671767,
      "eval_loss": 0.516144335269928,
      "eval_runtime": 46.8175,
      "eval_samples_per_second": 3586.909,
      "eval_steps_per_second": 448.38,
      "step": 313500
    },
    {
      "epoch": 3.31936100274718,
      "grad_norm": 0.9741460680961609,
      "learning_rate": 0.00042253543436695303,
      "loss": 0.7258,
      "step": 313550
    },
    {
      "epoch": 3.3198903245271834,
      "grad_norm": 0.8849056959152222,
      "learning_rate": 0.00042250200325685296,
      "loss": 0.7264,
      "step": 313600
    },
    {
      "epoch": 3.3204196463071867,
      "grad_norm": 1.062054991722107,
      "learning_rate": 0.0004224685662575978,
      "loss": 0.7241,
      "step": 313650
    },
    {
      "epoch": 3.32094896808719,
      "grad_norm": 0.9445559978485107,
      "learning_rate": 0.00042243512337032896,
      "loss": 0.7221,
      "step": 313700
    },
    {
      "epoch": 3.3214782898671933,
      "grad_norm": 0.9530121088027954,
      "learning_rate": 0.0004224016745961883,
      "loss": 0.7193,
      "step": 313750
    },
    {
      "epoch": 3.3220076116471966,
      "grad_norm": 0.8731009364128113,
      "learning_rate": 0.00042236821993631764,
      "loss": 0.7171,
      "step": 313800
    },
    {
      "epoch": 3.3225369334272,
      "grad_norm": 0.9000962376594543,
      "learning_rate": 0.00042233475939185925,
      "loss": 0.7147,
      "step": 313850
    },
    {
      "epoch": 3.323066255207203,
      "grad_norm": 0.9307037591934204,
      "learning_rate": 0.00042230129296395527,
      "loss": 0.734,
      "step": 313900
    },
    {
      "epoch": 3.3235955769872065,
      "grad_norm": 0.924876868724823,
      "learning_rate": 0.0004222678206537484,
      "loss": 0.7198,
      "step": 313950
    },
    {
      "epoch": 3.3241248987672094,
      "grad_norm": 0.913148045539856,
      "learning_rate": 0.0004222343424623813,
      "loss": 0.7299,
      "step": 314000
    },
    {
      "epoch": 3.3241248987672094,
      "eval_loss": 0.5187717080116272,
      "eval_runtime": 46.7792,
      "eval_samples_per_second": 3589.843,
      "eval_steps_per_second": 448.746,
      "step": 314000
    },
    {
      "epoch": 3.3246542205472127,
      "grad_norm": 0.9314387440681458,
      "learning_rate": 0.00042220085839099697,
      "loss": 0.7214,
      "step": 314050
    },
    {
      "epoch": 3.325183542327216,
      "grad_norm": 0.9792547821998596,
      "learning_rate": 0.00042216736844073846,
      "loss": 0.7202,
      "step": 314100
    },
    {
      "epoch": 3.3257128641072193,
      "grad_norm": 0.9055476188659668,
      "learning_rate": 0.00042213387261274903,
      "loss": 0.7085,
      "step": 314150
    },
    {
      "epoch": 3.3262421858872226,
      "grad_norm": 0.8978843092918396,
      "learning_rate": 0.00042210037090817246,
      "loss": 0.7135,
      "step": 314200
    },
    {
      "epoch": 3.326771507667226,
      "grad_norm": 0.9652143120765686,
      "learning_rate": 0.00042206686332815226,
      "loss": 0.7218,
      "step": 314250
    },
    {
      "epoch": 3.3273008294472293,
      "grad_norm": 1.0403146743774414,
      "learning_rate": 0.0004220333498738325,
      "loss": 0.7115,
      "step": 314300
    },
    {
      "epoch": 3.3278301512272326,
      "grad_norm": 1.0042943954467773,
      "learning_rate": 0.0004219998305463572,
      "loss": 0.7297,
      "step": 314350
    },
    {
      "epoch": 3.328359473007236,
      "grad_norm": 0.9206902980804443,
      "learning_rate": 0.0004219663053468708,
      "loss": 0.7082,
      "step": 314400
    },
    {
      "epoch": 3.328888794787239,
      "grad_norm": 0.9748449325561523,
      "learning_rate": 0.00042193277427651776,
      "loss": 0.7228,
      "step": 314450
    },
    {
      "epoch": 3.3294181165672425,
      "grad_norm": 0.9130542874336243,
      "learning_rate": 0.00042189923733644297,
      "loss": 0.7153,
      "step": 314500
    },
    {
      "epoch": 3.3294181165672425,
      "eval_loss": 0.5190359354019165,
      "eval_runtime": 46.8493,
      "eval_samples_per_second": 3584.471,
      "eval_steps_per_second": 448.075,
      "step": 314500
    },
    {
      "epoch": 3.329947438347246,
      "grad_norm": 1.0686302185058594,
      "learning_rate": 0.0004218656945277912,
      "loss": 0.7218,
      "step": 314550
    },
    {
      "epoch": 3.330476760127249,
      "grad_norm": 0.849260151386261,
      "learning_rate": 0.0004218321458517076,
      "loss": 0.7041,
      "step": 314600
    },
    {
      "epoch": 3.331006081907252,
      "grad_norm": 0.9298275113105774,
      "learning_rate": 0.0004217985913093376,
      "loss": 0.71,
      "step": 314650
    },
    {
      "epoch": 3.3315354036872558,
      "grad_norm": 0.9954336881637573,
      "learning_rate": 0.0004217650309018267,
      "loss": 0.7257,
      "step": 314700
    },
    {
      "epoch": 3.3320647254672586,
      "grad_norm": 0.8338567018508911,
      "learning_rate": 0.00042173146463032066,
      "loss": 0.7205,
      "step": 314750
    },
    {
      "epoch": 3.332594047247262,
      "grad_norm": 0.9386134147644043,
      "learning_rate": 0.00042169789249596533,
      "loss": 0.7186,
      "step": 314800
    },
    {
      "epoch": 3.3331233690272652,
      "grad_norm": 0.9876946210861206,
      "learning_rate": 0.000421664314499907,
      "loss": 0.7216,
      "step": 314850
    },
    {
      "epoch": 3.3336526908072686,
      "grad_norm": 0.922512412071228,
      "learning_rate": 0.0004216314023778502,
      "loss": 0.7222,
      "step": 314900
    },
    {
      "epoch": 3.334182012587272,
      "grad_norm": 0.9500108957290649,
      "learning_rate": 0.0004215978127790019,
      "loss": 0.7248,
      "step": 314950
    },
    {
      "epoch": 3.334711334367275,
      "grad_norm": 0.9634142518043518,
      "learning_rate": 0.00042156421732186713,
      "loss": 0.701,
      "step": 315000
    },
    {
      "epoch": 3.334711334367275,
      "eval_loss": 0.5157782435417175,
      "eval_runtime": 46.7525,
      "eval_samples_per_second": 3591.893,
      "eval_steps_per_second": 449.003,
      "step": 315000
    },
    {
      "epoch": 3.3352406561472785,
      "grad_norm": 0.9845700263977051,
      "learning_rate": 0.0004215306160075929,
      "loss": 0.7223,
      "step": 315050
    },
    {
      "epoch": 3.335769977927282,
      "grad_norm": 0.9831002354621887,
      "learning_rate": 0.00042149700883732644,
      "loss": 0.7373,
      "step": 315100
    },
    {
      "epoch": 3.336299299707285,
      "grad_norm": 0.8976641297340393,
      "learning_rate": 0.00042146339581221494,
      "loss": 0.7227,
      "step": 315150
    },
    {
      "epoch": 3.3368286214872884,
      "grad_norm": 0.9249986410140991,
      "learning_rate": 0.000421429776933406,
      "loss": 0.7178,
      "step": 315200
    },
    {
      "epoch": 3.3373579432672917,
      "grad_norm": 1.034722924232483,
      "learning_rate": 0.0004213961522020473,
      "loss": 0.7099,
      "step": 315250
    },
    {
      "epoch": 3.337887265047295,
      "grad_norm": 0.8986951112747192,
      "learning_rate": 0.0004213625216192868,
      "loss": 0.7231,
      "step": 315300
    },
    {
      "epoch": 3.3384165868272984,
      "grad_norm": 1.0003890991210938,
      "learning_rate": 0.00042132888518627275,
      "loss": 0.7211,
      "step": 315350
    },
    {
      "epoch": 3.3389459086073012,
      "grad_norm": 0.9917039275169373,
      "learning_rate": 0.0004212952429041533,
      "loss": 0.7234,
      "step": 315400
    },
    {
      "epoch": 3.339475230387305,
      "grad_norm": 0.9214447736740112,
      "learning_rate": 0.00042126159477407713,
      "loss": 0.7253,
      "step": 315450
    },
    {
      "epoch": 3.340004552167308,
      "grad_norm": 0.883816659450531,
      "learning_rate": 0.00042122794079719295,
      "loss": 0.7197,
      "step": 315500
    },
    {
      "epoch": 3.340004552167308,
      "eval_loss": 0.5160566568374634,
      "eval_runtime": 46.8622,
      "eval_samples_per_second": 3583.482,
      "eval_steps_per_second": 447.951,
      "step": 315500
    },
    {
      "epoch": 3.340533873947311,
      "grad_norm": 0.9996017217636108,
      "learning_rate": 0.00042119428097464964,
      "loss": 0.7255,
      "step": 315550
    },
    {
      "epoch": 3.3410631957273145,
      "grad_norm": 0.9870158433914185,
      "learning_rate": 0.00042116061530759634,
      "loss": 0.7244,
      "step": 315600
    },
    {
      "epoch": 3.341592517507318,
      "grad_norm": 0.9862950444221497,
      "learning_rate": 0.0004211269437971824,
      "loss": 0.7166,
      "step": 315650
    },
    {
      "epoch": 3.342121839287321,
      "grad_norm": 0.8937566876411438,
      "learning_rate": 0.0004210932664445575,
      "loss": 0.718,
      "step": 315700
    },
    {
      "epoch": 3.3426511610673244,
      "grad_norm": 0.9861506223678589,
      "learning_rate": 0.000421059583250871,
      "loss": 0.7248,
      "step": 315750
    },
    {
      "epoch": 3.3431804828473277,
      "grad_norm": 0.9376320242881775,
      "learning_rate": 0.0004210258942172732,
      "loss": 0.7109,
      "step": 315800
    },
    {
      "epoch": 3.343709804627331,
      "grad_norm": 0.9127609133720398,
      "learning_rate": 0.0004209921993449141,
      "loss": 0.7156,
      "step": 315850
    },
    {
      "epoch": 3.3442391264073343,
      "grad_norm": 0.9658521413803101,
      "learning_rate": 0.00042095849863494397,
      "loss": 0.7183,
      "step": 315900
    },
    {
      "epoch": 3.3447684481873377,
      "grad_norm": 0.928926408290863,
      "learning_rate": 0.0004209247920885134,
      "loss": 0.7328,
      "step": 315950
    },
    {
      "epoch": 3.345297769967341,
      "grad_norm": 0.9042743444442749,
      "learning_rate": 0.00042089107970677314,
      "loss": 0.7207,
      "step": 316000
    },
    {
      "epoch": 3.345297769967341,
      "eval_loss": 0.5150464773178101,
      "eval_runtime": 46.8189,
      "eval_samples_per_second": 3586.802,
      "eval_steps_per_second": 448.366,
      "step": 316000
    },
    {
      "epoch": 3.3458270917473443,
      "grad_norm": 0.9851782917976379,
      "learning_rate": 0.00042085736149087403,
      "loss": 0.7143,
      "step": 316050
    },
    {
      "epoch": 3.3463564135273476,
      "grad_norm": 0.9532768130302429,
      "learning_rate": 0.0004208236374419674,
      "loss": 0.7179,
      "step": 316100
    },
    {
      "epoch": 3.3468857353073505,
      "grad_norm": 0.9845483899116516,
      "learning_rate": 0.00042078990756120433,
      "loss": 0.723,
      "step": 316150
    },
    {
      "epoch": 3.347415057087354,
      "grad_norm": 0.9549482464790344,
      "learning_rate": 0.0004207561718497365,
      "loss": 0.7253,
      "step": 316200
    },
    {
      "epoch": 3.347944378867357,
      "grad_norm": 0.9587896466255188,
      "learning_rate": 0.0004207224303087155,
      "loss": 0.7231,
      "step": 316250
    },
    {
      "epoch": 3.3484737006473604,
      "grad_norm": 0.9882435202598572,
      "learning_rate": 0.0004206886829392934,
      "loss": 0.7144,
      "step": 316300
    },
    {
      "epoch": 3.3490030224273637,
      "grad_norm": 0.8701369762420654,
      "learning_rate": 0.0004206549297426222,
      "loss": 0.714,
      "step": 316350
    },
    {
      "epoch": 3.349532344207367,
      "grad_norm": 1.0576980113983154,
      "learning_rate": 0.0004206211707198544,
      "loss": 0.7183,
      "step": 316400
    },
    {
      "epoch": 3.3500616659873703,
      "grad_norm": 1.003756046295166,
      "learning_rate": 0.00042058740587214236,
      "loss": 0.7208,
      "step": 316450
    },
    {
      "epoch": 3.3505909877673736,
      "grad_norm": 1.0636327266693115,
      "learning_rate": 0.00042055363520063883,
      "loss": 0.718,
      "step": 316500
    },
    {
      "epoch": 3.3505909877673736,
      "eval_loss": 0.5134477615356445,
      "eval_runtime": 46.814,
      "eval_samples_per_second": 3587.178,
      "eval_steps_per_second": 448.413,
      "step": 316500
    },
    {
      "epoch": 3.351120309547377,
      "grad_norm": 0.8921179175376892,
      "learning_rate": 0.00042051985870649665,
      "loss": 0.7133,
      "step": 316550
    },
    {
      "epoch": 3.3516496313273803,
      "grad_norm": 0.9763488173484802,
      "learning_rate": 0.00042048607639086924,
      "loss": 0.7229,
      "step": 316600
    },
    {
      "epoch": 3.3521789531073836,
      "grad_norm": 1.045905351638794,
      "learning_rate": 0.00042045228825490956,
      "loss": 0.727,
      "step": 316650
    },
    {
      "epoch": 3.352708274887387,
      "grad_norm": 1.0060076713562012,
      "learning_rate": 0.00042041849429977124,
      "loss": 0.7208,
      "step": 316700
    },
    {
      "epoch": 3.35323759666739,
      "grad_norm": 0.9496333599090576,
      "learning_rate": 0.0004203846945266081,
      "loss": 0.7218,
      "step": 316750
    },
    {
      "epoch": 3.3537669184473935,
      "grad_norm": 0.9415357708930969,
      "learning_rate": 0.0004203508889365739,
      "loss": 0.7087,
      "step": 316800
    },
    {
      "epoch": 3.354296240227397,
      "grad_norm": 0.8937355875968933,
      "learning_rate": 0.00042031707753082293,
      "loss": 0.7292,
      "step": 316850
    },
    {
      "epoch": 3.3548255620073997,
      "grad_norm": 0.9670424461364746,
      "learning_rate": 0.00042028326031050934,
      "loss": 0.7103,
      "step": 316900
    },
    {
      "epoch": 3.3553548837874034,
      "grad_norm": 0.9908928871154785,
      "learning_rate": 0.00042024943727678773,
      "loss": 0.7038,
      "step": 316950
    },
    {
      "epoch": 3.3558842055674063,
      "grad_norm": 1.0144187211990356,
      "learning_rate": 0.0004202162850646849,
      "loss": 0.7268,
      "step": 317000
    },
    {
      "epoch": 3.3558842055674063,
      "eval_loss": 0.5154770016670227,
      "eval_runtime": 46.7814,
      "eval_samples_per_second": 3589.676,
      "eval_steps_per_second": 448.726,
      "step": 317000
    },
    {
      "epoch": 3.3564135273474096,
      "grad_norm": 1.0479986667633057,
      "learning_rate": 0.0004201824505238221,
      "loss": 0.7228,
      "step": 317050
    },
    {
      "epoch": 3.356942849127413,
      "grad_norm": 1.008644938468933,
      "learning_rate": 0.0004201486101729928,
      "loss": 0.7184,
      "step": 317100
    },
    {
      "epoch": 3.3574721709074162,
      "grad_norm": 0.885370135307312,
      "learning_rate": 0.00042011476401335244,
      "loss": 0.7205,
      "step": 317150
    },
    {
      "epoch": 3.3580014926874195,
      "grad_norm": 1.0156477689743042,
      "learning_rate": 0.0004200809120460564,
      "loss": 0.7211,
      "step": 317200
    },
    {
      "epoch": 3.358530814467423,
      "grad_norm": 1.003350019454956,
      "learning_rate": 0.0004200470542722604,
      "loss": 0.7116,
      "step": 317250
    },
    {
      "epoch": 3.359060136247426,
      "grad_norm": 0.9617461562156677,
      "learning_rate": 0.0004200131906931203,
      "loss": 0.7135,
      "step": 317300
    },
    {
      "epoch": 3.3595894580274295,
      "grad_norm": 0.9765333533287048,
      "learning_rate": 0.00041997932130979226,
      "loss": 0.7241,
      "step": 317350
    },
    {
      "epoch": 3.360118779807433,
      "grad_norm": 0.8673439025878906,
      "learning_rate": 0.00041994544612343254,
      "loss": 0.7171,
      "step": 317400
    },
    {
      "epoch": 3.360648101587436,
      "grad_norm": 0.9556451439857483,
      "learning_rate": 0.00041991156513519756,
      "loss": 0.7153,
      "step": 317450
    },
    {
      "epoch": 3.3611774233674394,
      "grad_norm": 0.9728057980537415,
      "learning_rate": 0.0004198776783462441,
      "loss": 0.7234,
      "step": 317500
    },
    {
      "epoch": 3.3611774233674394,
      "eval_loss": 0.5151671171188354,
      "eval_runtime": 46.7631,
      "eval_samples_per_second": 3591.078,
      "eval_steps_per_second": 448.901,
      "step": 317500
    },
    {
      "epoch": 3.3617067451474427,
      "grad_norm": 0.8743080496788025,
      "learning_rate": 0.000419843785757729,
      "loss": 0.7342,
      "step": 317550
    },
    {
      "epoch": 3.362236066927446,
      "grad_norm": 0.9808014035224915,
      "learning_rate": 0.0004198098873708093,
      "loss": 0.7176,
      "step": 317600
    },
    {
      "epoch": 3.362765388707449,
      "grad_norm": 0.8962835669517517,
      "learning_rate": 0.00041977598318664234,
      "loss": 0.7175,
      "step": 317650
    },
    {
      "epoch": 3.3632947104874527,
      "grad_norm": 0.9823529720306396,
      "learning_rate": 0.00041974207320638564,
      "loss": 0.7341,
      "step": 317700
    },
    {
      "epoch": 3.3638240322674555,
      "grad_norm": 0.9371034502983093,
      "learning_rate": 0.00041970815743119674,
      "loss": 0.7128,
      "step": 317750
    },
    {
      "epoch": 3.364353354047459,
      "grad_norm": 0.9705384969711304,
      "learning_rate": 0.00041967423586223364,
      "loss": 0.7118,
      "step": 317800
    },
    {
      "epoch": 3.364882675827462,
      "grad_norm": 0.9772337675094604,
      "learning_rate": 0.0004196403085006543,
      "loss": 0.7281,
      "step": 317850
    },
    {
      "epoch": 3.3654119976074655,
      "grad_norm": 1.0628024339675903,
      "learning_rate": 0.000419606375347617,
      "loss": 0.7178,
      "step": 317900
    },
    {
      "epoch": 3.3659413193874688,
      "grad_norm": 1.0292996168136597,
      "learning_rate": 0.00041957243640428033,
      "loss": 0.7106,
      "step": 317950
    },
    {
      "epoch": 3.366470641167472,
      "grad_norm": 0.9483001232147217,
      "learning_rate": 0.0004195384916718029,
      "loss": 0.7098,
      "step": 318000
    },
    {
      "epoch": 3.366470641167472,
      "eval_loss": 0.5150309801101685,
      "eval_runtime": 46.742,
      "eval_samples_per_second": 3592.702,
      "eval_steps_per_second": 449.104,
      "step": 318000
    },
    {
      "epoch": 3.3669999629474754,
      "grad_norm": 0.9622309803962708,
      "learning_rate": 0.00041950454115134353,
      "loss": 0.7239,
      "step": 318050
    },
    {
      "epoch": 3.3675292847274787,
      "grad_norm": 0.9099956750869751,
      "learning_rate": 0.0004194705848440612,
      "loss": 0.718,
      "step": 318100
    },
    {
      "epoch": 3.368058606507482,
      "grad_norm": 1.0114808082580566,
      "learning_rate": 0.00041943662275111535,
      "loss": 0.7147,
      "step": 318150
    },
    {
      "epoch": 3.3685879282874853,
      "grad_norm": 0.9837051033973694,
      "learning_rate": 0.00041940265487366526,
      "loss": 0.7088,
      "step": 318200
    },
    {
      "epoch": 3.3691172500674886,
      "grad_norm": 0.971316397190094,
      "learning_rate": 0.0004193686812128707,
      "loss": 0.7338,
      "step": 318250
    },
    {
      "epoch": 3.369646571847492,
      "grad_norm": 0.9958865642547607,
      "learning_rate": 0.0004193347017698915,
      "loss": 0.7309,
      "step": 318300
    },
    {
      "epoch": 3.3701758936274953,
      "grad_norm": 1.0049545764923096,
      "learning_rate": 0.0004193007165458876,
      "loss": 0.712,
      "step": 318350
    },
    {
      "epoch": 3.370705215407498,
      "grad_norm": 0.919355571269989,
      "learning_rate": 0.0004192667255420194,
      "loss": 0.724,
      "step": 318400
    },
    {
      "epoch": 3.371234537187502,
      "grad_norm": 0.8932105898857117,
      "learning_rate": 0.0004192327287594473,
      "loss": 0.7122,
      "step": 318450
    },
    {
      "epoch": 3.3717638589675047,
      "grad_norm": 0.9750320911407471,
      "learning_rate": 0.0004191987261993318,
      "loss": 0.7059,
      "step": 318500
    },
    {
      "epoch": 3.3717638589675047,
      "eval_loss": 0.5107794404029846,
      "eval_runtime": 46.8052,
      "eval_samples_per_second": 3587.845,
      "eval_steps_per_second": 448.497,
      "step": 318500
    },
    {
      "epoch": 3.372293180747508,
      "grad_norm": 0.9769445061683655,
      "learning_rate": 0.0004191647178628339,
      "loss": 0.7101,
      "step": 318550
    },
    {
      "epoch": 3.3728225025275114,
      "grad_norm": 0.9646046161651611,
      "learning_rate": 0.00041913070375111455,
      "loss": 0.7175,
      "step": 318600
    },
    {
      "epoch": 3.3733518243075147,
      "grad_norm": 0.9520687460899353,
      "learning_rate": 0.00041909668386533506,
      "loss": 0.718,
      "step": 318650
    },
    {
      "epoch": 3.373881146087518,
      "grad_norm": 0.9335576891899109,
      "learning_rate": 0.00041906265820665665,
      "loss": 0.7235,
      "step": 318700
    },
    {
      "epoch": 3.3744104678675213,
      "grad_norm": 1.0494859218597412,
      "learning_rate": 0.00041902862677624126,
      "loss": 0.724,
      "step": 318750
    },
    {
      "epoch": 3.3749397896475246,
      "grad_norm": 0.965099573135376,
      "learning_rate": 0.0004189945895752505,
      "loss": 0.7073,
      "step": 318800
    },
    {
      "epoch": 3.375469111427528,
      "grad_norm": 1.0902178287506104,
      "learning_rate": 0.0004189605466048464,
      "loss": 0.7029,
      "step": 318850
    },
    {
      "epoch": 3.3759984332075312,
      "grad_norm": 0.9930780529975891,
      "learning_rate": 0.00041892649786619117,
      "loss": 0.7208,
      "step": 318900
    },
    {
      "epoch": 3.3765277549875345,
      "grad_norm": 0.8270454406738281,
      "learning_rate": 0.0004188924433604473,
      "loss": 0.709,
      "step": 318950
    },
    {
      "epoch": 3.377057076767538,
      "grad_norm": 0.9359197616577148,
      "learning_rate": 0.0004188583830887773,
      "loss": 0.7127,
      "step": 319000
    },
    {
      "epoch": 3.377057076767538,
      "eval_loss": 0.511583149433136,
      "eval_runtime": 46.8042,
      "eval_samples_per_second": 3587.929,
      "eval_steps_per_second": 448.507,
      "step": 319000
    },
    {
      "epoch": 3.377586398547541,
      "grad_norm": 0.9203096032142639,
      "learning_rate": 0.00041882499842955994,
      "loss": 0.7125,
      "step": 319050
    },
    {
      "epoch": 3.3781157203275445,
      "grad_norm": 0.9092836976051331,
      "learning_rate": 0.000418790926744787,
      "loss": 0.7164,
      "step": 319100
    },
    {
      "epoch": 3.378645042107548,
      "grad_norm": 1.0882560014724731,
      "learning_rate": 0.00041875684929755383,
      "loss": 0.7329,
      "step": 319150
    },
    {
      "epoch": 3.379174363887551,
      "grad_norm": 0.9624106287956238,
      "learning_rate": 0.00041872276608902366,
      "loss": 0.7111,
      "step": 319200
    },
    {
      "epoch": 3.379703685667554,
      "grad_norm": 0.9358062148094177,
      "learning_rate": 0.0004186886771203601,
      "loss": 0.7118,
      "step": 319250
    },
    {
      "epoch": 3.3802330074475573,
      "grad_norm": 0.9705027341842651,
      "learning_rate": 0.000418654582392727,
      "loss": 0.7132,
      "step": 319300
    },
    {
      "epoch": 3.3807623292275606,
      "grad_norm": 1.046195149421692,
      "learning_rate": 0.0004186204819072883,
      "loss": 0.7071,
      "step": 319350
    },
    {
      "epoch": 3.381291651007564,
      "grad_norm": 1.0376691818237305,
      "learning_rate": 0.00041858637566520823,
      "loss": 0.7297,
      "step": 319400
    },
    {
      "epoch": 3.381820972787567,
      "grad_norm": 0.9169524312019348,
      "learning_rate": 0.00041855226366765107,
      "loss": 0.7188,
      "step": 319450
    },
    {
      "epoch": 3.3823502945675705,
      "grad_norm": 0.8682363033294678,
      "learning_rate": 0.0004185181459157815,
      "loss": 0.7116,
      "step": 319500
    },
    {
      "epoch": 3.3823502945675705,
      "eval_loss": 0.512670636177063,
      "eval_runtime": 46.9642,
      "eval_samples_per_second": 3575.703,
      "eval_steps_per_second": 446.979,
      "step": 319500
    },
    {
      "epoch": 3.382879616347574,
      "grad_norm": 0.984657883644104,
      "learning_rate": 0.00041848402241076416,
      "loss": 0.7186,
      "step": 319550
    },
    {
      "epoch": 3.383408938127577,
      "grad_norm": 0.956153929233551,
      "learning_rate": 0.00041844989315376415,
      "loss": 0.7107,
      "step": 319600
    },
    {
      "epoch": 3.3839382599075805,
      "grad_norm": 0.9095197319984436,
      "learning_rate": 0.00041841575814594647,
      "loss": 0.7224,
      "step": 319650
    },
    {
      "epoch": 3.3844675816875838,
      "grad_norm": 0.9260299801826477,
      "learning_rate": 0.00041838161738847666,
      "loss": 0.7095,
      "step": 319700
    },
    {
      "epoch": 3.384996903467587,
      "grad_norm": 1.035151481628418,
      "learning_rate": 0.00041834747088252016,
      "loss": 0.713,
      "step": 319750
    },
    {
      "epoch": 3.3855262252475904,
      "grad_norm": 0.9433609843254089,
      "learning_rate": 0.0004183133186292427,
      "loss": 0.7155,
      "step": 319800
    },
    {
      "epoch": 3.3860555470275937,
      "grad_norm": 0.9231280088424683,
      "learning_rate": 0.00041827916062981037,
      "loss": 0.7179,
      "step": 319850
    },
    {
      "epoch": 3.386584868807597,
      "grad_norm": 0.9453256726264954,
      "learning_rate": 0.00041824499688538914,
      "loss": 0.7167,
      "step": 319900
    },
    {
      "epoch": 3.3871141905876003,
      "grad_norm": 1.0275810956954956,
      "learning_rate": 0.00041821082739714545,
      "loss": 0.728,
      "step": 319950
    },
    {
      "epoch": 3.387643512367603,
      "grad_norm": 1.0125586986541748,
      "learning_rate": 0.0004181766521662458,
      "loss": 0.7045,
      "step": 320000
    },
    {
      "epoch": 3.387643512367603,
      "eval_loss": 0.5125501751899719,
      "eval_runtime": 46.8689,
      "eval_samples_per_second": 3582.971,
      "eval_steps_per_second": 447.887,
      "step": 320000
    },
    {
      "epoch": 3.3881728341476065,
      "grad_norm": 0.9639265537261963,
      "learning_rate": 0.00041814247119385686,
      "loss": 0.7137,
      "step": 320050
    },
    {
      "epoch": 3.38870215592761,
      "grad_norm": 0.968937873840332,
      "learning_rate": 0.00041810828448114555,
      "loss": 0.7122,
      "step": 320100
    },
    {
      "epoch": 3.389231477707613,
      "grad_norm": 0.9428993463516235,
      "learning_rate": 0.00041807409202927927,
      "loss": 0.7109,
      "step": 320150
    },
    {
      "epoch": 3.3897607994876164,
      "grad_norm": 1.0291788578033447,
      "learning_rate": 0.000418039893839425,
      "loss": 0.721,
      "step": 320200
    },
    {
      "epoch": 3.3902901212676197,
      "grad_norm": 0.9801315665245056,
      "learning_rate": 0.0004180056899127504,
      "loss": 0.702,
      "step": 320250
    },
    {
      "epoch": 3.390819443047623,
      "grad_norm": 0.9586601853370667,
      "learning_rate": 0.0004179714802504232,
      "loss": 0.7049,
      "step": 320300
    },
    {
      "epoch": 3.3913487648276264,
      "grad_norm": 0.9566434025764465,
      "learning_rate": 0.0004179372648536112,
      "loss": 0.7123,
      "step": 320350
    },
    {
      "epoch": 3.3918780866076297,
      "grad_norm": 0.9795584678649902,
      "learning_rate": 0.00041790304372348264,
      "loss": 0.7147,
      "step": 320400
    },
    {
      "epoch": 3.392407408387633,
      "grad_norm": 0.8700980544090271,
      "learning_rate": 0.0004178688168612057,
      "loss": 0.7324,
      "step": 320450
    },
    {
      "epoch": 3.3929367301676363,
      "grad_norm": 0.9592916965484619,
      "learning_rate": 0.000417834584267949,
      "loss": 0.7217,
      "step": 320500
    },
    {
      "epoch": 3.3929367301676363,
      "eval_loss": 0.5128105878829956,
      "eval_runtime": 46.884,
      "eval_samples_per_second": 3581.818,
      "eval_steps_per_second": 447.743,
      "step": 320500
    },
    {
      "epoch": 3.3934660519476396,
      "grad_norm": 0.9414165019989014,
      "learning_rate": 0.000417800345944881,
      "loss": 0.7114,
      "step": 320550
    },
    {
      "epoch": 3.393995373727643,
      "grad_norm": 0.9578151106834412,
      "learning_rate": 0.0004177661018931708,
      "loss": 0.7151,
      "step": 320600
    },
    {
      "epoch": 3.3945246955076462,
      "grad_norm": 0.9876692891120911,
      "learning_rate": 0.00041773185211398735,
      "loss": 0.7198,
      "step": 320650
    },
    {
      "epoch": 3.3950540172876496,
      "grad_norm": 1.10277259349823,
      "learning_rate": 0.00041769759660850004,
      "loss": 0.7173,
      "step": 320700
    },
    {
      "epoch": 3.3955833390676524,
      "grad_norm": 0.8947835564613342,
      "learning_rate": 0.00041766333537787833,
      "loss": 0.7117,
      "step": 320750
    },
    {
      "epoch": 3.3961126608476557,
      "grad_norm": 0.8713092803955078,
      "learning_rate": 0.0004176290684232918,
      "loss": 0.7045,
      "step": 320800
    },
    {
      "epoch": 3.396641982627659,
      "grad_norm": 0.9962227940559387,
      "learning_rate": 0.0004175947957459103,
      "loss": 0.7237,
      "step": 320850
    },
    {
      "epoch": 3.3971713044076624,
      "grad_norm": 0.8392430543899536,
      "learning_rate": 0.000417560517346904,
      "loss": 0.7219,
      "step": 320900
    },
    {
      "epoch": 3.3977006261876657,
      "grad_norm": 0.9740119576454163,
      "learning_rate": 0.00041752623322744304,
      "loss": 0.7216,
      "step": 320950
    },
    {
      "epoch": 3.398229947967669,
      "grad_norm": 1.0247529745101929,
      "learning_rate": 0.0004174919433886979,
      "loss": 0.7282,
      "step": 321000
    },
    {
      "epoch": 3.398229947967669,
      "eval_loss": 0.5116965770721436,
      "eval_runtime": 46.8124,
      "eval_samples_per_second": 3587.3,
      "eval_steps_per_second": 448.429,
      "step": 321000
    },
    {
      "epoch": 3.3987592697476723,
      "grad_norm": 0.9992267489433289,
      "learning_rate": 0.00041745833379900645,
      "loss": 0.717,
      "step": 321050
    },
    {
      "epoch": 3.3992885915276756,
      "grad_norm": 0.9335172772407532,
      "learning_rate": 0.0004174240326395325,
      "loss": 0.7035,
      "step": 321100
    },
    {
      "epoch": 3.399817913307679,
      "grad_norm": 0.9319167733192444,
      "learning_rate": 0.0004173897257642635,
      "loss": 0.7218,
      "step": 321150
    },
    {
      "epoch": 3.400347235087682,
      "grad_norm": 1.051636815071106,
      "learning_rate": 0.0004173554131743707,
      "loss": 0.7188,
      "step": 321200
    },
    {
      "epoch": 3.4008765568676855,
      "grad_norm": 1.0040700435638428,
      "learning_rate": 0.00041732109487102544,
      "loss": 0.7195,
      "step": 321250
    },
    {
      "epoch": 3.401405878647689,
      "grad_norm": 0.9571557641029358,
      "learning_rate": 0.00041728677085539937,
      "loss": 0.7282,
      "step": 321300
    },
    {
      "epoch": 3.401935200427692,
      "grad_norm": 1.025132179260254,
      "learning_rate": 0.0004172524411286642,
      "loss": 0.7148,
      "step": 321350
    },
    {
      "epoch": 3.4024645222076955,
      "grad_norm": 1.0516257286071777,
      "learning_rate": 0.0004172181056919921,
      "loss": 0.7279,
      "step": 321400
    },
    {
      "epoch": 3.4029938439876988,
      "grad_norm": 0.9787774682044983,
      "learning_rate": 0.0004171837645465552,
      "loss": 0.7045,
      "step": 321450
    },
    {
      "epoch": 3.4035231657677016,
      "grad_norm": 0.910284161567688,
      "learning_rate": 0.0004171494176935259,
      "loss": 0.7117,
      "step": 321500
    },
    {
      "epoch": 3.4035231657677016,
      "eval_loss": 0.5082271099090576,
      "eval_runtime": 46.8191,
      "eval_samples_per_second": 3586.781,
      "eval_steps_per_second": 448.364,
      "step": 321500
    },
    {
      "epoch": 3.404052487547705,
      "grad_norm": 1.0097941160202026,
      "learning_rate": 0.00041711506513407676,
      "loss": 0.705,
      "step": 321550
    },
    {
      "epoch": 3.4045818093277083,
      "grad_norm": 0.8218786716461182,
      "learning_rate": 0.0004170807068693806,
      "loss": 0.7352,
      "step": 321600
    },
    {
      "epoch": 3.4051111311077116,
      "grad_norm": 0.9229090213775635,
      "learning_rate": 0.0004170463429006104,
      "loss": 0.7143,
      "step": 321650
    },
    {
      "epoch": 3.405640452887715,
      "grad_norm": 0.7754417657852173,
      "learning_rate": 0.00041701197322893923,
      "loss": 0.7127,
      "step": 321700
    },
    {
      "epoch": 3.406169774667718,
      "grad_norm": 0.7799376249313354,
      "learning_rate": 0.0004169775978555407,
      "loss": 0.7166,
      "step": 321750
    },
    {
      "epoch": 3.4066990964477215,
      "grad_norm": 0.8681058287620544,
      "learning_rate": 0.0004169432167815881,
      "loss": 0.7067,
      "step": 321800
    },
    {
      "epoch": 3.407228418227725,
      "grad_norm": 0.891131579875946,
      "learning_rate": 0.0004169088300082553,
      "loss": 0.719,
      "step": 321850
    },
    {
      "epoch": 3.407757740007728,
      "grad_norm": 1.0786868333816528,
      "learning_rate": 0.0004168744375367163,
      "loss": 0.7111,
      "step": 321900
    },
    {
      "epoch": 3.4082870617877314,
      "grad_norm": 0.9752739667892456,
      "learning_rate": 0.00041684003936814516,
      "loss": 0.7129,
      "step": 321950
    },
    {
      "epoch": 3.4088163835677348,
      "grad_norm": 1.0385445356369019,
      "learning_rate": 0.0004168056355037163,
      "loss": 0.7136,
      "step": 322000
    },
    {
      "epoch": 3.4088163835677348,
      "eval_loss": 0.5095351338386536,
      "eval_runtime": 46.8643,
      "eval_samples_per_second": 3583.322,
      "eval_steps_per_second": 447.931,
      "step": 322000
    },
    {
      "epoch": 3.409345705347738,
      "grad_norm": 0.8736769556999207,
      "learning_rate": 0.00041677122594460414,
      "loss": 0.7177,
      "step": 322050
    },
    {
      "epoch": 3.4098750271277414,
      "grad_norm": 0.9209269881248474,
      "learning_rate": 0.0004167368106919836,
      "loss": 0.7049,
      "step": 322100
    },
    {
      "epoch": 3.4104043489077447,
      "grad_norm": 0.9545857906341553,
      "learning_rate": 0.00041670238974702943,
      "loss": 0.7107,
      "step": 322150
    },
    {
      "epoch": 3.410933670687748,
      "grad_norm": 0.933323860168457,
      "learning_rate": 0.0004166679631109168,
      "loss": 0.7061,
      "step": 322200
    },
    {
      "epoch": 3.411462992467751,
      "grad_norm": 0.9868251085281372,
      "learning_rate": 0.00041663353078482106,
      "loss": 0.7158,
      "step": 322250
    },
    {
      "epoch": 3.411992314247754,
      "grad_norm": 1.0000461339950562,
      "learning_rate": 0.0004165990927699177,
      "loss": 0.7204,
      "step": 322300
    },
    {
      "epoch": 3.4125216360277575,
      "grad_norm": 1.0281429290771484,
      "learning_rate": 0.0004165646490673824,
      "loss": 0.7162,
      "step": 322350
    },
    {
      "epoch": 3.413050957807761,
      "grad_norm": 0.9751673936843872,
      "learning_rate": 0.0004165301996783911,
      "loss": 0.7156,
      "step": 322400
    },
    {
      "epoch": 3.413580279587764,
      "grad_norm": 1.0535863637924194,
      "learning_rate": 0.00041649574460411975,
      "loss": 0.7164,
      "step": 322450
    },
    {
      "epoch": 3.4141096013677674,
      "grad_norm": 0.9211673140525818,
      "learning_rate": 0.0004164612838457449,
      "loss": 0.7187,
      "step": 322500
    },
    {
      "epoch": 3.4141096013677674,
      "eval_loss": 0.508283793926239,
      "eval_runtime": 46.86,
      "eval_samples_per_second": 3583.657,
      "eval_steps_per_second": 447.973,
      "step": 322500
    },
    {
      "epoch": 3.4146389231477707,
      "grad_norm": 0.9459112286567688,
      "learning_rate": 0.0004164268174044427,
      "loss": 0.7322,
      "step": 322550
    },
    {
      "epoch": 3.415168244927774,
      "grad_norm": 0.8504959344863892,
      "learning_rate": 0.0004163923452813901,
      "loss": 0.7205,
      "step": 322600
    },
    {
      "epoch": 3.4156975667077774,
      "grad_norm": 0.9718212485313416,
      "learning_rate": 0.00041635786747776384,
      "loss": 0.7106,
      "step": 322650
    },
    {
      "epoch": 3.4162268884877807,
      "grad_norm": 0.9779083728790283,
      "learning_rate": 0.0004163233839947409,
      "loss": 0.7246,
      "step": 322700
    },
    {
      "epoch": 3.416756210267784,
      "grad_norm": 0.9668115377426147,
      "learning_rate": 0.00041628889483349876,
      "loss": 0.7129,
      "step": 322750
    },
    {
      "epoch": 3.4172855320477873,
      "grad_norm": 1.0442644357681274,
      "learning_rate": 0.00041625439999521465,
      "loss": 0.7172,
      "step": 322800
    },
    {
      "epoch": 3.4178148538277906,
      "grad_norm": 0.900299072265625,
      "learning_rate": 0.0004162198994810663,
      "loss": 0.7132,
      "step": 322850
    },
    {
      "epoch": 3.418344175607794,
      "grad_norm": 0.9072404503822327,
      "learning_rate": 0.0004161853932922316,
      "loss": 0.7152,
      "step": 322900
    },
    {
      "epoch": 3.4188734973877972,
      "grad_norm": 0.9405292868614197,
      "learning_rate": 0.0004161508814298885,
      "loss": 0.6971,
      "step": 322950
    },
    {
      "epoch": 3.4194028191678,
      "grad_norm": 0.9258462190628052,
      "learning_rate": 0.00041611636389521524,
      "loss": 0.6975,
      "step": 323000
    },
    {
      "epoch": 3.4194028191678,
      "eval_loss": 0.5103893876075745,
      "eval_runtime": 46.7969,
      "eval_samples_per_second": 3588.484,
      "eval_steps_per_second": 448.577,
      "step": 323000
    },
    {
      "epoch": 3.4199321409478034,
      "grad_norm": 0.8957543969154358,
      "learning_rate": 0.0004160818406893902,
      "loss": 0.7221,
      "step": 323050
    },
    {
      "epoch": 3.4204614627278067,
      "grad_norm": 0.9237138628959656,
      "learning_rate": 0.0004160480024466661,
      "loss": 0.7198,
      "step": 323100
    },
    {
      "epoch": 3.42099078450781,
      "grad_norm": 0.932619035243988,
      "learning_rate": 0.000416013468015438,
      "loss": 0.7135,
      "step": 323150
    },
    {
      "epoch": 3.4215201062878133,
      "grad_norm": 0.9475842714309692,
      "learning_rate": 0.00041597892791657095,
      "loss": 0.7133,
      "step": 323200
    },
    {
      "epoch": 3.4220494280678166,
      "grad_norm": 0.9269946813583374,
      "learning_rate": 0.0004159443821512442,
      "loss": 0.7125,
      "step": 323250
    },
    {
      "epoch": 3.42257874984782,
      "grad_norm": 1.0992223024368286,
      "learning_rate": 0.00041590983072063703,
      "loss": 0.7246,
      "step": 323300
    },
    {
      "epoch": 3.4231080716278233,
      "grad_norm": 1.019563913345337,
      "learning_rate": 0.00041587527362592916,
      "loss": 0.7085,
      "step": 323350
    },
    {
      "epoch": 3.4236373934078266,
      "grad_norm": 0.9342892169952393,
      "learning_rate": 0.0004158407108683002,
      "loss": 0.7169,
      "step": 323400
    },
    {
      "epoch": 3.42416671518783,
      "grad_norm": 1.0940494537353516,
      "learning_rate": 0.0004158061424489302,
      "loss": 0.7108,
      "step": 323450
    },
    {
      "epoch": 3.424696036967833,
      "grad_norm": 0.9638688564300537,
      "learning_rate": 0.0004157715683689994,
      "loss": 0.7248,
      "step": 323500
    },
    {
      "epoch": 3.424696036967833,
      "eval_loss": 0.5099232792854309,
      "eval_runtime": 46.8459,
      "eval_samples_per_second": 3584.732,
      "eval_steps_per_second": 448.107,
      "step": 323500
    },
    {
      "epoch": 3.4252253587478365,
      "grad_norm": 0.8965621590614319,
      "learning_rate": 0.0004157369886296879,
      "loss": 0.7094,
      "step": 323550
    },
    {
      "epoch": 3.42575468052784,
      "grad_norm": 0.858995258808136,
      "learning_rate": 0.00041570240323217654,
      "loss": 0.7156,
      "step": 323600
    },
    {
      "epoch": 3.426284002307843,
      "grad_norm": 0.9251387119293213,
      "learning_rate": 0.0004156678121776458,
      "loss": 0.7202,
      "step": 323650
    },
    {
      "epoch": 3.4268133240878464,
      "grad_norm": 0.9891311526298523,
      "learning_rate": 0.00041563321546727683,
      "loss": 0.7251,
      "step": 323700
    },
    {
      "epoch": 3.4273426458678493,
      "grad_norm": 1.0154246091842651,
      "learning_rate": 0.00041559861310225054,
      "loss": 0.7148,
      "step": 323750
    },
    {
      "epoch": 3.4278719676478526,
      "grad_norm": 1.0224264860153198,
      "learning_rate": 0.00041556400508374836,
      "loss": 0.7042,
      "step": 323800
    },
    {
      "epoch": 3.428401289427856,
      "grad_norm": 0.9831735491752625,
      "learning_rate": 0.00041552939141295173,
      "loss": 0.7201,
      "step": 323850
    },
    {
      "epoch": 3.4289306112078592,
      "grad_norm": 0.9971405863761902,
      "learning_rate": 0.00041549477209104234,
      "loss": 0.7227,
      "step": 323900
    },
    {
      "epoch": 3.4294599329878626,
      "grad_norm": 1.049781084060669,
      "learning_rate": 0.0004154601471192022,
      "loss": 0.7103,
      "step": 323950
    },
    {
      "epoch": 3.429989254767866,
      "grad_norm": 1.0401266813278198,
      "learning_rate": 0.00041542551649861333,
      "loss": 0.7159,
      "step": 324000
    },
    {
      "epoch": 3.429989254767866,
      "eval_loss": 0.5098657011985779,
      "eval_runtime": 46.864,
      "eval_samples_per_second": 3583.346,
      "eval_steps_per_second": 447.934,
      "step": 324000
    },
    {
      "epoch": 3.430518576547869,
      "grad_norm": 0.8855518102645874,
      "learning_rate": 0.00041539088023045793,
      "loss": 0.7058,
      "step": 324050
    },
    {
      "epoch": 3.4310478983278725,
      "grad_norm": 0.9544139504432678,
      "learning_rate": 0.0004153562383159186,
      "loss": 0.722,
      "step": 324100
    },
    {
      "epoch": 3.431577220107876,
      "grad_norm": 0.8727010488510132,
      "learning_rate": 0.00041532159075617793,
      "loss": 0.7225,
      "step": 324150
    },
    {
      "epoch": 3.432106541887879,
      "grad_norm": 0.9613394141197205,
      "learning_rate": 0.00041528693755241874,
      "loss": 0.7169,
      "step": 324200
    },
    {
      "epoch": 3.4326358636678824,
      "grad_norm": 0.9599478244781494,
      "learning_rate": 0.00041525227870582417,
      "loss": 0.7062,
      "step": 324250
    },
    {
      "epoch": 3.4331651854478857,
      "grad_norm": 0.901977002620697,
      "learning_rate": 0.0004152176142175773,
      "loss": 0.7112,
      "step": 324300
    },
    {
      "epoch": 3.433694507227889,
      "grad_norm": 0.9213940501213074,
      "learning_rate": 0.0004151829440888618,
      "loss": 0.7162,
      "step": 324350
    },
    {
      "epoch": 3.4342238290078924,
      "grad_norm": 0.9640233516693115,
      "learning_rate": 0.0004151482683208611,
      "loss": 0.7104,
      "step": 324400
    },
    {
      "epoch": 3.4347531507878957,
      "grad_norm": 0.9160540699958801,
      "learning_rate": 0.0004151135869147591,
      "loss": 0.7156,
      "step": 324450
    },
    {
      "epoch": 3.4352824725678985,
      "grad_norm": 0.9489981532096863,
      "learning_rate": 0.0004150788998717399,
      "loss": 0.7221,
      "step": 324500
    },
    {
      "epoch": 3.4352824725678985,
      "eval_loss": 0.5096434354782104,
      "eval_runtime": 46.8268,
      "eval_samples_per_second": 3586.194,
      "eval_steps_per_second": 448.29,
      "step": 324500
    },
    {
      "epoch": 3.435811794347902,
      "grad_norm": 0.977185845375061,
      "learning_rate": 0.0004150442071929874,
      "loss": 0.7059,
      "step": 324550
    },
    {
      "epoch": 3.436341116127905,
      "grad_norm": 0.939226508140564,
      "learning_rate": 0.0004150095088796863,
      "loss": 0.7164,
      "step": 324600
    },
    {
      "epoch": 3.4368704379079085,
      "grad_norm": 1.0891005992889404,
      "learning_rate": 0.0004149748049330211,
      "loss": 0.7241,
      "step": 324650
    },
    {
      "epoch": 3.437399759687912,
      "grad_norm": 0.9995923638343811,
      "learning_rate": 0.0004149400953541765,
      "loss": 0.6984,
      "step": 324700
    },
    {
      "epoch": 3.437929081467915,
      "grad_norm": 0.9649218320846558,
      "learning_rate": 0.0004149053801443376,
      "loss": 0.7149,
      "step": 324750
    },
    {
      "epoch": 3.4384584032479184,
      "grad_norm": 0.9348332285881042,
      "learning_rate": 0.0004148706593046895,
      "loss": 0.7137,
      "step": 324800
    },
    {
      "epoch": 3.4389877250279217,
      "grad_norm": 0.9405090808868408,
      "learning_rate": 0.0004148359328364175,
      "loss": 0.7275,
      "step": 324850
    },
    {
      "epoch": 3.439517046807925,
      "grad_norm": 0.973814845085144,
      "learning_rate": 0.0004148012007407073,
      "loss": 0.719,
      "step": 324900
    },
    {
      "epoch": 3.4400463685879283,
      "grad_norm": 0.9233503937721252,
      "learning_rate": 0.00041476646301874445,
      "loss": 0.7197,
      "step": 324950
    },
    {
      "epoch": 3.4405756903679316,
      "grad_norm": 0.9681870937347412,
      "learning_rate": 0.00041473171967171496,
      "loss": 0.713,
      "step": 325000
    },
    {
      "epoch": 3.4405756903679316,
      "eval_loss": 0.5070772767066956,
      "eval_runtime": 46.7962,
      "eval_samples_per_second": 3588.541,
      "eval_steps_per_second": 448.584,
      "step": 325000
    },
    {
      "epoch": 3.441105012147935,
      "grad_norm": 0.9468470811843872,
      "learning_rate": 0.00041469697070080504,
      "loss": 0.7162,
      "step": 325050
    },
    {
      "epoch": 3.4416343339279383,
      "grad_norm": 0.9577397704124451,
      "learning_rate": 0.0004146622161072009,
      "loss": 0.7161,
      "step": 325100
    },
    {
      "epoch": 3.4421636557079416,
      "grad_norm": 0.9819237589836121,
      "learning_rate": 0.00041462745589208915,
      "loss": 0.7122,
      "step": 325150
    },
    {
      "epoch": 3.442692977487945,
      "grad_norm": 0.9253073334693909,
      "learning_rate": 0.0004145926900566563,
      "loss": 0.7089,
      "step": 325200
    },
    {
      "epoch": 3.4432222992679478,
      "grad_norm": 0.9278784394264221,
      "learning_rate": 0.00041455861408624066,
      "loss": 0.7176,
      "step": 325250
    },
    {
      "epoch": 3.443751621047951,
      "grad_norm": 1.0042126178741455,
      "learning_rate": 0.00041452383712607416,
      "loss": 0.7185,
      "step": 325300
    },
    {
      "epoch": 3.4442809428279544,
      "grad_norm": 0.9153934717178345,
      "learning_rate": 0.0004144890545491242,
      "loss": 0.7205,
      "step": 325350
    },
    {
      "epoch": 3.4448102646079577,
      "grad_norm": 1.0533032417297363,
      "learning_rate": 0.00041445426635657826,
      "loss": 0.7162,
      "step": 325400
    },
    {
      "epoch": 3.445339586387961,
      "grad_norm": 0.9658476114273071,
      "learning_rate": 0.0004144194725496239,
      "loss": 0.7201,
      "step": 325450
    },
    {
      "epoch": 3.4458689081679643,
      "grad_norm": 0.9574259519577026,
      "learning_rate": 0.0004143846731294491,
      "loss": 0.7045,
      "step": 325500
    },
    {
      "epoch": 3.4458689081679643,
      "eval_loss": 0.5087159872055054,
      "eval_runtime": 46.8033,
      "eval_samples_per_second": 3587.993,
      "eval_steps_per_second": 448.515,
      "step": 325500
    },
    {
      "epoch": 3.4463982299479676,
      "grad_norm": 0.9068149328231812,
      "learning_rate": 0.0004143498680972418,
      "loss": 0.7114,
      "step": 325550
    },
    {
      "epoch": 3.446927551727971,
      "grad_norm": 0.907500684261322,
      "learning_rate": 0.00041431505745419034,
      "loss": 0.709,
      "step": 325600
    },
    {
      "epoch": 3.4474568735079743,
      "grad_norm": 0.855753481388092,
      "learning_rate": 0.00041428024120148305,
      "loss": 0.7087,
      "step": 325650
    },
    {
      "epoch": 3.4479861952879776,
      "grad_norm": 0.9626292586326599,
      "learning_rate": 0.00041424541934030856,
      "loss": 0.7142,
      "step": 325700
    },
    {
      "epoch": 3.448515517067981,
      "grad_norm": 0.9006786942481995,
      "learning_rate": 0.0004142105918718557,
      "loss": 0.7029,
      "step": 325750
    },
    {
      "epoch": 3.449044838847984,
      "grad_norm": 1.1013633012771606,
      "learning_rate": 0.00041417575879731353,
      "loss": 0.7177,
      "step": 325800
    },
    {
      "epoch": 3.4495741606279875,
      "grad_norm": 0.991320788860321,
      "learning_rate": 0.00041414092011787107,
      "loss": 0.7185,
      "step": 325850
    },
    {
      "epoch": 3.450103482407991,
      "grad_norm": 1.0229166746139526,
      "learning_rate": 0.0004141060758347178,
      "loss": 0.71,
      "step": 325900
    },
    {
      "epoch": 3.450632804187994,
      "grad_norm": 0.9402223825454712,
      "learning_rate": 0.00041407122594904334,
      "loss": 0.7175,
      "step": 325950
    },
    {
      "epoch": 3.451162125967997,
      "grad_norm": 1.0262950658798218,
      "learning_rate": 0.00041403637046203735,
      "loss": 0.7084,
      "step": 326000
    },
    {
      "epoch": 3.451162125967997,
      "eval_loss": 0.5072762966156006,
      "eval_runtime": 46.7192,
      "eval_samples_per_second": 3594.455,
      "eval_steps_per_second": 449.323,
      "step": 326000
    },
    {
      "epoch": 3.4516914477480003,
      "grad_norm": 0.9952334761619568,
      "learning_rate": 0.0004140015093748898,
      "loss": 0.7278,
      "step": 326050
    },
    {
      "epoch": 3.4522207695280036,
      "grad_norm": 0.8747804760932922,
      "learning_rate": 0.0004139666426887909,
      "loss": 0.7131,
      "step": 326100
    },
    {
      "epoch": 3.452750091308007,
      "grad_norm": 0.9969602227210999,
      "learning_rate": 0.00041393177040493096,
      "loss": 0.7271,
      "step": 326150
    },
    {
      "epoch": 3.4532794130880102,
      "grad_norm": 0.8971933722496033,
      "learning_rate": 0.00041389689252450046,
      "loss": 0.7065,
      "step": 326200
    },
    {
      "epoch": 3.4538087348680135,
      "grad_norm": 1.075291633605957,
      "learning_rate": 0.0004138620090486902,
      "loss": 0.7081,
      "step": 326250
    },
    {
      "epoch": 3.454338056648017,
      "grad_norm": 1.042529821395874,
      "learning_rate": 0.00041382711997869107,
      "loss": 0.7102,
      "step": 326300
    },
    {
      "epoch": 3.45486737842802,
      "grad_norm": 1.0259101390838623,
      "learning_rate": 0.0004137922253156942,
      "loss": 0.7212,
      "step": 326350
    },
    {
      "epoch": 3.4553967002080235,
      "grad_norm": 0.8192424774169922,
      "learning_rate": 0.0004137573250608907,
      "loss": 0.7086,
      "step": 326400
    },
    {
      "epoch": 3.455926021988027,
      "grad_norm": 0.957646906375885,
      "learning_rate": 0.0004137224192154722,
      "loss": 0.7084,
      "step": 326450
    },
    {
      "epoch": 3.45645534376803,
      "grad_norm": 1.0137054920196533,
      "learning_rate": 0.00041368750778063035,
      "loss": 0.7102,
      "step": 326500
    },
    {
      "epoch": 3.45645534376803,
      "eval_loss": 0.5100081562995911,
      "eval_runtime": 46.8302,
      "eval_samples_per_second": 3585.931,
      "eval_steps_per_second": 448.257,
      "step": 326500
    },
    {
      "epoch": 3.4569846655480334,
      "grad_norm": 1.0216578245162964,
      "learning_rate": 0.000413652590757557,
      "loss": 0.7118,
      "step": 326550
    },
    {
      "epoch": 3.4575139873280367,
      "grad_norm": 0.9803423881530762,
      "learning_rate": 0.0004136176681474443,
      "loss": 0.7128,
      "step": 326600
    },
    {
      "epoch": 3.45804330910804,
      "grad_norm": 0.9852507710456848,
      "learning_rate": 0.0004135827399514844,
      "loss": 0.7093,
      "step": 326650
    },
    {
      "epoch": 3.4585726308880433,
      "grad_norm": 0.9285988211631775,
      "learning_rate": 0.00041354780617086976,
      "loss": 0.7118,
      "step": 326700
    },
    {
      "epoch": 3.459101952668046,
      "grad_norm": 0.9178280830383301,
      "learning_rate": 0.0004135128668067929,
      "loss": 0.7022,
      "step": 326750
    },
    {
      "epoch": 3.4596312744480495,
      "grad_norm": 1.0409015417099,
      "learning_rate": 0.0004134779218604468,
      "loss": 0.7091,
      "step": 326800
    },
    {
      "epoch": 3.460160596228053,
      "grad_norm": 0.8763709664344788,
      "learning_rate": 0.0004134429713330244,
      "loss": 0.7029,
      "step": 326850
    },
    {
      "epoch": 3.460689918008056,
      "grad_norm": 0.8133777976036072,
      "learning_rate": 0.00041340801522571883,
      "loss": 0.7247,
      "step": 326900
    },
    {
      "epoch": 3.4612192397880595,
      "grad_norm": 0.9532113671302795,
      "learning_rate": 0.0004133730535397236,
      "loss": 0.7045,
      "step": 326950
    },
    {
      "epoch": 3.4617485615680628,
      "grad_norm": 0.9594437479972839,
      "learning_rate": 0.0004133380862762323,
      "loss": 0.7256,
      "step": 327000
    },
    {
      "epoch": 3.4617485615680628,
      "eval_loss": 0.5081207752227783,
      "eval_runtime": 46.7872,
      "eval_samples_per_second": 3589.23,
      "eval_steps_per_second": 448.67,
      "step": 327000
    },
    {
      "epoch": 3.462277883348066,
      "grad_norm": 0.915205180644989,
      "learning_rate": 0.0004133031134364386,
      "loss": 0.7178,
      "step": 327050
    },
    {
      "epoch": 3.4628072051280694,
      "grad_norm": 1.0432968139648438,
      "learning_rate": 0.0004132681350215365,
      "loss": 0.7201,
      "step": 327100
    },
    {
      "epoch": 3.4633365269080727,
      "grad_norm": 0.9872460961341858,
      "learning_rate": 0.00041323315103272007,
      "loss": 0.6974,
      "step": 327150
    },
    {
      "epoch": 3.463865848688076,
      "grad_norm": 0.9281828999519348,
      "learning_rate": 0.00041319816147118385,
      "loss": 0.7111,
      "step": 327200
    },
    {
      "epoch": 3.4643951704680793,
      "grad_norm": 1.1075760126113892,
      "learning_rate": 0.0004131631663381222,
      "loss": 0.703,
      "step": 327250
    },
    {
      "epoch": 3.4649244922480826,
      "grad_norm": 1.0317530632019043,
      "learning_rate": 0.00041312886570337923,
      "loss": 0.717,
      "step": 327300
    },
    {
      "epoch": 3.465453814028086,
      "grad_norm": 1.062583088874817,
      "learning_rate": 0.00041309385954222213,
      "loss": 0.7093,
      "step": 327350
    },
    {
      "epoch": 3.4659831358080893,
      "grad_norm": 0.8992260098457336,
      "learning_rate": 0.00041305884781310054,
      "loss": 0.7142,
      "step": 327400
    },
    {
      "epoch": 3.4665124575880926,
      "grad_norm": 1.0252649784088135,
      "learning_rate": 0.0004130238305172096,
      "loss": 0.7157,
      "step": 327450
    },
    {
      "epoch": 3.4670417793680954,
      "grad_norm": 1.07047700881958,
      "learning_rate": 0.000412988807655745,
      "loss": 0.7118,
      "step": 327500
    },
    {
      "epoch": 3.4670417793680954,
      "eval_loss": 0.5073660612106323,
      "eval_runtime": 46.839,
      "eval_samples_per_second": 3585.257,
      "eval_steps_per_second": 448.173,
      "step": 327500
    },
    {
      "epoch": 3.467571101148099,
      "grad_norm": 1.0064833164215088,
      "learning_rate": 0.0004129537792299022,
      "loss": 0.7143,
      "step": 327550
    },
    {
      "epoch": 3.468100422928102,
      "grad_norm": 0.9817867279052734,
      "learning_rate": 0.0004129187452408771,
      "loss": 0.7167,
      "step": 327600
    },
    {
      "epoch": 3.4686297447081054,
      "grad_norm": 0.8736435174942017,
      "learning_rate": 0.0004128837056898659,
      "loss": 0.7116,
      "step": 327650
    },
    {
      "epoch": 3.4691590664881087,
      "grad_norm": 0.8098787069320679,
      "learning_rate": 0.00041284866057806464,
      "loss": 0.7071,
      "step": 327700
    },
    {
      "epoch": 3.469688388268112,
      "grad_norm": 0.9316630959510803,
      "learning_rate": 0.0004128136099066698,
      "loss": 0.6985,
      "step": 327750
    },
    {
      "epoch": 3.4702177100481153,
      "grad_norm": 0.8820828199386597,
      "learning_rate": 0.0004127785536768781,
      "loss": 0.7108,
      "step": 327800
    },
    {
      "epoch": 3.4707470318281186,
      "grad_norm": 0.8897829651832581,
      "learning_rate": 0.0004127434918898863,
      "loss": 0.71,
      "step": 327850
    },
    {
      "epoch": 3.471276353608122,
      "grad_norm": 1.0074050426483154,
      "learning_rate": 0.00041270842454689126,
      "loss": 0.71,
      "step": 327900
    },
    {
      "epoch": 3.4718056753881252,
      "grad_norm": 0.8711686730384827,
      "learning_rate": 0.0004126733516490904,
      "loss": 0.7168,
      "step": 327950
    },
    {
      "epoch": 3.4723349971681285,
      "grad_norm": 0.9881365299224854,
      "learning_rate": 0.0004126382731976809,
      "loss": 0.7102,
      "step": 328000
    },
    {
      "epoch": 3.4723349971681285,
      "eval_loss": 0.5054231882095337,
      "eval_runtime": 46.876,
      "eval_samples_per_second": 3582.431,
      "eval_steps_per_second": 447.82,
      "step": 328000
    },
    {
      "epoch": 3.472864318948132,
      "grad_norm": 0.9194270968437195,
      "learning_rate": 0.00041260318919386044,
      "loss": 0.7144,
      "step": 328050
    },
    {
      "epoch": 3.473393640728135,
      "grad_norm": 0.9227803945541382,
      "learning_rate": 0.0004125680996388267,
      "loss": 0.7205,
      "step": 328100
    },
    {
      "epoch": 3.4739229625081385,
      "grad_norm": 1.0818628072738647,
      "learning_rate": 0.0004125330045337776,
      "loss": 0.7261,
      "step": 328150
    },
    {
      "epoch": 3.474452284288142,
      "grad_norm": 0.8472614884376526,
      "learning_rate": 0.00041249790387991135,
      "loss": 0.7201,
      "step": 328200
    },
    {
      "epoch": 3.4749816060681447,
      "grad_norm": 0.9679329991340637,
      "learning_rate": 0.00041246279767842635,
      "loss": 0.7135,
      "step": 328250
    },
    {
      "epoch": 3.4755109278481484,
      "grad_norm": 0.9223789572715759,
      "learning_rate": 0.000412427685930521,
      "loss": 0.7119,
      "step": 328300
    },
    {
      "epoch": 3.4760402496281513,
      "grad_norm": 0.9478136897087097,
      "learning_rate": 0.000412392568637394,
      "loss": 0.7169,
      "step": 328350
    },
    {
      "epoch": 3.4765695714081546,
      "grad_norm": 1.0637251138687134,
      "learning_rate": 0.00041235744580024424,
      "loss": 0.7141,
      "step": 328400
    },
    {
      "epoch": 3.477098893188158,
      "grad_norm": 0.9775097966194153,
      "learning_rate": 0.0004123223174202708,
      "loss": 0.7093,
      "step": 328450
    },
    {
      "epoch": 3.477628214968161,
      "grad_norm": 0.9215085506439209,
      "learning_rate": 0.0004122871834986731,
      "loss": 0.7195,
      "step": 328500
    },
    {
      "epoch": 3.477628214968161,
      "eval_loss": 0.5053614377975464,
      "eval_runtime": 46.9269,
      "eval_samples_per_second": 3578.545,
      "eval_steps_per_second": 447.334,
      "step": 328500
    },
    {
      "epoch": 3.4781575367481645,
      "grad_norm": 1.1000661849975586,
      "learning_rate": 0.00041225204403665035,
      "loss": 0.7216,
      "step": 328550
    },
    {
      "epoch": 3.478686858528168,
      "grad_norm": 1.0250908136367798,
      "learning_rate": 0.00041221689903540236,
      "loss": 0.7107,
      "step": 328600
    },
    {
      "epoch": 3.479216180308171,
      "grad_norm": 0.8909761905670166,
      "learning_rate": 0.00041218174849612886,
      "loss": 0.7221,
      "step": 328650
    },
    {
      "epoch": 3.4797455020881745,
      "grad_norm": 1.0143548250198364,
      "learning_rate": 0.00041214659242003003,
      "loss": 0.7226,
      "step": 328700
    },
    {
      "epoch": 3.4802748238681778,
      "grad_norm": 0.899940013885498,
      "learning_rate": 0.000412111430808306,
      "loss": 0.7058,
      "step": 328750
    },
    {
      "epoch": 3.480804145648181,
      "grad_norm": 0.9944431185722351,
      "learning_rate": 0.00041207626366215715,
      "loss": 0.7119,
      "step": 328800
    },
    {
      "epoch": 3.4813334674281844,
      "grad_norm": 0.9499817490577698,
      "learning_rate": 0.0004120410909827841,
      "loss": 0.7146,
      "step": 328850
    },
    {
      "epoch": 3.4818627892081877,
      "grad_norm": 0.930285632610321,
      "learning_rate": 0.00041200591277138767,
      "loss": 0.7161,
      "step": 328900
    },
    {
      "epoch": 3.482392110988191,
      "grad_norm": 0.9155523777008057,
      "learning_rate": 0.00041197072902916874,
      "loss": 0.7071,
      "step": 328950
    },
    {
      "epoch": 3.482921432768194,
      "grad_norm": 1.07487952709198,
      "learning_rate": 0.00041193553975732856,
      "loss": 0.7156,
      "step": 329000
    },
    {
      "epoch": 3.482921432768194,
      "eval_loss": 0.5057063102722168,
      "eval_runtime": 46.7638,
      "eval_samples_per_second": 3591.028,
      "eval_steps_per_second": 448.895,
      "step": 329000
    },
    {
      "epoch": 3.4834507545481976,
      "grad_norm": 0.8832841515541077,
      "learning_rate": 0.0004119003449570684,
      "loss": 0.7127,
      "step": 329050
    },
    {
      "epoch": 3.4839800763282005,
      "grad_norm": 0.8812774419784546,
      "learning_rate": 0.00041186514462958985,
      "loss": 0.7132,
      "step": 329100
    },
    {
      "epoch": 3.484509398108204,
      "grad_norm": 0.9914112091064453,
      "learning_rate": 0.0004118299387760946,
      "loss": 0.7157,
      "step": 329150
    },
    {
      "epoch": 3.485038719888207,
      "grad_norm": 0.9660841822624207,
      "learning_rate": 0.0004117947273977847,
      "loss": 0.7135,
      "step": 329200
    },
    {
      "epoch": 3.4855680416682104,
      "grad_norm": 0.9858624339103699,
      "learning_rate": 0.00041175951049586204,
      "loss": 0.7137,
      "step": 329250
    },
    {
      "epoch": 3.4860973634482137,
      "grad_norm": 1.0483617782592773,
      "learning_rate": 0.00041172428807152906,
      "loss": 0.7106,
      "step": 329300
    },
    {
      "epoch": 3.486626685228217,
      "grad_norm": 1.0408594608306885,
      "learning_rate": 0.0004116890601259882,
      "loss": 0.7148,
      "step": 329350
    },
    {
      "epoch": 3.4871560070082204,
      "grad_norm": 1.0272935628890991,
      "learning_rate": 0.00041165382666044203,
      "loss": 0.7125,
      "step": 329400
    },
    {
      "epoch": 3.4876853287882237,
      "grad_norm": 1.0120817422866821,
      "learning_rate": 0.000411619292509857,
      "loss": 0.7143,
      "step": 329450
    },
    {
      "epoch": 3.488214650568227,
      "grad_norm": 1.0594286918640137,
      "learning_rate": 0.00041158404811824945,
      "loss": 0.7055,
      "step": 329500
    },
    {
      "epoch": 3.488214650568227,
      "eval_loss": 0.5038755536079407,
      "eval_runtime": 46.8474,
      "eval_samples_per_second": 3584.619,
      "eval_steps_per_second": 448.093,
      "step": 329500
    },
    {
      "epoch": 3.4887439723482303,
      "grad_norm": 0.9365805387496948,
      "learning_rate": 0.00041154879821022174,
      "loss": 0.6998,
      "step": 329550
    },
    {
      "epoch": 3.4892732941282336,
      "grad_norm": 1.0611358880996704,
      "learning_rate": 0.00041151354278697727,
      "loss": 0.6967,
      "step": 329600
    },
    {
      "epoch": 3.489802615908237,
      "grad_norm": 1.005879282951355,
      "learning_rate": 0.0004114782818497197,
      "loss": 0.709,
      "step": 329650
    },
    {
      "epoch": 3.4903319376882402,
      "grad_norm": 1.0025845766067505,
      "learning_rate": 0.00041144301539965285,
      "loss": 0.7258,
      "step": 329700
    },
    {
      "epoch": 3.490861259468243,
      "grad_norm": 0.971369743347168,
      "learning_rate": 0.0004114077434379806,
      "loss": 0.7153,
      "step": 329750
    },
    {
      "epoch": 3.491390581248247,
      "grad_norm": 0.9573204517364502,
      "learning_rate": 0.00041137246596590726,
      "loss": 0.7184,
      "step": 329800
    },
    {
      "epoch": 3.4919199030282497,
      "grad_norm": 0.9400131702423096,
      "learning_rate": 0.00041133718298463705,
      "loss": 0.7146,
      "step": 329850
    },
    {
      "epoch": 3.492449224808253,
      "grad_norm": 0.9567199349403381,
      "learning_rate": 0.00041130189449537456,
      "loss": 0.6971,
      "step": 329900
    },
    {
      "epoch": 3.4929785465882563,
      "grad_norm": 0.9983055591583252,
      "learning_rate": 0.0004112666004993246,
      "loss": 0.717,
      "step": 329950
    },
    {
      "epoch": 3.4935078683682597,
      "grad_norm": 0.854537308216095,
      "learning_rate": 0.000411231300997692,
      "loss": 0.7138,
      "step": 330000
    },
    {
      "epoch": 3.4935078683682597,
      "eval_loss": 0.5052849054336548,
      "eval_runtime": 46.8306,
      "eval_samples_per_second": 3585.905,
      "eval_steps_per_second": 448.254,
      "step": 330000
    },
    {
      "epoch": 3.494037190148263,
      "grad_norm": 1.019271731376648,
      "learning_rate": 0.00041119599599168203,
      "loss": 0.7033,
      "step": 330050
    },
    {
      "epoch": 3.4945665119282663,
      "grad_norm": 0.8602866530418396,
      "learning_rate": 0.00041116068548249974,
      "loss": 0.7161,
      "step": 330100
    },
    {
      "epoch": 3.4950958337082696,
      "grad_norm": 0.9885258674621582,
      "learning_rate": 0.00041112536947135084,
      "loss": 0.7136,
      "step": 330150
    },
    {
      "epoch": 3.495625155488273,
      "grad_norm": 1.0476940870285034,
      "learning_rate": 0.0004110900479594408,
      "loss": 0.6986,
      "step": 330200
    },
    {
      "epoch": 3.496154477268276,
      "grad_norm": 0.9105959534645081,
      "learning_rate": 0.00041105472094797574,
      "loss": 0.7028,
      "step": 330250
    },
    {
      "epoch": 3.4966837990482795,
      "grad_norm": 0.9475469589233398,
      "learning_rate": 0.0004110193884381615,
      "loss": 0.6979,
      "step": 330300
    },
    {
      "epoch": 3.497213120828283,
      "grad_norm": 1.0621165037155151,
      "learning_rate": 0.0004109840504312044,
      "loss": 0.7158,
      "step": 330350
    },
    {
      "epoch": 3.497742442608286,
      "grad_norm": 0.9042559862136841,
      "learning_rate": 0.0004109487069283109,
      "loss": 0.7031,
      "step": 330400
    },
    {
      "epoch": 3.4982717643882895,
      "grad_norm": 0.9796247482299805,
      "learning_rate": 0.00041091335793068753,
      "loss": 0.7166,
      "step": 330450
    },
    {
      "epoch": 3.4988010861682923,
      "grad_norm": 0.8887041807174683,
      "learning_rate": 0.00041087800343954107,
      "loss": 0.7156,
      "step": 330500
    },
    {
      "epoch": 3.4988010861682923,
      "eval_loss": 0.5056067109107971,
      "eval_runtime": 46.8819,
      "eval_samples_per_second": 3581.977,
      "eval_steps_per_second": 447.763,
      "step": 330500
    },
    {
      "epoch": 3.499330407948296,
      "grad_norm": 0.9370238780975342,
      "learning_rate": 0.0004108426434560787,
      "loss": 0.7081,
      "step": 330550
    },
    {
      "epoch": 3.499859729728299,
      "grad_norm": 1.0523430109024048,
      "learning_rate": 0.00041080727798150735,
      "loss": 0.7176,
      "step": 330600
    },
    {
      "epoch": 3.5003890515083023,
      "grad_norm": 0.9755952954292297,
      "learning_rate": 0.0004107719070170346,
      "loss": 0.7117,
      "step": 330650
    },
    {
      "epoch": 3.5009183732883056,
      "grad_norm": 1.0436923503875732,
      "learning_rate": 0.00041073653056386783,
      "loss": 0.7175,
      "step": 330700
    },
    {
      "epoch": 3.501447695068309,
      "grad_norm": 0.9274163246154785,
      "learning_rate": 0.00041070114862321494,
      "loss": 0.707,
      "step": 330750
    },
    {
      "epoch": 3.501977016848312,
      "grad_norm": 1.0469231605529785,
      "learning_rate": 0.0004106657611962837,
      "loss": 0.7172,
      "step": 330800
    },
    {
      "epoch": 3.5025063386283155,
      "grad_norm": 0.9508407711982727,
      "learning_rate": 0.0004106303682842823,
      "loss": 0.7097,
      "step": 330850
    },
    {
      "epoch": 3.503035660408319,
      "grad_norm": 1.0147794485092163,
      "learning_rate": 0.00041059496988841906,
      "loss": 0.7134,
      "step": 330900
    },
    {
      "epoch": 3.503564982188322,
      "grad_norm": 0.986588180065155,
      "learning_rate": 0.0004105595660099024,
      "loss": 0.6934,
      "step": 330950
    },
    {
      "epoch": 3.5040943039683254,
      "grad_norm": 0.9100633263587952,
      "learning_rate": 0.0004105241566499411,
      "loss": 0.7046,
      "step": 331000
    },
    {
      "epoch": 3.5040943039683254,
      "eval_loss": 0.5045022368431091,
      "eval_runtime": 46.7629,
      "eval_samples_per_second": 3591.098,
      "eval_steps_per_second": 448.903,
      "step": 331000
    },
    {
      "epoch": 3.5046236257483288,
      "grad_norm": 0.8755429983139038,
      "learning_rate": 0.0004104887418097439,
      "loss": 0.7018,
      "step": 331050
    },
    {
      "epoch": 3.505152947528332,
      "grad_norm": 0.9833455681800842,
      "learning_rate": 0.00041045332149052,
      "loss": 0.7142,
      "step": 331100
    },
    {
      "epoch": 3.5056822693083354,
      "grad_norm": 0.9259786009788513,
      "learning_rate": 0.00041041789569347853,
      "loss": 0.6981,
      "step": 331150
    },
    {
      "epoch": 3.5062115910883387,
      "grad_norm": 1.0440394878387451,
      "learning_rate": 0.00041038246441982886,
      "loss": 0.6997,
      "step": 331200
    },
    {
      "epoch": 3.5067409128683416,
      "grad_norm": 0.9416778683662415,
      "learning_rate": 0.0004103470276707807,
      "loss": 0.7167,
      "step": 331250
    },
    {
      "epoch": 3.5072702346483453,
      "grad_norm": 0.9446994066238403,
      "learning_rate": 0.00041031158544754386,
      "loss": 0.7235,
      "step": 331300
    },
    {
      "epoch": 3.507799556428348,
      "grad_norm": 1.0010645389556885,
      "learning_rate": 0.00041027613775132825,
      "loss": 0.7116,
      "step": 331350
    },
    {
      "epoch": 3.5083288782083515,
      "grad_norm": 0.9042827486991882,
      "learning_rate": 0.00041024068458334414,
      "loss": 0.6947,
      "step": 331400
    },
    {
      "epoch": 3.508858199988355,
      "grad_norm": 0.9068211913108826,
      "learning_rate": 0.0004102059351711762,
      "loss": 0.7042,
      "step": 331450
    },
    {
      "epoch": 3.509387521768358,
      "grad_norm": 0.9205505847930908,
      "learning_rate": 0.00041017047117266134,
      "loss": 0.7147,
      "step": 331500
    },
    {
      "epoch": 3.509387521768358,
      "eval_loss": 0.5042538642883301,
      "eval_runtime": 46.8084,
      "eval_samples_per_second": 3587.602,
      "eval_steps_per_second": 448.466,
      "step": 331500
    },
    {
      "epoch": 3.5099168435483614,
      "grad_norm": 0.9686437249183655,
      "learning_rate": 0.0004101350017059853,
      "loss": 0.7311,
      "step": 331550
    },
    {
      "epoch": 3.5104461653283647,
      "grad_norm": 0.9522883892059326,
      "learning_rate": 0.00041009952677235895,
      "loss": 0.7074,
      "step": 331600
    },
    {
      "epoch": 3.510975487108368,
      "grad_norm": 0.9627735018730164,
      "learning_rate": 0.0004100640463729934,
      "loss": 0.71,
      "step": 331650
    },
    {
      "epoch": 3.5115048088883714,
      "grad_norm": 0.9200913906097412,
      "learning_rate": 0.0004100285605091002,
      "loss": 0.7239,
      "step": 331700
    },
    {
      "epoch": 3.5120341306683747,
      "grad_norm": 0.9744173884391785,
      "learning_rate": 0.00040999306918189057,
      "loss": 0.7097,
      "step": 331750
    },
    {
      "epoch": 3.512563452448378,
      "grad_norm": 1.0244137048721313,
      "learning_rate": 0.00040995757239257617,
      "loss": 0.7048,
      "step": 331800
    },
    {
      "epoch": 3.5130927742283813,
      "grad_norm": 0.8964136838912964,
      "learning_rate": 0.000409922070142369,
      "loss": 0.7166,
      "step": 331850
    },
    {
      "epoch": 3.5136220960083846,
      "grad_norm": 0.9738854765892029,
      "learning_rate": 0.00040988656243248094,
      "loss": 0.6998,
      "step": 331900
    },
    {
      "epoch": 3.514151417788388,
      "grad_norm": 0.9380356669425964,
      "learning_rate": 0.00040985104926412433,
      "loss": 0.7132,
      "step": 331950
    },
    {
      "epoch": 3.5146807395683908,
      "grad_norm": 0.9657318592071533,
      "learning_rate": 0.00040981553063851144,
      "loss": 0.7086,
      "step": 332000
    },
    {
      "epoch": 3.5146807395683908,
      "eval_loss": 0.5040581226348877,
      "eval_runtime": 46.8124,
      "eval_samples_per_second": 3587.296,
      "eval_steps_per_second": 448.428,
      "step": 332000
    },
    {
      "epoch": 3.5152100613483945,
      "grad_norm": 0.914742648601532,
      "learning_rate": 0.000409780006556855,
      "loss": 0.7145,
      "step": 332050
    },
    {
      "epoch": 3.5157393831283974,
      "grad_norm": 0.8767793774604797,
      "learning_rate": 0.0004097444770203678,
      "loss": 0.7055,
      "step": 332100
    },
    {
      "epoch": 3.5162687049084007,
      "grad_norm": 0.9552895426750183,
      "learning_rate": 0.0004097089420302626,
      "loss": 0.7084,
      "step": 332150
    },
    {
      "epoch": 3.516798026688404,
      "grad_norm": 0.9992113709449768,
      "learning_rate": 0.0004096734015877528,
      "loss": 0.707,
      "step": 332200
    },
    {
      "epoch": 3.5173273484684073,
      "grad_norm": 0.9884032011032104,
      "learning_rate": 0.00040963785569405155,
      "loss": 0.7037,
      "step": 332250
    },
    {
      "epoch": 3.5178566702484106,
      "grad_norm": 0.8726624846458435,
      "learning_rate": 0.0004096023043503725,
      "loss": 0.7148,
      "step": 332300
    },
    {
      "epoch": 3.518385992028414,
      "grad_norm": 0.9499484300613403,
      "learning_rate": 0.00040956674755792934,
      "loss": 0.7042,
      "step": 332350
    },
    {
      "epoch": 3.5189153138084173,
      "grad_norm": 0.9395456314086914,
      "learning_rate": 0.0004095311853179359,
      "loss": 0.7044,
      "step": 332400
    },
    {
      "epoch": 3.5194446355884206,
      "grad_norm": 0.9551675915718079,
      "learning_rate": 0.00040949561763160624,
      "loss": 0.7004,
      "step": 332450
    },
    {
      "epoch": 3.519973957368424,
      "grad_norm": 0.8933233022689819,
      "learning_rate": 0.0004094600445001547,
      "loss": 0.7068,
      "step": 332500
    },
    {
      "epoch": 3.519973957368424,
      "eval_loss": 0.5030333995819092,
      "eval_runtime": 46.871,
      "eval_samples_per_second": 3582.81,
      "eval_steps_per_second": 447.867,
      "step": 332500
    },
    {
      "epoch": 3.520503279148427,
      "grad_norm": 0.9533810615539551,
      "learning_rate": 0.00040942446592479584,
      "loss": 0.7032,
      "step": 332550
    },
    {
      "epoch": 3.5210326009284305,
      "grad_norm": 1.0353716611862183,
      "learning_rate": 0.00040938888190674403,
      "loss": 0.7103,
      "step": 332600
    },
    {
      "epoch": 3.521561922708434,
      "grad_norm": 1.0664812326431274,
      "learning_rate": 0.0004093532924472144,
      "loss": 0.7164,
      "step": 332650
    },
    {
      "epoch": 3.522091244488437,
      "grad_norm": 1.068637728691101,
      "learning_rate": 0.0004093176975474217,
      "loss": 0.712,
      "step": 332700
    },
    {
      "epoch": 3.52262056626844,
      "grad_norm": 1.0288159847259521,
      "learning_rate": 0.0004092820972085812,
      "loss": 0.6886,
      "step": 332750
    },
    {
      "epoch": 3.5231498880484438,
      "grad_norm": 0.9237868189811707,
      "learning_rate": 0.00040924649143190845,
      "loss": 0.6993,
      "step": 332800
    },
    {
      "epoch": 3.5236792098284466,
      "grad_norm": 0.8489435315132141,
      "learning_rate": 0.00040921088021861877,
      "loss": 0.6933,
      "step": 332850
    },
    {
      "epoch": 3.52420853160845,
      "grad_norm": 0.9738907217979431,
      "learning_rate": 0.00040917526356992805,
      "loss": 0.7116,
      "step": 332900
    },
    {
      "epoch": 3.5247378533884532,
      "grad_norm": 1.0305439233779907,
      "learning_rate": 0.0004091396414870523,
      "loss": 0.7136,
      "step": 332950
    },
    {
      "epoch": 3.5252671751684566,
      "grad_norm": 0.9275541305541992,
      "learning_rate": 0.00040910401397120747,
      "loss": 0.7102,
      "step": 333000
    },
    {
      "epoch": 3.5252671751684566,
      "eval_loss": 0.5014156103134155,
      "eval_runtime": 46.8132,
      "eval_samples_per_second": 3587.236,
      "eval_steps_per_second": 448.421,
      "step": 333000
    },
    {
      "epoch": 3.52579649694846,
      "grad_norm": 0.9948868751525879,
      "learning_rate": 0.00040906838102360997,
      "loss": 0.7139,
      "step": 333050
    },
    {
      "epoch": 3.526325818728463,
      "grad_norm": 0.9385086894035339,
      "learning_rate": 0.0004090327426454763,
      "loss": 0.7032,
      "step": 333100
    },
    {
      "epoch": 3.5268551405084665,
      "grad_norm": 0.9332708120346069,
      "learning_rate": 0.000408997098838023,
      "loss": 0.6964,
      "step": 333150
    },
    {
      "epoch": 3.52738446228847,
      "grad_norm": 0.9776011109352112,
      "learning_rate": 0.0004089614496024672,
      "loss": 0.7167,
      "step": 333200
    },
    {
      "epoch": 3.527913784068473,
      "grad_norm": 1.0648945569992065,
      "learning_rate": 0.0004089257949400258,
      "loss": 0.7073,
      "step": 333250
    },
    {
      "epoch": 3.5284431058484764,
      "grad_norm": 0.9536500573158264,
      "learning_rate": 0.00040889013485191595,
      "loss": 0.7032,
      "step": 333300
    },
    {
      "epoch": 3.5289724276284797,
      "grad_norm": 1.001842975616455,
      "learning_rate": 0.0004088544693393552,
      "loss": 0.7175,
      "step": 333350
    },
    {
      "epoch": 3.529501749408483,
      "grad_norm": 0.9516427516937256,
      "learning_rate": 0.0004088187984035612,
      "loss": 0.6958,
      "step": 333400
    },
    {
      "epoch": 3.5300310711884864,
      "grad_norm": 1.026773452758789,
      "learning_rate": 0.00040878383562603567,
      "loss": 0.714,
      "step": 333450
    },
    {
      "epoch": 3.5305603929684892,
      "grad_norm": 1.01604425907135,
      "learning_rate": 0.0004087481539558325,
      "loss": 0.6973,
      "step": 333500
    },
    {
      "epoch": 3.5305603929684892,
      "eval_loss": 0.5025249719619751,
      "eval_runtime": 46.9125,
      "eval_samples_per_second": 3579.646,
      "eval_steps_per_second": 447.472,
      "step": 333500
    },
    {
      "epoch": 3.531089714748493,
      "grad_norm": 0.9181987047195435,
      "learning_rate": 0.00040871246686602564,
      "loss": 0.7198,
      "step": 333550
    },
    {
      "epoch": 3.531619036528496,
      "grad_norm": 0.9141807556152344,
      "learning_rate": 0.00040867677435783335,
      "loss": 0.7243,
      "step": 333600
    },
    {
      "epoch": 3.532148358308499,
      "grad_norm": 0.9520003795623779,
      "learning_rate": 0.0004086410764324742,
      "loss": 0.6947,
      "step": 333650
    },
    {
      "epoch": 3.5326776800885025,
      "grad_norm": 1.0277379751205444,
      "learning_rate": 0.0004086053730911668,
      "loss": 0.7061,
      "step": 333700
    },
    {
      "epoch": 3.533207001868506,
      "grad_norm": 0.9662365913391113,
      "learning_rate": 0.0004085696643351302,
      "loss": 0.7072,
      "step": 333750
    },
    {
      "epoch": 3.533736323648509,
      "grad_norm": 0.8676794171333313,
      "learning_rate": 0.00040853395016558335,
      "loss": 0.7068,
      "step": 333800
    },
    {
      "epoch": 3.5342656454285124,
      "grad_norm": 0.9679261445999146,
      "learning_rate": 0.0004084982305837457,
      "loss": 0.71,
      "step": 333850
    },
    {
      "epoch": 3.5347949672085157,
      "grad_norm": 1.0093891620635986,
      "learning_rate": 0.00040846250559083646,
      "loss": 0.7003,
      "step": 333900
    },
    {
      "epoch": 3.535324288988519,
      "grad_norm": 1.003744125366211,
      "learning_rate": 0.0004084267751880755,
      "loss": 0.7083,
      "step": 333950
    },
    {
      "epoch": 3.5358536107685223,
      "grad_norm": 1.0460824966430664,
      "learning_rate": 0.00040839103937668244,
      "loss": 0.7187,
      "step": 334000
    },
    {
      "epoch": 3.5358536107685223,
      "eval_loss": 0.5012409687042236,
      "eval_runtime": 46.8387,
      "eval_samples_per_second": 3585.281,
      "eval_steps_per_second": 448.176,
      "step": 334000
    },
    {
      "epoch": 3.5363829325485256,
      "grad_norm": 0.9634068608283997,
      "learning_rate": 0.0004083552981578774,
      "loss": 0.7189,
      "step": 334050
    },
    {
      "epoch": 3.536912254328529,
      "grad_norm": 1.0749684572219849,
      "learning_rate": 0.0004083195515328806,
      "loss": 0.717,
      "step": 334100
    },
    {
      "epoch": 3.5374415761085323,
      "grad_norm": 1.0215601921081543,
      "learning_rate": 0.00040828379950291234,
      "loss": 0.7157,
      "step": 334150
    },
    {
      "epoch": 3.5379708978885356,
      "grad_norm": 0.9852390289306641,
      "learning_rate": 0.0004082480420691932,
      "loss": 0.7008,
      "step": 334200
    },
    {
      "epoch": 3.5385002196685384,
      "grad_norm": 0.9268284440040588,
      "learning_rate": 0.00040821227923294403,
      "loss": 0.7194,
      "step": 334250
    },
    {
      "epoch": 3.539029541448542,
      "grad_norm": 0.9013856649398804,
      "learning_rate": 0.00040817651099538555,
      "loss": 0.7085,
      "step": 334300
    },
    {
      "epoch": 3.539558863228545,
      "grad_norm": 0.9843094348907471,
      "learning_rate": 0.00040814073735773903,
      "loss": 0.7043,
      "step": 334350
    },
    {
      "epoch": 3.5400881850085484,
      "grad_norm": 0.9691427946090698,
      "learning_rate": 0.00040810495832122577,
      "loss": 0.7116,
      "step": 334400
    },
    {
      "epoch": 3.5406175067885517,
      "grad_norm": 0.9992963671684265,
      "learning_rate": 0.00040806917388706723,
      "loss": 0.6926,
      "step": 334450
    },
    {
      "epoch": 3.541146828568555,
      "grad_norm": 1.0216314792633057,
      "learning_rate": 0.00040803338405648505,
      "loss": 0.6855,
      "step": 334500
    },
    {
      "epoch": 3.541146828568555,
      "eval_loss": 0.49943703413009644,
      "eval_runtime": 46.8792,
      "eval_samples_per_second": 3582.187,
      "eval_steps_per_second": 447.789,
      "step": 334500
    },
    {
      "epoch": 3.5416761503485583,
      "grad_norm": 0.9471032023429871,
      "learning_rate": 0.00040799758883070105,
      "loss": 0.7195,
      "step": 334550
    },
    {
      "epoch": 3.5422054721285616,
      "grad_norm": 0.9588789939880371,
      "learning_rate": 0.0004079617882109373,
      "loss": 0.7134,
      "step": 334600
    },
    {
      "epoch": 3.542734793908565,
      "grad_norm": 0.9393874406814575,
      "learning_rate": 0.00040792598219841614,
      "loss": 0.7089,
      "step": 334650
    },
    {
      "epoch": 3.5432641156885682,
      "grad_norm": 0.9456394910812378,
      "learning_rate": 0.0004078901707943598,
      "loss": 0.705,
      "step": 334700
    },
    {
      "epoch": 3.5437934374685716,
      "grad_norm": 0.9223986268043518,
      "learning_rate": 0.0004078543539999909,
      "loss": 0.7127,
      "step": 334750
    },
    {
      "epoch": 3.544322759248575,
      "grad_norm": 1.0154069662094116,
      "learning_rate": 0.0004078185318165323,
      "loss": 0.7,
      "step": 334800
    },
    {
      "epoch": 3.544852081028578,
      "grad_norm": 0.9032647013664246,
      "learning_rate": 0.00040778270424520684,
      "loss": 0.7076,
      "step": 334850
    },
    {
      "epoch": 3.5453814028085815,
      "grad_norm": 0.974425196647644,
      "learning_rate": 0.00040774687128723773,
      "loss": 0.7049,
      "step": 334900
    },
    {
      "epoch": 3.545910724588585,
      "grad_norm": 0.9092192053794861,
      "learning_rate": 0.0004077110329438484,
      "loss": 0.7183,
      "step": 334950
    },
    {
      "epoch": 3.5464400463685877,
      "grad_norm": 0.9227511286735535,
      "learning_rate": 0.0004076751892162621,
      "loss": 0.7161,
      "step": 335000
    },
    {
      "epoch": 3.5464400463685877,
      "eval_loss": 0.5019912719726562,
      "eval_runtime": 46.897,
      "eval_samples_per_second": 3580.828,
      "eval_steps_per_second": 447.62,
      "step": 335000
    },
    {
      "epoch": 3.5469693681485914,
      "grad_norm": 0.9033859968185425,
      "learning_rate": 0.0004076393401057028,
      "loss": 0.7165,
      "step": 335050
    },
    {
      "epoch": 3.5474986899285943,
      "grad_norm": 1.016031265258789,
      "learning_rate": 0.0004076034856133941,
      "loss": 0.696,
      "step": 335100
    },
    {
      "epoch": 3.548028011708598,
      "grad_norm": 1.0361673831939697,
      "learning_rate": 0.0004075676257405603,
      "loss": 0.7097,
      "step": 335150
    },
    {
      "epoch": 3.548557333488601,
      "grad_norm": 0.9598791003227234,
      "learning_rate": 0.0004075317604884255,
      "loss": 0.715,
      "step": 335200
    },
    {
      "epoch": 3.5490866552686042,
      "grad_norm": 0.9484337568283081,
      "learning_rate": 0.0004074958898582142,
      "loss": 0.7192,
      "step": 335250
    },
    {
      "epoch": 3.5496159770486075,
      "grad_norm": 0.9253131747245789,
      "learning_rate": 0.00040746001385115097,
      "loss": 0.7056,
      "step": 335300
    },
    {
      "epoch": 3.550145298828611,
      "grad_norm": 1.0449907779693604,
      "learning_rate": 0.00040742413246846055,
      "loss": 0.7019,
      "step": 335350
    },
    {
      "epoch": 3.550674620608614,
      "grad_norm": 0.9787087440490723,
      "learning_rate": 0.00040738824571136804,
      "loss": 0.712,
      "step": 335400
    },
    {
      "epoch": 3.5512039423886175,
      "grad_norm": 0.9520710110664368,
      "learning_rate": 0.0004073523535810986,
      "loss": 0.7199,
      "step": 335450
    },
    {
      "epoch": 3.551733264168621,
      "grad_norm": 0.9524200558662415,
      "learning_rate": 0.0004073164560788774,
      "loss": 0.7128,
      "step": 335500
    },
    {
      "epoch": 3.551733264168621,
      "eval_loss": 0.49801763892173767,
      "eval_runtime": 46.8889,
      "eval_samples_per_second": 3581.441,
      "eval_steps_per_second": 447.696,
      "step": 335500
    },
    {
      "epoch": 3.552262585948624,
      "grad_norm": 0.9515146613121033,
      "learning_rate": 0.0004072812713160142,
      "loss": 0.7059,
      "step": 335550
    },
    {
      "epoch": 3.5527919077286274,
      "grad_norm": 1.0118986368179321,
      "learning_rate": 0.00040724536318094455,
      "loss": 0.7123,
      "step": 335600
    },
    {
      "epoch": 3.5533212295086307,
      "grad_norm": 1.005663514137268,
      "learning_rate": 0.0004072094496775759,
      "loss": 0.7063,
      "step": 335650
    },
    {
      "epoch": 3.553850551288634,
      "grad_norm": 0.9317906498908997,
      "learning_rate": 0.0004071735308071342,
      "loss": 0.7112,
      "step": 335700
    },
    {
      "epoch": 3.554379873068637,
      "grad_norm": 0.9788586497306824,
      "learning_rate": 0.00040713760657084587,
      "loss": 0.7223,
      "step": 335750
    },
    {
      "epoch": 3.5549091948486407,
      "grad_norm": 0.8765026926994324,
      "learning_rate": 0.0004071016769699373,
      "loss": 0.7112,
      "step": 335800
    },
    {
      "epoch": 3.5554385166286435,
      "grad_norm": 0.8986456990242004,
      "learning_rate": 0.00040706574200563496,
      "loss": 0.6971,
      "step": 335850
    },
    {
      "epoch": 3.5559678384086473,
      "grad_norm": 0.9323033690452576,
      "learning_rate": 0.0004070298016791659,
      "loss": 0.7017,
      "step": 335900
    },
    {
      "epoch": 3.55649716018865,
      "grad_norm": 0.9366819262504578,
      "learning_rate": 0.000406993855991757,
      "loss": 0.7034,
      "step": 335950
    },
    {
      "epoch": 3.5570264819686535,
      "grad_norm": 0.9791187644004822,
      "learning_rate": 0.00040695790494463534,
      "loss": 0.694,
      "step": 336000
    },
    {
      "epoch": 3.5570264819686535,
      "eval_loss": 0.5006346106529236,
      "eval_runtime": 46.8107,
      "eval_samples_per_second": 3587.427,
      "eval_steps_per_second": 448.444,
      "step": 336000
    },
    {
      "epoch": 3.5575558037486568,
      "grad_norm": 0.9233722686767578,
      "learning_rate": 0.0004069219485390285,
      "loss": 0.7055,
      "step": 336050
    },
    {
      "epoch": 3.55808512552866,
      "grad_norm": 1.0157387256622314,
      "learning_rate": 0.00040688598677616377,
      "loss": 0.7038,
      "step": 336100
    },
    {
      "epoch": 3.5586144473086634,
      "grad_norm": 1.0170406103134155,
      "learning_rate": 0.0004068500196572691,
      "loss": 0.7211,
      "step": 336150
    },
    {
      "epoch": 3.5591437690886667,
      "grad_norm": 1.0157191753387451,
      "learning_rate": 0.0004068140471835722,
      "loss": 0.7036,
      "step": 336200
    },
    {
      "epoch": 3.55967309086867,
      "grad_norm": 0.9657531976699829,
      "learning_rate": 0.00040677806935630125,
      "loss": 0.7092,
      "step": 336250
    },
    {
      "epoch": 3.5602024126486733,
      "grad_norm": 0.981210470199585,
      "learning_rate": 0.0004067420861766845,
      "loss": 0.7102,
      "step": 336300
    },
    {
      "epoch": 3.5607317344286766,
      "grad_norm": 0.9885088205337524,
      "learning_rate": 0.00040670609764595047,
      "loss": 0.7054,
      "step": 336350
    },
    {
      "epoch": 3.56126105620868,
      "grad_norm": 0.9681450128555298,
      "learning_rate": 0.00040667010376532764,
      "loss": 0.6975,
      "step": 336400
    },
    {
      "epoch": 3.5617903779886833,
      "grad_norm": 0.9513646364212036,
      "learning_rate": 0.000406634104536045,
      "loss": 0.7083,
      "step": 336450
    },
    {
      "epoch": 3.562319699768686,
      "grad_norm": 0.9584800601005554,
      "learning_rate": 0.00040659809995933143,
      "loss": 0.713,
      "step": 336500
    },
    {
      "epoch": 3.562319699768686,
      "eval_loss": 0.49999362230300903,
      "eval_runtime": 46.871,
      "eval_samples_per_second": 3582.815,
      "eval_steps_per_second": 447.868,
      "step": 336500
    },
    {
      "epoch": 3.56284902154869,
      "grad_norm": 0.8769394159317017,
      "learning_rate": 0.0004065620900364162,
      "loss": 0.7018,
      "step": 336550
    },
    {
      "epoch": 3.5633783433286927,
      "grad_norm": 0.9516558051109314,
      "learning_rate": 0.00040652607476852865,
      "loss": 0.7041,
      "step": 336600
    },
    {
      "epoch": 3.5639076651086965,
      "grad_norm": 0.9810613989830017,
      "learning_rate": 0.0004064900541568983,
      "loss": 0.7057,
      "step": 336650
    },
    {
      "epoch": 3.5644369868886994,
      "grad_norm": 0.9231785535812378,
      "learning_rate": 0.00040645402820275485,
      "loss": 0.7121,
      "step": 336700
    },
    {
      "epoch": 3.5649663086687027,
      "grad_norm": 0.9962723255157471,
      "learning_rate": 0.0004064179969073283,
      "loss": 0.707,
      "step": 336750
    },
    {
      "epoch": 3.565495630448706,
      "grad_norm": 0.9950703978538513,
      "learning_rate": 0.0004063819602718486,
      "loss": 0.7186,
      "step": 336800
    },
    {
      "epoch": 3.5660249522287093,
      "grad_norm": 1.0120965242385864,
      "learning_rate": 0.0004063459182975462,
      "loss": 0.7192,
      "step": 336850
    },
    {
      "epoch": 3.5665542740087126,
      "grad_norm": 0.9533853530883789,
      "learning_rate": 0.00040630987098565154,
      "loss": 0.7062,
      "step": 336900
    },
    {
      "epoch": 3.567083595788716,
      "grad_norm": 0.9842753410339355,
      "learning_rate": 0.0004062738183373952,
      "loss": 0.6961,
      "step": 336950
    },
    {
      "epoch": 3.5676129175687192,
      "grad_norm": 0.9284767508506775,
      "learning_rate": 0.00040623776035400794,
      "loss": 0.7045,
      "step": 337000
    },
    {
      "epoch": 3.5676129175687192,
      "eval_loss": 0.49948978424072266,
      "eval_runtime": 46.779,
      "eval_samples_per_second": 3589.859,
      "eval_steps_per_second": 448.748,
      "step": 337000
    },
    {
      "epoch": 3.5681422393487225,
      "grad_norm": 1.1072930097579956,
      "learning_rate": 0.00040620169703672085,
      "loss": 0.7029,
      "step": 337050
    },
    {
      "epoch": 3.568671561128726,
      "grad_norm": 1.0553988218307495,
      "learning_rate": 0.0004061656283867652,
      "loss": 0.715,
      "step": 337100
    },
    {
      "epoch": 3.569200882908729,
      "grad_norm": 0.9132869243621826,
      "learning_rate": 0.0004061295544053721,
      "loss": 0.704,
      "step": 337150
    },
    {
      "epoch": 3.5697302046887325,
      "grad_norm": 0.9895866513252258,
      "learning_rate": 0.0004060934750937734,
      "loss": 0.7123,
      "step": 337200
    },
    {
      "epoch": 3.5702595264687353,
      "grad_norm": 0.8767944574356079,
      "learning_rate": 0.0004060573904532007,
      "loss": 0.7089,
      "step": 337250
    },
    {
      "epoch": 3.570788848248739,
      "grad_norm": 1.069752812385559,
      "learning_rate": 0.0004060213004848859,
      "loss": 0.7001,
      "step": 337300
    },
    {
      "epoch": 3.571318170028742,
      "grad_norm": 0.9235319495201111,
      "learning_rate": 0.0004059852051900611,
      "loss": 0.7121,
      "step": 337350
    },
    {
      "epoch": 3.5718474918087457,
      "grad_norm": 0.8770247101783752,
      "learning_rate": 0.00040594910456995866,
      "loss": 0.697,
      "step": 337400
    },
    {
      "epoch": 3.5723768135887486,
      "grad_norm": 1.002921462059021,
      "learning_rate": 0.0004059129986258109,
      "loss": 0.7069,
      "step": 337450
    },
    {
      "epoch": 3.572906135368752,
      "grad_norm": 0.9916043281555176,
      "learning_rate": 0.0004058768873588506,
      "loss": 0.7126,
      "step": 337500
    },
    {
      "epoch": 3.572906135368752,
      "eval_loss": 0.4992368817329407,
      "eval_runtime": 46.866,
      "eval_samples_per_second": 3583.194,
      "eval_steps_per_second": 447.915,
      "step": 337500
    },
    {
      "epoch": 3.573435457148755,
      "grad_norm": 0.9508374333381653,
      "learning_rate": 0.00040584077077031056,
      "loss": 0.7021,
      "step": 337550
    },
    {
      "epoch": 3.5739647789287585,
      "grad_norm": 1.1421706676483154,
      "learning_rate": 0.0004058053713517329,
      "loss": 0.7127,
      "step": 337600
    },
    {
      "epoch": 3.574494100708762,
      "grad_norm": 1.0161644220352173,
      "learning_rate": 0.00040576924423010266,
      "loss": 0.7091,
      "step": 337650
    },
    {
      "epoch": 3.575023422488765,
      "grad_norm": 0.9233355522155762,
      "learning_rate": 0.0004057331117905676,
      "loss": 0.7054,
      "step": 337700
    },
    {
      "epoch": 3.5755527442687685,
      "grad_norm": 0.9880672097206116,
      "learning_rate": 0.00040569697403436113,
      "loss": 0.7034,
      "step": 337750
    },
    {
      "epoch": 3.5760820660487718,
      "grad_norm": 0.9814420342445374,
      "learning_rate": 0.0004056608309627171,
      "loss": 0.7038,
      "step": 337800
    },
    {
      "epoch": 3.576611387828775,
      "grad_norm": 1.013576626777649,
      "learning_rate": 0.0004056246825768695,
      "loss": 0.6977,
      "step": 337850
    },
    {
      "epoch": 3.5771407096087784,
      "grad_norm": 0.966196596622467,
      "learning_rate": 0.0004055885288780522,
      "loss": 0.7061,
      "step": 337900
    },
    {
      "epoch": 3.5776700313887817,
      "grad_norm": 0.8928884863853455,
      "learning_rate": 0.0004055523698674995,
      "loss": 0.6989,
      "step": 337950
    },
    {
      "epoch": 3.5781993531687846,
      "grad_norm": 0.954655110836029,
      "learning_rate": 0.0004055162055464461,
      "loss": 0.7129,
      "step": 338000
    },
    {
      "epoch": 3.5781993531687846,
      "eval_loss": 0.5016732811927795,
      "eval_runtime": 46.7623,
      "eval_samples_per_second": 3591.143,
      "eval_steps_per_second": 448.909,
      "step": 338000
    },
    {
      "epoch": 3.5787286749487883,
      "grad_norm": 0.9549285173416138,
      "learning_rate": 0.0004054800359161264,
      "loss": 0.7072,
      "step": 338050
    },
    {
      "epoch": 3.579257996728791,
      "grad_norm": 0.9247501492500305,
      "learning_rate": 0.0004054438609777753,
      "loss": 0.6929,
      "step": 338100
    },
    {
      "epoch": 3.579787318508795,
      "grad_norm": 1.08107590675354,
      "learning_rate": 0.00040540768073262786,
      "loss": 0.7037,
      "step": 338150
    },
    {
      "epoch": 3.580316640288798,
      "grad_norm": 1.0488288402557373,
      "learning_rate": 0.00040537149518191914,
      "loss": 0.7077,
      "step": 338200
    },
    {
      "epoch": 3.580845962068801,
      "grad_norm": 1.0319528579711914,
      "learning_rate": 0.00040533530432688454,
      "loss": 0.7194,
      "step": 338250
    },
    {
      "epoch": 3.5813752838488044,
      "grad_norm": 0.9056358337402344,
      "learning_rate": 0.0004052991081687596,
      "loss": 0.7141,
      "step": 338300
    },
    {
      "epoch": 3.5819046056288077,
      "grad_norm": 0.933096706867218,
      "learning_rate": 0.00040526290670878014,
      "loss": 0.7151,
      "step": 338350
    },
    {
      "epoch": 3.582433927408811,
      "grad_norm": 0.9096428155899048,
      "learning_rate": 0.00040522669994818195,
      "loss": 0.7136,
      "step": 338400
    },
    {
      "epoch": 3.5829632491888144,
      "grad_norm": 0.9211427569389343,
      "learning_rate": 0.00040519048788820113,
      "loss": 0.705,
      "step": 338450
    },
    {
      "epoch": 3.5834925709688177,
      "grad_norm": 0.8699660897254944,
      "learning_rate": 0.000405154270530074,
      "loss": 0.684,
      "step": 338500
    },
    {
      "epoch": 3.5834925709688177,
      "eval_loss": 0.49977046251296997,
      "eval_runtime": 46.8913,
      "eval_samples_per_second": 3581.264,
      "eval_steps_per_second": 447.674,
      "step": 338500
    },
    {
      "epoch": 3.584021892748821,
      "grad_norm": 0.9813445210456848,
      "learning_rate": 0.00040511804787503694,
      "loss": 0.7059,
      "step": 338550
    },
    {
      "epoch": 3.5845512145288243,
      "grad_norm": 1.071642279624939,
      "learning_rate": 0.00040508181992432663,
      "loss": 0.7022,
      "step": 338600
    },
    {
      "epoch": 3.5850805363088276,
      "grad_norm": 0.9963324666023254,
      "learning_rate": 0.00040504558667917983,
      "loss": 0.6974,
      "step": 338650
    },
    {
      "epoch": 3.585609858088831,
      "grad_norm": 0.930868923664093,
      "learning_rate": 0.0004050093481408336,
      "loss": 0.71,
      "step": 338700
    },
    {
      "epoch": 3.586139179868834,
      "grad_norm": 1.0114638805389404,
      "learning_rate": 0.0004049731043105251,
      "loss": 0.7003,
      "step": 338750
    },
    {
      "epoch": 3.5866685016488375,
      "grad_norm": 0.9786271452903748,
      "learning_rate": 0.00040493685518949165,
      "loss": 0.7044,
      "step": 338800
    },
    {
      "epoch": 3.5871978234288404,
      "grad_norm": 1.0195120573043823,
      "learning_rate": 0.0004049006007789707,
      "loss": 0.7167,
      "step": 338850
    },
    {
      "epoch": 3.587727145208844,
      "grad_norm": 1.015745759010315,
      "learning_rate": 0.0004048643410802001,
      "loss": 0.709,
      "step": 338900
    },
    {
      "epoch": 3.588256466988847,
      "grad_norm": 0.9559745788574219,
      "learning_rate": 0.00040482807609441775,
      "loss": 0.7097,
      "step": 338950
    },
    {
      "epoch": 3.5887857887688503,
      "grad_norm": 0.9313119053840637,
      "learning_rate": 0.00040479180582286156,
      "loss": 0.71,
      "step": 339000
    },
    {
      "epoch": 3.5887857887688503,
      "eval_loss": 0.5005325078964233,
      "eval_runtime": 46.7827,
      "eval_samples_per_second": 3589.573,
      "eval_steps_per_second": 448.713,
      "step": 339000
    },
    {
      "epoch": 3.5893151105488537,
      "grad_norm": 0.918388843536377,
      "learning_rate": 0.0004047555302667699,
      "loss": 0.6935,
      "step": 339050
    },
    {
      "epoch": 3.589844432328857,
      "grad_norm": 0.8684139251708984,
      "learning_rate": 0.00040471924942738125,
      "loss": 0.7028,
      "step": 339100
    },
    {
      "epoch": 3.5903737541088603,
      "grad_norm": 1.0111942291259766,
      "learning_rate": 0.0004046829633059341,
      "loss": 0.7014,
      "step": 339150
    },
    {
      "epoch": 3.5909030758888636,
      "grad_norm": 0.936600387096405,
      "learning_rate": 0.00040464667190366746,
      "loss": 0.693,
      "step": 339200
    },
    {
      "epoch": 3.591432397668867,
      "grad_norm": 0.9187582731246948,
      "learning_rate": 0.00040461037522182,
      "loss": 0.7082,
      "step": 339250
    },
    {
      "epoch": 3.59196171944887,
      "grad_norm": 0.8314632773399353,
      "learning_rate": 0.0004045740732616311,
      "loss": 0.7009,
      "step": 339300
    },
    {
      "epoch": 3.5924910412288735,
      "grad_norm": 0.9767158031463623,
      "learning_rate": 0.00040453776602434,
      "loss": 0.7055,
      "step": 339350
    },
    {
      "epoch": 3.593020363008877,
      "grad_norm": 0.9311774373054504,
      "learning_rate": 0.0004045014535111862,
      "loss": 0.6819,
      "step": 339400
    },
    {
      "epoch": 3.59354968478888,
      "grad_norm": 0.9613469839096069,
      "learning_rate": 0.0004044651357234095,
      "loss": 0.7087,
      "step": 339450
    },
    {
      "epoch": 3.594079006568883,
      "grad_norm": 0.9552397727966309,
      "learning_rate": 0.00040442881266224975,
      "loss": 0.7107,
      "step": 339500
    },
    {
      "epoch": 3.594079006568883,
      "eval_loss": 0.49772143363952637,
      "eval_runtime": 46.8485,
      "eval_samples_per_second": 3584.534,
      "eval_steps_per_second": 448.083,
      "step": 339500
    },
    {
      "epoch": 3.5946083283488868,
      "grad_norm": 1.022407054901123,
      "learning_rate": 0.00040439248432894696,
      "loss": 0.698,
      "step": 339550
    },
    {
      "epoch": 3.5951376501288896,
      "grad_norm": 0.8863736987113953,
      "learning_rate": 0.0004043561507247413,
      "loss": 0.6936,
      "step": 339600
    },
    {
      "epoch": 3.5956669719088934,
      "grad_norm": 0.9375866651535034,
      "learning_rate": 0.0004043198118508733,
      "loss": 0.7041,
      "step": 339650
    },
    {
      "epoch": 3.5961962936888963,
      "grad_norm": 0.9232127070426941,
      "learning_rate": 0.00040428419464305176,
      "loss": 0.7135,
      "step": 339700
    },
    {
      "epoch": 3.5967256154688996,
      "grad_norm": 0.9431166052818298,
      "learning_rate": 0.00040424784533891247,
      "loss": 0.6994,
      "step": 339750
    },
    {
      "epoch": 3.597254937248903,
      "grad_norm": 0.8641541004180908,
      "learning_rate": 0.0004042114907688083,
      "loss": 0.7018,
      "step": 339800
    },
    {
      "epoch": 3.597784259028906,
      "grad_norm": 1.0637644529342651,
      "learning_rate": 0.00040417513093398034,
      "loss": 0.7122,
      "step": 339850
    },
    {
      "epoch": 3.5983135808089095,
      "grad_norm": 0.9872709512710571,
      "learning_rate": 0.00040413876583567,
      "loss": 0.6938,
      "step": 339900
    },
    {
      "epoch": 3.598842902588913,
      "grad_norm": 0.9630154967308044,
      "learning_rate": 0.00040410239547511873,
      "loss": 0.7119,
      "step": 339950
    },
    {
      "epoch": 3.599372224368916,
      "grad_norm": 0.9685515761375427,
      "learning_rate": 0.0004040660198535682,
      "loss": 0.7001,
      "step": 340000
    },
    {
      "epoch": 3.599372224368916,
      "eval_loss": 0.4958341419696808,
      "eval_runtime": 46.8849,
      "eval_samples_per_second": 3581.752,
      "eval_steps_per_second": 447.735,
      "step": 340000
    },
    {
      "epoch": 3.5999015461489194,
      "grad_norm": 1.0178446769714355,
      "learning_rate": 0.00040402963897226017,
      "loss": 0.7,
      "step": 340050
    },
    {
      "epoch": 3.6004308679289228,
      "grad_norm": 0.9756298661231995,
      "learning_rate": 0.0004039932528324368,
      "loss": 0.7103,
      "step": 340100
    },
    {
      "epoch": 3.600960189708926,
      "grad_norm": 0.9546335339546204,
      "learning_rate": 0.0004039568614353403,
      "loss": 0.7101,
      "step": 340150
    },
    {
      "epoch": 3.6014895114889294,
      "grad_norm": 1.0578899383544922,
      "learning_rate": 0.0004039204647822129,
      "loss": 0.7153,
      "step": 340200
    },
    {
      "epoch": 3.6020188332689322,
      "grad_norm": 0.8616626262664795,
      "learning_rate": 0.0004038840628742974,
      "loss": 0.7091,
      "step": 340250
    },
    {
      "epoch": 3.602548155048936,
      "grad_norm": 0.9401189684867859,
      "learning_rate": 0.00040384765571283633,
      "loss": 0.6984,
      "step": 340300
    },
    {
      "epoch": 3.603077476828939,
      "grad_norm": 1.0284104347229004,
      "learning_rate": 0.0004038112432990728,
      "loss": 0.7007,
      "step": 340350
    },
    {
      "epoch": 3.6036067986089426,
      "grad_norm": 0.9845606684684753,
      "learning_rate": 0.00040377482563424985,
      "loss": 0.7037,
      "step": 340400
    },
    {
      "epoch": 3.6041361203889455,
      "grad_norm": 1.0596859455108643,
      "learning_rate": 0.00040373840271961065,
      "loss": 0.7005,
      "step": 340450
    },
    {
      "epoch": 3.604665442168949,
      "grad_norm": 1.071873664855957,
      "learning_rate": 0.0004037019745563988,
      "loss": 0.7184,
      "step": 340500
    },
    {
      "epoch": 3.604665442168949,
      "eval_loss": 0.49682751297950745,
      "eval_runtime": 46.9292,
      "eval_samples_per_second": 3578.369,
      "eval_steps_per_second": 447.312,
      "step": 340500
    },
    {
      "epoch": 3.605194763948952,
      "grad_norm": 0.8290882110595703,
      "learning_rate": 0.000403665541145858,
      "loss": 0.6995,
      "step": 340550
    },
    {
      "epoch": 3.6057240857289554,
      "grad_norm": 1.024978756904602,
      "learning_rate": 0.0004036291024892318,
      "loss": 0.7001,
      "step": 340600
    },
    {
      "epoch": 3.6062534075089587,
      "grad_norm": 0.9660788178443909,
      "learning_rate": 0.0004035926585877645,
      "loss": 0.7019,
      "step": 340650
    },
    {
      "epoch": 3.606782729288962,
      "grad_norm": 1.057650089263916,
      "learning_rate": 0.0004035562094427001,
      "loss": 0.7152,
      "step": 340700
    },
    {
      "epoch": 3.6073120510689654,
      "grad_norm": 0.9224880337715149,
      "learning_rate": 0.00040351975505528313,
      "loss": 0.7047,
      "step": 340750
    },
    {
      "epoch": 3.6078413728489687,
      "grad_norm": 1.01292884349823,
      "learning_rate": 0.000403483295426758,
      "loss": 0.6967,
      "step": 340800
    },
    {
      "epoch": 3.608370694628972,
      "grad_norm": 0.9821770787239075,
      "learning_rate": 0.0004034468305583694,
      "loss": 0.7013,
      "step": 340850
    },
    {
      "epoch": 3.6089000164089753,
      "grad_norm": 1.015110731124878,
      "learning_rate": 0.00040341036045136227,
      "loss": 0.7173,
      "step": 340900
    },
    {
      "epoch": 3.6094293381889786,
      "grad_norm": 1.0191248655319214,
      "learning_rate": 0.0004033738851069817,
      "loss": 0.6972,
      "step": 340950
    },
    {
      "epoch": 3.609958659968982,
      "grad_norm": 0.9735736846923828,
      "learning_rate": 0.000403337404526473,
      "loss": 0.7134,
      "step": 341000
    },
    {
      "epoch": 3.609958659968982,
      "eval_loss": 0.5002366304397583,
      "eval_runtime": 46.9375,
      "eval_samples_per_second": 3577.734,
      "eval_steps_per_second": 447.233,
      "step": 341000
    },
    {
      "epoch": 3.610487981748985,
      "grad_norm": 0.8103446364402771,
      "learning_rate": 0.00040330091871108154,
      "loss": 0.7114,
      "step": 341050
    },
    {
      "epoch": 3.611017303528988,
      "grad_norm": 1.0224062204360962,
      "learning_rate": 0.00040326442766205287,
      "loss": 0.714,
      "step": 341100
    },
    {
      "epoch": 3.611546625308992,
      "grad_norm": 0.9269315004348755,
      "learning_rate": 0.00040322793138063286,
      "loss": 0.7114,
      "step": 341150
    },
    {
      "epoch": 3.6120759470889947,
      "grad_norm": 1.0254756212234497,
      "learning_rate": 0.00040319142986806753,
      "loss": 0.7178,
      "step": 341200
    },
    {
      "epoch": 3.612605268868998,
      "grad_norm": 1.0183264017105103,
      "learning_rate": 0.0004031549231256029,
      "loss": 0.7131,
      "step": 341250
    },
    {
      "epoch": 3.6131345906490013,
      "grad_norm": 1.0160114765167236,
      "learning_rate": 0.0004031184111544854,
      "loss": 0.6959,
      "step": 341300
    },
    {
      "epoch": 3.6136639124290046,
      "grad_norm": 1.0302845239639282,
      "learning_rate": 0.0004030818939559615,
      "loss": 0.7109,
      "step": 341350
    },
    {
      "epoch": 3.614193234209008,
      "grad_norm": 0.9691093564033508,
      "learning_rate": 0.00040304537153127784,
      "loss": 0.7022,
      "step": 341400
    },
    {
      "epoch": 3.6147225559890113,
      "grad_norm": 1.0363000631332397,
      "learning_rate": 0.00040300884388168133,
      "loss": 0.7044,
      "step": 341450
    },
    {
      "epoch": 3.6152518777690146,
      "grad_norm": 0.8712484240531921,
      "learning_rate": 0.00040297231100841903,
      "loss": 0.7034,
      "step": 341500
    },
    {
      "epoch": 3.6152518777690146,
      "eval_loss": 0.4948461055755615,
      "eval_runtime": 46.8468,
      "eval_samples_per_second": 3584.664,
      "eval_steps_per_second": 448.099,
      "step": 341500
    },
    {
      "epoch": 3.615781199549018,
      "grad_norm": 0.9486704468727112,
      "learning_rate": 0.00040293577291273814,
      "loss": 0.7046,
      "step": 341550
    },
    {
      "epoch": 3.616310521329021,
      "grad_norm": 0.9226303696632385,
      "learning_rate": 0.00040289922959588605,
      "loss": 0.6954,
      "step": 341600
    },
    {
      "epoch": 3.6168398431090245,
      "grad_norm": 0.8720223307609558,
      "learning_rate": 0.00040286268105911035,
      "loss": 0.6968,
      "step": 341650
    },
    {
      "epoch": 3.617369164889028,
      "grad_norm": Infinity,
      "learning_rate": 0.00040282685842990275,
      "loss": 0.7054,
      "step": 341700
    },
    {
      "epoch": 3.617898486669031,
      "grad_norm": 0.9823418855667114,
      "learning_rate": 0.0004027902995613595,
      "loss": 0.7012,
      "step": 341750
    },
    {
      "epoch": 3.6184278084490344,
      "grad_norm": 0.9670023322105408,
      "learning_rate": 0.0004027537354766115,
      "loss": 0.7115,
      "step": 341800
    },
    {
      "epoch": 3.6189571302290373,
      "grad_norm": 0.9158255457878113,
      "learning_rate": 0.000402717166176907,
      "loss": 0.7112,
      "step": 341850
    },
    {
      "epoch": 3.619486452009041,
      "grad_norm": 0.8718641996383667,
      "learning_rate": 0.00040268059166349444,
      "loss": 0.7002,
      "step": 341900
    },
    {
      "epoch": 3.620015773789044,
      "grad_norm": 1.027603030204773,
      "learning_rate": 0.00040264401193762246,
      "loss": 0.7008,
      "step": 341950
    },
    {
      "epoch": 3.6205450955690472,
      "grad_norm": 0.9388880133628845,
      "learning_rate": 0.00040260742700054,
      "loss": 0.7035,
      "step": 342000
    },
    {
      "epoch": 3.6205450955690472,
      "eval_loss": 0.4967423677444458,
      "eval_runtime": 46.8895,
      "eval_samples_per_second": 3581.399,
      "eval_steps_per_second": 447.691,
      "step": 342000
    },
    {
      "epoch": 3.6210744173490506,
      "grad_norm": 0.9422093629837036,
      "learning_rate": 0.00040257083685349583,
      "loss": 0.7035,
      "step": 342050
    },
    {
      "epoch": 3.621603739129054,
      "grad_norm": 0.9629888534545898,
      "learning_rate": 0.00040253424149773925,
      "loss": 0.6957,
      "step": 342100
    },
    {
      "epoch": 3.622133060909057,
      "grad_norm": 0.9261220693588257,
      "learning_rate": 0.0004024976409345197,
      "loss": 0.6996,
      "step": 342150
    },
    {
      "epoch": 3.6226623826890605,
      "grad_norm": 0.999345600605011,
      "learning_rate": 0.00040246103516508645,
      "loss": 0.7042,
      "step": 342200
    },
    {
      "epoch": 3.623191704469064,
      "grad_norm": 0.9059501886367798,
      "learning_rate": 0.00040242442419068954,
      "loss": 0.6949,
      "step": 342250
    },
    {
      "epoch": 3.623721026249067,
      "grad_norm": 0.875266432762146,
      "learning_rate": 0.0004023878080125786,
      "loss": 0.7108,
      "step": 342300
    },
    {
      "epoch": 3.6242503480290704,
      "grad_norm": 0.8848533034324646,
      "learning_rate": 0.00040235118663200375,
      "loss": 0.7063,
      "step": 342350
    },
    {
      "epoch": 3.6247796698090737,
      "grad_norm": 1.0634336471557617,
      "learning_rate": 0.0004023145600502154,
      "loss": 0.7081,
      "step": 342400
    },
    {
      "epoch": 3.625308991589077,
      "grad_norm": 0.9372817277908325,
      "learning_rate": 0.0004022779282684637,
      "loss": 0.7152,
      "step": 342450
    },
    {
      "epoch": 3.6258383133690804,
      "grad_norm": 1.015067458152771,
      "learning_rate": 0.00040224129128799943,
      "loss": 0.7071,
      "step": 342500
    },
    {
      "epoch": 3.6258383133690804,
      "eval_loss": 0.49440252780914307,
      "eval_runtime": 46.8576,
      "eval_samples_per_second": 3583.838,
      "eval_steps_per_second": 447.996,
      "step": 342500
    },
    {
      "epoch": 3.6263676351490837,
      "grad_norm": 0.9612657427787781,
      "learning_rate": 0.0004022046491100733,
      "loss": 0.713,
      "step": 342550
    },
    {
      "epoch": 3.6268969569290865,
      "grad_norm": 0.9382753372192383,
      "learning_rate": 0.00040216800173593627,
      "loss": 0.7065,
      "step": 342600
    },
    {
      "epoch": 3.6274262787090903,
      "grad_norm": 0.9230487942695618,
      "learning_rate": 0.00040213134916683945,
      "loss": 0.7023,
      "step": 342650
    },
    {
      "epoch": 3.627955600489093,
      "grad_norm": 0.9614115357398987,
      "learning_rate": 0.0004020946914040342,
      "loss": 0.684,
      "step": 342700
    },
    {
      "epoch": 3.6284849222690965,
      "grad_norm": 1.0744166374206543,
      "learning_rate": 0.00040205802844877194,
      "loss": 0.7168,
      "step": 342750
    },
    {
      "epoch": 3.6290142440491,
      "grad_norm": 0.88905930519104,
      "learning_rate": 0.0004020213603023043,
      "loss": 0.697,
      "step": 342800
    },
    {
      "epoch": 3.629543565829103,
      "grad_norm": 1.102984070777893,
      "learning_rate": 0.0004019846869658832,
      "loss": 0.7124,
      "step": 342850
    },
    {
      "epoch": 3.6300728876091064,
      "grad_norm": 0.9474685192108154,
      "learning_rate": 0.0004019480084407607,
      "loss": 0.7098,
      "step": 342900
    },
    {
      "epoch": 3.6306022093891097,
      "grad_norm": 1.0139654874801636,
      "learning_rate": 0.00040191132472818886,
      "loss": 0.7034,
      "step": 342950
    },
    {
      "epoch": 3.631131531169113,
      "grad_norm": 0.9547891020774841,
      "learning_rate": 0.0004018746358294201,
      "loss": 0.6953,
      "step": 343000
    },
    {
      "epoch": 3.631131531169113,
      "eval_loss": 0.4942324757575989,
      "eval_runtime": 46.8022,
      "eval_samples_per_second": 3588.082,
      "eval_steps_per_second": 448.526,
      "step": 343000
    },
    {
      "epoch": 3.6316608529491163,
      "grad_norm": 1.0076791048049927,
      "learning_rate": 0.00040183794174570697,
      "loss": 0.6994,
      "step": 343050
    },
    {
      "epoch": 3.6321901747291196,
      "grad_norm": 0.8562920689582825,
      "learning_rate": 0.0004018012424783022,
      "loss": 0.6991,
      "step": 343100
    },
    {
      "epoch": 3.632719496509123,
      "grad_norm": 1.0158278942108154,
      "learning_rate": 0.0004017645380284587,
      "loss": 0.6947,
      "step": 343150
    },
    {
      "epoch": 3.6332488182891263,
      "grad_norm": 0.9766553640365601,
      "learning_rate": 0.0004017278283974295,
      "loss": 0.7018,
      "step": 343200
    },
    {
      "epoch": 3.6337781400691296,
      "grad_norm": 0.9973496198654175,
      "learning_rate": 0.00040169111358646795,
      "loss": 0.6935,
      "step": 343250
    },
    {
      "epoch": 3.634307461849133,
      "grad_norm": 1.014906883239746,
      "learning_rate": 0.0004016543935968273,
      "loss": 0.7075,
      "step": 343300
    },
    {
      "epoch": 3.6348367836291358,
      "grad_norm": 0.9965673089027405,
      "learning_rate": 0.0004016176684297614,
      "loss": 0.7126,
      "step": 343350
    },
    {
      "epoch": 3.6353661054091395,
      "grad_norm": 0.8487144708633423,
      "learning_rate": 0.00040158093808652384,
      "loss": 0.6994,
      "step": 343400
    },
    {
      "epoch": 3.6358954271891424,
      "grad_norm": 0.8850216269493103,
      "learning_rate": 0.00040154420256836864,
      "loss": 0.7005,
      "step": 343450
    },
    {
      "epoch": 3.6364247489691457,
      "grad_norm": 0.9211007356643677,
      "learning_rate": 0.00040150746187655,
      "loss": 0.692,
      "step": 343500
    },
    {
      "epoch": 3.6364247489691457,
      "eval_loss": 0.49351856112480164,
      "eval_runtime": 46.8029,
      "eval_samples_per_second": 3588.029,
      "eval_steps_per_second": 448.52,
      "step": 343500
    },
    {
      "epoch": 3.636954070749149,
      "grad_norm": 0.9943022727966309,
      "learning_rate": 0.00040147071601232204,
      "loss": 0.7025,
      "step": 343550
    },
    {
      "epoch": 3.6374833925291523,
      "grad_norm": 0.9710022211074829,
      "learning_rate": 0.00040143470004831635,
      "loss": 0.7055,
      "step": 343600
    },
    {
      "epoch": 3.6380127143091556,
      "grad_norm": 0.9930675625801086,
      "learning_rate": 0.00040139794394641946,
      "loss": 0.7065,
      "step": 343650
    },
    {
      "epoch": 3.638542036089159,
      "grad_norm": 0.9675837159156799,
      "learning_rate": 0.0004013611826758523,
      "loss": 0.6892,
      "step": 343700
    },
    {
      "epoch": 3.6390713578691622,
      "grad_norm": 1.023945689201355,
      "learning_rate": 0.00040132441623786985,
      "loss": 0.6973,
      "step": 343750
    },
    {
      "epoch": 3.6396006796491656,
      "grad_norm": 0.9959913492202759,
      "learning_rate": 0.0004012876446337274,
      "loss": 0.701,
      "step": 343800
    },
    {
      "epoch": 3.640130001429169,
      "grad_norm": 0.9381201267242432,
      "learning_rate": 0.0004012508678646801,
      "loss": 0.7188,
      "step": 343850
    },
    {
      "epoch": 3.640659323209172,
      "grad_norm": 0.9468467235565186,
      "learning_rate": 0.0004012140859319837,
      "loss": 0.7122,
      "step": 343900
    },
    {
      "epoch": 3.6411886449891755,
      "grad_norm": 1.0349901914596558,
      "learning_rate": 0.00040117729883689394,
      "loss": 0.7049,
      "step": 343950
    },
    {
      "epoch": 3.641717966769179,
      "grad_norm": 1.033057451248169,
      "learning_rate": 0.00040114050658066655,
      "loss": 0.6992,
      "step": 344000
    },
    {
      "epoch": 3.641717966769179,
      "eval_loss": 0.49443793296813965,
      "eval_runtime": 46.7224,
      "eval_samples_per_second": 3594.204,
      "eval_steps_per_second": 449.292,
      "step": 344000
    },
    {
      "epoch": 3.642247288549182,
      "grad_norm": 0.9595619440078735,
      "learning_rate": 0.00040110370916455774,
      "loss": 0.7041,
      "step": 344050
    },
    {
      "epoch": 3.642776610329185,
      "grad_norm": 0.9624661207199097,
      "learning_rate": 0.0004010669065898237,
      "loss": 0.6999,
      "step": 344100
    },
    {
      "epoch": 3.6433059321091887,
      "grad_norm": 0.9554307460784912,
      "learning_rate": 0.00040103009885772087,
      "loss": 0.7035,
      "step": 344150
    },
    {
      "epoch": 3.6438352538891916,
      "grad_norm": 1.0097155570983887,
      "learning_rate": 0.0004009932859695058,
      "loss": 0.701,
      "step": 344200
    },
    {
      "epoch": 3.644364575669195,
      "grad_norm": 0.8472328782081604,
      "learning_rate": 0.00040095646792643534,
      "loss": 0.7044,
      "step": 344250
    },
    {
      "epoch": 3.6448938974491982,
      "grad_norm": 1.0066280364990234,
      "learning_rate": 0.0004009196447297665,
      "loss": 0.7016,
      "step": 344300
    },
    {
      "epoch": 3.6454232192292015,
      "grad_norm": 0.9462581872940063,
      "learning_rate": 0.0004008828163807563,
      "loss": 0.7023,
      "step": 344350
    },
    {
      "epoch": 3.645952541009205,
      "grad_norm": 1.0328786373138428,
      "learning_rate": 0.0004008459828806621,
      "loss": 0.6972,
      "step": 344400
    },
    {
      "epoch": 3.646481862789208,
      "grad_norm": 1.081371784210205,
      "learning_rate": 0.00040080914423074135,
      "loss": 0.7012,
      "step": 344450
    },
    {
      "epoch": 3.6470111845692115,
      "grad_norm": 0.9665740132331848,
      "learning_rate": 0.0004007723004322517,
      "loss": 0.6981,
      "step": 344500
    },
    {
      "epoch": 3.6470111845692115,
      "eval_loss": 0.49343252182006836,
      "eval_runtime": 46.882,
      "eval_samples_per_second": 3581.972,
      "eval_steps_per_second": 447.762,
      "step": 344500
    },
    {
      "epoch": 3.647540506349215,
      "grad_norm": 0.918397843837738,
      "learning_rate": 0.0004007354514864511,
      "loss": 0.7111,
      "step": 344550
    },
    {
      "epoch": 3.648069828129218,
      "grad_norm": 0.9800220727920532,
      "learning_rate": 0.00040069859739459734,
      "loss": 0.7148,
      "step": 344600
    },
    {
      "epoch": 3.6485991499092214,
      "grad_norm": 0.9757677912712097,
      "learning_rate": 0.0004006617381579488,
      "loss": 0.7076,
      "step": 344650
    },
    {
      "epoch": 3.6491284716892247,
      "grad_norm": 1.006253719329834,
      "learning_rate": 0.00040062487377776377,
      "loss": 0.7084,
      "step": 344700
    },
    {
      "epoch": 3.649657793469228,
      "grad_norm": 0.8163231015205383,
      "learning_rate": 0.00040058800425530076,
      "loss": 0.696,
      "step": 344750
    },
    {
      "epoch": 3.6501871152492313,
      "grad_norm": 0.9547339677810669,
      "learning_rate": 0.0004005511295918185,
      "loss": 0.7046,
      "step": 344800
    },
    {
      "epoch": 3.650716437029234,
      "grad_norm": 1.0088417530059814,
      "learning_rate": 0.000400514249788576,
      "loss": 0.7106,
      "step": 344850
    },
    {
      "epoch": 3.651245758809238,
      "grad_norm": 1.0256247520446777,
      "learning_rate": 0.0004004773648468321,
      "loss": 0.6998,
      "step": 344900
    },
    {
      "epoch": 3.651775080589241,
      "grad_norm": 1.0072367191314697,
      "learning_rate": 0.0004004404747678462,
      "loss": 0.6956,
      "step": 344950
    },
    {
      "epoch": 3.652304402369244,
      "grad_norm": 0.9616832137107849,
      "learning_rate": 0.00040040357955287766,
      "loss": 0.7008,
      "step": 345000
    },
    {
      "epoch": 3.652304402369244,
      "eval_loss": 0.493166983127594,
      "eval_runtime": 46.7407,
      "eval_samples_per_second": 3592.802,
      "eval_steps_per_second": 449.116,
      "step": 345000
    },
    {
      "epoch": 3.6528337241492475,
      "grad_norm": 0.9963505864143372,
      "learning_rate": 0.000400366679203186,
      "loss": 0.7127,
      "step": 345050
    },
    {
      "epoch": 3.6533630459292508,
      "grad_norm": 0.9449662566184998,
      "learning_rate": 0.00040032977372003124,
      "loss": 0.7059,
      "step": 345100
    },
    {
      "epoch": 3.653892367709254,
      "grad_norm": 1.010888695716858,
      "learning_rate": 0.0004002928631046729,
      "loss": 0.6992,
      "step": 345150
    },
    {
      "epoch": 3.6544216894892574,
      "grad_norm": 1.0317596197128296,
      "learning_rate": 0.00040025594735837146,
      "loss": 0.701,
      "step": 345200
    },
    {
      "epoch": 3.6549510112692607,
      "grad_norm": 0.9317855834960938,
      "learning_rate": 0.0004002190264823871,
      "loss": 0.6852,
      "step": 345250
    },
    {
      "epoch": 3.655480333049264,
      "grad_norm": 1.039939522743225,
      "learning_rate": 0.0004001821004779802,
      "loss": 0.7041,
      "step": 345300
    },
    {
      "epoch": 3.6560096548292673,
      "grad_norm": 0.9534376859664917,
      "learning_rate": 0.00040014516934641154,
      "loss": 0.7049,
      "step": 345350
    },
    {
      "epoch": 3.6565389766092706,
      "grad_norm": 0.9916050434112549,
      "learning_rate": 0.00040010823308894185,
      "loss": 0.7022,
      "step": 345400
    },
    {
      "epoch": 3.657068298389274,
      "grad_norm": 0.9371984601020813,
      "learning_rate": 0.0004000712917068321,
      "loss": 0.6947,
      "step": 345450
    },
    {
      "epoch": 3.6575976201692773,
      "grad_norm": 1.0043126344680786,
      "learning_rate": 0.00040003434520134354,
      "loss": 0.7043,
      "step": 345500
    },
    {
      "epoch": 3.6575976201692773,
      "eval_loss": 0.4925764203071594,
      "eval_runtime": 46.9576,
      "eval_samples_per_second": 3576.203,
      "eval_steps_per_second": 447.041,
      "step": 345500
    },
    {
      "epoch": 3.6581269419492806,
      "grad_norm": 0.9600312113761902,
      "learning_rate": 0.0003999973935737373,
      "loss": 0.7041,
      "step": 345550
    },
    {
      "epoch": 3.6586562637292834,
      "grad_norm": 0.9625875353813171,
      "learning_rate": 0.00039996043682527526,
      "loss": 0.7117,
      "step": 345600
    },
    {
      "epoch": 3.659185585509287,
      "grad_norm": 0.9352918863296509,
      "learning_rate": 0.00039992347495721874,
      "loss": 0.7063,
      "step": 345650
    },
    {
      "epoch": 3.65971490728929,
      "grad_norm": 1.0131062269210815,
      "learning_rate": 0.00039988650797082985,
      "loss": 0.7044,
      "step": 345700
    },
    {
      "epoch": 3.6602442290692934,
      "grad_norm": 0.9515681266784668,
      "learning_rate": 0.0003998495358673706,
      "loss": 0.7134,
      "step": 345750
    },
    {
      "epoch": 3.6607735508492967,
      "grad_norm": 1.056891679763794,
      "learning_rate": 0.0003998125586481031,
      "loss": 0.7084,
      "step": 345800
    },
    {
      "epoch": 3.6613028726293,
      "grad_norm": 0.9301705360412598,
      "learning_rate": 0.00039977557631428975,
      "loss": 0.7094,
      "step": 345850
    },
    {
      "epoch": 3.6618321944093033,
      "grad_norm": 1.0203922986984253,
      "learning_rate": 0.00039973858886719314,
      "loss": 0.6992,
      "step": 345900
    },
    {
      "epoch": 3.6623615161893066,
      "grad_norm": 0.9344595074653625,
      "learning_rate": 0.00039970159630807613,
      "loss": 0.7039,
      "step": 345950
    },
    {
      "epoch": 3.66289083796931,
      "grad_norm": 0.9219872951507568,
      "learning_rate": 0.0003996645986382014,
      "loss": 0.7013,
      "step": 346000
    },
    {
      "epoch": 3.66289083796931,
      "eval_loss": 0.4945700466632843,
      "eval_runtime": 46.8686,
      "eval_samples_per_second": 3582.999,
      "eval_steps_per_second": 447.891,
      "step": 346000
    },
    {
      "epoch": 3.6634201597493132,
      "grad_norm": 1.004866123199463,
      "learning_rate": 0.0003996275958588322,
      "loss": 0.6978,
      "step": 346050
    },
    {
      "epoch": 3.6639494815293165,
      "grad_norm": 0.9741085767745972,
      "learning_rate": 0.0003995905879712318,
      "loss": 0.702,
      "step": 346100
    },
    {
      "epoch": 3.66447880330932,
      "grad_norm": 1.0332026481628418,
      "learning_rate": 0.00039955357497666353,
      "loss": 0.7037,
      "step": 346150
    },
    {
      "epoch": 3.665008125089323,
      "grad_norm": 0.9082958102226257,
      "learning_rate": 0.0003995165568763911,
      "loss": 0.6914,
      "step": 346200
    },
    {
      "epoch": 3.6655374468693265,
      "grad_norm": 1.0317896604537964,
      "learning_rate": 0.0003994795336716782,
      "loss": 0.699,
      "step": 346250
    },
    {
      "epoch": 3.66606676864933,
      "grad_norm": 0.9006768465042114,
      "learning_rate": 0.0003994425053637889,
      "loss": 0.7069,
      "step": 346300
    },
    {
      "epoch": 3.6665960904293327,
      "grad_norm": 0.8592063188552856,
      "learning_rate": 0.00039940547195398726,
      "loss": 0.707,
      "step": 346350
    },
    {
      "epoch": 3.6671254122093364,
      "grad_norm": 0.9544225335121155,
      "learning_rate": 0.00039936843344353756,
      "loss": 0.6987,
      "step": 346400
    },
    {
      "epoch": 3.6676547339893393,
      "grad_norm": 0.9218384027481079,
      "learning_rate": 0.0003993313898337044,
      "loss": 0.7057,
      "step": 346450
    },
    {
      "epoch": 3.6681840557693426,
      "grad_norm": 1.0010449886322021,
      "learning_rate": 0.00039929434112575223,
      "loss": 0.6993,
      "step": 346500
    },
    {
      "epoch": 3.6681840557693426,
      "eval_loss": 0.49472030997276306,
      "eval_runtime": 46.92,
      "eval_samples_per_second": 3579.07,
      "eval_steps_per_second": 447.4,
      "step": 346500
    },
    {
      "epoch": 3.668713377549346,
      "grad_norm": 0.9365411400794983,
      "learning_rate": 0.00039925728732094614,
      "loss": 0.7068,
      "step": 346550
    },
    {
      "epoch": 3.669242699329349,
      "grad_norm": 0.9488730430603027,
      "learning_rate": 0.00039922022842055096,
      "loss": 0.6918,
      "step": 346600
    },
    {
      "epoch": 3.6697720211093525,
      "grad_norm": 0.948648989200592,
      "learning_rate": 0.00039918316442583184,
      "loss": 0.7122,
      "step": 346650
    },
    {
      "epoch": 3.670301342889356,
      "grad_norm": 0.9207552671432495,
      "learning_rate": 0.00039914609533805425,
      "loss": 0.7032,
      "step": 346700
    },
    {
      "epoch": 3.670830664669359,
      "grad_norm": 0.8429384827613831,
      "learning_rate": 0.0003991090211584837,
      "loss": 0.6929,
      "step": 346750
    },
    {
      "epoch": 3.6713599864493625,
      "grad_norm": 1.0307304859161377,
      "learning_rate": 0.0003990719418883858,
      "loss": 0.7027,
      "step": 346800
    },
    {
      "epoch": 3.6718893082293658,
      "grad_norm": 0.8876768350601196,
      "learning_rate": 0.00039903485752902645,
      "loss": 0.7094,
      "step": 346850
    },
    {
      "epoch": 3.672418630009369,
      "grad_norm": 0.9839721322059631,
      "learning_rate": 0.0003989977680816718,
      "loss": 0.6996,
      "step": 346900
    },
    {
      "epoch": 3.6729479517893724,
      "grad_norm": 1.0941630601882935,
      "learning_rate": 0.0003989606735475879,
      "loss": 0.6954,
      "step": 346950
    },
    {
      "epoch": 3.6734772735693757,
      "grad_norm": 0.9381338953971863,
      "learning_rate": 0.00039892357392804135,
      "loss": 0.7033,
      "step": 347000
    },
    {
      "epoch": 3.6734772735693757,
      "eval_loss": 0.4892771542072296,
      "eval_runtime": 46.8662,
      "eval_samples_per_second": 3583.177,
      "eval_steps_per_second": 447.913,
      "step": 347000
    },
    {
      "epoch": 3.674006595349379,
      "grad_norm": 0.9683306217193604,
      "learning_rate": 0.0003988864692242985,
      "loss": 0.6958,
      "step": 347050
    },
    {
      "epoch": 3.674535917129382,
      "grad_norm": 0.9574158787727356,
      "learning_rate": 0.00039884935943762626,
      "loss": 0.6965,
      "step": 347100
    },
    {
      "epoch": 3.6750652389093856,
      "grad_norm": 1.0367425680160522,
      "learning_rate": 0.00039881224456929143,
      "loss": 0.6961,
      "step": 347150
    },
    {
      "epoch": 3.6755945606893885,
      "grad_norm": 0.907183825969696,
      "learning_rate": 0.00039877512462056113,
      "loss": 0.7049,
      "step": 347200
    },
    {
      "epoch": 3.676123882469392,
      "grad_norm": 1.0819859504699707,
      "learning_rate": 0.00039873799959270275,
      "loss": 0.706,
      "step": 347250
    },
    {
      "epoch": 3.676653204249395,
      "grad_norm": 0.9437573552131653,
      "learning_rate": 0.0003987008694869835,
      "loss": 0.6993,
      "step": 347300
    },
    {
      "epoch": 3.6771825260293984,
      "grad_norm": 0.9638552069664001,
      "learning_rate": 0.0003986637343046711,
      "loss": 0.6984,
      "step": 347350
    },
    {
      "epoch": 3.6777118478094017,
      "grad_norm": 0.9351819753646851,
      "learning_rate": 0.00039862659404703337,
      "loss": 0.6944,
      "step": 347400
    },
    {
      "epoch": 3.678241169589405,
      "grad_norm": 0.8981795907020569,
      "learning_rate": 0.0003985894487153382,
      "loss": 0.6962,
      "step": 347450
    },
    {
      "epoch": 3.6787704913694084,
      "grad_norm": 0.9232504963874817,
      "learning_rate": 0.0003985522983108538,
      "loss": 0.7019,
      "step": 347500
    },
    {
      "epoch": 3.6787704913694084,
      "eval_loss": 0.4930093288421631,
      "eval_runtime": 46.8964,
      "eval_samples_per_second": 3580.869,
      "eval_steps_per_second": 447.625,
      "step": 347500
    },
    {
      "epoch": 3.6792998131494117,
      "grad_norm": 0.9513875246047974,
      "learning_rate": 0.00039851514283484833,
      "loss": 0.6986,
      "step": 347550
    },
    {
      "epoch": 3.679829134929415,
      "grad_norm": 1.088886022567749,
      "learning_rate": 0.0003984779822885904,
      "loss": 0.7061,
      "step": 347600
    },
    {
      "epoch": 3.6803584567094183,
      "grad_norm": 0.8649172782897949,
      "learning_rate": 0.00039844081667334864,
      "loss": 0.694,
      "step": 347650
    },
    {
      "epoch": 3.6808877784894216,
      "grad_norm": 0.9647241830825806,
      "learning_rate": 0.00039840438945370636,
      "loss": 0.6928,
      "step": 347700
    },
    {
      "epoch": 3.681417100269425,
      "grad_norm": 0.9475915431976318,
      "learning_rate": 0.00039836721380561997,
      "loss": 0.6912,
      "step": 347750
    },
    {
      "epoch": 3.6819464220494282,
      "grad_norm": 0.9406450986862183,
      "learning_rate": 0.0003983300330923313,
      "loss": 0.7002,
      "step": 347800
    },
    {
      "epoch": 3.682475743829431,
      "grad_norm": 1.016803503036499,
      "learning_rate": 0.00039829284731510975,
      "loss": 0.7102,
      "step": 347850
    },
    {
      "epoch": 3.683005065609435,
      "grad_norm": 1.0155572891235352,
      "learning_rate": 0.00039825565647522463,
      "loss": 0.6991,
      "step": 347900
    },
    {
      "epoch": 3.6835343873894377,
      "grad_norm": 1.0024089813232422,
      "learning_rate": 0.00039821846057394594,
      "loss": 0.7101,
      "step": 347950
    },
    {
      "epoch": 3.684063709169441,
      "grad_norm": 0.9535011649131775,
      "learning_rate": 0.00039818125961254327,
      "loss": 0.6968,
      "step": 348000
    },
    {
      "epoch": 3.684063709169441,
      "eval_loss": 0.4934127628803253,
      "eval_runtime": 46.9005,
      "eval_samples_per_second": 3580.56,
      "eval_steps_per_second": 447.586,
      "step": 348000
    },
    {
      "epoch": 3.6845930309494443,
      "grad_norm": 0.8851780891418457,
      "learning_rate": 0.00039814405359228677,
      "loss": 0.7026,
      "step": 348050
    },
    {
      "epoch": 3.6851223527294477,
      "grad_norm": 1.0555170774459839,
      "learning_rate": 0.0003981068425144466,
      "loss": 0.6976,
      "step": 348100
    },
    {
      "epoch": 3.685651674509451,
      "grad_norm": 0.9460350871086121,
      "learning_rate": 0.0003980696263802932,
      "loss": 0.6901,
      "step": 348150
    },
    {
      "epoch": 3.6861809962894543,
      "grad_norm": 0.992989718914032,
      "learning_rate": 0.00039803240519109697,
      "loss": 0.6873,
      "step": 348200
    },
    {
      "epoch": 3.6867103180694576,
      "grad_norm": 1.0556154251098633,
      "learning_rate": 0.0003979951789481288,
      "loss": 0.705,
      "step": 348250
    },
    {
      "epoch": 3.687239639849461,
      "grad_norm": 0.923586368560791,
      "learning_rate": 0.00039795794765265936,
      "loss": 0.7012,
      "step": 348300
    },
    {
      "epoch": 3.687768961629464,
      "grad_norm": 0.96686851978302,
      "learning_rate": 0.00039792071130595995,
      "loss": 0.6966,
      "step": 348350
    },
    {
      "epoch": 3.6882982834094675,
      "grad_norm": 0.9583343863487244,
      "learning_rate": 0.0003978834699093017,
      "loss": 0.7012,
      "step": 348400
    },
    {
      "epoch": 3.688827605189471,
      "grad_norm": 1.0177998542785645,
      "learning_rate": 0.00039784622346395604,
      "loss": 0.6923,
      "step": 348450
    },
    {
      "epoch": 3.689356926969474,
      "grad_norm": 0.8865159749984741,
      "learning_rate": 0.0003978089719711945,
      "loss": 0.7049,
      "step": 348500
    },
    {
      "epoch": 3.689356926969474,
      "eval_loss": 0.49170365929603577,
      "eval_runtime": 46.9785,
      "eval_samples_per_second": 3574.615,
      "eval_steps_per_second": 446.843,
      "step": 348500
    },
    {
      "epoch": 3.6898862487494775,
      "grad_norm": 0.9204952716827393,
      "learning_rate": 0.0003977717154322889,
      "loss": 0.6825,
      "step": 348550
    },
    {
      "epoch": 3.6904155705294803,
      "grad_norm": 1.0856422185897827,
      "learning_rate": 0.00039773445384851103,
      "loss": 0.7025,
      "step": 348600
    },
    {
      "epoch": 3.690944892309484,
      "grad_norm": 0.8940634727478027,
      "learning_rate": 0.00039769718722113326,
      "loss": 0.6986,
      "step": 348650
    },
    {
      "epoch": 3.691474214089487,
      "grad_norm": 0.9843122363090515,
      "learning_rate": 0.0003976599155514275,
      "loss": 0.6927,
      "step": 348700
    },
    {
      "epoch": 3.6920035358694903,
      "grad_norm": 1.0105196237564087,
      "learning_rate": 0.00039762263884066644,
      "loss": 0.6892,
      "step": 348750
    },
    {
      "epoch": 3.6925328576494936,
      "grad_norm": 0.9840747714042664,
      "learning_rate": 0.00039758535709012266,
      "loss": 0.6985,
      "step": 348800
    },
    {
      "epoch": 3.693062179429497,
      "grad_norm": 0.9870815277099609,
      "learning_rate": 0.00039754807030106885,
      "loss": 0.7115,
      "step": 348850
    },
    {
      "epoch": 3.6935915012095,
      "grad_norm": 0.9752546548843384,
      "learning_rate": 0.00039751077847477814,
      "loss": 0.7168,
      "step": 348900
    },
    {
      "epoch": 3.6941208229895035,
      "grad_norm": 1.0108675956726074,
      "learning_rate": 0.0003974734816125235,
      "loss": 0.6923,
      "step": 348950
    },
    {
      "epoch": 3.694650144769507,
      "grad_norm": 1.0136572122573853,
      "learning_rate": 0.0003974361797155783,
      "loss": 0.6948,
      "step": 349000
    },
    {
      "epoch": 3.694650144769507,
      "eval_loss": 0.4918263852596283,
      "eval_runtime": 46.9078,
      "eval_samples_per_second": 3580.001,
      "eval_steps_per_second": 447.516,
      "step": 349000
    },
    {
      "epoch": 3.69517946654951,
      "grad_norm": 0.894252598285675,
      "learning_rate": 0.00039739887278521593,
      "loss": 0.6951,
      "step": 349050
    },
    {
      "epoch": 3.6957087883295134,
      "grad_norm": 0.9315995573997498,
      "learning_rate": 0.00039736156082271015,
      "loss": 0.7023,
      "step": 349100
    },
    {
      "epoch": 3.6962381101095168,
      "grad_norm": 1.0367659330368042,
      "learning_rate": 0.00039732424382933477,
      "loss": 0.6944,
      "step": 349150
    },
    {
      "epoch": 3.69676743188952,
      "grad_norm": 0.9963321089744568,
      "learning_rate": 0.0003972869218063636,
      "loss": 0.6959,
      "step": 349200
    },
    {
      "epoch": 3.6972967536695234,
      "grad_norm": 1.0014569759368896,
      "learning_rate": 0.00039724959475507106,
      "loss": 0.7042,
      "step": 349250
    },
    {
      "epoch": 3.6978260754495267,
      "grad_norm": 1.015009880065918,
      "learning_rate": 0.00039721226267673126,
      "loss": 0.7054,
      "step": 349300
    },
    {
      "epoch": 3.6983553972295296,
      "grad_norm": 0.9981695413589478,
      "learning_rate": 0.0003971749255726189,
      "loss": 0.7053,
      "step": 349350
    },
    {
      "epoch": 3.6988847190095333,
      "grad_norm": 1.0661650896072388,
      "learning_rate": 0.00039713758344400854,
      "loss": 0.6949,
      "step": 349400
    },
    {
      "epoch": 3.699414040789536,
      "grad_norm": 0.9963685274124146,
      "learning_rate": 0.00039710023629217496,
      "loss": 0.7084,
      "step": 349450
    },
    {
      "epoch": 3.6999433625695395,
      "grad_norm": 0.9801826477050781,
      "learning_rate": 0.0003970628841183933,
      "loss": 0.6989,
      "step": 349500
    },
    {
      "epoch": 3.6999433625695395,
      "eval_loss": 0.49197182059288025,
      "eval_runtime": 46.8161,
      "eval_samples_per_second": 3587.012,
      "eval_steps_per_second": 448.393,
      "step": 349500
    },
    {
      "epoch": 3.700472684349543,
      "grad_norm": 0.9725528359413147,
      "learning_rate": 0.00039702552692393874,
      "loss": 0.6999,
      "step": 349550
    },
    {
      "epoch": 3.701002006129546,
      "grad_norm": 0.9960685968399048,
      "learning_rate": 0.0003969881647100866,
      "loss": 0.7148,
      "step": 349600
    },
    {
      "epoch": 3.7015313279095494,
      "grad_norm": 1.0843137502670288,
      "learning_rate": 0.00039695079747811244,
      "loss": 0.7019,
      "step": 349650
    },
    {
      "epoch": 3.7020606496895527,
      "grad_norm": 0.9388380646705627,
      "learning_rate": 0.0003969141727234252,
      "loss": 0.7073,
      "step": 349700
    },
    {
      "epoch": 3.702589971469556,
      "grad_norm": 0.936961829662323,
      "learning_rate": 0.0003968767955593331,
      "loss": 0.7205,
      "step": 349750
    },
    {
      "epoch": 3.7031192932495594,
      "grad_norm": 0.9351287484169006,
      "learning_rate": 0.0003968394133809211,
      "loss": 0.6903,
      "step": 349800
    },
    {
      "epoch": 3.7036486150295627,
      "grad_norm": 1.156989574432373,
      "learning_rate": 0.0003968020261894654,
      "loss": 0.6984,
      "step": 349850
    },
    {
      "epoch": 3.704177936809566,
      "grad_norm": 0.8726838827133179,
      "learning_rate": 0.0003967646339862423,
      "loss": 0.693,
      "step": 349900
    },
    {
      "epoch": 3.7047072585895693,
      "grad_norm": 0.9496539831161499,
      "learning_rate": 0.00039672723677252843,
      "loss": 0.6945,
      "step": 349950
    },
    {
      "epoch": 3.7052365803695726,
      "grad_norm": 0.9509821534156799,
      "learning_rate": 0.0003966898345496006,
      "loss": 0.6917,
      "step": 350000
    },
    {
      "epoch": 3.7052365803695726,
      "eval_loss": 0.49088653922080994,
      "eval_runtime": 46.8711,
      "eval_samples_per_second": 3582.801,
      "eval_steps_per_second": 447.866,
      "step": 350000
    },
    {
      "epoch": 3.705765902149576,
      "grad_norm": 1.006854772567749,
      "learning_rate": 0.0003966524273187355,
      "loss": 0.7024,
      "step": 350050
    },
    {
      "epoch": 3.7062952239295788,
      "grad_norm": 0.9612485766410828,
      "learning_rate": 0.0003966150150812104,
      "loss": 0.7048,
      "step": 350100
    },
    {
      "epoch": 3.7068245457095825,
      "grad_norm": 1.0212923288345337,
      "learning_rate": 0.00039657759783830236,
      "loss": 0.6987,
      "step": 350150
    },
    {
      "epoch": 3.7073538674895854,
      "grad_norm": 1.0001300573349,
      "learning_rate": 0.000396540175591289,
      "loss": 0.708,
      "step": 350200
    },
    {
      "epoch": 3.707883189269589,
      "grad_norm": 0.9796403646469116,
      "learning_rate": 0.00039650274834144775,
      "loss": 0.691,
      "step": 350250
    },
    {
      "epoch": 3.708412511049592,
      "grad_norm": 1.0062025785446167,
      "learning_rate": 0.0003964653160900564,
      "loss": 0.7143,
      "step": 350300
    },
    {
      "epoch": 3.7089418328295953,
      "grad_norm": 1.0194623470306396,
      "learning_rate": 0.0003964278788383928,
      "loss": 0.6841,
      "step": 350350
    },
    {
      "epoch": 3.7094711546095986,
      "grad_norm": 0.9821630120277405,
      "learning_rate": 0.0003963904365877352,
      "loss": 0.6989,
      "step": 350400
    },
    {
      "epoch": 3.710000476389602,
      "grad_norm": 0.9874005913734436,
      "learning_rate": 0.0003963529893393618,
      "loss": 0.6999,
      "step": 350450
    },
    {
      "epoch": 3.7105297981696053,
      "grad_norm": 0.8796320557594299,
      "learning_rate": 0.0003963155370945509,
      "loss": 0.7083,
      "step": 350500
    },
    {
      "epoch": 3.7105297981696053,
      "eval_loss": 0.4884437918663025,
      "eval_runtime": 46.8784,
      "eval_samples_per_second": 3582.247,
      "eval_steps_per_second": 447.797,
      "step": 350500
    },
    {
      "epoch": 3.7110591199496086,
      "grad_norm": 1.1295427083969116,
      "learning_rate": 0.0003962780798545813,
      "loss": 0.6958,
      "step": 350550
    },
    {
      "epoch": 3.711588441729612,
      "grad_norm": 0.8579903841018677,
      "learning_rate": 0.0003962406176207317,
      "loss": 0.6908,
      "step": 350600
    },
    {
      "epoch": 3.712117763509615,
      "grad_norm": 0.8665172457695007,
      "learning_rate": 0.00039620315039428104,
      "loss": 0.6884,
      "step": 350650
    },
    {
      "epoch": 3.7126470852896185,
      "grad_norm": 0.9218935370445251,
      "learning_rate": 0.0003961656781765085,
      "loss": 0.6919,
      "step": 350700
    },
    {
      "epoch": 3.713176407069622,
      "grad_norm": 0.9309002757072449,
      "learning_rate": 0.00039612820096869317,
      "loss": 0.6981,
      "step": 350750
    },
    {
      "epoch": 3.713705728849625,
      "grad_norm": 1.007423996925354,
      "learning_rate": 0.0003960907187721148,
      "loss": 0.7125,
      "step": 350800
    },
    {
      "epoch": 3.714235050629628,
      "grad_norm": 0.9917407631874084,
      "learning_rate": 0.00039605323158805277,
      "loss": 0.6972,
      "step": 350850
    },
    {
      "epoch": 3.7147643724096318,
      "grad_norm": 0.955539345741272,
      "learning_rate": 0.00039601573941778703,
      "loss": 0.6999,
      "step": 350900
    },
    {
      "epoch": 3.7152936941896346,
      "grad_norm": 1.0137914419174194,
      "learning_rate": 0.00039597824226259747,
      "loss": 0.7029,
      "step": 350950
    },
    {
      "epoch": 3.7158230159696384,
      "grad_norm": 0.9700803160667419,
      "learning_rate": 0.0003959407401237643,
      "loss": 0.6957,
      "step": 351000
    },
    {
      "epoch": 3.7158230159696384,
      "eval_loss": 0.48885709047317505,
      "eval_runtime": 46.7238,
      "eval_samples_per_second": 3594.098,
      "eval_steps_per_second": 449.278,
      "step": 351000
    },
    {
      "epoch": 3.7163523377496412,
      "grad_norm": 1.009297490119934,
      "learning_rate": 0.00039590323300256773,
      "loss": 0.7026,
      "step": 351050
    },
    {
      "epoch": 3.7168816595296446,
      "grad_norm": 0.8765634894371033,
      "learning_rate": 0.0003958657209002883,
      "loss": 0.6971,
      "step": 351100
    },
    {
      "epoch": 3.717410981309648,
      "grad_norm": 1.04456627368927,
      "learning_rate": 0.0003958282038182067,
      "loss": 0.7035,
      "step": 351150
    },
    {
      "epoch": 3.717940303089651,
      "grad_norm": 0.8808212876319885,
      "learning_rate": 0.0003957906817576037,
      "loss": 0.6938,
      "step": 351200
    },
    {
      "epoch": 3.7184696248696545,
      "grad_norm": 0.9797306060791016,
      "learning_rate": 0.00039575315471976027,
      "loss": 0.6903,
      "step": 351250
    },
    {
      "epoch": 3.718998946649658,
      "grad_norm": 1.0268168449401855,
      "learning_rate": 0.00039571562270595753,
      "loss": 0.7117,
      "step": 351300
    },
    {
      "epoch": 3.719528268429661,
      "grad_norm": 1.0135889053344727,
      "learning_rate": 0.00039567808571747696,
      "loss": 0.6947,
      "step": 351350
    },
    {
      "epoch": 3.7200575902096644,
      "grad_norm": 1.0004565715789795,
      "learning_rate": 0.0003956405437555999,
      "loss": 0.6938,
      "step": 351400
    },
    {
      "epoch": 3.7205869119896677,
      "grad_norm": 0.9417194724082947,
      "learning_rate": 0.00039560299682160816,
      "loss": 0.7006,
      "step": 351450
    },
    {
      "epoch": 3.721116233769671,
      "grad_norm": 0.9878831505775452,
      "learning_rate": 0.0003955654449167835,
      "loss": 0.6975,
      "step": 351500
    },
    {
      "epoch": 3.721116233769671,
      "eval_loss": 0.49037638306617737,
      "eval_runtime": 46.9813,
      "eval_samples_per_second": 3574.405,
      "eval_steps_per_second": 446.817,
      "step": 351500
    },
    {
      "epoch": 3.7216455555496744,
      "grad_norm": 1.032381296157837,
      "learning_rate": 0.00039552788804240785,
      "loss": 0.6914,
      "step": 351550
    },
    {
      "epoch": 3.7221748773296772,
      "grad_norm": 0.9629842638969421,
      "learning_rate": 0.0003954903261997635,
      "loss": 0.6999,
      "step": 351600
    },
    {
      "epoch": 3.722704199109681,
      "grad_norm": 1.0158799886703491,
      "learning_rate": 0.00039545275939013283,
      "loss": 0.7037,
      "step": 351650
    },
    {
      "epoch": 3.723233520889684,
      "grad_norm": 0.9809204339981079,
      "learning_rate": 0.0003954159390989606,
      "loss": 0.6942,
      "step": 351700
    },
    {
      "epoch": 3.7237628426696876,
      "grad_norm": 0.8931900858879089,
      "learning_rate": 0.0003953783624584806,
      "loss": 0.6908,
      "step": 351750
    },
    {
      "epoch": 3.7242921644496905,
      "grad_norm": 0.9299873113632202,
      "learning_rate": 0.00039534078085483673,
      "loss": 0.6977,
      "step": 351800
    },
    {
      "epoch": 3.724821486229694,
      "grad_norm": 1.0177298784255981,
      "learning_rate": 0.00039530319428931197,
      "loss": 0.6887,
      "step": 351850
    },
    {
      "epoch": 3.725350808009697,
      "grad_norm": 0.9648646712303162,
      "learning_rate": 0.00039526560276318935,
      "loss": 0.7,
      "step": 351900
    },
    {
      "epoch": 3.7258801297897004,
      "grad_norm": 0.9892442226409912,
      "learning_rate": 0.00039522800627775237,
      "loss": 0.7006,
      "step": 351950
    },
    {
      "epoch": 3.7264094515697037,
      "grad_norm": 0.9917140603065491,
      "learning_rate": 0.0003951904048342845,
      "loss": 0.6958,
      "step": 352000
    },
    {
      "epoch": 3.7264094515697037,
      "eval_loss": 0.48932144045829773,
      "eval_runtime": 46.7882,
      "eval_samples_per_second": 3589.152,
      "eval_steps_per_second": 448.66,
      "step": 352000
    },
    {
      "epoch": 3.726938773349707,
      "grad_norm": 0.9653137922286987,
      "learning_rate": 0.00039515279843406947,
      "loss": 0.7016,
      "step": 352050
    },
    {
      "epoch": 3.7274680951297103,
      "grad_norm": 0.9260681867599487,
      "learning_rate": 0.0003951151870783911,
      "loss": 0.6961,
      "step": 352100
    },
    {
      "epoch": 3.7279974169097136,
      "grad_norm": 0.9585635662078857,
      "learning_rate": 0.00039507757076853354,
      "loss": 0.6962,
      "step": 352150
    },
    {
      "epoch": 3.728526738689717,
      "grad_norm": 0.9183129668235779,
      "learning_rate": 0.00039503994950578083,
      "loss": 0.7025,
      "step": 352200
    },
    {
      "epoch": 3.7290560604697203,
      "grad_norm": 0.9834829568862915,
      "learning_rate": 0.0003950023232914175,
      "loss": 0.693,
      "step": 352250
    },
    {
      "epoch": 3.7295853822497236,
      "grad_norm": 0.9668461680412292,
      "learning_rate": 0.000394964692126728,
      "loss": 0.7069,
      "step": 352300
    },
    {
      "epoch": 3.7301147040297264,
      "grad_norm": 0.9978894591331482,
      "learning_rate": 0.0003949270560129971,
      "loss": 0.6971,
      "step": 352350
    },
    {
      "epoch": 3.73064402580973,
      "grad_norm": 0.9992498159408569,
      "learning_rate": 0.0003948894149515096,
      "loss": 0.6939,
      "step": 352400
    },
    {
      "epoch": 3.731173347589733,
      "grad_norm": 1.0152701139450073,
      "learning_rate": 0.0003948517689435507,
      "loss": 0.6989,
      "step": 352450
    },
    {
      "epoch": 3.731702669369737,
      "grad_norm": 0.8821627497673035,
      "learning_rate": 0.00039481411799040543,
      "loss": 0.6924,
      "step": 352500
    },
    {
      "epoch": 3.731702669369737,
      "eval_loss": 0.48841142654418945,
      "eval_runtime": 46.8367,
      "eval_samples_per_second": 3585.438,
      "eval_steps_per_second": 448.196,
      "step": 352500
    },
    {
      "epoch": 3.7322319911497397,
      "grad_norm": 1.0521354675292969,
      "learning_rate": 0.00039477646209335935,
      "loss": 0.6975,
      "step": 352550
    },
    {
      "epoch": 3.732761312929743,
      "grad_norm": 0.8555880188941956,
      "learning_rate": 0.0003947388012536979,
      "loss": 0.6848,
      "step": 352600
    },
    {
      "epoch": 3.7332906347097463,
      "grad_norm": 0.9737153649330139,
      "learning_rate": 0.00039470113547270685,
      "loss": 0.6932,
      "step": 352650
    },
    {
      "epoch": 3.7338199564897496,
      "grad_norm": 0.9714787602424622,
      "learning_rate": 0.00039466346475167216,
      "loss": 0.6941,
      "step": 352700
    },
    {
      "epoch": 3.734349278269753,
      "grad_norm": 1.0137269496917725,
      "learning_rate": 0.00039462578909187985,
      "loss": 0.7071,
      "step": 352750
    },
    {
      "epoch": 3.7348786000497562,
      "grad_norm": 0.9926744699478149,
      "learning_rate": 0.0003945881084946161,
      "loss": 0.6871,
      "step": 352800
    },
    {
      "epoch": 3.7354079218297596,
      "grad_norm": 0.9014798998832703,
      "learning_rate": 0.0003945504229611673,
      "loss": 0.6889,
      "step": 352850
    },
    {
      "epoch": 3.735937243609763,
      "grad_norm": 1.0076310634613037,
      "learning_rate": 0.00039451273249282016,
      "loss": 0.6966,
      "step": 352900
    },
    {
      "epoch": 3.736466565389766,
      "grad_norm": 1.00045645236969,
      "learning_rate": 0.0003944750370908613,
      "loss": 0.6977,
      "step": 352950
    },
    {
      "epoch": 3.7369958871697695,
      "grad_norm": 1.13668954372406,
      "learning_rate": 0.0003944373367565777,
      "loss": 0.6972,
      "step": 353000
    },
    {
      "epoch": 3.7369958871697695,
      "eval_loss": 0.4869174063205719,
      "eval_runtime": 46.801,
      "eval_samples_per_second": 3588.17,
      "eval_steps_per_second": 448.537,
      "step": 353000
    },
    {
      "epoch": 3.737525208949773,
      "grad_norm": 0.9274173378944397,
      "learning_rate": 0.00039439963149125634,
      "loss": 0.6923,
      "step": 353050
    },
    {
      "epoch": 3.7380545307297757,
      "grad_norm": 0.959703266620636,
      "learning_rate": 0.00039436192129618455,
      "loss": 0.6991,
      "step": 353100
    },
    {
      "epoch": 3.7385838525097794,
      "grad_norm": 1.0380580425262451,
      "learning_rate": 0.00039432420617264963,
      "loss": 0.6942,
      "step": 353150
    },
    {
      "epoch": 3.7391131742897823,
      "grad_norm": 0.9776882529258728,
      "learning_rate": 0.00039428648612193935,
      "loss": 0.6877,
      "step": 353200
    },
    {
      "epoch": 3.739642496069786,
      "grad_norm": 1.0109084844589233,
      "learning_rate": 0.0003942487611453413,
      "loss": 0.6935,
      "step": 353250
    },
    {
      "epoch": 3.740171817849789,
      "grad_norm": 1.008507490158081,
      "learning_rate": 0.0003942110312441435,
      "loss": 0.6866,
      "step": 353300
    },
    {
      "epoch": 3.7407011396297922,
      "grad_norm": 0.9635378122329712,
      "learning_rate": 0.00039417329641963384,
      "loss": 0.6993,
      "step": 353350
    },
    {
      "epoch": 3.7412304614097955,
      "grad_norm": 1.0208230018615723,
      "learning_rate": 0.00039413555667310084,
      "loss": 0.6929,
      "step": 353400
    },
    {
      "epoch": 3.741759783189799,
      "grad_norm": 0.871729850769043,
      "learning_rate": 0.00039409781200583274,
      "loss": 0.6946,
      "step": 353450
    },
    {
      "epoch": 3.742289104969802,
      "grad_norm": 0.8479596376419067,
      "learning_rate": 0.00039406006241911816,
      "loss": 0.691,
      "step": 353500
    },
    {
      "epoch": 3.742289104969802,
      "eval_loss": 0.4901866316795349,
      "eval_runtime": 46.8561,
      "eval_samples_per_second": 3583.954,
      "eval_steps_per_second": 448.01,
      "step": 353500
    },
    {
      "epoch": 3.7428184267498055,
      "grad_norm": 0.9918817281723022,
      "learning_rate": 0.00039402230791424597,
      "loss": 0.7007,
      "step": 353550
    },
    {
      "epoch": 3.743347748529809,
      "grad_norm": 0.9814030528068542,
      "learning_rate": 0.000393984548492505,
      "loss": 0.6965,
      "step": 353600
    },
    {
      "epoch": 3.743877070309812,
      "grad_norm": 1.0517969131469727,
      "learning_rate": 0.00039394678415518425,
      "loss": 0.6937,
      "step": 353650
    },
    {
      "epoch": 3.7444063920898154,
      "grad_norm": 1.048244833946228,
      "learning_rate": 0.0003939090149035732,
      "loss": 0.6986,
      "step": 353700
    },
    {
      "epoch": 3.7449357138698187,
      "grad_norm": 0.9574783444404602,
      "learning_rate": 0.00039387124073896106,
      "loss": 0.6969,
      "step": 353750
    },
    {
      "epoch": 3.745465035649822,
      "grad_norm": 1.005323886871338,
      "learning_rate": 0.00039383346166263754,
      "loss": 0.6918,
      "step": 353800
    },
    {
      "epoch": 3.745994357429825,
      "grad_norm": 1.0845664739608765,
      "learning_rate": 0.0003937956776758924,
      "loss": 0.7,
      "step": 353850
    },
    {
      "epoch": 3.7465236792098287,
      "grad_norm": 1.0063718557357788,
      "learning_rate": 0.00039375864460603426,
      "loss": 0.6996,
      "step": 353900
    },
    {
      "epoch": 3.7470530009898315,
      "grad_norm": 0.9278904795646667,
      "learning_rate": 0.0003937208509004601,
      "loss": 0.6905,
      "step": 353950
    },
    {
      "epoch": 3.7475823227698353,
      "grad_norm": 1.0338588953018188,
      "learning_rate": 0.0003936830522883087,
      "loss": 0.6838,
      "step": 354000
    },
    {
      "epoch": 3.7475823227698353,
      "eval_loss": 0.48686689138412476,
      "eval_runtime": 46.8033,
      "eval_samples_per_second": 3587.993,
      "eval_steps_per_second": 448.515,
      "step": 354000
    },
    {
      "epoch": 3.748111644549838,
      "grad_norm": 1.0945193767547607,
      "learning_rate": 0.0003936452487708706,
      "loss": 0.7071,
      "step": 354050
    },
    {
      "epoch": 3.7486409663298415,
      "grad_norm": 1.0436562299728394,
      "learning_rate": 0.0003936074403494364,
      "loss": 0.6946,
      "step": 354100
    },
    {
      "epoch": 3.7491702881098448,
      "grad_norm": 1.0804108381271362,
      "learning_rate": 0.00039356962702529684,
      "loss": 0.6947,
      "step": 354150
    },
    {
      "epoch": 3.749699609889848,
      "grad_norm": 1.0182502269744873,
      "learning_rate": 0.0003935318087997429,
      "loss": 0.7055,
      "step": 354200
    },
    {
      "epoch": 3.7502289316698514,
      "grad_norm": 1.020150065422058,
      "learning_rate": 0.00039349398567406556,
      "loss": 0.7031,
      "step": 354250
    },
    {
      "epoch": 3.7507582534498547,
      "grad_norm": 0.9460601806640625,
      "learning_rate": 0.0003934561576495562,
      "loss": 0.6935,
      "step": 354300
    },
    {
      "epoch": 3.751287575229858,
      "grad_norm": 0.9198930859565735,
      "learning_rate": 0.0003934183247275063,
      "loss": 0.7062,
      "step": 354350
    },
    {
      "epoch": 3.7518168970098613,
      "grad_norm": 0.8701692223548889,
      "learning_rate": 0.0003933804869092074,
      "loss": 0.6917,
      "step": 354400
    },
    {
      "epoch": 3.7523462187898646,
      "grad_norm": 0.8840987086296082,
      "learning_rate": 0.0003933426441959512,
      "loss": 0.692,
      "step": 354450
    },
    {
      "epoch": 3.752875540569868,
      "grad_norm": 0.9423094987869263,
      "learning_rate": 0.00039330479658902974,
      "loss": 0.7004,
      "step": 354500
    },
    {
      "epoch": 3.752875540569868,
      "eval_loss": 0.4869002401828766,
      "eval_runtime": 46.7792,
      "eval_samples_per_second": 3589.847,
      "eval_steps_per_second": 448.747,
      "step": 354500
    },
    {
      "epoch": 3.7534048623498713,
      "grad_norm": 0.9686472415924072,
      "learning_rate": 0.000393266944089735,
      "loss": 0.6855,
      "step": 354550
    },
    {
      "epoch": 3.753934184129874,
      "grad_norm": 1.0282704830169678,
      "learning_rate": 0.00039322908669935943,
      "loss": 0.6956,
      "step": 354600
    },
    {
      "epoch": 3.754463505909878,
      "grad_norm": 0.9928635358810425,
      "learning_rate": 0.0003931912244191953,
      "loss": 0.6997,
      "step": 354650
    },
    {
      "epoch": 3.7549928276898807,
      "grad_norm": 1.0196458101272583,
      "learning_rate": 0.00039315335725053523,
      "loss": 0.6973,
      "step": 354700
    },
    {
      "epoch": 3.7555221494698845,
      "grad_norm": 0.9935035705566406,
      "learning_rate": 0.0003931154851946722,
      "loss": 0.6972,
      "step": 354750
    },
    {
      "epoch": 3.7560514712498874,
      "grad_norm": 1.0402182340621948,
      "learning_rate": 0.0003930776082528988,
      "loss": 0.6877,
      "step": 354800
    },
    {
      "epoch": 3.7565807930298907,
      "grad_norm": 1.032651424407959,
      "learning_rate": 0.00039303972642650855,
      "loss": 0.6983,
      "step": 354850
    },
    {
      "epoch": 3.757110114809894,
      "grad_norm": 0.9482610821723938,
      "learning_rate": 0.0003930018397167944,
      "loss": 0.6887,
      "step": 354900
    },
    {
      "epoch": 3.7576394365898973,
      "grad_norm": 0.930579662322998,
      "learning_rate": 0.0003929639481250498,
      "loss": 0.6951,
      "step": 354950
    },
    {
      "epoch": 3.7581687583699006,
      "grad_norm": 1.0214831829071045,
      "learning_rate": 0.00039292605165256855,
      "loss": 0.7023,
      "step": 355000
    },
    {
      "epoch": 3.7581687583699006,
      "eval_loss": 0.4900137484073639,
      "eval_runtime": 46.8437,
      "eval_samples_per_second": 3584.9,
      "eval_steps_per_second": 448.129,
      "step": 355000
    },
    {
      "epoch": 3.758698080149904,
      "grad_norm": 0.9875390529632568,
      "learning_rate": 0.00039288815030064425,
      "loss": 0.682,
      "step": 355050
    },
    {
      "epoch": 3.7592274019299072,
      "grad_norm": 0.9571998715400696,
      "learning_rate": 0.0003928502440705709,
      "loss": 0.6939,
      "step": 355100
    },
    {
      "epoch": 3.7597567237099105,
      "grad_norm": 0.9042871594429016,
      "learning_rate": 0.0003928123329636426,
      "loss": 0.6987,
      "step": 355150
    },
    {
      "epoch": 3.760286045489914,
      "grad_norm": 1.065546989440918,
      "learning_rate": 0.0003927744169811537,
      "loss": 0.6863,
      "step": 355200
    },
    {
      "epoch": 3.760815367269917,
      "grad_norm": 0.9777845144271851,
      "learning_rate": 0.00039273649612439854,
      "loss": 0.6976,
      "step": 355250
    },
    {
      "epoch": 3.7613446890499205,
      "grad_norm": 0.9134430885314941,
      "learning_rate": 0.00039269857039467173,
      "loss": 0.6971,
      "step": 355300
    },
    {
      "epoch": 3.7618740108299233,
      "grad_norm": 1.0080862045288086,
      "learning_rate": 0.00039266063979326803,
      "loss": 0.7025,
      "step": 355350
    },
    {
      "epoch": 3.762403332609927,
      "grad_norm": 1.0775079727172852,
      "learning_rate": 0.00039262270432148245,
      "loss": 0.7016,
      "step": 355400
    },
    {
      "epoch": 3.76293265438993,
      "grad_norm": 1.01858651638031,
      "learning_rate": 0.00039258476398061,
      "loss": 0.692,
      "step": 355450
    },
    {
      "epoch": 3.7634619761699337,
      "grad_norm": 0.9386586546897888,
      "learning_rate": 0.0003925468187719461,
      "loss": 0.694,
      "step": 355500
    },
    {
      "epoch": 3.7634619761699337,
      "eval_loss": 0.48962557315826416,
      "eval_runtime": 46.8062,
      "eval_samples_per_second": 3587.77,
      "eval_steps_per_second": 448.487,
      "step": 355500
    },
    {
      "epoch": 3.7639912979499366,
      "grad_norm": 0.9254165887832642,
      "learning_rate": 0.00039250886869678596,
      "loss": 0.6938,
      "step": 355550
    },
    {
      "epoch": 3.76452061972994,
      "grad_norm": 0.9285764694213867,
      "learning_rate": 0.0003924709137564254,
      "loss": 0.7007,
      "step": 355600
    },
    {
      "epoch": 3.765049941509943,
      "grad_norm": 0.883870542049408,
      "learning_rate": 0.00039243295395216006,
      "loss": 0.7043,
      "step": 355650
    },
    {
      "epoch": 3.7655792632899465,
      "grad_norm": 1.0016294717788696,
      "learning_rate": 0.0003923949892852859,
      "loss": 0.6985,
      "step": 355700
    },
    {
      "epoch": 3.76610858506995,
      "grad_norm": 0.9697514176368713,
      "learning_rate": 0.00039235701975709903,
      "loss": 0.6889,
      "step": 355750
    },
    {
      "epoch": 3.766637906849953,
      "grad_norm": 0.9671214818954468,
      "learning_rate": 0.00039231904536889573,
      "loss": 0.7075,
      "step": 355800
    },
    {
      "epoch": 3.7671672286299565,
      "grad_norm": 0.9441342949867249,
      "learning_rate": 0.00039228106612197245,
      "loss": 0.6996,
      "step": 355850
    },
    {
      "epoch": 3.7676965504099598,
      "grad_norm": 0.9929513335227966,
      "learning_rate": 0.00039224384174730697,
      "loss": 0.7082,
      "step": 355900
    },
    {
      "epoch": 3.768225872189963,
      "grad_norm": 1.068015456199646,
      "learning_rate": 0.0003922058528839434,
      "loss": 0.6961,
      "step": 355950
    },
    {
      "epoch": 3.7687551939699664,
      "grad_norm": 0.8564633727073669,
      "learning_rate": 0.00039216785916572415,
      "loss": 0.6909,
      "step": 356000
    },
    {
      "epoch": 3.7687551939699664,
      "eval_loss": 0.486859530210495,
      "eval_runtime": 46.8079,
      "eval_samples_per_second": 3587.643,
      "eval_steps_per_second": 448.471,
      "step": 356000
    },
    {
      "epoch": 3.7692845157499697,
      "grad_norm": 0.9535242915153503,
      "learning_rate": 0.00039212986059394627,
      "loss": 0.6925,
      "step": 356050
    },
    {
      "epoch": 3.769813837529973,
      "grad_norm": 1.0488903522491455,
      "learning_rate": 0.0003920918571699072,
      "loss": 0.7019,
      "step": 356100
    },
    {
      "epoch": 3.7703431593099763,
      "grad_norm": 0.9683195352554321,
      "learning_rate": 0.00039205384889490414,
      "loss": 0.703,
      "step": 356150
    },
    {
      "epoch": 3.770872481089979,
      "grad_norm": 0.9951626062393188,
      "learning_rate": 0.00039201583577023487,
      "loss": 0.6905,
      "step": 356200
    },
    {
      "epoch": 3.771401802869983,
      "grad_norm": 0.9217661023139954,
      "learning_rate": 0.000391977817797197,
      "loss": 0.6903,
      "step": 356250
    },
    {
      "epoch": 3.771931124649986,
      "grad_norm": 0.8304852247238159,
      "learning_rate": 0.0003919397949770885,
      "loss": 0.7064,
      "step": 356300
    },
    {
      "epoch": 3.772460446429989,
      "grad_norm": 1.0048227310180664,
      "learning_rate": 0.0003919017673112074,
      "loss": 0.6934,
      "step": 356350
    },
    {
      "epoch": 3.7729897682099924,
      "grad_norm": 0.9925487041473389,
      "learning_rate": 0.0003918637348008521,
      "loss": 0.7088,
      "step": 356400
    },
    {
      "epoch": 3.7735190899899957,
      "grad_norm": 0.9919312596321106,
      "learning_rate": 0.00039182569744732087,
      "loss": 0.6989,
      "step": 356450
    },
    {
      "epoch": 3.774048411769999,
      "grad_norm": 0.9524515867233276,
      "learning_rate": 0.00039178765525191235,
      "loss": 0.6972,
      "step": 356500
    },
    {
      "epoch": 3.774048411769999,
      "eval_loss": 0.48753562569618225,
      "eval_runtime": 46.8879,
      "eval_samples_per_second": 3581.523,
      "eval_steps_per_second": 447.706,
      "step": 356500
    },
    {
      "epoch": 3.7745777335500024,
      "grad_norm": 1.1679116487503052,
      "learning_rate": 0.00039174960821592526,
      "loss": 0.694,
      "step": 356550
    },
    {
      "epoch": 3.7751070553300057,
      "grad_norm": 0.9088498950004578,
      "learning_rate": 0.0003917115563406586,
      "loss": 0.6931,
      "step": 356600
    },
    {
      "epoch": 3.775636377110009,
      "grad_norm": 1.0177106857299805,
      "learning_rate": 0.00039167349962741126,
      "loss": 0.694,
      "step": 356650
    },
    {
      "epoch": 3.7761656988900123,
      "grad_norm": 0.8570415377616882,
      "learning_rate": 0.0003916354380774827,
      "loss": 0.6922,
      "step": 356700
    },
    {
      "epoch": 3.7766950206700156,
      "grad_norm": 0.8829305171966553,
      "learning_rate": 0.0003915973716921722,
      "loss": 0.6966,
      "step": 356750
    },
    {
      "epoch": 3.777224342450019,
      "grad_norm": 0.9731466174125671,
      "learning_rate": 0.00039155930047277934,
      "loss": 0.6851,
      "step": 356800
    },
    {
      "epoch": 3.7777536642300222,
      "grad_norm": 1.0222923755645752,
      "learning_rate": 0.0003915212244206039,
      "loss": 0.7031,
      "step": 356850
    },
    {
      "epoch": 3.7782829860100255,
      "grad_norm": 0.9016731381416321,
      "learning_rate": 0.0003914831435369457,
      "loss": 0.6967,
      "step": 356900
    },
    {
      "epoch": 3.7788123077900284,
      "grad_norm": 0.9326549172401428,
      "learning_rate": 0.0003914450578231049,
      "loss": 0.6956,
      "step": 356950
    },
    {
      "epoch": 3.779341629570032,
      "grad_norm": 1.043163776397705,
      "learning_rate": 0.0003914069672803818,
      "loss": 0.7028,
      "step": 357000
    },
    {
      "epoch": 3.779341629570032,
      "eval_loss": 0.48558634519577026,
      "eval_runtime": 46.879,
      "eval_samples_per_second": 3582.202,
      "eval_steps_per_second": 447.791,
      "step": 357000
    },
    {
      "epoch": 3.779870951350035,
      "grad_norm": 0.8908265829086304,
      "learning_rate": 0.0003913688719100766,
      "loss": 0.6878,
      "step": 357050
    },
    {
      "epoch": 3.7804002731300383,
      "grad_norm": 0.9594445824623108,
      "learning_rate": 0.00039133077171348994,
      "loss": 0.6919,
      "step": 357100
    },
    {
      "epoch": 3.7809295949100417,
      "grad_norm": 0.9707273840904236,
      "learning_rate": 0.00039129266669192265,
      "loss": 0.6975,
      "step": 357150
    },
    {
      "epoch": 3.781458916690045,
      "grad_norm": 0.8870371580123901,
      "learning_rate": 0.00039125455684667544,
      "loss": 0.7043,
      "step": 357200
    },
    {
      "epoch": 3.7819882384700483,
      "grad_norm": 0.8781551718711853,
      "learning_rate": 0.0003912164421790495,
      "loss": 0.6905,
      "step": 357250
    },
    {
      "epoch": 3.7825175602500516,
      "grad_norm": 0.9765893816947937,
      "learning_rate": 0.000391178322690346,
      "loss": 0.69,
      "step": 357300
    },
    {
      "epoch": 3.783046882030055,
      "grad_norm": 1.024333119392395,
      "learning_rate": 0.0003911401983818664,
      "loss": 0.6909,
      "step": 357350
    },
    {
      "epoch": 3.783576203810058,
      "grad_norm": 1.0326353311538696,
      "learning_rate": 0.0003911020692549121,
      "loss": 0.7004,
      "step": 357400
    },
    {
      "epoch": 3.7841055255900615,
      "grad_norm": 1.005993127822876,
      "learning_rate": 0.00039106393531078496,
      "loss": 0.6913,
      "step": 357450
    },
    {
      "epoch": 3.784634847370065,
      "grad_norm": 1.0097591876983643,
      "learning_rate": 0.00039102579655078684,
      "loss": 0.7003,
      "step": 357500
    },
    {
      "epoch": 3.784634847370065,
      "eval_loss": 0.48666679859161377,
      "eval_runtime": 46.905,
      "eval_samples_per_second": 3580.217,
      "eval_steps_per_second": 447.543,
      "step": 357500
    },
    {
      "epoch": 3.785164169150068,
      "grad_norm": 0.9660471677780151,
      "learning_rate": 0.0003909876529762197,
      "loss": 0.6856,
      "step": 357550
    },
    {
      "epoch": 3.7856934909300715,
      "grad_norm": 0.9075292944908142,
      "learning_rate": 0.00039094950458838575,
      "loss": 0.6947,
      "step": 357600
    },
    {
      "epoch": 3.7862228127100748,
      "grad_norm": 1.0002833604812622,
      "learning_rate": 0.00039091135138858747,
      "loss": 0.6996,
      "step": 357650
    },
    {
      "epoch": 3.7867521344900776,
      "grad_norm": 1.0521748065948486,
      "learning_rate": 0.00039087319337812734,
      "loss": 0.696,
      "step": 357700
    },
    {
      "epoch": 3.7872814562700814,
      "grad_norm": 1.0757280588150024,
      "learning_rate": 0.00039083503055830797,
      "loss": 0.6964,
      "step": 357750
    },
    {
      "epoch": 3.7878107780500843,
      "grad_norm": 0.9095944762229919,
      "learning_rate": 0.00039079686293043235,
      "loss": 0.7015,
      "step": 357800
    },
    {
      "epoch": 3.7883400998300876,
      "grad_norm": 0.892776370048523,
      "learning_rate": 0.0003907586904958035,
      "loss": 0.6996,
      "step": 357850
    },
    {
      "epoch": 3.788869421610091,
      "grad_norm": 1.015270709991455,
      "learning_rate": 0.00039072051325572454,
      "loss": 0.6858,
      "step": 357900
    },
    {
      "epoch": 3.789398743390094,
      "grad_norm": 1.0363595485687256,
      "learning_rate": 0.00039068233121149887,
      "loss": 0.6882,
      "step": 357950
    },
    {
      "epoch": 3.7899280651700975,
      "grad_norm": 0.9418272972106934,
      "learning_rate": 0.00039064414436443,
      "loss": 0.695,
      "step": 358000
    },
    {
      "epoch": 3.7899280651700975,
      "eval_loss": 0.48649880290031433,
      "eval_runtime": 46.8811,
      "eval_samples_per_second": 3582.037,
      "eval_steps_per_second": 447.771,
      "step": 358000
    },
    {
      "epoch": 3.790457386950101,
      "grad_norm": 0.9454373717308044,
      "learning_rate": 0.0003906059527158217,
      "loss": 0.6997,
      "step": 358050
    },
    {
      "epoch": 3.790986708730104,
      "grad_norm": 0.9789563417434692,
      "learning_rate": 0.0003905677562669776,
      "loss": 0.693,
      "step": 358100
    },
    {
      "epoch": 3.7915160305101074,
      "grad_norm": 1.0328289270401,
      "learning_rate": 0.00039053031909117855,
      "loss": 0.6916,
      "step": 358150
    },
    {
      "epoch": 3.7920453522901107,
      "grad_norm": 1.0595309734344482,
      "learning_rate": 0.00039049211314171517,
      "loss": 0.6821,
      "step": 358200
    },
    {
      "epoch": 3.792574674070114,
      "grad_norm": 0.9358928799629211,
      "learning_rate": 0.0003904539023959026,
      "loss": 0.6966,
      "step": 358250
    },
    {
      "epoch": 3.7931039958501174,
      "grad_norm": 0.9178597927093506,
      "learning_rate": 0.00039041568685504525,
      "loss": 0.684,
      "step": 358300
    },
    {
      "epoch": 3.7936333176301207,
      "grad_norm": 1.0373088121414185,
      "learning_rate": 0.00039037746652044794,
      "loss": 0.6952,
      "step": 358350
    },
    {
      "epoch": 3.794162639410124,
      "grad_norm": 0.9520962834358215,
      "learning_rate": 0.00039033924139341537,
      "loss": 0.6972,
      "step": 358400
    },
    {
      "epoch": 3.794691961190127,
      "grad_norm": 0.9425652623176575,
      "learning_rate": 0.00039030101147525257,
      "loss": 0.6912,
      "step": 358450
    },
    {
      "epoch": 3.7952212829701306,
      "grad_norm": 0.900726318359375,
      "learning_rate": 0.0003902627767672646,
      "loss": 0.6938,
      "step": 358500
    },
    {
      "epoch": 3.7952212829701306,
      "eval_loss": 0.4876337945461273,
      "eval_runtime": 46.811,
      "eval_samples_per_second": 3587.406,
      "eval_steps_per_second": 448.442,
      "step": 358500
    },
    {
      "epoch": 3.7957506047501335,
      "grad_norm": 1.0530892610549927,
      "learning_rate": 0.0003902245372707569,
      "loss": 0.6917,
      "step": 358550
    },
    {
      "epoch": 3.796279926530137,
      "grad_norm": 0.9437915682792664,
      "learning_rate": 0.000390186292987035,
      "loss": 0.6858,
      "step": 358600
    },
    {
      "epoch": 3.79680924831014,
      "grad_norm": 1.0328567028045654,
      "learning_rate": 0.00039014804391740443,
      "loss": 0.7003,
      "step": 358650
    },
    {
      "epoch": 3.7973385700901434,
      "grad_norm": 1.0045852661132812,
      "learning_rate": 0.00039010979006317106,
      "loss": 0.6983,
      "step": 358700
    },
    {
      "epoch": 3.7978678918701467,
      "grad_norm": 0.9558843970298767,
      "learning_rate": 0.00039007153142564077,
      "loss": 0.6988,
      "step": 358750
    },
    {
      "epoch": 3.79839721365015,
      "grad_norm": 0.9475605487823486,
      "learning_rate": 0.0003900332680061198,
      "loss": 0.6987,
      "step": 358800
    },
    {
      "epoch": 3.7989265354301534,
      "grad_norm": 0.9335848689079285,
      "learning_rate": 0.00038999499980591444,
      "loss": 0.7086,
      "step": 358850
    },
    {
      "epoch": 3.7994558572101567,
      "grad_norm": 0.9521294832229614,
      "learning_rate": 0.0003899567268263312,
      "loss": 0.6993,
      "step": 358900
    },
    {
      "epoch": 3.79998517899016,
      "grad_norm": 1.0542123317718506,
      "learning_rate": 0.0003899184490686765,
      "loss": 0.693,
      "step": 358950
    },
    {
      "epoch": 3.8005145007701633,
      "grad_norm": 1.0713956356048584,
      "learning_rate": 0.00038988016653425736,
      "loss": 0.6988,
      "step": 359000
    },
    {
      "epoch": 3.8005145007701633,
      "eval_loss": 0.4835030436515808,
      "eval_runtime": 46.7449,
      "eval_samples_per_second": 3592.475,
      "eval_steps_per_second": 449.075,
      "step": 359000
    },
    {
      "epoch": 3.8010438225501666,
      "grad_norm": 1.0087614059448242,
      "learning_rate": 0.0003898418792243805,
      "loss": 0.6924,
      "step": 359050
    },
    {
      "epoch": 3.80157314433017,
      "grad_norm": 0.9758632183074951,
      "learning_rate": 0.00038980358714035335,
      "loss": 0.691,
      "step": 359100
    },
    {
      "epoch": 3.802102466110173,
      "grad_norm": 1.0860595703125,
      "learning_rate": 0.0003897652902834829,
      "loss": 0.6945,
      "step": 359150
    },
    {
      "epoch": 3.802631787890176,
      "grad_norm": 0.9541766047477722,
      "learning_rate": 0.0003897269886550767,
      "loss": 0.6836,
      "step": 359200
    },
    {
      "epoch": 3.80316110967018,
      "grad_norm": 0.8910118341445923,
      "learning_rate": 0.0003896886822564424,
      "loss": 0.6954,
      "step": 359250
    },
    {
      "epoch": 3.8036904314501827,
      "grad_norm": 1.0169280767440796,
      "learning_rate": 0.00038965037108888766,
      "loss": 0.6849,
      "step": 359300
    },
    {
      "epoch": 3.804219753230186,
      "grad_norm": 0.9930379390716553,
      "learning_rate": 0.0003896120551537205,
      "loss": 0.6876,
      "step": 359350
    },
    {
      "epoch": 3.8047490750101893,
      "grad_norm": 0.8909506797790527,
      "learning_rate": 0.00038957373445224896,
      "loss": 0.6876,
      "step": 359400
    },
    {
      "epoch": 3.8052783967901926,
      "grad_norm": 1.0504387617111206,
      "learning_rate": 0.0003895354089857813,
      "loss": 0.6955,
      "step": 359450
    },
    {
      "epoch": 3.805807718570196,
      "grad_norm": 0.9341616034507751,
      "learning_rate": 0.00038949707875562603,
      "loss": 0.6957,
      "step": 359500
    },
    {
      "epoch": 3.805807718570196,
      "eval_loss": 0.4849807322025299,
      "eval_runtime": 46.8653,
      "eval_samples_per_second": 3583.25,
      "eval_steps_per_second": 447.922,
      "step": 359500
    },
    {
      "epoch": 3.8063370403501993,
      "grad_norm": 1.0263971090316772,
      "learning_rate": 0.00038945874376309156,
      "loss": 0.6925,
      "step": 359550
    },
    {
      "epoch": 3.8068663621302026,
      "grad_norm": 1.012575626373291,
      "learning_rate": 0.00038942040400948675,
      "loss": 0.6883,
      "step": 359600
    },
    {
      "epoch": 3.807395683910206,
      "grad_norm": 1.071431279182434,
      "learning_rate": 0.0003893820594961205,
      "loss": 0.692,
      "step": 359650
    },
    {
      "epoch": 3.807925005690209,
      "grad_norm": 0.9079264402389526,
      "learning_rate": 0.00038934371022430184,
      "loss": 0.6897,
      "step": 359700
    },
    {
      "epoch": 3.8084543274702125,
      "grad_norm": 0.8056173324584961,
      "learning_rate": 0.00038930535619534004,
      "loss": 0.6889,
      "step": 359750
    },
    {
      "epoch": 3.808983649250216,
      "grad_norm": 0.926633894443512,
      "learning_rate": 0.0003892669974105444,
      "loss": 0.7019,
      "step": 359800
    },
    {
      "epoch": 3.809512971030219,
      "grad_norm": 1.1815298795700073,
      "learning_rate": 0.00038922863387122453,
      "loss": 0.6868,
      "step": 359850
    },
    {
      "epoch": 3.8100422928102224,
      "grad_norm": 0.9820325374603271,
      "learning_rate": 0.00038919026557869026,
      "loss": 0.6941,
      "step": 359900
    },
    {
      "epoch": 3.8105716145902253,
      "grad_norm": 0.9377942085266113,
      "learning_rate": 0.00038915189253425133,
      "loss": 0.6924,
      "step": 359950
    },
    {
      "epoch": 3.811100936370229,
      "grad_norm": 0.87493497133255,
      "learning_rate": 0.0003891135147392178,
      "loss": 0.6904,
      "step": 360000
    },
    {
      "epoch": 3.811100936370229,
      "eval_loss": 0.4838249981403351,
      "eval_runtime": 46.7558,
      "eval_samples_per_second": 3591.638,
      "eval_steps_per_second": 448.971,
      "step": 360000
    },
    {
      "epoch": 3.811630258150232,
      "grad_norm": 0.931608259677887,
      "learning_rate": 0.00038907513219489995,
      "loss": 0.6977,
      "step": 360050
    },
    {
      "epoch": 3.8121595799302352,
      "grad_norm": 0.9961100816726685,
      "learning_rate": 0.00038903674490260796,
      "loss": 0.694,
      "step": 360100
    },
    {
      "epoch": 3.8126889017102386,
      "grad_norm": 1.0379819869995117,
      "learning_rate": 0.0003889983528636526,
      "loss": 0.6933,
      "step": 360150
    },
    {
      "epoch": 3.813218223490242,
      "grad_norm": 0.8884109854698181,
      "learning_rate": 0.0003889599560793444,
      "loss": 0.7013,
      "step": 360200
    },
    {
      "epoch": 3.813747545270245,
      "grad_norm": 1.0039877891540527,
      "learning_rate": 0.0003889223226280445,
      "loss": 0.6966,
      "step": 360250
    },
    {
      "epoch": 3.8142768670502485,
      "grad_norm": 1.0402822494506836,
      "learning_rate": 0.0003888839164518052,
      "loss": 0.6851,
      "step": 360300
    },
    {
      "epoch": 3.814806188830252,
      "grad_norm": 0.9841439723968506,
      "learning_rate": 0.00038884550553412,
      "loss": 0.6909,
      "step": 360350
    },
    {
      "epoch": 3.815335510610255,
      "grad_norm": 0.917705237865448,
      "learning_rate": 0.00038880708987630016,
      "loss": 0.6951,
      "step": 360400
    },
    {
      "epoch": 3.8158648323902584,
      "grad_norm": 0.9690365195274353,
      "learning_rate": 0.00038876866947965715,
      "loss": 0.6924,
      "step": 360450
    },
    {
      "epoch": 3.8163941541702617,
      "grad_norm": 0.9583523273468018,
      "learning_rate": 0.00038873024434550265,
      "loss": 0.6975,
      "step": 360500
    },
    {
      "epoch": 3.8163941541702617,
      "eval_loss": 0.48534122109413147,
      "eval_runtime": 46.867,
      "eval_samples_per_second": 3583.118,
      "eval_steps_per_second": 447.906,
      "step": 360500
    },
    {
      "epoch": 3.816923475950265,
      "grad_norm": 1.1122126579284668,
      "learning_rate": 0.00038869181447514844,
      "loss": 0.7101,
      "step": 360550
    },
    {
      "epoch": 3.8174527977302684,
      "grad_norm": 1.0525610446929932,
      "learning_rate": 0.00038865337986990656,
      "loss": 0.6993,
      "step": 360600
    },
    {
      "epoch": 3.8179821195102717,
      "grad_norm": 1.0094088315963745,
      "learning_rate": 0.0003886149405310893,
      "loss": 0.6963,
      "step": 360650
    },
    {
      "epoch": 3.8185114412902745,
      "grad_norm": 0.9355990290641785,
      "learning_rate": 0.0003885764964600086,
      "loss": 0.6792,
      "step": 360700
    },
    {
      "epoch": 3.8190407630702783,
      "grad_norm": 0.9134108424186707,
      "learning_rate": 0.0003885380476579772,
      "loss": 0.691,
      "step": 360750
    },
    {
      "epoch": 3.819570084850281,
      "grad_norm": 1.031440258026123,
      "learning_rate": 0.0003884995941263077,
      "loss": 0.6946,
      "step": 360800
    },
    {
      "epoch": 3.8200994066302845,
      "grad_norm": 0.9722421169281006,
      "learning_rate": 0.0003884611358663128,
      "loss": 0.6904,
      "step": 360850
    },
    {
      "epoch": 3.8206287284102878,
      "grad_norm": 0.9019936919212341,
      "learning_rate": 0.0003884226728793055,
      "loss": 0.6885,
      "step": 360900
    },
    {
      "epoch": 3.821158050190291,
      "grad_norm": 0.8761774897575378,
      "learning_rate": 0.000388384205166599,
      "loss": 0.6982,
      "step": 360950
    },
    {
      "epoch": 3.8216873719702944,
      "grad_norm": 0.9619042277336121,
      "learning_rate": 0.0003883457327295064,
      "loss": 0.6749,
      "step": 361000
    },
    {
      "epoch": 3.8216873719702944,
      "eval_loss": 0.4834655225276947,
      "eval_runtime": 46.8298,
      "eval_samples_per_second": 3585.964,
      "eval_steps_per_second": 448.261,
      "step": 361000
    },
    {
      "epoch": 3.8222166937502977,
      "grad_norm": 1.104036808013916,
      "learning_rate": 0.0003883072555693412,
      "loss": 0.6945,
      "step": 361050
    },
    {
      "epoch": 3.822746015530301,
      "grad_norm": 1.0048305988311768,
      "learning_rate": 0.0003882687736874171,
      "loss": 0.7042,
      "step": 361100
    },
    {
      "epoch": 3.8232753373103043,
      "grad_norm": 0.9570140242576599,
      "learning_rate": 0.0003882302870850477,
      "loss": 0.7024,
      "step": 361150
    },
    {
      "epoch": 3.8238046590903076,
      "grad_norm": 0.9722259044647217,
      "learning_rate": 0.0003881917957635471,
      "loss": 0.6943,
      "step": 361200
    },
    {
      "epoch": 3.824333980870311,
      "grad_norm": 0.8444556593894958,
      "learning_rate": 0.0003881532997242292,
      "loss": 0.7025,
      "step": 361250
    },
    {
      "epoch": 3.8248633026503143,
      "grad_norm": 1.1725184917449951,
      "learning_rate": 0.0003881147989684083,
      "loss": 0.6882,
      "step": 361300
    },
    {
      "epoch": 3.8253926244303176,
      "grad_norm": 1.0369482040405273,
      "learning_rate": 0.0003880762934973988,
      "loss": 0.7101,
      "step": 361350
    },
    {
      "epoch": 3.825921946210321,
      "grad_norm": 0.9618353247642517,
      "learning_rate": 0.0003880377833125153,
      "loss": 0.6987,
      "step": 361400
    },
    {
      "epoch": 3.8264512679903238,
      "grad_norm": 0.8380071520805359,
      "learning_rate": 0.0003879992684150725,
      "loss": 0.6934,
      "step": 361450
    },
    {
      "epoch": 3.8269805897703275,
      "grad_norm": 1.0076029300689697,
      "learning_rate": 0.0003879607488063853,
      "loss": 0.6885,
      "step": 361500
    },
    {
      "epoch": 3.8269805897703275,
      "eval_loss": 0.4842720031738281,
      "eval_runtime": 47.0615,
      "eval_samples_per_second": 3568.313,
      "eval_steps_per_second": 446.055,
      "step": 361500
    },
    {
      "epoch": 3.8275099115503304,
      "grad_norm": 0.9674229621887207,
      "learning_rate": 0.0003879222244877688,
      "loss": 0.7,
      "step": 361550
    },
    {
      "epoch": 3.8280392333303337,
      "grad_norm": 0.9459137320518494,
      "learning_rate": 0.000387883695460538,
      "loss": 0.6925,
      "step": 361600
    },
    {
      "epoch": 3.828568555110337,
      "grad_norm": 0.9068873524665833,
      "learning_rate": 0.00038784516172600845,
      "loss": 0.6959,
      "step": 361650
    },
    {
      "epoch": 3.8290978768903403,
      "grad_norm": 0.8610949516296387,
      "learning_rate": 0.00038780662328549573,
      "loss": 0.6809,
      "step": 361700
    },
    {
      "epoch": 3.8296271986703436,
      "grad_norm": 0.8768677711486816,
      "learning_rate": 0.0003877680801403153,
      "loss": 0.6896,
      "step": 361750
    },
    {
      "epoch": 3.830156520450347,
      "grad_norm": 0.9498044848442078,
      "learning_rate": 0.0003877295322917832,
      "loss": 0.6898,
      "step": 361800
    },
    {
      "epoch": 3.8306858422303502,
      "grad_norm": 1.0228513479232788,
      "learning_rate": 0.00038769097974121534,
      "loss": 0.6837,
      "step": 361850
    },
    {
      "epoch": 3.8312151640103536,
      "grad_norm": 1.0186514854431152,
      "learning_rate": 0.00038765242248992797,
      "loss": 0.6918,
      "step": 361900
    },
    {
      "epoch": 3.831744485790357,
      "grad_norm": 1.0558940172195435,
      "learning_rate": 0.0003876138605392374,
      "loss": 0.6838,
      "step": 361950
    },
    {
      "epoch": 3.83227380757036,
      "grad_norm": 0.9662331938743591,
      "learning_rate": 0.00038757529389046007,
      "loss": 0.6967,
      "step": 362000
    },
    {
      "epoch": 3.83227380757036,
      "eval_loss": 0.48492735624313354,
      "eval_runtime": 46.875,
      "eval_samples_per_second": 3582.509,
      "eval_steps_per_second": 447.83,
      "step": 362000
    },
    {
      "epoch": 3.8328031293503635,
      "grad_norm": 1.0487337112426758,
      "learning_rate": 0.0003875367225449127,
      "loss": 0.6859,
      "step": 362050
    },
    {
      "epoch": 3.833332451130367,
      "grad_norm": 1.0263934135437012,
      "learning_rate": 0.00038749814650391204,
      "loss": 0.6834,
      "step": 362100
    },
    {
      "epoch": 3.83386177291037,
      "grad_norm": 1.0804691314697266,
      "learning_rate": 0.00038745956576877503,
      "loss": 0.6904,
      "step": 362150
    },
    {
      "epoch": 3.834391094690373,
      "grad_norm": 1.0212938785552979,
      "learning_rate": 0.00038742098034081886,
      "loss": 0.6889,
      "step": 362200
    },
    {
      "epoch": 3.8349204164703767,
      "grad_norm": 0.9715682864189148,
      "learning_rate": 0.00038738239022136084,
      "loss": 0.691,
      "step": 362250
    },
    {
      "epoch": 3.8354497382503796,
      "grad_norm": 1.003645420074463,
      "learning_rate": 0.0003873445673538666,
      "loss": 0.7007,
      "step": 362300
    },
    {
      "epoch": 3.835979060030383,
      "grad_norm": 0.8231258392333984,
      "learning_rate": 0.00038730596794912174,
      "loss": 0.6881,
      "step": 362350
    },
    {
      "epoch": 3.8365083818103862,
      "grad_norm": 0.9979062080383301,
      "learning_rate": 0.0003872673638568015,
      "loss": 0.6809,
      "step": 362400
    },
    {
      "epoch": 3.8370377035903895,
      "grad_norm": 0.9004082083702087,
      "learning_rate": 0.00038722875507822384,
      "loss": 0.6883,
      "step": 362450
    },
    {
      "epoch": 3.837567025370393,
      "grad_norm": 0.9400088787078857,
      "learning_rate": 0.00038719014161470676,
      "loss": 0.6914,
      "step": 362500
    },
    {
      "epoch": 3.837567025370393,
      "eval_loss": 0.48286738991737366,
      "eval_runtime": 46.9046,
      "eval_samples_per_second": 3580.247,
      "eval_steps_per_second": 447.547,
      "step": 362500
    },
    {
      "epoch": 3.838096347150396,
      "grad_norm": 1.0031273365020752,
      "learning_rate": 0.0003871515234675687,
      "loss": 0.7001,
      "step": 362550
    },
    {
      "epoch": 3.8386256689303995,
      "grad_norm": 1.0435329675674438,
      "learning_rate": 0.0003871129006381278,
      "loss": 0.704,
      "step": 362600
    },
    {
      "epoch": 3.839154990710403,
      "grad_norm": 0.9646249413490295,
      "learning_rate": 0.0003870742731277028,
      "loss": 0.7028,
      "step": 362650
    },
    {
      "epoch": 3.839684312490406,
      "grad_norm": 0.8728808760643005,
      "learning_rate": 0.0003870356409376123,
      "loss": 0.6854,
      "step": 362700
    },
    {
      "epoch": 3.8402136342704094,
      "grad_norm": 0.9625963568687439,
      "learning_rate": 0.0003869970040691754,
      "loss": 0.6851,
      "step": 362750
    },
    {
      "epoch": 3.8407429560504127,
      "grad_norm": 0.8453540802001953,
      "learning_rate": 0.000386958362523711,
      "loss": 0.6884,
      "step": 362800
    },
    {
      "epoch": 3.841272277830416,
      "grad_norm": 0.9774687886238098,
      "learning_rate": 0.0003869197163025383,
      "loss": 0.701,
      "step": 362850
    },
    {
      "epoch": 3.8418015996104193,
      "grad_norm": 1.0567582845687866,
      "learning_rate": 0.0003868810654069767,
      "loss": 0.6925,
      "step": 362900
    },
    {
      "epoch": 3.842330921390422,
      "grad_norm": 1.0134707689285278,
      "learning_rate": 0.00038684240983834575,
      "loss": 0.7039,
      "step": 362950
    },
    {
      "epoch": 3.842860243170426,
      "grad_norm": 1.0426973104476929,
      "learning_rate": 0.00038680374959796504,
      "loss": 0.706,
      "step": 363000
    },
    {
      "epoch": 3.842860243170426,
      "eval_loss": 0.48186224699020386,
      "eval_runtime": 46.8835,
      "eval_samples_per_second": 3581.856,
      "eval_steps_per_second": 447.748,
      "step": 363000
    },
    {
      "epoch": 3.843389564950429,
      "grad_norm": 0.9667883515357971,
      "learning_rate": 0.00038676508468715455,
      "loss": 0.6983,
      "step": 363050
    },
    {
      "epoch": 3.843918886730432,
      "grad_norm": 1.0376368761062622,
      "learning_rate": 0.0003867264151072343,
      "loss": 0.6942,
      "step": 363100
    },
    {
      "epoch": 3.8444482085104354,
      "grad_norm": 1.0538667440414429,
      "learning_rate": 0.0003866877408595243,
      "loss": 0.6857,
      "step": 363150
    },
    {
      "epoch": 3.8449775302904388,
      "grad_norm": 1.0479426383972168,
      "learning_rate": 0.0003866490619453449,
      "loss": 0.69,
      "step": 363200
    },
    {
      "epoch": 3.845506852070442,
      "grad_norm": 0.907312273979187,
      "learning_rate": 0.00038661037836601675,
      "loss": 0.6926,
      "step": 363250
    },
    {
      "epoch": 3.8460361738504454,
      "grad_norm": 0.9761319756507874,
      "learning_rate": 0.00038657169012286033,
      "loss": 0.6898,
      "step": 363300
    },
    {
      "epoch": 3.8465654956304487,
      "grad_norm": 0.8332398533821106,
      "learning_rate": 0.0003865329972171965,
      "loss": 0.6974,
      "step": 363350
    },
    {
      "epoch": 3.847094817410452,
      "grad_norm": 1.0378857851028442,
      "learning_rate": 0.0003864942996503462,
      "loss": 0.6789,
      "step": 363400
    },
    {
      "epoch": 3.8476241391904553,
      "grad_norm": 1.0786563158035278,
      "learning_rate": 0.00038645559742363054,
      "loss": 0.6879,
      "step": 363450
    },
    {
      "epoch": 3.8481534609704586,
      "grad_norm": 1.0676592588424683,
      "learning_rate": 0.00038641689053837085,
      "loss": 0.7078,
      "step": 363500
    },
    {
      "epoch": 3.8481534609704586,
      "eval_loss": 0.48100218176841736,
      "eval_runtime": 46.8407,
      "eval_samples_per_second": 3585.132,
      "eval_steps_per_second": 448.158,
      "step": 363500
    },
    {
      "epoch": 3.848682782750462,
      "grad_norm": 0.9991433620452881,
      "learning_rate": 0.0003863781789958886,
      "loss": 0.6873,
      "step": 363550
    },
    {
      "epoch": 3.8492121045304653,
      "grad_norm": 1.0037702322006226,
      "learning_rate": 0.0003863394627975053,
      "loss": 0.6826,
      "step": 363600
    },
    {
      "epoch": 3.8497414263104686,
      "grad_norm": 0.9958546757698059,
      "learning_rate": 0.0003863007419445427,
      "loss": 0.694,
      "step": 363650
    },
    {
      "epoch": 3.8502707480904714,
      "grad_norm": 1.0019291639328003,
      "learning_rate": 0.0003862620164383228,
      "loss": 0.6852,
      "step": 363700
    },
    {
      "epoch": 3.850800069870475,
      "grad_norm": 1.0187453031539917,
      "learning_rate": 0.0003862232862801677,
      "loss": 0.6918,
      "step": 363750
    },
    {
      "epoch": 3.851329391650478,
      "grad_norm": 0.959117591381073,
      "learning_rate": 0.0003861845514713994,
      "loss": 0.6966,
      "step": 363800
    },
    {
      "epoch": 3.8518587134304814,
      "grad_norm": 0.9973648190498352,
      "learning_rate": 0.0003861458120133406,
      "loss": 0.697,
      "step": 363850
    },
    {
      "epoch": 3.8523880352104847,
      "grad_norm": 1.0044265985488892,
      "learning_rate": 0.0003861070679073136,
      "loss": 0.6949,
      "step": 363900
    },
    {
      "epoch": 3.852917356990488,
      "grad_norm": 0.9777194857597351,
      "learning_rate": 0.00038606831915464134,
      "loss": 0.683,
      "step": 363950
    },
    {
      "epoch": 3.8534466787704913,
      "grad_norm": 1.0583890676498413,
      "learning_rate": 0.0003860295657566465,
      "loss": 0.6732,
      "step": 364000
    },
    {
      "epoch": 3.8534466787704913,
      "eval_loss": 0.47987616062164307,
      "eval_runtime": 46.8621,
      "eval_samples_per_second": 3583.492,
      "eval_steps_per_second": 447.953,
      "step": 364000
    },
    {
      "epoch": 3.8539760005504946,
      "grad_norm": 1.0070600509643555,
      "learning_rate": 0.00038599080771465217,
      "loss": 0.7031,
      "step": 364050
    },
    {
      "epoch": 3.854505322330498,
      "grad_norm": 0.9796402454376221,
      "learning_rate": 0.0003859520450299815,
      "loss": 0.6867,
      "step": 364100
    },
    {
      "epoch": 3.8550346441105012,
      "grad_norm": 0.9503567218780518,
      "learning_rate": 0.00038591327770395796,
      "loss": 0.6858,
      "step": 364150
    },
    {
      "epoch": 3.8555639658905045,
      "grad_norm": 1.0603872537612915,
      "learning_rate": 0.0003858745057379049,
      "loss": 0.6958,
      "step": 364200
    },
    {
      "epoch": 3.856093287670508,
      "grad_norm": 0.9449360370635986,
      "learning_rate": 0.00038583572913314607,
      "loss": 0.687,
      "step": 364250
    },
    {
      "epoch": 3.856622609450511,
      "grad_norm": 1.0474445819854736,
      "learning_rate": 0.00038579694789100526,
      "loss": 0.6895,
      "step": 364300
    },
    {
      "epoch": 3.8571519312305145,
      "grad_norm": 1.0304487943649292,
      "learning_rate": 0.0003857589377757952,
      "loss": 0.6882,
      "step": 364350
    },
    {
      "epoch": 3.857681253010518,
      "grad_norm": 0.9574303030967712,
      "learning_rate": 0.00038572014735554426,
      "loss": 0.6975,
      "step": 364400
    },
    {
      "epoch": 3.8582105747905207,
      "grad_norm": 0.8822356462478638,
      "learning_rate": 0.00038568135230185725,
      "loss": 0.6895,
      "step": 364450
    },
    {
      "epoch": 3.8587398965705244,
      "grad_norm": 1.0192699432373047,
      "learning_rate": 0.00038564255261605855,
      "loss": 0.6926,
      "step": 364500
    },
    {
      "epoch": 3.8587398965705244,
      "eval_loss": 0.4820549190044403,
      "eval_runtime": 46.7628,
      "eval_samples_per_second": 3591.099,
      "eval_steps_per_second": 448.903,
      "step": 364500
    },
    {
      "epoch": 3.8592692183505273,
      "grad_norm": 0.9081785082817078,
      "learning_rate": 0.000385603748299473,
      "loss": 0.6958,
      "step": 364550
    },
    {
      "epoch": 3.8597985401305306,
      "grad_norm": 1.0232652425765991,
      "learning_rate": 0.0003855649393534251,
      "loss": 0.6802,
      "step": 364600
    },
    {
      "epoch": 3.860327861910534,
      "grad_norm": 0.978728711605072,
      "learning_rate": 0.00038552612577923986,
      "loss": 0.6855,
      "step": 364650
    },
    {
      "epoch": 3.860857183690537,
      "grad_norm": 0.9451286196708679,
      "learning_rate": 0.00038548730757824245,
      "loss": 0.6961,
      "step": 364700
    },
    {
      "epoch": 3.8613865054705405,
      "grad_norm": 0.9618389010429382,
      "learning_rate": 0.00038544848475175803,
      "loss": 0.6908,
      "step": 364750
    },
    {
      "epoch": 3.861915827250544,
      "grad_norm": 0.9951555728912354,
      "learning_rate": 0.00038540965730111205,
      "loss": 0.6956,
      "step": 364800
    },
    {
      "epoch": 3.862445149030547,
      "grad_norm": 1.0325450897216797,
      "learning_rate": 0.00038537082522763,
      "loss": 0.6792,
      "step": 364850
    },
    {
      "epoch": 3.8629744708105505,
      "grad_norm": 0.9218809604644775,
      "learning_rate": 0.0003853319885326376,
      "loss": 0.699,
      "step": 364900
    },
    {
      "epoch": 3.8635037925905538,
      "grad_norm": 1.0324755907058716,
      "learning_rate": 0.00038529314721746076,
      "loss": 0.6967,
      "step": 364950
    },
    {
      "epoch": 3.864033114370557,
      "grad_norm": 1.0249178409576416,
      "learning_rate": 0.00038525430128342553,
      "loss": 0.6901,
      "step": 365000
    },
    {
      "epoch": 3.864033114370557,
      "eval_loss": 0.48083949089050293,
      "eval_runtime": 46.8529,
      "eval_samples_per_second": 3584.195,
      "eval_steps_per_second": 448.04,
      "step": 365000
    },
    {
      "epoch": 3.8645624361505604,
      "grad_norm": 1.0718779563903809,
      "learning_rate": 0.00038521545073185804,
      "loss": 0.6758,
      "step": 365050
    },
    {
      "epoch": 3.8650917579305637,
      "grad_norm": 1.0501561164855957,
      "learning_rate": 0.0003851765955640846,
      "loss": 0.6956,
      "step": 365100
    },
    {
      "epoch": 3.865621079710567,
      "grad_norm": 0.9539352655410767,
      "learning_rate": 0.0003851377357814318,
      "loss": 0.6861,
      "step": 365150
    },
    {
      "epoch": 3.86615040149057,
      "grad_norm": 0.9424963593482971,
      "learning_rate": 0.00038509887138522624,
      "loss": 0.6788,
      "step": 365200
    },
    {
      "epoch": 3.8666797232705736,
      "grad_norm": 0.9916601777076721,
      "learning_rate": 0.0003850600023767948,
      "loss": 0.6936,
      "step": 365250
    },
    {
      "epoch": 3.8672090450505765,
      "grad_norm": 1.029770851135254,
      "learning_rate": 0.00038502112875746437,
      "loss": 0.694,
      "step": 365300
    },
    {
      "epoch": 3.8677383668305803,
      "grad_norm": 0.9986363053321838,
      "learning_rate": 0.00038498225052856216,
      "loss": 0.6958,
      "step": 365350
    },
    {
      "epoch": 3.868267688610583,
      "grad_norm": 1.00587797164917,
      "learning_rate": 0.00038494336769141535,
      "loss": 0.6952,
      "step": 365400
    },
    {
      "epoch": 3.8687970103905864,
      "grad_norm": 0.9230544567108154,
      "learning_rate": 0.0003849044802473516,
      "loss": 0.6904,
      "step": 365450
    },
    {
      "epoch": 3.8693263321705897,
      "grad_norm": 0.9381579160690308,
      "learning_rate": 0.00038486558819769825,
      "loss": 0.7007,
      "step": 365500
    },
    {
      "epoch": 3.8693263321705897,
      "eval_loss": 0.4841938018798828,
      "eval_runtime": 46.879,
      "eval_samples_per_second": 3582.204,
      "eval_steps_per_second": 447.791,
      "step": 365500
    },
    {
      "epoch": 3.869855653950593,
      "grad_norm": 0.9275538921356201,
      "learning_rate": 0.0003848266915437832,
      "loss": 0.7018,
      "step": 365550
    },
    {
      "epoch": 3.8703849757305964,
      "grad_norm": 0.9773141145706177,
      "learning_rate": 0.00038478779028693435,
      "loss": 0.7093,
      "step": 365600
    },
    {
      "epoch": 3.8709142975105997,
      "grad_norm": 1.0185786485671997,
      "learning_rate": 0.00038474888442847975,
      "loss": 0.6949,
      "step": 365650
    },
    {
      "epoch": 3.871443619290603,
      "grad_norm": 1.0216833353042603,
      "learning_rate": 0.00038470997396974774,
      "loss": 0.7019,
      "step": 365700
    },
    {
      "epoch": 3.8719729410706063,
      "grad_norm": 1.0600601434707642,
      "learning_rate": 0.00038467105891206647,
      "loss": 0.7019,
      "step": 365750
    },
    {
      "epoch": 3.8725022628506096,
      "grad_norm": 1.047892451286316,
      "learning_rate": 0.00038463213925676474,
      "loss": 0.6808,
      "step": 365800
    },
    {
      "epoch": 3.873031584630613,
      "grad_norm": 1.0656919479370117,
      "learning_rate": 0.0003845932150051712,
      "loss": 0.6892,
      "step": 365850
    },
    {
      "epoch": 3.8735609064106162,
      "grad_norm": 1.0678991079330444,
      "learning_rate": 0.00038455428615861455,
      "loss": 0.6908,
      "step": 365900
    },
    {
      "epoch": 3.874090228190619,
      "grad_norm": 0.9847856760025024,
      "learning_rate": 0.00038451535271842395,
      "loss": 0.68,
      "step": 365950
    },
    {
      "epoch": 3.874619549970623,
      "grad_norm": 0.9692936539649963,
      "learning_rate": 0.0003844764146859285,
      "loss": 0.6926,
      "step": 366000
    },
    {
      "epoch": 3.874619549970623,
      "eval_loss": 0.47932714223861694,
      "eval_runtime": 46.781,
      "eval_samples_per_second": 3589.702,
      "eval_steps_per_second": 448.729,
      "step": 366000
    },
    {
      "epoch": 3.8751488717506257,
      "grad_norm": 1.0314922332763672,
      "learning_rate": 0.00038443747206245765,
      "loss": 0.6914,
      "step": 366050
    },
    {
      "epoch": 3.8756781935306295,
      "grad_norm": 0.9704537391662598,
      "learning_rate": 0.0003843985248493408,
      "loss": 0.688,
      "step": 366100
    },
    {
      "epoch": 3.8762075153106323,
      "grad_norm": 0.9691340327262878,
      "learning_rate": 0.0003843595730479076,
      "loss": 0.6963,
      "step": 366150
    },
    {
      "epoch": 3.8767368370906357,
      "grad_norm": 1.0901951789855957,
      "learning_rate": 0.0003843206166594878,
      "loss": 0.6819,
      "step": 366200
    },
    {
      "epoch": 3.877266158870639,
      "grad_norm": 0.9632251858711243,
      "learning_rate": 0.00038428165568541145,
      "loss": 0.6859,
      "step": 366250
    },
    {
      "epoch": 3.8777954806506423,
      "grad_norm": 1.0204613208770752,
      "learning_rate": 0.0003842426901270086,
      "loss": 0.6934,
      "step": 366300
    },
    {
      "epoch": 3.8783248024306456,
      "grad_norm": 1.1129924058914185,
      "learning_rate": 0.00038420449943334236,
      "loss": 0.6929,
      "step": 366350
    },
    {
      "epoch": 3.878854124210649,
      "grad_norm": 1.093121886253357,
      "learning_rate": 0.00038416552480189775,
      "loss": 0.687,
      "step": 366400
    },
    {
      "epoch": 3.879383445990652,
      "grad_norm": 1.0240191221237183,
      "learning_rate": 0.00038412654559009143,
      "loss": 0.6951,
      "step": 366450
    },
    {
      "epoch": 3.8799127677706555,
      "grad_norm": 0.907982587814331,
      "learning_rate": 0.00038408756179925395,
      "loss": 0.6964,
      "step": 366500
    },
    {
      "epoch": 3.8799127677706555,
      "eval_loss": 0.4808128774166107,
      "eval_runtime": 46.8915,
      "eval_samples_per_second": 3581.248,
      "eval_steps_per_second": 447.672,
      "step": 366500
    },
    {
      "epoch": 3.880442089550659,
      "grad_norm": 1.0022257566452026,
      "learning_rate": 0.00038404857343071633,
      "loss": 0.6956,
      "step": 366550
    },
    {
      "epoch": 3.880971411330662,
      "grad_norm": 0.9979374408721924,
      "learning_rate": 0.00038400958048580953,
      "loss": 0.7034,
      "step": 366600
    },
    {
      "epoch": 3.8815007331106655,
      "grad_norm": 1.0426251888275146,
      "learning_rate": 0.00038397058296586484,
      "loss": 0.6932,
      "step": 366650
    },
    {
      "epoch": 3.8820300548906683,
      "grad_norm": 1.0207644701004028,
      "learning_rate": 0.00038393158087221356,
      "loss": 0.6981,
      "step": 366700
    },
    {
      "epoch": 3.882559376670672,
      "grad_norm": 0.9079124927520752,
      "learning_rate": 0.0003838925742061873,
      "loss": 0.6978,
      "step": 366750
    },
    {
      "epoch": 3.883088698450675,
      "grad_norm": 1.038959264755249,
      "learning_rate": 0.00038385356296911753,
      "loss": 0.6731,
      "step": 366800
    },
    {
      "epoch": 3.8836180202306787,
      "grad_norm": 1.0851627588272095,
      "learning_rate": 0.00038381454716233634,
      "loss": 0.6968,
      "step": 366850
    },
    {
      "epoch": 3.8841473420106816,
      "grad_norm": 0.8959754109382629,
      "learning_rate": 0.00038377552678717556,
      "loss": 0.6899,
      "step": 366900
    },
    {
      "epoch": 3.884676663790685,
      "grad_norm": 0.9722497463226318,
      "learning_rate": 0.0003837365018449673,
      "loss": 0.6854,
      "step": 366950
    },
    {
      "epoch": 3.885205985570688,
      "grad_norm": 1.026503562927246,
      "learning_rate": 0.00038369747233704394,
      "loss": 0.6808,
      "step": 367000
    },
    {
      "epoch": 3.885205985570688,
      "eval_loss": 0.47903701663017273,
      "eval_runtime": 46.8223,
      "eval_samples_per_second": 3586.536,
      "eval_steps_per_second": 448.333,
      "step": 367000
    },
    {
      "epoch": 3.8857353073506915,
      "grad_norm": 1.0068511962890625,
      "learning_rate": 0.0003836584382647379,
      "loss": 0.6796,
      "step": 367050
    },
    {
      "epoch": 3.886264629130695,
      "grad_norm": 1.0183252096176147,
      "learning_rate": 0.0003836193996293818,
      "loss": 0.698,
      "step": 367100
    },
    {
      "epoch": 3.886793950910698,
      "grad_norm": 0.9821615219116211,
      "learning_rate": 0.0003835803564323084,
      "loss": 0.692,
      "step": 367150
    },
    {
      "epoch": 3.8873232726907014,
      "grad_norm": 0.9560126066207886,
      "learning_rate": 0.0003835413086748506,
      "loss": 0.6756,
      "step": 367200
    },
    {
      "epoch": 3.8878525944707047,
      "grad_norm": 0.9723744988441467,
      "learning_rate": 0.0003835022563583416,
      "loss": 0.6863,
      "step": 367250
    },
    {
      "epoch": 3.888381916250708,
      "grad_norm": 1.0608896017074585,
      "learning_rate": 0.0003834631994841144,
      "loss": 0.6894,
      "step": 367300
    },
    {
      "epoch": 3.8889112380307114,
      "grad_norm": 1.034512996673584,
      "learning_rate": 0.00038342413805350254,
      "loss": 0.6912,
      "step": 367350
    },
    {
      "epoch": 3.8894405598107147,
      "grad_norm": 1.0725736618041992,
      "learning_rate": 0.0003833850720678396,
      "loss": 0.6849,
      "step": 367400
    },
    {
      "epoch": 3.8899698815907175,
      "grad_norm": 1.0823290348052979,
      "learning_rate": 0.0003833460015284591,
      "loss": 0.7013,
      "step": 367450
    },
    {
      "epoch": 3.8904992033707213,
      "grad_norm": 0.9203150868415833,
      "learning_rate": 0.00038330692643669513,
      "loss": 0.6747,
      "step": 367500
    },
    {
      "epoch": 3.8904992033707213,
      "eval_loss": 0.47958704829216003,
      "eval_runtime": 46.9569,
      "eval_samples_per_second": 3576.259,
      "eval_steps_per_second": 447.048,
      "step": 367500
    },
    {
      "epoch": 3.891028525150724,
      "grad_norm": 0.9818865656852722,
      "learning_rate": 0.0003832678467938815,
      "loss": 0.6871,
      "step": 367550
    },
    {
      "epoch": 3.891557846930728,
      "grad_norm": 0.9911612868309021,
      "learning_rate": 0.0003832287626013525,
      "loss": 0.697,
      "step": 367600
    },
    {
      "epoch": 3.892087168710731,
      "grad_norm": 0.9235571622848511,
      "learning_rate": 0.00038318967386044247,
      "loss": 0.6929,
      "step": 367650
    },
    {
      "epoch": 3.892616490490734,
      "grad_norm": 0.9221562743186951,
      "learning_rate": 0.0003831505805724857,
      "loss": 0.7023,
      "step": 367700
    },
    {
      "epoch": 3.8931458122707374,
      "grad_norm": 1.0049573183059692,
      "learning_rate": 0.000383111482738817,
      "loss": 0.6892,
      "step": 367750
    },
    {
      "epoch": 3.8936751340507407,
      "grad_norm": 1.0731209516525269,
      "learning_rate": 0.00038307238036077107,
      "loss": 0.6942,
      "step": 367800
    },
    {
      "epoch": 3.894204455830744,
      "grad_norm": 1.0180773735046387,
      "learning_rate": 0.0003830332734396829,
      "loss": 0.6851,
      "step": 367850
    },
    {
      "epoch": 3.8947337776107473,
      "grad_norm": 0.9742950201034546,
      "learning_rate": 0.0003829941619768876,
      "loss": 0.6932,
      "step": 367900
    },
    {
      "epoch": 3.8952630993907507,
      "grad_norm": 0.983267605304718,
      "learning_rate": 0.0003829550459737203,
      "loss": 0.6908,
      "step": 367950
    },
    {
      "epoch": 3.895792421170754,
      "grad_norm": 0.9219947457313538,
      "learning_rate": 0.0003829159254315165,
      "loss": 0.6874,
      "step": 368000
    },
    {
      "epoch": 3.895792421170754,
      "eval_loss": 0.4779934883117676,
      "eval_runtime": 46.7928,
      "eval_samples_per_second": 3588.796,
      "eval_steps_per_second": 448.616,
      "step": 368000
    },
    {
      "epoch": 3.8963217429507573,
      "grad_norm": 0.8533000349998474,
      "learning_rate": 0.0003828768003516119,
      "loss": 0.6808,
      "step": 368050
    },
    {
      "epoch": 3.8968510647307606,
      "grad_norm": 0.9123543500900269,
      "learning_rate": 0.0003828376707353419,
      "loss": 0.6924,
      "step": 368100
    },
    {
      "epoch": 3.897380386510764,
      "grad_norm": 1.0261223316192627,
      "learning_rate": 0.0003827985365840426,
      "loss": 0.6963,
      "step": 368150
    },
    {
      "epoch": 3.8979097082907668,
      "grad_norm": 0.8992292284965515,
      "learning_rate": 0.0003827593978990499,
      "loss": 0.6866,
      "step": 368200
    },
    {
      "epoch": 3.8984390300707705,
      "grad_norm": 0.8825787901878357,
      "learning_rate": 0.0003827202546817001,
      "loss": 0.6899,
      "step": 368250
    },
    {
      "epoch": 3.8989683518507734,
      "grad_norm": 0.8612380623817444,
      "learning_rate": 0.0003826811069333295,
      "loss": 0.6813,
      "step": 368300
    },
    {
      "epoch": 3.899497673630777,
      "grad_norm": 1.02585768699646,
      "learning_rate": 0.0003826419546552745,
      "loss": 0.6767,
      "step": 368350
    },
    {
      "epoch": 3.90002699541078,
      "grad_norm": 0.9629439115524292,
      "learning_rate": 0.0003826035810293691,
      "loss": 0.6801,
      "step": 368400
    },
    {
      "epoch": 3.9005563171907833,
      "grad_norm": 1.0074442625045776,
      "learning_rate": 0.0003825644197864827,
      "loss": 0.6926,
      "step": 368450
    },
    {
      "epoch": 3.9010856389707866,
      "grad_norm": 0.9260302186012268,
      "learning_rate": 0.0003825252540178956,
      "loss": 0.6843,
      "step": 368500
    },
    {
      "epoch": 3.9010856389707866,
      "eval_loss": 0.4785477817058563,
      "eval_runtime": 46.8533,
      "eval_samples_per_second": 3584.168,
      "eval_steps_per_second": 448.037,
      "step": 368500
    },
    {
      "epoch": 3.90161496075079,
      "grad_norm": 0.9817274808883667,
      "learning_rate": 0.00038248608372494497,
      "loss": 0.6872,
      "step": 368550
    },
    {
      "epoch": 3.9021442825307933,
      "grad_norm": 1.021726131439209,
      "learning_rate": 0.00038244690890896794,
      "loss": 0.6864,
      "step": 368600
    },
    {
      "epoch": 3.9026736043107966,
      "grad_norm": 0.9994076490402222,
      "learning_rate": 0.0003824077295713021,
      "loss": 0.6937,
      "step": 368650
    },
    {
      "epoch": 3.9032029260908,
      "grad_norm": 0.8478192090988159,
      "learning_rate": 0.0003823693294347361,
      "loss": 0.6871,
      "step": 368700
    },
    {
      "epoch": 3.903732247870803,
      "grad_norm": 1.075581431388855,
      "learning_rate": 0.0003823301411480724,
      "loss": 0.6848,
      "step": 368750
    },
    {
      "epoch": 3.9042615696508065,
      "grad_norm": 1.0090227127075195,
      "learning_rate": 0.0003822909483437063,
      "loss": 0.6869,
      "step": 368800
    },
    {
      "epoch": 3.90479089143081,
      "grad_norm": 1.0638571977615356,
      "learning_rate": 0.0003822517510229757,
      "loss": 0.6796,
      "step": 368850
    },
    {
      "epoch": 3.905320213210813,
      "grad_norm": 0.9837260246276855,
      "learning_rate": 0.00038221254918721886,
      "loss": 0.682,
      "step": 368900
    },
    {
      "epoch": 3.905849534990816,
      "grad_norm": 0.9332876205444336,
      "learning_rate": 0.00038217334283777404,
      "loss": 0.6921,
      "step": 368950
    },
    {
      "epoch": 3.9063788567708198,
      "grad_norm": 0.9176567196846008,
      "learning_rate": 0.0003821341319759798,
      "loss": 0.6734,
      "step": 369000
    },
    {
      "epoch": 3.9063788567708198,
      "eval_loss": 0.47857800126075745,
      "eval_runtime": 46.8607,
      "eval_samples_per_second": 3583.601,
      "eval_steps_per_second": 447.966,
      "step": 369000
    },
    {
      "epoch": 3.9069081785508226,
      "grad_norm": 0.9861646890640259,
      "learning_rate": 0.0003820949166031747,
      "loss": 0.6802,
      "step": 369050
    },
    {
      "epoch": 3.9074375003308264,
      "grad_norm": 0.9031515717506409,
      "learning_rate": 0.00038205569672069764,
      "loss": 0.6872,
      "step": 369100
    },
    {
      "epoch": 3.9079668221108292,
      "grad_norm": 0.9588087201118469,
      "learning_rate": 0.00038201647232988744,
      "loss": 0.6741,
      "step": 369150
    },
    {
      "epoch": 3.9084961438908326,
      "grad_norm": 0.9703846573829651,
      "learning_rate": 0.0003819772434320834,
      "loss": 0.6807,
      "step": 369200
    },
    {
      "epoch": 3.909025465670836,
      "grad_norm": 0.9340110421180725,
      "learning_rate": 0.00038193801002862465,
      "loss": 0.6827,
      "step": 369250
    },
    {
      "epoch": 3.909554787450839,
      "grad_norm": 1.009695053100586,
      "learning_rate": 0.00038189877212085064,
      "loss": 0.6976,
      "step": 369300
    },
    {
      "epoch": 3.9100841092308425,
      "grad_norm": 1.0254859924316406,
      "learning_rate": 0.00038185952971010083,
      "loss": 0.6835,
      "step": 369350
    },
    {
      "epoch": 3.910613431010846,
      "grad_norm": 0.9653750658035278,
      "learning_rate": 0.00038182028279771515,
      "loss": 0.6768,
      "step": 369400
    },
    {
      "epoch": 3.911142752790849,
      "grad_norm": 0.9389665126800537,
      "learning_rate": 0.0003817810313850333,
      "loss": 0.6857,
      "step": 369450
    },
    {
      "epoch": 3.9116720745708524,
      "grad_norm": 0.9810153245925903,
      "learning_rate": 0.00038174177547339535,
      "loss": 0.6951,
      "step": 369500
    },
    {
      "epoch": 3.9116720745708524,
      "eval_loss": 0.47845175862312317,
      "eval_runtime": 46.7943,
      "eval_samples_per_second": 3588.687,
      "eval_steps_per_second": 448.602,
      "step": 369500
    },
    {
      "epoch": 3.9122013963508557,
      "grad_norm": 0.929923415184021,
      "learning_rate": 0.00038170251506414155,
      "loss": 0.6977,
      "step": 369550
    },
    {
      "epoch": 3.912730718130859,
      "grad_norm": 0.9802150726318359,
      "learning_rate": 0.00038166325015861216,
      "loss": 0.6743,
      "step": 369600
    },
    {
      "epoch": 3.9132600399108624,
      "grad_norm": 0.9254538416862488,
      "learning_rate": 0.00038162398075814764,
      "loss": 0.6837,
      "step": 369650
    },
    {
      "epoch": 3.913789361690865,
      "grad_norm": 1.0356658697128296,
      "learning_rate": 0.00038158470686408877,
      "loss": 0.6851,
      "step": 369700
    },
    {
      "epoch": 3.914318683470869,
      "grad_norm": 1.0287688970565796,
      "learning_rate": 0.0003815454284777762,
      "loss": 0.6954,
      "step": 369750
    },
    {
      "epoch": 3.914848005250872,
      "grad_norm": 1.0373989343643188,
      "learning_rate": 0.000381506145600551,
      "loss": 0.6961,
      "step": 369800
    },
    {
      "epoch": 3.9153773270308756,
      "grad_norm": 1.0322786569595337,
      "learning_rate": 0.00038146685823375415,
      "loss": 0.6824,
      "step": 369850
    },
    {
      "epoch": 3.9159066488108785,
      "grad_norm": 0.9517982602119446,
      "learning_rate": 0.000381427566378727,
      "loss": 0.6816,
      "step": 369900
    },
    {
      "epoch": 3.9164359705908818,
      "grad_norm": 0.9792966842651367,
      "learning_rate": 0.000381388270036811,
      "loss": 0.6923,
      "step": 369950
    },
    {
      "epoch": 3.916965292370885,
      "grad_norm": 1.049758791923523,
      "learning_rate": 0.0003813489692093476,
      "loss": 0.6869,
      "step": 370000
    },
    {
      "epoch": 3.916965292370885,
      "eval_loss": 0.4794108271598816,
      "eval_runtime": 46.7552,
      "eval_samples_per_second": 3591.683,
      "eval_steps_per_second": 448.976,
      "step": 370000
    },
    {
      "epoch": 3.9174946141508884,
      "grad_norm": 1.0041927099227905,
      "learning_rate": 0.00038130966389767856,
      "loss": 0.6816,
      "step": 370050
    },
    {
      "epoch": 3.9180239359308917,
      "grad_norm": 1.0239630937576294,
      "learning_rate": 0.00038127035410314575,
      "loss": 0.6891,
      "step": 370100
    },
    {
      "epoch": 3.918553257710895,
      "grad_norm": 1.0353047847747803,
      "learning_rate": 0.00038123103982709117,
      "loss": 0.6908,
      "step": 370150
    },
    {
      "epoch": 3.9190825794908983,
      "grad_norm": 1.042099952697754,
      "learning_rate": 0.00038119172107085707,
      "loss": 0.7035,
      "step": 370200
    },
    {
      "epoch": 3.9196119012709016,
      "grad_norm": 0.9732963442802429,
      "learning_rate": 0.0003811523978357857,
      "loss": 0.688,
      "step": 370250
    },
    {
      "epoch": 3.920141223050905,
      "grad_norm": 0.9906509518623352,
      "learning_rate": 0.0003811130701232196,
      "loss": 0.6706,
      "step": 370300
    },
    {
      "epoch": 3.9206705448309083,
      "grad_norm": 0.9679141640663147,
      "learning_rate": 0.00038107373793450127,
      "loss": 0.6956,
      "step": 370350
    },
    {
      "epoch": 3.9211998666109116,
      "grad_norm": 1.0652024745941162,
      "learning_rate": 0.00038103440127097374,
      "loss": 0.6797,
      "step": 370400
    },
    {
      "epoch": 3.9217291883909144,
      "grad_norm": 0.9965860247612,
      "learning_rate": 0.00038099506013397974,
      "loss": 0.697,
      "step": 370450
    },
    {
      "epoch": 3.922258510170918,
      "grad_norm": 0.9915342926979065,
      "learning_rate": 0.0003809557145248624,
      "loss": 0.6802,
      "step": 370500
    },
    {
      "epoch": 3.922258510170918,
      "eval_loss": 0.477721244096756,
      "eval_runtime": 46.7986,
      "eval_samples_per_second": 3588.355,
      "eval_steps_per_second": 448.56,
      "step": 370500
    },
    {
      "epoch": 3.922787831950921,
      "grad_norm": 0.8860396146774292,
      "learning_rate": 0.000380916364444965,
      "loss": 0.6954,
      "step": 370550
    },
    {
      "epoch": 3.923317153730925,
      "grad_norm": 0.9695972204208374,
      "learning_rate": 0.000380877009895631,
      "loss": 0.6932,
      "step": 370600
    },
    {
      "epoch": 3.9238464755109277,
      "grad_norm": 0.876221239566803,
      "learning_rate": 0.0003808376508782038,
      "loss": 0.6765,
      "step": 370650
    },
    {
      "epoch": 3.924375797290931,
      "grad_norm": 0.9561779499053955,
      "learning_rate": 0.0003807982873940271,
      "loss": 0.6896,
      "step": 370700
    },
    {
      "epoch": 3.9249051190709343,
      "grad_norm": 0.8976682424545288,
      "learning_rate": 0.000380758919444445,
      "loss": 0.6965,
      "step": 370750
    },
    {
      "epoch": 3.9254344408509376,
      "grad_norm": 0.907536506652832,
      "learning_rate": 0.00038071954703080126,
      "loss": 0.6849,
      "step": 370800
    },
    {
      "epoch": 3.925963762630941,
      "grad_norm": 0.9366806149482727,
      "learning_rate": 0.0003806801701544401,
      "loss": 0.7038,
      "step": 370850
    },
    {
      "epoch": 3.9264930844109442,
      "grad_norm": 0.9430135488510132,
      "learning_rate": 0.0003806407888167059,
      "loss": 0.6859,
      "step": 370900
    },
    {
      "epoch": 3.9270224061909476,
      "grad_norm": 1.0534182786941528,
      "learning_rate": 0.0003806014030189432,
      "loss": 0.6831,
      "step": 370950
    },
    {
      "epoch": 3.927551727970951,
      "grad_norm": 0.9656688570976257,
      "learning_rate": 0.00038056201276249633,
      "loss": 0.6793,
      "step": 371000
    },
    {
      "epoch": 3.927551727970951,
      "eval_loss": 0.47656896710395813,
      "eval_runtime": 46.7662,
      "eval_samples_per_second": 3590.838,
      "eval_steps_per_second": 448.871,
      "step": 371000
    },
    {
      "epoch": 3.928081049750954,
      "grad_norm": 1.1071361303329468,
      "learning_rate": 0.0003805226180487103,
      "loss": 0.7014,
      "step": 371050
    },
    {
      "epoch": 3.9286103715309575,
      "grad_norm": 1.0258324146270752,
      "learning_rate": 0.00038048321887892994,
      "loss": 0.6824,
      "step": 371100
    },
    {
      "epoch": 3.929139693310961,
      "grad_norm": 0.9936718940734863,
      "learning_rate": 0.00038044381525450036,
      "loss": 0.6868,
      "step": 371150
    },
    {
      "epoch": 3.929669015090964,
      "grad_norm": 1.0482511520385742,
      "learning_rate": 0.00038040440717676674,
      "loss": 0.6729,
      "step": 371200
    },
    {
      "epoch": 3.9301983368709674,
      "grad_norm": 0.9474388360977173,
      "learning_rate": 0.00038036499464707445,
      "loss": 0.6895,
      "step": 371250
    },
    {
      "epoch": 3.9307276586509703,
      "grad_norm": 1.0400104522705078,
      "learning_rate": 0.0003803255776667691,
      "loss": 0.6902,
      "step": 371300
    },
    {
      "epoch": 3.931256980430974,
      "grad_norm": 0.967035174369812,
      "learning_rate": 0.00038028615623719633,
      "loss": 0.6953,
      "step": 371350
    },
    {
      "epoch": 3.931786302210977,
      "grad_norm": 1.1318951845169067,
      "learning_rate": 0.00038024673035970196,
      "loss": 0.6829,
      "step": 371400
    },
    {
      "epoch": 3.9323156239909802,
      "grad_norm": 1.0097414255142212,
      "learning_rate": 0.000380207300035632,
      "loss": 0.6787,
      "step": 371450
    },
    {
      "epoch": 3.9328449457709835,
      "grad_norm": 0.9937751889228821,
      "learning_rate": 0.00038016786526633254,
      "loss": 0.6859,
      "step": 371500
    },
    {
      "epoch": 3.9328449457709835,
      "eval_loss": 0.4789060652256012,
      "eval_runtime": 46.8294,
      "eval_samples_per_second": 3585.997,
      "eval_steps_per_second": 448.266,
      "step": 371500
    },
    {
      "epoch": 3.933374267550987,
      "grad_norm": 1.0201256275177002,
      "learning_rate": 0.0003801284260531498,
      "loss": 0.6844,
      "step": 371550
    },
    {
      "epoch": 3.93390358933099,
      "grad_norm": 0.9132704734802246,
      "learning_rate": 0.0003800889823974305,
      "loss": 0.6931,
      "step": 371600
    },
    {
      "epoch": 3.9344329111109935,
      "grad_norm": 0.9718414545059204,
      "learning_rate": 0.0003800495343005209,
      "loss": 0.7001,
      "step": 371650
    },
    {
      "epoch": 3.934962232890997,
      "grad_norm": 1.0210165977478027,
      "learning_rate": 0.000380010081763768,
      "loss": 0.6822,
      "step": 371700
    },
    {
      "epoch": 3.935491554671,
      "grad_norm": 0.9785324335098267,
      "learning_rate": 0.0003799706247885186,
      "loss": 0.677,
      "step": 371750
    },
    {
      "epoch": 3.9360208764510034,
      "grad_norm": 0.9472576975822449,
      "learning_rate": 0.00037993116337611967,
      "loss": 0.6829,
      "step": 371800
    },
    {
      "epoch": 3.9365501982310067,
      "grad_norm": 1.1454159021377563,
      "learning_rate": 0.0003798916975279184,
      "loss": 0.6914,
      "step": 371850
    },
    {
      "epoch": 3.93707952001101,
      "grad_norm": 0.9928033351898193,
      "learning_rate": 0.00037985222724526234,
      "loss": 0.691,
      "step": 371900
    },
    {
      "epoch": 3.9376088417910133,
      "grad_norm": 0.9153526425361633,
      "learning_rate": 0.00037981275252949883,
      "loss": 0.6951,
      "step": 371950
    },
    {
      "epoch": 3.9381381635710166,
      "grad_norm": 0.9859114289283752,
      "learning_rate": 0.00037977327338197556,
      "loss": 0.686,
      "step": 372000
    },
    {
      "epoch": 3.9381381635710166,
      "eval_loss": 0.4780595004558563,
      "eval_runtime": 46.7753,
      "eval_samples_per_second": 3590.143,
      "eval_steps_per_second": 448.784,
      "step": 372000
    },
    {
      "epoch": 3.9386674853510195,
      "grad_norm": 0.8978340029716492,
      "learning_rate": 0.00037973378980404025,
      "loss": 0.689,
      "step": 372050
    },
    {
      "epoch": 3.9391968071310233,
      "grad_norm": 0.9085494875907898,
      "learning_rate": 0.00037969430179704105,
      "loss": 0.6897,
      "step": 372100
    },
    {
      "epoch": 3.939726128911026,
      "grad_norm": 0.9935016632080078,
      "learning_rate": 0.00037965480936232596,
      "loss": 0.6875,
      "step": 372150
    },
    {
      "epoch": 3.9402554506910294,
      "grad_norm": 1.0077166557312012,
      "learning_rate": 0.0003796153125012432,
      "loss": 0.6942,
      "step": 372200
    },
    {
      "epoch": 3.9407847724710328,
      "grad_norm": 1.0980224609375,
      "learning_rate": 0.0003795758112151411,
      "loss": 0.6876,
      "step": 372250
    },
    {
      "epoch": 3.941314094251036,
      "grad_norm": 0.9829543232917786,
      "learning_rate": 0.00037953630550536843,
      "loss": 0.6852,
      "step": 372300
    },
    {
      "epoch": 3.9418434160310394,
      "grad_norm": 1.0745677947998047,
      "learning_rate": 0.00037949679537327375,
      "loss": 0.6911,
      "step": 372350
    },
    {
      "epoch": 3.9423727378110427,
      "grad_norm": 0.94754958152771,
      "learning_rate": 0.00037945728082020605,
      "loss": 0.6848,
      "step": 372400
    },
    {
      "epoch": 3.942902059591046,
      "grad_norm": 1.0044350624084473,
      "learning_rate": 0.0003794177618475142,
      "loss": 0.6894,
      "step": 372450
    },
    {
      "epoch": 3.9434313813710493,
      "grad_norm": 1.0065336227416992,
      "learning_rate": 0.0003793782384565474,
      "loss": 0.6959,
      "step": 372500
    },
    {
      "epoch": 3.9434313813710493,
      "eval_loss": 0.4763435125350952,
      "eval_runtime": 46.8296,
      "eval_samples_per_second": 3585.978,
      "eval_steps_per_second": 448.263,
      "step": 372500
    },
    {
      "epoch": 3.9439607031510526,
      "grad_norm": 0.9671080708503723,
      "learning_rate": 0.000379338710648655,
      "loss": 0.702,
      "step": 372550
    },
    {
      "epoch": 3.944490024931056,
      "grad_norm": 1.1534525156021118,
      "learning_rate": 0.00037929917842518645,
      "loss": 0.7084,
      "step": 372600
    },
    {
      "epoch": 3.9450193467110592,
      "grad_norm": 1.0263700485229492,
      "learning_rate": 0.0003792596417874914,
      "loss": 0.6838,
      "step": 372650
    },
    {
      "epoch": 3.9455486684910626,
      "grad_norm": 0.9694629311561584,
      "learning_rate": 0.0003792208916011685,
      "loss": 0.6993,
      "step": 372700
    },
    {
      "epoch": 3.946077990271066,
      "grad_norm": 1.0367252826690674,
      "learning_rate": 0.00037918134622728705,
      "loss": 0.6786,
      "step": 372750
    },
    {
      "epoch": 3.9466073120510687,
      "grad_norm": 0.8633275628089905,
      "learning_rate": 0.0003791417964432019,
      "loss": 0.6877,
      "step": 372800
    },
    {
      "epoch": 3.9471366338310725,
      "grad_norm": 0.9398190379142761,
      "learning_rate": 0.00037910224225026323,
      "loss": 0.6959,
      "step": 372850
    },
    {
      "epoch": 3.9476659556110754,
      "grad_norm": 0.9897823333740234,
      "learning_rate": 0.00037906268364982127,
      "loss": 0.6802,
      "step": 372900
    },
    {
      "epoch": 3.9481952773910787,
      "grad_norm": 0.9052260518074036,
      "learning_rate": 0.0003790231206432266,
      "loss": 0.6743,
      "step": 372950
    },
    {
      "epoch": 3.948724599171082,
      "grad_norm": 1.0056872367858887,
      "learning_rate": 0.00037898355323183,
      "loss": 0.6924,
      "step": 373000
    },
    {
      "epoch": 3.948724599171082,
      "eval_loss": 0.4763096570968628,
      "eval_runtime": 46.7814,
      "eval_samples_per_second": 3589.675,
      "eval_steps_per_second": 448.725,
      "step": 373000
    },
    {
      "epoch": 3.9492539209510853,
      "grad_norm": 1.0301748514175415,
      "learning_rate": 0.00037894398141698215,
      "loss": 0.6913,
      "step": 373050
    },
    {
      "epoch": 3.9497832427310886,
      "grad_norm": 0.9989740252494812,
      "learning_rate": 0.00037890440520003406,
      "loss": 0.6912,
      "step": 373100
    },
    {
      "epoch": 3.950312564511092,
      "grad_norm": 1.00048828125,
      "learning_rate": 0.00037886482458233684,
      "loss": 0.6833,
      "step": 373150
    },
    {
      "epoch": 3.9508418862910952,
      "grad_norm": 0.9013612270355225,
      "learning_rate": 0.0003788252395652418,
      "loss": 0.6775,
      "step": 373200
    },
    {
      "epoch": 3.9513712080710985,
      "grad_norm": 1.0070009231567383,
      "learning_rate": 0.0003787856501501003,
      "loss": 0.686,
      "step": 373250
    },
    {
      "epoch": 3.951900529851102,
      "grad_norm": 0.9640012383460999,
      "learning_rate": 0.000378746056338264,
      "loss": 0.6844,
      "step": 373300
    },
    {
      "epoch": 3.952429851631105,
      "grad_norm": 0.8750249743461609,
      "learning_rate": 0.0003787064581310845,
      "loss": 0.6846,
      "step": 373350
    },
    {
      "epoch": 3.9529591734111085,
      "grad_norm": 0.9702724814414978,
      "learning_rate": 0.0003786668555299136,
      "loss": 0.6787,
      "step": 373400
    },
    {
      "epoch": 3.953488495191112,
      "grad_norm": 0.9667704105377197,
      "learning_rate": 0.0003786272485361036,
      "loss": 0.6793,
      "step": 373450
    },
    {
      "epoch": 3.954017816971115,
      "grad_norm": 0.9797099232673645,
      "learning_rate": 0.00037858763715100654,
      "loss": 0.6897,
      "step": 373500
    },
    {
      "epoch": 3.954017816971115,
      "eval_loss": 0.4744991064071655,
      "eval_runtime": 46.844,
      "eval_samples_per_second": 3584.875,
      "eval_steps_per_second": 448.125,
      "step": 373500
    },
    {
      "epoch": 3.954547138751118,
      "grad_norm": 1.009312629699707,
      "learning_rate": 0.0003785480213759746,
      "loss": 0.6892,
      "step": 373550
    },
    {
      "epoch": 3.9550764605311217,
      "grad_norm": 0.9889373183250427,
      "learning_rate": 0.00037850840121236043,
      "loss": 0.6786,
      "step": 373600
    },
    {
      "epoch": 3.9556057823111246,
      "grad_norm": 1.0844378471374512,
      "learning_rate": 0.0003784687766615165,
      "loss": 0.6935,
      "step": 373650
    },
    {
      "epoch": 3.956135104091128,
      "grad_norm": 1.058606505393982,
      "learning_rate": 0.00037842914772479567,
      "loss": 0.6945,
      "step": 373700
    },
    {
      "epoch": 3.956664425871131,
      "grad_norm": 1.0013667345046997,
      "learning_rate": 0.00037838951440355087,
      "loss": 0.6736,
      "step": 373750
    },
    {
      "epoch": 3.9571937476511345,
      "grad_norm": 1.0439714193344116,
      "learning_rate": 0.00037834987669913505,
      "loss": 0.6811,
      "step": 373800
    },
    {
      "epoch": 3.957723069431138,
      "grad_norm": 0.9710085391998291,
      "learning_rate": 0.0003783102346129016,
      "loss": 0.6833,
      "step": 373850
    },
    {
      "epoch": 3.958252391211141,
      "grad_norm": 1.0202860832214355,
      "learning_rate": 0.0003782705881462037,
      "loss": 0.6924,
      "step": 373900
    },
    {
      "epoch": 3.9587817129911445,
      "grad_norm": 1.0503349304199219,
      "learning_rate": 0.0003782309373003951,
      "loss": 0.6828,
      "step": 373950
    },
    {
      "epoch": 3.9593110347711478,
      "grad_norm": 1.0868828296661377,
      "learning_rate": 0.00037819128207682923,
      "loss": 0.6878,
      "step": 374000
    },
    {
      "epoch": 3.9593110347711478,
      "eval_loss": 0.47505754232406616,
      "eval_runtime": 46.7501,
      "eval_samples_per_second": 3592.081,
      "eval_steps_per_second": 449.026,
      "step": 374000
    },
    {
      "epoch": 3.959840356551151,
      "grad_norm": 0.9385133385658264,
      "learning_rate": 0.00037815162247686006,
      "loss": 0.686,
      "step": 374050
    },
    {
      "epoch": 3.9603696783311544,
      "grad_norm": 0.9677008986473083,
      "learning_rate": 0.0003781119585018414,
      "loss": 0.7,
      "step": 374100
    },
    {
      "epoch": 3.9608990001111577,
      "grad_norm": 0.9332354068756104,
      "learning_rate": 0.0003780722901531276,
      "loss": 0.6931,
      "step": 374150
    },
    {
      "epoch": 3.961428321891161,
      "grad_norm": 0.8934788703918457,
      "learning_rate": 0.00037803261743207274,
      "loss": 0.6713,
      "step": 374200
    },
    {
      "epoch": 3.9619576436711643,
      "grad_norm": 1.024497151374817,
      "learning_rate": 0.00037799294034003117,
      "loss": 0.6785,
      "step": 374250
    },
    {
      "epoch": 3.962486965451167,
      "grad_norm": 1.0131337642669678,
      "learning_rate": 0.0003779532588783577,
      "loss": 0.6734,
      "step": 374300
    },
    {
      "epoch": 3.963016287231171,
      "grad_norm": 0.9562784433364868,
      "learning_rate": 0.0003779135730484068,
      "loss": 0.6921,
      "step": 374350
    },
    {
      "epoch": 3.963545609011174,
      "grad_norm": 1.056335210800171,
      "learning_rate": 0.00037787388285153345,
      "loss": 0.6894,
      "step": 374400
    },
    {
      "epoch": 3.964074930791177,
      "grad_norm": 0.9714769124984741,
      "learning_rate": 0.00037783418828909267,
      "loss": 0.6846,
      "step": 374450
    },
    {
      "epoch": 3.9646042525711804,
      "grad_norm": 0.9863348603248596,
      "learning_rate": 0.00037779448936243955,
      "loss": 0.6776,
      "step": 374500
    },
    {
      "epoch": 3.9646042525711804,
      "eval_loss": 0.47206759452819824,
      "eval_runtime": 46.9309,
      "eval_samples_per_second": 3578.239,
      "eval_steps_per_second": 447.296,
      "step": 374500
    },
    {
      "epoch": 3.9651335743511837,
      "grad_norm": 1.040923833847046,
      "learning_rate": 0.00037775478607292946,
      "loss": 0.6862,
      "step": 374550
    },
    {
      "epoch": 3.965662896131187,
      "grad_norm": 1.0137418508529663,
      "learning_rate": 0.00037771507842191776,
      "loss": 0.683,
      "step": 374600
    },
    {
      "epoch": 3.9661922179111904,
      "grad_norm": 1.0274640321731567,
      "learning_rate": 0.0003776753664107602,
      "loss": 0.6986,
      "step": 374650
    },
    {
      "epoch": 3.9667215396911937,
      "grad_norm": 1.0002073049545288,
      "learning_rate": 0.00037763565004081233,
      "loss": 0.6781,
      "step": 374700
    },
    {
      "epoch": 3.967250861471197,
      "grad_norm": 1.0661054849624634,
      "learning_rate": 0.00037759672377067204,
      "loss": 0.6849,
      "step": 374750
    },
    {
      "epoch": 3.9677801832512003,
      "grad_norm": 0.9433769583702087,
      "learning_rate": 0.00037755699877432006,
      "loss": 0.6941,
      "step": 374800
    },
    {
      "epoch": 3.9683095050312036,
      "grad_norm": 0.9444417357444763,
      "learning_rate": 0.0003775172694232188,
      "loss": 0.692,
      "step": 374850
    },
    {
      "epoch": 3.968838826811207,
      "grad_norm": 0.994826078414917,
      "learning_rate": 0.0003774775357187249,
      "loss": 0.6778,
      "step": 374900
    },
    {
      "epoch": 3.9693681485912102,
      "grad_norm": 0.9137261509895325,
      "learning_rate": 0.00037743779766219454,
      "loss": 0.6784,
      "step": 374950
    },
    {
      "epoch": 3.9698974703712135,
      "grad_norm": 0.9100871682167053,
      "learning_rate": 0.00037739805525498454,
      "loss": 0.69,
      "step": 375000
    },
    {
      "epoch": 3.9698974703712135,
      "eval_loss": 0.47678500413894653,
      "eval_runtime": 46.8719,
      "eval_samples_per_second": 3582.744,
      "eval_steps_per_second": 447.859,
      "step": 375000
    },
    {
      "epoch": 3.9704267921512164,
      "grad_norm": 1.072928786277771,
      "learning_rate": 0.00037735830849845167,
      "loss": 0.6858,
      "step": 375050
    },
    {
      "epoch": 3.97095611393122,
      "grad_norm": 1.0164384841918945,
      "learning_rate": 0.00037731855739395285,
      "loss": 0.7001,
      "step": 375100
    },
    {
      "epoch": 3.971485435711223,
      "grad_norm": 0.9629902839660645,
      "learning_rate": 0.0003772788019428452,
      "loss": 0.6928,
      "step": 375150
    },
    {
      "epoch": 3.9720147574912263,
      "grad_norm": 0.9594630599021912,
      "learning_rate": 0.0003772390421464859,
      "loss": 0.68,
      "step": 375200
    },
    {
      "epoch": 3.9725440792712297,
      "grad_norm": 1.0351265668869019,
      "learning_rate": 0.0003771992780062324,
      "loss": 0.6829,
      "step": 375250
    },
    {
      "epoch": 3.973073401051233,
      "grad_norm": 0.9974592328071594,
      "learning_rate": 0.0003771595095234421,
      "loss": 0.6893,
      "step": 375300
    },
    {
      "epoch": 3.9736027228312363,
      "grad_norm": 0.9873735308647156,
      "learning_rate": 0.00037711973669947283,
      "loss": 0.6781,
      "step": 375350
    },
    {
      "epoch": 3.9741320446112396,
      "grad_norm": 0.9756039977073669,
      "learning_rate": 0.00037707995953568246,
      "loss": 0.6809,
      "step": 375400
    },
    {
      "epoch": 3.974661366391243,
      "grad_norm": 1.0704970359802246,
      "learning_rate": 0.0003770401780334288,
      "loss": 0.6822,
      "step": 375450
    },
    {
      "epoch": 3.975190688171246,
      "grad_norm": 0.9431775808334351,
      "learning_rate": 0.0003770003921940701,
      "loss": 0.67,
      "step": 375500
    },
    {
      "epoch": 3.975190688171246,
      "eval_loss": 0.4740387201309204,
      "eval_runtime": 46.9199,
      "eval_samples_per_second": 3579.082,
      "eval_steps_per_second": 447.401,
      "step": 375500
    },
    {
      "epoch": 3.9757200099512495,
      "grad_norm": 0.9842246770858765,
      "learning_rate": 0.00037696060201896454,
      "loss": 0.6864,
      "step": 375550
    },
    {
      "epoch": 3.976249331731253,
      "grad_norm": 0.9866399168968201,
      "learning_rate": 0.0003769208075094706,
      "loss": 0.6839,
      "step": 375600
    },
    {
      "epoch": 3.976778653511256,
      "grad_norm": 0.9444367289543152,
      "learning_rate": 0.0003768810086669468,
      "loss": 0.6891,
      "step": 375650
    },
    {
      "epoch": 3.9773079752912595,
      "grad_norm": 0.9177278280258179,
      "learning_rate": 0.00037684120549275193,
      "loss": 0.6776,
      "step": 375700
    },
    {
      "epoch": 3.9778372970712628,
      "grad_norm": 1.0687695741653442,
      "learning_rate": 0.0003768013979882448,
      "loss": 0.6886,
      "step": 375750
    },
    {
      "epoch": 3.9783666188512656,
      "grad_norm": 0.8964931964874268,
      "learning_rate": 0.00037676158615478447,
      "loss": 0.6832,
      "step": 375800
    },
    {
      "epoch": 3.9788959406312694,
      "grad_norm": 1.049312710762024,
      "learning_rate": 0.00037672176999373,
      "loss": 0.7006,
      "step": 375850
    },
    {
      "epoch": 3.9794252624112723,
      "grad_norm": 1.0244684219360352,
      "learning_rate": 0.00037668194950644083,
      "loss": 0.6981,
      "step": 375900
    },
    {
      "epoch": 3.9799545841912756,
      "grad_norm": 0.9480454325675964,
      "learning_rate": 0.00037664212469427645,
      "loss": 0.6843,
      "step": 375950
    },
    {
      "epoch": 3.980483905971279,
      "grad_norm": 0.982623815536499,
      "learning_rate": 0.00037660229555859634,
      "loss": 0.6925,
      "step": 376000
    },
    {
      "epoch": 3.980483905971279,
      "eval_loss": 0.4719651937484741,
      "eval_runtime": 46.8535,
      "eval_samples_per_second": 3584.148,
      "eval_steps_per_second": 448.035,
      "step": 376000
    },
    {
      "epoch": 3.981013227751282,
      "grad_norm": 0.9744559526443481,
      "learning_rate": 0.0003765624621007602,
      "loss": 0.6879,
      "step": 376050
    },
    {
      "epoch": 3.9815425495312855,
      "grad_norm": 0.9935507774353027,
      "learning_rate": 0.00037652262432212813,
      "loss": 0.674,
      "step": 376100
    },
    {
      "epoch": 3.982071871311289,
      "grad_norm": 0.9541009664535522,
      "learning_rate": 0.00037648278222405997,
      "loss": 0.6773,
      "step": 376150
    },
    {
      "epoch": 3.982601193091292,
      "grad_norm": 1.08912992477417,
      "learning_rate": 0.00037644293580791613,
      "loss": 0.6769,
      "step": 376200
    },
    {
      "epoch": 3.9831305148712954,
      "grad_norm": 0.9785776734352112,
      "learning_rate": 0.00037640308507505673,
      "loss": 0.6821,
      "step": 376250
    },
    {
      "epoch": 3.9836598366512987,
      "grad_norm": 0.9141724109649658,
      "learning_rate": 0.00037636323002684236,
      "loss": 0.694,
      "step": 376300
    },
    {
      "epoch": 3.984189158431302,
      "grad_norm": 1.0878055095672607,
      "learning_rate": 0.0003763233706646337,
      "loss": 0.6815,
      "step": 376350
    },
    {
      "epoch": 3.9847184802113054,
      "grad_norm": 0.928966224193573,
      "learning_rate": 0.0003762835069897915,
      "loss": 0.6819,
      "step": 376400
    },
    {
      "epoch": 3.9852478019913087,
      "grad_norm": 0.9991387724876404,
      "learning_rate": 0.00037624363900367664,
      "loss": 0.685,
      "step": 376450
    },
    {
      "epoch": 3.985777123771312,
      "grad_norm": 1.0895482301712036,
      "learning_rate": 0.0003762037667076503,
      "loss": 0.685,
      "step": 376500
    },
    {
      "epoch": 3.985777123771312,
      "eval_loss": 0.4734337329864502,
      "eval_runtime": 46.9336,
      "eval_samples_per_second": 3578.035,
      "eval_steps_per_second": 447.27,
      "step": 376500
    },
    {
      "epoch": 3.986306445551315,
      "grad_norm": 1.0067555904388428,
      "learning_rate": 0.0003761638901030736,
      "loss": 0.6838,
      "step": 376550
    },
    {
      "epoch": 3.9868357673313186,
      "grad_norm": 1.0937750339508057,
      "learning_rate": 0.000376124009191308,
      "loss": 0.6852,
      "step": 376600
    },
    {
      "epoch": 3.9873650891113215,
      "grad_norm": 1.0345301628112793,
      "learning_rate": 0.0003760841239737149,
      "loss": 0.6875,
      "step": 376650
    },
    {
      "epoch": 3.987894410891325,
      "grad_norm": 0.9685935974121094,
      "learning_rate": 0.00037604423445165613,
      "loss": 0.6987,
      "step": 376700
    },
    {
      "epoch": 3.988423732671328,
      "grad_norm": 1.0538381338119507,
      "learning_rate": 0.00037600513854515826,
      "loss": 0.6776,
      "step": 376750
    },
    {
      "epoch": 3.9889530544513314,
      "grad_norm": 1.0084233283996582,
      "learning_rate": 0.00037596524050427505,
      "loss": 0.6652,
      "step": 376800
    },
    {
      "epoch": 3.9894823762313347,
      "grad_norm": 1.044610857963562,
      "learning_rate": 0.00037592533816298475,
      "loss": 0.6911,
      "step": 376850
    },
    {
      "epoch": 3.990011698011338,
      "grad_norm": 0.9341995120048523,
      "learning_rate": 0.00037588543152264955,
      "loss": 0.685,
      "step": 376900
    },
    {
      "epoch": 3.9905410197913413,
      "grad_norm": 0.9671140313148499,
      "learning_rate": 0.0003758455205846319,
      "loss": 0.6733,
      "step": 376950
    },
    {
      "epoch": 3.9910703415713447,
      "grad_norm": 0.9374458193778992,
      "learning_rate": 0.0003758056053502943,
      "loss": 0.6854,
      "step": 377000
    },
    {
      "epoch": 3.9910703415713447,
      "eval_loss": 0.47554951906204224,
      "eval_runtime": 46.812,
      "eval_samples_per_second": 3587.33,
      "eval_steps_per_second": 448.432,
      "step": 377000
    },
    {
      "epoch": 3.991599663351348,
      "grad_norm": 0.9557629823684692,
      "learning_rate": 0.0003757656858209995,
      "loss": 0.6685,
      "step": 377050
    },
    {
      "epoch": 3.9921289851313513,
      "grad_norm": 1.0215989351272583,
      "learning_rate": 0.0003757257619981103,
      "loss": 0.6827,
      "step": 377100
    },
    {
      "epoch": 3.9926583069113546,
      "grad_norm": 1.0262980461120605,
      "learning_rate": 0.00037568583388298974,
      "loss": 0.6827,
      "step": 377150
    },
    {
      "epoch": 3.993187628691358,
      "grad_norm": 1.0299103260040283,
      "learning_rate": 0.0003756459014770008,
      "loss": 0.6823,
      "step": 377200
    },
    {
      "epoch": 3.993716950471361,
      "grad_norm": 1.0314245223999023,
      "learning_rate": 0.0003756059647815069,
      "loss": 0.678,
      "step": 377250
    },
    {
      "epoch": 3.994246272251364,
      "grad_norm": 1.0552870035171509,
      "learning_rate": 0.00037556602379787147,
      "loss": 0.7045,
      "step": 377300
    },
    {
      "epoch": 3.994775594031368,
      "grad_norm": 0.976972222328186,
      "learning_rate": 0.000375526078527458,
      "loss": 0.6856,
      "step": 377350
    },
    {
      "epoch": 3.9953049158113707,
      "grad_norm": 0.9730777740478516,
      "learning_rate": 0.00037548612897163027,
      "loss": 0.6857,
      "step": 377400
    },
    {
      "epoch": 3.995834237591374,
      "grad_norm": 0.8939850926399231,
      "learning_rate": 0.00037544617513175213,
      "loss": 0.685,
      "step": 377450
    },
    {
      "epoch": 3.9963635593713773,
      "grad_norm": 0.8662610054016113,
      "learning_rate": 0.00037540621700918753,
      "loss": 0.6725,
      "step": 377500
    },
    {
      "epoch": 3.9963635593713773,
      "eval_loss": 0.47475743293762207,
      "eval_runtime": 46.9097,
      "eval_samples_per_second": 3579.858,
      "eval_steps_per_second": 447.498,
      "step": 377500
    },
    {
      "epoch": 3.9968928811513806,
      "grad_norm": 1.014621615409851,
      "learning_rate": 0.00037536625460530073,
      "loss": 0.6774,
      "step": 377550
    },
    {
      "epoch": 3.997422202931384,
      "grad_norm": 0.9179254770278931,
      "learning_rate": 0.000375326287921456,
      "loss": 0.6931,
      "step": 377600
    },
    {
      "epoch": 3.9979515247113873,
      "grad_norm": 0.9370934367179871,
      "learning_rate": 0.00037528631695901764,
      "loss": 0.683,
      "step": 377650
    },
    {
      "epoch": 3.9984808464913906,
      "grad_norm": 0.9899023175239563,
      "learning_rate": 0.00037524634171935044,
      "loss": 0.6727,
      "step": 377700
    },
    {
      "epoch": 3.999010168271394,
      "grad_norm": 1.051140308380127,
      "learning_rate": 0.0003752063622038191,
      "loss": 0.6702,
      "step": 377750
    },
    {
      "epoch": 3.999539490051397,
      "grad_norm": 0.9747143983840942,
      "learning_rate": 0.00037516637841378844,
      "loss": 0.6832,
      "step": 377800
    },
    {
      "epoch": 4.0000635186136,
      "grad_norm": 0.9594563841819763,
      "learning_rate": 0.00037512639035062345,
      "loss": 0.6891,
      "step": 377850
    },
    {
      "epoch": 4.000592840393604,
      "grad_norm": 1.0526831150054932,
      "learning_rate": 0.0003750863980156895,
      "loss": 0.6732,
      "step": 377900
    },
    {
      "epoch": 4.001122162173607,
      "grad_norm": 1.0679980516433716,
      "learning_rate": 0.0003750464014103517,
      "loss": 0.6829,
      "step": 377950
    },
    {
      "epoch": 4.00165148395361,
      "grad_norm": 0.9714820384979248,
      "learning_rate": 0.0003750064005359757,
      "loss": 0.6782,
      "step": 378000
    },
    {
      "epoch": 4.00165148395361,
      "eval_loss": 0.47271212935447693,
      "eval_runtime": 46.9035,
      "eval_samples_per_second": 3580.329,
      "eval_steps_per_second": 447.557,
      "step": 378000
    },
    {
      "epoch": 4.002180805733613,
      "grad_norm": 1.0612359046936035,
      "learning_rate": 0.000374966395393927,
      "loss": 0.6725,
      "step": 378050
    },
    {
      "epoch": 4.002710127513617,
      "grad_norm": 1.0136020183563232,
      "learning_rate": 0.00037492638598557134,
      "loss": 0.6819,
      "step": 378100
    },
    {
      "epoch": 4.00323944929362,
      "grad_norm": 0.8045631051063538,
      "learning_rate": 0.00037488637231227476,
      "loss": 0.6786,
      "step": 378150
    },
    {
      "epoch": 4.003768771073624,
      "grad_norm": 0.931624710559845,
      "learning_rate": 0.0003748463543754032,
      "loss": 0.6629,
      "step": 378200
    },
    {
      "epoch": 4.0042980928536265,
      "grad_norm": 1.0113325119018555,
      "learning_rate": 0.00037480633217632284,
      "loss": 0.6789,
      "step": 378250
    },
    {
      "epoch": 4.00482741463363,
      "grad_norm": 0.9573364853858948,
      "learning_rate": 0.0003747663057164001,
      "loss": 0.6772,
      "step": 378300
    },
    {
      "epoch": 4.005356736413633,
      "grad_norm": 1.1102321147918701,
      "learning_rate": 0.00037472627499700144,
      "loss": 0.6856,
      "step": 378350
    },
    {
      "epoch": 4.005886058193637,
      "grad_norm": 1.0938036441802979,
      "learning_rate": 0.00037468624001949354,
      "loss": 0.673,
      "step": 378400
    },
    {
      "epoch": 4.00641537997364,
      "grad_norm": 0.96939617395401,
      "learning_rate": 0.0003746462007852431,
      "loss": 0.6778,
      "step": 378450
    },
    {
      "epoch": 4.0069447017536435,
      "grad_norm": 0.9366292357444763,
      "learning_rate": 0.0003746061572956171,
      "loss": 0.6784,
      "step": 378500
    },
    {
      "epoch": 4.0069447017536435,
      "eval_loss": 0.4725428819656372,
      "eval_runtime": 46.8333,
      "eval_samples_per_second": 3585.698,
      "eval_steps_per_second": 448.228,
      "step": 378500
    },
    {
      "epoch": 4.007474023533646,
      "grad_norm": 0.9755238890647888,
      "learning_rate": 0.0003745661095519825,
      "loss": 0.6696,
      "step": 378550
    },
    {
      "epoch": 4.008003345313649,
      "grad_norm": 1.0613629817962646,
      "learning_rate": 0.0003745260575557067,
      "loss": 0.6861,
      "step": 378600
    },
    {
      "epoch": 4.008532667093653,
      "grad_norm": 0.9388343095779419,
      "learning_rate": 0.0003744860013081569,
      "loss": 0.6863,
      "step": 378650
    },
    {
      "epoch": 4.009061988873656,
      "grad_norm": 0.9324060082435608,
      "learning_rate": 0.0003744459408107007,
      "loss": 0.6758,
      "step": 378700
    },
    {
      "epoch": 4.00959131065366,
      "grad_norm": 0.9344235062599182,
      "learning_rate": 0.0003744066774012525,
      "loss": 0.6738,
      "step": 378750
    },
    {
      "epoch": 4.0101206324336625,
      "grad_norm": 1.018507480621338,
      "learning_rate": 0.0003743666084930165,
      "loss": 0.6631,
      "step": 378800
    },
    {
      "epoch": 4.010649954213666,
      "grad_norm": 0.9165050387382507,
      "learning_rate": 0.00037432653533895016,
      "loss": 0.6781,
      "step": 378850
    },
    {
      "epoch": 4.011179275993669,
      "grad_norm": 1.0183327198028564,
      "learning_rate": 0.00037428645794042146,
      "loss": 0.6748,
      "step": 378900
    },
    {
      "epoch": 4.011708597773673,
      "grad_norm": 1.011522889137268,
      "learning_rate": 0.0003742463762987987,
      "loss": 0.6814,
      "step": 378950
    },
    {
      "epoch": 4.012237919553676,
      "grad_norm": 0.977571964263916,
      "learning_rate": 0.00037420629041545023,
      "loss": 0.6794,
      "step": 379000
    },
    {
      "epoch": 4.012237919553676,
      "eval_loss": 0.47216030955314636,
      "eval_runtime": 46.9083,
      "eval_samples_per_second": 3579.962,
      "eval_steps_per_second": 447.511,
      "step": 379000
    },
    {
      "epoch": 4.0127672413336795,
      "grad_norm": 0.8238886594772339,
      "learning_rate": 0.00037416620029174456,
      "loss": 0.6774,
      "step": 379050
    },
    {
      "epoch": 4.013296563113682,
      "grad_norm": 1.0375821590423584,
      "learning_rate": 0.00037412610592905027,
      "loss": 0.6702,
      "step": 379100
    },
    {
      "epoch": 4.013825884893686,
      "grad_norm": 0.9727690815925598,
      "learning_rate": 0.00037408600732873634,
      "loss": 0.6747,
      "step": 379150
    },
    {
      "epoch": 4.014355206673689,
      "grad_norm": 1.0384535789489746,
      "learning_rate": 0.0003740459044921716,
      "loss": 0.6746,
      "step": 379200
    },
    {
      "epoch": 4.014884528453693,
      "grad_norm": 0.9530359506607056,
      "learning_rate": 0.00037400579742072516,
      "loss": 0.6908,
      "step": 379250
    },
    {
      "epoch": 4.015413850233696,
      "grad_norm": 0.9781568646430969,
      "learning_rate": 0.00037396568611576623,
      "loss": 0.6874,
      "step": 379300
    },
    {
      "epoch": 4.015943172013698,
      "grad_norm": 1.0165163278579712,
      "learning_rate": 0.0003739255705786643,
      "loss": 0.6705,
      "step": 379350
    },
    {
      "epoch": 4.016472493793702,
      "grad_norm": 1.074861764907837,
      "learning_rate": 0.0003738854508107888,
      "loss": 0.6847,
      "step": 379400
    },
    {
      "epoch": 4.017001815573705,
      "grad_norm": 1.0405046939849854,
      "learning_rate": 0.00037384532681350945,
      "loss": 0.6905,
      "step": 379450
    },
    {
      "epoch": 4.017531137353709,
      "grad_norm": 0.9195520281791687,
      "learning_rate": 0.0003738051985881961,
      "loss": 0.6784,
      "step": 379500
    },
    {
      "epoch": 4.017531137353709,
      "eval_loss": 0.4740296006202698,
      "eval_runtime": 46.7918,
      "eval_samples_per_second": 3588.879,
      "eval_steps_per_second": 448.626,
      "step": 379500
    },
    {
      "epoch": 4.018060459133712,
      "grad_norm": 0.9508911371231079,
      "learning_rate": 0.00037376506613621865,
      "loss": 0.6906,
      "step": 379550
    },
    {
      "epoch": 4.018589780913715,
      "grad_norm": 0.9844347238540649,
      "learning_rate": 0.00037372492945894723,
      "loss": 0.6684,
      "step": 379600
    },
    {
      "epoch": 4.019119102693718,
      "grad_norm": 0.9580075740814209,
      "learning_rate": 0.00037368478855775213,
      "loss": 0.6814,
      "step": 379650
    },
    {
      "epoch": 4.019648424473722,
      "grad_norm": 1.0427665710449219,
      "learning_rate": 0.00037364464343400363,
      "loss": 0.684,
      "step": 379700
    },
    {
      "epoch": 4.020177746253725,
      "grad_norm": 0.9333707690238953,
      "learning_rate": 0.00037360449408907237,
      "loss": 0.6696,
      "step": 379750
    },
    {
      "epoch": 4.020707068033729,
      "grad_norm": 0.9846762418746948,
      "learning_rate": 0.00037356434052432906,
      "loss": 0.6815,
      "step": 379800
    },
    {
      "epoch": 4.0212363898137315,
      "grad_norm": 0.9768645763397217,
      "learning_rate": 0.00037352418274114445,
      "loss": 0.6755,
      "step": 379850
    },
    {
      "epoch": 4.021765711593735,
      "grad_norm": 1.0077441930770874,
      "learning_rate": 0.0003734840207408896,
      "loss": 0.6825,
      "step": 379900
    },
    {
      "epoch": 4.022295033373738,
      "grad_norm": 0.9839963912963867,
      "learning_rate": 0.0003734438545249355,
      "loss": 0.6917,
      "step": 379950
    },
    {
      "epoch": 4.022824355153742,
      "grad_norm": 0.9647488594055176,
      "learning_rate": 0.0003734036840946535,
      "loss": 0.6766,
      "step": 380000
    },
    {
      "epoch": 4.022824355153742,
      "eval_loss": 0.4742891490459442,
      "eval_runtime": 46.8115,
      "eval_samples_per_second": 3587.366,
      "eval_steps_per_second": 448.437,
      "step": 380000
    },
    {
      "epoch": 4.023353676933745,
      "grad_norm": 1.0097112655639648,
      "learning_rate": 0.00037336350945141496,
      "loss": 0.6756,
      "step": 380050
    },
    {
      "epoch": 4.023882998713748,
      "grad_norm": 1.0384682416915894,
      "learning_rate": 0.00037332333059659145,
      "loss": 0.6766,
      "step": 380100
    },
    {
      "epoch": 4.024412320493751,
      "grad_norm": 1.1175384521484375,
      "learning_rate": 0.0003732831475315547,
      "loss": 0.6644,
      "step": 380150
    },
    {
      "epoch": 4.024941642273754,
      "grad_norm": 1.0582793951034546,
      "learning_rate": 0.00037324296025767646,
      "loss": 0.6765,
      "step": 380200
    },
    {
      "epoch": 4.025470964053758,
      "grad_norm": 0.9878851771354675,
      "learning_rate": 0.0003732027687763287,
      "loss": 0.6829,
      "step": 380250
    },
    {
      "epoch": 4.026000285833761,
      "grad_norm": 0.9931116700172424,
      "learning_rate": 0.00037316257308888376,
      "loss": 0.6859,
      "step": 380300
    },
    {
      "epoch": 4.026529607613765,
      "grad_norm": 0.9886000156402588,
      "learning_rate": 0.00037312237319671364,
      "loss": 0.6674,
      "step": 380350
    },
    {
      "epoch": 4.0270589293937675,
      "grad_norm": 0.963758647441864,
      "learning_rate": 0.00037308216910119084,
      "loss": 0.6683,
      "step": 380400
    },
    {
      "epoch": 4.027588251173771,
      "grad_norm": 1.190854787826538,
      "learning_rate": 0.00037304196080368803,
      "loss": 0.6771,
      "step": 380450
    },
    {
      "epoch": 4.028117572953774,
      "grad_norm": 0.9879941344261169,
      "learning_rate": 0.0003730017483055777,
      "loss": 0.6567,
      "step": 380500
    },
    {
      "epoch": 4.028117572953774,
      "eval_loss": 0.46982014179229736,
      "eval_runtime": 46.8822,
      "eval_samples_per_second": 3581.954,
      "eval_steps_per_second": 447.76,
      "step": 380500
    },
    {
      "epoch": 4.028646894733778,
      "grad_norm": 0.9624597430229187,
      "learning_rate": 0.0003729615316082328,
      "loss": 0.6904,
      "step": 380550
    },
    {
      "epoch": 4.029176216513781,
      "grad_norm": 0.9314082860946655,
      "learning_rate": 0.0003729213107130264,
      "loss": 0.6678,
      "step": 380600
    },
    {
      "epoch": 4.0297055382937845,
      "grad_norm": 0.986520528793335,
      "learning_rate": 0.00037288108562133146,
      "loss": 0.6793,
      "step": 380650
    },
    {
      "epoch": 4.030234860073787,
      "grad_norm": 1.187723159790039,
      "learning_rate": 0.0003728408563345213,
      "loss": 0.6845,
      "step": 380700
    },
    {
      "epoch": 4.030764181853791,
      "grad_norm": 0.9538193345069885,
      "learning_rate": 0.00037280142756467016,
      "loss": 0.6687,
      "step": 380750
    },
    {
      "epoch": 4.031293503633794,
      "grad_norm": 1.0809963941574097,
      "learning_rate": 0.000372761189975584,
      "loss": 0.6794,
      "step": 380800
    },
    {
      "epoch": 4.031822825413797,
      "grad_norm": 0.8495787978172302,
      "learning_rate": 0.0003727209481954757,
      "loss": 0.6731,
      "step": 380850
    },
    {
      "epoch": 4.032352147193801,
      "grad_norm": 0.9194332957267761,
      "learning_rate": 0.00037268070222571927,
      "loss": 0.6669,
      "step": 380900
    },
    {
      "epoch": 4.0328814689738035,
      "grad_norm": 1.0807310342788696,
      "learning_rate": 0.0003726404520676887,
      "loss": 0.6852,
      "step": 380950
    },
    {
      "epoch": 4.033410790753807,
      "grad_norm": 1.0835061073303223,
      "learning_rate": 0.000372600197722758,
      "loss": 0.6781,
      "step": 381000
    },
    {
      "epoch": 4.033410790753807,
      "eval_loss": 0.4708474278450012,
      "eval_runtime": 46.7685,
      "eval_samples_per_second": 3590.663,
      "eval_steps_per_second": 448.849,
      "step": 381000
    },
    {
      "epoch": 4.03394011253381,
      "grad_norm": 0.9964550137519836,
      "learning_rate": 0.0003725599391923016,
      "loss": 0.6798,
      "step": 381050
    },
    {
      "epoch": 4.034469434313814,
      "grad_norm": 1.0078984498977661,
      "learning_rate": 0.0003725196764776937,
      "loss": 0.693,
      "step": 381100
    },
    {
      "epoch": 4.034998756093817,
      "grad_norm": 1.0181875228881836,
      "learning_rate": 0.00037247940958030906,
      "loss": 0.6683,
      "step": 381150
    },
    {
      "epoch": 4.0355280778738205,
      "grad_norm": 1.0764886140823364,
      "learning_rate": 0.00037243913850152233,
      "loss": 0.6759,
      "step": 381200
    },
    {
      "epoch": 4.036057399653823,
      "grad_norm": 1.0252344608306885,
      "learning_rate": 0.0003723988632427083,
      "loss": 0.672,
      "step": 381250
    },
    {
      "epoch": 4.036586721433827,
      "grad_norm": 0.8368316292762756,
      "learning_rate": 0.0003723585838052419,
      "loss": 0.6737,
      "step": 381300
    },
    {
      "epoch": 4.03711604321383,
      "grad_norm": 0.9206153154373169,
      "learning_rate": 0.0003723183001904984,
      "loss": 0.6823,
      "step": 381350
    },
    {
      "epoch": 4.037645364993834,
      "grad_norm": 1.0070109367370605,
      "learning_rate": 0.00037227801239985293,
      "loss": 0.6806,
      "step": 381400
    },
    {
      "epoch": 4.038174686773837,
      "grad_norm": 0.9974682331085205,
      "learning_rate": 0.000372237720434681,
      "loss": 0.6832,
      "step": 381450
    },
    {
      "epoch": 4.03870400855384,
      "grad_norm": 0.9005982875823975,
      "learning_rate": 0.0003721974242963581,
      "loss": 0.6767,
      "step": 381500
    },
    {
      "epoch": 4.03870400855384,
      "eval_loss": 0.47436439990997314,
      "eval_runtime": 46.9412,
      "eval_samples_per_second": 3577.453,
      "eval_steps_per_second": 447.198,
      "step": 381500
    },
    {
      "epoch": 4.039233330333843,
      "grad_norm": 1.118996500968933,
      "learning_rate": 0.00037215712398626,
      "loss": 0.6815,
      "step": 381550
    },
    {
      "epoch": 4.039762652113846,
      "grad_norm": 0.9021602869033813,
      "learning_rate": 0.0003721168195057624,
      "loss": 0.6798,
      "step": 381600
    },
    {
      "epoch": 4.04029197389385,
      "grad_norm": 1.0544795989990234,
      "learning_rate": 0.0003720765108562414,
      "loss": 0.6842,
      "step": 381650
    },
    {
      "epoch": 4.040821295673853,
      "grad_norm": 0.9753131866455078,
      "learning_rate": 0.0003720361980390731,
      "loss": 0.687,
      "step": 381700
    },
    {
      "epoch": 4.0413506174538565,
      "grad_norm": 0.9774184823036194,
      "learning_rate": 0.00037199588105563374,
      "loss": 0.6695,
      "step": 381750
    },
    {
      "epoch": 4.041879939233859,
      "grad_norm": 0.9877920746803284,
      "learning_rate": 0.00037195555990729976,
      "loss": 0.6759,
      "step": 381800
    },
    {
      "epoch": 4.042409261013863,
      "grad_norm": 1.0445802211761475,
      "learning_rate": 0.00037191523459544773,
      "loss": 0.6745,
      "step": 381850
    },
    {
      "epoch": 4.042938582793866,
      "grad_norm": 1.0896075963974,
      "learning_rate": 0.00037187490512145425,
      "loss": 0.6873,
      "step": 381900
    },
    {
      "epoch": 4.04346790457387,
      "grad_norm": 0.8893606066703796,
      "learning_rate": 0.00037183457148669627,
      "loss": 0.6794,
      "step": 381950
    },
    {
      "epoch": 4.043997226353873,
      "grad_norm": 1.032453179359436,
      "learning_rate": 0.0003717942336925506,
      "loss": 0.6814,
      "step": 382000
    },
    {
      "epoch": 4.043997226353873,
      "eval_loss": 0.4714176058769226,
      "eval_runtime": 46.7718,
      "eval_samples_per_second": 3590.409,
      "eval_steps_per_second": 448.817,
      "step": 382000
    },
    {
      "epoch": 4.044526548133876,
      "grad_norm": 0.9500906467437744,
      "learning_rate": 0.00037175389174039453,
      "loss": 0.666,
      "step": 382050
    },
    {
      "epoch": 4.045055869913879,
      "grad_norm": 0.9630421996116638,
      "learning_rate": 0.00037171354563160524,
      "loss": 0.6734,
      "step": 382100
    },
    {
      "epoch": 4.045585191693883,
      "grad_norm": 1.0354384183883667,
      "learning_rate": 0.0003716731953675602,
      "loss": 0.6838,
      "step": 382150
    },
    {
      "epoch": 4.046114513473886,
      "grad_norm": 0.8863423466682434,
      "learning_rate": 0.0003716328409496368,
      "loss": 0.6765,
      "step": 382200
    },
    {
      "epoch": 4.04664383525389,
      "grad_norm": 1.0824168920516968,
      "learning_rate": 0.0003715924823792128,
      "loss": 0.6726,
      "step": 382250
    },
    {
      "epoch": 4.0471731570338925,
      "grad_norm": 1.098222255706787,
      "learning_rate": 0.00037155211965766614,
      "loss": 0.6848,
      "step": 382300
    },
    {
      "epoch": 4.047702478813895,
      "grad_norm": 1.0381513833999634,
      "learning_rate": 0.00037151175278637456,
      "loss": 0.6791,
      "step": 382350
    },
    {
      "epoch": 4.048231800593899,
      "grad_norm": 1.0313838720321655,
      "learning_rate": 0.00037147138176671634,
      "loss": 0.6681,
      "step": 382400
    },
    {
      "epoch": 4.048761122373902,
      "grad_norm": 1.0106866359710693,
      "learning_rate": 0.0003714310066000698,
      "loss": 0.6856,
      "step": 382450
    },
    {
      "epoch": 4.049290444153906,
      "grad_norm": 1.0658650398254395,
      "learning_rate": 0.00037139062728781314,
      "loss": 0.6891,
      "step": 382500
    },
    {
      "epoch": 4.049290444153906,
      "eval_loss": 0.4716564416885376,
      "eval_runtime": 47.0175,
      "eval_samples_per_second": 3571.649,
      "eval_steps_per_second": 446.472,
      "step": 382500
    },
    {
      "epoch": 4.049819765933909,
      "grad_norm": 1.0395259857177734,
      "learning_rate": 0.000371350243831325,
      "loss": 0.6797,
      "step": 382550
    },
    {
      "epoch": 4.050349087713912,
      "grad_norm": 1.0157959461212158,
      "learning_rate": 0.00037130985623198403,
      "loss": 0.6863,
      "step": 382600
    },
    {
      "epoch": 4.050878409493915,
      "grad_norm": 0.9990686178207397,
      "learning_rate": 0.0003712694644911691,
      "loss": 0.6763,
      "step": 382650
    },
    {
      "epoch": 4.051407731273919,
      "grad_norm": 0.9397115707397461,
      "learning_rate": 0.00037122906861025907,
      "loss": 0.6908,
      "step": 382700
    },
    {
      "epoch": 4.051937053053922,
      "grad_norm": 1.0538833141326904,
      "learning_rate": 0.00037118866859063316,
      "loss": 0.6779,
      "step": 382750
    },
    {
      "epoch": 4.052466374833926,
      "grad_norm": 0.9963693618774414,
      "learning_rate": 0.0003711490725573467,
      "loss": 0.6787,
      "step": 382800
    },
    {
      "epoch": 4.0529956966139284,
      "grad_norm": 0.8103892207145691,
      "learning_rate": 0.00037110866434713236,
      "loss": 0.6775,
      "step": 382850
    },
    {
      "epoch": 4.053525018393932,
      "grad_norm": 1.1362230777740479,
      "learning_rate": 0.00037106825200231263,
      "loss": 0.6775,
      "step": 382900
    },
    {
      "epoch": 4.054054340173935,
      "grad_norm": 1.0497244596481323,
      "learning_rate": 0.00037102783552426724,
      "loss": 0.6593,
      "step": 382950
    },
    {
      "epoch": 4.054583661953939,
      "grad_norm": 1.0145504474639893,
      "learning_rate": 0.00037098741491437584,
      "loss": 0.673,
      "step": 383000
    },
    {
      "epoch": 4.054583661953939,
      "eval_loss": 0.4719735383987427,
      "eval_runtime": 46.9045,
      "eval_samples_per_second": 3580.253,
      "eval_steps_per_second": 447.548,
      "step": 383000
    },
    {
      "epoch": 4.055112983733942,
      "grad_norm": 0.9071434736251831,
      "learning_rate": 0.0003709469901740185,
      "loss": 0.6799,
      "step": 383050
    },
    {
      "epoch": 4.055642305513945,
      "grad_norm": 0.9968249797821045,
      "learning_rate": 0.0003709065613045753,
      "loss": 0.6812,
      "step": 383100
    },
    {
      "epoch": 4.056171627293948,
      "grad_norm": 1.0491225719451904,
      "learning_rate": 0.0003708661283074264,
      "loss": 0.6702,
      "step": 383150
    },
    {
      "epoch": 4.056700949073951,
      "grad_norm": 0.9293622374534607,
      "learning_rate": 0.0003708256911839522,
      "loss": 0.6761,
      "step": 383200
    },
    {
      "epoch": 4.057230270853955,
      "grad_norm": 1.0414104461669922,
      "learning_rate": 0.00037078524993553326,
      "loss": 0.6777,
      "step": 383250
    },
    {
      "epoch": 4.057759592633958,
      "grad_norm": 0.994636595249176,
      "learning_rate": 0.00037074480456355017,
      "loss": 0.6886,
      "step": 383300
    },
    {
      "epoch": 4.058288914413962,
      "grad_norm": 1.0533076524734497,
      "learning_rate": 0.0003707043550693837,
      "loss": 0.6778,
      "step": 383350
    },
    {
      "epoch": 4.058818236193964,
      "grad_norm": 1.0704678297042847,
      "learning_rate": 0.0003706639014544149,
      "loss": 0.6716,
      "step": 383400
    },
    {
      "epoch": 4.059347557973968,
      "grad_norm": 0.9974279403686523,
      "learning_rate": 0.00037062344372002464,
      "loss": 0.6822,
      "step": 383450
    },
    {
      "epoch": 4.059876879753971,
      "grad_norm": 0.9553862810134888,
      "learning_rate": 0.00037058298186759433,
      "loss": 0.6785,
      "step": 383500
    },
    {
      "epoch": 4.059876879753971,
      "eval_loss": 0.4703224003314972,
      "eval_runtime": 46.9647,
      "eval_samples_per_second": 3575.665,
      "eval_steps_per_second": 446.974,
      "step": 383500
    },
    {
      "epoch": 4.060406201533975,
      "grad_norm": 1.0302191972732544,
      "learning_rate": 0.0003705425158985052,
      "loss": 0.6709,
      "step": 383550
    },
    {
      "epoch": 4.060935523313978,
      "grad_norm": 1.085049033164978,
      "learning_rate": 0.0003705020458141387,
      "loss": 0.6777,
      "step": 383600
    },
    {
      "epoch": 4.061464845093981,
      "grad_norm": 1.0927752256393433,
      "learning_rate": 0.0003704615716158767,
      "loss": 0.6835,
      "step": 383650
    },
    {
      "epoch": 4.061994166873984,
      "grad_norm": 1.0670862197875977,
      "learning_rate": 0.00037042109330510074,
      "loss": 0.6772,
      "step": 383700
    },
    {
      "epoch": 4.062523488653988,
      "grad_norm": 1.0404539108276367,
      "learning_rate": 0.00037038061088319284,
      "loss": 0.6605,
      "step": 383750
    },
    {
      "epoch": 4.063052810433991,
      "grad_norm": 1.0158734321594238,
      "learning_rate": 0.00037034012435153507,
      "loss": 0.661,
      "step": 383800
    },
    {
      "epoch": 4.063582132213994,
      "grad_norm": 1.026131510734558,
      "learning_rate": 0.0003702996337115095,
      "loss": 0.6915,
      "step": 383850
    },
    {
      "epoch": 4.0641114539939975,
      "grad_norm": 0.926776111125946,
      "learning_rate": 0.0003702591389644987,
      "loss": 0.6685,
      "step": 383900
    },
    {
      "epoch": 4.064640775774,
      "grad_norm": 1.0588403940200806,
      "learning_rate": 0.0003702186401118849,
      "loss": 0.6701,
      "step": 383950
    },
    {
      "epoch": 4.065170097554004,
      "grad_norm": 0.9971224665641785,
      "learning_rate": 0.00037017813715505075,
      "loss": 0.6996,
      "step": 384000
    },
    {
      "epoch": 4.065170097554004,
      "eval_loss": 0.4716447591781616,
      "eval_runtime": 46.8641,
      "eval_samples_per_second": 3583.338,
      "eval_steps_per_second": 447.933,
      "step": 384000
    },
    {
      "epoch": 4.065699419334007,
      "grad_norm": 0.9672616124153137,
      "learning_rate": 0.00037013763009537923,
      "loss": 0.6732,
      "step": 384050
    },
    {
      "epoch": 4.066228741114011,
      "grad_norm": 0.9651072025299072,
      "learning_rate": 0.00037009711893425297,
      "loss": 0.6878,
      "step": 384100
    },
    {
      "epoch": 4.066758062894014,
      "grad_norm": 0.9766006469726562,
      "learning_rate": 0.0003700566036730552,
      "loss": 0.6621,
      "step": 384150
    },
    {
      "epoch": 4.067287384674017,
      "grad_norm": 1.0127259492874146,
      "learning_rate": 0.0003700160843131689,
      "loss": 0.6823,
      "step": 384200
    },
    {
      "epoch": 4.06781670645402,
      "grad_norm": 1.0162776708602905,
      "learning_rate": 0.0003699755608559776,
      "loss": 0.6772,
      "step": 384250
    },
    {
      "epoch": 4.068346028234024,
      "grad_norm": 0.9670246243476868,
      "learning_rate": 0.00036993503330286454,
      "loss": 0.6872,
      "step": 384300
    },
    {
      "epoch": 4.068875350014027,
      "grad_norm": 1.0956182479858398,
      "learning_rate": 0.00036989450165521347,
      "loss": 0.6688,
      "step": 384350
    },
    {
      "epoch": 4.069404671794031,
      "grad_norm": 0.9825306534767151,
      "learning_rate": 0.0003698539659144081,
      "loss": 0.6846,
      "step": 384400
    },
    {
      "epoch": 4.0699339935740335,
      "grad_norm": 0.9500319361686707,
      "learning_rate": 0.0003698134260818323,
      "loss": 0.6726,
      "step": 384450
    },
    {
      "epoch": 4.070463315354037,
      "grad_norm": 1.1520143747329712,
      "learning_rate": 0.0003697728821588701,
      "loss": 0.6752,
      "step": 384500
    },
    {
      "epoch": 4.070463315354037,
      "eval_loss": 0.46788036823272705,
      "eval_runtime": 46.8509,
      "eval_samples_per_second": 3584.35,
      "eval_steps_per_second": 448.06,
      "step": 384500
    },
    {
      "epoch": 4.07099263713404,
      "grad_norm": 0.9763860702514648,
      "learning_rate": 0.00036973233414690557,
      "loss": 0.6687,
      "step": 384550
    },
    {
      "epoch": 4.071521958914043,
      "grad_norm": 1.0962483882904053,
      "learning_rate": 0.000369691782047323,
      "loss": 0.6667,
      "step": 384600
    },
    {
      "epoch": 4.072051280694047,
      "grad_norm": 0.9442086815834045,
      "learning_rate": 0.000369651225861507,
      "loss": 0.6761,
      "step": 384650
    },
    {
      "epoch": 4.07258060247405,
      "grad_norm": 1.0039222240447998,
      "learning_rate": 0.000369610665590842,
      "loss": 0.6827,
      "step": 384700
    },
    {
      "epoch": 4.073109924254053,
      "grad_norm": 0.9830314517021179,
      "learning_rate": 0.00036957010123671275,
      "loss": 0.6725,
      "step": 384750
    },
    {
      "epoch": 4.073639246034056,
      "grad_norm": 1.02338445186615,
      "learning_rate": 0.00036952953280050413,
      "loss": 0.6688,
      "step": 384800
    },
    {
      "epoch": 4.07416856781406,
      "grad_norm": 0.9643582105636597,
      "learning_rate": 0.0003694897717739209,
      "loss": 0.6844,
      "step": 384850
    },
    {
      "epoch": 4.074697889594063,
      "grad_norm": 0.9444805979728699,
      "learning_rate": 0.0003694491952592812,
      "loss": 0.675,
      "step": 384900
    },
    {
      "epoch": 4.075227211374067,
      "grad_norm": 1.0326130390167236,
      "learning_rate": 0.0003694086146666897,
      "loss": 0.6698,
      "step": 384950
    },
    {
      "epoch": 4.0757565331540695,
      "grad_norm": 0.9074367880821228,
      "learning_rate": 0.00036936802999753193,
      "loss": 0.6872,
      "step": 385000
    },
    {
      "epoch": 4.0757565331540695,
      "eval_loss": 0.4717492461204529,
      "eval_runtime": 46.8828,
      "eval_samples_per_second": 3581.908,
      "eval_steps_per_second": 447.754,
      "step": 385000
    },
    {
      "epoch": 4.076285854934073,
      "grad_norm": 0.997643768787384,
      "learning_rate": 0.0003693274412531934,
      "loss": 0.6663,
      "step": 385050
    },
    {
      "epoch": 4.076815176714076,
      "grad_norm": 0.9808511137962341,
      "learning_rate": 0.00036928684843505976,
      "loss": 0.6744,
      "step": 385100
    },
    {
      "epoch": 4.07734449849408,
      "grad_norm": 1.0347687005996704,
      "learning_rate": 0.0003692462515445169,
      "loss": 0.6746,
      "step": 385150
    },
    {
      "epoch": 4.077873820274083,
      "grad_norm": 1.0090994834899902,
      "learning_rate": 0.0003692056505829507,
      "loss": 0.6769,
      "step": 385200
    },
    {
      "epoch": 4.0784031420540865,
      "grad_norm": 1.0396026372909546,
      "learning_rate": 0.00036916504555174734,
      "loss": 0.6753,
      "step": 385250
    },
    {
      "epoch": 4.078932463834089,
      "grad_norm": 0.9556496739387512,
      "learning_rate": 0.000369124436452293,
      "loss": 0.6908,
      "step": 385300
    },
    {
      "epoch": 4.079461785614092,
      "grad_norm": 0.9726169109344482,
      "learning_rate": 0.0003690838232859741,
      "loss": 0.6733,
      "step": 385350
    },
    {
      "epoch": 4.079991107394096,
      "grad_norm": 1.0264980792999268,
      "learning_rate": 0.00036904320605417714,
      "loss": 0.6817,
      "step": 385400
    },
    {
      "epoch": 4.080520429174099,
      "grad_norm": 1.0067349672317505,
      "learning_rate": 0.0003690025847582888,
      "loss": 0.6689,
      "step": 385450
    },
    {
      "epoch": 4.081049750954103,
      "grad_norm": 1.0003687143325806,
      "learning_rate": 0.00036896195939969587,
      "loss": 0.6706,
      "step": 385500
    },
    {
      "epoch": 4.081049750954103,
      "eval_loss": 0.4677509367465973,
      "eval_runtime": 46.8767,
      "eval_samples_per_second": 3582.377,
      "eval_steps_per_second": 447.813,
      "step": 385500
    },
    {
      "epoch": 4.0815790727341055,
      "grad_norm": 1.0062639713287354,
      "learning_rate": 0.0003689213299797852,
      "loss": 0.6665,
      "step": 385550
    },
    {
      "epoch": 4.082108394514109,
      "grad_norm": 0.9394998550415039,
      "learning_rate": 0.000368880696499944,
      "loss": 0.6827,
      "step": 385600
    },
    {
      "epoch": 4.082637716294112,
      "grad_norm": 1.0046623945236206,
      "learning_rate": 0.00036884005896155943,
      "loss": 0.6722,
      "step": 385650
    },
    {
      "epoch": 4.083167038074116,
      "grad_norm": 0.9653576016426086,
      "learning_rate": 0.00036879941736601876,
      "loss": 0.6752,
      "step": 385700
    },
    {
      "epoch": 4.083696359854119,
      "grad_norm": 1.0147820711135864,
      "learning_rate": 0.00036875877171470956,
      "loss": 0.6787,
      "step": 385750
    },
    {
      "epoch": 4.0842256816341225,
      "grad_norm": 0.9666523337364197,
      "learning_rate": 0.0003687181220090195,
      "loss": 0.6714,
      "step": 385800
    },
    {
      "epoch": 4.084755003414125,
      "grad_norm": 0.9241102337837219,
      "learning_rate": 0.00036867746825033627,
      "loss": 0.6802,
      "step": 385850
    },
    {
      "epoch": 4.085284325194129,
      "grad_norm": 1.0197614431381226,
      "learning_rate": 0.00036863681044004785,
      "loss": 0.6701,
      "step": 385900
    },
    {
      "epoch": 4.085813646974132,
      "grad_norm": 0.9394236207008362,
      "learning_rate": 0.0003685961485795422,
      "loss": 0.6816,
      "step": 385950
    },
    {
      "epoch": 4.086342968754136,
      "grad_norm": 1.0302149057388306,
      "learning_rate": 0.0003685554826702075,
      "loss": 0.677,
      "step": 386000
    },
    {
      "epoch": 4.086342968754136,
      "eval_loss": 0.46755391359329224,
      "eval_runtime": 47.2004,
      "eval_samples_per_second": 3557.812,
      "eval_steps_per_second": 444.742,
      "step": 386000
    },
    {
      "epoch": 4.086872290534139,
      "grad_norm": 0.9926055669784546,
      "learning_rate": 0.0003685148127134321,
      "loss": 0.6775,
      "step": 386050
    },
    {
      "epoch": 4.087401612314142,
      "grad_norm": 0.9559949636459351,
      "learning_rate": 0.00036847413871060445,
      "loss": 0.6692,
      "step": 386100
    },
    {
      "epoch": 4.087930934094145,
      "grad_norm": 0.9252493381500244,
      "learning_rate": 0.0003684334606631132,
      "loss": 0.6772,
      "step": 386150
    },
    {
      "epoch": 4.088460255874148,
      "grad_norm": 1.1318821907043457,
      "learning_rate": 0.00036839277857234705,
      "loss": 0.6799,
      "step": 386200
    },
    {
      "epoch": 4.088989577654152,
      "grad_norm": 0.8934460282325745,
      "learning_rate": 0.0003683520924396948,
      "loss": 0.6707,
      "step": 386250
    },
    {
      "epoch": 4.089518899434155,
      "grad_norm": 0.9595935940742493,
      "learning_rate": 0.00036831140226654556,
      "loss": 0.6937,
      "step": 386300
    },
    {
      "epoch": 4.0900482212141585,
      "grad_norm": 1.0838847160339355,
      "learning_rate": 0.0003682707080542884,
      "loss": 0.6752,
      "step": 386350
    },
    {
      "epoch": 4.090577542994161,
      "grad_norm": 0.9409285187721252,
      "learning_rate": 0.0003682300098043126,
      "loss": 0.6704,
      "step": 386400
    },
    {
      "epoch": 4.091106864774165,
      "grad_norm": 0.9474110007286072,
      "learning_rate": 0.0003681893075180078,
      "loss": 0.6769,
      "step": 386450
    },
    {
      "epoch": 4.091636186554168,
      "grad_norm": 0.9346114993095398,
      "learning_rate": 0.00036814860119676316,
      "loss": 0.6759,
      "step": 386500
    },
    {
      "epoch": 4.091636186554168,
      "eval_loss": 0.46607041358947754,
      "eval_runtime": 53.2384,
      "eval_samples_per_second": 3154.303,
      "eval_steps_per_second": 394.302,
      "step": 386500
    },
    {
      "epoch": 4.092165508334172,
      "grad_norm": 0.9751490354537964,
      "learning_rate": 0.0003681078908419688,
      "loss": 0.6793,
      "step": 386550
    },
    {
      "epoch": 4.092694830114175,
      "grad_norm": 0.9615724682807922,
      "learning_rate": 0.00036806717645501425,
      "loss": 0.6867,
      "step": 386600
    },
    {
      "epoch": 4.093224151894178,
      "grad_norm": 0.9028580188751221,
      "learning_rate": 0.0003680264580372896,
      "loss": 0.6664,
      "step": 386650
    },
    {
      "epoch": 4.093753473674181,
      "grad_norm": 1.0214893817901611,
      "learning_rate": 0.000367985735590185,
      "loss": 0.669,
      "step": 386700
    },
    {
      "epoch": 4.094282795454185,
      "grad_norm": 1.0041050910949707,
      "learning_rate": 0.0003679450091150907,
      "loss": 0.6587,
      "step": 386750
    },
    {
      "epoch": 4.094812117234188,
      "grad_norm": 0.9804525971412659,
      "learning_rate": 0.0003679042786133969,
      "loss": 0.6788,
      "step": 386800
    },
    {
      "epoch": 4.095341439014192,
      "grad_norm": 1.0182666778564453,
      "learning_rate": 0.00036786354408649435,
      "loss": 0.6843,
      "step": 386850
    },
    {
      "epoch": 4.095870760794194,
      "grad_norm": 0.9415866136550903,
      "learning_rate": 0.0003678236203462125,
      "loss": 0.6848,
      "step": 386900
    },
    {
      "epoch": 4.096400082574197,
      "grad_norm": 1.0177550315856934,
      "learning_rate": 0.0003677828778534993,
      "loss": 0.6737,
      "step": 386950
    },
    {
      "epoch": 4.096929404354201,
      "grad_norm": 0.9766831398010254,
      "learning_rate": 0.00036774213133972187,
      "loss": 0.6837,
      "step": 387000
    },
    {
      "epoch": 4.096929404354201,
      "eval_loss": 0.4694986343383789,
      "eval_runtime": 46.9497,
      "eval_samples_per_second": 3576.805,
      "eval_steps_per_second": 447.117,
      "step": 387000
    },
    {
      "epoch": 4.097458726134204,
      "grad_norm": 1.0715694427490234,
      "learning_rate": 0.00036770138080627124,
      "loss": 0.677,
      "step": 387050
    },
    {
      "epoch": 4.097988047914208,
      "grad_norm": 1.0060319900512695,
      "learning_rate": 0.0003676606262545387,
      "loss": 0.6776,
      "step": 387100
    },
    {
      "epoch": 4.0985173696942105,
      "grad_norm": 0.9755809307098389,
      "learning_rate": 0.00036761986768591543,
      "loss": 0.6827,
      "step": 387150
    },
    {
      "epoch": 4.099046691474214,
      "grad_norm": 0.9260755181312561,
      "learning_rate": 0.00036757910510179303,
      "loss": 0.6767,
      "step": 387200
    },
    {
      "epoch": 4.099576013254217,
      "grad_norm": 1.0299715995788574,
      "learning_rate": 0.0003675383385035632,
      "loss": 0.6888,
      "step": 387250
    },
    {
      "epoch": 4.100105335034221,
      "grad_norm": 1.0497723817825317,
      "learning_rate": 0.00036749756789261753,
      "loss": 0.6843,
      "step": 387300
    },
    {
      "epoch": 4.100634656814224,
      "grad_norm": 0.9602921009063721,
      "learning_rate": 0.00036745679327034796,
      "loss": 0.6829,
      "step": 387350
    },
    {
      "epoch": 4.1011639785942275,
      "grad_norm": 0.9709675312042236,
      "learning_rate": 0.0003674160146381466,
      "loss": 0.6767,
      "step": 387400
    },
    {
      "epoch": 4.10169330037423,
      "grad_norm": 0.9521270394325256,
      "learning_rate": 0.0003673752319974056,
      "loss": 0.6761,
      "step": 387450
    },
    {
      "epoch": 4.102222622154234,
      "grad_norm": 0.9535776972770691,
      "learning_rate": 0.0003673344453495171,
      "loss": 0.6774,
      "step": 387500
    },
    {
      "epoch": 4.102222622154234,
      "eval_loss": 0.46764644980430603,
      "eval_runtime": 46.8814,
      "eval_samples_per_second": 3582.019,
      "eval_steps_per_second": 447.768,
      "step": 387500
    },
    {
      "epoch": 4.102751943934237,
      "grad_norm": 0.9842532873153687,
      "learning_rate": 0.0003672936546958738,
      "loss": 0.6704,
      "step": 387550
    },
    {
      "epoch": 4.103281265714241,
      "grad_norm": 0.9262149333953857,
      "learning_rate": 0.00036725286003786806,
      "loss": 0.6821,
      "step": 387600
    },
    {
      "epoch": 4.103810587494244,
      "grad_norm": 0.911479651927948,
      "learning_rate": 0.00036721206137689267,
      "loss": 0.6853,
      "step": 387650
    },
    {
      "epoch": 4.1043399092742465,
      "grad_norm": 1.004415512084961,
      "learning_rate": 0.00036717125871434054,
      "loss": 0.6796,
      "step": 387700
    },
    {
      "epoch": 4.10486923105425,
      "grad_norm": 0.9931173920631409,
      "learning_rate": 0.00036713045205160455,
      "loss": 0.6723,
      "step": 387750
    },
    {
      "epoch": 4.105398552834253,
      "grad_norm": 0.9946351647377014,
      "learning_rate": 0.00036708964139007795,
      "loss": 0.6747,
      "step": 387800
    },
    {
      "epoch": 4.105927874614257,
      "grad_norm": 0.8761507272720337,
      "learning_rate": 0.00036704882673115394,
      "loss": 0.6764,
      "step": 387850
    },
    {
      "epoch": 4.10645719639426,
      "grad_norm": 1.0608845949172974,
      "learning_rate": 0.0003670080080762258,
      "loss": 0.6806,
      "step": 387900
    },
    {
      "epoch": 4.1069865181742635,
      "grad_norm": 1.0236883163452148,
      "learning_rate": 0.0003669671854266873,
      "loss": 0.674,
      "step": 387950
    },
    {
      "epoch": 4.107515839954266,
      "grad_norm": 0.9533730149269104,
      "learning_rate": 0.0003669263587839319,
      "loss": 0.6849,
      "step": 388000
    },
    {
      "epoch": 4.107515839954266,
      "eval_loss": 0.46818777918815613,
      "eval_runtime": 46.8887,
      "eval_samples_per_second": 3581.458,
      "eval_steps_per_second": 447.698,
      "step": 388000
    },
    {
      "epoch": 4.10804516173427,
      "grad_norm": 1.0914806127548218,
      "learning_rate": 0.0003668855281493535,
      "loss": 0.6769,
      "step": 388050
    },
    {
      "epoch": 4.108574483514273,
      "grad_norm": 1.0687898397445679,
      "learning_rate": 0.0003668446935243461,
      "loss": 0.6781,
      "step": 388100
    },
    {
      "epoch": 4.109103805294277,
      "grad_norm": 1.0267096757888794,
      "learning_rate": 0.00036680385491030365,
      "loss": 0.6657,
      "step": 388150
    },
    {
      "epoch": 4.10963312707428,
      "grad_norm": 1.0925456285476685,
      "learning_rate": 0.00036676301230862047,
      "loss": 0.6819,
      "step": 388200
    },
    {
      "epoch": 4.110162448854283,
      "grad_norm": 1.0077913999557495,
      "learning_rate": 0.00036672216572069085,
      "loss": 0.6751,
      "step": 388250
    },
    {
      "epoch": 4.110691770634286,
      "grad_norm": 0.9573802351951599,
      "learning_rate": 0.00036668131514790934,
      "loss": 0.6791,
      "step": 388300
    },
    {
      "epoch": 4.11122109241429,
      "grad_norm": 1.1219511032104492,
      "learning_rate": 0.0003666404605916705,
      "loss": 0.6693,
      "step": 388350
    },
    {
      "epoch": 4.111750414194293,
      "grad_norm": 0.9368433356285095,
      "learning_rate": 0.0003665996020533691,
      "loss": 0.676,
      "step": 388400
    },
    {
      "epoch": 4.112279735974296,
      "grad_norm": 0.9335055351257324,
      "learning_rate": 0.00036655873953440004,
      "loss": 0.6807,
      "step": 388450
    },
    {
      "epoch": 4.1128090577542995,
      "grad_norm": 1.0329381227493286,
      "learning_rate": 0.00036651787303615836,
      "loss": 0.6782,
      "step": 388500
    },
    {
      "epoch": 4.1128090577542995,
      "eval_loss": 0.46780499815940857,
      "eval_runtime": 46.8135,
      "eval_samples_per_second": 3587.217,
      "eval_steps_per_second": 448.418,
      "step": 388500
    },
    {
      "epoch": 4.113338379534302,
      "grad_norm": 1.0083235502243042,
      "learning_rate": 0.00036647700256003924,
      "loss": 0.6832,
      "step": 388550
    },
    {
      "epoch": 4.113867701314306,
      "grad_norm": 0.9574456214904785,
      "learning_rate": 0.000366436128107438,
      "loss": 0.6723,
      "step": 388600
    },
    {
      "epoch": 4.114397023094309,
      "grad_norm": 0.9109792709350586,
      "learning_rate": 0.00036639524967975,
      "loss": 0.6735,
      "step": 388650
    },
    {
      "epoch": 4.114926344874313,
      "grad_norm": 1.0155997276306152,
      "learning_rate": 0.0003663543672783709,
      "loss": 0.6828,
      "step": 388700
    },
    {
      "epoch": 4.115455666654316,
      "grad_norm": 1.051965594291687,
      "learning_rate": 0.0003663134809046963,
      "loss": 0.6682,
      "step": 388750
    },
    {
      "epoch": 4.115984988434319,
      "grad_norm": 0.9148169159889221,
      "learning_rate": 0.0003662725905601222,
      "loss": 0.672,
      "step": 388800
    },
    {
      "epoch": 4.116514310214322,
      "grad_norm": 0.8866551518440247,
      "learning_rate": 0.00036623169624604444,
      "loss": 0.6788,
      "step": 388850
    },
    {
      "epoch": 4.117043631994326,
      "grad_norm": 1.0074504613876343,
      "learning_rate": 0.00036619079796385923,
      "loss": 0.676,
      "step": 388900
    },
    {
      "epoch": 4.117572953774329,
      "grad_norm": 0.8560884594917297,
      "learning_rate": 0.0003661498957149628,
      "loss": 0.6719,
      "step": 388950
    },
    {
      "epoch": 4.118102275554333,
      "grad_norm": 0.9904484152793884,
      "learning_rate": 0.0003661098076638868,
      "loss": 0.6784,
      "step": 389000
    },
    {
      "epoch": 4.118102275554333,
      "eval_loss": 0.4679029583930969,
      "eval_runtime": 46.8313,
      "eval_samples_per_second": 3585.846,
      "eval_steps_per_second": 448.247,
      "step": 389000
    },
    {
      "epoch": 4.1186315973343355,
      "grad_norm": 1.0830132961273193,
      "learning_rate": 0.00036606889756502187,
      "loss": 0.6758,
      "step": 389050
    },
    {
      "epoch": 4.119160919114339,
      "grad_norm": 1.0304251909255981,
      "learning_rate": 0.00036602798350360733,
      "loss": 0.6839,
      "step": 389100
    },
    {
      "epoch": 4.119690240894342,
      "grad_norm": 0.9848104119300842,
      "learning_rate": 0.00036598706548104,
      "loss": 0.6685,
      "step": 389150
    },
    {
      "epoch": 4.120219562674345,
      "grad_norm": 1.015276312828064,
      "learning_rate": 0.0003659461434987168,
      "loss": 0.6811,
      "step": 389200
    },
    {
      "epoch": 4.120748884454349,
      "grad_norm": 1.0019012689590454,
      "learning_rate": 0.00036590521755803477,
      "loss": 0.6678,
      "step": 389250
    },
    {
      "epoch": 4.121278206234352,
      "grad_norm": 0.9438310265541077,
      "learning_rate": 0.00036586428766039115,
      "loss": 0.6733,
      "step": 389300
    },
    {
      "epoch": 4.121807528014355,
      "grad_norm": 0.9866993427276611,
      "learning_rate": 0.0003658233538071832,
      "loss": 0.6705,
      "step": 389350
    },
    {
      "epoch": 4.122336849794358,
      "grad_norm": 0.9909096360206604,
      "learning_rate": 0.00036578241599980843,
      "loss": 0.6795,
      "step": 389400
    },
    {
      "epoch": 4.122866171574362,
      "grad_norm": 0.989292562007904,
      "learning_rate": 0.00036574147423966446,
      "loss": 0.6772,
      "step": 389450
    },
    {
      "epoch": 4.123395493354365,
      "grad_norm": 0.9126049876213074,
      "learning_rate": 0.000365700528528149,
      "loss": 0.6643,
      "step": 389500
    },
    {
      "epoch": 4.123395493354365,
      "eval_loss": 0.4664021134376526,
      "eval_runtime": 46.8522,
      "eval_samples_per_second": 3584.247,
      "eval_steps_per_second": 448.047,
      "step": 389500
    },
    {
      "epoch": 4.123924815134369,
      "grad_norm": 1.1146281957626343,
      "learning_rate": 0.00036565957886665996,
      "loss": 0.6839,
      "step": 389550
    },
    {
      "epoch": 4.1244541369143715,
      "grad_norm": 0.9800648093223572,
      "learning_rate": 0.00036561862525659526,
      "loss": 0.6783,
      "step": 389600
    },
    {
      "epoch": 4.124983458694375,
      "grad_norm": 0.8491779565811157,
      "learning_rate": 0.0003655776676993531,
      "loss": 0.6737,
      "step": 389650
    },
    {
      "epoch": 4.125512780474378,
      "grad_norm": 0.9668752551078796,
      "learning_rate": 0.0003655367061963318,
      "loss": 0.6712,
      "step": 389700
    },
    {
      "epoch": 4.126042102254382,
      "grad_norm": 1.1176629066467285,
      "learning_rate": 0.0003654957407489297,
      "loss": 0.669,
      "step": 389750
    },
    {
      "epoch": 4.126571424034385,
      "grad_norm": 0.9597318768501282,
      "learning_rate": 0.00036545477135854537,
      "loss": 0.6641,
      "step": 389800
    },
    {
      "epoch": 4.1271007458143885,
      "grad_norm": 1.017900824546814,
      "learning_rate": 0.00036541379802657747,
      "loss": 0.6714,
      "step": 389850
    },
    {
      "epoch": 4.127630067594391,
      "grad_norm": 0.9855208992958069,
      "learning_rate": 0.00036537282075442486,
      "loss": 0.6596,
      "step": 389900
    },
    {
      "epoch": 4.128159389374394,
      "grad_norm": 0.9631058573722839,
      "learning_rate": 0.0003653318395434864,
      "loss": 0.6763,
      "step": 389950
    },
    {
      "epoch": 4.128688711154398,
      "grad_norm": 1.068748950958252,
      "learning_rate": 0.0003652908543951612,
      "loss": 0.6804,
      "step": 390000
    },
    {
      "epoch": 4.128688711154398,
      "eval_loss": 0.46729588508605957,
      "eval_runtime": 46.8175,
      "eval_samples_per_second": 3586.906,
      "eval_steps_per_second": 448.379,
      "step": 390000
    },
    {
      "epoch": 4.129218032934401,
      "grad_norm": 1.0152881145477295,
      "learning_rate": 0.00036524986531084864,
      "loss": 0.6791,
      "step": 390050
    },
    {
      "epoch": 4.129747354714405,
      "grad_norm": 1.0136945247650146,
      "learning_rate": 0.0003652088722919479,
      "loss": 0.6656,
      "step": 390100
    },
    {
      "epoch": 4.130276676494407,
      "grad_norm": 0.9384137988090515,
      "learning_rate": 0.0003651678753398585,
      "loss": 0.6864,
      "step": 390150
    },
    {
      "epoch": 4.130805998274411,
      "grad_norm": 1.0155863761901855,
      "learning_rate": 0.0003651268744559801,
      "loss": 0.6764,
      "step": 390200
    },
    {
      "epoch": 4.131335320054414,
      "grad_norm": 1.0427519083023071,
      "learning_rate": 0.0003650858696417124,
      "loss": 0.6744,
      "step": 390250
    },
    {
      "epoch": 4.131864641834418,
      "grad_norm": 1.0684373378753662,
      "learning_rate": 0.00036504486089845536,
      "loss": 0.6719,
      "step": 390300
    },
    {
      "epoch": 4.132393963614421,
      "grad_norm": 1.003266453742981,
      "learning_rate": 0.0003650038482276089,
      "loss": 0.6739,
      "step": 390350
    },
    {
      "epoch": 4.132923285394424,
      "grad_norm": 1.0015807151794434,
      "learning_rate": 0.00036496283163057325,
      "loss": 0.673,
      "step": 390400
    },
    {
      "epoch": 4.133452607174427,
      "grad_norm": 1.0072145462036133,
      "learning_rate": 0.0003649218111087487,
      "loss": 0.6749,
      "step": 390450
    },
    {
      "epoch": 4.133981928954431,
      "grad_norm": 1.0588815212249756,
      "learning_rate": 0.0003648807866635357,
      "loss": 0.673,
      "step": 390500
    },
    {
      "epoch": 4.133981928954431,
      "eval_loss": 0.4666036069393158,
      "eval_runtime": 46.9612,
      "eval_samples_per_second": 3575.93,
      "eval_steps_per_second": 447.007,
      "step": 390500
    },
    {
      "epoch": 4.134511250734434,
      "grad_norm": 1.072636604309082,
      "learning_rate": 0.00036483975829633474,
      "loss": 0.677,
      "step": 390550
    },
    {
      "epoch": 4.135040572514438,
      "grad_norm": 1.0804355144500732,
      "learning_rate": 0.0003647987260085465,
      "loss": 0.6836,
      "step": 390600
    },
    {
      "epoch": 4.1355698942944406,
      "grad_norm": 1.0341960191726685,
      "learning_rate": 0.00036475768980157193,
      "loss": 0.6835,
      "step": 390650
    },
    {
      "epoch": 4.136099216074443,
      "grad_norm": 0.9366632103919983,
      "learning_rate": 0.00036471664967681187,
      "loss": 0.6701,
      "step": 390700
    },
    {
      "epoch": 4.136628537854447,
      "grad_norm": 1.0203298330307007,
      "learning_rate": 0.00036467560563566755,
      "loss": 0.6761,
      "step": 390750
    },
    {
      "epoch": 4.13715785963445,
      "grad_norm": 1.009800910949707,
      "learning_rate": 0.00036463455767953994,
      "loss": 0.6697,
      "step": 390800
    },
    {
      "epoch": 4.137687181414454,
      "grad_norm": 0.912895679473877,
      "learning_rate": 0.0003645935058098307,
      "loss": 0.6681,
      "step": 390850
    },
    {
      "epoch": 4.138216503194457,
      "grad_norm": 0.991676390171051,
      "learning_rate": 0.0003645524500279412,
      "loss": 0.6706,
      "step": 390900
    },
    {
      "epoch": 4.13874582497446,
      "grad_norm": 0.9237522482872009,
      "learning_rate": 0.00036451139033527304,
      "loss": 0.6819,
      "step": 390950
    },
    {
      "epoch": 4.139275146754463,
      "grad_norm": Infinity,
      "learning_rate": 0.0003644711480435717,
      "loss": 0.6757,
      "step": 391000
    },
    {
      "epoch": 4.139275146754463,
      "eval_loss": 0.46480387449264526,
      "eval_runtime": 46.8192,
      "eval_samples_per_second": 3586.775,
      "eval_steps_per_second": 448.363,
      "step": 391000
    },
    {
      "epoch": 4.139804468534467,
      "grad_norm": 0.9963838458061218,
      "learning_rate": 0.00036443008061169744,
      "loss": 0.6758,
      "step": 391050
    },
    {
      "epoch": 4.14033379031447,
      "grad_norm": 1.1366710662841797,
      "learning_rate": 0.00036438900927322223,
      "loss": 0.6824,
      "step": 391100
    },
    {
      "epoch": 4.140863112094474,
      "grad_norm": 1.0709460973739624,
      "learning_rate": 0.0003643479340295482,
      "loss": 0.6803,
      "step": 391150
    },
    {
      "epoch": 4.1413924338744765,
      "grad_norm": 0.9277530312538147,
      "learning_rate": 0.0003643068548820776,
      "loss": 0.6721,
      "step": 391200
    },
    {
      "epoch": 4.14192175565448,
      "grad_norm": 1.0032964944839478,
      "learning_rate": 0.0003642657718322129,
      "loss": 0.6613,
      "step": 391250
    },
    {
      "epoch": 4.142451077434483,
      "grad_norm": 1.0294870138168335,
      "learning_rate": 0.0003642246848813566,
      "loss": 0.6578,
      "step": 391300
    },
    {
      "epoch": 4.142980399214487,
      "grad_norm": 1.0197635889053345,
      "learning_rate": 0.00036418359403091156,
      "loss": 0.6764,
      "step": 391350
    },
    {
      "epoch": 4.14350972099449,
      "grad_norm": 1.0565987825393677,
      "learning_rate": 0.00036414249928228037,
      "loss": 0.6655,
      "step": 391400
    },
    {
      "epoch": 4.144039042774493,
      "grad_norm": 1.0387496948242188,
      "learning_rate": 0.00036410140063686627,
      "loss": 0.678,
      "step": 391450
    },
    {
      "epoch": 4.144568364554496,
      "grad_norm": 1.001208782196045,
      "learning_rate": 0.0003640602980960721,
      "loss": 0.6804,
      "step": 391500
    },
    {
      "epoch": 4.144568364554496,
      "eval_loss": 0.46426454186439514,
      "eval_runtime": 46.8615,
      "eval_samples_per_second": 3583.538,
      "eval_steps_per_second": 447.958,
      "step": 391500
    },
    {
      "epoch": 4.145097686334499,
      "grad_norm": 1.0915062427520752,
      "learning_rate": 0.00036401919166130113,
      "loss": 0.6763,
      "step": 391550
    },
    {
      "epoch": 4.145627008114503,
      "grad_norm": 1.0186752080917358,
      "learning_rate": 0.00036397808133395687,
      "loss": 0.6653,
      "step": 391600
    },
    {
      "epoch": 4.146156329894506,
      "grad_norm": 0.9614906907081604,
      "learning_rate": 0.0003639369671154427,
      "loss": 0.6692,
      "step": 391650
    },
    {
      "epoch": 4.14668565167451,
      "grad_norm": 0.9481300711631775,
      "learning_rate": 0.00036389584900716225,
      "loss": 0.6736,
      "step": 391700
    },
    {
      "epoch": 4.1472149734545125,
      "grad_norm": 1.0298662185668945,
      "learning_rate": 0.0003638547270105193,
      "loss": 0.666,
      "step": 391750
    },
    {
      "epoch": 4.147744295234516,
      "grad_norm": 1.0341962575912476,
      "learning_rate": 0.0003638136011269177,
      "loss": 0.6792,
      "step": 391800
    },
    {
      "epoch": 4.148273617014519,
      "grad_norm": 1.0430562496185303,
      "learning_rate": 0.00036377247135776147,
      "loss": 0.6801,
      "step": 391850
    },
    {
      "epoch": 4.148802938794523,
      "grad_norm": 1.0872797966003418,
      "learning_rate": 0.0003637313377044549,
      "loss": 0.664,
      "step": 391900
    },
    {
      "epoch": 4.149332260574526,
      "grad_norm": 1.0380932092666626,
      "learning_rate": 0.00036369020016840205,
      "loss": 0.6751,
      "step": 391950
    },
    {
      "epoch": 4.1498615823545295,
      "grad_norm": 1.0300084352493286,
      "learning_rate": 0.0003636490587510075,
      "loss": 0.6792,
      "step": 392000
    },
    {
      "epoch": 4.1498615823545295,
      "eval_loss": 0.46569836139678955,
      "eval_runtime": 46.8369,
      "eval_samples_per_second": 3585.423,
      "eval_steps_per_second": 448.194,
      "step": 392000
    },
    {
      "epoch": 4.150390904134532,
      "grad_norm": 1.0179874897003174,
      "learning_rate": 0.00036360791345367577,
      "loss": 0.6756,
      "step": 392050
    },
    {
      "epoch": 4.150920225914536,
      "grad_norm": 0.8934378027915955,
      "learning_rate": 0.00036356676427781157,
      "loss": 0.6753,
      "step": 392100
    },
    {
      "epoch": 4.151449547694539,
      "grad_norm": 0.9733761548995972,
      "learning_rate": 0.00036352561122481963,
      "loss": 0.6674,
      "step": 392150
    },
    {
      "epoch": 4.151978869474542,
      "grad_norm": 0.9637250304222107,
      "learning_rate": 0.000363484454296105,
      "loss": 0.6751,
      "step": 392200
    },
    {
      "epoch": 4.152508191254546,
      "grad_norm": 0.9354144930839539,
      "learning_rate": 0.00036344329349307264,
      "loss": 0.6672,
      "step": 392250
    },
    {
      "epoch": 4.1530375130345485,
      "grad_norm": 0.9637334942817688,
      "learning_rate": 0.00036340212881712795,
      "loss": 0.6644,
      "step": 392300
    },
    {
      "epoch": 4.153566834814552,
      "grad_norm": 1.1057486534118652,
      "learning_rate": 0.00036336096026967613,
      "loss": 0.6844,
      "step": 392350
    },
    {
      "epoch": 4.154096156594555,
      "grad_norm": 0.9719513654708862,
      "learning_rate": 0.0003633197878521227,
      "loss": 0.6857,
      "step": 392400
    },
    {
      "epoch": 4.154625478374559,
      "grad_norm": 1.0220576524734497,
      "learning_rate": 0.0003632786115658733,
      "loss": 0.6818,
      "step": 392450
    },
    {
      "epoch": 4.155154800154562,
      "grad_norm": 1.105563998222351,
      "learning_rate": 0.00036323743141233357,
      "loss": 0.6655,
      "step": 392500
    },
    {
      "epoch": 4.155154800154562,
      "eval_loss": 0.4635023772716522,
      "eval_runtime": 46.8036,
      "eval_samples_per_second": 3587.974,
      "eval_steps_per_second": 448.513,
      "step": 392500
    },
    {
      "epoch": 4.1556841219345655,
      "grad_norm": 1.0074518918991089,
      "learning_rate": 0.0003631962473929095,
      "loss": 0.6627,
      "step": 392550
    },
    {
      "epoch": 4.156213443714568,
      "grad_norm": 1.0102890729904175,
      "learning_rate": 0.0003631550595090071,
      "loss": 0.6755,
      "step": 392600
    },
    {
      "epoch": 4.156742765494572,
      "grad_norm": 1.0341039896011353,
      "learning_rate": 0.0003631138677620324,
      "loss": 0.6768,
      "step": 392650
    },
    {
      "epoch": 4.157272087274575,
      "grad_norm": 1.0350035429000854,
      "learning_rate": 0.0003630726721533918,
      "loss": 0.6727,
      "step": 392700
    },
    {
      "epoch": 4.157801409054579,
      "grad_norm": 0.9906485080718994,
      "learning_rate": 0.0003630314726844916,
      "loss": 0.6731,
      "step": 392750
    },
    {
      "epoch": 4.158330730834582,
      "grad_norm": 0.9195758700370789,
      "learning_rate": 0.0003629902693567384,
      "loss": 0.6749,
      "step": 392800
    },
    {
      "epoch": 4.158860052614585,
      "grad_norm": 1.055625557899475,
      "learning_rate": 0.0003629490621715388,
      "loss": 0.6816,
      "step": 392850
    },
    {
      "epoch": 4.159389374394588,
      "grad_norm": 0.944833517074585,
      "learning_rate": 0.0003629078511302997,
      "loss": 0.6667,
      "step": 392900
    },
    {
      "epoch": 4.159918696174591,
      "grad_norm": 1.0107090473175049,
      "learning_rate": 0.0003628666362344279,
      "loss": 0.676,
      "step": 392950
    },
    {
      "epoch": 4.160448017954595,
      "grad_norm": 0.9448249936103821,
      "learning_rate": 0.0003628254174853306,
      "loss": 0.6587,
      "step": 393000
    },
    {
      "epoch": 4.160448017954595,
      "eval_loss": 0.4672086536884308,
      "eval_runtime": 46.8201,
      "eval_samples_per_second": 3586.711,
      "eval_steps_per_second": 448.355,
      "step": 393000
    },
    {
      "epoch": 4.160977339734598,
      "grad_norm": 1.101665735244751,
      "learning_rate": 0.00036278501937417193,
      "loss": 0.6839,
      "step": 393050
    },
    {
      "epoch": 4.1615066615146015,
      "grad_norm": 1.02074134349823,
      "learning_rate": 0.0003627437929998396,
      "loss": 0.6835,
      "step": 393100
    },
    {
      "epoch": 4.162035983294604,
      "grad_norm": 0.90351402759552,
      "learning_rate": 0.0003627025627764755,
      "loss": 0.6689,
      "step": 393150
    },
    {
      "epoch": 4.162565305074608,
      "grad_norm": 0.9332744479179382,
      "learning_rate": 0.00036266132870548727,
      "loss": 0.6806,
      "step": 393200
    },
    {
      "epoch": 4.163094626854611,
      "grad_norm": 0.9500319361686707,
      "learning_rate": 0.0003626200907882826,
      "loss": 0.6653,
      "step": 393250
    },
    {
      "epoch": 4.163623948634615,
      "grad_norm": 0.9084123373031616,
      "learning_rate": 0.00036257884902626933,
      "loss": 0.6681,
      "step": 393300
    },
    {
      "epoch": 4.164153270414618,
      "grad_norm": 1.0625176429748535,
      "learning_rate": 0.0003625376034208554,
      "loss": 0.6693,
      "step": 393350
    },
    {
      "epoch": 4.164682592194621,
      "grad_norm": 1.0562230348587036,
      "learning_rate": 0.00036249635397344904,
      "loss": 0.6782,
      "step": 393400
    },
    {
      "epoch": 4.165211913974624,
      "grad_norm": 1.1568069458007812,
      "learning_rate": 0.00036245510068545826,
      "loss": 0.6698,
      "step": 393450
    },
    {
      "epoch": 4.165741235754628,
      "grad_norm": 0.9687994122505188,
      "learning_rate": 0.00036241384355829176,
      "loss": 0.6664,
      "step": 393500
    },
    {
      "epoch": 4.165741235754628,
      "eval_loss": 0.46677911281585693,
      "eval_runtime": 46.8092,
      "eval_samples_per_second": 3587.542,
      "eval_steps_per_second": 448.459,
      "step": 393500
    },
    {
      "epoch": 4.166270557534631,
      "grad_norm": 0.9925147891044617,
      "learning_rate": 0.0003623725825933578,
      "loss": 0.6683,
      "step": 393550
    },
    {
      "epoch": 4.166799879314635,
      "grad_norm": 0.8882905840873718,
      "learning_rate": 0.0003623313177920651,
      "loss": 0.6766,
      "step": 393600
    },
    {
      "epoch": 4.1673292010946374,
      "grad_norm": 0.9644361138343811,
      "learning_rate": 0.00036229004915582235,
      "loss": 0.6727,
      "step": 393650
    },
    {
      "epoch": 4.16785852287464,
      "grad_norm": 0.9642286896705627,
      "learning_rate": 0.0003622487766860386,
      "loss": 0.6627,
      "step": 393700
    },
    {
      "epoch": 4.168387844654644,
      "grad_norm": 1.0449485778808594,
      "learning_rate": 0.00036220750038412267,
      "loss": 0.6708,
      "step": 393750
    },
    {
      "epoch": 4.168917166434647,
      "grad_norm": 1.0731990337371826,
      "learning_rate": 0.00036216622025148386,
      "loss": 0.6687,
      "step": 393800
    },
    {
      "epoch": 4.169446488214651,
      "grad_norm": 0.9464303851127625,
      "learning_rate": 0.0003621249362895315,
      "loss": 0.685,
      "step": 393850
    },
    {
      "epoch": 4.169975809994654,
      "grad_norm": 1.0173486471176147,
      "learning_rate": 0.00036208364849967483,
      "loss": 0.6764,
      "step": 393900
    },
    {
      "epoch": 4.170505131774657,
      "grad_norm": 1.0853418111801147,
      "learning_rate": 0.0003620423568833236,
      "loss": 0.6812,
      "step": 393950
    },
    {
      "epoch": 4.17103445355466,
      "grad_norm": 0.905379593372345,
      "learning_rate": 0.0003620010614418873,
      "loss": 0.6727,
      "step": 394000
    },
    {
      "epoch": 4.17103445355466,
      "eval_loss": 0.4641883969306946,
      "eval_runtime": 46.837,
      "eval_samples_per_second": 3585.41,
      "eval_steps_per_second": 448.192,
      "step": 394000
    },
    {
      "epoch": 4.171563775334664,
      "grad_norm": 0.982526421546936,
      "learning_rate": 0.000361959762176776,
      "loss": 0.6744,
      "step": 394050
    },
    {
      "epoch": 4.172093097114667,
      "grad_norm": 0.9107065796852112,
      "learning_rate": 0.0003619184590893993,
      "loss": 0.6701,
      "step": 394100
    },
    {
      "epoch": 4.172622418894671,
      "grad_norm": 0.9937993884086609,
      "learning_rate": 0.00036187715218116755,
      "loss": 0.6705,
      "step": 394150
    },
    {
      "epoch": 4.173151740674673,
      "grad_norm": 0.9608747363090515,
      "learning_rate": 0.0003618358414534908,
      "loss": 0.6694,
      "step": 394200
    },
    {
      "epoch": 4.173681062454677,
      "grad_norm": 1.0670281648635864,
      "learning_rate": 0.0003617945269077795,
      "loss": 0.668,
      "step": 394250
    },
    {
      "epoch": 4.17421038423468,
      "grad_norm": 1.0638225078582764,
      "learning_rate": 0.0003617532085454439,
      "loss": 0.6743,
      "step": 394300
    },
    {
      "epoch": 4.174739706014684,
      "grad_norm": 1.028684139251709,
      "learning_rate": 0.0003617118863678949,
      "loss": 0.6672,
      "step": 394350
    },
    {
      "epoch": 4.175269027794687,
      "grad_norm": 0.9980208277702332,
      "learning_rate": 0.00036167056037654305,
      "loss": 0.6698,
      "step": 394400
    },
    {
      "epoch": 4.1757983495746895,
      "grad_norm": 1.0394161939620972,
      "learning_rate": 0.00036162923057279917,
      "loss": 0.6806,
      "step": 394450
    },
    {
      "epoch": 4.176327671354693,
      "grad_norm": 0.9498326778411865,
      "learning_rate": 0.00036158789695807435,
      "loss": 0.6609,
      "step": 394500
    },
    {
      "epoch": 4.176327671354693,
      "eval_loss": 0.4649644196033478,
      "eval_runtime": 46.8447,
      "eval_samples_per_second": 3584.821,
      "eval_steps_per_second": 448.119,
      "step": 394500
    },
    {
      "epoch": 4.176856993134696,
      "grad_norm": 0.9814031720161438,
      "learning_rate": 0.00036154655953377963,
      "loss": 0.6701,
      "step": 394550
    },
    {
      "epoch": 4.1773863149147,
      "grad_norm": 1.0443429946899414,
      "learning_rate": 0.00036150521830132626,
      "loss": 0.6657,
      "step": 394600
    },
    {
      "epoch": 4.177915636694703,
      "grad_norm": 1.0634970664978027,
      "learning_rate": 0.00036146387326212566,
      "loss": 0.6801,
      "step": 394650
    },
    {
      "epoch": 4.1784449584747065,
      "grad_norm": 1.013358235359192,
      "learning_rate": 0.0003614225244175893,
      "loss": 0.6719,
      "step": 394700
    },
    {
      "epoch": 4.178974280254709,
      "grad_norm": 0.9846556782722473,
      "learning_rate": 0.00036138117176912884,
      "loss": 0.6749,
      "step": 394750
    },
    {
      "epoch": 4.179503602034713,
      "grad_norm": 1.084386944770813,
      "learning_rate": 0.00036133981531815594,
      "loss": 0.67,
      "step": 394800
    },
    {
      "epoch": 4.180032923814716,
      "grad_norm": 1.0978093147277832,
      "learning_rate": 0.00036129845506608266,
      "loss": 0.6597,
      "step": 394850
    },
    {
      "epoch": 4.18056224559472,
      "grad_norm": 0.9240736961364746,
      "learning_rate": 0.0003612570910143209,
      "loss": 0.6746,
      "step": 394900
    },
    {
      "epoch": 4.181091567374723,
      "grad_norm": 1.0061970949172974,
      "learning_rate": 0.00036121572316428287,
      "loss": 0.6671,
      "step": 394950
    },
    {
      "epoch": 4.181620889154726,
      "grad_norm": 1.0558395385742188,
      "learning_rate": 0.00036117435151738087,
      "loss": 0.6758,
      "step": 395000
    },
    {
      "epoch": 4.181620889154726,
      "eval_loss": 0.46228212118148804,
      "eval_runtime": 46.8736,
      "eval_samples_per_second": 3582.616,
      "eval_steps_per_second": 447.843,
      "step": 395000
    },
    {
      "epoch": 4.182150210934729,
      "grad_norm": 1.0041306018829346,
      "learning_rate": 0.00036113297607502724,
      "loss": 0.6636,
      "step": 395050
    },
    {
      "epoch": 4.182679532714733,
      "grad_norm": 0.9941140413284302,
      "learning_rate": 0.00036109242446053484,
      "loss": 0.6634,
      "step": 395100
    },
    {
      "epoch": 4.183208854494736,
      "grad_norm": 0.9779277443885803,
      "learning_rate": 0.0003610510415073545,
      "loss": 0.6795,
      "step": 395150
    },
    {
      "epoch": 4.183738176274739,
      "grad_norm": 1.083327293395996,
      "learning_rate": 0.00036100965476293227,
      "loss": 0.6805,
      "step": 395200
    },
    {
      "epoch": 4.1842674980547425,
      "grad_norm": 1.0264695882797241,
      "learning_rate": 0.00036096826422868123,
      "loss": 0.6713,
      "step": 395250
    },
    {
      "epoch": 4.184796819834745,
      "grad_norm": 1.0986582040786743,
      "learning_rate": 0.0003609268699060143,
      "loss": 0.6795,
      "step": 395300
    },
    {
      "epoch": 4.185326141614749,
      "grad_norm": 0.9454173445701599,
      "learning_rate": 0.0003608854717963447,
      "loss": 0.6822,
      "step": 395350
    },
    {
      "epoch": 4.185855463394752,
      "grad_norm": 1.0524054765701294,
      "learning_rate": 0.00036084406990108576,
      "loss": 0.669,
      "step": 395400
    },
    {
      "epoch": 4.186384785174756,
      "grad_norm": 0.9682757258415222,
      "learning_rate": 0.0003608026642216509,
      "loss": 0.6485,
      "step": 395450
    },
    {
      "epoch": 4.186914106954759,
      "grad_norm": 1.1190165281295776,
      "learning_rate": 0.00036076125475945374,
      "loss": 0.6612,
      "step": 395500
    },
    {
      "epoch": 4.186914106954759,
      "eval_loss": 0.4617636799812317,
      "eval_runtime": 46.7876,
      "eval_samples_per_second": 3589.201,
      "eval_steps_per_second": 448.666,
      "step": 395500
    },
    {
      "epoch": 4.187443428734762,
      "grad_norm": 1.0682648420333862,
      "learning_rate": 0.00036071984151590797,
      "loss": 0.6823,
      "step": 395550
    },
    {
      "epoch": 4.187972750514765,
      "grad_norm": 1.0281416177749634,
      "learning_rate": 0.0003606784244924274,
      "loss": 0.6802,
      "step": 395600
    },
    {
      "epoch": 4.188502072294769,
      "grad_norm": 1.008266806602478,
      "learning_rate": 0.0003606370036904261,
      "loss": 0.6784,
      "step": 395650
    },
    {
      "epoch": 4.189031394074772,
      "grad_norm": 1.0045214891433716,
      "learning_rate": 0.0003605955791113179,
      "loss": 0.6688,
      "step": 395700
    },
    {
      "epoch": 4.189560715854776,
      "grad_norm": 1.0090357065200806,
      "learning_rate": 0.0003605541507565173,
      "loss": 0.6695,
      "step": 395750
    },
    {
      "epoch": 4.1900900376347785,
      "grad_norm": 1.044956088066101,
      "learning_rate": 0.00036051271862743854,
      "loss": 0.6831,
      "step": 395800
    },
    {
      "epoch": 4.190619359414782,
      "grad_norm": 0.8978885412216187,
      "learning_rate": 0.00036047128272549613,
      "loss": 0.6741,
      "step": 395850
    },
    {
      "epoch": 4.191148681194785,
      "grad_norm": 1.0042027235031128,
      "learning_rate": 0.0003604298430521046,
      "loss": 0.6728,
      "step": 395900
    },
    {
      "epoch": 4.191678002974788,
      "grad_norm": 1.0173016786575317,
      "learning_rate": 0.0003603883996086786,
      "loss": 0.672,
      "step": 395950
    },
    {
      "epoch": 4.192207324754792,
      "grad_norm": 0.9417467713356018,
      "learning_rate": 0.0003603469523966333,
      "loss": 0.6689,
      "step": 396000
    },
    {
      "epoch": 4.192207324754792,
      "eval_loss": 0.46402838826179504,
      "eval_runtime": 46.7266,
      "eval_samples_per_second": 3593.883,
      "eval_steps_per_second": 449.251,
      "step": 396000
    },
    {
      "epoch": 4.192736646534795,
      "grad_norm": 0.9226959943771362,
      "learning_rate": 0.0003603055014173834,
      "loss": 0.6666,
      "step": 396050
    },
    {
      "epoch": 4.193265968314798,
      "grad_norm": 1.0087007284164429,
      "learning_rate": 0.00036026404667234427,
      "loss": 0.6783,
      "step": 396100
    },
    {
      "epoch": 4.193795290094801,
      "grad_norm": 0.9037997722625732,
      "learning_rate": 0.0003602225881629309,
      "loss": 0.6719,
      "step": 396150
    },
    {
      "epoch": 4.194324611874805,
      "grad_norm": 0.9908074140548706,
      "learning_rate": 0.00036018112589055883,
      "loss": 0.6719,
      "step": 396200
    },
    {
      "epoch": 4.194853933654808,
      "grad_norm": 1.0462183952331543,
      "learning_rate": 0.00036013965985664354,
      "loss": 0.6696,
      "step": 396250
    },
    {
      "epoch": 4.195383255434812,
      "grad_norm": 1.1250884532928467,
      "learning_rate": 0.0003600981900626007,
      "loss": 0.6682,
      "step": 396300
    },
    {
      "epoch": 4.1959125772148145,
      "grad_norm": 1.0554155111312866,
      "learning_rate": 0.0003600567165098459,
      "loss": 0.68,
      "step": 396350
    },
    {
      "epoch": 4.196441898994818,
      "grad_norm": 1.091417908668518,
      "learning_rate": 0.0003600152391997952,
      "loss": 0.6636,
      "step": 396400
    },
    {
      "epoch": 4.196971220774821,
      "grad_norm": 0.9565324187278748,
      "learning_rate": 0.0003599737581338647,
      "loss": 0.6772,
      "step": 396450
    },
    {
      "epoch": 4.197500542554825,
      "grad_norm": 1.0283688306808472,
      "learning_rate": 0.00035993227331347036,
      "loss": 0.6723,
      "step": 396500
    },
    {
      "epoch": 4.197500542554825,
      "eval_loss": 0.46304476261138916,
      "eval_runtime": 46.7656,
      "eval_samples_per_second": 3590.884,
      "eval_steps_per_second": 448.877,
      "step": 396500
    },
    {
      "epoch": 4.198029864334828,
      "grad_norm": 0.9965922236442566,
      "learning_rate": 0.00035989078474002846,
      "loss": 0.6618,
      "step": 396550
    },
    {
      "epoch": 4.1985591861148315,
      "grad_norm": 0.9532056450843811,
      "learning_rate": 0.00035984929241495556,
      "loss": 0.6836,
      "step": 396600
    },
    {
      "epoch": 4.199088507894834,
      "grad_norm": 1.0189541578292847,
      "learning_rate": 0.00035980779633966806,
      "loss": 0.662,
      "step": 396650
    },
    {
      "epoch": 4.199617829674837,
      "grad_norm": 1.031051754951477,
      "learning_rate": 0.0003597662965155827,
      "loss": 0.6793,
      "step": 396700
    },
    {
      "epoch": 4.200147151454841,
      "grad_norm": 0.9669512510299683,
      "learning_rate": 0.00035972479294411614,
      "loss": 0.6687,
      "step": 396750
    },
    {
      "epoch": 4.200676473234844,
      "grad_norm": 0.9375647306442261,
      "learning_rate": 0.00035968328562668546,
      "loss": 0.6687,
      "step": 396800
    },
    {
      "epoch": 4.201205795014848,
      "grad_norm": 1.1266148090362549,
      "learning_rate": 0.00035964177456470763,
      "loss": 0.6752,
      "step": 396850
    },
    {
      "epoch": 4.2017351167948505,
      "grad_norm": 0.8939652442932129,
      "learning_rate": 0.0003596002597595998,
      "loss": 0.6654,
      "step": 396900
    },
    {
      "epoch": 4.202264438574854,
      "grad_norm": 0.9170989990234375,
      "learning_rate": 0.00035955874121277936,
      "loss": 0.6642,
      "step": 396950
    },
    {
      "epoch": 4.202793760354857,
      "grad_norm": 0.8909177184104919,
      "learning_rate": 0.00035951721892566363,
      "loss": 0.6584,
      "step": 397000
    },
    {
      "epoch": 4.202793760354857,
      "eval_loss": 0.4629654884338379,
      "eval_runtime": 46.6982,
      "eval_samples_per_second": 3596.07,
      "eval_steps_per_second": 449.525,
      "step": 397000
    },
    {
      "epoch": 4.203323082134861,
      "grad_norm": 0.9638190865516663,
      "learning_rate": 0.0003594756928996702,
      "loss": 0.6744,
      "step": 397050
    },
    {
      "epoch": 4.203852403914864,
      "grad_norm": 0.9495277404785156,
      "learning_rate": 0.0003594341631362168,
      "loss": 0.6612,
      "step": 397100
    },
    {
      "epoch": 4.2043817256948675,
      "grad_norm": 1.0310733318328857,
      "learning_rate": 0.0003593934603433151,
      "loss": 0.6664,
      "step": 397150
    },
    {
      "epoch": 4.20491104747487,
      "grad_norm": 0.9078355431556702,
      "learning_rate": 0.0003593519231838738,
      "loss": 0.6749,
      "step": 397200
    },
    {
      "epoch": 4.205440369254874,
      "grad_norm": 1.0737767219543457,
      "learning_rate": 0.00035931038229119794,
      "loss": 0.6709,
      "step": 397250
    },
    {
      "epoch": 4.205969691034877,
      "grad_norm": 0.952426016330719,
      "learning_rate": 0.00035926883766670574,
      "loss": 0.6808,
      "step": 397300
    },
    {
      "epoch": 4.206499012814881,
      "grad_norm": 1.022444486618042,
      "learning_rate": 0.0003592272893118155,
      "loss": 0.6695,
      "step": 397350
    },
    {
      "epoch": 4.207028334594884,
      "grad_norm": 0.9006367921829224,
      "learning_rate": 0.00035918573722794567,
      "loss": 0.6747,
      "step": 397400
    },
    {
      "epoch": 4.207557656374886,
      "grad_norm": 0.9763554334640503,
      "learning_rate": 0.0003591441814165148,
      "loss": 0.6572,
      "step": 397450
    },
    {
      "epoch": 4.20808697815489,
      "grad_norm": 0.9803701639175415,
      "learning_rate": 0.0003591026218789416,
      "loss": 0.6753,
      "step": 397500
    },
    {
      "epoch": 4.20808697815489,
      "eval_loss": 0.4631722569465637,
      "eval_runtime": 46.8685,
      "eval_samples_per_second": 3583.002,
      "eval_steps_per_second": 447.891,
      "step": 397500
    },
    {
      "epoch": 4.208616299934893,
      "grad_norm": 0.9624776244163513,
      "learning_rate": 0.0003590610586166449,
      "loss": 0.6582,
      "step": 397550
    },
    {
      "epoch": 4.209145621714897,
      "grad_norm": 0.917948842048645,
      "learning_rate": 0.00035901949163104363,
      "loss": 0.6627,
      "step": 397600
    },
    {
      "epoch": 4.2096749434949,
      "grad_norm": 0.9649383425712585,
      "learning_rate": 0.000358977920923557,
      "loss": 0.6732,
      "step": 397650
    },
    {
      "epoch": 4.210204265274903,
      "grad_norm": 1.0261324644088745,
      "learning_rate": 0.000358936346495604,
      "loss": 0.6722,
      "step": 397700
    },
    {
      "epoch": 4.210733587054906,
      "grad_norm": 0.99039626121521,
      "learning_rate": 0.00035889476834860415,
      "loss": 0.674,
      "step": 397750
    },
    {
      "epoch": 4.21126290883491,
      "grad_norm": 0.9742910861968994,
      "learning_rate": 0.00035885318648397677,
      "loss": 0.6645,
      "step": 397800
    },
    {
      "epoch": 4.211792230614913,
      "grad_norm": 1.0156463384628296,
      "learning_rate": 0.00035881160090314154,
      "loss": 0.6637,
      "step": 397850
    },
    {
      "epoch": 4.212321552394917,
      "grad_norm": 1.0010031461715698,
      "learning_rate": 0.00035877001160751823,
      "loss": 0.6764,
      "step": 397900
    },
    {
      "epoch": 4.2128508741749195,
      "grad_norm": 1.0918151140213013,
      "learning_rate": 0.00035872841859852655,
      "loss": 0.6692,
      "step": 397950
    },
    {
      "epoch": 4.213380195954923,
      "grad_norm": 1.010253667831421,
      "learning_rate": 0.00035868682187758654,
      "loss": 0.6644,
      "step": 398000
    },
    {
      "epoch": 4.213380195954923,
      "eval_loss": 0.4619455337524414,
      "eval_runtime": 46.7862,
      "eval_samples_per_second": 3589.306,
      "eval_steps_per_second": 448.679,
      "step": 398000
    },
    {
      "epoch": 4.213951863477327,
      "grad_norm": 1.0660388469696045,
      "learning_rate": 0.0003586452214461183,
      "loss": 0.6751,
      "step": 398050
    },
    {
      "epoch": 4.21448118525733,
      "grad_norm": 0.9923812747001648,
      "learning_rate": 0.00035860361730554206,
      "loss": 0.6779,
      "step": 398100
    },
    {
      "epoch": 4.215010507037333,
      "grad_norm": 1.0442615747451782,
      "learning_rate": 0.0003585620094572782,
      "loss": 0.674,
      "step": 398150
    },
    {
      "epoch": 4.215539828817336,
      "grad_norm": 0.9716196656227112,
      "learning_rate": 0.000358520397902747,
      "loss": 0.6777,
      "step": 398200
    },
    {
      "epoch": 4.21606915059734,
      "grad_norm": 1.0351051092147827,
      "learning_rate": 0.0003584787826433694,
      "loss": 0.6651,
      "step": 398250
    },
    {
      "epoch": 4.216598472377343,
      "grad_norm": 0.9580503106117249,
      "learning_rate": 0.0003584371636805658,
      "loss": 0.6632,
      "step": 398300
    },
    {
      "epoch": 4.217127794157347,
      "grad_norm": 0.9768180847167969,
      "learning_rate": 0.0003583955410157573,
      "loss": 0.6647,
      "step": 398350
    },
    {
      "epoch": 4.2176571159373495,
      "grad_norm": 1.0573511123657227,
      "learning_rate": 0.0003583539146503648,
      "loss": 0.6798,
      "step": 398400
    },
    {
      "epoch": 4.218186437717352,
      "grad_norm": 0.9894901514053345,
      "learning_rate": 0.0003583122845858093,
      "loss": 0.6767,
      "step": 398450
    },
    {
      "epoch": 4.218715759497356,
      "grad_norm": 1.0302553176879883,
      "learning_rate": 0.00035827065082351216,
      "loss": 0.6647,
      "step": 398500
    },
    {
      "epoch": 4.218715759497356,
      "eval_loss": 0.46244966983795166,
      "eval_runtime": 46.9881,
      "eval_samples_per_second": 3573.886,
      "eval_steps_per_second": 446.752,
      "step": 398500
    },
    {
      "epoch": 4.219245081277359,
      "grad_norm": 0.9790531992912292,
      "learning_rate": 0.0003582290133648947,
      "loss": 0.6678,
      "step": 398550
    },
    {
      "epoch": 4.219774403057363,
      "grad_norm": 1.0076137781143188,
      "learning_rate": 0.00035818737221137835,
      "loss": 0.6704,
      "step": 398600
    },
    {
      "epoch": 4.220303724837366,
      "grad_norm": 0.9497551321983337,
      "learning_rate": 0.0003581457273643849,
      "loss": 0.675,
      "step": 398650
    },
    {
      "epoch": 4.220833046617369,
      "grad_norm": 0.9459179043769836,
      "learning_rate": 0.0003581040788253359,
      "loss": 0.6727,
      "step": 398700
    },
    {
      "epoch": 4.221362368397372,
      "grad_norm": 1.0034785270690918,
      "learning_rate": 0.00035806242659565336,
      "loss": 0.668,
      "step": 398750
    },
    {
      "epoch": 4.221891690177376,
      "grad_norm": 0.9759668707847595,
      "learning_rate": 0.0003580207706767592,
      "loss": 0.6637,
      "step": 398800
    },
    {
      "epoch": 4.222421011957379,
      "grad_norm": 0.9491812586784363,
      "learning_rate": 0.0003579791110700755,
      "loss": 0.6638,
      "step": 398850
    },
    {
      "epoch": 4.222950333737383,
      "grad_norm": 0.9144350290298462,
      "learning_rate": 0.0003579374477770246,
      "loss": 0.6843,
      "step": 398900
    },
    {
      "epoch": 4.2234796555173855,
      "grad_norm": 1.0565837621688843,
      "learning_rate": 0.0003578957807990288,
      "loss": 0.6785,
      "step": 398950
    },
    {
      "epoch": 4.224008977297389,
      "grad_norm": 0.9860767126083374,
      "learning_rate": 0.0003578541101375106,
      "loss": 0.6809,
      "step": 399000
    },
    {
      "epoch": 4.224008977297389,
      "eval_loss": 0.46318331360816956,
      "eval_runtime": 47.0328,
      "eval_samples_per_second": 3570.484,
      "eval_steps_per_second": 446.326,
      "step": 399000
    },
    {
      "epoch": 4.224538299077392,
      "grad_norm": 1.086565613746643,
      "learning_rate": 0.00035781243579389267,
      "loss": 0.6713,
      "step": 399050
    },
    {
      "epoch": 4.225067620857396,
      "grad_norm": 0.9475157856941223,
      "learning_rate": 0.00035777075776959765,
      "loss": 0.6764,
      "step": 399100
    },
    {
      "epoch": 4.225596942637399,
      "grad_norm": 0.9073686599731445,
      "learning_rate": 0.00035772990973616703,
      "loss": 0.6582,
      "step": 399150
    },
    {
      "epoch": 4.226126264417402,
      "grad_norm": 0.9309015870094299,
      "learning_rate": 0.00035768822442832943,
      "loss": 0.6639,
      "step": 399200
    },
    {
      "epoch": 4.226655586197405,
      "grad_norm": 1.1279860734939575,
      "learning_rate": 0.00035764653544405534,
      "loss": 0.6744,
      "step": 399250
    },
    {
      "epoch": 4.227184907977408,
      "grad_norm": 0.9508916735649109,
      "learning_rate": 0.000357604842784768,
      "loss": 0.673,
      "step": 399300
    },
    {
      "epoch": 4.227714229757412,
      "grad_norm": 1.177435278892517,
      "learning_rate": 0.0003575631464518908,
      "loss": 0.648,
      "step": 399350
    },
    {
      "epoch": 4.228243551537415,
      "grad_norm": 0.9532386660575867,
      "learning_rate": 0.00035752144644684723,
      "loss": 0.6723,
      "step": 399400
    },
    {
      "epoch": 4.228772873317419,
      "grad_norm": 0.9853010177612305,
      "learning_rate": 0.0003574797427710609,
      "loss": 0.6646,
      "step": 399450
    },
    {
      "epoch": 4.2293021950974214,
      "grad_norm": 1.008290410041809,
      "learning_rate": 0.00035743803542595564,
      "loss": 0.6711,
      "step": 399500
    },
    {
      "epoch": 4.2293021950974214,
      "eval_loss": 0.4635300934314728,
      "eval_runtime": 46.9646,
      "eval_samples_per_second": 3575.671,
      "eval_steps_per_second": 446.975,
      "step": 399500
    },
    {
      "epoch": 4.229831516877425,
      "grad_norm": 1.131169319152832,
      "learning_rate": 0.0003573963244129552,
      "loss": 0.6568,
      "step": 399550
    },
    {
      "epoch": 4.230360838657428,
      "grad_norm": 1.087583065032959,
      "learning_rate": 0.0003573546097334836,
      "loss": 0.6759,
      "step": 399600
    },
    {
      "epoch": 4.230890160437432,
      "grad_norm": 1.1043583154678345,
      "learning_rate": 0.00035731289138896507,
      "loss": 0.6701,
      "step": 399650
    },
    {
      "epoch": 4.231419482217435,
      "grad_norm": 0.9560680985450745,
      "learning_rate": 0.0003572711693808237,
      "loss": 0.6756,
      "step": 399700
    },
    {
      "epoch": 4.2319488039974384,
      "grad_norm": 0.945724368095398,
      "learning_rate": 0.00035722944371048397,
      "loss": 0.6569,
      "step": 399750
    },
    {
      "epoch": 4.232478125777441,
      "grad_norm": 1.0361416339874268,
      "learning_rate": 0.00035718771437937035,
      "loss": 0.6711,
      "step": 399800
    },
    {
      "epoch": 4.233007447557445,
      "grad_norm": 0.949454128742218,
      "learning_rate": 0.0003571459813889075,
      "loss": 0.6584,
      "step": 399850
    },
    {
      "epoch": 4.233536769337448,
      "grad_norm": 1.0032275915145874,
      "learning_rate": 0.00035710424474052013,
      "loss": 0.6765,
      "step": 399900
    },
    {
      "epoch": 4.234066091117451,
      "grad_norm": 0.9000475406646729,
      "learning_rate": 0.0003570625044356331,
      "loss": 0.6687,
      "step": 399950
    },
    {
      "epoch": 4.234595412897455,
      "grad_norm": 1.0744179487228394,
      "learning_rate": 0.00035702076047567147,
      "loss": 0.6605,
      "step": 400000
    },
    {
      "epoch": 4.234595412897455,
      "eval_loss": 0.4606032967567444,
      "eval_runtime": 46.8775,
      "eval_samples_per_second": 3582.318,
      "eval_steps_per_second": 447.806,
      "step": 400000
    },
    {
      "epoch": 4.235124734677457,
      "grad_norm": 1.001799464225769,
      "learning_rate": 0.0003569790128620603,
      "loss": 0.6805,
      "step": 400050
    },
    {
      "epoch": 4.235654056457461,
      "grad_norm": 0.8988260626792908,
      "learning_rate": 0.0003569380966573242,
      "loss": 0.6799,
      "step": 400100
    },
    {
      "epoch": 4.236183378237464,
      "grad_norm": 0.960295557975769,
      "learning_rate": 0.00035689634181369187,
      "loss": 0.684,
      "step": 400150
    },
    {
      "epoch": 4.236712700017468,
      "grad_norm": 0.9200921654701233,
      "learning_rate": 0.00035685458332065765,
      "loss": 0.6853,
      "step": 400200
    },
    {
      "epoch": 4.237242021797471,
      "grad_norm": 0.9105338454246521,
      "learning_rate": 0.00035681282117964715,
      "loss": 0.674,
      "step": 400250
    },
    {
      "epoch": 4.237771343577474,
      "grad_norm": 0.9958693385124207,
      "learning_rate": 0.0003567710553920861,
      "loss": 0.6746,
      "step": 400300
    },
    {
      "epoch": 4.238300665357477,
      "grad_norm": 0.970431387424469,
      "learning_rate": 0.0003567292859594004,
      "loss": 0.6645,
      "step": 400350
    },
    {
      "epoch": 4.238829987137481,
      "grad_norm": 1.022027850151062,
      "learning_rate": 0.00035668751288301596,
      "loss": 0.6616,
      "step": 400400
    },
    {
      "epoch": 4.239359308917484,
      "grad_norm": 1.0990149974822998,
      "learning_rate": 0.000356645736164359,
      "loss": 0.6551,
      "step": 400450
    },
    {
      "epoch": 4.239888630697488,
      "grad_norm": 1.042635202407837,
      "learning_rate": 0.0003566039558048557,
      "loss": 0.656,
      "step": 400500
    },
    {
      "epoch": 4.239888630697488,
      "eval_loss": 0.4592171907424927,
      "eval_runtime": 46.987,
      "eval_samples_per_second": 3573.965,
      "eval_steps_per_second": 446.762,
      "step": 400500
    },
    {
      "epoch": 4.2404179524774905,
      "grad_norm": 1.0403802394866943,
      "learning_rate": 0.0003565621718059325,
      "loss": 0.663,
      "step": 400550
    },
    {
      "epoch": 4.240947274257494,
      "grad_norm": 0.959056556224823,
      "learning_rate": 0.00035652038416901575,
      "loss": 0.6776,
      "step": 400600
    },
    {
      "epoch": 4.241476596037497,
      "grad_norm": 0.9487805962562561,
      "learning_rate": 0.0003564785928955322,
      "loss": 0.6744,
      "step": 400650
    },
    {
      "epoch": 4.2420059178175,
      "grad_norm": 1.1080185174942017,
      "learning_rate": 0.00035643679798690855,
      "loss": 0.6753,
      "step": 400700
    },
    {
      "epoch": 4.242535239597504,
      "grad_norm": 0.9482121467590332,
      "learning_rate": 0.00035639499944457165,
      "loss": 0.6618,
      "step": 400750
    },
    {
      "epoch": 4.243064561377507,
      "grad_norm": 1.043316125869751,
      "learning_rate": 0.0003563531972699485,
      "loss": 0.6696,
      "step": 400800
    },
    {
      "epoch": 4.24359388315751,
      "grad_norm": 0.9407874345779419,
      "learning_rate": 0.00035631139146446615,
      "loss": 0.6727,
      "step": 400850
    },
    {
      "epoch": 4.244123204937513,
      "grad_norm": 1.1160422563552856,
      "learning_rate": 0.0003562695820295519,
      "loss": 0.6753,
      "step": 400900
    },
    {
      "epoch": 4.244652526717517,
      "grad_norm": 1.0501948595046997,
      "learning_rate": 0.00035622776896663313,
      "loss": 0.67,
      "step": 400950
    },
    {
      "epoch": 4.24518184849752,
      "grad_norm": 0.9000099897384644,
      "learning_rate": 0.00035618595227713726,
      "loss": 0.682,
      "step": 401000
    },
    {
      "epoch": 4.24518184849752,
      "eval_loss": 0.4646487236022949,
      "eval_runtime": 47.0276,
      "eval_samples_per_second": 3570.879,
      "eval_steps_per_second": 446.376,
      "step": 401000
    },
    {
      "epoch": 4.245711170277524,
      "grad_norm": 1.0957363843917847,
      "learning_rate": 0.0003561441319624919,
      "loss": 0.6762,
      "step": 401050
    },
    {
      "epoch": 4.2462404920575265,
      "grad_norm": 1.096775770187378,
      "learning_rate": 0.0003561023080241248,
      "loss": 0.6754,
      "step": 401100
    },
    {
      "epoch": 4.24676981383753,
      "grad_norm": 1.0269546508789062,
      "learning_rate": 0.00035606048046346383,
      "loss": 0.6876,
      "step": 401150
    },
    {
      "epoch": 4.247299135617533,
      "grad_norm": 0.8830666542053223,
      "learning_rate": 0.000356018649281937,
      "loss": 0.6572,
      "step": 401200
    },
    {
      "epoch": 4.247828457397537,
      "grad_norm": 0.9750667214393616,
      "learning_rate": 0.0003559768144809723,
      "loss": 0.6635,
      "step": 401250
    },
    {
      "epoch": 4.24835777917754,
      "grad_norm": 1.0621291399002075,
      "learning_rate": 0.000355934976061998,
      "loss": 0.6602,
      "step": 401300
    },
    {
      "epoch": 4.2488871009575435,
      "grad_norm": 1.0881307125091553,
      "learning_rate": 0.00035589313402644253,
      "loss": 0.6645,
      "step": 401350
    },
    {
      "epoch": 4.249416422737546,
      "grad_norm": 1.0843498706817627,
      "learning_rate": 0.0003558512883757343,
      "loss": 0.6722,
      "step": 401400
    },
    {
      "epoch": 4.249945744517549,
      "grad_norm": 1.154317021369934,
      "learning_rate": 0.00035580943911130185,
      "loss": 0.6682,
      "step": 401450
    },
    {
      "epoch": 4.250475066297553,
      "grad_norm": 1.0206568241119385,
      "learning_rate": 0.000355767586234574,
      "loss": 0.6683,
      "step": 401500
    },
    {
      "epoch": 4.250475066297553,
      "eval_loss": 0.46035173535346985,
      "eval_runtime": 47.0021,
      "eval_samples_per_second": 3572.819,
      "eval_steps_per_second": 446.618,
      "step": 401500
    },
    {
      "epoch": 4.251004388077556,
      "grad_norm": 0.9908865690231323,
      "learning_rate": 0.0003557257297469796,
      "loss": 0.6668,
      "step": 401550
    },
    {
      "epoch": 4.25153370985756,
      "grad_norm": 0.9531059265136719,
      "learning_rate": 0.00035568386964994746,
      "loss": 0.67,
      "step": 401600
    },
    {
      "epoch": 4.2520630316375625,
      "grad_norm": 1.0210816860198975,
      "learning_rate": 0.0003556420059449068,
      "loss": 0.6771,
      "step": 401650
    },
    {
      "epoch": 4.252592353417566,
      "grad_norm": 0.9794699549674988,
      "learning_rate": 0.0003556001386332868,
      "loss": 0.6721,
      "step": 401700
    },
    {
      "epoch": 4.253121675197569,
      "grad_norm": 0.8715429306030273,
      "learning_rate": 0.0003555582677165168,
      "loss": 0.6627,
      "step": 401750
    },
    {
      "epoch": 4.253650996977573,
      "grad_norm": 0.9604726433753967,
      "learning_rate": 0.00035551639319602625,
      "loss": 0.6748,
      "step": 401800
    },
    {
      "epoch": 4.254180318757576,
      "grad_norm": 1.000806450843811,
      "learning_rate": 0.00035547451507324474,
      "loss": 0.6698,
      "step": 401850
    },
    {
      "epoch": 4.2547096405375795,
      "grad_norm": 1.0632461309432983,
      "learning_rate": 0.00035543263334960197,
      "loss": 0.6812,
      "step": 401900
    },
    {
      "epoch": 4.255238962317582,
      "grad_norm": 0.985535740852356,
      "learning_rate": 0.0003553907480265278,
      "loss": 0.66,
      "step": 401950
    },
    {
      "epoch": 4.255768284097586,
      "grad_norm": 0.911593496799469,
      "learning_rate": 0.00035534885910545205,
      "loss": 0.665,
      "step": 402000
    },
    {
      "epoch": 4.255768284097586,
      "eval_loss": 0.4594700038433075,
      "eval_runtime": 46.9292,
      "eval_samples_per_second": 3578.368,
      "eval_steps_per_second": 447.312,
      "step": 402000
    },
    {
      "epoch": 4.256297605877589,
      "grad_norm": 1.0400443077087402,
      "learning_rate": 0.0003553069665878049,
      "loss": 0.6792,
      "step": 402050
    },
    {
      "epoch": 4.256826927657593,
      "grad_norm": 1.1089861392974854,
      "learning_rate": 0.00035526507047501656,
      "loss": 0.6699,
      "step": 402100
    },
    {
      "epoch": 4.257356249437596,
      "grad_norm": 0.8698316812515259,
      "learning_rate": 0.0003552231707685173,
      "loss": 0.6628,
      "step": 402150
    },
    {
      "epoch": 4.2578855712175985,
      "grad_norm": 1.010291337966919,
      "learning_rate": 0.0003551812674697376,
      "loss": 0.6711,
      "step": 402200
    },
    {
      "epoch": 4.258414892997602,
      "grad_norm": 0.9340130090713501,
      "learning_rate": 0.00035513936058010807,
      "loss": 0.6787,
      "step": 402250
    },
    {
      "epoch": 4.258944214777605,
      "grad_norm": 1.0759676694869995,
      "learning_rate": 0.0003550974501010592,
      "loss": 0.6598,
      "step": 402300
    },
    {
      "epoch": 4.259473536557609,
      "grad_norm": 0.8959752917289734,
      "learning_rate": 0.00035505553603402203,
      "loss": 0.6699,
      "step": 402350
    },
    {
      "epoch": 4.260002858337612,
      "grad_norm": 1.0767624378204346,
      "learning_rate": 0.0003550136183804273,
      "loss": 0.6669,
      "step": 402400
    },
    {
      "epoch": 4.2605321801176155,
      "grad_norm": 1.1059454679489136,
      "learning_rate": 0.0003549716971417062,
      "loss": 0.6691,
      "step": 402450
    },
    {
      "epoch": 4.261061501897618,
      "grad_norm": 1.0386509895324707,
      "learning_rate": 0.00035492977231928993,
      "loss": 0.6719,
      "step": 402500
    },
    {
      "epoch": 4.261061501897618,
      "eval_loss": 0.46248286962509155,
      "eval_runtime": 47.0356,
      "eval_samples_per_second": 3570.276,
      "eval_steps_per_second": 446.3,
      "step": 402500
    },
    {
      "epoch": 4.261590823677622,
      "grad_norm": 1.0162426233291626,
      "learning_rate": 0.0003548878439146096,
      "loss": 0.6666,
      "step": 402550
    },
    {
      "epoch": 4.262120145457625,
      "grad_norm": 1.047559142112732,
      "learning_rate": 0.0003548459119290968,
      "loss": 0.6774,
      "step": 402600
    },
    {
      "epoch": 4.262649467237629,
      "grad_norm": 0.9784415364265442,
      "learning_rate": 0.000354803976364183,
      "loss": 0.6617,
      "step": 402650
    },
    {
      "epoch": 4.263178789017632,
      "grad_norm": 0.9611761569976807,
      "learning_rate": 0.0003547620372212999,
      "loss": 0.6703,
      "step": 402700
    },
    {
      "epoch": 4.263708110797635,
      "grad_norm": 0.9787927269935608,
      "learning_rate": 0.00035472009450187924,
      "loss": 0.6616,
      "step": 402750
    },
    {
      "epoch": 4.264237432577638,
      "grad_norm": 1.059903621673584,
      "learning_rate": 0.000354678148207353,
      "loss": 0.6825,
      "step": 402800
    },
    {
      "epoch": 4.264766754357642,
      "grad_norm": 1.0440620183944702,
      "learning_rate": 0.0003546361983391532,
      "loss": 0.646,
      "step": 402850
    },
    {
      "epoch": 4.265296076137645,
      "grad_norm": 1.0494356155395508,
      "learning_rate": 0.00035459424489871184,
      "loss": 0.6693,
      "step": 402900
    },
    {
      "epoch": 4.265825397917649,
      "grad_norm": 0.9309309124946594,
      "learning_rate": 0.0003545522878874614,
      "loss": 0.6707,
      "step": 402950
    },
    {
      "epoch": 4.2663547196976515,
      "grad_norm": 0.9785553216934204,
      "learning_rate": 0.0003545103273068342,
      "loss": 0.6701,
      "step": 403000
    },
    {
      "epoch": 4.2663547196976515,
      "eval_loss": 0.458986759185791,
      "eval_runtime": 46.9948,
      "eval_samples_per_second": 3573.373,
      "eval_steps_per_second": 446.688,
      "step": 403000
    },
    {
      "epoch": 4.266884041477654,
      "grad_norm": 1.013967514038086,
      "learning_rate": 0.0003544683631582627,
      "loss": 0.6702,
      "step": 403050
    },
    {
      "epoch": 4.267413363257658,
      "grad_norm": 0.9478808045387268,
      "learning_rate": 0.00035442639544317964,
      "loss": 0.679,
      "step": 403100
    },
    {
      "epoch": 4.267942685037661,
      "grad_norm": 1.0748907327651978,
      "learning_rate": 0.00035438442416301777,
      "loss": 0.676,
      "step": 403150
    },
    {
      "epoch": 4.268472006817665,
      "grad_norm": 1.0712106227874756,
      "learning_rate": 0.0003543424493192098,
      "loss": 0.6711,
      "step": 403200
    },
    {
      "epoch": 4.269001328597668,
      "grad_norm": 0.9814479947090149,
      "learning_rate": 0.000354300470913189,
      "loss": 0.6754,
      "step": 403250
    },
    {
      "epoch": 4.269530650377671,
      "grad_norm": 0.9732765555381775,
      "learning_rate": 0.00035425848894638835,
      "loss": 0.677,
      "step": 403300
    },
    {
      "epoch": 4.270059972157674,
      "grad_norm": 1.0625157356262207,
      "learning_rate": 0.0003542165034202411,
      "loss": 0.6675,
      "step": 403350
    },
    {
      "epoch": 4.270589293937678,
      "grad_norm": 0.9115423560142517,
      "learning_rate": 0.00035417451433618076,
      "loss": 0.6598,
      "step": 403400
    },
    {
      "epoch": 4.271118615717681,
      "grad_norm": 0.9894094467163086,
      "learning_rate": 0.0003541325216956406,
      "loss": 0.6596,
      "step": 403450
    },
    {
      "epoch": 4.271647937497685,
      "grad_norm": 0.9365724921226501,
      "learning_rate": 0.0003540905255000543,
      "loss": 0.6758,
      "step": 403500
    },
    {
      "epoch": 4.271647937497685,
      "eval_loss": 0.459697961807251,
      "eval_runtime": 46.9169,
      "eval_samples_per_second": 3579.305,
      "eval_steps_per_second": 447.429,
      "step": 403500
    },
    {
      "epoch": 4.272177259277687,
      "grad_norm": 1.0552809238433838,
      "learning_rate": 0.0003540485257508557,
      "loss": 0.6635,
      "step": 403550
    },
    {
      "epoch": 4.272706581057691,
      "grad_norm": 0.9866892099380493,
      "learning_rate": 0.0003540065224494786,
      "loss": 0.6527,
      "step": 403600
    },
    {
      "epoch": 4.273235902837694,
      "grad_norm": 0.8940772414207458,
      "learning_rate": 0.0003539645155973569,
      "loss": 0.6779,
      "step": 403650
    },
    {
      "epoch": 4.273765224617698,
      "grad_norm": 0.9832609295845032,
      "learning_rate": 0.0003539225051959248,
      "loss": 0.6637,
      "step": 403700
    },
    {
      "epoch": 4.274294546397701,
      "grad_norm": 1.0599979162216187,
      "learning_rate": 0.00035388049124661646,
      "loss": 0.6757,
      "step": 403750
    },
    {
      "epoch": 4.2748238681777035,
      "grad_norm": 1.0563991069793701,
      "learning_rate": 0.0003538384737508663,
      "loss": 0.6742,
      "step": 403800
    },
    {
      "epoch": 4.275353189957707,
      "grad_norm": 0.9868772029876709,
      "learning_rate": 0.0003537964527101087,
      "loss": 0.6696,
      "step": 403850
    },
    {
      "epoch": 4.27588251173771,
      "grad_norm": 0.9094681739807129,
      "learning_rate": 0.0003537544281257783,
      "loss": 0.6593,
      "step": 403900
    },
    {
      "epoch": 4.276411833517714,
      "grad_norm": 1.0608326196670532,
      "learning_rate": 0.0003537123999993097,
      "loss": 0.6675,
      "step": 403950
    },
    {
      "epoch": 4.276941155297717,
      "grad_norm": 1.0420150756835938,
      "learning_rate": 0.0003536703683321379,
      "loss": 0.6646,
      "step": 404000
    },
    {
      "epoch": 4.276941155297717,
      "eval_loss": 0.4581259787082672,
      "eval_runtime": 46.9329,
      "eval_samples_per_second": 3578.089,
      "eval_steps_per_second": 447.277,
      "step": 404000
    },
    {
      "epoch": 4.2774704770777205,
      "grad_norm": 1.0192773342132568,
      "learning_rate": 0.0003536283331256977,
      "loss": 0.6546,
      "step": 404050
    },
    {
      "epoch": 4.277999798857723,
      "grad_norm": 0.9517964720726013,
      "learning_rate": 0.0003535871351909712,
      "loss": 0.6546,
      "step": 404100
    },
    {
      "epoch": 4.278529120637727,
      "grad_norm": 1.008886456489563,
      "learning_rate": 0.00035354509298101344,
      "loss": 0.6702,
      "step": 404150
    },
    {
      "epoch": 4.27905844241773,
      "grad_norm": 1.0335736274719238,
      "learning_rate": 0.00035350304723606426,
      "loss": 0.6581,
      "step": 404200
    },
    {
      "epoch": 4.279587764197734,
      "grad_norm": 1.0374000072479248,
      "learning_rate": 0.000353460997957559,
      "loss": 0.665,
      "step": 404250
    },
    {
      "epoch": 4.280117085977737,
      "grad_norm": 0.9476638436317444,
      "learning_rate": 0.0003534189451469332,
      "loss": 0.6611,
      "step": 404300
    },
    {
      "epoch": 4.28064640775774,
      "grad_norm": 1.0035563707351685,
      "learning_rate": 0.0003533768888056225,
      "loss": 0.6675,
      "step": 404350
    },
    {
      "epoch": 4.281175729537743,
      "grad_norm": 0.9710924625396729,
      "learning_rate": 0.0003533348289350628,
      "loss": 0.6649,
      "step": 404400
    },
    {
      "epoch": 4.281705051317747,
      "grad_norm": 1.0154595375061035,
      "learning_rate": 0.00035329276553668987,
      "loss": 0.6596,
      "step": 404450
    },
    {
      "epoch": 4.28223437309775,
      "grad_norm": 1.0475773811340332,
      "learning_rate": 0.0003532506986119399,
      "loss": 0.6462,
      "step": 404500
    },
    {
      "epoch": 4.28223437309775,
      "eval_loss": 0.4585639238357544,
      "eval_runtime": 46.768,
      "eval_samples_per_second": 3590.703,
      "eval_steps_per_second": 448.854,
      "step": 404500
    },
    {
      "epoch": 4.282763694877753,
      "grad_norm": 0.9857012033462524,
      "learning_rate": 0.00035320862816224887,
      "loss": 0.6703,
      "step": 404550
    },
    {
      "epoch": 4.2832930166577565,
      "grad_norm": 1.0269266366958618,
      "learning_rate": 0.00035316655418905313,
      "loss": 0.6668,
      "step": 404600
    },
    {
      "epoch": 4.283822338437759,
      "grad_norm": 0.9754359126091003,
      "learning_rate": 0.0003531244766937891,
      "loss": 0.6647,
      "step": 404650
    },
    {
      "epoch": 4.284351660217763,
      "grad_norm": 1.0206334590911865,
      "learning_rate": 0.00035308239567789323,
      "loss": 0.6661,
      "step": 404700
    },
    {
      "epoch": 4.284880981997766,
      "grad_norm": 1.0961869955062866,
      "learning_rate": 0.00035304031114280216,
      "loss": 0.6753,
      "step": 404750
    },
    {
      "epoch": 4.28541030377777,
      "grad_norm": 0.9300652146339417,
      "learning_rate": 0.0003529982230899527,
      "loss": 0.6852,
      "step": 404800
    },
    {
      "epoch": 4.285939625557773,
      "grad_norm": 1.0384012460708618,
      "learning_rate": 0.00035295613152078165,
      "loss": 0.6652,
      "step": 404850
    },
    {
      "epoch": 4.286468947337776,
      "grad_norm": 0.8596302270889282,
      "learning_rate": 0.00035291403643672605,
      "loss": 0.6659,
      "step": 404900
    },
    {
      "epoch": 4.286998269117779,
      "grad_norm": 0.9165545105934143,
      "learning_rate": 0.00035287193783922294,
      "loss": 0.6617,
      "step": 404950
    },
    {
      "epoch": 4.287527590897783,
      "grad_norm": 0.9827726483345032,
      "learning_rate": 0.0003528298357297096,
      "loss": 0.6606,
      "step": 405000
    },
    {
      "epoch": 4.287527590897783,
      "eval_loss": 0.45756015181541443,
      "eval_runtime": 46.9453,
      "eval_samples_per_second": 3577.142,
      "eval_steps_per_second": 447.159,
      "step": 405000
    },
    {
      "epoch": 4.288056912677786,
      "grad_norm": 0.9895902872085571,
      "learning_rate": 0.0003527877301096234,
      "loss": 0.6724,
      "step": 405050
    },
    {
      "epoch": 4.28858623445779,
      "grad_norm": 1.0023002624511719,
      "learning_rate": 0.0003527456209804018,
      "loss": 0.6584,
      "step": 405100
    },
    {
      "epoch": 4.2891155562377925,
      "grad_norm": 0.9948468208312988,
      "learning_rate": 0.00035270350834348243,
      "loss": 0.6661,
      "step": 405150
    },
    {
      "epoch": 4.289644878017796,
      "grad_norm": 0.9861842393875122,
      "learning_rate": 0.0003526613922003029,
      "loss": 0.6793,
      "step": 405200
    },
    {
      "epoch": 4.290174199797799,
      "grad_norm": 1.0211515426635742,
      "learning_rate": 0.0003526192725523011,
      "loss": 0.6678,
      "step": 405250
    },
    {
      "epoch": 4.290703521577802,
      "grad_norm": 0.9737319946289062,
      "learning_rate": 0.0003525771494009149,
      "loss": 0.6676,
      "step": 405300
    },
    {
      "epoch": 4.291232843357806,
      "grad_norm": 1.0099525451660156,
      "learning_rate": 0.00035253502274758253,
      "loss": 0.6673,
      "step": 405350
    },
    {
      "epoch": 4.291762165137809,
      "grad_norm": 1.0109279155731201,
      "learning_rate": 0.00035249289259374207,
      "loss": 0.6555,
      "step": 405400
    },
    {
      "epoch": 4.292291486917812,
      "grad_norm": 0.934565007686615,
      "learning_rate": 0.00035245075894083176,
      "loss": 0.6702,
      "step": 405450
    },
    {
      "epoch": 4.292820808697815,
      "grad_norm": 0.9781014919281006,
      "learning_rate": 0.0003524086217902903,
      "loss": 0.6726,
      "step": 405500
    },
    {
      "epoch": 4.292820808697815,
      "eval_loss": 0.4592491090297699,
      "eval_runtime": 46.938,
      "eval_samples_per_second": 3577.697,
      "eval_steps_per_second": 447.228,
      "step": 405500
    },
    {
      "epoch": 4.293350130477819,
      "grad_norm": 1.0841023921966553,
      "learning_rate": 0.00035236648114355583,
      "loss": 0.6699,
      "step": 405550
    },
    {
      "epoch": 4.293879452257822,
      "grad_norm": 0.8991468548774719,
      "learning_rate": 0.0003523243370020674,
      "loss": 0.6666,
      "step": 405600
    },
    {
      "epoch": 4.294408774037826,
      "grad_norm": 1.0608161687850952,
      "learning_rate": 0.00035228218936726355,
      "loss": 0.67,
      "step": 405650
    },
    {
      "epoch": 4.2949380958178285,
      "grad_norm": 0.9783301949501038,
      "learning_rate": 0.0003522400382405833,
      "loss": 0.6737,
      "step": 405700
    },
    {
      "epoch": 4.295467417597832,
      "grad_norm": 1.0177313089370728,
      "learning_rate": 0.00035219788362346563,
      "loss": 0.6708,
      "step": 405750
    },
    {
      "epoch": 4.295996739377835,
      "grad_norm": 1.0580192804336548,
      "learning_rate": 0.00035215572551734964,
      "loss": 0.6643,
      "step": 405800
    },
    {
      "epoch": 4.296526061157839,
      "grad_norm": 1.0132383108139038,
      "learning_rate": 0.0003521135639236747,
      "loss": 0.6653,
      "step": 405850
    },
    {
      "epoch": 4.297055382937842,
      "grad_norm": 1.1223429441452026,
      "learning_rate": 0.0003520713988438801,
      "loss": 0.6527,
      "step": 405900
    },
    {
      "epoch": 4.2975847047178455,
      "grad_norm": 1.0014148950576782,
      "learning_rate": 0.0003520292302794054,
      "loss": 0.6823,
      "step": 405950
    },
    {
      "epoch": 4.298114026497848,
      "grad_norm": 1.009046196937561,
      "learning_rate": 0.00035198705823169025,
      "loss": 0.6779,
      "step": 406000
    },
    {
      "epoch": 4.298114026497848,
      "eval_loss": 0.45898863673210144,
      "eval_runtime": 46.888,
      "eval_samples_per_second": 3581.517,
      "eval_steps_per_second": 447.706,
      "step": 406000
    },
    {
      "epoch": 4.298643348277851,
      "grad_norm": 0.9630110263824463,
      "learning_rate": 0.0003519448827021743,
      "loss": 0.6662,
      "step": 406050
    },
    {
      "epoch": 4.299172670057855,
      "grad_norm": 0.9869595766067505,
      "learning_rate": 0.00035190354730659326,
      "loss": 0.6621,
      "step": 406100
    },
    {
      "epoch": 4.299701991837858,
      "grad_norm": 0.9675790667533875,
      "learning_rate": 0.00035186136488735977,
      "loss": 0.6705,
      "step": 406150
    },
    {
      "epoch": 4.300231313617862,
      "grad_norm": 0.9720834493637085,
      "learning_rate": 0.00035181917899061656,
      "loss": 0.6779,
      "step": 406200
    },
    {
      "epoch": 4.3007606353978645,
      "grad_norm": 1.0446529388427734,
      "learning_rate": 0.000351776989617804,
      "loss": 0.6728,
      "step": 406250
    },
    {
      "epoch": 4.301289957177868,
      "grad_norm": 1.0484251976013184,
      "learning_rate": 0.00035173479677036234,
      "loss": 0.664,
      "step": 406300
    },
    {
      "epoch": 4.301819278957871,
      "grad_norm": 0.9365256428718567,
      "learning_rate": 0.000351692600449732,
      "loss": 0.6675,
      "step": 406350
    },
    {
      "epoch": 4.302348600737875,
      "grad_norm": 1.0243088006973267,
      "learning_rate": 0.0003516504006573536,
      "loss": 0.6594,
      "step": 406400
    },
    {
      "epoch": 4.302877922517878,
      "grad_norm": 0.9477466940879822,
      "learning_rate": 0.00035160819739466783,
      "loss": 0.6566,
      "step": 406450
    },
    {
      "epoch": 4.3034072442978815,
      "grad_norm": 1.1016242504119873,
      "learning_rate": 0.0003515659906631154,
      "loss": 0.6737,
      "step": 406500
    },
    {
      "epoch": 4.3034072442978815,
      "eval_loss": 0.45520514249801636,
      "eval_runtime": 47.2415,
      "eval_samples_per_second": 3554.715,
      "eval_steps_per_second": 444.355,
      "step": 406500
    },
    {
      "epoch": 4.303936566077884,
      "grad_norm": 0.9804493188858032,
      "learning_rate": 0.00035152378046413734,
      "loss": 0.655,
      "step": 406550
    },
    {
      "epoch": 4.304465887857888,
      "grad_norm": 0.9945054650306702,
      "learning_rate": 0.00035148156679917466,
      "loss": 0.6587,
      "step": 406600
    },
    {
      "epoch": 4.304995209637891,
      "grad_norm": 1.1145119667053223,
      "learning_rate": 0.0003514393496696685,
      "loss": 0.6708,
      "step": 406650
    },
    {
      "epoch": 4.305524531417895,
      "grad_norm": 1.0378798246383667,
      "learning_rate": 0.0003513971290770601,
      "loss": 0.6706,
      "step": 406700
    },
    {
      "epoch": 4.306053853197898,
      "grad_norm": 1.0838322639465332,
      "learning_rate": 0.00035135490502279093,
      "loss": 0.6677,
      "step": 406750
    },
    {
      "epoch": 4.3065831749779,
      "grad_norm": 1.026373028755188,
      "learning_rate": 0.0003513126775083025,
      "loss": 0.6582,
      "step": 406800
    },
    {
      "epoch": 4.307112496757904,
      "grad_norm": 1.0544945001602173,
      "learning_rate": 0.00035127044653503637,
      "loss": 0.6634,
      "step": 406850
    },
    {
      "epoch": 4.307641818537907,
      "grad_norm": 1.0072200298309326,
      "learning_rate": 0.00035122821210443436,
      "loss": 0.6708,
      "step": 406900
    },
    {
      "epoch": 4.308171140317911,
      "grad_norm": 1.0565836429595947,
      "learning_rate": 0.0003511859742179383,
      "loss": 0.6674,
      "step": 406950
    },
    {
      "epoch": 4.308700462097914,
      "grad_norm": 0.9641504287719727,
      "learning_rate": 0.00035114373287699016,
      "loss": 0.6715,
      "step": 407000
    },
    {
      "epoch": 4.308700462097914,
      "eval_loss": 0.4583510458469391,
      "eval_runtime": 47.1477,
      "eval_samples_per_second": 3561.783,
      "eval_steps_per_second": 445.239,
      "step": 407000
    },
    {
      "epoch": 4.309229783877917,
      "grad_norm": 0.9154204726219177,
      "learning_rate": 0.0003511014880830321,
      "loss": 0.6635,
      "step": 407050
    },
    {
      "epoch": 4.30975910565792,
      "grad_norm": 0.9909324049949646,
      "learning_rate": 0.00035105923983750633,
      "loss": 0.6596,
      "step": 407100
    },
    {
      "epoch": 4.310288427437924,
      "grad_norm": 1.06564199924469,
      "learning_rate": 0.0003510169881418552,
      "loss": 0.6648,
      "step": 407150
    },
    {
      "epoch": 4.310817749217927,
      "grad_norm": 1.0460283756256104,
      "learning_rate": 0.000350974732997521,
      "loss": 0.6518,
      "step": 407200
    },
    {
      "epoch": 4.311347070997931,
      "grad_norm": 0.9470543265342712,
      "learning_rate": 0.00035093247440594664,
      "loss": 0.6756,
      "step": 407250
    },
    {
      "epoch": 4.3118763927779336,
      "grad_norm": 1.0739021301269531,
      "learning_rate": 0.00035089021236857446,
      "loss": 0.6748,
      "step": 407300
    },
    {
      "epoch": 4.312405714557937,
      "grad_norm": 0.9070006608963013,
      "learning_rate": 0.0003508479468868475,
      "loss": 0.6649,
      "step": 407350
    },
    {
      "epoch": 4.31293503633794,
      "grad_norm": 1.021698236465454,
      "learning_rate": 0.00035080567796220866,
      "loss": 0.6796,
      "step": 407400
    },
    {
      "epoch": 4.313464358117944,
      "grad_norm": 0.9616873860359192,
      "learning_rate": 0.00035076340559610095,
      "loss": 0.6562,
      "step": 407450
    },
    {
      "epoch": 4.313993679897947,
      "grad_norm": 1.0366873741149902,
      "learning_rate": 0.0003507211297899675,
      "loss": 0.6492,
      "step": 407500
    },
    {
      "epoch": 4.313993679897947,
      "eval_loss": 0.45616522431373596,
      "eval_runtime": 46.9305,
      "eval_samples_per_second": 3578.267,
      "eval_steps_per_second": 447.299,
      "step": 407500
    },
    {
      "epoch": 4.31452300167795,
      "grad_norm": 1.0871999263763428,
      "learning_rate": 0.00035067885054525157,
      "loss": 0.6721,
      "step": 407550
    },
    {
      "epoch": 4.315052323457953,
      "grad_norm": 0.9973878860473633,
      "learning_rate": 0.00035063656786339664,
      "loss": 0.6717,
      "step": 407600
    },
    {
      "epoch": 4.315581645237956,
      "grad_norm": 1.0733518600463867,
      "learning_rate": 0.0003505942817458462,
      "loss": 0.6558,
      "step": 407650
    },
    {
      "epoch": 4.31611096701796,
      "grad_norm": 1.0922248363494873,
      "learning_rate": 0.0003505519921940439,
      "loss": 0.6645,
      "step": 407700
    },
    {
      "epoch": 4.316640288797963,
      "grad_norm": 0.9993061423301697,
      "learning_rate": 0.0003505096992094334,
      "loss": 0.6704,
      "step": 407750
    },
    {
      "epoch": 4.317169610577967,
      "grad_norm": 0.9800723791122437,
      "learning_rate": 0.0003504674027934586,
      "loss": 0.6613,
      "step": 407800
    },
    {
      "epoch": 4.3176989323579695,
      "grad_norm": 1.0062650442123413,
      "learning_rate": 0.0003504251029475636,
      "loss": 0.6649,
      "step": 407850
    },
    {
      "epoch": 4.318228254137973,
      "grad_norm": 1.092818021774292,
      "learning_rate": 0.00035038279967319235,
      "loss": 0.6711,
      "step": 407900
    },
    {
      "epoch": 4.318757575917976,
      "grad_norm": 1.078957438468933,
      "learning_rate": 0.00035034049297178924,
      "loss": 0.6547,
      "step": 407950
    },
    {
      "epoch": 4.31928689769798,
      "grad_norm": 0.9840205311775208,
      "learning_rate": 0.0003502981828447984,
      "loss": 0.6637,
      "step": 408000
    },
    {
      "epoch": 4.31928689769798,
      "eval_loss": 0.4561271369457245,
      "eval_runtime": 46.896,
      "eval_samples_per_second": 3580.902,
      "eval_steps_per_second": 447.629,
      "step": 408000
    },
    {
      "epoch": 4.319816219477983,
      "grad_norm": 1.0709328651428223,
      "learning_rate": 0.0003502558692936644,
      "loss": 0.6627,
      "step": 408050
    },
    {
      "epoch": 4.3203455412579865,
      "grad_norm": 1.0748209953308105,
      "learning_rate": 0.0003502135523198318,
      "loss": 0.6664,
      "step": 408100
    },
    {
      "epoch": 4.320874863037989,
      "grad_norm": 1.041316032409668,
      "learning_rate": 0.0003501720783661659,
      "loss": 0.6738,
      "step": 408150
    },
    {
      "epoch": 4.321404184817993,
      "grad_norm": 1.0266907215118408,
      "learning_rate": 0.0003501297546196523,
      "loss": 0.6778,
      "step": 408200
    },
    {
      "epoch": 4.321933506597996,
      "grad_norm": 0.9895690083503723,
      "learning_rate": 0.0003500874274547456,
      "loss": 0.6771,
      "step": 408250
    },
    {
      "epoch": 4.322462828377999,
      "grad_norm": 0.9693835973739624,
      "learning_rate": 0.0003500450968728908,
      "loss": 0.6716,
      "step": 408300
    },
    {
      "epoch": 4.322992150158003,
      "grad_norm": 0.9070499539375305,
      "learning_rate": 0.0003500027628755331,
      "loss": 0.6595,
      "step": 408350
    },
    {
      "epoch": 4.3235214719380055,
      "grad_norm": 1.0118054151535034,
      "learning_rate": 0.00034996042546411773,
      "loss": 0.6749,
      "step": 408400
    },
    {
      "epoch": 4.324050793718009,
      "grad_norm": 1.088016390800476,
      "learning_rate": 0.0003499180846400901,
      "loss": 0.6705,
      "step": 408450
    },
    {
      "epoch": 4.324580115498012,
      "grad_norm": 1.0473244190216064,
      "learning_rate": 0.0003498757404048957,
      "loss": 0.6476,
      "step": 408500
    },
    {
      "epoch": 4.324580115498012,
      "eval_loss": 0.45623981952667236,
      "eval_runtime": 47.1205,
      "eval_samples_per_second": 3563.842,
      "eval_steps_per_second": 445.496,
      "step": 408500
    },
    {
      "epoch": 4.325109437278016,
      "grad_norm": 0.9711179137229919,
      "learning_rate": 0.0003498333927599801,
      "loss": 0.6702,
      "step": 408550
    },
    {
      "epoch": 4.325638759058019,
      "grad_norm": 0.969474732875824,
      "learning_rate": 0.0003497910417067892,
      "loss": 0.6737,
      "step": 408600
    },
    {
      "epoch": 4.3261680808380225,
      "grad_norm": 1.029973030090332,
      "learning_rate": 0.00034974868724676865,
      "loss": 0.6657,
      "step": 408650
    },
    {
      "epoch": 4.326697402618025,
      "grad_norm": 1.0787482261657715,
      "learning_rate": 0.00034970632938136455,
      "loss": 0.6639,
      "step": 408700
    },
    {
      "epoch": 4.327226724398029,
      "grad_norm": 0.9494093060493469,
      "learning_rate": 0.0003496639681120229,
      "loss": 0.6783,
      "step": 408750
    },
    {
      "epoch": 4.327756046178032,
      "grad_norm": 1.0422931909561157,
      "learning_rate": 0.0003496216034401899,
      "loss": 0.6703,
      "step": 408800
    },
    {
      "epoch": 4.328285367958036,
      "grad_norm": 1.058845043182373,
      "learning_rate": 0.00034957923536731194,
      "loss": 0.6659,
      "step": 408850
    },
    {
      "epoch": 4.328814689738039,
      "grad_norm": 0.9897315502166748,
      "learning_rate": 0.0003495368638948354,
      "loss": 0.6632,
      "step": 408900
    },
    {
      "epoch": 4.329344011518042,
      "grad_norm": 1.0403705835342407,
      "learning_rate": 0.0003494944890242068,
      "loss": 0.6723,
      "step": 408950
    },
    {
      "epoch": 4.329873333298045,
      "grad_norm": 0.9049813747406006,
      "learning_rate": 0.0003494521107568729,
      "loss": 0.667,
      "step": 409000
    },
    {
      "epoch": 4.329873333298045,
      "eval_loss": 0.45508265495300293,
      "eval_runtime": 46.887,
      "eval_samples_per_second": 3581.592,
      "eval_steps_per_second": 447.715,
      "step": 409000
    },
    {
      "epoch": 4.330402655078048,
      "grad_norm": 0.9216938018798828,
      "learning_rate": 0.00034940972909428035,
      "loss": 0.6675,
      "step": 409050
    },
    {
      "epoch": 4.330931976858052,
      "grad_norm": 1.015080213546753,
      "learning_rate": 0.00034936734403787615,
      "loss": 0.6508,
      "step": 409100
    },
    {
      "epoch": 4.331461298638055,
      "grad_norm": 1.0003278255462646,
      "learning_rate": 0.0003493249555891073,
      "loss": 0.6735,
      "step": 409150
    },
    {
      "epoch": 4.3319906204180585,
      "grad_norm": 0.8899487257003784,
      "learning_rate": 0.0003492825637494208,
      "loss": 0.6576,
      "step": 409200
    },
    {
      "epoch": 4.332519942198061,
      "grad_norm": 1.1185883283615112,
      "learning_rate": 0.000349240168520264,
      "loss": 0.6666,
      "step": 409250
    },
    {
      "epoch": 4.333049263978065,
      "grad_norm": 0.8268952965736389,
      "learning_rate": 0.0003491977699030842,
      "loss": 0.661,
      "step": 409300
    },
    {
      "epoch": 4.333578585758068,
      "grad_norm": 1.0796451568603516,
      "learning_rate": 0.000349155367899329,
      "loss": 0.6683,
      "step": 409350
    },
    {
      "epoch": 4.334107907538072,
      "grad_norm": 1.0705857276916504,
      "learning_rate": 0.0003491129625104459,
      "loss": 0.6631,
      "step": 409400
    },
    {
      "epoch": 4.334637229318075,
      "grad_norm": 1.1030890941619873,
      "learning_rate": 0.0003490705537378825,
      "loss": 0.6656,
      "step": 409450
    },
    {
      "epoch": 4.335166551098078,
      "grad_norm": 0.8824100494384766,
      "learning_rate": 0.00034902814158308687,
      "loss": 0.6605,
      "step": 409500
    },
    {
      "epoch": 4.335166551098078,
      "eval_loss": 0.4567485749721527,
      "eval_runtime": 46.9565,
      "eval_samples_per_second": 3576.289,
      "eval_steps_per_second": 447.052,
      "step": 409500
    },
    {
      "epoch": 4.335695872878081,
      "grad_norm": 0.9858425259590149,
      "learning_rate": 0.0003489857260475068,
      "loss": 0.6621,
      "step": 409550
    },
    {
      "epoch": 4.336225194658085,
      "grad_norm": 1.0478334426879883,
      "learning_rate": 0.00034894330713259024,
      "loss": 0.6681,
      "step": 409600
    },
    {
      "epoch": 4.336754516438088,
      "grad_norm": 1.139450192451477,
      "learning_rate": 0.00034890088483978556,
      "loss": 0.6543,
      "step": 409650
    },
    {
      "epoch": 4.337283838218092,
      "grad_norm": 0.974674642086029,
      "learning_rate": 0.00034885845917054085,
      "loss": 0.6603,
      "step": 409700
    },
    {
      "epoch": 4.3378131599980945,
      "grad_norm": 1.0498809814453125,
      "learning_rate": 0.0003488160301263047,
      "loss": 0.6661,
      "step": 409750
    },
    {
      "epoch": 4.338342481778097,
      "grad_norm": 0.9359694123268127,
      "learning_rate": 0.00034877359770852544,
      "loss": 0.6678,
      "step": 409800
    },
    {
      "epoch": 4.338871803558101,
      "grad_norm": 1.0259512662887573,
      "learning_rate": 0.00034873116191865185,
      "loss": 0.6762,
      "step": 409850
    },
    {
      "epoch": 4.339401125338104,
      "grad_norm": 0.9907614588737488,
      "learning_rate": 0.0003486887227581326,
      "loss": 0.6834,
      "step": 409900
    },
    {
      "epoch": 4.339930447118108,
      "grad_norm": 1.1031359434127808,
      "learning_rate": 0.0003486462802284165,
      "loss": 0.6524,
      "step": 409950
    },
    {
      "epoch": 4.340459768898111,
      "grad_norm": 0.9995375275611877,
      "learning_rate": 0.00034860383433095253,
      "loss": 0.6734,
      "step": 410000
    },
    {
      "epoch": 4.340459768898111,
      "eval_loss": 0.45468005537986755,
      "eval_runtime": 46.9079,
      "eval_samples_per_second": 3579.992,
      "eval_steps_per_second": 447.515,
      "step": 410000
    },
    {
      "epoch": 4.340989090678114,
      "grad_norm": 1.0241984128952026,
      "learning_rate": 0.0003485613850671899,
      "loss": 0.6673,
      "step": 410050
    },
    {
      "epoch": 4.341518412458117,
      "grad_norm": 1.039402961730957,
      "learning_rate": 0.0003485189324385776,
      "loss": 0.6699,
      "step": 410100
    },
    {
      "epoch": 4.342047734238121,
      "grad_norm": 1.0083283185958862,
      "learning_rate": 0.0003484773255993574,
      "loss": 0.6632,
      "step": 410150
    },
    {
      "epoch": 4.342577056018124,
      "grad_norm": 1.0153666734695435,
      "learning_rate": 0.000348434866312619,
      "loss": 0.6634,
      "step": 410200
    },
    {
      "epoch": 4.343106377798128,
      "grad_norm": 1.09824538230896,
      "learning_rate": 0.00034839240366535043,
      "loss": 0.661,
      "step": 410250
    },
    {
      "epoch": 4.3436356995781304,
      "grad_norm": 0.9503639340400696,
      "learning_rate": 0.0003483499376590012,
      "loss": 0.676,
      "step": 410300
    },
    {
      "epoch": 4.344165021358134,
      "grad_norm": 0.9717446565628052,
      "learning_rate": 0.00034830746829502115,
      "loss": 0.6697,
      "step": 410350
    },
    {
      "epoch": 4.344694343138137,
      "grad_norm": 1.009285569190979,
      "learning_rate": 0.0003482649955748602,
      "loss": 0.68,
      "step": 410400
    },
    {
      "epoch": 4.345223664918141,
      "grad_norm": 1.0343953371047974,
      "learning_rate": 0.00034822251949996835,
      "loss": 0.6739,
      "step": 410450
    },
    {
      "epoch": 4.345752986698144,
      "grad_norm": 1.0139566659927368,
      "learning_rate": 0.0003481800400717957,
      "loss": 0.6792,
      "step": 410500
    },
    {
      "epoch": 4.345752986698144,
      "eval_loss": 0.4544788897037506,
      "eval_runtime": 46.9463,
      "eval_samples_per_second": 3577.065,
      "eval_steps_per_second": 447.149,
      "step": 410500
    },
    {
      "epoch": 4.346282308478147,
      "grad_norm": 0.9860248565673828,
      "learning_rate": 0.00034813755729179246,
      "loss": 0.6738,
      "step": 410550
    },
    {
      "epoch": 4.34681163025815,
      "grad_norm": 1.0327647924423218,
      "learning_rate": 0.00034809507116140905,
      "loss": 0.6646,
      "step": 410600
    },
    {
      "epoch": 4.347340952038153,
      "grad_norm": 1.078373670578003,
      "learning_rate": 0.0003480525816820959,
      "loss": 0.6653,
      "step": 410650
    },
    {
      "epoch": 4.347870273818157,
      "grad_norm": 1.1137017011642456,
      "learning_rate": 0.00034801008885530354,
      "loss": 0.6729,
      "step": 410700
    },
    {
      "epoch": 4.34839959559816,
      "grad_norm": 0.9977909922599792,
      "learning_rate": 0.0003479675926824827,
      "loss": 0.6694,
      "step": 410750
    },
    {
      "epoch": 4.348928917378164,
      "grad_norm": 1.1030458211898804,
      "learning_rate": 0.00034792509316508417,
      "loss": 0.6813,
      "step": 410800
    },
    {
      "epoch": 4.349458239158166,
      "grad_norm": 0.9686506390571594,
      "learning_rate": 0.00034788259030455886,
      "loss": 0.6585,
      "step": 410850
    },
    {
      "epoch": 4.34998756093817,
      "grad_norm": 0.9712594151496887,
      "learning_rate": 0.0003478400841023579,
      "loss": 0.6591,
      "step": 410900
    },
    {
      "epoch": 4.350516882718173,
      "grad_norm": 1.1375116109848022,
      "learning_rate": 0.0003477975745599323,
      "loss": 0.6623,
      "step": 410950
    },
    {
      "epoch": 4.351046204498177,
      "grad_norm": 0.991685688495636,
      "learning_rate": 0.0003477550616787333,
      "loss": 0.6551,
      "step": 411000
    },
    {
      "epoch": 4.351046204498177,
      "eval_loss": 0.4547330439090729,
      "eval_runtime": 46.952,
      "eval_samples_per_second": 3576.628,
      "eval_steps_per_second": 447.094,
      "step": 411000
    },
    {
      "epoch": 4.35157552627818,
      "grad_norm": 1.0268313884735107,
      "learning_rate": 0.0003477125454602124,
      "loss": 0.652,
      "step": 411050
    },
    {
      "epoch": 4.352104848058183,
      "grad_norm": 1.1248594522476196,
      "learning_rate": 0.000347670025905821,
      "loss": 0.6657,
      "step": 411100
    },
    {
      "epoch": 4.352634169838186,
      "grad_norm": 1.0039210319519043,
      "learning_rate": 0.0003476275030170108,
      "loss": 0.6618,
      "step": 411150
    },
    {
      "epoch": 4.35316349161819,
      "grad_norm": 1.0399888753890991,
      "learning_rate": 0.0003475849767952334,
      "loss": 0.6587,
      "step": 411200
    },
    {
      "epoch": 4.353692813398193,
      "grad_norm": 1.1472126245498657,
      "learning_rate": 0.00034754244724194075,
      "loss": 0.6699,
      "step": 411250
    },
    {
      "epoch": 4.354222135178196,
      "grad_norm": 1.0791925191879272,
      "learning_rate": 0.00034749991435858464,
      "loss": 0.677,
      "step": 411300
    },
    {
      "epoch": 4.3547514569581995,
      "grad_norm": 1.0930209159851074,
      "learning_rate": 0.0003474573781466172,
      "loss": 0.6623,
      "step": 411350
    },
    {
      "epoch": 4.355280778738202,
      "grad_norm": 0.9774731993675232,
      "learning_rate": 0.0003474148386074907,
      "loss": 0.6731,
      "step": 411400
    },
    {
      "epoch": 4.355810100518206,
      "grad_norm": 1.0830501317977905,
      "learning_rate": 0.0003473722957426573,
      "loss": 0.6775,
      "step": 411450
    },
    {
      "epoch": 4.356339422298209,
      "grad_norm": 1.0266321897506714,
      "learning_rate": 0.0003473297495535694,
      "loss": 0.6548,
      "step": 411500
    },
    {
      "epoch": 4.356339422298209,
      "eval_loss": 0.4544285237789154,
      "eval_runtime": 46.9558,
      "eval_samples_per_second": 3576.338,
      "eval_steps_per_second": 447.058,
      "step": 411500
    },
    {
      "epoch": 4.356868744078213,
      "grad_norm": 0.9513086080551147,
      "learning_rate": 0.0003472872000416795,
      "loss": 0.6644,
      "step": 411550
    },
    {
      "epoch": 4.357398065858216,
      "grad_norm": 1.0464115142822266,
      "learning_rate": 0.0003472446472084404,
      "loss": 0.6789,
      "step": 411600
    },
    {
      "epoch": 4.357927387638219,
      "grad_norm": 1.0530561208724976,
      "learning_rate": 0.00034720209105530464,
      "loss": 0.6649,
      "step": 411650
    },
    {
      "epoch": 4.358456709418222,
      "grad_norm": 0.9796785116195679,
      "learning_rate": 0.00034715953158372516,
      "loss": 0.6525,
      "step": 411700
    },
    {
      "epoch": 4.358986031198226,
      "grad_norm": 1.1007564067840576,
      "learning_rate": 0.00034711696879515485,
      "loss": 0.6753,
      "step": 411750
    },
    {
      "epoch": 4.359515352978229,
      "grad_norm": 1.056721568107605,
      "learning_rate": 0.0003470744026910469,
      "loss": 0.6652,
      "step": 411800
    },
    {
      "epoch": 4.360044674758233,
      "grad_norm": 1.063679575920105,
      "learning_rate": 0.00034703183327285445,
      "loss": 0.6609,
      "step": 411850
    },
    {
      "epoch": 4.3605739965382355,
      "grad_norm": 0.9540368318557739,
      "learning_rate": 0.00034698926054203073,
      "loss": 0.6565,
      "step": 411900
    },
    {
      "epoch": 4.361103318318239,
      "grad_norm": 1.0041179656982422,
      "learning_rate": 0.0003469466845000293,
      "loss": 0.6751,
      "step": 411950
    },
    {
      "epoch": 4.361632640098242,
      "grad_norm": 1.0578628778457642,
      "learning_rate": 0.00034690410514830357,
      "loss": 0.6696,
      "step": 412000
    },
    {
      "epoch": 4.361632640098242,
      "eval_loss": 0.4548708498477936,
      "eval_runtime": 47.1586,
      "eval_samples_per_second": 3560.963,
      "eval_steps_per_second": 445.136,
      "step": 412000
    },
    {
      "epoch": 4.362161961878245,
      "grad_norm": 0.8903297185897827,
      "learning_rate": 0.0003468615224883072,
      "loss": 0.6729,
      "step": 412050
    },
    {
      "epoch": 4.362691283658249,
      "grad_norm": 0.9722495675086975,
      "learning_rate": 0.000346818936521494,
      "loss": 0.6521,
      "step": 412100
    },
    {
      "epoch": 4.363220605438252,
      "grad_norm": 1.055208683013916,
      "learning_rate": 0.00034677634724931787,
      "loss": 0.6781,
      "step": 412150
    },
    {
      "epoch": 4.363749927218255,
      "grad_norm": 0.9473221898078918,
      "learning_rate": 0.00034673460655712323,
      "loss": 0.6599,
      "step": 412200
    },
    {
      "epoch": 4.364279248998258,
      "grad_norm": 1.1250896453857422,
      "learning_rate": 0.00034669201074461804,
      "loss": 0.6779,
      "step": 412250
    },
    {
      "epoch": 4.364808570778262,
      "grad_norm": 1.034568428993225,
      "learning_rate": 0.000346649411631083,
      "loss": 0.6571,
      "step": 412300
    },
    {
      "epoch": 4.365337892558265,
      "grad_norm": 1.0636422634124756,
      "learning_rate": 0.0003466068092179725,
      "loss": 0.6748,
      "step": 412350
    },
    {
      "epoch": 4.365867214338269,
      "grad_norm": 1.2338906526565552,
      "learning_rate": 0.000346564203506741,
      "loss": 0.6535,
      "step": 412400
    },
    {
      "epoch": 4.3663965361182715,
      "grad_norm": 1.0658128261566162,
      "learning_rate": 0.000346521594498843,
      "loss": 0.6609,
      "step": 412450
    },
    {
      "epoch": 4.366925857898275,
      "grad_norm": 1.043005108833313,
      "learning_rate": 0.0003464789821957331,
      "loss": 0.665,
      "step": 412500
    },
    {
      "epoch": 4.366925857898275,
      "eval_loss": 0.45272064208984375,
      "eval_runtime": 47.132,
      "eval_samples_per_second": 3562.972,
      "eval_steps_per_second": 445.387,
      "step": 412500
    },
    {
      "epoch": 4.367455179678278,
      "grad_norm": 1.094642162322998,
      "learning_rate": 0.00034643636659886616,
      "loss": 0.6647,
      "step": 412550
    },
    {
      "epoch": 4.367984501458282,
      "grad_norm": 1.02769136428833,
      "learning_rate": 0.00034639374770969707,
      "loss": 0.6833,
      "step": 412600
    },
    {
      "epoch": 4.368513823238285,
      "grad_norm": 0.9967330098152161,
      "learning_rate": 0.00034635112552968073,
      "loss": 0.663,
      "step": 412650
    },
    {
      "epoch": 4.3690431450182885,
      "grad_norm": 1.0882314443588257,
      "learning_rate": 0.00034630850006027236,
      "loss": 0.6598,
      "step": 412700
    },
    {
      "epoch": 4.369572466798291,
      "grad_norm": 1.0902119874954224,
      "learning_rate": 0.000346265871302927,
      "loss": 0.6782,
      "step": 412750
    },
    {
      "epoch": 4.370101788578294,
      "grad_norm": 1.0820748805999756,
      "learning_rate": 0.0003462232392591002,
      "loss": 0.664,
      "step": 412800
    },
    {
      "epoch": 4.370631110358298,
      "grad_norm": 1.1046113967895508,
      "learning_rate": 0.0003461806039302473,
      "loss": 0.6492,
      "step": 412850
    },
    {
      "epoch": 4.371160432138301,
      "grad_norm": 1.0261330604553223,
      "learning_rate": 0.0003461379653178239,
      "loss": 0.6592,
      "step": 412900
    },
    {
      "epoch": 4.371689753918305,
      "grad_norm": 1.118783712387085,
      "learning_rate": 0.00034609532342328553,
      "loss": 0.6686,
      "step": 412950
    },
    {
      "epoch": 4.3722190756983075,
      "grad_norm": 1.0312597751617432,
      "learning_rate": 0.0003460526782480881,
      "loss": 0.658,
      "step": 413000
    },
    {
      "epoch": 4.3722190756983075,
      "eval_loss": 0.4536500871181488,
      "eval_runtime": 46.8729,
      "eval_samples_per_second": 3582.665,
      "eval_steps_per_second": 447.849,
      "step": 413000
    },
    {
      "epoch": 4.372748397478311,
      "grad_norm": 1.114065170288086,
      "learning_rate": 0.00034601002979368743,
      "loss": 0.6616,
      "step": 413050
    },
    {
      "epoch": 4.373277719258314,
      "grad_norm": 0.9908152222633362,
      "learning_rate": 0.0003459673780615396,
      "loss": 0.6621,
      "step": 413100
    },
    {
      "epoch": 4.373807041038318,
      "grad_norm": 0.9849669337272644,
      "learning_rate": 0.00034592472305310063,
      "loss": 0.6506,
      "step": 413150
    },
    {
      "epoch": 4.374336362818321,
      "grad_norm": 1.0750534534454346,
      "learning_rate": 0.00034588206476982686,
      "loss": 0.6726,
      "step": 413200
    },
    {
      "epoch": 4.3748656845983245,
      "grad_norm": 0.9592097401618958,
      "learning_rate": 0.0003458394032131745,
      "loss": 0.6689,
      "step": 413250
    },
    {
      "epoch": 4.375395006378327,
      "grad_norm": 1.012413740158081,
      "learning_rate": 0.0003457967383846001,
      "loss": 0.658,
      "step": 413300
    },
    {
      "epoch": 4.375924328158331,
      "grad_norm": 0.9517059326171875,
      "learning_rate": 0.0003457540702855602,
      "loss": 0.6646,
      "step": 413350
    },
    {
      "epoch": 4.376453649938334,
      "grad_norm": 1.0776476860046387,
      "learning_rate": 0.00034571139891751134,
      "loss": 0.6662,
      "step": 413400
    },
    {
      "epoch": 4.376982971718338,
      "grad_norm": 1.0385745763778687,
      "learning_rate": 0.00034566872428191053,
      "loss": 0.663,
      "step": 413450
    },
    {
      "epoch": 4.377512293498341,
      "grad_norm": 1.0316474437713623,
      "learning_rate": 0.00034562604638021453,
      "loss": 0.6676,
      "step": 413500
    },
    {
      "epoch": 4.377512293498341,
      "eval_loss": 0.45403456687927246,
      "eval_runtime": 46.8691,
      "eval_samples_per_second": 3582.956,
      "eval_steps_per_second": 447.885,
      "step": 413500
    },
    {
      "epoch": 4.3780416152783435,
      "grad_norm": 1.1183701753616333,
      "learning_rate": 0.00034558336521388046,
      "loss": 0.6736,
      "step": 413550
    },
    {
      "epoch": 4.378570937058347,
      "grad_norm": 0.954459011554718,
      "learning_rate": 0.00034554068078436516,
      "loss": 0.6757,
      "step": 413600
    },
    {
      "epoch": 4.37910025883835,
      "grad_norm": 1.0143460035324097,
      "learning_rate": 0.0003454979930931262,
      "loss": 0.6557,
      "step": 413650
    },
    {
      "epoch": 4.379629580618354,
      "grad_norm": 1.0844956636428833,
      "learning_rate": 0.00034545530214162074,
      "loss": 0.6738,
      "step": 413700
    },
    {
      "epoch": 4.380158902398357,
      "grad_norm": 0.9494567513465881,
      "learning_rate": 0.0003454126079313063,
      "loss": 0.6643,
      "step": 413750
    },
    {
      "epoch": 4.3806882241783605,
      "grad_norm": 0.9796157479286194,
      "learning_rate": 0.0003453699104636404,
      "loss": 0.655,
      "step": 413800
    },
    {
      "epoch": 4.381217545958363,
      "grad_norm": 1.1316629648208618,
      "learning_rate": 0.00034532720974008075,
      "loss": 0.6614,
      "step": 413850
    },
    {
      "epoch": 4.381746867738367,
      "grad_norm": 0.9964269399642944,
      "learning_rate": 0.0003452845057620851,
      "loss": 0.651,
      "step": 413900
    },
    {
      "epoch": 4.38227618951837,
      "grad_norm": 1.0744074583053589,
      "learning_rate": 0.0003452417985311114,
      "loss": 0.6611,
      "step": 413950
    },
    {
      "epoch": 4.382805511298374,
      "grad_norm": 1.0825856924057007,
      "learning_rate": 0.0003451990880486175,
      "loss": 0.6605,
      "step": 414000
    },
    {
      "epoch": 4.382805511298374,
      "eval_loss": 0.4532851278781891,
      "eval_runtime": 46.8203,
      "eval_samples_per_second": 3586.695,
      "eval_steps_per_second": 448.353,
      "step": 414000
    },
    {
      "epoch": 4.383334833078377,
      "grad_norm": 0.9648482203483582,
      "learning_rate": 0.0003451563743160618,
      "loss": 0.6725,
      "step": 414050
    },
    {
      "epoch": 4.38386415485838,
      "grad_norm": 1.0016120672225952,
      "learning_rate": 0.00034511365733490236,
      "loss": 0.6618,
      "step": 414100
    },
    {
      "epoch": 4.384393476638383,
      "grad_norm": 1.1224726438522339,
      "learning_rate": 0.00034507093710659756,
      "loss": 0.6582,
      "step": 414150
    },
    {
      "epoch": 4.384922798418387,
      "grad_norm": 0.9976330399513245,
      "learning_rate": 0.00034502906813388385,
      "loss": 0.6644,
      "step": 414200
    },
    {
      "epoch": 4.38545212019839,
      "grad_norm": 0.9730101823806763,
      "learning_rate": 0.000344986341480534,
      "loss": 0.6545,
      "step": 414250
    },
    {
      "epoch": 4.385981441978393,
      "grad_norm": 0.8871674537658691,
      "learning_rate": 0.00034494361158438525,
      "loss": 0.6632,
      "step": 414300
    },
    {
      "epoch": 4.386510763758396,
      "grad_norm": 1.057694435119629,
      "learning_rate": 0.0003449008784468964,
      "loss": 0.6519,
      "step": 414350
    },
    {
      "epoch": 4.387040085538399,
      "grad_norm": 0.9941750764846802,
      "learning_rate": 0.0003448581420695264,
      "loss": 0.6707,
      "step": 414400
    },
    {
      "epoch": 4.387569407318403,
      "grad_norm": 1.0433752536773682,
      "learning_rate": 0.0003448154024537343,
      "loss": 0.6655,
      "step": 414450
    },
    {
      "epoch": 4.388098729098406,
      "grad_norm": 0.9774463772773743,
      "learning_rate": 0.0003447735144897469,
      "loss": 0.6749,
      "step": 414500
    },
    {
      "epoch": 4.388098729098406,
      "eval_loss": 0.4524919092655182,
      "eval_runtime": 46.9557,
      "eval_samples_per_second": 3576.349,
      "eval_steps_per_second": 447.06,
      "step": 414500
    },
    {
      "epoch": 4.38862805087841,
      "grad_norm": 1.0610326528549194,
      "learning_rate": 0.00034473076846618355,
      "loss": 0.6587,
      "step": 414550
    },
    {
      "epoch": 4.3891573726584125,
      "grad_norm": 0.9798437356948853,
      "learning_rate": 0.0003446880192085466,
      "loss": 0.6546,
      "step": 414600
    },
    {
      "epoch": 4.389686694438416,
      "grad_norm": 1.079512119293213,
      "learning_rate": 0.0003446452667182953,
      "loss": 0.6688,
      "step": 414650
    },
    {
      "epoch": 4.390216016218419,
      "grad_norm": 1.0399348735809326,
      "learning_rate": 0.0003446025109968894,
      "loss": 0.6574,
      "step": 414700
    },
    {
      "epoch": 4.390745337998423,
      "grad_norm": 0.993110716342926,
      "learning_rate": 0.00034455975204578836,
      "loss": 0.6623,
      "step": 414750
    },
    {
      "epoch": 4.391274659778426,
      "grad_norm": 0.9995279312133789,
      "learning_rate": 0.00034451698986645216,
      "loss": 0.6542,
      "step": 414800
    },
    {
      "epoch": 4.3918039815584295,
      "grad_norm": 1.2439275979995728,
      "learning_rate": 0.00034447422446034056,
      "loss": 0.6655,
      "step": 414850
    },
    {
      "epoch": 4.392333303338432,
      "grad_norm": 1.0337797403335571,
      "learning_rate": 0.00034443145582891354,
      "loss": 0.6634,
      "step": 414900
    },
    {
      "epoch": 4.392862625118436,
      "grad_norm": 0.9978013038635254,
      "learning_rate": 0.0003443886839736313,
      "loss": 0.6607,
      "step": 414950
    },
    {
      "epoch": 4.393391946898439,
      "grad_norm": 0.9512547850608826,
      "learning_rate": 0.00034434590889595397,
      "loss": 0.662,
      "step": 415000
    },
    {
      "epoch": 4.393391946898439,
      "eval_loss": 0.45086047053337097,
      "eval_runtime": 46.8932,
      "eval_samples_per_second": 3581.119,
      "eval_steps_per_second": 447.656,
      "step": 415000
    },
    {
      "epoch": 4.393921268678442,
      "grad_norm": 1.1056418418884277,
      "learning_rate": 0.000344303130597342,
      "loss": 0.6506,
      "step": 415050
    },
    {
      "epoch": 4.394450590458446,
      "grad_norm": 0.9771986603736877,
      "learning_rate": 0.0003442603490792556,
      "loss": 0.6659,
      "step": 415100
    },
    {
      "epoch": 4.3949799122384485,
      "grad_norm": 0.984832227230072,
      "learning_rate": 0.00034421756434315555,
      "loss": 0.6621,
      "step": 415150
    },
    {
      "epoch": 4.395509234018452,
      "grad_norm": 0.9564297199249268,
      "learning_rate": 0.00034417477639050233,
      "loss": 0.6537,
      "step": 415200
    },
    {
      "epoch": 4.396038555798455,
      "grad_norm": 1.1202689409255981,
      "learning_rate": 0.0003441319852227568,
      "loss": 0.6507,
      "step": 415250
    },
    {
      "epoch": 4.396567877578459,
      "grad_norm": 1.0813122987747192,
      "learning_rate": 0.00034408919084137987,
      "loss": 0.6602,
      "step": 415300
    },
    {
      "epoch": 4.397097199358462,
      "grad_norm": 0.9846644401550293,
      "learning_rate": 0.0003440463932478324,
      "loss": 0.6613,
      "step": 415350
    },
    {
      "epoch": 4.3976265211384655,
      "grad_norm": 1.0925683975219727,
      "learning_rate": 0.0003440035924435756,
      "loss": 0.6741,
      "step": 415400
    },
    {
      "epoch": 4.398155842918468,
      "grad_norm": 1.1174510717391968,
      "learning_rate": 0.0003439607884300706,
      "loss": 0.6658,
      "step": 415450
    },
    {
      "epoch": 4.398685164698472,
      "grad_norm": 0.9169529676437378,
      "learning_rate": 0.00034391798120877884,
      "loss": 0.6648,
      "step": 415500
    },
    {
      "epoch": 4.398685164698472,
      "eval_loss": 0.4521440267562866,
      "eval_runtime": 47.0272,
      "eval_samples_per_second": 3570.914,
      "eval_steps_per_second": 446.38,
      "step": 415500
    },
    {
      "epoch": 4.399214486478475,
      "grad_norm": 0.9419681429862976,
      "learning_rate": 0.00034387517078116156,
      "loss": 0.6547,
      "step": 415550
    },
    {
      "epoch": 4.399743808258479,
      "grad_norm": 0.9303567409515381,
      "learning_rate": 0.0003438323571486804,
      "loss": 0.6756,
      "step": 415600
    },
    {
      "epoch": 4.400273130038482,
      "grad_norm": 0.947424054145813,
      "learning_rate": 0.00034378954031279694,
      "loss": 0.657,
      "step": 415650
    },
    {
      "epoch": 4.400802451818485,
      "grad_norm": 0.9495261907577515,
      "learning_rate": 0.000343746720274973,
      "loss": 0.6576,
      "step": 415700
    },
    {
      "epoch": 4.401331773598488,
      "grad_norm": 1.1000930070877075,
      "learning_rate": 0.00034370389703667037,
      "loss": 0.6542,
      "step": 415750
    },
    {
      "epoch": 4.401861095378491,
      "grad_norm": 1.018078088760376,
      "learning_rate": 0.00034366107059935117,
      "loss": 0.6534,
      "step": 415800
    },
    {
      "epoch": 4.402390417158495,
      "grad_norm": 1.0494072437286377,
      "learning_rate": 0.00034361824096447723,
      "loss": 0.6724,
      "step": 415850
    },
    {
      "epoch": 4.402919738938498,
      "grad_norm": 1.0292702913284302,
      "learning_rate": 0.00034357540813351097,
      "loss": 0.6654,
      "step": 415900
    },
    {
      "epoch": 4.4034490607185015,
      "grad_norm": 1.0272319316864014,
      "learning_rate": 0.00034353257210791455,
      "loss": 0.6627,
      "step": 415950
    },
    {
      "epoch": 4.403978382498504,
      "grad_norm": 0.9272782802581787,
      "learning_rate": 0.00034348973288915045,
      "loss": 0.6529,
      "step": 416000
    },
    {
      "epoch": 4.403978382498504,
      "eval_loss": 0.4508497714996338,
      "eval_runtime": 48.5007,
      "eval_samples_per_second": 3462.423,
      "eval_steps_per_second": 432.818,
      "step": 416000
    },
    {
      "epoch": 4.404507704278508,
      "grad_norm": 1.0198661088943481,
      "learning_rate": 0.00034344689047868115,
      "loss": 0.6571,
      "step": 416050
    },
    {
      "epoch": 4.405037026058511,
      "grad_norm": 0.9796271324157715,
      "learning_rate": 0.0003434040448779693,
      "loss": 0.6512,
      "step": 416100
    },
    {
      "epoch": 4.405566347838515,
      "grad_norm": 1.0693888664245605,
      "learning_rate": 0.0003433611960884775,
      "loss": 0.662,
      "step": 416150
    },
    {
      "epoch": 4.406095669618518,
      "grad_norm": 1.0645688772201538,
      "learning_rate": 0.00034331834411166886,
      "loss": 0.6685,
      "step": 416200
    },
    {
      "epoch": 4.406624991398521,
      "grad_norm": 1.032566785812378,
      "learning_rate": 0.000343275488949006,
      "loss": 0.6555,
      "step": 416250
    },
    {
      "epoch": 4.407154313178524,
      "grad_norm": 1.1602362394332886,
      "learning_rate": 0.0003432326306019523,
      "loss": 0.6593,
      "step": 416300
    },
    {
      "epoch": 4.407683634958528,
      "grad_norm": 0.9576719999313354,
      "learning_rate": 0.00034318976907197075,
      "loss": 0.6588,
      "step": 416350
    },
    {
      "epoch": 4.408212956738531,
      "grad_norm": 1.0607354640960693,
      "learning_rate": 0.00034314690436052463,
      "loss": 0.6732,
      "step": 416400
    },
    {
      "epoch": 4.408742278518535,
      "grad_norm": 1.0622437000274658,
      "learning_rate": 0.0003431040364690774,
      "loss": 0.6643,
      "step": 416450
    },
    {
      "epoch": 4.4092716002985375,
      "grad_norm": 1.11449134349823,
      "learning_rate": 0.0003430611653990925,
      "loss": 0.6685,
      "step": 416500
    },
    {
      "epoch": 4.4092716002985375,
      "eval_loss": 0.4511570930480957,
      "eval_runtime": 47.8145,
      "eval_samples_per_second": 3512.117,
      "eval_steps_per_second": 439.03,
      "step": 416500
    },
    {
      "epoch": 4.40980092207854,
      "grad_norm": 0.9940978288650513,
      "learning_rate": 0.00034301829115203353,
      "loss": 0.6609,
      "step": 416550
    },
    {
      "epoch": 4.410330243858544,
      "grad_norm": 0.9575993418693542,
      "learning_rate": 0.0003429754137293643,
      "loss": 0.6682,
      "step": 416600
    },
    {
      "epoch": 4.410859565638547,
      "grad_norm": 0.9707702398300171,
      "learning_rate": 0.00034293253313254836,
      "loss": 0.6705,
      "step": 416650
    },
    {
      "epoch": 4.411388887418551,
      "grad_norm": 1.079225778579712,
      "learning_rate": 0.00034288964936304996,
      "loss": 0.6546,
      "step": 416700
    },
    {
      "epoch": 4.411918209198554,
      "grad_norm": 0.9654713273048401,
      "learning_rate": 0.0003428467624223329,
      "loss": 0.6661,
      "step": 416750
    },
    {
      "epoch": 4.412447530978557,
      "grad_norm": 1.0389784574508667,
      "learning_rate": 0.0003428038723118615,
      "loss": 0.6519,
      "step": 416800
    },
    {
      "epoch": 4.41297685275856,
      "grad_norm": 1.0260847806930542,
      "learning_rate": 0.00034276097903309993,
      "loss": 0.6574,
      "step": 416850
    },
    {
      "epoch": 4.413506174538564,
      "grad_norm": 1.070866346359253,
      "learning_rate": 0.00034271808258751256,
      "loss": 0.6668,
      "step": 416900
    },
    {
      "epoch": 4.414035496318567,
      "grad_norm": 0.9352558851242065,
      "learning_rate": 0.0003426751829765639,
      "loss": 0.6635,
      "step": 416950
    },
    {
      "epoch": 4.414564818098571,
      "grad_norm": 1.023470401763916,
      "learning_rate": 0.0003426322802017183,
      "loss": 0.6497,
      "step": 417000
    },
    {
      "epoch": 4.414564818098571,
      "eval_loss": 0.45030802488327026,
      "eval_runtime": 47.7561,
      "eval_samples_per_second": 3516.41,
      "eval_steps_per_second": 439.567,
      "step": 417000
    },
    {
      "epoch": 4.4150941398785735,
      "grad_norm": 1.0099363327026367,
      "learning_rate": 0.0003425893742644408,
      "loss": 0.6604,
      "step": 417050
    },
    {
      "epoch": 4.415623461658577,
      "grad_norm": 1.0025975704193115,
      "learning_rate": 0.0003425464651661959,
      "loss": 0.6563,
      "step": 417100
    },
    {
      "epoch": 4.41615278343858,
      "grad_norm": 0.9348796606063843,
      "learning_rate": 0.0003425035529084487,
      "loss": 0.6668,
      "step": 417150
    },
    {
      "epoch": 4.416682105218584,
      "grad_norm": 0.9574776887893677,
      "learning_rate": 0.00034246063749266407,
      "loss": 0.6787,
      "step": 417200
    },
    {
      "epoch": 4.417211426998587,
      "grad_norm": 1.055446743965149,
      "learning_rate": 0.00034241771892030726,
      "loss": 0.6678,
      "step": 417250
    },
    {
      "epoch": 4.41774074877859,
      "grad_norm": 1.1818121671676636,
      "learning_rate": 0.00034237479719284337,
      "loss": 0.67,
      "step": 417300
    },
    {
      "epoch": 4.418270070558593,
      "grad_norm": 1.0421336889266968,
      "learning_rate": 0.0003423318723117378,
      "loss": 0.6571,
      "step": 417350
    },
    {
      "epoch": 4.418799392338596,
      "grad_norm": 0.9948487281799316,
      "learning_rate": 0.000342288944278456,
      "loss": 0.6626,
      "step": 417400
    },
    {
      "epoch": 4.4193287141186,
      "grad_norm": 0.9453309178352356,
      "learning_rate": 0.0003422460130944634,
      "loss": 0.6627,
      "step": 417450
    },
    {
      "epoch": 4.419858035898603,
      "grad_norm": 1.0228365659713745,
      "learning_rate": 0.0003422030787612258,
      "loss": 0.6561,
      "step": 417500
    },
    {
      "epoch": 4.419858035898603,
      "eval_loss": 0.44988495111465454,
      "eval_runtime": 47.7531,
      "eval_samples_per_second": 3516.628,
      "eval_steps_per_second": 439.594,
      "step": 417500
    },
    {
      "epoch": 4.420387357678607,
      "grad_norm": 0.9659549593925476,
      "learning_rate": 0.0003421601412802089,
      "loss": 0.6632,
      "step": 417550
    },
    {
      "epoch": 4.420916679458609,
      "grad_norm": 1.0280389785766602,
      "learning_rate": 0.0003421172006528786,
      "loss": 0.6628,
      "step": 417600
    },
    {
      "epoch": 4.421446001238613,
      "grad_norm": 1.1223759651184082,
      "learning_rate": 0.00034207425688070084,
      "loss": 0.6572,
      "step": 417650
    },
    {
      "epoch": 4.421975323018616,
      "grad_norm": 0.943236231803894,
      "learning_rate": 0.0003420313099651417,
      "loss": 0.6643,
      "step": 417700
    },
    {
      "epoch": 4.42250464479862,
      "grad_norm": 1.0722978115081787,
      "learning_rate": 0.0003419883599076674,
      "loss": 0.6561,
      "step": 417750
    },
    {
      "epoch": 4.423033966578623,
      "grad_norm": 0.9930921792984009,
      "learning_rate": 0.00034194540670974425,
      "loss": 0.6527,
      "step": 417800
    },
    {
      "epoch": 4.4235632883586264,
      "grad_norm": 0.9759464859962463,
      "learning_rate": 0.00034190245037283857,
      "loss": 0.6726,
      "step": 417850
    },
    {
      "epoch": 4.424092610138629,
      "grad_norm": 1.057801604270935,
      "learning_rate": 0.00034185949089841694,
      "loss": 0.6515,
      "step": 417900
    },
    {
      "epoch": 4.424621931918633,
      "grad_norm": 1.0049231052398682,
      "learning_rate": 0.000341816528287946,
      "loss": 0.6694,
      "step": 417950
    },
    {
      "epoch": 4.425151253698636,
      "grad_norm": 1.0704901218414307,
      "learning_rate": 0.0003417735625428925,
      "loss": 0.6629,
      "step": 418000
    },
    {
      "epoch": 4.425151253698636,
      "eval_loss": 0.44798800349235535,
      "eval_runtime": 47.5088,
      "eval_samples_per_second": 3534.714,
      "eval_steps_per_second": 441.855,
      "step": 418000
    },
    {
      "epoch": 4.425680575478639,
      "grad_norm": 1.013796091079712,
      "learning_rate": 0.0003417305936647232,
      "loss": 0.6646,
      "step": 418050
    },
    {
      "epoch": 4.426209897258643,
      "grad_norm": 0.9997844099998474,
      "learning_rate": 0.0003416876216549051,
      "loss": 0.6501,
      "step": 418100
    },
    {
      "epoch": 4.426739219038645,
      "grad_norm": 0.921335756778717,
      "learning_rate": 0.0003416446465149052,
      "loss": 0.6675,
      "step": 418150
    },
    {
      "epoch": 4.427268540818649,
      "grad_norm": 1.0694223642349243,
      "learning_rate": 0.00034160166824619067,
      "loss": 0.6556,
      "step": 418200
    },
    {
      "epoch": 4.427797862598652,
      "grad_norm": 0.9348466396331787,
      "learning_rate": 0.00034155868685022876,
      "loss": 0.6689,
      "step": 418250
    },
    {
      "epoch": 4.428327184378656,
      "grad_norm": 1.0664492845535278,
      "learning_rate": 0.0003415157023284869,
      "loss": 0.6577,
      "step": 418300
    },
    {
      "epoch": 4.428856506158659,
      "grad_norm": 1.1263984441757202,
      "learning_rate": 0.00034147271468243254,
      "loss": 0.6674,
      "step": 418350
    },
    {
      "epoch": 4.429385827938662,
      "grad_norm": 1.1172146797180176,
      "learning_rate": 0.0003414297239135332,
      "loss": 0.6631,
      "step": 418400
    },
    {
      "epoch": 4.429915149718665,
      "grad_norm": 1.0464766025543213,
      "learning_rate": 0.00034138673002325664,
      "loss": 0.666,
      "step": 418450
    },
    {
      "epoch": 4.430444471498669,
      "grad_norm": 1.073502779006958,
      "learning_rate": 0.00034134459298383997,
      "loss": 0.6612,
      "step": 418500
    },
    {
      "epoch": 4.430444471498669,
      "eval_loss": 0.4516240358352661,
      "eval_runtime": 47.1165,
      "eval_samples_per_second": 3564.146,
      "eval_steps_per_second": 445.534,
      "step": 418500
    },
    {
      "epoch": 4.430973793278672,
      "grad_norm": 1.022815227508545,
      "learning_rate": 0.00034130159291756684,
      "loss": 0.6572,
      "step": 418550
    },
    {
      "epoch": 4.431503115058676,
      "grad_norm": 0.932921826839447,
      "learning_rate": 0.0003412585897342908,
      "loss": 0.6429,
      "step": 418600
    },
    {
      "epoch": 4.4320324368386785,
      "grad_norm": 1.0364446640014648,
      "learning_rate": 0.00034121558343548,
      "loss": 0.6683,
      "step": 418650
    },
    {
      "epoch": 4.432561758618682,
      "grad_norm": 0.9609675407409668,
      "learning_rate": 0.0003411725740226027,
      "loss": 0.6549,
      "step": 418700
    },
    {
      "epoch": 4.433091080398685,
      "grad_norm": 1.0906260013580322,
      "learning_rate": 0.0003411295614971271,
      "loss": 0.6521,
      "step": 418750
    },
    {
      "epoch": 4.433620402178688,
      "grad_norm": 1.0366312265396118,
      "learning_rate": 0.00034108654586052165,
      "loss": 0.6581,
      "step": 418800
    },
    {
      "epoch": 4.434149723958692,
      "grad_norm": 0.8985291719436646,
      "learning_rate": 0.000341043527114255,
      "loss": 0.6587,
      "step": 418850
    },
    {
      "epoch": 4.434679045738695,
      "grad_norm": 1.0627318620681763,
      "learning_rate": 0.0003410005052597957,
      "loss": 0.6572,
      "step": 418900
    },
    {
      "epoch": 4.435208367518698,
      "grad_norm": 1.069993257522583,
      "learning_rate": 0.00034095748029861254,
      "loss": 0.6615,
      "step": 418950
    },
    {
      "epoch": 4.435737689298701,
      "grad_norm": 1.0374616384506226,
      "learning_rate": 0.00034091445223217434,
      "loss": 0.6592,
      "step": 419000
    },
    {
      "epoch": 4.435737689298701,
      "eval_loss": 0.44781163334846497,
      "eval_runtime": 47.2195,
      "eval_samples_per_second": 3556.372,
      "eval_steps_per_second": 444.562,
      "step": 419000
    },
    {
      "epoch": 4.436267011078705,
      "grad_norm": 1.046730637550354,
      "learning_rate": 0.00034087142106195003,
      "loss": 0.661,
      "step": 419050
    },
    {
      "epoch": 4.436796332858708,
      "grad_norm": 0.9569963812828064,
      "learning_rate": 0.0003408283867894088,
      "loss": 0.6585,
      "step": 419100
    },
    {
      "epoch": 4.437325654638712,
      "grad_norm": 1.0380016565322876,
      "learning_rate": 0.0003407853494160197,
      "loss": 0.6596,
      "step": 419150
    },
    {
      "epoch": 4.4378549764187145,
      "grad_norm": 1.0206044912338257,
      "learning_rate": 0.0003407423089432521,
      "loss": 0.6493,
      "step": 419200
    },
    {
      "epoch": 4.438384298198718,
      "grad_norm": 0.9308079481124878,
      "learning_rate": 0.00034069926537257534,
      "loss": 0.6622,
      "step": 419250
    },
    {
      "epoch": 4.438913619978721,
      "grad_norm": 1.0486503839492798,
      "learning_rate": 0.0003406562187054589,
      "loss": 0.6714,
      "step": 419300
    },
    {
      "epoch": 4.439442941758725,
      "grad_norm": 1.055098056793213,
      "learning_rate": 0.00034061316894337245,
      "loss": 0.6577,
      "step": 419350
    },
    {
      "epoch": 4.439972263538728,
      "grad_norm": 1.1022884845733643,
      "learning_rate": 0.00034057011608778565,
      "loss": 0.6631,
      "step": 419400
    },
    {
      "epoch": 4.4405015853187315,
      "grad_norm": 1.0641945600509644,
      "learning_rate": 0.0003405270601401683,
      "loss": 0.6682,
      "step": 419450
    },
    {
      "epoch": 4.441030907098734,
      "grad_norm": 1.0537190437316895,
      "learning_rate": 0.0003404840011019903,
      "loss": 0.6458,
      "step": 419500
    },
    {
      "epoch": 4.441030907098734,
      "eval_loss": 0.45063015818595886,
      "eval_runtime": 47.0212,
      "eval_samples_per_second": 3571.366,
      "eval_steps_per_second": 446.437,
      "step": 419500
    },
    {
      "epoch": 4.441560228878737,
      "grad_norm": 0.941478431224823,
      "learning_rate": 0.00034044093897472167,
      "loss": 0.6675,
      "step": 419550
    },
    {
      "epoch": 4.442089550658741,
      "grad_norm": 1.086683988571167,
      "learning_rate": 0.00034039787375983254,
      "loss": 0.6551,
      "step": 419600
    },
    {
      "epoch": 4.442618872438744,
      "grad_norm": 1.0807082653045654,
      "learning_rate": 0.0003403548054587932,
      "loss": 0.6671,
      "step": 419650
    },
    {
      "epoch": 4.443148194218748,
      "grad_norm": 1.0129023790359497,
      "learning_rate": 0.0003403117340730739,
      "loss": 0.6766,
      "step": 419700
    },
    {
      "epoch": 4.4436775159987505,
      "grad_norm": 0.8796965479850769,
      "learning_rate": 0.00034026865960414514,
      "loss": 0.6596,
      "step": 419750
    },
    {
      "epoch": 4.444206837778754,
      "grad_norm": 1.040649175643921,
      "learning_rate": 0.00034022558205347745,
      "loss": 0.6576,
      "step": 419800
    },
    {
      "epoch": 4.444736159558757,
      "grad_norm": 1.0106923580169678,
      "learning_rate": 0.00034018250142254147,
      "loss": 0.659,
      "step": 419850
    },
    {
      "epoch": 4.445265481338761,
      "grad_norm": 1.1409903764724731,
      "learning_rate": 0.00034013941771280796,
      "loss": 0.6625,
      "step": 419900
    },
    {
      "epoch": 4.445794803118764,
      "grad_norm": 0.992767870426178,
      "learning_rate": 0.00034009633092574776,
      "loss": 0.6606,
      "step": 419950
    },
    {
      "epoch": 4.4463241248987675,
      "grad_norm": 0.9754877090454102,
      "learning_rate": 0.0003400532410628319,
      "loss": 0.6542,
      "step": 420000
    },
    {
      "epoch": 4.4463241248987675,
      "eval_loss": 0.45113399624824524,
      "eval_runtime": 46.9026,
      "eval_samples_per_second": 3580.4,
      "eval_steps_per_second": 447.566,
      "step": 420000
    },
    {
      "epoch": 4.44685344667877,
      "grad_norm": 0.9998311400413513,
      "learning_rate": 0.00034001014812553145,
      "loss": 0.6669,
      "step": 420050
    },
    {
      "epoch": 4.447382768458774,
      "grad_norm": 1.035722017288208,
      "learning_rate": 0.00033996705211531753,
      "loss": 0.6687,
      "step": 420100
    },
    {
      "epoch": 4.447912090238777,
      "grad_norm": 1.0175198316574097,
      "learning_rate": 0.00033992395303366143,
      "loss": 0.6521,
      "step": 420150
    },
    {
      "epoch": 4.448441412018781,
      "grad_norm": 0.956069827079773,
      "learning_rate": 0.0003398808508820345,
      "loss": 0.6463,
      "step": 420200
    },
    {
      "epoch": 4.448970733798784,
      "grad_norm": 1.0328080654144287,
      "learning_rate": 0.0003398377456619084,
      "loss": 0.6537,
      "step": 420250
    },
    {
      "epoch": 4.4495000555787865,
      "grad_norm": 1.0358877182006836,
      "learning_rate": 0.0003397946373747545,
      "loss": 0.6539,
      "step": 420300
    },
    {
      "epoch": 4.45002937735879,
      "grad_norm": 0.9759083390235901,
      "learning_rate": 0.00033975152602204467,
      "loss": 0.658,
      "step": 420350
    },
    {
      "epoch": 4.450558699138793,
      "grad_norm": 1.0614452362060547,
      "learning_rate": 0.0003397084116052507,
      "loss": 0.6664,
      "step": 420400
    },
    {
      "epoch": 4.451088020918797,
      "grad_norm": 1.0513957738876343,
      "learning_rate": 0.00033966529412584435,
      "loss": 0.6613,
      "step": 420450
    },
    {
      "epoch": 4.4516173426988,
      "grad_norm": 0.8527642488479614,
      "learning_rate": 0.0003396230360260984,
      "loss": 0.6679,
      "step": 420500
    },
    {
      "epoch": 4.4516173426988,
      "eval_loss": 0.4493756592273712,
      "eval_runtime": 46.9418,
      "eval_samples_per_second": 3577.408,
      "eval_steps_per_second": 447.192,
      "step": 420500
    },
    {
      "epoch": 4.4521466644788035,
      "grad_norm": 0.9810371398925781,
      "learning_rate": 0.00033957991248706264,
      "loss": 0.6516,
      "step": 420550
    },
    {
      "epoch": 4.452675986258806,
      "grad_norm": 1.004281759262085,
      "learning_rate": 0.0003395367858898015,
      "loss": 0.6693,
      "step": 420600
    },
    {
      "epoch": 4.45320530803881,
      "grad_norm": 0.9981666803359985,
      "learning_rate": 0.00033949365623578735,
      "loss": 0.6606,
      "step": 420650
    },
    {
      "epoch": 4.453734629818813,
      "grad_norm": 0.9821649789810181,
      "learning_rate": 0.00033945052352649265,
      "loss": 0.6586,
      "step": 420700
    },
    {
      "epoch": 4.454263951598817,
      "grad_norm": 0.9564014673233032,
      "learning_rate": 0.0003394073877633898,
      "loss": 0.6532,
      "step": 420750
    },
    {
      "epoch": 4.45479327337882,
      "grad_norm": 1.0156499147415161,
      "learning_rate": 0.00033936424894795154,
      "loss": 0.6624,
      "step": 420800
    },
    {
      "epoch": 4.455322595158823,
      "grad_norm": 1.0360310077667236,
      "learning_rate": 0.00033932110708165063,
      "loss": 0.6605,
      "step": 420850
    },
    {
      "epoch": 4.455851916938826,
      "grad_norm": 0.902614414691925,
      "learning_rate": 0.00033927796216595983,
      "loss": 0.6582,
      "step": 420900
    },
    {
      "epoch": 4.45638123871883,
      "grad_norm": 1.0304243564605713,
      "learning_rate": 0.0003392348142023522,
      "loss": 0.6569,
      "step": 420950
    },
    {
      "epoch": 4.456910560498833,
      "grad_norm": 1.068918228149414,
      "learning_rate": 0.0003391916631923007,
      "loss": 0.6528,
      "step": 421000
    },
    {
      "epoch": 4.456910560498833,
      "eval_loss": 0.4478982985019684,
      "eval_runtime": 47.1245,
      "eval_samples_per_second": 3563.536,
      "eval_steps_per_second": 445.458,
      "step": 421000
    },
    {
      "epoch": 4.457439882278836,
      "grad_norm": 1.0695174932479858,
      "learning_rate": 0.00033914850913727856,
      "loss": 0.6672,
      "step": 421050
    },
    {
      "epoch": 4.4579692040588395,
      "grad_norm": 1.015227198600769,
      "learning_rate": 0.00033910535203875896,
      "loss": 0.6501,
      "step": 421100
    },
    {
      "epoch": 4.458498525838842,
      "grad_norm": 1.0718622207641602,
      "learning_rate": 0.00033906219189821536,
      "loss": 0.6594,
      "step": 421150
    },
    {
      "epoch": 4.459027847618846,
      "grad_norm": 0.9951292276382446,
      "learning_rate": 0.00033901902871712116,
      "loss": 0.6633,
      "step": 421200
    },
    {
      "epoch": 4.459557169398849,
      "grad_norm": 1.1038905382156372,
      "learning_rate": 0.00033897586249694993,
      "loss": 0.6581,
      "step": 421250
    },
    {
      "epoch": 4.460086491178853,
      "grad_norm": 1.129280686378479,
      "learning_rate": 0.0003389326932391755,
      "loss": 0.659,
      "step": 421300
    },
    {
      "epoch": 4.460615812958856,
      "grad_norm": 0.9211045503616333,
      "learning_rate": 0.0003388895209452715,
      "loss": 0.6594,
      "step": 421350
    },
    {
      "epoch": 4.461145134738859,
      "grad_norm": 0.9048163890838623,
      "learning_rate": 0.0003388463456167118,
      "loss": 0.6585,
      "step": 421400
    },
    {
      "epoch": 4.461674456518862,
      "grad_norm": 1.0399665832519531,
      "learning_rate": 0.00033880316725497044,
      "loss": 0.6619,
      "step": 421450
    },
    {
      "epoch": 4.462203778298866,
      "grad_norm": 0.9827475547790527,
      "learning_rate": 0.00033875998586152154,
      "loss": 0.6584,
      "step": 421500
    },
    {
      "epoch": 4.462203778298866,
      "eval_loss": 0.4481305778026581,
      "eval_runtime": 46.8204,
      "eval_samples_per_second": 3586.682,
      "eval_steps_per_second": 448.351,
      "step": 421500
    },
    {
      "epoch": 4.462733100078869,
      "grad_norm": 0.9603052735328674,
      "learning_rate": 0.00033871680143783935,
      "loss": 0.6646,
      "step": 421550
    },
    {
      "epoch": 4.463262421858873,
      "grad_norm": 0.937741756439209,
      "learning_rate": 0.000338673613985398,
      "loss": 0.6649,
      "step": 421600
    },
    {
      "epoch": 4.463791743638875,
      "grad_norm": 0.9103447794914246,
      "learning_rate": 0.0003386304235056721,
      "loss": 0.6545,
      "step": 421650
    },
    {
      "epoch": 4.464321065418879,
      "grad_norm": 1.0058073997497559,
      "learning_rate": 0.0003385872300001359,
      "loss": 0.6618,
      "step": 421700
    },
    {
      "epoch": 4.464850387198882,
      "grad_norm": 1.0722070932388306,
      "learning_rate": 0.00033854403347026424,
      "loss": 0.6684,
      "step": 421750
    },
    {
      "epoch": 4.465379708978885,
      "grad_norm": 1.061215877532959,
      "learning_rate": 0.00033850083391753175,
      "loss": 0.6492,
      "step": 421800
    },
    {
      "epoch": 4.465909030758889,
      "grad_norm": 1.1452986001968384,
      "learning_rate": 0.0003384576313434132,
      "loss": 0.6613,
      "step": 421850
    },
    {
      "epoch": 4.4664383525388915,
      "grad_norm": 1.10765540599823,
      "learning_rate": 0.00033841442574938365,
      "loss": 0.6562,
      "step": 421900
    },
    {
      "epoch": 4.466967674318895,
      "grad_norm": 1.1591331958770752,
      "learning_rate": 0.000338371217136918,
      "loss": 0.6677,
      "step": 421950
    },
    {
      "epoch": 4.467496996098898,
      "grad_norm": 1.040558099746704,
      "learning_rate": 0.0003383280055074913,
      "loss": 0.6563,
      "step": 422000
    },
    {
      "epoch": 4.467496996098898,
      "eval_loss": 0.4475782811641693,
      "eval_runtime": 46.8569,
      "eval_samples_per_second": 3583.891,
      "eval_steps_per_second": 448.002,
      "step": 422000
    },
    {
      "epoch": 4.468026317878902,
      "grad_norm": 1.0603877305984497,
      "learning_rate": 0.000338284790862579,
      "loss": 0.6544,
      "step": 422050
    },
    {
      "epoch": 4.468555639658905,
      "grad_norm": 1.0902665853500366,
      "learning_rate": 0.00033824157320365623,
      "loss": 0.6511,
      "step": 422100
    },
    {
      "epoch": 4.4690849614389085,
      "grad_norm": 1.003406286239624,
      "learning_rate": 0.00033819835253219853,
      "loss": 0.6613,
      "step": 422150
    },
    {
      "epoch": 4.469614283218911,
      "grad_norm": 0.9113385677337646,
      "learning_rate": 0.00033815512884968144,
      "loss": 0.6557,
      "step": 422200
    },
    {
      "epoch": 4.470143604998915,
      "grad_norm": 1.1567485332489014,
      "learning_rate": 0.0003381119021575806,
      "loss": 0.6637,
      "step": 422250
    },
    {
      "epoch": 4.470672926778918,
      "grad_norm": 0.9770152568817139,
      "learning_rate": 0.00033806867245737176,
      "loss": 0.6561,
      "step": 422300
    },
    {
      "epoch": 4.471202248558922,
      "grad_norm": 1.0579767227172852,
      "learning_rate": 0.0003380254397505307,
      "loss": 0.6592,
      "step": 422350
    },
    {
      "epoch": 4.471731570338925,
      "grad_norm": 1.0286232233047485,
      "learning_rate": 0.00033798220403853343,
      "loss": 0.6475,
      "step": 422400
    },
    {
      "epoch": 4.472260892118928,
      "grad_norm": 1.102530598640442,
      "learning_rate": 0.00033793896532285597,
      "loss": 0.6534,
      "step": 422450
    },
    {
      "epoch": 4.472790213898931,
      "grad_norm": 0.8704294562339783,
      "learning_rate": 0.0003378957236049745,
      "loss": 0.6448,
      "step": 422500
    },
    {
      "epoch": 4.472790213898931,
      "eval_loss": 0.4478496015071869,
      "eval_runtime": 46.8602,
      "eval_samples_per_second": 3583.639,
      "eval_steps_per_second": 447.971,
      "step": 422500
    },
    {
      "epoch": 4.473319535678934,
      "grad_norm": 1.048619031906128,
      "learning_rate": 0.000337853343810135,
      "loss": 0.6631,
      "step": 422550
    },
    {
      "epoch": 4.473848857458938,
      "grad_norm": 1.196912407875061,
      "learning_rate": 0.0003378100961522449,
      "loss": 0.6579,
      "step": 422600
    },
    {
      "epoch": 4.474378179238941,
      "grad_norm": 0.9517095685005188,
      "learning_rate": 0.00033776684549655025,
      "loss": 0.6563,
      "step": 422650
    },
    {
      "epoch": 4.4749075010189445,
      "grad_norm": 0.9221736192703247,
      "learning_rate": 0.0003377235918445277,
      "loss": 0.6606,
      "step": 422700
    },
    {
      "epoch": 4.475436822798947,
      "grad_norm": 0.9550618529319763,
      "learning_rate": 0.00033768033519765395,
      "loss": 0.6365,
      "step": 422750
    },
    {
      "epoch": 4.475966144578951,
      "grad_norm": 1.0075602531433105,
      "learning_rate": 0.00033763707555740577,
      "loss": 0.6554,
      "step": 422800
    },
    {
      "epoch": 4.476495466358954,
      "grad_norm": 1.0256831645965576,
      "learning_rate": 0.0003375938129252599,
      "loss": 0.6633,
      "step": 422850
    },
    {
      "epoch": 4.477024788138958,
      "grad_norm": 0.9736791849136353,
      "learning_rate": 0.00033755054730269334,
      "loss": 0.6534,
      "step": 422900
    },
    {
      "epoch": 4.477554109918961,
      "grad_norm": 0.9934867024421692,
      "learning_rate": 0.00033750727869118327,
      "loss": 0.6708,
      "step": 422950
    },
    {
      "epoch": 4.478083431698964,
      "grad_norm": 1.0306843519210815,
      "learning_rate": 0.0003374640070922068,
      "loss": 0.6629,
      "step": 423000
    },
    {
      "epoch": 4.478083431698964,
      "eval_loss": 0.4479502737522125,
      "eval_runtime": 46.7763,
      "eval_samples_per_second": 3590.07,
      "eval_steps_per_second": 448.775,
      "step": 423000
    },
    {
      "epoch": 4.478612753478967,
      "grad_norm": 1.100304365158081,
      "learning_rate": 0.0003374207325072411,
      "loss": 0.6528,
      "step": 423050
    },
    {
      "epoch": 4.479142075258971,
      "grad_norm": 1.0320627689361572,
      "learning_rate": 0.00033737745493776376,
      "loss": 0.6608,
      "step": 423100
    },
    {
      "epoch": 4.479671397038974,
      "grad_norm": 0.9936184287071228,
      "learning_rate": 0.0003373341743852522,
      "loss": 0.6589,
      "step": 423150
    },
    {
      "epoch": 4.480200718818978,
      "grad_norm": 0.925479531288147,
      "learning_rate": 0.00033729089085118386,
      "loss": 0.6567,
      "step": 423200
    },
    {
      "epoch": 4.4807300405989805,
      "grad_norm": 0.9288715124130249,
      "learning_rate": 0.00033724760433703657,
      "loss": 0.656,
      "step": 423250
    },
    {
      "epoch": 4.481259362378983,
      "grad_norm": 0.9764261245727539,
      "learning_rate": 0.000337204314844288,
      "loss": 0.6634,
      "step": 423300
    },
    {
      "epoch": 4.481788684158987,
      "grad_norm": 0.9914735555648804,
      "learning_rate": 0.00033716102237441617,
      "loss": 0.6556,
      "step": 423350
    },
    {
      "epoch": 4.48231800593899,
      "grad_norm": 1.030792236328125,
      "learning_rate": 0.00033711772692889897,
      "loss": 0.6586,
      "step": 423400
    },
    {
      "epoch": 4.482847327718994,
      "grad_norm": 0.9670392870903015,
      "learning_rate": 0.0003370744285092144,
      "loss": 0.6705,
      "step": 423450
    },
    {
      "epoch": 4.483376649498997,
      "grad_norm": 0.9760534167289734,
      "learning_rate": 0.00033703112711684093,
      "loss": 0.6573,
      "step": 423500
    },
    {
      "epoch": 4.483376649498997,
      "eval_loss": 0.44736677408218384,
      "eval_runtime": 46.8772,
      "eval_samples_per_second": 3582.339,
      "eval_steps_per_second": 447.808,
      "step": 423500
    },
    {
      "epoch": 4.483905971279,
      "grad_norm": 1.0280777215957642,
      "learning_rate": 0.00033698782275325666,
      "loss": 0.6558,
      "step": 423550
    },
    {
      "epoch": 4.484435293059003,
      "grad_norm": 0.8983606100082397,
      "learning_rate": 0.00033694451541994,
      "loss": 0.6461,
      "step": 423600
    },
    {
      "epoch": 4.484964614839007,
      "grad_norm": 0.9933573603630066,
      "learning_rate": 0.0003369012051183695,
      "loss": 0.6707,
      "step": 423650
    },
    {
      "epoch": 4.48549393661901,
      "grad_norm": 0.9454506039619446,
      "learning_rate": 0.0003368578918500238,
      "loss": 0.6709,
      "step": 423700
    },
    {
      "epoch": 4.486023258399014,
      "grad_norm": 1.0685029029846191,
      "learning_rate": 0.0003368145756163814,
      "loss": 0.6494,
      "step": 423750
    },
    {
      "epoch": 4.4865525801790165,
      "grad_norm": 1.0839086771011353,
      "learning_rate": 0.00033677125641892134,
      "loss": 0.6654,
      "step": 423800
    },
    {
      "epoch": 4.48708190195902,
      "grad_norm": 1.0450007915496826,
      "learning_rate": 0.0003367279342591223,
      "loss": 0.6626,
      "step": 423850
    },
    {
      "epoch": 4.487611223739023,
      "grad_norm": 1.0946975946426392,
      "learning_rate": 0.00033668460913846343,
      "loss": 0.653,
      "step": 423900
    },
    {
      "epoch": 4.488140545519027,
      "grad_norm": 0.91426682472229,
      "learning_rate": 0.00033664128105842387,
      "loss": 0.6481,
      "step": 423950
    },
    {
      "epoch": 4.48866986729903,
      "grad_norm": 0.9313919544219971,
      "learning_rate": 0.00033659795002048264,
      "loss": 0.6635,
      "step": 424000
    },
    {
      "epoch": 4.48866986729903,
      "eval_loss": 0.44626253843307495,
      "eval_runtime": 46.8429,
      "eval_samples_per_second": 3584.962,
      "eval_steps_per_second": 448.136,
      "step": 424000
    },
    {
      "epoch": 4.489199189079033,
      "grad_norm": 0.9212095141410828,
      "learning_rate": 0.0003365546160261192,
      "loss": 0.6522,
      "step": 424050
    },
    {
      "epoch": 4.489728510859036,
      "grad_norm": 0.9208086133003235,
      "learning_rate": 0.0003365112790768129,
      "loss": 0.649,
      "step": 424100
    },
    {
      "epoch": 4.490257832639039,
      "grad_norm": 0.9714544415473938,
      "learning_rate": 0.0003364679391740433,
      "loss": 0.6718,
      "step": 424150
    },
    {
      "epoch": 4.490787154419043,
      "grad_norm": 1.0678783655166626,
      "learning_rate": 0.0003364245963192899,
      "loss": 0.6584,
      "step": 424200
    },
    {
      "epoch": 4.491316476199046,
      "grad_norm": 1.0410414934158325,
      "learning_rate": 0.00033638125051403255,
      "loss": 0.6495,
      "step": 424250
    },
    {
      "epoch": 4.49184579797905,
      "grad_norm": 1.145595908164978,
      "learning_rate": 0.0003363379017597509,
      "loss": 0.6578,
      "step": 424300
    },
    {
      "epoch": 4.4923751197590525,
      "grad_norm": 0.9598618149757385,
      "learning_rate": 0.000336294550057925,
      "loss": 0.6612,
      "step": 424350
    },
    {
      "epoch": 4.492904441539056,
      "grad_norm": 1.083497166633606,
      "learning_rate": 0.0003362511954100348,
      "loss": 0.6623,
      "step": 424400
    },
    {
      "epoch": 4.493433763319059,
      "grad_norm": 0.8994141817092896,
      "learning_rate": 0.00033620783781756043,
      "loss": 0.6648,
      "step": 424450
    },
    {
      "epoch": 4.493963085099063,
      "grad_norm": 1.1114745140075684,
      "learning_rate": 0.00033616447728198207,
      "loss": 0.6651,
      "step": 424500
    },
    {
      "epoch": 4.493963085099063,
      "eval_loss": 0.4468253552913666,
      "eval_runtime": 46.8959,
      "eval_samples_per_second": 3580.911,
      "eval_steps_per_second": 447.63,
      "step": 424500
    },
    {
      "epoch": 4.494492406879066,
      "grad_norm": 1.026058554649353,
      "learning_rate": 0.0003361219811031425,
      "loss": 0.6563,
      "step": 424550
    },
    {
      "epoch": 4.4950217286590695,
      "grad_norm": 1.0607024431228638,
      "learning_rate": 0.0003360786147445856,
      "loss": 0.6668,
      "step": 424600
    },
    {
      "epoch": 4.495551050439072,
      "grad_norm": 1.1400262117385864,
      "learning_rate": 0.00033603524544733644,
      "loss": 0.6554,
      "step": 424650
    },
    {
      "epoch": 4.496080372219076,
      "grad_norm": 0.9522334933280945,
      "learning_rate": 0.0003359918732128754,
      "loss": 0.6539,
      "step": 424700
    },
    {
      "epoch": 4.496609693999079,
      "grad_norm": 1.0057880878448486,
      "learning_rate": 0.00033594849804268346,
      "loss": 0.6551,
      "step": 424750
    },
    {
      "epoch": 4.497139015779082,
      "grad_norm": 1.1052764654159546,
      "learning_rate": 0.0003359051199382413,
      "loss": 0.6574,
      "step": 424800
    },
    {
      "epoch": 4.497668337559086,
      "grad_norm": 1.085654616355896,
      "learning_rate": 0.00033586173890102984,
      "loss": 0.6625,
      "step": 424850
    },
    {
      "epoch": 4.498197659339088,
      "grad_norm": 0.9544299244880676,
      "learning_rate": 0.0003358183549325301,
      "loss": 0.6484,
      "step": 424900
    },
    {
      "epoch": 4.498726981119092,
      "grad_norm": 1.0792992115020752,
      "learning_rate": 0.00033577496803422326,
      "loss": 0.6487,
      "step": 424950
    },
    {
      "epoch": 4.499256302899095,
      "grad_norm": 0.9753087162971497,
      "learning_rate": 0.0003357315782075904,
      "loss": 0.6584,
      "step": 425000
    },
    {
      "epoch": 4.499256302899095,
      "eval_loss": 0.4458346664905548,
      "eval_runtime": 46.8711,
      "eval_samples_per_second": 3582.808,
      "eval_steps_per_second": 447.867,
      "step": 425000
    },
    {
      "epoch": 4.499785624679099,
      "grad_norm": 1.0933133363723755,
      "learning_rate": 0.0003356881854541129,
      "loss": 0.6701,
      "step": 425050
    },
    {
      "epoch": 4.500314946459102,
      "grad_norm": 1.0158023834228516,
      "learning_rate": 0.00033564478977527216,
      "loss": 0.6577,
      "step": 425100
    },
    {
      "epoch": 4.500844268239105,
      "grad_norm": 1.0031390190124512,
      "learning_rate": 0.00033560139117254974,
      "loss": 0.6558,
      "step": 425150
    },
    {
      "epoch": 4.501373590019108,
      "grad_norm": 1.0350362062454224,
      "learning_rate": 0.0003355579896474272,
      "loss": 0.6612,
      "step": 425200
    },
    {
      "epoch": 4.501902911799112,
      "grad_norm": 1.0745408535003662,
      "learning_rate": 0.00033551458520138635,
      "loss": 0.6622,
      "step": 425250
    },
    {
      "epoch": 4.502432233579115,
      "grad_norm": 1.0300472974777222,
      "learning_rate": 0.00033547117783590887,
      "loss": 0.6534,
      "step": 425300
    },
    {
      "epoch": 4.502961555359119,
      "grad_norm": 0.9562287330627441,
      "learning_rate": 0.00033542776755247667,
      "loss": 0.6641,
      "step": 425350
    },
    {
      "epoch": 4.5034908771391216,
      "grad_norm": 1.052407145500183,
      "learning_rate": 0.00033538435435257185,
      "loss": 0.6523,
      "step": 425400
    },
    {
      "epoch": 4.504020198919125,
      "grad_norm": 1.1125198602676392,
      "learning_rate": 0.0003353409382376765,
      "loss": 0.6524,
      "step": 425450
    },
    {
      "epoch": 4.504549520699128,
      "grad_norm": 0.9950366616249084,
      "learning_rate": 0.00033529751920927277,
      "loss": 0.6402,
      "step": 425500
    },
    {
      "epoch": 4.504549520699128,
      "eval_loss": 0.4444918930530548,
      "eval_runtime": 47.0148,
      "eval_samples_per_second": 3571.855,
      "eval_steps_per_second": 446.498,
      "step": 425500
    },
    {
      "epoch": 4.505078842479131,
      "grad_norm": 1.1259709596633911,
      "learning_rate": 0.00033525409726884304,
      "loss": 0.6642,
      "step": 425550
    },
    {
      "epoch": 4.505608164259135,
      "grad_norm": 1.0833948850631714,
      "learning_rate": 0.0003352106724178697,
      "loss": 0.6542,
      "step": 425600
    },
    {
      "epoch": 4.5061374860391386,
      "grad_norm": 1.0429511070251465,
      "learning_rate": 0.00033516724465783526,
      "loss": 0.6551,
      "step": 425650
    },
    {
      "epoch": 4.506666807819141,
      "grad_norm": 1.1080896854400635,
      "learning_rate": 0.00033512381399022234,
      "loss": 0.6548,
      "step": 425700
    },
    {
      "epoch": 4.507196129599144,
      "grad_norm": 0.9783198833465576,
      "learning_rate": 0.00033508038041651364,
      "loss": 0.6441,
      "step": 425750
    },
    {
      "epoch": 4.507725451379148,
      "grad_norm": 0.9679468870162964,
      "learning_rate": 0.00033503694393819197,
      "loss": 0.6635,
      "step": 425800
    },
    {
      "epoch": 4.508254773159151,
      "grad_norm": 1.081791877746582,
      "learning_rate": 0.00033499350455674015,
      "loss": 0.6594,
      "step": 425850
    },
    {
      "epoch": 4.508784094939155,
      "grad_norm": 0.9721575379371643,
      "learning_rate": 0.00033495006227364125,
      "loss": 0.6686,
      "step": 425900
    },
    {
      "epoch": 4.5093134167191575,
      "grad_norm": 0.9933049082756042,
      "learning_rate": 0.00033490661709037847,
      "loss": 0.6584,
      "step": 425950
    },
    {
      "epoch": 4.509842738499161,
      "grad_norm": 0.9879077076911926,
      "learning_rate": 0.0003348631690084348,
      "loss": 0.6685,
      "step": 426000
    },
    {
      "epoch": 4.509842738499161,
      "eval_loss": 0.4464055001735687,
      "eval_runtime": 47.0067,
      "eval_samples_per_second": 3572.467,
      "eval_steps_per_second": 446.574,
      "step": 426000
    },
    {
      "epoch": 4.510372060279164,
      "grad_norm": 1.061206579208374,
      "learning_rate": 0.00033481971802929377,
      "loss": 0.6654,
      "step": 426050
    },
    {
      "epoch": 4.510901382059168,
      "grad_norm": 1.1705986261367798,
      "learning_rate": 0.0003347762641544386,
      "loss": 0.6588,
      "step": 426100
    },
    {
      "epoch": 4.511430703839171,
      "grad_norm": 1.0667599439620972,
      "learning_rate": 0.00033473280738535293,
      "loss": 0.6335,
      "step": 426150
    },
    {
      "epoch": 4.5119600256191745,
      "grad_norm": 1.1900577545166016,
      "learning_rate": 0.0003346893477235202,
      "loss": 0.6642,
      "step": 426200
    },
    {
      "epoch": 4.512489347399177,
      "grad_norm": 1.070922613143921,
      "learning_rate": 0.00033464588517042427,
      "loss": 0.6614,
      "step": 426250
    },
    {
      "epoch": 4.51301866917918,
      "grad_norm": 1.0870741605758667,
      "learning_rate": 0.0003346024197275489,
      "loss": 0.6586,
      "step": 426300
    },
    {
      "epoch": 4.513547990959184,
      "grad_norm": 1.0736321210861206,
      "learning_rate": 0.0003345589513963778,
      "loss": 0.6558,
      "step": 426350
    },
    {
      "epoch": 4.514077312739188,
      "grad_norm": 0.8775689005851746,
      "learning_rate": 0.0003345154801783952,
      "loss": 0.6645,
      "step": 426400
    },
    {
      "epoch": 4.514606634519191,
      "grad_norm": 1.0417540073394775,
      "learning_rate": 0.0003344720060750851,
      "loss": 0.6462,
      "step": 426450
    },
    {
      "epoch": 4.5151359562991935,
      "grad_norm": 1.0420781373977661,
      "learning_rate": 0.00033442852908793173,
      "loss": 0.6538,
      "step": 426500
    },
    {
      "epoch": 4.5151359562991935,
      "eval_loss": 0.44547510147094727,
      "eval_runtime": 46.8868,
      "eval_samples_per_second": 3581.604,
      "eval_steps_per_second": 447.716,
      "step": 426500
    },
    {
      "epoch": 4.515665278079197,
      "grad_norm": 1.0343542098999023,
      "learning_rate": 0.00033438591884404705,
      "loss": 0.6537,
      "step": 426550
    },
    {
      "epoch": 4.5161945998592,
      "grad_norm": 0.997080385684967,
      "learning_rate": 0.0003343424361512629,
      "loss": 0.6611,
      "step": 426600
    },
    {
      "epoch": 4.516723921639204,
      "grad_norm": 1.0649362802505493,
      "learning_rate": 0.000334298950579059,
      "loss": 0.6486,
      "step": 426650
    },
    {
      "epoch": 4.517253243419207,
      "grad_norm": 0.8675714731216431,
      "learning_rate": 0.00033425546212891976,
      "loss": 0.6602,
      "step": 426700
    },
    {
      "epoch": 4.5177825651992105,
      "grad_norm": 1.066683053970337,
      "learning_rate": 0.00033421197080233,
      "loss": 0.6752,
      "step": 426750
    },
    {
      "epoch": 4.518311886979213,
      "grad_norm": 0.9323314428329468,
      "learning_rate": 0.00033416847660077445,
      "loss": 0.6556,
      "step": 426800
    },
    {
      "epoch": 4.518841208759217,
      "grad_norm": 1.0998165607452393,
      "learning_rate": 0.00033412497952573796,
      "loss": 0.655,
      "step": 426850
    },
    {
      "epoch": 4.51937053053922,
      "grad_norm": 1.091356635093689,
      "learning_rate": 0.0003340814795787055,
      "loss": 0.6568,
      "step": 426900
    },
    {
      "epoch": 4.519899852319224,
      "grad_norm": 1.108274221420288,
      "learning_rate": 0.0003340379767611621,
      "loss": 0.6576,
      "step": 426950
    },
    {
      "epoch": 4.520429174099227,
      "grad_norm": 1.0020960569381714,
      "learning_rate": 0.00033399447107459307,
      "loss": 0.6557,
      "step": 427000
    },
    {
      "epoch": 4.520429174099227,
      "eval_loss": 0.4469742178916931,
      "eval_runtime": 46.8632,
      "eval_samples_per_second": 3583.408,
      "eval_steps_per_second": 447.942,
      "step": 427000
    },
    {
      "epoch": 4.5209584958792295,
      "grad_norm": 1.0678629875183105,
      "learning_rate": 0.0003339509625204836,
      "loss": 0.6535,
      "step": 427050
    },
    {
      "epoch": 4.521487817659233,
      "grad_norm": 1.0535507202148438,
      "learning_rate": 0.0003339074511003191,
      "loss": 0.664,
      "step": 427100
    },
    {
      "epoch": 4.522017139439237,
      "grad_norm": 1.01459801197052,
      "learning_rate": 0.0003338639368155849,
      "loss": 0.6663,
      "step": 427150
    },
    {
      "epoch": 4.52254646121924,
      "grad_norm": 1.1098943948745728,
      "learning_rate": 0.00033382041966776666,
      "loss": 0.6518,
      "step": 427200
    },
    {
      "epoch": 4.523075782999243,
      "grad_norm": 0.9832800626754761,
      "learning_rate": 0.00033377689965835013,
      "loss": 0.6568,
      "step": 427250
    },
    {
      "epoch": 4.5236051047792465,
      "grad_norm": 1.125978946685791,
      "learning_rate": 0.00033373337678882086,
      "loss": 0.6508,
      "step": 427300
    },
    {
      "epoch": 4.524134426559249,
      "grad_norm": 1.0392495393753052,
      "learning_rate": 0.00033368985106066484,
      "loss": 0.663,
      "step": 427350
    },
    {
      "epoch": 4.524663748339253,
      "grad_norm": 1.042435646057129,
      "learning_rate": 0.0003336463224753681,
      "loss": 0.6556,
      "step": 427400
    },
    {
      "epoch": 4.525193070119256,
      "grad_norm": 1.1624860763549805,
      "learning_rate": 0.00033360279103441647,
      "loss": 0.6552,
      "step": 427450
    },
    {
      "epoch": 4.52572239189926,
      "grad_norm": 1.0390260219573975,
      "learning_rate": 0.0003335592567392962,
      "loss": 0.6652,
      "step": 427500
    },
    {
      "epoch": 4.52572239189926,
      "eval_loss": 0.4452258348464966,
      "eval_runtime": 46.739,
      "eval_samples_per_second": 3592.929,
      "eval_steps_per_second": 449.132,
      "step": 427500
    },
    {
      "epoch": 4.526251713679263,
      "grad_norm": 1.0458625555038452,
      "learning_rate": 0.00033351571959149365,
      "loss": 0.6583,
      "step": 427550
    },
    {
      "epoch": 4.526781035459266,
      "grad_norm": 1.0691040754318237,
      "learning_rate": 0.000333472179592495,
      "loss": 0.661,
      "step": 427600
    },
    {
      "epoch": 4.527310357239269,
      "grad_norm": 0.9524456858634949,
      "learning_rate": 0.00033342863674378675,
      "loss": 0.6444,
      "step": 427650
    },
    {
      "epoch": 4.527839679019273,
      "grad_norm": 1.0353926420211792,
      "learning_rate": 0.0003333850910468555,
      "loss": 0.6618,
      "step": 427700
    },
    {
      "epoch": 4.528369000799276,
      "grad_norm": 1.1353075504302979,
      "learning_rate": 0.00033334154250318774,
      "loss": 0.6581,
      "step": 427750
    },
    {
      "epoch": 4.528898322579279,
      "grad_norm": 0.9886618852615356,
      "learning_rate": 0.0003332979911142703,
      "loss": 0.6477,
      "step": 427800
    },
    {
      "epoch": 4.5294276443592825,
      "grad_norm": 1.035269856452942,
      "learning_rate": 0.00033325443688159,
      "loss": 0.6543,
      "step": 427850
    },
    {
      "epoch": 4.529956966139286,
      "grad_norm": 1.03883695602417,
      "learning_rate": 0.00033321087980663376,
      "loss": 0.6566,
      "step": 427900
    },
    {
      "epoch": 4.530486287919289,
      "grad_norm": 1.0229711532592773,
      "learning_rate": 0.0003331673198908886,
      "loss": 0.6454,
      "step": 427950
    },
    {
      "epoch": 4.531015609699292,
      "grad_norm": 0.8832036256790161,
      "learning_rate": 0.00033312375713584165,
      "loss": 0.6581,
      "step": 428000
    },
    {
      "epoch": 4.531015609699292,
      "eval_loss": 0.4444405734539032,
      "eval_runtime": 46.7406,
      "eval_samples_per_second": 3592.808,
      "eval_steps_per_second": 449.117,
      "step": 428000
    },
    {
      "epoch": 4.531544931479296,
      "grad_norm": 1.0524972677230835,
      "learning_rate": 0.00033308019154298013,
      "loss": 0.6641,
      "step": 428050
    },
    {
      "epoch": 4.532074253259299,
      "grad_norm": 1.0775340795516968,
      "learning_rate": 0.00033303662311379135,
      "loss": 0.6588,
      "step": 428100
    },
    {
      "epoch": 4.532603575039302,
      "grad_norm": 1.0791329145431519,
      "learning_rate": 0.00033299305184976267,
      "loss": 0.64,
      "step": 428150
    },
    {
      "epoch": 4.533132896819305,
      "grad_norm": 1.0592395067214966,
      "learning_rate": 0.0003329494777523817,
      "loss": 0.6652,
      "step": 428200
    },
    {
      "epoch": 4.533662218599309,
      "grad_norm": 1.0256351232528687,
      "learning_rate": 0.00033290590082313585,
      "loss": 0.6491,
      "step": 428250
    },
    {
      "epoch": 4.534191540379312,
      "grad_norm": 1.094962239265442,
      "learning_rate": 0.00033286232106351303,
      "loss": 0.6525,
      "step": 428300
    },
    {
      "epoch": 4.534720862159316,
      "grad_norm": 1.0402066707611084,
      "learning_rate": 0.000332818738475001,
      "loss": 0.6681,
      "step": 428350
    },
    {
      "epoch": 4.5352501839393184,
      "grad_norm": 1.1581963300704956,
      "learning_rate": 0.0003327751530590876,
      "loss": 0.6603,
      "step": 428400
    },
    {
      "epoch": 4.535779505719322,
      "grad_norm": 1.0423344373703003,
      "learning_rate": 0.00033273156481726073,
      "loss": 0.6633,
      "step": 428450
    },
    {
      "epoch": 4.536308827499325,
      "grad_norm": 0.9609301686286926,
      "learning_rate": 0.00033268797375100867,
      "loss": 0.6558,
      "step": 428500
    },
    {
      "epoch": 4.536308827499325,
      "eval_loss": 0.44602540135383606,
      "eval_runtime": 46.8545,
      "eval_samples_per_second": 3584.075,
      "eval_steps_per_second": 448.025,
      "step": 428500
    },
    {
      "epoch": 4.536838149279328,
      "grad_norm": 1.0671586990356445,
      "learning_rate": 0.0003326452517672585,
      "loss": 0.6551,
      "step": 428550
    },
    {
      "epoch": 4.537367471059332,
      "grad_norm": 1.0241715908050537,
      "learning_rate": 0.00033260165511303486,
      "loss": 0.6519,
      "step": 428600
    },
    {
      "epoch": 4.5378967928393354,
      "grad_norm": 1.022895097732544,
      "learning_rate": 0.000332558055638821,
      "loss": 0.6647,
      "step": 428650
    },
    {
      "epoch": 4.538426114619338,
      "grad_norm": 0.9841356873512268,
      "learning_rate": 0.0003325144533461054,
      "loss": 0.6546,
      "step": 428700
    },
    {
      "epoch": 4.538955436399341,
      "grad_norm": 1.0434842109680176,
      "learning_rate": 0.0003324708482363767,
      "loss": 0.6588,
      "step": 428750
    },
    {
      "epoch": 4.539484758179345,
      "grad_norm": 1.0388743877410889,
      "learning_rate": 0.0003324272403111235,
      "loss": 0.6647,
      "step": 428800
    },
    {
      "epoch": 4.540014079959348,
      "grad_norm": 1.0802425146102905,
      "learning_rate": 0.00033238362957183445,
      "loss": 0.6546,
      "step": 428850
    },
    {
      "epoch": 4.540543401739352,
      "grad_norm": 1.034533977508545,
      "learning_rate": 0.0003323400160199985,
      "loss": 0.6598,
      "step": 428900
    },
    {
      "epoch": 4.541072723519354,
      "grad_norm": 1.0912790298461914,
      "learning_rate": 0.00033229639965710466,
      "loss": 0.6549,
      "step": 428950
    },
    {
      "epoch": 4.541602045299358,
      "grad_norm": 1.0089062452316284,
      "learning_rate": 0.0003322527804846419,
      "loss": 0.659,
      "step": 429000
    },
    {
      "epoch": 4.541602045299358,
      "eval_loss": 0.44477400183677673,
      "eval_runtime": 46.8843,
      "eval_samples_per_second": 3581.793,
      "eval_steps_per_second": 447.74,
      "step": 429000
    },
    {
      "epoch": 4.542131367079361,
      "grad_norm": 1.1363658905029297,
      "learning_rate": 0.00033220915850409936,
      "loss": 0.6501,
      "step": 429050
    },
    {
      "epoch": 4.542660688859365,
      "grad_norm": 0.9918458461761475,
      "learning_rate": 0.00033216553371696634,
      "loss": 0.6588,
      "step": 429100
    },
    {
      "epoch": 4.543190010639368,
      "grad_norm": 0.975761890411377,
      "learning_rate": 0.0003321219061247321,
      "loss": 0.6674,
      "step": 429150
    },
    {
      "epoch": 4.543719332419371,
      "grad_norm": 1.1166483163833618,
      "learning_rate": 0.0003320782757288861,
      "loss": 0.6563,
      "step": 429200
    },
    {
      "epoch": 4.544248654199374,
      "grad_norm": 0.980016827583313,
      "learning_rate": 0.0003320346425309179,
      "loss": 0.6607,
      "step": 429250
    },
    {
      "epoch": 4.544777975979377,
      "grad_norm": 0.9099985361099243,
      "learning_rate": 0.00033199100653231707,
      "loss": 0.6386,
      "step": 429300
    },
    {
      "epoch": 4.545307297759381,
      "grad_norm": 0.966274619102478,
      "learning_rate": 0.00033194736773457334,
      "loss": 0.6627,
      "step": 429350
    },
    {
      "epoch": 4.545836619539385,
      "grad_norm": 0.9589616656303406,
      "learning_rate": 0.0003319037261391765,
      "loss": 0.6552,
      "step": 429400
    },
    {
      "epoch": 4.5463659413193875,
      "grad_norm": 0.9532379508018494,
      "learning_rate": 0.00033186008174761655,
      "loss": 0.651,
      "step": 429450
    },
    {
      "epoch": 4.54689526309939,
      "grad_norm": 1.0166665315628052,
      "learning_rate": 0.00033181643456138343,
      "loss": 0.6525,
      "step": 429500
    },
    {
      "epoch": 4.54689526309939,
      "eval_loss": 0.4453972578048706,
      "eval_runtime": 46.8601,
      "eval_samples_per_second": 3583.645,
      "eval_steps_per_second": 447.972,
      "step": 429500
    },
    {
      "epoch": 4.547424584879394,
      "grad_norm": 1.0518065690994263,
      "learning_rate": 0.0003317727845819672,
      "loss": 0.6554,
      "step": 429550
    },
    {
      "epoch": 4.547953906659397,
      "grad_norm": 1.1850625276565552,
      "learning_rate": 0.00033172913181085813,
      "loss": 0.6538,
      "step": 429600
    },
    {
      "epoch": 4.548483228439401,
      "grad_norm": 1.0055899620056152,
      "learning_rate": 0.00033168547624954644,
      "loss": 0.6597,
      "step": 429650
    },
    {
      "epoch": 4.549012550219404,
      "grad_norm": 0.9736127257347107,
      "learning_rate": 0.0003316418178995225,
      "loss": 0.6515,
      "step": 429700
    },
    {
      "epoch": 4.549541871999407,
      "grad_norm": 1.043530821800232,
      "learning_rate": 0.00033159815676227694,
      "loss": 0.6634,
      "step": 429750
    },
    {
      "epoch": 4.55007119377941,
      "grad_norm": 1.100524663925171,
      "learning_rate": 0.00033155449283930015,
      "loss": 0.6623,
      "step": 429800
    },
    {
      "epoch": 4.550600515559414,
      "grad_norm": 1.09129798412323,
      "learning_rate": 0.00033151082613208297,
      "loss": 0.657,
      "step": 429850
    },
    {
      "epoch": 4.551129837339417,
      "grad_norm": 1.0224608182907104,
      "learning_rate": 0.00033146715664211595,
      "loss": 0.655,
      "step": 429900
    },
    {
      "epoch": 4.551659159119421,
      "grad_norm": 1.1070823669433594,
      "learning_rate": 0.0003314234843708902,
      "loss": 0.6541,
      "step": 429950
    },
    {
      "epoch": 4.5521884808994235,
      "grad_norm": 1.1158632040023804,
      "learning_rate": 0.00033137980931989655,
      "loss": 0.6618,
      "step": 430000
    },
    {
      "epoch": 4.5521884808994235,
      "eval_loss": 0.44126248359680176,
      "eval_runtime": 46.837,
      "eval_samples_per_second": 3585.412,
      "eval_steps_per_second": 448.193,
      "step": 430000
    },
    {
      "epoch": 4.552717802679426,
      "grad_norm": 0.9436288475990295,
      "learning_rate": 0.00033133613149062595,
      "loss": 0.6604,
      "step": 430050
    },
    {
      "epoch": 4.55324712445943,
      "grad_norm": 1.0834656953811646,
      "learning_rate": 0.0003312924508845697,
      "loss": 0.6529,
      "step": 430100
    },
    {
      "epoch": 4.553776446239434,
      "grad_norm": 1.0504357814788818,
      "learning_rate": 0.0003312487675032191,
      "loss": 0.648,
      "step": 430150
    },
    {
      "epoch": 4.554305768019437,
      "grad_norm": 1.1023434400558472,
      "learning_rate": 0.00033120508134806527,
      "loss": 0.6487,
      "step": 430200
    },
    {
      "epoch": 4.55483508979944,
      "grad_norm": 1.0274773836135864,
      "learning_rate": 0.0003311613924205997,
      "loss": 0.6493,
      "step": 430250
    },
    {
      "epoch": 4.555364411579443,
      "grad_norm": 1.0809556245803833,
      "learning_rate": 0.00033111770072231407,
      "loss": 0.6548,
      "step": 430300
    },
    {
      "epoch": 4.555893733359446,
      "grad_norm": 1.1104766130447388,
      "learning_rate": 0.0003310740062546999,
      "loss": 0.6582,
      "step": 430350
    },
    {
      "epoch": 4.55642305513945,
      "grad_norm": 1.1143226623535156,
      "learning_rate": 0.00033103030901924873,
      "loss": 0.6496,
      "step": 430400
    },
    {
      "epoch": 4.556952376919453,
      "grad_norm": 1.0695204734802246,
      "learning_rate": 0.00033098660901745264,
      "loss": 0.6523,
      "step": 430450
    },
    {
      "epoch": 4.557481698699457,
      "grad_norm": 1.0391966104507446,
      "learning_rate": 0.00033094290625080344,
      "loss": 0.6632,
      "step": 430500
    },
    {
      "epoch": 4.557481698699457,
      "eval_loss": 0.4450857937335968,
      "eval_runtime": 46.7561,
      "eval_samples_per_second": 3591.618,
      "eval_steps_per_second": 448.968,
      "step": 430500
    },
    {
      "epoch": 4.5580110204794595,
      "grad_norm": 1.0610032081604004,
      "learning_rate": 0.00033089920072079307,
      "loss": 0.6645,
      "step": 430550
    },
    {
      "epoch": 4.558540342259463,
      "grad_norm": 1.1167309284210205,
      "learning_rate": 0.00033085636662180787,
      "loss": 0.6575,
      "step": 430600
    },
    {
      "epoch": 4.559069664039466,
      "grad_norm": 1.0169686079025269,
      "learning_rate": 0.0003308126556247445,
      "loss": 0.6646,
      "step": 430650
    },
    {
      "epoch": 4.55959898581947,
      "grad_norm": 1.061612844467163,
      "learning_rate": 0.00033076894186876674,
      "loss": 0.6588,
      "step": 430700
    },
    {
      "epoch": 4.560128307599473,
      "grad_norm": 1.1151819229125977,
      "learning_rate": 0.0003307252253553669,
      "loss": 0.6434,
      "step": 430750
    },
    {
      "epoch": 4.560657629379476,
      "grad_norm": 1.032182216644287,
      "learning_rate": 0.00033068150608603743,
      "loss": 0.6442,
      "step": 430800
    },
    {
      "epoch": 4.561186951159479,
      "grad_norm": 1.0902249813079834,
      "learning_rate": 0.00033063778406227095,
      "loss": 0.6643,
      "step": 430850
    },
    {
      "epoch": 4.561716272939483,
      "grad_norm": 1.1641056537628174,
      "learning_rate": 0.00033059405928556016,
      "loss": 0.6541,
      "step": 430900
    },
    {
      "epoch": 4.562245594719486,
      "grad_norm": 1.0553600788116455,
      "learning_rate": 0.0003305503317573977,
      "loss": 0.6605,
      "step": 430950
    },
    {
      "epoch": 4.562774916499489,
      "grad_norm": 0.9164713025093079,
      "learning_rate": 0.00033050660147927643,
      "loss": 0.646,
      "step": 431000
    },
    {
      "epoch": 4.562774916499489,
      "eval_loss": 0.4432390332221985,
      "eval_runtime": 46.9121,
      "eval_samples_per_second": 3579.673,
      "eval_steps_per_second": 447.475,
      "step": 431000
    },
    {
      "epoch": 4.563304238279493,
      "grad_norm": 0.9993100762367249,
      "learning_rate": 0.0003304628684526893,
      "loss": 0.6508,
      "step": 431050
    },
    {
      "epoch": 4.5638335600594955,
      "grad_norm": 1.0859980583190918,
      "learning_rate": 0.0003304191326791294,
      "loss": 0.6427,
      "step": 431100
    },
    {
      "epoch": 4.564362881839499,
      "grad_norm": 1.072418212890625,
      "learning_rate": 0.00033037539416008976,
      "loss": 0.6684,
      "step": 431150
    },
    {
      "epoch": 4.564892203619502,
      "grad_norm": 1.003196120262146,
      "learning_rate": 0.0003303316528970636,
      "loss": 0.6693,
      "step": 431200
    },
    {
      "epoch": 4.565421525399506,
      "grad_norm": 1.026116967201233,
      "learning_rate": 0.00033028790889154435,
      "loss": 0.6543,
      "step": 431250
    },
    {
      "epoch": 4.565950847179509,
      "grad_norm": 1.0929782390594482,
      "learning_rate": 0.0003302441621450253,
      "loss": 0.6519,
      "step": 431300
    },
    {
      "epoch": 4.5664801689595125,
      "grad_norm": 1.0246105194091797,
      "learning_rate": 0.00033020041265900007,
      "loss": 0.6494,
      "step": 431350
    },
    {
      "epoch": 4.567009490739515,
      "grad_norm": 1.0751266479492188,
      "learning_rate": 0.00033015666043496205,
      "loss": 0.6558,
      "step": 431400
    },
    {
      "epoch": 4.567538812519519,
      "grad_norm": 0.981438934803009,
      "learning_rate": 0.00033011290547440517,
      "loss": 0.6577,
      "step": 431450
    },
    {
      "epoch": 4.568068134299522,
      "grad_norm": 1.0557146072387695,
      "learning_rate": 0.000330069147778823,
      "loss": 0.6555,
      "step": 431500
    },
    {
      "epoch": 4.568068134299522,
      "eval_loss": 0.4454136788845062,
      "eval_runtime": 46.9006,
      "eval_samples_per_second": 3580.553,
      "eval_steps_per_second": 447.585,
      "step": 431500
    },
    {
      "epoch": 4.568597456079525,
      "grad_norm": 1.046186089515686,
      "learning_rate": 0.00033002538734970945,
      "loss": 0.6615,
      "step": 431550
    },
    {
      "epoch": 4.569126777859529,
      "grad_norm": 0.9480701684951782,
      "learning_rate": 0.00032998162418855856,
      "loss": 0.6495,
      "step": 431600
    },
    {
      "epoch": 4.569656099639532,
      "grad_norm": 1.035019874572754,
      "learning_rate": 0.00032993785829686434,
      "loss": 0.6519,
      "step": 431650
    },
    {
      "epoch": 4.570185421419535,
      "grad_norm": 1.026880145072937,
      "learning_rate": 0.000329894089676121,
      "loss": 0.6559,
      "step": 431700
    },
    {
      "epoch": 4.570714743199538,
      "grad_norm": 1.0466296672821045,
      "learning_rate": 0.0003298503183278227,
      "loss": 0.6567,
      "step": 431750
    },
    {
      "epoch": 4.571244064979542,
      "grad_norm": 1.0338984727859497,
      "learning_rate": 0.0003298065442534638,
      "loss": 0.6482,
      "step": 431800
    },
    {
      "epoch": 4.571773386759545,
      "grad_norm": 1.097367763519287,
      "learning_rate": 0.0003297627674545388,
      "loss": 0.6532,
      "step": 431850
    },
    {
      "epoch": 4.5723027085395485,
      "grad_norm": 0.9331444501876831,
      "learning_rate": 0.0003297189879325421,
      "loss": 0.6502,
      "step": 431900
    },
    {
      "epoch": 4.572832030319551,
      "grad_norm": 1.019391417503357,
      "learning_rate": 0.00032967520568896844,
      "loss": 0.6431,
      "step": 431950
    },
    {
      "epoch": 4.573361352099555,
      "grad_norm": 0.9653099775314331,
      "learning_rate": 0.00032963142072531243,
      "loss": 0.6513,
      "step": 432000
    },
    {
      "epoch": 4.573361352099555,
      "eval_loss": 0.4412277340888977,
      "eval_runtime": 46.8183,
      "eval_samples_per_second": 3586.842,
      "eval_steps_per_second": 448.371,
      "step": 432000
    },
    {
      "epoch": 4.573890673879558,
      "grad_norm": 1.0460193157196045,
      "learning_rate": 0.0003295876330430689,
      "loss": 0.6477,
      "step": 432050
    },
    {
      "epoch": 4.574419995659562,
      "grad_norm": 1.01580810546875,
      "learning_rate": 0.0003295438426437329,
      "loss": 0.6561,
      "step": 432100
    },
    {
      "epoch": 4.574949317439565,
      "grad_norm": 1.1619527339935303,
      "learning_rate": 0.0003295000495287992,
      "loss": 0.6615,
      "step": 432150
    },
    {
      "epoch": 4.575478639219568,
      "grad_norm": 0.9011754393577576,
      "learning_rate": 0.00032945625369976296,
      "loss": 0.639,
      "step": 432200
    },
    {
      "epoch": 4.576007960999571,
      "grad_norm": 1.1698830127716064,
      "learning_rate": 0.0003294124551581194,
      "loss": 0.6528,
      "step": 432250
    },
    {
      "epoch": 4.576537282779574,
      "grad_norm": 1.2152963876724243,
      "learning_rate": 0.0003293686539053637,
      "loss": 0.6511,
      "step": 432300
    },
    {
      "epoch": 4.577066604559578,
      "grad_norm": 0.9344123005867004,
      "learning_rate": 0.0003293248499429913,
      "loss": 0.6541,
      "step": 432350
    },
    {
      "epoch": 4.577595926339582,
      "grad_norm": 1.0668498277664185,
      "learning_rate": 0.0003292810432724975,
      "loss": 0.6603,
      "step": 432400
    },
    {
      "epoch": 4.578125248119584,
      "grad_norm": 1.0723762512207031,
      "learning_rate": 0.00032923723389537813,
      "loss": 0.6577,
      "step": 432450
    },
    {
      "epoch": 4.578654569899587,
      "grad_norm": 1.0204745531082153,
      "learning_rate": 0.00032919342181312857,
      "loss": 0.6539,
      "step": 432500
    },
    {
      "epoch": 4.578654569899587,
      "eval_loss": 0.4430777132511139,
      "eval_runtime": 46.9631,
      "eval_samples_per_second": 3575.785,
      "eval_steps_per_second": 446.989,
      "step": 432500
    },
    {
      "epoch": 4.579183891679591,
      "grad_norm": 0.9695695638656616,
      "learning_rate": 0.0003291496070272446,
      "loss": 0.6561,
      "step": 432550
    },
    {
      "epoch": 4.579713213459594,
      "grad_norm": 1.0352188348770142,
      "learning_rate": 0.00032910578953922214,
      "loss": 0.6621,
      "step": 432600
    },
    {
      "epoch": 4.580242535239598,
      "grad_norm": 1.098105549812317,
      "learning_rate": 0.00032906284578078685,
      "loss": 0.6635,
      "step": 432650
    },
    {
      "epoch": 4.5807718570196005,
      "grad_norm": 0.9774965643882751,
      "learning_rate": 0.00032901902294694334,
      "loss": 0.6416,
      "step": 432700
    },
    {
      "epoch": 4.581301178799604,
      "grad_norm": 1.0342035293579102,
      "learning_rate": 0.0003289751974154194,
      "loss": 0.658,
      "step": 432750
    },
    {
      "epoch": 4.581830500579607,
      "grad_norm": 0.982332170009613,
      "learning_rate": 0.00032893136918771114,
      "loss": 0.6606,
      "step": 432800
    },
    {
      "epoch": 4.582359822359611,
      "grad_norm": 0.9845858812332153,
      "learning_rate": 0.0003288875382653149,
      "loss": 0.6459,
      "step": 432850
    },
    {
      "epoch": 4.582889144139614,
      "grad_norm": 1.0917882919311523,
      "learning_rate": 0.00032884370464972707,
      "loss": 0.6515,
      "step": 432900
    },
    {
      "epoch": 4.5834184659196175,
      "grad_norm": 1.137312412261963,
      "learning_rate": 0.000328799868342444,
      "loss": 0.6504,
      "step": 432950
    },
    {
      "epoch": 4.58394778769962,
      "grad_norm": 1.1507058143615723,
      "learning_rate": 0.0003287560293449624,
      "loss": 0.6484,
      "step": 433000
    },
    {
      "epoch": 4.58394778769962,
      "eval_loss": 0.4423975348472595,
      "eval_runtime": 46.8603,
      "eval_samples_per_second": 3583.632,
      "eval_steps_per_second": 447.97,
      "step": 433000
    },
    {
      "epoch": 4.584477109479623,
      "grad_norm": 1.0324819087982178,
      "learning_rate": 0.00032871218765877886,
      "loss": 0.6475,
      "step": 433050
    },
    {
      "epoch": 4.585006431259627,
      "grad_norm": 0.9749863147735596,
      "learning_rate": 0.00032866834328539003,
      "loss": 0.6691,
      "step": 433100
    },
    {
      "epoch": 4.585535753039631,
      "grad_norm": 1.1000910997390747,
      "learning_rate": 0.0003286244962262928,
      "loss": 0.646,
      "step": 433150
    },
    {
      "epoch": 4.586065074819634,
      "grad_norm": 1.1612763404846191,
      "learning_rate": 0.00032858064648298414,
      "loss": 0.6567,
      "step": 433200
    },
    {
      "epoch": 4.5865943965996365,
      "grad_norm": 1.0300347805023193,
      "learning_rate": 0.000328536794056961,
      "loss": 0.6566,
      "step": 433250
    },
    {
      "epoch": 4.58712371837964,
      "grad_norm": 1.0296564102172852,
      "learning_rate": 0.00032849293894972054,
      "loss": 0.6394,
      "step": 433300
    },
    {
      "epoch": 4.587653040159643,
      "grad_norm": 1.0281531810760498,
      "learning_rate": 0.00032844908116275997,
      "loss": 0.6637,
      "step": 433350
    },
    {
      "epoch": 4.588182361939647,
      "grad_norm": 0.9888977408409119,
      "learning_rate": 0.00032840522069757646,
      "loss": 0.6517,
      "step": 433400
    },
    {
      "epoch": 4.58871168371965,
      "grad_norm": 1.0021229982376099,
      "learning_rate": 0.00032836135755566747,
      "loss": 0.6487,
      "step": 433450
    },
    {
      "epoch": 4.5892410054996535,
      "grad_norm": 1.0637595653533936,
      "learning_rate": 0.00032831749173853054,
      "loss": 0.6553,
      "step": 433500
    },
    {
      "epoch": 4.5892410054996535,
      "eval_loss": 0.4412025809288025,
      "eval_runtime": 46.9117,
      "eval_samples_per_second": 3579.707,
      "eval_steps_per_second": 447.479,
      "step": 433500
    },
    {
      "epoch": 4.589770327279656,
      "grad_norm": 1.0452916622161865,
      "learning_rate": 0.00032827362324766313,
      "loss": 0.6471,
      "step": 433550
    },
    {
      "epoch": 4.59029964905966,
      "grad_norm": 1.0344372987747192,
      "learning_rate": 0.00032822975208456295,
      "loss": 0.6655,
      "step": 433600
    },
    {
      "epoch": 4.590828970839663,
      "grad_norm": 1.1803793907165527,
      "learning_rate": 0.0003281858782507277,
      "loss": 0.6478,
      "step": 433650
    },
    {
      "epoch": 4.591358292619667,
      "grad_norm": 1.0119398832321167,
      "learning_rate": 0.00032814200174765526,
      "loss": 0.6555,
      "step": 433700
    },
    {
      "epoch": 4.59188761439967,
      "grad_norm": 0.919442355632782,
      "learning_rate": 0.0003280981225768435,
      "loss": 0.6633,
      "step": 433750
    },
    {
      "epoch": 4.5924169361796725,
      "grad_norm": 0.9619424939155579,
      "learning_rate": 0.0003280542407397905,
      "loss": 0.6569,
      "step": 433800
    },
    {
      "epoch": 4.592946257959676,
      "grad_norm": 1.043949842453003,
      "learning_rate": 0.00032801035623799434,
      "loss": 0.6552,
      "step": 433850
    },
    {
      "epoch": 4.59347557973968,
      "grad_norm": 1.0225346088409424,
      "learning_rate": 0.00032796646907295323,
      "loss": 0.6572,
      "step": 433900
    },
    {
      "epoch": 4.594004901519683,
      "grad_norm": 1.042332410812378,
      "learning_rate": 0.0003279225792461655,
      "loss": 0.6576,
      "step": 433950
    },
    {
      "epoch": 4.594534223299686,
      "grad_norm": 0.9975228905677795,
      "learning_rate": 0.00032787868675912947,
      "loss": 0.6408,
      "step": 434000
    },
    {
      "epoch": 4.594534223299686,
      "eval_loss": 0.44052818417549133,
      "eval_runtime": 46.9244,
      "eval_samples_per_second": 3578.738,
      "eval_steps_per_second": 447.358,
      "step": 434000
    },
    {
      "epoch": 4.5950635450796895,
      "grad_norm": 1.1470069885253906,
      "learning_rate": 0.0003278347916133436,
      "loss": 0.6535,
      "step": 434050
    },
    {
      "epoch": 4.595592866859692,
      "grad_norm": 1.0463496446609497,
      "learning_rate": 0.0003277908938103065,
      "loss": 0.6478,
      "step": 434100
    },
    {
      "epoch": 4.596122188639696,
      "grad_norm": 1.0070757865905762,
      "learning_rate": 0.0003277469933515167,
      "loss": 0.6523,
      "step": 434150
    },
    {
      "epoch": 4.596651510419699,
      "grad_norm": 1.0681406259536743,
      "learning_rate": 0.0003277030902384732,
      "loss": 0.6479,
      "step": 434200
    },
    {
      "epoch": 4.597180832199703,
      "grad_norm": 1.090804100036621,
      "learning_rate": 0.0003276591844726747,
      "loss": 0.6572,
      "step": 434250
    },
    {
      "epoch": 4.597710153979706,
      "grad_norm": 1.045633316040039,
      "learning_rate": 0.00032761527605562016,
      "loss": 0.6426,
      "step": 434300
    },
    {
      "epoch": 4.598239475759709,
      "grad_norm": 1.1151517629623413,
      "learning_rate": 0.00032757136498880846,
      "loss": 0.6418,
      "step": 434350
    },
    {
      "epoch": 4.598768797539712,
      "grad_norm": 0.9704936742782593,
      "learning_rate": 0.0003275274512737389,
      "loss": 0.6596,
      "step": 434400
    },
    {
      "epoch": 4.599298119319716,
      "grad_norm": 1.073359727859497,
      "learning_rate": 0.0003274835349119105,
      "loss": 0.66,
      "step": 434450
    },
    {
      "epoch": 4.599827441099719,
      "grad_norm": 1.0382343530654907,
      "learning_rate": 0.0003274396159048227,
      "loss": 0.6447,
      "step": 434500
    },
    {
      "epoch": 4.599827441099719,
      "eval_loss": 0.4410954713821411,
      "eval_runtime": 46.9177,
      "eval_samples_per_second": 3579.247,
      "eval_steps_per_second": 447.422,
      "step": 434500
    },
    {
      "epoch": 4.600356762879722,
      "grad_norm": 1.0807121992111206,
      "learning_rate": 0.00032739569425397475,
      "loss": 0.6559,
      "step": 434550
    },
    {
      "epoch": 4.6008860846597255,
      "grad_norm": 1.0142256021499634,
      "learning_rate": 0.00032735176996086625,
      "loss": 0.6561,
      "step": 434600
    },
    {
      "epoch": 4.601415406439729,
      "grad_norm": 1.0729832649230957,
      "learning_rate": 0.0003273087215915438,
      "loss": 0.653,
      "step": 434650
    },
    {
      "epoch": 4.601944728219732,
      "grad_norm": 0.9891840815544128,
      "learning_rate": 0.0003272647920711833,
      "loss": 0.6471,
      "step": 434700
    },
    {
      "epoch": 4.602474049999735,
      "grad_norm": 1.0064520835876465,
      "learning_rate": 0.00032722085991303116,
      "loss": 0.6519,
      "step": 434750
    },
    {
      "epoch": 4.603003371779739,
      "grad_norm": 0.9829464554786682,
      "learning_rate": 0.0003271769251185872,
      "loss": 0.6476,
      "step": 434800
    },
    {
      "epoch": 4.603532693559742,
      "grad_norm": 1.0814833641052246,
      "learning_rate": 0.0003271329876893513,
      "loss": 0.6503,
      "step": 434850
    },
    {
      "epoch": 4.604062015339745,
      "grad_norm": 0.9211350679397583,
      "learning_rate": 0.0003270890476268235,
      "loss": 0.6471,
      "step": 434900
    },
    {
      "epoch": 4.604591337119748,
      "grad_norm": 1.0727862119674683,
      "learning_rate": 0.0003270451049325039,
      "loss": 0.6512,
      "step": 434950
    },
    {
      "epoch": 4.605120658899752,
      "grad_norm": 1.076772928237915,
      "learning_rate": 0.00032700115960789265,
      "loss": 0.6375,
      "step": 435000
    },
    {
      "epoch": 4.605120658899752,
      "eval_loss": 0.4381951689720154,
      "eval_runtime": 46.9447,
      "eval_samples_per_second": 3577.188,
      "eval_steps_per_second": 447.164,
      "step": 435000
    },
    {
      "epoch": 4.605649980679755,
      "grad_norm": 1.0211368799209595,
      "learning_rate": 0.00032695721165449006,
      "loss": 0.6563,
      "step": 435050
    },
    {
      "epoch": 4.606179302459759,
      "grad_norm": 1.0373687744140625,
      "learning_rate": 0.0003269132610737965,
      "loss": 0.6392,
      "step": 435100
    },
    {
      "epoch": 4.6067086242397615,
      "grad_norm": 0.9995017647743225,
      "learning_rate": 0.0003268693078673124,
      "loss": 0.6625,
      "step": 435150
    },
    {
      "epoch": 4.607237946019765,
      "grad_norm": 1.0719289779663086,
      "learning_rate": 0.0003268253520365383,
      "loss": 0.649,
      "step": 435200
    },
    {
      "epoch": 4.607767267799768,
      "grad_norm": 1.0109351873397827,
      "learning_rate": 0.00032678139358297486,
      "loss": 0.6536,
      "step": 435250
    },
    {
      "epoch": 4.608296589579771,
      "grad_norm": 0.9894909262657166,
      "learning_rate": 0.0003267374325081228,
      "loss": 0.656,
      "step": 435300
    },
    {
      "epoch": 4.608825911359775,
      "grad_norm": 1.0810056924819946,
      "learning_rate": 0.000326693468813483,
      "loss": 0.6477,
      "step": 435350
    },
    {
      "epoch": 4.6093552331397785,
      "grad_norm": 1.111032485961914,
      "learning_rate": 0.0003266495025005562,
      "loss": 0.6452,
      "step": 435400
    },
    {
      "epoch": 4.609884554919781,
      "grad_norm": 1.0329558849334717,
      "learning_rate": 0.00032660553357084354,
      "loss": 0.6554,
      "step": 435450
    },
    {
      "epoch": 4.610413876699784,
      "grad_norm": 1.0094927549362183,
      "learning_rate": 0.00032656156202584606,
      "loss": 0.6386,
      "step": 435500
    },
    {
      "epoch": 4.610413876699784,
      "eval_loss": 0.44087156653404236,
      "eval_runtime": 46.8889,
      "eval_samples_per_second": 3581.444,
      "eval_steps_per_second": 447.696,
      "step": 435500
    },
    {
      "epoch": 4.610943198479788,
      "grad_norm": 1.0791869163513184,
      "learning_rate": 0.00032651758786706494,
      "loss": 0.6666,
      "step": 435550
    },
    {
      "epoch": 4.611472520259791,
      "grad_norm": 1.0278658866882324,
      "learning_rate": 0.0003264736110960014,
      "loss": 0.6445,
      "step": 435600
    },
    {
      "epoch": 4.612001842039795,
      "grad_norm": 1.1059316396713257,
      "learning_rate": 0.00032642963171415683,
      "loss": 0.6577,
      "step": 435650
    },
    {
      "epoch": 4.612531163819797,
      "grad_norm": 1.0166046619415283,
      "learning_rate": 0.00032638564972303275,
      "loss": 0.6561,
      "step": 435700
    },
    {
      "epoch": 4.613060485599801,
      "grad_norm": 1.1271578073501587,
      "learning_rate": 0.00032634166512413053,
      "loss": 0.6555,
      "step": 435750
    },
    {
      "epoch": 4.613589807379804,
      "grad_norm": 0.961262047290802,
      "learning_rate": 0.0003262976779189519,
      "loss": 0.6443,
      "step": 435800
    },
    {
      "epoch": 4.614119129159808,
      "grad_norm": 1.1231180429458618,
      "learning_rate": 0.0003262536881089985,
      "loss": 0.6331,
      "step": 435850
    },
    {
      "epoch": 4.614648450939811,
      "grad_norm": 1.0755351781845093,
      "learning_rate": 0.0003262096956957721,
      "loss": 0.657,
      "step": 435900
    },
    {
      "epoch": 4.615177772719814,
      "grad_norm": 1.0235947370529175,
      "learning_rate": 0.0003261657006807747,
      "loss": 0.6565,
      "step": 435950
    },
    {
      "epoch": 4.615707094499817,
      "grad_norm": 1.138749599456787,
      "learning_rate": 0.0003261217030655082,
      "loss": 0.6604,
      "step": 436000
    },
    {
      "epoch": 4.615707094499817,
      "eval_loss": 0.4385785758495331,
      "eval_runtime": 46.9068,
      "eval_samples_per_second": 3580.075,
      "eval_steps_per_second": 447.525,
      "step": 436000
    },
    {
      "epoch": 4.61623641627982,
      "grad_norm": 1.0749684572219849,
      "learning_rate": 0.00032607770285147464,
      "loss": 0.6541,
      "step": 436050
    },
    {
      "epoch": 4.616765738059824,
      "grad_norm": 1.046172857284546,
      "learning_rate": 0.00032603370004017626,
      "loss": 0.6542,
      "step": 436100
    },
    {
      "epoch": 4.617295059839828,
      "grad_norm": 1.1128218173980713,
      "learning_rate": 0.00032598969463311524,
      "loss": 0.649,
      "step": 436150
    },
    {
      "epoch": 4.6178243816198306,
      "grad_norm": 1.0507522821426392,
      "learning_rate": 0.0003259456866317938,
      "loss": 0.6593,
      "step": 436200
    },
    {
      "epoch": 4.618353703399833,
      "grad_norm": 1.0246833562850952,
      "learning_rate": 0.0003259016760377146,
      "loss": 0.66,
      "step": 436250
    },
    {
      "epoch": 4.618883025179837,
      "grad_norm": 0.9337823987007141,
      "learning_rate": 0.00032585766285237995,
      "loss": 0.6522,
      "step": 436300
    },
    {
      "epoch": 4.61941234695984,
      "grad_norm": 1.049216389656067,
      "learning_rate": 0.00032581364707729257,
      "loss": 0.6593,
      "step": 436350
    },
    {
      "epoch": 4.619941668739844,
      "grad_norm": 0.9919921159744263,
      "learning_rate": 0.00032576962871395503,
      "loss": 0.6463,
      "step": 436400
    },
    {
      "epoch": 4.620470990519847,
      "grad_norm": 1.1345453262329102,
      "learning_rate": 0.0003257256077638702,
      "loss": 0.6647,
      "step": 436450
    },
    {
      "epoch": 4.62100031229985,
      "grad_norm": 1.0452088117599487,
      "learning_rate": 0.0003256815842285409,
      "loss": 0.6542,
      "step": 436500
    },
    {
      "epoch": 4.62100031229985,
      "eval_loss": 0.4386060833930969,
      "eval_runtime": 46.8241,
      "eval_samples_per_second": 3586.397,
      "eval_steps_per_second": 448.316,
      "step": 436500
    },
    {
      "epoch": 4.621529634079853,
      "grad_norm": 1.0232468843460083,
      "learning_rate": 0.00032563755810947003,
      "loss": 0.6427,
      "step": 436550
    },
    {
      "epoch": 4.622058955859857,
      "grad_norm": 1.009631872177124,
      "learning_rate": 0.00032559352940816065,
      "loss": 0.6531,
      "step": 436600
    },
    {
      "epoch": 4.62258827763986,
      "grad_norm": 1.037956714630127,
      "learning_rate": 0.0003255503787770383,
      "loss": 0.6639,
      "step": 436650
    },
    {
      "epoch": 4.623117599419864,
      "grad_norm": 1.0913784503936768,
      "learning_rate": 0.0003255063449673313,
      "loss": 0.6567,
      "step": 436700
    },
    {
      "epoch": 4.6236469211998665,
      "grad_norm": 0.8732293844223022,
      "learning_rate": 0.0003254623085798655,
      "loss": 0.6497,
      "step": 436750
    },
    {
      "epoch": 4.624176242979869,
      "grad_norm": 1.1336976289749146,
      "learning_rate": 0.000325418269616144,
      "loss": 0.6479,
      "step": 436800
    },
    {
      "epoch": 4.624705564759873,
      "grad_norm": 1.1078593730926514,
      "learning_rate": 0.0003253742280776705,
      "loss": 0.6402,
      "step": 436850
    },
    {
      "epoch": 4.625234886539877,
      "grad_norm": 1.0009160041809082,
      "learning_rate": 0.0003253301839659484,
      "loss": 0.6537,
      "step": 436900
    },
    {
      "epoch": 4.62576420831988,
      "grad_norm": 1.007713794708252,
      "learning_rate": 0.0003252861372824816,
      "loss": 0.645,
      "step": 436950
    },
    {
      "epoch": 4.626293530099883,
      "grad_norm": 1.076204776763916,
      "learning_rate": 0.00032524208802877356,
      "loss": 0.6519,
      "step": 437000
    },
    {
      "epoch": 4.626293530099883,
      "eval_loss": 0.4393753111362457,
      "eval_runtime": 46.8438,
      "eval_samples_per_second": 3584.896,
      "eval_steps_per_second": 448.128,
      "step": 437000
    },
    {
      "epoch": 4.626822851879886,
      "grad_norm": 1.1437418460845947,
      "learning_rate": 0.0003251980362063283,
      "loss": 0.6492,
      "step": 437050
    },
    {
      "epoch": 4.627352173659889,
      "grad_norm": 1.029234766960144,
      "learning_rate": 0.0003251539818166497,
      "loss": 0.6603,
      "step": 437100
    },
    {
      "epoch": 4.627881495439893,
      "grad_norm": 0.8798626065254211,
      "learning_rate": 0.0003251099248612417,
      "loss": 0.6476,
      "step": 437150
    },
    {
      "epoch": 4.628410817219896,
      "grad_norm": 1.071704626083374,
      "learning_rate": 0.00032506586534160835,
      "loss": 0.648,
      "step": 437200
    },
    {
      "epoch": 4.6289401389999,
      "grad_norm": 1.0294501781463623,
      "learning_rate": 0.0003250218032592539,
      "loss": 0.6556,
      "step": 437250
    },
    {
      "epoch": 4.6294694607799025,
      "grad_norm": 1.061490774154663,
      "learning_rate": 0.0003249777386156826,
      "loss": 0.6655,
      "step": 437300
    },
    {
      "epoch": 4.629998782559906,
      "grad_norm": 1.0929560661315918,
      "learning_rate": 0.0003249336714123989,
      "loss": 0.6544,
      "step": 437350
    },
    {
      "epoch": 4.630528104339909,
      "grad_norm": 1.101729154586792,
      "learning_rate": 0.000324889601650907,
      "loss": 0.658,
      "step": 437400
    },
    {
      "epoch": 4.631057426119913,
      "grad_norm": 1.0645701885223389,
      "learning_rate": 0.00032484552933271165,
      "loss": 0.6549,
      "step": 437450
    },
    {
      "epoch": 4.631586747899916,
      "grad_norm": 0.9746926426887512,
      "learning_rate": 0.0003248014544593174,
      "loss": 0.6513,
      "step": 437500
    },
    {
      "epoch": 4.631586747899916,
      "eval_loss": 0.43986114859580994,
      "eval_runtime": 46.8878,
      "eval_samples_per_second": 3581.53,
      "eval_steps_per_second": 447.707,
      "step": 437500
    },
    {
      "epoch": 4.632116069679919,
      "grad_norm": 1.1060569286346436,
      "learning_rate": 0.00032475737703222885,
      "loss": 0.6426,
      "step": 437550
    },
    {
      "epoch": 4.632645391459922,
      "grad_norm": 1.0970077514648438,
      "learning_rate": 0.00032471329705295083,
      "loss": 0.6473,
      "step": 437600
    },
    {
      "epoch": 4.633174713239926,
      "grad_norm": 0.9883910417556763,
      "learning_rate": 0.0003246692145229884,
      "loss": 0.6522,
      "step": 437650
    },
    {
      "epoch": 4.633704035019929,
      "grad_norm": 1.1120707988739014,
      "learning_rate": 0.00032462512944384626,
      "loss": 0.6646,
      "step": 437700
    },
    {
      "epoch": 4.634233356799932,
      "grad_norm": 1.0459375381469727,
      "learning_rate": 0.00032458104181702955,
      "loss": 0.6546,
      "step": 437750
    },
    {
      "epoch": 4.634762678579936,
      "grad_norm": 1.0069444179534912,
      "learning_rate": 0.0003245369516440435,
      "loss": 0.6522,
      "step": 437800
    },
    {
      "epoch": 4.6352920003599385,
      "grad_norm": 1.0051225423812866,
      "learning_rate": 0.00032449285892639324,
      "loss": 0.6468,
      "step": 437850
    },
    {
      "epoch": 4.635821322139942,
      "grad_norm": 1.0355424880981445,
      "learning_rate": 0.0003244487636655841,
      "loss": 0.659,
      "step": 437900
    },
    {
      "epoch": 4.636350643919945,
      "grad_norm": 1.0541764497756958,
      "learning_rate": 0.00032440466586312146,
      "loss": 0.655,
      "step": 437950
    },
    {
      "epoch": 4.636879965699949,
      "grad_norm": 1.0296028852462769,
      "learning_rate": 0.00032436056552051073,
      "loss": 0.6425,
      "step": 438000
    },
    {
      "epoch": 4.636879965699949,
      "eval_loss": 0.43783310055732727,
      "eval_runtime": 46.9717,
      "eval_samples_per_second": 3575.133,
      "eval_steps_per_second": 446.908,
      "step": 438000
    },
    {
      "epoch": 4.637409287479952,
      "grad_norm": 1.1133586168289185,
      "learning_rate": 0.0003243164626392577,
      "loss": 0.6546,
      "step": 438050
    },
    {
      "epoch": 4.6379386092599555,
      "grad_norm": 0.9682387709617615,
      "learning_rate": 0.0003242723572208678,
      "loss": 0.6399,
      "step": 438100
    },
    {
      "epoch": 4.638467931039958,
      "grad_norm": 1.0456788539886475,
      "learning_rate": 0.0003242282492668469,
      "loss": 0.6443,
      "step": 438150
    },
    {
      "epoch": 4.638997252819962,
      "grad_norm": 1.0528064966201782,
      "learning_rate": 0.0003241841387787008,
      "loss": 0.6504,
      "step": 438200
    },
    {
      "epoch": 4.639526574599965,
      "grad_norm": 1.0342230796813965,
      "learning_rate": 0.0003241400257579354,
      "loss": 0.6421,
      "step": 438250
    },
    {
      "epoch": 4.640055896379968,
      "grad_norm": 1.0195273160934448,
      "learning_rate": 0.00032409591020605673,
      "loss": 0.6469,
      "step": 438300
    },
    {
      "epoch": 4.640585218159972,
      "grad_norm": 1.092048168182373,
      "learning_rate": 0.0003240517921245708,
      "loss": 0.6559,
      "step": 438350
    },
    {
      "epoch": 4.641114539939975,
      "grad_norm": 1.1173063516616821,
      "learning_rate": 0.0003240076715149839,
      "loss": 0.6617,
      "step": 438400
    },
    {
      "epoch": 4.641643861719978,
      "grad_norm": 1.1121095418930054,
      "learning_rate": 0.00032396354837880214,
      "loss": 0.6554,
      "step": 438450
    },
    {
      "epoch": 4.642173183499981,
      "grad_norm": 0.9419370889663696,
      "learning_rate": 0.0003239194227175321,
      "loss": 0.648,
      "step": 438500
    },
    {
      "epoch": 4.642173183499981,
      "eval_loss": 0.4389286935329437,
      "eval_runtime": 46.8878,
      "eval_samples_per_second": 3581.531,
      "eval_steps_per_second": 447.707,
      "step": 438500
    },
    {
      "epoch": 4.642702505279985,
      "grad_norm": 1.0569819211959839,
      "learning_rate": 0.00032387529453268,
      "loss": 0.6456,
      "step": 438550
    },
    {
      "epoch": 4.643231827059988,
      "grad_norm": 0.9780704379081726,
      "learning_rate": 0.00032383116382575245,
      "loss": 0.6578,
      "step": 438600
    },
    {
      "epoch": 4.6437611488399915,
      "grad_norm": 1.006308674812317,
      "learning_rate": 0.00032378703059825605,
      "loss": 0.6442,
      "step": 438650
    },
    {
      "epoch": 4.644290470619994,
      "grad_norm": 0.98367840051651,
      "learning_rate": 0.0003237428948516975,
      "loss": 0.6582,
      "step": 438700
    },
    {
      "epoch": 4.644819792399998,
      "grad_norm": 1.0493881702423096,
      "learning_rate": 0.0003236996393775282,
      "loss": 0.6579,
      "step": 438750
    },
    {
      "epoch": 4.645349114180001,
      "grad_norm": 1.2205493450164795,
      "learning_rate": 0.0003236554986476719,
      "loss": 0.642,
      "step": 438800
    },
    {
      "epoch": 4.645878435960005,
      "grad_norm": 1.0864760875701904,
      "learning_rate": 0.0003236113554032438,
      "loss": 0.6463,
      "step": 438850
    },
    {
      "epoch": 4.646407757740008,
      "grad_norm": 1.066257119178772,
      "learning_rate": 0.0003235672096457512,
      "loss": 0.6417,
      "step": 438900
    },
    {
      "epoch": 4.646937079520011,
      "grad_norm": 0.9766247868537903,
      "learning_rate": 0.00032352306137670096,
      "loss": 0.655,
      "step": 438950
    },
    {
      "epoch": 4.647466401300014,
      "grad_norm": 1.1112169027328491,
      "learning_rate": 0.00032347891059760045,
      "loss": 0.6503,
      "step": 439000
    },
    {
      "epoch": 4.647466401300014,
      "eval_loss": 0.43902188539505005,
      "eval_runtime": 46.9989,
      "eval_samples_per_second": 3573.062,
      "eval_steps_per_second": 446.649,
      "step": 439000
    },
    {
      "epoch": 4.647995723080018,
      "grad_norm": 1.0312694311141968,
      "learning_rate": 0.0003234347573099568,
      "loss": 0.6479,
      "step": 439050
    },
    {
      "epoch": 4.648525044860021,
      "grad_norm": 1.0420674085617065,
      "learning_rate": 0.0003233906015152775,
      "loss": 0.6515,
      "step": 439100
    },
    {
      "epoch": 4.649054366640025,
      "grad_norm": 1.0907304286956787,
      "learning_rate": 0.00032334644321506997,
      "loss": 0.6482,
      "step": 439150
    },
    {
      "epoch": 4.6495836884200274,
      "grad_norm": 1.0897561311721802,
      "learning_rate": 0.00032330228241084176,
      "loss": 0.6499,
      "step": 439200
    },
    {
      "epoch": 4.65011301020003,
      "grad_norm": 0.9804715514183044,
      "learning_rate": 0.00032325811910410054,
      "loss": 0.6453,
      "step": 439250
    },
    {
      "epoch": 4.650642331980034,
      "grad_norm": 0.8702759146690369,
      "learning_rate": 0.00032321395329635395,
      "loss": 0.6452,
      "step": 439300
    },
    {
      "epoch": 4.651171653760037,
      "grad_norm": 1.0084511041641235,
      "learning_rate": 0.0003231697849891099,
      "loss": 0.65,
      "step": 439350
    },
    {
      "epoch": 4.651700975540041,
      "grad_norm": 1.0880539417266846,
      "learning_rate": 0.0003231256141838762,
      "loss": 0.6508,
      "step": 439400
    },
    {
      "epoch": 4.652230297320044,
      "grad_norm": 1.0726635456085205,
      "learning_rate": 0.0003230814408821608,
      "loss": 0.6585,
      "step": 439450
    },
    {
      "epoch": 4.652759619100047,
      "grad_norm": 0.9860023260116577,
      "learning_rate": 0.0003230372650854719,
      "loss": 0.6514,
      "step": 439500
    },
    {
      "epoch": 4.652759619100047,
      "eval_loss": 0.43867069482803345,
      "eval_runtime": 46.7874,
      "eval_samples_per_second": 3589.216,
      "eval_steps_per_second": 448.668,
      "step": 439500
    },
    {
      "epoch": 4.65328894088005,
      "grad_norm": 1.09675133228302,
      "learning_rate": 0.0003229930867953175,
      "loss": 0.6548,
      "step": 439550
    },
    {
      "epoch": 4.653818262660054,
      "grad_norm": 1.0557881593704224,
      "learning_rate": 0.0003229489060132059,
      "loss": 0.6526,
      "step": 439600
    },
    {
      "epoch": 4.654347584440057,
      "grad_norm": 1.0915441513061523,
      "learning_rate": 0.00032290472274064543,
      "loss": 0.6487,
      "step": 439650
    },
    {
      "epoch": 4.654876906220061,
      "grad_norm": 1.0998286008834839,
      "learning_rate": 0.00032286053697914437,
      "loss": 0.6495,
      "step": 439700
    },
    {
      "epoch": 4.655406228000063,
      "grad_norm": 1.052930474281311,
      "learning_rate": 0.0003228163487302114,
      "loss": 0.6492,
      "step": 439750
    },
    {
      "epoch": 4.655935549780067,
      "grad_norm": 0.9151285886764526,
      "learning_rate": 0.0003227721579953549,
      "loss": 0.6358,
      "step": 439800
    },
    {
      "epoch": 4.65646487156007,
      "grad_norm": 1.0180166959762573,
      "learning_rate": 0.0003227279647760837,
      "loss": 0.6514,
      "step": 439850
    },
    {
      "epoch": 4.656994193340074,
      "grad_norm": 1.1397922039031982,
      "learning_rate": 0.0003226837690739064,
      "loss": 0.6488,
      "step": 439900
    },
    {
      "epoch": 4.657523515120077,
      "grad_norm": 1.1306195259094238,
      "learning_rate": 0.0003226395708903319,
      "loss": 0.6588,
      "step": 439950
    },
    {
      "epoch": 4.6580528369000795,
      "grad_norm": 1.0659900903701782,
      "learning_rate": 0.00032259537022686914,
      "loss": 0.6518,
      "step": 440000
    },
    {
      "epoch": 4.6580528369000795,
      "eval_loss": 0.43784329295158386,
      "eval_runtime": 46.8857,
      "eval_samples_per_second": 3581.69,
      "eval_steps_per_second": 447.727,
      "step": 440000
    },
    {
      "epoch": 4.658582158680083,
      "grad_norm": 0.8741022944450378,
      "learning_rate": 0.000322551167085027,
      "loss": 0.6517,
      "step": 440050
    },
    {
      "epoch": 4.659111480460086,
      "grad_norm": 1.0388399362564087,
      "learning_rate": 0.0003225069614663146,
      "loss": 0.6549,
      "step": 440100
    },
    {
      "epoch": 4.65964080224009,
      "grad_norm": 1.085189700126648,
      "learning_rate": 0.0003224627533722412,
      "loss": 0.6384,
      "step": 440150
    },
    {
      "epoch": 4.660170124020093,
      "grad_norm": 1.0045150518417358,
      "learning_rate": 0.0003224185428043159,
      "loss": 0.6669,
      "step": 440200
    },
    {
      "epoch": 4.6606994458000965,
      "grad_norm": 1.0198086500167847,
      "learning_rate": 0.00032237432976404815,
      "loss": 0.6519,
      "step": 440250
    },
    {
      "epoch": 4.661228767580099,
      "grad_norm": 1.0219634771347046,
      "learning_rate": 0.00032233011425294734,
      "loss": 0.6512,
      "step": 440300
    },
    {
      "epoch": 4.661758089360103,
      "grad_norm": 0.9825273752212524,
      "learning_rate": 0.0003222858962725229,
      "loss": 0.6608,
      "step": 440350
    },
    {
      "epoch": 4.662287411140106,
      "grad_norm": 1.084782361984253,
      "learning_rate": 0.0003222416758242845,
      "loss": 0.6447,
      "step": 440400
    },
    {
      "epoch": 4.66281673292011,
      "grad_norm": 0.9927913546562195,
      "learning_rate": 0.00032219745290974186,
      "loss": 0.6552,
      "step": 440450
    },
    {
      "epoch": 4.663346054700113,
      "grad_norm": 1.0355497598648071,
      "learning_rate": 0.00032215322753040456,
      "loss": 0.6515,
      "step": 440500
    },
    {
      "epoch": 4.663346054700113,
      "eval_loss": 0.4366280436515808,
      "eval_runtime": 46.8732,
      "eval_samples_per_second": 3582.647,
      "eval_steps_per_second": 447.847,
      "step": 440500
    },
    {
      "epoch": 4.663875376480116,
      "grad_norm": 1.0459715127944946,
      "learning_rate": 0.0003221089996877825,
      "loss": 0.6296,
      "step": 440550
    },
    {
      "epoch": 4.664404698260119,
      "grad_norm": 1.003331184387207,
      "learning_rate": 0.00032206476938338567,
      "loss": 0.6498,
      "step": 440600
    },
    {
      "epoch": 4.664934020040123,
      "grad_norm": 0.9106570482254028,
      "learning_rate": 0.0003220205366187241,
      "loss": 0.6455,
      "step": 440650
    },
    {
      "epoch": 4.665463341820126,
      "grad_norm": 1.0320650339126587,
      "learning_rate": 0.0003219763013953078,
      "loss": 0.6415,
      "step": 440700
    },
    {
      "epoch": 4.665992663600129,
      "grad_norm": 1.0952186584472656,
      "learning_rate": 0.000321932063714647,
      "loss": 0.651,
      "step": 440750
    },
    {
      "epoch": 4.6665219853801325,
      "grad_norm": 1.0855743885040283,
      "learning_rate": 0.0003218887084050363,
      "loss": 0.651,
      "step": 440800
    },
    {
      "epoch": 4.667051307160135,
      "grad_norm": 1.0324437618255615,
      "learning_rate": 0.00032184446586348684,
      "loss": 0.6479,
      "step": 440850
    },
    {
      "epoch": 4.667580628940139,
      "grad_norm": 1.0505844354629517,
      "learning_rate": 0.00032180022086919377,
      "loss": 0.6614,
      "step": 440900
    },
    {
      "epoch": 4.668109950720142,
      "grad_norm": 1.0531710386276245,
      "learning_rate": 0.0003217559734236674,
      "loss": 0.6506,
      "step": 440950
    },
    {
      "epoch": 4.668639272500146,
      "grad_norm": 1.1230404376983643,
      "learning_rate": 0.00032171172352841846,
      "loss": 0.6499,
      "step": 441000
    },
    {
      "epoch": 4.668639272500146,
      "eval_loss": 0.4386066794395447,
      "eval_runtime": 46.8581,
      "eval_samples_per_second": 3583.799,
      "eval_steps_per_second": 447.991,
      "step": 441000
    },
    {
      "epoch": 4.669168594280149,
      "grad_norm": 1.0934640169143677,
      "learning_rate": 0.0003216674711849576,
      "loss": 0.6393,
      "step": 441050
    },
    {
      "epoch": 4.669697916060152,
      "grad_norm": 1.125785231590271,
      "learning_rate": 0.0003216232163947956,
      "loss": 0.6518,
      "step": 441100
    },
    {
      "epoch": 4.670227237840155,
      "grad_norm": 0.9028493762016296,
      "learning_rate": 0.00032157895915944327,
      "loss": 0.6426,
      "step": 441150
    },
    {
      "epoch": 4.670756559620159,
      "grad_norm": 1.0366861820220947,
      "learning_rate": 0.0003215346994804114,
      "loss": 0.6516,
      "step": 441200
    },
    {
      "epoch": 4.671285881400162,
      "grad_norm": 0.9886871576309204,
      "learning_rate": 0.00032149043735921125,
      "loss": 0.6415,
      "step": 441250
    },
    {
      "epoch": 4.671815203180166,
      "grad_norm": 1.0106600522994995,
      "learning_rate": 0.0003214461727973537,
      "loss": 0.6478,
      "step": 441300
    },
    {
      "epoch": 4.6723445249601685,
      "grad_norm": 1.0268807411193848,
      "learning_rate": 0.0003214019057963501,
      "loss": 0.6508,
      "step": 441350
    },
    {
      "epoch": 4.672873846740172,
      "grad_norm": 1.0706781148910522,
      "learning_rate": 0.0003213576363577115,
      "loss": 0.6453,
      "step": 441400
    },
    {
      "epoch": 4.673403168520175,
      "grad_norm": 1.0874990224838257,
      "learning_rate": 0.00032131336448294946,
      "loss": 0.6419,
      "step": 441450
    },
    {
      "epoch": 4.673932490300178,
      "grad_norm": 0.9539148211479187,
      "learning_rate": 0.0003212690901735753,
      "loss": 0.6513,
      "step": 441500
    },
    {
      "epoch": 4.673932490300178,
      "eval_loss": 0.4382704198360443,
      "eval_runtime": 46.9154,
      "eval_samples_per_second": 3579.422,
      "eval_steps_per_second": 447.444,
      "step": 441500
    },
    {
      "epoch": 4.674461812080182,
      "grad_norm": 1.0033133029937744,
      "learning_rate": 0.0003212248134311005,
      "loss": 0.6398,
      "step": 441550
    },
    {
      "epoch": 4.674991133860185,
      "grad_norm": 1.0780936479568481,
      "learning_rate": 0.00032118053425703673,
      "loss": 0.6344,
      "step": 441600
    },
    {
      "epoch": 4.675520455640188,
      "grad_norm": 1.045548439025879,
      "learning_rate": 0.0003211362526528956,
      "loss": 0.6526,
      "step": 441650
    },
    {
      "epoch": 4.676049777420191,
      "grad_norm": 1.0614160299301147,
      "learning_rate": 0.0003210919686201889,
      "loss": 0.6457,
      "step": 441700
    },
    {
      "epoch": 4.676579099200195,
      "grad_norm": 1.0381653308868408,
      "learning_rate": 0.00032104768216042844,
      "loss": 0.6411,
      "step": 441750
    },
    {
      "epoch": 4.677108420980198,
      "grad_norm": 0.9514378309249878,
      "learning_rate": 0.00032100339327512616,
      "loss": 0.6445,
      "step": 441800
    },
    {
      "epoch": 4.677637742760202,
      "grad_norm": 1.0847115516662598,
      "learning_rate": 0.00032095910196579415,
      "loss": 0.6445,
      "step": 441850
    },
    {
      "epoch": 4.6781670645402045,
      "grad_norm": 1.124536395072937,
      "learning_rate": 0.00032091480823394434,
      "loss": 0.6503,
      "step": 441900
    },
    {
      "epoch": 4.678696386320208,
      "grad_norm": 1.009294033050537,
      "learning_rate": 0.000320870512081089,
      "loss": 0.6484,
      "step": 441950
    },
    {
      "epoch": 4.679225708100211,
      "grad_norm": 0.9749711155891418,
      "learning_rate": 0.00032082621350874044,
      "loss": 0.6421,
      "step": 442000
    },
    {
      "epoch": 4.679225708100211,
      "eval_loss": 0.43820029497146606,
      "eval_runtime": 46.9053,
      "eval_samples_per_second": 3580.195,
      "eval_steps_per_second": 447.54,
      "step": 442000
    },
    {
      "epoch": 4.679755029880215,
      "grad_norm": 0.9961475729942322,
      "learning_rate": 0.0003207819125184109,
      "loss": 0.6432,
      "step": 442050
    },
    {
      "epoch": 4.680284351660218,
      "grad_norm": 0.9849972128868103,
      "learning_rate": 0.00032073760911161274,
      "loss": 0.6528,
      "step": 442100
    },
    {
      "epoch": 4.6808136734402215,
      "grad_norm": 1.0585565567016602,
      "learning_rate": 0.00032069330328985855,
      "loss": 0.647,
      "step": 442150
    },
    {
      "epoch": 4.681342995220224,
      "grad_norm": 1.1469664573669434,
      "learning_rate": 0.000320648995054661,
      "loss": 0.6471,
      "step": 442200
    },
    {
      "epoch": 4.681872317000227,
      "grad_norm": 1.1595239639282227,
      "learning_rate": 0.00032060468440753265,
      "loss": 0.6517,
      "step": 442250
    },
    {
      "epoch": 4.682401638780231,
      "grad_norm": 1.0235276222229004,
      "learning_rate": 0.0003205603713499863,
      "loss": 0.6566,
      "step": 442300
    },
    {
      "epoch": 4.682930960560234,
      "grad_norm": 1.0066572427749634,
      "learning_rate": 0.0003205160558835347,
      "loss": 0.6515,
      "step": 442350
    },
    {
      "epoch": 4.683460282340238,
      "grad_norm": 1.0830340385437012,
      "learning_rate": 0.00032047173800969076,
      "loss": 0.6498,
      "step": 442400
    },
    {
      "epoch": 4.6839896041202405,
      "grad_norm": 1.119913935661316,
      "learning_rate": 0.0003204274177299676,
      "loss": 0.6588,
      "step": 442450
    },
    {
      "epoch": 4.684518925900244,
      "grad_norm": 1.0003241300582886,
      "learning_rate": 0.00032038309504587827,
      "loss": 0.6586,
      "step": 442500
    },
    {
      "epoch": 4.684518925900244,
      "eval_loss": 0.4374563694000244,
      "eval_runtime": 46.8425,
      "eval_samples_per_second": 3584.989,
      "eval_steps_per_second": 448.14,
      "step": 442500
    },
    {
      "epoch": 4.685048247680247,
      "grad_norm": 1.0361729860305786,
      "learning_rate": 0.0003203387699589358,
      "loss": 0.6587,
      "step": 442550
    },
    {
      "epoch": 4.685577569460251,
      "grad_norm": 1.163306474685669,
      "learning_rate": 0.00032029444247065353,
      "loss": 0.6543,
      "step": 442600
    },
    {
      "epoch": 4.686106891240254,
      "grad_norm": 1.12473464012146,
      "learning_rate": 0.00032025011258254485,
      "loss": 0.6524,
      "step": 442650
    },
    {
      "epoch": 4.6866362130202575,
      "grad_norm": 1.0771028995513916,
      "learning_rate": 0.000320205780296123,
      "loss": 0.6436,
      "step": 442700
    },
    {
      "epoch": 4.68716553480026,
      "grad_norm": 1.1641287803649902,
      "learning_rate": 0.00032016144561290157,
      "loss": 0.6599,
      "step": 442750
    },
    {
      "epoch": 4.687694856580264,
      "grad_norm": 1.0668671131134033,
      "learning_rate": 0.0003201179952994283,
      "loss": 0.6432,
      "step": 442800
    },
    {
      "epoch": 4.688224178360267,
      "grad_norm": 0.9673237800598145,
      "learning_rate": 0.0003200736558750091,
      "loss": 0.6404,
      "step": 442850
    },
    {
      "epoch": 4.688753500140271,
      "grad_norm": 1.0425007343292236,
      "learning_rate": 0.00032002931405830106,
      "loss": 0.6495,
      "step": 442900
    },
    {
      "epoch": 4.689282821920274,
      "grad_norm": 1.1658622026443481,
      "learning_rate": 0.0003199849698508178,
      "loss": 0.6477,
      "step": 442950
    },
    {
      "epoch": 4.689812143700276,
      "grad_norm": 1.0393236875534058,
      "learning_rate": 0.00031994062325407346,
      "loss": 0.6436,
      "step": 443000
    },
    {
      "epoch": 4.689812143700276,
      "eval_loss": 0.43485260009765625,
      "eval_runtime": 46.941,
      "eval_samples_per_second": 3577.467,
      "eval_steps_per_second": 447.199,
      "step": 443000
    },
    {
      "epoch": 4.69034146548028,
      "grad_norm": 1.0127443075180054,
      "learning_rate": 0.0003198962742695818,
      "loss": 0.6546,
      "step": 443050
    },
    {
      "epoch": 4.690870787260283,
      "grad_norm": 0.9326022863388062,
      "learning_rate": 0.000319851922898857,
      "loss": 0.6487,
      "step": 443100
    },
    {
      "epoch": 4.691400109040287,
      "grad_norm": 1.0687228441238403,
      "learning_rate": 0.00031980756914341314,
      "loss": 0.651,
      "step": 443150
    },
    {
      "epoch": 4.69192943082029,
      "grad_norm": 1.0629289150238037,
      "learning_rate": 0.0003197632130047645,
      "loss": 0.6499,
      "step": 443200
    },
    {
      "epoch": 4.692458752600293,
      "grad_norm": 1.1048595905303955,
      "learning_rate": 0.00031971885448442536,
      "loss": 0.6544,
      "step": 443250
    },
    {
      "epoch": 4.692988074380296,
      "grad_norm": 1.0575296878814697,
      "learning_rate": 0.0003196744935839101,
      "loss": 0.637,
      "step": 443300
    },
    {
      "epoch": 4.6935173961603,
      "grad_norm": 1.0576413869857788,
      "learning_rate": 0.00031963013030473315,
      "loss": 0.6484,
      "step": 443350
    },
    {
      "epoch": 4.694046717940303,
      "grad_norm": 1.0060995817184448,
      "learning_rate": 0.0003195857646484091,
      "loss": 0.6564,
      "step": 443400
    },
    {
      "epoch": 4.694576039720307,
      "grad_norm": 0.9439687728881836,
      "learning_rate": 0.0003195413966164526,
      "loss": 0.6471,
      "step": 443450
    },
    {
      "epoch": 4.6951053615003095,
      "grad_norm": 1.0515750646591187,
      "learning_rate": 0.0003194970262103783,
      "loss": 0.6526,
      "step": 443500
    },
    {
      "epoch": 4.6951053615003095,
      "eval_loss": 0.4366275668144226,
      "eval_runtime": 46.7803,
      "eval_samples_per_second": 3589.76,
      "eval_steps_per_second": 448.736,
      "step": 443500
    },
    {
      "epoch": 4.695634683280313,
      "grad_norm": 1.0877718925476074,
      "learning_rate": 0.00031945265343170096,
      "loss": 0.6469,
      "step": 443550
    },
    {
      "epoch": 4.696164005060316,
      "grad_norm": 1.0545578002929688,
      "learning_rate": 0.00031940827828193556,
      "loss": 0.6512,
      "step": 443600
    },
    {
      "epoch": 4.69669332684032,
      "grad_norm": 1.0403386354446411,
      "learning_rate": 0.000319363900762597,
      "loss": 0.6515,
      "step": 443650
    },
    {
      "epoch": 4.697222648620323,
      "grad_norm": 1.1448183059692383,
      "learning_rate": 0.0003193195208752003,
      "loss": 0.6456,
      "step": 443700
    },
    {
      "epoch": 4.697751970400326,
      "grad_norm": 1.0481098890304565,
      "learning_rate": 0.00031927513862126057,
      "loss": 0.6408,
      "step": 443750
    },
    {
      "epoch": 4.698281292180329,
      "grad_norm": 1.0447778701782227,
      "learning_rate": 0.00031923075400229305,
      "loss": 0.6441,
      "step": 443800
    },
    {
      "epoch": 4.698810613960332,
      "grad_norm": 0.9710487723350525,
      "learning_rate": 0.000319186367019813,
      "loss": 0.6595,
      "step": 443850
    },
    {
      "epoch": 4.699339935740336,
      "grad_norm": 1.189546823501587,
      "learning_rate": 0.00031914197767533565,
      "loss": 0.6397,
      "step": 443900
    },
    {
      "epoch": 4.699869257520339,
      "grad_norm": 1.2058483362197876,
      "learning_rate": 0.00031909758597037656,
      "loss": 0.6575,
      "step": 443950
    },
    {
      "epoch": 4.700398579300343,
      "grad_norm": 1.0322023630142212,
      "learning_rate": 0.0003190531919064512,
      "loss": 0.6423,
      "step": 444000
    },
    {
      "epoch": 4.700398579300343,
      "eval_loss": 0.4362671673297882,
      "eval_runtime": 46.8225,
      "eval_samples_per_second": 3586.525,
      "eval_steps_per_second": 448.332,
      "step": 444000
    },
    {
      "epoch": 4.7009279010803455,
      "grad_norm": 1.0837703943252563,
      "learning_rate": 0.00031900879548507524,
      "loss": 0.6505,
      "step": 444050
    },
    {
      "epoch": 4.701457222860349,
      "grad_norm": 1.0649899244308472,
      "learning_rate": 0.0003189643967077643,
      "loss": 0.6552,
      "step": 444100
    },
    {
      "epoch": 4.701986544640352,
      "grad_norm": 0.9800635576248169,
      "learning_rate": 0.0003189199955760342,
      "loss": 0.6525,
      "step": 444150
    },
    {
      "epoch": 4.702515866420356,
      "grad_norm": 1.0910636186599731,
      "learning_rate": 0.0003188755920914007,
      "loss": 0.6572,
      "step": 444200
    },
    {
      "epoch": 4.703045188200359,
      "grad_norm": 1.080875039100647,
      "learning_rate": 0.0003188311862553797,
      "loss": 0.6618,
      "step": 444250
    },
    {
      "epoch": 4.7035745099803625,
      "grad_norm": 1.0200530290603638,
      "learning_rate": 0.0003187867780694873,
      "loss": 0.6392,
      "step": 444300
    },
    {
      "epoch": 4.704103831760365,
      "grad_norm": 1.1236448287963867,
      "learning_rate": 0.0003187423675352395,
      "loss": 0.643,
      "step": 444350
    },
    {
      "epoch": 4.704633153540369,
      "grad_norm": 1.1115974187850952,
      "learning_rate": 0.0003186979546541525,
      "loss": 0.6407,
      "step": 444400
    },
    {
      "epoch": 4.705162475320372,
      "grad_norm": 1.087477207183838,
      "learning_rate": 0.0003186535394277425,
      "loss": 0.6447,
      "step": 444450
    },
    {
      "epoch": 4.705691797100375,
      "grad_norm": 1.1386629343032837,
      "learning_rate": 0.0003186091218575259,
      "loss": 0.6392,
      "step": 444500
    },
    {
      "epoch": 4.705691797100375,
      "eval_loss": 0.43629902601242065,
      "eval_runtime": 46.8453,
      "eval_samples_per_second": 3584.78,
      "eval_steps_per_second": 448.114,
      "step": 444500
    },
    {
      "epoch": 4.706221118880379,
      "grad_norm": 1.0120600461959839,
      "learning_rate": 0.00031856470194501895,
      "loss": 0.643,
      "step": 444550
    },
    {
      "epoch": 4.7067504406603815,
      "grad_norm": 1.0844919681549072,
      "learning_rate": 0.00031852027969173823,
      "loss": 0.6511,
      "step": 444600
    },
    {
      "epoch": 4.707279762440385,
      "grad_norm": 1.0815081596374512,
      "learning_rate": 0.00031847585509920035,
      "loss": 0.645,
      "step": 444650
    },
    {
      "epoch": 4.707809084220388,
      "grad_norm": 1.0156588554382324,
      "learning_rate": 0.0003184314281689219,
      "loss": 0.6359,
      "step": 444700
    },
    {
      "epoch": 4.708338406000392,
      "grad_norm": 0.9454994797706604,
      "learning_rate": 0.00031838699890241953,
      "loss": 0.6394,
      "step": 444750
    },
    {
      "epoch": 4.708867727780395,
      "grad_norm": 0.9087303280830383,
      "learning_rate": 0.0003183434559561046,
      "loss": 0.6386,
      "step": 444800
    },
    {
      "epoch": 4.7093970495603985,
      "grad_norm": 1.0727936029434204,
      "learning_rate": 0.00031829902206835395,
      "loss": 0.6533,
      "step": 444850
    },
    {
      "epoch": 4.709926371340401,
      "grad_norm": 0.9093947410583496,
      "learning_rate": 0.0003182545858488998,
      "loss": 0.6463,
      "step": 444900
    },
    {
      "epoch": 4.710455693120405,
      "grad_norm": 1.2395048141479492,
      "learning_rate": 0.0003182110360930778,
      "loss": 0.6476,
      "step": 444950
    },
    {
      "epoch": 4.710985014900408,
      "grad_norm": 1.0089941024780273,
      "learning_rate": 0.0003181665952613261,
      "loss": 0.6491,
      "step": 445000
    },
    {
      "epoch": 4.710985014900408,
      "eval_loss": 0.43547213077545166,
      "eval_runtime": 46.8817,
      "eval_samples_per_second": 3581.998,
      "eval_steps_per_second": 447.766,
      "step": 445000
    },
    {
      "epoch": 4.711514336680412,
      "grad_norm": 1.0369601249694824,
      "learning_rate": 0.00031812215210239193,
      "loss": 0.655,
      "step": 445050
    },
    {
      "epoch": 4.712043658460415,
      "grad_norm": 1.1019996404647827,
      "learning_rate": 0.0003180777066177924,
      "loss": 0.651,
      "step": 445100
    },
    {
      "epoch": 4.712572980240418,
      "grad_norm": 1.1638293266296387,
      "learning_rate": 0.000318033258809045,
      "loss": 0.6433,
      "step": 445150
    },
    {
      "epoch": 4.713102302020421,
      "grad_norm": 1.1748915910720825,
      "learning_rate": 0.00031798880867766704,
      "loss": 0.6548,
      "step": 445200
    },
    {
      "epoch": 4.713631623800424,
      "grad_norm": 1.094655990600586,
      "learning_rate": 0.0003179443562251761,
      "loss": 0.6527,
      "step": 445250
    },
    {
      "epoch": 4.714160945580428,
      "grad_norm": 1.0302751064300537,
      "learning_rate": 0.00031789990145308976,
      "loss": 0.6561,
      "step": 445300
    },
    {
      "epoch": 4.714690267360431,
      "grad_norm": 1.0700989961624146,
      "learning_rate": 0.00031785544436292566,
      "loss": 0.6425,
      "step": 445350
    },
    {
      "epoch": 4.7152195891404345,
      "grad_norm": 1.0225473642349243,
      "learning_rate": 0.00031781098495620164,
      "loss": 0.6587,
      "step": 445400
    },
    {
      "epoch": 4.715748910920437,
      "grad_norm": 1.0614057779312134,
      "learning_rate": 0.00031776652323443547,
      "loss": 0.645,
      "step": 445450
    },
    {
      "epoch": 4.716278232700441,
      "grad_norm": 1.1283044815063477,
      "learning_rate": 0.000317722059199145,
      "loss": 0.647,
      "step": 445500
    },
    {
      "epoch": 4.716278232700441,
      "eval_loss": 0.4346824288368225,
      "eval_runtime": 46.8117,
      "eval_samples_per_second": 3587.351,
      "eval_steps_per_second": 448.435,
      "step": 445500
    },
    {
      "epoch": 4.716807554480444,
      "grad_norm": 1.0216143131256104,
      "learning_rate": 0.0003176775928518483,
      "loss": 0.6552,
      "step": 445550
    },
    {
      "epoch": 4.717336876260448,
      "grad_norm": 1.032269835472107,
      "learning_rate": 0.0003176331241940633,
      "loss": 0.6447,
      "step": 445600
    },
    {
      "epoch": 4.717866198040451,
      "grad_norm": 1.034410834312439,
      "learning_rate": 0.00031758865322730834,
      "loss": 0.6586,
      "step": 445650
    },
    {
      "epoch": 4.718395519820454,
      "grad_norm": 0.9486591815948486,
      "learning_rate": 0.00031754417995310153,
      "loss": 0.6521,
      "step": 445700
    },
    {
      "epoch": 4.718924841600457,
      "grad_norm": 1.0266221761703491,
      "learning_rate": 0.00031749970437296117,
      "loss": 0.6521,
      "step": 445750
    },
    {
      "epoch": 4.719454163380461,
      "grad_norm": 1.0426844358444214,
      "learning_rate": 0.00031745522648840563,
      "loss": 0.6511,
      "step": 445800
    },
    {
      "epoch": 4.719983485160464,
      "grad_norm": 1.0781657695770264,
      "learning_rate": 0.0003174107463009534,
      "loss": 0.6515,
      "step": 445850
    },
    {
      "epoch": 4.720512806940468,
      "grad_norm": 1.0936994552612305,
      "learning_rate": 0.0003173662638121231,
      "loss": 0.6407,
      "step": 445900
    },
    {
      "epoch": 4.7210421287204705,
      "grad_norm": 0.9554452896118164,
      "learning_rate": 0.0003173217790234332,
      "loss": 0.6426,
      "step": 445950
    },
    {
      "epoch": 4.721571450500473,
      "grad_norm": 0.9884405732154846,
      "learning_rate": 0.00031727729193640244,
      "loss": 0.6456,
      "step": 446000
    },
    {
      "epoch": 4.721571450500473,
      "eval_loss": 0.43299347162246704,
      "eval_runtime": 46.8199,
      "eval_samples_per_second": 3586.72,
      "eval_steps_per_second": 448.356,
      "step": 446000
    },
    {
      "epoch": 4.722100772280477,
      "grad_norm": 0.9285850524902344,
      "learning_rate": 0.0003172328025525496,
      "loss": 0.6432,
      "step": 446050
    },
    {
      "epoch": 4.72263009406048,
      "grad_norm": 1.0975755453109741,
      "learning_rate": 0.00031718831087339364,
      "loss": 0.6372,
      "step": 446100
    },
    {
      "epoch": 4.723159415840484,
      "grad_norm": 1.1412078142166138,
      "learning_rate": 0.00031714381690045324,
      "loss": 0.6455,
      "step": 446150
    },
    {
      "epoch": 4.723688737620487,
      "grad_norm": 1.0406239032745361,
      "learning_rate": 0.0003170993206352477,
      "loss": 0.654,
      "step": 446200
    },
    {
      "epoch": 4.72421805940049,
      "grad_norm": 1.0619932413101196,
      "learning_rate": 0.0003170548220792958,
      "loss": 0.6513,
      "step": 446250
    },
    {
      "epoch": 4.724747381180493,
      "grad_norm": 1.075839638710022,
      "learning_rate": 0.000317010321234117,
      "loss": 0.6402,
      "step": 446300
    },
    {
      "epoch": 4.725276702960497,
      "grad_norm": 1.0308603048324585,
      "learning_rate": 0.00031696581810123037,
      "loss": 0.6549,
      "step": 446350
    },
    {
      "epoch": 4.7258060247405,
      "grad_norm": 1.0194429159164429,
      "learning_rate": 0.00031692131268215524,
      "loss": 0.6489,
      "step": 446400
    },
    {
      "epoch": 4.726335346520504,
      "grad_norm": 1.0361942052841187,
      "learning_rate": 0.0003168768049784111,
      "loss": 0.6458,
      "step": 446450
    },
    {
      "epoch": 4.7268646683005064,
      "grad_norm": 1.0978907346725464,
      "learning_rate": 0.0003168322949915173,
      "loss": 0.638,
      "step": 446500
    },
    {
      "epoch": 4.7268646683005064,
      "eval_loss": 0.4347950518131256,
      "eval_runtime": 46.7938,
      "eval_samples_per_second": 3588.727,
      "eval_steps_per_second": 448.607,
      "step": 446500
    },
    {
      "epoch": 4.72739399008051,
      "grad_norm": 1.0821623802185059,
      "learning_rate": 0.0003167877827229935,
      "loss": 0.6441,
      "step": 446550
    },
    {
      "epoch": 4.727923311860513,
      "grad_norm": 1.081161618232727,
      "learning_rate": 0.00031674326817435926,
      "loss": 0.6587,
      "step": 446600
    },
    {
      "epoch": 4.728452633640517,
      "grad_norm": 1.1176804304122925,
      "learning_rate": 0.00031669875134713427,
      "loss": 0.6513,
      "step": 446650
    },
    {
      "epoch": 4.72898195542052,
      "grad_norm": 1.0534026622772217,
      "learning_rate": 0.0003166542322428384,
      "loss": 0.6351,
      "step": 446700
    },
    {
      "epoch": 4.729511277200523,
      "grad_norm": 1.0289826393127441,
      "learning_rate": 0.00031660971086299155,
      "loss": 0.6398,
      "step": 446750
    },
    {
      "epoch": 4.730040598980526,
      "grad_norm": 1.0413614511489868,
      "learning_rate": 0.0003165651872091136,
      "loss": 0.6487,
      "step": 446800
    },
    {
      "epoch": 4.730569920760529,
      "grad_norm": 1.0204293727874756,
      "learning_rate": 0.0003165206612827245,
      "loss": 0.6385,
      "step": 446850
    },
    {
      "epoch": 4.731099242540533,
      "grad_norm": 1.002210259437561,
      "learning_rate": 0.0003164761330853445,
      "loss": 0.6397,
      "step": 446900
    },
    {
      "epoch": 4.731628564320536,
      "grad_norm": 1.0391210317611694,
      "learning_rate": 0.0003164316026184936,
      "loss": 0.6358,
      "step": 446950
    },
    {
      "epoch": 4.73215788610054,
      "grad_norm": 1.0366132259368896,
      "learning_rate": 0.00031638706988369226,
      "loss": 0.6475,
      "step": 447000
    },
    {
      "epoch": 4.73215788610054,
      "eval_loss": 0.4332537055015564,
      "eval_runtime": 46.8233,
      "eval_samples_per_second": 3586.465,
      "eval_steps_per_second": 448.324,
      "step": 447000
    },
    {
      "epoch": 4.732687207880542,
      "grad_norm": 0.9500578045845032,
      "learning_rate": 0.0003163425348824607,
      "loss": 0.6472,
      "step": 447050
    },
    {
      "epoch": 4.733216529660546,
      "grad_norm": 1.0043976306915283,
      "learning_rate": 0.0003162979976163192,
      "loss": 0.6416,
      "step": 447100
    },
    {
      "epoch": 4.733745851440549,
      "grad_norm": 1.0974870920181274,
      "learning_rate": 0.00031625345808678845,
      "loss": 0.6323,
      "step": 447150
    },
    {
      "epoch": 4.734275173220553,
      "grad_norm": 1.0109864473342896,
      "learning_rate": 0.00031620891629538896,
      "loss": 0.6516,
      "step": 447200
    },
    {
      "epoch": 4.734804495000556,
      "grad_norm": 1.0026847124099731,
      "learning_rate": 0.00031616437224364136,
      "loss": 0.6411,
      "step": 447250
    },
    {
      "epoch": 4.735333816780559,
      "grad_norm": 1.0636295080184937,
      "learning_rate": 0.0003161198259330663,
      "loss": 0.6517,
      "step": 447300
    },
    {
      "epoch": 4.735863138560562,
      "grad_norm": 1.1467872858047485,
      "learning_rate": 0.00031607527736518467,
      "loss": 0.6529,
      "step": 447350
    },
    {
      "epoch": 4.736392460340566,
      "grad_norm": 0.9358373284339905,
      "learning_rate": 0.00031603072654151735,
      "loss": 0.6456,
      "step": 447400
    },
    {
      "epoch": 4.736921782120569,
      "grad_norm": 0.9844328165054321,
      "learning_rate": 0.00031598617346358516,
      "loss": 0.649,
      "step": 447450
    },
    {
      "epoch": 4.737451103900572,
      "grad_norm": 0.9910088777542114,
      "learning_rate": 0.0003159416181329091,
      "loss": 0.6383,
      "step": 447500
    },
    {
      "epoch": 4.737451103900572,
      "eval_loss": 0.4333629012107849,
      "eval_runtime": 46.9134,
      "eval_samples_per_second": 3579.576,
      "eval_steps_per_second": 447.463,
      "step": 447500
    },
    {
      "epoch": 4.7379804256805755,
      "grad_norm": 0.999631941318512,
      "learning_rate": 0.00031589706055101054,
      "loss": 0.6356,
      "step": 447550
    },
    {
      "epoch": 4.738509747460578,
      "grad_norm": 1.00325345993042,
      "learning_rate": 0.0003158525007194105,
      "loss": 0.6499,
      "step": 447600
    },
    {
      "epoch": 4.739039069240582,
      "grad_norm": 1.1054210662841797,
      "learning_rate": 0.0003158079386396302,
      "loss": 0.6376,
      "step": 447650
    },
    {
      "epoch": 4.739568391020585,
      "grad_norm": 1.0321763753890991,
      "learning_rate": 0.000315763374313191,
      "loss": 0.6428,
      "step": 447700
    },
    {
      "epoch": 4.740097712800589,
      "grad_norm": 0.9780460596084595,
      "learning_rate": 0.00031571880774161436,
      "loss": 0.6463,
      "step": 447750
    },
    {
      "epoch": 4.740627034580592,
      "grad_norm": 1.0353949069976807,
      "learning_rate": 0.0003156742389264217,
      "loss": 0.6395,
      "step": 447800
    },
    {
      "epoch": 4.741156356360595,
      "grad_norm": 0.9897445440292358,
      "learning_rate": 0.0003156296678691346,
      "loss": 0.6562,
      "step": 447850
    },
    {
      "epoch": 4.741685678140598,
      "grad_norm": 1.0619152784347534,
      "learning_rate": 0.0003155850945712747,
      "loss": 0.6454,
      "step": 447900
    },
    {
      "epoch": 4.742214999920602,
      "grad_norm": 1.0274115800857544,
      "learning_rate": 0.0003155405190343638,
      "loss": 0.6439,
      "step": 447950
    },
    {
      "epoch": 4.742744321700605,
      "grad_norm": 1.1786741018295288,
      "learning_rate": 0.0003154959412599235,
      "loss": 0.6393,
      "step": 448000
    },
    {
      "epoch": 4.742744321700605,
      "eval_loss": 0.43355119228363037,
      "eval_runtime": 46.9336,
      "eval_samples_per_second": 3578.036,
      "eval_steps_per_second": 447.27,
      "step": 448000
    },
    {
      "epoch": 4.743273643480609,
      "grad_norm": 1.0846960544586182,
      "learning_rate": 0.0003154513612494759,
      "loss": 0.6476,
      "step": 448050
    },
    {
      "epoch": 4.7438029652606115,
      "grad_norm": 1.1052513122558594,
      "learning_rate": 0.00031540677900454274,
      "loss": 0.6398,
      "step": 448100
    },
    {
      "epoch": 4.744332287040615,
      "grad_norm": 1.0523086786270142,
      "learning_rate": 0.00031536219452664617,
      "loss": 0.6334,
      "step": 448150
    },
    {
      "epoch": 4.744861608820618,
      "grad_norm": 0.9117486476898193,
      "learning_rate": 0.0003153176078173083,
      "loss": 0.6451,
      "step": 448200
    },
    {
      "epoch": 4.745390930600621,
      "grad_norm": 1.0205693244934082,
      "learning_rate": 0.00031527301887805117,
      "loss": 0.6481,
      "step": 448250
    },
    {
      "epoch": 4.745920252380625,
      "grad_norm": 1.000280737876892,
      "learning_rate": 0.00031522842771039707,
      "loss": 0.6398,
      "step": 448300
    },
    {
      "epoch": 4.746449574160628,
      "grad_norm": 0.9270477890968323,
      "learning_rate": 0.0003151838343158684,
      "loss": 0.6425,
      "step": 448350
    },
    {
      "epoch": 4.746978895940631,
      "grad_norm": 1.112989902496338,
      "learning_rate": 0.00031513923869598765,
      "loss": 0.646,
      "step": 448400
    },
    {
      "epoch": 4.747508217720634,
      "grad_norm": 0.8999147415161133,
      "learning_rate": 0.00031509464085227714,
      "loss": 0.6558,
      "step": 448450
    },
    {
      "epoch": 4.748037539500638,
      "grad_norm": 1.1730709075927734,
      "learning_rate": 0.0003150500407862594,
      "loss": 0.6536,
      "step": 448500
    },
    {
      "epoch": 4.748037539500638,
      "eval_loss": 0.4346882402896881,
      "eval_runtime": 46.9511,
      "eval_samples_per_second": 3576.697,
      "eval_steps_per_second": 447.103,
      "step": 448500
    },
    {
      "epoch": 4.748566861280641,
      "grad_norm": 0.9889456033706665,
      "learning_rate": 0.0003150054384994571,
      "loss": 0.6498,
      "step": 448550
    },
    {
      "epoch": 4.749096183060645,
      "grad_norm": 1.168084740638733,
      "learning_rate": 0.00031496083399339304,
      "loss": 0.653,
      "step": 448600
    },
    {
      "epoch": 4.7496255048406475,
      "grad_norm": 0.9790117144584656,
      "learning_rate": 0.0003149162272695899,
      "loss": 0.6381,
      "step": 448650
    },
    {
      "epoch": 4.750154826620651,
      "grad_norm": 0.9967889189720154,
      "learning_rate": 0.00031487161832957064,
      "loss": 0.647,
      "step": 448700
    },
    {
      "epoch": 4.750684148400654,
      "grad_norm": 1.0182924270629883,
      "learning_rate": 0.00031482700717485804,
      "loss": 0.6507,
      "step": 448750
    },
    {
      "epoch": 4.751213470180658,
      "grad_norm": 1.0714486837387085,
      "learning_rate": 0.0003147823938069752,
      "loss": 0.6434,
      "step": 448800
    },
    {
      "epoch": 4.751742791960661,
      "grad_norm": 0.9912703037261963,
      "learning_rate": 0.0003147377782274452,
      "loss": 0.6481,
      "step": 448850
    },
    {
      "epoch": 4.7522721137406645,
      "grad_norm": 0.9454829096794128,
      "learning_rate": 0.0003146931604377912,
      "loss": 0.6463,
      "step": 448900
    },
    {
      "epoch": 4.752801435520667,
      "grad_norm": 1.057968258857727,
      "learning_rate": 0.00031464854043953644,
      "loss": 0.6487,
      "step": 448950
    },
    {
      "epoch": 4.75333075730067,
      "grad_norm": 1.0420700311660767,
      "learning_rate": 0.0003146048106999304,
      "loss": 0.6497,
      "step": 449000
    },
    {
      "epoch": 4.75333075730067,
      "eval_loss": 0.43343761563301086,
      "eval_runtime": 46.9531,
      "eval_samples_per_second": 3576.548,
      "eval_steps_per_second": 447.085,
      "step": 449000
    },
    {
      "epoch": 4.753860079080674,
      "grad_norm": 1.1041380167007446,
      "learning_rate": 0.0003145601863331402,
      "loss": 0.6547,
      "step": 449050
    },
    {
      "epoch": 4.754389400860677,
      "grad_norm": 1.038586974143982,
      "learning_rate": 0.00031451555976228895,
      "loss": 0.64,
      "step": 449100
    },
    {
      "epoch": 4.754918722640681,
      "grad_norm": 1.0340659618377686,
      "learning_rate": 0.0003144709309889002,
      "loss": 0.6503,
      "step": 449150
    },
    {
      "epoch": 4.7554480444206835,
      "grad_norm": 1.0432260036468506,
      "learning_rate": 0.00031442630001449743,
      "loss": 0.6528,
      "step": 449200
    },
    {
      "epoch": 4.755977366200687,
      "grad_norm": 1.0821707248687744,
      "learning_rate": 0.00031438166684060446,
      "loss": 0.6463,
      "step": 449250
    },
    {
      "epoch": 4.75650668798069,
      "grad_norm": 1.068036675453186,
      "learning_rate": 0.00031433703146874496,
      "loss": 0.6609,
      "step": 449300
    },
    {
      "epoch": 4.757036009760694,
      "grad_norm": 1.106497883796692,
      "learning_rate": 0.00031429239390044284,
      "loss": 0.6544,
      "step": 449350
    },
    {
      "epoch": 4.757565331540697,
      "grad_norm": 1.0981779098510742,
      "learning_rate": 0.00031424775413722194,
      "loss": 0.6456,
      "step": 449400
    },
    {
      "epoch": 4.7580946533207005,
      "grad_norm": 1.0627329349517822,
      "learning_rate": 0.0003142031121806063,
      "loss": 0.6531,
      "step": 449450
    },
    {
      "epoch": 4.758623975100703,
      "grad_norm": 1.1854914426803589,
      "learning_rate": 0.00031415846803211993,
      "loss": 0.6407,
      "step": 449500
    },
    {
      "epoch": 4.758623975100703,
      "eval_loss": 0.4327542185783386,
      "eval_runtime": 46.9451,
      "eval_samples_per_second": 3577.158,
      "eval_steps_per_second": 447.161,
      "step": 449500
    },
    {
      "epoch": 4.759153296880707,
      "grad_norm": 1.1087075471878052,
      "learning_rate": 0.00031411382169328696,
      "loss": 0.6427,
      "step": 449550
    },
    {
      "epoch": 4.75968261866071,
      "grad_norm": 1.0539683103561401,
      "learning_rate": 0.0003140691731656317,
      "loss": 0.6342,
      "step": 449600
    },
    {
      "epoch": 4.760211940440714,
      "grad_norm": 1.046143651008606,
      "learning_rate": 0.00031402452245067836,
      "loss": 0.6419,
      "step": 449650
    },
    {
      "epoch": 4.760741262220717,
      "grad_norm": 0.9551661610603333,
      "learning_rate": 0.0003139798695499513,
      "loss": 0.6467,
      "step": 449700
    },
    {
      "epoch": 4.7612705840007195,
      "grad_norm": 1.1719783544540405,
      "learning_rate": 0.0003139352144649749,
      "loss": 0.6519,
      "step": 449750
    },
    {
      "epoch": 4.761799905780723,
      "grad_norm": 1.1792476177215576,
      "learning_rate": 0.00031389055719727377,
      "loss": 0.6384,
      "step": 449800
    },
    {
      "epoch": 4.762329227560726,
      "grad_norm": 1.020655632019043,
      "learning_rate": 0.0003138458977483725,
      "loss": 0.6378,
      "step": 449850
    },
    {
      "epoch": 4.76285854934073,
      "grad_norm": 1.1464327573776245,
      "learning_rate": 0.0003138012361197956,
      "loss": 0.6461,
      "step": 449900
    },
    {
      "epoch": 4.763387871120733,
      "grad_norm": 0.9699414968490601,
      "learning_rate": 0.0003137565723130679,
      "loss": 0.6309,
      "step": 449950
    },
    {
      "epoch": 4.7639171929007365,
      "grad_norm": 0.9079487323760986,
      "learning_rate": 0.00031371190632971423,
      "loss": 0.6459,
      "step": 450000
    },
    {
      "epoch": 4.7639171929007365,
      "eval_loss": 0.43374568223953247,
      "eval_runtime": 46.9023,
      "eval_samples_per_second": 3580.422,
      "eval_steps_per_second": 447.569,
      "step": 450000
    },
    {
      "epoch": 4.764446514680739,
      "grad_norm": 1.1057180166244507,
      "learning_rate": 0.00031366723817125947,
      "loss": 0.644,
      "step": 450050
    },
    {
      "epoch": 4.764975836460743,
      "grad_norm": 0.975021481513977,
      "learning_rate": 0.00031362256783922855,
      "loss": 0.6501,
      "step": 450100
    },
    {
      "epoch": 4.765505158240746,
      "grad_norm": 0.9693819880485535,
      "learning_rate": 0.00031357789533514646,
      "loss": 0.6388,
      "step": 450150
    },
    {
      "epoch": 4.76603448002075,
      "grad_norm": 1.1203210353851318,
      "learning_rate": 0.00031353322066053835,
      "loss": 0.6497,
      "step": 450200
    },
    {
      "epoch": 4.766563801800753,
      "grad_norm": 1.01619553565979,
      "learning_rate": 0.0003134885438169294,
      "loss": 0.6442,
      "step": 450250
    },
    {
      "epoch": 4.767093123580756,
      "grad_norm": 1.02936851978302,
      "learning_rate": 0.0003134438648058449,
      "loss": 0.651,
      "step": 450300
    },
    {
      "epoch": 4.767622445360759,
      "grad_norm": 1.0693517923355103,
      "learning_rate": 0.00031339918362881,
      "loss": 0.6518,
      "step": 450350
    },
    {
      "epoch": 4.768151767140763,
      "grad_norm": 1.062922477722168,
      "learning_rate": 0.0003133545002873503,
      "loss": 0.6391,
      "step": 450400
    },
    {
      "epoch": 4.768681088920766,
      "grad_norm": 1.105513572692871,
      "learning_rate": 0.00031330981478299114,
      "loss": 0.6449,
      "step": 450450
    },
    {
      "epoch": 4.769210410700769,
      "grad_norm": 1.1847611665725708,
      "learning_rate": 0.0003132651271172582,
      "loss": 0.6432,
      "step": 450500
    },
    {
      "epoch": 4.769210410700769,
      "eval_loss": 0.4346768260002136,
      "eval_runtime": 46.8226,
      "eval_samples_per_second": 3586.514,
      "eval_steps_per_second": 448.33,
      "step": 450500
    },
    {
      "epoch": 4.769739732480772,
      "grad_norm": 0.9788568615913391,
      "learning_rate": 0.000313220437291677,
      "loss": 0.6493,
      "step": 450550
    },
    {
      "epoch": 4.770269054260775,
      "grad_norm": 1.0559855699539185,
      "learning_rate": 0.0003131757453077732,
      "loss": 0.6464,
      "step": 450600
    },
    {
      "epoch": 4.770798376040779,
      "grad_norm": 1.1592645645141602,
      "learning_rate": 0.0003131310511670727,
      "loss": 0.6507,
      "step": 450650
    },
    {
      "epoch": 4.771327697820782,
      "grad_norm": 1.08988618850708,
      "learning_rate": 0.0003130863548711012,
      "loss": 0.6386,
      "step": 450700
    },
    {
      "epoch": 4.771857019600786,
      "grad_norm": 1.0300477743148804,
      "learning_rate": 0.0003130416564213847,
      "loss": 0.6397,
      "step": 450750
    },
    {
      "epoch": 4.7723863413807885,
      "grad_norm": 1.0082169771194458,
      "learning_rate": 0.0003129969558194492,
      "loss": 0.6305,
      "step": 450800
    },
    {
      "epoch": 4.772915663160792,
      "grad_norm": 1.0063892602920532,
      "learning_rate": 0.0003129522530668207,
      "loss": 0.6475,
      "step": 450850
    },
    {
      "epoch": 4.773444984940795,
      "grad_norm": 1.0304166078567505,
      "learning_rate": 0.00031290754816502543,
      "loss": 0.6429,
      "step": 450900
    },
    {
      "epoch": 4.773974306720799,
      "grad_norm": 1.04117751121521,
      "learning_rate": 0.00031286284111558946,
      "loss": 0.6554,
      "step": 450950
    },
    {
      "epoch": 4.774503628500802,
      "grad_norm": 1.0571367740631104,
      "learning_rate": 0.00031281902612497224,
      "loss": 0.6458,
      "step": 451000
    },
    {
      "epoch": 4.774503628500802,
      "eval_loss": 0.4339115023612976,
      "eval_runtime": 46.8035,
      "eval_samples_per_second": 3587.982,
      "eval_steps_per_second": 448.514,
      "step": 451000
    },
    {
      "epoch": 4.7750329502808055,
      "grad_norm": 0.9626506567001343,
      "learning_rate": 0.0003127743148277108,
      "loss": 0.6442,
      "step": 451050
    },
    {
      "epoch": 4.775562272060808,
      "grad_norm": 1.024126648902893,
      "learning_rate": 0.0003127296013873572,
      "loss": 0.6352,
      "step": 451100
    },
    {
      "epoch": 4.776091593840812,
      "grad_norm": 1.0302104949951172,
      "learning_rate": 0.0003126848858054381,
      "loss": 0.6425,
      "step": 451150
    },
    {
      "epoch": 4.776620915620815,
      "grad_norm": 1.0637577772140503,
      "learning_rate": 0.00031264016808347996,
      "loss": 0.6497,
      "step": 451200
    },
    {
      "epoch": 4.777150237400818,
      "grad_norm": 1.080617904663086,
      "learning_rate": 0.0003125954482230095,
      "loss": 0.6276,
      "step": 451250
    },
    {
      "epoch": 4.777679559180822,
      "grad_norm": 0.9311171770095825,
      "learning_rate": 0.00031255072622555325,
      "loss": 0.6417,
      "step": 451300
    },
    {
      "epoch": 4.7782088809608245,
      "grad_norm": 1.0927674770355225,
      "learning_rate": 0.00031250600209263823,
      "loss": 0.6341,
      "step": 451350
    },
    {
      "epoch": 4.778738202740828,
      "grad_norm": 1.0785435438156128,
      "learning_rate": 0.0003124612758257912,
      "loss": 0.6288,
      "step": 451400
    },
    {
      "epoch": 4.779267524520831,
      "grad_norm": 1.0795748233795166,
      "learning_rate": 0.00031241654742653914,
      "loss": 0.6439,
      "step": 451450
    },
    {
      "epoch": 4.779796846300835,
      "grad_norm": 1.0327627658843994,
      "learning_rate": 0.00031237181689640906,
      "loss": 0.6362,
      "step": 451500
    },
    {
      "epoch": 4.779796846300835,
      "eval_loss": 0.43169599771499634,
      "eval_runtime": 46.952,
      "eval_samples_per_second": 3576.634,
      "eval_steps_per_second": 447.095,
      "step": 451500
    },
    {
      "epoch": 4.780326168080838,
      "grad_norm": 1.0831071138381958,
      "learning_rate": 0.00031232708423692803,
      "loss": 0.6356,
      "step": 451550
    },
    {
      "epoch": 4.7808554898608415,
      "grad_norm": 0.9938797354698181,
      "learning_rate": 0.00031228234944962314,
      "loss": 0.6472,
      "step": 451600
    },
    {
      "epoch": 4.781384811640844,
      "grad_norm": 0.9720876812934875,
      "learning_rate": 0.00031223761253602173,
      "loss": 0.6411,
      "step": 451650
    },
    {
      "epoch": 4.781914133420848,
      "grad_norm": 1.0326008796691895,
      "learning_rate": 0.0003121928734976511,
      "loss": 0.6567,
      "step": 451700
    },
    {
      "epoch": 4.782443455200851,
      "grad_norm": 1.1074382066726685,
      "learning_rate": 0.0003121481323360385,
      "loss": 0.6455,
      "step": 451750
    },
    {
      "epoch": 4.782972776980855,
      "grad_norm": 1.034837245941162,
      "learning_rate": 0.0003121033890527114,
      "loss": 0.6385,
      "step": 451800
    },
    {
      "epoch": 4.783502098760858,
      "grad_norm": 1.1169804334640503,
      "learning_rate": 0.00031205864364919746,
      "loss": 0.6426,
      "step": 451850
    },
    {
      "epoch": 4.784031420540861,
      "grad_norm": 1.0387204885482788,
      "learning_rate": 0.0003120138961270242,
      "loss": 0.6361,
      "step": 451900
    },
    {
      "epoch": 4.784560742320864,
      "grad_norm": 1.1038334369659424,
      "learning_rate": 0.00031196914648771925,
      "loss": 0.6497,
      "step": 451950
    },
    {
      "epoch": 4.785090064100867,
      "grad_norm": 1.119228720664978,
      "learning_rate": 0.0003119243947328104,
      "loss": 0.6297,
      "step": 452000
    },
    {
      "epoch": 4.785090064100867,
      "eval_loss": 0.4297090470790863,
      "eval_runtime": 46.8755,
      "eval_samples_per_second": 3582.469,
      "eval_steps_per_second": 447.825,
      "step": 452000
    },
    {
      "epoch": 4.785619385880871,
      "grad_norm": 1.0217589139938354,
      "learning_rate": 0.00031187964086382537,
      "loss": 0.6398,
      "step": 452050
    },
    {
      "epoch": 4.786148707660874,
      "grad_norm": 1.0032374858856201,
      "learning_rate": 0.00031183488488229204,
      "loss": 0.6441,
      "step": 452100
    },
    {
      "epoch": 4.7866780294408775,
      "grad_norm": 0.980087161064148,
      "learning_rate": 0.00031179012678973853,
      "loss": 0.6501,
      "step": 452150
    },
    {
      "epoch": 4.78720735122088,
      "grad_norm": 0.9731385707855225,
      "learning_rate": 0.0003117453665876927,
      "loss": 0.6388,
      "step": 452200
    },
    {
      "epoch": 4.787736673000884,
      "grad_norm": 1.0621211528778076,
      "learning_rate": 0.00031170060427768273,
      "loss": 0.6346,
      "step": 452250
    },
    {
      "epoch": 4.788265994780887,
      "grad_norm": 1.0407096147537231,
      "learning_rate": 0.00031165583986123675,
      "loss": 0.6309,
      "step": 452300
    },
    {
      "epoch": 4.788795316560891,
      "grad_norm": 1.0406248569488525,
      "learning_rate": 0.000311611073339883,
      "loss": 0.6437,
      "step": 452350
    },
    {
      "epoch": 4.789324638340894,
      "grad_norm": 0.9434936046600342,
      "learning_rate": 0.0003115663047151498,
      "loss": 0.6436,
      "step": 452400
    },
    {
      "epoch": 4.789853960120897,
      "grad_norm": 0.9158893823623657,
      "learning_rate": 0.00031152153398856554,
      "loss": 0.6317,
      "step": 452450
    },
    {
      "epoch": 4.7903832819009,
      "grad_norm": 1.0632940530776978,
      "learning_rate": 0.0003114767611616587,
      "loss": 0.6468,
      "step": 452500
    },
    {
      "epoch": 4.7903832819009,
      "eval_loss": 0.4307042062282562,
      "eval_runtime": 46.8775,
      "eval_samples_per_second": 3582.315,
      "eval_steps_per_second": 447.805,
      "step": 452500
    },
    {
      "epoch": 4.790912603680904,
      "grad_norm": 1.0352565050125122,
      "learning_rate": 0.0003114319862359577,
      "loss": 0.6565,
      "step": 452550
    },
    {
      "epoch": 4.791441925460907,
      "grad_norm": 1.0985201597213745,
      "learning_rate": 0.0003113872092129912,
      "loss": 0.6487,
      "step": 452600
    },
    {
      "epoch": 4.791971247240911,
      "grad_norm": 1.111708402633667,
      "learning_rate": 0.00031134243009428797,
      "loss": 0.6379,
      "step": 452650
    },
    {
      "epoch": 4.7925005690209135,
      "grad_norm": 1.0681781768798828,
      "learning_rate": 0.0003112976488813767,
      "loss": 0.6347,
      "step": 452700
    },
    {
      "epoch": 4.793029890800916,
      "grad_norm": 1.0744839906692505,
      "learning_rate": 0.0003112528655757861,
      "loss": 0.6406,
      "step": 452750
    },
    {
      "epoch": 4.79355921258092,
      "grad_norm": 1.1657251119613647,
      "learning_rate": 0.0003112080801790452,
      "loss": 0.6524,
      "step": 452800
    },
    {
      "epoch": 4.794088534360923,
      "grad_norm": 0.9835745096206665,
      "learning_rate": 0.00031116329269268285,
      "loss": 0.6389,
      "step": 452850
    },
    {
      "epoch": 4.794617856140927,
      "grad_norm": 1.1240028142929077,
      "learning_rate": 0.0003111185031182281,
      "loss": 0.6489,
      "step": 452900
    },
    {
      "epoch": 4.79514717792093,
      "grad_norm": 0.9507671594619751,
      "learning_rate": 0.0003110737114572101,
      "loss": 0.6455,
      "step": 452950
    },
    {
      "epoch": 4.795676499700933,
      "grad_norm": 1.1093482971191406,
      "learning_rate": 0.00031102891771115797,
      "loss": 0.6497,
      "step": 453000
    },
    {
      "epoch": 4.795676499700933,
      "eval_loss": 0.43138477206230164,
      "eval_runtime": 46.964,
      "eval_samples_per_second": 3575.718,
      "eval_steps_per_second": 446.981,
      "step": 453000
    },
    {
      "epoch": 4.796205821480936,
      "grad_norm": 1.1034672260284424,
      "learning_rate": 0.0003109850178186006,
      "loss": 0.6416,
      "step": 453050
    },
    {
      "epoch": 4.79673514326094,
      "grad_norm": 1.0752707719802856,
      "learning_rate": 0.0003109402199486926,
      "loss": 0.6445,
      "step": 453100
    },
    {
      "epoch": 4.797264465040943,
      "grad_norm": 1.070000171661377,
      "learning_rate": 0.00031089541999830783,
      "loss": 0.6676,
      "step": 453150
    },
    {
      "epoch": 4.797793786820947,
      "grad_norm": 0.9322772026062012,
      "learning_rate": 0.00031085061796897574,
      "loss": 0.6416,
      "step": 453200
    },
    {
      "epoch": 4.7983231086009495,
      "grad_norm": 1.1288522481918335,
      "learning_rate": 0.0003108058138622259,
      "loss": 0.6418,
      "step": 453250
    },
    {
      "epoch": 4.798852430380953,
      "grad_norm": 1.1325721740722656,
      "learning_rate": 0.0003107610076795878,
      "loss": 0.6312,
      "step": 453300
    },
    {
      "epoch": 4.799381752160956,
      "grad_norm": 1.114231824874878,
      "learning_rate": 0.0003107161994225913,
      "loss": 0.6461,
      "step": 453350
    },
    {
      "epoch": 4.79991107394096,
      "grad_norm": 1.052556037902832,
      "learning_rate": 0.0003106713890927659,
      "loss": 0.6472,
      "step": 453400
    },
    {
      "epoch": 4.800440395720963,
      "grad_norm": 1.1240458488464355,
      "learning_rate": 0.00031062657669164164,
      "loss": 0.6361,
      "step": 453450
    },
    {
      "epoch": 4.800969717500966,
      "grad_norm": 1.002849817276001,
      "learning_rate": 0.0003105817622207482,
      "loss": 0.6499,
      "step": 453500
    },
    {
      "epoch": 4.800969717500966,
      "eval_loss": 0.42905735969543457,
      "eval_runtime": 46.8183,
      "eval_samples_per_second": 3586.848,
      "eval_steps_per_second": 448.372,
      "step": 453500
    },
    {
      "epoch": 4.801499039280969,
      "grad_norm": 0.9541341066360474,
      "learning_rate": 0.0003105369456816156,
      "loss": 0.6494,
      "step": 453550
    },
    {
      "epoch": 4.802028361060972,
      "grad_norm": 1.0638638734817505,
      "learning_rate": 0.00031049212707577394,
      "loss": 0.6555,
      "step": 453600
    },
    {
      "epoch": 4.802557682840976,
      "grad_norm": 0.9481087923049927,
      "learning_rate": 0.00031044730640475323,
      "loss": 0.6426,
      "step": 453650
    },
    {
      "epoch": 4.803087004620979,
      "grad_norm": 1.104929804801941,
      "learning_rate": 0.0003104024836700836,
      "loss": 0.6504,
      "step": 453700
    },
    {
      "epoch": 4.803616326400983,
      "grad_norm": 1.0839459896087646,
      "learning_rate": 0.0003103576588732954,
      "loss": 0.6418,
      "step": 453750
    },
    {
      "epoch": 4.804145648180985,
      "grad_norm": 0.9772513508796692,
      "learning_rate": 0.00031031283201591887,
      "loss": 0.6505,
      "step": 453800
    },
    {
      "epoch": 4.804674969960989,
      "grad_norm": 1.0084775686264038,
      "learning_rate": 0.00031026800309948426,
      "loss": 0.6445,
      "step": 453850
    },
    {
      "epoch": 4.805204291740992,
      "grad_norm": 0.9717179536819458,
      "learning_rate": 0.0003102231721255222,
      "loss": 0.6348,
      "step": 453900
    },
    {
      "epoch": 4.805733613520996,
      "grad_norm": 0.9697591662406921,
      "learning_rate": 0.00031017833909556314,
      "loss": 0.6384,
      "step": 453950
    },
    {
      "epoch": 4.806262935300999,
      "grad_norm": 1.0235062837600708,
      "learning_rate": 0.00031013350401113766,
      "loss": 0.6406,
      "step": 454000
    },
    {
      "epoch": 4.806262935300999,
      "eval_loss": 0.4306780993938446,
      "eval_runtime": 46.8837,
      "eval_samples_per_second": 3581.84,
      "eval_steps_per_second": 447.746,
      "step": 454000
    },
    {
      "epoch": 4.806792257081002,
      "grad_norm": 1.102575421333313,
      "learning_rate": 0.0003100886668737764,
      "loss": 0.6424,
      "step": 454050
    },
    {
      "epoch": 4.807321578861005,
      "grad_norm": 1.155349850654602,
      "learning_rate": 0.0003100438276850101,
      "loss": 0.6535,
      "step": 454100
    },
    {
      "epoch": 4.807850900641009,
      "grad_norm": 1.0482914447784424,
      "learning_rate": 0.0003099989864463695,
      "loss": 0.6411,
      "step": 454150
    },
    {
      "epoch": 4.808380222421012,
      "grad_norm": 1.0170444250106812,
      "learning_rate": 0.00030995414315938553,
      "loss": 0.6471,
      "step": 454200
    },
    {
      "epoch": 4.808909544201015,
      "grad_norm": 1.030775785446167,
      "learning_rate": 0.0003099092978255891,
      "loss": 0.6434,
      "step": 454250
    },
    {
      "epoch": 4.8094388659810186,
      "grad_norm": 1.0702588558197021,
      "learning_rate": 0.0003098644504465112,
      "loss": 0.6424,
      "step": 454300
    },
    {
      "epoch": 4.809968187761021,
      "grad_norm": 1.0508413314819336,
      "learning_rate": 0.00030981960102368294,
      "loss": 0.6365,
      "step": 454350
    },
    {
      "epoch": 4.810497509541025,
      "grad_norm": 0.9750394821166992,
      "learning_rate": 0.00030977474955863545,
      "loss": 0.6479,
      "step": 454400
    },
    {
      "epoch": 4.811026831321028,
      "grad_norm": 1.0054843425750732,
      "learning_rate": 0.0003097298960528999,
      "loss": 0.6385,
      "step": 454450
    },
    {
      "epoch": 4.811556153101032,
      "grad_norm": 1.0141221284866333,
      "learning_rate": 0.0003096850405080076,
      "loss": 0.6504,
      "step": 454500
    },
    {
      "epoch": 4.811556153101032,
      "eval_loss": 0.43152040243148804,
      "eval_runtime": 46.8413,
      "eval_samples_per_second": 3585.085,
      "eval_steps_per_second": 448.152,
      "step": 454500
    },
    {
      "epoch": 4.812085474881035,
      "grad_norm": 1.1228188276290894,
      "learning_rate": 0.00030964018292548994,
      "loss": 0.641,
      "step": 454550
    },
    {
      "epoch": 4.812614796661038,
      "grad_norm": 1.0760976076126099,
      "learning_rate": 0.0003095953233068783,
      "loss": 0.6399,
      "step": 454600
    },
    {
      "epoch": 4.813144118441041,
      "grad_norm": 1.000474452972412,
      "learning_rate": 0.00030955046165370416,
      "loss": 0.6476,
      "step": 454650
    },
    {
      "epoch": 4.813673440221045,
      "grad_norm": 0.9722874164581299,
      "learning_rate": 0.00030950559796749904,
      "loss": 0.647,
      "step": 454700
    },
    {
      "epoch": 4.814202762001048,
      "grad_norm": 1.0687744617462158,
      "learning_rate": 0.0003094607322497947,
      "loss": 0.6321,
      "step": 454750
    },
    {
      "epoch": 4.814732083781052,
      "grad_norm": 1.126888632774353,
      "learning_rate": 0.0003094158645021228,
      "loss": 0.6477,
      "step": 454800
    },
    {
      "epoch": 4.8152614055610545,
      "grad_norm": 1.056606411933899,
      "learning_rate": 0.00030937099472601505,
      "loss": 0.6445,
      "step": 454850
    },
    {
      "epoch": 4.815790727341058,
      "grad_norm": 1.0518585443496704,
      "learning_rate": 0.0003093261229230033,
      "loss": 0.6351,
      "step": 454900
    },
    {
      "epoch": 4.816320049121061,
      "grad_norm": 0.9945378303527832,
      "learning_rate": 0.00030928124909461945,
      "loss": 0.6489,
      "step": 454950
    },
    {
      "epoch": 4.816849370901064,
      "grad_norm": 0.9643844962120056,
      "learning_rate": 0.0003092363732423955,
      "loss": 0.6448,
      "step": 455000
    },
    {
      "epoch": 4.816849370901064,
      "eval_loss": 0.4299428164958954,
      "eval_runtime": 46.7685,
      "eval_samples_per_second": 3590.667,
      "eval_steps_per_second": 448.849,
      "step": 455000
    },
    {
      "epoch": 4.817378692681068,
      "grad_norm": 1.095057725906372,
      "learning_rate": 0.00030919149536786354,
      "loss": 0.6464,
      "step": 455050
    },
    {
      "epoch": 4.817908014461071,
      "grad_norm": 1.069634199142456,
      "learning_rate": 0.00030914751309025546,
      "loss": 0.6333,
      "step": 455100
    },
    {
      "epoch": 4.818437336241074,
      "grad_norm": 1.0845129489898682,
      "learning_rate": 0.0003091026312160736,
      "loss": 0.6398,
      "step": 455150
    },
    {
      "epoch": 4.818966658021077,
      "grad_norm": 1.0729986429214478,
      "learning_rate": 0.00030905774732414967,
      "loss": 0.6375,
      "step": 455200
    },
    {
      "epoch": 4.819495979801081,
      "grad_norm": 1.0349804162979126,
      "learning_rate": 0.00030901286141601583,
      "loss": 0.6389,
      "step": 455250
    },
    {
      "epoch": 4.820025301581084,
      "grad_norm": 1.0344464778900146,
      "learning_rate": 0.00030896797349320456,
      "loss": 0.649,
      "step": 455300
    },
    {
      "epoch": 4.820554623361088,
      "grad_norm": 1.0296303033828735,
      "learning_rate": 0.0003089230835572483,
      "loss": 0.6441,
      "step": 455350
    },
    {
      "epoch": 4.8210839451410905,
      "grad_norm": 1.2002941370010376,
      "learning_rate": 0.00030887819160967957,
      "loss": 0.6484,
      "step": 455400
    },
    {
      "epoch": 4.821613266921094,
      "grad_norm": 0.9885190725326538,
      "learning_rate": 0.000308833297652031,
      "loss": 0.6504,
      "step": 455450
    },
    {
      "epoch": 4.822142588701097,
      "grad_norm": 1.1512197256088257,
      "learning_rate": 0.00030878840168583515,
      "loss": 0.6383,
      "step": 455500
    },
    {
      "epoch": 4.822142588701097,
      "eval_loss": 0.4287092685699463,
      "eval_runtime": 46.9069,
      "eval_samples_per_second": 3580.069,
      "eval_steps_per_second": 447.525,
      "step": 455500
    },
    {
      "epoch": 4.822671910481101,
      "grad_norm": 1.1363699436187744,
      "learning_rate": 0.00030874350371262494,
      "loss": 0.6401,
      "step": 455550
    },
    {
      "epoch": 4.823201232261104,
      "grad_norm": 1.1189576387405396,
      "learning_rate": 0.000308698603733933,
      "loss": 0.6418,
      "step": 455600
    },
    {
      "epoch": 4.8237305540411075,
      "grad_norm": 1.1620064973831177,
      "learning_rate": 0.00030865370175129226,
      "loss": 0.6471,
      "step": 455650
    },
    {
      "epoch": 4.82425987582111,
      "grad_norm": 1.0205204486846924,
      "learning_rate": 0.00030860879776623565,
      "loss": 0.6522,
      "step": 455700
    },
    {
      "epoch": 4.824789197601113,
      "grad_norm": 1.0758286714553833,
      "learning_rate": 0.0003085638917802961,
      "loss": 0.6399,
      "step": 455750
    },
    {
      "epoch": 4.825318519381117,
      "grad_norm": 1.1132893562316895,
      "learning_rate": 0.00030851898379500686,
      "loss": 0.6302,
      "step": 455800
    },
    {
      "epoch": 4.825847841161121,
      "grad_norm": 1.0099332332611084,
      "learning_rate": 0.00030847407381190097,
      "loss": 0.6505,
      "step": 455850
    },
    {
      "epoch": 4.826377162941124,
      "grad_norm": 1.1322709321975708,
      "learning_rate": 0.00030842916183251157,
      "loss": 0.6362,
      "step": 455900
    },
    {
      "epoch": 4.8269064847211265,
      "grad_norm": 1.1429392099380493,
      "learning_rate": 0.0003083842478583721,
      "loss": 0.6396,
      "step": 455950
    },
    {
      "epoch": 4.82743580650113,
      "grad_norm": 1.0573886632919312,
      "learning_rate": 0.0003083393318910158,
      "loss": 0.6434,
      "step": 456000
    },
    {
      "epoch": 4.82743580650113,
      "eval_loss": 0.4291394054889679,
      "eval_runtime": 46.8299,
      "eval_samples_per_second": 3585.957,
      "eval_steps_per_second": 448.261,
      "step": 456000
    },
    {
      "epoch": 4.827965128281133,
      "grad_norm": 1.081952452659607,
      "learning_rate": 0.00030829441393197607,
      "loss": 0.6282,
      "step": 456050
    },
    {
      "epoch": 4.828494450061137,
      "grad_norm": 1.0302926301956177,
      "learning_rate": 0.00030824949398278645,
      "loss": 0.6362,
      "step": 456100
    },
    {
      "epoch": 4.82902377184114,
      "grad_norm": 1.0627790689468384,
      "learning_rate": 0.00030820457204498047,
      "loss": 0.634,
      "step": 456150
    },
    {
      "epoch": 4.8295530936211435,
      "grad_norm": 1.014624834060669,
      "learning_rate": 0.00030815964812009174,
      "loss": 0.6309,
      "step": 456200
    },
    {
      "epoch": 4.830082415401146,
      "grad_norm": 1.0125066041946411,
      "learning_rate": 0.00030811472220965396,
      "loss": 0.6443,
      "step": 456250
    },
    {
      "epoch": 4.83061173718115,
      "grad_norm": 1.128002643585205,
      "learning_rate": 0.00030806979431520086,
      "loss": 0.6444,
      "step": 456300
    },
    {
      "epoch": 4.831141058961153,
      "grad_norm": 0.9473808407783508,
      "learning_rate": 0.0003080248644382663,
      "loss": 0.6477,
      "step": 456350
    },
    {
      "epoch": 4.831670380741157,
      "grad_norm": 0.988023042678833,
      "learning_rate": 0.0003079799325803842,
      "loss": 0.6464,
      "step": 456400
    },
    {
      "epoch": 4.83219970252116,
      "grad_norm": 0.9421167373657227,
      "learning_rate": 0.0003079349987430884,
      "loss": 0.6409,
      "step": 456450
    },
    {
      "epoch": 4.8327290243011625,
      "grad_norm": 1.0570895671844482,
      "learning_rate": 0.000307890062927913,
      "loss": 0.6647,
      "step": 456500
    },
    {
      "epoch": 4.8327290243011625,
      "eval_loss": 0.43126583099365234,
      "eval_runtime": 46.9837,
      "eval_samples_per_second": 3574.221,
      "eval_steps_per_second": 446.794,
      "step": 456500
    },
    {
      "epoch": 4.833258346081166,
      "grad_norm": 1.0036207437515259,
      "learning_rate": 0.0003078451251363921,
      "loss": 0.6386,
      "step": 456550
    },
    {
      "epoch": 4.83378766786117,
      "grad_norm": 1.0160597562789917,
      "learning_rate": 0.0003078001853700598,
      "loss": 0.6435,
      "step": 456600
    },
    {
      "epoch": 4.834316989641173,
      "grad_norm": 1.0029118061065674,
      "learning_rate": 0.0003077552436304504,
      "loss": 0.6334,
      "step": 456650
    },
    {
      "epoch": 4.834846311421176,
      "grad_norm": 1.022950291633606,
      "learning_rate": 0.0003077102999190981,
      "loss": 0.64,
      "step": 456700
    },
    {
      "epoch": 4.8353756332011795,
      "grad_norm": 1.0419665575027466,
      "learning_rate": 0.00030766535423753735,
      "loss": 0.6392,
      "step": 456750
    },
    {
      "epoch": 4.835904954981182,
      "grad_norm": 1.0484062433242798,
      "learning_rate": 0.00030762040658730255,
      "loss": 0.6494,
      "step": 456800
    },
    {
      "epoch": 4.836434276761186,
      "grad_norm": 1.096950888633728,
      "learning_rate": 0.0003075754569699283,
      "loss": 0.6433,
      "step": 456850
    },
    {
      "epoch": 4.836963598541189,
      "grad_norm": 1.1188057661056519,
      "learning_rate": 0.000307530505386949,
      "loss": 0.6545,
      "step": 456900
    },
    {
      "epoch": 4.837492920321193,
      "grad_norm": 1.030543327331543,
      "learning_rate": 0.00030748555183989927,
      "loss": 0.652,
      "step": 456950
    },
    {
      "epoch": 4.838022242101196,
      "grad_norm": 1.0594611167907715,
      "learning_rate": 0.00030744059633031404,
      "loss": 0.6512,
      "step": 457000
    },
    {
      "epoch": 4.838022242101196,
      "eval_loss": 0.4294765591621399,
      "eval_runtime": 46.88,
      "eval_samples_per_second": 3582.122,
      "eval_steps_per_second": 447.781,
      "step": 457000
    },
    {
      "epoch": 4.838551563881199,
      "grad_norm": 1.0499688386917114,
      "learning_rate": 0.0003073956388597278,
      "loss": 0.6429,
      "step": 457050
    },
    {
      "epoch": 4.839080885661202,
      "grad_norm": 1.0633955001831055,
      "learning_rate": 0.0003073506794296755,
      "loss": 0.6389,
      "step": 457100
    },
    {
      "epoch": 4.839610207441206,
      "grad_norm": 1.070120930671692,
      "learning_rate": 0.00030730661728862953,
      "loss": 0.6348,
      "step": 457150
    },
    {
      "epoch": 4.840139529221209,
      "grad_norm": 0.9530172944068909,
      "learning_rate": 0.0003072616539833628,
      "loss": 0.6275,
      "step": 457200
    },
    {
      "epoch": 4.840668851001212,
      "grad_norm": 1.1307165622711182,
      "learning_rate": 0.0003072166887232042,
      "loss": 0.6462,
      "step": 457250
    },
    {
      "epoch": 4.8411981727812154,
      "grad_norm": 1.0751705169677734,
      "learning_rate": 0.0003071717215096888,
      "loss": 0.6385,
      "step": 457300
    },
    {
      "epoch": 4.841727494561219,
      "grad_norm": 1.0116652250289917,
      "learning_rate": 0.00030712675234435176,
      "loss": 0.6449,
      "step": 457350
    },
    {
      "epoch": 4.842256816341222,
      "grad_norm": 1.1290141344070435,
      "learning_rate": 0.00030708178122872837,
      "loss": 0.6488,
      "step": 457400
    },
    {
      "epoch": 4.842786138121225,
      "grad_norm": 1.0716683864593506,
      "learning_rate": 0.00030703680816435397,
      "loss": 0.6397,
      "step": 457450
    },
    {
      "epoch": 4.843315459901229,
      "grad_norm": 1.0612467527389526,
      "learning_rate": 0.0003069918331527638,
      "loss": 0.6501,
      "step": 457500
    },
    {
      "epoch": 4.843315459901229,
      "eval_loss": 0.42903363704681396,
      "eval_runtime": 46.8794,
      "eval_samples_per_second": 3582.171,
      "eval_steps_per_second": 447.787,
      "step": 457500
    },
    {
      "epoch": 4.843844781681232,
      "grad_norm": 1.0513182878494263,
      "learning_rate": 0.00030694685619549335,
      "loss": 0.6414,
      "step": 457550
    },
    {
      "epoch": 4.844374103461235,
      "grad_norm": 1.088791847229004,
      "learning_rate": 0.00030690187729407814,
      "loss": 0.6333,
      "step": 457600
    },
    {
      "epoch": 4.844903425241238,
      "grad_norm": 1.0371387004852295,
      "learning_rate": 0.0003068568964500537,
      "loss": 0.6436,
      "step": 457650
    },
    {
      "epoch": 4.845432747021242,
      "grad_norm": 1.0258450508117676,
      "learning_rate": 0.00030681191366495564,
      "loss": 0.6348,
      "step": 457700
    },
    {
      "epoch": 4.845962068801245,
      "grad_norm": 1.0187240839004517,
      "learning_rate": 0.0003067669289403197,
      "loss": 0.6439,
      "step": 457750
    },
    {
      "epoch": 4.846491390581249,
      "grad_norm": 0.9953460097312927,
      "learning_rate": 0.0003067219422776817,
      "loss": 0.6416,
      "step": 457800
    },
    {
      "epoch": 4.847020712361251,
      "grad_norm": 1.0700595378875732,
      "learning_rate": 0.0003066769536785773,
      "loss": 0.6353,
      "step": 457850
    },
    {
      "epoch": 4.847550034141255,
      "grad_norm": 1.09009850025177,
      "learning_rate": 0.0003066319631445425,
      "loss": 0.6345,
      "step": 457900
    },
    {
      "epoch": 4.848079355921258,
      "grad_norm": 1.05178701877594,
      "learning_rate": 0.00030658697067711325,
      "loss": 0.6402,
      "step": 457950
    },
    {
      "epoch": 4.848608677701261,
      "grad_norm": 0.9648205637931824,
      "learning_rate": 0.0003065419762778256,
      "loss": 0.6413,
      "step": 458000
    },
    {
      "epoch": 4.848608677701261,
      "eval_loss": 0.4304473400115967,
      "eval_runtime": 46.9323,
      "eval_samples_per_second": 3578.134,
      "eval_steps_per_second": 447.283,
      "step": 458000
    },
    {
      "epoch": 4.849137999481265,
      "grad_norm": 1.1932239532470703,
      "learning_rate": 0.0003064969799482156,
      "loss": 0.6419,
      "step": 458050
    },
    {
      "epoch": 4.849667321261268,
      "grad_norm": 1.0487455129623413,
      "learning_rate": 0.0003064519816898194,
      "loss": 0.6502,
      "step": 458100
    },
    {
      "epoch": 4.850196643041271,
      "grad_norm": 1.0907896757125854,
      "learning_rate": 0.00030640698150417324,
      "loss": 0.6398,
      "step": 458150
    },
    {
      "epoch": 4.850725964821274,
      "grad_norm": 1.1407135725021362,
      "learning_rate": 0.0003063619793928134,
      "loss": 0.6377,
      "step": 458200
    },
    {
      "epoch": 4.851255286601278,
      "grad_norm": 1.1115140914916992,
      "learning_rate": 0.00030631697535727634,
      "loss": 0.639,
      "step": 458250
    },
    {
      "epoch": 4.851784608381281,
      "grad_norm": 0.9942390322685242,
      "learning_rate": 0.00030627196939909837,
      "loss": 0.6392,
      "step": 458300
    },
    {
      "epoch": 4.8523139301612845,
      "grad_norm": 0.9551951885223389,
      "learning_rate": 0.000306226961519816,
      "loss": 0.6306,
      "step": 458350
    },
    {
      "epoch": 4.852843251941287,
      "grad_norm": 1.0737826824188232,
      "learning_rate": 0.00030618195172096575,
      "loss": 0.6388,
      "step": 458400
    },
    {
      "epoch": 4.853372573721291,
      "grad_norm": 1.061352252960205,
      "learning_rate": 0.00030613694000408427,
      "loss": 0.6326,
      "step": 458450
    },
    {
      "epoch": 4.853901895501294,
      "grad_norm": 1.0800673961639404,
      "learning_rate": 0.00030609192637070826,
      "loss": 0.6421,
      "step": 458500
    },
    {
      "epoch": 4.853901895501294,
      "eval_loss": 0.4295804500579834,
      "eval_runtime": 46.8847,
      "eval_samples_per_second": 3581.763,
      "eval_steps_per_second": 447.736,
      "step": 458500
    },
    {
      "epoch": 4.854431217281298,
      "grad_norm": 1.0385050773620605,
      "learning_rate": 0.0003060469108223745,
      "loss": 0.6358,
      "step": 458550
    },
    {
      "epoch": 4.854960539061301,
      "grad_norm": 1.0819464921951294,
      "learning_rate": 0.0003060018933606197,
      "loss": 0.6414,
      "step": 458600
    },
    {
      "epoch": 4.855489860841304,
      "grad_norm": 1.023367166519165,
      "learning_rate": 0.00030595687398698085,
      "loss": 0.6283,
      "step": 458650
    },
    {
      "epoch": 4.856019182621307,
      "grad_norm": 1.0650900602340698,
      "learning_rate": 0.0003059118527029948,
      "loss": 0.6344,
      "step": 458700
    },
    {
      "epoch": 4.85654850440131,
      "grad_norm": 0.9716605544090271,
      "learning_rate": 0.0003058668295101986,
      "loss": 0.6459,
      "step": 458750
    },
    {
      "epoch": 4.857077826181314,
      "grad_norm": 1.049193024635315,
      "learning_rate": 0.00030582180441012934,
      "loss": 0.653,
      "step": 458800
    },
    {
      "epoch": 4.857607147961318,
      "grad_norm": 1.1158770322799683,
      "learning_rate": 0.0003057767774043242,
      "loss": 0.6354,
      "step": 458850
    },
    {
      "epoch": 4.8581364697413205,
      "grad_norm": 0.9278897047042847,
      "learning_rate": 0.0003057317484943203,
      "loss": 0.6328,
      "step": 458900
    },
    {
      "epoch": 4.858665791521323,
      "grad_norm": 1.029471516609192,
      "learning_rate": 0.0003056867176816549,
      "loss": 0.6318,
      "step": 458950
    },
    {
      "epoch": 4.859195113301327,
      "grad_norm": 1.0289946794509888,
      "learning_rate": 0.00030564168496786536,
      "loss": 0.6418,
      "step": 459000
    },
    {
      "epoch": 4.859195113301327,
      "eval_loss": 0.42892035841941833,
      "eval_runtime": 47.0145,
      "eval_samples_per_second": 3571.876,
      "eval_steps_per_second": 446.501,
      "step": 459000
    },
    {
      "epoch": 4.85972443508133,
      "grad_norm": 1.0599380731582642,
      "learning_rate": 0.00030559665035448917,
      "loss": 0.646,
      "step": 459050
    },
    {
      "epoch": 4.860253756861334,
      "grad_norm": 1.0241769552230835,
      "learning_rate": 0.0003055516138430637,
      "loss": 0.6425,
      "step": 459100
    },
    {
      "epoch": 4.860783078641337,
      "grad_norm": 1.0981040000915527,
      "learning_rate": 0.00030550657543512656,
      "loss": 0.6467,
      "step": 459150
    },
    {
      "epoch": 4.86131240042134,
      "grad_norm": 1.0602622032165527,
      "learning_rate": 0.0003054624359568343,
      "loss": 0.6406,
      "step": 459200
    },
    {
      "epoch": 4.861841722201343,
      "grad_norm": 1.0749881267547607,
      "learning_rate": 0.00030541739379834023,
      "loss": 0.6494,
      "step": 459250
    },
    {
      "epoch": 4.862371043981347,
      "grad_norm": 1.0906518697738647,
      "learning_rate": 0.0003053723497479166,
      "loss": 0.6321,
      "step": 459300
    },
    {
      "epoch": 4.86290036576135,
      "grad_norm": 1.1196597814559937,
      "learning_rate": 0.00030532730380710126,
      "loss": 0.6476,
      "step": 459350
    },
    {
      "epoch": 4.863429687541354,
      "grad_norm": 1.0742634534835815,
      "learning_rate": 0.00030528225597743205,
      "loss": 0.6341,
      "step": 459400
    },
    {
      "epoch": 4.8639590093213565,
      "grad_norm": 1.0893480777740479,
      "learning_rate": 0.0003052372062604469,
      "loss": 0.6405,
      "step": 459450
    },
    {
      "epoch": 4.864488331101359,
      "grad_norm": 1.0572199821472168,
      "learning_rate": 0.00030519215465768377,
      "loss": 0.645,
      "step": 459500
    },
    {
      "epoch": 4.864488331101359,
      "eval_loss": 0.4288080036640167,
      "eval_runtime": 46.8251,
      "eval_samples_per_second": 3586.322,
      "eval_steps_per_second": 448.306,
      "step": 459500
    },
    {
      "epoch": 4.865017652881363,
      "grad_norm": 1.1685847043991089,
      "learning_rate": 0.0003051471011706808,
      "loss": 0.6409,
      "step": 459550
    },
    {
      "epoch": 4.865546974661367,
      "grad_norm": 1.011194109916687,
      "learning_rate": 0.000305102045800976,
      "loss": 0.6469,
      "step": 459600
    },
    {
      "epoch": 4.86607629644137,
      "grad_norm": 1.1743520498275757,
      "learning_rate": 0.0003050569885501075,
      "loss": 0.6489,
      "step": 459650
    },
    {
      "epoch": 4.866605618221373,
      "grad_norm": 1.0333768129348755,
      "learning_rate": 0.00030501192941961364,
      "loss": 0.6358,
      "step": 459700
    },
    {
      "epoch": 4.867134940001376,
      "grad_norm": 0.9965838193893433,
      "learning_rate": 0.0003049668684110327,
      "loss": 0.6289,
      "step": 459750
    },
    {
      "epoch": 4.867664261781379,
      "grad_norm": 1.010923147201538,
      "learning_rate": 0.000304921805525903,
      "loss": 0.6355,
      "step": 459800
    },
    {
      "epoch": 4.868193583561383,
      "grad_norm": 1.0588067770004272,
      "learning_rate": 0.00030487674076576306,
      "loss": 0.6446,
      "step": 459850
    },
    {
      "epoch": 4.868722905341386,
      "grad_norm": 1.0153474807739258,
      "learning_rate": 0.00030483167413215123,
      "loss": 0.6489,
      "step": 459900
    },
    {
      "epoch": 4.86925222712139,
      "grad_norm": 1.0480400323867798,
      "learning_rate": 0.0003047866056266062,
      "loss": 0.6507,
      "step": 459950
    },
    {
      "epoch": 4.8697815489013925,
      "grad_norm": 0.9762146472930908,
      "learning_rate": 0.00030474153525066657,
      "loss": 0.6343,
      "step": 460000
    },
    {
      "epoch": 4.8697815489013925,
      "eval_loss": 0.42867958545684814,
      "eval_runtime": 47.0774,
      "eval_samples_per_second": 3567.106,
      "eval_steps_per_second": 445.904,
      "step": 460000
    },
    {
      "epoch": 4.870310870681396,
      "grad_norm": 1.0180633068084717,
      "learning_rate": 0.00030469646300587097,
      "loss": 0.6342,
      "step": 460050
    },
    {
      "epoch": 4.870840192461399,
      "grad_norm": 1.0059940814971924,
      "learning_rate": 0.0003046513888937582,
      "loss": 0.639,
      "step": 460100
    },
    {
      "epoch": 4.871369514241403,
      "grad_norm": 1.006019115447998,
      "learning_rate": 0.00030460631291586706,
      "loss": 0.6285,
      "step": 460150
    },
    {
      "epoch": 4.871898836021406,
      "grad_norm": 0.9480358362197876,
      "learning_rate": 0.0003045612350737364,
      "loss": 0.6383,
      "step": 460200
    },
    {
      "epoch": 4.872428157801409,
      "grad_norm": 1.062537431716919,
      "learning_rate": 0.00030451615536890514,
      "loss": 0.6377,
      "step": 460250
    },
    {
      "epoch": 4.872957479581412,
      "grad_norm": 0.972216010093689,
      "learning_rate": 0.0003044710738029124,
      "loss": 0.6417,
      "step": 460300
    },
    {
      "epoch": 4.873486801361416,
      "grad_norm": 0.9889315962791443,
      "learning_rate": 0.00030442599037729714,
      "loss": 0.6398,
      "step": 460350
    },
    {
      "epoch": 4.874016123141419,
      "grad_norm": 1.0488563776016235,
      "learning_rate": 0.0003043809050935985,
      "loss": 0.645,
      "step": 460400
    },
    {
      "epoch": 4.874545444921422,
      "grad_norm": 1.0173423290252686,
      "learning_rate": 0.0003043358179533558,
      "loss": 0.6343,
      "step": 460450
    },
    {
      "epoch": 4.875074766701426,
      "grad_norm": 1.1538487672805786,
      "learning_rate": 0.00030429072895810815,
      "loss": 0.6333,
      "step": 460500
    },
    {
      "epoch": 4.875074766701426,
      "eval_loss": 0.42727959156036377,
      "eval_runtime": 46.8942,
      "eval_samples_per_second": 3581.04,
      "eval_steps_per_second": 447.646,
      "step": 460500
    },
    {
      "epoch": 4.8756040884814285,
      "grad_norm": 1.0207756757736206,
      "learning_rate": 0.00030424563810939494,
      "loss": 0.6392,
      "step": 460550
    },
    {
      "epoch": 4.876133410261432,
      "grad_norm": 1.1012293100357056,
      "learning_rate": 0.0003042005454087555,
      "loss": 0.6505,
      "step": 460600
    },
    {
      "epoch": 4.876662732041435,
      "grad_norm": 1.0381526947021484,
      "learning_rate": 0.0003041554508577293,
      "loss": 0.652,
      "step": 460650
    },
    {
      "epoch": 4.877192053821439,
      "grad_norm": 1.1055269241333008,
      "learning_rate": 0.00030411035445785593,
      "loss": 0.6503,
      "step": 460700
    },
    {
      "epoch": 4.877721375601442,
      "grad_norm": 0.9683148860931396,
      "learning_rate": 0.0003040652562106749,
      "loss": 0.634,
      "step": 460750
    },
    {
      "epoch": 4.8782506973814455,
      "grad_norm": 0.9820207953453064,
      "learning_rate": 0.0003040201561177258,
      "loss": 0.6559,
      "step": 460800
    },
    {
      "epoch": 4.878780019161448,
      "grad_norm": 1.0603538751602173,
      "learning_rate": 0.0003039750541805485,
      "loss": 0.6509,
      "step": 460850
    },
    {
      "epoch": 4.879309340941452,
      "grad_norm": 1.1173592805862427,
      "learning_rate": 0.00030392995040068256,
      "loss": 0.6353,
      "step": 460900
    },
    {
      "epoch": 4.879838662721455,
      "grad_norm": 1.1374127864837646,
      "learning_rate": 0.00030388484477966786,
      "loss": 0.6454,
      "step": 460950
    },
    {
      "epoch": 4.880367984501458,
      "grad_norm": 1.0605360269546509,
      "learning_rate": 0.00030383973731904434,
      "loss": 0.6326,
      "step": 461000
    },
    {
      "epoch": 4.880367984501458,
      "eval_loss": 0.42782333493232727,
      "eval_runtime": 46.8023,
      "eval_samples_per_second": 3588.075,
      "eval_steps_per_second": 448.525,
      "step": 461000
    },
    {
      "epoch": 4.880897306281462,
      "grad_norm": 1.0390725135803223,
      "learning_rate": 0.0003037946280203519,
      "loss": 0.646,
      "step": 461050
    },
    {
      "epoch": 4.881426628061465,
      "grad_norm": 0.980093777179718,
      "learning_rate": 0.00030374951688513064,
      "loss": 0.6332,
      "step": 461100
    },
    {
      "epoch": 4.881955949841468,
      "grad_norm": 1.1438322067260742,
      "learning_rate": 0.0003037044039149206,
      "loss": 0.6345,
      "step": 461150
    },
    {
      "epoch": 4.882485271621471,
      "grad_norm": 1.1050862073898315,
      "learning_rate": 0.0003036592891112619,
      "loss": 0.6397,
      "step": 461200
    },
    {
      "epoch": 4.883014593401475,
      "grad_norm": 1.1037029027938843,
      "learning_rate": 0.00030361507482634876,
      "loss": 0.631,
      "step": 461250
    },
    {
      "epoch": 4.883543915181478,
      "grad_norm": 1.0296353101730347,
      "learning_rate": 0.0003035699563970057,
      "loss": 0.6233,
      "step": 461300
    },
    {
      "epoch": 4.884073236961481,
      "grad_norm": 1.0208532810211182,
      "learning_rate": 0.0003035248361388039,
      "loss": 0.6296,
      "step": 461350
    },
    {
      "epoch": 4.884602558741484,
      "grad_norm": 1.0134162902832031,
      "learning_rate": 0.00030347971405328395,
      "loss": 0.644,
      "step": 461400
    },
    {
      "epoch": 4.885131880521488,
      "grad_norm": 1.0673338174819946,
      "learning_rate": 0.0003034345901419861,
      "loss": 0.6376,
      "step": 461450
    },
    {
      "epoch": 4.885661202301491,
      "grad_norm": 1.117605447769165,
      "learning_rate": 0.00030338946440645095,
      "loss": 0.6391,
      "step": 461500
    },
    {
      "epoch": 4.885661202301491,
      "eval_loss": 0.426494300365448,
      "eval_runtime": 46.8015,
      "eval_samples_per_second": 3588.133,
      "eval_steps_per_second": 448.533,
      "step": 461500
    },
    {
      "epoch": 4.886190524081495,
      "grad_norm": 1.0490301847457886,
      "learning_rate": 0.00030334433684821906,
      "loss": 0.6378,
      "step": 461550
    },
    {
      "epoch": 4.8867198458614975,
      "grad_norm": 1.0159289836883545,
      "learning_rate": 0.00030329920746883105,
      "loss": 0.6467,
      "step": 461600
    },
    {
      "epoch": 4.887249167641501,
      "grad_norm": 0.929719090461731,
      "learning_rate": 0.0003032540762698276,
      "loss": 0.6288,
      "step": 461650
    },
    {
      "epoch": 4.887778489421504,
      "grad_norm": 1.159258246421814,
      "learning_rate": 0.00030320894325274963,
      "loss": 0.629,
      "step": 461700
    },
    {
      "epoch": 4.888307811201507,
      "grad_norm": 0.9499598145484924,
      "learning_rate": 0.00030316380841913774,
      "loss": 0.6493,
      "step": 461750
    },
    {
      "epoch": 4.888837132981511,
      "grad_norm": 1.0683099031448364,
      "learning_rate": 0.00030311867177053303,
      "loss": 0.6327,
      "step": 461800
    },
    {
      "epoch": 4.8893664547615145,
      "grad_norm": 1.0297497510910034,
      "learning_rate": 0.0003030735333084763,
      "loss": 0.6416,
      "step": 461850
    },
    {
      "epoch": 4.889895776541517,
      "grad_norm": 1.0330291986465454,
      "learning_rate": 0.00030302839303450864,
      "loss": 0.634,
      "step": 461900
    },
    {
      "epoch": 4.89042509832152,
      "grad_norm": 1.0810819864273071,
      "learning_rate": 0.00030298325095017107,
      "loss": 0.6479,
      "step": 461950
    },
    {
      "epoch": 4.890954420101524,
      "grad_norm": 1.122894525527954,
      "learning_rate": 0.0003029381070570047,
      "loss": 0.6402,
      "step": 462000
    },
    {
      "epoch": 4.890954420101524,
      "eval_loss": 0.4268931448459625,
      "eval_runtime": 46.8732,
      "eval_samples_per_second": 3582.647,
      "eval_steps_per_second": 447.847,
      "step": 462000
    },
    {
      "epoch": 4.891483741881527,
      "grad_norm": 1.0127547979354858,
      "learning_rate": 0.0003028929613565508,
      "loss": 0.6465,
      "step": 462050
    },
    {
      "epoch": 4.892013063661531,
      "grad_norm": 1.0266221761703491,
      "learning_rate": 0.00030284781385035063,
      "loss": 0.6383,
      "step": 462100
    },
    {
      "epoch": 4.8925423854415335,
      "grad_norm": 1.0244563817977905,
      "learning_rate": 0.00030280266453994544,
      "loss": 0.6283,
      "step": 462150
    },
    {
      "epoch": 4.893071707221537,
      "grad_norm": 0.9933379292488098,
      "learning_rate": 0.0003027575134268766,
      "loss": 0.6287,
      "step": 462200
    },
    {
      "epoch": 4.89360102900154,
      "grad_norm": 1.1842169761657715,
      "learning_rate": 0.0003027123605126857,
      "loss": 0.646,
      "step": 462250
    },
    {
      "epoch": 4.894130350781544,
      "grad_norm": 1.1576838493347168,
      "learning_rate": 0.0003026672057989141,
      "loss": 0.6376,
      "step": 462300
    },
    {
      "epoch": 4.894659672561547,
      "grad_norm": 1.048439621925354,
      "learning_rate": 0.0003026220492871035,
      "loss": 0.6295,
      "step": 462350
    },
    {
      "epoch": 4.8951889943415505,
      "grad_norm": 1.1953915357589722,
      "learning_rate": 0.0003025768909787953,
      "loss": 0.6317,
      "step": 462400
    },
    {
      "epoch": 4.895718316121553,
      "grad_norm": 1.112561821937561,
      "learning_rate": 0.0003025317308755313,
      "loss": 0.6456,
      "step": 462450
    },
    {
      "epoch": 4.896247637901556,
      "grad_norm": 1.0204927921295166,
      "learning_rate": 0.0003024865689788534,
      "loss": 0.6307,
      "step": 462500
    },
    {
      "epoch": 4.896247637901556,
      "eval_loss": 0.4263201057910919,
      "eval_runtime": 47.1626,
      "eval_samples_per_second": 3560.664,
      "eval_steps_per_second": 445.099,
      "step": 462500
    },
    {
      "epoch": 4.89677695968156,
      "grad_norm": 1.0655460357666016,
      "learning_rate": 0.0003024414052903032,
      "loss": 0.6397,
      "step": 462550
    },
    {
      "epoch": 4.897306281461564,
      "grad_norm": 1.0890393257141113,
      "learning_rate": 0.00030239623981142264,
      "loss": 0.6398,
      "step": 462600
    },
    {
      "epoch": 4.897835603241567,
      "grad_norm": 1.1592353582382202,
      "learning_rate": 0.00030235107254375374,
      "loss": 0.6422,
      "step": 462650
    },
    {
      "epoch": 4.8983649250215695,
      "grad_norm": 1.0113062858581543,
      "learning_rate": 0.0003023059034888384,
      "loss": 0.6503,
      "step": 462700
    },
    {
      "epoch": 4.898894246801573,
      "grad_norm": 1.0931473970413208,
      "learning_rate": 0.0003022607326482187,
      "loss": 0.6377,
      "step": 462750
    },
    {
      "epoch": 4.899423568581576,
      "grad_norm": 1.130924940109253,
      "learning_rate": 0.0003022155600234367,
      "loss": 0.6398,
      "step": 462800
    },
    {
      "epoch": 4.89995289036158,
      "grad_norm": 1.0551074743270874,
      "learning_rate": 0.0003021703856160347,
      "loss": 0.6436,
      "step": 462850
    },
    {
      "epoch": 4.900482212141583,
      "grad_norm": 1.0911368131637573,
      "learning_rate": 0.0003021252094275548,
      "loss": 0.6414,
      "step": 462900
    },
    {
      "epoch": 4.9010115339215865,
      "grad_norm": 1.023380160331726,
      "learning_rate": 0.00030208003145953944,
      "loss": 0.642,
      "step": 462950
    },
    {
      "epoch": 4.901540855701589,
      "grad_norm": 1.0382046699523926,
      "learning_rate": 0.0003020348517135309,
      "loss": 0.6458,
      "step": 463000
    },
    {
      "epoch": 4.901540855701589,
      "eval_loss": 0.42607274651527405,
      "eval_runtime": 47.02,
      "eval_samples_per_second": 3571.459,
      "eval_steps_per_second": 446.448,
      "step": 463000
    },
    {
      "epoch": 4.902070177481593,
      "grad_norm": 1.1834183931350708,
      "learning_rate": 0.0003019896701910716,
      "loss": 0.6443,
      "step": 463050
    },
    {
      "epoch": 4.902599499261596,
      "grad_norm": 1.1965028047561646,
      "learning_rate": 0.00030194448689370397,
      "loss": 0.6443,
      "step": 463100
    },
    {
      "epoch": 4.9031288210416,
      "grad_norm": 0.9794292449951172,
      "learning_rate": 0.00030189930182297065,
      "loss": 0.6415,
      "step": 463150
    },
    {
      "epoch": 4.903658142821603,
      "grad_norm": 1.0722111463546753,
      "learning_rate": 0.0003018541149804142,
      "loss": 0.6492,
      "step": 463200
    },
    {
      "epoch": 4.9041874646016055,
      "grad_norm": 1.0243104696273804,
      "learning_rate": 0.00030180983015717276,
      "loss": 0.6131,
      "step": 463250
    },
    {
      "epoch": 4.904716786381609,
      "grad_norm": 0.9881762862205505,
      "learning_rate": 0.00030176463981095773,
      "loss": 0.6398,
      "step": 463300
    },
    {
      "epoch": 4.905246108161613,
      "grad_norm": 1.0392143726348877,
      "learning_rate": 0.0003017194476975169,
      "loss": 0.637,
      "step": 463350
    },
    {
      "epoch": 4.905775429941616,
      "grad_norm": 1.093902349472046,
      "learning_rate": 0.0003016742538183931,
      "loss": 0.6388,
      "step": 463400
    },
    {
      "epoch": 4.906304751721619,
      "grad_norm": 0.9970776438713074,
      "learning_rate": 0.00030162905817512914,
      "loss": 0.6294,
      "step": 463450
    },
    {
      "epoch": 4.9068340735016225,
      "grad_norm": 1.0592589378356934,
      "learning_rate": 0.00030158386076926816,
      "loss": 0.6387,
      "step": 463500
    },
    {
      "epoch": 4.9068340735016225,
      "eval_loss": 0.4261190593242645,
      "eval_runtime": 47.0722,
      "eval_samples_per_second": 3567.497,
      "eval_steps_per_second": 445.953,
      "step": 463500
    },
    {
      "epoch": 4.907363395281625,
      "grad_norm": 1.0753840208053589,
      "learning_rate": 0.00030153866160235305,
      "loss": 0.6449,
      "step": 463550
    },
    {
      "epoch": 4.907892717061629,
      "grad_norm": 1.1032418012619019,
      "learning_rate": 0.00030149346067592694,
      "loss": 0.6458,
      "step": 463600
    },
    {
      "epoch": 4.908422038841632,
      "grad_norm": 1.1359339952468872,
      "learning_rate": 0.000301448257991533,
      "loss": 0.6357,
      "step": 463650
    },
    {
      "epoch": 4.908951360621636,
      "grad_norm": 1.0579092502593994,
      "learning_rate": 0.00030140305355071427,
      "loss": 0.6305,
      "step": 463700
    },
    {
      "epoch": 4.909480682401639,
      "grad_norm": 1.0949413776397705,
      "learning_rate": 0.00030135784735501426,
      "loss": 0.6486,
      "step": 463750
    },
    {
      "epoch": 4.910010004181642,
      "grad_norm": 0.9799771308898926,
      "learning_rate": 0.0003013126394059761,
      "loss": 0.6358,
      "step": 463800
    },
    {
      "epoch": 4.910539325961645,
      "grad_norm": 0.9065978527069092,
      "learning_rate": 0.00030126742970514335,
      "loss": 0.6443,
      "step": 463850
    },
    {
      "epoch": 4.911068647741649,
      "grad_norm": 1.0453284978866577,
      "learning_rate": 0.0003012222182540593,
      "loss": 0.6399,
      "step": 463900
    },
    {
      "epoch": 4.911597969521652,
      "grad_norm": 0.9960294365882874,
      "learning_rate": 0.0003011770050542675,
      "loss": 0.6429,
      "step": 463950
    },
    {
      "epoch": 4.912127291301655,
      "grad_norm": 0.9817235469818115,
      "learning_rate": 0.00030113179010731155,
      "loss": 0.6304,
      "step": 464000
    },
    {
      "epoch": 4.912127291301655,
      "eval_loss": 0.42700445652008057,
      "eval_runtime": 46.9374,
      "eval_samples_per_second": 3577.746,
      "eval_steps_per_second": 447.234,
      "step": 464000
    },
    {
      "epoch": 4.9126566130816585,
      "grad_norm": 1.0104100704193115,
      "learning_rate": 0.000301086573414735,
      "loss": 0.6454,
      "step": 464050
    },
    {
      "epoch": 4.913185934861662,
      "grad_norm": 1.0980701446533203,
      "learning_rate": 0.0003010413549780816,
      "loss": 0.6394,
      "step": 464100
    },
    {
      "epoch": 4.913715256641665,
      "grad_norm": 1.1106250286102295,
      "learning_rate": 0.000300996134798895,
      "loss": 0.636,
      "step": 464150
    },
    {
      "epoch": 4.914244578421668,
      "grad_norm": 1.0195088386535645,
      "learning_rate": 0.00030095091287871915,
      "loss": 0.6407,
      "step": 464200
    },
    {
      "epoch": 4.914773900201672,
      "grad_norm": 0.9263055324554443,
      "learning_rate": 0.0003009056892190978,
      "loss": 0.6344,
      "step": 464250
    },
    {
      "epoch": 4.915303221981675,
      "grad_norm": 1.0839413404464722,
      "learning_rate": 0.00030086046382157486,
      "loss": 0.6429,
      "step": 464300
    },
    {
      "epoch": 4.915832543761678,
      "grad_norm": 0.9638394117355347,
      "learning_rate": 0.00030081523668769436,
      "loss": 0.6364,
      "step": 464350
    },
    {
      "epoch": 4.916361865541681,
      "grad_norm": 1.0684758424758911,
      "learning_rate": 0.0003007700078190003,
      "loss": 0.6386,
      "step": 464400
    },
    {
      "epoch": 4.916891187321685,
      "grad_norm": 0.9673624634742737,
      "learning_rate": 0.00030072477721703676,
      "loss": 0.6351,
      "step": 464450
    },
    {
      "epoch": 4.917420509101688,
      "grad_norm": 1.1810420751571655,
      "learning_rate": 0.00030067954488334795,
      "loss": 0.6311,
      "step": 464500
    },
    {
      "epoch": 4.917420509101688,
      "eval_loss": 0.4259594678878784,
      "eval_runtime": 46.8044,
      "eval_samples_per_second": 3587.911,
      "eval_steps_per_second": 448.505,
      "step": 464500
    },
    {
      "epoch": 4.917949830881692,
      "grad_norm": 0.9633573889732361,
      "learning_rate": 0.000300634310819478,
      "loss": 0.643,
      "step": 464550
    },
    {
      "epoch": 4.918479152661694,
      "grad_norm": 1.1069480180740356,
      "learning_rate": 0.0003005890750269714,
      "loss": 0.6258,
      "step": 464600
    },
    {
      "epoch": 4.919008474441698,
      "grad_norm": 1.0238865613937378,
      "learning_rate": 0.00030054383750737217,
      "loss": 0.6322,
      "step": 464650
    },
    {
      "epoch": 4.919537796221701,
      "grad_norm": 1.1160579919815063,
      "learning_rate": 0.000300498598262225,
      "loss": 0.6321,
      "step": 464700
    },
    {
      "epoch": 4.920067118001704,
      "grad_norm": 1.0444377660751343,
      "learning_rate": 0.0003004533572930741,
      "loss": 0.6381,
      "step": 464750
    },
    {
      "epoch": 4.920596439781708,
      "grad_norm": 1.098669171333313,
      "learning_rate": 0.00030040811460146417,
      "loss": 0.6492,
      "step": 464800
    },
    {
      "epoch": 4.921125761561711,
      "grad_norm": 0.9608095288276672,
      "learning_rate": 0.00030036287018893966,
      "loss": 0.6361,
      "step": 464850
    },
    {
      "epoch": 4.921655083341714,
      "grad_norm": 1.0125269889831543,
      "learning_rate": 0.0003003176240570452,
      "loss": 0.6467,
      "step": 464900
    },
    {
      "epoch": 4.922184405121717,
      "grad_norm": 1.1495985984802246,
      "learning_rate": 0.0003002723762073256,
      "loss": 0.6378,
      "step": 464950
    },
    {
      "epoch": 4.922713726901721,
      "grad_norm": 1.0050212144851685,
      "learning_rate": 0.00030022712664132543,
      "loss": 0.6452,
      "step": 465000
    },
    {
      "epoch": 4.922713726901721,
      "eval_loss": 0.42471036314964294,
      "eval_runtime": 46.9813,
      "eval_samples_per_second": 3574.398,
      "eval_steps_per_second": 446.816,
      "step": 465000
    },
    {
      "epoch": 4.923243048681724,
      "grad_norm": 1.0287470817565918,
      "learning_rate": 0.00030018187536058963,
      "loss": 0.6489,
      "step": 465050
    },
    {
      "epoch": 4.9237723704617276,
      "grad_norm": 0.894805371761322,
      "learning_rate": 0.0003001366223666629,
      "loss": 0.6349,
      "step": 465100
    },
    {
      "epoch": 4.92430169224173,
      "grad_norm": 1.0704596042633057,
      "learning_rate": 0.0003000913676610904,
      "loss": 0.6309,
      "step": 465150
    },
    {
      "epoch": 4.924831014021734,
      "grad_norm": 1.145859718322754,
      "learning_rate": 0.0003000461112454169,
      "loss": 0.6423,
      "step": 465200
    },
    {
      "epoch": 4.925360335801737,
      "grad_norm": 0.9467533826828003,
      "learning_rate": 0.0003000008531211876,
      "loss": 0.6435,
      "step": 465250
    },
    {
      "epoch": 4.925889657581741,
      "grad_norm": 1.0376485586166382,
      "learning_rate": 0.00029995649850329093,
      "loss": 0.6301,
      "step": 465300
    },
    {
      "epoch": 4.926418979361744,
      "grad_norm": 1.042932391166687,
      "learning_rate": 0.00029991123700067937,
      "loss": 0.6402,
      "step": 465350
    },
    {
      "epoch": 4.926948301141747,
      "grad_norm": 1.0274850130081177,
      "learning_rate": 0.0002998659737941164,
      "loss": 0.6318,
      "step": 465400
    },
    {
      "epoch": 4.92747762292175,
      "grad_norm": 1.1325170993804932,
      "learning_rate": 0.00029982070888514737,
      "loss": 0.6352,
      "step": 465450
    },
    {
      "epoch": 4.928006944701753,
      "grad_norm": 1.166041612625122,
      "learning_rate": 0.00029977544227531767,
      "loss": 0.6386,
      "step": 465500
    },
    {
      "epoch": 4.928006944701753,
      "eval_loss": 0.42429453134536743,
      "eval_runtime": 46.8681,
      "eval_samples_per_second": 3583.034,
      "eval_steps_per_second": 447.895,
      "step": 465500
    },
    {
      "epoch": 4.928536266481757,
      "grad_norm": 1.0975815057754517,
      "learning_rate": 0.0002997301739661726,
      "loss": 0.6357,
      "step": 465550
    },
    {
      "epoch": 4.929065588261761,
      "grad_norm": 0.9814993739128113,
      "learning_rate": 0.00029968490395925764,
      "loss": 0.6359,
      "step": 465600
    },
    {
      "epoch": 4.9295949100417635,
      "grad_norm": 1.1729587316513062,
      "learning_rate": 0.00029963963225611826,
      "loss": 0.6447,
      "step": 465650
    },
    {
      "epoch": 4.930124231821766,
      "grad_norm": 1.01615571975708,
      "learning_rate": 0.00029959435885830004,
      "loss": 0.6311,
      "step": 465700
    },
    {
      "epoch": 4.93065355360177,
      "grad_norm": 1.1616178750991821,
      "learning_rate": 0.0002995490837673486,
      "loss": 0.6422,
      "step": 465750
    },
    {
      "epoch": 4.931182875381773,
      "grad_norm": 1.0813262462615967,
      "learning_rate": 0.0002995038069848096,
      "loss": 0.6315,
      "step": 465800
    },
    {
      "epoch": 4.931712197161777,
      "grad_norm": 1.031287670135498,
      "learning_rate": 0.0002994585285122288,
      "loss": 0.6311,
      "step": 465850
    },
    {
      "epoch": 4.93224151894178,
      "grad_norm": 0.9768134355545044,
      "learning_rate": 0.000299413248351152,
      "loss": 0.6478,
      "step": 465900
    },
    {
      "epoch": 4.932770840721783,
      "grad_norm": 1.060937523841858,
      "learning_rate": 0.0002993688721566076,
      "loss": 0.6358,
      "step": 465950
    },
    {
      "epoch": 4.933300162501786,
      "grad_norm": 1.0303014516830444,
      "learning_rate": 0.0002993235886568693,
      "loss": 0.6334,
      "step": 466000
    },
    {
      "epoch": 4.933300162501786,
      "eval_loss": 0.4252080023288727,
      "eval_runtime": 47.2107,
      "eval_samples_per_second": 3557.03,
      "eval_steps_per_second": 444.645,
      "step": 466000
    },
    {
      "epoch": 4.93382948428179,
      "grad_norm": 1.2061388492584229,
      "learning_rate": 0.0002992783034732417,
      "loss": 0.6468,
      "step": 466050
    },
    {
      "epoch": 4.934358806061793,
      "grad_norm": 1.04450261592865,
      "learning_rate": 0.00029923301660727094,
      "loss": 0.6269,
      "step": 466100
    },
    {
      "epoch": 4.934888127841797,
      "grad_norm": 0.9827244877815247,
      "learning_rate": 0.000299187728060503,
      "loss": 0.6407,
      "step": 466150
    },
    {
      "epoch": 4.9354174496217995,
      "grad_norm": 1.0660037994384766,
      "learning_rate": 0.0002991424378344841,
      "loss": 0.6266,
      "step": 466200
    },
    {
      "epoch": 4.935946771401802,
      "grad_norm": 1.0363658666610718,
      "learning_rate": 0.00029909714593076044,
      "loss": 0.6389,
      "step": 466250
    },
    {
      "epoch": 4.936476093181806,
      "grad_norm": 1.256635069847107,
      "learning_rate": 0.0002990518523508782,
      "loss": 0.6319,
      "step": 466300
    },
    {
      "epoch": 4.93700541496181,
      "grad_norm": 1.0578336715698242,
      "learning_rate": 0.00029900655709638366,
      "loss": 0.6469,
      "step": 466350
    },
    {
      "epoch": 4.937534736741813,
      "grad_norm": 1.1612576246261597,
      "learning_rate": 0.00029896126016882327,
      "loss": 0.6449,
      "step": 466400
    },
    {
      "epoch": 4.938064058521816,
      "grad_norm": 1.1282739639282227,
      "learning_rate": 0.0002989159615697434,
      "loss": 0.6388,
      "step": 466450
    },
    {
      "epoch": 4.938593380301819,
      "grad_norm": 0.9997372627258301,
      "learning_rate": 0.0002988706613006905,
      "loss": 0.6453,
      "step": 466500
    },
    {
      "epoch": 4.938593380301819,
      "eval_loss": 0.42439088225364685,
      "eval_runtime": 47.16,
      "eval_samples_per_second": 3560.859,
      "eval_steps_per_second": 445.123,
      "step": 466500
    },
    {
      "epoch": 4.939122702081822,
      "grad_norm": 1.0533572435379028,
      "learning_rate": 0.0002988253593632112,
      "loss": 0.6355,
      "step": 466550
    },
    {
      "epoch": 4.939652023861826,
      "grad_norm": 1.0672638416290283,
      "learning_rate": 0.000298780055758852,
      "loss": 0.6355,
      "step": 466600
    },
    {
      "epoch": 4.940181345641829,
      "grad_norm": 1.0852190256118774,
      "learning_rate": 0.00029873475048915963,
      "loss": 0.634,
      "step": 466650
    },
    {
      "epoch": 4.940710667421833,
      "grad_norm": 1.0517176389694214,
      "learning_rate": 0.0002986894435556808,
      "loss": 0.6394,
      "step": 466700
    },
    {
      "epoch": 4.9412399892018355,
      "grad_norm": 1.0059698820114136,
      "learning_rate": 0.00029864413495996213,
      "loss": 0.6283,
      "step": 466750
    },
    {
      "epoch": 4.941769310981839,
      "grad_norm": 1.1205217838287354,
      "learning_rate": 0.0002985988247035506,
      "loss": 0.6555,
      "step": 466800
    },
    {
      "epoch": 4.942298632761842,
      "grad_norm": 1.0497467517852783,
      "learning_rate": 0.00029855351278799296,
      "loss": 0.635,
      "step": 466850
    },
    {
      "epoch": 4.942827954541846,
      "grad_norm": 1.04787015914917,
      "learning_rate": 0.0002985081992148362,
      "loss": 0.626,
      "step": 466900
    },
    {
      "epoch": 4.943357276321849,
      "grad_norm": 1.11802077293396,
      "learning_rate": 0.00029846288398562736,
      "loss": 0.6294,
      "step": 466950
    },
    {
      "epoch": 4.943886598101852,
      "grad_norm": 1.0981439352035522,
      "learning_rate": 0.0002984175671019134,
      "loss": 0.6369,
      "step": 467000
    },
    {
      "epoch": 4.943886598101852,
      "eval_loss": 0.4238230288028717,
      "eval_runtime": 47.1211,
      "eval_samples_per_second": 3563.799,
      "eval_steps_per_second": 445.491,
      "step": 467000
    },
    {
      "epoch": 4.944415919881855,
      "grad_norm": 1.0672208070755005,
      "learning_rate": 0.00029837224856524145,
      "loss": 0.6337,
      "step": 467050
    },
    {
      "epoch": 4.944945241661859,
      "grad_norm": 1.0079338550567627,
      "learning_rate": 0.0002983269283771587,
      "loss": 0.6313,
      "step": 467100
    },
    {
      "epoch": 4.945474563441862,
      "grad_norm": 1.1314516067504883,
      "learning_rate": 0.0002982816065392123,
      "loss": 0.6388,
      "step": 467150
    },
    {
      "epoch": 4.946003885221865,
      "grad_norm": 1.0802668333053589,
      "learning_rate": 0.0002982362830529495,
      "loss": 0.6369,
      "step": 467200
    },
    {
      "epoch": 4.946533207001869,
      "grad_norm": 1.0307508707046509,
      "learning_rate": 0.0002981909579199178,
      "loss": 0.6387,
      "step": 467250
    },
    {
      "epoch": 4.9470625287818715,
      "grad_norm": 1.0811172723770142,
      "learning_rate": 0.0002981456311416644,
      "loss": 0.6376,
      "step": 467300
    },
    {
      "epoch": 4.947591850561875,
      "grad_norm": 1.0170998573303223,
      "learning_rate": 0.0002981003027197369,
      "loss": 0.644,
      "step": 467350
    },
    {
      "epoch": 4.948121172341878,
      "grad_norm": 1.0302077531814575,
      "learning_rate": 0.00029805497265568263,
      "loss": 0.6298,
      "step": 467400
    },
    {
      "epoch": 4.948650494121882,
      "grad_norm": 1.0208125114440918,
      "learning_rate": 0.00029800964095104925,
      "loss": 0.6358,
      "step": 467450
    },
    {
      "epoch": 4.949179815901885,
      "grad_norm": 1.020710825920105,
      "learning_rate": 0.00029796430760738434,
      "loss": 0.6351,
      "step": 467500
    },
    {
      "epoch": 4.949179815901885,
      "eval_loss": 0.4225711226463318,
      "eval_runtime": 47.1345,
      "eval_samples_per_second": 3562.784,
      "eval_steps_per_second": 445.364,
      "step": 467500
    },
    {
      "epoch": 4.9497091376818885,
      "grad_norm": 0.9411614537239075,
      "learning_rate": 0.00029791897262623556,
      "loss": 0.6395,
      "step": 467550
    },
    {
      "epoch": 4.950238459461891,
      "grad_norm": 1.1400333642959595,
      "learning_rate": 0.0002978736360091506,
      "loss": 0.6374,
      "step": 467600
    },
    {
      "epoch": 4.950767781241895,
      "grad_norm": 1.0321226119995117,
      "learning_rate": 0.0002978282977576773,
      "loss": 0.6338,
      "step": 467650
    },
    {
      "epoch": 4.951297103021898,
      "grad_norm": 1.0711534023284912,
      "learning_rate": 0.0002977829578733634,
      "loss": 0.6447,
      "step": 467700
    },
    {
      "epoch": 4.951826424801901,
      "grad_norm": 1.0084989070892334,
      "learning_rate": 0.00029773761635775695,
      "loss": 0.6352,
      "step": 467750
    },
    {
      "epoch": 4.952355746581905,
      "grad_norm": 0.9722475409507751,
      "learning_rate": 0.00029769227321240567,
      "loss": 0.6328,
      "step": 467800
    },
    {
      "epoch": 4.952885068361908,
      "grad_norm": 1.1131532192230225,
      "learning_rate": 0.0002976469284388577,
      "loss": 0.6422,
      "step": 467850
    },
    {
      "epoch": 4.953414390141911,
      "grad_norm": 1.0931917428970337,
      "learning_rate": 0.00029760158203866107,
      "loss": 0.635,
      "step": 467900
    },
    {
      "epoch": 4.953943711921914,
      "grad_norm": 1.0174546241760254,
      "learning_rate": 0.0002975562340133639,
      "loss": 0.6392,
      "step": 467950
    },
    {
      "epoch": 4.954473033701918,
      "grad_norm": 1.106909155845642,
      "learning_rate": 0.0002975108843645143,
      "loss": 0.6366,
      "step": 468000
    },
    {
      "epoch": 4.954473033701918,
      "eval_loss": 0.42402201890945435,
      "eval_runtime": 47.0184,
      "eval_samples_per_second": 3571.582,
      "eval_steps_per_second": 446.464,
      "step": 468000
    },
    {
      "epoch": 4.955002355481921,
      "grad_norm": 1.1083155870437622,
      "learning_rate": 0.0002974655330936606,
      "loss": 0.6302,
      "step": 468050
    },
    {
      "epoch": 4.9555316772619245,
      "grad_norm": 1.0730102062225342,
      "learning_rate": 0.00029742018020235093,
      "loss": 0.6453,
      "step": 468100
    },
    {
      "epoch": 4.956060999041927,
      "grad_norm": 1.0398045778274536,
      "learning_rate": 0.00029737482569213374,
      "loss": 0.6318,
      "step": 468150
    },
    {
      "epoch": 4.956590320821931,
      "grad_norm": 1.0557870864868164,
      "learning_rate": 0.0002973294695645574,
      "loss": 0.6352,
      "step": 468200
    },
    {
      "epoch": 4.957119642601934,
      "grad_norm": 1.1324145793914795,
      "learning_rate": 0.0002972841118211703,
      "loss": 0.6289,
      "step": 468250
    },
    {
      "epoch": 4.957648964381938,
      "grad_norm": 1.0773191452026367,
      "learning_rate": 0.000297238752463521,
      "loss": 0.6301,
      "step": 468300
    },
    {
      "epoch": 4.958178286161941,
      "grad_norm": 1.0487582683563232,
      "learning_rate": 0.000297193391493158,
      "loss": 0.6341,
      "step": 468350
    },
    {
      "epoch": 4.958707607941944,
      "grad_norm": 1.143949031829834,
      "learning_rate": 0.0002971480289116299,
      "loss": 0.6446,
      "step": 468400
    },
    {
      "epoch": 4.959236929721947,
      "grad_norm": 0.995812714099884,
      "learning_rate": 0.00029710266472048535,
      "loss": 0.6358,
      "step": 468450
    },
    {
      "epoch": 4.95976625150195,
      "grad_norm": 1.025059700012207,
      "learning_rate": 0.0002970572989212732,
      "loss": 0.6347,
      "step": 468500
    },
    {
      "epoch": 4.95976625150195,
      "eval_loss": 0.4218241572380066,
      "eval_runtime": 47.1265,
      "eval_samples_per_second": 3563.389,
      "eval_steps_per_second": 445.439,
      "step": 468500
    },
    {
      "epoch": 4.960295573281954,
      "grad_norm": 1.0750535726547241,
      "learning_rate": 0.0002970119315155421,
      "loss": 0.633,
      "step": 468550
    },
    {
      "epoch": 4.960824895061958,
      "grad_norm": 1.0325003862380981,
      "learning_rate": 0.00029696656250484085,
      "loss": 0.6341,
      "step": 468600
    },
    {
      "epoch": 4.96135421684196,
      "grad_norm": 1.0630818605422974,
      "learning_rate": 0.0002969211918907184,
      "loss": 0.633,
      "step": 468650
    },
    {
      "epoch": 4.961883538621963,
      "grad_norm": 1.167592167854309,
      "learning_rate": 0.0002968758196747236,
      "loss": 0.6314,
      "step": 468700
    },
    {
      "epoch": 4.962412860401967,
      "grad_norm": 1.022095799446106,
      "learning_rate": 0.0002968304458584056,
      "loss": 0.6232,
      "step": 468750
    },
    {
      "epoch": 4.96294218218197,
      "grad_norm": 1.1638520956039429,
      "learning_rate": 0.00029678507044331333,
      "loss": 0.6431,
      "step": 468800
    },
    {
      "epoch": 4.963471503961974,
      "grad_norm": 1.1123647689819336,
      "learning_rate": 0.0002967396934309958,
      "loss": 0.6429,
      "step": 468850
    },
    {
      "epoch": 4.9640008257419765,
      "grad_norm": 1.2048591375350952,
      "learning_rate": 0.00029669431482300243,
      "loss": 0.6294,
      "step": 468900
    },
    {
      "epoch": 4.96453014752198,
      "grad_norm": 0.9894402623176575,
      "learning_rate": 0.0002966489346208822,
      "loss": 0.6261,
      "step": 468950
    },
    {
      "epoch": 4.965059469301983,
      "grad_norm": 1.0065014362335205,
      "learning_rate": 0.0002966035528261845,
      "loss": 0.6339,
      "step": 469000
    },
    {
      "epoch": 4.965059469301983,
      "eval_loss": 0.42398887872695923,
      "eval_runtime": 46.8005,
      "eval_samples_per_second": 3588.208,
      "eval_steps_per_second": 448.542,
      "step": 469000
    },
    {
      "epoch": 4.965588791081987,
      "grad_norm": 1.0194185972213745,
      "learning_rate": 0.0002965581694404586,
      "loss": 0.6317,
      "step": 469050
    },
    {
      "epoch": 4.96611811286199,
      "grad_norm": 1.1518090963363647,
      "learning_rate": 0.0002965127844652538,
      "loss": 0.6325,
      "step": 469100
    },
    {
      "epoch": 4.9666474346419935,
      "grad_norm": 1.0600290298461914,
      "learning_rate": 0.0002964673979021197,
      "loss": 0.6255,
      "step": 469150
    },
    {
      "epoch": 4.967176756421996,
      "grad_norm": 0.9695703387260437,
      "learning_rate": 0.0002964220097526056,
      "loss": 0.6263,
      "step": 469200
    },
    {
      "epoch": 4.967706078202,
      "grad_norm": 1.1064876317977905,
      "learning_rate": 0.0002963766200182612,
      "loss": 0.6405,
      "step": 469250
    },
    {
      "epoch": 4.968235399982003,
      "grad_norm": 1.0851069688796997,
      "learning_rate": 0.0002963312287006359,
      "loss": 0.6287,
      "step": 469300
    },
    {
      "epoch": 4.968764721762007,
      "grad_norm": 0.9413466453552246,
      "learning_rate": 0.00029628583580127945,
      "loss": 0.633,
      "step": 469350
    },
    {
      "epoch": 4.96929404354201,
      "grad_norm": 1.0879675149917603,
      "learning_rate": 0.00029624044132174154,
      "loss": 0.6278,
      "step": 469400
    },
    {
      "epoch": 4.9698233653220125,
      "grad_norm": 1.0670627355575562,
      "learning_rate": 0.000296195045263572,
      "loss": 0.6293,
      "step": 469450
    },
    {
      "epoch": 4.970352687102016,
      "grad_norm": 1.0099231004714966,
      "learning_rate": 0.0002961496476283205,
      "loss": 0.6475,
      "step": 469500
    },
    {
      "epoch": 4.970352687102016,
      "eval_loss": 0.42358535528182983,
      "eval_runtime": 46.9103,
      "eval_samples_per_second": 3579.808,
      "eval_steps_per_second": 447.492,
      "step": 469500
    },
    {
      "epoch": 4.970882008882019,
      "grad_norm": 1.0926450490951538,
      "learning_rate": 0.00029610424841753697,
      "loss": 0.6447,
      "step": 469550
    },
    {
      "epoch": 4.971411330662023,
      "grad_norm": 0.9819314479827881,
      "learning_rate": 0.0002960588476327713,
      "loss": 0.6333,
      "step": 469600
    },
    {
      "epoch": 4.971940652442026,
      "grad_norm": 0.9861904382705688,
      "learning_rate": 0.00029601344527557344,
      "loss": 0.6323,
      "step": 469650
    },
    {
      "epoch": 4.9724699742220295,
      "grad_norm": 1.0407848358154297,
      "learning_rate": 0.0002959680413474934,
      "loss": 0.6277,
      "step": 469700
    },
    {
      "epoch": 4.972999296002032,
      "grad_norm": 1.1512435674667358,
      "learning_rate": 0.00029592263585008136,
      "loss": 0.6499,
      "step": 469750
    },
    {
      "epoch": 4.973528617782036,
      "grad_norm": 1.0975990295410156,
      "learning_rate": 0.0002958772287848873,
      "loss": 0.6373,
      "step": 469800
    },
    {
      "epoch": 4.974057939562039,
      "grad_norm": 1.1407556533813477,
      "learning_rate": 0.0002958318201534616,
      "loss": 0.6324,
      "step": 469850
    },
    {
      "epoch": 4.974587261342043,
      "grad_norm": 1.1473268270492554,
      "learning_rate": 0.0002957864099573543,
      "loss": 0.6343,
      "step": 469900
    },
    {
      "epoch": 4.975116583122046,
      "grad_norm": 1.1158121824264526,
      "learning_rate": 0.00029574190644860923,
      "loss": 0.6293,
      "step": 469950
    },
    {
      "epoch": 4.975645904902049,
      "grad_norm": 1.1253150701522827,
      "learning_rate": 0.00029569649315900617,
      "loss": 0.6393,
      "step": 470000
    },
    {
      "epoch": 4.975645904902049,
      "eval_loss": 0.4213688373565674,
      "eval_runtime": 47.1441,
      "eval_samples_per_second": 3562.054,
      "eval_steps_per_second": 445.273,
      "step": 470000
    },
    {
      "epoch": 4.976175226682052,
      "grad_norm": 1.0592293739318848,
      "learning_rate": 0.0002956510783093416,
      "loss": 0.6389,
      "step": 470050
    },
    {
      "epoch": 4.976704548462056,
      "grad_norm": 1.1044261455535889,
      "learning_rate": 0.000295605661901166,
      "loss": 0.6432,
      "step": 470100
    },
    {
      "epoch": 4.977233870242059,
      "grad_norm": 0.9839956760406494,
      "learning_rate": 0.00029556024393602974,
      "loss": 0.6374,
      "step": 470150
    },
    {
      "epoch": 4.977763192022062,
      "grad_norm": 1.1333842277526855,
      "learning_rate": 0.0002955148244154836,
      "loss": 0.6449,
      "step": 470200
    },
    {
      "epoch": 4.9782925138020655,
      "grad_norm": 1.0923326015472412,
      "learning_rate": 0.00029546940334107796,
      "loss": 0.6415,
      "step": 470250
    },
    {
      "epoch": 4.978821835582068,
      "grad_norm": 0.9940231442451477,
      "learning_rate": 0.0002954239807143636,
      "loss": 0.6367,
      "step": 470300
    },
    {
      "epoch": 4.979351157362072,
      "grad_norm": 1.214094638824463,
      "learning_rate": 0.0002953785565368912,
      "loss": 0.6294,
      "step": 470350
    },
    {
      "epoch": 4.979880479142075,
      "grad_norm": 1.1190632581710815,
      "learning_rate": 0.0002953331308102115,
      "loss": 0.6365,
      "step": 470400
    },
    {
      "epoch": 4.980409800922079,
      "grad_norm": 1.0836882591247559,
      "learning_rate": 0.0002952877035358753,
      "loss": 0.6332,
      "step": 470450
    },
    {
      "epoch": 4.980939122702082,
      "grad_norm": 0.9761850833892822,
      "learning_rate": 0.0002952422747154336,
      "loss": 0.6386,
      "step": 470500
    },
    {
      "epoch": 4.980939122702082,
      "eval_loss": 0.42145249247550964,
      "eval_runtime": 47.0372,
      "eval_samples_per_second": 3570.153,
      "eval_steps_per_second": 446.285,
      "step": 470500
    },
    {
      "epoch": 4.981468444482085,
      "grad_norm": 1.1847341060638428,
      "learning_rate": 0.0002951968443504372,
      "loss": 0.6419,
      "step": 470550
    },
    {
      "epoch": 4.981997766262088,
      "grad_norm": 1.0371934175491333,
      "learning_rate": 0.0002951514124424371,
      "loss": 0.6355,
      "step": 470600
    },
    {
      "epoch": 4.982527088042092,
      "grad_norm": 1.1240448951721191,
      "learning_rate": 0.0002951059789929843,
      "loss": 0.6356,
      "step": 470650
    },
    {
      "epoch": 4.983056409822095,
      "grad_norm": 1.1496505737304688,
      "learning_rate": 0.00029506054400363,
      "loss": 0.6348,
      "step": 470700
    },
    {
      "epoch": 4.983585731602099,
      "grad_norm": 1.2236149311065674,
      "learning_rate": 0.00029501510747592517,
      "loss": 0.6337,
      "step": 470750
    },
    {
      "epoch": 4.9841150533821015,
      "grad_norm": 0.9717358350753784,
      "learning_rate": 0.00029497057818776175,
      "loss": 0.6282,
      "step": 470800
    },
    {
      "epoch": 4.984644375162105,
      "grad_norm": 1.0749564170837402,
      "learning_rate": 0.0002949251386186994,
      "loss": 0.6406,
      "step": 470850
    },
    {
      "epoch": 4.985173696942108,
      "grad_norm": 0.9771601557731628,
      "learning_rate": 0.00029487969751590935,
      "loss": 0.6374,
      "step": 470900
    },
    {
      "epoch": 4.985703018722111,
      "grad_norm": 0.9971118569374084,
      "learning_rate": 0.00029483425488094285,
      "loss": 0.6473,
      "step": 470950
    },
    {
      "epoch": 4.986232340502115,
      "grad_norm": 1.15434992313385,
      "learning_rate": 0.00029478881071535133,
      "loss": 0.6294,
      "step": 471000
    },
    {
      "epoch": 4.986232340502115,
      "eval_loss": 0.4220919907093048,
      "eval_runtime": 47.2023,
      "eval_samples_per_second": 3557.664,
      "eval_steps_per_second": 444.724,
      "step": 471000
    },
    {
      "epoch": 4.986761662282118,
      "grad_norm": 1.082521915435791,
      "learning_rate": 0.0002947433650206863,
      "loss": 0.635,
      "step": 471050
    },
    {
      "epoch": 4.987290984062121,
      "grad_norm": 1.1102508306503296,
      "learning_rate": 0.00029469791779849916,
      "loss": 0.6326,
      "step": 471100
    },
    {
      "epoch": 4.987820305842124,
      "grad_norm": 1.0809264183044434,
      "learning_rate": 0.0002946524690503415,
      "loss": 0.6344,
      "step": 471150
    },
    {
      "epoch": 4.988349627622128,
      "grad_norm": 1.0693179368972778,
      "learning_rate": 0.00029460701877776483,
      "loss": 0.6284,
      "step": 471200
    },
    {
      "epoch": 4.988878949402131,
      "grad_norm": 1.0946528911590576,
      "learning_rate": 0.00029456156698232105,
      "loss": 0.6369,
      "step": 471250
    },
    {
      "epoch": 4.989408271182135,
      "grad_norm": 1.026732325553894,
      "learning_rate": 0.00029451611366556165,
      "loss": 0.6441,
      "step": 471300
    },
    {
      "epoch": 4.9899375929621375,
      "grad_norm": 1.1369526386260986,
      "learning_rate": 0.00029447065882903843,
      "loss": 0.6436,
      "step": 471350
    },
    {
      "epoch": 4.990466914742141,
      "grad_norm": 1.0204883813858032,
      "learning_rate": 0.0002944252024743033,
      "loss": 0.6358,
      "step": 471400
    },
    {
      "epoch": 4.990996236522144,
      "grad_norm": 1.0903306007385254,
      "learning_rate": 0.00029437974460290797,
      "loss": 0.641,
      "step": 471450
    },
    {
      "epoch": 4.991525558302148,
      "grad_norm": 0.9806420207023621,
      "learning_rate": 0.00029433428521640436,
      "loss": 0.6359,
      "step": 471500
    },
    {
      "epoch": 4.991525558302148,
      "eval_loss": 0.4197772741317749,
      "eval_runtime": 46.9381,
      "eval_samples_per_second": 3577.689,
      "eval_steps_per_second": 447.227,
      "step": 471500
    },
    {
      "epoch": 4.992054880082151,
      "grad_norm": 1.2339333295822144,
      "learning_rate": 0.00029428882431634465,
      "loss": 0.6366,
      "step": 471550
    },
    {
      "epoch": 4.9925842018621545,
      "grad_norm": 1.1270921230316162,
      "learning_rate": 0.0002942433619042807,
      "loss": 0.6401,
      "step": 471600
    },
    {
      "epoch": 4.993113523642157,
      "grad_norm": 1.0408480167388916,
      "learning_rate": 0.0002941978979817645,
      "loss": 0.6408,
      "step": 471650
    },
    {
      "epoch": 4.99364284542216,
      "grad_norm": 1.118293285369873,
      "learning_rate": 0.0002941524325503484,
      "loss": 0.6453,
      "step": 471700
    },
    {
      "epoch": 4.994172167202164,
      "grad_norm": 0.998096227645874,
      "learning_rate": 0.00029410696561158443,
      "loss": 0.6423,
      "step": 471750
    },
    {
      "epoch": 4.994701488982167,
      "grad_norm": 1.09488046169281,
      "learning_rate": 0.0002940614971670248,
      "loss": 0.638,
      "step": 471800
    },
    {
      "epoch": 4.995230810762171,
      "grad_norm": 1.0099966526031494,
      "learning_rate": 0.0002940160272182218,
      "loss": 0.6357,
      "step": 471850
    },
    {
      "epoch": 4.995760132542173,
      "grad_norm": 1.1044234037399292,
      "learning_rate": 0.00029397055576672784,
      "loss": 0.626,
      "step": 471900
    },
    {
      "epoch": 4.996289454322177,
      "grad_norm": 1.0555040836334229,
      "learning_rate": 0.00029392508281409516,
      "loss": 0.6362,
      "step": 471950
    },
    {
      "epoch": 4.99681877610218,
      "grad_norm": 1.2381799221038818,
      "learning_rate": 0.00029387960836187627,
      "loss": 0.6389,
      "step": 472000
    },
    {
      "epoch": 4.99681877610218,
      "eval_loss": 0.42187052965164185,
      "eval_runtime": 47.4554,
      "eval_samples_per_second": 3538.694,
      "eval_steps_per_second": 442.352,
      "step": 472000
    },
    {
      "epoch": 4.997348097882184,
      "grad_norm": 1.0215646028518677,
      "learning_rate": 0.00029383413241162364,
      "loss": 0.6344,
      "step": 472050
    },
    {
      "epoch": 4.997877419662187,
      "grad_norm": 1.1052035093307495,
      "learning_rate": 0.00029378865496488985,
      "loss": 0.6325,
      "step": 472100
    },
    {
      "epoch": 4.99840674144219,
      "grad_norm": 1.0857889652252197,
      "learning_rate": 0.0002937431760232274,
      "loss": 0.6332,
      "step": 472150
    },
    {
      "epoch": 4.998936063222193,
      "grad_norm": 1.1160982847213745,
      "learning_rate": 0.000293697695588189,
      "loss": 0.6386,
      "step": 472200
    },
    {
      "epoch": 4.999465385002197,
      "grad_norm": 1.0190491676330566,
      "learning_rate": 0.0002936522136613273,
      "loss": 0.6378,
      "step": 472250
    },
    {
      "epoch": 4.9999947067822,
      "grad_norm": 1.035417079925537,
      "learning_rate": 0.000293606730244195,
      "loss": 0.6399,
      "step": 472300
    },
    {
      "epoch": 5.000529321780003,
      "grad_norm": 1.0111229419708252,
      "learning_rate": 0.0002935612453383448,
      "loss": 0.635,
      "step": 472350
    },
    {
      "epoch": 5.001058643560007,
      "grad_norm": 1.0857658386230469,
      "learning_rate": 0.0002935157589453298,
      "loss": 0.6272,
      "step": 472400
    },
    {
      "epoch": 5.0015879653400095,
      "grad_norm": 1.0557328462600708,
      "learning_rate": 0.00029347027106670277,
      "loss": 0.6299,
      "step": 472450
    },
    {
      "epoch": 5.002117287120013,
      "grad_norm": 1.0421417951583862,
      "learning_rate": 0.0002934247817040166,
      "loss": 0.6331,
      "step": 472500
    },
    {
      "epoch": 5.002117287120013,
      "eval_loss": 0.4196528494358063,
      "eval_runtime": 47.4792,
      "eval_samples_per_second": 3536.92,
      "eval_steps_per_second": 442.131,
      "step": 472500
    },
    {
      "epoch": 5.002646608900016,
      "grad_norm": 0.9752956628799438,
      "learning_rate": 0.0002933792908588243,
      "loss": 0.625,
      "step": 472550
    },
    {
      "epoch": 5.00317593068002,
      "grad_norm": 1.1104298830032349,
      "learning_rate": 0.00029333379853267895,
      "loss": 0.6265,
      "step": 472600
    },
    {
      "epoch": 5.003705252460023,
      "grad_norm": 1.066324234008789,
      "learning_rate": 0.0002932883047271335,
      "loss": 0.6354,
      "step": 472650
    },
    {
      "epoch": 5.0042345742400265,
      "grad_norm": 1.0440053939819336,
      "learning_rate": 0.00029324280944374135,
      "loss": 0.6284,
      "step": 472700
    },
    {
      "epoch": 5.004763896020029,
      "grad_norm": 0.9930887818336487,
      "learning_rate": 0.0002931973126840555,
      "loss": 0.6282,
      "step": 472750
    },
    {
      "epoch": 5.005293217800033,
      "grad_norm": 1.1946690082550049,
      "learning_rate": 0.00029315181444962917,
      "loss": 0.6327,
      "step": 472800
    },
    {
      "epoch": 5.005822539580036,
      "grad_norm": 1.1392228603363037,
      "learning_rate": 0.00029310631474201577,
      "loss": 0.6227,
      "step": 472850
    },
    {
      "epoch": 5.00635186136004,
      "grad_norm": 1.2101502418518066,
      "learning_rate": 0.0002930608135627686,
      "loss": 0.6322,
      "step": 472900
    },
    {
      "epoch": 5.006881183140043,
      "grad_norm": 1.1330091953277588,
      "learning_rate": 0.00029301531091344103,
      "loss": 0.6311,
      "step": 472950
    },
    {
      "epoch": 5.007410504920046,
      "grad_norm": 1.0691155195236206,
      "learning_rate": 0.0002929698067955865,
      "loss": 0.636,
      "step": 473000
    },
    {
      "epoch": 5.007410504920046,
      "eval_loss": 0.41933488845825195,
      "eval_runtime": 47.2955,
      "eval_samples_per_second": 3550.656,
      "eval_steps_per_second": 443.848,
      "step": 473000
    },
    {
      "epoch": 5.007939826700049,
      "grad_norm": 1.0569992065429688,
      "learning_rate": 0.00029292430121075855,
      "loss": 0.6276,
      "step": 473050
    },
    {
      "epoch": 5.008469148480052,
      "grad_norm": 1.0149909257888794,
      "learning_rate": 0.0002928787941605108,
      "loss": 0.6427,
      "step": 473100
    },
    {
      "epoch": 5.008998470260056,
      "grad_norm": 1.084114909172058,
      "learning_rate": 0.00029283328564639656,
      "loss": 0.6302,
      "step": 473150
    },
    {
      "epoch": 5.009527792040059,
      "grad_norm": 1.0782231092453003,
      "learning_rate": 0.00029278777566996974,
      "loss": 0.626,
      "step": 473200
    },
    {
      "epoch": 5.0100571138200625,
      "grad_norm": 1.121713399887085,
      "learning_rate": 0.00029274226423278395,
      "loss": 0.6293,
      "step": 473250
    },
    {
      "epoch": 5.010586435600065,
      "grad_norm": 1.1026071310043335,
      "learning_rate": 0.00029269675133639295,
      "loss": 0.6261,
      "step": 473300
    },
    {
      "epoch": 5.011115757380069,
      "grad_norm": 1.1107373237609863,
      "learning_rate": 0.00029265123698235046,
      "loss": 0.6376,
      "step": 473350
    },
    {
      "epoch": 5.011645079160072,
      "grad_norm": 1.0009984970092773,
      "learning_rate": 0.00029260572117221047,
      "loss": 0.6253,
      "step": 473400
    },
    {
      "epoch": 5.012174400940076,
      "grad_norm": 1.028486967086792,
      "learning_rate": 0.0002925602039075267,
      "loss": 0.6255,
      "step": 473450
    },
    {
      "epoch": 5.012703722720079,
      "grad_norm": 1.1791452169418335,
      "learning_rate": 0.00029251468518985327,
      "loss": 0.6373,
      "step": 473500
    },
    {
      "epoch": 5.012703722720079,
      "eval_loss": 0.4202226996421814,
      "eval_runtime": 47.4648,
      "eval_samples_per_second": 3537.994,
      "eval_steps_per_second": 442.265,
      "step": 473500
    },
    {
      "epoch": 5.013233044500082,
      "grad_norm": 1.096531629562378,
      "learning_rate": 0.000292469165020744,
      "loss": 0.6242,
      "step": 473550
    },
    {
      "epoch": 5.013762366280085,
      "grad_norm": 1.01105535030365,
      "learning_rate": 0.00029242364340175303,
      "loss": 0.6292,
      "step": 473600
    },
    {
      "epoch": 5.014291688060089,
      "grad_norm": 1.0818202495574951,
      "learning_rate": 0.00029237812033443446,
      "loss": 0.6374,
      "step": 473650
    },
    {
      "epoch": 5.014821009840092,
      "grad_norm": 0.99021977186203,
      "learning_rate": 0.0002923325958203424,
      "loss": 0.622,
      "step": 473700
    },
    {
      "epoch": 5.015350331620096,
      "grad_norm": 1.024172306060791,
      "learning_rate": 0.000292287069861031,
      "loss": 0.6383,
      "step": 473750
    },
    {
      "epoch": 5.0158796534000984,
      "grad_norm": 1.0360170602798462,
      "learning_rate": 0.00029224154245805455,
      "loss": 0.6327,
      "step": 473800
    },
    {
      "epoch": 5.016408975180101,
      "grad_norm": 1.1563422679901123,
      "learning_rate": 0.0002921960136129674,
      "loss": 0.6359,
      "step": 473850
    },
    {
      "epoch": 5.016938296960105,
      "grad_norm": 1.0808321237564087,
      "learning_rate": 0.0002921504833273237,
      "loss": 0.6215,
      "step": 473900
    },
    {
      "epoch": 5.017467618740108,
      "grad_norm": 1.0715522766113281,
      "learning_rate": 0.00029210495160267807,
      "loss": 0.6302,
      "step": 473950
    },
    {
      "epoch": 5.017996940520112,
      "grad_norm": 1.0567493438720703,
      "learning_rate": 0.00029205941844058476,
      "loss": 0.6221,
      "step": 474000
    },
    {
      "epoch": 5.017996940520112,
      "eval_loss": 0.4174201488494873,
      "eval_runtime": 48.3348,
      "eval_samples_per_second": 3474.312,
      "eval_steps_per_second": 434.304,
      "step": 474000
    },
    {
      "epoch": 5.018526262300115,
      "grad_norm": 0.9356294870376587,
      "learning_rate": 0.0002920138838425984,
      "loss": 0.631,
      "step": 474050
    },
    {
      "epoch": 5.019055584080118,
      "grad_norm": 1.1103277206420898,
      "learning_rate": 0.00029196834781027335,
      "loss": 0.6353,
      "step": 474100
    },
    {
      "epoch": 5.019584905860121,
      "grad_norm": 0.8708274960517883,
      "learning_rate": 0.00029192281034516436,
      "loss": 0.6263,
      "step": 474150
    },
    {
      "epoch": 5.020114227640125,
      "grad_norm": 1.1586048603057861,
      "learning_rate": 0.00029187727144882605,
      "loss": 0.6273,
      "step": 474200
    },
    {
      "epoch": 5.020643549420128,
      "grad_norm": 1.1454014778137207,
      "learning_rate": 0.00029183173112281294,
      "loss": 0.6287,
      "step": 474250
    },
    {
      "epoch": 5.021172871200132,
      "grad_norm": 1.0453383922576904,
      "learning_rate": 0.00029178618936867996,
      "loss": 0.6189,
      "step": 474300
    },
    {
      "epoch": 5.021702192980134,
      "grad_norm": 1.1092027425765991,
      "learning_rate": 0.0002917406461879818,
      "loss": 0.6169,
      "step": 474350
    },
    {
      "epoch": 5.022231514760138,
      "grad_norm": 1.0294194221496582,
      "learning_rate": 0.00029169510158227326,
      "loss": 0.6257,
      "step": 474400
    },
    {
      "epoch": 5.022760836540141,
      "grad_norm": 1.037235140800476,
      "learning_rate": 0.0002916495555531092,
      "loss": 0.6326,
      "step": 474450
    },
    {
      "epoch": 5.023290158320145,
      "grad_norm": 1.1180131435394287,
      "learning_rate": 0.0002916040081020447,
      "loss": 0.624,
      "step": 474500
    },
    {
      "epoch": 5.023290158320145,
      "eval_loss": 0.4193980097770691,
      "eval_runtime": 47.9726,
      "eval_samples_per_second": 3500.542,
      "eval_steps_per_second": 437.583,
      "step": 474500
    },
    {
      "epoch": 5.023819480100148,
      "grad_norm": 1.0020043849945068,
      "learning_rate": 0.0002915584592306345,
      "loss": 0.6306,
      "step": 474550
    },
    {
      "epoch": 5.0243488018801505,
      "grad_norm": 1.025413155555725,
      "learning_rate": 0.00029151290894043383,
      "loss": 0.6249,
      "step": 474600
    },
    {
      "epoch": 5.024878123660154,
      "grad_norm": 1.1273963451385498,
      "learning_rate": 0.00029146735723299764,
      "loss": 0.6287,
      "step": 474650
    },
    {
      "epoch": 5.025407445440157,
      "grad_norm": 1.0846731662750244,
      "learning_rate": 0.00029142180410988104,
      "loss": 0.618,
      "step": 474700
    },
    {
      "epoch": 5.025936767220161,
      "grad_norm": 1.0174347162246704,
      "learning_rate": 0.0002913762495726393,
      "loss": 0.6288,
      "step": 474750
    },
    {
      "epoch": 5.026466089000164,
      "grad_norm": 1.1149731874465942,
      "learning_rate": 0.00029133160475565694,
      "loss": 0.636,
      "step": 474800
    },
    {
      "epoch": 5.0269954107801675,
      "grad_norm": 1.2134478092193604,
      "learning_rate": 0.00029128604742303547,
      "loss": 0.6373,
      "step": 474850
    },
    {
      "epoch": 5.02752473256017,
      "grad_norm": 1.0942343473434448,
      "learning_rate": 0.0002912404886809236,
      "loss": 0.6316,
      "step": 474900
    },
    {
      "epoch": 5.028054054340174,
      "grad_norm": 1.1790754795074463,
      "learning_rate": 0.00029119492853087647,
      "loss": 0.6283,
      "step": 474950
    },
    {
      "epoch": 5.028583376120177,
      "grad_norm": 1.1102519035339355,
      "learning_rate": 0.0002911493669744497,
      "loss": 0.6279,
      "step": 475000
    },
    {
      "epoch": 5.028583376120177,
      "eval_loss": 0.41885682940483093,
      "eval_runtime": 47.7073,
      "eval_samples_per_second": 3520.006,
      "eval_steps_per_second": 440.016,
      "step": 475000
    },
    {
      "epoch": 5.029112697900181,
      "grad_norm": 1.13705313205719,
      "learning_rate": 0.00029110380401319854,
      "loss": 0.6305,
      "step": 475050
    },
    {
      "epoch": 5.029642019680184,
      "grad_norm": 1.0504447221755981,
      "learning_rate": 0.0002910582396486786,
      "loss": 0.6278,
      "step": 475100
    },
    {
      "epoch": 5.030171341460187,
      "grad_norm": 1.1213866472244263,
      "learning_rate": 0.0002910126738824454,
      "loss": 0.6377,
      "step": 475150
    },
    {
      "epoch": 5.03070066324019,
      "grad_norm": 1.0513403415679932,
      "learning_rate": 0.0002909671067160546,
      "loss": 0.6418,
      "step": 475200
    },
    {
      "epoch": 5.031229985020194,
      "grad_norm": 1.0499802827835083,
      "learning_rate": 0.0002909215381510617,
      "loss": 0.6366,
      "step": 475250
    },
    {
      "epoch": 5.031759306800197,
      "grad_norm": 1.0443974733352661,
      "learning_rate": 0.00029087596818902256,
      "loss": 0.6307,
      "step": 475300
    },
    {
      "epoch": 5.0322886285802,
      "grad_norm": 1.0987122058868408,
      "learning_rate": 0.00029083039683149286,
      "loss": 0.6374,
      "step": 475350
    },
    {
      "epoch": 5.0328179503602035,
      "grad_norm": 0.9656646251678467,
      "learning_rate": 0.00029078482408002843,
      "loss": 0.621,
      "step": 475400
    },
    {
      "epoch": 5.033347272140206,
      "grad_norm": 0.9902089238166809,
      "learning_rate": 0.000290739249936185,
      "loss": 0.6186,
      "step": 475450
    },
    {
      "epoch": 5.03387659392021,
      "grad_norm": 1.0788406133651733,
      "learning_rate": 0.00029069367440151853,
      "loss": 0.6242,
      "step": 475500
    },
    {
      "epoch": 5.03387659392021,
      "eval_loss": 0.41849133372306824,
      "eval_runtime": 47.6686,
      "eval_samples_per_second": 3522.863,
      "eval_steps_per_second": 440.374,
      "step": 475500
    },
    {
      "epoch": 5.034405915700213,
      "grad_norm": 0.9815695285797119,
      "learning_rate": 0.000290648097477585,
      "loss": 0.6321,
      "step": 475550
    },
    {
      "epoch": 5.034935237480217,
      "grad_norm": 1.0592105388641357,
      "learning_rate": 0.00029060251916594027,
      "loss": 0.6284,
      "step": 475600
    },
    {
      "epoch": 5.03546455926022,
      "grad_norm": 1.0175001621246338,
      "learning_rate": 0.0002905569394681404,
      "loss": 0.6342,
      "step": 475650
    },
    {
      "epoch": 5.035993881040223,
      "grad_norm": 1.082137107849121,
      "learning_rate": 0.00029051135838574157,
      "loss": 0.6289,
      "step": 475700
    },
    {
      "epoch": 5.036523202820226,
      "grad_norm": 1.0630971193313599,
      "learning_rate": 0.00029046577592029975,
      "loss": 0.6417,
      "step": 475750
    },
    {
      "epoch": 5.03705252460023,
      "grad_norm": 1.0511800050735474,
      "learning_rate": 0.0002904201920733712,
      "loss": 0.6282,
      "step": 475800
    },
    {
      "epoch": 5.037581846380233,
      "grad_norm": 1.1054185628890991,
      "learning_rate": 0.0002903746068465122,
      "loss": 0.6254,
      "step": 475850
    },
    {
      "epoch": 5.038111168160237,
      "grad_norm": 1.1005816459655762,
      "learning_rate": 0.00029032902024127885,
      "loss": 0.6245,
      "step": 475900
    },
    {
      "epoch": 5.0386404899402395,
      "grad_norm": 1.0665236711502075,
      "learning_rate": 0.00029028343225922756,
      "loss": 0.6242,
      "step": 475950
    },
    {
      "epoch": 5.039169811720243,
      "grad_norm": 1.0663678646087646,
      "learning_rate": 0.00029023784290191465,
      "loss": 0.6341,
      "step": 476000
    },
    {
      "epoch": 5.039169811720243,
      "eval_loss": 0.4185171127319336,
      "eval_runtime": 46.8273,
      "eval_samples_per_second": 3586.155,
      "eval_steps_per_second": 448.285,
      "step": 476000
    },
    {
      "epoch": 5.039699133500246,
      "grad_norm": 1.032518982887268,
      "learning_rate": 0.00029019225217089646,
      "loss": 0.6367,
      "step": 476050
    },
    {
      "epoch": 5.040228455280249,
      "grad_norm": 1.1050362586975098,
      "learning_rate": 0.0002901466600677296,
      "loss": 0.6253,
      "step": 476100
    },
    {
      "epoch": 5.040757777060253,
      "grad_norm": 1.054666519165039,
      "learning_rate": 0.0002901010665939705,
      "loss": 0.6411,
      "step": 476150
    },
    {
      "epoch": 5.041287098840256,
      "grad_norm": 1.0556542873382568,
      "learning_rate": 0.00029005547175117567,
      "loss": 0.6353,
      "step": 476200
    },
    {
      "epoch": 5.041816420620259,
      "grad_norm": 1.0603344440460205,
      "learning_rate": 0.00029000987554090175,
      "loss": 0.6242,
      "step": 476250
    },
    {
      "epoch": 5.042345742400262,
      "grad_norm": 1.1919742822647095,
      "learning_rate": 0.0002899642779647054,
      "loss": 0.6288,
      "step": 476300
    },
    {
      "epoch": 5.042875064180266,
      "grad_norm": 0.9253861308097839,
      "learning_rate": 0.00028991867902414313,
      "loss": 0.6351,
      "step": 476350
    },
    {
      "epoch": 5.043404385960269,
      "grad_norm": 1.1265666484832764,
      "learning_rate": 0.0002898730787207719,
      "loss": 0.6251,
      "step": 476400
    },
    {
      "epoch": 5.043933707740273,
      "grad_norm": 1.1349257230758667,
      "learning_rate": 0.00028982747705614837,
      "loss": 0.6267,
      "step": 476450
    },
    {
      "epoch": 5.0444630295202755,
      "grad_norm": 1.0218186378479004,
      "learning_rate": 0.00028978187403182936,
      "loss": 0.6235,
      "step": 476500
    },
    {
      "epoch": 5.0444630295202755,
      "eval_loss": 0.4185192584991455,
      "eval_runtime": 46.8541,
      "eval_samples_per_second": 3584.102,
      "eval_steps_per_second": 448.029,
      "step": 476500
    },
    {
      "epoch": 5.044992351300279,
      "grad_norm": 1.0574238300323486,
      "learning_rate": 0.00028973626964937175,
      "loss": 0.6285,
      "step": 476550
    },
    {
      "epoch": 5.045521673080282,
      "grad_norm": 1.0303758382797241,
      "learning_rate": 0.00028969066391033247,
      "loss": 0.6272,
      "step": 476600
    },
    {
      "epoch": 5.046050994860286,
      "grad_norm": 1.0086305141448975,
      "learning_rate": 0.00028964505681626854,
      "loss": 0.6258,
      "step": 476650
    },
    {
      "epoch": 5.046580316640289,
      "grad_norm": 1.0454261302947998,
      "learning_rate": 0.00028959944836873686,
      "loss": 0.623,
      "step": 476700
    },
    {
      "epoch": 5.0471096384202925,
      "grad_norm": 1.0712827444076538,
      "learning_rate": 0.0002895538385692945,
      "loss": 0.6193,
      "step": 476750
    },
    {
      "epoch": 5.047638960200295,
      "grad_norm": 1.182043194770813,
      "learning_rate": 0.00028950822741949866,
      "loss": 0.6233,
      "step": 476800
    },
    {
      "epoch": 5.048168281980298,
      "grad_norm": 1.0031713247299194,
      "learning_rate": 0.0002894626149209064,
      "loss": 0.6232,
      "step": 476850
    },
    {
      "epoch": 5.048697603760302,
      "grad_norm": 1.0507253408432007,
      "learning_rate": 0.0002894179133651844,
      "loss": 0.6314,
      "step": 476900
    },
    {
      "epoch": 5.049226925540305,
      "grad_norm": 1.125747561454773,
      "learning_rate": 0.00028937229820056936,
      "loss": 0.6259,
      "step": 476950
    },
    {
      "epoch": 5.049756247320309,
      "grad_norm": 1.0183552503585815,
      "learning_rate": 0.0002893266816917985,
      "loss": 0.6257,
      "step": 477000
    },
    {
      "epoch": 5.049756247320309,
      "eval_loss": 0.42013898491859436,
      "eval_runtime": 46.9704,
      "eval_samples_per_second": 3575.229,
      "eval_steps_per_second": 446.92,
      "step": 477000
    },
    {
      "epoch": 5.0502855691003115,
      "grad_norm": 1.1360785961151123,
      "learning_rate": 0.0002892810638404291,
      "loss": 0.6267,
      "step": 477050
    },
    {
      "epoch": 5.050814890880315,
      "grad_norm": 1.0391466617584229,
      "learning_rate": 0.00028923544464801865,
      "loss": 0.6341,
      "step": 477100
    },
    {
      "epoch": 5.051344212660318,
      "grad_norm": 1.0768908262252808,
      "learning_rate": 0.0002891898241161245,
      "loss": 0.6279,
      "step": 477150
    },
    {
      "epoch": 5.051873534440322,
      "grad_norm": 1.0697933435440063,
      "learning_rate": 0.0002891442022463041,
      "loss": 0.6396,
      "step": 477200
    },
    {
      "epoch": 5.052402856220325,
      "grad_norm": 1.0534955263137817,
      "learning_rate": 0.000289098579040115,
      "loss": 0.6276,
      "step": 477250
    },
    {
      "epoch": 5.0529321780003285,
      "grad_norm": 1.0871565341949463,
      "learning_rate": 0.0002890529544991147,
      "loss": 0.6303,
      "step": 477300
    },
    {
      "epoch": 5.053461499780331,
      "grad_norm": 1.0724965333938599,
      "learning_rate": 0.00028900732862486097,
      "loss": 0.6136,
      "step": 477350
    },
    {
      "epoch": 5.053990821560335,
      "grad_norm": 1.0268218517303467,
      "learning_rate": 0.00028896170141891125,
      "loss": 0.629,
      "step": 477400
    },
    {
      "epoch": 5.054520143340338,
      "grad_norm": 1.0074466466903687,
      "learning_rate": 0.0002889160728828233,
      "loss": 0.6192,
      "step": 477450
    },
    {
      "epoch": 5.055049465120342,
      "grad_norm": 1.2451897859573364,
      "learning_rate": 0.00028887044301815503,
      "loss": 0.6203,
      "step": 477500
    },
    {
      "epoch": 5.055049465120342,
      "eval_loss": 0.41882649064064026,
      "eval_runtime": 46.9219,
      "eval_samples_per_second": 3578.929,
      "eval_steps_per_second": 447.382,
      "step": 477500
    },
    {
      "epoch": 5.055578786900345,
      "grad_norm": 1.177103877067566,
      "learning_rate": 0.00028882481182646404,
      "loss": 0.6288,
      "step": 477550
    },
    {
      "epoch": 5.056108108680347,
      "grad_norm": 1.116659164428711,
      "learning_rate": 0.0002887791793093082,
      "loss": 0.631,
      "step": 477600
    },
    {
      "epoch": 5.056637430460351,
      "grad_norm": 0.9495700001716614,
      "learning_rate": 0.0002887335454682454,
      "loss": 0.6186,
      "step": 477650
    },
    {
      "epoch": 5.057166752240354,
      "grad_norm": 1.0712995529174805,
      "learning_rate": 0.00028868791030483356,
      "loss": 0.6359,
      "step": 477700
    },
    {
      "epoch": 5.057696074020358,
      "grad_norm": 1.0902776718139648,
      "learning_rate": 0.00028864227382063064,
      "loss": 0.6316,
      "step": 477750
    },
    {
      "epoch": 5.058225395800361,
      "grad_norm": 1.1707180738449097,
      "learning_rate": 0.00028859663601719465,
      "loss": 0.6291,
      "step": 477800
    },
    {
      "epoch": 5.058754717580364,
      "grad_norm": 1.1348129510879517,
      "learning_rate": 0.00028855099689608374,
      "loss": 0.6237,
      "step": 477850
    },
    {
      "epoch": 5.059284039360367,
      "grad_norm": 1.051257610321045,
      "learning_rate": 0.00028850535645885586,
      "loss": 0.6287,
      "step": 477900
    },
    {
      "epoch": 5.059813361140371,
      "grad_norm": 1.0437405109405518,
      "learning_rate": 0.0002884597147070692,
      "loss": 0.6274,
      "step": 477950
    },
    {
      "epoch": 5.060342682920374,
      "grad_norm": 1.1505690813064575,
      "learning_rate": 0.0002884140716422821,
      "loss": 0.6247,
      "step": 478000
    },
    {
      "epoch": 5.060342682920374,
      "eval_loss": 0.41767627000808716,
      "eval_runtime": 46.9026,
      "eval_samples_per_second": 3580.396,
      "eval_steps_per_second": 447.565,
      "step": 478000
    },
    {
      "epoch": 5.060872004700378,
      "grad_norm": 1.0401461124420166,
      "learning_rate": 0.0002883684272660526,
      "loss": 0.6293,
      "step": 478050
    },
    {
      "epoch": 5.0614013264803805,
      "grad_norm": 1.1460652351379395,
      "learning_rate": 0.0002883227815799391,
      "loss": 0.6244,
      "step": 478100
    },
    {
      "epoch": 5.061930648260384,
      "grad_norm": 1.0888768434524536,
      "learning_rate": 0.00028827713458549984,
      "loss": 0.6219,
      "step": 478150
    },
    {
      "epoch": 5.062459970040387,
      "grad_norm": 1.04412841796875,
      "learning_rate": 0.0002882314862842933,
      "loss": 0.6265,
      "step": 478200
    },
    {
      "epoch": 5.062989291820391,
      "grad_norm": 1.0535707473754883,
      "learning_rate": 0.0002881858366778778,
      "loss": 0.6217,
      "step": 478250
    },
    {
      "epoch": 5.063518613600394,
      "grad_norm": 1.067516803741455,
      "learning_rate": 0.0002881401857678118,
      "loss": 0.6247,
      "step": 478300
    },
    {
      "epoch": 5.0640479353803975,
      "grad_norm": 1.1026389598846436,
      "learning_rate": 0.0002880945335556539,
      "loss": 0.628,
      "step": 478350
    },
    {
      "epoch": 5.0645772571604,
      "grad_norm": 1.1240925788879395,
      "learning_rate": 0.0002880488800429626,
      "loss": 0.6352,
      "step": 478400
    },
    {
      "epoch": 5.065106578940403,
      "grad_norm": 1.1545301675796509,
      "learning_rate": 0.0002880032252312965,
      "loss": 0.6227,
      "step": 478450
    },
    {
      "epoch": 5.065635900720407,
      "grad_norm": 0.9259748458862305,
      "learning_rate": 0.00028795756912221423,
      "loss": 0.6356,
      "step": 478500
    },
    {
      "epoch": 5.065635900720407,
      "eval_loss": 0.41748130321502686,
      "eval_runtime": 46.9015,
      "eval_samples_per_second": 3580.483,
      "eval_steps_per_second": 447.576,
      "step": 478500
    },
    {
      "epoch": 5.06616522250041,
      "grad_norm": 1.1201317310333252,
      "learning_rate": 0.00028791191171727445,
      "loss": 0.6329,
      "step": 478550
    },
    {
      "epoch": 5.066694544280414,
      "grad_norm": 1.0925877094268799,
      "learning_rate": 0.00028786625301803595,
      "loss": 0.6252,
      "step": 478600
    },
    {
      "epoch": 5.0672238660604165,
      "grad_norm": 1.1741549968719482,
      "learning_rate": 0.0002878205930260574,
      "loss": 0.6264,
      "step": 478650
    },
    {
      "epoch": 5.06775318784042,
      "grad_norm": 1.0967521667480469,
      "learning_rate": 0.0002877749317428977,
      "loss": 0.6249,
      "step": 478700
    },
    {
      "epoch": 5.068282509620423,
      "grad_norm": 1.1115540266036987,
      "learning_rate": 0.00028772926917011564,
      "loss": 0.6335,
      "step": 478750
    },
    {
      "epoch": 5.068811831400427,
      "grad_norm": 1.1803902387619019,
      "learning_rate": 0.0002876836053092702,
      "loss": 0.6292,
      "step": 478800
    },
    {
      "epoch": 5.06934115318043,
      "grad_norm": 1.1702790260314941,
      "learning_rate": 0.00028763794016192036,
      "loss": 0.628,
      "step": 478850
    },
    {
      "epoch": 5.0698704749604335,
      "grad_norm": 1.0899443626403809,
      "learning_rate": 0.00028759318707085327,
      "loss": 0.6386,
      "step": 478900
    },
    {
      "epoch": 5.070399796740436,
      "grad_norm": 0.8639134764671326,
      "learning_rate": 0.0002875475193808239,
      "loss": 0.6199,
      "step": 478950
    },
    {
      "epoch": 5.07092911852044,
      "grad_norm": 1.0219333171844482,
      "learning_rate": 0.000287501850408936,
      "loss": 0.6274,
      "step": 479000
    },
    {
      "epoch": 5.07092911852044,
      "eval_loss": 0.4172491431236267,
      "eval_runtime": 46.996,
      "eval_samples_per_second": 3573.283,
      "eval_steps_per_second": 446.676,
      "step": 479000
    },
    {
      "epoch": 5.071458440300443,
      "grad_norm": 1.0145914554595947,
      "learning_rate": 0.0002874561801567487,
      "loss": 0.6234,
      "step": 479050
    },
    {
      "epoch": 5.071987762080447,
      "grad_norm": 0.9704838991165161,
      "learning_rate": 0.0002874105086258211,
      "loss": 0.6219,
      "step": 479100
    },
    {
      "epoch": 5.07251708386045,
      "grad_norm": 1.1141408681869507,
      "learning_rate": 0.0002873648358177125,
      "loss": 0.6203,
      "step": 479150
    },
    {
      "epoch": 5.0730464056404525,
      "grad_norm": 1.081481695175171,
      "learning_rate": 0.0002873191617339821,
      "loss": 0.6329,
      "step": 479200
    },
    {
      "epoch": 5.073575727420456,
      "grad_norm": 1.0119215250015259,
      "learning_rate": 0.00028727348637618916,
      "loss": 0.6232,
      "step": 479250
    },
    {
      "epoch": 5.074105049200459,
      "grad_norm": 1.0403962135314941,
      "learning_rate": 0.00028722780974589315,
      "loss": 0.6163,
      "step": 479300
    },
    {
      "epoch": 5.074634370980463,
      "grad_norm": 1.0508012771606445,
      "learning_rate": 0.0002871821318446533,
      "loss": 0.6321,
      "step": 479350
    },
    {
      "epoch": 5.075163692760466,
      "grad_norm": 1.101019263267517,
      "learning_rate": 0.0002871364526740291,
      "loss": 0.6381,
      "step": 479400
    },
    {
      "epoch": 5.0756930145404695,
      "grad_norm": 1.005635142326355,
      "learning_rate": 0.00028709077223558005,
      "loss": 0.6265,
      "step": 479450
    },
    {
      "epoch": 5.076222336320472,
      "grad_norm": 1.1782399415969849,
      "learning_rate": 0.0002870450905308656,
      "loss": 0.6091,
      "step": 479500
    },
    {
      "epoch": 5.076222336320472,
      "eval_loss": 0.416456401348114,
      "eval_runtime": 46.9234,
      "eval_samples_per_second": 3578.81,
      "eval_steps_per_second": 447.367,
      "step": 479500
    },
    {
      "epoch": 5.076751658100476,
      "grad_norm": 1.1521656513214111,
      "learning_rate": 0.0002869994075614454,
      "loss": 0.627,
      "step": 479550
    },
    {
      "epoch": 5.077280979880479,
      "grad_norm": 1.068084478378296,
      "learning_rate": 0.00028695372332887895,
      "loss": 0.6314,
      "step": 479600
    },
    {
      "epoch": 5.077810301660483,
      "grad_norm": 1.073046088218689,
      "learning_rate": 0.00028690803783472596,
      "loss": 0.6264,
      "step": 479650
    },
    {
      "epoch": 5.078339623440486,
      "grad_norm": 1.1025053262710571,
      "learning_rate": 0.00028686235108054607,
      "loss": 0.6323,
      "step": 479700
    },
    {
      "epoch": 5.078868945220489,
      "grad_norm": 1.110985517501831,
      "learning_rate": 0.0002868166630678991,
      "loss": 0.622,
      "step": 479750
    },
    {
      "epoch": 5.079398267000492,
      "grad_norm": 1.0030500888824463,
      "learning_rate": 0.0002867709737983447,
      "loss": 0.6336,
      "step": 479800
    },
    {
      "epoch": 5.079927588780496,
      "grad_norm": 0.9601160883903503,
      "learning_rate": 0.0002867252832734428,
      "loss": 0.6191,
      "step": 479850
    },
    {
      "epoch": 5.080456910560499,
      "grad_norm": 0.9141653776168823,
      "learning_rate": 0.00028667959149475316,
      "loss": 0.6241,
      "step": 479900
    },
    {
      "epoch": 5.080986232340502,
      "grad_norm": 1.067447304725647,
      "learning_rate": 0.00028663389846383567,
      "loss": 0.6252,
      "step": 479950
    },
    {
      "epoch": 5.0815155541205055,
      "grad_norm": 1.0179541110992432,
      "learning_rate": 0.0002865882041822504,
      "loss": 0.6161,
      "step": 480000
    },
    {
      "epoch": 5.0815155541205055,
      "eval_loss": 0.41810116171836853,
      "eval_runtime": 46.9535,
      "eval_samples_per_second": 3576.514,
      "eval_steps_per_second": 447.08,
      "step": 480000
    },
    {
      "epoch": 5.082044875900508,
      "grad_norm": 1.0121266841888428,
      "learning_rate": 0.00028654250865155716,
      "loss": 0.6241,
      "step": 480050
    },
    {
      "epoch": 5.082574197680512,
      "grad_norm": 1.193706750869751,
      "learning_rate": 0.00028649681187331615,
      "loss": 0.6405,
      "step": 480100
    },
    {
      "epoch": 5.083103519460515,
      "grad_norm": 1.0705889463424683,
      "learning_rate": 0.0002864511138490874,
      "loss": 0.6205,
      "step": 480150
    },
    {
      "epoch": 5.083632841240519,
      "grad_norm": 0.9831382036209106,
      "learning_rate": 0.0002864054145804309,
      "loss": 0.6325,
      "step": 480200
    },
    {
      "epoch": 5.084162163020522,
      "grad_norm": 0.9875110387802124,
      "learning_rate": 0.000286359714068907,
      "loss": 0.626,
      "step": 480250
    },
    {
      "epoch": 5.084691484800525,
      "grad_norm": 1.0690101385116577,
      "learning_rate": 0.00028631401231607575,
      "loss": 0.6332,
      "step": 480300
    },
    {
      "epoch": 5.085220806580528,
      "grad_norm": 1.1518404483795166,
      "learning_rate": 0.0002862683093234973,
      "loss": 0.6237,
      "step": 480350
    },
    {
      "epoch": 5.085750128360532,
      "grad_norm": 1.037057638168335,
      "learning_rate": 0.00028622260509273225,
      "loss": 0.6269,
      "step": 480400
    },
    {
      "epoch": 5.086279450140535,
      "grad_norm": 1.13115394115448,
      "learning_rate": 0.00028617689962534066,
      "loss": 0.6366,
      "step": 480450
    },
    {
      "epoch": 5.086808771920539,
      "grad_norm": 1.0668739080429077,
      "learning_rate": 0.00028613119292288303,
      "loss": 0.6276,
      "step": 480500
    },
    {
      "epoch": 5.086808771920539,
      "eval_loss": 0.4179232120513916,
      "eval_runtime": 46.9783,
      "eval_samples_per_second": 3574.632,
      "eval_steps_per_second": 446.845,
      "step": 480500
    },
    {
      "epoch": 5.0873380937005415,
      "grad_norm": 1.065071940422058,
      "learning_rate": 0.0002860854849869197,
      "loss": 0.6311,
      "step": 480550
    },
    {
      "epoch": 5.087867415480545,
      "grad_norm": 1.129157304763794,
      "learning_rate": 0.00028603977581901117,
      "loss": 0.6301,
      "step": 480600
    },
    {
      "epoch": 5.088396737260548,
      "grad_norm": 1.0505157709121704,
      "learning_rate": 0.0002859940654207179,
      "loss": 0.6243,
      "step": 480650
    },
    {
      "epoch": 5.088926059040551,
      "grad_norm": 1.006955862045288,
      "learning_rate": 0.00028594835379360043,
      "loss": 0.633,
      "step": 480700
    },
    {
      "epoch": 5.089455380820555,
      "grad_norm": 1.0901814699172974,
      "learning_rate": 0.0002859026409392194,
      "loss": 0.6323,
      "step": 480750
    },
    {
      "epoch": 5.089984702600558,
      "grad_norm": 1.0403153896331787,
      "learning_rate": 0.00028585692685913536,
      "loss": 0.6333,
      "step": 480800
    },
    {
      "epoch": 5.090514024380561,
      "grad_norm": 0.9613710045814514,
      "learning_rate": 0.0002858112115549089,
      "loss": 0.6256,
      "step": 480850
    },
    {
      "epoch": 5.091043346160564,
      "grad_norm": 1.1215806007385254,
      "learning_rate": 0.00028576640937060823,
      "loss": 0.6377,
      "step": 480900
    },
    {
      "epoch": 5.091572667940568,
      "grad_norm": 1.0339046716690063,
      "learning_rate": 0.0002857206916471844,
      "loss": 0.6193,
      "step": 480950
    },
    {
      "epoch": 5.092101989720571,
      "grad_norm": 1.0585309267044067,
      "learning_rate": 0.0002856749727042693,
      "loss": 0.6192,
      "step": 481000
    },
    {
      "epoch": 5.092101989720571,
      "eval_loss": 0.4167424738407135,
      "eval_runtime": 46.9776,
      "eval_samples_per_second": 3574.683,
      "eval_steps_per_second": 446.851,
      "step": 481000
    },
    {
      "epoch": 5.092631311500575,
      "grad_norm": 1.1036652326583862,
      "learning_rate": 0.0002856292525434237,
      "loss": 0.6103,
      "step": 481050
    },
    {
      "epoch": 5.093160633280577,
      "grad_norm": 1.0754903554916382,
      "learning_rate": 0.0002855835311662085,
      "loss": 0.6292,
      "step": 481100
    },
    {
      "epoch": 5.093689955060581,
      "grad_norm": 1.1401270627975464,
      "learning_rate": 0.0002855378085741846,
      "loss": 0.6312,
      "step": 481150
    },
    {
      "epoch": 5.094219276840584,
      "grad_norm": 1.1370571851730347,
      "learning_rate": 0.00028549208476891296,
      "loss": 0.6399,
      "step": 481200
    },
    {
      "epoch": 5.094748598620588,
      "grad_norm": 1.0244470834732056,
      "learning_rate": 0.00028544635975195454,
      "loss": 0.6285,
      "step": 481250
    },
    {
      "epoch": 5.095277920400591,
      "grad_norm": 0.9612453579902649,
      "learning_rate": 0.00028540063352487037,
      "loss": 0.6286,
      "step": 481300
    },
    {
      "epoch": 5.095807242180594,
      "grad_norm": 0.9842817783355713,
      "learning_rate": 0.0002853549060892216,
      "loss": 0.6186,
      "step": 481350
    },
    {
      "epoch": 5.096336563960597,
      "grad_norm": 1.0771721601486206,
      "learning_rate": 0.00028530917744656924,
      "loss": 0.6176,
      "step": 481400
    },
    {
      "epoch": 5.0968658857406,
      "grad_norm": 1.0792696475982666,
      "learning_rate": 0.0002852634475984746,
      "loss": 0.631,
      "step": 481450
    },
    {
      "epoch": 5.097395207520604,
      "grad_norm": 1.032212734222412,
      "learning_rate": 0.0002852177165464988,
      "loss": 0.6279,
      "step": 481500
    },
    {
      "epoch": 5.097395207520604,
      "eval_loss": 0.4162978529930115,
      "eval_runtime": 46.9507,
      "eval_samples_per_second": 3576.73,
      "eval_steps_per_second": 447.107,
      "step": 481500
    },
    {
      "epoch": 5.097924529300607,
      "grad_norm": 1.175550937652588,
      "learning_rate": 0.00028517198429220294,
      "loss": 0.6455,
      "step": 481550
    },
    {
      "epoch": 5.0984538510806106,
      "grad_norm": 1.1157143115997314,
      "learning_rate": 0.0002851262508371485,
      "loss": 0.6187,
      "step": 481600
    },
    {
      "epoch": 5.098983172860613,
      "grad_norm": 1.1322588920593262,
      "learning_rate": 0.0002850805161828967,
      "loss": 0.6242,
      "step": 481650
    },
    {
      "epoch": 5.099512494640617,
      "grad_norm": 1.1298857927322388,
      "learning_rate": 0.00028503478033100905,
      "loss": 0.6242,
      "step": 481700
    },
    {
      "epoch": 5.10004181642062,
      "grad_norm": 1.090258240699768,
      "learning_rate": 0.0002849890432830468,
      "loss": 0.6245,
      "step": 481750
    },
    {
      "epoch": 5.100571138200624,
      "grad_norm": 1.030663251876831,
      "learning_rate": 0.00028494330504057143,
      "loss": 0.6247,
      "step": 481800
    },
    {
      "epoch": 5.101100459980627,
      "grad_norm": 1.079712986946106,
      "learning_rate": 0.0002848975656051444,
      "loss": 0.6265,
      "step": 481850
    },
    {
      "epoch": 5.10162978176063,
      "grad_norm": 1.148215651512146,
      "learning_rate": 0.0002848518249783273,
      "loss": 0.6141,
      "step": 481900
    },
    {
      "epoch": 5.102159103540633,
      "grad_norm": 1.0035978555679321,
      "learning_rate": 0.0002848060831616818,
      "loss": 0.6324,
      "step": 481950
    },
    {
      "epoch": 5.102688425320637,
      "grad_norm": 1.0708885192871094,
      "learning_rate": 0.00028476034015676924,
      "loss": 0.632,
      "step": 482000
    },
    {
      "epoch": 5.102688425320637,
      "eval_loss": 0.4161347448825836,
      "eval_runtime": 46.9769,
      "eval_samples_per_second": 3574.739,
      "eval_steps_per_second": 446.858,
      "step": 482000
    },
    {
      "epoch": 5.10321774710064,
      "grad_norm": 1.0308504104614258,
      "learning_rate": 0.00028471459596515145,
      "loss": 0.6226,
      "step": 482050
    },
    {
      "epoch": 5.103747068880644,
      "grad_norm": 1.0414888858795166,
      "learning_rate": 0.0002846688505883901,
      "loss": 0.6273,
      "step": 482100
    },
    {
      "epoch": 5.1042763906606465,
      "grad_norm": 1.0891685485839844,
      "learning_rate": 0.00028462310402804693,
      "loss": 0.6311,
      "step": 482150
    },
    {
      "epoch": 5.104805712440649,
      "grad_norm": 1.1252278089523315,
      "learning_rate": 0.0002845773562856837,
      "loss": 0.6283,
      "step": 482200
    },
    {
      "epoch": 5.105335034220653,
      "grad_norm": 1.0376402139663696,
      "learning_rate": 0.0002845316073628621,
      "loss": 0.6197,
      "step": 482250
    },
    {
      "epoch": 5.105864356000656,
      "grad_norm": 1.0039340257644653,
      "learning_rate": 0.0002844858572611442,
      "loss": 0.6292,
      "step": 482300
    },
    {
      "epoch": 5.10639367778066,
      "grad_norm": 1.0349973440170288,
      "learning_rate": 0.00028444010598209176,
      "loss": 0.6158,
      "step": 482350
    },
    {
      "epoch": 5.106922999560663,
      "grad_norm": 1.1017366647720337,
      "learning_rate": 0.0002843943535272667,
      "loss": 0.6171,
      "step": 482400
    },
    {
      "epoch": 5.107452321340666,
      "grad_norm": 1.1183711290359497,
      "learning_rate": 0.000284348599898231,
      "loss": 0.6367,
      "step": 482450
    },
    {
      "epoch": 5.107981643120669,
      "grad_norm": 1.13787841796875,
      "learning_rate": 0.0002843028450965467,
      "loss": 0.622,
      "step": 482500
    },
    {
      "epoch": 5.107981643120669,
      "eval_loss": 0.41439318656921387,
      "eval_runtime": 47.1605,
      "eval_samples_per_second": 3560.821,
      "eval_steps_per_second": 445.119,
      "step": 482500
    },
    {
      "epoch": 5.108510964900673,
      "grad_norm": 1.0671629905700684,
      "learning_rate": 0.00028425708912377585,
      "loss": 0.6342,
      "step": 482550
    },
    {
      "epoch": 5.109040286680676,
      "grad_norm": 1.0249587297439575,
      "learning_rate": 0.0002842113319814806,
      "loss": 0.6198,
      "step": 482600
    },
    {
      "epoch": 5.10956960846068,
      "grad_norm": 0.9656885862350464,
      "learning_rate": 0.00028416557367122295,
      "loss": 0.6273,
      "step": 482650
    },
    {
      "epoch": 5.1100989302406825,
      "grad_norm": 1.0903106927871704,
      "learning_rate": 0.0002841198141945652,
      "loss": 0.6179,
      "step": 482700
    },
    {
      "epoch": 5.110628252020686,
      "grad_norm": 1.114227056503296,
      "learning_rate": 0.00028407405355306947,
      "loss": 0.628,
      "step": 482750
    },
    {
      "epoch": 5.111157573800689,
      "grad_norm": 1.140957236289978,
      "learning_rate": 0.0002840282917482981,
      "loss": 0.6354,
      "step": 482800
    },
    {
      "epoch": 5.111686895580693,
      "grad_norm": 1.1392899751663208,
      "learning_rate": 0.0002839825287818133,
      "loss": 0.6295,
      "step": 482850
    },
    {
      "epoch": 5.112216217360696,
      "grad_norm": 1.070746898651123,
      "learning_rate": 0.00028393676465517743,
      "loss": 0.6077,
      "step": 482900
    },
    {
      "epoch": 5.112745539140699,
      "grad_norm": 1.0795167684555054,
      "learning_rate": 0.0002838919146870014,
      "loss": 0.6353,
      "step": 482950
    },
    {
      "epoch": 5.113274860920702,
      "grad_norm": 1.0217769145965576,
      "learning_rate": 0.0002838461482678757,
      "loss": 0.6295,
      "step": 483000
    },
    {
      "epoch": 5.113274860920702,
      "eval_loss": 0.41643020510673523,
      "eval_runtime": 46.9418,
      "eval_samples_per_second": 3577.411,
      "eval_steps_per_second": 447.192,
      "step": 483000
    },
    {
      "epoch": 5.113804182700705,
      "grad_norm": 1.0433776378631592,
      "learning_rate": 0.000283800380693255,
      "loss": 0.6294,
      "step": 483050
    },
    {
      "epoch": 5.114333504480709,
      "grad_norm": 1.0896285772323608,
      "learning_rate": 0.00028375461196470167,
      "loss": 0.6313,
      "step": 483100
    },
    {
      "epoch": 5.114862826260712,
      "grad_norm": 1.0229642391204834,
      "learning_rate": 0.0002837088420837782,
      "loss": 0.6298,
      "step": 483150
    },
    {
      "epoch": 5.115392148040716,
      "grad_norm": 1.0286093950271606,
      "learning_rate": 0.00028366307105204735,
      "loss": 0.6237,
      "step": 483200
    },
    {
      "epoch": 5.1159214698207185,
      "grad_norm": 1.0973023176193237,
      "learning_rate": 0.0002836172988710715,
      "loss": 0.6345,
      "step": 483250
    },
    {
      "epoch": 5.116450791600722,
      "grad_norm": 1.0841177701950073,
      "learning_rate": 0.00028357152554241345,
      "loss": 0.6283,
      "step": 483300
    },
    {
      "epoch": 5.116980113380725,
      "grad_norm": 1.0988713502883911,
      "learning_rate": 0.00028352575106763584,
      "loss": 0.6293,
      "step": 483350
    },
    {
      "epoch": 5.117509435160729,
      "grad_norm": 0.9617145657539368,
      "learning_rate": 0.00028347997544830134,
      "loss": 0.622,
      "step": 483400
    },
    {
      "epoch": 5.118038756940732,
      "grad_norm": 0.9491930603981018,
      "learning_rate": 0.0002834341986859728,
      "loss": 0.6278,
      "step": 483450
    },
    {
      "epoch": 5.1185680787207355,
      "grad_norm": 1.1465164422988892,
      "learning_rate": 0.0002833884207822129,
      "loss": 0.6351,
      "step": 483500
    },
    {
      "epoch": 5.1185680787207355,
      "eval_loss": 0.41647669672966003,
      "eval_runtime": 46.8973,
      "eval_samples_per_second": 3580.802,
      "eval_steps_per_second": 447.616,
      "step": 483500
    },
    {
      "epoch": 5.119097400500738,
      "grad_norm": 1.1031558513641357,
      "learning_rate": 0.00028334264173858465,
      "loss": 0.6245,
      "step": 483550
    },
    {
      "epoch": 5.119626722280742,
      "grad_norm": 1.1323132514953613,
      "learning_rate": 0.0002832968615566508,
      "loss": 0.6281,
      "step": 483600
    },
    {
      "epoch": 5.120156044060745,
      "grad_norm": 1.0277950763702393,
      "learning_rate": 0.0002832510802379743,
      "loss": 0.6216,
      "step": 483650
    },
    {
      "epoch": 5.120685365840748,
      "grad_norm": 1.0194242000579834,
      "learning_rate": 0.00028320529778411813,
      "loss": 0.6207,
      "step": 483700
    },
    {
      "epoch": 5.121214687620752,
      "grad_norm": 1.1099735498428345,
      "learning_rate": 0.0002831595141966453,
      "loss": 0.628,
      "step": 483750
    },
    {
      "epoch": 5.1217440094007545,
      "grad_norm": 1.1099543571472168,
      "learning_rate": 0.0002831137294771187,
      "loss": 0.6177,
      "step": 483800
    },
    {
      "epoch": 5.122273331180758,
      "grad_norm": 1.1043791770935059,
      "learning_rate": 0.0002830679436271016,
      "loss": 0.6272,
      "step": 483850
    },
    {
      "epoch": 5.122802652960761,
      "grad_norm": 1.0398277044296265,
      "learning_rate": 0.000283022156648157,
      "loss": 0.6218,
      "step": 483900
    },
    {
      "epoch": 5.123331974740765,
      "grad_norm": 1.1039016246795654,
      "learning_rate": 0.00028297636854184813,
      "loss": 0.6247,
      "step": 483950
    },
    {
      "epoch": 5.123861296520768,
      "grad_norm": 1.1586633920669556,
      "learning_rate": 0.00028293057930973807,
      "loss": 0.6215,
      "step": 484000
    },
    {
      "epoch": 5.123861296520768,
      "eval_loss": 0.4143078029155731,
      "eval_runtime": 46.9709,
      "eval_samples_per_second": 3575.196,
      "eval_steps_per_second": 446.915,
      "step": 484000
    },
    {
      "epoch": 5.1243906183007715,
      "grad_norm": 0.9840993881225586,
      "learning_rate": 0.0002828847889533902,
      "loss": 0.639,
      "step": 484050
    },
    {
      "epoch": 5.124919940080774,
      "grad_norm": 1.0886591672897339,
      "learning_rate": 0.00028283899747436763,
      "loss": 0.6303,
      "step": 484100
    },
    {
      "epoch": 5.125449261860778,
      "grad_norm": 1.0833187103271484,
      "learning_rate": 0.0002827932048742338,
      "loss": 0.6279,
      "step": 484150
    },
    {
      "epoch": 5.125978583640781,
      "grad_norm": 1.0466434955596924,
      "learning_rate": 0.0002827474111545519,
      "loss": 0.633,
      "step": 484200
    },
    {
      "epoch": 5.126507905420785,
      "grad_norm": 1.0455472469329834,
      "learning_rate": 0.0002827016163168854,
      "loss": 0.618,
      "step": 484250
    },
    {
      "epoch": 5.127037227200788,
      "grad_norm": 1.0374727249145508,
      "learning_rate": 0.00028265582036279775,
      "loss": 0.6232,
      "step": 484300
    },
    {
      "epoch": 5.127566548980791,
      "grad_norm": 1.061460018157959,
      "learning_rate": 0.0002826100232938524,
      "loss": 0.6293,
      "step": 484350
    },
    {
      "epoch": 5.128095870760794,
      "grad_norm": 1.1187862157821655,
      "learning_rate": 0.00028256422511161274,
      "loss": 0.6234,
      "step": 484400
    },
    {
      "epoch": 5.128625192540797,
      "grad_norm": 1.1992008686065674,
      "learning_rate": 0.0002825184258176424,
      "loss": 0.6346,
      "step": 484450
    },
    {
      "epoch": 5.129154514320801,
      "grad_norm": 0.9873424172401428,
      "learning_rate": 0.0002824726254135049,
      "loss": 0.6214,
      "step": 484500
    },
    {
      "epoch": 5.129154514320801,
      "eval_loss": 0.41345882415771484,
      "eval_runtime": 46.9011,
      "eval_samples_per_second": 3580.513,
      "eval_steps_per_second": 447.58,
      "step": 484500
    },
    {
      "epoch": 5.129683836100804,
      "grad_norm": 1.070173740386963,
      "learning_rate": 0.000282426823900764,
      "loss": 0.6168,
      "step": 484550
    },
    {
      "epoch": 5.1302131578808075,
      "grad_norm": 1.0590434074401855,
      "learning_rate": 0.0002823810212809831,
      "loss": 0.6164,
      "step": 484600
    },
    {
      "epoch": 5.13074247966081,
      "grad_norm": 1.0290446281433105,
      "learning_rate": 0.000282335217555726,
      "loss": 0.6198,
      "step": 484650
    },
    {
      "epoch": 5.131271801440814,
      "grad_norm": 1.0219672918319702,
      "learning_rate": 0.00028228941272655646,
      "loss": 0.62,
      "step": 484700
    },
    {
      "epoch": 5.131801123220817,
      "grad_norm": 1.2030619382858276,
      "learning_rate": 0.00028224360679503826,
      "loss": 0.6257,
      "step": 484750
    },
    {
      "epoch": 5.132330445000821,
      "grad_norm": 1.0590925216674805,
      "learning_rate": 0.0002821977997627351,
      "loss": 0.6299,
      "step": 484800
    },
    {
      "epoch": 5.132859766780824,
      "grad_norm": 1.1088560819625854,
      "learning_rate": 0.00028215199163121086,
      "loss": 0.6263,
      "step": 484850
    },
    {
      "epoch": 5.133389088560827,
      "grad_norm": 1.024436116218567,
      "learning_rate": 0.0002821061824020295,
      "loss": 0.6221,
      "step": 484900
    },
    {
      "epoch": 5.13391841034083,
      "grad_norm": 1.185712218284607,
      "learning_rate": 0.0002820612882939919,
      "loss": 0.635,
      "step": 484950
    },
    {
      "epoch": 5.134447732120834,
      "grad_norm": 1.048041820526123,
      "learning_rate": 0.00028201547689606305,
      "loss": 0.6192,
      "step": 485000
    },
    {
      "epoch": 5.134447732120834,
      "eval_loss": 0.41593149304389954,
      "eval_runtime": 46.9156,
      "eval_samples_per_second": 3579.403,
      "eval_steps_per_second": 447.441,
      "step": 485000
    },
    {
      "epoch": 5.134977053900837,
      "grad_norm": 1.0965704917907715,
      "learning_rate": 0.0002819696644051376,
      "loss": 0.6198,
      "step": 485050
    },
    {
      "epoch": 5.135506375680841,
      "grad_norm": 1.2724453210830688,
      "learning_rate": 0.0002819238508227795,
      "loss": 0.6372,
      "step": 485100
    },
    {
      "epoch": 5.136035697460843,
      "grad_norm": 1.0510529279708862,
      "learning_rate": 0.00028187803615055293,
      "loss": 0.6194,
      "step": 485150
    },
    {
      "epoch": 5.136565019240846,
      "grad_norm": 1.1520376205444336,
      "learning_rate": 0.0002818322203900218,
      "loss": 0.6372,
      "step": 485200
    },
    {
      "epoch": 5.13709434102085,
      "grad_norm": 1.1359766721725464,
      "learning_rate": 0.00028178640354275045,
      "loss": 0.6224,
      "step": 485250
    },
    {
      "epoch": 5.137623662800853,
      "grad_norm": 1.1656414270401,
      "learning_rate": 0.00028174058561030287,
      "loss": 0.6228,
      "step": 485300
    },
    {
      "epoch": 5.138152984580857,
      "grad_norm": 1.0754063129425049,
      "learning_rate": 0.0002816947665942433,
      "loss": 0.6195,
      "step": 485350
    },
    {
      "epoch": 5.1386823063608595,
      "grad_norm": 1.162199854850769,
      "learning_rate": 0.0002816489464961361,
      "loss": 0.6221,
      "step": 485400
    },
    {
      "epoch": 5.139211628140863,
      "grad_norm": 1.0605835914611816,
      "learning_rate": 0.00028160312531754546,
      "loss": 0.6175,
      "step": 485450
    },
    {
      "epoch": 5.139740949920866,
      "grad_norm": 1.0960508584976196,
      "learning_rate": 0.00028155730306003566,
      "loss": 0.6229,
      "step": 485500
    },
    {
      "epoch": 5.139740949920866,
      "eval_loss": 0.4151199162006378,
      "eval_runtime": 47.1329,
      "eval_samples_per_second": 3562.907,
      "eval_steps_per_second": 445.379,
      "step": 485500
    },
    {
      "epoch": 5.14027027170087,
      "grad_norm": 1.1282036304473877,
      "learning_rate": 0.0002815114797251712,
      "loss": 0.6268,
      "step": 485550
    },
    {
      "epoch": 5.140799593480873,
      "grad_norm": 1.0634630918502808,
      "learning_rate": 0.0002814656553145163,
      "loss": 0.6269,
      "step": 485600
    },
    {
      "epoch": 5.1413289152608765,
      "grad_norm": 1.0833247900009155,
      "learning_rate": 0.0002814198298296355,
      "loss": 0.6311,
      "step": 485650
    },
    {
      "epoch": 5.141858237040879,
      "grad_norm": 1.088417887687683,
      "learning_rate": 0.00028137400327209324,
      "loss": 0.6303,
      "step": 485700
    },
    {
      "epoch": 5.142387558820883,
      "grad_norm": 0.9462155103683472,
      "learning_rate": 0.00028132817564345395,
      "loss": 0.6316,
      "step": 485750
    },
    {
      "epoch": 5.142916880600886,
      "grad_norm": 1.0293866395950317,
      "learning_rate": 0.00028128234694528234,
      "loss": 0.617,
      "step": 485800
    },
    {
      "epoch": 5.14344620238089,
      "grad_norm": 1.165419578552246,
      "learning_rate": 0.0002812365171791428,
      "loss": 0.6243,
      "step": 485850
    },
    {
      "epoch": 5.143975524160893,
      "grad_norm": 1.107515811920166,
      "learning_rate": 0.00028119068634659995,
      "loss": 0.6202,
      "step": 485900
    },
    {
      "epoch": 5.1445048459408955,
      "grad_norm": 1.0085132122039795,
      "learning_rate": 0.0002811448544492186,
      "loss": 0.6377,
      "step": 485950
    },
    {
      "epoch": 5.145034167720899,
      "grad_norm": 1.0268604755401611,
      "learning_rate": 0.0002810990214885633,
      "loss": 0.6285,
      "step": 486000
    },
    {
      "epoch": 5.145034167720899,
      "eval_loss": 0.415953665971756,
      "eval_runtime": 46.8898,
      "eval_samples_per_second": 3581.377,
      "eval_steps_per_second": 447.688,
      "step": 486000
    },
    {
      "epoch": 5.145563489500902,
      "grad_norm": 1.1420013904571533,
      "learning_rate": 0.0002810531874661989,
      "loss": 0.6179,
      "step": 486050
    },
    {
      "epoch": 5.146092811280906,
      "grad_norm": 1.0565983057022095,
      "learning_rate": 0.00028100735238369,
      "loss": 0.6171,
      "step": 486100
    },
    {
      "epoch": 5.146622133060909,
      "grad_norm": 1.11505925655365,
      "learning_rate": 0.0002809615162426015,
      "loss": 0.6211,
      "step": 486150
    },
    {
      "epoch": 5.1471514548409125,
      "grad_norm": 1.0234644412994385,
      "learning_rate": 0.0002809156790444981,
      "loss": 0.6224,
      "step": 486200
    },
    {
      "epoch": 5.147680776620915,
      "grad_norm": 1.0996390581130981,
      "learning_rate": 0.00028086984079094484,
      "loss": 0.6257,
      "step": 486250
    },
    {
      "epoch": 5.148210098400919,
      "grad_norm": 0.956134557723999,
      "learning_rate": 0.0002808240014835065,
      "loss": 0.6199,
      "step": 486300
    },
    {
      "epoch": 5.148739420180922,
      "grad_norm": 1.0831520557403564,
      "learning_rate": 0.0002807781611237481,
      "loss": 0.6308,
      "step": 486350
    },
    {
      "epoch": 5.149268741960926,
      "grad_norm": 0.9583472609519958,
      "learning_rate": 0.0002807323197132345,
      "loss": 0.6396,
      "step": 486400
    },
    {
      "epoch": 5.149798063740929,
      "grad_norm": 1.1935614347457886,
      "learning_rate": 0.00028068647725353085,
      "loss": 0.6372,
      "step": 486450
    },
    {
      "epoch": 5.150327385520932,
      "grad_norm": 1.2243480682373047,
      "learning_rate": 0.0002806406337462021,
      "loss": 0.6159,
      "step": 486500
    },
    {
      "epoch": 5.150327385520932,
      "eval_loss": 0.4139920175075531,
      "eval_runtime": 47.4902,
      "eval_samples_per_second": 3536.097,
      "eval_steps_per_second": 442.028,
      "step": 486500
    },
    {
      "epoch": 5.150856707300935,
      "grad_norm": 1.0338400602340698,
      "learning_rate": 0.0002805947891928133,
      "loss": 0.6214,
      "step": 486550
    },
    {
      "epoch": 5.151386029080939,
      "grad_norm": 1.0312215089797974,
      "learning_rate": 0.00028054894359492966,
      "loss": 0.6137,
      "step": 486600
    },
    {
      "epoch": 5.151915350860942,
      "grad_norm": 1.1507234573364258,
      "learning_rate": 0.0002805030969541163,
      "loss": 0.619,
      "step": 486650
    },
    {
      "epoch": 5.152444672640945,
      "grad_norm": 1.012326717376709,
      "learning_rate": 0.0002804572492719384,
      "loss": 0.6217,
      "step": 486700
    },
    {
      "epoch": 5.1529739944209485,
      "grad_norm": 1.075618028640747,
      "learning_rate": 0.00028041140054996114,
      "loss": 0.6259,
      "step": 486750
    },
    {
      "epoch": 5.153503316200951,
      "grad_norm": 1.0340884923934937,
      "learning_rate": 0.0002803655507897498,
      "loss": 0.6208,
      "step": 486800
    },
    {
      "epoch": 5.154032637980955,
      "grad_norm": 1.0630300045013428,
      "learning_rate": 0.0002803196999928697,
      "loss": 0.6346,
      "step": 486850
    },
    {
      "epoch": 5.154561959760958,
      "grad_norm": 1.0475597381591797,
      "learning_rate": 0.0002802738481608862,
      "loss": 0.6214,
      "step": 486900
    },
    {
      "epoch": 5.155091281540962,
      "grad_norm": 1.0753308534622192,
      "learning_rate": 0.0002802289123627936,
      "loss": 0.6303,
      "step": 486950
    },
    {
      "epoch": 5.155620603320965,
      "grad_norm": 0.9527567028999329,
      "learning_rate": 0.00028018305848592344,
      "loss": 0.6161,
      "step": 487000
    },
    {
      "epoch": 5.155620603320965,
      "eval_loss": 0.4141641855239868,
      "eval_runtime": 47.4683,
      "eval_samples_per_second": 3537.728,
      "eval_steps_per_second": 442.232,
      "step": 487000
    },
    {
      "epoch": 5.156149925100968,
      "grad_norm": 0.9903663396835327,
      "learning_rate": 0.00028013720357861476,
      "loss": 0.6259,
      "step": 487050
    },
    {
      "epoch": 5.156679246880971,
      "grad_norm": 1.0496563911437988,
      "learning_rate": 0.000280091347642433,
      "loss": 0.625,
      "step": 487100
    },
    {
      "epoch": 5.157208568660975,
      "grad_norm": 1.071485161781311,
      "learning_rate": 0.00028004549067894364,
      "loss": 0.6288,
      "step": 487150
    },
    {
      "epoch": 5.157737890440978,
      "grad_norm": 1.1088014841079712,
      "learning_rate": 0.00027999963268971227,
      "loss": 0.6192,
      "step": 487200
    },
    {
      "epoch": 5.158267212220982,
      "grad_norm": 1.0584229230880737,
      "learning_rate": 0.00027995377367630444,
      "loss": 0.6253,
      "step": 487250
    },
    {
      "epoch": 5.1587965340009845,
      "grad_norm": 1.0755892992019653,
      "learning_rate": 0.0002799079136402858,
      "loss": 0.6052,
      "step": 487300
    },
    {
      "epoch": 5.159325855780988,
      "grad_norm": 1.0906225442886353,
      "learning_rate": 0.0002798620525832218,
      "loss": 0.62,
      "step": 487350
    },
    {
      "epoch": 5.159855177560991,
      "grad_norm": 1.0242853164672852,
      "learning_rate": 0.0002798161905066784,
      "loss": 0.6347,
      "step": 487400
    },
    {
      "epoch": 5.160384499340994,
      "grad_norm": 1.0600043535232544,
      "learning_rate": 0.0002797703274122212,
      "loss": 0.6322,
      "step": 487450
    },
    {
      "epoch": 5.160913821120998,
      "grad_norm": 1.1504164934158325,
      "learning_rate": 0.0002797244633014159,
      "loss": 0.6285,
      "step": 487500
    },
    {
      "epoch": 5.160913821120998,
      "eval_loss": 0.41507330536842346,
      "eval_runtime": 47.515,
      "eval_samples_per_second": 3534.255,
      "eval_steps_per_second": 441.798,
      "step": 487500
    },
    {
      "epoch": 5.161443142901001,
      "grad_norm": 1.1528817415237427,
      "learning_rate": 0.00027967859817582837,
      "loss": 0.6396,
      "step": 487550
    },
    {
      "epoch": 5.161972464681004,
      "grad_norm": 1.0657461881637573,
      "learning_rate": 0.0002796327320370244,
      "loss": 0.6234,
      "step": 487600
    },
    {
      "epoch": 5.162501786461007,
      "grad_norm": 1.0770171880722046,
      "learning_rate": 0.00027958686488656977,
      "loss": 0.6256,
      "step": 487650
    },
    {
      "epoch": 5.163031108241011,
      "grad_norm": 0.9425199627876282,
      "learning_rate": 0.0002795409967260304,
      "loss": 0.6119,
      "step": 487700
    },
    {
      "epoch": 5.163560430021014,
      "grad_norm": 1.059260606765747,
      "learning_rate": 0.00027949512755697225,
      "loss": 0.6246,
      "step": 487750
    },
    {
      "epoch": 5.164089751801018,
      "grad_norm": 1.0947401523590088,
      "learning_rate": 0.00027944925738096135,
      "loss": 0.6197,
      "step": 487800
    },
    {
      "epoch": 5.1646190735810205,
      "grad_norm": 1.1092365980148315,
      "learning_rate": 0.0002794033861995635,
      "loss": 0.6204,
      "step": 487850
    },
    {
      "epoch": 5.165148395361024,
      "grad_norm": 1.1058225631713867,
      "learning_rate": 0.0002793575140143449,
      "loss": 0.625,
      "step": 487900
    },
    {
      "epoch": 5.165677717141027,
      "grad_norm": 1.11590576171875,
      "learning_rate": 0.0002793116408268715,
      "loss": 0.6311,
      "step": 487950
    },
    {
      "epoch": 5.166207038921031,
      "grad_norm": 1.0390065908432007,
      "learning_rate": 0.00027926576663870944,
      "loss": 0.6182,
      "step": 488000
    },
    {
      "epoch": 5.166207038921031,
      "eval_loss": 0.41424575448036194,
      "eval_runtime": 47.194,
      "eval_samples_per_second": 3558.289,
      "eval_steps_per_second": 444.802,
      "step": 488000
    },
    {
      "epoch": 5.166736360701034,
      "grad_norm": 1.0668624639511108,
      "learning_rate": 0.00027921989145142487,
      "loss": 0.6242,
      "step": 488050
    },
    {
      "epoch": 5.1672656824810375,
      "grad_norm": 0.9395009875297546,
      "learning_rate": 0.0002791740152665839,
      "loss": 0.6271,
      "step": 488100
    },
    {
      "epoch": 5.16779500426104,
      "grad_norm": 1.0354959964752197,
      "learning_rate": 0.00027912813808575265,
      "loss": 0.6207,
      "step": 488150
    },
    {
      "epoch": 5.168324326041043,
      "grad_norm": 1.0433263778686523,
      "learning_rate": 0.0002790822599104975,
      "loss": 0.6302,
      "step": 488200
    },
    {
      "epoch": 5.168853647821047,
      "grad_norm": 1.0252846479415894,
      "learning_rate": 0.00027903638074238475,
      "loss": 0.6243,
      "step": 488250
    },
    {
      "epoch": 5.16938296960105,
      "grad_norm": 1.1654657125473022,
      "learning_rate": 0.0002789905005829805,
      "loss": 0.6279,
      "step": 488300
    },
    {
      "epoch": 5.169912291381054,
      "grad_norm": 1.0879502296447754,
      "learning_rate": 0.0002789446194338513,
      "loss": 0.6156,
      "step": 488350
    },
    {
      "epoch": 5.170441613161056,
      "grad_norm": 0.9936251640319824,
      "learning_rate": 0.00027889873729656335,
      "loss": 0.6339,
      "step": 488400
    },
    {
      "epoch": 5.17097093494106,
      "grad_norm": 1.2296031713485718,
      "learning_rate": 0.0002788528541726831,
      "loss": 0.6234,
      "step": 488450
    },
    {
      "epoch": 5.171500256721063,
      "grad_norm": 1.186631441116333,
      "learning_rate": 0.000278806970063777,
      "loss": 0.6212,
      "step": 488500
    },
    {
      "epoch": 5.171500256721063,
      "eval_loss": 0.41353437304496765,
      "eval_runtime": 47.2404,
      "eval_samples_per_second": 3554.794,
      "eval_steps_per_second": 444.365,
      "step": 488500
    },
    {
      "epoch": 5.172029578501067,
      "grad_norm": 1.1023749113082886,
      "learning_rate": 0.0002787610849714115,
      "loss": 0.6226,
      "step": 488550
    },
    {
      "epoch": 5.17255890028107,
      "grad_norm": 1.1143914461135864,
      "learning_rate": 0.00027871519889715316,
      "loss": 0.6303,
      "step": 488600
    },
    {
      "epoch": 5.173088222061073,
      "grad_norm": 1.1996393203735352,
      "learning_rate": 0.00027866931184256837,
      "loss": 0.6304,
      "step": 488650
    },
    {
      "epoch": 5.173617543841076,
      "grad_norm": 1.1479910612106323,
      "learning_rate": 0.0002786234238092239,
      "loss": 0.6314,
      "step": 488700
    },
    {
      "epoch": 5.17414686562108,
      "grad_norm": 1.226974368095398,
      "learning_rate": 0.00027857753479868614,
      "loss": 0.6186,
      "step": 488750
    },
    {
      "epoch": 5.174676187401083,
      "grad_norm": 0.9698705673217773,
      "learning_rate": 0.00027853164481252184,
      "loss": 0.606,
      "step": 488800
    },
    {
      "epoch": 5.175205509181087,
      "grad_norm": 1.040122628211975,
      "learning_rate": 0.00027848575385229767,
      "loss": 0.6187,
      "step": 488850
    },
    {
      "epoch": 5.1757348309610895,
      "grad_norm": 1.0653722286224365,
      "learning_rate": 0.00027843986191958037,
      "loss": 0.6129,
      "step": 488900
    },
    {
      "epoch": 5.176264152741092,
      "grad_norm": 1.0208019018173218,
      "learning_rate": 0.00027839396901593655,
      "loss": 0.6181,
      "step": 488950
    },
    {
      "epoch": 5.176793474521096,
      "grad_norm": 1.08668851852417,
      "learning_rate": 0.00027834899302988265,
      "loss": 0.6185,
      "step": 489000
    },
    {
      "epoch": 5.176793474521096,
      "eval_loss": 0.4124526381492615,
      "eval_runtime": 47.3026,
      "eval_samples_per_second": 3550.119,
      "eval_steps_per_second": 443.781,
      "step": 489000
    },
    {
      "epoch": 5.177322796301099,
      "grad_norm": 1.0402839183807373,
      "learning_rate": 0.00027830309820842683,
      "loss": 0.6406,
      "step": 489050
    },
    {
      "epoch": 5.177852118081103,
      "grad_norm": 1.1444008350372314,
      "learning_rate": 0.0002782572024207135,
      "loss": 0.6395,
      "step": 489100
    },
    {
      "epoch": 5.178381439861106,
      "grad_norm": 1.1386910676956177,
      "learning_rate": 0.00027821130566830967,
      "loss": 0.6234,
      "step": 489150
    },
    {
      "epoch": 5.178910761641109,
      "grad_norm": 1.0970044136047363,
      "learning_rate": 0.0002781654079527822,
      "loss": 0.6166,
      "step": 489200
    },
    {
      "epoch": 5.179440083421112,
      "grad_norm": 1.1165838241577148,
      "learning_rate": 0.0002781195092756981,
      "loss": 0.6257,
      "step": 489250
    },
    {
      "epoch": 5.179969405201116,
      "grad_norm": 1.0471055507659912,
      "learning_rate": 0.0002780736096386242,
      "loss": 0.6265,
      "step": 489300
    },
    {
      "epoch": 5.180498726981119,
      "grad_norm": 1.0153874158859253,
      "learning_rate": 0.0002780277090431276,
      "loss": 0.6304,
      "step": 489350
    },
    {
      "epoch": 5.181028048761123,
      "grad_norm": 1.121556282043457,
      "learning_rate": 0.0002779818074907752,
      "loss": 0.6256,
      "step": 489400
    },
    {
      "epoch": 5.1815573705411255,
      "grad_norm": 0.9843862652778625,
      "learning_rate": 0.00027793590498313426,
      "loss": 0.6264,
      "step": 489450
    },
    {
      "epoch": 5.182086692321129,
      "grad_norm": 1.111995816230774,
      "learning_rate": 0.00027789000152177173,
      "loss": 0.621,
      "step": 489500
    },
    {
      "epoch": 5.182086692321129,
      "eval_loss": 0.413889616727829,
      "eval_runtime": 47.6602,
      "eval_samples_per_second": 3523.485,
      "eval_steps_per_second": 440.451,
      "step": 489500
    },
    {
      "epoch": 5.182616014101132,
      "grad_norm": 0.9714987874031067,
      "learning_rate": 0.00027784409710825483,
      "loss": 0.6121,
      "step": 489550
    },
    {
      "epoch": 5.183145335881136,
      "grad_norm": 1.1286271810531616,
      "learning_rate": 0.0002777981917441506,
      "loss": 0.6225,
      "step": 489600
    },
    {
      "epoch": 5.183674657661139,
      "grad_norm": 1.0314146280288696,
      "learning_rate": 0.0002777522854310264,
      "loss": 0.6159,
      "step": 489650
    },
    {
      "epoch": 5.184203979441142,
      "grad_norm": 1.0823701620101929,
      "learning_rate": 0.00027770637817044923,
      "loss": 0.6178,
      "step": 489700
    },
    {
      "epoch": 5.184733301221145,
      "grad_norm": 1.0348094701766968,
      "learning_rate": 0.0002776604699639865,
      "loss": 0.627,
      "step": 489750
    },
    {
      "epoch": 5.185262623001148,
      "grad_norm": 1.051865577697754,
      "learning_rate": 0.00027761456081320553,
      "loss": 0.6159,
      "step": 489800
    },
    {
      "epoch": 5.185791944781152,
      "grad_norm": 1.0829142332077026,
      "learning_rate": 0.0002775686507196735,
      "loss": 0.626,
      "step": 489850
    },
    {
      "epoch": 5.186321266561155,
      "grad_norm": 1.148650050163269,
      "learning_rate": 0.0002775227396849579,
      "loss": 0.6242,
      "step": 489900
    },
    {
      "epoch": 5.186850588341159,
      "grad_norm": 1.030844807624817,
      "learning_rate": 0.00027747682771062603,
      "loss": 0.6316,
      "step": 489950
    },
    {
      "epoch": 5.1873799101211615,
      "grad_norm": 1.0336005687713623,
      "learning_rate": 0.0002774309147982454,
      "loss": 0.626,
      "step": 490000
    },
    {
      "epoch": 5.1873799101211615,
      "eval_loss": 0.4112764596939087,
      "eval_runtime": 47.6809,
      "eval_samples_per_second": 3521.958,
      "eval_steps_per_second": 440.26,
      "step": 490000
    },
    {
      "epoch": 5.187909231901165,
      "grad_norm": 1.0649042129516602,
      "learning_rate": 0.00027738500094938337,
      "loss": 0.6185,
      "step": 490050
    },
    {
      "epoch": 5.188438553681168,
      "grad_norm": 1.015089511871338,
      "learning_rate": 0.0002773390861656074,
      "loss": 0.6239,
      "step": 490100
    },
    {
      "epoch": 5.188967875461172,
      "grad_norm": 1.1935062408447266,
      "learning_rate": 0.00027729317044848504,
      "loss": 0.6214,
      "step": 490150
    },
    {
      "epoch": 5.189497197241175,
      "grad_norm": 1.1408270597457886,
      "learning_rate": 0.0002772472537995839,
      "loss": 0.6346,
      "step": 490200
    },
    {
      "epoch": 5.1900265190211785,
      "grad_norm": 1.061043381690979,
      "learning_rate": 0.0002772013362204715,
      "loss": 0.6217,
      "step": 490250
    },
    {
      "epoch": 5.190555840801181,
      "grad_norm": 1.0981004238128662,
      "learning_rate": 0.00027715541771271545,
      "loss": 0.6245,
      "step": 490300
    },
    {
      "epoch": 5.191085162581185,
      "grad_norm": 1.1025283336639404,
      "learning_rate": 0.0002771094982778834,
      "loss": 0.6174,
      "step": 490350
    },
    {
      "epoch": 5.191614484361188,
      "grad_norm": 1.1405985355377197,
      "learning_rate": 0.00027706357791754306,
      "loss": 0.6358,
      "step": 490400
    },
    {
      "epoch": 5.192143806141191,
      "grad_norm": 1.0793834924697876,
      "learning_rate": 0.00027701765663326204,
      "loss": 0.6111,
      "step": 490450
    },
    {
      "epoch": 5.192673127921195,
      "grad_norm": 1.0701512098312378,
      "learning_rate": 0.00027697173442660817,
      "loss": 0.6184,
      "step": 490500
    },
    {
      "epoch": 5.192673127921195,
      "eval_loss": 0.413655161857605,
      "eval_runtime": 47.636,
      "eval_samples_per_second": 3525.279,
      "eval_steps_per_second": 440.676,
      "step": 490500
    },
    {
      "epoch": 5.1932024497011975,
      "grad_norm": 1.102441668510437,
      "learning_rate": 0.0002769258112991492,
      "loss": 0.632,
      "step": 490550
    },
    {
      "epoch": 5.193731771481201,
      "grad_norm": 1.0943763256072998,
      "learning_rate": 0.0002768798872524528,
      "loss": 0.6245,
      "step": 490600
    },
    {
      "epoch": 5.194261093261204,
      "grad_norm": 1.1456738710403442,
      "learning_rate": 0.00027683396228808703,
      "loss": 0.6177,
      "step": 490650
    },
    {
      "epoch": 5.194790415041208,
      "grad_norm": 1.085530161857605,
      "learning_rate": 0.0002767880364076196,
      "loss": 0.619,
      "step": 490700
    },
    {
      "epoch": 5.195319736821211,
      "grad_norm": 1.0643866062164307,
      "learning_rate": 0.0002767421096126184,
      "loss": 0.6152,
      "step": 490750
    },
    {
      "epoch": 5.1958490586012145,
      "grad_norm": 1.1310319900512695,
      "learning_rate": 0.0002766961819046514,
      "loss": 0.6268,
      "step": 490800
    },
    {
      "epoch": 5.196378380381217,
      "grad_norm": 1.0081921815872192,
      "learning_rate": 0.00027665025328528655,
      "loss": 0.6246,
      "step": 490850
    },
    {
      "epoch": 5.196907702161221,
      "grad_norm": 1.137257695198059,
      "learning_rate": 0.00027660432375609177,
      "loss": 0.6201,
      "step": 490900
    },
    {
      "epoch": 5.197437023941224,
      "grad_norm": 1.222426176071167,
      "learning_rate": 0.0002765583933186352,
      "loss": 0.6199,
      "step": 490950
    },
    {
      "epoch": 5.197966345721228,
      "grad_norm": 1.0708911418914795,
      "learning_rate": 0.0002765133806102433,
      "loss": 0.6279,
      "step": 491000
    },
    {
      "epoch": 5.197966345721228,
      "eval_loss": 0.4122215509414673,
      "eval_runtime": 47.0383,
      "eval_samples_per_second": 3570.069,
      "eval_steps_per_second": 446.275,
      "step": 491000
    },
    {
      "epoch": 5.198495667501231,
      "grad_norm": 1.1188584566116333,
      "learning_rate": 0.0002764674483790543,
      "loss": 0.6362,
      "step": 491050
    },
    {
      "epoch": 5.199024989281234,
      "grad_norm": 1.1568994522094727,
      "learning_rate": 0.00027642151524427634,
      "loss": 0.6244,
      "step": 491100
    },
    {
      "epoch": 5.199554311061237,
      "grad_norm": 1.1363781690597534,
      "learning_rate": 0.00027637558120747753,
      "loss": 0.6235,
      "step": 491150
    },
    {
      "epoch": 5.20008363284124,
      "grad_norm": 1.0511884689331055,
      "learning_rate": 0.00027632964627022605,
      "loss": 0.62,
      "step": 491200
    },
    {
      "epoch": 5.200612954621244,
      "grad_norm": 1.089938759803772,
      "learning_rate": 0.00027628371043409013,
      "loss": 0.6234,
      "step": 491250
    },
    {
      "epoch": 5.201142276401247,
      "grad_norm": 0.9841645359992981,
      "learning_rate": 0.00027623777370063793,
      "loss": 0.6159,
      "step": 491300
    },
    {
      "epoch": 5.2016715981812505,
      "grad_norm": 1.070057988166809,
      "learning_rate": 0.0002761918360714378,
      "loss": 0.6211,
      "step": 491350
    },
    {
      "epoch": 5.202200919961253,
      "grad_norm": 1.0231589078903198,
      "learning_rate": 0.00027614589754805795,
      "loss": 0.6211,
      "step": 491400
    },
    {
      "epoch": 5.202730241741257,
      "grad_norm": 1.045569896697998,
      "learning_rate": 0.0002760999581320667,
      "loss": 0.6196,
      "step": 491450
    },
    {
      "epoch": 5.20325956352126,
      "grad_norm": 1.0153920650482178,
      "learning_rate": 0.00027605401782503254,
      "loss": 0.6318,
      "step": 491500
    },
    {
      "epoch": 5.20325956352126,
      "eval_loss": 0.4120327830314636,
      "eval_runtime": 47.6642,
      "eval_samples_per_second": 3523.192,
      "eval_steps_per_second": 440.415,
      "step": 491500
    },
    {
      "epoch": 5.203788885301264,
      "grad_norm": 1.161238193511963,
      "learning_rate": 0.00027600807662852373,
      "loss": 0.6347,
      "step": 491550
    },
    {
      "epoch": 5.204318207081267,
      "grad_norm": 1.0448633432388306,
      "learning_rate": 0.0002759621345441088,
      "loss": 0.6193,
      "step": 491600
    },
    {
      "epoch": 5.20484752886127,
      "grad_norm": 1.0631263256072998,
      "learning_rate": 0.000275916191573356,
      "loss": 0.6329,
      "step": 491650
    },
    {
      "epoch": 5.205376850641273,
      "grad_norm": 1.2524840831756592,
      "learning_rate": 0.000275870247717834,
      "loss": 0.627,
      "step": 491700
    },
    {
      "epoch": 5.205906172421277,
      "grad_norm": 1.1513631343841553,
      "learning_rate": 0.0002758243029791112,
      "loss": 0.6274,
      "step": 491750
    },
    {
      "epoch": 5.20643549420128,
      "grad_norm": 1.0649523735046387,
      "learning_rate": 0.0002757783573587562,
      "loss": 0.6166,
      "step": 491800
    },
    {
      "epoch": 5.206964815981284,
      "grad_norm": 0.9342859387397766,
      "learning_rate": 0.00027573241085833753,
      "loss": 0.6213,
      "step": 491850
    },
    {
      "epoch": 5.2074941377612864,
      "grad_norm": 1.0995755195617676,
      "learning_rate": 0.00027568646347942376,
      "loss": 0.6147,
      "step": 491900
    },
    {
      "epoch": 5.208023459541289,
      "grad_norm": 0.9751141667366028,
      "learning_rate": 0.0002756405152235836,
      "loss": 0.6296,
      "step": 491950
    },
    {
      "epoch": 5.208552781321293,
      "grad_norm": 1.0705525875091553,
      "learning_rate": 0.0002755945660923856,
      "loss": 0.6169,
      "step": 492000
    },
    {
      "epoch": 5.208552781321293,
      "eval_loss": 0.40953969955444336,
      "eval_runtime": 47.2716,
      "eval_samples_per_second": 3552.451,
      "eval_steps_per_second": 444.072,
      "step": 492000
    },
    {
      "epoch": 5.209082103101296,
      "grad_norm": 1.1364035606384277,
      "learning_rate": 0.0002755486160873985,
      "loss": 0.6253,
      "step": 492050
    },
    {
      "epoch": 5.2096114248813,
      "grad_norm": 1.0588881969451904,
      "learning_rate": 0.00027550266521019103,
      "loss": 0.6323,
      "step": 492100
    },
    {
      "epoch": 5.210140746661303,
      "grad_norm": 0.8597064018249512,
      "learning_rate": 0.0002754567134623319,
      "loss": 0.6266,
      "step": 492150
    },
    {
      "epoch": 5.210670068441306,
      "grad_norm": 1.1182024478912354,
      "learning_rate": 0.00027541076084538997,
      "loss": 0.6102,
      "step": 492200
    },
    {
      "epoch": 5.211199390221309,
      "grad_norm": 1.173001766204834,
      "learning_rate": 0.00027536480736093397,
      "loss": 0.6173,
      "step": 492250
    },
    {
      "epoch": 5.211728712001313,
      "grad_norm": 1.0087261199951172,
      "learning_rate": 0.00027531977210601676,
      "loss": 0.6221,
      "step": 492300
    },
    {
      "epoch": 5.212258033781316,
      "grad_norm": 1.1629726886749268,
      "learning_rate": 0.00027527381690851135,
      "loss": 0.6243,
      "step": 492350
    },
    {
      "epoch": 5.21278735556132,
      "grad_norm": 1.0332932472229004,
      "learning_rate": 0.000275227860848167,
      "loss": 0.6108,
      "step": 492400
    },
    {
      "epoch": 5.213316677341322,
      "grad_norm": 1.0923832654953003,
      "learning_rate": 0.00027518190392655285,
      "loss": 0.6136,
      "step": 492450
    },
    {
      "epoch": 5.213845999121326,
      "grad_norm": 1.0563335418701172,
      "learning_rate": 0.0002751359461452377,
      "loss": 0.6345,
      "step": 492500
    },
    {
      "epoch": 5.213845999121326,
      "eval_loss": 0.4113202393054962,
      "eval_runtime": 47.316,
      "eval_samples_per_second": 3549.115,
      "eval_steps_per_second": 443.655,
      "step": 492500
    },
    {
      "epoch": 5.214375320901329,
      "grad_norm": 1.0617951154708862,
      "learning_rate": 0.0002750899875057905,
      "loss": 0.623,
      "step": 492550
    },
    {
      "epoch": 5.214904642681333,
      "grad_norm": 1.0399760007858276,
      "learning_rate": 0.0002750440280097804,
      "loss": 0.6248,
      "step": 492600
    },
    {
      "epoch": 5.215433964461336,
      "grad_norm": 1.0405025482177734,
      "learning_rate": 0.00027499806765877635,
      "loss": 0.6184,
      "step": 492650
    },
    {
      "epoch": 5.2159632862413385,
      "grad_norm": 1.0642741918563843,
      "learning_rate": 0.0002749521064543474,
      "loss": 0.6243,
      "step": 492700
    },
    {
      "epoch": 5.216492608021342,
      "grad_norm": 1.04459810256958,
      "learning_rate": 0.00027490614439806273,
      "loss": 0.634,
      "step": 492750
    },
    {
      "epoch": 5.217021929801345,
      "grad_norm": 1.0863603353500366,
      "learning_rate": 0.0002748601814914914,
      "loss": 0.6272,
      "step": 492800
    },
    {
      "epoch": 5.217551251581349,
      "grad_norm": 1.096312165260315,
      "learning_rate": 0.00027481421773620256,
      "loss": 0.6208,
      "step": 492850
    },
    {
      "epoch": 5.218080573361352,
      "grad_norm": 1.2093837261199951,
      "learning_rate": 0.00027476825313376546,
      "loss": 0.6187,
      "step": 492900
    },
    {
      "epoch": 5.2186098951413555,
      "grad_norm": 1.0770387649536133,
      "learning_rate": 0.00027472228768574933,
      "loss": 0.618,
      "step": 492950
    },
    {
      "epoch": 5.219139216921358,
      "grad_norm": 1.0363043546676636,
      "learning_rate": 0.0002746763213937233,
      "loss": 0.6186,
      "step": 493000
    },
    {
      "epoch": 5.219139216921358,
      "eval_loss": 0.41047102212905884,
      "eval_runtime": 47.3679,
      "eval_samples_per_second": 3545.23,
      "eval_steps_per_second": 443.17,
      "step": 493000
    },
    {
      "epoch": 5.219668538701362,
      "grad_norm": 1.1506829261779785,
      "learning_rate": 0.0002746303542592567,
      "loss": 0.6341,
      "step": 493050
    },
    {
      "epoch": 5.220197860481365,
      "grad_norm": 1.0334645509719849,
      "learning_rate": 0.0002745843862839189,
      "loss": 0.6256,
      "step": 493100
    },
    {
      "epoch": 5.220727182261369,
      "grad_norm": 1.0440787076950073,
      "learning_rate": 0.00027453841746927915,
      "loss": 0.6271,
      "step": 493150
    },
    {
      "epoch": 5.221256504041372,
      "grad_norm": 1.0127232074737549,
      "learning_rate": 0.0002744924478169068,
      "loss": 0.6235,
      "step": 493200
    },
    {
      "epoch": 5.221785825821375,
      "grad_norm": 1.140895962715149,
      "learning_rate": 0.0002744464773283713,
      "loss": 0.6192,
      "step": 493250
    },
    {
      "epoch": 5.222315147601378,
      "grad_norm": 0.982994019985199,
      "learning_rate": 0.00027440050600524205,
      "loss": 0.6322,
      "step": 493300
    },
    {
      "epoch": 5.222844469381382,
      "grad_norm": 1.055474042892456,
      "learning_rate": 0.0002743545338490884,
      "loss": 0.6052,
      "step": 493350
    },
    {
      "epoch": 5.223373791161385,
      "grad_norm": 1.0645802021026611,
      "learning_rate": 0.00027430856086147994,
      "loss": 0.6203,
      "step": 493400
    },
    {
      "epoch": 5.223903112941388,
      "grad_norm": 1.146765112876892,
      "learning_rate": 0.0002742625870439861,
      "loss": 0.6208,
      "step": 493450
    },
    {
      "epoch": 5.2244324347213915,
      "grad_norm": 1.1342021226882935,
      "learning_rate": 0.00027421661239817647,
      "loss": 0.6155,
      "step": 493500
    },
    {
      "epoch": 5.2244324347213915,
      "eval_loss": 0.41162464022636414,
      "eval_runtime": 47.3496,
      "eval_samples_per_second": 3546.599,
      "eval_steps_per_second": 443.341,
      "step": 493500
    },
    {
      "epoch": 5.224961756501394,
      "grad_norm": 1.1684445142745972,
      "learning_rate": 0.00027417063692562055,
      "loss": 0.6256,
      "step": 493550
    },
    {
      "epoch": 5.225491078281398,
      "grad_norm": 1.070483684539795,
      "learning_rate": 0.00027412466062788794,
      "loss": 0.6088,
      "step": 493600
    },
    {
      "epoch": 5.226020400061401,
      "grad_norm": 1.1020584106445312,
      "learning_rate": 0.0002740786835065483,
      "loss": 0.6229,
      "step": 493650
    },
    {
      "epoch": 5.226549721841405,
      "grad_norm": 1.0639030933380127,
      "learning_rate": 0.00027403270556317116,
      "loss": 0.6143,
      "step": 493700
    },
    {
      "epoch": 5.227079043621408,
      "grad_norm": 1.090143084526062,
      "learning_rate": 0.0002739867267993263,
      "loss": 0.6215,
      "step": 493750
    },
    {
      "epoch": 5.227608365401411,
      "grad_norm": 1.1744940280914307,
      "learning_rate": 0.0002739407472165834,
      "loss": 0.629,
      "step": 493800
    },
    {
      "epoch": 5.228137687181414,
      "grad_norm": 1.1180713176727295,
      "learning_rate": 0.0002738947668165122,
      "loss": 0.6233,
      "step": 493850
    },
    {
      "epoch": 5.228667008961418,
      "grad_norm": 1.1406627893447876,
      "learning_rate": 0.00027384878560068236,
      "loss": 0.6233,
      "step": 493900
    },
    {
      "epoch": 5.229196330741421,
      "grad_norm": 1.095492959022522,
      "learning_rate": 0.0002738028035706638,
      "loss": 0.6134,
      "step": 493950
    },
    {
      "epoch": 5.229725652521425,
      "grad_norm": 1.0945154428482056,
      "learning_rate": 0.00027375682072802623,
      "loss": 0.6163,
      "step": 494000
    },
    {
      "epoch": 5.229725652521425,
      "eval_loss": 0.41087740659713745,
      "eval_runtime": 47.4102,
      "eval_samples_per_second": 3542.068,
      "eval_steps_per_second": 442.774,
      "step": 494000
    },
    {
      "epoch": 5.2302549743014275,
      "grad_norm": 1.2165933847427368,
      "learning_rate": 0.0002737108370743395,
      "loss": 0.6157,
      "step": 494050
    },
    {
      "epoch": 5.230784296081431,
      "grad_norm": 1.2250967025756836,
      "learning_rate": 0.00027366485261117346,
      "loss": 0.6235,
      "step": 494100
    },
    {
      "epoch": 5.231313617861434,
      "grad_norm": 0.9860531091690063,
      "learning_rate": 0.0002736188673400981,
      "loss": 0.6243,
      "step": 494150
    },
    {
      "epoch": 5.231842939641437,
      "grad_norm": 0.9912470579147339,
      "learning_rate": 0.0002735728812626832,
      "loss": 0.6279,
      "step": 494200
    },
    {
      "epoch": 5.232372261421441,
      "grad_norm": 1.0554823875427246,
      "learning_rate": 0.0002735268943804988,
      "loss": 0.6197,
      "step": 494250
    },
    {
      "epoch": 5.232901583201444,
      "grad_norm": 1.1343188285827637,
      "learning_rate": 0.0002734809066951149,
      "loss": 0.6113,
      "step": 494300
    },
    {
      "epoch": 5.233430904981447,
      "grad_norm": 1.1584049463272095,
      "learning_rate": 0.0002734349182081015,
      "loss": 0.6146,
      "step": 494350
    },
    {
      "epoch": 5.23396022676145,
      "grad_norm": 1.1204683780670166,
      "learning_rate": 0.0002733889289210285,
      "loss": 0.6212,
      "step": 494400
    },
    {
      "epoch": 5.234489548541454,
      "grad_norm": 1.055393934249878,
      "learning_rate": 0.000273342938835466,
      "loss": 0.6155,
      "step": 494450
    },
    {
      "epoch": 5.235018870321457,
      "grad_norm": 1.1032555103302002,
      "learning_rate": 0.0002732969479529842,
      "loss": 0.6148,
      "step": 494500
    },
    {
      "epoch": 5.235018870321457,
      "eval_loss": 0.4108242988586426,
      "eval_runtime": 47.2656,
      "eval_samples_per_second": 3552.898,
      "eval_steps_per_second": 444.128,
      "step": 494500
    },
    {
      "epoch": 5.235548192101461,
      "grad_norm": 1.1517432928085327,
      "learning_rate": 0.0002732509562751531,
      "loss": 0.625,
      "step": 494550
    },
    {
      "epoch": 5.2360775138814635,
      "grad_norm": 1.030438780784607,
      "learning_rate": 0.00027320496380354287,
      "loss": 0.6287,
      "step": 494600
    },
    {
      "epoch": 5.236606835661467,
      "grad_norm": 1.113961935043335,
      "learning_rate": 0.0002731589705397237,
      "loss": 0.6301,
      "step": 494650
    },
    {
      "epoch": 5.23713615744147,
      "grad_norm": 1.24760901927948,
      "learning_rate": 0.0002731129764852658,
      "loss": 0.6311,
      "step": 494700
    },
    {
      "epoch": 5.237665479221474,
      "grad_norm": 1.2417354583740234,
      "learning_rate": 0.0002730669816417394,
      "loss": 0.6176,
      "step": 494750
    },
    {
      "epoch": 5.238194801001477,
      "grad_norm": 1.0756958723068237,
      "learning_rate": 0.0002730209860107146,
      "loss": 0.6225,
      "step": 494800
    },
    {
      "epoch": 5.2387241227814805,
      "grad_norm": 1.0850220918655396,
      "learning_rate": 0.0002729749895937618,
      "loss": 0.6276,
      "step": 494850
    },
    {
      "epoch": 5.239253444561483,
      "grad_norm": 1.1663885116577148,
      "learning_rate": 0.0002729289923924514,
      "loss": 0.6385,
      "step": 494900
    },
    {
      "epoch": 5.239782766341486,
      "grad_norm": 0.9923173785209656,
      "learning_rate": 0.0002728829944083535,
      "loss": 0.6199,
      "step": 494950
    },
    {
      "epoch": 5.24031208812149,
      "grad_norm": 0.9818036556243896,
      "learning_rate": 0.0002728369956430386,
      "loss": 0.6217,
      "step": 495000
    },
    {
      "epoch": 5.24031208812149,
      "eval_loss": 0.4116327166557312,
      "eval_runtime": 46.8923,
      "eval_samples_per_second": 3581.182,
      "eval_steps_per_second": 447.664,
      "step": 495000
    },
    {
      "epoch": 5.240841409901493,
      "grad_norm": 0.9548150300979614,
      "learning_rate": 0.000272790996098077,
      "loss": 0.6201,
      "step": 495050
    },
    {
      "epoch": 5.241370731681497,
      "grad_norm": 1.0296928882598877,
      "learning_rate": 0.0002727449957750392,
      "loss": 0.6268,
      "step": 495100
    },
    {
      "epoch": 5.2419000534614995,
      "grad_norm": 1.0824825763702393,
      "learning_rate": 0.0002726989946754956,
      "loss": 0.6242,
      "step": 495150
    },
    {
      "epoch": 5.242429375241503,
      "grad_norm": 1.1345049142837524,
      "learning_rate": 0.0002726529928010166,
      "loss": 0.633,
      "step": 495200
    },
    {
      "epoch": 5.242958697021506,
      "grad_norm": 1.0124591588974,
      "learning_rate": 0.0002726069901531728,
      "loss": 0.6214,
      "step": 495250
    },
    {
      "epoch": 5.24348801880151,
      "grad_norm": 1.146790862083435,
      "learning_rate": 0.00027256098673353454,
      "loss": 0.6281,
      "step": 495300
    },
    {
      "epoch": 5.244017340581513,
      "grad_norm": 1.110909342765808,
      "learning_rate": 0.00027251498254367247,
      "loss": 0.6209,
      "step": 495350
    },
    {
      "epoch": 5.2445466623615165,
      "grad_norm": 1.1298366785049438,
      "learning_rate": 0.0002724689775851572,
      "loss": 0.6179,
      "step": 495400
    },
    {
      "epoch": 5.245075984141519,
      "grad_norm": 0.880714476108551,
      "learning_rate": 0.0002724229718595593,
      "loss": 0.6323,
      "step": 495450
    },
    {
      "epoch": 5.245605305921523,
      "grad_norm": 1.126277208328247,
      "learning_rate": 0.00027237696536844936,
      "loss": 0.6326,
      "step": 495500
    },
    {
      "epoch": 5.245605305921523,
      "eval_loss": 0.4115252196788788,
      "eval_runtime": 47.1656,
      "eval_samples_per_second": 3560.433,
      "eval_steps_per_second": 445.07,
      "step": 495500
    },
    {
      "epoch": 5.246134627701526,
      "grad_norm": 1.0706355571746826,
      "learning_rate": 0.00027233095811339796,
      "loss": 0.6123,
      "step": 495550
    },
    {
      "epoch": 5.24666394948153,
      "grad_norm": 1.027344822883606,
      "learning_rate": 0.00027228495009597593,
      "loss": 0.622,
      "step": 495600
    },
    {
      "epoch": 5.247193271261533,
      "grad_norm": 1.0863052606582642,
      "learning_rate": 0.00027223894131775384,
      "loss": 0.6182,
      "step": 495650
    },
    {
      "epoch": 5.247722593041535,
      "grad_norm": 1.119323492050171,
      "learning_rate": 0.0002721929317803025,
      "loss": 0.6215,
      "step": 495700
    },
    {
      "epoch": 5.248251914821539,
      "grad_norm": 1.1530861854553223,
      "learning_rate": 0.0002721469214851925,
      "loss": 0.6133,
      "step": 495750
    },
    {
      "epoch": 5.248781236601542,
      "grad_norm": 0.9952747821807861,
      "learning_rate": 0.00027210091043399474,
      "loss": 0.6255,
      "step": 495800
    },
    {
      "epoch": 5.249310558381546,
      "grad_norm": 1.0476130247116089,
      "learning_rate": 0.0002720548986282801,
      "loss": 0.6116,
      "step": 495850
    },
    {
      "epoch": 5.249839880161549,
      "grad_norm": 1.0755971670150757,
      "learning_rate": 0.0002720088860696193,
      "loss": 0.6271,
      "step": 495900
    },
    {
      "epoch": 5.250369201941552,
      "grad_norm": 1.1419744491577148,
      "learning_rate": 0.0002719628727595831,
      "loss": 0.6155,
      "step": 495950
    },
    {
      "epoch": 5.250898523721555,
      "grad_norm": 1.1775213479995728,
      "learning_rate": 0.00027191685869974253,
      "loss": 0.6168,
      "step": 496000
    },
    {
      "epoch": 5.250898523721555,
      "eval_loss": 0.40817010402679443,
      "eval_runtime": 46.7925,
      "eval_samples_per_second": 3588.825,
      "eval_steps_per_second": 448.619,
      "step": 496000
    },
    {
      "epoch": 5.251427845501559,
      "grad_norm": 1.1811187267303467,
      "learning_rate": 0.0002718708438916684,
      "loss": 0.6285,
      "step": 496050
    },
    {
      "epoch": 5.251957167281562,
      "grad_norm": 1.0382773876190186,
      "learning_rate": 0.0002718248283369318,
      "loss": 0.6212,
      "step": 496100
    },
    {
      "epoch": 5.252486489061566,
      "grad_norm": 1.2102841138839722,
      "learning_rate": 0.0002717788120371035,
      "loss": 0.627,
      "step": 496150
    },
    {
      "epoch": 5.2530158108415685,
      "grad_norm": 1.0750919580459595,
      "learning_rate": 0.0002717327949937545,
      "loss": 0.6125,
      "step": 496200
    },
    {
      "epoch": 5.253545132621572,
      "grad_norm": 1.0166741609573364,
      "learning_rate": 0.00027168677720845584,
      "loss": 0.6189,
      "step": 496250
    },
    {
      "epoch": 5.254074454401575,
      "grad_norm": 1.1023668050765991,
      "learning_rate": 0.0002716407586827786,
      "loss": 0.6272,
      "step": 496300
    },
    {
      "epoch": 5.254603776181579,
      "grad_norm": 1.1753556728363037,
      "learning_rate": 0.0002715956598108137,
      "loss": 0.6111,
      "step": 496350
    },
    {
      "epoch": 5.255133097961582,
      "grad_norm": 1.0949143171310425,
      "learning_rate": 0.00027154963982382174,
      "loss": 0.6292,
      "step": 496400
    },
    {
      "epoch": 5.255662419741585,
      "grad_norm": 1.0361077785491943,
      "learning_rate": 0.00027150361910113297,
      "loss": 0.6212,
      "step": 496450
    },
    {
      "epoch": 5.256191741521588,
      "grad_norm": 1.2193478345870972,
      "learning_rate": 0.00027145759764431854,
      "loss": 0.6136,
      "step": 496500
    },
    {
      "epoch": 5.256191741521588,
      "eval_loss": 0.40938058495521545,
      "eval_runtime": 46.8073,
      "eval_samples_per_second": 3587.686,
      "eval_steps_per_second": 448.477,
      "step": 496500
    },
    {
      "epoch": 5.256721063301591,
      "grad_norm": 1.1342787742614746,
      "learning_rate": 0.0002714115754549496,
      "loss": 0.6215,
      "step": 496550
    },
    {
      "epoch": 5.257250385081595,
      "grad_norm": 1.0884367227554321,
      "learning_rate": 0.00027136555253459726,
      "loss": 0.6177,
      "step": 496600
    },
    {
      "epoch": 5.257779706861598,
      "grad_norm": 1.0590929985046387,
      "learning_rate": 0.0002713195288848329,
      "loss": 0.6249,
      "step": 496650
    },
    {
      "epoch": 5.258309028641602,
      "grad_norm": 1.0286521911621094,
      "learning_rate": 0.0002712735045072276,
      "loss": 0.61,
      "step": 496700
    },
    {
      "epoch": 5.2588383504216045,
      "grad_norm": 1.1293885707855225,
      "learning_rate": 0.0002712274794033527,
      "loss": 0.6242,
      "step": 496750
    },
    {
      "epoch": 5.259367672201608,
      "grad_norm": 1.0821635723114014,
      "learning_rate": 0.00027118145357477936,
      "loss": 0.6158,
      "step": 496800
    },
    {
      "epoch": 5.259896993981611,
      "grad_norm": 1.1730455160140991,
      "learning_rate": 0.00027113542702307905,
      "loss": 0.6186,
      "step": 496850
    },
    {
      "epoch": 5.260426315761615,
      "grad_norm": 1.037067174911499,
      "learning_rate": 0.00027108939974982294,
      "loss": 0.6251,
      "step": 496900
    },
    {
      "epoch": 5.260955637541618,
      "grad_norm": 1.0227843523025513,
      "learning_rate": 0.00027104337175658244,
      "loss": 0.6206,
      "step": 496950
    },
    {
      "epoch": 5.2614849593216215,
      "grad_norm": 1.1615005731582642,
      "learning_rate": 0.00027099734304492903,
      "loss": 0.6152,
      "step": 497000
    },
    {
      "epoch": 5.2614849593216215,
      "eval_loss": 0.408927321434021,
      "eval_runtime": 46.9274,
      "eval_samples_per_second": 3578.505,
      "eval_steps_per_second": 447.329,
      "step": 497000
    },
    {
      "epoch": 5.262014281101624,
      "grad_norm": 1.1171798706054688,
      "learning_rate": 0.000270951313616434,
      "loss": 0.6239,
      "step": 497050
    },
    {
      "epoch": 5.262543602881628,
      "grad_norm": 0.9782105684280396,
      "learning_rate": 0.00027090528347266873,
      "loss": 0.6207,
      "step": 497100
    },
    {
      "epoch": 5.263072924661631,
      "grad_norm": 1.0290236473083496,
      "learning_rate": 0.0002708592526152048,
      "loss": 0.6244,
      "step": 497150
    },
    {
      "epoch": 5.263602246441634,
      "grad_norm": 1.1819771528244019,
      "learning_rate": 0.0002708132210456137,
      "loss": 0.6234,
      "step": 497200
    },
    {
      "epoch": 5.264131568221638,
      "grad_norm": 1.043013334274292,
      "learning_rate": 0.0002707671887654668,
      "loss": 0.6189,
      "step": 497250
    },
    {
      "epoch": 5.2646608900016405,
      "grad_norm": 1.119630217552185,
      "learning_rate": 0.0002707211557763357,
      "loss": 0.6228,
      "step": 497300
    },
    {
      "epoch": 5.265190211781644,
      "grad_norm": 1.0133627653121948,
      "learning_rate": 0.0002706751220797919,
      "loss": 0.6162,
      "step": 497350
    },
    {
      "epoch": 5.265719533561647,
      "grad_norm": 1.0003048181533813,
      "learning_rate": 0.0002706290876774071,
      "loss": 0.6282,
      "step": 497400
    },
    {
      "epoch": 5.266248855341651,
      "grad_norm": 1.1756258010864258,
      "learning_rate": 0.0002705830525707528,
      "loss": 0.6196,
      "step": 497450
    },
    {
      "epoch": 5.266778177121654,
      "grad_norm": 1.1597980260849,
      "learning_rate": 0.0002705370167614006,
      "loss": 0.6106,
      "step": 497500
    },
    {
      "epoch": 5.266778177121654,
      "eval_loss": 0.4082454741001129,
      "eval_runtime": 46.972,
      "eval_samples_per_second": 3575.111,
      "eval_steps_per_second": 446.905,
      "step": 497500
    },
    {
      "epoch": 5.2673074989016575,
      "grad_norm": 1.1667660474777222,
      "learning_rate": 0.0002704909802509222,
      "loss": 0.6125,
      "step": 497550
    },
    {
      "epoch": 5.26783682068166,
      "grad_norm": 1.0853917598724365,
      "learning_rate": 0.0002704449430408892,
      "loss": 0.6182,
      "step": 497600
    },
    {
      "epoch": 5.268366142461664,
      "grad_norm": 0.9942089915275574,
      "learning_rate": 0.00027039890513287336,
      "loss": 0.625,
      "step": 497650
    },
    {
      "epoch": 5.268895464241667,
      "grad_norm": 1.141892910003662,
      "learning_rate": 0.00027035286652844645,
      "loss": 0.6133,
      "step": 497700
    },
    {
      "epoch": 5.269424786021671,
      "grad_norm": 1.143043875694275,
      "learning_rate": 0.00027030682722918006,
      "loss": 0.6201,
      "step": 497750
    },
    {
      "epoch": 5.269954107801674,
      "grad_norm": 1.1917575597763062,
      "learning_rate": 0.000270260787236646,
      "loss": 0.6246,
      "step": 497800
    },
    {
      "epoch": 5.270483429581677,
      "grad_norm": 1.1180347204208374,
      "learning_rate": 0.00027021474655241625,
      "loss": 0.6258,
      "step": 497850
    },
    {
      "epoch": 5.27101275136168,
      "grad_norm": 1.0805444717407227,
      "learning_rate": 0.00027016870517806237,
      "loss": 0.6287,
      "step": 497900
    },
    {
      "epoch": 5.271542073141683,
      "grad_norm": 1.1249070167541504,
      "learning_rate": 0.0002701226631151563,
      "loss": 0.622,
      "step": 497950
    },
    {
      "epoch": 5.272071394921687,
      "grad_norm": 1.0762416124343872,
      "learning_rate": 0.00027007662036526985,
      "loss": 0.615,
      "step": 498000
    },
    {
      "epoch": 5.272071394921687,
      "eval_loss": 0.40740659832954407,
      "eval_runtime": 46.8364,
      "eval_samples_per_second": 3585.457,
      "eval_steps_per_second": 448.198,
      "step": 498000
    },
    {
      "epoch": 5.27260071670169,
      "grad_norm": 1.0424658060073853,
      "learning_rate": 0.00027003057692997503,
      "loss": 0.6169,
      "step": 498050
    },
    {
      "epoch": 5.2731300384816935,
      "grad_norm": 1.0633327960968018,
      "learning_rate": 0.0002699845328108436,
      "loss": 0.6117,
      "step": 498100
    },
    {
      "epoch": 5.273659360261696,
      "grad_norm": 1.1392046213150024,
      "learning_rate": 0.0002699384880094475,
      "loss": 0.6221,
      "step": 498150
    },
    {
      "epoch": 5.2741886820417,
      "grad_norm": 1.053147554397583,
      "learning_rate": 0.0002698924425273588,
      "loss": 0.6317,
      "step": 498200
    },
    {
      "epoch": 5.274718003821703,
      "grad_norm": 1.0267741680145264,
      "learning_rate": 0.0002698463963661494,
      "loss": 0.6168,
      "step": 498250
    },
    {
      "epoch": 5.275247325601707,
      "grad_norm": 1.1721646785736084,
      "learning_rate": 0.0002698003495273913,
      "loss": 0.6301,
      "step": 498300
    },
    {
      "epoch": 5.27577664738171,
      "grad_norm": 1.1043215990066528,
      "learning_rate": 0.0002697552229695656,
      "loss": 0.6199,
      "step": 498350
    },
    {
      "epoch": 5.276305969161713,
      "grad_norm": 1.0809082984924316,
      "learning_rate": 0.0002697091747938989,
      "loss": 0.6184,
      "step": 498400
    },
    {
      "epoch": 5.276835290941716,
      "grad_norm": 1.06764554977417,
      "learning_rate": 0.0002696631259453682,
      "loss": 0.6145,
      "step": 498450
    },
    {
      "epoch": 5.27736461272172,
      "grad_norm": 0.98310387134552,
      "learning_rate": 0.0002696170764255456,
      "loss": 0.6111,
      "step": 498500
    },
    {
      "epoch": 5.27736461272172,
      "eval_loss": 0.40818169713020325,
      "eval_runtime": 46.8373,
      "eval_samples_per_second": 3585.392,
      "eval_steps_per_second": 448.19,
      "step": 498500
    },
    {
      "epoch": 5.277893934501723,
      "grad_norm": 1.1704888343811035,
      "learning_rate": 0.00026957102623600314,
      "loss": 0.6236,
      "step": 498550
    },
    {
      "epoch": 5.278423256281727,
      "grad_norm": 1.0316096544265747,
      "learning_rate": 0.0002695249753783131,
      "loss": 0.6342,
      "step": 498600
    },
    {
      "epoch": 5.2789525780617295,
      "grad_norm": 1.0691431760787964,
      "learning_rate": 0.00026947892385404754,
      "loss": 0.615,
      "step": 498650
    },
    {
      "epoch": 5.279481899841732,
      "grad_norm": 1.0973315238952637,
      "learning_rate": 0.0002694328716647787,
      "loss": 0.6163,
      "step": 498700
    },
    {
      "epoch": 5.280011221621736,
      "grad_norm": 1.1666936874389648,
      "learning_rate": 0.0002693868188120787,
      "loss": 0.6148,
      "step": 498750
    },
    {
      "epoch": 5.280540543401739,
      "grad_norm": 1.1253103017807007,
      "learning_rate": 0.0002693407652975198,
      "loss": 0.6093,
      "step": 498800
    },
    {
      "epoch": 5.281069865181743,
      "grad_norm": 1.098740577697754,
      "learning_rate": 0.00026929471112267426,
      "loss": 0.6158,
      "step": 498850
    },
    {
      "epoch": 5.281599186961746,
      "grad_norm": 1.1303088665008545,
      "learning_rate": 0.0002692486562891144,
      "loss": 0.6228,
      "step": 498900
    },
    {
      "epoch": 5.282128508741749,
      "grad_norm": 1.2044837474822998,
      "learning_rate": 0.0002692026007984124,
      "loss": 0.6154,
      "step": 498950
    },
    {
      "epoch": 5.282657830521752,
      "grad_norm": 1.0900869369506836,
      "learning_rate": 0.0002691565446521407,
      "loss": 0.6174,
      "step": 499000
    },
    {
      "epoch": 5.282657830521752,
      "eval_loss": 0.40851637721061707,
      "eval_runtime": 46.8756,
      "eval_samples_per_second": 3582.461,
      "eval_steps_per_second": 447.824,
      "step": 499000
    },
    {
      "epoch": 5.283187152301756,
      "grad_norm": 1.092943549156189,
      "learning_rate": 0.00026911048785187167,
      "loss": 0.6127,
      "step": 499050
    },
    {
      "epoch": 5.283716474081759,
      "grad_norm": 1.2174131870269775,
      "learning_rate": 0.0002690644303991775,
      "loss": 0.6094,
      "step": 499100
    },
    {
      "epoch": 5.284245795861763,
      "grad_norm": 1.174951195716858,
      "learning_rate": 0.0002690183722956307,
      "loss": 0.6204,
      "step": 499150
    },
    {
      "epoch": 5.284775117641765,
      "grad_norm": 1.1352448463439941,
      "learning_rate": 0.00026897231354280367,
      "loss": 0.6079,
      "step": 499200
    },
    {
      "epoch": 5.285304439421769,
      "grad_norm": 0.9678260087966919,
      "learning_rate": 0.00026892625414226876,
      "loss": 0.6095,
      "step": 499250
    },
    {
      "epoch": 5.285833761201772,
      "grad_norm": 1.125916600227356,
      "learning_rate": 0.0002688801940955985,
      "loss": 0.617,
      "step": 499300
    },
    {
      "epoch": 5.286363082981776,
      "grad_norm": 1.043183445930481,
      "learning_rate": 0.0002688341334043654,
      "loss": 0.6127,
      "step": 499350
    },
    {
      "epoch": 5.286892404761779,
      "grad_norm": 0.9792291522026062,
      "learning_rate": 0.0002687880720701418,
      "loss": 0.6166,
      "step": 499400
    },
    {
      "epoch": 5.2874217265417816,
      "grad_norm": 1.1655503511428833,
      "learning_rate": 0.00026874201009450025,
      "loss": 0.6317,
      "step": 499450
    },
    {
      "epoch": 5.287951048321785,
      "grad_norm": 1.121444821357727,
      "learning_rate": 0.0002686959474790135,
      "loss": 0.61,
      "step": 499500
    },
    {
      "epoch": 5.287951048321785,
      "eval_loss": 0.40812233090400696,
      "eval_runtime": 46.8954,
      "eval_samples_per_second": 3580.949,
      "eval_steps_per_second": 447.635,
      "step": 499500
    },
    {
      "epoch": 5.288480370101788,
      "grad_norm": 1.1698492765426636,
      "learning_rate": 0.00026864988422525387,
      "loss": 0.6196,
      "step": 499550
    },
    {
      "epoch": 5.289009691881792,
      "grad_norm": 1.0102769136428833,
      "learning_rate": 0.0002686038203347941,
      "loss": 0.6196,
      "step": 499600
    },
    {
      "epoch": 5.289539013661795,
      "grad_norm": 1.1820359230041504,
      "learning_rate": 0.0002685577558092066,
      "loss": 0.6159,
      "step": 499650
    },
    {
      "epoch": 5.2900683354417986,
      "grad_norm": 1.2486909627914429,
      "learning_rate": 0.0002685116906500642,
      "loss": 0.62,
      "step": 499700
    },
    {
      "epoch": 5.290597657221801,
      "grad_norm": 1.0001963376998901,
      "learning_rate": 0.0002684656248589395,
      "loss": 0.6186,
      "step": 499750
    },
    {
      "epoch": 5.291126979001805,
      "grad_norm": 1.129103422164917,
      "learning_rate": 0.00026841955843740514,
      "loss": 0.616,
      "step": 499800
    },
    {
      "epoch": 5.291656300781808,
      "grad_norm": 1.0766596794128418,
      "learning_rate": 0.00026837349138703374,
      "loss": 0.6201,
      "step": 499850
    },
    {
      "epoch": 5.292185622561812,
      "grad_norm": 0.9818214774131775,
      "learning_rate": 0.0002683274237093981,
      "loss": 0.618,
      "step": 499900
    },
    {
      "epoch": 5.292714944341815,
      "grad_norm": 1.1211564540863037,
      "learning_rate": 0.000268281355406071,
      "loss": 0.6107,
      "step": 499950
    },
    {
      "epoch": 5.293244266121818,
      "grad_norm": 0.9940754771232605,
      "learning_rate": 0.00026823528647862513,
      "loss": 0.6108,
      "step": 500000
    },
    {
      "epoch": 5.293244266121818,
      "eval_loss": 0.4062138497829437,
      "eval_runtime": 46.8854,
      "eval_samples_per_second": 3581.714,
      "eval_steps_per_second": 447.73,
      "step": 500000
    },
    {
      "epoch": 5.293773587901821,
      "grad_norm": 1.113779067993164,
      "learning_rate": 0.0002681892169286332,
      "loss": 0.6234,
      "step": 500050
    },
    {
      "epoch": 5.294302909681825,
      "grad_norm": 1.2052497863769531,
      "learning_rate": 0.0002681431467576681,
      "loss": 0.6204,
      "step": 500100
    },
    {
      "epoch": 5.294832231461828,
      "grad_norm": 1.0619593858718872,
      "learning_rate": 0.00026809707596730267,
      "loss": 0.6103,
      "step": 500150
    },
    {
      "epoch": 5.295361553241831,
      "grad_norm": 1.079169511795044,
      "learning_rate": 0.00026805100455910965,
      "loss": 0.6267,
      "step": 500200
    },
    {
      "epoch": 5.2958908750218345,
      "grad_norm": 1.0754926204681396,
      "learning_rate": 0.000268004932534662,
      "loss": 0.6208,
      "step": 500250
    },
    {
      "epoch": 5.296420196801837,
      "grad_norm": 1.0747178792953491,
      "learning_rate": 0.0002679588598955325,
      "loss": 0.6229,
      "step": 500300
    },
    {
      "epoch": 5.296949518581841,
      "grad_norm": 1.1041141748428345,
      "learning_rate": 0.0002679137081143372,
      "loss": 0.6143,
      "step": 500350
    },
    {
      "epoch": 5.297478840361844,
      "grad_norm": 1.2068312168121338,
      "learning_rate": 0.0002678676342627782,
      "loss": 0.6165,
      "step": 500400
    },
    {
      "epoch": 5.298008162141848,
      "grad_norm": 1.174751877784729,
      "learning_rate": 0.00026782155980122465,
      "loss": 0.6188,
      "step": 500450
    },
    {
      "epoch": 5.298537483921851,
      "grad_norm": 1.0649229288101196,
      "learning_rate": 0.00026777548473124965,
      "loss": 0.6241,
      "step": 500500
    },
    {
      "epoch": 5.298537483921851,
      "eval_loss": 0.40778425335884094,
      "eval_runtime": 47.289,
      "eval_samples_per_second": 3551.146,
      "eval_steps_per_second": 443.909,
      "step": 500500
    },
    {
      "epoch": 5.299066805701854,
      "grad_norm": 1.0997695922851562,
      "learning_rate": 0.00026772940905442604,
      "loss": 0.6259,
      "step": 500550
    },
    {
      "epoch": 5.299596127481857,
      "grad_norm": 1.0348109006881714,
      "learning_rate": 0.000267683332772327,
      "loss": 0.6186,
      "step": 500600
    },
    {
      "epoch": 5.300125449261861,
      "grad_norm": 1.0928740501403809,
      "learning_rate": 0.00026763725588652544,
      "loss": 0.611,
      "step": 500650
    },
    {
      "epoch": 5.300654771041864,
      "grad_norm": 1.0961023569107056,
      "learning_rate": 0.00026759117839859437,
      "loss": 0.6211,
      "step": 500700
    },
    {
      "epoch": 5.301184092821868,
      "grad_norm": 1.0992190837860107,
      "learning_rate": 0.00026754510031010696,
      "loss": 0.608,
      "step": 500750
    },
    {
      "epoch": 5.3017134146018705,
      "grad_norm": 1.0295660495758057,
      "learning_rate": 0.0002674990216226363,
      "loss": 0.6147,
      "step": 500800
    },
    {
      "epoch": 5.302242736381874,
      "grad_norm": 1.0119701623916626,
      "learning_rate": 0.0002674529423377554,
      "loss": 0.6137,
      "step": 500850
    },
    {
      "epoch": 5.302772058161877,
      "grad_norm": 1.0873432159423828,
      "learning_rate": 0.0002674068624570375,
      "loss": 0.6323,
      "step": 500900
    },
    {
      "epoch": 5.30330137994188,
      "grad_norm": 1.2286903858184814,
      "learning_rate": 0.0002673607819820557,
      "loss": 0.6172,
      "step": 500950
    },
    {
      "epoch": 5.303830701721884,
      "grad_norm": 1.1843340396881104,
      "learning_rate": 0.0002673147009143831,
      "loss": 0.6166,
      "step": 501000
    },
    {
      "epoch": 5.303830701721884,
      "eval_loss": 0.4049261212348938,
      "eval_runtime": 47.1776,
      "eval_samples_per_second": 3559.529,
      "eval_steps_per_second": 444.957,
      "step": 501000
    },
    {
      "epoch": 5.304360023501887,
      "grad_norm": 1.1018309593200684,
      "learning_rate": 0.00026726861925559296,
      "loss": 0.6146,
      "step": 501050
    },
    {
      "epoch": 5.30488934528189,
      "grad_norm": 1.0977401733398438,
      "learning_rate": 0.00026722253700725855,
      "loss": 0.635,
      "step": 501100
    },
    {
      "epoch": 5.305418667061893,
      "grad_norm": 0.9681386351585388,
      "learning_rate": 0.00026717645417095306,
      "loss": 0.6204,
      "step": 501150
    },
    {
      "epoch": 5.305947988841897,
      "grad_norm": 1.0940991640090942,
      "learning_rate": 0.00026713037074824967,
      "loss": 0.6209,
      "step": 501200
    },
    {
      "epoch": 5.3064773106219,
      "grad_norm": 1.151708722114563,
      "learning_rate": 0.0002670842867407218,
      "loss": 0.6101,
      "step": 501250
    },
    {
      "epoch": 5.307006632401904,
      "grad_norm": 1.043614387512207,
      "learning_rate": 0.00026703820214994255,
      "loss": 0.6203,
      "step": 501300
    },
    {
      "epoch": 5.3075359541819065,
      "grad_norm": 1.200992465019226,
      "learning_rate": 0.0002669921169774854,
      "loss": 0.6253,
      "step": 501350
    },
    {
      "epoch": 5.30806527596191,
      "grad_norm": 1.1100709438323975,
      "learning_rate": 0.00026694603122492353,
      "loss": 0.626,
      "step": 501400
    },
    {
      "epoch": 5.308594597741913,
      "grad_norm": 1.1520756483078003,
      "learning_rate": 0.0002668999448938304,
      "loss": 0.6146,
      "step": 501450
    },
    {
      "epoch": 5.309123919521917,
      "grad_norm": 1.0175459384918213,
      "learning_rate": 0.0002668538579857793,
      "loss": 0.6164,
      "step": 501500
    },
    {
      "epoch": 5.309123919521917,
      "eval_loss": 0.4053787887096405,
      "eval_runtime": 46.8838,
      "eval_samples_per_second": 3581.831,
      "eval_steps_per_second": 447.745,
      "step": 501500
    },
    {
      "epoch": 5.30965324130192,
      "grad_norm": 1.0143392086029053,
      "learning_rate": 0.00026680777050234377,
      "loss": 0.619,
      "step": 501550
    },
    {
      "epoch": 5.3101825630819235,
      "grad_norm": 1.1546530723571777,
      "learning_rate": 0.0002667616824450971,
      "loss": 0.6279,
      "step": 501600
    },
    {
      "epoch": 5.310711884861926,
      "grad_norm": 1.0695102214813232,
      "learning_rate": 0.00026671559381561267,
      "loss": 0.6271,
      "step": 501650
    },
    {
      "epoch": 5.311241206641929,
      "grad_norm": 1.12586510181427,
      "learning_rate": 0.0002666695046154641,
      "loss": 0.6128,
      "step": 501700
    },
    {
      "epoch": 5.311770528421933,
      "grad_norm": 1.061072587966919,
      "learning_rate": 0.0002666234148462246,
      "loss": 0.6221,
      "step": 501750
    },
    {
      "epoch": 5.312299850201936,
      "grad_norm": 1.0743056535720825,
      "learning_rate": 0.0002665773245094679,
      "loss": 0.6142,
      "step": 501800
    },
    {
      "epoch": 5.31282917198194,
      "grad_norm": 1.0399972200393677,
      "learning_rate": 0.0002665312336067675,
      "loss": 0.6066,
      "step": 501850
    },
    {
      "epoch": 5.3133584937619425,
      "grad_norm": 1.025617003440857,
      "learning_rate": 0.0002664851421396967,
      "loss": 0.6066,
      "step": 501900
    },
    {
      "epoch": 5.313887815541946,
      "grad_norm": 1.2175811529159546,
      "learning_rate": 0.00026643905010982925,
      "loss": 0.6077,
      "step": 501950
    },
    {
      "epoch": 5.314417137321949,
      "grad_norm": 1.1594979763031006,
      "learning_rate": 0.00026639295751873873,
      "loss": 0.6234,
      "step": 502000
    },
    {
      "epoch": 5.314417137321949,
      "eval_loss": 0.4064711332321167,
      "eval_runtime": 46.8225,
      "eval_samples_per_second": 3586.527,
      "eval_steps_per_second": 448.332,
      "step": 502000
    },
    {
      "epoch": 5.314946459101953,
      "grad_norm": 1.114870548248291,
      "learning_rate": 0.00026634686436799855,
      "loss": 0.6174,
      "step": 502050
    },
    {
      "epoch": 5.315475780881956,
      "grad_norm": 1.165524959564209,
      "learning_rate": 0.00026630077065918243,
      "loss": 0.6181,
      "step": 502100
    },
    {
      "epoch": 5.3160051026619595,
      "grad_norm": 1.048463225364685,
      "learning_rate": 0.0002662546763938641,
      "loss": 0.6074,
      "step": 502150
    },
    {
      "epoch": 5.316534424441962,
      "grad_norm": 0.9784950613975525,
      "learning_rate": 0.00026620858157361694,
      "loss": 0.6109,
      "step": 502200
    },
    {
      "epoch": 5.317063746221966,
      "grad_norm": 1.1279284954071045,
      "learning_rate": 0.00026616248620001484,
      "loss": 0.6112,
      "step": 502250
    },
    {
      "epoch": 5.317593068001969,
      "grad_norm": 1.1455963850021362,
      "learning_rate": 0.0002661163902746313,
      "loss": 0.6165,
      "step": 502300
    },
    {
      "epoch": 5.318122389781973,
      "grad_norm": 1.187847375869751,
      "learning_rate": 0.00026607121573393386,
      "loss": 0.6044,
      "step": 502350
    },
    {
      "epoch": 5.318651711561976,
      "grad_norm": 1.0800985097885132,
      "learning_rate": 0.00026602511872066603,
      "loss": 0.6209,
      "step": 502400
    },
    {
      "epoch": 5.319181033341979,
      "grad_norm": 1.1023526191711426,
      "learning_rate": 0.00026597902116030653,
      "loss": 0.6178,
      "step": 502450
    },
    {
      "epoch": 5.319710355121982,
      "grad_norm": 1.202886939048767,
      "learning_rate": 0.0002659329230544291,
      "loss": 0.6215,
      "step": 502500
    },
    {
      "epoch": 5.319710355121982,
      "eval_loss": 0.4039570391178131,
      "eval_runtime": 46.7424,
      "eval_samples_per_second": 3592.666,
      "eval_steps_per_second": 449.099,
      "step": 502500
    },
    {
      "epoch": 5.320239676901985,
      "grad_norm": 1.0001065731048584,
      "learning_rate": 0.0002658868244046075,
      "loss": 0.617,
      "step": 502550
    },
    {
      "epoch": 5.320768998681989,
      "grad_norm": 1.1784391403198242,
      "learning_rate": 0.0002658407252124156,
      "loss": 0.6135,
      "step": 502600
    },
    {
      "epoch": 5.321298320461992,
      "grad_norm": 1.0695945024490356,
      "learning_rate": 0.0002657946254794271,
      "loss": 0.624,
      "step": 502650
    },
    {
      "epoch": 5.3218276422419954,
      "grad_norm": 1.094244360923767,
      "learning_rate": 0.00026574852520721594,
      "loss": 0.6202,
      "step": 502700
    },
    {
      "epoch": 5.322356964021998,
      "grad_norm": 0.9869745969772339,
      "learning_rate": 0.00026570242439735584,
      "loss": 0.6233,
      "step": 502750
    },
    {
      "epoch": 5.322886285802002,
      "grad_norm": 1.0377901792526245,
      "learning_rate": 0.00026565632305142076,
      "loss": 0.6097,
      "step": 502800
    },
    {
      "epoch": 5.323415607582005,
      "grad_norm": 1.104103446006775,
      "learning_rate": 0.0002656102211709845,
      "loss": 0.6242,
      "step": 502850
    },
    {
      "epoch": 5.323944929362009,
      "grad_norm": 1.166366696357727,
      "learning_rate": 0.0002655641187576211,
      "loss": 0.6199,
      "step": 502900
    },
    {
      "epoch": 5.324474251142012,
      "grad_norm": 1.103853702545166,
      "learning_rate": 0.0002655180158129043,
      "loss": 0.6172,
      "step": 502950
    },
    {
      "epoch": 5.325003572922015,
      "grad_norm": 1.0843006372451782,
      "learning_rate": 0.0002654719123384082,
      "loss": 0.6047,
      "step": 503000
    },
    {
      "epoch": 5.325003572922015,
      "eval_loss": 0.40639016032218933,
      "eval_runtime": 47.1119,
      "eval_samples_per_second": 3564.49,
      "eval_steps_per_second": 445.577,
      "step": 503000
    },
    {
      "epoch": 5.325532894702018,
      "grad_norm": 1.154244303703308,
      "learning_rate": 0.0002654258083357066,
      "loss": 0.6185,
      "step": 503050
    },
    {
      "epoch": 5.326062216482022,
      "grad_norm": 1.0986707210540771,
      "learning_rate": 0.00026537970380637364,
      "loss": 0.6228,
      "step": 503100
    },
    {
      "epoch": 5.326591538262025,
      "grad_norm": 1.0699927806854248,
      "learning_rate": 0.0002653335987519832,
      "loss": 0.6134,
      "step": 503150
    },
    {
      "epoch": 5.327120860042029,
      "grad_norm": 1.145706295967102,
      "learning_rate": 0.0002652874931741093,
      "loss": 0.6131,
      "step": 503200
    },
    {
      "epoch": 5.327650181822031,
      "grad_norm": 1.0743992328643799,
      "learning_rate": 0.0002652413870743261,
      "loss": 0.6074,
      "step": 503250
    },
    {
      "epoch": 5.328179503602035,
      "grad_norm": 1.1382602453231812,
      "learning_rate": 0.0002651952804542074,
      "loss": 0.6095,
      "step": 503300
    },
    {
      "epoch": 5.328708825382038,
      "grad_norm": 1.150811791419983,
      "learning_rate": 0.0002651491733153275,
      "loss": 0.6193,
      "step": 503350
    },
    {
      "epoch": 5.329238147162041,
      "grad_norm": 1.103217363357544,
      "learning_rate": 0.00026510306565926035,
      "loss": 0.622,
      "step": 503400
    },
    {
      "epoch": 5.329767468942045,
      "grad_norm": 1.0471831560134888,
      "learning_rate": 0.00026505695748758006,
      "loss": 0.6172,
      "step": 503450
    },
    {
      "epoch": 5.3302967907220475,
      "grad_norm": 1.0594854354858398,
      "learning_rate": 0.0002650108488018608,
      "loss": 0.6086,
      "step": 503500
    },
    {
      "epoch": 5.3302967907220475,
      "eval_loss": 0.4040740132331848,
      "eval_runtime": 46.8087,
      "eval_samples_per_second": 3587.583,
      "eval_steps_per_second": 448.464,
      "step": 503500
    },
    {
      "epoch": 5.330826112502051,
      "grad_norm": 1.0309500694274902,
      "learning_rate": 0.00026496473960367666,
      "loss": 0.6204,
      "step": 503550
    },
    {
      "epoch": 5.331355434282054,
      "grad_norm": 1.1551508903503418,
      "learning_rate": 0.00026491862989460176,
      "loss": 0.621,
      "step": 503600
    },
    {
      "epoch": 5.331884756062058,
      "grad_norm": 1.1512107849121094,
      "learning_rate": 0.00026487251967621036,
      "loss": 0.6276,
      "step": 503650
    },
    {
      "epoch": 5.332414077842061,
      "grad_norm": 1.1397701501846313,
      "learning_rate": 0.00026482640895007656,
      "loss": 0.6187,
      "step": 503700
    },
    {
      "epoch": 5.3329433996220645,
      "grad_norm": 1.0537210702896118,
      "learning_rate": 0.0002647802977177746,
      "loss": 0.6133,
      "step": 503750
    },
    {
      "epoch": 5.333472721402067,
      "grad_norm": 1.07906973361969,
      "learning_rate": 0.0002647341859808787,
      "loss": 0.6125,
      "step": 503800
    },
    {
      "epoch": 5.334002043182071,
      "grad_norm": 1.0654830932617188,
      "learning_rate": 0.00026468807374096305,
      "loss": 0.6116,
      "step": 503850
    },
    {
      "epoch": 5.334531364962074,
      "grad_norm": 1.1200376749038696,
      "learning_rate": 0.00026464196099960203,
      "loss": 0.6169,
      "step": 503900
    },
    {
      "epoch": 5.335060686742078,
      "grad_norm": 1.030934453010559,
      "learning_rate": 0.0002645958477583697,
      "loss": 0.6276,
      "step": 503950
    },
    {
      "epoch": 5.335590008522081,
      "grad_norm": 1.0258538722991943,
      "learning_rate": 0.0002645497340188406,
      "loss": 0.616,
      "step": 504000
    },
    {
      "epoch": 5.335590008522081,
      "eval_loss": 0.40652263164520264,
      "eval_runtime": 47.6265,
      "eval_samples_per_second": 3525.98,
      "eval_steps_per_second": 440.763,
      "step": 504000
    },
    {
      "epoch": 5.336119330302084,
      "grad_norm": 1.1478394269943237,
      "learning_rate": 0.00026450361978258883,
      "loss": 0.6268,
      "step": 504050
    },
    {
      "epoch": 5.336648652082087,
      "grad_norm": 1.053239345550537,
      "learning_rate": 0.00026445750505118886,
      "loss": 0.6159,
      "step": 504100
    },
    {
      "epoch": 5.33717797386209,
      "grad_norm": 1.004489779472351,
      "learning_rate": 0.00026441138982621497,
      "loss": 0.6123,
      "step": 504150
    },
    {
      "epoch": 5.337707295642094,
      "grad_norm": 1.1144696474075317,
      "learning_rate": 0.0002643661964283924,
      "loss": 0.6056,
      "step": 504200
    },
    {
      "epoch": 5.338236617422097,
      "grad_norm": 1.0430271625518799,
      "learning_rate": 0.00026432008023078693,
      "loss": 0.6111,
      "step": 504250
    },
    {
      "epoch": 5.3387659392021005,
      "grad_norm": 1.1417489051818848,
      "learning_rate": 0.000264273963544299,
      "loss": 0.6111,
      "step": 504300
    },
    {
      "epoch": 5.339295260982103,
      "grad_norm": 1.0659422874450684,
      "learning_rate": 0.00026422784637050327,
      "loss": 0.6138,
      "step": 504350
    },
    {
      "epoch": 5.339824582762107,
      "grad_norm": 1.094436764717102,
      "learning_rate": 0.000264181728710974,
      "loss": 0.6151,
      "step": 504400
    },
    {
      "epoch": 5.34035390454211,
      "grad_norm": 0.9593459367752075,
      "learning_rate": 0.0002641356105672858,
      "loss": 0.6065,
      "step": 504450
    },
    {
      "epoch": 5.340883226322114,
      "grad_norm": 1.165010929107666,
      "learning_rate": 0.00026408949194101306,
      "loss": 0.624,
      "step": 504500
    },
    {
      "epoch": 5.340883226322114,
      "eval_loss": 0.40590694546699524,
      "eval_runtime": 47.7492,
      "eval_samples_per_second": 3516.919,
      "eval_steps_per_second": 439.631,
      "step": 504500
    },
    {
      "epoch": 5.341412548102117,
      "grad_norm": 1.1646958589553833,
      "learning_rate": 0.0002640433728337302,
      "loss": 0.6156,
      "step": 504550
    },
    {
      "epoch": 5.34194186988212,
      "grad_norm": 1.0076905488967896,
      "learning_rate": 0.0002639972532470117,
      "loss": 0.6219,
      "step": 504600
    },
    {
      "epoch": 5.342471191662123,
      "grad_norm": 1.2360663414001465,
      "learning_rate": 0.00026395113318243216,
      "loss": 0.6139,
      "step": 504650
    },
    {
      "epoch": 5.343000513442127,
      "grad_norm": 0.989827036857605,
      "learning_rate": 0.000263905012641566,
      "loss": 0.6186,
      "step": 504700
    },
    {
      "epoch": 5.34352983522213,
      "grad_norm": 1.0986384153366089,
      "learning_rate": 0.00026385889162598784,
      "loss": 0.6233,
      "step": 504750
    },
    {
      "epoch": 5.344059157002134,
      "grad_norm": 1.0456480979919434,
      "learning_rate": 0.00026381277013727225,
      "loss": 0.6305,
      "step": 504800
    },
    {
      "epoch": 5.3445884787821365,
      "grad_norm": 1.021986961364746,
      "learning_rate": 0.0002637666481769937,
      "loss": 0.6166,
      "step": 504850
    },
    {
      "epoch": 5.345117800562139,
      "grad_norm": 1.1775933504104614,
      "learning_rate": 0.0002637205257467268,
      "loss": 0.6119,
      "step": 504900
    },
    {
      "epoch": 5.345647122342143,
      "grad_norm": 1.1911216974258423,
      "learning_rate": 0.0002636744028480463,
      "loss": 0.6196,
      "step": 504950
    },
    {
      "epoch": 5.346176444122146,
      "grad_norm": 0.9160125255584717,
      "learning_rate": 0.0002636282794825266,
      "loss": 0.623,
      "step": 505000
    },
    {
      "epoch": 5.346176444122146,
      "eval_loss": 0.4066900908946991,
      "eval_runtime": 47.4092,
      "eval_samples_per_second": 3542.142,
      "eval_steps_per_second": 442.784,
      "step": 505000
    },
    {
      "epoch": 5.34670576590215,
      "grad_norm": 1.051315188407898,
      "learning_rate": 0.0002635821556517424,
      "loss": 0.6127,
      "step": 505050
    },
    {
      "epoch": 5.347235087682153,
      "grad_norm": 1.1394782066345215,
      "learning_rate": 0.0002635360313572685,
      "loss": 0.6092,
      "step": 505100
    },
    {
      "epoch": 5.347764409462156,
      "grad_norm": 1.1011288166046143,
      "learning_rate": 0.0002634899066006794,
      "loss": 0.6179,
      "step": 505150
    },
    {
      "epoch": 5.348293731242159,
      "grad_norm": 1.2082087993621826,
      "learning_rate": 0.0002634437813835498,
      "loss": 0.6122,
      "step": 505200
    },
    {
      "epoch": 5.348823053022163,
      "grad_norm": 1.2037166357040405,
      "learning_rate": 0.00026339765570745444,
      "loss": 0.6124,
      "step": 505250
    },
    {
      "epoch": 5.349352374802166,
      "grad_norm": 1.0532708168029785,
      "learning_rate": 0.00026335152957396806,
      "loss": 0.6174,
      "step": 505300
    },
    {
      "epoch": 5.34988169658217,
      "grad_norm": 1.1577171087265015,
      "learning_rate": 0.00026330540298466536,
      "loss": 0.6076,
      "step": 505350
    },
    {
      "epoch": 5.3504110183621725,
      "grad_norm": 1.0604342222213745,
      "learning_rate": 0.0002632592759411211,
      "loss": 0.6133,
      "step": 505400
    },
    {
      "epoch": 5.350940340142176,
      "grad_norm": 0.9129740595817566,
      "learning_rate": 0.00026321314844490994,
      "loss": 0.6154,
      "step": 505450
    },
    {
      "epoch": 5.351469661922179,
      "grad_norm": 0.9868960380554199,
      "learning_rate": 0.00026316702049760684,
      "loss": 0.6157,
      "step": 505500
    },
    {
      "epoch": 5.351469661922179,
      "eval_loss": 0.4060688018798828,
      "eval_runtime": 47.3061,
      "eval_samples_per_second": 3549.857,
      "eval_steps_per_second": 443.748,
      "step": 505500
    },
    {
      "epoch": 5.351998983702183,
      "grad_norm": 1.134214997291565,
      "learning_rate": 0.00026312089210078646,
      "loss": 0.6186,
      "step": 505550
    },
    {
      "epoch": 5.352528305482186,
      "grad_norm": 1.048987865447998,
      "learning_rate": 0.00026307476325602356,
      "loss": 0.6037,
      "step": 505600
    },
    {
      "epoch": 5.353057627262189,
      "grad_norm": 1.1399286985397339,
      "learning_rate": 0.0002630286339648931,
      "loss": 0.6056,
      "step": 505650
    },
    {
      "epoch": 5.353586949042192,
      "grad_norm": 1.095729112625122,
      "learning_rate": 0.0002629825042289699,
      "loss": 0.6156,
      "step": 505700
    },
    {
      "epoch": 5.354116270822195,
      "grad_norm": 1.0943764448165894,
      "learning_rate": 0.0002629363740498287,
      "loss": 0.6119,
      "step": 505750
    },
    {
      "epoch": 5.354645592602199,
      "grad_norm": 1.0973572731018066,
      "learning_rate": 0.0002628902434290445,
      "loss": 0.6163,
      "step": 505800
    },
    {
      "epoch": 5.355174914382202,
      "grad_norm": 1.0591588020324707,
      "learning_rate": 0.00026284411236819204,
      "loss": 0.6128,
      "step": 505850
    },
    {
      "epoch": 5.355704236162206,
      "grad_norm": 1.0736480951309204,
      "learning_rate": 0.0002627979808688463,
      "loss": 0.618,
      "step": 505900
    },
    {
      "epoch": 5.3562335579422085,
      "grad_norm": 1.063198208808899,
      "learning_rate": 0.00026275184893258225,
      "loss": 0.6095,
      "step": 505950
    },
    {
      "epoch": 5.356762879722212,
      "grad_norm": 1.1666061878204346,
      "learning_rate": 0.0002627057165609747,
      "loss": 0.6133,
      "step": 506000
    },
    {
      "epoch": 5.356762879722212,
      "eval_loss": 0.4033701717853546,
      "eval_runtime": 47.1049,
      "eval_samples_per_second": 3565.023,
      "eval_steps_per_second": 445.644,
      "step": 506000
    },
    {
      "epoch": 5.357292201502215,
      "grad_norm": 1.1364184617996216,
      "learning_rate": 0.0002626595837555986,
      "loss": 0.6072,
      "step": 506050
    },
    {
      "epoch": 5.357821523282219,
      "grad_norm": 1.202555775642395,
      "learning_rate": 0.00026261345051802905,
      "loss": 0.6128,
      "step": 506100
    },
    {
      "epoch": 5.358350845062222,
      "grad_norm": 1.0793408155441284,
      "learning_rate": 0.00026256731684984086,
      "loss": 0.6156,
      "step": 506150
    },
    {
      "epoch": 5.3588801668422255,
      "grad_norm": 1.0367176532745361,
      "learning_rate": 0.0002625211827526091,
      "loss": 0.6077,
      "step": 506200
    },
    {
      "epoch": 5.359409488622228,
      "grad_norm": 1.1707123517990112,
      "learning_rate": 0.0002624750482279088,
      "loss": 0.6111,
      "step": 506250
    },
    {
      "epoch": 5.359938810402232,
      "grad_norm": 1.0504945516586304,
      "learning_rate": 0.0002624289132773149,
      "loss": 0.615,
      "step": 506300
    },
    {
      "epoch": 5.360468132182235,
      "grad_norm": 1.0860140323638916,
      "learning_rate": 0.00026238277790240246,
      "loss": 0.6158,
      "step": 506350
    },
    {
      "epoch": 5.360997453962238,
      "grad_norm": 1.0950593948364258,
      "learning_rate": 0.0002623366421047465,
      "loss": 0.6149,
      "step": 506400
    },
    {
      "epoch": 5.361526775742242,
      "grad_norm": 1.1221401691436768,
      "learning_rate": 0.0002622905058859221,
      "loss": 0.6163,
      "step": 506450
    },
    {
      "epoch": 5.362056097522244,
      "grad_norm": 1.0841174125671387,
      "learning_rate": 0.0002622443692475044,
      "loss": 0.6112,
      "step": 506500
    },
    {
      "epoch": 5.362056097522244,
      "eval_loss": 0.40430933237075806,
      "eval_runtime": 46.9378,
      "eval_samples_per_second": 3577.712,
      "eval_steps_per_second": 447.23,
      "step": 506500
    },
    {
      "epoch": 5.362585419302248,
      "grad_norm": 1.1535255908966064,
      "learning_rate": 0.00026219823219106835,
      "loss": 0.6251,
      "step": 506550
    },
    {
      "epoch": 5.363114741082251,
      "grad_norm": 0.9853124618530273,
      "learning_rate": 0.0002621520947181891,
      "loss": 0.6157,
      "step": 506600
    },
    {
      "epoch": 5.363644062862255,
      "grad_norm": 1.1739741563796997,
      "learning_rate": 0.0002621059568304419,
      "loss": 0.6161,
      "step": 506650
    },
    {
      "epoch": 5.364173384642258,
      "grad_norm": 1.141249418258667,
      "learning_rate": 0.00026205981852940174,
      "loss": 0.6207,
      "step": 506700
    },
    {
      "epoch": 5.364702706422261,
      "grad_norm": 1.155783772468567,
      "learning_rate": 0.00026201367981664375,
      "loss": 0.6111,
      "step": 506750
    },
    {
      "epoch": 5.365232028202264,
      "grad_norm": 1.0240877866744995,
      "learning_rate": 0.0002619675406937432,
      "loss": 0.622,
      "step": 506800
    },
    {
      "epoch": 5.365761349982268,
      "grad_norm": 1.0664854049682617,
      "learning_rate": 0.0002619214011622751,
      "loss": 0.6141,
      "step": 506850
    },
    {
      "epoch": 5.366290671762271,
      "grad_norm": 1.1497443914413452,
      "learning_rate": 0.00026187526122381483,
      "loss": 0.6094,
      "step": 506900
    },
    {
      "epoch": 5.366819993542275,
      "grad_norm": 1.0599689483642578,
      "learning_rate": 0.00026182912087993745,
      "loss": 0.6048,
      "step": 506950
    },
    {
      "epoch": 5.3673493153222775,
      "grad_norm": 1.1336264610290527,
      "learning_rate": 0.00026178298013221823,
      "loss": 0.6121,
      "step": 507000
    },
    {
      "epoch": 5.3673493153222775,
      "eval_loss": 0.40539324283599854,
      "eval_runtime": 46.9432,
      "eval_samples_per_second": 3577.299,
      "eval_steps_per_second": 447.178,
      "step": 507000
    },
    {
      "epoch": 5.367878637102281,
      "grad_norm": 1.0766226053237915,
      "learning_rate": 0.0002617368389822324,
      "loss": 0.6249,
      "step": 507050
    },
    {
      "epoch": 5.368407958882284,
      "grad_norm": 1.1565780639648438,
      "learning_rate": 0.00026169069743155524,
      "loss": 0.6224,
      "step": 507100
    },
    {
      "epoch": 5.368937280662287,
      "grad_norm": 1.1151628494262695,
      "learning_rate": 0.0002616445554817619,
      "loss": 0.6118,
      "step": 507150
    },
    {
      "epoch": 5.369466602442291,
      "grad_norm": 1.029247760772705,
      "learning_rate": 0.0002615984131344277,
      "loss": 0.6209,
      "step": 507200
    },
    {
      "epoch": 5.369995924222294,
      "grad_norm": 1.1048506498336792,
      "learning_rate": 0.00026155227039112796,
      "loss": 0.6197,
      "step": 507250
    },
    {
      "epoch": 5.370525246002297,
      "grad_norm": 1.0252773761749268,
      "learning_rate": 0.00026150612725343793,
      "loss": 0.6136,
      "step": 507300
    },
    {
      "epoch": 5.3710545677823,
      "grad_norm": 0.976628303527832,
      "learning_rate": 0.00026145998372293294,
      "loss": 0.6152,
      "step": 507350
    },
    {
      "epoch": 5.371583889562304,
      "grad_norm": 1.0310919284820557,
      "learning_rate": 0.0002614138398011883,
      "loss": 0.6207,
      "step": 507400
    },
    {
      "epoch": 5.372113211342307,
      "grad_norm": 1.1326267719268799,
      "learning_rate": 0.00026136769548977935,
      "loss": 0.6178,
      "step": 507450
    },
    {
      "epoch": 5.372642533122311,
      "grad_norm": 1.2755990028381348,
      "learning_rate": 0.00026132155079028145,
      "loss": 0.6241,
      "step": 507500
    },
    {
      "epoch": 5.372642533122311,
      "eval_loss": 0.40320268273353577,
      "eval_runtime": 46.6929,
      "eval_samples_per_second": 3596.477,
      "eval_steps_per_second": 449.576,
      "step": 507500
    },
    {
      "epoch": 5.3731718549023135,
      "grad_norm": 1.2098098993301392,
      "learning_rate": 0.00026127540570427,
      "loss": 0.6166,
      "step": 507550
    },
    {
      "epoch": 5.373701176682317,
      "grad_norm": 1.1987676620483398,
      "learning_rate": 0.0002612292602333203,
      "loss": 0.6201,
      "step": 507600
    },
    {
      "epoch": 5.37423049846232,
      "grad_norm": 1.1716150045394897,
      "learning_rate": 0.0002611831143790078,
      "loss": 0.6233,
      "step": 507650
    },
    {
      "epoch": 5.374759820242324,
      "grad_norm": 1.1342183351516724,
      "learning_rate": 0.0002611369681429077,
      "loss": 0.6191,
      "step": 507700
    },
    {
      "epoch": 5.375289142022327,
      "grad_norm": 1.1590399742126465,
      "learning_rate": 0.0002610908215265958,
      "loss": 0.604,
      "step": 507750
    },
    {
      "epoch": 5.3758184638023305,
      "grad_norm": 1.2440625429153442,
      "learning_rate": 0.00026104467453164727,
      "loss": 0.6055,
      "step": 507800
    },
    {
      "epoch": 5.376347785582333,
      "grad_norm": 1.167033314704895,
      "learning_rate": 0.0002609985271596376,
      "loss": 0.6205,
      "step": 507850
    },
    {
      "epoch": 5.376877107362336,
      "grad_norm": 1.1166377067565918,
      "learning_rate": 0.0002609523794121422,
      "loss": 0.6113,
      "step": 507900
    },
    {
      "epoch": 5.37740642914234,
      "grad_norm": 1.133750319480896,
      "learning_rate": 0.00026090623129073666,
      "loss": 0.6121,
      "step": 507950
    },
    {
      "epoch": 5.377935750922343,
      "grad_norm": 1.0128836631774902,
      "learning_rate": 0.0002608600827969963,
      "loss": 0.6153,
      "step": 508000
    },
    {
      "epoch": 5.377935750922343,
      "eval_loss": 0.4045912027359009,
      "eval_runtime": 46.9737,
      "eval_samples_per_second": 3574.977,
      "eval_steps_per_second": 446.888,
      "step": 508000
    },
    {
      "epoch": 5.378465072702347,
      "grad_norm": 1.0489474534988403,
      "learning_rate": 0.00026081393393249675,
      "loss": 0.6157,
      "step": 508050
    },
    {
      "epoch": 5.3789943944823495,
      "grad_norm": 1.1202348470687866,
      "learning_rate": 0.00026076778469881343,
      "loss": 0.6152,
      "step": 508100
    },
    {
      "epoch": 5.379523716262353,
      "grad_norm": 1.1017401218414307,
      "learning_rate": 0.00026072163509752194,
      "loss": 0.612,
      "step": 508150
    },
    {
      "epoch": 5.380053038042356,
      "grad_norm": 1.0389134883880615,
      "learning_rate": 0.00026067640813312115,
      "loss": 0.6132,
      "step": 508200
    },
    {
      "epoch": 5.38058235982236,
      "grad_norm": 1.0996242761611938,
      "learning_rate": 0.0002606302578086135,
      "loss": 0.6147,
      "step": 508250
    },
    {
      "epoch": 5.381111681602363,
      "grad_norm": 1.0653538703918457,
      "learning_rate": 0.00026058410712119273,
      "loss": 0.6148,
      "step": 508300
    },
    {
      "epoch": 5.3816410033823665,
      "grad_norm": 1.156246542930603,
      "learning_rate": 0.00026053795607243447,
      "loss": 0.6135,
      "step": 508350
    },
    {
      "epoch": 5.382170325162369,
      "grad_norm": 1.1476349830627441,
      "learning_rate": 0.0002604918046639142,
      "loss": 0.6102,
      "step": 508400
    },
    {
      "epoch": 5.382699646942373,
      "grad_norm": 1.0505731105804443,
      "learning_rate": 0.0002604456528972076,
      "loss": 0.6092,
      "step": 508450
    },
    {
      "epoch": 5.383228968722376,
      "grad_norm": 1.0778855085372925,
      "learning_rate": 0.00026039950077389026,
      "loss": 0.6043,
      "step": 508500
    },
    {
      "epoch": 5.383228968722376,
      "eval_loss": 0.40314868092536926,
      "eval_runtime": 47.7141,
      "eval_samples_per_second": 3519.504,
      "eval_steps_per_second": 439.954,
      "step": 508500
    },
    {
      "epoch": 5.38375829050238,
      "grad_norm": 1.0585018396377563,
      "learning_rate": 0.0002603533482955377,
      "loss": 0.6171,
      "step": 508550
    },
    {
      "epoch": 5.384287612282383,
      "grad_norm": 1.1346049308776855,
      "learning_rate": 0.00026030719546372565,
      "loss": 0.6188,
      "step": 508600
    },
    {
      "epoch": 5.3848169340623855,
      "grad_norm": 1.1711736917495728,
      "learning_rate": 0.00026026104228002976,
      "loss": 0.6212,
      "step": 508650
    },
    {
      "epoch": 5.385346255842389,
      "grad_norm": 1.262665033340454,
      "learning_rate": 0.00026021488874602565,
      "loss": 0.6096,
      "step": 508700
    },
    {
      "epoch": 5.385875577622392,
      "grad_norm": 1.1596648693084717,
      "learning_rate": 0.000260168734863289,
      "loss": 0.6134,
      "step": 508750
    },
    {
      "epoch": 5.386404899402396,
      "grad_norm": 0.9659271836280823,
      "learning_rate": 0.0002601225806333954,
      "loss": 0.6128,
      "step": 508800
    },
    {
      "epoch": 5.386934221182399,
      "grad_norm": 1.0181125402450562,
      "learning_rate": 0.0002600764260579207,
      "loss": 0.6069,
      "step": 508850
    },
    {
      "epoch": 5.3874635429624025,
      "grad_norm": 1.0719175338745117,
      "learning_rate": 0.0002600302711384405,
      "loss": 0.6133,
      "step": 508900
    },
    {
      "epoch": 5.387992864742405,
      "grad_norm": 1.1393083333969116,
      "learning_rate": 0.0002599841158765304,
      "loss": 0.611,
      "step": 508950
    },
    {
      "epoch": 5.388522186522409,
      "grad_norm": 1.0323328971862793,
      "learning_rate": 0.00025993796027376634,
      "loss": 0.6109,
      "step": 509000
    },
    {
      "epoch": 5.388522186522409,
      "eval_loss": 0.40404200553894043,
      "eval_runtime": 46.8961,
      "eval_samples_per_second": 3580.892,
      "eval_steps_per_second": 447.628,
      "step": 509000
    },
    {
      "epoch": 5.389051508302412,
      "grad_norm": 1.0776699781417847,
      "learning_rate": 0.00025989180433172394,
      "loss": 0.6183,
      "step": 509050
    },
    {
      "epoch": 5.389580830082416,
      "grad_norm": 1.172577977180481,
      "learning_rate": 0.00025984564805197897,
      "loss": 0.607,
      "step": 509100
    },
    {
      "epoch": 5.390110151862419,
      "grad_norm": 1.1562469005584717,
      "learning_rate": 0.0002597994914361072,
      "loss": 0.6054,
      "step": 509150
    },
    {
      "epoch": 5.390639473642422,
      "grad_norm": 1.1148875951766968,
      "learning_rate": 0.00025975333448568437,
      "loss": 0.6133,
      "step": 509200
    },
    {
      "epoch": 5.391168795422425,
      "grad_norm": 0.991096019744873,
      "learning_rate": 0.0002597071772022863,
      "loss": 0.6156,
      "step": 509250
    },
    {
      "epoch": 5.391698117202429,
      "grad_norm": 1.128167748451233,
      "learning_rate": 0.00025966101958748876,
      "loss": 0.6174,
      "step": 509300
    },
    {
      "epoch": 5.392227438982432,
      "grad_norm": 1.2909480333328247,
      "learning_rate": 0.0002596148616428676,
      "loss": 0.6203,
      "step": 509350
    },
    {
      "epoch": 5.392756760762435,
      "grad_norm": 1.0395303964614868,
      "learning_rate": 0.0002595687033699985,
      "loss": 0.6063,
      "step": 509400
    },
    {
      "epoch": 5.3932860825424385,
      "grad_norm": 0.9884204268455505,
      "learning_rate": 0.00025952254477045746,
      "loss": 0.6153,
      "step": 509450
    },
    {
      "epoch": 5.393815404322441,
      "grad_norm": 1.1343047618865967,
      "learning_rate": 0.00025947638584582016,
      "loss": 0.6116,
      "step": 509500
    },
    {
      "epoch": 5.393815404322441,
      "eval_loss": 0.40257692337036133,
      "eval_runtime": 46.8177,
      "eval_samples_per_second": 3586.893,
      "eval_steps_per_second": 448.378,
      "step": 509500
    },
    {
      "epoch": 5.394344726102445,
      "grad_norm": 1.1365180015563965,
      "learning_rate": 0.0002594302265976625,
      "loss": 0.6039,
      "step": 509550
    },
    {
      "epoch": 5.394874047882448,
      "grad_norm": 1.0691946744918823,
      "learning_rate": 0.00025938406702756046,
      "loss": 0.6134,
      "step": 509600
    },
    {
      "epoch": 5.395403369662452,
      "grad_norm": 1.0173511505126953,
      "learning_rate": 0.0002593379071370898,
      "loss": 0.6047,
      "step": 509650
    },
    {
      "epoch": 5.395932691442455,
      "grad_norm": 1.2337874174118042,
      "learning_rate": 0.0002592917469278264,
      "loss": 0.6192,
      "step": 509700
    },
    {
      "epoch": 5.396462013222458,
      "grad_norm": 1.1162889003753662,
      "learning_rate": 0.00025924558640134606,
      "loss": 0.6142,
      "step": 509750
    },
    {
      "epoch": 5.396991335002461,
      "grad_norm": 1.1200743913650513,
      "learning_rate": 0.0002591994255592249,
      "loss": 0.6108,
      "step": 509800
    },
    {
      "epoch": 5.397520656782465,
      "grad_norm": 1.0548604726791382,
      "learning_rate": 0.00025915326440303867,
      "loss": 0.6119,
      "step": 509850
    },
    {
      "epoch": 5.398049978562468,
      "grad_norm": 0.9871694445610046,
      "learning_rate": 0.00025910710293436336,
      "loss": 0.6203,
      "step": 509900
    },
    {
      "epoch": 5.398579300342472,
      "grad_norm": 1.1418780088424683,
      "learning_rate": 0.00025906094115477497,
      "loss": 0.6176,
      "step": 509950
    },
    {
      "epoch": 5.399108622122474,
      "grad_norm": 1.0692315101623535,
      "learning_rate": 0.0002590147790658493,
      "loss": 0.6215,
      "step": 510000
    },
    {
      "epoch": 5.399108622122474,
      "eval_loss": 0.40229082107543945,
      "eval_runtime": 46.8157,
      "eval_samples_per_second": 3587.043,
      "eval_steps_per_second": 448.396,
      "step": 510000
    },
    {
      "epoch": 5.399637943902478,
      "grad_norm": 1.0869356393814087,
      "learning_rate": 0.0002589686166691624,
      "loss": 0.6211,
      "step": 510050
    },
    {
      "epoch": 5.400167265682481,
      "grad_norm": 1.1091184616088867,
      "learning_rate": 0.0002589224539662902,
      "loss": 0.6052,
      "step": 510100
    },
    {
      "epoch": 5.400696587462484,
      "grad_norm": 1.0331429243087769,
      "learning_rate": 0.0002588762909588087,
      "loss": 0.6193,
      "step": 510150
    },
    {
      "epoch": 5.401225909242488,
      "grad_norm": 1.0159423351287842,
      "learning_rate": 0.0002588301276482939,
      "loss": 0.6094,
      "step": 510200
    },
    {
      "epoch": 5.4017552310224906,
      "grad_norm": 1.0978132486343384,
      "learning_rate": 0.00025878488731150527,
      "loss": 0.6219,
      "step": 510250
    },
    {
      "epoch": 5.402284552802494,
      "grad_norm": 1.0916099548339844,
      "learning_rate": 0.000258738723405634,
      "loss": 0.6186,
      "step": 510300
    },
    {
      "epoch": 5.402813874582497,
      "grad_norm": 1.1034183502197266,
      "learning_rate": 0.0002586925592014259,
      "loss": 0.6135,
      "step": 510350
    },
    {
      "epoch": 5.403343196362501,
      "grad_norm": 0.9549893140792847,
      "learning_rate": 0.00025864639470045707,
      "loss": 0.6055,
      "step": 510400
    },
    {
      "epoch": 5.403872518142504,
      "grad_norm": 1.0935145616531372,
      "learning_rate": 0.0002586002299043035,
      "loss": 0.6156,
      "step": 510450
    },
    {
      "epoch": 5.4044018399225076,
      "grad_norm": 1.0846551656723022,
      "learning_rate": 0.0002585540648145412,
      "loss": 0.6207,
      "step": 510500
    },
    {
      "epoch": 5.4044018399225076,
      "eval_loss": 0.40200740098953247,
      "eval_runtime": 47.1772,
      "eval_samples_per_second": 3559.56,
      "eval_steps_per_second": 444.961,
      "step": 510500
    },
    {
      "epoch": 5.40493116170251,
      "grad_norm": 1.123313307762146,
      "learning_rate": 0.00025850789943274627,
      "loss": 0.6049,
      "step": 510550
    },
    {
      "epoch": 5.405460483482514,
      "grad_norm": 1.0248395204544067,
      "learning_rate": 0.0002584617337604948,
      "loss": 0.6184,
      "step": 510600
    },
    {
      "epoch": 5.405989805262517,
      "grad_norm": 1.1334266662597656,
      "learning_rate": 0.00025841556779936277,
      "loss": 0.6143,
      "step": 510650
    },
    {
      "epoch": 5.406519127042521,
      "grad_norm": 1.0840123891830444,
      "learning_rate": 0.0002583694015509264,
      "loss": 0.6217,
      "step": 510700
    },
    {
      "epoch": 5.407048448822524,
      "grad_norm": 1.209265112876892,
      "learning_rate": 0.0002583232350167618,
      "loss": 0.6213,
      "step": 510750
    },
    {
      "epoch": 5.407577770602527,
      "grad_norm": 1.119466781616211,
      "learning_rate": 0.0002582770681984449,
      "loss": 0.6028,
      "step": 510800
    },
    {
      "epoch": 5.40810709238253,
      "grad_norm": 1.18252432346344,
      "learning_rate": 0.0002582309010975519,
      "loss": 0.6133,
      "step": 510850
    },
    {
      "epoch": 5.408636414162533,
      "grad_norm": 1.2020257711410522,
      "learning_rate": 0.00025818473371565904,
      "loss": 0.6111,
      "step": 510900
    },
    {
      "epoch": 5.409165735942537,
      "grad_norm": 1.0593358278274536,
      "learning_rate": 0.00025813856605434233,
      "loss": 0.6091,
      "step": 510950
    },
    {
      "epoch": 5.40969505772254,
      "grad_norm": 1.0439029932022095,
      "learning_rate": 0.000258092398115178,
      "loss": 0.6041,
      "step": 511000
    },
    {
      "epoch": 5.40969505772254,
      "eval_loss": 0.4013238847255707,
      "eval_runtime": 47.1229,
      "eval_samples_per_second": 3563.663,
      "eval_steps_per_second": 445.474,
      "step": 511000
    },
    {
      "epoch": 5.4102243795025435,
      "grad_norm": 1.1396799087524414,
      "learning_rate": 0.00025804622989974215,
      "loss": 0.6219,
      "step": 511050
    },
    {
      "epoch": 5.410753701282546,
      "grad_norm": 1.2188199758529663,
      "learning_rate": 0.0002580000614096109,
      "loss": 0.6084,
      "step": 511100
    },
    {
      "epoch": 5.41128302306255,
      "grad_norm": 1.1554769277572632,
      "learning_rate": 0.0002579538926463606,
      "loss": 0.6247,
      "step": 511150
    },
    {
      "epoch": 5.411812344842553,
      "grad_norm": 1.1370896100997925,
      "learning_rate": 0.0002579077236115672,
      "loss": 0.6153,
      "step": 511200
    },
    {
      "epoch": 5.412341666622557,
      "grad_norm": 1.0990487337112427,
      "learning_rate": 0.00025786155430680707,
      "loss": 0.5995,
      "step": 511250
    },
    {
      "epoch": 5.41287098840256,
      "grad_norm": 1.1151137351989746,
      "learning_rate": 0.00025781538473365633,
      "loss": 0.5992,
      "step": 511300
    },
    {
      "epoch": 5.413400310182563,
      "grad_norm": 1.035015344619751,
      "learning_rate": 0.00025776921489369125,
      "loss": 0.6208,
      "step": 511350
    },
    {
      "epoch": 5.413929631962566,
      "grad_norm": 1.1639598608016968,
      "learning_rate": 0.0002577230447884881,
      "loss": 0.6114,
      "step": 511400
    },
    {
      "epoch": 5.41445895374257,
      "grad_norm": 1.0375577211380005,
      "learning_rate": 0.00025767687441962295,
      "loss": 0.6155,
      "step": 511450
    },
    {
      "epoch": 5.414988275522573,
      "grad_norm": 1.0868675708770752,
      "learning_rate": 0.00025763070378867215,
      "loss": 0.6154,
      "step": 511500
    },
    {
      "epoch": 5.414988275522573,
      "eval_loss": 0.4015640914440155,
      "eval_runtime": 47.2487,
      "eval_samples_per_second": 3554.173,
      "eval_steps_per_second": 444.287,
      "step": 511500
    },
    {
      "epoch": 5.415517597302577,
      "grad_norm": 1.1250914335250854,
      "learning_rate": 0.0002575845328972119,
      "loss": 0.6242,
      "step": 511550
    },
    {
      "epoch": 5.4160469190825795,
      "grad_norm": 1.0698364973068237,
      "learning_rate": 0.0002575383617468185,
      "loss": 0.619,
      "step": 511600
    },
    {
      "epoch": 5.416576240862582,
      "grad_norm": 1.1497633457183838,
      "learning_rate": 0.0002574921903390682,
      "loss": 0.6163,
      "step": 511650
    },
    {
      "epoch": 5.417105562642586,
      "grad_norm": 0.999537467956543,
      "learning_rate": 0.0002574460186755372,
      "loss": 0.6049,
      "step": 511700
    },
    {
      "epoch": 5.417634884422589,
      "grad_norm": 1.1306272745132446,
      "learning_rate": 0.0002573998467578019,
      "loss": 0.6267,
      "step": 511750
    },
    {
      "epoch": 5.418164206202593,
      "grad_norm": 1.1423957347869873,
      "learning_rate": 0.0002573536745874386,
      "loss": 0.603,
      "step": 511800
    },
    {
      "epoch": 5.418693527982596,
      "grad_norm": 1.109036922454834,
      "learning_rate": 0.00025730750216602347,
      "loss": 0.6052,
      "step": 511850
    },
    {
      "epoch": 5.419222849762599,
      "grad_norm": 1.0762648582458496,
      "learning_rate": 0.00025726132949513295,
      "loss": 0.6103,
      "step": 511900
    },
    {
      "epoch": 5.419752171542602,
      "grad_norm": 1.0706673860549927,
      "learning_rate": 0.00025721515657634324,
      "loss": 0.6121,
      "step": 511950
    },
    {
      "epoch": 5.420281493322606,
      "grad_norm": 1.174128532409668,
      "learning_rate": 0.00025716898341123076,
      "loss": 0.6147,
      "step": 512000
    },
    {
      "epoch": 5.420281493322606,
      "eval_loss": 0.40093156695365906,
      "eval_runtime": 46.8524,
      "eval_samples_per_second": 3584.237,
      "eval_steps_per_second": 448.046,
      "step": 512000
    },
    {
      "epoch": 5.420810815102609,
      "grad_norm": 1.0527807474136353,
      "learning_rate": 0.0002571228100013718,
      "loss": 0.6087,
      "step": 512050
    },
    {
      "epoch": 5.421340136882613,
      "grad_norm": 1.1813243627548218,
      "learning_rate": 0.00025707663634834274,
      "loss": 0.6095,
      "step": 512100
    },
    {
      "epoch": 5.4218694586626155,
      "grad_norm": 1.082651972770691,
      "learning_rate": 0.0002570304624537199,
      "loss": 0.6091,
      "step": 512150
    },
    {
      "epoch": 5.422398780442619,
      "grad_norm": 1.0473005771636963,
      "learning_rate": 0.0002569842883190797,
      "loss": 0.6115,
      "step": 512200
    },
    {
      "epoch": 5.422928102222622,
      "grad_norm": 1.1563700437545776,
      "learning_rate": 0.00025693903743578654,
      "loss": 0.6119,
      "step": 512250
    },
    {
      "epoch": 5.423457424002626,
      "grad_norm": 1.193583369255066,
      "learning_rate": 0.00025689286283056247,
      "loss": 0.6115,
      "step": 512300
    },
    {
      "epoch": 5.423986745782629,
      "grad_norm": 1.0747947692871094,
      "learning_rate": 0.0002568466879900186,
      "loss": 0.6174,
      "step": 512350
    },
    {
      "epoch": 5.424516067562632,
      "grad_norm": 1.0480859279632568,
      "learning_rate": 0.0002568005129157312,
      "loss": 0.6056,
      "step": 512400
    },
    {
      "epoch": 5.425045389342635,
      "grad_norm": 1.102858066558838,
      "learning_rate": 0.00025675433760927684,
      "loss": 0.6003,
      "step": 512450
    },
    {
      "epoch": 5.425574711122638,
      "grad_norm": 1.0780069828033447,
      "learning_rate": 0.0002567081620722319,
      "loss": 0.6276,
      "step": 512500
    },
    {
      "epoch": 5.425574711122638,
      "eval_loss": 0.4009450674057007,
      "eval_runtime": 46.816,
      "eval_samples_per_second": 3587.022,
      "eval_steps_per_second": 448.394,
      "step": 512500
    },
    {
      "epoch": 5.426104032902642,
      "grad_norm": 1.0851539373397827,
      "learning_rate": 0.0002566619863061728,
      "loss": 0.6232,
      "step": 512550
    },
    {
      "epoch": 5.426633354682645,
      "grad_norm": 1.2786235809326172,
      "learning_rate": 0.0002566158103126758,
      "loss": 0.6174,
      "step": 512600
    },
    {
      "epoch": 5.427162676462649,
      "grad_norm": 1.1713626384735107,
      "learning_rate": 0.00025656963409331757,
      "loss": 0.6138,
      "step": 512650
    },
    {
      "epoch": 5.4276919982426515,
      "grad_norm": 1.1197391748428345,
      "learning_rate": 0.00025652345764967443,
      "loss": 0.6118,
      "step": 512700
    },
    {
      "epoch": 5.428221320022655,
      "grad_norm": 1.1344621181488037,
      "learning_rate": 0.00025647728098332284,
      "loss": 0.624,
      "step": 512750
    },
    {
      "epoch": 5.428750641802658,
      "grad_norm": 1.1133207082748413,
      "learning_rate": 0.00025643110409583926,
      "loss": 0.61,
      "step": 512800
    },
    {
      "epoch": 5.429279963582662,
      "grad_norm": 1.2292413711547852,
      "learning_rate": 0.00025638492698880014,
      "loss": 0.6165,
      "step": 512850
    },
    {
      "epoch": 5.429809285362665,
      "grad_norm": 1.0280864238739014,
      "learning_rate": 0.0002563387496637819,
      "loss": 0.6151,
      "step": 512900
    },
    {
      "epoch": 5.4303386071426685,
      "grad_norm": 1.1794195175170898,
      "learning_rate": 0.00025629257212236113,
      "loss": 0.6141,
      "step": 512950
    },
    {
      "epoch": 5.430867928922671,
      "grad_norm": 1.283844232559204,
      "learning_rate": 0.0002562463943661142,
      "loss": 0.6101,
      "step": 513000
    },
    {
      "epoch": 5.430867928922671,
      "eval_loss": 0.4006447494029999,
      "eval_runtime": 47.4257,
      "eval_samples_per_second": 3540.909,
      "eval_steps_per_second": 442.629,
      "step": 513000
    },
    {
      "epoch": 5.431397250702675,
      "grad_norm": 1.0745985507965088,
      "learning_rate": 0.00025620021639661774,
      "loss": 0.6171,
      "step": 513050
    },
    {
      "epoch": 5.431926572482678,
      "grad_norm": 0.9537816643714905,
      "learning_rate": 0.0002561540382154481,
      "loss": 0.6172,
      "step": 513100
    },
    {
      "epoch": 5.432455894262681,
      "grad_norm": 1.3642501831054688,
      "learning_rate": 0.00025610785982418184,
      "loss": 0.6167,
      "step": 513150
    },
    {
      "epoch": 5.432985216042685,
      "grad_norm": 1.1509853601455688,
      "learning_rate": 0.00025606168122439555,
      "loss": 0.5995,
      "step": 513200
    },
    {
      "epoch": 5.4335145378226875,
      "grad_norm": 1.123921513557434,
      "learning_rate": 0.0002560155024176656,
      "loss": 0.6112,
      "step": 513250
    },
    {
      "epoch": 5.434043859602691,
      "grad_norm": 1.014345645904541,
      "learning_rate": 0.0002559693234055686,
      "loss": 0.6116,
      "step": 513300
    },
    {
      "epoch": 5.434573181382694,
      "grad_norm": 1.1787394285202026,
      "learning_rate": 0.00025592314418968116,
      "loss": 0.6082,
      "step": 513350
    },
    {
      "epoch": 5.435102503162698,
      "grad_norm": 1.0970454216003418,
      "learning_rate": 0.0002558769647715797,
      "loss": 0.6214,
      "step": 513400
    },
    {
      "epoch": 5.435631824942701,
      "grad_norm": 1.0648247003555298,
      "learning_rate": 0.00025583078515284093,
      "loss": 0.6091,
      "step": 513450
    },
    {
      "epoch": 5.4361611467227045,
      "grad_norm": 1.1962666511535645,
      "learning_rate": 0.0002557846053350412,
      "loss": 0.6065,
      "step": 513500
    },
    {
      "epoch": 5.4361611467227045,
      "eval_loss": 0.4014713168144226,
      "eval_runtime": 46.7418,
      "eval_samples_per_second": 3592.719,
      "eval_steps_per_second": 449.106,
      "step": 513500
    },
    {
      "epoch": 5.436690468502707,
      "grad_norm": 1.1014505624771118,
      "learning_rate": 0.00025573842531975715,
      "loss": 0.6159,
      "step": 513550
    },
    {
      "epoch": 5.437219790282711,
      "grad_norm": 1.1213948726654053,
      "learning_rate": 0.0002556922451085654,
      "loss": 0.615,
      "step": 513600
    },
    {
      "epoch": 5.437749112062714,
      "grad_norm": 1.055399775505066,
      "learning_rate": 0.0002556460647030425,
      "loss": 0.6053,
      "step": 513650
    },
    {
      "epoch": 5.438278433842718,
      "grad_norm": 1.1884900331497192,
      "learning_rate": 0.00025559988410476505,
      "loss": 0.6206,
      "step": 513700
    },
    {
      "epoch": 5.438807755622721,
      "grad_norm": 1.1141244173049927,
      "learning_rate": 0.0002555537033153095,
      "loss": 0.6117,
      "step": 513750
    },
    {
      "epoch": 5.439337077402724,
      "grad_norm": 1.2315109968185425,
      "learning_rate": 0.0002555075223362526,
      "loss": 0.6108,
      "step": 513800
    },
    {
      "epoch": 5.439866399182727,
      "grad_norm": 1.0779309272766113,
      "learning_rate": 0.00025546134116917094,
      "loss": 0.6083,
      "step": 513850
    },
    {
      "epoch": 5.44039572096273,
      "grad_norm": 1.140749216079712,
      "learning_rate": 0.00025541515981564113,
      "loss": 0.6156,
      "step": 513900
    },
    {
      "epoch": 5.440925042742734,
      "grad_norm": 1.0573155879974365,
      "learning_rate": 0.0002553689782772397,
      "loss": 0.613,
      "step": 513950
    },
    {
      "epoch": 5.441454364522737,
      "grad_norm": 1.0326862335205078,
      "learning_rate": 0.0002553227965555433,
      "loss": 0.6062,
      "step": 514000
    },
    {
      "epoch": 5.441454364522737,
      "eval_loss": 0.4000057280063629,
      "eval_runtime": 46.8984,
      "eval_samples_per_second": 3580.718,
      "eval_steps_per_second": 447.606,
      "step": 514000
    },
    {
      "epoch": 5.44198368630274,
      "grad_norm": 1.0171107053756714,
      "learning_rate": 0.0002552766146521286,
      "loss": 0.6068,
      "step": 514050
    },
    {
      "epoch": 5.442513008082743,
      "grad_norm": 1.053605079650879,
      "learning_rate": 0.0002552304325685722,
      "loss": 0.609,
      "step": 514100
    },
    {
      "epoch": 5.443042329862747,
      "grad_norm": 1.1029486656188965,
      "learning_rate": 0.00025518425030645074,
      "loss": 0.6055,
      "step": 514150
    },
    {
      "epoch": 5.44357165164275,
      "grad_norm": 1.1775996685028076,
      "learning_rate": 0.0002551380678673409,
      "loss": 0.6073,
      "step": 514200
    },
    {
      "epoch": 5.444100973422754,
      "grad_norm": 1.1908341646194458,
      "learning_rate": 0.0002550928089068186,
      "loss": 0.6163,
      "step": 514250
    },
    {
      "epoch": 5.4446302952027565,
      "grad_norm": 1.0595110654830933,
      "learning_rate": 0.0002550466261219231,
      "loss": 0.6209,
      "step": 514300
    },
    {
      "epoch": 5.44515961698276,
      "grad_norm": 1.1416325569152832,
      "learning_rate": 0.0002550004431647377,
      "loss": 0.6167,
      "step": 514350
    },
    {
      "epoch": 5.445688938762763,
      "grad_norm": 1.0755558013916016,
      "learning_rate": 0.000254954260036839,
      "loss": 0.6196,
      "step": 514400
    },
    {
      "epoch": 5.446218260542767,
      "grad_norm": 1.0895733833312988,
      "learning_rate": 0.0002549080767398037,
      "loss": 0.613,
      "step": 514450
    },
    {
      "epoch": 5.44674758232277,
      "grad_norm": 1.1055580377578735,
      "learning_rate": 0.00025486189327520847,
      "loss": 0.6103,
      "step": 514500
    },
    {
      "epoch": 5.44674758232277,
      "eval_loss": 0.39978939294815063,
      "eval_runtime": 46.745,
      "eval_samples_per_second": 3592.472,
      "eval_steps_per_second": 449.075,
      "step": 514500
    },
    {
      "epoch": 5.4472769041027735,
      "grad_norm": 0.9877170920372009,
      "learning_rate": 0.00025481570964463,
      "loss": 0.5984,
      "step": 514550
    },
    {
      "epoch": 5.447806225882776,
      "grad_norm": 1.0070382356643677,
      "learning_rate": 0.0002547695258496449,
      "loss": 0.6072,
      "step": 514600
    },
    {
      "epoch": 5.448335547662779,
      "grad_norm": 1.1177737712860107,
      "learning_rate": 0.0002547233418918299,
      "loss": 0.6029,
      "step": 514650
    },
    {
      "epoch": 5.448864869442783,
      "grad_norm": 1.124411940574646,
      "learning_rate": 0.0002546771577727618,
      "loss": 0.613,
      "step": 514700
    },
    {
      "epoch": 5.449394191222786,
      "grad_norm": 1.0312060117721558,
      "learning_rate": 0.00025463097349401727,
      "loss": 0.6076,
      "step": 514750
    },
    {
      "epoch": 5.44992351300279,
      "grad_norm": 1.047873854637146,
      "learning_rate": 0.000254584789057173,
      "loss": 0.6106,
      "step": 514800
    },
    {
      "epoch": 5.4504528347827925,
      "grad_norm": 1.1363632678985596,
      "learning_rate": 0.0002545386044638057,
      "loss": 0.6121,
      "step": 514850
    },
    {
      "epoch": 5.450982156562796,
      "grad_norm": 1.1699153184890747,
      "learning_rate": 0.00025449241971549206,
      "loss": 0.6118,
      "step": 514900
    },
    {
      "epoch": 5.451511478342799,
      "grad_norm": 1.0584807395935059,
      "learning_rate": 0.0002544462348138089,
      "loss": 0.6155,
      "step": 514950
    },
    {
      "epoch": 5.452040800122803,
      "grad_norm": 1.085154414176941,
      "learning_rate": 0.00025440004976033296,
      "loss": 0.609,
      "step": 515000
    },
    {
      "epoch": 5.452040800122803,
      "eval_loss": 0.40067458152770996,
      "eval_runtime": 46.8433,
      "eval_samples_per_second": 3584.929,
      "eval_steps_per_second": 448.132,
      "step": 515000
    },
    {
      "epoch": 5.452570121902806,
      "grad_norm": 1.0965540409088135,
      "learning_rate": 0.0002543538645566409,
      "loss": 0.6117,
      "step": 515050
    },
    {
      "epoch": 5.4530994436828095,
      "grad_norm": 1.0941270589828491,
      "learning_rate": 0.0002543076792043095,
      "loss": 0.6078,
      "step": 515100
    },
    {
      "epoch": 5.453628765462812,
      "grad_norm": 1.1466742753982544,
      "learning_rate": 0.0002542614937049155,
      "loss": 0.621,
      "step": 515150
    },
    {
      "epoch": 5.454158087242816,
      "grad_norm": 1.219030737876892,
      "learning_rate": 0.0002542153080600356,
      "loss": 0.609,
      "step": 515200
    },
    {
      "epoch": 5.454687409022819,
      "grad_norm": 1.0930020809173584,
      "learning_rate": 0.00025416912227124673,
      "loss": 0.6156,
      "step": 515250
    },
    {
      "epoch": 5.455216730802823,
      "grad_norm": 1.156487226486206,
      "learning_rate": 0.00025412293634012557,
      "loss": 0.611,
      "step": 515300
    },
    {
      "epoch": 5.455746052582826,
      "grad_norm": 1.1400136947631836,
      "learning_rate": 0.00025407675026824884,
      "loss": 0.6065,
      "step": 515350
    },
    {
      "epoch": 5.4562753743628285,
      "grad_norm": 0.9717406630516052,
      "learning_rate": 0.00025403056405719335,
      "loss": 0.611,
      "step": 515400
    },
    {
      "epoch": 5.456804696142832,
      "grad_norm": 1.0413907766342163,
      "learning_rate": 0.00025398437770853585,
      "loss": 0.6117,
      "step": 515450
    },
    {
      "epoch": 5.457334017922835,
      "grad_norm": 1.1045786142349243,
      "learning_rate": 0.00025393819122385315,
      "loss": 0.6082,
      "step": 515500
    },
    {
      "epoch": 5.457334017922835,
      "eval_loss": 0.3993571996688843,
      "eval_runtime": 46.8163,
      "eval_samples_per_second": 3586.995,
      "eval_steps_per_second": 448.39,
      "step": 515500
    },
    {
      "epoch": 5.457863339702839,
      "grad_norm": 1.111507534980774,
      "learning_rate": 0.00025389200460472207,
      "loss": 0.6106,
      "step": 515550
    },
    {
      "epoch": 5.458392661482842,
      "grad_norm": 1.0500425100326538,
      "learning_rate": 0.00025384581785271935,
      "loss": 0.6091,
      "step": 515600
    },
    {
      "epoch": 5.4589219832628455,
      "grad_norm": 0.9744393229484558,
      "learning_rate": 0.00025379963096942187,
      "loss": 0.6071,
      "step": 515650
    },
    {
      "epoch": 5.459451305042848,
      "grad_norm": 1.0977632999420166,
      "learning_rate": 0.00025375344395640637,
      "loss": 0.6184,
      "step": 515700
    },
    {
      "epoch": 5.459980626822852,
      "grad_norm": 1.1916749477386475,
      "learning_rate": 0.00025370725681524966,
      "loss": 0.6083,
      "step": 515750
    },
    {
      "epoch": 5.460509948602855,
      "grad_norm": 1.1510519981384277,
      "learning_rate": 0.0002536610695475286,
      "loss": 0.6188,
      "step": 515800
    },
    {
      "epoch": 5.461039270382859,
      "grad_norm": 1.078481674194336,
      "learning_rate": 0.00025361488215481994,
      "loss": 0.6089,
      "step": 515850
    },
    {
      "epoch": 5.461568592162862,
      "grad_norm": 1.0752551555633545,
      "learning_rate": 0.00025356869463870053,
      "loss": 0.6018,
      "step": 515900
    },
    {
      "epoch": 5.462097913942865,
      "grad_norm": 1.0858750343322754,
      "learning_rate": 0.0002535225070007472,
      "loss": 0.6093,
      "step": 515950
    },
    {
      "epoch": 5.462627235722868,
      "grad_norm": 1.1239980459213257,
      "learning_rate": 0.00025347631924253674,
      "loss": 0.6063,
      "step": 516000
    },
    {
      "epoch": 5.462627235722868,
      "eval_loss": 0.3994876444339752,
      "eval_runtime": 47.6686,
      "eval_samples_per_second": 3522.862,
      "eval_steps_per_second": 440.373,
      "step": 516000
    },
    {
      "epoch": 5.463156557502872,
      "grad_norm": 1.174673080444336,
      "learning_rate": 0.000253430131365646,
      "loss": 0.6026,
      "step": 516050
    },
    {
      "epoch": 5.463685879282875,
      "grad_norm": 1.049957513809204,
      "learning_rate": 0.00025338394337165194,
      "loss": 0.6006,
      "step": 516100
    },
    {
      "epoch": 5.464215201062878,
      "grad_norm": 1.1588152647018433,
      "learning_rate": 0.00025333775526213123,
      "loss": 0.6212,
      "step": 516150
    },
    {
      "epoch": 5.4647445228428815,
      "grad_norm": 1.1557270288467407,
      "learning_rate": 0.00025329156703866076,
      "loss": 0.6187,
      "step": 516200
    },
    {
      "epoch": 5.465273844622884,
      "grad_norm": 1.155845046043396,
      "learning_rate": 0.0002532453787028174,
      "loss": 0.6085,
      "step": 516250
    },
    {
      "epoch": 5.465803166402888,
      "grad_norm": 1.0739258527755737,
      "learning_rate": 0.00025320011402618636,
      "loss": 0.6143,
      "step": 516300
    },
    {
      "epoch": 5.466332488182891,
      "grad_norm": 1.176215410232544,
      "learning_rate": 0.00025315392547249675,
      "loss": 0.6087,
      "step": 516350
    },
    {
      "epoch": 5.466861809962895,
      "grad_norm": 1.0755910873413086,
      "learning_rate": 0.00025310866058540554,
      "loss": 0.62,
      "step": 516400
    },
    {
      "epoch": 5.467391131742898,
      "grad_norm": 1.1555941104888916,
      "learning_rate": 0.00025306247182005153,
      "loss": 0.6218,
      "step": 516450
    },
    {
      "epoch": 5.467920453522901,
      "grad_norm": 1.095126748085022,
      "learning_rate": 0.00025301628295014585,
      "loss": 0.6235,
      "step": 516500
    },
    {
      "epoch": 5.467920453522901,
      "eval_loss": 0.39919307827949524,
      "eval_runtime": 47.179,
      "eval_samples_per_second": 3559.424,
      "eval_steps_per_second": 444.944,
      "step": 516500
    },
    {
      "epoch": 5.468449775302904,
      "grad_norm": 0.9737281799316406,
      "learning_rate": 0.0002529700939772654,
      "loss": 0.6144,
      "step": 516550
    },
    {
      "epoch": 5.468979097082908,
      "grad_norm": 1.1514396667480469,
      "learning_rate": 0.000252923904902987,
      "loss": 0.6105,
      "step": 516600
    },
    {
      "epoch": 5.469508418862911,
      "grad_norm": 1.005712866783142,
      "learning_rate": 0.0002528777157288876,
      "loss": 0.6074,
      "step": 516650
    },
    {
      "epoch": 5.470037740642915,
      "grad_norm": 1.1197631359100342,
      "learning_rate": 0.000252831526456544,
      "loss": 0.6157,
      "step": 516700
    },
    {
      "epoch": 5.4705670624229175,
      "grad_norm": 1.0730571746826172,
      "learning_rate": 0.0002527853370875331,
      "loss": 0.6223,
      "step": 516750
    },
    {
      "epoch": 5.471096384202921,
      "grad_norm": 1.1316322088241577,
      "learning_rate": 0.0002527391476234319,
      "loss": 0.5998,
      "step": 516800
    },
    {
      "epoch": 5.471625705982924,
      "grad_norm": 1.1642441749572754,
      "learning_rate": 0.0002526929580658172,
      "loss": 0.6022,
      "step": 516850
    },
    {
      "epoch": 5.472155027762927,
      "grad_norm": 1.1020296812057495,
      "learning_rate": 0.0002526467684162658,
      "loss": 0.6112,
      "step": 516900
    },
    {
      "epoch": 5.472684349542931,
      "grad_norm": 0.990898609161377,
      "learning_rate": 0.00025260057867635484,
      "loss": 0.5982,
      "step": 516950
    },
    {
      "epoch": 5.473213671322934,
      "grad_norm": 1.1205174922943115,
      "learning_rate": 0.000252554388847661,
      "loss": 0.6191,
      "step": 517000
    },
    {
      "epoch": 5.473213671322934,
      "eval_loss": 0.4002683758735657,
      "eval_runtime": 46.8297,
      "eval_samples_per_second": 3585.975,
      "eval_steps_per_second": 448.263,
      "step": 517000
    },
    {
      "epoch": 5.473742993102937,
      "grad_norm": 1.1212791204452515,
      "learning_rate": 0.00025250819893176123,
      "loss": 0.6045,
      "step": 517050
    },
    {
      "epoch": 5.47427231488294,
      "grad_norm": 1.1017332077026367,
      "learning_rate": 0.00025246200893023254,
      "loss": 0.6137,
      "step": 517100
    },
    {
      "epoch": 5.474801636662944,
      "grad_norm": 1.1295418739318848,
      "learning_rate": 0.00025241581884465167,
      "loss": 0.6006,
      "step": 517150
    },
    {
      "epoch": 5.475330958442947,
      "grad_norm": 1.1524962186813354,
      "learning_rate": 0.00025236962867659565,
      "loss": 0.6208,
      "step": 517200
    },
    {
      "epoch": 5.475860280222951,
      "grad_norm": 1.1138813495635986,
      "learning_rate": 0.0002523234384276414,
      "loss": 0.6049,
      "step": 517250
    },
    {
      "epoch": 5.476389602002953,
      "grad_norm": 1.1618897914886475,
      "learning_rate": 0.0002522772480993658,
      "loss": 0.6075,
      "step": 517300
    },
    {
      "epoch": 5.476918923782957,
      "grad_norm": 1.1459290981292725,
      "learning_rate": 0.0002522310576933459,
      "loss": 0.6039,
      "step": 517350
    },
    {
      "epoch": 5.47744824556296,
      "grad_norm": 1.2195706367492676,
      "learning_rate": 0.0002521848672111584,
      "loss": 0.6088,
      "step": 517400
    },
    {
      "epoch": 5.477977567342964,
      "grad_norm": 1.1773606538772583,
      "learning_rate": 0.0002521386766543803,
      "loss": 0.6141,
      "step": 517450
    },
    {
      "epoch": 5.478506889122967,
      "grad_norm": 1.117448329925537,
      "learning_rate": 0.0002520924860245886,
      "loss": 0.6111,
      "step": 517500
    },
    {
      "epoch": 5.478506889122967,
      "eval_loss": 0.3985781967639923,
      "eval_runtime": 46.7281,
      "eval_samples_per_second": 3593.766,
      "eval_steps_per_second": 449.237,
      "step": 517500
    },
    {
      "epoch": 5.47903621090297,
      "grad_norm": 1.1778637170791626,
      "learning_rate": 0.00025204629532336024,
      "loss": 0.6166,
      "step": 517550
    },
    {
      "epoch": 5.479565532682973,
      "grad_norm": 1.085094928741455,
      "learning_rate": 0.00025200010455227206,
      "loss": 0.6113,
      "step": 517600
    },
    {
      "epoch": 5.480094854462976,
      "grad_norm": 1.0673167705535889,
      "learning_rate": 0.0002519539137129011,
      "loss": 0.618,
      "step": 517650
    },
    {
      "epoch": 5.48062417624298,
      "grad_norm": 0.989856481552124,
      "learning_rate": 0.00025190772280682416,
      "loss": 0.6161,
      "step": 517700
    },
    {
      "epoch": 5.481153498022983,
      "grad_norm": 0.9885583519935608,
      "learning_rate": 0.00025186153183561833,
      "loss": 0.6023,
      "step": 517750
    },
    {
      "epoch": 5.4816828198029866,
      "grad_norm": 1.0802743434906006,
      "learning_rate": 0.0002518153408008605,
      "loss": 0.6135,
      "step": 517800
    },
    {
      "epoch": 5.482212141582989,
      "grad_norm": 1.1001927852630615,
      "learning_rate": 0.00025176914970412756,
      "loss": 0.6151,
      "step": 517850
    },
    {
      "epoch": 5.482741463362993,
      "grad_norm": 1.125726580619812,
      "learning_rate": 0.0002517229585469965,
      "loss": 0.6165,
      "step": 517900
    },
    {
      "epoch": 5.483270785142996,
      "grad_norm": 1.1911982297897339,
      "learning_rate": 0.00025167676733104424,
      "loss": 0.5949,
      "step": 517950
    },
    {
      "epoch": 5.483800106923,
      "grad_norm": 1.1199429035186768,
      "learning_rate": 0.0002516305760578478,
      "loss": 0.624,
      "step": 518000
    },
    {
      "epoch": 5.483800106923,
      "eval_loss": 0.39821508526802063,
      "eval_runtime": 46.8369,
      "eval_samples_per_second": 3585.42,
      "eval_steps_per_second": 448.193,
      "step": 518000
    },
    {
      "epoch": 5.484329428703003,
      "grad_norm": 1.2103075981140137,
      "learning_rate": 0.00025158438472898403,
      "loss": 0.6199,
      "step": 518050
    },
    {
      "epoch": 5.484858750483006,
      "grad_norm": 1.040212631225586,
      "learning_rate": 0.00025153819334603,
      "loss": 0.62,
      "step": 518100
    },
    {
      "epoch": 5.485388072263009,
      "grad_norm": 1.1980527639389038,
      "learning_rate": 0.0002514920019105626,
      "loss": 0.6067,
      "step": 518150
    },
    {
      "epoch": 5.485917394043013,
      "grad_norm": 1.0591459274291992,
      "learning_rate": 0.0002514458104241588,
      "loss": 0.609,
      "step": 518200
    },
    {
      "epoch": 5.486446715823016,
      "grad_norm": 1.0332565307617188,
      "learning_rate": 0.00025139961888839563,
      "loss": 0.6076,
      "step": 518250
    },
    {
      "epoch": 5.48697603760302,
      "grad_norm": 1.1307411193847656,
      "learning_rate": 0.0002513534273048499,
      "loss": 0.6015,
      "step": 518300
    },
    {
      "epoch": 5.4875053593830225,
      "grad_norm": 1.175880789756775,
      "learning_rate": 0.00025130723567509867,
      "loss": 0.603,
      "step": 518350
    },
    {
      "epoch": 5.488034681163025,
      "grad_norm": 1.0757204294204712,
      "learning_rate": 0.00025126104400071894,
      "loss": 0.6134,
      "step": 518400
    },
    {
      "epoch": 5.488564002943029,
      "grad_norm": 0.9677727818489075,
      "learning_rate": 0.0002512148522832876,
      "loss": 0.5942,
      "step": 518450
    },
    {
      "epoch": 5.489093324723032,
      "grad_norm": 1.2263996601104736,
      "learning_rate": 0.00025116866052438163,
      "loss": 0.6121,
      "step": 518500
    },
    {
      "epoch": 5.489093324723032,
      "eval_loss": 0.3964114189147949,
      "eval_runtime": 46.7766,
      "eval_samples_per_second": 3590.046,
      "eval_steps_per_second": 448.772,
      "step": 518500
    },
    {
      "epoch": 5.489622646503036,
      "grad_norm": 1.164052963256836,
      "learning_rate": 0.00025112246872557804,
      "loss": 0.6089,
      "step": 518550
    },
    {
      "epoch": 5.490151968283039,
      "grad_norm": 1.0618268251419067,
      "learning_rate": 0.0002510762768884538,
      "loss": 0.616,
      "step": 518600
    },
    {
      "epoch": 5.490681290063042,
      "grad_norm": 1.024341344833374,
      "learning_rate": 0.0002510300850145858,
      "loss": 0.6029,
      "step": 518650
    },
    {
      "epoch": 5.491210611843045,
      "grad_norm": 1.1800479888916016,
      "learning_rate": 0.00025098389310555114,
      "loss": 0.615,
      "step": 518700
    },
    {
      "epoch": 5.491739933623049,
      "grad_norm": 1.1288479566574097,
      "learning_rate": 0.00025093770116292667,
      "loss": 0.6113,
      "step": 518750
    },
    {
      "epoch": 5.492269255403052,
      "grad_norm": 1.1010075807571411,
      "learning_rate": 0.00025089150918828945,
      "loss": 0.6115,
      "step": 518800
    },
    {
      "epoch": 5.492798577183056,
      "grad_norm": 1.0501086711883545,
      "learning_rate": 0.00025084531718321646,
      "loss": 0.6077,
      "step": 518850
    },
    {
      "epoch": 5.4933278989630585,
      "grad_norm": 1.042115330696106,
      "learning_rate": 0.0002507991251492846,
      "loss": 0.6148,
      "step": 518900
    },
    {
      "epoch": 5.493857220743062,
      "grad_norm": 1.093863844871521,
      "learning_rate": 0.000250752933088071,
      "loss": 0.6117,
      "step": 518950
    },
    {
      "epoch": 5.494386542523065,
      "grad_norm": 1.1762964725494385,
      "learning_rate": 0.00025070674100115243,
      "loss": 0.6211,
      "step": 519000
    },
    {
      "epoch": 5.494386542523065,
      "eval_loss": 0.3986315131187439,
      "eval_runtime": 46.7262,
      "eval_samples_per_second": 3593.913,
      "eval_steps_per_second": 449.255,
      "step": 519000
    },
    {
      "epoch": 5.494915864303069,
      "grad_norm": 1.083349585533142,
      "learning_rate": 0.00025066054889010604,
      "loss": 0.6087,
      "step": 519050
    },
    {
      "epoch": 5.495445186083072,
      "grad_norm": 1.1992088556289673,
      "learning_rate": 0.00025061435675650874,
      "loss": 0.6112,
      "step": 519100
    },
    {
      "epoch": 5.495974507863075,
      "grad_norm": 1.0661802291870117,
      "learning_rate": 0.00025056816460193755,
      "loss": 0.6077,
      "step": 519150
    },
    {
      "epoch": 5.496503829643078,
      "grad_norm": 1.1645545959472656,
      "learning_rate": 0.0002505219724279694,
      "loss": 0.6122,
      "step": 519200
    },
    {
      "epoch": 5.497033151423081,
      "grad_norm": 1.131707787513733,
      "learning_rate": 0.0002504757802361813,
      "loss": 0.6048,
      "step": 519250
    },
    {
      "epoch": 5.497562473203085,
      "grad_norm": 1.122480034828186,
      "learning_rate": 0.00025042958802815024,
      "loss": 0.6212,
      "step": 519300
    },
    {
      "epoch": 5.498091794983088,
      "grad_norm": 1.1677759885787964,
      "learning_rate": 0.0002503833958054532,
      "loss": 0.607,
      "step": 519350
    },
    {
      "epoch": 5.498621116763092,
      "grad_norm": 1.0673092603683472,
      "learning_rate": 0.00025033720356966714,
      "loss": 0.6196,
      "step": 519400
    },
    {
      "epoch": 5.4991504385430945,
      "grad_norm": 1.1641427278518677,
      "learning_rate": 0.00025029101132236913,
      "loss": 0.6013,
      "step": 519450
    },
    {
      "epoch": 5.499679760323098,
      "grad_norm": 0.9570695161819458,
      "learning_rate": 0.0002502448190651361,
      "loss": 0.5955,
      "step": 519500
    },
    {
      "epoch": 5.499679760323098,
      "eval_loss": 0.39568793773651123,
      "eval_runtime": 46.8311,
      "eval_samples_per_second": 3585.864,
      "eval_steps_per_second": 448.249,
      "step": 519500
    },
    {
      "epoch": 5.500209082103101,
      "grad_norm": 1.1082713603973389,
      "learning_rate": 0.000250198626799545,
      "loss": 0.6036,
      "step": 519550
    },
    {
      "epoch": 5.500738403883105,
      "grad_norm": 1.1093528270721436,
      "learning_rate": 0.00025015243452717283,
      "loss": 0.6141,
      "step": 519600
    },
    {
      "epoch": 5.501267725663108,
      "grad_norm": 1.1727324724197388,
      "learning_rate": 0.0002501062422495967,
      "loss": 0.6065,
      "step": 519650
    },
    {
      "epoch": 5.5017970474431115,
      "grad_norm": 1.165351152420044,
      "learning_rate": 0.0002500600499683934,
      "loss": 0.61,
      "step": 519700
    },
    {
      "epoch": 5.502326369223114,
      "grad_norm": 1.0812708139419556,
      "learning_rate": 0.00025001385768514,
      "loss": 0.6146,
      "step": 519750
    },
    {
      "epoch": 5.502855691003118,
      "grad_norm": 1.0390249490737915,
      "learning_rate": 0.00024996766540141363,
      "loss": 0.6009,
      "step": 519800
    },
    {
      "epoch": 5.503385012783121,
      "grad_norm": 1.0144686698913574,
      "learning_rate": 0.000249921473118791,
      "loss": 0.6026,
      "step": 519850
    },
    {
      "epoch": 5.503914334563124,
      "grad_norm": 1.2305957078933716,
      "learning_rate": 0.0002498752808388494,
      "loss": 0.6137,
      "step": 519900
    },
    {
      "epoch": 5.504443656343128,
      "grad_norm": 1.0953350067138672,
      "learning_rate": 0.0002498290885631655,
      "loss": 0.6124,
      "step": 519950
    },
    {
      "epoch": 5.5049729781231305,
      "grad_norm": 1.028316855430603,
      "learning_rate": 0.0002497828962933166,
      "loss": 0.606,
      "step": 520000
    },
    {
      "epoch": 5.5049729781231305,
      "eval_loss": 0.39516595005989075,
      "eval_runtime": 46.776,
      "eval_samples_per_second": 3590.088,
      "eval_steps_per_second": 448.777,
      "step": 520000
    },
    {
      "epoch": 5.505502299903134,
      "grad_norm": 1.1421127319335938,
      "learning_rate": 0.00024973670403087946,
      "loss": 0.6138,
      "step": 520050
    },
    {
      "epoch": 5.506031621683137,
      "grad_norm": 1.0313082933425903,
      "learning_rate": 0.00024969051177743125,
      "loss": 0.6114,
      "step": 520100
    },
    {
      "epoch": 5.506560943463141,
      "grad_norm": 1.173639178276062,
      "learning_rate": 0.0002496443195345487,
      "loss": 0.6056,
      "step": 520150
    },
    {
      "epoch": 5.507090265243144,
      "grad_norm": 1.281237006187439,
      "learning_rate": 0.0002495981273038091,
      "loss": 0.6161,
      "step": 520200
    },
    {
      "epoch": 5.5076195870231475,
      "grad_norm": 1.1495014429092407,
      "learning_rate": 0.0002495519350867892,
      "loss": 0.5982,
      "step": 520250
    },
    {
      "epoch": 5.50814890880315,
      "grad_norm": 1.123736023902893,
      "learning_rate": 0.0002495057428850661,
      "loss": 0.603,
      "step": 520300
    },
    {
      "epoch": 5.508678230583154,
      "grad_norm": 1.0558298826217651,
      "learning_rate": 0.0002494595507002167,
      "loss": 0.6034,
      "step": 520350
    },
    {
      "epoch": 5.509207552363157,
      "grad_norm": 1.0862995386123657,
      "learning_rate": 0.00024941335853381817,
      "loss": 0.6116,
      "step": 520400
    },
    {
      "epoch": 5.509736874143161,
      "grad_norm": 1.0793266296386719,
      "learning_rate": 0.0002493680902301682,
      "loss": 0.6138,
      "step": 520450
    },
    {
      "epoch": 5.510266195923164,
      "grad_norm": 1.017527461051941,
      "learning_rate": 0.00024932189810495444,
      "loss": 0.6018,
      "step": 520500
    },
    {
      "epoch": 5.510266195923164,
      "eval_loss": 0.3969470262527466,
      "eval_runtime": 46.7539,
      "eval_samples_per_second": 3591.787,
      "eval_steps_per_second": 448.989,
      "step": 520500
    },
    {
      "epoch": 5.510795517703167,
      "grad_norm": 1.0876444578170776,
      "learning_rate": 0.0002492757060028909,
      "loss": 0.6141,
      "step": 520550
    },
    {
      "epoch": 5.51132483948317,
      "grad_norm": 1.190233826637268,
      "learning_rate": 0.0002492295139255544,
      "loss": 0.6091,
      "step": 520600
    },
    {
      "epoch": 5.511854161263173,
      "grad_norm": 1.0880728960037231,
      "learning_rate": 0.00024918332187452214,
      "loss": 0.6012,
      "step": 520650
    },
    {
      "epoch": 5.512383483043177,
      "grad_norm": 1.237243890762329,
      "learning_rate": 0.00024913712985137084,
      "loss": 0.6179,
      "step": 520700
    },
    {
      "epoch": 5.51291280482318,
      "grad_norm": 1.1215617656707764,
      "learning_rate": 0.00024909093785767774,
      "loss": 0.6052,
      "step": 520750
    },
    {
      "epoch": 5.5134421266031834,
      "grad_norm": 1.1326119899749756,
      "learning_rate": 0.00024904474589501955,
      "loss": 0.6019,
      "step": 520800
    },
    {
      "epoch": 5.513971448383186,
      "grad_norm": 1.006909728050232,
      "learning_rate": 0.00024899855396497345,
      "loss": 0.6166,
      "step": 520850
    },
    {
      "epoch": 5.51450077016319,
      "grad_norm": 1.069835901260376,
      "learning_rate": 0.0002489523620691163,
      "loss": 0.601,
      "step": 520900
    },
    {
      "epoch": 5.515030091943193,
      "grad_norm": 1.08274245262146,
      "learning_rate": 0.0002489061702090252,
      "loss": 0.606,
      "step": 520950
    },
    {
      "epoch": 5.515559413723197,
      "grad_norm": 0.9790341258049011,
      "learning_rate": 0.00024885997838627704,
      "loss": 0.6172,
      "step": 521000
    },
    {
      "epoch": 5.515559413723197,
      "eval_loss": 0.3983474373817444,
      "eval_runtime": 46.6958,
      "eval_samples_per_second": 3596.256,
      "eval_steps_per_second": 449.548,
      "step": 521000
    },
    {
      "epoch": 5.5160887355032,
      "grad_norm": 1.178264856338501,
      "learning_rate": 0.0002488137866024488,
      "loss": 0.6025,
      "step": 521050
    },
    {
      "epoch": 5.516618057283203,
      "grad_norm": 1.050811767578125,
      "learning_rate": 0.00024876759485911737,
      "loss": 0.6153,
      "step": 521100
    },
    {
      "epoch": 5.517147379063206,
      "grad_norm": 1.037757396697998,
      "learning_rate": 0.00024872140315785994,
      "loss": 0.6072,
      "step": 521150
    },
    {
      "epoch": 5.51767670084321,
      "grad_norm": 1.1078547239303589,
      "learning_rate": 0.0002486752115002532,
      "loss": 0.6084,
      "step": 521200
    },
    {
      "epoch": 5.518206022623213,
      "grad_norm": 1.0764901638031006,
      "learning_rate": 0.0002486290198878744,
      "loss": 0.6075,
      "step": 521250
    },
    {
      "epoch": 5.518735344403217,
      "grad_norm": 1.1298696994781494,
      "learning_rate": 0.0002485828283223002,
      "loss": 0.6133,
      "step": 521300
    },
    {
      "epoch": 5.519264666183219,
      "grad_norm": 1.1543245315551758,
      "learning_rate": 0.0002485366368051078,
      "loss": 0.614,
      "step": 521350
    },
    {
      "epoch": 5.519793987963222,
      "grad_norm": 1.0632729530334473,
      "learning_rate": 0.00024849044533787403,
      "loss": 0.6111,
      "step": 521400
    },
    {
      "epoch": 5.520323309743226,
      "grad_norm": 1.1212085485458374,
      "learning_rate": 0.00024844425392217605,
      "loss": 0.6118,
      "step": 521450
    },
    {
      "epoch": 5.520852631523229,
      "grad_norm": 1.0876164436340332,
      "learning_rate": 0.00024839806255959047,
      "loss": 0.6137,
      "step": 521500
    },
    {
      "epoch": 5.520852631523229,
      "eval_loss": 0.39436691999435425,
      "eval_runtime": 46.7811,
      "eval_samples_per_second": 3589.699,
      "eval_steps_per_second": 448.728,
      "step": 521500
    },
    {
      "epoch": 5.521381953303233,
      "grad_norm": 1.0001649856567383,
      "learning_rate": 0.0002483518712516946,
      "loss": 0.6108,
      "step": 521550
    },
    {
      "epoch": 5.5219112750832355,
      "grad_norm": 1.0580265522003174,
      "learning_rate": 0.00024830568000006514,
      "loss": 0.5951,
      "step": 521600
    },
    {
      "epoch": 5.522440596863239,
      "grad_norm": 1.1180756092071533,
      "learning_rate": 0.0002482594888062793,
      "loss": 0.6126,
      "step": 521650
    },
    {
      "epoch": 5.522969918643242,
      "grad_norm": 1.169081449508667,
      "learning_rate": 0.00024821329767191365,
      "loss": 0.5987,
      "step": 521700
    },
    {
      "epoch": 5.523499240423246,
      "grad_norm": 1.1772559881210327,
      "learning_rate": 0.0002481671065985455,
      "loss": 0.6093,
      "step": 521750
    },
    {
      "epoch": 5.524028562203249,
      "grad_norm": 1.0509339570999146,
      "learning_rate": 0.00024812091558775167,
      "loss": 0.6131,
      "step": 521800
    },
    {
      "epoch": 5.5245578839832525,
      "grad_norm": 1.1202417612075806,
      "learning_rate": 0.00024807472464110904,
      "loss": 0.6043,
      "step": 521850
    },
    {
      "epoch": 5.525087205763255,
      "grad_norm": 1.1143620014190674,
      "learning_rate": 0.0002480285337601946,
      "loss": 0.6084,
      "step": 521900
    },
    {
      "epoch": 5.525616527543259,
      "grad_norm": 0.9969183206558228,
      "learning_rate": 0.00024798234294658535,
      "loss": 0.6135,
      "step": 521950
    },
    {
      "epoch": 5.526145849323262,
      "grad_norm": 1.031742811203003,
      "learning_rate": 0.0002479361522018581,
      "loss": 0.6087,
      "step": 522000
    },
    {
      "epoch": 5.526145849323262,
      "eval_loss": 0.39797940850257874,
      "eval_runtime": 46.6987,
      "eval_samples_per_second": 3596.031,
      "eval_steps_per_second": 449.52,
      "step": 522000
    },
    {
      "epoch": 5.526675171103266,
      "grad_norm": 1.2152595520019531,
      "learning_rate": 0.0002478899615275899,
      "loss": 0.6187,
      "step": 522050
    },
    {
      "epoch": 5.527204492883269,
      "grad_norm": 1.0392662286758423,
      "learning_rate": 0.0002478437709253576,
      "loss": 0.5987,
      "step": 522100
    },
    {
      "epoch": 5.5277338146632715,
      "grad_norm": 1.2758638858795166,
      "learning_rate": 0.0002477975803967383,
      "loss": 0.5988,
      "step": 522150
    },
    {
      "epoch": 5.528263136443275,
      "grad_norm": 1.196984052658081,
      "learning_rate": 0.0002477513899433086,
      "loss": 0.6019,
      "step": 522200
    },
    {
      "epoch": 5.528792458223278,
      "grad_norm": 1.0090768337249756,
      "learning_rate": 0.0002477051995666458,
      "loss": 0.6132,
      "step": 522250
    },
    {
      "epoch": 5.529321780003282,
      "grad_norm": 1.1167988777160645,
      "learning_rate": 0.0002476590092683265,
      "loss": 0.6266,
      "step": 522300
    },
    {
      "epoch": 5.529851101783285,
      "grad_norm": 1.1835633516311646,
      "learning_rate": 0.0002476128190499279,
      "loss": 0.6077,
      "step": 522350
    },
    {
      "epoch": 5.5303804235632885,
      "grad_norm": 1.0605725049972534,
      "learning_rate": 0.00024756662891302665,
      "loss": 0.6083,
      "step": 522400
    },
    {
      "epoch": 5.530909745343291,
      "grad_norm": 1.000461220741272,
      "learning_rate": 0.00024752043885919995,
      "loss": 0.6063,
      "step": 522450
    },
    {
      "epoch": 5.531439067123295,
      "grad_norm": 1.2258906364440918,
      "learning_rate": 0.0002474751726885681,
      "loss": 0.5938,
      "step": 522500
    },
    {
      "epoch": 5.531439067123295,
      "eval_loss": 0.3949919044971466,
      "eval_runtime": 46.8452,
      "eval_samples_per_second": 3584.788,
      "eval_steps_per_second": 448.115,
      "step": 522500
    },
    {
      "epoch": 5.531968388903298,
      "grad_norm": 1.198531150817871,
      "learning_rate": 0.00024742898280388087,
      "loss": 0.5985,
      "step": 522550
    },
    {
      "epoch": 5.532497710683302,
      "grad_norm": 1.2277969121932983,
      "learning_rate": 0.0002473827930069671,
      "loss": 0.6006,
      "step": 522600
    },
    {
      "epoch": 5.533027032463305,
      "grad_norm": 1.1443325281143188,
      "learning_rate": 0.00024733660329940394,
      "loss": 0.608,
      "step": 522650
    },
    {
      "epoch": 5.533556354243308,
      "grad_norm": 1.0701857805252075,
      "learning_rate": 0.0002472904136827681,
      "loss": 0.6073,
      "step": 522700
    },
    {
      "epoch": 5.534085676023311,
      "grad_norm": 1.1880425214767456,
      "learning_rate": 0.0002472442241586366,
      "loss": 0.6102,
      "step": 522750
    },
    {
      "epoch": 5.534614997803315,
      "grad_norm": 1.1255624294281006,
      "learning_rate": 0.0002471980347285862,
      "loss": 0.5966,
      "step": 522800
    },
    {
      "epoch": 5.535144319583318,
      "grad_norm": 1.0381183624267578,
      "learning_rate": 0.0002471518453941939,
      "loss": 0.61,
      "step": 522850
    },
    {
      "epoch": 5.535673641363321,
      "grad_norm": 1.1793512105941772,
      "learning_rate": 0.00024710565615703654,
      "loss": 0.6094,
      "step": 522900
    },
    {
      "epoch": 5.5362029631433245,
      "grad_norm": 1.0455251932144165,
      "learning_rate": 0.00024705946701869113,
      "loss": 0.6054,
      "step": 522950
    },
    {
      "epoch": 5.536732284923327,
      "grad_norm": 1.2109222412109375,
      "learning_rate": 0.00024701327798073427,
      "loss": 0.6185,
      "step": 523000
    },
    {
      "epoch": 5.536732284923327,
      "eval_loss": 0.396278440952301,
      "eval_runtime": 46.7624,
      "eval_samples_per_second": 3591.132,
      "eval_steps_per_second": 448.907,
      "step": 523000
    },
    {
      "epoch": 5.537261606703331,
      "grad_norm": 1.0652003288269043,
      "learning_rate": 0.0002469670890447431,
      "loss": 0.6157,
      "step": 523050
    },
    {
      "epoch": 5.537790928483334,
      "grad_norm": 1.1098233461380005,
      "learning_rate": 0.00024692090021229433,
      "loss": 0.6073,
      "step": 523100
    },
    {
      "epoch": 5.538320250263338,
      "grad_norm": 1.1005218029022217,
      "learning_rate": 0.000246874711484965,
      "loss": 0.6045,
      "step": 523150
    },
    {
      "epoch": 5.538849572043341,
      "grad_norm": 1.0763317346572876,
      "learning_rate": 0.0002468285228643318,
      "loss": 0.6063,
      "step": 523200
    },
    {
      "epoch": 5.539378893823344,
      "grad_norm": 1.1700108051300049,
      "learning_rate": 0.0002467823343519717,
      "loss": 0.6101,
      "step": 523250
    },
    {
      "epoch": 5.539908215603347,
      "grad_norm": 1.1750915050506592,
      "learning_rate": 0.0002467361459494614,
      "loss": 0.6053,
      "step": 523300
    },
    {
      "epoch": 5.540437537383351,
      "grad_norm": 1.1045746803283691,
      "learning_rate": 0.0002466899576583781,
      "loss": 0.6222,
      "step": 523350
    },
    {
      "epoch": 5.540966859163354,
      "grad_norm": 1.084767460823059,
      "learning_rate": 0.0002466437694802982,
      "loss": 0.614,
      "step": 523400
    },
    {
      "epoch": 5.541496180943358,
      "grad_norm": 1.0752465724945068,
      "learning_rate": 0.000246597581416799,
      "loss": 0.6066,
      "step": 523450
    },
    {
      "epoch": 5.5420255027233605,
      "grad_norm": 1.1736009120941162,
      "learning_rate": 0.00024655139346945696,
      "loss": 0.6053,
      "step": 523500
    },
    {
      "epoch": 5.5420255027233605,
      "eval_loss": 0.3946852385997772,
      "eval_runtime": 46.799,
      "eval_samples_per_second": 3588.321,
      "eval_steps_per_second": 448.556,
      "step": 523500
    },
    {
      "epoch": 5.542554824503364,
      "grad_norm": 1.2374801635742188,
      "learning_rate": 0.0002465052056398492,
      "loss": 0.6082,
      "step": 523550
    },
    {
      "epoch": 5.543084146283367,
      "grad_norm": 1.1410882472991943,
      "learning_rate": 0.00024645901792955235,
      "loss": 0.5996,
      "step": 523600
    },
    {
      "epoch": 5.54361346806337,
      "grad_norm": 1.1386312246322632,
      "learning_rate": 0.00024641283034014343,
      "loss": 0.5982,
      "step": 523650
    },
    {
      "epoch": 5.544142789843374,
      "grad_norm": 1.1421787738800049,
      "learning_rate": 0.000246366642873199,
      "loss": 0.6062,
      "step": 523700
    },
    {
      "epoch": 5.544672111623377,
      "grad_norm": 1.1861872673034668,
      "learning_rate": 0.0002463204555302962,
      "loss": 0.6053,
      "step": 523750
    },
    {
      "epoch": 5.54520143340338,
      "grad_norm": 1.0615755319595337,
      "learning_rate": 0.0002462742683130116,
      "loss": 0.6071,
      "step": 523800
    },
    {
      "epoch": 5.545730755183383,
      "grad_norm": 0.9708450436592102,
      "learning_rate": 0.00024622808122292224,
      "loss": 0.599,
      "step": 523850
    },
    {
      "epoch": 5.546260076963387,
      "grad_norm": 1.1292330026626587,
      "learning_rate": 0.00024618189426160465,
      "loss": 0.6029,
      "step": 523900
    },
    {
      "epoch": 5.54678939874339,
      "grad_norm": 1.1861649751663208,
      "learning_rate": 0.00024613570743063585,
      "loss": 0.5967,
      "step": 523950
    },
    {
      "epoch": 5.547318720523394,
      "grad_norm": 1.1504143476486206,
      "learning_rate": 0.0002460895207315926,
      "loss": 0.606,
      "step": 524000
    },
    {
      "epoch": 5.547318720523394,
      "eval_loss": 0.3952542543411255,
      "eval_runtime": 46.7876,
      "eval_samples_per_second": 3589.203,
      "eval_steps_per_second": 448.666,
      "step": 524000
    },
    {
      "epoch": 5.5478480423033965,
      "grad_norm": 1.0812355279922485,
      "learning_rate": 0.0002460433341660517,
      "loss": 0.6059,
      "step": 524050
    },
    {
      "epoch": 5.5483773640834,
      "grad_norm": 1.1309483051300049,
      "learning_rate": 0.00024599714773558984,
      "loss": 0.6089,
      "step": 524100
    },
    {
      "epoch": 5.548906685863403,
      "grad_norm": 1.1364136934280396,
      "learning_rate": 0.000245950961441784,
      "loss": 0.6148,
      "step": 524150
    },
    {
      "epoch": 5.549436007643407,
      "grad_norm": 1.0672870874404907,
      "learning_rate": 0.00024590477528621074,
      "loss": 0.6097,
      "step": 524200
    },
    {
      "epoch": 5.54996532942341,
      "grad_norm": 1.1015793085098267,
      "learning_rate": 0.00024585858927044706,
      "loss": 0.6145,
      "step": 524250
    },
    {
      "epoch": 5.5504946512034135,
      "grad_norm": 1.1238223314285278,
      "learning_rate": 0.0002458124033960695,
      "loss": 0.6186,
      "step": 524300
    },
    {
      "epoch": 5.551023972983416,
      "grad_norm": 1.2737905979156494,
      "learning_rate": 0.0002457662176646551,
      "loss": 0.6161,
      "step": 524350
    },
    {
      "epoch": 5.551553294763419,
      "grad_norm": 1.1934324502944946,
      "learning_rate": 0.0002457200320777803,
      "loss": 0.601,
      "step": 524400
    },
    {
      "epoch": 5.552082616543423,
      "grad_norm": 1.0135945081710815,
      "learning_rate": 0.0002456738466370222,
      "loss": 0.6072,
      "step": 524450
    },
    {
      "epoch": 5.552611938323426,
      "grad_norm": 1.096178412437439,
      "learning_rate": 0.0002456276613439573,
      "loss": 0.5972,
      "step": 524500
    },
    {
      "epoch": 5.552611938323426,
      "eval_loss": 0.39608243107795715,
      "eval_runtime": 46.7918,
      "eval_samples_per_second": 3588.879,
      "eval_steps_per_second": 448.626,
      "step": 524500
    },
    {
      "epoch": 5.55314126010343,
      "grad_norm": 1.1279776096343994,
      "learning_rate": 0.00024558239990156525,
      "loss": 0.6096,
      "step": 524550
    },
    {
      "epoch": 5.553670581883432,
      "grad_norm": 0.9711199402809143,
      "learning_rate": 0.0002455362149055849,
      "loss": 0.6053,
      "step": 524600
    },
    {
      "epoch": 5.554199903663436,
      "grad_norm": 1.0914117097854614,
      "learning_rate": 0.00024549003006199636,
      "loss": 0.6037,
      "step": 524650
    },
    {
      "epoch": 5.554729225443439,
      "grad_norm": 1.095223307609558,
      "learning_rate": 0.0002454438453723767,
      "loss": 0.6176,
      "step": 524700
    },
    {
      "epoch": 5.555258547223443,
      "grad_norm": 1.0770882368087769,
      "learning_rate": 0.00024539766083830233,
      "loss": 0.6109,
      "step": 524750
    },
    {
      "epoch": 5.555787869003446,
      "grad_norm": 1.0014477968215942,
      "learning_rate": 0.0002453514764613503,
      "loss": 0.6034,
      "step": 524800
    },
    {
      "epoch": 5.556317190783449,
      "grad_norm": 1.0673102140426636,
      "learning_rate": 0.000245305292243097,
      "loss": 0.5925,
      "step": 524850
    },
    {
      "epoch": 5.556846512563452,
      "grad_norm": 1.005516767501831,
      "learning_rate": 0.0002452591081851194,
      "loss": 0.6055,
      "step": 524900
    },
    {
      "epoch": 5.557375834343456,
      "grad_norm": 1.1768652200698853,
      "learning_rate": 0.00024521292428899405,
      "loss": 0.6089,
      "step": 524950
    },
    {
      "epoch": 5.557905156123459,
      "grad_norm": 1.2518398761749268,
      "learning_rate": 0.00024516674055629777,
      "loss": 0.6213,
      "step": 525000
    },
    {
      "epoch": 5.557905156123459,
      "eval_loss": 0.3951170742511749,
      "eval_runtime": 46.8412,
      "eval_samples_per_second": 3585.089,
      "eval_steps_per_second": 448.152,
      "step": 525000
    },
    {
      "epoch": 5.558434477903463,
      "grad_norm": 1.114266037940979,
      "learning_rate": 0.00024512055698860713,
      "loss": 0.6063,
      "step": 525050
    },
    {
      "epoch": 5.5589637996834655,
      "grad_norm": 1.1106781959533691,
      "learning_rate": 0.00024507437358749895,
      "loss": 0.6075,
      "step": 525100
    },
    {
      "epoch": 5.559493121463468,
      "grad_norm": 1.103346824645996,
      "learning_rate": 0.0002450281903545498,
      "loss": 0.5961,
      "step": 525150
    },
    {
      "epoch": 5.560022443243472,
      "grad_norm": 1.099137783050537,
      "learning_rate": 0.0002449820072913364,
      "loss": 0.596,
      "step": 525200
    },
    {
      "epoch": 5.560551765023475,
      "grad_norm": 1.0992685556411743,
      "learning_rate": 0.00024493582439943543,
      "loss": 0.6066,
      "step": 525250
    },
    {
      "epoch": 5.561081086803479,
      "grad_norm": 1.054688572883606,
      "learning_rate": 0.0002448896416804236,
      "loss": 0.6077,
      "step": 525300
    },
    {
      "epoch": 5.561610408583482,
      "grad_norm": 1.003574013710022,
      "learning_rate": 0.00024484345913587744,
      "loss": 0.6087,
      "step": 525350
    },
    {
      "epoch": 5.562139730363485,
      "grad_norm": 1.150383472442627,
      "learning_rate": 0.0002447972767673738,
      "loss": 0.6048,
      "step": 525400
    },
    {
      "epoch": 5.562669052143488,
      "grad_norm": 1.1141897439956665,
      "learning_rate": 0.00024475109457648914,
      "loss": 0.6048,
      "step": 525450
    },
    {
      "epoch": 5.563198373923492,
      "grad_norm": 1.217165231704712,
      "learning_rate": 0.0002447049125648003,
      "loss": 0.6128,
      "step": 525500
    },
    {
      "epoch": 5.563198373923492,
      "eval_loss": 0.39483192563056946,
      "eval_runtime": 46.7708,
      "eval_samples_per_second": 3590.488,
      "eval_steps_per_second": 448.827,
      "step": 525500
    },
    {
      "epoch": 5.563727695703495,
      "grad_norm": 1.1173930168151855,
      "learning_rate": 0.0002446587307338837,
      "loss": 0.6053,
      "step": 525550
    },
    {
      "epoch": 5.564257017483499,
      "grad_norm": 1.2171827554702759,
      "learning_rate": 0.0002446125490853162,
      "loss": 0.6065,
      "step": 525600
    },
    {
      "epoch": 5.5647863392635015,
      "grad_norm": 1.125641942024231,
      "learning_rate": 0.0002445663676206741,
      "loss": 0.6041,
      "step": 525650
    },
    {
      "epoch": 5.565315661043505,
      "grad_norm": 1.049866795539856,
      "learning_rate": 0.0002445201863415344,
      "loss": 0.6011,
      "step": 525700
    },
    {
      "epoch": 5.565844982823508,
      "grad_norm": 1.0117748975753784,
      "learning_rate": 0.0002444740052494734,
      "loss": 0.6075,
      "step": 525750
    },
    {
      "epoch": 5.566374304603512,
      "grad_norm": 1.2246979475021362,
      "learning_rate": 0.00024442782434606794,
      "loss": 0.6086,
      "step": 525800
    },
    {
      "epoch": 5.566903626383515,
      "grad_norm": 1.1270904541015625,
      "learning_rate": 0.0002443816436328944,
      "loss": 0.6052,
      "step": 525850
    },
    {
      "epoch": 5.567432948163518,
      "grad_norm": 1.1909884214401245,
      "learning_rate": 0.0002443354631115296,
      "loss": 0.6013,
      "step": 525900
    },
    {
      "epoch": 5.567962269943521,
      "grad_norm": 1.014682650566101,
      "learning_rate": 0.0002442892827835499,
      "loss": 0.595,
      "step": 525950
    },
    {
      "epoch": 5.568491591723525,
      "grad_norm": 1.1026397943496704,
      "learning_rate": 0.00024424310265053206,
      "loss": 0.6075,
      "step": 526000
    },
    {
      "epoch": 5.568491591723525,
      "eval_loss": 0.39587852358818054,
      "eval_runtime": 46.7561,
      "eval_samples_per_second": 3591.617,
      "eval_steps_per_second": 448.968,
      "step": 526000
    },
    {
      "epoch": 5.569020913503528,
      "grad_norm": 1.011985421180725,
      "learning_rate": 0.00024419692271405254,
      "loss": 0.5996,
      "step": 526050
    },
    {
      "epoch": 5.569550235283531,
      "grad_norm": 1.0592907667160034,
      "learning_rate": 0.000244150742975688,
      "loss": 0.6073,
      "step": 526100
    },
    {
      "epoch": 5.570079557063535,
      "grad_norm": 1.0804269313812256,
      "learning_rate": 0.0002441045634370149,
      "loss": 0.6015,
      "step": 526150
    },
    {
      "epoch": 5.5706088788435375,
      "grad_norm": 1.226033329963684,
      "learning_rate": 0.00024405838409960993,
      "loss": 0.6047,
      "step": 526200
    },
    {
      "epoch": 5.571138200623541,
      "grad_norm": 1.133693814277649,
      "learning_rate": 0.00024401220496504946,
      "loss": 0.6057,
      "step": 526250
    },
    {
      "epoch": 5.571667522403544,
      "grad_norm": 1.1066466569900513,
      "learning_rate": 0.0002439660260349102,
      "loss": 0.6048,
      "step": 526300
    },
    {
      "epoch": 5.572196844183548,
      "grad_norm": 1.2184869050979614,
      "learning_rate": 0.00024391984731076847,
      "loss": 0.6069,
      "step": 526350
    },
    {
      "epoch": 5.572726165963551,
      "grad_norm": 1.1449862718582153,
      "learning_rate": 0.00024387366879420106,
      "loss": 0.6065,
      "step": 526400
    },
    {
      "epoch": 5.5732554877435545,
      "grad_norm": 1.0436588525772095,
      "learning_rate": 0.00024382749048678423,
      "loss": 0.5987,
      "step": 526450
    },
    {
      "epoch": 5.573784809523557,
      "grad_norm": 1.0707851648330688,
      "learning_rate": 0.00024378131239009474,
      "loss": 0.6021,
      "step": 526500
    },
    {
      "epoch": 5.573784809523557,
      "eval_loss": 0.39524024724960327,
      "eval_runtime": 46.8499,
      "eval_samples_per_second": 3584.426,
      "eval_steps_per_second": 448.069,
      "step": 526500
    },
    {
      "epoch": 5.574314131303561,
      "grad_norm": 1.092296838760376,
      "learning_rate": 0.00024373605806130578,
      "loss": 0.6174,
      "step": 526550
    },
    {
      "epoch": 5.574843453083564,
      "grad_norm": 1.1394716501235962,
      "learning_rate": 0.00024368988038650708,
      "loss": 0.5994,
      "step": 526600
    },
    {
      "epoch": 5.575372774863567,
      "grad_norm": 1.071318507194519,
      "learning_rate": 0.00024364370292713359,
      "loss": 0.6069,
      "step": 526650
    },
    {
      "epoch": 5.575902096643571,
      "grad_norm": 1.0649573802947998,
      "learning_rate": 0.00024359752568476172,
      "loss": 0.6014,
      "step": 526700
    },
    {
      "epoch": 5.576431418423574,
      "grad_norm": 1.1686714887619019,
      "learning_rate": 0.00024355134866096794,
      "loss": 0.597,
      "step": 526750
    },
    {
      "epoch": 5.576960740203577,
      "grad_norm": 1.0529983043670654,
      "learning_rate": 0.0002435051718573288,
      "loss": 0.6084,
      "step": 526800
    },
    {
      "epoch": 5.57749006198358,
      "grad_norm": 1.0022400617599487,
      "learning_rate": 0.00024345899527542067,
      "loss": 0.6053,
      "step": 526850
    },
    {
      "epoch": 5.578019383763584,
      "grad_norm": 1.0911707878112793,
      "learning_rate": 0.00024341281891682013,
      "loss": 0.6072,
      "step": 526900
    },
    {
      "epoch": 5.578548705543587,
      "grad_norm": 1.1239484548568726,
      "learning_rate": 0.00024336664278310345,
      "loss": 0.6134,
      "step": 526950
    },
    {
      "epoch": 5.5790780273235905,
      "grad_norm": 1.1555980443954468,
      "learning_rate": 0.00024332046687584722,
      "loss": 0.602,
      "step": 527000
    },
    {
      "epoch": 5.5790780273235905,
      "eval_loss": 0.39314961433410645,
      "eval_runtime": 46.7503,
      "eval_samples_per_second": 3592.066,
      "eval_steps_per_second": 449.024,
      "step": 527000
    },
    {
      "epoch": 5.579607349103593,
      "grad_norm": 0.9735942482948303,
      "learning_rate": 0.0002432742911966277,
      "loss": 0.6167,
      "step": 527050
    },
    {
      "epoch": 5.580136670883597,
      "grad_norm": 1.1639376878738403,
      "learning_rate": 0.00024322811574702154,
      "loss": 0.6041,
      "step": 527100
    },
    {
      "epoch": 5.5806659926636,
      "grad_norm": 1.080794334411621,
      "learning_rate": 0.00024318194052860492,
      "loss": 0.6016,
      "step": 527150
    },
    {
      "epoch": 5.581195314443604,
      "grad_norm": 1.0667463541030884,
      "learning_rate": 0.00024313576554295445,
      "loss": 0.6032,
      "step": 527200
    },
    {
      "epoch": 5.581724636223607,
      "grad_norm": 1.1359353065490723,
      "learning_rate": 0.0002430895907916463,
      "loss": 0.6042,
      "step": 527250
    },
    {
      "epoch": 5.58225395800361,
      "grad_norm": 1.198560357093811,
      "learning_rate": 0.00024304341627625711,
      "loss": 0.6151,
      "step": 527300
    },
    {
      "epoch": 5.582783279783613,
      "grad_norm": 0.9999679923057556,
      "learning_rate": 0.00024299724199836303,
      "loss": 0.5975,
      "step": 527350
    },
    {
      "epoch": 5.583312601563616,
      "grad_norm": 1.0467205047607422,
      "learning_rate": 0.00024295106795954062,
      "loss": 0.6018,
      "step": 527400
    },
    {
      "epoch": 5.58384192334362,
      "grad_norm": 1.136801838874817,
      "learning_rate": 0.00024290489416136613,
      "loss": 0.6149,
      "step": 527450
    },
    {
      "epoch": 5.584371245123624,
      "grad_norm": 1.1380555629730225,
      "learning_rate": 0.00024285872060541595,
      "loss": 0.6176,
      "step": 527500
    },
    {
      "epoch": 5.584371245123624,
      "eval_loss": 0.3961640000343323,
      "eval_runtime": 46.7397,
      "eval_samples_per_second": 3592.881,
      "eval_steps_per_second": 449.126,
      "step": 527500
    },
    {
      "epoch": 5.5849005669036265,
      "grad_norm": 1.060645580291748,
      "learning_rate": 0.00024281254729326644,
      "loss": 0.6017,
      "step": 527550
    },
    {
      "epoch": 5.585429888683629,
      "grad_norm": 1.103954553604126,
      "learning_rate": 0.00024276637422649392,
      "loss": 0.6011,
      "step": 527600
    },
    {
      "epoch": 5.585959210463633,
      "grad_norm": 1.2394285202026367,
      "learning_rate": 0.00024272020140667468,
      "loss": 0.6099,
      "step": 527650
    },
    {
      "epoch": 5.586488532243636,
      "grad_norm": 1.326671838760376,
      "learning_rate": 0.0002426740288353852,
      "loss": 0.6076,
      "step": 527700
    },
    {
      "epoch": 5.58701785402364,
      "grad_norm": 1.1403123140335083,
      "learning_rate": 0.0002426278565142016,
      "loss": 0.5961,
      "step": 527750
    },
    {
      "epoch": 5.587547175803643,
      "grad_norm": 1.122648000717163,
      "learning_rate": 0.0002425816844447004,
      "loss": 0.6006,
      "step": 527800
    },
    {
      "epoch": 5.588076497583646,
      "grad_norm": 1.0585212707519531,
      "learning_rate": 0.0002425355126284576,
      "loss": 0.5949,
      "step": 527850
    },
    {
      "epoch": 5.588605819363649,
      "grad_norm": 1.0728158950805664,
      "learning_rate": 0.00024248934106704982,
      "loss": 0.6054,
      "step": 527900
    },
    {
      "epoch": 5.589135141143653,
      "grad_norm": 1.1570183038711548,
      "learning_rate": 0.00024244316976205306,
      "loss": 0.607,
      "step": 527950
    },
    {
      "epoch": 5.589664462923656,
      "grad_norm": 1.1378633975982666,
      "learning_rate": 0.0002423969987150438,
      "loss": 0.6019,
      "step": 528000
    },
    {
      "epoch": 5.589664462923656,
      "eval_loss": 0.3927246034145355,
      "eval_runtime": 46.7786,
      "eval_samples_per_second": 3589.891,
      "eval_steps_per_second": 448.752,
      "step": 528000
    },
    {
      "epoch": 5.59019378470366,
      "grad_norm": 1.2079836130142212,
      "learning_rate": 0.00024235082792759812,
      "loss": 0.6012,
      "step": 528050
    },
    {
      "epoch": 5.590723106483662,
      "grad_norm": 1.1441929340362549,
      "learning_rate": 0.00024230465740129252,
      "loss": 0.6122,
      "step": 528100
    },
    {
      "epoch": 5.591252428263665,
      "grad_norm": 1.1282682418823242,
      "learning_rate": 0.00024225848713770292,
      "loss": 0.6112,
      "step": 528150
    },
    {
      "epoch": 5.591781750043669,
      "grad_norm": 1.076674222946167,
      "learning_rate": 0.00024221231713840587,
      "loss": 0.6136,
      "step": 528200
    },
    {
      "epoch": 5.592311071823673,
      "grad_norm": 1.1762580871582031,
      "learning_rate": 0.00024216614740497737,
      "loss": 0.6054,
      "step": 528250
    },
    {
      "epoch": 5.592840393603676,
      "grad_norm": 1.0251476764678955,
      "learning_rate": 0.00024211997793899376,
      "loss": 0.605,
      "step": 528300
    },
    {
      "epoch": 5.5933697153836786,
      "grad_norm": 1.203688144683838,
      "learning_rate": 0.0002420738087420312,
      "loss": 0.6048,
      "step": 528350
    },
    {
      "epoch": 5.593899037163682,
      "grad_norm": 1.1192543506622314,
      "learning_rate": 0.0002420276398156659,
      "loss": 0.6053,
      "step": 528400
    },
    {
      "epoch": 5.594428358943685,
      "grad_norm": 1.1272828578948975,
      "learning_rate": 0.000241981471161474,
      "loss": 0.6022,
      "step": 528450
    },
    {
      "epoch": 5.594957680723689,
      "grad_norm": 1.1778881549835205,
      "learning_rate": 0.00024193530278103186,
      "loss": 0.6023,
      "step": 528500
    },
    {
      "epoch": 5.594957680723689,
      "eval_loss": 0.3930390775203705,
      "eval_runtime": 46.7644,
      "eval_samples_per_second": 3590.982,
      "eval_steps_per_second": 448.889,
      "step": 528500
    },
    {
      "epoch": 5.595487002503692,
      "grad_norm": 1.1057872772216797,
      "learning_rate": 0.00024189005803530947,
      "loss": 0.6057,
      "step": 528550
    },
    {
      "epoch": 5.5960163242836956,
      "grad_norm": 1.0994349718093872,
      "learning_rate": 0.0002418438902015415,
      "loss": 0.5994,
      "step": 528600
    },
    {
      "epoch": 5.596545646063698,
      "grad_norm": 1.06327223777771,
      "learning_rate": 0.00024179772264622018,
      "loss": 0.5927,
      "step": 528650
    },
    {
      "epoch": 5.597074967843702,
      "grad_norm": 1.050150752067566,
      "learning_rate": 0.0002417515553709216,
      "loss": 0.6042,
      "step": 528700
    },
    {
      "epoch": 5.597604289623705,
      "grad_norm": 1.2028175592422485,
      "learning_rate": 0.0002417053883772219,
      "loss": 0.6082,
      "step": 528750
    },
    {
      "epoch": 5.598133611403709,
      "grad_norm": 1.118600845336914,
      "learning_rate": 0.00024165922166669718,
      "loss": 0.6014,
      "step": 528800
    },
    {
      "epoch": 5.598662933183712,
      "grad_norm": 1.1097772121429443,
      "learning_rate": 0.0002416130552409236,
      "loss": 0.6062,
      "step": 528850
    },
    {
      "epoch": 5.5991922549637145,
      "grad_norm": 1.1223249435424805,
      "learning_rate": 0.00024156688910147717,
      "loss": 0.6052,
      "step": 528900
    },
    {
      "epoch": 5.599721576743718,
      "grad_norm": 1.1142796277999878,
      "learning_rate": 0.00024152072324993418,
      "loss": 0.6041,
      "step": 528950
    },
    {
      "epoch": 5.600250898523722,
      "grad_norm": 1.2666326761245728,
      "learning_rate": 0.00024147455768787048,
      "loss": 0.6004,
      "step": 529000
    },
    {
      "epoch": 5.600250898523722,
      "eval_loss": 0.3924802243709564,
      "eval_runtime": 46.6645,
      "eval_samples_per_second": 3598.668,
      "eval_steps_per_second": 449.85,
      "step": 529000
    },
    {
      "epoch": 5.600780220303725,
      "grad_norm": 1.0580599308013916,
      "learning_rate": 0.00024142839241686234,
      "loss": 0.6021,
      "step": 529050
    },
    {
      "epoch": 5.601309542083728,
      "grad_norm": 1.1875745058059692,
      "learning_rate": 0.00024138222743848563,
      "loss": 0.6025,
      "step": 529100
    },
    {
      "epoch": 5.6018388638637315,
      "grad_norm": 1.1948243379592896,
      "learning_rate": 0.00024133606275431664,
      "loss": 0.6083,
      "step": 529150
    },
    {
      "epoch": 5.602368185643734,
      "grad_norm": 1.202303171157837,
      "learning_rate": 0.00024128989836593118,
      "loss": 0.6064,
      "step": 529200
    },
    {
      "epoch": 5.602897507423738,
      "grad_norm": 1.0961337089538574,
      "learning_rate": 0.00024124373427490548,
      "loss": 0.6093,
      "step": 529250
    },
    {
      "epoch": 5.603426829203741,
      "grad_norm": 1.0908252000808716,
      "learning_rate": 0.0002411975704828154,
      "loss": 0.6113,
      "step": 529300
    },
    {
      "epoch": 5.603956150983745,
      "grad_norm": 1.148870825767517,
      "learning_rate": 0.00024115140699123715,
      "loss": 0.6181,
      "step": 529350
    },
    {
      "epoch": 5.604485472763748,
      "grad_norm": 1.0350170135498047,
      "learning_rate": 0.00024110524380174648,
      "loss": 0.6109,
      "step": 529400
    },
    {
      "epoch": 5.605014794543751,
      "grad_norm": 1.1968345642089844,
      "learning_rate": 0.00024105908091591967,
      "loss": 0.5998,
      "step": 529450
    },
    {
      "epoch": 5.605544116323754,
      "grad_norm": 1.1687791347503662,
      "learning_rate": 0.00024101291833533242,
      "loss": 0.6003,
      "step": 529500
    },
    {
      "epoch": 5.605544116323754,
      "eval_loss": 0.3929463326931,
      "eval_runtime": 46.7462,
      "eval_samples_per_second": 3592.374,
      "eval_steps_per_second": 449.063,
      "step": 529500
    },
    {
      "epoch": 5.606073438103758,
      "grad_norm": 1.0821805000305176,
      "learning_rate": 0.00024096675606156092,
      "loss": 0.5991,
      "step": 529550
    },
    {
      "epoch": 5.606602759883761,
      "grad_norm": 1.089445948600769,
      "learning_rate": 0.00024092059409618104,
      "loss": 0.6128,
      "step": 529600
    },
    {
      "epoch": 5.607132081663764,
      "grad_norm": 1.296311855316162,
      "learning_rate": 0.00024087443244076874,
      "loss": 0.5953,
      "step": 529650
    },
    {
      "epoch": 5.6076614034437675,
      "grad_norm": 1.1598470211029053,
      "learning_rate": 0.00024082827109689993,
      "loss": 0.5996,
      "step": 529700
    },
    {
      "epoch": 5.608190725223771,
      "grad_norm": 1.180169701576233,
      "learning_rate": 0.00024078211006615068,
      "loss": 0.6072,
      "step": 529750
    },
    {
      "epoch": 5.608720047003774,
      "grad_norm": 1.061580777168274,
      "learning_rate": 0.0002407359493500967,
      "loss": 0.6056,
      "step": 529800
    },
    {
      "epoch": 5.609249368783777,
      "grad_norm": 1.2551381587982178,
      "learning_rate": 0.00024068978895031414,
      "loss": 0.5966,
      "step": 529850
    },
    {
      "epoch": 5.609778690563781,
      "grad_norm": 1.1222513914108276,
      "learning_rate": 0.00024064362886837862,
      "loss": 0.6092,
      "step": 529900
    },
    {
      "epoch": 5.610308012343784,
      "grad_norm": 1.0648307800292969,
      "learning_rate": 0.00024059746910586632,
      "loss": 0.6043,
      "step": 529950
    },
    {
      "epoch": 5.610837334123787,
      "grad_norm": 1.1318351030349731,
      "learning_rate": 0.00024055130966435287,
      "loss": 0.6159,
      "step": 530000
    },
    {
      "epoch": 5.610837334123787,
      "eval_loss": 0.3926846981048584,
      "eval_runtime": 46.7674,
      "eval_samples_per_second": 3590.751,
      "eval_steps_per_second": 448.86,
      "step": 530000
    },
    {
      "epoch": 5.61136665590379,
      "grad_norm": 0.9975240230560303,
      "learning_rate": 0.00024050515054541437,
      "loss": 0.5966,
      "step": 530050
    },
    {
      "epoch": 5.611895977683794,
      "grad_norm": 1.177812933921814,
      "learning_rate": 0.0002404589917506264,
      "loss": 0.6059,
      "step": 530100
    },
    {
      "epoch": 5.612425299463797,
      "grad_norm": 1.023605227470398,
      "learning_rate": 0.00024041283328156507,
      "loss": 0.6007,
      "step": 530150
    },
    {
      "epoch": 5.612954621243801,
      "grad_norm": 1.170243501663208,
      "learning_rate": 0.000240366675139806,
      "loss": 0.6134,
      "step": 530200
    },
    {
      "epoch": 5.6134839430238035,
      "grad_norm": 1.018314242362976,
      "learning_rate": 0.00024032051732692522,
      "loss": 0.603,
      "step": 530250
    },
    {
      "epoch": 5.614013264803807,
      "grad_norm": 1.1138972043991089,
      "learning_rate": 0.0002402743598444983,
      "loss": 0.6037,
      "step": 530300
    },
    {
      "epoch": 5.61454258658381,
      "grad_norm": 1.0764623880386353,
      "learning_rate": 0.00024022820269410124,
      "loss": 0.5947,
      "step": 530350
    },
    {
      "epoch": 5.615071908363813,
      "grad_norm": 1.1156142950057983,
      "learning_rate": 0.00024018204587730974,
      "loss": 0.6026,
      "step": 530400
    },
    {
      "epoch": 5.615601230143817,
      "grad_norm": 1.1974893808364868,
      "learning_rate": 0.0002401358893956996,
      "loss": 0.6031,
      "step": 530450
    },
    {
      "epoch": 5.6161305519238205,
      "grad_norm": 1.1821033954620361,
      "learning_rate": 0.00024008973325084654,
      "loss": 0.5953,
      "step": 530500
    },
    {
      "epoch": 5.6161305519238205,
      "eval_loss": 0.39246243238449097,
      "eval_runtime": 46.7989,
      "eval_samples_per_second": 3588.331,
      "eval_steps_per_second": 448.557,
      "step": 530500
    },
    {
      "epoch": 5.616659873703823,
      "grad_norm": 1.1606818437576294,
      "learning_rate": 0.00024004450055713098,
      "loss": 0.5965,
      "step": 530550
    },
    {
      "epoch": 5.617189195483826,
      "grad_norm": 1.2175220251083374,
      "learning_rate": 0.0002399983450837059,
      "loss": 0.6093,
      "step": 530600
    },
    {
      "epoch": 5.61771851726383,
      "grad_norm": 1.1464974880218506,
      "learning_rate": 0.00023995218995173352,
      "loss": 0.6191,
      "step": 530650
    },
    {
      "epoch": 5.618247839043833,
      "grad_norm": 1.1259716749191284,
      "learning_rate": 0.00023990603516278974,
      "loss": 0.6001,
      "step": 530700
    },
    {
      "epoch": 5.618777160823837,
      "grad_norm": 1.3322683572769165,
      "learning_rate": 0.00023985988071845024,
      "loss": 0.6065,
      "step": 530750
    },
    {
      "epoch": 5.6193064826038395,
      "grad_norm": 1.0750296115875244,
      "learning_rate": 0.0002398137266202907,
      "loss": 0.6101,
      "step": 530800
    },
    {
      "epoch": 5.619835804383843,
      "grad_norm": 1.1601835489273071,
      "learning_rate": 0.00023976757286988678,
      "loss": 0.6093,
      "step": 530850
    },
    {
      "epoch": 5.620365126163846,
      "grad_norm": 1.0645337104797363,
      "learning_rate": 0.00023972141946881418,
      "loss": 0.6021,
      "step": 530900
    },
    {
      "epoch": 5.62089444794385,
      "grad_norm": 1.1814059019088745,
      "learning_rate": 0.0002396752664186485,
      "loss": 0.6104,
      "step": 530950
    },
    {
      "epoch": 5.621423769723853,
      "grad_norm": 1.0765516757965088,
      "learning_rate": 0.00023962911372096553,
      "loss": 0.6051,
      "step": 531000
    },
    {
      "epoch": 5.621423769723853,
      "eval_loss": 0.3921467065811157,
      "eval_runtime": 46.7843,
      "eval_samples_per_second": 3589.45,
      "eval_steps_per_second": 448.697,
      "step": 531000
    },
    {
      "epoch": 5.6219530915038565,
      "grad_norm": 1.0819581747055054,
      "learning_rate": 0.0002395829613773407,
      "loss": 0.6034,
      "step": 531050
    },
    {
      "epoch": 5.622482413283859,
      "grad_norm": 1.2029176950454712,
      "learning_rate": 0.0002395368093893499,
      "loss": 0.597,
      "step": 531100
    },
    {
      "epoch": 5.623011735063862,
      "grad_norm": 1.1891741752624512,
      "learning_rate": 0.00023949065775856842,
      "loss": 0.6037,
      "step": 531150
    },
    {
      "epoch": 5.623541056843866,
      "grad_norm": 1.1605709791183472,
      "learning_rate": 0.00023944450648657217,
      "loss": 0.5971,
      "step": 531200
    },
    {
      "epoch": 5.62407037862387,
      "grad_norm": 1.118510365486145,
      "learning_rate": 0.00023939835557493648,
      "loss": 0.6082,
      "step": 531250
    },
    {
      "epoch": 5.624599700403873,
      "grad_norm": 1.0721228122711182,
      "learning_rate": 0.00023935220502523715,
      "loss": 0.6034,
      "step": 531300
    },
    {
      "epoch": 5.6251290221838754,
      "grad_norm": 1.130171298980713,
      "learning_rate": 0.00023930605483904954,
      "loss": 0.6044,
      "step": 531350
    },
    {
      "epoch": 5.625658343963879,
      "grad_norm": 1.1418516635894775,
      "learning_rate": 0.0002392599050179494,
      "loss": 0.602,
      "step": 531400
    },
    {
      "epoch": 5.626187665743882,
      "grad_norm": 1.1138145923614502,
      "learning_rate": 0.00023921375556351204,
      "loss": 0.6082,
      "step": 531450
    },
    {
      "epoch": 5.626716987523886,
      "grad_norm": 1.1587300300598145,
      "learning_rate": 0.00023916760647731326,
      "loss": 0.5998,
      "step": 531500
    },
    {
      "epoch": 5.626716987523886,
      "eval_loss": 0.39189279079437256,
      "eval_runtime": 46.8009,
      "eval_samples_per_second": 3588.177,
      "eval_steps_per_second": 448.538,
      "step": 531500
    },
    {
      "epoch": 5.627246309303889,
      "grad_norm": 1.090149164199829,
      "learning_rate": 0.00023912145776092827,
      "loss": 0.6142,
      "step": 531550
    },
    {
      "epoch": 5.6277756310838924,
      "grad_norm": 1.0607292652130127,
      "learning_rate": 0.00023907530941593281,
      "loss": 0.6017,
      "step": 531600
    },
    {
      "epoch": 5.628304952863895,
      "grad_norm": 1.1274293661117554,
      "learning_rate": 0.00023902916144390225,
      "loss": 0.6064,
      "step": 531650
    },
    {
      "epoch": 5.628834274643899,
      "grad_norm": 1.0914051532745361,
      "learning_rate": 0.0002389830138464121,
      "loss": 0.6091,
      "step": 531700
    },
    {
      "epoch": 5.629363596423902,
      "grad_norm": 1.1019481420516968,
      "learning_rate": 0.00023893686662503777,
      "loss": 0.6064,
      "step": 531750
    },
    {
      "epoch": 5.629892918203906,
      "grad_norm": 1.1917098760604858,
      "learning_rate": 0.00023889071978135486,
      "loss": 0.6052,
      "step": 531800
    },
    {
      "epoch": 5.630422239983909,
      "grad_norm": 1.0317575931549072,
      "learning_rate": 0.00023884457331693862,
      "loss": 0.592,
      "step": 531850
    },
    {
      "epoch": 5.630951561763911,
      "grad_norm": 1.2523667812347412,
      "learning_rate": 0.00023879842723336465,
      "loss": 0.5934,
      "step": 531900
    },
    {
      "epoch": 5.631480883543915,
      "grad_norm": 1.0633422136306763,
      "learning_rate": 0.00023875228153220814,
      "loss": 0.6084,
      "step": 531950
    },
    {
      "epoch": 5.632010205323919,
      "grad_norm": 1.1965525150299072,
      "learning_rate": 0.0002387061362150447,
      "loss": 0.6063,
      "step": 532000
    },
    {
      "epoch": 5.632010205323919,
      "eval_loss": 0.3904263973236084,
      "eval_runtime": 46.8879,
      "eval_samples_per_second": 3581.52,
      "eval_steps_per_second": 447.706,
      "step": 532000
    },
    {
      "epoch": 5.632539527103922,
      "grad_norm": 1.144397258758545,
      "learning_rate": 0.0002386599912834496,
      "loss": 0.6043,
      "step": 532050
    },
    {
      "epoch": 5.633068848883925,
      "grad_norm": 1.1681779623031616,
      "learning_rate": 0.00023861384673899827,
      "loss": 0.592,
      "step": 532100
    },
    {
      "epoch": 5.633598170663928,
      "grad_norm": 0.9683228135108948,
      "learning_rate": 0.000238567702583266,
      "loss": 0.6034,
      "step": 532150
    },
    {
      "epoch": 5.634127492443931,
      "grad_norm": 1.1653891801834106,
      "learning_rate": 0.00023852155881782822,
      "loss": 0.5951,
      "step": 532200
    },
    {
      "epoch": 5.634656814223935,
      "grad_norm": 1.1367988586425781,
      "learning_rate": 0.0002384754154442601,
      "loss": 0.6012,
      "step": 532250
    },
    {
      "epoch": 5.635186136003938,
      "grad_norm": 1.078121542930603,
      "learning_rate": 0.0002384292724641372,
      "loss": 0.5984,
      "step": 532300
    },
    {
      "epoch": 5.635715457783942,
      "grad_norm": 1.075128436088562,
      "learning_rate": 0.0002383831298790346,
      "loss": 0.6008,
      "step": 532350
    },
    {
      "epoch": 5.6362447795639445,
      "grad_norm": 1.0678764581680298,
      "learning_rate": 0.00023833698769052772,
      "loss": 0.5978,
      "step": 532400
    },
    {
      "epoch": 5.636774101343948,
      "grad_norm": 1.135414481163025,
      "learning_rate": 0.00023829084590019182,
      "loss": 0.6003,
      "step": 532450
    },
    {
      "epoch": 5.637303423123951,
      "grad_norm": 1.194822072982788,
      "learning_rate": 0.0002382447045096021,
      "loss": 0.6019,
      "step": 532500
    },
    {
      "epoch": 5.637303423123951,
      "eval_loss": 0.3921310603618622,
      "eval_runtime": 46.7212,
      "eval_samples_per_second": 3594.303,
      "eval_steps_per_second": 449.304,
      "step": 532500
    },
    {
      "epoch": 5.637832744903955,
      "grad_norm": 1.1356124877929688,
      "learning_rate": 0.00023819856352033387,
      "loss": 0.6035,
      "step": 532550
    },
    {
      "epoch": 5.638362066683958,
      "grad_norm": 0.9715762734413147,
      "learning_rate": 0.00023815334574173126,
      "loss": 0.6023,
      "step": 532600
    },
    {
      "epoch": 5.638891388463961,
      "grad_norm": 1.1227823495864868,
      "learning_rate": 0.00023810720555172678,
      "loss": 0.6077,
      "step": 532650
    },
    {
      "epoch": 5.639420710243964,
      "grad_norm": 1.087572693824768,
      "learning_rate": 0.00023806106576773804,
      "loss": 0.6093,
      "step": 532700
    },
    {
      "epoch": 5.639950032023968,
      "grad_norm": 1.088240385055542,
      "learning_rate": 0.00023801492639134004,
      "loss": 0.593,
      "step": 532750
    },
    {
      "epoch": 5.640479353803971,
      "grad_norm": 1.177833914756775,
      "learning_rate": 0.00023796878742410815,
      "loss": 0.6056,
      "step": 532800
    },
    {
      "epoch": 5.641008675583974,
      "grad_norm": 1.0881739854812622,
      "learning_rate": 0.00023792264886761733,
      "loss": 0.5914,
      "step": 532850
    },
    {
      "epoch": 5.641537997363978,
      "grad_norm": 1.2474268674850464,
      "learning_rate": 0.00023787651072344296,
      "loss": 0.6154,
      "step": 532900
    },
    {
      "epoch": 5.6420673191439805,
      "grad_norm": 1.1015465259552002,
      "learning_rate": 0.00023783037299315998,
      "loss": 0.5985,
      "step": 532950
    },
    {
      "epoch": 5.642596640923984,
      "grad_norm": 1.0818347930908203,
      "learning_rate": 0.00023778423567834365,
      "loss": 0.5953,
      "step": 533000
    },
    {
      "epoch": 5.642596640923984,
      "eval_loss": 0.3905150592327118,
      "eval_runtime": 46.7457,
      "eval_samples_per_second": 3592.417,
      "eval_steps_per_second": 449.068,
      "step": 533000
    },
    {
      "epoch": 5.643125962703987,
      "grad_norm": 1.1190881729125977,
      "learning_rate": 0.00023773809878056902,
      "loss": 0.5937,
      "step": 533050
    },
    {
      "epoch": 5.643655284483991,
      "grad_norm": 1.084652066230774,
      "learning_rate": 0.00023769196230141122,
      "loss": 0.6018,
      "step": 533100
    },
    {
      "epoch": 5.644184606263994,
      "grad_norm": 1.0337114334106445,
      "learning_rate": 0.00023764582624244524,
      "loss": 0.613,
      "step": 533150
    },
    {
      "epoch": 5.6447139280439975,
      "grad_norm": 1.073938012123108,
      "learning_rate": 0.00023759969060524634,
      "loss": 0.5903,
      "step": 533200
    },
    {
      "epoch": 5.645243249824,
      "grad_norm": 1.1879318952560425,
      "learning_rate": 0.00023755355539138934,
      "loss": 0.604,
      "step": 533250
    },
    {
      "epoch": 5.645772571604004,
      "grad_norm": 0.96883225440979,
      "learning_rate": 0.00023750742060244952,
      "loss": 0.6041,
      "step": 533300
    },
    {
      "epoch": 5.646301893384007,
      "grad_norm": 1.059084177017212,
      "learning_rate": 0.00023746128624000165,
      "loss": 0.603,
      "step": 533350
    },
    {
      "epoch": 5.64683121516401,
      "grad_norm": 1.1004444360733032,
      "learning_rate": 0.00023741515230562099,
      "loss": 0.6008,
      "step": 533400
    },
    {
      "epoch": 5.647360536944014,
      "grad_norm": 0.9915013313293457,
      "learning_rate": 0.0002373690188008823,
      "loss": 0.6026,
      "step": 533450
    },
    {
      "epoch": 5.647889858724017,
      "grad_norm": 1.0610909461975098,
      "learning_rate": 0.0002373228857273608,
      "loss": 0.6025,
      "step": 533500
    },
    {
      "epoch": 5.647889858724017,
      "eval_loss": 0.392586886882782,
      "eval_runtime": 47.3605,
      "eval_samples_per_second": 3545.779,
      "eval_steps_per_second": 443.238,
      "step": 533500
    },
    {
      "epoch": 5.64841918050402,
      "grad_norm": 1.0351179838180542,
      "learning_rate": 0.0002372767530866312,
      "loss": 0.6054,
      "step": 533550
    },
    {
      "epoch": 5.648948502284023,
      "grad_norm": 1.0361673831939697,
      "learning_rate": 0.0002372306208802687,
      "loss": 0.5977,
      "step": 533600
    },
    {
      "epoch": 5.649477824064027,
      "grad_norm": 1.073174238204956,
      "learning_rate": 0.000237184489109848,
      "loss": 0.5991,
      "step": 533650
    },
    {
      "epoch": 5.65000714584403,
      "grad_norm": 1.0994206666946411,
      "learning_rate": 0.0002371383577769443,
      "loss": 0.6028,
      "step": 533700
    },
    {
      "epoch": 5.6505364676240335,
      "grad_norm": 1.1795343160629272,
      "learning_rate": 0.00023709222688313218,
      "loss": 0.6065,
      "step": 533750
    },
    {
      "epoch": 5.651065789404036,
      "grad_norm": 1.1037938594818115,
      "learning_rate": 0.00023704609642998678,
      "loss": 0.6007,
      "step": 533800
    },
    {
      "epoch": 5.65159511118404,
      "grad_norm": 1.0985184907913208,
      "learning_rate": 0.0002369999664190829,
      "loss": 0.6027,
      "step": 533850
    },
    {
      "epoch": 5.652124432964043,
      "grad_norm": 1.0780552625656128,
      "learning_rate": 0.0002369538368519954,
      "loss": 0.6132,
      "step": 533900
    },
    {
      "epoch": 5.652653754744047,
      "grad_norm": 1.066758155822754,
      "learning_rate": 0.00023690770773029908,
      "loss": 0.5946,
      "step": 533950
    },
    {
      "epoch": 5.65318307652405,
      "grad_norm": 1.0836594104766846,
      "learning_rate": 0.00023686157905556887,
      "loss": 0.6051,
      "step": 534000
    },
    {
      "epoch": 5.65318307652405,
      "eval_loss": 0.39256545901298523,
      "eval_runtime": 46.8232,
      "eval_samples_per_second": 3586.472,
      "eval_steps_per_second": 448.325,
      "step": 534000
    },
    {
      "epoch": 5.653712398304053,
      "grad_norm": 1.0973204374313354,
      "learning_rate": 0.0002368154508293795,
      "loss": 0.6001,
      "step": 534050
    },
    {
      "epoch": 5.654241720084056,
      "grad_norm": 1.1867671012878418,
      "learning_rate": 0.00023676932305330588,
      "loss": 0.604,
      "step": 534100
    },
    {
      "epoch": 5.654771041864059,
      "grad_norm": 1.1468281745910645,
      "learning_rate": 0.0002367231957289226,
      "loss": 0.6134,
      "step": 534150
    },
    {
      "epoch": 5.655300363644063,
      "grad_norm": 1.1926493644714355,
      "learning_rate": 0.00023667706885780466,
      "loss": 0.6081,
      "step": 534200
    },
    {
      "epoch": 5.655829685424067,
      "grad_norm": 1.041550874710083,
      "learning_rate": 0.0002366309424415266,
      "loss": 0.5948,
      "step": 534250
    },
    {
      "epoch": 5.6563590072040695,
      "grad_norm": 1.0706977844238281,
      "learning_rate": 0.00023658481648166336,
      "loss": 0.6059,
      "step": 534300
    },
    {
      "epoch": 5.656888328984072,
      "grad_norm": 1.1471617221832275,
      "learning_rate": 0.00023653869097978948,
      "loss": 0.5883,
      "step": 534350
    },
    {
      "epoch": 5.657417650764076,
      "grad_norm": 1.1484849452972412,
      "learning_rate": 0.00023649256593747983,
      "loss": 0.6056,
      "step": 534400
    },
    {
      "epoch": 5.657946972544079,
      "grad_norm": 1.1152364015579224,
      "learning_rate": 0.00023644644135630894,
      "loss": 0.5929,
      "step": 534450
    },
    {
      "epoch": 5.658476294324083,
      "grad_norm": 0.9859641790390015,
      "learning_rate": 0.00023640031723785168,
      "loss": 0.5993,
      "step": 534500
    },
    {
      "epoch": 5.658476294324083,
      "eval_loss": 0.38985905051231384,
      "eval_runtime": 46.8219,
      "eval_samples_per_second": 3586.57,
      "eval_steps_per_second": 448.337,
      "step": 534500
    },
    {
      "epoch": 5.659005616104086,
      "grad_norm": 1.0280922651290894,
      "learning_rate": 0.00023635419358368248,
      "loss": 0.6008,
      "step": 534550
    },
    {
      "epoch": 5.659534937884089,
      "grad_norm": 1.194490909576416,
      "learning_rate": 0.00023630899285456664,
      "loss": 0.5968,
      "step": 534600
    },
    {
      "epoch": 5.660064259664092,
      "grad_norm": 1.0909936428070068,
      "learning_rate": 0.00023626287012433366,
      "loss": 0.6017,
      "step": 534650
    },
    {
      "epoch": 5.660593581444096,
      "grad_norm": 1.2160351276397705,
      "learning_rate": 0.00023621674786308117,
      "loss": 0.6007,
      "step": 534700
    },
    {
      "epoch": 5.661122903224099,
      "grad_norm": 1.0146095752716064,
      "learning_rate": 0.00023617062607238394,
      "loss": 0.6003,
      "step": 534750
    },
    {
      "epoch": 5.661652225004103,
      "grad_norm": 1.085327386856079,
      "learning_rate": 0.00023612450475381634,
      "loss": 0.5868,
      "step": 534800
    },
    {
      "epoch": 5.6621815467841055,
      "grad_norm": 1.1420704126358032,
      "learning_rate": 0.00023607838390895318,
      "loss": 0.5913,
      "step": 534850
    },
    {
      "epoch": 5.662710868564108,
      "grad_norm": 1.258638858795166,
      "learning_rate": 0.00023603226353936877,
      "loss": 0.606,
      "step": 534900
    },
    {
      "epoch": 5.663240190344112,
      "grad_norm": 1.1776518821716309,
      "learning_rate": 0.0002359861436466379,
      "loss": 0.5966,
      "step": 534950
    },
    {
      "epoch": 5.663769512124116,
      "grad_norm": 1.104178786277771,
      "learning_rate": 0.0002359400242323348,
      "loss": 0.5967,
      "step": 535000
    },
    {
      "epoch": 5.663769512124116,
      "eval_loss": 0.3899092972278595,
      "eval_runtime": 46.7819,
      "eval_samples_per_second": 3589.637,
      "eval_steps_per_second": 448.721,
      "step": 535000
    },
    {
      "epoch": 5.664298833904119,
      "grad_norm": 1.0589964389801025,
      "learning_rate": 0.0002358939052980342,
      "loss": 0.6124,
      "step": 535050
    },
    {
      "epoch": 5.664828155684122,
      "grad_norm": 1.1758275032043457,
      "learning_rate": 0.00023584778684531047,
      "loss": 0.6084,
      "step": 535100
    },
    {
      "epoch": 5.665357477464125,
      "grad_norm": 1.1483696699142456,
      "learning_rate": 0.00023580166887573814,
      "loss": 0.6038,
      "step": 535150
    },
    {
      "epoch": 5.665886799244128,
      "grad_norm": 1.2261543273925781,
      "learning_rate": 0.00023575555139089156,
      "loss": 0.5975,
      "step": 535200
    },
    {
      "epoch": 5.666416121024132,
      "grad_norm": 1.0526427030563354,
      "learning_rate": 0.00023570943439234533,
      "loss": 0.5971,
      "step": 535250
    },
    {
      "epoch": 5.666945442804135,
      "grad_norm": 1.126359462738037,
      "learning_rate": 0.00023566331788167367,
      "loss": 0.6005,
      "step": 535300
    },
    {
      "epoch": 5.667474764584139,
      "grad_norm": 1.1854498386383057,
      "learning_rate": 0.00023561720186045118,
      "loss": 0.6019,
      "step": 535350
    },
    {
      "epoch": 5.668004086364141,
      "grad_norm": 1.0783686637878418,
      "learning_rate": 0.00023557108633025204,
      "loss": 0.6021,
      "step": 535400
    },
    {
      "epoch": 5.668533408144145,
      "grad_norm": 1.1655603647232056,
      "learning_rate": 0.00023552497129265083,
      "loss": 0.6063,
      "step": 535450
    },
    {
      "epoch": 5.669062729924148,
      "grad_norm": 1.2846847772598267,
      "learning_rate": 0.0002354788567492217,
      "loss": 0.598,
      "step": 535500
    },
    {
      "epoch": 5.669062729924148,
      "eval_loss": 0.38977253437042236,
      "eval_runtime": 46.7913,
      "eval_samples_per_second": 3588.914,
      "eval_steps_per_second": 448.63,
      "step": 535500
    },
    {
      "epoch": 5.669592051704152,
      "grad_norm": 1.0105303525924683,
      "learning_rate": 0.00023543274270153918,
      "loss": 0.593,
      "step": 535550
    },
    {
      "epoch": 5.670121373484155,
      "grad_norm": 1.2447216510772705,
      "learning_rate": 0.00023538662915117734,
      "loss": 0.6085,
      "step": 535600
    },
    {
      "epoch": 5.6706506952641575,
      "grad_norm": 1.033207893371582,
      "learning_rate": 0.00023534051609971074,
      "loss": 0.593,
      "step": 535650
    },
    {
      "epoch": 5.671180017044161,
      "grad_norm": 1.2181001901626587,
      "learning_rate": 0.00023529440354871345,
      "loss": 0.5991,
      "step": 535700
    },
    {
      "epoch": 5.671709338824165,
      "grad_norm": 1.1305278539657593,
      "learning_rate": 0.00023524829149975995,
      "loss": 0.5953,
      "step": 535750
    },
    {
      "epoch": 5.672238660604168,
      "grad_norm": 0.9995354413986206,
      "learning_rate": 0.00023520217995442425,
      "loss": 0.6095,
      "step": 535800
    },
    {
      "epoch": 5.672767982384171,
      "grad_norm": 1.2503414154052734,
      "learning_rate": 0.00023515606891428073,
      "loss": 0.603,
      "step": 535850
    },
    {
      "epoch": 5.6732973041641745,
      "grad_norm": 1.0845752954483032,
      "learning_rate": 0.0002351099583809036,
      "loss": 0.6004,
      "step": 535900
    },
    {
      "epoch": 5.673826625944177,
      "grad_norm": 1.2376481294631958,
      "learning_rate": 0.00023506384835586704,
      "loss": 0.6132,
      "step": 535950
    },
    {
      "epoch": 5.674355947724181,
      "grad_norm": 1.09697687625885,
      "learning_rate": 0.00023501773884074517,
      "loss": 0.5989,
      "step": 536000
    },
    {
      "epoch": 5.674355947724181,
      "eval_loss": 0.39054664969444275,
      "eval_runtime": 46.6859,
      "eval_samples_per_second": 3597.015,
      "eval_steps_per_second": 449.643,
      "step": 536000
    },
    {
      "epoch": 5.674885269504184,
      "grad_norm": 1.118633508682251,
      "learning_rate": 0.00023497162983711223,
      "loss": 0.5972,
      "step": 536050
    },
    {
      "epoch": 5.675414591284188,
      "grad_norm": 1.1750953197479248,
      "learning_rate": 0.0002349255213465423,
      "loss": 0.5876,
      "step": 536100
    },
    {
      "epoch": 5.675943913064191,
      "grad_norm": 1.2006245851516724,
      "learning_rate": 0.00023487941337060965,
      "loss": 0.6058,
      "step": 536150
    },
    {
      "epoch": 5.676473234844194,
      "grad_norm": 1.1685384511947632,
      "learning_rate": 0.00023483330591088814,
      "loss": 0.6019,
      "step": 536200
    },
    {
      "epoch": 5.677002556624197,
      "grad_norm": 0.9852401614189148,
      "learning_rate": 0.00023478719896895213,
      "loss": 0.5937,
      "step": 536250
    },
    {
      "epoch": 5.677531878404201,
      "grad_norm": 1.1269116401672363,
      "learning_rate": 0.00023474109254637546,
      "loss": 0.5998,
      "step": 536300
    },
    {
      "epoch": 5.678061200184204,
      "grad_norm": 1.146728515625,
      "learning_rate": 0.0002346949866447324,
      "loss": 0.5949,
      "step": 536350
    },
    {
      "epoch": 5.678590521964207,
      "grad_norm": 1.1035298109054565,
      "learning_rate": 0.00023464888126559677,
      "loss": 0.6153,
      "step": 536400
    },
    {
      "epoch": 5.6791198437442105,
      "grad_norm": 1.2246770858764648,
      "learning_rate": 0.00023460277641054283,
      "loss": 0.5983,
      "step": 536450
    },
    {
      "epoch": 5.679649165524214,
      "grad_norm": 1.1775850057601929,
      "learning_rate": 0.00023455667208114434,
      "loss": 0.609,
      "step": 536500
    },
    {
      "epoch": 5.679649165524214,
      "eval_loss": 0.3924463093280792,
      "eval_runtime": 46.7795,
      "eval_samples_per_second": 3589.822,
      "eval_steps_per_second": 448.744,
      "step": 536500
    },
    {
      "epoch": 5.680178487304217,
      "grad_norm": 1.2060678005218506,
      "learning_rate": 0.00023451056827897553,
      "loss": 0.6068,
      "step": 536550
    },
    {
      "epoch": 5.68070780908422,
      "grad_norm": 1.1074645519256592,
      "learning_rate": 0.0002344644650056101,
      "loss": 0.6066,
      "step": 536600
    },
    {
      "epoch": 5.681237130864224,
      "grad_norm": 1.0827617645263672,
      "learning_rate": 0.00023441928431227406,
      "loss": 0.5905,
      "step": 536650
    },
    {
      "epoch": 5.681766452644227,
      "grad_norm": 1.193713903427124,
      "learning_rate": 0.00023437318209058305,
      "loss": 0.6037,
      "step": 536700
    },
    {
      "epoch": 5.68229577442423,
      "grad_norm": 1.1005473136901855,
      "learning_rate": 0.000234327080402386,
      "loss": 0.6004,
      "step": 536750
    },
    {
      "epoch": 5.682825096204233,
      "grad_norm": 1.108953833580017,
      "learning_rate": 0.00023428097924925654,
      "loss": 0.5956,
      "step": 536800
    },
    {
      "epoch": 5.683354417984237,
      "grad_norm": 1.2163902521133423,
      "learning_rate": 0.0002342348786327688,
      "loss": 0.5935,
      "step": 536850
    },
    {
      "epoch": 5.68388373976424,
      "grad_norm": 1.101702332496643,
      "learning_rate": 0.0002341887785544964,
      "loss": 0.6057,
      "step": 536900
    },
    {
      "epoch": 5.684413061544244,
      "grad_norm": 0.9920012950897217,
      "learning_rate": 0.00023414267901601343,
      "loss": 0.5925,
      "step": 536950
    },
    {
      "epoch": 5.6849423833242465,
      "grad_norm": 1.2139036655426025,
      "learning_rate": 0.00023409658001889347,
      "loss": 0.5987,
      "step": 537000
    },
    {
      "epoch": 5.6849423833242465,
      "eval_loss": 0.3887838125228882,
      "eval_runtime": 46.7126,
      "eval_samples_per_second": 3594.965,
      "eval_steps_per_second": 449.387,
      "step": 537000
    },
    {
      "epoch": 5.68547170510425,
      "grad_norm": 1.2216379642486572,
      "learning_rate": 0.00023405048156471058,
      "loss": 0.6069,
      "step": 537050
    },
    {
      "epoch": 5.686001026884253,
      "grad_norm": 0.9639776945114136,
      "learning_rate": 0.00023400438365503824,
      "loss": 0.5991,
      "step": 537100
    },
    {
      "epoch": 5.686530348664256,
      "grad_norm": 1.0597819089889526,
      "learning_rate": 0.0002339582862914505,
      "loss": 0.6031,
      "step": 537150
    },
    {
      "epoch": 5.68705967044426,
      "grad_norm": 1.0565463304519653,
      "learning_rate": 0.00023391218947552088,
      "loss": 0.6054,
      "step": 537200
    },
    {
      "epoch": 5.6875889922242635,
      "grad_norm": 1.130694031715393,
      "learning_rate": 0.00023386609320882323,
      "loss": 0.5945,
      "step": 537250
    },
    {
      "epoch": 5.688118314004266,
      "grad_norm": 1.139306664466858,
      "learning_rate": 0.0002338199974929313,
      "loss": 0.6021,
      "step": 537300
    },
    {
      "epoch": 5.688647635784269,
      "grad_norm": 1.2097458839416504,
      "learning_rate": 0.0002337739023294187,
      "loss": 0.5944,
      "step": 537350
    },
    {
      "epoch": 5.689176957564273,
      "grad_norm": 1.2872188091278076,
      "learning_rate": 0.0002337278077198591,
      "loss": 0.5957,
      "step": 537400
    },
    {
      "epoch": 5.689706279344276,
      "grad_norm": 1.1813716888427734,
      "learning_rate": 0.00023368171366582618,
      "loss": 0.5969,
      "step": 537450
    },
    {
      "epoch": 5.69023560112428,
      "grad_norm": 1.2051942348480225,
      "learning_rate": 0.00023363562016889356,
      "loss": 0.6063,
      "step": 537500
    },
    {
      "epoch": 5.69023560112428,
      "eval_loss": 0.38997215032577515,
      "eval_runtime": 46.7917,
      "eval_samples_per_second": 3588.883,
      "eval_steps_per_second": 448.626,
      "step": 537500
    },
    {
      "epoch": 5.6907649229042825,
      "grad_norm": 1.1804020404815674,
      "learning_rate": 0.0002335895272306349,
      "loss": 0.6056,
      "step": 537550
    },
    {
      "epoch": 5.691294244684286,
      "grad_norm": 1.1279375553131104,
      "learning_rate": 0.00023354343485262373,
      "loss": 0.5964,
      "step": 537600
    },
    {
      "epoch": 5.691823566464289,
      "grad_norm": 1.202683687210083,
      "learning_rate": 0.00023349734303643375,
      "loss": 0.5979,
      "step": 537650
    },
    {
      "epoch": 5.692352888244293,
      "grad_norm": 1.112834095954895,
      "learning_rate": 0.0002334512517836383,
      "loss": 0.6083,
      "step": 537700
    },
    {
      "epoch": 5.692882210024296,
      "grad_norm": 1.0315699577331543,
      "learning_rate": 0.00023340516109581115,
      "loss": 0.6037,
      "step": 537750
    },
    {
      "epoch": 5.6934115318042995,
      "grad_norm": 1.0869289636611938,
      "learning_rate": 0.0002333590709745256,
      "loss": 0.5936,
      "step": 537800
    },
    {
      "epoch": 5.693940853584302,
      "grad_norm": 1.286487102508545,
      "learning_rate": 0.0002333129814213554,
      "loss": 0.594,
      "step": 537850
    },
    {
      "epoch": 5.694470175364305,
      "grad_norm": 1.1671487092971802,
      "learning_rate": 0.00023326689243787378,
      "loss": 0.6019,
      "step": 537900
    },
    {
      "epoch": 5.694999497144309,
      "grad_norm": 1.1329982280731201,
      "learning_rate": 0.0002332208040256544,
      "loss": 0.5934,
      "step": 537950
    },
    {
      "epoch": 5.695528818924313,
      "grad_norm": 1.1236214637756348,
      "learning_rate": 0.00023317471618627053,
      "loss": 0.5978,
      "step": 538000
    },
    {
      "epoch": 5.695528818924313,
      "eval_loss": 0.3892693817615509,
      "eval_runtime": 46.7603,
      "eval_samples_per_second": 3591.292,
      "eval_steps_per_second": 448.928,
      "step": 538000
    },
    {
      "epoch": 5.696058140704316,
      "grad_norm": 1.0777479410171509,
      "learning_rate": 0.00023312862892129577,
      "loss": 0.5991,
      "step": 538050
    },
    {
      "epoch": 5.6965874624843185,
      "grad_norm": 1.1439249515533447,
      "learning_rate": 0.00023308254223230334,
      "loss": 0.5926,
      "step": 538100
    },
    {
      "epoch": 5.697116784264322,
      "grad_norm": 1.0698399543762207,
      "learning_rate": 0.00023303645612086677,
      "loss": 0.6055,
      "step": 538150
    },
    {
      "epoch": 5.697646106044325,
      "grad_norm": 1.1882579326629639,
      "learning_rate": 0.00023299037058855938,
      "loss": 0.6048,
      "step": 538200
    },
    {
      "epoch": 5.698175427824329,
      "grad_norm": 1.1232357025146484,
      "learning_rate": 0.00023294428563695448,
      "loss": 0.599,
      "step": 538250
    },
    {
      "epoch": 5.698704749604332,
      "grad_norm": 1.1171995401382446,
      "learning_rate": 0.00023289820126762533,
      "loss": 0.5966,
      "step": 538300
    },
    {
      "epoch": 5.6992340713843355,
      "grad_norm": 1.2053062915802002,
      "learning_rate": 0.00023285211748214546,
      "loss": 0.6069,
      "step": 538350
    },
    {
      "epoch": 5.699763393164338,
      "grad_norm": 1.2151073217391968,
      "learning_rate": 0.00023280603428208792,
      "loss": 0.6078,
      "step": 538400
    },
    {
      "epoch": 5.700292714944342,
      "grad_norm": 1.2180684804916382,
      "learning_rate": 0.00023275995166902613,
      "loss": 0.5922,
      "step": 538450
    },
    {
      "epoch": 5.700822036724345,
      "grad_norm": 1.1868818998336792,
      "learning_rate": 0.00023271386964453318,
      "loss": 0.5988,
      "step": 538500
    },
    {
      "epoch": 5.700822036724345,
      "eval_loss": 0.3886643052101135,
      "eval_runtime": 46.7569,
      "eval_samples_per_second": 3591.559,
      "eval_steps_per_second": 448.961,
      "step": 538500
    },
    {
      "epoch": 5.701351358504349,
      "grad_norm": 1.0736064910888672,
      "learning_rate": 0.00023266778821018247,
      "loss": 0.6081,
      "step": 538550
    },
    {
      "epoch": 5.701880680284352,
      "grad_norm": 1.065383791923523,
      "learning_rate": 0.00023262170736754705,
      "loss": 0.5918,
      "step": 538600
    },
    {
      "epoch": 5.702410002064354,
      "grad_norm": 1.1792057752609253,
      "learning_rate": 0.00023257654871736274,
      "loss": 0.6081,
      "step": 538650
    },
    {
      "epoch": 5.702939323844358,
      "grad_norm": 1.1771152019500732,
      "learning_rate": 0.00023253046905096495,
      "loss": 0.5956,
      "step": 538700
    },
    {
      "epoch": 5.703468645624362,
      "grad_norm": 1.010321855545044,
      "learning_rate": 0.00023248438998097046,
      "loss": 0.6072,
      "step": 538750
    },
    {
      "epoch": 5.703997967404365,
      "grad_norm": 1.104384183883667,
      "learning_rate": 0.0002324383115089526,
      "loss": 0.5917,
      "step": 538800
    },
    {
      "epoch": 5.704527289184368,
      "grad_norm": 1.2239280939102173,
      "learning_rate": 0.0002323922336364842,
      "loss": 0.5966,
      "step": 538850
    },
    {
      "epoch": 5.705056610964371,
      "grad_norm": 1.1073002815246582,
      "learning_rate": 0.00023234615636513864,
      "loss": 0.5998,
      "step": 538900
    },
    {
      "epoch": 5.705585932744374,
      "grad_norm": 1.0864325761795044,
      "learning_rate": 0.0002323000796964887,
      "loss": 0.5972,
      "step": 538950
    },
    {
      "epoch": 5.706115254524378,
      "grad_norm": 1.0309075117111206,
      "learning_rate": 0.00023225400363210762,
      "loss": 0.5974,
      "step": 539000
    },
    {
      "epoch": 5.706115254524378,
      "eval_loss": 0.38847702741622925,
      "eval_runtime": 46.7979,
      "eval_samples_per_second": 3588.406,
      "eval_steps_per_second": 448.567,
      "step": 539000
    },
    {
      "epoch": 5.706644576304381,
      "grad_norm": 1.0798125267028809,
      "learning_rate": 0.0002322079281735683,
      "loss": 0.604,
      "step": 539050
    },
    {
      "epoch": 5.707173898084385,
      "grad_norm": 1.1470842361450195,
      "learning_rate": 0.0002321618533224439,
      "loss": 0.6012,
      "step": 539100
    },
    {
      "epoch": 5.707703219864388,
      "grad_norm": 1.2198667526245117,
      "learning_rate": 0.00023211577908030713,
      "loss": 0.5912,
      "step": 539150
    },
    {
      "epoch": 5.708232541644391,
      "grad_norm": 1.1091305017471313,
      "learning_rate": 0.0002320697054487312,
      "loss": 0.6034,
      "step": 539200
    },
    {
      "epoch": 5.708761863424394,
      "grad_norm": 1.1643894910812378,
      "learning_rate": 0.00023202363242928888,
      "loss": 0.6106,
      "step": 539250
    },
    {
      "epoch": 5.709291185204398,
      "grad_norm": 1.1172431707382202,
      "learning_rate": 0.00023197756002355327,
      "loss": 0.6042,
      "step": 539300
    },
    {
      "epoch": 5.709820506984401,
      "grad_norm": 1.1325494050979614,
      "learning_rate": 0.00023193148823309702,
      "loss": 0.6069,
      "step": 539350
    },
    {
      "epoch": 5.710349828764405,
      "grad_norm": 1.1297266483306885,
      "learning_rate": 0.0002318854170594932,
      "loss": 0.6079,
      "step": 539400
    },
    {
      "epoch": 5.710879150544407,
      "grad_norm": 1.1619900465011597,
      "learning_rate": 0.0002318393465043146,
      "loss": 0.606,
      "step": 539450
    },
    {
      "epoch": 5.711408472324411,
      "grad_norm": 0.9974457621574402,
      "learning_rate": 0.00023179327656913404,
      "loss": 0.5951,
      "step": 539500
    },
    {
      "epoch": 5.711408472324411,
      "eval_loss": 0.3880200684070587,
      "eval_runtime": 46.7978,
      "eval_samples_per_second": 3588.417,
      "eval_steps_per_second": 448.568,
      "step": 539500
    },
    {
      "epoch": 5.711937794104414,
      "grad_norm": 1.1260464191436768,
      "learning_rate": 0.0002317472072555243,
      "loss": 0.6112,
      "step": 539550
    },
    {
      "epoch": 5.712467115884417,
      "grad_norm": 1.129706859588623,
      "learning_rate": 0.0002317011385650583,
      "loss": 0.5936,
      "step": 539600
    },
    {
      "epoch": 5.712996437664421,
      "grad_norm": 1.148681402206421,
      "learning_rate": 0.0002316550704993086,
      "loss": 0.6054,
      "step": 539650
    },
    {
      "epoch": 5.7135257594444235,
      "grad_norm": 1.1521819829940796,
      "learning_rate": 0.00023160900305984822,
      "loss": 0.5916,
      "step": 539700
    },
    {
      "epoch": 5.714055081224427,
      "grad_norm": 1.0468727350234985,
      "learning_rate": 0.0002315629362482496,
      "loss": 0.6134,
      "step": 539750
    },
    {
      "epoch": 5.71458440300443,
      "grad_norm": 1.1539489030838013,
      "learning_rate": 0.0002315168700660857,
      "loss": 0.5943,
      "step": 539800
    },
    {
      "epoch": 5.715113724784434,
      "grad_norm": 1.0888657569885254,
      "learning_rate": 0.00023147080451492894,
      "loss": 0.588,
      "step": 539850
    },
    {
      "epoch": 5.715643046564437,
      "grad_norm": 1.1180527210235596,
      "learning_rate": 0.00023142473959635225,
      "loss": 0.6002,
      "step": 539900
    },
    {
      "epoch": 5.7161723683444405,
      "grad_norm": 1.1965683698654175,
      "learning_rate": 0.000231378675311928,
      "loss": 0.6067,
      "step": 539950
    },
    {
      "epoch": 5.716701690124443,
      "grad_norm": 1.2178194522857666,
      "learning_rate": 0.00023133261166322905,
      "loss": 0.5973,
      "step": 540000
    },
    {
      "epoch": 5.716701690124443,
      "eval_loss": 0.38715219497680664,
      "eval_runtime": 46.719,
      "eval_samples_per_second": 3594.468,
      "eval_steps_per_second": 449.325,
      "step": 540000
    },
    {
      "epoch": 5.717231011904447,
      "grad_norm": 1.1667745113372803,
      "learning_rate": 0.00023128654865182783,
      "loss": 0.6005,
      "step": 540050
    },
    {
      "epoch": 5.71776033368445,
      "grad_norm": 1.012040138244629,
      "learning_rate": 0.00023124048627929706,
      "loss": 0.5999,
      "step": 540100
    },
    {
      "epoch": 5.718289655464454,
      "grad_norm": 1.04435396194458,
      "learning_rate": 0.00023119442454720907,
      "loss": 0.5974,
      "step": 540150
    },
    {
      "epoch": 5.718818977244457,
      "grad_norm": 1.0572900772094727,
      "learning_rate": 0.00023114836345713662,
      "loss": 0.6003,
      "step": 540200
    },
    {
      "epoch": 5.71934829902446,
      "grad_norm": 1.199663519859314,
      "learning_rate": 0.00023110230301065214,
      "loss": 0.6004,
      "step": 540250
    },
    {
      "epoch": 5.719877620804463,
      "grad_norm": 1.050241231918335,
      "learning_rate": 0.00023105624320932805,
      "loss": 0.6027,
      "step": 540300
    },
    {
      "epoch": 5.720406942584466,
      "grad_norm": 1.113681674003601,
      "learning_rate": 0.00023101018405473686,
      "loss": 0.5886,
      "step": 540350
    },
    {
      "epoch": 5.72093626436447,
      "grad_norm": 1.091530442237854,
      "learning_rate": 0.00023096412554845114,
      "loss": 0.6023,
      "step": 540400
    },
    {
      "epoch": 5.721465586144473,
      "grad_norm": 1.1836349964141846,
      "learning_rate": 0.00023091806769204304,
      "loss": 0.6076,
      "step": 540450
    },
    {
      "epoch": 5.7219949079244765,
      "grad_norm": 1.2626911401748657,
      "learning_rate": 0.00023087201048708526,
      "loss": 0.6007,
      "step": 540500
    },
    {
      "epoch": 5.7219949079244765,
      "eval_loss": 0.3877374231815338,
      "eval_runtime": 46.7473,
      "eval_samples_per_second": 3592.293,
      "eval_steps_per_second": 449.053,
      "step": 540500
    },
    {
      "epoch": 5.722524229704479,
      "grad_norm": 1.0082337856292725,
      "learning_rate": 0.0002308259539351499,
      "loss": 0.6111,
      "step": 540550
    },
    {
      "epoch": 5.723053551484483,
      "grad_norm": 1.0765854120254517,
      "learning_rate": 0.00023077989803780956,
      "loss": 0.5969,
      "step": 540600
    },
    {
      "epoch": 5.723582873264486,
      "grad_norm": 1.1030550003051758,
      "learning_rate": 0.00023073476389501922,
      "loss": 0.6041,
      "step": 540650
    },
    {
      "epoch": 5.72411219504449,
      "grad_norm": 1.1985085010528564,
      "learning_rate": 0.0002306887092984154,
      "loss": 0.6007,
      "step": 540700
    },
    {
      "epoch": 5.724641516824493,
      "grad_norm": 1.2977089881896973,
      "learning_rate": 0.00023064265536109195,
      "loss": 0.5925,
      "step": 540750
    },
    {
      "epoch": 5.725170838604496,
      "grad_norm": 1.2568895816802979,
      "learning_rate": 0.00023059660208462108,
      "loss": 0.6019,
      "step": 540800
    },
    {
      "epoch": 5.725700160384499,
      "grad_norm": 1.1568032503128052,
      "learning_rate": 0.00023055054947057523,
      "loss": 0.5902,
      "step": 540850
    },
    {
      "epoch": 5.726229482164503,
      "grad_norm": 1.1836284399032593,
      "learning_rate": 0.00023050449752052638,
      "loss": 0.6033,
      "step": 540900
    },
    {
      "epoch": 5.726758803944506,
      "grad_norm": 1.1864423751831055,
      "learning_rate": 0.00023045844623604693,
      "loss": 0.5959,
      "step": 540950
    },
    {
      "epoch": 5.72728812572451,
      "grad_norm": 1.1745529174804688,
      "learning_rate": 0.00023041239561870887,
      "loss": 0.5991,
      "step": 541000
    },
    {
      "epoch": 5.72728812572451,
      "eval_loss": 0.38825997710227966,
      "eval_runtime": 46.8132,
      "eval_samples_per_second": 3587.239,
      "eval_steps_per_second": 448.421,
      "step": 541000
    },
    {
      "epoch": 5.7278174475045125,
      "grad_norm": 1.1724382638931274,
      "learning_rate": 0.0002303663456700845,
      "loss": 0.591,
      "step": 541050
    },
    {
      "epoch": 5.728346769284515,
      "grad_norm": 1.1350092887878418,
      "learning_rate": 0.00023032029639174584,
      "loss": 0.5913,
      "step": 541100
    },
    {
      "epoch": 5.728876091064519,
      "grad_norm": 1.1118569374084473,
      "learning_rate": 0.0002302742477852651,
      "loss": 0.5876,
      "step": 541150
    },
    {
      "epoch": 5.729405412844522,
      "grad_norm": 1.1331253051757812,
      "learning_rate": 0.00023022819985221425,
      "loss": 0.5874,
      "step": 541200
    },
    {
      "epoch": 5.729934734624526,
      "grad_norm": 1.0526700019836426,
      "learning_rate": 0.0002301821525941655,
      "loss": 0.5991,
      "step": 541250
    },
    {
      "epoch": 5.730464056404529,
      "grad_norm": 1.099775791168213,
      "learning_rate": 0.00023013610601269066,
      "loss": 0.5965,
      "step": 541300
    },
    {
      "epoch": 5.730993378184532,
      "grad_norm": 1.2493442296981812,
      "learning_rate": 0.000230090060109362,
      "loss": 0.6026,
      "step": 541350
    },
    {
      "epoch": 5.731522699964535,
      "grad_norm": 1.1614223718643188,
      "learning_rate": 0.00023004401488575126,
      "loss": 0.5998,
      "step": 541400
    },
    {
      "epoch": 5.732052021744539,
      "grad_norm": 1.2373698949813843,
      "learning_rate": 0.00022999797034343062,
      "loss": 0.594,
      "step": 541450
    },
    {
      "epoch": 5.732581343524542,
      "grad_norm": 1.1445831060409546,
      "learning_rate": 0.00022995192648397192,
      "loss": 0.6028,
      "step": 541500
    },
    {
      "epoch": 5.732581343524542,
      "eval_loss": 0.3871959149837494,
      "eval_runtime": 46.8306,
      "eval_samples_per_second": 3585.906,
      "eval_steps_per_second": 448.254,
      "step": 541500
    },
    {
      "epoch": 5.733110665304546,
      "grad_norm": 1.0595245361328125,
      "learning_rate": 0.0002299058833089471,
      "loss": 0.6112,
      "step": 541550
    },
    {
      "epoch": 5.7336399870845485,
      "grad_norm": 1.1535731554031372,
      "learning_rate": 0.000229859840819928,
      "loss": 0.582,
      "step": 541600
    },
    {
      "epoch": 5.734169308864552,
      "grad_norm": 1.1583383083343506,
      "learning_rate": 0.00022981379901848665,
      "loss": 0.6027,
      "step": 541650
    },
    {
      "epoch": 5.734698630644555,
      "grad_norm": 1.0877383947372437,
      "learning_rate": 0.0002297677579061947,
      "loss": 0.5863,
      "step": 541700
    },
    {
      "epoch": 5.735227952424559,
      "grad_norm": 1.1104350090026855,
      "learning_rate": 0.00022972171748462418,
      "loss": 0.5935,
      "step": 541750
    },
    {
      "epoch": 5.735757274204562,
      "grad_norm": 1.0873533487319946,
      "learning_rate": 0.00022967567775534668,
      "loss": 0.5924,
      "step": 541800
    },
    {
      "epoch": 5.736286595984565,
      "grad_norm": 1.16286039352417,
      "learning_rate": 0.0002296296387199342,
      "loss": 0.6004,
      "step": 541850
    },
    {
      "epoch": 5.736815917764568,
      "grad_norm": 1.1113150119781494,
      "learning_rate": 0.00022958360037995826,
      "loss": 0.5827,
      "step": 541900
    },
    {
      "epoch": 5.737345239544571,
      "grad_norm": 1.1335928440093994,
      "learning_rate": 0.00022953756273699083,
      "loss": 0.6055,
      "step": 541950
    },
    {
      "epoch": 5.737874561324575,
      "grad_norm": 1.082255482673645,
      "learning_rate": 0.0002294915257926034,
      "loss": 0.5965,
      "step": 542000
    },
    {
      "epoch": 5.737874561324575,
      "eval_loss": 0.38723981380462646,
      "eval_runtime": 46.7676,
      "eval_samples_per_second": 3590.732,
      "eval_steps_per_second": 448.858,
      "step": 542000
    },
    {
      "epoch": 5.738403883104578,
      "grad_norm": 1.1963958740234375,
      "learning_rate": 0.00022944548954836774,
      "loss": 0.588,
      "step": 542050
    },
    {
      "epoch": 5.738933204884582,
      "grad_norm": 1.1196969747543335,
      "learning_rate": 0.00022939945400585565,
      "loss": 0.5967,
      "step": 542100
    },
    {
      "epoch": 5.7394625266645845,
      "grad_norm": 1.1814464330673218,
      "learning_rate": 0.00022935341916663853,
      "loss": 0.5887,
      "step": 542150
    },
    {
      "epoch": 5.739991848444588,
      "grad_norm": 1.1976410150527954,
      "learning_rate": 0.00022930738503228827,
      "loss": 0.5989,
      "step": 542200
    },
    {
      "epoch": 5.740521170224591,
      "grad_norm": 1.067969799041748,
      "learning_rate": 0.00022926135160437615,
      "loss": 0.5893,
      "step": 542250
    },
    {
      "epoch": 5.741050492004595,
      "grad_norm": 1.1844892501831055,
      "learning_rate": 0.00022921531888447398,
      "loss": 0.6033,
      "step": 542300
    },
    {
      "epoch": 5.741579813784598,
      "grad_norm": 1.2843310832977295,
      "learning_rate": 0.00022916928687415308,
      "loss": 0.5985,
      "step": 542350
    },
    {
      "epoch": 5.7421091355646015,
      "grad_norm": 1.1400023698806763,
      "learning_rate": 0.00022912325557498513,
      "loss": 0.5837,
      "step": 542400
    },
    {
      "epoch": 5.742638457344604,
      "grad_norm": 1.242948293685913,
      "learning_rate": 0.00022907722498854163,
      "loss": 0.599,
      "step": 542450
    },
    {
      "epoch": 5.743167779124608,
      "grad_norm": 1.1710255146026611,
      "learning_rate": 0.00022903119511639397,
      "loss": 0.5959,
      "step": 542500
    },
    {
      "epoch": 5.743167779124608,
      "eval_loss": 0.38660892844200134,
      "eval_runtime": 46.7839,
      "eval_samples_per_second": 3589.482,
      "eval_steps_per_second": 448.701,
      "step": 542500
    },
    {
      "epoch": 5.743697100904611,
      "grad_norm": 1.052843689918518,
      "learning_rate": 0.00022898516596011362,
      "loss": 0.5891,
      "step": 542550
    },
    {
      "epoch": 5.744226422684614,
      "grad_norm": 1.2264368534088135,
      "learning_rate": 0.00022893913752127198,
      "loss": 0.5936,
      "step": 542600
    },
    {
      "epoch": 5.744755744464618,
      "grad_norm": 1.1629126071929932,
      "learning_rate": 0.00022889310980144043,
      "loss": 0.5917,
      "step": 542650
    },
    {
      "epoch": 5.74528506624462,
      "grad_norm": 1.107035517692566,
      "learning_rate": 0.0002288480033351036,
      "loss": 0.5905,
      "step": 542700
    },
    {
      "epoch": 5.745814388024624,
      "grad_norm": 1.2324644327163696,
      "learning_rate": 0.00022880197704354803,
      "loss": 0.5915,
      "step": 542750
    },
    {
      "epoch": 5.746343709804627,
      "grad_norm": 1.0492656230926514,
      "learning_rate": 0.00022875595147568505,
      "loss": 0.6089,
      "step": 542800
    },
    {
      "epoch": 5.746873031584631,
      "grad_norm": 1.1093782186508179,
      "learning_rate": 0.00022870992663308622,
      "loss": 0.593,
      "step": 542850
    },
    {
      "epoch": 5.747402353364634,
      "grad_norm": 1.204505205154419,
      "learning_rate": 0.0002286639025173226,
      "loss": 0.5956,
      "step": 542900
    },
    {
      "epoch": 5.747931675144637,
      "grad_norm": 1.1484756469726562,
      "learning_rate": 0.00022861787912996557,
      "loss": 0.6,
      "step": 542950
    },
    {
      "epoch": 5.74846099692464,
      "grad_norm": 1.1132559776306152,
      "learning_rate": 0.00022857185647258624,
      "loss": 0.5956,
      "step": 543000
    },
    {
      "epoch": 5.74846099692464,
      "eval_loss": 0.3871767520904541,
      "eval_runtime": 46.7502,
      "eval_samples_per_second": 3592.068,
      "eval_steps_per_second": 449.025,
      "step": 543000
    },
    {
      "epoch": 5.748990318704644,
      "grad_norm": 1.2448906898498535,
      "learning_rate": 0.00022852583454675599,
      "loss": 0.5957,
      "step": 543050
    },
    {
      "epoch": 5.749519640484647,
      "grad_norm": 1.1248618364334106,
      "learning_rate": 0.00022847981335404578,
      "loss": 0.6009,
      "step": 543100
    },
    {
      "epoch": 5.750048962264651,
      "grad_norm": 1.3536139726638794,
      "learning_rate": 0.0002284337928960269,
      "loss": 0.5995,
      "step": 543150
    },
    {
      "epoch": 5.7505782840446535,
      "grad_norm": 1.2483669519424438,
      "learning_rate": 0.00022838777317427036,
      "loss": 0.6072,
      "step": 543200
    },
    {
      "epoch": 5.751107605824657,
      "grad_norm": 1.0353204011917114,
      "learning_rate": 0.00022834175419034742,
      "loss": 0.593,
      "step": 543250
    },
    {
      "epoch": 5.75163692760466,
      "grad_norm": 1.0022929906845093,
      "learning_rate": 0.00022829573594582896,
      "loss": 0.5866,
      "step": 543300
    },
    {
      "epoch": 5.752166249384663,
      "grad_norm": 1.087924838066101,
      "learning_rate": 0.00022824971844228616,
      "loss": 0.591,
      "step": 543350
    },
    {
      "epoch": 5.752695571164667,
      "grad_norm": 1.1443909406661987,
      "learning_rate": 0.00022820370168128996,
      "loss": 0.6049,
      "step": 543400
    },
    {
      "epoch": 5.75322489294467,
      "grad_norm": 1.0467805862426758,
      "learning_rate": 0.00022815768566441144,
      "loss": 0.5966,
      "step": 543450
    },
    {
      "epoch": 5.753754214724673,
      "grad_norm": 1.1057045459747314,
      "learning_rate": 0.00022811167039322146,
      "loss": 0.6051,
      "step": 543500
    },
    {
      "epoch": 5.753754214724673,
      "eval_loss": 0.38659873604774475,
      "eval_runtime": 46.8259,
      "eval_samples_per_second": 3586.265,
      "eval_steps_per_second": 448.299,
      "step": 543500
    },
    {
      "epoch": 5.754283536504676,
      "grad_norm": 1.2014189958572388,
      "learning_rate": 0.00022806565586929112,
      "loss": 0.5999,
      "step": 543550
    },
    {
      "epoch": 5.75481285828468,
      "grad_norm": 1.1743069887161255,
      "learning_rate": 0.00022801964209419112,
      "loss": 0.5872,
      "step": 543600
    },
    {
      "epoch": 5.755342180064683,
      "grad_norm": 1.1534464359283447,
      "learning_rate": 0.00022797362906949254,
      "loss": 0.5841,
      "step": 543650
    },
    {
      "epoch": 5.755871501844687,
      "grad_norm": 1.2260955572128296,
      "learning_rate": 0.0002279276167967662,
      "loss": 0.5896,
      "step": 543700
    },
    {
      "epoch": 5.7564008236246895,
      "grad_norm": 0.9787683486938477,
      "learning_rate": 0.0002278816052775829,
      "loss": 0.6052,
      "step": 543750
    },
    {
      "epoch": 5.756930145404693,
      "grad_norm": 1.1529772281646729,
      "learning_rate": 0.00022783559451351344,
      "loss": 0.587,
      "step": 543800
    },
    {
      "epoch": 5.757459467184696,
      "grad_norm": 1.1353713274002075,
      "learning_rate": 0.00022778958450612877,
      "loss": 0.6059,
      "step": 543850
    },
    {
      "epoch": 5.7579887889647,
      "grad_norm": 1.2651888132095337,
      "learning_rate": 0.00022774357525699943,
      "loss": 0.5975,
      "step": 543900
    },
    {
      "epoch": 5.758518110744703,
      "grad_norm": 1.177026391029358,
      "learning_rate": 0.00022769756676769637,
      "loss": 0.5956,
      "step": 543950
    },
    {
      "epoch": 5.7590474325247065,
      "grad_norm": 1.264029860496521,
      "learning_rate": 0.0002276515590397901,
      "loss": 0.603,
      "step": 544000
    },
    {
      "epoch": 5.7590474325247065,
      "eval_loss": 0.3865620493888855,
      "eval_runtime": 46.8569,
      "eval_samples_per_second": 3583.887,
      "eval_steps_per_second": 448.002,
      "step": 544000
    },
    {
      "epoch": 5.759576754304709,
      "grad_norm": 1.1813687086105347,
      "learning_rate": 0.00022760555207485152,
      "loss": 0.5907,
      "step": 544050
    },
    {
      "epoch": 5.760106076084712,
      "grad_norm": 1.0810552835464478,
      "learning_rate": 0.00022755954587445104,
      "loss": 0.6123,
      "step": 544100
    },
    {
      "epoch": 5.760635397864716,
      "grad_norm": 1.1917617321014404,
      "learning_rate": 0.0002275135404401596,
      "loss": 0.5858,
      "step": 544150
    },
    {
      "epoch": 5.761164719644719,
      "grad_norm": 1.1225224733352661,
      "learning_rate": 0.0002274675357735475,
      "loss": 0.5981,
      "step": 544200
    },
    {
      "epoch": 5.761694041424723,
      "grad_norm": 1.1449205875396729,
      "learning_rate": 0.0002274215318761856,
      "loss": 0.6033,
      "step": 544250
    },
    {
      "epoch": 5.7622233632047255,
      "grad_norm": 0.9631157517433167,
      "learning_rate": 0.00022737552874964415,
      "loss": 0.5915,
      "step": 544300
    },
    {
      "epoch": 5.762752684984729,
      "grad_norm": 1.230678677558899,
      "learning_rate": 0.000227329526395494,
      "loss": 0.5926,
      "step": 544350
    },
    {
      "epoch": 5.763282006764732,
      "grad_norm": 1.0813177824020386,
      "learning_rate": 0.0002272835248153054,
      "loss": 0.5959,
      "step": 544400
    },
    {
      "epoch": 5.763811328544736,
      "grad_norm": 1.1058640480041504,
      "learning_rate": 0.00022723752401064898,
      "loss": 0.5924,
      "step": 544450
    },
    {
      "epoch": 5.764340650324739,
      "grad_norm": 1.0595382452011108,
      "learning_rate": 0.00022719152398309515,
      "loss": 0.5861,
      "step": 544500
    },
    {
      "epoch": 5.764340650324739,
      "eval_loss": 0.384333074092865,
      "eval_runtime": 46.8689,
      "eval_samples_per_second": 3582.971,
      "eval_steps_per_second": 447.887,
      "step": 544500
    },
    {
      "epoch": 5.7648699721047425,
      "grad_norm": 1.107592225074768,
      "learning_rate": 0.00022714552473421433,
      "loss": 0.5969,
      "step": 544550
    },
    {
      "epoch": 5.765399293884745,
      "grad_norm": 1.0701788663864136,
      "learning_rate": 0.00022709952626557688,
      "loss": 0.5981,
      "step": 544600
    },
    {
      "epoch": 5.765928615664749,
      "grad_norm": 1.2352635860443115,
      "learning_rate": 0.00022705352857875326,
      "loss": 0.5942,
      "step": 544650
    },
    {
      "epoch": 5.766457937444752,
      "grad_norm": 1.1148240566253662,
      "learning_rate": 0.00022700845160569523,
      "loss": 0.5907,
      "step": 544700
    },
    {
      "epoch": 5.766987259224756,
      "grad_norm": 1.1423996686935425,
      "learning_rate": 0.00022696245547149558,
      "loss": 0.588,
      "step": 544750
    },
    {
      "epoch": 5.767516581004759,
      "grad_norm": 1.225909948348999,
      "learning_rate": 0.00022691646012378938,
      "loss": 0.592,
      "step": 544800
    },
    {
      "epoch": 5.7680459027847615,
      "grad_norm": 1.1854201555252075,
      "learning_rate": 0.00022687046556414667,
      "loss": 0.5928,
      "step": 544850
    },
    {
      "epoch": 5.768575224564765,
      "grad_norm": 1.2591640949249268,
      "learning_rate": 0.0002268244717941378,
      "loss": 0.6008,
      "step": 544900
    },
    {
      "epoch": 5.769104546344768,
      "grad_norm": 1.1518982648849487,
      "learning_rate": 0.000226778478815333,
      "loss": 0.5991,
      "step": 544950
    },
    {
      "epoch": 5.769633868124772,
      "grad_norm": 1.2111366987228394,
      "learning_rate": 0.00022673248662930244,
      "loss": 0.6021,
      "step": 545000
    },
    {
      "epoch": 5.769633868124772,
      "eval_loss": 0.38476407527923584,
      "eval_runtime": 46.7806,
      "eval_samples_per_second": 3589.739,
      "eval_steps_per_second": 448.733,
      "step": 545000
    },
    {
      "epoch": 5.770163189904775,
      "grad_norm": 1.0943747758865356,
      "learning_rate": 0.00022668649523761614,
      "loss": 0.5962,
      "step": 545050
    },
    {
      "epoch": 5.7706925116847785,
      "grad_norm": 1.2215241193771362,
      "learning_rate": 0.0002266405046418445,
      "loss": 0.6052,
      "step": 545100
    },
    {
      "epoch": 5.771221833464781,
      "grad_norm": 1.166772484779358,
      "learning_rate": 0.00022659451484355732,
      "loss": 0.5948,
      "step": 545150
    },
    {
      "epoch": 5.771751155244785,
      "grad_norm": 1.1880978345870972,
      "learning_rate": 0.00022654852584432495,
      "loss": 0.5865,
      "step": 545200
    },
    {
      "epoch": 5.772280477024788,
      "grad_norm": 1.2582165002822876,
      "learning_rate": 0.00022650253764571718,
      "loss": 0.5963,
      "step": 545250
    },
    {
      "epoch": 5.772809798804792,
      "grad_norm": 1.2171926498413086,
      "learning_rate": 0.00022645655024930428,
      "loss": 0.588,
      "step": 545300
    },
    {
      "epoch": 5.773339120584795,
      "grad_norm": 1.157243251800537,
      "learning_rate": 0.00022641056365665599,
      "loss": 0.6063,
      "step": 545350
    },
    {
      "epoch": 5.773868442364798,
      "grad_norm": 1.1084963083267212,
      "learning_rate": 0.00022636457786934255,
      "loss": 0.5864,
      "step": 545400
    },
    {
      "epoch": 5.774397764144801,
      "grad_norm": 1.2594000101089478,
      "learning_rate": 0.00022631859288893362,
      "loss": 0.6022,
      "step": 545450
    },
    {
      "epoch": 5.774927085924805,
      "grad_norm": 1.213653564453125,
      "learning_rate": 0.00022627260871699938,
      "loss": 0.5956,
      "step": 545500
    },
    {
      "epoch": 5.774927085924805,
      "eval_loss": 0.3851023018360138,
      "eval_runtime": 46.7591,
      "eval_samples_per_second": 3591.383,
      "eval_steps_per_second": 448.939,
      "step": 545500
    },
    {
      "epoch": 5.775456407704808,
      "grad_norm": 0.9973514676094055,
      "learning_rate": 0.00022622662535510944,
      "loss": 0.6164,
      "step": 545550
    },
    {
      "epoch": 5.775985729484811,
      "grad_norm": 1.1578454971313477,
      "learning_rate": 0.0002261806428048339,
      "loss": 0.5839,
      "step": 545600
    },
    {
      "epoch": 5.7765150512648145,
      "grad_norm": 1.1704367399215698,
      "learning_rate": 0.0002261346610677424,
      "loss": 0.6027,
      "step": 545650
    },
    {
      "epoch": 5.777044373044817,
      "grad_norm": 1.1556637287139893,
      "learning_rate": 0.0002260886801454048,
      "loss": 0.5961,
      "step": 545700
    },
    {
      "epoch": 5.777573694824821,
      "grad_norm": 1.2576088905334473,
      "learning_rate": 0.00022604270003939099,
      "loss": 0.5911,
      "step": 545750
    },
    {
      "epoch": 5.778103016604824,
      "grad_norm": 1.1300640106201172,
      "learning_rate": 0.00022599672075127052,
      "loss": 0.5959,
      "step": 545800
    },
    {
      "epoch": 5.778632338384828,
      "grad_norm": 1.0969723463058472,
      "learning_rate": 0.00022595074228261324,
      "loss": 0.5902,
      "step": 545850
    },
    {
      "epoch": 5.779161660164831,
      "grad_norm": 1.1405576467514038,
      "learning_rate": 0.00022590476463498881,
      "loss": 0.6016,
      "step": 545900
    },
    {
      "epoch": 5.779690981944834,
      "grad_norm": 1.2012228965759277,
      "learning_rate": 0.00022585878780996684,
      "loss": 0.6126,
      "step": 545950
    },
    {
      "epoch": 5.780220303724837,
      "grad_norm": 1.0839800834655762,
      "learning_rate": 0.0002258128118091171,
      "loss": 0.6048,
      "step": 546000
    },
    {
      "epoch": 5.780220303724837,
      "eval_loss": 0.3861605226993561,
      "eval_runtime": 46.8519,
      "eval_samples_per_second": 3584.271,
      "eval_steps_per_second": 448.05,
      "step": 546000
    },
    {
      "epoch": 5.780749625504841,
      "grad_norm": 1.1659576892852783,
      "learning_rate": 0.00022576683663400897,
      "loss": 0.604,
      "step": 546050
    },
    {
      "epoch": 5.781278947284844,
      "grad_norm": 1.1664592027664185,
      "learning_rate": 0.00022572086228621224,
      "loss": 0.6017,
      "step": 546100
    },
    {
      "epoch": 5.781808269064848,
      "grad_norm": 1.1870474815368652,
      "learning_rate": 0.0002256748887672963,
      "loss": 0.5999,
      "step": 546150
    },
    {
      "epoch": 5.78233759084485,
      "grad_norm": 1.07290780544281,
      "learning_rate": 0.0002256289160788308,
      "loss": 0.6037,
      "step": 546200
    },
    {
      "epoch": 5.782866912624854,
      "grad_norm": 1.198696494102478,
      "learning_rate": 0.00022558294422238512,
      "loss": 0.5891,
      "step": 546250
    },
    {
      "epoch": 5.783396234404857,
      "grad_norm": 1.1481388807296753,
      "learning_rate": 0.00022553697319952883,
      "loss": 0.5919,
      "step": 546300
    },
    {
      "epoch": 5.78392555618486,
      "grad_norm": 1.2254436016082764,
      "learning_rate": 0.00022549100301183124,
      "loss": 0.5995,
      "step": 546350
    },
    {
      "epoch": 5.784454877964864,
      "grad_norm": 1.182498812675476,
      "learning_rate": 0.0002254450336608619,
      "loss": 0.5832,
      "step": 546400
    },
    {
      "epoch": 5.7849841997448666,
      "grad_norm": 1.180249571800232,
      "learning_rate": 0.00022539906514818997,
      "loss": 0.586,
      "step": 546450
    },
    {
      "epoch": 5.78551352152487,
      "grad_norm": 1.1662424802780151,
      "learning_rate": 0.00022535309747538507,
      "loss": 0.5978,
      "step": 546500
    },
    {
      "epoch": 5.78551352152487,
      "eval_loss": 0.3851105272769928,
      "eval_runtime": 46.8545,
      "eval_samples_per_second": 3584.077,
      "eval_steps_per_second": 448.026,
      "step": 546500
    },
    {
      "epoch": 5.786042843304873,
      "grad_norm": 1.1561427116394043,
      "learning_rate": 0.00022530713064401625,
      "loss": 0.6017,
      "step": 546550
    },
    {
      "epoch": 5.786572165084877,
      "grad_norm": 1.0287970304489136,
      "learning_rate": 0.00022526116465565303,
      "loss": 0.5945,
      "step": 546600
    },
    {
      "epoch": 5.78710148686488,
      "grad_norm": 1.2006787061691284,
      "learning_rate": 0.00022521519951186457,
      "loss": 0.5981,
      "step": 546650
    },
    {
      "epoch": 5.7876308086448836,
      "grad_norm": 1.239065170288086,
      "learning_rate": 0.00022516923521422006,
      "loss": 0.595,
      "step": 546700
    },
    {
      "epoch": 5.788160130424886,
      "grad_norm": 1.1259971857070923,
      "learning_rate": 0.00022512419102496963,
      "loss": 0.5899,
      "step": 546750
    },
    {
      "epoch": 5.78868945220489,
      "grad_norm": 1.2508172988891602,
      "learning_rate": 0.00022507822840731975,
      "loss": 0.5919,
      "step": 546800
    },
    {
      "epoch": 5.789218773984893,
      "grad_norm": 1.0528504848480225,
      "learning_rate": 0.00022503226664048992,
      "loss": 0.5911,
      "step": 546850
    },
    {
      "epoch": 5.789748095764897,
      "grad_norm": 1.1358826160430908,
      "learning_rate": 0.00022498630572604945,
      "loss": 0.6047,
      "step": 546900
    },
    {
      "epoch": 5.7902774175449,
      "grad_norm": 1.1068681478500366,
      "learning_rate": 0.00022494034566556724,
      "loss": 0.6055,
      "step": 546950
    },
    {
      "epoch": 5.790806739324903,
      "grad_norm": 1.2048879861831665,
      "learning_rate": 0.00022489438646061254,
      "loss": 0.5993,
      "step": 547000
    },
    {
      "epoch": 5.790806739324903,
      "eval_loss": 0.3844187557697296,
      "eval_runtime": 46.8465,
      "eval_samples_per_second": 3584.688,
      "eval_steps_per_second": 448.102,
      "step": 547000
    },
    {
      "epoch": 5.791336061104906,
      "grad_norm": 1.1124227046966553,
      "learning_rate": 0.00022484842811275416,
      "loss": 0.6012,
      "step": 547050
    },
    {
      "epoch": 5.791865382884909,
      "grad_norm": 1.0422232151031494,
      "learning_rate": 0.00022480247062356127,
      "loss": 0.5917,
      "step": 547100
    },
    {
      "epoch": 5.792394704664913,
      "grad_norm": 1.2069171667099,
      "learning_rate": 0.00022475651399460282,
      "loss": 0.5843,
      "step": 547150
    },
    {
      "epoch": 5.792924026444916,
      "grad_norm": 1.1586484909057617,
      "learning_rate": 0.00022471055822744767,
      "loss": 0.6005,
      "step": 547200
    },
    {
      "epoch": 5.7934533482249195,
      "grad_norm": 1.1891098022460938,
      "learning_rate": 0.00022466460332366483,
      "loss": 0.5964,
      "step": 547250
    },
    {
      "epoch": 5.793982670004922,
      "grad_norm": 1.151566505432129,
      "learning_rate": 0.00022461864928482314,
      "loss": 0.6031,
      "step": 547300
    },
    {
      "epoch": 5.794511991784926,
      "grad_norm": 1.2010263204574585,
      "learning_rate": 0.0002245726961124914,
      "loss": 0.6061,
      "step": 547350
    },
    {
      "epoch": 5.795041313564929,
      "grad_norm": 1.1604119539260864,
      "learning_rate": 0.0002245267438082386,
      "loss": 0.6001,
      "step": 547400
    },
    {
      "epoch": 5.795570635344933,
      "grad_norm": 1.186429500579834,
      "learning_rate": 0.0002244807923736333,
      "loss": 0.5946,
      "step": 547450
    },
    {
      "epoch": 5.796099957124936,
      "grad_norm": 1.2452290058135986,
      "learning_rate": 0.0002244348418102445,
      "loss": 0.5956,
      "step": 547500
    },
    {
      "epoch": 5.796099957124936,
      "eval_loss": 0.3839811384677887,
      "eval_runtime": 46.8407,
      "eval_samples_per_second": 3585.13,
      "eval_steps_per_second": 448.157,
      "step": 547500
    },
    {
      "epoch": 5.796629278904939,
      "grad_norm": 1.1728692054748535,
      "learning_rate": 0.00022438889211964075,
      "loss": 0.6025,
      "step": 547550
    },
    {
      "epoch": 5.797158600684942,
      "grad_norm": 1.127065658569336,
      "learning_rate": 0.0002243429433033909,
      "loss": 0.6037,
      "step": 547600
    },
    {
      "epoch": 5.797687922464946,
      "grad_norm": 1.2253471612930298,
      "learning_rate": 0.00022429699536306348,
      "loss": 0.6011,
      "step": 547650
    },
    {
      "epoch": 5.798217244244949,
      "grad_norm": 1.0804572105407715,
      "learning_rate": 0.00022425104830022728,
      "loss": 0.6001,
      "step": 547700
    },
    {
      "epoch": 5.798746566024953,
      "grad_norm": 1.1319366693496704,
      "learning_rate": 0.00022420510211645077,
      "loss": 0.6043,
      "step": 547750
    },
    {
      "epoch": 5.7992758878049555,
      "grad_norm": 1.1042640209197998,
      "learning_rate": 0.00022415915681330272,
      "loss": 0.5954,
      "step": 547800
    },
    {
      "epoch": 5.799805209584958,
      "grad_norm": 1.1366292238235474,
      "learning_rate": 0.00022411321239235144,
      "loss": 0.6024,
      "step": 547850
    },
    {
      "epoch": 5.800334531364962,
      "grad_norm": 1.0703213214874268,
      "learning_rate": 0.00022406726885516575,
      "loss": 0.5945,
      "step": 547900
    },
    {
      "epoch": 5.800863853144965,
      "grad_norm": 1.218404769897461,
      "learning_rate": 0.00022402132620331385,
      "loss": 0.6026,
      "step": 547950
    },
    {
      "epoch": 5.801393174924969,
      "grad_norm": 1.0878268480300903,
      "learning_rate": 0.0002239753844383644,
      "loss": 0.5923,
      "step": 548000
    },
    {
      "epoch": 5.801393174924969,
      "eval_loss": 0.3835415840148926,
      "eval_runtime": 46.9015,
      "eval_samples_per_second": 3580.486,
      "eval_steps_per_second": 447.577,
      "step": 548000
    },
    {
      "epoch": 5.801922496704972,
      "grad_norm": 1.170107364654541,
      "learning_rate": 0.0002239294435618858,
      "loss": 0.5957,
      "step": 548050
    },
    {
      "epoch": 5.802451818484975,
      "grad_norm": 1.2391833066940308,
      "learning_rate": 0.00022388350357544642,
      "loss": 0.5918,
      "step": 548100
    },
    {
      "epoch": 5.802981140264978,
      "grad_norm": 1.1224688291549683,
      "learning_rate": 0.0002238375644806146,
      "loss": 0.5914,
      "step": 548150
    },
    {
      "epoch": 5.803510462044982,
      "grad_norm": 1.1354379653930664,
      "learning_rate": 0.00022379162627895885,
      "loss": 0.5944,
      "step": 548200
    },
    {
      "epoch": 5.804039783824985,
      "grad_norm": 1.0899771451950073,
      "learning_rate": 0.00022374568897204724,
      "loss": 0.5882,
      "step": 548250
    },
    {
      "epoch": 5.804569105604989,
      "grad_norm": 1.1228779554367065,
      "learning_rate": 0.0002236997525614483,
      "loss": 0.5949,
      "step": 548300
    },
    {
      "epoch": 5.8050984273849915,
      "grad_norm": 1.0130289793014526,
      "learning_rate": 0.00022365381704873006,
      "loss": 0.5916,
      "step": 548350
    },
    {
      "epoch": 5.805627749164995,
      "grad_norm": 1.220096230506897,
      "learning_rate": 0.00022360788243546095,
      "loss": 0.6008,
      "step": 548400
    },
    {
      "epoch": 5.806157070944998,
      "grad_norm": 1.0680710077285767,
      "learning_rate": 0.00022356194872320896,
      "loss": 0.6012,
      "step": 548450
    },
    {
      "epoch": 5.806686392725002,
      "grad_norm": 1.175290822982788,
      "learning_rate": 0.00022351601591354242,
      "loss": 0.5939,
      "step": 548500
    },
    {
      "epoch": 5.806686392725002,
      "eval_loss": 0.3837180435657501,
      "eval_runtime": 47.098,
      "eval_samples_per_second": 3565.542,
      "eval_steps_per_second": 445.709,
      "step": 548500
    },
    {
      "epoch": 5.807215714505005,
      "grad_norm": 1.1149601936340332,
      "learning_rate": 0.0002234700840080293,
      "loss": 0.5973,
      "step": 548550
    },
    {
      "epoch": 5.807745036285008,
      "grad_norm": 0.9992095232009888,
      "learning_rate": 0.00022342415300823787,
      "loss": 0.5906,
      "step": 548600
    },
    {
      "epoch": 5.808274358065011,
      "grad_norm": 1.199654459953308,
      "learning_rate": 0.00022337822291573604,
      "loss": 0.594,
      "step": 548650
    },
    {
      "epoch": 5.808803679845014,
      "grad_norm": 1.2336738109588623,
      "learning_rate": 0.000223332293732092,
      "loss": 0.6049,
      "step": 548700
    },
    {
      "epoch": 5.809333001625018,
      "grad_norm": 1.168212890625,
      "learning_rate": 0.00022328728401540567,
      "loss": 0.5974,
      "step": 548750
    },
    {
      "epoch": 5.809862323405021,
      "grad_norm": 1.1231803894042969,
      "learning_rate": 0.00022324135663592565,
      "loss": 0.5925,
      "step": 548800
    },
    {
      "epoch": 5.810391645185025,
      "grad_norm": 1.0166517496109009,
      "learning_rate": 0.00022319543016997604,
      "loss": 0.5867,
      "step": 548850
    },
    {
      "epoch": 5.8109209669650275,
      "grad_norm": 1.0679963827133179,
      "learning_rate": 0.0002231495046191245,
      "loss": 0.5882,
      "step": 548900
    },
    {
      "epoch": 5.811450288745031,
      "grad_norm": 1.2731118202209473,
      "learning_rate": 0.00022310357998493914,
      "loss": 0.5917,
      "step": 548950
    },
    {
      "epoch": 5.811979610525034,
      "grad_norm": 1.2542736530303955,
      "learning_rate": 0.0002230576562689876,
      "loss": 0.597,
      "step": 549000
    },
    {
      "epoch": 5.811979610525034,
      "eval_loss": 0.38395848870277405,
      "eval_runtime": 46.8252,
      "eval_samples_per_second": 3586.314,
      "eval_steps_per_second": 448.305,
      "step": 549000
    },
    {
      "epoch": 5.812508932305038,
      "grad_norm": 1.1010583639144897,
      "learning_rate": 0.00022301173347283787,
      "loss": 0.6037,
      "step": 549050
    },
    {
      "epoch": 5.813038254085041,
      "grad_norm": 1.2112449407577515,
      "learning_rate": 0.00022296581159805758,
      "loss": 0.5931,
      "step": 549100
    },
    {
      "epoch": 5.8135675758650445,
      "grad_norm": 1.0945806503295898,
      "learning_rate": 0.00022291989064621466,
      "loss": 0.5915,
      "step": 549150
    },
    {
      "epoch": 5.814096897645047,
      "grad_norm": 1.0757496356964111,
      "learning_rate": 0.00022287397061887665,
      "loss": 0.5972,
      "step": 549200
    },
    {
      "epoch": 5.814626219425051,
      "grad_norm": 1.1705610752105713,
      "learning_rate": 0.00022282805151761139,
      "loss": 0.5958,
      "step": 549250
    },
    {
      "epoch": 5.815155541205054,
      "grad_norm": 1.0928890705108643,
      "learning_rate": 0.00022278213334398644,
      "loss": 0.6037,
      "step": 549300
    },
    {
      "epoch": 5.815684862985057,
      "grad_norm": 1.0984854698181152,
      "learning_rate": 0.00022273621609956954,
      "loss": 0.6101,
      "step": 549350
    },
    {
      "epoch": 5.816214184765061,
      "grad_norm": 1.0819305181503296,
      "learning_rate": 0.00022269029978592815,
      "loss": 0.5987,
      "step": 549400
    },
    {
      "epoch": 5.8167435065450634,
      "grad_norm": 1.0031789541244507,
      "learning_rate": 0.00022264438440462999,
      "loss": 0.5956,
      "step": 549450
    },
    {
      "epoch": 5.817272828325067,
      "grad_norm": 1.1171597242355347,
      "learning_rate": 0.00022259846995724243,
      "loss": 0.5883,
      "step": 549500
    },
    {
      "epoch": 5.817272828325067,
      "eval_loss": 0.3817194700241089,
      "eval_runtime": 46.7961,
      "eval_samples_per_second": 3588.547,
      "eval_steps_per_second": 448.584,
      "step": 549500
    },
    {
      "epoch": 5.81780215010507,
      "grad_norm": 1.0962326526641846,
      "learning_rate": 0.00022255255644533314,
      "loss": 0.597,
      "step": 549550
    },
    {
      "epoch": 5.818331471885074,
      "grad_norm": Infinity,
      "learning_rate": 0.00022250756211277355,
      "loss": 0.5996,
      "step": 549600
    },
    {
      "epoch": 5.818860793665077,
      "grad_norm": 1.1764823198318481,
      "learning_rate": 0.00022246165045773536,
      "loss": 0.5887,
      "step": 549650
    },
    {
      "epoch": 5.8193901154450804,
      "grad_norm": 1.0911046266555786,
      "learning_rate": 0.00022241573974284633,
      "loss": 0.5863,
      "step": 549700
    },
    {
      "epoch": 5.819919437225083,
      "grad_norm": 1.1924338340759277,
      "learning_rate": 0.0002223698299696738,
      "loss": 0.593,
      "step": 549750
    },
    {
      "epoch": 5.820448759005087,
      "grad_norm": 1.1662709712982178,
      "learning_rate": 0.00022232392113978515,
      "loss": 0.5863,
      "step": 549800
    },
    {
      "epoch": 5.82097808078509,
      "grad_norm": 1.1324492692947388,
      "learning_rate": 0.00022227801325474763,
      "loss": 0.5911,
      "step": 549850
    },
    {
      "epoch": 5.821507402565094,
      "grad_norm": 1.05287766456604,
      "learning_rate": 0.00022223210631612872,
      "loss": 0.6003,
      "step": 549900
    },
    {
      "epoch": 5.822036724345097,
      "grad_norm": 1.1224629878997803,
      "learning_rate": 0.00022218620032549534,
      "loss": 0.5873,
      "step": 549950
    },
    {
      "epoch": 5.8225660461251,
      "grad_norm": 1.2277426719665527,
      "learning_rate": 0.00022214029528441504,
      "loss": 0.5924,
      "step": 550000
    },
    {
      "epoch": 5.8225660461251,
      "eval_loss": 0.38328975439071655,
      "eval_runtime": 47.3325,
      "eval_samples_per_second": 3547.881,
      "eval_steps_per_second": 443.501,
      "step": 550000
    },
    {
      "epoch": 5.823095367905103,
      "grad_norm": 1.0581679344177246,
      "learning_rate": 0.00022209439119445472,
      "loss": 0.606,
      "step": 550050
    },
    {
      "epoch": 5.823624689685106,
      "grad_norm": 1.096615195274353,
      "learning_rate": 0.00022204848805718174,
      "loss": 0.5943,
      "step": 550100
    },
    {
      "epoch": 5.82415401146511,
      "grad_norm": 1.154720425605774,
      "learning_rate": 0.00022200258587416305,
      "loss": 0.6081,
      "step": 550150
    },
    {
      "epoch": 5.824683333245113,
      "grad_norm": 1.1538697481155396,
      "learning_rate": 0.00022195668464696593,
      "loss": 0.6001,
      "step": 550200
    },
    {
      "epoch": 5.825212655025116,
      "grad_norm": 1.2598191499710083,
      "learning_rate": 0.00022191078437715713,
      "loss": 0.5948,
      "step": 550250
    },
    {
      "epoch": 5.825741976805119,
      "grad_norm": 1.0276410579681396,
      "learning_rate": 0.00022186488506630402,
      "loss": 0.5886,
      "step": 550300
    },
    {
      "epoch": 5.826271298585123,
      "grad_norm": 1.0027636289596558,
      "learning_rate": 0.00022181898671597331,
      "loss": 0.6022,
      "step": 550350
    },
    {
      "epoch": 5.826800620365126,
      "grad_norm": 1.2325198650360107,
      "learning_rate": 0.00022177308932773212,
      "loss": 0.5902,
      "step": 550400
    },
    {
      "epoch": 5.82732994214513,
      "grad_norm": 1.1836048364639282,
      "learning_rate": 0.00022172719290314725,
      "loss": 0.6033,
      "step": 550450
    },
    {
      "epoch": 5.8278592639251325,
      "grad_norm": 1.0492035150527954,
      "learning_rate": 0.0002216812974437857,
      "loss": 0.5976,
      "step": 550500
    },
    {
      "epoch": 5.8278592639251325,
      "eval_loss": 0.3831038177013397,
      "eval_runtime": 47.3739,
      "eval_samples_per_second": 3544.782,
      "eval_steps_per_second": 443.114,
      "step": 550500
    },
    {
      "epoch": 5.828388585705136,
      "grad_norm": 1.1756563186645508,
      "learning_rate": 0.00022163540295121423,
      "loss": 0.6031,
      "step": 550550
    },
    {
      "epoch": 5.828917907485139,
      "grad_norm": 1.2169488668441772,
      "learning_rate": 0.0002215895094269997,
      "loss": 0.5928,
      "step": 550600
    },
    {
      "epoch": 5.829447229265143,
      "grad_norm": 1.054243564605713,
      "learning_rate": 0.00022154361687270888,
      "loss": 0.5923,
      "step": 550650
    },
    {
      "epoch": 5.829976551045146,
      "grad_norm": 1.0076580047607422,
      "learning_rate": 0.00022149772528990864,
      "loss": 0.5908,
      "step": 550700
    },
    {
      "epoch": 5.8305058728251495,
      "grad_norm": 1.137893795967102,
      "learning_rate": 0.0002214518346801655,
      "loss": 0.6048,
      "step": 550750
    },
    {
      "epoch": 5.831035194605152,
      "grad_norm": 1.1391019821166992,
      "learning_rate": 0.00022140594504504635,
      "loss": 0.5952,
      "step": 550800
    },
    {
      "epoch": 5.831564516385155,
      "grad_norm": 1.2432425022125244,
      "learning_rate": 0.00022136005638611765,
      "loss": 0.5905,
      "step": 550850
    },
    {
      "epoch": 5.832093838165159,
      "grad_norm": 1.0182123184204102,
      "learning_rate": 0.00022131416870494621,
      "loss": 0.5857,
      "step": 550900
    },
    {
      "epoch": 5.832623159945162,
      "grad_norm": 1.2854593992233276,
      "learning_rate": 0.00022126828200309844,
      "loss": 0.5897,
      "step": 550950
    },
    {
      "epoch": 5.833152481725166,
      "grad_norm": 1.1477992534637451,
      "learning_rate": 0.0002212223962821411,
      "loss": 0.5895,
      "step": 551000
    },
    {
      "epoch": 5.833152481725166,
      "eval_loss": 0.3828697204589844,
      "eval_runtime": 46.798,
      "eval_samples_per_second": 3588.399,
      "eval_steps_per_second": 448.566,
      "step": 551000
    },
    {
      "epoch": 5.8336818035051685,
      "grad_norm": 1.2106750011444092,
      "learning_rate": 0.0002211765115436405,
      "loss": 0.5964,
      "step": 551050
    },
    {
      "epoch": 5.834211125285172,
      "grad_norm": 1.135481595993042,
      "learning_rate": 0.00022113062778916328,
      "loss": 0.5991,
      "step": 551100
    },
    {
      "epoch": 5.834740447065175,
      "grad_norm": 1.1727360486984253,
      "learning_rate": 0.00022108474502027578,
      "loss": 0.5834,
      "step": 551150
    },
    {
      "epoch": 5.835269768845179,
      "grad_norm": 1.1588730812072754,
      "learning_rate": 0.00022103886323854446,
      "loss": 0.6012,
      "step": 551200
    },
    {
      "epoch": 5.835799090625182,
      "grad_norm": 1.2044589519500732,
      "learning_rate": 0.00022099298244553583,
      "loss": 0.5915,
      "step": 551250
    },
    {
      "epoch": 5.8363284124051855,
      "grad_norm": 1.0650886297225952,
      "learning_rate": 0.00022094710264281605,
      "loss": 0.5948,
      "step": 551300
    },
    {
      "epoch": 5.836857734185188,
      "grad_norm": 1.1861428022384644,
      "learning_rate": 0.00022090122383195166,
      "loss": 0.5899,
      "step": 551350
    },
    {
      "epoch": 5.837387055965192,
      "grad_norm": 1.237572431564331,
      "learning_rate": 0.00022085534601450868,
      "loss": 0.6007,
      "step": 551400
    },
    {
      "epoch": 5.837916377745195,
      "grad_norm": 1.0663095712661743,
      "learning_rate": 0.00022080946919205354,
      "loss": 0.5893,
      "step": 551450
    },
    {
      "epoch": 5.838445699525199,
      "grad_norm": 1.1267451047897339,
      "learning_rate": 0.00022076359336615245,
      "loss": 0.5779,
      "step": 551500
    },
    {
      "epoch": 5.838445699525199,
      "eval_loss": 0.3823277950286865,
      "eval_runtime": 46.7939,
      "eval_samples_per_second": 3588.718,
      "eval_steps_per_second": 448.606,
      "step": 551500
    },
    {
      "epoch": 5.838975021305202,
      "grad_norm": 1.1753928661346436,
      "learning_rate": 0.00022071771853837154,
      "loss": 0.6121,
      "step": 551550
    },
    {
      "epoch": 5.8395043430852045,
      "grad_norm": 1.0418130159378052,
      "learning_rate": 0.00022067184471027693,
      "loss": 0.5951,
      "step": 551600
    },
    {
      "epoch": 5.840033664865208,
      "grad_norm": 1.3614805936813354,
      "learning_rate": 0.00022062597188343488,
      "loss": 0.5948,
      "step": 551650
    },
    {
      "epoch": 5.840562986645211,
      "grad_norm": 1.0683021545410156,
      "learning_rate": 0.00022058010005941128,
      "loss": 0.599,
      "step": 551700
    },
    {
      "epoch": 5.841092308425215,
      "grad_norm": 1.160094141960144,
      "learning_rate": 0.0002205342292397724,
      "loss": 0.5928,
      "step": 551750
    },
    {
      "epoch": 5.841621630205218,
      "grad_norm": 1.1365540027618408,
      "learning_rate": 0.000220488359426084,
      "loss": 0.5844,
      "step": 551800
    },
    {
      "epoch": 5.8421509519852215,
      "grad_norm": 0.9681400060653687,
      "learning_rate": 0.00022044249061991232,
      "loss": 0.5895,
      "step": 551850
    },
    {
      "epoch": 5.842680273765224,
      "grad_norm": 1.0838409662246704,
      "learning_rate": 0.00022039662282282303,
      "loss": 0.5949,
      "step": 551900
    },
    {
      "epoch": 5.843209595545228,
      "grad_norm": 1.0588971376419067,
      "learning_rate": 0.0002203507560363823,
      "loss": 0.5861,
      "step": 551950
    },
    {
      "epoch": 5.843738917325231,
      "grad_norm": 1.2067447900772095,
      "learning_rate": 0.00022030489026215577,
      "loss": 0.5909,
      "step": 552000
    },
    {
      "epoch": 5.843738917325231,
      "eval_loss": 0.383122056722641,
      "eval_runtime": 46.874,
      "eval_samples_per_second": 3582.586,
      "eval_steps_per_second": 447.839,
      "step": 552000
    },
    {
      "epoch": 5.844268239105235,
      "grad_norm": 1.0870565176010132,
      "learning_rate": 0.00022025902550170952,
      "loss": 0.5982,
      "step": 552050
    },
    {
      "epoch": 5.844797560885238,
      "grad_norm": 1.063664197921753,
      "learning_rate": 0.0002202131617566091,
      "loss": 0.5865,
      "step": 552100
    },
    {
      "epoch": 5.845326882665241,
      "grad_norm": 1.2135069370269775,
      "learning_rate": 0.00022016729902842052,
      "loss": 0.5906,
      "step": 552150
    },
    {
      "epoch": 5.845856204445244,
      "grad_norm": 1.2074923515319824,
      "learning_rate": 0.00022012143731870934,
      "loss": 0.5902,
      "step": 552200
    },
    {
      "epoch": 5.846385526225248,
      "grad_norm": 1.2667633295059204,
      "learning_rate": 0.0002200755766290414,
      "loss": 0.5989,
      "step": 552250
    },
    {
      "epoch": 5.846914848005251,
      "grad_norm": 1.0885406732559204,
      "learning_rate": 0.00022002971696098223,
      "loss": 0.5967,
      "step": 552300
    },
    {
      "epoch": 5.847444169785254,
      "grad_norm": 1.2343686819076538,
      "learning_rate": 0.00021998385831609757,
      "loss": 0.6003,
      "step": 552350
    },
    {
      "epoch": 5.8479734915652575,
      "grad_norm": 1.0308881998062134,
      "learning_rate": 0.00021993800069595296,
      "loss": 0.6085,
      "step": 552400
    },
    {
      "epoch": 5.84850281334526,
      "grad_norm": 1.181153655052185,
      "learning_rate": 0.000219892144102114,
      "loss": 0.605,
      "step": 552450
    },
    {
      "epoch": 5.849032135125264,
      "grad_norm": 1.0535863637924194,
      "learning_rate": 0.00021984628853614614,
      "loss": 0.5953,
      "step": 552500
    },
    {
      "epoch": 5.849032135125264,
      "eval_loss": 0.38148757815361023,
      "eval_runtime": 46.7911,
      "eval_samples_per_second": 3588.933,
      "eval_steps_per_second": 448.633,
      "step": 552500
    },
    {
      "epoch": 5.849561456905267,
      "grad_norm": 1.0189861059188843,
      "learning_rate": 0.00021980043399961506,
      "loss": 0.5958,
      "step": 552550
    },
    {
      "epoch": 5.850090778685271,
      "grad_norm": 1.1633321046829224,
      "learning_rate": 0.00021975458049408594,
      "loss": 0.5816,
      "step": 552600
    },
    {
      "epoch": 5.850620100465274,
      "grad_norm": 1.1120246648788452,
      "learning_rate": 0.0002197087280211245,
      "loss": 0.5844,
      "step": 552650
    },
    {
      "epoch": 5.851149422245277,
      "grad_norm": 1.0254194736480713,
      "learning_rate": 0.00021966287658229584,
      "loss": 0.5921,
      "step": 552700
    },
    {
      "epoch": 5.85167874402528,
      "grad_norm": 1.1636083126068115,
      "learning_rate": 0.00021961702617916555,
      "loss": 0.5848,
      "step": 552750
    },
    {
      "epoch": 5.852208065805284,
      "grad_norm": 1.289559245109558,
      "learning_rate": 0.00021957117681329873,
      "loss": 0.5975,
      "step": 552800
    },
    {
      "epoch": 5.852737387585287,
      "grad_norm": 1.1496764421463013,
      "learning_rate": 0.0002195253284862609,
      "loss": 0.5943,
      "step": 552850
    },
    {
      "epoch": 5.853266709365291,
      "grad_norm": 1.1500451564788818,
      "learning_rate": 0.0002194794811996171,
      "loss": 0.6002,
      "step": 552900
    },
    {
      "epoch": 5.8537960311452935,
      "grad_norm": 1.0826412439346313,
      "learning_rate": 0.00021943363495493268,
      "loss": 0.5942,
      "step": 552950
    },
    {
      "epoch": 5.854325352925297,
      "grad_norm": 1.0859405994415283,
      "learning_rate": 0.00021938778975377267,
      "loss": 0.5917,
      "step": 553000
    },
    {
      "epoch": 5.854325352925297,
      "eval_loss": 0.38075482845306396,
      "eval_runtime": 46.7678,
      "eval_samples_per_second": 3590.718,
      "eval_steps_per_second": 448.856,
      "step": 553000
    },
    {
      "epoch": 5.8548546747053,
      "grad_norm": 1.1444238424301147,
      "learning_rate": 0.00021934194559770237,
      "loss": 0.595,
      "step": 553050
    },
    {
      "epoch": 5.855383996485303,
      "grad_norm": 1.1427253484725952,
      "learning_rate": 0.00021929610248828675,
      "loss": 0.606,
      "step": 553100
    },
    {
      "epoch": 5.855913318265307,
      "grad_norm": 1.214674711227417,
      "learning_rate": 0.00021925026042709093,
      "loss": 0.5851,
      "step": 553150
    },
    {
      "epoch": 5.85644264004531,
      "grad_norm": 1.2086318731307983,
      "learning_rate": 0.00021920441941567997,
      "loss": 0.5872,
      "step": 553200
    },
    {
      "epoch": 5.856971961825313,
      "grad_norm": 0.9749950170516968,
      "learning_rate": 0.00021915857945561885,
      "loss": 0.5865,
      "step": 553250
    },
    {
      "epoch": 5.857501283605316,
      "grad_norm": 1.1646276712417603,
      "learning_rate": 0.0002191127405484724,
      "loss": 0.5929,
      "step": 553300
    },
    {
      "epoch": 5.85803060538532,
      "grad_norm": 1.1574561595916748,
      "learning_rate": 0.00021906690269580585,
      "loss": 0.5916,
      "step": 553350
    },
    {
      "epoch": 5.858559927165323,
      "grad_norm": 1.1938562393188477,
      "learning_rate": 0.00021902106589918375,
      "loss": 0.5884,
      "step": 553400
    },
    {
      "epoch": 5.859089248945327,
      "grad_norm": 1.0417219400405884,
      "learning_rate": 0.0002189752301601712,
      "loss": 0.5909,
      "step": 553450
    },
    {
      "epoch": 5.859618570725329,
      "grad_norm": 1.1682130098342896,
      "learning_rate": 0.0002189293954803328,
      "loss": 0.5939,
      "step": 553500
    },
    {
      "epoch": 5.859618570725329,
      "eval_loss": 0.38102051615715027,
      "eval_runtime": 46.8221,
      "eval_samples_per_second": 3586.555,
      "eval_steps_per_second": 448.335,
      "step": 553500
    },
    {
      "epoch": 5.860147892505333,
      "grad_norm": 1.0778452157974243,
      "learning_rate": 0.00021888356186123358,
      "loss": 0.6039,
      "step": 553550
    },
    {
      "epoch": 5.860677214285336,
      "grad_norm": 1.1090123653411865,
      "learning_rate": 0.000218837729304438,
      "loss": 0.5987,
      "step": 553600
    },
    {
      "epoch": 5.86120653606534,
      "grad_norm": 1.0459293127059937,
      "learning_rate": 0.00021879281443093354,
      "loss": 0.5927,
      "step": 553650
    },
    {
      "epoch": 5.861735857845343,
      "grad_norm": 1.181119680404663,
      "learning_rate": 0.0002187469839821157,
      "loss": 0.5932,
      "step": 553700
    },
    {
      "epoch": 5.862265179625346,
      "grad_norm": 1.15666663646698,
      "learning_rate": 0.00021870115460026433,
      "loss": 0.5904,
      "step": 553750
    },
    {
      "epoch": 5.862794501405349,
      "grad_norm": 1.1339144706726074,
      "learning_rate": 0.00021865532628694416,
      "loss": 0.5808,
      "step": 553800
    },
    {
      "epoch": 5.863323823185352,
      "grad_norm": 1.0991261005401611,
      "learning_rate": 0.00021860949904371952,
      "loss": 0.5931,
      "step": 553850
    },
    {
      "epoch": 5.863853144965356,
      "grad_norm": 1.2277133464813232,
      "learning_rate": 0.0002185636728721552,
      "loss": 0.5996,
      "step": 553900
    },
    {
      "epoch": 5.864382466745359,
      "grad_norm": 1.2161487340927124,
      "learning_rate": 0.00021851784777381545,
      "loss": 0.588,
      "step": 553950
    },
    {
      "epoch": 5.8649117885253625,
      "grad_norm": 1.0783650875091553,
      "learning_rate": 0.00021847202375026493,
      "loss": 0.5866,
      "step": 554000
    },
    {
      "epoch": 5.8649117885253625,
      "eval_loss": 0.3821086287498474,
      "eval_runtime": 46.7788,
      "eval_samples_per_second": 3589.872,
      "eval_steps_per_second": 448.75,
      "step": 554000
    },
    {
      "epoch": 5.865441110305365,
      "grad_norm": 1.188312292098999,
      "learning_rate": 0.00021842620080306786,
      "loss": 0.5973,
      "step": 554050
    },
    {
      "epoch": 5.865970432085369,
      "grad_norm": 1.1259857416152954,
      "learning_rate": 0.0002183803789337888,
      "loss": 0.588,
      "step": 554100
    },
    {
      "epoch": 5.866499753865372,
      "grad_norm": 1.2436124086380005,
      "learning_rate": 0.00021833455814399195,
      "loss": 0.5875,
      "step": 554150
    },
    {
      "epoch": 5.867029075645376,
      "grad_norm": 1.1482715606689453,
      "learning_rate": 0.0002182887384352417,
      "loss": 0.5976,
      "step": 554200
    },
    {
      "epoch": 5.867558397425379,
      "grad_norm": 1.0414527654647827,
      "learning_rate": 0.00021824291980910226,
      "loss": 0.5966,
      "step": 554250
    },
    {
      "epoch": 5.868087719205382,
      "grad_norm": 1.0729126930236816,
      "learning_rate": 0.00021819710226713795,
      "loss": 0.5888,
      "step": 554300
    },
    {
      "epoch": 5.868617040985385,
      "grad_norm": 1.189666986465454,
      "learning_rate": 0.00021815128581091284,
      "loss": 0.586,
      "step": 554350
    },
    {
      "epoch": 5.869146362765389,
      "grad_norm": 1.049790382385254,
      "learning_rate": 0.00021810547044199118,
      "loss": 0.5966,
      "step": 554400
    },
    {
      "epoch": 5.869675684545392,
      "grad_norm": 1.3133466243743896,
      "learning_rate": 0.00021805965616193706,
      "loss": 0.6024,
      "step": 554450
    },
    {
      "epoch": 5.870205006325396,
      "grad_norm": 1.0920298099517822,
      "learning_rate": 0.0002180138429723146,
      "loss": 0.593,
      "step": 554500
    },
    {
      "epoch": 5.870205006325396,
      "eval_loss": 0.38103967905044556,
      "eval_runtime": 46.8876,
      "eval_samples_per_second": 3581.543,
      "eval_steps_per_second": 447.709,
      "step": 554500
    },
    {
      "epoch": 5.8707343281053985,
      "grad_norm": 1.2289916276931763,
      "learning_rate": 0.0002179680308746877,
      "loss": 0.5906,
      "step": 554550
    },
    {
      "epoch": 5.871263649885401,
      "grad_norm": 0.9920478463172913,
      "learning_rate": 0.0002179222198706206,
      "loss": 0.5974,
      "step": 554600
    },
    {
      "epoch": 5.871792971665405,
      "grad_norm": 1.196053147315979,
      "learning_rate": 0.00021787640996167706,
      "loss": 0.5955,
      "step": 554650
    },
    {
      "epoch": 5.872322293445408,
      "grad_norm": 1.2394793033599854,
      "learning_rate": 0.00021783060114942122,
      "loss": 0.6016,
      "step": 554700
    },
    {
      "epoch": 5.872851615225412,
      "grad_norm": 1.2737020254135132,
      "learning_rate": 0.0002177847934354167,
      "loss": 0.5975,
      "step": 554750
    },
    {
      "epoch": 5.873380937005415,
      "grad_norm": 1.174242615699768,
      "learning_rate": 0.00021773898682122766,
      "loss": 0.5893,
      "step": 554800
    },
    {
      "epoch": 5.873910258785418,
      "grad_norm": 1.3245407342910767,
      "learning_rate": 0.0002176931813084177,
      "loss": 0.5943,
      "step": 554850
    },
    {
      "epoch": 5.874439580565421,
      "grad_norm": 1.1293178796768188,
      "learning_rate": 0.00021764737689855074,
      "loss": 0.5903,
      "step": 554900
    },
    {
      "epoch": 5.874968902345425,
      "grad_norm": 1.123998761177063,
      "learning_rate": 0.00021760157359319038,
      "loss": 0.5791,
      "step": 554950
    },
    {
      "epoch": 5.875498224125428,
      "grad_norm": 1.0708644390106201,
      "learning_rate": 0.00021755577139390052,
      "loss": 0.6028,
      "step": 555000
    },
    {
      "epoch": 5.875498224125428,
      "eval_loss": 0.381773442029953,
      "eval_runtime": 46.7146,
      "eval_samples_per_second": 3594.806,
      "eval_steps_per_second": 449.367,
      "step": 555000
    },
    {
      "epoch": 5.876027545905432,
      "grad_norm": 1.0714128017425537,
      "learning_rate": 0.00021750997030224465,
      "loss": 0.5845,
      "step": 555050
    },
    {
      "epoch": 5.8765568676854345,
      "grad_norm": 1.1119909286499023,
      "learning_rate": 0.00021746417031978654,
      "loss": 0.5937,
      "step": 555100
    },
    {
      "epoch": 5.877086189465438,
      "grad_norm": 1.2081471681594849,
      "learning_rate": 0.00021741837144808966,
      "loss": 0.5981,
      "step": 555150
    },
    {
      "epoch": 5.877615511245441,
      "grad_norm": 1.1530131101608276,
      "learning_rate": 0.00021737257368871764,
      "loss": 0.5949,
      "step": 555200
    },
    {
      "epoch": 5.878144833025445,
      "grad_norm": 1.2292993068695068,
      "learning_rate": 0.000217326777043234,
      "loss": 0.5886,
      "step": 555250
    },
    {
      "epoch": 5.878674154805448,
      "grad_norm": 1.2080122232437134,
      "learning_rate": 0.0002172809815132022,
      "loss": 0.5877,
      "step": 555300
    },
    {
      "epoch": 5.879203476585451,
      "grad_norm": 1.2034296989440918,
      "learning_rate": 0.00021723518710018566,
      "loss": 0.5887,
      "step": 555350
    },
    {
      "epoch": 5.879732798365454,
      "grad_norm": 1.2182461023330688,
      "learning_rate": 0.00021718939380574792,
      "loss": 0.5896,
      "step": 555400
    },
    {
      "epoch": 5.880262120145457,
      "grad_norm": 1.1483663320541382,
      "learning_rate": 0.00021714360163145214,
      "loss": 0.5959,
      "step": 555450
    },
    {
      "epoch": 5.880791441925461,
      "grad_norm": 1.163930058479309,
      "learning_rate": 0.00021709781057886184,
      "loss": 0.5976,
      "step": 555500
    },
    {
      "epoch": 5.880791441925461,
      "eval_loss": 0.3805815577507019,
      "eval_runtime": 46.8174,
      "eval_samples_per_second": 3586.915,
      "eval_steps_per_second": 448.38,
      "step": 555500
    },
    {
      "epoch": 5.881320763705464,
      "grad_norm": 1.1756515502929688,
      "learning_rate": 0.00021705202064954012,
      "loss": 0.6042,
      "step": 555550
    },
    {
      "epoch": 5.881850085485468,
      "grad_norm": 1.039101004600525,
      "learning_rate": 0.00021700623184505048,
      "loss": 0.5938,
      "step": 555600
    },
    {
      "epoch": 5.8823794072654705,
      "grad_norm": 1.1863380670547485,
      "learning_rate": 0.00021696135990946898,
      "loss": 0.5979,
      "step": 555650
    },
    {
      "epoch": 5.882908729045474,
      "grad_norm": 1.1473957300186157,
      "learning_rate": 0.0002169155733367582,
      "loss": 0.5942,
      "step": 555700
    },
    {
      "epoch": 5.883438050825477,
      "grad_norm": 1.094625473022461,
      "learning_rate": 0.00021686978789353767,
      "loss": 0.5948,
      "step": 555750
    },
    {
      "epoch": 5.883967372605481,
      "grad_norm": 1.183502197265625,
      "learning_rate": 0.00021682400358137034,
      "loss": 0.598,
      "step": 555800
    },
    {
      "epoch": 5.884496694385484,
      "grad_norm": 1.2028374671936035,
      "learning_rate": 0.00021677822040181945,
      "loss": 0.5912,
      "step": 555850
    },
    {
      "epoch": 5.8850260161654875,
      "grad_norm": 1.1401771306991577,
      "learning_rate": 0.00021673243835644787,
      "loss": 0.5951,
      "step": 555900
    },
    {
      "epoch": 5.88555533794549,
      "grad_norm": 1.1974188089370728,
      "learning_rate": 0.00021668665744681873,
      "loss": 0.5936,
      "step": 555950
    },
    {
      "epoch": 5.886084659725494,
      "grad_norm": 1.23085618019104,
      "learning_rate": 0.00021664087767449478,
      "loss": 0.5901,
      "step": 556000
    },
    {
      "epoch": 5.886084659725494,
      "eval_loss": 0.38048332929611206,
      "eval_runtime": 46.7717,
      "eval_samples_per_second": 3590.422,
      "eval_steps_per_second": 448.819,
      "step": 556000
    },
    {
      "epoch": 5.886613981505497,
      "grad_norm": 1.176482915878296,
      "learning_rate": 0.00021659509904103913,
      "loss": 0.5828,
      "step": 556050
    },
    {
      "epoch": 5.8871433032855,
      "grad_norm": 0.9946151375770569,
      "learning_rate": 0.00021654932154801447,
      "loss": 0.5898,
      "step": 556100
    },
    {
      "epoch": 5.887672625065504,
      "grad_norm": 1.3087553977966309,
      "learning_rate": 0.00021650354519698377,
      "loss": 0.5872,
      "step": 556150
    },
    {
      "epoch": 5.888201946845507,
      "grad_norm": 1.0667200088500977,
      "learning_rate": 0.00021645776998950968,
      "loss": 0.5941,
      "step": 556200
    },
    {
      "epoch": 5.88873126862551,
      "grad_norm": 1.116929054260254,
      "learning_rate": 0.00021641199592715513,
      "loss": 0.5941,
      "step": 556250
    },
    {
      "epoch": 5.889260590405513,
      "grad_norm": 1.108147382736206,
      "learning_rate": 0.00021636622301148258,
      "loss": 0.5812,
      "step": 556300
    },
    {
      "epoch": 5.889789912185517,
      "grad_norm": 1.0875884294509888,
      "learning_rate": 0.000216320451244055,
      "loss": 0.5871,
      "step": 556350
    },
    {
      "epoch": 5.89031923396552,
      "grad_norm": 1.1115012168884277,
      "learning_rate": 0.0002162746806264347,
      "loss": 0.5909,
      "step": 556400
    },
    {
      "epoch": 5.8908485557455235,
      "grad_norm": 1.0725785493850708,
      "learning_rate": 0.00021622891116018452,
      "loss": 0.5998,
      "step": 556450
    },
    {
      "epoch": 5.891377877525526,
      "grad_norm": 1.1924587488174438,
      "learning_rate": 0.00021618314284686693,
      "loss": 0.5827,
      "step": 556500
    },
    {
      "epoch": 5.891377877525526,
      "eval_loss": 0.3785863518714905,
      "eval_runtime": 46.7869,
      "eval_samples_per_second": 3589.255,
      "eval_steps_per_second": 448.673,
      "step": 556500
    },
    {
      "epoch": 5.89190719930553,
      "grad_norm": 1.2307907342910767,
      "learning_rate": 0.00021613737568804443,
      "loss": 0.5989,
      "step": 556550
    },
    {
      "epoch": 5.892436521085533,
      "grad_norm": 1.1979936361312866,
      "learning_rate": 0.00021609160968527946,
      "loss": 0.5882,
      "step": 556600
    },
    {
      "epoch": 5.892965842865537,
      "grad_norm": 1.1253838539123535,
      "learning_rate": 0.00021604584484013461,
      "loss": 0.5991,
      "step": 556650
    },
    {
      "epoch": 5.89349516464554,
      "grad_norm": 1.0500558614730835,
      "learning_rate": 0.00021600008115417205,
      "loss": 0.5963,
      "step": 556700
    },
    {
      "epoch": 5.894024486425543,
      "grad_norm": 1.1088206768035889,
      "learning_rate": 0.00021595431862895436,
      "loss": 0.59,
      "step": 556750
    },
    {
      "epoch": 5.894553808205546,
      "grad_norm": 1.194916844367981,
      "learning_rate": 0.00021590855726604365,
      "loss": 0.5925,
      "step": 556800
    },
    {
      "epoch": 5.895083129985549,
      "grad_norm": 1.2213616371154785,
      "learning_rate": 0.00021586279706700234,
      "loss": 0.598,
      "step": 556850
    },
    {
      "epoch": 5.895612451765553,
      "grad_norm": 1.097779393196106,
      "learning_rate": 0.00021581703803339258,
      "loss": 0.594,
      "step": 556900
    },
    {
      "epoch": 5.896141773545557,
      "grad_norm": 1.1046146154403687,
      "learning_rate": 0.00021577128016677668,
      "loss": 0.5805,
      "step": 556950
    },
    {
      "epoch": 5.896671095325559,
      "grad_norm": 1.2043346166610718,
      "learning_rate": 0.00021572552346871664,
      "loss": 0.5928,
      "step": 557000
    },
    {
      "epoch": 5.896671095325559,
      "eval_loss": 0.3791922330856323,
      "eval_runtime": 47.0935,
      "eval_samples_per_second": 3565.888,
      "eval_steps_per_second": 445.752,
      "step": 557000
    },
    {
      "epoch": 5.897200417105562,
      "grad_norm": 1.0641010999679565,
      "learning_rate": 0.00021567976794077475,
      "loss": 0.5911,
      "step": 557050
    },
    {
      "epoch": 5.897729738885566,
      "grad_norm": 1.183451533317566,
      "learning_rate": 0.0002156340135845129,
      "loss": 0.5872,
      "step": 557100
    },
    {
      "epoch": 5.898259060665569,
      "grad_norm": 1.1553738117218018,
      "learning_rate": 0.00021558826040149332,
      "loss": 0.5927,
      "step": 557150
    },
    {
      "epoch": 5.898788382445573,
      "grad_norm": 1.1276861429214478,
      "learning_rate": 0.00021554250839327777,
      "loss": 0.5984,
      "step": 557200
    },
    {
      "epoch": 5.8993177042255756,
      "grad_norm": 1.0361465215682983,
      "learning_rate": 0.00021549675756142844,
      "loss": 0.5849,
      "step": 557250
    },
    {
      "epoch": 5.899847026005579,
      "grad_norm": 1.04552161693573,
      "learning_rate": 0.00021545100790750716,
      "loss": 0.5985,
      "step": 557300
    },
    {
      "epoch": 5.900376347785582,
      "grad_norm": 1.2380571365356445,
      "learning_rate": 0.00021540525943307577,
      "loss": 0.5912,
      "step": 557350
    },
    {
      "epoch": 5.900905669565586,
      "grad_norm": 1.1480813026428223,
      "learning_rate": 0.00021535951213969609,
      "loss": 0.5941,
      "step": 557400
    },
    {
      "epoch": 5.901434991345589,
      "grad_norm": 1.1303013563156128,
      "learning_rate": 0.0002153137660289301,
      "loss": 0.5981,
      "step": 557450
    },
    {
      "epoch": 5.9019643131255926,
      "grad_norm": 1.1725610494613647,
      "learning_rate": 0.0002152680211023393,
      "loss": 0.586,
      "step": 557500
    },
    {
      "epoch": 5.9019643131255926,
      "eval_loss": 0.3798655569553375,
      "eval_runtime": 46.7473,
      "eval_samples_per_second": 3592.293,
      "eval_steps_per_second": 449.053,
      "step": 557500
    },
    {
      "epoch": 5.902493634905595,
      "grad_norm": 1.0943533182144165,
      "learning_rate": 0.00021522227736148558,
      "loss": 0.5923,
      "step": 557550
    },
    {
      "epoch": 5.903022956685598,
      "grad_norm": 1.1997863054275513,
      "learning_rate": 0.00021517653480793047,
      "loss": 0.5981,
      "step": 557600
    },
    {
      "epoch": 5.903552278465602,
      "grad_norm": 1.14409601688385,
      "learning_rate": 0.0002151317082588688,
      "loss": 0.5755,
      "step": 557650
    },
    {
      "epoch": 5.904081600245606,
      "grad_norm": 1.1175603866577148,
      "learning_rate": 0.00021508596806077217,
      "loss": 0.5888,
      "step": 557700
    },
    {
      "epoch": 5.904610922025609,
      "grad_norm": 1.2930350303649902,
      "learning_rate": 0.00021504022905462797,
      "loss": 0.5877,
      "step": 557750
    },
    {
      "epoch": 5.9051402438056115,
      "grad_norm": 1.1734551191329956,
      "learning_rate": 0.0002149944912419974,
      "loss": 0.5871,
      "step": 557800
    },
    {
      "epoch": 5.905669565585615,
      "grad_norm": 1.1481711864471436,
      "learning_rate": 0.0002149487546244421,
      "loss": 0.5915,
      "step": 557850
    },
    {
      "epoch": 5.906198887365618,
      "grad_norm": 1.2518123388290405,
      "learning_rate": 0.00021490301920352344,
      "loss": 0.591,
      "step": 557900
    },
    {
      "epoch": 5.906728209145622,
      "grad_norm": 0.9705315232276917,
      "learning_rate": 0.00021485728498080286,
      "loss": 0.5941,
      "step": 557950
    },
    {
      "epoch": 5.907257530925625,
      "grad_norm": 1.2531687021255493,
      "learning_rate": 0.00021481155195784166,
      "loss": 0.5842,
      "step": 558000
    },
    {
      "epoch": 5.907257530925625,
      "eval_loss": 0.37936797738075256,
      "eval_runtime": 46.7669,
      "eval_samples_per_second": 3590.784,
      "eval_steps_per_second": 448.864,
      "step": 558000
    },
    {
      "epoch": 5.9077868527056285,
      "grad_norm": 1.1115719079971313,
      "learning_rate": 0.00021476582013620126,
      "loss": 0.5826,
      "step": 558050
    },
    {
      "epoch": 5.908316174485631,
      "grad_norm": 1.1894049644470215,
      "learning_rate": 0.0002147200895174427,
      "loss": 0.5884,
      "step": 558100
    },
    {
      "epoch": 5.908845496265635,
      "grad_norm": 1.1477677822113037,
      "learning_rate": 0.00021467436010312748,
      "loss": 0.5987,
      "step": 558150
    },
    {
      "epoch": 5.909374818045638,
      "grad_norm": 1.0439165830612183,
      "learning_rate": 0.00021462863189481652,
      "loss": 0.606,
      "step": 558200
    },
    {
      "epoch": 5.909904139825642,
      "grad_norm": 1.1122137308120728,
      "learning_rate": 0.00021458290489407124,
      "loss": 0.5889,
      "step": 558250
    },
    {
      "epoch": 5.910433461605645,
      "grad_norm": 1.182724118232727,
      "learning_rate": 0.00021453717910245246,
      "loss": 0.579,
      "step": 558300
    },
    {
      "epoch": 5.9109627833856475,
      "grad_norm": 1.1805574893951416,
      "learning_rate": 0.0002144914545215215,
      "loss": 0.5832,
      "step": 558350
    },
    {
      "epoch": 5.911492105165651,
      "grad_norm": 1.1814159154891968,
      "learning_rate": 0.00021444573115283916,
      "loss": 0.5897,
      "step": 558400
    },
    {
      "epoch": 5.912021426945655,
      "grad_norm": 1.115283727645874,
      "learning_rate": 0.0002144000089979666,
      "loss": 0.589,
      "step": 558450
    },
    {
      "epoch": 5.912550748725658,
      "grad_norm": 1.0190315246582031,
      "learning_rate": 0.00021435428805846457,
      "loss": 0.6022,
      "step": 558500
    },
    {
      "epoch": 5.912550748725658,
      "eval_loss": 0.3806056082248688,
      "eval_runtime": 46.8232,
      "eval_samples_per_second": 3586.471,
      "eval_steps_per_second": 448.325,
      "step": 558500
    },
    {
      "epoch": 5.913080070505661,
      "grad_norm": 1.286581039428711,
      "learning_rate": 0.0002143085683358942,
      "loss": 0.5912,
      "step": 558550
    },
    {
      "epoch": 5.9136093922856645,
      "grad_norm": 1.3087074756622314,
      "learning_rate": 0.00021426284983181611,
      "loss": 0.5834,
      "step": 558600
    },
    {
      "epoch": 5.914138714065667,
      "grad_norm": 1.2096608877182007,
      "learning_rate": 0.0002142171325477913,
      "loss": 0.5848,
      "step": 558650
    },
    {
      "epoch": 5.914668035845671,
      "grad_norm": 1.2546919584274292,
      "learning_rate": 0.00021417141648538042,
      "loss": 0.5898,
      "step": 558700
    },
    {
      "epoch": 5.915197357625674,
      "grad_norm": 1.0821620225906372,
      "learning_rate": 0.00021412570164614425,
      "loss": 0.589,
      "step": 558750
    },
    {
      "epoch": 5.915726679405678,
      "grad_norm": 1.2314612865447998,
      "learning_rate": 0.00021407998803164342,
      "loss": 0.605,
      "step": 558800
    },
    {
      "epoch": 5.916256001185681,
      "grad_norm": 1.1173495054244995,
      "learning_rate": 0.00021403427564343876,
      "loss": 0.5902,
      "step": 558850
    },
    {
      "epoch": 5.916785322965684,
      "grad_norm": 1.1772631406784058,
      "learning_rate": 0.00021398856448309056,
      "loss": 0.5936,
      "step": 558900
    },
    {
      "epoch": 5.917314644745687,
      "grad_norm": 1.1852060556411743,
      "learning_rate": 0.00021394285455215973,
      "loss": 0.5821,
      "step": 558950
    },
    {
      "epoch": 5.917843966525691,
      "grad_norm": 1.1604852676391602,
      "learning_rate": 0.00021389714585220648,
      "loss": 0.594,
      "step": 559000
    },
    {
      "epoch": 5.917843966525691,
      "eval_loss": 0.37967392802238464,
      "eval_runtime": 46.8203,
      "eval_samples_per_second": 3586.692,
      "eval_steps_per_second": 448.352,
      "step": 559000
    },
    {
      "epoch": 5.918373288305694,
      "grad_norm": 1.116265058517456,
      "learning_rate": 0.00021385143838479156,
      "loss": 0.6,
      "step": 559050
    },
    {
      "epoch": 5.918902610085697,
      "grad_norm": 1.3851959705352783,
      "learning_rate": 0.00021380573215147518,
      "loss": 0.5941,
      "step": 559100
    },
    {
      "epoch": 5.9194319318657005,
      "grad_norm": 1.2020773887634277,
      "learning_rate": 0.00021376002715381792,
      "loss": 0.5893,
      "step": 559150
    },
    {
      "epoch": 5.919961253645704,
      "grad_norm": 1.0708420276641846,
      "learning_rate": 0.00021371432339337994,
      "loss": 0.5949,
      "step": 559200
    },
    {
      "epoch": 5.920490575425707,
      "grad_norm": 1.3238526582717896,
      "learning_rate": 0.00021366862087172177,
      "loss": 0.5867,
      "step": 559250
    },
    {
      "epoch": 5.92101989720571,
      "grad_norm": 1.1570615768432617,
      "learning_rate": 0.00021362291959040343,
      "loss": 0.5932,
      "step": 559300
    },
    {
      "epoch": 5.921549218985714,
      "grad_norm": 1.1796208620071411,
      "learning_rate": 0.0002135772195509854,
      "loss": 0.5967,
      "step": 559350
    },
    {
      "epoch": 5.922078540765717,
      "grad_norm": 1.1849873065948486,
      "learning_rate": 0.0002135315207550276,
      "loss": 0.5972,
      "step": 559400
    },
    {
      "epoch": 5.92260786254572,
      "grad_norm": 1.1294437646865845,
      "learning_rate": 0.0002134858232040904,
      "loss": 0.5893,
      "step": 559450
    },
    {
      "epoch": 5.923137184325723,
      "grad_norm": 1.0649693012237549,
      "learning_rate": 0.00021344012689973377,
      "loss": 0.5891,
      "step": 559500
    },
    {
      "epoch": 5.923137184325723,
      "eval_loss": 0.37781575322151184,
      "eval_runtime": 46.7363,
      "eval_samples_per_second": 3593.142,
      "eval_steps_per_second": 449.159,
      "step": 559500
    },
    {
      "epoch": 5.923666506105727,
      "grad_norm": 1.0480847358703613,
      "learning_rate": 0.0002133944318435178,
      "loss": 0.5913,
      "step": 559550
    },
    {
      "epoch": 5.92419582788573,
      "grad_norm": 1.2587196826934814,
      "learning_rate": 0.00021334873803700253,
      "loss": 0.5977,
      "step": 559600
    },
    {
      "epoch": 5.924725149665734,
      "grad_norm": 1.1769940853118896,
      "learning_rate": 0.0002133030454817479,
      "loss": 0.5971,
      "step": 559650
    },
    {
      "epoch": 5.9252544714457365,
      "grad_norm": 1.2512128353118896,
      "learning_rate": 0.0002132582679930748,
      "loss": 0.5941,
      "step": 559700
    },
    {
      "epoch": 5.92578379322574,
      "grad_norm": 1.0770366191864014,
      "learning_rate": 0.00021321257791991825,
      "loss": 0.5868,
      "step": 559750
    },
    {
      "epoch": 5.926313115005743,
      "grad_norm": 1.0968481302261353,
      "learning_rate": 0.00021316688910267087,
      "loss": 0.5851,
      "step": 559800
    },
    {
      "epoch": 5.926842436785746,
      "grad_norm": 1.023966908454895,
      "learning_rate": 0.0002131212015428923,
      "loss": 0.5921,
      "step": 559850
    },
    {
      "epoch": 5.92737175856575,
      "grad_norm": 1.1440963745117188,
      "learning_rate": 0.00021307551524214245,
      "loss": 0.5884,
      "step": 559900
    },
    {
      "epoch": 5.9279010803457535,
      "grad_norm": 1.1345711946487427,
      "learning_rate": 0.00021302983020198094,
      "loss": 0.5887,
      "step": 559950
    },
    {
      "epoch": 5.928430402125756,
      "grad_norm": 1.0658340454101562,
      "learning_rate": 0.00021298414642396748,
      "loss": 0.5874,
      "step": 560000
    },
    {
      "epoch": 5.928430402125756,
      "eval_loss": 0.37743815779685974,
      "eval_runtime": 46.725,
      "eval_samples_per_second": 3594.008,
      "eval_steps_per_second": 449.267,
      "step": 560000
    },
    {
      "epoch": 5.928959723905759,
      "grad_norm": 1.1942309141159058,
      "learning_rate": 0.00021293846390966166,
      "loss": 0.5932,
      "step": 560050
    },
    {
      "epoch": 5.929489045685763,
      "grad_norm": 1.2122094631195068,
      "learning_rate": 0.00021289278266062314,
      "loss": 0.5873,
      "step": 560100
    },
    {
      "epoch": 5.930018367465766,
      "grad_norm": 1.1466624736785889,
      "learning_rate": 0.00021284710267841135,
      "loss": 0.5945,
      "step": 560150
    },
    {
      "epoch": 5.93054768924577,
      "grad_norm": 1.136857271194458,
      "learning_rate": 0.00021280142396458594,
      "loss": 0.5854,
      "step": 560200
    },
    {
      "epoch": 5.9310770110257724,
      "grad_norm": 1.1332085132598877,
      "learning_rate": 0.00021275574652070616,
      "loss": 0.6034,
      "step": 560250
    },
    {
      "epoch": 5.931606332805776,
      "grad_norm": 1.1644023656845093,
      "learning_rate": 0.00021271007034833167,
      "loss": 0.5859,
      "step": 560300
    },
    {
      "epoch": 5.932135654585779,
      "grad_norm": 1.17557692527771,
      "learning_rate": 0.00021266439544902156,
      "loss": 0.5888,
      "step": 560350
    },
    {
      "epoch": 5.932664976365783,
      "grad_norm": 1.1126195192337036,
      "learning_rate": 0.00021261872182433541,
      "loss": 0.5908,
      "step": 560400
    },
    {
      "epoch": 5.933194298145786,
      "grad_norm": 1.242031216621399,
      "learning_rate": 0.0002125730494758323,
      "loss": 0.5957,
      "step": 560450
    },
    {
      "epoch": 5.9337236199257894,
      "grad_norm": 1.2554396390914917,
      "learning_rate": 0.00021252737840507166,
      "loss": 0.5861,
      "step": 560500
    },
    {
      "epoch": 5.9337236199257894,
      "eval_loss": 0.37854239344596863,
      "eval_runtime": 46.8531,
      "eval_samples_per_second": 3584.183,
      "eval_steps_per_second": 448.039,
      "step": 560500
    },
    {
      "epoch": 5.934252941705792,
      "grad_norm": 1.1057881116867065,
      "learning_rate": 0.00021248170861361246,
      "loss": 0.5892,
      "step": 560550
    },
    {
      "epoch": 5.934782263485795,
      "grad_norm": 1.2477220296859741,
      "learning_rate": 0.0002124360401030141,
      "loss": 0.5748,
      "step": 560600
    },
    {
      "epoch": 5.935311585265799,
      "grad_norm": 1.140210509300232,
      "learning_rate": 0.00021239037287483544,
      "loss": 0.5921,
      "step": 560650
    },
    {
      "epoch": 5.935840907045803,
      "grad_norm": 1.0545177459716797,
      "learning_rate": 0.00021234470693063566,
      "loss": 0.5974,
      "step": 560700
    },
    {
      "epoch": 5.936370228825806,
      "grad_norm": 1.2048840522766113,
      "learning_rate": 0.00021229904227197384,
      "loss": 0.5855,
      "step": 560750
    },
    {
      "epoch": 5.936899550605808,
      "grad_norm": 1.091230869293213,
      "learning_rate": 0.00021225337890040885,
      "loss": 0.5924,
      "step": 560800
    },
    {
      "epoch": 5.937428872385812,
      "grad_norm": 1.1552077531814575,
      "learning_rate": 0.00021220771681749968,
      "loss": 0.5967,
      "step": 560850
    },
    {
      "epoch": 5.937958194165815,
      "grad_norm": 1.1780205965042114,
      "learning_rate": 0.00021216205602480522,
      "loss": 0.5887,
      "step": 560900
    },
    {
      "epoch": 5.938487515945819,
      "grad_norm": 1.1305341720581055,
      "learning_rate": 0.00021211639652388416,
      "loss": 0.5928,
      "step": 560950
    },
    {
      "epoch": 5.939016837725822,
      "grad_norm": 1.1979697942733765,
      "learning_rate": 0.0002120707383162956,
      "loss": 0.5853,
      "step": 561000
    },
    {
      "epoch": 5.939016837725822,
      "eval_loss": 0.3777157962322235,
      "eval_runtime": 46.813,
      "eval_samples_per_second": 3587.25,
      "eval_steps_per_second": 448.422,
      "step": 561000
    },
    {
      "epoch": 5.939546159505825,
      "grad_norm": 1.1045161485671997,
      "learning_rate": 0.00021202508140359802,
      "loss": 0.5846,
      "step": 561050
    },
    {
      "epoch": 5.940075481285828,
      "grad_norm": 1.0461581945419312,
      "learning_rate": 0.00021197942578735034,
      "loss": 0.5903,
      "step": 561100
    },
    {
      "epoch": 5.940604803065832,
      "grad_norm": 1.2510284185409546,
      "learning_rate": 0.00021193377146911096,
      "loss": 0.5847,
      "step": 561150
    },
    {
      "epoch": 5.941134124845835,
      "grad_norm": 1.1900039911270142,
      "learning_rate": 0.0002118881184504388,
      "loss": 0.5867,
      "step": 561200
    },
    {
      "epoch": 5.941663446625839,
      "grad_norm": 1.2414284944534302,
      "learning_rate": 0.00021184246673289223,
      "loss": 0.5965,
      "step": 561250
    },
    {
      "epoch": 5.9421927684058415,
      "grad_norm": 1.128159523010254,
      "learning_rate": 0.00021179681631802993,
      "loss": 0.593,
      "step": 561300
    },
    {
      "epoch": 5.942722090185844,
      "grad_norm": 1.2760108709335327,
      "learning_rate": 0.0002117511672074102,
      "loss": 0.5878,
      "step": 561350
    },
    {
      "epoch": 5.943251411965848,
      "grad_norm": 1.1357169151306152,
      "learning_rate": 0.0002117055194025917,
      "loss": 0.5871,
      "step": 561400
    },
    {
      "epoch": 5.943780733745852,
      "grad_norm": 1.0999298095703125,
      "learning_rate": 0.00021165987290513262,
      "loss": 0.5943,
      "step": 561450
    },
    {
      "epoch": 5.944310055525855,
      "grad_norm": 1.195112705230713,
      "learning_rate": 0.0002116142277165915,
      "loss": 0.5972,
      "step": 561500
    },
    {
      "epoch": 5.944310055525855,
      "eval_loss": 0.3773936629295349,
      "eval_runtime": 46.7841,
      "eval_samples_per_second": 3589.464,
      "eval_steps_per_second": 448.699,
      "step": 561500
    },
    {
      "epoch": 5.944839377305858,
      "grad_norm": 1.2241767644882202,
      "learning_rate": 0.00021156858383852652,
      "loss": 0.5884,
      "step": 561550
    },
    {
      "epoch": 5.945368699085861,
      "grad_norm": 1.3135842084884644,
      "learning_rate": 0.000211522941272496,
      "loss": 0.5872,
      "step": 561600
    },
    {
      "epoch": 5.945898020865864,
      "grad_norm": 0.9684752225875854,
      "learning_rate": 0.00021147730002005815,
      "loss": 0.5944,
      "step": 561650
    },
    {
      "epoch": 5.946427342645868,
      "grad_norm": 1.1806215047836304,
      "learning_rate": 0.00021143166008277117,
      "loss": 0.5861,
      "step": 561700
    },
    {
      "epoch": 5.946956664425871,
      "grad_norm": 1.1207224130630493,
      "learning_rate": 0.0002113860214621931,
      "loss": 0.5847,
      "step": 561750
    },
    {
      "epoch": 5.947485986205875,
      "grad_norm": 0.9645989537239075,
      "learning_rate": 0.00021134129689299934,
      "loss": 0.5893,
      "step": 561800
    },
    {
      "epoch": 5.9480153079858775,
      "grad_norm": 1.226504921913147,
      "learning_rate": 0.0002112956608841017,
      "loss": 0.5994,
      "step": 561850
    },
    {
      "epoch": 5.948544629765881,
      "grad_norm": 1.1874929666519165,
      "learning_rate": 0.00021125002619655609,
      "loss": 0.6013,
      "step": 561900
    },
    {
      "epoch": 5.949073951545884,
      "grad_norm": 1.0918726921081543,
      "learning_rate": 0.00021120439283192025,
      "loss": 0.5854,
      "step": 561950
    },
    {
      "epoch": 5.949603273325888,
      "grad_norm": 1.2403095960617065,
      "learning_rate": 0.00021115876079175232,
      "loss": 0.5918,
      "step": 562000
    },
    {
      "epoch": 5.949603273325888,
      "eval_loss": 0.3773699402809143,
      "eval_runtime": 46.8051,
      "eval_samples_per_second": 3587.854,
      "eval_steps_per_second": 448.498,
      "step": 562000
    },
    {
      "epoch": 5.950132595105891,
      "grad_norm": 1.1610709428787231,
      "learning_rate": 0.00021111313007760998,
      "loss": 0.5841,
      "step": 562050
    },
    {
      "epoch": 5.950661916885894,
      "grad_norm": 1.1623483896255493,
      "learning_rate": 0.00021106750069105118,
      "loss": 0.5817,
      "step": 562100
    },
    {
      "epoch": 5.951191238665897,
      "grad_norm": 1.0769363641738892,
      "learning_rate": 0.0002110218726336336,
      "loss": 0.589,
      "step": 562150
    },
    {
      "epoch": 5.951720560445901,
      "grad_norm": 1.1606916189193726,
      "learning_rate": 0.000210976245906915,
      "loss": 0.5827,
      "step": 562200
    },
    {
      "epoch": 5.952249882225904,
      "grad_norm": 1.0561387538909912,
      "learning_rate": 0.00021093062051245304,
      "loss": 0.585,
      "step": 562250
    },
    {
      "epoch": 5.952779204005907,
      "grad_norm": 1.0565131902694702,
      "learning_rate": 0.00021088499645180537,
      "loss": 0.5935,
      "step": 562300
    },
    {
      "epoch": 5.953308525785911,
      "grad_norm": 1.2037452459335327,
      "learning_rate": 0.00021083937372652953,
      "loss": 0.5954,
      "step": 562350
    },
    {
      "epoch": 5.9538378475659135,
      "grad_norm": 1.247199535369873,
      "learning_rate": 0.0002107937523381832,
      "loss": 0.5883,
      "step": 562400
    },
    {
      "epoch": 5.954367169345917,
      "grad_norm": 1.1350797414779663,
      "learning_rate": 0.00021074813228832374,
      "loss": 0.5886,
      "step": 562450
    },
    {
      "epoch": 5.95489649112592,
      "grad_norm": 0.9872500896453857,
      "learning_rate": 0.0002107025135785087,
      "loss": 0.5921,
      "step": 562500
    },
    {
      "epoch": 5.95489649112592,
      "eval_loss": 0.37957116961479187,
      "eval_runtime": 46.7735,
      "eval_samples_per_second": 3590.277,
      "eval_steps_per_second": 448.801,
      "step": 562500
    },
    {
      "epoch": 5.955425812905924,
      "grad_norm": 1.171624779701233,
      "learning_rate": 0.00021065689621029533,
      "loss": 0.5796,
      "step": 562550
    },
    {
      "epoch": 5.955955134685927,
      "grad_norm": 1.2595223188400269,
      "learning_rate": 0.00021061128018524123,
      "loss": 0.5901,
      "step": 562600
    },
    {
      "epoch": 5.9564844564659305,
      "grad_norm": 1.11674165725708,
      "learning_rate": 0.00021056566550490345,
      "loss": 0.5899,
      "step": 562650
    },
    {
      "epoch": 5.957013778245933,
      "grad_norm": 1.1379961967468262,
      "learning_rate": 0.00021052005217083946,
      "loss": 0.5931,
      "step": 562700
    },
    {
      "epoch": 5.957543100025937,
      "grad_norm": 1.2324597835540771,
      "learning_rate": 0.00021047444018460637,
      "loss": 0.574,
      "step": 562750
    },
    {
      "epoch": 5.95807242180594,
      "grad_norm": 1.2258906364440918,
      "learning_rate": 0.00021042882954776145,
      "loss": 0.5852,
      "step": 562800
    },
    {
      "epoch": 5.958601743585943,
      "grad_norm": 1.2210657596588135,
      "learning_rate": 0.00021038322026186172,
      "loss": 0.5823,
      "step": 562850
    },
    {
      "epoch": 5.959131065365947,
      "grad_norm": 1.0777190923690796,
      "learning_rate": 0.0002103376123284644,
      "loss": 0.5726,
      "step": 562900
    },
    {
      "epoch": 5.95966038714595,
      "grad_norm": 1.2371019124984741,
      "learning_rate": 0.00021029200574912633,
      "loss": 0.598,
      "step": 562950
    },
    {
      "epoch": 5.960189708925953,
      "grad_norm": 1.2860859632492065,
      "learning_rate": 0.0002102464005254047,
      "loss": 0.5873,
      "step": 563000
    },
    {
      "epoch": 5.960189708925953,
      "eval_loss": 0.3782755136489868,
      "eval_runtime": 46.7724,
      "eval_samples_per_second": 3590.362,
      "eval_steps_per_second": 448.811,
      "step": 563000
    },
    {
      "epoch": 5.960719030705956,
      "grad_norm": 1.262673020362854,
      "learning_rate": 0.00021020079665885636,
      "loss": 0.5926,
      "step": 563050
    },
    {
      "epoch": 5.96124835248596,
      "grad_norm": 0.9783468842506409,
      "learning_rate": 0.00021015519415103822,
      "loss": 0.6003,
      "step": 563100
    },
    {
      "epoch": 5.961777674265963,
      "grad_norm": 1.2637218236923218,
      "learning_rate": 0.00021010959300350713,
      "loss": 0.5842,
      "step": 563150
    },
    {
      "epoch": 5.9623069960459665,
      "grad_norm": 1.1120996475219727,
      "learning_rate": 0.00021006399321781997,
      "loss": 0.5858,
      "step": 563200
    },
    {
      "epoch": 5.962836317825969,
      "grad_norm": 1.1719653606414795,
      "learning_rate": 0.00021001839479553334,
      "loss": 0.5974,
      "step": 563250
    },
    {
      "epoch": 5.963365639605973,
      "grad_norm": 1.0228973627090454,
      "learning_rate": 0.00020997279773820416,
      "loss": 0.5864,
      "step": 563300
    },
    {
      "epoch": 5.963894961385976,
      "grad_norm": 1.1416246891021729,
      "learning_rate": 0.00020992720204738885,
      "loss": 0.5919,
      "step": 563350
    },
    {
      "epoch": 5.96442428316598,
      "grad_norm": 1.1491725444793701,
      "learning_rate": 0.00020988160772464432,
      "loss": 0.5743,
      "step": 563400
    },
    {
      "epoch": 5.964953604945983,
      "grad_norm": 1.096045732498169,
      "learning_rate": 0.00020983601477152686,
      "loss": 0.5936,
      "step": 563450
    },
    {
      "epoch": 5.965482926725986,
      "grad_norm": 1.0842112302780151,
      "learning_rate": 0.00020979042318959324,
      "loss": 0.5761,
      "step": 563500
    },
    {
      "epoch": 5.965482926725986,
      "eval_loss": 0.37703242897987366,
      "eval_runtime": 46.7465,
      "eval_samples_per_second": 3592.353,
      "eval_steps_per_second": 449.06,
      "step": 563500
    },
    {
      "epoch": 5.966012248505989,
      "grad_norm": 1.166084885597229,
      "learning_rate": 0.00020974574477112068,
      "loss": 0.5958,
      "step": 563550
    },
    {
      "epoch": 5.966541570285992,
      "grad_norm": 1.0416184663772583,
      "learning_rate": 0.0002097001559087226,
      "loss": 0.5851,
      "step": 563600
    },
    {
      "epoch": 5.967070892065996,
      "grad_norm": 1.1886111497879028,
      "learning_rate": 0.00020965456842214652,
      "loss": 0.5905,
      "step": 563650
    },
    {
      "epoch": 5.967600213846,
      "grad_norm": 1.133404016494751,
      "learning_rate": 0.00020960898231294858,
      "loss": 0.5895,
      "step": 563700
    },
    {
      "epoch": 5.9681295356260025,
      "grad_norm": 1.130206823348999,
      "learning_rate": 0.00020956339758268527,
      "loss": 0.5809,
      "step": 563750
    },
    {
      "epoch": 5.968658857406005,
      "grad_norm": 1.0334688425064087,
      "learning_rate": 0.00020951781423291267,
      "loss": 0.5933,
      "step": 563800
    },
    {
      "epoch": 5.969188179186009,
      "grad_norm": 1.1748038530349731,
      "learning_rate": 0.0002094722322651871,
      "loss": 0.5867,
      "step": 563850
    },
    {
      "epoch": 5.969717500966012,
      "grad_norm": 1.1748074293136597,
      "learning_rate": 0.00020942665168106455,
      "loss": 0.5848,
      "step": 563900
    },
    {
      "epoch": 5.970246822746016,
      "grad_norm": 1.0648225545883179,
      "learning_rate": 0.0002093810724821014,
      "loss": 0.5825,
      "step": 563950
    },
    {
      "epoch": 5.970776144526019,
      "grad_norm": 1.2037805318832397,
      "learning_rate": 0.0002093354946698534,
      "loss": 0.5919,
      "step": 564000
    },
    {
      "epoch": 5.970776144526019,
      "eval_loss": 0.377046674489975,
      "eval_runtime": 46.7151,
      "eval_samples_per_second": 3594.771,
      "eval_steps_per_second": 449.362,
      "step": 564000
    },
    {
      "epoch": 5.971305466306022,
      "grad_norm": 1.1588929891586304,
      "learning_rate": 0.00020928991824587678,
      "loss": 0.5789,
      "step": 564050
    },
    {
      "epoch": 5.971834788086025,
      "grad_norm": 1.0928725004196167,
      "learning_rate": 0.0002092443432117273,
      "loss": 0.5885,
      "step": 564100
    },
    {
      "epoch": 5.972364109866029,
      "grad_norm": 1.1515918970108032,
      "learning_rate": 0.00020919876956896117,
      "loss": 0.593,
      "step": 564150
    },
    {
      "epoch": 5.972893431646032,
      "grad_norm": 1.1793767213821411,
      "learning_rate": 0.00020915319731913394,
      "loss": 0.589,
      "step": 564200
    },
    {
      "epoch": 5.973422753426036,
      "grad_norm": 1.1022218465805054,
      "learning_rate": 0.0002091076264638016,
      "loss": 0.5891,
      "step": 564250
    },
    {
      "epoch": 5.973952075206038,
      "grad_norm": 1.2396519184112549,
      "learning_rate": 0.00020906205700451993,
      "loss": 0.5905,
      "step": 564300
    },
    {
      "epoch": 5.974481396986041,
      "grad_norm": 1.1304795742034912,
      "learning_rate": 0.00020901648894284462,
      "loss": 0.5968,
      "step": 564350
    },
    {
      "epoch": 5.975010718766045,
      "grad_norm": 1.2448177337646484,
      "learning_rate": 0.00020897092228033126,
      "loss": 0.5855,
      "step": 564400
    },
    {
      "epoch": 5.975540040546049,
      "grad_norm": 1.2235156297683716,
      "learning_rate": 0.00020892535701853572,
      "loss": 0.5871,
      "step": 564450
    },
    {
      "epoch": 5.976069362326052,
      "grad_norm": 1.151447057723999,
      "learning_rate": 0.0002088797931590133,
      "loss": 0.5772,
      "step": 564500
    },
    {
      "epoch": 5.976069362326052,
      "eval_loss": 0.3762851655483246,
      "eval_runtime": 46.6869,
      "eval_samples_per_second": 3596.938,
      "eval_steps_per_second": 449.633,
      "step": 564500
    },
    {
      "epoch": 5.9765986841060545,
      "grad_norm": 1.1295342445373535,
      "learning_rate": 0.00020883423070331978,
      "loss": 0.5805,
      "step": 564550
    },
    {
      "epoch": 5.977128005886058,
      "grad_norm": 1.2287451028823853,
      "learning_rate": 0.0002087886696530104,
      "loss": 0.5819,
      "step": 564600
    },
    {
      "epoch": 5.977657327666061,
      "grad_norm": 1.2012693881988525,
      "learning_rate": 0.00020874311000964083,
      "loss": 0.5815,
      "step": 564650
    },
    {
      "epoch": 5.978186649446065,
      "grad_norm": 1.107053518295288,
      "learning_rate": 0.00020869755177476627,
      "loss": 0.5844,
      "step": 564700
    },
    {
      "epoch": 5.978715971226068,
      "grad_norm": 0.993883490562439,
      "learning_rate": 0.00020865199494994225,
      "loss": 0.5755,
      "step": 564750
    },
    {
      "epoch": 5.9792452930060715,
      "grad_norm": 1.2198187112808228,
      "learning_rate": 0.00020860643953672382,
      "loss": 0.5893,
      "step": 564800
    },
    {
      "epoch": 5.979774614786074,
      "grad_norm": 1.10450279712677,
      "learning_rate": 0.0002085608855366665,
      "loss": 0.5894,
      "step": 564850
    },
    {
      "epoch": 5.980303936566078,
      "grad_norm": 1.1313283443450928,
      "learning_rate": 0.00020851533295132525,
      "loss": 0.5802,
      "step": 564900
    },
    {
      "epoch": 5.980833258346081,
      "grad_norm": 1.0756007432937622,
      "learning_rate": 0.0002084697817822554,
      "loss": 0.5984,
      "step": 564950
    },
    {
      "epoch": 5.981362580126085,
      "grad_norm": 1.1310011148452759,
      "learning_rate": 0.00020842423203101186,
      "loss": 0.576,
      "step": 565000
    },
    {
      "epoch": 5.981362580126085,
      "eval_loss": 0.37586262822151184,
      "eval_runtime": 46.7753,
      "eval_samples_per_second": 3590.142,
      "eval_steps_per_second": 448.784,
      "step": 565000
    },
    {
      "epoch": 5.981891901906088,
      "grad_norm": 1.1658779382705688,
      "learning_rate": 0.00020837868369914987,
      "loss": 0.5812,
      "step": 565050
    },
    {
      "epoch": 5.9824212236860905,
      "grad_norm": 1.00711989402771,
      "learning_rate": 0.00020833313678822433,
      "loss": 0.5898,
      "step": 565100
    },
    {
      "epoch": 5.982950545466094,
      "grad_norm": 1.1892545223236084,
      "learning_rate": 0.00020828759129979023,
      "loss": 0.59,
      "step": 565150
    },
    {
      "epoch": 5.983479867246098,
      "grad_norm": 1.1576982736587524,
      "learning_rate": 0.00020824204723540241,
      "loss": 0.5841,
      "step": 565200
    },
    {
      "epoch": 5.984009189026101,
      "grad_norm": 1.3084362745285034,
      "learning_rate": 0.00020819650459661589,
      "loss": 0.5939,
      "step": 565250
    },
    {
      "epoch": 5.984538510806104,
      "grad_norm": 1.1460115909576416,
      "learning_rate": 0.00020815096338498528,
      "loss": 0.5925,
      "step": 565300
    },
    {
      "epoch": 5.9850678325861075,
      "grad_norm": 1.1226286888122559,
      "learning_rate": 0.00020810542360206552,
      "loss": 0.5723,
      "step": 565350
    },
    {
      "epoch": 5.98559715436611,
      "grad_norm": 1.0161253213882446,
      "learning_rate": 0.00020805988524941112,
      "loss": 0.5896,
      "step": 565400
    },
    {
      "epoch": 5.986126476146114,
      "grad_norm": 1.1273212432861328,
      "learning_rate": 0.000208014348328577,
      "loss": 0.5935,
      "step": 565450
    },
    {
      "epoch": 5.986655797926117,
      "grad_norm": 1.0774009227752686,
      "learning_rate": 0.0002079688128411175,
      "loss": 0.588,
      "step": 565500
    },
    {
      "epoch": 5.986655797926117,
      "eval_loss": 0.3770124614238739,
      "eval_runtime": 46.795,
      "eval_samples_per_second": 3588.632,
      "eval_steps_per_second": 448.595,
      "step": 565500
    },
    {
      "epoch": 5.987185119706121,
      "grad_norm": 1.159016728401184,
      "learning_rate": 0.0002079232787885874,
      "loss": 0.5865,
      "step": 565550
    },
    {
      "epoch": 5.987714441486124,
      "grad_norm": 0.9773604273796082,
      "learning_rate": 0.00020787774617254105,
      "loss": 0.5834,
      "step": 565600
    },
    {
      "epoch": 5.988243763266127,
      "grad_norm": 1.2308818101882935,
      "learning_rate": 0.0002078322149945331,
      "loss": 0.5813,
      "step": 565650
    },
    {
      "epoch": 5.98877308504613,
      "grad_norm": 1.1608943939208984,
      "learning_rate": 0.00020778668525611778,
      "loss": 0.5848,
      "step": 565700
    },
    {
      "epoch": 5.989302406826134,
      "grad_norm": 1.2130975723266602,
      "learning_rate": 0.0002077411569588496,
      "loss": 0.5903,
      "step": 565750
    },
    {
      "epoch": 5.989831728606137,
      "grad_norm": 1.1083043813705444,
      "learning_rate": 0.00020769563010428278,
      "loss": 0.5876,
      "step": 565800
    },
    {
      "epoch": 5.99036105038614,
      "grad_norm": 1.1722691059112549,
      "learning_rate": 0.00020765010469397162,
      "loss": 0.5861,
      "step": 565850
    },
    {
      "epoch": 5.9908903721661435,
      "grad_norm": 1.1460022926330566,
      "learning_rate": 0.0002076045807294704,
      "loss": 0.5962,
      "step": 565900
    },
    {
      "epoch": 5.991419693946147,
      "grad_norm": 1.1428754329681396,
      "learning_rate": 0.00020755905821233324,
      "loss": 0.589,
      "step": 565950
    },
    {
      "epoch": 5.99194901572615,
      "grad_norm": 1.2191888093948364,
      "learning_rate": 0.0002075135371441142,
      "loss": 0.5821,
      "step": 566000
    },
    {
      "epoch": 5.99194901572615,
      "eval_loss": 0.3742194175720215,
      "eval_runtime": 46.7792,
      "eval_samples_per_second": 3589.84,
      "eval_steps_per_second": 448.746,
      "step": 566000
    },
    {
      "epoch": 5.992478337506153,
      "grad_norm": 1.2447046041488647,
      "learning_rate": 0.00020746801752636755,
      "loss": 0.5896,
      "step": 566050
    },
    {
      "epoch": 5.993007659286157,
      "grad_norm": 1.2139254808425903,
      "learning_rate": 0.00020742249936064706,
      "loss": 0.5829,
      "step": 566100
    },
    {
      "epoch": 5.99353698106616,
      "grad_norm": 1.206041693687439,
      "learning_rate": 0.00020737698264850694,
      "loss": 0.5934,
      "step": 566150
    },
    {
      "epoch": 5.994066302846163,
      "grad_norm": 1.126868724822998,
      "learning_rate": 0.00020733146739150088,
      "loss": 0.5941,
      "step": 566200
    },
    {
      "epoch": 5.994595624626166,
      "grad_norm": 1.2480311393737793,
      "learning_rate": 0.000207285953591183,
      "loss": 0.5882,
      "step": 566250
    },
    {
      "epoch": 5.99512494640617,
      "grad_norm": 1.1634200811386108,
      "learning_rate": 0.0002072404412491069,
      "loss": 0.5804,
      "step": 566300
    },
    {
      "epoch": 5.995654268186173,
      "grad_norm": 1.1518633365631104,
      "learning_rate": 0.00020719493036682653,
      "loss": 0.5816,
      "step": 566350
    },
    {
      "epoch": 5.996183589966177,
      "grad_norm": 1.2432682514190674,
      "learning_rate": 0.00020714942094589544,
      "loss": 0.5797,
      "step": 566400
    },
    {
      "epoch": 5.9967129117461795,
      "grad_norm": 1.1053121089935303,
      "learning_rate": 0.0002071039129878675,
      "loss": 0.5904,
      "step": 566450
    },
    {
      "epoch": 5.997242233526183,
      "grad_norm": 1.173673152923584,
      "learning_rate": 0.00020705840649429616,
      "loss": 0.5818,
      "step": 566500
    },
    {
      "epoch": 5.997242233526183,
      "eval_loss": 0.37707823514938354,
      "eval_runtime": 46.7612,
      "eval_samples_per_second": 3591.225,
      "eval_steps_per_second": 448.919,
      "step": 566500
    },
    {
      "epoch": 5.997771555306186,
      "grad_norm": 1.1236836910247803,
      "learning_rate": 0.00020701290146673518,
      "loss": 0.5906,
      "step": 566550
    },
    {
      "epoch": 5.998300877086189,
      "grad_norm": 1.1054141521453857,
      "learning_rate": 0.00020696739790673784,
      "loss": 0.588,
      "step": 566600
    },
    {
      "epoch": 5.998830198866193,
      "grad_norm": 1.1718608140945435,
      "learning_rate": 0.00020692189581585785,
      "loss": 0.5813,
      "step": 566650
    },
    {
      "epoch": 5.9993595206461965,
      "grad_norm": 1.2253859043121338,
      "learning_rate": 0.00020687639519564852,
      "loss": 0.5806,
      "step": 566700
    },
    {
      "epoch": 5.999888842426199,
      "grad_norm": 1.2099361419677734,
      "learning_rate": 0.00020683089604766326,
      "loss": 0.5836,
      "step": 566750
    },
    {
      "epoch": 6.000412870988402,
      "grad_norm": 1.210862398147583,
      "learning_rate": 0.00020678539837345534,
      "loss": 0.5723,
      "step": 566800
    },
    {
      "epoch": 6.000942192768406,
      "grad_norm": 1.2442452907562256,
      "learning_rate": 0.0002067399021745781,
      "loss": 0.5897,
      "step": 566850
    },
    {
      "epoch": 6.001471514548409,
      "grad_norm": 1.1431589126586914,
      "learning_rate": 0.00020669440745258466,
      "loss": 0.5838,
      "step": 566900
    },
    {
      "epoch": 6.0020008363284125,
      "grad_norm": 1.1436926126480103,
      "learning_rate": 0.0002066489142090284,
      "loss": 0.5797,
      "step": 566950
    },
    {
      "epoch": 6.002530158108415,
      "grad_norm": 1.0623704195022583,
      "learning_rate": 0.00020660342244546218,
      "loss": 0.5805,
      "step": 567000
    },
    {
      "epoch": 6.002530158108415,
      "eval_loss": 0.37444594502449036,
      "eval_runtime": 46.8749,
      "eval_samples_per_second": 3582.511,
      "eval_steps_per_second": 447.83,
      "step": 567000
    },
    {
      "epoch": 6.003059479888419,
      "grad_norm": 1.2038969993591309,
      "learning_rate": 0.00020655793216343933,
      "loss": 0.5946,
      "step": 567050
    },
    {
      "epoch": 6.003588801668422,
      "grad_norm": 1.1529607772827148,
      "learning_rate": 0.00020651244336451262,
      "loss": 0.5801,
      "step": 567100
    },
    {
      "epoch": 6.004118123448426,
      "grad_norm": 1.0928373336791992,
      "learning_rate": 0.00020646695605023525,
      "loss": 0.5879,
      "step": 567150
    },
    {
      "epoch": 6.004647445228429,
      "grad_norm": 1.0119969844818115,
      "learning_rate": 0.00020642147022215994,
      "loss": 0.5711,
      "step": 567200
    },
    {
      "epoch": 6.005176767008432,
      "grad_norm": 1.0905159711837769,
      "learning_rate": 0.00020637598588183975,
      "loss": 0.5783,
      "step": 567250
    },
    {
      "epoch": 6.005706088788435,
      "grad_norm": 1.1845377683639526,
      "learning_rate": 0.00020633050303082732,
      "loss": 0.5811,
      "step": 567300
    },
    {
      "epoch": 6.006235410568439,
      "grad_norm": 1.1286463737487793,
      "learning_rate": 0.0002062850216706756,
      "loss": 0.5847,
      "step": 567350
    },
    {
      "epoch": 6.006764732348442,
      "grad_norm": 1.1209412813186646,
      "learning_rate": 0.00020623954180293708,
      "loss": 0.5796,
      "step": 567400
    },
    {
      "epoch": 6.007294054128446,
      "grad_norm": 1.209210753440857,
      "learning_rate": 0.00020619406342916466,
      "loss": 0.5827,
      "step": 567450
    },
    {
      "epoch": 6.0078233759084485,
      "grad_norm": 1.157541275024414,
      "learning_rate": 0.00020614858655091075,
      "loss": 0.587,
      "step": 567500
    },
    {
      "epoch": 6.0078233759084485,
      "eval_loss": 0.3747901916503906,
      "eval_runtime": 46.7757,
      "eval_samples_per_second": 3590.112,
      "eval_steps_per_second": 448.78,
      "step": 567500
    },
    {
      "epoch": 6.008352697688451,
      "grad_norm": 1.1374186277389526,
      "learning_rate": 0.0002061031111697281,
      "loss": 0.597,
      "step": 567550
    },
    {
      "epoch": 6.008882019468455,
      "grad_norm": 1.1356631517410278,
      "learning_rate": 0.00020605854675012376,
      "loss": 0.5876,
      "step": 567600
    },
    {
      "epoch": 6.009411341248458,
      "grad_norm": 1.020524501800537,
      "learning_rate": 0.00020601307433772213,
      "loss": 0.5761,
      "step": 567650
    },
    {
      "epoch": 6.009940663028462,
      "grad_norm": 1.198910117149353,
      "learning_rate": 0.0002059676034270181,
      "loss": 0.5852,
      "step": 567700
    },
    {
      "epoch": 6.010469984808465,
      "grad_norm": 1.1902542114257812,
      "learning_rate": 0.00020592213401956385,
      "loss": 0.5838,
      "step": 567750
    },
    {
      "epoch": 6.010999306588468,
      "grad_norm": 1.131232500076294,
      "learning_rate": 0.0002058766661169119,
      "loss": 0.5783,
      "step": 567800
    },
    {
      "epoch": 6.011528628368471,
      "grad_norm": 1.207747220993042,
      "learning_rate": 0.00020583119972061425,
      "loss": 0.5811,
      "step": 567850
    },
    {
      "epoch": 6.012057950148475,
      "grad_norm": 1.186066746711731,
      "learning_rate": 0.00020578573483222328,
      "loss": 0.5788,
      "step": 567900
    },
    {
      "epoch": 6.012587271928478,
      "grad_norm": 1.2631783485412598,
      "learning_rate": 0.00020574027145329115,
      "loss": 0.5859,
      "step": 567950
    },
    {
      "epoch": 6.013116593708482,
      "grad_norm": 1.1831868886947632,
      "learning_rate": 0.00020569480958536988,
      "loss": 0.5909,
      "step": 568000
    },
    {
      "epoch": 6.013116593708482,
      "eval_loss": 0.37412169575691223,
      "eval_runtime": 46.7956,
      "eval_samples_per_second": 3588.583,
      "eval_steps_per_second": 448.589,
      "step": 568000
    },
    {
      "epoch": 6.0136459154884845,
      "grad_norm": 1.2511582374572754,
      "learning_rate": 0.00020564934923001166,
      "loss": 0.5904,
      "step": 568050
    },
    {
      "epoch": 6.014175237268488,
      "grad_norm": 1.0491724014282227,
      "learning_rate": 0.00020560389038876825,
      "loss": 0.5865,
      "step": 568100
    },
    {
      "epoch": 6.014704559048491,
      "grad_norm": 1.0830925703048706,
      "learning_rate": 0.00020555843306319183,
      "loss": 0.5775,
      "step": 568150
    },
    {
      "epoch": 6.015233880828495,
      "grad_norm": 1.2751091718673706,
      "learning_rate": 0.00020551297725483416,
      "loss": 0.5731,
      "step": 568200
    },
    {
      "epoch": 6.015763202608498,
      "grad_norm": 1.1950856447219849,
      "learning_rate": 0.00020546752296524717,
      "loss": 0.594,
      "step": 568250
    },
    {
      "epoch": 6.016292524388501,
      "grad_norm": 1.3149452209472656,
      "learning_rate": 0.00020542207019598254,
      "loss": 0.5834,
      "step": 568300
    },
    {
      "epoch": 6.016821846168504,
      "grad_norm": 1.2475279569625854,
      "learning_rate": 0.00020537661894859223,
      "loss": 0.5896,
      "step": 568350
    },
    {
      "epoch": 6.017351167948507,
      "grad_norm": 1.176061749458313,
      "learning_rate": 0.00020533116922462764,
      "loss": 0.5864,
      "step": 568400
    },
    {
      "epoch": 6.017880489728511,
      "grad_norm": 1.1923078298568726,
      "learning_rate": 0.00020528572102564068,
      "loss": 0.5698,
      "step": 568450
    },
    {
      "epoch": 6.018409811508514,
      "grad_norm": 1.0577694177627563,
      "learning_rate": 0.00020524027435318268,
      "loss": 0.5756,
      "step": 568500
    },
    {
      "epoch": 6.018409811508514,
      "eval_loss": 0.3734571039676666,
      "eval_runtime": 46.8438,
      "eval_samples_per_second": 3584.889,
      "eval_steps_per_second": 448.127,
      "step": 568500
    },
    {
      "epoch": 6.018939133288518,
      "grad_norm": 1.1679624319076538,
      "learning_rate": 0.00020519482920880542,
      "loss": 0.5802,
      "step": 568550
    },
    {
      "epoch": 6.0194684550685205,
      "grad_norm": 1.0654900074005127,
      "learning_rate": 0.00020514938559406016,
      "loss": 0.5808,
      "step": 568600
    },
    {
      "epoch": 6.019997776848524,
      "grad_norm": 1.1095969676971436,
      "learning_rate": 0.00020510394351049848,
      "loss": 0.5826,
      "step": 568650
    },
    {
      "epoch": 6.020527098628527,
      "grad_norm": 1.1052850484848022,
      "learning_rate": 0.00020505850295967165,
      "loss": 0.5923,
      "step": 568700
    },
    {
      "epoch": 6.021056420408531,
      "grad_norm": 1.1494866609573364,
      "learning_rate": 0.00020501306394313116,
      "loss": 0.5863,
      "step": 568750
    },
    {
      "epoch": 6.021585742188534,
      "grad_norm": 1.1443276405334473,
      "learning_rate": 0.00020496762646242804,
      "loss": 0.5831,
      "step": 568800
    },
    {
      "epoch": 6.0221150639685375,
      "grad_norm": 1.238724946975708,
      "learning_rate": 0.00020492219051911374,
      "loss": 0.5767,
      "step": 568850
    },
    {
      "epoch": 6.02264438574854,
      "grad_norm": 1.218919277191162,
      "learning_rate": 0.00020487675611473923,
      "loss": 0.5829,
      "step": 568900
    },
    {
      "epoch": 6.023173707528544,
      "grad_norm": 1.034155011177063,
      "learning_rate": 0.00020483132325085573,
      "loss": 0.5716,
      "step": 568950
    },
    {
      "epoch": 6.023703029308547,
      "grad_norm": 1.0260834693908691,
      "learning_rate": 0.00020478589192901434,
      "loss": 0.5753,
      "step": 569000
    },
    {
      "epoch": 6.023703029308547,
      "eval_loss": 0.3743135929107666,
      "eval_runtime": 46.8083,
      "eval_samples_per_second": 3587.612,
      "eval_steps_per_second": 448.468,
      "step": 569000
    },
    {
      "epoch": 6.02423235108855,
      "grad_norm": 1.1671972274780273,
      "learning_rate": 0.000204740462150766,
      "loss": 0.581,
      "step": 569050
    },
    {
      "epoch": 6.024761672868554,
      "grad_norm": 1.1884725093841553,
      "learning_rate": 0.00020469503391766164,
      "loss": 0.5872,
      "step": 569100
    },
    {
      "epoch": 6.025290994648556,
      "grad_norm": 1.14634370803833,
      "learning_rate": 0.0002046496072312523,
      "loss": 0.582,
      "step": 569150
    },
    {
      "epoch": 6.02582031642856,
      "grad_norm": 1.122481346130371,
      "learning_rate": 0.00020460418209308862,
      "loss": 0.5797,
      "step": 569200
    },
    {
      "epoch": 6.026349638208563,
      "grad_norm": 1.1218606233596802,
      "learning_rate": 0.00020455875850472165,
      "loss": 0.595,
      "step": 569250
    },
    {
      "epoch": 6.026878959988567,
      "grad_norm": 1.202257513999939,
      "learning_rate": 0.00020451333646770187,
      "loss": 0.576,
      "step": 569300
    },
    {
      "epoch": 6.02740828176857,
      "grad_norm": 1.3401925563812256,
      "learning_rate": 0.00020446791598358022,
      "loss": 0.5875,
      "step": 569350
    },
    {
      "epoch": 6.027937603548573,
      "grad_norm": 1.2363320589065552,
      "learning_rate": 0.00020442249705390712,
      "loss": 0.5867,
      "step": 569400
    },
    {
      "epoch": 6.028466925328576,
      "grad_norm": 1.2239142656326294,
      "learning_rate": 0.00020437707968023336,
      "loss": 0.5896,
      "step": 569450
    },
    {
      "epoch": 6.02899624710858,
      "grad_norm": 1.1777474880218506,
      "learning_rate": 0.00020433166386410925,
      "loss": 0.5764,
      "step": 569500
    },
    {
      "epoch": 6.02899624710858,
      "eval_loss": 0.3736257553100586,
      "eval_runtime": 46.8141,
      "eval_samples_per_second": 3587.168,
      "eval_steps_per_second": 448.412,
      "step": 569500
    },
    {
      "epoch": 6.029525568888583,
      "grad_norm": 1.136028528213501,
      "learning_rate": 0.0002042862496070855,
      "loss": 0.5835,
      "step": 569550
    },
    {
      "epoch": 6.030054890668587,
      "grad_norm": 1.2285584211349487,
      "learning_rate": 0.0002042417451493354,
      "loss": 0.5781,
      "step": 569600
    },
    {
      "epoch": 6.0305842124485896,
      "grad_norm": 1.1237906217575073,
      "learning_rate": 0.00020419633398390406,
      "loss": 0.577,
      "step": 569650
    },
    {
      "epoch": 6.031113534228593,
      "grad_norm": 1.2712416648864746,
      "learning_rate": 0.0002041509243821932,
      "loss": 0.5756,
      "step": 569700
    },
    {
      "epoch": 6.031642856008596,
      "grad_norm": 1.1729817390441895,
      "learning_rate": 0.0002041055163457528,
      "loss": 0.5817,
      "step": 569750
    },
    {
      "epoch": 6.032172177788599,
      "grad_norm": 1.181406855583191,
      "learning_rate": 0.0002040601098761334,
      "loss": 0.5888,
      "step": 569800
    },
    {
      "epoch": 6.032701499568603,
      "grad_norm": 1.1838144063949585,
      "learning_rate": 0.00020401470497488487,
      "loss": 0.5765,
      "step": 569850
    },
    {
      "epoch": 6.033230821348606,
      "grad_norm": 1.19322669506073,
      "learning_rate": 0.00020396930164355754,
      "loss": 0.5854,
      "step": 569900
    },
    {
      "epoch": 6.033760143128609,
      "grad_norm": 1.2136317491531372,
      "learning_rate": 0.0002039238998837013,
      "loss": 0.5883,
      "step": 569950
    },
    {
      "epoch": 6.034289464908612,
      "grad_norm": 1.2090402841567993,
      "learning_rate": 0.0002038784996968663,
      "loss": 0.5907,
      "step": 570000
    },
    {
      "epoch": 6.034289464908612,
      "eval_loss": 0.3736893832683563,
      "eval_runtime": 46.7927,
      "eval_samples_per_second": 3588.81,
      "eval_steps_per_second": 448.617,
      "step": 570000
    },
    {
      "epoch": 6.034818786688616,
      "grad_norm": 1.1822785139083862,
      "learning_rate": 0.00020383310108460233,
      "loss": 0.574,
      "step": 570050
    },
    {
      "epoch": 6.035348108468619,
      "grad_norm": 1.2209392786026,
      "learning_rate": 0.00020378770404845943,
      "loss": 0.5786,
      "step": 570100
    },
    {
      "epoch": 6.035877430248623,
      "grad_norm": 1.195611596107483,
      "learning_rate": 0.00020374230858998728,
      "loss": 0.5788,
      "step": 570150
    },
    {
      "epoch": 6.0364067520286255,
      "grad_norm": 1.1955031156539917,
      "learning_rate": 0.0002036969147107358,
      "loss": 0.5796,
      "step": 570200
    },
    {
      "epoch": 6.036936073808629,
      "grad_norm": 1.1749162673950195,
      "learning_rate": 0.00020365152241225466,
      "loss": 0.5796,
      "step": 570250
    },
    {
      "epoch": 6.037465395588632,
      "grad_norm": 1.1809470653533936,
      "learning_rate": 0.00020360613169609354,
      "loss": 0.5833,
      "step": 570300
    },
    {
      "epoch": 6.037994717368636,
      "grad_norm": 1.2002404928207397,
      "learning_rate": 0.00020356074256380202,
      "loss": 0.5835,
      "step": 570350
    },
    {
      "epoch": 6.038524039148639,
      "grad_norm": 1.1214618682861328,
      "learning_rate": 0.00020351535501692987,
      "loss": 0.5614,
      "step": 570400
    },
    {
      "epoch": 6.0390533609286425,
      "grad_norm": 1.170028567314148,
      "learning_rate": 0.00020346996905702631,
      "loss": 0.571,
      "step": 570450
    },
    {
      "epoch": 6.039582682708645,
      "grad_norm": 1.1528371572494507,
      "learning_rate": 0.00020342458468564103,
      "loss": 0.5822,
      "step": 570500
    },
    {
      "epoch": 6.039582682708645,
      "eval_loss": 0.3740912973880768,
      "eval_runtime": 46.7808,
      "eval_samples_per_second": 3589.723,
      "eval_steps_per_second": 448.731,
      "step": 570500
    },
    {
      "epoch": 6.040112004488648,
      "grad_norm": 1.1349042654037476,
      "learning_rate": 0.00020337920190432326,
      "loss": 0.5787,
      "step": 570550
    },
    {
      "epoch": 6.040641326268652,
      "grad_norm": 1.2150123119354248,
      "learning_rate": 0.00020333382071462255,
      "loss": 0.5799,
      "step": 570600
    },
    {
      "epoch": 6.041170648048655,
      "grad_norm": 1.1457328796386719,
      "learning_rate": 0.00020328844111808798,
      "loss": 0.5792,
      "step": 570650
    },
    {
      "epoch": 6.041699969828659,
      "grad_norm": 1.2534948587417603,
      "learning_rate": 0.000203243063116269,
      "loss": 0.5764,
      "step": 570700
    },
    {
      "epoch": 6.0422292916086615,
      "grad_norm": 1.141450047492981,
      "learning_rate": 0.0002031976867107146,
      "loss": 0.5776,
      "step": 570750
    },
    {
      "epoch": 6.042758613388665,
      "grad_norm": 1.1989717483520508,
      "learning_rate": 0.00020315231190297408,
      "loss": 0.5847,
      "step": 570800
    },
    {
      "epoch": 6.043287935168668,
      "grad_norm": 1.1581794023513794,
      "learning_rate": 0.0002031069386945964,
      "loss": 0.5765,
      "step": 570850
    },
    {
      "epoch": 6.043817256948672,
      "grad_norm": 1.032091498374939,
      "learning_rate": 0.00020306156708713068,
      "loss": 0.5796,
      "step": 570900
    },
    {
      "epoch": 6.044346578728675,
      "grad_norm": 1.1952850818634033,
      "learning_rate": 0.00020301619708212583,
      "loss": 0.581,
      "step": 570950
    },
    {
      "epoch": 6.0448759005086785,
      "grad_norm": 1.1698989868164062,
      "learning_rate": 0.00020297082868113076,
      "loss": 0.5782,
      "step": 571000
    },
    {
      "epoch": 6.0448759005086785,
      "eval_loss": 0.37204709649086,
      "eval_runtime": 46.7895,
      "eval_samples_per_second": 3589.053,
      "eval_steps_per_second": 448.648,
      "step": 571000
    },
    {
      "epoch": 6.045405222288681,
      "grad_norm": 1.0929532051086426,
      "learning_rate": 0.00020292546188569436,
      "loss": 0.586,
      "step": 571050
    },
    {
      "epoch": 6.045934544068685,
      "grad_norm": 1.1322460174560547,
      "learning_rate": 0.00020288009669736546,
      "loss": 0.5753,
      "step": 571100
    },
    {
      "epoch": 6.046463865848688,
      "grad_norm": 1.2184170484542847,
      "learning_rate": 0.00020283473311769268,
      "loss": 0.585,
      "step": 571150
    },
    {
      "epoch": 6.046993187628692,
      "grad_norm": 1.1431506872177124,
      "learning_rate": 0.00020278937114822496,
      "loss": 0.5809,
      "step": 571200
    },
    {
      "epoch": 6.047522509408695,
      "grad_norm": 1.1974562406539917,
      "learning_rate": 0.00020274401079051067,
      "loss": 0.5824,
      "step": 571250
    },
    {
      "epoch": 6.0480518311886975,
      "grad_norm": 1.1183959245681763,
      "learning_rate": 0.0002026986520460986,
      "loss": 0.5791,
      "step": 571300
    },
    {
      "epoch": 6.048581152968701,
      "grad_norm": 1.106967568397522,
      "learning_rate": 0.00020265329491653714,
      "loss": 0.5705,
      "step": 571350
    },
    {
      "epoch": 6.049110474748704,
      "grad_norm": 1.0266473293304443,
      "learning_rate": 0.0002026079394033749,
      "loss": 0.5775,
      "step": 571400
    },
    {
      "epoch": 6.049639796528708,
      "grad_norm": 1.034480333328247,
      "learning_rate": 0.00020256258550816017,
      "loss": 0.5872,
      "step": 571450
    },
    {
      "epoch": 6.050169118308711,
      "grad_norm": 1.156983494758606,
      "learning_rate": 0.00020251723323244146,
      "loss": 0.5781,
      "step": 571500
    },
    {
      "epoch": 6.050169118308711,
      "eval_loss": 0.3736804723739624,
      "eval_runtime": 46.8508,
      "eval_samples_per_second": 3584.355,
      "eval_steps_per_second": 448.06,
      "step": 571500
    },
    {
      "epoch": 6.0506984400887145,
      "grad_norm": 1.2345044612884521,
      "learning_rate": 0.00020247188257776686,
      "loss": 0.5911,
      "step": 571550
    },
    {
      "epoch": 6.051227761868717,
      "grad_norm": 1.1341980695724487,
      "learning_rate": 0.00020242744051041504,
      "loss": 0.5803,
      "step": 571600
    },
    {
      "epoch": 6.051757083648721,
      "grad_norm": 1.0682660341262817,
      "learning_rate": 0.00020238209306997577,
      "loss": 0.5862,
      "step": 571650
    },
    {
      "epoch": 6.052286405428724,
      "grad_norm": 1.2320133447647095,
      "learning_rate": 0.00020233674725519428,
      "loss": 0.5838,
      "step": 571700
    },
    {
      "epoch": 6.052815727208728,
      "grad_norm": 1.0014476776123047,
      "learning_rate": 0.00020229140306761886,
      "loss": 0.5709,
      "step": 571750
    },
    {
      "epoch": 6.053345048988731,
      "grad_norm": 1.1855567693710327,
      "learning_rate": 0.00020224606050879736,
      "loss": 0.573,
      "step": 571800
    },
    {
      "epoch": 6.053874370768734,
      "grad_norm": 1.1403032541275024,
      "learning_rate": 0.00020220071958027791,
      "loss": 0.578,
      "step": 571850
    },
    {
      "epoch": 6.054403692548737,
      "grad_norm": 1.146054983139038,
      "learning_rate": 0.00020215538028360827,
      "loss": 0.5757,
      "step": 571900
    },
    {
      "epoch": 6.054933014328741,
      "grad_norm": 1.2628405094146729,
      "learning_rate": 0.0002021100426203365,
      "loss": 0.5758,
      "step": 571950
    },
    {
      "epoch": 6.055462336108744,
      "grad_norm": 1.2407944202423096,
      "learning_rate": 0.00020206470659201023,
      "loss": 0.5796,
      "step": 572000
    },
    {
      "epoch": 6.055462336108744,
      "eval_loss": 0.3737463057041168,
      "eval_runtime": 46.8325,
      "eval_samples_per_second": 3585.76,
      "eval_steps_per_second": 448.236,
      "step": 572000
    },
    {
      "epoch": 6.055991657888747,
      "grad_norm": 1.1197623014450073,
      "learning_rate": 0.0002020193722001774,
      "loss": 0.5878,
      "step": 572050
    },
    {
      "epoch": 6.0565209796687505,
      "grad_norm": 1.2102993726730347,
      "learning_rate": 0.00020197403944638548,
      "loss": 0.5861,
      "step": 572100
    },
    {
      "epoch": 6.057050301448753,
      "grad_norm": 1.0839835405349731,
      "learning_rate": 0.00020192870833218236,
      "loss": 0.5753,
      "step": 572150
    },
    {
      "epoch": 6.057579623228757,
      "grad_norm": 1.094575047492981,
      "learning_rate": 0.0002018833788591154,
      "loss": 0.5853,
      "step": 572200
    },
    {
      "epoch": 6.05810894500876,
      "grad_norm": 1.266339898109436,
      "learning_rate": 0.00020183805102873227,
      "loss": 0.5923,
      "step": 572250
    },
    {
      "epoch": 6.058638266788764,
      "grad_norm": 1.0857425928115845,
      "learning_rate": 0.00020179272484258044,
      "loss": 0.5769,
      "step": 572300
    },
    {
      "epoch": 6.059167588568767,
      "grad_norm": 1.1442126035690308,
      "learning_rate": 0.00020174740030220732,
      "loss": 0.5755,
      "step": 572350
    },
    {
      "epoch": 6.05969691034877,
      "grad_norm": 1.2851969003677368,
      "learning_rate": 0.00020170207740916016,
      "loss": 0.5831,
      "step": 572400
    },
    {
      "epoch": 6.060226232128773,
      "grad_norm": 1.2375177145004272,
      "learning_rate": 0.00020165675616498648,
      "loss": 0.5875,
      "step": 572450
    },
    {
      "epoch": 6.060755553908777,
      "grad_norm": 1.158198356628418,
      "learning_rate": 0.00020161143657123335,
      "loss": 0.5691,
      "step": 572500
    },
    {
      "epoch": 6.060755553908777,
      "eval_loss": 0.3720690608024597,
      "eval_runtime": 46.8211,
      "eval_samples_per_second": 3586.628,
      "eval_steps_per_second": 448.345,
      "step": 572500
    },
    {
      "epoch": 6.06128487568878,
      "grad_norm": 1.185778260231018,
      "learning_rate": 0.0002015661186294481,
      "loss": 0.5886,
      "step": 572550
    },
    {
      "epoch": 6.061814197468784,
      "grad_norm": 1.3209222555160522,
      "learning_rate": 0.0002015208023411777,
      "loss": 0.5942,
      "step": 572600
    },
    {
      "epoch": 6.0623435192487864,
      "grad_norm": 1.14774489402771,
      "learning_rate": 0.00020147548770796945,
      "loss": 0.5785,
      "step": 572650
    },
    {
      "epoch": 6.06287284102879,
      "grad_norm": 1.2932802438735962,
      "learning_rate": 0.00020143017473137013,
      "loss": 0.5773,
      "step": 572700
    },
    {
      "epoch": 6.063402162808793,
      "grad_norm": 1.144407033920288,
      "learning_rate": 0.00020138486341292694,
      "loss": 0.5786,
      "step": 572750
    },
    {
      "epoch": 6.063931484588796,
      "grad_norm": 1.1435903310775757,
      "learning_rate": 0.00020133955375418658,
      "loss": 0.5858,
      "step": 572800
    },
    {
      "epoch": 6.0644608063688,
      "grad_norm": 1.1346237659454346,
      "learning_rate": 0.0002012942457566961,
      "loss": 0.5694,
      "step": 572850
    },
    {
      "epoch": 6.064990128148803,
      "grad_norm": 1.0591095685958862,
      "learning_rate": 0.0002012489394220021,
      "loss": 0.5792,
      "step": 572900
    },
    {
      "epoch": 6.065519449928806,
      "grad_norm": 1.1473455429077148,
      "learning_rate": 0.00020120363475165158,
      "loss": 0.5852,
      "step": 572950
    },
    {
      "epoch": 6.066048771708809,
      "grad_norm": 1.1626237630844116,
      "learning_rate": 0.00020115833174719094,
      "loss": 0.5725,
      "step": 573000
    },
    {
      "epoch": 6.066048771708809,
      "eval_loss": 0.373551607131958,
      "eval_runtime": 46.7238,
      "eval_samples_per_second": 3594.103,
      "eval_steps_per_second": 449.279,
      "step": 573000
    },
    {
      "epoch": 6.066578093488813,
      "grad_norm": 1.0247573852539062,
      "learning_rate": 0.00020111303041016698,
      "loss": 0.5833,
      "step": 573050
    },
    {
      "epoch": 6.067107415268816,
      "grad_norm": 1.204026460647583,
      "learning_rate": 0.00020106773074212626,
      "loss": 0.5665,
      "step": 573100
    },
    {
      "epoch": 6.06763673704882,
      "grad_norm": 1.1576789617538452,
      "learning_rate": 0.00020102243274461523,
      "loss": 0.5756,
      "step": 573150
    },
    {
      "epoch": 6.068166058828822,
      "grad_norm": 1.1739531755447388,
      "learning_rate": 0.00020097713641918037,
      "loss": 0.571,
      "step": 573200
    },
    {
      "epoch": 6.068695380608826,
      "grad_norm": 1.192558765411377,
      "learning_rate": 0.00020093184176736816,
      "loss": 0.5727,
      "step": 573250
    },
    {
      "epoch": 6.069224702388829,
      "grad_norm": 1.2451834678649902,
      "learning_rate": 0.00020088654879072483,
      "loss": 0.5846,
      "step": 573300
    },
    {
      "epoch": 6.069754024168833,
      "grad_norm": 1.2727731466293335,
      "learning_rate": 0.0002008412574907968,
      "loss": 0.5846,
      "step": 573350
    },
    {
      "epoch": 6.070283345948836,
      "grad_norm": 1.1080390214920044,
      "learning_rate": 0.00020079596786913006,
      "loss": 0.5785,
      "step": 573400
    },
    {
      "epoch": 6.070812667728839,
      "grad_norm": 1.1903002262115479,
      "learning_rate": 0.0002007506799272711,
      "loss": 0.5715,
      "step": 573450
    },
    {
      "epoch": 6.071341989508842,
      "grad_norm": 1.069876790046692,
      "learning_rate": 0.00020070539366676571,
      "loss": 0.583,
      "step": 573500
    },
    {
      "epoch": 6.071341989508842,
      "eval_loss": 0.3718585968017578,
      "eval_runtime": 46.8351,
      "eval_samples_per_second": 3585.562,
      "eval_steps_per_second": 448.211,
      "step": 573500
    },
    {
      "epoch": 6.071871311288845,
      "grad_norm": 1.0828006267547607,
      "learning_rate": 0.00020066010908916022,
      "loss": 0.5877,
      "step": 573550
    },
    {
      "epoch": 6.072400633068849,
      "grad_norm": 1.0912306308746338,
      "learning_rate": 0.00020061573183734603,
      "loss": 0.5761,
      "step": 573600
    },
    {
      "epoch": 6.072929954848852,
      "grad_norm": 1.225220799446106,
      "learning_rate": 0.00020057045059644298,
      "loss": 0.5885,
      "step": 573650
    },
    {
      "epoch": 6.0734592766288555,
      "grad_norm": 1.0982842445373535,
      "learning_rate": 0.00020052517104304668,
      "loss": 0.5744,
      "step": 573700
    },
    {
      "epoch": 6.073988598408858,
      "grad_norm": 1.0858534574508667,
      "learning_rate": 0.00020047989317870286,
      "loss": 0.585,
      "step": 573750
    },
    {
      "epoch": 6.074517920188862,
      "grad_norm": 1.129785180091858,
      "learning_rate": 0.00020043461700495726,
      "loss": 0.5835,
      "step": 573800
    },
    {
      "epoch": 6.075047241968865,
      "grad_norm": 1.1609426736831665,
      "learning_rate": 0.0002003893425233558,
      "loss": 0.5698,
      "step": 573850
    },
    {
      "epoch": 6.075576563748869,
      "grad_norm": 1.1632344722747803,
      "learning_rate": 0.00020034406973544385,
      "loss": 0.5754,
      "step": 573900
    },
    {
      "epoch": 6.076105885528872,
      "grad_norm": 1.1420080661773682,
      "learning_rate": 0.0002002987986427673,
      "loss": 0.5795,
      "step": 573950
    },
    {
      "epoch": 6.076635207308875,
      "grad_norm": 1.14825439453125,
      "learning_rate": 0.0002002535292468714,
      "loss": 0.5824,
      "step": 574000
    },
    {
      "epoch": 6.076635207308875,
      "eval_loss": 0.3733330965042114,
      "eval_runtime": 46.8291,
      "eval_samples_per_second": 3586.015,
      "eval_steps_per_second": 448.268,
      "step": 574000
    },
    {
      "epoch": 6.077164529088878,
      "grad_norm": 1.2379462718963623,
      "learning_rate": 0.0002002082615493019,
      "loss": 0.5839,
      "step": 574050
    },
    {
      "epoch": 6.077693850868882,
      "grad_norm": 1.1751453876495361,
      "learning_rate": 0.00020016299555160395,
      "loss": 0.5814,
      "step": 574100
    },
    {
      "epoch": 6.078223172648885,
      "grad_norm": 1.071168303489685,
      "learning_rate": 0.00020011773125532315,
      "loss": 0.5822,
      "step": 574150
    },
    {
      "epoch": 6.078752494428889,
      "grad_norm": 1.086038589477539,
      "learning_rate": 0.00020007246866200464,
      "loss": 0.574,
      "step": 574200
    },
    {
      "epoch": 6.0792818162088915,
      "grad_norm": 1.2067149877548218,
      "learning_rate": 0.00020002720777319383,
      "loss": 0.5742,
      "step": 574250
    },
    {
      "epoch": 6.079811137988894,
      "grad_norm": 1.1859874725341797,
      "learning_rate": 0.00019998194859043573,
      "loss": 0.5856,
      "step": 574300
    },
    {
      "epoch": 6.080340459768898,
      "grad_norm": 1.2664053440093994,
      "learning_rate": 0.00019993669111527564,
      "loss": 0.5788,
      "step": 574350
    },
    {
      "epoch": 6.080869781548901,
      "grad_norm": 1.2380071878433228,
      "learning_rate": 0.00019989143534925846,
      "loss": 0.5784,
      "step": 574400
    },
    {
      "epoch": 6.081399103328905,
      "grad_norm": 1.1169734001159668,
      "learning_rate": 0.00019984618129392933,
      "loss": 0.5743,
      "step": 574450
    },
    {
      "epoch": 6.081928425108908,
      "grad_norm": 1.2007895708084106,
      "learning_rate": 0.00019980092895083323,
      "loss": 0.583,
      "step": 574500
    },
    {
      "epoch": 6.081928425108908,
      "eval_loss": 0.3728032410144806,
      "eval_runtime": 46.8053,
      "eval_samples_per_second": 3587.841,
      "eval_steps_per_second": 448.496,
      "step": 574500
    },
    {
      "epoch": 6.082457746888911,
      "grad_norm": 1.3425253629684448,
      "learning_rate": 0.00019975567832151498,
      "loss": 0.5784,
      "step": 574550
    },
    {
      "epoch": 6.082987068668914,
      "grad_norm": 1.1042354106903076,
      "learning_rate": 0.00019971042940751944,
      "loss": 0.5806,
      "step": 574600
    },
    {
      "epoch": 6.083516390448918,
      "grad_norm": 1.0471047163009644,
      "learning_rate": 0.0001996651822103914,
      "loss": 0.5821,
      "step": 574650
    },
    {
      "epoch": 6.084045712228921,
      "grad_norm": 1.2670632600784302,
      "learning_rate": 0.00019961993673167552,
      "loss": 0.5866,
      "step": 574700
    },
    {
      "epoch": 6.084575034008925,
      "grad_norm": 1.2534927129745483,
      "learning_rate": 0.00019957469297291665,
      "loss": 0.591,
      "step": 574750
    },
    {
      "epoch": 6.0851043557889275,
      "grad_norm": 0.9794229865074158,
      "learning_rate": 0.00019952945093565917,
      "loss": 0.5901,
      "step": 574800
    },
    {
      "epoch": 6.085633677568931,
      "grad_norm": 1.2628928422927856,
      "learning_rate": 0.0001994842106214478,
      "loss": 0.5679,
      "step": 574850
    },
    {
      "epoch": 6.086162999348934,
      "grad_norm": 1.112902283668518,
      "learning_rate": 0.00019943897203182685,
      "loss": 0.5772,
      "step": 574900
    },
    {
      "epoch": 6.086692321128938,
      "grad_norm": 1.23407781124115,
      "learning_rate": 0.00019939373516834096,
      "loss": 0.5832,
      "step": 574950
    },
    {
      "epoch": 6.087221642908941,
      "grad_norm": 1.1527782678604126,
      "learning_rate": 0.0001993485000325343,
      "loss": 0.5885,
      "step": 575000
    },
    {
      "epoch": 6.087221642908941,
      "eval_loss": 0.37400469183921814,
      "eval_runtime": 46.878,
      "eval_samples_per_second": 3582.279,
      "eval_steps_per_second": 447.801,
      "step": 575000
    },
    {
      "epoch": 6.087750964688944,
      "grad_norm": 1.0765591859817505,
      "learning_rate": 0.0001993032666259514,
      "loss": 0.5891,
      "step": 575050
    },
    {
      "epoch": 6.088280286468947,
      "grad_norm": 1.2977654933929443,
      "learning_rate": 0.00019925803495013622,
      "loss": 0.5839,
      "step": 575100
    },
    {
      "epoch": 6.08880960824895,
      "grad_norm": 1.1920008659362793,
      "learning_rate": 0.00019921280500663328,
      "loss": 0.5764,
      "step": 575150
    },
    {
      "epoch": 6.089338930028954,
      "grad_norm": 1.2409701347351074,
      "learning_rate": 0.0001991675767969864,
      "loss": 0.5815,
      "step": 575200
    },
    {
      "epoch": 6.089868251808957,
      "grad_norm": 1.103139877319336,
      "learning_rate": 0.00019912235032273996,
      "loss": 0.5792,
      "step": 575250
    },
    {
      "epoch": 6.090397573588961,
      "grad_norm": 1.1929576396942139,
      "learning_rate": 0.00019907712558543767,
      "loss": 0.5714,
      "step": 575300
    },
    {
      "epoch": 6.0909268953689635,
      "grad_norm": 1.154351830482483,
      "learning_rate": 0.0001990319025866237,
      "loss": 0.5856,
      "step": 575350
    },
    {
      "epoch": 6.091456217148967,
      "grad_norm": 1.1804866790771484,
      "learning_rate": 0.0001989866813278419,
      "loss": 0.5826,
      "step": 575400
    },
    {
      "epoch": 6.09198553892897,
      "grad_norm": 1.1535478830337524,
      "learning_rate": 0.00019894146181063607,
      "loss": 0.5704,
      "step": 575450
    },
    {
      "epoch": 6.092514860708974,
      "grad_norm": 1.3188918828964233,
      "learning_rate": 0.00019889624403655,
      "loss": 0.585,
      "step": 575500
    },
    {
      "epoch": 6.092514860708974,
      "eval_loss": 0.37277427315711975,
      "eval_runtime": 46.8822,
      "eval_samples_per_second": 3581.958,
      "eval_steps_per_second": 447.761,
      "step": 575500
    },
    {
      "epoch": 6.093044182488977,
      "grad_norm": 1.1244957447052002,
      "learning_rate": 0.00019885102800712746,
      "loss": 0.5698,
      "step": 575550
    },
    {
      "epoch": 6.0935735042689805,
      "grad_norm": 1.125657320022583,
      "learning_rate": 0.000198805813723912,
      "loss": 0.5803,
      "step": 575600
    },
    {
      "epoch": 6.094102826048983,
      "grad_norm": 1.1214284896850586,
      "learning_rate": 0.0001987615054220187,
      "loss": 0.5733,
      "step": 575650
    },
    {
      "epoch": 6.094632147828987,
      "grad_norm": 1.2314221858978271,
      "learning_rate": 0.0001987162946008473,
      "loss": 0.5786,
      "step": 575700
    },
    {
      "epoch": 6.09516146960899,
      "grad_norm": 1.1240779161453247,
      "learning_rate": 0.0001986710855304828,
      "loss": 0.5795,
      "step": 575750
    },
    {
      "epoch": 6.095690791388993,
      "grad_norm": 1.0984582901000977,
      "learning_rate": 0.0001986258782124686,
      "loss": 0.5754,
      "step": 575800
    },
    {
      "epoch": 6.096220113168997,
      "grad_norm": 1.2660518884658813,
      "learning_rate": 0.00019858067264834806,
      "loss": 0.5783,
      "step": 575850
    },
    {
      "epoch": 6.0967494349489995,
      "grad_norm": 1.1322708129882812,
      "learning_rate": 0.00019853546883966456,
      "loss": 0.5771,
      "step": 575900
    },
    {
      "epoch": 6.097278756729003,
      "grad_norm": 1.239163875579834,
      "learning_rate": 0.0001984902667879612,
      "loss": 0.577,
      "step": 575950
    },
    {
      "epoch": 6.097808078509006,
      "grad_norm": 1.180895209312439,
      "learning_rate": 0.00019844506649478134,
      "loss": 0.5796,
      "step": 576000
    },
    {
      "epoch": 6.097808078509006,
      "eval_loss": 0.37171849608421326,
      "eval_runtime": 46.7493,
      "eval_samples_per_second": 3592.137,
      "eval_steps_per_second": 449.033,
      "step": 576000
    },
    {
      "epoch": 6.09833740028901,
      "grad_norm": 1.0794154405593872,
      "learning_rate": 0.0001983998679616679,
      "loss": 0.5785,
      "step": 576050
    },
    {
      "epoch": 6.098866722069013,
      "grad_norm": 1.216037631034851,
      "learning_rate": 0.00019835467119016414,
      "loss": 0.5746,
      "step": 576100
    },
    {
      "epoch": 6.0993960438490165,
      "grad_norm": 1.108872413635254,
      "learning_rate": 0.00019830947618181287,
      "loss": 0.5765,
      "step": 576150
    },
    {
      "epoch": 6.099925365629019,
      "grad_norm": 1.3237568140029907,
      "learning_rate": 0.00019826428293815725,
      "loss": 0.5686,
      "step": 576200
    },
    {
      "epoch": 6.100454687409023,
      "grad_norm": 1.1849902868270874,
      "learning_rate": 0.00019821909146073988,
      "loss": 0.5772,
      "step": 576250
    },
    {
      "epoch": 6.100984009189026,
      "grad_norm": 1.12941575050354,
      "learning_rate": 0.00019817390175110388,
      "loss": 0.5806,
      "step": 576300
    },
    {
      "epoch": 6.10151333096903,
      "grad_norm": 1.197965145111084,
      "learning_rate": 0.00019812871381079175,
      "loss": 0.5796,
      "step": 576350
    },
    {
      "epoch": 6.102042652749033,
      "grad_norm": 1.2220103740692139,
      "learning_rate": 0.0001980835276413464,
      "loss": 0.5884,
      "step": 576400
    },
    {
      "epoch": 6.102571974529036,
      "grad_norm": 1.2245290279388428,
      "learning_rate": 0.0001980383432443103,
      "loss": 0.5885,
      "step": 576450
    },
    {
      "epoch": 6.103101296309039,
      "grad_norm": 1.1684094667434692,
      "learning_rate": 0.00019799316062122613,
      "loss": 0.5781,
      "step": 576500
    },
    {
      "epoch": 6.103101296309039,
      "eval_loss": 0.37198683619499207,
      "eval_runtime": 46.7275,
      "eval_samples_per_second": 3593.812,
      "eval_steps_per_second": 449.243,
      "step": 576500
    },
    {
      "epoch": 6.103630618089042,
      "grad_norm": 1.0828702449798584,
      "learning_rate": 0.0001979479797736364,
      "loss": 0.5737,
      "step": 576550
    },
    {
      "epoch": 6.104159939869046,
      "grad_norm": 1.166701078414917,
      "learning_rate": 0.00019790280070308355,
      "loss": 0.583,
      "step": 576600
    },
    {
      "epoch": 6.104689261649049,
      "grad_norm": 1.1015229225158691,
      "learning_rate": 0.00019785762341111,
      "loss": 0.5751,
      "step": 576650
    },
    {
      "epoch": 6.105218583429052,
      "grad_norm": 1.1995935440063477,
      "learning_rate": 0.00019781244789925803,
      "loss": 0.5816,
      "step": 576700
    },
    {
      "epoch": 6.105747905209055,
      "grad_norm": 1.0902180671691895,
      "learning_rate": 0.0001977672741690699,
      "loss": 0.5867,
      "step": 576750
    },
    {
      "epoch": 6.106277226989059,
      "grad_norm": 1.3518918752670288,
      "learning_rate": 0.000197722102222088,
      "loss": 0.5722,
      "step": 576800
    },
    {
      "epoch": 6.106806548769062,
      "grad_norm": 1.2199122905731201,
      "learning_rate": 0.00019767693205985425,
      "loss": 0.5811,
      "step": 576850
    },
    {
      "epoch": 6.107335870549066,
      "grad_norm": 1.1216987371444702,
      "learning_rate": 0.00019763176368391096,
      "loss": 0.5774,
      "step": 576900
    },
    {
      "epoch": 6.1078651923290685,
      "grad_norm": 1.1746134757995605,
      "learning_rate": 0.00019758659709579992,
      "loss": 0.5775,
      "step": 576950
    },
    {
      "epoch": 6.108394514109072,
      "grad_norm": 1.2341029644012451,
      "learning_rate": 0.00019754143229706335,
      "loss": 0.5795,
      "step": 577000
    },
    {
      "epoch": 6.108394514109072,
      "eval_loss": 0.3708427846431732,
      "eval_runtime": 46.7787,
      "eval_samples_per_second": 3589.881,
      "eval_steps_per_second": 448.751,
      "step": 577000
    },
    {
      "epoch": 6.108923835889075,
      "grad_norm": 1.2014204263687134,
      "learning_rate": 0.00019749626928924292,
      "loss": 0.5898,
      "step": 577050
    },
    {
      "epoch": 6.109453157669079,
      "grad_norm": 1.2098942995071411,
      "learning_rate": 0.00019745110807388073,
      "loss": 0.5708,
      "step": 577100
    },
    {
      "epoch": 6.109982479449082,
      "grad_norm": 1.208423376083374,
      "learning_rate": 0.00019740594865251833,
      "loss": 0.5764,
      "step": 577150
    },
    {
      "epoch": 6.1105118012290855,
      "grad_norm": 1.2062770128250122,
      "learning_rate": 0.00019736079102669764,
      "loss": 0.5766,
      "step": 577200
    },
    {
      "epoch": 6.111041123009088,
      "grad_norm": 1.1057201623916626,
      "learning_rate": 0.00019731563519796017,
      "loss": 0.5789,
      "step": 577250
    },
    {
      "epoch": 6.111570444789092,
      "grad_norm": 1.1142799854278564,
      "learning_rate": 0.00019727048116784769,
      "loss": 0.5808,
      "step": 577300
    },
    {
      "epoch": 6.112099766569095,
      "grad_norm": 1.1262482404708862,
      "learning_rate": 0.0001972253289379015,
      "loss": 0.5818,
      "step": 577350
    },
    {
      "epoch": 6.112629088349098,
      "grad_norm": 1.1361088752746582,
      "learning_rate": 0.00019718017850966333,
      "loss": 0.5751,
      "step": 577400
    },
    {
      "epoch": 6.113158410129102,
      "grad_norm": 1.2023427486419678,
      "learning_rate": 0.00019713502988467446,
      "loss": 0.5943,
      "step": 577450
    },
    {
      "epoch": 6.1136877319091045,
      "grad_norm": 1.2635146379470825,
      "learning_rate": 0.00019708988306447632,
      "loss": 0.5817,
      "step": 577500
    },
    {
      "epoch": 6.1136877319091045,
      "eval_loss": 0.371526837348938,
      "eval_runtime": 46.7771,
      "eval_samples_per_second": 3590.007,
      "eval_steps_per_second": 448.767,
      "step": 577500
    },
    {
      "epoch": 6.114217053689108,
      "grad_norm": 1.1986228227615356,
      "learning_rate": 0.00019704473805061008,
      "loss": 0.5804,
      "step": 577550
    },
    {
      "epoch": 6.114746375469111,
      "grad_norm": 1.2053208351135254,
      "learning_rate": 0.0001969995948446172,
      "loss": 0.5797,
      "step": 577600
    },
    {
      "epoch": 6.115275697249115,
      "grad_norm": 1.143751859664917,
      "learning_rate": 0.00019695535625822787,
      "loss": 0.5711,
      "step": 577650
    },
    {
      "epoch": 6.115805019029118,
      "grad_norm": 1.330383539199829,
      "learning_rate": 0.0001969102166363707,
      "loss": 0.5747,
      "step": 577700
    },
    {
      "epoch": 6.1163343408091215,
      "grad_norm": 1.1917160749435425,
      "learning_rate": 0.0001968650788269791,
      "loss": 0.5825,
      "step": 577750
    },
    {
      "epoch": 6.116863662589124,
      "grad_norm": 1.1229872703552246,
      "learning_rate": 0.00019681994283159433,
      "loss": 0.5781,
      "step": 577800
    },
    {
      "epoch": 6.117392984369128,
      "grad_norm": 1.2905205488204956,
      "learning_rate": 0.0001967748086517571,
      "loss": 0.5802,
      "step": 577850
    },
    {
      "epoch": 6.117922306149131,
      "grad_norm": 1.110585331916809,
      "learning_rate": 0.0001967296762890085,
      "loss": 0.5801,
      "step": 577900
    },
    {
      "epoch": 6.118451627929135,
      "grad_norm": 1.1483302116394043,
      "learning_rate": 0.00019668454574488914,
      "loss": 0.5856,
      "step": 577950
    },
    {
      "epoch": 6.118980949709138,
      "grad_norm": 1.2318799495697021,
      "learning_rate": 0.00019663941702093986,
      "loss": 0.5765,
      "step": 578000
    },
    {
      "epoch": 6.118980949709138,
      "eval_loss": 0.3722958564758301,
      "eval_runtime": 46.7887,
      "eval_samples_per_second": 3589.116,
      "eval_steps_per_second": 448.656,
      "step": 578000
    },
    {
      "epoch": 6.119510271489141,
      "grad_norm": 1.1835401058197021,
      "learning_rate": 0.0001965942901187013,
      "loss": 0.5695,
      "step": 578050
    },
    {
      "epoch": 6.120039593269144,
      "grad_norm": 1.2861881256103516,
      "learning_rate": 0.0001965491650397141,
      "loss": 0.588,
      "step": 578100
    },
    {
      "epoch": 6.120568915049147,
      "grad_norm": 1.258230447769165,
      "learning_rate": 0.00019650404178551874,
      "loss": 0.5762,
      "step": 578150
    },
    {
      "epoch": 6.121098236829151,
      "grad_norm": 1.0744987726211548,
      "learning_rate": 0.0001964589203576559,
      "loss": 0.5779,
      "step": 578200
    },
    {
      "epoch": 6.121627558609154,
      "grad_norm": 1.0954949855804443,
      "learning_rate": 0.0001964138007576658,
      "loss": 0.5723,
      "step": 578250
    },
    {
      "epoch": 6.1221568803891575,
      "grad_norm": 1.1409231424331665,
      "learning_rate": 0.00019636868298708896,
      "loss": 0.578,
      "step": 578300
    },
    {
      "epoch": 6.12268620216916,
      "grad_norm": 1.0632542371749878,
      "learning_rate": 0.00019632356704746553,
      "loss": 0.5837,
      "step": 578350
    },
    {
      "epoch": 6.123215523949164,
      "grad_norm": 1.2424806356430054,
      "learning_rate": 0.0001962784529403359,
      "loss": 0.5748,
      "step": 578400
    },
    {
      "epoch": 6.123744845729167,
      "grad_norm": 1.144463062286377,
      "learning_rate": 0.0001962333406672401,
      "loss": 0.5885,
      "step": 578450
    },
    {
      "epoch": 6.124274167509171,
      "grad_norm": 1.2303272485733032,
      "learning_rate": 0.00019618823022971845,
      "loss": 0.5845,
      "step": 578500
    },
    {
      "epoch": 6.124274167509171,
      "eval_loss": 0.37078532576560974,
      "eval_runtime": 46.7487,
      "eval_samples_per_second": 3592.184,
      "eval_steps_per_second": 449.039,
      "step": 578500
    },
    {
      "epoch": 6.124803489289174,
      "grad_norm": 1.1947916746139526,
      "learning_rate": 0.00019614312162931079,
      "loss": 0.5699,
      "step": 578550
    },
    {
      "epoch": 6.125332811069177,
      "grad_norm": 1.2707738876342773,
      "learning_rate": 0.0001960980148675573,
      "loss": 0.5807,
      "step": 578600
    },
    {
      "epoch": 6.12586213284918,
      "grad_norm": 1.1306570768356323,
      "learning_rate": 0.0001960529099459977,
      "loss": 0.5783,
      "step": 578650
    },
    {
      "epoch": 6.126391454629184,
      "grad_norm": 1.1304435729980469,
      "learning_rate": 0.00019600780686617207,
      "loss": 0.5655,
      "step": 578700
    },
    {
      "epoch": 6.126920776409187,
      "grad_norm": 1.049681305885315,
      "learning_rate": 0.00019596270562962002,
      "loss": 0.5689,
      "step": 578750
    },
    {
      "epoch": 6.127450098189191,
      "grad_norm": 1.2003579139709473,
      "learning_rate": 0.00019591760623788142,
      "loss": 0.5835,
      "step": 578800
    },
    {
      "epoch": 6.1279794199691935,
      "grad_norm": 1.2263851165771484,
      "learning_rate": 0.00019587250869249593,
      "loss": 0.5715,
      "step": 578850
    },
    {
      "epoch": 6.128508741749196,
      "grad_norm": 1.376061201095581,
      "learning_rate": 0.0001958274129950031,
      "loss": 0.5872,
      "step": 578900
    },
    {
      "epoch": 6.1290380635292,
      "grad_norm": 1.1632447242736816,
      "learning_rate": 0.00019578231914694252,
      "loss": 0.583,
      "step": 578950
    },
    {
      "epoch": 6.129567385309203,
      "grad_norm": 1.155792474746704,
      "learning_rate": 0.00019573722714985378,
      "loss": 0.5697,
      "step": 579000
    },
    {
      "epoch": 6.129567385309203,
      "eval_loss": 0.3701949715614319,
      "eval_runtime": 46.9518,
      "eval_samples_per_second": 3576.647,
      "eval_steps_per_second": 447.097,
      "step": 579000
    },
    {
      "epoch": 6.130096707089207,
      "grad_norm": 1.28887939453125,
      "learning_rate": 0.00019569213700527607,
      "loss": 0.5737,
      "step": 579050
    },
    {
      "epoch": 6.13062602886921,
      "grad_norm": 1.2100157737731934,
      "learning_rate": 0.00019564704871474902,
      "loss": 0.5799,
      "step": 579100
    },
    {
      "epoch": 6.131155350649213,
      "grad_norm": 1.1752374172210693,
      "learning_rate": 0.00019560196227981166,
      "loss": 0.5798,
      "step": 579150
    },
    {
      "epoch": 6.131684672429216,
      "grad_norm": 1.0981049537658691,
      "learning_rate": 0.0001955568777020035,
      "loss": 0.5839,
      "step": 579200
    },
    {
      "epoch": 6.13221399420922,
      "grad_norm": 1.0368252992630005,
      "learning_rate": 0.00019551179498286344,
      "loss": 0.5775,
      "step": 579250
    },
    {
      "epoch": 6.132743315989223,
      "grad_norm": 1.143792986869812,
      "learning_rate": 0.00019546671412393082,
      "loss": 0.569,
      "step": 579300
    },
    {
      "epoch": 6.133272637769227,
      "grad_norm": 1.1848883628845215,
      "learning_rate": 0.0001954216351267445,
      "loss": 0.5821,
      "step": 579350
    },
    {
      "epoch": 6.1338019595492295,
      "grad_norm": 1.0640753507614136,
      "learning_rate": 0.00019537655799284362,
      "loss": 0.5682,
      "step": 579400
    },
    {
      "epoch": 6.134331281329233,
      "grad_norm": 1.1526950597763062,
      "learning_rate": 0.00019533148272376691,
      "loss": 0.5743,
      "step": 579450
    },
    {
      "epoch": 6.134860603109236,
      "grad_norm": 1.1825919151306152,
      "learning_rate": 0.00019528640932105345,
      "loss": 0.5761,
      "step": 579500
    },
    {
      "epoch": 6.134860603109236,
      "eval_loss": 0.3712259531021118,
      "eval_runtime": 46.8383,
      "eval_samples_per_second": 3585.315,
      "eval_steps_per_second": 448.18,
      "step": 579500
    },
    {
      "epoch": 6.13538992488924,
      "grad_norm": 1.0988497734069824,
      "learning_rate": 0.00019524133778624182,
      "loss": 0.5764,
      "step": 579550
    },
    {
      "epoch": 6.135919246669243,
      "grad_norm": 1.2799677848815918,
      "learning_rate": 0.00019519626812087085,
      "loss": 0.5837,
      "step": 579600
    },
    {
      "epoch": 6.136448568449246,
      "grad_norm": 1.1745857000350952,
      "learning_rate": 0.00019515210166402153,
      "loss": 0.5789,
      "step": 579650
    },
    {
      "epoch": 6.136977890229249,
      "grad_norm": 1.1771796941757202,
      "learning_rate": 0.0001951070357046823,
      "loss": 0.5868,
      "step": 579700
    },
    {
      "epoch": 6.137507212009252,
      "grad_norm": 1.162365436553955,
      "learning_rate": 0.00019506197161936885,
      "loss": 0.5735,
      "step": 579750
    },
    {
      "epoch": 6.138036533789256,
      "grad_norm": 1.0894662141799927,
      "learning_rate": 0.00019501690940961942,
      "loss": 0.5768,
      "step": 579800
    },
    {
      "epoch": 6.138565855569259,
      "grad_norm": 1.245081901550293,
      "learning_rate": 0.00019497184907697266,
      "loss": 0.5805,
      "step": 579850
    },
    {
      "epoch": 6.139095177349263,
      "grad_norm": 1.171432375907898,
      "learning_rate": 0.0001949267906229667,
      "loss": 0.5709,
      "step": 579900
    },
    {
      "epoch": 6.1396244991292654,
      "grad_norm": 1.2700337171554565,
      "learning_rate": 0.00019488173404914001,
      "loss": 0.5803,
      "step": 579950
    },
    {
      "epoch": 6.140153820909269,
      "grad_norm": 1.1903069019317627,
      "learning_rate": 0.00019483667935703055,
      "loss": 0.5718,
      "step": 580000
    },
    {
      "epoch": 6.140153820909269,
      "eval_loss": 0.3692060708999634,
      "eval_runtime": 46.8511,
      "eval_samples_per_second": 3584.335,
      "eval_steps_per_second": 448.058,
      "step": 580000
    },
    {
      "epoch": 6.140683142689272,
      "grad_norm": 1.1748651266098022,
      "learning_rate": 0.00019479162654817672,
      "loss": 0.579,
      "step": 580050
    },
    {
      "epoch": 6.141212464469276,
      "grad_norm": 1.1484403610229492,
      "learning_rate": 0.00019474657562411652,
      "loss": 0.5804,
      "step": 580100
    },
    {
      "epoch": 6.141741786249279,
      "grad_norm": 1.0278719663619995,
      "learning_rate": 0.00019470152658638794,
      "loss": 0.588,
      "step": 580150
    },
    {
      "epoch": 6.1422711080292824,
      "grad_norm": 1.1296871900558472,
      "learning_rate": 0.00019465647943652894,
      "loss": 0.5834,
      "step": 580200
    },
    {
      "epoch": 6.142800429809285,
      "grad_norm": 1.1523832082748413,
      "learning_rate": 0.00019461143417607752,
      "loss": 0.572,
      "step": 580250
    },
    {
      "epoch": 6.143329751589289,
      "grad_norm": 1.17374587059021,
      "learning_rate": 0.00019456639080657134,
      "loss": 0.5824,
      "step": 580300
    },
    {
      "epoch": 6.143859073369292,
      "grad_norm": 1.11491060256958,
      "learning_rate": 0.00019452134932954832,
      "loss": 0.5728,
      "step": 580350
    },
    {
      "epoch": 6.144388395149295,
      "grad_norm": 1.13408625125885,
      "learning_rate": 0.000194476309746546,
      "loss": 0.5695,
      "step": 580400
    },
    {
      "epoch": 6.144917716929299,
      "grad_norm": 1.3376874923706055,
      "learning_rate": 0.00019443127205910223,
      "loss": 0.5807,
      "step": 580450
    },
    {
      "epoch": 6.145447038709301,
      "grad_norm": 1.175663948059082,
      "learning_rate": 0.00019438623626875432,
      "loss": 0.5782,
      "step": 580500
    },
    {
      "epoch": 6.145447038709301,
      "eval_loss": 0.3687642514705658,
      "eval_runtime": 46.8814,
      "eval_samples_per_second": 3582.015,
      "eval_steps_per_second": 447.768,
      "step": 580500
    },
    {
      "epoch": 6.145976360489305,
      "grad_norm": 1.0876652002334595,
      "learning_rate": 0.00019434120237704001,
      "loss": 0.5759,
      "step": 580550
    },
    {
      "epoch": 6.146505682269308,
      "grad_norm": 1.210343360900879,
      "learning_rate": 0.00019429617038549654,
      "loss": 0.5699,
      "step": 580600
    },
    {
      "epoch": 6.147035004049312,
      "grad_norm": 1.220647931098938,
      "learning_rate": 0.00019425114029566148,
      "loss": 0.5689,
      "step": 580650
    },
    {
      "epoch": 6.147564325829315,
      "grad_norm": 1.1170964241027832,
      "learning_rate": 0.00019420611210907196,
      "loss": 0.5911,
      "step": 580700
    },
    {
      "epoch": 6.148093647609318,
      "grad_norm": 1.2068785429000854,
      "learning_rate": 0.00019416108582726542,
      "loss": 0.5784,
      "step": 580750
    },
    {
      "epoch": 6.148622969389321,
      "grad_norm": 1.09779691696167,
      "learning_rate": 0.0001941160614517788,
      "loss": 0.58,
      "step": 580800
    },
    {
      "epoch": 6.149152291169325,
      "grad_norm": 1.1763708591461182,
      "learning_rate": 0.0001940710389841494,
      "loss": 0.5716,
      "step": 580850
    },
    {
      "epoch": 6.149681612949328,
      "grad_norm": 1.2699214220046997,
      "learning_rate": 0.00019402601842591425,
      "loss": 0.5784,
      "step": 580900
    },
    {
      "epoch": 6.150210934729332,
      "grad_norm": 1.2159216403961182,
      "learning_rate": 0.00019398099977861028,
      "loss": 0.5733,
      "step": 580950
    },
    {
      "epoch": 6.1507402565093345,
      "grad_norm": 1.0696345567703247,
      "learning_rate": 0.00019393598304377437,
      "loss": 0.5667,
      "step": 581000
    },
    {
      "epoch": 6.1507402565093345,
      "eval_loss": 0.36884963512420654,
      "eval_runtime": 47.0035,
      "eval_samples_per_second": 3572.714,
      "eval_steps_per_second": 446.605,
      "step": 581000
    },
    {
      "epoch": 6.151269578289338,
      "grad_norm": 1.1398946046829224,
      "learning_rate": 0.00019389096822294358,
      "loss": 0.5808,
      "step": 581050
    },
    {
      "epoch": 6.151798900069341,
      "grad_norm": 1.158279299736023,
      "learning_rate": 0.0001938459553176544,
      "loss": 0.585,
      "step": 581100
    },
    {
      "epoch": 6.152328221849344,
      "grad_norm": 1.186933994293213,
      "learning_rate": 0.00019380094432944387,
      "loss": 0.5778,
      "step": 581150
    },
    {
      "epoch": 6.152857543629348,
      "grad_norm": 0.9942544102668762,
      "learning_rate": 0.00019375593525984837,
      "loss": 0.5761,
      "step": 581200
    },
    {
      "epoch": 6.153386865409351,
      "grad_norm": 1.2521076202392578,
      "learning_rate": 0.0001937109281104047,
      "loss": 0.5813,
      "step": 581250
    },
    {
      "epoch": 6.153916187189354,
      "grad_norm": 1.2819993495941162,
      "learning_rate": 0.0001936659228826492,
      "loss": 0.5737,
      "step": 581300
    },
    {
      "epoch": 6.154445508969357,
      "grad_norm": 1.2682732343673706,
      "learning_rate": 0.00019362091957811855,
      "loss": 0.5778,
      "step": 581350
    },
    {
      "epoch": 6.154974830749361,
      "grad_norm": 1.1540049314498901,
      "learning_rate": 0.0001935759181983489,
      "loss": 0.5794,
      "step": 581400
    },
    {
      "epoch": 6.155504152529364,
      "grad_norm": 1.0277575254440308,
      "learning_rate": 0.00019353091874487686,
      "loss": 0.581,
      "step": 581450
    },
    {
      "epoch": 6.156033474309368,
      "grad_norm": 1.3348634243011475,
      "learning_rate": 0.00019348592121923842,
      "loss": 0.5885,
      "step": 581500
    },
    {
      "epoch": 6.156033474309368,
      "eval_loss": 0.368582159280777,
      "eval_runtime": 46.8152,
      "eval_samples_per_second": 3587.08,
      "eval_steps_per_second": 448.401,
      "step": 581500
    },
    {
      "epoch": 6.1565627960893705,
      "grad_norm": 1.1121658086776733,
      "learning_rate": 0.00019344092562297,
      "loss": 0.573,
      "step": 581550
    },
    {
      "epoch": 6.157092117869374,
      "grad_norm": 1.1012986898422241,
      "learning_rate": 0.0001933959319576075,
      "loss": 0.5762,
      "step": 581600
    },
    {
      "epoch": 6.157621439649377,
      "grad_norm": 1.1126883029937744,
      "learning_rate": 0.00019335184004039773,
      "loss": 0.5772,
      "step": 581650
    },
    {
      "epoch": 6.158150761429381,
      "grad_norm": 1.163985252380371,
      "learning_rate": 0.000193306850202761,
      "loss": 0.5709,
      "step": 581700
    },
    {
      "epoch": 6.158680083209384,
      "grad_norm": 1.1326054334640503,
      "learning_rate": 0.0001932618623006075,
      "loss": 0.58,
      "step": 581750
    },
    {
      "epoch": 6.1592094049893875,
      "grad_norm": 1.185749888420105,
      "learning_rate": 0.00019321687633547336,
      "loss": 0.5731,
      "step": 581800
    },
    {
      "epoch": 6.15973872676939,
      "grad_norm": 1.3183211088180542,
      "learning_rate": 0.0001931718923088941,
      "loss": 0.5709,
      "step": 581850
    },
    {
      "epoch": 6.160268048549393,
      "grad_norm": 1.0483372211456299,
      "learning_rate": 0.0001931269102224057,
      "loss": 0.5827,
      "step": 581900
    },
    {
      "epoch": 6.160797370329397,
      "grad_norm": 1.0883820056915283,
      "learning_rate": 0.00019308193007754363,
      "loss": 0.5721,
      "step": 581950
    },
    {
      "epoch": 6.1613266921094,
      "grad_norm": 1.192539930343628,
      "learning_rate": 0.0001930369518758437,
      "loss": 0.5762,
      "step": 582000
    },
    {
      "epoch": 6.1613266921094,
      "eval_loss": 0.3693230450153351,
      "eval_runtime": 46.8869,
      "eval_samples_per_second": 3581.595,
      "eval_steps_per_second": 447.715,
      "step": 582000
    },
    {
      "epoch": 6.161856013889404,
      "grad_norm": 1.2566922903060913,
      "learning_rate": 0.00019299197561884122,
      "loss": 0.5779,
      "step": 582050
    },
    {
      "epoch": 6.1623853356694065,
      "grad_norm": 1.2434959411621094,
      "learning_rate": 0.00019294700130807182,
      "loss": 0.5854,
      "step": 582100
    },
    {
      "epoch": 6.16291465744941,
      "grad_norm": 1.104374647140503,
      "learning_rate": 0.00019290202894507093,
      "loss": 0.5761,
      "step": 582150
    },
    {
      "epoch": 6.163443979229413,
      "grad_norm": 1.30374014377594,
      "learning_rate": 0.00019285705853137379,
      "loss": 0.5793,
      "step": 582200
    },
    {
      "epoch": 6.163973301009417,
      "grad_norm": 1.3071236610412598,
      "learning_rate": 0.00019281209006851566,
      "loss": 0.5803,
      "step": 582250
    },
    {
      "epoch": 6.16450262278942,
      "grad_norm": 1.1791929006576538,
      "learning_rate": 0.0001927671235580319,
      "loss": 0.5819,
      "step": 582300
    },
    {
      "epoch": 6.1650319445694235,
      "grad_norm": 1.1805721521377563,
      "learning_rate": 0.00019272215900145747,
      "loss": 0.5778,
      "step": 582350
    },
    {
      "epoch": 6.165561266349426,
      "grad_norm": 1.2383445501327515,
      "learning_rate": 0.00019267719640032765,
      "loss": 0.5799,
      "step": 582400
    },
    {
      "epoch": 6.16609058812943,
      "grad_norm": 1.1684826612472534,
      "learning_rate": 0.0001926322357561772,
      "loss": 0.576,
      "step": 582450
    },
    {
      "epoch": 6.166619909909433,
      "grad_norm": 1.2968237400054932,
      "learning_rate": 0.00019258727707054127,
      "loss": 0.5747,
      "step": 582500
    },
    {
      "epoch": 6.166619909909433,
      "eval_loss": 0.36898159980773926,
      "eval_runtime": 46.8559,
      "eval_samples_per_second": 3583.965,
      "eval_steps_per_second": 448.012,
      "step": 582500
    },
    {
      "epoch": 6.167149231689437,
      "grad_norm": 1.2767966985702515,
      "learning_rate": 0.00019254232034495456,
      "loss": 0.5743,
      "step": 582550
    },
    {
      "epoch": 6.16767855346944,
      "grad_norm": 1.1750357151031494,
      "learning_rate": 0.00019249736558095204,
      "loss": 0.582,
      "step": 582600
    },
    {
      "epoch": 6.1682078752494425,
      "grad_norm": 1.3104798793792725,
      "learning_rate": 0.00019245241278006828,
      "loss": 0.5835,
      "step": 582650
    },
    {
      "epoch": 6.168737197029446,
      "grad_norm": 1.1782952547073364,
      "learning_rate": 0.00019240746194383818,
      "loss": 0.5841,
      "step": 582700
    },
    {
      "epoch": 6.169266518809449,
      "grad_norm": 1.1480660438537598,
      "learning_rate": 0.00019236251307379605,
      "loss": 0.574,
      "step": 582750
    },
    {
      "epoch": 6.169795840589453,
      "grad_norm": 1.2277480363845825,
      "learning_rate": 0.0001923175661714767,
      "loss": 0.5736,
      "step": 582800
    },
    {
      "epoch": 6.170325162369456,
      "grad_norm": 1.1546630859375,
      "learning_rate": 0.0001922726212384144,
      "loss": 0.582,
      "step": 582850
    },
    {
      "epoch": 6.1708544841494595,
      "grad_norm": 1.1952074766159058,
      "learning_rate": 0.00019222767827614372,
      "loss": 0.5779,
      "step": 582900
    },
    {
      "epoch": 6.171383805929462,
      "grad_norm": 1.1876165866851807,
      "learning_rate": 0.00019218273728619886,
      "loss": 0.5813,
      "step": 582950
    },
    {
      "epoch": 6.171913127709466,
      "grad_norm": 1.2104308605194092,
      "learning_rate": 0.00019213779827011418,
      "loss": 0.5798,
      "step": 583000
    },
    {
      "epoch": 6.171913127709466,
      "eval_loss": 0.3693440854549408,
      "eval_runtime": 46.8561,
      "eval_samples_per_second": 3583.952,
      "eval_steps_per_second": 448.01,
      "step": 583000
    },
    {
      "epoch": 6.172442449489469,
      "grad_norm": 1.1296021938323975,
      "learning_rate": 0.0001920928612294238,
      "loss": 0.5771,
      "step": 583050
    },
    {
      "epoch": 6.172971771269473,
      "grad_norm": 1.1113158464431763,
      "learning_rate": 0.00019204792616566197,
      "loss": 0.5817,
      "step": 583100
    },
    {
      "epoch": 6.173501093049476,
      "grad_norm": 1.2093217372894287,
      "learning_rate": 0.0001920029930803626,
      "loss": 0.5834,
      "step": 583150
    },
    {
      "epoch": 6.174030414829479,
      "grad_norm": 1.1200228929519653,
      "learning_rate": 0.00019195806197505987,
      "loss": 0.5692,
      "step": 583200
    },
    {
      "epoch": 6.174559736609482,
      "grad_norm": 1.2608908414840698,
      "learning_rate": 0.00019191313285128752,
      "loss": 0.5762,
      "step": 583250
    },
    {
      "epoch": 6.175089058389486,
      "grad_norm": 1.050398588180542,
      "learning_rate": 0.00019186820571057966,
      "loss": 0.5709,
      "step": 583300
    },
    {
      "epoch": 6.175618380169489,
      "grad_norm": 1.1490565538406372,
      "learning_rate": 0.0001918232805544698,
      "loss": 0.5821,
      "step": 583350
    },
    {
      "epoch": 6.176147701949492,
      "grad_norm": 1.1234447956085205,
      "learning_rate": 0.0001917783573844919,
      "loss": 0.5736,
      "step": 583400
    },
    {
      "epoch": 6.1766770237294955,
      "grad_norm": 1.055194616317749,
      "learning_rate": 0.00019173343620217941,
      "loss": 0.5796,
      "step": 583450
    },
    {
      "epoch": 6.177206345509498,
      "grad_norm": 1.2819901704788208,
      "learning_rate": 0.00019168851700906617,
      "loss": 0.5824,
      "step": 583500
    },
    {
      "epoch": 6.177206345509498,
      "eval_loss": 0.36764535307884216,
      "eval_runtime": 46.9144,
      "eval_samples_per_second": 3579.501,
      "eval_steps_per_second": 447.454,
      "step": 583500
    },
    {
      "epoch": 6.177735667289502,
      "grad_norm": 1.0136163234710693,
      "learning_rate": 0.00019164359980668546,
      "loss": 0.5772,
      "step": 583550
    },
    {
      "epoch": 6.178264989069505,
      "grad_norm": 1.2589749097824097,
      "learning_rate": 0.000191598684596571,
      "loss": 0.5657,
      "step": 583600
    },
    {
      "epoch": 6.178794310849509,
      "grad_norm": 1.259148359298706,
      "learning_rate": 0.00019155466962503292,
      "loss": 0.5799,
      "step": 583650
    },
    {
      "epoch": 6.179323632629512,
      "grad_norm": 1.202112078666687,
      "learning_rate": 0.00019150975836412903,
      "loss": 0.5739,
      "step": 583700
    },
    {
      "epoch": 6.179852954409515,
      "grad_norm": 1.113120436668396,
      "learning_rate": 0.00019146484910006047,
      "loss": 0.571,
      "step": 583750
    },
    {
      "epoch": 6.180382276189518,
      "grad_norm": 1.2002136707305908,
      "learning_rate": 0.00019141994183436057,
      "loss": 0.5797,
      "step": 583800
    },
    {
      "epoch": 6.180911597969522,
      "grad_norm": 1.1589863300323486,
      "learning_rate": 0.00019137503656856225,
      "loss": 0.5768,
      "step": 583850
    },
    {
      "epoch": 6.181440919749525,
      "grad_norm": 1.0661715269088745,
      "learning_rate": 0.00019133013330419881,
      "loss": 0.571,
      "step": 583900
    },
    {
      "epoch": 6.181970241529529,
      "grad_norm": 1.1305339336395264,
      "learning_rate": 0.000191285232042803,
      "loss": 0.5745,
      "step": 583950
    },
    {
      "epoch": 6.182499563309531,
      "grad_norm": 1.256791114807129,
      "learning_rate": 0.0001912403327859079,
      "loss": 0.5738,
      "step": 584000
    },
    {
      "epoch": 6.182499563309531,
      "eval_loss": 0.3673267662525177,
      "eval_runtime": 46.9182,
      "eval_samples_per_second": 3579.207,
      "eval_steps_per_second": 447.417,
      "step": 584000
    },
    {
      "epoch": 6.183028885089535,
      "grad_norm": 1.1792222261428833,
      "learning_rate": 0.00019119543553504625,
      "loss": 0.5713,
      "step": 584050
    },
    {
      "epoch": 6.183558206869538,
      "grad_norm": 1.3209068775177002,
      "learning_rate": 0.00019115054029175094,
      "loss": 0.5722,
      "step": 584100
    },
    {
      "epoch": 6.184087528649541,
      "grad_norm": 1.3084213733673096,
      "learning_rate": 0.0001911056470575545,
      "loss": 0.5788,
      "step": 584150
    },
    {
      "epoch": 6.184616850429545,
      "grad_norm": 1.1386735439300537,
      "learning_rate": 0.00019106075583398975,
      "loss": 0.5762,
      "step": 584200
    },
    {
      "epoch": 6.1851461722095475,
      "grad_norm": 1.2418162822723389,
      "learning_rate": 0.00019101586662258907,
      "loss": 0.5859,
      "step": 584250
    },
    {
      "epoch": 6.185675493989551,
      "grad_norm": 1.095800757408142,
      "learning_rate": 0.00019097097942488518,
      "loss": 0.5655,
      "step": 584300
    },
    {
      "epoch": 6.186204815769554,
      "grad_norm": 1.2564756870269775,
      "learning_rate": 0.00019092609424241035,
      "loss": 0.5756,
      "step": 584350
    },
    {
      "epoch": 6.186734137549558,
      "grad_norm": 1.1717573404312134,
      "learning_rate": 0.00019088121107669703,
      "loss": 0.5783,
      "step": 584400
    },
    {
      "epoch": 6.187263459329561,
      "grad_norm": 1.2055039405822754,
      "learning_rate": 0.00019083632992927748,
      "loss": 0.5703,
      "step": 584450
    },
    {
      "epoch": 6.1877927811095645,
      "grad_norm": 1.1131221055984497,
      "learning_rate": 0.00019079145080168393,
      "loss": 0.572,
      "step": 584500
    },
    {
      "epoch": 6.1877927811095645,
      "eval_loss": 0.3675326406955719,
      "eval_runtime": 46.8789,
      "eval_samples_per_second": 3582.209,
      "eval_steps_per_second": 447.792,
      "step": 584500
    },
    {
      "epoch": 6.188322102889567,
      "grad_norm": 1.2141098976135254,
      "learning_rate": 0.00019074657369544845,
      "loss": 0.5774,
      "step": 584550
    },
    {
      "epoch": 6.188851424669571,
      "grad_norm": 1.1630958318710327,
      "learning_rate": 0.00019070169861210335,
      "loss": 0.5761,
      "step": 584600
    },
    {
      "epoch": 6.189380746449574,
      "grad_norm": 1.1945124864578247,
      "learning_rate": 0.0001906568255531804,
      "loss": 0.5762,
      "step": 584650
    },
    {
      "epoch": 6.189910068229578,
      "grad_norm": 1.2256704568862915,
      "learning_rate": 0.00019061195452021177,
      "loss": 0.5729,
      "step": 584700
    },
    {
      "epoch": 6.190439390009581,
      "grad_norm": 1.2177071571350098,
      "learning_rate": 0.00019056708551472913,
      "loss": 0.5805,
      "step": 584750
    },
    {
      "epoch": 6.190968711789584,
      "grad_norm": 1.1620537042617798,
      "learning_rate": 0.0001905222185382645,
      "loss": 0.5678,
      "step": 584800
    },
    {
      "epoch": 6.191498033569587,
      "grad_norm": 1.1384185552597046,
      "learning_rate": 0.0001904773535923494,
      "loss": 0.5711,
      "step": 584850
    },
    {
      "epoch": 6.19202735534959,
      "grad_norm": 1.2046241760253906,
      "learning_rate": 0.0001904324906785157,
      "loss": 0.5734,
      "step": 584900
    },
    {
      "epoch": 6.192556677129594,
      "grad_norm": 1.1206392049789429,
      "learning_rate": 0.00019038762979829485,
      "loss": 0.577,
      "step": 584950
    },
    {
      "epoch": 6.193085998909597,
      "grad_norm": 1.1975678205490112,
      "learning_rate": 0.00019034277095321856,
      "loss": 0.5737,
      "step": 585000
    },
    {
      "epoch": 6.193085998909597,
      "eval_loss": 0.3669719994068146,
      "eval_runtime": 46.7398,
      "eval_samples_per_second": 3592.873,
      "eval_steps_per_second": 449.125,
      "step": 585000
    },
    {
      "epoch": 6.1936153206896005,
      "grad_norm": 1.2723902463912964,
      "learning_rate": 0.00019029791414481808,
      "loss": 0.5863,
      "step": 585050
    },
    {
      "epoch": 6.194144642469603,
      "grad_norm": 1.1491296291351318,
      "learning_rate": 0.00019025305937462504,
      "loss": 0.5736,
      "step": 585100
    },
    {
      "epoch": 6.194673964249607,
      "grad_norm": 1.1990668773651123,
      "learning_rate": 0.0001902082066441705,
      "loss": 0.5764,
      "step": 585150
    },
    {
      "epoch": 6.19520328602961,
      "grad_norm": 1.1192266941070557,
      "learning_rate": 0.00019016335595498597,
      "loss": 0.5779,
      "step": 585200
    },
    {
      "epoch": 6.195732607809614,
      "grad_norm": 1.1675677299499512,
      "learning_rate": 0.00019011850730860246,
      "loss": 0.5728,
      "step": 585250
    },
    {
      "epoch": 6.196261929589617,
      "grad_norm": 1.135970115661621,
      "learning_rate": 0.00019007366070655118,
      "loss": 0.5698,
      "step": 585300
    },
    {
      "epoch": 6.19679125136962,
      "grad_norm": 1.0413975715637207,
      "learning_rate": 0.00019002881615036308,
      "loss": 0.5763,
      "step": 585350
    },
    {
      "epoch": 6.197320573149623,
      "grad_norm": 1.2354764938354492,
      "learning_rate": 0.00018998397364156932,
      "loss": 0.5771,
      "step": 585400
    },
    {
      "epoch": 6.197849894929627,
      "grad_norm": 1.1559377908706665,
      "learning_rate": 0.00018993913318170058,
      "loss": 0.5863,
      "step": 585450
    },
    {
      "epoch": 6.19837921670963,
      "grad_norm": 1.085136890411377,
      "learning_rate": 0.00018989429477228793,
      "loss": 0.5737,
      "step": 585500
    },
    {
      "epoch": 6.19837921670963,
      "eval_loss": 0.367208868265152,
      "eval_runtime": 46.8488,
      "eval_samples_per_second": 3584.512,
      "eval_steps_per_second": 448.08,
      "step": 585500
    },
    {
      "epoch": 6.198908538489634,
      "grad_norm": 1.1836917400360107,
      "learning_rate": 0.00018984945841486186,
      "loss": 0.5815,
      "step": 585550
    },
    {
      "epoch": 6.1994378602696365,
      "grad_norm": 1.1427476406097412,
      "learning_rate": 0.00018980462411095336,
      "loss": 0.574,
      "step": 585600
    },
    {
      "epoch": 6.199967182049639,
      "grad_norm": 1.1051408052444458,
      "learning_rate": 0.00018976068848692069,
      "loss": 0.5674,
      "step": 585650
    },
    {
      "epoch": 6.200496503829643,
      "grad_norm": 1.2227011919021606,
      "learning_rate": 0.00018971585825349225,
      "loss": 0.574,
      "step": 585700
    },
    {
      "epoch": 6.201025825609646,
      "grad_norm": 1.2779877185821533,
      "learning_rate": 0.00018967103007814227,
      "loss": 0.5708,
      "step": 585750
    },
    {
      "epoch": 6.20155514738965,
      "grad_norm": 1.2189384698867798,
      "learning_rate": 0.00018962620396240114,
      "loss": 0.5815,
      "step": 585800
    },
    {
      "epoch": 6.202084469169653,
      "grad_norm": 1.081711769104004,
      "learning_rate": 0.0001895813799077994,
      "loss": 0.5795,
      "step": 585850
    },
    {
      "epoch": 6.202613790949656,
      "grad_norm": 1.0354877710342407,
      "learning_rate": 0.00018953655791586707,
      "loss": 0.5808,
      "step": 585900
    },
    {
      "epoch": 6.203143112729659,
      "grad_norm": 1.248219609260559,
      "learning_rate": 0.0001894917379881346,
      "loss": 0.5764,
      "step": 585950
    },
    {
      "epoch": 6.203672434509663,
      "grad_norm": 1.1918548345565796,
      "learning_rate": 0.00018944692012613188,
      "loss": 0.5716,
      "step": 586000
    },
    {
      "epoch": 6.203672434509663,
      "eval_loss": 0.3674485981464386,
      "eval_runtime": 46.8755,
      "eval_samples_per_second": 3582.47,
      "eval_steps_per_second": 447.825,
      "step": 586000
    },
    {
      "epoch": 6.204201756289666,
      "grad_norm": 1.1186753511428833,
      "learning_rate": 0.0001894021043313892,
      "loss": 0.5677,
      "step": 586050
    },
    {
      "epoch": 6.20473107806967,
      "grad_norm": 1.1903002262115479,
      "learning_rate": 0.00018935729060543639,
      "loss": 0.5778,
      "step": 586100
    },
    {
      "epoch": 6.2052603998496725,
      "grad_norm": 1.1494890451431274,
      "learning_rate": 0.0001893124789498035,
      "loss": 0.5723,
      "step": 586150
    },
    {
      "epoch": 6.205789721629676,
      "grad_norm": 1.0133668184280396,
      "learning_rate": 0.00018926766936602026,
      "loss": 0.5717,
      "step": 586200
    },
    {
      "epoch": 6.206319043409679,
      "grad_norm": 1.1735605001449585,
      "learning_rate": 0.00018922286185561654,
      "loss": 0.583,
      "step": 586250
    },
    {
      "epoch": 6.206848365189683,
      "grad_norm": 1.1739599704742432,
      "learning_rate": 0.000189178056420122,
      "loss": 0.5626,
      "step": 586300
    },
    {
      "epoch": 6.207377686969686,
      "grad_norm": 1.1234036684036255,
      "learning_rate": 0.00018913325306106637,
      "loss": 0.5734,
      "step": 586350
    },
    {
      "epoch": 6.2079070087496895,
      "grad_norm": 1.109611988067627,
      "learning_rate": 0.00018908845177997908,
      "loss": 0.5748,
      "step": 586400
    },
    {
      "epoch": 6.208436330529692,
      "grad_norm": 1.1928913593292236,
      "learning_rate": 0.00018904365257838978,
      "loss": 0.5717,
      "step": 586450
    },
    {
      "epoch": 6.208965652309695,
      "grad_norm": 1.090416669845581,
      "learning_rate": 0.00018899885545782777,
      "loss": 0.5778,
      "step": 586500
    },
    {
      "epoch": 6.208965652309695,
      "eval_loss": 0.366282194852829,
      "eval_runtime": 46.8236,
      "eval_samples_per_second": 3586.438,
      "eval_steps_per_second": 448.321,
      "step": 586500
    },
    {
      "epoch": 6.209494974089699,
      "grad_norm": 1.1197227239608765,
      "learning_rate": 0.00018895406041982249,
      "loss": 0.5642,
      "step": 586550
    },
    {
      "epoch": 6.210024295869702,
      "grad_norm": 1.2134554386138916,
      "learning_rate": 0.00018890926746590315,
      "loss": 0.5824,
      "step": 586600
    },
    {
      "epoch": 6.210553617649706,
      "grad_norm": 1.0984338521957397,
      "learning_rate": 0.00018886447659759913,
      "loss": 0.5706,
      "step": 586650
    },
    {
      "epoch": 6.2110829394297085,
      "grad_norm": 1.106290340423584,
      "learning_rate": 0.0001888196878164393,
      "loss": 0.577,
      "step": 586700
    },
    {
      "epoch": 6.211612261209712,
      "grad_norm": 1.264406442642212,
      "learning_rate": 0.00018877490112395308,
      "loss": 0.5848,
      "step": 586750
    },
    {
      "epoch": 6.212141582989715,
      "grad_norm": 1.1523069143295288,
      "learning_rate": 0.0001887301165216691,
      "loss": 0.5722,
      "step": 586800
    },
    {
      "epoch": 6.212670904769719,
      "grad_norm": 1.1176784038543701,
      "learning_rate": 0.00018868533401111663,
      "loss": 0.5842,
      "step": 586850
    },
    {
      "epoch": 6.213200226549722,
      "grad_norm": 1.1706764698028564,
      "learning_rate": 0.00018864055359382422,
      "loss": 0.5753,
      "step": 586900
    },
    {
      "epoch": 6.2137295483297255,
      "grad_norm": 1.2454649209976196,
      "learning_rate": 0.00018859577527132094,
      "loss": 0.5765,
      "step": 586950
    },
    {
      "epoch": 6.214258870109728,
      "grad_norm": 1.093665361404419,
      "learning_rate": 0.00018855099904513525,
      "loss": 0.571,
      "step": 587000
    },
    {
      "epoch": 6.214258870109728,
      "eval_loss": 0.3685317635536194,
      "eval_runtime": 46.8512,
      "eval_samples_per_second": 3584.327,
      "eval_steps_per_second": 448.057,
      "step": 587000
    },
    {
      "epoch": 6.214788191889732,
      "grad_norm": 1.2081260681152344,
      "learning_rate": 0.00018850622491679606,
      "loss": 0.5686,
      "step": 587050
    },
    {
      "epoch": 6.215317513669735,
      "grad_norm": 1.2075127363204956,
      "learning_rate": 0.00018846145288783169,
      "loss": 0.5697,
      "step": 587100
    },
    {
      "epoch": 6.215846835449739,
      "grad_norm": 1.2749807834625244,
      "learning_rate": 0.00018841668295977083,
      "loss": 0.5609,
      "step": 587150
    },
    {
      "epoch": 6.216376157229742,
      "grad_norm": 1.2866805791854858,
      "learning_rate": 0.0001883719151341417,
      "loss": 0.5636,
      "step": 587200
    },
    {
      "epoch": 6.216905479009744,
      "grad_norm": 1.1162488460540771,
      "learning_rate": 0.00018832714941247286,
      "loss": 0.573,
      "step": 587250
    },
    {
      "epoch": 6.217434800789748,
      "grad_norm": 1.304352045059204,
      "learning_rate": 0.00018828238579629252,
      "loss": 0.5704,
      "step": 587300
    },
    {
      "epoch": 6.217964122569751,
      "grad_norm": 1.0998520851135254,
      "learning_rate": 0.00018823762428712892,
      "loss": 0.5702,
      "step": 587350
    },
    {
      "epoch": 6.218493444349755,
      "grad_norm": 1.2731772661209106,
      "learning_rate": 0.0001881928648865101,
      "loss": 0.5709,
      "step": 587400
    },
    {
      "epoch": 6.219022766129758,
      "grad_norm": 1.179788589477539,
      "learning_rate": 0.00018814810759596433,
      "loss": 0.5746,
      "step": 587450
    },
    {
      "epoch": 6.219552087909761,
      "grad_norm": 1.1282851696014404,
      "learning_rate": 0.00018810335241701938,
      "loss": 0.582,
      "step": 587500
    },
    {
      "epoch": 6.219552087909761,
      "eval_loss": 0.3668665289878845,
      "eval_runtime": 46.856,
      "eval_samples_per_second": 3583.96,
      "eval_steps_per_second": 448.011,
      "step": 587500
    },
    {
      "epoch": 6.220081409689764,
      "grad_norm": 1.1454200744628906,
      "learning_rate": 0.00018805859935120333,
      "loss": 0.5806,
      "step": 587550
    },
    {
      "epoch": 6.220610731469768,
      "grad_norm": 1.1078948974609375,
      "learning_rate": 0.00018801384840004393,
      "loss": 0.5751,
      "step": 587600
    },
    {
      "epoch": 6.221140053249771,
      "grad_norm": 1.3932641744613647,
      "learning_rate": 0.0001879699945210201,
      "loss": 0.5707,
      "step": 587650
    },
    {
      "epoch": 6.221669375029775,
      "grad_norm": 1.1265218257904053,
      "learning_rate": 0.00018792524776138815,
      "loss": 0.5697,
      "step": 587700
    },
    {
      "epoch": 6.2221986968097776,
      "grad_norm": 1.2071952819824219,
      "learning_rate": 0.00018788050312096557,
      "loss": 0.5838,
      "step": 587750
    },
    {
      "epoch": 6.222728018589781,
      "grad_norm": 1.1731255054473877,
      "learning_rate": 0.00018783576060127973,
      "loss": 0.5788,
      "step": 587800
    },
    {
      "epoch": 6.223257340369784,
      "grad_norm": 1.2473289966583252,
      "learning_rate": 0.00018779102020385829,
      "loss": 0.5795,
      "step": 587850
    },
    {
      "epoch": 6.223786662149788,
      "grad_norm": 1.1997190713882446,
      "learning_rate": 0.00018774628193022857,
      "loss": 0.5708,
      "step": 587900
    },
    {
      "epoch": 6.224315983929791,
      "grad_norm": 1.2279585599899292,
      "learning_rate": 0.000187701545781918,
      "loss": 0.5741,
      "step": 587950
    },
    {
      "epoch": 6.224845305709794,
      "grad_norm": 1.1838316917419434,
      "learning_rate": 0.00018765681176045374,
      "loss": 0.5704,
      "step": 588000
    },
    {
      "epoch": 6.224845305709794,
      "eval_loss": 0.3662571310997009,
      "eval_runtime": 46.8358,
      "eval_samples_per_second": 3585.506,
      "eval_steps_per_second": 448.204,
      "step": 588000
    },
    {
      "epoch": 6.225374627489797,
      "grad_norm": 1.1259609460830688,
      "learning_rate": 0.00018761207986736316,
      "loss": 0.5678,
      "step": 588050
    },
    {
      "epoch": 6.2259039492698,
      "grad_norm": 1.197725534439087,
      "learning_rate": 0.0001875673501041732,
      "loss": 0.5749,
      "step": 588100
    },
    {
      "epoch": 6.226433271049804,
      "grad_norm": 1.0882830619812012,
      "learning_rate": 0.00018752262247241112,
      "loss": 0.5645,
      "step": 588150
    },
    {
      "epoch": 6.226962592829807,
      "grad_norm": 1.1760005950927734,
      "learning_rate": 0.00018747789697360368,
      "loss": 0.5699,
      "step": 588200
    },
    {
      "epoch": 6.227491914609811,
      "grad_norm": 1.2888342142105103,
      "learning_rate": 0.000187433173609278,
      "loss": 0.5732,
      "step": 588250
    },
    {
      "epoch": 6.2280212363898135,
      "grad_norm": 1.1923102140426636,
      "learning_rate": 0.00018738845238096074,
      "loss": 0.5773,
      "step": 588300
    },
    {
      "epoch": 6.228550558169817,
      "grad_norm": 1.276350498199463,
      "learning_rate": 0.00018734373329017885,
      "loss": 0.5727,
      "step": 588350
    },
    {
      "epoch": 6.22907987994982,
      "grad_norm": 1.1469002962112427,
      "learning_rate": 0.0001872990163384588,
      "loss": 0.58,
      "step": 588400
    },
    {
      "epoch": 6.229609201729824,
      "grad_norm": 0.9336304068565369,
      "learning_rate": 0.00018725430152732747,
      "loss": 0.5638,
      "step": 588450
    },
    {
      "epoch": 6.230138523509827,
      "grad_norm": 1.2730047702789307,
      "learning_rate": 0.00018720958885831118,
      "loss": 0.58,
      "step": 588500
    },
    {
      "epoch": 6.230138523509827,
      "eval_loss": 0.366698682308197,
      "eval_runtime": 46.7423,
      "eval_samples_per_second": 3592.674,
      "eval_steps_per_second": 449.1,
      "step": 588500
    },
    {
      "epoch": 6.2306678452898305,
      "grad_norm": 1.1555284261703491,
      "learning_rate": 0.0001871648783329366,
      "loss": 0.5737,
      "step": 588550
    },
    {
      "epoch": 6.231197167069833,
      "grad_norm": 1.1050851345062256,
      "learning_rate": 0.0001871201699527299,
      "loss": 0.5761,
      "step": 588600
    },
    {
      "epoch": 6.231726488849837,
      "grad_norm": 1.2874500751495361,
      "learning_rate": 0.00018707546371921763,
      "loss": 0.5831,
      "step": 588650
    },
    {
      "epoch": 6.23225581062984,
      "grad_norm": 1.3477182388305664,
      "learning_rate": 0.00018703075963392592,
      "loss": 0.5723,
      "step": 588700
    },
    {
      "epoch": 6.232785132409843,
      "grad_norm": 1.0172613859176636,
      "learning_rate": 0.000186986057698381,
      "loss": 0.5815,
      "step": 588750
    },
    {
      "epoch": 6.233314454189847,
      "grad_norm": 1.254416823387146,
      "learning_rate": 0.00018694135791410887,
      "loss": 0.5827,
      "step": 588800
    },
    {
      "epoch": 6.2338437759698495,
      "grad_norm": 1.2286005020141602,
      "learning_rate": 0.0001868966602826358,
      "loss": 0.5771,
      "step": 588850
    },
    {
      "epoch": 6.234373097749853,
      "grad_norm": 1.158010482788086,
      "learning_rate": 0.00018685196480548749,
      "loss": 0.5759,
      "step": 588900
    },
    {
      "epoch": 6.234902419529856,
      "grad_norm": 1.2938607931137085,
      "learning_rate": 0.00018680727148419004,
      "loss": 0.5724,
      "step": 588950
    },
    {
      "epoch": 6.23543174130986,
      "grad_norm": 1.187503457069397,
      "learning_rate": 0.00018676258032026906,
      "loss": 0.5779,
      "step": 589000
    },
    {
      "epoch": 6.23543174130986,
      "eval_loss": 0.36445000767707825,
      "eval_runtime": 46.8112,
      "eval_samples_per_second": 3587.39,
      "eval_steps_per_second": 448.44,
      "step": 589000
    },
    {
      "epoch": 6.235961063089863,
      "grad_norm": 1.2775977849960327,
      "learning_rate": 0.0001867178913152505,
      "loss": 0.5749,
      "step": 589050
    },
    {
      "epoch": 6.2364903848698665,
      "grad_norm": 1.1517413854599,
      "learning_rate": 0.00018667320447065982,
      "loss": 0.5813,
      "step": 589100
    },
    {
      "epoch": 6.237019706649869,
      "grad_norm": 1.1868685483932495,
      "learning_rate": 0.00018662851978802286,
      "loss": 0.5733,
      "step": 589150
    },
    {
      "epoch": 6.237549028429873,
      "grad_norm": 1.123753547668457,
      "learning_rate": 0.00018658383726886485,
      "loss": 0.5593,
      "step": 589200
    },
    {
      "epoch": 6.238078350209876,
      "grad_norm": 1.094374656677246,
      "learning_rate": 0.0001865391569147115,
      "loss": 0.5861,
      "step": 589250
    },
    {
      "epoch": 6.23860767198988,
      "grad_norm": 1.2558269500732422,
      "learning_rate": 0.00018649537226959857,
      "loss": 0.5715,
      "step": 589300
    },
    {
      "epoch": 6.239136993769883,
      "grad_norm": 1.1607216596603394,
      "learning_rate": 0.00018645069620665418,
      "loss": 0.578,
      "step": 589350
    },
    {
      "epoch": 6.239666315549886,
      "grad_norm": 1.1170908212661743,
      "learning_rate": 0.00018640602231325982,
      "loss": 0.5744,
      "step": 589400
    },
    {
      "epoch": 6.240195637329889,
      "grad_norm": 1.2289701700210571,
      "learning_rate": 0.00018636135059094038,
      "loss": 0.5749,
      "step": 589450
    },
    {
      "epoch": 6.240724959109892,
      "grad_norm": 1.1253255605697632,
      "learning_rate": 0.00018631668104122123,
      "loss": 0.5703,
      "step": 589500
    },
    {
      "epoch": 6.240724959109892,
      "eval_loss": 0.3663165271282196,
      "eval_runtime": 46.9687,
      "eval_samples_per_second": 3575.364,
      "eval_steps_per_second": 446.936,
      "step": 589500
    },
    {
      "epoch": 6.241254280889896,
      "grad_norm": 1.1763131618499756,
      "learning_rate": 0.00018627201366562716,
      "loss": 0.5773,
      "step": 589550
    },
    {
      "epoch": 6.241783602669899,
      "grad_norm": 1.083502173423767,
      "learning_rate": 0.00018622734846568322,
      "loss": 0.575,
      "step": 589600
    },
    {
      "epoch": 6.2423129244499025,
      "grad_norm": 1.158332347869873,
      "learning_rate": 0.00018618268544291417,
      "loss": 0.5739,
      "step": 589650
    },
    {
      "epoch": 6.242842246229905,
      "grad_norm": 1.097726821899414,
      "learning_rate": 0.0001861380245988449,
      "loss": 0.5798,
      "step": 589700
    },
    {
      "epoch": 6.243371568009909,
      "grad_norm": 1.084444522857666,
      "learning_rate": 0.000186093365935,
      "loss": 0.579,
      "step": 589750
    },
    {
      "epoch": 6.243900889789912,
      "grad_norm": 1.0558606386184692,
      "learning_rate": 0.00018604870945290418,
      "loss": 0.5722,
      "step": 589800
    },
    {
      "epoch": 6.244430211569916,
      "grad_norm": 1.2293684482574463,
      "learning_rate": 0.00018600405515408188,
      "loss": 0.5657,
      "step": 589850
    },
    {
      "epoch": 6.244959533349919,
      "grad_norm": 1.0310560464859009,
      "learning_rate": 0.00018595940304005774,
      "loss": 0.5776,
      "step": 589900
    },
    {
      "epoch": 6.245488855129922,
      "grad_norm": 1.1607816219329834,
      "learning_rate": 0.00018591475311235608,
      "loss": 0.5781,
      "step": 589950
    },
    {
      "epoch": 6.246018176909925,
      "grad_norm": 1.0589796304702759,
      "learning_rate": 0.00018587010537250126,
      "loss": 0.5755,
      "step": 590000
    },
    {
      "epoch": 6.246018176909925,
      "eval_loss": 0.365654855966568,
      "eval_runtime": 46.8817,
      "eval_samples_per_second": 3581.993,
      "eval_steps_per_second": 447.765,
      "step": 590000
    },
    {
      "epoch": 6.246547498689929,
      "grad_norm": 1.2215007543563843,
      "learning_rate": 0.00018582545982201746,
      "loss": 0.5779,
      "step": 590050
    },
    {
      "epoch": 6.247076820469932,
      "grad_norm": 1.0409804582595825,
      "learning_rate": 0.00018578081646242902,
      "loss": 0.5811,
      "step": 590100
    },
    {
      "epoch": 6.247606142249936,
      "grad_norm": 1.3467353582382202,
      "learning_rate": 0.00018573617529525987,
      "loss": 0.5715,
      "step": 590150
    },
    {
      "epoch": 6.2481354640299385,
      "grad_norm": 1.1602283716201782,
      "learning_rate": 0.00018569153632203424,
      "loss": 0.5717,
      "step": 590200
    },
    {
      "epoch": 6.248664785809941,
      "grad_norm": 1.282792091369629,
      "learning_rate": 0.00018564689954427582,
      "loss": 0.5854,
      "step": 590250
    },
    {
      "epoch": 6.249194107589945,
      "grad_norm": 1.1893913745880127,
      "learning_rate": 0.00018560226496350883,
      "loss": 0.564,
      "step": 590300
    },
    {
      "epoch": 6.249723429369948,
      "grad_norm": 1.4033088684082031,
      "learning_rate": 0.00018555763258125673,
      "loss": 0.5705,
      "step": 590350
    },
    {
      "epoch": 6.250252751149952,
      "grad_norm": 1.1336426734924316,
      "learning_rate": 0.00018551300239904355,
      "loss": 0.5767,
      "step": 590400
    },
    {
      "epoch": 6.250782072929955,
      "grad_norm": 1.1553279161453247,
      "learning_rate": 0.00018546837441839271,
      "loss": 0.5751,
      "step": 590450
    },
    {
      "epoch": 6.251311394709958,
      "grad_norm": 1.1102219820022583,
      "learning_rate": 0.000185423748640828,
      "loss": 0.5773,
      "step": 590500
    },
    {
      "epoch": 6.251311394709958,
      "eval_loss": 0.3650931119918823,
      "eval_runtime": 46.7948,
      "eval_samples_per_second": 3588.648,
      "eval_steps_per_second": 448.597,
      "step": 590500
    },
    {
      "epoch": 6.251840716489961,
      "grad_norm": 1.267029047012329,
      "learning_rate": 0.00018537912506787275,
      "loss": 0.5673,
      "step": 590550
    },
    {
      "epoch": 6.252370038269965,
      "grad_norm": 1.167725682258606,
      "learning_rate": 0.00018533450370105054,
      "loss": 0.5707,
      "step": 590600
    },
    {
      "epoch": 6.252899360049968,
      "grad_norm": 1.1058284044265747,
      "learning_rate": 0.00018528988454188456,
      "loss": 0.5637,
      "step": 590650
    },
    {
      "epoch": 6.253428681829972,
      "grad_norm": 1.1990313529968262,
      "learning_rate": 0.00018524526759189824,
      "loss": 0.5726,
      "step": 590700
    },
    {
      "epoch": 6.2539580036099744,
      "grad_norm": 1.1249773502349854,
      "learning_rate": 0.00018520065285261477,
      "loss": 0.5678,
      "step": 590750
    },
    {
      "epoch": 6.254487325389978,
      "grad_norm": 1.1994813680648804,
      "learning_rate": 0.00018515604032555723,
      "loss": 0.571,
      "step": 590800
    },
    {
      "epoch": 6.255016647169981,
      "grad_norm": 1.0890216827392578,
      "learning_rate": 0.0001851114300122486,
      "loss": 0.5729,
      "step": 590850
    },
    {
      "epoch": 6.255545968949985,
      "grad_norm": 0.9704738259315491,
      "learning_rate": 0.00018506682191421213,
      "loss": 0.5706,
      "step": 590900
    },
    {
      "epoch": 6.256075290729988,
      "grad_norm": 1.1194193363189697,
      "learning_rate": 0.0001850222160329704,
      "loss": 0.57,
      "step": 590950
    },
    {
      "epoch": 6.256604612509991,
      "grad_norm": 1.2075284719467163,
      "learning_rate": 0.00018497761237004648,
      "loss": 0.582,
      "step": 591000
    },
    {
      "epoch": 6.256604612509991,
      "eval_loss": 0.3652340769767761,
      "eval_runtime": 46.8643,
      "eval_samples_per_second": 3583.325,
      "eval_steps_per_second": 447.932,
      "step": 591000
    },
    {
      "epoch": 6.257133934289994,
      "grad_norm": 1.2688612937927246,
      "learning_rate": 0.00018493301092696295,
      "loss": 0.5708,
      "step": 591050
    },
    {
      "epoch": 6.257663256069997,
      "grad_norm": 1.2262465953826904,
      "learning_rate": 0.00018488841170524265,
      "loss": 0.5731,
      "step": 591100
    },
    {
      "epoch": 6.258192577850001,
      "grad_norm": 1.1786106824874878,
      "learning_rate": 0.000184843814706408,
      "loss": 0.5648,
      "step": 591150
    },
    {
      "epoch": 6.258721899630004,
      "grad_norm": 1.1498807668685913,
      "learning_rate": 0.00018479921993198173,
      "loss": 0.5654,
      "step": 591200
    },
    {
      "epoch": 6.259251221410008,
      "grad_norm": 1.1863220930099487,
      "learning_rate": 0.00018475462738348604,
      "loss": 0.5722,
      "step": 591250
    },
    {
      "epoch": 6.25978054319001,
      "grad_norm": 1.259496808052063,
      "learning_rate": 0.00018471003706244357,
      "loss": 0.569,
      "step": 591300
    },
    {
      "epoch": 6.260309864970014,
      "grad_norm": 1.1560215950012207,
      "learning_rate": 0.0001846654489703764,
      "loss": 0.5731,
      "step": 591350
    },
    {
      "epoch": 6.260839186750017,
      "grad_norm": 1.1473063230514526,
      "learning_rate": 0.00018462086310880692,
      "loss": 0.5667,
      "step": 591400
    },
    {
      "epoch": 6.261368508530021,
      "grad_norm": 1.1549301147460938,
      "learning_rate": 0.0001845762794792571,
      "loss": 0.5808,
      "step": 591450
    },
    {
      "epoch": 6.261897830310024,
      "grad_norm": 1.3338792324066162,
      "learning_rate": 0.00018453169808324918,
      "loss": 0.5731,
      "step": 591500
    },
    {
      "epoch": 6.261897830310024,
      "eval_loss": 0.36428672075271606,
      "eval_runtime": 46.7775,
      "eval_samples_per_second": 3589.97,
      "eval_steps_per_second": 448.762,
      "step": 591500
    },
    {
      "epoch": 6.262427152090027,
      "grad_norm": 1.2243804931640625,
      "learning_rate": 0.00018448711892230508,
      "loss": 0.5598,
      "step": 591550
    },
    {
      "epoch": 6.26295647387003,
      "grad_norm": 1.119734287261963,
      "learning_rate": 0.00018444254199794668,
      "loss": 0.5795,
      "step": 591600
    },
    {
      "epoch": 6.263485795650034,
      "grad_norm": 1.127345085144043,
      "learning_rate": 0.0001843979673116959,
      "loss": 0.5739,
      "step": 591650
    },
    {
      "epoch": 6.264015117430037,
      "grad_norm": 1.2940387725830078,
      "learning_rate": 0.0001843533948650744,
      "loss": 0.5679,
      "step": 591700
    },
    {
      "epoch": 6.26454443921004,
      "grad_norm": 1.2590912580490112,
      "learning_rate": 0.00018430882465960392,
      "loss": 0.5666,
      "step": 591750
    },
    {
      "epoch": 6.2650737609900435,
      "grad_norm": 1.0837267637252808,
      "learning_rate": 0.00018426425669680613,
      "loss": 0.5684,
      "step": 591800
    },
    {
      "epoch": 6.265603082770046,
      "grad_norm": 1.21380615234375,
      "learning_rate": 0.00018421969097820242,
      "loss": 0.5749,
      "step": 591850
    },
    {
      "epoch": 6.26613240455005,
      "grad_norm": 1.1830592155456543,
      "learning_rate": 0.00018417512750531446,
      "loss": 0.5804,
      "step": 591900
    },
    {
      "epoch": 6.266661726330053,
      "grad_norm": 1.1594959497451782,
      "learning_rate": 0.0001841305662796634,
      "loss": 0.5783,
      "step": 591950
    },
    {
      "epoch": 6.267191048110057,
      "grad_norm": 1.0443588495254517,
      "learning_rate": 0.00018408600730277075,
      "loss": 0.5664,
      "step": 592000
    },
    {
      "epoch": 6.267191048110057,
      "eval_loss": 0.36538946628570557,
      "eval_runtime": 46.7908,
      "eval_samples_per_second": 3588.951,
      "eval_steps_per_second": 448.635,
      "step": 592000
    },
    {
      "epoch": 6.26772036989006,
      "grad_norm": 1.101874828338623,
      "learning_rate": 0.00018404145057615752,
      "loss": 0.5622,
      "step": 592050
    },
    {
      "epoch": 6.268249691670063,
      "grad_norm": 1.297501802444458,
      "learning_rate": 0.0001839968961013451,
      "loss": 0.5729,
      "step": 592100
    },
    {
      "epoch": 6.268779013450066,
      "grad_norm": 1.1787569522857666,
      "learning_rate": 0.0001839523438798543,
      "loss": 0.573,
      "step": 592150
    },
    {
      "epoch": 6.26930833523007,
      "grad_norm": 1.121870756149292,
      "learning_rate": 0.00018390779391320642,
      "loss": 0.5745,
      "step": 592200
    },
    {
      "epoch": 6.269837657010073,
      "grad_norm": 1.1264569759368896,
      "learning_rate": 0.00018386324620292207,
      "loss": 0.5802,
      "step": 592250
    },
    {
      "epoch": 6.270366978790077,
      "grad_norm": 1.2130398750305176,
      "learning_rate": 0.00018381870075052237,
      "loss": 0.5731,
      "step": 592300
    },
    {
      "epoch": 6.2708963005700795,
      "grad_norm": 1.265647530555725,
      "learning_rate": 0.00018377415755752786,
      "loss": 0.568,
      "step": 592350
    },
    {
      "epoch": 6.271425622350083,
      "grad_norm": 1.1309813261032104,
      "learning_rate": 0.00018372961662545934,
      "loss": 0.5678,
      "step": 592400
    },
    {
      "epoch": 6.271954944130086,
      "grad_norm": 1.2689244747161865,
      "learning_rate": 0.00018368507795583742,
      "loss": 0.575,
      "step": 592450
    },
    {
      "epoch": 6.272484265910089,
      "grad_norm": 1.3200979232788086,
      "learning_rate": 0.00018364054155018262,
      "loss": 0.5666,
      "step": 592500
    },
    {
      "epoch": 6.272484265910089,
      "eval_loss": 0.36454248428344727,
      "eval_runtime": 46.7808,
      "eval_samples_per_second": 3589.717,
      "eval_steps_per_second": 448.731,
      "step": 592500
    },
    {
      "epoch": 6.273013587690093,
      "grad_norm": 1.1559444665908813,
      "learning_rate": 0.00018359600741001535,
      "loss": 0.5672,
      "step": 592550
    },
    {
      "epoch": 6.273542909470096,
      "grad_norm": 1.2253447771072388,
      "learning_rate": 0.0001835514755368561,
      "loss": 0.5742,
      "step": 592600
    },
    {
      "epoch": 6.274072231250099,
      "grad_norm": 1.2145229578018188,
      "learning_rate": 0.00018350694593222505,
      "loss": 0.5791,
      "step": 592650
    },
    {
      "epoch": 6.274601553030102,
      "grad_norm": 1.213910460472107,
      "learning_rate": 0.00018346241859764256,
      "loss": 0.5779,
      "step": 592700
    },
    {
      "epoch": 6.275130874810106,
      "grad_norm": 1.188188910484314,
      "learning_rate": 0.0001834178935346286,
      "loss": 0.5728,
      "step": 592750
    },
    {
      "epoch": 6.275660196590109,
      "grad_norm": 1.2935864925384521,
      "learning_rate": 0.00018337337074470346,
      "loss": 0.5719,
      "step": 592800
    },
    {
      "epoch": 6.276189518370113,
      "grad_norm": 1.2362194061279297,
      "learning_rate": 0.00018332885022938686,
      "loss": 0.5736,
      "step": 592850
    },
    {
      "epoch": 6.2767188401501155,
      "grad_norm": 1.3052325248718262,
      "learning_rate": 0.000183284331990199,
      "loss": 0.5692,
      "step": 592900
    },
    {
      "epoch": 6.277248161930119,
      "grad_norm": 1.109205961227417,
      "learning_rate": 0.00018323981602865947,
      "loss": 0.5758,
      "step": 592950
    },
    {
      "epoch": 6.277777483710122,
      "grad_norm": 1.189638614654541,
      "learning_rate": 0.00018319530234628823,
      "loss": 0.5712,
      "step": 593000
    },
    {
      "epoch": 6.277777483710122,
      "eval_loss": 0.36406078934669495,
      "eval_runtime": 46.8348,
      "eval_samples_per_second": 3585.583,
      "eval_steps_per_second": 448.214,
      "step": 593000
    },
    {
      "epoch": 6.278306805490126,
      "grad_norm": 1.094148874282837,
      "learning_rate": 0.00018315079094460474,
      "loss": 0.5686,
      "step": 593050
    },
    {
      "epoch": 6.278836127270129,
      "grad_norm": 1.173884630203247,
      "learning_rate": 0.0001831062818251289,
      "loss": 0.5758,
      "step": 593100
    },
    {
      "epoch": 6.2793654490501325,
      "grad_norm": 1.2063521146774292,
      "learning_rate": 0.0001830617749893799,
      "loss": 0.5745,
      "step": 593150
    },
    {
      "epoch": 6.279894770830135,
      "grad_norm": 1.2541133165359497,
      "learning_rate": 0.00018301727043887745,
      "loss": 0.5645,
      "step": 593200
    },
    {
      "epoch": 6.280424092610138,
      "grad_norm": 1.1655356884002686,
      "learning_rate": 0.0001829727681751408,
      "loss": 0.5709,
      "step": 593250
    },
    {
      "epoch": 6.280953414390142,
      "grad_norm": 1.0166579484939575,
      "learning_rate": 0.00018292915817676324,
      "loss": 0.582,
      "step": 593300
    },
    {
      "epoch": 6.281482736170145,
      "grad_norm": 1.1721440553665161,
      "learning_rate": 0.0001828846604453051,
      "loss": 0.5697,
      "step": 593350
    },
    {
      "epoch": 6.282012057950149,
      "grad_norm": 1.3358685970306396,
      "learning_rate": 0.00018284016500513995,
      "loss": 0.5781,
      "step": 593400
    },
    {
      "epoch": 6.2825413797301515,
      "grad_norm": 1.1342558860778809,
      "learning_rate": 0.00018279567185778707,
      "loss": 0.5762,
      "step": 593450
    },
    {
      "epoch": 6.283070701510155,
      "grad_norm": 1.2019444704055786,
      "learning_rate": 0.00018275118100476512,
      "loss": 0.57,
      "step": 593500
    },
    {
      "epoch": 6.283070701510155,
      "eval_loss": 0.3646988272666931,
      "eval_runtime": 46.8439,
      "eval_samples_per_second": 3584.884,
      "eval_steps_per_second": 448.127,
      "step": 593500
    },
    {
      "epoch": 6.283600023290158,
      "grad_norm": 1.119055986404419,
      "learning_rate": 0.00018270669244759336,
      "loss": 0.5809,
      "step": 593550
    },
    {
      "epoch": 6.284129345070162,
      "grad_norm": 1.14193594455719,
      "learning_rate": 0.0001826622061877903,
      "loss": 0.5709,
      "step": 593600
    },
    {
      "epoch": 6.284658666850165,
      "grad_norm": 1.256235957145691,
      "learning_rate": 0.0001826177222268749,
      "loss": 0.573,
      "step": 593650
    },
    {
      "epoch": 6.2851879886301685,
      "grad_norm": 1.260184645652771,
      "learning_rate": 0.00018257324056636577,
      "loss": 0.5846,
      "step": 593700
    },
    {
      "epoch": 6.285717310410171,
      "grad_norm": 1.1173301935195923,
      "learning_rate": 0.0001825287612077814,
      "loss": 0.5718,
      "step": 593750
    },
    {
      "epoch": 6.286246632190175,
      "grad_norm": 1.243960976600647,
      "learning_rate": 0.0001824842841526404,
      "loss": 0.5673,
      "step": 593800
    },
    {
      "epoch": 6.286775953970178,
      "grad_norm": 1.2233877182006836,
      "learning_rate": 0.0001824398094024612,
      "loss": 0.5712,
      "step": 593850
    },
    {
      "epoch": 6.287305275750182,
      "grad_norm": 1.2167469263076782,
      "learning_rate": 0.00018239533695876215,
      "loss": 0.5628,
      "step": 593900
    },
    {
      "epoch": 6.287834597530185,
      "grad_norm": 1.3168827295303345,
      "learning_rate": 0.00018235086682306145,
      "loss": 0.5677,
      "step": 593950
    },
    {
      "epoch": 6.2883639193101875,
      "grad_norm": 1.2358864545822144,
      "learning_rate": 0.00018230639899687742,
      "loss": 0.5715,
      "step": 594000
    },
    {
      "epoch": 6.2883639193101875,
      "eval_loss": 0.36307036876678467,
      "eval_runtime": 46.8043,
      "eval_samples_per_second": 3587.916,
      "eval_steps_per_second": 448.506,
      "step": 594000
    },
    {
      "epoch": 6.288893241090191,
      "grad_norm": 1.244137167930603,
      "learning_rate": 0.00018226193348172803,
      "loss": 0.5785,
      "step": 594050
    },
    {
      "epoch": 6.289422562870194,
      "grad_norm": 1.1438380479812622,
      "learning_rate": 0.00018221747027913148,
      "loss": 0.5643,
      "step": 594100
    },
    {
      "epoch": 6.289951884650198,
      "grad_norm": 1.1035761833190918,
      "learning_rate": 0.00018217300939060555,
      "loss": 0.5759,
      "step": 594150
    },
    {
      "epoch": 6.290481206430201,
      "grad_norm": 1.0811530351638794,
      "learning_rate": 0.00018212855081766827,
      "loss": 0.5746,
      "step": 594200
    },
    {
      "epoch": 6.2910105282102045,
      "grad_norm": 1.0902940034866333,
      "learning_rate": 0.0001820840945618373,
      "loss": 0.5555,
      "step": 594250
    },
    {
      "epoch": 6.291539849990207,
      "grad_norm": 1.2590104341506958,
      "learning_rate": 0.00018203964062463052,
      "loss": 0.5659,
      "step": 594300
    },
    {
      "epoch": 6.292069171770211,
      "grad_norm": 1.2906521558761597,
      "learning_rate": 0.00018199518900756539,
      "loss": 0.5727,
      "step": 594350
    },
    {
      "epoch": 6.292598493550214,
      "grad_norm": 1.079674243927002,
      "learning_rate": 0.0001819507397121597,
      "loss": 0.5845,
      "step": 594400
    },
    {
      "epoch": 6.293127815330218,
      "grad_norm": 1.1975010633468628,
      "learning_rate": 0.00018190629273993065,
      "loss": 0.5807,
      "step": 594450
    },
    {
      "epoch": 6.293657137110221,
      "grad_norm": 1.2307907342910767,
      "learning_rate": 0.0001818618480923959,
      "loss": 0.5678,
      "step": 594500
    },
    {
      "epoch": 6.293657137110221,
      "eval_loss": 0.362129807472229,
      "eval_runtime": 46.8575,
      "eval_samples_per_second": 3583.846,
      "eval_steps_per_second": 447.997,
      "step": 594500
    },
    {
      "epoch": 6.294186458890224,
      "grad_norm": 1.225591778755188,
      "learning_rate": 0.00018181740577107258,
      "loss": 0.5632,
      "step": 594550
    },
    {
      "epoch": 6.294715780670227,
      "grad_norm": 1.1009615659713745,
      "learning_rate": 0.00018177296577747808,
      "loss": 0.5711,
      "step": 594600
    },
    {
      "epoch": 6.295245102450231,
      "grad_norm": 1.2944053411483765,
      "learning_rate": 0.00018172852811312951,
      "loss": 0.5843,
      "step": 594650
    },
    {
      "epoch": 6.295774424230234,
      "grad_norm": 1.2508537769317627,
      "learning_rate": 0.00018168409277954394,
      "loss": 0.5799,
      "step": 594700
    },
    {
      "epoch": 6.296303746010237,
      "grad_norm": 1.075041651725769,
      "learning_rate": 0.00018163965977823835,
      "loss": 0.5763,
      "step": 594750
    },
    {
      "epoch": 6.29683306779024,
      "grad_norm": 1.2315833568572998,
      "learning_rate": 0.0001815952291107298,
      "loss": 0.57,
      "step": 594800
    },
    {
      "epoch": 6.297362389570243,
      "grad_norm": 1.1243705749511719,
      "learning_rate": 0.00018155080077853492,
      "loss": 0.5664,
      "step": 594850
    },
    {
      "epoch": 6.297891711350247,
      "grad_norm": 1.2114003896713257,
      "learning_rate": 0.00018150637478317073,
      "loss": 0.5759,
      "step": 594900
    },
    {
      "epoch": 6.29842103313025,
      "grad_norm": 1.1591428518295288,
      "learning_rate": 0.00018146195112615367,
      "loss": 0.5771,
      "step": 594950
    },
    {
      "epoch": 6.298950354910254,
      "grad_norm": 1.2488102912902832,
      "learning_rate": 0.00018141752980900056,
      "loss": 0.5784,
      "step": 595000
    },
    {
      "epoch": 6.298950354910254,
      "eval_loss": 0.36359384655952454,
      "eval_runtime": 46.9774,
      "eval_samples_per_second": 3574.699,
      "eval_steps_per_second": 446.853,
      "step": 595000
    },
    {
      "epoch": 6.2994796766902565,
      "grad_norm": 1.1121290922164917,
      "learning_rate": 0.0001813731108332277,
      "loss": 0.5753,
      "step": 595050
    },
    {
      "epoch": 6.30000899847026,
      "grad_norm": 1.0306981801986694,
      "learning_rate": 0.00018132869420035182,
      "loss": 0.5668,
      "step": 595100
    },
    {
      "epoch": 6.300538320250263,
      "grad_norm": 1.133841872215271,
      "learning_rate": 0.00018128427991188903,
      "loss": 0.5778,
      "step": 595150
    },
    {
      "epoch": 6.301067642030267,
      "grad_norm": 1.2637734413146973,
      "learning_rate": 0.00018123986796935582,
      "loss": 0.5796,
      "step": 595200
    },
    {
      "epoch": 6.30159696381027,
      "grad_norm": 1.0730830430984497,
      "learning_rate": 0.0001811954583742682,
      "loss": 0.5685,
      "step": 595250
    },
    {
      "epoch": 6.3021262855902735,
      "grad_norm": 1.1879249811172485,
      "learning_rate": 0.00018115193925003528,
      "loss": 0.5636,
      "step": 595300
    },
    {
      "epoch": 6.302655607370276,
      "grad_norm": 1.2730385065078735,
      "learning_rate": 0.00018110753430736304,
      "loss": 0.5713,
      "step": 595350
    },
    {
      "epoch": 6.30318492915028,
      "grad_norm": 1.2740741968154907,
      "learning_rate": 0.00018106313171665418,
      "loss": 0.5788,
      "step": 595400
    },
    {
      "epoch": 6.303714250930283,
      "grad_norm": 1.2832437753677368,
      "learning_rate": 0.00018101873147942482,
      "loss": 0.5812,
      "step": 595450
    },
    {
      "epoch": 6.304243572710286,
      "grad_norm": 1.1645599603652954,
      "learning_rate": 0.0001809743335971906,
      "loss": 0.5727,
      "step": 595500
    },
    {
      "epoch": 6.304243572710286,
      "eval_loss": 0.36225634813308716,
      "eval_runtime": 46.7644,
      "eval_samples_per_second": 3590.982,
      "eval_steps_per_second": 448.889,
      "step": 595500
    },
    {
      "epoch": 6.30477289449029,
      "grad_norm": 1.2018681764602661,
      "learning_rate": 0.0001809299380714674,
      "loss": 0.5759,
      "step": 595550
    },
    {
      "epoch": 6.3053022162702925,
      "grad_norm": 1.1723250150680542,
      "learning_rate": 0.0001808855449037707,
      "loss": 0.5564,
      "step": 595600
    },
    {
      "epoch": 6.305831538050296,
      "grad_norm": 1.2450875043869019,
      "learning_rate": 0.00018084115409561623,
      "loss": 0.5656,
      "step": 595650
    },
    {
      "epoch": 6.306360859830299,
      "grad_norm": 1.1314911842346191,
      "learning_rate": 0.00018079676564851927,
      "loss": 0.5695,
      "step": 595700
    },
    {
      "epoch": 6.306890181610303,
      "grad_norm": 1.2016935348510742,
      "learning_rate": 0.00018075237956399548,
      "loss": 0.5777,
      "step": 595750
    },
    {
      "epoch": 6.307419503390306,
      "grad_norm": 1.2330710887908936,
      "learning_rate": 0.00018070799584355996,
      "loss": 0.5719,
      "step": 595800
    },
    {
      "epoch": 6.3079488251703095,
      "grad_norm": 1.1752774715423584,
      "learning_rate": 0.0001806636144887281,
      "loss": 0.5635,
      "step": 595850
    },
    {
      "epoch": 6.308478146950312,
      "grad_norm": 1.2218564748764038,
      "learning_rate": 0.000180619235501015,
      "loss": 0.5631,
      "step": 595900
    },
    {
      "epoch": 6.309007468730316,
      "grad_norm": 1.1274373531341553,
      "learning_rate": 0.00018057485888193578,
      "loss": 0.5693,
      "step": 595950
    },
    {
      "epoch": 6.309536790510319,
      "grad_norm": 1.2704641819000244,
      "learning_rate": 0.00018053048463300534,
      "loss": 0.5717,
      "step": 596000
    },
    {
      "epoch": 6.309536790510319,
      "eval_loss": 0.362856924533844,
      "eval_runtime": 46.7332,
      "eval_samples_per_second": 3593.376,
      "eval_steps_per_second": 449.188,
      "step": 596000
    },
    {
      "epoch": 6.310066112290323,
      "grad_norm": 1.1968798637390137,
      "learning_rate": 0.0001804861127557388,
      "loss": 0.5752,
      "step": 596050
    },
    {
      "epoch": 6.310595434070326,
      "grad_norm": 1.058368444442749,
      "learning_rate": 0.00018044174325165075,
      "loss": 0.5691,
      "step": 596100
    },
    {
      "epoch": 6.311124755850329,
      "grad_norm": 1.2481008768081665,
      "learning_rate": 0.0001803973761222562,
      "loss": 0.5651,
      "step": 596150
    },
    {
      "epoch": 6.311654077630332,
      "grad_norm": 1.1599260568618774,
      "learning_rate": 0.0001803530113690696,
      "loss": 0.572,
      "step": 596200
    },
    {
      "epoch": 6.312183399410335,
      "grad_norm": 1.181443691253662,
      "learning_rate": 0.00018030864899360575,
      "loss": 0.563,
      "step": 596250
    },
    {
      "epoch": 6.312712721190339,
      "grad_norm": 1.1507859230041504,
      "learning_rate": 0.00018026428899737895,
      "loss": 0.5686,
      "step": 596300
    },
    {
      "epoch": 6.313242042970342,
      "grad_norm": 1.2165577411651611,
      "learning_rate": 0.00018021993138190386,
      "loss": 0.5721,
      "step": 596350
    },
    {
      "epoch": 6.3137713647503455,
      "grad_norm": 1.215955376625061,
      "learning_rate": 0.00018017557614869462,
      "loss": 0.5734,
      "step": 596400
    },
    {
      "epoch": 6.314300686530348,
      "grad_norm": 1.090444564819336,
      "learning_rate": 0.00018013122329926568,
      "loss": 0.5728,
      "step": 596450
    },
    {
      "epoch": 6.314830008310352,
      "grad_norm": 1.1154794692993164,
      "learning_rate": 0.00018008687283513109,
      "loss": 0.5599,
      "step": 596500
    },
    {
      "epoch": 6.314830008310352,
      "eval_loss": 0.36172783374786377,
      "eval_runtime": 46.8422,
      "eval_samples_per_second": 3585.012,
      "eval_steps_per_second": 448.142,
      "step": 596500
    },
    {
      "epoch": 6.315359330090355,
      "grad_norm": 1.2415050268173218,
      "learning_rate": 0.0001800425247578051,
      "loss": 0.5771,
      "step": 596550
    },
    {
      "epoch": 6.315888651870359,
      "grad_norm": 1.1364549398422241,
      "learning_rate": 0.00017999817906880157,
      "loss": 0.5869,
      "step": 596600
    },
    {
      "epoch": 6.316417973650362,
      "grad_norm": 1.1201130151748657,
      "learning_rate": 0.0001799538357696346,
      "loss": 0.5661,
      "step": 596650
    },
    {
      "epoch": 6.316947295430365,
      "grad_norm": 1.1639271974563599,
      "learning_rate": 0.00017990949486181796,
      "loss": 0.573,
      "step": 596700
    },
    {
      "epoch": 6.317476617210368,
      "grad_norm": 1.2877228260040283,
      "learning_rate": 0.00017986515634686547,
      "loss": 0.5618,
      "step": 596750
    },
    {
      "epoch": 6.318005938990372,
      "grad_norm": 1.158352017402649,
      "learning_rate": 0.00017982082022629083,
      "loss": 0.5684,
      "step": 596800
    },
    {
      "epoch": 6.318535260770375,
      "grad_norm": 1.157138705253601,
      "learning_rate": 0.00017977648650160762,
      "loss": 0.5569,
      "step": 596850
    },
    {
      "epoch": 6.319064582550379,
      "grad_norm": 1.2801456451416016,
      "learning_rate": 0.00017973215517432935,
      "loss": 0.5602,
      "step": 596900
    },
    {
      "epoch": 6.3195939043303815,
      "grad_norm": 1.1677390336990356,
      "learning_rate": 0.0001796878262459697,
      "loss": 0.5701,
      "step": 596950
    },
    {
      "epoch": 6.320123226110384,
      "grad_norm": 1.3103322982788086,
      "learning_rate": 0.00017964349971804171,
      "loss": 0.5647,
      "step": 597000
    },
    {
      "epoch": 6.320123226110384,
      "eval_loss": 0.36224305629730225,
      "eval_runtime": 46.7557,
      "eval_samples_per_second": 3591.645,
      "eval_steps_per_second": 448.972,
      "step": 597000
    },
    {
      "epoch": 6.320652547890388,
      "grad_norm": 1.1168047189712524,
      "learning_rate": 0.00017959917559205897,
      "loss": 0.5687,
      "step": 597050
    },
    {
      "epoch": 6.321181869670391,
      "grad_norm": 1.2597594261169434,
      "learning_rate": 0.00017955485386953444,
      "loss": 0.5659,
      "step": 597100
    },
    {
      "epoch": 6.321711191450395,
      "grad_norm": 1.11506187915802,
      "learning_rate": 0.00017951053455198148,
      "loss": 0.5695,
      "step": 597150
    },
    {
      "epoch": 6.322240513230398,
      "grad_norm": 1.225479006767273,
      "learning_rate": 0.0001794662176409129,
      "loss": 0.5736,
      "step": 597200
    },
    {
      "epoch": 6.322769835010401,
      "grad_norm": 1.2804219722747803,
      "learning_rate": 0.0001794219031378419,
      "loss": 0.574,
      "step": 597250
    },
    {
      "epoch": 6.323299156790404,
      "grad_norm": 1.1593559980392456,
      "learning_rate": 0.00017937759104428113,
      "loss": 0.5734,
      "step": 597300
    },
    {
      "epoch": 6.323828478570408,
      "grad_norm": 1.2507820129394531,
      "learning_rate": 0.00017933416753175647,
      "loss": 0.5774,
      "step": 597350
    },
    {
      "epoch": 6.324357800350411,
      "grad_norm": 1.372165322303772,
      "learning_rate": 0.0001792898602134893,
      "loss": 0.5732,
      "step": 597400
    },
    {
      "epoch": 6.324887122130415,
      "grad_norm": 1.1408841609954834,
      "learning_rate": 0.00017924555530924018,
      "loss": 0.5799,
      "step": 597450
    },
    {
      "epoch": 6.3254164439104175,
      "grad_norm": 1.1848623752593994,
      "learning_rate": 0.000179201252820522,
      "loss": 0.5695,
      "step": 597500
    },
    {
      "epoch": 6.3254164439104175,
      "eval_loss": 0.36324942111968994,
      "eval_runtime": 46.8072,
      "eval_samples_per_second": 3587.696,
      "eval_steps_per_second": 448.478,
      "step": 597500
    },
    {
      "epoch": 6.325945765690421,
      "grad_norm": 1.1913297176361084,
      "learning_rate": 0.00017915695274884702,
      "loss": 0.5803,
      "step": 597550
    },
    {
      "epoch": 6.326475087470424,
      "grad_norm": 1.3102898597717285,
      "learning_rate": 0.00017911265509572776,
      "loss": 0.5765,
      "step": 597600
    },
    {
      "epoch": 6.327004409250428,
      "grad_norm": 1.1506434679031372,
      "learning_rate": 0.0001790683598626764,
      "loss": 0.5729,
      "step": 597650
    },
    {
      "epoch": 6.327533731030431,
      "grad_norm": 1.2572671175003052,
      "learning_rate": 0.00017902406705120529,
      "loss": 0.5613,
      "step": 597700
    },
    {
      "epoch": 6.328063052810434,
      "grad_norm": 1.1702011823654175,
      "learning_rate": 0.00017897977666282637,
      "loss": 0.568,
      "step": 597750
    },
    {
      "epoch": 6.328592374590437,
      "grad_norm": 1.0952266454696655,
      "learning_rate": 0.00017893548869905192,
      "loss": 0.5655,
      "step": 597800
    },
    {
      "epoch": 6.32912169637044,
      "grad_norm": 1.0906236171722412,
      "learning_rate": 0.0001788912031613938,
      "loss": 0.5781,
      "step": 597850
    },
    {
      "epoch": 6.329651018150444,
      "grad_norm": 1.2166680097579956,
      "learning_rate": 0.0001788469200513639,
      "loss": 0.5595,
      "step": 597900
    },
    {
      "epoch": 6.330180339930447,
      "grad_norm": 1.0699244737625122,
      "learning_rate": 0.00017880263937047409,
      "loss": 0.563,
      "step": 597950
    },
    {
      "epoch": 6.330709661710451,
      "grad_norm": 1.2070727348327637,
      "learning_rate": 0.0001787583611202361,
      "loss": 0.5822,
      "step": 598000
    },
    {
      "epoch": 6.330709661710451,
      "eval_loss": 0.3623887300491333,
      "eval_runtime": 46.8792,
      "eval_samples_per_second": 3582.183,
      "eval_steps_per_second": 447.789,
      "step": 598000
    },
    {
      "epoch": 6.331238983490453,
      "grad_norm": 1.31487238407135,
      "learning_rate": 0.0001787140853021614,
      "loss": 0.5631,
      "step": 598050
    },
    {
      "epoch": 6.331768305270457,
      "grad_norm": 1.2700765132904053,
      "learning_rate": 0.00017866981191776182,
      "loss": 0.568,
      "step": 598100
    },
    {
      "epoch": 6.33229762705046,
      "grad_norm": 1.2345696687698364,
      "learning_rate": 0.0001786255409685486,
      "loss": 0.5751,
      "step": 598150
    },
    {
      "epoch": 6.332826948830464,
      "grad_norm": 1.2731834650039673,
      "learning_rate": 0.00017858127245603335,
      "loss": 0.5801,
      "step": 598200
    },
    {
      "epoch": 6.333356270610467,
      "grad_norm": 1.1900883913040161,
      "learning_rate": 0.00017853700638172714,
      "loss": 0.5674,
      "step": 598250
    },
    {
      "epoch": 6.33388559239047,
      "grad_norm": 1.306626796722412,
      "learning_rate": 0.00017849274274714147,
      "loss": 0.5676,
      "step": 598300
    },
    {
      "epoch": 6.334414914170473,
      "grad_norm": 1.2438246011734009,
      "learning_rate": 0.0001784484815537872,
      "loss": 0.5677,
      "step": 598350
    },
    {
      "epoch": 6.334944235950477,
      "grad_norm": 1.1977994441986084,
      "learning_rate": 0.00017840422280317563,
      "loss": 0.573,
      "step": 598400
    },
    {
      "epoch": 6.33547355773048,
      "grad_norm": 1.0822398662567139,
      "learning_rate": 0.00017835996649681756,
      "loss": 0.5662,
      "step": 598450
    },
    {
      "epoch": 6.336002879510483,
      "grad_norm": 1.1901755332946777,
      "learning_rate": 0.00017831571263622406,
      "loss": 0.5715,
      "step": 598500
    },
    {
      "epoch": 6.336002879510483,
      "eval_loss": 0.3618406653404236,
      "eval_runtime": 46.8553,
      "eval_samples_per_second": 3584.013,
      "eval_steps_per_second": 448.018,
      "step": 598500
    },
    {
      "epoch": 6.3365322012904866,
      "grad_norm": 1.20464026927948,
      "learning_rate": 0.0001782714612229057,
      "loss": 0.5703,
      "step": 598550
    },
    {
      "epoch": 6.337061523070489,
      "grad_norm": 1.1630220413208008,
      "learning_rate": 0.00017822721225837352,
      "loss": 0.5637,
      "step": 598600
    },
    {
      "epoch": 6.337590844850493,
      "grad_norm": 1.196192741394043,
      "learning_rate": 0.00017818296574413783,
      "loss": 0.5742,
      "step": 598650
    },
    {
      "epoch": 6.338120166630496,
      "grad_norm": 1.2492396831512451,
      "learning_rate": 0.00017813872168170942,
      "loss": 0.5765,
      "step": 598700
    },
    {
      "epoch": 6.3386494884105,
      "grad_norm": 1.1818453073501587,
      "learning_rate": 0.0001780944800725987,
      "loss": 0.563,
      "step": 598750
    },
    {
      "epoch": 6.339178810190503,
      "grad_norm": 1.2038679122924805,
      "learning_rate": 0.00017805024091831608,
      "loss": 0.5676,
      "step": 598800
    },
    {
      "epoch": 6.339708131970506,
      "grad_norm": 1.162559986114502,
      "learning_rate": 0.0001780060042203718,
      "loss": 0.5811,
      "step": 598850
    },
    {
      "epoch": 6.340237453750509,
      "grad_norm": 1.3111087083816528,
      "learning_rate": 0.00017796176998027615,
      "loss": 0.5644,
      "step": 598900
    },
    {
      "epoch": 6.340766775530513,
      "grad_norm": 1.2722281217575073,
      "learning_rate": 0.0001779175381995392,
      "loss": 0.5629,
      "step": 598950
    },
    {
      "epoch": 6.341296097310516,
      "grad_norm": 1.1531833410263062,
      "learning_rate": 0.00017787330887967119,
      "loss": 0.5787,
      "step": 599000
    },
    {
      "epoch": 6.341296097310516,
      "eval_loss": 0.36141064763069153,
      "eval_runtime": 46.7578,
      "eval_samples_per_second": 3591.483,
      "eval_steps_per_second": 448.951,
      "step": 599000
    },
    {
      "epoch": 6.34182541909052,
      "grad_norm": 1.14533531665802,
      "learning_rate": 0.00017782908202218183,
      "loss": 0.5613,
      "step": 599050
    },
    {
      "epoch": 6.3423547408705225,
      "grad_norm": 1.1794670820236206,
      "learning_rate": 0.00017778485762858127,
      "loss": 0.5691,
      "step": 599100
    },
    {
      "epoch": 6.342884062650526,
      "grad_norm": 1.2838751077651978,
      "learning_rate": 0.00017774063570037907,
      "loss": 0.5674,
      "step": 599150
    },
    {
      "epoch": 6.343413384430529,
      "grad_norm": 1.1463336944580078,
      "learning_rate": 0.00017769641623908517,
      "loss": 0.5609,
      "step": 599200
    },
    {
      "epoch": 6.343942706210532,
      "grad_norm": 1.1117268800735474,
      "learning_rate": 0.000177652199246209,
      "loss": 0.56,
      "step": 599250
    },
    {
      "epoch": 6.344472027990536,
      "grad_norm": 1.151179552078247,
      "learning_rate": 0.00017760798472326035,
      "loss": 0.5702,
      "step": 599300
    },
    {
      "epoch": 6.345001349770539,
      "grad_norm": 1.2353028059005737,
      "learning_rate": 0.00017756465688854877,
      "loss": 0.5615,
      "step": 599350
    },
    {
      "epoch": 6.345530671550542,
      "grad_norm": 1.2524263858795166,
      "learning_rate": 0.0001775204472605094,
      "loss": 0.5698,
      "step": 599400
    },
    {
      "epoch": 6.346059993330545,
      "grad_norm": 1.2076375484466553,
      "learning_rate": 0.0001774762401068954,
      "loss": 0.5714,
      "step": 599450
    },
    {
      "epoch": 6.346589315110549,
      "grad_norm": 1.3300480842590332,
      "learning_rate": 0.00017743203542921595,
      "loss": 0.5726,
      "step": 599500
    },
    {
      "epoch": 6.346589315110549,
      "eval_loss": 0.3610401153564453,
      "eval_runtime": 46.7973,
      "eval_samples_per_second": 3588.458,
      "eval_steps_per_second": 448.573,
      "step": 599500
    },
    {
      "epoch": 6.347118636890552,
      "grad_norm": 1.1738486289978027,
      "learning_rate": 0.00017738783322898016,
      "loss": 0.5708,
      "step": 599550
    },
    {
      "epoch": 6.347647958670556,
      "grad_norm": 1.1571502685546875,
      "learning_rate": 0.00017734363350769723,
      "loss": 0.5662,
      "step": 599600
    },
    {
      "epoch": 6.3481772804505585,
      "grad_norm": 1.047913670539856,
      "learning_rate": 0.00017729943626687583,
      "loss": 0.5683,
      "step": 599650
    },
    {
      "epoch": 6.348706602230562,
      "grad_norm": 1.210084080696106,
      "learning_rate": 0.0001772552415080252,
      "loss": 0.5828,
      "step": 599700
    },
    {
      "epoch": 6.349235924010565,
      "grad_norm": 1.2475249767303467,
      "learning_rate": 0.00017721193305381342,
      "loss": 0.5637,
      "step": 599750
    },
    {
      "epoch": 6.349765245790569,
      "grad_norm": 1.3535701036453247,
      "learning_rate": 0.00017716774321371558,
      "loss": 0.5766,
      "step": 599800
    },
    {
      "epoch": 6.350294567570572,
      "grad_norm": 1.0749863386154175,
      "learning_rate": 0.00017712355586008434,
      "loss": 0.574,
      "step": 599850
    },
    {
      "epoch": 6.3508238893505755,
      "grad_norm": 1.2480357885360718,
      "learning_rate": 0.00017707937099442812,
      "loss": 0.5644,
      "step": 599900
    },
    {
      "epoch": 6.351353211130578,
      "grad_norm": 1.0048458576202393,
      "learning_rate": 0.0001770351886182555,
      "loss": 0.5732,
      "step": 599950
    },
    {
      "epoch": 6.351882532910581,
      "grad_norm": 1.1958972215652466,
      "learning_rate": 0.0001769910087330747,
      "loss": 0.5582,
      "step": 600000
    },
    {
      "epoch": 6.351882532910581,
      "eval_loss": 0.3602256774902344,
      "eval_runtime": 46.9188,
      "eval_samples_per_second": 3579.163,
      "eval_steps_per_second": 447.411,
      "step": 600000
    },
    {
      "epoch": 6.352411854690585,
      "grad_norm": 1.1750506162643433,
      "learning_rate": 0.00017694683134039419,
      "loss": 0.5747,
      "step": 600050
    },
    {
      "epoch": 6.352941176470588,
      "grad_norm": 1.2436548471450806,
      "learning_rate": 0.00017690265644172194,
      "loss": 0.5669,
      "step": 600100
    },
    {
      "epoch": 6.353470498250592,
      "grad_norm": 1.180168867111206,
      "learning_rate": 0.00017685848403856632,
      "loss": 0.566,
      "step": 600150
    },
    {
      "epoch": 6.3539998200305945,
      "grad_norm": 1.2203110456466675,
      "learning_rate": 0.00017681431413243512,
      "loss": 0.5642,
      "step": 600200
    },
    {
      "epoch": 6.354529141810598,
      "grad_norm": 1.2018532752990723,
      "learning_rate": 0.0001767701467248365,
      "loss": 0.579,
      "step": 600250
    },
    {
      "epoch": 6.355058463590601,
      "grad_norm": 1.2399500608444214,
      "learning_rate": 0.0001767259818172781,
      "loss": 0.566,
      "step": 600300
    },
    {
      "epoch": 6.355587785370605,
      "grad_norm": 1.2382019758224487,
      "learning_rate": 0.00017668181941126794,
      "loss": 0.5715,
      "step": 600350
    },
    {
      "epoch": 6.356117107150608,
      "grad_norm": 1.161842942237854,
      "learning_rate": 0.00017663765950831346,
      "loss": 0.5603,
      "step": 600400
    },
    {
      "epoch": 6.3566464289306115,
      "grad_norm": 1.2344942092895508,
      "learning_rate": 0.00017659350210992247,
      "loss": 0.5694,
      "step": 600450
    },
    {
      "epoch": 6.357175750710614,
      "grad_norm": 1.2117466926574707,
      "learning_rate": 0.0001765493472176023,
      "loss": 0.5734,
      "step": 600500
    },
    {
      "epoch": 6.357175750710614,
      "eval_loss": 0.36150336265563965,
      "eval_runtime": 46.7788,
      "eval_samples_per_second": 3589.877,
      "eval_steps_per_second": 448.751,
      "step": 600500
    },
    {
      "epoch": 6.357705072490618,
      "grad_norm": 1.2272560596466064,
      "learning_rate": 0.00017650519483286054,
      "loss": 0.5656,
      "step": 600550
    },
    {
      "epoch": 6.358234394270621,
      "grad_norm": 1.2282755374908447,
      "learning_rate": 0.00017646104495720445,
      "loss": 0.5793,
      "step": 600600
    },
    {
      "epoch": 6.358763716050625,
      "grad_norm": 1.0782872438430786,
      "learning_rate": 0.00017641689759214133,
      "loss": 0.5749,
      "step": 600650
    },
    {
      "epoch": 6.359293037830628,
      "grad_norm": 1.053991436958313,
      "learning_rate": 0.0001763727527391783,
      "loss": 0.5692,
      "step": 600700
    },
    {
      "epoch": 6.3598223596106305,
      "grad_norm": 1.1756561994552612,
      "learning_rate": 0.00017632861039982258,
      "loss": 0.5677,
      "step": 600750
    },
    {
      "epoch": 6.360351681390634,
      "grad_norm": 1.1511811017990112,
      "learning_rate": 0.00017628447057558097,
      "loss": 0.5674,
      "step": 600800
    },
    {
      "epoch": 6.360881003170637,
      "grad_norm": 1.1287015676498413,
      "learning_rate": 0.00017624033326796063,
      "loss": 0.5632,
      "step": 600850
    },
    {
      "epoch": 6.361410324950641,
      "grad_norm": 1.2883572578430176,
      "learning_rate": 0.00017619619847846814,
      "loss": 0.5746,
      "step": 600900
    },
    {
      "epoch": 6.361939646730644,
      "grad_norm": 1.213542103767395,
      "learning_rate": 0.00017615206620861046,
      "loss": 0.576,
      "step": 600950
    },
    {
      "epoch": 6.3624689685106475,
      "grad_norm": 1.1284425258636475,
      "learning_rate": 0.00017610793645989409,
      "loss": 0.5669,
      "step": 601000
    },
    {
      "epoch": 6.3624689685106475,
      "eval_loss": 0.36067482829093933,
      "eval_runtime": 46.8744,
      "eval_samples_per_second": 3582.552,
      "eval_steps_per_second": 447.835,
      "step": 601000
    },
    {
      "epoch": 6.36299829029065,
      "grad_norm": 1.1786328554153442,
      "learning_rate": 0.00017606380923382577,
      "loss": 0.5691,
      "step": 601050
    },
    {
      "epoch": 6.363527612070654,
      "grad_norm": 1.214572548866272,
      "learning_rate": 0.00017601968453191176,
      "loss": 0.5752,
      "step": 601100
    },
    {
      "epoch": 6.364056933850657,
      "grad_norm": 1.1989244222640991,
      "learning_rate": 0.00017597556235565868,
      "loss": 0.5727,
      "step": 601150
    },
    {
      "epoch": 6.364586255630661,
      "grad_norm": 1.0534297227859497,
      "learning_rate": 0.00017593144270657265,
      "loss": 0.5676,
      "step": 601200
    },
    {
      "epoch": 6.365115577410664,
      "grad_norm": 1.1018798351287842,
      "learning_rate": 0.00017588732558616014,
      "loss": 0.5751,
      "step": 601250
    },
    {
      "epoch": 6.365644899190667,
      "grad_norm": 1.174543857574463,
      "learning_rate": 0.00017584321099592705,
      "loss": 0.5719,
      "step": 601300
    },
    {
      "epoch": 6.36617422097067,
      "grad_norm": 1.2561546564102173,
      "learning_rate": 0.00017579909893737956,
      "loss": 0.5651,
      "step": 601350
    },
    {
      "epoch": 6.366703542750674,
      "grad_norm": 1.348720908164978,
      "learning_rate": 0.0001757549894120236,
      "loss": 0.5692,
      "step": 601400
    },
    {
      "epoch": 6.367232864530677,
      "grad_norm": 1.1960387229919434,
      "learning_rate": 0.00017571088242136513,
      "loss": 0.5701,
      "step": 601450
    },
    {
      "epoch": 6.36776218631068,
      "grad_norm": 1.1621040105819702,
      "learning_rate": 0.00017566677796690988,
      "loss": 0.5673,
      "step": 601500
    },
    {
      "epoch": 6.36776218631068,
      "eval_loss": 0.36019060015678406,
      "eval_runtime": 46.6971,
      "eval_samples_per_second": 3596.157,
      "eval_steps_per_second": 449.536,
      "step": 601500
    },
    {
      "epoch": 6.3682915080906835,
      "grad_norm": 1.1524739265441895,
      "learning_rate": 0.00017562267605016356,
      "loss": 0.5702,
      "step": 601550
    },
    {
      "epoch": 6.368820829870686,
      "grad_norm": 1.1223037242889404,
      "learning_rate": 0.00017557857667263176,
      "loss": 0.5588,
      "step": 601600
    },
    {
      "epoch": 6.36935015165069,
      "grad_norm": 1.3224881887435913,
      "learning_rate": 0.00017553447983582014,
      "loss": 0.5631,
      "step": 601650
    },
    {
      "epoch": 6.369879473430693,
      "grad_norm": 1.2024604082107544,
      "learning_rate": 0.00017549038554123396,
      "loss": 0.5679,
      "step": 601700
    },
    {
      "epoch": 6.370408795210697,
      "grad_norm": 1.2762649059295654,
      "learning_rate": 0.00017544629379037883,
      "loss": 0.5727,
      "step": 601750
    },
    {
      "epoch": 6.3709381169907,
      "grad_norm": 1.2070084810256958,
      "learning_rate": 0.00017540220458475976,
      "loss": 0.5652,
      "step": 601800
    },
    {
      "epoch": 6.371467438770703,
      "grad_norm": 1.162909746170044,
      "learning_rate": 0.0001753581179258822,
      "loss": 0.5647,
      "step": 601850
    },
    {
      "epoch": 6.371996760550706,
      "grad_norm": 1.0800762176513672,
      "learning_rate": 0.00017531403381525096,
      "loss": 0.5707,
      "step": 601900
    },
    {
      "epoch": 6.37252608233071,
      "grad_norm": 1.277079701423645,
      "learning_rate": 0.00017526995225437136,
      "loss": 0.575,
      "step": 601950
    },
    {
      "epoch": 6.373055404110713,
      "grad_norm": 1.2088779211044312,
      "learning_rate": 0.0001752258732447481,
      "loss": 0.5701,
      "step": 602000
    },
    {
      "epoch": 6.373055404110713,
      "eval_loss": 0.3602578043937683,
      "eval_runtime": 46.7991,
      "eval_samples_per_second": 3588.317,
      "eval_steps_per_second": 448.556,
      "step": 602000
    },
    {
      "epoch": 6.373584725890717,
      "grad_norm": 1.290932297706604,
      "learning_rate": 0.00017518179678788616,
      "loss": 0.5718,
      "step": 602050
    },
    {
      "epoch": 6.374114047670719,
      "grad_norm": 1.2406648397445679,
      "learning_rate": 0.00017513772288529016,
      "loss": 0.5637,
      "step": 602100
    },
    {
      "epoch": 6.374643369450723,
      "grad_norm": 1.1709895133972168,
      "learning_rate": 0.00017509365153846497,
      "loss": 0.5744,
      "step": 602150
    },
    {
      "epoch": 6.375172691230726,
      "grad_norm": 1.208144187927246,
      "learning_rate": 0.0001750495827489149,
      "loss": 0.5691,
      "step": 602200
    },
    {
      "epoch": 6.375702013010729,
      "grad_norm": 1.2610235214233398,
      "learning_rate": 0.00017500551651814463,
      "loss": 0.5633,
      "step": 602250
    },
    {
      "epoch": 6.376231334790733,
      "grad_norm": 1.1199467182159424,
      "learning_rate": 0.00017496145284765858,
      "loss": 0.5635,
      "step": 602300
    },
    {
      "epoch": 6.3767606565707355,
      "grad_norm": 1.2111150026321411,
      "learning_rate": 0.00017491739173896098,
      "loss": 0.5702,
      "step": 602350
    },
    {
      "epoch": 6.377289978350739,
      "grad_norm": 1.2266136407852173,
      "learning_rate": 0.00017487333319355603,
      "loss": 0.5714,
      "step": 602400
    },
    {
      "epoch": 6.377819300130742,
      "grad_norm": 1.1190235614776611,
      "learning_rate": 0.00017482927721294806,
      "loss": 0.5692,
      "step": 602450
    },
    {
      "epoch": 6.378348621910746,
      "grad_norm": 1.1070642471313477,
      "learning_rate": 0.00017478522379864086,
      "loss": 0.5662,
      "step": 602500
    },
    {
      "epoch": 6.378348621910746,
      "eval_loss": 0.3593617081642151,
      "eval_runtime": 46.8041,
      "eval_samples_per_second": 3587.936,
      "eval_steps_per_second": 448.508,
      "step": 602500
    },
    {
      "epoch": 6.378877943690749,
      "grad_norm": 1.1082834005355835,
      "learning_rate": 0.00017474117295213865,
      "loss": 0.5727,
      "step": 602550
    },
    {
      "epoch": 6.3794072654707525,
      "grad_norm": 1.1786631345748901,
      "learning_rate": 0.0001746971246749451,
      "loss": 0.5692,
      "step": 602600
    },
    {
      "epoch": 6.379936587250755,
      "grad_norm": 1.1744441986083984,
      "learning_rate": 0.0001746530789685642,
      "loss": 0.5555,
      "step": 602650
    },
    {
      "epoch": 6.380465909030759,
      "grad_norm": 1.2817212343215942,
      "learning_rate": 0.00017460903583449945,
      "loss": 0.5716,
      "step": 602700
    },
    {
      "epoch": 6.380995230810762,
      "grad_norm": 1.2818150520324707,
      "learning_rate": 0.00017456499527425469,
      "loss": 0.5612,
      "step": 602750
    },
    {
      "epoch": 6.381524552590766,
      "grad_norm": 1.2099905014038086,
      "learning_rate": 0.0001745209572893332,
      "loss": 0.5705,
      "step": 602800
    },
    {
      "epoch": 6.382053874370769,
      "grad_norm": 1.225602149963379,
      "learning_rate": 0.00017447692188123865,
      "loss": 0.57,
      "step": 602850
    },
    {
      "epoch": 6.382583196150772,
      "grad_norm": 1.2204095125198364,
      "learning_rate": 0.00017443288905147418,
      "loss": 0.5658,
      "step": 602900
    },
    {
      "epoch": 6.383112517930775,
      "grad_norm": 1.149854302406311,
      "learning_rate": 0.00017438885880154326,
      "loss": 0.565,
      "step": 602950
    },
    {
      "epoch": 6.383641839710778,
      "grad_norm": 1.2136955261230469,
      "learning_rate": 0.00017434483113294892,
      "loss": 0.5632,
      "step": 603000
    },
    {
      "epoch": 6.383641839710778,
      "eval_loss": 0.3601095378398895,
      "eval_runtime": 46.8096,
      "eval_samples_per_second": 3587.511,
      "eval_steps_per_second": 448.455,
      "step": 603000
    },
    {
      "epoch": 6.384171161490782,
      "grad_norm": 1.2463527917861938,
      "learning_rate": 0.00017430080604719428,
      "loss": 0.5662,
      "step": 603050
    },
    {
      "epoch": 6.384700483270785,
      "grad_norm": 1.277424931526184,
      "learning_rate": 0.0001742567835457824,
      "loss": 0.5664,
      "step": 603100
    },
    {
      "epoch": 6.3852298050507885,
      "grad_norm": 1.3192379474639893,
      "learning_rate": 0.00017421276363021614,
      "loss": 0.5644,
      "step": 603150
    },
    {
      "epoch": 6.385759126830791,
      "grad_norm": 1.157509684562683,
      "learning_rate": 0.0001741687463019983,
      "loss": 0.5544,
      "step": 603200
    },
    {
      "epoch": 6.386288448610795,
      "grad_norm": 1.3053077459335327,
      "learning_rate": 0.00017412473156263176,
      "loss": 0.5723,
      "step": 603250
    },
    {
      "epoch": 6.386817770390798,
      "grad_norm": 1.2148640155792236,
      "learning_rate": 0.00017408071941361891,
      "loss": 0.5713,
      "step": 603300
    },
    {
      "epoch": 6.387347092170802,
      "grad_norm": 1.2503756284713745,
      "learning_rate": 0.00017403670985646262,
      "loss": 0.5658,
      "step": 603350
    },
    {
      "epoch": 6.387876413950805,
      "grad_norm": 1.1503382921218872,
      "learning_rate": 0.00017399270289266506,
      "loss": 0.5689,
      "step": 603400
    },
    {
      "epoch": 6.388405735730808,
      "grad_norm": 1.3042786121368408,
      "learning_rate": 0.00017394869852372884,
      "loss": 0.5688,
      "step": 603450
    },
    {
      "epoch": 6.388935057510811,
      "grad_norm": 1.1282236576080322,
      "learning_rate": 0.00017390469675115605,
      "loss": 0.5583,
      "step": 603500
    },
    {
      "epoch": 6.388935057510811,
      "eval_loss": 0.3583598732948303,
      "eval_runtime": 47.3691,
      "eval_samples_per_second": 3545.138,
      "eval_steps_per_second": 443.158,
      "step": 603500
    },
    {
      "epoch": 6.389464379290815,
      "grad_norm": 1.2031522989273071,
      "learning_rate": 0.00017386069757644915,
      "loss": 0.5745,
      "step": 603550
    },
    {
      "epoch": 6.389993701070818,
      "grad_norm": 1.180759310722351,
      "learning_rate": 0.00017381670100111,
      "loss": 0.5576,
      "step": 603600
    },
    {
      "epoch": 6.390523022850822,
      "grad_norm": 1.2146453857421875,
      "learning_rate": 0.00017377270702664084,
      "loss": 0.5694,
      "step": 603650
    },
    {
      "epoch": 6.3910523446308245,
      "grad_norm": 1.1930618286132812,
      "learning_rate": 0.00017372871565454339,
      "loss": 0.5629,
      "step": 603700
    },
    {
      "epoch": 6.391581666410827,
      "grad_norm": 1.2381881475448608,
      "learning_rate": 0.00017368560663615646,
      "loss": 0.5708,
      "step": 603750
    },
    {
      "epoch": 6.392110988190831,
      "grad_norm": 1.2812687158584595,
      "learning_rate": 0.0001736416204211859,
      "loss": 0.5596,
      "step": 603800
    },
    {
      "epoch": 6.392640309970834,
      "grad_norm": 1.221320629119873,
      "learning_rate": 0.0001735976368130625,
      "loss": 0.5522,
      "step": 603850
    },
    {
      "epoch": 6.393169631750838,
      "grad_norm": 1.0832809209823608,
      "learning_rate": 0.0001735536558132877,
      "loss": 0.5617,
      "step": 603900
    },
    {
      "epoch": 6.393698953530841,
      "grad_norm": 1.175334095954895,
      "learning_rate": 0.0001735096774233631,
      "loss": 0.5701,
      "step": 603950
    },
    {
      "epoch": 6.394228275310844,
      "grad_norm": 1.1607530117034912,
      "learning_rate": 0.00017346570164479,
      "loss": 0.5525,
      "step": 604000
    },
    {
      "epoch": 6.394228275310844,
      "eval_loss": 0.35909801721572876,
      "eval_runtime": 47.3626,
      "eval_samples_per_second": 3545.623,
      "eval_steps_per_second": 443.219,
      "step": 604000
    },
    {
      "epoch": 6.394757597090847,
      "grad_norm": 1.2557827234268188,
      "learning_rate": 0.0001734217284790699,
      "loss": 0.5739,
      "step": 604050
    },
    {
      "epoch": 6.395286918870851,
      "grad_norm": 1.2744250297546387,
      "learning_rate": 0.00017337775792770378,
      "loss": 0.5632,
      "step": 604100
    },
    {
      "epoch": 6.395816240650854,
      "grad_norm": 1.2849019765853882,
      "learning_rate": 0.00017333378999219296,
      "loss": 0.5678,
      "step": 604150
    },
    {
      "epoch": 6.396345562430858,
      "grad_norm": 1.148853063583374,
      "learning_rate": 0.0001732898246740384,
      "loss": 0.564,
      "step": 604200
    },
    {
      "epoch": 6.3968748842108605,
      "grad_norm": 1.1608164310455322,
      "learning_rate": 0.00017324586197474116,
      "loss": 0.5628,
      "step": 604250
    },
    {
      "epoch": 6.397404205990864,
      "grad_norm": 1.0766916275024414,
      "learning_rate": 0.00017320190189580194,
      "loss": 0.5725,
      "step": 604300
    },
    {
      "epoch": 6.397933527770867,
      "grad_norm": 1.2588105201721191,
      "learning_rate": 0.00017315794443872174,
      "loss": 0.5614,
      "step": 604350
    },
    {
      "epoch": 6.398462849550871,
      "grad_norm": 1.202154517173767,
      "learning_rate": 0.00017311398960500102,
      "loss": 0.5758,
      "step": 604400
    },
    {
      "epoch": 6.398992171330874,
      "grad_norm": 1.1040642261505127,
      "learning_rate": 0.00017307003739614057,
      "loss": 0.553,
      "step": 604450
    },
    {
      "epoch": 6.399521493110877,
      "grad_norm": 1.1604230403900146,
      "learning_rate": 0.00017302608781364083,
      "loss": 0.5651,
      "step": 604500
    },
    {
      "epoch": 6.399521493110877,
      "eval_loss": 0.35882121324539185,
      "eval_runtime": 47.7547,
      "eval_samples_per_second": 3516.514,
      "eval_steps_per_second": 439.58,
      "step": 604500
    },
    {
      "epoch": 6.40005081489088,
      "grad_norm": 1.1609262228012085,
      "learning_rate": 0.0001729821408590022,
      "loss": 0.5647,
      "step": 604550
    },
    {
      "epoch": 6.400580136670883,
      "grad_norm": 1.3401808738708496,
      "learning_rate": 0.000172938196533725,
      "loss": 0.5551,
      "step": 604600
    },
    {
      "epoch": 6.401109458450887,
      "grad_norm": 1.3029309511184692,
      "learning_rate": 0.00017289425483930958,
      "loss": 0.5786,
      "step": 604650
    },
    {
      "epoch": 6.40163878023089,
      "grad_norm": 1.328888177871704,
      "learning_rate": 0.00017285031577725596,
      "loss": 0.5652,
      "step": 604700
    },
    {
      "epoch": 6.402168102010894,
      "grad_norm": 1.2002204656600952,
      "learning_rate": 0.00017280637934906435,
      "loss": 0.5713,
      "step": 604750
    },
    {
      "epoch": 6.4026974237908965,
      "grad_norm": 1.1707537174224854,
      "learning_rate": 0.00017276244555623454,
      "loss": 0.5698,
      "step": 604800
    },
    {
      "epoch": 6.4032267455709,
      "grad_norm": 1.194137454032898,
      "learning_rate": 0.0001727185144002666,
      "loss": 0.5616,
      "step": 604850
    },
    {
      "epoch": 6.403756067350903,
      "grad_norm": 1.2346467971801758,
      "learning_rate": 0.00017267458588266017,
      "loss": 0.5651,
      "step": 604900
    },
    {
      "epoch": 6.404285389130907,
      "grad_norm": 1.3761786222457886,
      "learning_rate": 0.0001726306600049151,
      "loss": 0.571,
      "step": 604950
    },
    {
      "epoch": 6.40481471091091,
      "grad_norm": 1.169162392616272,
      "learning_rate": 0.0001725867367685308,
      "loss": 0.5605,
      "step": 605000
    },
    {
      "epoch": 6.40481471091091,
      "eval_loss": 0.3592146039009094,
      "eval_runtime": 48.024,
      "eval_samples_per_second": 3496.796,
      "eval_steps_per_second": 437.115,
      "step": 605000
    },
    {
      "epoch": 6.4053440326909135,
      "grad_norm": 1.037474274635315,
      "learning_rate": 0.00017254281617500706,
      "loss": 0.5656,
      "step": 605050
    },
    {
      "epoch": 6.405873354470916,
      "grad_norm": 1.1272755861282349,
      "learning_rate": 0.00017249889822584303,
      "loss": 0.5698,
      "step": 605100
    },
    {
      "epoch": 6.40640267625092,
      "grad_norm": 1.2084815502166748,
      "learning_rate": 0.0001724549829225383,
      "loss": 0.5641,
      "step": 605150
    },
    {
      "epoch": 6.406931998030923,
      "grad_norm": 1.2262523174285889,
      "learning_rate": 0.00017241107026659194,
      "loss": 0.5693,
      "step": 605200
    },
    {
      "epoch": 6.407461319810926,
      "grad_norm": 1.1448029279708862,
      "learning_rate": 0.00017236716025950322,
      "loss": 0.5724,
      "step": 605250
    },
    {
      "epoch": 6.40799064159093,
      "grad_norm": 1.2124124765396118,
      "learning_rate": 0.00017232325290277118,
      "loss": 0.5607,
      "step": 605300
    },
    {
      "epoch": 6.408519963370932,
      "grad_norm": 1.2206542491912842,
      "learning_rate": 0.00017227934819789482,
      "loss": 0.5713,
      "step": 605350
    },
    {
      "epoch": 6.409049285150936,
      "grad_norm": 1.289781093597412,
      "learning_rate": 0.00017223544614637296,
      "loss": 0.5541,
      "step": 605400
    },
    {
      "epoch": 6.409578606930939,
      "grad_norm": 1.2439262866973877,
      "learning_rate": 0.0001721915467497045,
      "loss": 0.5598,
      "step": 605450
    },
    {
      "epoch": 6.410107928710943,
      "grad_norm": 1.3731379508972168,
      "learning_rate": 0.00017214765000938802,
      "loss": 0.5656,
      "step": 605500
    },
    {
      "epoch": 6.410107928710943,
      "eval_loss": 0.3592076003551483,
      "eval_runtime": 47.8674,
      "eval_samples_per_second": 3508.236,
      "eval_steps_per_second": 438.545,
      "step": 605500
    },
    {
      "epoch": 6.410637250490946,
      "grad_norm": 1.1691423654556274,
      "learning_rate": 0.0001721037559269223,
      "loss": 0.5646,
      "step": 605550
    },
    {
      "epoch": 6.411166572270949,
      "grad_norm": 1.2832006216049194,
      "learning_rate": 0.00017205986450380571,
      "loss": 0.5713,
      "step": 605600
    },
    {
      "epoch": 6.411695894050952,
      "grad_norm": 1.2529654502868652,
      "learning_rate": 0.00017201597574153688,
      "loss": 0.5679,
      "step": 605650
    },
    {
      "epoch": 6.412225215830956,
      "grad_norm": 1.1828652620315552,
      "learning_rate": 0.00017197208964161387,
      "loss": 0.5554,
      "step": 605700
    },
    {
      "epoch": 6.412754537610959,
      "grad_norm": 1.291701078414917,
      "learning_rate": 0.00017192908384814148,
      "loss": 0.559,
      "step": 605750
    },
    {
      "epoch": 6.413283859390963,
      "grad_norm": 1.2149426937103271,
      "learning_rate": 0.00017188520302408367,
      "loss": 0.5599,
      "step": 605800
    },
    {
      "epoch": 6.4138131811709655,
      "grad_norm": 1.195651888847351,
      "learning_rate": 0.00017184132486683634,
      "loss": 0.5624,
      "step": 605850
    },
    {
      "epoch": 6.414342502950969,
      "grad_norm": 1.181008219718933,
      "learning_rate": 0.00017179744937789764,
      "loss": 0.5658,
      "step": 605900
    },
    {
      "epoch": 6.414871824730972,
      "grad_norm": 1.1751941442489624,
      "learning_rate": 0.00017175357655876522,
      "loss": 0.5572,
      "step": 605950
    },
    {
      "epoch": 6.415401146510975,
      "grad_norm": 1.2926350831985474,
      "learning_rate": 0.0001717097064109371,
      "loss": 0.5642,
      "step": 606000
    },
    {
      "epoch": 6.415401146510975,
      "eval_loss": 0.35888543725013733,
      "eval_runtime": 47.8754,
      "eval_samples_per_second": 3507.644,
      "eval_steps_per_second": 438.471,
      "step": 606000
    },
    {
      "epoch": 6.415930468290979,
      "grad_norm": 1.1283890008926392,
      "learning_rate": 0.0001716658389359108,
      "loss": 0.5633,
      "step": 606050
    },
    {
      "epoch": 6.416459790070982,
      "grad_norm": 1.2444024085998535,
      "learning_rate": 0.00017162197413518414,
      "loss": 0.5649,
      "step": 606100
    },
    {
      "epoch": 6.416989111850985,
      "grad_norm": 1.2456722259521484,
      "learning_rate": 0.00017157811201025443,
      "loss": 0.5638,
      "step": 606150
    },
    {
      "epoch": 6.417518433630988,
      "grad_norm": 1.2651931047439575,
      "learning_rate": 0.0001715342525626193,
      "loss": 0.5684,
      "step": 606200
    },
    {
      "epoch": 6.418047755410992,
      "grad_norm": 1.1405279636383057,
      "learning_rate": 0.0001714903957937759,
      "loss": 0.5625,
      "step": 606250
    },
    {
      "epoch": 6.418577077190995,
      "grad_norm": 1.2290589809417725,
      "learning_rate": 0.00017144654170522173,
      "loss": 0.5623,
      "step": 606300
    },
    {
      "epoch": 6.419106398970999,
      "grad_norm": 1.1923718452453613,
      "learning_rate": 0.00017140269029845368,
      "loss": 0.5551,
      "step": 606350
    },
    {
      "epoch": 6.4196357207510015,
      "grad_norm": 1.1638129949569702,
      "learning_rate": 0.00017135884157496912,
      "loss": 0.5641,
      "step": 606400
    },
    {
      "epoch": 6.420165042531005,
      "grad_norm": 1.2640471458435059,
      "learning_rate": 0.0001713149955362647,
      "loss": 0.5662,
      "step": 606450
    },
    {
      "epoch": 6.420694364311008,
      "grad_norm": 1.15426766872406,
      "learning_rate": 0.00017127115218383755,
      "loss": 0.5684,
      "step": 606500
    },
    {
      "epoch": 6.420694364311008,
      "eval_loss": 0.358897864818573,
      "eval_runtime": 47.941,
      "eval_samples_per_second": 3502.847,
      "eval_steps_per_second": 437.872,
      "step": 606500
    },
    {
      "epoch": 6.421223686091012,
      "grad_norm": 1.150701880455017,
      "learning_rate": 0.00017122731151918442,
      "loss": 0.5683,
      "step": 606550
    },
    {
      "epoch": 6.421753007871015,
      "grad_norm": 1.2214834690093994,
      "learning_rate": 0.00017118347354380193,
      "loss": 0.5666,
      "step": 606600
    },
    {
      "epoch": 6.4222823296510185,
      "grad_norm": 1.1464667320251465,
      "learning_rate": 0.0001711396382591868,
      "loss": 0.5592,
      "step": 606650
    },
    {
      "epoch": 6.422811651431021,
      "grad_norm": 1.2759582996368408,
      "learning_rate": 0.00017109580566683548,
      "loss": 0.5658,
      "step": 606700
    },
    {
      "epoch": 6.423340973211024,
      "grad_norm": 1.235718011856079,
      "learning_rate": 0.00017105197576824436,
      "loss": 0.5726,
      "step": 606750
    },
    {
      "epoch": 6.423870294991028,
      "grad_norm": 1.1320744752883911,
      "learning_rate": 0.00017100814856490994,
      "loss": 0.5739,
      "step": 606800
    },
    {
      "epoch": 6.424399616771031,
      "grad_norm": 1.0725548267364502,
      "learning_rate": 0.00017096432405832822,
      "loss": 0.5621,
      "step": 606850
    },
    {
      "epoch": 6.424928938551035,
      "grad_norm": 1.2660025358200073,
      "learning_rate": 0.00017092050224999566,
      "loss": 0.5671,
      "step": 606900
    },
    {
      "epoch": 6.4254582603310375,
      "grad_norm": 1.2068042755126953,
      "learning_rate": 0.00017087668314140803,
      "loss": 0.5574,
      "step": 606950
    },
    {
      "epoch": 6.425987582111041,
      "grad_norm": 1.1967277526855469,
      "learning_rate": 0.00017083286673406152,
      "loss": 0.5701,
      "step": 607000
    },
    {
      "epoch": 6.425987582111041,
      "eval_loss": 0.3581923842430115,
      "eval_runtime": 47.9119,
      "eval_samples_per_second": 3504.977,
      "eval_steps_per_second": 438.138,
      "step": 607000
    },
    {
      "epoch": 6.426516903891044,
      "grad_norm": 1.3477329015731812,
      "learning_rate": 0.00017078905302945178,
      "loss": 0.5669,
      "step": 607050
    },
    {
      "epoch": 6.427046225671048,
      "grad_norm": 1.1093696355819702,
      "learning_rate": 0.00017074524202907482,
      "loss": 0.5718,
      "step": 607100
    },
    {
      "epoch": 6.427575547451051,
      "grad_norm": 1.0636110305786133,
      "learning_rate": 0.00017070143373442616,
      "loss": 0.5617,
      "step": 607150
    },
    {
      "epoch": 6.4281048692310545,
      "grad_norm": 1.2555755376815796,
      "learning_rate": 0.00017065762814700157,
      "loss": 0.5669,
      "step": 607200
    },
    {
      "epoch": 6.428634191011057,
      "grad_norm": 1.1493924856185913,
      "learning_rate": 0.00017061382526829634,
      "loss": 0.5607,
      "step": 607250
    },
    {
      "epoch": 6.429163512791061,
      "grad_norm": 1.153648853302002,
      "learning_rate": 0.00017057002509980612,
      "loss": 0.5654,
      "step": 607300
    },
    {
      "epoch": 6.429692834571064,
      "grad_norm": 1.3300436735153198,
      "learning_rate": 0.000170526227643026,
      "loss": 0.5618,
      "step": 607350
    },
    {
      "epoch": 6.430222156351068,
      "grad_norm": 1.199908971786499,
      "learning_rate": 0.00017048243289945138,
      "loss": 0.5707,
      "step": 607400
    },
    {
      "epoch": 6.430751478131071,
      "grad_norm": 1.223446249961853,
      "learning_rate": 0.0001704386408705773,
      "loss": 0.5781,
      "step": 607450
    },
    {
      "epoch": 6.4312807999110735,
      "grad_norm": 1.2175432443618774,
      "learning_rate": 0.00017039485155789888,
      "loss": 0.5669,
      "step": 607500
    },
    {
      "epoch": 6.4312807999110735,
      "eval_loss": 0.3572567105293274,
      "eval_runtime": 47.867,
      "eval_samples_per_second": 3508.263,
      "eval_steps_per_second": 438.549,
      "step": 607500
    },
    {
      "epoch": 6.431810121691077,
      "grad_norm": 1.222841739654541,
      "learning_rate": 0.00017035106496291098,
      "loss": 0.5609,
      "step": 607550
    },
    {
      "epoch": 6.43233944347108,
      "grad_norm": 1.153917908668518,
      "learning_rate": 0.0001703072810871086,
      "loss": 0.5586,
      "step": 607600
    },
    {
      "epoch": 6.432868765251084,
      "grad_norm": 1.1669296026229858,
      "learning_rate": 0.0001702634999319863,
      "loss": 0.5673,
      "step": 607650
    },
    {
      "epoch": 6.433398087031087,
      "grad_norm": 1.1200982332229614,
      "learning_rate": 0.00017021972149903903,
      "loss": 0.5543,
      "step": 607700
    },
    {
      "epoch": 6.4339274088110905,
      "grad_norm": 1.2576532363891602,
      "learning_rate": 0.00017017682127724504,
      "loss": 0.5604,
      "step": 607750
    },
    {
      "epoch": 6.434456730591093,
      "grad_norm": 1.2952685356140137,
      "learning_rate": 0.00017013304823861313,
      "loss": 0.5612,
      "step": 607800
    },
    {
      "epoch": 6.434986052371097,
      "grad_norm": 1.2254133224487305,
      "learning_rate": 0.00017008927792660968,
      "loss": 0.5565,
      "step": 607850
    },
    {
      "epoch": 6.4355153741511,
      "grad_norm": 1.1837491989135742,
      "learning_rate": 0.00017004551034272898,
      "loss": 0.5609,
      "step": 607900
    },
    {
      "epoch": 6.436044695931104,
      "grad_norm": 1.2303298711776733,
      "learning_rate": 0.00017000174548846523,
      "loss": 0.5735,
      "step": 607950
    },
    {
      "epoch": 6.436574017711107,
      "grad_norm": 1.167453646659851,
      "learning_rate": 0.00016995798336531248,
      "loss": 0.5631,
      "step": 608000
    },
    {
      "epoch": 6.436574017711107,
      "eval_loss": 0.356949120759964,
      "eval_runtime": 48.1689,
      "eval_samples_per_second": 3486.278,
      "eval_steps_per_second": 435.8,
      "step": 608000
    },
    {
      "epoch": 6.43710333949111,
      "grad_norm": 1.0713835954666138,
      "learning_rate": 0.00016991422397476496,
      "loss": 0.5736,
      "step": 608050
    },
    {
      "epoch": 6.437632661271113,
      "grad_norm": 1.1543244123458862,
      "learning_rate": 0.00016987046731831634,
      "loss": 0.5576,
      "step": 608100
    },
    {
      "epoch": 6.438161983051117,
      "grad_norm": 1.2282249927520752,
      "learning_rate": 0.0001698267133974607,
      "loss": 0.5673,
      "step": 608150
    },
    {
      "epoch": 6.43869130483112,
      "grad_norm": 1.3260953426361084,
      "learning_rate": 0.00016978296221369156,
      "loss": 0.5665,
      "step": 608200
    },
    {
      "epoch": 6.439220626611123,
      "grad_norm": 1.1460213661193848,
      "learning_rate": 0.00016973921376850273,
      "loss": 0.5617,
      "step": 608250
    },
    {
      "epoch": 6.4397499483911265,
      "grad_norm": 1.1406972408294678,
      "learning_rate": 0.00016969546806338764,
      "loss": 0.5578,
      "step": 608300
    },
    {
      "epoch": 6.440279270171129,
      "grad_norm": 1.2756363153457642,
      "learning_rate": 0.0001696517250998399,
      "loss": 0.5677,
      "step": 608350
    },
    {
      "epoch": 6.440808591951133,
      "grad_norm": 1.1847220659255981,
      "learning_rate": 0.00016960798487935272,
      "loss": 0.5619,
      "step": 608400
    },
    {
      "epoch": 6.441337913731136,
      "grad_norm": 1.2179068326950073,
      "learning_rate": 0.00016956424740341956,
      "loss": 0.5671,
      "step": 608450
    },
    {
      "epoch": 6.44186723551114,
      "grad_norm": 1.1590193510055542,
      "learning_rate": 0.00016952051267353336,
      "loss": 0.5606,
      "step": 608500
    },
    {
      "epoch": 6.44186723551114,
      "eval_loss": 0.3580743372440338,
      "eval_runtime": 47.354,
      "eval_samples_per_second": 3546.27,
      "eval_steps_per_second": 443.3,
      "step": 608500
    },
    {
      "epoch": 6.442396557291143,
      "grad_norm": 1.2450770139694214,
      "learning_rate": 0.00016947678069118745,
      "loss": 0.5699,
      "step": 608550
    },
    {
      "epoch": 6.442925879071146,
      "grad_norm": 1.3062163591384888,
      "learning_rate": 0.00016943305145787464,
      "loss": 0.5681,
      "step": 608600
    },
    {
      "epoch": 6.443455200851149,
      "grad_norm": 1.1253000497817993,
      "learning_rate": 0.00016938932497508798,
      "loss": 0.5696,
      "step": 608650
    },
    {
      "epoch": 6.443984522631153,
      "grad_norm": 1.1673152446746826,
      "learning_rate": 0.00016934560124432014,
      "loss": 0.553,
      "step": 608700
    },
    {
      "epoch": 6.444513844411156,
      "grad_norm": 1.2976574897766113,
      "learning_rate": 0.00016930188026706392,
      "loss": 0.5647,
      "step": 608750
    },
    {
      "epoch": 6.44504316619116,
      "grad_norm": 1.253442406654358,
      "learning_rate": 0.00016925816204481188,
      "loss": 0.5676,
      "step": 608800
    },
    {
      "epoch": 6.4455724879711624,
      "grad_norm": 1.1637623310089111,
      "learning_rate": 0.00016921444657905666,
      "loss": 0.5831,
      "step": 608850
    },
    {
      "epoch": 6.446101809751166,
      "grad_norm": 1.2191901206970215,
      "learning_rate": 0.00016917073387129051,
      "loss": 0.5602,
      "step": 608900
    },
    {
      "epoch": 6.446631131531169,
      "grad_norm": 1.225760817527771,
      "learning_rate": 0.00016912702392300595,
      "loss": 0.5661,
      "step": 608950
    },
    {
      "epoch": 6.447160453311172,
      "grad_norm": 1.2530829906463623,
      "learning_rate": 0.00016908331673569504,
      "loss": 0.5716,
      "step": 609000
    },
    {
      "epoch": 6.447160453311172,
      "eval_loss": 0.3588351607322693,
      "eval_runtime": 47.3131,
      "eval_samples_per_second": 3549.332,
      "eval_steps_per_second": 443.682,
      "step": 609000
    },
    {
      "epoch": 6.447689775091176,
      "grad_norm": 1.113545298576355,
      "learning_rate": 0.00016903961231085014,
      "loss": 0.5767,
      "step": 609050
    },
    {
      "epoch": 6.448219096871179,
      "grad_norm": 1.2229702472686768,
      "learning_rate": 0.00016899591064996306,
      "loss": 0.5584,
      "step": 609100
    },
    {
      "epoch": 6.448748418651182,
      "grad_norm": 1.0928763151168823,
      "learning_rate": 0.00016895221175452596,
      "loss": 0.5613,
      "step": 609150
    },
    {
      "epoch": 6.449277740431185,
      "grad_norm": 1.1293991804122925,
      "learning_rate": 0.00016890851562603056,
      "loss": 0.5587,
      "step": 609200
    },
    {
      "epoch": 6.449807062211189,
      "grad_norm": 1.3315390348434448,
      "learning_rate": 0.00016886482226596884,
      "loss": 0.5591,
      "step": 609250
    },
    {
      "epoch": 6.450336383991192,
      "grad_norm": 1.249251127243042,
      "learning_rate": 0.00016882113167583215,
      "loss": 0.5654,
      "step": 609300
    },
    {
      "epoch": 6.450865705771196,
      "grad_norm": 1.183828592300415,
      "learning_rate": 0.00016877744385711241,
      "loss": 0.571,
      "step": 609350
    },
    {
      "epoch": 6.451395027551198,
      "grad_norm": 1.2393854856491089,
      "learning_rate": 0.0001687337588113008,
      "loss": 0.5675,
      "step": 609400
    },
    {
      "epoch": 6.451924349331202,
      "grad_norm": 1.1099447011947632,
      "learning_rate": 0.00016869007653988897,
      "loss": 0.5664,
      "step": 609450
    },
    {
      "epoch": 6.452453671111205,
      "grad_norm": 1.2003962993621826,
      "learning_rate": 0.00016864639704436808,
      "loss": 0.5563,
      "step": 609500
    },
    {
      "epoch": 6.452453671111205,
      "eval_loss": 0.3569459319114685,
      "eval_runtime": 46.9072,
      "eval_samples_per_second": 3580.05,
      "eval_steps_per_second": 447.522,
      "step": 609500
    },
    {
      "epoch": 6.452982992891209,
      "grad_norm": 1.251098871231079,
      "learning_rate": 0.00016860272032622937,
      "loss": 0.5651,
      "step": 609550
    },
    {
      "epoch": 6.453512314671212,
      "grad_norm": 1.1639974117279053,
      "learning_rate": 0.00016855904638696383,
      "loss": 0.5545,
      "step": 609600
    },
    {
      "epoch": 6.454041636451215,
      "grad_norm": 1.1442831754684448,
      "learning_rate": 0.00016851537522806275,
      "loss": 0.5593,
      "step": 609650
    },
    {
      "epoch": 6.454570958231218,
      "grad_norm": 1.2054593563079834,
      "learning_rate": 0.00016847170685101677,
      "loss": 0.5617,
      "step": 609700
    },
    {
      "epoch": 6.455100280011221,
      "grad_norm": 1.1588329076766968,
      "learning_rate": 0.00016842891454190443,
      "loss": 0.5534,
      "step": 609750
    },
    {
      "epoch": 6.455629601791225,
      "grad_norm": 1.1437163352966309,
      "learning_rate": 0.00016838525167732986,
      "loss": 0.5626,
      "step": 609800
    },
    {
      "epoch": 6.456158923571228,
      "grad_norm": 1.2206467390060425,
      "learning_rate": 0.000168341591599053,
      "loss": 0.5613,
      "step": 609850
    },
    {
      "epoch": 6.4566882453512315,
      "grad_norm": 1.3708454370498657,
      "learning_rate": 0.00016829793430856411,
      "loss": 0.5718,
      "step": 609900
    },
    {
      "epoch": 6.457217567131234,
      "grad_norm": 1.2348922491073608,
      "learning_rate": 0.00016825427980735391,
      "loss": 0.551,
      "step": 609950
    },
    {
      "epoch": 6.457746888911238,
      "grad_norm": 1.1982364654541016,
      "learning_rate": 0.0001682106280969125,
      "loss": 0.5723,
      "step": 610000
    },
    {
      "epoch": 6.457746888911238,
      "eval_loss": 0.35709595680236816,
      "eval_runtime": 47.0953,
      "eval_samples_per_second": 3565.748,
      "eval_steps_per_second": 445.734,
      "step": 610000
    },
    {
      "epoch": 6.458276210691241,
      "grad_norm": 1.2258360385894775,
      "learning_rate": 0.00016816697917873032,
      "loss": 0.5609,
      "step": 610050
    },
    {
      "epoch": 6.458805532471245,
      "grad_norm": 1.2063530683517456,
      "learning_rate": 0.00016812333305429744,
      "loss": 0.5715,
      "step": 610100
    },
    {
      "epoch": 6.459334854251248,
      "grad_norm": 1.17593514919281,
      "learning_rate": 0.00016807968972510395,
      "loss": 0.5684,
      "step": 610150
    },
    {
      "epoch": 6.459864176031251,
      "grad_norm": 1.1198831796646118,
      "learning_rate": 0.00016803604919263975,
      "loss": 0.5569,
      "step": 610200
    },
    {
      "epoch": 6.460393497811254,
      "grad_norm": 1.1924723386764526,
      "learning_rate": 0.0001679924114583949,
      "loss": 0.572,
      "step": 610250
    },
    {
      "epoch": 6.460922819591258,
      "grad_norm": 1.1678451299667358,
      "learning_rate": 0.00016794877652385893,
      "loss": 0.5613,
      "step": 610300
    },
    {
      "epoch": 6.461452141371261,
      "grad_norm": 1.1915291547775269,
      "learning_rate": 0.00016790514439052174,
      "loss": 0.5623,
      "step": 610350
    },
    {
      "epoch": 6.461981463151265,
      "grad_norm": 1.2810890674591064,
      "learning_rate": 0.00016786151505987268,
      "loss": 0.5641,
      "step": 610400
    },
    {
      "epoch": 6.4625107849312675,
      "grad_norm": 1.1496899127960205,
      "learning_rate": 0.00016781788853340151,
      "loss": 0.5677,
      "step": 610450
    },
    {
      "epoch": 6.46304010671127,
      "grad_norm": 1.153448224067688,
      "learning_rate": 0.0001677742648125974,
      "loss": 0.5574,
      "step": 610500
    },
    {
      "epoch": 6.46304010671127,
      "eval_loss": 0.356039822101593,
      "eval_runtime": 47.0586,
      "eval_samples_per_second": 3568.533,
      "eval_steps_per_second": 446.083,
      "step": 610500
    },
    {
      "epoch": 6.463569428491274,
      "grad_norm": 1.2367924451828003,
      "learning_rate": 0.0001677306438989498,
      "loss": 0.5623,
      "step": 610550
    },
    {
      "epoch": 6.464098750271277,
      "grad_norm": 1.2714406251907349,
      "learning_rate": 0.00016768702579394778,
      "loss": 0.5649,
      "step": 610600
    },
    {
      "epoch": 6.464628072051281,
      "grad_norm": 1.0828063488006592,
      "learning_rate": 0.0001676434104990806,
      "loss": 0.5526,
      "step": 610650
    },
    {
      "epoch": 6.465157393831284,
      "grad_norm": 1.335824966430664,
      "learning_rate": 0.00016759979801583705,
      "loss": 0.5629,
      "step": 610700
    },
    {
      "epoch": 6.465686715611287,
      "grad_norm": 1.296190619468689,
      "learning_rate": 0.0001675561883457063,
      "loss": 0.5666,
      "step": 610750
    },
    {
      "epoch": 6.46621603739129,
      "grad_norm": 1.178781509399414,
      "learning_rate": 0.00016751258149017695,
      "loss": 0.5689,
      "step": 610800
    },
    {
      "epoch": 6.466745359171294,
      "grad_norm": 1.183191180229187,
      "learning_rate": 0.00016746897745073785,
      "loss": 0.5565,
      "step": 610850
    },
    {
      "epoch": 6.467274680951297,
      "grad_norm": 1.1033899784088135,
      "learning_rate": 0.0001674253762288776,
      "loss": 0.5653,
      "step": 610900
    },
    {
      "epoch": 6.467804002731301,
      "grad_norm": 1.2093322277069092,
      "learning_rate": 0.00016738177782608474,
      "loss": 0.5556,
      "step": 610950
    },
    {
      "epoch": 6.4683333245113035,
      "grad_norm": 1.1942098140716553,
      "learning_rate": 0.00016733818224384762,
      "loss": 0.5578,
      "step": 611000
    },
    {
      "epoch": 6.4683333245113035,
      "eval_loss": 0.35692960023880005,
      "eval_runtime": 46.9203,
      "eval_samples_per_second": 3579.049,
      "eval_steps_per_second": 447.397,
      "step": 611000
    },
    {
      "epoch": 6.468862646291307,
      "grad_norm": 1.1498197317123413,
      "learning_rate": 0.00016729458948365472,
      "loss": 0.5642,
      "step": 611050
    },
    {
      "epoch": 6.46939196807131,
      "grad_norm": 1.3723689317703247,
      "learning_rate": 0.00016725099954699414,
      "loss": 0.5702,
      "step": 611100
    },
    {
      "epoch": 6.469921289851314,
      "grad_norm": 1.189099669456482,
      "learning_rate": 0.0001672074124353542,
      "loss": 0.5666,
      "step": 611150
    },
    {
      "epoch": 6.470450611631317,
      "grad_norm": 1.27480149269104,
      "learning_rate": 0.00016716382815022267,
      "loss": 0.5573,
      "step": 611200
    },
    {
      "epoch": 6.47097993341132,
      "grad_norm": 1.3402376174926758,
      "learning_rate": 0.00016712024669308785,
      "loss": 0.555,
      "step": 611250
    },
    {
      "epoch": 6.471509255191323,
      "grad_norm": 1.106101155281067,
      "learning_rate": 0.00016707666806543725,
      "loss": 0.5671,
      "step": 611300
    },
    {
      "epoch": 6.472038576971326,
      "grad_norm": 1.1356048583984375,
      "learning_rate": 0.0001670330922687589,
      "loss": 0.5628,
      "step": 611350
    },
    {
      "epoch": 6.47256789875133,
      "grad_norm": 1.3424874544143677,
      "learning_rate": 0.0001669895193045403,
      "loss": 0.5603,
      "step": 611400
    },
    {
      "epoch": 6.473097220531333,
      "grad_norm": 1.2993261814117432,
      "learning_rate": 0.00016694594917426913,
      "loss": 0.5522,
      "step": 611450
    },
    {
      "epoch": 6.473626542311337,
      "grad_norm": 1.1809718608856201,
      "learning_rate": 0.0001669023818794327,
      "loss": 0.5645,
      "step": 611500
    },
    {
      "epoch": 6.473626542311337,
      "eval_loss": 0.3569219410419464,
      "eval_runtime": 46.9383,
      "eval_samples_per_second": 3577.673,
      "eval_steps_per_second": 447.225,
      "step": 611500
    },
    {
      "epoch": 6.4741558640913395,
      "grad_norm": 1.2354850769042969,
      "learning_rate": 0.00016685881742151856,
      "loss": 0.562,
      "step": 611550
    },
    {
      "epoch": 6.474685185871343,
      "grad_norm": 1.2795979976654053,
      "learning_rate": 0.0001668152558020138,
      "loss": 0.5755,
      "step": 611600
    },
    {
      "epoch": 6.475214507651346,
      "grad_norm": 1.225347876548767,
      "learning_rate": 0.0001667716970224058,
      "loss": 0.5626,
      "step": 611650
    },
    {
      "epoch": 6.47574382943135,
      "grad_norm": 1.3039084672927856,
      "learning_rate": 0.0001667281410841815,
      "loss": 0.5707,
      "step": 611700
    },
    {
      "epoch": 6.476273151211353,
      "grad_norm": 1.2256996631622314,
      "learning_rate": 0.00016668545902286526,
      "loss": 0.5658,
      "step": 611750
    },
    {
      "epoch": 6.4768024729913565,
      "grad_norm": 1.2010666131973267,
      "learning_rate": 0.0001666419087149676,
      "loss": 0.5624,
      "step": 611800
    },
    {
      "epoch": 6.477331794771359,
      "grad_norm": 1.168449878692627,
      "learning_rate": 0.00016659836125288455,
      "loss": 0.564,
      "step": 611850
    },
    {
      "epoch": 6.477861116551363,
      "grad_norm": 1.3571151494979858,
      "learning_rate": 0.00016655481663810297,
      "loss": 0.561,
      "step": 611900
    },
    {
      "epoch": 6.478390438331366,
      "grad_norm": 1.1417906284332275,
      "learning_rate": 0.0001665112748721092,
      "loss": 0.5674,
      "step": 611950
    },
    {
      "epoch": 6.478919760111369,
      "grad_norm": 1.1433496475219727,
      "learning_rate": 0.00016646773595639004,
      "loss": 0.5605,
      "step": 612000
    },
    {
      "epoch": 6.478919760111369,
      "eval_loss": 0.35620880126953125,
      "eval_runtime": 46.9255,
      "eval_samples_per_second": 3578.651,
      "eval_steps_per_second": 447.347,
      "step": 612000
    },
    {
      "epoch": 6.479449081891373,
      "grad_norm": 1.1804676055908203,
      "learning_rate": 0.00016642419989243158,
      "loss": 0.5677,
      "step": 612050
    },
    {
      "epoch": 6.4799784036713755,
      "grad_norm": 1.2003446817398071,
      "learning_rate": 0.00016638066668172037,
      "loss": 0.5533,
      "step": 612100
    },
    {
      "epoch": 6.480507725451379,
      "grad_norm": 1.3968257904052734,
      "learning_rate": 0.00016633713632574254,
      "loss": 0.5615,
      "step": 612150
    },
    {
      "epoch": 6.481037047231382,
      "grad_norm": 1.3152190446853638,
      "learning_rate": 0.00016629360882598415,
      "loss": 0.5516,
      "step": 612200
    },
    {
      "epoch": 6.481566369011386,
      "grad_norm": 1.1961778402328491,
      "learning_rate": 0.00016625008418393129,
      "loss": 0.5615,
      "step": 612250
    },
    {
      "epoch": 6.482095690791389,
      "grad_norm": 1.1680048704147339,
      "learning_rate": 0.00016620656240106985,
      "loss": 0.554,
      "step": 612300
    },
    {
      "epoch": 6.4826250125713925,
      "grad_norm": 1.2755110263824463,
      "learning_rate": 0.0001661630434788856,
      "loss": 0.5601,
      "step": 612350
    },
    {
      "epoch": 6.483154334351395,
      "grad_norm": 1.2226396799087524,
      "learning_rate": 0.0001661195274188644,
      "loss": 0.5664,
      "step": 612400
    },
    {
      "epoch": 6.483683656131399,
      "grad_norm": 1.1723812818527222,
      "learning_rate": 0.00016607601422249165,
      "loss": 0.5548,
      "step": 612450
    },
    {
      "epoch": 6.484212977911402,
      "grad_norm": 1.2906173467636108,
      "learning_rate": 0.00016603250389125306,
      "loss": 0.5739,
      "step": 612500
    },
    {
      "epoch": 6.484212977911402,
      "eval_loss": 0.3554885685443878,
      "eval_runtime": 47.0095,
      "eval_samples_per_second": 3572.258,
      "eval_steps_per_second": 446.548,
      "step": 612500
    },
    {
      "epoch": 6.484742299691406,
      "grad_norm": 1.2190877199172974,
      "learning_rate": 0.00016598899642663396,
      "loss": 0.56,
      "step": 612550
    },
    {
      "epoch": 6.485271621471409,
      "grad_norm": 1.1551368236541748,
      "learning_rate": 0.00016594549183011976,
      "loss": 0.5582,
      "step": 612600
    },
    {
      "epoch": 6.485800943251412,
      "grad_norm": 1.1369681358337402,
      "learning_rate": 0.00016590199010319557,
      "loss": 0.5617,
      "step": 612650
    },
    {
      "epoch": 6.486330265031415,
      "grad_norm": 1.3098200559616089,
      "learning_rate": 0.0001658584912473467,
      "loss": 0.561,
      "step": 612700
    },
    {
      "epoch": 6.486859586811419,
      "grad_norm": 1.2164227962493896,
      "learning_rate": 0.00016581499526405796,
      "loss": 0.5626,
      "step": 612750
    },
    {
      "epoch": 6.487388908591422,
      "grad_norm": 1.2579526901245117,
      "learning_rate": 0.00016577150215481452,
      "loss": 0.5693,
      "step": 612800
    },
    {
      "epoch": 6.487918230371425,
      "grad_norm": 1.2124249935150146,
      "learning_rate": 0.000165728011921101,
      "loss": 0.5516,
      "step": 612850
    },
    {
      "epoch": 6.488447552151428,
      "grad_norm": 1.138973593711853,
      "learning_rate": 0.0001656845245644023,
      "loss": 0.5592,
      "step": 612900
    },
    {
      "epoch": 6.488976873931431,
      "grad_norm": 1.2860950231552124,
      "learning_rate": 0.000165641040086203,
      "loss": 0.5605,
      "step": 612950
    },
    {
      "epoch": 6.489506195711435,
      "grad_norm": 1.1733697652816772,
      "learning_rate": 0.00016559755848798767,
      "loss": 0.568,
      "step": 613000
    },
    {
      "epoch": 6.489506195711435,
      "eval_loss": 0.35485851764678955,
      "eval_runtime": 47.0363,
      "eval_samples_per_second": 3570.223,
      "eval_steps_per_second": 446.294,
      "step": 613000
    },
    {
      "epoch": 6.490035517491438,
      "grad_norm": 1.1260640621185303,
      "learning_rate": 0.00016555407977124071,
      "loss": 0.5678,
      "step": 613050
    },
    {
      "epoch": 6.490564839271442,
      "grad_norm": 1.2298574447631836,
      "learning_rate": 0.00016551060393744655,
      "loss": 0.5645,
      "step": 613100
    },
    {
      "epoch": 6.4910941610514445,
      "grad_norm": 1.1430505514144897,
      "learning_rate": 0.00016546713098808933,
      "loss": 0.567,
      "step": 613150
    },
    {
      "epoch": 6.491623482831448,
      "grad_norm": 1.2553704977035522,
      "learning_rate": 0.00016542366092465332,
      "loss": 0.5713,
      "step": 613200
    },
    {
      "epoch": 6.492152804611451,
      "grad_norm": 1.2131792306900024,
      "learning_rate": 0.00016538019374862242,
      "loss": 0.5677,
      "step": 613250
    },
    {
      "epoch": 6.492682126391455,
      "grad_norm": 1.361838698387146,
      "learning_rate": 0.00016533672946148078,
      "loss": 0.5634,
      "step": 613300
    },
    {
      "epoch": 6.493211448171458,
      "grad_norm": 1.216016173362732,
      "learning_rate": 0.00016529326806471206,
      "loss": 0.5524,
      "step": 613350
    },
    {
      "epoch": 6.4937407699514615,
      "grad_norm": 1.1153782606124878,
      "learning_rate": 0.00016524980955980018,
      "loss": 0.5662,
      "step": 613400
    },
    {
      "epoch": 6.494270091731464,
      "grad_norm": 1.2560579776763916,
      "learning_rate": 0.00016520635394822863,
      "loss": 0.5657,
      "step": 613450
    },
    {
      "epoch": 6.494799413511468,
      "grad_norm": 1.2363381385803223,
      "learning_rate": 0.00016516290123148115,
      "loss": 0.5588,
      "step": 613500
    },
    {
      "epoch": 6.494799413511468,
      "eval_loss": 0.3553975820541382,
      "eval_runtime": 47.1046,
      "eval_samples_per_second": 3565.047,
      "eval_steps_per_second": 445.647,
      "step": 613500
    },
    {
      "epoch": 6.495328735291471,
      "grad_norm": 1.1849851608276367,
      "learning_rate": 0.000165119451411041,
      "loss": 0.5551,
      "step": 613550
    },
    {
      "epoch": 6.495858057071475,
      "grad_norm": 1.3280549049377441,
      "learning_rate": 0.00016507600448839178,
      "loss": 0.5545,
      "step": 613600
    },
    {
      "epoch": 6.496387378851478,
      "grad_norm": 1.3445279598236084,
      "learning_rate": 0.0001650325604650165,
      "loss": 0.5655,
      "step": 613650
    },
    {
      "epoch": 6.4969167006314805,
      "grad_norm": 1.2527250051498413,
      "learning_rate": 0.00016498911934239853,
      "loss": 0.5642,
      "step": 613700
    },
    {
      "epoch": 6.497446022411484,
      "grad_norm": 1.1102958917617798,
      "learning_rate": 0.00016494654985797674,
      "loss": 0.5649,
      "step": 613750
    },
    {
      "epoch": 6.497975344191487,
      "grad_norm": 1.2312911748886108,
      "learning_rate": 0.0001649031144832333,
      "loss": 0.5526,
      "step": 613800
    },
    {
      "epoch": 6.498504665971491,
      "grad_norm": 1.285668134689331,
      "learning_rate": 0.0001648596820136663,
      "loss": 0.5518,
      "step": 613850
    },
    {
      "epoch": 6.499033987751494,
      "grad_norm": 1.1668477058410645,
      "learning_rate": 0.00016481625245075857,
      "loss": 0.5534,
      "step": 613900
    },
    {
      "epoch": 6.4995633095314975,
      "grad_norm": 1.045795202255249,
      "learning_rate": 0.00016477282579599266,
      "loss": 0.5678,
      "step": 613950
    },
    {
      "epoch": 6.5000926313115,
      "grad_norm": 1.1301121711730957,
      "learning_rate": 0.0001647294020508513,
      "loss": 0.5735,
      "step": 614000
    },
    {
      "epoch": 6.5000926313115,
      "eval_loss": 0.35659196972846985,
      "eval_runtime": 46.9331,
      "eval_samples_per_second": 3578.072,
      "eval_steps_per_second": 447.275,
      "step": 614000
    },
    {
      "epoch": 6.500621953091504,
      "grad_norm": 1.121069073677063,
      "learning_rate": 0.00016468598121681684,
      "loss": 0.557,
      "step": 614050
    },
    {
      "epoch": 6.501151274871507,
      "grad_norm": 1.2765493392944336,
      "learning_rate": 0.00016464256329537175,
      "loss": 0.5576,
      "step": 614100
    },
    {
      "epoch": 6.501680596651511,
      "grad_norm": 1.346718192100525,
      "learning_rate": 0.00016459914828799815,
      "loss": 0.5637,
      "step": 614150
    },
    {
      "epoch": 6.502209918431514,
      "grad_norm": 1.3303567171096802,
      "learning_rate": 0.0001645557361961784,
      "loss": 0.5658,
      "step": 614200
    },
    {
      "epoch": 6.5027392402115165,
      "grad_norm": 1.2644685506820679,
      "learning_rate": 0.0001645123270213944,
      "loss": 0.5638,
      "step": 614250
    },
    {
      "epoch": 6.50326856199152,
      "grad_norm": 1.29801607131958,
      "learning_rate": 0.00016446892076512826,
      "loss": 0.5586,
      "step": 614300
    },
    {
      "epoch": 6.503797883771524,
      "grad_norm": 1.304033875465393,
      "learning_rate": 0.00016442551742886175,
      "loss": 0.5599,
      "step": 614350
    },
    {
      "epoch": 6.504327205551527,
      "grad_norm": 1.2029861211776733,
      "learning_rate": 0.00016438211701407673,
      "loss": 0.5641,
      "step": 614400
    },
    {
      "epoch": 6.50485652733153,
      "grad_norm": 1.139776587486267,
      "learning_rate": 0.00016433871952225483,
      "loss": 0.5523,
      "step": 614450
    },
    {
      "epoch": 6.5053858491115335,
      "grad_norm": 1.0863220691680908,
      "learning_rate": 0.00016429532495487763,
      "loss": 0.563,
      "step": 614500
    },
    {
      "epoch": 6.5053858491115335,
      "eval_loss": 0.35482218861579895,
      "eval_runtime": 47.163,
      "eval_samples_per_second": 3560.631,
      "eval_steps_per_second": 445.095,
      "step": 614500
    },
    {
      "epoch": 6.505915170891536,
      "grad_norm": 1.2869982719421387,
      "learning_rate": 0.00016425193331342657,
      "loss": 0.5573,
      "step": 614550
    },
    {
      "epoch": 6.50644449267154,
      "grad_norm": 1.2278213500976562,
      "learning_rate": 0.00016420854459938314,
      "loss": 0.5588,
      "step": 614600
    },
    {
      "epoch": 6.506973814451543,
      "grad_norm": 1.1913397312164307,
      "learning_rate": 0.00016416515881422845,
      "loss": 0.5613,
      "step": 614650
    },
    {
      "epoch": 6.507503136231547,
      "grad_norm": 1.1810929775238037,
      "learning_rate": 0.00016412177595944382,
      "loss": 0.5799,
      "step": 614700
    },
    {
      "epoch": 6.50803245801155,
      "grad_norm": 1.3133896589279175,
      "learning_rate": 0.0001640783960365102,
      "loss": 0.5611,
      "step": 614750
    },
    {
      "epoch": 6.508561779791553,
      "grad_norm": 1.3953123092651367,
      "learning_rate": 0.0001640350190469087,
      "loss": 0.5701,
      "step": 614800
    },
    {
      "epoch": 6.509091101571556,
      "grad_norm": 1.2693257331848145,
      "learning_rate": 0.00016399164499212004,
      "loss": 0.5684,
      "step": 614850
    },
    {
      "epoch": 6.50962042335156,
      "grad_norm": 1.1589949131011963,
      "learning_rate": 0.00016394827387362522,
      "loss": 0.5515,
      "step": 614900
    },
    {
      "epoch": 6.510149745131563,
      "grad_norm": 1.1126677989959717,
      "learning_rate": 0.0001639049056929046,
      "loss": 0.5564,
      "step": 614950
    },
    {
      "epoch": 6.510679066911566,
      "grad_norm": 1.2518699169158936,
      "learning_rate": 0.0001638615404514391,
      "loss": 0.5647,
      "step": 615000
    },
    {
      "epoch": 6.510679066911566,
      "eval_loss": 0.3544788360595703,
      "eval_runtime": 47.113,
      "eval_samples_per_second": 3564.407,
      "eval_steps_per_second": 445.567,
      "step": 615000
    },
    {
      "epoch": 6.5112083886915695,
      "grad_norm": 1.1719175577163696,
      "learning_rate": 0.00016381817815070882,
      "loss": 0.5587,
      "step": 615050
    },
    {
      "epoch": 6.511737710471573,
      "grad_norm": 1.1911290884017944,
      "learning_rate": 0.00016377481879219452,
      "loss": 0.5644,
      "step": 615100
    },
    {
      "epoch": 6.512267032251576,
      "grad_norm": 1.3190760612487793,
      "learning_rate": 0.00016373146237737613,
      "loss": 0.5484,
      "step": 615150
    },
    {
      "epoch": 6.512796354031579,
      "grad_norm": 1.1483595371246338,
      "learning_rate": 0.00016368810890773406,
      "loss": 0.5598,
      "step": 615200
    },
    {
      "epoch": 6.513325675811583,
      "grad_norm": 1.2540867328643799,
      "learning_rate": 0.0001636447583847483,
      "loss": 0.5588,
      "step": 615250
    },
    {
      "epoch": 6.513854997591586,
      "grad_norm": 1.2787474393844604,
      "learning_rate": 0.00016360141080989877,
      "loss": 0.5623,
      "step": 615300
    },
    {
      "epoch": 6.514384319371589,
      "grad_norm": 1.1003130674362183,
      "learning_rate": 0.00016355806618466537,
      "loss": 0.5631,
      "step": 615350
    },
    {
      "epoch": 6.514913641151592,
      "grad_norm": 1.245104432106018,
      "learning_rate": 0.000163514724510528,
      "loss": 0.5629,
      "step": 615400
    },
    {
      "epoch": 6.515442962931596,
      "grad_norm": 1.1375480890274048,
      "learning_rate": 0.00016347138578896612,
      "loss": 0.5612,
      "step": 615450
    },
    {
      "epoch": 6.515972284711599,
      "grad_norm": 1.2222703695297241,
      "learning_rate": 0.0001634280500214595,
      "loss": 0.567,
      "step": 615500
    },
    {
      "epoch": 6.515972284711599,
      "eval_loss": 0.3544897437095642,
      "eval_runtime": 47.1015,
      "eval_samples_per_second": 3565.279,
      "eval_steps_per_second": 445.676,
      "step": 615500
    },
    {
      "epoch": 6.516501606491603,
      "grad_norm": 1.1950732469558716,
      "learning_rate": 0.00016338471720948736,
      "loss": 0.5758,
      "step": 615550
    },
    {
      "epoch": 6.5170309282716055,
      "grad_norm": 1.181382656097412,
      "learning_rate": 0.00016334138735452935,
      "loss": 0.5543,
      "step": 615600
    },
    {
      "epoch": 6.517560250051609,
      "grad_norm": 1.1845935583114624,
      "learning_rate": 0.00016329806045806448,
      "loss": 0.5726,
      "step": 615650
    },
    {
      "epoch": 6.518089571831612,
      "grad_norm": 1.268359661102295,
      "learning_rate": 0.00016325473652157213,
      "loss": 0.567,
      "step": 615700
    },
    {
      "epoch": 6.518618893611615,
      "grad_norm": 1.19206702709198,
      "learning_rate": 0.00016321141554653115,
      "loss": 0.5599,
      "step": 615750
    },
    {
      "epoch": 6.519148215391619,
      "grad_norm": 1.0883381366729736,
      "learning_rate": 0.00016316896386561657,
      "loss": 0.553,
      "step": 615800
    },
    {
      "epoch": 6.5196775371716225,
      "grad_norm": 1.2243895530700684,
      "learning_rate": 0.0001631256487586128,
      "loss": 0.5486,
      "step": 615850
    },
    {
      "epoch": 6.520206858951625,
      "grad_norm": 1.1913291215896606,
      "learning_rate": 0.0001630823366174674,
      "loss": 0.5512,
      "step": 615900
    },
    {
      "epoch": 6.520736180731628,
      "grad_norm": 1.2144187688827515,
      "learning_rate": 0.00016303902744365924,
      "loss": 0.5516,
      "step": 615950
    },
    {
      "epoch": 6.521265502511632,
      "grad_norm": 1.292159914970398,
      "learning_rate": 0.00016299572123866667,
      "loss": 0.5547,
      "step": 616000
    },
    {
      "epoch": 6.521265502511632,
      "eval_loss": 0.35363247990608215,
      "eval_runtime": 46.9705,
      "eval_samples_per_second": 3575.221,
      "eval_steps_per_second": 446.919,
      "step": 616000
    },
    {
      "epoch": 6.521794824291635,
      "grad_norm": 1.1018357276916504,
      "learning_rate": 0.00016295241800396841,
      "loss": 0.555,
      "step": 616050
    },
    {
      "epoch": 6.522324146071639,
      "grad_norm": 1.1243025064468384,
      "learning_rate": 0.00016290911774104256,
      "loss": 0.5476,
      "step": 616100
    },
    {
      "epoch": 6.522853467851641,
      "grad_norm": 1.280545949935913,
      "learning_rate": 0.00016286582045136762,
      "loss": 0.5597,
      "step": 616150
    },
    {
      "epoch": 6.523382789631645,
      "grad_norm": 1.1890332698822021,
      "learning_rate": 0.00016282252613642145,
      "loss": 0.5721,
      "step": 616200
    },
    {
      "epoch": 6.523912111411648,
      "grad_norm": 1.233981728553772,
      "learning_rate": 0.00016277923479768243,
      "loss": 0.5664,
      "step": 616250
    },
    {
      "epoch": 6.524441433191652,
      "grad_norm": 1.2389428615570068,
      "learning_rate": 0.0001627359464366282,
      "loss": 0.5631,
      "step": 616300
    },
    {
      "epoch": 6.524970754971655,
      "grad_norm": 1.2502585649490356,
      "learning_rate": 0.00016269266105473684,
      "loss": 0.5667,
      "step": 616350
    },
    {
      "epoch": 6.525500076751658,
      "grad_norm": 1.1151251792907715,
      "learning_rate": 0.00016264937865348602,
      "loss": 0.5577,
      "step": 616400
    },
    {
      "epoch": 6.526029398531661,
      "grad_norm": 1.203569769859314,
      "learning_rate": 0.00016260609923435333,
      "loss": 0.5569,
      "step": 616450
    },
    {
      "epoch": 6.526558720311664,
      "grad_norm": 1.3757100105285645,
      "learning_rate": 0.0001625628227988164,
      "loss": 0.567,
      "step": 616500
    },
    {
      "epoch": 6.526558720311664,
      "eval_loss": 0.3545999825000763,
      "eval_runtime": 47.1632,
      "eval_samples_per_second": 3560.618,
      "eval_steps_per_second": 445.093,
      "step": 616500
    },
    {
      "epoch": 6.527088042091668,
      "grad_norm": 1.1367517709732056,
      "learning_rate": 0.0001625195493483526,
      "loss": 0.5578,
      "step": 616550
    },
    {
      "epoch": 6.527617363871672,
      "grad_norm": 1.2149715423583984,
      "learning_rate": 0.00016247627888443927,
      "loss": 0.562,
      "step": 616600
    },
    {
      "epoch": 6.5281466856516746,
      "grad_norm": 1.2554359436035156,
      "learning_rate": 0.0001624330114085538,
      "loss": 0.5622,
      "step": 616650
    },
    {
      "epoch": 6.528676007431677,
      "grad_norm": 1.3128331899642944,
      "learning_rate": 0.0001623897469221731,
      "loss": 0.5664,
      "step": 616700
    },
    {
      "epoch": 6.529205329211681,
      "grad_norm": 1.2894415855407715,
      "learning_rate": 0.0001623464854267744,
      "loss": 0.5596,
      "step": 616750
    },
    {
      "epoch": 6.529734650991684,
      "grad_norm": 1.2571271657943726,
      "learning_rate": 0.0001623032269238344,
      "loss": 0.5652,
      "step": 616800
    },
    {
      "epoch": 6.530263972771688,
      "grad_norm": 1.12876558303833,
      "learning_rate": 0.00016225997141483024,
      "loss": 0.5695,
      "step": 616850
    },
    {
      "epoch": 6.530793294551691,
      "grad_norm": 1.3593318462371826,
      "learning_rate": 0.00016221671890123834,
      "loss": 0.5644,
      "step": 616900
    },
    {
      "epoch": 6.531322616331694,
      "grad_norm": 1.1856611967086792,
      "learning_rate": 0.0001621734693845356,
      "loss": 0.5588,
      "step": 616950
    },
    {
      "epoch": 6.531851938111697,
      "grad_norm": 1.1704076528549194,
      "learning_rate": 0.00016213022286619828,
      "loss": 0.5569,
      "step": 617000
    },
    {
      "epoch": 6.531851938111697,
      "eval_loss": 0.3550703227519989,
      "eval_runtime": 47.0627,
      "eval_samples_per_second": 3568.217,
      "eval_steps_per_second": 446.043,
      "step": 617000
    },
    {
      "epoch": 6.532381259891701,
      "grad_norm": 1.2140828371047974,
      "learning_rate": 0.000162086979347703,
      "loss": 0.5562,
      "step": 617050
    },
    {
      "epoch": 6.532910581671704,
      "grad_norm": 1.3643908500671387,
      "learning_rate": 0.00016204373883052593,
      "loss": 0.5596,
      "step": 617100
    },
    {
      "epoch": 6.533439903451708,
      "grad_norm": 1.1736847162246704,
      "learning_rate": 0.00016200050131614347,
      "loss": 0.5617,
      "step": 617150
    },
    {
      "epoch": 6.5339692252317105,
      "grad_norm": 1.2651081085205078,
      "learning_rate": 0.0001619572668060315,
      "loss": 0.562,
      "step": 617200
    },
    {
      "epoch": 6.534498547011713,
      "grad_norm": 1.2910007238388062,
      "learning_rate": 0.0001619140353016662,
      "loss": 0.5588,
      "step": 617250
    },
    {
      "epoch": 6.535027868791717,
      "grad_norm": 1.1862727403640747,
      "learning_rate": 0.0001618708068045235,
      "loss": 0.5617,
      "step": 617300
    },
    {
      "epoch": 6.535557190571721,
      "grad_norm": 1.286496639251709,
      "learning_rate": 0.00016182758131607906,
      "loss": 0.562,
      "step": 617350
    },
    {
      "epoch": 6.536086512351724,
      "grad_norm": 1.4472277164459229,
      "learning_rate": 0.0001617843588378086,
      "loss": 0.5589,
      "step": 617400
    },
    {
      "epoch": 6.536615834131727,
      "grad_norm": 1.2861255407333374,
      "learning_rate": 0.00016174113937118793,
      "loss": 0.5552,
      "step": 617450
    },
    {
      "epoch": 6.53714515591173,
      "grad_norm": 1.1861991882324219,
      "learning_rate": 0.00016169792291769226,
      "loss": 0.563,
      "step": 617500
    },
    {
      "epoch": 6.53714515591173,
      "eval_loss": 0.35358139872550964,
      "eval_runtime": 47.056,
      "eval_samples_per_second": 3568.728,
      "eval_steps_per_second": 446.107,
      "step": 617500
    },
    {
      "epoch": 6.537674477691733,
      "grad_norm": 1.2375762462615967,
      "learning_rate": 0.00016165470947879723,
      "loss": 0.5609,
      "step": 617550
    },
    {
      "epoch": 6.538203799471737,
      "grad_norm": 1.0579217672348022,
      "learning_rate": 0.0001616114990559779,
      "loss": 0.5625,
      "step": 617600
    },
    {
      "epoch": 6.53873312125174,
      "grad_norm": 1.0946751832962036,
      "learning_rate": 0.0001615682916507097,
      "loss": 0.5585,
      "step": 617650
    },
    {
      "epoch": 6.539262443031744,
      "grad_norm": 1.296018123626709,
      "learning_rate": 0.00016152508726446747,
      "loss": 0.5622,
      "step": 617700
    },
    {
      "epoch": 6.5397917648117465,
      "grad_norm": 1.3247509002685547,
      "learning_rate": 0.00016148188589872641,
      "loss": 0.567,
      "step": 617750
    },
    {
      "epoch": 6.54032108659175,
      "grad_norm": 1.0770426988601685,
      "learning_rate": 0.0001614395514922117,
      "loss": 0.5571,
      "step": 617800
    },
    {
      "epoch": 6.540850408371753,
      "grad_norm": 1.2403788566589355,
      "learning_rate": 0.00016139635611141372,
      "loss": 0.5651,
      "step": 617850
    },
    {
      "epoch": 6.541379730151757,
      "grad_norm": 1.2587281465530396,
      "learning_rate": 0.00016135316375551182,
      "loss": 0.5574,
      "step": 617900
    },
    {
      "epoch": 6.54190905193176,
      "grad_norm": 1.098110318183899,
      "learning_rate": 0.00016130997442598028,
      "loss": 0.56,
      "step": 617950
    },
    {
      "epoch": 6.542438373711763,
      "grad_norm": 1.2339059114456177,
      "learning_rate": 0.0001612667881242938,
      "loss": 0.5583,
      "step": 618000
    },
    {
      "epoch": 6.542438373711763,
      "eval_loss": 0.35319557785987854,
      "eval_runtime": 47.0111,
      "eval_samples_per_second": 3572.136,
      "eval_steps_per_second": 446.533,
      "step": 618000
    },
    {
      "epoch": 6.542967695491766,
      "grad_norm": 1.1128491163253784,
      "learning_rate": 0.0001612236048519265,
      "loss": 0.5666,
      "step": 618050
    },
    {
      "epoch": 6.54349701727177,
      "grad_norm": 1.2598334550857544,
      "learning_rate": 0.00016118042461035287,
      "loss": 0.5578,
      "step": 618100
    },
    {
      "epoch": 6.544026339051773,
      "grad_norm": 1.2857210636138916,
      "learning_rate": 0.0001611372474010469,
      "loss": 0.5594,
      "step": 618150
    },
    {
      "epoch": 6.544555660831776,
      "grad_norm": 1.094203233718872,
      "learning_rate": 0.0001610940732254828,
      "loss": 0.5631,
      "step": 618200
    },
    {
      "epoch": 6.54508498261178,
      "grad_norm": 1.1840765476226807,
      "learning_rate": 0.00016105090208513433,
      "loss": 0.5629,
      "step": 618250
    },
    {
      "epoch": 6.5456143043917825,
      "grad_norm": 1.284522294998169,
      "learning_rate": 0.00016100773398147555,
      "loss": 0.5614,
      "step": 618300
    },
    {
      "epoch": 6.546143626171786,
      "grad_norm": 1.324304461479187,
      "learning_rate": 0.00016096456891597999,
      "loss": 0.5653,
      "step": 618350
    },
    {
      "epoch": 6.546672947951789,
      "grad_norm": 1.1170092821121216,
      "learning_rate": 0.0001609214068901215,
      "loss": 0.5708,
      "step": 618400
    },
    {
      "epoch": 6.547202269731793,
      "grad_norm": 1.2404649257659912,
      "learning_rate": 0.0001608782479053734,
      "loss": 0.556,
      "step": 618450
    },
    {
      "epoch": 6.547731591511796,
      "grad_norm": 1.1658421754837036,
      "learning_rate": 0.00016083509196320928,
      "loss": 0.5638,
      "step": 618500
    },
    {
      "epoch": 6.547731591511796,
      "eval_loss": 0.3528536558151245,
      "eval_runtime": 47.0789,
      "eval_samples_per_second": 3566.992,
      "eval_steps_per_second": 445.89,
      "step": 618500
    },
    {
      "epoch": 6.5482609132917995,
      "grad_norm": 1.2052712440490723,
      "learning_rate": 0.00016079193906510245,
      "loss": 0.5597,
      "step": 618550
    },
    {
      "epoch": 6.548790235071802,
      "grad_norm": 1.2241219282150269,
      "learning_rate": 0.00016074878921252606,
      "loss": 0.5577,
      "step": 618600
    },
    {
      "epoch": 6.549319556851806,
      "grad_norm": 1.1846346855163574,
      "learning_rate": 0.00016070564240695326,
      "loss": 0.5534,
      "step": 618650
    },
    {
      "epoch": 6.549848878631809,
      "grad_norm": 1.1150537729263306,
      "learning_rate": 0.00016066249864985717,
      "loss": 0.5616,
      "step": 618700
    },
    {
      "epoch": 6.550378200411812,
      "grad_norm": 1.26331627368927,
      "learning_rate": 0.00016061935794271052,
      "loss": 0.5584,
      "step": 618750
    },
    {
      "epoch": 6.550907522191816,
      "grad_norm": 1.2110340595245361,
      "learning_rate": 0.0001605762202869863,
      "loss": 0.5596,
      "step": 618800
    },
    {
      "epoch": 6.551436843971819,
      "grad_norm": 1.3016566038131714,
      "learning_rate": 0.00016053308568415704,
      "loss": 0.5582,
      "step": 618850
    },
    {
      "epoch": 6.551966165751822,
      "grad_norm": 1.210291862487793,
      "learning_rate": 0.00016048995413569552,
      "loss": 0.5544,
      "step": 618900
    },
    {
      "epoch": 6.552495487531825,
      "grad_norm": 1.15719735622406,
      "learning_rate": 0.000160446825643074,
      "loss": 0.5514,
      "step": 618950
    },
    {
      "epoch": 6.553024809311829,
      "grad_norm": 1.1810276508331299,
      "learning_rate": 0.00016040370020776513,
      "loss": 0.5562,
      "step": 619000
    },
    {
      "epoch": 6.553024809311829,
      "eval_loss": 0.3533340394496918,
      "eval_runtime": 47.0727,
      "eval_samples_per_second": 3567.46,
      "eval_steps_per_second": 445.948,
      "step": 619000
    },
    {
      "epoch": 6.553554131091832,
      "grad_norm": 1.2734860181808472,
      "learning_rate": 0.00016036057783124096,
      "loss": 0.5655,
      "step": 619050
    },
    {
      "epoch": 6.5540834528718355,
      "grad_norm": 1.2305856943130493,
      "learning_rate": 0.00016031745851497392,
      "loss": 0.5574,
      "step": 619100
    },
    {
      "epoch": 6.554612774651838,
      "grad_norm": 1.1965185403823853,
      "learning_rate": 0.00016027434226043586,
      "loss": 0.566,
      "step": 619150
    },
    {
      "epoch": 6.555142096431842,
      "grad_norm": 1.2027342319488525,
      "learning_rate": 0.00016023122906909897,
      "loss": 0.5632,
      "step": 619200
    },
    {
      "epoch": 6.555671418211845,
      "grad_norm": 1.3697441816329956,
      "learning_rate": 0.00016018811894243486,
      "loss": 0.5544,
      "step": 619250
    },
    {
      "epoch": 6.556200739991849,
      "grad_norm": 1.195692777633667,
      "learning_rate": 0.0001601450118819155,
      "loss": 0.5576,
      "step": 619300
    },
    {
      "epoch": 6.556730061771852,
      "grad_norm": 1.3405461311340332,
      "learning_rate": 0.00016010190788901243,
      "loss": 0.5655,
      "step": 619350
    },
    {
      "epoch": 6.557259383551855,
      "grad_norm": 1.1750080585479736,
      "learning_rate": 0.0001600588069651973,
      "loss": 0.5634,
      "step": 619400
    },
    {
      "epoch": 6.557788705331858,
      "grad_norm": 1.2675226926803589,
      "learning_rate": 0.00016001570911194145,
      "loss": 0.5531,
      "step": 619450
    },
    {
      "epoch": 6.558318027111862,
      "grad_norm": 1.2385878562927246,
      "learning_rate": 0.0001599726143307164,
      "loss": 0.5578,
      "step": 619500
    },
    {
      "epoch": 6.558318027111862,
      "eval_loss": 0.35354799032211304,
      "eval_runtime": 47.3133,
      "eval_samples_per_second": 3549.318,
      "eval_steps_per_second": 443.681,
      "step": 619500
    },
    {
      "epoch": 6.558847348891865,
      "grad_norm": 1.322606086730957,
      "learning_rate": 0.0001599295226229932,
      "loss": 0.5625,
      "step": 619550
    },
    {
      "epoch": 6.559376670671869,
      "grad_norm": 1.2680124044418335,
      "learning_rate": 0.00015988643399024314,
      "loss": 0.5717,
      "step": 619600
    },
    {
      "epoch": 6.5599059924518714,
      "grad_norm": 1.1992301940917969,
      "learning_rate": 0.0001598433484339371,
      "loss": 0.5648,
      "step": 619650
    },
    {
      "epoch": 6.560435314231874,
      "grad_norm": 1.1491056680679321,
      "learning_rate": 0.00015980026595554603,
      "loss": 0.5667,
      "step": 619700
    },
    {
      "epoch": 6.560964636011878,
      "grad_norm": 1.2118154764175415,
      "learning_rate": 0.00015975718655654092,
      "loss": 0.5554,
      "step": 619750
    },
    {
      "epoch": 6.561493957791881,
      "grad_norm": 1.1938517093658447,
      "learning_rate": 0.00015971497173455346,
      "loss": 0.5539,
      "step": 619800
    },
    {
      "epoch": 6.562023279571885,
      "grad_norm": 1.2869982719421387,
      "learning_rate": 0.00015967189843707103,
      "loss": 0.5429,
      "step": 619850
    },
    {
      "epoch": 6.562552601351888,
      "grad_norm": 1.2248183488845825,
      "learning_rate": 0.0001596288282233569,
      "loss": 0.5566,
      "step": 619900
    },
    {
      "epoch": 6.563081923131891,
      "grad_norm": 1.308294415473938,
      "learning_rate": 0.00015958576109488144,
      "loss": 0.5569,
      "step": 619950
    },
    {
      "epoch": 6.563611244911894,
      "grad_norm": 1.2970573902130127,
      "learning_rate": 0.00015954269705311492,
      "loss": 0.561,
      "step": 620000
    },
    {
      "epoch": 6.563611244911894,
      "eval_loss": 0.3526913821697235,
      "eval_runtime": 47.4119,
      "eval_samples_per_second": 3541.936,
      "eval_steps_per_second": 442.758,
      "step": 620000
    },
    {
      "epoch": 6.564140566691898,
      "grad_norm": 1.1608926057815552,
      "learning_rate": 0.00015949963609952753,
      "loss": 0.5533,
      "step": 620050
    },
    {
      "epoch": 6.564669888471901,
      "grad_norm": 1.181258201599121,
      "learning_rate": 0.00015945657823558947,
      "loss": 0.5613,
      "step": 620100
    },
    {
      "epoch": 6.565199210251905,
      "grad_norm": 1.3676236867904663,
      "learning_rate": 0.00015941352346277048,
      "loss": 0.5554,
      "step": 620150
    },
    {
      "epoch": 6.565728532031907,
      "grad_norm": 1.298579454421997,
      "learning_rate": 0.00015937047178254073,
      "loss": 0.5595,
      "step": 620200
    },
    {
      "epoch": 6.566257853811911,
      "grad_norm": 1.287806749343872,
      "learning_rate": 0.00015932742319636973,
      "loss": 0.5618,
      "step": 620250
    },
    {
      "epoch": 6.566787175591914,
      "grad_norm": 1.042823314666748,
      "learning_rate": 0.0001592843777057273,
      "loss": 0.5533,
      "step": 620300
    },
    {
      "epoch": 6.567316497371918,
      "grad_norm": 1.163039207458496,
      "learning_rate": 0.0001592413353120829,
      "loss": 0.5602,
      "step": 620350
    },
    {
      "epoch": 6.567845819151921,
      "grad_norm": 1.2971687316894531,
      "learning_rate": 0.0001591982960169061,
      "loss": 0.5628,
      "step": 620400
    },
    {
      "epoch": 6.5683751409319235,
      "grad_norm": 1.2298651933670044,
      "learning_rate": 0.00015915525982166607,
      "loss": 0.5524,
      "step": 620450
    },
    {
      "epoch": 6.568904462711927,
      "grad_norm": 1.341709852218628,
      "learning_rate": 0.00015911222672783227,
      "loss": 0.5594,
      "step": 620500
    },
    {
      "epoch": 6.568904462711927,
      "eval_loss": 0.3531404137611389,
      "eval_runtime": 47.4968,
      "eval_samples_per_second": 3535.61,
      "eval_steps_per_second": 441.967,
      "step": 620500
    },
    {
      "epoch": 6.56943378449193,
      "grad_norm": 1.1434838771820068,
      "learning_rate": 0.0001590691967368736,
      "loss": 0.5569,
      "step": 620550
    },
    {
      "epoch": 6.569963106271934,
      "grad_norm": 1.1744102239608765,
      "learning_rate": 0.00015902616985025934,
      "loss": 0.5539,
      "step": 620600
    },
    {
      "epoch": 6.570492428051937,
      "grad_norm": 1.3511896133422852,
      "learning_rate": 0.00015898314606945812,
      "loss": 0.5504,
      "step": 620650
    },
    {
      "epoch": 6.5710217498319405,
      "grad_norm": 1.2271676063537598,
      "learning_rate": 0.00015894012539593901,
      "loss": 0.5673,
      "step": 620700
    },
    {
      "epoch": 6.571551071611943,
      "grad_norm": 1.1352676153182983,
      "learning_rate": 0.0001588971078311706,
      "loss": 0.5638,
      "step": 620750
    },
    {
      "epoch": 6.572080393391947,
      "grad_norm": 1.2633980512619019,
      "learning_rate": 0.00015885409337662153,
      "loss": 0.5642,
      "step": 620800
    },
    {
      "epoch": 6.57260971517195,
      "grad_norm": 1.295341968536377,
      "learning_rate": 0.00015881108203376026,
      "loss": 0.5469,
      "step": 620850
    },
    {
      "epoch": 6.573139036951954,
      "grad_norm": 1.1544207334518433,
      "learning_rate": 0.00015876807380405528,
      "loss": 0.5617,
      "step": 620900
    },
    {
      "epoch": 6.573668358731957,
      "grad_norm": 1.1579123735427856,
      "learning_rate": 0.00015872506868897472,
      "loss": 0.5605,
      "step": 620950
    },
    {
      "epoch": 6.57419768051196,
      "grad_norm": 1.2850637435913086,
      "learning_rate": 0.00015868206668998692,
      "loss": 0.5661,
      "step": 621000
    },
    {
      "epoch": 6.57419768051196,
      "eval_loss": 0.35202503204345703,
      "eval_runtime": 47.3179,
      "eval_samples_per_second": 3548.973,
      "eval_steps_per_second": 443.637,
      "step": 621000
    },
    {
      "epoch": 6.574727002291963,
      "grad_norm": 1.1882091760635376,
      "learning_rate": 0.00015863906780855976,
      "loss": 0.56,
      "step": 621050
    },
    {
      "epoch": 6.575256324071967,
      "grad_norm": 1.259121060371399,
      "learning_rate": 0.00015859607204616143,
      "loss": 0.5515,
      "step": 621100
    },
    {
      "epoch": 6.57578564585197,
      "grad_norm": 1.2827467918395996,
      "learning_rate": 0.00015855307940425961,
      "loss": 0.5613,
      "step": 621150
    },
    {
      "epoch": 6.576314967631973,
      "grad_norm": 1.2454017400741577,
      "learning_rate": 0.0001585100898843222,
      "loss": 0.5574,
      "step": 621200
    },
    {
      "epoch": 6.5768442894119765,
      "grad_norm": 1.1603463888168335,
      "learning_rate": 0.00015846710348781668,
      "loss": 0.5497,
      "step": 621250
    },
    {
      "epoch": 6.577373611191979,
      "grad_norm": 1.2307208776474,
      "learning_rate": 0.00015842412021621074,
      "loss": 0.567,
      "step": 621300
    },
    {
      "epoch": 6.577902932971983,
      "grad_norm": 1.1679692268371582,
      "learning_rate": 0.00015838114007097167,
      "loss": 0.5629,
      "step": 621350
    },
    {
      "epoch": 6.578432254751986,
      "grad_norm": 1.2840157747268677,
      "learning_rate": 0.00015833816305356701,
      "loss": 0.5594,
      "step": 621400
    },
    {
      "epoch": 6.57896157653199,
      "grad_norm": 1.3048739433288574,
      "learning_rate": 0.0001582951891654637,
      "loss": 0.5586,
      "step": 621450
    },
    {
      "epoch": 6.579490898311993,
      "grad_norm": 1.2288174629211426,
      "learning_rate": 0.0001582522184081291,
      "loss": 0.5653,
      "step": 621500
    },
    {
      "epoch": 6.579490898311993,
      "eval_loss": 0.35119256377220154,
      "eval_runtime": 47.3701,
      "eval_samples_per_second": 3545.064,
      "eval_steps_per_second": 443.149,
      "step": 621500
    },
    {
      "epoch": 6.580020220091996,
      "grad_norm": 1.2597413063049316,
      "learning_rate": 0.00015820925078303006,
      "loss": 0.563,
      "step": 621550
    },
    {
      "epoch": 6.580549541871999,
      "grad_norm": 1.222588300704956,
      "learning_rate": 0.00015816628629163358,
      "loss": 0.5565,
      "step": 621600
    },
    {
      "epoch": 6.581078863652003,
      "grad_norm": 1.1304627656936646,
      "learning_rate": 0.00015812332493540638,
      "loss": 0.5554,
      "step": 621650
    },
    {
      "epoch": 6.581608185432006,
      "grad_norm": 1.0369758605957031,
      "learning_rate": 0.0001580803667158152,
      "loss": 0.5561,
      "step": 621700
    },
    {
      "epoch": 6.58213750721201,
      "grad_norm": 1.205658197402954,
      "learning_rate": 0.0001580374116343265,
      "loss": 0.5603,
      "step": 621750
    },
    {
      "epoch": 6.5826668289920125,
      "grad_norm": 1.3117446899414062,
      "learning_rate": 0.00015799445969240698,
      "loss": 0.552,
      "step": 621800
    },
    {
      "epoch": 6.583196150772016,
      "grad_norm": 1.2568027973175049,
      "learning_rate": 0.00015795236983674887,
      "loss": 0.5502,
      "step": 621850
    },
    {
      "epoch": 6.583725472552019,
      "grad_norm": 1.268278956413269,
      "learning_rate": 0.0001579094241155019,
      "loss": 0.5568,
      "step": 621900
    },
    {
      "epoch": 6.584254794332022,
      "grad_norm": 1.1185160875320435,
      "learning_rate": 0.00015786648153819343,
      "loss": 0.558,
      "step": 621950
    },
    {
      "epoch": 6.584784116112026,
      "grad_norm": 1.2725796699523926,
      "learning_rate": 0.00015782354210628954,
      "loss": 0.5611,
      "step": 622000
    },
    {
      "epoch": 6.584784116112026,
      "eval_loss": 0.3509269654750824,
      "eval_runtime": 47.6658,
      "eval_samples_per_second": 3523.068,
      "eval_steps_per_second": 440.399,
      "step": 622000
    },
    {
      "epoch": 6.585313437892029,
      "grad_norm": 1.2059924602508545,
      "learning_rate": 0.00015778060582125611,
      "loss": 0.5571,
      "step": 622050
    },
    {
      "epoch": 6.585842759672032,
      "grad_norm": 1.2335727214813232,
      "learning_rate": 0.0001577376726845589,
      "loss": 0.5579,
      "step": 622100
    },
    {
      "epoch": 6.586372081452035,
      "grad_norm": 1.2167664766311646,
      "learning_rate": 0.00015769474269766384,
      "loss": 0.5509,
      "step": 622150
    },
    {
      "epoch": 6.586901403232039,
      "grad_norm": 1.2407392263412476,
      "learning_rate": 0.0001576518158620363,
      "loss": 0.5593,
      "step": 622200
    },
    {
      "epoch": 6.587430725012042,
      "grad_norm": 1.2073167562484741,
      "learning_rate": 0.00015760889217914198,
      "loss": 0.5725,
      "step": 622250
    },
    {
      "epoch": 6.587960046792046,
      "grad_norm": 1.1909788846969604,
      "learning_rate": 0.0001575659716504461,
      "loss": 0.5533,
      "step": 622300
    },
    {
      "epoch": 6.5884893685720485,
      "grad_norm": 1.3098632097244263,
      "learning_rate": 0.0001575230542774142,
      "loss": 0.5723,
      "step": 622350
    },
    {
      "epoch": 6.589018690352052,
      "grad_norm": 1.2202309370040894,
      "learning_rate": 0.00015748014006151118,
      "loss": 0.5566,
      "step": 622400
    },
    {
      "epoch": 6.589548012132055,
      "grad_norm": 1.2762914896011353,
      "learning_rate": 0.0001574372290042023,
      "loss": 0.5565,
      "step": 622450
    },
    {
      "epoch": 6.590077333912059,
      "grad_norm": 1.222352147102356,
      "learning_rate": 0.00015739432110695246,
      "loss": 0.557,
      "step": 622500
    },
    {
      "epoch": 6.590077333912059,
      "eval_loss": 0.3530137538909912,
      "eval_runtime": 47.4401,
      "eval_samples_per_second": 3539.829,
      "eval_steps_per_second": 442.494,
      "step": 622500
    },
    {
      "epoch": 6.590606655692062,
      "grad_norm": 1.1127617359161377,
      "learning_rate": 0.00015735141637122658,
      "loss": 0.5541,
      "step": 622550
    },
    {
      "epoch": 6.5911359774720655,
      "grad_norm": 1.289902925491333,
      "learning_rate": 0.00015730851479848928,
      "loss": 0.5508,
      "step": 622600
    },
    {
      "epoch": 6.591665299252068,
      "grad_norm": 1.264543056488037,
      "learning_rate": 0.0001572656163902054,
      "loss": 0.55,
      "step": 622650
    },
    {
      "epoch": 6.592194621032071,
      "grad_norm": 1.3342201709747314,
      "learning_rate": 0.00015722272114783925,
      "loss": 0.5485,
      "step": 622700
    },
    {
      "epoch": 6.592723942812075,
      "grad_norm": 1.0615900754928589,
      "learning_rate": 0.00015717982907285545,
      "loss": 0.5531,
      "step": 622750
    },
    {
      "epoch": 6.593253264592078,
      "grad_norm": 1.2225892543792725,
      "learning_rate": 0.0001571369401667182,
      "loss": 0.5467,
      "step": 622800
    },
    {
      "epoch": 6.593782586372082,
      "grad_norm": 1.1746370792388916,
      "learning_rate": 0.0001570940544308918,
      "loss": 0.5606,
      "step": 622850
    },
    {
      "epoch": 6.5943119081520845,
      "grad_norm": 1.1213465929031372,
      "learning_rate": 0.00015705117186684027,
      "loss": 0.553,
      "step": 622900
    },
    {
      "epoch": 6.594841229932088,
      "grad_norm": 1.0797983407974243,
      "learning_rate": 0.00015700829247602768,
      "loss": 0.5627,
      "step": 622950
    },
    {
      "epoch": 6.595370551712091,
      "grad_norm": 1.1792906522750854,
      "learning_rate": 0.00015696541625991785,
      "loss": 0.5566,
      "step": 623000
    },
    {
      "epoch": 6.595370551712091,
      "eval_loss": 0.35070177912712097,
      "eval_runtime": 47.38,
      "eval_samples_per_second": 3544.321,
      "eval_steps_per_second": 443.056,
      "step": 623000
    },
    {
      "epoch": 6.595899873492095,
      "grad_norm": 1.4135253429412842,
      "learning_rate": 0.00015692254321997463,
      "loss": 0.5508,
      "step": 623050
    },
    {
      "epoch": 6.596429195272098,
      "grad_norm": 1.3433349132537842,
      "learning_rate": 0.00015687967335766158,
      "loss": 0.5518,
      "step": 623100
    },
    {
      "epoch": 6.5969585170521015,
      "grad_norm": 1.2081736326217651,
      "learning_rate": 0.00015683680667444245,
      "loss": 0.5727,
      "step": 623150
    },
    {
      "epoch": 6.597487838832104,
      "grad_norm": 1.1467067003250122,
      "learning_rate": 0.0001567939431717804,
      "loss": 0.5586,
      "step": 623200
    },
    {
      "epoch": 6.598017160612108,
      "grad_norm": 1.268265724182129,
      "learning_rate": 0.00015675108285113915,
      "loss": 0.561,
      "step": 623250
    },
    {
      "epoch": 6.598546482392111,
      "grad_norm": 1.1716575622558594,
      "learning_rate": 0.00015670822571398158,
      "loss": 0.5618,
      "step": 623300
    },
    {
      "epoch": 6.599075804172115,
      "grad_norm": 1.3458794355392456,
      "learning_rate": 0.00015666537176177106,
      "loss": 0.5612,
      "step": 623350
    },
    {
      "epoch": 6.599605125952118,
      "grad_norm": 1.245957374572754,
      "learning_rate": 0.00015662252099597044,
      "loss": 0.5634,
      "step": 623400
    },
    {
      "epoch": 6.60013444773212,
      "grad_norm": 1.1880309581756592,
      "learning_rate": 0.0001565796734180428,
      "loss": 0.5546,
      "step": 623450
    },
    {
      "epoch": 6.600663769512124,
      "grad_norm": 1.2033237218856812,
      "learning_rate": 0.00015653682902945073,
      "loss": 0.5619,
      "step": 623500
    },
    {
      "epoch": 6.600663769512124,
      "eval_loss": 0.35141247510910034,
      "eval_runtime": 47.4516,
      "eval_samples_per_second": 3538.974,
      "eval_steps_per_second": 442.388,
      "step": 623500
    },
    {
      "epoch": 6.601193091292127,
      "grad_norm": 1.1909759044647217,
      "learning_rate": 0.00015649398783165714,
      "loss": 0.5645,
      "step": 623550
    },
    {
      "epoch": 6.601722413072131,
      "grad_norm": 1.1323901414871216,
      "learning_rate": 0.00015645114982612446,
      "loss": 0.5522,
      "step": 623600
    },
    {
      "epoch": 6.602251734852134,
      "grad_norm": 1.158362865447998,
      "learning_rate": 0.00015640831501431525,
      "loss": 0.5516,
      "step": 623650
    },
    {
      "epoch": 6.602781056632137,
      "grad_norm": 1.2434546947479248,
      "learning_rate": 0.00015636548339769183,
      "loss": 0.5574,
      "step": 623700
    },
    {
      "epoch": 6.60331037841214,
      "grad_norm": 1.345133900642395,
      "learning_rate": 0.00015632265497771648,
      "loss": 0.5415,
      "step": 623750
    },
    {
      "epoch": 6.603839700192144,
      "grad_norm": 1.4004000425338745,
      "learning_rate": 0.00015627982975585127,
      "loss": 0.5617,
      "step": 623800
    },
    {
      "epoch": 6.604369021972147,
      "grad_norm": 1.203589916229248,
      "learning_rate": 0.00015623786414263897,
      "loss": 0.551,
      "step": 623850
    },
    {
      "epoch": 6.604898343752151,
      "grad_norm": 1.2736104726791382,
      "learning_rate": 0.00015619504525734519,
      "loss": 0.564,
      "step": 623900
    },
    {
      "epoch": 6.6054276655321535,
      "grad_norm": 1.2502204179763794,
      "learning_rate": 0.0001561522295745182,
      "loss": 0.5583,
      "step": 623950
    },
    {
      "epoch": 6.605956987312157,
      "grad_norm": 1.2978659868240356,
      "learning_rate": 0.0001561094170956196,
      "loss": 0.5658,
      "step": 624000
    },
    {
      "epoch": 6.605956987312157,
      "eval_loss": 0.35288211703300476,
      "eval_runtime": 47.215,
      "eval_samples_per_second": 3556.707,
      "eval_steps_per_second": 444.604,
      "step": 624000
    },
    {
      "epoch": 6.60648630909216,
      "grad_norm": 1.1898657083511353,
      "learning_rate": 0.00015606660782211117,
      "loss": 0.5605,
      "step": 624050
    },
    {
      "epoch": 6.607015630872164,
      "grad_norm": 1.2507728338241577,
      "learning_rate": 0.00015602380175545422,
      "loss": 0.5567,
      "step": 624100
    },
    {
      "epoch": 6.607544952652167,
      "grad_norm": 1.1765738725662231,
      "learning_rate": 0.00015598099889711027,
      "loss": 0.5455,
      "step": 624150
    },
    {
      "epoch": 6.60807427443217,
      "grad_norm": 1.2947221994400024,
      "learning_rate": 0.00015593819924854051,
      "loss": 0.5635,
      "step": 624200
    },
    {
      "epoch": 6.608603596212173,
      "grad_norm": 1.1932034492492676,
      "learning_rate": 0.00015589540281120613,
      "loss": 0.5634,
      "step": 624250
    },
    {
      "epoch": 6.609132917992176,
      "grad_norm": 1.3329025506973267,
      "learning_rate": 0.0001558526095865682,
      "loss": 0.5658,
      "step": 624300
    },
    {
      "epoch": 6.60966223977218,
      "grad_norm": 1.1231333017349243,
      "learning_rate": 0.00015580981957608763,
      "loss": 0.5552,
      "step": 624350
    },
    {
      "epoch": 6.610191561552183,
      "grad_norm": 1.1691076755523682,
      "learning_rate": 0.00015576703278122529,
      "loss": 0.5546,
      "step": 624400
    },
    {
      "epoch": 6.610720883332187,
      "grad_norm": 1.3524051904678345,
      "learning_rate": 0.00015572424920344191,
      "loss": 0.5591,
      "step": 624450
    },
    {
      "epoch": 6.6112502051121895,
      "grad_norm": 1.2477775812149048,
      "learning_rate": 0.00015568146884419805,
      "loss": 0.5516,
      "step": 624500
    },
    {
      "epoch": 6.6112502051121895,
      "eval_loss": 0.3513386845588684,
      "eval_runtime": 47.0132,
      "eval_samples_per_second": 3571.974,
      "eval_steps_per_second": 446.513,
      "step": 624500
    },
    {
      "epoch": 6.611779526892193,
      "grad_norm": 1.2582330703735352,
      "learning_rate": 0.00015563869170495432,
      "loss": 0.5605,
      "step": 624550
    },
    {
      "epoch": 6.612308848672196,
      "grad_norm": 1.169912576675415,
      "learning_rate": 0.00015559591778717093,
      "loss": 0.5592,
      "step": 624600
    },
    {
      "epoch": 6.6128381704522,
      "grad_norm": 1.2121424674987793,
      "learning_rate": 0.00015555314709230842,
      "loss": 0.5647,
      "step": 624650
    },
    {
      "epoch": 6.613367492232203,
      "grad_norm": 1.1843721866607666,
      "learning_rate": 0.00015551037962182674,
      "loss": 0.5629,
      "step": 624700
    },
    {
      "epoch": 6.6138968140122065,
      "grad_norm": 1.206421971321106,
      "learning_rate": 0.00015546761537718612,
      "loss": 0.5634,
      "step": 624750
    },
    {
      "epoch": 6.614426135792209,
      "grad_norm": 1.2613714933395386,
      "learning_rate": 0.00015542485435984633,
      "loss": 0.5544,
      "step": 624800
    },
    {
      "epoch": 6.614955457572213,
      "grad_norm": 1.2459025382995605,
      "learning_rate": 0.00015538209657126745,
      "loss": 0.5579,
      "step": 624850
    },
    {
      "epoch": 6.615484779352216,
      "grad_norm": 1.2950873374938965,
      "learning_rate": 0.000155339342012909,
      "loss": 0.569,
      "step": 624900
    },
    {
      "epoch": 6.616014101132219,
      "grad_norm": 1.1802711486816406,
      "learning_rate": 0.00015529659068623078,
      "loss": 0.5545,
      "step": 624950
    },
    {
      "epoch": 6.616543422912223,
      "grad_norm": 1.1886024475097656,
      "learning_rate": 0.00015525384259269215,
      "loss": 0.5506,
      "step": 625000
    },
    {
      "epoch": 6.616543422912223,
      "eval_loss": 0.3506740927696228,
      "eval_runtime": 46.9252,
      "eval_samples_per_second": 3578.675,
      "eval_steps_per_second": 447.35,
      "step": 625000
    },
    {
      "epoch": 6.6170727446922255,
      "grad_norm": 1.1312499046325684,
      "learning_rate": 0.00015521109773375258,
      "loss": 0.5592,
      "step": 625050
    },
    {
      "epoch": 6.617602066472229,
      "grad_norm": 1.3181136846542358,
      "learning_rate": 0.00015516835611087144,
      "loss": 0.5515,
      "step": 625100
    },
    {
      "epoch": 6.618131388252232,
      "grad_norm": 1.1903784275054932,
      "learning_rate": 0.0001551256177255078,
      "loss": 0.5614,
      "step": 625150
    },
    {
      "epoch": 6.618660710032236,
      "grad_norm": 1.1113929748535156,
      "learning_rate": 0.00015508288257912073,
      "loss": 0.5547,
      "step": 625200
    },
    {
      "epoch": 6.619190031812239,
      "grad_norm": 1.1331899166107178,
      "learning_rate": 0.00015504015067316934,
      "loss": 0.5509,
      "step": 625250
    },
    {
      "epoch": 6.6197193535922425,
      "grad_norm": 1.1462515592575073,
      "learning_rate": 0.00015499742200911231,
      "loss": 0.5523,
      "step": 625300
    },
    {
      "epoch": 6.620248675372245,
      "grad_norm": 1.1565769910812378,
      "learning_rate": 0.00015495469658840852,
      "loss": 0.5562,
      "step": 625350
    },
    {
      "epoch": 6.620777997152249,
      "grad_norm": 1.313234567642212,
      "learning_rate": 0.00015491197441251645,
      "loss": 0.5566,
      "step": 625400
    },
    {
      "epoch": 6.621307318932252,
      "grad_norm": 1.137497067451477,
      "learning_rate": 0.00015486925548289477,
      "loss": 0.5582,
      "step": 625450
    },
    {
      "epoch": 6.621836640712256,
      "grad_norm": 1.3611193895339966,
      "learning_rate": 0.00015482653980100175,
      "loss": 0.5601,
      "step": 625500
    },
    {
      "epoch": 6.621836640712256,
      "eval_loss": 0.35078343749046326,
      "eval_runtime": 46.9348,
      "eval_samples_per_second": 3577.94,
      "eval_steps_per_second": 447.259,
      "step": 625500
    },
    {
      "epoch": 6.622365962492259,
      "grad_norm": 1.3281313180923462,
      "learning_rate": 0.00015478382736829586,
      "loss": 0.5572,
      "step": 625550
    },
    {
      "epoch": 6.622895284272262,
      "grad_norm": 1.1402658224105835,
      "learning_rate": 0.00015474111818623506,
      "loss": 0.5479,
      "step": 625600
    },
    {
      "epoch": 6.623424606052265,
      "grad_norm": 1.3489161729812622,
      "learning_rate": 0.0001546984122562777,
      "loss": 0.5629,
      "step": 625650
    },
    {
      "epoch": 6.623953927832268,
      "grad_norm": 1.0747134685516357,
      "learning_rate": 0.00015465570957988141,
      "loss": 0.5603,
      "step": 625700
    },
    {
      "epoch": 6.624483249612272,
      "grad_norm": 1.1176930665969849,
      "learning_rate": 0.0001546130101585044,
      "loss": 0.556,
      "step": 625750
    },
    {
      "epoch": 6.625012571392275,
      "grad_norm": 1.269602656364441,
      "learning_rate": 0.0001545703139936041,
      "loss": 0.5492,
      "step": 625800
    },
    {
      "epoch": 6.6255418931722785,
      "grad_norm": 1.2329540252685547,
      "learning_rate": 0.00015452847491284047,
      "loss": 0.5532,
      "step": 625850
    },
    {
      "epoch": 6.626071214952281,
      "grad_norm": 1.3211721181869507,
      "learning_rate": 0.00015448578520006466,
      "loss": 0.5538,
      "step": 625900
    },
    {
      "epoch": 6.626600536732285,
      "grad_norm": 1.3290306329727173,
      "learning_rate": 0.00015444309874810899,
      "loss": 0.554,
      "step": 625950
    },
    {
      "epoch": 6.627129858512288,
      "grad_norm": 1.1827683448791504,
      "learning_rate": 0.00015440041555843102,
      "loss": 0.5621,
      "step": 626000
    },
    {
      "epoch": 6.627129858512288,
      "eval_loss": 0.3503621220588684,
      "eval_runtime": 47.0332,
      "eval_samples_per_second": 3570.459,
      "eval_steps_per_second": 446.323,
      "step": 626000
    },
    {
      "epoch": 6.627659180292292,
      "grad_norm": 1.1633388996124268,
      "learning_rate": 0.00015435773563248766,
      "loss": 0.5493,
      "step": 626050
    },
    {
      "epoch": 6.628188502072295,
      "grad_norm": 1.1620045900344849,
      "learning_rate": 0.00015431505897173624,
      "loss": 0.5532,
      "step": 626100
    },
    {
      "epoch": 6.628717823852298,
      "grad_norm": 1.2367370128631592,
      "learning_rate": 0.00015427238557763355,
      "loss": 0.5615,
      "step": 626150
    },
    {
      "epoch": 6.629247145632301,
      "grad_norm": 1.2297395467758179,
      "learning_rate": 0.00015422971545163658,
      "loss": 0.5563,
      "step": 626200
    },
    {
      "epoch": 6.629776467412305,
      "grad_norm": 1.1661062240600586,
      "learning_rate": 0.00015418704859520188,
      "loss": 0.5584,
      "step": 626250
    },
    {
      "epoch": 6.630305789192308,
      "grad_norm": 1.307754397392273,
      "learning_rate": 0.00015414438500978628,
      "loss": 0.5679,
      "step": 626300
    },
    {
      "epoch": 6.630835110972312,
      "grad_norm": 1.2394548654556274,
      "learning_rate": 0.00015410172469684625,
      "loss": 0.5502,
      "step": 626350
    },
    {
      "epoch": 6.6313644327523145,
      "grad_norm": 1.1884616613388062,
      "learning_rate": 0.0001540590676578381,
      "loss": 0.5627,
      "step": 626400
    },
    {
      "epoch": 6.631893754532317,
      "grad_norm": 1.2176423072814941,
      "learning_rate": 0.00015401641389421823,
      "loss": 0.5545,
      "step": 626450
    },
    {
      "epoch": 6.632423076312321,
      "grad_norm": 1.1264396905899048,
      "learning_rate": 0.00015397461638505584,
      "loss": 0.5523,
      "step": 626500
    },
    {
      "epoch": 6.632423076312321,
      "eval_loss": 0.3498917520046234,
      "eval_runtime": 46.9009,
      "eval_samples_per_second": 3580.528,
      "eval_steps_per_second": 447.582,
      "step": 626500
    },
    {
      "epoch": 6.632952398092324,
      "grad_norm": 1.2144320011138916,
      "learning_rate": 0.00015393196911100065,
      "loss": 0.5582,
      "step": 626550
    },
    {
      "epoch": 6.633481719872328,
      "grad_norm": 1.1985113620758057,
      "learning_rate": 0.00015388932511667275,
      "loss": 0.556,
      "step": 626600
    },
    {
      "epoch": 6.634011041652331,
      "grad_norm": 1.271028995513916,
      "learning_rate": 0.00015384668440352806,
      "loss": 0.564,
      "step": 626650
    },
    {
      "epoch": 6.634540363432334,
      "grad_norm": 1.197048544883728,
      "learning_rate": 0.0001538040469730223,
      "loss": 0.5442,
      "step": 626700
    },
    {
      "epoch": 6.635069685212337,
      "grad_norm": 1.3066314458847046,
      "learning_rate": 0.00015376141282661112,
      "loss": 0.5643,
      "step": 626750
    },
    {
      "epoch": 6.635599006992341,
      "grad_norm": 1.2509663105010986,
      "learning_rate": 0.00015371878196574995,
      "loss": 0.5669,
      "step": 626800
    },
    {
      "epoch": 6.636128328772344,
      "grad_norm": 1.3006150722503662,
      "learning_rate": 0.00015367615439189437,
      "loss": 0.5532,
      "step": 626850
    },
    {
      "epoch": 6.636657650552348,
      "grad_norm": 1.1970359086990356,
      "learning_rate": 0.00015363353010649944,
      "loss": 0.5557,
      "step": 626900
    },
    {
      "epoch": 6.63718697233235,
      "grad_norm": 1.216745138168335,
      "learning_rate": 0.00015359090911102054,
      "loss": 0.5632,
      "step": 626950
    },
    {
      "epoch": 6.637716294112354,
      "grad_norm": 1.2656097412109375,
      "learning_rate": 0.00015354829140691256,
      "loss": 0.5647,
      "step": 627000
    },
    {
      "epoch": 6.637716294112354,
      "eval_loss": 0.35096776485443115,
      "eval_runtime": 47.4665,
      "eval_samples_per_second": 3537.865,
      "eval_steps_per_second": 442.249,
      "step": 627000
    },
    {
      "epoch": 6.638245615892357,
      "grad_norm": 1.3078157901763916,
      "learning_rate": 0.0001535056769956306,
      "loss": 0.5511,
      "step": 627050
    },
    {
      "epoch": 6.638774937672361,
      "grad_norm": 1.277806043624878,
      "learning_rate": 0.0001534630658786294,
      "loss": 0.567,
      "step": 627100
    },
    {
      "epoch": 6.639304259452364,
      "grad_norm": 1.1735336780548096,
      "learning_rate": 0.0001534204580573638,
      "loss": 0.5526,
      "step": 627150
    },
    {
      "epoch": 6.6398335812323666,
      "grad_norm": 1.1458128690719604,
      "learning_rate": 0.00015337785353328824,
      "loss": 0.564,
      "step": 627200
    },
    {
      "epoch": 6.64036290301237,
      "grad_norm": 1.202994704246521,
      "learning_rate": 0.00015333525230785744,
      "loss": 0.559,
      "step": 627250
    },
    {
      "epoch": 6.640892224792373,
      "grad_norm": 1.1702104806900024,
      "learning_rate": 0.00015329265438252554,
      "loss": 0.5667,
      "step": 627300
    },
    {
      "epoch": 6.641421546572377,
      "grad_norm": 1.193487524986267,
      "learning_rate": 0.00015325005975874706,
      "loss": 0.5544,
      "step": 627350
    },
    {
      "epoch": 6.64195086835238,
      "grad_norm": 1.1538619995117188,
      "learning_rate": 0.000153207468437976,
      "loss": 0.5537,
      "step": 627400
    },
    {
      "epoch": 6.6424801901323836,
      "grad_norm": 1.248368263244629,
      "learning_rate": 0.0001531648804216665,
      "loss": 0.5571,
      "step": 627450
    },
    {
      "epoch": 6.643009511912386,
      "grad_norm": 1.2448455095291138,
      "learning_rate": 0.00015312229571127245,
      "loss": 0.5451,
      "step": 627500
    },
    {
      "epoch": 6.643009511912386,
      "eval_loss": 0.3491328954696655,
      "eval_runtime": 47.5913,
      "eval_samples_per_second": 3528.589,
      "eval_steps_per_second": 441.089,
      "step": 627500
    },
    {
      "epoch": 6.64353883369239,
      "grad_norm": 1.2990888357162476,
      "learning_rate": 0.0001530797143082477,
      "loss": 0.5492,
      "step": 627550
    },
    {
      "epoch": 6.644068155472393,
      "grad_norm": 1.2676701545715332,
      "learning_rate": 0.00015303713621404598,
      "loss": 0.5641,
      "step": 627600
    },
    {
      "epoch": 6.644597477252397,
      "grad_norm": 1.2533414363861084,
      "learning_rate": 0.00015299456143012086,
      "loss": 0.56,
      "step": 627650
    },
    {
      "epoch": 6.6451267990324,
      "grad_norm": 1.2327022552490234,
      "learning_rate": 0.00015295198995792574,
      "loss": 0.5584,
      "step": 627700
    },
    {
      "epoch": 6.645656120812403,
      "grad_norm": 1.2412681579589844,
      "learning_rate": 0.00015290942179891427,
      "loss": 0.5575,
      "step": 627750
    },
    {
      "epoch": 6.646185442592406,
      "grad_norm": 1.2358952760696411,
      "learning_rate": 0.0001528668569545394,
      "loss": 0.5546,
      "step": 627800
    },
    {
      "epoch": 6.64671476437241,
      "grad_norm": 1.1688165664672852,
      "learning_rate": 0.0001528242954262545,
      "loss": 0.5618,
      "step": 627850
    },
    {
      "epoch": 6.647244086152413,
      "grad_norm": 1.372470498085022,
      "learning_rate": 0.0001527817372155124,
      "loss": 0.549,
      "step": 627900
    },
    {
      "epoch": 6.647773407932416,
      "grad_norm": 0.928502082824707,
      "learning_rate": 0.00015273918232376626,
      "loss": 0.5588,
      "step": 627950
    },
    {
      "epoch": 6.6483027297124195,
      "grad_norm": 1.2258230447769165,
      "learning_rate": 0.0001526966307524687,
      "loss": 0.5611,
      "step": 628000
    },
    {
      "epoch": 6.6483027297124195,
      "eval_loss": 0.34982460737228394,
      "eval_runtime": 46.8995,
      "eval_samples_per_second": 3580.635,
      "eval_steps_per_second": 447.595,
      "step": 628000
    },
    {
      "epoch": 6.648832051492422,
      "grad_norm": 1.2144770622253418,
      "learning_rate": 0.00015265408250307255,
      "loss": 0.5498,
      "step": 628050
    },
    {
      "epoch": 6.649361373272426,
      "grad_norm": 1.120396614074707,
      "learning_rate": 0.00015261153757703023,
      "loss": 0.5637,
      "step": 628100
    },
    {
      "epoch": 6.649890695052429,
      "grad_norm": 1.2716522216796875,
      "learning_rate": 0.00015256899597579438,
      "loss": 0.5579,
      "step": 628150
    },
    {
      "epoch": 6.650420016832433,
      "grad_norm": 1.1394797563552856,
      "learning_rate": 0.00015252645770081718,
      "loss": 0.547,
      "step": 628200
    },
    {
      "epoch": 6.650949338612436,
      "grad_norm": 1.254058599472046,
      "learning_rate": 0.00015248392275355108,
      "loss": 0.5602,
      "step": 628250
    },
    {
      "epoch": 6.651478660392439,
      "grad_norm": 1.1627010107040405,
      "learning_rate": 0.00015244139113544796,
      "loss": 0.5617,
      "step": 628300
    },
    {
      "epoch": 6.652007982172442,
      "grad_norm": 1.2307446002960205,
      "learning_rate": 0.00015239886284796006,
      "loss": 0.5551,
      "step": 628350
    },
    {
      "epoch": 6.652537303952446,
      "grad_norm": 1.2445611953735352,
      "learning_rate": 0.0001523563378925392,
      "loss": 0.5581,
      "step": 628400
    },
    {
      "epoch": 6.653066625732449,
      "grad_norm": 1.2138137817382812,
      "learning_rate": 0.0001523138162706371,
      "loss": 0.5448,
      "step": 628450
    },
    {
      "epoch": 6.653595947512453,
      "grad_norm": 1.4009623527526855,
      "learning_rate": 0.0001522712979837055,
      "loss": 0.5657,
      "step": 628500
    },
    {
      "epoch": 6.653595947512453,
      "eval_loss": 0.34884461760520935,
      "eval_runtime": 46.9434,
      "eval_samples_per_second": 3577.288,
      "eval_steps_per_second": 447.177,
      "step": 628500
    },
    {
      "epoch": 6.6541252692924555,
      "grad_norm": 1.2748218774795532,
      "learning_rate": 0.000152228783033196,
      "loss": 0.5585,
      "step": 628550
    },
    {
      "epoch": 6.654654591072459,
      "grad_norm": 1.2750439643859863,
      "learning_rate": 0.00015218627142055992,
      "loss": 0.5502,
      "step": 628600
    },
    {
      "epoch": 6.655183912852462,
      "grad_norm": 1.2568577527999878,
      "learning_rate": 0.00015214376314724872,
      "loss": 0.5516,
      "step": 628650
    },
    {
      "epoch": 6.655713234632465,
      "grad_norm": 1.103827714920044,
      "learning_rate": 0.0001521012582147135,
      "loss": 0.5506,
      "step": 628700
    },
    {
      "epoch": 6.656242556412469,
      "grad_norm": 1.2507959604263306,
      "learning_rate": 0.0001520587566244055,
      "loss": 0.5487,
      "step": 628750
    },
    {
      "epoch": 6.656771878192472,
      "grad_norm": 1.1171255111694336,
      "learning_rate": 0.00015201625837777554,
      "loss": 0.549,
      "step": 628800
    },
    {
      "epoch": 6.657301199972475,
      "grad_norm": 1.2550041675567627,
      "learning_rate": 0.00015197376347627468,
      "loss": 0.5598,
      "step": 628850
    },
    {
      "epoch": 6.657830521752478,
      "grad_norm": 1.1495822668075562,
      "learning_rate": 0.00015193127192135347,
      "loss": 0.5572,
      "step": 628900
    },
    {
      "epoch": 6.658359843532482,
      "grad_norm": 1.2694494724273682,
      "learning_rate": 0.0001518887837144627,
      "loss": 0.5563,
      "step": 628950
    },
    {
      "epoch": 6.658889165312485,
      "grad_norm": 1.1624770164489746,
      "learning_rate": 0.00015184629885705295,
      "loss": 0.5543,
      "step": 629000
    },
    {
      "epoch": 6.658889165312485,
      "eval_loss": 0.34865260124206543,
      "eval_runtime": 46.9719,
      "eval_samples_per_second": 3575.119,
      "eval_steps_per_second": 446.906,
      "step": 629000
    },
    {
      "epoch": 6.659418487092489,
      "grad_norm": 1.2201133966445923,
      "learning_rate": 0.00015180381735057448,
      "loss": 0.5485,
      "step": 629050
    },
    {
      "epoch": 6.6599478088724915,
      "grad_norm": 1.0919225215911865,
      "learning_rate": 0.00015176133919647775,
      "loss": 0.5527,
      "step": 629100
    },
    {
      "epoch": 6.660477130652495,
      "grad_norm": 1.1459856033325195,
      "learning_rate": 0.0001517188643962128,
      "loss": 0.561,
      "step": 629150
    },
    {
      "epoch": 6.661006452432498,
      "grad_norm": 1.1746774911880493,
      "learning_rate": 0.00015167639295122985,
      "loss": 0.5622,
      "step": 629200
    },
    {
      "epoch": 6.661535774212502,
      "grad_norm": 1.2673819065093994,
      "learning_rate": 0.00015163392486297866,
      "loss": 0.5475,
      "step": 629250
    },
    {
      "epoch": 6.662065095992505,
      "grad_norm": 1.2698500156402588,
      "learning_rate": 0.0001515914601329093,
      "loss": 0.5595,
      "step": 629300
    },
    {
      "epoch": 6.6625944177725085,
      "grad_norm": 1.213563323020935,
      "learning_rate": 0.0001515489987624714,
      "loss": 0.5623,
      "step": 629350
    },
    {
      "epoch": 6.663123739552511,
      "grad_norm": 1.167825698852539,
      "learning_rate": 0.00015150654075311455,
      "loss": 0.5634,
      "step": 629400
    },
    {
      "epoch": 6.663653061332514,
      "grad_norm": 1.1658039093017578,
      "learning_rate": 0.00015146408610628825,
      "loss": 0.5604,
      "step": 629450
    },
    {
      "epoch": 6.664182383112518,
      "grad_norm": 1.1621299982070923,
      "learning_rate": 0.00015142163482344202,
      "loss": 0.5615,
      "step": 629500
    },
    {
      "epoch": 6.664182383112518,
      "eval_loss": 0.34849032759666443,
      "eval_runtime": 46.9139,
      "eval_samples_per_second": 3579.533,
      "eval_steps_per_second": 447.458,
      "step": 629500
    },
    {
      "epoch": 6.664711704892521,
      "grad_norm": 1.2198765277862549,
      "learning_rate": 0.00015137918690602488,
      "loss": 0.5554,
      "step": 629550
    },
    {
      "epoch": 6.665241026672525,
      "grad_norm": 1.2540091276168823,
      "learning_rate": 0.0001513367423554863,
      "loss": 0.558,
      "step": 629600
    },
    {
      "epoch": 6.6657703484525275,
      "grad_norm": 1.142471194267273,
      "learning_rate": 0.00015129430117327496,
      "loss": 0.5579,
      "step": 629650
    },
    {
      "epoch": 6.666299670232531,
      "grad_norm": 1.2914422750473022,
      "learning_rate": 0.00015125186336084016,
      "loss": 0.5547,
      "step": 629700
    },
    {
      "epoch": 6.666828992012534,
      "grad_norm": 1.2392241954803467,
      "learning_rate": 0.00015120942891963039,
      "loss": 0.5587,
      "step": 629750
    },
    {
      "epoch": 6.667358313792538,
      "grad_norm": 1.1576679944992065,
      "learning_rate": 0.0001511669978510946,
      "loss": 0.5526,
      "step": 629800
    },
    {
      "epoch": 6.667887635572541,
      "grad_norm": 1.2698850631713867,
      "learning_rate": 0.00015112457015668113,
      "loss": 0.5507,
      "step": 629850
    },
    {
      "epoch": 6.6684169573525445,
      "grad_norm": 1.110384464263916,
      "learning_rate": 0.0001510821458378387,
      "loss": 0.564,
      "step": 629900
    },
    {
      "epoch": 6.668946279132547,
      "grad_norm": 1.3074867725372314,
      "learning_rate": 0.00015103972489601545,
      "loss": 0.5509,
      "step": 629950
    },
    {
      "epoch": 6.669475600912551,
      "grad_norm": 1.2373409271240234,
      "learning_rate": 0.00015099730733265977,
      "loss": 0.5673,
      "step": 630000
    },
    {
      "epoch": 6.669475600912551,
      "eval_loss": 0.34970489144325256,
      "eval_runtime": 47.1179,
      "eval_samples_per_second": 3564.041,
      "eval_steps_per_second": 445.521,
      "step": 630000
    },
    {
      "epoch": 6.670004922692554,
      "grad_norm": 1.17368483543396,
      "learning_rate": 0.00015095489314921961,
      "loss": 0.5546,
      "step": 630050
    },
    {
      "epoch": 6.670534244472558,
      "grad_norm": 1.064462661743164,
      "learning_rate": 0.00015091248234714314,
      "loss": 0.5605,
      "step": 630100
    },
    {
      "epoch": 6.671063566252561,
      "grad_norm": 1.207970380783081,
      "learning_rate": 0.0001508700749278782,
      "loss": 0.5494,
      "step": 630150
    },
    {
      "epoch": 6.6715928880325635,
      "grad_norm": 1.2053900957107544,
      "learning_rate": 0.0001508276708928725,
      "loss": 0.5483,
      "step": 630200
    },
    {
      "epoch": 6.672122209812567,
      "grad_norm": 1.2692334651947021,
      "learning_rate": 0.00015078527024357376,
      "loss": 0.5632,
      "step": 630250
    },
    {
      "epoch": 6.67265153159257,
      "grad_norm": 1.2434134483337402,
      "learning_rate": 0.00015074287298142954,
      "loss": 0.5549,
      "step": 630300
    },
    {
      "epoch": 6.673180853372574,
      "grad_norm": 1.214842438697815,
      "learning_rate": 0.00015070047910788716,
      "loss": 0.5538,
      "step": 630350
    },
    {
      "epoch": 6.673710175152577,
      "grad_norm": 1.2542595863342285,
      "learning_rate": 0.00015065808862439408,
      "loss": 0.5589,
      "step": 630400
    },
    {
      "epoch": 6.6742394969325805,
      "grad_norm": 1.3046497106552124,
      "learning_rate": 0.00015061570153239738,
      "loss": 0.5588,
      "step": 630450
    },
    {
      "epoch": 6.674768818712583,
      "grad_norm": 1.1470921039581299,
      "learning_rate": 0.00015057416547406509,
      "loss": 0.5581,
      "step": 630500
    },
    {
      "epoch": 6.674768818712583,
      "eval_loss": 0.3498500883579254,
      "eval_runtime": 47.3712,
      "eval_samples_per_second": 3544.979,
      "eval_steps_per_second": 443.138,
      "step": 630500
    },
    {
      "epoch": 6.675298140492587,
      "grad_norm": 1.1548686027526855,
      "learning_rate": 0.00015053178510150038,
      "loss": 0.5571,
      "step": 630550
    },
    {
      "epoch": 6.67582746227259,
      "grad_norm": 1.137345790863037,
      "learning_rate": 0.00015048940812474403,
      "loss": 0.5455,
      "step": 630600
    },
    {
      "epoch": 6.676356784052594,
      "grad_norm": 1.120661973953247,
      "learning_rate": 0.00015044703454524284,
      "loss": 0.5589,
      "step": 630650
    },
    {
      "epoch": 6.676886105832597,
      "grad_norm": 0.9738648533821106,
      "learning_rate": 0.0001504046643644433,
      "loss": 0.5621,
      "step": 630700
    },
    {
      "epoch": 6.6774154276126,
      "grad_norm": 1.2769134044647217,
      "learning_rate": 0.0001503622975837921,
      "loss": 0.5527,
      "step": 630750
    },
    {
      "epoch": 6.677944749392603,
      "grad_norm": 1.2139772176742554,
      "learning_rate": 0.00015031993420473543,
      "loss": 0.5616,
      "step": 630800
    },
    {
      "epoch": 6.678474071172607,
      "grad_norm": 1.3008712530136108,
      "learning_rate": 0.00015027757422871973,
      "loss": 0.5486,
      "step": 630850
    },
    {
      "epoch": 6.67900339295261,
      "grad_norm": 1.1933420896530151,
      "learning_rate": 0.000150235217657191,
      "loss": 0.5541,
      "step": 630900
    },
    {
      "epoch": 6.679532714732613,
      "grad_norm": 1.2933820486068726,
      "learning_rate": 0.00015019286449159542,
      "loss": 0.5543,
      "step": 630950
    },
    {
      "epoch": 6.680062036512616,
      "grad_norm": 1.1944429874420166,
      "learning_rate": 0.00015015051473337877,
      "loss": 0.5596,
      "step": 631000
    },
    {
      "epoch": 6.680062036512616,
      "eval_loss": 0.34805265069007874,
      "eval_runtime": 47.2746,
      "eval_samples_per_second": 3552.226,
      "eval_steps_per_second": 444.044,
      "step": 631000
    },
    {
      "epoch": 6.680591358292619,
      "grad_norm": 1.2587958574295044,
      "learning_rate": 0.000150108168383987,
      "loss": 0.5519,
      "step": 631050
    },
    {
      "epoch": 6.681120680072623,
      "grad_norm": 1.1790388822555542,
      "learning_rate": 0.00015006582544486565,
      "loss": 0.5556,
      "step": 631100
    },
    {
      "epoch": 6.681650001852626,
      "grad_norm": 1.2244070768356323,
      "learning_rate": 0.00015002348591746045,
      "loss": 0.5554,
      "step": 631150
    },
    {
      "epoch": 6.68217932363263,
      "grad_norm": 1.1014238595962524,
      "learning_rate": 0.0001499811498032167,
      "loss": 0.5513,
      "step": 631200
    },
    {
      "epoch": 6.6827086454126325,
      "grad_norm": 1.3383153676986694,
      "learning_rate": 0.00014993881710357993,
      "loss": 0.5529,
      "step": 631250
    },
    {
      "epoch": 6.683237967192636,
      "grad_norm": 1.3225047588348389,
      "learning_rate": 0.0001498964878199951,
      "loss": 0.55,
      "step": 631300
    },
    {
      "epoch": 6.683767288972639,
      "grad_norm": 1.2744519710540771,
      "learning_rate": 0.00014985416195390755,
      "loss": 0.5564,
      "step": 631350
    },
    {
      "epoch": 6.684296610752643,
      "grad_norm": 1.3842899799346924,
      "learning_rate": 0.00014981183950676217,
      "loss": 0.5506,
      "step": 631400
    },
    {
      "epoch": 6.684825932532646,
      "grad_norm": 1.204589605331421,
      "learning_rate": 0.00014976952048000383,
      "loss": 0.5511,
      "step": 631450
    },
    {
      "epoch": 6.6853552543126495,
      "grad_norm": 1.2205045223236084,
      "learning_rate": 0.00014972720487507732,
      "loss": 0.5519,
      "step": 631500
    },
    {
      "epoch": 6.6853552543126495,
      "eval_loss": 0.34837377071380615,
      "eval_runtime": 47.0935,
      "eval_samples_per_second": 3565.886,
      "eval_steps_per_second": 445.752,
      "step": 631500
    },
    {
      "epoch": 6.685884576092652,
      "grad_norm": 1.3042734861373901,
      "learning_rate": 0.0001496848926934273,
      "loss": 0.5609,
      "step": 631550
    },
    {
      "epoch": 6.686413897872656,
      "grad_norm": 1.373515009880066,
      "learning_rate": 0.00014964258393649813,
      "loss": 0.5643,
      "step": 631600
    },
    {
      "epoch": 6.686943219652659,
      "grad_norm": 1.249017596244812,
      "learning_rate": 0.00014960027860573446,
      "loss": 0.5566,
      "step": 631650
    },
    {
      "epoch": 6.687472541432662,
      "grad_norm": 1.2790544033050537,
      "learning_rate": 0.00014955797670258036,
      "loss": 0.5513,
      "step": 631700
    },
    {
      "epoch": 6.688001863212666,
      "grad_norm": 1.2054657936096191,
      "learning_rate": 0.00014951567822848023,
      "loss": 0.5552,
      "step": 631750
    },
    {
      "epoch": 6.6885311849926685,
      "grad_norm": 1.27021324634552,
      "learning_rate": 0.00014947338318487785,
      "loss": 0.5624,
      "step": 631800
    },
    {
      "epoch": 6.689060506772672,
      "grad_norm": 1.1840382814407349,
      "learning_rate": 0.00014943109157321743,
      "loss": 0.5569,
      "step": 631850
    },
    {
      "epoch": 6.689589828552675,
      "grad_norm": 1.291900634765625,
      "learning_rate": 0.00014938880339494256,
      "loss": 0.5623,
      "step": 631900
    },
    {
      "epoch": 6.690119150332679,
      "grad_norm": 1.3554562330245972,
      "learning_rate": 0.00014934651865149715,
      "loss": 0.5441,
      "step": 631950
    },
    {
      "epoch": 6.690648472112682,
      "grad_norm": 1.2886489629745483,
      "learning_rate": 0.00014930423734432457,
      "loss": 0.5472,
      "step": 632000
    },
    {
      "epoch": 6.690648472112682,
      "eval_loss": 0.34718552231788635,
      "eval_runtime": 46.9917,
      "eval_samples_per_second": 3573.612,
      "eval_steps_per_second": 446.717,
      "step": 632000
    },
    {
      "epoch": 6.6911777938926855,
      "grad_norm": 1.1172431707382202,
      "learning_rate": 0.00014926195947486849,
      "loss": 0.5576,
      "step": 632050
    },
    {
      "epoch": 6.691707115672688,
      "grad_norm": 1.198728084564209,
      "learning_rate": 0.00014921968504457206,
      "loss": 0.5615,
      "step": 632100
    },
    {
      "epoch": 6.692236437452692,
      "grad_norm": 1.2348731756210327,
      "learning_rate": 0.00014917741405487875,
      "loss": 0.5575,
      "step": 632150
    },
    {
      "epoch": 6.692765759232695,
      "grad_norm": 1.317145824432373,
      "learning_rate": 0.00014913599182444305,
      "loss": 0.5559,
      "step": 632200
    },
    {
      "epoch": 6.693295081012699,
      "grad_norm": 1.2145500183105469,
      "learning_rate": 0.0001490937276514009,
      "loss": 0.5564,
      "step": 632250
    },
    {
      "epoch": 6.693824402792702,
      "grad_norm": 1.230621576309204,
      "learning_rate": 0.000149051466923262,
      "loss": 0.5566,
      "step": 632300
    },
    {
      "epoch": 6.694353724572705,
      "grad_norm": 1.1939693689346313,
      "learning_rate": 0.00014900920964146892,
      "loss": 0.5475,
      "step": 632350
    },
    {
      "epoch": 6.694883046352708,
      "grad_norm": 1.2027065753936768,
      "learning_rate": 0.00014896695580746445,
      "loss": 0.5451,
      "step": 632400
    },
    {
      "epoch": 6.695412368132711,
      "grad_norm": 1.2182776927947998,
      "learning_rate": 0.00014892470542269098,
      "loss": 0.5512,
      "step": 632450
    },
    {
      "epoch": 6.695941689912715,
      "grad_norm": 1.2138487100601196,
      "learning_rate": 0.0001488824584885911,
      "loss": 0.5427,
      "step": 632500
    },
    {
      "epoch": 6.695941689912715,
      "eval_loss": 0.34761878848075867,
      "eval_runtime": 47.6391,
      "eval_samples_per_second": 3525.045,
      "eval_steps_per_second": 440.646,
      "step": 632500
    },
    {
      "epoch": 6.696471011692718,
      "grad_norm": 1.1706633567810059,
      "learning_rate": 0.00014884021500660688,
      "loss": 0.5412,
      "step": 632550
    },
    {
      "epoch": 6.6970003334727215,
      "grad_norm": 1.1570680141448975,
      "learning_rate": 0.00014879797497818067,
      "loss": 0.5437,
      "step": 632600
    },
    {
      "epoch": 6.697529655252724,
      "grad_norm": 1.2007367610931396,
      "learning_rate": 0.0001487557384047545,
      "loss": 0.558,
      "step": 632650
    },
    {
      "epoch": 6.698058977032728,
      "grad_norm": 1.1581594944000244,
      "learning_rate": 0.00014871350528777028,
      "loss": 0.5628,
      "step": 632700
    },
    {
      "epoch": 6.698588298812731,
      "grad_norm": 1.2059050798416138,
      "learning_rate": 0.00014867127562866986,
      "loss": 0.5506,
      "step": 632750
    },
    {
      "epoch": 6.699117620592735,
      "grad_norm": 1.2008501291275024,
      "learning_rate": 0.0001486290494288949,
      "loss": 0.5572,
      "step": 632800
    },
    {
      "epoch": 6.699646942372738,
      "grad_norm": 1.3318488597869873,
      "learning_rate": 0.000148586826689887,
      "loss": 0.546,
      "step": 632850
    },
    {
      "epoch": 6.700176264152741,
      "grad_norm": 1.11030912399292,
      "learning_rate": 0.00014854460741308773,
      "loss": 0.5535,
      "step": 632900
    },
    {
      "epoch": 6.700705585932744,
      "grad_norm": 1.2451874017715454,
      "learning_rate": 0.00014850239159993822,
      "loss": 0.5552,
      "step": 632950
    },
    {
      "epoch": 6.701234907712748,
      "grad_norm": 1.292966365814209,
      "learning_rate": 0.00014846017925188,
      "loss": 0.5583,
      "step": 633000
    },
    {
      "epoch": 6.701234907712748,
      "eval_loss": 0.3469131886959076,
      "eval_runtime": 47.6153,
      "eval_samples_per_second": 3526.805,
      "eval_steps_per_second": 440.866,
      "step": 633000
    },
    {
      "epoch": 6.701764229492751,
      "grad_norm": 1.285094976425171,
      "learning_rate": 0.00014841797037035387,
      "loss": 0.5584,
      "step": 633050
    },
    {
      "epoch": 6.702293551272755,
      "grad_norm": 1.1273013353347778,
      "learning_rate": 0.0001483757649568011,
      "loss": 0.5626,
      "step": 633100
    },
    {
      "epoch": 6.7028228730527575,
      "grad_norm": 1.238590955734253,
      "learning_rate": 0.00014833356301266235,
      "loss": 0.5531,
      "step": 633150
    },
    {
      "epoch": 6.70335219483276,
      "grad_norm": 1.2529596090316772,
      "learning_rate": 0.00014829136453937858,
      "loss": 0.5494,
      "step": 633200
    },
    {
      "epoch": 6.703881516612764,
      "grad_norm": 1.243489384651184,
      "learning_rate": 0.00014824916953839017,
      "loss": 0.5393,
      "step": 633250
    },
    {
      "epoch": 6.704410838392767,
      "grad_norm": 1.347808837890625,
      "learning_rate": 0.00014820697801113796,
      "loss": 0.5584,
      "step": 633300
    },
    {
      "epoch": 6.704940160172771,
      "grad_norm": 1.303834080696106,
      "learning_rate": 0.00014816478995906209,
      "loss": 0.5533,
      "step": 633350
    },
    {
      "epoch": 6.705469481952774,
      "grad_norm": 1.3142402172088623,
      "learning_rate": 0.000148122605383603,
      "loss": 0.5463,
      "step": 633400
    },
    {
      "epoch": 6.705998803732777,
      "grad_norm": 1.1684190034866333,
      "learning_rate": 0.00014808042428620072,
      "loss": 0.5487,
      "step": 633450
    },
    {
      "epoch": 6.70652812551278,
      "grad_norm": 1.0666718482971191,
      "learning_rate": 0.00014803824666829543,
      "loss": 0.553,
      "step": 633500
    },
    {
      "epoch": 6.70652812551278,
      "eval_loss": 0.3473145365715027,
      "eval_runtime": 47.6023,
      "eval_samples_per_second": 3527.768,
      "eval_steps_per_second": 440.987,
      "step": 633500
    },
    {
      "epoch": 6.707057447292784,
      "grad_norm": 1.1054165363311768,
      "learning_rate": 0.000147996072531327,
      "loss": 0.5636,
      "step": 633550
    },
    {
      "epoch": 6.707586769072787,
      "grad_norm": 1.199925184249878,
      "learning_rate": 0.00014795390187673525,
      "loss": 0.5525,
      "step": 633600
    },
    {
      "epoch": 6.708116090852791,
      "grad_norm": 1.2062782049179077,
      "learning_rate": 0.0001479117347059598,
      "loss": 0.5578,
      "step": 633650
    },
    {
      "epoch": 6.7086454126327935,
      "grad_norm": 1.179509162902832,
      "learning_rate": 0.0001478695710204404,
      "loss": 0.5515,
      "step": 633700
    },
    {
      "epoch": 6.709174734412797,
      "grad_norm": 1.1789320707321167,
      "learning_rate": 0.0001478274108216163,
      "loss": 0.5603,
      "step": 633750
    },
    {
      "epoch": 6.7097040561928,
      "grad_norm": 1.1823921203613281,
      "learning_rate": 0.00014778525411092704,
      "loss": 0.5509,
      "step": 633800
    },
    {
      "epoch": 6.710233377972804,
      "grad_norm": 1.3855570554733276,
      "learning_rate": 0.00014774310088981157,
      "loss": 0.5461,
      "step": 633850
    },
    {
      "epoch": 6.710762699752807,
      "grad_norm": 1.1931030750274658,
      "learning_rate": 0.00014770095115970925,
      "loss": 0.5517,
      "step": 633900
    },
    {
      "epoch": 6.71129202153281,
      "grad_norm": 1.163407802581787,
      "learning_rate": 0.00014765880492205886,
      "loss": 0.5485,
      "step": 633950
    },
    {
      "epoch": 6.711821343312813,
      "grad_norm": 1.1314619779586792,
      "learning_rate": 0.0001476166621782994,
      "loss": 0.5515,
      "step": 634000
    },
    {
      "epoch": 6.711821343312813,
      "eval_loss": 0.34701186418533325,
      "eval_runtime": 46.8492,
      "eval_samples_per_second": 3584.477,
      "eval_steps_per_second": 448.076,
      "step": 634000
    },
    {
      "epoch": 6.712350665092816,
      "grad_norm": 1.1384848356246948,
      "learning_rate": 0.00014757452292986947,
      "loss": 0.548,
      "step": 634050
    },
    {
      "epoch": 6.71287998687282,
      "grad_norm": 1.1243277788162231,
      "learning_rate": 0.0001475323871782079,
      "loss": 0.5542,
      "step": 634100
    },
    {
      "epoch": 6.713409308652823,
      "grad_norm": 1.1616724729537964,
      "learning_rate": 0.00014749025492475287,
      "loss": 0.5519,
      "step": 634150
    },
    {
      "epoch": 6.713938630432827,
      "grad_norm": 1.260996699333191,
      "learning_rate": 0.0001474481261709431,
      "loss": 0.5594,
      "step": 634200
    },
    {
      "epoch": 6.714467952212829,
      "grad_norm": 1.1350346803665161,
      "learning_rate": 0.0001474060009182166,
      "loss": 0.5458,
      "step": 634250
    },
    {
      "epoch": 6.714997273992833,
      "grad_norm": 1.1761484146118164,
      "learning_rate": 0.00014736387916801163,
      "loss": 0.5463,
      "step": 634300
    },
    {
      "epoch": 6.715526595772836,
      "grad_norm": 1.2588778734207153,
      "learning_rate": 0.0001473217609217662,
      "loss": 0.5559,
      "step": 634350
    },
    {
      "epoch": 6.71605591755284,
      "grad_norm": 1.4646133184432983,
      "learning_rate": 0.00014727964618091815,
      "loss": 0.5599,
      "step": 634400
    },
    {
      "epoch": 6.716585239332843,
      "grad_norm": 1.283522605895996,
      "learning_rate": 0.0001472375349469053,
      "loss": 0.5624,
      "step": 634450
    },
    {
      "epoch": 6.717114561112846,
      "grad_norm": 1.3620007038116455,
      "learning_rate": 0.0001471954272211654,
      "loss": 0.5482,
      "step": 634500
    },
    {
      "epoch": 6.717114561112846,
      "eval_loss": 0.3466317355632782,
      "eval_runtime": 47.6064,
      "eval_samples_per_second": 3527.468,
      "eval_steps_per_second": 440.949,
      "step": 634500
    },
    {
      "epoch": 6.717643882892849,
      "grad_norm": 1.3268508911132812,
      "learning_rate": 0.00014715332300513584,
      "loss": 0.5428,
      "step": 634550
    },
    {
      "epoch": 6.718173204672853,
      "grad_norm": 1.1678086519241333,
      "learning_rate": 0.0001471112223002542,
      "loss": 0.5566,
      "step": 634600
    },
    {
      "epoch": 6.718702526452856,
      "grad_norm": 1.2450822591781616,
      "learning_rate": 0.0001470691251079576,
      "loss": 0.5518,
      "step": 634650
    },
    {
      "epoch": 6.719231848232859,
      "grad_norm": 1.1255784034729004,
      "learning_rate": 0.00014702703142968341,
      "loss": 0.5521,
      "step": 634700
    },
    {
      "epoch": 6.7197611700128626,
      "grad_norm": 1.2284752130508423,
      "learning_rate": 0.0001469849412668685,
      "loss": 0.5586,
      "step": 634750
    },
    {
      "epoch": 6.720290491792865,
      "grad_norm": 1.283139705657959,
      "learning_rate": 0.00014694285462095002,
      "loss": 0.5496,
      "step": 634800
    },
    {
      "epoch": 6.720819813572869,
      "grad_norm": 1.1293957233428955,
      "learning_rate": 0.00014690077149336463,
      "loss": 0.5639,
      "step": 634850
    },
    {
      "epoch": 6.721349135352872,
      "grad_norm": 1.1775517463684082,
      "learning_rate": 0.00014685869188554913,
      "loss": 0.5529,
      "step": 634900
    },
    {
      "epoch": 6.721878457132876,
      "grad_norm": 1.2672507762908936,
      "learning_rate": 0.00014681661579894,
      "loss": 0.5456,
      "step": 634950
    },
    {
      "epoch": 6.722407778912879,
      "grad_norm": 1.2931045293807983,
      "learning_rate": 0.00014677454323497386,
      "loss": 0.5564,
      "step": 635000
    },
    {
      "epoch": 6.722407778912879,
      "eval_loss": 0.34665316343307495,
      "eval_runtime": 48.5702,
      "eval_samples_per_second": 3457.467,
      "eval_steps_per_second": 432.199,
      "step": 635000
    },
    {
      "epoch": 6.722937100692882,
      "grad_norm": 1.2792271375656128,
      "learning_rate": 0.00014673247419508685,
      "loss": 0.5549,
      "step": 635050
    },
    {
      "epoch": 6.723466422472885,
      "grad_norm": 1.246330738067627,
      "learning_rate": 0.00014669040868071532,
      "loss": 0.5562,
      "step": 635100
    },
    {
      "epoch": 6.723995744252889,
      "grad_norm": 1.3305981159210205,
      "learning_rate": 0.0001466483466932954,
      "loss": 0.5471,
      "step": 635150
    },
    {
      "epoch": 6.724525066032892,
      "grad_norm": 1.2816489934921265,
      "learning_rate": 0.00014660628823426298,
      "loss": 0.5478,
      "step": 635200
    },
    {
      "epoch": 6.725054387812896,
      "grad_norm": 1.2284431457519531,
      "learning_rate": 0.00014656423330505392,
      "loss": 0.5511,
      "step": 635250
    },
    {
      "epoch": 6.7255837095928985,
      "grad_norm": 1.2023718357086182,
      "learning_rate": 0.00014652218190710413,
      "loss": 0.5571,
      "step": 635300
    },
    {
      "epoch": 6.726113031372902,
      "grad_norm": 1.337908148765564,
      "learning_rate": 0.00014648013404184896,
      "loss": 0.5528,
      "step": 635350
    },
    {
      "epoch": 6.726642353152905,
      "grad_norm": 1.3515108823776245,
      "learning_rate": 0.00014643808971072418,
      "loss": 0.5558,
      "step": 635400
    },
    {
      "epoch": 6.727171674932908,
      "grad_norm": 1.2527261972427368,
      "learning_rate": 0.0001463960489151649,
      "loss": 0.5438,
      "step": 635450
    },
    {
      "epoch": 6.727700996712912,
      "grad_norm": 1.2728430032730103,
      "learning_rate": 0.00014635401165660666,
      "loss": 0.5471,
      "step": 635500
    },
    {
      "epoch": 6.727700996712912,
      "eval_loss": 0.34658491611480713,
      "eval_runtime": 47.8775,
      "eval_samples_per_second": 3507.494,
      "eval_steps_per_second": 438.452,
      "step": 635500
    },
    {
      "epoch": 6.728230318492915,
      "grad_norm": 1.1663486957550049,
      "learning_rate": 0.00014631197793648433,
      "loss": 0.5575,
      "step": 635550
    },
    {
      "epoch": 6.728759640272918,
      "grad_norm": 1.1982533931732178,
      "learning_rate": 0.00014626994775623315,
      "loss": 0.5526,
      "step": 635600
    },
    {
      "epoch": 6.729288962052921,
      "grad_norm": 1.171391487121582,
      "learning_rate": 0.0001462279211172878,
      "loss": 0.562,
      "step": 635650
    },
    {
      "epoch": 6.729818283832925,
      "grad_norm": 1.1997989416122437,
      "learning_rate": 0.0001461858980210833,
      "loss": 0.5483,
      "step": 635700
    },
    {
      "epoch": 6.730347605612928,
      "grad_norm": 1.2458657026290894,
      "learning_rate": 0.00014614387846905404,
      "loss": 0.5459,
      "step": 635750
    },
    {
      "epoch": 6.730876927392932,
      "grad_norm": 1.2209049463272095,
      "learning_rate": 0.0001461018624626348,
      "loss": 0.562,
      "step": 635800
    },
    {
      "epoch": 6.7314062491729345,
      "grad_norm": 1.1410266160964966,
      "learning_rate": 0.00014605985000325973,
      "loss": 0.5432,
      "step": 635850
    },
    {
      "epoch": 6.731935570952938,
      "grad_norm": 1.175290822982788,
      "learning_rate": 0.00014601784109236331,
      "loss": 0.5559,
      "step": 635900
    },
    {
      "epoch": 6.732464892732941,
      "grad_norm": 1.2446000576019287,
      "learning_rate": 0.00014597583573137973,
      "loss": 0.5446,
      "step": 635950
    },
    {
      "epoch": 6.732994214512945,
      "grad_norm": 1.264601707458496,
      "learning_rate": 0.00014593383392174297,
      "loss": 0.5525,
      "step": 636000
    },
    {
      "epoch": 6.732994214512945,
      "eval_loss": 0.34671685099601746,
      "eval_runtime": 47.2912,
      "eval_samples_per_second": 3550.976,
      "eval_steps_per_second": 443.888,
      "step": 636000
    },
    {
      "epoch": 6.733523536292948,
      "grad_norm": 1.1348838806152344,
      "learning_rate": 0.00014589183566488686,
      "loss": 0.5542,
      "step": 636050
    },
    {
      "epoch": 6.7340528580729515,
      "grad_norm": 1.2098033428192139,
      "learning_rate": 0.0001458498409622454,
      "loss": 0.5566,
      "step": 636100
    },
    {
      "epoch": 6.734582179852954,
      "grad_norm": 1.2342455387115479,
      "learning_rate": 0.00014580784981525207,
      "loss": 0.5476,
      "step": 636150
    },
    {
      "epoch": 6.735111501632957,
      "grad_norm": 1.4001665115356445,
      "learning_rate": 0.00014576670194227015,
      "loss": 0.5501,
      "step": 636200
    },
    {
      "epoch": 6.735640823412961,
      "grad_norm": 1.3250991106033325,
      "learning_rate": 0.00014572471783968948,
      "loss": 0.5476,
      "step": 636250
    },
    {
      "epoch": 6.736170145192965,
      "grad_norm": 1.3057167530059814,
      "learning_rate": 0.00014568273729702886,
      "loss": 0.5442,
      "step": 636300
    },
    {
      "epoch": 6.736699466972968,
      "grad_norm": 1.1142046451568604,
      "learning_rate": 0.0001456407603157212,
      "loss": 0.5511,
      "step": 636350
    },
    {
      "epoch": 6.7372287887529705,
      "grad_norm": 1.0616685152053833,
      "learning_rate": 0.0001455987868971998,
      "loss": 0.5417,
      "step": 636400
    },
    {
      "epoch": 6.737758110532974,
      "grad_norm": 1.223137378692627,
      "learning_rate": 0.00014555681704289745,
      "loss": 0.5574,
      "step": 636450
    },
    {
      "epoch": 6.738287432312977,
      "grad_norm": 1.0963128805160522,
      "learning_rate": 0.00014551485075424715,
      "loss": 0.5516,
      "step": 636500
    },
    {
      "epoch": 6.738287432312977,
      "eval_loss": 0.3462246358394623,
      "eval_runtime": 48.0296,
      "eval_samples_per_second": 3496.384,
      "eval_steps_per_second": 437.064,
      "step": 636500
    },
    {
      "epoch": 6.738816754092981,
      "grad_norm": 1.1905618906021118,
      "learning_rate": 0.00014547288803268144,
      "loss": 0.5611,
      "step": 636550
    },
    {
      "epoch": 6.739346075872984,
      "grad_norm": 1.3452019691467285,
      "learning_rate": 0.00014543092887963306,
      "loss": 0.5556,
      "step": 636600
    },
    {
      "epoch": 6.7398753976529875,
      "grad_norm": 1.0775667428970337,
      "learning_rate": 0.00014538897329653434,
      "loss": 0.5535,
      "step": 636650
    },
    {
      "epoch": 6.74040471943299,
      "grad_norm": 1.2312672138214111,
      "learning_rate": 0.0001453470212848178,
      "loss": 0.5499,
      "step": 636700
    },
    {
      "epoch": 6.740934041212994,
      "grad_norm": 1.3531301021575928,
      "learning_rate": 0.00014530507284591548,
      "loss": 0.5461,
      "step": 636750
    },
    {
      "epoch": 6.741463362992997,
      "grad_norm": 1.281185507774353,
      "learning_rate": 0.0001452631279812597,
      "loss": 0.5531,
      "step": 636800
    },
    {
      "epoch": 6.741992684773001,
      "grad_norm": 1.1212334632873535,
      "learning_rate": 0.00014522118669228217,
      "loss": 0.5537,
      "step": 636850
    },
    {
      "epoch": 6.742522006553004,
      "grad_norm": 1.3201206922531128,
      "learning_rate": 0.00014517924898041495,
      "loss": 0.5473,
      "step": 636900
    },
    {
      "epoch": 6.7430513283330065,
      "grad_norm": 1.1686631441116333,
      "learning_rate": 0.0001451373148470898,
      "loss": 0.5481,
      "step": 636950
    },
    {
      "epoch": 6.74358065011301,
      "grad_norm": 1.2283194065093994,
      "learning_rate": 0.0001450953842937382,
      "loss": 0.5466,
      "step": 637000
    },
    {
      "epoch": 6.74358065011301,
      "eval_loss": 0.3467925488948822,
      "eval_runtime": 47.4494,
      "eval_samples_per_second": 3539.135,
      "eval_steps_per_second": 442.408,
      "step": 637000
    },
    {
      "epoch": 6.744109971893014,
      "grad_norm": 1.3709288835525513,
      "learning_rate": 0.00014505345732179176,
      "loss": 0.5549,
      "step": 637050
    },
    {
      "epoch": 6.744639293673017,
      "grad_norm": 1.3232722282409668,
      "learning_rate": 0.00014501153393268174,
      "loss": 0.5537,
      "step": 637100
    },
    {
      "epoch": 6.74516861545302,
      "grad_norm": 1.1729118824005127,
      "learning_rate": 0.0001449696141278394,
      "loss": 0.5447,
      "step": 637150
    },
    {
      "epoch": 6.7456979372330235,
      "grad_norm": 1.106078028678894,
      "learning_rate": 0.00014492769790869602,
      "loss": 0.5544,
      "step": 637200
    },
    {
      "epoch": 6.746227259013026,
      "grad_norm": 1.300727367401123,
      "learning_rate": 0.00014488578527668244,
      "loss": 0.544,
      "step": 637250
    },
    {
      "epoch": 6.74675658079303,
      "grad_norm": 1.1598912477493286,
      "learning_rate": 0.0001448438762332297,
      "loss": 0.5521,
      "step": 637300
    },
    {
      "epoch": 6.747285902573033,
      "grad_norm": 1.1258608102798462,
      "learning_rate": 0.00014480197077976835,
      "loss": 0.552,
      "step": 637350
    },
    {
      "epoch": 6.747815224353037,
      "grad_norm": 1.1862014532089233,
      "learning_rate": 0.00014476006891772923,
      "loss": 0.5557,
      "step": 637400
    },
    {
      "epoch": 6.74834454613304,
      "grad_norm": 1.223981499671936,
      "learning_rate": 0.00014471817064854264,
      "loss": 0.5455,
      "step": 637450
    },
    {
      "epoch": 6.748873867913043,
      "grad_norm": 1.2918622493743896,
      "learning_rate": 0.00014467627597363923,
      "loss": 0.5444,
      "step": 637500
    },
    {
      "epoch": 6.748873867913043,
      "eval_loss": 0.34593647718429565,
      "eval_runtime": 47.8786,
      "eval_samples_per_second": 3507.415,
      "eval_steps_per_second": 438.442,
      "step": 637500
    },
    {
      "epoch": 6.749403189693046,
      "grad_norm": 1.2330219745635986,
      "learning_rate": 0.00014463438489444903,
      "loss": 0.5479,
      "step": 637550
    },
    {
      "epoch": 6.74993251147305,
      "grad_norm": 1.188083529472351,
      "learning_rate": 0.00014459249741240236,
      "loss": 0.5448,
      "step": 637600
    },
    {
      "epoch": 6.750461833253053,
      "grad_norm": 1.2688699960708618,
      "learning_rate": 0.00014455061352892907,
      "loss": 0.5524,
      "step": 637650
    },
    {
      "epoch": 6.750991155033056,
      "grad_norm": 1.2674342393875122,
      "learning_rate": 0.00014450873324545926,
      "loss": 0.553,
      "step": 637700
    },
    {
      "epoch": 6.7515204768130594,
      "grad_norm": 1.2267922163009644,
      "learning_rate": 0.00014446685656342254,
      "loss": 0.5509,
      "step": 637750
    },
    {
      "epoch": 6.752049798593063,
      "grad_norm": 1.1788113117218018,
      "learning_rate": 0.0001444249834842487,
      "loss": 0.5536,
      "step": 637800
    },
    {
      "epoch": 6.752579120373066,
      "grad_norm": 1.200266718864441,
      "learning_rate": 0.00014438311400936715,
      "loss": 0.5526,
      "step": 637850
    },
    {
      "epoch": 6.753108442153069,
      "grad_norm": 1.240890383720398,
      "learning_rate": 0.00014434124814020744,
      "loss": 0.5452,
      "step": 637900
    },
    {
      "epoch": 6.753637763933073,
      "grad_norm": 1.2840092182159424,
      "learning_rate": 0.00014429938587819864,
      "loss": 0.5553,
      "step": 637950
    },
    {
      "epoch": 6.754167085713076,
      "grad_norm": 1.2569143772125244,
      "learning_rate": 0.00014425752722477015,
      "loss": 0.544,
      "step": 638000
    },
    {
      "epoch": 6.754167085713076,
      "eval_loss": 0.3448179066181183,
      "eval_runtime": 47.4483,
      "eval_samples_per_second": 3539.219,
      "eval_steps_per_second": 442.418,
      "step": 638000
    },
    {
      "epoch": 6.754696407493079,
      "grad_norm": 1.2953951358795166,
      "learning_rate": 0.0001442156721813508,
      "loss": 0.5431,
      "step": 638050
    },
    {
      "epoch": 6.755225729273082,
      "grad_norm": 1.1161518096923828,
      "learning_rate": 0.00014417382074936974,
      "loss": 0.5498,
      "step": 638100
    },
    {
      "epoch": 6.755755051053086,
      "grad_norm": 1.2819793224334717,
      "learning_rate": 0.0001441319729302555,
      "loss": 0.5515,
      "step": 638150
    },
    {
      "epoch": 6.756284372833089,
      "grad_norm": 1.2416075468063354,
      "learning_rate": 0.00014409096557410395,
      "loss": 0.5555,
      "step": 638200
    },
    {
      "epoch": 6.756813694613093,
      "grad_norm": 1.1441309452056885,
      "learning_rate": 0.00014404912491268113,
      "loss": 0.5479,
      "step": 638250
    },
    {
      "epoch": 6.757343016393095,
      "grad_norm": 1.2948285341262817,
      "learning_rate": 0.00014400728786838219,
      "loss": 0.5493,
      "step": 638300
    },
    {
      "epoch": 6.757872338173099,
      "grad_norm": 1.1372395753860474,
      "learning_rate": 0.0001439654544426357,
      "loss": 0.5512,
      "step": 638350
    },
    {
      "epoch": 6.758401659953102,
      "grad_norm": 1.221314787864685,
      "learning_rate": 0.0001439236246368696,
      "loss": 0.556,
      "step": 638400
    },
    {
      "epoch": 6.758930981733105,
      "grad_norm": 1.1111266613006592,
      "learning_rate": 0.00014388179845251217,
      "loss": 0.5494,
      "step": 638450
    },
    {
      "epoch": 6.759460303513109,
      "grad_norm": 1.2837022542953491,
      "learning_rate": 0.00014383997589099113,
      "loss": 0.553,
      "step": 638500
    },
    {
      "epoch": 6.759460303513109,
      "eval_loss": 0.3457305431365967,
      "eval_runtime": 48.3187,
      "eval_samples_per_second": 3475.467,
      "eval_steps_per_second": 434.449,
      "step": 638500
    },
    {
      "epoch": 6.759989625293112,
      "grad_norm": 1.0839793682098389,
      "learning_rate": 0.00014379815695373443,
      "loss": 0.5568,
      "step": 638550
    },
    {
      "epoch": 6.760518947073115,
      "grad_norm": 1.2008973360061646,
      "learning_rate": 0.00014375634164216964,
      "loss": 0.5597,
      "step": 638600
    },
    {
      "epoch": 6.761048268853118,
      "grad_norm": 1.2426815032958984,
      "learning_rate": 0.00014371452995772446,
      "loss": 0.5481,
      "step": 638650
    },
    {
      "epoch": 6.761577590633122,
      "grad_norm": 1.3368449211120605,
      "learning_rate": 0.00014367272190182618,
      "loss": 0.5548,
      "step": 638700
    },
    {
      "epoch": 6.762106912413125,
      "grad_norm": 1.2989016771316528,
      "learning_rate": 0.00014363091747590225,
      "loss": 0.5495,
      "step": 638750
    },
    {
      "epoch": 6.7626362341931285,
      "grad_norm": 1.3651801347732544,
      "learning_rate": 0.00014358911668137968,
      "loss": 0.5551,
      "step": 638800
    },
    {
      "epoch": 6.763165555973131,
      "grad_norm": 1.2773138284683228,
      "learning_rate": 0.0001435473195196858,
      "loss": 0.5456,
      "step": 638850
    },
    {
      "epoch": 6.763694877753135,
      "grad_norm": 1.2446856498718262,
      "learning_rate": 0.00014350552599224725,
      "loss": 0.5508,
      "step": 638900
    },
    {
      "epoch": 6.764224199533138,
      "grad_norm": 1.2058751583099365,
      "learning_rate": 0.00014346373610049106,
      "loss": 0.5449,
      "step": 638950
    },
    {
      "epoch": 6.764753521313142,
      "grad_norm": 1.1889199018478394,
      "learning_rate": 0.0001434219498458438,
      "loss": 0.5594,
      "step": 639000
    },
    {
      "epoch": 6.764753521313142,
      "eval_loss": 0.3463432192802429,
      "eval_runtime": 48.2398,
      "eval_samples_per_second": 3481.148,
      "eval_steps_per_second": 435.159,
      "step": 639000
    },
    {
      "epoch": 6.765282843093145,
      "grad_norm": 1.3266388177871704,
      "learning_rate": 0.00014338016722973207,
      "loss": 0.5472,
      "step": 639050
    },
    {
      "epoch": 6.765812164873148,
      "grad_norm": 1.2285717725753784,
      "learning_rate": 0.00014333838825358243,
      "loss": 0.5452,
      "step": 639100
    },
    {
      "epoch": 6.766341486653151,
      "grad_norm": 1.3044114112854004,
      "learning_rate": 0.00014329661291882095,
      "loss": 0.5492,
      "step": 639150
    },
    {
      "epoch": 6.766870808433154,
      "grad_norm": 1.3020914793014526,
      "learning_rate": 0.00014325484122687404,
      "loss": 0.5393,
      "step": 639200
    },
    {
      "epoch": 6.767400130213158,
      "grad_norm": 1.18959641456604,
      "learning_rate": 0.00014321307317916778,
      "loss": 0.5497,
      "step": 639250
    },
    {
      "epoch": 6.767929451993162,
      "grad_norm": 1.2791311740875244,
      "learning_rate": 0.0001431713087771279,
      "loss": 0.5555,
      "step": 639300
    },
    {
      "epoch": 6.7684587737731645,
      "grad_norm": 1.1804219484329224,
      "learning_rate": 0.00014312954802218054,
      "loss": 0.5474,
      "step": 639350
    },
    {
      "epoch": 6.768988095553167,
      "grad_norm": 1.1826320886611938,
      "learning_rate": 0.00014308779091575104,
      "loss": 0.5582,
      "step": 639400
    },
    {
      "epoch": 6.769517417333171,
      "grad_norm": 1.2486387491226196,
      "learning_rate": 0.00014304603745926532,
      "loss": 0.5579,
      "step": 639450
    },
    {
      "epoch": 6.770046739113174,
      "grad_norm": 1.3045111894607544,
      "learning_rate": 0.0001430042876541485,
      "loss": 0.5483,
      "step": 639500
    },
    {
      "epoch": 6.770046739113174,
      "eval_loss": 0.3437482714653015,
      "eval_runtime": 47.7765,
      "eval_samples_per_second": 3514.905,
      "eval_steps_per_second": 439.379,
      "step": 639500
    },
    {
      "epoch": 6.770576060893178,
      "grad_norm": 1.2244200706481934,
      "learning_rate": 0.00014296254150182616,
      "loss": 0.5406,
      "step": 639550
    },
    {
      "epoch": 6.771105382673181,
      "grad_norm": 1.2628034353256226,
      "learning_rate": 0.00014292079900372334,
      "loss": 0.5512,
      "step": 639600
    },
    {
      "epoch": 6.771634704453184,
      "grad_norm": 0.9828241467475891,
      "learning_rate": 0.00014287906016126524,
      "loss": 0.5522,
      "step": 639650
    },
    {
      "epoch": 6.772164026233187,
      "grad_norm": 1.2507014274597168,
      "learning_rate": 0.00014283732497587665,
      "loss": 0.5496,
      "step": 639700
    },
    {
      "epoch": 6.772693348013191,
      "grad_norm": 1.1874316930770874,
      "learning_rate": 0.0001427955934489826,
      "loss": 0.5441,
      "step": 639750
    },
    {
      "epoch": 6.773222669793194,
      "grad_norm": 1.129653811454773,
      "learning_rate": 0.00014275386558200754,
      "loss": 0.545,
      "step": 639800
    },
    {
      "epoch": 6.773751991573198,
      "grad_norm": 1.221704125404358,
      "learning_rate": 0.0001427121413763763,
      "loss": 0.5553,
      "step": 639850
    },
    {
      "epoch": 6.7742813133532005,
      "grad_norm": 1.3151376247406006,
      "learning_rate": 0.0001426704208335131,
      "loss": 0.5482,
      "step": 639900
    },
    {
      "epoch": 6.774810635133203,
      "grad_norm": 1.2950669527053833,
      "learning_rate": 0.00014262870395484245,
      "loss": 0.5531,
      "step": 639950
    },
    {
      "epoch": 6.775339956913207,
      "grad_norm": 1.339189887046814,
      "learning_rate": 0.0001425869907417884,
      "loss": 0.555,
      "step": 640000
    },
    {
      "epoch": 6.775339956913207,
      "eval_loss": 0.34583619236946106,
      "eval_runtime": 47.2762,
      "eval_samples_per_second": 3552.106,
      "eval_steps_per_second": 444.029,
      "step": 640000
    },
    {
      "epoch": 6.775869278693211,
      "grad_norm": 1.3319460153579712,
      "learning_rate": 0.0001425452811957752,
      "loss": 0.5407,
      "step": 640050
    },
    {
      "epoch": 6.776398600473214,
      "grad_norm": 1.280479073524475,
      "learning_rate": 0.0001425044093998173,
      "loss": 0.5525,
      "step": 640100
    },
    {
      "epoch": 6.776927922253217,
      "grad_norm": 1.1863734722137451,
      "learning_rate": 0.0001424627071187456,
      "loss": 0.5537,
      "step": 640150
    },
    {
      "epoch": 6.77745724403322,
      "grad_norm": 1.317038893699646,
      "learning_rate": 0.0001424210085089575,
      "loss": 0.5502,
      "step": 640200
    },
    {
      "epoch": 6.777986565813223,
      "grad_norm": 1.184348464012146,
      "learning_rate": 0.00014237931357187684,
      "loss": 0.5451,
      "step": 640250
    },
    {
      "epoch": 6.778515887593227,
      "grad_norm": 1.28995943069458,
      "learning_rate": 0.0001423376223089268,
      "loss": 0.5483,
      "step": 640300
    },
    {
      "epoch": 6.77904520937323,
      "grad_norm": 1.0937365293502808,
      "learning_rate": 0.000142295934721531,
      "loss": 0.5454,
      "step": 640350
    },
    {
      "epoch": 6.779574531153234,
      "grad_norm": 1.2358633279800415,
      "learning_rate": 0.00014225425081111238,
      "loss": 0.5455,
      "step": 640400
    },
    {
      "epoch": 6.7801038529332365,
      "grad_norm": 1.326177954673767,
      "learning_rate": 0.0001422125705790942,
      "loss": 0.5332,
      "step": 640450
    },
    {
      "epoch": 6.78063317471324,
      "grad_norm": 1.1894378662109375,
      "learning_rate": 0.00014217089402689925,
      "loss": 0.5454,
      "step": 640500
    },
    {
      "epoch": 6.78063317471324,
      "eval_loss": 0.34449073672294617,
      "eval_runtime": 47.6751,
      "eval_samples_per_second": 3522.38,
      "eval_steps_per_second": 440.313,
      "step": 640500
    },
    {
      "epoch": 6.781162496493243,
      "grad_norm": 1.207402229309082,
      "learning_rate": 0.0001421292211559505,
      "loss": 0.55,
      "step": 640550
    },
    {
      "epoch": 6.781691818273247,
      "grad_norm": 1.2166824340820312,
      "learning_rate": 0.00014208755196767054,
      "loss": 0.5548,
      "step": 640600
    },
    {
      "epoch": 6.78222114005325,
      "grad_norm": 1.246166467666626,
      "learning_rate": 0.00014204588646348203,
      "loss": 0.5493,
      "step": 640650
    },
    {
      "epoch": 6.782750461833253,
      "grad_norm": 1.2318633794784546,
      "learning_rate": 0.00014200422464480728,
      "loss": 0.5494,
      "step": 640700
    },
    {
      "epoch": 6.783279783613256,
      "grad_norm": 1.140644907951355,
      "learning_rate": 0.0001419625665130688,
      "loss": 0.5435,
      "step": 640750
    },
    {
      "epoch": 6.78380910539326,
      "grad_norm": 1.230425238609314,
      "learning_rate": 0.00014192091206968857,
      "loss": 0.5509,
      "step": 640800
    },
    {
      "epoch": 6.784338427173263,
      "grad_norm": 1.2075557708740234,
      "learning_rate": 0.00014187926131608886,
      "loss": 0.5545,
      "step": 640850
    },
    {
      "epoch": 6.784867748953266,
      "grad_norm": 1.1850762367248535,
      "learning_rate": 0.00014183761425369144,
      "loss": 0.5533,
      "step": 640900
    },
    {
      "epoch": 6.78539707073327,
      "grad_norm": 1.225783348083496,
      "learning_rate": 0.00014179597088391827,
      "loss": 0.5537,
      "step": 640950
    },
    {
      "epoch": 6.7859263925132725,
      "grad_norm": 1.2284208536148071,
      "learning_rate": 0.00014175433120819093,
      "loss": 0.5497,
      "step": 641000
    },
    {
      "epoch": 6.7859263925132725,
      "eval_loss": 0.3445225954055786,
      "eval_runtime": 47.6608,
      "eval_samples_per_second": 3523.442,
      "eval_steps_per_second": 440.446,
      "step": 641000
    },
    {
      "epoch": 6.786455714293276,
      "grad_norm": 1.215781807899475,
      "learning_rate": 0.00014171269522793105,
      "loss": 0.5493,
      "step": 641050
    },
    {
      "epoch": 6.786985036073279,
      "grad_norm": 1.2605843544006348,
      "learning_rate": 0.00014167106294456,
      "loss": 0.5559,
      "step": 641100
    },
    {
      "epoch": 6.787514357853283,
      "grad_norm": 1.245660662651062,
      "learning_rate": 0.0001416294343594992,
      "loss": 0.547,
      "step": 641150
    },
    {
      "epoch": 6.788043679633286,
      "grad_norm": 1.2233963012695312,
      "learning_rate": 0.00014158780947416967,
      "loss": 0.5432,
      "step": 641200
    },
    {
      "epoch": 6.7885730014132895,
      "grad_norm": 1.2927730083465576,
      "learning_rate": 0.00014154618828999256,
      "loss": 0.55,
      "step": 641250
    },
    {
      "epoch": 6.789102323193292,
      "grad_norm": 1.289678692817688,
      "learning_rate": 0.00014150457080838892,
      "loss": 0.5501,
      "step": 641300
    },
    {
      "epoch": 6.789631644973296,
      "grad_norm": 1.2158350944519043,
      "learning_rate": 0.00014146295703077933,
      "loss": 0.543,
      "step": 641350
    },
    {
      "epoch": 6.790160966753299,
      "grad_norm": 1.282717227935791,
      "learning_rate": 0.0001414213469585846,
      "loss": 0.5478,
      "step": 641400
    },
    {
      "epoch": 6.790690288533302,
      "grad_norm": 1.2395819425582886,
      "learning_rate": 0.00014137974059322535,
      "loss": 0.5538,
      "step": 641450
    },
    {
      "epoch": 6.791219610313306,
      "grad_norm": 1.2963534593582153,
      "learning_rate": 0.00014133813793612183,
      "loss": 0.5491,
      "step": 641500
    },
    {
      "epoch": 6.791219610313306,
      "eval_loss": 0.3440086245536804,
      "eval_runtime": 47.7347,
      "eval_samples_per_second": 3517.983,
      "eval_steps_per_second": 439.764,
      "step": 641500
    },
    {
      "epoch": 6.791748932093309,
      "grad_norm": 1.304296612739563,
      "learning_rate": 0.00014129653898869453,
      "loss": 0.538,
      "step": 641550
    },
    {
      "epoch": 6.792278253873312,
      "grad_norm": 1.3433358669281006,
      "learning_rate": 0.00014125494375236342,
      "loss": 0.5488,
      "step": 641600
    },
    {
      "epoch": 6.792807575653315,
      "grad_norm": 1.197140097618103,
      "learning_rate": 0.00014121335222854874,
      "loss": 0.5378,
      "step": 641650
    },
    {
      "epoch": 6.793336897433319,
      "grad_norm": 1.2099206447601318,
      "learning_rate": 0.00014117176441867026,
      "loss": 0.5467,
      "step": 641700
    },
    {
      "epoch": 6.793866219213322,
      "grad_norm": 1.2279083728790283,
      "learning_rate": 0.0001411301803241479,
      "loss": 0.5493,
      "step": 641750
    },
    {
      "epoch": 6.794395540993325,
      "grad_norm": 1.0903037786483765,
      "learning_rate": 0.00014108859994640117,
      "loss": 0.554,
      "step": 641800
    },
    {
      "epoch": 6.794924862773328,
      "grad_norm": 1.2004021406173706,
      "learning_rate": 0.00014104702328684976,
      "loss": 0.5588,
      "step": 641850
    },
    {
      "epoch": 6.795454184553332,
      "grad_norm": 1.3117183446884155,
      "learning_rate": 0.00014100545034691296,
      "loss": 0.55,
      "step": 641900
    },
    {
      "epoch": 6.795983506333335,
      "grad_norm": 1.37832772731781,
      "learning_rate": 0.00014096388112801018,
      "loss": 0.5541,
      "step": 641950
    },
    {
      "epoch": 6.796512828113339,
      "grad_norm": 1.105664610862732,
      "learning_rate": 0.00014092231563156044,
      "loss": 0.5528,
      "step": 642000
    },
    {
      "epoch": 6.796512828113339,
      "eval_loss": 0.34343230724334717,
      "eval_runtime": 47.7474,
      "eval_samples_per_second": 3517.053,
      "eval_steps_per_second": 439.647,
      "step": 642000
    },
    {
      "epoch": 6.7970421498933415,
      "grad_norm": 1.183516025543213,
      "learning_rate": 0.0001408807538589829,
      "loss": 0.5544,
      "step": 642050
    },
    {
      "epoch": 6.797571471673345,
      "grad_norm": 1.2673523426055908,
      "learning_rate": 0.00014083919581169636,
      "loss": 0.5568,
      "step": 642100
    },
    {
      "epoch": 6.798100793453348,
      "grad_norm": 1.2615903615951538,
      "learning_rate": 0.00014079764149111968,
      "loss": 0.5422,
      "step": 642150
    },
    {
      "epoch": 6.798630115233351,
      "grad_norm": 1.3301167488098145,
      "learning_rate": 0.00014075609089867142,
      "loss": 0.5528,
      "step": 642200
    },
    {
      "epoch": 6.799159437013355,
      "grad_norm": 1.1714890003204346,
      "learning_rate": 0.00014071454403577022,
      "loss": 0.5558,
      "step": 642250
    },
    {
      "epoch": 6.7996887587933585,
      "grad_norm": 1.2286862134933472,
      "learning_rate": 0.00014067300090383434,
      "loss": 0.5459,
      "step": 642300
    },
    {
      "epoch": 6.800218080573361,
      "grad_norm": 1.1834033727645874,
      "learning_rate": 0.0001406314615042822,
      "loss": 0.5462,
      "step": 642350
    },
    {
      "epoch": 6.800747402353364,
      "grad_norm": 1.301395058631897,
      "learning_rate": 0.00014058992583853175,
      "loss": 0.5427,
      "step": 642400
    },
    {
      "epoch": 6.801276724133368,
      "grad_norm": 1.222939372062683,
      "learning_rate": 0.0001405483939080012,
      "loss": 0.547,
      "step": 642450
    },
    {
      "epoch": 6.801806045913371,
      "grad_norm": 1.3394718170166016,
      "learning_rate": 0.00014050686571410827,
      "loss": 0.5469,
      "step": 642500
    },
    {
      "epoch": 6.801806045913371,
      "eval_loss": 0.3440052568912506,
      "eval_runtime": 47.6201,
      "eval_samples_per_second": 3526.449,
      "eval_steps_per_second": 440.822,
      "step": 642500
    },
    {
      "epoch": 6.802335367693375,
      "grad_norm": 1.0992977619171143,
      "learning_rate": 0.00014046534125827085,
      "loss": 0.5433,
      "step": 642550
    },
    {
      "epoch": 6.8028646894733775,
      "grad_norm": 1.409945011138916,
      "learning_rate": 0.00014042382054190646,
      "loss": 0.5554,
      "step": 642600
    },
    {
      "epoch": 6.803394011253381,
      "grad_norm": 1.318084955215454,
      "learning_rate": 0.00014038230356643266,
      "loss": 0.5492,
      "step": 642650
    },
    {
      "epoch": 6.803923333033384,
      "grad_norm": 1.3186697959899902,
      "learning_rate": 0.0001403407903332668,
      "loss": 0.5522,
      "step": 642700
    },
    {
      "epoch": 6.804452654813388,
      "grad_norm": 1.2185101509094238,
      "learning_rate": 0.0001402992808438262,
      "loss": 0.5454,
      "step": 642750
    },
    {
      "epoch": 6.804981976593391,
      "grad_norm": 1.1718758344650269,
      "learning_rate": 0.00014025777509952785,
      "loss": 0.5489,
      "step": 642800
    },
    {
      "epoch": 6.8055112983733945,
      "grad_norm": 1.3974469900131226,
      "learning_rate": 0.00014021627310178888,
      "loss": 0.5511,
      "step": 642850
    },
    {
      "epoch": 6.806040620153397,
      "grad_norm": 1.331199049949646,
      "learning_rate": 0.000140174774852026,
      "loss": 0.549,
      "step": 642900
    },
    {
      "epoch": 6.8065699419334,
      "grad_norm": 1.2589030265808105,
      "learning_rate": 0.00014013328035165603,
      "loss": 0.5521,
      "step": 642950
    },
    {
      "epoch": 6.807099263713404,
      "grad_norm": 1.1044714450836182,
      "learning_rate": 0.0001400917896020957,
      "loss": 0.5456,
      "step": 643000
    },
    {
      "epoch": 6.807099263713404,
      "eval_loss": 0.3445073068141937,
      "eval_runtime": 47.538,
      "eval_samples_per_second": 3532.54,
      "eval_steps_per_second": 441.583,
      "step": 643000
    },
    {
      "epoch": 6.807628585493408,
      "grad_norm": 1.2727733850479126,
      "learning_rate": 0.00014005030260476122,
      "loss": 0.556,
      "step": 643050
    },
    {
      "epoch": 6.808157907273411,
      "grad_norm": 1.2245090007781982,
      "learning_rate": 0.00014000881936106912,
      "loss": 0.555,
      "step": 643100
    },
    {
      "epoch": 6.8086872290534135,
      "grad_norm": 1.1926392316818237,
      "learning_rate": 0.00013996733987243568,
      "loss": 0.5461,
      "step": 643150
    },
    {
      "epoch": 6.809216550833417,
      "grad_norm": 1.25015127658844,
      "learning_rate": 0.0001399258641402768,
      "loss": 0.5549,
      "step": 643200
    },
    {
      "epoch": 6.80974587261342,
      "grad_norm": 1.371852159500122,
      "learning_rate": 0.00013988439216600866,
      "loss": 0.5477,
      "step": 643250
    },
    {
      "epoch": 6.810275194393424,
      "grad_norm": 1.3434771299362183,
      "learning_rate": 0.00013984292395104685,
      "loss": 0.5396,
      "step": 643300
    },
    {
      "epoch": 6.810804516173427,
      "grad_norm": 1.223943829536438,
      "learning_rate": 0.00013980145949680736,
      "loss": 0.5475,
      "step": 643350
    },
    {
      "epoch": 6.8113338379534305,
      "grad_norm": 1.158781886100769,
      "learning_rate": 0.00013975999880470552,
      "loss": 0.5476,
      "step": 643400
    },
    {
      "epoch": 6.811863159733433,
      "grad_norm": 1.279707670211792,
      "learning_rate": 0.00013971854187615698,
      "loss": 0.5563,
      "step": 643450
    },
    {
      "epoch": 6.812392481513437,
      "grad_norm": 1.2656195163726807,
      "learning_rate": 0.0001396770887125769,
      "loss": 0.5466,
      "step": 643500
    },
    {
      "epoch": 6.812392481513437,
      "eval_loss": 0.34368789196014404,
      "eval_runtime": 46.8099,
      "eval_samples_per_second": 3587.492,
      "eval_steps_per_second": 448.452,
      "step": 643500
    },
    {
      "epoch": 6.81292180329344,
      "grad_norm": 1.341210126876831,
      "learning_rate": 0.00013963563931538062,
      "loss": 0.5541,
      "step": 643550
    },
    {
      "epoch": 6.813451125073444,
      "grad_norm": 1.345511555671692,
      "learning_rate": 0.00013959419368598302,
      "loss": 0.5483,
      "step": 643600
    },
    {
      "epoch": 6.813980446853447,
      "grad_norm": 1.1113369464874268,
      "learning_rate": 0.00013955275182579932,
      "loss": 0.5419,
      "step": 643650
    },
    {
      "epoch": 6.8145097686334495,
      "grad_norm": 1.230624794960022,
      "learning_rate": 0.00013951131373624403,
      "loss": 0.5473,
      "step": 643700
    },
    {
      "epoch": 6.815039090413453,
      "grad_norm": 1.1921885013580322,
      "learning_rate": 0.00013946987941873207,
      "loss": 0.5446,
      "step": 643750
    },
    {
      "epoch": 6.815568412193457,
      "grad_norm": 1.184019923210144,
      "learning_rate": 0.0001394284488746778,
      "loss": 0.5502,
      "step": 643800
    },
    {
      "epoch": 6.81609773397346,
      "grad_norm": 1.1787103414535522,
      "learning_rate": 0.00013938702210549583,
      "loss": 0.5562,
      "step": 643850
    },
    {
      "epoch": 6.816627055753463,
      "grad_norm": 1.232323408126831,
      "learning_rate": 0.00013934559911260024,
      "loss": 0.5597,
      "step": 643900
    },
    {
      "epoch": 6.8171563775334665,
      "grad_norm": 1.242539882659912,
      "learning_rate": 0.00013930417989740546,
      "loss": 0.5562,
      "step": 643950
    },
    {
      "epoch": 6.817685699313469,
      "grad_norm": 1.20615553855896,
      "learning_rate": 0.00013926276446132524,
      "loss": 0.554,
      "step": 644000
    },
    {
      "epoch": 6.817685699313469,
      "eval_loss": 0.34315577149391174,
      "eval_runtime": 46.7321,
      "eval_samples_per_second": 3593.46,
      "eval_steps_per_second": 449.199,
      "step": 644000
    },
    {
      "epoch": 6.818215021093473,
      "grad_norm": 1.218178391456604,
      "learning_rate": 0.00013922135280577375,
      "loss": 0.5588,
      "step": 644050
    },
    {
      "epoch": 6.818744342873476,
      "grad_norm": 1.1970016956329346,
      "learning_rate": 0.0001391807730525646,
      "loss": 0.5417,
      "step": 644100
    },
    {
      "epoch": 6.81927366465348,
      "grad_norm": 1.2239731550216675,
      "learning_rate": 0.00013913936888663045,
      "loss": 0.5539,
      "step": 644150
    },
    {
      "epoch": 6.819802986433483,
      "grad_norm": 1.3446999788284302,
      "learning_rate": 0.00013909796850543771,
      "loss": 0.5483,
      "step": 644200
    },
    {
      "epoch": 6.820332308213486,
      "grad_norm": 1.2705508470535278,
      "learning_rate": 0.00013905657191039952,
      "loss": 0.5379,
      "step": 644250
    },
    {
      "epoch": 6.820861629993489,
      "grad_norm": 1.2860041856765747,
      "learning_rate": 0.0001390151791029294,
      "loss": 0.555,
      "step": 644300
    },
    {
      "epoch": 6.821390951773493,
      "grad_norm": 1.2534109354019165,
      "learning_rate": 0.00013897379008444028,
      "loss": 0.5553,
      "step": 644350
    },
    {
      "epoch": 6.821920273553496,
      "grad_norm": 1.2392157316207886,
      "learning_rate": 0.0001389324048563453,
      "loss": 0.5504,
      "step": 644400
    },
    {
      "epoch": 6.822449595333499,
      "grad_norm": 1.316347360610962,
      "learning_rate": 0.00013889102342005722,
      "loss": 0.5491,
      "step": 644450
    },
    {
      "epoch": 6.8229789171135025,
      "grad_norm": 1.2460548877716064,
      "learning_rate": 0.00013884964577698893,
      "loss": 0.5448,
      "step": 644500
    },
    {
      "epoch": 6.8229789171135025,
      "eval_loss": 0.34230121970176697,
      "eval_runtime": 47.4678,
      "eval_samples_per_second": 3537.764,
      "eval_steps_per_second": 442.236,
      "step": 644500
    },
    {
      "epoch": 6.823508238893506,
      "grad_norm": 1.26558518409729,
      "learning_rate": 0.00013880827192855292,
      "loss": 0.5416,
      "step": 644550
    },
    {
      "epoch": 6.824037560673509,
      "grad_norm": 1.1582005023956299,
      "learning_rate": 0.0001387669018761618,
      "loss": 0.5396,
      "step": 644600
    },
    {
      "epoch": 6.824566882453512,
      "grad_norm": 1.1934555768966675,
      "learning_rate": 0.00013872553562122776,
      "loss": 0.5538,
      "step": 644650
    },
    {
      "epoch": 6.825096204233516,
      "grad_norm": 1.1043579578399658,
      "learning_rate": 0.00013868417316516317,
      "loss": 0.5379,
      "step": 644700
    },
    {
      "epoch": 6.825625526013519,
      "grad_norm": 1.2299398183822632,
      "learning_rate": 0.00013864281450938005,
      "loss": 0.5484,
      "step": 644750
    },
    {
      "epoch": 6.826154847793522,
      "grad_norm": 1.2484004497528076,
      "learning_rate": 0.0001386014596552905,
      "loss": 0.5441,
      "step": 644800
    },
    {
      "epoch": 6.826684169573525,
      "grad_norm": 1.1322165727615356,
      "learning_rate": 0.00013856010860430613,
      "loss": 0.5412,
      "step": 644850
    },
    {
      "epoch": 6.827213491353529,
      "grad_norm": 1.1985210180282593,
      "learning_rate": 0.0001385187613578389,
      "loss": 0.5493,
      "step": 644900
    },
    {
      "epoch": 6.827742813133532,
      "grad_norm": 1.2140673398971558,
      "learning_rate": 0.00013847741791730018,
      "loss": 0.5487,
      "step": 644950
    },
    {
      "epoch": 6.828272134913536,
      "grad_norm": 1.243498682975769,
      "learning_rate": 0.0001384360782841015,
      "loss": 0.5477,
      "step": 645000
    },
    {
      "epoch": 6.828272134913536,
      "eval_loss": 0.34366220235824585,
      "eval_runtime": 47.0336,
      "eval_samples_per_second": 3570.423,
      "eval_steps_per_second": 446.319,
      "step": 645000
    },
    {
      "epoch": 6.828801456693538,
      "grad_norm": 1.157073736190796,
      "learning_rate": 0.0001383947424596543,
      "loss": 0.5521,
      "step": 645050
    },
    {
      "epoch": 6.829330778473542,
      "grad_norm": 1.2427787780761719,
      "learning_rate": 0.00013835341044536958,
      "loss": 0.5491,
      "step": 645100
    },
    {
      "epoch": 6.829860100253545,
      "grad_norm": 1.2633899450302124,
      "learning_rate": 0.00013831208224265846,
      "loss": 0.5426,
      "step": 645150
    },
    {
      "epoch": 6.830389422033548,
      "grad_norm": 1.3487387895584106,
      "learning_rate": 0.00013827075785293198,
      "loss": 0.5506,
      "step": 645200
    },
    {
      "epoch": 6.830918743813552,
      "grad_norm": 1.3287352323532104,
      "learning_rate": 0.0001382294372776008,
      "loss": 0.5492,
      "step": 645250
    },
    {
      "epoch": 6.831448065593555,
      "grad_norm": 1.2016935348510742,
      "learning_rate": 0.00013818812051807566,
      "loss": 0.5462,
      "step": 645300
    },
    {
      "epoch": 6.831977387373558,
      "grad_norm": 1.160723328590393,
      "learning_rate": 0.00013814680757576704,
      "loss": 0.542,
      "step": 645350
    },
    {
      "epoch": 6.832506709153561,
      "grad_norm": 1.2819435596466064,
      "learning_rate": 0.00013810549845208548,
      "loss": 0.5498,
      "step": 645400
    },
    {
      "epoch": 6.833036030933565,
      "grad_norm": 1.286163330078125,
      "learning_rate": 0.00013806419314844106,
      "loss": 0.556,
      "step": 645450
    },
    {
      "epoch": 6.833565352713568,
      "grad_norm": 1.29996919631958,
      "learning_rate": 0.00013802289166624416,
      "loss": 0.5492,
      "step": 645500
    },
    {
      "epoch": 6.833565352713568,
      "eval_loss": 0.34293392300605774,
      "eval_runtime": 47.6579,
      "eval_samples_per_second": 3523.659,
      "eval_steps_per_second": 440.473,
      "step": 645500
    },
    {
      "epoch": 6.8340946744935716,
      "grad_norm": 1.0800443887710571,
      "learning_rate": 0.00013798159400690453,
      "loss": 0.5506,
      "step": 645550
    },
    {
      "epoch": 6.834623996273574,
      "grad_norm": 1.2455110549926758,
      "learning_rate": 0.00013794030017183232,
      "loss": 0.5452,
      "step": 645600
    },
    {
      "epoch": 6.835153318053578,
      "grad_norm": 1.269761562347412,
      "learning_rate": 0.00013789901016243706,
      "loss": 0.5521,
      "step": 645650
    },
    {
      "epoch": 6.835682639833581,
      "grad_norm": 1.3651525974273682,
      "learning_rate": 0.00013785772398012858,
      "loss": 0.5386,
      "step": 645700
    },
    {
      "epoch": 6.836211961613585,
      "grad_norm": 1.2213753461837769,
      "learning_rate": 0.0001378164416263162,
      "loss": 0.5488,
      "step": 645750
    },
    {
      "epoch": 6.836741283393588,
      "grad_norm": 1.2565351724624634,
      "learning_rate": 0.00013777516310240943,
      "loss": 0.5456,
      "step": 645800
    },
    {
      "epoch": 6.837270605173591,
      "grad_norm": 1.2741138935089111,
      "learning_rate": 0.00013773388840981733,
      "loss": 0.5483,
      "step": 645850
    },
    {
      "epoch": 6.837799926953594,
      "grad_norm": 1.3038644790649414,
      "learning_rate": 0.00013769344292957674,
      "loss": 0.5501,
      "step": 645900
    },
    {
      "epoch": 6.838329248733597,
      "grad_norm": 1.2598936557769775,
      "learning_rate": 0.0001376521758271449,
      "loss": 0.5541,
      "step": 645950
    },
    {
      "epoch": 6.838858570513601,
      "grad_norm": 1.29029381275177,
      "learning_rate": 0.00013761091256022666,
      "loss": 0.5531,
      "step": 646000
    },
    {
      "epoch": 6.838858570513601,
      "eval_loss": 0.3422602415084839,
      "eval_runtime": 47.6732,
      "eval_samples_per_second": 3522.526,
      "eval_steps_per_second": 440.332,
      "step": 646000
    },
    {
      "epoch": 6.839387892293605,
      "grad_norm": 1.1452258825302124,
      "learning_rate": 0.00013756965313023063,
      "loss": 0.5532,
      "step": 646050
    },
    {
      "epoch": 6.8399172140736075,
      "grad_norm": 1.2084218263626099,
      "learning_rate": 0.00013752839753856545,
      "loss": 0.5437,
      "step": 646100
    },
    {
      "epoch": 6.84044653585361,
      "grad_norm": 1.2596194744110107,
      "learning_rate": 0.00013748714578663943,
      "loss": 0.5488,
      "step": 646150
    },
    {
      "epoch": 6.840975857633614,
      "grad_norm": 1.2943974733352661,
      "learning_rate": 0.0001374458978758611,
      "loss": 0.554,
      "step": 646200
    },
    {
      "epoch": 6.841505179413617,
      "grad_norm": 1.3009047508239746,
      "learning_rate": 0.00013740465380763844,
      "loss": 0.5568,
      "step": 646250
    },
    {
      "epoch": 6.842034501193621,
      "grad_norm": 1.3903286457061768,
      "learning_rate": 0.0001373634135833797,
      "loss": 0.5387,
      "step": 646300
    },
    {
      "epoch": 6.842563822973624,
      "grad_norm": 1.2116750478744507,
      "learning_rate": 0.00013732217720449264,
      "loss": 0.5533,
      "step": 646350
    },
    {
      "epoch": 6.843093144753627,
      "grad_norm": 1.183964729309082,
      "learning_rate": 0.00013728094467238517,
      "loss": 0.5497,
      "step": 646400
    },
    {
      "epoch": 6.84362246653363,
      "grad_norm": 1.286125659942627,
      "learning_rate": 0.00013723971598846485,
      "loss": 0.5518,
      "step": 646450
    },
    {
      "epoch": 6.844151788313634,
      "grad_norm": 1.2368104457855225,
      "learning_rate": 0.00013719849115413938,
      "loss": 0.5493,
      "step": 646500
    },
    {
      "epoch": 6.844151788313634,
      "eval_loss": 0.3426007926464081,
      "eval_runtime": 47.6917,
      "eval_samples_per_second": 3521.158,
      "eval_steps_per_second": 440.16,
      "step": 646500
    },
    {
      "epoch": 6.844681110093637,
      "grad_norm": 1.1372301578521729,
      "learning_rate": 0.00013715727017081592,
      "loss": 0.5447,
      "step": 646550
    },
    {
      "epoch": 6.845210431873641,
      "grad_norm": 1.2036081552505493,
      "learning_rate": 0.00013711605303990199,
      "loss": 0.5484,
      "step": 646600
    },
    {
      "epoch": 6.8457397536536435,
      "grad_norm": 1.1980366706848145,
      "learning_rate": 0.0001370748397628045,
      "loss": 0.5522,
      "step": 646650
    },
    {
      "epoch": 6.846269075433646,
      "grad_norm": 1.3796443939208984,
      "learning_rate": 0.00013703363034093068,
      "loss": 0.5522,
      "step": 646700
    },
    {
      "epoch": 6.84679839721365,
      "grad_norm": 1.3052440881729126,
      "learning_rate": 0.0001369924247756872,
      "loss": 0.5453,
      "step": 646750
    },
    {
      "epoch": 6.847327718993654,
      "grad_norm": 1.2307907342910767,
      "learning_rate": 0.00013695122306848102,
      "loss": 0.541,
      "step": 646800
    },
    {
      "epoch": 6.847857040773657,
      "grad_norm": 1.2071224451065063,
      "learning_rate": 0.00013691002522071846,
      "loss": 0.5525,
      "step": 646850
    },
    {
      "epoch": 6.84838636255366,
      "grad_norm": 1.2209891080856323,
      "learning_rate": 0.0001368688312338063,
      "loss": 0.5444,
      "step": 646900
    },
    {
      "epoch": 6.848915684333663,
      "grad_norm": 1.3433860540390015,
      "learning_rate": 0.00013682764110915064,
      "loss": 0.5461,
      "step": 646950
    },
    {
      "epoch": 6.849445006113666,
      "grad_norm": 1.312427043914795,
      "learning_rate": 0.0001367864548481579,
      "loss": 0.5453,
      "step": 647000
    },
    {
      "epoch": 6.849445006113666,
      "eval_loss": 0.3423316180706024,
      "eval_runtime": 47.7626,
      "eval_samples_per_second": 3515.932,
      "eval_steps_per_second": 439.507,
      "step": 647000
    },
    {
      "epoch": 6.84997432789367,
      "grad_norm": 1.243865728378296,
      "learning_rate": 0.000136745272452234,
      "loss": 0.5412,
      "step": 647050
    },
    {
      "epoch": 6.850503649673673,
      "grad_norm": 1.2274107933044434,
      "learning_rate": 0.00013670409392278505,
      "loss": 0.5442,
      "step": 647100
    },
    {
      "epoch": 6.851032971453677,
      "grad_norm": 1.2390373945236206,
      "learning_rate": 0.00013666291926121667,
      "loss": 0.5442,
      "step": 647150
    },
    {
      "epoch": 6.8515622932336795,
      "grad_norm": 1.2572978734970093,
      "learning_rate": 0.00013662174846893466,
      "loss": 0.5484,
      "step": 647200
    },
    {
      "epoch": 6.852091615013683,
      "grad_norm": 1.2643251419067383,
      "learning_rate": 0.0001365805815473447,
      "loss": 0.5462,
      "step": 647250
    },
    {
      "epoch": 6.852620936793686,
      "grad_norm": 1.2051624059677124,
      "learning_rate": 0.000136539418497852,
      "loss": 0.5456,
      "step": 647300
    },
    {
      "epoch": 6.85315025857369,
      "grad_norm": 1.2177199125289917,
      "learning_rate": 0.0001364982593218619,
      "loss": 0.5404,
      "step": 647350
    },
    {
      "epoch": 6.853679580353693,
      "grad_norm": 1.2390626668930054,
      "learning_rate": 0.0001364571040207797,
      "loss": 0.5495,
      "step": 647400
    },
    {
      "epoch": 6.854208902133696,
      "grad_norm": 1.313752293586731,
      "learning_rate": 0.00013641595259601027,
      "loss": 0.5461,
      "step": 647450
    },
    {
      "epoch": 6.854738223913699,
      "grad_norm": 1.3089078664779663,
      "learning_rate": 0.00013637480504895865,
      "loss": 0.5476,
      "step": 647500
    },
    {
      "epoch": 6.854738223913699,
      "eval_loss": 0.342416912317276,
      "eval_runtime": 47.7536,
      "eval_samples_per_second": 3516.594,
      "eval_steps_per_second": 439.59,
      "step": 647500
    },
    {
      "epoch": 6.855267545693703,
      "grad_norm": 1.2635548114776611,
      "learning_rate": 0.0001363336613810294,
      "loss": 0.5538,
      "step": 647550
    },
    {
      "epoch": 6.855796867473706,
      "grad_norm": 1.33046293258667,
      "learning_rate": 0.00013629252159362738,
      "loss": 0.5455,
      "step": 647600
    },
    {
      "epoch": 6.856326189253709,
      "grad_norm": 1.3247413635253906,
      "learning_rate": 0.00013625138568815686,
      "loss": 0.552,
      "step": 647650
    },
    {
      "epoch": 6.856855511033713,
      "grad_norm": 1.2834980487823486,
      "learning_rate": 0.0001362102536660224,
      "loss": 0.5521,
      "step": 647700
    },
    {
      "epoch": 6.8573848328137155,
      "grad_norm": 1.274195671081543,
      "learning_rate": 0.00013616912552862808,
      "loss": 0.5425,
      "step": 647750
    },
    {
      "epoch": 6.857914154593719,
      "grad_norm": 1.3595212697982788,
      "learning_rate": 0.00013612800127737817,
      "loss": 0.5354,
      "step": 647800
    },
    {
      "epoch": 6.858443476373722,
      "grad_norm": 1.2396125793457031,
      "learning_rate": 0.00013608688091367645,
      "loss": 0.5504,
      "step": 647850
    },
    {
      "epoch": 6.858972798153726,
      "grad_norm": 1.2268178462982178,
      "learning_rate": 0.00013604576443892688,
      "loss": 0.5397,
      "step": 647900
    },
    {
      "epoch": 6.859502119933729,
      "grad_norm": 1.2932226657867432,
      "learning_rate": 0.00013600465185453306,
      "loss": 0.5468,
      "step": 647950
    },
    {
      "epoch": 6.8600314417137325,
      "grad_norm": 1.270139217376709,
      "learning_rate": 0.00013596354316189872,
      "loss": 0.5425,
      "step": 648000
    },
    {
      "epoch": 6.8600314417137325,
      "eval_loss": 0.34200751781463623,
      "eval_runtime": 47.3039,
      "eval_samples_per_second": 3550.026,
      "eval_steps_per_second": 443.769,
      "step": 648000
    },
    {
      "epoch": 6.860560763493735,
      "grad_norm": 1.2791203260421753,
      "learning_rate": 0.00013592243836242708,
      "loss": 0.5465,
      "step": 648050
    },
    {
      "epoch": 6.861090085273739,
      "grad_norm": 1.068621039390564,
      "learning_rate": 0.00013588133745752167,
      "loss": 0.5509,
      "step": 648100
    },
    {
      "epoch": 6.861619407053742,
      "grad_norm": 1.507601261138916,
      "learning_rate": 0.0001358402404485854,
      "loss": 0.5481,
      "step": 648150
    },
    {
      "epoch": 6.862148728833745,
      "grad_norm": 1.4418565034866333,
      "learning_rate": 0.0001357991473370216,
      "loss": 0.551,
      "step": 648200
    },
    {
      "epoch": 6.862678050613749,
      "grad_norm": 1.2245407104492188,
      "learning_rate": 0.00013575805812423295,
      "loss": 0.5508,
      "step": 648250
    },
    {
      "epoch": 6.863207372393752,
      "grad_norm": 1.305322289466858,
      "learning_rate": 0.00013571697281162238,
      "loss": 0.543,
      "step": 648300
    },
    {
      "epoch": 6.863736694173755,
      "grad_norm": 1.3813656568527222,
      "learning_rate": 0.00013567589140059234,
      "loss": 0.5505,
      "step": 648350
    },
    {
      "epoch": 6.864266015953758,
      "grad_norm": 1.1762253046035767,
      "learning_rate": 0.00013563481389254552,
      "loss": 0.5404,
      "step": 648400
    },
    {
      "epoch": 6.864795337733762,
      "grad_norm": 1.3359023332595825,
      "learning_rate": 0.00013559374028888414,
      "loss": 0.5469,
      "step": 648450
    },
    {
      "epoch": 6.865324659513765,
      "grad_norm": 1.2903419733047485,
      "learning_rate": 0.00013555267059101058,
      "loss": 0.5524,
      "step": 648500
    },
    {
      "epoch": 6.865324659513765,
      "eval_loss": 0.34177541732788086,
      "eval_runtime": 47.6951,
      "eval_samples_per_second": 3520.903,
      "eval_steps_per_second": 440.129,
      "step": 648500
    },
    {
      "epoch": 6.8658539812937684,
      "grad_norm": 1.193686604499817,
      "learning_rate": 0.00013551160480032681,
      "loss": 0.5386,
      "step": 648550
    },
    {
      "epoch": 6.866383303073771,
      "grad_norm": 1.1013833284378052,
      "learning_rate": 0.00013547054291823492,
      "loss": 0.5431,
      "step": 648600
    },
    {
      "epoch": 6.866912624853775,
      "grad_norm": 1.2274833917617798,
      "learning_rate": 0.00013542948494613667,
      "loss": 0.5492,
      "step": 648650
    },
    {
      "epoch": 6.867441946633778,
      "grad_norm": 1.2252405881881714,
      "learning_rate": 0.0001353884308854338,
      "loss": 0.5441,
      "step": 648700
    },
    {
      "epoch": 6.867971268413782,
      "grad_norm": 1.2926726341247559,
      "learning_rate": 0.0001353473807375278,
      "loss": 0.5374,
      "step": 648750
    },
    {
      "epoch": 6.868500590193785,
      "grad_norm": 1.2617841958999634,
      "learning_rate": 0.00013530633450382028,
      "loss": 0.5547,
      "step": 648800
    },
    {
      "epoch": 6.869029911973788,
      "grad_norm": 1.198638916015625,
      "learning_rate": 0.00013526529218571234,
      "loss": 0.543,
      "step": 648850
    },
    {
      "epoch": 6.869559233753791,
      "grad_norm": 1.2204991579055786,
      "learning_rate": 0.00013522425378460523,
      "loss": 0.5399,
      "step": 648900
    },
    {
      "epoch": 6.870088555533794,
      "grad_norm": 1.2554841041564941,
      "learning_rate": 0.00013518321930190014,
      "loss": 0.5452,
      "step": 648950
    },
    {
      "epoch": 6.870617877313798,
      "grad_norm": 1.1474403142929077,
      "learning_rate": 0.0001351421887389977,
      "loss": 0.5496,
      "step": 649000
    },
    {
      "epoch": 6.870617877313798,
      "eval_loss": 0.34144455194473267,
      "eval_runtime": 47.591,
      "eval_samples_per_second": 3528.609,
      "eval_steps_per_second": 441.092,
      "step": 649000
    },
    {
      "epoch": 6.871147199093802,
      "grad_norm": 1.2215310335159302,
      "learning_rate": 0.00013510116209729885,
      "loss": 0.545,
      "step": 649050
    },
    {
      "epoch": 6.871676520873804,
      "grad_norm": 1.2257171869277954,
      "learning_rate": 0.0001350601393782042,
      "loss": 0.5422,
      "step": 649100
    },
    {
      "epoch": 6.872205842653807,
      "grad_norm": 1.3020243644714355,
      "learning_rate": 0.00013501912058311422,
      "loss": 0.549,
      "step": 649150
    },
    {
      "epoch": 6.872735164433811,
      "grad_norm": 1.2418360710144043,
      "learning_rate": 0.0001349781057134294,
      "loss": 0.5443,
      "step": 649200
    },
    {
      "epoch": 6.873264486213814,
      "grad_norm": 1.1914401054382324,
      "learning_rate": 0.0001349370947705497,
      "loss": 0.5506,
      "step": 649250
    },
    {
      "epoch": 6.873793807993818,
      "grad_norm": 1.1476744413375854,
      "learning_rate": 0.00013489608775587555,
      "loss": 0.538,
      "step": 649300
    },
    {
      "epoch": 6.8743231297738205,
      "grad_norm": 1.1453996896743774,
      "learning_rate": 0.00013485508467080666,
      "loss": 0.5394,
      "step": 649350
    },
    {
      "epoch": 6.874852451553824,
      "grad_norm": 1.2956019639968872,
      "learning_rate": 0.00013481408551674302,
      "loss": 0.5459,
      "step": 649400
    },
    {
      "epoch": 6.875381773333827,
      "grad_norm": 1.1299196481704712,
      "learning_rate": 0.00013477309029508413,
      "loss": 0.5465,
      "step": 649450
    },
    {
      "epoch": 6.875911095113831,
      "grad_norm": 1.3917925357818604,
      "learning_rate": 0.00013473209900722983,
      "loss": 0.5449,
      "step": 649500
    },
    {
      "epoch": 6.875911095113831,
      "eval_loss": 0.34019017219543457,
      "eval_runtime": 46.9165,
      "eval_samples_per_second": 3579.337,
      "eval_steps_per_second": 447.433,
      "step": 649500
    },
    {
      "epoch": 6.876440416893834,
      "grad_norm": 1.372936725616455,
      "learning_rate": 0.00013469111165457926,
      "loss": 0.5509,
      "step": 649550
    },
    {
      "epoch": 6.8769697386738375,
      "grad_norm": 1.356702208518982,
      "learning_rate": 0.00013465012823853196,
      "loss": 0.5501,
      "step": 649600
    },
    {
      "epoch": 6.87749906045384,
      "grad_norm": 1.1746978759765625,
      "learning_rate": 0.0001346091487604869,
      "loss": 0.5455,
      "step": 649650
    },
    {
      "epoch": 6.878028382233844,
      "grad_norm": 1.2898976802825928,
      "learning_rate": 0.00013456817322184326,
      "loss": 0.5415,
      "step": 649700
    },
    {
      "epoch": 6.878557704013847,
      "grad_norm": 1.2912871837615967,
      "learning_rate": 0.00013452720162399973,
      "loss": 0.5386,
      "step": 649750
    },
    {
      "epoch": 6.879087025793851,
      "grad_norm": 1.3101493120193481,
      "learning_rate": 0.00013448623396835534,
      "loss": 0.5451,
      "step": 649800
    },
    {
      "epoch": 6.879616347573854,
      "grad_norm": 1.297175407409668,
      "learning_rate": 0.00013444527025630843,
      "loss": 0.5412,
      "step": 649850
    },
    {
      "epoch": 6.8801456693538565,
      "grad_norm": 1.2747268676757812,
      "learning_rate": 0.00013440512964592866,
      "loss": 0.551,
      "step": 649900
    },
    {
      "epoch": 6.88067499113386,
      "grad_norm": 1.172305941581726,
      "learning_rate": 0.00013436417374633082,
      "loss": 0.5495,
      "step": 649950
    },
    {
      "epoch": 6.881204312913863,
      "grad_norm": 1.1426174640655518,
      "learning_rate": 0.00013432322179449756,
      "loss": 0.537,
      "step": 650000
    },
    {
      "epoch": 6.881204312913863,
      "eval_loss": 0.3396521210670471,
      "eval_runtime": 46.5916,
      "eval_samples_per_second": 3604.296,
      "eval_steps_per_second": 450.553,
      "step": 650000
    },
    {
      "epoch": 6.881733634693867,
      "grad_norm": 1.1535344123840332,
      "learning_rate": 0.00013428227379182718,
      "loss": 0.5334,
      "step": 650050
    },
    {
      "epoch": 6.88226295647387,
      "grad_norm": 1.1528420448303223,
      "learning_rate": 0.00013424132973971744,
      "loss": 0.5516,
      "step": 650100
    },
    {
      "epoch": 6.8827922782538735,
      "grad_norm": 1.252841591835022,
      "learning_rate": 0.0001342003896395664,
      "loss": 0.5417,
      "step": 650150
    },
    {
      "epoch": 6.883321600033876,
      "grad_norm": 1.1707158088684082,
      "learning_rate": 0.00013415945349277143,
      "loss": 0.5424,
      "step": 650200
    },
    {
      "epoch": 6.88385092181388,
      "grad_norm": 1.2995623350143433,
      "learning_rate": 0.00013411852130073033,
      "loss": 0.5429,
      "step": 650250
    },
    {
      "epoch": 6.884380243593883,
      "grad_norm": 1.2570173740386963,
      "learning_rate": 0.00013407759306484032,
      "loss": 0.5437,
      "step": 650300
    },
    {
      "epoch": 6.884909565373887,
      "grad_norm": 1.3336724042892456,
      "learning_rate": 0.0001340366687864989,
      "loss": 0.5492,
      "step": 650350
    },
    {
      "epoch": 6.88543888715389,
      "grad_norm": 1.2019118070602417,
      "learning_rate": 0.00013399574846710295,
      "loss": 0.5408,
      "step": 650400
    },
    {
      "epoch": 6.885968208933893,
      "grad_norm": 1.2638194561004639,
      "learning_rate": 0.0001339548321080497,
      "loss": 0.5445,
      "step": 650450
    },
    {
      "epoch": 6.886497530713896,
      "grad_norm": 1.3255599737167358,
      "learning_rate": 0.00013391391971073586,
      "loss": 0.5475,
      "step": 650500
    },
    {
      "epoch": 6.886497530713896,
      "eval_loss": 0.33983394503593445,
      "eval_runtime": 47.2702,
      "eval_samples_per_second": 3552.554,
      "eval_steps_per_second": 444.085,
      "step": 650500
    },
    {
      "epoch": 6.8870268524939,
      "grad_norm": 1.2521148920059204,
      "learning_rate": 0.00013387301127655828,
      "loss": 0.5487,
      "step": 650550
    },
    {
      "epoch": 6.887556174273903,
      "grad_norm": 1.3440637588500977,
      "learning_rate": 0.00013383210680691343,
      "loss": 0.5433,
      "step": 650600
    },
    {
      "epoch": 6.888085496053906,
      "grad_norm": 1.297931432723999,
      "learning_rate": 0.00013379120630319796,
      "loss": 0.5538,
      "step": 650650
    },
    {
      "epoch": 6.8886148178339095,
      "grad_norm": 1.2390620708465576,
      "learning_rate": 0.00013375030976680796,
      "loss": 0.5361,
      "step": 650700
    },
    {
      "epoch": 6.889144139613912,
      "grad_norm": 1.2224236726760864,
      "learning_rate": 0.0001337094171991399,
      "loss": 0.5447,
      "step": 650750
    },
    {
      "epoch": 6.889673461393916,
      "grad_norm": 1.3562089204788208,
      "learning_rate": 0.00013366852860158956,
      "loss": 0.5415,
      "step": 650800
    },
    {
      "epoch": 6.890202783173919,
      "grad_norm": 1.2470260858535767,
      "learning_rate": 0.0001336276439755531,
      "loss": 0.5501,
      "step": 650850
    },
    {
      "epoch": 6.890732104953923,
      "grad_norm": 1.307729959487915,
      "learning_rate": 0.0001335867633224261,
      "loss": 0.5476,
      "step": 650900
    },
    {
      "epoch": 6.891261426733926,
      "grad_norm": 1.3673455715179443,
      "learning_rate": 0.0001335458866436043,
      "loss": 0.5422,
      "step": 650950
    },
    {
      "epoch": 6.891790748513929,
      "grad_norm": 1.3033905029296875,
      "learning_rate": 0.00013350501394048328,
      "loss": 0.5502,
      "step": 651000
    },
    {
      "epoch": 6.891790748513929,
      "eval_loss": 0.3404083549976349,
      "eval_runtime": 46.7815,
      "eval_samples_per_second": 3589.667,
      "eval_steps_per_second": 448.724,
      "step": 651000
    },
    {
      "epoch": 6.892320070293932,
      "grad_norm": 1.143052577972412,
      "learning_rate": 0.0001334641452144583,
      "loss": 0.5385,
      "step": 651050
    },
    {
      "epoch": 6.892849392073936,
      "grad_norm": 1.1304508447647095,
      "learning_rate": 0.00013342328046692464,
      "loss": 0.5537,
      "step": 651100
    },
    {
      "epoch": 6.893378713853939,
      "grad_norm": 1.2105587720870972,
      "learning_rate": 0.00013338241969927756,
      "loss": 0.5472,
      "step": 651150
    },
    {
      "epoch": 6.893908035633943,
      "grad_norm": 1.1237186193466187,
      "learning_rate": 0.0001333415629129118,
      "loss": 0.5507,
      "step": 651200
    },
    {
      "epoch": 6.8944373574139455,
      "grad_norm": 1.080333948135376,
      "learning_rate": 0.0001333007101092224,
      "loss": 0.5401,
      "step": 651250
    },
    {
      "epoch": 6.894966679193949,
      "grad_norm": 1.3316289186477661,
      "learning_rate": 0.00013325986128960384,
      "loss": 0.5456,
      "step": 651300
    },
    {
      "epoch": 6.895496000973952,
      "grad_norm": 1.1775091886520386,
      "learning_rate": 0.00013321901645545092,
      "loss": 0.5496,
      "step": 651350
    },
    {
      "epoch": 6.896025322753955,
      "grad_norm": 1.2904295921325684,
      "learning_rate": 0.00013317817560815786,
      "loss": 0.546,
      "step": 651400
    },
    {
      "epoch": 6.896554644533959,
      "grad_norm": 1.3014270067214966,
      "learning_rate": 0.00013313733874911914,
      "loss": 0.5466,
      "step": 651450
    },
    {
      "epoch": 6.897083966313962,
      "grad_norm": 1.2712198495864868,
      "learning_rate": 0.00013309650587972868,
      "loss": 0.5502,
      "step": 651500
    },
    {
      "epoch": 6.897083966313962,
      "eval_loss": 0.3408726751804352,
      "eval_runtime": 47.5352,
      "eval_samples_per_second": 3532.749,
      "eval_steps_per_second": 441.609,
      "step": 651500
    },
    {
      "epoch": 6.897613288093965,
      "grad_norm": 1.2622947692871094,
      "learning_rate": 0.00013305567700138077,
      "loss": 0.54,
      "step": 651550
    },
    {
      "epoch": 6.898142609873968,
      "grad_norm": 1.4023700952529907,
      "learning_rate": 0.00013301485211546904,
      "loss": 0.5419,
      "step": 651600
    },
    {
      "epoch": 6.898671931653972,
      "grad_norm": 1.1896600723266602,
      "learning_rate": 0.00013297403122338746,
      "loss": 0.5498,
      "step": 651650
    },
    {
      "epoch": 6.899201253433975,
      "grad_norm": 1.208182692527771,
      "learning_rate": 0.00013293321432652943,
      "loss": 0.5457,
      "step": 651700
    },
    {
      "epoch": 6.899730575213979,
      "grad_norm": 1.2220876216888428,
      "learning_rate": 0.00013289240142628865,
      "loss": 0.5432,
      "step": 651750
    },
    {
      "epoch": 6.9002598969939815,
      "grad_norm": 1.274158239364624,
      "learning_rate": 0.00013285159252405824,
      "loss": 0.5449,
      "step": 651800
    },
    {
      "epoch": 6.900789218773985,
      "grad_norm": 1.1827073097229004,
      "learning_rate": 0.00013281078762123158,
      "loss": 0.5494,
      "step": 651850
    },
    {
      "epoch": 6.901318540553988,
      "grad_norm": 1.3015687465667725,
      "learning_rate": 0.0001327708026980254,
      "loss": 0.5456,
      "step": 651900
    },
    {
      "epoch": 6.901847862333992,
      "grad_norm": 1.335166096687317,
      "learning_rate": 0.00013273000571812756,
      "loss": 0.5529,
      "step": 651950
    },
    {
      "epoch": 6.902377184113995,
      "grad_norm": 1.1928476095199585,
      "learning_rate": 0.00013268921274178446,
      "loss": 0.5446,
      "step": 652000
    },
    {
      "epoch": 6.902377184113995,
      "eval_loss": 0.34048983454704285,
      "eval_runtime": 47.9938,
      "eval_samples_per_second": 3498.993,
      "eval_steps_per_second": 437.39,
      "step": 652000
    },
    {
      "epoch": 6.9029065058939985,
      "grad_norm": 1.2521791458129883,
      "learning_rate": 0.00013264842377038848,
      "loss": 0.5453,
      "step": 652050
    },
    {
      "epoch": 6.903435827674001,
      "grad_norm": 1.2124414443969727,
      "learning_rate": 0.00013260763880533244,
      "loss": 0.5405,
      "step": 652100
    },
    {
      "epoch": 6.903965149454004,
      "grad_norm": 1.2674640417099,
      "learning_rate": 0.00013256685784800843,
      "loss": 0.5424,
      "step": 652150
    },
    {
      "epoch": 6.904494471234008,
      "grad_norm": 1.391660451889038,
      "learning_rate": 0.00013252608089980888,
      "loss": 0.5389,
      "step": 652200
    },
    {
      "epoch": 6.905023793014011,
      "grad_norm": 1.0946414470672607,
      "learning_rate": 0.00013248530796212583,
      "loss": 0.5423,
      "step": 652250
    },
    {
      "epoch": 6.905553114794015,
      "grad_norm": 1.3041986227035522,
      "learning_rate": 0.0001324445390363513,
      "loss": 0.5467,
      "step": 652300
    },
    {
      "epoch": 6.906082436574017,
      "grad_norm": 1.2111823558807373,
      "learning_rate": 0.000132403774123877,
      "loss": 0.5454,
      "step": 652350
    },
    {
      "epoch": 6.906611758354021,
      "grad_norm": 1.2012850046157837,
      "learning_rate": 0.00013236301322609484,
      "loss": 0.5479,
      "step": 652400
    },
    {
      "epoch": 6.907141080134024,
      "grad_norm": 1.1691746711730957,
      "learning_rate": 0.0001323222563443962,
      "loss": 0.5403,
      "step": 652450
    },
    {
      "epoch": 6.907670401914028,
      "grad_norm": 1.2661091089248657,
      "learning_rate": 0.0001322815034801726,
      "loss": 0.5353,
      "step": 652500
    },
    {
      "epoch": 6.907670401914028,
      "eval_loss": 0.33991366624832153,
      "eval_runtime": 47.8564,
      "eval_samples_per_second": 3509.041,
      "eval_steps_per_second": 438.646,
      "step": 652500
    },
    {
      "epoch": 6.908199723694031,
      "grad_norm": 1.3309048414230347,
      "learning_rate": 0.00013224075463481527,
      "loss": 0.5411,
      "step": 652550
    },
    {
      "epoch": 6.908729045474034,
      "grad_norm": 1.4518930912017822,
      "learning_rate": 0.00013220000980971545,
      "loss": 0.5493,
      "step": 652600
    },
    {
      "epoch": 6.909258367254037,
      "grad_norm": 1.212803840637207,
      "learning_rate": 0.000132159269006264,
      "loss": 0.5417,
      "step": 652650
    },
    {
      "epoch": 6.909787689034041,
      "grad_norm": 1.1954209804534912,
      "learning_rate": 0.00013211853222585198,
      "loss": 0.5419,
      "step": 652700
    },
    {
      "epoch": 6.910317010814044,
      "grad_norm": 1.2377272844314575,
      "learning_rate": 0.00013207779946986997,
      "loss": 0.5535,
      "step": 652750
    },
    {
      "epoch": 6.910846332594048,
      "grad_norm": 1.2559633255004883,
      "learning_rate": 0.0001320370707397087,
      "loss": 0.5446,
      "step": 652800
    },
    {
      "epoch": 6.9113756543740505,
      "grad_norm": 1.197164535522461,
      "learning_rate": 0.00013199634603675847,
      "loss": 0.5473,
      "step": 652850
    },
    {
      "epoch": 6.911904976154053,
      "grad_norm": 1.1630507707595825,
      "learning_rate": 0.00013195562536240973,
      "loss": 0.5384,
      "step": 652900
    },
    {
      "epoch": 6.912434297934057,
      "grad_norm": 1.2186812162399292,
      "learning_rate": 0.00013191490871805278,
      "loss": 0.5346,
      "step": 652950
    },
    {
      "epoch": 6.91296361971406,
      "grad_norm": 1.3365015983581543,
      "learning_rate": 0.00013187419610507739,
      "loss": 0.5376,
      "step": 653000
    },
    {
      "epoch": 6.91296361971406,
      "eval_loss": 0.3394719064235687,
      "eval_runtime": 47.5527,
      "eval_samples_per_second": 3531.453,
      "eval_steps_per_second": 441.447,
      "step": 653000
    },
    {
      "epoch": 6.913492941494064,
      "grad_norm": 1.3129442930221558,
      "learning_rate": 0.00013183348752487375,
      "loss": 0.5416,
      "step": 653050
    },
    {
      "epoch": 6.914022263274067,
      "grad_norm": 1.3446943759918213,
      "learning_rate": 0.00013179278297883142,
      "loss": 0.5501,
      "step": 653100
    },
    {
      "epoch": 6.91455158505407,
      "grad_norm": 1.1900765895843506,
      "learning_rate": 0.00013175208246834008,
      "loss": 0.5433,
      "step": 653150
    },
    {
      "epoch": 6.915080906834073,
      "grad_norm": 1.1902354955673218,
      "learning_rate": 0.00013171138599478942,
      "loss": 0.5489,
      "step": 653200
    },
    {
      "epoch": 6.915610228614077,
      "grad_norm": 1.2192151546478271,
      "learning_rate": 0.00013167069355956857,
      "loss": 0.5516,
      "step": 653250
    },
    {
      "epoch": 6.91613955039408,
      "grad_norm": 1.2480685710906982,
      "learning_rate": 0.0001316300051640669,
      "loss": 0.5454,
      "step": 653300
    },
    {
      "epoch": 6.916668872174084,
      "grad_norm": 1.3843551874160767,
      "learning_rate": 0.00013158932080967339,
      "loss": 0.541,
      "step": 653350
    },
    {
      "epoch": 6.9171981939540865,
      "grad_norm": 1.3400986194610596,
      "learning_rate": 0.00013154864049777702,
      "loss": 0.5604,
      "step": 653400
    },
    {
      "epoch": 6.91772751573409,
      "grad_norm": 1.2616043090820312,
      "learning_rate": 0.00013150796422976672,
      "loss": 0.5473,
      "step": 653450
    },
    {
      "epoch": 6.918256837514093,
      "grad_norm": 1.2955743074417114,
      "learning_rate": 0.00013146729200703093,
      "loss": 0.5481,
      "step": 653500
    },
    {
      "epoch": 6.918256837514093,
      "eval_loss": 0.3397991955280304,
      "eval_runtime": 47.8568,
      "eval_samples_per_second": 3509.012,
      "eval_steps_per_second": 438.642,
      "step": 653500
    },
    {
      "epoch": 6.918786159294097,
      "grad_norm": 1.3103904724121094,
      "learning_rate": 0.0001314266238309585,
      "loss": 0.5446,
      "step": 653550
    },
    {
      "epoch": 6.9193154810741,
      "grad_norm": 1.2731187343597412,
      "learning_rate": 0.00013138595970293748,
      "loss": 0.5558,
      "step": 653600
    },
    {
      "epoch": 6.919844802854103,
      "grad_norm": 1.2078368663787842,
      "learning_rate": 0.00013134529962435644,
      "loss": 0.5403,
      "step": 653650
    },
    {
      "epoch": 6.920374124634106,
      "grad_norm": 1.1822662353515625,
      "learning_rate": 0.0001313046435966032,
      "loss": 0.5451,
      "step": 653700
    },
    {
      "epoch": 6.920903446414109,
      "grad_norm": 1.2236090898513794,
      "learning_rate": 0.00013126399162106606,
      "loss": 0.5359,
      "step": 653750
    },
    {
      "epoch": 6.921432768194113,
      "grad_norm": 1.2372552156448364,
      "learning_rate": 0.00013122334369913258,
      "loss": 0.5424,
      "step": 653800
    },
    {
      "epoch": 6.921962089974116,
      "grad_norm": 1.3335301876068115,
      "learning_rate": 0.00013118269983219066,
      "loss": 0.5406,
      "step": 653850
    },
    {
      "epoch": 6.92249141175412,
      "grad_norm": 1.1777325868606567,
      "learning_rate": 0.0001311428727780775,
      "loss": 0.5495,
      "step": 653900
    },
    {
      "epoch": 6.9230207335341225,
      "grad_norm": 1.1520466804504395,
      "learning_rate": 0.00013110223694411214,
      "loss": 0.5489,
      "step": 653950
    },
    {
      "epoch": 6.923550055314126,
      "grad_norm": 1.2437047958374023,
      "learning_rate": 0.00013106160516927287,
      "loss": 0.55,
      "step": 654000
    },
    {
      "epoch": 6.923550055314126,
      "eval_loss": 0.34005674719810486,
      "eval_runtime": 48.1435,
      "eval_samples_per_second": 3488.116,
      "eval_steps_per_second": 436.03,
      "step": 654000
    },
    {
      "epoch": 6.924079377094129,
      "grad_norm": 1.1850383281707764,
      "learning_rate": 0.00013102097745494668,
      "loss": 0.5413,
      "step": 654050
    },
    {
      "epoch": 6.924608698874133,
      "grad_norm": 1.3141138553619385,
      "learning_rate": 0.0001309803538025208,
      "loss": 0.5373,
      "step": 654100
    },
    {
      "epoch": 6.925138020654136,
      "grad_norm": 1.1868972778320312,
      "learning_rate": 0.00013093973421338188,
      "loss": 0.5431,
      "step": 654150
    },
    {
      "epoch": 6.9256673424341395,
      "grad_norm": 1.2114344835281372,
      "learning_rate": 0.00013089911868891684,
      "loss": 0.5419,
      "step": 654200
    },
    {
      "epoch": 6.926196664214142,
      "grad_norm": 1.2510920763015747,
      "learning_rate": 0.00013085850723051218,
      "loss": 0.5485,
      "step": 654250
    },
    {
      "epoch": 6.926725985994146,
      "grad_norm": 1.2351561784744263,
      "learning_rate": 0.00013081789983955444,
      "loss": 0.5317,
      "step": 654300
    },
    {
      "epoch": 6.927255307774149,
      "grad_norm": 1.2344509363174438,
      "learning_rate": 0.0001307772965174298,
      "loss": 0.5336,
      "step": 654350
    },
    {
      "epoch": 6.927784629554152,
      "grad_norm": 1.2532432079315186,
      "learning_rate": 0.00013073669726552462,
      "loss": 0.5461,
      "step": 654400
    },
    {
      "epoch": 6.928313951334156,
      "grad_norm": 1.3782429695129395,
      "learning_rate": 0.0001306961020852248,
      "loss": 0.5477,
      "step": 654450
    },
    {
      "epoch": 6.9288432731141585,
      "grad_norm": 1.2921040058135986,
      "learning_rate": 0.00013065551097791634,
      "loss": 0.5444,
      "step": 654500
    },
    {
      "epoch": 6.9288432731141585,
      "eval_loss": 0.34001612663269043,
      "eval_runtime": 48.1476,
      "eval_samples_per_second": 3487.818,
      "eval_steps_per_second": 435.993,
      "step": 654500
    },
    {
      "epoch": 6.929372594894162,
      "grad_norm": 1.2512911558151245,
      "learning_rate": 0.00013061492394498493,
      "loss": 0.5421,
      "step": 654550
    },
    {
      "epoch": 6.929901916674165,
      "grad_norm": 1.2487502098083496,
      "learning_rate": 0.0001305743409878163,
      "loss": 0.5419,
      "step": 654600
    },
    {
      "epoch": 6.930431238454169,
      "grad_norm": 1.2355793714523315,
      "learning_rate": 0.00013053376210779577,
      "loss": 0.5368,
      "step": 654650
    },
    {
      "epoch": 6.930960560234172,
      "grad_norm": 1.240363597869873,
      "learning_rate": 0.0001304931873063089,
      "loss": 0.5369,
      "step": 654700
    },
    {
      "epoch": 6.9314898820141755,
      "grad_norm": 1.2617403268814087,
      "learning_rate": 0.00013045261658474068,
      "loss": 0.5432,
      "step": 654750
    },
    {
      "epoch": 6.932019203794178,
      "grad_norm": 1.3277195692062378,
      "learning_rate": 0.00013041204994447637,
      "loss": 0.544,
      "step": 654800
    },
    {
      "epoch": 6.932548525574182,
      "grad_norm": 1.2772949934005737,
      "learning_rate": 0.00013037148738690072,
      "loss": 0.543,
      "step": 654850
    },
    {
      "epoch": 6.933077847354185,
      "grad_norm": 1.3131872415542603,
      "learning_rate": 0.00013033092891339874,
      "loss": 0.5439,
      "step": 654900
    },
    {
      "epoch": 6.933607169134189,
      "grad_norm": 1.2546087503433228,
      "learning_rate": 0.00013029037452535485,
      "loss": 0.5423,
      "step": 654950
    },
    {
      "epoch": 6.934136490914192,
      "grad_norm": 1.306189775466919,
      "learning_rate": 0.00013024982422415378,
      "loss": 0.5463,
      "step": 655000
    },
    {
      "epoch": 6.934136490914192,
      "eval_loss": 0.3389282524585724,
      "eval_runtime": 47.3459,
      "eval_samples_per_second": 3546.877,
      "eval_steps_per_second": 443.375,
      "step": 655000
    },
    {
      "epoch": 6.934665812694195,
      "grad_norm": 1.2996585369110107,
      "learning_rate": 0.00013020927801117964,
      "loss": 0.5472,
      "step": 655050
    },
    {
      "epoch": 6.935195134474198,
      "grad_norm": 1.2518577575683594,
      "learning_rate": 0.000130168735887817,
      "loss": 0.5379,
      "step": 655100
    },
    {
      "epoch": 6.935724456254201,
      "grad_norm": 1.1817235946655273,
      "learning_rate": 0.00013012819785544963,
      "loss": 0.5451,
      "step": 655150
    },
    {
      "epoch": 6.936253778034205,
      "grad_norm": 1.2719522714614868,
      "learning_rate": 0.00013008766391546162,
      "loss": 0.5456,
      "step": 655200
    },
    {
      "epoch": 6.936783099814208,
      "grad_norm": 1.2662022113800049,
      "learning_rate": 0.0001300471340692369,
      "loss": 0.5405,
      "step": 655250
    },
    {
      "epoch": 6.9373124215942115,
      "grad_norm": 1.2859828472137451,
      "learning_rate": 0.00013000660831815892,
      "loss": 0.5462,
      "step": 655300
    },
    {
      "epoch": 6.937841743374214,
      "grad_norm": 1.1087934970855713,
      "learning_rate": 0.00012996608666361142,
      "loss": 0.5453,
      "step": 655350
    },
    {
      "epoch": 6.938371065154218,
      "grad_norm": 1.3178023099899292,
      "learning_rate": 0.0001299255691069776,
      "loss": 0.5463,
      "step": 655400
    },
    {
      "epoch": 6.938900386934221,
      "grad_norm": 1.358324646949768,
      "learning_rate": 0.00012988505564964084,
      "loss": 0.5398,
      "step": 655450
    },
    {
      "epoch": 6.939429708714225,
      "grad_norm": 1.1937144994735718,
      "learning_rate": 0.00012984454629298432,
      "loss": 0.5476,
      "step": 655500
    },
    {
      "epoch": 6.939429708714225,
      "eval_loss": 0.3378449082374573,
      "eval_runtime": 47.3961,
      "eval_samples_per_second": 3543.115,
      "eval_steps_per_second": 442.905,
      "step": 655500
    },
    {
      "epoch": 6.939959030494228,
      "grad_norm": 1.2804754972457886,
      "learning_rate": 0.00012980404103839083,
      "loss": 0.5508,
      "step": 655550
    },
    {
      "epoch": 6.940488352274231,
      "grad_norm": 1.284622311592102,
      "learning_rate": 0.0001297635398872434,
      "loss": 0.5365,
      "step": 655600
    },
    {
      "epoch": 6.941017674054234,
      "grad_norm": 1.287726879119873,
      "learning_rate": 0.00012972304284092448,
      "loss": 0.5453,
      "step": 655650
    },
    {
      "epoch": 6.941546995834238,
      "grad_norm": 1.2756880521774292,
      "learning_rate": 0.0001296825499008169,
      "loss": 0.5452,
      "step": 655700
    },
    {
      "epoch": 6.942076317614241,
      "grad_norm": 1.2597274780273438,
      "learning_rate": 0.00012964206106830283,
      "loss": 0.5435,
      "step": 655750
    },
    {
      "epoch": 6.942605639394245,
      "grad_norm": 1.1603169441223145,
      "learning_rate": 0.00012960157634476477,
      "loss": 0.5502,
      "step": 655800
    },
    {
      "epoch": 6.943134961174247,
      "grad_norm": 1.3172112703323364,
      "learning_rate": 0.00012956109573158465,
      "loss": 0.5464,
      "step": 655850
    },
    {
      "epoch": 6.94366428295425,
      "grad_norm": 1.1456654071807861,
      "learning_rate": 0.00012952061923014464,
      "loss": 0.5414,
      "step": 655900
    },
    {
      "epoch": 6.944193604734254,
      "grad_norm": 1.199763298034668,
      "learning_rate": 0.00012948095624927525,
      "loss": 0.5455,
      "step": 655950
    },
    {
      "epoch": 6.944722926514257,
      "grad_norm": 1.40302312374115,
      "learning_rate": 0.00012944048789315698,
      "loss": 0.5438,
      "step": 656000
    },
    {
      "epoch": 6.944722926514257,
      "eval_loss": 0.3399743139743805,
      "eval_runtime": 47.7874,
      "eval_samples_per_second": 3514.108,
      "eval_steps_per_second": 439.279,
      "step": 656000
    },
    {
      "epoch": 6.945252248294261,
      "grad_norm": 1.3016481399536133,
      "learning_rate": 0.00012940002365289632,
      "loss": 0.5459,
      "step": 656050
    },
    {
      "epoch": 6.9457815700742636,
      "grad_norm": 1.1453603506088257,
      "learning_rate": 0.00012935956352987454,
      "loss": 0.5412,
      "step": 656100
    },
    {
      "epoch": 6.946310891854267,
      "grad_norm": 1.2464441061019897,
      "learning_rate": 0.00012931910752547314,
      "loss": 0.546,
      "step": 656150
    },
    {
      "epoch": 6.94684021363427,
      "grad_norm": 1.2096034288406372,
      "learning_rate": 0.00012927865564107304,
      "loss": 0.5468,
      "step": 656200
    },
    {
      "epoch": 6.947369535414274,
      "grad_norm": 1.279691219329834,
      "learning_rate": 0.00012923820787805545,
      "loss": 0.5366,
      "step": 656250
    },
    {
      "epoch": 6.947898857194277,
      "grad_norm": 1.197044014930725,
      "learning_rate": 0.00012919776423780108,
      "loss": 0.5448,
      "step": 656300
    },
    {
      "epoch": 6.9484281789742806,
      "grad_norm": 1.2384005784988403,
      "learning_rate": 0.0001291573247216908,
      "loss": 0.5487,
      "step": 656350
    },
    {
      "epoch": 6.948957500754283,
      "grad_norm": 1.1446727514266968,
      "learning_rate": 0.00012911688933110507,
      "loss": 0.5432,
      "step": 656400
    },
    {
      "epoch": 6.949486822534287,
      "grad_norm": 1.1589034795761108,
      "learning_rate": 0.00012907645806742448,
      "loss": 0.5567,
      "step": 656450
    },
    {
      "epoch": 6.95001614431429,
      "grad_norm": 1.1257175207138062,
      "learning_rate": 0.0001290360309320292,
      "loss": 0.5467,
      "step": 656500
    },
    {
      "epoch": 6.95001614431429,
      "eval_loss": 0.33790943026542664,
      "eval_runtime": 47.698,
      "eval_samples_per_second": 3520.696,
      "eval_steps_per_second": 440.103,
      "step": 656500
    },
    {
      "epoch": 6.950545466094294,
      "grad_norm": 1.1730998754501343,
      "learning_rate": 0.00012899560792629952,
      "loss": 0.5449,
      "step": 656550
    },
    {
      "epoch": 6.951074787874297,
      "grad_norm": 1.2231745719909668,
      "learning_rate": 0.00012895518905161533,
      "loss": 0.5359,
      "step": 656600
    },
    {
      "epoch": 6.9516041096542995,
      "grad_norm": 1.2679518461227417,
      "learning_rate": 0.0001289147743093567,
      "loss": 0.5401,
      "step": 656650
    },
    {
      "epoch": 6.952133431434303,
      "grad_norm": 1.1814583539962769,
      "learning_rate": 0.00012887436370090317,
      "loss": 0.5558,
      "step": 656700
    },
    {
      "epoch": 6.952662753214306,
      "grad_norm": 1.366106390953064,
      "learning_rate": 0.00012883395722763452,
      "loss": 0.5502,
      "step": 656750
    },
    {
      "epoch": 6.95319207499431,
      "grad_norm": 1.3042333126068115,
      "learning_rate": 0.00012879355489093004,
      "loss": 0.5374,
      "step": 656800
    },
    {
      "epoch": 6.953721396774313,
      "grad_norm": 1.210315227508545,
      "learning_rate": 0.00012875315669216925,
      "loss": 0.5419,
      "step": 656850
    },
    {
      "epoch": 6.9542507185543165,
      "grad_norm": 1.3406404256820679,
      "learning_rate": 0.0001287127626327311,
      "loss": 0.5282,
      "step": 656900
    },
    {
      "epoch": 6.954780040334319,
      "grad_norm": 1.3180545568466187,
      "learning_rate": 0.0001286723727139949,
      "loss": 0.5389,
      "step": 656950
    },
    {
      "epoch": 6.955309362114323,
      "grad_norm": 1.3119192123413086,
      "learning_rate": 0.00012863198693733924,
      "loss": 0.54,
      "step": 657000
    },
    {
      "epoch": 6.955309362114323,
      "eval_loss": 0.3378639817237854,
      "eval_runtime": 47.7424,
      "eval_samples_per_second": 3517.422,
      "eval_steps_per_second": 439.693,
      "step": 657000
    },
    {
      "epoch": 6.955838683894326,
      "grad_norm": 1.2525197267532349,
      "learning_rate": 0.00012859160530414318,
      "loss": 0.548,
      "step": 657050
    },
    {
      "epoch": 6.95636800567433,
      "grad_norm": 1.2696622610092163,
      "learning_rate": 0.00012855122781578509,
      "loss": 0.5415,
      "step": 657100
    },
    {
      "epoch": 6.956897327454333,
      "grad_norm": 1.158806324005127,
      "learning_rate": 0.00012851085447364364,
      "loss": 0.5376,
      "step": 657150
    },
    {
      "epoch": 6.957426649234336,
      "grad_norm": 1.2795400619506836,
      "learning_rate": 0.00012847048527909693,
      "loss": 0.543,
      "step": 657200
    },
    {
      "epoch": 6.957955971014339,
      "grad_norm": 1.1806679964065552,
      "learning_rate": 0.0001284301202335234,
      "loss": 0.5497,
      "step": 657250
    },
    {
      "epoch": 6.958485292794343,
      "grad_norm": 1.1827740669250488,
      "learning_rate": 0.00012838975933830092,
      "loss": 0.5366,
      "step": 657300
    },
    {
      "epoch": 6.959014614574346,
      "grad_norm": 1.3083992004394531,
      "learning_rate": 0.00012834940259480744,
      "loss": 0.5404,
      "step": 657350
    },
    {
      "epoch": 6.959543936354349,
      "grad_norm": 1.2267484664916992,
      "learning_rate": 0.0001283090500044208,
      "loss": 0.542,
      "step": 657400
    },
    {
      "epoch": 6.9600732581343525,
      "grad_norm": 1.3573297262191772,
      "learning_rate": 0.0001282687015685185,
      "loss": 0.5507,
      "step": 657450
    },
    {
      "epoch": 6.960602579914355,
      "grad_norm": 1.3247488737106323,
      "learning_rate": 0.00012822835728847808,
      "loss": 0.5458,
      "step": 657500
    },
    {
      "epoch": 6.960602579914355,
      "eval_loss": 0.33860403299331665,
      "eval_runtime": 47.7248,
      "eval_samples_per_second": 3518.715,
      "eval_steps_per_second": 439.855,
      "step": 657500
    },
    {
      "epoch": 6.961131901694359,
      "grad_norm": 1.2546286582946777,
      "learning_rate": 0.00012818801716567697,
      "loss": 0.5369,
      "step": 657550
    },
    {
      "epoch": 6.961661223474362,
      "grad_norm": 1.2328790426254272,
      "learning_rate": 0.0001281476812014922,
      "loss": 0.5432,
      "step": 657600
    },
    {
      "epoch": 6.962190545254366,
      "grad_norm": 1.2791576385498047,
      "learning_rate": 0.00012810734939730102,
      "loss": 0.5426,
      "step": 657650
    },
    {
      "epoch": 6.962719867034369,
      "grad_norm": 1.1630897521972656,
      "learning_rate": 0.0001280670217544801,
      "loss": 0.5384,
      "step": 657700
    },
    {
      "epoch": 6.963249188814372,
      "grad_norm": 1.2980302572250366,
      "learning_rate": 0.00012802669827440645,
      "loss": 0.5328,
      "step": 657750
    },
    {
      "epoch": 6.963778510594375,
      "grad_norm": 1.2690352201461792,
      "learning_rate": 0.00012798637895845646,
      "loss": 0.536,
      "step": 657800
    },
    {
      "epoch": 6.964307832374379,
      "grad_norm": 1.2941765785217285,
      "learning_rate": 0.00012794606380800688,
      "loss": 0.5466,
      "step": 657850
    },
    {
      "epoch": 6.964837154154382,
      "grad_norm": 1.2684552669525146,
      "learning_rate": 0.00012790575282443378,
      "loss": 0.5396,
      "step": 657900
    },
    {
      "epoch": 6.965366475934386,
      "grad_norm": 1.324758529663086,
      "learning_rate": 0.00012786625210456221,
      "loss": 0.5366,
      "step": 657950
    },
    {
      "epoch": 6.9658957977143885,
      "grad_norm": 1.362481951713562,
      "learning_rate": 0.00012782594937546488,
      "loss": 0.5485,
      "step": 658000
    },
    {
      "epoch": 6.9658957977143885,
      "eval_loss": 0.3379594385623932,
      "eval_runtime": 47.2558,
      "eval_samples_per_second": 3553.638,
      "eval_steps_per_second": 444.221,
      "step": 658000
    },
    {
      "epoch": 6.966425119494392,
      "grad_norm": 1.22777259349823,
      "learning_rate": 0.00012778565081734473,
      "loss": 0.5416,
      "step": 658050
    },
    {
      "epoch": 6.966954441274395,
      "grad_norm": 1.1611405611038208,
      "learning_rate": 0.00012774535643157763,
      "loss": 0.5459,
      "step": 658100
    },
    {
      "epoch": 6.967483763054398,
      "grad_norm": 1.118666648864746,
      "learning_rate": 0.00012770506621953936,
      "loss": 0.5358,
      "step": 658150
    },
    {
      "epoch": 6.968013084834402,
      "grad_norm": 1.2676773071289062,
      "learning_rate": 0.00012766478018260514,
      "loss": 0.5357,
      "step": 658200
    },
    {
      "epoch": 6.968542406614405,
      "grad_norm": 1.1959209442138672,
      "learning_rate": 0.0001276244983221506,
      "loss": 0.5419,
      "step": 658250
    },
    {
      "epoch": 6.969071728394408,
      "grad_norm": 1.0809420347213745,
      "learning_rate": 0.00012758422063955066,
      "loss": 0.5377,
      "step": 658300
    },
    {
      "epoch": 6.969601050174411,
      "grad_norm": 1.1731464862823486,
      "learning_rate": 0.00012754394713618066,
      "loss": 0.5433,
      "step": 658350
    },
    {
      "epoch": 6.970130371954415,
      "grad_norm": 1.219383955001831,
      "learning_rate": 0.0001275036778134153,
      "loss": 0.5392,
      "step": 658400
    },
    {
      "epoch": 6.970659693734418,
      "grad_norm": 1.2142287492752075,
      "learning_rate": 0.00012746341267262954,
      "loss": 0.5406,
      "step": 658450
    },
    {
      "epoch": 6.971189015514422,
      "grad_norm": 1.3543728590011597,
      "learning_rate": 0.00012742315171519785,
      "loss": 0.5413,
      "step": 658500
    },
    {
      "epoch": 6.971189015514422,
      "eval_loss": 0.33779144287109375,
      "eval_runtime": 47.8288,
      "eval_samples_per_second": 3511.062,
      "eval_steps_per_second": 438.898,
      "step": 658500
    },
    {
      "epoch": 6.9717183372944245,
      "grad_norm": 1.3283724784851074,
      "learning_rate": 0.0001273828949424949,
      "loss": 0.5449,
      "step": 658550
    },
    {
      "epoch": 6.972247659074428,
      "grad_norm": 1.2227526903152466,
      "learning_rate": 0.0001273426423558948,
      "loss": 0.5445,
      "step": 658600
    },
    {
      "epoch": 6.972776980854431,
      "grad_norm": 1.4294275045394897,
      "learning_rate": 0.00012730239395677208,
      "loss": 0.5472,
      "step": 658650
    },
    {
      "epoch": 6.973306302634435,
      "grad_norm": 1.2522029876708984,
      "learning_rate": 0.00012726214974650052,
      "loss": 0.537,
      "step": 658700
    },
    {
      "epoch": 6.973835624414438,
      "grad_norm": 1.4115499258041382,
      "learning_rate": 0.00012722190972645422,
      "loss": 0.5465,
      "step": 658750
    },
    {
      "epoch": 6.9743649461944415,
      "grad_norm": 1.2374478578567505,
      "learning_rate": 0.00012718167389800684,
      "loss": 0.543,
      "step": 658800
    },
    {
      "epoch": 6.974894267974444,
      "grad_norm": 1.4152896404266357,
      "learning_rate": 0.0001271414422625321,
      "loss": 0.5368,
      "step": 658850
    },
    {
      "epoch": 6.975423589754447,
      "grad_norm": 1.3214491605758667,
      "learning_rate": 0.00012710201932911256,
      "loss": 0.5478,
      "step": 658900
    },
    {
      "epoch": 6.975952911534451,
      "grad_norm": 1.1912248134613037,
      "learning_rate": 0.00012706179599977546,
      "loss": 0.5364,
      "step": 658950
    },
    {
      "epoch": 6.976482233314454,
      "grad_norm": 1.2167689800262451,
      "learning_rate": 0.0001270215768675037,
      "loss": 0.5451,
      "step": 659000
    },
    {
      "epoch": 6.976482233314454,
      "eval_loss": 0.3378106951713562,
      "eval_runtime": 48.0096,
      "eval_samples_per_second": 3497.845,
      "eval_steps_per_second": 437.246,
      "step": 659000
    },
    {
      "epoch": 6.977011555094458,
      "grad_norm": 1.2129675149917603,
      "learning_rate": 0.00012698136193367004,
      "loss": 0.537,
      "step": 659050
    },
    {
      "epoch": 6.9775408768744605,
      "grad_norm": 1.2275418043136597,
      "learning_rate": 0.0001269411511996477,
      "loss": 0.5402,
      "step": 659100
    },
    {
      "epoch": 6.978070198654464,
      "grad_norm": 1.3835111856460571,
      "learning_rate": 0.00012690094466680926,
      "loss": 0.5401,
      "step": 659150
    },
    {
      "epoch": 6.978599520434467,
      "grad_norm": 1.36832594871521,
      "learning_rate": 0.0001268607423365275,
      "loss": 0.5416,
      "step": 659200
    },
    {
      "epoch": 6.979128842214471,
      "grad_norm": 1.2385083436965942,
      "learning_rate": 0.0001268205442101747,
      "loss": 0.5383,
      "step": 659250
    },
    {
      "epoch": 6.979658163994474,
      "grad_norm": 1.262658953666687,
      "learning_rate": 0.0001267803502891235,
      "loss": 0.5447,
      "step": 659300
    },
    {
      "epoch": 6.9801874857744775,
      "grad_norm": 1.2550185918807983,
      "learning_rate": 0.00012674016057474585,
      "loss": 0.5451,
      "step": 659350
    },
    {
      "epoch": 6.98071680755448,
      "grad_norm": 1.3517189025878906,
      "learning_rate": 0.00012669997506841395,
      "loss": 0.5354,
      "step": 659400
    },
    {
      "epoch": 6.981246129334484,
      "grad_norm": 1.2530468702316284,
      "learning_rate": 0.00012665979377149967,
      "loss": 0.5418,
      "step": 659450
    },
    {
      "epoch": 6.981775451114487,
      "grad_norm": 1.2559857368469238,
      "learning_rate": 0.00012661961668537485,
      "loss": 0.5415,
      "step": 659500
    },
    {
      "epoch": 6.981775451114487,
      "eval_loss": 0.3375670313835144,
      "eval_runtime": 46.9227,
      "eval_samples_per_second": 3578.867,
      "eval_steps_per_second": 447.374,
      "step": 659500
    },
    {
      "epoch": 6.982304772894491,
      "grad_norm": 1.257453203201294,
      "learning_rate": 0.00012657944381141094,
      "loss": 0.5413,
      "step": 659550
    },
    {
      "epoch": 6.982834094674494,
      "grad_norm": 1.263954758644104,
      "learning_rate": 0.0001265392751509797,
      "loss": 0.5377,
      "step": 659600
    },
    {
      "epoch": 6.983363416454496,
      "grad_norm": 1.2979704141616821,
      "learning_rate": 0.00012649911070545223,
      "loss": 0.5419,
      "step": 659650
    },
    {
      "epoch": 6.9838927382345,
      "grad_norm": 1.1965694427490234,
      "learning_rate": 0.0001264589504761999,
      "loss": 0.5398,
      "step": 659700
    },
    {
      "epoch": 6.984422060014503,
      "grad_norm": 1.2056686878204346,
      "learning_rate": 0.00012641879446459358,
      "loss": 0.5415,
      "step": 659750
    },
    {
      "epoch": 6.984951381794507,
      "grad_norm": 1.308245301246643,
      "learning_rate": 0.00012637864267200444,
      "loss": 0.5401,
      "step": 659800
    },
    {
      "epoch": 6.98548070357451,
      "grad_norm": 1.279626727104187,
      "learning_rate": 0.000126338495099803,
      "loss": 0.5313,
      "step": 659850
    },
    {
      "epoch": 6.986010025354513,
      "grad_norm": 1.2495261430740356,
      "learning_rate": 0.00012629835174936006,
      "loss": 0.5525,
      "step": 659900
    },
    {
      "epoch": 6.986539347134516,
      "grad_norm": 1.2176233530044556,
      "learning_rate": 0.00012625821262204592,
      "loss": 0.539,
      "step": 659950
    },
    {
      "epoch": 6.98706866891452,
      "grad_norm": 1.256123661994934,
      "learning_rate": 0.00012621807771923105,
      "loss": 0.5421,
      "step": 660000
    },
    {
      "epoch": 6.98706866891452,
      "eval_loss": 0.33738043904304504,
      "eval_runtime": 47.8536,
      "eval_samples_per_second": 3509.244,
      "eval_steps_per_second": 438.671,
      "step": 660000
    },
    {
      "epoch": 6.987597990694523,
      "grad_norm": 1.1570876836776733,
      "learning_rate": 0.00012617794704228568,
      "loss": 0.5402,
      "step": 660050
    },
    {
      "epoch": 6.988127312474527,
      "grad_norm": 1.2270108461380005,
      "learning_rate": 0.00012613782059257972,
      "loss": 0.5398,
      "step": 660100
    },
    {
      "epoch": 6.9886566342545295,
      "grad_norm": 1.1907172203063965,
      "learning_rate": 0.0001260976983714831,
      "loss": 0.543,
      "step": 660150
    },
    {
      "epoch": 6.989185956034533,
      "grad_norm": 1.1834805011749268,
      "learning_rate": 0.00012605758038036573,
      "loss": 0.5428,
      "step": 660200
    },
    {
      "epoch": 6.989715277814536,
      "grad_norm": 1.2452787160873413,
      "learning_rate": 0.00012601746662059703,
      "loss": 0.5336,
      "step": 660250
    },
    {
      "epoch": 6.99024459959454,
      "grad_norm": 1.2275006771087646,
      "learning_rate": 0.00012597735709354664,
      "loss": 0.539,
      "step": 660300
    },
    {
      "epoch": 6.990773921374543,
      "grad_norm": 1.2544410228729248,
      "learning_rate": 0.0001259372518005837,
      "loss": 0.5384,
      "step": 660350
    },
    {
      "epoch": 6.991303243154546,
      "grad_norm": 1.184317946434021,
      "learning_rate": 0.00012589715074307758,
      "loss": 0.5384,
      "step": 660400
    },
    {
      "epoch": 6.991832564934549,
      "grad_norm": 1.2298609018325806,
      "learning_rate": 0.00012585705392239712,
      "loss": 0.5478,
      "step": 660450
    },
    {
      "epoch": 6.992361886714552,
      "grad_norm": 1.2606405019760132,
      "learning_rate": 0.00012581696133991143,
      "loss": 0.5284,
      "step": 660500
    },
    {
      "epoch": 6.992361886714552,
      "eval_loss": 0.3370366096496582,
      "eval_runtime": 48.0191,
      "eval_samples_per_second": 3497.147,
      "eval_steps_per_second": 437.159,
      "step": 660500
    },
    {
      "epoch": 6.992891208494556,
      "grad_norm": 1.3056144714355469,
      "learning_rate": 0.000125776872996989,
      "loss": 0.5388,
      "step": 660550
    },
    {
      "epoch": 6.993420530274559,
      "grad_norm": 1.2843085527420044,
      "learning_rate": 0.0001257367888949987,
      "loss": 0.5417,
      "step": 660600
    },
    {
      "epoch": 6.993949852054563,
      "grad_norm": 1.3085423707962036,
      "learning_rate": 0.00012569670903530872,
      "loss": 0.5389,
      "step": 660650
    },
    {
      "epoch": 6.9944791738345655,
      "grad_norm": 1.3484503030776978,
      "learning_rate": 0.00012565663341928765,
      "loss": 0.5443,
      "step": 660700
    },
    {
      "epoch": 6.995008495614569,
      "grad_norm": 1.3323756456375122,
      "learning_rate": 0.0001256165620483034,
      "loss": 0.5509,
      "step": 660750
    },
    {
      "epoch": 6.995537817394572,
      "grad_norm": 1.1966350078582764,
      "learning_rate": 0.0001255764949237242,
      "loss": 0.5375,
      "step": 660800
    },
    {
      "epoch": 6.996067139174576,
      "grad_norm": 1.368749976158142,
      "learning_rate": 0.00012553643204691773,
      "loss": 0.539,
      "step": 660850
    },
    {
      "epoch": 6.996596460954579,
      "grad_norm": 1.252332329750061,
      "learning_rate": 0.0001254963734192519,
      "loss": 0.5452,
      "step": 660900
    },
    {
      "epoch": 6.9971257827345825,
      "grad_norm": 1.3104101419448853,
      "learning_rate": 0.00012545631904209415,
      "loss": 0.5388,
      "step": 660950
    },
    {
      "epoch": 6.997655104514585,
      "grad_norm": 1.2150453329086304,
      "learning_rate": 0.0001254162689168121,
      "loss": 0.5387,
      "step": 661000
    },
    {
      "epoch": 6.997655104514585,
      "eval_loss": 0.336525559425354,
      "eval_runtime": 47.9791,
      "eval_samples_per_second": 3500.063,
      "eval_steps_per_second": 437.524,
      "step": 661000
    },
    {
      "epoch": 6.998184426294589,
      "grad_norm": 1.22901451587677,
      "learning_rate": 0.0001253762230447728,
      "loss": 0.535,
      "step": 661050
    },
    {
      "epoch": 6.998713748074592,
      "grad_norm": 1.249396562576294,
      "learning_rate": 0.00012533618142734367,
      "loss": 0.5344,
      "step": 661100
    },
    {
      "epoch": 6.999243069854595,
      "grad_norm": 1.3758575916290283,
      "learning_rate": 0.00012529614406589151,
      "loss": 0.5358,
      "step": 661150
    },
    {
      "epoch": 6.999772391634599,
      "grad_norm": 1.3694957494735718,
      "learning_rate": 0.00012525691158213461,
      "loss": 0.5403,
      "step": 661200
    },
    {
      "epoch": 7.000296420196801,
      "grad_norm": 1.192082405090332,
      "learning_rate": 0.00012521688265154947,
      "loss": 0.5307,
      "step": 661250
    },
    {
      "epoch": 7.000825741976805,
      "grad_norm": 1.355916976928711,
      "learning_rate": 0.00012517685798101407,
      "loss": 0.5347,
      "step": 661300
    },
    {
      "epoch": 7.001355063756808,
      "grad_norm": 1.2843087911605835,
      "learning_rate": 0.00012513683757189504,
      "loss": 0.5312,
      "step": 661350
    },
    {
      "epoch": 7.001884385536812,
      "grad_norm": 1.2933429479599,
      "learning_rate": 0.0001250968214255585,
      "loss": 0.5369,
      "step": 661400
    },
    {
      "epoch": 7.002413707316815,
      "grad_norm": 1.1664197444915771,
      "learning_rate": 0.00012505680954337078,
      "loss": 0.5381,
      "step": 661450
    },
    {
      "epoch": 7.002943029096818,
      "grad_norm": 1.2087187767028809,
      "learning_rate": 0.00012501680192669766,
      "loss": 0.5327,
      "step": 661500
    },
    {
      "epoch": 7.002943029096818,
      "eval_loss": 0.335869699716568,
      "eval_runtime": 48.0928,
      "eval_samples_per_second": 3491.794,
      "eval_steps_per_second": 436.49,
      "step": 661500
    },
    {
      "epoch": 7.003472350876821,
      "grad_norm": 1.2833259105682373,
      "learning_rate": 0.00012497679857690518,
      "loss": 0.5405,
      "step": 661550
    },
    {
      "epoch": 7.004001672656825,
      "grad_norm": 1.1428258419036865,
      "learning_rate": 0.00012493679949535888,
      "loss": 0.5453,
      "step": 661600
    },
    {
      "epoch": 7.004530994436828,
      "grad_norm": 1.2258672714233398,
      "learning_rate": 0.00012489680468342443,
      "loss": 0.5301,
      "step": 661650
    },
    {
      "epoch": 7.005060316216832,
      "grad_norm": 1.329775094985962,
      "learning_rate": 0.0001248568141424671,
      "loss": 0.5401,
      "step": 661700
    },
    {
      "epoch": 7.0055896379968345,
      "grad_norm": 1.2996419668197632,
      "learning_rate": 0.00012481682787385238,
      "loss": 0.5258,
      "step": 661750
    },
    {
      "epoch": 7.006118959776838,
      "grad_norm": 1.1663471460342407,
      "learning_rate": 0.00012477684587894512,
      "loss": 0.5269,
      "step": 661800
    },
    {
      "epoch": 7.006648281556841,
      "grad_norm": 1.2324721813201904,
      "learning_rate": 0.00012473686815911048,
      "loss": 0.5251,
      "step": 661850
    },
    {
      "epoch": 7.007177603336845,
      "grad_norm": 1.1958647966384888,
      "learning_rate": 0.00012469689471571315,
      "loss": 0.5319,
      "step": 661900
    },
    {
      "epoch": 7.007706925116848,
      "grad_norm": 1.3850111961364746,
      "learning_rate": 0.000124656925550118,
      "loss": 0.5369,
      "step": 661950
    },
    {
      "epoch": 7.008236246896851,
      "grad_norm": 1.1671435832977295,
      "learning_rate": 0.00012461696066368933,
      "loss": 0.5422,
      "step": 662000
    },
    {
      "epoch": 7.008236246896851,
      "eval_loss": 0.33641043305397034,
      "eval_runtime": 48.06,
      "eval_samples_per_second": 3494.173,
      "eval_steps_per_second": 436.787,
      "step": 662000
    },
    {
      "epoch": 7.008765568676854,
      "grad_norm": 1.249233365058899,
      "learning_rate": 0.00012457700005779162,
      "loss": 0.5419,
      "step": 662050
    },
    {
      "epoch": 7.009294890456857,
      "grad_norm": 1.3536852598190308,
      "learning_rate": 0.00012453704373378927,
      "loss": 0.5319,
      "step": 662100
    },
    {
      "epoch": 7.009824212236861,
      "grad_norm": 1.2245512008666992,
      "learning_rate": 0.0001244970916930461,
      "loss": 0.5343,
      "step": 662150
    },
    {
      "epoch": 7.010353534016864,
      "grad_norm": 1.3291780948638916,
      "learning_rate": 0.00012445714393692623,
      "loss": 0.5329,
      "step": 662200
    },
    {
      "epoch": 7.010882855796868,
      "grad_norm": 1.20875084400177,
      "learning_rate": 0.00012441720046679349,
      "loss": 0.5256,
      "step": 662250
    },
    {
      "epoch": 7.0114121775768705,
      "grad_norm": 1.3575539588928223,
      "learning_rate": 0.0001243772612840114,
      "loss": 0.5338,
      "step": 662300
    },
    {
      "epoch": 7.011941499356874,
      "grad_norm": 1.2373920679092407,
      "learning_rate": 0.0001243373263899435,
      "loss": 0.5487,
      "step": 662350
    },
    {
      "epoch": 7.012470821136877,
      "grad_norm": 1.4026533365249634,
      "learning_rate": 0.00012429739578595332,
      "loss": 0.5291,
      "step": 662400
    },
    {
      "epoch": 7.013000142916881,
      "grad_norm": 1.1523447036743164,
      "learning_rate": 0.00012425746947340382,
      "loss": 0.5274,
      "step": 662450
    },
    {
      "epoch": 7.013529464696884,
      "grad_norm": 1.2077035903930664,
      "learning_rate": 0.00012421754745365831,
      "loss": 0.5327,
      "step": 662500
    },
    {
      "epoch": 7.013529464696884,
      "eval_loss": 0.336931049823761,
      "eval_runtime": 48.0817,
      "eval_samples_per_second": 3492.597,
      "eval_steps_per_second": 436.59,
      "step": 662500
    },
    {
      "epoch": 7.0140587864768875,
      "grad_norm": 1.3005964756011963,
      "learning_rate": 0.00012417762972807952,
      "loss": 0.5402,
      "step": 662550
    },
    {
      "epoch": 7.01458810825689,
      "grad_norm": 1.0302973985671997,
      "learning_rate": 0.00012413771629803038,
      "loss": 0.5317,
      "step": 662600
    },
    {
      "epoch": 7.015117430036894,
      "grad_norm": 1.2396891117095947,
      "learning_rate": 0.00012409780716487337,
      "loss": 0.5417,
      "step": 662650
    },
    {
      "epoch": 7.015646751816897,
      "grad_norm": 1.3367576599121094,
      "learning_rate": 0.00012405790232997114,
      "loss": 0.5478,
      "step": 662700
    },
    {
      "epoch": 7.0161760735969,
      "grad_norm": 1.4365296363830566,
      "learning_rate": 0.00012401800179468584,
      "loss": 0.5359,
      "step": 662750
    },
    {
      "epoch": 7.016705395376904,
      "grad_norm": 1.2432490587234497,
      "learning_rate": 0.00012397810556037987,
      "loss": 0.5454,
      "step": 662800
    },
    {
      "epoch": 7.0172347171569065,
      "grad_norm": 1.279587745666504,
      "learning_rate": 0.000123938213628415,
      "loss": 0.5431,
      "step": 662850
    },
    {
      "epoch": 7.01776403893691,
      "grad_norm": 1.2576563358306885,
      "learning_rate": 0.00012389832600015344,
      "loss": 0.5306,
      "step": 662900
    },
    {
      "epoch": 7.018293360716913,
      "grad_norm": 1.2134227752685547,
      "learning_rate": 0.00012385844267695666,
      "loss": 0.5297,
      "step": 662950
    },
    {
      "epoch": 7.018822682496917,
      "grad_norm": 1.4182344675064087,
      "learning_rate": 0.00012381856366018652,
      "loss": 0.5318,
      "step": 663000
    },
    {
      "epoch": 7.018822682496917,
      "eval_loss": 0.3350031077861786,
      "eval_runtime": 48.2498,
      "eval_samples_per_second": 3480.429,
      "eval_steps_per_second": 435.069,
      "step": 663000
    },
    {
      "epoch": 7.01935200427692,
      "grad_norm": 1.2275896072387695,
      "learning_rate": 0.0001237786889512042,
      "loss": 0.5278,
      "step": 663050
    },
    {
      "epoch": 7.0198813260569235,
      "grad_norm": 1.2798130512237549,
      "learning_rate": 0.0001237388185513713,
      "loss": 0.5382,
      "step": 663100
    },
    {
      "epoch": 7.020410647836926,
      "grad_norm": 1.303055763244629,
      "learning_rate": 0.00012369895246204868,
      "loss": 0.5381,
      "step": 663150
    },
    {
      "epoch": 7.02093996961693,
      "grad_norm": 1.1892355680465698,
      "learning_rate": 0.0001236590906845976,
      "loss": 0.5336,
      "step": 663200
    },
    {
      "epoch": 7.021469291396933,
      "grad_norm": 1.3548600673675537,
      "learning_rate": 0.00012361923322037877,
      "loss": 0.5417,
      "step": 663250
    },
    {
      "epoch": 7.021998613176937,
      "grad_norm": 1.239024043083191,
      "learning_rate": 0.00012357938007075304,
      "loss": 0.5335,
      "step": 663300
    },
    {
      "epoch": 7.02252793495694,
      "grad_norm": 1.1384402513504028,
      "learning_rate": 0.0001235395312370808,
      "loss": 0.5313,
      "step": 663350
    },
    {
      "epoch": 7.023057256736943,
      "grad_norm": 1.2802519798278809,
      "learning_rate": 0.00012349968672072274,
      "loss": 0.5419,
      "step": 663400
    },
    {
      "epoch": 7.023586578516946,
      "grad_norm": 1.1691052913665771,
      "learning_rate": 0.0001234598465230388,
      "loss": 0.5317,
      "step": 663450
    },
    {
      "epoch": 7.024115900296949,
      "grad_norm": 1.3255999088287354,
      "learning_rate": 0.00012342001064538947,
      "loss": 0.5252,
      "step": 663500
    },
    {
      "epoch": 7.024115900296949,
      "eval_loss": 0.33604180812835693,
      "eval_runtime": 48.2475,
      "eval_samples_per_second": 3480.595,
      "eval_steps_per_second": 435.09,
      "step": 663500
    },
    {
      "epoch": 7.024645222076953,
      "grad_norm": 1.2557063102722168,
      "learning_rate": 0.00012338017908913442,
      "loss": 0.5266,
      "step": 663550
    },
    {
      "epoch": 7.025174543856956,
      "grad_norm": 1.20671808719635,
      "learning_rate": 0.0001233403518556337,
      "loss": 0.5483,
      "step": 663600
    },
    {
      "epoch": 7.0257038656369595,
      "grad_norm": 1.1995607614517212,
      "learning_rate": 0.00012330052894624687,
      "loss": 0.5359,
      "step": 663650
    },
    {
      "epoch": 7.026233187416962,
      "grad_norm": 1.0527234077453613,
      "learning_rate": 0.00012326071036233358,
      "loss": 0.536,
      "step": 663700
    },
    {
      "epoch": 7.026762509196966,
      "grad_norm": 1.1593506336212158,
      "learning_rate": 0.00012322089610525307,
      "loss": 0.5353,
      "step": 663750
    },
    {
      "epoch": 7.027291830976969,
      "grad_norm": 1.3991529941558838,
      "learning_rate": 0.00012318108617636475,
      "loss": 0.5339,
      "step": 663800
    },
    {
      "epoch": 7.027821152756973,
      "grad_norm": 1.2775523662567139,
      "learning_rate": 0.00012314128057702755,
      "loss": 0.5278,
      "step": 663850
    },
    {
      "epoch": 7.028350474536976,
      "grad_norm": 1.3293778896331787,
      "learning_rate": 0.0001231014793086005,
      "loss": 0.5433,
      "step": 663900
    },
    {
      "epoch": 7.028879796316979,
      "grad_norm": 1.3113750219345093,
      "learning_rate": 0.00012306168237244256,
      "loss": 0.5377,
      "step": 663950
    },
    {
      "epoch": 7.029409118096982,
      "grad_norm": 1.3268027305603027,
      "learning_rate": 0.0001230218897699121,
      "loss": 0.5371,
      "step": 664000
    },
    {
      "epoch": 7.029409118096982,
      "eval_loss": 0.3360667824745178,
      "eval_runtime": 46.9936,
      "eval_samples_per_second": 3573.467,
      "eval_steps_per_second": 446.699,
      "step": 664000
    },
    {
      "epoch": 7.029938439876986,
      "grad_norm": 1.2423195838928223,
      "learning_rate": 0.00012298210150236773,
      "loss": 0.5311,
      "step": 664050
    },
    {
      "epoch": 7.030467761656989,
      "grad_norm": 1.380421757698059,
      "learning_rate": 0.00012294231757116795,
      "loss": 0.5292,
      "step": 664100
    },
    {
      "epoch": 7.030997083436993,
      "grad_norm": 1.3035610914230347,
      "learning_rate": 0.00012290253797767075,
      "loss": 0.5398,
      "step": 664150
    },
    {
      "epoch": 7.0315264052169955,
      "grad_norm": 1.2877272367477417,
      "learning_rate": 0.00012286276272323437,
      "loss": 0.529,
      "step": 664200
    },
    {
      "epoch": 7.032055726996998,
      "grad_norm": 1.2765542268753052,
      "learning_rate": 0.00012282299180921657,
      "loss": 0.5404,
      "step": 664250
    },
    {
      "epoch": 7.032585048777002,
      "grad_norm": 1.0892759561538696,
      "learning_rate": 0.0001227832252369753,
      "loss": 0.5357,
      "step": 664300
    },
    {
      "epoch": 7.033114370557005,
      "grad_norm": 1.3153202533721924,
      "learning_rate": 0.00012274346300786797,
      "loss": 0.541,
      "step": 664350
    },
    {
      "epoch": 7.033643692337009,
      "grad_norm": 1.2856484651565552,
      "learning_rate": 0.00012270370512325218,
      "loss": 0.5361,
      "step": 664400
    },
    {
      "epoch": 7.034173014117012,
      "grad_norm": 1.2112468481063843,
      "learning_rate": 0.0001226639515844852,
      "loss": 0.5436,
      "step": 664450
    },
    {
      "epoch": 7.034702335897015,
      "grad_norm": 1.301130771636963,
      "learning_rate": 0.00012262420239292425,
      "loss": 0.5317,
      "step": 664500
    },
    {
      "epoch": 7.034702335897015,
      "eval_loss": 0.3360668122768402,
      "eval_runtime": 47.0342,
      "eval_samples_per_second": 3570.38,
      "eval_steps_per_second": 446.313,
      "step": 664500
    },
    {
      "epoch": 7.035231657677018,
      "grad_norm": 1.1957011222839355,
      "learning_rate": 0.00012258445754992621,
      "loss": 0.5261,
      "step": 664550
    },
    {
      "epoch": 7.035760979457022,
      "grad_norm": 1.3164968490600586,
      "learning_rate": 0.00012254471705684818,
      "loss": 0.526,
      "step": 664600
    },
    {
      "epoch": 7.036290301237025,
      "grad_norm": 1.2373281717300415,
      "learning_rate": 0.0001225049809150467,
      "loss": 0.5414,
      "step": 664650
    },
    {
      "epoch": 7.036819623017029,
      "grad_norm": 1.2259795665740967,
      "learning_rate": 0.00012246524912587847,
      "loss": 0.5187,
      "step": 664700
    },
    {
      "epoch": 7.037348944797031,
      "grad_norm": 1.2554893493652344,
      "learning_rate": 0.0001224255216906998,
      "loss": 0.5403,
      "step": 664750
    },
    {
      "epoch": 7.037878266577035,
      "grad_norm": 1.1132248640060425,
      "learning_rate": 0.0001223857986108671,
      "loss": 0.5381,
      "step": 664800
    },
    {
      "epoch": 7.038407588357038,
      "grad_norm": 1.2303309440612793,
      "learning_rate": 0.00012234607988773636,
      "loss": 0.5369,
      "step": 664850
    },
    {
      "epoch": 7.038936910137042,
      "grad_norm": 1.1629447937011719,
      "learning_rate": 0.00012230715976724736,
      "loss": 0.5322,
      "step": 664900
    },
    {
      "epoch": 7.039466231917045,
      "grad_norm": 1.2221559286117554,
      "learning_rate": 0.000122267449674387,
      "loss": 0.5297,
      "step": 664950
    },
    {
      "epoch": 7.0399955536970475,
      "grad_norm": 1.2562888860702515,
      "learning_rate": 0.000122227743942269,
      "loss": 0.5448,
      "step": 665000
    },
    {
      "epoch": 7.0399955536970475,
      "eval_loss": 0.33619025349617004,
      "eval_runtime": 48.2734,
      "eval_samples_per_second": 3478.728,
      "eval_steps_per_second": 434.857,
      "step": 665000
    },
    {
      "epoch": 7.040524875477051,
      "grad_norm": 1.2725495100021362,
      "learning_rate": 0.00012218804257224902,
      "loss": 0.5397,
      "step": 665050
    },
    {
      "epoch": 7.041054197257054,
      "grad_norm": 1.343725562095642,
      "learning_rate": 0.0001221483455656823,
      "loss": 0.5278,
      "step": 665100
    },
    {
      "epoch": 7.041583519037058,
      "grad_norm": 1.300797939300537,
      "learning_rate": 0.0001221086529239243,
      "loss": 0.5312,
      "step": 665150
    },
    {
      "epoch": 7.042112840817061,
      "grad_norm": 1.3807109594345093,
      "learning_rate": 0.00012206896464832987,
      "loss": 0.5373,
      "step": 665200
    },
    {
      "epoch": 7.0426421625970645,
      "grad_norm": 1.3326431512832642,
      "learning_rate": 0.00012202928074025416,
      "loss": 0.5336,
      "step": 665250
    },
    {
      "epoch": 7.043171484377067,
      "grad_norm": 1.190294623374939,
      "learning_rate": 0.00012198960120105179,
      "loss": 0.5249,
      "step": 665300
    },
    {
      "epoch": 7.043700806157071,
      "grad_norm": 1.3894522190093994,
      "learning_rate": 0.00012194992603207758,
      "loss": 0.5399,
      "step": 665350
    },
    {
      "epoch": 7.044230127937074,
      "grad_norm": 1.189619779586792,
      "learning_rate": 0.00012191025523468582,
      "loss": 0.5408,
      "step": 665400
    },
    {
      "epoch": 7.044759449717078,
      "grad_norm": 1.4031248092651367,
      "learning_rate": 0.0001218705888102311,
      "loss": 0.5368,
      "step": 665450
    },
    {
      "epoch": 7.045288771497081,
      "grad_norm": 1.3282719850540161,
      "learning_rate": 0.00012183092676006737,
      "loss": 0.531,
      "step": 665500
    },
    {
      "epoch": 7.045288771497081,
      "eval_loss": 0.33591601252555847,
      "eval_runtime": 47.6859,
      "eval_samples_per_second": 3521.586,
      "eval_steps_per_second": 440.214,
      "step": 665500
    },
    {
      "epoch": 7.045818093277084,
      "grad_norm": 1.2390327453613281,
      "learning_rate": 0.00012179126908554891,
      "loss": 0.5354,
      "step": 665550
    },
    {
      "epoch": 7.046347415057087,
      "grad_norm": 1.173334002494812,
      "learning_rate": 0.00012175161578802938,
      "loss": 0.5435,
      "step": 665600
    },
    {
      "epoch": 7.046876736837091,
      "grad_norm": 1.2294456958770752,
      "learning_rate": 0.00012171196686886276,
      "loss": 0.5353,
      "step": 665650
    },
    {
      "epoch": 7.047406058617094,
      "grad_norm": 1.2609915733337402,
      "learning_rate": 0.00012167232232940248,
      "loss": 0.538,
      "step": 665700
    },
    {
      "epoch": 7.047935380397097,
      "grad_norm": 1.25222909450531,
      "learning_rate": 0.00012163268217100209,
      "loss": 0.5356,
      "step": 665750
    },
    {
      "epoch": 7.0484647021771005,
      "grad_norm": 1.1988966464996338,
      "learning_rate": 0.00012159304639501481,
      "loss": 0.5445,
      "step": 665800
    },
    {
      "epoch": 7.048994023957103,
      "grad_norm": 1.221740961074829,
      "learning_rate": 0.00012155341500279391,
      "loss": 0.5393,
      "step": 665850
    },
    {
      "epoch": 7.049523345737107,
      "grad_norm": 1.2481650114059448,
      "learning_rate": 0.00012151378799569222,
      "loss": 0.54,
      "step": 665900
    },
    {
      "epoch": 7.05005266751711,
      "grad_norm": 1.27330482006073,
      "learning_rate": 0.00012147416537506267,
      "loss": 0.5322,
      "step": 665950
    },
    {
      "epoch": 7.050581989297114,
      "grad_norm": 1.2210564613342285,
      "learning_rate": 0.0001214345471422581,
      "loss": 0.5337,
      "step": 666000
    },
    {
      "epoch": 7.050581989297114,
      "eval_loss": 0.33533382415771484,
      "eval_runtime": 47.5196,
      "eval_samples_per_second": 3533.91,
      "eval_steps_per_second": 441.755,
      "step": 666000
    },
    {
      "epoch": 7.051111311077117,
      "grad_norm": 1.3000153303146362,
      "learning_rate": 0.00012139493329863083,
      "loss": 0.5433,
      "step": 666050
    },
    {
      "epoch": 7.05164063285712,
      "grad_norm": 1.2805521488189697,
      "learning_rate": 0.00012135532384553338,
      "loss": 0.5391,
      "step": 666100
    },
    {
      "epoch": 7.052169954637123,
      "grad_norm": 1.2183051109313965,
      "learning_rate": 0.00012131571878431808,
      "loss": 0.5374,
      "step": 666150
    },
    {
      "epoch": 7.052699276417127,
      "grad_norm": 1.3996670246124268,
      "learning_rate": 0.00012127611811633687,
      "loss": 0.5452,
      "step": 666200
    },
    {
      "epoch": 7.05322859819713,
      "grad_norm": 1.2624949216842651,
      "learning_rate": 0.00012123652184294187,
      "loss": 0.5486,
      "step": 666250
    },
    {
      "epoch": 7.053757919977134,
      "grad_norm": 1.3107082843780518,
      "learning_rate": 0.00012119692996548467,
      "loss": 0.5319,
      "step": 666300
    },
    {
      "epoch": 7.0542872417571365,
      "grad_norm": 1.1644114255905151,
      "learning_rate": 0.00012115734248531718,
      "loss": 0.5359,
      "step": 666350
    },
    {
      "epoch": 7.05481656353714,
      "grad_norm": 1.1038068532943726,
      "learning_rate": 0.00012111775940379064,
      "loss": 0.5309,
      "step": 666400
    },
    {
      "epoch": 7.055345885317143,
      "grad_norm": 1.2920465469360352,
      "learning_rate": 0.00012107818072225663,
      "loss": 0.5435,
      "step": 666450
    },
    {
      "epoch": 7.055875207097146,
      "grad_norm": 1.218875527381897,
      "learning_rate": 0.00012103860644206616,
      "loss": 0.5159,
      "step": 666500
    },
    {
      "epoch": 7.055875207097146,
      "eval_loss": 0.3336750268936157,
      "eval_runtime": 46.9195,
      "eval_samples_per_second": 3579.108,
      "eval_steps_per_second": 447.404,
      "step": 666500
    },
    {
      "epoch": 7.05640452887715,
      "grad_norm": 1.2085574865341187,
      "learning_rate": 0.00012099903656457045,
      "loss": 0.5337,
      "step": 666550
    },
    {
      "epoch": 7.056933850657153,
      "grad_norm": 1.2540632486343384,
      "learning_rate": 0.00012095947109112023,
      "loss": 0.5284,
      "step": 666600
    },
    {
      "epoch": 7.057463172437156,
      "grad_norm": 1.1404889822006226,
      "learning_rate": 0.00012091991002306646,
      "loss": 0.532,
      "step": 666650
    },
    {
      "epoch": 7.057992494217159,
      "grad_norm": 1.1869910955429077,
      "learning_rate": 0.00012088035336175951,
      "loss": 0.534,
      "step": 666700
    },
    {
      "epoch": 7.058521815997163,
      "grad_norm": 1.3535503149032593,
      "learning_rate": 0.00012084080110855006,
      "loss": 0.5321,
      "step": 666750
    },
    {
      "epoch": 7.059051137777166,
      "grad_norm": 1.313746452331543,
      "learning_rate": 0.00012080125326478817,
      "loss": 0.5325,
      "step": 666800
    },
    {
      "epoch": 7.05958045955717,
      "grad_norm": 1.3455615043640137,
      "learning_rate": 0.00012076170983182422,
      "loss": 0.5406,
      "step": 666850
    },
    {
      "epoch": 7.0601097813371725,
      "grad_norm": 1.25037682056427,
      "learning_rate": 0.000120722170811008,
      "loss": 0.5449,
      "step": 666900
    },
    {
      "epoch": 7.060639103117176,
      "grad_norm": 1.2940114736557007,
      "learning_rate": 0.00012068263620368955,
      "loss": 0.5332,
      "step": 666950
    },
    {
      "epoch": 7.061168424897179,
      "grad_norm": 1.2368680238723755,
      "learning_rate": 0.00012064310601121839,
      "loss": 0.5364,
      "step": 667000
    },
    {
      "epoch": 7.061168424897179,
      "eval_loss": 0.33459484577178955,
      "eval_runtime": 46.9381,
      "eval_samples_per_second": 3577.688,
      "eval_steps_per_second": 447.227,
      "step": 667000
    },
    {
      "epoch": 7.061697746677183,
      "grad_norm": 1.2877858877182007,
      "learning_rate": 0.00012060358023494425,
      "loss": 0.5369,
      "step": 667050
    },
    {
      "epoch": 7.062227068457186,
      "grad_norm": 1.2734754085540771,
      "learning_rate": 0.0001205640588762163,
      "loss": 0.5338,
      "step": 667100
    },
    {
      "epoch": 7.0627563902371895,
      "grad_norm": 1.274879813194275,
      "learning_rate": 0.00012052454193638405,
      "loss": 0.5326,
      "step": 667150
    },
    {
      "epoch": 7.063285712017192,
      "grad_norm": 1.3037621974945068,
      "learning_rate": 0.00012048502941679632,
      "loss": 0.5383,
      "step": 667200
    },
    {
      "epoch": 7.063815033797195,
      "grad_norm": 1.3300893306732178,
      "learning_rate": 0.0001204455213188023,
      "loss": 0.5319,
      "step": 667250
    },
    {
      "epoch": 7.064344355577199,
      "grad_norm": 1.2114473581314087,
      "learning_rate": 0.00012040601764375055,
      "loss": 0.533,
      "step": 667300
    },
    {
      "epoch": 7.064873677357202,
      "grad_norm": 1.3570243120193481,
      "learning_rate": 0.00012036651839298996,
      "loss": 0.5353,
      "step": 667350
    },
    {
      "epoch": 7.065402999137206,
      "grad_norm": 1.2973735332489014,
      "learning_rate": 0.00012032702356786878,
      "loss": 0.534,
      "step": 667400
    },
    {
      "epoch": 7.0659323209172085,
      "grad_norm": 1.2030695676803589,
      "learning_rate": 0.00012028753316973556,
      "loss": 0.5342,
      "step": 667450
    },
    {
      "epoch": 7.066461642697212,
      "grad_norm": 1.2881876230239868,
      "learning_rate": 0.00012024804719993828,
      "loss": 0.5409,
      "step": 667500
    },
    {
      "epoch": 7.066461642697212,
      "eval_loss": 0.33482760190963745,
      "eval_runtime": 47.2248,
      "eval_samples_per_second": 3555.973,
      "eval_steps_per_second": 444.513,
      "step": 667500
    },
    {
      "epoch": 7.066990964477215,
      "grad_norm": 1.1615573167800903,
      "learning_rate": 0.0001202085656598251,
      "loss": 0.5426,
      "step": 667550
    },
    {
      "epoch": 7.067520286257219,
      "grad_norm": 1.2785320281982422,
      "learning_rate": 0.00012016908855074399,
      "loss": 0.5325,
      "step": 667600
    },
    {
      "epoch": 7.068049608037222,
      "grad_norm": 1.2726833820343018,
      "learning_rate": 0.00012012961587404245,
      "loss": 0.5271,
      "step": 667650
    },
    {
      "epoch": 7.0685789298172255,
      "grad_norm": 1.3568730354309082,
      "learning_rate": 0.00012009014763106832,
      "loss": 0.544,
      "step": 667700
    },
    {
      "epoch": 7.069108251597228,
      "grad_norm": 1.1614867448806763,
      "learning_rate": 0.0001200506838231688,
      "loss": 0.5333,
      "step": 667750
    },
    {
      "epoch": 7.069637573377232,
      "grad_norm": 1.2394176721572876,
      "learning_rate": 0.0001200112244516913,
      "loss": 0.5206,
      "step": 667800
    },
    {
      "epoch": 7.070166895157235,
      "grad_norm": 1.2647621631622314,
      "learning_rate": 0.00011997176951798299,
      "loss": 0.5328,
      "step": 667850
    },
    {
      "epoch": 7.070696216937239,
      "grad_norm": 1.2203694581985474,
      "learning_rate": 0.00011993231902339069,
      "loss": 0.5321,
      "step": 667900
    },
    {
      "epoch": 7.071225538717242,
      "grad_norm": 1.2540560960769653,
      "learning_rate": 0.00011989287296926144,
      "loss": 0.5371,
      "step": 667950
    },
    {
      "epoch": 7.071754860497244,
      "grad_norm": 1.2173441648483276,
      "learning_rate": 0.00011985343135694168,
      "loss": 0.5261,
      "step": 668000
    },
    {
      "epoch": 7.071754860497244,
      "eval_loss": 0.33526289463043213,
      "eval_runtime": 47.394,
      "eval_samples_per_second": 3543.277,
      "eval_steps_per_second": 442.925,
      "step": 668000
    },
    {
      "epoch": 7.072284182277248,
      "grad_norm": 1.199353575706482,
      "learning_rate": 0.00011981399418777814,
      "loss": 0.5298,
      "step": 668050
    },
    {
      "epoch": 7.072813504057251,
      "grad_norm": 1.2502743005752563,
      "learning_rate": 0.00011977456146311699,
      "loss": 0.5306,
      "step": 668100
    },
    {
      "epoch": 7.073342825837255,
      "grad_norm": 1.3108466863632202,
      "learning_rate": 0.00011973513318430465,
      "loss": 0.5372,
      "step": 668150
    },
    {
      "epoch": 7.073872147617258,
      "grad_norm": 1.3244298696517944,
      "learning_rate": 0.00011969570935268701,
      "loss": 0.5432,
      "step": 668200
    },
    {
      "epoch": 7.074401469397261,
      "grad_norm": 1.2703540325164795,
      "learning_rate": 0.00011965628996961014,
      "loss": 0.5468,
      "step": 668250
    },
    {
      "epoch": 7.074930791177264,
      "grad_norm": 1.1325109004974365,
      "learning_rate": 0.00011961687503641963,
      "loss": 0.5314,
      "step": 668300
    },
    {
      "epoch": 7.075460112957268,
      "grad_norm": 1.333045244216919,
      "learning_rate": 0.0001195774645544613,
      "loss": 0.5423,
      "step": 668350
    },
    {
      "epoch": 7.075989434737271,
      "grad_norm": 1.2179436683654785,
      "learning_rate": 0.0001195380585250804,
      "loss": 0.5271,
      "step": 668400
    },
    {
      "epoch": 7.076518756517275,
      "grad_norm": 1.3275741338729858,
      "learning_rate": 0.00011949865694962244,
      "loss": 0.5343,
      "step": 668450
    },
    {
      "epoch": 7.0770480782972776,
      "grad_norm": 1.2199167013168335,
      "learning_rate": 0.00011945925982943237,
      "loss": 0.5337,
      "step": 668500
    },
    {
      "epoch": 7.0770480782972776,
      "eval_loss": 0.3343229293823242,
      "eval_runtime": 47.1887,
      "eval_samples_per_second": 3558.689,
      "eval_steps_per_second": 444.852,
      "step": 668500
    },
    {
      "epoch": 7.077577400077281,
      "grad_norm": 1.1591547727584839,
      "learning_rate": 0.0001194198671658554,
      "loss": 0.5403,
      "step": 668550
    },
    {
      "epoch": 7.078106721857284,
      "grad_norm": 1.187052845954895,
      "learning_rate": 0.00011938047896023615,
      "loss": 0.5378,
      "step": 668600
    },
    {
      "epoch": 7.078636043637288,
      "grad_norm": 1.2605658769607544,
      "learning_rate": 0.00011934188284513598,
      "loss": 0.5388,
      "step": 668650
    },
    {
      "epoch": 7.079165365417291,
      "grad_norm": 1.1931414604187012,
      "learning_rate": 0.00011930250347024036,
      "loss": 0.5339,
      "step": 668700
    },
    {
      "epoch": 7.0796946871972946,
      "grad_norm": 1.2998121976852417,
      "learning_rate": 0.00011926312855730925,
      "loss": 0.5441,
      "step": 668750
    },
    {
      "epoch": 7.080224008977297,
      "grad_norm": 1.252713680267334,
      "learning_rate": 0.00011922375810768707,
      "loss": 0.5334,
      "step": 668800
    },
    {
      "epoch": 7.0807533307573,
      "grad_norm": 1.2740287780761719,
      "learning_rate": 0.00011918439212271775,
      "loss": 0.5316,
      "step": 668850
    },
    {
      "epoch": 7.081282652537304,
      "grad_norm": 1.234228491783142,
      "learning_rate": 0.00011914503060374541,
      "loss": 0.5329,
      "step": 668900
    },
    {
      "epoch": 7.081811974317307,
      "grad_norm": 1.3222424983978271,
      "learning_rate": 0.0001191056735521136,
      "loss": 0.526,
      "step": 668950
    },
    {
      "epoch": 7.082341296097311,
      "grad_norm": 1.2356544733047485,
      "learning_rate": 0.00011906632096916623,
      "loss": 0.5354,
      "step": 669000
    },
    {
      "epoch": 7.082341296097311,
      "eval_loss": 0.33402392268180847,
      "eval_runtime": 47.0775,
      "eval_samples_per_second": 3567.094,
      "eval_steps_per_second": 445.903,
      "step": 669000
    },
    {
      "epoch": 7.0828706178773135,
      "grad_norm": 1.2043609619140625,
      "learning_rate": 0.0001190269728562465,
      "loss": 0.5353,
      "step": 669050
    },
    {
      "epoch": 7.083399939657317,
      "grad_norm": 1.4088706970214844,
      "learning_rate": 0.00011898762921469802,
      "loss": 0.5359,
      "step": 669100
    },
    {
      "epoch": 7.08392926143732,
      "grad_norm": 1.2083982229232788,
      "learning_rate": 0.00011894829004586371,
      "loss": 0.5239,
      "step": 669150
    },
    {
      "epoch": 7.084458583217324,
      "grad_norm": 1.2554291486740112,
      "learning_rate": 0.00011890895535108684,
      "loss": 0.534,
      "step": 669200
    },
    {
      "epoch": 7.084987904997327,
      "grad_norm": 1.2308626174926758,
      "learning_rate": 0.00011886962513171004,
      "loss": 0.5332,
      "step": 669250
    },
    {
      "epoch": 7.0855172267773305,
      "grad_norm": 1.3263150453567505,
      "learning_rate": 0.00011883029938907625,
      "loss": 0.528,
      "step": 669300
    },
    {
      "epoch": 7.086046548557333,
      "grad_norm": 1.3923568725585938,
      "learning_rate": 0.00011879097812452786,
      "loss": 0.5322,
      "step": 669350
    },
    {
      "epoch": 7.086575870337337,
      "grad_norm": 1.366109013557434,
      "learning_rate": 0.0001187516613394074,
      "loss": 0.5333,
      "step": 669400
    },
    {
      "epoch": 7.08710519211734,
      "grad_norm": 1.27377188205719,
      "learning_rate": 0.00011871234903505704,
      "loss": 0.5387,
      "step": 669450
    },
    {
      "epoch": 7.087634513897344,
      "grad_norm": 1.3655532598495483,
      "learning_rate": 0.00011867304121281903,
      "loss": 0.5359,
      "step": 669500
    },
    {
      "epoch": 7.087634513897344,
      "eval_loss": 0.33463865518569946,
      "eval_runtime": 47.0934,
      "eval_samples_per_second": 3565.895,
      "eval_steps_per_second": 445.753,
      "step": 669500
    },
    {
      "epoch": 7.088163835677347,
      "grad_norm": 1.3066236972808838,
      "learning_rate": 0.00011863373787403508,
      "loss": 0.5339,
      "step": 669550
    },
    {
      "epoch": 7.0886931574573495,
      "grad_norm": 1.271397590637207,
      "learning_rate": 0.00011859443902004721,
      "loss": 0.5335,
      "step": 669600
    },
    {
      "epoch": 7.089222479237353,
      "grad_norm": 1.3945417404174805,
      "learning_rate": 0.00011855514465219705,
      "loss": 0.5265,
      "step": 669650
    },
    {
      "epoch": 7.089751801017356,
      "grad_norm": 1.102256417274475,
      "learning_rate": 0.00011851585477182596,
      "loss": 0.5318,
      "step": 669700
    },
    {
      "epoch": 7.09028112279736,
      "grad_norm": 1.2529698610305786,
      "learning_rate": 0.00011847656938027548,
      "loss": 0.5324,
      "step": 669750
    },
    {
      "epoch": 7.090810444577363,
      "grad_norm": 1.0909510850906372,
      "learning_rate": 0.00011843728847888658,
      "loss": 0.534,
      "step": 669800
    },
    {
      "epoch": 7.0913397663573665,
      "grad_norm": 1.2033188343048096,
      "learning_rate": 0.00011839801206900042,
      "loss": 0.5357,
      "step": 669850
    },
    {
      "epoch": 7.091869088137369,
      "grad_norm": 1.384952187538147,
      "learning_rate": 0.00011835874015195793,
      "loss": 0.5277,
      "step": 669900
    },
    {
      "epoch": 7.092398409917373,
      "grad_norm": 1.3415255546569824,
      "learning_rate": 0.00011831947272909968,
      "loss": 0.5358,
      "step": 669950
    },
    {
      "epoch": 7.092927731697376,
      "grad_norm": 1.3046702146530151,
      "learning_rate": 0.00011828020980176635,
      "loss": 0.5314,
      "step": 670000
    },
    {
      "epoch": 7.092927731697376,
      "eval_loss": 0.33495259284973145,
      "eval_runtime": 47.0484,
      "eval_samples_per_second": 3569.302,
      "eval_steps_per_second": 446.179,
      "step": 670000
    },
    {
      "epoch": 7.09345705347738,
      "grad_norm": 1.3981505632400513,
      "learning_rate": 0.00011824095137129845,
      "loss": 0.5239,
      "step": 670050
    },
    {
      "epoch": 7.093986375257383,
      "grad_norm": 1.3566430807113647,
      "learning_rate": 0.00011820169743903605,
      "loss": 0.5338,
      "step": 670100
    },
    {
      "epoch": 7.094515697037386,
      "grad_norm": 1.329652190208435,
      "learning_rate": 0.00011816244800631945,
      "loss": 0.5343,
      "step": 670150
    },
    {
      "epoch": 7.095045018817389,
      "grad_norm": 1.253735065460205,
      "learning_rate": 0.00011812320307448845,
      "loss": 0.5309,
      "step": 670200
    },
    {
      "epoch": 7.095574340597393,
      "grad_norm": 1.3131426572799683,
      "learning_rate": 0.000118083962644883,
      "loss": 0.5426,
      "step": 670250
    },
    {
      "epoch": 7.096103662377396,
      "grad_norm": 1.3148316144943237,
      "learning_rate": 0.00011804472671884261,
      "loss": 0.5377,
      "step": 670300
    },
    {
      "epoch": 7.096632984157399,
      "grad_norm": 1.2891769409179688,
      "learning_rate": 0.00011800549529770696,
      "loss": 0.5421,
      "step": 670350
    },
    {
      "epoch": 7.0971623059374025,
      "grad_norm": 1.403493881225586,
      "learning_rate": 0.00011796626838281519,
      "loss": 0.5425,
      "step": 670400
    },
    {
      "epoch": 7.097691627717405,
      "grad_norm": 1.2171093225479126,
      "learning_rate": 0.00011792704597550668,
      "loss": 0.5442,
      "step": 670450
    },
    {
      "epoch": 7.098220949497409,
      "grad_norm": 1.2967844009399414,
      "learning_rate": 0.00011788782807712028,
      "loss": 0.5413,
      "step": 670500
    },
    {
      "epoch": 7.098220949497409,
      "eval_loss": 0.33407625555992126,
      "eval_runtime": 46.9538,
      "eval_samples_per_second": 3576.495,
      "eval_steps_per_second": 447.078,
      "step": 670500
    },
    {
      "epoch": 7.098750271277412,
      "grad_norm": 1.235052466392517,
      "learning_rate": 0.0001178486146889951,
      "loss": 0.535,
      "step": 670550
    },
    {
      "epoch": 7.099279593057416,
      "grad_norm": 1.1792941093444824,
      "learning_rate": 0.00011780940581246966,
      "loss": 0.5405,
      "step": 670600
    },
    {
      "epoch": 7.099808914837419,
      "grad_norm": 1.2026124000549316,
      "learning_rate": 0.00011777020144888267,
      "loss": 0.5283,
      "step": 670650
    },
    {
      "epoch": 7.100338236617422,
      "grad_norm": 1.237738013267517,
      "learning_rate": 0.00011773100159957245,
      "loss": 0.5291,
      "step": 670700
    },
    {
      "epoch": 7.100867558397425,
      "grad_norm": 1.3377326726913452,
      "learning_rate": 0.00011769180626587745,
      "loss": 0.5467,
      "step": 670750
    },
    {
      "epoch": 7.101396880177429,
      "grad_norm": 1.3222843408584595,
      "learning_rate": 0.00011765261544913552,
      "loss": 0.5345,
      "step": 670800
    },
    {
      "epoch": 7.101926201957432,
      "grad_norm": 1.2567065954208374,
      "learning_rate": 0.00011761342915068488,
      "loss": 0.5417,
      "step": 670850
    },
    {
      "epoch": 7.102455523737436,
      "grad_norm": 1.3102997541427612,
      "learning_rate": 0.00011757424737186312,
      "loss": 0.5395,
      "step": 670900
    },
    {
      "epoch": 7.1029848455174385,
      "grad_norm": 1.3097171783447266,
      "learning_rate": 0.00011753507011400807,
      "loss": 0.5302,
      "step": 670950
    },
    {
      "epoch": 7.103514167297442,
      "grad_norm": 1.1675292253494263,
      "learning_rate": 0.00011749589737845706,
      "loss": 0.5322,
      "step": 671000
    },
    {
      "epoch": 7.103514167297442,
      "eval_loss": 0.3329777121543884,
      "eval_runtime": 46.9425,
      "eval_samples_per_second": 3577.358,
      "eval_steps_per_second": 447.186,
      "step": 671000
    },
    {
      "epoch": 7.104043489077445,
      "grad_norm": 1.3323516845703125,
      "learning_rate": 0.00011745672916654763,
      "loss": 0.5296,
      "step": 671050
    },
    {
      "epoch": 7.104572810857448,
      "grad_norm": 1.2494521141052246,
      "learning_rate": 0.00011741756547961674,
      "loss": 0.5336,
      "step": 671100
    },
    {
      "epoch": 7.105102132637452,
      "grad_norm": 1.262588381767273,
      "learning_rate": 0.00011737840631900162,
      "loss": 0.5287,
      "step": 671150
    },
    {
      "epoch": 7.105631454417455,
      "grad_norm": 1.1776161193847656,
      "learning_rate": 0.00011733925168603902,
      "loss": 0.5387,
      "step": 671200
    },
    {
      "epoch": 7.106160776197458,
      "grad_norm": 1.2272868156433105,
      "learning_rate": 0.00011730010158206578,
      "loss": 0.5273,
      "step": 671250
    },
    {
      "epoch": 7.106690097977461,
      "grad_norm": 1.2517004013061523,
      "learning_rate": 0.00011726095600841833,
      "loss": 0.5375,
      "step": 671300
    },
    {
      "epoch": 7.107219419757465,
      "grad_norm": 1.3990504741668701,
      "learning_rate": 0.00011722181496643325,
      "loss": 0.527,
      "step": 671350
    },
    {
      "epoch": 7.107748741537468,
      "grad_norm": 1.1680138111114502,
      "learning_rate": 0.00011718346114319434,
      "loss": 0.535,
      "step": 671400
    },
    {
      "epoch": 7.108278063317472,
      "grad_norm": 1.3208699226379395,
      "learning_rate": 0.00011714432907784256,
      "loss": 0.5391,
      "step": 671450
    },
    {
      "epoch": 7.1088073850974745,
      "grad_norm": 1.3715739250183105,
      "learning_rate": 0.00011710520154813479,
      "loss": 0.5385,
      "step": 671500
    },
    {
      "epoch": 7.1088073850974745,
      "eval_loss": 0.3330362141132355,
      "eval_runtime": 47.0266,
      "eval_samples_per_second": 3570.96,
      "eval_steps_per_second": 446.386,
      "step": 671500
    },
    {
      "epoch": 7.109336706877478,
      "grad_norm": 1.277213454246521,
      "learning_rate": 0.00011706607855540654,
      "loss": 0.5338,
      "step": 671550
    },
    {
      "epoch": 7.109866028657481,
      "grad_norm": 1.2282198667526245,
      "learning_rate": 0.00011702696010099376,
      "loss": 0.5338,
      "step": 671600
    },
    {
      "epoch": 7.110395350437485,
      "grad_norm": 1.289322853088379,
      "learning_rate": 0.0001169878461862317,
      "loss": 0.534,
      "step": 671650
    },
    {
      "epoch": 7.110924672217488,
      "grad_norm": 1.2469755411148071,
      "learning_rate": 0.00011694873681245588,
      "loss": 0.5305,
      "step": 671700
    },
    {
      "epoch": 7.1114539939974915,
      "grad_norm": 1.4260900020599365,
      "learning_rate": 0.00011690963198100129,
      "loss": 0.5422,
      "step": 671750
    },
    {
      "epoch": 7.111983315777494,
      "grad_norm": 1.3080737590789795,
      "learning_rate": 0.00011687053169320313,
      "loss": 0.5337,
      "step": 671800
    },
    {
      "epoch": 7.112512637557497,
      "grad_norm": 1.1904001235961914,
      "learning_rate": 0.00011683143595039614,
      "loss": 0.5317,
      "step": 671850
    },
    {
      "epoch": 7.113041959337501,
      "grad_norm": 1.2305828332901,
      "learning_rate": 0.00011679234475391506,
      "loss": 0.5376,
      "step": 671900
    },
    {
      "epoch": 7.113571281117504,
      "grad_norm": 1.3150538206100464,
      "learning_rate": 0.00011675325810509457,
      "loss": 0.5412,
      "step": 671950
    },
    {
      "epoch": 7.114100602897508,
      "grad_norm": 1.371466875076294,
      "learning_rate": 0.0001167141760052689,
      "loss": 0.5294,
      "step": 672000
    },
    {
      "epoch": 7.114100602897508,
      "eval_loss": 0.33267873525619507,
      "eval_runtime": 46.9963,
      "eval_samples_per_second": 3573.261,
      "eval_steps_per_second": 446.674,
      "step": 672000
    },
    {
      "epoch": 7.11462992467751,
      "grad_norm": 1.3379433155059814,
      "learning_rate": 0.0001166750984557724,
      "loss": 0.5303,
      "step": 672050
    },
    {
      "epoch": 7.115159246457514,
      "grad_norm": 1.2086896896362305,
      "learning_rate": 0.0001166360254579392,
      "loss": 0.5335,
      "step": 672100
    },
    {
      "epoch": 7.115688568237517,
      "grad_norm": 1.2665194272994995,
      "learning_rate": 0.0001165969570131031,
      "loss": 0.5427,
      "step": 672150
    },
    {
      "epoch": 7.116217890017521,
      "grad_norm": 1.219344139099121,
      "learning_rate": 0.00011655789312259807,
      "loss": 0.5297,
      "step": 672200
    },
    {
      "epoch": 7.116747211797524,
      "grad_norm": 1.2544866800308228,
      "learning_rate": 0.00011651883378775752,
      "loss": 0.5397,
      "step": 672250
    },
    {
      "epoch": 7.117276533577527,
      "grad_norm": 1.3502508401870728,
      "learning_rate": 0.00011647977900991514,
      "loss": 0.5403,
      "step": 672300
    },
    {
      "epoch": 7.11780585535753,
      "grad_norm": 1.3656543493270874,
      "learning_rate": 0.00011644072879040402,
      "loss": 0.5246,
      "step": 672350
    },
    {
      "epoch": 7.118335177137534,
      "grad_norm": 1.2574387788772583,
      "learning_rate": 0.00011640168313055755,
      "loss": 0.5204,
      "step": 672400
    },
    {
      "epoch": 7.118864498917537,
      "grad_norm": 1.3464077711105347,
      "learning_rate": 0.00011636264203170854,
      "loss": 0.5301,
      "step": 672450
    },
    {
      "epoch": 7.119393820697541,
      "grad_norm": 1.2801553010940552,
      "learning_rate": 0.00011632360549519,
      "loss": 0.5251,
      "step": 672500
    },
    {
      "epoch": 7.119393820697541,
      "eval_loss": 0.332838773727417,
      "eval_runtime": 47.0579,
      "eval_samples_per_second": 3568.581,
      "eval_steps_per_second": 446.089,
      "step": 672500
    },
    {
      "epoch": 7.1199231424775435,
      "grad_norm": 1.395358920097351,
      "learning_rate": 0.00011628457352233443,
      "loss": 0.5426,
      "step": 672550
    },
    {
      "epoch": 7.120452464257546,
      "grad_norm": 1.1968811750411987,
      "learning_rate": 0.0001162455461144746,
      "loss": 0.526,
      "step": 672600
    },
    {
      "epoch": 7.12098178603755,
      "grad_norm": 1.1530052423477173,
      "learning_rate": 0.00011620652327294268,
      "loss": 0.5315,
      "step": 672650
    },
    {
      "epoch": 7.121511107817553,
      "grad_norm": 1.2732993364334106,
      "learning_rate": 0.00011616750499907109,
      "loss": 0.5375,
      "step": 672700
    },
    {
      "epoch": 7.122040429597557,
      "grad_norm": 1.2863459587097168,
      "learning_rate": 0.00011612849129419167,
      "loss": 0.5421,
      "step": 672750
    },
    {
      "epoch": 7.12256975137756,
      "grad_norm": 1.3927947282791138,
      "learning_rate": 0.00011608948215963658,
      "loss": 0.5324,
      "step": 672800
    },
    {
      "epoch": 7.123099073157563,
      "grad_norm": 1.2244375944137573,
      "learning_rate": 0.00011605047759673737,
      "loss": 0.5377,
      "step": 672850
    },
    {
      "epoch": 7.123628394937566,
      "grad_norm": 1.263298511505127,
      "learning_rate": 0.00011601147760682579,
      "loss": 0.5249,
      "step": 672900
    },
    {
      "epoch": 7.12415771671757,
      "grad_norm": 1.2053707838058472,
      "learning_rate": 0.00011597248219123316,
      "loss": 0.5272,
      "step": 672950
    },
    {
      "epoch": 7.124687038497573,
      "grad_norm": 1.0952521562576294,
      "learning_rate": 0.00011593349135129092,
      "loss": 0.542,
      "step": 673000
    },
    {
      "epoch": 7.124687038497573,
      "eval_loss": 0.33328625559806824,
      "eval_runtime": 47.1075,
      "eval_samples_per_second": 3564.827,
      "eval_steps_per_second": 445.619,
      "step": 673000
    },
    {
      "epoch": 7.125216360277577,
      "grad_norm": 1.1796159744262695,
      "learning_rate": 0.00011589450508833005,
      "loss": 0.5339,
      "step": 673050
    },
    {
      "epoch": 7.1257456820575795,
      "grad_norm": 1.1810792684555054,
      "learning_rate": 0.00011585552340368166,
      "loss": 0.5308,
      "step": 673100
    },
    {
      "epoch": 7.126275003837583,
      "grad_norm": 1.2633414268493652,
      "learning_rate": 0.00011581654629867641,
      "loss": 0.5315,
      "step": 673150
    },
    {
      "epoch": 7.126804325617586,
      "grad_norm": 1.3313649892807007,
      "learning_rate": 0.00011577757377464515,
      "loss": 0.524,
      "step": 673200
    },
    {
      "epoch": 7.12733364739759,
      "grad_norm": 1.2954113483428955,
      "learning_rate": 0.00011573860583291822,
      "loss": 0.5312,
      "step": 673250
    },
    {
      "epoch": 7.127862969177593,
      "grad_norm": 1.3060898780822754,
      "learning_rate": 0.00011569964247482614,
      "loss": 0.5256,
      "step": 673300
    },
    {
      "epoch": 7.128392290957596,
      "grad_norm": 1.3842453956604004,
      "learning_rate": 0.00011566068370169891,
      "loss": 0.5358,
      "step": 673350
    },
    {
      "epoch": 7.128921612737599,
      "grad_norm": 1.157995581626892,
      "learning_rate": 0.00011562172951486677,
      "loss": 0.5348,
      "step": 673400
    },
    {
      "epoch": 7.129450934517602,
      "grad_norm": 1.303804636001587,
      "learning_rate": 0.0001155827799156594,
      "loss": 0.5365,
      "step": 673450
    },
    {
      "epoch": 7.129980256297606,
      "grad_norm": 1.1749404668807983,
      "learning_rate": 0.00011554383490540663,
      "loss": 0.5282,
      "step": 673500
    },
    {
      "epoch": 7.129980256297606,
      "eval_loss": 0.3323891758918762,
      "eval_runtime": 47.1492,
      "eval_samples_per_second": 3561.674,
      "eval_steps_per_second": 445.225,
      "step": 673500
    },
    {
      "epoch": 7.130509578077609,
      "grad_norm": 1.2886607646942139,
      "learning_rate": 0.00011550489448543814,
      "loss": 0.5246,
      "step": 673550
    },
    {
      "epoch": 7.131038899857613,
      "grad_norm": 1.1702172756195068,
      "learning_rate": 0.00011546595865708313,
      "loss": 0.5265,
      "step": 673600
    },
    {
      "epoch": 7.1315682216376155,
      "grad_norm": 1.2534626722335815,
      "learning_rate": 0.00011542702742167102,
      "loss": 0.534,
      "step": 673650
    },
    {
      "epoch": 7.132097543417619,
      "grad_norm": 1.3393429517745972,
      "learning_rate": 0.00011538810078053074,
      "loss": 0.5346,
      "step": 673700
    },
    {
      "epoch": 7.132626865197622,
      "grad_norm": 1.322622537612915,
      "learning_rate": 0.00011534917873499138,
      "loss": 0.5305,
      "step": 673750
    },
    {
      "epoch": 7.133156186977626,
      "grad_norm": 1.3535358905792236,
      "learning_rate": 0.00011531026128638172,
      "loss": 0.543,
      "step": 673800
    },
    {
      "epoch": 7.133685508757629,
      "grad_norm": 1.2331955432891846,
      "learning_rate": 0.00011527134843603029,
      "loss": 0.5404,
      "step": 673850
    },
    {
      "epoch": 7.1342148305376325,
      "grad_norm": 1.2859951257705688,
      "learning_rate": 0.00011523244018526569,
      "loss": 0.5353,
      "step": 673900
    },
    {
      "epoch": 7.134744152317635,
      "grad_norm": 1.252384901046753,
      "learning_rate": 0.00011519353653541606,
      "loss": 0.542,
      "step": 673950
    },
    {
      "epoch": 7.135273474097639,
      "grad_norm": 1.2423077821731567,
      "learning_rate": 0.00011515463748780975,
      "loss": 0.5288,
      "step": 674000
    },
    {
      "epoch": 7.135273474097639,
      "eval_loss": 0.33167150616645813,
      "eval_runtime": 47.1299,
      "eval_samples_per_second": 3563.13,
      "eval_steps_per_second": 445.407,
      "step": 674000
    },
    {
      "epoch": 7.135802795877642,
      "grad_norm": 1.3556127548217773,
      "learning_rate": 0.00011511574304377457,
      "loss": 0.5366,
      "step": 674050
    },
    {
      "epoch": 7.136332117657645,
      "grad_norm": 1.1848520040512085,
      "learning_rate": 0.00011507685320463854,
      "loss": 0.5386,
      "step": 674100
    },
    {
      "epoch": 7.136861439437649,
      "grad_norm": 1.3238893747329712,
      "learning_rate": 0.0001150379679717292,
      "loss": 0.5237,
      "step": 674150
    },
    {
      "epoch": 7.1373907612176515,
      "grad_norm": 1.2347009181976318,
      "learning_rate": 0.00011499908734637418,
      "loss": 0.5361,
      "step": 674200
    },
    {
      "epoch": 7.137920082997655,
      "grad_norm": 1.1607177257537842,
      "learning_rate": 0.00011496021132990076,
      "loss": 0.5265,
      "step": 674250
    },
    {
      "epoch": 7.138449404777658,
      "grad_norm": 1.1573351621627808,
      "learning_rate": 0.00011492133992363627,
      "loss": 0.5325,
      "step": 674300
    },
    {
      "epoch": 7.138978726557662,
      "grad_norm": 1.332461953163147,
      "learning_rate": 0.00011488247312890762,
      "loss": 0.5356,
      "step": 674350
    },
    {
      "epoch": 7.139508048337665,
      "grad_norm": 1.2041096687316895,
      "learning_rate": 0.00011484361094704184,
      "loss": 0.5279,
      "step": 674400
    },
    {
      "epoch": 7.1400373701176685,
      "grad_norm": 1.215114951133728,
      "learning_rate": 0.00011480475337936555,
      "loss": 0.526,
      "step": 674450
    },
    {
      "epoch": 7.140566691897671,
      "grad_norm": 1.4462817907333374,
      "learning_rate": 0.0001147659004272055,
      "loss": 0.5259,
      "step": 674500
    },
    {
      "epoch": 7.140566691897671,
      "eval_loss": 0.3323071002960205,
      "eval_runtime": 47.0993,
      "eval_samples_per_second": 3565.448,
      "eval_steps_per_second": 445.697,
      "step": 674500
    },
    {
      "epoch": 7.141096013677675,
      "grad_norm": 1.3425918817520142,
      "learning_rate": 0.0001147270520918879,
      "loss": 0.5267,
      "step": 674550
    },
    {
      "epoch": 7.141625335457678,
      "grad_norm": 1.214624047279358,
      "learning_rate": 0.00011468820837473925,
      "loss": 0.5315,
      "step": 674600
    },
    {
      "epoch": 7.142154657237682,
      "grad_norm": 1.2395814657211304,
      "learning_rate": 0.00011464936927708544,
      "loss": 0.5357,
      "step": 674650
    },
    {
      "epoch": 7.142683979017685,
      "grad_norm": 1.3758714199066162,
      "learning_rate": 0.0001146105348002526,
      "loss": 0.5302,
      "step": 674700
    },
    {
      "epoch": 7.143213300797688,
      "grad_norm": 1.3058099746704102,
      "learning_rate": 0.00011457170494556637,
      "loss": 0.5368,
      "step": 674750
    },
    {
      "epoch": 7.143742622577691,
      "grad_norm": 1.338957667350769,
      "learning_rate": 0.00011453287971435256,
      "loss": 0.533,
      "step": 674800
    },
    {
      "epoch": 7.144271944357694,
      "grad_norm": 1.3070249557495117,
      "learning_rate": 0.00011449405910793645,
      "loss": 0.524,
      "step": 674850
    },
    {
      "epoch": 7.144801266137698,
      "grad_norm": 1.1708154678344727,
      "learning_rate": 0.00011445524312764357,
      "loss": 0.5293,
      "step": 674900
    },
    {
      "epoch": 7.145330587917701,
      "grad_norm": 1.3003028631210327,
      "learning_rate": 0.00011441643177479888,
      "loss": 0.5309,
      "step": 674950
    },
    {
      "epoch": 7.1458599096977045,
      "grad_norm": 1.2864621877670288,
      "learning_rate": 0.0001143776250507276,
      "loss": 0.5304,
      "step": 675000
    },
    {
      "epoch": 7.1458599096977045,
      "eval_loss": 0.3316445052623749,
      "eval_runtime": 47.1175,
      "eval_samples_per_second": 3564.065,
      "eval_steps_per_second": 445.524,
      "step": 675000
    },
    {
      "epoch": 7.146389231477707,
      "grad_norm": 1.2776813507080078,
      "learning_rate": 0.00011433882295675435,
      "loss": 0.529,
      "step": 675050
    },
    {
      "epoch": 7.146918553257711,
      "grad_norm": 1.2486857175827026,
      "learning_rate": 0.00011430002549420404,
      "loss": 0.5337,
      "step": 675100
    },
    {
      "epoch": 7.147447875037714,
      "grad_norm": 1.1609044075012207,
      "learning_rate": 0.00011426123266440097,
      "loss": 0.5279,
      "step": 675150
    },
    {
      "epoch": 7.147977196817718,
      "grad_norm": 1.4804646968841553,
      "learning_rate": 0.00011422244446866967,
      "loss": 0.5333,
      "step": 675200
    },
    {
      "epoch": 7.148506518597721,
      "grad_norm": 1.2044538259506226,
      "learning_rate": 0.00011418366090833441,
      "loss": 0.5249,
      "step": 675250
    },
    {
      "epoch": 7.149035840377724,
      "grad_norm": 1.2864477634429932,
      "learning_rate": 0.00011414488198471903,
      "loss": 0.5312,
      "step": 675300
    },
    {
      "epoch": 7.149565162157727,
      "grad_norm": 1.3167107105255127,
      "learning_rate": 0.00011410610769914758,
      "loss": 0.5354,
      "step": 675350
    },
    {
      "epoch": 7.150094483937731,
      "grad_norm": 1.3460510969161987,
      "learning_rate": 0.00011406811340039361,
      "loss": 0.5308,
      "step": 675400
    },
    {
      "epoch": 7.150623805717734,
      "grad_norm": 1.396814227104187,
      "learning_rate": 0.00011402934830205433,
      "loss": 0.5366,
      "step": 675450
    },
    {
      "epoch": 7.151153127497738,
      "grad_norm": 1.3647847175598145,
      "learning_rate": 0.00011399058784570316,
      "loss": 0.5268,
      "step": 675500
    },
    {
      "epoch": 7.151153127497738,
      "eval_loss": 0.33213865756988525,
      "eval_runtime": 47.5263,
      "eval_samples_per_second": 3533.412,
      "eval_steps_per_second": 441.692,
      "step": 675500
    },
    {
      "epoch": 7.15168244927774,
      "grad_norm": 1.3774237632751465,
      "learning_rate": 0.00011395183203266349,
      "loss": 0.5354,
      "step": 675550
    },
    {
      "epoch": 7.152211771057743,
      "grad_norm": 1.33078932762146,
      "learning_rate": 0.0001139130808642583,
      "loss": 0.5358,
      "step": 675600
    },
    {
      "epoch": 7.152741092837747,
      "grad_norm": 1.252529263496399,
      "learning_rate": 0.00011387433434181065,
      "loss": 0.5385,
      "step": 675650
    },
    {
      "epoch": 7.15327041461775,
      "grad_norm": 1.2835757732391357,
      "learning_rate": 0.00011383559246664338,
      "loss": 0.5275,
      "step": 675700
    },
    {
      "epoch": 7.153799736397754,
      "grad_norm": 1.2909321784973145,
      "learning_rate": 0.00011379685524007896,
      "loss": 0.531,
      "step": 675750
    },
    {
      "epoch": 7.1543290581777566,
      "grad_norm": 1.2312430143356323,
      "learning_rate": 0.00011375812266343993,
      "loss": 0.5307,
      "step": 675800
    },
    {
      "epoch": 7.15485837995776,
      "grad_norm": 1.2763315439224243,
      "learning_rate": 0.00011371939473804874,
      "loss": 0.5286,
      "step": 675850
    },
    {
      "epoch": 7.155387701737763,
      "grad_norm": 1.3729346990585327,
      "learning_rate": 0.00011368067146522731,
      "loss": 0.5326,
      "step": 675900
    },
    {
      "epoch": 7.155917023517767,
      "grad_norm": 1.2011544704437256,
      "learning_rate": 0.00011364195284629788,
      "loss": 0.5305,
      "step": 675950
    },
    {
      "epoch": 7.15644634529777,
      "grad_norm": 1.3234755992889404,
      "learning_rate": 0.0001136032388825821,
      "loss": 0.5396,
      "step": 676000
    },
    {
      "epoch": 7.15644634529777,
      "eval_loss": 0.3316311240196228,
      "eval_runtime": 47.272,
      "eval_samples_per_second": 3552.416,
      "eval_steps_per_second": 444.068,
      "step": 676000
    },
    {
      "epoch": 7.1569756670777736,
      "grad_norm": 1.2083007097244263,
      "learning_rate": 0.00011356452957540179,
      "loss": 0.5361,
      "step": 676050
    },
    {
      "epoch": 7.157504988857776,
      "grad_norm": 1.2651864290237427,
      "learning_rate": 0.0001135258249260783,
      "loss": 0.5297,
      "step": 676100
    },
    {
      "epoch": 7.15803431063778,
      "grad_norm": 1.2541249990463257,
      "learning_rate": 0.00011348712493593321,
      "loss": 0.5349,
      "step": 676150
    },
    {
      "epoch": 7.158563632417783,
      "grad_norm": 1.187933087348938,
      "learning_rate": 0.00011344842960628752,
      "loss": 0.5284,
      "step": 676200
    },
    {
      "epoch": 7.159092954197787,
      "grad_norm": 1.22226083278656,
      "learning_rate": 0.00011340973893846243,
      "loss": 0.5325,
      "step": 676250
    },
    {
      "epoch": 7.15962227597779,
      "grad_norm": 1.218371033668518,
      "learning_rate": 0.0001133710529337787,
      "loss": 0.5285,
      "step": 676300
    },
    {
      "epoch": 7.1601515977577925,
      "grad_norm": 1.3097758293151855,
      "learning_rate": 0.0001133323715935572,
      "loss": 0.5362,
      "step": 676350
    },
    {
      "epoch": 7.160680919537796,
      "grad_norm": 1.1264537572860718,
      "learning_rate": 0.00011329369491911832,
      "loss": 0.5262,
      "step": 676400
    },
    {
      "epoch": 7.161210241317799,
      "grad_norm": 1.294142484664917,
      "learning_rate": 0.00011325502291178263,
      "loss": 0.5224,
      "step": 676450
    },
    {
      "epoch": 7.161739563097803,
      "grad_norm": 1.3021689653396606,
      "learning_rate": 0.00011321635557287021,
      "loss": 0.532,
      "step": 676500
    },
    {
      "epoch": 7.161739563097803,
      "eval_loss": 0.33144834637641907,
      "eval_runtime": 48.0635,
      "eval_samples_per_second": 3493.919,
      "eval_steps_per_second": 436.755,
      "step": 676500
    },
    {
      "epoch": 7.162268884877806,
      "grad_norm": 1.3478907346725464,
      "learning_rate": 0.00011317769290370137,
      "loss": 0.5308,
      "step": 676550
    },
    {
      "epoch": 7.1627982066578095,
      "grad_norm": 1.2951217889785767,
      "learning_rate": 0.00011313903490559582,
      "loss": 0.5323,
      "step": 676600
    },
    {
      "epoch": 7.163327528437812,
      "grad_norm": 1.239524006843567,
      "learning_rate": 0.00011310038157987352,
      "loss": 0.5312,
      "step": 676650
    },
    {
      "epoch": 7.163856850217816,
      "grad_norm": 1.2688435316085815,
      "learning_rate": 0.00011306173292785387,
      "loss": 0.5311,
      "step": 676700
    },
    {
      "epoch": 7.164386171997819,
      "grad_norm": 1.2531665563583374,
      "learning_rate": 0.00011302308895085656,
      "loss": 0.5333,
      "step": 676750
    },
    {
      "epoch": 7.164915493777823,
      "grad_norm": 1.3225613832473755,
      "learning_rate": 0.00011298444965020063,
      "loss": 0.5188,
      "step": 676800
    },
    {
      "epoch": 7.165444815557826,
      "grad_norm": 1.2374176979064941,
      "learning_rate": 0.00011294581502720547,
      "loss": 0.5282,
      "step": 676850
    },
    {
      "epoch": 7.165974137337829,
      "grad_norm": 1.2674442529678345,
      "learning_rate": 0.00011290718508318982,
      "loss": 0.5238,
      "step": 676900
    },
    {
      "epoch": 7.166503459117832,
      "grad_norm": 1.3459067344665527,
      "learning_rate": 0.00011286855981947259,
      "loss": 0.5272,
      "step": 676950
    },
    {
      "epoch": 7.167032780897836,
      "grad_norm": 1.3383204936981201,
      "learning_rate": 0.0001128299392373725,
      "loss": 0.52,
      "step": 677000
    },
    {
      "epoch": 7.167032780897836,
      "eval_loss": 0.330961674451828,
      "eval_runtime": 48.5313,
      "eval_samples_per_second": 3460.244,
      "eval_steps_per_second": 432.546,
      "step": 677000
    },
    {
      "epoch": 7.167562102677839,
      "grad_norm": 1.2982728481292725,
      "learning_rate": 0.00011279132333820793,
      "loss": 0.5248,
      "step": 677050
    },
    {
      "epoch": 7.168091424457842,
      "grad_norm": 1.319293737411499,
      "learning_rate": 0.00011275271212329732,
      "loss": 0.5348,
      "step": 677100
    },
    {
      "epoch": 7.1686207462378455,
      "grad_norm": 1.1990776062011719,
      "learning_rate": 0.00011271410559395873,
      "loss": 0.526,
      "step": 677150
    },
    {
      "epoch": 7.169150068017848,
      "grad_norm": 1.37035071849823,
      "learning_rate": 0.00011267550375151029,
      "loss": 0.5363,
      "step": 677200
    },
    {
      "epoch": 7.169679389797852,
      "grad_norm": 1.2477185726165771,
      "learning_rate": 0.00011263690659726969,
      "loss": 0.5339,
      "step": 677250
    },
    {
      "epoch": 7.170208711577855,
      "grad_norm": 1.2674472332000732,
      "learning_rate": 0.00011259831413255483,
      "loss": 0.5324,
      "step": 677300
    },
    {
      "epoch": 7.170738033357859,
      "grad_norm": 1.2117267847061157,
      "learning_rate": 0.00011255972635868306,
      "loss": 0.5327,
      "step": 677350
    },
    {
      "epoch": 7.171267355137862,
      "grad_norm": 1.360176920890808,
      "learning_rate": 0.00011252191489261435,
      "loss": 0.5236,
      "step": 677400
    },
    {
      "epoch": 7.171796676917865,
      "grad_norm": 1.3108491897583008,
      "learning_rate": 0.00011248333641049848,
      "loss": 0.5302,
      "step": 677450
    },
    {
      "epoch": 7.172325998697868,
      "grad_norm": 1.3820385932922363,
      "learning_rate": 0.00011244476262315099,
      "loss": 0.5203,
      "step": 677500
    },
    {
      "epoch": 7.172325998697868,
      "eval_loss": 0.3307638168334961,
      "eval_runtime": 47.8287,
      "eval_samples_per_second": 3511.07,
      "eval_steps_per_second": 438.899,
      "step": 677500
    },
    {
      "epoch": 7.172855320477872,
      "grad_norm": 1.2758840322494507,
      "learning_rate": 0.00011240619353188894,
      "loss": 0.5277,
      "step": 677550
    },
    {
      "epoch": 7.173384642257875,
      "grad_norm": 1.2020339965820312,
      "learning_rate": 0.00011236762913802887,
      "loss": 0.5347,
      "step": 677600
    },
    {
      "epoch": 7.173913964037879,
      "grad_norm": 1.1979153156280518,
      "learning_rate": 0.0001123290694428876,
      "loss": 0.5253,
      "step": 677650
    },
    {
      "epoch": 7.1744432858178815,
      "grad_norm": 1.249572992324829,
      "learning_rate": 0.00011229051444778126,
      "loss": 0.5346,
      "step": 677700
    },
    {
      "epoch": 7.174972607597885,
      "grad_norm": 1.1779876947402954,
      "learning_rate": 0.00011225196415402639,
      "loss": 0.5421,
      "step": 677750
    },
    {
      "epoch": 7.175501929377888,
      "grad_norm": 1.2159591913223267,
      "learning_rate": 0.00011221341856293884,
      "loss": 0.5287,
      "step": 677800
    },
    {
      "epoch": 7.176031251157891,
      "grad_norm": 1.3462276458740234,
      "learning_rate": 0.00011217487767583465,
      "loss": 0.53,
      "step": 677850
    },
    {
      "epoch": 7.176560572937895,
      "grad_norm": 1.1233787536621094,
      "learning_rate": 0.00011213634149402968,
      "loss": 0.5212,
      "step": 677900
    },
    {
      "epoch": 7.177089894717898,
      "grad_norm": 1.2392367124557495,
      "learning_rate": 0.00011209781001883936,
      "loss": 0.5266,
      "step": 677950
    },
    {
      "epoch": 7.177619216497901,
      "grad_norm": 1.2076164484024048,
      "learning_rate": 0.00011205928325157925,
      "loss": 0.5254,
      "step": 678000
    },
    {
      "epoch": 7.177619216497901,
      "eval_loss": 0.3306924104690552,
      "eval_runtime": 47.8813,
      "eval_samples_per_second": 3507.212,
      "eval_steps_per_second": 438.417,
      "step": 678000
    },
    {
      "epoch": 7.178148538277904,
      "grad_norm": 1.2871265411376953,
      "learning_rate": 0.0001120207611935647,
      "loss": 0.5284,
      "step": 678050
    },
    {
      "epoch": 7.178677860057908,
      "grad_norm": 1.4228029251098633,
      "learning_rate": 0.00011198224384611066,
      "loss": 0.5263,
      "step": 678100
    },
    {
      "epoch": 7.179207181837911,
      "grad_norm": 1.2867704629898071,
      "learning_rate": 0.00011194373121053228,
      "loss": 0.5284,
      "step": 678150
    },
    {
      "epoch": 7.179736503617915,
      "grad_norm": 1.3660049438476562,
      "learning_rate": 0.00011190522328814423,
      "loss": 0.5386,
      "step": 678200
    },
    {
      "epoch": 7.1802658253979175,
      "grad_norm": 1.3278642892837524,
      "learning_rate": 0.00011186672008026128,
      "loss": 0.5231,
      "step": 678250
    },
    {
      "epoch": 7.180795147177921,
      "grad_norm": 1.3054563999176025,
      "learning_rate": 0.00011182822158819774,
      "loss": 0.532,
      "step": 678300
    },
    {
      "epoch": 7.181324468957924,
      "grad_norm": 1.3001283407211304,
      "learning_rate": 0.00011178972781326816,
      "loss": 0.5285,
      "step": 678350
    },
    {
      "epoch": 7.181853790737928,
      "grad_norm": 1.299385905265808,
      "learning_rate": 0.0001117512387567865,
      "loss": 0.5439,
      "step": 678400
    },
    {
      "epoch": 7.182383112517931,
      "grad_norm": 1.2993131875991821,
      "learning_rate": 0.00011171275442006692,
      "loss": 0.53,
      "step": 678450
    },
    {
      "epoch": 7.1829124342979345,
      "grad_norm": 1.2478128671646118,
      "learning_rate": 0.0001116742748044231,
      "loss": 0.5354,
      "step": 678500
    },
    {
      "epoch": 7.1829124342979345,
      "eval_loss": 0.3315151333808899,
      "eval_runtime": 47.637,
      "eval_samples_per_second": 3525.197,
      "eval_steps_per_second": 440.665,
      "step": 678500
    },
    {
      "epoch": 7.183441756077937,
      "grad_norm": 1.4199016094207764,
      "learning_rate": 0.0001116357999111689,
      "loss": 0.5244,
      "step": 678550
    },
    {
      "epoch": 7.18397107785794,
      "grad_norm": 1.2655671834945679,
      "learning_rate": 0.00011159732974161766,
      "loss": 0.5305,
      "step": 678600
    },
    {
      "epoch": 7.184500399637944,
      "grad_norm": 1.3298099040985107,
      "learning_rate": 0.00011155886429708292,
      "loss": 0.5231,
      "step": 678650
    },
    {
      "epoch": 7.185029721417947,
      "grad_norm": 1.2300605773925781,
      "learning_rate": 0.00011152040357887769,
      "loss": 0.5407,
      "step": 678700
    },
    {
      "epoch": 7.185559043197951,
      "grad_norm": 1.2335807085037231,
      "learning_rate": 0.00011148194758831517,
      "loss": 0.5311,
      "step": 678750
    },
    {
      "epoch": 7.1860883649779534,
      "grad_norm": 1.1787842512130737,
      "learning_rate": 0.00011144349632670808,
      "loss": 0.54,
      "step": 678800
    },
    {
      "epoch": 7.186617686757957,
      "grad_norm": 1.304506540298462,
      "learning_rate": 0.0001114050497953693,
      "loss": 0.5301,
      "step": 678850
    },
    {
      "epoch": 7.18714700853796,
      "grad_norm": 1.108973503112793,
      "learning_rate": 0.00011136660799561122,
      "loss": 0.5318,
      "step": 678900
    },
    {
      "epoch": 7.187676330317964,
      "grad_norm": 1.306610107421875,
      "learning_rate": 0.00011132817092874637,
      "loss": 0.5357,
      "step": 678950
    },
    {
      "epoch": 7.188205652097967,
      "grad_norm": 1.2440085411071777,
      "learning_rate": 0.00011128973859608682,
      "loss": 0.5419,
      "step": 679000
    },
    {
      "epoch": 7.188205652097967,
      "eval_loss": 0.3315586447715759,
      "eval_runtime": 48.4158,
      "eval_samples_per_second": 3468.494,
      "eval_steps_per_second": 433.577,
      "step": 679000
    },
    {
      "epoch": 7.1887349738779704,
      "grad_norm": 1.2827028036117554,
      "learning_rate": 0.00011125131099894481,
      "loss": 0.5363,
      "step": 679050
    },
    {
      "epoch": 7.189264295657973,
      "grad_norm": 1.2340469360351562,
      "learning_rate": 0.00011121288813863209,
      "loss": 0.5325,
      "step": 679100
    },
    {
      "epoch": 7.189793617437977,
      "grad_norm": 1.20699942111969,
      "learning_rate": 0.00011117447001646053,
      "loss": 0.5304,
      "step": 679150
    },
    {
      "epoch": 7.19032293921798,
      "grad_norm": 1.2837973833084106,
      "learning_rate": 0.00011113605663374158,
      "loss": 0.5367,
      "step": 679200
    },
    {
      "epoch": 7.190852260997984,
      "grad_norm": 1.2705198526382446,
      "learning_rate": 0.00011109764799178681,
      "loss": 0.539,
      "step": 679250
    },
    {
      "epoch": 7.191381582777987,
      "grad_norm": 1.3402607440948486,
      "learning_rate": 0.00011105924409190731,
      "loss": 0.5327,
      "step": 679300
    },
    {
      "epoch": 7.191910904557989,
      "grad_norm": 1.3978745937347412,
      "learning_rate": 0.00011102084493541436,
      "loss": 0.5398,
      "step": 679350
    },
    {
      "epoch": 7.192440226337993,
      "grad_norm": 1.2213115692138672,
      "learning_rate": 0.00011098321836534813,
      "loss": 0.5247,
      "step": 679400
    },
    {
      "epoch": 7.192969548117996,
      "grad_norm": 1.3153979778289795,
      "learning_rate": 0.00011094482860462762,
      "loss": 0.5355,
      "step": 679450
    },
    {
      "epoch": 7.193498869898,
      "grad_norm": 1.313199758529663,
      "learning_rate": 0.00011090644359119975,
      "loss": 0.5255,
      "step": 679500
    },
    {
      "epoch": 7.193498869898,
      "eval_loss": 0.32996103167533875,
      "eval_runtime": 48.1988,
      "eval_samples_per_second": 3484.115,
      "eval_steps_per_second": 435.53,
      "step": 679500
    },
    {
      "epoch": 7.194028191678003,
      "grad_norm": 1.1259175539016724,
      "learning_rate": 0.00011086806332637481,
      "loss": 0.54,
      "step": 679550
    },
    {
      "epoch": 7.194557513458006,
      "grad_norm": 1.1050500869750977,
      "learning_rate": 0.00011082968781146321,
      "loss": 0.5221,
      "step": 679600
    },
    {
      "epoch": 7.195086835238009,
      "grad_norm": 1.2250710725784302,
      "learning_rate": 0.00011079131704777499,
      "loss": 0.5414,
      "step": 679650
    },
    {
      "epoch": 7.195616157018013,
      "grad_norm": 1.3439383506774902,
      "learning_rate": 0.0001107529510366202,
      "loss": 0.5339,
      "step": 679700
    },
    {
      "epoch": 7.196145478798016,
      "grad_norm": 1.340035080909729,
      "learning_rate": 0.00011071458977930855,
      "loss": 0.532,
      "step": 679750
    },
    {
      "epoch": 7.19667480057802,
      "grad_norm": 1.3989381790161133,
      "learning_rate": 0.00011067623327714976,
      "loss": 0.5342,
      "step": 679800
    },
    {
      "epoch": 7.1972041223580225,
      "grad_norm": 1.2030788660049438,
      "learning_rate": 0.00011063788153145321,
      "loss": 0.5327,
      "step": 679850
    },
    {
      "epoch": 7.197733444138026,
      "grad_norm": 1.32522714138031,
      "learning_rate": 0.00011059953454352829,
      "loss": 0.535,
      "step": 679900
    },
    {
      "epoch": 7.198262765918029,
      "grad_norm": 1.255162000656128,
      "learning_rate": 0.0001105611923146842,
      "loss": 0.5303,
      "step": 679950
    },
    {
      "epoch": 7.198792087698033,
      "grad_norm": 1.1562777757644653,
      "learning_rate": 0.00011052285484622978,
      "loss": 0.5341,
      "step": 680000
    },
    {
      "epoch": 7.198792087698033,
      "eval_loss": 0.329953134059906,
      "eval_runtime": 48.4902,
      "eval_samples_per_second": 3463.172,
      "eval_steps_per_second": 432.912,
      "step": 680000
    },
    {
      "epoch": 7.199321409478036,
      "grad_norm": 1.1327924728393555,
      "learning_rate": 0.00011048452213947396,
      "loss": 0.5378,
      "step": 680050
    },
    {
      "epoch": 7.199850731258039,
      "grad_norm": 1.2639192342758179,
      "learning_rate": 0.00011044619419572547,
      "loss": 0.5225,
      "step": 680100
    },
    {
      "epoch": 7.200380053038042,
      "grad_norm": 1.1858232021331787,
      "learning_rate": 0.00011040787101629262,
      "loss": 0.5348,
      "step": 680150
    },
    {
      "epoch": 7.200909374818045,
      "grad_norm": 1.3172727823257446,
      "learning_rate": 0.000110369552602484,
      "loss": 0.5278,
      "step": 680200
    },
    {
      "epoch": 7.201438696598049,
      "grad_norm": 1.4720240831375122,
      "learning_rate": 0.00011033123895560751,
      "loss": 0.5259,
      "step": 680250
    },
    {
      "epoch": 7.201968018378052,
      "grad_norm": 1.3166708946228027,
      "learning_rate": 0.00011029293007697139,
      "loss": 0.5308,
      "step": 680300
    },
    {
      "epoch": 7.202497340158056,
      "grad_norm": 1.36726975440979,
      "learning_rate": 0.00011025462596788333,
      "loss": 0.5328,
      "step": 680350
    },
    {
      "epoch": 7.2030266619380585,
      "grad_norm": 1.1887108087539673,
      "learning_rate": 0.00011021632662965117,
      "loss": 0.5288,
      "step": 680400
    },
    {
      "epoch": 7.203555983718062,
      "grad_norm": 1.2953139543533325,
      "learning_rate": 0.00011017803206358229,
      "loss": 0.5297,
      "step": 680450
    },
    {
      "epoch": 7.204085305498065,
      "grad_norm": 1.1313780546188354,
      "learning_rate": 0.00011013974227098416,
      "loss": 0.5263,
      "step": 680500
    },
    {
      "epoch": 7.204085305498065,
      "eval_loss": 0.33035317063331604,
      "eval_runtime": 48.2138,
      "eval_samples_per_second": 3483.028,
      "eval_steps_per_second": 435.394,
      "step": 680500
    },
    {
      "epoch": 7.204614627278069,
      "grad_norm": 1.3470298051834106,
      "learning_rate": 0.00011010145725316389,
      "loss": 0.5339,
      "step": 680550
    },
    {
      "epoch": 7.205143949058072,
      "grad_norm": 1.3643172979354858,
      "learning_rate": 0.00011006317701142862,
      "loss": 0.535,
      "step": 680600
    },
    {
      "epoch": 7.2056732708380755,
      "grad_norm": 1.3846174478530884,
      "learning_rate": 0.00011002490154708512,
      "loss": 0.54,
      "step": 680650
    },
    {
      "epoch": 7.206202592618078,
      "grad_norm": 1.2634284496307373,
      "learning_rate": 0.0001099866308614402,
      "loss": 0.5385,
      "step": 680700
    },
    {
      "epoch": 7.206731914398082,
      "grad_norm": 1.1814417839050293,
      "learning_rate": 0.00010994836495580027,
      "loss": 0.5239,
      "step": 680750
    },
    {
      "epoch": 7.207261236178085,
      "grad_norm": 1.3339378833770752,
      "learning_rate": 0.0001099101038314719,
      "loss": 0.5392,
      "step": 680800
    },
    {
      "epoch": 7.207790557958088,
      "grad_norm": 1.2518401145935059,
      "learning_rate": 0.00010987184748976109,
      "loss": 0.5324,
      "step": 680850
    },
    {
      "epoch": 7.208319879738092,
      "grad_norm": 1.300675868988037,
      "learning_rate": 0.00010983359593197414,
      "loss": 0.5355,
      "step": 680900
    },
    {
      "epoch": 7.2088492015180945,
      "grad_norm": 1.149523377418518,
      "learning_rate": 0.00010979534915941671,
      "loss": 0.5172,
      "step": 680950
    },
    {
      "epoch": 7.209378523298098,
      "grad_norm": 1.334126591682434,
      "learning_rate": 0.00010975710717339474,
      "loss": 0.5347,
      "step": 681000
    },
    {
      "epoch": 7.209378523298098,
      "eval_loss": 0.3306290805339813,
      "eval_runtime": 48.0253,
      "eval_samples_per_second": 3496.699,
      "eval_steps_per_second": 437.103,
      "step": 681000
    },
    {
      "epoch": 7.209907845078101,
      "grad_norm": 1.3166178464889526,
      "learning_rate": 0.00010971886997521361,
      "loss": 0.5311,
      "step": 681050
    },
    {
      "epoch": 7.210437166858105,
      "grad_norm": 1.2387853860855103,
      "learning_rate": 0.00010968063756617888,
      "loss": 0.524,
      "step": 681100
    },
    {
      "epoch": 7.210966488638108,
      "grad_norm": 1.4264352321624756,
      "learning_rate": 0.00010964240994759566,
      "loss": 0.5384,
      "step": 681150
    },
    {
      "epoch": 7.2114958104181115,
      "grad_norm": 1.214607834815979,
      "learning_rate": 0.00010960418712076917,
      "loss": 0.5312,
      "step": 681200
    },
    {
      "epoch": 7.212025132198114,
      "grad_norm": 1.2921315431594849,
      "learning_rate": 0.00010956596908700416,
      "loss": 0.5263,
      "step": 681250
    },
    {
      "epoch": 7.212554453978118,
      "grad_norm": 1.3420735597610474,
      "learning_rate": 0.00010952775584760554,
      "loss": 0.5233,
      "step": 681300
    },
    {
      "epoch": 7.213083775758121,
      "grad_norm": 1.2252916097640991,
      "learning_rate": 0.00010948954740387773,
      "loss": 0.5293,
      "step": 681350
    },
    {
      "epoch": 7.213613097538125,
      "grad_norm": 1.2024097442626953,
      "learning_rate": 0.00010945210778304155,
      "loss": 0.5295,
      "step": 681400
    },
    {
      "epoch": 7.214142419318128,
      "grad_norm": 1.2804327011108398,
      "learning_rate": 0.00010941390883859026,
      "loss": 0.5346,
      "step": 681450
    },
    {
      "epoch": 7.214671741098131,
      "grad_norm": 1.3036909103393555,
      "learning_rate": 0.00010937571469369667,
      "loss": 0.5238,
      "step": 681500
    },
    {
      "epoch": 7.214671741098131,
      "eval_loss": 0.3297763466835022,
      "eval_runtime": 48.3207,
      "eval_samples_per_second": 3475.326,
      "eval_steps_per_second": 434.431,
      "step": 681500
    },
    {
      "epoch": 7.215201062878134,
      "grad_norm": 1.3020107746124268,
      "learning_rate": 0.00010933752534966451,
      "loss": 0.5328,
      "step": 681550
    },
    {
      "epoch": 7.215730384658137,
      "grad_norm": 1.316536784172058,
      "learning_rate": 0.00010929934080779774,
      "loss": 0.5342,
      "step": 681600
    },
    {
      "epoch": 7.216259706438141,
      "grad_norm": 1.236332893371582,
      "learning_rate": 0.00010926116106939978,
      "loss": 0.5329,
      "step": 681650
    },
    {
      "epoch": 7.216789028218144,
      "grad_norm": 1.463955283164978,
      "learning_rate": 0.00010922374958735153,
      "loss": 0.5298,
      "step": 681700
    },
    {
      "epoch": 7.2173183499981475,
      "grad_norm": 1.3177523612976074,
      "learning_rate": 0.00010918557936366736,
      "loss": 0.5225,
      "step": 681750
    },
    {
      "epoch": 7.21784767177815,
      "grad_norm": 1.146086573600769,
      "learning_rate": 0.00010914741394733576,
      "loss": 0.5338,
      "step": 681800
    },
    {
      "epoch": 7.218376993558154,
      "grad_norm": 1.1827529668807983,
      "learning_rate": 0.00010910925333965991,
      "loss": 0.5285,
      "step": 681850
    },
    {
      "epoch": 7.218906315338157,
      "grad_norm": 1.3343844413757324,
      "learning_rate": 0.00010907109754194239,
      "loss": 0.5336,
      "step": 681900
    },
    {
      "epoch": 7.219435637118161,
      "grad_norm": 1.2741299867630005,
      "learning_rate": 0.00010903294655548598,
      "loss": 0.5397,
      "step": 681950
    },
    {
      "epoch": 7.219964958898164,
      "grad_norm": 1.4015617370605469,
      "learning_rate": 0.00010899480038159299,
      "loss": 0.5268,
      "step": 682000
    },
    {
      "epoch": 7.219964958898164,
      "eval_loss": 0.3296806514263153,
      "eval_runtime": 47.9269,
      "eval_samples_per_second": 3503.879,
      "eval_steps_per_second": 438.0,
      "step": 682000
    },
    {
      "epoch": 7.220494280678167,
      "grad_norm": 1.2217395305633545,
      "learning_rate": 0.00010895665902156591,
      "loss": 0.5292,
      "step": 682050
    },
    {
      "epoch": 7.22102360245817,
      "grad_norm": 1.3635754585266113,
      "learning_rate": 0.00010891852247670666,
      "loss": 0.5282,
      "step": 682100
    },
    {
      "epoch": 7.221552924238174,
      "grad_norm": 1.2055175304412842,
      "learning_rate": 0.0001088803907483174,
      "loss": 0.5323,
      "step": 682150
    },
    {
      "epoch": 7.222082246018177,
      "grad_norm": 1.373128890991211,
      "learning_rate": 0.00010884226383769977,
      "loss": 0.5176,
      "step": 682200
    },
    {
      "epoch": 7.222611567798181,
      "grad_norm": 1.1208343505859375,
      "learning_rate": 0.00010880414174615558,
      "loss": 0.5341,
      "step": 682250
    },
    {
      "epoch": 7.2231408895781835,
      "grad_norm": 1.3985226154327393,
      "learning_rate": 0.00010876602447498609,
      "loss": 0.523,
      "step": 682300
    },
    {
      "epoch": 7.223670211358186,
      "grad_norm": 1.3089104890823364,
      "learning_rate": 0.00010872791202549284,
      "loss": 0.5288,
      "step": 682350
    },
    {
      "epoch": 7.22419953313819,
      "grad_norm": 1.3052273988723755,
      "learning_rate": 0.00010868980439897677,
      "loss": 0.5255,
      "step": 682400
    },
    {
      "epoch": 7.224728854918193,
      "grad_norm": 1.1927649974822998,
      "learning_rate": 0.00010865170159673904,
      "loss": 0.539,
      "step": 682450
    },
    {
      "epoch": 7.225258176698197,
      "grad_norm": 1.2850464582443237,
      "learning_rate": 0.0001086136036200803,
      "loss": 0.5255,
      "step": 682500
    },
    {
      "epoch": 7.225258176698197,
      "eval_loss": 0.32962602376937866,
      "eval_runtime": 49.6983,
      "eval_samples_per_second": 3378.988,
      "eval_steps_per_second": 422.389,
      "step": 682500
    },
    {
      "epoch": 7.2257874984782,
      "grad_norm": 1.2546586990356445,
      "learning_rate": 0.00010857551047030125,
      "loss": 0.5227,
      "step": 682550
    },
    {
      "epoch": 7.226316820258203,
      "grad_norm": 1.2134639024734497,
      "learning_rate": 0.00010853742214870255,
      "loss": 0.5234,
      "step": 682600
    },
    {
      "epoch": 7.226846142038206,
      "grad_norm": 1.2355015277862549,
      "learning_rate": 0.00010849933865658424,
      "loss": 0.5302,
      "step": 682650
    },
    {
      "epoch": 7.22737546381821,
      "grad_norm": 1.288221836090088,
      "learning_rate": 0.00010846125999524673,
      "loss": 0.524,
      "step": 682700
    },
    {
      "epoch": 7.227904785598213,
      "grad_norm": 1.2215105295181274,
      "learning_rate": 0.00010842318616598978,
      "loss": 0.5275,
      "step": 682750
    },
    {
      "epoch": 7.228434107378217,
      "grad_norm": 1.38041090965271,
      "learning_rate": 0.00010838511717011337,
      "loss": 0.5291,
      "step": 682800
    },
    {
      "epoch": 7.228963429158219,
      "grad_norm": 1.293378472328186,
      "learning_rate": 0.0001083470530089172,
      "loss": 0.5264,
      "step": 682850
    },
    {
      "epoch": 7.229492750938223,
      "grad_norm": 1.2925792932510376,
      "learning_rate": 0.0001083089936837006,
      "loss": 0.5314,
      "step": 682900
    },
    {
      "epoch": 7.230022072718226,
      "grad_norm": 1.2908018827438354,
      "learning_rate": 0.00010827093919576306,
      "loss": 0.5264,
      "step": 682950
    },
    {
      "epoch": 7.23055139449823,
      "grad_norm": 1.3108946084976196,
      "learning_rate": 0.0001082328895464036,
      "loss": 0.5263,
      "step": 683000
    },
    {
      "epoch": 7.23055139449823,
      "eval_loss": 0.3302043378353119,
      "eval_runtime": 48.48,
      "eval_samples_per_second": 3463.906,
      "eval_steps_per_second": 433.004,
      "step": 683000
    },
    {
      "epoch": 7.231080716278233,
      "grad_norm": 1.3335611820220947,
      "learning_rate": 0.0001081948447369214,
      "loss": 0.5404,
      "step": 683050
    },
    {
      "epoch": 7.2316100380582355,
      "grad_norm": 1.2563894987106323,
      "learning_rate": 0.00010815680476861508,
      "loss": 0.5391,
      "step": 683100
    },
    {
      "epoch": 7.232139359838239,
      "grad_norm": 1.2045818567276,
      "learning_rate": 0.00010811876964278356,
      "loss": 0.5303,
      "step": 683150
    },
    {
      "epoch": 7.232668681618242,
      "grad_norm": 1.3192219734191895,
      "learning_rate": 0.00010808073936072508,
      "loss": 0.5354,
      "step": 683200
    },
    {
      "epoch": 7.233198003398246,
      "grad_norm": 1.2142561674118042,
      "learning_rate": 0.00010804271392373821,
      "loss": 0.5194,
      "step": 683250
    },
    {
      "epoch": 7.233727325178249,
      "grad_norm": 1.222316861152649,
      "learning_rate": 0.00010800469333312097,
      "loss": 0.5299,
      "step": 683300
    },
    {
      "epoch": 7.2342566469582525,
      "grad_norm": 1.2376738786697388,
      "learning_rate": 0.00010796667759017147,
      "loss": 0.5343,
      "step": 683350
    },
    {
      "epoch": 7.234785968738255,
      "grad_norm": 1.3359736204147339,
      "learning_rate": 0.00010792866669618742,
      "loss": 0.5352,
      "step": 683400
    },
    {
      "epoch": 7.235315290518259,
      "grad_norm": 1.2833086252212524,
      "learning_rate": 0.00010789066065246669,
      "loss": 0.5278,
      "step": 683450
    },
    {
      "epoch": 7.235844612298262,
      "grad_norm": 1.2427293062210083,
      "learning_rate": 0.00010785265946030662,
      "loss": 0.5269,
      "step": 683500
    },
    {
      "epoch": 7.235844612298262,
      "eval_loss": 0.3304557502269745,
      "eval_runtime": 47.8437,
      "eval_samples_per_second": 3509.969,
      "eval_steps_per_second": 438.762,
      "step": 683500
    },
    {
      "epoch": 7.236373934078266,
      "grad_norm": 1.270011305809021,
      "learning_rate": 0.00010781466312100469,
      "loss": 0.5237,
      "step": 683550
    },
    {
      "epoch": 7.236903255858269,
      "grad_norm": 1.3634448051452637,
      "learning_rate": 0.00010777667163585791,
      "loss": 0.5305,
      "step": 683600
    },
    {
      "epoch": 7.237432577638272,
      "grad_norm": 1.3263533115386963,
      "learning_rate": 0.00010773868500616352,
      "loss": 0.5329,
      "step": 683650
    },
    {
      "epoch": 7.237961899418275,
      "grad_norm": 1.0992660522460938,
      "learning_rate": 0.00010770070323321815,
      "loss": 0.5231,
      "step": 683700
    },
    {
      "epoch": 7.238491221198279,
      "grad_norm": 1.3028383255004883,
      "learning_rate": 0.00010766272631831867,
      "loss": 0.5168,
      "step": 683750
    },
    {
      "epoch": 7.239020542978282,
      "grad_norm": 1.3292542695999146,
      "learning_rate": 0.00010762475426276145,
      "loss": 0.5358,
      "step": 683800
    },
    {
      "epoch": 7.239549864758285,
      "grad_norm": 1.3975955247879028,
      "learning_rate": 0.00010758678706784297,
      "loss": 0.5265,
      "step": 683850
    },
    {
      "epoch": 7.2400791865382885,
      "grad_norm": 1.3546136617660522,
      "learning_rate": 0.00010754882473485924,
      "loss": 0.528,
      "step": 683900
    },
    {
      "epoch": 7.240608508318291,
      "grad_norm": 1.1672197580337524,
      "learning_rate": 0.00010751086726510654,
      "loss": 0.5246,
      "step": 683950
    },
    {
      "epoch": 7.241137830098295,
      "grad_norm": 1.2679150104522705,
      "learning_rate": 0.00010747291465988043,
      "loss": 0.523,
      "step": 684000
    },
    {
      "epoch": 7.241137830098295,
      "eval_loss": 0.32878822088241577,
      "eval_runtime": 47.597,
      "eval_samples_per_second": 3528.163,
      "eval_steps_per_second": 441.036,
      "step": 684000
    },
    {
      "epoch": 7.241667151878298,
      "grad_norm": 1.3137720823287964,
      "learning_rate": 0.00010743496692047686,
      "loss": 0.5316,
      "step": 684050
    },
    {
      "epoch": 7.242196473658302,
      "grad_norm": 1.3005582094192505,
      "learning_rate": 0.00010739702404819113,
      "loss": 0.5216,
      "step": 684100
    },
    {
      "epoch": 7.242725795438305,
      "grad_norm": 1.386749505996704,
      "learning_rate": 0.00010735908604431879,
      "loss": 0.5315,
      "step": 684150
    },
    {
      "epoch": 7.243255117218308,
      "grad_norm": 1.3522589206695557,
      "learning_rate": 0.00010732115291015487,
      "loss": 0.5286,
      "step": 684200
    },
    {
      "epoch": 7.243784438998311,
      "grad_norm": 1.3238661289215088,
      "learning_rate": 0.00010728322464699444,
      "loss": 0.535,
      "step": 684250
    },
    {
      "epoch": 7.244313760778315,
      "grad_norm": 1.3881943225860596,
      "learning_rate": 0.00010724530125613249,
      "loss": 0.5301,
      "step": 684300
    },
    {
      "epoch": 7.244843082558318,
      "grad_norm": 1.2938644886016846,
      "learning_rate": 0.00010720738273886352,
      "loss": 0.5308,
      "step": 684350
    },
    {
      "epoch": 7.245372404338322,
      "grad_norm": 1.2798435688018799,
      "learning_rate": 0.00010716946909648212,
      "loss": 0.5368,
      "step": 684400
    },
    {
      "epoch": 7.2459017261183245,
      "grad_norm": 1.27163827419281,
      "learning_rate": 0.00010713156033028276,
      "loss": 0.5236,
      "step": 684450
    },
    {
      "epoch": 7.246431047898328,
      "grad_norm": 1.4620016813278198,
      "learning_rate": 0.00010709365644155943,
      "loss": 0.5281,
      "step": 684500
    },
    {
      "epoch": 7.246431047898328,
      "eval_loss": 0.3288264274597168,
      "eval_runtime": 48.1923,
      "eval_samples_per_second": 3484.579,
      "eval_steps_per_second": 435.588,
      "step": 684500
    },
    {
      "epoch": 7.246960369678331,
      "grad_norm": 1.244672179222107,
      "learning_rate": 0.00010705575743160636,
      "loss": 0.5298,
      "step": 684550
    },
    {
      "epoch": 7.247489691458334,
      "grad_norm": 1.3191895484924316,
      "learning_rate": 0.00010701786330171723,
      "loss": 0.5352,
      "step": 684600
    },
    {
      "epoch": 7.248019013238338,
      "grad_norm": 1.2661718130111694,
      "learning_rate": 0.00010697997405318588,
      "loss": 0.528,
      "step": 684650
    },
    {
      "epoch": 7.248548335018341,
      "grad_norm": 1.2141603231430054,
      "learning_rate": 0.00010694208968730567,
      "loss": 0.5261,
      "step": 684700
    },
    {
      "epoch": 7.249077656798344,
      "grad_norm": 1.2667090892791748,
      "learning_rate": 0.00010690421020537016,
      "loss": 0.5277,
      "step": 684750
    },
    {
      "epoch": 7.249606978578347,
      "grad_norm": 1.2489923238754272,
      "learning_rate": 0.00010686633560867234,
      "loss": 0.5308,
      "step": 684800
    },
    {
      "epoch": 7.250136300358351,
      "grad_norm": 1.2059695720672607,
      "learning_rate": 0.00010682846589850542,
      "loss": 0.5252,
      "step": 684850
    },
    {
      "epoch": 7.250665622138354,
      "grad_norm": 1.3231309652328491,
      "learning_rate": 0.0001067906010761621,
      "loss": 0.5242,
      "step": 684900
    },
    {
      "epoch": 7.251194943918358,
      "grad_norm": 1.2800071239471436,
      "learning_rate": 0.00010675274114293517,
      "loss": 0.5371,
      "step": 684950
    },
    {
      "epoch": 7.2517242656983605,
      "grad_norm": 1.23301362991333,
      "learning_rate": 0.00010671488610011709,
      "loss": 0.5277,
      "step": 685000
    },
    {
      "epoch": 7.2517242656983605,
      "eval_loss": 0.3285837471485138,
      "eval_runtime": 48.1744,
      "eval_samples_per_second": 3485.873,
      "eval_steps_per_second": 435.75,
      "step": 685000
    },
    {
      "epoch": 7.252253587478364,
      "grad_norm": 1.3045310974121094,
      "learning_rate": 0.0001066770359490003,
      "loss": 0.538,
      "step": 685050
    },
    {
      "epoch": 7.252782909258367,
      "grad_norm": 1.2729980945587158,
      "learning_rate": 0.00010663919069087689,
      "loss": 0.5295,
      "step": 685100
    },
    {
      "epoch": 7.253312231038371,
      "grad_norm": 1.335187315940857,
      "learning_rate": 0.00010660135032703899,
      "loss": 0.5239,
      "step": 685150
    },
    {
      "epoch": 7.253841552818374,
      "grad_norm": 1.3395510911941528,
      "learning_rate": 0.00010656351485877832,
      "loss": 0.5209,
      "step": 685200
    },
    {
      "epoch": 7.2543708745983775,
      "grad_norm": 1.1821722984313965,
      "learning_rate": 0.00010652568428738674,
      "loss": 0.5164,
      "step": 685250
    },
    {
      "epoch": 7.25490019637838,
      "grad_norm": 1.3521735668182373,
      "learning_rate": 0.0001064878586141556,
      "loss": 0.5216,
      "step": 685300
    },
    {
      "epoch": 7.255429518158383,
      "grad_norm": 1.4635088443756104,
      "learning_rate": 0.00010645003784037641,
      "loss": 0.5252,
      "step": 685350
    },
    {
      "epoch": 7.255958839938387,
      "grad_norm": 1.2770706415176392,
      "learning_rate": 0.00010641222196734022,
      "loss": 0.5277,
      "step": 685400
    },
    {
      "epoch": 7.25648816171839,
      "grad_norm": 1.4725651741027832,
      "learning_rate": 0.00010637441099633818,
      "loss": 0.5364,
      "step": 685450
    },
    {
      "epoch": 7.257017483498394,
      "grad_norm": 1.1816234588623047,
      "learning_rate": 0.00010633660492866099,
      "loss": 0.5291,
      "step": 685500
    },
    {
      "epoch": 7.257017483498394,
      "eval_loss": 0.3286842107772827,
      "eval_runtime": 49.9041,
      "eval_samples_per_second": 3365.054,
      "eval_steps_per_second": 420.647,
      "step": 685500
    },
    {
      "epoch": 7.2575468052783965,
      "grad_norm": 1.1938633918762207,
      "learning_rate": 0.0001062988037655995,
      "loss": 0.5215,
      "step": 685550
    },
    {
      "epoch": 7.2580761270584,
      "grad_norm": 1.3677270412445068,
      "learning_rate": 0.00010626100750844405,
      "loss": 0.5285,
      "step": 685600
    },
    {
      "epoch": 7.258605448838403,
      "grad_norm": 1.1781508922576904,
      "learning_rate": 0.00010622321615848521,
      "loss": 0.5326,
      "step": 685650
    },
    {
      "epoch": 7.259134770618407,
      "grad_norm": 1.2836799621582031,
      "learning_rate": 0.00010618618539773089,
      "loss": 0.5306,
      "step": 685700
    },
    {
      "epoch": 7.25966409239841,
      "grad_norm": 1.2892309427261353,
      "learning_rate": 0.00010614840376782714,
      "loss": 0.5208,
      "step": 685750
    },
    {
      "epoch": 7.2601934141784135,
      "grad_norm": 1.2413445711135864,
      "learning_rate": 0.00010611062704896421,
      "loss": 0.5301,
      "step": 685800
    },
    {
      "epoch": 7.260722735958416,
      "grad_norm": 1.210868239402771,
      "learning_rate": 0.00010607285524243163,
      "loss": 0.5271,
      "step": 685850
    },
    {
      "epoch": 7.26125205773842,
      "grad_norm": 1.352212905883789,
      "learning_rate": 0.00010603508834951905,
      "loss": 0.524,
      "step": 685900
    },
    {
      "epoch": 7.261781379518423,
      "grad_norm": 1.1709941625595093,
      "learning_rate": 0.00010599732637151568,
      "loss": 0.5271,
      "step": 685950
    },
    {
      "epoch": 7.262310701298427,
      "grad_norm": 1.2719697952270508,
      "learning_rate": 0.00010595956930971084,
      "loss": 0.5293,
      "step": 686000
    },
    {
      "epoch": 7.262310701298427,
      "eval_loss": 0.32829374074935913,
      "eval_runtime": 50.1325,
      "eval_samples_per_second": 3349.726,
      "eval_steps_per_second": 418.731,
      "step": 686000
    },
    {
      "epoch": 7.26284002307843,
      "grad_norm": 1.200289249420166,
      "learning_rate": 0.00010592181716539342,
      "loss": 0.5271,
      "step": 686050
    },
    {
      "epoch": 7.263369344858432,
      "grad_norm": 1.3114336729049683,
      "learning_rate": 0.00010588406993985242,
      "loss": 0.5319,
      "step": 686100
    },
    {
      "epoch": 7.263898666638436,
      "grad_norm": 1.3070926666259766,
      "learning_rate": 0.0001058463276343763,
      "loss": 0.5299,
      "step": 686150
    },
    {
      "epoch": 7.264427988418439,
      "grad_norm": 1.2610145807266235,
      "learning_rate": 0.00010580859025025372,
      "loss": 0.5245,
      "step": 686200
    },
    {
      "epoch": 7.264957310198443,
      "grad_norm": 1.4126715660095215,
      "learning_rate": 0.00010577085778877305,
      "loss": 0.5296,
      "step": 686250
    },
    {
      "epoch": 7.265486631978446,
      "grad_norm": 1.1976345777511597,
      "learning_rate": 0.00010573313025122231,
      "loss": 0.5241,
      "step": 686300
    },
    {
      "epoch": 7.266015953758449,
      "grad_norm": 1.3742297887802124,
      "learning_rate": 0.00010569540763888971,
      "loss": 0.5249,
      "step": 686350
    },
    {
      "epoch": 7.266545275538452,
      "grad_norm": 1.2723875045776367,
      "learning_rate": 0.00010565768995306286,
      "loss": 0.5266,
      "step": 686400
    },
    {
      "epoch": 7.267074597318456,
      "grad_norm": 1.3396693468093872,
      "learning_rate": 0.00010561997719502953,
      "loss": 0.534,
      "step": 686450
    },
    {
      "epoch": 7.267603919098459,
      "grad_norm": 1.2286592721939087,
      "learning_rate": 0.00010558226936607734,
      "loss": 0.5286,
      "step": 686500
    },
    {
      "epoch": 7.267603919098459,
      "eval_loss": 0.32841724157333374,
      "eval_runtime": 50.0847,
      "eval_samples_per_second": 3352.923,
      "eval_steps_per_second": 419.13,
      "step": 686500
    },
    {
      "epoch": 7.268133240878463,
      "grad_norm": 1.2254087924957275,
      "learning_rate": 0.00010554456646749341,
      "loss": 0.5329,
      "step": 686550
    },
    {
      "epoch": 7.2686625626584656,
      "grad_norm": 1.2815881967544556,
      "learning_rate": 0.0001055068685005651,
      "loss": 0.5279,
      "step": 686600
    },
    {
      "epoch": 7.269191884438469,
      "grad_norm": 1.3619333505630493,
      "learning_rate": 0.00010546917546657922,
      "loss": 0.5349,
      "step": 686650
    },
    {
      "epoch": 7.269721206218472,
      "grad_norm": 1.234939694404602,
      "learning_rate": 0.00010543148736682268,
      "loss": 0.54,
      "step": 686700
    },
    {
      "epoch": 7.270250527998476,
      "grad_norm": 1.2248083353042603,
      "learning_rate": 0.00010539380420258224,
      "loss": 0.5198,
      "step": 686750
    },
    {
      "epoch": 7.270779849778479,
      "grad_norm": 1.1412408351898193,
      "learning_rate": 0.00010535612597514419,
      "loss": 0.5234,
      "step": 686800
    },
    {
      "epoch": 7.271309171558482,
      "grad_norm": 1.3456807136535645,
      "learning_rate": 0.00010531845268579504,
      "loss": 0.529,
      "step": 686850
    },
    {
      "epoch": 7.271838493338485,
      "grad_norm": 1.2860146760940552,
      "learning_rate": 0.00010528078433582077,
      "loss": 0.5296,
      "step": 686900
    },
    {
      "epoch": 7.272367815118488,
      "grad_norm": 1.209364891052246,
      "learning_rate": 0.00010524312092650753,
      "loss": 0.5231,
      "step": 686950
    },
    {
      "epoch": 7.272897136898492,
      "grad_norm": 1.2866710424423218,
      "learning_rate": 0.00010520546245914098,
      "loss": 0.525,
      "step": 687000
    },
    {
      "epoch": 7.272897136898492,
      "eval_loss": 0.3275274336338043,
      "eval_runtime": 49.4672,
      "eval_samples_per_second": 3394.776,
      "eval_steps_per_second": 424.362,
      "step": 687000
    },
    {
      "epoch": 7.273426458678495,
      "grad_norm": 1.370473027229309,
      "learning_rate": 0.00010516780893500694,
      "loss": 0.5209,
      "step": 687050
    },
    {
      "epoch": 7.273955780458499,
      "grad_norm": 1.3700331449508667,
      "learning_rate": 0.00010513016035539066,
      "loss": 0.5324,
      "step": 687100
    },
    {
      "epoch": 7.2744851022385015,
      "grad_norm": 1.328155279159546,
      "learning_rate": 0.00010509251672157769,
      "loss": 0.5264,
      "step": 687150
    },
    {
      "epoch": 7.275014424018505,
      "grad_norm": 1.1919785737991333,
      "learning_rate": 0.00010505487803485294,
      "loss": 0.5262,
      "step": 687200
    },
    {
      "epoch": 7.275543745798508,
      "grad_norm": 1.3285260200500488,
      "learning_rate": 0.00010501724429650164,
      "loss": 0.5276,
      "step": 687250
    },
    {
      "epoch": 7.276073067578512,
      "grad_norm": 1.2704005241394043,
      "learning_rate": 0.00010497961550780832,
      "loss": 0.5271,
      "step": 687300
    },
    {
      "epoch": 7.276602389358515,
      "grad_norm": 1.2113627195358276,
      "learning_rate": 0.00010494199167005784,
      "loss": 0.5304,
      "step": 687350
    },
    {
      "epoch": 7.2771317111385185,
      "grad_norm": 1.177062749862671,
      "learning_rate": 0.00010490437278453447,
      "loss": 0.53,
      "step": 687400
    },
    {
      "epoch": 7.277661032918521,
      "grad_norm": 1.4200689792633057,
      "learning_rate": 0.0001048667588525227,
      "loss": 0.5266,
      "step": 687450
    },
    {
      "epoch": 7.278190354698525,
      "grad_norm": 1.2034010887145996,
      "learning_rate": 0.00010482914987530646,
      "loss": 0.5221,
      "step": 687500
    },
    {
      "epoch": 7.278190354698525,
      "eval_loss": 0.32759514451026917,
      "eval_runtime": 50.7612,
      "eval_samples_per_second": 3308.236,
      "eval_steps_per_second": 413.544,
      "step": 687500
    },
    {
      "epoch": 7.278719676478528,
      "grad_norm": 1.2246501445770264,
      "learning_rate": 0.0001047915458541699,
      "loss": 0.5213,
      "step": 687550
    },
    {
      "epoch": 7.279248998258531,
      "grad_norm": 1.3165055513381958,
      "learning_rate": 0.0001047539467903966,
      "loss": 0.53,
      "step": 687600
    },
    {
      "epoch": 7.279778320038535,
      "grad_norm": 1.409013271331787,
      "learning_rate": 0.00010471635268527041,
      "loss": 0.5179,
      "step": 687650
    },
    {
      "epoch": 7.2803076418185375,
      "grad_norm": 1.268174409866333,
      "learning_rate": 0.00010467951527436287,
      "loss": 0.5263,
      "step": 687700
    },
    {
      "epoch": 7.280836963598541,
      "grad_norm": 1.3915437459945679,
      "learning_rate": 0.00010464193099114388,
      "loss": 0.5352,
      "step": 687750
    },
    {
      "epoch": 7.281366285378544,
      "grad_norm": 1.273240566253662,
      "learning_rate": 0.00010460435167039618,
      "loss": 0.5128,
      "step": 687800
    },
    {
      "epoch": 7.281895607158548,
      "grad_norm": 1.1007088422775269,
      "learning_rate": 0.00010456677731340245,
      "loss": 0.5315,
      "step": 687850
    },
    {
      "epoch": 7.282424928938551,
      "grad_norm": 1.3216652870178223,
      "learning_rate": 0.00010452920792144571,
      "loss": 0.5264,
      "step": 687900
    },
    {
      "epoch": 7.2829542507185545,
      "grad_norm": 1.3104134798049927,
      "learning_rate": 0.0001044916434958084,
      "loss": 0.527,
      "step": 687950
    },
    {
      "epoch": 7.283483572498557,
      "grad_norm": 1.2578091621398926,
      "learning_rate": 0.00010445408403777306,
      "loss": 0.5225,
      "step": 688000
    },
    {
      "epoch": 7.283483572498557,
      "eval_loss": 0.3276965916156769,
      "eval_runtime": 50.1373,
      "eval_samples_per_second": 3349.402,
      "eval_steps_per_second": 418.69,
      "step": 688000
    },
    {
      "epoch": 7.284012894278561,
      "grad_norm": 1.3016241788864136,
      "learning_rate": 0.00010441652954862186,
      "loss": 0.5287,
      "step": 688050
    },
    {
      "epoch": 7.284542216058564,
      "grad_norm": 1.2506217956542969,
      "learning_rate": 0.00010437898002963703,
      "loss": 0.5235,
      "step": 688100
    },
    {
      "epoch": 7.285071537838568,
      "grad_norm": 1.4302014112472534,
      "learning_rate": 0.00010434143548210034,
      "loss": 0.5347,
      "step": 688150
    },
    {
      "epoch": 7.285600859618571,
      "grad_norm": 1.367957592010498,
      "learning_rate": 0.0001043038959072937,
      "loss": 0.532,
      "step": 688200
    },
    {
      "epoch": 7.286130181398574,
      "grad_norm": 1.1846076250076294,
      "learning_rate": 0.00010426636130649852,
      "loss": 0.5308,
      "step": 688250
    },
    {
      "epoch": 7.286659503178577,
      "grad_norm": 1.287201166152954,
      "learning_rate": 0.00010422883168099642,
      "loss": 0.5242,
      "step": 688300
    },
    {
      "epoch": 7.28718882495858,
      "grad_norm": 1.2049964666366577,
      "learning_rate": 0.00010419130703206848,
      "loss": 0.5191,
      "step": 688350
    },
    {
      "epoch": 7.287718146738584,
      "grad_norm": 1.2645037174224854,
      "learning_rate": 0.0001041537873609959,
      "loss": 0.522,
      "step": 688400
    },
    {
      "epoch": 7.288247468518587,
      "grad_norm": 1.2241088151931763,
      "learning_rate": 0.00010411627266905945,
      "loss": 0.5318,
      "step": 688450
    },
    {
      "epoch": 7.2887767902985905,
      "grad_norm": 1.3725749254226685,
      "learning_rate": 0.00010407876295753996,
      "loss": 0.5271,
      "step": 688500
    },
    {
      "epoch": 7.2887767902985905,
      "eval_loss": 0.3275492191314697,
      "eval_runtime": 49.919,
      "eval_samples_per_second": 3364.05,
      "eval_steps_per_second": 420.521,
      "step": 688500
    },
    {
      "epoch": 7.289306112078593,
      "grad_norm": 1.2765077352523804,
      "learning_rate": 0.00010404125822771806,
      "loss": 0.5265,
      "step": 688550
    },
    {
      "epoch": 7.289835433858597,
      "grad_norm": 1.2667248249053955,
      "learning_rate": 0.00010400375848087399,
      "loss": 0.5321,
      "step": 688600
    },
    {
      "epoch": 7.2903647556386,
      "grad_norm": 1.245772361755371,
      "learning_rate": 0.00010396626371828816,
      "loss": 0.5351,
      "step": 688650
    },
    {
      "epoch": 7.290894077418604,
      "grad_norm": 1.3105069398880005,
      "learning_rate": 0.00010392877394124045,
      "loss": 0.5241,
      "step": 688700
    },
    {
      "epoch": 7.291423399198607,
      "grad_norm": 1.1676008701324463,
      "learning_rate": 0.00010389128915101082,
      "loss": 0.5208,
      "step": 688750
    },
    {
      "epoch": 7.29195272097861,
      "grad_norm": 1.2721997499465942,
      "learning_rate": 0.00010385380934887906,
      "loss": 0.5264,
      "step": 688800
    },
    {
      "epoch": 7.292482042758613,
      "grad_norm": 1.426203966140747,
      "learning_rate": 0.0001038163345361246,
      "loss": 0.5193,
      "step": 688850
    },
    {
      "epoch": 7.293011364538617,
      "grad_norm": 1.3227533102035522,
      "learning_rate": 0.00010377886471402693,
      "loss": 0.5318,
      "step": 688900
    },
    {
      "epoch": 7.29354068631862,
      "grad_norm": 1.257650375366211,
      "learning_rate": 0.00010374139988386511,
      "loss": 0.5256,
      "step": 688950
    },
    {
      "epoch": 7.294070008098624,
      "grad_norm": 1.1974846124649048,
      "learning_rate": 0.00010370468919471553,
      "loss": 0.5242,
      "step": 689000
    },
    {
      "epoch": 7.294070008098624,
      "eval_loss": 0.327316015958786,
      "eval_runtime": 48.2209,
      "eval_samples_per_second": 3482.513,
      "eval_steps_per_second": 435.33,
      "step": 689000
    },
    {
      "epoch": 7.2945993298786265,
      "grad_norm": 1.35935378074646,
      "learning_rate": 0.00010366723425236013,
      "loss": 0.5265,
      "step": 689050
    },
    {
      "epoch": 7.295128651658629,
      "grad_norm": 1.2186696529388428,
      "learning_rate": 0.00010362978430575164,
      "loss": 0.526,
      "step": 689100
    },
    {
      "epoch": 7.295657973438633,
      "grad_norm": 1.3361760377883911,
      "learning_rate": 0.00010359233935616877,
      "loss": 0.5366,
      "step": 689150
    },
    {
      "epoch": 7.296187295218636,
      "grad_norm": 1.2265033721923828,
      "learning_rate": 0.00010355489940488963,
      "loss": 0.5331,
      "step": 689200
    },
    {
      "epoch": 7.29671661699864,
      "grad_norm": 1.3672842979431152,
      "learning_rate": 0.0001035174644531926,
      "loss": 0.5226,
      "step": 689250
    },
    {
      "epoch": 7.297245938778643,
      "grad_norm": 1.3207166194915771,
      "learning_rate": 0.00010348003450235554,
      "loss": 0.5112,
      "step": 689300
    },
    {
      "epoch": 7.297775260558646,
      "grad_norm": 1.3483880758285522,
      "learning_rate": 0.00010344260955365644,
      "loss": 0.5188,
      "step": 689350
    },
    {
      "epoch": 7.298304582338649,
      "grad_norm": 1.3517649173736572,
      "learning_rate": 0.0001034051896083728,
      "loss": 0.5293,
      "step": 689400
    },
    {
      "epoch": 7.298833904118653,
      "grad_norm": 1.2390326261520386,
      "learning_rate": 0.00010336777466778236,
      "loss": 0.5225,
      "step": 689450
    },
    {
      "epoch": 7.299363225898656,
      "grad_norm": 1.4020817279815674,
      "learning_rate": 0.00010333036473316219,
      "loss": 0.5326,
      "step": 689500
    },
    {
      "epoch": 7.299363225898656,
      "eval_loss": 0.32722893357276917,
      "eval_runtime": 48.9561,
      "eval_samples_per_second": 3430.216,
      "eval_steps_per_second": 428.792,
      "step": 689500
    },
    {
      "epoch": 7.29989254767866,
      "grad_norm": 1.2446855306625366,
      "learning_rate": 0.00010329295980578968,
      "loss": 0.5149,
      "step": 689550
    },
    {
      "epoch": 7.3004218694586624,
      "grad_norm": 1.1896271705627441,
      "learning_rate": 0.00010325555988694163,
      "loss": 0.5203,
      "step": 689600
    },
    {
      "epoch": 7.300951191238666,
      "grad_norm": 1.4157181978225708,
      "learning_rate": 0.00010321816497789505,
      "loss": 0.5265,
      "step": 689650
    },
    {
      "epoch": 7.301480513018669,
      "grad_norm": 1.3616974353790283,
      "learning_rate": 0.00010318077507992637,
      "loss": 0.5229,
      "step": 689700
    },
    {
      "epoch": 7.302009834798673,
      "grad_norm": 1.3154293298721313,
      "learning_rate": 0.0001031433901943123,
      "loss": 0.5273,
      "step": 689750
    },
    {
      "epoch": 7.302539156578676,
      "grad_norm": 1.2129995822906494,
      "learning_rate": 0.00010310601032232891,
      "loss": 0.5255,
      "step": 689800
    },
    {
      "epoch": 7.303068478358679,
      "grad_norm": 1.3623833656311035,
      "learning_rate": 0.00010306863546525256,
      "loss": 0.5278,
      "step": 689850
    },
    {
      "epoch": 7.303597800138682,
      "grad_norm": 1.3146034479141235,
      "learning_rate": 0.00010303126562435903,
      "loss": 0.5389,
      "step": 689900
    },
    {
      "epoch": 7.304127121918685,
      "grad_norm": 1.1955952644348145,
      "learning_rate": 0.00010299390080092427,
      "loss": 0.5319,
      "step": 689950
    },
    {
      "epoch": 7.304656443698689,
      "grad_norm": 1.2876245975494385,
      "learning_rate": 0.00010295654099622375,
      "loss": 0.5292,
      "step": 690000
    },
    {
      "epoch": 7.304656443698689,
      "eval_loss": 0.32745519280433655,
      "eval_runtime": 48.8284,
      "eval_samples_per_second": 3439.184,
      "eval_steps_per_second": 429.913,
      "step": 690000
    },
    {
      "epoch": 7.305185765478692,
      "grad_norm": 1.438922643661499,
      "learning_rate": 0.00010291918621153307,
      "loss": 0.5195,
      "step": 690050
    },
    {
      "epoch": 7.305715087258696,
      "grad_norm": 1.3881282806396484,
      "learning_rate": 0.00010288183644812735,
      "loss": 0.5325,
      "step": 690100
    },
    {
      "epoch": 7.306244409038698,
      "grad_norm": 1.2273991107940674,
      "learning_rate": 0.00010284449170728186,
      "loss": 0.5234,
      "step": 690150
    },
    {
      "epoch": 7.306773730818702,
      "grad_norm": 1.2474385499954224,
      "learning_rate": 0.00010280715199027138,
      "loss": 0.5381,
      "step": 690200
    },
    {
      "epoch": 7.307303052598705,
      "grad_norm": 1.2439464330673218,
      "learning_rate": 0.00010276981729837082,
      "loss": 0.5226,
      "step": 690250
    },
    {
      "epoch": 7.307832374378709,
      "grad_norm": 1.3574503660202026,
      "learning_rate": 0.00010273248763285462,
      "loss": 0.5268,
      "step": 690300
    },
    {
      "epoch": 7.308361696158712,
      "grad_norm": 1.258994221687317,
      "learning_rate": 0.00010269516299499737,
      "loss": 0.5261,
      "step": 690350
    },
    {
      "epoch": 7.308891017938715,
      "grad_norm": 1.2621021270751953,
      "learning_rate": 0.00010265784338607314,
      "loss": 0.5257,
      "step": 690400
    },
    {
      "epoch": 7.309420339718718,
      "grad_norm": 1.410056471824646,
      "learning_rate": 0.0001026205288073562,
      "loss": 0.5245,
      "step": 690450
    },
    {
      "epoch": 7.309949661498722,
      "grad_norm": 1.4108757972717285,
      "learning_rate": 0.00010258321926012029,
      "loss": 0.5256,
      "step": 690500
    },
    {
      "epoch": 7.309949661498722,
      "eval_loss": 0.3268919587135315,
      "eval_runtime": 48.6354,
      "eval_samples_per_second": 3452.833,
      "eval_steps_per_second": 431.62,
      "step": 690500
    },
    {
      "epoch": 7.310478983278725,
      "grad_norm": 1.171469807624817,
      "learning_rate": 0.00010254591474563926,
      "loss": 0.524,
      "step": 690550
    },
    {
      "epoch": 7.311008305058728,
      "grad_norm": 1.355102777481079,
      "learning_rate": 0.00010250861526518657,
      "loss": 0.5295,
      "step": 690600
    },
    {
      "epoch": 7.3115376268387315,
      "grad_norm": 1.2901105880737305,
      "learning_rate": 0.00010247132082003563,
      "loss": 0.5374,
      "step": 690650
    },
    {
      "epoch": 7.312066948618734,
      "grad_norm": 1.2916524410247803,
      "learning_rate": 0.0001024340314114598,
      "loss": 0.5233,
      "step": 690700
    },
    {
      "epoch": 7.312596270398738,
      "grad_norm": 1.2880232334136963,
      "learning_rate": 0.00010239674704073193,
      "loss": 0.5268,
      "step": 690750
    },
    {
      "epoch": 7.313125592178741,
      "grad_norm": 1.3098143339157104,
      "learning_rate": 0.00010235946770912497,
      "loss": 0.5261,
      "step": 690800
    },
    {
      "epoch": 7.313654913958745,
      "grad_norm": 1.3638776540756226,
      "learning_rate": 0.00010232219341791175,
      "loss": 0.5255,
      "step": 690850
    },
    {
      "epoch": 7.314184235738748,
      "grad_norm": 1.282158374786377,
      "learning_rate": 0.00010228492416836457,
      "loss": 0.5294,
      "step": 690900
    },
    {
      "epoch": 7.314713557518751,
      "grad_norm": 1.3104029893875122,
      "learning_rate": 0.000102247659961756,
      "loss": 0.5294,
      "step": 690950
    },
    {
      "epoch": 7.315242879298754,
      "grad_norm": 1.2523919343948364,
      "learning_rate": 0.00010221040079935806,
      "loss": 0.5294,
      "step": 691000
    },
    {
      "epoch": 7.315242879298754,
      "eval_loss": 0.3267279863357544,
      "eval_runtime": 48.0596,
      "eval_samples_per_second": 3494.201,
      "eval_steps_per_second": 436.791,
      "step": 691000
    },
    {
      "epoch": 7.315772201078758,
      "grad_norm": 1.260288953781128,
      "learning_rate": 0.00010217314668244292,
      "loss": 0.5356,
      "step": 691050
    },
    {
      "epoch": 7.316301522858761,
      "grad_norm": 1.3362001180648804,
      "learning_rate": 0.00010213589761228226,
      "loss": 0.5256,
      "step": 691100
    },
    {
      "epoch": 7.316830844638765,
      "grad_norm": 1.5034700632095337,
      "learning_rate": 0.00010209865359014789,
      "loss": 0.528,
      "step": 691150
    },
    {
      "epoch": 7.3173601664187675,
      "grad_norm": 1.288078784942627,
      "learning_rate": 0.00010206141461731117,
      "loss": 0.5297,
      "step": 691200
    },
    {
      "epoch": 7.317889488198771,
      "grad_norm": 1.342181921005249,
      "learning_rate": 0.0001020241806950436,
      "loss": 0.5179,
      "step": 691250
    },
    {
      "epoch": 7.318418809978774,
      "grad_norm": 1.34807550907135,
      "learning_rate": 0.00010198695182461612,
      "loss": 0.5242,
      "step": 691300
    },
    {
      "epoch": 7.318948131758777,
      "grad_norm": 1.3007869720458984,
      "learning_rate": 0.00010194972800729993,
      "loss": 0.5256,
      "step": 691350
    },
    {
      "epoch": 7.319477453538781,
      "grad_norm": 1.1142315864562988,
      "learning_rate": 0.00010191250924436565,
      "loss": 0.5272,
      "step": 691400
    },
    {
      "epoch": 7.320006775318784,
      "grad_norm": 1.3302630186080933,
      "learning_rate": 0.00010187529553708405,
      "loss": 0.522,
      "step": 691450
    },
    {
      "epoch": 7.320536097098787,
      "grad_norm": 1.313865303993225,
      "learning_rate": 0.00010183808688672547,
      "loss": 0.523,
      "step": 691500
    },
    {
      "epoch": 7.320536097098787,
      "eval_loss": 0.3266114294528961,
      "eval_runtime": 47.6319,
      "eval_samples_per_second": 3525.578,
      "eval_steps_per_second": 440.713,
      "step": 691500
    },
    {
      "epoch": 7.32106541887879,
      "grad_norm": 1.2088563442230225,
      "learning_rate": 0.00010180088329456036,
      "loss": 0.5174,
      "step": 691550
    },
    {
      "epoch": 7.321594740658794,
      "grad_norm": 1.2890907526016235,
      "learning_rate": 0.00010176368476185866,
      "loss": 0.5233,
      "step": 691600
    },
    {
      "epoch": 7.322124062438797,
      "grad_norm": 1.350677728652954,
      "learning_rate": 0.00010172649128989048,
      "loss": 0.5208,
      "step": 691650
    },
    {
      "epoch": 7.322653384218801,
      "grad_norm": 1.420876145362854,
      "learning_rate": 0.0001016893028799254,
      "loss": 0.5271,
      "step": 691700
    },
    {
      "epoch": 7.3231827059988035,
      "grad_norm": 1.2703601121902466,
      "learning_rate": 0.00010165211953323323,
      "loss": 0.5212,
      "step": 691750
    },
    {
      "epoch": 7.323712027778807,
      "grad_norm": 1.296585202217102,
      "learning_rate": 0.00010161494125108323,
      "loss": 0.5253,
      "step": 691800
    },
    {
      "epoch": 7.32424134955881,
      "grad_norm": 1.2572051286697388,
      "learning_rate": 0.00010157776803474478,
      "loss": 0.519,
      "step": 691850
    },
    {
      "epoch": 7.324770671338814,
      "grad_norm": 1.4055225849151611,
      "learning_rate": 0.0001015405998854868,
      "loss": 0.5211,
      "step": 691900
    },
    {
      "epoch": 7.325299993118817,
      "grad_norm": 1.333789348602295,
      "learning_rate": 0.00010150343680457841,
      "loss": 0.5222,
      "step": 691950
    },
    {
      "epoch": 7.3258293148988205,
      "grad_norm": 1.1673303842544556,
      "learning_rate": 0.00010146627879328809,
      "loss": 0.5172,
      "step": 692000
    },
    {
      "epoch": 7.3258293148988205,
      "eval_loss": 0.3263924717903137,
      "eval_runtime": 49.1013,
      "eval_samples_per_second": 3420.071,
      "eval_steps_per_second": 427.524,
      "step": 692000
    },
    {
      "epoch": 7.326358636678823,
      "grad_norm": 1.2563341856002808,
      "learning_rate": 0.0001014291258528847,
      "loss": 0.5307,
      "step": 692050
    },
    {
      "epoch": 7.326887958458827,
      "grad_norm": 1.3451493978500366,
      "learning_rate": 0.00010139197798463631,
      "loss": 0.5269,
      "step": 692100
    },
    {
      "epoch": 7.32741728023883,
      "grad_norm": 1.3007224798202515,
      "learning_rate": 0.00010135483518981143,
      "loss": 0.5227,
      "step": 692150
    },
    {
      "epoch": 7.327946602018833,
      "grad_norm": 1.3591893911361694,
      "learning_rate": 0.00010131769746967784,
      "loss": 0.5248,
      "step": 692200
    },
    {
      "epoch": 7.328475923798837,
      "grad_norm": 1.2749052047729492,
      "learning_rate": 0.00010128056482550354,
      "loss": 0.5222,
      "step": 692250
    },
    {
      "epoch": 7.3290052455788395,
      "grad_norm": 1.4511873722076416,
      "learning_rate": 0.00010124343725855631,
      "loss": 0.5348,
      "step": 692300
    },
    {
      "epoch": 7.329534567358843,
      "grad_norm": 1.3318686485290527,
      "learning_rate": 0.0001012063147701035,
      "loss": 0.5257,
      "step": 692350
    },
    {
      "epoch": 7.330063889138846,
      "grad_norm": 1.2806148529052734,
      "learning_rate": 0.0001011691973614125,
      "loss": 0.5239,
      "step": 692400
    },
    {
      "epoch": 7.33059321091885,
      "grad_norm": 1.3734217882156372,
      "learning_rate": 0.00010113208503375065,
      "loss": 0.5268,
      "step": 692450
    },
    {
      "epoch": 7.331122532698853,
      "grad_norm": 1.3915568590164185,
      "learning_rate": 0.00010109497778838473,
      "loss": 0.5284,
      "step": 692500
    },
    {
      "epoch": 7.331122532698853,
      "eval_loss": 0.3255678415298462,
      "eval_runtime": 48.6067,
      "eval_samples_per_second": 3454.874,
      "eval_steps_per_second": 431.875,
      "step": 692500
    },
    {
      "epoch": 7.3316518544788565,
      "grad_norm": 1.1767443418502808,
      "learning_rate": 0.00010105787562658169,
      "loss": 0.5251,
      "step": 692550
    },
    {
      "epoch": 7.332181176258859,
      "grad_norm": 1.109899878501892,
      "learning_rate": 0.00010102077854960812,
      "loss": 0.5134,
      "step": 692600
    },
    {
      "epoch": 7.332710498038863,
      "grad_norm": 1.2100532054901123,
      "learning_rate": 0.00010098368655873061,
      "loss": 0.5207,
      "step": 692650
    },
    {
      "epoch": 7.333239819818866,
      "grad_norm": 1.3647617101669312,
      "learning_rate": 0.0001009465996552153,
      "loss": 0.521,
      "step": 692700
    },
    {
      "epoch": 7.33376914159887,
      "grad_norm": 1.35537588596344,
      "learning_rate": 0.00010090951784032851,
      "loss": 0.5243,
      "step": 692750
    },
    {
      "epoch": 7.334298463378873,
      "grad_norm": 1.2925755977630615,
      "learning_rate": 0.000100872441115336,
      "loss": 0.5335,
      "step": 692800
    },
    {
      "epoch": 7.334827785158876,
      "grad_norm": 1.2799595594406128,
      "learning_rate": 0.00010083536948150376,
      "loss": 0.5125,
      "step": 692850
    },
    {
      "epoch": 7.335357106938879,
      "grad_norm": 1.245385766029358,
      "learning_rate": 0.00010079830294009721,
      "loss": 0.5212,
      "step": 692900
    },
    {
      "epoch": 7.335886428718882,
      "grad_norm": 1.3594679832458496,
      "learning_rate": 0.00010076124149238197,
      "loss": 0.5256,
      "step": 692950
    },
    {
      "epoch": 7.336415750498886,
      "grad_norm": 1.526843786239624,
      "learning_rate": 0.00010072492621673949,
      "loss": 0.529,
      "step": 693000
    },
    {
      "epoch": 7.336415750498886,
      "eval_loss": 0.3258272707462311,
      "eval_runtime": 48.9687,
      "eval_samples_per_second": 3429.333,
      "eval_steps_per_second": 428.682,
      "step": 693000
    },
    {
      "epoch": 7.336945072278889,
      "grad_norm": 1.2568076848983765,
      "learning_rate": 0.00010068787485826547,
      "loss": 0.5242,
      "step": 693050
    },
    {
      "epoch": 7.3374743940588925,
      "grad_norm": 1.2716630697250366,
      "learning_rate": 0.00010065082859725256,
      "loss": 0.5252,
      "step": 693100
    },
    {
      "epoch": 7.338003715838895,
      "grad_norm": 1.4629849195480347,
      "learning_rate": 0.00010061378743496566,
      "loss": 0.5286,
      "step": 693150
    },
    {
      "epoch": 7.338533037618899,
      "grad_norm": 1.2399356365203857,
      "learning_rate": 0.00010057675137266922,
      "loss": 0.53,
      "step": 693200
    },
    {
      "epoch": 7.339062359398902,
      "grad_norm": 1.1902645826339722,
      "learning_rate": 0.00010053972041162777,
      "loss": 0.5272,
      "step": 693250
    },
    {
      "epoch": 7.339591681178906,
      "grad_norm": 1.3289085626602173,
      "learning_rate": 0.00010050269455310534,
      "loss": 0.5287,
      "step": 693300
    },
    {
      "epoch": 7.340121002958909,
      "grad_norm": 1.3419084548950195,
      "learning_rate": 0.00010046567379836619,
      "loss": 0.5176,
      "step": 693350
    },
    {
      "epoch": 7.340650324738912,
      "grad_norm": 1.2815818786621094,
      "learning_rate": 0.000100428658148674,
      "loss": 0.5168,
      "step": 693400
    },
    {
      "epoch": 7.341179646518915,
      "grad_norm": 1.2564964294433594,
      "learning_rate": 0.00010039164760529268,
      "loss": 0.5262,
      "step": 693450
    },
    {
      "epoch": 7.341708968298919,
      "grad_norm": 1.2227321863174438,
      "learning_rate": 0.00010035464216948554,
      "loss": 0.5182,
      "step": 693500
    },
    {
      "epoch": 7.341708968298919,
      "eval_loss": 0.32537028193473816,
      "eval_runtime": 48.7464,
      "eval_samples_per_second": 3444.974,
      "eval_steps_per_second": 430.637,
      "step": 693500
    },
    {
      "epoch": 7.342238290078922,
      "grad_norm": 1.2361598014831543,
      "learning_rate": 0.00010031764184251613,
      "loss": 0.513,
      "step": 693550
    },
    {
      "epoch": 7.342767611858926,
      "grad_norm": 1.2604814767837524,
      "learning_rate": 0.00010028064662564743,
      "loss": 0.5161,
      "step": 693600
    },
    {
      "epoch": 7.343296933638928,
      "grad_norm": 1.2132278680801392,
      "learning_rate": 0.00010024365652014263,
      "loss": 0.5343,
      "step": 693650
    },
    {
      "epoch": 7.343826255418932,
      "grad_norm": 1.269043207168579,
      "learning_rate": 0.0001002066715272644,
      "loss": 0.5278,
      "step": 693700
    },
    {
      "epoch": 7.344355577198935,
      "grad_norm": 1.31705641746521,
      "learning_rate": 0.00010016969164827558,
      "loss": 0.5256,
      "step": 693750
    },
    {
      "epoch": 7.344884898978938,
      "grad_norm": 1.2442477941513062,
      "learning_rate": 0.00010013271688443842,
      "loss": 0.524,
      "step": 693800
    },
    {
      "epoch": 7.345414220758942,
      "grad_norm": 1.4054045677185059,
      "learning_rate": 0.00010009574723701542,
      "loss": 0.531,
      "step": 693850
    },
    {
      "epoch": 7.3459435425389445,
      "grad_norm": 1.3922386169433594,
      "learning_rate": 0.00010005878270726857,
      "loss": 0.5166,
      "step": 693900
    },
    {
      "epoch": 7.346472864318948,
      "grad_norm": 1.298771619796753,
      "learning_rate": 0.00010002182329645997,
      "loss": 0.5272,
      "step": 693950
    },
    {
      "epoch": 7.347002186098951,
      "grad_norm": 1.2335411310195923,
      "learning_rate": 9.998486900585124e-05,
      "loss": 0.5326,
      "step": 694000
    },
    {
      "epoch": 7.347002186098951,
      "eval_loss": 0.32588979601860046,
      "eval_runtime": 46.8001,
      "eval_samples_per_second": 3588.239,
      "eval_steps_per_second": 448.546,
      "step": 694000
    },
    {
      "epoch": 7.347531507878955,
      "grad_norm": 1.0779063701629639,
      "learning_rate": 9.994791983670414e-05,
      "loss": 0.5239,
      "step": 694050
    },
    {
      "epoch": 7.348060829658958,
      "grad_norm": 1.249083161354065,
      "learning_rate": 9.991097579027997e-05,
      "loss": 0.5301,
      "step": 694100
    },
    {
      "epoch": 7.3485901514389615,
      "grad_norm": 1.417214274406433,
      "learning_rate": 9.987403686784008e-05,
      "loss": 0.5273,
      "step": 694150
    },
    {
      "epoch": 7.349119473218964,
      "grad_norm": 1.363621711730957,
      "learning_rate": 9.983710307064547e-05,
      "loss": 0.5264,
      "step": 694200
    },
    {
      "epoch": 7.349648794998968,
      "grad_norm": 1.2399433851242065,
      "learning_rate": 9.980017439995715e-05,
      "loss": 0.5215,
      "step": 694250
    },
    {
      "epoch": 7.350178116778971,
      "grad_norm": 1.1727423667907715,
      "learning_rate": 9.976325085703572e-05,
      "loss": 0.5316,
      "step": 694300
    },
    {
      "epoch": 7.350707438558975,
      "grad_norm": 1.276315689086914,
      "learning_rate": 9.972633244314189e-05,
      "loss": 0.5206,
      "step": 694350
    },
    {
      "epoch": 7.351236760338978,
      "grad_norm": 1.2572336196899414,
      "learning_rate": 9.968941915953586e-05,
      "loss": 0.5209,
      "step": 694400
    },
    {
      "epoch": 7.351766082118981,
      "grad_norm": 1.3127387762069702,
      "learning_rate": 9.965251100747805e-05,
      "loss": 0.5246,
      "step": 694450
    },
    {
      "epoch": 7.352295403898984,
      "grad_norm": 1.1881933212280273,
      "learning_rate": 9.961560798822827e-05,
      "loss": 0.5245,
      "step": 694500
    },
    {
      "epoch": 7.352295403898984,
      "eval_loss": 0.32593342661857605,
      "eval_runtime": 46.867,
      "eval_samples_per_second": 3583.117,
      "eval_steps_per_second": 447.906,
      "step": 694500
    },
    {
      "epoch": 7.352824725678987,
      "grad_norm": 1.3610187768936157,
      "learning_rate": 9.957871010304647e-05,
      "loss": 0.5369,
      "step": 694550
    },
    {
      "epoch": 7.353354047458991,
      "grad_norm": 1.4198236465454102,
      "learning_rate": 9.954181735319245e-05,
      "loss": 0.5294,
      "step": 694600
    },
    {
      "epoch": 7.353883369238994,
      "grad_norm": 1.4348968267440796,
      "learning_rate": 9.950492973992553e-05,
      "loss": 0.5314,
      "step": 694650
    },
    {
      "epoch": 7.3544126910189975,
      "grad_norm": 1.3336281776428223,
      "learning_rate": 9.946804726450508e-05,
      "loss": 0.5273,
      "step": 694700
    },
    {
      "epoch": 7.354942012799,
      "grad_norm": 1.1956815719604492,
      "learning_rate": 9.943190742454535e-05,
      "loss": 0.5248,
      "step": 694750
    },
    {
      "epoch": 7.355471334579004,
      "grad_norm": 1.2321943044662476,
      "learning_rate": 9.93950351257757e-05,
      "loss": 0.519,
      "step": 694800
    },
    {
      "epoch": 7.356000656359007,
      "grad_norm": 1.1729834079742432,
      "learning_rate": 9.93581679686042e-05,
      "loss": 0.5244,
      "step": 694850
    },
    {
      "epoch": 7.356529978139011,
      "grad_norm": 1.1556679010391235,
      "learning_rate": 9.932130595428959e-05,
      "loss": 0.5302,
      "step": 694900
    },
    {
      "epoch": 7.357059299919014,
      "grad_norm": 1.2201215028762817,
      "learning_rate": 9.928444908409045e-05,
      "loss": 0.5339,
      "step": 694950
    },
    {
      "epoch": 7.357588621699017,
      "grad_norm": 1.3554006814956665,
      "learning_rate": 9.924759735926483e-05,
      "loss": 0.5247,
      "step": 695000
    },
    {
      "epoch": 7.357588621699017,
      "eval_loss": 0.32594987750053406,
      "eval_runtime": 46.773,
      "eval_samples_per_second": 3590.32,
      "eval_steps_per_second": 448.806,
      "step": 695000
    },
    {
      "epoch": 7.35811794347902,
      "grad_norm": 1.2531623840332031,
      "learning_rate": 9.921075078107097e-05,
      "loss": 0.5299,
      "step": 695050
    },
    {
      "epoch": 7.358647265259024,
      "grad_norm": 1.2542860507965088,
      "learning_rate": 9.917390935076687e-05,
      "loss": 0.5239,
      "step": 695100
    },
    {
      "epoch": 7.359176587039027,
      "grad_norm": 1.2827130556106567,
      "learning_rate": 9.913707306961009e-05,
      "loss": 0.5241,
      "step": 695150
    },
    {
      "epoch": 7.359705908819031,
      "grad_norm": 1.3114019632339478,
      "learning_rate": 9.910024193885839e-05,
      "loss": 0.5258,
      "step": 695200
    },
    {
      "epoch": 7.3602352305990335,
      "grad_norm": 1.2729082107543945,
      "learning_rate": 9.9063415959769e-05,
      "loss": 0.5313,
      "step": 695250
    },
    {
      "epoch": 7.360764552379036,
      "grad_norm": 1.1517771482467651,
      "learning_rate": 9.902659513359935e-05,
      "loss": 0.5295,
      "step": 695300
    },
    {
      "epoch": 7.36129387415904,
      "grad_norm": 1.2490763664245605,
      "learning_rate": 9.898977946160629e-05,
      "loss": 0.5292,
      "step": 695350
    },
    {
      "epoch": 7.361823195939043,
      "grad_norm": 1.1976398229599,
      "learning_rate": 9.895296894504682e-05,
      "loss": 0.5191,
      "step": 695400
    },
    {
      "epoch": 7.362352517719047,
      "grad_norm": 1.153384804725647,
      "learning_rate": 9.891616358517755e-05,
      "loss": 0.513,
      "step": 695450
    },
    {
      "epoch": 7.36288183949905,
      "grad_norm": 1.3186419010162354,
      "learning_rate": 9.88793633832551e-05,
      "loss": 0.5288,
      "step": 695500
    },
    {
      "epoch": 7.36288183949905,
      "eval_loss": 0.32531920075416565,
      "eval_runtime": 47.4973,
      "eval_samples_per_second": 3535.571,
      "eval_steps_per_second": 441.962,
      "step": 695500
    },
    {
      "epoch": 7.363411161279053,
      "grad_norm": 1.3011199235916138,
      "learning_rate": 9.88425683405357e-05,
      "loss": 0.5276,
      "step": 695550
    },
    {
      "epoch": 7.363940483059056,
      "grad_norm": 1.2231826782226562,
      "learning_rate": 9.880577845827565e-05,
      "loss": 0.5339,
      "step": 695600
    },
    {
      "epoch": 7.36446980483906,
      "grad_norm": 1.378874659538269,
      "learning_rate": 9.876899373773079e-05,
      "loss": 0.5235,
      "step": 695650
    },
    {
      "epoch": 7.364999126619063,
      "grad_norm": 1.3018897771835327,
      "learning_rate": 9.873221418015712e-05,
      "loss": 0.513,
      "step": 695700
    },
    {
      "epoch": 7.365528448399067,
      "grad_norm": 1.234494686126709,
      "learning_rate": 9.869543978681012e-05,
      "loss": 0.5314,
      "step": 695750
    },
    {
      "epoch": 7.3660577701790695,
      "grad_norm": 1.3138478994369507,
      "learning_rate": 9.865867055894537e-05,
      "loss": 0.5238,
      "step": 695800
    },
    {
      "epoch": 7.366587091959073,
      "grad_norm": 1.3545171022415161,
      "learning_rate": 9.862190649781802e-05,
      "loss": 0.5198,
      "step": 695850
    },
    {
      "epoch": 7.367116413739076,
      "grad_norm": 1.410683035850525,
      "learning_rate": 9.858514760468335e-05,
      "loss": 0.5252,
      "step": 695900
    },
    {
      "epoch": 7.36764573551908,
      "grad_norm": 1.327898621559143,
      "learning_rate": 9.854839388079612e-05,
      "loss": 0.5149,
      "step": 695950
    },
    {
      "epoch": 7.368175057299083,
      "grad_norm": 1.2125136852264404,
      "learning_rate": 9.851164532741128e-05,
      "loss": 0.5264,
      "step": 696000
    },
    {
      "epoch": 7.368175057299083,
      "eval_loss": 0.3253999650478363,
      "eval_runtime": 47.5406,
      "eval_samples_per_second": 3532.352,
      "eval_steps_per_second": 441.56,
      "step": 696000
    },
    {
      "epoch": 7.368704379079086,
      "grad_norm": 1.2837073802947998,
      "learning_rate": 9.847490194578323e-05,
      "loss": 0.5183,
      "step": 696050
    },
    {
      "epoch": 7.369233700859089,
      "grad_norm": 1.3351987600326538,
      "learning_rate": 9.843816373716652e-05,
      "loss": 0.5192,
      "step": 696100
    },
    {
      "epoch": 7.369763022639092,
      "grad_norm": 1.3935061693191528,
      "learning_rate": 9.840143070281526e-05,
      "loss": 0.5282,
      "step": 696150
    },
    {
      "epoch": 7.370292344419096,
      "grad_norm": 1.3773417472839355,
      "learning_rate": 9.836470284398364e-05,
      "loss": 0.5286,
      "step": 696200
    },
    {
      "epoch": 7.370821666199099,
      "grad_norm": 1.3662196397781372,
      "learning_rate": 9.832798016192535e-05,
      "loss": 0.524,
      "step": 696250
    },
    {
      "epoch": 7.371350987979103,
      "grad_norm": 1.2796438932418823,
      "learning_rate": 9.829126265789429e-05,
      "loss": 0.5237,
      "step": 696300
    },
    {
      "epoch": 7.3718803097591055,
      "grad_norm": 1.4304139614105225,
      "learning_rate": 9.825455033314379e-05,
      "loss": 0.5152,
      "step": 696350
    },
    {
      "epoch": 7.372409631539109,
      "grad_norm": 1.2871392965316772,
      "learning_rate": 9.821784318892737e-05,
      "loss": 0.5233,
      "step": 696400
    },
    {
      "epoch": 7.372938953319112,
      "grad_norm": 1.3036357164382935,
      "learning_rate": 9.818114122649804e-05,
      "loss": 0.5196,
      "step": 696450
    },
    {
      "epoch": 7.373468275099116,
      "grad_norm": 1.2128493785858154,
      "learning_rate": 9.814444444710899e-05,
      "loss": 0.5307,
      "step": 696500
    },
    {
      "epoch": 7.373468275099116,
      "eval_loss": 0.3255697190761566,
      "eval_runtime": 48.5818,
      "eval_samples_per_second": 3456.643,
      "eval_steps_per_second": 432.096,
      "step": 696500
    },
    {
      "epoch": 7.373997596879119,
      "grad_norm": 1.2656598091125488,
      "learning_rate": 9.810775285201279e-05,
      "loss": 0.5273,
      "step": 696550
    },
    {
      "epoch": 7.3745269186591225,
      "grad_norm": 1.3417450189590454,
      "learning_rate": 9.807106644246223e-05,
      "loss": 0.5274,
      "step": 696600
    },
    {
      "epoch": 7.375056240439125,
      "grad_norm": 1.3680113554000854,
      "learning_rate": 9.803438521970979e-05,
      "loss": 0.524,
      "step": 696650
    },
    {
      "epoch": 7.375585562219129,
      "grad_norm": 1.210966944694519,
      "learning_rate": 9.799770918500764e-05,
      "loss": 0.5242,
      "step": 696700
    },
    {
      "epoch": 7.376114883999132,
      "grad_norm": 1.288807988166809,
      "learning_rate": 9.796103833960796e-05,
      "loss": 0.519,
      "step": 696750
    },
    {
      "epoch": 7.376644205779135,
      "grad_norm": 1.2789667844772339,
      "learning_rate": 9.792437268476276e-05,
      "loss": 0.5306,
      "step": 696800
    },
    {
      "epoch": 7.377173527559139,
      "grad_norm": 1.2880185842514038,
      "learning_rate": 9.788771222172361e-05,
      "loss": 0.5236,
      "step": 696850
    },
    {
      "epoch": 7.3777028493391414,
      "grad_norm": 1.3860092163085938,
      "learning_rate": 9.785105695174227e-05,
      "loss": 0.5225,
      "step": 696900
    },
    {
      "epoch": 7.378232171119145,
      "grad_norm": 1.2784498929977417,
      "learning_rate": 9.781440687606995e-05,
      "loss": 0.5275,
      "step": 696950
    },
    {
      "epoch": 7.378761492899148,
      "grad_norm": 1.23721182346344,
      "learning_rate": 9.777776199595808e-05,
      "loss": 0.5174,
      "step": 697000
    },
    {
      "epoch": 7.378761492899148,
      "eval_loss": 0.32488614320755005,
      "eval_runtime": 48.22,
      "eval_samples_per_second": 3482.581,
      "eval_steps_per_second": 435.338,
      "step": 697000
    },
    {
      "epoch": 7.379290814679152,
      "grad_norm": 1.226763367652893,
      "learning_rate": 9.774112231265748e-05,
      "loss": 0.5246,
      "step": 697050
    },
    {
      "epoch": 7.379820136459155,
      "grad_norm": 1.3491238355636597,
      "learning_rate": 9.770448782741922e-05,
      "loss": 0.5172,
      "step": 697100
    },
    {
      "epoch": 7.3803494582391584,
      "grad_norm": 1.370448350906372,
      "learning_rate": 9.76678585414938e-05,
      "loss": 0.523,
      "step": 697150
    },
    {
      "epoch": 7.380878780019161,
      "grad_norm": 1.2098826169967651,
      "learning_rate": 9.763123445613192e-05,
      "loss": 0.5247,
      "step": 697200
    },
    {
      "epoch": 7.381408101799165,
      "grad_norm": 1.1865038871765137,
      "learning_rate": 9.759461557258373e-05,
      "loss": 0.5151,
      "step": 697250
    },
    {
      "epoch": 7.381937423579168,
      "grad_norm": 1.480629324913025,
      "learning_rate": 9.755800189209954e-05,
      "loss": 0.5275,
      "step": 697300
    },
    {
      "epoch": 7.382466745359172,
      "grad_norm": 1.3441725969314575,
      "learning_rate": 9.752139341592916e-05,
      "loss": 0.5191,
      "step": 697350
    },
    {
      "epoch": 7.382996067139175,
      "grad_norm": 1.2793034315109253,
      "learning_rate": 9.74847901453226e-05,
      "loss": 0.5223,
      "step": 697400
    },
    {
      "epoch": 7.383525388919178,
      "grad_norm": 1.2404565811157227,
      "learning_rate": 9.74481920815293e-05,
      "loss": 0.5241,
      "step": 697450
    },
    {
      "epoch": 7.384054710699181,
      "grad_norm": 1.1805707216262817,
      "learning_rate": 9.741159922579884e-05,
      "loss": 0.524,
      "step": 697500
    },
    {
      "epoch": 7.384054710699181,
      "eval_loss": 0.32514849305152893,
      "eval_runtime": 48.2636,
      "eval_samples_per_second": 3479.435,
      "eval_steps_per_second": 434.945,
      "step": 697500
    },
    {
      "epoch": 7.384584032479184,
      "grad_norm": 1.3961178064346313,
      "learning_rate": 9.737501157938034e-05,
      "loss": 0.5167,
      "step": 697550
    },
    {
      "epoch": 7.385113354259188,
      "grad_norm": 1.2801069021224976,
      "learning_rate": 9.733842914352307e-05,
      "loss": 0.5251,
      "step": 697600
    },
    {
      "epoch": 7.385642676039191,
      "grad_norm": 1.2597298622131348,
      "learning_rate": 9.730185191947574e-05,
      "loss": 0.526,
      "step": 697650
    },
    {
      "epoch": 7.386171997819194,
      "grad_norm": 1.171391248703003,
      "learning_rate": 9.726527990848727e-05,
      "loss": 0.5413,
      "step": 697700
    },
    {
      "epoch": 7.386701319599197,
      "grad_norm": 1.4089620113372803,
      "learning_rate": 9.722871311180607e-05,
      "loss": 0.5236,
      "step": 697750
    },
    {
      "epoch": 7.387230641379201,
      "grad_norm": 1.3438892364501953,
      "learning_rate": 9.719215153068062e-05,
      "loss": 0.5141,
      "step": 697800
    },
    {
      "epoch": 7.387759963159204,
      "grad_norm": 1.4009933471679688,
      "learning_rate": 9.715559516635903e-05,
      "loss": 0.5157,
      "step": 697850
    },
    {
      "epoch": 7.388289284939208,
      "grad_norm": 1.3885048627853394,
      "learning_rate": 9.711904402008942e-05,
      "loss": 0.5173,
      "step": 697900
    },
    {
      "epoch": 7.3888186067192105,
      "grad_norm": 1.3616288900375366,
      "learning_rate": 9.70824980931195e-05,
      "loss": 0.5271,
      "step": 697950
    },
    {
      "epoch": 7.389347928499214,
      "grad_norm": 1.27139151096344,
      "learning_rate": 9.70459573866971e-05,
      "loss": 0.5176,
      "step": 698000
    },
    {
      "epoch": 7.389347928499214,
      "eval_loss": 0.3239891529083252,
      "eval_runtime": 47.5069,
      "eval_samples_per_second": 3534.854,
      "eval_steps_per_second": 441.873,
      "step": 698000
    },
    {
      "epoch": 7.389877250279217,
      "grad_norm": 1.1687347888946533,
      "learning_rate": 9.700942190206957e-05,
      "loss": 0.522,
      "step": 698050
    },
    {
      "epoch": 7.390406572059221,
      "grad_norm": 1.3092622756958008,
      "learning_rate": 9.697289164048431e-05,
      "loss": 0.5288,
      "step": 698100
    },
    {
      "epoch": 7.390935893839224,
      "grad_norm": 1.3092732429504395,
      "learning_rate": 9.693636660318835e-05,
      "loss": 0.5212,
      "step": 698150
    },
    {
      "epoch": 7.3914652156192275,
      "grad_norm": 1.3906763792037964,
      "learning_rate": 9.689984679142869e-05,
      "loss": 0.525,
      "step": 698200
    },
    {
      "epoch": 7.39199453739923,
      "grad_norm": 1.2032463550567627,
      "learning_rate": 9.686333220645219e-05,
      "loss": 0.5282,
      "step": 698250
    },
    {
      "epoch": 7.392523859179233,
      "grad_norm": 1.2870908975601196,
      "learning_rate": 9.682682284950531e-05,
      "loss": 0.5206,
      "step": 698300
    },
    {
      "epoch": 7.393053180959237,
      "grad_norm": 1.218751311302185,
      "learning_rate": 9.679031872183458e-05,
      "loss": 0.5247,
      "step": 698350
    },
    {
      "epoch": 7.39358250273924,
      "grad_norm": 1.2334392070770264,
      "learning_rate": 9.675381982468608e-05,
      "loss": 0.5365,
      "step": 698400
    },
    {
      "epoch": 7.394111824519244,
      "grad_norm": 1.2836048603057861,
      "learning_rate": 9.671732615930601e-05,
      "loss": 0.5235,
      "step": 698450
    },
    {
      "epoch": 7.3946411462992465,
      "grad_norm": 1.315737247467041,
      "learning_rate": 9.668083772694028e-05,
      "loss": 0.5182,
      "step": 698500
    },
    {
      "epoch": 7.3946411462992465,
      "eval_loss": 0.32423529028892517,
      "eval_runtime": 48.4976,
      "eval_samples_per_second": 3462.643,
      "eval_steps_per_second": 432.846,
      "step": 698500
    },
    {
      "epoch": 7.39517046807925,
      "grad_norm": 1.2639247179031372,
      "learning_rate": 9.664435452883444e-05,
      "loss": 0.5255,
      "step": 698550
    },
    {
      "epoch": 7.395699789859253,
      "grad_norm": 1.2604817152023315,
      "learning_rate": 9.660787656623418e-05,
      "loss": 0.5269,
      "step": 698600
    },
    {
      "epoch": 7.396229111639257,
      "grad_norm": 1.3061882257461548,
      "learning_rate": 9.657140384038466e-05,
      "loss": 0.5192,
      "step": 698650
    },
    {
      "epoch": 7.39675843341926,
      "grad_norm": 1.3040398359298706,
      "learning_rate": 9.653493635253124e-05,
      "loss": 0.5274,
      "step": 698700
    },
    {
      "epoch": 7.3972877551992635,
      "grad_norm": 1.1799068450927734,
      "learning_rate": 9.649920329753839e-05,
      "loss": 0.5188,
      "step": 698750
    },
    {
      "epoch": 7.397817076979266,
      "grad_norm": 1.3196014165878296,
      "learning_rate": 9.646274618458978e-05,
      "loss": 0.5246,
      "step": 698800
    },
    {
      "epoch": 7.39834639875927,
      "grad_norm": 1.304979681968689,
      "learning_rate": 9.642629431334677e-05,
      "loss": 0.5193,
      "step": 698850
    },
    {
      "epoch": 7.398875720539273,
      "grad_norm": 1.2435449361801147,
      "learning_rate": 9.638984768505365e-05,
      "loss": 0.523,
      "step": 698900
    },
    {
      "epoch": 7.399405042319277,
      "grad_norm": 1.0936416387557983,
      "learning_rate": 9.635340630095483e-05,
      "loss": 0.5141,
      "step": 698950
    },
    {
      "epoch": 7.39993436409928,
      "grad_norm": 1.3079088926315308,
      "learning_rate": 9.631697016229443e-05,
      "loss": 0.5308,
      "step": 699000
    },
    {
      "epoch": 7.39993436409928,
      "eval_loss": 0.3236273229122162,
      "eval_runtime": 49.9768,
      "eval_samples_per_second": 3360.161,
      "eval_steps_per_second": 420.035,
      "step": 699000
    },
    {
      "epoch": 7.4004636858792825,
      "grad_norm": 1.336194634437561,
      "learning_rate": 9.628053927031625e-05,
      "loss": 0.5286,
      "step": 699050
    },
    {
      "epoch": 7.400993007659286,
      "grad_norm": 1.386667251586914,
      "learning_rate": 9.624411362626411e-05,
      "loss": 0.52,
      "step": 699100
    },
    {
      "epoch": 7.401522329439289,
      "grad_norm": 1.239359736442566,
      "learning_rate": 9.620769323138151e-05,
      "loss": 0.5219,
      "step": 699150
    },
    {
      "epoch": 7.402051651219293,
      "grad_norm": 1.2449119091033936,
      "learning_rate": 9.617127808691195e-05,
      "loss": 0.517,
      "step": 699200
    },
    {
      "epoch": 7.402580972999296,
      "grad_norm": 1.2648426294326782,
      "learning_rate": 9.613486819409844e-05,
      "loss": 0.516,
      "step": 699250
    },
    {
      "epoch": 7.4031102947792995,
      "grad_norm": 1.3497638702392578,
      "learning_rate": 9.609846355418417e-05,
      "loss": 0.5108,
      "step": 699300
    },
    {
      "epoch": 7.403639616559302,
      "grad_norm": 1.219680666923523,
      "learning_rate": 9.606206416841184e-05,
      "loss": 0.5179,
      "step": 699350
    },
    {
      "epoch": 7.404168938339306,
      "grad_norm": 1.391569972038269,
      "learning_rate": 9.60256700380243e-05,
      "loss": 0.5113,
      "step": 699400
    },
    {
      "epoch": 7.404698260119309,
      "grad_norm": 1.441280722618103,
      "learning_rate": 9.599000889021606e-05,
      "loss": 0.5255,
      "step": 699450
    },
    {
      "epoch": 7.405227581899313,
      "grad_norm": 1.3034573793411255,
      "learning_rate": 9.595362516915545e-05,
      "loss": 0.5198,
      "step": 699500
    },
    {
      "epoch": 7.405227581899313,
      "eval_loss": 0.32434022426605225,
      "eval_runtime": 48.8246,
      "eval_samples_per_second": 3439.451,
      "eval_steps_per_second": 429.947,
      "step": 699500
    },
    {
      "epoch": 7.405756903679316,
      "grad_norm": 1.321022391319275,
      "learning_rate": 9.591724670718168e-05,
      "loss": 0.5151,
      "step": 699550
    },
    {
      "epoch": 7.406286225459319,
      "grad_norm": 1.4096800088882446,
      "learning_rate": 9.588087350553651e-05,
      "loss": 0.5284,
      "step": 699600
    },
    {
      "epoch": 7.406815547239322,
      "grad_norm": 1.2389503717422485,
      "learning_rate": 9.58445055654619e-05,
      "loss": 0.5296,
      "step": 699650
    },
    {
      "epoch": 7.407344869019326,
      "grad_norm": 1.3554587364196777,
      "learning_rate": 9.580814288819923e-05,
      "loss": 0.5244,
      "step": 699700
    },
    {
      "epoch": 7.407874190799329,
      "grad_norm": 1.34379243850708,
      "learning_rate": 9.57717854749901e-05,
      "loss": 0.5214,
      "step": 699750
    },
    {
      "epoch": 7.408403512579332,
      "grad_norm": 1.400607943534851,
      "learning_rate": 9.573543332707557e-05,
      "loss": 0.5199,
      "step": 699800
    },
    {
      "epoch": 7.4089328343593355,
      "grad_norm": 1.1595568656921387,
      "learning_rate": 9.569908644569685e-05,
      "loss": 0.5182,
      "step": 699850
    },
    {
      "epoch": 7.409462156139338,
      "grad_norm": 1.3908839225769043,
      "learning_rate": 9.566274483209464e-05,
      "loss": 0.5413,
      "step": 699900
    },
    {
      "epoch": 7.409991477919342,
      "grad_norm": 1.464723825454712,
      "learning_rate": 9.562640848750983e-05,
      "loss": 0.5214,
      "step": 699950
    },
    {
      "epoch": 7.410520799699345,
      "grad_norm": 1.3610866069793701,
      "learning_rate": 9.559007741318271e-05,
      "loss": 0.5202,
      "step": 700000
    },
    {
      "epoch": 7.410520799699345,
      "eval_loss": 0.32331132888793945,
      "eval_runtime": 48.6803,
      "eval_samples_per_second": 3449.651,
      "eval_steps_per_second": 431.222,
      "step": 700000
    },
    {
      "epoch": 7.411050121479349,
      "grad_norm": 1.2719814777374268,
      "learning_rate": 9.555375161035381e-05,
      "loss": 0.5304,
      "step": 700050
    },
    {
      "epoch": 7.411579443259352,
      "grad_norm": 1.3831369876861572,
      "learning_rate": 9.551743108026312e-05,
      "loss": 0.5138,
      "step": 700100
    },
    {
      "epoch": 7.412108765039355,
      "grad_norm": 1.407613754272461,
      "learning_rate": 9.548111582415076e-05,
      "loss": 0.5361,
      "step": 700150
    },
    {
      "epoch": 7.412638086819358,
      "grad_norm": 1.2369099855422974,
      "learning_rate": 9.544480584325634e-05,
      "loss": 0.5276,
      "step": 700200
    },
    {
      "epoch": 7.413167408599362,
      "grad_norm": 1.2275545597076416,
      "learning_rate": 9.540850113881966e-05,
      "loss": 0.5185,
      "step": 700250
    },
    {
      "epoch": 7.413696730379365,
      "grad_norm": 1.3491992950439453,
      "learning_rate": 9.537220171207998e-05,
      "loss": 0.523,
      "step": 700300
    },
    {
      "epoch": 7.414226052159369,
      "grad_norm": 1.2263933420181274,
      "learning_rate": 9.533590756427668e-05,
      "loss": 0.5153,
      "step": 700350
    },
    {
      "epoch": 7.4147553739393715,
      "grad_norm": 1.3255980014801025,
      "learning_rate": 9.529961869664872e-05,
      "loss": 0.5107,
      "step": 700400
    },
    {
      "epoch": 7.415284695719375,
      "grad_norm": 1.366015911102295,
      "learning_rate": 9.526333511043511e-05,
      "loss": 0.5235,
      "step": 700450
    },
    {
      "epoch": 7.415814017499378,
      "grad_norm": 1.2393779754638672,
      "learning_rate": 9.52270568068744e-05,
      "loss": 0.5243,
      "step": 700500
    },
    {
      "epoch": 7.415814017499378,
      "eval_loss": 0.32328134775161743,
      "eval_runtime": 48.4306,
      "eval_samples_per_second": 3467.434,
      "eval_steps_per_second": 433.445,
      "step": 700500
    },
    {
      "epoch": 7.416343339279381,
      "grad_norm": 1.3855175971984863,
      "learning_rate": 9.51907837872053e-05,
      "loss": 0.5184,
      "step": 700550
    },
    {
      "epoch": 7.416872661059385,
      "grad_norm": 1.2864989042282104,
      "learning_rate": 9.5154516052666e-05,
      "loss": 0.5225,
      "step": 700600
    },
    {
      "epoch": 7.417401982839388,
      "grad_norm": 1.4369685649871826,
      "learning_rate": 9.51182536044948e-05,
      "loss": 0.5231,
      "step": 700650
    },
    {
      "epoch": 7.417931304619391,
      "grad_norm": 1.3876585960388184,
      "learning_rate": 9.508199644392953e-05,
      "loss": 0.5251,
      "step": 700700
    },
    {
      "epoch": 7.418460626399394,
      "grad_norm": 1.469704508781433,
      "learning_rate": 9.504574457220822e-05,
      "loss": 0.5211,
      "step": 700750
    },
    {
      "epoch": 7.418989948179398,
      "grad_norm": 1.3644294738769531,
      "learning_rate": 9.500949799056821e-05,
      "loss": 0.5181,
      "step": 700800
    },
    {
      "epoch": 7.419519269959401,
      "grad_norm": 1.3214516639709473,
      "learning_rate": 9.497325670024715e-05,
      "loss": 0.5279,
      "step": 700850
    },
    {
      "epoch": 7.420048591739405,
      "grad_norm": 1.3463772535324097,
      "learning_rate": 9.49370207024823e-05,
      "loss": 0.5205,
      "step": 700900
    },
    {
      "epoch": 7.420577913519407,
      "grad_norm": 1.328356146812439,
      "learning_rate": 9.490078999851062e-05,
      "loss": 0.512,
      "step": 700950
    },
    {
      "epoch": 7.421107235299411,
      "grad_norm": 1.3798643350601196,
      "learning_rate": 9.486456458956918e-05,
      "loss": 0.526,
      "step": 701000
    },
    {
      "epoch": 7.421107235299411,
      "eval_loss": 0.3233061134815216,
      "eval_runtime": 48.9457,
      "eval_samples_per_second": 3430.945,
      "eval_steps_per_second": 428.883,
      "step": 701000
    },
    {
      "epoch": 7.421636557079414,
      "grad_norm": 1.4577202796936035,
      "learning_rate": 9.482834447689454e-05,
      "loss": 0.5216,
      "step": 701050
    },
    {
      "epoch": 7.422165878859418,
      "grad_norm": 1.2612671852111816,
      "learning_rate": 9.479212966172329e-05,
      "loss": 0.5264,
      "step": 701100
    },
    {
      "epoch": 7.422695200639421,
      "grad_norm": 1.41616952419281,
      "learning_rate": 9.475592014529191e-05,
      "loss": 0.5176,
      "step": 701150
    },
    {
      "epoch": 7.423224522419424,
      "grad_norm": 1.2656445503234863,
      "learning_rate": 9.471971592883638e-05,
      "loss": 0.5209,
      "step": 701200
    },
    {
      "epoch": 7.423753844199427,
      "grad_norm": 1.3262176513671875,
      "learning_rate": 9.46835170135929e-05,
      "loss": 0.5214,
      "step": 701250
    },
    {
      "epoch": 7.42428316597943,
      "grad_norm": 1.2984931468963623,
      "learning_rate": 9.46473234007971e-05,
      "loss": 0.5127,
      "step": 701300
    },
    {
      "epoch": 7.424812487759434,
      "grad_norm": 1.3233680725097656,
      "learning_rate": 9.461113509168482e-05,
      "loss": 0.5254,
      "step": 701350
    },
    {
      "epoch": 7.425341809539437,
      "grad_norm": 1.2617820501327515,
      "learning_rate": 9.457495208749125e-05,
      "loss": 0.5244,
      "step": 701400
    },
    {
      "epoch": 7.4258711313194405,
      "grad_norm": 1.3895015716552734,
      "learning_rate": 9.453877438945196e-05,
      "loss": 0.5272,
      "step": 701450
    },
    {
      "epoch": 7.426400453099443,
      "grad_norm": 1.1851458549499512,
      "learning_rate": 9.450260199880178e-05,
      "loss": 0.5284,
      "step": 701500
    },
    {
      "epoch": 7.426400453099443,
      "eval_loss": 0.3229130506515503,
      "eval_runtime": 48.7803,
      "eval_samples_per_second": 3442.582,
      "eval_steps_per_second": 430.338,
      "step": 701500
    },
    {
      "epoch": 7.426929774879447,
      "grad_norm": 1.1409636735916138,
      "learning_rate": 9.446643491677584e-05,
      "loss": 0.5271,
      "step": 701550
    },
    {
      "epoch": 7.42745909665945,
      "grad_norm": 1.1940337419509888,
      "learning_rate": 9.44302731446087e-05,
      "loss": 0.525,
      "step": 701600
    },
    {
      "epoch": 7.427988418439454,
      "grad_norm": 1.303580403327942,
      "learning_rate": 9.439411668353503e-05,
      "loss": 0.5294,
      "step": 701650
    },
    {
      "epoch": 7.428517740219457,
      "grad_norm": 1.223429560661316,
      "learning_rate": 9.435796553478909e-05,
      "loss": 0.516,
      "step": 701700
    },
    {
      "epoch": 7.42904706199946,
      "grad_norm": 1.4149397611618042,
      "learning_rate": 9.432181969960521e-05,
      "loss": 0.521,
      "step": 701750
    },
    {
      "epoch": 7.429576383779463,
      "grad_norm": 1.443773865699768,
      "learning_rate": 9.42856791792172e-05,
      "loss": 0.5196,
      "step": 701800
    },
    {
      "epoch": 7.430105705559467,
      "grad_norm": 1.2734498977661133,
      "learning_rate": 9.424954397485913e-05,
      "loss": 0.5317,
      "step": 701850
    },
    {
      "epoch": 7.43063502733947,
      "grad_norm": 1.3750659227371216,
      "learning_rate": 9.421341408776438e-05,
      "loss": 0.523,
      "step": 701900
    },
    {
      "epoch": 7.431164349119474,
      "grad_norm": 1.3953937292099,
      "learning_rate": 9.417728951916666e-05,
      "loss": 0.5229,
      "step": 701950
    },
    {
      "epoch": 7.4316936708994765,
      "grad_norm": 1.2332409620285034,
      "learning_rate": 9.414117027029903e-05,
      "loss": 0.5301,
      "step": 702000
    },
    {
      "epoch": 7.4316936708994765,
      "eval_loss": 0.3233751058578491,
      "eval_runtime": 50.8878,
      "eval_samples_per_second": 3300.005,
      "eval_steps_per_second": 412.515,
      "step": 702000
    },
    {
      "epoch": 7.432222992679479,
      "grad_norm": 1.3851107358932495,
      "learning_rate": 9.410505634239477e-05,
      "loss": 0.5166,
      "step": 702050
    },
    {
      "epoch": 7.432752314459483,
      "grad_norm": 1.1995469331741333,
      "learning_rate": 9.406894773668662e-05,
      "loss": 0.5222,
      "step": 702100
    },
    {
      "epoch": 7.433281636239486,
      "grad_norm": 1.2309811115264893,
      "learning_rate": 9.403284445440749e-05,
      "loss": 0.5184,
      "step": 702150
    },
    {
      "epoch": 7.43381095801949,
      "grad_norm": 1.3783655166625977,
      "learning_rate": 9.39967464967898e-05,
      "loss": 0.5201,
      "step": 702200
    },
    {
      "epoch": 7.434340279799493,
      "grad_norm": 1.3434972763061523,
      "learning_rate": 9.396065386506603e-05,
      "loss": 0.5215,
      "step": 702250
    },
    {
      "epoch": 7.434869601579496,
      "grad_norm": 1.2147812843322754,
      "learning_rate": 9.392456656046822e-05,
      "loss": 0.5236,
      "step": 702300
    },
    {
      "epoch": 7.435398923359499,
      "grad_norm": 1.3263334035873413,
      "learning_rate": 9.388848458422857e-05,
      "loss": 0.5304,
      "step": 702350
    },
    {
      "epoch": 7.435928245139503,
      "grad_norm": 1.292667269706726,
      "learning_rate": 9.38524079375787e-05,
      "loss": 0.526,
      "step": 702400
    },
    {
      "epoch": 7.436457566919506,
      "grad_norm": 1.1595909595489502,
      "learning_rate": 9.381633662175046e-05,
      "loss": 0.5146,
      "step": 702450
    },
    {
      "epoch": 7.43698688869951,
      "grad_norm": 1.328870177268982,
      "learning_rate": 9.378027063797512e-05,
      "loss": 0.5149,
      "step": 702500
    },
    {
      "epoch": 7.43698688869951,
      "eval_loss": 0.32257434725761414,
      "eval_runtime": 48.0723,
      "eval_samples_per_second": 3493.278,
      "eval_steps_per_second": 436.675,
      "step": 702500
    },
    {
      "epoch": 7.4375162104795125,
      "grad_norm": 1.571661114692688,
      "learning_rate": 9.374420998748407e-05,
      "loss": 0.5276,
      "step": 702550
    },
    {
      "epoch": 7.438045532259516,
      "grad_norm": 1.183495044708252,
      "learning_rate": 9.370815467150842e-05,
      "loss": 0.533,
      "step": 702600
    },
    {
      "epoch": 7.438574854039519,
      "grad_norm": 1.2042667865753174,
      "learning_rate": 9.367210469127901e-05,
      "loss": 0.5112,
      "step": 702650
    },
    {
      "epoch": 7.439104175819523,
      "grad_norm": 1.2689529657363892,
      "learning_rate": 9.36360600480266e-05,
      "loss": 0.5205,
      "step": 702700
    },
    {
      "epoch": 7.439633497599526,
      "grad_norm": 1.193350076675415,
      "learning_rate": 9.360002074298182e-05,
      "loss": 0.5247,
      "step": 702750
    },
    {
      "epoch": 7.440162819379529,
      "grad_norm": 1.3225921392440796,
      "learning_rate": 9.356398677737494e-05,
      "loss": 0.5187,
      "step": 702800
    },
    {
      "epoch": 7.440692141159532,
      "grad_norm": 1.297553300857544,
      "learning_rate": 9.352795815243623e-05,
      "loss": 0.5184,
      "step": 702850
    },
    {
      "epoch": 7.441221462939535,
      "grad_norm": 1.1791802644729614,
      "learning_rate": 9.349193486939555e-05,
      "loss": 0.5197,
      "step": 702900
    },
    {
      "epoch": 7.441750784719539,
      "grad_norm": 1.3064926862716675,
      "learning_rate": 9.345591692948291e-05,
      "loss": 0.5241,
      "step": 702950
    },
    {
      "epoch": 7.442280106499542,
      "grad_norm": 1.1950428485870361,
      "learning_rate": 9.341990433392778e-05,
      "loss": 0.5166,
      "step": 703000
    },
    {
      "epoch": 7.442280106499542,
      "eval_loss": 0.3221192955970764,
      "eval_runtime": 47.8747,
      "eval_samples_per_second": 3507.699,
      "eval_steps_per_second": 438.478,
      "step": 703000
    },
    {
      "epoch": 7.442809428279546,
      "grad_norm": 1.3065348863601685,
      "learning_rate": 9.338389708395978e-05,
      "loss": 0.5174,
      "step": 703050
    },
    {
      "epoch": 7.4433387500595485,
      "grad_norm": 1.138487458229065,
      "learning_rate": 9.334789518080799e-05,
      "loss": 0.5134,
      "step": 703100
    },
    {
      "epoch": 7.443868071839552,
      "grad_norm": 1.327183485031128,
      "learning_rate": 9.331189862570168e-05,
      "loss": 0.5175,
      "step": 703150
    },
    {
      "epoch": 7.444397393619555,
      "grad_norm": 1.320862889289856,
      "learning_rate": 9.327590741986966e-05,
      "loss": 0.52,
      "step": 703200
    },
    {
      "epoch": 7.444926715399559,
      "grad_norm": 1.3281822204589844,
      "learning_rate": 9.323992156454072e-05,
      "loss": 0.5192,
      "step": 703250
    },
    {
      "epoch": 7.445456037179562,
      "grad_norm": 1.3815817832946777,
      "learning_rate": 9.320394106094329e-05,
      "loss": 0.5202,
      "step": 703300
    },
    {
      "epoch": 7.4459853589595655,
      "grad_norm": 1.1708345413208008,
      "learning_rate": 9.31679659103059e-05,
      "loss": 0.5186,
      "step": 703350
    },
    {
      "epoch": 7.446514680739568,
      "grad_norm": 1.2230745553970337,
      "learning_rate": 9.313199611385656e-05,
      "loss": 0.521,
      "step": 703400
    },
    {
      "epoch": 7.447044002519572,
      "grad_norm": 1.2964552640914917,
      "learning_rate": 9.3096750909153e-05,
      "loss": 0.5109,
      "step": 703450
    },
    {
      "epoch": 7.447573324299575,
      "grad_norm": 1.2481096982955933,
      "learning_rate": 9.306079171761883e-05,
      "loss": 0.5198,
      "step": 703500
    },
    {
      "epoch": 7.447573324299575,
      "eval_loss": 0.3224537968635559,
      "eval_runtime": 48.2879,
      "eval_samples_per_second": 3477.683,
      "eval_steps_per_second": 434.726,
      "step": 703500
    },
    {
      "epoch": 7.448102646079578,
      "grad_norm": 1.2900716066360474,
      "learning_rate": 9.302483788393173e-05,
      "loss": 0.5163,
      "step": 703550
    },
    {
      "epoch": 7.448631967859582,
      "grad_norm": 1.362265706062317,
      "learning_rate": 9.298888940931902e-05,
      "loss": 0.5248,
      "step": 703600
    },
    {
      "epoch": 7.4491612896395845,
      "grad_norm": 1.461891770362854,
      "learning_rate": 9.29529462950081e-05,
      "loss": 0.5227,
      "step": 703650
    },
    {
      "epoch": 7.449690611419588,
      "grad_norm": 1.4533616304397583,
      "learning_rate": 9.291700854222596e-05,
      "loss": 0.5156,
      "step": 703700
    },
    {
      "epoch": 7.450219933199591,
      "grad_norm": 1.1822713613510132,
      "learning_rate": 9.28810761521996e-05,
      "loss": 0.5138,
      "step": 703750
    },
    {
      "epoch": 7.450749254979595,
      "grad_norm": 1.301931381225586,
      "learning_rate": 9.284514912615558e-05,
      "loss": 0.5123,
      "step": 703800
    },
    {
      "epoch": 7.451278576759598,
      "grad_norm": 1.3773200511932373,
      "learning_rate": 9.280922746532064e-05,
      "loss": 0.5144,
      "step": 703850
    },
    {
      "epoch": 7.4518078985396015,
      "grad_norm": 1.2649781703948975,
      "learning_rate": 9.277331117092091e-05,
      "loss": 0.5143,
      "step": 703900
    },
    {
      "epoch": 7.452337220319604,
      "grad_norm": 1.3451027870178223,
      "learning_rate": 9.273740024418281e-05,
      "loss": 0.516,
      "step": 703950
    },
    {
      "epoch": 7.452866542099608,
      "grad_norm": 1.284993290901184,
      "learning_rate": 9.270149468633208e-05,
      "loss": 0.5304,
      "step": 704000
    },
    {
      "epoch": 7.452866542099608,
      "eval_loss": 0.3229275941848755,
      "eval_runtime": 47.5,
      "eval_samples_per_second": 3535.365,
      "eval_steps_per_second": 441.936,
      "step": 704000
    },
    {
      "epoch": 7.453395863879611,
      "grad_norm": 1.3036478757858276,
      "learning_rate": 9.266559449859472e-05,
      "loss": 0.5177,
      "step": 704050
    },
    {
      "epoch": 7.453925185659615,
      "grad_norm": 1.1970220804214478,
      "learning_rate": 9.262969968219617e-05,
      "loss": 0.5181,
      "step": 704100
    },
    {
      "epoch": 7.454454507439618,
      "grad_norm": 1.375855803489685,
      "learning_rate": 9.259381023836205e-05,
      "loss": 0.5234,
      "step": 704150
    },
    {
      "epoch": 7.454983829219621,
      "grad_norm": 1.350985050201416,
      "learning_rate": 9.255792616831743e-05,
      "loss": 0.5148,
      "step": 704200
    },
    {
      "epoch": 7.455513150999624,
      "grad_norm": 1.2559658288955688,
      "learning_rate": 9.252204747328757e-05,
      "loss": 0.5255,
      "step": 704250
    },
    {
      "epoch": 7.456042472779627,
      "grad_norm": 1.1496691703796387,
      "learning_rate": 9.248617415449717e-05,
      "loss": 0.5277,
      "step": 704300
    },
    {
      "epoch": 7.456571794559631,
      "grad_norm": 1.3511239290237427,
      "learning_rate": 9.245102351929049e-05,
      "loss": 0.5281,
      "step": 704350
    },
    {
      "epoch": 7.457101116339634,
      "grad_norm": 1.4610553979873657,
      "learning_rate": 9.24151608490674e-05,
      "loss": 0.5184,
      "step": 704400
    },
    {
      "epoch": 7.457630438119637,
      "grad_norm": 1.3595976829528809,
      "learning_rate": 9.237930355873287e-05,
      "loss": 0.5205,
      "step": 704450
    },
    {
      "epoch": 7.45815975989964,
      "grad_norm": 1.2584179639816284,
      "learning_rate": 9.234345164951116e-05,
      "loss": 0.521,
      "step": 704500
    },
    {
      "epoch": 7.45815975989964,
      "eval_loss": 0.32185977697372437,
      "eval_runtime": 46.8265,
      "eval_samples_per_second": 3586.22,
      "eval_steps_per_second": 448.294,
      "step": 704500
    },
    {
      "epoch": 7.458689081679644,
      "grad_norm": 1.5026195049285889,
      "learning_rate": 9.230760512262612e-05,
      "loss": 0.5169,
      "step": 704550
    },
    {
      "epoch": 7.459218403459647,
      "grad_norm": 1.395836353302002,
      "learning_rate": 9.227176397930171e-05,
      "loss": 0.5206,
      "step": 704600
    },
    {
      "epoch": 7.459747725239651,
      "grad_norm": 1.3270405530929565,
      "learning_rate": 9.223592822076132e-05,
      "loss": 0.5238,
      "step": 704650
    },
    {
      "epoch": 7.4602770470196536,
      "grad_norm": 1.2577967643737793,
      "learning_rate": 9.220009784822858e-05,
      "loss": 0.5304,
      "step": 704700
    },
    {
      "epoch": 7.460806368799657,
      "grad_norm": 1.4972267150878906,
      "learning_rate": 9.216427286292656e-05,
      "loss": 0.5254,
      "step": 704750
    },
    {
      "epoch": 7.46133569057966,
      "grad_norm": 1.376754641532898,
      "learning_rate": 9.212845326607843e-05,
      "loss": 0.5226,
      "step": 704800
    },
    {
      "epoch": 7.461865012359664,
      "grad_norm": 1.3408664464950562,
      "learning_rate": 9.209263905890695e-05,
      "loss": 0.5236,
      "step": 704850
    },
    {
      "epoch": 7.462394334139667,
      "grad_norm": 1.248940110206604,
      "learning_rate": 9.205683024263495e-05,
      "loss": 0.5263,
      "step": 704900
    },
    {
      "epoch": 7.4629236559196706,
      "grad_norm": 1.3293206691741943,
      "learning_rate": 9.202102681848473e-05,
      "loss": 0.5158,
      "step": 704950
    },
    {
      "epoch": 7.463452977699673,
      "grad_norm": 1.2888429164886475,
      "learning_rate": 9.198522878767882e-05,
      "loss": 0.5249,
      "step": 705000
    },
    {
      "epoch": 7.463452977699673,
      "eval_loss": 0.32232531905174255,
      "eval_runtime": 46.8329,
      "eval_samples_per_second": 3585.725,
      "eval_steps_per_second": 448.232,
      "step": 705000
    },
    {
      "epoch": 7.463982299479676,
      "grad_norm": 1.3238413333892822,
      "learning_rate": 9.194943615143917e-05,
      "loss": 0.5182,
      "step": 705050
    },
    {
      "epoch": 7.46451162125968,
      "grad_norm": 1.2190972566604614,
      "learning_rate": 9.191364891098789e-05,
      "loss": 0.5189,
      "step": 705100
    },
    {
      "epoch": 7.465040943039683,
      "grad_norm": 1.1510249376296997,
      "learning_rate": 9.187786706754656e-05,
      "loss": 0.5268,
      "step": 705150
    },
    {
      "epoch": 7.465570264819687,
      "grad_norm": 1.333784580230713,
      "learning_rate": 9.184209062233687e-05,
      "loss": 0.5209,
      "step": 705200
    },
    {
      "epoch": 7.4660995865996895,
      "grad_norm": 1.2994592189788818,
      "learning_rate": 9.180631957658028e-05,
      "loss": 0.5181,
      "step": 705250
    },
    {
      "epoch": 7.466628908379693,
      "grad_norm": 1.379626750946045,
      "learning_rate": 9.177055393149784e-05,
      "loss": 0.5169,
      "step": 705300
    },
    {
      "epoch": 7.467158230159696,
      "grad_norm": 1.304010033607483,
      "learning_rate": 9.173479368831064e-05,
      "loss": 0.5203,
      "step": 705350
    },
    {
      "epoch": 7.4676875519397,
      "grad_norm": 1.296111822128296,
      "learning_rate": 9.169903884823965e-05,
      "loss": 0.5154,
      "step": 705400
    },
    {
      "epoch": 7.468216873719703,
      "grad_norm": 1.507082462310791,
      "learning_rate": 9.166328941250535e-05,
      "loss": 0.5203,
      "step": 705450
    },
    {
      "epoch": 7.4687461954997065,
      "grad_norm": 1.2153328657150269,
      "learning_rate": 9.162754538232834e-05,
      "loss": 0.5244,
      "step": 705500
    },
    {
      "epoch": 7.4687461954997065,
      "eval_loss": 0.3224952518939972,
      "eval_runtime": 46.792,
      "eval_samples_per_second": 3588.863,
      "eval_steps_per_second": 448.624,
      "step": 705500
    },
    {
      "epoch": 7.469275517279709,
      "grad_norm": 1.3328784704208374,
      "learning_rate": 9.159180675892878e-05,
      "loss": 0.5166,
      "step": 705550
    },
    {
      "epoch": 7.469804839059713,
      "grad_norm": 1.2588214874267578,
      "learning_rate": 9.15560735435269e-05,
      "loss": 0.5236,
      "step": 705600
    },
    {
      "epoch": 7.470334160839716,
      "grad_norm": 1.1864123344421387,
      "learning_rate": 9.152034573734253e-05,
      "loss": 0.5221,
      "step": 705650
    },
    {
      "epoch": 7.47086348261972,
      "grad_norm": 1.3042025566101074,
      "learning_rate": 9.148462334159547e-05,
      "loss": 0.5202,
      "step": 705700
    },
    {
      "epoch": 7.471392804399723,
      "grad_norm": 1.4386799335479736,
      "learning_rate": 9.144890635750516e-05,
      "loss": 0.5239,
      "step": 705750
    },
    {
      "epoch": 7.4719221261797255,
      "grad_norm": 1.367693543434143,
      "learning_rate": 9.141319478629114e-05,
      "loss": 0.5153,
      "step": 705800
    },
    {
      "epoch": 7.472451447959729,
      "grad_norm": 1.3455135822296143,
      "learning_rate": 9.137748862917239e-05,
      "loss": 0.5252,
      "step": 705850
    },
    {
      "epoch": 7.472980769739732,
      "grad_norm": 1.276757836341858,
      "learning_rate": 9.13417878873681e-05,
      "loss": 0.5157,
      "step": 705900
    },
    {
      "epoch": 7.473510091519736,
      "grad_norm": 1.293667197227478,
      "learning_rate": 9.13060925620969e-05,
      "loss": 0.5156,
      "step": 705950
    },
    {
      "epoch": 7.474039413299739,
      "grad_norm": 1.302899956703186,
      "learning_rate": 9.12704026545776e-05,
      "loss": 0.5186,
      "step": 706000
    },
    {
      "epoch": 7.474039413299739,
      "eval_loss": 0.32232096791267395,
      "eval_runtime": 46.833,
      "eval_samples_per_second": 3585.723,
      "eval_steps_per_second": 448.231,
      "step": 706000
    },
    {
      "epoch": 7.4745687350797425,
      "grad_norm": 1.353903889656067,
      "learning_rate": 9.123471816602844e-05,
      "loss": 0.5149,
      "step": 706050
    },
    {
      "epoch": 7.475098056859745,
      "grad_norm": 1.3917771577835083,
      "learning_rate": 9.119903909766786e-05,
      "loss": 0.5226,
      "step": 706100
    },
    {
      "epoch": 7.475627378639749,
      "grad_norm": 1.2414566278457642,
      "learning_rate": 9.116336545071374e-05,
      "loss": 0.5223,
      "step": 706150
    },
    {
      "epoch": 7.476156700419752,
      "grad_norm": 1.4637538194656372,
      "learning_rate": 9.11276972263842e-05,
      "loss": 0.5238,
      "step": 706200
    },
    {
      "epoch": 7.476686022199756,
      "grad_norm": 1.203080654144287,
      "learning_rate": 9.109203442589669e-05,
      "loss": 0.5189,
      "step": 706250
    },
    {
      "epoch": 7.477215343979759,
      "grad_norm": 1.3187203407287598,
      "learning_rate": 9.105637705046896e-05,
      "loss": 0.5207,
      "step": 706300
    },
    {
      "epoch": 7.477744665759762,
      "grad_norm": 1.336514949798584,
      "learning_rate": 9.102072510131812e-05,
      "loss": 0.5164,
      "step": 706350
    },
    {
      "epoch": 7.478273987539765,
      "grad_norm": 1.3239842653274536,
      "learning_rate": 9.09850785796615e-05,
      "loss": 0.5262,
      "step": 706400
    },
    {
      "epoch": 7.478803309319769,
      "grad_norm": 1.2717468738555908,
      "learning_rate": 9.094943748671595e-05,
      "loss": 0.5231,
      "step": 706450
    },
    {
      "epoch": 7.479332631099772,
      "grad_norm": 1.2524868249893188,
      "learning_rate": 9.091451448373744e-05,
      "loss": 0.5234,
      "step": 706500
    },
    {
      "epoch": 7.479332631099772,
      "eval_loss": 0.3221127390861511,
      "eval_runtime": 46.7699,
      "eval_samples_per_second": 3590.56,
      "eval_steps_per_second": 448.836,
      "step": 706500
    },
    {
      "epoch": 7.479861952879775,
      "grad_norm": 1.226662278175354,
      "learning_rate": 9.087888414322947e-05,
      "loss": 0.5218,
      "step": 706550
    },
    {
      "epoch": 7.4803912746597785,
      "grad_norm": 1.2746052742004395,
      "learning_rate": 9.084325923505792e-05,
      "loss": 0.5205,
      "step": 706600
    },
    {
      "epoch": 7.480920596439781,
      "grad_norm": 1.3046497106552124,
      "learning_rate": 9.080763976043926e-05,
      "loss": 0.5188,
      "step": 706650
    },
    {
      "epoch": 7.481449918219785,
      "grad_norm": 1.4234585762023926,
      "learning_rate": 9.077202572058929e-05,
      "loss": 0.5214,
      "step": 706700
    },
    {
      "epoch": 7.481979239999788,
      "grad_norm": 1.3116862773895264,
      "learning_rate": 9.073641711672406e-05,
      "loss": 0.5227,
      "step": 706750
    },
    {
      "epoch": 7.482508561779792,
      "grad_norm": 1.2616372108459473,
      "learning_rate": 9.070081395005906e-05,
      "loss": 0.5161,
      "step": 706800
    },
    {
      "epoch": 7.483037883559795,
      "grad_norm": 1.4149959087371826,
      "learning_rate": 9.066521622180992e-05,
      "loss": 0.5169,
      "step": 706850
    },
    {
      "epoch": 7.483567205339798,
      "grad_norm": 1.1942002773284912,
      "learning_rate": 9.062962393319179e-05,
      "loss": 0.5224,
      "step": 706900
    },
    {
      "epoch": 7.484096527119801,
      "grad_norm": 1.2667529582977295,
      "learning_rate": 9.059403708541993e-05,
      "loss": 0.5162,
      "step": 706950
    },
    {
      "epoch": 7.484625848899805,
      "grad_norm": 1.2262401580810547,
      "learning_rate": 9.05584556797091e-05,
      "loss": 0.5203,
      "step": 707000
    },
    {
      "epoch": 7.484625848899805,
      "eval_loss": 0.32223495841026306,
      "eval_runtime": 46.7903,
      "eval_samples_per_second": 3588.994,
      "eval_steps_per_second": 448.64,
      "step": 707000
    },
    {
      "epoch": 7.485155170679808,
      "grad_norm": 1.2926827669143677,
      "learning_rate": 9.052287971727422e-05,
      "loss": 0.5257,
      "step": 707050
    },
    {
      "epoch": 7.485684492459812,
      "grad_norm": 1.3200849294662476,
      "learning_rate": 9.048730919932962e-05,
      "loss": 0.5233,
      "step": 707100
    },
    {
      "epoch": 7.4862138142398145,
      "grad_norm": 1.3540350198745728,
      "learning_rate": 9.04517441270899e-05,
      "loss": 0.5143,
      "step": 707150
    },
    {
      "epoch": 7.486743136019818,
      "grad_norm": 1.338170051574707,
      "learning_rate": 9.041618450176903e-05,
      "loss": 0.5177,
      "step": 707200
    },
    {
      "epoch": 7.487272457799821,
      "grad_norm": 1.164743423461914,
      "learning_rate": 9.038063032458108e-05,
      "loss": 0.5114,
      "step": 707250
    },
    {
      "epoch": 7.487801779579824,
      "grad_norm": 1.353345513343811,
      "learning_rate": 9.034508159673999e-05,
      "loss": 0.5179,
      "step": 707300
    },
    {
      "epoch": 7.488331101359828,
      "grad_norm": 1.483695387840271,
      "learning_rate": 9.030953831945915e-05,
      "loss": 0.5219,
      "step": 707350
    },
    {
      "epoch": 7.488860423139831,
      "grad_norm": 1.2291079759597778,
      "learning_rate": 9.02740004939521e-05,
      "loss": 0.5176,
      "step": 707400
    },
    {
      "epoch": 7.489389744919834,
      "grad_norm": 1.1769129037857056,
      "learning_rate": 9.023846812143221e-05,
      "loss": 0.5152,
      "step": 707450
    },
    {
      "epoch": 7.489919066699837,
      "grad_norm": 1.264621615409851,
      "learning_rate": 9.020294120311232e-05,
      "loss": 0.5118,
      "step": 707500
    },
    {
      "epoch": 7.489919066699837,
      "eval_loss": 0.3206791281700134,
      "eval_runtime": 46.7228,
      "eval_samples_per_second": 3594.177,
      "eval_steps_per_second": 449.288,
      "step": 707500
    },
    {
      "epoch": 7.490448388479841,
      "grad_norm": 1.2883917093276978,
      "learning_rate": 9.01674197402055e-05,
      "loss": 0.5105,
      "step": 707550
    },
    {
      "epoch": 7.490977710259844,
      "grad_norm": 1.2991646528244019,
      "learning_rate": 9.013190373392427e-05,
      "loss": 0.5202,
      "step": 707600
    },
    {
      "epoch": 7.491507032039848,
      "grad_norm": 1.3602747917175293,
      "learning_rate": 9.009639318548132e-05,
      "loss": 0.5276,
      "step": 707650
    },
    {
      "epoch": 7.4920363538198504,
      "grad_norm": 1.3865264654159546,
      "learning_rate": 9.006088809608875e-05,
      "loss": 0.5304,
      "step": 707700
    },
    {
      "epoch": 7.492565675599854,
      "grad_norm": 1.315028190612793,
      "learning_rate": 9.00253884669589e-05,
      "loss": 0.5103,
      "step": 707750
    },
    {
      "epoch": 7.493094997379857,
      "grad_norm": 1.2583820819854736,
      "learning_rate": 8.998989429930354e-05,
      "loss": 0.5189,
      "step": 707800
    },
    {
      "epoch": 7.493624319159861,
      "grad_norm": 1.3440850973129272,
      "learning_rate": 8.99544055943346e-05,
      "loss": 0.513,
      "step": 707850
    },
    {
      "epoch": 7.494153640939864,
      "grad_norm": 1.339813470840454,
      "learning_rate": 8.991892235326346e-05,
      "loss": 0.5255,
      "step": 707900
    },
    {
      "epoch": 7.4946829627198674,
      "grad_norm": 1.334480881690979,
      "learning_rate": 8.988344457730168e-05,
      "loss": 0.5164,
      "step": 707950
    },
    {
      "epoch": 7.49521228449987,
      "grad_norm": 1.2339725494384766,
      "learning_rate": 8.984797226766031e-05,
      "loss": 0.5073,
      "step": 708000
    },
    {
      "epoch": 7.49521228449987,
      "eval_loss": 0.32098808884620667,
      "eval_runtime": 47.0018,
      "eval_samples_per_second": 3572.841,
      "eval_steps_per_second": 446.621,
      "step": 708000
    },
    {
      "epoch": 7.495741606279873,
      "grad_norm": 1.4184231758117676,
      "learning_rate": 8.981250542555053e-05,
      "loss": 0.5219,
      "step": 708050
    },
    {
      "epoch": 7.496270928059877,
      "grad_norm": 1.205021619796753,
      "learning_rate": 8.977704405218295e-05,
      "loss": 0.5169,
      "step": 708100
    },
    {
      "epoch": 7.49680024983988,
      "grad_norm": 1.1267309188842773,
      "learning_rate": 8.974158814876842e-05,
      "loss": 0.51,
      "step": 708150
    },
    {
      "epoch": 7.497329571619884,
      "grad_norm": 1.268554449081421,
      "learning_rate": 8.970613771651722e-05,
      "loss": 0.5191,
      "step": 708200
    },
    {
      "epoch": 7.497858893399886,
      "grad_norm": 1.2326534986495972,
      "learning_rate": 8.967069275663977e-05,
      "loss": 0.5193,
      "step": 708250
    },
    {
      "epoch": 7.49838821517989,
      "grad_norm": 1.4153213500976562,
      "learning_rate": 8.9635253270346e-05,
      "loss": 0.5225,
      "step": 708300
    },
    {
      "epoch": 7.498917536959893,
      "grad_norm": 1.2498774528503418,
      "learning_rate": 8.959981925884594e-05,
      "loss": 0.5194,
      "step": 708350
    },
    {
      "epoch": 7.499446858739897,
      "grad_norm": 1.3078335523605347,
      "learning_rate": 8.956439072334915e-05,
      "loss": 0.5137,
      "step": 708400
    },
    {
      "epoch": 7.4999761805199,
      "grad_norm": 1.299965500831604,
      "learning_rate": 8.952896766506532e-05,
      "loss": 0.5166,
      "step": 708450
    },
    {
      "epoch": 7.500505502299903,
      "grad_norm": 1.2265169620513916,
      "learning_rate": 8.949355008520358e-05,
      "loss": 0.5159,
      "step": 708500
    },
    {
      "epoch": 7.500505502299903,
      "eval_loss": 0.32101520895957947,
      "eval_runtime": 46.7289,
      "eval_samples_per_second": 3593.708,
      "eval_steps_per_second": 449.229,
      "step": 708500
    },
    {
      "epoch": 7.501034824079906,
      "grad_norm": 1.2667653560638428,
      "learning_rate": 8.945813798497327e-05,
      "loss": 0.5096,
      "step": 708550
    },
    {
      "epoch": 7.50156414585991,
      "grad_norm": 1.3746048212051392,
      "learning_rate": 8.942273136558315e-05,
      "loss": 0.5152,
      "step": 708600
    },
    {
      "epoch": 7.502093467639913,
      "grad_norm": 1.2763901948928833,
      "learning_rate": 8.938733022824219e-05,
      "loss": 0.5135,
      "step": 708650
    },
    {
      "epoch": 7.502622789419917,
      "grad_norm": 1.2234370708465576,
      "learning_rate": 8.93519345741588e-05,
      "loss": 0.5139,
      "step": 708700
    },
    {
      "epoch": 7.5031521111999195,
      "grad_norm": 1.5962203741073608,
      "learning_rate": 8.931654440454152e-05,
      "loss": 0.5105,
      "step": 708750
    },
    {
      "epoch": 7.503681432979922,
      "grad_norm": 1.3415943384170532,
      "learning_rate": 8.928115972059839e-05,
      "loss": 0.5189,
      "step": 708800
    },
    {
      "epoch": 7.504210754759926,
      "grad_norm": 1.3084816932678223,
      "learning_rate": 8.924578052353762e-05,
      "loss": 0.5261,
      "step": 708850
    },
    {
      "epoch": 7.504740076539929,
      "grad_norm": 1.3357621431350708,
      "learning_rate": 8.921040681456685e-05,
      "loss": 0.5241,
      "step": 708900
    },
    {
      "epoch": 7.505269398319933,
      "grad_norm": 1.4164941310882568,
      "learning_rate": 8.917503859489384e-05,
      "loss": 0.5219,
      "step": 708950
    },
    {
      "epoch": 7.505798720099936,
      "grad_norm": 1.3042147159576416,
      "learning_rate": 8.913967586572614e-05,
      "loss": 0.5194,
      "step": 709000
    },
    {
      "epoch": 7.505798720099936,
      "eval_loss": 0.3207548260688782,
      "eval_runtime": 46.9072,
      "eval_samples_per_second": 3580.045,
      "eval_steps_per_second": 447.522,
      "step": 709000
    },
    {
      "epoch": 7.506328041879939,
      "grad_norm": 1.3044648170471191,
      "learning_rate": 8.910431862827079e-05,
      "loss": 0.5129,
      "step": 709050
    },
    {
      "epoch": 7.506857363659942,
      "grad_norm": 1.1793594360351562,
      "learning_rate": 8.9068966883735e-05,
      "loss": 0.5164,
      "step": 709100
    },
    {
      "epoch": 7.507386685439946,
      "grad_norm": 1.319440484046936,
      "learning_rate": 8.903362063332574e-05,
      "loss": 0.5187,
      "step": 709150
    },
    {
      "epoch": 7.507916007219949,
      "grad_norm": 1.2100331783294678,
      "learning_rate": 8.899827987824957e-05,
      "loss": 0.5218,
      "step": 709200
    },
    {
      "epoch": 7.508445328999953,
      "grad_norm": 1.2507041692733765,
      "learning_rate": 8.896294461971316e-05,
      "loss": 0.5213,
      "step": 709250
    },
    {
      "epoch": 7.5089746507799555,
      "grad_norm": 1.3284258842468262,
      "learning_rate": 8.892761485892267e-05,
      "loss": 0.5229,
      "step": 709300
    },
    {
      "epoch": 7.509503972559959,
      "grad_norm": 1.311000108718872,
      "learning_rate": 8.889229059708443e-05,
      "loss": 0.5282,
      "step": 709350
    },
    {
      "epoch": 7.510033294339962,
      "grad_norm": 1.3120824098587036,
      "learning_rate": 8.885697183540423e-05,
      "loss": 0.5192,
      "step": 709400
    },
    {
      "epoch": 7.510562616119966,
      "grad_norm": 1.3888813257217407,
      "learning_rate": 8.882165857508797e-05,
      "loss": 0.5167,
      "step": 709450
    },
    {
      "epoch": 7.511091937899969,
      "grad_norm": 1.2301928997039795,
      "learning_rate": 8.87863508173411e-05,
      "loss": 0.5248,
      "step": 709500
    },
    {
      "epoch": 7.511091937899969,
      "eval_loss": 0.32065680623054504,
      "eval_runtime": 46.7901,
      "eval_samples_per_second": 3589.008,
      "eval_steps_per_second": 448.642,
      "step": 709500
    },
    {
      "epoch": 7.511621259679972,
      "grad_norm": 1.3556828498840332,
      "learning_rate": 8.875104856336919e-05,
      "loss": 0.5253,
      "step": 709550
    },
    {
      "epoch": 7.512150581459975,
      "grad_norm": 1.2876347303390503,
      "learning_rate": 8.871575181437724e-05,
      "loss": 0.5182,
      "step": 709600
    },
    {
      "epoch": 7.512679903239978,
      "grad_norm": 1.1731425523757935,
      "learning_rate": 8.868046057157048e-05,
      "loss": 0.5277,
      "step": 709650
    },
    {
      "epoch": 7.513209225019982,
      "grad_norm": 1.2819751501083374,
      "learning_rate": 8.864517483615356e-05,
      "loss": 0.5162,
      "step": 709700
    },
    {
      "epoch": 7.513738546799985,
      "grad_norm": 1.433345079421997,
      "learning_rate": 8.860989460933125e-05,
      "loss": 0.5188,
      "step": 709750
    },
    {
      "epoch": 7.514267868579989,
      "grad_norm": 1.2820290327072144,
      "learning_rate": 8.857461989230786e-05,
      "loss": 0.5176,
      "step": 709800
    },
    {
      "epoch": 7.5147971903599915,
      "grad_norm": 1.4162278175354004,
      "learning_rate": 8.853935068628786e-05,
      "loss": 0.5274,
      "step": 709850
    },
    {
      "epoch": 7.515326512139995,
      "grad_norm": 1.4394140243530273,
      "learning_rate": 8.850408699247512e-05,
      "loss": 0.5125,
      "step": 709900
    },
    {
      "epoch": 7.515855833919998,
      "grad_norm": 1.3420480489730835,
      "learning_rate": 8.846882881207368e-05,
      "loss": 0.5135,
      "step": 709950
    },
    {
      "epoch": 7.516385155700002,
      "grad_norm": 1.2573893070220947,
      "learning_rate": 8.843357614628713e-05,
      "loss": 0.5134,
      "step": 710000
    },
    {
      "epoch": 7.516385155700002,
      "eval_loss": 0.3204263746738434,
      "eval_runtime": 46.6854,
      "eval_samples_per_second": 3597.058,
      "eval_steps_per_second": 449.648,
      "step": 710000
    },
    {
      "epoch": 7.516914477480005,
      "grad_norm": 1.4485819339752197,
      "learning_rate": 8.839832899631911e-05,
      "loss": 0.5231,
      "step": 710050
    },
    {
      "epoch": 7.5174437992600085,
      "grad_norm": 1.3754698038101196,
      "learning_rate": 8.836308736337281e-05,
      "loss": 0.5084,
      "step": 710100
    },
    {
      "epoch": 7.517973121040011,
      "grad_norm": 1.2968648672103882,
      "learning_rate": 8.83278512486515e-05,
      "loss": 0.5286,
      "step": 710150
    },
    {
      "epoch": 7.518502442820015,
      "grad_norm": 1.2617913484573364,
      "learning_rate": 8.829262065335797e-05,
      "loss": 0.5157,
      "step": 710200
    },
    {
      "epoch": 7.519031764600018,
      "grad_norm": 1.2806791067123413,
      "learning_rate": 8.825739557869505e-05,
      "loss": 0.5159,
      "step": 710250
    },
    {
      "epoch": 7.519561086380021,
      "grad_norm": 1.2588685750961304,
      "learning_rate": 8.822217602586543e-05,
      "loss": 0.5208,
      "step": 710300
    },
    {
      "epoch": 7.520090408160025,
      "grad_norm": 1.4037871360778809,
      "learning_rate": 8.818696199607129e-05,
      "loss": 0.524,
      "step": 710350
    },
    {
      "epoch": 7.5206197299400275,
      "grad_norm": 1.3257707357406616,
      "learning_rate": 8.815175349051502e-05,
      "loss": 0.5181,
      "step": 710400
    },
    {
      "epoch": 7.521149051720031,
      "grad_norm": 1.2793132066726685,
      "learning_rate": 8.811655051039847e-05,
      "loss": 0.5167,
      "step": 710450
    },
    {
      "epoch": 7.521678373500034,
      "grad_norm": 1.4079949855804443,
      "learning_rate": 8.808205695182414e-05,
      "loss": 0.5145,
      "step": 710500
    },
    {
      "epoch": 7.521678373500034,
      "eval_loss": 0.32026368379592896,
      "eval_runtime": 46.7647,
      "eval_samples_per_second": 3590.958,
      "eval_steps_per_second": 448.886,
      "step": 710500
    },
    {
      "epoch": 7.522207695280038,
      "grad_norm": 1.3604069948196411,
      "learning_rate": 8.804686491562383e-05,
      "loss": 0.5184,
      "step": 710550
    },
    {
      "epoch": 7.522737017060041,
      "grad_norm": 1.2893294095993042,
      "learning_rate": 8.80116784084441e-05,
      "loss": 0.5243,
      "step": 710600
    },
    {
      "epoch": 7.5232663388400445,
      "grad_norm": 1.3234411478042603,
      "learning_rate": 8.797649743148631e-05,
      "loss": 0.5136,
      "step": 710650
    },
    {
      "epoch": 7.523795660620047,
      "grad_norm": 1.306252360343933,
      "learning_rate": 8.79413219859514e-05,
      "loss": 0.5244,
      "step": 710700
    },
    {
      "epoch": 7.524324982400051,
      "grad_norm": 1.318386435508728,
      "learning_rate": 8.790615207304042e-05,
      "loss": 0.516,
      "step": 710750
    },
    {
      "epoch": 7.524854304180054,
      "grad_norm": 1.3348981142044067,
      "learning_rate": 8.787098769395386e-05,
      "loss": 0.5163,
      "step": 710800
    },
    {
      "epoch": 7.525383625960058,
      "grad_norm": 1.4213201999664307,
      "learning_rate": 8.783582884989241e-05,
      "loss": 0.5194,
      "step": 710850
    },
    {
      "epoch": 7.525912947740061,
      "grad_norm": 1.1911298036575317,
      "learning_rate": 8.780067554205623e-05,
      "loss": 0.5194,
      "step": 710900
    },
    {
      "epoch": 7.526442269520064,
      "grad_norm": 1.4643052816390991,
      "learning_rate": 8.776552777164557e-05,
      "loss": 0.513,
      "step": 710950
    },
    {
      "epoch": 7.526971591300067,
      "grad_norm": 1.2073856592178345,
      "learning_rate": 8.773038553986021e-05,
      "loss": 0.5121,
      "step": 711000
    },
    {
      "epoch": 7.526971591300067,
      "eval_loss": 0.31928807497024536,
      "eval_runtime": 46.6744,
      "eval_samples_per_second": 3597.901,
      "eval_steps_per_second": 449.754,
      "step": 711000
    },
    {
      "epoch": 7.52750091308007,
      "grad_norm": 1.3810786008834839,
      "learning_rate": 8.769524884790006e-05,
      "loss": 0.5132,
      "step": 711050
    },
    {
      "epoch": 7.528030234860074,
      "grad_norm": 1.3812549114227295,
      "learning_rate": 8.76601176969645e-05,
      "loss": 0.5118,
      "step": 711100
    },
    {
      "epoch": 7.528559556640077,
      "grad_norm": 1.3785653114318848,
      "learning_rate": 8.762499208825298e-05,
      "loss": 0.5141,
      "step": 711150
    },
    {
      "epoch": 7.5290888784200805,
      "grad_norm": 1.2683082818984985,
      "learning_rate": 8.758987202296479e-05,
      "loss": 0.5138,
      "step": 711200
    },
    {
      "epoch": 7.529618200200083,
      "grad_norm": 1.3948702812194824,
      "learning_rate": 8.755475750229872e-05,
      "loss": 0.5222,
      "step": 711250
    },
    {
      "epoch": 7.530147521980087,
      "grad_norm": 1.261277198791504,
      "learning_rate": 8.751964852745361e-05,
      "loss": 0.5196,
      "step": 711300
    },
    {
      "epoch": 7.53067684376009,
      "grad_norm": 1.1865968704223633,
      "learning_rate": 8.748454509962825e-05,
      "loss": 0.5134,
      "step": 711350
    },
    {
      "epoch": 7.531206165540094,
      "grad_norm": 1.2947545051574707,
      "learning_rate": 8.744944722002082e-05,
      "loss": 0.506,
      "step": 711400
    },
    {
      "epoch": 7.531735487320097,
      "grad_norm": 1.2811630964279175,
      "learning_rate": 8.741435488982971e-05,
      "loss": 0.5195,
      "step": 711450
    },
    {
      "epoch": 7.5322648091001,
      "grad_norm": 1.2194217443466187,
      "learning_rate": 8.737926811025285e-05,
      "loss": 0.5067,
      "step": 711500
    },
    {
      "epoch": 7.5322648091001,
      "eval_loss": 0.3202541470527649,
      "eval_runtime": 46.8513,
      "eval_samples_per_second": 3584.32,
      "eval_steps_per_second": 448.056,
      "step": 711500
    },
    {
      "epoch": 7.532794130880103,
      "grad_norm": 1.3045920133590698,
      "learning_rate": 8.734418688248819e-05,
      "loss": 0.5161,
      "step": 711550
    },
    {
      "epoch": 7.533323452660107,
      "grad_norm": 1.3815116882324219,
      "learning_rate": 8.730911120773328e-05,
      "loss": 0.5205,
      "step": 711600
    },
    {
      "epoch": 7.53385277444011,
      "grad_norm": 1.365203857421875,
      "learning_rate": 8.72740410871857e-05,
      "loss": 0.5144,
      "step": 711650
    },
    {
      "epoch": 7.534382096220114,
      "grad_norm": 1.190250277519226,
      "learning_rate": 8.72389765220426e-05,
      "loss": 0.5101,
      "step": 711700
    },
    {
      "epoch": 7.534911418000116,
      "grad_norm": 1.0450084209442139,
      "learning_rate": 8.720391751350126e-05,
      "loss": 0.5247,
      "step": 711750
    },
    {
      "epoch": 7.535440739780119,
      "grad_norm": 1.404946208000183,
      "learning_rate": 8.716886406275837e-05,
      "loss": 0.5127,
      "step": 711800
    },
    {
      "epoch": 7.535970061560123,
      "grad_norm": 1.2222356796264648,
      "learning_rate": 8.713381617101082e-05,
      "loss": 0.5123,
      "step": 711850
    },
    {
      "epoch": 7.536499383340126,
      "grad_norm": 1.2890825271606445,
      "learning_rate": 8.7098773839455e-05,
      "loss": 0.5094,
      "step": 711900
    },
    {
      "epoch": 7.53702870512013,
      "grad_norm": 1.4057716131210327,
      "learning_rate": 8.706373706928736e-05,
      "loss": 0.5174,
      "step": 711950
    },
    {
      "epoch": 7.5375580269001325,
      "grad_norm": 1.2409964799880981,
      "learning_rate": 8.702870586170392e-05,
      "loss": 0.5164,
      "step": 712000
    },
    {
      "epoch": 7.5375580269001325,
      "eval_loss": 0.3193361163139343,
      "eval_runtime": 46.7786,
      "eval_samples_per_second": 3589.892,
      "eval_steps_per_second": 448.753,
      "step": 712000
    },
    {
      "epoch": 7.538087348680136,
      "grad_norm": 1.3692212104797363,
      "learning_rate": 8.699368021790075e-05,
      "loss": 0.5144,
      "step": 712050
    },
    {
      "epoch": 7.538616670460139,
      "grad_norm": 1.383731722831726,
      "learning_rate": 8.69586601390735e-05,
      "loss": 0.5193,
      "step": 712100
    },
    {
      "epoch": 7.539145992240143,
      "grad_norm": 1.3901499509811401,
      "learning_rate": 8.692364562641785e-05,
      "loss": 0.5264,
      "step": 712150
    },
    {
      "epoch": 7.539675314020146,
      "grad_norm": 1.35127854347229,
      "learning_rate": 8.688863668112907e-05,
      "loss": 0.5173,
      "step": 712200
    },
    {
      "epoch": 7.5402046358001495,
      "grad_norm": 1.3079148530960083,
      "learning_rate": 8.68536333044025e-05,
      "loss": 0.5188,
      "step": 712250
    },
    {
      "epoch": 7.540733957580152,
      "grad_norm": 1.2812327146530151,
      "learning_rate": 8.681863549743296e-05,
      "loss": 0.5116,
      "step": 712300
    },
    {
      "epoch": 7.541263279360156,
      "grad_norm": 1.3803246021270752,
      "learning_rate": 8.678364326141547e-05,
      "loss": 0.5243,
      "step": 712350
    },
    {
      "epoch": 7.541792601140159,
      "grad_norm": 1.3063726425170898,
      "learning_rate": 8.674865659754445e-05,
      "loss": 0.5107,
      "step": 712400
    },
    {
      "epoch": 7.542321922920163,
      "grad_norm": 1.3191001415252686,
      "learning_rate": 8.671367550701448e-05,
      "loss": 0.5155,
      "step": 712450
    },
    {
      "epoch": 7.542851244700166,
      "grad_norm": 1.148187279701233,
      "learning_rate": 8.667939944670141e-05,
      "loss": 0.5126,
      "step": 712500
    },
    {
      "epoch": 7.542851244700166,
      "eval_loss": 0.3194115161895752,
      "eval_runtime": 46.9096,
      "eval_samples_per_second": 3579.867,
      "eval_steps_per_second": 447.499,
      "step": 712500
    },
    {
      "epoch": 7.5433805664801685,
      "grad_norm": 1.4708811044692993,
      "learning_rate": 8.664442939490964e-05,
      "loss": 0.5196,
      "step": 712550
    },
    {
      "epoch": 7.543909888260172,
      "grad_norm": 1.3613983392715454,
      "learning_rate": 8.660946492001717e-05,
      "loss": 0.5125,
      "step": 712600
    },
    {
      "epoch": 7.544439210040175,
      "grad_norm": 1.3677326440811157,
      "learning_rate": 8.657450602321759e-05,
      "loss": 0.5094,
      "step": 712650
    },
    {
      "epoch": 7.544968531820179,
      "grad_norm": 1.3324211835861206,
      "learning_rate": 8.653955270570452e-05,
      "loss": 0.5182,
      "step": 712700
    },
    {
      "epoch": 7.545497853600182,
      "grad_norm": 1.3178067207336426,
      "learning_rate": 8.650460496867108e-05,
      "loss": 0.513,
      "step": 712750
    },
    {
      "epoch": 7.5460271753801855,
      "grad_norm": 1.3342986106872559,
      "learning_rate": 8.646966281331056e-05,
      "loss": 0.5111,
      "step": 712800
    },
    {
      "epoch": 7.546556497160188,
      "grad_norm": 1.4084768295288086,
      "learning_rate": 8.643472624081569e-05,
      "loss": 0.5196,
      "step": 712850
    },
    {
      "epoch": 7.547085818940192,
      "grad_norm": 1.3913908004760742,
      "learning_rate": 8.639979525237937e-05,
      "loss": 0.5185,
      "step": 712900
    },
    {
      "epoch": 7.547615140720195,
      "grad_norm": 1.2878506183624268,
      "learning_rate": 8.636486984919395e-05,
      "loss": 0.5113,
      "step": 712950
    },
    {
      "epoch": 7.548144462500199,
      "grad_norm": 1.3118420839309692,
      "learning_rate": 8.632995003245195e-05,
      "loss": 0.521,
      "step": 713000
    },
    {
      "epoch": 7.548144462500199,
      "eval_loss": 0.3194993734359741,
      "eval_runtime": 46.7851,
      "eval_samples_per_second": 3589.392,
      "eval_steps_per_second": 448.69,
      "step": 713000
    },
    {
      "epoch": 7.548673784280202,
      "grad_norm": 1.3141908645629883,
      "learning_rate": 8.629503580334533e-05,
      "loss": 0.5149,
      "step": 713050
    },
    {
      "epoch": 7.549203106060205,
      "grad_norm": 1.3980486392974854,
      "learning_rate": 8.626012716306625e-05,
      "loss": 0.517,
      "step": 713100
    },
    {
      "epoch": 7.549732427840208,
      "grad_norm": 1.2200838327407837,
      "learning_rate": 8.622522411280631e-05,
      "loss": 0.526,
      "step": 713150
    },
    {
      "epoch": 7.550261749620212,
      "grad_norm": 1.3737691640853882,
      "learning_rate": 8.619032665375714e-05,
      "loss": 0.5181,
      "step": 713200
    },
    {
      "epoch": 7.550791071400215,
      "grad_norm": 1.3644434213638306,
      "learning_rate": 8.615543478711021e-05,
      "loss": 0.5135,
      "step": 713250
    },
    {
      "epoch": 7.551320393180218,
      "grad_norm": 1.426982045173645,
      "learning_rate": 8.61205485140566e-05,
      "loss": 0.5111,
      "step": 713300
    },
    {
      "epoch": 7.5518497149602215,
      "grad_norm": 1.415924072265625,
      "learning_rate": 8.608566783578734e-05,
      "loss": 0.5184,
      "step": 713350
    },
    {
      "epoch": 7.552379036740224,
      "grad_norm": 1.1111363172531128,
      "learning_rate": 8.605079275349333e-05,
      "loss": 0.52,
      "step": 713400
    },
    {
      "epoch": 7.552908358520228,
      "grad_norm": 1.4055136442184448,
      "learning_rate": 8.60159232683651e-05,
      "loss": 0.5257,
      "step": 713450
    },
    {
      "epoch": 7.553437680300231,
      "grad_norm": 1.25675630569458,
      "learning_rate": 8.598105938159315e-05,
      "loss": 0.52,
      "step": 713500
    },
    {
      "epoch": 7.553437680300231,
      "eval_loss": 0.3196437954902649,
      "eval_runtime": 46.8106,
      "eval_samples_per_second": 3587.433,
      "eval_steps_per_second": 448.445,
      "step": 713500
    },
    {
      "epoch": 7.553967002080235,
      "grad_norm": 1.3316936492919922,
      "learning_rate": 8.594620109436763e-05,
      "loss": 0.5113,
      "step": 713550
    },
    {
      "epoch": 7.554496323860238,
      "grad_norm": 1.2758901119232178,
      "learning_rate": 8.591134840787868e-05,
      "loss": 0.5244,
      "step": 713600
    },
    {
      "epoch": 7.555025645640241,
      "grad_norm": 1.18417227268219,
      "learning_rate": 8.587650132331606e-05,
      "loss": 0.526,
      "step": 713650
    },
    {
      "epoch": 7.555554967420244,
      "grad_norm": 1.2890948057174683,
      "learning_rate": 8.584165984186959e-05,
      "loss": 0.5151,
      "step": 713700
    },
    {
      "epoch": 7.556084289200248,
      "grad_norm": 1.2418893575668335,
      "learning_rate": 8.580682396472856e-05,
      "loss": 0.5172,
      "step": 713750
    },
    {
      "epoch": 7.556613610980251,
      "grad_norm": 1.1103780269622803,
      "learning_rate": 8.577199369308238e-05,
      "loss": 0.5245,
      "step": 713800
    },
    {
      "epoch": 7.557142932760255,
      "grad_norm": 1.3607765436172485,
      "learning_rate": 8.57371690281201e-05,
      "loss": 0.5134,
      "step": 713850
    },
    {
      "epoch": 7.5576722545402575,
      "grad_norm": 1.2677823305130005,
      "learning_rate": 8.570234997103066e-05,
      "loss": 0.5055,
      "step": 713900
    },
    {
      "epoch": 7.558201576320261,
      "grad_norm": 1.428958535194397,
      "learning_rate": 8.566753652300265e-05,
      "loss": 0.5139,
      "step": 713950
    },
    {
      "epoch": 7.558730898100264,
      "grad_norm": 1.3939592838287354,
      "learning_rate": 8.563272868522479e-05,
      "loss": 0.5102,
      "step": 714000
    },
    {
      "epoch": 7.558730898100264,
      "eval_loss": 0.3195095658302307,
      "eval_runtime": 46.7331,
      "eval_samples_per_second": 3593.385,
      "eval_steps_per_second": 449.189,
      "step": 714000
    },
    {
      "epoch": 7.559260219880267,
      "grad_norm": 1.3937190771102905,
      "learning_rate": 8.55979264588852e-05,
      "loss": 0.518,
      "step": 714050
    },
    {
      "epoch": 7.559789541660271,
      "grad_norm": 1.2376426458358765,
      "learning_rate": 8.556312984517217e-05,
      "loss": 0.5172,
      "step": 714100
    },
    {
      "epoch": 7.560318863440274,
      "grad_norm": 1.376786231994629,
      "learning_rate": 8.552833884527353e-05,
      "loss": 0.5149,
      "step": 714150
    },
    {
      "epoch": 7.560848185220277,
      "grad_norm": 1.3514090776443481,
      "learning_rate": 8.549355346037715e-05,
      "loss": 0.5189,
      "step": 714200
    },
    {
      "epoch": 7.56137750700028,
      "grad_norm": 1.421831727027893,
      "learning_rate": 8.545877369167043e-05,
      "loss": 0.5148,
      "step": 714250
    },
    {
      "epoch": 7.561906828780284,
      "grad_norm": 1.2473224401474,
      "learning_rate": 8.542399954034094e-05,
      "loss": 0.5153,
      "step": 714300
    },
    {
      "epoch": 7.562436150560287,
      "grad_norm": 1.4625823497772217,
      "learning_rate": 8.538923100757565e-05,
      "loss": 0.5138,
      "step": 714350
    },
    {
      "epoch": 7.562965472340291,
      "grad_norm": 1.3901921510696411,
      "learning_rate": 8.535446809456174e-05,
      "loss": 0.5147,
      "step": 714400
    },
    {
      "epoch": 7.5634947941202935,
      "grad_norm": 1.368492841720581,
      "learning_rate": 8.53197108024858e-05,
      "loss": 0.5227,
      "step": 714450
    },
    {
      "epoch": 7.564024115900297,
      "grad_norm": 1.1807774305343628,
      "learning_rate": 8.528565411082911e-05,
      "loss": 0.5164,
      "step": 714500
    },
    {
      "epoch": 7.564024115900297,
      "eval_loss": 0.3198300302028656,
      "eval_runtime": 46.7212,
      "eval_samples_per_second": 3594.297,
      "eval_steps_per_second": 449.303,
      "step": 714500
    },
    {
      "epoch": 7.5645534376803,
      "grad_norm": 1.2190660238265991,
      "learning_rate": 8.525090795171111e-05,
      "loss": 0.51,
      "step": 714550
    },
    {
      "epoch": 7.565082759460304,
      "grad_norm": 1.3627617359161377,
      "learning_rate": 8.521616741706679e-05,
      "loss": 0.5113,
      "step": 714600
    },
    {
      "epoch": 7.565612081240307,
      "grad_norm": 1.4104022979736328,
      "learning_rate": 8.518143250808197e-05,
      "loss": 0.514,
      "step": 714650
    },
    {
      "epoch": 7.5661414030203105,
      "grad_norm": 1.2297497987747192,
      "learning_rate": 8.514670322594267e-05,
      "loss": 0.5151,
      "step": 714700
    },
    {
      "epoch": 7.566670724800313,
      "grad_norm": 1.2331839799880981,
      "learning_rate": 8.511267398975422e-05,
      "loss": 0.518,
      "step": 714750
    },
    {
      "epoch": 7.567200046580316,
      "grad_norm": 1.3322432041168213,
      "learning_rate": 8.507795585226657e-05,
      "loss": 0.5105,
      "step": 714800
    },
    {
      "epoch": 7.56772936836032,
      "grad_norm": 1.3298243284225464,
      "learning_rate": 8.504324334515709e-05,
      "loss": 0.5181,
      "step": 714850
    },
    {
      "epoch": 7.568258690140323,
      "grad_norm": 1.2358384132385254,
      "learning_rate": 8.500853646961067e-05,
      "loss": 0.5246,
      "step": 714900
    },
    {
      "epoch": 7.568788011920327,
      "grad_norm": 1.3134779930114746,
      "learning_rate": 8.497383522681242e-05,
      "loss": 0.5158,
      "step": 714950
    },
    {
      "epoch": 7.569317333700329,
      "grad_norm": 1.2635220289230347,
      "learning_rate": 8.493913961794686e-05,
      "loss": 0.5195,
      "step": 715000
    },
    {
      "epoch": 7.569317333700329,
      "eval_loss": 0.31877490878105164,
      "eval_runtime": 46.928,
      "eval_samples_per_second": 3578.463,
      "eval_steps_per_second": 447.324,
      "step": 715000
    },
    {
      "epoch": 7.569846655480333,
      "grad_norm": 1.3702898025512695,
      "learning_rate": 8.490444964419858e-05,
      "loss": 0.5293,
      "step": 715050
    },
    {
      "epoch": 7.570375977260336,
      "grad_norm": 1.3072086572647095,
      "learning_rate": 8.486976530675177e-05,
      "loss": 0.521,
      "step": 715100
    },
    {
      "epoch": 7.57090529904034,
      "grad_norm": 1.3126517534255981,
      "learning_rate": 8.48350866067907e-05,
      "loss": 0.5271,
      "step": 715150
    },
    {
      "epoch": 7.571434620820343,
      "grad_norm": 1.2277278900146484,
      "learning_rate": 8.480041354549912e-05,
      "loss": 0.5138,
      "step": 715200
    },
    {
      "epoch": 7.571963942600346,
      "grad_norm": 1.2443912029266357,
      "learning_rate": 8.476574612406091e-05,
      "loss": 0.5274,
      "step": 715250
    },
    {
      "epoch": 7.572493264380349,
      "grad_norm": 1.1141266822814941,
      "learning_rate": 8.473108434365944e-05,
      "loss": 0.506,
      "step": 715300
    },
    {
      "epoch": 7.573022586160353,
      "grad_norm": 1.3555063009262085,
      "learning_rate": 8.469642820547824e-05,
      "loss": 0.516,
      "step": 715350
    },
    {
      "epoch": 7.573551907940356,
      "grad_norm": 1.2567145824432373,
      "learning_rate": 8.466177771070028e-05,
      "loss": 0.5095,
      "step": 715400
    },
    {
      "epoch": 7.57408122972036,
      "grad_norm": 1.266215205192566,
      "learning_rate": 8.462713286050866e-05,
      "loss": 0.518,
      "step": 715450
    },
    {
      "epoch": 7.5746105515003626,
      "grad_norm": 1.2613561153411865,
      "learning_rate": 8.459249365608599e-05,
      "loss": 0.5194,
      "step": 715500
    },
    {
      "epoch": 7.5746105515003626,
      "eval_loss": 0.319105327129364,
      "eval_runtime": 46.8006,
      "eval_samples_per_second": 3588.202,
      "eval_steps_per_second": 448.541,
      "step": 715500
    },
    {
      "epoch": 7.575139873280365,
      "grad_norm": 1.2713260650634766,
      "learning_rate": 8.455786009861502e-05,
      "loss": 0.5194,
      "step": 715550
    },
    {
      "epoch": 7.575669195060369,
      "grad_norm": 1.1949347257614136,
      "learning_rate": 8.452323218927793e-05,
      "loss": 0.5174,
      "step": 715600
    },
    {
      "epoch": 7.576198516840372,
      "grad_norm": 1.1687911748886108,
      "learning_rate": 8.44886099292571e-05,
      "loss": 0.5109,
      "step": 715650
    },
    {
      "epoch": 7.576727838620376,
      "grad_norm": 1.4248243570327759,
      "learning_rate": 8.445399331973435e-05,
      "loss": 0.5138,
      "step": 715700
    },
    {
      "epoch": 7.577257160400379,
      "grad_norm": 1.3942062854766846,
      "learning_rate": 8.441938236189164e-05,
      "loss": 0.5115,
      "step": 715750
    },
    {
      "epoch": 7.577786482180382,
      "grad_norm": 1.3543258905410767,
      "learning_rate": 8.438477705691039e-05,
      "loss": 0.5213,
      "step": 715800
    },
    {
      "epoch": 7.578315803960385,
      "grad_norm": 1.3107775449752808,
      "learning_rate": 8.435017740597215e-05,
      "loss": 0.5081,
      "step": 715850
    },
    {
      "epoch": 7.578845125740389,
      "grad_norm": 1.2365152835845947,
      "learning_rate": 8.431558341025817e-05,
      "loss": 0.5167,
      "step": 715900
    },
    {
      "epoch": 7.579374447520392,
      "grad_norm": 1.3134541511535645,
      "learning_rate": 8.42809950709493e-05,
      "loss": 0.5188,
      "step": 715950
    },
    {
      "epoch": 7.579903769300396,
      "grad_norm": 1.3008404970169067,
      "learning_rate": 8.424641238922659e-05,
      "loss": 0.5129,
      "step": 716000
    },
    {
      "epoch": 7.579903769300396,
      "eval_loss": 0.3189767599105835,
      "eval_runtime": 46.9417,
      "eval_samples_per_second": 3577.419,
      "eval_steps_per_second": 447.193,
      "step": 716000
    },
    {
      "epoch": 7.5804330910803985,
      "grad_norm": 1.361789584159851,
      "learning_rate": 8.421183536627047e-05,
      "loss": 0.5148,
      "step": 716050
    },
    {
      "epoch": 7.580962412860402,
      "grad_norm": 1.2889986038208008,
      "learning_rate": 8.41772640032615e-05,
      "loss": 0.5167,
      "step": 716100
    },
    {
      "epoch": 7.581491734640405,
      "grad_norm": 1.4130650758743286,
      "learning_rate": 8.414269830138003e-05,
      "loss": 0.5194,
      "step": 716150
    },
    {
      "epoch": 7.582021056420409,
      "grad_norm": 1.2663242816925049,
      "learning_rate": 8.410813826180591e-05,
      "loss": 0.5177,
      "step": 716200
    },
    {
      "epoch": 7.582550378200412,
      "grad_norm": 1.4625763893127441,
      "learning_rate": 8.40735838857192e-05,
      "loss": 0.5099,
      "step": 716250
    },
    {
      "epoch": 7.583079699980415,
      "grad_norm": 1.376304030418396,
      "learning_rate": 8.40390351742994e-05,
      "loss": 0.5162,
      "step": 716300
    },
    {
      "epoch": 7.583609021760418,
      "grad_norm": 1.318290114402771,
      "learning_rate": 8.400449212872613e-05,
      "loss": 0.5227,
      "step": 716350
    },
    {
      "epoch": 7.584138343540422,
      "grad_norm": 1.3717952966690063,
      "learning_rate": 8.396995475017857e-05,
      "loss": 0.5087,
      "step": 716400
    },
    {
      "epoch": 7.584667665320425,
      "grad_norm": 1.218817949295044,
      "learning_rate": 8.393542303983595e-05,
      "loss": 0.5212,
      "step": 716450
    },
    {
      "epoch": 7.585196987100428,
      "grad_norm": 1.3188965320587158,
      "learning_rate": 8.390089699887698e-05,
      "loss": 0.5134,
      "step": 716500
    },
    {
      "epoch": 7.585196987100428,
      "eval_loss": 0.31881213188171387,
      "eval_runtime": 46.8157,
      "eval_samples_per_second": 3587.046,
      "eval_steps_per_second": 448.397,
      "step": 716500
    },
    {
      "epoch": 7.585726308880432,
      "grad_norm": 1.2876056432724,
      "learning_rate": 8.386637662848057e-05,
      "loss": 0.5171,
      "step": 716550
    },
    {
      "epoch": 7.5862556306604345,
      "grad_norm": 1.314972162246704,
      "learning_rate": 8.383186192982506e-05,
      "loss": 0.5089,
      "step": 716600
    },
    {
      "epoch": 7.586784952440438,
      "grad_norm": 1.3624420166015625,
      "learning_rate": 8.379735290408891e-05,
      "loss": 0.5214,
      "step": 716650
    },
    {
      "epoch": 7.587314274220441,
      "grad_norm": 1.3470513820648193,
      "learning_rate": 8.376284955245009e-05,
      "loss": 0.5196,
      "step": 716700
    },
    {
      "epoch": 7.587843596000445,
      "grad_norm": 1.3977923393249512,
      "learning_rate": 8.372835187608671e-05,
      "loss": 0.5079,
      "step": 716750
    },
    {
      "epoch": 7.588372917780448,
      "grad_norm": 1.425908088684082,
      "learning_rate": 8.369385987617634e-05,
      "loss": 0.5087,
      "step": 716800
    },
    {
      "epoch": 7.5889022395604515,
      "grad_norm": 1.330823302268982,
      "learning_rate": 8.365937355389668e-05,
      "loss": 0.5174,
      "step": 716850
    },
    {
      "epoch": 7.589431561340454,
      "grad_norm": 1.3502980470657349,
      "learning_rate": 8.362489291042493e-05,
      "loss": 0.5125,
      "step": 716900
    },
    {
      "epoch": 7.589960883120458,
      "grad_norm": 1.4331278800964355,
      "learning_rate": 8.359041794693839e-05,
      "loss": 0.5152,
      "step": 716950
    },
    {
      "epoch": 7.590490204900461,
      "grad_norm": 1.3387548923492432,
      "learning_rate": 8.355594866461389e-05,
      "loss": 0.512,
      "step": 717000
    },
    {
      "epoch": 7.590490204900461,
      "eval_loss": 0.31813305616378784,
      "eval_runtime": 46.8811,
      "eval_samples_per_second": 3582.038,
      "eval_steps_per_second": 447.771,
      "step": 717000
    },
    {
      "epoch": 7.591019526680464,
      "grad_norm": 1.2079216241836548,
      "learning_rate": 8.352148506462835e-05,
      "loss": 0.5125,
      "step": 717050
    },
    {
      "epoch": 7.591548848460468,
      "grad_norm": 1.1953994035720825,
      "learning_rate": 8.348702714815812e-05,
      "loss": 0.521,
      "step": 717100
    },
    {
      "epoch": 7.592078170240471,
      "grad_norm": 1.1910964250564575,
      "learning_rate": 8.345257491637984e-05,
      "loss": 0.511,
      "step": 717150
    },
    {
      "epoch": 7.592607492020474,
      "grad_norm": 1.265673041343689,
      "learning_rate": 8.34181283704695e-05,
      "loss": 0.5199,
      "step": 717200
    },
    {
      "epoch": 7.593136813800477,
      "grad_norm": 1.2639310359954834,
      "learning_rate": 8.338368751160321e-05,
      "loss": 0.521,
      "step": 717250
    },
    {
      "epoch": 7.593666135580481,
      "grad_norm": 1.3263981342315674,
      "learning_rate": 8.334925234095666e-05,
      "loss": 0.5021,
      "step": 717300
    },
    {
      "epoch": 7.594195457360484,
      "grad_norm": 1.181010127067566,
      "learning_rate": 8.33148228597056e-05,
      "loss": 0.5146,
      "step": 717350
    },
    {
      "epoch": 7.5947247791404875,
      "grad_norm": 1.196964979171753,
      "learning_rate": 8.328039906902529e-05,
      "loss": 0.5122,
      "step": 717400
    },
    {
      "epoch": 7.59525410092049,
      "grad_norm": 1.4099599123001099,
      "learning_rate": 8.32459809700911e-05,
      "loss": 0.5043,
      "step": 717450
    },
    {
      "epoch": 7.595783422700494,
      "grad_norm": Infinity,
      "learning_rate": 8.32122567563999e-05,
      "loss": 0.51,
      "step": 717500
    },
    {
      "epoch": 7.595783422700494,
      "eval_loss": 0.31831449270248413,
      "eval_runtime": 46.8072,
      "eval_samples_per_second": 3587.697,
      "eval_steps_per_second": 448.478,
      "step": 717500
    },
    {
      "epoch": 7.596312744480497,
      "grad_norm": 1.3225542306900024,
      "learning_rate": 8.317784993058913e-05,
      "loss": 0.5196,
      "step": 717550
    },
    {
      "epoch": 7.596842066260501,
      "grad_norm": 1.167941927909851,
      "learning_rate": 8.314344880002545e-05,
      "loss": 0.5087,
      "step": 717600
    },
    {
      "epoch": 7.597371388040504,
      "grad_norm": 1.3782532215118408,
      "learning_rate": 8.310905336588314e-05,
      "loss": 0.5167,
      "step": 717650
    },
    {
      "epoch": 7.597900709820507,
      "grad_norm": 1.333569884300232,
      "learning_rate": 8.307466362933666e-05,
      "loss": 0.5233,
      "step": 717700
    },
    {
      "epoch": 7.59843003160051,
      "grad_norm": 1.3299283981323242,
      "learning_rate": 8.304027959155983e-05,
      "loss": 0.5124,
      "step": 717750
    },
    {
      "epoch": 7.598959353380513,
      "grad_norm": 1.2513502836227417,
      "learning_rate": 8.300590125372673e-05,
      "loss": 0.5085,
      "step": 717800
    },
    {
      "epoch": 7.599488675160517,
      "grad_norm": 1.2093288898468018,
      "learning_rate": 8.297152861701082e-05,
      "loss": 0.51,
      "step": 717850
    },
    {
      "epoch": 7.600017996940521,
      "grad_norm": 1.2637966871261597,
      "learning_rate": 8.293716168258566e-05,
      "loss": 0.5195,
      "step": 717900
    },
    {
      "epoch": 7.6005473187205235,
      "grad_norm": 1.263951063156128,
      "learning_rate": 8.290280045162463e-05,
      "loss": 0.5128,
      "step": 717950
    },
    {
      "epoch": 7.601076640500526,
      "grad_norm": 1.2046234607696533,
      "learning_rate": 8.286844492530063e-05,
      "loss": 0.5117,
      "step": 718000
    },
    {
      "epoch": 7.601076640500526,
      "eval_loss": 0.3181753158569336,
      "eval_runtime": 46.7682,
      "eval_samples_per_second": 3590.685,
      "eval_steps_per_second": 448.852,
      "step": 718000
    },
    {
      "epoch": 7.60160596228053,
      "grad_norm": 1.405668020248413,
      "learning_rate": 8.28340951047867e-05,
      "loss": 0.5193,
      "step": 718050
    },
    {
      "epoch": 7.602135284060533,
      "grad_norm": 1.2491600513458252,
      "learning_rate": 8.27997509912554e-05,
      "loss": 0.5169,
      "step": 718100
    },
    {
      "epoch": 7.602664605840537,
      "grad_norm": 1.3009521961212158,
      "learning_rate": 8.276541258587925e-05,
      "loss": 0.5206,
      "step": 718150
    },
    {
      "epoch": 7.60319392762054,
      "grad_norm": 1.2494027614593506,
      "learning_rate": 8.273107988983066e-05,
      "loss": 0.5135,
      "step": 718200
    },
    {
      "epoch": 7.603723249400543,
      "grad_norm": 1.3131663799285889,
      "learning_rate": 8.269675290428161e-05,
      "loss": 0.5101,
      "step": 718250
    },
    {
      "epoch": 7.604252571180546,
      "grad_norm": 1.2892171144485474,
      "learning_rate": 8.26624316304041e-05,
      "loss": 0.5104,
      "step": 718300
    },
    {
      "epoch": 7.60478189296055,
      "grad_norm": 1.357327938079834,
      "learning_rate": 8.262811606936977e-05,
      "loss": 0.508,
      "step": 718350
    },
    {
      "epoch": 7.605311214740553,
      "grad_norm": 1.120012879371643,
      "learning_rate": 8.259380622235022e-05,
      "loss": 0.5189,
      "step": 718400
    },
    {
      "epoch": 7.605840536520557,
      "grad_norm": 1.1797263622283936,
      "learning_rate": 8.255950209051666e-05,
      "loss": 0.5083,
      "step": 718450
    },
    {
      "epoch": 7.6063698583005595,
      "grad_norm": 1.3595596551895142,
      "learning_rate": 8.252520367504038e-05,
      "loss": 0.5204,
      "step": 718500
    },
    {
      "epoch": 7.6063698583005595,
      "eval_loss": 0.31930026412010193,
      "eval_runtime": 46.9856,
      "eval_samples_per_second": 3574.074,
      "eval_steps_per_second": 446.775,
      "step": 718500
    },
    {
      "epoch": 7.606899180080562,
      "grad_norm": 1.2946693897247314,
      "learning_rate": 8.249091097709213e-05,
      "loss": 0.5183,
      "step": 718550
    },
    {
      "epoch": 7.607428501860566,
      "grad_norm": 1.332221269607544,
      "learning_rate": 8.245662399784284e-05,
      "loss": 0.5127,
      "step": 718600
    },
    {
      "epoch": 7.60795782364057,
      "grad_norm": 1.3881471157073975,
      "learning_rate": 8.242234273846289e-05,
      "loss": 0.5154,
      "step": 718650
    },
    {
      "epoch": 7.608487145420573,
      "grad_norm": 1.3888325691223145,
      "learning_rate": 8.238806720012276e-05,
      "loss": 0.5193,
      "step": 718700
    },
    {
      "epoch": 7.609016467200576,
      "grad_norm": 1.1901192665100098,
      "learning_rate": 8.235379738399248e-05,
      "loss": 0.5236,
      "step": 718750
    },
    {
      "epoch": 7.609545788980579,
      "grad_norm": 1.3457813262939453,
      "learning_rate": 8.231953329124215e-05,
      "loss": 0.5188,
      "step": 718800
    },
    {
      "epoch": 7.610075110760582,
      "grad_norm": 1.3623234033584595,
      "learning_rate": 8.228527492304139e-05,
      "loss": 0.5178,
      "step": 718850
    },
    {
      "epoch": 7.610604432540586,
      "grad_norm": 1.469968557357788,
      "learning_rate": 8.22510222805599e-05,
      "loss": 0.5156,
      "step": 718900
    },
    {
      "epoch": 7.611133754320589,
      "grad_norm": 1.3617664575576782,
      "learning_rate": 8.221677536496691e-05,
      "loss": 0.5174,
      "step": 718950
    },
    {
      "epoch": 7.611663076100593,
      "grad_norm": 1.0777082443237305,
      "learning_rate": 8.218253417743177e-05,
      "loss": 0.5127,
      "step": 719000
    },
    {
      "epoch": 7.611663076100593,
      "eval_loss": 0.3182431757450104,
      "eval_runtime": 46.8021,
      "eval_samples_per_second": 3588.084,
      "eval_steps_per_second": 448.527,
      "step": 719000
    },
    {
      "epoch": 7.612192397880595,
      "grad_norm": 1.288926601409912,
      "learning_rate": 8.214829871912328e-05,
      "loss": 0.5184,
      "step": 719050
    },
    {
      "epoch": 7.612721719660599,
      "grad_norm": 1.4559128284454346,
      "learning_rate": 8.21140689912104e-05,
      "loss": 0.5166,
      "step": 719100
    },
    {
      "epoch": 7.613251041440602,
      "grad_norm": 1.3005449771881104,
      "learning_rate": 8.207984499486154e-05,
      "loss": 0.5243,
      "step": 719150
    },
    {
      "epoch": 7.613780363220606,
      "grad_norm": 1.4004496335983276,
      "learning_rate": 8.204562673124528e-05,
      "loss": 0.5132,
      "step": 719200
    },
    {
      "epoch": 7.614309685000609,
      "grad_norm": 1.3088455200195312,
      "learning_rate": 8.201141420152963e-05,
      "loss": 0.5118,
      "step": 719250
    },
    {
      "epoch": 7.6148390067806115,
      "grad_norm": 1.1730573177337646,
      "learning_rate": 8.19772074068828e-05,
      "loss": 0.5051,
      "step": 719300
    },
    {
      "epoch": 7.615368328560615,
      "grad_norm": 1.358647346496582,
      "learning_rate": 8.19430063484724e-05,
      "loss": 0.52,
      "step": 719350
    },
    {
      "epoch": 7.615897650340619,
      "grad_norm": 1.5029317140579224,
      "learning_rate": 8.190881102746619e-05,
      "loss": 0.5181,
      "step": 719400
    },
    {
      "epoch": 7.616426972120622,
      "grad_norm": 1.2144808769226074,
      "learning_rate": 8.187462144503147e-05,
      "loss": 0.5137,
      "step": 719450
    },
    {
      "epoch": 7.616956293900625,
      "grad_norm": 1.325061559677124,
      "learning_rate": 8.18404376023355e-05,
      "loss": 0.5088,
      "step": 719500
    },
    {
      "epoch": 7.616956293900625,
      "eval_loss": 0.31795984506607056,
      "eval_runtime": 46.8519,
      "eval_samples_per_second": 3584.271,
      "eval_steps_per_second": 448.05,
      "step": 719500
    },
    {
      "epoch": 7.6174856156806285,
      "grad_norm": 1.2617629766464233,
      "learning_rate": 8.180625950054541e-05,
      "loss": 0.5244,
      "step": 719550
    },
    {
      "epoch": 7.618014937460631,
      "grad_norm": 1.38205087184906,
      "learning_rate": 8.177208714082787e-05,
      "loss": 0.5142,
      "step": 719600
    },
    {
      "epoch": 7.618544259240635,
      "grad_norm": 1.3757092952728271,
      "learning_rate": 8.173792052434964e-05,
      "loss": 0.5185,
      "step": 719650
    },
    {
      "epoch": 7.619073581020638,
      "grad_norm": 1.3137487173080444,
      "learning_rate": 8.1703759652277e-05,
      "loss": 0.511,
      "step": 719700
    },
    {
      "epoch": 7.619602902800642,
      "grad_norm": 1.189071774482727,
      "learning_rate": 8.166960452577631e-05,
      "loss": 0.5177,
      "step": 719750
    },
    {
      "epoch": 7.620132224580645,
      "grad_norm": 1.3716365098953247,
      "learning_rate": 8.163545514601367e-05,
      "loss": 0.5123,
      "step": 719800
    },
    {
      "epoch": 7.620661546360648,
      "grad_norm": 1.3137050867080688,
      "learning_rate": 8.160131151415476e-05,
      "loss": 0.5176,
      "step": 719850
    },
    {
      "epoch": 7.621190868140651,
      "grad_norm": 1.3174686431884766,
      "learning_rate": 8.15671736313653e-05,
      "loss": 0.5114,
      "step": 719900
    },
    {
      "epoch": 7.621720189920655,
      "grad_norm": 1.2653226852416992,
      "learning_rate": 8.153304149881085e-05,
      "loss": 0.5179,
      "step": 719950
    },
    {
      "epoch": 7.622249511700658,
      "grad_norm": 1.187133550643921,
      "learning_rate": 8.14989151176565e-05,
      "loss": 0.5096,
      "step": 720000
    },
    {
      "epoch": 7.622249511700658,
      "eval_loss": 0.3174563944339752,
      "eval_runtime": 46.8049,
      "eval_samples_per_second": 3587.872,
      "eval_steps_per_second": 448.5,
      "step": 720000
    },
    {
      "epoch": 7.622778833480661,
      "grad_norm": 1.307948112487793,
      "learning_rate": 8.146479448906749e-05,
      "loss": 0.51,
      "step": 720050
    },
    {
      "epoch": 7.6233081552606645,
      "grad_norm": 1.326041340827942,
      "learning_rate": 8.143067961420847e-05,
      "loss": 0.5145,
      "step": 720100
    },
    {
      "epoch": 7.623837477040668,
      "grad_norm": 1.3060437440872192,
      "learning_rate": 8.139657049424434e-05,
      "loss": 0.512,
      "step": 720150
    },
    {
      "epoch": 7.624366798820671,
      "grad_norm": 1.270023226737976,
      "learning_rate": 8.136246713033937e-05,
      "loss": 0.5124,
      "step": 720200
    },
    {
      "epoch": 7.624896120600674,
      "grad_norm": 1.3915470838546753,
      "learning_rate": 8.132836952365802e-05,
      "loss": 0.5181,
      "step": 720250
    },
    {
      "epoch": 7.625425442380678,
      "grad_norm": 1.2944560050964355,
      "learning_rate": 8.129427767536419e-05,
      "loss": 0.51,
      "step": 720300
    },
    {
      "epoch": 7.625954764160681,
      "grad_norm": 1.2942607402801514,
      "learning_rate": 8.12601915866219e-05,
      "loss": 0.5229,
      "step": 720350
    },
    {
      "epoch": 7.626484085940684,
      "grad_norm": 1.258239984512329,
      "learning_rate": 8.122611125859472e-05,
      "loss": 0.5089,
      "step": 720400
    },
    {
      "epoch": 7.627013407720687,
      "grad_norm": 1.4003757238388062,
      "learning_rate": 8.119203669244629e-05,
      "loss": 0.5175,
      "step": 720450
    },
    {
      "epoch": 7.627542729500691,
      "grad_norm": 1.2288578748703003,
      "learning_rate": 8.115796788933974e-05,
      "loss": 0.5128,
      "step": 720500
    },
    {
      "epoch": 7.627542729500691,
      "eval_loss": 0.31794583797454834,
      "eval_runtime": 46.8555,
      "eval_samples_per_second": 3583.996,
      "eval_steps_per_second": 448.016,
      "step": 720500
    },
    {
      "epoch": 7.628072051280694,
      "grad_norm": 1.2976644039154053,
      "learning_rate": 8.112390485043833e-05,
      "loss": 0.5031,
      "step": 720550
    },
    {
      "epoch": 7.628601373060698,
      "grad_norm": 1.3115553855895996,
      "learning_rate": 8.10898475769048e-05,
      "loss": 0.5097,
      "step": 720600
    },
    {
      "epoch": 7.6291306948407005,
      "grad_norm": 1.4330233335494995,
      "learning_rate": 8.105579606990199e-05,
      "loss": 0.5132,
      "step": 720650
    },
    {
      "epoch": 7.629660016620704,
      "grad_norm": 1.302487850189209,
      "learning_rate": 8.102175033059228e-05,
      "loss": 0.5182,
      "step": 720700
    },
    {
      "epoch": 7.630189338400707,
      "grad_norm": 1.3737162351608276,
      "learning_rate": 8.09877103601381e-05,
      "loss": 0.5067,
      "step": 720750
    },
    {
      "epoch": 7.63071866018071,
      "grad_norm": 1.3203080892562866,
      "learning_rate": 8.095367615970145e-05,
      "loss": 0.5141,
      "step": 720800
    },
    {
      "epoch": 7.631247981960714,
      "grad_norm": 1.2374098300933838,
      "learning_rate": 8.091964773044436e-05,
      "loss": 0.5138,
      "step": 720850
    },
    {
      "epoch": 7.6317773037407175,
      "grad_norm": 1.363299012184143,
      "learning_rate": 8.088562507352843e-05,
      "loss": 0.5162,
      "step": 720900
    },
    {
      "epoch": 7.63230662552072,
      "grad_norm": 1.3435388803482056,
      "learning_rate": 8.085160819011531e-05,
      "loss": 0.5116,
      "step": 720950
    },
    {
      "epoch": 7.632835947300723,
      "grad_norm": 1.313156247138977,
      "learning_rate": 8.081759708136616e-05,
      "loss": 0.506,
      "step": 721000
    },
    {
      "epoch": 7.632835947300723,
      "eval_loss": 0.31669098138809204,
      "eval_runtime": 46.7585,
      "eval_samples_per_second": 3591.431,
      "eval_steps_per_second": 448.945,
      "step": 721000
    },
    {
      "epoch": 7.633365269080727,
      "grad_norm": 1.177098035812378,
      "learning_rate": 8.07835917484423e-05,
      "loss": 0.5107,
      "step": 721050
    },
    {
      "epoch": 7.63389459086073,
      "grad_norm": 1.3779163360595703,
      "learning_rate": 8.074959219250446e-05,
      "loss": 0.5102,
      "step": 721100
    },
    {
      "epoch": 7.634423912640734,
      "grad_norm": 1.3960182666778564,
      "learning_rate": 8.071559841471358e-05,
      "loss": 0.5106,
      "step": 721150
    },
    {
      "epoch": 7.6349532344207365,
      "grad_norm": 1.3667628765106201,
      "learning_rate": 8.068161041622995e-05,
      "loss": 0.5087,
      "step": 721200
    },
    {
      "epoch": 7.63548255620074,
      "grad_norm": 1.4674516916275024,
      "learning_rate": 8.064762819821417e-05,
      "loss": 0.51,
      "step": 721250
    },
    {
      "epoch": 7.636011877980743,
      "grad_norm": 1.2096575498580933,
      "learning_rate": 8.061365176182617e-05,
      "loss": 0.5179,
      "step": 721300
    },
    {
      "epoch": 7.636541199760747,
      "grad_norm": 1.2118663787841797,
      "learning_rate": 8.057968110822606e-05,
      "loss": 0.5118,
      "step": 721350
    },
    {
      "epoch": 7.63707052154075,
      "grad_norm": 1.2575148344039917,
      "learning_rate": 8.054571623857342e-05,
      "loss": 0.5186,
      "step": 721400
    },
    {
      "epoch": 7.6375998433207535,
      "grad_norm": 1.1099755764007568,
      "learning_rate": 8.051175715402786e-05,
      "loss": 0.514,
      "step": 721450
    },
    {
      "epoch": 7.638129165100756,
      "grad_norm": 1.2356573343276978,
      "learning_rate": 8.047780385574887e-05,
      "loss": 0.5157,
      "step": 721500
    },
    {
      "epoch": 7.638129165100756,
      "eval_loss": 0.317636102437973,
      "eval_runtime": 46.7483,
      "eval_samples_per_second": 3592.217,
      "eval_steps_per_second": 449.043,
      "step": 721500
    },
    {
      "epoch": 7.638658486880759,
      "grad_norm": 1.5329840183258057,
      "learning_rate": 8.044453523838822e-05,
      "loss": 0.5268,
      "step": 721550
    },
    {
      "epoch": 7.639187808660763,
      "grad_norm": 1.2190502882003784,
      "learning_rate": 8.041059340033633e-05,
      "loss": 0.5121,
      "step": 721600
    },
    {
      "epoch": 7.639717130440767,
      "grad_norm": 1.2862871885299683,
      "learning_rate": 8.03766573520045e-05,
      "loss": 0.5087,
      "step": 721650
    },
    {
      "epoch": 7.64024645222077,
      "grad_norm": 1.33151376247406,
      "learning_rate": 8.034272709455148e-05,
      "loss": 0.5173,
      "step": 721700
    },
    {
      "epoch": 7.6407757740007725,
      "grad_norm": 1.3525689840316772,
      "learning_rate": 8.030880262913545e-05,
      "loss": 0.5116,
      "step": 721750
    },
    {
      "epoch": 7.641305095780776,
      "grad_norm": 1.4275695085525513,
      "learning_rate": 8.027488395691465e-05,
      "loss": 0.5132,
      "step": 721800
    },
    {
      "epoch": 7.641834417560779,
      "grad_norm": 1.3224989175796509,
      "learning_rate": 8.024097107904717e-05,
      "loss": 0.5161,
      "step": 721850
    },
    {
      "epoch": 7.642363739340783,
      "grad_norm": 1.2790145874023438,
      "learning_rate": 8.020706399669058e-05,
      "loss": 0.5065,
      "step": 721900
    },
    {
      "epoch": 7.642893061120786,
      "grad_norm": 1.2145262956619263,
      "learning_rate": 8.017316271100266e-05,
      "loss": 0.5194,
      "step": 721950
    },
    {
      "epoch": 7.6434223829007895,
      "grad_norm": 1.2267359495162964,
      "learning_rate": 8.013926722314057e-05,
      "loss": 0.5182,
      "step": 722000
    },
    {
      "epoch": 7.6434223829007895,
      "eval_loss": 0.3178624212741852,
      "eval_runtime": 46.836,
      "eval_samples_per_second": 3585.493,
      "eval_steps_per_second": 448.203,
      "step": 722000
    },
    {
      "epoch": 7.643951704680792,
      "grad_norm": 1.328560471534729,
      "learning_rate": 8.010537753426164e-05,
      "loss": 0.5091,
      "step": 722050
    },
    {
      "epoch": 7.644481026460796,
      "grad_norm": 1.361513376235962,
      "learning_rate": 8.007149364552288e-05,
      "loss": 0.5204,
      "step": 722100
    },
    {
      "epoch": 7.645010348240799,
      "grad_norm": 1.277493953704834,
      "learning_rate": 8.00376155580809e-05,
      "loss": 0.5106,
      "step": 722150
    },
    {
      "epoch": 7.645539670020803,
      "grad_norm": 1.2830466032028198,
      "learning_rate": 8.000374327309251e-05,
      "loss": 0.5023,
      "step": 722200
    },
    {
      "epoch": 7.646068991800806,
      "grad_norm": 1.2734252214431763,
      "learning_rate": 7.996987679171389e-05,
      "loss": 0.5091,
      "step": 722250
    },
    {
      "epoch": 7.646598313580808,
      "grad_norm": 1.3460355997085571,
      "learning_rate": 7.993601611510137e-05,
      "loss": 0.5203,
      "step": 722300
    },
    {
      "epoch": 7.647127635360812,
      "grad_norm": 1.3222609758377075,
      "learning_rate": 7.990216124441086e-05,
      "loss": 0.5247,
      "step": 722350
    },
    {
      "epoch": 7.647656957140816,
      "grad_norm": 1.262564778327942,
      "learning_rate": 7.986831218079824e-05,
      "loss": 0.5144,
      "step": 722400
    },
    {
      "epoch": 7.648186278920819,
      "grad_norm": 1.4476193189620972,
      "learning_rate": 7.983446892541896e-05,
      "loss": 0.5046,
      "step": 722450
    },
    {
      "epoch": 7.648715600700822,
      "grad_norm": 1.3445595502853394,
      "learning_rate": 7.980063147942859e-05,
      "loss": 0.5129,
      "step": 722500
    },
    {
      "epoch": 7.648715600700822,
      "eval_loss": 0.3165692687034607,
      "eval_runtime": 46.6872,
      "eval_samples_per_second": 3596.921,
      "eval_steps_per_second": 449.631,
      "step": 722500
    },
    {
      "epoch": 7.649244922480825,
      "grad_norm": 1.299789547920227,
      "learning_rate": 7.976679984398217e-05,
      "loss": 0.5128,
      "step": 722550
    },
    {
      "epoch": 7.649774244260828,
      "grad_norm": 1.2946912050247192,
      "learning_rate": 7.973297402023483e-05,
      "loss": 0.515,
      "step": 722600
    },
    {
      "epoch": 7.650303566040832,
      "grad_norm": 1.389930248260498,
      "learning_rate": 7.969915400934125e-05,
      "loss": 0.5172,
      "step": 722650
    },
    {
      "epoch": 7.650832887820835,
      "grad_norm": 1.3106337785720825,
      "learning_rate": 7.966533981245616e-05,
      "loss": 0.5214,
      "step": 722700
    },
    {
      "epoch": 7.651362209600839,
      "grad_norm": 1.3407387733459473,
      "learning_rate": 7.963153143073385e-05,
      "loss": 0.5106,
      "step": 722750
    },
    {
      "epoch": 7.6518915313808415,
      "grad_norm": 1.2328869104385376,
      "learning_rate": 7.959772886532865e-05,
      "loss": 0.5171,
      "step": 722800
    },
    {
      "epoch": 7.652420853160845,
      "grad_norm": 1.3055007457733154,
      "learning_rate": 7.95639321173944e-05,
      "loss": 0.5067,
      "step": 722850
    },
    {
      "epoch": 7.652950174940848,
      "grad_norm": 1.188473105430603,
      "learning_rate": 7.953014118808507e-05,
      "loss": 0.5068,
      "step": 722900
    },
    {
      "epoch": 7.653479496720852,
      "grad_norm": 1.410305142402649,
      "learning_rate": 7.949635607855416e-05,
      "loss": 0.514,
      "step": 722950
    },
    {
      "epoch": 7.654008818500855,
      "grad_norm": 1.2276496887207031,
      "learning_rate": 7.946257678995516e-05,
      "loss": 0.5111,
      "step": 723000
    },
    {
      "epoch": 7.654008818500855,
      "eval_loss": 0.31645479798316956,
      "eval_runtime": 47.0047,
      "eval_samples_per_second": 3572.625,
      "eval_steps_per_second": 446.594,
      "step": 723000
    },
    {
      "epoch": 7.654538140280858,
      "grad_norm": 1.1315529346466064,
      "learning_rate": 7.942880332344119e-05,
      "loss": 0.5161,
      "step": 723050
    },
    {
      "epoch": 7.655067462060861,
      "grad_norm": 1.2207087278366089,
      "learning_rate": 7.93950356801654e-05,
      "loss": 0.5166,
      "step": 723100
    },
    {
      "epoch": 7.655596783840865,
      "grad_norm": 1.4060293436050415,
      "learning_rate": 7.936127386128044e-05,
      "loss": 0.5112,
      "step": 723150
    },
    {
      "epoch": 7.656126105620868,
      "grad_norm": 1.318548321723938,
      "learning_rate": 7.932751786793909e-05,
      "loss": 0.5137,
      "step": 723200
    },
    {
      "epoch": 7.656655427400871,
      "grad_norm": 1.2394100427627563,
      "learning_rate": 7.92937677012936e-05,
      "loss": 0.5166,
      "step": 723250
    },
    {
      "epoch": 7.657184749180875,
      "grad_norm": 1.30827796459198,
      "learning_rate": 7.926002336249638e-05,
      "loss": 0.5076,
      "step": 723300
    },
    {
      "epoch": 7.6577140709608775,
      "grad_norm": 1.382683277130127,
      "learning_rate": 7.922628485269925e-05,
      "loss": 0.5095,
      "step": 723350
    },
    {
      "epoch": 7.658243392740881,
      "grad_norm": 1.3347187042236328,
      "learning_rate": 7.919255217305421e-05,
      "loss": 0.5227,
      "step": 723400
    },
    {
      "epoch": 7.658772714520884,
      "grad_norm": 1.3795000314712524,
      "learning_rate": 7.91588253247127e-05,
      "loss": 0.5203,
      "step": 723450
    },
    {
      "epoch": 7.659302036300888,
      "grad_norm": 1.1695775985717773,
      "learning_rate": 7.912510430882625e-05,
      "loss": 0.5077,
      "step": 723500
    },
    {
      "epoch": 7.659302036300888,
      "eval_loss": 0.3161333203315735,
      "eval_runtime": 46.8293,
      "eval_samples_per_second": 3586.0,
      "eval_steps_per_second": 448.266,
      "step": 723500
    },
    {
      "epoch": 7.659831358080891,
      "grad_norm": 1.3368791341781616,
      "learning_rate": 7.9092063373015e-05,
      "loss": 0.5055,
      "step": 723550
    },
    {
      "epoch": 7.6603606798608945,
      "grad_norm": 1.352672815322876,
      "learning_rate": 7.905835390878569e-05,
      "loss": 0.5076,
      "step": 723600
    },
    {
      "epoch": 7.660890001640897,
      "grad_norm": 1.274941325187683,
      "learning_rate": 7.902465028044159e-05,
      "loss": 0.512,
      "step": 723650
    },
    {
      "epoch": 7.661419323420901,
      "grad_norm": 1.4413261413574219,
      "learning_rate": 7.899095248913313e-05,
      "loss": 0.5112,
      "step": 723700
    },
    {
      "epoch": 7.661948645200904,
      "grad_norm": 1.26445734500885,
      "learning_rate": 7.895726053601091e-05,
      "loss": 0.5044,
      "step": 723750
    },
    {
      "epoch": 7.662477966980907,
      "grad_norm": 1.3010841608047485,
      "learning_rate": 7.8923574422225e-05,
      "loss": 0.5111,
      "step": 723800
    },
    {
      "epoch": 7.663007288760911,
      "grad_norm": 1.2747797966003418,
      "learning_rate": 7.88898941489256e-05,
      "loss": 0.5041,
      "step": 723850
    },
    {
      "epoch": 7.663536610540914,
      "grad_norm": 1.2720359563827515,
      "learning_rate": 7.88562197172624e-05,
      "loss": 0.5166,
      "step": 723900
    },
    {
      "epoch": 7.664065932320917,
      "grad_norm": 1.2822614908218384,
      "learning_rate": 7.882255112838507e-05,
      "loss": 0.5123,
      "step": 723950
    },
    {
      "epoch": 7.66459525410092,
      "grad_norm": 1.3216155767440796,
      "learning_rate": 7.878888838344316e-05,
      "loss": 0.5097,
      "step": 724000
    },
    {
      "epoch": 7.66459525410092,
      "eval_loss": 0.3168450593948364,
      "eval_runtime": 46.8598,
      "eval_samples_per_second": 3583.666,
      "eval_steps_per_second": 447.974,
      "step": 724000
    },
    {
      "epoch": 7.665124575880924,
      "grad_norm": 1.3190706968307495,
      "learning_rate": 7.875523148358573e-05,
      "loss": 0.5162,
      "step": 724050
    },
    {
      "epoch": 7.665653897660927,
      "grad_norm": 1.2861920595169067,
      "learning_rate": 7.872158042996191e-05,
      "loss": 0.51,
      "step": 724100
    },
    {
      "epoch": 7.6661832194409305,
      "grad_norm": 1.2993687391281128,
      "learning_rate": 7.868793522372058e-05,
      "loss": 0.5156,
      "step": 724150
    },
    {
      "epoch": 7.666712541220933,
      "grad_norm": 1.3916360139846802,
      "learning_rate": 7.865429586601025e-05,
      "loss": 0.5151,
      "step": 724200
    },
    {
      "epoch": 7.667241863000937,
      "grad_norm": 1.3310226202011108,
      "learning_rate": 7.862066235797949e-05,
      "loss": 0.5123,
      "step": 724250
    },
    {
      "epoch": 7.66777118478094,
      "grad_norm": 1.2959612607955933,
      "learning_rate": 7.858703470077639e-05,
      "loss": 0.5092,
      "step": 724300
    },
    {
      "epoch": 7.668300506560944,
      "grad_norm": 1.3609338998794556,
      "learning_rate": 7.855341289554912e-05,
      "loss": 0.5072,
      "step": 724350
    },
    {
      "epoch": 7.668829828340947,
      "grad_norm": 1.3446916341781616,
      "learning_rate": 7.851979694344541e-05,
      "loss": 0.5105,
      "step": 724400
    },
    {
      "epoch": 7.66935915012095,
      "grad_norm": 1.2017532587051392,
      "learning_rate": 7.848618684561302e-05,
      "loss": 0.5143,
      "step": 724450
    },
    {
      "epoch": 7.669888471900953,
      "grad_norm": 1.280771255493164,
      "learning_rate": 7.84525826031992e-05,
      "loss": 0.5086,
      "step": 724500
    },
    {
      "epoch": 7.669888471900953,
      "eval_loss": 0.31723031401634216,
      "eval_runtime": 46.6998,
      "eval_samples_per_second": 3595.948,
      "eval_steps_per_second": 449.51,
      "step": 724500
    },
    {
      "epoch": 7.670417793680956,
      "grad_norm": 1.240020513534546,
      "learning_rate": 7.841898421735141e-05,
      "loss": 0.5107,
      "step": 724550
    },
    {
      "epoch": 7.67094711546096,
      "grad_norm": 1.4798613786697388,
      "learning_rate": 7.838539168921649e-05,
      "loss": 0.5173,
      "step": 724600
    },
    {
      "epoch": 7.671476437240964,
      "grad_norm": 1.3334583044052124,
      "learning_rate": 7.835180501994141e-05,
      "loss": 0.5186,
      "step": 724650
    },
    {
      "epoch": 7.6720057590209665,
      "grad_norm": 1.2908118963241577,
      "learning_rate": 7.83182242106727e-05,
      "loss": 0.5107,
      "step": 724700
    },
    {
      "epoch": 7.672535080800969,
      "grad_norm": 1.3827234506607056,
      "learning_rate": 7.828464926255694e-05,
      "loss": 0.5018,
      "step": 724750
    },
    {
      "epoch": 7.673064402580973,
      "grad_norm": 1.2454352378845215,
      "learning_rate": 7.825108017674019e-05,
      "loss": 0.5184,
      "step": 724800
    },
    {
      "epoch": 7.673593724360976,
      "grad_norm": 1.3202840089797974,
      "learning_rate": 7.821751695436866e-05,
      "loss": 0.5146,
      "step": 724850
    },
    {
      "epoch": 7.67412304614098,
      "grad_norm": 1.4450085163116455,
      "learning_rate": 7.8183959596588e-05,
      "loss": 0.5155,
      "step": 724900
    },
    {
      "epoch": 7.674652367920983,
      "grad_norm": 1.2427089214324951,
      "learning_rate": 7.815040810454404e-05,
      "loss": 0.5089,
      "step": 724950
    },
    {
      "epoch": 7.675181689700986,
      "grad_norm": 1.1306167840957642,
      "learning_rate": 7.811686247938204e-05,
      "loss": 0.5024,
      "step": 725000
    },
    {
      "epoch": 7.675181689700986,
      "eval_loss": 0.3165777921676636,
      "eval_runtime": 46.8888,
      "eval_samples_per_second": 3581.454,
      "eval_steps_per_second": 447.698,
      "step": 725000
    },
    {
      "epoch": 7.675711011480989,
      "grad_norm": 1.0853447914123535,
      "learning_rate": 7.808332272224741e-05,
      "loss": 0.513,
      "step": 725050
    },
    {
      "epoch": 7.676240333260993,
      "grad_norm": 1.48622465133667,
      "learning_rate": 7.804978883428501e-05,
      "loss": 0.5168,
      "step": 725100
    },
    {
      "epoch": 7.676769655040996,
      "grad_norm": 1.336136817932129,
      "learning_rate": 7.801626081663984e-05,
      "loss": 0.512,
      "step": 725150
    },
    {
      "epoch": 7.677298976821,
      "grad_norm": 1.3903558254241943,
      "learning_rate": 7.798340905583226e-05,
      "loss": 0.5206,
      "step": 725200
    },
    {
      "epoch": 7.6778282986010025,
      "grad_norm": 1.2555043697357178,
      "learning_rate": 7.794989266479174e-05,
      "loss": 0.5174,
      "step": 725250
    },
    {
      "epoch": 7.678357620381005,
      "grad_norm": 1.3260283470153809,
      "learning_rate": 7.79163821474787e-05,
      "loss": 0.514,
      "step": 725300
    },
    {
      "epoch": 7.678886942161009,
      "grad_norm": 1.2936071157455444,
      "learning_rate": 7.788287750503737e-05,
      "loss": 0.5155,
      "step": 725350
    },
    {
      "epoch": 7.679416263941013,
      "grad_norm": 1.2836081981658936,
      "learning_rate": 7.784937873861139e-05,
      "loss": 0.5022,
      "step": 725400
    },
    {
      "epoch": 7.679945585721016,
      "grad_norm": 1.3891127109527588,
      "learning_rate": 7.781588584934458e-05,
      "loss": 0.5192,
      "step": 725450
    },
    {
      "epoch": 7.680474907501019,
      "grad_norm": 1.3735370635986328,
      "learning_rate": 7.778239883838018e-05,
      "loss": 0.5071,
      "step": 725500
    },
    {
      "epoch": 7.680474907501019,
      "eval_loss": 0.31549549102783203,
      "eval_runtime": 46.7691,
      "eval_samples_per_second": 3590.618,
      "eval_steps_per_second": 448.843,
      "step": 725500
    },
    {
      "epoch": 7.681004229281022,
      "grad_norm": 1.326683759689331,
      "learning_rate": 7.77489177068616e-05,
      "loss": 0.5238,
      "step": 725550
    },
    {
      "epoch": 7.681533551061025,
      "grad_norm": 1.4492554664611816,
      "learning_rate": 7.771544245593174e-05,
      "loss": 0.5058,
      "step": 725600
    },
    {
      "epoch": 7.682062872841029,
      "grad_norm": 1.3482438325881958,
      "learning_rate": 7.768197308673352e-05,
      "loss": 0.5118,
      "step": 725650
    },
    {
      "epoch": 7.682592194621032,
      "grad_norm": 1.19669771194458,
      "learning_rate": 7.76485096004095e-05,
      "loss": 0.5031,
      "step": 725700
    },
    {
      "epoch": 7.683121516401036,
      "grad_norm": 1.4511264562606812,
      "learning_rate": 7.761505199810226e-05,
      "loss": 0.5117,
      "step": 725750
    },
    {
      "epoch": 7.6836508381810384,
      "grad_norm": 1.3861980438232422,
      "learning_rate": 7.758160028095382e-05,
      "loss": 0.5104,
      "step": 725800
    },
    {
      "epoch": 7.684180159961042,
      "grad_norm": 1.4240894317626953,
      "learning_rate": 7.754815445010637e-05,
      "loss": 0.509,
      "step": 725850
    },
    {
      "epoch": 7.684709481741045,
      "grad_norm": 1.2928214073181152,
      "learning_rate": 7.751471450670164e-05,
      "loss": 0.5111,
      "step": 725900
    },
    {
      "epoch": 7.685238803521049,
      "grad_norm": 1.3184497356414795,
      "learning_rate": 7.748128045188135e-05,
      "loss": 0.5099,
      "step": 725950
    },
    {
      "epoch": 7.685768125301052,
      "grad_norm": 1.3458542823791504,
      "learning_rate": 7.744785228678683e-05,
      "loss": 0.4986,
      "step": 726000
    },
    {
      "epoch": 7.685768125301052,
      "eval_loss": 0.31599190831184387,
      "eval_runtime": 46.7515,
      "eval_samples_per_second": 3591.967,
      "eval_steps_per_second": 449.012,
      "step": 726000
    },
    {
      "epoch": 7.686297447081055,
      "grad_norm": 1.3179168701171875,
      "learning_rate": 7.74144300125594e-05,
      "loss": 0.5132,
      "step": 726050
    },
    {
      "epoch": 7.686826768861058,
      "grad_norm": 1.3511512279510498,
      "learning_rate": 7.738101363033998e-05,
      "loss": 0.5178,
      "step": 726100
    },
    {
      "epoch": 7.687356090641062,
      "grad_norm": 1.2527214288711548,
      "learning_rate": 7.734760314126944e-05,
      "loss": 0.5177,
      "step": 726150
    },
    {
      "epoch": 7.687885412421065,
      "grad_norm": 1.2767754793167114,
      "learning_rate": 7.731419854648847e-05,
      "loss": 0.5129,
      "step": 726200
    },
    {
      "epoch": 7.688414734201068,
      "grad_norm": 1.200189471244812,
      "learning_rate": 7.728079984713737e-05,
      "loss": 0.4956,
      "step": 726250
    },
    {
      "epoch": 7.688944055981072,
      "grad_norm": 1.3511735200881958,
      "learning_rate": 7.72474070443564e-05,
      "loss": 0.5102,
      "step": 726300
    },
    {
      "epoch": 7.689473377761074,
      "grad_norm": 1.3871819972991943,
      "learning_rate": 7.721402013928572e-05,
      "loss": 0.5051,
      "step": 726350
    },
    {
      "epoch": 7.690002699541078,
      "grad_norm": 1.2784987688064575,
      "learning_rate": 7.718063913306492e-05,
      "loss": 0.5039,
      "step": 726400
    },
    {
      "epoch": 7.690532021321081,
      "grad_norm": 1.5506658554077148,
      "learning_rate": 7.714726402683377e-05,
      "loss": 0.5082,
      "step": 726450
    },
    {
      "epoch": 7.691061343101085,
      "grad_norm": 1.3972997665405273,
      "learning_rate": 7.71138948217316e-05,
      "loss": 0.5092,
      "step": 726500
    },
    {
      "epoch": 7.691061343101085,
      "eval_loss": 0.3153984248638153,
      "eval_runtime": 46.8574,
      "eval_samples_per_second": 3583.853,
      "eval_steps_per_second": 447.998,
      "step": 726500
    },
    {
      "epoch": 7.691590664881088,
      "grad_norm": 1.3419148921966553,
      "learning_rate": 7.708053151889772e-05,
      "loss": 0.5084,
      "step": 726550
    },
    {
      "epoch": 7.692119986661091,
      "grad_norm": 1.1659667491912842,
      "learning_rate": 7.704717411947098e-05,
      "loss": 0.5177,
      "step": 726600
    },
    {
      "epoch": 7.692649308441094,
      "grad_norm": 1.3052526712417603,
      "learning_rate": 7.701382262459042e-05,
      "loss": 0.5158,
      "step": 726650
    },
    {
      "epoch": 7.693178630221098,
      "grad_norm": 1.2901960611343384,
      "learning_rate": 7.698047703539438e-05,
      "loss": 0.5123,
      "step": 726700
    },
    {
      "epoch": 7.693707952001101,
      "grad_norm": 1.2947536706924438,
      "learning_rate": 7.69471373530215e-05,
      "loss": 0.5051,
      "step": 726750
    },
    {
      "epoch": 7.694237273781104,
      "grad_norm": 1.3577624559402466,
      "learning_rate": 7.691380357860981e-05,
      "loss": 0.5087,
      "step": 726800
    },
    {
      "epoch": 7.6947665955611075,
      "grad_norm": 1.4178709983825684,
      "learning_rate": 7.688047571329746e-05,
      "loss": 0.5157,
      "step": 726850
    },
    {
      "epoch": 7.695295917341111,
      "grad_norm": 1.4191787242889404,
      "learning_rate": 7.68471537582221e-05,
      "loss": 0.507,
      "step": 726900
    },
    {
      "epoch": 7.695825239121114,
      "grad_norm": 1.3750030994415283,
      "learning_rate": 7.68138377145215e-05,
      "loss": 0.516,
      "step": 726950
    },
    {
      "epoch": 7.696354560901117,
      "grad_norm": 1.3319051265716553,
      "learning_rate": 7.678052758333288e-05,
      "loss": 0.5108,
      "step": 727000
    },
    {
      "epoch": 7.696354560901117,
      "eval_loss": 0.3162286579608917,
      "eval_runtime": 46.77,
      "eval_samples_per_second": 3590.55,
      "eval_steps_per_second": 448.835,
      "step": 727000
    },
    {
      "epoch": 7.696883882681121,
      "grad_norm": 1.3690465688705444,
      "learning_rate": 7.67472233657936e-05,
      "loss": 0.5135,
      "step": 727050
    },
    {
      "epoch": 7.697413204461124,
      "grad_norm": 1.2467114925384521,
      "learning_rate": 7.67139250630405e-05,
      "loss": 0.5072,
      "step": 727100
    },
    {
      "epoch": 7.697942526241127,
      "grad_norm": 1.3369131088256836,
      "learning_rate": 7.668063267621054e-05,
      "loss": 0.5069,
      "step": 727150
    },
    {
      "epoch": 7.69847184802113,
      "grad_norm": 1.323644995689392,
      "learning_rate": 7.664734620644009e-05,
      "loss": 0.5021,
      "step": 727200
    },
    {
      "epoch": 7.699001169801134,
      "grad_norm": 1.311244249343872,
      "learning_rate": 7.661406565486579e-05,
      "loss": 0.5149,
      "step": 727250
    },
    {
      "epoch": 7.699530491581137,
      "grad_norm": 1.2713696956634521,
      "learning_rate": 7.658079102262361e-05,
      "loss": 0.5104,
      "step": 727300
    },
    {
      "epoch": 7.700059813361141,
      "grad_norm": 1.3432453870773315,
      "learning_rate": 7.654752231084969e-05,
      "loss": 0.5168,
      "step": 727350
    },
    {
      "epoch": 7.7005891351411435,
      "grad_norm": 1.4355847835540771,
      "learning_rate": 7.651425952067969e-05,
      "loss": 0.5154,
      "step": 727400
    },
    {
      "epoch": 7.701118456921147,
      "grad_norm": 1.353506088256836,
      "learning_rate": 7.648100265324931e-05,
      "loss": 0.5101,
      "step": 727450
    },
    {
      "epoch": 7.70164777870115,
      "grad_norm": 1.3020904064178467,
      "learning_rate": 7.644775170969378e-05,
      "loss": 0.5054,
      "step": 727500
    },
    {
      "epoch": 7.70164777870115,
      "eval_loss": 0.3154706656932831,
      "eval_runtime": 46.8016,
      "eval_samples_per_second": 3588.122,
      "eval_steps_per_second": 448.531,
      "step": 727500
    },
    {
      "epoch": 7.702177100481153,
      "grad_norm": 1.3897628784179688,
      "learning_rate": 7.641450669114846e-05,
      "loss": 0.5148,
      "step": 727550
    },
    {
      "epoch": 7.702706422261157,
      "grad_norm": 1.227675199508667,
      "learning_rate": 7.638126759874813e-05,
      "loss": 0.5104,
      "step": 727600
    },
    {
      "epoch": 7.7032357440411605,
      "grad_norm": 1.2509946823120117,
      "learning_rate": 7.634803443362772e-05,
      "loss": 0.5087,
      "step": 727650
    },
    {
      "epoch": 7.703765065821163,
      "grad_norm": 1.371236801147461,
      "learning_rate": 7.631480719692166e-05,
      "loss": 0.5141,
      "step": 727700
    },
    {
      "epoch": 7.704294387601166,
      "grad_norm": 1.3267359733581543,
      "learning_rate": 7.628158588976448e-05,
      "loss": 0.5049,
      "step": 727750
    },
    {
      "epoch": 7.70482370938117,
      "grad_norm": 1.3300657272338867,
      "learning_rate": 7.624837051329014e-05,
      "loss": 0.5073,
      "step": 727800
    },
    {
      "epoch": 7.705353031161173,
      "grad_norm": 1.5468271970748901,
      "learning_rate": 7.621516106863272e-05,
      "loss": 0.5085,
      "step": 727850
    },
    {
      "epoch": 7.705882352941177,
      "grad_norm": 1.4448966979980469,
      "learning_rate": 7.618195755692603e-05,
      "loss": 0.5136,
      "step": 727900
    },
    {
      "epoch": 7.7064116747211795,
      "grad_norm": 1.4103484153747559,
      "learning_rate": 7.614875997930352e-05,
      "loss": 0.5036,
      "step": 727950
    },
    {
      "epoch": 7.706940996501183,
      "grad_norm": 1.2464059591293335,
      "learning_rate": 7.611556833689857e-05,
      "loss": 0.516,
      "step": 728000
    },
    {
      "epoch": 7.706940996501183,
      "eval_loss": 0.31557199358940125,
      "eval_runtime": 46.7284,
      "eval_samples_per_second": 3593.746,
      "eval_steps_per_second": 449.234,
      "step": 728000
    },
    {
      "epoch": 7.707470318281186,
      "grad_norm": 1.3087811470031738,
      "learning_rate": 7.608238263084442e-05,
      "loss": 0.5047,
      "step": 728050
    },
    {
      "epoch": 7.70799964006119,
      "grad_norm": 1.4276127815246582,
      "learning_rate": 7.604920286227384e-05,
      "loss": 0.5218,
      "step": 728100
    },
    {
      "epoch": 7.708528961841193,
      "grad_norm": 1.3964282274246216,
      "learning_rate": 7.60160290323198e-05,
      "loss": 0.5052,
      "step": 728150
    },
    {
      "epoch": 7.7090582836211965,
      "grad_norm": 1.4158531427383423,
      "learning_rate": 7.598286114211464e-05,
      "loss": 0.5076,
      "step": 728200
    },
    {
      "epoch": 7.709587605401199,
      "grad_norm": 1.2765504121780396,
      "learning_rate": 7.594969919279085e-05,
      "loss": 0.5083,
      "step": 728250
    },
    {
      "epoch": 7.710116927181202,
      "grad_norm": 1.2997454404830933,
      "learning_rate": 7.591654318548041e-05,
      "loss": 0.5031,
      "step": 728300
    },
    {
      "epoch": 7.710646248961206,
      "grad_norm": 1.241289496421814,
      "learning_rate": 7.588339312131545e-05,
      "loss": 0.5155,
      "step": 728350
    },
    {
      "epoch": 7.71117557074121,
      "grad_norm": 1.424599289894104,
      "learning_rate": 7.585024900142748e-05,
      "loss": 0.5127,
      "step": 728400
    },
    {
      "epoch": 7.711704892521213,
      "grad_norm": 1.3169206380844116,
      "learning_rate": 7.581711082694825e-05,
      "loss": 0.5102,
      "step": 728450
    },
    {
      "epoch": 7.7122342143012155,
      "grad_norm": 1.4193031787872314,
      "learning_rate": 7.578397859900888e-05,
      "loss": 0.5224,
      "step": 728500
    },
    {
      "epoch": 7.7122342143012155,
      "eval_loss": 0.31536009907722473,
      "eval_runtime": 46.8448,
      "eval_samples_per_second": 3584.813,
      "eval_steps_per_second": 448.118,
      "step": 728500
    },
    {
      "epoch": 7.712763536081219,
      "grad_norm": 1.1582062244415283,
      "learning_rate": 7.575085231874068e-05,
      "loss": 0.4976,
      "step": 728550
    },
    {
      "epoch": 7.713292857861222,
      "grad_norm": 1.506512999534607,
      "learning_rate": 7.571773198727439e-05,
      "loss": 0.5111,
      "step": 728600
    },
    {
      "epoch": 7.713822179641226,
      "grad_norm": 1.358193278312683,
      "learning_rate": 7.568461760574088e-05,
      "loss": 0.5129,
      "step": 728650
    },
    {
      "epoch": 7.714351501421229,
      "grad_norm": 1.1315171718597412,
      "learning_rate": 7.565150917527052e-05,
      "loss": 0.5093,
      "step": 728700
    },
    {
      "epoch": 7.7148808232012325,
      "grad_norm": 1.0857768058776855,
      "learning_rate": 7.56184066969938e-05,
      "loss": 0.4985,
      "step": 728750
    },
    {
      "epoch": 7.715410144981235,
      "grad_norm": 1.274091124534607,
      "learning_rate": 7.558531017204063e-05,
      "loss": 0.4969,
      "step": 728800
    },
    {
      "epoch": 7.715939466761239,
      "grad_norm": 1.3228873014450073,
      "learning_rate": 7.555221960154108e-05,
      "loss": 0.5028,
      "step": 728850
    },
    {
      "epoch": 7.716468788541242,
      "grad_norm": 1.2786439657211304,
      "learning_rate": 7.551913498662472e-05,
      "loss": 0.5053,
      "step": 728900
    },
    {
      "epoch": 7.716998110321246,
      "grad_norm": 1.4964724779129028,
      "learning_rate": 7.548605632842115e-05,
      "loss": 0.5204,
      "step": 728950
    },
    {
      "epoch": 7.717527432101249,
      "grad_norm": 1.2642295360565186,
      "learning_rate": 7.545298362805955e-05,
      "loss": 0.5085,
      "step": 729000
    },
    {
      "epoch": 7.717527432101249,
      "eval_loss": 0.31491371989250183,
      "eval_runtime": 47.0891,
      "eval_samples_per_second": 3566.221,
      "eval_steps_per_second": 445.794,
      "step": 729000
    },
    {
      "epoch": 7.7180567538812515,
      "grad_norm": 1.453750729560852,
      "learning_rate": 7.541991688666916e-05,
      "loss": 0.5084,
      "step": 729050
    },
    {
      "epoch": 7.718586075661255,
      "grad_norm": 1.3706517219543457,
      "learning_rate": 7.538685610537869e-05,
      "loss": 0.5099,
      "step": 729100
    },
    {
      "epoch": 7.719115397441259,
      "grad_norm": 1.329774022102356,
      "learning_rate": 7.5353801285317e-05,
      "loss": 0.5101,
      "step": 729150
    },
    {
      "epoch": 7.719644719221262,
      "grad_norm": 1.1768155097961426,
      "learning_rate": 7.532141334632813e-05,
      "loss": 0.5089,
      "step": 729200
    },
    {
      "epoch": 7.720174041001265,
      "grad_norm": 1.3977638483047485,
      "learning_rate": 7.528837033282823e-05,
      "loss": 0.5151,
      "step": 729250
    },
    {
      "epoch": 7.7207033627812685,
      "grad_norm": 1.3407680988311768,
      "learning_rate": 7.525533328391937e-05,
      "loss": 0.5018,
      "step": 729300
    },
    {
      "epoch": 7.721232684561271,
      "grad_norm": 1.3323924541473389,
      "learning_rate": 7.522230220072926e-05,
      "loss": 0.513,
      "step": 729350
    },
    {
      "epoch": 7.721762006341275,
      "grad_norm": 1.2795889377593994,
      "learning_rate": 7.518927708438572e-05,
      "loss": 0.5115,
      "step": 729400
    },
    {
      "epoch": 7.722291328121278,
      "grad_norm": 1.296499490737915,
      "learning_rate": 7.51562579360161e-05,
      "loss": 0.5075,
      "step": 729450
    },
    {
      "epoch": 7.722820649901282,
      "grad_norm": 1.3097896575927734,
      "learning_rate": 7.512324475674778e-05,
      "loss": 0.508,
      "step": 729500
    },
    {
      "epoch": 7.722820649901282,
      "eval_loss": 0.31567293405532837,
      "eval_runtime": 46.7512,
      "eval_samples_per_second": 3591.992,
      "eval_steps_per_second": 449.015,
      "step": 729500
    },
    {
      "epoch": 7.723349971681285,
      "grad_norm": 1.263045310974121,
      "learning_rate": 7.509023754770766e-05,
      "loss": 0.5108,
      "step": 729550
    },
    {
      "epoch": 7.723879293461288,
      "grad_norm": 1.3098351955413818,
      "learning_rate": 7.505723631002276e-05,
      "loss": 0.504,
      "step": 729600
    },
    {
      "epoch": 7.724408615241291,
      "grad_norm": 1.3598190546035767,
      "learning_rate": 7.502424104481958e-05,
      "loss": 0.5099,
      "step": 729650
    },
    {
      "epoch": 7.724937937021295,
      "grad_norm": 1.2838853597640991,
      "learning_rate": 7.499125175322474e-05,
      "loss": 0.5055,
      "step": 729700
    },
    {
      "epoch": 7.725467258801298,
      "grad_norm": 1.4231030941009521,
      "learning_rate": 7.49582684363643e-05,
      "loss": 0.505,
      "step": 729750
    },
    {
      "epoch": 7.725996580581302,
      "grad_norm": 1.3008713722229004,
      "learning_rate": 7.492529109536444e-05,
      "loss": 0.5008,
      "step": 729800
    },
    {
      "epoch": 7.726525902361304,
      "grad_norm": 1.1988176107406616,
      "learning_rate": 7.489231973135085e-05,
      "loss": 0.5061,
      "step": 729850
    },
    {
      "epoch": 7.727055224141308,
      "grad_norm": 1.2116154432296753,
      "learning_rate": 7.485935434544927e-05,
      "loss": 0.5128,
      "step": 729900
    },
    {
      "epoch": 7.727584545921311,
      "grad_norm": 1.189805269241333,
      "learning_rate": 7.482639493878519e-05,
      "loss": 0.5048,
      "step": 729950
    },
    {
      "epoch": 7.728113867701314,
      "grad_norm": 1.3109034299850464,
      "learning_rate": 7.479344151248362e-05,
      "loss": 0.509,
      "step": 730000
    },
    {
      "epoch": 7.728113867701314,
      "eval_loss": 0.3143213391304016,
      "eval_runtime": 46.8406,
      "eval_samples_per_second": 3585.139,
      "eval_steps_per_second": 448.158,
      "step": 730000
    },
    {
      "epoch": 7.728643189481318,
      "grad_norm": 1.3344964981079102,
      "learning_rate": 7.476049406766975e-05,
      "loss": 0.5254,
      "step": 730050
    },
    {
      "epoch": 7.7291725112613205,
      "grad_norm": 1.2583904266357422,
      "learning_rate": 7.47275526054684e-05,
      "loss": 0.5151,
      "step": 730100
    },
    {
      "epoch": 7.729701833041324,
      "grad_norm": 1.3740485906600952,
      "learning_rate": 7.469461712700404e-05,
      "loss": 0.5051,
      "step": 730150
    },
    {
      "epoch": 7.730231154821327,
      "grad_norm": 1.3213961124420166,
      "learning_rate": 7.466168763340125e-05,
      "loss": 0.5112,
      "step": 730200
    },
    {
      "epoch": 7.730760476601331,
      "grad_norm": 1.3807933330535889,
      "learning_rate": 7.462876412578407e-05,
      "loss": 0.5098,
      "step": 730250
    },
    {
      "epoch": 7.731289798381334,
      "grad_norm": 1.308395504951477,
      "learning_rate": 7.459584660527663e-05,
      "loss": 0.5056,
      "step": 730300
    },
    {
      "epoch": 7.7318191201613375,
      "grad_norm": 1.3187867403030396,
      "learning_rate": 7.456293507300257e-05,
      "loss": 0.5176,
      "step": 730350
    },
    {
      "epoch": 7.73234844194134,
      "grad_norm": 1.2032699584960938,
      "learning_rate": 7.453002953008567e-05,
      "loss": 0.5036,
      "step": 730400
    },
    {
      "epoch": 7.732877763721344,
      "grad_norm": 1.2145493030548096,
      "learning_rate": 7.449712997764913e-05,
      "loss": 0.5127,
      "step": 730450
    },
    {
      "epoch": 7.733407085501347,
      "grad_norm": 1.1876864433288574,
      "learning_rate": 7.446423641681627e-05,
      "loss": 0.5167,
      "step": 730500
    },
    {
      "epoch": 7.733407085501347,
      "eval_loss": 0.3148697316646576,
      "eval_runtime": 46.8496,
      "eval_samples_per_second": 3584.449,
      "eval_steps_per_second": 448.072,
      "step": 730500
    },
    {
      "epoch": 7.733936407281351,
      "grad_norm": 1.2211108207702637,
      "learning_rate": 7.443134884870992e-05,
      "loss": 0.5133,
      "step": 730550
    },
    {
      "epoch": 7.734465729061354,
      "grad_norm": 1.1839375495910645,
      "learning_rate": 7.439846727445305e-05,
      "loss": 0.5059,
      "step": 730600
    },
    {
      "epoch": 7.734995050841357,
      "grad_norm": 1.2578142881393433,
      "learning_rate": 7.436559169516798e-05,
      "loss": 0.5031,
      "step": 730650
    },
    {
      "epoch": 7.73552437262136,
      "grad_norm": 1.3000514507293701,
      "learning_rate": 7.43327221119773e-05,
      "loss": 0.5038,
      "step": 730700
    },
    {
      "epoch": 7.736053694401363,
      "grad_norm": 1.378668189048767,
      "learning_rate": 7.429985852600299e-05,
      "loss": 0.512,
      "step": 730750
    },
    {
      "epoch": 7.736583016181367,
      "grad_norm": 1.2821967601776123,
      "learning_rate": 7.426700093836714e-05,
      "loss": 0.513,
      "step": 730800
    },
    {
      "epoch": 7.73711233796137,
      "grad_norm": 1.2997699975967407,
      "learning_rate": 7.423414935019135e-05,
      "loss": 0.5044,
      "step": 730850
    },
    {
      "epoch": 7.7376416597413735,
      "grad_norm": 1.3237141370773315,
      "learning_rate": 7.420130376259734e-05,
      "loss": 0.5017,
      "step": 730900
    },
    {
      "epoch": 7.738170981521376,
      "grad_norm": 1.3203128576278687,
      "learning_rate": 7.416846417670625e-05,
      "loss": 0.5008,
      "step": 730950
    },
    {
      "epoch": 7.73870030330138,
      "grad_norm": 1.4527661800384521,
      "learning_rate": 7.413563059363939e-05,
      "loss": 0.5167,
      "step": 731000
    },
    {
      "epoch": 7.73870030330138,
      "eval_loss": 0.31499791145324707,
      "eval_runtime": 46.8855,
      "eval_samples_per_second": 3581.705,
      "eval_steps_per_second": 447.729,
      "step": 731000
    },
    {
      "epoch": 7.739229625081383,
      "grad_norm": 1.1508383750915527,
      "learning_rate": 7.410280301451753e-05,
      "loss": 0.5008,
      "step": 731050
    },
    {
      "epoch": 7.739758946861387,
      "grad_norm": 1.2757147550582886,
      "learning_rate": 7.406998144046153e-05,
      "loss": 0.5114,
      "step": 731100
    },
    {
      "epoch": 7.74028826864139,
      "grad_norm": 1.4776719808578491,
      "learning_rate": 7.40371658725918e-05,
      "loss": 0.51,
      "step": 731150
    },
    {
      "epoch": 7.740817590421393,
      "grad_norm": 1.2328215837478638,
      "learning_rate": 7.400501244436111e-05,
      "loss": 0.5092,
      "step": 731200
    },
    {
      "epoch": 7.741346912201396,
      "grad_norm": 1.3563486337661743,
      "learning_rate": 7.397220877204519e-05,
      "loss": 0.5018,
      "step": 731250
    },
    {
      "epoch": 7.7418762339814,
      "grad_norm": 1.2512136697769165,
      "learning_rate": 7.393941110925361e-05,
      "loss": 0.5099,
      "step": 731300
    },
    {
      "epoch": 7.742405555761403,
      "grad_norm": 1.3984110355377197,
      "learning_rate": 7.390661945710588e-05,
      "loss": 0.5108,
      "step": 731350
    },
    {
      "epoch": 7.742934877541407,
      "grad_norm": 1.3795732259750366,
      "learning_rate": 7.387383381672166e-05,
      "loss": 0.5101,
      "step": 731400
    },
    {
      "epoch": 7.7434641993214095,
      "grad_norm": 1.3978681564331055,
      "learning_rate": 7.384105418922007e-05,
      "loss": 0.5146,
      "step": 731450
    },
    {
      "epoch": 7.743993521101412,
      "grad_norm": 1.3700038194656372,
      "learning_rate": 7.380828057572037e-05,
      "loss": 0.5071,
      "step": 731500
    },
    {
      "epoch": 7.743993521101412,
      "eval_loss": 0.31374454498291016,
      "eval_runtime": 46.7993,
      "eval_samples_per_second": 3588.304,
      "eval_steps_per_second": 448.554,
      "step": 731500
    },
    {
      "epoch": 7.744522842881416,
      "grad_norm": 1.288308024406433,
      "learning_rate": 7.377551297734129e-05,
      "loss": 0.5021,
      "step": 731550
    },
    {
      "epoch": 7.745052164661419,
      "grad_norm": 1.1888459920883179,
      "learning_rate": 7.374275139520162e-05,
      "loss": 0.5122,
      "step": 731600
    },
    {
      "epoch": 7.745581486441423,
      "grad_norm": 1.3330198526382446,
      "learning_rate": 7.370999583041973e-05,
      "loss": 0.5086,
      "step": 731650
    },
    {
      "epoch": 7.746110808221426,
      "grad_norm": 1.4096945524215698,
      "learning_rate": 7.367724628411399e-05,
      "loss": 0.5172,
      "step": 731700
    },
    {
      "epoch": 7.746640130001429,
      "grad_norm": 1.2883778810501099,
      "learning_rate": 7.364450275740231e-05,
      "loss": 0.5096,
      "step": 731750
    },
    {
      "epoch": 7.747169451781432,
      "grad_norm": 1.3700670003890991,
      "learning_rate": 7.361176525140273e-05,
      "loss": 0.5044,
      "step": 731800
    },
    {
      "epoch": 7.747698773561436,
      "grad_norm": 1.3998475074768066,
      "learning_rate": 7.357968833789496e-05,
      "loss": 0.5158,
      "step": 731850
    },
    {
      "epoch": 7.748228095341439,
      "grad_norm": 1.289359211921692,
      "learning_rate": 7.354696275620216e-05,
      "loss": 0.5049,
      "step": 731900
    },
    {
      "epoch": 7.748757417121443,
      "grad_norm": 1.4666953086853027,
      "learning_rate": 7.351424319855137e-05,
      "loss": 0.5158,
      "step": 731950
    },
    {
      "epoch": 7.7492867389014455,
      "grad_norm": 1.3383896350860596,
      "learning_rate": 7.348152966605953e-05,
      "loss": 0.5117,
      "step": 732000
    },
    {
      "epoch": 7.7492867389014455,
      "eval_loss": 0.3146815598011017,
      "eval_runtime": 46.8684,
      "eval_samples_per_second": 3583.009,
      "eval_steps_per_second": 447.892,
      "step": 732000
    },
    {
      "epoch": 7.749816060681449,
      "grad_norm": 1.2491447925567627,
      "learning_rate": 7.344882215984362e-05,
      "loss": 0.5079,
      "step": 732050
    },
    {
      "epoch": 7.750345382461452,
      "grad_norm": 1.106428623199463,
      "learning_rate": 7.341612068102007e-05,
      "loss": 0.5127,
      "step": 732100
    },
    {
      "epoch": 7.750874704241456,
      "grad_norm": 1.2482143640518188,
      "learning_rate": 7.338342523070552e-05,
      "loss": 0.5084,
      "step": 732150
    },
    {
      "epoch": 7.751404026021459,
      "grad_norm": 1.4250069856643677,
      "learning_rate": 7.335073581001594e-05,
      "loss": 0.5002,
      "step": 732200
    },
    {
      "epoch": 7.751933347801462,
      "grad_norm": 1.293325662612915,
      "learning_rate": 7.331805242006756e-05,
      "loss": 0.5072,
      "step": 732250
    },
    {
      "epoch": 7.752462669581465,
      "grad_norm": 1.3879393339157104,
      "learning_rate": 7.3285375061976e-05,
      "loss": 0.5112,
      "step": 732300
    },
    {
      "epoch": 7.752991991361468,
      "grad_norm": 1.3099912405014038,
      "learning_rate": 7.325270373685697e-05,
      "loss": 0.5144,
      "step": 732350
    },
    {
      "epoch": 7.753521313141472,
      "grad_norm": 1.3099786043167114,
      "learning_rate": 7.322003844582578e-05,
      "loss": 0.5077,
      "step": 732400
    },
    {
      "epoch": 7.754050634921475,
      "grad_norm": 1.3954776525497437,
      "learning_rate": 7.318737918999768e-05,
      "loss": 0.5201,
      "step": 732450
    },
    {
      "epoch": 7.754579956701479,
      "grad_norm": 1.2770119905471802,
      "learning_rate": 7.315472597048755e-05,
      "loss": 0.5103,
      "step": 732500
    },
    {
      "epoch": 7.754579956701479,
      "eval_loss": 0.3136572539806366,
      "eval_runtime": 46.7821,
      "eval_samples_per_second": 3589.624,
      "eval_steps_per_second": 448.719,
      "step": 732500
    },
    {
      "epoch": 7.7551092784814815,
      "grad_norm": 1.348628044128418,
      "learning_rate": 7.312207878841024e-05,
      "loss": 0.5062,
      "step": 732550
    },
    {
      "epoch": 7.755638600261485,
      "grad_norm": 1.270280122756958,
      "learning_rate": 7.308943764488036e-05,
      "loss": 0.5086,
      "step": 732600
    },
    {
      "epoch": 7.756167922041488,
      "grad_norm": 1.4031128883361816,
      "learning_rate": 7.305680254101211e-05,
      "loss": 0.5144,
      "step": 732650
    },
    {
      "epoch": 7.756697243821492,
      "grad_norm": 1.4271560907363892,
      "learning_rate": 7.302417347791973e-05,
      "loss": 0.509,
      "step": 732700
    },
    {
      "epoch": 7.757226565601495,
      "grad_norm": 1.4486987590789795,
      "learning_rate": 7.299155045671724e-05,
      "loss": 0.5254,
      "step": 732750
    },
    {
      "epoch": 7.7577558873814985,
      "grad_norm": 1.3173213005065918,
      "learning_rate": 7.295893347851823e-05,
      "loss": 0.5143,
      "step": 732800
    },
    {
      "epoch": 7.758285209161501,
      "grad_norm": 1.3326306343078613,
      "learning_rate": 7.292632254443638e-05,
      "loss": 0.5073,
      "step": 732850
    },
    {
      "epoch": 7.758814530941505,
      "grad_norm": 1.285980224609375,
      "learning_rate": 7.289371765558486e-05,
      "loss": 0.5063,
      "step": 732900
    },
    {
      "epoch": 7.759343852721508,
      "grad_norm": 1.4216629266738892,
      "learning_rate": 7.286111881307694e-05,
      "loss": 0.5037,
      "step": 732950
    },
    {
      "epoch": 7.759873174501511,
      "grad_norm": 1.2882823944091797,
      "learning_rate": 7.282852601802539e-05,
      "loss": 0.5156,
      "step": 733000
    },
    {
      "epoch": 7.759873174501511,
      "eval_loss": 0.3133352994918823,
      "eval_runtime": 46.7401,
      "eval_samples_per_second": 3592.85,
      "eval_steps_per_second": 449.122,
      "step": 733000
    },
    {
      "epoch": 7.760402496281515,
      "grad_norm": 1.1970735788345337,
      "learning_rate": 7.279593927154307e-05,
      "loss": 0.5061,
      "step": 733050
    },
    {
      "epoch": 7.760931818061517,
      "grad_norm": 1.5376955270767212,
      "learning_rate": 7.276335857474231e-05,
      "loss": 0.5124,
      "step": 733100
    },
    {
      "epoch": 7.761461139841521,
      "grad_norm": 1.349698543548584,
      "learning_rate": 7.273078392873556e-05,
      "loss": 0.5078,
      "step": 733150
    },
    {
      "epoch": 7.761990461621524,
      "grad_norm": 1.2801170349121094,
      "learning_rate": 7.269821533463475e-05,
      "loss": 0.5104,
      "step": 733200
    },
    {
      "epoch": 7.762519783401528,
      "grad_norm": 1.382216215133667,
      "learning_rate": 7.266565279355194e-05,
      "loss": 0.5071,
      "step": 733250
    },
    {
      "epoch": 7.763049105181531,
      "grad_norm": 1.3844059705734253,
      "learning_rate": 7.263309630659862e-05,
      "loss": 0.5113,
      "step": 733300
    },
    {
      "epoch": 7.763578426961534,
      "grad_norm": 1.3644834756851196,
      "learning_rate": 7.260054587488643e-05,
      "loss": 0.5081,
      "step": 733350
    },
    {
      "epoch": 7.764107748741537,
      "grad_norm": 1.4283030033111572,
      "learning_rate": 7.256800149952647e-05,
      "loss": 0.5147,
      "step": 733400
    },
    {
      "epoch": 7.764637070521541,
      "grad_norm": 1.3187917470932007,
      "learning_rate": 7.253546318162993e-05,
      "loss": 0.514,
      "step": 733450
    },
    {
      "epoch": 7.765166392301544,
      "grad_norm": 1.322601556777954,
      "learning_rate": 7.250293092230753e-05,
      "loss": 0.5092,
      "step": 733500
    },
    {
      "epoch": 7.765166392301544,
      "eval_loss": 0.3143133521080017,
      "eval_runtime": 46.8141,
      "eval_samples_per_second": 3587.17,
      "eval_steps_per_second": 448.412,
      "step": 733500
    },
    {
      "epoch": 7.765695714081548,
      "grad_norm": 1.4695576429367065,
      "learning_rate": 7.247040472267005e-05,
      "loss": 0.5084,
      "step": 733550
    },
    {
      "epoch": 7.7662250358615506,
      "grad_norm": 1.3782047033309937,
      "learning_rate": 7.243788458382778e-05,
      "loss": 0.511,
      "step": 733600
    },
    {
      "epoch": 7.766754357641554,
      "grad_norm": 1.289080023765564,
      "learning_rate": 7.240537050689106e-05,
      "loss": 0.5122,
      "step": 733650
    },
    {
      "epoch": 7.767283679421557,
      "grad_norm": 1.363664984703064,
      "learning_rate": 7.237286249296979e-05,
      "loss": 0.5077,
      "step": 733700
    },
    {
      "epoch": 7.76781300120156,
      "grad_norm": 1.3993234634399414,
      "learning_rate": 7.234036054317394e-05,
      "loss": 0.5173,
      "step": 733750
    },
    {
      "epoch": 7.768342322981564,
      "grad_norm": 1.2623709440231323,
      "learning_rate": 7.230786465861295e-05,
      "loss": 0.5086,
      "step": 733800
    },
    {
      "epoch": 7.768871644761567,
      "grad_norm": 1.4049140214920044,
      "learning_rate": 7.227537484039637e-05,
      "loss": 0.5126,
      "step": 733850
    },
    {
      "epoch": 7.76940096654157,
      "grad_norm": 1.3891468048095703,
      "learning_rate": 7.224289108963322e-05,
      "loss": 0.5072,
      "step": 733900
    },
    {
      "epoch": 7.769930288321573,
      "grad_norm": 1.4391793012619019,
      "learning_rate": 7.221041340743268e-05,
      "loss": 0.5083,
      "step": 733950
    },
    {
      "epoch": 7.770459610101577,
      "grad_norm": 1.3805263042449951,
      "learning_rate": 7.21779417949033e-05,
      "loss": 0.5117,
      "step": 734000
    },
    {
      "epoch": 7.770459610101577,
      "eval_loss": 0.3136817514896393,
      "eval_runtime": 46.9386,
      "eval_samples_per_second": 3577.653,
      "eval_steps_per_second": 447.223,
      "step": 734000
    },
    {
      "epoch": 7.77098893188158,
      "grad_norm": 1.396446704864502,
      "learning_rate": 7.21454762531539e-05,
      "loss": 0.5078,
      "step": 734050
    },
    {
      "epoch": 7.771518253661584,
      "grad_norm": 1.1400220394134521,
      "learning_rate": 7.211301678329263e-05,
      "loss": 0.5085,
      "step": 734100
    },
    {
      "epoch": 7.7720475754415865,
      "grad_norm": 1.3444935083389282,
      "learning_rate": 7.208056338642771e-05,
      "loss": 0.506,
      "step": 734150
    },
    {
      "epoch": 7.77257689722159,
      "grad_norm": 1.3213053941726685,
      "learning_rate": 7.204876495058904e-05,
      "loss": 0.5082,
      "step": 734200
    },
    {
      "epoch": 7.773106219001593,
      "grad_norm": 1.2972428798675537,
      "learning_rate": 7.201632358152541e-05,
      "loss": 0.5072,
      "step": 734250
    },
    {
      "epoch": 7.773635540781597,
      "grad_norm": 1.5008811950683594,
      "learning_rate": 7.198388828875929e-05,
      "loss": 0.511,
      "step": 734300
    },
    {
      "epoch": 7.7741648625616,
      "grad_norm": 1.103682518005371,
      "learning_rate": 7.195145907339787e-05,
      "loss": 0.5076,
      "step": 734350
    },
    {
      "epoch": 7.7746941843416035,
      "grad_norm": 1.4348136186599731,
      "learning_rate": 7.191903593654839e-05,
      "loss": 0.5083,
      "step": 734400
    },
    {
      "epoch": 7.775223506121606,
      "grad_norm": 1.2309074401855469,
      "learning_rate": 7.188661887931766e-05,
      "loss": 0.5079,
      "step": 734450
    },
    {
      "epoch": 7.775752827901609,
      "grad_norm": 1.159379482269287,
      "learning_rate": 7.185420790281253e-05,
      "loss": 0.508,
      "step": 734500
    },
    {
      "epoch": 7.775752827901609,
      "eval_loss": 0.3131958842277527,
      "eval_runtime": 46.836,
      "eval_samples_per_second": 3585.488,
      "eval_steps_per_second": 448.202,
      "step": 734500
    },
    {
      "epoch": 7.776282149681613,
      "grad_norm": 1.2507377862930298,
      "learning_rate": 7.182180300813931e-05,
      "loss": 0.5025,
      "step": 734550
    },
    {
      "epoch": 7.776811471461616,
      "grad_norm": 1.3622249364852905,
      "learning_rate": 7.17894041964044e-05,
      "loss": 0.5105,
      "step": 734600
    },
    {
      "epoch": 7.77734079324162,
      "grad_norm": 1.4065663814544678,
      "learning_rate": 7.175701146871394e-05,
      "loss": 0.5045,
      "step": 734650
    },
    {
      "epoch": 7.7778701150216225,
      "grad_norm": 1.318367838859558,
      "learning_rate": 7.172462482617368e-05,
      "loss": 0.5201,
      "step": 734700
    },
    {
      "epoch": 7.778399436801626,
      "grad_norm": 1.326518177986145,
      "learning_rate": 7.169224426988933e-05,
      "loss": 0.5113,
      "step": 734750
    },
    {
      "epoch": 7.778928758581629,
      "grad_norm": 1.3313926458358765,
      "learning_rate": 7.165986980096645e-05,
      "loss": 0.5181,
      "step": 734800
    },
    {
      "epoch": 7.779458080361633,
      "grad_norm": 1.4138551950454712,
      "learning_rate": 7.162750142051014e-05,
      "loss": 0.5134,
      "step": 734850
    },
    {
      "epoch": 7.779987402141636,
      "grad_norm": 1.3560075759887695,
      "learning_rate": 7.15951391296256e-05,
      "loss": 0.5085,
      "step": 734900
    },
    {
      "epoch": 7.7805167239216395,
      "grad_norm": 1.263495922088623,
      "learning_rate": 7.156278292941748e-05,
      "loss": 0.5019,
      "step": 734950
    },
    {
      "epoch": 7.781046045701642,
      "grad_norm": 1.3828222751617432,
      "learning_rate": 7.153043282099058e-05,
      "loss": 0.506,
      "step": 735000
    },
    {
      "epoch": 7.781046045701642,
      "eval_loss": 0.3127366602420807,
      "eval_runtime": 46.7892,
      "eval_samples_per_second": 3589.075,
      "eval_steps_per_second": 448.65,
      "step": 735000
    },
    {
      "epoch": 7.781575367481646,
      "grad_norm": 1.2843947410583496,
      "learning_rate": 7.14980888054492e-05,
      "loss": 0.5068,
      "step": 735050
    },
    {
      "epoch": 7.782104689261649,
      "grad_norm": 1.2606769800186157,
      "learning_rate": 7.146575088389767e-05,
      "loss": 0.5059,
      "step": 735100
    },
    {
      "epoch": 7.782634011041653,
      "grad_norm": 1.3827022314071655,
      "learning_rate": 7.143341905743989e-05,
      "loss": 0.504,
      "step": 735150
    },
    {
      "epoch": 7.783163332821656,
      "grad_norm": 1.398992657661438,
      "learning_rate": 7.140109332717973e-05,
      "loss": 0.5072,
      "step": 735200
    },
    {
      "epoch": 7.7836926546016585,
      "grad_norm": 1.3346582651138306,
      "learning_rate": 7.136877369422068e-05,
      "loss": 0.5103,
      "step": 735250
    },
    {
      "epoch": 7.784221976381662,
      "grad_norm": 1.3784974813461304,
      "learning_rate": 7.133646015966624e-05,
      "loss": 0.5149,
      "step": 735300
    },
    {
      "epoch": 7.784751298161665,
      "grad_norm": 1.3650286197662354,
      "learning_rate": 7.130415272461948e-05,
      "loss": 0.5177,
      "step": 735350
    },
    {
      "epoch": 7.785280619941669,
      "grad_norm": 1.3956514596939087,
      "learning_rate": 7.12718513901835e-05,
      "loss": 0.5117,
      "step": 735400
    },
    {
      "epoch": 7.785809941721672,
      "grad_norm": 1.336453914642334,
      "learning_rate": 7.123955615746086e-05,
      "loss": 0.5005,
      "step": 735450
    },
    {
      "epoch": 7.7863392635016755,
      "grad_norm": 1.3018345832824707,
      "learning_rate": 7.120726702755431e-05,
      "loss": 0.5101,
      "step": 735500
    },
    {
      "epoch": 7.7863392635016755,
      "eval_loss": 0.31307217478752136,
      "eval_runtime": 46.8562,
      "eval_samples_per_second": 3583.948,
      "eval_steps_per_second": 448.009,
      "step": 735500
    },
    {
      "epoch": 7.786868585281678,
      "grad_norm": 1.3356462717056274,
      "learning_rate": 7.1174984001566e-05,
      "loss": 0.5073,
      "step": 735550
    },
    {
      "epoch": 7.787397907061682,
      "grad_norm": 1.2759402990341187,
      "learning_rate": 7.114270708059822e-05,
      "loss": 0.5031,
      "step": 735600
    },
    {
      "epoch": 7.787927228841685,
      "grad_norm": 1.4085636138916016,
      "learning_rate": 7.111043626575279e-05,
      "loss": 0.512,
      "step": 735650
    },
    {
      "epoch": 7.788456550621689,
      "grad_norm": 1.3113033771514893,
      "learning_rate": 7.107817155813151e-05,
      "loss": 0.5136,
      "step": 735700
    },
    {
      "epoch": 7.788985872401692,
      "grad_norm": 1.4409549236297607,
      "learning_rate": 7.104591295883575e-05,
      "loss": 0.4992,
      "step": 735750
    },
    {
      "epoch": 7.789515194181695,
      "grad_norm": 1.4673835039138794,
      "learning_rate": 7.101366046896699e-05,
      "loss": 0.5136,
      "step": 735800
    },
    {
      "epoch": 7.790044515961698,
      "grad_norm": 1.2756342887878418,
      "learning_rate": 7.098141408962613e-05,
      "loss": 0.5043,
      "step": 735850
    },
    {
      "epoch": 7.790573837741702,
      "grad_norm": 1.417833685874939,
      "learning_rate": 7.094917382191423e-05,
      "loss": 0.5093,
      "step": 735900
    },
    {
      "epoch": 7.791103159521705,
      "grad_norm": 1.1992993354797363,
      "learning_rate": 7.091693966693177e-05,
      "loss": 0.5045,
      "step": 735950
    },
    {
      "epoch": 7.791632481301708,
      "grad_norm": 1.3454444408416748,
      "learning_rate": 7.088471162577942e-05,
      "loss": 0.5071,
      "step": 736000
    },
    {
      "epoch": 7.791632481301708,
      "eval_loss": 0.3131279945373535,
      "eval_runtime": 46.7799,
      "eval_samples_per_second": 3589.786,
      "eval_steps_per_second": 448.739,
      "step": 736000
    },
    {
      "epoch": 7.7921618030817115,
      "grad_norm": 1.2713181972503662,
      "learning_rate": 7.085248969955724e-05,
      "loss": 0.5005,
      "step": 736050
    },
    {
      "epoch": 7.792691124861714,
      "grad_norm": 1.3502917289733887,
      "learning_rate": 7.082027388936535e-05,
      "loss": 0.5049,
      "step": 736100
    },
    {
      "epoch": 7.793220446641718,
      "grad_norm": 1.1406662464141846,
      "learning_rate": 7.078806419630368e-05,
      "loss": 0.5068,
      "step": 736150
    },
    {
      "epoch": 7.793749768421721,
      "grad_norm": 1.33278489112854,
      "learning_rate": 7.075650463300259e-05,
      "loss": 0.5021,
      "step": 736200
    },
    {
      "epoch": 7.794279090201725,
      "grad_norm": 1.212531566619873,
      "learning_rate": 7.072430705510244e-05,
      "loss": 0.5154,
      "step": 736250
    },
    {
      "epoch": 7.794808411981728,
      "grad_norm": 1.5496057271957397,
      "learning_rate": 7.069211559760876e-05,
      "loss": 0.516,
      "step": 736300
    },
    {
      "epoch": 7.795337733761731,
      "grad_norm": 1.3450602293014526,
      "learning_rate": 7.065993026162044e-05,
      "loss": 0.5041,
      "step": 736350
    },
    {
      "epoch": 7.795867055541734,
      "grad_norm": 1.48490571975708,
      "learning_rate": 7.06277510482364e-05,
      "loss": 0.5165,
      "step": 736400
    },
    {
      "epoch": 7.796396377321738,
      "grad_norm": 1.3661142587661743,
      "learning_rate": 7.059557795855506e-05,
      "loss": 0.5087,
      "step": 736450
    },
    {
      "epoch": 7.796925699101741,
      "grad_norm": 1.357440710067749,
      "learning_rate": 7.0563410993675e-05,
      "loss": 0.5048,
      "step": 736500
    },
    {
      "epoch": 7.796925699101741,
      "eval_loss": 0.3126331865787506,
      "eval_runtime": 46.8952,
      "eval_samples_per_second": 3580.966,
      "eval_steps_per_second": 447.637,
      "step": 736500
    },
    {
      "epoch": 7.797455020881745,
      "grad_norm": 1.3759245872497559,
      "learning_rate": 7.053125015469419e-05,
      "loss": 0.5011,
      "step": 736550
    },
    {
      "epoch": 7.7979843426617474,
      "grad_norm": 1.240808129310608,
      "learning_rate": 7.049909544271075e-05,
      "loss": 0.4938,
      "step": 736600
    },
    {
      "epoch": 7.798513664441751,
      "grad_norm": 1.2681522369384766,
      "learning_rate": 7.046694685882229e-05,
      "loss": 0.5163,
      "step": 736650
    },
    {
      "epoch": 7.799042986221754,
      "grad_norm": 1.353453278541565,
      "learning_rate": 7.04348044041265e-05,
      "loss": 0.5083,
      "step": 736700
    },
    {
      "epoch": 7.799572308001757,
      "grad_norm": 1.4708784818649292,
      "learning_rate": 7.040266807972057e-05,
      "loss": 0.5017,
      "step": 736750
    },
    {
      "epoch": 7.800101629781761,
      "grad_norm": 1.539750337600708,
      "learning_rate": 7.037053788670167e-05,
      "loss": 0.5051,
      "step": 736800
    },
    {
      "epoch": 7.800630951561764,
      "grad_norm": 1.2361502647399902,
      "learning_rate": 7.033841382616682e-05,
      "loss": 0.4999,
      "step": 736850
    },
    {
      "epoch": 7.801160273341767,
      "grad_norm": 1.260157585144043,
      "learning_rate": 7.030629589921254e-05,
      "loss": 0.5019,
      "step": 736900
    },
    {
      "epoch": 7.80168959512177,
      "grad_norm": 1.4896283149719238,
      "learning_rate": 7.02741841069355e-05,
      "loss": 0.5054,
      "step": 736950
    },
    {
      "epoch": 7.802218916901774,
      "grad_norm": 1.3928929567337036,
      "learning_rate": 7.024207845043182e-05,
      "loss": 0.517,
      "step": 737000
    },
    {
      "epoch": 7.802218916901774,
      "eval_loss": 0.31344568729400635,
      "eval_runtime": 46.942,
      "eval_samples_per_second": 3577.396,
      "eval_steps_per_second": 447.19,
      "step": 737000
    },
    {
      "epoch": 7.802748238681777,
      "grad_norm": 1.405301570892334,
      "learning_rate": 7.020997893079768e-05,
      "loss": 0.502,
      "step": 737050
    },
    {
      "epoch": 7.803277560461781,
      "grad_norm": 1.3601258993148804,
      "learning_rate": 7.017788554912896e-05,
      "loss": 0.5097,
      "step": 737100
    },
    {
      "epoch": 7.803806882241783,
      "grad_norm": 1.3561052083969116,
      "learning_rate": 7.014579830652123e-05,
      "loss": 0.5069,
      "step": 737150
    },
    {
      "epoch": 7.804336204021787,
      "grad_norm": 1.3364953994750977,
      "learning_rate": 7.011371720407006e-05,
      "loss": 0.5126,
      "step": 737200
    },
    {
      "epoch": 7.80486552580179,
      "grad_norm": 1.3494094610214233,
      "learning_rate": 7.008164224287056e-05,
      "loss": 0.5101,
      "step": 737250
    },
    {
      "epoch": 7.805394847581794,
      "grad_norm": 1.2788108587265015,
      "learning_rate": 7.004957342401786e-05,
      "loss": 0.5049,
      "step": 737300
    },
    {
      "epoch": 7.805924169361797,
      "grad_norm": 1.2999608516693115,
      "learning_rate": 7.001751074860666e-05,
      "loss": 0.5039,
      "step": 737350
    },
    {
      "epoch": 7.8064534911418,
      "grad_norm": 1.2935912609100342,
      "learning_rate": 6.998545421773169e-05,
      "loss": 0.5008,
      "step": 737400
    },
    {
      "epoch": 7.806982812921803,
      "grad_norm": 1.3882924318313599,
      "learning_rate": 6.995340383248724e-05,
      "loss": 0.5185,
      "step": 737450
    },
    {
      "epoch": 7.807512134701806,
      "grad_norm": 1.4287022352218628,
      "learning_rate": 6.992135959396761e-05,
      "loss": 0.5108,
      "step": 737500
    },
    {
      "epoch": 7.807512134701806,
      "eval_loss": 0.3122771084308624,
      "eval_runtime": 46.774,
      "eval_samples_per_second": 3590.243,
      "eval_steps_per_second": 448.796,
      "step": 737500
    },
    {
      "epoch": 7.80804145648181,
      "grad_norm": 1.3402340412139893,
      "learning_rate": 6.988932150326668e-05,
      "loss": 0.5135,
      "step": 737550
    },
    {
      "epoch": 7.808570778261813,
      "grad_norm": 1.3972809314727783,
      "learning_rate": 6.98572895614783e-05,
      "loss": 0.5176,
      "step": 737600
    },
    {
      "epoch": 7.8091001000418165,
      "grad_norm": 1.3960610628128052,
      "learning_rate": 6.982526376969595e-05,
      "loss": 0.507,
      "step": 737650
    },
    {
      "epoch": 7.809629421821819,
      "grad_norm": 1.3645464181900024,
      "learning_rate": 6.979324412901305e-05,
      "loss": 0.5021,
      "step": 737700
    },
    {
      "epoch": 7.810158743601823,
      "grad_norm": 1.3381450176239014,
      "learning_rate": 6.976123064052267e-05,
      "loss": 0.515,
      "step": 737750
    },
    {
      "epoch": 7.810688065381826,
      "grad_norm": 1.3477399349212646,
      "learning_rate": 6.972922330531784e-05,
      "loss": 0.5063,
      "step": 737800
    },
    {
      "epoch": 7.81121738716183,
      "grad_norm": 1.3889875411987305,
      "learning_rate": 6.969722212449112e-05,
      "loss": 0.5138,
      "step": 737850
    },
    {
      "epoch": 7.811746708941833,
      "grad_norm": 1.3101844787597656,
      "learning_rate": 6.96652270991352e-05,
      "loss": 0.5058,
      "step": 737900
    },
    {
      "epoch": 7.812276030721836,
      "grad_norm": 1.4707002639770508,
      "learning_rate": 6.963323823034223e-05,
      "loss": 0.5138,
      "step": 737950
    },
    {
      "epoch": 7.812805352501839,
      "grad_norm": 1.3468455076217651,
      "learning_rate": 6.96012555192044e-05,
      "loss": 0.5027,
      "step": 738000
    },
    {
      "epoch": 7.812805352501839,
      "eval_loss": 0.3120238780975342,
      "eval_runtime": 46.9402,
      "eval_samples_per_second": 3577.527,
      "eval_steps_per_second": 447.207,
      "step": 738000
    },
    {
      "epoch": 7.813334674281843,
      "grad_norm": 1.4655663967132568,
      "learning_rate": 6.95692789668135e-05,
      "loss": 0.5021,
      "step": 738050
    },
    {
      "epoch": 7.813863996061846,
      "grad_norm": 1.4268522262573242,
      "learning_rate": 6.953730857426133e-05,
      "loss": 0.5109,
      "step": 738100
    },
    {
      "epoch": 7.81439331784185,
      "grad_norm": 1.2926493883132935,
      "learning_rate": 6.950534434263917e-05,
      "loss": 0.506,
      "step": 738150
    },
    {
      "epoch": 7.8149226396218525,
      "grad_norm": 1.1466045379638672,
      "learning_rate": 6.947338627303842e-05,
      "loss": 0.5051,
      "step": 738200
    },
    {
      "epoch": 7.815451961401855,
      "grad_norm": 1.1887705326080322,
      "learning_rate": 6.944143436655001e-05,
      "loss": 0.5021,
      "step": 738250
    },
    {
      "epoch": 7.815981283181859,
      "grad_norm": 1.2819393873214722,
      "learning_rate": 6.940948862426488e-05,
      "loss": 0.5067,
      "step": 738300
    },
    {
      "epoch": 7.816510604961862,
      "grad_norm": 1.4150060415267944,
      "learning_rate": 6.937754904727348e-05,
      "loss": 0.5085,
      "step": 738350
    },
    {
      "epoch": 7.817039926741866,
      "grad_norm": 1.3657394647598267,
      "learning_rate": 6.934561563666641e-05,
      "loss": 0.5033,
      "step": 738400
    },
    {
      "epoch": 7.817569248521869,
      "grad_norm": 1.3917453289031982,
      "learning_rate": 6.93136883935337e-05,
      "loss": 0.5126,
      "step": 738450
    },
    {
      "epoch": 7.818098570301872,
      "grad_norm": 1.3033252954483032,
      "learning_rate": 6.928176731896541e-05,
      "loss": 0.5041,
      "step": 738500
    },
    {
      "epoch": 7.818098570301872,
      "eval_loss": 0.31109559535980225,
      "eval_runtime": 46.7287,
      "eval_samples_per_second": 3593.721,
      "eval_steps_per_second": 449.231,
      "step": 738500
    },
    {
      "epoch": 7.818627892081875,
      "grad_norm": 1.5129766464233398,
      "learning_rate": 6.924985241405135e-05,
      "loss": 0.5096,
      "step": 738550
    },
    {
      "epoch": 7.819157213861879,
      "grad_norm": 1.3522157669067383,
      "learning_rate": 6.9217943679881e-05,
      "loss": 0.5018,
      "step": 738600
    },
    {
      "epoch": 7.819686535641882,
      "grad_norm": 1.3314367532730103,
      "learning_rate": 6.918604111754373e-05,
      "loss": 0.5097,
      "step": 738650
    },
    {
      "epoch": 7.820215857421886,
      "grad_norm": 1.3847811222076416,
      "learning_rate": 6.915414472812878e-05,
      "loss": 0.5113,
      "step": 738700
    },
    {
      "epoch": 7.8207451792018885,
      "grad_norm": 1.241910457611084,
      "learning_rate": 6.912225451272491e-05,
      "loss": 0.512,
      "step": 738750
    },
    {
      "epoch": 7.821274500981892,
      "grad_norm": 1.2787115573883057,
      "learning_rate": 6.909037047242106e-05,
      "loss": 0.5058,
      "step": 738800
    },
    {
      "epoch": 7.821803822761895,
      "grad_norm": 1.1906983852386475,
      "learning_rate": 6.905849260830552e-05,
      "loss": 0.5078,
      "step": 738850
    },
    {
      "epoch": 7.822333144541899,
      "grad_norm": 1.382684588432312,
      "learning_rate": 6.902662092146675e-05,
      "loss": 0.5112,
      "step": 738900
    },
    {
      "epoch": 7.822862466321902,
      "grad_norm": 1.3355430364608765,
      "learning_rate": 6.899475541299268e-05,
      "loss": 0.5101,
      "step": 738950
    },
    {
      "epoch": 7.823391788101905,
      "grad_norm": 1.4393267631530762,
      "learning_rate": 6.896289608397138e-05,
      "loss": 0.5064,
      "step": 739000
    },
    {
      "epoch": 7.823391788101905,
      "eval_loss": 0.3122738003730774,
      "eval_runtime": 46.8686,
      "eval_samples_per_second": 3582.997,
      "eval_steps_per_second": 447.891,
      "step": 739000
    },
    {
      "epoch": 7.823921109881908,
      "grad_norm": 1.346619963645935,
      "learning_rate": 6.893104293549035e-05,
      "loss": 0.5032,
      "step": 739050
    },
    {
      "epoch": 7.824450431661911,
      "grad_norm": 1.2702867984771729,
      "learning_rate": 6.889983284738721e-05,
      "loss": 0.505,
      "step": 739100
    },
    {
      "epoch": 7.824979753441915,
      "grad_norm": 1.3097420930862427,
      "learning_rate": 6.886799193958409e-05,
      "loss": 0.5097,
      "step": 739150
    },
    {
      "epoch": 7.825509075221918,
      "grad_norm": 1.5079576969146729,
      "learning_rate": 6.883615721556125e-05,
      "loss": 0.5056,
      "step": 739200
    },
    {
      "epoch": 7.826038397001922,
      "grad_norm": 1.5598187446594238,
      "learning_rate": 6.880432867640563e-05,
      "loss": 0.4992,
      "step": 739250
    },
    {
      "epoch": 7.8265677187819245,
      "grad_norm": 1.2864197492599487,
      "learning_rate": 6.87725063232037e-05,
      "loss": 0.5023,
      "step": 739300
    },
    {
      "epoch": 7.827097040561928,
      "grad_norm": 1.2926479578018188,
      "learning_rate": 6.874069015704201e-05,
      "loss": 0.5031,
      "step": 739350
    },
    {
      "epoch": 7.827626362341931,
      "grad_norm": 1.267462968826294,
      "learning_rate": 6.870888017900662e-05,
      "loss": 0.4997,
      "step": 739400
    },
    {
      "epoch": 7.828155684121935,
      "grad_norm": 1.3624200820922852,
      "learning_rate": 6.867707639018364e-05,
      "loss": 0.5055,
      "step": 739450
    },
    {
      "epoch": 7.828685005901938,
      "grad_norm": 1.2980798482894897,
      "learning_rate": 6.86452787916587e-05,
      "loss": 0.5061,
      "step": 739500
    },
    {
      "epoch": 7.828685005901938,
      "eval_loss": 0.3120141327381134,
      "eval_runtime": 46.7624,
      "eval_samples_per_second": 3591.131,
      "eval_steps_per_second": 448.907,
      "step": 739500
    },
    {
      "epoch": 7.8292143276819415,
      "grad_norm": 1.4607172012329102,
      "learning_rate": 6.86134873845175e-05,
      "loss": 0.5041,
      "step": 739550
    },
    {
      "epoch": 7.829743649461944,
      "grad_norm": 1.353771686553955,
      "learning_rate": 6.858170216984527e-05,
      "loss": 0.5126,
      "step": 739600
    },
    {
      "epoch": 7.830272971241948,
      "grad_norm": 1.2915669679641724,
      "learning_rate": 6.854992314872724e-05,
      "loss": 0.5069,
      "step": 739650
    },
    {
      "epoch": 7.830802293021951,
      "grad_norm": 1.2638275623321533,
      "learning_rate": 6.851815032224823e-05,
      "loss": 0.5209,
      "step": 739700
    },
    {
      "epoch": 7.831331614801954,
      "grad_norm": 1.43695867061615,
      "learning_rate": 6.848638369149307e-05,
      "loss": 0.5131,
      "step": 739750
    },
    {
      "epoch": 7.831860936581958,
      "grad_norm": 1.3393627405166626,
      "learning_rate": 6.845462325754615e-05,
      "loss": 0.5108,
      "step": 739800
    },
    {
      "epoch": 7.8323902583619605,
      "grad_norm": 1.3452465534210205,
      "learning_rate": 6.84228690214919e-05,
      "loss": 0.5143,
      "step": 739850
    },
    {
      "epoch": 7.832919580141964,
      "grad_norm": 1.3640568256378174,
      "learning_rate": 6.83911209844142e-05,
      "loss": 0.5069,
      "step": 739900
    },
    {
      "epoch": 7.833448901921967,
      "grad_norm": 1.2059741020202637,
      "learning_rate": 6.83593791473971e-05,
      "loss": 0.4965,
      "step": 739950
    },
    {
      "epoch": 7.833978223701971,
      "grad_norm": 1.2473344802856445,
      "learning_rate": 6.832764351152412e-05,
      "loss": 0.5032,
      "step": 740000
    },
    {
      "epoch": 7.833978223701971,
      "eval_loss": 0.311777263879776,
      "eval_runtime": 46.8725,
      "eval_samples_per_second": 3582.695,
      "eval_steps_per_second": 447.853,
      "step": 740000
    },
    {
      "epoch": 7.834507545481974,
      "grad_norm": 1.314771294593811,
      "learning_rate": 6.829591407787885e-05,
      "loss": 0.5041,
      "step": 740050
    },
    {
      "epoch": 7.8350368672619775,
      "grad_norm": 1.2854708433151245,
      "learning_rate": 6.826419084754435e-05,
      "loss": 0.5038,
      "step": 740100
    },
    {
      "epoch": 7.83556618904198,
      "grad_norm": 1.3288702964782715,
      "learning_rate": 6.82324738216038e-05,
      "loss": 0.5077,
      "step": 740150
    },
    {
      "epoch": 7.836095510821984,
      "grad_norm": 1.3671525716781616,
      "learning_rate": 6.820076300113984e-05,
      "loss": 0.4945,
      "step": 740200
    },
    {
      "epoch": 7.836624832601987,
      "grad_norm": 1.3583842515945435,
      "learning_rate": 6.816905838723525e-05,
      "loss": 0.511,
      "step": 740250
    },
    {
      "epoch": 7.837154154381991,
      "grad_norm": 1.4841594696044922,
      "learning_rate": 6.813735998097225e-05,
      "loss": 0.5124,
      "step": 740300
    },
    {
      "epoch": 7.837683476161994,
      "grad_norm": 1.3286885023117065,
      "learning_rate": 6.810566778343316e-05,
      "loss": 0.5032,
      "step": 740350
    },
    {
      "epoch": 7.838212797941997,
      "grad_norm": 1.2922618389129639,
      "learning_rate": 6.807398179569979e-05,
      "loss": 0.5126,
      "step": 740400
    },
    {
      "epoch": 7.838742119722,
      "grad_norm": 1.4424511194229126,
      "learning_rate": 6.804230201885403e-05,
      "loss": 0.5092,
      "step": 740450
    },
    {
      "epoch": 7.839271441502003,
      "grad_norm": 1.3286314010620117,
      "learning_rate": 6.801062845397726e-05,
      "loss": 0.507,
      "step": 740500
    },
    {
      "epoch": 7.839271441502003,
      "eval_loss": 0.3112606108188629,
      "eval_runtime": 46.8075,
      "eval_samples_per_second": 3587.676,
      "eval_steps_per_second": 448.475,
      "step": 740500
    },
    {
      "epoch": 7.839800763282007,
      "grad_norm": 1.337845802307129,
      "learning_rate": 6.79789611021509e-05,
      "loss": 0.5048,
      "step": 740550
    },
    {
      "epoch": 7.84033008506201,
      "grad_norm": 1.3659089803695679,
      "learning_rate": 6.794729996445614e-05,
      "loss": 0.5053,
      "step": 740600
    },
    {
      "epoch": 7.840859406842013,
      "grad_norm": 1.1717225313186646,
      "learning_rate": 6.791564504197372e-05,
      "loss": 0.501,
      "step": 740650
    },
    {
      "epoch": 7.841388728622016,
      "grad_norm": 1.399105429649353,
      "learning_rate": 6.78839963357844e-05,
      "loss": 0.5052,
      "step": 740700
    },
    {
      "epoch": 7.84191805040202,
      "grad_norm": 1.3325786590576172,
      "learning_rate": 6.785235384696872e-05,
      "loss": 0.5096,
      "step": 740750
    },
    {
      "epoch": 7.842447372182023,
      "grad_norm": 1.3516653776168823,
      "learning_rate": 6.782071757660682e-05,
      "loss": 0.5038,
      "step": 740800
    },
    {
      "epoch": 7.842976693962027,
      "grad_norm": 1.2152070999145508,
      "learning_rate": 6.778908752577886e-05,
      "loss": 0.5031,
      "step": 740850
    },
    {
      "epoch": 7.8435060157420295,
      "grad_norm": 1.3789467811584473,
      "learning_rate": 6.775746369556457e-05,
      "loss": 0.5164,
      "step": 740900
    },
    {
      "epoch": 7.844035337522033,
      "grad_norm": 1.397025465965271,
      "learning_rate": 6.772584608704371e-05,
      "loss": 0.5076,
      "step": 740950
    },
    {
      "epoch": 7.844564659302036,
      "grad_norm": 1.3394461870193481,
      "learning_rate": 6.769423470129554e-05,
      "loss": 0.5089,
      "step": 741000
    },
    {
      "epoch": 7.844564659302036,
      "eval_loss": 0.31192418932914734,
      "eval_runtime": 46.8161,
      "eval_samples_per_second": 3587.012,
      "eval_steps_per_second": 448.393,
      "step": 741000
    },
    {
      "epoch": 7.84509398108204,
      "grad_norm": 1.3566186428070068,
      "learning_rate": 6.766262953939941e-05,
      "loss": 0.5097,
      "step": 741050
    },
    {
      "epoch": 7.845623302862043,
      "grad_norm": 1.223573923110962,
      "learning_rate": 6.763103060243416e-05,
      "loss": 0.5054,
      "step": 741100
    },
    {
      "epoch": 7.8461526246420465,
      "grad_norm": 1.409087896347046,
      "learning_rate": 6.759943789147871e-05,
      "loss": 0.5005,
      "step": 741150
    },
    {
      "epoch": 7.846681946422049,
      "grad_norm": 1.388469934463501,
      "learning_rate": 6.756785140761151e-05,
      "loss": 0.5099,
      "step": 741200
    },
    {
      "epoch": 7.847211268202052,
      "grad_norm": 1.2259833812713623,
      "learning_rate": 6.753627115191102e-05,
      "loss": 0.5106,
      "step": 741250
    },
    {
      "epoch": 7.847740589982056,
      "grad_norm": 1.2295225858688354,
      "learning_rate": 6.750469712545523e-05,
      "loss": 0.5025,
      "step": 741300
    },
    {
      "epoch": 7.848269911762059,
      "grad_norm": 1.135603904724121,
      "learning_rate": 6.747312932932223e-05,
      "loss": 0.5068,
      "step": 741350
    },
    {
      "epoch": 7.848799233542063,
      "grad_norm": 1.3969708681106567,
      "learning_rate": 6.74415677645896e-05,
      "loss": 0.5038,
      "step": 741400
    },
    {
      "epoch": 7.8493285553220655,
      "grad_norm": 1.3278952836990356,
      "learning_rate": 6.741001243233494e-05,
      "loss": 0.5063,
      "step": 741450
    },
    {
      "epoch": 7.849857877102069,
      "grad_norm": 1.3040366172790527,
      "learning_rate": 6.737909425451358e-05,
      "loss": 0.5032,
      "step": 741500
    },
    {
      "epoch": 7.849857877102069,
      "eval_loss": 0.3118440806865692,
      "eval_runtime": 46.9087,
      "eval_samples_per_second": 3579.937,
      "eval_steps_per_second": 447.508,
      "step": 741500
    },
    {
      "epoch": 7.850387198882072,
      "grad_norm": 1.2335373163223267,
      "learning_rate": 6.734755126574324e-05,
      "loss": 0.5087,
      "step": 741550
    },
    {
      "epoch": 7.850916520662076,
      "grad_norm": 1.3169928789138794,
      "learning_rate": 6.731601451266042e-05,
      "loss": 0.5015,
      "step": 741600
    },
    {
      "epoch": 7.851445842442079,
      "grad_norm": 1.3290979862213135,
      "learning_rate": 6.728448399634196e-05,
      "loss": 0.511,
      "step": 741650
    },
    {
      "epoch": 7.8519751642220825,
      "grad_norm": 1.4070943593978882,
      "learning_rate": 6.725295971786413e-05,
      "loss": 0.5092,
      "step": 741700
    },
    {
      "epoch": 7.852504486002085,
      "grad_norm": 1.3363100290298462,
      "learning_rate": 6.722144167830329e-05,
      "loss": 0.5003,
      "step": 741750
    },
    {
      "epoch": 7.853033807782089,
      "grad_norm": 1.2133492231369019,
      "learning_rate": 6.718992987873534e-05,
      "loss": 0.4973,
      "step": 741800
    },
    {
      "epoch": 7.853563129562092,
      "grad_norm": 1.3334909677505493,
      "learning_rate": 6.715842432023622e-05,
      "loss": 0.5079,
      "step": 741850
    },
    {
      "epoch": 7.854092451342096,
      "grad_norm": 1.3536033630371094,
      "learning_rate": 6.712692500388137e-05,
      "loss": 0.498,
      "step": 741900
    },
    {
      "epoch": 7.854621773122099,
      "grad_norm": 1.510864019393921,
      "learning_rate": 6.70954319307463e-05,
      "loss": 0.5099,
      "step": 741950
    },
    {
      "epoch": 7.8551510949021015,
      "grad_norm": 1.4217369556427002,
      "learning_rate": 6.706394510190603e-05,
      "loss": 0.5024,
      "step": 742000
    },
    {
      "epoch": 7.8551510949021015,
      "eval_loss": 0.3112572133541107,
      "eval_runtime": 46.772,
      "eval_samples_per_second": 3590.395,
      "eval_steps_per_second": 448.815,
      "step": 742000
    },
    {
      "epoch": 7.855680416682105,
      "grad_norm": 1.2910734415054321,
      "learning_rate": 6.703246451843567e-05,
      "loss": 0.4987,
      "step": 742050
    },
    {
      "epoch": 7.856209738462108,
      "grad_norm": 1.3409863710403442,
      "learning_rate": 6.700099018140978e-05,
      "loss": 0.5031,
      "step": 742100
    },
    {
      "epoch": 7.856739060242112,
      "grad_norm": 1.309141755104065,
      "learning_rate": 6.696952209190305e-05,
      "loss": 0.5089,
      "step": 742150
    },
    {
      "epoch": 7.857268382022115,
      "grad_norm": 1.3466237783432007,
      "learning_rate": 6.693806025098964e-05,
      "loss": 0.518,
      "step": 742200
    },
    {
      "epoch": 7.8577977038021185,
      "grad_norm": 1.2843999862670898,
      "learning_rate": 6.69066046597438e-05,
      "loss": 0.5044,
      "step": 742250
    },
    {
      "epoch": 7.858327025582121,
      "grad_norm": 1.34125554561615,
      "learning_rate": 6.687515531923924e-05,
      "loss": 0.5053,
      "step": 742300
    },
    {
      "epoch": 7.858856347362125,
      "grad_norm": 1.4781566858291626,
      "learning_rate": 6.684371223054978e-05,
      "loss": 0.5094,
      "step": 742350
    },
    {
      "epoch": 7.859385669142128,
      "grad_norm": 1.1064996719360352,
      "learning_rate": 6.681227539474876e-05,
      "loss": 0.4989,
      "step": 742400
    },
    {
      "epoch": 7.859914990922132,
      "grad_norm": 1.316464900970459,
      "learning_rate": 6.678084481290955e-05,
      "loss": 0.5067,
      "step": 742450
    },
    {
      "epoch": 7.860444312702135,
      "grad_norm": 1.3835448026657104,
      "learning_rate": 6.674942048610502e-05,
      "loss": 0.5065,
      "step": 742500
    },
    {
      "epoch": 7.860444312702135,
      "eval_loss": 0.3113103210926056,
      "eval_runtime": 46.8529,
      "eval_samples_per_second": 3584.194,
      "eval_steps_per_second": 448.04,
      "step": 742500
    },
    {
      "epoch": 7.860973634482138,
      "grad_norm": 1.3168818950653076,
      "learning_rate": 6.671800241540816e-05,
      "loss": 0.4992,
      "step": 742550
    },
    {
      "epoch": 7.861502956262141,
      "grad_norm": 1.4195220470428467,
      "learning_rate": 6.668659060189139e-05,
      "loss": 0.4981,
      "step": 742600
    },
    {
      "epoch": 7.862032278042145,
      "grad_norm": 1.4274439811706543,
      "learning_rate": 6.665518504662726e-05,
      "loss": 0.5064,
      "step": 742650
    },
    {
      "epoch": 7.862561599822148,
      "grad_norm": 1.3554913997650146,
      "learning_rate": 6.662378575068781e-05,
      "loss": 0.5074,
      "step": 742700
    },
    {
      "epoch": 7.863090921602151,
      "grad_norm": 1.3079196214675903,
      "learning_rate": 6.659239271514506e-05,
      "loss": 0.5096,
      "step": 742750
    },
    {
      "epoch": 7.8636202433821545,
      "grad_norm": 1.3441097736358643,
      "learning_rate": 6.656100594107084e-05,
      "loss": 0.4993,
      "step": 742800
    },
    {
      "epoch": 7.864149565162157,
      "grad_norm": 1.2351493835449219,
      "learning_rate": 6.652962542953653e-05,
      "loss": 0.5111,
      "step": 742850
    },
    {
      "epoch": 7.864678886942161,
      "grad_norm": 1.3687065839767456,
      "learning_rate": 6.64982511816136e-05,
      "loss": 0.5065,
      "step": 742900
    },
    {
      "epoch": 7.865208208722164,
      "grad_norm": 1.3603994846343994,
      "learning_rate": 6.6466883198373e-05,
      "loss": 0.4936,
      "step": 742950
    },
    {
      "epoch": 7.865737530502168,
      "grad_norm": 1.4996439218521118,
      "learning_rate": 6.643552148088566e-05,
      "loss": 0.5094,
      "step": 743000
    },
    {
      "epoch": 7.865737530502168,
      "eval_loss": 0.31150925159454346,
      "eval_runtime": 46.8511,
      "eval_samples_per_second": 3584.331,
      "eval_steps_per_second": 448.057,
      "step": 743000
    },
    {
      "epoch": 7.866266852282171,
      "grad_norm": 1.2288812398910522,
      "learning_rate": 6.640416603022242e-05,
      "loss": 0.5048,
      "step": 743050
    },
    {
      "epoch": 7.866796174062174,
      "grad_norm": 1.2708625793457031,
      "learning_rate": 6.637281684745352e-05,
      "loss": 0.5008,
      "step": 743100
    },
    {
      "epoch": 7.867325495842177,
      "grad_norm": 1.3397798538208008,
      "learning_rate": 6.63414739336494e-05,
      "loss": 0.5081,
      "step": 743150
    },
    {
      "epoch": 7.867854817622181,
      "grad_norm": 1.4072067737579346,
      "learning_rate": 6.631013728987992e-05,
      "loss": 0.5034,
      "step": 743200
    },
    {
      "epoch": 7.868384139402184,
      "grad_norm": 1.2135952711105347,
      "learning_rate": 6.627880691721506e-05,
      "loss": 0.497,
      "step": 743250
    },
    {
      "epoch": 7.868913461182188,
      "grad_norm": 1.3473814725875854,
      "learning_rate": 6.62474828167243e-05,
      "loss": 0.5014,
      "step": 743300
    },
    {
      "epoch": 7.8694427829621905,
      "grad_norm": 1.240141749382019,
      "learning_rate": 6.621616498947714e-05,
      "loss": 0.4866,
      "step": 743350
    },
    {
      "epoch": 7.869972104742194,
      "grad_norm": 1.3534797430038452,
      "learning_rate": 6.618485343654263e-05,
      "loss": 0.5035,
      "step": 743400
    },
    {
      "epoch": 7.870501426522197,
      "grad_norm": 1.456770896911621,
      "learning_rate": 6.615354815898988e-05,
      "loss": 0.5142,
      "step": 743450
    },
    {
      "epoch": 7.8710307483022,
      "grad_norm": 1.3844170570373535,
      "learning_rate": 6.612224915788753e-05,
      "loss": 0.5038,
      "step": 743500
    },
    {
      "epoch": 7.8710307483022,
      "eval_loss": 0.3110795319080353,
      "eval_runtime": 46.9371,
      "eval_samples_per_second": 3577.764,
      "eval_steps_per_second": 447.237,
      "step": 743500
    },
    {
      "epoch": 7.871560070082204,
      "grad_norm": 1.3551886081695557,
      "learning_rate": 6.60909564343042e-05,
      "loss": 0.5132,
      "step": 743550
    },
    {
      "epoch": 7.872089391862207,
      "grad_norm": 1.4774125814437866,
      "learning_rate": 6.605966998930812e-05,
      "loss": 0.5072,
      "step": 743600
    },
    {
      "epoch": 7.87261871364221,
      "grad_norm": 1.5567249059677124,
      "learning_rate": 6.60283898239675e-05,
      "loss": 0.5105,
      "step": 743650
    },
    {
      "epoch": 7.873148035422213,
      "grad_norm": 1.3162206411361694,
      "learning_rate": 6.599711593935012e-05,
      "loss": 0.5049,
      "step": 743700
    },
    {
      "epoch": 7.873677357202217,
      "grad_norm": 1.2792192697525024,
      "learning_rate": 6.59658483365238e-05,
      "loss": 0.4961,
      "step": 743750
    },
    {
      "epoch": 7.87420667898222,
      "grad_norm": 1.2456754446029663,
      "learning_rate": 6.593458701655583e-05,
      "loss": 0.5067,
      "step": 743800
    },
    {
      "epoch": 7.874736000762224,
      "grad_norm": 1.2256085872650146,
      "learning_rate": 6.590333198051366e-05,
      "loss": 0.5069,
      "step": 743850
    },
    {
      "epoch": 7.875265322542226,
      "grad_norm": 1.2898820638656616,
      "learning_rate": 6.587208322946414e-05,
      "loss": 0.5058,
      "step": 743900
    },
    {
      "epoch": 7.87579464432223,
      "grad_norm": 1.3975752592086792,
      "learning_rate": 6.584084076447422e-05,
      "loss": 0.5028,
      "step": 743950
    },
    {
      "epoch": 7.876323966102233,
      "grad_norm": 1.3556240797042847,
      "learning_rate": 6.58096045866104e-05,
      "loss": 0.5057,
      "step": 744000
    },
    {
      "epoch": 7.876323966102233,
      "eval_loss": 0.3106538951396942,
      "eval_runtime": 46.7878,
      "eval_samples_per_second": 3589.187,
      "eval_steps_per_second": 448.664,
      "step": 744000
    },
    {
      "epoch": 7.876853287882237,
      "grad_norm": 1.2624578475952148,
      "learning_rate": 6.57783746969392e-05,
      "loss": 0.497,
      "step": 744050
    },
    {
      "epoch": 7.87738260966224,
      "grad_norm": 1.3627171516418457,
      "learning_rate": 6.574715109652668e-05,
      "loss": 0.5057,
      "step": 744100
    },
    {
      "epoch": 7.877911931442243,
      "grad_norm": 1.4362473487854004,
      "learning_rate": 6.57159337864389e-05,
      "loss": 0.5037,
      "step": 744150
    },
    {
      "epoch": 7.878441253222246,
      "grad_norm": 1.234417200088501,
      "learning_rate": 6.568472276774148e-05,
      "loss": 0.4932,
      "step": 744200
    },
    {
      "epoch": 7.878970575002249,
      "grad_norm": 1.3971614837646484,
      "learning_rate": 6.565351804150011e-05,
      "loss": 0.5061,
      "step": 744250
    },
    {
      "epoch": 7.879499896782253,
      "grad_norm": 1.1923497915267944,
      "learning_rate": 6.562231960877993e-05,
      "loss": 0.4948,
      "step": 744300
    },
    {
      "epoch": 7.880029218562256,
      "grad_norm": 1.2616322040557861,
      "learning_rate": 6.559112747064625e-05,
      "loss": 0.502,
      "step": 744350
    },
    {
      "epoch": 7.8805585403422596,
      "grad_norm": 1.366287350654602,
      "learning_rate": 6.555994162816376e-05,
      "loss": 0.4965,
      "step": 744400
    },
    {
      "epoch": 7.881087862122262,
      "grad_norm": 1.4015549421310425,
      "learning_rate": 6.552876208239719e-05,
      "loss": 0.5123,
      "step": 744450
    },
    {
      "epoch": 7.881617183902266,
      "grad_norm": 1.4171189069747925,
      "learning_rate": 6.549758883441115e-05,
      "loss": 0.5049,
      "step": 744500
    },
    {
      "epoch": 7.881617183902266,
      "eval_loss": 0.3106924891471863,
      "eval_runtime": 46.7242,
      "eval_samples_per_second": 3594.067,
      "eval_steps_per_second": 449.274,
      "step": 744500
    },
    {
      "epoch": 7.882146505682269,
      "grad_norm": 1.2621028423309326,
      "learning_rate": 6.546642188526967e-05,
      "loss": 0.5032,
      "step": 744550
    },
    {
      "epoch": 7.882675827462273,
      "grad_norm": 1.4675064086914062,
      "learning_rate": 6.543526123603686e-05,
      "loss": 0.5075,
      "step": 744600
    },
    {
      "epoch": 7.883205149242276,
      "grad_norm": 1.3730806112289429,
      "learning_rate": 6.540410688777662e-05,
      "loss": 0.5009,
      "step": 744650
    },
    {
      "epoch": 7.883734471022279,
      "grad_norm": 1.3259608745574951,
      "learning_rate": 6.537295884155242e-05,
      "loss": 0.4996,
      "step": 744700
    },
    {
      "epoch": 7.884263792802282,
      "grad_norm": 1.281070351600647,
      "learning_rate": 6.534181709842776e-05,
      "loss": 0.503,
      "step": 744750
    },
    {
      "epoch": 7.884793114582286,
      "grad_norm": 1.307152271270752,
      "learning_rate": 6.531068165946566e-05,
      "loss": 0.5093,
      "step": 744800
    },
    {
      "epoch": 7.885322436362289,
      "grad_norm": 1.313672423362732,
      "learning_rate": 6.527955252572923e-05,
      "loss": 0.5023,
      "step": 744850
    },
    {
      "epoch": 7.885851758142293,
      "grad_norm": 1.3116205930709839,
      "learning_rate": 6.524842969828108e-05,
      "loss": 0.5053,
      "step": 744900
    },
    {
      "epoch": 7.8863810799222955,
      "grad_norm": 1.3766331672668457,
      "learning_rate": 6.521731317818383e-05,
      "loss": 0.4953,
      "step": 744950
    },
    {
      "epoch": 7.886910401702298,
      "grad_norm": 1.3983550071716309,
      "learning_rate": 6.518620296649968e-05,
      "loss": 0.5084,
      "step": 745000
    },
    {
      "epoch": 7.886910401702298,
      "eval_loss": 0.31046152114868164,
      "eval_runtime": 46.9471,
      "eval_samples_per_second": 3577.007,
      "eval_steps_per_second": 447.142,
      "step": 745000
    },
    {
      "epoch": 7.887439723482302,
      "grad_norm": 1.217829942703247,
      "learning_rate": 6.515509906429085e-05,
      "loss": 0.5014,
      "step": 745050
    },
    {
      "epoch": 7.887969045262305,
      "grad_norm": 1.2438074350357056,
      "learning_rate": 6.512400147261907e-05,
      "loss": 0.5101,
      "step": 745100
    },
    {
      "epoch": 7.888498367042309,
      "grad_norm": 1.3504770994186401,
      "learning_rate": 6.509291019254618e-05,
      "loss": 0.5109,
      "step": 745150
    },
    {
      "epoch": 7.889027688822312,
      "grad_norm": 1.3384953737258911,
      "learning_rate": 6.506182522513343e-05,
      "loss": 0.509,
      "step": 745200
    },
    {
      "epoch": 7.889557010602315,
      "grad_norm": 1.3731498718261719,
      "learning_rate": 6.50307465714422e-05,
      "loss": 0.5084,
      "step": 745250
    },
    {
      "epoch": 7.890086332382318,
      "grad_norm": 1.3274677991867065,
      "learning_rate": 6.499967423253339e-05,
      "loss": 0.5022,
      "step": 745300
    },
    {
      "epoch": 7.890615654162322,
      "grad_norm": 1.1690131425857544,
      "learning_rate": 6.496860820946793e-05,
      "loss": 0.4975,
      "step": 745350
    },
    {
      "epoch": 7.891144975942325,
      "grad_norm": 1.3365702629089355,
      "learning_rate": 6.493754850330624e-05,
      "loss": 0.5041,
      "step": 745400
    },
    {
      "epoch": 7.891674297722329,
      "grad_norm": 1.3818944692611694,
      "learning_rate": 6.490649511510888e-05,
      "loss": 0.5009,
      "step": 745450
    },
    {
      "epoch": 7.8922036195023315,
      "grad_norm": 1.1949573755264282,
      "learning_rate": 6.4876068925386e-05,
      "loss": 0.5011,
      "step": 745500
    },
    {
      "epoch": 7.8922036195023315,
      "eval_loss": 0.3108614683151245,
      "eval_runtime": 46.8365,
      "eval_samples_per_second": 3585.449,
      "eval_steps_per_second": 448.197,
      "step": 745500
    },
    {
      "epoch": 7.892732941282335,
      "grad_norm": 1.1262120008468628,
      "learning_rate": 6.484502804988515e-05,
      "loss": 0.5054,
      "step": 745550
    },
    {
      "epoch": 7.893262263062338,
      "grad_norm": 1.337136149406433,
      "learning_rate": 6.481399349550723e-05,
      "loss": 0.5112,
      "step": 745600
    },
    {
      "epoch": 7.893791584842342,
      "grad_norm": 1.4245156049728394,
      "learning_rate": 6.478296526331157e-05,
      "loss": 0.5027,
      "step": 745650
    },
    {
      "epoch": 7.894320906622345,
      "grad_norm": 1.2818647623062134,
      "learning_rate": 6.475194335435763e-05,
      "loss": 0.5029,
      "step": 745700
    },
    {
      "epoch": 7.894850228402348,
      "grad_norm": 1.2120380401611328,
      "learning_rate": 6.472092776970434e-05,
      "loss": 0.503,
      "step": 745750
    },
    {
      "epoch": 7.895379550182351,
      "grad_norm": 1.349303960800171,
      "learning_rate": 6.468991851041068e-05,
      "loss": 0.5038,
      "step": 745800
    },
    {
      "epoch": 7.895908871962354,
      "grad_norm": 1.3696681261062622,
      "learning_rate": 6.465891557753518e-05,
      "loss": 0.5001,
      "step": 745850
    },
    {
      "epoch": 7.896438193742358,
      "grad_norm": 1.5347293615341187,
      "learning_rate": 6.46279189721364e-05,
      "loss": 0.5077,
      "step": 745900
    },
    {
      "epoch": 7.896967515522361,
      "grad_norm": 1.346419095993042,
      "learning_rate": 6.459692869527242e-05,
      "loss": 0.5107,
      "step": 745950
    },
    {
      "epoch": 7.897496837302365,
      "grad_norm": 1.3708913326263428,
      "learning_rate": 6.456594474800138e-05,
      "loss": 0.5056,
      "step": 746000
    },
    {
      "epoch": 7.897496837302365,
      "eval_loss": 0.31035688519477844,
      "eval_runtime": 46.8527,
      "eval_samples_per_second": 3584.215,
      "eval_steps_per_second": 448.043,
      "step": 746000
    },
    {
      "epoch": 7.8980261590823675,
      "grad_norm": 1.2874383926391602,
      "learning_rate": 6.453496713138088e-05,
      "loss": 0.5036,
      "step": 746050
    },
    {
      "epoch": 7.898555480862371,
      "grad_norm": 1.388522982597351,
      "learning_rate": 6.450399584646869e-05,
      "loss": 0.4998,
      "step": 746100
    },
    {
      "epoch": 7.899084802642374,
      "grad_norm": 1.3394503593444824,
      "learning_rate": 6.447303089432194e-05,
      "loss": 0.507,
      "step": 746150
    },
    {
      "epoch": 7.899614124422378,
      "grad_norm": 1.2590360641479492,
      "learning_rate": 6.444269138628612e-05,
      "loss": 0.5054,
      "step": 746200
    },
    {
      "epoch": 7.900143446202381,
      "grad_norm": 1.339072823524475,
      "learning_rate": 6.441173897613372e-05,
      "loss": 0.509,
      "step": 746250
    },
    {
      "epoch": 7.9006727679823845,
      "grad_norm": 1.3706008195877075,
      "learning_rate": 6.438079290189658e-05,
      "loss": 0.5045,
      "step": 746300
    },
    {
      "epoch": 7.901202089762387,
      "grad_norm": 1.4151253700256348,
      "learning_rate": 6.434985316463101e-05,
      "loss": 0.5012,
      "step": 746350
    },
    {
      "epoch": 7.901731411542391,
      "grad_norm": 1.3158953189849854,
      "learning_rate": 6.431891976539345e-05,
      "loss": 0.514,
      "step": 746400
    },
    {
      "epoch": 7.902260733322394,
      "grad_norm": 1.1472680568695068,
      "learning_rate": 6.42879927052398e-05,
      "loss": 0.5041,
      "step": 746450
    },
    {
      "epoch": 7.902790055102397,
      "grad_norm": 1.2411750555038452,
      "learning_rate": 6.425707198522604e-05,
      "loss": 0.5001,
      "step": 746500
    },
    {
      "epoch": 7.902790055102397,
      "eval_loss": 0.31000077724456787,
      "eval_runtime": 46.8087,
      "eval_samples_per_second": 3587.584,
      "eval_steps_per_second": 448.464,
      "step": 746500
    },
    {
      "epoch": 7.903319376882401,
      "grad_norm": 1.4529304504394531,
      "learning_rate": 6.422615760640763e-05,
      "loss": 0.5071,
      "step": 746550
    },
    {
      "epoch": 7.903848698662404,
      "grad_norm": 1.4227045774459839,
      "learning_rate": 6.419524956984015e-05,
      "loss": 0.5073,
      "step": 746600
    },
    {
      "epoch": 7.904378020442407,
      "grad_norm": 1.2605125904083252,
      "learning_rate": 6.416434787657865e-05,
      "loss": 0.5022,
      "step": 746650
    },
    {
      "epoch": 7.90490734222241,
      "grad_norm": 1.26020348072052,
      "learning_rate": 6.413345252767824e-05,
      "loss": 0.4988,
      "step": 746700
    },
    {
      "epoch": 7.905436664002414,
      "grad_norm": 1.4496103525161743,
      "learning_rate": 6.410256352419353e-05,
      "loss": 0.4967,
      "step": 746750
    },
    {
      "epoch": 7.905965985782417,
      "grad_norm": 1.2663023471832275,
      "learning_rate": 6.407168086717916e-05,
      "loss": 0.5052,
      "step": 746800
    },
    {
      "epoch": 7.9064953075624205,
      "grad_norm": 1.3632680177688599,
      "learning_rate": 6.404080455768937e-05,
      "loss": 0.5038,
      "step": 746850
    },
    {
      "epoch": 7.907024629342423,
      "grad_norm": 1.18826425075531,
      "learning_rate": 6.40099345967784e-05,
      "loss": 0.5058,
      "step": 746900
    },
    {
      "epoch": 7.907553951122427,
      "grad_norm": 1.319938063621521,
      "learning_rate": 6.397907098549995e-05,
      "loss": 0.4993,
      "step": 746950
    },
    {
      "epoch": 7.90808327290243,
      "grad_norm": 1.2740199565887451,
      "learning_rate": 6.39482137249079e-05,
      "loss": 0.5044,
      "step": 747000
    },
    {
      "epoch": 7.90808327290243,
      "eval_loss": 0.3105888068675995,
      "eval_runtime": 46.776,
      "eval_samples_per_second": 3590.089,
      "eval_steps_per_second": 448.777,
      "step": 747000
    },
    {
      "epoch": 7.908612594682434,
      "grad_norm": 1.4145095348358154,
      "learning_rate": 6.391736281605548e-05,
      "loss": 0.5061,
      "step": 747050
    },
    {
      "epoch": 7.909141916462437,
      "grad_norm": 1.2510020732879639,
      "learning_rate": 6.388651825999608e-05,
      "loss": 0.5128,
      "step": 747100
    },
    {
      "epoch": 7.90967123824244,
      "grad_norm": 1.5449538230895996,
      "learning_rate": 6.385568005778278e-05,
      "loss": 0.4963,
      "step": 747150
    },
    {
      "epoch": 7.910200560022443,
      "grad_norm": 1.2932510375976562,
      "learning_rate": 6.382484821046819e-05,
      "loss": 0.5109,
      "step": 747200
    },
    {
      "epoch": 7.910729881802446,
      "grad_norm": 1.2052403688430786,
      "learning_rate": 6.379402271910503e-05,
      "loss": 0.4999,
      "step": 747250
    },
    {
      "epoch": 7.91125920358245,
      "grad_norm": 1.3070728778839111,
      "learning_rate": 6.376320358474569e-05,
      "loss": 0.4994,
      "step": 747300
    },
    {
      "epoch": 7.911788525362454,
      "grad_norm": 1.4018741846084595,
      "learning_rate": 6.373239080844223e-05,
      "loss": 0.5064,
      "step": 747350
    },
    {
      "epoch": 7.9123178471424565,
      "grad_norm": 1.353009819984436,
      "learning_rate": 6.37015843912467e-05,
      "loss": 0.5131,
      "step": 747400
    },
    {
      "epoch": 7.912847168922459,
      "grad_norm": 1.492895483970642,
      "learning_rate": 6.367078433421069e-05,
      "loss": 0.5027,
      "step": 747450
    },
    {
      "epoch": 7.913376490702463,
      "grad_norm": 1.3665337562561035,
      "learning_rate": 6.363999063838585e-05,
      "loss": 0.4989,
      "step": 747500
    },
    {
      "epoch": 7.913376490702463,
      "eval_loss": 0.3096247613430023,
      "eval_runtime": 46.799,
      "eval_samples_per_second": 3588.321,
      "eval_steps_per_second": 448.556,
      "step": 747500
    },
    {
      "epoch": 7.913905812482466,
      "grad_norm": 1.3826186656951904,
      "learning_rate": 6.360920330482329e-05,
      "loss": 0.5048,
      "step": 747550
    },
    {
      "epoch": 7.91443513426247,
      "grad_norm": 1.3761051893234253,
      "learning_rate": 6.357842233457425e-05,
      "loss": 0.5083,
      "step": 747600
    },
    {
      "epoch": 7.914964456042473,
      "grad_norm": 1.3787094354629517,
      "learning_rate": 6.354764772868946e-05,
      "loss": 0.5049,
      "step": 747650
    },
    {
      "epoch": 7.915493777822476,
      "grad_norm": 1.200469970703125,
      "learning_rate": 6.351687948821963e-05,
      "loss": 0.501,
      "step": 747700
    },
    {
      "epoch": 7.916023099602479,
      "grad_norm": 1.2805215120315552,
      "learning_rate": 6.348611761421507e-05,
      "loss": 0.51,
      "step": 747750
    },
    {
      "epoch": 7.916552421382483,
      "grad_norm": 1.3782700300216675,
      "learning_rate": 6.345536210772615e-05,
      "loss": 0.4959,
      "step": 747800
    },
    {
      "epoch": 7.917081743162486,
      "grad_norm": 1.3338483572006226,
      "learning_rate": 6.342461296980268e-05,
      "loss": 0.4983,
      "step": 747850
    },
    {
      "epoch": 7.91761106494249,
      "grad_norm": 1.4375059604644775,
      "learning_rate": 6.339387020149457e-05,
      "loss": 0.5032,
      "step": 747900
    },
    {
      "epoch": 7.918140386722492,
      "grad_norm": 1.3013970851898193,
      "learning_rate": 6.33631338038512e-05,
      "loss": 0.5016,
      "step": 747950
    },
    {
      "epoch": 7.918669708502495,
      "grad_norm": 1.207156777381897,
      "learning_rate": 6.33324037779221e-05,
      "loss": 0.5049,
      "step": 748000
    },
    {
      "epoch": 7.918669708502495,
      "eval_loss": 0.3093984127044678,
      "eval_runtime": 46.7439,
      "eval_samples_per_second": 3592.551,
      "eval_steps_per_second": 449.085,
      "step": 748000
    },
    {
      "epoch": 7.919199030282499,
      "grad_norm": 1.2536383867263794,
      "learning_rate": 6.330168012475618e-05,
      "loss": 0.5038,
      "step": 748050
    },
    {
      "epoch": 7.919728352062503,
      "grad_norm": 1.382964849472046,
      "learning_rate": 6.327096284540251e-05,
      "loss": 0.5017,
      "step": 748100
    },
    {
      "epoch": 7.920257673842506,
      "grad_norm": 1.4666932821273804,
      "learning_rate": 6.324025194090962e-05,
      "loss": 0.5008,
      "step": 748150
    },
    {
      "epoch": 7.9207869956225085,
      "grad_norm": 1.3886048793792725,
      "learning_rate": 6.320954741232609e-05,
      "loss": 0.5016,
      "step": 748200
    },
    {
      "epoch": 7.921316317402512,
      "grad_norm": 1.2562545537948608,
      "learning_rate": 6.317884926070005e-05,
      "loss": 0.4963,
      "step": 748250
    },
    {
      "epoch": 7.921845639182515,
      "grad_norm": 1.2806504964828491,
      "learning_rate": 6.314815748707966e-05,
      "loss": 0.5042,
      "step": 748300
    },
    {
      "epoch": 7.922374960962519,
      "grad_norm": 1.3291380405426025,
      "learning_rate": 6.31174720925126e-05,
      "loss": 0.504,
      "step": 748350
    },
    {
      "epoch": 7.922904282742522,
      "grad_norm": 1.3276550769805908,
      "learning_rate": 6.308679307804651e-05,
      "loss": 0.5118,
      "step": 748400
    },
    {
      "epoch": 7.9234336045225255,
      "grad_norm": 1.477273941040039,
      "learning_rate": 6.305612044472875e-05,
      "loss": 0.5034,
      "step": 748450
    },
    {
      "epoch": 7.923962926302528,
      "grad_norm": 1.2559819221496582,
      "learning_rate": 6.30254541936065e-05,
      "loss": 0.5113,
      "step": 748500
    },
    {
      "epoch": 7.923962926302528,
      "eval_loss": 0.31007713079452515,
      "eval_runtime": 46.8683,
      "eval_samples_per_second": 3583.016,
      "eval_steps_per_second": 447.893,
      "step": 748500
    },
    {
      "epoch": 7.924492248082532,
      "grad_norm": 1.3201162815093994,
      "learning_rate": 6.299479432572664e-05,
      "loss": 0.5062,
      "step": 748550
    },
    {
      "epoch": 7.925021569862535,
      "grad_norm": 1.455180048942566,
      "learning_rate": 6.296414084213597e-05,
      "loss": 0.5038,
      "step": 748600
    },
    {
      "epoch": 7.925550891642539,
      "grad_norm": 1.4994275569915771,
      "learning_rate": 6.293349374388088e-05,
      "loss": 0.498,
      "step": 748650
    },
    {
      "epoch": 7.926080213422542,
      "grad_norm": 1.340139627456665,
      "learning_rate": 6.290285303200777e-05,
      "loss": 0.4952,
      "step": 748700
    },
    {
      "epoch": 7.9266095352025445,
      "grad_norm": 1.252010464668274,
      "learning_rate": 6.287221870756258e-05,
      "loss": 0.5048,
      "step": 748750
    },
    {
      "epoch": 7.927138856982548,
      "grad_norm": 1.3616845607757568,
      "learning_rate": 6.284159077159118e-05,
      "loss": 0.4969,
      "step": 748800
    },
    {
      "epoch": 7.927668178762552,
      "grad_norm": 1.3674417734146118,
      "learning_rate": 6.281096922513935e-05,
      "loss": 0.5007,
      "step": 748850
    },
    {
      "epoch": 7.928197500542555,
      "grad_norm": 1.2528365850448608,
      "learning_rate": 6.278035406925228e-05,
      "loss": 0.501,
      "step": 748900
    },
    {
      "epoch": 7.928726822322558,
      "grad_norm": 1.2705981731414795,
      "learning_rate": 6.274974530497527e-05,
      "loss": 0.5112,
      "step": 748950
    },
    {
      "epoch": 7.9292561441025615,
      "grad_norm": 1.2250372171401978,
      "learning_rate": 6.271914293335338e-05,
      "loss": 0.501,
      "step": 749000
    },
    {
      "epoch": 7.9292561441025615,
      "eval_loss": 0.30948612093925476,
      "eval_runtime": 46.8478,
      "eval_samples_per_second": 3584.59,
      "eval_steps_per_second": 448.09,
      "step": 749000
    },
    {
      "epoch": 7.929785465882564,
      "grad_norm": 1.3255964517593384,
      "learning_rate": 6.268854695543116e-05,
      "loss": 0.4925,
      "step": 749050
    },
    {
      "epoch": 7.930314787662568,
      "grad_norm": 1.2209559679031372,
      "learning_rate": 6.265795737225333e-05,
      "loss": 0.4981,
      "step": 749100
    },
    {
      "epoch": 7.930844109442571,
      "grad_norm": 1.4295787811279297,
      "learning_rate": 6.262737418486405e-05,
      "loss": 0.4975,
      "step": 749150
    },
    {
      "epoch": 7.931373431222575,
      "grad_norm": 1.4262815713882446,
      "learning_rate": 6.25967973943076e-05,
      "loss": 0.5052,
      "step": 749200
    },
    {
      "epoch": 7.931902753002578,
      "grad_norm": 1.473293423652649,
      "learning_rate": 6.256622700162767e-05,
      "loss": 0.5017,
      "step": 749250
    },
    {
      "epoch": 7.932432074782581,
      "grad_norm": 1.5675177574157715,
      "learning_rate": 6.253566300786809e-05,
      "loss": 0.5045,
      "step": 749300
    },
    {
      "epoch": 7.932961396562584,
      "grad_norm": 1.3248518705368042,
      "learning_rate": 6.250510541407215e-05,
      "loss": 0.5092,
      "step": 749350
    },
    {
      "epoch": 7.933490718342588,
      "grad_norm": 1.2589361667633057,
      "learning_rate": 6.24745542212832e-05,
      "loss": 0.5101,
      "step": 749400
    },
    {
      "epoch": 7.934020040122591,
      "grad_norm": 1.2357943058013916,
      "learning_rate": 6.244400943054416e-05,
      "loss": 0.501,
      "step": 749450
    },
    {
      "epoch": 7.934549361902594,
      "grad_norm": 1.4782912731170654,
      "learning_rate": 6.241347104289791e-05,
      "loss": 0.5032,
      "step": 749500
    },
    {
      "epoch": 7.934549361902594,
      "eval_loss": 0.30944812297821045,
      "eval_runtime": 46.9186,
      "eval_samples_per_second": 3579.181,
      "eval_steps_per_second": 447.414,
      "step": 749500
    },
    {
      "epoch": 7.9350786836825975,
      "grad_norm": 1.2156840562820435,
      "learning_rate": 6.238293905938688e-05,
      "loss": 0.4896,
      "step": 749550
    },
    {
      "epoch": 7.935608005462601,
      "grad_norm": 1.4835236072540283,
      "learning_rate": 6.235241348105358e-05,
      "loss": 0.5023,
      "step": 749600
    },
    {
      "epoch": 7.936137327242604,
      "grad_norm": 1.3960411548614502,
      "learning_rate": 6.232189430894e-05,
      "loss": 0.5,
      "step": 749650
    },
    {
      "epoch": 7.936666649022607,
      "grad_norm": 1.3411272764205933,
      "learning_rate": 6.22913815440882e-05,
      "loss": 0.5005,
      "step": 749700
    },
    {
      "epoch": 7.937195970802611,
      "grad_norm": 1.3749651908874512,
      "learning_rate": 6.22608751875397e-05,
      "loss": 0.5032,
      "step": 749750
    },
    {
      "epoch": 7.937725292582614,
      "grad_norm": 1.6337709426879883,
      "learning_rate": 6.223037524033615e-05,
      "loss": 0.5037,
      "step": 749800
    },
    {
      "epoch": 7.938254614362617,
      "grad_norm": 1.3182361125946045,
      "learning_rate": 6.219988170351867e-05,
      "loss": 0.5037,
      "step": 749850
    },
    {
      "epoch": 7.93878393614262,
      "grad_norm": 1.3662811517715454,
      "learning_rate": 6.216939457812842e-05,
      "loss": 0.5076,
      "step": 749900
    },
    {
      "epoch": 7.939313257922624,
      "grad_norm": 1.4948607683181763,
      "learning_rate": 6.213891386520606e-05,
      "loss": 0.5041,
      "step": 749950
    },
    {
      "epoch": 7.939842579702627,
      "grad_norm": 1.368415355682373,
      "learning_rate": 6.210843956579237e-05,
      "loss": 0.5064,
      "step": 750000
    },
    {
      "epoch": 7.939842579702627,
      "eval_loss": 0.30942896008491516,
      "eval_runtime": 46.8438,
      "eval_samples_per_second": 3584.894,
      "eval_steps_per_second": 448.128,
      "step": 750000
    },
    {
      "epoch": 7.940371901482631,
      "grad_norm": 1.3809330463409424,
      "learning_rate": 6.20785809757556e-05,
      "loss": 0.4917,
      "step": 750050
    },
    {
      "epoch": 7.9409012232626335,
      "grad_norm": 1.4144231081008911,
      "learning_rate": 6.204811937815797e-05,
      "loss": 0.5093,
      "step": 750100
    },
    {
      "epoch": 7.941430545042637,
      "grad_norm": 1.3206177949905396,
      "learning_rate": 6.201766419716867e-05,
      "loss": 0.5063,
      "step": 750150
    },
    {
      "epoch": 7.94195986682264,
      "grad_norm": 1.0809870958328247,
      "learning_rate": 6.198721543382733e-05,
      "loss": 0.5003,
      "step": 750200
    },
    {
      "epoch": 7.942489188602643,
      "grad_norm": 1.302525520324707,
      "learning_rate": 6.195677308917356e-05,
      "loss": 0.4995,
      "step": 750250
    },
    {
      "epoch": 7.943018510382647,
      "grad_norm": 1.273289442062378,
      "learning_rate": 6.19263371642465e-05,
      "loss": 0.4887,
      "step": 750300
    },
    {
      "epoch": 7.9435478321626505,
      "grad_norm": 1.2984578609466553,
      "learning_rate": 6.18959076600854e-05,
      "loss": 0.5087,
      "step": 750350
    },
    {
      "epoch": 7.944077153942653,
      "grad_norm": 1.3975354433059692,
      "learning_rate": 6.186548457772898e-05,
      "loss": 0.5013,
      "step": 750400
    },
    {
      "epoch": 7.944606475722656,
      "grad_norm": 1.3577866554260254,
      "learning_rate": 6.183506791821594e-05,
      "loss": 0.5047,
      "step": 750450
    },
    {
      "epoch": 7.94513579750266,
      "grad_norm": 1.3375115394592285,
      "learning_rate": 6.180465768258464e-05,
      "loss": 0.503,
      "step": 750500
    },
    {
      "epoch": 7.94513579750266,
      "eval_loss": 0.30949485301971436,
      "eval_runtime": 46.9151,
      "eval_samples_per_second": 3579.448,
      "eval_steps_per_second": 447.447,
      "step": 750500
    },
    {
      "epoch": 7.945665119282663,
      "grad_norm": 1.4470621347427368,
      "learning_rate": 6.177425387187337e-05,
      "loss": 0.4994,
      "step": 750550
    },
    {
      "epoch": 7.946194441062667,
      "grad_norm": 1.2232799530029297,
      "learning_rate": 6.174385648712e-05,
      "loss": 0.5024,
      "step": 750600
    },
    {
      "epoch": 7.9467237628426695,
      "grad_norm": 1.3692485094070435,
      "learning_rate": 6.171346552936236e-05,
      "loss": 0.5008,
      "step": 750650
    },
    {
      "epoch": 7.947253084622673,
      "grad_norm": 1.384103775024414,
      "learning_rate": 6.16830809996379e-05,
      "loss": 0.5036,
      "step": 750700
    },
    {
      "epoch": 7.947782406402676,
      "grad_norm": 1.354819893836975,
      "learning_rate": 6.165270289898407e-05,
      "loss": 0.5044,
      "step": 750750
    },
    {
      "epoch": 7.94831172818268,
      "grad_norm": 1.2864625453948975,
      "learning_rate": 6.16223312284378e-05,
      "loss": 0.5051,
      "step": 750800
    },
    {
      "epoch": 7.948841049962683,
      "grad_norm": 1.410080075263977,
      "learning_rate": 6.159196598903608e-05,
      "loss": 0.4965,
      "step": 750850
    },
    {
      "epoch": 7.9493703717426865,
      "grad_norm": 1.252353310585022,
      "learning_rate": 6.156160718181558e-05,
      "loss": 0.5052,
      "step": 750900
    },
    {
      "epoch": 7.949899693522689,
      "grad_norm": 1.3136683702468872,
      "learning_rate": 6.153125480781266e-05,
      "loss": 0.498,
      "step": 750950
    },
    {
      "epoch": 7.950429015302692,
      "grad_norm": 1.2816790342330933,
      "learning_rate": 6.150090886806356e-05,
      "loss": 0.5036,
      "step": 751000
    },
    {
      "epoch": 7.950429015302692,
      "eval_loss": 0.3093850016593933,
      "eval_runtime": 46.794,
      "eval_samples_per_second": 3588.706,
      "eval_steps_per_second": 448.604,
      "step": 751000
    },
    {
      "epoch": 7.950958337082696,
      "grad_norm": 1.4300113916397095,
      "learning_rate": 6.14705693636044e-05,
      "loss": 0.506,
      "step": 751050
    },
    {
      "epoch": 7.9514876588627,
      "grad_norm": 1.292738437652588,
      "learning_rate": 6.144023629547077e-05,
      "loss": 0.4979,
      "step": 751100
    },
    {
      "epoch": 7.952016980642703,
      "grad_norm": 1.4149764776229858,
      "learning_rate": 6.140990966469839e-05,
      "loss": 0.498,
      "step": 751150
    },
    {
      "epoch": 7.952546302422705,
      "grad_norm": 1.3637349605560303,
      "learning_rate": 6.137958947232247e-05,
      "loss": 0.5064,
      "step": 751200
    },
    {
      "epoch": 7.953075624202709,
      "grad_norm": 1.3973673582077026,
      "learning_rate": 6.134927571937826e-05,
      "loss": 0.4957,
      "step": 751250
    },
    {
      "epoch": 7.953604945982712,
      "grad_norm": 1.2725121974945068,
      "learning_rate": 6.131896840690054e-05,
      "loss": 0.4999,
      "step": 751300
    },
    {
      "epoch": 7.954134267762716,
      "grad_norm": 1.2889492511749268,
      "learning_rate": 6.128866753592408e-05,
      "loss": 0.5066,
      "step": 751350
    },
    {
      "epoch": 7.954663589542719,
      "grad_norm": 1.4921330213546753,
      "learning_rate": 6.125837310748325e-05,
      "loss": 0.4944,
      "step": 751400
    },
    {
      "epoch": 7.955192911322722,
      "grad_norm": 1.4095556735992432,
      "learning_rate": 6.122808512261241e-05,
      "loss": 0.5018,
      "step": 751450
    },
    {
      "epoch": 7.955722233102725,
      "grad_norm": 1.3945401906967163,
      "learning_rate": 6.119780358234544e-05,
      "loss": 0.5045,
      "step": 751500
    },
    {
      "epoch": 7.955722233102725,
      "eval_loss": 0.3097709119319916,
      "eval_runtime": 46.7951,
      "eval_samples_per_second": 3588.624,
      "eval_steps_per_second": 448.594,
      "step": 751500
    },
    {
      "epoch": 7.956251554882729,
      "grad_norm": 1.4106571674346924,
      "learning_rate": 6.116752848771628e-05,
      "loss": 0.5063,
      "step": 751550
    },
    {
      "epoch": 7.956780876662732,
      "grad_norm": 1.4333161115646362,
      "learning_rate": 6.113725983975837e-05,
      "loss": 0.5118,
      "step": 751600
    },
    {
      "epoch": 7.957310198442736,
      "grad_norm": 1.292789101600647,
      "learning_rate": 6.110699763950525e-05,
      "loss": 0.5041,
      "step": 751650
    },
    {
      "epoch": 7.9578395202227385,
      "grad_norm": 1.417128324508667,
      "learning_rate": 6.107674188798984e-05,
      "loss": 0.5041,
      "step": 751700
    },
    {
      "epoch": 7.958368842002741,
      "grad_norm": 1.3287434577941895,
      "learning_rate": 6.104649258624528e-05,
      "loss": 0.5023,
      "step": 751750
    },
    {
      "epoch": 7.958898163782745,
      "grad_norm": 1.375573754310608,
      "learning_rate": 6.101624973530409e-05,
      "loss": 0.5009,
      "step": 751800
    },
    {
      "epoch": 7.959427485562749,
      "grad_norm": 1.2855433225631714,
      "learning_rate": 6.098601333619888e-05,
      "loss": 0.502,
      "step": 751850
    },
    {
      "epoch": 7.959956807342752,
      "grad_norm": 1.3467411994934082,
      "learning_rate": 6.09557833899618e-05,
      "loss": 0.4945,
      "step": 751900
    },
    {
      "epoch": 7.960486129122755,
      "grad_norm": 1.5470941066741943,
      "learning_rate": 6.092555989762502e-05,
      "loss": 0.5111,
      "step": 751950
    },
    {
      "epoch": 7.961015450902758,
      "grad_norm": 1.530820369720459,
      "learning_rate": 6.0895342860220194e-05,
      "loss": 0.5134,
      "step": 752000
    },
    {
      "epoch": 7.961015450902758,
      "eval_loss": 0.30924421548843384,
      "eval_runtime": 46.7761,
      "eval_samples_per_second": 3590.085,
      "eval_steps_per_second": 448.777,
      "step": 752000
    },
    {
      "epoch": 7.961544772682761,
      "grad_norm": 1.3135465383529663,
      "learning_rate": 6.08651322787791e-05,
      "loss": 0.5021,
      "step": 752050
    },
    {
      "epoch": 7.962074094462765,
      "grad_norm": 1.3722116947174072,
      "learning_rate": 6.0834928154332946e-05,
      "loss": 0.4995,
      "step": 752100
    },
    {
      "epoch": 7.962603416242768,
      "grad_norm": 1.3285280466079712,
      "learning_rate": 6.080473048791305e-05,
      "loss": 0.4974,
      "step": 752150
    },
    {
      "epoch": 7.963132738022772,
      "grad_norm": 1.409299612045288,
      "learning_rate": 6.0774539280550186e-05,
      "loss": 0.5031,
      "step": 752200
    },
    {
      "epoch": 7.9636620598027745,
      "grad_norm": 1.2516167163848877,
      "learning_rate": 6.074435453327523e-05,
      "loss": 0.5038,
      "step": 752250
    },
    {
      "epoch": 7.964191381582778,
      "grad_norm": 1.2882726192474365,
      "learning_rate": 6.071417624711856e-05,
      "loss": 0.4986,
      "step": 752300
    },
    {
      "epoch": 7.964720703362781,
      "grad_norm": 1.351550817489624,
      "learning_rate": 6.0684607796254925e-05,
      "loss": 0.4973,
      "step": 752350
    },
    {
      "epoch": 7.965250025142785,
      "grad_norm": 1.2156466245651245,
      "learning_rate": 6.065444230615189e-05,
      "loss": 0.4954,
      "step": 752400
    },
    {
      "epoch": 7.965779346922788,
      "grad_norm": 1.4518792629241943,
      "learning_rate": 6.06242832802367e-05,
      "loss": 0.506,
      "step": 752450
    },
    {
      "epoch": 7.966308668702791,
      "grad_norm": 1.2672632932662964,
      "learning_rate": 6.059413071953909e-05,
      "loss": 0.4919,
      "step": 752500
    },
    {
      "epoch": 7.966308668702791,
      "eval_loss": 0.30894696712493896,
      "eval_runtime": 46.7728,
      "eval_samples_per_second": 3590.336,
      "eval_steps_per_second": 448.808,
      "step": 752500
    },
    {
      "epoch": 7.966837990482794,
      "grad_norm": 1.3287532329559326,
      "learning_rate": 6.0563984625088334e-05,
      "loss": 0.4984,
      "step": 752550
    },
    {
      "epoch": 7.967367312262798,
      "grad_norm": 1.1872658729553223,
      "learning_rate": 6.053384499791373e-05,
      "loss": 0.5092,
      "step": 752600
    },
    {
      "epoch": 7.967896634042801,
      "grad_norm": 1.2733575105667114,
      "learning_rate": 6.0503711839044076e-05,
      "loss": 0.5018,
      "step": 752650
    },
    {
      "epoch": 7.968425955822804,
      "grad_norm": 1.3490298986434937,
      "learning_rate": 6.047358514950832e-05,
      "loss": 0.5027,
      "step": 752700
    },
    {
      "epoch": 7.968955277602808,
      "grad_norm": 1.4031771421432495,
      "learning_rate": 6.0443464930334755e-05,
      "loss": 0.5045,
      "step": 752750
    },
    {
      "epoch": 7.9694845993828105,
      "grad_norm": 1.2832841873168945,
      "learning_rate": 6.0413351182551815e-05,
      "loss": 0.505,
      "step": 752800
    },
    {
      "epoch": 7.970013921162814,
      "grad_norm": 1.3893731832504272,
      "learning_rate": 6.038324390718758e-05,
      "loss": 0.4977,
      "step": 752850
    },
    {
      "epoch": 7.970543242942817,
      "grad_norm": 1.5014472007751465,
      "learning_rate": 6.035314310526979e-05,
      "loss": 0.5032,
      "step": 752900
    },
    {
      "epoch": 7.971072564722821,
      "grad_norm": 1.404263973236084,
      "learning_rate": 6.032304877782621e-05,
      "loss": 0.496,
      "step": 752950
    },
    {
      "epoch": 7.971601886502824,
      "grad_norm": 1.397655725479126,
      "learning_rate": 6.029296092588413e-05,
      "loss": 0.5115,
      "step": 753000
    },
    {
      "epoch": 7.971601886502824,
      "eval_loss": 0.308829128742218,
      "eval_runtime": 46.9252,
      "eval_samples_per_second": 3578.67,
      "eval_steps_per_second": 447.35,
      "step": 753000
    },
    {
      "epoch": 7.9721312082828275,
      "grad_norm": 1.3418166637420654,
      "learning_rate": 6.026287955047077e-05,
      "loss": 0.5089,
      "step": 753050
    },
    {
      "epoch": 7.97266053006283,
      "grad_norm": 1.2703475952148438,
      "learning_rate": 6.0232804652613185e-05,
      "loss": 0.5037,
      "step": 753100
    },
    {
      "epoch": 7.973189851842834,
      "grad_norm": 1.2461568117141724,
      "learning_rate": 6.0202736233338025e-05,
      "loss": 0.5005,
      "step": 753150
    },
    {
      "epoch": 7.973719173622837,
      "grad_norm": 1.4182888269424438,
      "learning_rate": 6.0172674293671794e-05,
      "loss": 0.496,
      "step": 753200
    },
    {
      "epoch": 7.97424849540284,
      "grad_norm": 1.3656706809997559,
      "learning_rate": 6.014261883464095e-05,
      "loss": 0.4977,
      "step": 753250
    },
    {
      "epoch": 7.974777817182844,
      "grad_norm": 1.2953948974609375,
      "learning_rate": 6.01125698572714e-05,
      "loss": 0.5006,
      "step": 753300
    },
    {
      "epoch": 7.975307138962847,
      "grad_norm": 1.401014804840088,
      "learning_rate": 6.008252736258912e-05,
      "loss": 0.4958,
      "step": 753350
    },
    {
      "epoch": 7.97583646074285,
      "grad_norm": 1.3102635145187378,
      "learning_rate": 6.005249135161966e-05,
      "loss": 0.5015,
      "step": 753400
    },
    {
      "epoch": 7.976365782522853,
      "grad_norm": 1.3764574527740479,
      "learning_rate": 6.0022461825388535e-05,
      "loss": 0.5023,
      "step": 753450
    },
    {
      "epoch": 7.976895104302857,
      "grad_norm": 1.3180347681045532,
      "learning_rate": 5.999243878492083e-05,
      "loss": 0.5084,
      "step": 753500
    },
    {
      "epoch": 7.976895104302857,
      "eval_loss": 0.3084022104740143,
      "eval_runtime": 46.825,
      "eval_samples_per_second": 3586.334,
      "eval_steps_per_second": 448.308,
      "step": 753500
    },
    {
      "epoch": 7.97742442608286,
      "grad_norm": 1.2579894065856934,
      "learning_rate": 5.9962422231241655e-05,
      "loss": 0.5012,
      "step": 753550
    },
    {
      "epoch": 7.9779537478628635,
      "grad_norm": 1.49946129322052,
      "learning_rate": 5.993241216537562e-05,
      "loss": 0.5065,
      "step": 753600
    },
    {
      "epoch": 7.978483069642866,
      "grad_norm": 1.2756832838058472,
      "learning_rate": 5.990240858834739e-05,
      "loss": 0.4981,
      "step": 753650
    },
    {
      "epoch": 7.97901239142287,
      "grad_norm": 1.389276385307312,
      "learning_rate": 5.9872411501181165e-05,
      "loss": 0.5043,
      "step": 753700
    },
    {
      "epoch": 7.979541713202873,
      "grad_norm": 1.3588640689849854,
      "learning_rate": 5.984242090490114e-05,
      "loss": 0.4991,
      "step": 753750
    },
    {
      "epoch": 7.980071034982877,
      "grad_norm": 1.3594136238098145,
      "learning_rate": 5.981243680053106e-05,
      "loss": 0.5069,
      "step": 753800
    },
    {
      "epoch": 7.98060035676288,
      "grad_norm": 1.36319100856781,
      "learning_rate": 5.97824591890947e-05,
      "loss": 0.5012,
      "step": 753850
    },
    {
      "epoch": 7.981129678542883,
      "grad_norm": 1.3557771444320679,
      "learning_rate": 5.975248807161535e-05,
      "loss": 0.5027,
      "step": 753900
    },
    {
      "epoch": 7.981659000322886,
      "grad_norm": 1.4136887788772583,
      "learning_rate": 5.9722523449116356e-05,
      "loss": 0.5061,
      "step": 753950
    },
    {
      "epoch": 7.982188322102889,
      "grad_norm": 1.3715227842330933,
      "learning_rate": 5.9692565322620575e-05,
      "loss": 0.5046,
      "step": 754000
    },
    {
      "epoch": 7.982188322102889,
      "eval_loss": 0.30859166383743286,
      "eval_runtime": 46.8992,
      "eval_samples_per_second": 3580.662,
      "eval_steps_per_second": 447.599,
      "step": 754000
    },
    {
      "epoch": 7.982717643882893,
      "grad_norm": 1.4300265312194824,
      "learning_rate": 5.9662613693150875e-05,
      "loss": 0.5054,
      "step": 754050
    },
    {
      "epoch": 7.983246965662897,
      "grad_norm": 1.4229662418365479,
      "learning_rate": 5.9632668561729694e-05,
      "loss": 0.4977,
      "step": 754100
    },
    {
      "epoch": 7.9837762874428995,
      "grad_norm": 1.3284400701522827,
      "learning_rate": 5.960272992937943e-05,
      "loss": 0.508,
      "step": 754150
    },
    {
      "epoch": 7.984305609222902,
      "grad_norm": 1.3172441720962524,
      "learning_rate": 5.9572797797122105e-05,
      "loss": 0.5043,
      "step": 754200
    },
    {
      "epoch": 7.984834931002906,
      "grad_norm": 1.4303338527679443,
      "learning_rate": 5.954287216597967e-05,
      "loss": 0.4993,
      "step": 754250
    },
    {
      "epoch": 7.985364252782909,
      "grad_norm": 1.382338047027588,
      "learning_rate": 5.9512953036973655e-05,
      "loss": 0.5023,
      "step": 754300
    },
    {
      "epoch": 7.985893574562913,
      "grad_norm": 1.408614158630371,
      "learning_rate": 5.948304041112565e-05,
      "loss": 0.4964,
      "step": 754350
    },
    {
      "epoch": 7.986422896342916,
      "grad_norm": 1.4352563619613647,
      "learning_rate": 5.94531342894567e-05,
      "loss": 0.5053,
      "step": 754400
    },
    {
      "epoch": 7.986952218122919,
      "grad_norm": 1.2407306432724,
      "learning_rate": 5.942323467298796e-05,
      "loss": 0.4921,
      "step": 754450
    },
    {
      "epoch": 7.987481539902922,
      "grad_norm": 1.386899709701538,
      "learning_rate": 5.9393341562739984e-05,
      "loss": 0.5035,
      "step": 754500
    },
    {
      "epoch": 7.987481539902922,
      "eval_loss": 0.3076167702674866,
      "eval_runtime": 46.9189,
      "eval_samples_per_second": 3579.151,
      "eval_steps_per_second": 447.41,
      "step": 754500
    },
    {
      "epoch": 7.988010861682926,
      "grad_norm": 1.410194754600525,
      "learning_rate": 5.936345495973352e-05,
      "loss": 0.4991,
      "step": 754550
    },
    {
      "epoch": 7.988540183462929,
      "grad_norm": 1.1830285787582397,
      "learning_rate": 5.9333574864988724e-05,
      "loss": 0.5035,
      "step": 754600
    },
    {
      "epoch": 7.989069505242933,
      "grad_norm": 1.2372556924819946,
      "learning_rate": 5.930370127952581e-05,
      "loss": 0.4984,
      "step": 754650
    },
    {
      "epoch": 7.9895988270229354,
      "grad_norm": 1.4269813299179077,
      "learning_rate": 5.927383420436452e-05,
      "loss": 0.4965,
      "step": 754700
    },
    {
      "epoch": 7.990128148802938,
      "grad_norm": 1.41376531124115,
      "learning_rate": 5.924397364052461e-05,
      "loss": 0.5025,
      "step": 754750
    },
    {
      "epoch": 7.990657470582942,
      "grad_norm": 1.436721920967102,
      "learning_rate": 5.921411958902553e-05,
      "loss": 0.5036,
      "step": 754800
    },
    {
      "epoch": 7.991186792362946,
      "grad_norm": 1.2382127046585083,
      "learning_rate": 5.918427205088639e-05,
      "loss": 0.5012,
      "step": 754850
    },
    {
      "epoch": 7.991716114142949,
      "grad_norm": 1.3399243354797363,
      "learning_rate": 5.91544310271262e-05,
      "loss": 0.4991,
      "step": 754900
    },
    {
      "epoch": 7.992245435922952,
      "grad_norm": 1.3436707258224487,
      "learning_rate": 5.912519314507361e-05,
      "loss": 0.5029,
      "step": 754950
    },
    {
      "epoch": 7.992774757702955,
      "grad_norm": 1.3066447973251343,
      "learning_rate": 5.9095365022789226e-05,
      "loss": 0.5047,
      "step": 755000
    },
    {
      "epoch": 7.992774757702955,
      "eval_loss": 0.3086684048175812,
      "eval_runtime": 46.9217,
      "eval_samples_per_second": 3578.944,
      "eval_steps_per_second": 447.384,
      "step": 755000
    },
    {
      "epoch": 7.993304079482958,
      "grad_norm": 1.3298922777175903,
      "learning_rate": 5.906554341791898e-05,
      "loss": 0.4981,
      "step": 755050
    },
    {
      "epoch": 7.993833401262962,
      "grad_norm": 1.2436392307281494,
      "learning_rate": 5.903572833148105e-05,
      "loss": 0.4931,
      "step": 755100
    },
    {
      "epoch": 7.994362723042965,
      "grad_norm": 1.4332833290100098,
      "learning_rate": 5.900591976449338e-05,
      "loss": 0.4918,
      "step": 755150
    },
    {
      "epoch": 7.994892044822969,
      "grad_norm": 1.4609745740890503,
      "learning_rate": 5.897611771797351e-05,
      "loss": 0.4965,
      "step": 755200
    },
    {
      "epoch": 7.995421366602971,
      "grad_norm": 1.338963508605957,
      "learning_rate": 5.8946322192938996e-05,
      "loss": 0.4995,
      "step": 755250
    },
    {
      "epoch": 7.995950688382975,
      "grad_norm": 1.3418452739715576,
      "learning_rate": 5.891653319040691e-05,
      "loss": 0.5013,
      "step": 755300
    },
    {
      "epoch": 7.996480010162978,
      "grad_norm": 1.4029333591461182,
      "learning_rate": 5.888675071139429e-05,
      "loss": 0.4951,
      "step": 755350
    },
    {
      "epoch": 7.997009331942982,
      "grad_norm": 1.3537882566452026,
      "learning_rate": 5.885697475691798e-05,
      "loss": 0.4994,
      "step": 755400
    },
    {
      "epoch": 7.997538653722985,
      "grad_norm": 1.286679983139038,
      "learning_rate": 5.8827205327994405e-05,
      "loss": 0.5018,
      "step": 755450
    },
    {
      "epoch": 7.9980679755029875,
      "grad_norm": 1.3588427305221558,
      "learning_rate": 5.8797442425639974e-05,
      "loss": 0.4971,
      "step": 755500
    },
    {
      "epoch": 7.9980679755029875,
      "eval_loss": 0.30782097578048706,
      "eval_runtime": 46.811,
      "eval_samples_per_second": 3587.403,
      "eval_steps_per_second": 448.441,
      "step": 755500
    },
    {
      "epoch": 7.998597297282991,
      "grad_norm": 1.3336492776870728,
      "learning_rate": 5.876768605087068e-05,
      "loss": 0.5026,
      "step": 755550
    },
    {
      "epoch": 7.999126619062995,
      "grad_norm": 1.441322922706604,
      "learning_rate": 5.8737936204702524e-05,
      "loss": 0.5047,
      "step": 755600
    },
    {
      "epoch": 7.999655940842998,
      "grad_norm": 1.383140206336975,
      "learning_rate": 5.870819288815099e-05,
      "loss": 0.5016,
      "step": 755650
    },
    {
      "epoch": 8.0001799694052,
      "grad_norm": 1.174824833869934,
      "learning_rate": 5.867845610223169e-05,
      "loss": 0.4982,
      "step": 755700
    },
    {
      "epoch": 8.000709291185204,
      "grad_norm": 1.3265739679336548,
      "learning_rate": 5.8648725847959664e-05,
      "loss": 0.4875,
      "step": 755750
    },
    {
      "epoch": 8.001238612965208,
      "grad_norm": 1.3388653993606567,
      "learning_rate": 5.8619002126350015e-05,
      "loss": 0.5027,
      "step": 755800
    },
    {
      "epoch": 8.00176793474521,
      "grad_norm": 1.4226409196853638,
      "learning_rate": 5.8589284938417395e-05,
      "loss": 0.4925,
      "step": 755850
    },
    {
      "epoch": 8.002297256525214,
      "grad_norm": 1.4628307819366455,
      "learning_rate": 5.855957428517644e-05,
      "loss": 0.5,
      "step": 755900
    },
    {
      "epoch": 8.002826578305218,
      "grad_norm": 1.4054489135742188,
      "learning_rate": 5.852987016764136e-05,
      "loss": 0.4963,
      "step": 755950
    },
    {
      "epoch": 8.003355900085221,
      "grad_norm": 1.2205301523208618,
      "learning_rate": 5.850017258682635e-05,
      "loss": 0.4945,
      "step": 756000
    },
    {
      "epoch": 8.003355900085221,
      "eval_loss": 0.30756884813308716,
      "eval_runtime": 46.7486,
      "eval_samples_per_second": 3592.196,
      "eval_steps_per_second": 449.041,
      "step": 756000
    },
    {
      "epoch": 8.003885221865223,
      "grad_norm": 1.2296416759490967,
      "learning_rate": 5.8470481543745153e-05,
      "loss": 0.5013,
      "step": 756050
    },
    {
      "epoch": 8.004414543645227,
      "grad_norm": 1.2953888177871704,
      "learning_rate": 5.8440797039411545e-05,
      "loss": 0.5058,
      "step": 756100
    },
    {
      "epoch": 8.004943865425231,
      "grad_norm": 1.2975232601165771,
      "learning_rate": 5.841111907483879e-05,
      "loss": 0.4934,
      "step": 756150
    },
    {
      "epoch": 8.005473187205235,
      "grad_norm": 1.3487563133239746,
      "learning_rate": 5.8381447651040255e-05,
      "loss": 0.5,
      "step": 756200
    },
    {
      "epoch": 8.006002508985237,
      "grad_norm": 1.3338091373443604,
      "learning_rate": 5.835178276902875e-05,
      "loss": 0.4927,
      "step": 756250
    },
    {
      "epoch": 8.00653183076524,
      "grad_norm": 1.2674447298049927,
      "learning_rate": 5.832212442981716e-05,
      "loss": 0.4989,
      "step": 756300
    },
    {
      "epoch": 8.007061152545244,
      "grad_norm": 1.2748279571533203,
      "learning_rate": 5.829247263441787e-05,
      "loss": 0.4986,
      "step": 756350
    },
    {
      "epoch": 8.007590474325246,
      "grad_norm": 1.2594717741012573,
      "learning_rate": 5.8262827383843335e-05,
      "loss": 0.4936,
      "step": 756400
    },
    {
      "epoch": 8.00811979610525,
      "grad_norm": 1.264620304107666,
      "learning_rate": 5.8233188679105485e-05,
      "loss": 0.4892,
      "step": 756450
    },
    {
      "epoch": 8.008649117885254,
      "grad_norm": 1.3064217567443848,
      "learning_rate": 5.8203556521216336e-05,
      "loss": 0.4851,
      "step": 756500
    },
    {
      "epoch": 8.008649117885254,
      "eval_loss": 0.30703315138816833,
      "eval_runtime": 46.888,
      "eval_samples_per_second": 3581.513,
      "eval_steps_per_second": 447.705,
      "step": 756500
    },
    {
      "epoch": 8.009178439665257,
      "grad_norm": 1.4033139944076538,
      "learning_rate": 5.8173930911187335e-05,
      "loss": 0.4875,
      "step": 756550
    },
    {
      "epoch": 8.00970776144526,
      "grad_norm": 1.5197371244430542,
      "learning_rate": 5.814431185003005e-05,
      "loss": 0.4903,
      "step": 756600
    },
    {
      "epoch": 8.010237083225263,
      "grad_norm": 1.4092693328857422,
      "learning_rate": 5.8114699338755545e-05,
      "loss": 0.4935,
      "step": 756650
    },
    {
      "epoch": 8.010766405005267,
      "grad_norm": 1.3362510204315186,
      "learning_rate": 5.8085093378374894e-05,
      "loss": 0.4961,
      "step": 756700
    },
    {
      "epoch": 8.01129572678527,
      "grad_norm": 1.276191234588623,
      "learning_rate": 5.8055493969898675e-05,
      "loss": 0.4944,
      "step": 756750
    },
    {
      "epoch": 8.011825048565273,
      "grad_norm": 1.3457857370376587,
      "learning_rate": 5.8025901114337534e-05,
      "loss": 0.4977,
      "step": 756800
    },
    {
      "epoch": 8.012354370345276,
      "grad_norm": 1.3866151571273804,
      "learning_rate": 5.799631481270179e-05,
      "loss": 0.4958,
      "step": 756850
    },
    {
      "epoch": 8.01288369212528,
      "grad_norm": 1.2737557888031006,
      "learning_rate": 5.796673506600136e-05,
      "loss": 0.4971,
      "step": 756900
    },
    {
      "epoch": 8.013413013905284,
      "grad_norm": 1.3268336057662964,
      "learning_rate": 5.793716187524617e-05,
      "loss": 0.5037,
      "step": 756950
    },
    {
      "epoch": 8.013942335685286,
      "grad_norm": 1.4612106084823608,
      "learning_rate": 5.7907595241445895e-05,
      "loss": 0.4949,
      "step": 757000
    },
    {
      "epoch": 8.013942335685286,
      "eval_loss": 0.30736640095710754,
      "eval_runtime": 46.7253,
      "eval_samples_per_second": 3593.983,
      "eval_steps_per_second": 449.264,
      "step": 757000
    },
    {
      "epoch": 8.01447165746529,
      "grad_norm": 1.4211499691009521,
      "learning_rate": 5.787803516560983e-05,
      "loss": 0.4919,
      "step": 757050
    },
    {
      "epoch": 8.015000979245293,
      "grad_norm": 1.4270343780517578,
      "learning_rate": 5.784848164874726e-05,
      "loss": 0.5007,
      "step": 757100
    },
    {
      "epoch": 8.015530301025295,
      "grad_norm": 1.4570413827896118,
      "learning_rate": 5.781893469186694e-05,
      "loss": 0.5003,
      "step": 757150
    },
    {
      "epoch": 8.0160596228053,
      "grad_norm": 1.2878004312515259,
      "learning_rate": 5.7789985039591404e-05,
      "loss": 0.4986,
      "step": 757200
    },
    {
      "epoch": 8.016588944585303,
      "grad_norm": 1.342518925666809,
      "learning_rate": 5.776045107445191e-05,
      "loss": 0.494,
      "step": 757250
    },
    {
      "epoch": 8.017118266365307,
      "grad_norm": 1.386425495147705,
      "learning_rate": 5.773092367230018e-05,
      "loss": 0.5032,
      "step": 757300
    },
    {
      "epoch": 8.017647588145309,
      "grad_norm": 1.3478292226791382,
      "learning_rate": 5.770140283414416e-05,
      "loss": 0.4894,
      "step": 757350
    },
    {
      "epoch": 8.018176909925312,
      "grad_norm": 1.3568925857543945,
      "learning_rate": 5.76718885609917e-05,
      "loss": 0.4892,
      "step": 757400
    },
    {
      "epoch": 8.018706231705316,
      "grad_norm": 1.3219894170761108,
      "learning_rate": 5.764238085385051e-05,
      "loss": 0.4972,
      "step": 757450
    },
    {
      "epoch": 8.01923555348532,
      "grad_norm": 1.4459391832351685,
      "learning_rate": 5.761287971372783e-05,
      "loss": 0.4968,
      "step": 757500
    },
    {
      "epoch": 8.01923555348532,
      "eval_loss": 0.3071257174015045,
      "eval_runtime": 46.9091,
      "eval_samples_per_second": 3579.904,
      "eval_steps_per_second": 447.504,
      "step": 757500
    },
    {
      "epoch": 8.019764875265322,
      "grad_norm": 1.277263879776001,
      "learning_rate": 5.758338514163094e-05,
      "loss": 0.4884,
      "step": 757550
    },
    {
      "epoch": 8.020294197045326,
      "grad_norm": 1.3427765369415283,
      "learning_rate": 5.7553897138566624e-05,
      "loss": 0.5006,
      "step": 757600
    },
    {
      "epoch": 8.02082351882533,
      "grad_norm": 1.4940251111984253,
      "learning_rate": 5.752441570554179e-05,
      "loss": 0.4878,
      "step": 757650
    },
    {
      "epoch": 8.021352840605333,
      "grad_norm": 1.2458903789520264,
      "learning_rate": 5.7494940843562714e-05,
      "loss": 0.4977,
      "step": 757700
    },
    {
      "epoch": 8.021882162385335,
      "grad_norm": 1.3071699142456055,
      "learning_rate": 5.746547255363585e-05,
      "loss": 0.4927,
      "step": 757750
    },
    {
      "epoch": 8.022411484165339,
      "grad_norm": 1.3860734701156616,
      "learning_rate": 5.743601083676708e-05,
      "loss": 0.4939,
      "step": 757800
    },
    {
      "epoch": 8.022940805945343,
      "grad_norm": 1.2551298141479492,
      "learning_rate": 5.7406555693962334e-05,
      "loss": 0.496,
      "step": 757850
    },
    {
      "epoch": 8.023470127725346,
      "grad_norm": 1.4113352298736572,
      "learning_rate": 5.737710712622707e-05,
      "loss": 0.4991,
      "step": 757900
    },
    {
      "epoch": 8.023999449505348,
      "grad_norm": 1.3621857166290283,
      "learning_rate": 5.7347665134566794e-05,
      "loss": 0.4981,
      "step": 757950
    },
    {
      "epoch": 8.024528771285352,
      "grad_norm": 1.4174950122833252,
      "learning_rate": 5.731822971998651e-05,
      "loss": 0.5044,
      "step": 758000
    },
    {
      "epoch": 8.024528771285352,
      "eval_loss": 0.30762994289398193,
      "eval_runtime": 46.8604,
      "eval_samples_per_second": 3583.623,
      "eval_steps_per_second": 447.969,
      "step": 758000
    },
    {
      "epoch": 8.025058093065356,
      "grad_norm": 1.425365686416626,
      "learning_rate": 5.7288800883491284e-05,
      "loss": 0.4951,
      "step": 758050
    },
    {
      "epoch": 8.025587414845358,
      "grad_norm": 1.3362641334533691,
      "learning_rate": 5.725937862608566e-05,
      "loss": 0.503,
      "step": 758100
    },
    {
      "epoch": 8.026116736625362,
      "grad_norm": 1.433775782585144,
      "learning_rate": 5.7229962948774197e-05,
      "loss": 0.4994,
      "step": 758150
    },
    {
      "epoch": 8.026646058405365,
      "grad_norm": 1.4510362148284912,
      "learning_rate": 5.7200553852561064e-05,
      "loss": 0.4897,
      "step": 758200
    },
    {
      "epoch": 8.02717538018537,
      "grad_norm": 1.3601293563842773,
      "learning_rate": 5.717115133845038e-05,
      "loss": 0.4985,
      "step": 758250
    },
    {
      "epoch": 8.027704701965371,
      "grad_norm": 1.2264224290847778,
      "learning_rate": 5.714175540744579e-05,
      "loss": 0.4956,
      "step": 758300
    },
    {
      "epoch": 8.028234023745375,
      "grad_norm": 1.3244794607162476,
      "learning_rate": 5.711236606055101e-05,
      "loss": 0.4969,
      "step": 758350
    },
    {
      "epoch": 8.028763345525379,
      "grad_norm": 1.3120722770690918,
      "learning_rate": 5.7082983298769265e-05,
      "loss": 0.5018,
      "step": 758400
    },
    {
      "epoch": 8.029292667305382,
      "grad_norm": 1.3936868906021118,
      "learning_rate": 5.7053607123103755e-05,
      "loss": 0.4963,
      "step": 758450
    },
    {
      "epoch": 8.029821989085384,
      "grad_norm": 1.3642337322235107,
      "learning_rate": 5.702423753455729e-05,
      "loss": 0.4973,
      "step": 758500
    },
    {
      "epoch": 8.029821989085384,
      "eval_loss": 0.30747225880622864,
      "eval_runtime": 46.9436,
      "eval_samples_per_second": 3577.274,
      "eval_steps_per_second": 447.175,
      "step": 758500
    },
    {
      "epoch": 8.030351310865388,
      "grad_norm": 1.3910075426101685,
      "learning_rate": 5.6994874534132655e-05,
      "loss": 0.4958,
      "step": 758550
    },
    {
      "epoch": 8.030880632645392,
      "grad_norm": 1.2670462131500244,
      "learning_rate": 5.6965518122832155e-05,
      "loss": 0.4888,
      "step": 758600
    },
    {
      "epoch": 8.031409954425396,
      "grad_norm": 1.485319972038269,
      "learning_rate": 5.6936168301658124e-05,
      "loss": 0.4976,
      "step": 758650
    },
    {
      "epoch": 8.031939276205398,
      "grad_norm": 1.2382245063781738,
      "learning_rate": 5.690682507161243e-05,
      "loss": 0.4988,
      "step": 758700
    },
    {
      "epoch": 8.032468597985401,
      "grad_norm": 1.2871540784835815,
      "learning_rate": 5.6877488433697e-05,
      "loss": 0.497,
      "step": 758750
    },
    {
      "epoch": 8.032997919765405,
      "grad_norm": 1.4294981956481934,
      "learning_rate": 5.684815838891322e-05,
      "loss": 0.5003,
      "step": 758800
    },
    {
      "epoch": 8.033527241545407,
      "grad_norm": 1.215827465057373,
      "learning_rate": 5.681883493826248e-05,
      "loss": 0.4953,
      "step": 758850
    },
    {
      "epoch": 8.03405656332541,
      "grad_norm": 1.2518963813781738,
      "learning_rate": 5.678951808274591e-05,
      "loss": 0.4992,
      "step": 758900
    },
    {
      "epoch": 8.034585885105415,
      "grad_norm": 1.2416733503341675,
      "learning_rate": 5.6760207823364304e-05,
      "loss": 0.4957,
      "step": 758950
    },
    {
      "epoch": 8.035115206885418,
      "grad_norm": 1.2863825559616089,
      "learning_rate": 5.673090416111831e-05,
      "loss": 0.4873,
      "step": 759000
    },
    {
      "epoch": 8.035115206885418,
      "eval_loss": 0.30697938799858093,
      "eval_runtime": 46.854,
      "eval_samples_per_second": 3584.113,
      "eval_steps_per_second": 448.03,
      "step": 759000
    },
    {
      "epoch": 8.03564452866542,
      "grad_norm": 1.3059871196746826,
      "learning_rate": 5.6701607097008446e-05,
      "loss": 0.4963,
      "step": 759050
    },
    {
      "epoch": 8.036173850445424,
      "grad_norm": 1.3166964054107666,
      "learning_rate": 5.6672316632034735e-05,
      "loss": 0.4923,
      "step": 759100
    },
    {
      "epoch": 8.036703172225428,
      "grad_norm": 1.2668603658676147,
      "learning_rate": 5.6643032767197314e-05,
      "loss": 0.4977,
      "step": 759150
    },
    {
      "epoch": 8.037232494005432,
      "grad_norm": 1.4687608480453491,
      "learning_rate": 5.661375550349579e-05,
      "loss": 0.4962,
      "step": 759200
    },
    {
      "epoch": 8.037761815785434,
      "grad_norm": 1.3338758945465088,
      "learning_rate": 5.6584484841929794e-05,
      "loss": 0.4978,
      "step": 759250
    },
    {
      "epoch": 8.038291137565437,
      "grad_norm": 1.2402180433273315,
      "learning_rate": 5.655522078349848e-05,
      "loss": 0.4922,
      "step": 759300
    },
    {
      "epoch": 8.038820459345441,
      "grad_norm": 1.427565574645996,
      "learning_rate": 5.652596332920104e-05,
      "loss": 0.4987,
      "step": 759350
    },
    {
      "epoch": 8.039349781125445,
      "grad_norm": 1.3364989757537842,
      "learning_rate": 5.6496712480036214e-05,
      "loss": 0.4969,
      "step": 759400
    },
    {
      "epoch": 8.039879102905447,
      "grad_norm": 1.4027483463287354,
      "learning_rate": 5.646746823700272e-05,
      "loss": 0.502,
      "step": 759450
    },
    {
      "epoch": 8.04040842468545,
      "grad_norm": 1.382015347480774,
      "learning_rate": 5.643823060109879e-05,
      "loss": 0.4997,
      "step": 759500
    },
    {
      "epoch": 8.04040842468545,
      "eval_loss": 0.3074054419994354,
      "eval_runtime": 46.7727,
      "eval_samples_per_second": 3590.344,
      "eval_steps_per_second": 448.809,
      "step": 759500
    },
    {
      "epoch": 8.040937746465454,
      "grad_norm": 1.2538961172103882,
      "learning_rate": 5.640899957332277e-05,
      "loss": 0.501,
      "step": 759550
    },
    {
      "epoch": 8.041467068245456,
      "grad_norm": 1.2841888666152954,
      "learning_rate": 5.6379775154672435e-05,
      "loss": 0.4976,
      "step": 759600
    },
    {
      "epoch": 8.04199639002546,
      "grad_norm": 1.271011471748352,
      "learning_rate": 5.6350557346145636e-05,
      "loss": 0.4908,
      "step": 759650
    },
    {
      "epoch": 8.042525711805464,
      "grad_norm": 1.2488514184951782,
      "learning_rate": 5.6321346148739736e-05,
      "loss": 0.4912,
      "step": 759700
    },
    {
      "epoch": 8.043055033585468,
      "grad_norm": 1.417614459991455,
      "learning_rate": 5.629214156345211e-05,
      "loss": 0.4909,
      "step": 759750
    },
    {
      "epoch": 8.04358435536547,
      "grad_norm": 1.3454389572143555,
      "learning_rate": 5.626294359127965e-05,
      "loss": 0.5014,
      "step": 759800
    },
    {
      "epoch": 8.044113677145473,
      "grad_norm": 1.4544004201889038,
      "learning_rate": 5.623375223321933e-05,
      "loss": 0.5006,
      "step": 759850
    },
    {
      "epoch": 8.044642998925477,
      "grad_norm": 1.4350351095199585,
      "learning_rate": 5.620456749026756e-05,
      "loss": 0.4922,
      "step": 759900
    },
    {
      "epoch": 8.04517232070548,
      "grad_norm": 1.271788239479065,
      "learning_rate": 5.617538936342087e-05,
      "loss": 0.4819,
      "step": 759950
    },
    {
      "epoch": 8.045701642485483,
      "grad_norm": 1.4935563802719116,
      "learning_rate": 5.614621785367524e-05,
      "loss": 0.4934,
      "step": 760000
    },
    {
      "epoch": 8.045701642485483,
      "eval_loss": 0.30659884214401245,
      "eval_runtime": 46.8519,
      "eval_samples_per_second": 3584.271,
      "eval_steps_per_second": 448.05,
      "step": 760000
    },
    {
      "epoch": 8.046230964265487,
      "grad_norm": 1.3576796054840088,
      "learning_rate": 5.611705296202668e-05,
      "loss": 0.5012,
      "step": 760050
    },
    {
      "epoch": 8.04676028604549,
      "grad_norm": 1.4241695404052734,
      "learning_rate": 5.6087894689470784e-05,
      "loss": 0.4953,
      "step": 760100
    },
    {
      "epoch": 8.047289607825494,
      "grad_norm": 1.3615204095840454,
      "learning_rate": 5.605874303700304e-05,
      "loss": 0.5013,
      "step": 760150
    },
    {
      "epoch": 8.047818929605496,
      "grad_norm": 1.470329999923706,
      "learning_rate": 5.602959800561874e-05,
      "loss": 0.4967,
      "step": 760200
    },
    {
      "epoch": 8.0483482513855,
      "grad_norm": 1.2266502380371094,
      "learning_rate": 5.6000459596312755e-05,
      "loss": 0.4974,
      "step": 760250
    },
    {
      "epoch": 8.048877573165504,
      "grad_norm": 1.503546953201294,
      "learning_rate": 5.597132781008002e-05,
      "loss": 0.4983,
      "step": 760300
    },
    {
      "epoch": 8.049406894945506,
      "grad_norm": 1.4898154735565186,
      "learning_rate": 5.5942202647914915e-05,
      "loss": 0.4957,
      "step": 760350
    },
    {
      "epoch": 8.04993621672551,
      "grad_norm": 1.3221913576126099,
      "learning_rate": 5.591308411081192e-05,
      "loss": 0.4904,
      "step": 760400
    },
    {
      "epoch": 8.050465538505513,
      "grad_norm": 1.3815321922302246,
      "learning_rate": 5.588397219976499e-05,
      "loss": 0.4982,
      "step": 760450
    },
    {
      "epoch": 8.050994860285517,
      "grad_norm": 1.378096580505371,
      "learning_rate": 5.585486691576813e-05,
      "loss": 0.4923,
      "step": 760500
    },
    {
      "epoch": 8.050994860285517,
      "eval_loss": 0.3067270517349243,
      "eval_runtime": 46.7614,
      "eval_samples_per_second": 3591.207,
      "eval_steps_per_second": 448.917,
      "step": 760500
    },
    {
      "epoch": 8.051524182065519,
      "grad_norm": 1.3254609107971191,
      "learning_rate": 5.5825768259814837e-05,
      "loss": 0.499,
      "step": 760550
    },
    {
      "epoch": 8.052053503845523,
      "grad_norm": 1.3060392141342163,
      "learning_rate": 5.579667623289866e-05,
      "loss": 0.5019,
      "step": 760600
    },
    {
      "epoch": 8.052582825625526,
      "grad_norm": 1.3041296005249023,
      "learning_rate": 5.576759083601268e-05,
      "loss": 0.4973,
      "step": 760650
    },
    {
      "epoch": 8.05311214740553,
      "grad_norm": 1.3297462463378906,
      "learning_rate": 5.573851207014991e-05,
      "loss": 0.4917,
      "step": 760700
    },
    {
      "epoch": 8.053641469185532,
      "grad_norm": 1.2969508171081543,
      "learning_rate": 5.5709439936303144e-05,
      "loss": 0.5045,
      "step": 760750
    },
    {
      "epoch": 8.054170790965536,
      "grad_norm": 1.400456428527832,
      "learning_rate": 5.568037443546481e-05,
      "loss": 0.5103,
      "step": 760800
    },
    {
      "epoch": 8.05470011274554,
      "grad_norm": 1.5416982173919678,
      "learning_rate": 5.565131556862721e-05,
      "loss": 0.4943,
      "step": 760850
    },
    {
      "epoch": 8.055229434525543,
      "grad_norm": 1.3279995918273926,
      "learning_rate": 5.56222633367825e-05,
      "loss": 0.5003,
      "step": 760900
    },
    {
      "epoch": 8.055758756305545,
      "grad_norm": 1.228827714920044,
      "learning_rate": 5.559321774092235e-05,
      "loss": 0.4931,
      "step": 760950
    },
    {
      "epoch": 8.056288078085549,
      "grad_norm": 1.3924282789230347,
      "learning_rate": 5.5564178782038536e-05,
      "loss": 0.4959,
      "step": 761000
    },
    {
      "epoch": 8.056288078085549,
      "eval_loss": 0.3065900504589081,
      "eval_runtime": 46.891,
      "eval_samples_per_second": 3581.283,
      "eval_steps_per_second": 447.676,
      "step": 761000
    },
    {
      "epoch": 8.056817399865553,
      "grad_norm": 1.243930697441101,
      "learning_rate": 5.5535146461122286e-05,
      "loss": 0.4943,
      "step": 761050
    },
    {
      "epoch": 8.057346721645555,
      "grad_norm": 1.4790465831756592,
      "learning_rate": 5.550612077916487e-05,
      "loss": 0.5028,
      "step": 761100
    },
    {
      "epoch": 8.057876043425559,
      "grad_norm": 1.4036868810653687,
      "learning_rate": 5.547710173715709e-05,
      "loss": 0.5026,
      "step": 761150
    },
    {
      "epoch": 8.058405365205562,
      "grad_norm": 1.1654731035232544,
      "learning_rate": 5.544866951902356e-05,
      "loss": 0.4906,
      "step": 761200
    },
    {
      "epoch": 8.058934686985566,
      "grad_norm": 1.161446213722229,
      "learning_rate": 5.541966362703874e-05,
      "loss": 0.503,
      "step": 761250
    },
    {
      "epoch": 8.059464008765568,
      "grad_norm": 1.330509066581726,
      "learning_rate": 5.5390664377955255e-05,
      "loss": 0.4893,
      "step": 761300
    },
    {
      "epoch": 8.059993330545572,
      "grad_norm": 1.4456939697265625,
      "learning_rate": 5.536167177276319e-05,
      "loss": 0.5005,
      "step": 761350
    },
    {
      "epoch": 8.060522652325576,
      "grad_norm": 1.1867337226867676,
      "learning_rate": 5.533268581245221e-05,
      "loss": 0.4871,
      "step": 761400
    },
    {
      "epoch": 8.06105197410558,
      "grad_norm": 1.4979488849639893,
      "learning_rate": 5.5303706498012005e-05,
      "loss": 0.4972,
      "step": 761450
    },
    {
      "epoch": 8.061581295885581,
      "grad_norm": 1.2650014162063599,
      "learning_rate": 5.527473383043177e-05,
      "loss": 0.4963,
      "step": 761500
    },
    {
      "epoch": 8.061581295885581,
      "eval_loss": 0.30685898661613464,
      "eval_runtime": 46.7192,
      "eval_samples_per_second": 3594.457,
      "eval_steps_per_second": 449.323,
      "step": 761500
    },
    {
      "epoch": 8.062110617665585,
      "grad_norm": 1.4194973707199097,
      "learning_rate": 5.5245767810700786e-05,
      "loss": 0.4884,
      "step": 761550
    },
    {
      "epoch": 8.062639939445589,
      "grad_norm": 1.3300161361694336,
      "learning_rate": 5.521738756206068e-05,
      "loss": 0.5049,
      "step": 761600
    },
    {
      "epoch": 8.063169261225593,
      "grad_norm": 1.2448201179504395,
      "learning_rate": 5.518843470798821e-05,
      "loss": 0.5026,
      "step": 761650
    },
    {
      "epoch": 8.063698583005595,
      "grad_norm": 1.4531923532485962,
      "learning_rate": 5.5159488504711195e-05,
      "loss": 0.4937,
      "step": 761700
    },
    {
      "epoch": 8.064227904785598,
      "grad_norm": 1.3473646640777588,
      "learning_rate": 5.5130548953217704e-05,
      "loss": 0.5081,
      "step": 761750
    },
    {
      "epoch": 8.064757226565602,
      "grad_norm": 1.4271516799926758,
      "learning_rate": 5.51016160544959e-05,
      "loss": 0.4975,
      "step": 761800
    },
    {
      "epoch": 8.065286548345604,
      "grad_norm": 1.3812694549560547,
      "learning_rate": 5.5072689809533364e-05,
      "loss": 0.4946,
      "step": 761850
    },
    {
      "epoch": 8.065815870125608,
      "grad_norm": 1.3306150436401367,
      "learning_rate": 5.5043770219317777e-05,
      "loss": 0.4909,
      "step": 761900
    },
    {
      "epoch": 8.066345191905612,
      "grad_norm": 1.31452476978302,
      "learning_rate": 5.501485728483629e-05,
      "loss": 0.4996,
      "step": 761950
    },
    {
      "epoch": 8.066874513685615,
      "grad_norm": 1.2341095209121704,
      "learning_rate": 5.498595100707618e-05,
      "loss": 0.5027,
      "step": 762000
    },
    {
      "epoch": 8.066874513685615,
      "eval_loss": 0.3066607117652893,
      "eval_runtime": 46.8665,
      "eval_samples_per_second": 3583.159,
      "eval_steps_per_second": 447.911,
      "step": 762000
    },
    {
      "epoch": 8.067403835465617,
      "grad_norm": 1.2170429229736328,
      "learning_rate": 5.495705138702409e-05,
      "loss": 0.4954,
      "step": 762050
    },
    {
      "epoch": 8.067933157245621,
      "grad_norm": 1.406814455986023,
      "learning_rate": 5.4928158425666784e-05,
      "loss": 0.5007,
      "step": 762100
    },
    {
      "epoch": 8.068462479025625,
      "grad_norm": 1.1792019605636597,
      "learning_rate": 5.489927212399057e-05,
      "loss": 0.4945,
      "step": 762150
    },
    {
      "epoch": 8.068991800805629,
      "grad_norm": 1.2858693599700928,
      "learning_rate": 5.4870392482981704e-05,
      "loss": 0.4927,
      "step": 762200
    },
    {
      "epoch": 8.06952112258563,
      "grad_norm": 1.2995872497558594,
      "learning_rate": 5.484151950362601e-05,
      "loss": 0.495,
      "step": 762250
    },
    {
      "epoch": 8.070050444365634,
      "grad_norm": 1.346768856048584,
      "learning_rate": 5.481265318690937e-05,
      "loss": 0.4995,
      "step": 762300
    },
    {
      "epoch": 8.070579766145638,
      "grad_norm": 1.2825387716293335,
      "learning_rate": 5.4783793533817046e-05,
      "loss": 0.491,
      "step": 762350
    },
    {
      "epoch": 8.071109087925642,
      "grad_norm": 1.2951431274414062,
      "learning_rate": 5.475494054533453e-05,
      "loss": 0.5,
      "step": 762400
    },
    {
      "epoch": 8.071638409705644,
      "grad_norm": 1.3982731103897095,
      "learning_rate": 5.472609422244665e-05,
      "loss": 0.4918,
      "step": 762450
    },
    {
      "epoch": 8.072167731485647,
      "grad_norm": 1.2346192598342896,
      "learning_rate": 5.469725456613836e-05,
      "loss": 0.4925,
      "step": 762500
    },
    {
      "epoch": 8.072167731485647,
      "eval_loss": 0.3071954846382141,
      "eval_runtime": 46.797,
      "eval_samples_per_second": 3588.48,
      "eval_steps_per_second": 448.576,
      "step": 762500
    },
    {
      "epoch": 8.072697053265651,
      "grad_norm": 1.406672477722168,
      "learning_rate": 5.466842157739413e-05,
      "loss": 0.4852,
      "step": 762550
    },
    {
      "epoch": 8.073226375045653,
      "grad_norm": 1.2784850597381592,
      "learning_rate": 5.463959525719839e-05,
      "loss": 0.4896,
      "step": 762600
    },
    {
      "epoch": 8.073755696825657,
      "grad_norm": 1.1626073122024536,
      "learning_rate": 5.461077560653518e-05,
      "loss": 0.4969,
      "step": 762650
    },
    {
      "epoch": 8.07428501860566,
      "grad_norm": 1.2714840173721313,
      "learning_rate": 5.4581962626388484e-05,
      "loss": 0.4933,
      "step": 762700
    },
    {
      "epoch": 8.074814340385664,
      "grad_norm": 1.2555583715438843,
      "learning_rate": 5.4553156317741856e-05,
      "loss": 0.4956,
      "step": 762750
    },
    {
      "epoch": 8.075343662165666,
      "grad_norm": 1.4529780149459839,
      "learning_rate": 5.452435668157887e-05,
      "loss": 0.5,
      "step": 762800
    },
    {
      "epoch": 8.07587298394567,
      "grad_norm": 1.4698853492736816,
      "learning_rate": 5.449556371888256e-05,
      "loss": 0.5048,
      "step": 762850
    },
    {
      "epoch": 8.076402305725674,
      "grad_norm": 1.2717517614364624,
      "learning_rate": 5.4466777430636106e-05,
      "loss": 0.4994,
      "step": 762900
    },
    {
      "epoch": 8.076931627505678,
      "grad_norm": 1.4224048852920532,
      "learning_rate": 5.4437997817822076e-05,
      "loss": 0.5033,
      "step": 762950
    },
    {
      "epoch": 8.07746094928568,
      "grad_norm": 1.2458244562149048,
      "learning_rate": 5.440922488142316e-05,
      "loss": 0.4971,
      "step": 763000
    },
    {
      "epoch": 8.07746094928568,
      "eval_loss": 0.3062223196029663,
      "eval_runtime": 46.779,
      "eval_samples_per_second": 3589.861,
      "eval_steps_per_second": 448.749,
      "step": 763000
    },
    {
      "epoch": 8.077990271065683,
      "grad_norm": 1.282767653465271,
      "learning_rate": 5.43804586224215e-05,
      "loss": 0.5004,
      "step": 763050
    },
    {
      "epoch": 8.078519592845687,
      "grad_norm": 1.3189167976379395,
      "learning_rate": 5.435169904179932e-05,
      "loss": 0.5004,
      "step": 763100
    },
    {
      "epoch": 8.079048914625691,
      "grad_norm": 1.3213635683059692,
      "learning_rate": 5.432294614053829e-05,
      "loss": 0.4874,
      "step": 763150
    },
    {
      "epoch": 8.079578236405693,
      "grad_norm": 1.3738226890563965,
      "learning_rate": 5.4294199919620144e-05,
      "loss": 0.4906,
      "step": 763200
    },
    {
      "epoch": 8.080107558185697,
      "grad_norm": 1.3714755773544312,
      "learning_rate": 5.426546038002628e-05,
      "loss": 0.4947,
      "step": 763250
    },
    {
      "epoch": 8.0806368799657,
      "grad_norm": 1.3909351825714111,
      "learning_rate": 5.423672752273775e-05,
      "loss": 0.4966,
      "step": 763300
    },
    {
      "epoch": 8.081166201745702,
      "grad_norm": 1.3391826152801514,
      "learning_rate": 5.4208001348735576e-05,
      "loss": 0.4822,
      "step": 763350
    },
    {
      "epoch": 8.081695523525706,
      "grad_norm": 1.1335597038269043,
      "learning_rate": 5.417928185900048e-05,
      "loss": 0.496,
      "step": 763400
    },
    {
      "epoch": 8.08222484530571,
      "grad_norm": 1.4191880226135254,
      "learning_rate": 5.415056905451282e-05,
      "loss": 0.486,
      "step": 763450
    },
    {
      "epoch": 8.082754167085714,
      "grad_norm": 1.3509235382080078,
      "learning_rate": 5.4121862936252985e-05,
      "loss": 0.491,
      "step": 763500
    },
    {
      "epoch": 8.082754167085714,
      "eval_loss": 0.3061818778514862,
      "eval_runtime": 46.7752,
      "eval_samples_per_second": 3590.151,
      "eval_steps_per_second": 448.785,
      "step": 763500
    },
    {
      "epoch": 8.083283488865716,
      "grad_norm": 1.3381268978118896,
      "learning_rate": 5.4093163505200826e-05,
      "loss": 0.4906,
      "step": 763550
    },
    {
      "epoch": 8.08381281064572,
      "grad_norm": 1.1800506114959717,
      "learning_rate": 5.406447076233631e-05,
      "loss": 0.4956,
      "step": 763600
    },
    {
      "epoch": 8.084342132425723,
      "grad_norm": 1.3835433721542358,
      "learning_rate": 5.403578470863882e-05,
      "loss": 0.5012,
      "step": 763650
    },
    {
      "epoch": 8.084871454205727,
      "grad_norm": 1.4075485467910767,
      "learning_rate": 5.400710534508785e-05,
      "loss": 0.4952,
      "step": 763700
    },
    {
      "epoch": 8.085400775985729,
      "grad_norm": 1.2996360063552856,
      "learning_rate": 5.397843267266234e-05,
      "loss": 0.4932,
      "step": 763750
    },
    {
      "epoch": 8.085930097765733,
      "grad_norm": 1.327116847038269,
      "learning_rate": 5.3949766692341336e-05,
      "loss": 0.4967,
      "step": 763800
    },
    {
      "epoch": 8.086459419545736,
      "grad_norm": 1.4166470766067505,
      "learning_rate": 5.3921107405103306e-05,
      "loss": 0.495,
      "step": 763850
    },
    {
      "epoch": 8.08698874132574,
      "grad_norm": 1.3074584007263184,
      "learning_rate": 5.389245481192684e-05,
      "loss": 0.4903,
      "step": 763900
    },
    {
      "epoch": 8.087518063105742,
      "grad_norm": 1.4073326587677002,
      "learning_rate": 5.3863808913790005e-05,
      "loss": 0.5025,
      "step": 763950
    },
    {
      "epoch": 8.088047384885746,
      "grad_norm": 1.6274293661117554,
      "learning_rate": 5.3835169711670825e-05,
      "loss": 0.5027,
      "step": 764000
    },
    {
      "epoch": 8.088047384885746,
      "eval_loss": 0.3064793646335602,
      "eval_runtime": 46.7742,
      "eval_samples_per_second": 3590.228,
      "eval_steps_per_second": 448.795,
      "step": 764000
    },
    {
      "epoch": 8.08857670666575,
      "grad_norm": 1.4583529233932495,
      "learning_rate": 5.380653720654696e-05,
      "loss": 0.5029,
      "step": 764050
    },
    {
      "epoch": 8.089106028445752,
      "grad_norm": 1.3115159273147583,
      "learning_rate": 5.3777911399396054e-05,
      "loss": 0.4941,
      "step": 764100
    },
    {
      "epoch": 8.089635350225755,
      "grad_norm": 1.479313611984253,
      "learning_rate": 5.3749292291195184e-05,
      "loss": 0.4932,
      "step": 764150
    },
    {
      "epoch": 8.09016467200576,
      "grad_norm": 1.3561235666275024,
      "learning_rate": 5.372067988292159e-05,
      "loss": 0.5071,
      "step": 764200
    },
    {
      "epoch": 8.090693993785763,
      "grad_norm": 1.2851040363311768,
      "learning_rate": 5.369207417555194e-05,
      "loss": 0.4995,
      "step": 764250
    },
    {
      "epoch": 8.091223315565765,
      "grad_norm": 1.2289693355560303,
      "learning_rate": 5.3663475170062956e-05,
      "loss": 0.4986,
      "step": 764300
    },
    {
      "epoch": 8.091752637345769,
      "grad_norm": 1.2727798223495483,
      "learning_rate": 5.3634882867430844e-05,
      "loss": 0.4888,
      "step": 764350
    },
    {
      "epoch": 8.092281959125772,
      "grad_norm": 1.2543308734893799,
      "learning_rate": 5.360629726863189e-05,
      "loss": 0.497,
      "step": 764400
    },
    {
      "epoch": 8.092811280905776,
      "grad_norm": 1.4310829639434814,
      "learning_rate": 5.357771837464184e-05,
      "loss": 0.4961,
      "step": 764450
    },
    {
      "epoch": 8.093340602685778,
      "grad_norm": 1.270215392112732,
      "learning_rate": 5.3549146186436523e-05,
      "loss": 0.4889,
      "step": 764500
    },
    {
      "epoch": 8.093340602685778,
      "eval_loss": 0.3060009777545929,
      "eval_runtime": 46.8301,
      "eval_samples_per_second": 3585.938,
      "eval_steps_per_second": 448.258,
      "step": 764500
    },
    {
      "epoch": 8.093869924465782,
      "grad_norm": 1.4061765670776367,
      "learning_rate": 5.3520580704991244e-05,
      "loss": 0.491,
      "step": 764550
    },
    {
      "epoch": 8.094399246245786,
      "grad_norm": 1.2019658088684082,
      "learning_rate": 5.349202193128136e-05,
      "loss": 0.4918,
      "step": 764600
    },
    {
      "epoch": 8.09492856802579,
      "grad_norm": 1.486685037612915,
      "learning_rate": 5.34634698662817e-05,
      "loss": 0.4956,
      "step": 764650
    },
    {
      "epoch": 8.095457889805791,
      "grad_norm": 1.3940199613571167,
      "learning_rate": 5.343492451096718e-05,
      "loss": 0.4905,
      "step": 764700
    },
    {
      "epoch": 8.095987211585795,
      "grad_norm": 1.4272176027297974,
      "learning_rate": 5.3406385866312166e-05,
      "loss": 0.4891,
      "step": 764750
    },
    {
      "epoch": 8.096516533365799,
      "grad_norm": 1.240032434463501,
      "learning_rate": 5.3377853933291056e-05,
      "loss": 0.4977,
      "step": 764800
    },
    {
      "epoch": 8.0970458551458,
      "grad_norm": 1.445009708404541,
      "learning_rate": 5.3349328712877956e-05,
      "loss": 0.4944,
      "step": 764850
    },
    {
      "epoch": 8.097575176925805,
      "grad_norm": 1.2130380868911743,
      "learning_rate": 5.332081020604659e-05,
      "loss": 0.4911,
      "step": 764900
    },
    {
      "epoch": 8.098104498705808,
      "grad_norm": 1.310278058052063,
      "learning_rate": 5.329229841377065e-05,
      "loss": 0.4949,
      "step": 764950
    },
    {
      "epoch": 8.098633820485812,
      "grad_norm": 1.2880226373672485,
      "learning_rate": 5.326379333702355e-05,
      "loss": 0.4957,
      "step": 765000
    },
    {
      "epoch": 8.098633820485812,
      "eval_loss": 0.30642610788345337,
      "eval_runtime": 46.8562,
      "eval_samples_per_second": 3583.944,
      "eval_steps_per_second": 448.009,
      "step": 765000
    },
    {
      "epoch": 8.099163142265814,
      "grad_norm": 1.4012051820755005,
      "learning_rate": 5.323529497677834e-05,
      "loss": 0.5001,
      "step": 765050
    },
    {
      "epoch": 8.099692464045818,
      "grad_norm": 1.2695339918136597,
      "learning_rate": 5.3206803334008044e-05,
      "loss": 0.49,
      "step": 765100
    },
    {
      "epoch": 8.100221785825822,
      "grad_norm": 1.2288506031036377,
      "learning_rate": 5.317831840968526e-05,
      "loss": 0.4867,
      "step": 765150
    },
    {
      "epoch": 8.100751107605825,
      "grad_norm": 1.2934753894805908,
      "learning_rate": 5.314984020478258e-05,
      "loss": 0.4867,
      "step": 765200
    },
    {
      "epoch": 8.101280429385827,
      "grad_norm": 1.3879462480545044,
      "learning_rate": 5.312136872027207e-05,
      "loss": 0.4955,
      "step": 765250
    },
    {
      "epoch": 8.101809751165831,
      "grad_norm": 1.3241299390792847,
      "learning_rate": 5.30929039571259e-05,
      "loss": 0.4936,
      "step": 765300
    },
    {
      "epoch": 8.102339072945835,
      "grad_norm": 1.42574143409729,
      "learning_rate": 5.306444591631573e-05,
      "loss": 0.4958,
      "step": 765350
    },
    {
      "epoch": 8.102868394725839,
      "grad_norm": 1.2717854976654053,
      "learning_rate": 5.3035994598813224e-05,
      "loss": 0.4998,
      "step": 765400
    },
    {
      "epoch": 8.10339771650584,
      "grad_norm": 1.2827422618865967,
      "learning_rate": 5.3007550005589544e-05,
      "loss": 0.4846,
      "step": 765450
    },
    {
      "epoch": 8.103927038285844,
      "grad_norm": 1.3920682668685913,
      "learning_rate": 5.297911213761591e-05,
      "loss": 0.4941,
      "step": 765500
    },
    {
      "epoch": 8.103927038285844,
      "eval_loss": 0.3055294454097748,
      "eval_runtime": 46.8871,
      "eval_samples_per_second": 3581.584,
      "eval_steps_per_second": 447.714,
      "step": 765500
    },
    {
      "epoch": 8.104456360065848,
      "grad_norm": 1.4500269889831543,
      "learning_rate": 5.295068099586309e-05,
      "loss": 0.4823,
      "step": 765550
    },
    {
      "epoch": 8.10498568184585,
      "grad_norm": 1.3831185102462769,
      "learning_rate": 5.292282500366025e-05,
      "loss": 0.4911,
      "step": 765600
    },
    {
      "epoch": 8.105515003625854,
      "grad_norm": 1.4308745861053467,
      "learning_rate": 5.289497547316552e-05,
      "loss": 0.4976,
      "step": 765650
    },
    {
      "epoch": 8.106044325405858,
      "grad_norm": 1.4028289318084717,
      "learning_rate": 5.286656424671421e-05,
      "loss": 0.4964,
      "step": 765700
    },
    {
      "epoch": 8.106573647185861,
      "grad_norm": 1.2958451509475708,
      "learning_rate": 5.283815975032616e-05,
      "loss": 0.5047,
      "step": 765750
    },
    {
      "epoch": 8.107102968965863,
      "grad_norm": 1.3199084997177124,
      "learning_rate": 5.280976198497098e-05,
      "loss": 0.4869,
      "step": 765800
    },
    {
      "epoch": 8.107632290745867,
      "grad_norm": 1.2357581853866577,
      "learning_rate": 5.278137095161819e-05,
      "loss": 0.4938,
      "step": 765850
    },
    {
      "epoch": 8.10816161252587,
      "grad_norm": 1.29982590675354,
      "learning_rate": 5.275298665123715e-05,
      "loss": 0.4983,
      "step": 765900
    },
    {
      "epoch": 8.108690934305875,
      "grad_norm": 1.1951866149902344,
      "learning_rate": 5.272460908479673e-05,
      "loss": 0.4977,
      "step": 765950
    },
    {
      "epoch": 8.109220256085877,
      "grad_norm": 1.2822169065475464,
      "learning_rate": 5.26962382532658e-05,
      "loss": 0.497,
      "step": 766000
    },
    {
      "epoch": 8.109220256085877,
      "eval_loss": 0.3054819703102112,
      "eval_runtime": 46.7565,
      "eval_samples_per_second": 3591.588,
      "eval_steps_per_second": 448.965,
      "step": 766000
    },
    {
      "epoch": 8.10974957786588,
      "grad_norm": 1.2843568325042725,
      "learning_rate": 5.266787415761301e-05,
      "loss": 0.4962,
      "step": 766050
    },
    {
      "epoch": 8.110278899645884,
      "grad_norm": 1.3729901313781738,
      "learning_rate": 5.263951679880658e-05,
      "loss": 0.4937,
      "step": 766100
    },
    {
      "epoch": 8.110808221425888,
      "grad_norm": 1.3820538520812988,
      "learning_rate": 5.2611166177814695e-05,
      "loss": 0.4978,
      "step": 766150
    },
    {
      "epoch": 8.11133754320589,
      "grad_norm": 1.3105159997940063,
      "learning_rate": 5.258282229560518e-05,
      "loss": 0.496,
      "step": 766200
    },
    {
      "epoch": 8.111866864985894,
      "grad_norm": 1.4118980169296265,
      "learning_rate": 5.255448515314576e-05,
      "loss": 0.4972,
      "step": 766250
    },
    {
      "epoch": 8.112396186765897,
      "grad_norm": 1.3297176361083984,
      "learning_rate": 5.252615475140374e-05,
      "loss": 0.4992,
      "step": 766300
    },
    {
      "epoch": 8.1129255085459,
      "grad_norm": 1.3346960544586182,
      "learning_rate": 5.249783109134643e-05,
      "loss": 0.4936,
      "step": 766350
    },
    {
      "epoch": 8.113454830325903,
      "grad_norm": 1.3541114330291748,
      "learning_rate": 5.246951417394069e-05,
      "loss": 0.4876,
      "step": 766400
    },
    {
      "epoch": 8.113984152105907,
      "grad_norm": 1.3577606678009033,
      "learning_rate": 5.244120400015334e-05,
      "loss": 0.4993,
      "step": 766450
    },
    {
      "epoch": 8.11451347388591,
      "grad_norm": 1.3854809999465942,
      "learning_rate": 5.241290057095077e-05,
      "loss": 0.4938,
      "step": 766500
    },
    {
      "epoch": 8.11451347388591,
      "eval_loss": 0.30547890067100525,
      "eval_runtime": 46.8249,
      "eval_samples_per_second": 3586.338,
      "eval_steps_per_second": 448.308,
      "step": 766500
    },
    {
      "epoch": 8.115042795665913,
      "grad_norm": 1.1806391477584839,
      "learning_rate": 5.2384603887299404e-05,
      "loss": 0.4884,
      "step": 766550
    },
    {
      "epoch": 8.115572117445916,
      "grad_norm": 1.3202283382415771,
      "learning_rate": 5.2356313950165105e-05,
      "loss": 0.4972,
      "step": 766600
    },
    {
      "epoch": 8.11610143922592,
      "grad_norm": 1.434877872467041,
      "learning_rate": 5.232803076051382e-05,
      "loss": 0.4987,
      "step": 766650
    },
    {
      "epoch": 8.116630761005924,
      "grad_norm": 1.2863740921020508,
      "learning_rate": 5.2299754319311e-05,
      "loss": 0.4937,
      "step": 766700
    },
    {
      "epoch": 8.117160082785926,
      "grad_norm": 1.3664782047271729,
      "learning_rate": 5.2271484627522155e-05,
      "loss": 0.4848,
      "step": 766750
    },
    {
      "epoch": 8.11768940456593,
      "grad_norm": 1.3876831531524658,
      "learning_rate": 5.2243221686112204e-05,
      "loss": 0.492,
      "step": 766800
    },
    {
      "epoch": 8.118218726345933,
      "grad_norm": 1.2345058917999268,
      "learning_rate": 5.2214965496046236e-05,
      "loss": 0.4978,
      "step": 766850
    },
    {
      "epoch": 8.118748048125937,
      "grad_norm": 1.332370638847351,
      "learning_rate": 5.218671605828876e-05,
      "loss": 0.4883,
      "step": 766900
    },
    {
      "epoch": 8.119277369905939,
      "grad_norm": 1.313099980354309,
      "learning_rate": 5.215847337380428e-05,
      "loss": 0.4907,
      "step": 766950
    },
    {
      "epoch": 8.119806691685943,
      "grad_norm": 1.4153938293457031,
      "learning_rate": 5.213023744355691e-05,
      "loss": 0.4891,
      "step": 767000
    },
    {
      "epoch": 8.119806691685943,
      "eval_loss": 0.3055177330970764,
      "eval_runtime": 46.8477,
      "eval_samples_per_second": 3584.596,
      "eval_steps_per_second": 448.091,
      "step": 767000
    },
    {
      "epoch": 8.120336013465947,
      "grad_norm": 1.3334026336669922,
      "learning_rate": 5.210200826851075e-05,
      "loss": 0.4904,
      "step": 767050
    },
    {
      "epoch": 8.120865335245949,
      "grad_norm": 1.3085514307022095,
      "learning_rate": 5.207378584962935e-05,
      "loss": 0.4979,
      "step": 767100
    },
    {
      "epoch": 8.121394657025952,
      "grad_norm": 1.493503212928772,
      "learning_rate": 5.204557018787642e-05,
      "loss": 0.4936,
      "step": 767150
    },
    {
      "epoch": 8.121923978805956,
      "grad_norm": 1.3426799774169922,
      "learning_rate": 5.201736128421503e-05,
      "loss": 0.4905,
      "step": 767200
    },
    {
      "epoch": 8.12245330058596,
      "grad_norm": 1.3193657398223877,
      "learning_rate": 5.1989159139608385e-05,
      "loss": 0.4882,
      "step": 767250
    },
    {
      "epoch": 8.122982622365962,
      "grad_norm": 1.4881160259246826,
      "learning_rate": 5.196096375501919e-05,
      "loss": 0.502,
      "step": 767300
    },
    {
      "epoch": 8.123511944145966,
      "grad_norm": 1.431955337524414,
      "learning_rate": 5.193277513141012e-05,
      "loss": 0.4929,
      "step": 767350
    },
    {
      "epoch": 8.12404126592597,
      "grad_norm": 1.3772621154785156,
      "learning_rate": 5.1904593269743394e-05,
      "loss": 0.502,
      "step": 767400
    },
    {
      "epoch": 8.124570587705973,
      "grad_norm": 1.2973034381866455,
      "learning_rate": 5.187641817098118e-05,
      "loss": 0.4935,
      "step": 767450
    },
    {
      "epoch": 8.125099909485975,
      "grad_norm": 1.490319848060608,
      "learning_rate": 5.184824983608549e-05,
      "loss": 0.5047,
      "step": 767500
    },
    {
      "epoch": 8.125099909485975,
      "eval_loss": 0.3055950105190277,
      "eval_runtime": 46.7733,
      "eval_samples_per_second": 3590.294,
      "eval_steps_per_second": 448.803,
      "step": 767500
    },
    {
      "epoch": 8.125629231265979,
      "grad_norm": 1.426537275314331,
      "learning_rate": 5.182008826601781e-05,
      "loss": 0.4979,
      "step": 767550
    },
    {
      "epoch": 8.126158553045983,
      "grad_norm": 1.3611935377120972,
      "learning_rate": 5.179193346173969e-05,
      "loss": 0.5021,
      "step": 767600
    },
    {
      "epoch": 8.126687874825986,
      "grad_norm": 1.2858933210372925,
      "learning_rate": 5.1763785424212226e-05,
      "loss": 0.4983,
      "step": 767650
    },
    {
      "epoch": 8.127217196605988,
      "grad_norm": 1.2544714212417603,
      "learning_rate": 5.1735644154396414e-05,
      "loss": 0.498,
      "step": 767700
    },
    {
      "epoch": 8.127746518385992,
      "grad_norm": 1.1553666591644287,
      "learning_rate": 5.170750965325305e-05,
      "loss": 0.4954,
      "step": 767750
    },
    {
      "epoch": 8.128275840165996,
      "grad_norm": 1.4192970991134644,
      "learning_rate": 5.167938192174254e-05,
      "loss": 0.4966,
      "step": 767800
    },
    {
      "epoch": 8.128805161945998,
      "grad_norm": 1.1830099821090698,
      "learning_rate": 5.165126096082526e-05,
      "loss": 0.4957,
      "step": 767850
    },
    {
      "epoch": 8.129334483726002,
      "grad_norm": 1.3031493425369263,
      "learning_rate": 5.16231467714611e-05,
      "loss": 0.4912,
      "step": 767900
    },
    {
      "epoch": 8.129863805506005,
      "grad_norm": 1.4614369869232178,
      "learning_rate": 5.159503935461005e-05,
      "loss": 0.4959,
      "step": 767950
    },
    {
      "epoch": 8.130393127286009,
      "grad_norm": 1.295333743095398,
      "learning_rate": 5.156693871123152e-05,
      "loss": 0.4902,
      "step": 768000
    },
    {
      "epoch": 8.130393127286009,
      "eval_loss": 0.3047529458999634,
      "eval_runtime": 46.9309,
      "eval_samples_per_second": 3578.238,
      "eval_steps_per_second": 447.296,
      "step": 768000
    },
    {
      "epoch": 8.130922449066011,
      "grad_norm": 1.4700945615768433,
      "learning_rate": 5.153884484228499e-05,
      "loss": 0.4947,
      "step": 768050
    },
    {
      "epoch": 8.131451770846015,
      "grad_norm": 1.2369552850723267,
      "learning_rate": 5.151075774872946e-05,
      "loss": 0.4994,
      "step": 768100
    },
    {
      "epoch": 8.131981092626019,
      "grad_norm": 1.3219183683395386,
      "learning_rate": 5.1482677431523935e-05,
      "loss": 0.492,
      "step": 768150
    },
    {
      "epoch": 8.132510414406022,
      "grad_norm": 1.3889418840408325,
      "learning_rate": 5.14546038916269e-05,
      "loss": 0.4831,
      "step": 768200
    },
    {
      "epoch": 8.133039736186024,
      "grad_norm": 1.3459033966064453,
      "learning_rate": 5.142653712999698e-05,
      "loss": 0.4946,
      "step": 768250
    },
    {
      "epoch": 8.133569057966028,
      "grad_norm": 1.4644205570220947,
      "learning_rate": 5.139847714759216e-05,
      "loss": 0.4977,
      "step": 768300
    },
    {
      "epoch": 8.134098379746032,
      "grad_norm": 1.228258728981018,
      "learning_rate": 5.1370984942962996e-05,
      "loss": 0.4858,
      "step": 768350
    },
    {
      "epoch": 8.134627701526036,
      "grad_norm": 1.4879719018936157,
      "learning_rate": 5.134293838625006e-05,
      "loss": 0.5038,
      "step": 768400
    },
    {
      "epoch": 8.135157023306038,
      "grad_norm": 1.4007195234298706,
      "learning_rate": 5.131489861161634e-05,
      "loss": 0.4987,
      "step": 768450
    },
    {
      "epoch": 8.135686345086041,
      "grad_norm": 1.3860270977020264,
      "learning_rate": 5.128686562001916e-05,
      "loss": 0.4877,
      "step": 768500
    },
    {
      "epoch": 8.135686345086041,
      "eval_loss": 0.3056116998195648,
      "eval_runtime": 46.9016,
      "eval_samples_per_second": 3580.475,
      "eval_steps_per_second": 447.575,
      "step": 768500
    },
    {
      "epoch": 8.136215666866045,
      "grad_norm": 1.37851083278656,
      "learning_rate": 5.1258839412415434e-05,
      "loss": 0.5064,
      "step": 768550
    },
    {
      "epoch": 8.136744988646047,
      "grad_norm": 1.4430782794952393,
      "learning_rate": 5.1230819989762115e-05,
      "loss": 0.4987,
      "step": 768600
    },
    {
      "epoch": 8.13727431042605,
      "grad_norm": 1.5103223323822021,
      "learning_rate": 5.120280735301566e-05,
      "loss": 0.4941,
      "step": 768650
    },
    {
      "epoch": 8.137803632206055,
      "grad_norm": 1.2683008909225464,
      "learning_rate": 5.11748015031325e-05,
      "loss": 0.4952,
      "step": 768700
    },
    {
      "epoch": 8.138332953986058,
      "grad_norm": 1.296617031097412,
      "learning_rate": 5.1146802441068645e-05,
      "loss": 0.498,
      "step": 768750
    },
    {
      "epoch": 8.13886227576606,
      "grad_norm": 1.4270622730255127,
      "learning_rate": 5.1118810167780086e-05,
      "loss": 0.4962,
      "step": 768800
    },
    {
      "epoch": 8.139391597546064,
      "grad_norm": 1.3408899307250977,
      "learning_rate": 5.1090824684222326e-05,
      "loss": 0.4906,
      "step": 768850
    },
    {
      "epoch": 8.139920919326068,
      "grad_norm": 1.4041712284088135,
      "learning_rate": 5.106284599135097e-05,
      "loss": 0.5027,
      "step": 768900
    },
    {
      "epoch": 8.140450241106072,
      "grad_norm": 1.3980252742767334,
      "learning_rate": 5.1034874090121e-05,
      "loss": 0.4916,
      "step": 768950
    },
    {
      "epoch": 8.140979562886073,
      "grad_norm": 1.3820600509643555,
      "learning_rate": 5.100690898148752e-05,
      "loss": 0.494,
      "step": 769000
    },
    {
      "epoch": 8.140979562886073,
      "eval_loss": 0.30499231815338135,
      "eval_runtime": 46.9617,
      "eval_samples_per_second": 3575.889,
      "eval_steps_per_second": 447.002,
      "step": 769000
    },
    {
      "epoch": 8.141508884666077,
      "grad_norm": 1.3949475288391113,
      "learning_rate": 5.097895066640515e-05,
      "loss": 0.4942,
      "step": 769050
    },
    {
      "epoch": 8.142038206446081,
      "grad_norm": 1.36958909034729,
      "learning_rate": 5.0950999145828456e-05,
      "loss": 0.489,
      "step": 769100
    },
    {
      "epoch": 8.142567528226085,
      "grad_norm": 1.2023228406906128,
      "learning_rate": 5.09230544207116e-05,
      "loss": 0.5039,
      "step": 769150
    },
    {
      "epoch": 8.143096850006087,
      "grad_norm": 1.3470338582992554,
      "learning_rate": 5.0895116492008734e-05,
      "loss": 0.4955,
      "step": 769200
    },
    {
      "epoch": 8.14362617178609,
      "grad_norm": 1.274355411529541,
      "learning_rate": 5.086718536067347e-05,
      "loss": 0.4989,
      "step": 769250
    },
    {
      "epoch": 8.144155493566094,
      "grad_norm": 1.359782099723816,
      "learning_rate": 5.083926102765957e-05,
      "loss": 0.4948,
      "step": 769300
    },
    {
      "epoch": 8.144684815346096,
      "grad_norm": 1.3260282278060913,
      "learning_rate": 5.081134349392016e-05,
      "loss": 0.4881,
      "step": 769350
    },
    {
      "epoch": 8.1452141371261,
      "grad_norm": 1.2568552494049072,
      "learning_rate": 5.0783432760408446e-05,
      "loss": 0.4913,
      "step": 769400
    },
    {
      "epoch": 8.145743458906104,
      "grad_norm": 1.2701032161712646,
      "learning_rate": 5.0755528828077355e-05,
      "loss": 0.487,
      "step": 769450
    },
    {
      "epoch": 8.146272780686107,
      "grad_norm": 1.3695168495178223,
      "learning_rate": 5.072763169787936e-05,
      "loss": 0.5004,
      "step": 769500
    },
    {
      "epoch": 8.146272780686107,
      "eval_loss": 0.30539485812187195,
      "eval_runtime": 46.8701,
      "eval_samples_per_second": 3582.878,
      "eval_steps_per_second": 447.876,
      "step": 769500
    },
    {
      "epoch": 8.14680210246611,
      "grad_norm": 1.3524755239486694,
      "learning_rate": 5.069974137076702e-05,
      "loss": 0.4896,
      "step": 769550
    },
    {
      "epoch": 8.147331424246113,
      "grad_norm": 1.3489691019058228,
      "learning_rate": 5.0671857847692346e-05,
      "loss": 0.493,
      "step": 769600
    },
    {
      "epoch": 8.147860746026117,
      "grad_norm": 1.4210747480392456,
      "learning_rate": 5.064398112960741e-05,
      "loss": 0.4966,
      "step": 769650
    },
    {
      "epoch": 8.14839006780612,
      "grad_norm": 1.382089614868164,
      "learning_rate": 5.0616111217463764e-05,
      "loss": 0.4922,
      "step": 769700
    },
    {
      "epoch": 8.148919389586123,
      "grad_norm": 1.2251735925674438,
      "learning_rate": 5.058824811221296e-05,
      "loss": 0.4981,
      "step": 769750
    },
    {
      "epoch": 8.149448711366126,
      "grad_norm": 1.3795585632324219,
      "learning_rate": 5.056039181480632e-05,
      "loss": 0.4888,
      "step": 769800
    },
    {
      "epoch": 8.14997803314613,
      "grad_norm": 1.249756932258606,
      "learning_rate": 5.05325423261947e-05,
      "loss": 0.5047,
      "step": 769850
    },
    {
      "epoch": 8.150507354926134,
      "grad_norm": 1.3493155241012573,
      "learning_rate": 5.05046996473289e-05,
      "loss": 0.4989,
      "step": 769900
    },
    {
      "epoch": 8.151036676706136,
      "grad_norm": 1.4677317142486572,
      "learning_rate": 5.0476863779159584e-05,
      "loss": 0.4895,
      "step": 769950
    },
    {
      "epoch": 8.15156599848614,
      "grad_norm": 1.4298653602600098,
      "learning_rate": 5.044903472263687e-05,
      "loss": 0.4939,
      "step": 770000
    },
    {
      "epoch": 8.15156599848614,
      "eval_loss": 0.3047187924385071,
      "eval_runtime": 46.9431,
      "eval_samples_per_second": 3577.308,
      "eval_steps_per_second": 447.179,
      "step": 770000
    },
    {
      "epoch": 8.152095320266143,
      "grad_norm": 1.4088059663772583,
      "learning_rate": 5.0421212478711035e-05,
      "loss": 0.494,
      "step": 770050
    },
    {
      "epoch": 8.152624642046145,
      "grad_norm": 1.3103094100952148,
      "learning_rate": 5.039339704833171e-05,
      "loss": 0.4871,
      "step": 770100
    },
    {
      "epoch": 8.15315396382615,
      "grad_norm": 1.473427414894104,
      "learning_rate": 5.0365588432448705e-05,
      "loss": 0.497,
      "step": 770150
    },
    {
      "epoch": 8.153683285606153,
      "grad_norm": 1.440993070602417,
      "learning_rate": 5.033778663201119e-05,
      "loss": 0.4936,
      "step": 770200
    },
    {
      "epoch": 8.154212607386157,
      "grad_norm": 1.3756669759750366,
      "learning_rate": 5.030999164796851e-05,
      "loss": 0.4831,
      "step": 770250
    },
    {
      "epoch": 8.154741929166159,
      "grad_norm": 1.3616273403167725,
      "learning_rate": 5.028220348126941e-05,
      "loss": 0.4964,
      "step": 770300
    },
    {
      "epoch": 8.155271250946162,
      "grad_norm": 1.411500096321106,
      "learning_rate": 5.025442213286271e-05,
      "loss": 0.4982,
      "step": 770350
    },
    {
      "epoch": 8.155800572726166,
      "grad_norm": 1.4179946184158325,
      "learning_rate": 5.022664760369672e-05,
      "loss": 0.4956,
      "step": 770400
    },
    {
      "epoch": 8.15632989450617,
      "grad_norm": 1.4252690076828003,
      "learning_rate": 5.019887989471977e-05,
      "loss": 0.4989,
      "step": 770450
    },
    {
      "epoch": 8.156859216286172,
      "grad_norm": 1.4148414134979248,
      "learning_rate": 5.017111900687971e-05,
      "loss": 0.4887,
      "step": 770500
    },
    {
      "epoch": 8.156859216286172,
      "eval_loss": 0.3043072819709778,
      "eval_runtime": 46.8769,
      "eval_samples_per_second": 3582.362,
      "eval_steps_per_second": 447.811,
      "step": 770500
    },
    {
      "epoch": 8.157388538066176,
      "grad_norm": 1.208055853843689,
      "learning_rate": 5.014336494112445e-05,
      "loss": 0.4934,
      "step": 770550
    },
    {
      "epoch": 8.15791785984618,
      "grad_norm": 1.3547141551971436,
      "learning_rate": 5.0115617698401337e-05,
      "loss": 0.4933,
      "step": 770600
    },
    {
      "epoch": 8.158447181626183,
      "grad_norm": 1.2768348455429077,
      "learning_rate": 5.00878772796578e-05,
      "loss": 0.5007,
      "step": 770650
    },
    {
      "epoch": 8.158976503406185,
      "grad_norm": 1.3715375661849976,
      "learning_rate": 5.006014368584075e-05,
      "loss": 0.4893,
      "step": 770700
    },
    {
      "epoch": 8.159505825186189,
      "grad_norm": 1.2125072479248047,
      "learning_rate": 5.003241691789714e-05,
      "loss": 0.4964,
      "step": 770750
    },
    {
      "epoch": 8.160035146966193,
      "grad_norm": 1.4868130683898926,
      "learning_rate": 5.00046969767734e-05,
      "loss": 0.4949,
      "step": 770800
    },
    {
      "epoch": 8.160564468746195,
      "grad_norm": 1.2534000873565674,
      "learning_rate": 4.9976983863416034e-05,
      "loss": 0.4959,
      "step": 770850
    },
    {
      "epoch": 8.161093790526198,
      "grad_norm": 1.383091926574707,
      "learning_rate": 4.9949277578771016e-05,
      "loss": 0.4865,
      "step": 770900
    },
    {
      "epoch": 8.161623112306202,
      "grad_norm": 1.2790318727493286,
      "learning_rate": 4.9921578123784365e-05,
      "loss": 0.4947,
      "step": 770950
    },
    {
      "epoch": 8.162152434086206,
      "grad_norm": 1.3970842361450195,
      "learning_rate": 4.9893885499401606e-05,
      "loss": 0.4938,
      "step": 771000
    },
    {
      "epoch": 8.162152434086206,
      "eval_loss": 0.304722398519516,
      "eval_runtime": 46.8138,
      "eval_samples_per_second": 3587.188,
      "eval_steps_per_second": 448.415,
      "step": 771000
    },
    {
      "epoch": 8.162681755866208,
      "grad_norm": 1.3517537117004395,
      "learning_rate": 4.986619970656825e-05,
      "loss": 0.4981,
      "step": 771050
    },
    {
      "epoch": 8.163211077646212,
      "grad_norm": 1.3464851379394531,
      "learning_rate": 4.983852074622938e-05,
      "loss": 0.4992,
      "step": 771100
    },
    {
      "epoch": 8.163740399426215,
      "grad_norm": 1.2603896856307983,
      "learning_rate": 4.981084861933008e-05,
      "loss": 0.5007,
      "step": 771150
    },
    {
      "epoch": 8.16426972120622,
      "grad_norm": 1.4076030254364014,
      "learning_rate": 4.978318332681492e-05,
      "loss": 0.4868,
      "step": 771200
    },
    {
      "epoch": 8.164799042986221,
      "grad_norm": 1.3441548347473145,
      "learning_rate": 4.975552486962851e-05,
      "loss": 0.4977,
      "step": 771250
    },
    {
      "epoch": 8.165328364766225,
      "grad_norm": 1.4247647523880005,
      "learning_rate": 4.9727873248715e-05,
      "loss": 0.4865,
      "step": 771300
    },
    {
      "epoch": 8.165857686546229,
      "grad_norm": 1.3671469688415527,
      "learning_rate": 4.9700228465018424e-05,
      "loss": 0.5007,
      "step": 771350
    },
    {
      "epoch": 8.166387008326232,
      "grad_norm": 1.245972990989685,
      "learning_rate": 4.9672590519482666e-05,
      "loss": 0.4906,
      "step": 771400
    },
    {
      "epoch": 8.166916330106234,
      "grad_norm": 1.5256527662277222,
      "learning_rate": 4.9644959413051135e-05,
      "loss": 0.495,
      "step": 771450
    },
    {
      "epoch": 8.167445651886238,
      "grad_norm": 1.3058956861495972,
      "learning_rate": 4.961733514666722e-05,
      "loss": 0.4856,
      "step": 771500
    },
    {
      "epoch": 8.167445651886238,
      "eval_loss": 0.3043539822101593,
      "eval_runtime": 46.9059,
      "eval_samples_per_second": 3580.143,
      "eval_steps_per_second": 447.534,
      "step": 771500
    },
    {
      "epoch": 8.167974973666242,
      "grad_norm": 1.5149720907211304,
      "learning_rate": 4.9589717721274044e-05,
      "loss": 0.486,
      "step": 771550
    },
    {
      "epoch": 8.168504295446244,
      "grad_norm": 1.28571617603302,
      "learning_rate": 4.9562107137814365e-05,
      "loss": 0.49,
      "step": 771600
    },
    {
      "epoch": 8.169033617226248,
      "grad_norm": 1.3930580615997314,
      "learning_rate": 4.953450339723089e-05,
      "loss": 0.4938,
      "step": 771650
    },
    {
      "epoch": 8.169562939006251,
      "grad_norm": 1.2907772064208984,
      "learning_rate": 4.950690650046588e-05,
      "loss": 0.4925,
      "step": 771700
    },
    {
      "epoch": 8.170092260786255,
      "grad_norm": 1.2991055250167847,
      "learning_rate": 4.9479316448461624e-05,
      "loss": 0.4942,
      "step": 771750
    },
    {
      "epoch": 8.170621582566257,
      "grad_norm": 1.235574722290039,
      "learning_rate": 4.94517332421599e-05,
      "loss": 0.4982,
      "step": 771800
    },
    {
      "epoch": 8.171150904346261,
      "grad_norm": 1.3685489892959595,
      "learning_rate": 4.942415688250251e-05,
      "loss": 0.4946,
      "step": 771850
    },
    {
      "epoch": 8.171680226126265,
      "grad_norm": 1.3723015785217285,
      "learning_rate": 4.939658737043079e-05,
      "loss": 0.5008,
      "step": 771900
    },
    {
      "epoch": 8.172209547906268,
      "grad_norm": 1.2787836790084839,
      "learning_rate": 4.936902470688609e-05,
      "loss": 0.4929,
      "step": 771950
    },
    {
      "epoch": 8.17273886968627,
      "grad_norm": 1.4035133123397827,
      "learning_rate": 4.934146889280922e-05,
      "loss": 0.4944,
      "step": 772000
    },
    {
      "epoch": 8.17273886968627,
      "eval_loss": 0.30458804965019226,
      "eval_runtime": 46.7917,
      "eval_samples_per_second": 3588.882,
      "eval_steps_per_second": 448.626,
      "step": 772000
    },
    {
      "epoch": 8.173268191466274,
      "grad_norm": 1.4264088869094849,
      "learning_rate": 4.931391992914108e-05,
      "loss": 0.4832,
      "step": 772050
    },
    {
      "epoch": 8.173797513246278,
      "grad_norm": 1.2074778079986572,
      "learning_rate": 4.928637781682205e-05,
      "loss": 0.4887,
      "step": 772100
    },
    {
      "epoch": 8.174326835026282,
      "grad_norm": 1.2847976684570312,
      "learning_rate": 4.925884255679255e-05,
      "loss": 0.4885,
      "step": 772150
    },
    {
      "epoch": 8.174856156806284,
      "grad_norm": 1.4072232246398926,
      "learning_rate": 4.923131414999246e-05,
      "loss": 0.4894,
      "step": 772200
    },
    {
      "epoch": 8.175385478586287,
      "grad_norm": 1.2430732250213623,
      "learning_rate": 4.920379259736174e-05,
      "loss": 0.4885,
      "step": 772250
    },
    {
      "epoch": 8.175914800366291,
      "grad_norm": 1.3664764165878296,
      "learning_rate": 4.9176277899839864e-05,
      "loss": 0.4966,
      "step": 772300
    },
    {
      "epoch": 8.176444122146293,
      "grad_norm": 1.4501674175262451,
      "learning_rate": 4.9149320148000334e-05,
      "loss": 0.4996,
      "step": 772350
    },
    {
      "epoch": 8.176973443926297,
      "grad_norm": 1.1981991529464722,
      "learning_rate": 4.912181902636511e-05,
      "loss": 0.4921,
      "step": 772400
    },
    {
      "epoch": 8.1775027657063,
      "grad_norm": 1.3244071006774902,
      "learning_rate": 4.9094324762637255e-05,
      "loss": 0.4902,
      "step": 772450
    },
    {
      "epoch": 8.178032087486304,
      "grad_norm": 1.3590000867843628,
      "learning_rate": 4.906683735775552e-05,
      "loss": 0.4897,
      "step": 772500
    },
    {
      "epoch": 8.178032087486304,
      "eval_loss": 0.3042795658111572,
      "eval_runtime": 46.9152,
      "eval_samples_per_second": 3579.438,
      "eval_steps_per_second": 447.446,
      "step": 772500
    },
    {
      "epoch": 8.178561409266306,
      "grad_norm": 1.4448648691177368,
      "learning_rate": 4.90393568126582e-05,
      "loss": 0.4955,
      "step": 772550
    },
    {
      "epoch": 8.17909073104631,
      "grad_norm": 1.2436012029647827,
      "learning_rate": 4.901188312828361e-05,
      "loss": 0.4951,
      "step": 772600
    },
    {
      "epoch": 8.179620052826314,
      "grad_norm": 1.3840593099594116,
      "learning_rate": 4.898441630556957e-05,
      "loss": 0.4914,
      "step": 772650
    },
    {
      "epoch": 8.180149374606318,
      "grad_norm": 1.3732235431671143,
      "learning_rate": 4.895695634545391e-05,
      "loss": 0.4924,
      "step": 772700
    },
    {
      "epoch": 8.18067869638632,
      "grad_norm": 1.456112027168274,
      "learning_rate": 4.8929503248873934e-05,
      "loss": 0.493,
      "step": 772750
    },
    {
      "epoch": 8.181208018166323,
      "grad_norm": 1.268835425376892,
      "learning_rate": 4.890205701676706e-05,
      "loss": 0.4908,
      "step": 772800
    },
    {
      "epoch": 8.181737339946327,
      "grad_norm": 1.407463788986206,
      "learning_rate": 4.887461765007015e-05,
      "loss": 0.4922,
      "step": 772850
    },
    {
      "epoch": 8.18226666172633,
      "grad_norm": 1.358564019203186,
      "learning_rate": 4.884718514972006e-05,
      "loss": 0.4847,
      "step": 772900
    },
    {
      "epoch": 8.182795983506333,
      "grad_norm": 1.4236704111099243,
      "learning_rate": 4.8819759516653266e-05,
      "loss": 0.4868,
      "step": 772950
    },
    {
      "epoch": 8.183325305286337,
      "grad_norm": 1.4555243253707886,
      "learning_rate": 4.879234075180616e-05,
      "loss": 0.495,
      "step": 773000
    },
    {
      "epoch": 8.183325305286337,
      "eval_loss": 0.3037222623825073,
      "eval_runtime": 46.7906,
      "eval_samples_per_second": 3588.967,
      "eval_steps_per_second": 448.637,
      "step": 773000
    },
    {
      "epoch": 8.18385462706634,
      "grad_norm": 1.25836980342865,
      "learning_rate": 4.8764928856114693e-05,
      "loss": 0.4977,
      "step": 773050
    },
    {
      "epoch": 8.184383948846342,
      "grad_norm": 1.3393415212631226,
      "learning_rate": 4.8737523830514804e-05,
      "loss": 0.49,
      "step": 773100
    },
    {
      "epoch": 8.184913270626346,
      "grad_norm": 1.2925723791122437,
      "learning_rate": 4.871012567594199e-05,
      "loss": 0.4888,
      "step": 773150
    },
    {
      "epoch": 8.18544259240635,
      "grad_norm": 1.4122915267944336,
      "learning_rate": 4.868273439333171e-05,
      "loss": 0.4908,
      "step": 773200
    },
    {
      "epoch": 8.185971914186354,
      "grad_norm": 1.3637689352035522,
      "learning_rate": 4.8655349983619004e-05,
      "loss": 0.4912,
      "step": 773250
    },
    {
      "epoch": 8.186501235966356,
      "grad_norm": 1.2934556007385254,
      "learning_rate": 4.8627972447738864e-05,
      "loss": 0.5036,
      "step": 773300
    },
    {
      "epoch": 8.18703055774636,
      "grad_norm": 1.2687727212905884,
      "learning_rate": 4.8600601786625816e-05,
      "loss": 0.4831,
      "step": 773350
    },
    {
      "epoch": 8.187559879526363,
      "grad_norm": 1.383531093597412,
      "learning_rate": 4.857323800121438e-05,
      "loss": 0.491,
      "step": 773400
    },
    {
      "epoch": 8.188089201306367,
      "grad_norm": 1.2770824432373047,
      "learning_rate": 4.854642816321725e-05,
      "loss": 0.4955,
      "step": 773450
    },
    {
      "epoch": 8.188618523086369,
      "grad_norm": 1.4228706359863281,
      "learning_rate": 4.85190779944508e-05,
      "loss": 0.4963,
      "step": 773500
    },
    {
      "epoch": 8.188618523086369,
      "eval_loss": 0.30407801270484924,
      "eval_runtime": 46.7457,
      "eval_samples_per_second": 3592.414,
      "eval_steps_per_second": 449.068,
      "step": 773500
    },
    {
      "epoch": 8.189147844866373,
      "grad_norm": 1.2966580390930176,
      "learning_rate": 4.849173470416918e-05,
      "loss": 0.4884,
      "step": 773550
    },
    {
      "epoch": 8.189677166646376,
      "grad_norm": 1.4147441387176514,
      "learning_rate": 4.846439829330576e-05,
      "loss": 0.4846,
      "step": 773600
    },
    {
      "epoch": 8.19020648842638,
      "grad_norm": 1.2338151931762695,
      "learning_rate": 4.8437068762793965e-05,
      "loss": 0.4969,
      "step": 773650
    },
    {
      "epoch": 8.190735810206382,
      "grad_norm": 1.4103827476501465,
      "learning_rate": 4.840974611356663e-05,
      "loss": 0.4893,
      "step": 773700
    },
    {
      "epoch": 8.191265131986386,
      "grad_norm": 1.4222807884216309,
      "learning_rate": 4.838243034655671e-05,
      "loss": 0.4904,
      "step": 773750
    },
    {
      "epoch": 8.19179445376639,
      "grad_norm": 1.3628745079040527,
      "learning_rate": 4.835512146269663e-05,
      "loss": 0.4916,
      "step": 773800
    },
    {
      "epoch": 8.192323775546392,
      "grad_norm": 1.288972020149231,
      "learning_rate": 4.8327819462918725e-05,
      "loss": 0.495,
      "step": 773850
    },
    {
      "epoch": 8.192853097326395,
      "grad_norm": 1.1855063438415527,
      "learning_rate": 4.830052434815518e-05,
      "loss": 0.493,
      "step": 773900
    },
    {
      "epoch": 8.193382419106399,
      "grad_norm": 1.25564706325531,
      "learning_rate": 4.8273236119337675e-05,
      "loss": 0.4944,
      "step": 773950
    },
    {
      "epoch": 8.193911740886403,
      "grad_norm": 1.2979083061218262,
      "learning_rate": 4.8245954777397934e-05,
      "loss": 0.4889,
      "step": 774000
    },
    {
      "epoch": 8.193911740886403,
      "eval_loss": 0.3040260076522827,
      "eval_runtime": 46.8295,
      "eval_samples_per_second": 3585.984,
      "eval_steps_per_second": 448.264,
      "step": 774000
    },
    {
      "epoch": 8.194441062666405,
      "grad_norm": 1.4523046016693115,
      "learning_rate": 4.821868032326737e-05,
      "loss": 0.4943,
      "step": 774050
    },
    {
      "epoch": 8.194970384446409,
      "grad_norm": 1.1699819564819336,
      "learning_rate": 4.819141275787698e-05,
      "loss": 0.4852,
      "step": 774100
    },
    {
      "epoch": 8.195499706226412,
      "grad_norm": 1.4248706102371216,
      "learning_rate": 4.816415208215782e-05,
      "loss": 0.49,
      "step": 774150
    },
    {
      "epoch": 8.196029028006416,
      "grad_norm": 1.4041028022766113,
      "learning_rate": 4.813689829704043e-05,
      "loss": 0.4914,
      "step": 774200
    },
    {
      "epoch": 8.196558349786418,
      "grad_norm": 1.3037673234939575,
      "learning_rate": 4.8109651403455356e-05,
      "loss": 0.4918,
      "step": 774250
    },
    {
      "epoch": 8.197087671566422,
      "grad_norm": 1.493901252746582,
      "learning_rate": 4.808241140233269e-05,
      "loss": 0.4859,
      "step": 774300
    },
    {
      "epoch": 8.197616993346426,
      "grad_norm": 1.2779849767684937,
      "learning_rate": 4.8055178294602484e-05,
      "loss": 0.5056,
      "step": 774350
    },
    {
      "epoch": 8.19814631512643,
      "grad_norm": 1.5002021789550781,
      "learning_rate": 4.802795208119437e-05,
      "loss": 0.487,
      "step": 774400
    },
    {
      "epoch": 8.198675636906431,
      "grad_norm": 1.3410011529922485,
      "learning_rate": 4.8000732763037986e-05,
      "loss": 0.4978,
      "step": 774450
    },
    {
      "epoch": 8.199204958686435,
      "grad_norm": 1.3556270599365234,
      "learning_rate": 4.797352034106242e-05,
      "loss": 0.4976,
      "step": 774500
    },
    {
      "epoch": 8.199204958686435,
      "eval_loss": 0.30349957942962646,
      "eval_runtime": 46.7775,
      "eval_samples_per_second": 3589.977,
      "eval_steps_per_second": 448.763,
      "step": 774500
    },
    {
      "epoch": 8.199734280466439,
      "grad_norm": 1.4647681713104248,
      "learning_rate": 4.794631481619688e-05,
      "loss": 0.4938,
      "step": 774550
    },
    {
      "epoch": 8.20026360224644,
      "grad_norm": 1.4701191186904907,
      "learning_rate": 4.791911618936995e-05,
      "loss": 0.4934,
      "step": 774600
    },
    {
      "epoch": 8.200792924026445,
      "grad_norm": 1.2515490055084229,
      "learning_rate": 4.789192446151036e-05,
      "loss": 0.4927,
      "step": 774650
    },
    {
      "epoch": 8.201322245806448,
      "grad_norm": 1.4394757747650146,
      "learning_rate": 4.7864739633546265e-05,
      "loss": 0.4977,
      "step": 774700
    },
    {
      "epoch": 8.201851567586452,
      "grad_norm": 1.4104433059692383,
      "learning_rate": 4.7837561706405906e-05,
      "loss": 0.4823,
      "step": 774750
    },
    {
      "epoch": 8.202380889366454,
      "grad_norm": 1.4089243412017822,
      "learning_rate": 4.7810390681017e-05,
      "loss": 0.4903,
      "step": 774800
    },
    {
      "epoch": 8.202910211146458,
      "grad_norm": 1.3939214944839478,
      "learning_rate": 4.7783226558307244e-05,
      "loss": 0.4975,
      "step": 774850
    },
    {
      "epoch": 8.203439532926462,
      "grad_norm": 1.3803083896636963,
      "learning_rate": 4.775606933920393e-05,
      "loss": 0.4902,
      "step": 774900
    },
    {
      "epoch": 8.203968854706465,
      "grad_norm": 1.2349601984024048,
      "learning_rate": 4.77289190246343e-05,
      "loss": 0.4952,
      "step": 774950
    },
    {
      "epoch": 8.204498176486467,
      "grad_norm": 1.3245790004730225,
      "learning_rate": 4.7701775615525103e-05,
      "loss": 0.4916,
      "step": 775000
    },
    {
      "epoch": 8.204498176486467,
      "eval_loss": 0.3037920594215393,
      "eval_runtime": 46.8765,
      "eval_samples_per_second": 3582.39,
      "eval_steps_per_second": 447.815,
      "step": 775000
    },
    {
      "epoch": 8.205027498266471,
      "grad_norm": 1.463255524635315,
      "learning_rate": 4.767463911280318e-05,
      "loss": 0.4974,
      "step": 775050
    },
    {
      "epoch": 8.205556820046475,
      "grad_norm": 1.2559453248977661,
      "learning_rate": 4.764750951739483e-05,
      "loss": 0.4902,
      "step": 775100
    },
    {
      "epoch": 8.206086141826479,
      "grad_norm": 1.314250111579895,
      "learning_rate": 4.762038683022632e-05,
      "loss": 0.4914,
      "step": 775150
    },
    {
      "epoch": 8.20661546360648,
      "grad_norm": 1.306674599647522,
      "learning_rate": 4.759327105222355e-05,
      "loss": 0.4938,
      "step": 775200
    },
    {
      "epoch": 8.207144785386484,
      "grad_norm": 1.3956942558288574,
      "learning_rate": 4.756616218431234e-05,
      "loss": 0.4883,
      "step": 775250
    },
    {
      "epoch": 8.207674107166488,
      "grad_norm": 1.2199652194976807,
      "learning_rate": 4.7539060227418024e-05,
      "loss": 0.4891,
      "step": 775300
    },
    {
      "epoch": 8.20820342894649,
      "grad_norm": 1.3037240505218506,
      "learning_rate": 4.7511965182466034e-05,
      "loss": 0.4932,
      "step": 775350
    },
    {
      "epoch": 8.208732750726494,
      "grad_norm": 1.3693954944610596,
      "learning_rate": 4.748487705038121e-05,
      "loss": 0.4851,
      "step": 775400
    },
    {
      "epoch": 8.209262072506498,
      "grad_norm": 1.4832170009613037,
      "learning_rate": 4.745779583208848e-05,
      "loss": 0.4912,
      "step": 775450
    },
    {
      "epoch": 8.209791394286501,
      "grad_norm": 1.3981504440307617,
      "learning_rate": 4.743072152851224e-05,
      "loss": 0.4891,
      "step": 775500
    },
    {
      "epoch": 8.209791394286501,
      "eval_loss": 0.3034341037273407,
      "eval_runtime": 46.7602,
      "eval_samples_per_second": 3591.305,
      "eval_steps_per_second": 448.929,
      "step": 775500
    },
    {
      "epoch": 8.210320716066503,
      "grad_norm": 1.3388174772262573,
      "learning_rate": 4.7403654140576904e-05,
      "loss": 0.4822,
      "step": 775550
    },
    {
      "epoch": 8.210850037846507,
      "grad_norm": 1.4381000995635986,
      "learning_rate": 4.7376593669206576e-05,
      "loss": 0.4874,
      "step": 775600
    },
    {
      "epoch": 8.21137935962651,
      "grad_norm": 1.6266227960586548,
      "learning_rate": 4.734954011532494e-05,
      "loss": 0.4947,
      "step": 775650
    },
    {
      "epoch": 8.211908681406515,
      "grad_norm": 1.3792611360549927,
      "learning_rate": 4.7322493479855705e-05,
      "loss": 0.4957,
      "step": 775700
    },
    {
      "epoch": 8.212438003186517,
      "grad_norm": 1.3856817483901978,
      "learning_rate": 4.729545376372227e-05,
      "loss": 0.4934,
      "step": 775750
    },
    {
      "epoch": 8.21296732496652,
      "grad_norm": 1.5479366779327393,
      "learning_rate": 4.726842096784764e-05,
      "loss": 0.4901,
      "step": 775800
    },
    {
      "epoch": 8.213496646746524,
      "grad_norm": 1.479300856590271,
      "learning_rate": 4.724139509315484e-05,
      "loss": 0.4962,
      "step": 775850
    },
    {
      "epoch": 8.214025968526528,
      "grad_norm": 1.3169487714767456,
      "learning_rate": 4.721437614056639e-05,
      "loss": 0.4954,
      "step": 775900
    },
    {
      "epoch": 8.21455529030653,
      "grad_norm": 1.2276986837387085,
      "learning_rate": 4.718736411100483e-05,
      "loss": 0.4915,
      "step": 775950
    },
    {
      "epoch": 8.215084612086534,
      "grad_norm": 1.2360589504241943,
      "learning_rate": 4.716035900539223e-05,
      "loss": 0.4965,
      "step": 776000
    },
    {
      "epoch": 8.215084612086534,
      "eval_loss": 0.3036148250102997,
      "eval_runtime": 46.8559,
      "eval_samples_per_second": 3583.967,
      "eval_steps_per_second": 448.012,
      "step": 776000
    },
    {
      "epoch": 8.215613933866537,
      "grad_norm": 1.3515238761901855,
      "learning_rate": 4.713336082465061e-05,
      "loss": 0.4905,
      "step": 776050
    },
    {
      "epoch": 8.21614325564654,
      "grad_norm": 1.4812878370285034,
      "learning_rate": 4.710636956970163e-05,
      "loss": 0.486,
      "step": 776100
    },
    {
      "epoch": 8.216672577426543,
      "grad_norm": 1.2491679191589355,
      "learning_rate": 4.707938524146682e-05,
      "loss": 0.4909,
      "step": 776150
    },
    {
      "epoch": 8.217201899206547,
      "grad_norm": 1.238087773323059,
      "learning_rate": 4.705240784086731e-05,
      "loss": 0.4964,
      "step": 776200
    },
    {
      "epoch": 8.21773122098655,
      "grad_norm": 1.5047919750213623,
      "learning_rate": 4.7025437368824254e-05,
      "loss": 0.4886,
      "step": 776250
    },
    {
      "epoch": 8.218260542766552,
      "grad_norm": 1.440011978149414,
      "learning_rate": 4.699847382625827e-05,
      "loss": 0.4817,
      "step": 776300
    },
    {
      "epoch": 8.218789864546556,
      "grad_norm": 1.294143557548523,
      "learning_rate": 4.6971517214089985e-05,
      "loss": 0.492,
      "step": 776350
    },
    {
      "epoch": 8.21931918632656,
      "grad_norm": 1.3871707916259766,
      "learning_rate": 4.6944567533239584e-05,
      "loss": 0.4868,
      "step": 776400
    },
    {
      "epoch": 8.219848508106564,
      "grad_norm": 1.4238182306289673,
      "learning_rate": 4.6917624784627244e-05,
      "loss": 0.4928,
      "step": 776450
    },
    {
      "epoch": 8.220377829886566,
      "grad_norm": 1.4191335439682007,
      "learning_rate": 4.689068896917265e-05,
      "loss": 0.4948,
      "step": 776500
    },
    {
      "epoch": 8.220377829886566,
      "eval_loss": 0.30330324172973633,
      "eval_runtime": 46.7542,
      "eval_samples_per_second": 3591.759,
      "eval_steps_per_second": 448.986,
      "step": 776500
    },
    {
      "epoch": 8.22090715166657,
      "grad_norm": 1.440352201461792,
      "learning_rate": 4.68637600877955e-05,
      "loss": 0.4996,
      "step": 776550
    },
    {
      "epoch": 8.221436473446573,
      "grad_norm": 1.4258590936660767,
      "learning_rate": 4.683683814141504e-05,
      "loss": 0.4902,
      "step": 776600
    },
    {
      "epoch": 8.221965795226577,
      "grad_norm": 1.3819843530654907,
      "learning_rate": 4.680992313095045e-05,
      "loss": 0.4912,
      "step": 776650
    },
    {
      "epoch": 8.222495117006579,
      "grad_norm": 1.3199812173843384,
      "learning_rate": 4.678301505732052e-05,
      "loss": 0.4912,
      "step": 776700
    },
    {
      "epoch": 8.223024438786583,
      "grad_norm": 1.3925058841705322,
      "learning_rate": 4.675611392144402e-05,
      "loss": 0.4945,
      "step": 776750
    },
    {
      "epoch": 8.223553760566586,
      "grad_norm": 1.2520737648010254,
      "learning_rate": 4.6729219724239155e-05,
      "loss": 0.4975,
      "step": 776800
    },
    {
      "epoch": 8.224083082346588,
      "grad_norm": 1.2450984716415405,
      "learning_rate": 4.67023324666242e-05,
      "loss": 0.4845,
      "step": 776850
    },
    {
      "epoch": 8.224612404126592,
      "grad_norm": 1.370495319366455,
      "learning_rate": 4.66754521495171e-05,
      "loss": 0.4887,
      "step": 776900
    },
    {
      "epoch": 8.225141725906596,
      "grad_norm": 1.2243260145187378,
      "learning_rate": 4.6648578773835435e-05,
      "loss": 0.487,
      "step": 776950
    },
    {
      "epoch": 8.2256710476866,
      "grad_norm": 1.2499603033065796,
      "learning_rate": 4.662171234049681e-05,
      "loss": 0.4922,
      "step": 777000
    },
    {
      "epoch": 8.2256710476866,
      "eval_loss": 0.30351462960243225,
      "eval_runtime": 46.9293,
      "eval_samples_per_second": 3578.362,
      "eval_steps_per_second": 447.311,
      "step": 777000
    },
    {
      "epoch": 8.226200369466602,
      "grad_norm": 1.3349589109420776,
      "learning_rate": 4.659485285041823e-05,
      "loss": 0.4868,
      "step": 777050
    },
    {
      "epoch": 8.226729691246605,
      "grad_norm": 1.4221446514129639,
      "learning_rate": 4.656800030451688e-05,
      "loss": 0.4846,
      "step": 777100
    },
    {
      "epoch": 8.22725901302661,
      "grad_norm": 1.2354695796966553,
      "learning_rate": 4.6541154703709316e-05,
      "loss": 0.4925,
      "step": 777150
    },
    {
      "epoch": 8.227788334806613,
      "grad_norm": 1.4259320497512817,
      "learning_rate": 4.6514316048912155e-05,
      "loss": 0.4827,
      "step": 777200
    },
    {
      "epoch": 8.228317656586615,
      "grad_norm": 1.2347238063812256,
      "learning_rate": 4.648748434104158e-05,
      "loss": 0.4954,
      "step": 777250
    },
    {
      "epoch": 8.228846978366619,
      "grad_norm": 1.3206851482391357,
      "learning_rate": 4.646065958101364e-05,
      "loss": 0.488,
      "step": 777300
    },
    {
      "epoch": 8.229376300146622,
      "grad_norm": 1.3670694828033447,
      "learning_rate": 4.6433841769744214e-05,
      "loss": 0.4906,
      "step": 777350
    },
    {
      "epoch": 8.229905621926626,
      "grad_norm": 1.41746187210083,
      "learning_rate": 4.640703090814871e-05,
      "loss": 0.489,
      "step": 777400
    },
    {
      "epoch": 8.230434943706628,
      "grad_norm": 1.273514747619629,
      "learning_rate": 4.638076300724101e-05,
      "loss": 0.4922,
      "step": 777450
    },
    {
      "epoch": 8.230964265486632,
      "grad_norm": 1.287912130355835,
      "learning_rate": 4.635396590870011e-05,
      "loss": 0.4918,
      "step": 777500
    },
    {
      "epoch": 8.230964265486632,
      "eval_loss": 0.303052693605423,
      "eval_runtime": 46.789,
      "eval_samples_per_second": 3589.09,
      "eval_steps_per_second": 448.652,
      "step": 777500
    },
    {
      "epoch": 8.231493587266636,
      "grad_norm": 1.441171407699585,
      "learning_rate": 4.6327175762560206e-05,
      "loss": 0.4951,
      "step": 777550
    },
    {
      "epoch": 8.232022909046638,
      "grad_norm": 1.392200231552124,
      "learning_rate": 4.630039256973575e-05,
      "loss": 0.4889,
      "step": 777600
    },
    {
      "epoch": 8.232552230826641,
      "grad_norm": 1.3169405460357666,
      "learning_rate": 4.627361633114127e-05,
      "loss": 0.4935,
      "step": 777650
    },
    {
      "epoch": 8.233081552606645,
      "grad_norm": 1.520745038986206,
      "learning_rate": 4.624684704769075e-05,
      "loss": 0.5025,
      "step": 777700
    },
    {
      "epoch": 8.233610874386649,
      "grad_norm": 1.358669638633728,
      "learning_rate": 4.622008472029812e-05,
      "loss": 0.4844,
      "step": 777750
    },
    {
      "epoch": 8.234140196166651,
      "grad_norm": 1.3962913751602173,
      "learning_rate": 4.619332934987716e-05,
      "loss": 0.5006,
      "step": 777800
    },
    {
      "epoch": 8.234669517946655,
      "grad_norm": 1.39322829246521,
      "learning_rate": 4.6166580937341104e-05,
      "loss": 0.4992,
      "step": 777850
    },
    {
      "epoch": 8.235198839726658,
      "grad_norm": 1.36448073387146,
      "learning_rate": 4.613983948360323e-05,
      "loss": 0.4887,
      "step": 777900
    },
    {
      "epoch": 8.235728161506662,
      "grad_norm": 1.3320331573486328,
      "learning_rate": 4.611310498957652e-05,
      "loss": 0.4852,
      "step": 777950
    },
    {
      "epoch": 8.236257483286664,
      "grad_norm": 1.3273286819458008,
      "learning_rate": 4.608637745617358e-05,
      "loss": 0.4888,
      "step": 778000
    },
    {
      "epoch": 8.236257483286664,
      "eval_loss": 0.3031122386455536,
      "eval_runtime": 46.7938,
      "eval_samples_per_second": 3588.721,
      "eval_steps_per_second": 448.606,
      "step": 778000
    },
    {
      "epoch": 8.236786805066668,
      "grad_norm": 1.4365589618682861,
      "learning_rate": 4.605965688430702e-05,
      "loss": 0.5008,
      "step": 778050
    },
    {
      "epoch": 8.237316126846672,
      "grad_norm": 1.5042612552642822,
      "learning_rate": 4.6032943274888885e-05,
      "loss": 0.4899,
      "step": 778100
    },
    {
      "epoch": 8.237845448626675,
      "grad_norm": 1.4592163562774658,
      "learning_rate": 4.6006236628831356e-05,
      "loss": 0.4957,
      "step": 778150
    },
    {
      "epoch": 8.238374770406677,
      "grad_norm": 1.3010690212249756,
      "learning_rate": 4.597953694704601e-05,
      "loss": 0.4887,
      "step": 778200
    },
    {
      "epoch": 8.238904092186681,
      "grad_norm": 1.3008240461349487,
      "learning_rate": 4.595284423044452e-05,
      "loss": 0.4931,
      "step": 778250
    },
    {
      "epoch": 8.239433413966685,
      "grad_norm": 1.225853681564331,
      "learning_rate": 4.592615847993803e-05,
      "loss": 0.4942,
      "step": 778300
    },
    {
      "epoch": 8.239962735746687,
      "grad_norm": 1.4196629524230957,
      "learning_rate": 4.5899479696437705e-05,
      "loss": 0.4954,
      "step": 778350
    },
    {
      "epoch": 8.24049205752669,
      "grad_norm": 1.4109561443328857,
      "learning_rate": 4.587280788085424e-05,
      "loss": 0.4872,
      "step": 778400
    },
    {
      "epoch": 8.241021379306694,
      "grad_norm": 1.4863295555114746,
      "learning_rate": 4.584614303409831e-05,
      "loss": 0.4857,
      "step": 778450
    },
    {
      "epoch": 8.241550701086698,
      "grad_norm": 1.3393300771713257,
      "learning_rate": 4.581948515708012e-05,
      "loss": 0.4924,
      "step": 778500
    },
    {
      "epoch": 8.241550701086698,
      "eval_loss": 0.30305489897727966,
      "eval_runtime": 46.8218,
      "eval_samples_per_second": 3586.58,
      "eval_steps_per_second": 448.339,
      "step": 778500
    },
    {
      "epoch": 8.2420800228667,
      "grad_norm": 1.520122766494751,
      "learning_rate": 4.579283425070987e-05,
      "loss": 0.4864,
      "step": 778550
    },
    {
      "epoch": 8.242609344646704,
      "grad_norm": 1.3410356044769287,
      "learning_rate": 4.576619031589735e-05,
      "loss": 0.4854,
      "step": 778600
    },
    {
      "epoch": 8.243138666426708,
      "grad_norm": 1.3587925434112549,
      "learning_rate": 4.574008602446303e-05,
      "loss": 0.4783,
      "step": 778650
    },
    {
      "epoch": 8.243667988206711,
      "grad_norm": 1.3276463747024536,
      "learning_rate": 4.571345589601819e-05,
      "loss": 0.4973,
      "step": 778700
    },
    {
      "epoch": 8.244197309986713,
      "grad_norm": 1.4744455814361572,
      "learning_rate": 4.5686832741841015e-05,
      "loss": 0.4905,
      "step": 778750
    },
    {
      "epoch": 8.244726631766717,
      "grad_norm": 1.3896538019180298,
      "learning_rate": 4.5660216562840475e-05,
      "loss": 0.4864,
      "step": 778800
    },
    {
      "epoch": 8.245255953546721,
      "grad_norm": 1.3914813995361328,
      "learning_rate": 4.563360735992514e-05,
      "loss": 0.4845,
      "step": 778850
    },
    {
      "epoch": 8.245785275326725,
      "grad_norm": 1.3564074039459229,
      "learning_rate": 4.560700513400359e-05,
      "loss": 0.4848,
      "step": 778900
    },
    {
      "epoch": 8.246314597106727,
      "grad_norm": 1.5264934301376343,
      "learning_rate": 4.558040988598383e-05,
      "loss": 0.4883,
      "step": 778950
    },
    {
      "epoch": 8.24684391888673,
      "grad_norm": 1.4439479112625122,
      "learning_rate": 4.555382161677399e-05,
      "loss": 0.4977,
      "step": 779000
    },
    {
      "epoch": 8.24684391888673,
      "eval_loss": 0.30278280377388,
      "eval_runtime": 46.7841,
      "eval_samples_per_second": 3589.469,
      "eval_steps_per_second": 448.7,
      "step": 779000
    },
    {
      "epoch": 8.247373240666734,
      "grad_norm": 1.4603149890899658,
      "learning_rate": 4.552724032728164e-05,
      "loss": 0.489,
      "step": 779050
    },
    {
      "epoch": 8.247902562446736,
      "grad_norm": 1.3407139778137207,
      "learning_rate": 4.550066601841438e-05,
      "loss": 0.4849,
      "step": 779100
    },
    {
      "epoch": 8.24843188422674,
      "grad_norm": 1.2306016683578491,
      "learning_rate": 4.547409869107932e-05,
      "loss": 0.4966,
      "step": 779150
    },
    {
      "epoch": 8.248961206006744,
      "grad_norm": 1.267447829246521,
      "learning_rate": 4.5447538346183564e-05,
      "loss": 0.4952,
      "step": 779200
    },
    {
      "epoch": 8.249490527786747,
      "grad_norm": 1.2824708223342896,
      "learning_rate": 4.542098498463379e-05,
      "loss": 0.4874,
      "step": 779250
    },
    {
      "epoch": 8.25001984956675,
      "grad_norm": 1.3649424314498901,
      "learning_rate": 4.5394438607336634e-05,
      "loss": 0.4989,
      "step": 779300
    },
    {
      "epoch": 8.250549171346753,
      "grad_norm": 1.2262462377548218,
      "learning_rate": 4.536789921519821e-05,
      "loss": 0.4968,
      "step": 779350
    },
    {
      "epoch": 8.251078493126757,
      "grad_norm": 1.4423160552978516,
      "learning_rate": 4.534136680912476e-05,
      "loss": 0.4881,
      "step": 779400
    },
    {
      "epoch": 8.25160781490676,
      "grad_norm": 1.3497227430343628,
      "learning_rate": 4.53148413900219e-05,
      "loss": 0.4814,
      "step": 779450
    },
    {
      "epoch": 8.252137136686763,
      "grad_norm": 1.2741745710372925,
      "learning_rate": 4.528832295879537e-05,
      "loss": 0.4917,
      "step": 779500
    },
    {
      "epoch": 8.252137136686763,
      "eval_loss": 0.30267733335494995,
      "eval_runtime": 47.0604,
      "eval_samples_per_second": 3568.396,
      "eval_steps_per_second": 446.065,
      "step": 779500
    },
    {
      "epoch": 8.252666458466766,
      "grad_norm": 1.3665348291397095,
      "learning_rate": 4.526181151635037e-05,
      "loss": 0.4938,
      "step": 779550
    },
    {
      "epoch": 8.25319578024677,
      "grad_norm": 1.364583134651184,
      "learning_rate": 4.523530706359205e-05,
      "loss": 0.4923,
      "step": 779600
    },
    {
      "epoch": 8.253725102026774,
      "grad_norm": 1.3650951385498047,
      "learning_rate": 4.520880960142523e-05,
      "loss": 0.5003,
      "step": 779650
    },
    {
      "epoch": 8.254254423806776,
      "grad_norm": 1.452439546585083,
      "learning_rate": 4.51823191307546e-05,
      "loss": 0.4905,
      "step": 779700
    },
    {
      "epoch": 8.25478374558678,
      "grad_norm": 1.3635244369506836,
      "learning_rate": 4.515583565248441e-05,
      "loss": 0.4958,
      "step": 779750
    },
    {
      "epoch": 8.255313067366783,
      "grad_norm": 1.34018874168396,
      "learning_rate": 4.512935916751887e-05,
      "loss": 0.4928,
      "step": 779800
    },
    {
      "epoch": 8.255842389146785,
      "grad_norm": 1.3070834875106812,
      "learning_rate": 4.510288967676193e-05,
      "loss": 0.4964,
      "step": 779850
    },
    {
      "epoch": 8.25637171092679,
      "grad_norm": 1.2615772485733032,
      "learning_rate": 4.5076427181117153e-05,
      "loss": 0.4948,
      "step": 779900
    },
    {
      "epoch": 8.256901032706793,
      "grad_norm": 1.290607213973999,
      "learning_rate": 4.504997168148797e-05,
      "loss": 0.4974,
      "step": 779950
    },
    {
      "epoch": 8.257430354486797,
      "grad_norm": 1.1804771423339844,
      "learning_rate": 4.502352317877767e-05,
      "loss": 0.4943,
      "step": 780000
    },
    {
      "epoch": 8.257430354486797,
      "eval_loss": 0.30326637625694275,
      "eval_runtime": 46.849,
      "eval_samples_per_second": 3584.494,
      "eval_steps_per_second": 448.078,
      "step": 780000
    },
    {
      "epoch": 8.257959676266799,
      "grad_norm": 1.3763483762741089,
      "learning_rate": 4.499708167388905e-05,
      "loss": 0.4823,
      "step": 780050
    },
    {
      "epoch": 8.258488998046802,
      "grad_norm": 1.2934304475784302,
      "learning_rate": 4.4970647167724946e-05,
      "loss": 0.494,
      "step": 780100
    },
    {
      "epoch": 8.259018319826806,
      "grad_norm": 1.3686189651489258,
      "learning_rate": 4.49442196611877e-05,
      "loss": 0.4864,
      "step": 780150
    },
    {
      "epoch": 8.25954764160681,
      "grad_norm": 1.4568350315093994,
      "learning_rate": 4.491779915517963e-05,
      "loss": 0.4939,
      "step": 780200
    },
    {
      "epoch": 8.260076963386812,
      "grad_norm": 1.310348629951477,
      "learning_rate": 4.489138565060263e-05,
      "loss": 0.4877,
      "step": 780250
    },
    {
      "epoch": 8.260606285166816,
      "grad_norm": 1.5394923686981201,
      "learning_rate": 4.4864979148358574e-05,
      "loss": 0.488,
      "step": 780300
    },
    {
      "epoch": 8.26113560694682,
      "grad_norm": 1.2033870220184326,
      "learning_rate": 4.4838579649348844e-05,
      "loss": 0.4852,
      "step": 780350
    },
    {
      "epoch": 8.261664928726823,
      "grad_norm": 1.4068667888641357,
      "learning_rate": 4.48121871544748e-05,
      "loss": 0.4932,
      "step": 780400
    },
    {
      "epoch": 8.262194250506825,
      "grad_norm": 1.2505625486373901,
      "learning_rate": 4.478580166463739e-05,
      "loss": 0.4953,
      "step": 780450
    },
    {
      "epoch": 8.262723572286829,
      "grad_norm": 1.4886279106140137,
      "learning_rate": 4.475942318073753e-05,
      "loss": 0.4881,
      "step": 780500
    },
    {
      "epoch": 8.262723572286829,
      "eval_loss": 0.3024919629096985,
      "eval_runtime": 46.9344,
      "eval_samples_per_second": 3577.972,
      "eval_steps_per_second": 447.263,
      "step": 780500
    },
    {
      "epoch": 8.263252894066833,
      "grad_norm": 1.369818925857544,
      "learning_rate": 4.4733051703675616e-05,
      "loss": 0.4844,
      "step": 780550
    },
    {
      "epoch": 8.263782215846835,
      "grad_norm": 1.2729827165603638,
      "learning_rate": 4.470668723435209e-05,
      "loss": 0.4933,
      "step": 780600
    },
    {
      "epoch": 8.264311537626838,
      "grad_norm": 1.3848768472671509,
      "learning_rate": 4.46803297736669e-05,
      "loss": 0.4872,
      "step": 780650
    },
    {
      "epoch": 8.264840859406842,
      "grad_norm": 1.419528603553772,
      "learning_rate": 4.465397932252005e-05,
      "loss": 0.4914,
      "step": 780700
    },
    {
      "epoch": 8.265370181186846,
      "grad_norm": 1.2771697044372559,
      "learning_rate": 4.4627635881810956e-05,
      "loss": 0.4923,
      "step": 780750
    },
    {
      "epoch": 8.265899502966848,
      "grad_norm": 1.351479411125183,
      "learning_rate": 4.46012994524391e-05,
      "loss": 0.4879,
      "step": 780800
    },
    {
      "epoch": 8.266428824746852,
      "grad_norm": 1.520348310470581,
      "learning_rate": 4.457497003530353e-05,
      "loss": 0.4893,
      "step": 780850
    },
    {
      "epoch": 8.266958146526855,
      "grad_norm": 1.489637017250061,
      "learning_rate": 4.4548647631303174e-05,
      "loss": 0.4942,
      "step": 780900
    },
    {
      "epoch": 8.267487468306859,
      "grad_norm": 1.430011510848999,
      "learning_rate": 4.4522332241336586e-05,
      "loss": 0.4866,
      "step": 780950
    },
    {
      "epoch": 8.268016790086861,
      "grad_norm": 1.2745318412780762,
      "learning_rate": 4.44960238663023e-05,
      "loss": 0.4868,
      "step": 781000
    },
    {
      "epoch": 8.268016790086861,
      "eval_loss": 0.3022949695587158,
      "eval_runtime": 46.7846,
      "eval_samples_per_second": 3589.426,
      "eval_steps_per_second": 448.694,
      "step": 781000
    },
    {
      "epoch": 8.268546111866865,
      "grad_norm": 1.4477386474609375,
      "learning_rate": 4.4469722507098296e-05,
      "loss": 0.4935,
      "step": 781050
    },
    {
      "epoch": 8.269075433646869,
      "grad_norm": 1.3610888719558716,
      "learning_rate": 4.444342816462268e-05,
      "loss": 0.4982,
      "step": 781100
    },
    {
      "epoch": 8.269604755426872,
      "grad_norm": 1.1465234756469727,
      "learning_rate": 4.441766651749138e-05,
      "loss": 0.4877,
      "step": 781150
    },
    {
      "epoch": 8.270134077206874,
      "grad_norm": 1.3681964874267578,
      "learning_rate": 4.4391386070785884e-05,
      "loss": 0.4997,
      "step": 781200
    },
    {
      "epoch": 8.270663398986878,
      "grad_norm": 1.3240883350372314,
      "learning_rate": 4.4365112643483e-05,
      "loss": 0.4846,
      "step": 781250
    },
    {
      "epoch": 8.271192720766882,
      "grad_norm": 1.426898717880249,
      "learning_rate": 4.4338846236479824e-05,
      "loss": 0.4962,
      "step": 781300
    },
    {
      "epoch": 8.271722042546884,
      "grad_norm": 1.2799038887023926,
      "learning_rate": 4.431258685067297e-05,
      "loss": 0.4932,
      "step": 781350
    },
    {
      "epoch": 8.272251364326888,
      "grad_norm": 1.3349767923355103,
      "learning_rate": 4.4286334486959014e-05,
      "loss": 0.4941,
      "step": 781400
    },
    {
      "epoch": 8.272780686106891,
      "grad_norm": 1.3732469081878662,
      "learning_rate": 4.426008914623408e-05,
      "loss": 0.4886,
      "step": 781450
    },
    {
      "epoch": 8.273310007886895,
      "grad_norm": 1.3309651613235474,
      "learning_rate": 4.4233850829394326e-05,
      "loss": 0.4936,
      "step": 781500
    },
    {
      "epoch": 8.273310007886895,
      "eval_loss": 0.3020685017108917,
      "eval_runtime": 46.9091,
      "eval_samples_per_second": 3579.901,
      "eval_steps_per_second": 447.504,
      "step": 781500
    },
    {
      "epoch": 8.273839329666897,
      "grad_norm": 1.281326174736023,
      "learning_rate": 4.4207619537335346e-05,
      "loss": 0.4847,
      "step": 781550
    },
    {
      "epoch": 8.2743686514469,
      "grad_norm": 1.3907122611999512,
      "learning_rate": 4.418139527095286e-05,
      "loss": 0.4939,
      "step": 781600
    },
    {
      "epoch": 8.274897973226905,
      "grad_norm": 1.3405860662460327,
      "learning_rate": 4.415517803114199e-05,
      "loss": 0.491,
      "step": 781650
    },
    {
      "epoch": 8.275427295006908,
      "grad_norm": 1.4282405376434326,
      "learning_rate": 4.412896781879791e-05,
      "loss": 0.4876,
      "step": 781700
    },
    {
      "epoch": 8.27595661678691,
      "grad_norm": 1.2712451219558716,
      "learning_rate": 4.41027646348153e-05,
      "loss": 0.485,
      "step": 781750
    },
    {
      "epoch": 8.276485938566914,
      "grad_norm": 1.2020565271377563,
      "learning_rate": 4.4076568480088866e-05,
      "loss": 0.4898,
      "step": 781800
    },
    {
      "epoch": 8.277015260346918,
      "grad_norm": 1.2151713371276855,
      "learning_rate": 4.4050379355512816e-05,
      "loss": 0.4864,
      "step": 781850
    },
    {
      "epoch": 8.277544582126922,
      "grad_norm": 1.4728301763534546,
      "learning_rate": 4.402419726198132e-05,
      "loss": 0.4901,
      "step": 781900
    },
    {
      "epoch": 8.278073903906924,
      "grad_norm": 1.2797306776046753,
      "learning_rate": 4.399802220038815e-05,
      "loss": 0.4884,
      "step": 781950
    },
    {
      "epoch": 8.278603225686927,
      "grad_norm": 1.3091566562652588,
      "learning_rate": 4.3971854171626994e-05,
      "loss": 0.489,
      "step": 782000
    },
    {
      "epoch": 8.278603225686927,
      "eval_loss": 0.3021632432937622,
      "eval_runtime": 46.9927,
      "eval_samples_per_second": 3573.534,
      "eval_steps_per_second": 446.708,
      "step": 782000
    },
    {
      "epoch": 8.279132547466931,
      "grad_norm": 1.399666666984558,
      "learning_rate": 4.394569317659111e-05,
      "loss": 0.4848,
      "step": 782050
    },
    {
      "epoch": 8.279661869246933,
      "grad_norm": 1.2772541046142578,
      "learning_rate": 4.391953921617372e-05,
      "loss": 0.4969,
      "step": 782100
    },
    {
      "epoch": 8.280191191026937,
      "grad_norm": 1.4451415538787842,
      "learning_rate": 4.3893392291267736e-05,
      "loss": 0.4938,
      "step": 782150
    },
    {
      "epoch": 8.28072051280694,
      "grad_norm": 1.5090770721435547,
      "learning_rate": 4.386725240276568e-05,
      "loss": 0.4922,
      "step": 782200
    },
    {
      "epoch": 8.281249834586944,
      "grad_norm": 1.2908847332000732,
      "learning_rate": 4.384111955156003e-05,
      "loss": 0.4781,
      "step": 782250
    },
    {
      "epoch": 8.281779156366946,
      "grad_norm": 1.3482714891433716,
      "learning_rate": 4.381499373854303e-05,
      "loss": 0.4878,
      "step": 782300
    },
    {
      "epoch": 8.28230847814695,
      "grad_norm": 1.4418649673461914,
      "learning_rate": 4.378887496460646e-05,
      "loss": 0.4971,
      "step": 782350
    },
    {
      "epoch": 8.282837799926954,
      "grad_norm": 1.3373130559921265,
      "learning_rate": 4.3762763230642124e-05,
      "loss": 0.4907,
      "step": 782400
    },
    {
      "epoch": 8.283367121706958,
      "grad_norm": 1.3463633060455322,
      "learning_rate": 4.3736658537541355e-05,
      "loss": 0.4934,
      "step": 782450
    },
    {
      "epoch": 8.28389644348696,
      "grad_norm": 1.2234171628952026,
      "learning_rate": 4.371056088619549e-05,
      "loss": 0.4982,
      "step": 782500
    },
    {
      "epoch": 8.28389644348696,
      "eval_loss": 0.301896333694458,
      "eval_runtime": 46.8104,
      "eval_samples_per_second": 3587.447,
      "eval_steps_per_second": 448.447,
      "step": 782500
    },
    {
      "epoch": 8.284425765266963,
      "grad_norm": 1.2279638051986694,
      "learning_rate": 4.368447027749536e-05,
      "loss": 0.4974,
      "step": 782550
    },
    {
      "epoch": 8.284955087046967,
      "grad_norm": 1.1814987659454346,
      "learning_rate": 4.36583867123318e-05,
      "loss": 0.4901,
      "step": 782600
    },
    {
      "epoch": 8.28548440882697,
      "grad_norm": 1.4415209293365479,
      "learning_rate": 4.363231019159519e-05,
      "loss": 0.5022,
      "step": 782650
    },
    {
      "epoch": 8.286013730606973,
      "grad_norm": 1.4254001379013062,
      "learning_rate": 4.360624071617589e-05,
      "loss": 0.4989,
      "step": 782700
    },
    {
      "epoch": 8.286543052386977,
      "grad_norm": 1.3836196660995483,
      "learning_rate": 4.3580178286963785e-05,
      "loss": 0.4895,
      "step": 782750
    },
    {
      "epoch": 8.28707237416698,
      "grad_norm": 1.309683918952942,
      "learning_rate": 4.355412290484872e-05,
      "loss": 0.4964,
      "step": 782800
    },
    {
      "epoch": 8.287601695946982,
      "grad_norm": 1.3785061836242676,
      "learning_rate": 4.3528074570720164e-05,
      "loss": 0.4938,
      "step": 782850
    },
    {
      "epoch": 8.288131017726986,
      "grad_norm": 1.2337003946304321,
      "learning_rate": 4.350203328546748e-05,
      "loss": 0.4833,
      "step": 782900
    },
    {
      "epoch": 8.28866033950699,
      "grad_norm": 1.3774422407150269,
      "learning_rate": 4.3475999049979564e-05,
      "loss": 0.4903,
      "step": 782950
    },
    {
      "epoch": 8.289189661286994,
      "grad_norm": 1.3149750232696533,
      "learning_rate": 4.344997186514538e-05,
      "loss": 0.4935,
      "step": 783000
    },
    {
      "epoch": 8.289189661286994,
      "eval_loss": 0.3017669916152954,
      "eval_runtime": 46.8785,
      "eval_samples_per_second": 3582.24,
      "eval_steps_per_second": 447.796,
      "step": 783000
    },
    {
      "epoch": 8.289718983066996,
      "grad_norm": 1.4449269771575928,
      "learning_rate": 4.3423951731853315e-05,
      "loss": 0.4944,
      "step": 783050
    },
    {
      "epoch": 8.290248304847,
      "grad_norm": 1.4325244426727295,
      "learning_rate": 4.339793865099187e-05,
      "loss": 0.4898,
      "step": 783100
    },
    {
      "epoch": 8.290777626627003,
      "grad_norm": 1.232242226600647,
      "learning_rate": 4.337193262344896e-05,
      "loss": 0.4915,
      "step": 783150
    },
    {
      "epoch": 8.291306948407007,
      "grad_norm": 1.303890347480774,
      "learning_rate": 4.334593365011255e-05,
      "loss": 0.4892,
      "step": 783200
    },
    {
      "epoch": 8.291836270187009,
      "grad_norm": 1.3832429647445679,
      "learning_rate": 4.331994173187012e-05,
      "loss": 0.4788,
      "step": 783250
    },
    {
      "epoch": 8.292365591967013,
      "grad_norm": 1.348193645477295,
      "learning_rate": 4.3293956869609156e-05,
      "loss": 0.4947,
      "step": 783300
    },
    {
      "epoch": 8.292894913747016,
      "grad_norm": 1.3583738803863525,
      "learning_rate": 4.326797906421662e-05,
      "loss": 0.4864,
      "step": 783350
    },
    {
      "epoch": 8.29342423552702,
      "grad_norm": 1.3858989477157593,
      "learning_rate": 4.324200831657954e-05,
      "loss": 0.4878,
      "step": 783400
    },
    {
      "epoch": 8.293953557307022,
      "grad_norm": 1.2639729976654053,
      "learning_rate": 4.3216044627584384e-05,
      "loss": 0.4945,
      "step": 783450
    },
    {
      "epoch": 8.294482879087026,
      "grad_norm": 1.1604818105697632,
      "learning_rate": 4.319008799811769e-05,
      "loss": 0.4914,
      "step": 783500
    },
    {
      "epoch": 8.294482879087026,
      "eval_loss": 0.30218756198883057,
      "eval_runtime": 46.7098,
      "eval_samples_per_second": 3595.178,
      "eval_steps_per_second": 449.413,
      "step": 783500
    },
    {
      "epoch": 8.29501220086703,
      "grad_norm": 1.2380080223083496,
      "learning_rate": 4.3164138429065494e-05,
      "loss": 0.4889,
      "step": 783550
    },
    {
      "epoch": 8.295541522647031,
      "grad_norm": 1.3280669450759888,
      "learning_rate": 4.313819592131382e-05,
      "loss": 0.4874,
      "step": 783600
    },
    {
      "epoch": 8.296070844427035,
      "grad_norm": 1.4108762741088867,
      "learning_rate": 4.311226047574823e-05,
      "loss": 0.4916,
      "step": 783650
    },
    {
      "epoch": 8.296600166207039,
      "grad_norm": 1.3930155038833618,
      "learning_rate": 4.308633209325416e-05,
      "loss": 0.4867,
      "step": 783700
    },
    {
      "epoch": 8.297129487987043,
      "grad_norm": 1.4185900688171387,
      "learning_rate": 4.30604107747169e-05,
      "loss": 0.482,
      "step": 783750
    },
    {
      "epoch": 8.297658809767045,
      "grad_norm": 1.2718040943145752,
      "learning_rate": 4.303449652102129e-05,
      "loss": 0.4847,
      "step": 783800
    },
    {
      "epoch": 8.298188131547048,
      "grad_norm": 1.3733773231506348,
      "learning_rate": 4.300858933305202e-05,
      "loss": 0.4856,
      "step": 783850
    },
    {
      "epoch": 8.298717453327052,
      "grad_norm": 1.4647325277328491,
      "learning_rate": 4.298268921169368e-05,
      "loss": 0.4951,
      "step": 783900
    },
    {
      "epoch": 8.299246775107056,
      "grad_norm": 1.5179256200790405,
      "learning_rate": 4.295679615783035e-05,
      "loss": 0.487,
      "step": 783950
    },
    {
      "epoch": 8.299776096887058,
      "grad_norm": 1.2823456525802612,
      "learning_rate": 4.2930910172346126e-05,
      "loss": 0.4947,
      "step": 784000
    },
    {
      "epoch": 8.299776096887058,
      "eval_loss": 0.3022197186946869,
      "eval_runtime": 46.9112,
      "eval_samples_per_second": 3579.743,
      "eval_steps_per_second": 447.484,
      "step": 784000
    },
    {
      "epoch": 8.300305418667062,
      "grad_norm": 1.434095859527588,
      "learning_rate": 4.290503125612463e-05,
      "loss": 0.4864,
      "step": 784050
    },
    {
      "epoch": 8.300834740447065,
      "grad_norm": 1.3913122415542603,
      "learning_rate": 4.287915941004949e-05,
      "loss": 0.4889,
      "step": 784100
    },
    {
      "epoch": 8.30136406222707,
      "grad_norm": 1.3373627662658691,
      "learning_rate": 4.285329463500381e-05,
      "loss": 0.4891,
      "step": 784150
    },
    {
      "epoch": 8.301893384007071,
      "grad_norm": 1.3782819509506226,
      "learning_rate": 4.282743693187077e-05,
      "loss": 0.4903,
      "step": 784200
    },
    {
      "epoch": 8.302422705787075,
      "grad_norm": 1.5309325456619263,
      "learning_rate": 4.280158630153297e-05,
      "loss": 0.4969,
      "step": 784250
    },
    {
      "epoch": 8.302952027567079,
      "grad_norm": 1.2199169397354126,
      "learning_rate": 4.277574274487309e-05,
      "loss": 0.4839,
      "step": 784300
    },
    {
      "epoch": 8.30348134934708,
      "grad_norm": 1.387856125831604,
      "learning_rate": 4.274990626277328e-05,
      "loss": 0.4921,
      "step": 784350
    },
    {
      "epoch": 8.304010671127084,
      "grad_norm": 1.35703706741333,
      "learning_rate": 4.2724076856115737e-05,
      "loss": 0.4814,
      "step": 784400
    },
    {
      "epoch": 8.304539992907088,
      "grad_norm": 1.3029903173446655,
      "learning_rate": 4.2698254525782134e-05,
      "loss": 0.4848,
      "step": 784450
    },
    {
      "epoch": 8.305069314687092,
      "grad_norm": 1.373093843460083,
      "learning_rate": 4.2672439272654154e-05,
      "loss": 0.487,
      "step": 784500
    },
    {
      "epoch": 8.305069314687092,
      "eval_loss": 0.30151501297950745,
      "eval_runtime": 46.7969,
      "eval_samples_per_second": 3588.489,
      "eval_steps_per_second": 448.577,
      "step": 784500
    },
    {
      "epoch": 8.305598636467094,
      "grad_norm": 1.266524314880371,
      "learning_rate": 4.264663109761302e-05,
      "loss": 0.4862,
      "step": 784550
    },
    {
      "epoch": 8.306127958247098,
      "grad_norm": 1.3502520322799683,
      "learning_rate": 4.2620830001539905e-05,
      "loss": 0.4869,
      "step": 784600
    },
    {
      "epoch": 8.306657280027101,
      "grad_norm": 1.3118213415145874,
      "learning_rate": 4.2595035985315525e-05,
      "loss": 0.4997,
      "step": 784650
    },
    {
      "epoch": 8.307186601807105,
      "grad_norm": 1.323312759399414,
      "learning_rate": 4.256924904982062e-05,
      "loss": 0.4867,
      "step": 784700
    },
    {
      "epoch": 8.307715923587107,
      "grad_norm": 1.3204234838485718,
      "learning_rate": 4.2543469195935436e-05,
      "loss": 0.4849,
      "step": 784750
    },
    {
      "epoch": 8.308245245367111,
      "grad_norm": 1.372531533241272,
      "learning_rate": 4.2517696424540174e-05,
      "loss": 0.4959,
      "step": 784800
    },
    {
      "epoch": 8.308774567147115,
      "grad_norm": 1.2936325073242188,
      "learning_rate": 4.249193073651461e-05,
      "loss": 0.4876,
      "step": 784850
    },
    {
      "epoch": 8.309303888927118,
      "grad_norm": 1.4300024509429932,
      "learning_rate": 4.2466172132738486e-05,
      "loss": 0.4923,
      "step": 784900
    },
    {
      "epoch": 8.30983321070712,
      "grad_norm": 1.2426660060882568,
      "learning_rate": 4.244042061409106e-05,
      "loss": 0.4925,
      "step": 784950
    },
    {
      "epoch": 8.310362532487124,
      "grad_norm": 1.3558621406555176,
      "learning_rate": 4.241467618145164e-05,
      "loss": 0.4843,
      "step": 785000
    },
    {
      "epoch": 8.310362532487124,
      "eval_loss": 0.3015829622745514,
      "eval_runtime": 46.8647,
      "eval_samples_per_second": 3583.296,
      "eval_steps_per_second": 447.928,
      "step": 785000
    },
    {
      "epoch": 8.310891854267128,
      "grad_norm": 1.2988992929458618,
      "learning_rate": 4.238893883569897e-05,
      "loss": 0.4872,
      "step": 785050
    },
    {
      "epoch": 8.31142117604713,
      "grad_norm": 1.497595191001892,
      "learning_rate": 4.2363208577711866e-05,
      "loss": 0.4842,
      "step": 785100
    },
    {
      "epoch": 8.311950497827134,
      "grad_norm": 1.5390986204147339,
      "learning_rate": 4.233799980228109e-05,
      "loss": 0.4892,
      "step": 785150
    },
    {
      "epoch": 8.312479819607137,
      "grad_norm": 1.4386621713638306,
      "learning_rate": 4.2312797835610455e-05,
      "loss": 0.4931,
      "step": 785200
    },
    {
      "epoch": 8.313009141387141,
      "grad_norm": 1.3740637302398682,
      "learning_rate": 4.2287088562556475e-05,
      "loss": 0.4886,
      "step": 785250
    },
    {
      "epoch": 8.313538463167143,
      "grad_norm": 1.2823066711425781,
      "learning_rate": 4.226138638074514e-05,
      "loss": 0.4986,
      "step": 785300
    },
    {
      "epoch": 8.314067784947147,
      "grad_norm": 1.2417889833450317,
      "learning_rate": 4.223569129105384e-05,
      "loss": 0.484,
      "step": 785350
    },
    {
      "epoch": 8.31459710672715,
      "grad_norm": 1.3279147148132324,
      "learning_rate": 4.221000329435989e-05,
      "loss": 0.49,
      "step": 785400
    },
    {
      "epoch": 8.315126428507154,
      "grad_norm": 1.3200798034667969,
      "learning_rate": 4.218432239154019e-05,
      "loss": 0.484,
      "step": 785450
    },
    {
      "epoch": 8.315655750287156,
      "grad_norm": 1.3835963010787964,
      "learning_rate": 4.215864858347157e-05,
      "loss": 0.4855,
      "step": 785500
    },
    {
      "epoch": 8.315655750287156,
      "eval_loss": 0.30119597911834717,
      "eval_runtime": 46.8047,
      "eval_samples_per_second": 3587.89,
      "eval_steps_per_second": 448.502,
      "step": 785500
    },
    {
      "epoch": 8.31618507206716,
      "grad_norm": 1.220743179321289,
      "learning_rate": 4.213298187103037e-05,
      "loss": 0.486,
      "step": 785550
    },
    {
      "epoch": 8.316714393847164,
      "grad_norm": 1.3920842409133911,
      "learning_rate": 4.2107322255093035e-05,
      "loss": 0.4927,
      "step": 785600
    },
    {
      "epoch": 8.317243715627168,
      "grad_norm": 1.3660998344421387,
      "learning_rate": 4.2081669736535374e-05,
      "loss": 0.4895,
      "step": 785650
    },
    {
      "epoch": 8.31777303740717,
      "grad_norm": 1.3130239248275757,
      "learning_rate": 4.2056024316233345e-05,
      "loss": 0.4883,
      "step": 785700
    },
    {
      "epoch": 8.318302359187173,
      "grad_norm": 1.4473578929901123,
      "learning_rate": 4.203038599506232e-05,
      "loss": 0.4945,
      "step": 785750
    },
    {
      "epoch": 8.318831680967177,
      "grad_norm": 1.3995521068572998,
      "learning_rate": 4.20047547738977e-05,
      "loss": 0.4903,
      "step": 785800
    },
    {
      "epoch": 8.31936100274718,
      "grad_norm": 1.3105781078338623,
      "learning_rate": 4.197913065361442e-05,
      "loss": 0.4884,
      "step": 785850
    },
    {
      "epoch": 8.319890324527183,
      "grad_norm": 1.589897632598877,
      "learning_rate": 4.19535136350874e-05,
      "loss": 0.4943,
      "step": 785900
    },
    {
      "epoch": 8.320419646307187,
      "grad_norm": 1.514103651046753,
      "learning_rate": 4.1927903719191054e-05,
      "loss": 0.492,
      "step": 785950
    },
    {
      "epoch": 8.32094896808719,
      "grad_norm": 1.3086137771606445,
      "learning_rate": 4.190230090679981e-05,
      "loss": 0.4849,
      "step": 786000
    },
    {
      "epoch": 8.32094896808719,
      "eval_loss": 0.30152612924575806,
      "eval_runtime": 46.8048,
      "eval_samples_per_second": 3587.881,
      "eval_steps_per_second": 448.501,
      "step": 786000
    },
    {
      "epoch": 8.321478289867192,
      "grad_norm": 1.5050228834152222,
      "learning_rate": 4.187670519878767e-05,
      "loss": 0.4833,
      "step": 786050
    },
    {
      "epoch": 8.322007611647196,
      "grad_norm": 1.4254306554794312,
      "learning_rate": 4.185111659602844e-05,
      "loss": 0.4887,
      "step": 786100
    },
    {
      "epoch": 8.3225369334272,
      "grad_norm": 1.3902816772460938,
      "learning_rate": 4.182553509939585e-05,
      "loss": 0.4931,
      "step": 786150
    },
    {
      "epoch": 8.323066255207204,
      "grad_norm": 1.1934089660644531,
      "learning_rate": 4.179996070976308e-05,
      "loss": 0.4917,
      "step": 786200
    },
    {
      "epoch": 8.323595576987206,
      "grad_norm": 1.3494970798492432,
      "learning_rate": 4.177439342800335e-05,
      "loss": 0.4841,
      "step": 786250
    },
    {
      "epoch": 8.32412489876721,
      "grad_norm": 1.4271118640899658,
      "learning_rate": 4.17488332549894e-05,
      "loss": 0.4838,
      "step": 786300
    },
    {
      "epoch": 8.324654220547213,
      "grad_norm": 1.3667494058609009,
      "learning_rate": 4.172328019159394e-05,
      "loss": 0.4942,
      "step": 786350
    },
    {
      "epoch": 8.325183542327217,
      "grad_norm": 1.3233433961868286,
      "learning_rate": 4.1697734238689336e-05,
      "loss": 0.4949,
      "step": 786400
    },
    {
      "epoch": 8.325712864107219,
      "grad_norm": 1.4460808038711548,
      "learning_rate": 4.1672195397147644e-05,
      "loss": 0.4906,
      "step": 786450
    },
    {
      "epoch": 8.326242185887223,
      "grad_norm": 1.4341884851455688,
      "learning_rate": 4.1646663667840784e-05,
      "loss": 0.4968,
      "step": 786500
    },
    {
      "epoch": 8.326242185887223,
      "eval_loss": 0.3014703392982483,
      "eval_runtime": 46.8853,
      "eval_samples_per_second": 3581.718,
      "eval_steps_per_second": 447.731,
      "step": 786500
    },
    {
      "epoch": 8.326771507667226,
      "grad_norm": 1.4058325290679932,
      "learning_rate": 4.16211390516405e-05,
      "loss": 0.4955,
      "step": 786550
    },
    {
      "epoch": 8.327300829447228,
      "grad_norm": 1.2523342370986938,
      "learning_rate": 4.159562154941804e-05,
      "loss": 0.4917,
      "step": 786600
    },
    {
      "epoch": 8.327830151227232,
      "grad_norm": 1.3239420652389526,
      "learning_rate": 4.1570111162044674e-05,
      "loss": 0.4917,
      "step": 786650
    },
    {
      "epoch": 8.328359473007236,
      "grad_norm": 1.4126437902450562,
      "learning_rate": 4.1544607890391244e-05,
      "loss": 0.4931,
      "step": 786700
    },
    {
      "epoch": 8.32888879478724,
      "grad_norm": 1.0909792184829712,
      "learning_rate": 4.151911173532849e-05,
      "loss": 0.4908,
      "step": 786750
    },
    {
      "epoch": 8.329418116567242,
      "grad_norm": 1.3142540454864502,
      "learning_rate": 4.1493622697726747e-05,
      "loss": 0.4827,
      "step": 786800
    },
    {
      "epoch": 8.329947438347245,
      "grad_norm": 1.5257238149642944,
      "learning_rate": 4.146814077845631e-05,
      "loss": 0.4915,
      "step": 786850
    },
    {
      "epoch": 8.33047676012725,
      "grad_norm": 1.3334574699401855,
      "learning_rate": 4.144266597838703e-05,
      "loss": 0.4841,
      "step": 786900
    },
    {
      "epoch": 8.331006081907253,
      "grad_norm": 1.2948194742202759,
      "learning_rate": 4.141719829838869e-05,
      "loss": 0.4905,
      "step": 786950
    },
    {
      "epoch": 8.331535403687255,
      "grad_norm": 1.6211215257644653,
      "learning_rate": 4.139173773933066e-05,
      "loss": 0.4934,
      "step": 787000
    },
    {
      "epoch": 8.331535403687255,
      "eval_loss": 0.3014172315597534,
      "eval_runtime": 46.8578,
      "eval_samples_per_second": 3583.823,
      "eval_steps_per_second": 447.994,
      "step": 787000
    },
    {
      "epoch": 8.332064725467259,
      "grad_norm": 1.4416191577911377,
      "learning_rate": 4.136628430208225e-05,
      "loss": 0.4954,
      "step": 787050
    },
    {
      "epoch": 8.332594047247262,
      "grad_norm": 1.3354675769805908,
      "learning_rate": 4.1340837987512315e-05,
      "loss": 0.4874,
      "step": 787100
    },
    {
      "epoch": 8.333123369027266,
      "grad_norm": 1.2245993614196777,
      "learning_rate": 4.1315398796489714e-05,
      "loss": 0.495,
      "step": 787150
    },
    {
      "epoch": 8.333652690807268,
      "grad_norm": 1.2497450113296509,
      "learning_rate": 4.128996672988281e-05,
      "loss": 0.4863,
      "step": 787200
    },
    {
      "epoch": 8.334182012587272,
      "grad_norm": 1.3456573486328125,
      "learning_rate": 4.126454178855993e-05,
      "loss": 0.4894,
      "step": 787250
    },
    {
      "epoch": 8.334711334367276,
      "grad_norm": 1.236193060874939,
      "learning_rate": 4.123963225985056e-05,
      "loss": 0.487,
      "step": 787300
    },
    {
      "epoch": 8.335240656147278,
      "grad_norm": 1.280146598815918,
      "learning_rate": 4.121422142915046e-05,
      "loss": 0.4952,
      "step": 787350
    },
    {
      "epoch": 8.335769977927281,
      "grad_norm": 1.4804022312164307,
      "learning_rate": 4.118881772632035e-05,
      "loss": 0.4954,
      "step": 787400
    },
    {
      "epoch": 8.336299299707285,
      "grad_norm": 1.2131047248840332,
      "learning_rate": 4.1163421152227376e-05,
      "loss": 0.4849,
      "step": 787450
    },
    {
      "epoch": 8.336828621487289,
      "grad_norm": 1.4815996885299683,
      "learning_rate": 4.113803170773867e-05,
      "loss": 0.4838,
      "step": 787500
    },
    {
      "epoch": 8.336828621487289,
      "eval_loss": 0.301013708114624,
      "eval_runtime": 46.9002,
      "eval_samples_per_second": 3580.585,
      "eval_steps_per_second": 447.589,
      "step": 787500
    },
    {
      "epoch": 8.33735794326729,
      "grad_norm": 1.579502820968628,
      "learning_rate": 4.1112649393720894e-05,
      "loss": 0.4859,
      "step": 787550
    },
    {
      "epoch": 8.337887265047295,
      "grad_norm": 1.4406769275665283,
      "learning_rate": 4.108727421104072e-05,
      "loss": 0.4815,
      "step": 787600
    },
    {
      "epoch": 8.338416586827298,
      "grad_norm": 1.3006196022033691,
      "learning_rate": 4.106190616056435e-05,
      "loss": 0.4892,
      "step": 787650
    },
    {
      "epoch": 8.338945908607302,
      "grad_norm": 1.2997386455535889,
      "learning_rate": 4.103654524315792e-05,
      "loss": 0.491,
      "step": 787700
    },
    {
      "epoch": 8.339475230387304,
      "grad_norm": 1.5275554656982422,
      "learning_rate": 4.1011191459687125e-05,
      "loss": 0.4856,
      "step": 787750
    },
    {
      "epoch": 8.340004552167308,
      "grad_norm": 1.4047240018844604,
      "learning_rate": 4.098584481101769e-05,
      "loss": 0.4931,
      "step": 787800
    },
    {
      "epoch": 8.340533873947312,
      "grad_norm": 1.464320421218872,
      "learning_rate": 4.0960505298014816e-05,
      "loss": 0.479,
      "step": 787850
    },
    {
      "epoch": 8.341063195727315,
      "grad_norm": 1.503433346748352,
      "learning_rate": 4.093517292154367e-05,
      "loss": 0.4938,
      "step": 787900
    },
    {
      "epoch": 8.341592517507317,
      "grad_norm": 1.4376543760299683,
      "learning_rate": 4.090984768246897e-05,
      "loss": 0.4848,
      "step": 787950
    },
    {
      "epoch": 8.342121839287321,
      "grad_norm": 1.3729177713394165,
      "learning_rate": 4.0884529581655476e-05,
      "loss": 0.4911,
      "step": 788000
    },
    {
      "epoch": 8.342121839287321,
      "eval_loss": 0.3011855185031891,
      "eval_runtime": 46.8317,
      "eval_samples_per_second": 3585.822,
      "eval_steps_per_second": 448.244,
      "step": 788000
    },
    {
      "epoch": 8.342651161067325,
      "grad_norm": 1.5032885074615479,
      "learning_rate": 4.085921861996736e-05,
      "loss": 0.4893,
      "step": 788050
    },
    {
      "epoch": 8.343180482847327,
      "grad_norm": 1.343363642692566,
      "learning_rate": 4.083391479826892e-05,
      "loss": 0.4875,
      "step": 788100
    },
    {
      "epoch": 8.34370980462733,
      "grad_norm": 1.3821899890899658,
      "learning_rate": 4.080861811742384e-05,
      "loss": 0.4766,
      "step": 788150
    },
    {
      "epoch": 8.344239126407334,
      "grad_norm": 1.303178310394287,
      "learning_rate": 4.0783328578295864e-05,
      "loss": 0.4899,
      "step": 788200
    },
    {
      "epoch": 8.344768448187338,
      "grad_norm": 1.1938945055007935,
      "learning_rate": 4.075804618174828e-05,
      "loss": 0.4814,
      "step": 788250
    },
    {
      "epoch": 8.34529776996734,
      "grad_norm": 1.4074130058288574,
      "learning_rate": 4.07327709286443e-05,
      "loss": 0.4864,
      "step": 788300
    },
    {
      "epoch": 8.345827091747344,
      "grad_norm": 1.230115532875061,
      "learning_rate": 4.0707502819846756e-05,
      "loss": 0.4904,
      "step": 788350
    },
    {
      "epoch": 8.346356413527348,
      "grad_norm": 1.3792121410369873,
      "learning_rate": 4.0682241856218275e-05,
      "loss": 0.4862,
      "step": 788400
    },
    {
      "epoch": 8.346885735307351,
      "grad_norm": 1.3654283285140991,
      "learning_rate": 4.065698803862136e-05,
      "loss": 0.4976,
      "step": 788450
    },
    {
      "epoch": 8.347415057087353,
      "grad_norm": 1.3344457149505615,
      "learning_rate": 4.0631741367918056e-05,
      "loss": 0.49,
      "step": 788500
    },
    {
      "epoch": 8.347415057087353,
      "eval_loss": 0.3013628125190735,
      "eval_runtime": 46.8094,
      "eval_samples_per_second": 3587.529,
      "eval_steps_per_second": 448.457,
      "step": 788500
    },
    {
      "epoch": 8.347944378867357,
      "grad_norm": 1.3818590641021729,
      "learning_rate": 4.060650184497036e-05,
      "loss": 0.489,
      "step": 788550
    },
    {
      "epoch": 8.34847370064736,
      "grad_norm": 1.3556060791015625,
      "learning_rate": 4.0581269470639836e-05,
      "loss": 0.4818,
      "step": 788600
    },
    {
      "epoch": 8.349003022427365,
      "grad_norm": 1.3882673978805542,
      "learning_rate": 4.055604424578796e-05,
      "loss": 0.4874,
      "step": 788650
    },
    {
      "epoch": 8.349532344207367,
      "grad_norm": 1.4263521432876587,
      "learning_rate": 4.053082617127601e-05,
      "loss": 0.4831,
      "step": 788700
    },
    {
      "epoch": 8.35006166598737,
      "grad_norm": 1.3832651376724243,
      "learning_rate": 4.050561524796476e-05,
      "loss": 0.4927,
      "step": 788750
    },
    {
      "epoch": 8.350590987767374,
      "grad_norm": 1.4147082567214966,
      "learning_rate": 4.048041147671505e-05,
      "loss": 0.4882,
      "step": 788800
    },
    {
      "epoch": 8.351120309547376,
      "grad_norm": 1.4569624662399292,
      "learning_rate": 4.0455214858387184e-05,
      "loss": 0.4894,
      "step": 788850
    },
    {
      "epoch": 8.35164963132738,
      "grad_norm": 1.3267840147018433,
      "learning_rate": 4.0430025393841466e-05,
      "loss": 0.4922,
      "step": 788900
    },
    {
      "epoch": 8.352178953107384,
      "grad_norm": 1.53598952293396,
      "learning_rate": 4.0404843083937795e-05,
      "loss": 0.4781,
      "step": 788950
    },
    {
      "epoch": 8.352708274887387,
      "grad_norm": 1.4735568761825562,
      "learning_rate": 4.037966792953599e-05,
      "loss": 0.4904,
      "step": 789000
    },
    {
      "epoch": 8.352708274887387,
      "eval_loss": 0.3009338974952698,
      "eval_runtime": 46.8464,
      "eval_samples_per_second": 3584.692,
      "eval_steps_per_second": 448.103,
      "step": 789000
    },
    {
      "epoch": 8.35323759666739,
      "grad_norm": 1.3295785188674927,
      "learning_rate": 4.0354499931495344e-05,
      "loss": 0.4864,
      "step": 789050
    },
    {
      "epoch": 8.353766918447393,
      "grad_norm": 1.349122405052185,
      "learning_rate": 4.0329339090675264e-05,
      "loss": 0.4815,
      "step": 789100
    },
    {
      "epoch": 8.354296240227397,
      "grad_norm": 1.2993197441101074,
      "learning_rate": 4.0304185407934596e-05,
      "loss": 0.4969,
      "step": 789150
    },
    {
      "epoch": 8.3548255620074,
      "grad_norm": 1.3991678953170776,
      "learning_rate": 4.02790388841322e-05,
      "loss": 0.4873,
      "step": 789200
    },
    {
      "epoch": 8.355354883787403,
      "grad_norm": 1.4095499515533447,
      "learning_rate": 4.0253899520126424e-05,
      "loss": 0.4948,
      "step": 789250
    },
    {
      "epoch": 8.355884205567406,
      "grad_norm": 1.430626630783081,
      "learning_rate": 4.022876731677566e-05,
      "loss": 0.491,
      "step": 789300
    },
    {
      "epoch": 8.35641352734741,
      "grad_norm": 1.221179723739624,
      "learning_rate": 4.02041447055862e-05,
      "loss": 0.4886,
      "step": 789350
    },
    {
      "epoch": 8.356942849127414,
      "grad_norm": 1.2556859254837036,
      "learning_rate": 4.0179026682863245e-05,
      "loss": 0.4846,
      "step": 789400
    },
    {
      "epoch": 8.357472170907416,
      "grad_norm": 1.3597149848937988,
      "learning_rate": 4.01539158233514e-05,
      "loss": 0.4825,
      "step": 789450
    },
    {
      "epoch": 8.35800149268742,
      "grad_norm": 1.3109514713287354,
      "learning_rate": 4.0128812127907864e-05,
      "loss": 0.4856,
      "step": 789500
    },
    {
      "epoch": 8.35800149268742,
      "eval_loss": 0.30097925662994385,
      "eval_runtime": 46.8212,
      "eval_samples_per_second": 3586.626,
      "eval_steps_per_second": 448.344,
      "step": 789500
    },
    {
      "epoch": 8.358530814467423,
      "grad_norm": 1.2323048114776611,
      "learning_rate": 4.010371559738979e-05,
      "loss": 0.4849,
      "step": 789550
    },
    {
      "epoch": 8.359060136247425,
      "grad_norm": 1.387776494026184,
      "learning_rate": 4.007862623265379e-05,
      "loss": 0.4832,
      "step": 789600
    },
    {
      "epoch": 8.359589458027429,
      "grad_norm": 1.2471997737884521,
      "learning_rate": 4.0053544034556605e-05,
      "loss": 0.4968,
      "step": 789650
    },
    {
      "epoch": 8.360118779807433,
      "grad_norm": 1.3216346502304077,
      "learning_rate": 4.002846900395435e-05,
      "loss": 0.4857,
      "step": 789700
    },
    {
      "epoch": 8.360648101587437,
      "grad_norm": 1.5213011503219604,
      "learning_rate": 4.0003401141703225e-05,
      "loss": 0.4798,
      "step": 789750
    },
    {
      "epoch": 8.361177423367439,
      "grad_norm": 1.3161134719848633,
      "learning_rate": 3.997834044865889e-05,
      "loss": 0.486,
      "step": 789800
    },
    {
      "epoch": 8.361706745147442,
      "grad_norm": 1.3716323375701904,
      "learning_rate": 3.995328692567707e-05,
      "loss": 0.4899,
      "step": 789850
    },
    {
      "epoch": 8.362236066927446,
      "grad_norm": 1.3246381282806396,
      "learning_rate": 3.992824057361294e-05,
      "loss": 0.4899,
      "step": 789900
    },
    {
      "epoch": 8.36276538870745,
      "grad_norm": 1.3927106857299805,
      "learning_rate": 3.9903201393321684e-05,
      "loss": 0.4936,
      "step": 789950
    },
    {
      "epoch": 8.363294710487452,
      "grad_norm": 1.453685998916626,
      "learning_rate": 3.987816938565803e-05,
      "loss": 0.4784,
      "step": 790000
    },
    {
      "epoch": 8.363294710487452,
      "eval_loss": 0.30104735493659973,
      "eval_runtime": 46.8503,
      "eval_samples_per_second": 3584.392,
      "eval_steps_per_second": 448.065,
      "step": 790000
    },
    {
      "epoch": 8.363824032267456,
      "grad_norm": 1.4072529077529907,
      "learning_rate": 3.985314455147668e-05,
      "loss": 0.4896,
      "step": 790050
    },
    {
      "epoch": 8.36435335404746,
      "grad_norm": 1.349509835243225,
      "learning_rate": 3.9828126891631844e-05,
      "loss": 0.4929,
      "step": 790100
    },
    {
      "epoch": 8.364882675827463,
      "grad_norm": 1.3229676485061646,
      "learning_rate": 3.980311640697773e-05,
      "loss": 0.49,
      "step": 790150
    },
    {
      "epoch": 8.365411997607465,
      "grad_norm": 1.3575963973999023,
      "learning_rate": 3.977811309836807e-05,
      "loss": 0.4835,
      "step": 790200
    },
    {
      "epoch": 8.365941319387469,
      "grad_norm": 1.24229896068573,
      "learning_rate": 3.975311696665659e-05,
      "loss": 0.4848,
      "step": 790250
    },
    {
      "epoch": 8.366470641167473,
      "grad_norm": 1.4096075296401978,
      "learning_rate": 3.972812801269654e-05,
      "loss": 0.4825,
      "step": 790300
    },
    {
      "epoch": 8.366999962947475,
      "grad_norm": 1.3834038972854614,
      "learning_rate": 3.970314623734114e-05,
      "loss": 0.4922,
      "step": 790350
    },
    {
      "epoch": 8.367529284727478,
      "grad_norm": 1.4344563484191895,
      "learning_rate": 3.967817164144316e-05,
      "loss": 0.4909,
      "step": 790400
    },
    {
      "epoch": 8.368058606507482,
      "grad_norm": 1.443992257118225,
      "learning_rate": 3.965320422585525e-05,
      "loss": 0.4793,
      "step": 790450
    },
    {
      "epoch": 8.368587928287486,
      "grad_norm": 1.357470989227295,
      "learning_rate": 3.9628243991429864e-05,
      "loss": 0.4906,
      "step": 790500
    },
    {
      "epoch": 8.368587928287486,
      "eval_loss": 0.3004927635192871,
      "eval_runtime": 46.8465,
      "eval_samples_per_second": 3584.686,
      "eval_steps_per_second": 448.102,
      "step": 790500
    },
    {
      "epoch": 8.369117250067488,
      "grad_norm": 1.2873616218566895,
      "learning_rate": 3.9603290939019045e-05,
      "loss": 0.4872,
      "step": 790550
    },
    {
      "epoch": 8.369646571847492,
      "grad_norm": 1.3499568700790405,
      "learning_rate": 3.957834506947475e-05,
      "loss": 0.4859,
      "step": 790600
    },
    {
      "epoch": 8.370175893627495,
      "grad_norm": 1.3127268552780151,
      "learning_rate": 3.955340638364851e-05,
      "loss": 0.4813,
      "step": 790650
    },
    {
      "epoch": 8.370705215407499,
      "grad_norm": 1.4454408884048462,
      "learning_rate": 3.9528474882391804e-05,
      "loss": 0.4917,
      "step": 790700
    },
    {
      "epoch": 8.371234537187501,
      "grad_norm": 1.3691660165786743,
      "learning_rate": 3.950355056655586e-05,
      "loss": 0.4997,
      "step": 790750
    },
    {
      "epoch": 8.371763858967505,
      "grad_norm": 1.308241605758667,
      "learning_rate": 3.947863343699143e-05,
      "loss": 0.4983,
      "step": 790800
    },
    {
      "epoch": 8.372293180747509,
      "grad_norm": 1.4138476848602295,
      "learning_rate": 3.945372349454929e-05,
      "loss": 0.4896,
      "step": 790850
    },
    {
      "epoch": 8.372822502527512,
      "grad_norm": 1.3982977867126465,
      "learning_rate": 3.9428820740079777e-05,
      "loss": 0.4832,
      "step": 790900
    },
    {
      "epoch": 8.373351824307514,
      "grad_norm": 1.4090242385864258,
      "learning_rate": 3.940392517443314e-05,
      "loss": 0.4902,
      "step": 790950
    },
    {
      "epoch": 8.373881146087518,
      "grad_norm": 1.3195449113845825,
      "learning_rate": 3.937903679845922e-05,
      "loss": 0.4804,
      "step": 791000
    },
    {
      "epoch": 8.373881146087518,
      "eval_loss": 0.3002985715866089,
      "eval_runtime": 46.8501,
      "eval_samples_per_second": 3584.411,
      "eval_steps_per_second": 448.067,
      "step": 791000
    },
    {
      "epoch": 8.374410467867522,
      "grad_norm": 1.2638455629348755,
      "learning_rate": 3.935415561300779e-05,
      "loss": 0.4961,
      "step": 791050
    },
    {
      "epoch": 8.374939789647524,
      "grad_norm": 1.372925043106079,
      "learning_rate": 3.932928161892818e-05,
      "loss": 0.4952,
      "step": 791100
    },
    {
      "epoch": 8.375469111427527,
      "grad_norm": 1.2622205018997192,
      "learning_rate": 3.93044148170697e-05,
      "loss": 0.4861,
      "step": 791150
    },
    {
      "epoch": 8.375998433207531,
      "grad_norm": 1.315721035003662,
      "learning_rate": 3.9279555208281166e-05,
      "loss": 0.4947,
      "step": 791200
    },
    {
      "epoch": 8.376527754987535,
      "grad_norm": 1.4199057817459106,
      "learning_rate": 3.92547027934114e-05,
      "loss": 0.4836,
      "step": 791250
    },
    {
      "epoch": 8.377057076767537,
      "grad_norm": 1.3471622467041016,
      "learning_rate": 3.922985757330871e-05,
      "loss": 0.4823,
      "step": 791300
    },
    {
      "epoch": 8.37758639854754,
      "grad_norm": 1.408880591392517,
      "learning_rate": 3.9205019548821466e-05,
      "loss": 0.4851,
      "step": 791350
    },
    {
      "epoch": 8.378115720327544,
      "grad_norm": 1.3039249181747437,
      "learning_rate": 3.918018872079748e-05,
      "loss": 0.4879,
      "step": 791400
    },
    {
      "epoch": 8.378645042107548,
      "grad_norm": 1.4112085103988647,
      "learning_rate": 3.91553650900846e-05,
      "loss": 0.4894,
      "step": 791450
    },
    {
      "epoch": 8.37917436388755,
      "grad_norm": 1.2924226522445679,
      "learning_rate": 3.9130548657530154e-05,
      "loss": 0.4863,
      "step": 791500
    },
    {
      "epoch": 8.37917436388755,
      "eval_loss": 0.3008610010147095,
      "eval_runtime": 46.8111,
      "eval_samples_per_second": 3587.398,
      "eval_steps_per_second": 448.441,
      "step": 791500
    },
    {
      "epoch": 8.379703685667554,
      "grad_norm": 1.2610355615615845,
      "learning_rate": 3.910573942398154e-05,
      "loss": 0.4929,
      "step": 791550
    },
    {
      "epoch": 8.380233007447558,
      "grad_norm": 1.5477302074432373,
      "learning_rate": 3.9080937390285536e-05,
      "loss": 0.4883,
      "step": 791600
    },
    {
      "epoch": 8.380762329227561,
      "grad_norm": 1.2473407983779907,
      "learning_rate": 3.9056142557289067e-05,
      "loss": 0.4903,
      "step": 791650
    },
    {
      "epoch": 8.381291651007563,
      "grad_norm": 1.3725658655166626,
      "learning_rate": 3.9031354925838454e-05,
      "loss": 0.4876,
      "step": 791700
    },
    {
      "epoch": 8.381820972787567,
      "grad_norm": 1.3372007608413696,
      "learning_rate": 3.9006574496780076e-05,
      "loss": 0.4866,
      "step": 791750
    },
    {
      "epoch": 8.382350294567571,
      "grad_norm": 1.3357701301574707,
      "learning_rate": 3.898180127095982e-05,
      "loss": 0.4845,
      "step": 791800
    },
    {
      "epoch": 8.382879616347573,
      "grad_norm": 1.2830779552459717,
      "learning_rate": 3.895703524922353e-05,
      "loss": 0.4857,
      "step": 791850
    },
    {
      "epoch": 8.383408938127577,
      "grad_norm": 1.3150718212127686,
      "learning_rate": 3.893227643241659e-05,
      "loss": 0.4936,
      "step": 791900
    },
    {
      "epoch": 8.38393825990758,
      "grad_norm": 1.3760240077972412,
      "learning_rate": 3.89075248213844e-05,
      "loss": 0.4906,
      "step": 791950
    },
    {
      "epoch": 8.384467581687584,
      "grad_norm": 1.223746418952942,
      "learning_rate": 3.888278041697183e-05,
      "loss": 0.4882,
      "step": 792000
    },
    {
      "epoch": 8.384467581687584,
      "eval_loss": 0.3001597821712494,
      "eval_runtime": 46.936,
      "eval_samples_per_second": 3577.854,
      "eval_steps_per_second": 447.248,
      "step": 792000
    },
    {
      "epoch": 8.384996903467586,
      "grad_norm": 1.3650072813034058,
      "learning_rate": 3.885804322002376e-05,
      "loss": 0.4899,
      "step": 792050
    },
    {
      "epoch": 8.38552622524759,
      "grad_norm": 1.2657737731933594,
      "learning_rate": 3.8833313231384616e-05,
      "loss": 0.4857,
      "step": 792100
    },
    {
      "epoch": 8.386055547027594,
      "grad_norm": 1.3303232192993164,
      "learning_rate": 3.880859045189872e-05,
      "loss": 0.485,
      "step": 792150
    },
    {
      "epoch": 8.386584868807597,
      "grad_norm": 1.360308289527893,
      "learning_rate": 3.878387488241014e-05,
      "loss": 0.4909,
      "step": 792200
    },
    {
      "epoch": 8.3871141905876,
      "grad_norm": 1.3917734622955322,
      "learning_rate": 3.8759660620263814e-05,
      "loss": 0.4863,
      "step": 792250
    },
    {
      "epoch": 8.387643512367603,
      "grad_norm": 1.3002870082855225,
      "learning_rate": 3.873495932905885e-05,
      "loss": 0.4892,
      "step": 792300
    },
    {
      "epoch": 8.388172834147607,
      "grad_norm": 1.2927569150924683,
      "learning_rate": 3.8710265250364974e-05,
      "loss": 0.4811,
      "step": 792350
    },
    {
      "epoch": 8.38870215592761,
      "grad_norm": 1.488910436630249,
      "learning_rate": 3.8685578385025095e-05,
      "loss": 0.4878,
      "step": 792400
    },
    {
      "epoch": 8.389231477707613,
      "grad_norm": 1.2543877363204956,
      "learning_rate": 3.8660898733882094e-05,
      "loss": 0.4928,
      "step": 792450
    },
    {
      "epoch": 8.389760799487616,
      "grad_norm": 1.4249361753463745,
      "learning_rate": 3.8636226297778463e-05,
      "loss": 0.4889,
      "step": 792500
    },
    {
      "epoch": 8.389760799487616,
      "eval_loss": 0.3002646565437317,
      "eval_runtime": 46.8341,
      "eval_samples_per_second": 3585.632,
      "eval_steps_per_second": 448.22,
      "step": 792500
    },
    {
      "epoch": 8.39029012126762,
      "grad_norm": 1.2802009582519531,
      "learning_rate": 3.861156107755664e-05,
      "loss": 0.4893,
      "step": 792550
    },
    {
      "epoch": 8.390819443047622,
      "grad_norm": 1.5132739543914795,
      "learning_rate": 3.858690307405851e-05,
      "loss": 0.4851,
      "step": 792600
    },
    {
      "epoch": 8.391348764827626,
      "grad_norm": 1.3612045049667358,
      "learning_rate": 3.856225228812604e-05,
      "loss": 0.4954,
      "step": 792650
    },
    {
      "epoch": 8.39187808660763,
      "grad_norm": 1.3685719966888428,
      "learning_rate": 3.8537608720600666e-05,
      "loss": 0.4846,
      "step": 792700
    },
    {
      "epoch": 8.392407408387633,
      "grad_norm": 1.4975999593734741,
      "learning_rate": 3.851297237232379e-05,
      "loss": 0.4871,
      "step": 792750
    },
    {
      "epoch": 8.392936730167635,
      "grad_norm": 1.3745671510696411,
      "learning_rate": 3.8488343244136525e-05,
      "loss": 0.4818,
      "step": 792800
    },
    {
      "epoch": 8.39346605194764,
      "grad_norm": 1.296475887298584,
      "learning_rate": 3.846372133687961e-05,
      "loss": 0.4991,
      "step": 792850
    },
    {
      "epoch": 8.393995373727643,
      "grad_norm": 1.2843985557556152,
      "learning_rate": 3.8439106651393665e-05,
      "loss": 0.4909,
      "step": 792900
    },
    {
      "epoch": 8.394524695507647,
      "grad_norm": 1.1795166730880737,
      "learning_rate": 3.841449918851908e-05,
      "loss": 0.4874,
      "step": 792950
    },
    {
      "epoch": 8.395054017287649,
      "grad_norm": 1.3207035064697266,
      "learning_rate": 3.8389898949095834e-05,
      "loss": 0.4869,
      "step": 793000
    },
    {
      "epoch": 8.395054017287649,
      "eval_loss": 0.300276517868042,
      "eval_runtime": 46.8644,
      "eval_samples_per_second": 3583.32,
      "eval_steps_per_second": 447.931,
      "step": 793000
    },
    {
      "epoch": 8.395583339067652,
      "grad_norm": 1.2450391054153442,
      "learning_rate": 3.8365305933963895e-05,
      "loss": 0.4827,
      "step": 793050
    },
    {
      "epoch": 8.396112660847656,
      "grad_norm": 1.2863119840621948,
      "learning_rate": 3.8340720143962755e-05,
      "loss": 0.4792,
      "step": 793100
    },
    {
      "epoch": 8.39664198262766,
      "grad_norm": 1.4689991474151611,
      "learning_rate": 3.831614157993185e-05,
      "loss": 0.4926,
      "step": 793150
    },
    {
      "epoch": 8.397171304407662,
      "grad_norm": 1.42630934715271,
      "learning_rate": 3.8291570242710185e-05,
      "loss": 0.4876,
      "step": 793200
    },
    {
      "epoch": 8.397700626187666,
      "grad_norm": 1.476650357246399,
      "learning_rate": 3.8267006133136714e-05,
      "loss": 0.4915,
      "step": 793250
    },
    {
      "epoch": 8.39822994796767,
      "grad_norm": 1.235971212387085,
      "learning_rate": 3.8242449252049946e-05,
      "loss": 0.4914,
      "step": 793300
    },
    {
      "epoch": 8.398759269747671,
      "grad_norm": 1.2772009372711182,
      "learning_rate": 3.8217899600288376e-05,
      "loss": 0.4854,
      "step": 793350
    },
    {
      "epoch": 8.399288591527675,
      "grad_norm": 1.3203712701797485,
      "learning_rate": 3.8193357178689964e-05,
      "loss": 0.4844,
      "step": 793400
    },
    {
      "epoch": 8.399817913307679,
      "grad_norm": 1.481662392616272,
      "learning_rate": 3.8168821988092736e-05,
      "loss": 0.4985,
      "step": 793450
    },
    {
      "epoch": 8.400347235087683,
      "grad_norm": 1.2638484239578247,
      "learning_rate": 3.81442940293342e-05,
      "loss": 0.4838,
      "step": 793500
    },
    {
      "epoch": 8.400347235087683,
      "eval_loss": 0.299599826335907,
      "eval_runtime": 46.7848,
      "eval_samples_per_second": 3589.413,
      "eval_steps_per_second": 448.693,
      "step": 793500
    },
    {
      "epoch": 8.400876556867685,
      "grad_norm": 1.3114509582519531,
      "learning_rate": 3.811977330325178e-05,
      "loss": 0.4827,
      "step": 793550
    },
    {
      "epoch": 8.401405878647688,
      "grad_norm": 1.3137444257736206,
      "learning_rate": 3.809525981068257e-05,
      "loss": 0.4896,
      "step": 793600
    },
    {
      "epoch": 8.401935200427692,
      "grad_norm": 1.5181955099105835,
      "learning_rate": 3.807075355246353e-05,
      "loss": 0.49,
      "step": 793650
    },
    {
      "epoch": 8.402464522207696,
      "grad_norm": 1.365001916885376,
      "learning_rate": 3.804625452943117e-05,
      "loss": 0.4867,
      "step": 793700
    },
    {
      "epoch": 8.402993843987698,
      "grad_norm": 1.3934376239776611,
      "learning_rate": 3.8021762742422025e-05,
      "loss": 0.4881,
      "step": 793750
    },
    {
      "epoch": 8.403523165767702,
      "grad_norm": 1.3683295249938965,
      "learning_rate": 3.7997278192272084e-05,
      "loss": 0.4933,
      "step": 793800
    },
    {
      "epoch": 8.404052487547705,
      "grad_norm": 1.4757155179977417,
      "learning_rate": 3.797280087981739e-05,
      "loss": 0.4858,
      "step": 793850
    },
    {
      "epoch": 8.40458180932771,
      "grad_norm": 1.4316222667694092,
      "learning_rate": 3.794833080589344e-05,
      "loss": 0.4814,
      "step": 793900
    },
    {
      "epoch": 8.405111131107711,
      "grad_norm": 1.3276753425598145,
      "learning_rate": 3.792386797133579e-05,
      "loss": 0.4868,
      "step": 793950
    },
    {
      "epoch": 8.405640452887715,
      "grad_norm": 1.2583976984024048,
      "learning_rate": 3.789941237697942e-05,
      "loss": 0.4789,
      "step": 794000
    },
    {
      "epoch": 8.405640452887715,
      "eval_loss": 0.2999368906021118,
      "eval_runtime": 46.7127,
      "eval_samples_per_second": 3594.951,
      "eval_steps_per_second": 449.385,
      "step": 794000
    },
    {
      "epoch": 8.406169774667719,
      "grad_norm": 1.3156434297561646,
      "learning_rate": 3.787496402365939e-05,
      "loss": 0.4844,
      "step": 794050
    },
    {
      "epoch": 8.40669909644772,
      "grad_norm": 1.3913172483444214,
      "learning_rate": 3.785052291221025e-05,
      "loss": 0.4943,
      "step": 794100
    },
    {
      "epoch": 8.407228418227724,
      "grad_norm": 1.419983148574829,
      "learning_rate": 3.7826089043466516e-05,
      "loss": 0.4822,
      "step": 794150
    },
    {
      "epoch": 8.407757740007728,
      "grad_norm": 1.2984545230865479,
      "learning_rate": 3.780166241826222e-05,
      "loss": 0.4843,
      "step": 794200
    },
    {
      "epoch": 8.408287061787732,
      "grad_norm": 1.438187599182129,
      "learning_rate": 3.777724303743141e-05,
      "loss": 0.4828,
      "step": 794250
    },
    {
      "epoch": 8.408816383567734,
      "grad_norm": 1.3215676546096802,
      "learning_rate": 3.7752830901807645e-05,
      "loss": 0.4849,
      "step": 794300
    },
    {
      "epoch": 8.409345705347738,
      "grad_norm": Infinity,
      "learning_rate": 3.772891403899947e-05,
      "loss": 0.4932,
      "step": 794350
    },
    {
      "epoch": 8.409875027127741,
      "grad_norm": 1.3566293716430664,
      "learning_rate": 3.770451625134433e-05,
      "loss": 0.4814,
      "step": 794400
    },
    {
      "epoch": 8.410404348907745,
      "grad_norm": 1.3721848726272583,
      "learning_rate": 3.7680125711379076e-05,
      "loss": 0.4763,
      "step": 794450
    },
    {
      "epoch": 8.410933670687747,
      "grad_norm": 1.2943676710128784,
      "learning_rate": 3.765574241993652e-05,
      "loss": 0.4912,
      "step": 794500
    },
    {
      "epoch": 8.410933670687747,
      "eval_loss": 0.29983025789260864,
      "eval_runtime": 46.9483,
      "eval_samples_per_second": 3576.91,
      "eval_steps_per_second": 447.13,
      "step": 794500
    },
    {
      "epoch": 8.41146299246775,
      "grad_norm": 1.3363412618637085,
      "learning_rate": 3.763136637784898e-05,
      "loss": 0.4857,
      "step": 794550
    },
    {
      "epoch": 8.411992314247755,
      "grad_norm": 1.4391037225723267,
      "learning_rate": 3.760699758594876e-05,
      "loss": 0.4862,
      "step": 794600
    },
    {
      "epoch": 8.412521636027758,
      "grad_norm": 1.093858242034912,
      "learning_rate": 3.758263604506773e-05,
      "loss": 0.4825,
      "step": 794650
    },
    {
      "epoch": 8.41305095780776,
      "grad_norm": 1.48432457447052,
      "learning_rate": 3.755828175603762e-05,
      "loss": 0.4936,
      "step": 794700
    },
    {
      "epoch": 8.413580279587764,
      "grad_norm": 1.4900548458099365,
      "learning_rate": 3.753393471968983e-05,
      "loss": 0.4892,
      "step": 794750
    },
    {
      "epoch": 8.414109601367768,
      "grad_norm": 1.441998839378357,
      "learning_rate": 3.7509594936855575e-05,
      "loss": 0.4884,
      "step": 794800
    },
    {
      "epoch": 8.414638923147772,
      "grad_norm": 1.4052873849868774,
      "learning_rate": 3.748526240836589e-05,
      "loss": 0.483,
      "step": 794850
    },
    {
      "epoch": 8.415168244927774,
      "grad_norm": 1.3539739847183228,
      "learning_rate": 3.746093713505133e-05,
      "loss": 0.483,
      "step": 794900
    },
    {
      "epoch": 8.415697566707777,
      "grad_norm": 1.313504934310913,
      "learning_rate": 3.743661911774243e-05,
      "loss": 0.4833,
      "step": 794950
    },
    {
      "epoch": 8.416226888487781,
      "grad_norm": 1.4317983388900757,
      "learning_rate": 3.741230835726947e-05,
      "loss": 0.498,
      "step": 795000
    },
    {
      "epoch": 8.416226888487781,
      "eval_loss": 0.30004948377609253,
      "eval_runtime": 46.7341,
      "eval_samples_per_second": 3593.309,
      "eval_steps_per_second": 449.18,
      "step": 795000
    },
    {
      "epoch": 8.416756210267783,
      "grad_norm": 1.3840161561965942,
      "learning_rate": 3.738800485446228e-05,
      "loss": 0.4905,
      "step": 795050
    },
    {
      "epoch": 8.417285532047787,
      "grad_norm": 1.3635047674179077,
      "learning_rate": 3.7363708610150674e-05,
      "loss": 0.4863,
      "step": 795100
    },
    {
      "epoch": 8.41781485382779,
      "grad_norm": 1.2836499214172363,
      "learning_rate": 3.7339419625164046e-05,
      "loss": 0.4881,
      "step": 795150
    },
    {
      "epoch": 8.418344175607794,
      "grad_norm": 1.342373251914978,
      "learning_rate": 3.731513790033167e-05,
      "loss": 0.4773,
      "step": 795200
    },
    {
      "epoch": 8.418873497387796,
      "grad_norm": 1.3177655935287476,
      "learning_rate": 3.729086343648244e-05,
      "loss": 0.4809,
      "step": 795250
    },
    {
      "epoch": 8.4194028191678,
      "grad_norm": 1.439531922340393,
      "learning_rate": 3.72665962344452e-05,
      "loss": 0.4877,
      "step": 795300
    },
    {
      "epoch": 8.419932140947804,
      "grad_norm": 1.3806066513061523,
      "learning_rate": 3.724233629504825e-05,
      "loss": 0.4905,
      "step": 795350
    },
    {
      "epoch": 8.420461462727808,
      "grad_norm": 1.3379526138305664,
      "learning_rate": 3.721808361911999e-05,
      "loss": 0.4868,
      "step": 795400
    },
    {
      "epoch": 8.42099078450781,
      "grad_norm": 1.25809645652771,
      "learning_rate": 3.7193838207488256e-05,
      "loss": 0.4795,
      "step": 795450
    },
    {
      "epoch": 8.421520106287813,
      "grad_norm": 1.335033893585205,
      "learning_rate": 3.7169600060980915e-05,
      "loss": 0.4782,
      "step": 795500
    },
    {
      "epoch": 8.421520106287813,
      "eval_loss": 0.29962989687919617,
      "eval_runtime": 46.9658,
      "eval_samples_per_second": 3575.583,
      "eval_steps_per_second": 446.964,
      "step": 795500
    },
    {
      "epoch": 8.422049428067817,
      "grad_norm": 1.451850414276123,
      "learning_rate": 3.7145369180425296e-05,
      "loss": 0.4941,
      "step": 795550
    },
    {
      "epoch": 8.42257874984782,
      "grad_norm": 1.2669155597686768,
      "learning_rate": 3.712114556664878e-05,
      "loss": 0.487,
      "step": 795600
    },
    {
      "epoch": 8.423108071627823,
      "grad_norm": 1.521254301071167,
      "learning_rate": 3.709692922047822e-05,
      "loss": 0.483,
      "step": 795650
    },
    {
      "epoch": 8.423637393407827,
      "grad_norm": 1.4769102334976196,
      "learning_rate": 3.707272014274049e-05,
      "loss": 0.4815,
      "step": 795700
    },
    {
      "epoch": 8.42416671518783,
      "grad_norm": 1.2730393409729004,
      "learning_rate": 3.704851833426193e-05,
      "loss": 0.4874,
      "step": 795750
    },
    {
      "epoch": 8.424696036967832,
      "grad_norm": 1.2666224241256714,
      "learning_rate": 3.7024323795868925e-05,
      "loss": 0.4815,
      "step": 795800
    },
    {
      "epoch": 8.425225358747836,
      "grad_norm": 1.378875970840454,
      "learning_rate": 3.700013652838735e-05,
      "loss": 0.4954,
      "step": 795850
    },
    {
      "epoch": 8.42575468052784,
      "grad_norm": 1.4401791095733643,
      "learning_rate": 3.697595653264305e-05,
      "loss": 0.4834,
      "step": 795900
    },
    {
      "epoch": 8.426284002307844,
      "grad_norm": 1.4124163389205933,
      "learning_rate": 3.695178380946138e-05,
      "loss": 0.4759,
      "step": 795950
    },
    {
      "epoch": 8.426813324087846,
      "grad_norm": 1.4115108251571655,
      "learning_rate": 3.6927618359667765e-05,
      "loss": 0.4891,
      "step": 796000
    },
    {
      "epoch": 8.426813324087846,
      "eval_loss": 0.2996903955936432,
      "eval_runtime": 46.8373,
      "eval_samples_per_second": 3585.393,
      "eval_steps_per_second": 448.19,
      "step": 796000
    },
    {
      "epoch": 8.42734264586785,
      "grad_norm": 1.330263376235962,
      "learning_rate": 3.690346018408705e-05,
      "loss": 0.4938,
      "step": 796050
    },
    {
      "epoch": 8.427871967647853,
      "grad_norm": 1.300674557685852,
      "learning_rate": 3.687930928354413e-05,
      "loss": 0.4926,
      "step": 796100
    },
    {
      "epoch": 8.428401289427857,
      "grad_norm": 1.3764972686767578,
      "learning_rate": 3.685516565886335e-05,
      "loss": 0.486,
      "step": 796150
    },
    {
      "epoch": 8.428930611207859,
      "grad_norm": 1.3417803049087524,
      "learning_rate": 3.683102931086912e-05,
      "loss": 0.4916,
      "step": 796200
    },
    {
      "epoch": 8.429459932987863,
      "grad_norm": 1.3676401376724243,
      "learning_rate": 3.68069002403853e-05,
      "loss": 0.4843,
      "step": 796250
    },
    {
      "epoch": 8.429989254767866,
      "grad_norm": 1.27448570728302,
      "learning_rate": 3.678277844823577e-05,
      "loss": 0.4864,
      "step": 796300
    },
    {
      "epoch": 8.43051857654787,
      "grad_norm": 1.425707221031189,
      "learning_rate": 3.6758663935243964e-05,
      "loss": 0.4944,
      "step": 796350
    },
    {
      "epoch": 8.431047898327872,
      "grad_norm": 1.4082636833190918,
      "learning_rate": 3.673455670223319e-05,
      "loss": 0.486,
      "step": 796400
    },
    {
      "epoch": 8.431577220107876,
      "grad_norm": 1.359809398651123,
      "learning_rate": 3.6710456750026404e-05,
      "loss": 0.4893,
      "step": 796450
    },
    {
      "epoch": 8.43210654188788,
      "grad_norm": 1.3909761905670166,
      "learning_rate": 3.6686364079446395e-05,
      "loss": 0.4855,
      "step": 796500
    },
    {
      "epoch": 8.43210654188788,
      "eval_loss": 0.29963913559913635,
      "eval_runtime": 46.8711,
      "eval_samples_per_second": 3582.801,
      "eval_steps_per_second": 447.866,
      "step": 796500
    },
    {
      "epoch": 8.432635863667882,
      "grad_norm": 1.2963783740997314,
      "learning_rate": 3.666227869131575e-05,
      "loss": 0.4878,
      "step": 796550
    },
    {
      "epoch": 8.433165185447885,
      "grad_norm": 1.4574345350265503,
      "learning_rate": 3.663820058645659e-05,
      "loss": 0.4858,
      "step": 796600
    },
    {
      "epoch": 8.433694507227889,
      "grad_norm": 1.3627537488937378,
      "learning_rate": 3.661412976569104e-05,
      "loss": 0.4894,
      "step": 796650
    },
    {
      "epoch": 8.434223829007893,
      "grad_norm": 1.5457496643066406,
      "learning_rate": 3.659006622984087e-05,
      "loss": 0.488,
      "step": 796700
    },
    {
      "epoch": 8.434753150787895,
      "grad_norm": 1.4410202503204346,
      "learning_rate": 3.656600997972756e-05,
      "loss": 0.5004,
      "step": 796750
    },
    {
      "epoch": 8.435282472567899,
      "grad_norm": 1.4411441087722778,
      "learning_rate": 3.654196101617241e-05,
      "loss": 0.4817,
      "step": 796800
    },
    {
      "epoch": 8.435811794347902,
      "grad_norm": 1.2009003162384033,
      "learning_rate": 3.65179193399964e-05,
      "loss": 0.4861,
      "step": 796850
    },
    {
      "epoch": 8.436341116127906,
      "grad_norm": 1.4885199069976807,
      "learning_rate": 3.6493884952020387e-05,
      "loss": 0.4802,
      "step": 796900
    },
    {
      "epoch": 8.436870437907908,
      "grad_norm": 1.477495789527893,
      "learning_rate": 3.6469857853064754e-05,
      "loss": 0.4873,
      "step": 796950
    },
    {
      "epoch": 8.437399759687912,
      "grad_norm": 1.5339044332504272,
      "learning_rate": 3.644583804394994e-05,
      "loss": 0.483,
      "step": 797000
    },
    {
      "epoch": 8.437399759687912,
      "eval_loss": 0.2994997501373291,
      "eval_runtime": 46.8094,
      "eval_samples_per_second": 3587.53,
      "eval_steps_per_second": 448.457,
      "step": 797000
    },
    {
      "epoch": 8.437929081467916,
      "grad_norm": 1.4750498533248901,
      "learning_rate": 3.642182552549583e-05,
      "loss": 0.4903,
      "step": 797050
    },
    {
      "epoch": 8.43845840324792,
      "grad_norm": 1.355675220489502,
      "learning_rate": 3.639782029852234e-05,
      "loss": 0.4838,
      "step": 797100
    },
    {
      "epoch": 8.438987725027921,
      "grad_norm": 1.462557077407837,
      "learning_rate": 3.637382236384887e-05,
      "loss": 0.496,
      "step": 797150
    },
    {
      "epoch": 8.439517046807925,
      "grad_norm": 1.377186894416809,
      "learning_rate": 3.634983172229481e-05,
      "loss": 0.4918,
      "step": 797200
    },
    {
      "epoch": 8.440046368587929,
      "grad_norm": 1.2194093465805054,
      "learning_rate": 3.632584837467909e-05,
      "loss": 0.4906,
      "step": 797250
    },
    {
      "epoch": 8.44057569036793,
      "grad_norm": 1.4208049774169922,
      "learning_rate": 3.630235177138383e-05,
      "loss": 0.4892,
      "step": 797300
    },
    {
      "epoch": 8.441105012147935,
      "grad_norm": 1.3584232330322266,
      "learning_rate": 3.627838286818144e-05,
      "loss": 0.4921,
      "step": 797350
    },
    {
      "epoch": 8.441634333927938,
      "grad_norm": 1.506188154220581,
      "learning_rate": 3.625442126135675e-05,
      "loss": 0.4935,
      "step": 797400
    },
    {
      "epoch": 8.442163655707942,
      "grad_norm": 1.4474165439605713,
      "learning_rate": 3.623046695172769e-05,
      "loss": 0.4841,
      "step": 797450
    },
    {
      "epoch": 8.442692977487944,
      "grad_norm": 1.3304836750030518,
      "learning_rate": 3.620651994011212e-05,
      "loss": 0.4848,
      "step": 797500
    },
    {
      "epoch": 8.442692977487944,
      "eval_loss": 0.29863953590393066,
      "eval_runtime": 46.7146,
      "eval_samples_per_second": 3594.809,
      "eval_steps_per_second": 449.367,
      "step": 797500
    },
    {
      "epoch": 8.443222299267948,
      "grad_norm": 1.520137071609497,
      "learning_rate": 3.618258022732751e-05,
      "loss": 0.487,
      "step": 797550
    },
    {
      "epoch": 8.443751621047952,
      "grad_norm": 1.425426959991455,
      "learning_rate": 3.615864781419123e-05,
      "loss": 0.4779,
      "step": 797600
    },
    {
      "epoch": 8.444280942827955,
      "grad_norm": 1.3259823322296143,
      "learning_rate": 3.613472270152027e-05,
      "loss": 0.4947,
      "step": 797650
    },
    {
      "epoch": 8.444810264607957,
      "grad_norm": 1.3115867376327515,
      "learning_rate": 3.6110804890131465e-05,
      "loss": 0.4798,
      "step": 797700
    },
    {
      "epoch": 8.445339586387961,
      "grad_norm": 1.3591667413711548,
      "learning_rate": 3.608689438084131e-05,
      "loss": 0.4938,
      "step": 797750
    },
    {
      "epoch": 8.445868908167965,
      "grad_norm": 1.464756965637207,
      "learning_rate": 3.606299117446618e-05,
      "loss": 0.4847,
      "step": 797800
    },
    {
      "epoch": 8.446398229947969,
      "grad_norm": 1.506485939025879,
      "learning_rate": 3.6039095271822005e-05,
      "loss": 0.4868,
      "step": 797850
    },
    {
      "epoch": 8.44692755172797,
      "grad_norm": 1.2350530624389648,
      "learning_rate": 3.601520667372471e-05,
      "loss": 0.4899,
      "step": 797900
    },
    {
      "epoch": 8.447456873507974,
      "grad_norm": 1.423343539237976,
      "learning_rate": 3.599132538098973e-05,
      "loss": 0.4892,
      "step": 797950
    },
    {
      "epoch": 8.447986195287978,
      "grad_norm": 1.3343815803527832,
      "learning_rate": 3.596745139443247e-05,
      "loss": 0.4906,
      "step": 798000
    },
    {
      "epoch": 8.447986195287978,
      "eval_loss": 0.2996213734149933,
      "eval_runtime": 46.8972,
      "eval_samples_per_second": 3580.812,
      "eval_steps_per_second": 447.618,
      "step": 798000
    },
    {
      "epoch": 8.44851551706798,
      "grad_norm": 1.3607721328735352,
      "learning_rate": 3.594358471486786e-05,
      "loss": 0.4883,
      "step": 798050
    },
    {
      "epoch": 8.449044838847984,
      "grad_norm": 1.3986380100250244,
      "learning_rate": 3.591972534311083e-05,
      "loss": 0.4916,
      "step": 798100
    },
    {
      "epoch": 8.449574160627987,
      "grad_norm": 1.4229892492294312,
      "learning_rate": 3.589587327997581e-05,
      "loss": 0.4778,
      "step": 798150
    },
    {
      "epoch": 8.450103482407991,
      "grad_norm": 1.3400216102600098,
      "learning_rate": 3.587202852627722e-05,
      "loss": 0.485,
      "step": 798200
    },
    {
      "epoch": 8.450632804187993,
      "grad_norm": 1.3994380235671997,
      "learning_rate": 3.5848191082828996e-05,
      "loss": 0.4959,
      "step": 798250
    },
    {
      "epoch": 8.451162125967997,
      "grad_norm": 1.3651067018508911,
      "learning_rate": 3.582436095044503e-05,
      "loss": 0.491,
      "step": 798300
    },
    {
      "epoch": 8.451691447748,
      "grad_norm": 1.3605326414108276,
      "learning_rate": 3.580053812993878e-05,
      "loss": 0.484,
      "step": 798350
    },
    {
      "epoch": 8.452220769528004,
      "grad_norm": 1.2929699420928955,
      "learning_rate": 3.577672262212367e-05,
      "loss": 0.4781,
      "step": 798400
    },
    {
      "epoch": 8.452750091308006,
      "grad_norm": 1.4549237489700317,
      "learning_rate": 3.575291442781262e-05,
      "loss": 0.4826,
      "step": 798450
    },
    {
      "epoch": 8.45327941308801,
      "grad_norm": 1.2740060091018677,
      "learning_rate": 3.572911354781855e-05,
      "loss": 0.4919,
      "step": 798500
    },
    {
      "epoch": 8.45327941308801,
      "eval_loss": 0.2994670867919922,
      "eval_runtime": 46.8012,
      "eval_samples_per_second": 3588.157,
      "eval_steps_per_second": 448.536,
      "step": 798500
    },
    {
      "epoch": 8.453808734868014,
      "grad_norm": 1.382791519165039,
      "learning_rate": 3.5705319982953895e-05,
      "loss": 0.4913,
      "step": 798550
    },
    {
      "epoch": 8.454338056648018,
      "grad_norm": 1.357172966003418,
      "learning_rate": 3.56815337340311e-05,
      "loss": 0.488,
      "step": 798600
    },
    {
      "epoch": 8.45486737842802,
      "grad_norm": 1.264844298362732,
      "learning_rate": 3.565775480186209e-05,
      "loss": 0.4834,
      "step": 798650
    },
    {
      "epoch": 8.455396700208023,
      "grad_norm": 1.3249285221099854,
      "learning_rate": 3.5633983187258715e-05,
      "loss": 0.4841,
      "step": 798700
    },
    {
      "epoch": 8.455926021988027,
      "grad_norm": 1.3022946119308472,
      "learning_rate": 3.561021889103261e-05,
      "loss": 0.4844,
      "step": 798750
    },
    {
      "epoch": 8.45645534376803,
      "grad_norm": 1.3694769144058228,
      "learning_rate": 3.558646191399492e-05,
      "loss": 0.4833,
      "step": 798800
    },
    {
      "epoch": 8.456984665548033,
      "grad_norm": 1.3820140361785889,
      "learning_rate": 3.556271225695681e-05,
      "loss": 0.4967,
      "step": 798850
    },
    {
      "epoch": 8.457513987328037,
      "grad_norm": 1.284680724143982,
      "learning_rate": 3.553896992072911e-05,
      "loss": 0.4882,
      "step": 798900
    },
    {
      "epoch": 8.45804330910804,
      "grad_norm": 1.3688093423843384,
      "learning_rate": 3.5515234906122265e-05,
      "loss": 0.4851,
      "step": 798950
    },
    {
      "epoch": 8.458572630888042,
      "grad_norm": 1.3874062299728394,
      "learning_rate": 3.549150721394673e-05,
      "loss": 0.479,
      "step": 799000
    },
    {
      "epoch": 8.458572630888042,
      "eval_loss": 0.29852771759033203,
      "eval_runtime": 47.113,
      "eval_samples_per_second": 3564.407,
      "eval_steps_per_second": 445.567,
      "step": 799000
    },
    {
      "epoch": 8.459101952668046,
      "grad_norm": 1.2364810705184937,
      "learning_rate": 3.546778684501237e-05,
      "loss": 0.4905,
      "step": 799050
    },
    {
      "epoch": 8.45963127444805,
      "grad_norm": 1.3162245750427246,
      "learning_rate": 3.544407380012915e-05,
      "loss": 0.4852,
      "step": 799100
    },
    {
      "epoch": 8.460160596228054,
      "grad_norm": 1.4594647884368896,
      "learning_rate": 3.542036808010654e-05,
      "loss": 0.4899,
      "step": 799150
    },
    {
      "epoch": 8.460689918008056,
      "grad_norm": 1.3027966022491455,
      "learning_rate": 3.539666968575389e-05,
      "loss": 0.486,
      "step": 799200
    },
    {
      "epoch": 8.46121923978806,
      "grad_norm": 1.2311116456985474,
      "learning_rate": 3.537297861788019e-05,
      "loss": 0.4905,
      "step": 799250
    },
    {
      "epoch": 8.461748561568063,
      "grad_norm": 1.2657455205917358,
      "learning_rate": 3.534929487729435e-05,
      "loss": 0.4751,
      "step": 799300
    },
    {
      "epoch": 8.462277883348067,
      "grad_norm": 1.3288216590881348,
      "learning_rate": 3.532561846480481e-05,
      "loss": 0.4801,
      "step": 799350
    },
    {
      "epoch": 8.462807205128069,
      "grad_norm": 1.2703454494476318,
      "learning_rate": 3.530242269106315e-05,
      "loss": 0.4893,
      "step": 799400
    },
    {
      "epoch": 8.463336526908073,
      "grad_norm": 1.2285516262054443,
      "learning_rate": 3.5278760790588836e-05,
      "loss": 0.4782,
      "step": 799450
    },
    {
      "epoch": 8.463865848688076,
      "grad_norm": 1.3443955183029175,
      "learning_rate": 3.5255106220618835e-05,
      "loss": 0.4825,
      "step": 799500
    },
    {
      "epoch": 8.463865848688076,
      "eval_loss": 0.29877614974975586,
      "eval_runtime": 46.8926,
      "eval_samples_per_second": 3581.159,
      "eval_steps_per_second": 447.661,
      "step": 799500
    },
    {
      "epoch": 8.464395170468078,
      "grad_norm": 1.413205862045288,
      "learning_rate": 3.523145898196084e-05,
      "loss": 0.4871,
      "step": 799550
    },
    {
      "epoch": 8.464924492248082,
      "grad_norm": 1.3277533054351807,
      "learning_rate": 3.520781907542198e-05,
      "loss": 0.4846,
      "step": 799600
    },
    {
      "epoch": 8.465453814028086,
      "grad_norm": 1.4877458810806274,
      "learning_rate": 3.518418650180946e-05,
      "loss": 0.4856,
      "step": 799650
    },
    {
      "epoch": 8.46598313580809,
      "grad_norm": 1.2703622579574585,
      "learning_rate": 3.516056126192999e-05,
      "loss": 0.4775,
      "step": 799700
    },
    {
      "epoch": 8.466512457588092,
      "grad_norm": 1.4938428401947021,
      "learning_rate": 3.5136943356590235e-05,
      "loss": 0.489,
      "step": 799750
    },
    {
      "epoch": 8.467041779368095,
      "grad_norm": 1.2368227243423462,
      "learning_rate": 3.511333278659637e-05,
      "loss": 0.4949,
      "step": 799800
    },
    {
      "epoch": 8.4675711011481,
      "grad_norm": 1.3231678009033203,
      "learning_rate": 3.508972955275455e-05,
      "loss": 0.489,
      "step": 799850
    },
    {
      "epoch": 8.468100422928103,
      "grad_norm": 1.4389564990997314,
      "learning_rate": 3.506613365587052e-05,
      "loss": 0.4855,
      "step": 799900
    },
    {
      "epoch": 8.468629744708105,
      "grad_norm": 1.392901062965393,
      "learning_rate": 3.50425450967499e-05,
      "loss": 0.484,
      "step": 799950
    },
    {
      "epoch": 8.469159066488109,
      "grad_norm": 1.4849936962127686,
      "learning_rate": 3.501896387619791e-05,
      "loss": 0.4858,
      "step": 800000
    },
    {
      "epoch": 8.469159066488109,
      "eval_loss": 0.29876917600631714,
      "eval_runtime": 46.8627,
      "eval_samples_per_second": 3583.45,
      "eval_steps_per_second": 447.947,
      "step": 800000
    },
    {
      "epoch": 8.469688388268112,
      "grad_norm": 1.244937539100647,
      "learning_rate": 3.49953899950197e-05,
      "loss": 0.4904,
      "step": 800050
    },
    {
      "epoch": 8.470217710048116,
      "grad_norm": 1.385922908782959,
      "learning_rate": 3.497182345401997e-05,
      "loss": 0.4832,
      "step": 800100
    },
    {
      "epoch": 8.470747031828118,
      "grad_norm": 1.198610782623291,
      "learning_rate": 3.494826425400338e-05,
      "loss": 0.4889,
      "step": 800150
    },
    {
      "epoch": 8.471276353608122,
      "grad_norm": 1.335637092590332,
      "learning_rate": 3.492471239577413e-05,
      "loss": 0.4848,
      "step": 800200
    },
    {
      "epoch": 8.471805675388126,
      "grad_norm": 1.392805814743042,
      "learning_rate": 3.490116788013639e-05,
      "loss": 0.483,
      "step": 800250
    },
    {
      "epoch": 8.472334997168128,
      "grad_norm": 1.279203176498413,
      "learning_rate": 3.487763070789382e-05,
      "loss": 0.4808,
      "step": 800300
    },
    {
      "epoch": 8.472864318948131,
      "grad_norm": 1.389248251914978,
      "learning_rate": 3.485410087985011e-05,
      "loss": 0.4849,
      "step": 800350
    },
    {
      "epoch": 8.473393640728135,
      "grad_norm": 1.3351852893829346,
      "learning_rate": 3.483057839680845e-05,
      "loss": 0.4856,
      "step": 800400
    },
    {
      "epoch": 8.473922962508139,
      "grad_norm": 1.3176169395446777,
      "learning_rate": 3.4807063259571945e-05,
      "loss": 0.4841,
      "step": 800450
    },
    {
      "epoch": 8.474452284288141,
      "grad_norm": 1.2947022914886475,
      "learning_rate": 3.478355546894338e-05,
      "loss": 0.486,
      "step": 800500
    },
    {
      "epoch": 8.474452284288141,
      "eval_loss": 0.2989251911640167,
      "eval_runtime": 46.7726,
      "eval_samples_per_second": 3590.347,
      "eval_steps_per_second": 448.809,
      "step": 800500
    },
    {
      "epoch": 8.474981606068145,
      "grad_norm": 1.3599005937576294,
      "learning_rate": 3.476005502572532e-05,
      "loss": 0.4751,
      "step": 800550
    },
    {
      "epoch": 8.475510927848148,
      "grad_norm": 1.4645692110061646,
      "learning_rate": 3.473656193072e-05,
      "loss": 0.4833,
      "step": 800600
    },
    {
      "epoch": 8.476040249628152,
      "grad_norm": 1.494388461112976,
      "learning_rate": 3.471307618472958e-05,
      "loss": 0.4798,
      "step": 800650
    },
    {
      "epoch": 8.476569571408154,
      "grad_norm": 1.3569837808609009,
      "learning_rate": 3.468959778855568e-05,
      "loss": 0.4826,
      "step": 800700
    },
    {
      "epoch": 8.477098893188158,
      "grad_norm": 1.5196605920791626,
      "learning_rate": 3.466612674299999e-05,
      "loss": 0.4832,
      "step": 800750
    },
    {
      "epoch": 8.477628214968162,
      "grad_norm": 1.3186880350112915,
      "learning_rate": 3.464266304886382e-05,
      "loss": 0.4866,
      "step": 800800
    },
    {
      "epoch": 8.478157536748165,
      "grad_norm": 1.6079800128936768,
      "learning_rate": 3.4619206706948096e-05,
      "loss": 0.4862,
      "step": 800850
    },
    {
      "epoch": 8.478686858528167,
      "grad_norm": 1.3906996250152588,
      "learning_rate": 3.459575771805365e-05,
      "loss": 0.482,
      "step": 800900
    },
    {
      "epoch": 8.479216180308171,
      "grad_norm": 1.1676926612854004,
      "learning_rate": 3.457231608298111e-05,
      "loss": 0.4842,
      "step": 800950
    },
    {
      "epoch": 8.479745502088175,
      "grad_norm": 1.4257128238677979,
      "learning_rate": 3.454888180253063e-05,
      "loss": 0.4953,
      "step": 801000
    },
    {
      "epoch": 8.479745502088175,
      "eval_loss": 0.29910966753959656,
      "eval_runtime": 46.8505,
      "eval_samples_per_second": 3584.377,
      "eval_steps_per_second": 448.063,
      "step": 801000
    },
    {
      "epoch": 8.480274823868177,
      "grad_norm": 1.3504881858825684,
      "learning_rate": 3.452545487750236e-05,
      "loss": 0.4879,
      "step": 801050
    },
    {
      "epoch": 8.48080414564818,
      "grad_norm": 1.3074759244918823,
      "learning_rate": 3.450203530869597e-05,
      "loss": 0.4874,
      "step": 801100
    },
    {
      "epoch": 8.481333467428184,
      "grad_norm": 1.283913016319275,
      "learning_rate": 3.447862309691116e-05,
      "loss": 0.4806,
      "step": 801150
    },
    {
      "epoch": 8.481862789208188,
      "grad_norm": 1.1898090839385986,
      "learning_rate": 3.445521824294703e-05,
      "loss": 0.4873,
      "step": 801200
    },
    {
      "epoch": 8.48239211098819,
      "grad_norm": 1.3444013595581055,
      "learning_rate": 3.443182074760276e-05,
      "loss": 0.4866,
      "step": 801250
    },
    {
      "epoch": 8.482921432768194,
      "grad_norm": 1.4102370738983154,
      "learning_rate": 3.440843061167703e-05,
      "loss": 0.4857,
      "step": 801300
    },
    {
      "epoch": 8.483450754548198,
      "grad_norm": 1.4702869653701782,
      "learning_rate": 3.4385047835968466e-05,
      "loss": 0.4966,
      "step": 801350
    },
    {
      "epoch": 8.483980076328201,
      "grad_norm": 1.3430094718933105,
      "learning_rate": 3.436167242127522e-05,
      "loss": 0.4875,
      "step": 801400
    },
    {
      "epoch": 8.484509398108203,
      "grad_norm": 1.3237656354904175,
      "learning_rate": 3.4338304368395466e-05,
      "loss": 0.4816,
      "step": 801450
    },
    {
      "epoch": 8.485038719888207,
      "grad_norm": 1.4207419157028198,
      "learning_rate": 3.431494367812685e-05,
      "loss": 0.4849,
      "step": 801500
    },
    {
      "epoch": 8.485038719888207,
      "eval_loss": 0.2983971834182739,
      "eval_runtime": 46.8899,
      "eval_samples_per_second": 3581.368,
      "eval_steps_per_second": 447.687,
      "step": 801500
    },
    {
      "epoch": 8.48556804166821,
      "grad_norm": 1.5833944082260132,
      "learning_rate": 3.4291590351267e-05,
      "loss": 0.4822,
      "step": 801550
    },
    {
      "epoch": 8.486097363448215,
      "grad_norm": 1.3295843601226807,
      "learning_rate": 3.426824438861312e-05,
      "loss": 0.4869,
      "step": 801600
    },
    {
      "epoch": 8.486626685228217,
      "grad_norm": 1.402803897857666,
      "learning_rate": 3.424490579096229e-05,
      "loss": 0.4912,
      "step": 801650
    },
    {
      "epoch": 8.48715600700822,
      "grad_norm": 1.4858745336532593,
      "learning_rate": 3.422157455911121e-05,
      "loss": 0.4802,
      "step": 801700
    },
    {
      "epoch": 8.487685328788224,
      "grad_norm": 1.3865830898284912,
      "learning_rate": 3.419825069385649e-05,
      "loss": 0.4942,
      "step": 801750
    },
    {
      "epoch": 8.488214650568226,
      "grad_norm": 1.3858338594436646,
      "learning_rate": 3.417493419599429e-05,
      "loss": 0.4911,
      "step": 801800
    },
    {
      "epoch": 8.48874397234823,
      "grad_norm": 1.2717063426971436,
      "learning_rate": 3.4151625066320744e-05,
      "loss": 0.4882,
      "step": 801850
    },
    {
      "epoch": 8.489273294128234,
      "grad_norm": 1.2806453704833984,
      "learning_rate": 3.412832330563148e-05,
      "loss": 0.4864,
      "step": 801900
    },
    {
      "epoch": 8.489802615908237,
      "grad_norm": 1.3393369913101196,
      "learning_rate": 3.410502891472217e-05,
      "loss": 0.4846,
      "step": 801950
    },
    {
      "epoch": 8.49033193768824,
      "grad_norm": 1.4574085474014282,
      "learning_rate": 3.408174189438795e-05,
      "loss": 0.4873,
      "step": 802000
    },
    {
      "epoch": 8.49033193768824,
      "eval_loss": 0.2981513738632202,
      "eval_runtime": 46.8159,
      "eval_samples_per_second": 3587.028,
      "eval_steps_per_second": 448.395,
      "step": 802000
    },
    {
      "epoch": 8.490861259468243,
      "grad_norm": 1.3052126169204712,
      "learning_rate": 3.4058462245423916e-05,
      "loss": 0.4921,
      "step": 802050
    },
    {
      "epoch": 8.491390581248247,
      "grad_norm": 1.4934930801391602,
      "learning_rate": 3.403518996862473e-05,
      "loss": 0.4819,
      "step": 802100
    },
    {
      "epoch": 8.49191990302825,
      "grad_norm": 1.4358361959457397,
      "learning_rate": 3.401192506478501e-05,
      "loss": 0.4823,
      "step": 802150
    },
    {
      "epoch": 8.492449224808253,
      "grad_norm": 1.3865039348602295,
      "learning_rate": 3.39886675346989e-05,
      "loss": 0.4915,
      "step": 802200
    },
    {
      "epoch": 8.492978546588256,
      "grad_norm": 1.2869157791137695,
      "learning_rate": 3.3965417379160534e-05,
      "loss": 0.4792,
      "step": 802250
    },
    {
      "epoch": 8.49350786836826,
      "grad_norm": 1.5091509819030762,
      "learning_rate": 3.3942639382283976e-05,
      "loss": 0.4833,
      "step": 802300
    },
    {
      "epoch": 8.494037190148264,
      "grad_norm": 1.30350661277771,
      "learning_rate": 3.391940383069142e-05,
      "loss": 0.4823,
      "step": 802350
    },
    {
      "epoch": 8.494566511928266,
      "grad_norm": 1.3850395679473877,
      "learning_rate": 3.3896175656011216e-05,
      "loss": 0.4829,
      "step": 802400
    },
    {
      "epoch": 8.49509583370827,
      "grad_norm": 1.368708610534668,
      "learning_rate": 3.387295485903627e-05,
      "loss": 0.4751,
      "step": 802450
    },
    {
      "epoch": 8.495625155488273,
      "grad_norm": 1.3441044092178345,
      "learning_rate": 3.384974144055944e-05,
      "loss": 0.4903,
      "step": 802500
    },
    {
      "epoch": 8.495625155488273,
      "eval_loss": 0.2982339560985565,
      "eval_runtime": 46.9543,
      "eval_samples_per_second": 3576.459,
      "eval_steps_per_second": 447.073,
      "step": 802500
    },
    {
      "epoch": 8.496154477268275,
      "grad_norm": 1.264310598373413,
      "learning_rate": 3.382653540137312e-05,
      "loss": 0.4835,
      "step": 802550
    },
    {
      "epoch": 8.496683799048279,
      "grad_norm": 1.3006930351257324,
      "learning_rate": 3.380333674226965e-05,
      "loss": 0.4783,
      "step": 802600
    },
    {
      "epoch": 8.497213120828283,
      "grad_norm": 1.487249493598938,
      "learning_rate": 3.37801454640409e-05,
      "loss": 0.4823,
      "step": 802650
    },
    {
      "epoch": 8.497742442608287,
      "grad_norm": 1.2999293804168701,
      "learning_rate": 3.3756961567478704e-05,
      "loss": 0.4784,
      "step": 802700
    },
    {
      "epoch": 8.498271764388289,
      "grad_norm": 1.34317946434021,
      "learning_rate": 3.37337850533746e-05,
      "loss": 0.4766,
      "step": 802750
    },
    {
      "epoch": 8.498801086168292,
      "grad_norm": 1.3826067447662354,
      "learning_rate": 3.37106159225197e-05,
      "loss": 0.4893,
      "step": 802800
    },
    {
      "epoch": 8.499330407948296,
      "grad_norm": 1.3652245998382568,
      "learning_rate": 3.368745417570509e-05,
      "loss": 0.4739,
      "step": 802850
    },
    {
      "epoch": 8.4998597297283,
      "grad_norm": 1.5037251710891724,
      "learning_rate": 3.366429981372143e-05,
      "loss": 0.4885,
      "step": 802900
    },
    {
      "epoch": 8.500389051508302,
      "grad_norm": 1.463620901107788,
      "learning_rate": 3.3641152837359276e-05,
      "loss": 0.4909,
      "step": 802950
    },
    {
      "epoch": 8.500918373288306,
      "grad_norm": 1.3677281141281128,
      "learning_rate": 3.361801324740876e-05,
      "loss": 0.4884,
      "step": 803000
    },
    {
      "epoch": 8.500918373288306,
      "eval_loss": 0.2987268269062042,
      "eval_runtime": 46.7728,
      "eval_samples_per_second": 3590.331,
      "eval_steps_per_second": 448.807,
      "step": 803000
    },
    {
      "epoch": 8.50144769506831,
      "grad_norm": 1.4204380512237549,
      "learning_rate": 3.3594881044659935e-05,
      "loss": 0.4766,
      "step": 803050
    },
    {
      "epoch": 8.501977016848313,
      "grad_norm": 1.3784034252166748,
      "learning_rate": 3.357175622990255e-05,
      "loss": 0.4858,
      "step": 803100
    },
    {
      "epoch": 8.502506338628315,
      "grad_norm": 1.365683913230896,
      "learning_rate": 3.3548638803925973e-05,
      "loss": 0.4923,
      "step": 803150
    },
    {
      "epoch": 8.503035660408319,
      "grad_norm": 1.2529480457305908,
      "learning_rate": 3.352552876751949e-05,
      "loss": 0.4813,
      "step": 803200
    },
    {
      "epoch": 8.503564982188323,
      "grad_norm": 1.4179552793502808,
      "learning_rate": 3.350242612147214e-05,
      "loss": 0.4834,
      "step": 803250
    },
    {
      "epoch": 8.504094303968325,
      "grad_norm": 1.3798692226409912,
      "learning_rate": 3.3479330866572485e-05,
      "loss": 0.4743,
      "step": 803300
    },
    {
      "epoch": 8.504623625748328,
      "grad_norm": 1.2346460819244385,
      "learning_rate": 3.345624300360914e-05,
      "loss": 0.4861,
      "step": 803350
    },
    {
      "epoch": 8.505152947528332,
      "grad_norm": 1.2902896404266357,
      "learning_rate": 3.343316253337017e-05,
      "loss": 0.4828,
      "step": 803400
    },
    {
      "epoch": 8.505682269308336,
      "grad_norm": 1.4426617622375488,
      "learning_rate": 3.341008945664367e-05,
      "loss": 0.475,
      "step": 803450
    },
    {
      "epoch": 8.506211591088338,
      "grad_norm": 1.40675950050354,
      "learning_rate": 3.338702377421723e-05,
      "loss": 0.4857,
      "step": 803500
    },
    {
      "epoch": 8.506211591088338,
      "eval_loss": 0.29838797450065613,
      "eval_runtime": 46.8937,
      "eval_samples_per_second": 3581.075,
      "eval_steps_per_second": 447.65,
      "step": 803500
    },
    {
      "epoch": 8.506740912868342,
      "grad_norm": 1.4069902896881104,
      "learning_rate": 3.336396548687839e-05,
      "loss": 0.4854,
      "step": 803550
    },
    {
      "epoch": 8.507270234648345,
      "grad_norm": 1.4587560892105103,
      "learning_rate": 3.33409145954143e-05,
      "loss": 0.4855,
      "step": 803600
    },
    {
      "epoch": 8.507799556428349,
      "grad_norm": 1.5002604722976685,
      "learning_rate": 3.3317871100611965e-05,
      "loss": 0.4865,
      "step": 803650
    },
    {
      "epoch": 8.508328878208351,
      "grad_norm": 1.3044168949127197,
      "learning_rate": 3.3294835003258e-05,
      "loss": 0.4846,
      "step": 803700
    },
    {
      "epoch": 8.508858199988355,
      "grad_norm": 1.4023324251174927,
      "learning_rate": 3.327180630413895e-05,
      "loss": 0.4824,
      "step": 803750
    },
    {
      "epoch": 8.509387521768359,
      "grad_norm": 1.4703673124313354,
      "learning_rate": 3.324878500404088e-05,
      "loss": 0.4891,
      "step": 803800
    },
    {
      "epoch": 8.509916843548362,
      "grad_norm": 1.4674586057662964,
      "learning_rate": 3.322577110374986e-05,
      "loss": 0.4842,
      "step": 803850
    },
    {
      "epoch": 8.510446165328364,
      "grad_norm": 1.4364948272705078,
      "learning_rate": 3.320276460405147e-05,
      "loss": 0.4835,
      "step": 803900
    },
    {
      "epoch": 8.510975487108368,
      "grad_norm": 1.3557045459747314,
      "learning_rate": 3.3179765505731234e-05,
      "loss": 0.4714,
      "step": 803950
    },
    {
      "epoch": 8.511504808888372,
      "grad_norm": 1.3989096879959106,
      "learning_rate": 3.3156773809574216e-05,
      "loss": 0.4859,
      "step": 804000
    },
    {
      "epoch": 8.511504808888372,
      "eval_loss": 0.29783427715301514,
      "eval_runtime": 46.802,
      "eval_samples_per_second": 3588.098,
      "eval_steps_per_second": 448.528,
      "step": 804000
    },
    {
      "epoch": 8.512034130668376,
      "grad_norm": 1.361052393913269,
      "learning_rate": 3.31337895163655e-05,
      "loss": 0.4888,
      "step": 804050
    },
    {
      "epoch": 8.512563452448378,
      "grad_norm": 1.4301005601882935,
      "learning_rate": 3.3110812626889614e-05,
      "loss": 0.4868,
      "step": 804100
    },
    {
      "epoch": 8.513092774228381,
      "grad_norm": 1.3490185737609863,
      "learning_rate": 3.3087843141931086e-05,
      "loss": 0.4825,
      "step": 804150
    },
    {
      "epoch": 8.513622096008385,
      "grad_norm": 1.4887206554412842,
      "learning_rate": 3.306488106227398e-05,
      "loss": 0.4787,
      "step": 804200
    },
    {
      "epoch": 8.514151417788387,
      "grad_norm": 1.3288791179656982,
      "learning_rate": 3.3041926388702346e-05,
      "loss": 0.4791,
      "step": 804250
    },
    {
      "epoch": 8.51468073956839,
      "grad_norm": 1.4725043773651123,
      "learning_rate": 3.301897912199972e-05,
      "loss": 0.478,
      "step": 804300
    },
    {
      "epoch": 8.515210061348395,
      "grad_norm": 1.408928394317627,
      "learning_rate": 3.299603926294964e-05,
      "loss": 0.4784,
      "step": 804350
    },
    {
      "epoch": 8.515739383128398,
      "grad_norm": 1.3803870677947998,
      "learning_rate": 3.297310681233512e-05,
      "loss": 0.4821,
      "step": 804400
    },
    {
      "epoch": 8.5162687049084,
      "grad_norm": 1.2533735036849976,
      "learning_rate": 3.29506401991517e-05,
      "loss": 0.4727,
      "step": 804450
    },
    {
      "epoch": 8.516798026688404,
      "grad_norm": 1.4942792654037476,
      "learning_rate": 3.2927722419549276e-05,
      "loss": 0.482,
      "step": 804500
    },
    {
      "epoch": 8.516798026688404,
      "eval_loss": 0.2981396019458771,
      "eval_runtime": 46.8295,
      "eval_samples_per_second": 3585.988,
      "eval_steps_per_second": 448.264,
      "step": 804500
    },
    {
      "epoch": 8.517327348468408,
      "grad_norm": 1.3364057540893555,
      "learning_rate": 3.290481205071477e-05,
      "loss": 0.4805,
      "step": 804550
    },
    {
      "epoch": 8.517856670248412,
      "grad_norm": 1.2820613384246826,
      "learning_rate": 3.288190909343039e-05,
      "loss": 0.4808,
      "step": 804600
    },
    {
      "epoch": 8.518385992028414,
      "grad_norm": 1.3728828430175781,
      "learning_rate": 3.285901354847798e-05,
      "loss": 0.4884,
      "step": 804650
    },
    {
      "epoch": 8.518915313808417,
      "grad_norm": 1.4972926378250122,
      "learning_rate": 3.283612541663925e-05,
      "loss": 0.4761,
      "step": 804700
    },
    {
      "epoch": 8.519444635588421,
      "grad_norm": 1.2089613676071167,
      "learning_rate": 3.281324469869551e-05,
      "loss": 0.4845,
      "step": 804750
    },
    {
      "epoch": 8.519973957368425,
      "grad_norm": 1.3333979845046997,
      "learning_rate": 3.2790371395427985e-05,
      "loss": 0.4902,
      "step": 804800
    },
    {
      "epoch": 8.520503279148427,
      "grad_norm": 1.3757067918777466,
      "learning_rate": 3.276750550761748e-05,
      "loss": 0.4852,
      "step": 804850
    },
    {
      "epoch": 8.52103260092843,
      "grad_norm": 1.400076150894165,
      "learning_rate": 3.2744647036044715e-05,
      "loss": 0.4846,
      "step": 804900
    },
    {
      "epoch": 8.521561922708434,
      "grad_norm": 1.4225796461105347,
      "learning_rate": 3.272179598148997e-05,
      "loss": 0.4802,
      "step": 804950
    },
    {
      "epoch": 8.522091244488436,
      "grad_norm": 1.413506031036377,
      "learning_rate": 3.2698952344733494e-05,
      "loss": 0.4767,
      "step": 805000
    },
    {
      "epoch": 8.522091244488436,
      "eval_loss": 0.2979486286640167,
      "eval_runtime": 46.8273,
      "eval_samples_per_second": 3586.155,
      "eval_steps_per_second": 448.285,
      "step": 805000
    },
    {
      "epoch": 8.52262056626844,
      "grad_norm": 1.3460578918457031,
      "learning_rate": 3.2676116126555024e-05,
      "loss": 0.487,
      "step": 805050
    },
    {
      "epoch": 8.523149888048444,
      "grad_norm": 1.312227725982666,
      "learning_rate": 3.265328732773426e-05,
      "loss": 0.4926,
      "step": 805100
    },
    {
      "epoch": 8.523679209828448,
      "grad_norm": 1.3090726137161255,
      "learning_rate": 3.263046594905059e-05,
      "loss": 0.4904,
      "step": 805150
    },
    {
      "epoch": 8.52420853160845,
      "grad_norm": 1.3113389015197754,
      "learning_rate": 3.2607651991283074e-05,
      "loss": 0.4936,
      "step": 805200
    },
    {
      "epoch": 8.524737853388453,
      "grad_norm": 1.3110829591751099,
      "learning_rate": 3.2584845455210566e-05,
      "loss": 0.486,
      "step": 805250
    },
    {
      "epoch": 8.525267175168457,
      "grad_norm": 1.307778239250183,
      "learning_rate": 3.256204634161175e-05,
      "loss": 0.4761,
      "step": 805300
    },
    {
      "epoch": 8.52579649694846,
      "grad_norm": 1.4534070491790771,
      "learning_rate": 3.253925465126489e-05,
      "loss": 0.4859,
      "step": 805350
    },
    {
      "epoch": 8.526325818728463,
      "grad_norm": 1.5475852489471436,
      "learning_rate": 3.2516470384948174e-05,
      "loss": 0.4762,
      "step": 805400
    },
    {
      "epoch": 8.526855140508466,
      "grad_norm": 1.368032455444336,
      "learning_rate": 3.249369354343934e-05,
      "loss": 0.4879,
      "step": 805450
    },
    {
      "epoch": 8.52738446228847,
      "grad_norm": 1.3550901412963867,
      "learning_rate": 3.2470924127516094e-05,
      "loss": 0.4827,
      "step": 805500
    },
    {
      "epoch": 8.52738446228847,
      "eval_loss": 0.29780811071395874,
      "eval_runtime": 46.8014,
      "eval_samples_per_second": 3588.143,
      "eval_steps_per_second": 448.534,
      "step": 805500
    },
    {
      "epoch": 8.527913784068474,
      "grad_norm": 1.5562392473220825,
      "learning_rate": 3.2448162137955675e-05,
      "loss": 0.4833,
      "step": 805550
    },
    {
      "epoch": 8.528443105848476,
      "grad_norm": 1.3574330806732178,
      "learning_rate": 3.2425407575535274e-05,
      "loss": 0.4803,
      "step": 805600
    },
    {
      "epoch": 8.52897242762848,
      "grad_norm": 1.381935477256775,
      "learning_rate": 3.24026604410316e-05,
      "loss": 0.4881,
      "step": 805650
    },
    {
      "epoch": 8.529501749408483,
      "grad_norm": 1.3739466667175293,
      "learning_rate": 3.2379920735221365e-05,
      "loss": 0.4943,
      "step": 805700
    },
    {
      "epoch": 8.530031071188485,
      "grad_norm": 1.4857455492019653,
      "learning_rate": 3.2357188458880746e-05,
      "loss": 0.4908,
      "step": 805750
    },
    {
      "epoch": 8.53056039296849,
      "grad_norm": 1.4343479871749878,
      "learning_rate": 3.233446361278597e-05,
      "loss": 0.484,
      "step": 805800
    },
    {
      "epoch": 8.531089714748493,
      "grad_norm": 1.3241322040557861,
      "learning_rate": 3.231174619771274e-05,
      "loss": 0.4777,
      "step": 805850
    },
    {
      "epoch": 8.531619036528497,
      "grad_norm": 1.357053518295288,
      "learning_rate": 3.2289036214436684e-05,
      "loss": 0.4824,
      "step": 805900
    },
    {
      "epoch": 8.532148358308499,
      "grad_norm": 1.3457261323928833,
      "learning_rate": 3.226633366373305e-05,
      "loss": 0.4802,
      "step": 805950
    },
    {
      "epoch": 8.532677680088502,
      "grad_norm": 1.3420774936676025,
      "learning_rate": 3.224363854637699e-05,
      "loss": 0.4819,
      "step": 806000
    },
    {
      "epoch": 8.532677680088502,
      "eval_loss": 0.2976696491241455,
      "eval_runtime": 46.8647,
      "eval_samples_per_second": 3583.293,
      "eval_steps_per_second": 447.928,
      "step": 806000
    },
    {
      "epoch": 8.533207001868506,
      "grad_norm": 1.4291391372680664,
      "learning_rate": 3.2220950863143194e-05,
      "loss": 0.4812,
      "step": 806050
    },
    {
      "epoch": 8.53373632364851,
      "grad_norm": 1.2637436389923096,
      "learning_rate": 3.219827061480632e-05,
      "loss": 0.4877,
      "step": 806100
    },
    {
      "epoch": 8.534265645428512,
      "grad_norm": 1.4611971378326416,
      "learning_rate": 3.217559780214055e-05,
      "loss": 0.4884,
      "step": 806150
    },
    {
      "epoch": 8.534794967208516,
      "grad_norm": 1.2581987380981445,
      "learning_rate": 3.2152932425920044e-05,
      "loss": 0.4915,
      "step": 806200
    },
    {
      "epoch": 8.53532428898852,
      "grad_norm": 1.1362134218215942,
      "learning_rate": 3.2130274486918464e-05,
      "loss": 0.4791,
      "step": 806250
    },
    {
      "epoch": 8.535853610768523,
      "grad_norm": 1.4356635808944702,
      "learning_rate": 3.210762398590947e-05,
      "loss": 0.4869,
      "step": 806300
    },
    {
      "epoch": 8.536382932548525,
      "grad_norm": 1.463136911392212,
      "learning_rate": 3.208498092366624e-05,
      "loss": 0.4868,
      "step": 806350
    },
    {
      "epoch": 8.536912254328529,
      "grad_norm": 1.3419933319091797,
      "learning_rate": 3.2062345300961915e-05,
      "loss": 0.48,
      "step": 806400
    },
    {
      "epoch": 8.537441576108533,
      "grad_norm": 1.4003562927246094,
      "learning_rate": 3.203971711856912e-05,
      "loss": 0.4816,
      "step": 806450
    },
    {
      "epoch": 8.537970897888535,
      "grad_norm": 1.5059804916381836,
      "learning_rate": 3.20170963772605e-05,
      "loss": 0.4824,
      "step": 806500
    },
    {
      "epoch": 8.537970897888535,
      "eval_loss": 0.2973968982696533,
      "eval_runtime": 46.8422,
      "eval_samples_per_second": 3585.015,
      "eval_steps_per_second": 448.143,
      "step": 806500
    },
    {
      "epoch": 8.538500219668538,
      "grad_norm": 1.3651083707809448,
      "learning_rate": 3.199448307780822e-05,
      "loss": 0.4868,
      "step": 806550
    },
    {
      "epoch": 8.539029541448542,
      "grad_norm": 1.2658647298812866,
      "learning_rate": 3.197187722098438e-05,
      "loss": 0.4746,
      "step": 806600
    },
    {
      "epoch": 8.539558863228546,
      "grad_norm": 1.433029055595398,
      "learning_rate": 3.194927880756066e-05,
      "loss": 0.4864,
      "step": 806650
    },
    {
      "epoch": 8.540088185008548,
      "grad_norm": 1.276068925857544,
      "learning_rate": 3.1926687838308574e-05,
      "loss": 0.48,
      "step": 806700
    },
    {
      "epoch": 8.540617506788552,
      "grad_norm": 1.4411067962646484,
      "learning_rate": 3.1904104313999426e-05,
      "loss": 0.4847,
      "step": 806750
    },
    {
      "epoch": 8.541146828568555,
      "grad_norm": 1.3196945190429688,
      "learning_rate": 3.1881528235404164e-05,
      "loss": 0.4796,
      "step": 806800
    },
    {
      "epoch": 8.54167615034856,
      "grad_norm": 1.3328933715820312,
      "learning_rate": 3.185895960329355e-05,
      "loss": 0.4908,
      "step": 806850
    },
    {
      "epoch": 8.542205472128561,
      "grad_norm": 1.3964308500289917,
      "learning_rate": 3.1836849569147066e-05,
      "loss": 0.4789,
      "step": 806900
    },
    {
      "epoch": 8.542734793908565,
      "grad_norm": 1.2567213773727417,
      "learning_rate": 3.181429568334887e-05,
      "loss": 0.4883,
      "step": 806950
    },
    {
      "epoch": 8.543264115688569,
      "grad_norm": 1.4701675176620483,
      "learning_rate": 3.1791749246330574e-05,
      "loss": 0.4845,
      "step": 807000
    },
    {
      "epoch": 8.543264115688569,
      "eval_loss": 0.2976515591144562,
      "eval_runtime": 46.9163,
      "eval_samples_per_second": 3579.349,
      "eval_steps_per_second": 447.435,
      "step": 807000
    },
    {
      "epoch": 8.543793437468572,
      "grad_norm": 1.4523361921310425,
      "learning_rate": 3.176921025886198e-05,
      "loss": 0.4841,
      "step": 807050
    },
    {
      "epoch": 8.544322759248574,
      "grad_norm": 1.3918689489364624,
      "learning_rate": 3.174667872171244e-05,
      "loss": 0.4817,
      "step": 807100
    },
    {
      "epoch": 8.544852081028578,
      "grad_norm": 1.5211809873580933,
      "learning_rate": 3.172415463565126e-05,
      "loss": 0.4893,
      "step": 807150
    },
    {
      "epoch": 8.545381402808582,
      "grad_norm": 1.2746652364730835,
      "learning_rate": 3.170163800144743e-05,
      "loss": 0.4859,
      "step": 807200
    },
    {
      "epoch": 8.545910724588584,
      "grad_norm": 1.248044729232788,
      "learning_rate": 3.167912881986959e-05,
      "loss": 0.4749,
      "step": 807250
    },
    {
      "epoch": 8.546440046368588,
      "grad_norm": 1.1977295875549316,
      "learning_rate": 3.1656627091686206e-05,
      "loss": 0.4815,
      "step": 807300
    },
    {
      "epoch": 8.546969368148591,
      "grad_norm": 1.3327347040176392,
      "learning_rate": 3.163413281766556e-05,
      "loss": 0.4794,
      "step": 807350
    },
    {
      "epoch": 8.547498689928595,
      "grad_norm": 1.2516546249389648,
      "learning_rate": 3.1611645998575494e-05,
      "loss": 0.4811,
      "step": 807400
    },
    {
      "epoch": 8.548028011708597,
      "grad_norm": 1.515742540359497,
      "learning_rate": 3.158916663518377e-05,
      "loss": 0.4832,
      "step": 807450
    },
    {
      "epoch": 8.548557333488601,
      "grad_norm": 1.2804666757583618,
      "learning_rate": 3.1566694728257767e-05,
      "loss": 0.4878,
      "step": 807500
    },
    {
      "epoch": 8.548557333488601,
      "eval_loss": 0.297347754240036,
      "eval_runtime": 46.8094,
      "eval_samples_per_second": 3587.526,
      "eval_steps_per_second": 448.457,
      "step": 807500
    },
    {
      "epoch": 8.549086655268605,
      "grad_norm": 1.3467926979064941,
      "learning_rate": 3.154423027856473e-05,
      "loss": 0.48,
      "step": 807550
    },
    {
      "epoch": 8.549615977048608,
      "grad_norm": 1.6013028621673584,
      "learning_rate": 3.152177328687153e-05,
      "loss": 0.4841,
      "step": 807600
    },
    {
      "epoch": 8.55014529882861,
      "grad_norm": 1.3318021297454834,
      "learning_rate": 3.14993237539449e-05,
      "loss": 0.4762,
      "step": 807650
    },
    {
      "epoch": 8.550674620608614,
      "grad_norm": 1.4082062244415283,
      "learning_rate": 3.1476881680551154e-05,
      "loss": 0.477,
      "step": 807700
    },
    {
      "epoch": 8.551203942388618,
      "grad_norm": 1.3023141622543335,
      "learning_rate": 3.145444706745662e-05,
      "loss": 0.4822,
      "step": 807750
    },
    {
      "epoch": 8.551733264168622,
      "grad_norm": 1.3183097839355469,
      "learning_rate": 3.143201991542702e-05,
      "loss": 0.4807,
      "step": 807800
    },
    {
      "epoch": 8.552262585948624,
      "grad_norm": 1.401610255241394,
      "learning_rate": 3.140960022522818e-05,
      "loss": 0.4811,
      "step": 807850
    },
    {
      "epoch": 8.552791907728627,
      "grad_norm": 1.3967593908309937,
      "learning_rate": 3.1387187997625384e-05,
      "loss": 0.4829,
      "step": 807900
    },
    {
      "epoch": 8.553321229508631,
      "grad_norm": 1.2835854291915894,
      "learning_rate": 3.136478323338385e-05,
      "loss": 0.4859,
      "step": 807950
    },
    {
      "epoch": 8.553850551288633,
      "grad_norm": 1.2973554134368896,
      "learning_rate": 3.1342385933268354e-05,
      "loss": 0.487,
      "step": 808000
    },
    {
      "epoch": 8.553850551288633,
      "eval_loss": 0.2975400388240814,
      "eval_runtime": 46.8675,
      "eval_samples_per_second": 3583.083,
      "eval_steps_per_second": 447.901,
      "step": 808000
    },
    {
      "epoch": 8.554379873068637,
      "grad_norm": 1.3860814571380615,
      "learning_rate": 3.13199960980437e-05,
      "loss": 0.4857,
      "step": 808050
    },
    {
      "epoch": 8.55490919484864,
      "grad_norm": 1.4664357900619507,
      "learning_rate": 3.129761372847412e-05,
      "loss": 0.4843,
      "step": 808100
    },
    {
      "epoch": 8.555438516628644,
      "grad_norm": 1.2758307456970215,
      "learning_rate": 3.127523882532385e-05,
      "loss": 0.4835,
      "step": 808150
    },
    {
      "epoch": 8.555967838408646,
      "grad_norm": 1.4477061033248901,
      "learning_rate": 3.125287138935667e-05,
      "loss": 0.4861,
      "step": 808200
    },
    {
      "epoch": 8.55649716018865,
      "grad_norm": 1.457008719444275,
      "learning_rate": 3.123051142133629e-05,
      "loss": 0.4818,
      "step": 808250
    },
    {
      "epoch": 8.557026481968654,
      "grad_norm": 1.2747278213500977,
      "learning_rate": 3.120815892202594e-05,
      "loss": 0.4748,
      "step": 808300
    },
    {
      "epoch": 8.557555803748658,
      "grad_norm": 1.3763372898101807,
      "learning_rate": 3.118581389218889e-05,
      "loss": 0.4865,
      "step": 808350
    },
    {
      "epoch": 8.55808512552866,
      "grad_norm": 1.4837796688079834,
      "learning_rate": 3.1163476332587814e-05,
      "loss": 0.487,
      "step": 808400
    },
    {
      "epoch": 8.558614447308663,
      "grad_norm": 1.3886802196502686,
      "learning_rate": 3.114114624398548e-05,
      "loss": 0.4776,
      "step": 808450
    },
    {
      "epoch": 8.559143769088667,
      "grad_norm": 1.224483847618103,
      "learning_rate": 3.11188236271441e-05,
      "loss": 0.4785,
      "step": 808500
    },
    {
      "epoch": 8.559143769088667,
      "eval_loss": 0.2971510589122772,
      "eval_runtime": 46.875,
      "eval_samples_per_second": 3582.505,
      "eval_steps_per_second": 447.829,
      "step": 808500
    },
    {
      "epoch": 8.559673090868671,
      "grad_norm": 1.4479318857192993,
      "learning_rate": 3.109650848282586e-05,
      "loss": 0.4772,
      "step": 808550
    },
    {
      "epoch": 8.560202412648673,
      "grad_norm": 1.278356671333313,
      "learning_rate": 3.107420081179246e-05,
      "loss": 0.4794,
      "step": 808600
    },
    {
      "epoch": 8.560731734428677,
      "grad_norm": 1.4467462301254272,
      "learning_rate": 3.1051900614805644e-05,
      "loss": 0.4823,
      "step": 808650
    },
    {
      "epoch": 8.56126105620868,
      "grad_norm": 1.4008156061172485,
      "learning_rate": 3.1029607892626574e-05,
      "loss": 0.4754,
      "step": 808700
    },
    {
      "epoch": 8.561790377988682,
      "grad_norm": 1.434234857559204,
      "learning_rate": 3.100732264601644e-05,
      "loss": 0.4851,
      "step": 808750
    },
    {
      "epoch": 8.562319699768686,
      "grad_norm": 1.3986191749572754,
      "learning_rate": 3.098504487573595e-05,
      "loss": 0.4789,
      "step": 808800
    },
    {
      "epoch": 8.56284902154869,
      "grad_norm": 1.3207398653030396,
      "learning_rate": 3.096277458254571e-05,
      "loss": 0.4816,
      "step": 808850
    },
    {
      "epoch": 8.563378343328694,
      "grad_norm": 1.2782751321792603,
      "learning_rate": 3.094051176720605e-05,
      "loss": 0.4754,
      "step": 808900
    },
    {
      "epoch": 8.563907665108696,
      "grad_norm": 1.5370523929595947,
      "learning_rate": 3.0918256430476934e-05,
      "loss": 0.489,
      "step": 808950
    },
    {
      "epoch": 8.5644369868887,
      "grad_norm": 1.2376124858856201,
      "learning_rate": 3.0896008573118225e-05,
      "loss": 0.4809,
      "step": 809000
    },
    {
      "epoch": 8.5644369868887,
      "eval_loss": 0.29684484004974365,
      "eval_runtime": 46.7486,
      "eval_samples_per_second": 3592.19,
      "eval_steps_per_second": 449.04,
      "step": 809000
    },
    {
      "epoch": 8.564966308668703,
      "grad_norm": 1.5480895042419434,
      "learning_rate": 3.087376819588944e-05,
      "loss": 0.4932,
      "step": 809050
    },
    {
      "epoch": 8.565495630448707,
      "grad_norm": 1.471382737159729,
      "learning_rate": 3.085153529954982e-05,
      "loss": 0.4828,
      "step": 809100
    },
    {
      "epoch": 8.566024952228709,
      "grad_norm": 1.3155757188796997,
      "learning_rate": 3.082930988485846e-05,
      "loss": 0.4877,
      "step": 809150
    },
    {
      "epoch": 8.566554274008713,
      "grad_norm": 1.4164594411849976,
      "learning_rate": 3.080709195257403e-05,
      "loss": 0.4896,
      "step": 809200
    },
    {
      "epoch": 8.567083595788716,
      "grad_norm": 1.499147653579712,
      "learning_rate": 3.078488150345515e-05,
      "loss": 0.49,
      "step": 809250
    },
    {
      "epoch": 8.56761291756872,
      "grad_norm": 1.3615083694458008,
      "learning_rate": 3.076312252421654e-05,
      "loss": 0.4801,
      "step": 809300
    },
    {
      "epoch": 8.568142239348722,
      "grad_norm": 1.3194202184677124,
      "learning_rate": 3.074092689400204e-05,
      "loss": 0.4785,
      "step": 809350
    },
    {
      "epoch": 8.568671561128726,
      "grad_norm": 1.4434739351272583,
      "learning_rate": 3.0718738749211936e-05,
      "loss": 0.4888,
      "step": 809400
    },
    {
      "epoch": 8.56920088290873,
      "grad_norm": 1.5073260068893433,
      "learning_rate": 3.069655809060362e-05,
      "loss": 0.4863,
      "step": 809450
    },
    {
      "epoch": 8.569730204688732,
      "grad_norm": 1.1920697689056396,
      "learning_rate": 3.067438491893446e-05,
      "loss": 0.4853,
      "step": 809500
    },
    {
      "epoch": 8.569730204688732,
      "eval_loss": 0.2971950173377991,
      "eval_runtime": 46.9677,
      "eval_samples_per_second": 3575.437,
      "eval_steps_per_second": 446.946,
      "step": 809500
    },
    {
      "epoch": 8.570259526468735,
      "grad_norm": 1.585098147392273,
      "learning_rate": 3.0652219234961284e-05,
      "loss": 0.4767,
      "step": 809550
    },
    {
      "epoch": 8.570788848248739,
      "grad_norm": 1.3376504182815552,
      "learning_rate": 3.063006103944091e-05,
      "loss": 0.4865,
      "step": 809600
    },
    {
      "epoch": 8.571318170028743,
      "grad_norm": 1.4969651699066162,
      "learning_rate": 3.060835327385694e-05,
      "loss": 0.48,
      "step": 809650
    },
    {
      "epoch": 8.571847491808745,
      "grad_norm": 1.3769538402557373,
      "learning_rate": 3.0586209907704636e-05,
      "loss": 0.4831,
      "step": 809700
    },
    {
      "epoch": 8.572376813588749,
      "grad_norm": 1.4375598430633545,
      "learning_rate": 3.0564074032258636e-05,
      "loss": 0.4854,
      "step": 809750
    },
    {
      "epoch": 8.572906135368752,
      "grad_norm": 1.397007942199707,
      "learning_rate": 3.054194564827464e-05,
      "loss": 0.4907,
      "step": 809800
    },
    {
      "epoch": 8.573435457148756,
      "grad_norm": 1.3782626390457153,
      "learning_rate": 3.051982475650819e-05,
      "loss": 0.4824,
      "step": 809850
    },
    {
      "epoch": 8.573964778928758,
      "grad_norm": 1.4000568389892578,
      "learning_rate": 3.04977113577144e-05,
      "loss": 0.4795,
      "step": 809900
    },
    {
      "epoch": 8.574494100708762,
      "grad_norm": 1.4726170301437378,
      "learning_rate": 3.0475605452648214e-05,
      "loss": 0.479,
      "step": 809950
    },
    {
      "epoch": 8.575023422488766,
      "grad_norm": 1.2329808473587036,
      "learning_rate": 3.0453507042064427e-05,
      "loss": 0.4811,
      "step": 810000
    },
    {
      "epoch": 8.575023422488766,
      "eval_loss": 0.2972918152809143,
      "eval_runtime": 46.7386,
      "eval_samples_per_second": 3592.962,
      "eval_steps_per_second": 449.136,
      "step": 810000
    },
    {
      "epoch": 8.57555274426877,
      "grad_norm": 1.253455400466919,
      "learning_rate": 3.0431416126717347e-05,
      "loss": 0.4894,
      "step": 810050
    },
    {
      "epoch": 8.576082066048771,
      "grad_norm": 1.3430675268173218,
      "learning_rate": 3.0409332707361237e-05,
      "loss": 0.4826,
      "step": 810100
    },
    {
      "epoch": 8.576611387828775,
      "grad_norm": 1.4159085750579834,
      "learning_rate": 3.0387256784749906e-05,
      "loss": 0.475,
      "step": 810150
    },
    {
      "epoch": 8.577140709608779,
      "grad_norm": 1.4351258277893066,
      "learning_rate": 3.036518835963714e-05,
      "loss": 0.478,
      "step": 810200
    },
    {
      "epoch": 8.57767003138878,
      "grad_norm": 1.3882728815078735,
      "learning_rate": 3.0343127432776287e-05,
      "loss": 0.4871,
      "step": 810250
    },
    {
      "epoch": 8.578199353168785,
      "grad_norm": 1.48055100440979,
      "learning_rate": 3.032107400492051e-05,
      "loss": 0.4737,
      "step": 810300
    },
    {
      "epoch": 8.578728674948788,
      "grad_norm": 1.4686628580093384,
      "learning_rate": 3.0299028076822665e-05,
      "loss": 0.476,
      "step": 810350
    },
    {
      "epoch": 8.579257996728792,
      "grad_norm": 1.3811503648757935,
      "learning_rate": 3.0276989649235475e-05,
      "loss": 0.4853,
      "step": 810400
    },
    {
      "epoch": 8.579787318508794,
      "grad_norm": 1.3062529563903809,
      "learning_rate": 3.025495872291126e-05,
      "loss": 0.4892,
      "step": 810450
    },
    {
      "epoch": 8.580316640288798,
      "grad_norm": 1.3875739574432373,
      "learning_rate": 3.023293529860219e-05,
      "loss": 0.4869,
      "step": 810500
    },
    {
      "epoch": 8.580316640288798,
      "eval_loss": 0.29716813564300537,
      "eval_runtime": 46.9175,
      "eval_samples_per_second": 3579.259,
      "eval_steps_per_second": 447.423,
      "step": 810500
    },
    {
      "epoch": 8.580845962068802,
      "grad_norm": 1.4132651090621948,
      "learning_rate": 3.0210919377060055e-05,
      "loss": 0.4753,
      "step": 810550
    },
    {
      "epoch": 8.581375283848805,
      "grad_norm": 1.366950273513794,
      "learning_rate": 3.0188910959036587e-05,
      "loss": 0.4837,
      "step": 810600
    },
    {
      "epoch": 8.581904605628807,
      "grad_norm": 1.4032618999481201,
      "learning_rate": 3.016691004528302e-05,
      "loss": 0.4824,
      "step": 810650
    },
    {
      "epoch": 8.582433927408811,
      "grad_norm": 1.3119189739227295,
      "learning_rate": 3.0144916636550583e-05,
      "loss": 0.4827,
      "step": 810700
    },
    {
      "epoch": 8.582963249188815,
      "grad_norm": 1.3739317655563354,
      "learning_rate": 3.0122930733590016e-05,
      "loss": 0.4859,
      "step": 810750
    },
    {
      "epoch": 8.583492570968819,
      "grad_norm": 1.428708791732788,
      "learning_rate": 3.0100952337152016e-05,
      "loss": 0.4805,
      "step": 810800
    },
    {
      "epoch": 8.58402189274882,
      "grad_norm": 1.3169492483139038,
      "learning_rate": 3.007898144798679e-05,
      "loss": 0.483,
      "step": 810850
    },
    {
      "epoch": 8.584551214528824,
      "grad_norm": 1.290614128112793,
      "learning_rate": 3.0057018066844523e-05,
      "loss": 0.4827,
      "step": 810900
    },
    {
      "epoch": 8.585080536308828,
      "grad_norm": 1.5282230377197266,
      "learning_rate": 3.0035062194474966e-05,
      "loss": 0.4874,
      "step": 810950
    },
    {
      "epoch": 8.58560985808883,
      "grad_norm": 1.4477365016937256,
      "learning_rate": 3.0013113831627774e-05,
      "loss": 0.4741,
      "step": 811000
    },
    {
      "epoch": 8.58560985808883,
      "eval_loss": 0.2967042028903961,
      "eval_runtime": 46.765,
      "eval_samples_per_second": 3590.934,
      "eval_steps_per_second": 448.883,
      "step": 811000
    },
    {
      "epoch": 8.586139179868834,
      "grad_norm": 1.4175920486450195,
      "learning_rate": 2.9991172979052128e-05,
      "loss": 0.4782,
      "step": 811050
    },
    {
      "epoch": 8.586668501648838,
      "grad_norm": 1.1881566047668457,
      "learning_rate": 2.9969239637497204e-05,
      "loss": 0.4809,
      "step": 811100
    },
    {
      "epoch": 8.587197823428841,
      "grad_norm": 1.324480652809143,
      "learning_rate": 2.9947313807711705e-05,
      "loss": 0.4817,
      "step": 811150
    },
    {
      "epoch": 8.587727145208843,
      "grad_norm": 1.2759360074996948,
      "learning_rate": 2.9925395490444263e-05,
      "loss": 0.4733,
      "step": 811200
    },
    {
      "epoch": 8.588256466988847,
      "grad_norm": 1.541382908821106,
      "learning_rate": 2.990348468644305e-05,
      "loss": 0.4814,
      "step": 811250
    },
    {
      "epoch": 8.58878578876885,
      "grad_norm": 1.3873623609542847,
      "learning_rate": 2.9881581396456193e-05,
      "loss": 0.4818,
      "step": 811300
    },
    {
      "epoch": 8.589315110548855,
      "grad_norm": 1.5024521350860596,
      "learning_rate": 2.9859685621231396e-05,
      "loss": 0.4844,
      "step": 811350
    },
    {
      "epoch": 8.589844432328857,
      "grad_norm": 1.390055775642395,
      "learning_rate": 2.9837797361516233e-05,
      "loss": 0.479,
      "step": 811400
    },
    {
      "epoch": 8.59037375410886,
      "grad_norm": 1.3847976922988892,
      "learning_rate": 2.9815916618057882e-05,
      "loss": 0.4785,
      "step": 811450
    },
    {
      "epoch": 8.590903075888864,
      "grad_norm": 1.3236939907073975,
      "learning_rate": 2.9794043391603383e-05,
      "loss": 0.4842,
      "step": 811500
    },
    {
      "epoch": 8.590903075888864,
      "eval_loss": 0.2970322370529175,
      "eval_runtime": 46.8282,
      "eval_samples_per_second": 3586.084,
      "eval_steps_per_second": 448.276,
      "step": 811500
    },
    {
      "epoch": 8.591432397668868,
      "grad_norm": 1.4561002254486084,
      "learning_rate": 2.9772177682899527e-05,
      "loss": 0.4858,
      "step": 811550
    },
    {
      "epoch": 8.59196171944887,
      "grad_norm": 1.2458609342575073,
      "learning_rate": 2.9750319492692717e-05,
      "loss": 0.4801,
      "step": 811600
    },
    {
      "epoch": 8.592491041228874,
      "grad_norm": 1.431464433670044,
      "learning_rate": 2.972846882172922e-05,
      "loss": 0.4836,
      "step": 811650
    },
    {
      "epoch": 8.593020363008877,
      "grad_norm": 1.3477469682693481,
      "learning_rate": 2.9706625670755077e-05,
      "loss": 0.4814,
      "step": 811700
    },
    {
      "epoch": 8.59354968478888,
      "grad_norm": 1.2955322265625,
      "learning_rate": 2.968479004051586e-05,
      "loss": 0.4913,
      "step": 811750
    },
    {
      "epoch": 8.594079006568883,
      "grad_norm": 1.2602888345718384,
      "learning_rate": 2.9662961931757188e-05,
      "loss": 0.4793,
      "step": 811800
    },
    {
      "epoch": 8.594608328348887,
      "grad_norm": 1.4931411743164062,
      "learning_rate": 2.9641141345224136e-05,
      "loss": 0.4836,
      "step": 811850
    },
    {
      "epoch": 8.59513765012889,
      "grad_norm": 1.2787185907363892,
      "learning_rate": 2.9619328281661778e-05,
      "loss": 0.4883,
      "step": 811900
    },
    {
      "epoch": 8.595666971908893,
      "grad_norm": 1.3120185136795044,
      "learning_rate": 2.9597522741814653e-05,
      "loss": 0.492,
      "step": 811950
    },
    {
      "epoch": 8.596196293688896,
      "grad_norm": 1.3520007133483887,
      "learning_rate": 2.9575724726427332e-05,
      "loss": 0.4841,
      "step": 812000
    },
    {
      "epoch": 8.596196293688896,
      "eval_loss": 0.29687562584877014,
      "eval_runtime": 46.7962,
      "eval_samples_per_second": 3588.537,
      "eval_steps_per_second": 448.583,
      "step": 812000
    },
    {
      "epoch": 8.5967256154689,
      "grad_norm": 1.4915281534194946,
      "learning_rate": 2.9553934236243863e-05,
      "loss": 0.4823,
      "step": 812050
    },
    {
      "epoch": 8.597254937248904,
      "grad_norm": 1.3609830141067505,
      "learning_rate": 2.953215127200831e-05,
      "loss": 0.4908,
      "step": 812100
    },
    {
      "epoch": 8.597784259028906,
      "grad_norm": 1.2457784414291382,
      "learning_rate": 2.951037583446417e-05,
      "loss": 0.4729,
      "step": 812150
    },
    {
      "epoch": 8.59831358080891,
      "grad_norm": 1.2330856323242188,
      "learning_rate": 2.9488607924355038e-05,
      "loss": 0.4771,
      "step": 812200
    },
    {
      "epoch": 8.598842902588913,
      "grad_norm": 1.5373692512512207,
      "learning_rate": 2.9466847542423876e-05,
      "loss": 0.4865,
      "step": 812250
    },
    {
      "epoch": 8.599372224368917,
      "grad_norm": 1.4277442693710327,
      "learning_rate": 2.9445094689413727e-05,
      "loss": 0.4751,
      "step": 812300
    },
    {
      "epoch": 8.599901546148919,
      "grad_norm": 1.394597053527832,
      "learning_rate": 2.942334936606708e-05,
      "loss": 0.4865,
      "step": 812350
    },
    {
      "epoch": 8.600430867928923,
      "grad_norm": 1.3646875619888306,
      "learning_rate": 2.9401611573126456e-05,
      "loss": 0.4745,
      "step": 812400
    },
    {
      "epoch": 8.600960189708927,
      "grad_norm": 1.4497257471084595,
      "learning_rate": 2.9379881311333873e-05,
      "loss": 0.476,
      "step": 812450
    },
    {
      "epoch": 8.601489511488928,
      "grad_norm": 1.2869049310684204,
      "learning_rate": 2.9358158581431287e-05,
      "loss": 0.4842,
      "step": 812500
    },
    {
      "epoch": 8.601489511488928,
      "eval_loss": 0.29691070318222046,
      "eval_runtime": 46.822,
      "eval_samples_per_second": 3586.565,
      "eval_steps_per_second": 448.337,
      "step": 812500
    },
    {
      "epoch": 8.602018833268932,
      "grad_norm": 1.4042136669158936,
      "learning_rate": 2.9336443384160192e-05,
      "loss": 0.4866,
      "step": 812550
    },
    {
      "epoch": 8.602548155048936,
      "grad_norm": 1.3831993341445923,
      "learning_rate": 2.9314735720262027e-05,
      "loss": 0.4697,
      "step": 812600
    },
    {
      "epoch": 8.60307747682894,
      "grad_norm": 1.3402352333068848,
      "learning_rate": 2.929303559047783e-05,
      "loss": 0.4846,
      "step": 812650
    },
    {
      "epoch": 8.603606798608942,
      "grad_norm": 1.3184717893600464,
      "learning_rate": 2.9271342995548482e-05,
      "loss": 0.4845,
      "step": 812700
    },
    {
      "epoch": 8.604136120388945,
      "grad_norm": 1.1946121454238892,
      "learning_rate": 2.924965793621448e-05,
      "loss": 0.4788,
      "step": 812750
    },
    {
      "epoch": 8.60466544216895,
      "grad_norm": 1.3569085597991943,
      "learning_rate": 2.9227980413216255e-05,
      "loss": 0.4827,
      "step": 812800
    },
    {
      "epoch": 8.605194763948953,
      "grad_norm": 1.485394835472107,
      "learning_rate": 2.920631042729377e-05,
      "loss": 0.4815,
      "step": 812850
    },
    {
      "epoch": 8.605724085728955,
      "grad_norm": 1.3127845525741577,
      "learning_rate": 2.9184647979186933e-05,
      "loss": 0.4773,
      "step": 812900
    },
    {
      "epoch": 8.606253407508959,
      "grad_norm": 1.3412781953811646,
      "learning_rate": 2.9162993069635157e-05,
      "loss": 0.4769,
      "step": 812950
    },
    {
      "epoch": 8.606782729288962,
      "grad_norm": 1.2852061986923218,
      "learning_rate": 2.9141345699377874e-05,
      "loss": 0.4841,
      "step": 813000
    },
    {
      "epoch": 8.606782729288962,
      "eval_loss": 0.29651808738708496,
      "eval_runtime": 46.8289,
      "eval_samples_per_second": 3586.037,
      "eval_steps_per_second": 448.271,
      "step": 813000
    },
    {
      "epoch": 8.607312051068966,
      "grad_norm": 1.3767609596252441,
      "learning_rate": 2.9119705869153994e-05,
      "loss": 0.4812,
      "step": 813050
    },
    {
      "epoch": 8.607841372848968,
      "grad_norm": 1.3791154623031616,
      "learning_rate": 2.9098073579702344e-05,
      "loss": 0.4838,
      "step": 813100
    },
    {
      "epoch": 8.608370694628972,
      "grad_norm": 1.4407097101211548,
      "learning_rate": 2.9076448831761526e-05,
      "loss": 0.4901,
      "step": 813150
    },
    {
      "epoch": 8.608900016408976,
      "grad_norm": 1.4545401334762573,
      "learning_rate": 2.9054831626069644e-05,
      "loss": 0.4773,
      "step": 813200
    },
    {
      "epoch": 8.609429338188978,
      "grad_norm": 1.5417040586471558,
      "learning_rate": 2.9033221963364804e-05,
      "loss": 0.4829,
      "step": 813250
    },
    {
      "epoch": 8.609958659968981,
      "grad_norm": 1.3974465131759644,
      "learning_rate": 2.9011619844384774e-05,
      "loss": 0.4835,
      "step": 813300
    },
    {
      "epoch": 8.610487981748985,
      "grad_norm": 1.1544874906539917,
      "learning_rate": 2.8990025269866937e-05,
      "loss": 0.48,
      "step": 813350
    },
    {
      "epoch": 8.611017303528989,
      "grad_norm": 1.2475916147232056,
      "learning_rate": 2.896843824054862e-05,
      "loss": 0.4823,
      "step": 813400
    },
    {
      "epoch": 8.611546625308991,
      "grad_norm": 1.2494516372680664,
      "learning_rate": 2.894685875716674e-05,
      "loss": 0.4829,
      "step": 813450
    },
    {
      "epoch": 8.612075947088995,
      "grad_norm": 1.4430794715881348,
      "learning_rate": 2.8925286820458085e-05,
      "loss": 0.4884,
      "step": 813500
    },
    {
      "epoch": 8.612075947088995,
      "eval_loss": 0.2965581715106964,
      "eval_runtime": 46.7273,
      "eval_samples_per_second": 3593.834,
      "eval_steps_per_second": 449.245,
      "step": 813500
    },
    {
      "epoch": 8.612605268868998,
      "grad_norm": 1.4445911645889282,
      "learning_rate": 2.890372243115899e-05,
      "loss": 0.4774,
      "step": 813550
    },
    {
      "epoch": 8.613134590649002,
      "grad_norm": 1.4626553058624268,
      "learning_rate": 2.8882165590005784e-05,
      "loss": 0.4747,
      "step": 813600
    },
    {
      "epoch": 8.613663912429004,
      "grad_norm": 1.4851499795913696,
      "learning_rate": 2.8860616297734287e-05,
      "loss": 0.4795,
      "step": 813650
    },
    {
      "epoch": 8.614193234209008,
      "grad_norm": 1.399991512298584,
      "learning_rate": 2.8839074555080337e-05,
      "loss": 0.4768,
      "step": 813700
    },
    {
      "epoch": 8.614722555989012,
      "grad_norm": 1.3634058237075806,
      "learning_rate": 2.88175403627792e-05,
      "loss": 0.4825,
      "step": 813750
    },
    {
      "epoch": 8.615251877769015,
      "grad_norm": 1.3900017738342285,
      "learning_rate": 2.879644418038496e-05,
      "loss": 0.4767,
      "step": 813800
    },
    {
      "epoch": 8.615781199549017,
      "grad_norm": 1.2741563320159912,
      "learning_rate": 2.8774924939951208e-05,
      "loss": 0.4803,
      "step": 813850
    },
    {
      "epoch": 8.616310521329021,
      "grad_norm": 1.242926001548767,
      "learning_rate": 2.8753413252060407e-05,
      "loss": 0.477,
      "step": 813900
    },
    {
      "epoch": 8.616839843109025,
      "grad_norm": 1.1910346746444702,
      "learning_rate": 2.8731909117446884e-05,
      "loss": 0.4828,
      "step": 813950
    },
    {
      "epoch": 8.617369164889027,
      "grad_norm": 1.3729649782180786,
      "learning_rate": 2.871041253684492e-05,
      "loss": 0.4862,
      "step": 814000
    },
    {
      "epoch": 8.617369164889027,
      "eval_loss": 0.2966674864292145,
      "eval_runtime": 46.7931,
      "eval_samples_per_second": 3588.78,
      "eval_steps_per_second": 448.613,
      "step": 814000
    },
    {
      "epoch": 8.61789848666903,
      "grad_norm": 1.3120839595794678,
      "learning_rate": 2.868892351098823e-05,
      "loss": 0.4807,
      "step": 814050
    },
    {
      "epoch": 8.618427808449034,
      "grad_norm": 1.368141770362854,
      "learning_rate": 2.8667442040610586e-05,
      "loss": 0.4862,
      "step": 814100
    },
    {
      "epoch": 8.618957130229038,
      "grad_norm": 1.4186713695526123,
      "learning_rate": 2.8645968126445267e-05,
      "loss": 0.4837,
      "step": 814150
    },
    {
      "epoch": 8.61948645200904,
      "grad_norm": 1.389234185218811,
      "learning_rate": 2.862450176922546e-05,
      "loss": 0.4672,
      "step": 814200
    },
    {
      "epoch": 8.620015773789044,
      "grad_norm": 1.3933651447296143,
      "learning_rate": 2.8603042969683913e-05,
      "loss": 0.4837,
      "step": 814250
    },
    {
      "epoch": 8.620545095569048,
      "grad_norm": 1.4491937160491943,
      "learning_rate": 2.8581591728553346e-05,
      "loss": 0.4827,
      "step": 814300
    },
    {
      "epoch": 8.621074417349051,
      "grad_norm": 1.4099262952804565,
      "learning_rate": 2.856014804656598e-05,
      "loss": 0.4778,
      "step": 814350
    },
    {
      "epoch": 8.621603739129053,
      "grad_norm": 1.3945354223251343,
      "learning_rate": 2.8538711924454007e-05,
      "loss": 0.4792,
      "step": 814400
    },
    {
      "epoch": 8.622133060909057,
      "grad_norm": 1.3735482692718506,
      "learning_rate": 2.851728336294912e-05,
      "loss": 0.484,
      "step": 814450
    },
    {
      "epoch": 8.622662382689061,
      "grad_norm": 1.3301588296890259,
      "learning_rate": 2.849586236278301e-05,
      "loss": 0.4838,
      "step": 814500
    },
    {
      "epoch": 8.622662382689061,
      "eval_loss": 0.2960011065006256,
      "eval_runtime": 46.8785,
      "eval_samples_per_second": 3582.243,
      "eval_steps_per_second": 447.796,
      "step": 814500
    },
    {
      "epoch": 8.623191704469065,
      "grad_norm": 1.460951566696167,
      "learning_rate": 2.8474448924686896e-05,
      "loss": 0.4791,
      "step": 814550
    },
    {
      "epoch": 8.623721026249067,
      "grad_norm": 1.4375370740890503,
      "learning_rate": 2.845304304939189e-05,
      "loss": 0.4803,
      "step": 814600
    },
    {
      "epoch": 8.62425034802907,
      "grad_norm": 1.3875885009765625,
      "learning_rate": 2.8431644737628685e-05,
      "loss": 0.4788,
      "step": 814650
    },
    {
      "epoch": 8.624779669809074,
      "grad_norm": 1.409075140953064,
      "learning_rate": 2.841025399012792e-05,
      "loss": 0.4846,
      "step": 814700
    },
    {
      "epoch": 8.625308991589076,
      "grad_norm": 1.3571504354476929,
      "learning_rate": 2.838887080761979e-05,
      "loss": 0.4805,
      "step": 814750
    },
    {
      "epoch": 8.62583831336908,
      "grad_norm": 1.4754915237426758,
      "learning_rate": 2.836749519083437e-05,
      "loss": 0.4839,
      "step": 814800
    },
    {
      "epoch": 8.626367635149084,
      "grad_norm": 1.417202115058899,
      "learning_rate": 2.8346127140501333e-05,
      "loss": 0.4873,
      "step": 814850
    },
    {
      "epoch": 8.626896956929087,
      "grad_norm": 1.4877212047576904,
      "learning_rate": 2.832476665735026e-05,
      "loss": 0.4813,
      "step": 814900
    },
    {
      "epoch": 8.62742627870909,
      "grad_norm": 1.3704652786254883,
      "learning_rate": 2.8303413742110346e-05,
      "loss": 0.4809,
      "step": 814950
    },
    {
      "epoch": 8.627955600489093,
      "grad_norm": 1.2401278018951416,
      "learning_rate": 2.828206839551059e-05,
      "loss": 0.4804,
      "step": 815000
    },
    {
      "epoch": 8.627955600489093,
      "eval_loss": 0.29634812474250793,
      "eval_runtime": 46.7583,
      "eval_samples_per_second": 3591.452,
      "eval_steps_per_second": 448.947,
      "step": 815000
    },
    {
      "epoch": 8.628484922269097,
      "grad_norm": 1.4283949136734009,
      "learning_rate": 2.826073061827969e-05,
      "loss": 0.4824,
      "step": 815050
    },
    {
      "epoch": 8.6290142440491,
      "grad_norm": 1.2837984561920166,
      "learning_rate": 2.823940041114617e-05,
      "loss": 0.4816,
      "step": 815100
    },
    {
      "epoch": 8.629543565829103,
      "grad_norm": 1.3636698722839355,
      "learning_rate": 2.821807777483812e-05,
      "loss": 0.4875,
      "step": 815150
    },
    {
      "epoch": 8.630072887609106,
      "grad_norm": 1.2213252782821655,
      "learning_rate": 2.8196762710083617e-05,
      "loss": 0.4798,
      "step": 815200
    },
    {
      "epoch": 8.63060220938911,
      "grad_norm": 1.2688242197036743,
      "learning_rate": 2.817545521761025e-05,
      "loss": 0.4815,
      "step": 815250
    },
    {
      "epoch": 8.631131531169114,
      "grad_norm": 1.3114771842956543,
      "learning_rate": 2.815415529814555e-05,
      "loss": 0.4876,
      "step": 815300
    },
    {
      "epoch": 8.631660852949116,
      "grad_norm": 1.419672966003418,
      "learning_rate": 2.813286295241657e-05,
      "loss": 0.4801,
      "step": 815350
    },
    {
      "epoch": 8.63219017472912,
      "grad_norm": 1.324745774269104,
      "learning_rate": 2.811157818115026e-05,
      "loss": 0.4827,
      "step": 815400
    },
    {
      "epoch": 8.632719496509123,
      "grad_norm": 1.5053553581237793,
      "learning_rate": 2.809030098507337e-05,
      "loss": 0.4759,
      "step": 815450
    },
    {
      "epoch": 8.633248818289125,
      "grad_norm": 1.2878339290618896,
      "learning_rate": 2.806903136491215e-05,
      "loss": 0.4832,
      "step": 815500
    },
    {
      "epoch": 8.633248818289125,
      "eval_loss": 0.29583802819252014,
      "eval_runtime": 46.8284,
      "eval_samples_per_second": 3586.07,
      "eval_steps_per_second": 448.275,
      "step": 815500
    },
    {
      "epoch": 8.63377814006913,
      "grad_norm": 1.3716048002243042,
      "learning_rate": 2.804776932139283e-05,
      "loss": 0.4843,
      "step": 815550
    },
    {
      "epoch": 8.634307461849133,
      "grad_norm": 1.4734140634536743,
      "learning_rate": 2.8026514855241325e-05,
      "loss": 0.4878,
      "step": 815600
    },
    {
      "epoch": 8.634836783629137,
      "grad_norm": 1.2359905242919922,
      "learning_rate": 2.800526796718311e-05,
      "loss": 0.4792,
      "step": 815650
    },
    {
      "epoch": 8.635366105409139,
      "grad_norm": 1.3839664459228516,
      "learning_rate": 2.7984028657943723e-05,
      "loss": 0.4811,
      "step": 815700
    },
    {
      "epoch": 8.635895427189142,
      "grad_norm": 1.339138150215149,
      "learning_rate": 2.79627969282481e-05,
      "loss": 0.476,
      "step": 815750
    },
    {
      "epoch": 8.636424748969146,
      "grad_norm": 1.398148536682129,
      "learning_rate": 2.79415727788212e-05,
      "loss": 0.4727,
      "step": 815800
    },
    {
      "epoch": 8.63695407074915,
      "grad_norm": 1.5255824327468872,
      "learning_rate": 2.792035621038755e-05,
      "loss": 0.482,
      "step": 815850
    },
    {
      "epoch": 8.637483392529152,
      "grad_norm": 1.4152634143829346,
      "learning_rate": 2.7899147223671512e-05,
      "loss": 0.4853,
      "step": 815900
    },
    {
      "epoch": 8.638012714309156,
      "grad_norm": 1.2529844045639038,
      "learning_rate": 2.7877945819397094e-05,
      "loss": 0.4749,
      "step": 815950
    },
    {
      "epoch": 8.63854203608916,
      "grad_norm": 1.3069772720336914,
      "learning_rate": 2.7856751998288217e-05,
      "loss": 0.4796,
      "step": 816000
    },
    {
      "epoch": 8.63854203608916,
      "eval_loss": 0.29547959566116333,
      "eval_runtime": 46.6236,
      "eval_samples_per_second": 3601.826,
      "eval_steps_per_second": 450.244,
      "step": 816000
    },
    {
      "epoch": 8.639071357869163,
      "grad_norm": 1.412196397781372,
      "learning_rate": 2.7835565761068298e-05,
      "loss": 0.4811,
      "step": 816050
    },
    {
      "epoch": 8.639600679649165,
      "grad_norm": 1.3718453645706177,
      "learning_rate": 2.781438710846071e-05,
      "loss": 0.4749,
      "step": 816100
    },
    {
      "epoch": 8.640130001429169,
      "grad_norm": 1.1574164628982544,
      "learning_rate": 2.779321604118845e-05,
      "loss": 0.4798,
      "step": 816150
    },
    {
      "epoch": 8.640659323209173,
      "grad_norm": 1.3407822847366333,
      "learning_rate": 2.7772052559974335e-05,
      "loss": 0.4792,
      "step": 816200
    },
    {
      "epoch": 8.641188644989175,
      "grad_norm": 1.3696184158325195,
      "learning_rate": 2.7750896665540788e-05,
      "loss": 0.4718,
      "step": 816250
    },
    {
      "epoch": 8.641717966769178,
      "grad_norm": 1.52877676486969,
      "learning_rate": 2.772974835861017e-05,
      "loss": 0.485,
      "step": 816300
    },
    {
      "epoch": 8.642247288549182,
      "grad_norm": 1.395680546760559,
      "learning_rate": 2.7708607639904403e-05,
      "loss": 0.4755,
      "step": 816350
    },
    {
      "epoch": 8.642776610329186,
      "grad_norm": 1.4423363208770752,
      "learning_rate": 2.768747451014528e-05,
      "loss": 0.4882,
      "step": 816400
    },
    {
      "epoch": 8.643305932109188,
      "grad_norm": 1.198696494102478,
      "learning_rate": 2.7666348970054184e-05,
      "loss": 0.476,
      "step": 816450
    },
    {
      "epoch": 8.643835253889192,
      "grad_norm": 1.3121544122695923,
      "learning_rate": 2.7645231020352463e-05,
      "loss": 0.4814,
      "step": 816500
    },
    {
      "epoch": 8.643835253889192,
      "eval_loss": 0.296099990606308,
      "eval_runtime": 46.7584,
      "eval_samples_per_second": 3591.442,
      "eval_steps_per_second": 448.946,
      "step": 816500
    },
    {
      "epoch": 8.644364575669195,
      "grad_norm": 1.2043484449386597,
      "learning_rate": 2.7624120661760953e-05,
      "loss": 0.4872,
      "step": 816550
    },
    {
      "epoch": 8.6448938974492,
      "grad_norm": 1.3947079181671143,
      "learning_rate": 2.760301789500047e-05,
      "loss": 0.4826,
      "step": 816600
    },
    {
      "epoch": 8.645423219229201,
      "grad_norm": 1.3412573337554932,
      "learning_rate": 2.7581922720791324e-05,
      "loss": 0.4773,
      "step": 816650
    },
    {
      "epoch": 8.645952541009205,
      "grad_norm": 1.4682197570800781,
      "learning_rate": 2.7560835139853828e-05,
      "loss": 0.4756,
      "step": 816700
    },
    {
      "epoch": 8.646481862789209,
      "grad_norm": 1.498034119606018,
      "learning_rate": 2.7539755152907797e-05,
      "loss": 0.4781,
      "step": 816750
    },
    {
      "epoch": 8.647011184569212,
      "grad_norm": 1.5160608291625977,
      "learning_rate": 2.7518682760672987e-05,
      "loss": 0.4754,
      "step": 816800
    },
    {
      "epoch": 8.647540506349214,
      "grad_norm": 1.4343324899673462,
      "learning_rate": 2.749761796386871e-05,
      "loss": 0.4792,
      "step": 816850
    },
    {
      "epoch": 8.648069828129218,
      "grad_norm": 1.3836926221847534,
      "learning_rate": 2.7476560763214197e-05,
      "loss": 0.4789,
      "step": 816900
    },
    {
      "epoch": 8.648599149909222,
      "grad_norm": 1.3224607706069946,
      "learning_rate": 2.7455511159428265e-05,
      "loss": 0.4781,
      "step": 816950
    },
    {
      "epoch": 8.649128471689224,
      "grad_norm": 1.3758578300476074,
      "learning_rate": 2.743446915322953e-05,
      "loss": 0.4795,
      "step": 817000
    },
    {
      "epoch": 8.649128471689224,
      "eval_loss": 0.29624059796333313,
      "eval_runtime": 46.7693,
      "eval_samples_per_second": 3590.606,
      "eval_steps_per_second": 448.842,
      "step": 817000
    },
    {
      "epoch": 8.649657793469228,
      "grad_norm": 1.5842491388320923,
      "learning_rate": 2.7413434745336475e-05,
      "loss": 0.4932,
      "step": 817050
    },
    {
      "epoch": 8.650187115249231,
      "grad_norm": 1.2752134799957275,
      "learning_rate": 2.739240793646705e-05,
      "loss": 0.485,
      "step": 817100
    },
    {
      "epoch": 8.650716437029235,
      "grad_norm": 1.2690930366516113,
      "learning_rate": 2.7371388727339186e-05,
      "loss": 0.4824,
      "step": 817150
    },
    {
      "epoch": 8.651245758809237,
      "grad_norm": 1.428890347480774,
      "learning_rate": 2.7350377118670527e-05,
      "loss": 0.4842,
      "step": 817200
    },
    {
      "epoch": 8.65177508058924,
      "grad_norm": 1.369072437286377,
      "learning_rate": 2.732937311117828e-05,
      "loss": 0.4827,
      "step": 817250
    },
    {
      "epoch": 8.652304402369245,
      "grad_norm": 1.4327524900436401,
      "learning_rate": 2.730837670557962e-05,
      "loss": 0.4782,
      "step": 817300
    },
    {
      "epoch": 8.652833724149248,
      "grad_norm": 1.27344810962677,
      "learning_rate": 2.7287387902591275e-05,
      "loss": 0.4858,
      "step": 817350
    },
    {
      "epoch": 8.65336304592925,
      "grad_norm": 1.305937647819519,
      "learning_rate": 2.7266406702929848e-05,
      "loss": 0.4796,
      "step": 817400
    },
    {
      "epoch": 8.653892367709254,
      "grad_norm": 1.2861084938049316,
      "learning_rate": 2.724543310731159e-05,
      "loss": 0.4829,
      "step": 817450
    },
    {
      "epoch": 8.654421689489258,
      "grad_norm": Infinity,
      "learning_rate": 2.722488636173853e-05,
      "loss": 0.4834,
      "step": 817500
    },
    {
      "epoch": 8.654421689489258,
      "eval_loss": 0.296055406332016,
      "eval_runtime": 46.6412,
      "eval_samples_per_second": 3600.462,
      "eval_steps_per_second": 450.074,
      "step": 817500
    },
    {
      "epoch": 8.654951011269262,
      "grad_norm": 1.3462786674499512,
      "learning_rate": 2.7203927824237945e-05,
      "loss": 0.4794,
      "step": 817550
    },
    {
      "epoch": 8.655480333049264,
      "grad_norm": 1.4304769039154053,
      "learning_rate": 2.7182976892913576e-05,
      "loss": 0.4879,
      "step": 817600
    },
    {
      "epoch": 8.656009654829267,
      "grad_norm": 1.3756208419799805,
      "learning_rate": 2.716203356848071e-05,
      "loss": 0.4835,
      "step": 817650
    },
    {
      "epoch": 8.656538976609271,
      "grad_norm": 1.386473298072815,
      "learning_rate": 2.714109785165425e-05,
      "loss": 0.4813,
      "step": 817700
    },
    {
      "epoch": 8.657068298389273,
      "grad_norm": 1.4087369441986084,
      "learning_rate": 2.7120169743149015e-05,
      "loss": 0.4738,
      "step": 817750
    },
    {
      "epoch": 8.657597620169277,
      "grad_norm": 1.3621333837509155,
      "learning_rate": 2.7099249243679402e-05,
      "loss": 0.4803,
      "step": 817800
    },
    {
      "epoch": 8.65812694194928,
      "grad_norm": 1.421240210533142,
      "learning_rate": 2.707833635395973e-05,
      "loss": 0.4755,
      "step": 817850
    },
    {
      "epoch": 8.658656263729284,
      "grad_norm": 1.5196971893310547,
      "learning_rate": 2.7057431074703848e-05,
      "loss": 0.4838,
      "step": 817900
    },
    {
      "epoch": 8.659185585509286,
      "grad_norm": 1.4277074337005615,
      "learning_rate": 2.703653340662554e-05,
      "loss": 0.4844,
      "step": 817950
    },
    {
      "epoch": 8.65971490728929,
      "grad_norm": 1.3023996353149414,
      "learning_rate": 2.7015643350438185e-05,
      "loss": 0.4764,
      "step": 818000
    },
    {
      "epoch": 8.65971490728929,
      "eval_loss": 0.2957529127597809,
      "eval_runtime": 46.7752,
      "eval_samples_per_second": 3590.15,
      "eval_steps_per_second": 448.785,
      "step": 818000
    },
    {
      "epoch": 8.660244229069294,
      "grad_norm": 1.3833131790161133,
      "learning_rate": 2.6994760906855013e-05,
      "loss": 0.486,
      "step": 818050
    },
    {
      "epoch": 8.660773550849298,
      "grad_norm": 1.5241674184799194,
      "learning_rate": 2.6973886076588907e-05,
      "loss": 0.471,
      "step": 818100
    },
    {
      "epoch": 8.6613028726293,
      "grad_norm": 1.5008931159973145,
      "learning_rate": 2.6953018860352564e-05,
      "loss": 0.4785,
      "step": 818150
    },
    {
      "epoch": 8.661832194409303,
      "grad_norm": 1.4766243696212769,
      "learning_rate": 2.6932159258858307e-05,
      "loss": 0.4739,
      "step": 818200
    },
    {
      "epoch": 8.662361516189307,
      "grad_norm": 1.4027822017669678,
      "learning_rate": 2.6911307272818376e-05,
      "loss": 0.4792,
      "step": 818250
    },
    {
      "epoch": 8.66289083796931,
      "grad_norm": 1.3646363019943237,
      "learning_rate": 2.689046290294453e-05,
      "loss": 0.4821,
      "step": 818300
    },
    {
      "epoch": 8.663420159749313,
      "grad_norm": 1.3492012023925781,
      "learning_rate": 2.6869626149948534e-05,
      "loss": 0.4813,
      "step": 818350
    },
    {
      "epoch": 8.663949481529317,
      "grad_norm": 1.2838441133499146,
      "learning_rate": 2.6848797014541626e-05,
      "loss": 0.4752,
      "step": 818400
    },
    {
      "epoch": 8.66447880330932,
      "grad_norm": 1.391838788986206,
      "learning_rate": 2.6827975497434985e-05,
      "loss": 0.4851,
      "step": 818450
    },
    {
      "epoch": 8.665008125089322,
      "grad_norm": 1.38668692111969,
      "learning_rate": 2.680716159933935e-05,
      "loss": 0.4855,
      "step": 818500
    },
    {
      "epoch": 8.665008125089322,
      "eval_loss": 0.29579615592956543,
      "eval_runtime": 46.9539,
      "eval_samples_per_second": 3576.487,
      "eval_steps_per_second": 447.077,
      "step": 818500
    },
    {
      "epoch": 8.665537446869326,
      "grad_norm": 1.4297893047332764,
      "learning_rate": 2.6786355320965434e-05,
      "loss": 0.4823,
      "step": 818550
    },
    {
      "epoch": 8.66606676864933,
      "grad_norm": 1.45025634765625,
      "learning_rate": 2.6765556663023438e-05,
      "loss": 0.4792,
      "step": 818600
    },
    {
      "epoch": 8.666596090429334,
      "grad_norm": 1.4368795156478882,
      "learning_rate": 2.6744765626223522e-05,
      "loss": 0.481,
      "step": 818650
    },
    {
      "epoch": 8.667125412209336,
      "grad_norm": 1.3469215631484985,
      "learning_rate": 2.6723982211275365e-05,
      "loss": 0.4828,
      "step": 818700
    },
    {
      "epoch": 8.66765473398934,
      "grad_norm": 1.2496668100357056,
      "learning_rate": 2.6703206418888626e-05,
      "loss": 0.48,
      "step": 818750
    },
    {
      "epoch": 8.668184055769343,
      "grad_norm": 1.4326423406600952,
      "learning_rate": 2.6682438249772484e-05,
      "loss": 0.4798,
      "step": 818800
    },
    {
      "epoch": 8.668713377549347,
      "grad_norm": 1.3991727828979492,
      "learning_rate": 2.666167770463604e-05,
      "loss": 0.4789,
      "step": 818850
    },
    {
      "epoch": 8.669242699329349,
      "grad_norm": 1.4389346837997437,
      "learning_rate": 2.6640924784187975e-05,
      "loss": 0.482,
      "step": 818900
    },
    {
      "epoch": 8.669772021109353,
      "grad_norm": 1.3846622705459595,
      "learning_rate": 2.6620179489136864e-05,
      "loss": 0.483,
      "step": 818950
    },
    {
      "epoch": 8.670301342889356,
      "grad_norm": 1.3755451440811157,
      "learning_rate": 2.6599441820190863e-05,
      "loss": 0.4791,
      "step": 819000
    },
    {
      "epoch": 8.670301342889356,
      "eval_loss": 0.29575085639953613,
      "eval_runtime": 46.8128,
      "eval_samples_per_second": 3587.268,
      "eval_steps_per_second": 448.425,
      "step": 819000
    },
    {
      "epoch": 8.67083066466936,
      "grad_norm": 1.3906657695770264,
      "learning_rate": 2.6578711778057984e-05,
      "loss": 0.481,
      "step": 819050
    },
    {
      "epoch": 8.671359986449362,
      "grad_norm": 1.4111316204071045,
      "learning_rate": 2.6557989363446e-05,
      "loss": 0.4845,
      "step": 819100
    },
    {
      "epoch": 8.671889308229366,
      "grad_norm": 1.430688500404358,
      "learning_rate": 2.653727457706226e-05,
      "loss": 0.4671,
      "step": 819150
    },
    {
      "epoch": 8.67241863000937,
      "grad_norm": 1.3888477087020874,
      "learning_rate": 2.6516567419614057e-05,
      "loss": 0.476,
      "step": 819200
    },
    {
      "epoch": 8.672947951789372,
      "grad_norm": 1.250419020652771,
      "learning_rate": 2.6495867891808245e-05,
      "loss": 0.478,
      "step": 819250
    },
    {
      "epoch": 8.673477273569375,
      "grad_norm": 1.5505675077438354,
      "learning_rate": 2.6475175994351535e-05,
      "loss": 0.4769,
      "step": 819300
    },
    {
      "epoch": 8.674006595349379,
      "grad_norm": 1.3688758611679077,
      "learning_rate": 2.6454491727950365e-05,
      "loss": 0.485,
      "step": 819350
    },
    {
      "epoch": 8.674535917129383,
      "grad_norm": 1.3563640117645264,
      "learning_rate": 2.6433815093310832e-05,
      "loss": 0.4782,
      "step": 819400
    },
    {
      "epoch": 8.675065238909385,
      "grad_norm": 1.3917064666748047,
      "learning_rate": 2.6413146091138928e-05,
      "loss": 0.4885,
      "step": 819450
    },
    {
      "epoch": 8.675594560689389,
      "grad_norm": 1.47783362865448,
      "learning_rate": 2.6392484722140146e-05,
      "loss": 0.4807,
      "step": 819500
    },
    {
      "epoch": 8.675594560689389,
      "eval_loss": 0.2959724962711334,
      "eval_runtime": 46.8281,
      "eval_samples_per_second": 3586.091,
      "eval_steps_per_second": 448.277,
      "step": 819500
    },
    {
      "epoch": 8.676123882469392,
      "grad_norm": 1.3488438129425049,
      "learning_rate": 2.6371830987019978e-05,
      "loss": 0.4794,
      "step": 819550
    },
    {
      "epoch": 8.676653204249396,
      "grad_norm": 1.292842149734497,
      "learning_rate": 2.6351184886483472e-05,
      "loss": 0.4844,
      "step": 819600
    },
    {
      "epoch": 8.677182526029398,
      "grad_norm": 1.4259233474731445,
      "learning_rate": 2.6330546421235503e-05,
      "loss": 0.471,
      "step": 819650
    },
    {
      "epoch": 8.677711847809402,
      "grad_norm": 1.4471756219863892,
      "learning_rate": 2.6310328133728438e-05,
      "loss": 0.4791,
      "step": 819700
    },
    {
      "epoch": 8.678241169589406,
      "grad_norm": 1.3478986024856567,
      "learning_rate": 2.628970478843015e-05,
      "loss": 0.4847,
      "step": 819750
    },
    {
      "epoch": 8.67877049136941,
      "grad_norm": 1.4000812768936157,
      "learning_rate": 2.626908908051931e-05,
      "loss": 0.472,
      "step": 819800
    },
    {
      "epoch": 8.679299813149411,
      "grad_norm": 1.333728313446045,
      "learning_rate": 2.6248481010699736e-05,
      "loss": 0.4793,
      "step": 819850
    },
    {
      "epoch": 8.679829134929415,
      "grad_norm": 1.471203327178955,
      "learning_rate": 2.6227880579674928e-05,
      "loss": 0.4768,
      "step": 819900
    },
    {
      "epoch": 8.680358456709419,
      "grad_norm": 1.3819160461425781,
      "learning_rate": 2.6207287788148264e-05,
      "loss": 0.4895,
      "step": 819950
    },
    {
      "epoch": 8.68088777848942,
      "grad_norm": 1.357454776763916,
      "learning_rate": 2.6186702636822656e-05,
      "loss": 0.4816,
      "step": 820000
    },
    {
      "epoch": 8.68088777848942,
      "eval_loss": 0.2956486642360687,
      "eval_runtime": 46.7838,
      "eval_samples_per_second": 3589.49,
      "eval_steps_per_second": 448.702,
      "step": 820000
    },
    {
      "epoch": 8.681417100269424,
      "grad_norm": 1.4135897159576416,
      "learning_rate": 2.6166125126401014e-05,
      "loss": 0.479,
      "step": 820050
    },
    {
      "epoch": 8.681946422049428,
      "grad_norm": 1.3870247602462769,
      "learning_rate": 2.6145555257585717e-05,
      "loss": 0.4824,
      "step": 820100
    },
    {
      "epoch": 8.682475743829432,
      "grad_norm": 1.3823907375335693,
      "learning_rate": 2.6124993031079098e-05,
      "loss": 0.485,
      "step": 820150
    },
    {
      "epoch": 8.683005065609434,
      "grad_norm": 1.3161897659301758,
      "learning_rate": 2.6104438447583062e-05,
      "loss": 0.4795,
      "step": 820200
    },
    {
      "epoch": 8.683534387389438,
      "grad_norm": 1.3305529356002808,
      "learning_rate": 2.608389150779947e-05,
      "loss": 0.4816,
      "step": 820250
    },
    {
      "epoch": 8.684063709169441,
      "grad_norm": 1.3281675577163696,
      "learning_rate": 2.6063352212429613e-05,
      "loss": 0.4686,
      "step": 820300
    },
    {
      "epoch": 8.684593030949445,
      "grad_norm": 1.4282349348068237,
      "learning_rate": 2.6042820562174858e-05,
      "loss": 0.4853,
      "step": 820350
    },
    {
      "epoch": 8.685122352729447,
      "grad_norm": 1.3623466491699219,
      "learning_rate": 2.6022296557736026e-05,
      "loss": 0.4801,
      "step": 820400
    },
    {
      "epoch": 8.685651674509451,
      "grad_norm": 1.3652821779251099,
      "learning_rate": 2.600178019981389e-05,
      "loss": 0.4695,
      "step": 820450
    },
    {
      "epoch": 8.686180996289455,
      "grad_norm": 1.4587984085083008,
      "learning_rate": 2.5981271489108783e-05,
      "loss": 0.477,
      "step": 820500
    },
    {
      "epoch": 8.686180996289455,
      "eval_loss": 0.295519083738327,
      "eval_runtime": 46.7836,
      "eval_samples_per_second": 3589.507,
      "eval_steps_per_second": 448.704,
      "step": 820500
    },
    {
      "epoch": 8.686710318069458,
      "grad_norm": 1.4299097061157227,
      "learning_rate": 2.5960770426320944e-05,
      "loss": 0.4776,
      "step": 820550
    },
    {
      "epoch": 8.68723963984946,
      "grad_norm": 1.3561662435531616,
      "learning_rate": 2.594027701215021e-05,
      "loss": 0.4794,
      "step": 820600
    },
    {
      "epoch": 8.687768961629464,
      "grad_norm": 1.483881950378418,
      "learning_rate": 2.5919791247296294e-05,
      "loss": 0.4772,
      "step": 820650
    },
    {
      "epoch": 8.688298283409468,
      "grad_norm": 1.332316279411316,
      "learning_rate": 2.5899313132458467e-05,
      "loss": 0.481,
      "step": 820700
    },
    {
      "epoch": 8.68882760518947,
      "grad_norm": 1.456438422203064,
      "learning_rate": 2.5878842668335957e-05,
      "loss": 0.4805,
      "step": 820750
    },
    {
      "epoch": 8.689356926969474,
      "grad_norm": 1.1765669584274292,
      "learning_rate": 2.58583798556275e-05,
      "loss": 0.4781,
      "step": 820800
    },
    {
      "epoch": 8.689886248749477,
      "grad_norm": 1.5017220973968506,
      "learning_rate": 2.5837924695031822e-05,
      "loss": 0.4908,
      "step": 820850
    },
    {
      "epoch": 8.690415570529481,
      "grad_norm": 1.534686803817749,
      "learning_rate": 2.581747718724714e-05,
      "loss": 0.4732,
      "step": 820900
    },
    {
      "epoch": 8.690944892309483,
      "grad_norm": 1.5140812397003174,
      "learning_rate": 2.5797037332971618e-05,
      "loss": 0.4847,
      "step": 820950
    },
    {
      "epoch": 8.691474214089487,
      "grad_norm": 1.30840003490448,
      "learning_rate": 2.5776605132902946e-05,
      "loss": 0.4758,
      "step": 821000
    },
    {
      "epoch": 8.691474214089487,
      "eval_loss": 0.29530858993530273,
      "eval_runtime": 46.7599,
      "eval_samples_per_second": 3591.324,
      "eval_steps_per_second": 448.932,
      "step": 821000
    },
    {
      "epoch": 8.69200353586949,
      "grad_norm": 1.4772319793701172,
      "learning_rate": 2.575618058773882e-05,
      "loss": 0.4833,
      "step": 821050
    },
    {
      "epoch": 8.692532857649494,
      "grad_norm": 1.383543848991394,
      "learning_rate": 2.5735763698176374e-05,
      "loss": 0.4748,
      "step": 821100
    },
    {
      "epoch": 8.693062179429496,
      "grad_norm": 1.5368460416793823,
      "learning_rate": 2.571535446491277e-05,
      "loss": 0.4763,
      "step": 821150
    },
    {
      "epoch": 8.6935915012095,
      "grad_norm": 1.2959338426589966,
      "learning_rate": 2.569495288864468e-05,
      "loss": 0.4869,
      "step": 821200
    },
    {
      "epoch": 8.694120822989504,
      "grad_norm": 1.4840790033340454,
      "learning_rate": 2.567455897006868e-05,
      "loss": 0.4787,
      "step": 821250
    },
    {
      "epoch": 8.694650144769508,
      "grad_norm": 1.3036285638809204,
      "learning_rate": 2.5654172709880907e-05,
      "loss": 0.471,
      "step": 821300
    },
    {
      "epoch": 8.69517946654951,
      "grad_norm": 1.2569425106048584,
      "learning_rate": 2.5633794108777393e-05,
      "loss": 0.4782,
      "step": 821350
    },
    {
      "epoch": 8.695708788329513,
      "grad_norm": 1.2969281673431396,
      "learning_rate": 2.5613423167453908e-05,
      "loss": 0.4772,
      "step": 821400
    },
    {
      "epoch": 8.696238110109517,
      "grad_norm": 1.4319612979888916,
      "learning_rate": 2.5593059886605847e-05,
      "loss": 0.4861,
      "step": 821450
    },
    {
      "epoch": 8.69676743188952,
      "grad_norm": 1.5028960704803467,
      "learning_rate": 2.5572704266928397e-05,
      "loss": 0.4788,
      "step": 821500
    },
    {
      "epoch": 8.69676743188952,
      "eval_loss": 0.2953472435474396,
      "eval_runtime": 46.7002,
      "eval_samples_per_second": 3595.913,
      "eval_steps_per_second": 449.505,
      "step": 821500
    },
    {
      "epoch": 8.697296753669523,
      "grad_norm": 1.3502801656723022,
      "learning_rate": 2.5552356309116593e-05,
      "loss": 0.4738,
      "step": 821550
    },
    {
      "epoch": 8.697826075449527,
      "grad_norm": 1.4138108491897583,
      "learning_rate": 2.5532016013864956e-05,
      "loss": 0.493,
      "step": 821600
    },
    {
      "epoch": 8.69835539722953,
      "grad_norm": 1.3848596811294556,
      "learning_rate": 2.5511683381868018e-05,
      "loss": 0.4761,
      "step": 821650
    },
    {
      "epoch": 8.698884719009532,
      "grad_norm": 1.3005177974700928,
      "learning_rate": 2.549135841381986e-05,
      "loss": 0.4847,
      "step": 821700
    },
    {
      "epoch": 8.699414040789536,
      "grad_norm": 1.3385114669799805,
      "learning_rate": 2.54710411104144e-05,
      "loss": 0.4854,
      "step": 821750
    },
    {
      "epoch": 8.69994336256954,
      "grad_norm": 1.3506842851638794,
      "learning_rate": 2.5451137589981855e-05,
      "loss": 0.4776,
      "step": 821800
    },
    {
      "epoch": 8.700472684349544,
      "grad_norm": 1.3805968761444092,
      "learning_rate": 2.5430835464615e-05,
      "loss": 0.4834,
      "step": 821850
    },
    {
      "epoch": 8.701002006129546,
      "grad_norm": 1.2574515342712402,
      "learning_rate": 2.541054100595705e-05,
      "loss": 0.4888,
      "step": 821900
    },
    {
      "epoch": 8.70153132790955,
      "grad_norm": 1.5575017929077148,
      "learning_rate": 2.5390254214700843e-05,
      "loss": 0.4861,
      "step": 821950
    },
    {
      "epoch": 8.702060649689553,
      "grad_norm": 1.3329616785049438,
      "learning_rate": 2.5369975091539045e-05,
      "loss": 0.477,
      "step": 822000
    },
    {
      "epoch": 8.702060649689553,
      "eval_loss": 0.2952535152435303,
      "eval_runtime": 46.7901,
      "eval_samples_per_second": 3589.008,
      "eval_steps_per_second": 448.642,
      "step": 822000
    },
    {
      "epoch": 8.702589971469557,
      "grad_norm": 1.3627703189849854,
      "learning_rate": 2.5349703637163852e-05,
      "loss": 0.4717,
      "step": 822050
    },
    {
      "epoch": 8.703119293249559,
      "grad_norm": 1.2948516607284546,
      "learning_rate": 2.5329439852267433e-05,
      "loss": 0.4858,
      "step": 822100
    },
    {
      "epoch": 8.703648615029563,
      "grad_norm": 1.3998064994812012,
      "learning_rate": 2.5309183737541513e-05,
      "loss": 0.4785,
      "step": 822150
    },
    {
      "epoch": 8.704177936809566,
      "grad_norm": 1.2446715831756592,
      "learning_rate": 2.5288935293677707e-05,
      "loss": 0.4777,
      "step": 822200
    },
    {
      "epoch": 8.704707258589568,
      "grad_norm": 1.4896079301834106,
      "learning_rate": 2.526869452136718e-05,
      "loss": 0.4848,
      "step": 822250
    },
    {
      "epoch": 8.705236580369572,
      "grad_norm": 1.4355148077011108,
      "learning_rate": 2.524846142130105e-05,
      "loss": 0.4874,
      "step": 822300
    },
    {
      "epoch": 8.705765902149576,
      "grad_norm": 1.487313151359558,
      "learning_rate": 2.5228235994169986e-05,
      "loss": 0.4689,
      "step": 822350
    },
    {
      "epoch": 8.70629522392958,
      "grad_norm": 1.2694458961486816,
      "learning_rate": 2.5208018240664543e-05,
      "loss": 0.477,
      "step": 822400
    },
    {
      "epoch": 8.706824545709582,
      "grad_norm": 1.2989338636398315,
      "learning_rate": 2.5187808161474866e-05,
      "loss": 0.4685,
      "step": 822450
    },
    {
      "epoch": 8.707353867489585,
      "grad_norm": 1.3737365007400513,
      "learning_rate": 2.5167605757291046e-05,
      "loss": 0.486,
      "step": 822500
    },
    {
      "epoch": 8.707353867489585,
      "eval_loss": 0.29545167088508606,
      "eval_runtime": 46.8878,
      "eval_samples_per_second": 3581.532,
      "eval_steps_per_second": 447.707,
      "step": 822500
    },
    {
      "epoch": 8.70788318926959,
      "grad_norm": 1.3911921977996826,
      "learning_rate": 2.5147411028802636e-05,
      "loss": 0.4805,
      "step": 822550
    },
    {
      "epoch": 8.708412511049593,
      "grad_norm": 1.4360990524291992,
      "learning_rate": 2.5127223976699226e-05,
      "loss": 0.4786,
      "step": 822600
    },
    {
      "epoch": 8.708941832829595,
      "grad_norm": 1.4477018117904663,
      "learning_rate": 2.510704460166985e-05,
      "loss": 0.4736,
      "step": 822650
    },
    {
      "epoch": 8.709471154609599,
      "grad_norm": 1.3010480403900146,
      "learning_rate": 2.5086872904403534e-05,
      "loss": 0.4819,
      "step": 822700
    },
    {
      "epoch": 8.710000476389602,
      "grad_norm": 1.4471104145050049,
      "learning_rate": 2.5066708885588874e-05,
      "loss": 0.4715,
      "step": 822750
    },
    {
      "epoch": 8.710529798169606,
      "grad_norm": 1.4911787509918213,
      "learning_rate": 2.5046552545914314e-05,
      "loss": 0.4757,
      "step": 822800
    },
    {
      "epoch": 8.711059119949608,
      "grad_norm": 1.4531445503234863,
      "learning_rate": 2.5026403886067888e-05,
      "loss": 0.4796,
      "step": 822850
    },
    {
      "epoch": 8.711588441729612,
      "grad_norm": 1.1679004430770874,
      "learning_rate": 2.5006262906737604e-05,
      "loss": 0.4786,
      "step": 822900
    },
    {
      "epoch": 8.712117763509616,
      "grad_norm": 1.3761414289474487,
      "learning_rate": 2.4986129608610937e-05,
      "loss": 0.4752,
      "step": 822950
    },
    {
      "epoch": 8.712647085289618,
      "grad_norm": 1.3970515727996826,
      "learning_rate": 2.4966003992375306e-05,
      "loss": 0.4826,
      "step": 823000
    },
    {
      "epoch": 8.712647085289618,
      "eval_loss": 0.2951101064682007,
      "eval_runtime": 46.8778,
      "eval_samples_per_second": 3582.293,
      "eval_steps_per_second": 447.803,
      "step": 823000
    },
    {
      "epoch": 8.713176407069621,
      "grad_norm": 1.3049087524414062,
      "learning_rate": 2.4945886058717753e-05,
      "loss": 0.4741,
      "step": 823050
    },
    {
      "epoch": 8.713705728849625,
      "grad_norm": 1.2684229612350464,
      "learning_rate": 2.492577580832514e-05,
      "loss": 0.482,
      "step": 823100
    },
    {
      "epoch": 8.714235050629629,
      "grad_norm": 1.3799643516540527,
      "learning_rate": 2.4905673241883947e-05,
      "loss": 0.4814,
      "step": 823150
    },
    {
      "epoch": 8.71476437240963,
      "grad_norm": 1.4284957647323608,
      "learning_rate": 2.4885578360080595e-05,
      "loss": 0.4799,
      "step": 823200
    },
    {
      "epoch": 8.715293694189635,
      "grad_norm": 1.4649171829223633,
      "learning_rate": 2.4865491163600958e-05,
      "loss": 0.4821,
      "step": 823250
    },
    {
      "epoch": 8.715823015969638,
      "grad_norm": 1.2607851028442383,
      "learning_rate": 2.484541165313095e-05,
      "loss": 0.4792,
      "step": 823300
    },
    {
      "epoch": 8.716352337749642,
      "grad_norm": 1.4325991868972778,
      "learning_rate": 2.4825339829355974e-05,
      "loss": 0.4854,
      "step": 823350
    },
    {
      "epoch": 8.716881659529644,
      "grad_norm": 1.1897614002227783,
      "learning_rate": 2.480527569296129e-05,
      "loss": 0.4781,
      "step": 823400
    },
    {
      "epoch": 8.717410981309648,
      "grad_norm": 1.374206781387329,
      "learning_rate": 2.4785219244631978e-05,
      "loss": 0.4771,
      "step": 823450
    },
    {
      "epoch": 8.717940303089652,
      "grad_norm": 1.3525047302246094,
      "learning_rate": 2.476517048505264e-05,
      "loss": 0.4719,
      "step": 823500
    },
    {
      "epoch": 8.717940303089652,
      "eval_loss": 0.2952350974082947,
      "eval_runtime": 46.8563,
      "eval_samples_per_second": 3583.934,
      "eval_steps_per_second": 448.008,
      "step": 823500
    },
    {
      "epoch": 8.718469624869655,
      "grad_norm": 1.4484087228775024,
      "learning_rate": 2.474512941490778e-05,
      "loss": 0.4833,
      "step": 823550
    },
    {
      "epoch": 8.718998946649657,
      "grad_norm": 1.2702982425689697,
      "learning_rate": 2.4725096034881627e-05,
      "loss": 0.4791,
      "step": 823600
    },
    {
      "epoch": 8.719528268429661,
      "grad_norm": 1.4347251653671265,
      "learning_rate": 2.4705070345658025e-05,
      "loss": 0.4818,
      "step": 823650
    },
    {
      "epoch": 8.720057590209665,
      "grad_norm": 1.3930295705795288,
      "learning_rate": 2.4685052347920762e-05,
      "loss": 0.473,
      "step": 823700
    },
    {
      "epoch": 8.720586911989667,
      "grad_norm": 1.4289333820343018,
      "learning_rate": 2.466504204235312e-05,
      "loss": 0.4881,
      "step": 823750
    },
    {
      "epoch": 8.72111623376967,
      "grad_norm": 1.3826067447662354,
      "learning_rate": 2.46454394064983e-05,
      "loss": 0.4806,
      "step": 823800
    },
    {
      "epoch": 8.721645555549674,
      "grad_norm": 1.4427036046981812,
      "learning_rate": 2.462544433344177e-05,
      "loss": 0.4779,
      "step": 823850
    },
    {
      "epoch": 8.722174877329678,
      "grad_norm": 1.4362061023712158,
      "learning_rate": 2.460545695458999e-05,
      "loss": 0.4685,
      "step": 823900
    },
    {
      "epoch": 8.72270419910968,
      "grad_norm": 1.3271284103393555,
      "learning_rate": 2.458547727062521e-05,
      "loss": 0.4788,
      "step": 823950
    },
    {
      "epoch": 8.723233520889684,
      "grad_norm": 1.4309622049331665,
      "learning_rate": 2.4565505282229532e-05,
      "loss": 0.4794,
      "step": 824000
    },
    {
      "epoch": 8.723233520889684,
      "eval_loss": 0.294708788394928,
      "eval_runtime": 46.8089,
      "eval_samples_per_second": 3587.569,
      "eval_steps_per_second": 448.462,
      "step": 824000
    },
    {
      "epoch": 8.723762842669688,
      "grad_norm": 1.4005732536315918,
      "learning_rate": 2.454554099008491e-05,
      "loss": 0.4823,
      "step": 824050
    },
    {
      "epoch": 8.724292164449691,
      "grad_norm": 1.3444372415542603,
      "learning_rate": 2.4525584394872764e-05,
      "loss": 0.4811,
      "step": 824100
    },
    {
      "epoch": 8.724821486229693,
      "grad_norm": 1.3564163446426392,
      "learning_rate": 2.4505635497274555e-05,
      "loss": 0.4737,
      "step": 824150
    },
    {
      "epoch": 8.725350808009697,
      "grad_norm": 1.4884512424468994,
      "learning_rate": 2.4485694297971177e-05,
      "loss": 0.4859,
      "step": 824200
    },
    {
      "epoch": 8.7258801297897,
      "grad_norm": 1.4682114124298096,
      "learning_rate": 2.446576079764354e-05,
      "loss": 0.4798,
      "step": 824250
    },
    {
      "epoch": 8.726409451569705,
      "grad_norm": 1.2880606651306152,
      "learning_rate": 2.4445834996972062e-05,
      "loss": 0.48,
      "step": 824300
    },
    {
      "epoch": 8.726938773349707,
      "grad_norm": 1.4040570259094238,
      "learning_rate": 2.4425916896637118e-05,
      "loss": 0.4728,
      "step": 824350
    },
    {
      "epoch": 8.72746809512971,
      "grad_norm": 1.4430103302001953,
      "learning_rate": 2.440600649731861e-05,
      "loss": 0.478,
      "step": 824400
    },
    {
      "epoch": 8.727997416909714,
      "grad_norm": 1.3664965629577637,
      "learning_rate": 2.438610379969633e-05,
      "loss": 0.4855,
      "step": 824450
    },
    {
      "epoch": 8.728526738689716,
      "grad_norm": 1.2586193084716797,
      "learning_rate": 2.4366208804449703e-05,
      "loss": 0.4732,
      "step": 824500
    },
    {
      "epoch": 8.728526738689716,
      "eval_loss": 0.295129656791687,
      "eval_runtime": 46.735,
      "eval_samples_per_second": 3593.238,
      "eval_steps_per_second": 449.171,
      "step": 824500
    },
    {
      "epoch": 8.72905606046972,
      "grad_norm": 1.324907898902893,
      "learning_rate": 2.434632151225799e-05,
      "loss": 0.4803,
      "step": 824550
    },
    {
      "epoch": 8.729585382249724,
      "grad_norm": 1.3085694313049316,
      "learning_rate": 2.432644192380004e-05,
      "loss": 0.4818,
      "step": 824600
    },
    {
      "epoch": 8.730114704029727,
      "grad_norm": 1.542409896850586,
      "learning_rate": 2.430657003975467e-05,
      "loss": 0.4738,
      "step": 824650
    },
    {
      "epoch": 8.73064402580973,
      "grad_norm": 1.4355692863464355,
      "learning_rate": 2.4286705860800173e-05,
      "loss": 0.4706,
      "step": 824700
    },
    {
      "epoch": 8.731173347589733,
      "grad_norm": 1.524419903755188,
      "learning_rate": 2.426684938761481e-05,
      "loss": 0.4857,
      "step": 824750
    },
    {
      "epoch": 8.731702669369737,
      "grad_norm": 1.2876797914505005,
      "learning_rate": 2.424700062087637e-05,
      "loss": 0.4797,
      "step": 824800
    },
    {
      "epoch": 8.73223199114974,
      "grad_norm": 1.3147025108337402,
      "learning_rate": 2.422715956126259e-05,
      "loss": 0.4786,
      "step": 824850
    },
    {
      "epoch": 8.732761312929743,
      "grad_norm": 1.260243535041809,
      "learning_rate": 2.4207326209450735e-05,
      "loss": 0.4756,
      "step": 824900
    },
    {
      "epoch": 8.733290634709746,
      "grad_norm": 1.4383360147476196,
      "learning_rate": 2.4187500566118016e-05,
      "loss": 0.4886,
      "step": 824950
    },
    {
      "epoch": 8.73381995648975,
      "grad_norm": 1.343466877937317,
      "learning_rate": 2.4167682631941134e-05,
      "loss": 0.4826,
      "step": 825000
    },
    {
      "epoch": 8.73381995648975,
      "eval_loss": 0.2947521209716797,
      "eval_runtime": 46.7958,
      "eval_samples_per_second": 3588.573,
      "eval_steps_per_second": 448.588,
      "step": 825000
    },
    {
      "epoch": 8.734349278269754,
      "grad_norm": 1.3844499588012695,
      "learning_rate": 2.414787240759683e-05,
      "loss": 0.4799,
      "step": 825050
    },
    {
      "epoch": 8.734878600049756,
      "grad_norm": 1.325245976448059,
      "learning_rate": 2.4128069893761263e-05,
      "loss": 0.4786,
      "step": 825100
    },
    {
      "epoch": 8.73540792182976,
      "grad_norm": 1.3959249258041382,
      "learning_rate": 2.4108275091110603e-05,
      "loss": 0.4794,
      "step": 825150
    },
    {
      "epoch": 8.735937243609763,
      "grad_norm": 1.3863967657089233,
      "learning_rate": 2.408848800032054e-05,
      "loss": 0.4809,
      "step": 825200
    },
    {
      "epoch": 8.736466565389765,
      "grad_norm": 1.3998887538909912,
      "learning_rate": 2.40687086220667e-05,
      "loss": 0.4834,
      "step": 825250
    },
    {
      "epoch": 8.736995887169769,
      "grad_norm": 1.4995710849761963,
      "learning_rate": 2.4048936957024232e-05,
      "loss": 0.4781,
      "step": 825300
    },
    {
      "epoch": 8.737525208949773,
      "grad_norm": 1.3484854698181152,
      "learning_rate": 2.4029173005868237e-05,
      "loss": 0.4765,
      "step": 825350
    },
    {
      "epoch": 8.738054530729777,
      "grad_norm": 1.2483118772506714,
      "learning_rate": 2.4009416769273372e-05,
      "loss": 0.4849,
      "step": 825400
    },
    {
      "epoch": 8.738583852509779,
      "grad_norm": 1.4226884841918945,
      "learning_rate": 2.3989668247914127e-05,
      "loss": 0.4752,
      "step": 825450
    },
    {
      "epoch": 8.739113174289782,
      "grad_norm": 1.4542148113250732,
      "learning_rate": 2.396992744246479e-05,
      "loss": 0.4854,
      "step": 825500
    },
    {
      "epoch": 8.739113174289782,
      "eval_loss": 0.2948540449142456,
      "eval_runtime": 46.7809,
      "eval_samples_per_second": 3589.713,
      "eval_steps_per_second": 448.73,
      "step": 825500
    },
    {
      "epoch": 8.739642496069786,
      "grad_norm": 1.3280943632125854,
      "learning_rate": 2.395019435359916e-05,
      "loss": 0.4838,
      "step": 825550
    },
    {
      "epoch": 8.74017181784979,
      "grad_norm": 1.272499442100525,
      "learning_rate": 2.3930468981990998e-05,
      "loss": 0.481,
      "step": 825600
    },
    {
      "epoch": 8.740701139629792,
      "grad_norm": 1.4296314716339111,
      "learning_rate": 2.3910751328313773e-05,
      "loss": 0.4726,
      "step": 825650
    },
    {
      "epoch": 8.741230461409796,
      "grad_norm": 1.2815852165222168,
      "learning_rate": 2.3891041393240525e-05,
      "loss": 0.4716,
      "step": 825700
    },
    {
      "epoch": 8.7417597831898,
      "grad_norm": 1.3668073415756226,
      "learning_rate": 2.3871339177444244e-05,
      "loss": 0.4715,
      "step": 825750
    },
    {
      "epoch": 8.742289104969803,
      "grad_norm": 1.4108359813690186,
      "learning_rate": 2.385164468159748e-05,
      "loss": 0.4823,
      "step": 825800
    },
    {
      "epoch": 8.742818426749805,
      "grad_norm": 1.3344576358795166,
      "learning_rate": 2.3831957906372688e-05,
      "loss": 0.4744,
      "step": 825850
    },
    {
      "epoch": 8.743347748529809,
      "grad_norm": 1.314737319946289,
      "learning_rate": 2.381227885244183e-05,
      "loss": 0.4808,
      "step": 825900
    },
    {
      "epoch": 8.743877070309813,
      "grad_norm": 1.2319366931915283,
      "learning_rate": 2.3792607520476876e-05,
      "loss": 0.4831,
      "step": 825950
    },
    {
      "epoch": 8.744406392089815,
      "grad_norm": 1.4663288593292236,
      "learning_rate": 2.37733371076497e-05,
      "loss": 0.476,
      "step": 826000
    },
    {
      "epoch": 8.744406392089815,
      "eval_loss": 0.294495552778244,
      "eval_runtime": 46.7886,
      "eval_samples_per_second": 3589.12,
      "eval_steps_per_second": 448.656,
      "step": 826000
    },
    {
      "epoch": 8.744935713869818,
      "grad_norm": 1.2823740243911743,
      "learning_rate": 2.3753681067158112e-05,
      "loss": 0.4893,
      "step": 826050
    },
    {
      "epoch": 8.745465035649822,
      "grad_norm": 1.3809912204742432,
      "learning_rate": 2.3734032750632904e-05,
      "loss": 0.4751,
      "step": 826100
    },
    {
      "epoch": 8.745994357429826,
      "grad_norm": 1.2914549112319946,
      "learning_rate": 2.3714392158744795e-05,
      "loss": 0.4771,
      "step": 826150
    },
    {
      "epoch": 8.746523679209828,
      "grad_norm": 1.2835243940353394,
      "learning_rate": 2.3694759292164357e-05,
      "loss": 0.4776,
      "step": 826200
    },
    {
      "epoch": 8.747053000989832,
      "grad_norm": 1.5669865608215332,
      "learning_rate": 2.3675134151561888e-05,
      "loss": 0.4715,
      "step": 826250
    },
    {
      "epoch": 8.747582322769835,
      "grad_norm": 1.409891128540039,
      "learning_rate": 2.3655516737607296e-05,
      "loss": 0.4823,
      "step": 826300
    },
    {
      "epoch": 8.748111644549839,
      "grad_norm": 1.3031986951828003,
      "learning_rate": 2.3635907050970405e-05,
      "loss": 0.4714,
      "step": 826350
    },
    {
      "epoch": 8.748640966329841,
      "grad_norm": 1.4404526948928833,
      "learning_rate": 2.3616305092320574e-05,
      "loss": 0.4793,
      "step": 826400
    },
    {
      "epoch": 8.749170288109845,
      "grad_norm": 1.3260244131088257,
      "learning_rate": 2.359671086232709e-05,
      "loss": 0.4771,
      "step": 826450
    },
    {
      "epoch": 8.749699609889849,
      "grad_norm": 1.3188456296920776,
      "learning_rate": 2.3577124361658847e-05,
      "loss": 0.4822,
      "step": 826500
    },
    {
      "epoch": 8.749699609889849,
      "eval_loss": 0.29471805691719055,
      "eval_runtime": 46.7829,
      "eval_samples_per_second": 3589.562,
      "eval_steps_per_second": 448.711,
      "step": 826500
    },
    {
      "epoch": 8.750228931669852,
      "grad_norm": 1.2939499616622925,
      "learning_rate": 2.355754559098458e-05,
      "loss": 0.4696,
      "step": 826550
    },
    {
      "epoch": 8.750758253449854,
      "grad_norm": 1.4677399396896362,
      "learning_rate": 2.3537974550972617e-05,
      "loss": 0.4835,
      "step": 826600
    },
    {
      "epoch": 8.751287575229858,
      "grad_norm": 1.3359755277633667,
      "learning_rate": 2.3518411242291178e-05,
      "loss": 0.484,
      "step": 826650
    },
    {
      "epoch": 8.751816897009862,
      "grad_norm": 1.382504940032959,
      "learning_rate": 2.349885566560811e-05,
      "loss": 0.4836,
      "step": 826700
    },
    {
      "epoch": 8.752346218789864,
      "grad_norm": 1.303949236869812,
      "learning_rate": 2.3479307821591052e-05,
      "loss": 0.4731,
      "step": 826750
    },
    {
      "epoch": 8.752875540569867,
      "grad_norm": 1.2928571701049805,
      "learning_rate": 2.3459767710907328e-05,
      "loss": 0.478,
      "step": 826800
    },
    {
      "epoch": 8.753404862349871,
      "grad_norm": 1.446508526802063,
      "learning_rate": 2.3440235334224095e-05,
      "loss": 0.4815,
      "step": 826850
    },
    {
      "epoch": 8.753934184129875,
      "grad_norm": 1.4392858743667603,
      "learning_rate": 2.342071069220808e-05,
      "loss": 0.481,
      "step": 826900
    },
    {
      "epoch": 8.754463505909877,
      "grad_norm": 1.2488311529159546,
      "learning_rate": 2.3401193785525965e-05,
      "loss": 0.4812,
      "step": 826950
    },
    {
      "epoch": 8.75499282768988,
      "grad_norm": 1.335264801979065,
      "learning_rate": 2.338168461484394e-05,
      "loss": 0.4711,
      "step": 827000
    },
    {
      "epoch": 8.75499282768988,
      "eval_loss": 0.2942189574241638,
      "eval_runtime": 46.7574,
      "eval_samples_per_second": 3591.515,
      "eval_steps_per_second": 448.955,
      "step": 827000
    },
    {
      "epoch": 8.755522149469884,
      "grad_norm": 1.3379998207092285,
      "learning_rate": 2.336218318082814e-05,
      "loss": 0.4729,
      "step": 827050
    },
    {
      "epoch": 8.756051471249888,
      "grad_norm": 1.338563323020935,
      "learning_rate": 2.3342689484144225e-05,
      "loss": 0.477,
      "step": 827100
    },
    {
      "epoch": 8.75658079302989,
      "grad_norm": 1.3860583305358887,
      "learning_rate": 2.3323203525457833e-05,
      "loss": 0.4898,
      "step": 827150
    },
    {
      "epoch": 8.757110114809894,
      "grad_norm": 1.4086952209472656,
      "learning_rate": 2.3303725305434094e-05,
      "loss": 0.4801,
      "step": 827200
    },
    {
      "epoch": 8.757639436589898,
      "grad_norm": 1.4218225479125977,
      "learning_rate": 2.328425482473809e-05,
      "loss": 0.4807,
      "step": 827250
    },
    {
      "epoch": 8.758168758369901,
      "grad_norm": 1.5568376779556274,
      "learning_rate": 2.3264792084034426e-05,
      "loss": 0.4857,
      "step": 827300
    },
    {
      "epoch": 8.758698080149903,
      "grad_norm": 1.302791953086853,
      "learning_rate": 2.3245337083987654e-05,
      "loss": 0.4798,
      "step": 827350
    },
    {
      "epoch": 8.759227401929907,
      "grad_norm": 1.4541335105895996,
      "learning_rate": 2.322588982526186e-05,
      "loss": 0.4792,
      "step": 827400
    },
    {
      "epoch": 8.759756723709911,
      "grad_norm": 1.3198939561843872,
      "learning_rate": 2.3206450308521087e-05,
      "loss": 0.4783,
      "step": 827450
    },
    {
      "epoch": 8.760286045489913,
      "grad_norm": 1.3542505502700806,
      "learning_rate": 2.3187018534428868e-05,
      "loss": 0.4733,
      "step": 827500
    },
    {
      "epoch": 8.760286045489913,
      "eval_loss": 0.29483938217163086,
      "eval_runtime": 46.7019,
      "eval_samples_per_second": 3595.781,
      "eval_steps_per_second": 449.489,
      "step": 827500
    },
    {
      "epoch": 8.760815367269917,
      "grad_norm": 1.432827353477478,
      "learning_rate": 2.3167594503648693e-05,
      "loss": 0.4817,
      "step": 827550
    },
    {
      "epoch": 8.76134468904992,
      "grad_norm": 1.3541570901870728,
      "learning_rate": 2.3148178216843592e-05,
      "loss": 0.4831,
      "step": 827600
    },
    {
      "epoch": 8.761874010829924,
      "grad_norm": 1.4353159666061401,
      "learning_rate": 2.312876967467653e-05,
      "loss": 0.4665,
      "step": 827650
    },
    {
      "epoch": 8.762403332609926,
      "grad_norm": 1.3890507221221924,
      "learning_rate": 2.3109368877810095e-05,
      "loss": 0.4726,
      "step": 827700
    },
    {
      "epoch": 8.76293265438993,
      "grad_norm": 1.4079043865203857,
      "learning_rate": 2.3089975826906556e-05,
      "loss": 0.47,
      "step": 827750
    },
    {
      "epoch": 8.763461976169934,
      "grad_norm": 1.2271219491958618,
      "learning_rate": 2.3070590522628055e-05,
      "loss": 0.4772,
      "step": 827800
    },
    {
      "epoch": 8.763991297949937,
      "grad_norm": 1.3331420421600342,
      "learning_rate": 2.3051212965636337e-05,
      "loss": 0.4853,
      "step": 827850
    },
    {
      "epoch": 8.76452061972994,
      "grad_norm": 1.3586632013320923,
      "learning_rate": 2.3031843156592986e-05,
      "loss": 0.4668,
      "step": 827900
    },
    {
      "epoch": 8.765049941509943,
      "grad_norm": 1.2482942342758179,
      "learning_rate": 2.3012481096159305e-05,
      "loss": 0.4884,
      "step": 827950
    },
    {
      "epoch": 8.765579263289947,
      "grad_norm": 1.345781922340393,
      "learning_rate": 2.2993126784996237e-05,
      "loss": 0.4829,
      "step": 828000
    },
    {
      "epoch": 8.765579263289947,
      "eval_loss": 0.2942875027656555,
      "eval_runtime": 46.8913,
      "eval_samples_per_second": 3581.261,
      "eval_steps_per_second": 447.674,
      "step": 828000
    },
    {
      "epoch": 8.76610858506995,
      "grad_norm": 1.4922151565551758,
      "learning_rate": 2.297378022376459e-05,
      "loss": 0.4762,
      "step": 828050
    },
    {
      "epoch": 8.766637906849953,
      "grad_norm": 1.3960046768188477,
      "learning_rate": 2.2954441413124806e-05,
      "loss": 0.4853,
      "step": 828100
    },
    {
      "epoch": 8.767167228629956,
      "grad_norm": 1.479442834854126,
      "learning_rate": 2.2935110353737158e-05,
      "loss": 0.4848,
      "step": 828150
    },
    {
      "epoch": 8.76769655040996,
      "grad_norm": 1.298843502998352,
      "learning_rate": 2.2915787046261544e-05,
      "loss": 0.4723,
      "step": 828200
    },
    {
      "epoch": 8.768225872189962,
      "grad_norm": 1.3800411224365234,
      "learning_rate": 2.2896471491357708e-05,
      "loss": 0.4843,
      "step": 828250
    },
    {
      "epoch": 8.768755193969966,
      "grad_norm": 1.35832941532135,
      "learning_rate": 2.2877549769732554e-05,
      "loss": 0.4823,
      "step": 828300
    },
    {
      "epoch": 8.76928451574997,
      "grad_norm": 1.482310175895691,
      "learning_rate": 2.2858249566865912e-05,
      "loss": 0.4885,
      "step": 828350
    },
    {
      "epoch": 8.769813837529973,
      "grad_norm": 1.266194224357605,
      "learning_rate": 2.2838957118535368e-05,
      "loss": 0.474,
      "step": 828400
    },
    {
      "epoch": 8.770343159309975,
      "grad_norm": 1.309810757637024,
      "learning_rate": 2.2819672425399507e-05,
      "loss": 0.4722,
      "step": 828450
    },
    {
      "epoch": 8.77087248108998,
      "grad_norm": 1.4782987833023071,
      "learning_rate": 2.280039548811674e-05,
      "loss": 0.4796,
      "step": 828500
    },
    {
      "epoch": 8.77087248108998,
      "eval_loss": 0.29428377747535706,
      "eval_runtime": 46.8759,
      "eval_samples_per_second": 3582.436,
      "eval_steps_per_second": 447.82,
      "step": 828500
    },
    {
      "epoch": 8.771401802869983,
      "grad_norm": 1.396234393119812,
      "learning_rate": 2.2781126307345108e-05,
      "loss": 0.4761,
      "step": 828550
    },
    {
      "epoch": 8.771931124649987,
      "grad_norm": 1.6105916500091553,
      "learning_rate": 2.2761864883742516e-05,
      "loss": 0.4821,
      "step": 828600
    },
    {
      "epoch": 8.772460446429989,
      "grad_norm": 1.334083080291748,
      "learning_rate": 2.2742611217966502e-05,
      "loss": 0.4695,
      "step": 828650
    },
    {
      "epoch": 8.772989768209992,
      "grad_norm": 1.3991782665252686,
      "learning_rate": 2.2723365310674427e-05,
      "loss": 0.4875,
      "step": 828700
    },
    {
      "epoch": 8.773519089989996,
      "grad_norm": 1.3995822668075562,
      "learning_rate": 2.270412716252329e-05,
      "loss": 0.4802,
      "step": 828750
    },
    {
      "epoch": 8.77404841177,
      "grad_norm": 1.248104214668274,
      "learning_rate": 2.2684896774169905e-05,
      "loss": 0.4706,
      "step": 828800
    },
    {
      "epoch": 8.774577733550002,
      "grad_norm": 1.4384504556655884,
      "learning_rate": 2.2665674146270743e-05,
      "loss": 0.4806,
      "step": 828850
    },
    {
      "epoch": 8.775107055330006,
      "grad_norm": 1.2022438049316406,
      "learning_rate": 2.264645927948214e-05,
      "loss": 0.4755,
      "step": 828900
    },
    {
      "epoch": 8.77563637711001,
      "grad_norm": 1.435113787651062,
      "learning_rate": 2.262725217445999e-05,
      "loss": 0.4766,
      "step": 828950
    },
    {
      "epoch": 8.776165698890011,
      "grad_norm": 1.4540154933929443,
      "learning_rate": 2.2608052831860127e-05,
      "loss": 0.4819,
      "step": 829000
    },
    {
      "epoch": 8.776165698890011,
      "eval_loss": 0.2941928803920746,
      "eval_runtime": 46.7003,
      "eval_samples_per_second": 3595.909,
      "eval_steps_per_second": 449.505,
      "step": 829000
    },
    {
      "epoch": 8.776695020670015,
      "grad_norm": 1.3568977117538452,
      "learning_rate": 2.2588861252337888e-05,
      "loss": 0.4762,
      "step": 829050
    },
    {
      "epoch": 8.777224342450019,
      "grad_norm": 1.4154281616210938,
      "learning_rate": 2.256967743654856e-05,
      "loss": 0.4742,
      "step": 829100
    },
    {
      "epoch": 8.777753664230023,
      "grad_norm": 1.3755848407745361,
      "learning_rate": 2.2550501385147026e-05,
      "loss": 0.4761,
      "step": 829150
    },
    {
      "epoch": 8.778282986010025,
      "grad_norm": 1.5044695138931274,
      "learning_rate": 2.2531333098787964e-05,
      "loss": 0.483,
      "step": 829200
    },
    {
      "epoch": 8.778812307790028,
      "grad_norm": 1.3219794034957886,
      "learning_rate": 2.251217257812574e-05,
      "loss": 0.4743,
      "step": 829250
    },
    {
      "epoch": 8.779341629570032,
      "grad_norm": 1.4180548191070557,
      "learning_rate": 2.2493019823814576e-05,
      "loss": 0.4752,
      "step": 829300
    },
    {
      "epoch": 8.779870951350036,
      "grad_norm": 1.322160243988037,
      "learning_rate": 2.24738748365082e-05,
      "loss": 0.4744,
      "step": 829350
    },
    {
      "epoch": 8.780400273130038,
      "grad_norm": 1.3807400465011597,
      "learning_rate": 2.245473761686037e-05,
      "loss": 0.4747,
      "step": 829400
    },
    {
      "epoch": 8.780929594910042,
      "grad_norm": 1.4273961782455444,
      "learning_rate": 2.2435608165524286e-05,
      "loss": 0.4795,
      "step": 829450
    },
    {
      "epoch": 8.781458916690045,
      "grad_norm": 1.3685914278030396,
      "learning_rate": 2.2416486483153143e-05,
      "loss": 0.4793,
      "step": 829500
    },
    {
      "epoch": 8.781458916690045,
      "eval_loss": 0.2939050495624542,
      "eval_runtime": 46.8923,
      "eval_samples_per_second": 3581.182,
      "eval_steps_per_second": 447.664,
      "step": 829500
    },
    {
      "epoch": 8.78198823847005,
      "grad_norm": 1.5250300168991089,
      "learning_rate": 2.2397372570399617e-05,
      "loss": 0.4822,
      "step": 829550
    },
    {
      "epoch": 8.782517560250051,
      "grad_norm": 1.3120813369750977,
      "learning_rate": 2.2378266427916406e-05,
      "loss": 0.472,
      "step": 829600
    },
    {
      "epoch": 8.783046882030055,
      "grad_norm": 1.4558902978897095,
      "learning_rate": 2.2359168056355626e-05,
      "loss": 0.4824,
      "step": 829650
    },
    {
      "epoch": 8.783576203810059,
      "grad_norm": 1.3893182277679443,
      "learning_rate": 2.2340077456369402e-05,
      "loss": 0.4817,
      "step": 829700
    },
    {
      "epoch": 8.78410552559006,
      "grad_norm": 1.3535276651382446,
      "learning_rate": 2.2320994628609427e-05,
      "loss": 0.482,
      "step": 829750
    },
    {
      "epoch": 8.784634847370064,
      "grad_norm": 1.3152275085449219,
      "learning_rate": 2.2301919573727155e-05,
      "loss": 0.4726,
      "step": 829800
    },
    {
      "epoch": 8.785164169150068,
      "grad_norm": 1.3834458589553833,
      "learning_rate": 2.2282852292373922e-05,
      "loss": 0.4841,
      "step": 829850
    },
    {
      "epoch": 8.785693490930072,
      "grad_norm": 1.3851784467697144,
      "learning_rate": 2.226379278520055e-05,
      "loss": 0.4815,
      "step": 829900
    },
    {
      "epoch": 8.786222812710074,
      "grad_norm": 1.4494363069534302,
      "learning_rate": 2.224474105285776e-05,
      "loss": 0.475,
      "step": 829950
    },
    {
      "epoch": 8.786752134490078,
      "grad_norm": 1.3851574659347534,
      "learning_rate": 2.2225697095996034e-05,
      "loss": 0.4713,
      "step": 830000
    },
    {
      "epoch": 8.786752134490078,
      "eval_loss": 0.29385289549827576,
      "eval_runtime": 46.7599,
      "eval_samples_per_second": 3591.323,
      "eval_steps_per_second": 448.931,
      "step": 830000
    },
    {
      "epoch": 8.787281456270081,
      "grad_norm": 1.3043904304504395,
      "learning_rate": 2.2206660915265435e-05,
      "loss": 0.4792,
      "step": 830050
    },
    {
      "epoch": 8.787810778050085,
      "grad_norm": 1.2667580842971802,
      "learning_rate": 2.218763251131592e-05,
      "loss": 0.4833,
      "step": 830100
    },
    {
      "epoch": 8.788340099830087,
      "grad_norm": 1.4994890689849854,
      "learning_rate": 2.2168611884797047e-05,
      "loss": 0.4753,
      "step": 830150
    },
    {
      "epoch": 8.78886942161009,
      "grad_norm": 1.4114516973495483,
      "learning_rate": 2.214959903635827e-05,
      "loss": 0.4781,
      "step": 830200
    },
    {
      "epoch": 8.789398743390095,
      "grad_norm": 1.490035057067871,
      "learning_rate": 2.2130593966648543e-05,
      "loss": 0.4845,
      "step": 830250
    },
    {
      "epoch": 8.789928065170098,
      "grad_norm": 1.3563809394836426,
      "learning_rate": 2.2111596676316847e-05,
      "loss": 0.473,
      "step": 830300
    },
    {
      "epoch": 8.7904573869501,
      "grad_norm": 1.4051905870437622,
      "learning_rate": 2.209260716601161e-05,
      "loss": 0.4668,
      "step": 830350
    },
    {
      "epoch": 8.790986708730104,
      "grad_norm": 1.3816680908203125,
      "learning_rate": 2.2073625436381224e-05,
      "loss": 0.4829,
      "step": 830400
    },
    {
      "epoch": 8.791516030510108,
      "grad_norm": 1.304176688194275,
      "learning_rate": 2.205465148807362e-05,
      "loss": 0.476,
      "step": 830450
    },
    {
      "epoch": 8.79204535229011,
      "grad_norm": 1.2874313592910767,
      "learning_rate": 2.2035685321736692e-05,
      "loss": 0.4743,
      "step": 830500
    },
    {
      "epoch": 8.79204535229011,
      "eval_loss": 0.29376959800720215,
      "eval_runtime": 46.923,
      "eval_samples_per_second": 3578.842,
      "eval_steps_per_second": 447.371,
      "step": 830500
    },
    {
      "epoch": 8.792574674070114,
      "grad_norm": 1.384243130683899,
      "learning_rate": 2.201672693801779e-05,
      "loss": 0.4748,
      "step": 830550
    },
    {
      "epoch": 8.793103995850117,
      "grad_norm": 1.3483983278274536,
      "learning_rate": 2.199777633756428e-05,
      "loss": 0.4735,
      "step": 830600
    },
    {
      "epoch": 8.793633317630121,
      "grad_norm": 1.271151065826416,
      "learning_rate": 2.1978833521023007e-05,
      "loss": 0.4824,
      "step": 830650
    },
    {
      "epoch": 8.794162639410123,
      "grad_norm": 1.3816856145858765,
      "learning_rate": 2.196027711338755e-05,
      "loss": 0.4827,
      "step": 830700
    },
    {
      "epoch": 8.794691961190127,
      "grad_norm": 1.2457680702209473,
      "learning_rate": 2.1941349710900282e-05,
      "loss": 0.4735,
      "step": 830750
    },
    {
      "epoch": 8.79522128297013,
      "grad_norm": 1.4655014276504517,
      "learning_rate": 2.192243009425174e-05,
      "loss": 0.4795,
      "step": 830800
    },
    {
      "epoch": 8.795750604750134,
      "grad_norm": 1.3470721244812012,
      "learning_rate": 2.1903518264087736e-05,
      "loss": 0.4787,
      "step": 830850
    },
    {
      "epoch": 8.796279926530136,
      "grad_norm": 1.4650875329971313,
      "learning_rate": 2.1884614221054033e-05,
      "loss": 0.4769,
      "step": 830900
    },
    {
      "epoch": 8.79680924831014,
      "grad_norm": 1.5334919691085815,
      "learning_rate": 2.1865717965795867e-05,
      "loss": 0.4809,
      "step": 830950
    },
    {
      "epoch": 8.797338570090144,
      "grad_norm": 1.4601472616195679,
      "learning_rate": 2.1846829498958498e-05,
      "loss": 0.4781,
      "step": 831000
    },
    {
      "epoch": 8.797338570090144,
      "eval_loss": 0.29391583800315857,
      "eval_runtime": 46.8735,
      "eval_samples_per_second": 3582.625,
      "eval_steps_per_second": 447.844,
      "step": 831000
    },
    {
      "epoch": 8.797867891870148,
      "grad_norm": 1.3395226001739502,
      "learning_rate": 2.1827948821186634e-05,
      "loss": 0.4767,
      "step": 831050
    },
    {
      "epoch": 8.79839721365015,
      "grad_norm": 1.3523069620132446,
      "learning_rate": 2.180907593312495e-05,
      "loss": 0.4816,
      "step": 831100
    },
    {
      "epoch": 8.798926535430153,
      "grad_norm": 1.4436421394348145,
      "learning_rate": 2.179021083541771e-05,
      "loss": 0.4825,
      "step": 831150
    },
    {
      "epoch": 8.799455857210157,
      "grad_norm": 1.4892640113830566,
      "learning_rate": 2.1771353528709015e-05,
      "loss": 0.4801,
      "step": 831200
    },
    {
      "epoch": 8.799985178990159,
      "grad_norm": 1.4507275819778442,
      "learning_rate": 2.1752504013642567e-05,
      "loss": 0.4679,
      "step": 831250
    },
    {
      "epoch": 8.800514500770163,
      "grad_norm": 1.3152194023132324,
      "learning_rate": 2.173366229086196e-05,
      "loss": 0.4791,
      "step": 831300
    },
    {
      "epoch": 8.801043822550167,
      "grad_norm": 1.4582858085632324,
      "learning_rate": 2.171482836101038e-05,
      "loss": 0.4806,
      "step": 831350
    },
    {
      "epoch": 8.80157314433017,
      "grad_norm": 1.2961629629135132,
      "learning_rate": 2.1696002224730864e-05,
      "loss": 0.4803,
      "step": 831400
    },
    {
      "epoch": 8.802102466110172,
      "grad_norm": 1.3885091543197632,
      "learning_rate": 2.1677183882666068e-05,
      "loss": 0.4777,
      "step": 831450
    },
    {
      "epoch": 8.802631787890176,
      "grad_norm": 1.222429633140564,
      "learning_rate": 2.165837333545853e-05,
      "loss": 0.4753,
      "step": 831500
    },
    {
      "epoch": 8.802631787890176,
      "eval_loss": 0.2942129075527191,
      "eval_runtime": 46.7856,
      "eval_samples_per_second": 3589.355,
      "eval_steps_per_second": 448.685,
      "step": 831500
    },
    {
      "epoch": 8.80316110967018,
      "grad_norm": 1.3315136432647705,
      "learning_rate": 2.1639570583750323e-05,
      "loss": 0.4784,
      "step": 831550
    },
    {
      "epoch": 8.803690431450184,
      "grad_norm": 1.2634683847427368,
      "learning_rate": 2.1620775628183486e-05,
      "loss": 0.4732,
      "step": 831600
    },
    {
      "epoch": 8.804219753230186,
      "grad_norm": 1.3577044010162354,
      "learning_rate": 2.1601988469399565e-05,
      "loss": 0.4739,
      "step": 831650
    },
    {
      "epoch": 8.80474907501019,
      "grad_norm": 1.3968102931976318,
      "learning_rate": 2.1583209108040043e-05,
      "loss": 0.4807,
      "step": 831700
    },
    {
      "epoch": 8.805278396790193,
      "grad_norm": 1.361554741859436,
      "learning_rate": 2.1564437544745934e-05,
      "loss": 0.4783,
      "step": 831750
    },
    {
      "epoch": 8.805807718570197,
      "grad_norm": 1.4739809036254883,
      "learning_rate": 2.1545673780158204e-05,
      "loss": 0.4805,
      "step": 831800
    },
    {
      "epoch": 8.806337040350199,
      "grad_norm": 1.415185809135437,
      "learning_rate": 2.1526917814917336e-05,
      "loss": 0.479,
      "step": 831850
    },
    {
      "epoch": 8.806866362130203,
      "grad_norm": 1.4489011764526367,
      "learning_rate": 2.150816964966376e-05,
      "loss": 0.4713,
      "step": 831900
    },
    {
      "epoch": 8.807395683910206,
      "grad_norm": 1.4701335430145264,
      "learning_rate": 2.1489429285037443e-05,
      "loss": 0.4754,
      "step": 831950
    },
    {
      "epoch": 8.807925005690208,
      "grad_norm": 1.2947242259979248,
      "learning_rate": 2.1470696721678173e-05,
      "loss": 0.4776,
      "step": 832000
    },
    {
      "epoch": 8.807925005690208,
      "eval_loss": 0.29369768500328064,
      "eval_runtime": 46.9071,
      "eval_samples_per_second": 3580.053,
      "eval_steps_per_second": 447.523,
      "step": 832000
    },
    {
      "epoch": 8.808454327470212,
      "grad_norm": 1.4341927766799927,
      "learning_rate": 2.145197196022558e-05,
      "loss": 0.4776,
      "step": 832050
    },
    {
      "epoch": 8.808983649250216,
      "grad_norm": 1.5517412424087524,
      "learning_rate": 2.143325500131879e-05,
      "loss": 0.4752,
      "step": 832100
    },
    {
      "epoch": 8.80951297103022,
      "grad_norm": 1.5210274457931519,
      "learning_rate": 2.141454584559685e-05,
      "loss": 0.4775,
      "step": 832150
    },
    {
      "epoch": 8.810042292810222,
      "grad_norm": 1.3751145601272583,
      "learning_rate": 2.1395844493698523e-05,
      "loss": 0.4733,
      "step": 832200
    },
    {
      "epoch": 8.810571614590225,
      "grad_norm": 1.5002528429031372,
      "learning_rate": 2.1377150946262192e-05,
      "loss": 0.4752,
      "step": 832250
    },
    {
      "epoch": 8.811100936370229,
      "grad_norm": 1.3334470987319946,
      "learning_rate": 2.135846520392612e-05,
      "loss": 0.4711,
      "step": 832300
    },
    {
      "epoch": 8.811630258150233,
      "grad_norm": 1.348839282989502,
      "learning_rate": 2.1339787267328158e-05,
      "loss": 0.484,
      "step": 832350
    },
    {
      "epoch": 8.812159579930235,
      "grad_norm": 1.5286873579025269,
      "learning_rate": 2.132111713710605e-05,
      "loss": 0.4793,
      "step": 832400
    },
    {
      "epoch": 8.812688901710239,
      "grad_norm": 1.3123540878295898,
      "learning_rate": 2.130245481389706e-05,
      "loss": 0.4728,
      "step": 832450
    },
    {
      "epoch": 8.813218223490242,
      "grad_norm": 1.3650493621826172,
      "learning_rate": 2.1283800298338456e-05,
      "loss": 0.4731,
      "step": 832500
    },
    {
      "epoch": 8.813218223490242,
      "eval_loss": 0.29366636276245117,
      "eval_runtime": 46.7928,
      "eval_samples_per_second": 3588.803,
      "eval_steps_per_second": 448.616,
      "step": 832500
    },
    {
      "epoch": 8.813747545270246,
      "grad_norm": 1.3742564916610718,
      "learning_rate": 2.126515359106701e-05,
      "loss": 0.4757,
      "step": 832550
    },
    {
      "epoch": 8.814276867050248,
      "grad_norm": 1.3909786939620972,
      "learning_rate": 2.124651469271935e-05,
      "loss": 0.4835,
      "step": 832600
    },
    {
      "epoch": 8.814806188830252,
      "grad_norm": 1.3353086709976196,
      "learning_rate": 2.122788360393174e-05,
      "loss": 0.4814,
      "step": 832650
    },
    {
      "epoch": 8.815335510610256,
      "grad_norm": 1.537959098815918,
      "learning_rate": 2.1209260325340345e-05,
      "loss": 0.4768,
      "step": 832700
    },
    {
      "epoch": 8.815864832390258,
      "grad_norm": 1.3004400730133057,
      "learning_rate": 2.1190644857580822e-05,
      "loss": 0.4786,
      "step": 832750
    },
    {
      "epoch": 8.816394154170261,
      "grad_norm": 1.2918134927749634,
      "learning_rate": 2.1172037201288853e-05,
      "loss": 0.4769,
      "step": 832800
    },
    {
      "epoch": 8.816923475950265,
      "grad_norm": 1.3794649839401245,
      "learning_rate": 2.115343735709954e-05,
      "loss": 0.4803,
      "step": 832850
    },
    {
      "epoch": 8.817452797730269,
      "grad_norm": 1.4392558336257935,
      "learning_rate": 2.1134845325647996e-05,
      "loss": 0.4742,
      "step": 832900
    },
    {
      "epoch": 8.81798211951027,
      "grad_norm": 1.3877893686294556,
      "learning_rate": 2.1116261107568868e-05,
      "loss": 0.4713,
      "step": 832950
    },
    {
      "epoch": 8.818511441290275,
      "grad_norm": 1.3230116367340088,
      "learning_rate": 2.1097684703496685e-05,
      "loss": 0.4733,
      "step": 833000
    },
    {
      "epoch": 8.818511441290275,
      "eval_loss": 0.29351741075515747,
      "eval_runtime": 46.9273,
      "eval_samples_per_second": 3578.514,
      "eval_steps_per_second": 447.33,
      "step": 833000
    },
    {
      "epoch": 8.819040763070278,
      "grad_norm": 1.2781884670257568,
      "learning_rate": 2.1079116114065543e-05,
      "loss": 0.4749,
      "step": 833050
    },
    {
      "epoch": 8.819570084850282,
      "grad_norm": 1.4952484369277954,
      "learning_rate": 2.1060555339909497e-05,
      "loss": 0.4742,
      "step": 833100
    },
    {
      "epoch": 8.820099406630284,
      "grad_norm": 1.3431216478347778,
      "learning_rate": 2.1042002381662067e-05,
      "loss": 0.4718,
      "step": 833150
    },
    {
      "epoch": 8.820628728410288,
      "grad_norm": 1.4938167333602905,
      "learning_rate": 2.1023457239956745e-05,
      "loss": 0.4794,
      "step": 833200
    },
    {
      "epoch": 8.821158050190292,
      "grad_norm": 1.4936470985412598,
      "learning_rate": 2.100491991542658e-05,
      "loss": 0.4893,
      "step": 833250
    },
    {
      "epoch": 8.821687371970295,
      "grad_norm": 1.3159798383712769,
      "learning_rate": 2.098639040870451e-05,
      "loss": 0.4702,
      "step": 833300
    },
    {
      "epoch": 8.822216693750297,
      "grad_norm": 1.4803452491760254,
      "learning_rate": 2.0967868720423028e-05,
      "loss": 0.4802,
      "step": 833350
    },
    {
      "epoch": 8.822746015530301,
      "grad_norm": 1.4459762573242188,
      "learning_rate": 2.0949354851214573e-05,
      "loss": 0.4763,
      "step": 833400
    },
    {
      "epoch": 8.823275337310305,
      "grad_norm": 1.3610620498657227,
      "learning_rate": 2.0930848801711088e-05,
      "loss": 0.4809,
      "step": 833450
    },
    {
      "epoch": 8.823804659090307,
      "grad_norm": 1.3777542114257812,
      "learning_rate": 2.091235057254448e-05,
      "loss": 0.482,
      "step": 833500
    },
    {
      "epoch": 8.823804659090307,
      "eval_loss": 0.2940134108066559,
      "eval_runtime": 46.807,
      "eval_samples_per_second": 3587.708,
      "eval_steps_per_second": 448.479,
      "step": 833500
    },
    {
      "epoch": 8.82433398087031,
      "grad_norm": 1.4343719482421875,
      "learning_rate": 2.0893860164346134e-05,
      "loss": 0.4783,
      "step": 833550
    },
    {
      "epoch": 8.824863302650314,
      "grad_norm": 1.4474798440933228,
      "learning_rate": 2.0875377577747435e-05,
      "loss": 0.4756,
      "step": 833600
    },
    {
      "epoch": 8.825392624430318,
      "grad_norm": 1.3095759153366089,
      "learning_rate": 2.085690281337929e-05,
      "loss": 0.4747,
      "step": 833650
    },
    {
      "epoch": 8.82592194621032,
      "grad_norm": 1.377878189086914,
      "learning_rate": 2.0838435871872425e-05,
      "loss": 0.4833,
      "step": 833700
    },
    {
      "epoch": 8.826451267990324,
      "grad_norm": 1.4894808530807495,
      "learning_rate": 2.0819976753857383e-05,
      "loss": 0.4725,
      "step": 833750
    },
    {
      "epoch": 8.826980589770328,
      "grad_norm": 1.4040932655334473,
      "learning_rate": 2.0801525459964222e-05,
      "loss": 0.4819,
      "step": 833800
    },
    {
      "epoch": 8.827509911550331,
      "grad_norm": 1.37264883518219,
      "learning_rate": 2.0783450783519176e-05,
      "loss": 0.4797,
      "step": 833850
    },
    {
      "epoch": 8.828039233330333,
      "grad_norm": 1.4512001276016235,
      "learning_rate": 2.0765014983245596e-05,
      "loss": 0.4794,
      "step": 833900
    },
    {
      "epoch": 8.828568555110337,
      "grad_norm": 1.2456246614456177,
      "learning_rate": 2.074658700897039e-05,
      "loss": 0.4775,
      "step": 833950
    },
    {
      "epoch": 8.82909787689034,
      "grad_norm": 1.632807731628418,
      "learning_rate": 2.072816686132259e-05,
      "loss": 0.481,
      "step": 834000
    },
    {
      "epoch": 8.82909787689034,
      "eval_loss": 0.2935349643230438,
      "eval_runtime": 46.8996,
      "eval_samples_per_second": 3580.624,
      "eval_steps_per_second": 447.594,
      "step": 834000
    },
    {
      "epoch": 8.829627198670345,
      "grad_norm": 1.2118427753448486,
      "learning_rate": 2.0709754540931077e-05,
      "loss": 0.4747,
      "step": 834050
    },
    {
      "epoch": 8.830156520450346,
      "grad_norm": 1.4374651908874512,
      "learning_rate": 2.069135004842451e-05,
      "loss": 0.4817,
      "step": 834100
    },
    {
      "epoch": 8.83068584223035,
      "grad_norm": 1.366843819618225,
      "learning_rate": 2.0672953384431092e-05,
      "loss": 0.4852,
      "step": 834150
    },
    {
      "epoch": 8.831215164010354,
      "grad_norm": 1.3855102062225342,
      "learning_rate": 2.0654564549578953e-05,
      "loss": 0.4792,
      "step": 834200
    },
    {
      "epoch": 8.831744485790356,
      "grad_norm": 1.4613840579986572,
      "learning_rate": 2.0636183544495924e-05,
      "loss": 0.4703,
      "step": 834250
    },
    {
      "epoch": 8.83227380757036,
      "grad_norm": 1.431262493133545,
      "learning_rate": 2.061781036980942e-05,
      "loss": 0.4766,
      "step": 834300
    },
    {
      "epoch": 8.832803129350363,
      "grad_norm": 1.3324695825576782,
      "learning_rate": 2.0599445026146773e-05,
      "loss": 0.4849,
      "step": 834350
    },
    {
      "epoch": 8.833332451130367,
      "grad_norm": 1.355308175086975,
      "learning_rate": 2.0581087514134928e-05,
      "loss": 0.4771,
      "step": 834400
    },
    {
      "epoch": 8.83386177291037,
      "grad_norm": 1.3748499155044556,
      "learning_rate": 2.056273783440063e-05,
      "loss": 0.4778,
      "step": 834450
    },
    {
      "epoch": 8.834391094690373,
      "grad_norm": 1.3359841108322144,
      "learning_rate": 2.0544395987570298e-05,
      "loss": 0.4826,
      "step": 834500
    },
    {
      "epoch": 8.834391094690373,
      "eval_loss": 0.2938002943992615,
      "eval_runtime": 46.7451,
      "eval_samples_per_second": 3592.465,
      "eval_steps_per_second": 449.074,
      "step": 834500
    },
    {
      "epoch": 8.834920416470377,
      "grad_norm": 1.4650310277938843,
      "learning_rate": 2.0526061974270177e-05,
      "loss": 0.4758,
      "step": 834550
    },
    {
      "epoch": 8.83544973825038,
      "grad_norm": 1.4673168659210205,
      "learning_rate": 2.0507735795126103e-05,
      "loss": 0.4806,
      "step": 834600
    },
    {
      "epoch": 8.835979060030382,
      "grad_norm": 1.408864974975586,
      "learning_rate": 2.0489417450763796e-05,
      "loss": 0.4757,
      "step": 834650
    },
    {
      "epoch": 8.836508381810386,
      "grad_norm": 1.3982319831848145,
      "learning_rate": 2.0471106941808593e-05,
      "loss": 0.4726,
      "step": 834700
    },
    {
      "epoch": 8.83703770359039,
      "grad_norm": 1.3033543825149536,
      "learning_rate": 2.0452804268885628e-05,
      "loss": 0.4774,
      "step": 834750
    },
    {
      "epoch": 8.837567025370394,
      "grad_norm": 1.4695276021957397,
      "learning_rate": 2.0434509432619706e-05,
      "loss": 0.474,
      "step": 834800
    },
    {
      "epoch": 8.838096347150396,
      "grad_norm": 1.427701711654663,
      "learning_rate": 2.04162224336355e-05,
      "loss": 0.4739,
      "step": 834850
    },
    {
      "epoch": 8.8386256689304,
      "grad_norm": 1.437007188796997,
      "learning_rate": 2.0397943272557202e-05,
      "loss": 0.4742,
      "step": 834900
    },
    {
      "epoch": 8.839154990710403,
      "grad_norm": 1.4528043270111084,
      "learning_rate": 2.0379671950008977e-05,
      "loss": 0.4725,
      "step": 834950
    },
    {
      "epoch": 8.839684312490405,
      "grad_norm": 1.339645266532898,
      "learning_rate": 2.0361408466614496e-05,
      "loss": 0.472,
      "step": 835000
    },
    {
      "epoch": 8.839684312490405,
      "eval_loss": 0.2933686077594757,
      "eval_runtime": 46.9037,
      "eval_samples_per_second": 3580.318,
      "eval_steps_per_second": 447.556,
      "step": 835000
    },
    {
      "epoch": 8.840213634270409,
      "grad_norm": 1.3494492769241333,
      "learning_rate": 2.034315282299734e-05,
      "loss": 0.4808,
      "step": 835050
    },
    {
      "epoch": 8.840742956050413,
      "grad_norm": 1.405953288078308,
      "learning_rate": 2.0324905019780682e-05,
      "loss": 0.4778,
      "step": 835100
    },
    {
      "epoch": 8.841272277830416,
      "grad_norm": 1.4906858205795288,
      "learning_rate": 2.0306665057587603e-05,
      "loss": 0.4845,
      "step": 835150
    },
    {
      "epoch": 8.841801599610418,
      "grad_norm": 1.2793233394622803,
      "learning_rate": 2.0288432937040662e-05,
      "loss": 0.4797,
      "step": 835200
    },
    {
      "epoch": 8.842330921390422,
      "grad_norm": 1.4694972038269043,
      "learning_rate": 2.0270208658762446e-05,
      "loss": 0.4749,
      "step": 835250
    },
    {
      "epoch": 8.842860243170426,
      "grad_norm": 1.2861865758895874,
      "learning_rate": 2.025199222337501e-05,
      "loss": 0.4773,
      "step": 835300
    },
    {
      "epoch": 8.84338956495043,
      "grad_norm": 1.3938379287719727,
      "learning_rate": 2.023378363150033e-05,
      "loss": 0.4834,
      "step": 835350
    },
    {
      "epoch": 8.843918886730432,
      "grad_norm": 1.4695913791656494,
      "learning_rate": 2.0215582883759992e-05,
      "loss": 0.4741,
      "step": 835400
    },
    {
      "epoch": 8.844448208510435,
      "grad_norm": 1.3545465469360352,
      "learning_rate": 2.0197389980775415e-05,
      "loss": 0.4763,
      "step": 835450
    },
    {
      "epoch": 8.84497753029044,
      "grad_norm": 1.2457650899887085,
      "learning_rate": 2.0179204923167605e-05,
      "loss": 0.4717,
      "step": 835500
    },
    {
      "epoch": 8.84497753029044,
      "eval_loss": 0.29338905215263367,
      "eval_runtime": 46.8907,
      "eval_samples_per_second": 3581.307,
      "eval_steps_per_second": 447.679,
      "step": 835500
    },
    {
      "epoch": 8.845506852070443,
      "grad_norm": 1.5275079011917114,
      "learning_rate": 2.0161027711557504e-05,
      "loss": 0.4752,
      "step": 835550
    },
    {
      "epoch": 8.846036173850445,
      "grad_norm": 1.3297531604766846,
      "learning_rate": 2.0142858346565595e-05,
      "loss": 0.4833,
      "step": 835600
    },
    {
      "epoch": 8.846565495630449,
      "grad_norm": 1.4691240787506104,
      "learning_rate": 2.0124696828812265e-05,
      "loss": 0.4757,
      "step": 835650
    },
    {
      "epoch": 8.847094817410452,
      "grad_norm": 1.4011423587799072,
      "learning_rate": 2.0106543158917414e-05,
      "loss": 0.4847,
      "step": 835700
    },
    {
      "epoch": 8.847624139190454,
      "grad_norm": 1.4343281984329224,
      "learning_rate": 2.0088397337500868e-05,
      "loss": 0.4787,
      "step": 835750
    },
    {
      "epoch": 8.848153460970458,
      "grad_norm": 1.336463451385498,
      "learning_rate": 2.007025936518217e-05,
      "loss": 0.4773,
      "step": 835800
    },
    {
      "epoch": 8.848682782750462,
      "grad_norm": 1.369313359260559,
      "learning_rate": 2.005212924258043e-05,
      "loss": 0.4798,
      "step": 835850
    },
    {
      "epoch": 8.849212104530466,
      "grad_norm": 1.4877195358276367,
      "learning_rate": 2.0034006970314684e-05,
      "loss": 0.4717,
      "step": 835900
    },
    {
      "epoch": 8.849741426310468,
      "grad_norm": 1.4881914854049683,
      "learning_rate": 2.0015892549003657e-05,
      "loss": 0.4803,
      "step": 835950
    },
    {
      "epoch": 8.850270748090471,
      "grad_norm": 1.401997447013855,
      "learning_rate": 1.999778597926566e-05,
      "loss": 0.4821,
      "step": 836000
    },
    {
      "epoch": 8.850270748090471,
      "eval_loss": 0.2933776378631592,
      "eval_runtime": 46.8263,
      "eval_samples_per_second": 3586.229,
      "eval_steps_per_second": 448.295,
      "step": 836000
    },
    {
      "epoch": 8.850800069870475,
      "grad_norm": 1.3700556755065918,
      "learning_rate": 1.997968726171895e-05,
      "loss": 0.4816,
      "step": 836050
    },
    {
      "epoch": 8.851329391650479,
      "grad_norm": 1.291996955871582,
      "learning_rate": 1.996159639698128e-05,
      "loss": 0.4803,
      "step": 836100
    },
    {
      "epoch": 8.851858713430481,
      "grad_norm": 1.3453373908996582,
      "learning_rate": 1.9943513385670437e-05,
      "loss": 0.4756,
      "step": 836150
    },
    {
      "epoch": 8.852388035210485,
      "grad_norm": 1.2990069389343262,
      "learning_rate": 1.9925799654575334e-05,
      "loss": 0.4784,
      "step": 836200
    },
    {
      "epoch": 8.852917356990488,
      "grad_norm": 1.3516364097595215,
      "learning_rate": 1.9907732194870436e-05,
      "loss": 0.4749,
      "step": 836250
    },
    {
      "epoch": 8.853446678770492,
      "grad_norm": 1.2842872142791748,
      "learning_rate": 1.9889672590431147e-05,
      "loss": 0.4768,
      "step": 836300
    },
    {
      "epoch": 8.853976000550494,
      "grad_norm": 1.340527057647705,
      "learning_rate": 1.987162084187402e-05,
      "loss": 0.4774,
      "step": 836350
    },
    {
      "epoch": 8.854505322330498,
      "grad_norm": 1.4752000570297241,
      "learning_rate": 1.9853576949815432e-05,
      "loss": 0.4774,
      "step": 836400
    },
    {
      "epoch": 8.855034644110502,
      "grad_norm": 1.297048807144165,
      "learning_rate": 1.9835540914871277e-05,
      "loss": 0.4775,
      "step": 836450
    },
    {
      "epoch": 8.855563965890504,
      "grad_norm": 1.2823187112808228,
      "learning_rate": 1.9817512737657335e-05,
      "loss": 0.4758,
      "step": 836500
    },
    {
      "epoch": 8.855563965890504,
      "eval_loss": 0.2931692600250244,
      "eval_runtime": 46.8748,
      "eval_samples_per_second": 3582.52,
      "eval_steps_per_second": 447.831,
      "step": 836500
    },
    {
      "epoch": 8.856093287670507,
      "grad_norm": 1.3439462184906006,
      "learning_rate": 1.9799492418789146e-05,
      "loss": 0.4736,
      "step": 836550
    },
    {
      "epoch": 8.856622609450511,
      "grad_norm": 1.4935470819473267,
      "learning_rate": 1.9781479958881797e-05,
      "loss": 0.4893,
      "step": 836600
    },
    {
      "epoch": 8.857151931230515,
      "grad_norm": 1.2675647735595703,
      "learning_rate": 1.9763475358550357e-05,
      "loss": 0.4769,
      "step": 836650
    },
    {
      "epoch": 8.857681253010517,
      "grad_norm": 1.1758733987808228,
      "learning_rate": 1.974547861840939e-05,
      "loss": 0.4766,
      "step": 836700
    },
    {
      "epoch": 8.85821057479052,
      "grad_norm": 1.426067590713501,
      "learning_rate": 1.9727489739073374e-05,
      "loss": 0.4755,
      "step": 836750
    },
    {
      "epoch": 8.858739896570524,
      "grad_norm": 1.2110897302627563,
      "learning_rate": 1.9709508721156343e-05,
      "loss": 0.477,
      "step": 836800
    },
    {
      "epoch": 8.859269218350528,
      "grad_norm": 1.5672022104263306,
      "learning_rate": 1.9691535565272284e-05,
      "loss": 0.4819,
      "step": 836850
    },
    {
      "epoch": 8.85979854013053,
      "grad_norm": 1.3518543243408203,
      "learning_rate": 1.9673570272034703e-05,
      "loss": 0.4712,
      "step": 836900
    },
    {
      "epoch": 8.860327861910534,
      "grad_norm": 1.3466367721557617,
      "learning_rate": 1.9655612842057023e-05,
      "loss": 0.4801,
      "step": 836950
    },
    {
      "epoch": 8.860857183690538,
      "grad_norm": 1.2545409202575684,
      "learning_rate": 1.963766327595218e-05,
      "loss": 0.4791,
      "step": 837000
    },
    {
      "epoch": 8.860857183690538,
      "eval_loss": 0.29292452335357666,
      "eval_runtime": 46.8143,
      "eval_samples_per_second": 3587.149,
      "eval_steps_per_second": 448.41,
      "step": 837000
    },
    {
      "epoch": 8.861386505470541,
      "grad_norm": 1.4417988061904907,
      "learning_rate": 1.961972157433306e-05,
      "loss": 0.4741,
      "step": 837050
    },
    {
      "epoch": 8.861915827250543,
      "grad_norm": 1.524970531463623,
      "learning_rate": 1.9601787737812155e-05,
      "loss": 0.4678,
      "step": 837100
    },
    {
      "epoch": 8.862445149030547,
      "grad_norm": 1.329976201057434,
      "learning_rate": 1.958386176700172e-05,
      "loss": 0.4747,
      "step": 837150
    },
    {
      "epoch": 8.862974470810551,
      "grad_norm": 1.4277739524841309,
      "learning_rate": 1.9565943662513714e-05,
      "loss": 0.4803,
      "step": 837200
    },
    {
      "epoch": 8.863503792590553,
      "grad_norm": 1.3886134624481201,
      "learning_rate": 1.954803342495992e-05,
      "loss": 0.4772,
      "step": 837250
    },
    {
      "epoch": 8.864033114370557,
      "grad_norm": 1.4789035320281982,
      "learning_rate": 1.9530131054951716e-05,
      "loss": 0.4804,
      "step": 837300
    },
    {
      "epoch": 8.86456243615056,
      "grad_norm": 1.3984167575836182,
      "learning_rate": 1.951223655310036e-05,
      "loss": 0.4747,
      "step": 837350
    },
    {
      "epoch": 8.865091757930564,
      "grad_norm": 1.4403921365737915,
      "learning_rate": 1.949434992001667e-05,
      "loss": 0.4778,
      "step": 837400
    },
    {
      "epoch": 8.865621079710566,
      "grad_norm": 1.370214819908142,
      "learning_rate": 1.9476471156311405e-05,
      "loss": 0.4753,
      "step": 837450
    },
    {
      "epoch": 8.86615040149057,
      "grad_norm": 1.2129405736923218,
      "learning_rate": 1.94586002625948e-05,
      "loss": 0.4766,
      "step": 837500
    },
    {
      "epoch": 8.86615040149057,
      "eval_loss": 0.2931399941444397,
      "eval_runtime": 47.1449,
      "eval_samples_per_second": 3561.994,
      "eval_steps_per_second": 445.265,
      "step": 837500
    },
    {
      "epoch": 8.866679723270574,
      "grad_norm": 1.31532621383667,
      "learning_rate": 1.944073723947709e-05,
      "loss": 0.4759,
      "step": 837550
    },
    {
      "epoch": 8.867209045050577,
      "grad_norm": 1.3116098642349243,
      "learning_rate": 1.9422882087567985e-05,
      "loss": 0.4745,
      "step": 837600
    },
    {
      "epoch": 8.86773836683058,
      "grad_norm": 1.3025791645050049,
      "learning_rate": 1.9405034807477184e-05,
      "loss": 0.4839,
      "step": 837650
    },
    {
      "epoch": 8.868267688610583,
      "grad_norm": 1.3324334621429443,
      "learning_rate": 1.93871953998139e-05,
      "loss": 0.4743,
      "step": 837700
    },
    {
      "epoch": 8.868797010390587,
      "grad_norm": 1.2142380475997925,
      "learning_rate": 1.9369363865187228e-05,
      "loss": 0.4763,
      "step": 837750
    },
    {
      "epoch": 8.86932633217059,
      "grad_norm": 1.4814046621322632,
      "learning_rate": 1.9351540204205846e-05,
      "loss": 0.4738,
      "step": 837800
    },
    {
      "epoch": 8.869855653950593,
      "grad_norm": 1.4577932357788086,
      "learning_rate": 1.9333724417478328e-05,
      "loss": 0.4748,
      "step": 837850
    },
    {
      "epoch": 8.870384975730596,
      "grad_norm": 1.2650953531265259,
      "learning_rate": 1.9315916505612817e-05,
      "loss": 0.4745,
      "step": 837900
    },
    {
      "epoch": 8.8709142975106,
      "grad_norm": 1.4116605520248413,
      "learning_rate": 1.9298116469217335e-05,
      "loss": 0.4813,
      "step": 837950
    },
    {
      "epoch": 8.871443619290602,
      "grad_norm": 1.3635711669921875,
      "learning_rate": 1.928032430889956e-05,
      "loss": 0.4705,
      "step": 838000
    },
    {
      "epoch": 8.871443619290602,
      "eval_loss": 0.2930363118648529,
      "eval_runtime": 46.8738,
      "eval_samples_per_second": 3582.595,
      "eval_steps_per_second": 447.84,
      "step": 838000
    },
    {
      "epoch": 8.871972941070606,
      "grad_norm": 1.3563339710235596,
      "learning_rate": 1.9262540025266895e-05,
      "loss": 0.4698,
      "step": 838050
    },
    {
      "epoch": 8.87250226285061,
      "grad_norm": 1.422003149986267,
      "learning_rate": 1.9244763618926464e-05,
      "loss": 0.4773,
      "step": 838100
    },
    {
      "epoch": 8.873031584630613,
      "grad_norm": 1.5043092966079712,
      "learning_rate": 1.9226995090485227e-05,
      "loss": 0.4823,
      "step": 838150
    },
    {
      "epoch": 8.873560906410615,
      "grad_norm": 1.4502224922180176,
      "learning_rate": 1.92092344405497e-05,
      "loss": 0.4717,
      "step": 838200
    },
    {
      "epoch": 8.874090228190619,
      "grad_norm": 1.404392957687378,
      "learning_rate": 1.919148166972634e-05,
      "loss": 0.4804,
      "step": 838250
    },
    {
      "epoch": 8.874619549970623,
      "grad_norm": 1.4336634874343872,
      "learning_rate": 1.9173736778621082e-05,
      "loss": 0.4777,
      "step": 838300
    },
    {
      "epoch": 8.875148871750627,
      "grad_norm": 1.3831745386123657,
      "learning_rate": 1.9155999767839827e-05,
      "loss": 0.4746,
      "step": 838350
    },
    {
      "epoch": 8.875678193530629,
      "grad_norm": 1.3624128103256226,
      "learning_rate": 1.9138270637988066e-05,
      "loss": 0.4718,
      "step": 838400
    },
    {
      "epoch": 8.876207515310632,
      "grad_norm": 1.2450872659683228,
      "learning_rate": 1.91209037373945e-05,
      "loss": 0.4754,
      "step": 838450
    },
    {
      "epoch": 8.876736837090636,
      "grad_norm": 1.42336106300354,
      "learning_rate": 1.9103190213568546e-05,
      "loss": 0.4754,
      "step": 838500
    },
    {
      "epoch": 8.876736837090636,
      "eval_loss": 0.2930881977081299,
      "eval_runtime": 46.8883,
      "eval_samples_per_second": 3581.492,
      "eval_steps_per_second": 447.702,
      "step": 838500
    },
    {
      "epoch": 8.87726615887064,
      "grad_norm": 1.256155252456665,
      "learning_rate": 1.9085484572474998e-05,
      "loss": 0.4693,
      "step": 838550
    },
    {
      "epoch": 8.877795480650642,
      "grad_norm": 1.4736220836639404,
      "learning_rate": 1.906778681471835e-05,
      "loss": 0.4783,
      "step": 838600
    },
    {
      "epoch": 8.878324802430646,
      "grad_norm": 1.3561400175094604,
      "learning_rate": 1.9050096940902763e-05,
      "loss": 0.4765,
      "step": 838650
    },
    {
      "epoch": 8.87885412421065,
      "grad_norm": 1.335592269897461,
      "learning_rate": 1.9032414951632188e-05,
      "loss": 0.4752,
      "step": 838700
    },
    {
      "epoch": 8.879383445990651,
      "grad_norm": 1.4147087335586548,
      "learning_rate": 1.9014740847510205e-05,
      "loss": 0.4735,
      "step": 838750
    },
    {
      "epoch": 8.879912767770655,
      "grad_norm": 1.335781455039978,
      "learning_rate": 1.8997074629140325e-05,
      "loss": 0.4683,
      "step": 838800
    },
    {
      "epoch": 8.880442089550659,
      "grad_norm": 1.3326207399368286,
      "learning_rate": 1.8979416297125545e-05,
      "loss": 0.4722,
      "step": 838850
    },
    {
      "epoch": 8.880971411330663,
      "grad_norm": 1.4753601551055908,
      "learning_rate": 1.8961765852068825e-05,
      "loss": 0.4802,
      "step": 838900
    },
    {
      "epoch": 8.881500733110665,
      "grad_norm": 1.4134985208511353,
      "learning_rate": 1.8944123294572624e-05,
      "loss": 0.4742,
      "step": 838950
    },
    {
      "epoch": 8.882030054890668,
      "grad_norm": 1.4179868698120117,
      "learning_rate": 1.892648862523938e-05,
      "loss": 0.4737,
      "step": 839000
    },
    {
      "epoch": 8.882030054890668,
      "eval_loss": 0.29289960861206055,
      "eval_runtime": 46.8562,
      "eval_samples_per_second": 3583.943,
      "eval_steps_per_second": 448.009,
      "step": 839000
    },
    {
      "epoch": 8.882559376670672,
      "grad_norm": 1.48868727684021,
      "learning_rate": 1.8908861844671e-05,
      "loss": 0.4726,
      "step": 839050
    },
    {
      "epoch": 8.883088698450676,
      "grad_norm": 1.4534215927124023,
      "learning_rate": 1.889124295346939e-05,
      "loss": 0.4726,
      "step": 839100
    },
    {
      "epoch": 8.883618020230678,
      "grad_norm": 1.3021384477615356,
      "learning_rate": 1.887363195223593e-05,
      "loss": 0.4797,
      "step": 839150
    },
    {
      "epoch": 8.884147342010682,
      "grad_norm": 1.308156132698059,
      "learning_rate": 1.8856028841571977e-05,
      "loss": 0.4844,
      "step": 839200
    },
    {
      "epoch": 8.884676663790685,
      "grad_norm": 1.3232718706130981,
      "learning_rate": 1.8838433622078377e-05,
      "loss": 0.4767,
      "step": 839250
    },
    {
      "epoch": 8.885205985570689,
      "grad_norm": 1.362308144569397,
      "learning_rate": 1.882084629435593e-05,
      "loss": 0.4759,
      "step": 839300
    },
    {
      "epoch": 8.885735307350691,
      "grad_norm": 1.2114195823669434,
      "learning_rate": 1.8803266859004935e-05,
      "loss": 0.4761,
      "step": 839350
    },
    {
      "epoch": 8.886264629130695,
      "grad_norm": 1.5587809085845947,
      "learning_rate": 1.8785695316625688e-05,
      "loss": 0.4838,
      "step": 839400
    },
    {
      "epoch": 8.886793950910699,
      "grad_norm": 1.4438968896865845,
      "learning_rate": 1.8768131667817962e-05,
      "loss": 0.476,
      "step": 839450
    },
    {
      "epoch": 8.8873232726907,
      "grad_norm": 1.2185438871383667,
      "learning_rate": 1.8750575913181468e-05,
      "loss": 0.4708,
      "step": 839500
    },
    {
      "epoch": 8.8873232726907,
      "eval_loss": 0.29270270466804504,
      "eval_runtime": 46.8898,
      "eval_samples_per_second": 3581.378,
      "eval_steps_per_second": 447.688,
      "step": 839500
    },
    {
      "epoch": 8.887852594470704,
      "grad_norm": 1.5080783367156982,
      "learning_rate": 1.8733028053315447e-05,
      "loss": 0.4859,
      "step": 839550
    },
    {
      "epoch": 8.888381916250708,
      "grad_norm": 1.3733001947402954,
      "learning_rate": 1.8715488088819066e-05,
      "loss": 0.4726,
      "step": 839600
    },
    {
      "epoch": 8.888911238030712,
      "grad_norm": 1.4025002717971802,
      "learning_rate": 1.869795602029109e-05,
      "loss": 0.4719,
      "step": 839650
    },
    {
      "epoch": 8.889440559810714,
      "grad_norm": 1.43815279006958,
      "learning_rate": 1.86804318483301e-05,
      "loss": 0.4759,
      "step": 839700
    },
    {
      "epoch": 8.889969881590718,
      "grad_norm": 1.3716316223144531,
      "learning_rate": 1.8662915573534277e-05,
      "loss": 0.4789,
      "step": 839750
    },
    {
      "epoch": 8.890499203370721,
      "grad_norm": 1.377408504486084,
      "learning_rate": 1.8645407196501735e-05,
      "loss": 0.472,
      "step": 839800
    },
    {
      "epoch": 8.891028525150725,
      "grad_norm": 1.4802465438842773,
      "learning_rate": 1.8627906717830073e-05,
      "loss": 0.472,
      "step": 839850
    },
    {
      "epoch": 8.891557846930727,
      "grad_norm": 1.2065644264221191,
      "learning_rate": 1.86104141381169e-05,
      "loss": 0.4748,
      "step": 839900
    },
    {
      "epoch": 8.89208716871073,
      "grad_norm": 1.354276180267334,
      "learning_rate": 1.859292945795926e-05,
      "loss": 0.4738,
      "step": 839950
    },
    {
      "epoch": 8.892616490490735,
      "grad_norm": 1.3459854125976562,
      "learning_rate": 1.8575452677954157e-05,
      "loss": 0.4733,
      "step": 840000
    },
    {
      "epoch": 8.892616490490735,
      "eval_loss": 0.2927502691745758,
      "eval_runtime": 46.8857,
      "eval_samples_per_second": 3581.69,
      "eval_steps_per_second": 447.727,
      "step": 840000
    },
    {
      "epoch": 8.893145812270738,
      "grad_norm": 1.2030794620513916,
      "learning_rate": 1.8557983798698246e-05,
      "loss": 0.4825,
      "step": 840050
    },
    {
      "epoch": 8.89367513405074,
      "grad_norm": 1.3935304880142212,
      "learning_rate": 1.8540522820787885e-05,
      "loss": 0.479,
      "step": 840100
    },
    {
      "epoch": 8.894204455830744,
      "grad_norm": 1.3220701217651367,
      "learning_rate": 1.852306974481921e-05,
      "loss": 0.4741,
      "step": 840150
    },
    {
      "epoch": 8.894733777610748,
      "grad_norm": 1.5006600618362427,
      "learning_rate": 1.8505624571387993e-05,
      "loss": 0.4888,
      "step": 840200
    },
    {
      "epoch": 8.89526309939075,
      "grad_norm": 1.4576396942138672,
      "learning_rate": 1.8488187301089863e-05,
      "loss": 0.4852,
      "step": 840250
    },
    {
      "epoch": 8.895792421170754,
      "grad_norm": 1.3149280548095703,
      "learning_rate": 1.847075793452016e-05,
      "loss": 0.4744,
      "step": 840300
    },
    {
      "epoch": 8.896321742950757,
      "grad_norm": 1.4150078296661377,
      "learning_rate": 1.8453336472273818e-05,
      "loss": 0.4774,
      "step": 840350
    },
    {
      "epoch": 8.896851064730761,
      "grad_norm": 1.379838228225708,
      "learning_rate": 1.8435922914945726e-05,
      "loss": 0.4743,
      "step": 840400
    },
    {
      "epoch": 8.897380386510763,
      "grad_norm": 1.4526666402816772,
      "learning_rate": 1.8418517263130236e-05,
      "loss": 0.4672,
      "step": 840450
    },
    {
      "epoch": 8.897909708290767,
      "grad_norm": 1.4470412731170654,
      "learning_rate": 1.8401119517421654e-05,
      "loss": 0.4804,
      "step": 840500
    },
    {
      "epoch": 8.897909708290767,
      "eval_loss": 0.2927674353122711,
      "eval_runtime": 46.8029,
      "eval_samples_per_second": 3588.029,
      "eval_steps_per_second": 448.52,
      "step": 840500
    },
    {
      "epoch": 8.89843903007077,
      "grad_norm": 1.506812334060669,
      "learning_rate": 1.8383729678413896e-05,
      "loss": 0.4775,
      "step": 840550
    },
    {
      "epoch": 8.898968351850774,
      "grad_norm": 1.5561683177947998,
      "learning_rate": 1.8366347746700708e-05,
      "loss": 0.4774,
      "step": 840600
    },
    {
      "epoch": 8.899497673630776,
      "grad_norm": 1.4095021486282349,
      "learning_rate": 1.8348973722875416e-05,
      "loss": 0.4756,
      "step": 840650
    },
    {
      "epoch": 8.90002699541078,
      "grad_norm": 1.4069150686264038,
      "learning_rate": 1.833160760753125e-05,
      "loss": 0.4763,
      "step": 840700
    },
    {
      "epoch": 8.900556317190784,
      "grad_norm": 1.372423768043518,
      "learning_rate": 1.8314249401261e-05,
      "loss": 0.4709,
      "step": 840750
    },
    {
      "epoch": 8.901085638970788,
      "grad_norm": 1.3774008750915527,
      "learning_rate": 1.8296899104657343e-05,
      "loss": 0.472,
      "step": 840800
    },
    {
      "epoch": 8.90161496075079,
      "grad_norm": 1.4792019128799438,
      "learning_rate": 1.8279556718312525e-05,
      "loss": 0.4835,
      "step": 840850
    },
    {
      "epoch": 8.902144282530793,
      "grad_norm": 1.458633542060852,
      "learning_rate": 1.8262222242818704e-05,
      "loss": 0.4732,
      "step": 840900
    },
    {
      "epoch": 8.902673604310797,
      "grad_norm": 1.4184908866882324,
      "learning_rate": 1.8244895678767608e-05,
      "loss": 0.4682,
      "step": 840950
    },
    {
      "epoch": 8.903202926090799,
      "grad_norm": 1.3574612140655518,
      "learning_rate": 1.822757702675079e-05,
      "loss": 0.4665,
      "step": 841000
    },
    {
      "epoch": 8.903202926090799,
      "eval_loss": 0.29231417179107666,
      "eval_runtime": 46.9453,
      "eval_samples_per_second": 3577.145,
      "eval_steps_per_second": 447.159,
      "step": 841000
    },
    {
      "epoch": 8.903732247870803,
      "grad_norm": 1.3679827451705933,
      "learning_rate": 1.8210266287359472e-05,
      "loss": 0.4784,
      "step": 841050
    },
    {
      "epoch": 8.904261569650807,
      "grad_norm": 1.2382668256759644,
      "learning_rate": 1.819296346118471e-05,
      "loss": 0.4725,
      "step": 841100
    },
    {
      "epoch": 8.90479089143081,
      "grad_norm": 1.3145478963851929,
      "learning_rate": 1.817566854881708e-05,
      "loss": 0.4767,
      "step": 841150
    },
    {
      "epoch": 8.905320213210812,
      "grad_norm": 1.3611929416656494,
      "learning_rate": 1.8158727213241632e-05,
      "loss": 0.4746,
      "step": 841200
    },
    {
      "epoch": 8.905849534990816,
      "grad_norm": 1.3270883560180664,
      "learning_rate": 1.814144797195402e-05,
      "loss": 0.4718,
      "step": 841250
    },
    {
      "epoch": 8.90637885677082,
      "grad_norm": 1.3158392906188965,
      "learning_rate": 1.812417664623231e-05,
      "loss": 0.475,
      "step": 841300
    },
    {
      "epoch": 8.906908178550824,
      "grad_norm": 1.348389983177185,
      "learning_rate": 1.810691323666619e-05,
      "loss": 0.4897,
      "step": 841350
    },
    {
      "epoch": 8.907437500330825,
      "grad_norm": 1.392874002456665,
      "learning_rate": 1.8089657743844967e-05,
      "loss": 0.4782,
      "step": 841400
    },
    {
      "epoch": 8.90796682211083,
      "grad_norm": 1.3983161449432373,
      "learning_rate": 1.8072410168357838e-05,
      "loss": 0.4805,
      "step": 841450
    },
    {
      "epoch": 8.908496143890833,
      "grad_norm": 1.2735400199890137,
      "learning_rate": 1.80551705107935e-05,
      "loss": 0.4742,
      "step": 841500
    },
    {
      "epoch": 8.908496143890833,
      "eval_loss": 0.2926534414291382,
      "eval_runtime": 46.8757,
      "eval_samples_per_second": 3582.457,
      "eval_steps_per_second": 447.823,
      "step": 841500
    },
    {
      "epoch": 8.909025465670837,
      "grad_norm": 1.329208254814148,
      "learning_rate": 1.803793877174065e-05,
      "loss": 0.473,
      "step": 841550
    },
    {
      "epoch": 8.909554787450839,
      "grad_norm": 1.4066003561019897,
      "learning_rate": 1.802071495178742e-05,
      "loss": 0.4831,
      "step": 841600
    },
    {
      "epoch": 8.910084109230842,
      "grad_norm": 1.409493327140808,
      "learning_rate": 1.8003499051521987e-05,
      "loss": 0.4775,
      "step": 841650
    },
    {
      "epoch": 8.910613431010846,
      "grad_norm": 1.4014227390289307,
      "learning_rate": 1.7986291071531962e-05,
      "loss": 0.4733,
      "step": 841700
    },
    {
      "epoch": 8.911142752790848,
      "grad_norm": 1.5499204397201538,
      "learning_rate": 1.7969091012404905e-05,
      "loss": 0.4803,
      "step": 841750
    },
    {
      "epoch": 8.911672074570852,
      "grad_norm": 1.3265103101730347,
      "learning_rate": 1.795189887472795e-05,
      "loss": 0.4757,
      "step": 841800
    },
    {
      "epoch": 8.912201396350856,
      "grad_norm": 1.4215929508209229,
      "learning_rate": 1.793471465908808e-05,
      "loss": 0.4901,
      "step": 841850
    },
    {
      "epoch": 8.91273071813086,
      "grad_norm": 1.3371469974517822,
      "learning_rate": 1.7917538366071932e-05,
      "loss": 0.4654,
      "step": 841900
    },
    {
      "epoch": 8.913260039910861,
      "grad_norm": 1.3790289163589478,
      "learning_rate": 1.7900369996265957e-05,
      "loss": 0.4797,
      "step": 841950
    },
    {
      "epoch": 8.913789361690865,
      "grad_norm": 1.4815689325332642,
      "learning_rate": 1.7883209550256184e-05,
      "loss": 0.4815,
      "step": 842000
    },
    {
      "epoch": 8.913789361690865,
      "eval_loss": 0.2929789423942566,
      "eval_runtime": 46.9273,
      "eval_samples_per_second": 3578.512,
      "eval_steps_per_second": 447.33,
      "step": 842000
    },
    {
      "epoch": 8.914318683470869,
      "grad_norm": 1.4338173866271973,
      "learning_rate": 1.786605702862848e-05,
      "loss": 0.4731,
      "step": 842050
    },
    {
      "epoch": 8.914848005250873,
      "grad_norm": 1.3446595668792725,
      "learning_rate": 1.784891243196854e-05,
      "loss": 0.4735,
      "step": 842100
    },
    {
      "epoch": 8.915377327030875,
      "grad_norm": 1.2848708629608154,
      "learning_rate": 1.7831775760861534e-05,
      "loss": 0.4709,
      "step": 842150
    },
    {
      "epoch": 8.915906648810878,
      "grad_norm": 1.3699604272842407,
      "learning_rate": 1.7814647015892583e-05,
      "loss": 0.4732,
      "step": 842200
    },
    {
      "epoch": 8.916435970590882,
      "grad_norm": 1.3477354049682617,
      "learning_rate": 1.779752619764641e-05,
      "loss": 0.4842,
      "step": 842250
    },
    {
      "epoch": 8.916965292370886,
      "grad_norm": 1.3880244493484497,
      "learning_rate": 1.7780413306707515e-05,
      "loss": 0.4746,
      "step": 842300
    },
    {
      "epoch": 8.917494614150888,
      "grad_norm": 1.3928866386413574,
      "learning_rate": 1.7763308343660218e-05,
      "loss": 0.4827,
      "step": 842350
    },
    {
      "epoch": 8.918023935930892,
      "grad_norm": 1.2776445150375366,
      "learning_rate": 1.774621130908835e-05,
      "loss": 0.4787,
      "step": 842400
    },
    {
      "epoch": 8.918553257710895,
      "grad_norm": 1.388458490371704,
      "learning_rate": 1.772912220357567e-05,
      "loss": 0.4779,
      "step": 842450
    },
    {
      "epoch": 8.919082579490897,
      "grad_norm": 1.5665278434753418,
      "learning_rate": 1.771204102770557e-05,
      "loss": 0.4846,
      "step": 842500
    },
    {
      "epoch": 8.919082579490897,
      "eval_loss": 0.29266229271888733,
      "eval_runtime": 46.822,
      "eval_samples_per_second": 3586.564,
      "eval_steps_per_second": 448.336,
      "step": 842500
    },
    {
      "epoch": 8.919611901270901,
      "grad_norm": 1.284153938293457,
      "learning_rate": 1.7694967782061226e-05,
      "loss": 0.4734,
      "step": 842550
    },
    {
      "epoch": 8.920141223050905,
      "grad_norm": 1.3489813804626465,
      "learning_rate": 1.767790246722542e-05,
      "loss": 0.4797,
      "step": 842600
    },
    {
      "epoch": 8.920670544830909,
      "grad_norm": 1.2781977653503418,
      "learning_rate": 1.7660845083780908e-05,
      "loss": 0.4777,
      "step": 842650
    },
    {
      "epoch": 8.92119986661091,
      "grad_norm": 1.3934872150421143,
      "learning_rate": 1.7643795632309863e-05,
      "loss": 0.4731,
      "step": 842700
    },
    {
      "epoch": 8.921729188390914,
      "grad_norm": 1.3637619018554688,
      "learning_rate": 1.7626754113394482e-05,
      "loss": 0.4767,
      "step": 842750
    },
    {
      "epoch": 8.922258510170918,
      "grad_norm": 1.4884573221206665,
      "learning_rate": 1.760972052761642e-05,
      "loss": 0.4788,
      "step": 842800
    },
    {
      "epoch": 8.922787831950922,
      "grad_norm": 1.2118788957595825,
      "learning_rate": 1.7592694875557343e-05,
      "loss": 0.4751,
      "step": 842850
    },
    {
      "epoch": 8.923317153730924,
      "grad_norm": 1.3442455530166626,
      "learning_rate": 1.7575677157798398e-05,
      "loss": 0.47,
      "step": 842900
    },
    {
      "epoch": 8.923846475510928,
      "grad_norm": 1.3499629497528076,
      "learning_rate": 1.7558667374920623e-05,
      "loss": 0.472,
      "step": 842950
    },
    {
      "epoch": 8.924375797290931,
      "grad_norm": 1.2584466934204102,
      "learning_rate": 1.7541665527504634e-05,
      "loss": 0.4806,
      "step": 843000
    },
    {
      "epoch": 8.924375797290931,
      "eval_loss": 0.2926170229911804,
      "eval_runtime": 46.9441,
      "eval_samples_per_second": 3577.232,
      "eval_steps_per_second": 447.17,
      "step": 843000
    },
    {
      "epoch": 8.924905119070935,
      "grad_norm": 1.3443948030471802,
      "learning_rate": 1.7524671616131e-05,
      "loss": 0.4795,
      "step": 843050
    },
    {
      "epoch": 8.925434440850937,
      "grad_norm": 1.4412102699279785,
      "learning_rate": 1.750768564137978e-05,
      "loss": 0.4776,
      "step": 843100
    },
    {
      "epoch": 8.925963762630941,
      "grad_norm": 1.3854085206985474,
      "learning_rate": 1.749070760383095e-05,
      "loss": 0.4758,
      "step": 843150
    },
    {
      "epoch": 8.926493084410945,
      "grad_norm": 1.3164814710617065,
      "learning_rate": 1.747407682826535e-05,
      "loss": 0.4719,
      "step": 843200
    },
    {
      "epoch": 8.927022406190947,
      "grad_norm": 1.381556510925293,
      "learning_rate": 1.7457114508086904e-05,
      "loss": 0.4752,
      "step": 843250
    },
    {
      "epoch": 8.92755172797095,
      "grad_norm": 1.3865654468536377,
      "learning_rate": 1.7440160126837245e-05,
      "loss": 0.4791,
      "step": 843300
    },
    {
      "epoch": 8.928081049750954,
      "grad_norm": 1.3985075950622559,
      "learning_rate": 1.742321368509528e-05,
      "loss": 0.4733,
      "step": 843350
    },
    {
      "epoch": 8.928610371530958,
      "grad_norm": 1.4280524253845215,
      "learning_rate": 1.7406275183439457e-05,
      "loss": 0.4774,
      "step": 843400
    },
    {
      "epoch": 8.92913969331096,
      "grad_norm": 1.3430410623550415,
      "learning_rate": 1.738934462244815e-05,
      "loss": 0.4789,
      "step": 843450
    },
    {
      "epoch": 8.929669015090964,
      "grad_norm": 1.2946326732635498,
      "learning_rate": 1.7372422002699257e-05,
      "loss": 0.4828,
      "step": 843500
    },
    {
      "epoch": 8.929669015090964,
      "eval_loss": 0.29258424043655396,
      "eval_runtime": 46.8245,
      "eval_samples_per_second": 3586.37,
      "eval_steps_per_second": 448.312,
      "step": 843500
    },
    {
      "epoch": 8.930198336870967,
      "grad_norm": 1.3576756715774536,
      "learning_rate": 1.735550732477059e-05,
      "loss": 0.4751,
      "step": 843550
    },
    {
      "epoch": 8.930727658650971,
      "grad_norm": 1.431856632232666,
      "learning_rate": 1.7338600589239554e-05,
      "loss": 0.4763,
      "step": 843600
    },
    {
      "epoch": 8.931256980430973,
      "grad_norm": 1.3931736946105957,
      "learning_rate": 1.7321701796683435e-05,
      "loss": 0.483,
      "step": 843650
    },
    {
      "epoch": 8.931786302210977,
      "grad_norm": 1.268256664276123,
      "learning_rate": 1.7304810947679023e-05,
      "loss": 0.4747,
      "step": 843700
    },
    {
      "epoch": 8.93231562399098,
      "grad_norm": 1.4305349588394165,
      "learning_rate": 1.7287928042803046e-05,
      "loss": 0.4781,
      "step": 843750
    },
    {
      "epoch": 8.932844945770984,
      "grad_norm": 1.1937741041183472,
      "learning_rate": 1.7271053082631855e-05,
      "loss": 0.4743,
      "step": 843800
    },
    {
      "epoch": 8.933374267550986,
      "grad_norm": 1.5140172243118286,
      "learning_rate": 1.7254186067741595e-05,
      "loss": 0.4758,
      "step": 843850
    },
    {
      "epoch": 8.93390358933099,
      "grad_norm": 1.4310336112976074,
      "learning_rate": 1.7237326998708003e-05,
      "loss": 0.4844,
      "step": 843900
    },
    {
      "epoch": 8.934432911110994,
      "grad_norm": 1.4080708026885986,
      "learning_rate": 1.7220475876106757e-05,
      "loss": 0.4796,
      "step": 843950
    },
    {
      "epoch": 8.934962232890996,
      "grad_norm": 1.461108684539795,
      "learning_rate": 1.7203632700513063e-05,
      "loss": 0.4791,
      "step": 844000
    },
    {
      "epoch": 8.934962232890996,
      "eval_loss": 0.29223257303237915,
      "eval_runtime": 46.8161,
      "eval_samples_per_second": 3587.016,
      "eval_steps_per_second": 448.393,
      "step": 844000
    },
    {
      "epoch": 8.935491554671,
      "grad_norm": 1.3701728582382202,
      "learning_rate": 1.7186797472502013e-05,
      "loss": 0.4769,
      "step": 844050
    },
    {
      "epoch": 8.936020876451003,
      "grad_norm": 1.3643348217010498,
      "learning_rate": 1.7169970192648267e-05,
      "loss": 0.4718,
      "step": 844100
    },
    {
      "epoch": 8.936550198231007,
      "grad_norm": 1.4215667247772217,
      "learning_rate": 1.7153150861526383e-05,
      "loss": 0.4705,
      "step": 844150
    },
    {
      "epoch": 8.93707952001101,
      "grad_norm": 1.4544957876205444,
      "learning_rate": 1.7136339479710524e-05,
      "loss": 0.4743,
      "step": 844200
    },
    {
      "epoch": 8.937608841791013,
      "grad_norm": 1.4640240669250488,
      "learning_rate": 1.7119536047774636e-05,
      "loss": 0.4758,
      "step": 844250
    },
    {
      "epoch": 8.938138163571017,
      "grad_norm": 1.4212602376937866,
      "learning_rate": 1.710274056629235e-05,
      "loss": 0.4788,
      "step": 844300
    },
    {
      "epoch": 8.93866748535102,
      "grad_norm": 1.3382337093353271,
      "learning_rate": 1.7085953035837097e-05,
      "loss": 0.4751,
      "step": 844350
    },
    {
      "epoch": 8.939196807131022,
      "grad_norm": 1.4564234018325806,
      "learning_rate": 1.7069173456982056e-05,
      "loss": 0.4796,
      "step": 844400
    },
    {
      "epoch": 8.939726128911026,
      "grad_norm": 1.3866772651672363,
      "learning_rate": 1.7052401830299936e-05,
      "loss": 0.4771,
      "step": 844450
    },
    {
      "epoch": 8.94025545069103,
      "grad_norm": 1.4512531757354736,
      "learning_rate": 1.7035638156363387e-05,
      "loss": 0.4719,
      "step": 844500
    },
    {
      "epoch": 8.94025545069103,
      "eval_loss": 0.29213187098503113,
      "eval_runtime": 47.008,
      "eval_samples_per_second": 3572.374,
      "eval_steps_per_second": 446.563,
      "step": 844500
    },
    {
      "epoch": 8.940784772471034,
      "grad_norm": 1.4500219821929932,
      "learning_rate": 1.7018882435744758e-05,
      "loss": 0.4743,
      "step": 844550
    },
    {
      "epoch": 8.941314094251036,
      "grad_norm": 1.4272125959396362,
      "learning_rate": 1.700213466901601e-05,
      "loss": 0.4771,
      "step": 844600
    },
    {
      "epoch": 8.94184341603104,
      "grad_norm": 1.3331003189086914,
      "learning_rate": 1.6985394856748966e-05,
      "loss": 0.4639,
      "step": 844650
    },
    {
      "epoch": 8.942372737811043,
      "grad_norm": 1.3656009435653687,
      "learning_rate": 1.696866299951505e-05,
      "loss": 0.4763,
      "step": 844700
    },
    {
      "epoch": 8.942902059591045,
      "grad_norm": 1.2986235618591309,
      "learning_rate": 1.6951939097885532e-05,
      "loss": 0.4725,
      "step": 844750
    },
    {
      "epoch": 8.943431381371049,
      "grad_norm": 1.4495317935943604,
      "learning_rate": 1.6935223152431344e-05,
      "loss": 0.478,
      "step": 844800
    },
    {
      "epoch": 8.943960703151053,
      "grad_norm": 1.3642902374267578,
      "learning_rate": 1.691851516372317e-05,
      "loss": 0.4741,
      "step": 844850
    },
    {
      "epoch": 8.944490024931056,
      "grad_norm": 1.3841636180877686,
      "learning_rate": 1.6901815132331384e-05,
      "loss": 0.4763,
      "step": 844900
    },
    {
      "epoch": 8.945019346711058,
      "grad_norm": 1.331727385520935,
      "learning_rate": 1.6885123058826196e-05,
      "loss": 0.4703,
      "step": 844950
    },
    {
      "epoch": 8.945548668491062,
      "grad_norm": 1.5301430225372314,
      "learning_rate": 1.6868438943777347e-05,
      "loss": 0.4747,
      "step": 845000
    },
    {
      "epoch": 8.945548668491062,
      "eval_loss": 0.2920014560222626,
      "eval_runtime": 46.8037,
      "eval_samples_per_second": 3587.966,
      "eval_steps_per_second": 448.512,
      "step": 845000
    },
    {
      "epoch": 8.946077990271066,
      "grad_norm": 1.314854383468628,
      "learning_rate": 1.685176278775455e-05,
      "loss": 0.4714,
      "step": 845050
    },
    {
      "epoch": 8.94660731205107,
      "grad_norm": 1.4463826417922974,
      "learning_rate": 1.6835094591327037e-05,
      "loss": 0.4764,
      "step": 845100
    },
    {
      "epoch": 8.947136633831072,
      "grad_norm": 1.495988130569458,
      "learning_rate": 1.6818434355063917e-05,
      "loss": 0.4692,
      "step": 845150
    },
    {
      "epoch": 8.947665955611075,
      "grad_norm": 1.4109989404678345,
      "learning_rate": 1.6801782079533866e-05,
      "loss": 0.4787,
      "step": 845200
    },
    {
      "epoch": 8.94819527739108,
      "grad_norm": 1.1724106073379517,
      "learning_rate": 1.678513776530552e-05,
      "loss": 0.4722,
      "step": 845250
    },
    {
      "epoch": 8.948724599171083,
      "grad_norm": 1.4702954292297363,
      "learning_rate": 1.6768501412947e-05,
      "loss": 0.4871,
      "step": 845300
    },
    {
      "epoch": 8.949253920951085,
      "grad_norm": 1.456870436668396,
      "learning_rate": 1.675187302302633e-05,
      "loss": 0.477,
      "step": 845350
    },
    {
      "epoch": 8.949783242731089,
      "grad_norm": 1.4405595064163208,
      "learning_rate": 1.673525259611114e-05,
      "loss": 0.4711,
      "step": 845400
    },
    {
      "epoch": 8.950312564511092,
      "grad_norm": 1.4118232727050781,
      "learning_rate": 1.671864013276894e-05,
      "loss": 0.482,
      "step": 845450
    },
    {
      "epoch": 8.950841886291094,
      "grad_norm": 1.5025651454925537,
      "learning_rate": 1.6702035633566732e-05,
      "loss": 0.4765,
      "step": 845500
    },
    {
      "epoch": 8.950841886291094,
      "eval_loss": 0.2920190393924713,
      "eval_runtime": 46.9564,
      "eval_samples_per_second": 3576.294,
      "eval_steps_per_second": 447.053,
      "step": 845500
    },
    {
      "epoch": 8.951371208071098,
      "grad_norm": 1.3480433225631714,
      "learning_rate": 1.6685439099071553e-05,
      "loss": 0.48,
      "step": 845550
    },
    {
      "epoch": 8.951900529851102,
      "grad_norm": 1.2244402170181274,
      "learning_rate": 1.6668850529849844e-05,
      "loss": 0.4713,
      "step": 845600
    },
    {
      "epoch": 8.952429851631106,
      "grad_norm": 1.4375532865524292,
      "learning_rate": 1.6652269926468068e-05,
      "loss": 0.4785,
      "step": 845650
    },
    {
      "epoch": 8.952959173411108,
      "grad_norm": 1.3865687847137451,
      "learning_rate": 1.6635697289492157e-05,
      "loss": 0.4786,
      "step": 845700
    },
    {
      "epoch": 8.953488495191111,
      "grad_norm": 1.4256618022918701,
      "learning_rate": 1.6619132619487997e-05,
      "loss": 0.4648,
      "step": 845750
    },
    {
      "epoch": 8.954017816971115,
      "grad_norm": 1.3285897970199585,
      "learning_rate": 1.660257591702105e-05,
      "loss": 0.4853,
      "step": 845800
    },
    {
      "epoch": 8.954547138751119,
      "grad_norm": 1.3835827112197876,
      "learning_rate": 1.6586027182656588e-05,
      "loss": 0.4809,
      "step": 845850
    },
    {
      "epoch": 8.95507646053112,
      "grad_norm": 1.2900874614715576,
      "learning_rate": 1.6569486416959517e-05,
      "loss": 0.4732,
      "step": 845900
    },
    {
      "epoch": 8.955605782311125,
      "grad_norm": 1.393373727798462,
      "learning_rate": 1.6552953620494555e-05,
      "loss": 0.4819,
      "step": 845950
    },
    {
      "epoch": 8.956135104091128,
      "grad_norm": 1.3247122764587402,
      "learning_rate": 1.6536759212251923e-05,
      "loss": 0.474,
      "step": 846000
    },
    {
      "epoch": 8.956135104091128,
      "eval_loss": 0.2922932803630829,
      "eval_runtime": 46.7466,
      "eval_samples_per_second": 3592.345,
      "eval_steps_per_second": 449.059,
      "step": 846000
    },
    {
      "epoch": 8.956664425871132,
      "grad_norm": 1.5044844150543213,
      "learning_rate": 1.6520242196531478e-05,
      "loss": 0.4793,
      "step": 846050
    },
    {
      "epoch": 8.957193747651134,
      "grad_norm": 1.3408823013305664,
      "learning_rate": 1.6503733151724376e-05,
      "loss": 0.4688,
      "step": 846100
    },
    {
      "epoch": 8.957723069431138,
      "grad_norm": 1.3584996461868286,
      "learning_rate": 1.648723207839417e-05,
      "loss": 0.4764,
      "step": 846150
    },
    {
      "epoch": 8.958252391211142,
      "grad_norm": 1.4876821041107178,
      "learning_rate": 1.6470738977104243e-05,
      "loss": 0.4803,
      "step": 846200
    },
    {
      "epoch": 8.958781712991144,
      "grad_norm": 1.350579857826233,
      "learning_rate": 1.6454253848417616e-05,
      "loss": 0.4833,
      "step": 846250
    },
    {
      "epoch": 8.959311034771147,
      "grad_norm": 1.4947266578674316,
      "learning_rate": 1.6437776692897144e-05,
      "loss": 0.477,
      "step": 846300
    },
    {
      "epoch": 8.959840356551151,
      "grad_norm": 1.2861231565475464,
      "learning_rate": 1.6421307511105292e-05,
      "loss": 0.474,
      "step": 846350
    },
    {
      "epoch": 8.960369678331155,
      "grad_norm": 1.3579630851745605,
      "learning_rate": 1.640484630360434e-05,
      "loss": 0.4827,
      "step": 846400
    },
    {
      "epoch": 8.960899000111157,
      "grad_norm": 1.5587552785873413,
      "learning_rate": 1.638839307095627e-05,
      "loss": 0.4709,
      "step": 846450
    },
    {
      "epoch": 8.96142832189116,
      "grad_norm": 1.3030383586883545,
      "learning_rate": 1.637194781372278e-05,
      "loss": 0.4737,
      "step": 846500
    },
    {
      "epoch": 8.96142832189116,
      "eval_loss": 0.2922013998031616,
      "eval_runtime": 46.9471,
      "eval_samples_per_second": 3577.002,
      "eval_steps_per_second": 447.141,
      "step": 846500
    },
    {
      "epoch": 8.961957643671164,
      "grad_norm": 1.2599050998687744,
      "learning_rate": 1.635551053246531e-05,
      "loss": 0.4733,
      "step": 846550
    },
    {
      "epoch": 8.962486965451168,
      "grad_norm": 1.2564146518707275,
      "learning_rate": 1.633908122774505e-05,
      "loss": 0.4667,
      "step": 846600
    },
    {
      "epoch": 8.96301628723117,
      "grad_norm": 1.272405743598938,
      "learning_rate": 1.6322659900122828e-05,
      "loss": 0.4759,
      "step": 846650
    },
    {
      "epoch": 8.963545609011174,
      "grad_norm": 1.4268200397491455,
      "learning_rate": 1.630624655015936e-05,
      "loss": 0.4722,
      "step": 846700
    },
    {
      "epoch": 8.964074930791178,
      "grad_norm": 1.4421305656433105,
      "learning_rate": 1.6289841178414866e-05,
      "loss": 0.4754,
      "step": 846750
    },
    {
      "epoch": 8.964604252571181,
      "grad_norm": 1.408942699432373,
      "learning_rate": 1.627344378544951e-05,
      "loss": 0.4779,
      "step": 846800
    },
    {
      "epoch": 8.965133574351183,
      "grad_norm": 1.345707893371582,
      "learning_rate": 1.6257054371823067e-05,
      "loss": 0.468,
      "step": 846850
    },
    {
      "epoch": 8.965662896131187,
      "grad_norm": 1.3229538202285767,
      "learning_rate": 1.6240672938095086e-05,
      "loss": 0.4703,
      "step": 846900
    },
    {
      "epoch": 8.96619221791119,
      "grad_norm": 1.278153419494629,
      "learning_rate": 1.6224299484824732e-05,
      "loss": 0.4672,
      "step": 846950
    },
    {
      "epoch": 8.966721539691193,
      "grad_norm": 1.4180657863616943,
      "learning_rate": 1.6207934012571145e-05,
      "loss": 0.4742,
      "step": 847000
    },
    {
      "epoch": 8.966721539691193,
      "eval_loss": 0.29213741421699524,
      "eval_runtime": 46.8445,
      "eval_samples_per_second": 3584.842,
      "eval_steps_per_second": 448.121,
      "step": 847000
    },
    {
      "epoch": 8.967250861471197,
      "grad_norm": 1.2974504232406616,
      "learning_rate": 1.6191576521892876e-05,
      "loss": 0.4661,
      "step": 847050
    },
    {
      "epoch": 8.9677801832512,
      "grad_norm": 1.4261136054992676,
      "learning_rate": 1.6175227013348505e-05,
      "loss": 0.4756,
      "step": 847100
    },
    {
      "epoch": 8.968309505031204,
      "grad_norm": 1.3276681900024414,
      "learning_rate": 1.6158885487496082e-05,
      "loss": 0.479,
      "step": 847150
    },
    {
      "epoch": 8.968838826811206,
      "grad_norm": 1.3045669794082642,
      "learning_rate": 1.6142551944893584e-05,
      "loss": 0.4792,
      "step": 847200
    },
    {
      "epoch": 8.96936814859121,
      "grad_norm": 1.3110677003860474,
      "learning_rate": 1.6126226386098562e-05,
      "loss": 0.4836,
      "step": 847250
    },
    {
      "epoch": 8.969897470371214,
      "grad_norm": 1.2166149616241455,
      "learning_rate": 1.6109908811668432e-05,
      "loss": 0.4821,
      "step": 847300
    },
    {
      "epoch": 8.970426792151217,
      "grad_norm": 1.274458885192871,
      "learning_rate": 1.6093599222160193e-05,
      "loss": 0.4745,
      "step": 847350
    },
    {
      "epoch": 8.97095611393122,
      "grad_norm": 1.3662992715835571,
      "learning_rate": 1.6077297618130758e-05,
      "loss": 0.4703,
      "step": 847400
    },
    {
      "epoch": 8.971485435711223,
      "grad_norm": 1.474769115447998,
      "learning_rate": 1.6061004000136547e-05,
      "loss": 0.4708,
      "step": 847450
    },
    {
      "epoch": 8.972014757491227,
      "grad_norm": 1.2661762237548828,
      "learning_rate": 1.604471836873389e-05,
      "loss": 0.4764,
      "step": 847500
    },
    {
      "epoch": 8.972014757491227,
      "eval_loss": 0.2919454574584961,
      "eval_runtime": 46.7677,
      "eval_samples_per_second": 3590.723,
      "eval_steps_per_second": 448.856,
      "step": 847500
    },
    {
      "epoch": 8.97254407927123,
      "grad_norm": 1.388252854347229,
      "learning_rate": 1.602844072447873e-05,
      "loss": 0.4727,
      "step": 847550
    },
    {
      "epoch": 8.973073401051233,
      "grad_norm": 1.3402090072631836,
      "learning_rate": 1.6012171067926824e-05,
      "loss": 0.481,
      "step": 847600
    },
    {
      "epoch": 8.973602722831236,
      "grad_norm": 1.49522864818573,
      "learning_rate": 1.5995909399633524e-05,
      "loss": 0.4837,
      "step": 847650
    },
    {
      "epoch": 8.97413204461124,
      "grad_norm": 1.4775737524032593,
      "learning_rate": 1.597965572015414e-05,
      "loss": 0.483,
      "step": 847700
    },
    {
      "epoch": 8.974661366391242,
      "grad_norm": 1.4332984685897827,
      "learning_rate": 1.5963410030043423e-05,
      "loss": 0.4751,
      "step": 847750
    },
    {
      "epoch": 8.975190688171246,
      "grad_norm": 1.3432507514953613,
      "learning_rate": 1.5947172329856096e-05,
      "loss": 0.4695,
      "step": 847800
    },
    {
      "epoch": 8.97572000995125,
      "grad_norm": 1.3718892335891724,
      "learning_rate": 1.593094262014641e-05,
      "loss": 0.4782,
      "step": 847850
    },
    {
      "epoch": 8.976249331731253,
      "grad_norm": 1.3774745464324951,
      "learning_rate": 1.5914720901468587e-05,
      "loss": 0.4762,
      "step": 847900
    },
    {
      "epoch": 8.976778653511255,
      "grad_norm": 1.2391120195388794,
      "learning_rate": 1.589850717437627e-05,
      "loss": 0.4719,
      "step": 847950
    },
    {
      "epoch": 8.977307975291259,
      "grad_norm": 1.4559447765350342,
      "learning_rate": 1.5882301439423124e-05,
      "loss": 0.4772,
      "step": 848000
    },
    {
      "epoch": 8.977307975291259,
      "eval_loss": 0.291986882686615,
      "eval_runtime": 46.9386,
      "eval_samples_per_second": 3577.653,
      "eval_steps_per_second": 447.223,
      "step": 848000
    },
    {
      "epoch": 8.977837297071263,
      "grad_norm": 1.3982939720153809,
      "learning_rate": 1.5866103697162294e-05,
      "loss": 0.4799,
      "step": 848050
    },
    {
      "epoch": 8.978366618851267,
      "grad_norm": 1.455045223236084,
      "learning_rate": 1.5849913948146805e-05,
      "loss": 0.4736,
      "step": 848100
    },
    {
      "epoch": 8.978895940631269,
      "grad_norm": 1.5727311372756958,
      "learning_rate": 1.583373219292944e-05,
      "loss": 0.4689,
      "step": 848150
    },
    {
      "epoch": 8.979425262411272,
      "grad_norm": 1.4865522384643555,
      "learning_rate": 1.5817558432062536e-05,
      "loss": 0.4723,
      "step": 848200
    },
    {
      "epoch": 8.979954584191276,
      "grad_norm": 1.3174083232879639,
      "learning_rate": 1.5801392666098313e-05,
      "loss": 0.4755,
      "step": 848250
    },
    {
      "epoch": 8.98048390597128,
      "grad_norm": 1.413521409034729,
      "learning_rate": 1.578523489558867e-05,
      "loss": 0.468,
      "step": 848300
    },
    {
      "epoch": 8.981013227751282,
      "grad_norm": 1.4518133401870728,
      "learning_rate": 1.5769085121085186e-05,
      "loss": 0.4776,
      "step": 848350
    },
    {
      "epoch": 8.981542549531286,
      "grad_norm": 1.505822777748108,
      "learning_rate": 1.5752943343139285e-05,
      "loss": 0.4687,
      "step": 848400
    },
    {
      "epoch": 8.98207187131129,
      "grad_norm": 1.3939671516418457,
      "learning_rate": 1.5736809562301947e-05,
      "loss": 0.4717,
      "step": 848450
    },
    {
      "epoch": 8.982601193091291,
      "grad_norm": 1.3421238660812378,
      "learning_rate": 1.572068377912403e-05,
      "loss": 0.4811,
      "step": 848500
    },
    {
      "epoch": 8.982601193091291,
      "eval_loss": 0.29199329018592834,
      "eval_runtime": 46.8072,
      "eval_samples_per_second": 3587.699,
      "eval_steps_per_second": 448.478,
      "step": 848500
    },
    {
      "epoch": 8.983130514871295,
      "grad_norm": 1.4551804065704346,
      "learning_rate": 1.5704888271469404e-05,
      "loss": 0.474,
      "step": 848550
    },
    {
      "epoch": 8.983659836651299,
      "grad_norm": 1.4842727184295654,
      "learning_rate": 1.568877832528104e-05,
      "loss": 0.4764,
      "step": 848600
    },
    {
      "epoch": 8.984189158431303,
      "grad_norm": 1.3034591674804688,
      "learning_rate": 1.5672676378391814e-05,
      "loss": 0.4809,
      "step": 848650
    },
    {
      "epoch": 8.984718480211304,
      "grad_norm": 1.2513651847839355,
      "learning_rate": 1.5656582431351456e-05,
      "loss": 0.4697,
      "step": 848700
    },
    {
      "epoch": 8.985247801991308,
      "grad_norm": 1.218157172203064,
      "learning_rate": 1.5640496484709498e-05,
      "loss": 0.4683,
      "step": 848750
    },
    {
      "epoch": 8.985777123771312,
      "grad_norm": 1.2509496212005615,
      "learning_rate": 1.5624418539015e-05,
      "loss": 0.4725,
      "step": 848800
    },
    {
      "epoch": 8.986306445551316,
      "grad_norm": 1.4691598415374756,
      "learning_rate": 1.5608348594816912e-05,
      "loss": 0.4783,
      "step": 848850
    },
    {
      "epoch": 8.986835767331318,
      "grad_norm": 1.3190668821334839,
      "learning_rate": 1.559228665266385e-05,
      "loss": 0.4758,
      "step": 848900
    },
    {
      "epoch": 8.987365089111321,
      "grad_norm": 1.5130233764648438,
      "learning_rate": 1.5576232713104125e-05,
      "loss": 0.4657,
      "step": 848950
    },
    {
      "epoch": 8.987894410891325,
      "grad_norm": 1.3559587001800537,
      "learning_rate": 1.5560186776685887e-05,
      "loss": 0.4797,
      "step": 849000
    },
    {
      "epoch": 8.987894410891325,
      "eval_loss": 0.2917863428592682,
      "eval_runtime": 46.9424,
      "eval_samples_per_second": 3577.366,
      "eval_steps_per_second": 447.187,
      "step": 849000
    },
    {
      "epoch": 8.988423732671329,
      "grad_norm": 1.453965187072754,
      "learning_rate": 1.5544148843956856e-05,
      "loss": 0.4808,
      "step": 849050
    },
    {
      "epoch": 8.988953054451331,
      "grad_norm": 1.4927278757095337,
      "learning_rate": 1.5528118915464655e-05,
      "loss": 0.4839,
      "step": 849100
    },
    {
      "epoch": 8.989482376231335,
      "grad_norm": 1.3626426458358765,
      "learning_rate": 1.551209699175643e-05,
      "loss": 0.4878,
      "step": 849150
    },
    {
      "epoch": 8.990011698011338,
      "grad_norm": 1.3902853727340698,
      "learning_rate": 1.5496083073379243e-05,
      "loss": 0.4814,
      "step": 849200
    },
    {
      "epoch": 8.99054101979134,
      "grad_norm": 1.4385706186294556,
      "learning_rate": 1.5480077160879764e-05,
      "loss": 0.4757,
      "step": 849250
    },
    {
      "epoch": 8.991070341571344,
      "grad_norm": 1.3672773838043213,
      "learning_rate": 1.5464079254804447e-05,
      "loss": 0.4795,
      "step": 849300
    },
    {
      "epoch": 8.991599663351348,
      "grad_norm": 1.412275791168213,
      "learning_rate": 1.544808935569944e-05,
      "loss": 0.4771,
      "step": 849350
    },
    {
      "epoch": 8.992128985131352,
      "grad_norm": 1.3528035879135132,
      "learning_rate": 1.5432107464110667e-05,
      "loss": 0.4731,
      "step": 849400
    },
    {
      "epoch": 8.992658306911354,
      "grad_norm": 1.5128532648086548,
      "learning_rate": 1.541613358058369e-05,
      "loss": 0.4736,
      "step": 849450
    },
    {
      "epoch": 8.993187628691357,
      "grad_norm": 1.4811972379684448,
      "learning_rate": 1.5400167705663936e-05,
      "loss": 0.4634,
      "step": 849500
    },
    {
      "epoch": 8.993187628691357,
      "eval_loss": 0.2916809022426605,
      "eval_runtime": 46.8463,
      "eval_samples_per_second": 3584.704,
      "eval_steps_per_second": 448.104,
      "step": 849500
    },
    {
      "epoch": 8.993716950471361,
      "grad_norm": 1.3021601438522339,
      "learning_rate": 1.5384209839896358e-05,
      "loss": 0.4712,
      "step": 849550
    },
    {
      "epoch": 8.994246272251365,
      "grad_norm": 1.4696162939071655,
      "learning_rate": 1.536825998382585e-05,
      "loss": 0.4813,
      "step": 849600
    },
    {
      "epoch": 8.994775594031367,
      "grad_norm": 1.3828701972961426,
      "learning_rate": 1.5352318137996868e-05,
      "loss": 0.4683,
      "step": 849650
    },
    {
      "epoch": 8.99530491581137,
      "grad_norm": 1.4179067611694336,
      "learning_rate": 1.5336384302953728e-05,
      "loss": 0.48,
      "step": 849700
    },
    {
      "epoch": 8.995834237591374,
      "grad_norm": 1.3083550930023193,
      "learning_rate": 1.5320458479240324e-05,
      "loss": 0.4721,
      "step": 849750
    },
    {
      "epoch": 8.996363559371378,
      "grad_norm": 1.4122430086135864,
      "learning_rate": 1.5304540667400446e-05,
      "loss": 0.4741,
      "step": 849800
    },
    {
      "epoch": 8.99689288115138,
      "grad_norm": 1.429152250289917,
      "learning_rate": 1.5288630867977436e-05,
      "loss": 0.4798,
      "step": 849850
    },
    {
      "epoch": 8.997422202931384,
      "grad_norm": 1.4975579977035522,
      "learning_rate": 1.527272908151453e-05,
      "loss": 0.4741,
      "step": 849900
    },
    {
      "epoch": 8.997951524711388,
      "grad_norm": 1.3764984607696533,
      "learning_rate": 1.525683530855454e-05,
      "loss": 0.4783,
      "step": 849950
    },
    {
      "epoch": 8.99848084649139,
      "grad_norm": 1.4707331657409668,
      "learning_rate": 1.5240949549640143e-05,
      "loss": 0.4771,
      "step": 850000
    },
    {
      "epoch": 8.99848084649139,
      "eval_loss": 0.29177629947662354,
      "eval_runtime": 46.9363,
      "eval_samples_per_second": 3577.824,
      "eval_steps_per_second": 447.244,
      "step": 850000
    },
    {
      "epoch": 8.999010168271393,
      "grad_norm": 1.4448935985565186,
      "learning_rate": 1.5225071805313573e-05,
      "loss": 0.4724,
      "step": 850050
    },
    {
      "epoch": 8.999539490051397,
      "grad_norm": 1.5189154148101807,
      "learning_rate": 1.5209202076117007e-05,
      "loss": 0.4702,
      "step": 850100
    },
    {
      "epoch": 9.0000635186136,
      "grad_norm": 1.1425641775131226,
      "learning_rate": 1.5193340362592123e-05,
      "loss": 0.4745,
      "step": 850150
    },
    {
      "epoch": 9.000592840393603,
      "grad_norm": 1.4618000984191895,
      "learning_rate": 1.5177486665280515e-05,
      "loss": 0.4753,
      "step": 850200
    },
    {
      "epoch": 9.001122162173607,
      "grad_norm": 1.475365161895752,
      "learning_rate": 1.5161640984723391e-05,
      "loss": 0.4693,
      "step": 850250
    },
    {
      "epoch": 9.00165148395361,
      "grad_norm": 1.4441523551940918,
      "learning_rate": 1.5145803321461704e-05,
      "loss": 0.4749,
      "step": 850300
    },
    {
      "epoch": 9.002180805733614,
      "grad_norm": 1.3210902214050293,
      "learning_rate": 1.5129973676036191e-05,
      "loss": 0.4617,
      "step": 850350
    },
    {
      "epoch": 9.002710127513616,
      "grad_norm": 1.451735258102417,
      "learning_rate": 1.5114152048987195e-05,
      "loss": 0.4727,
      "step": 850400
    },
    {
      "epoch": 9.00323944929362,
      "grad_norm": 1.40966796875,
      "learning_rate": 1.5098338440854924e-05,
      "loss": 0.4724,
      "step": 850450
    },
    {
      "epoch": 9.003768771073624,
      "grad_norm": 1.4909406900405884,
      "learning_rate": 1.5082532852179254e-05,
      "loss": 0.473,
      "step": 850500
    },
    {
      "epoch": 9.003768771073624,
      "eval_loss": 0.29142966866493225,
      "eval_runtime": 46.9088,
      "eval_samples_per_second": 3579.923,
      "eval_steps_per_second": 447.506,
      "step": 850500
    },
    {
      "epoch": 9.004298092853627,
      "grad_norm": 1.4191631078720093,
      "learning_rate": 1.5066735283499722e-05,
      "loss": 0.4677,
      "step": 850550
    },
    {
      "epoch": 9.00482741463363,
      "grad_norm": 1.381799340248108,
      "learning_rate": 1.5051261447713904e-05,
      "loss": 0.4691,
      "step": 850600
    },
    {
      "epoch": 9.005356736413633,
      "grad_norm": 1.3993891477584839,
      "learning_rate": 1.5035479760217685e-05,
      "loss": 0.4718,
      "step": 850650
    },
    {
      "epoch": 9.005886058193637,
      "grad_norm": 1.3871458768844604,
      "learning_rate": 1.5019706094323987e-05,
      "loss": 0.4684,
      "step": 850700
    },
    {
      "epoch": 9.00641537997364,
      "grad_norm": 1.4784449338912964,
      "learning_rate": 1.5003940450571351e-05,
      "loss": 0.4727,
      "step": 850750
    },
    {
      "epoch": 9.006944701753643,
      "grad_norm": 1.4271230697631836,
      "learning_rate": 1.4988182829498043e-05,
      "loss": 0.4684,
      "step": 850800
    },
    {
      "epoch": 9.007474023533646,
      "grad_norm": 1.4964277744293213,
      "learning_rate": 1.4972433231641935e-05,
      "loss": 0.4813,
      "step": 850850
    },
    {
      "epoch": 9.00800334531365,
      "grad_norm": 1.2487766742706299,
      "learning_rate": 1.4956691657540766e-05,
      "loss": 0.4777,
      "step": 850900
    },
    {
      "epoch": 9.008532667093652,
      "grad_norm": 1.3972758054733276,
      "learning_rate": 1.4940958107731967e-05,
      "loss": 0.466,
      "step": 850950
    },
    {
      "epoch": 9.009061988873656,
      "grad_norm": 1.2621175050735474,
      "learning_rate": 1.4925232582752635e-05,
      "loss": 0.4756,
      "step": 851000
    },
    {
      "epoch": 9.009061988873656,
      "eval_loss": 0.29169490933418274,
      "eval_runtime": 46.7752,
      "eval_samples_per_second": 3590.153,
      "eval_steps_per_second": 448.785,
      "step": 851000
    },
    {
      "epoch": 9.00959131065366,
      "grad_norm": 1.5637156963348389,
      "learning_rate": 1.4909515083139702e-05,
      "loss": 0.4702,
      "step": 851050
    },
    {
      "epoch": 9.010120632433663,
      "grad_norm": 1.3076677322387695,
      "learning_rate": 1.4893805609429657e-05,
      "loss": 0.467,
      "step": 851100
    },
    {
      "epoch": 9.010649954213665,
      "grad_norm": 1.1688244342803955,
      "learning_rate": 1.4878104162158872e-05,
      "loss": 0.4694,
      "step": 851150
    },
    {
      "epoch": 9.011179275993669,
      "grad_norm": 1.285901665687561,
      "learning_rate": 1.4862410741863398e-05,
      "loss": 0.4713,
      "step": 851200
    },
    {
      "epoch": 9.011708597773673,
      "grad_norm": 1.2660294771194458,
      "learning_rate": 1.4846725349078993e-05,
      "loss": 0.4732,
      "step": 851250
    },
    {
      "epoch": 9.012237919553677,
      "grad_norm": 1.3487411737442017,
      "learning_rate": 1.4831047984341095e-05,
      "loss": 0.4682,
      "step": 851300
    },
    {
      "epoch": 9.012767241333679,
      "grad_norm": 1.2837505340576172,
      "learning_rate": 1.4815378648185051e-05,
      "loss": 0.4711,
      "step": 851350
    },
    {
      "epoch": 9.013296563113682,
      "grad_norm": 1.2856847047805786,
      "learning_rate": 1.4799717341145658e-05,
      "loss": 0.4624,
      "step": 851400
    },
    {
      "epoch": 9.013825884893686,
      "grad_norm": 1.4773563146591187,
      "learning_rate": 1.4784064063757708e-05,
      "loss": 0.4762,
      "step": 851450
    },
    {
      "epoch": 9.01435520667369,
      "grad_norm": 1.4683005809783936,
      "learning_rate": 1.4768418816555496e-05,
      "loss": 0.4731,
      "step": 851500
    },
    {
      "epoch": 9.01435520667369,
      "eval_loss": 0.2916956841945648,
      "eval_runtime": 46.8979,
      "eval_samples_per_second": 3580.761,
      "eval_steps_per_second": 447.611,
      "step": 851500
    },
    {
      "epoch": 9.014884528453692,
      "grad_norm": 1.2907280921936035,
      "learning_rate": 1.4752781600073261e-05,
      "loss": 0.4666,
      "step": 851550
    },
    {
      "epoch": 9.015413850233696,
      "grad_norm": 1.3339385986328125,
      "learning_rate": 1.4737152414844719e-05,
      "loss": 0.469,
      "step": 851600
    },
    {
      "epoch": 9.0159431720137,
      "grad_norm": 1.286202311515808,
      "learning_rate": 1.4721531261403576e-05,
      "loss": 0.4637,
      "step": 851650
    },
    {
      "epoch": 9.016472493793701,
      "grad_norm": 1.5357023477554321,
      "learning_rate": 1.470591814028302e-05,
      "loss": 0.4794,
      "step": 851700
    },
    {
      "epoch": 9.017001815573705,
      "grad_norm": 1.3802694082260132,
      "learning_rate": 1.469031305201618e-05,
      "loss": 0.4644,
      "step": 851750
    },
    {
      "epoch": 9.017531137353709,
      "grad_norm": 1.3701285123825073,
      "learning_rate": 1.4674715997135713e-05,
      "loss": 0.4745,
      "step": 851800
    },
    {
      "epoch": 9.018060459133713,
      "grad_norm": 1.384330153465271,
      "learning_rate": 1.4659126976174165e-05,
      "loss": 0.475,
      "step": 851850
    },
    {
      "epoch": 9.018589780913715,
      "grad_norm": 1.338154911994934,
      "learning_rate": 1.4643545989663664e-05,
      "loss": 0.4757,
      "step": 851900
    },
    {
      "epoch": 9.019119102693718,
      "grad_norm": 1.529547095298767,
      "learning_rate": 1.4627973038136262e-05,
      "loss": 0.4815,
      "step": 851950
    },
    {
      "epoch": 9.019648424473722,
      "grad_norm": 1.3774335384368896,
      "learning_rate": 1.4612408122123472e-05,
      "loss": 0.467,
      "step": 852000
    },
    {
      "epoch": 9.019648424473722,
      "eval_loss": 0.2913745641708374,
      "eval_runtime": 46.8854,
      "eval_samples_per_second": 3581.71,
      "eval_steps_per_second": 447.73,
      "step": 852000
    },
    {
      "epoch": 9.020177746253726,
      "grad_norm": 1.3338714838027954,
      "learning_rate": 1.4596851242156789e-05,
      "loss": 0.4647,
      "step": 852050
    },
    {
      "epoch": 9.020707068033728,
      "grad_norm": 1.4438735246658325,
      "learning_rate": 1.4581302398767232e-05,
      "loss": 0.4701,
      "step": 852100
    },
    {
      "epoch": 9.021236389813732,
      "grad_norm": 1.604570746421814,
      "learning_rate": 1.456576159248571e-05,
      "loss": 0.4712,
      "step": 852150
    },
    {
      "epoch": 9.021765711593735,
      "grad_norm": 1.441827654838562,
      "learning_rate": 1.4550228823842715e-05,
      "loss": 0.4652,
      "step": 852200
    },
    {
      "epoch": 9.022295033373739,
      "grad_norm": 1.3521901369094849,
      "learning_rate": 1.45347040933686e-05,
      "loss": 0.4801,
      "step": 852250
    },
    {
      "epoch": 9.022824355153741,
      "grad_norm": 1.2668585777282715,
      "learning_rate": 1.4519187401593304e-05,
      "loss": 0.4656,
      "step": 852300
    },
    {
      "epoch": 9.023353676933745,
      "grad_norm": 1.4169642925262451,
      "learning_rate": 1.4503678749046568e-05,
      "loss": 0.4691,
      "step": 852350
    },
    {
      "epoch": 9.023882998713749,
      "grad_norm": 1.5157698392868042,
      "learning_rate": 1.4488178136257912e-05,
      "loss": 0.4696,
      "step": 852400
    },
    {
      "epoch": 9.02441232049375,
      "grad_norm": 1.311314582824707,
      "learning_rate": 1.4472685563756471e-05,
      "loss": 0.4656,
      "step": 852450
    },
    {
      "epoch": 9.024941642273754,
      "grad_norm": 1.3303416967391968,
      "learning_rate": 1.4457201032071182e-05,
      "loss": 0.474,
      "step": 852500
    },
    {
      "epoch": 9.024941642273754,
      "eval_loss": 0.291272908449173,
      "eval_runtime": 46.8872,
      "eval_samples_per_second": 3581.572,
      "eval_steps_per_second": 447.712,
      "step": 852500
    },
    {
      "epoch": 9.025470964053758,
      "grad_norm": 1.431552529335022,
      "learning_rate": 1.4441724541730623e-05,
      "loss": 0.4676,
      "step": 852550
    },
    {
      "epoch": 9.026000285833762,
      "grad_norm": 1.3982126712799072,
      "learning_rate": 1.442625609326323e-05,
      "loss": 0.4777,
      "step": 852600
    },
    {
      "epoch": 9.026529607613764,
      "grad_norm": 1.2346203327178955,
      "learning_rate": 1.4410795687197053e-05,
      "loss": 0.4698,
      "step": 852650
    },
    {
      "epoch": 9.027058929393768,
      "grad_norm": 1.2648509740829468,
      "learning_rate": 1.4395343324059923e-05,
      "loss": 0.4646,
      "step": 852700
    },
    {
      "epoch": 9.027588251173771,
      "grad_norm": 1.4390685558319092,
      "learning_rate": 1.4380207811943714e-05,
      "loss": 0.4594,
      "step": 852750
    },
    {
      "epoch": 9.028117572953775,
      "grad_norm": 1.401181936264038,
      "learning_rate": 1.436477137536213e-05,
      "loss": 0.4754,
      "step": 852800
    },
    {
      "epoch": 9.028646894733777,
      "grad_norm": 1.414974570274353,
      "learning_rate": 1.4349342983280861e-05,
      "loss": 0.4785,
      "step": 852850
    },
    {
      "epoch": 9.02917621651378,
      "grad_norm": 1.5017095804214478,
      "learning_rate": 1.433392263622657e-05,
      "loss": 0.4742,
      "step": 852900
    },
    {
      "epoch": 9.029705538293785,
      "grad_norm": 1.2536189556121826,
      "learning_rate": 1.4318510334725726e-05,
      "loss": 0.4745,
      "step": 852950
    },
    {
      "epoch": 9.030234860073788,
      "grad_norm": 1.4515818357467651,
      "learning_rate": 1.4303106079304573e-05,
      "loss": 0.4681,
      "step": 853000
    },
    {
      "epoch": 9.030234860073788,
      "eval_loss": 0.2911764979362488,
      "eval_runtime": 46.8753,
      "eval_samples_per_second": 3582.485,
      "eval_steps_per_second": 447.827,
      "step": 853000
    },
    {
      "epoch": 9.03076418185379,
      "grad_norm": 1.3621644973754883,
      "learning_rate": 1.4287709870488858e-05,
      "loss": 0.4729,
      "step": 853050
    },
    {
      "epoch": 9.031293503633794,
      "grad_norm": 1.4870439767837524,
      "learning_rate": 1.4272321708804326e-05,
      "loss": 0.4684,
      "step": 853100
    },
    {
      "epoch": 9.031822825413798,
      "grad_norm": 1.3118959665298462,
      "learning_rate": 1.425694159477628e-05,
      "loss": 0.4693,
      "step": 853150
    },
    {
      "epoch": 9.0323521471938,
      "grad_norm": 1.312522292137146,
      "learning_rate": 1.4241569528929771e-05,
      "loss": 0.4707,
      "step": 853200
    },
    {
      "epoch": 9.032881468973804,
      "grad_norm": 1.2685598134994507,
      "learning_rate": 1.4226205511789658e-05,
      "loss": 0.4742,
      "step": 853250
    },
    {
      "epoch": 9.033410790753807,
      "grad_norm": 1.545653223991394,
      "learning_rate": 1.4210849543880383e-05,
      "loss": 0.4769,
      "step": 853300
    },
    {
      "epoch": 9.033940112533811,
      "grad_norm": 1.2619781494140625,
      "learning_rate": 1.4195501625726248e-05,
      "loss": 0.472,
      "step": 853350
    },
    {
      "epoch": 9.034469434313813,
      "grad_norm": 1.347041368484497,
      "learning_rate": 1.4180161757851195e-05,
      "loss": 0.4725,
      "step": 853400
    },
    {
      "epoch": 9.034998756093817,
      "grad_norm": 1.1910213232040405,
      "learning_rate": 1.4164829940778972e-05,
      "loss": 0.4739,
      "step": 853450
    },
    {
      "epoch": 9.03552807787382,
      "grad_norm": 1.214673638343811,
      "learning_rate": 1.4149506175032911e-05,
      "loss": 0.4777,
      "step": 853500
    },
    {
      "epoch": 9.03552807787382,
      "eval_loss": 0.2914496064186096,
      "eval_runtime": 46.9024,
      "eval_samples_per_second": 3580.414,
      "eval_steps_per_second": 447.568,
      "step": 853500
    },
    {
      "epoch": 9.036057399653824,
      "grad_norm": 1.3080700635910034,
      "learning_rate": 1.413419046113626e-05,
      "loss": 0.4738,
      "step": 853550
    },
    {
      "epoch": 9.036586721433826,
      "grad_norm": 1.4459075927734375,
      "learning_rate": 1.411888279961182e-05,
      "loss": 0.4693,
      "step": 853600
    },
    {
      "epoch": 9.03711604321383,
      "grad_norm": 1.3952172994613647,
      "learning_rate": 1.4103583190982233e-05,
      "loss": 0.4734,
      "step": 853650
    },
    {
      "epoch": 9.037645364993834,
      "grad_norm": 1.5797619819641113,
      "learning_rate": 1.4088291635769773e-05,
      "loss": 0.4742,
      "step": 853700
    },
    {
      "epoch": 9.038174686773838,
      "grad_norm": 1.4896291494369507,
      "learning_rate": 1.4073008134496551e-05,
      "loss": 0.4712,
      "step": 853750
    },
    {
      "epoch": 9.03870400855384,
      "grad_norm": 1.3368974924087524,
      "learning_rate": 1.4057732687684288e-05,
      "loss": 0.4817,
      "step": 853800
    },
    {
      "epoch": 9.039233330333843,
      "grad_norm": 1.3854196071624756,
      "learning_rate": 1.4042465295854511e-05,
      "loss": 0.4726,
      "step": 853850
    },
    {
      "epoch": 9.039762652113847,
      "grad_norm": 1.524987816810608,
      "learning_rate": 1.4027205959528417e-05,
      "loss": 0.4733,
      "step": 853900
    },
    {
      "epoch": 9.040291973893849,
      "grad_norm": 1.419559359550476,
      "learning_rate": 1.4011954679227001e-05,
      "loss": 0.471,
      "step": 853950
    },
    {
      "epoch": 9.040821295673853,
      "grad_norm": 1.5148779153823853,
      "learning_rate": 1.3996711455470879e-05,
      "loss": 0.4733,
      "step": 854000
    },
    {
      "epoch": 9.040821295673853,
      "eval_loss": 0.2913859784603119,
      "eval_runtime": 46.9474,
      "eval_samples_per_second": 3576.981,
      "eval_steps_per_second": 447.139,
      "step": 854000
    },
    {
      "epoch": 9.041350617453856,
      "grad_norm": 1.2497262954711914,
      "learning_rate": 1.3981476288780492e-05,
      "loss": 0.4702,
      "step": 854050
    },
    {
      "epoch": 9.04187993923386,
      "grad_norm": 1.2935746908187866,
      "learning_rate": 1.3966249179675928e-05,
      "loss": 0.4607,
      "step": 854100
    },
    {
      "epoch": 9.042409261013862,
      "grad_norm": 1.5717508792877197,
      "learning_rate": 1.39510301286771e-05,
      "loss": 0.4735,
      "step": 854150
    },
    {
      "epoch": 9.042938582793866,
      "grad_norm": 1.3519341945648193,
      "learning_rate": 1.3935819136303485e-05,
      "loss": 0.474,
      "step": 854200
    },
    {
      "epoch": 9.04346790457387,
      "grad_norm": 1.4486918449401855,
      "learning_rate": 1.3920616203074471e-05,
      "loss": 0.4768,
      "step": 854250
    },
    {
      "epoch": 9.043997226353873,
      "grad_norm": 1.4750829935073853,
      "learning_rate": 1.3905421329508978e-05,
      "loss": 0.4815,
      "step": 854300
    },
    {
      "epoch": 9.044526548133875,
      "grad_norm": 1.421308159828186,
      "learning_rate": 1.3890234516125894e-05,
      "loss": 0.4695,
      "step": 854350
    },
    {
      "epoch": 9.04505586991388,
      "grad_norm": 1.3723033666610718,
      "learning_rate": 1.3875055763443556e-05,
      "loss": 0.4714,
      "step": 854400
    },
    {
      "epoch": 9.045585191693883,
      "grad_norm": 1.3058935403823853,
      "learning_rate": 1.3859885071980243e-05,
      "loss": 0.4646,
      "step": 854450
    },
    {
      "epoch": 9.046114513473887,
      "grad_norm": 1.4596500396728516,
      "learning_rate": 1.3844722442253822e-05,
      "loss": 0.4595,
      "step": 854500
    },
    {
      "epoch": 9.046114513473887,
      "eval_loss": 0.29113996028900146,
      "eval_runtime": 46.852,
      "eval_samples_per_second": 3584.262,
      "eval_steps_per_second": 448.049,
      "step": 854500
    },
    {
      "epoch": 9.046643835253889,
      "grad_norm": 1.3046663999557495,
      "learning_rate": 1.3829567874782011e-05,
      "loss": 0.4808,
      "step": 854550
    },
    {
      "epoch": 9.047173157033892,
      "grad_norm": 1.4453412294387817,
      "learning_rate": 1.3814421370082098e-05,
      "loss": 0.4637,
      "step": 854600
    },
    {
      "epoch": 9.047702478813896,
      "grad_norm": 1.411864161491394,
      "learning_rate": 1.379928292867122e-05,
      "loss": 0.4665,
      "step": 854650
    },
    {
      "epoch": 9.048231800593898,
      "grad_norm": 1.3488740921020508,
      "learning_rate": 1.3784152551066242e-05,
      "loss": 0.4709,
      "step": 854700
    },
    {
      "epoch": 9.048761122373902,
      "grad_norm": 1.3487436771392822,
      "learning_rate": 1.3769030237783641e-05,
      "loss": 0.4696,
      "step": 854750
    },
    {
      "epoch": 9.049290444153906,
      "grad_norm": 1.4402313232421875,
      "learning_rate": 1.37539159893397e-05,
      "loss": 0.4718,
      "step": 854800
    },
    {
      "epoch": 9.04981976593391,
      "grad_norm": 1.455440878868103,
      "learning_rate": 1.3738809806250446e-05,
      "loss": 0.475,
      "step": 854850
    },
    {
      "epoch": 9.050349087713911,
      "grad_norm": 1.4301973581314087,
      "learning_rate": 1.3724013572327137e-05,
      "loss": 0.4793,
      "step": 854900
    },
    {
      "epoch": 9.050878409493915,
      "grad_norm": 1.3971916437149048,
      "learning_rate": 1.3708923360161302e-05,
      "loss": 0.4654,
      "step": 854950
    },
    {
      "epoch": 9.051407731273919,
      "grad_norm": 1.4211066961288452,
      "learning_rate": 1.3693841214886177e-05,
      "loss": 0.4704,
      "step": 855000
    },
    {
      "epoch": 9.051407731273919,
      "eval_loss": 0.29114222526550293,
      "eval_runtime": 46.8321,
      "eval_samples_per_second": 3585.787,
      "eval_steps_per_second": 448.239,
      "step": 855000
    },
    {
      "epoch": 9.051937053053923,
      "grad_norm": 1.3550081253051758,
      "learning_rate": 1.3678767137016712e-05,
      "loss": 0.472,
      "step": 855050
    },
    {
      "epoch": 9.052466374833925,
      "grad_norm": 1.3573135137557983,
      "learning_rate": 1.3663701127067385e-05,
      "loss": 0.478,
      "step": 855100
    },
    {
      "epoch": 9.052995696613928,
      "grad_norm": 1.3032257556915283,
      "learning_rate": 1.36486431855527e-05,
      "loss": 0.4712,
      "step": 855150
    },
    {
      "epoch": 9.053525018393932,
      "grad_norm": 1.3768726587295532,
      "learning_rate": 1.363359331298661e-05,
      "loss": 0.4734,
      "step": 855200
    },
    {
      "epoch": 9.054054340173936,
      "grad_norm": 1.3041844367980957,
      "learning_rate": 1.3618551509882948e-05,
      "loss": 0.4744,
      "step": 855250
    },
    {
      "epoch": 9.054583661953938,
      "grad_norm": 1.217635989189148,
      "learning_rate": 1.3603517776755309e-05,
      "loss": 0.4692,
      "step": 855300
    },
    {
      "epoch": 9.055112983733942,
      "grad_norm": 1.4793853759765625,
      "learning_rate": 1.3588492114116807e-05,
      "loss": 0.4652,
      "step": 855350
    },
    {
      "epoch": 9.055642305513945,
      "grad_norm": 1.3482199907302856,
      "learning_rate": 1.3573474522480561e-05,
      "loss": 0.4697,
      "step": 855400
    },
    {
      "epoch": 9.056171627293947,
      "grad_norm": 1.380685806274414,
      "learning_rate": 1.3558465002359105e-05,
      "loss": 0.4756,
      "step": 855450
    },
    {
      "epoch": 9.056700949073951,
      "grad_norm": 1.3525699377059937,
      "learning_rate": 1.3543463554265002e-05,
      "loss": 0.4674,
      "step": 855500
    },
    {
      "epoch": 9.056700949073951,
      "eval_loss": 0.2910603880882263,
      "eval_runtime": 46.8052,
      "eval_samples_per_second": 3587.848,
      "eval_steps_per_second": 448.497,
      "step": 855500
    },
    {
      "epoch": 9.057230270853955,
      "grad_norm": 1.370809555053711,
      "learning_rate": 1.3528470178710312e-05,
      "loss": 0.4662,
      "step": 855550
    },
    {
      "epoch": 9.057759592633959,
      "grad_norm": 1.416418194770813,
      "learning_rate": 1.3513484876206934e-05,
      "loss": 0.4721,
      "step": 855600
    },
    {
      "epoch": 9.05828891441396,
      "grad_norm": 1.2417503595352173,
      "learning_rate": 1.3498507647266427e-05,
      "loss": 0.4706,
      "step": 855650
    },
    {
      "epoch": 9.058818236193964,
      "grad_norm": 1.5094563961029053,
      "learning_rate": 1.3483538492400194e-05,
      "loss": 0.4722,
      "step": 855700
    },
    {
      "epoch": 9.059347557973968,
      "grad_norm": 1.3690108060836792,
      "learning_rate": 1.3468577412119155e-05,
      "loss": 0.4647,
      "step": 855750
    },
    {
      "epoch": 9.059876879753972,
      "grad_norm": 1.2566332817077637,
      "learning_rate": 1.3453624406934179e-05,
      "loss": 0.4673,
      "step": 855800
    },
    {
      "epoch": 9.060406201533974,
      "grad_norm": 1.4131397008895874,
      "learning_rate": 1.3438679477355692e-05,
      "loss": 0.4687,
      "step": 855850
    },
    {
      "epoch": 9.060935523313978,
      "grad_norm": 1.2643272876739502,
      "learning_rate": 1.3423742623893954e-05,
      "loss": 0.4651,
      "step": 855900
    },
    {
      "epoch": 9.061464845093981,
      "grad_norm": 1.4946900606155396,
      "learning_rate": 1.3408813847058831e-05,
      "loss": 0.4664,
      "step": 855950
    },
    {
      "epoch": 9.061994166873985,
      "grad_norm": 1.4751005172729492,
      "learning_rate": 1.3393893147360087e-05,
      "loss": 0.476,
      "step": 856000
    },
    {
      "epoch": 9.061994166873985,
      "eval_loss": 0.29098764061927795,
      "eval_runtime": 46.9588,
      "eval_samples_per_second": 3576.116,
      "eval_steps_per_second": 447.031,
      "step": 856000
    },
    {
      "epoch": 9.062523488653987,
      "grad_norm": 1.4817020893096924,
      "learning_rate": 1.3378980525307032e-05,
      "loss": 0.4674,
      "step": 856050
    },
    {
      "epoch": 9.063052810433991,
      "grad_norm": 1.3601939678192139,
      "learning_rate": 1.3364075981408818e-05,
      "loss": 0.4674,
      "step": 856100
    },
    {
      "epoch": 9.063582132213995,
      "grad_norm": 1.4250192642211914,
      "learning_rate": 1.334917951617426e-05,
      "loss": 0.4774,
      "step": 856150
    },
    {
      "epoch": 9.064111453993997,
      "grad_norm": 1.3287831544876099,
      "learning_rate": 1.3334291130111947e-05,
      "loss": 0.4675,
      "step": 856200
    },
    {
      "epoch": 9.064640775774,
      "grad_norm": 1.3165348768234253,
      "learning_rate": 1.3319410823730089e-05,
      "loss": 0.4724,
      "step": 856250
    },
    {
      "epoch": 9.065170097554004,
      "grad_norm": 1.24188232421875,
      "learning_rate": 1.3304538597536802e-05,
      "loss": 0.4662,
      "step": 856300
    },
    {
      "epoch": 9.065699419334008,
      "grad_norm": 1.4384665489196777,
      "learning_rate": 1.3289674452039713e-05,
      "loss": 0.4696,
      "step": 856350
    },
    {
      "epoch": 9.06622874111401,
      "grad_norm": 1.338052749633789,
      "learning_rate": 1.3274818387746357e-05,
      "loss": 0.4722,
      "step": 856400
    },
    {
      "epoch": 9.066758062894014,
      "grad_norm": 1.4578289985656738,
      "learning_rate": 1.3259970405163856e-05,
      "loss": 0.4684,
      "step": 856450
    },
    {
      "epoch": 9.067287384674017,
      "grad_norm": 1.4512898921966553,
      "learning_rate": 1.3245130504799197e-05,
      "loss": 0.4737,
      "step": 856500
    },
    {
      "epoch": 9.067287384674017,
      "eval_loss": 0.29117459058761597,
      "eval_runtime": 46.8366,
      "eval_samples_per_second": 3585.441,
      "eval_steps_per_second": 448.196,
      "step": 856500
    },
    {
      "epoch": 9.067816706454021,
      "grad_norm": 1.5277758836746216,
      "learning_rate": 1.3230298687158887e-05,
      "loss": 0.4666,
      "step": 856550
    },
    {
      "epoch": 9.068346028234023,
      "grad_norm": 1.4406219720840454,
      "learning_rate": 1.3215474952749413e-05,
      "loss": 0.4746,
      "step": 856600
    },
    {
      "epoch": 9.068875350014027,
      "grad_norm": 1.3912612199783325,
      "learning_rate": 1.3200659302076728e-05,
      "loss": 0.4793,
      "step": 856650
    },
    {
      "epoch": 9.06940467179403,
      "grad_norm": 1.4282033443450928,
      "learning_rate": 1.3185851735646708e-05,
      "loss": 0.4734,
      "step": 856700
    },
    {
      "epoch": 9.069933993574034,
      "grad_norm": 1.3293102979660034,
      "learning_rate": 1.3171052253964866e-05,
      "loss": 0.4632,
      "step": 856750
    },
    {
      "epoch": 9.070463315354036,
      "grad_norm": 1.4202911853790283,
      "learning_rate": 1.3156260857536434e-05,
      "loss": 0.4745,
      "step": 856800
    },
    {
      "epoch": 9.07099263713404,
      "grad_norm": 1.367445945739746,
      "learning_rate": 1.3141477546866399e-05,
      "loss": 0.4622,
      "step": 856850
    },
    {
      "epoch": 9.071521958914044,
      "grad_norm": 1.3053483963012695,
      "learning_rate": 1.3126702322459493e-05,
      "loss": 0.4665,
      "step": 856900
    },
    {
      "epoch": 9.072051280694046,
      "grad_norm": 1.3605867624282837,
      "learning_rate": 1.311193518482004e-05,
      "loss": 0.474,
      "step": 856950
    },
    {
      "epoch": 9.07258060247405,
      "grad_norm": 1.3898793458938599,
      "learning_rate": 1.30971761344523e-05,
      "loss": 0.4719,
      "step": 857000
    },
    {
      "epoch": 9.07258060247405,
      "eval_loss": 0.29070737957954407,
      "eval_runtime": 46.8974,
      "eval_samples_per_second": 3580.795,
      "eval_steps_per_second": 447.615,
      "step": 857000
    },
    {
      "epoch": 9.073109924254053,
      "grad_norm": 1.1995928287506104,
      "learning_rate": 1.3082425171860063e-05,
      "loss": 0.471,
      "step": 857050
    },
    {
      "epoch": 9.073639246034057,
      "grad_norm": 1.4107568264007568,
      "learning_rate": 1.3067682297546956e-05,
      "loss": 0.4653,
      "step": 857100
    },
    {
      "epoch": 9.07416856781406,
      "grad_norm": 1.424080491065979,
      "learning_rate": 1.3053242128453546e-05,
      "loss": 0.4762,
      "step": 857150
    },
    {
      "epoch": 9.074697889594063,
      "grad_norm": 1.402418613433838,
      "learning_rate": 1.3038515270417716e-05,
      "loss": 0.4727,
      "step": 857200
    },
    {
      "epoch": 9.075227211374067,
      "grad_norm": 1.3513432741165161,
      "learning_rate": 1.302379650216004e-05,
      "loss": 0.4654,
      "step": 857250
    },
    {
      "epoch": 9.07575653315407,
      "grad_norm": 1.3612756729125977,
      "learning_rate": 1.3009085824183032e-05,
      "loss": 0.4703,
      "step": 857300
    },
    {
      "epoch": 9.076285854934072,
      "grad_norm": 1.4272356033325195,
      "learning_rate": 1.2994383236988955e-05,
      "loss": 0.4737,
      "step": 857350
    },
    {
      "epoch": 9.076815176714076,
      "grad_norm": 1.3254388570785522,
      "learning_rate": 1.2979688741079687e-05,
      "loss": 0.472,
      "step": 857400
    },
    {
      "epoch": 9.07734449849408,
      "grad_norm": 1.3143024444580078,
      "learning_rate": 1.2965002336956966e-05,
      "loss": 0.4683,
      "step": 857450
    },
    {
      "epoch": 9.077873820274084,
      "grad_norm": 1.4799977540969849,
      "learning_rate": 1.2950324025122085e-05,
      "loss": 0.469,
      "step": 857500
    },
    {
      "epoch": 9.077873820274084,
      "eval_loss": 0.2910441756248474,
      "eval_runtime": 46.8438,
      "eval_samples_per_second": 3584.895,
      "eval_steps_per_second": 448.128,
      "step": 857500
    },
    {
      "epoch": 9.078403142054086,
      "grad_norm": 1.4064860343933105,
      "learning_rate": 1.2935653806076253e-05,
      "loss": 0.4731,
      "step": 857550
    },
    {
      "epoch": 9.07893246383409,
      "grad_norm": 1.430741548538208,
      "learning_rate": 1.292099168032021e-05,
      "loss": 0.4709,
      "step": 857600
    },
    {
      "epoch": 9.079461785614093,
      "grad_norm": 1.3639469146728516,
      "learning_rate": 1.290633764835461e-05,
      "loss": 0.4746,
      "step": 857650
    },
    {
      "epoch": 9.079991107394095,
      "grad_norm": 1.2838833332061768,
      "learning_rate": 1.2891691710679638e-05,
      "loss": 0.4719,
      "step": 857700
    },
    {
      "epoch": 9.080520429174099,
      "grad_norm": 1.3218623399734497,
      "learning_rate": 1.287705386779539e-05,
      "loss": 0.4722,
      "step": 857750
    },
    {
      "epoch": 9.081049750954103,
      "grad_norm": 1.4516421556472778,
      "learning_rate": 1.2862424120201554e-05,
      "loss": 0.4822,
      "step": 857800
    },
    {
      "epoch": 9.081579072734106,
      "grad_norm": 1.4374140501022339,
      "learning_rate": 1.2847802468397619e-05,
      "loss": 0.4697,
      "step": 857850
    },
    {
      "epoch": 9.082108394514108,
      "grad_norm": 1.3640241622924805,
      "learning_rate": 1.2833188912882681e-05,
      "loss": 0.4729,
      "step": 857900
    },
    {
      "epoch": 9.082637716294112,
      "grad_norm": 1.4031587839126587,
      "learning_rate": 1.2818583454155735e-05,
      "loss": 0.471,
      "step": 857950
    },
    {
      "epoch": 9.083167038074116,
      "grad_norm": 1.3389636278152466,
      "learning_rate": 1.2803986092715325e-05,
      "loss": 0.4704,
      "step": 858000
    },
    {
      "epoch": 9.083167038074116,
      "eval_loss": 0.29088348150253296,
      "eval_runtime": 46.8432,
      "eval_samples_per_second": 3584.938,
      "eval_steps_per_second": 448.133,
      "step": 858000
    },
    {
      "epoch": 9.08369635985412,
      "grad_norm": 1.3946620225906372,
      "learning_rate": 1.2789396829059885e-05,
      "loss": 0.4658,
      "step": 858050
    },
    {
      "epoch": 9.084225681634122,
      "grad_norm": 1.2549939155578613,
      "learning_rate": 1.2774815663687434e-05,
      "loss": 0.4709,
      "step": 858100
    },
    {
      "epoch": 9.084755003414125,
      "grad_norm": 1.5031404495239258,
      "learning_rate": 1.2760242597095768e-05,
      "loss": 0.4706,
      "step": 858150
    },
    {
      "epoch": 9.085284325194129,
      "grad_norm": 1.3312180042266846,
      "learning_rate": 1.2745677629782404e-05,
      "loss": 0.4691,
      "step": 858200
    },
    {
      "epoch": 9.085813646974133,
      "grad_norm": 1.2766269445419312,
      "learning_rate": 1.2731120762244613e-05,
      "loss": 0.4653,
      "step": 858250
    },
    {
      "epoch": 9.086342968754135,
      "grad_norm": 1.3514295816421509,
      "learning_rate": 1.2716571994979332e-05,
      "loss": 0.4696,
      "step": 858300
    },
    {
      "epoch": 9.086872290534139,
      "grad_norm": 1.4201953411102295,
      "learning_rate": 1.2702031328483271e-05,
      "loss": 0.4773,
      "step": 858350
    },
    {
      "epoch": 9.087401612314142,
      "grad_norm": 1.5539122819900513,
      "learning_rate": 1.2687498763252813e-05,
      "loss": 0.4751,
      "step": 858400
    },
    {
      "epoch": 9.087930934094144,
      "grad_norm": 1.4797266721725464,
      "learning_rate": 1.2672974299784173e-05,
      "loss": 0.4753,
      "step": 858450
    },
    {
      "epoch": 9.088460255874148,
      "grad_norm": 1.5645159482955933,
      "learning_rate": 1.2658457938573092e-05,
      "loss": 0.4776,
      "step": 858500
    },
    {
      "epoch": 9.088460255874148,
      "eval_loss": 0.29080134630203247,
      "eval_runtime": 46.8541,
      "eval_samples_per_second": 3584.102,
      "eval_steps_per_second": 448.029,
      "step": 858500
    },
    {
      "epoch": 9.088989577654152,
      "grad_norm": 1.3780845403671265,
      "learning_rate": 1.264394968011523e-05,
      "loss": 0.4641,
      "step": 858550
    },
    {
      "epoch": 9.089518899434156,
      "grad_norm": 1.4005953073501587,
      "learning_rate": 1.2629449524905884e-05,
      "loss": 0.4706,
      "step": 858600
    },
    {
      "epoch": 9.090048221214158,
      "grad_norm": 1.164610505104065,
      "learning_rate": 1.2614957473440075e-05,
      "loss": 0.4664,
      "step": 858650
    },
    {
      "epoch": 9.090577542994161,
      "grad_norm": 1.2657297849655151,
      "learning_rate": 1.2600473526212547e-05,
      "loss": 0.4647,
      "step": 858700
    },
    {
      "epoch": 9.091106864774165,
      "grad_norm": 1.4710862636566162,
      "learning_rate": 1.2585997683717793e-05,
      "loss": 0.4761,
      "step": 858750
    },
    {
      "epoch": 9.091636186554169,
      "grad_norm": 1.3795331716537476,
      "learning_rate": 1.2571529946450028e-05,
      "loss": 0.4684,
      "step": 858800
    },
    {
      "epoch": 9.09216550833417,
      "grad_norm": 1.3865492343902588,
      "learning_rate": 1.2557070314903135e-05,
      "loss": 0.4746,
      "step": 858850
    },
    {
      "epoch": 9.092694830114175,
      "grad_norm": 1.3966526985168457,
      "learning_rate": 1.2542618789570776e-05,
      "loss": 0.472,
      "step": 858900
    },
    {
      "epoch": 9.093224151894178,
      "grad_norm": 1.555708885192871,
      "learning_rate": 1.252817537094636e-05,
      "loss": 0.4739,
      "step": 858950
    },
    {
      "epoch": 9.093753473674182,
      "grad_norm": 1.3167959451675415,
      "learning_rate": 1.251374005952291e-05,
      "loss": 0.4666,
      "step": 859000
    },
    {
      "epoch": 9.093753473674182,
      "eval_loss": 0.2908504009246826,
      "eval_runtime": 46.7856,
      "eval_samples_per_second": 3589.353,
      "eval_steps_per_second": 448.685,
      "step": 859000
    },
    {
      "epoch": 9.094282795454184,
      "grad_norm": 1.4232659339904785,
      "learning_rate": 1.2499312855793338e-05,
      "loss": 0.4738,
      "step": 859050
    },
    {
      "epoch": 9.094812117234188,
      "grad_norm": 1.4167157411575317,
      "learning_rate": 1.2484893760250055e-05,
      "loss": 0.4786,
      "step": 859100
    },
    {
      "epoch": 9.095341439014192,
      "grad_norm": 1.3683797121047974,
      "learning_rate": 1.2470482773385444e-05,
      "loss": 0.4728,
      "step": 859150
    },
    {
      "epoch": 9.095870760794194,
      "grad_norm": 1.4024044275283813,
      "learning_rate": 1.2456079895691392e-05,
      "loss": 0.4765,
      "step": 859200
    },
    {
      "epoch": 9.096400082574197,
      "grad_norm": 1.3777087926864624,
      "learning_rate": 1.244197294354249e-05,
      "loss": 0.4696,
      "step": 859250
    },
    {
      "epoch": 9.096929404354201,
      "grad_norm": 1.4337657690048218,
      "learning_rate": 1.2427586123456625e-05,
      "loss": 0.4702,
      "step": 859300
    },
    {
      "epoch": 9.097458726134205,
      "grad_norm": 1.3805948495864868,
      "learning_rate": 1.241320741400584e-05,
      "loss": 0.4641,
      "step": 859350
    },
    {
      "epoch": 9.097988047914207,
      "grad_norm": 1.588316559791565,
      "learning_rate": 1.2398836815681047e-05,
      "loss": 0.4747,
      "step": 859400
    },
    {
      "epoch": 9.09851736969421,
      "grad_norm": 1.3817617893218994,
      "learning_rate": 1.23844743289728e-05,
      "loss": 0.4671,
      "step": 859450
    },
    {
      "epoch": 9.099046691474214,
      "grad_norm": 1.280938982963562,
      "learning_rate": 1.2370119954371457e-05,
      "loss": 0.4769,
      "step": 859500
    },
    {
      "epoch": 9.099046691474214,
      "eval_loss": 0.2908075451850891,
      "eval_runtime": 46.9693,
      "eval_samples_per_second": 3575.318,
      "eval_steps_per_second": 446.931,
      "step": 859500
    },
    {
      "epoch": 9.099576013254218,
      "grad_norm": 1.416111707687378,
      "learning_rate": 1.2355773692367122e-05,
      "loss": 0.4755,
      "step": 859550
    },
    {
      "epoch": 9.10010533503422,
      "grad_norm": 1.363619089126587,
      "learning_rate": 1.2341435543449464e-05,
      "loss": 0.466,
      "step": 859600
    },
    {
      "epoch": 9.100634656814224,
      "grad_norm": 1.537622332572937,
      "learning_rate": 1.2327105508108061e-05,
      "loss": 0.4616,
      "step": 859650
    },
    {
      "epoch": 9.101163978594228,
      "grad_norm": 1.5316963195800781,
      "learning_rate": 1.2312783586832105e-05,
      "loss": 0.4634,
      "step": 859700
    },
    {
      "epoch": 9.101693300374231,
      "grad_norm": 1.5022451877593994,
      "learning_rate": 1.2298469780110566e-05,
      "loss": 0.4703,
      "step": 859750
    },
    {
      "epoch": 9.102222622154233,
      "grad_norm": 1.4412391185760498,
      "learning_rate": 1.2284164088432081e-05,
      "loss": 0.4794,
      "step": 859800
    },
    {
      "epoch": 9.102751943934237,
      "grad_norm": 1.4252049922943115,
      "learning_rate": 1.2269866512285067e-05,
      "loss": 0.4681,
      "step": 859850
    },
    {
      "epoch": 9.10328126571424,
      "grad_norm": 1.3747525215148926,
      "learning_rate": 1.2255577052157601e-05,
      "loss": 0.4625,
      "step": 859900
    },
    {
      "epoch": 9.103810587494243,
      "grad_norm": 1.3916484117507935,
      "learning_rate": 1.2241295708537575e-05,
      "loss": 0.4734,
      "step": 859950
    },
    {
      "epoch": 9.104339909274247,
      "grad_norm": 1.360024333000183,
      "learning_rate": 1.2227022481912458e-05,
      "loss": 0.4764,
      "step": 860000
    },
    {
      "epoch": 9.104339909274247,
      "eval_loss": 0.2907729744911194,
      "eval_runtime": 46.855,
      "eval_samples_per_second": 3584.038,
      "eval_steps_per_second": 448.021,
      "step": 860000
    },
    {
      "epoch": 9.10486923105425,
      "grad_norm": 1.395210862159729,
      "learning_rate": 1.2212757372769668e-05,
      "loss": 0.4699,
      "step": 860050
    },
    {
      "epoch": 9.105398552834254,
      "grad_norm": 1.2308430671691895,
      "learning_rate": 1.219850038159609e-05,
      "loss": 0.4749,
      "step": 860100
    },
    {
      "epoch": 9.105927874614256,
      "grad_norm": 1.2964956760406494,
      "learning_rate": 1.218425150887853e-05,
      "loss": 0.4732,
      "step": 860150
    },
    {
      "epoch": 9.10645719639426,
      "grad_norm": 1.5741310119628906,
      "learning_rate": 1.217001075510335e-05,
      "loss": 0.4687,
      "step": 860200
    },
    {
      "epoch": 9.106986518174264,
      "grad_norm": 1.5605679750442505,
      "learning_rate": 1.2155778120756855e-05,
      "loss": 0.4764,
      "step": 860250
    },
    {
      "epoch": 9.107515839954267,
      "grad_norm": 1.2812210321426392,
      "learning_rate": 1.2141553606324795e-05,
      "loss": 0.4692,
      "step": 860300
    },
    {
      "epoch": 9.10804516173427,
      "grad_norm": 1.3573565483093262,
      "learning_rate": 1.212733721229292e-05,
      "loss": 0.4683,
      "step": 860350
    },
    {
      "epoch": 9.108574483514273,
      "grad_norm": 1.2910957336425781,
      "learning_rate": 1.2113128939146484e-05,
      "loss": 0.4667,
      "step": 860400
    },
    {
      "epoch": 9.109103805294277,
      "grad_norm": 1.3671337366104126,
      "learning_rate": 1.2098928787370595e-05,
      "loss": 0.4648,
      "step": 860450
    },
    {
      "epoch": 9.10963312707428,
      "grad_norm": 1.3149491548538208,
      "learning_rate": 1.2084736757450033e-05,
      "loss": 0.4691,
      "step": 860500
    },
    {
      "epoch": 9.10963312707428,
      "eval_loss": 0.29065507650375366,
      "eval_runtime": 46.9362,
      "eval_samples_per_second": 3577.832,
      "eval_steps_per_second": 447.245,
      "step": 860500
    },
    {
      "epoch": 9.110162448854283,
      "grad_norm": 1.202582597732544,
      "learning_rate": 1.2070552849869298e-05,
      "loss": 0.4693,
      "step": 860550
    },
    {
      "epoch": 9.110691770634286,
      "grad_norm": 1.4221421480178833,
      "learning_rate": 1.2056377065112618e-05,
      "loss": 0.4693,
      "step": 860600
    },
    {
      "epoch": 9.11122109241429,
      "grad_norm": 1.4350324869155884,
      "learning_rate": 1.2042209403663989e-05,
      "loss": 0.4722,
      "step": 860650
    },
    {
      "epoch": 9.111750414194292,
      "grad_norm": 1.241947054862976,
      "learning_rate": 1.2028049866007029e-05,
      "loss": 0.4635,
      "step": 860700
    },
    {
      "epoch": 9.112279735974296,
      "grad_norm": 1.540910243988037,
      "learning_rate": 1.201389845262521e-05,
      "loss": 0.4644,
      "step": 860750
    },
    {
      "epoch": 9.1128090577543,
      "grad_norm": 1.4313671588897705,
      "learning_rate": 1.1999755164001591e-05,
      "loss": 0.474,
      "step": 860800
    },
    {
      "epoch": 9.113338379534303,
      "grad_norm": 1.410820484161377,
      "learning_rate": 1.198562000061909e-05,
      "loss": 0.4721,
      "step": 860850
    },
    {
      "epoch": 9.113867701314305,
      "grad_norm": 1.3934214115142822,
      "learning_rate": 1.1971492962960184e-05,
      "loss": 0.4726,
      "step": 860900
    },
    {
      "epoch": 9.114397023094309,
      "grad_norm": 1.3080337047576904,
      "learning_rate": 1.1957374051507208e-05,
      "loss": 0.4746,
      "step": 860950
    },
    {
      "epoch": 9.114926344874313,
      "grad_norm": 1.3907557725906372,
      "learning_rate": 1.1943263266742222e-05,
      "loss": 0.4639,
      "step": 861000
    },
    {
      "epoch": 9.114926344874313,
      "eval_loss": 0.29093030095100403,
      "eval_runtime": 46.7826,
      "eval_samples_per_second": 3589.58,
      "eval_steps_per_second": 448.714,
      "step": 861000
    },
    {
      "epoch": 9.115455666654317,
      "grad_norm": 1.4204272031784058,
      "learning_rate": 1.1929160609146895e-05,
      "loss": 0.4678,
      "step": 861050
    },
    {
      "epoch": 9.115984988434318,
      "grad_norm": 1.4886531829833984,
      "learning_rate": 1.191506607920273e-05,
      "loss": 0.4814,
      "step": 861100
    },
    {
      "epoch": 9.116514310214322,
      "grad_norm": 1.3175673484802246,
      "learning_rate": 1.1900979677390872e-05,
      "loss": 0.4645,
      "step": 861150
    },
    {
      "epoch": 9.117043631994326,
      "grad_norm": 1.2875068187713623,
      "learning_rate": 1.1886901404192241e-05,
      "loss": 0.471,
      "step": 861200
    },
    {
      "epoch": 9.11757295377433,
      "grad_norm": 1.2869126796722412,
      "learning_rate": 1.1872831260087535e-05,
      "loss": 0.4741,
      "step": 861250
    },
    {
      "epoch": 9.118102275554332,
      "grad_norm": 1.443838357925415,
      "learning_rate": 1.1858769245556983e-05,
      "loss": 0.4622,
      "step": 861300
    },
    {
      "epoch": 9.118631597334335,
      "grad_norm": 1.5280625820159912,
      "learning_rate": 1.1844715361080726e-05,
      "loss": 0.4703,
      "step": 861350
    },
    {
      "epoch": 9.11916091911434,
      "grad_norm": 1.3885387182235718,
      "learning_rate": 1.183066960713855e-05,
      "loss": 0.4614,
      "step": 861400
    },
    {
      "epoch": 9.119690240894341,
      "grad_norm": 1.4207141399383545,
      "learning_rate": 1.1816631984209985e-05,
      "loss": 0.4731,
      "step": 861450
    },
    {
      "epoch": 9.120219562674345,
      "grad_norm": 1.4447734355926514,
      "learning_rate": 1.1802602492774205e-05,
      "loss": 0.4686,
      "step": 861500
    },
    {
      "epoch": 9.120219562674345,
      "eval_loss": 0.2907186448574066,
      "eval_runtime": 46.8204,
      "eval_samples_per_second": 3586.685,
      "eval_steps_per_second": 448.352,
      "step": 861500
    },
    {
      "epoch": 9.120748884454349,
      "grad_norm": 1.505698561668396,
      "learning_rate": 1.1788581133310273e-05,
      "loss": 0.4739,
      "step": 861550
    },
    {
      "epoch": 9.121278206234352,
      "grad_norm": 1.3635601997375488,
      "learning_rate": 1.1774567906296773e-05,
      "loss": 0.4706,
      "step": 861600
    },
    {
      "epoch": 9.121807528014354,
      "grad_norm": 1.4654994010925293,
      "learning_rate": 1.1760562812212188e-05,
      "loss": 0.4713,
      "step": 861650
    },
    {
      "epoch": 9.122336849794358,
      "grad_norm": 1.4412709474563599,
      "learning_rate": 1.1746565851534607e-05,
      "loss": 0.4658,
      "step": 861700
    },
    {
      "epoch": 9.122866171574362,
      "grad_norm": 1.4541338682174683,
      "learning_rate": 1.1732577024741897e-05,
      "loss": 0.4747,
      "step": 861750
    },
    {
      "epoch": 9.123395493354366,
      "grad_norm": 1.48124361038208,
      "learning_rate": 1.171859633231162e-05,
      "loss": 0.4679,
      "step": 861800
    },
    {
      "epoch": 9.123924815134368,
      "grad_norm": 1.404016375541687,
      "learning_rate": 1.170462377472109e-05,
      "loss": 0.4657,
      "step": 861850
    },
    {
      "epoch": 9.124454136914371,
      "grad_norm": 1.437131404876709,
      "learning_rate": 1.1690659352447286e-05,
      "loss": 0.4672,
      "step": 861900
    },
    {
      "epoch": 9.124983458694375,
      "grad_norm": 1.3993157148361206,
      "learning_rate": 1.1676703065966993e-05,
      "loss": 0.468,
      "step": 861950
    },
    {
      "epoch": 9.125512780474379,
      "grad_norm": 1.4728505611419678,
      "learning_rate": 1.1662754915756635e-05,
      "loss": 0.4759,
      "step": 862000
    },
    {
      "epoch": 9.125512780474379,
      "eval_loss": 0.29062047600746155,
      "eval_runtime": 46.8336,
      "eval_samples_per_second": 3585.673,
      "eval_steps_per_second": 448.225,
      "step": 862000
    },
    {
      "epoch": 9.126042102254381,
      "grad_norm": 1.4183698892593384,
      "learning_rate": 1.1648814902292443e-05,
      "loss": 0.4714,
      "step": 862050
    },
    {
      "epoch": 9.126571424034385,
      "grad_norm": 1.390404462814331,
      "learning_rate": 1.1634883026050286e-05,
      "loss": 0.4691,
      "step": 862100
    },
    {
      "epoch": 9.127100745814388,
      "grad_norm": 1.3259940147399902,
      "learning_rate": 1.162095928750581e-05,
      "loss": 0.4735,
      "step": 862150
    },
    {
      "epoch": 9.12763006759439,
      "grad_norm": 1.6038334369659424,
      "learning_rate": 1.1607043687134333e-05,
      "loss": 0.4626,
      "step": 862200
    },
    {
      "epoch": 9.128159389374394,
      "grad_norm": 1.3649452924728394,
      "learning_rate": 1.1593136225411e-05,
      "loss": 0.4781,
      "step": 862250
    },
    {
      "epoch": 9.128688711154398,
      "grad_norm": 1.4078960418701172,
      "learning_rate": 1.1579236902810542e-05,
      "loss": 0.4693,
      "step": 862300
    },
    {
      "epoch": 9.129218032934402,
      "grad_norm": 1.3061610460281372,
      "learning_rate": 1.1565623463696413e-05,
      "loss": 0.473,
      "step": 862350
    },
    {
      "epoch": 9.129747354714404,
      "grad_norm": 1.2387031316757202,
      "learning_rate": 1.1551740257958965e-05,
      "loss": 0.4684,
      "step": 862400
    },
    {
      "epoch": 9.130276676494407,
      "grad_norm": 1.4116426706314087,
      "learning_rate": 1.1537865192757624e-05,
      "loss": 0.4695,
      "step": 862450
    },
    {
      "epoch": 9.130805998274411,
      "grad_norm": 1.1784626245498657,
      "learning_rate": 1.1523998268566122e-05,
      "loss": 0.4692,
      "step": 862500
    },
    {
      "epoch": 9.130805998274411,
      "eval_loss": 0.2907884418964386,
      "eval_runtime": 46.8176,
      "eval_samples_per_second": 3586.899,
      "eval_steps_per_second": 448.378,
      "step": 862500
    },
    {
      "epoch": 9.131335320054415,
      "grad_norm": 1.4202611446380615,
      "learning_rate": 1.1510139485857856e-05,
      "loss": 0.4732,
      "step": 862550
    },
    {
      "epoch": 9.131864641834417,
      "grad_norm": 1.337768793106079,
      "learning_rate": 1.1496288845105979e-05,
      "loss": 0.4738,
      "step": 862600
    },
    {
      "epoch": 9.13239396361442,
      "grad_norm": 1.2944892644882202,
      "learning_rate": 1.1482446346783304e-05,
      "loss": 0.4691,
      "step": 862650
    },
    {
      "epoch": 9.132923285394424,
      "grad_norm": 1.3124607801437378,
      "learning_rate": 1.1468611991362482e-05,
      "loss": 0.4791,
      "step": 862700
    },
    {
      "epoch": 9.133452607174428,
      "grad_norm": 1.460930347442627,
      "learning_rate": 1.1454785779315719e-05,
      "loss": 0.4783,
      "step": 862750
    },
    {
      "epoch": 9.13398192895443,
      "grad_norm": 1.5610148906707764,
      "learning_rate": 1.1440967711115136e-05,
      "loss": 0.4747,
      "step": 862800
    },
    {
      "epoch": 9.134511250734434,
      "grad_norm": 1.5178587436676025,
      "learning_rate": 1.1427157787232384e-05,
      "loss": 0.4713,
      "step": 862850
    },
    {
      "epoch": 9.135040572514438,
      "grad_norm": 1.402408242225647,
      "learning_rate": 1.1413356008139004e-05,
      "loss": 0.4687,
      "step": 862900
    },
    {
      "epoch": 9.13556989429444,
      "grad_norm": 1.2734957933425903,
      "learning_rate": 1.1399562374306088e-05,
      "loss": 0.4701,
      "step": 862950
    },
    {
      "epoch": 9.136099216074443,
      "grad_norm": 1.358340859413147,
      "learning_rate": 1.138577688620468e-05,
      "loss": 0.4776,
      "step": 863000
    },
    {
      "epoch": 9.136099216074443,
      "eval_loss": 0.2906893789768219,
      "eval_runtime": 46.9376,
      "eval_samples_per_second": 3577.727,
      "eval_steps_per_second": 447.232,
      "step": 863000
    },
    {
      "epoch": 9.136628537854447,
      "grad_norm": 1.4812484979629517,
      "learning_rate": 1.1371999544305289e-05,
      "loss": 0.4731,
      "step": 863050
    },
    {
      "epoch": 9.137157859634451,
      "grad_norm": 1.486336350440979,
      "learning_rate": 1.1358230349078347e-05,
      "loss": 0.4762,
      "step": 863100
    },
    {
      "epoch": 9.137687181414453,
      "grad_norm": 1.4171684980392456,
      "learning_rate": 1.1344469300993893e-05,
      "loss": 0.4682,
      "step": 863150
    },
    {
      "epoch": 9.138216503194457,
      "grad_norm": 1.3486090898513794,
      "learning_rate": 1.1330716400521718e-05,
      "loss": 0.4729,
      "step": 863200
    },
    {
      "epoch": 9.13874582497446,
      "grad_norm": 1.3228955268859863,
      "learning_rate": 1.1316971648131364e-05,
      "loss": 0.4712,
      "step": 863250
    },
    {
      "epoch": 9.139275146754464,
      "grad_norm": 1.4021286964416504,
      "learning_rate": 1.1303235044292093e-05,
      "loss": 0.4714,
      "step": 863300
    },
    {
      "epoch": 9.139804468534466,
      "grad_norm": 1.429497241973877,
      "learning_rate": 1.1289506589472809e-05,
      "loss": 0.466,
      "step": 863350
    },
    {
      "epoch": 9.14033379031447,
      "grad_norm": 1.2456812858581543,
      "learning_rate": 1.1275786284142247e-05,
      "loss": 0.4667,
      "step": 863400
    },
    {
      "epoch": 9.140863112094474,
      "grad_norm": 1.3377379179000854,
      "learning_rate": 1.1262074128768756e-05,
      "loss": 0.4723,
      "step": 863450
    },
    {
      "epoch": 9.141392433874477,
      "grad_norm": 1.3475286960601807,
      "learning_rate": 1.1248370123820545e-05,
      "loss": 0.4671,
      "step": 863500
    },
    {
      "epoch": 9.141392433874477,
      "eval_loss": 0.29040998220443726,
      "eval_runtime": 46.7601,
      "eval_samples_per_second": 3591.311,
      "eval_steps_per_second": 448.93,
      "step": 863500
    },
    {
      "epoch": 9.14192175565448,
      "grad_norm": 1.1602444648742676,
      "learning_rate": 1.1234674269765377e-05,
      "loss": 0.4575,
      "step": 863550
    },
    {
      "epoch": 9.142451077434483,
      "grad_norm": 1.4149140119552612,
      "learning_rate": 1.1220986567070906e-05,
      "loss": 0.4659,
      "step": 863600
    },
    {
      "epoch": 9.142980399214487,
      "grad_norm": 1.307677984237671,
      "learning_rate": 1.1207307016204343e-05,
      "loss": 0.4717,
      "step": 863650
    },
    {
      "epoch": 9.143509720994489,
      "grad_norm": 1.4626233577728271,
      "learning_rate": 1.1193635617632786e-05,
      "loss": 0.4676,
      "step": 863700
    },
    {
      "epoch": 9.144039042774493,
      "grad_norm": 1.1508972644805908,
      "learning_rate": 1.1179972371822888e-05,
      "loss": 0.4698,
      "step": 863750
    },
    {
      "epoch": 9.144568364554496,
      "grad_norm": 1.433809757232666,
      "learning_rate": 1.1166317279241167e-05,
      "loss": 0.475,
      "step": 863800
    },
    {
      "epoch": 9.1450976863345,
      "grad_norm": 1.5189478397369385,
      "learning_rate": 1.1152670340353776e-05,
      "loss": 0.4692,
      "step": 863850
    },
    {
      "epoch": 9.145627008114502,
      "grad_norm": 1.5173734426498413,
      "learning_rate": 1.113903155562665e-05,
      "loss": 0.4645,
      "step": 863900
    },
    {
      "epoch": 9.146156329894506,
      "grad_norm": 1.3693536520004272,
      "learning_rate": 1.1125400925525358e-05,
      "loss": 0.4694,
      "step": 863950
    },
    {
      "epoch": 9.14668565167451,
      "grad_norm": 1.315579891204834,
      "learning_rate": 1.111177845051528e-05,
      "loss": 0.4667,
      "step": 864000
    },
    {
      "epoch": 9.14668565167451,
      "eval_loss": 0.29043933749198914,
      "eval_runtime": 46.9662,
      "eval_samples_per_second": 3575.553,
      "eval_steps_per_second": 446.96,
      "step": 864000
    },
    {
      "epoch": 9.147214973454513,
      "grad_norm": 1.4090832471847534,
      "learning_rate": 1.1098164131061489e-05,
      "loss": 0.4749,
      "step": 864050
    },
    {
      "epoch": 9.147744295234515,
      "grad_norm": 1.2294886112213135,
      "learning_rate": 1.108455796762875e-05,
      "loss": 0.4678,
      "step": 864100
    },
    {
      "epoch": 9.14827361701452,
      "grad_norm": 1.3851395845413208,
      "learning_rate": 1.1070959960681581e-05,
      "loss": 0.4727,
      "step": 864150
    },
    {
      "epoch": 9.148802938794523,
      "grad_norm": 1.353643774986267,
      "learning_rate": 1.1057370110684223e-05,
      "loss": 0.474,
      "step": 864200
    },
    {
      "epoch": 9.149332260574527,
      "grad_norm": 1.3560913801193237,
      "learning_rate": 1.1043788418100609e-05,
      "loss": 0.4653,
      "step": 864250
    },
    {
      "epoch": 9.149861582354529,
      "grad_norm": 1.2820353507995605,
      "learning_rate": 1.1030214883394452e-05,
      "loss": 0.4722,
      "step": 864300
    },
    {
      "epoch": 9.150390904134532,
      "grad_norm": 1.3734171390533447,
      "learning_rate": 1.1016649507029075e-05,
      "loss": 0.4666,
      "step": 864350
    },
    {
      "epoch": 9.150920225914536,
      "grad_norm": 1.4309728145599365,
      "learning_rate": 1.1003092289467665e-05,
      "loss": 0.4795,
      "step": 864400
    },
    {
      "epoch": 9.15144954769454,
      "grad_norm": 1.4375404119491577,
      "learning_rate": 1.0989543231173016e-05,
      "loss": 0.4768,
      "step": 864450
    },
    {
      "epoch": 9.151978869474542,
      "grad_norm": 1.4509366750717163,
      "learning_rate": 1.0976002332607733e-05,
      "loss": 0.4732,
      "step": 864500
    },
    {
      "epoch": 9.151978869474542,
      "eval_loss": 0.29041099548339844,
      "eval_runtime": 46.7956,
      "eval_samples_per_second": 3588.587,
      "eval_steps_per_second": 448.589,
      "step": 864500
    },
    {
      "epoch": 9.152508191254546,
      "grad_norm": 1.415299654006958,
      "learning_rate": 1.0962469594234054e-05,
      "loss": 0.4658,
      "step": 864550
    },
    {
      "epoch": 9.15303751303455,
      "grad_norm": 1.3329439163208008,
      "learning_rate": 1.0948945016514001e-05,
      "loss": 0.4723,
      "step": 864600
    },
    {
      "epoch": 9.153566834814551,
      "grad_norm": 1.4720096588134766,
      "learning_rate": 1.0935428599909286e-05,
      "loss": 0.4719,
      "step": 864650
    },
    {
      "epoch": 9.154096156594555,
      "grad_norm": 1.239126205444336,
      "learning_rate": 1.0921920344881375e-05,
      "loss": 0.4684,
      "step": 864700
    },
    {
      "epoch": 9.154625478374559,
      "grad_norm": 1.391913890838623,
      "learning_rate": 1.0908420251891427e-05,
      "loss": 0.4684,
      "step": 864750
    },
    {
      "epoch": 9.155154800154563,
      "grad_norm": 1.467531442642212,
      "learning_rate": 1.089492832140032e-05,
      "loss": 0.4718,
      "step": 864800
    },
    {
      "epoch": 9.155684121934565,
      "grad_norm": 1.3611701726913452,
      "learning_rate": 1.0881444553868663e-05,
      "loss": 0.4683,
      "step": 864850
    },
    {
      "epoch": 9.156213443714568,
      "grad_norm": 1.2411959171295166,
      "learning_rate": 1.0867968949756806e-05,
      "loss": 0.4674,
      "step": 864900
    },
    {
      "epoch": 9.156742765494572,
      "grad_norm": 1.3982059955596924,
      "learning_rate": 1.0854501509524772e-05,
      "loss": 0.4762,
      "step": 864950
    },
    {
      "epoch": 9.157272087274576,
      "grad_norm": 1.3807698488235474,
      "learning_rate": 1.0841042233632387e-05,
      "loss": 0.4745,
      "step": 865000
    },
    {
      "epoch": 9.157272087274576,
      "eval_loss": 0.2906639873981476,
      "eval_runtime": 46.8903,
      "eval_samples_per_second": 3581.335,
      "eval_steps_per_second": 447.683,
      "step": 865000
    },
    {
      "epoch": 9.157801409054578,
      "grad_norm": 1.252264142036438,
      "learning_rate": 1.0827591122539087e-05,
      "loss": 0.4661,
      "step": 865050
    },
    {
      "epoch": 9.158330730834582,
      "grad_norm": 1.2102967500686646,
      "learning_rate": 1.0814148176704148e-05,
      "loss": 0.4674,
      "step": 865100
    },
    {
      "epoch": 9.158860052614585,
      "grad_norm": 1.3189159631729126,
      "learning_rate": 1.080071339658642e-05,
      "loss": 0.465,
      "step": 865150
    },
    {
      "epoch": 9.159389374394589,
      "grad_norm": 1.3690052032470703,
      "learning_rate": 1.0787286782644651e-05,
      "loss": 0.4649,
      "step": 865200
    },
    {
      "epoch": 9.159918696174591,
      "grad_norm": 1.4955836534500122,
      "learning_rate": 1.077386833533714e-05,
      "loss": 0.47,
      "step": 865250
    },
    {
      "epoch": 9.160448017954595,
      "grad_norm": 1.3205567598342896,
      "learning_rate": 1.0760458055122075e-05,
      "loss": 0.47,
      "step": 865300
    },
    {
      "epoch": 9.160977339734599,
      "grad_norm": 1.4996892213821411,
      "learning_rate": 1.0747055942457202e-05,
      "loss": 0.4657,
      "step": 865350
    },
    {
      "epoch": 9.1615066615146,
      "grad_norm": 1.3125687837600708,
      "learning_rate": 1.0733929796643838e-05,
      "loss": 0.4777,
      "step": 865400
    },
    {
      "epoch": 9.162035983294604,
      "grad_norm": 1.4709445238113403,
      "learning_rate": 1.0720543857077963e-05,
      "loss": 0.4683,
      "step": 865450
    },
    {
      "epoch": 9.162565305074608,
      "grad_norm": 1.4040533304214478,
      "learning_rate": 1.0707166086425025e-05,
      "loss": 0.4649,
      "step": 865500
    },
    {
      "epoch": 9.162565305074608,
      "eval_loss": 0.2904638946056366,
      "eval_runtime": 46.8429,
      "eval_samples_per_second": 3584.96,
      "eval_steps_per_second": 448.136,
      "step": 865500
    },
    {
      "epoch": 9.163094626854612,
      "grad_norm": 1.4182076454162598,
      "learning_rate": 1.0693796485141627e-05,
      "loss": 0.4716,
      "step": 865550
    },
    {
      "epoch": 9.163623948634614,
      "grad_norm": 1.336094617843628,
      "learning_rate": 1.0680435053684322e-05,
      "loss": 0.478,
      "step": 865600
    },
    {
      "epoch": 9.164153270414618,
      "grad_norm": 1.3596616983413696,
      "learning_rate": 1.0667081792509136e-05,
      "loss": 0.4708,
      "step": 865650
    },
    {
      "epoch": 9.164682592194621,
      "grad_norm": 1.431978464126587,
      "learning_rate": 1.0653736702072036e-05,
      "loss": 0.4659,
      "step": 865700
    },
    {
      "epoch": 9.165211913974625,
      "grad_norm": 1.4445871114730835,
      "learning_rate": 1.0640399782828547e-05,
      "loss": 0.4718,
      "step": 865750
    },
    {
      "epoch": 9.165741235754627,
      "grad_norm": 1.411346673965454,
      "learning_rate": 1.0627071035234081e-05,
      "loss": 0.4686,
      "step": 865800
    },
    {
      "epoch": 9.16627055753463,
      "grad_norm": 1.3825753927230835,
      "learning_rate": 1.0613750459743581e-05,
      "loss": 0.4721,
      "step": 865850
    },
    {
      "epoch": 9.166799879314635,
      "grad_norm": 1.4905791282653809,
      "learning_rate": 1.0600438056811879e-05,
      "loss": 0.4694,
      "step": 865900
    },
    {
      "epoch": 9.167329201094638,
      "grad_norm": 1.4388718605041504,
      "learning_rate": 1.0587133826893413e-05,
      "loss": 0.4692,
      "step": 865950
    },
    {
      "epoch": 9.16785852287464,
      "grad_norm": 1.5166805982589722,
      "learning_rate": 1.0573837770442407e-05,
      "loss": 0.4663,
      "step": 866000
    },
    {
      "epoch": 9.16785852287464,
      "eval_loss": 0.2901269495487213,
      "eval_runtime": 46.8177,
      "eval_samples_per_second": 3586.889,
      "eval_steps_per_second": 448.377,
      "step": 866000
    },
    {
      "epoch": 9.168387844654644,
      "grad_norm": 1.2580900192260742,
      "learning_rate": 1.0560549887912747e-05,
      "loss": 0.4684,
      "step": 866050
    },
    {
      "epoch": 9.168917166434648,
      "grad_norm": 1.460155963897705,
      "learning_rate": 1.0547270179758123e-05,
      "loss": 0.4667,
      "step": 866100
    },
    {
      "epoch": 9.16944648821465,
      "grad_norm": 1.4826494455337524,
      "learning_rate": 1.0533998646431841e-05,
      "loss": 0.4717,
      "step": 866150
    },
    {
      "epoch": 9.169975809994654,
      "grad_norm": 1.3507658243179321,
      "learning_rate": 1.0520735288387068e-05,
      "loss": 0.469,
      "step": 866200
    },
    {
      "epoch": 9.170505131774657,
      "grad_norm": 1.3258850574493408,
      "learning_rate": 1.050748010607655e-05,
      "loss": 0.4569,
      "step": 866250
    },
    {
      "epoch": 9.171034453554661,
      "grad_norm": 1.3603019714355469,
      "learning_rate": 1.0494233099952843e-05,
      "loss": 0.4741,
      "step": 866300
    },
    {
      "epoch": 9.171563775334663,
      "grad_norm": 1.2036322355270386,
      "learning_rate": 1.0480994270468142e-05,
      "loss": 0.4614,
      "step": 866350
    },
    {
      "epoch": 9.172093097114667,
      "grad_norm": 1.5273733139038086,
      "learning_rate": 1.0467763618074499e-05,
      "loss": 0.4722,
      "step": 866400
    },
    {
      "epoch": 9.17262241889467,
      "grad_norm": 1.4112679958343506,
      "learning_rate": 1.0454541143223529e-05,
      "loss": 0.4702,
      "step": 866450
    },
    {
      "epoch": 9.173151740674674,
      "grad_norm": 1.4226813316345215,
      "learning_rate": 1.04413268463667e-05,
      "loss": 0.4665,
      "step": 866500
    },
    {
      "epoch": 9.173151740674674,
      "eval_loss": 0.2903189957141876,
      "eval_runtime": 46.8299,
      "eval_samples_per_second": 3585.958,
      "eval_steps_per_second": 448.261,
      "step": 866500
    },
    {
      "epoch": 9.173681062454676,
      "grad_norm": 1.2016477584838867,
      "learning_rate": 1.0428120727955098e-05,
      "loss": 0.4695,
      "step": 866550
    },
    {
      "epoch": 9.17421038423468,
      "grad_norm": 1.2375810146331787,
      "learning_rate": 1.0414922788439612e-05,
      "loss": 0.4651,
      "step": 866600
    },
    {
      "epoch": 9.174739706014684,
      "grad_norm": 1.3780473470687866,
      "learning_rate": 1.040173302827077e-05,
      "loss": 0.4698,
      "step": 866650
    },
    {
      "epoch": 9.175269027794688,
      "grad_norm": 1.2956578731536865,
      "learning_rate": 1.0388551447898908e-05,
      "loss": 0.4652,
      "step": 866700
    },
    {
      "epoch": 9.17579834957469,
      "grad_norm": 1.4322587251663208,
      "learning_rate": 1.0375378047774026e-05,
      "loss": 0.4689,
      "step": 866750
    },
    {
      "epoch": 9.176327671354693,
      "grad_norm": 1.2262393236160278,
      "learning_rate": 1.0362212828345845e-05,
      "loss": 0.4663,
      "step": 866800
    },
    {
      "epoch": 9.176856993134697,
      "grad_norm": 1.5379232168197632,
      "learning_rate": 1.0349055790063843e-05,
      "loss": 0.4686,
      "step": 866850
    },
    {
      "epoch": 9.177386314914699,
      "grad_norm": 1.4448751211166382,
      "learning_rate": 1.0335906933377214e-05,
      "loss": 0.4732,
      "step": 866900
    },
    {
      "epoch": 9.177915636694703,
      "grad_norm": 1.462989330291748,
      "learning_rate": 1.0322766258734766e-05,
      "loss": 0.4708,
      "step": 866950
    },
    {
      "epoch": 9.178444958474707,
      "grad_norm": 1.4787790775299072,
      "learning_rate": 1.0309633766585198e-05,
      "loss": 0.4636,
      "step": 867000
    },
    {
      "epoch": 9.178444958474707,
      "eval_loss": 0.29007041454315186,
      "eval_runtime": 46.887,
      "eval_samples_per_second": 3581.593,
      "eval_steps_per_second": 447.715,
      "step": 867000
    },
    {
      "epoch": 9.17897428025471,
      "grad_norm": 1.4401413202285767,
      "learning_rate": 1.0296509457376868e-05,
      "loss": 0.4655,
      "step": 867050
    },
    {
      "epoch": 9.179503602034712,
      "grad_norm": 1.5010161399841309,
      "learning_rate": 1.0283393331557755e-05,
      "loss": 0.4775,
      "step": 867100
    },
    {
      "epoch": 9.180032923814716,
      "grad_norm": 1.496808409690857,
      "learning_rate": 1.0270285389575695e-05,
      "loss": 0.4737,
      "step": 867150
    },
    {
      "epoch": 9.18056224559472,
      "grad_norm": 1.4104187488555908,
      "learning_rate": 1.0257185631878191e-05,
      "loss": 0.4666,
      "step": 867200
    },
    {
      "epoch": 9.181091567374724,
      "grad_norm": 1.3030037879943848,
      "learning_rate": 1.0244094058912411e-05,
      "loss": 0.4661,
      "step": 867250
    },
    {
      "epoch": 9.181620889154726,
      "grad_norm": 1.3880771398544312,
      "learning_rate": 1.0231010671125363e-05,
      "loss": 0.4686,
      "step": 867300
    },
    {
      "epoch": 9.18215021093473,
      "grad_norm": 1.2282248735427856,
      "learning_rate": 1.0217935468963657e-05,
      "loss": 0.4735,
      "step": 867350
    },
    {
      "epoch": 9.182679532714733,
      "grad_norm": 1.3475310802459717,
      "learning_rate": 1.0204868452873716e-05,
      "loss": 0.4727,
      "step": 867400
    },
    {
      "epoch": 9.183208854494737,
      "grad_norm": 1.2746267318725586,
      "learning_rate": 1.01920707196623e-05,
      "loss": 0.4714,
      "step": 867450
    },
    {
      "epoch": 9.183738176274739,
      "grad_norm": 1.4749324321746826,
      "learning_rate": 1.0179019913310216e-05,
      "loss": 0.4682,
      "step": 867500
    },
    {
      "epoch": 9.183738176274739,
      "eval_loss": 0.29029688239097595,
      "eval_runtime": 46.9596,
      "eval_samples_per_second": 3576.049,
      "eval_steps_per_second": 447.022,
      "step": 867500
    },
    {
      "epoch": 9.184267498054743,
      "grad_norm": 1.3741992712020874,
      "learning_rate": 1.0165977294358475e-05,
      "loss": 0.4602,
      "step": 867550
    },
    {
      "epoch": 9.184796819834746,
      "grad_norm": 1.4016886949539185,
      "learning_rate": 1.0152942863252273e-05,
      "loss": 0.4653,
      "step": 867600
    },
    {
      "epoch": 9.185326141614748,
      "grad_norm": 1.4627838134765625,
      "learning_rate": 1.0139916620436673e-05,
      "loss": 0.4708,
      "step": 867650
    },
    {
      "epoch": 9.185855463394752,
      "grad_norm": 1.341284155845642,
      "learning_rate": 1.012689856635632e-05,
      "loss": 0.4616,
      "step": 867700
    },
    {
      "epoch": 9.186384785174756,
      "grad_norm": 1.292213797569275,
      "learning_rate": 1.0113888701455714e-05,
      "loss": 0.4717,
      "step": 867750
    },
    {
      "epoch": 9.18691410695476,
      "grad_norm": 1.4735946655273438,
      "learning_rate": 1.010088702617895e-05,
      "loss": 0.4603,
      "step": 867800
    },
    {
      "epoch": 9.187443428734761,
      "grad_norm": 1.425716519355774,
      "learning_rate": 1.008789354096995e-05,
      "loss": 0.4749,
      "step": 867850
    },
    {
      "epoch": 9.187972750514765,
      "grad_norm": 1.3574753999710083,
      "learning_rate": 1.0074908246272247e-05,
      "loss": 0.4765,
      "step": 867900
    },
    {
      "epoch": 9.188502072294769,
      "grad_norm": 1.3430954217910767,
      "learning_rate": 1.0061931142529207e-05,
      "loss": 0.4714,
      "step": 867950
    },
    {
      "epoch": 9.189031394074773,
      "grad_norm": 1.5809054374694824,
      "learning_rate": 1.0048962230183811e-05,
      "loss": 0.482,
      "step": 868000
    },
    {
      "epoch": 9.189031394074773,
      "eval_loss": 0.2901201546192169,
      "eval_runtime": 46.8377,
      "eval_samples_per_second": 3585.357,
      "eval_steps_per_second": 448.186,
      "step": 868000
    },
    {
      "epoch": 9.189560715854775,
      "grad_norm": 1.406097412109375,
      "learning_rate": 1.0036001509678899e-05,
      "loss": 0.4737,
      "step": 868050
    },
    {
      "epoch": 9.190090037634778,
      "grad_norm": 1.2569937705993652,
      "learning_rate": 1.0023048981456839e-05,
      "loss": 0.4721,
      "step": 868100
    },
    {
      "epoch": 9.190619359414782,
      "grad_norm": 1.2306599617004395,
      "learning_rate": 1.0010104645959916e-05,
      "loss": 0.4712,
      "step": 868150
    },
    {
      "epoch": 9.191148681194786,
      "grad_norm": 1.3356789350509644,
      "learning_rate": 9.997168503629972e-06,
      "loss": 0.4641,
      "step": 868200
    },
    {
      "epoch": 9.191678002974788,
      "grad_norm": 1.2987996339797974,
      "learning_rate": 9.984240554908708e-06,
      "loss": 0.4752,
      "step": 868250
    },
    {
      "epoch": 9.192207324754792,
      "grad_norm": 1.4283257722854614,
      "learning_rate": 9.971320800237438e-06,
      "loss": 0.4683,
      "step": 868300
    },
    {
      "epoch": 9.192736646534795,
      "grad_norm": 1.4672605991363525,
      "learning_rate": 9.958409240057254e-06,
      "loss": 0.4774,
      "step": 868350
    },
    {
      "epoch": 9.193265968314797,
      "grad_norm": 1.3851118087768555,
      "learning_rate": 9.945505874808913e-06,
      "loss": 0.4743,
      "step": 868400
    },
    {
      "epoch": 9.193795290094801,
      "grad_norm": 1.384750485420227,
      "learning_rate": 9.932610704933009e-06,
      "loss": 0.4698,
      "step": 868450
    },
    {
      "epoch": 9.194324611874805,
      "grad_norm": 1.541359305381775,
      "learning_rate": 9.919723730869689e-06,
      "loss": 0.4712,
      "step": 868500
    },
    {
      "epoch": 9.194324611874805,
      "eval_loss": 0.29015856981277466,
      "eval_runtime": 46.9067,
      "eval_samples_per_second": 3580.085,
      "eval_steps_per_second": 447.527,
      "step": 868500
    },
    {
      "epoch": 9.194853933654809,
      "grad_norm": 1.323081374168396,
      "learning_rate": 9.90684495305899e-06,
      "loss": 0.4737,
      "step": 868550
    },
    {
      "epoch": 9.19538325543481,
      "grad_norm": 1.444799780845642,
      "learning_rate": 9.893974371940533e-06,
      "loss": 0.472,
      "step": 868600
    },
    {
      "epoch": 9.195912577214814,
      "grad_norm": 1.370607614517212,
      "learning_rate": 9.881111987953745e-06,
      "loss": 0.4662,
      "step": 868650
    },
    {
      "epoch": 9.196441898994818,
      "grad_norm": 1.505696415901184,
      "learning_rate": 9.868257801537717e-06,
      "loss": 0.4592,
      "step": 868700
    },
    {
      "epoch": 9.196971220774822,
      "grad_norm": 1.3558390140533447,
      "learning_rate": 9.855411813131349e-06,
      "loss": 0.4721,
      "step": 868750
    },
    {
      "epoch": 9.197500542554824,
      "grad_norm": 1.286356806755066,
      "learning_rate": 9.842574023173095e-06,
      "loss": 0.4689,
      "step": 868800
    },
    {
      "epoch": 9.198029864334828,
      "grad_norm": 1.3407315015792847,
      "learning_rate": 9.82974443210133e-06,
      "loss": 0.4641,
      "step": 868850
    },
    {
      "epoch": 9.198559186114831,
      "grad_norm": 1.5058199167251587,
      "learning_rate": 9.816923040353948e-06,
      "loss": 0.4667,
      "step": 868900
    },
    {
      "epoch": 9.199088507894835,
      "grad_norm": 1.4281601905822754,
      "learning_rate": 9.804109848368797e-06,
      "loss": 0.4643,
      "step": 868950
    },
    {
      "epoch": 9.199617829674837,
      "grad_norm": 1.3391680717468262,
      "learning_rate": 9.791304856583194e-06,
      "loss": 0.4717,
      "step": 869000
    },
    {
      "epoch": 9.199617829674837,
      "eval_loss": 0.2898161709308624,
      "eval_runtime": 47.0064,
      "eval_samples_per_second": 3572.494,
      "eval_steps_per_second": 446.578,
      "step": 869000
    },
    {
      "epoch": 9.200147151454841,
      "grad_norm": 1.529695749282837,
      "learning_rate": 9.778508065434372e-06,
      "loss": 0.4699,
      "step": 869050
    },
    {
      "epoch": 9.200676473234845,
      "grad_norm": 1.337506890296936,
      "learning_rate": 9.765719475359202e-06,
      "loss": 0.4638,
      "step": 869100
    },
    {
      "epoch": 9.201205795014847,
      "grad_norm": 1.2296264171600342,
      "learning_rate": 9.752939086794227e-06,
      "loss": 0.4676,
      "step": 869150
    },
    {
      "epoch": 9.20173511679485,
      "grad_norm": 1.2492667436599731,
      "learning_rate": 9.740166900175817e-06,
      "loss": 0.4675,
      "step": 869200
    },
    {
      "epoch": 9.202264438574854,
      "grad_norm": 1.4605051279067993,
      "learning_rate": 9.727402915940043e-06,
      "loss": 0.4718,
      "step": 869250
    },
    {
      "epoch": 9.202793760354858,
      "grad_norm": 1.372543454170227,
      "learning_rate": 9.714647134522553e-06,
      "loss": 0.4679,
      "step": 869300
    },
    {
      "epoch": 9.20332308213486,
      "grad_norm": 1.3176159858703613,
      "learning_rate": 9.701899556358945e-06,
      "loss": 0.4667,
      "step": 869350
    },
    {
      "epoch": 9.203852403914864,
      "grad_norm": 1.3529406785964966,
      "learning_rate": 9.689160181884316e-06,
      "loss": 0.4642,
      "step": 869400
    },
    {
      "epoch": 9.204381725694867,
      "grad_norm": 1.3909426927566528,
      "learning_rate": 9.67642901153365e-06,
      "loss": 0.4722,
      "step": 869450
    },
    {
      "epoch": 9.204911047474871,
      "grad_norm": 1.4416122436523438,
      "learning_rate": 9.663706045741544e-06,
      "loss": 0.4708,
      "step": 869500
    },
    {
      "epoch": 9.204911047474871,
      "eval_loss": 0.2900339365005493,
      "eval_runtime": 46.8765,
      "eval_samples_per_second": 3582.392,
      "eval_steps_per_second": 447.815,
      "step": 869500
    },
    {
      "epoch": 9.205440369254873,
      "grad_norm": 1.3825373649597168,
      "learning_rate": 9.650991284942373e-06,
      "loss": 0.4705,
      "step": 869550
    },
    {
      "epoch": 9.205969691034877,
      "grad_norm": 1.420393943786621,
      "learning_rate": 9.638284729570206e-06,
      "loss": 0.473,
      "step": 869600
    },
    {
      "epoch": 9.20649901281488,
      "grad_norm": 1.3610703945159912,
      "learning_rate": 9.625586380058892e-06,
      "loss": 0.475,
      "step": 869650
    },
    {
      "epoch": 9.207028334594884,
      "grad_norm": 1.3240946531295776,
      "learning_rate": 9.612896236841862e-06,
      "loss": 0.4744,
      "step": 869700
    },
    {
      "epoch": 9.207557656374886,
      "grad_norm": 1.4436460733413696,
      "learning_rate": 9.600214300352433e-06,
      "loss": 0.475,
      "step": 869750
    },
    {
      "epoch": 9.20808697815489,
      "grad_norm": 1.2860798835754395,
      "learning_rate": 9.587793965177061e-06,
      "loss": 0.4662,
      "step": 869800
    },
    {
      "epoch": 9.208616299934894,
      "grad_norm": 1.5459887981414795,
      "learning_rate": 9.575128279285251e-06,
      "loss": 0.4709,
      "step": 869850
    },
    {
      "epoch": 9.209145621714896,
      "grad_norm": 1.3305238485336304,
      "learning_rate": 9.562470801410345e-06,
      "loss": 0.4721,
      "step": 869900
    },
    {
      "epoch": 9.2096749434949,
      "grad_norm": 1.3555718660354614,
      "learning_rate": 9.549821531984527e-06,
      "loss": 0.4743,
      "step": 869950
    },
    {
      "epoch": 9.210204265274903,
      "grad_norm": 1.227531909942627,
      "learning_rate": 9.537180471439588e-06,
      "loss": 0.4704,
      "step": 870000
    },
    {
      "epoch": 9.210204265274903,
      "eval_loss": 0.29016146063804626,
      "eval_runtime": 46.8621,
      "eval_samples_per_second": 3583.494,
      "eval_steps_per_second": 447.953,
      "step": 870000
    },
    {
      "epoch": 9.210733587054907,
      "grad_norm": 1.5030003786087036,
      "learning_rate": 9.524547620207186e-06,
      "loss": 0.4683,
      "step": 870050
    },
    {
      "epoch": 9.21126290883491,
      "grad_norm": 1.2810670137405396,
      "learning_rate": 9.511922978718474e-06,
      "loss": 0.4746,
      "step": 870100
    },
    {
      "epoch": 9.211792230614913,
      "grad_norm": 1.4275506734848022,
      "learning_rate": 9.499306547404551e-06,
      "loss": 0.4735,
      "step": 870150
    },
    {
      "epoch": 9.212321552394917,
      "grad_norm": 1.494033694267273,
      "learning_rate": 9.486698326696074e-06,
      "loss": 0.4693,
      "step": 870200
    },
    {
      "epoch": 9.21285087417492,
      "grad_norm": 1.3479235172271729,
      "learning_rate": 9.474098317023533e-06,
      "loss": 0.471,
      "step": 870250
    },
    {
      "epoch": 9.213380195954922,
      "grad_norm": 1.2388352155685425,
      "learning_rate": 9.461506518817054e-06,
      "loss": 0.4673,
      "step": 870300
    },
    {
      "epoch": 9.213909517734926,
      "grad_norm": 1.2392182350158691,
      "learning_rate": 9.448922932506543e-06,
      "loss": 0.4692,
      "step": 870350
    },
    {
      "epoch": 9.21443883951493,
      "grad_norm": 1.396169662475586,
      "learning_rate": 9.436347558521547e-06,
      "loss": 0.4608,
      "step": 870400
    },
    {
      "epoch": 9.214968161294934,
      "grad_norm": 1.3279728889465332,
      "learning_rate": 9.423780397291471e-06,
      "loss": 0.4649,
      "step": 870450
    },
    {
      "epoch": 9.215497483074936,
      "grad_norm": 1.2508350610733032,
      "learning_rate": 9.41122144924525e-06,
      "loss": 0.4641,
      "step": 870500
    },
    {
      "epoch": 9.215497483074936,
      "eval_loss": 0.2897796630859375,
      "eval_runtime": 46.7996,
      "eval_samples_per_second": 3588.278,
      "eval_steps_per_second": 448.551,
      "step": 870500
    },
    {
      "epoch": 9.21602680485494,
      "grad_norm": 1.5171849727630615,
      "learning_rate": 9.398670714811736e-06,
      "loss": 0.4784,
      "step": 870550
    },
    {
      "epoch": 9.216556126634943,
      "grad_norm": 1.4053250551223755,
      "learning_rate": 9.386128194419364e-06,
      "loss": 0.4687,
      "step": 870600
    },
    {
      "epoch": 9.217085448414945,
      "grad_norm": 1.3871055841445923,
      "learning_rate": 9.373593888496318e-06,
      "loss": 0.464,
      "step": 870650
    },
    {
      "epoch": 9.217614770194949,
      "grad_norm": 1.4103946685791016,
      "learning_rate": 9.361067797470534e-06,
      "loss": 0.4735,
      "step": 870700
    },
    {
      "epoch": 9.218144091974953,
      "grad_norm": 1.393229365348816,
      "learning_rate": 9.348549921769645e-06,
      "loss": 0.4674,
      "step": 870750
    },
    {
      "epoch": 9.218673413754956,
      "grad_norm": 1.2284059524536133,
      "learning_rate": 9.336040261820999e-06,
      "loss": 0.4642,
      "step": 870800
    },
    {
      "epoch": 9.219202735534958,
      "grad_norm": 1.2278952598571777,
      "learning_rate": 9.323538818051675e-06,
      "loss": 0.4731,
      "step": 870850
    },
    {
      "epoch": 9.219732057314962,
      "grad_norm": 1.4042915105819702,
      "learning_rate": 9.311045590888467e-06,
      "loss": 0.4687,
      "step": 870900
    },
    {
      "epoch": 9.220261379094966,
      "grad_norm": 1.501202940940857,
      "learning_rate": 9.298560580757925e-06,
      "loss": 0.4637,
      "step": 870950
    },
    {
      "epoch": 9.22079070087497,
      "grad_norm": 1.346836805343628,
      "learning_rate": 9.286083788086208e-06,
      "loss": 0.4694,
      "step": 871000
    },
    {
      "epoch": 9.22079070087497,
      "eval_loss": 0.28999993205070496,
      "eval_runtime": 47.0161,
      "eval_samples_per_second": 3571.755,
      "eval_steps_per_second": 446.485,
      "step": 871000
    },
    {
      "epoch": 9.221320022654972,
      "grad_norm": 1.4187668561935425,
      "learning_rate": 9.273615213299335e-06,
      "loss": 0.4686,
      "step": 871050
    },
    {
      "epoch": 9.221849344434975,
      "grad_norm": 1.3354480266571045,
      "learning_rate": 9.26115485682294e-06,
      "loss": 0.4697,
      "step": 871100
    },
    {
      "epoch": 9.22237866621498,
      "grad_norm": 1.421512246131897,
      "learning_rate": 9.248702719082458e-06,
      "loss": 0.469,
      "step": 871150
    },
    {
      "epoch": 9.222907987994983,
      "grad_norm": 1.4654580354690552,
      "learning_rate": 9.236258800502939e-06,
      "loss": 0.4667,
      "step": 871200
    },
    {
      "epoch": 9.223437309774985,
      "grad_norm": 1.4555271863937378,
      "learning_rate": 9.223823101509266e-06,
      "loss": 0.465,
      "step": 871250
    },
    {
      "epoch": 9.223966631554989,
      "grad_norm": 1.312767505645752,
      "learning_rate": 9.21139562252596e-06,
      "loss": 0.4595,
      "step": 871300
    },
    {
      "epoch": 9.224495953334992,
      "grad_norm": 1.4274888038635254,
      "learning_rate": 9.19897636397729e-06,
      "loss": 0.4675,
      "step": 871350
    },
    {
      "epoch": 9.225025275114994,
      "grad_norm": 1.4838662147521973,
      "learning_rate": 9.186565326287254e-06,
      "loss": 0.4768,
      "step": 871400
    },
    {
      "epoch": 9.225554596894998,
      "grad_norm": 1.4266263246536255,
      "learning_rate": 9.174162509879596e-06,
      "loss": 0.4711,
      "step": 871450
    },
    {
      "epoch": 9.226083918675002,
      "grad_norm": 1.366848111152649,
      "learning_rate": 9.161767915177699e-06,
      "loss": 0.4723,
      "step": 871500
    },
    {
      "epoch": 9.226083918675002,
      "eval_loss": 0.2899494171142578,
      "eval_runtime": 46.8591,
      "eval_samples_per_second": 3583.724,
      "eval_steps_per_second": 447.981,
      "step": 871500
    },
    {
      "epoch": 9.226613240455006,
      "grad_norm": 1.3288676738739014,
      "learning_rate": 9.149381542604724e-06,
      "loss": 0.4715,
      "step": 871550
    },
    {
      "epoch": 9.227142562235008,
      "grad_norm": 1.2746580839157104,
      "learning_rate": 9.137003392583499e-06,
      "loss": 0.475,
      "step": 871600
    },
    {
      "epoch": 9.227671884015011,
      "grad_norm": 1.373638391494751,
      "learning_rate": 9.124633465536686e-06,
      "loss": 0.466,
      "step": 871650
    },
    {
      "epoch": 9.228201205795015,
      "grad_norm": 1.3718260526657104,
      "learning_rate": 9.112271761886532e-06,
      "loss": 0.4693,
      "step": 871700
    },
    {
      "epoch": 9.228730527575019,
      "grad_norm": 1.57248854637146,
      "learning_rate": 9.099918282055087e-06,
      "loss": 0.4693,
      "step": 871750
    },
    {
      "epoch": 9.22925984935502,
      "grad_norm": 1.4167898893356323,
      "learning_rate": 9.08757302646407e-06,
      "loss": 0.4708,
      "step": 871800
    },
    {
      "epoch": 9.229789171135025,
      "grad_norm": 1.316369891166687,
      "learning_rate": 9.075235995534975e-06,
      "loss": 0.4651,
      "step": 871850
    },
    {
      "epoch": 9.230318492915028,
      "grad_norm": 1.515365719795227,
      "learning_rate": 9.063153685197334e-06,
      "loss": 0.4714,
      "step": 871900
    },
    {
      "epoch": 9.230847814695032,
      "grad_norm": 1.3625057935714722,
      "learning_rate": 9.050832940341064e-06,
      "loss": 0.4717,
      "step": 871950
    },
    {
      "epoch": 9.231377136475034,
      "grad_norm": 1.487786889076233,
      "learning_rate": 9.038520421401047e-06,
      "loss": 0.4689,
      "step": 872000
    },
    {
      "epoch": 9.231377136475034,
      "eval_loss": 0.28993192315101624,
      "eval_runtime": 47.0891,
      "eval_samples_per_second": 3566.222,
      "eval_steps_per_second": 445.794,
      "step": 872000
    },
    {
      "epoch": 9.231906458255038,
      "grad_norm": 1.3642933368682861,
      "learning_rate": 9.026216128797532e-06,
      "loss": 0.4681,
      "step": 872050
    },
    {
      "epoch": 9.232435780035042,
      "grad_norm": 1.454445719718933,
      "learning_rate": 9.013920062950653e-06,
      "loss": 0.4678,
      "step": 872100
    },
    {
      "epoch": 9.232965101815044,
      "grad_norm": 1.4102180004119873,
      "learning_rate": 9.00163222428016e-06,
      "loss": 0.4678,
      "step": 872150
    },
    {
      "epoch": 9.233494423595047,
      "grad_norm": 1.383553147315979,
      "learning_rate": 8.989352613205548e-06,
      "loss": 0.4699,
      "step": 872200
    },
    {
      "epoch": 9.234023745375051,
      "grad_norm": 1.3585225343704224,
      "learning_rate": 8.977081230146039e-06,
      "loss": 0.4733,
      "step": 872250
    },
    {
      "epoch": 9.234553067155055,
      "grad_norm": 1.3500127792358398,
      "learning_rate": 8.964818075520631e-06,
      "loss": 0.4664,
      "step": 872300
    },
    {
      "epoch": 9.235082388935057,
      "grad_norm": 1.433398962020874,
      "learning_rate": 8.952563149747878e-06,
      "loss": 0.467,
      "step": 872350
    },
    {
      "epoch": 9.23561171071506,
      "grad_norm": 1.4684582948684692,
      "learning_rate": 8.940316453246278e-06,
      "loss": 0.4696,
      "step": 872400
    },
    {
      "epoch": 9.236141032495064,
      "grad_norm": 1.2469496726989746,
      "learning_rate": 8.928077986433802e-06,
      "loss": 0.4707,
      "step": 872450
    },
    {
      "epoch": 9.236670354275068,
      "grad_norm": 1.4268043041229248,
      "learning_rate": 8.915847749728395e-06,
      "loss": 0.4656,
      "step": 872500
    },
    {
      "epoch": 9.236670354275068,
      "eval_loss": 0.28974825143814087,
      "eval_runtime": 46.8746,
      "eval_samples_per_second": 3582.539,
      "eval_steps_per_second": 447.833,
      "step": 872500
    },
    {
      "epoch": 9.23719967605507,
      "grad_norm": 1.3922381401062012,
      "learning_rate": 8.903625743547472e-06,
      "loss": 0.4696,
      "step": 872550
    },
    {
      "epoch": 9.237728997835074,
      "grad_norm": 1.4503111839294434,
      "learning_rate": 8.891411968308393e-06,
      "loss": 0.4632,
      "step": 872600
    },
    {
      "epoch": 9.238258319615078,
      "grad_norm": 1.408473253250122,
      "learning_rate": 8.87920642442805e-06,
      "loss": 0.468,
      "step": 872650
    },
    {
      "epoch": 9.238787641395081,
      "grad_norm": 1.3120023012161255,
      "learning_rate": 8.867009112323216e-06,
      "loss": 0.4761,
      "step": 872700
    },
    {
      "epoch": 9.239316963175083,
      "grad_norm": 1.5120720863342285,
      "learning_rate": 8.8548200324102e-06,
      "loss": 0.4736,
      "step": 872750
    },
    {
      "epoch": 9.239846284955087,
      "grad_norm": 1.3465911149978638,
      "learning_rate": 8.84263918510525e-06,
      "loss": 0.4655,
      "step": 872800
    },
    {
      "epoch": 9.24037560673509,
      "grad_norm": 1.5202114582061768,
      "learning_rate": 8.830466570824119e-06,
      "loss": 0.4751,
      "step": 872850
    },
    {
      "epoch": 9.240904928515093,
      "grad_norm": 1.4194811582565308,
      "learning_rate": 8.81830218998242e-06,
      "loss": 0.4676,
      "step": 872900
    },
    {
      "epoch": 9.241434250295097,
      "grad_norm": 1.480026364326477,
      "learning_rate": 8.806146042995427e-06,
      "loss": 0.4719,
      "step": 872950
    },
    {
      "epoch": 9.2419635720751,
      "grad_norm": 1.3520663976669312,
      "learning_rate": 8.793998130278174e-06,
      "loss": 0.4709,
      "step": 873000
    },
    {
      "epoch": 9.2419635720751,
      "eval_loss": 0.2897058129310608,
      "eval_runtime": 46.8636,
      "eval_samples_per_second": 3583.38,
      "eval_steps_per_second": 447.939,
      "step": 873000
    },
    {
      "epoch": 9.242492893855104,
      "grad_norm": 1.4526479244232178,
      "learning_rate": 8.781858452245356e-06,
      "loss": 0.4695,
      "step": 873050
    },
    {
      "epoch": 9.243022215635106,
      "grad_norm": 1.302818775177002,
      "learning_rate": 8.769727009311419e-06,
      "loss": 0.4686,
      "step": 873100
    },
    {
      "epoch": 9.24355153741511,
      "grad_norm": 1.5131874084472656,
      "learning_rate": 8.757603801890528e-06,
      "loss": 0.4644,
      "step": 873150
    },
    {
      "epoch": 9.244080859195114,
      "grad_norm": 1.3285560607910156,
      "learning_rate": 8.745488830396609e-06,
      "loss": 0.4689,
      "step": 873200
    },
    {
      "epoch": 9.244610180975117,
      "grad_norm": 1.4426157474517822,
      "learning_rate": 8.733382095243159e-06,
      "loss": 0.466,
      "step": 873250
    },
    {
      "epoch": 9.24513950275512,
      "grad_norm": 1.5214135646820068,
      "learning_rate": 8.721283596843598e-06,
      "loss": 0.4739,
      "step": 873300
    },
    {
      "epoch": 9.245668824535123,
      "grad_norm": 1.3034509420394897,
      "learning_rate": 8.709193335610932e-06,
      "loss": 0.4715,
      "step": 873350
    },
    {
      "epoch": 9.246198146315127,
      "grad_norm": 1.4550635814666748,
      "learning_rate": 8.697111311957884e-06,
      "loss": 0.4654,
      "step": 873400
    },
    {
      "epoch": 9.24672746809513,
      "grad_norm": 1.2960195541381836,
      "learning_rate": 8.685037526297012e-06,
      "loss": 0.4725,
      "step": 873450
    },
    {
      "epoch": 9.247256789875133,
      "grad_norm": 1.2948616743087769,
      "learning_rate": 8.672971979040434e-06,
      "loss": 0.4771,
      "step": 873500
    },
    {
      "epoch": 9.247256789875133,
      "eval_loss": 0.2899525761604309,
      "eval_runtime": 46.8574,
      "eval_samples_per_second": 3583.855,
      "eval_steps_per_second": 447.998,
      "step": 873500
    },
    {
      "epoch": 9.247786111655136,
      "grad_norm": 1.3670496940612793,
      "learning_rate": 8.660914670600067e-06,
      "loss": 0.4701,
      "step": 873550
    },
    {
      "epoch": 9.24831543343514,
      "grad_norm": 1.5414292812347412,
      "learning_rate": 8.648865601387584e-06,
      "loss": 0.4711,
      "step": 873600
    },
    {
      "epoch": 9.248844755215142,
      "grad_norm": 1.470578670501709,
      "learning_rate": 8.636824771814322e-06,
      "loss": 0.469,
      "step": 873650
    },
    {
      "epoch": 9.249374076995146,
      "grad_norm": 1.33766508102417,
      "learning_rate": 8.624792182291342e-06,
      "loss": 0.4695,
      "step": 873700
    },
    {
      "epoch": 9.24990339877515,
      "grad_norm": 1.3574193716049194,
      "learning_rate": 8.612767833229424e-06,
      "loss": 0.4687,
      "step": 873750
    },
    {
      "epoch": 9.250432720555153,
      "grad_norm": 1.4500651359558105,
      "learning_rate": 8.600751725039102e-06,
      "loss": 0.4622,
      "step": 873800
    },
    {
      "epoch": 9.250962042335155,
      "grad_norm": 1.4631316661834717,
      "learning_rate": 8.588743858130577e-06,
      "loss": 0.4655,
      "step": 873850
    },
    {
      "epoch": 9.251491364115159,
      "grad_norm": 1.556166648864746,
      "learning_rate": 8.576744232913824e-06,
      "loss": 0.4735,
      "step": 873900
    },
    {
      "epoch": 9.252020685895163,
      "grad_norm": 1.365525722503662,
      "learning_rate": 8.564752849798435e-06,
      "loss": 0.4723,
      "step": 873950
    },
    {
      "epoch": 9.252550007675167,
      "grad_norm": 1.4137176275253296,
      "learning_rate": 8.552769709193886e-06,
      "loss": 0.4768,
      "step": 874000
    },
    {
      "epoch": 9.252550007675167,
      "eval_loss": 0.28974151611328125,
      "eval_runtime": 46.638,
      "eval_samples_per_second": 3600.709,
      "eval_steps_per_second": 450.105,
      "step": 874000
    },
    {
      "epoch": 9.253079329455169,
      "grad_norm": 1.5231010913848877,
      "learning_rate": 8.541034228679634e-06,
      "loss": 0.4715,
      "step": 874050
    },
    {
      "epoch": 9.253608651235172,
      "grad_norm": 1.5318794250488281,
      "learning_rate": 8.529067409453085e-06,
      "loss": 0.4694,
      "step": 874100
    },
    {
      "epoch": 9.254137973015176,
      "grad_norm": 1.4199696779251099,
      "learning_rate": 8.51710883395565e-06,
      "loss": 0.4729,
      "step": 874150
    },
    {
      "epoch": 9.25466729479518,
      "grad_norm": 1.475652813911438,
      "learning_rate": 8.505158502595534e-06,
      "loss": 0.4661,
      "step": 874200
    },
    {
      "epoch": 9.255196616575182,
      "grad_norm": 1.4248270988464355,
      "learning_rate": 8.493216415780741e-06,
      "loss": 0.4672,
      "step": 874250
    },
    {
      "epoch": 9.255725938355186,
      "grad_norm": 1.288084864616394,
      "learning_rate": 8.481282573918975e-06,
      "loss": 0.463,
      "step": 874300
    },
    {
      "epoch": 9.25625526013519,
      "grad_norm": 1.5382460355758667,
      "learning_rate": 8.46935697741763e-06,
      "loss": 0.4662,
      "step": 874350
    },
    {
      "epoch": 9.256784581915191,
      "grad_norm": 1.5302762985229492,
      "learning_rate": 8.457439626683883e-06,
      "loss": 0.4612,
      "step": 874400
    },
    {
      "epoch": 9.257313903695195,
      "grad_norm": 1.4696370363235474,
      "learning_rate": 8.445530522124545e-06,
      "loss": 0.4654,
      "step": 874450
    },
    {
      "epoch": 9.257843225475199,
      "grad_norm": 1.5012909173965454,
      "learning_rate": 8.433629664146209e-06,
      "loss": 0.469,
      "step": 874500
    },
    {
      "epoch": 9.257843225475199,
      "eval_loss": 0.28956517577171326,
      "eval_runtime": 46.972,
      "eval_samples_per_second": 3575.107,
      "eval_steps_per_second": 446.904,
      "step": 874500
    },
    {
      "epoch": 9.258372547255203,
      "grad_norm": 1.2895748615264893,
      "learning_rate": 8.421737053155187e-06,
      "loss": 0.47,
      "step": 874550
    },
    {
      "epoch": 9.258901869035205,
      "grad_norm": 1.5176490545272827,
      "learning_rate": 8.409852689557434e-06,
      "loss": 0.475,
      "step": 874600
    },
    {
      "epoch": 9.259431190815208,
      "grad_norm": 1.3325951099395752,
      "learning_rate": 8.397976573758737e-06,
      "loss": 0.4673,
      "step": 874650
    },
    {
      "epoch": 9.259960512595212,
      "grad_norm": 1.4956884384155273,
      "learning_rate": 8.386108706164491e-06,
      "loss": 0.4579,
      "step": 874700
    },
    {
      "epoch": 9.260489834375216,
      "grad_norm": 1.4294846057891846,
      "learning_rate": 8.37424908717993e-06,
      "loss": 0.4773,
      "step": 874750
    },
    {
      "epoch": 9.261019156155218,
      "grad_norm": 1.4120556116104126,
      "learning_rate": 8.36239771720984e-06,
      "loss": 0.4744,
      "step": 874800
    },
    {
      "epoch": 9.261548477935222,
      "grad_norm": 1.3041672706604004,
      "learning_rate": 8.350554596658899e-06,
      "loss": 0.4619,
      "step": 874850
    },
    {
      "epoch": 9.262077799715225,
      "grad_norm": 1.3089325428009033,
      "learning_rate": 8.338719725931365e-06,
      "loss": 0.4701,
      "step": 874900
    },
    {
      "epoch": 9.262607121495229,
      "grad_norm": 1.434616208076477,
      "learning_rate": 8.32689310543136e-06,
      "loss": 0.4823,
      "step": 874950
    },
    {
      "epoch": 9.263136443275231,
      "grad_norm": 1.2351020574569702,
      "learning_rate": 8.315074735562561e-06,
      "loss": 0.4776,
      "step": 875000
    },
    {
      "epoch": 9.263136443275231,
      "eval_loss": 0.28981226682662964,
      "eval_runtime": 46.7867,
      "eval_samples_per_second": 3589.272,
      "eval_steps_per_second": 448.675,
      "step": 875000
    },
    {
      "epoch": 9.263665765055235,
      "grad_norm": 1.2488350868225098,
      "learning_rate": 8.303264616728506e-06,
      "loss": 0.4655,
      "step": 875050
    },
    {
      "epoch": 9.264195086835239,
      "grad_norm": 1.4258836507797241,
      "learning_rate": 8.291462749332347e-06,
      "loss": 0.4711,
      "step": 875100
    },
    {
      "epoch": 9.26472440861524,
      "grad_norm": 1.2317910194396973,
      "learning_rate": 8.279669133777007e-06,
      "loss": 0.4691,
      "step": 875150
    },
    {
      "epoch": 9.265253730395244,
      "grad_norm": 1.3888930082321167,
      "learning_rate": 8.267883770465085e-06,
      "loss": 0.4647,
      "step": 875200
    },
    {
      "epoch": 9.265783052175248,
      "grad_norm": 1.543434500694275,
      "learning_rate": 8.256106659799006e-06,
      "loss": 0.4707,
      "step": 875250
    },
    {
      "epoch": 9.266312373955252,
      "grad_norm": 1.4611769914627075,
      "learning_rate": 8.24433780218073e-06,
      "loss": 0.4636,
      "step": 875300
    },
    {
      "epoch": 9.266841695735254,
      "grad_norm": 1.327368974685669,
      "learning_rate": 8.232577198012126e-06,
      "loss": 0.4761,
      "step": 875350
    },
    {
      "epoch": 9.267371017515257,
      "grad_norm": 1.4630601406097412,
      "learning_rate": 8.220824847694709e-06,
      "loss": 0.4725,
      "step": 875400
    },
    {
      "epoch": 9.267900339295261,
      "grad_norm": 1.3816591501235962,
      "learning_rate": 8.2090807516296e-06,
      "loss": 0.469,
      "step": 875450
    },
    {
      "epoch": 9.268429661075265,
      "grad_norm": 1.2216778993606567,
      "learning_rate": 8.197344910217842e-06,
      "loss": 0.4714,
      "step": 875500
    },
    {
      "epoch": 9.268429661075265,
      "eval_loss": 0.28969326615333557,
      "eval_runtime": 46.8248,
      "eval_samples_per_second": 3586.348,
      "eval_steps_per_second": 448.31,
      "step": 875500
    },
    {
      "epoch": 9.268958982855267,
      "grad_norm": 1.2820497751235962,
      "learning_rate": 8.185617323860028e-06,
      "loss": 0.4739,
      "step": 875550
    },
    {
      "epoch": 9.26948830463527,
      "grad_norm": 1.4317163228988647,
      "learning_rate": 8.173897992956565e-06,
      "loss": 0.4663,
      "step": 875600
    },
    {
      "epoch": 9.270017626415274,
      "grad_norm": 1.257556438446045,
      "learning_rate": 8.162186917907544e-06,
      "loss": 0.4684,
      "step": 875650
    },
    {
      "epoch": 9.270546948195278,
      "grad_norm": 1.393500804901123,
      "learning_rate": 8.150484099112759e-06,
      "loss": 0.471,
      "step": 875700
    },
    {
      "epoch": 9.27107626997528,
      "grad_norm": 1.5358024835586548,
      "learning_rate": 8.138789536971752e-06,
      "loss": 0.473,
      "step": 875750
    },
    {
      "epoch": 9.271605591755284,
      "grad_norm": 1.3502858877182007,
      "learning_rate": 8.127103231883759e-06,
      "loss": 0.4626,
      "step": 875800
    },
    {
      "epoch": 9.272134913535288,
      "grad_norm": 1.3310869932174683,
      "learning_rate": 8.11565866427491e-06,
      "loss": 0.4666,
      "step": 875850
    },
    {
      "epoch": 9.27266423531529,
      "grad_norm": 1.3423482179641724,
      "learning_rate": 8.103988709328686e-06,
      "loss": 0.4663,
      "step": 875900
    },
    {
      "epoch": 9.273193557095293,
      "grad_norm": 1.4492055177688599,
      "learning_rate": 8.092327012623552e-06,
      "loss": 0.4729,
      "step": 875950
    },
    {
      "epoch": 9.273722878875297,
      "grad_norm": 1.3519275188446045,
      "learning_rate": 8.08067357455769e-06,
      "loss": 0.4775,
      "step": 876000
    },
    {
      "epoch": 9.273722878875297,
      "eval_loss": 0.28964492678642273,
      "eval_runtime": 46.8163,
      "eval_samples_per_second": 3587.002,
      "eval_steps_per_second": 448.391,
      "step": 876000
    },
    {
      "epoch": 9.274252200655301,
      "grad_norm": 1.475460410118103,
      "learning_rate": 8.069028395528865e-06,
      "loss": 0.4704,
      "step": 876050
    },
    {
      "epoch": 9.274781522435303,
      "grad_norm": 1.583239197731018,
      "learning_rate": 8.057391475934734e-06,
      "loss": 0.4745,
      "step": 876100
    },
    {
      "epoch": 9.275310844215307,
      "grad_norm": 1.4285335540771484,
      "learning_rate": 8.045762816172502e-06,
      "loss": 0.4622,
      "step": 876150
    },
    {
      "epoch": 9.27584016599531,
      "grad_norm": 1.3526848554611206,
      "learning_rate": 8.03414241663919e-06,
      "loss": 0.4625,
      "step": 876200
    },
    {
      "epoch": 9.276369487775314,
      "grad_norm": 1.378961205482483,
      "learning_rate": 8.022530277731533e-06,
      "loss": 0.4675,
      "step": 876250
    },
    {
      "epoch": 9.276898809555316,
      "grad_norm": 1.4317138195037842,
      "learning_rate": 8.010926399845936e-06,
      "loss": 0.4708,
      "step": 876300
    },
    {
      "epoch": 9.27742813133532,
      "grad_norm": 1.2881884574890137,
      "learning_rate": 7.999330783378584e-06,
      "loss": 0.4688,
      "step": 876350
    },
    {
      "epoch": 9.277957453115324,
      "grad_norm": 1.448459506034851,
      "learning_rate": 7.987743428725297e-06,
      "loss": 0.4707,
      "step": 876400
    },
    {
      "epoch": 9.278486774895327,
      "grad_norm": 1.5103471279144287,
      "learning_rate": 7.976164336281733e-06,
      "loss": 0.46,
      "step": 876450
    },
    {
      "epoch": 9.27901609667533,
      "grad_norm": 1.317314624786377,
      "learning_rate": 7.96459350644313e-06,
      "loss": 0.464,
      "step": 876500
    },
    {
      "epoch": 9.27901609667533,
      "eval_loss": 0.289467990398407,
      "eval_runtime": 46.953,
      "eval_samples_per_second": 3576.559,
      "eval_steps_per_second": 447.086,
      "step": 876500
    },
    {
      "epoch": 9.279545418455333,
      "grad_norm": 1.3950104713439941,
      "learning_rate": 7.95303093960456e-06,
      "loss": 0.4637,
      "step": 876550
    },
    {
      "epoch": 9.280074740235337,
      "grad_norm": 1.4008433818817139,
      "learning_rate": 7.94147663616071e-06,
      "loss": 0.4638,
      "step": 876600
    },
    {
      "epoch": 9.280604062015339,
      "grad_norm": 1.2387158870697021,
      "learning_rate": 7.929930596506125e-06,
      "loss": 0.467,
      "step": 876650
    },
    {
      "epoch": 9.281133383795343,
      "grad_norm": 1.314448595046997,
      "learning_rate": 7.918392821034902e-06,
      "loss": 0.4744,
      "step": 876700
    },
    {
      "epoch": 9.281662705575346,
      "grad_norm": 1.4884694814682007,
      "learning_rate": 7.906863310140982e-06,
      "loss": 0.4672,
      "step": 876750
    },
    {
      "epoch": 9.28219202735535,
      "grad_norm": 1.4181272983551025,
      "learning_rate": 7.895342064217937e-06,
      "loss": 0.4758,
      "step": 876800
    },
    {
      "epoch": 9.282721349135352,
      "grad_norm": 1.5069305896759033,
      "learning_rate": 7.883829083659172e-06,
      "loss": 0.4704,
      "step": 876850
    },
    {
      "epoch": 9.283250670915356,
      "grad_norm": 1.4034242630004883,
      "learning_rate": 7.872324368857625e-06,
      "loss": 0.473,
      "step": 876900
    },
    {
      "epoch": 9.28377999269536,
      "grad_norm": 1.2499091625213623,
      "learning_rate": 7.860827920206175e-06,
      "loss": 0.4674,
      "step": 876950
    },
    {
      "epoch": 9.284309314475363,
      "grad_norm": 1.3623002767562866,
      "learning_rate": 7.849339738097234e-06,
      "loss": 0.478,
      "step": 877000
    },
    {
      "epoch": 9.284309314475363,
      "eval_loss": 0.28960081934928894,
      "eval_runtime": 46.8611,
      "eval_samples_per_second": 3583.572,
      "eval_steps_per_second": 447.962,
      "step": 877000
    },
    {
      "epoch": 9.284838636255365,
      "grad_norm": 1.241026520729065,
      "learning_rate": 7.837859822923065e-06,
      "loss": 0.4606,
      "step": 877050
    },
    {
      "epoch": 9.28536795803537,
      "grad_norm": 1.5133689641952515,
      "learning_rate": 7.826388175075499e-06,
      "loss": 0.4739,
      "step": 877100
    },
    {
      "epoch": 9.285897279815373,
      "grad_norm": 1.4312829971313477,
      "learning_rate": 7.814924794946277e-06,
      "loss": 0.4669,
      "step": 877150
    },
    {
      "epoch": 9.286426601595377,
      "grad_norm": 1.2446900606155396,
      "learning_rate": 7.803469682926667e-06,
      "loss": 0.4616,
      "step": 877200
    },
    {
      "epoch": 9.286955923375379,
      "grad_norm": 1.5145353078842163,
      "learning_rate": 7.792022839407804e-06,
      "loss": 0.4688,
      "step": 877250
    },
    {
      "epoch": 9.287485245155382,
      "grad_norm": 1.1344738006591797,
      "learning_rate": 7.780584264780427e-06,
      "loss": 0.4628,
      "step": 877300
    },
    {
      "epoch": 9.288014566935386,
      "grad_norm": 1.2890664339065552,
      "learning_rate": 7.769153959435088e-06,
      "loss": 0.4657,
      "step": 877350
    },
    {
      "epoch": 9.288543888715388,
      "grad_norm": 1.3444856405258179,
      "learning_rate": 7.757731923761974e-06,
      "loss": 0.4662,
      "step": 877400
    },
    {
      "epoch": 9.289073210495392,
      "grad_norm": 1.4803500175476074,
      "learning_rate": 7.746318158151078e-06,
      "loss": 0.4689,
      "step": 877450
    },
    {
      "epoch": 9.289602532275396,
      "grad_norm": 1.3812837600708008,
      "learning_rate": 7.734912662992033e-06,
      "loss": 0.4666,
      "step": 877500
    },
    {
      "epoch": 9.289602532275396,
      "eval_loss": 0.28945469856262207,
      "eval_runtime": 46.8484,
      "eval_samples_per_second": 3584.54,
      "eval_steps_per_second": 448.084,
      "step": 877500
    },
    {
      "epoch": 9.2901318540554,
      "grad_norm": 1.5159896612167358,
      "learning_rate": 7.723515438674222e-06,
      "loss": 0.4706,
      "step": 877550
    },
    {
      "epoch": 9.290661175835401,
      "grad_norm": 1.4216697216033936,
      "learning_rate": 7.712126485586724e-06,
      "loss": 0.4717,
      "step": 877600
    },
    {
      "epoch": 9.291190497615405,
      "grad_norm": 1.514108419418335,
      "learning_rate": 7.700745804118393e-06,
      "loss": 0.4671,
      "step": 877650
    },
    {
      "epoch": 9.291719819395409,
      "grad_norm": 1.4566071033477783,
      "learning_rate": 7.689373394657723e-06,
      "loss": 0.4663,
      "step": 877700
    },
    {
      "epoch": 9.292249141175413,
      "grad_norm": 1.4242321252822876,
      "learning_rate": 7.678009257592988e-06,
      "loss": 0.4701,
      "step": 877750
    },
    {
      "epoch": 9.292778462955415,
      "grad_norm": 1.4374500513076782,
      "learning_rate": 7.666653393312128e-06,
      "loss": 0.4697,
      "step": 877800
    },
    {
      "epoch": 9.293307784735418,
      "grad_norm": 1.401932954788208,
      "learning_rate": 7.655305802202888e-06,
      "loss": 0.4614,
      "step": 877850
    },
    {
      "epoch": 9.293837106515422,
      "grad_norm": 1.3427318334579468,
      "learning_rate": 7.643966484652598e-06,
      "loss": 0.466,
      "step": 877900
    },
    {
      "epoch": 9.294366428295426,
      "grad_norm": 1.4052793979644775,
      "learning_rate": 7.632635441048447e-06,
      "loss": 0.4705,
      "step": 877950
    },
    {
      "epoch": 9.294895750075428,
      "grad_norm": 1.1839560270309448,
      "learning_rate": 7.621312671777181e-06,
      "loss": 0.464,
      "step": 878000
    },
    {
      "epoch": 9.294895750075428,
      "eval_loss": 0.2894299030303955,
      "eval_runtime": 46.9989,
      "eval_samples_per_second": 3573.063,
      "eval_steps_per_second": 446.649,
      "step": 878000
    },
    {
      "epoch": 9.295425071855432,
      "grad_norm": 1.359182596206665,
      "learning_rate": 7.609998177225464e-06,
      "loss": 0.4764,
      "step": 878050
    },
    {
      "epoch": 9.295954393635435,
      "grad_norm": 1.3136088848114014,
      "learning_rate": 7.598691957779486e-06,
      "loss": 0.4617,
      "step": 878100
    },
    {
      "epoch": 9.296483715415437,
      "grad_norm": 1.5740371942520142,
      "learning_rate": 7.587394013825272e-06,
      "loss": 0.472,
      "step": 878150
    },
    {
      "epoch": 9.297013037195441,
      "grad_norm": 1.3631573915481567,
      "learning_rate": 7.576104345748514e-06,
      "loss": 0.4697,
      "step": 878200
    },
    {
      "epoch": 9.297542358975445,
      "grad_norm": 1.413873314857483,
      "learning_rate": 7.56482295393468e-06,
      "loss": 0.469,
      "step": 878250
    },
    {
      "epoch": 9.298071680755449,
      "grad_norm": 1.2949491739273071,
      "learning_rate": 7.553549838768853e-06,
      "loss": 0.4613,
      "step": 878300
    },
    {
      "epoch": 9.29860100253545,
      "grad_norm": 1.2371134757995605,
      "learning_rate": 7.542285000635946e-06,
      "loss": 0.4657,
      "step": 878350
    },
    {
      "epoch": 9.299130324315454,
      "grad_norm": 1.3832030296325684,
      "learning_rate": 7.531028439920456e-06,
      "loss": 0.4685,
      "step": 878400
    },
    {
      "epoch": 9.299659646095458,
      "grad_norm": 1.4105682373046875,
      "learning_rate": 7.5197801570068e-06,
      "loss": 0.4652,
      "step": 878450
    },
    {
      "epoch": 9.300188967875462,
      "grad_norm": 1.352484107017517,
      "learning_rate": 7.508540152278865e-06,
      "loss": 0.4675,
      "step": 878500
    },
    {
      "epoch": 9.300188967875462,
      "eval_loss": 0.2894000709056854,
      "eval_runtime": 46.8573,
      "eval_samples_per_second": 3583.862,
      "eval_steps_per_second": 447.999,
      "step": 878500
    },
    {
      "epoch": 9.300718289655464,
      "grad_norm": 1.251663327217102,
      "learning_rate": 7.49730842612048e-06,
      "loss": 0.4683,
      "step": 878550
    },
    {
      "epoch": 9.301247611435468,
      "grad_norm": 1.37174391746521,
      "learning_rate": 7.486084978915009e-06,
      "loss": 0.4702,
      "step": 878600
    },
    {
      "epoch": 9.301776933215471,
      "grad_norm": 1.299250841140747,
      "learning_rate": 7.4750940332631025e-06,
      "loss": 0.4747,
      "step": 878650
    },
    {
      "epoch": 9.302306254995475,
      "grad_norm": 1.4353361129760742,
      "learning_rate": 7.463886979514667e-06,
      "loss": 0.4602,
      "step": 878700
    },
    {
      "epoch": 9.302835576775477,
      "grad_norm": 1.4945837259292603,
      "learning_rate": 7.452688205860148e-06,
      "loss": 0.4737,
      "step": 878750
    },
    {
      "epoch": 9.30336489855548,
      "grad_norm": 1.4424680471420288,
      "learning_rate": 7.441497712681933e-06,
      "loss": 0.4598,
      "step": 878800
    },
    {
      "epoch": 9.303894220335485,
      "grad_norm": 1.340793490409851,
      "learning_rate": 7.4303155003619945e-06,
      "loss": 0.4603,
      "step": 878850
    },
    {
      "epoch": 9.304423542115487,
      "grad_norm": 1.2635514736175537,
      "learning_rate": 7.419141569282139e-06,
      "loss": 0.4686,
      "step": 878900
    },
    {
      "epoch": 9.30495286389549,
      "grad_norm": 1.4625598192214966,
      "learning_rate": 7.407975919823812e-06,
      "loss": 0.4726,
      "step": 878950
    },
    {
      "epoch": 9.305482185675494,
      "grad_norm": 1.4631237983703613,
      "learning_rate": 7.3968185523682616e-06,
      "loss": 0.4638,
      "step": 879000
    },
    {
      "epoch": 9.305482185675494,
      "eval_loss": 0.2893085777759552,
      "eval_runtime": 46.8749,
      "eval_samples_per_second": 3582.511,
      "eval_steps_per_second": 447.83,
      "step": 879000
    },
    {
      "epoch": 9.306011507455498,
      "grad_norm": 1.5101498365402222,
      "learning_rate": 7.385669467296324e-06,
      "loss": 0.4755,
      "step": 879050
    },
    {
      "epoch": 9.3065408292355,
      "grad_norm": 1.5254038572311401,
      "learning_rate": 7.374528664988667e-06,
      "loss": 0.4719,
      "step": 879100
    },
    {
      "epoch": 9.307070151015504,
      "grad_norm": 1.3600257635116577,
      "learning_rate": 7.363396145825596e-06,
      "loss": 0.4653,
      "step": 879150
    },
    {
      "epoch": 9.307599472795507,
      "grad_norm": 1.323988437652588,
      "learning_rate": 7.352271910187225e-06,
      "loss": 0.4676,
      "step": 879200
    },
    {
      "epoch": 9.308128794575511,
      "grad_norm": 1.323414921760559,
      "learning_rate": 7.341155958453278e-06,
      "loss": 0.4729,
      "step": 879250
    },
    {
      "epoch": 9.308658116355513,
      "grad_norm": 1.3927531242370605,
      "learning_rate": 7.33004829100331e-06,
      "loss": 0.4691,
      "step": 879300
    },
    {
      "epoch": 9.309187438135517,
      "grad_norm": 1.373916745185852,
      "learning_rate": 7.318948908216438e-06,
      "loss": 0.4638,
      "step": 879350
    },
    {
      "epoch": 9.30971675991552,
      "grad_norm": 1.4593902826309204,
      "learning_rate": 7.307857810471719e-06,
      "loss": 0.4618,
      "step": 879400
    },
    {
      "epoch": 9.310246081695524,
      "grad_norm": 1.4889153242111206,
      "learning_rate": 7.296774998147681e-06,
      "loss": 0.4726,
      "step": 879450
    },
    {
      "epoch": 9.310775403475526,
      "grad_norm": 1.3494640588760376,
      "learning_rate": 7.285700471622747e-06,
      "loss": 0.4725,
      "step": 879500
    },
    {
      "epoch": 9.310775403475526,
      "eval_loss": 0.28941383957862854,
      "eval_runtime": 46.8241,
      "eval_samples_per_second": 3586.4,
      "eval_steps_per_second": 448.316,
      "step": 879500
    },
    {
      "epoch": 9.31130472525553,
      "grad_norm": 1.5155216455459595,
      "learning_rate": 7.274634231274974e-06,
      "loss": 0.4637,
      "step": 879550
    },
    {
      "epoch": 9.311834047035534,
      "grad_norm": 1.2626585960388184,
      "learning_rate": 7.263576277482198e-06,
      "loss": 0.4728,
      "step": 879600
    },
    {
      "epoch": 9.312363368815536,
      "grad_norm": 1.3007384538650513,
      "learning_rate": 7.252526610621896e-06,
      "loss": 0.4699,
      "step": 879650
    },
    {
      "epoch": 9.31289269059554,
      "grad_norm": 1.435194730758667,
      "learning_rate": 7.2414852310712934e-06,
      "loss": 0.4643,
      "step": 879700
    },
    {
      "epoch": 9.313422012375543,
      "grad_norm": 1.292649507522583,
      "learning_rate": 7.230452139207394e-06,
      "loss": 0.4694,
      "step": 879750
    },
    {
      "epoch": 9.313951334155547,
      "grad_norm": 1.3096548318862915,
      "learning_rate": 7.219427335406786e-06,
      "loss": 0.4706,
      "step": 879800
    },
    {
      "epoch": 9.314480655935549,
      "grad_norm": 1.2544529438018799,
      "learning_rate": 7.208410820045891e-06,
      "loss": 0.4661,
      "step": 879850
    },
    {
      "epoch": 9.315009977715553,
      "grad_norm": 1.2509987354278564,
      "learning_rate": 7.197402593500852e-06,
      "loss": 0.4596,
      "step": 879900
    },
    {
      "epoch": 9.315539299495557,
      "grad_norm": 1.344211220741272,
      "learning_rate": 7.1864026561473946e-06,
      "loss": 0.4721,
      "step": 879950
    },
    {
      "epoch": 9.31606862127556,
      "grad_norm": 1.332783579826355,
      "learning_rate": 7.175411008361138e-06,
      "loss": 0.468,
      "step": 880000
    },
    {
      "epoch": 9.31606862127556,
      "eval_loss": 0.28951793909072876,
      "eval_runtime": 46.8288,
      "eval_samples_per_second": 3586.039,
      "eval_steps_per_second": 448.271,
      "step": 880000
    },
    {
      "epoch": 9.316597943055562,
      "grad_norm": 1.3549060821533203,
      "learning_rate": 7.16442765051728e-06,
      "loss": 0.4703,
      "step": 880050
    },
    {
      "epoch": 9.317127264835566,
      "grad_norm": 1.3492012023925781,
      "learning_rate": 7.153452582990799e-06,
      "loss": 0.4682,
      "step": 880100
    },
    {
      "epoch": 9.31765658661557,
      "grad_norm": 1.4672092199325562,
      "learning_rate": 7.1424858061563955e-06,
      "loss": 0.4623,
      "step": 880150
    },
    {
      "epoch": 9.318185908395574,
      "grad_norm": 1.2803106307983398,
      "learning_rate": 7.131527320388465e-06,
      "loss": 0.4719,
      "step": 880200
    },
    {
      "epoch": 9.318715230175576,
      "grad_norm": 1.4232916831970215,
      "learning_rate": 7.120577126061095e-06,
      "loss": 0.469,
      "step": 880250
    },
    {
      "epoch": 9.31924455195558,
      "grad_norm": 1.5351510047912598,
      "learning_rate": 7.109635223548183e-06,
      "loss": 0.4694,
      "step": 880300
    },
    {
      "epoch": 9.319773873735583,
      "grad_norm": 1.3486846685409546,
      "learning_rate": 7.098701613223235e-06,
      "loss": 0.4724,
      "step": 880350
    },
    {
      "epoch": 9.320303195515585,
      "grad_norm": 1.4137179851531982,
      "learning_rate": 7.087776295459536e-06,
      "loss": 0.4635,
      "step": 880400
    },
    {
      "epoch": 9.320832517295589,
      "grad_norm": 1.3198482990264893,
      "learning_rate": 7.076859270630065e-06,
      "loss": 0.4709,
      "step": 880450
    },
    {
      "epoch": 9.321361839075593,
      "grad_norm": 1.381864309310913,
      "learning_rate": 7.065950539107524e-06,
      "loss": 0.4748,
      "step": 880500
    },
    {
      "epoch": 9.321361839075593,
      "eval_loss": 0.289424866437912,
      "eval_runtime": 46.8175,
      "eval_samples_per_second": 3586.908,
      "eval_steps_per_second": 448.379,
      "step": 880500
    },
    {
      "epoch": 9.321891160855596,
      "grad_norm": 1.4109541177749634,
      "learning_rate": 7.0550501012643375e-06,
      "loss": 0.4685,
      "step": 880550
    },
    {
      "epoch": 9.322420482635598,
      "grad_norm": 1.3956937789916992,
      "learning_rate": 7.04415795747268e-06,
      "loss": 0.472,
      "step": 880600
    },
    {
      "epoch": 9.322949804415602,
      "grad_norm": 1.2310631275177002,
      "learning_rate": 7.033274108104309e-06,
      "loss": 0.4555,
      "step": 880650
    },
    {
      "epoch": 9.323479126195606,
      "grad_norm": 1.4924466609954834,
      "learning_rate": 7.022398553530901e-06,
      "loss": 0.4738,
      "step": 880700
    },
    {
      "epoch": 9.32400844797561,
      "grad_norm": 1.3327041864395142,
      "learning_rate": 7.011531294123657e-06,
      "loss": 0.4711,
      "step": 880750
    },
    {
      "epoch": 9.324537769755612,
      "grad_norm": 1.2422597408294678,
      "learning_rate": 7.000672330253671e-06,
      "loss": 0.4685,
      "step": 880800
    },
    {
      "epoch": 9.325067091535615,
      "grad_norm": 1.291729211807251,
      "learning_rate": 6.989821662291562e-06,
      "loss": 0.4645,
      "step": 880850
    },
    {
      "epoch": 9.325596413315619,
      "grad_norm": 1.4364935159683228,
      "learning_rate": 6.97897929060784e-06,
      "loss": 0.4635,
      "step": 880900
    },
    {
      "epoch": 9.326125735095623,
      "grad_norm": 1.3756167888641357,
      "learning_rate": 6.968145215572652e-06,
      "loss": 0.4711,
      "step": 880950
    },
    {
      "epoch": 9.326655056875625,
      "grad_norm": 1.3565788269042969,
      "learning_rate": 6.957319437555842e-06,
      "loss": 0.472,
      "step": 881000
    },
    {
      "epoch": 9.326655056875625,
      "eval_loss": 0.2892061471939087,
      "eval_runtime": 46.8048,
      "eval_samples_per_second": 3587.88,
      "eval_steps_per_second": 448.501,
      "step": 881000
    },
    {
      "epoch": 9.327184378655629,
      "grad_norm": 1.3883755207061768,
      "learning_rate": 6.946501956927004e-06,
      "loss": 0.4664,
      "step": 881050
    },
    {
      "epoch": 9.327713700435632,
      "grad_norm": 1.3061929941177368,
      "learning_rate": 6.93569277405548e-06,
      "loss": 0.4664,
      "step": 881100
    },
    {
      "epoch": 9.328243022215634,
      "grad_norm": 1.2495357990264893,
      "learning_rate": 6.924891889310253e-06,
      "loss": 0.4672,
      "step": 881150
    },
    {
      "epoch": 9.328772343995638,
      "grad_norm": 1.4593925476074219,
      "learning_rate": 6.914099303060084e-06,
      "loss": 0.4695,
      "step": 881200
    },
    {
      "epoch": 9.329301665775642,
      "grad_norm": 1.4358042478561401,
      "learning_rate": 6.903315015673373e-06,
      "loss": 0.4708,
      "step": 881250
    },
    {
      "epoch": 9.329830987555646,
      "grad_norm": 1.542230248451233,
      "learning_rate": 6.89253902751838e-06,
      "loss": 0.4665,
      "step": 881300
    },
    {
      "epoch": 9.330360309335648,
      "grad_norm": 1.4417818784713745,
      "learning_rate": 6.881771338962922e-06,
      "loss": 0.474,
      "step": 881350
    },
    {
      "epoch": 9.330889631115651,
      "grad_norm": 1.415932536125183,
      "learning_rate": 6.871011950374623e-06,
      "loss": 0.4752,
      "step": 881400
    },
    {
      "epoch": 9.331418952895655,
      "grad_norm": 1.4942293167114258,
      "learning_rate": 6.860260862120827e-06,
      "loss": 0.4655,
      "step": 881450
    },
    {
      "epoch": 9.331948274675659,
      "grad_norm": 1.4677773714065552,
      "learning_rate": 6.849518074568545e-06,
      "loss": 0.4706,
      "step": 881500
    },
    {
      "epoch": 9.331948274675659,
      "eval_loss": 0.28932589292526245,
      "eval_runtime": 46.8606,
      "eval_samples_per_second": 3583.61,
      "eval_steps_per_second": 447.967,
      "step": 881500
    },
    {
      "epoch": 9.33247759645566,
      "grad_norm": 1.4333504438400269,
      "learning_rate": 6.8387835880845405e-06,
      "loss": 0.4708,
      "step": 881550
    },
    {
      "epoch": 9.333006918235665,
      "grad_norm": 1.4021109342575073,
      "learning_rate": 6.828057403035298e-06,
      "loss": 0.4701,
      "step": 881600
    },
    {
      "epoch": 9.333536240015668,
      "grad_norm": 1.4434850215911865,
      "learning_rate": 6.817339519786997e-06,
      "loss": 0.4759,
      "step": 881650
    },
    {
      "epoch": 9.334065561795672,
      "grad_norm": 1.3615930080413818,
      "learning_rate": 6.806629938705539e-06,
      "loss": 0.4701,
      "step": 881700
    },
    {
      "epoch": 9.334594883575674,
      "grad_norm": 1.3669873476028442,
      "learning_rate": 6.795928660156548e-06,
      "loss": 0.4681,
      "step": 881750
    },
    {
      "epoch": 9.335124205355678,
      "grad_norm": 1.462773084640503,
      "learning_rate": 6.78523568450537e-06,
      "loss": 0.4621,
      "step": 881800
    },
    {
      "epoch": 9.335653527135682,
      "grad_norm": 1.395029067993164,
      "learning_rate": 6.774551012117019e-06,
      "loss": 0.4673,
      "step": 881850
    },
    {
      "epoch": 9.336182848915684,
      "grad_norm": 1.5743330717086792,
      "learning_rate": 6.763874643356316e-06,
      "loss": 0.4611,
      "step": 881900
    },
    {
      "epoch": 9.336712170695687,
      "grad_norm": 1.3888083696365356,
      "learning_rate": 6.753206578587717e-06,
      "loss": 0.4664,
      "step": 881950
    },
    {
      "epoch": 9.337241492475691,
      "grad_norm": 1.2589176893234253,
      "learning_rate": 6.74254681817546e-06,
      "loss": 0.4635,
      "step": 882000
    },
    {
      "epoch": 9.337241492475691,
      "eval_loss": 0.2892859876155853,
      "eval_runtime": 46.8059,
      "eval_samples_per_second": 3587.798,
      "eval_steps_per_second": 448.491,
      "step": 882000
    },
    {
      "epoch": 9.337770814255695,
      "grad_norm": 1.4026621580123901,
      "learning_rate": 6.73189536248342e-06,
      "loss": 0.4658,
      "step": 882050
    },
    {
      "epoch": 9.338300136035697,
      "grad_norm": 1.4347654581069946,
      "learning_rate": 6.721252211875278e-06,
      "loss": 0.4723,
      "step": 882100
    },
    {
      "epoch": 9.3388294578157,
      "grad_norm": 1.4386515617370605,
      "learning_rate": 6.710617366714356e-06,
      "loss": 0.4638,
      "step": 882150
    },
    {
      "epoch": 9.339358779595704,
      "grad_norm": 1.3611462116241455,
      "learning_rate": 6.699990827363722e-06,
      "loss": 0.4625,
      "step": 882200
    },
    {
      "epoch": 9.339888101375708,
      "grad_norm": 1.3589859008789062,
      "learning_rate": 6.689372594186171e-06,
      "loss": 0.4801,
      "step": 882250
    },
    {
      "epoch": 9.34041742315571,
      "grad_norm": 1.3193470239639282,
      "learning_rate": 6.678762667544247e-06,
      "loss": 0.4672,
      "step": 882300
    },
    {
      "epoch": 9.340946744935714,
      "grad_norm": 1.4703493118286133,
      "learning_rate": 6.668161047800076e-06,
      "loss": 0.4664,
      "step": 882350
    },
    {
      "epoch": 9.341476066715718,
      "grad_norm": 1.2589932680130005,
      "learning_rate": 6.6575677353157e-06,
      "loss": 0.4704,
      "step": 882400
    },
    {
      "epoch": 9.342005388495721,
      "grad_norm": 1.3946285247802734,
      "learning_rate": 6.646982730452666e-06,
      "loss": 0.4627,
      "step": 882450
    },
    {
      "epoch": 9.342534710275723,
      "grad_norm": 1.5182902812957764,
      "learning_rate": 6.636406033572434e-06,
      "loss": 0.4665,
      "step": 882500
    },
    {
      "epoch": 9.342534710275723,
      "eval_loss": 0.2893616259098053,
      "eval_runtime": 46.9411,
      "eval_samples_per_second": 3577.459,
      "eval_steps_per_second": 447.198,
      "step": 882500
    },
    {
      "epoch": 9.343064032055727,
      "grad_norm": 1.291205883026123,
      "learning_rate": 6.62583764503602e-06,
      "loss": 0.4685,
      "step": 882550
    },
    {
      "epoch": 9.34359335383573,
      "grad_norm": 1.3471788167953491,
      "learning_rate": 6.615277565204275e-06,
      "loss": 0.4616,
      "step": 882600
    },
    {
      "epoch": 9.344122675615733,
      "grad_norm": 1.2061707973480225,
      "learning_rate": 6.604725794437688e-06,
      "loss": 0.4643,
      "step": 882650
    },
    {
      "epoch": 9.344651997395736,
      "grad_norm": 1.4093910455703735,
      "learning_rate": 6.594182333096499e-06,
      "loss": 0.4686,
      "step": 882700
    },
    {
      "epoch": 9.34518131917574,
      "grad_norm": 1.486136555671692,
      "learning_rate": 6.5836471815406695e-06,
      "loss": 0.4718,
      "step": 882750
    },
    {
      "epoch": 9.345710640955744,
      "grad_norm": 1.475785255432129,
      "learning_rate": 6.573120340129856e-06,
      "loss": 0.465,
      "step": 882800
    },
    {
      "epoch": 9.346239962735746,
      "grad_norm": 1.3344067335128784,
      "learning_rate": 6.5626018092234115e-06,
      "loss": 0.4719,
      "step": 882850
    },
    {
      "epoch": 9.34676928451575,
      "grad_norm": 1.5411064624786377,
      "learning_rate": 6.552091589180492e-06,
      "loss": 0.4734,
      "step": 882900
    },
    {
      "epoch": 9.347298606295753,
      "grad_norm": 1.4112441539764404,
      "learning_rate": 6.541589680359866e-06,
      "loss": 0.468,
      "step": 882950
    },
    {
      "epoch": 9.347827928075757,
      "grad_norm": 1.3813155889511108,
      "learning_rate": 6.531096083120081e-06,
      "loss": 0.4642,
      "step": 883000
    },
    {
      "epoch": 9.347827928075757,
      "eval_loss": 0.2892460227012634,
      "eval_runtime": 46.8561,
      "eval_samples_per_second": 3583.953,
      "eval_steps_per_second": 448.01,
      "step": 883000
    },
    {
      "epoch": 9.34835724985576,
      "grad_norm": 1.4518132209777832,
      "learning_rate": 6.520610797819404e-06,
      "loss": 0.4752,
      "step": 883050
    },
    {
      "epoch": 9.348886571635763,
      "grad_norm": 1.3904560804367065,
      "learning_rate": 6.510133824815745e-06,
      "loss": 0.4678,
      "step": 883100
    },
    {
      "epoch": 9.349415893415767,
      "grad_norm": 1.5218199491500854,
      "learning_rate": 6.499665164466845e-06,
      "loss": 0.4674,
      "step": 883150
    },
    {
      "epoch": 9.34994521519577,
      "grad_norm": 1.3885409832000732,
      "learning_rate": 6.489204817130084e-06,
      "loss": 0.4655,
      "step": 883200
    },
    {
      "epoch": 9.350474536975772,
      "grad_norm": 1.3209238052368164,
      "learning_rate": 6.478752783162539e-06,
      "loss": 0.4682,
      "step": 883250
    },
    {
      "epoch": 9.351003858755776,
      "grad_norm": 1.2717798948287964,
      "learning_rate": 6.468517855849121e-06,
      "loss": 0.4643,
      "step": 883300
    },
    {
      "epoch": 9.35153318053578,
      "grad_norm": 1.2347478866577148,
      "learning_rate": 6.458082283405109e-06,
      "loss": 0.4659,
      "step": 883350
    },
    {
      "epoch": 9.352062502315782,
      "grad_norm": 1.4257124662399292,
      "learning_rate": 6.447655025392906e-06,
      "loss": 0.4682,
      "step": 883400
    },
    {
      "epoch": 9.352591824095786,
      "grad_norm": 1.5642677545547485,
      "learning_rate": 6.437236082168396e-06,
      "loss": 0.4687,
      "step": 883450
    },
    {
      "epoch": 9.35312114587579,
      "grad_norm": 1.4885566234588623,
      "learning_rate": 6.426825454087348e-06,
      "loss": 0.4659,
      "step": 883500
    },
    {
      "epoch": 9.35312114587579,
      "eval_loss": 0.2890876531600952,
      "eval_runtime": 46.8558,
      "eval_samples_per_second": 3583.973,
      "eval_steps_per_second": 448.013,
      "step": 883500
    },
    {
      "epoch": 9.353650467655793,
      "grad_norm": 1.4103482961654663,
      "learning_rate": 6.416423141505145e-06,
      "loss": 0.4669,
      "step": 883550
    },
    {
      "epoch": 9.354179789435795,
      "grad_norm": 1.3848007917404175,
      "learning_rate": 6.406029144776893e-06,
      "loss": 0.4642,
      "step": 883600
    },
    {
      "epoch": 9.354709111215799,
      "grad_norm": 1.5447381734848022,
      "learning_rate": 6.395643464257528e-06,
      "loss": 0.4761,
      "step": 883650
    },
    {
      "epoch": 9.355238432995803,
      "grad_norm": 1.3916434049606323,
      "learning_rate": 6.38526610030149e-06,
      "loss": 0.4716,
      "step": 883700
    },
    {
      "epoch": 9.355767754775806,
      "grad_norm": 1.3240317106246948,
      "learning_rate": 6.374897053263162e-06,
      "loss": 0.4626,
      "step": 883750
    },
    {
      "epoch": 9.356297076555808,
      "grad_norm": 1.376541018486023,
      "learning_rate": 6.364536323496512e-06,
      "loss": 0.464,
      "step": 883800
    },
    {
      "epoch": 9.356826398335812,
      "grad_norm": 1.4511786699295044,
      "learning_rate": 6.354183911355227e-06,
      "loss": 0.4672,
      "step": 883850
    },
    {
      "epoch": 9.357355720115816,
      "grad_norm": 1.597831130027771,
      "learning_rate": 6.343839817192748e-06,
      "loss": 0.4728,
      "step": 883900
    },
    {
      "epoch": 9.35788504189582,
      "grad_norm": 1.3483694791793823,
      "learning_rate": 6.333504041362209e-06,
      "loss": 0.4631,
      "step": 883950
    },
    {
      "epoch": 9.358414363675822,
      "grad_norm": 1.354945421218872,
      "learning_rate": 6.3231765842165224e-06,
      "loss": 0.4689,
      "step": 884000
    },
    {
      "epoch": 9.358414363675822,
      "eval_loss": 0.28904637694358826,
      "eval_runtime": 46.8351,
      "eval_samples_per_second": 3585.562,
      "eval_steps_per_second": 448.211,
      "step": 884000
    },
    {
      "epoch": 9.358943685455825,
      "grad_norm": 1.3990966081619263,
      "learning_rate": 6.312857446108155e-06,
      "loss": 0.462,
      "step": 884050
    },
    {
      "epoch": 9.35947300723583,
      "grad_norm": 1.3899059295654297,
      "learning_rate": 6.302546627389522e-06,
      "loss": 0.4634,
      "step": 884100
    },
    {
      "epoch": 9.360002329015831,
      "grad_norm": 1.5181084871292114,
      "learning_rate": 6.292244128412561e-06,
      "loss": 0.4662,
      "step": 884150
    },
    {
      "epoch": 9.360531650795835,
      "grad_norm": 1.5637266635894775,
      "learning_rate": 6.281949949528992e-06,
      "loss": 0.4672,
      "step": 884200
    },
    {
      "epoch": 9.361060972575839,
      "grad_norm": 1.4290530681610107,
      "learning_rate": 6.271664091090284e-06,
      "loss": 0.4751,
      "step": 884250
    },
    {
      "epoch": 9.361590294355842,
      "grad_norm": 1.4149492979049683,
      "learning_rate": 6.261386553447574e-06,
      "loss": 0.4766,
      "step": 884300
    },
    {
      "epoch": 9.362119616135844,
      "grad_norm": 1.2757776975631714,
      "learning_rate": 6.251117336951745e-06,
      "loss": 0.4673,
      "step": 884350
    },
    {
      "epoch": 9.362648937915848,
      "grad_norm": 1.2952686548233032,
      "learning_rate": 6.24085644195338e-06,
      "loss": 0.4675,
      "step": 884400
    },
    {
      "epoch": 9.363178259695852,
      "grad_norm": 1.3101855516433716,
      "learning_rate": 6.230603868802754e-06,
      "loss": 0.4702,
      "step": 884450
    },
    {
      "epoch": 9.363707581475856,
      "grad_norm": 1.2885711193084717,
      "learning_rate": 6.220359617849947e-06,
      "loss": 0.4642,
      "step": 884500
    },
    {
      "epoch": 9.363707581475856,
      "eval_loss": 0.2890474200248718,
      "eval_runtime": 46.9351,
      "eval_samples_per_second": 3577.923,
      "eval_steps_per_second": 447.256,
      "step": 884500
    },
    {
      "epoch": 9.364236903255858,
      "grad_norm": 1.3276264667510986,
      "learning_rate": 6.2101236894446244e-06,
      "loss": 0.4643,
      "step": 884550
    },
    {
      "epoch": 9.364766225035861,
      "grad_norm": 1.3616083860397339,
      "learning_rate": 6.199896083936313e-06,
      "loss": 0.4631,
      "step": 884600
    },
    {
      "epoch": 9.365295546815865,
      "grad_norm": 1.5355339050292969,
      "learning_rate": 6.189676801674094e-06,
      "loss": 0.4662,
      "step": 884650
    },
    {
      "epoch": 9.365824868595869,
      "grad_norm": 1.4344141483306885,
      "learning_rate": 6.17946584300691e-06,
      "loss": 0.4735,
      "step": 884700
    },
    {
      "epoch": 9.366354190375871,
      "grad_norm": 1.3182893991470337,
      "learning_rate": 6.1692632082833434e-06,
      "loss": 0.474,
      "step": 884750
    },
    {
      "epoch": 9.366883512155875,
      "grad_norm": 1.4566028118133545,
      "learning_rate": 6.159068897851727e-06,
      "loss": 0.4597,
      "step": 884800
    },
    {
      "epoch": 9.367412833935878,
      "grad_norm": 1.4824130535125732,
      "learning_rate": 6.148882912060061e-06,
      "loss": 0.4697,
      "step": 884850
    },
    {
      "epoch": 9.36794215571588,
      "grad_norm": 1.375503420829773,
      "learning_rate": 6.1387052512560935e-06,
      "loss": 0.4706,
      "step": 884900
    },
    {
      "epoch": 9.368471477495884,
      "grad_norm": 1.3844319581985474,
      "learning_rate": 6.1285359157872974e-06,
      "loss": 0.4781,
      "step": 884950
    },
    {
      "epoch": 9.369000799275888,
      "grad_norm": 1.3252527713775635,
      "learning_rate": 6.118374906000867e-06,
      "loss": 0.4667,
      "step": 885000
    },
    {
      "epoch": 9.369000799275888,
      "eval_loss": 0.2891767919063568,
      "eval_runtime": 46.8353,
      "eval_samples_per_second": 3585.544,
      "eval_steps_per_second": 448.209,
      "step": 885000
    },
    {
      "epoch": 9.369530121055892,
      "grad_norm": 1.3062841892242432,
      "learning_rate": 6.108222222243637e-06,
      "loss": 0.4646,
      "step": 885050
    },
    {
      "epoch": 9.370059442835894,
      "grad_norm": 1.3080390691757202,
      "learning_rate": 6.0980778648623e-06,
      "loss": 0.4684,
      "step": 885100
    },
    {
      "epoch": 9.370588764615897,
      "grad_norm": 1.360198736190796,
      "learning_rate": 6.087941834203109e-06,
      "loss": 0.4667,
      "step": 885150
    },
    {
      "epoch": 9.371118086395901,
      "grad_norm": 1.5419704914093018,
      "learning_rate": 6.077814130612147e-06,
      "loss": 0.4724,
      "step": 885200
    },
    {
      "epoch": 9.371647408175905,
      "grad_norm": 1.4334585666656494,
      "learning_rate": 6.067694754435138e-06,
      "loss": 0.4701,
      "step": 885250
    },
    {
      "epoch": 9.372176729955907,
      "grad_norm": 1.3194869756698608,
      "learning_rate": 6.057583706017555e-06,
      "loss": 0.4727,
      "step": 885300
    },
    {
      "epoch": 9.37270605173591,
      "grad_norm": 1.4968360662460327,
      "learning_rate": 6.047682958493256e-06,
      "loss": 0.4733,
      "step": 885350
    },
    {
      "epoch": 9.373235373515914,
      "grad_norm": 1.2744920253753662,
      "learning_rate": 6.03758840005747e-06,
      "loss": 0.4638,
      "step": 885400
    },
    {
      "epoch": 9.373764695295918,
      "grad_norm": 1.2080392837524414,
      "learning_rate": 6.027502170408983e-06,
      "loss": 0.4685,
      "step": 885450
    },
    {
      "epoch": 9.37429401707592,
      "grad_norm": 1.336916208267212,
      "learning_rate": 6.017424269892075e-06,
      "loss": 0.468,
      "step": 885500
    },
    {
      "epoch": 9.37429401707592,
      "eval_loss": 0.2891187071800232,
      "eval_runtime": 46.786,
      "eval_samples_per_second": 3589.323,
      "eval_steps_per_second": 448.681,
      "step": 885500
    },
    {
      "epoch": 9.374823338855924,
      "grad_norm": 1.2212910652160645,
      "learning_rate": 6.007354698850831e-06,
      "loss": 0.462,
      "step": 885550
    },
    {
      "epoch": 9.375352660635928,
      "grad_norm": 1.3422170877456665,
      "learning_rate": 5.9972934576290054e-06,
      "loss": 0.4685,
      "step": 885600
    },
    {
      "epoch": 9.37588198241593,
      "grad_norm": 1.4618827104568481,
      "learning_rate": 5.987240546570072e-06,
      "loss": 0.4645,
      "step": 885650
    },
    {
      "epoch": 9.376411304195933,
      "grad_norm": 1.3596456050872803,
      "learning_rate": 5.977195966017313e-06,
      "loss": 0.4658,
      "step": 885700
    },
    {
      "epoch": 9.376940625975937,
      "grad_norm": 1.3291782140731812,
      "learning_rate": 5.967159716313564e-06,
      "loss": 0.4691,
      "step": 885750
    },
    {
      "epoch": 9.377469947755941,
      "grad_norm": 1.383647084236145,
      "learning_rate": 5.957131797801469e-06,
      "loss": 0.4672,
      "step": 885800
    },
    {
      "epoch": 9.377999269535943,
      "grad_norm": 1.4184128046035767,
      "learning_rate": 5.947112210823419e-06,
      "loss": 0.474,
      "step": 885850
    },
    {
      "epoch": 9.378528591315947,
      "grad_norm": 1.386066198348999,
      "learning_rate": 5.937100955721447e-06,
      "loss": 0.4708,
      "step": 885900
    },
    {
      "epoch": 9.37905791309595,
      "grad_norm": 1.5338650941848755,
      "learning_rate": 5.927098032837336e-06,
      "loss": 0.4685,
      "step": 885950
    },
    {
      "epoch": 9.379587234875954,
      "grad_norm": 1.4195886850357056,
      "learning_rate": 5.917103442512589e-06,
      "loss": 0.4742,
      "step": 886000
    },
    {
      "epoch": 9.379587234875954,
      "eval_loss": 0.28926312923431396,
      "eval_runtime": 47.0545,
      "eval_samples_per_second": 3568.838,
      "eval_steps_per_second": 446.121,
      "step": 886000
    },
    {
      "epoch": 9.380116556655956,
      "grad_norm": 1.4592610597610474,
      "learning_rate": 5.907117185088434e-06,
      "loss": 0.4689,
      "step": 886050
    },
    {
      "epoch": 9.38064587843596,
      "grad_norm": 1.4116740226745605,
      "learning_rate": 5.897139260905765e-06,
      "loss": 0.4658,
      "step": 886100
    },
    {
      "epoch": 9.381175200215964,
      "grad_norm": 1.1761575937271118,
      "learning_rate": 5.887169670305253e-06,
      "loss": 0.4656,
      "step": 886150
    },
    {
      "epoch": 9.381704521995967,
      "grad_norm": 1.3707892894744873,
      "learning_rate": 5.877208413627211e-06,
      "loss": 0.4578,
      "step": 886200
    },
    {
      "epoch": 9.38223384377597,
      "grad_norm": 1.4604511260986328,
      "learning_rate": 5.867255491211781e-06,
      "loss": 0.4693,
      "step": 886250
    },
    {
      "epoch": 9.382763165555973,
      "grad_norm": 1.5028969049453735,
      "learning_rate": 5.857310903398666e-06,
      "loss": 0.4694,
      "step": 886300
    },
    {
      "epoch": 9.383292487335977,
      "grad_norm": 1.298327088356018,
      "learning_rate": 5.847374650527482e-06,
      "loss": 0.4711,
      "step": 886350
    },
    {
      "epoch": 9.383821809115979,
      "grad_norm": 1.380831241607666,
      "learning_rate": 5.837446732937346e-06,
      "loss": 0.4695,
      "step": 886400
    },
    {
      "epoch": 9.384351130895983,
      "grad_norm": 1.4897520542144775,
      "learning_rate": 5.827527150967238e-06,
      "loss": 0.4689,
      "step": 886450
    },
    {
      "epoch": 9.384880452675986,
      "grad_norm": 1.4965171813964844,
      "learning_rate": 5.817615904955803e-06,
      "loss": 0.4777,
      "step": 886500
    },
    {
      "epoch": 9.384880452675986,
      "eval_loss": 0.28917041420936584,
      "eval_runtime": 46.9375,
      "eval_samples_per_second": 3577.736,
      "eval_steps_per_second": 447.233,
      "step": 886500
    },
    {
      "epoch": 9.38540977445599,
      "grad_norm": 1.2681365013122559,
      "learning_rate": 5.8077129952414376e-06,
      "loss": 0.4696,
      "step": 886550
    },
    {
      "epoch": 9.385939096235992,
      "grad_norm": 1.4018968343734741,
      "learning_rate": 5.797818422162176e-06,
      "loss": 0.471,
      "step": 886600
    },
    {
      "epoch": 9.386468418015996,
      "grad_norm": 1.4848763942718506,
      "learning_rate": 5.787932186055833e-06,
      "loss": 0.4644,
      "step": 886650
    },
    {
      "epoch": 9.386997739796,
      "grad_norm": 1.3221423625946045,
      "learning_rate": 5.778054287259915e-06,
      "loss": 0.4608,
      "step": 886700
    },
    {
      "epoch": 9.387527061576003,
      "grad_norm": 1.3780477046966553,
      "learning_rate": 5.76818472611168e-06,
      "loss": 0.4654,
      "step": 886750
    },
    {
      "epoch": 9.388056383356005,
      "grad_norm": 1.3435349464416504,
      "learning_rate": 5.758323502948027e-06,
      "loss": 0.484,
      "step": 886800
    },
    {
      "epoch": 9.388585705136009,
      "grad_norm": 1.2969504594802856,
      "learning_rate": 5.7484706181056555e-06,
      "loss": 0.4611,
      "step": 886850
    },
    {
      "epoch": 9.389115026916013,
      "grad_norm": 1.2141600847244263,
      "learning_rate": 5.73862607192091e-06,
      "loss": 0.4598,
      "step": 886900
    },
    {
      "epoch": 9.389644348696017,
      "grad_norm": 1.4006129503250122,
      "learning_rate": 5.728789864729911e-06,
      "loss": 0.4714,
      "step": 886950
    },
    {
      "epoch": 9.390173670476019,
      "grad_norm": 1.4339662790298462,
      "learning_rate": 5.718961996868416e-06,
      "loss": 0.4714,
      "step": 887000
    },
    {
      "epoch": 9.390173670476019,
      "eval_loss": 0.28912338614463806,
      "eval_runtime": 47.0854,
      "eval_samples_per_second": 3566.499,
      "eval_steps_per_second": 445.828,
      "step": 887000
    },
    {
      "epoch": 9.390702992256022,
      "grad_norm": 1.2709351778030396,
      "learning_rate": 5.709142468671991e-06,
      "loss": 0.4607,
      "step": 887050
    },
    {
      "epoch": 9.391232314036026,
      "grad_norm": 1.5324115753173828,
      "learning_rate": 5.699331280475811e-06,
      "loss": 0.4681,
      "step": 887100
    },
    {
      "epoch": 9.391761635816028,
      "grad_norm": 1.3867247104644775,
      "learning_rate": 5.6895284326149156e-06,
      "loss": 0.4663,
      "step": 887150
    },
    {
      "epoch": 9.392290957596032,
      "grad_norm": 1.458359956741333,
      "learning_rate": 5.679733925423869e-06,
      "loss": 0.4773,
      "step": 887200
    },
    {
      "epoch": 9.392820279376036,
      "grad_norm": 1.3319408893585205,
      "learning_rate": 5.669947759237154e-06,
      "loss": 0.4621,
      "step": 887250
    },
    {
      "epoch": 9.39334960115604,
      "grad_norm": 1.4799716472625732,
      "learning_rate": 5.660169934388781e-06,
      "loss": 0.4709,
      "step": 887300
    },
    {
      "epoch": 9.393878922936041,
      "grad_norm": 1.3273297548294067,
      "learning_rate": 5.650400451212622e-06,
      "loss": 0.4681,
      "step": 887350
    },
    {
      "epoch": 9.394408244716045,
      "grad_norm": 1.3428875207901,
      "learning_rate": 5.640639310042161e-06,
      "loss": 0.4592,
      "step": 887400
    },
    {
      "epoch": 9.394937566496049,
      "grad_norm": 1.439038872718811,
      "learning_rate": 5.630886511210659e-06,
      "loss": 0.4688,
      "step": 887450
    },
    {
      "epoch": 9.395466888276053,
      "grad_norm": 1.3054428100585938,
      "learning_rate": 5.62114205505107e-06,
      "loss": 0.459,
      "step": 887500
    },
    {
      "epoch": 9.395466888276053,
      "eval_loss": 0.2888801395893097,
      "eval_runtime": 46.9481,
      "eval_samples_per_second": 3576.932,
      "eval_steps_per_second": 447.132,
      "step": 887500
    },
    {
      "epoch": 9.395996210056055,
      "grad_norm": 1.5749331712722778,
      "learning_rate": 5.611405941896103e-06,
      "loss": 0.4648,
      "step": 887550
    },
    {
      "epoch": 9.396525531836058,
      "grad_norm": 1.3464765548706055,
      "learning_rate": 5.601678172078073e-06,
      "loss": 0.4756,
      "step": 887600
    },
    {
      "epoch": 9.397054853616062,
      "grad_norm": 1.4845082759857178,
      "learning_rate": 5.591958745929132e-06,
      "loss": 0.4676,
      "step": 887650
    },
    {
      "epoch": 9.397584175396066,
      "grad_norm": 1.3086884021759033,
      "learning_rate": 5.5822476637810706e-06,
      "loss": 0.4668,
      "step": 887700
    },
    {
      "epoch": 9.398113497176068,
      "grad_norm": 1.2077921628952026,
      "learning_rate": 5.5725449259654835e-06,
      "loss": 0.4684,
      "step": 887750
    },
    {
      "epoch": 9.398642818956072,
      "grad_norm": 1.1909072399139404,
      "learning_rate": 5.562850532813524e-06,
      "loss": 0.4738,
      "step": 887800
    },
    {
      "epoch": 9.399172140736075,
      "grad_norm": 1.4953291416168213,
      "learning_rate": 5.553164484656231e-06,
      "loss": 0.4675,
      "step": 887850
    },
    {
      "epoch": 9.399701462516077,
      "grad_norm": 1.377238154411316,
      "learning_rate": 5.5434867818242306e-06,
      "loss": 0.4703,
      "step": 887900
    },
    {
      "epoch": 9.400230784296081,
      "grad_norm": 1.3623790740966797,
      "learning_rate": 5.534010730001899e-06,
      "loss": 0.4679,
      "step": 887950
    },
    {
      "epoch": 9.400760106076085,
      "grad_norm": 1.3021904230117798,
      "learning_rate": 5.5243495518884915e-06,
      "loss": 0.4647,
      "step": 888000
    },
    {
      "epoch": 9.400760106076085,
      "eval_loss": 0.28890901803970337,
      "eval_runtime": 46.893,
      "eval_samples_per_second": 3581.133,
      "eval_steps_per_second": 447.658,
      "step": 888000
    },
    {
      "epoch": 9.401289427856089,
      "grad_norm": 1.3296639919281006,
      "learning_rate": 5.514696720084117e-06,
      "loss": 0.4666,
      "step": 888050
    },
    {
      "epoch": 9.40181874963609,
      "grad_norm": 1.3530136346817017,
      "learning_rate": 5.505052234918345e-06,
      "loss": 0.47,
      "step": 888100
    },
    {
      "epoch": 9.402348071416094,
      "grad_norm": 1.486966848373413,
      "learning_rate": 5.495416096720412e-06,
      "loss": 0.4681,
      "step": 888150
    },
    {
      "epoch": 9.402877393196098,
      "grad_norm": 1.4416561126708984,
      "learning_rate": 5.485788305819306e-06,
      "loss": 0.4628,
      "step": 888200
    },
    {
      "epoch": 9.403406714976102,
      "grad_norm": 1.401231288909912,
      "learning_rate": 5.476168862543734e-06,
      "loss": 0.4609,
      "step": 888250
    },
    {
      "epoch": 9.403936036756104,
      "grad_norm": 1.2976211309432983,
      "learning_rate": 5.466557767222074e-06,
      "loss": 0.4669,
      "step": 888300
    },
    {
      "epoch": 9.404465358536108,
      "grad_norm": 1.234801173210144,
      "learning_rate": 5.456955020182452e-06,
      "loss": 0.4667,
      "step": 888350
    },
    {
      "epoch": 9.404994680316111,
      "grad_norm": 1.2805746793746948,
      "learning_rate": 5.4473606217526895e-06,
      "loss": 0.4593,
      "step": 888400
    },
    {
      "epoch": 9.405524002096115,
      "grad_norm": 1.3771390914916992,
      "learning_rate": 5.437774572260356e-06,
      "loss": 0.4735,
      "step": 888450
    },
    {
      "epoch": 9.406053323876117,
      "grad_norm": 1.3978406190872192,
      "learning_rate": 5.4281968720326926e-06,
      "loss": 0.466,
      "step": 888500
    },
    {
      "epoch": 9.406053323876117,
      "eval_loss": 0.2889706790447235,
      "eval_runtime": 46.9826,
      "eval_samples_per_second": 3574.3,
      "eval_steps_per_second": 446.804,
      "step": 888500
    },
    {
      "epoch": 9.40658264565612,
      "grad_norm": 1.3096219301223755,
      "learning_rate": 5.418627521396713e-06,
      "loss": 0.4671,
      "step": 888550
    },
    {
      "epoch": 9.407111967436125,
      "grad_norm": 1.380897045135498,
      "learning_rate": 5.409066520679101e-06,
      "loss": 0.4686,
      "step": 888600
    },
    {
      "epoch": 9.407641289216127,
      "grad_norm": 1.4102191925048828,
      "learning_rate": 5.399513870206235e-06,
      "loss": 0.474,
      "step": 888650
    },
    {
      "epoch": 9.40817061099613,
      "grad_norm": 1.358652949333191,
      "learning_rate": 5.389969570304271e-06,
      "loss": 0.4596,
      "step": 888700
    },
    {
      "epoch": 9.408699932776134,
      "grad_norm": 1.4570667743682861,
      "learning_rate": 5.38043362129903e-06,
      "loss": 0.4697,
      "step": 888750
    },
    {
      "epoch": 9.409229254556138,
      "grad_norm": 1.4529963731765747,
      "learning_rate": 5.370906023516087e-06,
      "loss": 0.4616,
      "step": 888800
    },
    {
      "epoch": 9.40975857633614,
      "grad_norm": 1.4142581224441528,
      "learning_rate": 5.36138677728068e-06,
      "loss": 0.4798,
      "step": 888850
    },
    {
      "epoch": 9.410287898116144,
      "grad_norm": 1.432960033416748,
      "learning_rate": 5.351875882917828e-06,
      "loss": 0.4632,
      "step": 888900
    },
    {
      "epoch": 9.410817219896147,
      "grad_norm": 1.397854208946228,
      "learning_rate": 5.342373340752215e-06,
      "loss": 0.4688,
      "step": 888950
    },
    {
      "epoch": 9.411346541676151,
      "grad_norm": 1.1825275421142578,
      "learning_rate": 5.332879151108222e-06,
      "loss": 0.4626,
      "step": 889000
    },
    {
      "epoch": 9.411346541676151,
      "eval_loss": 0.2889291048049927,
      "eval_runtime": 46.6774,
      "eval_samples_per_second": 3597.676,
      "eval_steps_per_second": 449.726,
      "step": 889000
    },
    {
      "epoch": 9.411875863456153,
      "grad_norm": 1.4787644147872925,
      "learning_rate": 5.3233933143100325e-06,
      "loss": 0.4726,
      "step": 889050
    },
    {
      "epoch": 9.412405185236157,
      "grad_norm": 1.499703288078308,
      "learning_rate": 5.313915830681443e-06,
      "loss": 0.4587,
      "step": 889100
    },
    {
      "epoch": 9.41293450701616,
      "grad_norm": 1.4509471654891968,
      "learning_rate": 5.304446700546029e-06,
      "loss": 0.4785,
      "step": 889150
    },
    {
      "epoch": 9.413463828796164,
      "grad_norm": 1.4310635328292847,
      "learning_rate": 5.294985924227086e-06,
      "loss": 0.4654,
      "step": 889200
    },
    {
      "epoch": 9.413993150576166,
      "grad_norm": 1.2853487730026245,
      "learning_rate": 5.285533502047579e-06,
      "loss": 0.4669,
      "step": 889250
    },
    {
      "epoch": 9.41452247235617,
      "grad_norm": 1.4505500793457031,
      "learning_rate": 5.276089434330194e-06,
      "loss": 0.4595,
      "step": 889300
    },
    {
      "epoch": 9.415051794136174,
      "grad_norm": 1.4430986642837524,
      "learning_rate": 5.266653721397369e-06,
      "loss": 0.4656,
      "step": 889350
    },
    {
      "epoch": 9.415581115916176,
      "grad_norm": 1.3641937971115112,
      "learning_rate": 5.2572263635712325e-06,
      "loss": 0.4744,
      "step": 889400
    },
    {
      "epoch": 9.41611043769618,
      "grad_norm": 1.3609830141067505,
      "learning_rate": 5.24780736117364e-06,
      "loss": 0.4718,
      "step": 889450
    },
    {
      "epoch": 9.416639759476183,
      "grad_norm": 1.4121731519699097,
      "learning_rate": 5.238396714526139e-06,
      "loss": 0.4712,
      "step": 889500
    },
    {
      "epoch": 9.416639759476183,
      "eval_loss": 0.28898492455482483,
      "eval_runtime": 46.9181,
      "eval_samples_per_second": 3579.216,
      "eval_steps_per_second": 447.418,
      "step": 889500
    },
    {
      "epoch": 9.417169081256187,
      "grad_norm": 1.3876097202301025,
      "learning_rate": 5.228994423950001e-06,
      "loss": 0.4733,
      "step": 889550
    },
    {
      "epoch": 9.417698403036189,
      "grad_norm": 1.4742950201034546,
      "learning_rate": 5.219600489766247e-06,
      "loss": 0.4674,
      "step": 889600
    },
    {
      "epoch": 9.418227724816193,
      "grad_norm": 1.383133888244629,
      "learning_rate": 5.210214912295535e-06,
      "loss": 0.4703,
      "step": 889650
    },
    {
      "epoch": 9.418757046596197,
      "grad_norm": 1.2867000102996826,
      "learning_rate": 5.200837691858335e-06,
      "loss": 0.4656,
      "step": 889700
    },
    {
      "epoch": 9.4192863683762,
      "grad_norm": 1.509106159210205,
      "learning_rate": 5.191468828774748e-06,
      "loss": 0.4711,
      "step": 889750
    },
    {
      "epoch": 9.419815690156202,
      "grad_norm": 1.463895320892334,
      "learning_rate": 5.182108323364631e-06,
      "loss": 0.4768,
      "step": 889800
    },
    {
      "epoch": 9.420345011936206,
      "grad_norm": 1.3002780675888062,
      "learning_rate": 5.172756175947563e-06,
      "loss": 0.47,
      "step": 889850
    },
    {
      "epoch": 9.42087433371621,
      "grad_norm": 1.407442569732666,
      "learning_rate": 5.163412386842814e-06,
      "loss": 0.4644,
      "step": 889900
    },
    {
      "epoch": 9.421403655496214,
      "grad_norm": 1.4544422626495361,
      "learning_rate": 5.15407695636938e-06,
      "loss": 0.4625,
      "step": 889950
    },
    {
      "epoch": 9.421932977276215,
      "grad_norm": 1.279542326927185,
      "learning_rate": 5.144749884845923e-06,
      "loss": 0.4698,
      "step": 890000
    },
    {
      "epoch": 9.421932977276215,
      "eval_loss": 0.2889641225337982,
      "eval_runtime": 46.8676,
      "eval_samples_per_second": 3583.069,
      "eval_steps_per_second": 447.9,
      "step": 890000
    },
    {
      "epoch": 9.42246229905622,
      "grad_norm": 1.5807807445526123,
      "learning_rate": 5.1354311725909656e-06,
      "loss": 0.4743,
      "step": 890050
    },
    {
      "epoch": 9.422991620836223,
      "grad_norm": 1.5091431140899658,
      "learning_rate": 5.126120819922531e-06,
      "loss": 0.4726,
      "step": 890100
    },
    {
      "epoch": 9.423520942616225,
      "grad_norm": 1.3989062309265137,
      "learning_rate": 5.116818827158559e-06,
      "loss": 0.4655,
      "step": 890150
    },
    {
      "epoch": 9.424050264396229,
      "grad_norm": 1.4655718803405762,
      "learning_rate": 5.107525194616574e-06,
      "loss": 0.4712,
      "step": 890200
    },
    {
      "epoch": 9.424579586176232,
      "grad_norm": 1.296652913093567,
      "learning_rate": 5.098239922613879e-06,
      "loss": 0.4642,
      "step": 890250
    },
    {
      "epoch": 9.425108907956236,
      "grad_norm": 1.3588563203811646,
      "learning_rate": 5.08896301146744e-06,
      "loss": 0.4635,
      "step": 890300
    },
    {
      "epoch": 9.425638229736238,
      "grad_norm": 1.2436368465423584,
      "learning_rate": 5.079879750551936e-06,
      "loss": 0.4679,
      "step": 890350
    },
    {
      "epoch": 9.426167551516242,
      "grad_norm": 1.4886149168014526,
      "learning_rate": 5.070619394835025e-06,
      "loss": 0.4727,
      "step": 890400
    },
    {
      "epoch": 9.426696873296246,
      "grad_norm": 1.3204866647720337,
      "learning_rate": 5.06136740091731e-06,
      "loss": 0.4675,
      "step": 890450
    },
    {
      "epoch": 9.42722619507625,
      "grad_norm": 1.4962481260299683,
      "learning_rate": 5.052123769114708e-06,
      "loss": 0.4603,
      "step": 890500
    },
    {
      "epoch": 9.42722619507625,
      "eval_loss": 0.28895020484924316,
      "eval_runtime": 46.9372,
      "eval_samples_per_second": 3577.76,
      "eval_steps_per_second": 447.236,
      "step": 890500
    },
    {
      "epoch": 9.427755516856251,
      "grad_norm": 1.3103760480880737,
      "learning_rate": 5.042888499742742e-06,
      "loss": 0.4696,
      "step": 890550
    },
    {
      "epoch": 9.428284838636255,
      "grad_norm": 1.4647102355957031,
      "learning_rate": 5.0336615931167725e-06,
      "loss": 0.4682,
      "step": 890600
    },
    {
      "epoch": 9.428814160416259,
      "grad_norm": 1.4466416835784912,
      "learning_rate": 5.0244430495517135e-06,
      "loss": 0.4652,
      "step": 890650
    },
    {
      "epoch": 9.429343482196263,
      "grad_norm": 1.412766456604004,
      "learning_rate": 5.015232869362369e-06,
      "loss": 0.4706,
      "step": 890700
    },
    {
      "epoch": 9.429872803976265,
      "grad_norm": 1.3627691268920898,
      "learning_rate": 5.006031052863097e-06,
      "loss": 0.4684,
      "step": 890750
    },
    {
      "epoch": 9.430402125756268,
      "grad_norm": 1.354637622833252,
      "learning_rate": 4.996837600368093e-06,
      "loss": 0.4671,
      "step": 890800
    },
    {
      "epoch": 9.430931447536272,
      "grad_norm": 1.3855347633361816,
      "learning_rate": 4.9876525121911874e-06,
      "loss": 0.4678,
      "step": 890850
    },
    {
      "epoch": 9.431460769316274,
      "grad_norm": 1.2740817070007324,
      "learning_rate": 4.978475788645992e-06,
      "loss": 0.466,
      "step": 890900
    },
    {
      "epoch": 9.431990091096278,
      "grad_norm": 1.4950350522994995,
      "learning_rate": 4.969307430045727e-06,
      "loss": 0.4715,
      "step": 890950
    },
    {
      "epoch": 9.432519412876282,
      "grad_norm": 1.2276579141616821,
      "learning_rate": 4.960147436703505e-06,
      "loss": 0.4699,
      "step": 891000
    },
    {
      "epoch": 9.432519412876282,
      "eval_loss": 0.2888439893722534,
      "eval_runtime": 46.8298,
      "eval_samples_per_second": 3585.966,
      "eval_steps_per_second": 448.262,
      "step": 891000
    },
    {
      "epoch": 9.433048734656285,
      "grad_norm": 1.3239363431930542,
      "learning_rate": 4.950995808931935e-06,
      "loss": 0.4651,
      "step": 891050
    },
    {
      "epoch": 9.433578056436287,
      "grad_norm": 1.451482892036438,
      "learning_rate": 4.941852547043518e-06,
      "loss": 0.4649,
      "step": 891100
    },
    {
      "epoch": 9.434107378216291,
      "grad_norm": 1.3543241024017334,
      "learning_rate": 4.932717651350366e-06,
      "loss": 0.4713,
      "step": 891150
    },
    {
      "epoch": 9.434636699996295,
      "grad_norm": 1.3302438259124756,
      "learning_rate": 4.923591122164395e-06,
      "loss": 0.4599,
      "step": 891200
    },
    {
      "epoch": 9.435166021776299,
      "grad_norm": 1.427048683166504,
      "learning_rate": 4.914472959797106e-06,
      "loss": 0.467,
      "step": 891250
    },
    {
      "epoch": 9.4356953435563,
      "grad_norm": 1.3010364770889282,
      "learning_rate": 4.905363164559862e-06,
      "loss": 0.466,
      "step": 891300
    },
    {
      "epoch": 9.436224665336304,
      "grad_norm": 1.5017765760421753,
      "learning_rate": 4.896261736763607e-06,
      "loss": 0.4673,
      "step": 891350
    },
    {
      "epoch": 9.436753987116308,
      "grad_norm": 1.4774364233016968,
      "learning_rate": 4.887168676719094e-06,
      "loss": 0.4643,
      "step": 891400
    },
    {
      "epoch": 9.437283308896312,
      "grad_norm": 1.280751347541809,
      "learning_rate": 4.878083984736742e-06,
      "loss": 0.4621,
      "step": 891450
    },
    {
      "epoch": 9.437812630676314,
      "grad_norm": 1.3732355833053589,
      "learning_rate": 4.869007661126745e-06,
      "loss": 0.4596,
      "step": 891500
    },
    {
      "epoch": 9.437812630676314,
      "eval_loss": 0.2887277901172638,
      "eval_runtime": 46.9458,
      "eval_samples_per_second": 3577.104,
      "eval_steps_per_second": 447.154,
      "step": 891500
    },
    {
      "epoch": 9.438341952456318,
      "grad_norm": 1.3558077812194824,
      "learning_rate": 4.859939706198885e-06,
      "loss": 0.4771,
      "step": 891550
    },
    {
      "epoch": 9.438871274236321,
      "grad_norm": 1.498066782951355,
      "learning_rate": 4.850880120262774e-06,
      "loss": 0.4726,
      "step": 891600
    },
    {
      "epoch": 9.439400596016323,
      "grad_norm": 1.399423360824585,
      "learning_rate": 4.841828903627748e-06,
      "loss": 0.4719,
      "step": 891650
    },
    {
      "epoch": 9.439929917796327,
      "grad_norm": 1.332231879234314,
      "learning_rate": 4.832786056602728e-06,
      "loss": 0.4613,
      "step": 891700
    },
    {
      "epoch": 9.440459239576331,
      "grad_norm": 1.3467390537261963,
      "learning_rate": 4.8237515794965215e-06,
      "loss": 0.4587,
      "step": 891750
    },
    {
      "epoch": 9.440988561356335,
      "grad_norm": 1.3916094303131104,
      "learning_rate": 4.814725472617493e-06,
      "loss": 0.4661,
      "step": 891800
    },
    {
      "epoch": 9.441517883136337,
      "grad_norm": 1.1328226327896118,
      "learning_rate": 4.80570773627384e-06,
      "loss": 0.4715,
      "step": 891850
    },
    {
      "epoch": 9.44204720491634,
      "grad_norm": 1.270806074142456,
      "learning_rate": 4.7966983707734e-06,
      "loss": 0.4738,
      "step": 891900
    },
    {
      "epoch": 9.442576526696344,
      "grad_norm": 1.4045817852020264,
      "learning_rate": 4.787697376423733e-06,
      "loss": 0.47,
      "step": 891950
    },
    {
      "epoch": 9.443105848476348,
      "grad_norm": 1.225941777229309,
      "learning_rate": 4.778704753532176e-06,
      "loss": 0.4648,
      "step": 892000
    },
    {
      "epoch": 9.443105848476348,
      "eval_loss": 0.288818895816803,
      "eval_runtime": 46.8036,
      "eval_samples_per_second": 3587.973,
      "eval_steps_per_second": 448.513,
      "step": 892000
    },
    {
      "epoch": 9.44363517025635,
      "grad_norm": 1.4547390937805176,
      "learning_rate": 4.769720502405677e-06,
      "loss": 0.4573,
      "step": 892050
    },
    {
      "epoch": 9.444164492036354,
      "grad_norm": 1.4889277219772339,
      "learning_rate": 4.760744623350993e-06,
      "loss": 0.4689,
      "step": 892100
    },
    {
      "epoch": 9.444693813816357,
      "grad_norm": 1.2863729000091553,
      "learning_rate": 4.7517771166745436e-06,
      "loss": 0.474,
      "step": 892150
    },
    {
      "epoch": 9.445223135596361,
      "grad_norm": 1.2914413213729858,
      "learning_rate": 4.742817982682501e-06,
      "loss": 0.4721,
      "step": 892200
    },
    {
      "epoch": 9.445752457376363,
      "grad_norm": 1.4833906888961792,
      "learning_rate": 4.733867221680705e-06,
      "loss": 0.4716,
      "step": 892250
    },
    {
      "epoch": 9.446281779156367,
      "grad_norm": 1.3687529563903809,
      "learning_rate": 4.724924833974742e-06,
      "loss": 0.4727,
      "step": 892300
    },
    {
      "epoch": 9.44681110093637,
      "grad_norm": 1.467297911643982,
      "learning_rate": 4.715990819869842e-06,
      "loss": 0.4631,
      "step": 892350
    },
    {
      "epoch": 9.447340422716373,
      "grad_norm": 1.3510479927062988,
      "learning_rate": 4.707065179671121e-06,
      "loss": 0.4588,
      "step": 892400
    },
    {
      "epoch": 9.447869744496376,
      "grad_norm": 1.4186019897460938,
      "learning_rate": 4.698147913683199e-06,
      "loss": 0.4724,
      "step": 892450
    },
    {
      "epoch": 9.44839906627638,
      "grad_norm": 1.4335954189300537,
      "learning_rate": 4.689239022210551e-06,
      "loss": 0.4799,
      "step": 892500
    },
    {
      "epoch": 9.44839906627638,
      "eval_loss": 0.2888532876968384,
      "eval_runtime": 46.8744,
      "eval_samples_per_second": 3582.553,
      "eval_steps_per_second": 447.835,
      "step": 892500
    },
    {
      "epoch": 9.448928388056384,
      "grad_norm": 1.386871337890625,
      "learning_rate": 4.680338505557324e-06,
      "loss": 0.4714,
      "step": 892550
    },
    {
      "epoch": 9.449457709836386,
      "grad_norm": 1.5437819957733154,
      "learning_rate": 4.671446364027387e-06,
      "loss": 0.4632,
      "step": 892600
    },
    {
      "epoch": 9.44998703161639,
      "grad_norm": 1.4703916311264038,
      "learning_rate": 4.6625625979242745e-06,
      "loss": 0.4721,
      "step": 892650
    },
    {
      "epoch": 9.450516353396393,
      "grad_norm": 1.2698653936386108,
      "learning_rate": 4.653687207551327e-06,
      "loss": 0.465,
      "step": 892700
    },
    {
      "epoch": 9.451045675176397,
      "grad_norm": 1.3138071298599243,
      "learning_rate": 4.644820193211468e-06,
      "loss": 0.4665,
      "step": 892750
    },
    {
      "epoch": 9.4515749969564,
      "grad_norm": 1.371949315071106,
      "learning_rate": 4.635961555207513e-06,
      "loss": 0.4619,
      "step": 892800
    },
    {
      "epoch": 9.452104318736403,
      "grad_norm": 1.5492420196533203,
      "learning_rate": 4.627111293841829e-06,
      "loss": 0.4639,
      "step": 892850
    },
    {
      "epoch": 9.452633640516407,
      "grad_norm": 1.2970935106277466,
      "learning_rate": 4.618269409416593e-06,
      "loss": 0.4638,
      "step": 892900
    },
    {
      "epoch": 9.45316296229641,
      "grad_norm": 1.5519518852233887,
      "learning_rate": 4.609435902233616e-06,
      "loss": 0.4716,
      "step": 892950
    },
    {
      "epoch": 9.453692284076412,
      "grad_norm": 1.3877296447753906,
      "learning_rate": 4.600610772594549e-06,
      "loss": 0.4605,
      "step": 893000
    },
    {
      "epoch": 9.453692284076412,
      "eval_loss": 0.28869152069091797,
      "eval_runtime": 46.8788,
      "eval_samples_per_second": 3582.216,
      "eval_steps_per_second": 447.793,
      "step": 893000
    },
    {
      "epoch": 9.454221605856416,
      "grad_norm": 1.466609239578247,
      "learning_rate": 4.591794020800594e-06,
      "loss": 0.4683,
      "step": 893050
    },
    {
      "epoch": 9.45475092763642,
      "grad_norm": 1.3250246047973633,
      "learning_rate": 4.582985647152815e-06,
      "loss": 0.4641,
      "step": 893100
    },
    {
      "epoch": 9.455280249416422,
      "grad_norm": 1.4457449913024902,
      "learning_rate": 4.57418565195189e-06,
      "loss": 0.4653,
      "step": 893150
    },
    {
      "epoch": 9.455809571196426,
      "grad_norm": 1.2142152786254883,
      "learning_rate": 4.565394035498271e-06,
      "loss": 0.4631,
      "step": 893200
    },
    {
      "epoch": 9.45633889297643,
      "grad_norm": 1.390732765197754,
      "learning_rate": 4.556610798092053e-06,
      "loss": 0.4621,
      "step": 893250
    },
    {
      "epoch": 9.456868214756433,
      "grad_norm": 1.2617427110671997,
      "learning_rate": 4.5478359400331345e-06,
      "loss": 0.4693,
      "step": 893300
    },
    {
      "epoch": 9.457397536536435,
      "grad_norm": 1.3831933736801147,
      "learning_rate": 4.539069461621109e-06,
      "loss": 0.4655,
      "step": 893350
    },
    {
      "epoch": 9.457926858316439,
      "grad_norm": 1.4543933868408203,
      "learning_rate": 4.53031136315521e-06,
      "loss": 0.4649,
      "step": 893400
    },
    {
      "epoch": 9.458456180096443,
      "grad_norm": 1.4062573909759521,
      "learning_rate": 4.521736557170558e-06,
      "loss": 0.4632,
      "step": 893450
    },
    {
      "epoch": 9.458985501876446,
      "grad_norm": 1.3094583749771118,
      "learning_rate": 4.5129950518798815e-06,
      "loss": 0.4659,
      "step": 893500
    },
    {
      "epoch": 9.458985501876446,
      "eval_loss": 0.2885408401489258,
      "eval_runtime": 46.8472,
      "eval_samples_per_second": 3584.633,
      "eval_steps_per_second": 448.095,
      "step": 893500
    },
    {
      "epoch": 9.459514823656448,
      "grad_norm": 1.353718876838684,
      "learning_rate": 4.504261927425507e-06,
      "loss": 0.4662,
      "step": 893550
    },
    {
      "epoch": 9.460044145436452,
      "grad_norm": 1.349187970161438,
      "learning_rate": 4.495537184105614e-06,
      "loss": 0.4692,
      "step": 893600
    },
    {
      "epoch": 9.460573467216456,
      "grad_norm": 1.500012755393982,
      "learning_rate": 4.486820822218018e-06,
      "loss": 0.468,
      "step": 893650
    },
    {
      "epoch": 9.46110278899646,
      "grad_norm": 1.405309796333313,
      "learning_rate": 4.4781128420603724e-06,
      "loss": 0.4596,
      "step": 893700
    },
    {
      "epoch": 9.461632110776462,
      "grad_norm": 1.4443639516830444,
      "learning_rate": 4.469413243929854e-06,
      "loss": 0.4678,
      "step": 893750
    },
    {
      "epoch": 9.462161432556465,
      "grad_norm": 1.360046148300171,
      "learning_rate": 4.4607220281235594e-06,
      "loss": 0.4636,
      "step": 893800
    },
    {
      "epoch": 9.46269075433647,
      "grad_norm": 1.2481255531311035,
      "learning_rate": 4.45203919493814e-06,
      "loss": 0.4655,
      "step": 893850
    },
    {
      "epoch": 9.463220076116471,
      "grad_norm": 1.3798446655273438,
      "learning_rate": 4.443364744670053e-06,
      "loss": 0.4672,
      "step": 893900
    },
    {
      "epoch": 9.463749397896475,
      "grad_norm": 1.3562350273132324,
      "learning_rate": 4.434698677615451e-06,
      "loss": 0.4658,
      "step": 893950
    },
    {
      "epoch": 9.464278719676479,
      "grad_norm": 1.4547910690307617,
      "learning_rate": 4.42604099407018e-06,
      "loss": 0.4642,
      "step": 894000
    },
    {
      "epoch": 9.464278719676479,
      "eval_loss": 0.28859198093414307,
      "eval_runtime": 46.9211,
      "eval_samples_per_second": 3578.987,
      "eval_steps_per_second": 447.389,
      "step": 894000
    },
    {
      "epoch": 9.464808041456482,
      "grad_norm": 1.407768726348877,
      "learning_rate": 4.417391694329781e-06,
      "loss": 0.4707,
      "step": 894050
    },
    {
      "epoch": 9.465337363236484,
      "grad_norm": 1.3349846601486206,
      "learning_rate": 4.408750778689602e-06,
      "loss": 0.4679,
      "step": 894100
    },
    {
      "epoch": 9.465866685016488,
      "grad_norm": 1.2657626867294312,
      "learning_rate": 4.400118247444573e-06,
      "loss": 0.4583,
      "step": 894150
    },
    {
      "epoch": 9.466396006796492,
      "grad_norm": 1.3581268787384033,
      "learning_rate": 4.3914941008894596e-06,
      "loss": 0.467,
      "step": 894200
    },
    {
      "epoch": 9.466925328576496,
      "grad_norm": 1.258065938949585,
      "learning_rate": 4.382878339318663e-06,
      "loss": 0.4734,
      "step": 894250
    },
    {
      "epoch": 9.467454650356498,
      "grad_norm": 1.277470588684082,
      "learning_rate": 4.374270963026311e-06,
      "loss": 0.4684,
      "step": 894300
    },
    {
      "epoch": 9.467983972136501,
      "grad_norm": 1.4890729188919067,
      "learning_rate": 4.365671972306251e-06,
      "loss": 0.4647,
      "step": 894350
    },
    {
      "epoch": 9.468513293916505,
      "grad_norm": 1.4390393495559692,
      "learning_rate": 4.357081367452109e-06,
      "loss": 0.4665,
      "step": 894400
    },
    {
      "epoch": 9.469042615696509,
      "grad_norm": 1.4959510564804077,
      "learning_rate": 4.348499148757096e-06,
      "loss": 0.4648,
      "step": 894450
    },
    {
      "epoch": 9.46957193747651,
      "grad_norm": 1.4266341924667358,
      "learning_rate": 4.339925316514226e-06,
      "loss": 0.4662,
      "step": 894500
    },
    {
      "epoch": 9.46957193747651,
      "eval_loss": 0.28865325450897217,
      "eval_runtime": 46.9036,
      "eval_samples_per_second": 3580.326,
      "eval_steps_per_second": 447.557,
      "step": 894500
    },
    {
      "epoch": 9.470101259256515,
      "grad_norm": 1.4791178703308105,
      "learning_rate": 4.331359871016211e-06,
      "loss": 0.4533,
      "step": 894550
    },
    {
      "epoch": 9.470630581036518,
      "grad_norm": 1.344668984413147,
      "learning_rate": 4.32280281255551e-06,
      "loss": 0.4656,
      "step": 894600
    },
    {
      "epoch": 9.47115990281652,
      "grad_norm": 1.3541470766067505,
      "learning_rate": 4.314254141424168e-06,
      "loss": 0.4641,
      "step": 894650
    },
    {
      "epoch": 9.471689224596524,
      "grad_norm": 1.4041048288345337,
      "learning_rate": 4.305713857914145e-06,
      "loss": 0.4722,
      "step": 894700
    },
    {
      "epoch": 9.472218546376528,
      "grad_norm": 1.509482502937317,
      "learning_rate": 4.2971819623169035e-06,
      "loss": 0.4687,
      "step": 894750
    },
    {
      "epoch": 9.472747868156532,
      "grad_norm": 1.3577419519424438,
      "learning_rate": 4.288658454923766e-06,
      "loss": 0.4647,
      "step": 894800
    },
    {
      "epoch": 9.473277189936534,
      "grad_norm": 1.314995288848877,
      "learning_rate": 4.280143336025721e-06,
      "loss": 0.4614,
      "step": 894850
    },
    {
      "epoch": 9.473806511716537,
      "grad_norm": 1.3671860694885254,
      "learning_rate": 4.2716366059134814e-06,
      "loss": 0.4623,
      "step": 894900
    },
    {
      "epoch": 9.474335833496541,
      "grad_norm": 1.4001240730285645,
      "learning_rate": 4.263138264877425e-06,
      "loss": 0.4729,
      "step": 894950
    },
    {
      "epoch": 9.474865155276545,
      "grad_norm": 1.2751893997192383,
      "learning_rate": 4.2546483132077375e-06,
      "loss": 0.4628,
      "step": 895000
    },
    {
      "epoch": 9.474865155276545,
      "eval_loss": 0.2885477542877197,
      "eval_runtime": 46.9572,
      "eval_samples_per_second": 3576.232,
      "eval_steps_per_second": 447.045,
      "step": 895000
    },
    {
      "epoch": 9.475394477056547,
      "grad_norm": 1.4382519721984863,
      "learning_rate": 4.246166751194186e-06,
      "loss": 0.4683,
      "step": 895050
    },
    {
      "epoch": 9.47592379883655,
      "grad_norm": 1.4974607229232788,
      "learning_rate": 4.237693579126428e-06,
      "loss": 0.4615,
      "step": 895100
    },
    {
      "epoch": 9.476453120616554,
      "grad_norm": 1.3755429983139038,
      "learning_rate": 4.229228797293622e-06,
      "loss": 0.4725,
      "step": 895150
    },
    {
      "epoch": 9.476982442396558,
      "grad_norm": 1.2448948621749878,
      "learning_rate": 4.220772405984868e-06,
      "loss": 0.4657,
      "step": 895200
    },
    {
      "epoch": 9.47751176417656,
      "grad_norm": 1.4404181241989136,
      "learning_rate": 4.212324405488771e-06,
      "loss": 0.4668,
      "step": 895250
    },
    {
      "epoch": 9.478041085956564,
      "grad_norm": 1.2953522205352783,
      "learning_rate": 4.203884796093793e-06,
      "loss": 0.4691,
      "step": 895300
    },
    {
      "epoch": 9.478570407736568,
      "grad_norm": 1.4674201011657715,
      "learning_rate": 4.195453578088038e-06,
      "loss": 0.4701,
      "step": 895350
    },
    {
      "epoch": 9.47909972951657,
      "grad_norm": 1.6023370027542114,
      "learning_rate": 4.1870307517593576e-06,
      "loss": 0.4684,
      "step": 895400
    },
    {
      "epoch": 9.479629051296573,
      "grad_norm": 1.3140876293182373,
      "learning_rate": 4.178616317395301e-06,
      "loss": 0.4573,
      "step": 895450
    },
    {
      "epoch": 9.480158373076577,
      "grad_norm": 1.2727352380752563,
      "learning_rate": 4.170378313879425e-06,
      "loss": 0.4691,
      "step": 895500
    },
    {
      "epoch": 9.480158373076577,
      "eval_loss": 0.2886589765548706,
      "eval_runtime": 46.8597,
      "eval_samples_per_second": 3583.68,
      "eval_steps_per_second": 447.976,
      "step": 895500
    },
    {
      "epoch": 9.48068769485658,
      "grad_norm": 1.4321138858795166,
      "learning_rate": 4.161980496452555e-06,
      "loss": 0.4668,
      "step": 895550
    },
    {
      "epoch": 9.481217016636583,
      "grad_norm": 1.4640194177627563,
      "learning_rate": 4.153591071845458e-06,
      "loss": 0.4702,
      "step": 895600
    },
    {
      "epoch": 9.481746338416587,
      "grad_norm": 1.3207279443740845,
      "learning_rate": 4.145210040344627e-06,
      "loss": 0.4666,
      "step": 895650
    },
    {
      "epoch": 9.48227566019659,
      "grad_norm": 1.4853209257125854,
      "learning_rate": 4.136837402236165e-06,
      "loss": 0.4648,
      "step": 895700
    },
    {
      "epoch": 9.482804981976594,
      "grad_norm": 1.3513506650924683,
      "learning_rate": 4.128473157805901e-06,
      "loss": 0.4682,
      "step": 895750
    },
    {
      "epoch": 9.483334303756596,
      "grad_norm": 1.4552466869354248,
      "learning_rate": 4.120117307339382e-06,
      "loss": 0.4693,
      "step": 895800
    },
    {
      "epoch": 9.4838636255366,
      "grad_norm": 1.3578295707702637,
      "learning_rate": 4.11176985112191e-06,
      "loss": 0.4718,
      "step": 895850
    },
    {
      "epoch": 9.484392947316604,
      "grad_norm": 1.4643735885620117,
      "learning_rate": 4.103430789438423e-06,
      "loss": 0.4683,
      "step": 895900
    },
    {
      "epoch": 9.484922269096607,
      "grad_norm": 1.3115992546081543,
      "learning_rate": 4.095100122573608e-06,
      "loss": 0.4722,
      "step": 895950
    },
    {
      "epoch": 9.48545159087661,
      "grad_norm": 1.4998475313186646,
      "learning_rate": 4.086777850811935e-06,
      "loss": 0.4708,
      "step": 896000
    },
    {
      "epoch": 9.48545159087661,
      "eval_loss": 0.2885579764842987,
      "eval_runtime": 46.7541,
      "eval_samples_per_second": 3591.77,
      "eval_steps_per_second": 448.987,
      "step": 896000
    },
    {
      "epoch": 9.485980912656613,
      "grad_norm": 1.4662245512008667,
      "learning_rate": 4.078463974437452e-06,
      "loss": 0.4621,
      "step": 896050
    },
    {
      "epoch": 9.486510234436617,
      "grad_norm": 1.6219607591629028,
      "learning_rate": 4.070158493734016e-06,
      "loss": 0.4756,
      "step": 896100
    },
    {
      "epoch": 9.487039556216619,
      "grad_norm": 1.231892704963684,
      "learning_rate": 4.061861408985179e-06,
      "loss": 0.466,
      "step": 896150
    },
    {
      "epoch": 9.487568877996623,
      "grad_norm": 1.3763600587844849,
      "learning_rate": 4.053572720474214e-06,
      "loss": 0.4626,
      "step": 896200
    },
    {
      "epoch": 9.488098199776626,
      "grad_norm": 1.3252662420272827,
      "learning_rate": 4.045292428484088e-06,
      "loss": 0.4663,
      "step": 896250
    },
    {
      "epoch": 9.48862752155663,
      "grad_norm": 1.4845298528671265,
      "learning_rate": 4.037020533297436e-06,
      "loss": 0.4711,
      "step": 896300
    },
    {
      "epoch": 9.489156843336632,
      "grad_norm": 1.470913052558899,
      "learning_rate": 4.028757035196728e-06,
      "loss": 0.4616,
      "step": 896350
    },
    {
      "epoch": 9.489686165116636,
      "grad_norm": 1.4173803329467773,
      "learning_rate": 4.020501934464044e-06,
      "loss": 0.471,
      "step": 896400
    },
    {
      "epoch": 9.49021548689664,
      "grad_norm": 1.331247329711914,
      "learning_rate": 4.012255231381212e-06,
      "loss": 0.4643,
      "step": 896450
    },
    {
      "epoch": 9.490744808676643,
      "grad_norm": 1.368007779121399,
      "learning_rate": 4.0040169262297584e-06,
      "loss": 0.4669,
      "step": 896500
    },
    {
      "epoch": 9.490744808676643,
      "eval_loss": 0.28854382038116455,
      "eval_runtime": 46.8445,
      "eval_samples_per_second": 3584.842,
      "eval_steps_per_second": 448.121,
      "step": 896500
    },
    {
      "epoch": 9.491274130456645,
      "grad_norm": 1.4229270219802856,
      "learning_rate": 3.995787019290986e-06,
      "loss": 0.4695,
      "step": 896550
    },
    {
      "epoch": 9.491803452236649,
      "grad_norm": 1.4181134700775146,
      "learning_rate": 3.987565510845781e-06,
      "loss": 0.4643,
      "step": 896600
    },
    {
      "epoch": 9.492332774016653,
      "grad_norm": 1.2887380123138428,
      "learning_rate": 3.97935240117489e-06,
      "loss": 0.4741,
      "step": 896650
    },
    {
      "epoch": 9.492862095796657,
      "grad_norm": 1.4592647552490234,
      "learning_rate": 3.971147690558674e-06,
      "loss": 0.4707,
      "step": 896700
    },
    {
      "epoch": 9.493391417576658,
      "grad_norm": 1.523349642753601,
      "learning_rate": 3.9629513792772685e-06,
      "loss": 0.4673,
      "step": 896750
    },
    {
      "epoch": 9.493920739356662,
      "grad_norm": 1.5319876670837402,
      "learning_rate": 3.95476346761045e-06,
      "loss": 0.4779,
      "step": 896800
    },
    {
      "epoch": 9.494450061136666,
      "grad_norm": 1.247391700744629,
      "learning_rate": 3.946583955837801e-06,
      "loss": 0.473,
      "step": 896850
    },
    {
      "epoch": 9.494979382916668,
      "grad_norm": 1.2597529888153076,
      "learning_rate": 3.938412844238515e-06,
      "loss": 0.4627,
      "step": 896900
    },
    {
      "epoch": 9.495508704696672,
      "grad_norm": 1.3784849643707275,
      "learning_rate": 3.930250133091562e-06,
      "loss": 0.4642,
      "step": 896950
    },
    {
      "epoch": 9.496038026476675,
      "grad_norm": 1.3503634929656982,
      "learning_rate": 3.922095822675636e-06,
      "loss": 0.4724,
      "step": 897000
    },
    {
      "epoch": 9.496038026476675,
      "eval_loss": 0.28862062096595764,
      "eval_runtime": 46.8423,
      "eval_samples_per_second": 3585.004,
      "eval_steps_per_second": 448.142,
      "step": 897000
    },
    {
      "epoch": 9.49656734825668,
      "grad_norm": 1.5009196996688843,
      "learning_rate": 3.913949913269127e-06,
      "loss": 0.4753,
      "step": 897050
    },
    {
      "epoch": 9.497096670036681,
      "grad_norm": 1.2972934246063232,
      "learning_rate": 3.905812405150116e-06,
      "loss": 0.4688,
      "step": 897100
    },
    {
      "epoch": 9.497625991816685,
      "grad_norm": 1.3584105968475342,
      "learning_rate": 3.8976832985964105e-06,
      "loss": 0.4618,
      "step": 897150
    },
    {
      "epoch": 9.498155313596689,
      "grad_norm": 1.4267770051956177,
      "learning_rate": 3.8895625938855375e-06,
      "loss": 0.4721,
      "step": 897200
    },
    {
      "epoch": 9.498684635376692,
      "grad_norm": 1.257444977760315,
      "learning_rate": 3.8814502912947465e-06,
      "loss": 0.4661,
      "step": 897250
    },
    {
      "epoch": 9.499213957156694,
      "grad_norm": 1.451363444328308,
      "learning_rate": 3.873346391100957e-06,
      "loss": 0.4653,
      "step": 897300
    },
    {
      "epoch": 9.499743278936698,
      "grad_norm": 1.4827085733413696,
      "learning_rate": 3.865250893580891e-06,
      "loss": 0.4713,
      "step": 897350
    },
    {
      "epoch": 9.500272600716702,
      "grad_norm": 1.4516887664794922,
      "learning_rate": 3.8571637990108824e-06,
      "loss": 0.4586,
      "step": 897400
    },
    {
      "epoch": 9.500801922496706,
      "grad_norm": 1.2693582773208618,
      "learning_rate": 3.849085107667016e-06,
      "loss": 0.4655,
      "step": 897450
    },
    {
      "epoch": 9.501331244276708,
      "grad_norm": 1.4604449272155762,
      "learning_rate": 3.8410148198251285e-06,
      "loss": 0.4719,
      "step": 897500
    },
    {
      "epoch": 9.501331244276708,
      "eval_loss": 0.28849950432777405,
      "eval_runtime": 46.9639,
      "eval_samples_per_second": 3575.726,
      "eval_steps_per_second": 446.982,
      "step": 897500
    },
    {
      "epoch": 9.501860566056711,
      "grad_norm": 1.423854947090149,
      "learning_rate": 3.832952935760692e-06,
      "loss": 0.4653,
      "step": 897550
    },
    {
      "epoch": 9.502389887836715,
      "grad_norm": 1.3236631155014038,
      "learning_rate": 3.824899455748987e-06,
      "loss": 0.4585,
      "step": 897600
    },
    {
      "epoch": 9.502919209616717,
      "grad_norm": 1.4591840505599976,
      "learning_rate": 3.816854380064933e-06,
      "loss": 0.4586,
      "step": 897650
    },
    {
      "epoch": 9.503448531396721,
      "grad_norm": 1.3410778045654297,
      "learning_rate": 3.808817708983198e-06,
      "loss": 0.4735,
      "step": 897700
    },
    {
      "epoch": 9.503977853176725,
      "grad_norm": 1.4650378227233887,
      "learning_rate": 3.800789442778091e-06,
      "loss": 0.4686,
      "step": 897750
    },
    {
      "epoch": 9.504507174956728,
      "grad_norm": 1.4457265138626099,
      "learning_rate": 3.7927695817237816e-06,
      "loss": 0.4653,
      "step": 897800
    },
    {
      "epoch": 9.50503649673673,
      "grad_norm": 1.3858065605163574,
      "learning_rate": 3.7847581260940233e-06,
      "loss": 0.4584,
      "step": 897850
    },
    {
      "epoch": 9.505565818516734,
      "grad_norm": 1.548201322555542,
      "learning_rate": 3.7767550761622916e-06,
      "loss": 0.4699,
      "step": 897900
    },
    {
      "epoch": 9.506095140296738,
      "grad_norm": 1.3006937503814697,
      "learning_rate": 3.7687604322018952e-06,
      "loss": 0.4612,
      "step": 897950
    },
    {
      "epoch": 9.506624462076742,
      "grad_norm": 1.4298490285873413,
      "learning_rate": 3.76093383685705e-06,
      "loss": 0.4704,
      "step": 898000
    },
    {
      "epoch": 9.506624462076742,
      "eval_loss": 0.2885008156299591,
      "eval_runtime": 46.8847,
      "eval_samples_per_second": 3581.765,
      "eval_steps_per_second": 447.737,
      "step": 898000
    },
    {
      "epoch": 9.507153783856744,
      "grad_norm": 1.524171233177185,
      "learning_rate": 3.752955837524691e-06,
      "loss": 0.4655,
      "step": 898050
    },
    {
      "epoch": 9.507683105636747,
      "grad_norm": 1.361804485321045,
      "learning_rate": 3.7449862449761007e-06,
      "loss": 0.4659,
      "step": 898100
    },
    {
      "epoch": 9.508212427416751,
      "grad_norm": 1.4172453880310059,
      "learning_rate": 3.7370250594833953e-06,
      "loss": 0.4652,
      "step": 898150
    },
    {
      "epoch": 9.508741749196755,
      "grad_norm": 1.4418270587921143,
      "learning_rate": 3.72907228131833e-06,
      "loss": 0.4682,
      "step": 898200
    },
    {
      "epoch": 9.509271070976757,
      "grad_norm": 1.4446704387664795,
      "learning_rate": 3.721127910752409e-06,
      "loss": 0.4673,
      "step": 898250
    },
    {
      "epoch": 9.50980039275676,
      "grad_norm": 1.3391703367233276,
      "learning_rate": 3.7131919480568875e-06,
      "loss": 0.4746,
      "step": 898300
    },
    {
      "epoch": 9.510329714536764,
      "grad_norm": 1.5534923076629639,
      "learning_rate": 3.705264393502633e-06,
      "loss": 0.4703,
      "step": 898350
    },
    {
      "epoch": 9.510859036316766,
      "grad_norm": 1.2789586782455444,
      "learning_rate": 3.697345247360373e-06,
      "loss": 0.4672,
      "step": 898400
    },
    {
      "epoch": 9.51138835809677,
      "grad_norm": 1.3969148397445679,
      "learning_rate": 3.6894345099003913e-06,
      "loss": 0.4701,
      "step": 898450
    },
    {
      "epoch": 9.511917679876774,
      "grad_norm": 1.5237619876861572,
      "learning_rate": 3.681532181392777e-06,
      "loss": 0.4667,
      "step": 898500
    },
    {
      "epoch": 9.511917679876774,
      "eval_loss": 0.2883928716182709,
      "eval_runtime": 46.9967,
      "eval_samples_per_second": 3573.232,
      "eval_steps_per_second": 446.67,
      "step": 898500
    },
    {
      "epoch": 9.512447001656778,
      "grad_norm": 1.473502278327942,
      "learning_rate": 3.673638262107315e-06,
      "loss": 0.475,
      "step": 898550
    },
    {
      "epoch": 9.51297632343678,
      "grad_norm": 1.415913462638855,
      "learning_rate": 3.6657527523135392e-06,
      "loss": 0.4692,
      "step": 898600
    },
    {
      "epoch": 9.513505645216783,
      "grad_norm": 1.378836989402771,
      "learning_rate": 3.6578756522805957e-06,
      "loss": 0.4728,
      "step": 898650
    },
    {
      "epoch": 9.514034966996787,
      "grad_norm": 1.3034684658050537,
      "learning_rate": 3.6500069622774357e-06,
      "loss": 0.4668,
      "step": 898700
    },
    {
      "epoch": 9.514564288776791,
      "grad_norm": 1.3583769798278809,
      "learning_rate": 3.6421466825727056e-06,
      "loss": 0.4656,
      "step": 898750
    },
    {
      "epoch": 9.515093610556793,
      "grad_norm": 1.4198817014694214,
      "learning_rate": 3.6342948134347187e-06,
      "loss": 0.4665,
      "step": 898800
    },
    {
      "epoch": 9.515622932336797,
      "grad_norm": 1.3098866939544678,
      "learning_rate": 3.626451355131566e-06,
      "loss": 0.4654,
      "step": 898850
    },
    {
      "epoch": 9.5161522541168,
      "grad_norm": 1.3433431386947632,
      "learning_rate": 3.618616307931005e-06,
      "loss": 0.4697,
      "step": 898900
    },
    {
      "epoch": 9.516681575896804,
      "grad_norm": 1.49540114402771,
      "learning_rate": 3.6107896721005174e-06,
      "loss": 0.4748,
      "step": 898950
    },
    {
      "epoch": 9.517210897676806,
      "grad_norm": 1.4683870077133179,
      "learning_rate": 3.6029714479073327e-06,
      "loss": 0.4787,
      "step": 899000
    },
    {
      "epoch": 9.517210897676806,
      "eval_loss": 0.2885359525680542,
      "eval_runtime": 46.9093,
      "eval_samples_per_second": 3579.89,
      "eval_steps_per_second": 447.502,
      "step": 899000
    },
    {
      "epoch": 9.51774021945681,
      "grad_norm": 1.335845708847046,
      "learning_rate": 3.5951616356183215e-06,
      "loss": 0.4766,
      "step": 899050
    },
    {
      "epoch": 9.518269541236814,
      "grad_norm": 1.5586060285568237,
      "learning_rate": 3.587360235500131e-06,
      "loss": 0.4678,
      "step": 899100
    },
    {
      "epoch": 9.518798863016816,
      "grad_norm": 1.5260258913040161,
      "learning_rate": 3.5795672478191045e-06,
      "loss": 0.4739,
      "step": 899150
    },
    {
      "epoch": 9.51932818479682,
      "grad_norm": 1.5689868927001953,
      "learning_rate": 3.5717826728412783e-06,
      "loss": 0.4651,
      "step": 899200
    },
    {
      "epoch": 9.519857506576823,
      "grad_norm": 1.3568440675735474,
      "learning_rate": 3.564006510832385e-06,
      "loss": 0.467,
      "step": 899250
    },
    {
      "epoch": 9.520386828356827,
      "grad_norm": 1.473362684249878,
      "learning_rate": 3.5562387620579618e-06,
      "loss": 0.4714,
      "step": 899300
    },
    {
      "epoch": 9.520916150136829,
      "grad_norm": 1.5192461013793945,
      "learning_rate": 3.548479426783158e-06,
      "loss": 0.4708,
      "step": 899350
    },
    {
      "epoch": 9.521445471916833,
      "grad_norm": 1.5257257223129272,
      "learning_rate": 3.5407285052729e-06,
      "loss": 0.4767,
      "step": 899400
    },
    {
      "epoch": 9.521974793696836,
      "grad_norm": 1.4241985082626343,
      "learning_rate": 3.5329859977917545e-06,
      "loss": 0.4664,
      "step": 899450
    },
    {
      "epoch": 9.52250411547684,
      "grad_norm": 1.5710960626602173,
      "learning_rate": 3.5252519046040933e-06,
      "loss": 0.4535,
      "step": 899500
    },
    {
      "epoch": 9.52250411547684,
      "eval_loss": 0.2884419560432434,
      "eval_runtime": 46.9022,
      "eval_samples_per_second": 3580.432,
      "eval_steps_per_second": 447.57,
      "step": 899500
    },
    {
      "epoch": 9.523033437256842,
      "grad_norm": 1.3083770275115967,
      "learning_rate": 3.5175262259739273e-06,
      "loss": 0.4773,
      "step": 899550
    },
    {
      "epoch": 9.523562759036846,
      "grad_norm": 1.568075180053711,
      "learning_rate": 3.509808962165045e-06,
      "loss": 0.4607,
      "step": 899600
    },
    {
      "epoch": 9.52409208081685,
      "grad_norm": 1.2907805442810059,
      "learning_rate": 3.5021001134408758e-06,
      "loss": 0.4641,
      "step": 899650
    },
    {
      "epoch": 9.524621402596853,
      "grad_norm": 1.334157109260559,
      "learning_rate": 3.4943996800645973e-06,
      "loss": 0.4673,
      "step": 899700
    },
    {
      "epoch": 9.525150724376855,
      "grad_norm": 1.3581658601760864,
      "learning_rate": 3.4867076622991103e-06,
      "loss": 0.4794,
      "step": 899750
    },
    {
      "epoch": 9.52568004615686,
      "grad_norm": 1.3335083723068237,
      "learning_rate": 3.479024060407038e-06,
      "loss": 0.4631,
      "step": 899800
    },
    {
      "epoch": 9.526209367936863,
      "grad_norm": 1.3746708631515503,
      "learning_rate": 3.4713488746506426e-06,
      "loss": 0.4684,
      "step": 899850
    },
    {
      "epoch": 9.526738689716865,
      "grad_norm": 1.4076159000396729,
      "learning_rate": 3.4636821052920207e-06,
      "loss": 0.4756,
      "step": 899900
    },
    {
      "epoch": 9.527268011496869,
      "grad_norm": 1.2542301416397095,
      "learning_rate": 3.4560237525928517e-06,
      "loss": 0.4635,
      "step": 899950
    },
    {
      "epoch": 9.527797333276872,
      "grad_norm": 1.3143858909606934,
      "learning_rate": 3.4483738168146206e-06,
      "loss": 0.4635,
      "step": 900000
    },
    {
      "epoch": 9.527797333276872,
      "eval_loss": 0.28850650787353516,
      "eval_runtime": 46.9023,
      "eval_samples_per_second": 3580.421,
      "eval_steps_per_second": 447.569,
      "step": 900000
    },
    {
      "epoch": 9.528326655056876,
      "grad_norm": 1.2565577030181885,
      "learning_rate": 3.4407322982185074e-06,
      "loss": 0.474,
      "step": 900050
    },
    {
      "epoch": 9.528855976836878,
      "grad_norm": 1.3886133432388306,
      "learning_rate": 3.433099197065359e-06,
      "loss": 0.4707,
      "step": 900100
    },
    {
      "epoch": 9.529385298616882,
      "grad_norm": 1.3727247714996338,
      "learning_rate": 3.425474513615745e-06,
      "loss": 0.465,
      "step": 900150
    },
    {
      "epoch": 9.529914620396886,
      "grad_norm": 1.281402349472046,
      "learning_rate": 3.4178582481300404e-06,
      "loss": 0.4676,
      "step": 900200
    },
    {
      "epoch": 9.53044394217689,
      "grad_norm": 1.3589653968811035,
      "learning_rate": 3.410250400868231e-06,
      "loss": 0.4597,
      "step": 900250
    },
    {
      "epoch": 9.530973263956891,
      "grad_norm": 1.3928643465042114,
      "learning_rate": 3.4026509720900266e-06,
      "loss": 0.4734,
      "step": 900300
    },
    {
      "epoch": 9.531502585736895,
      "grad_norm": 1.3737363815307617,
      "learning_rate": 3.3950599620548582e-06,
      "loss": 0.4699,
      "step": 900350
    },
    {
      "epoch": 9.532031907516899,
      "grad_norm": 1.2775620222091675,
      "learning_rate": 3.387477371021935e-06,
      "loss": 0.4658,
      "step": 900400
    },
    {
      "epoch": 9.532561229296903,
      "grad_norm": 1.632501482963562,
      "learning_rate": 3.3799031992500783e-06,
      "loss": 0.4688,
      "step": 900450
    },
    {
      "epoch": 9.533090551076905,
      "grad_norm": 1.329116940498352,
      "learning_rate": 3.372337446997886e-06,
      "loss": 0.4766,
      "step": 900500
    },
    {
      "epoch": 9.533090551076905,
      "eval_loss": 0.28852158784866333,
      "eval_runtime": 46.8946,
      "eval_samples_per_second": 3581.007,
      "eval_steps_per_second": 447.642,
      "step": 900500
    },
    {
      "epoch": 9.533619872856908,
      "grad_norm": 1.5851696729660034,
      "learning_rate": 3.3647801145236244e-06,
      "loss": 0.4615,
      "step": 900550
    },
    {
      "epoch": 9.534149194636912,
      "grad_norm": 1.4923256635665894,
      "learning_rate": 3.357231202085337e-06,
      "loss": 0.4689,
      "step": 900600
    },
    {
      "epoch": 9.534678516416914,
      "grad_norm": 1.3994407653808594,
      "learning_rate": 3.349690709940706e-06,
      "loss": 0.4708,
      "step": 900650
    },
    {
      "epoch": 9.535207838196918,
      "grad_norm": 1.1791727542877197,
      "learning_rate": 3.3421586383471925e-06,
      "loss": 0.4582,
      "step": 900700
    },
    {
      "epoch": 9.535737159976922,
      "grad_norm": 1.4423069953918457,
      "learning_rate": 3.3346349875619244e-06,
      "loss": 0.4744,
      "step": 900750
    },
    {
      "epoch": 9.536266481756925,
      "grad_norm": 1.2404230833053589,
      "learning_rate": 3.327119757841751e-06,
      "loss": 0.4673,
      "step": 900800
    },
    {
      "epoch": 9.536795803536927,
      "grad_norm": 1.231429100036621,
      "learning_rate": 3.3197630030806224e-06,
      "loss": 0.4705,
      "step": 900850
    },
    {
      "epoch": 9.537325125316931,
      "grad_norm": 1.5168323516845703,
      "learning_rate": 3.312264447826008e-06,
      "loss": 0.4672,
      "step": 900900
    },
    {
      "epoch": 9.537854447096935,
      "grad_norm": 1.3811309337615967,
      "learning_rate": 3.304774314400183e-06,
      "loss": 0.4637,
      "step": 900950
    },
    {
      "epoch": 9.538383768876939,
      "grad_norm": 1.2721415758132935,
      "learning_rate": 3.2972926030589155e-06,
      "loss": 0.4564,
      "step": 901000
    },
    {
      "epoch": 9.538383768876939,
      "eval_loss": 0.28853628039360046,
      "eval_runtime": 46.9822,
      "eval_samples_per_second": 3574.336,
      "eval_steps_per_second": 446.808,
      "step": 901000
    },
    {
      "epoch": 9.53891309065694,
      "grad_norm": 1.361409306526184,
      "learning_rate": 3.289819314057613e-06,
      "loss": 0.4701,
      "step": 901050
    },
    {
      "epoch": 9.539442412436944,
      "grad_norm": 1.3640649318695068,
      "learning_rate": 3.2823544476513757e-06,
      "loss": 0.4717,
      "step": 901100
    },
    {
      "epoch": 9.539971734216948,
      "grad_norm": 1.4115713834762573,
      "learning_rate": 3.274898004095084e-06,
      "loss": 0.4707,
      "step": 901150
    },
    {
      "epoch": 9.540501055996952,
      "grad_norm": 1.411972999572754,
      "learning_rate": 3.2674499836433113e-06,
      "loss": 0.4663,
      "step": 901200
    },
    {
      "epoch": 9.541030377776954,
      "grad_norm": 1.4291834831237793,
      "learning_rate": 3.260010386550272e-06,
      "loss": 0.4632,
      "step": 901250
    },
    {
      "epoch": 9.541559699556958,
      "grad_norm": 1.3153743743896484,
      "learning_rate": 3.2525792130700114e-06,
      "loss": 0.4758,
      "step": 901300
    },
    {
      "epoch": 9.542089021336961,
      "grad_norm": 1.306592583656311,
      "learning_rate": 3.245156463456217e-06,
      "loss": 0.472,
      "step": 901350
    },
    {
      "epoch": 9.542618343116963,
      "grad_norm": 1.391664743423462,
      "learning_rate": 3.2377421379622686e-06,
      "loss": 0.468,
      "step": 901400
    },
    {
      "epoch": 9.543147664896967,
      "grad_norm": 1.3537874221801758,
      "learning_rate": 3.230336236841297e-06,
      "loss": 0.4714,
      "step": 901450
    },
    {
      "epoch": 9.54367698667697,
      "grad_norm": 1.4837379455566406,
      "learning_rate": 3.2229387603461833e-06,
      "loss": 0.4587,
      "step": 901500
    },
    {
      "epoch": 9.54367698667697,
      "eval_loss": 0.28856199979782104,
      "eval_runtime": 46.8616,
      "eval_samples_per_second": 3583.528,
      "eval_steps_per_second": 447.957,
      "step": 901500
    },
    {
      "epoch": 9.544206308456975,
      "grad_norm": 1.4172003269195557,
      "learning_rate": 3.2155497087293926e-06,
      "loss": 0.4672,
      "step": 901550
    },
    {
      "epoch": 9.544735630236977,
      "grad_norm": 1.4133658409118652,
      "learning_rate": 3.208169082243251e-06,
      "loss": 0.4777,
      "step": 901600
    },
    {
      "epoch": 9.54526495201698,
      "grad_norm": 1.394405484199524,
      "learning_rate": 3.2007968811396947e-06,
      "loss": 0.4673,
      "step": 901650
    },
    {
      "epoch": 9.545794273796984,
      "grad_norm": 1.2797646522521973,
      "learning_rate": 3.19343310567044e-06,
      "loss": 0.4651,
      "step": 901700
    },
    {
      "epoch": 9.546323595576988,
      "grad_norm": 1.469064474105835,
      "learning_rate": 3.1860777560868692e-06,
      "loss": 0.458,
      "step": 901750
    },
    {
      "epoch": 9.54685291735699,
      "grad_norm": 1.4155935049057007,
      "learning_rate": 3.1787308326400865e-06,
      "loss": 0.4634,
      "step": 901800
    },
    {
      "epoch": 9.547382239136994,
      "grad_norm": 1.3694244623184204,
      "learning_rate": 3.1713923355808915e-06,
      "loss": 0.4574,
      "step": 901850
    },
    {
      "epoch": 9.547911560916997,
      "grad_norm": 1.5371270179748535,
      "learning_rate": 3.164062265159834e-06,
      "loss": 0.4742,
      "step": 901900
    },
    {
      "epoch": 9.548440882697001,
      "grad_norm": 1.3728801012039185,
      "learning_rate": 3.156740621627213e-06,
      "loss": 0.465,
      "step": 901950
    },
    {
      "epoch": 9.548970204477003,
      "grad_norm": 1.4226629734039307,
      "learning_rate": 3.1494274052328854e-06,
      "loss": 0.4662,
      "step": 902000
    },
    {
      "epoch": 9.548970204477003,
      "eval_loss": 0.2884867489337921,
      "eval_runtime": 46.9568,
      "eval_samples_per_second": 3576.267,
      "eval_steps_per_second": 447.049,
      "step": 902000
    },
    {
      "epoch": 9.549499526257007,
      "grad_norm": 1.353270173072815,
      "learning_rate": 3.1421226162265947e-06,
      "loss": 0.4555,
      "step": 902050
    },
    {
      "epoch": 9.55002884803701,
      "grad_norm": 1.4529520273208618,
      "learning_rate": 3.1348262548577257e-06,
      "loss": 0.4656,
      "step": 902100
    },
    {
      "epoch": 9.550558169817013,
      "grad_norm": 1.4731786251068115,
      "learning_rate": 3.1275383213753285e-06,
      "loss": 0.4719,
      "step": 902150
    },
    {
      "epoch": 9.551087491597016,
      "grad_norm": 1.3288911581039429,
      "learning_rate": 3.1202588160282597e-06,
      "loss": 0.4671,
      "step": 902200
    },
    {
      "epoch": 9.55161681337702,
      "grad_norm": 1.4630390405654907,
      "learning_rate": 3.112987739065015e-06,
      "loss": 0.4694,
      "step": 902250
    },
    {
      "epoch": 9.552146135157024,
      "grad_norm": 1.3237241506576538,
      "learning_rate": 3.105725090733813e-06,
      "loss": 0.4645,
      "step": 902300
    },
    {
      "epoch": 9.552675456937026,
      "grad_norm": 1.45750093460083,
      "learning_rate": 3.098470871282594e-06,
      "loss": 0.463,
      "step": 902350
    },
    {
      "epoch": 9.55320477871703,
      "grad_norm": 1.4794957637786865,
      "learning_rate": 3.091225080959076e-06,
      "loss": 0.4666,
      "step": 902400
    },
    {
      "epoch": 9.553734100497033,
      "grad_norm": 1.3893787860870361,
      "learning_rate": 3.0839877200105337e-06,
      "loss": 0.4734,
      "step": 902450
    },
    {
      "epoch": 9.554263422277037,
      "grad_norm": 1.5579588413238525,
      "learning_rate": 3.0767587886841306e-06,
      "loss": 0.4679,
      "step": 902500
    },
    {
      "epoch": 9.554263422277037,
      "eval_loss": 0.28840258717536926,
      "eval_runtime": 46.8455,
      "eval_samples_per_second": 3584.76,
      "eval_steps_per_second": 448.111,
      "step": 902500
    },
    {
      "epoch": 9.554792744057039,
      "grad_norm": 1.3774012327194214,
      "learning_rate": 3.069538287226614e-06,
      "loss": 0.4659,
      "step": 902550
    },
    {
      "epoch": 9.555322065837043,
      "grad_norm": 1.2492610216140747,
      "learning_rate": 3.062326215884509e-06,
      "loss": 0.4739,
      "step": 902600
    },
    {
      "epoch": 9.555851387617047,
      "grad_norm": 1.58451509475708,
      "learning_rate": 3.0551225749040066e-06,
      "loss": 0.4619,
      "step": 902650
    },
    {
      "epoch": 9.55638070939705,
      "grad_norm": 1.2973544597625732,
      "learning_rate": 3.04792736453105e-06,
      "loss": 0.4734,
      "step": 902700
    },
    {
      "epoch": 9.556910031177052,
      "grad_norm": 1.3585211038589478,
      "learning_rate": 3.0407405850113033e-06,
      "loss": 0.4647,
      "step": 902750
    },
    {
      "epoch": 9.557439352957056,
      "grad_norm": 1.4117058515548706,
      "learning_rate": 3.0335622365900985e-06,
      "loss": 0.4654,
      "step": 902800
    },
    {
      "epoch": 9.55796867473706,
      "grad_norm": 1.348504900932312,
      "learning_rate": 3.0265356352253137e-06,
      "loss": 0.468,
      "step": 902850
    },
    {
      "epoch": 9.558497996517062,
      "grad_norm": 1.4133659601211548,
      "learning_rate": 3.0193739811019415e-06,
      "loss": 0.4692,
      "step": 902900
    },
    {
      "epoch": 9.559027318297066,
      "grad_norm": 1.3801114559173584,
      "learning_rate": 3.012220758806583e-06,
      "loss": 0.4645,
      "step": 902950
    },
    {
      "epoch": 9.55955664007707,
      "grad_norm": 1.418339490890503,
      "learning_rate": 3.005075968583404e-06,
      "loss": 0.4695,
      "step": 903000
    },
    {
      "epoch": 9.55955664007707,
      "eval_loss": 0.28840282559394836,
      "eval_runtime": 46.9051,
      "eval_samples_per_second": 3580.211,
      "eval_steps_per_second": 447.542,
      "step": 903000
    },
    {
      "epoch": 9.560085961857073,
      "grad_norm": 1.451548457145691,
      "learning_rate": 2.9979396106763757e-06,
      "loss": 0.4674,
      "step": 903050
    },
    {
      "epoch": 9.560615283637075,
      "grad_norm": 1.283629298210144,
      "learning_rate": 2.9908116853290814e-06,
      "loss": 0.4645,
      "step": 903100
    },
    {
      "epoch": 9.561144605417079,
      "grad_norm": 1.2699477672576904,
      "learning_rate": 2.9836921927849094e-06,
      "loss": 0.4665,
      "step": 903150
    },
    {
      "epoch": 9.561673927197083,
      "grad_norm": 1.4597158432006836,
      "learning_rate": 2.9765811332868876e-06,
      "loss": 0.4642,
      "step": 903200
    },
    {
      "epoch": 9.562203248977086,
      "grad_norm": 1.361838698387146,
      "learning_rate": 2.9694785070777942e-06,
      "loss": 0.4758,
      "step": 903250
    },
    {
      "epoch": 9.562732570757088,
      "grad_norm": 1.386400818824768,
      "learning_rate": 2.962384314400102e-06,
      "loss": 0.4701,
      "step": 903300
    },
    {
      "epoch": 9.563261892537092,
      "grad_norm": 1.4217520952224731,
      "learning_rate": 2.9552985554960054e-06,
      "loss": 0.4616,
      "step": 903350
    },
    {
      "epoch": 9.563791214317096,
      "grad_norm": 1.304202914237976,
      "learning_rate": 2.948221230607423e-06,
      "loss": 0.4648,
      "step": 903400
    },
    {
      "epoch": 9.5643205360971,
      "grad_norm": 1.3569982051849365,
      "learning_rate": 2.9411523399759665e-06,
      "loss": 0.4668,
      "step": 903450
    },
    {
      "epoch": 9.564849857877102,
      "grad_norm": 1.326499342918396,
      "learning_rate": 2.934091883842943e-06,
      "loss": 0.4618,
      "step": 903500
    },
    {
      "epoch": 9.564849857877102,
      "eval_loss": 0.2883671522140503,
      "eval_runtime": 46.9099,
      "eval_samples_per_second": 3579.841,
      "eval_steps_per_second": 447.496,
      "step": 903500
    },
    {
      "epoch": 9.565379179657105,
      "grad_norm": 1.3514816761016846,
      "learning_rate": 2.9270398624494374e-06,
      "loss": 0.4651,
      "step": 903550
    },
    {
      "epoch": 9.565908501437109,
      "grad_norm": 1.3182034492492676,
      "learning_rate": 2.9199962760361743e-06,
      "loss": 0.4606,
      "step": 903600
    },
    {
      "epoch": 9.566437823217111,
      "grad_norm": 1.3697924613952637,
      "learning_rate": 2.9129611248436274e-06,
      "loss": 0.4738,
      "step": 903650
    },
    {
      "epoch": 9.566967144997115,
      "grad_norm": 1.4817622900009155,
      "learning_rate": 2.9059344091119377e-06,
      "loss": 0.4753,
      "step": 903700
    },
    {
      "epoch": 9.567496466777119,
      "grad_norm": 1.4308733940124512,
      "learning_rate": 2.898916129081081e-06,
      "loss": 0.4734,
      "step": 903750
    },
    {
      "epoch": 9.568025788557122,
      "grad_norm": 1.4710270166397095,
      "learning_rate": 2.8919062849905586e-06,
      "loss": 0.4697,
      "step": 903800
    },
    {
      "epoch": 9.568555110337124,
      "grad_norm": 1.3753334283828735,
      "learning_rate": 2.8849048770797637e-06,
      "loss": 0.4691,
      "step": 903850
    },
    {
      "epoch": 9.569084432117128,
      "grad_norm": 1.4161076545715332,
      "learning_rate": 2.8779119055876713e-06,
      "loss": 0.4607,
      "step": 903900
    },
    {
      "epoch": 9.569613753897132,
      "grad_norm": 1.3965380191802979,
      "learning_rate": 2.8709273707530346e-06,
      "loss": 0.4601,
      "step": 903950
    },
    {
      "epoch": 9.570143075677136,
      "grad_norm": 1.1654120683670044,
      "learning_rate": 2.86395127281433e-06,
      "loss": 0.4618,
      "step": 904000
    },
    {
      "epoch": 9.570143075677136,
      "eval_loss": 0.28837716579437256,
      "eval_runtime": 46.8454,
      "eval_samples_per_second": 3584.769,
      "eval_steps_per_second": 448.112,
      "step": 904000
    },
    {
      "epoch": 9.570672397457137,
      "grad_norm": 1.2944639921188354,
      "learning_rate": 2.8569836120096725e-06,
      "loss": 0.4655,
      "step": 904050
    },
    {
      "epoch": 9.571201719237141,
      "grad_norm": 1.15298593044281,
      "learning_rate": 2.850024388576983e-06,
      "loss": 0.4662,
      "step": 904100
    },
    {
      "epoch": 9.571731041017145,
      "grad_norm": 1.3598846197128296,
      "learning_rate": 2.843073602753793e-06,
      "loss": 0.464,
      "step": 904150
    },
    {
      "epoch": 9.572260362797149,
      "grad_norm": 1.4379889965057373,
      "learning_rate": 2.836131254777413e-06,
      "loss": 0.4633,
      "step": 904200
    },
    {
      "epoch": 9.57278968457715,
      "grad_norm": 1.4872875213623047,
      "learning_rate": 2.829197344884904e-06,
      "loss": 0.4626,
      "step": 904250
    },
    {
      "epoch": 9.573319006357154,
      "grad_norm": 1.3005199432373047,
      "learning_rate": 2.822271873312937e-06,
      "loss": 0.4727,
      "step": 904300
    },
    {
      "epoch": 9.573848328137158,
      "grad_norm": 1.3630037307739258,
      "learning_rate": 2.8153548402979623e-06,
      "loss": 0.472,
      "step": 904350
    },
    {
      "epoch": 9.57437764991716,
      "grad_norm": 1.3704004287719727,
      "learning_rate": 2.808446246076124e-06,
      "loss": 0.4717,
      "step": 904400
    },
    {
      "epoch": 9.574906971697164,
      "grad_norm": 1.3467411994934082,
      "learning_rate": 2.8015460908832613e-06,
      "loss": 0.4655,
      "step": 904450
    },
    {
      "epoch": 9.575436293477168,
      "grad_norm": 1.363246202468872,
      "learning_rate": 2.7946543749549636e-06,
      "loss": 0.4635,
      "step": 904500
    },
    {
      "epoch": 9.575436293477168,
      "eval_loss": 0.2883550226688385,
      "eval_runtime": 46.9054,
      "eval_samples_per_second": 3580.185,
      "eval_steps_per_second": 447.539,
      "step": 904500
    },
    {
      "epoch": 9.575965615257171,
      "grad_norm": 1.374308466911316,
      "learning_rate": 2.7877710985265146e-06,
      "loss": 0.467,
      "step": 904550
    },
    {
      "epoch": 9.576494937037173,
      "grad_norm": 1.430720567703247,
      "learning_rate": 2.7808962618328937e-06,
      "loss": 0.4684,
      "step": 904600
    },
    {
      "epoch": 9.577024258817177,
      "grad_norm": 1.2264081239700317,
      "learning_rate": 2.7740298651088012e-06,
      "loss": 0.4644,
      "step": 904650
    },
    {
      "epoch": 9.577553580597181,
      "grad_norm": 1.3826676607131958,
      "learning_rate": 2.7671719085886613e-06,
      "loss": 0.4629,
      "step": 904700
    },
    {
      "epoch": 9.578082902377185,
      "grad_norm": 1.2468862533569336,
      "learning_rate": 2.76032239250662e-06,
      "loss": 0.4696,
      "step": 904750
    },
    {
      "epoch": 9.578612224157187,
      "grad_norm": 1.3642898797988892,
      "learning_rate": 2.75348131709649e-06,
      "loss": 0.4607,
      "step": 904800
    },
    {
      "epoch": 9.57914154593719,
      "grad_norm": 1.2910866737365723,
      "learning_rate": 2.7466486825918345e-06,
      "loss": 0.4693,
      "step": 904850
    },
    {
      "epoch": 9.579670867717194,
      "grad_norm": 1.3875824213027954,
      "learning_rate": 2.7398244892259115e-06,
      "loss": 0.474,
      "step": 904900
    },
    {
      "epoch": 9.580200189497198,
      "grad_norm": 1.2645610570907593,
      "learning_rate": 2.7330087372317014e-06,
      "loss": 0.4687,
      "step": 904950
    },
    {
      "epoch": 9.5807295112772,
      "grad_norm": 1.2225065231323242,
      "learning_rate": 2.726201426841879e-06,
      "loss": 0.4631,
      "step": 905000
    },
    {
      "epoch": 9.5807295112772,
      "eval_loss": 0.28832748532295227,
      "eval_runtime": 46.8066,
      "eval_samples_per_second": 3587.742,
      "eval_steps_per_second": 448.484,
      "step": 905000
    },
    {
      "epoch": 9.581258833057204,
      "grad_norm": 1.354797601699829,
      "learning_rate": 2.7194025582888695e-06,
      "loss": 0.4679,
      "step": 905050
    },
    {
      "epoch": 9.581788154837207,
      "grad_norm": 1.2998207807540894,
      "learning_rate": 2.712612131804765e-06,
      "loss": 0.4627,
      "step": 905100
    },
    {
      "epoch": 9.58231747661721,
      "grad_norm": 1.4331579208374023,
      "learning_rate": 2.7058301476214077e-06,
      "loss": 0.4691,
      "step": 905150
    },
    {
      "epoch": 9.582846798397213,
      "grad_norm": 1.4775973558425903,
      "learning_rate": 2.6990566059702794e-06,
      "loss": 0.4621,
      "step": 905200
    },
    {
      "epoch": 9.583376120177217,
      "grad_norm": 1.292809247970581,
      "learning_rate": 2.692291507082695e-06,
      "loss": 0.4686,
      "step": 905250
    },
    {
      "epoch": 9.58390544195722,
      "grad_norm": 1.37750244140625,
      "learning_rate": 2.6855348511895806e-06,
      "loss": 0.4621,
      "step": 905300
    },
    {
      "epoch": 9.584434763737223,
      "grad_norm": 1.3091734647750854,
      "learning_rate": 2.678786638521585e-06,
      "loss": 0.4592,
      "step": 905350
    },
    {
      "epoch": 9.584964085517226,
      "grad_norm": 1.4984773397445679,
      "learning_rate": 2.672046869309136e-06,
      "loss": 0.4643,
      "step": 905400
    },
    {
      "epoch": 9.58549340729723,
      "grad_norm": 1.2426713705062866,
      "learning_rate": 2.6653155437822983e-06,
      "loss": 0.4687,
      "step": 905450
    },
    {
      "epoch": 9.586022729077234,
      "grad_norm": 1.378515362739563,
      "learning_rate": 2.658592662170861e-06,
      "loss": 0.4661,
      "step": 905500
    },
    {
      "epoch": 9.586022729077234,
      "eval_loss": 0.2882319688796997,
      "eval_runtime": 46.8967,
      "eval_samples_per_second": 3580.848,
      "eval_steps_per_second": 447.622,
      "step": 905500
    },
    {
      "epoch": 9.586552050857236,
      "grad_norm": 1.4395010471343994,
      "learning_rate": 2.6518782247043627e-06,
      "loss": 0.4616,
      "step": 905550
    },
    {
      "epoch": 9.58708137263724,
      "grad_norm": 1.4033147096633911,
      "learning_rate": 2.645172231612036e-06,
      "loss": 0.4581,
      "step": 905600
    },
    {
      "epoch": 9.587610694417243,
      "grad_norm": 1.4609707593917847,
      "learning_rate": 2.63847468312281e-06,
      "loss": 0.4649,
      "step": 905650
    },
    {
      "epoch": 9.588140016197247,
      "grad_norm": 1.3561232089996338,
      "learning_rate": 2.6317855794653623e-06,
      "loss": 0.4685,
      "step": 905700
    },
    {
      "epoch": 9.58866933797725,
      "grad_norm": 1.321784496307373,
      "learning_rate": 2.62510492086801e-06,
      "loss": 0.4621,
      "step": 905750
    },
    {
      "epoch": 9.589198659757253,
      "grad_norm": 1.435071587562561,
      "learning_rate": 2.6184327075588486e-06,
      "loss": 0.4635,
      "step": 905800
    },
    {
      "epoch": 9.589727981537257,
      "grad_norm": 1.498240351676941,
      "learning_rate": 2.6117689397656964e-06,
      "loss": 0.472,
      "step": 905850
    },
    {
      "epoch": 9.590257303317259,
      "grad_norm": 1.4852813482284546,
      "learning_rate": 2.6051136177160097e-06,
      "loss": 0.4616,
      "step": 905900
    },
    {
      "epoch": 9.590786625097262,
      "grad_norm": 1.3998193740844727,
      "learning_rate": 2.5984667416370236e-06,
      "loss": 0.4705,
      "step": 905950
    },
    {
      "epoch": 9.591315946877266,
      "grad_norm": 1.3662192821502686,
      "learning_rate": 2.5918283117556396e-06,
      "loss": 0.467,
      "step": 906000
    },
    {
      "epoch": 9.591315946877266,
      "eval_loss": 0.28822797536849976,
      "eval_runtime": 46.7837,
      "eval_samples_per_second": 3589.494,
      "eval_steps_per_second": 448.703,
      "step": 906000
    },
    {
      "epoch": 9.59184526865727,
      "grad_norm": 1.3663297891616821,
      "learning_rate": 2.58519832829851e-06,
      "loss": 0.4653,
      "step": 906050
    },
    {
      "epoch": 9.592374590437272,
      "grad_norm": 1.250170350074768,
      "learning_rate": 2.578576791491982e-06,
      "loss": 0.4644,
      "step": 906100
    },
    {
      "epoch": 9.592903912217276,
      "grad_norm": 1.3093440532684326,
      "learning_rate": 2.5719637015620966e-06,
      "loss": 0.4637,
      "step": 906150
    },
    {
      "epoch": 9.59343323399728,
      "grad_norm": 1.5653003454208374,
      "learning_rate": 2.5653590587346177e-06,
      "loss": 0.4699,
      "step": 906200
    },
    {
      "epoch": 9.593962555777283,
      "grad_norm": 1.2962335348129272,
      "learning_rate": 2.558762863235059e-06,
      "loss": 0.4691,
      "step": 906250
    },
    {
      "epoch": 9.594491877557285,
      "grad_norm": 1.4093809127807617,
      "learning_rate": 2.5521751152885743e-06,
      "loss": 0.4697,
      "step": 906300
    },
    {
      "epoch": 9.595021199337289,
      "grad_norm": 1.3813194036483765,
      "learning_rate": 2.5455958151200665e-06,
      "loss": 0.4663,
      "step": 906350
    },
    {
      "epoch": 9.595550521117293,
      "grad_norm": 1.4169963598251343,
      "learning_rate": 2.5390249629541897e-06,
      "loss": 0.4664,
      "step": 906400
    },
    {
      "epoch": 9.596079842897296,
      "grad_norm": 1.3270177841186523,
      "learning_rate": 2.5325937242999532e-06,
      "loss": 0.4646,
      "step": 906450
    },
    {
      "epoch": 9.596609164677298,
      "grad_norm": 1.3916113376617432,
      "learning_rate": 2.5260395998407406e-06,
      "loss": 0.4574,
      "step": 906500
    },
    {
      "epoch": 9.596609164677298,
      "eval_loss": 0.2882571816444397,
      "eval_runtime": 46.9142,
      "eval_samples_per_second": 3579.514,
      "eval_steps_per_second": 447.455,
      "step": 906500
    },
    {
      "epoch": 9.597138486457302,
      "grad_norm": 1.2420631647109985,
      "learning_rate": 2.5194939240518187e-06,
      "loss": 0.4661,
      "step": 906550
    },
    {
      "epoch": 9.597667808237306,
      "grad_norm": 1.20947265625,
      "learning_rate": 2.5129566971565654e-06,
      "loss": 0.4649,
      "step": 906600
    },
    {
      "epoch": 9.598197130017308,
      "grad_norm": 1.2465866804122925,
      "learning_rate": 2.506427919378246e-06,
      "loss": 0.4702,
      "step": 906650
    },
    {
      "epoch": 9.598726451797312,
      "grad_norm": 1.3704360723495483,
      "learning_rate": 2.4999075909397096e-06,
      "loss": 0.4664,
      "step": 906700
    },
    {
      "epoch": 9.599255773577315,
      "grad_norm": 1.3207478523254395,
      "learning_rate": 2.4933957120635565e-06,
      "loss": 0.4673,
      "step": 906750
    },
    {
      "epoch": 9.59978509535732,
      "grad_norm": 1.2283891439437866,
      "learning_rate": 2.486892282972081e-06,
      "loss": 0.4628,
      "step": 906800
    },
    {
      "epoch": 9.600314417137321,
      "grad_norm": 1.432199239730835,
      "learning_rate": 2.480397303887355e-06,
      "loss": 0.4675,
      "step": 906850
    },
    {
      "epoch": 9.600843738917325,
      "grad_norm": 1.4665108919143677,
      "learning_rate": 2.4739107750310907e-06,
      "loss": 0.4651,
      "step": 906900
    },
    {
      "epoch": 9.601373060697329,
      "grad_norm": 1.446271300315857,
      "learning_rate": 2.467432696624722e-06,
      "loss": 0.4596,
      "step": 906950
    },
    {
      "epoch": 9.601902382477332,
      "grad_norm": 1.4020320177078247,
      "learning_rate": 2.4609630688894326e-06,
      "loss": 0.469,
      "step": 907000
    },
    {
      "epoch": 9.601902382477332,
      "eval_loss": 0.28816714882850647,
      "eval_runtime": 46.9416,
      "eval_samples_per_second": 3577.42,
      "eval_steps_per_second": 447.194,
      "step": 907000
    },
    {
      "epoch": 9.602431704257334,
      "grad_norm": 1.3078994750976562,
      "learning_rate": 2.4545018920460736e-06,
      "loss": 0.4678,
      "step": 907050
    },
    {
      "epoch": 9.602961026037338,
      "grad_norm": 1.4769566059112549,
      "learning_rate": 2.448049166315247e-06,
      "loss": 0.4696,
      "step": 907100
    },
    {
      "epoch": 9.603490347817342,
      "grad_norm": 1.4413425922393799,
      "learning_rate": 2.4416048919172208e-06,
      "loss": 0.4711,
      "step": 907150
    },
    {
      "epoch": 9.604019669597346,
      "grad_norm": 1.33358895778656,
      "learning_rate": 2.435169069072013e-06,
      "loss": 0.467,
      "step": 907200
    },
    {
      "epoch": 9.604548991377348,
      "grad_norm": 1.3786031007766724,
      "learning_rate": 2.428741697999337e-06,
      "loss": 0.4699,
      "step": 907250
    },
    {
      "epoch": 9.605078313157351,
      "grad_norm": 1.3979599475860596,
      "learning_rate": 2.4223227789186287e-06,
      "loss": 0.4628,
      "step": 907300
    },
    {
      "epoch": 9.605607634937355,
      "grad_norm": 1.4273613691329956,
      "learning_rate": 2.4159123120490455e-06,
      "loss": 0.4714,
      "step": 907350
    },
    {
      "epoch": 9.606136956717357,
      "grad_norm": 1.4499599933624268,
      "learning_rate": 2.409510297609385e-06,
      "loss": 0.4662,
      "step": 907400
    },
    {
      "epoch": 9.60666627849736,
      "grad_norm": 1.1978003978729248,
      "learning_rate": 2.403116735818278e-06,
      "loss": 0.4599,
      "step": 907450
    },
    {
      "epoch": 9.607195600277365,
      "grad_norm": 1.2717595100402832,
      "learning_rate": 2.3967316268939387e-06,
      "loss": 0.4676,
      "step": 907500
    },
    {
      "epoch": 9.607195600277365,
      "eval_loss": 0.28823480010032654,
      "eval_runtime": 46.9583,
      "eval_samples_per_second": 3576.148,
      "eval_steps_per_second": 447.034,
      "step": 907500
    },
    {
      "epoch": 9.607724922057368,
      "grad_norm": 1.4129700660705566,
      "learning_rate": 2.390354971054387e-06,
      "loss": 0.4661,
      "step": 907550
    },
    {
      "epoch": 9.60825424383737,
      "grad_norm": 1.3614221811294556,
      "learning_rate": 2.3839867685172824e-06,
      "loss": 0.4716,
      "step": 907600
    },
    {
      "epoch": 9.608783565617374,
      "grad_norm": 1.4336254596710205,
      "learning_rate": 2.3776270195000893e-06,
      "loss": 0.4701,
      "step": 907650
    },
    {
      "epoch": 9.609312887397378,
      "grad_norm": 1.3322991132736206,
      "learning_rate": 2.3712757242198848e-06,
      "loss": 0.4662,
      "step": 907700
    },
    {
      "epoch": 9.609842209177382,
      "grad_norm": 1.3671802282333374,
      "learning_rate": 2.3649328828935224e-06,
      "loss": 0.4711,
      "step": 907750
    },
    {
      "epoch": 9.610371530957384,
      "grad_norm": 1.4085631370544434,
      "learning_rate": 2.3585984957375238e-06,
      "loss": 0.4684,
      "step": 907800
    },
    {
      "epoch": 9.610900852737387,
      "grad_norm": 1.552592396736145,
      "learning_rate": 2.352272562968133e-06,
      "loss": 0.4626,
      "step": 907850
    },
    {
      "epoch": 9.611430174517391,
      "grad_norm": 1.4805165529251099,
      "learning_rate": 2.3459550848013713e-06,
      "loss": 0.478,
      "step": 907900
    },
    {
      "epoch": 9.611959496297395,
      "grad_norm": 1.3565884828567505,
      "learning_rate": 2.339646061452844e-06,
      "loss": 0.4662,
      "step": 907950
    },
    {
      "epoch": 9.612488818077397,
      "grad_norm": 1.3246370553970337,
      "learning_rate": 2.3333454931379892e-06,
      "loss": 0.4738,
      "step": 908000
    },
    {
      "epoch": 9.612488818077397,
      "eval_loss": 0.28822559118270874,
      "eval_runtime": 46.9487,
      "eval_samples_per_second": 3576.885,
      "eval_steps_per_second": 447.127,
      "step": 908000
    },
    {
      "epoch": 9.6130181398574,
      "grad_norm": 1.6415551900863647,
      "learning_rate": 2.3270533800718864e-06,
      "loss": 0.4708,
      "step": 908050
    },
    {
      "epoch": 9.613547461637404,
      "grad_norm": 1.4640042781829834,
      "learning_rate": 2.3207697224693625e-06,
      "loss": 0.4736,
      "step": 908100
    },
    {
      "epoch": 9.614076783417406,
      "grad_norm": 1.4640952348709106,
      "learning_rate": 2.314494520544913e-06,
      "loss": 0.4618,
      "step": 908150
    },
    {
      "epoch": 9.61460610519741,
      "grad_norm": 1.345735788345337,
      "learning_rate": 2.3082277745127835e-06,
      "loss": 0.4679,
      "step": 908200
    },
    {
      "epoch": 9.615135426977414,
      "grad_norm": 1.4042253494262695,
      "learning_rate": 2.301969484586941e-06,
      "loss": 0.4658,
      "step": 908250
    },
    {
      "epoch": 9.615664748757418,
      "grad_norm": 1.495023250579834,
      "learning_rate": 2.295719650980993e-06,
      "loss": 0.4765,
      "step": 908300
    },
    {
      "epoch": 9.61619407053742,
      "grad_norm": 1.2239130735397339,
      "learning_rate": 2.289478273908352e-06,
      "loss": 0.4744,
      "step": 908350
    },
    {
      "epoch": 9.616723392317423,
      "grad_norm": 1.4276384115219116,
      "learning_rate": 2.2832453535820697e-06,
      "loss": 0.4667,
      "step": 908400
    },
    {
      "epoch": 9.617252714097427,
      "grad_norm": 1.2980860471725464,
      "learning_rate": 2.277020890214948e-06,
      "loss": 0.4697,
      "step": 908450
    },
    {
      "epoch": 9.61778203587743,
      "grad_norm": 1.5363479852676392,
      "learning_rate": 2.2708048840194837e-06,
      "loss": 0.4619,
      "step": 908500
    },
    {
      "epoch": 9.61778203587743,
      "eval_loss": 0.2882576882839203,
      "eval_runtime": 46.894,
      "eval_samples_per_second": 3581.053,
      "eval_steps_per_second": 447.648,
      "step": 908500
    },
    {
      "epoch": 9.618311357657433,
      "grad_norm": 1.5203732252120972,
      "learning_rate": 2.2645973352078687e-06,
      "loss": 0.4661,
      "step": 908550
    },
    {
      "epoch": 9.618840679437437,
      "grad_norm": 1.1763617992401123,
      "learning_rate": 2.2583982439920716e-06,
      "loss": 0.4704,
      "step": 908600
    },
    {
      "epoch": 9.61937000121744,
      "grad_norm": 1.4713000059127808,
      "learning_rate": 2.2522076105837007e-06,
      "loss": 0.4633,
      "step": 908650
    },
    {
      "epoch": 9.619899322997444,
      "grad_norm": 1.4512404203414917,
      "learning_rate": 2.2460254351940877e-06,
      "loss": 0.4608,
      "step": 908700
    },
    {
      "epoch": 9.620428644777446,
      "grad_norm": 1.3765047788619995,
      "learning_rate": 2.2398517180343136e-06,
      "loss": 0.472,
      "step": 908750
    },
    {
      "epoch": 9.62095796655745,
      "grad_norm": 1.361825704574585,
      "learning_rate": 2.2336864593151263e-06,
      "loss": 0.4713,
      "step": 908800
    },
    {
      "epoch": 9.621487288337454,
      "grad_norm": 1.2886182069778442,
      "learning_rate": 2.227529659247024e-06,
      "loss": 0.4674,
      "step": 908850
    },
    {
      "epoch": 9.622016610117456,
      "grad_norm": 1.4022835493087769,
      "learning_rate": 2.2215042019661513e-06,
      "loss": 0.4665,
      "step": 908900
    },
    {
      "epoch": 9.62254593189746,
      "grad_norm": 1.3835225105285645,
      "learning_rate": 2.2153641506469923e-06,
      "loss": 0.4758,
      "step": 908950
    },
    {
      "epoch": 9.623075253677463,
      "grad_norm": 1.3827345371246338,
      "learning_rate": 2.2092325586044737e-06,
      "loss": 0.4598,
      "step": 909000
    },
    {
      "epoch": 9.623075253677463,
      "eval_loss": 0.2881864011287689,
      "eval_runtime": 46.8938,
      "eval_samples_per_second": 3581.072,
      "eval_steps_per_second": 447.65,
      "step": 909000
    },
    {
      "epoch": 9.623604575457467,
      "grad_norm": 1.275995135307312,
      "learning_rate": 2.2031094260478445e-06,
      "loss": 0.4652,
      "step": 909050
    },
    {
      "epoch": 9.624133897237469,
      "grad_norm": 1.2699475288391113,
      "learning_rate": 2.1969947531862158e-06,
      "loss": 0.462,
      "step": 909100
    },
    {
      "epoch": 9.624663219017473,
      "grad_norm": 1.4282881021499634,
      "learning_rate": 2.190888540228281e-06,
      "loss": 0.4737,
      "step": 909150
    },
    {
      "epoch": 9.625192540797476,
      "grad_norm": 1.3096370697021484,
      "learning_rate": 2.18479078738254e-06,
      "loss": 0.4672,
      "step": 909200
    },
    {
      "epoch": 9.62572186257748,
      "grad_norm": 1.4340236186981201,
      "learning_rate": 2.1787014948571327e-06,
      "loss": 0.4725,
      "step": 909250
    },
    {
      "epoch": 9.626251184357482,
      "grad_norm": 1.2592653036117554,
      "learning_rate": 2.172620662860003e-06,
      "loss": 0.4625,
      "step": 909300
    },
    {
      "epoch": 9.626780506137486,
      "grad_norm": 1.3719594478607178,
      "learning_rate": 2.1665482915987077e-06,
      "loss": 0.4704,
      "step": 909350
    },
    {
      "epoch": 9.62730982791749,
      "grad_norm": 1.5686899423599243,
      "learning_rate": 2.160484381280581e-06,
      "loss": 0.4652,
      "step": 909400
    },
    {
      "epoch": 9.627839149697493,
      "grad_norm": 1.3908053636550903,
      "learning_rate": 2.1544289321125952e-06,
      "loss": 0.4746,
      "step": 909450
    },
    {
      "epoch": 9.628368471477495,
      "grad_norm": 1.3590656518936157,
      "learning_rate": 2.148381944301531e-06,
      "loss": 0.4619,
      "step": 909500
    },
    {
      "epoch": 9.628368471477495,
      "eval_loss": 0.2881018817424774,
      "eval_runtime": 46.8855,
      "eval_samples_per_second": 3581.703,
      "eval_steps_per_second": 447.729,
      "step": 909500
    },
    {
      "epoch": 9.628897793257499,
      "grad_norm": 1.4038633108139038,
      "learning_rate": 2.1423434180537772e-06,
      "loss": 0.4637,
      "step": 909550
    },
    {
      "epoch": 9.629427115037503,
      "grad_norm": 1.3708593845367432,
      "learning_rate": 2.1363133535755587e-06,
      "loss": 0.4586,
      "step": 909600
    },
    {
      "epoch": 9.629956436817505,
      "grad_norm": 1.3905972242355347,
      "learning_rate": 2.1302917510726826e-06,
      "loss": 0.4742,
      "step": 909650
    },
    {
      "epoch": 9.630485758597509,
      "grad_norm": 1.327161431312561,
      "learning_rate": 2.124278610750735e-06,
      "loss": 0.4685,
      "step": 909700
    },
    {
      "epoch": 9.631015080377512,
      "grad_norm": 1.4872833490371704,
      "learning_rate": 2.1182739328150236e-06,
      "loss": 0.4632,
      "step": 909750
    },
    {
      "epoch": 9.631544402157516,
      "grad_norm": 1.2718260288238525,
      "learning_rate": 2.112277717470551e-06,
      "loss": 0.4606,
      "step": 909800
    },
    {
      "epoch": 9.632073723937518,
      "grad_norm": 1.4770359992980957,
      "learning_rate": 2.106289964921959e-06,
      "loss": 0.4687,
      "step": 909850
    },
    {
      "epoch": 9.632603045717522,
      "grad_norm": 1.2136714458465576,
      "learning_rate": 2.100310675373751e-06,
      "loss": 0.4601,
      "step": 909900
    },
    {
      "epoch": 9.633132367497526,
      "grad_norm": 1.4153389930725098,
      "learning_rate": 2.094339849030014e-06,
      "loss": 0.4658,
      "step": 909950
    },
    {
      "epoch": 9.63366168927753,
      "grad_norm": 1.3541313409805298,
      "learning_rate": 2.0883774860945836e-06,
      "loss": 0.4639,
      "step": 910000
    },
    {
      "epoch": 9.63366168927753,
      "eval_loss": 0.28810933232307434,
      "eval_runtime": 46.9397,
      "eval_samples_per_second": 3577.568,
      "eval_steps_per_second": 447.212,
      "step": 910000
    },
    {
      "epoch": 9.634191011057531,
      "grad_norm": 1.387384295463562,
      "learning_rate": 2.0824235867710486e-06,
      "loss": 0.4687,
      "step": 910050
    },
    {
      "epoch": 9.634720332837535,
      "grad_norm": 1.480880618095398,
      "learning_rate": 2.076478151262634e-06,
      "loss": 0.4684,
      "step": 910100
    },
    {
      "epoch": 9.635249654617539,
      "grad_norm": 1.2498729228973389,
      "learning_rate": 2.0705411797723173e-06,
      "loss": 0.4673,
      "step": 910150
    },
    {
      "epoch": 9.635778976397543,
      "grad_norm": 1.4273185729980469,
      "learning_rate": 2.0646126725028245e-06,
      "loss": 0.4612,
      "step": 910200
    },
    {
      "epoch": 9.636308298177545,
      "grad_norm": 1.428632378578186,
      "learning_rate": 2.0586926296565222e-06,
      "loss": 0.467,
      "step": 910250
    },
    {
      "epoch": 9.636837619957548,
      "grad_norm": 1.416254997253418,
      "learning_rate": 2.0527810514355537e-06,
      "loss": 0.4683,
      "step": 910300
    },
    {
      "epoch": 9.637366941737552,
      "grad_norm": 1.4642038345336914,
      "learning_rate": 2.046877938041647e-06,
      "loss": 0.4678,
      "step": 910350
    },
    {
      "epoch": 9.637896263517554,
      "grad_norm": 1.5840189456939697,
      "learning_rate": 2.040983289676446e-06,
      "loss": 0.4648,
      "step": 910400
    },
    {
      "epoch": 9.638425585297558,
      "grad_norm": 1.433440923690796,
      "learning_rate": 2.035097106541123e-06,
      "loss": 0.4701,
      "step": 910450
    },
    {
      "epoch": 9.638954907077562,
      "grad_norm": 1.2974982261657715,
      "learning_rate": 2.0292193888366284e-06,
      "loss": 0.4691,
      "step": 910500
    },
    {
      "epoch": 9.638954907077562,
      "eval_loss": 0.2881316840648651,
      "eval_runtime": 46.8487,
      "eval_samples_per_second": 3584.519,
      "eval_steps_per_second": 448.081,
      "step": 910500
    },
    {
      "epoch": 9.639484228857565,
      "grad_norm": 1.4986414909362793,
      "learning_rate": 2.0233501367636632e-06,
      "loss": 0.467,
      "step": 910550
    },
    {
      "epoch": 9.640013550637567,
      "grad_norm": 1.2714461088180542,
      "learning_rate": 2.0174893505225667e-06,
      "loss": 0.4718,
      "step": 910600
    },
    {
      "epoch": 9.640542872417571,
      "grad_norm": 1.2260252237319946,
      "learning_rate": 2.0116370303134566e-06,
      "loss": 0.4708,
      "step": 910650
    },
    {
      "epoch": 9.641072194197575,
      "grad_norm": 1.402713656425476,
      "learning_rate": 2.005793176336118e-06,
      "loss": 0.4743,
      "step": 910700
    },
    {
      "epoch": 9.641601515977579,
      "grad_norm": 1.4271225929260254,
      "learning_rate": 1.9999577887900023e-06,
      "loss": 0.468,
      "step": 910750
    },
    {
      "epoch": 9.64213083775758,
      "grad_norm": 1.3946223258972168,
      "learning_rate": 1.9941308678744217e-06,
      "loss": 0.4671,
      "step": 910800
    },
    {
      "epoch": 9.642660159537584,
      "grad_norm": 1.4095808267593384,
      "learning_rate": 1.9883124137882456e-06,
      "loss": 0.4642,
      "step": 910850
    },
    {
      "epoch": 9.643189481317588,
      "grad_norm": 1.4323420524597168,
      "learning_rate": 1.9825024267301485e-06,
      "loss": 0.463,
      "step": 910900
    },
    {
      "epoch": 9.643718803097592,
      "grad_norm": 1.3251926898956299,
      "learning_rate": 1.9767009068984154e-06,
      "loss": 0.4616,
      "step": 910950
    },
    {
      "epoch": 9.644248124877594,
      "grad_norm": 1.4180395603179932,
      "learning_rate": 1.970907854491194e-06,
      "loss": 0.4687,
      "step": 911000
    },
    {
      "epoch": 9.644248124877594,
      "eval_loss": 0.28808486461639404,
      "eval_runtime": 46.9952,
      "eval_samples_per_second": 3573.345,
      "eval_steps_per_second": 446.684,
      "step": 911000
    },
    {
      "epoch": 9.644777446657598,
      "grad_norm": 1.382349967956543,
      "learning_rate": 1.965123269706187e-06,
      "loss": 0.4726,
      "step": 911050
    },
    {
      "epoch": 9.645306768437601,
      "grad_norm": 1.5238367319107056,
      "learning_rate": 1.959462592094313e-06,
      "loss": 0.4742,
      "step": 911100
    },
    {
      "epoch": 9.645836090217603,
      "grad_norm": 1.3740485906600952,
      "learning_rate": 1.9536947737837096e-06,
      "loss": 0.4692,
      "step": 911150
    },
    {
      "epoch": 9.646365411997607,
      "grad_norm": 1.400641679763794,
      "learning_rate": 1.9479354236829892e-06,
      "loss": 0.4623,
      "step": 911200
    },
    {
      "epoch": 9.64689473377761,
      "grad_norm": 1.3834302425384521,
      "learning_rate": 1.942184541988773e-06,
      "loss": 0.4653,
      "step": 911250
    },
    {
      "epoch": 9.647424055557615,
      "grad_norm": 1.4785454273223877,
      "learning_rate": 1.936442128897431e-06,
      "loss": 0.4611,
      "step": 911300
    },
    {
      "epoch": 9.647953377337616,
      "grad_norm": 1.3542258739471436,
      "learning_rate": 1.930708184604946e-06,
      "loss": 0.4611,
      "step": 911350
    },
    {
      "epoch": 9.64848269911762,
      "grad_norm": 1.547621250152588,
      "learning_rate": 1.9249827093071325e-06,
      "loss": 0.471,
      "step": 911400
    },
    {
      "epoch": 9.649012020897624,
      "grad_norm": 1.2539162635803223,
      "learning_rate": 1.919265703199419e-06,
      "loss": 0.4641,
      "step": 911450
    },
    {
      "epoch": 9.649541342677628,
      "grad_norm": 1.273316502571106,
      "learning_rate": 1.913557166477009e-06,
      "loss": 0.4594,
      "step": 911500
    },
    {
      "epoch": 9.649541342677628,
      "eval_loss": 0.28802621364593506,
      "eval_runtime": 46.844,
      "eval_samples_per_second": 3584.878,
      "eval_steps_per_second": 448.126,
      "step": 911500
    },
    {
      "epoch": 9.65007066445763,
      "grad_norm": 1.40223228931427,
      "learning_rate": 1.9078570993347477e-06,
      "loss": 0.4684,
      "step": 911550
    },
    {
      "epoch": 9.650599986237633,
      "grad_norm": 1.2860850095748901,
      "learning_rate": 1.9021655019672846e-06,
      "loss": 0.4659,
      "step": 911600
    },
    {
      "epoch": 9.651129308017637,
      "grad_norm": 1.4703123569488525,
      "learning_rate": 1.8964823745688809e-06,
      "loss": 0.4624,
      "step": 911650
    },
    {
      "epoch": 9.651658629797641,
      "grad_norm": 1.4970794916152954,
      "learning_rate": 1.8908077173336036e-06,
      "loss": 0.4619,
      "step": 911700
    },
    {
      "epoch": 9.652187951577643,
      "grad_norm": 1.4284793138504028,
      "learning_rate": 1.885141530455159e-06,
      "loss": 0.4633,
      "step": 911750
    },
    {
      "epoch": 9.652717273357647,
      "grad_norm": 1.3951841592788696,
      "learning_rate": 1.8794838141269754e-06,
      "loss": 0.4625,
      "step": 911800
    },
    {
      "epoch": 9.65324659513765,
      "grad_norm": 1.2527167797088623,
      "learning_rate": 1.8738345685422042e-06,
      "loss": 0.4711,
      "step": 911850
    },
    {
      "epoch": 9.653775916917654,
      "grad_norm": 1.4860554933547974,
      "learning_rate": 1.8681937938937466e-06,
      "loss": 0.4669,
      "step": 911900
    },
    {
      "epoch": 9.654305238697656,
      "grad_norm": 1.4210984706878662,
      "learning_rate": 1.8625614903741427e-06,
      "loss": 0.462,
      "step": 911950
    },
    {
      "epoch": 9.65483456047766,
      "grad_norm": 1.3908547163009644,
      "learning_rate": 1.8569376581757115e-06,
      "loss": 0.4615,
      "step": 912000
    },
    {
      "epoch": 9.65483456047766,
      "eval_loss": 0.2879931628704071,
      "eval_runtime": 46.8187,
      "eval_samples_per_second": 3586.812,
      "eval_steps_per_second": 448.368,
      "step": 912000
    },
    {
      "epoch": 9.655363882257664,
      "grad_norm": 1.3587177991867065,
      "learning_rate": 1.8513222974903822e-06,
      "loss": 0.4617,
      "step": 912050
    },
    {
      "epoch": 9.655893204037666,
      "grad_norm": 1.3599330186843872,
      "learning_rate": 1.845715408509946e-06,
      "loss": 0.4728,
      "step": 912100
    },
    {
      "epoch": 9.65642252581767,
      "grad_norm": 1.432321548461914,
      "learning_rate": 1.8401169914257498e-06,
      "loss": 0.4621,
      "step": 912150
    },
    {
      "epoch": 9.656951847597673,
      "grad_norm": 1.4512301683425903,
      "learning_rate": 1.8345270464289466e-06,
      "loss": 0.4656,
      "step": 912200
    },
    {
      "epoch": 9.657481169377677,
      "grad_norm": 1.4582449197769165,
      "learning_rate": 1.8289455737103833e-06,
      "loss": 0.4639,
      "step": 912250
    },
    {
      "epoch": 9.658010491157679,
      "grad_norm": 1.3419936895370483,
      "learning_rate": 1.8233725734606022e-06,
      "loss": 0.4653,
      "step": 912300
    },
    {
      "epoch": 9.658539812937683,
      "grad_norm": 1.4495857954025269,
      "learning_rate": 1.8178080458698675e-06,
      "loss": 0.4648,
      "step": 912350
    },
    {
      "epoch": 9.659069134717686,
      "grad_norm": 1.3876937627792358,
      "learning_rate": 1.8122519911281665e-06,
      "loss": 0.466,
      "step": 912400
    },
    {
      "epoch": 9.65959845649769,
      "grad_norm": 1.5145035982131958,
      "learning_rate": 1.8067044094251527e-06,
      "loss": 0.4645,
      "step": 912450
    },
    {
      "epoch": 9.660127778277692,
      "grad_norm": 1.453830361366272,
      "learning_rate": 1.8011653009502305e-06,
      "loss": 0.4758,
      "step": 912500
    },
    {
      "epoch": 9.660127778277692,
      "eval_loss": 0.288015216588974,
      "eval_runtime": 46.9591,
      "eval_samples_per_second": 3576.091,
      "eval_steps_per_second": 447.027,
      "step": 912500
    },
    {
      "epoch": 9.660657100057696,
      "grad_norm": 1.4882087707519531,
      "learning_rate": 1.7956346658924704e-06,
      "loss": 0.4642,
      "step": 912550
    },
    {
      "epoch": 9.6611864218377,
      "grad_norm": 1.4545300006866455,
      "learning_rate": 1.7901125044407496e-06,
      "loss": 0.4686,
      "step": 912600
    },
    {
      "epoch": 9.661715743617703,
      "grad_norm": 1.3640027046203613,
      "learning_rate": 1.7845988167835558e-06,
      "loss": 0.4688,
      "step": 912650
    },
    {
      "epoch": 9.662245065397705,
      "grad_norm": 1.3182754516601562,
      "learning_rate": 1.7790936031091275e-06,
      "loss": 0.4766,
      "step": 912700
    },
    {
      "epoch": 9.66277438717771,
      "grad_norm": 1.4498299360275269,
      "learning_rate": 1.7735968636053977e-06,
      "loss": 0.4694,
      "step": 912750
    },
    {
      "epoch": 9.663303708957713,
      "grad_norm": 1.6413496732711792,
      "learning_rate": 1.7681085984600498e-06,
      "loss": 0.468,
      "step": 912800
    },
    {
      "epoch": 9.663833030737715,
      "grad_norm": 1.3560242652893066,
      "learning_rate": 1.7626288078604335e-06,
      "loss": 0.471,
      "step": 912850
    },
    {
      "epoch": 9.664362352517719,
      "grad_norm": 1.5590381622314453,
      "learning_rate": 1.7571574919936494e-06,
      "loss": 0.4687,
      "step": 912900
    },
    {
      "epoch": 9.664891674297722,
      "grad_norm": 1.333439826965332,
      "learning_rate": 1.7516946510464372e-06,
      "loss": 0.4666,
      "step": 912950
    },
    {
      "epoch": 9.665420996077726,
      "grad_norm": 1.3386406898498535,
      "learning_rate": 1.7462402852053416e-06,
      "loss": 0.4687,
      "step": 913000
    },
    {
      "epoch": 9.665420996077726,
      "eval_loss": 0.2880481779575348,
      "eval_runtime": 46.8435,
      "eval_samples_per_second": 3584.916,
      "eval_steps_per_second": 448.131,
      "step": 913000
    },
    {
      "epoch": 9.665950317857728,
      "grad_norm": 1.5637413263320923,
      "learning_rate": 1.7407943946565474e-06,
      "loss": 0.4631,
      "step": 913050
    },
    {
      "epoch": 9.666479639637732,
      "grad_norm": 1.4152015447616577,
      "learning_rate": 1.735356979585989e-06,
      "loss": 0.4744,
      "step": 913100
    },
    {
      "epoch": 9.667008961417736,
      "grad_norm": 1.325620412826538,
      "learning_rate": 1.7300365359047276e-06,
      "loss": 0.4697,
      "step": 913150
    },
    {
      "epoch": 9.66753828319774,
      "grad_norm": 1.4929802417755127,
      "learning_rate": 1.7246159028284635e-06,
      "loss": 0.4636,
      "step": 913200
    },
    {
      "epoch": 9.668067604977741,
      "grad_norm": 1.4372092485427856,
      "learning_rate": 1.7192037457827437e-06,
      "loss": 0.4625,
      "step": 913250
    },
    {
      "epoch": 9.668596926757745,
      "grad_norm": 1.4178998470306396,
      "learning_rate": 1.7138000649523367e-06,
      "loss": 0.4658,
      "step": 913300
    },
    {
      "epoch": 9.669126248537749,
      "grad_norm": 1.4060560464859009,
      "learning_rate": 1.7084048605217618e-06,
      "loss": 0.467,
      "step": 913350
    },
    {
      "epoch": 9.669655570317753,
      "grad_norm": 1.3139863014221191,
      "learning_rate": 1.7030181326751771e-06,
      "loss": 0.4685,
      "step": 913400
    },
    {
      "epoch": 9.670184892097755,
      "grad_norm": 1.5725336074829102,
      "learning_rate": 1.697639881596519e-06,
      "loss": 0.4679,
      "step": 913450
    },
    {
      "epoch": 9.670714213877758,
      "grad_norm": 1.368541955947876,
      "learning_rate": 1.6922701074693348e-06,
      "loss": 0.4609,
      "step": 913500
    },
    {
      "epoch": 9.670714213877758,
      "eval_loss": 0.28804296255111694,
      "eval_runtime": 46.9594,
      "eval_samples_per_second": 3576.069,
      "eval_steps_per_second": 447.025,
      "step": 913500
    },
    {
      "epoch": 9.671243535657762,
      "grad_norm": 1.3754903078079224,
      "learning_rate": 1.6869088104770058e-06,
      "loss": 0.4626,
      "step": 913550
    },
    {
      "epoch": 9.671772857437764,
      "grad_norm": 1.2655320167541504,
      "learning_rate": 1.6815559908025247e-06,
      "loss": 0.4629,
      "step": 913600
    },
    {
      "epoch": 9.672302179217768,
      "grad_norm": 1.5157294273376465,
      "learning_rate": 1.6762116486286893e-06,
      "loss": 0.4807,
      "step": 913650
    },
    {
      "epoch": 9.672831500997772,
      "grad_norm": 1.424802541732788,
      "learning_rate": 1.670875784137882e-06,
      "loss": 0.4632,
      "step": 913700
    },
    {
      "epoch": 9.673360822777775,
      "grad_norm": 1.3770984411239624,
      "learning_rate": 1.6655483975123176e-06,
      "loss": 0.4761,
      "step": 913750
    },
    {
      "epoch": 9.673890144557777,
      "grad_norm": 1.3059285879135132,
      "learning_rate": 1.6602294889338509e-06,
      "loss": 0.4718,
      "step": 913800
    },
    {
      "epoch": 9.674419466337781,
      "grad_norm": 1.499241590499878,
      "learning_rate": 1.6549190585840867e-06,
      "loss": 0.4579,
      "step": 913850
    },
    {
      "epoch": 9.674948788117785,
      "grad_norm": 1.37000572681427,
      "learning_rate": 1.6496171066442967e-06,
      "loss": 0.4664,
      "step": 913900
    },
    {
      "epoch": 9.675478109897789,
      "grad_norm": 1.5197323560714722,
      "learning_rate": 1.6443236332955024e-06,
      "loss": 0.4636,
      "step": 913950
    },
    {
      "epoch": 9.67600743167779,
      "grad_norm": 1.4704233407974243,
      "learning_rate": 1.6390386387184208e-06,
      "loss": 0.4687,
      "step": 914000
    },
    {
      "epoch": 9.67600743167779,
      "eval_loss": 0.2880552113056183,
      "eval_runtime": 46.8161,
      "eval_samples_per_second": 3587.017,
      "eval_steps_per_second": 448.393,
      "step": 914000
    },
    {
      "epoch": 9.676536753457794,
      "grad_norm": 1.3732738494873047,
      "learning_rate": 1.6337621230934907e-06,
      "loss": 0.4616,
      "step": 914050
    },
    {
      "epoch": 9.677066075237798,
      "grad_norm": 1.3770629167556763,
      "learning_rate": 1.6284940866007902e-06,
      "loss": 0.4637,
      "step": 914100
    },
    {
      "epoch": 9.677595397017802,
      "grad_norm": 1.1606078147888184,
      "learning_rate": 1.6232345294202588e-06,
      "loss": 0.4622,
      "step": 914150
    },
    {
      "epoch": 9.678124718797804,
      "grad_norm": 1.3811876773834229,
      "learning_rate": 1.6179834517313918e-06,
      "loss": 0.4699,
      "step": 914200
    },
    {
      "epoch": 9.678654040577808,
      "grad_norm": 1.4436126947402954,
      "learning_rate": 1.6127408537134625e-06,
      "loss": 0.4664,
      "step": 914250
    },
    {
      "epoch": 9.679183362357811,
      "grad_norm": 1.4357483386993408,
      "learning_rate": 1.6075067355454941e-06,
      "loss": 0.4694,
      "step": 914300
    },
    {
      "epoch": 9.679712684137815,
      "grad_norm": 1.4531437158584595,
      "learning_rate": 1.6022810974061498e-06,
      "loss": 0.477,
      "step": 914350
    },
    {
      "epoch": 9.680242005917817,
      "grad_norm": 1.336483120918274,
      "learning_rate": 1.597063939473814e-06,
      "loss": 0.4632,
      "step": 914400
    },
    {
      "epoch": 9.680771327697821,
      "grad_norm": 1.5152099132537842,
      "learning_rate": 1.5918552619266225e-06,
      "loss": 0.4651,
      "step": 914450
    },
    {
      "epoch": 9.681300649477825,
      "grad_norm": 1.2842881679534912,
      "learning_rate": 1.5866550649424049e-06,
      "loss": 0.4679,
      "step": 914500
    },
    {
      "epoch": 9.681300649477825,
      "eval_loss": 0.28806445002555847,
      "eval_runtime": 46.8888,
      "eval_samples_per_second": 3581.454,
      "eval_steps_per_second": 447.698,
      "step": 914500
    },
    {
      "epoch": 9.681829971257827,
      "grad_norm": 1.388776421546936,
      "learning_rate": 1.5814633486986584e-06,
      "loss": 0.4667,
      "step": 914550
    },
    {
      "epoch": 9.68235929303783,
      "grad_norm": 1.3346891403198242,
      "learning_rate": 1.5762801133726579e-06,
      "loss": 0.4618,
      "step": 914600
    },
    {
      "epoch": 9.682888614817834,
      "grad_norm": 1.2758870124816895,
      "learning_rate": 1.5711053591413727e-06,
      "loss": 0.4738,
      "step": 914650
    },
    {
      "epoch": 9.683417936597838,
      "grad_norm": 1.3923898935317993,
      "learning_rate": 1.5659390861814116e-06,
      "loss": 0.4605,
      "step": 914700
    },
    {
      "epoch": 9.68394725837784,
      "grad_norm": 1.371896505355835,
      "learning_rate": 1.5607812946691891e-06,
      "loss": 0.4677,
      "step": 914750
    },
    {
      "epoch": 9.684476580157844,
      "grad_norm": 1.3713446855545044,
      "learning_rate": 1.5556319847807587e-06,
      "loss": 0.4662,
      "step": 914800
    },
    {
      "epoch": 9.685005901937847,
      "grad_norm": 1.501752495765686,
      "learning_rate": 1.5504911566919799e-06,
      "loss": 0.4645,
      "step": 914850
    },
    {
      "epoch": 9.685535223717851,
      "grad_norm": 1.4541574716567993,
      "learning_rate": 1.5453588105782678e-06,
      "loss": 0.4576,
      "step": 914900
    },
    {
      "epoch": 9.686064545497853,
      "grad_norm": 1.3229725360870361,
      "learning_rate": 1.5402349466149269e-06,
      "loss": 0.4639,
      "step": 914950
    },
    {
      "epoch": 9.686593867277857,
      "grad_norm": 1.3297063112258911,
      "learning_rate": 1.5351195649768168e-06,
      "loss": 0.4617,
      "step": 915000
    },
    {
      "epoch": 9.686593867277857,
      "eval_loss": 0.288054883480072,
      "eval_runtime": 46.8643,
      "eval_samples_per_second": 3583.324,
      "eval_steps_per_second": 447.932,
      "step": 915000
    },
    {
      "epoch": 9.68712318905786,
      "grad_norm": 1.456297516822815,
      "learning_rate": 1.5300126658386315e-06,
      "loss": 0.4619,
      "step": 915050
    },
    {
      "epoch": 9.687652510837864,
      "grad_norm": 1.3250093460083008,
      "learning_rate": 1.5249142493746758e-06,
      "loss": 0.4598,
      "step": 915100
    },
    {
      "epoch": 9.688181832617866,
      "grad_norm": 1.399234652519226,
      "learning_rate": 1.519824315759033e-06,
      "loss": 0.4625,
      "step": 915150
    },
    {
      "epoch": 9.68871115439787,
      "grad_norm": 1.3751434087753296,
      "learning_rate": 1.5147428651654527e-06,
      "loss": 0.4635,
      "step": 915200
    },
    {
      "epoch": 9.689240476177874,
      "grad_norm": 1.4805183410644531,
      "learning_rate": 1.5096698977674073e-06,
      "loss": 0.4778,
      "step": 915250
    },
    {
      "epoch": 9.689769797957876,
      "grad_norm": 1.5307602882385254,
      "learning_rate": 1.5046054137381193e-06,
      "loss": 0.4678,
      "step": 915300
    },
    {
      "epoch": 9.69029911973788,
      "grad_norm": 1.4424231052398682,
      "learning_rate": 1.4995494132504505e-06,
      "loss": 0.4694,
      "step": 915350
    },
    {
      "epoch": 9.690828441517883,
      "grad_norm": 1.4714562892913818,
      "learning_rate": 1.4945018964770406e-06,
      "loss": 0.4705,
      "step": 915400
    },
    {
      "epoch": 9.691357763297887,
      "grad_norm": 1.3863976001739502,
      "learning_rate": 1.4894628635902242e-06,
      "loss": 0.4642,
      "step": 915450
    },
    {
      "epoch": 9.691887085077889,
      "grad_norm": 1.4232969284057617,
      "learning_rate": 1.4844323147619744e-06,
      "loss": 0.4677,
      "step": 915500
    },
    {
      "epoch": 9.691887085077889,
      "eval_loss": 0.28809526562690735,
      "eval_runtime": 46.7721,
      "eval_samples_per_second": 3590.388,
      "eval_steps_per_second": 448.814,
      "step": 915500
    },
    {
      "epoch": 9.692416406857893,
      "grad_norm": 1.5220775604248047,
      "learning_rate": 1.4794102501640706e-06,
      "loss": 0.4693,
      "step": 915550
    },
    {
      "epoch": 9.692945728637897,
      "grad_norm": 1.3845105171203613,
      "learning_rate": 1.4743966699679589e-06,
      "loss": 0.465,
      "step": 915600
    },
    {
      "epoch": 9.6934750504179,
      "grad_norm": 1.4381678104400635,
      "learning_rate": 1.4693915743448083e-06,
      "loss": 0.4686,
      "step": 915650
    },
    {
      "epoch": 9.694004372197902,
      "grad_norm": 1.1652369499206543,
      "learning_rate": 1.4643949634654818e-06,
      "loss": 0.4672,
      "step": 915700
    },
    {
      "epoch": 9.694533693977906,
      "grad_norm": 1.465213656425476,
      "learning_rate": 1.4594068375005654e-06,
      "loss": 0.4742,
      "step": 915750
    },
    {
      "epoch": 9.69506301575791,
      "grad_norm": 1.2868335247039795,
      "learning_rate": 1.4544271966203394e-06,
      "loss": 0.4599,
      "step": 915800
    },
    {
      "epoch": 9.695592337537914,
      "grad_norm": 1.348021388053894,
      "learning_rate": 1.4494560409948343e-06,
      "loss": 0.4662,
      "step": 915850
    },
    {
      "epoch": 9.696121659317916,
      "grad_norm": 1.3465330600738525,
      "learning_rate": 1.4444933707937203e-06,
      "loss": 0.4631,
      "step": 915900
    },
    {
      "epoch": 9.69665098109792,
      "grad_norm": 1.4170386791229248,
      "learning_rate": 1.4395391861864449e-06,
      "loss": 0.4754,
      "step": 915950
    },
    {
      "epoch": 9.697180302877923,
      "grad_norm": 1.2974241971969604,
      "learning_rate": 1.4345934873421784e-06,
      "loss": 0.4684,
      "step": 916000
    },
    {
      "epoch": 9.697180302877923,
      "eval_loss": 0.2881297767162323,
      "eval_runtime": 46.9217,
      "eval_samples_per_second": 3578.944,
      "eval_steps_per_second": 447.384,
      "step": 916000
    },
    {
      "epoch": 9.697709624657925,
      "grad_norm": 1.3282667398452759,
      "learning_rate": 1.4296562744297026e-06,
      "loss": 0.466,
      "step": 916050
    },
    {
      "epoch": 9.698238946437929,
      "grad_norm": 1.47676420211792,
      "learning_rate": 1.4247275476176047e-06,
      "loss": 0.4705,
      "step": 916100
    },
    {
      "epoch": 9.698768268217933,
      "grad_norm": 1.4928572177886963,
      "learning_rate": 1.419807307074167e-06,
      "loss": 0.473,
      "step": 916150
    },
    {
      "epoch": 9.699297589997936,
      "grad_norm": 1.399820327758789,
      "learning_rate": 1.414895552967338e-06,
      "loss": 0.4701,
      "step": 916200
    },
    {
      "epoch": 9.699826911777938,
      "grad_norm": 1.4676480293273926,
      "learning_rate": 1.4099922854647895e-06,
      "loss": 0.4683,
      "step": 916250
    },
    {
      "epoch": 9.700356233557942,
      "grad_norm": 1.425173282623291,
      "learning_rate": 1.4051953171771158e-06,
      "loss": 0.4624,
      "step": 916300
    },
    {
      "epoch": 9.700885555337946,
      "grad_norm": 1.3549273014068604,
      "learning_rate": 1.4003088536446717e-06,
      "loss": 0.4683,
      "step": 916350
    },
    {
      "epoch": 9.70141487711795,
      "grad_norm": 1.5883067846298218,
      "learning_rate": 1.3954308772144985e-06,
      "loss": 0.4717,
      "step": 916400
    },
    {
      "epoch": 9.701944198897952,
      "grad_norm": 1.2502342462539673,
      "learning_rate": 1.3905613880531577e-06,
      "loss": 0.4678,
      "step": 916450
    },
    {
      "epoch": 9.702473520677955,
      "grad_norm": 1.4960664510726929,
      "learning_rate": 1.3857003863268768e-06,
      "loss": 0.4733,
      "step": 916500
    },
    {
      "epoch": 9.702473520677955,
      "eval_loss": 0.28809452056884766,
      "eval_runtime": 46.6937,
      "eval_samples_per_second": 3596.42,
      "eval_steps_per_second": 449.569,
      "step": 916500
    },
    {
      "epoch": 9.703002842457959,
      "grad_norm": 1.3332158327102661,
      "learning_rate": 1.3808478722015794e-06,
      "loss": 0.4633,
      "step": 916550
    },
    {
      "epoch": 9.703532164237963,
      "grad_norm": 1.3653303384780884,
      "learning_rate": 1.3760038458429936e-06,
      "loss": 0.4663,
      "step": 916600
    },
    {
      "epoch": 9.704061486017965,
      "grad_norm": 1.3460359573364258,
      "learning_rate": 1.3711683074164317e-06,
      "loss": 0.4619,
      "step": 916650
    },
    {
      "epoch": 9.704590807797969,
      "grad_norm": 1.3558249473571777,
      "learning_rate": 1.3663412570870115e-06,
      "loss": 0.4761,
      "step": 916700
    },
    {
      "epoch": 9.705120129577972,
      "grad_norm": 1.3130794763565063,
      "learning_rate": 1.361522695019518e-06,
      "loss": 0.4702,
      "step": 916750
    },
    {
      "epoch": 9.705649451357974,
      "grad_norm": 1.4110556840896606,
      "learning_rate": 1.3567126213784586e-06,
      "loss": 0.4643,
      "step": 916800
    },
    {
      "epoch": 9.706178773137978,
      "grad_norm": 1.4260029792785645,
      "learning_rate": 1.351911036328035e-06,
      "loss": 0.4676,
      "step": 916850
    },
    {
      "epoch": 9.706708094917982,
      "grad_norm": 1.4850831031799316,
      "learning_rate": 1.347117940032172e-06,
      "loss": 0.4703,
      "step": 916900
    },
    {
      "epoch": 9.707237416697986,
      "grad_norm": 1.4787676334381104,
      "learning_rate": 1.3423333326545162e-06,
      "loss": 0.4763,
      "step": 916950
    },
    {
      "epoch": 9.707766738477988,
      "grad_norm": 1.3683794736862183,
      "learning_rate": 1.3375572143584092e-06,
      "loss": 0.4675,
      "step": 917000
    },
    {
      "epoch": 9.707766738477988,
      "eval_loss": 0.2881016135215759,
      "eval_runtime": 46.8784,
      "eval_samples_per_second": 3582.25,
      "eval_steps_per_second": 447.797,
      "step": 917000
    },
    {
      "epoch": 9.708296060257991,
      "grad_norm": 1.3661307096481323,
      "learning_rate": 1.332789585306915e-06,
      "loss": 0.4673,
      "step": 917050
    },
    {
      "epoch": 9.708825382037995,
      "grad_norm": 1.4101779460906982,
      "learning_rate": 1.3280304456627646e-06,
      "loss": 0.4659,
      "step": 917100
    },
    {
      "epoch": 9.709354703817999,
      "grad_norm": 1.4399659633636475,
      "learning_rate": 1.3232797955884668e-06,
      "loss": 0.4677,
      "step": 917150
    },
    {
      "epoch": 9.709884025598,
      "grad_norm": 1.3292756080627441,
      "learning_rate": 1.3185376352462253e-06,
      "loss": 0.4711,
      "step": 917200
    },
    {
      "epoch": 9.710413347378005,
      "grad_norm": 1.4434527158737183,
      "learning_rate": 1.3138039647978828e-06,
      "loss": 0.4663,
      "step": 917250
    },
    {
      "epoch": 9.710942669158008,
      "grad_norm": 1.3718805313110352,
      "learning_rate": 1.30907878440506e-06,
      "loss": 0.4692,
      "step": 917300
    },
    {
      "epoch": 9.711471990938012,
      "grad_norm": 1.413128137588501,
      "learning_rate": 1.3043620942291e-06,
      "loss": 0.463,
      "step": 917350
    },
    {
      "epoch": 9.712001312718014,
      "grad_norm": 1.3411078453063965,
      "learning_rate": 1.2996538944310132e-06,
      "loss": 0.4621,
      "step": 917400
    },
    {
      "epoch": 9.712530634498018,
      "grad_norm": 1.4342305660247803,
      "learning_rate": 1.2949541851715318e-06,
      "loss": 0.4647,
      "step": 917450
    },
    {
      "epoch": 9.713059956278022,
      "grad_norm": 1.3959360122680664,
      "learning_rate": 1.2902629666110833e-06,
      "loss": 0.4553,
      "step": 917500
    },
    {
      "epoch": 9.713059956278022,
      "eval_loss": 0.28810206055641174,
      "eval_runtime": 46.8658,
      "eval_samples_per_second": 3583.21,
      "eval_steps_per_second": 447.917,
      "step": 917500
    },
    {
      "epoch": 9.713589278058024,
      "grad_norm": 1.4240630865097046,
      "learning_rate": 1.2855802389098725e-06,
      "loss": 0.4702,
      "step": 917550
    },
    {
      "epoch": 9.714118599838027,
      "grad_norm": 1.4091109037399292,
      "learning_rate": 1.2809060022277164e-06,
      "loss": 0.4687,
      "step": 917600
    },
    {
      "epoch": 9.714647921618031,
      "grad_norm": 1.2727960348129272,
      "learning_rate": 1.276240256724237e-06,
      "loss": 0.4701,
      "step": 917650
    },
    {
      "epoch": 9.715177243398035,
      "grad_norm": 1.4224257469177246,
      "learning_rate": 1.2715830025586684e-06,
      "loss": 0.4684,
      "step": 917700
    },
    {
      "epoch": 9.715706565178037,
      "grad_norm": 1.3660699129104614,
      "learning_rate": 1.2669342398900774e-06,
      "loss": 0.465,
      "step": 917750
    },
    {
      "epoch": 9.71623588695804,
      "grad_norm": 1.4454922676086426,
      "learning_rate": 1.2622939688770873e-06,
      "loss": 0.4792,
      "step": 917800
    },
    {
      "epoch": 9.716765208738044,
      "grad_norm": 1.3272231817245483,
      "learning_rate": 1.2576621896782104e-06,
      "loss": 0.4651,
      "step": 917850
    },
    {
      "epoch": 9.717294530518048,
      "grad_norm": 1.4093364477157593,
      "learning_rate": 1.2530389024514866e-06,
      "loss": 0.4729,
      "step": 917900
    },
    {
      "epoch": 9.71782385229805,
      "grad_norm": 1.408831000328064,
      "learning_rate": 1.2484241073547898e-06,
      "loss": 0.4726,
      "step": 917950
    },
    {
      "epoch": 9.718353174078054,
      "grad_norm": 1.5230330228805542,
      "learning_rate": 1.2438178045456883e-06,
      "loss": 0.4581,
      "step": 918000
    },
    {
      "epoch": 9.718353174078054,
      "eval_loss": 0.28806230425834656,
      "eval_runtime": 46.921,
      "eval_samples_per_second": 3578.998,
      "eval_steps_per_second": 447.391,
      "step": 918000
    },
    {
      "epoch": 9.718882495858058,
      "grad_norm": 1.3431928157806396,
      "learning_rate": 1.2392199941813898e-06,
      "loss": 0.4632,
      "step": 918050
    },
    {
      "epoch": 9.719411817638061,
      "grad_norm": 1.3464983701705933,
      "learning_rate": 1.2346306764189075e-06,
      "loss": 0.4678,
      "step": 918100
    },
    {
      "epoch": 9.719941139418063,
      "grad_norm": 1.3640897274017334,
      "learning_rate": 1.2300498514148939e-06,
      "loss": 0.4678,
      "step": 918150
    },
    {
      "epoch": 9.720470461198067,
      "grad_norm": 1.3229601383209229,
      "learning_rate": 1.2254775193257518e-06,
      "loss": 0.4635,
      "step": 918200
    },
    {
      "epoch": 9.72099978297807,
      "grad_norm": 1.4705774784088135,
      "learning_rate": 1.2209136803075783e-06,
      "loss": 0.4696,
      "step": 918250
    },
    {
      "epoch": 9.721529104758073,
      "grad_norm": 1.549288272857666,
      "learning_rate": 1.2163583345161655e-06,
      "loss": 0.4648,
      "step": 918300
    },
    {
      "epoch": 9.722058426538077,
      "grad_norm": 1.6154834032058716,
      "learning_rate": 1.211811482107028e-06,
      "loss": 0.4653,
      "step": 918350
    },
    {
      "epoch": 9.72258774831808,
      "grad_norm": 1.4043145179748535,
      "learning_rate": 1.2073638071752047e-06,
      "loss": 0.4743,
      "step": 918400
    },
    {
      "epoch": 9.723117070098084,
      "grad_norm": 1.2802753448486328,
      "learning_rate": 1.2028337721206595e-06,
      "loss": 0.4684,
      "step": 918450
    },
    {
      "epoch": 9.723646391878086,
      "grad_norm": 1.314953327178955,
      "learning_rate": 1.198312230910159e-06,
      "loss": 0.4667,
      "step": 918500
    },
    {
      "epoch": 9.723646391878086,
      "eval_loss": 0.2880292236804962,
      "eval_runtime": 46.9197,
      "eval_samples_per_second": 3579.095,
      "eval_steps_per_second": 447.403,
      "step": 918500
    },
    {
      "epoch": 9.72417571365809,
      "grad_norm": 1.422987699508667,
      "learning_rate": 1.1937991836980244e-06,
      "loss": 0.4591,
      "step": 918550
    },
    {
      "epoch": 9.724705035438094,
      "grad_norm": 1.5162252187728882,
      "learning_rate": 1.1892946306383268e-06,
      "loss": 0.4615,
      "step": 918600
    },
    {
      "epoch": 9.725234357218097,
      "grad_norm": 1.5144656896591187,
      "learning_rate": 1.1847985718848876e-06,
      "loss": 0.4605,
      "step": 918650
    },
    {
      "epoch": 9.7257636789981,
      "grad_norm": 1.2711533308029175,
      "learning_rate": 1.1803110075911671e-06,
      "loss": 0.4684,
      "step": 918700
    },
    {
      "epoch": 9.726293000778103,
      "grad_norm": 1.345794439315796,
      "learning_rate": 1.1758319379103488e-06,
      "loss": 0.464,
      "step": 918750
    },
    {
      "epoch": 9.726822322558107,
      "grad_norm": 1.3977274894714355,
      "learning_rate": 1.1713613629953935e-06,
      "loss": 0.4634,
      "step": 918800
    },
    {
      "epoch": 9.72735164433811,
      "grad_norm": 1.426193356513977,
      "learning_rate": 1.1668992829989012e-06,
      "loss": 0.4657,
      "step": 918850
    },
    {
      "epoch": 9.727880966118112,
      "grad_norm": 1.4903334379196167,
      "learning_rate": 1.16244569807325e-06,
      "loss": 0.4709,
      "step": 918900
    },
    {
      "epoch": 9.728410287898116,
      "grad_norm": 1.3853237628936768,
      "learning_rate": 1.158000608370402e-06,
      "loss": 0.4706,
      "step": 918950
    },
    {
      "epoch": 9.72893960967812,
      "grad_norm": 1.3166738748550415,
      "learning_rate": 1.1535640140421521e-06,
      "loss": 0.4611,
      "step": 919000
    },
    {
      "epoch": 9.72893960967812,
      "eval_loss": 0.2879895567893982,
      "eval_runtime": 46.8334,
      "eval_samples_per_second": 3585.686,
      "eval_steps_per_second": 448.227,
      "step": 919000
    },
    {
      "epoch": 9.729468931458122,
      "grad_norm": 1.4710941314697266,
      "learning_rate": 1.1491359152399906e-06,
      "loss": 0.466,
      "step": 919050
    },
    {
      "epoch": 9.729998253238126,
      "grad_norm": 1.5601580142974854,
      "learning_rate": 1.144716312115046e-06,
      "loss": 0.4678,
      "step": 919100
    },
    {
      "epoch": 9.73052757501813,
      "grad_norm": 1.3002992868423462,
      "learning_rate": 1.1403052048182261e-06,
      "loss": 0.4675,
      "step": 919150
    },
    {
      "epoch": 9.731056896798133,
      "grad_norm": 1.3183510303497314,
      "learning_rate": 1.1359025935001043e-06,
      "loss": 0.4696,
      "step": 919200
    },
    {
      "epoch": 9.731586218578135,
      "grad_norm": 1.4489775896072388,
      "learning_rate": 1.131508478311033e-06,
      "loss": 0.4663,
      "step": 919250
    },
    {
      "epoch": 9.732115540358139,
      "grad_norm": 1.4360699653625488,
      "learning_rate": 1.1271228594009752e-06,
      "loss": 0.4663,
      "step": 919300
    },
    {
      "epoch": 9.732644862138143,
      "grad_norm": 1.2332563400268555,
      "learning_rate": 1.1227457369196725e-06,
      "loss": 0.4642,
      "step": 919350
    },
    {
      "epoch": 9.733174183918146,
      "grad_norm": 1.2834445238113403,
      "learning_rate": 1.1183771110165608e-06,
      "loss": 0.4613,
      "step": 919400
    },
    {
      "epoch": 9.733703505698148,
      "grad_norm": 1.430104374885559,
      "learning_rate": 1.1140169818407708e-06,
      "loss": 0.461,
      "step": 919450
    },
    {
      "epoch": 9.734232827478152,
      "grad_norm": 1.3646527528762817,
      "learning_rate": 1.1096653495411557e-06,
      "loss": 0.4596,
      "step": 919500
    },
    {
      "epoch": 9.734232827478152,
      "eval_loss": 0.28793269395828247,
      "eval_runtime": 46.9644,
      "eval_samples_per_second": 3575.684,
      "eval_steps_per_second": 446.976,
      "step": 919500
    },
    {
      "epoch": 9.734762149258156,
      "grad_norm": 1.2933261394500732,
      "learning_rate": 1.105322214266291e-06,
      "loss": 0.4673,
      "step": 919550
    },
    {
      "epoch": 9.73529147103816,
      "grad_norm": 1.3245904445648193,
      "learning_rate": 1.100987576164475e-06,
      "loss": 0.4679,
      "step": 919600
    },
    {
      "epoch": 9.735820792818162,
      "grad_norm": 1.5379242897033691,
      "learning_rate": 1.0966614353836445e-06,
      "loss": 0.4682,
      "step": 919650
    },
    {
      "epoch": 9.736350114598165,
      "grad_norm": 1.3199166059494019,
      "learning_rate": 1.0923437920714874e-06,
      "loss": 0.4686,
      "step": 919700
    },
    {
      "epoch": 9.73687943637817,
      "grad_norm": 1.431992769241333,
      "learning_rate": 1.0880346463754686e-06,
      "loss": 0.4715,
      "step": 919750
    },
    {
      "epoch": 9.737408758158171,
      "grad_norm": 1.3313630819320679,
      "learning_rate": 1.0837339984426376e-06,
      "loss": 0.4674,
      "step": 919800
    },
    {
      "epoch": 9.737938079938175,
      "grad_norm": 1.4831546545028687,
      "learning_rate": 1.0794418484198488e-06,
      "loss": 0.4682,
      "step": 919850
    },
    {
      "epoch": 9.738467401718179,
      "grad_norm": 1.345848560333252,
      "learning_rate": 1.075158196453624e-06,
      "loss": 0.4664,
      "step": 919900
    },
    {
      "epoch": 9.738996723498182,
      "grad_norm": 1.4683598279953003,
      "learning_rate": 1.0708830426902072e-06,
      "loss": 0.4618,
      "step": 919950
    },
    {
      "epoch": 9.739526045278184,
      "grad_norm": 1.4763213396072388,
      "learning_rate": 1.0666163872755374e-06,
      "loss": 0.4653,
      "step": 920000
    },
    {
      "epoch": 9.739526045278184,
      "eval_loss": 0.2879127562046051,
      "eval_runtime": 46.7279,
      "eval_samples_per_second": 3593.787,
      "eval_steps_per_second": 449.239,
      "step": 920000
    },
    {
      "epoch": 9.740055367058188,
      "grad_norm": 1.2983176708221436,
      "learning_rate": 1.0623582303553037e-06,
      "loss": 0.4674,
      "step": 920050
    },
    {
      "epoch": 9.740584688838192,
      "grad_norm": 1.3588707447052002,
      "learning_rate": 1.0581085720748617e-06,
      "loss": 0.4641,
      "step": 920100
    },
    {
      "epoch": 9.741114010618196,
      "grad_norm": 1.372111201286316,
      "learning_rate": 1.0538674125792902e-06,
      "loss": 0.4645,
      "step": 920150
    },
    {
      "epoch": 9.741643332398198,
      "grad_norm": 1.3698458671569824,
      "learning_rate": 1.0496347520133898e-06,
      "loss": 0.4703,
      "step": 920200
    },
    {
      "epoch": 9.742172654178201,
      "grad_norm": 1.534568428993225,
      "learning_rate": 1.0454105905216838e-06,
      "loss": 0.4564,
      "step": 920250
    },
    {
      "epoch": 9.742701975958205,
      "grad_norm": 1.2845616340637207,
      "learning_rate": 1.0411949282483347e-06,
      "loss": 0.4627,
      "step": 920300
    },
    {
      "epoch": 9.743231297738209,
      "grad_norm": 1.484076738357544,
      "learning_rate": 1.0369877653372828e-06,
      "loss": 0.4692,
      "step": 920350
    },
    {
      "epoch": 9.743760619518211,
      "grad_norm": 1.3240468502044678,
      "learning_rate": 1.0327891019321911e-06,
      "loss": 0.4646,
      "step": 920400
    },
    {
      "epoch": 9.744289941298215,
      "grad_norm": 1.3318166732788086,
      "learning_rate": 1.0285989381763338e-06,
      "loss": 0.4566,
      "step": 920450
    },
    {
      "epoch": 9.744819263078218,
      "grad_norm": 1.4818005561828613,
      "learning_rate": 1.0244172742128465e-06,
      "loss": 0.4622,
      "step": 920500
    },
    {
      "epoch": 9.744819263078218,
      "eval_loss": 0.28786927461624146,
      "eval_runtime": 46.8912,
      "eval_samples_per_second": 3581.271,
      "eval_steps_per_second": 447.675,
      "step": 920500
    },
    {
      "epoch": 9.74534858485822,
      "grad_norm": 1.2774296998977661,
      "learning_rate": 1.0202441101843928e-06,
      "loss": 0.4642,
      "step": 920550
    },
    {
      "epoch": 9.745877906638224,
      "grad_norm": 1.4082868099212646,
      "learning_rate": 1.0160794462335531e-06,
      "loss": 0.4723,
      "step": 920600
    },
    {
      "epoch": 9.746407228418228,
      "grad_norm": 1.2707502841949463,
      "learning_rate": 1.0120063224739461e-06,
      "loss": 0.4586,
      "step": 920650
    },
    {
      "epoch": 9.746936550198232,
      "grad_norm": 1.4297937154769897,
      "learning_rate": 1.0078584890958198e-06,
      "loss": 0.4637,
      "step": 920700
    },
    {
      "epoch": 9.747465871978234,
      "grad_norm": 1.3103116750717163,
      "learning_rate": 1.0037191562180803e-06,
      "loss": 0.4616,
      "step": 920750
    },
    {
      "epoch": 9.747995193758237,
      "grad_norm": 1.2773534059524536,
      "learning_rate": 9.995883239820591e-07,
      "loss": 0.4697,
      "step": 920800
    },
    {
      "epoch": 9.748524515538241,
      "grad_norm": 1.3005609512329102,
      "learning_rate": 9.954659925287823e-07,
      "loss": 0.4585,
      "step": 920850
    },
    {
      "epoch": 9.749053837318245,
      "grad_norm": 1.1932626962661743,
      "learning_rate": 9.913521619989707e-07,
      "loss": 0.4598,
      "step": 920900
    },
    {
      "epoch": 9.749583159098247,
      "grad_norm": 1.3985012769699097,
      "learning_rate": 9.872468325330674e-07,
      "loss": 0.4727,
      "step": 920950
    },
    {
      "epoch": 9.75011248087825,
      "grad_norm": 1.5576813220977783,
      "learning_rate": 9.831500042712382e-07,
      "loss": 0.4682,
      "step": 921000
    },
    {
      "epoch": 9.75011248087825,
      "eval_loss": 0.28787970542907715,
      "eval_runtime": 46.8786,
      "eval_samples_per_second": 3582.232,
      "eval_steps_per_second": 447.795,
      "step": 921000
    },
    {
      "epoch": 9.750641802658254,
      "grad_norm": 1.51565420627594,
      "learning_rate": 9.790616773533435e-07,
      "loss": 0.4613,
      "step": 921050
    },
    {
      "epoch": 9.751171124438258,
      "grad_norm": 1.3626179695129395,
      "learning_rate": 9.74981851918938e-07,
      "loss": 0.4605,
      "step": 921100
    },
    {
      "epoch": 9.75170044621826,
      "grad_norm": 1.401426076889038,
      "learning_rate": 9.709105281073548e-07,
      "loss": 0.4648,
      "step": 921150
    },
    {
      "epoch": 9.752229767998264,
      "grad_norm": 1.5494182109832764,
      "learning_rate": 9.668477060575388e-07,
      "loss": 0.4721,
      "step": 921200
    },
    {
      "epoch": 9.752759089778268,
      "grad_norm": 1.3624736070632935,
      "learning_rate": 9.627933859082395e-07,
      "loss": 0.4702,
      "step": 921250
    },
    {
      "epoch": 9.75328841155827,
      "grad_norm": 1.3997786045074463,
      "learning_rate": 9.587475677978185e-07,
      "loss": 0.4672,
      "step": 921300
    },
    {
      "epoch": 9.753817733338273,
      "grad_norm": 1.467897891998291,
      "learning_rate": 9.547102518644157e-07,
      "loss": 0.4588,
      "step": 921350
    },
    {
      "epoch": 9.754347055118277,
      "grad_norm": 1.4654240608215332,
      "learning_rate": 9.506814382458928e-07,
      "loss": 0.4656,
      "step": 921400
    },
    {
      "epoch": 9.754876376898281,
      "grad_norm": 1.3516911268234253,
      "learning_rate": 9.466611270797509e-07,
      "loss": 0.4727,
      "step": 921450
    },
    {
      "epoch": 9.755405698678283,
      "grad_norm": 1.4107288122177124,
      "learning_rate": 9.426493185032692e-07,
      "loss": 0.4647,
      "step": 921500
    },
    {
      "epoch": 9.755405698678283,
      "eval_loss": 0.28786659240722656,
      "eval_runtime": 46.9825,
      "eval_samples_per_second": 3574.313,
      "eval_steps_per_second": 446.805,
      "step": 921500
    },
    {
      "epoch": 9.755935020458287,
      "grad_norm": 1.3276714086532593,
      "learning_rate": 9.386460126533935e-07,
      "loss": 0.4686,
      "step": 921550
    },
    {
      "epoch": 9.75646434223829,
      "grad_norm": 1.288376808166504,
      "learning_rate": 9.346512096667926e-07,
      "loss": 0.4583,
      "step": 921600
    },
    {
      "epoch": 9.756993664018294,
      "grad_norm": 1.3615291118621826,
      "learning_rate": 9.306649096798847e-07,
      "loss": 0.4644,
      "step": 921650
    },
    {
      "epoch": 9.757522985798296,
      "grad_norm": 1.3919695615768433,
      "learning_rate": 9.266871128287279e-07,
      "loss": 0.4706,
      "step": 921700
    },
    {
      "epoch": 9.7580523075783,
      "grad_norm": 1.4926084280014038,
      "learning_rate": 9.227178192491026e-07,
      "loss": 0.4653,
      "step": 921750
    },
    {
      "epoch": 9.758581629358304,
      "grad_norm": 1.3037757873535156,
      "learning_rate": 9.187570290765668e-07,
      "loss": 0.4663,
      "step": 921800
    },
    {
      "epoch": 9.759110951138307,
      "grad_norm": 1.320913314819336,
      "learning_rate": 9.148047424463179e-07,
      "loss": 0.4679,
      "step": 921850
    },
    {
      "epoch": 9.75964027291831,
      "grad_norm": 1.3483057022094727,
      "learning_rate": 9.10860959493276e-07,
      "loss": 0.4708,
      "step": 921900
    },
    {
      "epoch": 9.760169594698313,
      "grad_norm": 1.2539585828781128,
      "learning_rate": 9.069256803521109e-07,
      "loss": 0.4585,
      "step": 921950
    },
    {
      "epoch": 9.760698916478317,
      "grad_norm": 1.3265751600265503,
      "learning_rate": 9.029989051571319e-07,
      "loss": 0.4706,
      "step": 922000
    },
    {
      "epoch": 9.760698916478317,
      "eval_loss": 0.28786709904670715,
      "eval_runtime": 46.8644,
      "eval_samples_per_second": 3583.318,
      "eval_steps_per_second": 447.931,
      "step": 922000
    },
    {
      "epoch": 9.761228238258319,
      "grad_norm": 1.362927794456482,
      "learning_rate": 8.990806340424262e-07,
      "loss": 0.4647,
      "step": 922050
    },
    {
      "epoch": 9.761757560038323,
      "grad_norm": 1.3730571269989014,
      "learning_rate": 8.951708671417203e-07,
      "loss": 0.4585,
      "step": 922100
    },
    {
      "epoch": 9.762286881818326,
      "grad_norm": 1.4345628023147583,
      "learning_rate": 8.912696045885738e-07,
      "loss": 0.4679,
      "step": 922150
    },
    {
      "epoch": 9.76281620359833,
      "grad_norm": 1.3299169540405273,
      "learning_rate": 8.873768465160748e-07,
      "loss": 0.4672,
      "step": 922200
    },
    {
      "epoch": 9.763345525378332,
      "grad_norm": 1.4622536897659302,
      "learning_rate": 8.834925930572001e-07,
      "loss": 0.4646,
      "step": 922250
    },
    {
      "epoch": 9.763874847158336,
      "grad_norm": 1.336005449295044,
      "learning_rate": 8.796168443445385e-07,
      "loss": 0.4585,
      "step": 922300
    },
    {
      "epoch": 9.76440416893834,
      "grad_norm": 1.32917058467865,
      "learning_rate": 8.757496005103727e-07,
      "loss": 0.46,
      "step": 922350
    },
    {
      "epoch": 9.764933490718343,
      "grad_norm": 1.4219872951507568,
      "learning_rate": 8.718908616867638e-07,
      "loss": 0.4731,
      "step": 922400
    },
    {
      "epoch": 9.765462812498345,
      "grad_norm": 1.4727296829223633,
      "learning_rate": 8.680406280054121e-07,
      "loss": 0.4655,
      "step": 922450
    },
    {
      "epoch": 9.76599213427835,
      "grad_norm": 1.459338665008545,
      "learning_rate": 8.641988995978234e-07,
      "loss": 0.4621,
      "step": 922500
    },
    {
      "epoch": 9.76599213427835,
      "eval_loss": 0.28785496950149536,
      "eval_runtime": 46.7841,
      "eval_samples_per_second": 3589.469,
      "eval_steps_per_second": 448.7,
      "step": 922500
    },
    {
      "epoch": 9.766521456058353,
      "grad_norm": 1.4135087728500366,
      "learning_rate": 8.603656765950874e-07,
      "loss": 0.4682,
      "step": 922550
    },
    {
      "epoch": 9.767050777838357,
      "grad_norm": 1.3663969039916992,
      "learning_rate": 8.56540959128127e-07,
      "loss": 0.463,
      "step": 922600
    },
    {
      "epoch": 9.767580099618359,
      "grad_norm": 1.3787388801574707,
      "learning_rate": 8.527247473274768e-07,
      "loss": 0.4678,
      "step": 922650
    },
    {
      "epoch": 9.768109421398362,
      "grad_norm": 1.3041642904281616,
      "learning_rate": 8.489170413234216e-07,
      "loss": 0.4648,
      "step": 922700
    },
    {
      "epoch": 9.768638743178366,
      "grad_norm": 1.484110713005066,
      "learning_rate": 8.451178412459681e-07,
      "loss": 0.4603,
      "step": 922750
    },
    {
      "epoch": 9.769168064958368,
      "grad_norm": 1.1499522924423218,
      "learning_rate": 8.413271472248185e-07,
      "loss": 0.4591,
      "step": 922800
    },
    {
      "epoch": 9.769697386738372,
      "grad_norm": 1.409698724746704,
      "learning_rate": 8.375449593893691e-07,
      "loss": 0.4609,
      "step": 922850
    },
    {
      "epoch": 9.770226708518376,
      "grad_norm": 1.4544588327407837,
      "learning_rate": 8.337712778687667e-07,
      "loss": 0.4634,
      "step": 922900
    },
    {
      "epoch": 9.77075603029838,
      "grad_norm": 1.3943707942962646,
      "learning_rate": 8.300061027918527e-07,
      "loss": 0.4708,
      "step": 922950
    },
    {
      "epoch": 9.771285352078381,
      "grad_norm": 1.4413728713989258,
      "learning_rate": 8.262494342871352e-07,
      "loss": 0.4567,
      "step": 923000
    },
    {
      "epoch": 9.771285352078381,
      "eval_loss": 0.2878359854221344,
      "eval_runtime": 46.903,
      "eval_samples_per_second": 3580.365,
      "eval_steps_per_second": 447.562,
      "step": 923000
    },
    {
      "epoch": 9.771814673858385,
      "grad_norm": 1.3707258701324463,
      "learning_rate": 8.225761523524556e-07,
      "loss": 0.4676,
      "step": 923050
    },
    {
      "epoch": 9.772343995638389,
      "grad_norm": 1.446930170059204,
      "learning_rate": 8.188363272388088e-07,
      "loss": 0.4636,
      "step": 923100
    },
    {
      "epoch": 9.772873317418393,
      "grad_norm": 1.504213809967041,
      "learning_rate": 8.151050090786926e-07,
      "loss": 0.4595,
      "step": 923150
    },
    {
      "epoch": 9.773402639198395,
      "grad_norm": 1.2980732917785645,
      "learning_rate": 8.113821979995051e-07,
      "loss": 0.4739,
      "step": 923200
    },
    {
      "epoch": 9.773931960978398,
      "grad_norm": 1.3328797817230225,
      "learning_rate": 8.076678941283666e-07,
      "loss": 0.4624,
      "step": 923250
    },
    {
      "epoch": 9.774461282758402,
      "grad_norm": 1.462593674659729,
      "learning_rate": 8.03962097592037e-07,
      "loss": 0.4676,
      "step": 923300
    },
    {
      "epoch": 9.774990604538406,
      "grad_norm": 1.3371407985687256,
      "learning_rate": 8.002648085170538e-07,
      "loss": 0.468,
      "step": 923350
    },
    {
      "epoch": 9.775519926318408,
      "grad_norm": 1.3904402256011963,
      "learning_rate": 7.965760270296496e-07,
      "loss": 0.4677,
      "step": 923400
    },
    {
      "epoch": 9.776049248098412,
      "grad_norm": 1.519310474395752,
      "learning_rate": 7.928957532557235e-07,
      "loss": 0.4642,
      "step": 923450
    },
    {
      "epoch": 9.776578569878415,
      "grad_norm": 1.5224738121032715,
      "learning_rate": 7.892239873209528e-07,
      "loss": 0.464,
      "step": 923500
    },
    {
      "epoch": 9.776578569878415,
      "eval_loss": 0.2878410220146179,
      "eval_runtime": 46.8723,
      "eval_samples_per_second": 3582.715,
      "eval_steps_per_second": 447.855,
      "step": 923500
    },
    {
      "epoch": 9.777107891658417,
      "grad_norm": 1.4564664363861084,
      "learning_rate": 7.855607293506817e-07,
      "loss": 0.4661,
      "step": 923550
    },
    {
      "epoch": 9.777637213438421,
      "grad_norm": 1.5013530254364014,
      "learning_rate": 7.819059794699767e-07,
      "loss": 0.4796,
      "step": 923600
    },
    {
      "epoch": 9.778166535218425,
      "grad_norm": 1.4961823225021362,
      "learning_rate": 7.782597378035994e-07,
      "loss": 0.4692,
      "step": 923650
    },
    {
      "epoch": 9.778695856998429,
      "grad_norm": 1.3899809122085571,
      "learning_rate": 7.746220044760333e-07,
      "loss": 0.4669,
      "step": 923700
    },
    {
      "epoch": 9.77922517877843,
      "grad_norm": 1.403257131576538,
      "learning_rate": 7.709927796114846e-07,
      "loss": 0.4609,
      "step": 923750
    },
    {
      "epoch": 9.779754500558434,
      "grad_norm": 1.2808936834335327,
      "learning_rate": 7.673720633337988e-07,
      "loss": 0.4697,
      "step": 923800
    },
    {
      "epoch": 9.780283822338438,
      "grad_norm": 1.3851069211959839,
      "learning_rate": 7.637598557666825e-07,
      "loss": 0.4749,
      "step": 923850
    },
    {
      "epoch": 9.780813144118442,
      "grad_norm": 1.3609615564346313,
      "learning_rate": 7.601561570333704e-07,
      "loss": 0.4606,
      "step": 923900
    },
    {
      "epoch": 9.781342465898444,
      "grad_norm": 1.439656138420105,
      "learning_rate": 7.565609672569307e-07,
      "loss": 0.4704,
      "step": 923950
    },
    {
      "epoch": 9.781871787678448,
      "grad_norm": 1.330759882926941,
      "learning_rate": 7.529742865600708e-07,
      "loss": 0.4669,
      "step": 924000
    },
    {
      "epoch": 9.781871787678448,
      "eval_loss": 0.2878507673740387,
      "eval_runtime": 47.0129,
      "eval_samples_per_second": 3571.999,
      "eval_steps_per_second": 446.516,
      "step": 924000
    },
    {
      "epoch": 9.782401109458451,
      "grad_norm": 1.3481565713882446,
      "learning_rate": 7.493961150652761e-07,
      "loss": 0.4659,
      "step": 924050
    },
    {
      "epoch": 9.782930431238455,
      "grad_norm": 1.3076344728469849,
      "learning_rate": 7.458264528946712e-07,
      "loss": 0.473,
      "step": 924100
    },
    {
      "epoch": 9.783459753018457,
      "grad_norm": 1.1852197647094727,
      "learning_rate": 7.422653001701584e-07,
      "loss": 0.4668,
      "step": 924150
    },
    {
      "epoch": 9.78398907479846,
      "grad_norm": 1.3994117975234985,
      "learning_rate": 7.387126570133074e-07,
      "loss": 0.4686,
      "step": 924200
    },
    {
      "epoch": 9.784518396578465,
      "grad_norm": 1.1570274829864502,
      "learning_rate": 7.35168523545382e-07,
      "loss": 0.4634,
      "step": 924250
    },
    {
      "epoch": 9.785047718358467,
      "grad_norm": 1.3710672855377197,
      "learning_rate": 7.316328998873689e-07,
      "loss": 0.4671,
      "step": 924300
    },
    {
      "epoch": 9.78557704013847,
      "grad_norm": 1.434680461883545,
      "learning_rate": 7.281057861600049e-07,
      "loss": 0.47,
      "step": 924350
    },
    {
      "epoch": 9.786106361918474,
      "grad_norm": 1.5206042528152466,
      "learning_rate": 7.245871824836936e-07,
      "loss": 0.4689,
      "step": 924400
    },
    {
      "epoch": 9.786635683698478,
      "grad_norm": 1.3811758756637573,
      "learning_rate": 7.210770889785611e-07,
      "loss": 0.4633,
      "step": 924450
    },
    {
      "epoch": 9.78716500547848,
      "grad_norm": 1.4520130157470703,
      "learning_rate": 7.175755057644284e-07,
      "loss": 0.4736,
      "step": 924500
    },
    {
      "epoch": 9.78716500547848,
      "eval_loss": 0.28785035014152527,
      "eval_runtime": 46.8759,
      "eval_samples_per_second": 3582.437,
      "eval_steps_per_second": 447.821,
      "step": 924500
    },
    {
      "epoch": 9.787694327258484,
      "grad_norm": 1.3699945211410522,
      "learning_rate": 7.140824329608387e-07,
      "loss": 0.4618,
      "step": 924550
    },
    {
      "epoch": 9.788223649038487,
      "grad_norm": 1.4255259037017822,
      "learning_rate": 7.105978706870853e-07,
      "loss": 0.4712,
      "step": 924600
    },
    {
      "epoch": 9.788752970818491,
      "grad_norm": 1.3348006010055542,
      "learning_rate": 7.071218190620454e-07,
      "loss": 0.4537,
      "step": 924650
    },
    {
      "epoch": 9.789282292598493,
      "grad_norm": 1.3833274841308594,
      "learning_rate": 7.036542782044853e-07,
      "loss": 0.4647,
      "step": 924700
    },
    {
      "epoch": 9.789811614378497,
      "grad_norm": 1.3478590250015259,
      "learning_rate": 7.001952482327268e-07,
      "loss": 0.4693,
      "step": 924750
    },
    {
      "epoch": 9.7903409361585,
      "grad_norm": 1.4320179224014282,
      "learning_rate": 6.967447292648698e-07,
      "loss": 0.4684,
      "step": 924800
    },
    {
      "epoch": 9.790870257938504,
      "grad_norm": 1.322014331817627,
      "learning_rate": 6.933027214187093e-07,
      "loss": 0.4697,
      "step": 924850
    },
    {
      "epoch": 9.791399579718506,
      "grad_norm": 1.408882975578308,
      "learning_rate": 6.898692248117899e-07,
      "loss": 0.4719,
      "step": 924900
    },
    {
      "epoch": 9.79192890149851,
      "grad_norm": 1.407690167427063,
      "learning_rate": 6.86444239561268e-07,
      "loss": 0.4683,
      "step": 924950
    },
    {
      "epoch": 9.792458223278514,
      "grad_norm": 1.4407596588134766,
      "learning_rate": 6.830277657841333e-07,
      "loss": 0.4662,
      "step": 925000
    },
    {
      "epoch": 9.792458223278514,
      "eval_loss": 0.2878677248954773,
      "eval_runtime": 46.8535,
      "eval_samples_per_second": 3584.154,
      "eval_steps_per_second": 448.035,
      "step": 925000
    },
    {
      "epoch": 9.792987545058516,
      "grad_norm": 1.501131534576416,
      "learning_rate": 6.79619803596987e-07,
      "loss": 0.4582,
      "step": 925050
    },
    {
      "epoch": 9.79351686683852,
      "grad_norm": 1.414986491203308,
      "learning_rate": 6.762203531161803e-07,
      "loss": 0.4754,
      "step": 925100
    },
    {
      "epoch": 9.794046188618523,
      "grad_norm": 1.3011680841445923,
      "learning_rate": 6.728294144577873e-07,
      "loss": 0.4609,
      "step": 925150
    },
    {
      "epoch": 9.794575510398527,
      "grad_norm": 1.3814905881881714,
      "learning_rate": 6.694469877375486e-07,
      "loss": 0.4653,
      "step": 925200
    },
    {
      "epoch": 9.795104832178529,
      "grad_norm": 1.2809864282608032,
      "learning_rate": 6.66073073070983e-07,
      "loss": 0.4618,
      "step": 925250
    },
    {
      "epoch": 9.795634153958533,
      "grad_norm": 1.5294195413589478,
      "learning_rate": 6.627076705731927e-07,
      "loss": 0.4695,
      "step": 925300
    },
    {
      "epoch": 9.796163475738537,
      "grad_norm": 1.548751950263977,
      "learning_rate": 6.593507803591414e-07,
      "loss": 0.4705,
      "step": 925350
    },
    {
      "epoch": 9.79669279751854,
      "grad_norm": 1.4376094341278076,
      "learning_rate": 6.560024025434319e-07,
      "loss": 0.4636,
      "step": 925400
    },
    {
      "epoch": 9.797222119298542,
      "grad_norm": 1.3468350172042847,
      "learning_rate": 6.526625372403339e-07,
      "loss": 0.4666,
      "step": 925450
    },
    {
      "epoch": 9.797751441078546,
      "grad_norm": 1.348894476890564,
      "learning_rate": 6.493311845638949e-07,
      "loss": 0.4732,
      "step": 925500
    },
    {
      "epoch": 9.797751441078546,
      "eval_loss": 0.28789928555488586,
      "eval_runtime": 46.8451,
      "eval_samples_per_second": 3584.792,
      "eval_steps_per_second": 448.115,
      "step": 925500
    },
    {
      "epoch": 9.79828076285855,
      "grad_norm": 1.1228439807891846,
      "learning_rate": 6.460083446278297e-07,
      "loss": 0.463,
      "step": 925550
    },
    {
      "epoch": 9.798810084638554,
      "grad_norm": 1.463809609413147,
      "learning_rate": 6.42694017545603e-07,
      "loss": 0.4647,
      "step": 925600
    },
    {
      "epoch": 9.799339406418555,
      "grad_norm": 1.6003178358078003,
      "learning_rate": 6.393882034303744e-07,
      "loss": 0.4636,
      "step": 925650
    },
    {
      "epoch": 9.79986872819856,
      "grad_norm": 1.2708097696304321,
      "learning_rate": 6.360909023949424e-07,
      "loss": 0.4752,
      "step": 925700
    },
    {
      "epoch": 9.800398049978563,
      "grad_norm": 1.1799894571304321,
      "learning_rate": 6.328678068787952e-07,
      "loss": 0.4568,
      "step": 925750
    },
    {
      "epoch": 9.800927371758565,
      "grad_norm": 1.4769712686538696,
      "learning_rate": 6.295873620732751e-07,
      "loss": 0.4643,
      "step": 925800
    },
    {
      "epoch": 9.801456693538569,
      "grad_norm": 1.3843241930007935,
      "learning_rate": 6.263154306822006e-07,
      "loss": 0.4595,
      "step": 925850
    },
    {
      "epoch": 9.801986015318572,
      "grad_norm": 1.2485240697860718,
      "learning_rate": 6.230520128172323e-07,
      "loss": 0.4692,
      "step": 925900
    },
    {
      "epoch": 9.802515337098576,
      "grad_norm": 1.3278448581695557,
      "learning_rate": 6.197971085898369e-07,
      "loss": 0.4672,
      "step": 925950
    },
    {
      "epoch": 9.803044658878578,
      "grad_norm": 1.4787243604660034,
      "learning_rate": 6.165507181111196e-07,
      "loss": 0.4647,
      "step": 926000
    },
    {
      "epoch": 9.803044658878578,
      "eval_loss": 0.28787854313850403,
      "eval_runtime": 47.0079,
      "eval_samples_per_second": 3572.376,
      "eval_steps_per_second": 446.563,
      "step": 926000
    },
    {
      "epoch": 9.803573980658582,
      "grad_norm": 1.5141816139221191,
      "learning_rate": 6.133128414918809e-07,
      "loss": 0.4619,
      "step": 926050
    },
    {
      "epoch": 9.804103302438586,
      "grad_norm": 1.4505137205123901,
      "learning_rate": 6.10083478842699e-07,
      "loss": 0.4641,
      "step": 926100
    },
    {
      "epoch": 9.80463262421859,
      "grad_norm": 1.4315377473831177,
      "learning_rate": 6.068626302737912e-07,
      "loss": 0.4707,
      "step": 926150
    },
    {
      "epoch": 9.805161945998591,
      "grad_norm": 1.4110504388809204,
      "learning_rate": 6.036502958951528e-07,
      "loss": 0.4684,
      "step": 926200
    },
    {
      "epoch": 9.805691267778595,
      "grad_norm": 1.3185415267944336,
      "learning_rate": 6.004464758163908e-07,
      "loss": 0.4658,
      "step": 926250
    },
    {
      "epoch": 9.806220589558599,
      "grad_norm": 1.4065830707550049,
      "learning_rate": 5.972511701469452e-07,
      "loss": 0.4609,
      "step": 926300
    },
    {
      "epoch": 9.806749911338603,
      "grad_norm": 1.4309295415878296,
      "learning_rate": 5.940643789958955e-07,
      "loss": 0.4619,
      "step": 926350
    },
    {
      "epoch": 9.807279233118605,
      "grad_norm": 1.2694227695465088,
      "learning_rate": 5.908861024719881e-07,
      "loss": 0.4637,
      "step": 926400
    },
    {
      "epoch": 9.807808554898608,
      "grad_norm": 1.2223302125930786,
      "learning_rate": 5.877163406837748e-07,
      "loss": 0.4684,
      "step": 926450
    },
    {
      "epoch": 9.808337876678612,
      "grad_norm": 1.2605301141738892,
      "learning_rate": 5.84555093739475e-07,
      "loss": 0.4682,
      "step": 926500
    },
    {
      "epoch": 9.808337876678612,
      "eval_loss": 0.28787216544151306,
      "eval_runtime": 46.9118,
      "eval_samples_per_second": 3579.699,
      "eval_steps_per_second": 447.478,
      "step": 926500
    },
    {
      "epoch": 9.808867198458614,
      "grad_norm": 1.571123719215393,
      "learning_rate": 5.814023617469744e-07,
      "loss": 0.4727,
      "step": 926550
    },
    {
      "epoch": 9.809396520238618,
      "grad_norm": 1.294585108757019,
      "learning_rate": 5.78258144813909e-07,
      "loss": 0.4681,
      "step": 926600
    },
    {
      "epoch": 9.809925842018622,
      "grad_norm": 1.2968323230743408,
      "learning_rate": 5.751224430476654e-07,
      "loss": 0.4609,
      "step": 926650
    },
    {
      "epoch": 9.810455163798625,
      "grad_norm": 1.3753920793533325,
      "learning_rate": 5.719952565552689e-07,
      "loss": 0.4737,
      "step": 926700
    },
    {
      "epoch": 9.810984485578627,
      "grad_norm": 1.4493300914764404,
      "learning_rate": 5.688765854434397e-07,
      "loss": 0.4681,
      "step": 926750
    },
    {
      "epoch": 9.811513807358631,
      "grad_norm": 1.3879985809326172,
      "learning_rate": 5.657664298187315e-07,
      "loss": 0.4607,
      "step": 926800
    },
    {
      "epoch": 9.812043129138635,
      "grad_norm": 1.3726240396499634,
      "learning_rate": 5.626647897872539e-07,
      "loss": 0.465,
      "step": 926850
    },
    {
      "epoch": 9.812572450918639,
      "grad_norm": 1.2876152992248535,
      "learning_rate": 5.595716654549499e-07,
      "loss": 0.47,
      "step": 926900
    },
    {
      "epoch": 9.81310177269864,
      "grad_norm": 1.4346648454666138,
      "learning_rate": 5.564870569273739e-07,
      "loss": 0.4774,
      "step": 926950
    },
    {
      "epoch": 9.813631094478644,
      "grad_norm": 1.43050217628479,
      "learning_rate": 5.534109643098583e-07,
      "loss": 0.4685,
      "step": 927000
    },
    {
      "epoch": 9.813631094478644,
      "eval_loss": 0.2878739833831787,
      "eval_runtime": 46.8489,
      "eval_samples_per_second": 3584.504,
      "eval_steps_per_second": 448.079,
      "step": 927000
    },
    {
      "epoch": 9.814160416258648,
      "grad_norm": 1.4150073528289795,
      "learning_rate": 5.503433877073749e-07,
      "loss": 0.4675,
      "step": 927050
    },
    {
      "epoch": 9.814689738038652,
      "grad_norm": 1.342066764831543,
      "learning_rate": 5.472843272247286e-07,
      "loss": 0.4699,
      "step": 927100
    },
    {
      "epoch": 9.815219059818654,
      "grad_norm": 1.2360599040985107,
      "learning_rate": 5.442337829662802e-07,
      "loss": 0.4703,
      "step": 927150
    },
    {
      "epoch": 9.815748381598658,
      "grad_norm": 1.540603518486023,
      "learning_rate": 5.411917550362244e-07,
      "loss": 0.4596,
      "step": 927200
    },
    {
      "epoch": 9.816277703378661,
      "grad_norm": 1.3459036350250244,
      "learning_rate": 5.381582435383947e-07,
      "loss": 0.4569,
      "step": 927250
    },
    {
      "epoch": 9.816807025158663,
      "grad_norm": 1.4465092420578003,
      "learning_rate": 5.351332485763471e-07,
      "loss": 0.4691,
      "step": 927300
    },
    {
      "epoch": 9.817336346938667,
      "grad_norm": 1.297569751739502,
      "learning_rate": 5.321167702533603e-07,
      "loss": 0.4761,
      "step": 927350
    },
    {
      "epoch": 9.817865668718671,
      "grad_norm": 1.3265342712402344,
      "learning_rate": 5.291088086724349e-07,
      "loss": 0.462,
      "step": 927400
    },
    {
      "epoch": 9.818394990498675,
      "grad_norm": 1.375004529953003,
      "learning_rate": 5.261093639362113e-07,
      "loss": 0.4682,
      "step": 927450
    },
    {
      "epoch": 9.818924312278677,
      "grad_norm": 1.2779321670532227,
      "learning_rate": 5.231184361471353e-07,
      "loss": 0.4641,
      "step": 927500
    },
    {
      "epoch": 9.818924312278677,
      "eval_loss": 0.28785446286201477,
      "eval_runtime": 46.9172,
      "eval_samples_per_second": 3579.285,
      "eval_steps_per_second": 447.427,
      "step": 927500
    },
    {
      "epoch": 9.81945363405868,
      "grad_norm": 1.536726474761963,
      "learning_rate": 5.201360254073195e-07,
      "loss": 0.4665,
      "step": 927550
    },
    {
      "epoch": 9.819982955838684,
      "grad_norm": 1.2675635814666748,
      "learning_rate": 5.171621318185438e-07,
      "loss": 0.4619,
      "step": 927600
    },
    {
      "epoch": 9.820512277618688,
      "grad_norm": 1.317200779914856,
      "learning_rate": 5.141967554823656e-07,
      "loss": 0.4619,
      "step": 927650
    },
    {
      "epoch": 9.82104159939869,
      "grad_norm": 1.2948192358016968,
      "learning_rate": 5.112398965000376e-07,
      "loss": 0.4676,
      "step": 927700
    },
    {
      "epoch": 9.821570921178694,
      "grad_norm": 1.4272950887680054,
      "learning_rate": 5.082915549724509e-07,
      "loss": 0.4678,
      "step": 927750
    },
    {
      "epoch": 9.822100242958697,
      "grad_norm": 1.4318281412124634,
      "learning_rate": 5.053517310003031e-07,
      "loss": 0.4637,
      "step": 927800
    },
    {
      "epoch": 9.822629564738701,
      "grad_norm": 1.452662467956543,
      "learning_rate": 5.024204246839581e-07,
      "loss": 0.4673,
      "step": 927850
    },
    {
      "epoch": 9.823158886518703,
      "grad_norm": 1.308381199836731,
      "learning_rate": 4.994976361234749e-07,
      "loss": 0.4614,
      "step": 927900
    },
    {
      "epoch": 9.823688208298707,
      "grad_norm": 1.3842284679412842,
      "learning_rate": 4.965833654186069e-07,
      "loss": 0.457,
      "step": 927950
    },
    {
      "epoch": 9.82421753007871,
      "grad_norm": 1.4970693588256836,
      "learning_rate": 4.936776126689135e-07,
      "loss": 0.4718,
      "step": 928000
    },
    {
      "epoch": 9.82421753007871,
      "eval_loss": 0.28786250948905945,
      "eval_runtime": 46.8676,
      "eval_samples_per_second": 3583.073,
      "eval_steps_per_second": 447.9,
      "step": 928000
    },
    {
      "epoch": 9.824746851858713,
      "grad_norm": 1.2246590852737427,
      "learning_rate": 4.907803779735654e-07,
      "loss": 0.4567,
      "step": 928050
    },
    {
      "epoch": 9.825276173638716,
      "grad_norm": 1.44669508934021,
      "learning_rate": 4.878916614314554e-07,
      "loss": 0.4652,
      "step": 928100
    },
    {
      "epoch": 9.82580549541872,
      "grad_norm": 1.6106500625610352,
      "learning_rate": 4.850114631412273e-07,
      "loss": 0.4644,
      "step": 928150
    },
    {
      "epoch": 9.826334817198724,
      "grad_norm": 1.41964852809906,
      "learning_rate": 4.821397832011909e-07,
      "loss": 0.4578,
      "step": 928200
    },
    {
      "epoch": 9.826864138978726,
      "grad_norm": 1.194478154182434,
      "learning_rate": 4.792766217094069e-07,
      "loss": 0.4644,
      "step": 928250
    },
    {
      "epoch": 9.82739346075873,
      "grad_norm": 1.484736442565918,
      "learning_rate": 4.764219787636026e-07,
      "loss": 0.4609,
      "step": 928300
    },
    {
      "epoch": 9.827922782538733,
      "grad_norm": 1.3459242582321167,
      "learning_rate": 4.7357585446125563e-07,
      "loss": 0.4662,
      "step": 928350
    },
    {
      "epoch": 9.828452104318737,
      "grad_norm": 1.3968080282211304,
      "learning_rate": 4.707382488994827e-07,
      "loss": 0.4629,
      "step": 928400
    },
    {
      "epoch": 9.82898142609874,
      "grad_norm": 1.3435982465744019,
      "learning_rate": 4.6790916217523406e-07,
      "loss": 0.4692,
      "step": 928450
    },
    {
      "epoch": 9.829510747878743,
      "grad_norm": 1.415682315826416,
      "learning_rate": 4.6508859438501583e-07,
      "loss": 0.4696,
      "step": 928500
    },
    {
      "epoch": 9.829510747878743,
      "eval_loss": 0.28786328434944153,
      "eval_runtime": 46.9841,
      "eval_samples_per_second": 3574.186,
      "eval_steps_per_second": 446.789,
      "step": 928500
    },
    {
      "epoch": 9.830040069658747,
      "grad_norm": 1.2809799909591675,
      "learning_rate": 4.623327031132718e-07,
      "loss": 0.4676,
      "step": 928550
    },
    {
      "epoch": 9.83056939143875,
      "grad_norm": 1.5540255308151245,
      "learning_rate": 4.595290030963151e-07,
      "loss": 0.4718,
      "step": 928600
    },
    {
      "epoch": 9.831098713218752,
      "grad_norm": 1.5757230520248413,
      "learning_rate": 4.5673382229954874e-07,
      "loss": 0.4682,
      "step": 928650
    },
    {
      "epoch": 9.831628034998756,
      "grad_norm": 1.4177786111831665,
      "learning_rate": 4.5394716081836875e-07,
      "loss": 0.4702,
      "step": 928700
    },
    {
      "epoch": 9.83215735677876,
      "grad_norm": 1.530344843864441,
      "learning_rate": 4.511690187478934e-07,
      "loss": 0.468,
      "step": 928750
    },
    {
      "epoch": 9.832686678558762,
      "grad_norm": 1.3075212240219116,
      "learning_rate": 4.483993961829913e-07,
      "loss": 0.4581,
      "step": 928800
    },
    {
      "epoch": 9.833216000338766,
      "grad_norm": 1.448509931564331,
      "learning_rate": 4.4563829321825346e-07,
      "loss": 0.4699,
      "step": 928850
    },
    {
      "epoch": 9.83374532211877,
      "grad_norm": 1.2733919620513916,
      "learning_rate": 4.428857099478545e-07,
      "loss": 0.4718,
      "step": 928900
    },
    {
      "epoch": 9.834274643898773,
      "grad_norm": 1.367275357246399,
      "learning_rate": 4.4014164646583033e-07,
      "loss": 0.4636,
      "step": 928950
    },
    {
      "epoch": 9.834803965678775,
      "grad_norm": 1.3899699449539185,
      "learning_rate": 4.37406102865856e-07,
      "loss": 0.4711,
      "step": 929000
    },
    {
      "epoch": 9.834803965678775,
      "eval_loss": 0.2878511846065521,
      "eval_runtime": 46.8729,
      "eval_samples_per_second": 3582.668,
      "eval_steps_per_second": 447.85,
      "step": 929000
    },
    {
      "epoch": 9.835333287458779,
      "grad_norm": 1.415781021118164,
      "learning_rate": 4.3467907924130134e-07,
      "loss": 0.4684,
      "step": 929050
    },
    {
      "epoch": 9.835862609238783,
      "grad_norm": 1.4138716459274292,
      "learning_rate": 4.319605756852862e-07,
      "loss": 0.4668,
      "step": 929100
    },
    {
      "epoch": 9.836391931018786,
      "grad_norm": 1.5887601375579834,
      "learning_rate": 4.292505922905976e-07,
      "loss": 0.4645,
      "step": 929150
    },
    {
      "epoch": 9.836921252798788,
      "grad_norm": 1.4334349632263184,
      "learning_rate": 4.2654912914980025e-07,
      "loss": 0.4604,
      "step": 929200
    },
    {
      "epoch": 9.837450574578792,
      "grad_norm": 1.259081482887268,
      "learning_rate": 4.238561863550428e-07,
      "loss": 0.4689,
      "step": 929250
    },
    {
      "epoch": 9.837979896358796,
      "grad_norm": 1.5315592288970947,
      "learning_rate": 4.211717639983348e-07,
      "loss": 0.4714,
      "step": 929300
    },
    {
      "epoch": 9.8385092181388,
      "grad_norm": 1.2838438749313354,
      "learning_rate": 4.1849586217129756e-07,
      "loss": 0.4652,
      "step": 929350
    },
    {
      "epoch": 9.839038539918802,
      "grad_norm": 1.4826641082763672,
      "learning_rate": 4.1582848096524685e-07,
      "loss": 0.4636,
      "step": 929400
    },
    {
      "epoch": 9.839567861698805,
      "grad_norm": 1.5074539184570312,
      "learning_rate": 4.1316962047130426e-07,
      "loss": 0.464,
      "step": 929450
    },
    {
      "epoch": 9.84009718347881,
      "grad_norm": 1.3426369428634644,
      "learning_rate": 4.105192807802305e-07,
      "loss": 0.4714,
      "step": 929500
    },
    {
      "epoch": 9.84009718347881,
      "eval_loss": 0.2878343462944031,
      "eval_runtime": 46.8934,
      "eval_samples_per_second": 3581.099,
      "eval_steps_per_second": 447.653,
      "step": 929500
    },
    {
      "epoch": 9.840626505258811,
      "grad_norm": 1.4377063512802124,
      "learning_rate": 4.078774619824532e-07,
      "loss": 0.4692,
      "step": 929550
    },
    {
      "epoch": 9.841155827038815,
      "grad_norm": 1.56497061252594,
      "learning_rate": 4.052441641682336e-07,
      "loss": 0.4694,
      "step": 929600
    },
    {
      "epoch": 9.841685148818819,
      "grad_norm": 1.3181205987930298,
      "learning_rate": 4.026193874274442e-07,
      "loss": 0.4671,
      "step": 929650
    },
    {
      "epoch": 9.842214470598822,
      "grad_norm": 1.2792749404907227,
      "learning_rate": 4.0000313184967994e-07,
      "loss": 0.4649,
      "step": 929700
    },
    {
      "epoch": 9.842743792378824,
      "grad_norm": 1.3084577322006226,
      "learning_rate": 3.9739539752425837e-07,
      "loss": 0.4612,
      "step": 929750
    },
    {
      "epoch": 9.843273114158828,
      "grad_norm": 1.3412442207336426,
      "learning_rate": 3.94796184540247e-07,
      "loss": 0.464,
      "step": 929800
    },
    {
      "epoch": 9.843802435938832,
      "grad_norm": 1.2168937921524048,
      "learning_rate": 3.92205492986325e-07,
      "loss": 0.462,
      "step": 929850
    },
    {
      "epoch": 9.844331757718836,
      "grad_norm": 1.335385799407959,
      "learning_rate": 3.8962332295100486e-07,
      "loss": 0.4625,
      "step": 929900
    },
    {
      "epoch": 9.844861079498838,
      "grad_norm": 1.3311688899993896,
      "learning_rate": 3.8704967452235505e-07,
      "loss": 0.4688,
      "step": 929950
    },
    {
      "epoch": 9.845390401278841,
      "grad_norm": 1.575071930885315,
      "learning_rate": 3.8448454778833297e-07,
      "loss": 0.4679,
      "step": 930000
    },
    {
      "epoch": 9.845390401278841,
      "eval_loss": 0.28784164786338806,
      "eval_runtime": 46.9376,
      "eval_samples_per_second": 3577.731,
      "eval_steps_per_second": 447.232,
      "step": 930000
    },
    {
      "epoch": 9.845919723058845,
      "grad_norm": 1.459446668624878,
      "learning_rate": 3.8192794283642416e-07,
      "loss": 0.4656,
      "step": 930050
    },
    {
      "epoch": 9.846449044838849,
      "grad_norm": 1.4226754903793335,
      "learning_rate": 3.793798597539755e-07,
      "loss": 0.471,
      "step": 930100
    },
    {
      "epoch": 9.84697836661885,
      "grad_norm": 1.2947814464569092,
      "learning_rate": 3.768402986279451e-07,
      "loss": 0.4681,
      "step": 930150
    },
    {
      "epoch": 9.847507688398855,
      "grad_norm": 1.44600510597229,
      "learning_rate": 3.743092595450415e-07,
      "loss": 0.4689,
      "step": 930200
    },
    {
      "epoch": 9.848037010178858,
      "grad_norm": 1.5298278331756592,
      "learning_rate": 3.7178674259166766e-07,
      "loss": 0.4672,
      "step": 930250
    },
    {
      "epoch": 9.84856633195886,
      "grad_norm": 1.3005712032318115,
      "learning_rate": 3.6927274785394927e-07,
      "loss": 0.4662,
      "step": 930300
    },
    {
      "epoch": 9.849095653738864,
      "grad_norm": 1.3741892576217651,
      "learning_rate": 3.6676727541770647e-07,
      "loss": 0.4597,
      "step": 930350
    },
    {
      "epoch": 9.849624975518868,
      "grad_norm": 1.2695014476776123,
      "learning_rate": 3.642703253685098e-07,
      "loss": 0.456,
      "step": 930400
    },
    {
      "epoch": 9.850154297298872,
      "grad_norm": 1.4794150590896606,
      "learning_rate": 3.61781897791541e-07,
      "loss": 0.4741,
      "step": 930450
    },
    {
      "epoch": 9.850683619078874,
      "grad_norm": 1.2878594398498535,
      "learning_rate": 3.5930199277178775e-07,
      "loss": 0.4625,
      "step": 930500
    },
    {
      "epoch": 9.850683619078874,
      "eval_loss": 0.2878425121307373,
      "eval_runtime": 46.8456,
      "eval_samples_per_second": 3584.755,
      "eval_steps_per_second": 448.11,
      "step": 930500
    },
    {
      "epoch": 9.851212940858877,
      "grad_norm": 1.4124855995178223,
      "learning_rate": 3.568799545190238e-07,
      "loss": 0.4657,
      "step": 930550
    },
    {
      "epoch": 9.851742262638881,
      "grad_norm": 1.4764988422393799,
      "learning_rate": 3.5441692441204323e-07,
      "loss": 0.4563,
      "step": 930600
    },
    {
      "epoch": 9.852271584418885,
      "grad_norm": 1.3564971685409546,
      "learning_rate": 3.519624171137437e-07,
      "loss": 0.473,
      "step": 930650
    },
    {
      "epoch": 9.852800906198887,
      "grad_norm": 1.3777869939804077,
      "learning_rate": 3.495164327078637e-07,
      "loss": 0.4665,
      "step": 930700
    },
    {
      "epoch": 9.85333022797889,
      "grad_norm": 1.3811665773391724,
      "learning_rate": 3.4707897127791986e-07,
      "loss": 0.4648,
      "step": 930750
    },
    {
      "epoch": 9.853859549758894,
      "grad_norm": 1.380383014678955,
      "learning_rate": 3.4465003290717887e-07,
      "loss": 0.4656,
      "step": 930800
    },
    {
      "epoch": 9.854388871538898,
      "grad_norm": 1.3154559135437012,
      "learning_rate": 3.4222961767849113e-07,
      "loss": 0.4678,
      "step": 930850
    },
    {
      "epoch": 9.8549181933189,
      "grad_norm": 1.2809778451919556,
      "learning_rate": 3.3981772567456824e-07,
      "loss": 0.467,
      "step": 930900
    },
    {
      "epoch": 9.855447515098904,
      "grad_norm": 1.2620662450790405,
      "learning_rate": 3.3741435697767775e-07,
      "loss": 0.468,
      "step": 930950
    },
    {
      "epoch": 9.855976836878908,
      "grad_norm": 1.5251644849777222,
      "learning_rate": 3.3501951166989286e-07,
      "loss": 0.4674,
      "step": 931000
    },
    {
      "epoch": 9.855976836878908,
      "eval_loss": 0.28785237669944763,
      "eval_runtime": 46.8897,
      "eval_samples_per_second": 3581.38,
      "eval_steps_per_second": 447.689,
      "step": 931000
    },
    {
      "epoch": 9.85650615865891,
      "grad_norm": 1.3013216257095337,
      "learning_rate": 3.3263318983300927e-07,
      "loss": 0.4654,
      "step": 931050
    },
    {
      "epoch": 9.857035480438913,
      "grad_norm": 1.362525463104248,
      "learning_rate": 3.302553915484341e-07,
      "loss": 0.4657,
      "step": 931100
    },
    {
      "epoch": 9.857564802218917,
      "grad_norm": 1.6284202337265015,
      "learning_rate": 3.278861168974079e-07,
      "loss": 0.465,
      "step": 931150
    },
    {
      "epoch": 9.85809412399892,
      "grad_norm": 1.328019142150879,
      "learning_rate": 3.255253659607549e-07,
      "loss": 0.466,
      "step": 931200
    },
    {
      "epoch": 9.858623445778923,
      "grad_norm": 1.4743266105651855,
      "learning_rate": 3.231731388191328e-07,
      "loss": 0.4707,
      "step": 931250
    },
    {
      "epoch": 9.859152767558927,
      "grad_norm": 1.435129165649414,
      "learning_rate": 3.20829435552783e-07,
      "loss": 0.4646,
      "step": 931300
    },
    {
      "epoch": 9.85968208933893,
      "grad_norm": 1.2834923267364502,
      "learning_rate": 3.1849425624175254e-07,
      "loss": 0.4682,
      "step": 931350
    },
    {
      "epoch": 9.860211411118934,
      "grad_norm": 1.516467809677124,
      "learning_rate": 3.1616760096578324e-07,
      "loss": 0.4611,
      "step": 931400
    },
    {
      "epoch": 9.860740732898936,
      "grad_norm": 1.398012638092041,
      "learning_rate": 3.13849469804256e-07,
      "loss": 0.4557,
      "step": 931450
    },
    {
      "epoch": 9.86127005467894,
      "grad_norm": 1.3178191184997559,
      "learning_rate": 3.115398628363575e-07,
      "loss": 0.4693,
      "step": 931500
    },
    {
      "epoch": 9.86127005467894,
      "eval_loss": 0.2878574728965759,
      "eval_runtime": 46.705,
      "eval_samples_per_second": 3595.545,
      "eval_steps_per_second": 449.459,
      "step": 931500
    },
    {
      "epoch": 9.861799376458944,
      "grad_norm": 1.332836389541626,
      "learning_rate": 3.0923878014091357e-07,
      "loss": 0.4707,
      "step": 931550
    },
    {
      "epoch": 9.862328698238947,
      "grad_norm": 1.4778705835342407,
      "learning_rate": 3.069462217964725e-07,
      "loss": 0.4767,
      "step": 931600
    },
    {
      "epoch": 9.86285802001895,
      "grad_norm": 1.5167207717895508,
      "learning_rate": 3.046621878813327e-07,
      "loss": 0.4738,
      "step": 931650
    },
    {
      "epoch": 9.863387341798953,
      "grad_norm": 1.3054686784744263,
      "learning_rate": 3.0238667847345967e-07,
      "loss": 0.4645,
      "step": 931700
    },
    {
      "epoch": 9.863916663578957,
      "grad_norm": 1.3740884065628052,
      "learning_rate": 3.001196936505135e-07,
      "loss": 0.4653,
      "step": 931750
    },
    {
      "epoch": 9.864445985358959,
      "grad_norm": 1.2657688856124878,
      "learning_rate": 2.9786123348990445e-07,
      "loss": 0.472,
      "step": 931800
    },
    {
      "epoch": 9.864975307138963,
      "grad_norm": 1.4573726654052734,
      "learning_rate": 2.9561129806873755e-07,
      "loss": 0.4737,
      "step": 931850
    },
    {
      "epoch": 9.865504628918966,
      "grad_norm": 1.320043683052063,
      "learning_rate": 2.9336988746384016e-07,
      "loss": 0.4584,
      "step": 931900
    },
    {
      "epoch": 9.86603395069897,
      "grad_norm": 1.3754066228866577,
      "learning_rate": 2.9113700175170677e-07,
      "loss": 0.4631,
      "step": 931950
    },
    {
      "epoch": 9.866563272478972,
      "grad_norm": 1.4313230514526367,
      "learning_rate": 2.8891264100858183e-07,
      "loss": 0.4752,
      "step": 932000
    },
    {
      "epoch": 9.866563272478972,
      "eval_loss": 0.287849485874176,
      "eval_runtime": 47.0257,
      "eval_samples_per_second": 3571.029,
      "eval_steps_per_second": 446.395,
      "step": 932000
    },
    {
      "epoch": 9.867092594258976,
      "grad_norm": 1.4349323511123657,
      "learning_rate": 2.866968053103769e-07,
      "loss": 0.4648,
      "step": 932050
    },
    {
      "epoch": 9.86762191603898,
      "grad_norm": 1.3319889307022095,
      "learning_rate": 2.8448949473278143e-07,
      "loss": 0.4647,
      "step": 932100
    },
    {
      "epoch": 9.868151237818983,
      "grad_norm": 1.2291126251220703,
      "learning_rate": 2.8229070935115175e-07,
      "loss": 0.4593,
      "step": 932150
    },
    {
      "epoch": 9.868680559598985,
      "grad_norm": 1.3063969612121582,
      "learning_rate": 2.8010044924051126e-07,
      "loss": 0.4663,
      "step": 932200
    },
    {
      "epoch": 9.869209881378989,
      "grad_norm": 1.1600604057312012,
      "learning_rate": 2.77918714475689e-07,
      "loss": 0.4617,
      "step": 932250
    },
    {
      "epoch": 9.869739203158993,
      "grad_norm": 1.311221957206726,
      "learning_rate": 2.7574550513109753e-07,
      "loss": 0.4594,
      "step": 932300
    },
    {
      "epoch": 9.870268524938997,
      "grad_norm": 1.2086690664291382,
      "learning_rate": 2.735808212810109e-07,
      "loss": 0.4751,
      "step": 932350
    },
    {
      "epoch": 9.870797846718999,
      "grad_norm": 1.3909648656845093,
      "learning_rate": 2.7142466299925896e-07,
      "loss": 0.4644,
      "step": 932400
    },
    {
      "epoch": 9.871327168499002,
      "grad_norm": 1.3271902799606323,
      "learning_rate": 2.692770303595049e-07,
      "loss": 0.4637,
      "step": 932450
    },
    {
      "epoch": 9.871856490279006,
      "grad_norm": 1.400394082069397,
      "learning_rate": 2.671379234350235e-07,
      "loss": 0.4595,
      "step": 932500
    },
    {
      "epoch": 9.871856490279006,
      "eval_loss": 0.2878558039665222,
      "eval_runtime": 46.8367,
      "eval_samples_per_second": 3585.436,
      "eval_steps_per_second": 448.195,
      "step": 932500
    },
    {
      "epoch": 9.872385812059008,
      "grad_norm": 1.477060079574585,
      "learning_rate": 2.650073422988952e-07,
      "loss": 0.4685,
      "step": 932550
    },
    {
      "epoch": 9.872915133839012,
      "grad_norm": 1.333107829093933,
      "learning_rate": 2.628852870238119e-07,
      "loss": 0.4672,
      "step": 932600
    },
    {
      "epoch": 9.873444455619016,
      "grad_norm": 1.4345999956130981,
      "learning_rate": 2.607717576822155e-07,
      "loss": 0.4607,
      "step": 932650
    },
    {
      "epoch": 9.87397377739902,
      "grad_norm": 1.5668344497680664,
      "learning_rate": 2.5866675434632615e-07,
      "loss": 0.4692,
      "step": 932700
    },
    {
      "epoch": 9.874503099179021,
      "grad_norm": 1.4251446723937988,
      "learning_rate": 2.565702770879197e-07,
      "loss": 0.4693,
      "step": 932750
    },
    {
      "epoch": 9.875032420959025,
      "grad_norm": 1.5008292198181152,
      "learning_rate": 2.544823259786611e-07,
      "loss": 0.4726,
      "step": 932800
    },
    {
      "epoch": 9.875561742739029,
      "grad_norm": 1.4817332029342651,
      "learning_rate": 2.524029010897433e-07,
      "loss": 0.4673,
      "step": 932850
    },
    {
      "epoch": 9.876091064519033,
      "grad_norm": 1.4862213134765625,
      "learning_rate": 2.5033200249222064e-07,
      "loss": 0.4558,
      "step": 932900
    },
    {
      "epoch": 9.876620386299034,
      "grad_norm": 1.3858636617660522,
      "learning_rate": 2.4826963025675884e-07,
      "loss": 0.462,
      "step": 932950
    },
    {
      "epoch": 9.877149708079038,
      "grad_norm": 1.456659197807312,
      "learning_rate": 2.462157844537738e-07,
      "loss": 0.4743,
      "step": 933000
    },
    {
      "epoch": 9.877149708079038,
      "eval_loss": 0.28785112500190735,
      "eval_runtime": 46.9499,
      "eval_samples_per_second": 3576.789,
      "eval_steps_per_second": 447.115,
      "step": 933000
    },
    {
      "epoch": 9.877679029859042,
      "grad_norm": 1.4403058290481567,
      "learning_rate": 2.441704651534038e-07,
      "loss": 0.4701,
      "step": 933050
    },
    {
      "epoch": 9.878208351639046,
      "grad_norm": 1.4089773893356323,
      "learning_rate": 2.4213367242545416e-07,
      "loss": 0.4741,
      "step": 933100
    },
    {
      "epoch": 9.878737673419048,
      "grad_norm": 1.2907809019088745,
      "learning_rate": 2.4014588809964655e-07,
      "loss": 0.4688,
      "step": 933150
    },
    {
      "epoch": 9.879266995199051,
      "grad_norm": 1.275472640991211,
      "learning_rate": 2.381259781899514e-07,
      "loss": 0.4617,
      "step": 933200
    },
    {
      "epoch": 9.879796316979055,
      "grad_norm": 1.3665826320648193,
      "learning_rate": 2.3611459505903932e-07,
      "loss": 0.4659,
      "step": 933250
    },
    {
      "epoch": 9.880325638759057,
      "grad_norm": 1.3637369871139526,
      "learning_rate": 2.3411173877560533e-07,
      "loss": 0.4665,
      "step": 933300
    },
    {
      "epoch": 9.880854960539061,
      "grad_norm": 1.3901283740997314,
      "learning_rate": 2.3211740940795588e-07,
      "loss": 0.4699,
      "step": 933350
    },
    {
      "epoch": 9.881384282319065,
      "grad_norm": 1.3639822006225586,
      "learning_rate": 2.3013160702423098e-07,
      "loss": 0.4724,
      "step": 933400
    },
    {
      "epoch": 9.881913604099068,
      "grad_norm": 1.3685595989227295,
      "learning_rate": 2.2815433169223741e-07,
      "loss": 0.4623,
      "step": 933450
    },
    {
      "epoch": 9.88244292587907,
      "grad_norm": 1.3179876804351807,
      "learning_rate": 2.2618558347942132e-07,
      "loss": 0.466,
      "step": 933500
    },
    {
      "epoch": 9.88244292587907,
      "eval_loss": 0.28786295652389526,
      "eval_runtime": 46.8672,
      "eval_samples_per_second": 3583.103,
      "eval_steps_per_second": 447.904,
      "step": 933500
    },
    {
      "epoch": 9.882972247659074,
      "grad_norm": 1.3062466382980347,
      "learning_rate": 2.2422536245303438e-07,
      "loss": 0.4707,
      "step": 933550
    },
    {
      "epoch": 9.883501569439078,
      "grad_norm": 1.2451709508895874,
      "learning_rate": 2.2227366868002307e-07,
      "loss": 0.4677,
      "step": 933600
    },
    {
      "epoch": 9.884030891219082,
      "grad_norm": 1.393255591392517,
      "learning_rate": 2.2033050222694528e-07,
      "loss": 0.4661,
      "step": 933650
    },
    {
      "epoch": 9.884560212999084,
      "grad_norm": 1.289910078048706,
      "learning_rate": 2.1839586316019233e-07,
      "loss": 0.465,
      "step": 933700
    },
    {
      "epoch": 9.885089534779087,
      "grad_norm": 1.4352444410324097,
      "learning_rate": 2.1646975154579473e-07,
      "loss": 0.4632,
      "step": 933750
    },
    {
      "epoch": 9.885618856559091,
      "grad_norm": 1.3678032159805298,
      "learning_rate": 2.1455216744953322e-07,
      "loss": 0.4636,
      "step": 933800
    },
    {
      "epoch": 9.886148178339095,
      "grad_norm": 1.494445562362671,
      "learning_rate": 2.126431109368554e-07,
      "loss": 0.4645,
      "step": 933850
    },
    {
      "epoch": 9.886677500119097,
      "grad_norm": 1.2899582386016846,
      "learning_rate": 2.1074258207290364e-07,
      "loss": 0.4627,
      "step": 933900
    },
    {
      "epoch": 9.8872068218991,
      "grad_norm": 1.2414391040802002,
      "learning_rate": 2.0885058092262599e-07,
      "loss": 0.4675,
      "step": 933950
    },
    {
      "epoch": 9.887736143679104,
      "grad_norm": 1.2765545845031738,
      "learning_rate": 2.0696710755055415e-07,
      "loss": 0.4651,
      "step": 934000
    },
    {
      "epoch": 9.887736143679104,
      "eval_loss": 0.28785935044288635,
      "eval_runtime": 46.6851,
      "eval_samples_per_second": 3597.077,
      "eval_steps_per_second": 449.651,
      "step": 934000
    },
    {
      "epoch": 9.888265465459106,
      "grad_norm": 1.2708338499069214,
      "learning_rate": 2.0509216202102553e-07,
      "loss": 0.4579,
      "step": 934050
    },
    {
      "epoch": 9.88879478723911,
      "grad_norm": 1.4391815662384033,
      "learning_rate": 2.0322574439804452e-07,
      "loss": 0.4642,
      "step": 934100
    },
    {
      "epoch": 9.889324109019114,
      "grad_norm": 1.3111518621444702,
      "learning_rate": 2.0136785474533791e-07,
      "loss": 0.4664,
      "step": 934150
    },
    {
      "epoch": 9.889853430799118,
      "grad_norm": 1.3561851978302002,
      "learning_rate": 1.9951849312629943e-07,
      "loss": 0.459,
      "step": 934200
    },
    {
      "epoch": 9.89038275257912,
      "grad_norm": 1.4371490478515625,
      "learning_rate": 1.9767765960410079e-07,
      "loss": 0.4592,
      "step": 934250
    },
    {
      "epoch": 9.890912074359123,
      "grad_norm": 1.3369793891906738,
      "learning_rate": 1.9584535424158058e-07,
      "loss": 0.4656,
      "step": 934300
    },
    {
      "epoch": 9.891441396139127,
      "grad_norm": 1.3275588750839233,
      "learning_rate": 1.940215771012721e-07,
      "loss": 0.4666,
      "step": 934350
    },
    {
      "epoch": 9.891970717919131,
      "grad_norm": 1.4790112972259521,
      "learning_rate": 1.9220632824545892e-07,
      "loss": 0.4683,
      "step": 934400
    },
    {
      "epoch": 9.892500039699133,
      "grad_norm": 1.4512548446655273,
      "learning_rate": 1.9039960773609145e-07,
      "loss": 0.4724,
      "step": 934450
    },
    {
      "epoch": 9.893029361479137,
      "grad_norm": 1.279556393623352,
      "learning_rate": 1.8860141563489808e-07,
      "loss": 0.4643,
      "step": 934500
    },
    {
      "epoch": 9.893029361479137,
      "eval_loss": 0.2878555953502655,
      "eval_runtime": 46.8537,
      "eval_samples_per_second": 3584.136,
      "eval_steps_per_second": 448.033,
      "step": 934500
    },
    {
      "epoch": 9.89355868325914,
      "grad_norm": 1.3564561605453491,
      "learning_rate": 1.8681175200321864e-07,
      "loss": 0.4601,
      "step": 934550
    },
    {
      "epoch": 9.894088005039144,
      "grad_norm": 1.283323049545288,
      "learning_rate": 1.8503061690217092e-07,
      "loss": 0.4646,
      "step": 934600
    },
    {
      "epoch": 9.894617326819146,
      "grad_norm": 1.2975093126296997,
      "learning_rate": 1.832580103925674e-07,
      "loss": 0.4684,
      "step": 934650
    },
    {
      "epoch": 9.89514664859915,
      "grad_norm": 1.2530920505523682,
      "learning_rate": 1.814939325349152e-07,
      "loss": 0.4575,
      "step": 934700
    },
    {
      "epoch": 9.895675970379154,
      "grad_norm": 1.436198115348816,
      "learning_rate": 1.7973838338941618e-07,
      "loss": 0.4641,
      "step": 934750
    },
    {
      "epoch": 9.896205292159156,
      "grad_norm": 1.3688393831253052,
      "learning_rate": 1.7799136301605012e-07,
      "loss": 0.4649,
      "step": 934800
    },
    {
      "epoch": 9.89673461393916,
      "grad_norm": 1.3054323196411133,
      "learning_rate": 1.7625287147446378e-07,
      "loss": 0.4601,
      "step": 934850
    },
    {
      "epoch": 9.897263935719163,
      "grad_norm": 1.2586336135864258,
      "learning_rate": 1.7452290882394306e-07,
      "loss": 0.4687,
      "step": 934900
    },
    {
      "epoch": 9.897793257499167,
      "grad_norm": 1.5436104536056519,
      "learning_rate": 1.7280147512360732e-07,
      "loss": 0.4769,
      "step": 934950
    },
    {
      "epoch": 9.898322579279169,
      "grad_norm": 1.4434959888458252,
      "learning_rate": 1.7108857043221516e-07,
      "loss": 0.4693,
      "step": 935000
    },
    {
      "epoch": 9.898322579279169,
      "eval_loss": 0.2878579795360565,
      "eval_runtime": 46.8976,
      "eval_samples_per_second": 3580.783,
      "eval_steps_per_second": 447.614,
      "step": 935000
    },
    {
      "epoch": 9.898851901059173,
      "grad_norm": 1.356438398361206,
      "learning_rate": 1.6938419480821977e-07,
      "loss": 0.47,
      "step": 935050
    },
    {
      "epoch": 9.899381222839176,
      "grad_norm": 1.3934245109558105,
      "learning_rate": 1.6768834830985236e-07,
      "loss": 0.4604,
      "step": 935100
    },
    {
      "epoch": 9.89991054461918,
      "grad_norm": 1.3231984376907349,
      "learning_rate": 1.6600103099495556e-07,
      "loss": 0.4689,
      "step": 935150
    },
    {
      "epoch": 9.900439866399182,
      "grad_norm": 1.3508082628250122,
      "learning_rate": 1.643222429211777e-07,
      "loss": 0.4605,
      "step": 935200
    },
    {
      "epoch": 9.900969188179186,
      "grad_norm": 1.4087064266204834,
      "learning_rate": 1.6265198414580628e-07,
      "loss": 0.4712,
      "step": 935250
    },
    {
      "epoch": 9.90149850995919,
      "grad_norm": 1.4002087116241455,
      "learning_rate": 1.6099025472585126e-07,
      "loss": 0.4655,
      "step": 935300
    },
    {
      "epoch": 9.902027831739193,
      "grad_norm": 1.408042073249817,
      "learning_rate": 1.5933705471810056e-07,
      "loss": 0.4716,
      "step": 935350
    },
    {
      "epoch": 9.902557153519195,
      "grad_norm": 1.4702980518341064,
      "learning_rate": 1.5769238417892573e-07,
      "loss": 0.4724,
      "step": 935400
    },
    {
      "epoch": 9.9030864752992,
      "grad_norm": 1.351545810699463,
      "learning_rate": 1.5605624316453182e-07,
      "loss": 0.4696,
      "step": 935450
    },
    {
      "epoch": 9.903615797079203,
      "grad_norm": 1.4570616483688354,
      "learning_rate": 1.544286317307353e-07,
      "loss": 0.4673,
      "step": 935500
    },
    {
      "epoch": 9.903615797079203,
      "eval_loss": 0.287856787443161,
      "eval_runtime": 47.015,
      "eval_samples_per_second": 3571.837,
      "eval_steps_per_second": 446.496,
      "step": 935500
    },
    {
      "epoch": 9.904145118859205,
      "grad_norm": 1.4223204851150513,
      "learning_rate": 1.5284184797825785e-07,
      "loss": 0.4669,
      "step": 935550
    },
    {
      "epoch": 9.904674440639209,
      "grad_norm": 1.411757230758667,
      "learning_rate": 1.512311252777343e-07,
      "loss": 0.4631,
      "step": 935600
    },
    {
      "epoch": 9.905203762419212,
      "grad_norm": 1.3445804119110107,
      "learning_rate": 1.4962893232253748e-07,
      "loss": 0.4633,
      "step": 935650
    },
    {
      "epoch": 9.905733084199216,
      "grad_norm": 1.3483692407608032,
      "learning_rate": 1.4803526916737364e-07,
      "loss": 0.4645,
      "step": 935700
    },
    {
      "epoch": 9.906262405979218,
      "grad_norm": 1.2158557176589966,
      "learning_rate": 1.4645013586667144e-07,
      "loss": 0.463,
      "step": 935750
    },
    {
      "epoch": 9.906791727759222,
      "grad_norm": 1.3197004795074463,
      "learning_rate": 1.448735324745265e-07,
      "loss": 0.467,
      "step": 935800
    },
    {
      "epoch": 9.907321049539226,
      "grad_norm": 1.517243504524231,
      "learning_rate": 1.433054590447569e-07,
      "loss": 0.4733,
      "step": 935850
    },
    {
      "epoch": 9.90785037131923,
      "grad_norm": 1.395908236503601,
      "learning_rate": 1.4174591563093087e-07,
      "loss": 0.4637,
      "step": 935900
    },
    {
      "epoch": 9.908379693099231,
      "grad_norm": 1.6013580560684204,
      "learning_rate": 1.401949022862281e-07,
      "loss": 0.4674,
      "step": 935950
    },
    {
      "epoch": 9.908909014879235,
      "grad_norm": 1.37970769405365,
      "learning_rate": 1.3865241906366178e-07,
      "loss": 0.4631,
      "step": 936000
    },
    {
      "epoch": 9.908909014879235,
      "eval_loss": 0.2878524959087372,
      "eval_runtime": 46.8793,
      "eval_samples_per_second": 3582.176,
      "eval_steps_per_second": 447.788,
      "step": 936000
    },
    {
      "epoch": 9.909438336659239,
      "grad_norm": 1.4307734966278076,
      "learning_rate": 1.3711846601585642e-07,
      "loss": 0.461,
      "step": 936050
    },
    {
      "epoch": 9.909967658439243,
      "grad_norm": 1.5001411437988281,
      "learning_rate": 1.3559304319521458e-07,
      "loss": 0.4699,
      "step": 936100
    },
    {
      "epoch": 9.910496980219245,
      "grad_norm": 1.373792290687561,
      "learning_rate": 1.34076150653778e-07,
      "loss": 0.4709,
      "step": 936150
    },
    {
      "epoch": 9.911026301999248,
      "grad_norm": 1.3085609674453735,
      "learning_rate": 1.325677884433385e-07,
      "loss": 0.4699,
      "step": 936200
    },
    {
      "epoch": 9.911555623779252,
      "grad_norm": 1.4720697402954102,
      "learning_rate": 1.3106795661541048e-07,
      "loss": 0.4587,
      "step": 936250
    },
    {
      "epoch": 9.912084945559254,
      "grad_norm": 1.2717392444610596,
      "learning_rate": 1.2957665522117522e-07,
      "loss": 0.4613,
      "step": 936300
    },
    {
      "epoch": 9.912614267339258,
      "grad_norm": 1.3713328838348389,
      "learning_rate": 1.2809388431156422e-07,
      "loss": 0.4593,
      "step": 936350
    },
    {
      "epoch": 9.913143589119262,
      "grad_norm": 1.4218019247055054,
      "learning_rate": 1.2661964393717584e-07,
      "loss": 0.4634,
      "step": 936400
    },
    {
      "epoch": 9.913672910899265,
      "grad_norm": 1.4164527654647827,
      "learning_rate": 1.2515393414835873e-07,
      "loss": 0.465,
      "step": 936450
    },
    {
      "epoch": 9.914202232679267,
      "grad_norm": 1.4548641443252563,
      "learning_rate": 1.236967549951562e-07,
      "loss": 0.4694,
      "step": 936500
    },
    {
      "epoch": 9.914202232679267,
      "eval_loss": 0.2878466248512268,
      "eval_runtime": 46.9725,
      "eval_samples_per_second": 3575.069,
      "eval_steps_per_second": 446.9,
      "step": 936500
    },
    {
      "epoch": 9.914731554459271,
      "grad_norm": 1.4340182542800903,
      "learning_rate": 1.222481065273062e-07,
      "loss": 0.4734,
      "step": 936550
    },
    {
      "epoch": 9.915260876239275,
      "grad_norm": 1.4810267686843872,
      "learning_rate": 1.2080798879426924e-07,
      "loss": 0.4676,
      "step": 936600
    },
    {
      "epoch": 9.915790198019279,
      "grad_norm": 1.5112756490707397,
      "learning_rate": 1.1937640184520039e-07,
      "loss": 0.4641,
      "step": 936650
    },
    {
      "epoch": 9.91631951979928,
      "grad_norm": 1.4099310636520386,
      "learning_rate": 1.179533457289772e-07,
      "loss": 0.4627,
      "step": 936700
    },
    {
      "epoch": 9.916848841579284,
      "grad_norm": 1.4447578191757202,
      "learning_rate": 1.1653882049419972e-07,
      "loss": 0.4622,
      "step": 936750
    },
    {
      "epoch": 9.917378163359288,
      "grad_norm": 1.1288310289382935,
      "learning_rate": 1.151328261891349e-07,
      "loss": 0.4686,
      "step": 936800
    },
    {
      "epoch": 9.917907485139292,
      "grad_norm": 1.4689137935638428,
      "learning_rate": 1.1373536286177211e-07,
      "loss": 0.4603,
      "step": 936850
    },
    {
      "epoch": 9.918436806919294,
      "grad_norm": 1.402085542678833,
      "learning_rate": 1.123464305598787e-07,
      "loss": 0.4668,
      "step": 936900
    },
    {
      "epoch": 9.918966128699298,
      "grad_norm": 1.3730164766311646,
      "learning_rate": 1.1096602933080569e-07,
      "loss": 0.4629,
      "step": 936950
    },
    {
      "epoch": 9.919495450479301,
      "grad_norm": 1.3499020338058472,
      "learning_rate": 1.0959415922170979e-07,
      "loss": 0.4609,
      "step": 937000
    },
    {
      "epoch": 9.919495450479301,
      "eval_loss": 0.2878434956073761,
      "eval_runtime": 46.9632,
      "eval_samples_per_second": 3575.776,
      "eval_steps_per_second": 446.988,
      "step": 937000
    },
    {
      "epoch": 9.920024772259303,
      "grad_norm": 1.4646342992782593,
      "learning_rate": 1.0823082027944242e-07,
      "loss": 0.4621,
      "step": 937050
    },
    {
      "epoch": 9.920554094039307,
      "grad_norm": 1.3643310070037842,
      "learning_rate": 1.0687601255052193e-07,
      "loss": 0.4669,
      "step": 937100
    },
    {
      "epoch": 9.92108341581931,
      "grad_norm": 1.3413126468658447,
      "learning_rate": 1.0552973608121686e-07,
      "loss": 0.4678,
      "step": 937150
    },
    {
      "epoch": 9.921612737599315,
      "grad_norm": 1.2809596061706543,
      "learning_rate": 1.0419199091746268e-07,
      "loss": 0.4573,
      "step": 937200
    },
    {
      "epoch": 9.922142059379317,
      "grad_norm": 1.340011477470398,
      "learning_rate": 1.0286277710494508e-07,
      "loss": 0.4633,
      "step": 937250
    },
    {
      "epoch": 9.92267138115932,
      "grad_norm": 1.3336163759231567,
      "learning_rate": 1.0154209468907216e-07,
      "loss": 0.4653,
      "step": 937300
    },
    {
      "epoch": 9.923200702939324,
      "grad_norm": 1.460233449935913,
      "learning_rate": 1.002299437148635e-07,
      "loss": 0.464,
      "step": 937350
    },
    {
      "epoch": 9.923730024719328,
      "grad_norm": 1.5400052070617676,
      "learning_rate": 9.892632422719983e-08,
      "loss": 0.4626,
      "step": 937400
    },
    {
      "epoch": 9.92425934649933,
      "grad_norm": 1.319832682609558,
      "learning_rate": 9.763123627051784e-08,
      "loss": 0.4644,
      "step": 937450
    },
    {
      "epoch": 9.924788668279334,
      "grad_norm": 1.3026349544525146,
      "learning_rate": 9.634467988905992e-08,
      "loss": 0.4715,
      "step": 937500
    },
    {
      "epoch": 9.924788668279334,
      "eval_loss": 0.287842333316803,
      "eval_runtime": 46.865,
      "eval_samples_per_second": 3583.274,
      "eval_steps_per_second": 447.925,
      "step": 937500
    },
    {
      "epoch": 9.925317990059337,
      "grad_norm": 1.3782713413238525,
      "learning_rate": 9.50666551267354e-08,
      "loss": 0.4658,
      "step": 937550
    },
    {
      "epoch": 9.925847311839341,
      "grad_norm": 1.3684170246124268,
      "learning_rate": 9.379716202720378e-08,
      "loss": 0.4642,
      "step": 937600
    },
    {
      "epoch": 9.926376633619343,
      "grad_norm": 1.4624167680740356,
      "learning_rate": 9.253620063379153e-08,
      "loss": 0.4612,
      "step": 937650
    },
    {
      "epoch": 9.926905955399347,
      "grad_norm": 1.367377519607544,
      "learning_rate": 9.128377098951978e-08,
      "loss": 0.4611,
      "step": 937700
    },
    {
      "epoch": 9.92743527717935,
      "grad_norm": 1.4135448932647705,
      "learning_rate": 9.003987313718765e-08,
      "loss": 0.4636,
      "step": 937750
    },
    {
      "epoch": 9.927964598959353,
      "grad_norm": 1.3439395427703857,
      "learning_rate": 8.880450711923338e-08,
      "loss": 0.4613,
      "step": 937800
    },
    {
      "epoch": 9.928493920739356,
      "grad_norm": 1.4512954950332642,
      "learning_rate": 8.757767297784547e-08,
      "loss": 0.47,
      "step": 937850
    },
    {
      "epoch": 9.92902324251936,
      "grad_norm": 1.4432692527770996,
      "learning_rate": 8.635937075490707e-08,
      "loss": 0.4667,
      "step": 937900
    },
    {
      "epoch": 9.929552564299364,
      "grad_norm": 1.3867170810699463,
      "learning_rate": 8.517371228378145e-08,
      "loss": 0.4774,
      "step": 937950
    },
    {
      "epoch": 9.930081886079366,
      "grad_norm": 1.3776984214782715,
      "learning_rate": 8.397230338177963e-08,
      "loss": 0.4685,
      "step": 938000
    },
    {
      "epoch": 9.930081886079366,
      "eval_loss": 0.28784096240997314,
      "eval_runtime": 46.9095,
      "eval_samples_per_second": 3579.874,
      "eval_steps_per_second": 447.5,
      "step": 938000
    },
    {
      "epoch": 9.93061120785937,
      "grad_norm": 1.4580720663070679,
      "learning_rate": 8.277942652129555e-08,
      "loss": 0.4712,
      "step": 938050
    },
    {
      "epoch": 9.931140529639373,
      "grad_norm": 1.4156863689422607,
      "learning_rate": 8.159508174310215e-08,
      "loss": 0.4668,
      "step": 938100
    },
    {
      "epoch": 9.931669851419377,
      "grad_norm": 1.275331974029541,
      "learning_rate": 8.041926908758379e-08,
      "loss": 0.4637,
      "step": 938150
    },
    {
      "epoch": 9.932199173199379,
      "grad_norm": 1.394290566444397,
      "learning_rate": 7.925198859487503e-08,
      "loss": 0.4664,
      "step": 938200
    },
    {
      "epoch": 9.932728494979383,
      "grad_norm": 1.3088490962982178,
      "learning_rate": 7.809324030486065e-08,
      "loss": 0.4615,
      "step": 938250
    },
    {
      "epoch": 9.933257816759387,
      "grad_norm": 1.4165416955947876,
      "learning_rate": 7.694302425709232e-08,
      "loss": 0.4646,
      "step": 938300
    },
    {
      "epoch": 9.93378713853939,
      "grad_norm": 1.5436432361602783,
      "learning_rate": 7.580134049084419e-08,
      "loss": 0.4654,
      "step": 938350
    },
    {
      "epoch": 9.934316460319392,
      "grad_norm": 1.338773250579834,
      "learning_rate": 7.466818904505735e-08,
      "loss": 0.4634,
      "step": 938400
    },
    {
      "epoch": 9.934845782099396,
      "grad_norm": 1.4210325479507446,
      "learning_rate": 7.35435699584508e-08,
      "loss": 0.4609,
      "step": 938450
    },
    {
      "epoch": 9.9353751038794,
      "grad_norm": 1.3561939001083374,
      "learning_rate": 7.242748326941051e-08,
      "loss": 0.4608,
      "step": 938500
    },
    {
      "epoch": 9.9353751038794,
      "eval_loss": 0.2878352403640747,
      "eval_runtime": 46.7359,
      "eval_samples_per_second": 3593.171,
      "eval_steps_per_second": 449.162,
      "step": 938500
    },
    {
      "epoch": 9.935904425659402,
      "grad_norm": 1.338747262954712,
      "learning_rate": 7.13199290160449e-08,
      "loss": 0.463,
      "step": 938550
    },
    {
      "epoch": 9.936433747439406,
      "grad_norm": 1.3606501817703247,
      "learning_rate": 7.022090723615704e-08,
      "loss": 0.4625,
      "step": 938600
    },
    {
      "epoch": 9.93696306921941,
      "grad_norm": 1.3997279405593872,
      "learning_rate": 6.913041796724472e-08,
      "loss": 0.4601,
      "step": 938650
    },
    {
      "epoch": 9.937492390999413,
      "grad_norm": 1.3243389129638672,
      "learning_rate": 6.80484612465837e-08,
      "loss": 0.4625,
      "step": 938700
    },
    {
      "epoch": 9.938021712779415,
      "grad_norm": 1.420252799987793,
      "learning_rate": 6.697503711108888e-08,
      "loss": 0.46,
      "step": 938750
    },
    {
      "epoch": 9.938551034559419,
      "grad_norm": 1.209947943687439,
      "learning_rate": 6.59101455973976e-08,
      "loss": 0.464,
      "step": 938800
    },
    {
      "epoch": 9.939080356339423,
      "grad_norm": 1.4431766271591187,
      "learning_rate": 6.48537867418697e-08,
      "loss": 0.4711,
      "step": 938850
    },
    {
      "epoch": 9.939609678119426,
      "grad_norm": 1.4900978803634644,
      "learning_rate": 6.380596058058741e-08,
      "loss": 0.4587,
      "step": 938900
    },
    {
      "epoch": 9.940138999899428,
      "grad_norm": 1.3832391500473022,
      "learning_rate": 6.276666714927215e-08,
      "loss": 0.4801,
      "step": 938950
    },
    {
      "epoch": 9.940668321679432,
      "grad_norm": 1.2399086952209473,
      "learning_rate": 6.173590648347882e-08,
      "loss": 0.459,
      "step": 939000
    },
    {
      "epoch": 9.940668321679432,
      "eval_loss": 0.28783631324768066,
      "eval_runtime": 46.9829,
      "eval_samples_per_second": 3574.282,
      "eval_steps_per_second": 446.801,
      "step": 939000
    },
    {
      "epoch": 9.941197643459436,
      "grad_norm": 1.4950586557388306,
      "learning_rate": 6.071367861834598e-08,
      "loss": 0.4647,
      "step": 939050
    },
    {
      "epoch": 9.94172696523944,
      "grad_norm": 1.4757461547851562,
      "learning_rate": 5.969998358879014e-08,
      "loss": 0.4644,
      "step": 939100
    },
    {
      "epoch": 9.942256287019442,
      "grad_norm": 1.427471399307251,
      "learning_rate": 5.869482142939475e-08,
      "loss": 0.4688,
      "step": 939150
    },
    {
      "epoch": 9.942785608799445,
      "grad_norm": 1.2621564865112305,
      "learning_rate": 5.769819217452121e-08,
      "loss": 0.4639,
      "step": 939200
    },
    {
      "epoch": 9.943314930579449,
      "grad_norm": 1.2337521314620972,
      "learning_rate": 5.671009585817011e-08,
      "loss": 0.4622,
      "step": 939250
    },
    {
      "epoch": 9.943844252359451,
      "grad_norm": 1.3930431604385376,
      "learning_rate": 5.57305325140367e-08,
      "loss": 0.4675,
      "step": 939300
    },
    {
      "epoch": 9.944373574139455,
      "grad_norm": 1.460548758506775,
      "learning_rate": 5.475950217562198e-08,
      "loss": 0.46,
      "step": 939350
    },
    {
      "epoch": 9.944902895919459,
      "grad_norm": 1.3399841785430908,
      "learning_rate": 5.379700487606609e-08,
      "loss": 0.463,
      "step": 939400
    },
    {
      "epoch": 9.945432217699462,
      "grad_norm": 1.3097528219223022,
      "learning_rate": 5.2843040648203886e-08,
      "loss": 0.4564,
      "step": 939450
    },
    {
      "epoch": 9.945961539479464,
      "grad_norm": 1.3619157075881958,
      "learning_rate": 5.189760952459266e-08,
      "loss": 0.4674,
      "step": 939500
    },
    {
      "epoch": 9.945961539479464,
      "eval_loss": 0.2878364622592926,
      "eval_runtime": 46.7617,
      "eval_samples_per_second": 3591.189,
      "eval_steps_per_second": 448.915,
      "step": 939500
    },
    {
      "epoch": 9.946490861259468,
      "grad_norm": 1.3910671472549438,
      "learning_rate": 5.096071153756765e-08,
      "loss": 0.4622,
      "step": 939550
    },
    {
      "epoch": 9.947020183039472,
      "grad_norm": 1.313184380531311,
      "learning_rate": 5.003234671904777e-08,
      "loss": 0.4712,
      "step": 939600
    },
    {
      "epoch": 9.947549504819476,
      "grad_norm": 1.3616878986358643,
      "learning_rate": 4.9112515100785405e-08,
      "loss": 0.4656,
      "step": 939650
    },
    {
      "epoch": 9.948078826599478,
      "grad_norm": 1.4037467241287231,
      "learning_rate": 4.820121671411659e-08,
      "loss": 0.4589,
      "step": 939700
    },
    {
      "epoch": 9.948608148379481,
      "grad_norm": 1.5944626331329346,
      "learning_rate": 4.72984515902386e-08,
      "loss": 0.4766,
      "step": 939750
    },
    {
      "epoch": 9.949137470159485,
      "grad_norm": 1.274182677268982,
      "learning_rate": 4.6404219759876854e-08,
      "loss": 0.4754,
      "step": 939800
    },
    {
      "epoch": 9.949666791939489,
      "grad_norm": 1.2983551025390625,
      "learning_rate": 4.551852125364575e-08,
      "loss": 0.4643,
      "step": 939850
    },
    {
      "epoch": 9.95019611371949,
      "grad_norm": 1.3858767747879028,
      "learning_rate": 4.4641356101715604e-08,
      "loss": 0.4651,
      "step": 939900
    },
    {
      "epoch": 9.950725435499495,
      "grad_norm": 1.3687397241592407,
      "learning_rate": 4.3772724334090185e-08,
      "loss": 0.4652,
      "step": 939950
    },
    {
      "epoch": 9.951254757279498,
      "grad_norm": 1.4162763357162476,
      "learning_rate": 4.2912625980356944e-08,
      "loss": 0.4636,
      "step": 940000
    },
    {
      "epoch": 9.951254757279498,
      "eval_loss": 0.2878361940383911,
      "eval_runtime": 47.0248,
      "eval_samples_per_second": 3571.095,
      "eval_steps_per_second": 446.403,
      "step": 940000
    },
    {
      "epoch": 9.9517840790595,
      "grad_norm": 1.231471300125122,
      "learning_rate": 4.206106106996455e-08,
      "loss": 0.4606,
      "step": 940050
    },
    {
      "epoch": 9.952313400839504,
      "grad_norm": 1.5418455600738525,
      "learning_rate": 4.1218029631889806e-08,
      "loss": 0.4678,
      "step": 940100
    },
    {
      "epoch": 9.952842722619508,
      "grad_norm": 1.35832679271698,
      "learning_rate": 4.038353169499853e-08,
      "loss": 0.4624,
      "step": 940150
    },
    {
      "epoch": 9.953372044399512,
      "grad_norm": 1.3269906044006348,
      "learning_rate": 3.955756728771243e-08,
      "loss": 0.4662,
      "step": 940200
    },
    {
      "epoch": 9.953901366179513,
      "grad_norm": 1.5038107633590698,
      "learning_rate": 3.874013643828667e-08,
      "loss": 0.4661,
      "step": 940250
    },
    {
      "epoch": 9.954430687959517,
      "grad_norm": 1.5814156532287598,
      "learning_rate": 3.793123917458785e-08,
      "loss": 0.4653,
      "step": 940300
    },
    {
      "epoch": 9.954960009739521,
      "grad_norm": 1.4109538793563843,
      "learning_rate": 3.7130875524260534e-08,
      "loss": 0.4657,
      "step": 940350
    },
    {
      "epoch": 9.955489331519525,
      "grad_norm": 1.4632807970046997,
      "learning_rate": 3.633904551458844e-08,
      "loss": 0.4731,
      "step": 940400
    },
    {
      "epoch": 9.956018653299527,
      "grad_norm": 1.4636456966400146,
      "learning_rate": 3.5571331469363976e-08,
      "loss": 0.4641,
      "step": 940450
    },
    {
      "epoch": 9.95654797507953,
      "grad_norm": 1.3142839670181274,
      "learning_rate": 3.47963981477406e-08,
      "loss": 0.4644,
      "step": 940500
    },
    {
      "epoch": 9.95654797507953,
      "eval_loss": 0.2878358066082001,
      "eval_runtime": 46.903,
      "eval_samples_per_second": 3580.368,
      "eval_steps_per_second": 447.562,
      "step": 940500
    },
    {
      "epoch": 9.957077296859534,
      "grad_norm": 1.3088229894638062,
      "learning_rate": 3.4029998546486474e-08,
      "loss": 0.4694,
      "step": 940550
    },
    {
      "epoch": 9.957606618639538,
      "grad_norm": 1.3892661333084106,
      "learning_rate": 3.3272132691775094e-08,
      "loss": 0.4589,
      "step": 940600
    },
    {
      "epoch": 9.95813594041954,
      "grad_norm": 1.3450599908828735,
      "learning_rate": 3.252280060947466e-08,
      "loss": 0.4745,
      "step": 940650
    },
    {
      "epoch": 9.958665262199544,
      "grad_norm": 1.36765456199646,
      "learning_rate": 3.178200232517581e-08,
      "loss": 0.4658,
      "step": 940700
    },
    {
      "epoch": 9.959194583979547,
      "grad_norm": 1.4811017513275146,
      "learning_rate": 3.104973786416387e-08,
      "loss": 0.4653,
      "step": 940750
    },
    {
      "epoch": 9.95972390575955,
      "grad_norm": 1.3006370067596436,
      "learning_rate": 3.0326007251418876e-08,
      "loss": 0.4656,
      "step": 940800
    },
    {
      "epoch": 9.960253227539553,
      "grad_norm": 1.295554757118225,
      "learning_rate": 2.9610810511698783e-08,
      "loss": 0.4633,
      "step": 940850
    },
    {
      "epoch": 9.960782549319557,
      "grad_norm": 1.3576011657714844,
      "learning_rate": 2.8904147669400747e-08,
      "loss": 0.4701,
      "step": 940900
    },
    {
      "epoch": 9.96131187109956,
      "grad_norm": 1.2840088605880737,
      "learning_rate": 2.8206018748616613e-08,
      "loss": 0.4666,
      "step": 940950
    },
    {
      "epoch": 9.961841192879563,
      "grad_norm": 1.309983253479004,
      "learning_rate": 2.751642377321617e-08,
      "loss": 0.4595,
      "step": 941000
    },
    {
      "epoch": 9.961841192879563,
      "eval_loss": 0.28783437609672546,
      "eval_runtime": 46.8599,
      "eval_samples_per_second": 3583.663,
      "eval_steps_per_second": 447.974,
      "step": 941000
    },
    {
      "epoch": 9.962370514659566,
      "grad_norm": 1.4211143255233765,
      "learning_rate": 2.6835362766736148e-08,
      "loss": 0.4668,
      "step": 941050
    },
    {
      "epoch": 9.96289983643957,
      "grad_norm": 1.2932205200195312,
      "learning_rate": 2.6162835752407966e-08,
      "loss": 0.4653,
      "step": 941100
    },
    {
      "epoch": 9.963429158219574,
      "grad_norm": 1.4079338312149048,
      "learning_rate": 2.5498842753213237e-08,
      "loss": 0.4662,
      "step": 941150
    },
    {
      "epoch": 9.963958479999576,
      "grad_norm": 1.3560190200805664,
      "learning_rate": 2.4843383791800512e-08,
      "loss": 0.4591,
      "step": 941200
    },
    {
      "epoch": 9.96448780177958,
      "grad_norm": 1.357333779335022,
      "learning_rate": 2.419645889056854e-08,
      "loss": 0.4646,
      "step": 941250
    },
    {
      "epoch": 9.965017123559583,
      "grad_norm": 1.4666024446487427,
      "learning_rate": 2.3558068071583006e-08,
      "loss": 0.4631,
      "step": 941300
    },
    {
      "epoch": 9.965546445339587,
      "grad_norm": 1.4189893007278442,
      "learning_rate": 2.292821135665979e-08,
      "loss": 0.4775,
      "step": 941350
    },
    {
      "epoch": 9.96607576711959,
      "grad_norm": 1.3560222387313843,
      "learning_rate": 2.2306888767309465e-08,
      "loss": 0.4622,
      "step": 941400
    },
    {
      "epoch": 9.966605088899593,
      "grad_norm": 1.421676754951477,
      "learning_rate": 2.1694100324681775e-08,
      "loss": 0.4714,
      "step": 941450
    },
    {
      "epoch": 9.967134410679597,
      "grad_norm": 1.3024369478225708,
      "learning_rate": 2.1089846049787696e-08,
      "loss": 0.4616,
      "step": 941500
    },
    {
      "epoch": 9.967134410679597,
      "eval_loss": 0.2878343462944031,
      "eval_runtime": 46.9431,
      "eval_samples_per_second": 3577.311,
      "eval_steps_per_second": 447.18,
      "step": 941500
    },
    {
      "epoch": 9.967663732459599,
      "grad_norm": 1.5137550830841064,
      "learning_rate": 2.0494125963166354e-08,
      "loss": 0.4599,
      "step": 941550
    },
    {
      "epoch": 9.968193054239602,
      "grad_norm": 1.4061181545257568,
      "learning_rate": 1.9906940085218094e-08,
      "loss": 0.4626,
      "step": 941600
    },
    {
      "epoch": 9.968722376019606,
      "grad_norm": 1.5026830434799194,
      "learning_rate": 1.9328288435982445e-08,
      "loss": 0.4694,
      "step": 941650
    },
    {
      "epoch": 9.96925169779961,
      "grad_norm": 1.5198469161987305,
      "learning_rate": 1.8758171035193617e-08,
      "loss": 0.4678,
      "step": 941700
    },
    {
      "epoch": 9.969781019579612,
      "grad_norm": 1.473637580871582,
      "learning_rate": 1.819658790230827e-08,
      "loss": 0.4639,
      "step": 941750
    },
    {
      "epoch": 9.970310341359616,
      "grad_norm": 1.5090203285217285,
      "learning_rate": 1.764353905650551e-08,
      "loss": 0.4616,
      "step": 941800
    },
    {
      "epoch": 9.97083966313962,
      "grad_norm": 1.4545936584472656,
      "learning_rate": 1.7099024516714633e-08,
      "loss": 0.4699,
      "step": 941850
    },
    {
      "epoch": 9.971368984919623,
      "grad_norm": 1.4042795896530151,
      "learning_rate": 1.6563044301448615e-08,
      "loss": 0.4658,
      "step": 941900
    },
    {
      "epoch": 9.971898306699625,
      "grad_norm": 1.2714898586273193,
      "learning_rate": 1.603559842905389e-08,
      "loss": 0.4598,
      "step": 941950
    },
    {
      "epoch": 9.972427628479629,
      "grad_norm": 1.3702747821807861,
      "learning_rate": 1.5516686917516066e-08,
      "loss": 0.4672,
      "step": 942000
    },
    {
      "epoch": 9.972427628479629,
      "eval_loss": 0.2878333628177643,
      "eval_runtime": 46.8103,
      "eval_samples_per_second": 3587.462,
      "eval_steps_per_second": 448.449,
      "step": 942000
    },
    {
      "epoch": 9.972956950259633,
      "grad_norm": 1.5829156637191772,
      "learning_rate": 1.500630978457096e-08,
      "loss": 0.464,
      "step": 942050
    },
    {
      "epoch": 9.973486272039636,
      "grad_norm": 1.2915432453155518,
      "learning_rate": 1.4504467047621318e-08,
      "loss": 0.4598,
      "step": 942100
    },
    {
      "epoch": 9.974015593819638,
      "grad_norm": 1.4908006191253662,
      "learning_rate": 1.4011158723820083e-08,
      "loss": 0.466,
      "step": 942150
    },
    {
      "epoch": 9.974544915599642,
      "grad_norm": 1.4279206991195679,
      "learning_rate": 1.3526384829987137e-08,
      "loss": 0.4733,
      "step": 942200
    },
    {
      "epoch": 9.975074237379646,
      "grad_norm": 1.3689295053482056,
      "learning_rate": 1.3050145382692557e-08,
      "loss": 0.4679,
      "step": 942250
    },
    {
      "epoch": 9.975603559159648,
      "grad_norm": 1.3264621496200562,
      "learning_rate": 1.2582440398201112e-08,
      "loss": 0.4587,
      "step": 942300
    },
    {
      "epoch": 9.976132880939652,
      "grad_norm": 1.3967772722244263,
      "learning_rate": 1.21232698924445e-08,
      "loss": 0.4662,
      "step": 942350
    },
    {
      "epoch": 9.976662202719655,
      "grad_norm": 1.5410964488983154,
      "learning_rate": 1.1672633881104621e-08,
      "loss": 0.4766,
      "step": 942400
    },
    {
      "epoch": 9.97719152449966,
      "grad_norm": 1.448664665222168,
      "learning_rate": 1.1230532379613578e-08,
      "loss": 0.4707,
      "step": 942450
    },
    {
      "epoch": 9.977720846279661,
      "grad_norm": 1.4586199522018433,
      "learning_rate": 1.0796965403014891e-08,
      "loss": 0.4682,
      "step": 942500
    },
    {
      "epoch": 9.977720846279661,
      "eval_loss": 0.28783300518989563,
      "eval_runtime": 46.9442,
      "eval_samples_per_second": 3577.223,
      "eval_steps_per_second": 447.169,
      "step": 942500
    },
    {
      "epoch": 9.978250168059665,
      "grad_norm": 1.3762626647949219,
      "learning_rate": 1.0371932966130038e-08,
      "loss": 0.4576,
      "step": 942550
    },
    {
      "epoch": 9.978779489839669,
      "grad_norm": 1.2968063354492188,
      "learning_rate": 9.955435083447428e-09,
      "loss": 0.4602,
      "step": 942600
    },
    {
      "epoch": 9.979308811619672,
      "grad_norm": 1.3724679946899414,
      "learning_rate": 9.55554739665021e-09,
      "loss": 0.4773,
      "step": 942650
    },
    {
      "epoch": 9.979838133399674,
      "grad_norm": 1.4670002460479736,
      "learning_rate": 9.155947973016332e-09,
      "loss": 0.4674,
      "step": 942700
    },
    {
      "epoch": 9.980367455179678,
      "grad_norm": 1.3369380235671997,
      "learning_rate": 8.764883145107039e-09,
      "loss": 0.4665,
      "step": 942750
    },
    {
      "epoch": 9.980896776959682,
      "grad_norm": 1.4051852226257324,
      "learning_rate": 8.382352926272762e-09,
      "loss": 0.47,
      "step": 942800
    },
    {
      "epoch": 9.981426098739686,
      "grad_norm": 1.4005013704299927,
      "learning_rate": 8.008357329614136e-09,
      "loss": 0.4551,
      "step": 942850
    },
    {
      "epoch": 9.981955420519688,
      "grad_norm": 1.3795727491378784,
      "learning_rate": 7.642896367843211e-09,
      "loss": 0.4732,
      "step": 942900
    },
    {
      "epoch": 9.982484742299691,
      "grad_norm": 1.3740458488464355,
      "learning_rate": 7.285970053477753e-09,
      "loss": 0.4674,
      "step": 942950
    },
    {
      "epoch": 9.983014064079695,
      "grad_norm": 1.2714197635650635,
      "learning_rate": 6.937578398674705e-09,
      "loss": 0.4675,
      "step": 943000
    },
    {
      "epoch": 9.983014064079695,
      "eval_loss": 0.28783300518989563,
      "eval_runtime": 46.8239,
      "eval_samples_per_second": 3586.417,
      "eval_steps_per_second": 448.318,
      "step": 943000
    },
    {
      "epoch": 9.983543385859697,
      "grad_norm": 1.3657910823822021,
      "learning_rate": 6.597721415341207e-09,
      "loss": 0.4712,
      "step": 943050
    },
    {
      "epoch": 9.984072707639701,
      "grad_norm": 1.3623121976852417,
      "learning_rate": 6.266399115079091e-09,
      "loss": 0.4628,
      "step": 943100
    },
    {
      "epoch": 9.984602029419705,
      "grad_norm": 1.3739830255508423,
      "learning_rate": 5.943611509212632e-09,
      "loss": 0.4656,
      "step": 943150
    },
    {
      "epoch": 9.985131351199708,
      "grad_norm": 1.5673795938491821,
      "learning_rate": 5.6293586087330375e-09,
      "loss": 0.459,
      "step": 943200
    },
    {
      "epoch": 9.98566067297971,
      "grad_norm": 1.3219165802001953,
      "learning_rate": 5.323640424381715e-09,
      "loss": 0.4667,
      "step": 943250
    },
    {
      "epoch": 9.986189994759714,
      "grad_norm": 1.4337347745895386,
      "learning_rate": 5.026456966594761e-09,
      "loss": 0.4628,
      "step": 943300
    },
    {
      "epoch": 9.986719316539718,
      "grad_norm": 1.3823906183242798,
      "learning_rate": 4.737808245530717e-09,
      "loss": 0.4718,
      "step": 943350
    },
    {
      "epoch": 9.987248638319722,
      "grad_norm": 1.3792736530303955,
      "learning_rate": 4.457694271042812e-09,
      "loss": 0.4603,
      "step": 943400
    },
    {
      "epoch": 9.987777960099724,
      "grad_norm": 1.4366487264633179,
      "learning_rate": 4.186115052678962e-09,
      "loss": 0.4701,
      "step": 943450
    },
    {
      "epoch": 9.988307281879727,
      "grad_norm": 1.374562382698059,
      "learning_rate": 3.923070599737288e-09,
      "loss": 0.4654,
      "step": 943500
    },
    {
      "epoch": 9.988307281879727,
      "eval_loss": 0.28783348202705383,
      "eval_runtime": 46.9262,
      "eval_samples_per_second": 3578.6,
      "eval_steps_per_second": 447.341,
      "step": 943500
    },
    {
      "epoch": 9.988836603659731,
      "grad_norm": 1.2911661863327026,
      "learning_rate": 3.668560921155084e-09,
      "loss": 0.4644,
      "step": 943550
    },
    {
      "epoch": 9.989365925439735,
      "grad_norm": 1.3172672986984253,
      "learning_rate": 3.4225860256476004e-09,
      "loss": 0.4672,
      "step": 943600
    },
    {
      "epoch": 9.989895247219737,
      "grad_norm": 1.3973678350448608,
      "learning_rate": 3.1851459215970214e-09,
      "loss": 0.4631,
      "step": 943650
    },
    {
      "epoch": 9.99042456899974,
      "grad_norm": 1.3665893077850342,
      "learning_rate": 2.9562406171357304e-09,
      "loss": 0.4686,
      "step": 943700
    },
    {
      "epoch": 9.990953890779744,
      "grad_norm": 1.410394549369812,
      "learning_rate": 2.7358701200907997e-09,
      "loss": 0.4672,
      "step": 943750
    },
    {
      "epoch": 9.991483212559746,
      "grad_norm": 1.162831425666809,
      "learning_rate": 2.5240344379284795e-09,
      "loss": 0.4689,
      "step": 943800
    },
    {
      "epoch": 9.99201253433975,
      "grad_norm": 1.3463910818099976,
      "learning_rate": 2.3207335779207305e-09,
      "loss": 0.4655,
      "step": 943850
    },
    {
      "epoch": 9.992541856119754,
      "grad_norm": 1.231523871421814,
      "learning_rate": 2.125967546978691e-09,
      "loss": 0.468,
      "step": 943900
    },
    {
      "epoch": 9.993071177899758,
      "grad_norm": 1.1924017667770386,
      "learning_rate": 1.9397363517914547e-09,
      "loss": 0.4711,
      "step": 943950
    },
    {
      "epoch": 9.99360049967976,
      "grad_norm": 1.3623855113983154,
      "learning_rate": 1.7620399986872925e-09,
      "loss": 0.4739,
      "step": 944000
    },
    {
      "epoch": 9.99360049967976,
      "eval_loss": 0.28783315420150757,
      "eval_runtime": 46.9551,
      "eval_samples_per_second": 3576.397,
      "eval_steps_per_second": 447.066,
      "step": 944000
    },
    {
      "epoch": 9.994129821459763,
      "grad_norm": 1.3824007511138916,
      "learning_rate": 1.5928784937724317e-09,
      "loss": 0.4695,
      "step": 944050
    },
    {
      "epoch": 9.994659143239767,
      "grad_norm": 1.3372763395309448,
      "learning_rate": 1.4322518427645203e-09,
      "loss": 0.4717,
      "step": 944100
    },
    {
      "epoch": 9.99518846501977,
      "grad_norm": 1.3304628133773804,
      "learning_rate": 1.2801600511869182e-09,
      "loss": 0.4661,
      "step": 944150
    },
    {
      "epoch": 9.995717786799773,
      "grad_norm": 1.3802459239959717,
      "learning_rate": 1.1366031242021623e-09,
      "loss": 0.4535,
      "step": 944200
    },
    {
      "epoch": 9.996247108579777,
      "grad_norm": 1.4151440858840942,
      "learning_rate": 1.0015810667507452e-09,
      "loss": 0.4715,
      "step": 944250
    },
    {
      "epoch": 9.99677643035978,
      "grad_norm": 1.4479789733886719,
      "learning_rate": 8.750938834123368e-10,
      "loss": 0.4615,
      "step": 944300
    },
    {
      "epoch": 9.997305752139784,
      "grad_norm": 1.2870393991470337,
      "learning_rate": 7.571415784890512e-10,
      "loss": 0.4629,
      "step": 944350
    },
    {
      "epoch": 9.997835073919786,
      "grad_norm": 1.2930853366851807,
      "learning_rate": 6.477241560609581e-10,
      "loss": 0.4663,
      "step": 944400
    },
    {
      "epoch": 9.99836439569979,
      "grad_norm": 1.4732282161712646,
      "learning_rate": 5.468416198473048e-10,
      "loss": 0.4669,
      "step": 944450
    },
    {
      "epoch": 9.998893717479794,
      "grad_norm": 1.3875994682312012,
      "learning_rate": 4.544939732620268e-10,
      "loss": 0.4592,
      "step": 944500
    },
    {
      "epoch": 9.998893717479794,
      "eval_loss": 0.28783342242240906,
      "eval_runtime": 46.9801,
      "eval_samples_per_second": 3574.493,
      "eval_steps_per_second": 446.828,
      "step": 944500
    },
    {
      "epoch": 9.999423039259796,
      "grad_norm": 1.433057188987732,
      "learning_rate": 3.7068121946925994e-10,
      "loss": 0.4682,
      "step": 944550
    },
    {
      "epoch": 9.9999523610398,
      "grad_norm": 1.3663560152053833,
      "learning_rate": 2.9540336132782843e-10,
      "loss": 0.4741,
      "step": 944600
    }
  ],
  "logging_steps": 50,
  "max_steps": 944600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7503633370710016e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
