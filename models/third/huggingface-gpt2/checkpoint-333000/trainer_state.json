{
  "best_metric": 0.30536413192749023,
  "best_model_checkpoint": "./models/third/huggingface-gpt2/checkpoint-328000",
  "epoch": 3.5252671751684566,
  "eval_steps": 1000,
  "global_step": 333000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0010586435600065636,
      "grad_norm": 24.430843353271484,
      "learning_rate": 3.1759474910014816e-08,
      "loss": 5.2035,
      "step": 100
    },
    {
      "epoch": 0.0021172871200131273,
      "grad_norm": 24.456748962402344,
      "learning_rate": 6.351894982002963e-08,
      "loss": 5.0562,
      "step": 200
    },
    {
      "epoch": 0.0031759306800196907,
      "grad_norm": 21.938371658325195,
      "learning_rate": 9.527842473004445e-08,
      "loss": 4.7798,
      "step": 300
    },
    {
      "epoch": 0.004234574240026255,
      "grad_norm": 17.205066680908203,
      "learning_rate": 1.2703789964005926e-07,
      "loss": 4.3942,
      "step": 400
    },
    {
      "epoch": 0.005293217800032818,
      "grad_norm": 11.859346389770508,
      "learning_rate": 1.5879737455007407e-07,
      "loss": 3.9816,
      "step": 500
    },
    {
      "epoch": 0.006351861360039381,
      "grad_norm": 9.144007682800293,
      "learning_rate": 1.905568494600889e-07,
      "loss": 3.6383,
      "step": 600
    },
    {
      "epoch": 0.007410504920045945,
      "grad_norm": 7.0633416175842285,
      "learning_rate": 2.2231632437010372e-07,
      "loss": 3.3737,
      "step": 700
    },
    {
      "epoch": 0.00846914848005251,
      "grad_norm": 6.387392520904541,
      "learning_rate": 2.540757992801185e-07,
      "loss": 3.2241,
      "step": 800
    },
    {
      "epoch": 0.009527792040059073,
      "grad_norm": 6.308503150939941,
      "learning_rate": 2.8583527419013336e-07,
      "loss": 3.1168,
      "step": 900
    },
    {
      "epoch": 0.010586435600065636,
      "grad_norm": 6.718043804168701,
      "learning_rate": 3.1759474910014814e-07,
      "loss": 2.9972,
      "step": 1000
    },
    {
      "epoch": 0.010586435600065636,
      "eval_loss": 2.917384624481201,
      "eval_runtime": 57.7291,
      "eval_samples_per_second": 2908.929,
      "eval_steps_per_second": 363.629,
      "step": 1000
    },
    {
      "epoch": 0.0116450791600722,
      "grad_norm": 5.2288641929626465,
      "learning_rate": 3.4935422401016303e-07,
      "loss": 2.9198,
      "step": 1100
    },
    {
      "epoch": 0.012703722720078763,
      "grad_norm": 5.920466899871826,
      "learning_rate": 3.811136989201778e-07,
      "loss": 2.8433,
      "step": 1200
    },
    {
      "epoch": 0.013762366280085326,
      "grad_norm": 5.006708145141602,
      "learning_rate": 4.1287317383019265e-07,
      "loss": 2.7764,
      "step": 1300
    },
    {
      "epoch": 0.01482100984009189,
      "grad_norm": 5.157912254333496,
      "learning_rate": 4.4463264874020743e-07,
      "loss": 2.6942,
      "step": 1400
    },
    {
      "epoch": 0.015879653400098455,
      "grad_norm": 4.866508483886719,
      "learning_rate": 4.763921236502223e-07,
      "loss": 2.6507,
      "step": 1500
    },
    {
      "epoch": 0.01693829696010502,
      "grad_norm": 6.02846622467041,
      "learning_rate": 5.08151598560237e-07,
      "loss": 2.6235,
      "step": 1600
    },
    {
      "epoch": 0.017996940520111582,
      "grad_norm": 5.460129737854004,
      "learning_rate": 5.399110734702519e-07,
      "loss": 2.5847,
      "step": 1700
    },
    {
      "epoch": 0.019055584080118145,
      "grad_norm": 5.4913787841796875,
      "learning_rate": 5.716705483802667e-07,
      "loss": 2.5352,
      "step": 1800
    },
    {
      "epoch": 0.02011422764012471,
      "grad_norm": 4.743558406829834,
      "learning_rate": 6.034300232902816e-07,
      "loss": 2.5144,
      "step": 1900
    },
    {
      "epoch": 0.021172871200131272,
      "grad_norm": 5.557276725769043,
      "learning_rate": 6.351894982002963e-07,
      "loss": 2.5188,
      "step": 2000
    },
    {
      "epoch": 0.021172871200131272,
      "eval_loss": 2.464190721511841,
      "eval_runtime": 57.5315,
      "eval_samples_per_second": 2918.925,
      "eval_steps_per_second": 364.879,
      "step": 2000
    },
    {
      "epoch": 0.022231514760137835,
      "grad_norm": 5.795792579650879,
      "learning_rate": 6.669489731103112e-07,
      "loss": 2.4718,
      "step": 2100
    },
    {
      "epoch": 0.0232901583201444,
      "grad_norm": 4.256834983825684,
      "learning_rate": 6.987084480203261e-07,
      "loss": 2.4655,
      "step": 2200
    },
    {
      "epoch": 0.024348801880150962,
      "grad_norm": 4.4388427734375,
      "learning_rate": 7.304679229303408e-07,
      "loss": 2.412,
      "step": 2300
    },
    {
      "epoch": 0.025407445440157526,
      "grad_norm": 4.811970233917236,
      "learning_rate": 7.622273978403556e-07,
      "loss": 2.407,
      "step": 2400
    },
    {
      "epoch": 0.02646608900016409,
      "grad_norm": 4.580066680908203,
      "learning_rate": 7.939868727503705e-07,
      "loss": 2.3774,
      "step": 2500
    },
    {
      "epoch": 0.027524732560170653,
      "grad_norm": 4.691243648529053,
      "learning_rate": 8.257463476603853e-07,
      "loss": 2.3681,
      "step": 2600
    },
    {
      "epoch": 0.028583376120177216,
      "grad_norm": 4.142621040344238,
      "learning_rate": 8.575058225704001e-07,
      "loss": 2.3524,
      "step": 2700
    },
    {
      "epoch": 0.02964201968018378,
      "grad_norm": 5.2618489265441895,
      "learning_rate": 8.892652974804149e-07,
      "loss": 2.327,
      "step": 2800
    },
    {
      "epoch": 0.030700663240190343,
      "grad_norm": 5.152374744415283,
      "learning_rate": 9.210247723904297e-07,
      "loss": 2.3214,
      "step": 2900
    },
    {
      "epoch": 0.03175930680019691,
      "grad_norm": 4.567437171936035,
      "learning_rate": 9.527842473004446e-07,
      "loss": 2.2989,
      "step": 3000
    },
    {
      "epoch": 0.03175930680019691,
      "eval_loss": 2.29868483543396,
      "eval_runtime": 57.6055,
      "eval_samples_per_second": 2915.171,
      "eval_steps_per_second": 364.409,
      "step": 3000
    },
    {
      "epoch": 0.03281795036020347,
      "grad_norm": 4.693101406097412,
      "learning_rate": 9.845437222104594e-07,
      "loss": 2.2919,
      "step": 3100
    },
    {
      "epoch": 0.03387659392021004,
      "grad_norm": 5.473380088806152,
      "learning_rate": 1.016303197120474e-06,
      "loss": 2.2817,
      "step": 3200
    },
    {
      "epoch": 0.0349352374802166,
      "grad_norm": 4.46942138671875,
      "learning_rate": 1.048062672030489e-06,
      "loss": 2.2638,
      "step": 3300
    },
    {
      "epoch": 0.035993881040223163,
      "grad_norm": 3.928621292114258,
      "learning_rate": 1.0798221469405038e-06,
      "loss": 2.2433,
      "step": 3400
    },
    {
      "epoch": 0.03705252460022972,
      "grad_norm": 5.2112226486206055,
      "learning_rate": 1.1115816218505187e-06,
      "loss": 2.2453,
      "step": 3500
    },
    {
      "epoch": 0.03811116816023629,
      "grad_norm": 5.603671073913574,
      "learning_rate": 1.1433410967605334e-06,
      "loss": 2.2328,
      "step": 3600
    },
    {
      "epoch": 0.03916981172024285,
      "grad_norm": 4.842904090881348,
      "learning_rate": 1.1751005716705484e-06,
      "loss": 2.234,
      "step": 3700
    },
    {
      "epoch": 0.04022845528024942,
      "grad_norm": 5.0588836669921875,
      "learning_rate": 1.2068600465805631e-06,
      "loss": 2.1888,
      "step": 3800
    },
    {
      "epoch": 0.04128709884025598,
      "grad_norm": 4.442283630371094,
      "learning_rate": 1.2386195214905778e-06,
      "loss": 2.214,
      "step": 3900
    },
    {
      "epoch": 0.042345742400262544,
      "grad_norm": 4.599628448486328,
      "learning_rate": 1.2703789964005926e-06,
      "loss": 2.195,
      "step": 4000
    },
    {
      "epoch": 0.042345742400262544,
      "eval_loss": 2.1817502975463867,
      "eval_runtime": 57.6684,
      "eval_samples_per_second": 2911.992,
      "eval_steps_per_second": 364.012,
      "step": 4000
    },
    {
      "epoch": 0.043404385960269104,
      "grad_norm": 4.898568153381348,
      "learning_rate": 1.3021384713106075e-06,
      "loss": 2.1705,
      "step": 4100
    },
    {
      "epoch": 0.04446302952027567,
      "grad_norm": 3.874974489212036,
      "learning_rate": 1.3338979462206225e-06,
      "loss": 2.1615,
      "step": 4200
    },
    {
      "epoch": 0.04552167308028224,
      "grad_norm": 4.539478302001953,
      "learning_rate": 1.3656574211306372e-06,
      "loss": 2.1609,
      "step": 4300
    },
    {
      "epoch": 0.0465803166402888,
      "grad_norm": 4.405272006988525,
      "learning_rate": 1.3974168960406521e-06,
      "loss": 2.145,
      "step": 4400
    },
    {
      "epoch": 0.047638960200295365,
      "grad_norm": 4.8248090744018555,
      "learning_rate": 1.4291763709506669e-06,
      "loss": 2.1216,
      "step": 4500
    },
    {
      "epoch": 0.048697603760301925,
      "grad_norm": 3.913130760192871,
      "learning_rate": 1.4609358458606816e-06,
      "loss": 2.1468,
      "step": 4600
    },
    {
      "epoch": 0.04975624732030849,
      "grad_norm": 4.916311740875244,
      "learning_rate": 1.4926953207706965e-06,
      "loss": 2.1387,
      "step": 4700
    },
    {
      "epoch": 0.05081489088031505,
      "grad_norm": 4.466479301452637,
      "learning_rate": 1.5244547956807113e-06,
      "loss": 2.1359,
      "step": 4800
    },
    {
      "epoch": 0.05187353444032162,
      "grad_norm": 5.312924861907959,
      "learning_rate": 1.556214270590726e-06,
      "loss": 2.0968,
      "step": 4900
    },
    {
      "epoch": 0.05293217800032818,
      "grad_norm": 4.014692306518555,
      "learning_rate": 1.587973745500741e-06,
      "loss": 2.0901,
      "step": 5000
    },
    {
      "epoch": 0.05293217800032818,
      "eval_loss": 2.1003756523132324,
      "eval_runtime": 57.5541,
      "eval_samples_per_second": 2917.779,
      "eval_steps_per_second": 364.735,
      "step": 5000
    },
    {
      "epoch": 0.053990821560334745,
      "grad_norm": 4.3215861320495605,
      "learning_rate": 1.6197332204107559e-06,
      "loss": 2.096,
      "step": 5100
    },
    {
      "epoch": 0.055049465120341305,
      "grad_norm": 4.146119117736816,
      "learning_rate": 1.6514926953207706e-06,
      "loss": 2.0937,
      "step": 5200
    },
    {
      "epoch": 0.05610810868034787,
      "grad_norm": 4.251446723937988,
      "learning_rate": 1.6832521702307855e-06,
      "loss": 2.091,
      "step": 5300
    },
    {
      "epoch": 0.05716675224035443,
      "grad_norm": 3.9418957233428955,
      "learning_rate": 1.7150116451408003e-06,
      "loss": 2.0698,
      "step": 5400
    },
    {
      "epoch": 0.058225395800361,
      "grad_norm": 4.518497467041016,
      "learning_rate": 1.746771120050815e-06,
      "loss": 2.094,
      "step": 5500
    },
    {
      "epoch": 0.05928403936036756,
      "grad_norm": 3.9519288539886475,
      "learning_rate": 1.7785305949608297e-06,
      "loss": 2.0651,
      "step": 5600
    },
    {
      "epoch": 0.060342682920374126,
      "grad_norm": 4.2935357093811035,
      "learning_rate": 1.8102900698708447e-06,
      "loss": 2.0582,
      "step": 5700
    },
    {
      "epoch": 0.061401326480380686,
      "grad_norm": 4.905015468597412,
      "learning_rate": 1.8420495447808594e-06,
      "loss": 2.0392,
      "step": 5800
    },
    {
      "epoch": 0.06245997004038725,
      "grad_norm": 5.256981372833252,
      "learning_rate": 1.8738090196908741e-06,
      "loss": 2.042,
      "step": 5900
    },
    {
      "epoch": 0.06351861360039382,
      "grad_norm": 4.144157409667969,
      "learning_rate": 1.9055684946008893e-06,
      "loss": 2.0386,
      "step": 6000
    },
    {
      "epoch": 0.06351861360039382,
      "eval_loss": 2.0467841625213623,
      "eval_runtime": 57.6535,
      "eval_samples_per_second": 2912.747,
      "eval_steps_per_second": 364.106,
      "step": 6000
    },
    {
      "epoch": 0.06457725716040037,
      "grad_norm": 4.1333770751953125,
      "learning_rate": 1.9370103747618036e-06,
      "loss": 2.0353,
      "step": 6100
    },
    {
      "epoch": 0.06563590072040694,
      "grad_norm": 4.725251197814941,
      "learning_rate": 1.9687698496718186e-06,
      "loss": 2.0233,
      "step": 6200
    },
    {
      "epoch": 0.0666945442804135,
      "grad_norm": 4.225010871887207,
      "learning_rate": 2.0005293245818335e-06,
      "loss": 2.0362,
      "step": 6300
    },
    {
      "epoch": 0.06775318784042007,
      "grad_norm": 4.9698710441589355,
      "learning_rate": 2.032288799491848e-06,
      "loss": 2.0242,
      "step": 6400
    },
    {
      "epoch": 0.06881183140042664,
      "grad_norm": 4.083765506744385,
      "learning_rate": 2.064048274401863e-06,
      "loss": 2.0201,
      "step": 6500
    },
    {
      "epoch": 0.0698704749604332,
      "grad_norm": 4.310042858123779,
      "learning_rate": 2.095807749311878e-06,
      "loss": 2.0117,
      "step": 6600
    },
    {
      "epoch": 0.07092911852043976,
      "grad_norm": 4.559233665466309,
      "learning_rate": 2.127567224221893e-06,
      "loss": 2.0344,
      "step": 6700
    },
    {
      "epoch": 0.07198776208044633,
      "grad_norm": 4.281623840332031,
      "learning_rate": 2.1593266991319074e-06,
      "loss": 2.0162,
      "step": 6800
    },
    {
      "epoch": 0.0730464056404529,
      "grad_norm": 3.906655788421631,
      "learning_rate": 2.1910861740419223e-06,
      "loss": 2.0117,
      "step": 6900
    },
    {
      "epoch": 0.07410504920045945,
      "grad_norm": 3.8091912269592285,
      "learning_rate": 2.2228456489519373e-06,
      "loss": 1.9954,
      "step": 7000
    },
    {
      "epoch": 0.07410504920045945,
      "eval_loss": 2.013216257095337,
      "eval_runtime": 57.6413,
      "eval_samples_per_second": 2913.361,
      "eval_steps_per_second": 364.183,
      "step": 7000
    },
    {
      "epoch": 0.07516369276046601,
      "grad_norm": 3.9671292304992676,
      "learning_rate": 2.2546051238619518e-06,
      "loss": 2.0191,
      "step": 7100
    },
    {
      "epoch": 0.07622233632047258,
      "grad_norm": 5.231055736541748,
      "learning_rate": 2.2863645987719667e-06,
      "loss": 2.0145,
      "step": 7200
    },
    {
      "epoch": 0.07728097988047915,
      "grad_norm": 4.6129608154296875,
      "learning_rate": 2.3181240736819817e-06,
      "loss": 1.9847,
      "step": 7300
    },
    {
      "epoch": 0.0783396234404857,
      "grad_norm": 4.026264190673828,
      "learning_rate": 2.3498835485919966e-06,
      "loss": 2.0007,
      "step": 7400
    },
    {
      "epoch": 0.07939826700049227,
      "grad_norm": 4.534401893615723,
      "learning_rate": 2.3816430235020115e-06,
      "loss": 2.0027,
      "step": 7500
    },
    {
      "epoch": 0.08045691056049883,
      "grad_norm": 5.170559883117676,
      "learning_rate": 2.413402498412026e-06,
      "loss": 1.9631,
      "step": 7600
    },
    {
      "epoch": 0.0815155541205054,
      "grad_norm": 3.8301336765289307,
      "learning_rate": 2.445161973322041e-06,
      "loss": 1.9971,
      "step": 7700
    },
    {
      "epoch": 0.08257419768051195,
      "grad_norm": 4.733866214752197,
      "learning_rate": 2.4769214482320555e-06,
      "loss": 1.9818,
      "step": 7800
    },
    {
      "epoch": 0.08363284124051852,
      "grad_norm": 4.099436283111572,
      "learning_rate": 2.5086809231420705e-06,
      "loss": 1.9684,
      "step": 7900
    },
    {
      "epoch": 0.08469148480052509,
      "grad_norm": 4.166833877563477,
      "learning_rate": 2.5404403980520854e-06,
      "loss": 1.9593,
      "step": 8000
    },
    {
      "epoch": 0.08469148480052509,
      "eval_loss": 1.9872324466705322,
      "eval_runtime": 57.5497,
      "eval_samples_per_second": 2918.002,
      "eval_steps_per_second": 364.763,
      "step": 8000
    },
    {
      "epoch": 0.08575012836053165,
      "grad_norm": 4.51580810546875,
      "learning_rate": 2.5721998729621003e-06,
      "loss": 1.983,
      "step": 8100
    },
    {
      "epoch": 0.08680877192053821,
      "grad_norm": 4.527337074279785,
      "learning_rate": 2.6036417531230147e-06,
      "loss": 1.9806,
      "step": 8200
    },
    {
      "epoch": 0.08786741548054477,
      "grad_norm": 3.805485725402832,
      "learning_rate": 2.6354012280330296e-06,
      "loss": 1.9656,
      "step": 8300
    },
    {
      "epoch": 0.08892605904055134,
      "grad_norm": 4.311373710632324,
      "learning_rate": 2.667160702943044e-06,
      "loss": 1.9771,
      "step": 8400
    },
    {
      "epoch": 0.08998470260055791,
      "grad_norm": 4.387763977050781,
      "learning_rate": 2.698920177853059e-06,
      "loss": 1.9722,
      "step": 8500
    },
    {
      "epoch": 0.09104334616056448,
      "grad_norm": 4.729931354522705,
      "learning_rate": 2.730679652763074e-06,
      "loss": 1.9696,
      "step": 8600
    },
    {
      "epoch": 0.09210198972057103,
      "grad_norm": 5.378541946411133,
      "learning_rate": 2.762439127673089e-06,
      "loss": 1.9426,
      "step": 8700
    },
    {
      "epoch": 0.0931606332805776,
      "grad_norm": 4.156233310699463,
      "learning_rate": 2.794198602583104e-06,
      "loss": 1.959,
      "step": 8800
    },
    {
      "epoch": 0.09421927684058416,
      "grad_norm": 4.679974555969238,
      "learning_rate": 2.8259580774931184e-06,
      "loss": 1.9639,
      "step": 8900
    },
    {
      "epoch": 0.09527792040059073,
      "grad_norm": 4.24869441986084,
      "learning_rate": 2.8577175524031334e-06,
      "loss": 1.9606,
      "step": 9000
    },
    {
      "epoch": 0.09527792040059073,
      "eval_loss": 1.9634838104248047,
      "eval_runtime": 57.5931,
      "eval_samples_per_second": 2915.799,
      "eval_steps_per_second": 364.488,
      "step": 9000
    },
    {
      "epoch": 0.09633656396059728,
      "grad_norm": 3.8798131942749023,
      "learning_rate": 2.889477027313148e-06,
      "loss": 1.9553,
      "step": 9100
    },
    {
      "epoch": 0.09739520752060385,
      "grad_norm": 4.40772008895874,
      "learning_rate": 2.921236502223163e-06,
      "loss": 1.9379,
      "step": 9200
    },
    {
      "epoch": 0.09845385108061042,
      "grad_norm": 4.597944736480713,
      "learning_rate": 2.952995977133178e-06,
      "loss": 1.9503,
      "step": 9300
    },
    {
      "epoch": 0.09951249464061698,
      "grad_norm": 4.3910627365112305,
      "learning_rate": 2.9847554520431927e-06,
      "loss": 1.9458,
      "step": 9400
    },
    {
      "epoch": 0.10057113820062354,
      "grad_norm": 4.198166370391846,
      "learning_rate": 3.0165149269532077e-06,
      "loss": 1.9503,
      "step": 9500
    },
    {
      "epoch": 0.1016297817606301,
      "grad_norm": 4.255577564239502,
      "learning_rate": 3.048274401863222e-06,
      "loss": 1.9529,
      "step": 9600
    },
    {
      "epoch": 0.10268842532063667,
      "grad_norm": 3.8628838062286377,
      "learning_rate": 3.080033876773237e-06,
      "loss": 1.9431,
      "step": 9700
    },
    {
      "epoch": 0.10374706888064324,
      "grad_norm": 3.7423415184020996,
      "learning_rate": 3.1117933516832516e-06,
      "loss": 1.922,
      "step": 9800
    },
    {
      "epoch": 0.10480571244064979,
      "grad_norm": 4.6015238761901855,
      "learning_rate": 3.143552826593267e-06,
      "loss": 1.9265,
      "step": 9900
    },
    {
      "epoch": 0.10586435600065636,
      "grad_norm": 3.962885856628418,
      "learning_rate": 3.1753123015032815e-06,
      "loss": 1.9396,
      "step": 10000
    },
    {
      "epoch": 0.10586435600065636,
      "eval_loss": 1.9439082145690918,
      "eval_runtime": 57.5683,
      "eval_samples_per_second": 2917.056,
      "eval_steps_per_second": 364.645,
      "step": 10000
    },
    {
      "epoch": 0.10692299956066292,
      "grad_norm": 4.541780471801758,
      "learning_rate": 3.2070717764132965e-06,
      "loss": 1.9238,
      "step": 10100
    },
    {
      "epoch": 0.10798164312066949,
      "grad_norm": 3.7999331951141357,
      "learning_rate": 3.238831251323311e-06,
      "loss": 1.9344,
      "step": 10200
    },
    {
      "epoch": 0.10904028668067604,
      "grad_norm": 3.926361322402954,
      "learning_rate": 3.270590726233326e-06,
      "loss": 1.9337,
      "step": 10300
    },
    {
      "epoch": 0.11009893024068261,
      "grad_norm": 4.352002143859863,
      "learning_rate": 3.302350201143341e-06,
      "loss": 1.9273,
      "step": 10400
    },
    {
      "epoch": 0.11115757380068918,
      "grad_norm": 3.8649253845214844,
      "learning_rate": 3.3341096760533554e-06,
      "loss": 1.9298,
      "step": 10500
    },
    {
      "epoch": 0.11221621736069574,
      "grad_norm": 4.617393970489502,
      "learning_rate": 3.3658691509633707e-06,
      "loss": 1.9319,
      "step": 10600
    },
    {
      "epoch": 0.11327486092070231,
      "grad_norm": 3.9019622802734375,
      "learning_rate": 3.3976286258733853e-06,
      "loss": 1.9302,
      "step": 10700
    },
    {
      "epoch": 0.11433350448070886,
      "grad_norm": 4.354842662811279,
      "learning_rate": 3.4293881007834e-06,
      "loss": 1.9329,
      "step": 10800
    },
    {
      "epoch": 0.11539214804071543,
      "grad_norm": 4.777172565460205,
      "learning_rate": 3.4611475756934147e-06,
      "loss": 1.9183,
      "step": 10900
    },
    {
      "epoch": 0.116450791600722,
      "grad_norm": 3.989776134490967,
      "learning_rate": 3.4929070506034297e-06,
      "loss": 1.9056,
      "step": 11000
    },
    {
      "epoch": 0.116450791600722,
      "eval_loss": 1.9284024238586426,
      "eval_runtime": 57.6214,
      "eval_samples_per_second": 2914.367,
      "eval_steps_per_second": 364.309,
      "step": 11000
    },
    {
      "epoch": 0.11750943516072856,
      "grad_norm": 4.167524337768555,
      "learning_rate": 3.524666525513444e-06,
      "loss": 1.9306,
      "step": 11100
    },
    {
      "epoch": 0.11856807872073512,
      "grad_norm": 3.8575527667999268,
      "learning_rate": 3.5564260004234595e-06,
      "loss": 1.9141,
      "step": 11200
    },
    {
      "epoch": 0.11962672228074168,
      "grad_norm": 4.166985988616943,
      "learning_rate": 3.5881854753334745e-06,
      "loss": 1.9048,
      "step": 11300
    },
    {
      "epoch": 0.12068536584074825,
      "grad_norm": 4.212471008300781,
      "learning_rate": 3.619944950243489e-06,
      "loss": 1.9152,
      "step": 11400
    },
    {
      "epoch": 0.12174400940075482,
      "grad_norm": 3.9291226863861084,
      "learning_rate": 3.651704425153504e-06,
      "loss": 1.9178,
      "step": 11500
    },
    {
      "epoch": 0.12280265296076137,
      "grad_norm": 4.065088272094727,
      "learning_rate": 3.6834639000635185e-06,
      "loss": 1.9247,
      "step": 11600
    },
    {
      "epoch": 0.12386129652076794,
      "grad_norm": 3.8566904067993164,
      "learning_rate": 3.7152233749735334e-06,
      "loss": 1.9156,
      "step": 11700
    },
    {
      "epoch": 0.1249199400807745,
      "grad_norm": 4.099164962768555,
      "learning_rate": 3.746982849883548e-06,
      "loss": 1.9136,
      "step": 11800
    },
    {
      "epoch": 0.12597858364078107,
      "grad_norm": 4.270382404327393,
      "learning_rate": 3.7787423247935633e-06,
      "loss": 1.9133,
      "step": 11900
    },
    {
      "epoch": 0.12703722720078764,
      "grad_norm": 3.6241610050201416,
      "learning_rate": 3.8105017997035782e-06,
      "loss": 1.9133,
      "step": 12000
    },
    {
      "epoch": 0.12703722720078764,
      "eval_loss": 1.9107460975646973,
      "eval_runtime": 58.0069,
      "eval_samples_per_second": 2894.999,
      "eval_steps_per_second": 361.888,
      "step": 12000
    },
    {
      "epoch": 0.1280958707607942,
      "grad_norm": 4.30761194229126,
      "learning_rate": 3.842261274613593e-06,
      "loss": 1.9105,
      "step": 12100
    },
    {
      "epoch": 0.12915451432080075,
      "grad_norm": 3.9956843852996826,
      "learning_rate": 3.8737031547745075e-06,
      "loss": 1.8871,
      "step": 12200
    },
    {
      "epoch": 0.1302131578808073,
      "grad_norm": 4.396095275878906,
      "learning_rate": 3.905462629684522e-06,
      "loss": 1.8932,
      "step": 12300
    },
    {
      "epoch": 0.13127180144081388,
      "grad_norm": 3.989975690841675,
      "learning_rate": 3.9372221045945366e-06,
      "loss": 1.9072,
      "step": 12400
    },
    {
      "epoch": 0.13233044500082045,
      "grad_norm": 3.970668315887451,
      "learning_rate": 3.968981579504552e-06,
      "loss": 1.8912,
      "step": 12500
    },
    {
      "epoch": 0.133389088560827,
      "grad_norm": 3.661752223968506,
      "learning_rate": 4.0007410544145664e-06,
      "loss": 1.9094,
      "step": 12600
    },
    {
      "epoch": 0.13444773212083358,
      "grad_norm": 3.9450035095214844,
      "learning_rate": 4.032500529324582e-06,
      "loss": 1.8854,
      "step": 12700
    },
    {
      "epoch": 0.13550637568084015,
      "grad_norm": 4.105353355407715,
      "learning_rate": 4.064260004234596e-06,
      "loss": 1.8996,
      "step": 12800
    },
    {
      "epoch": 0.1365650192408467,
      "grad_norm": 4.3337249755859375,
      "learning_rate": 4.096019479144611e-06,
      "loss": 1.903,
      "step": 12900
    },
    {
      "epoch": 0.13762366280085328,
      "grad_norm": 3.6761364936828613,
      "learning_rate": 4.127778954054625e-06,
      "loss": 1.8827,
      "step": 13000
    },
    {
      "epoch": 0.13762366280085328,
      "eval_loss": 1.8959187269210815,
      "eval_runtime": 57.3998,
      "eval_samples_per_second": 2925.62,
      "eval_steps_per_second": 365.716,
      "step": 13000
    },
    {
      "epoch": 0.13868230636085982,
      "grad_norm": 3.9034390449523926,
      "learning_rate": 4.159538428964641e-06,
      "loss": 1.9008,
      "step": 13100
    },
    {
      "epoch": 0.1397409499208664,
      "grad_norm": 4.246476173400879,
      "learning_rate": 4.191297903874656e-06,
      "loss": 1.8741,
      "step": 13200
    },
    {
      "epoch": 0.14079959348087295,
      "grad_norm": 3.5334668159484863,
      "learning_rate": 4.223057378784671e-06,
      "loss": 1.8798,
      "step": 13300
    },
    {
      "epoch": 0.14185823704087952,
      "grad_norm": 3.8841466903686523,
      "learning_rate": 4.254816853694685e-06,
      "loss": 1.8849,
      "step": 13400
    },
    {
      "epoch": 0.1429168806008861,
      "grad_norm": 3.679039239883423,
      "learning_rate": 4.2865763286047e-06,
      "loss": 1.8758,
      "step": 13500
    },
    {
      "epoch": 0.14397552416089265,
      "grad_norm": 4.125595569610596,
      "learning_rate": 4.318335803514715e-06,
      "loss": 1.8861,
      "step": 13600
    },
    {
      "epoch": 0.14503416772089922,
      "grad_norm": 3.642867088317871,
      "learning_rate": 4.3500952784247295e-06,
      "loss": 1.8844,
      "step": 13700
    },
    {
      "epoch": 0.1460928112809058,
      "grad_norm": 3.859651803970337,
      "learning_rate": 4.381854753334745e-06,
      "loss": 1.8809,
      "step": 13800
    },
    {
      "epoch": 0.14715145484091233,
      "grad_norm": 3.9354331493377686,
      "learning_rate": 4.413614228244759e-06,
      "loss": 1.8812,
      "step": 13900
    },
    {
      "epoch": 0.1482100984009189,
      "grad_norm": 4.903969764709473,
      "learning_rate": 4.445373703154774e-06,
      "loss": 1.864,
      "step": 14000
    },
    {
      "epoch": 0.1482100984009189,
      "eval_loss": 1.8775231838226318,
      "eval_runtime": 58.0782,
      "eval_samples_per_second": 2891.448,
      "eval_steps_per_second": 361.444,
      "step": 14000
    },
    {
      "epoch": 0.14926874196092546,
      "grad_norm": 4.597944736480713,
      "learning_rate": 4.477133178064789e-06,
      "loss": 1.8792,
      "step": 14100
    },
    {
      "epoch": 0.15032738552093203,
      "grad_norm": 4.276087284088135,
      "learning_rate": 4.508575058225703e-06,
      "loss": 1.861,
      "step": 14200
    },
    {
      "epoch": 0.1513860290809386,
      "grad_norm": 3.6080684661865234,
      "learning_rate": 4.540334533135719e-06,
      "loss": 1.8726,
      "step": 14300
    },
    {
      "epoch": 0.15244467264094516,
      "grad_norm": 3.884469747543335,
      "learning_rate": 4.572094008045733e-06,
      "loss": 1.8776,
      "step": 14400
    },
    {
      "epoch": 0.15350331620095173,
      "grad_norm": 3.9688191413879395,
      "learning_rate": 4.6038534829557485e-06,
      "loss": 1.8623,
      "step": 14500
    },
    {
      "epoch": 0.1545619597609583,
      "grad_norm": 3.9291231632232666,
      "learning_rate": 4.635612957865763e-06,
      "loss": 1.8702,
      "step": 14600
    },
    {
      "epoch": 0.15562060332096483,
      "grad_norm": 3.8078927993774414,
      "learning_rate": 4.6673724327757775e-06,
      "loss": 1.8537,
      "step": 14700
    },
    {
      "epoch": 0.1566792468809714,
      "grad_norm": 4.019222259521484,
      "learning_rate": 4.699131907685793e-06,
      "loss": 1.8696,
      "step": 14800
    },
    {
      "epoch": 0.15773789044097797,
      "grad_norm": 3.982206344604492,
      "learning_rate": 4.730891382595807e-06,
      "loss": 1.8691,
      "step": 14900
    },
    {
      "epoch": 0.15879653400098453,
      "grad_norm": 4.315815448760986,
      "learning_rate": 4.762650857505823e-06,
      "loss": 1.8577,
      "step": 15000
    },
    {
      "epoch": 0.15879653400098453,
      "eval_loss": 1.8598296642303467,
      "eval_runtime": 57.9857,
      "eval_samples_per_second": 2896.057,
      "eval_steps_per_second": 362.02,
      "step": 15000
    },
    {
      "epoch": 0.1598551775609911,
      "grad_norm": 3.7882537841796875,
      "learning_rate": 4.794410332415837e-06,
      "loss": 1.8418,
      "step": 15100
    },
    {
      "epoch": 0.16091382112099767,
      "grad_norm": 3.8057196140289307,
      "learning_rate": 4.826169807325852e-06,
      "loss": 1.8426,
      "step": 15200
    },
    {
      "epoch": 0.16197246468100424,
      "grad_norm": 3.568512439727783,
      "learning_rate": 4.857929282235866e-06,
      "loss": 1.8445,
      "step": 15300
    },
    {
      "epoch": 0.1630311082410108,
      "grad_norm": 4.435119152069092,
      "learning_rate": 4.889688757145882e-06,
      "loss": 1.8557,
      "step": 15400
    },
    {
      "epoch": 0.16408975180101737,
      "grad_norm": 3.956911087036133,
      "learning_rate": 4.921448232055896e-06,
      "loss": 1.8351,
      "step": 15500
    },
    {
      "epoch": 0.1651483953610239,
      "grad_norm": 4.233882427215576,
      "learning_rate": 4.953207706965911e-06,
      "loss": 1.8354,
      "step": 15600
    },
    {
      "epoch": 0.16620703892103048,
      "grad_norm": 3.9190168380737305,
      "learning_rate": 4.984967181875925e-06,
      "loss": 1.8615,
      "step": 15700
    },
    {
      "epoch": 0.16726568248103704,
      "grad_norm": 4.384501934051514,
      "learning_rate": 5.016726656785941e-06,
      "loss": 1.8481,
      "step": 15800
    },
    {
      "epoch": 0.1683243260410436,
      "grad_norm": 4.15214729309082,
      "learning_rate": 5.048486131695955e-06,
      "loss": 1.8421,
      "step": 15900
    },
    {
      "epoch": 0.16938296960105018,
      "grad_norm": 3.948502779006958,
      "learning_rate": 5.0802456066059705e-06,
      "loss": 1.8549,
      "step": 16000
    },
    {
      "epoch": 0.16938296960105018,
      "eval_loss": 1.8407539129257202,
      "eval_runtime": 57.6727,
      "eval_samples_per_second": 2911.775,
      "eval_steps_per_second": 363.985,
      "step": 16000
    },
    {
      "epoch": 0.17044161316105674,
      "grad_norm": 3.838841199874878,
      "learning_rate": 5.112005081515986e-06,
      "loss": 1.851,
      "step": 16100
    },
    {
      "epoch": 0.1715002567210633,
      "grad_norm": 4.445017337799072,
      "learning_rate": 5.1434469616769e-06,
      "loss": 1.8473,
      "step": 16200
    },
    {
      "epoch": 0.17255890028106988,
      "grad_norm": 4.086837291717529,
      "learning_rate": 5.175206436586914e-06,
      "loss": 1.8424,
      "step": 16300
    },
    {
      "epoch": 0.17361754384107642,
      "grad_norm": 4.757064342498779,
      "learning_rate": 5.206965911496929e-06,
      "loss": 1.8374,
      "step": 16400
    },
    {
      "epoch": 0.17467618740108298,
      "grad_norm": 4.065337657928467,
      "learning_rate": 5.238725386406944e-06,
      "loss": 1.8275,
      "step": 16500
    },
    {
      "epoch": 0.17573483096108955,
      "grad_norm": 4.286645412445068,
      "learning_rate": 5.2704848613169595e-06,
      "loss": 1.8338,
      "step": 16600
    },
    {
      "epoch": 0.17679347452109612,
      "grad_norm": 4.3684916496276855,
      "learning_rate": 5.302244336226974e-06,
      "loss": 1.8369,
      "step": 16700
    },
    {
      "epoch": 0.17785211808110268,
      "grad_norm": 4.066076278686523,
      "learning_rate": 5.334003811136989e-06,
      "loss": 1.8268,
      "step": 16800
    },
    {
      "epoch": 0.17891076164110925,
      "grad_norm": 4.075256824493408,
      "learning_rate": 5.365763286047004e-06,
      "loss": 1.8199,
      "step": 16900
    },
    {
      "epoch": 0.17996940520111582,
      "grad_norm": 4.373626708984375,
      "learning_rate": 5.3975227609570184e-06,
      "loss": 1.8257,
      "step": 17000
    },
    {
      "epoch": 0.17996940520111582,
      "eval_loss": 1.8157893419265747,
      "eval_runtime": 57.6276,
      "eval_samples_per_second": 2914.054,
      "eval_steps_per_second": 364.27,
      "step": 17000
    },
    {
      "epoch": 0.18102804876112238,
      "grad_norm": 4.478017330169678,
      "learning_rate": 5.429282235867033e-06,
      "loss": 1.8147,
      "step": 17100
    },
    {
      "epoch": 0.18208669232112895,
      "grad_norm": 4.016772270202637,
      "learning_rate": 5.461041710777048e-06,
      "loss": 1.821,
      "step": 17200
    },
    {
      "epoch": 0.1831453358811355,
      "grad_norm": 4.294445514678955,
      "learning_rate": 5.492801185687063e-06,
      "loss": 1.8266,
      "step": 17300
    },
    {
      "epoch": 0.18420397944114206,
      "grad_norm": 4.282205581665039,
      "learning_rate": 5.524560660597077e-06,
      "loss": 1.801,
      "step": 17400
    },
    {
      "epoch": 0.18526262300114862,
      "grad_norm": 4.359781265258789,
      "learning_rate": 5.556320135507092e-06,
      "loss": 1.8153,
      "step": 17500
    },
    {
      "epoch": 0.1863212665611552,
      "grad_norm": 4.3746771812438965,
      "learning_rate": 5.588079610417107e-06,
      "loss": 1.8049,
      "step": 17600
    },
    {
      "epoch": 0.18737991012116176,
      "grad_norm": 4.647176742553711,
      "learning_rate": 5.619839085327122e-06,
      "loss": 1.8002,
      "step": 17700
    },
    {
      "epoch": 0.18843855368116832,
      "grad_norm": 4.330231189727783,
      "learning_rate": 5.651598560237136e-06,
      "loss": 1.8044,
      "step": 17800
    },
    {
      "epoch": 0.1894971972411749,
      "grad_norm": 4.3708648681640625,
      "learning_rate": 5.6833580351471525e-06,
      "loss": 1.814,
      "step": 17900
    },
    {
      "epoch": 0.19055584080118146,
      "grad_norm": 4.062213897705078,
      "learning_rate": 5.715117510057167e-06,
      "loss": 1.8055,
      "step": 18000
    },
    {
      "epoch": 0.19055584080118146,
      "eval_loss": 1.7909173965454102,
      "eval_runtime": 57.6501,
      "eval_samples_per_second": 2912.919,
      "eval_steps_per_second": 364.128,
      "step": 18000
    },
    {
      "epoch": 0.191614484361188,
      "grad_norm": 4.427695274353027,
      "learning_rate": 5.7468769849671815e-06,
      "loss": 1.7863,
      "step": 18100
    },
    {
      "epoch": 0.19267312792119456,
      "grad_norm": 4.455685138702393,
      "learning_rate": 5.7783188651280955e-06,
      "loss": 1.7897,
      "step": 18200
    },
    {
      "epoch": 0.19373177148120113,
      "grad_norm": 4.156861782073975,
      "learning_rate": 5.810078340038111e-06,
      "loss": 1.8059,
      "step": 18300
    },
    {
      "epoch": 0.1947904150412077,
      "grad_norm": 4.176085948944092,
      "learning_rate": 5.841837814948125e-06,
      "loss": 1.785,
      "step": 18400
    },
    {
      "epoch": 0.19584905860121427,
      "grad_norm": 4.190321922302246,
      "learning_rate": 5.873597289858141e-06,
      "loss": 1.7855,
      "step": 18500
    },
    {
      "epoch": 0.19690770216122083,
      "grad_norm": 4.157288074493408,
      "learning_rate": 5.905356764768156e-06,
      "loss": 1.7953,
      "step": 18600
    },
    {
      "epoch": 0.1979663457212274,
      "grad_norm": 4.090560436248779,
      "learning_rate": 5.937116239678171e-06,
      "loss": 1.7834,
      "step": 18700
    },
    {
      "epoch": 0.19902498928123397,
      "grad_norm": 4.109589099884033,
      "learning_rate": 5.968875714588185e-06,
      "loss": 1.7641,
      "step": 18800
    },
    {
      "epoch": 0.2000836328412405,
      "grad_norm": 4.17642068862915,
      "learning_rate": 6.0006351894982e-06,
      "loss": 1.7802,
      "step": 18900
    },
    {
      "epoch": 0.20114227640124707,
      "grad_norm": 4.580854415893555,
      "learning_rate": 6.032394664408215e-06,
      "loss": 1.7815,
      "step": 19000
    },
    {
      "epoch": 0.20114227640124707,
      "eval_loss": 1.760793924331665,
      "eval_runtime": 57.5881,
      "eval_samples_per_second": 2916.054,
      "eval_steps_per_second": 364.52,
      "step": 19000
    },
    {
      "epoch": 0.20220091996125364,
      "grad_norm": 4.822668552398682,
      "learning_rate": 6.0641541393182295e-06,
      "loss": 1.7777,
      "step": 19100
    },
    {
      "epoch": 0.2032595635212602,
      "grad_norm": 4.231073379516602,
      "learning_rate": 6.095913614228244e-06,
      "loss": 1.7609,
      "step": 19200
    },
    {
      "epoch": 0.20431820708126677,
      "grad_norm": 3.7230238914489746,
      "learning_rate": 6.1276730891382585e-06,
      "loss": 1.7627,
      "step": 19300
    },
    {
      "epoch": 0.20537685064127334,
      "grad_norm": 3.9921226501464844,
      "learning_rate": 6.159432564048274e-06,
      "loss": 1.7672,
      "step": 19400
    },
    {
      "epoch": 0.2064354942012799,
      "grad_norm": 4.346738815307617,
      "learning_rate": 6.1911920389582884e-06,
      "loss": 1.7529,
      "step": 19500
    },
    {
      "epoch": 0.20749413776128647,
      "grad_norm": 3.959491491317749,
      "learning_rate": 6.222951513868303e-06,
      "loss": 1.7672,
      "step": 19600
    },
    {
      "epoch": 0.20855278132129304,
      "grad_norm": 4.512282371520996,
      "learning_rate": 6.2547109887783175e-06,
      "loss": 1.755,
      "step": 19700
    },
    {
      "epoch": 0.20961142488129958,
      "grad_norm": 4.137764930725098,
      "learning_rate": 6.286470463688334e-06,
      "loss": 1.7492,
      "step": 19800
    },
    {
      "epoch": 0.21067006844130615,
      "grad_norm": 4.129113674163818,
      "learning_rate": 6.318229938598348e-06,
      "loss": 1.7573,
      "step": 19900
    },
    {
      "epoch": 0.2117287120013127,
      "grad_norm": 3.968787670135498,
      "learning_rate": 6.349989413508363e-06,
      "loss": 1.7636,
      "step": 20000
    },
    {
      "epoch": 0.2117287120013127,
      "eval_loss": 1.7334376573562622,
      "eval_runtime": 57.5385,
      "eval_samples_per_second": 2918.566,
      "eval_steps_per_second": 364.834,
      "step": 20000
    },
    {
      "epoch": 0.21278735556131928,
      "grad_norm": 4.30012321472168,
      "learning_rate": 6.381748888418378e-06,
      "loss": 1.749,
      "step": 20100
    },
    {
      "epoch": 0.21384599912132585,
      "grad_norm": 4.297034740447998,
      "learning_rate": 6.413190768579292e-06,
      "loss": 1.7411,
      "step": 20200
    },
    {
      "epoch": 0.21490464268133241,
      "grad_norm": 4.843512535095215,
      "learning_rate": 6.4449502434893065e-06,
      "loss": 1.7432,
      "step": 20300
    },
    {
      "epoch": 0.21596328624133898,
      "grad_norm": 4.076075077056885,
      "learning_rate": 6.476709718399323e-06,
      "loss": 1.7635,
      "step": 20400
    },
    {
      "epoch": 0.21702192980134555,
      "grad_norm": 4.494231224060059,
      "learning_rate": 6.508469193309337e-06,
      "loss": 1.7352,
      "step": 20500
    },
    {
      "epoch": 0.2180805733613521,
      "grad_norm": 4.270169734954834,
      "learning_rate": 6.540228668219352e-06,
      "loss": 1.7429,
      "step": 20600
    },
    {
      "epoch": 0.21913921692135865,
      "grad_norm": 4.54133415222168,
      "learning_rate": 6.571988143129366e-06,
      "loss": 1.733,
      "step": 20700
    },
    {
      "epoch": 0.22019786048136522,
      "grad_norm": 4.464035511016846,
      "learning_rate": 6.603747618039382e-06,
      "loss": 1.7397,
      "step": 20800
    },
    {
      "epoch": 0.2212565040413718,
      "grad_norm": 4.40487813949585,
      "learning_rate": 6.635507092949396e-06,
      "loss": 1.735,
      "step": 20900
    },
    {
      "epoch": 0.22231514760137835,
      "grad_norm": 4.641275405883789,
      "learning_rate": 6.667266567859411e-06,
      "loss": 1.7189,
      "step": 21000
    },
    {
      "epoch": 0.22231514760137835,
      "eval_loss": 1.7047173976898193,
      "eval_runtime": 57.6526,
      "eval_samples_per_second": 2912.791,
      "eval_steps_per_second": 364.112,
      "step": 21000
    },
    {
      "epoch": 0.22337379116138492,
      "grad_norm": 4.41911506652832,
      "learning_rate": 6.699026042769425e-06,
      "loss": 1.7232,
      "step": 21100
    },
    {
      "epoch": 0.2244324347213915,
      "grad_norm": 3.9991235733032227,
      "learning_rate": 6.7307855176794406e-06,
      "loss": 1.7216,
      "step": 21200
    },
    {
      "epoch": 0.22549107828139806,
      "grad_norm": 4.470282077789307,
      "learning_rate": 6.762544992589455e-06,
      "loss": 1.7376,
      "step": 21300
    },
    {
      "epoch": 0.22654972184140462,
      "grad_norm": 4.574617862701416,
      "learning_rate": 6.79430446749947e-06,
      "loss": 1.7132,
      "step": 21400
    },
    {
      "epoch": 0.22760836540141116,
      "grad_norm": 4.258284091949463,
      "learning_rate": 6.826063942409484e-06,
      "loss": 1.7025,
      "step": 21500
    },
    {
      "epoch": 0.22866700896141773,
      "grad_norm": 4.1816864013671875,
      "learning_rate": 6.8578234173194995e-06,
      "loss": 1.711,
      "step": 21600
    },
    {
      "epoch": 0.2297256525214243,
      "grad_norm": 4.489067077636719,
      "learning_rate": 6.889582892229515e-06,
      "loss": 1.7137,
      "step": 21700
    },
    {
      "epoch": 0.23078429608143086,
      "grad_norm": 4.351415634155273,
      "learning_rate": 6.921342367139529e-06,
      "loss": 1.7153,
      "step": 21800
    },
    {
      "epoch": 0.23184293964143743,
      "grad_norm": 4.094040870666504,
      "learning_rate": 6.953101842049545e-06,
      "loss": 1.7182,
      "step": 21900
    },
    {
      "epoch": 0.232901583201444,
      "grad_norm": 4.237917900085449,
      "learning_rate": 6.984861316959559e-06,
      "loss": 1.7027,
      "step": 22000
    },
    {
      "epoch": 0.232901583201444,
      "eval_loss": 1.6801559925079346,
      "eval_runtime": 57.6387,
      "eval_samples_per_second": 2913.495,
      "eval_steps_per_second": 364.2,
      "step": 22000
    },
    {
      "epoch": 0.23396022676145056,
      "grad_norm": 4.146373748779297,
      "learning_rate": 7.016620791869574e-06,
      "loss": 1.7165,
      "step": 22100
    },
    {
      "epoch": 0.23501887032145713,
      "grad_norm": 4.541094779968262,
      "learning_rate": 7.048062672030488e-06,
      "loss": 1.7144,
      "step": 22200
    },
    {
      "epoch": 0.23607751388146367,
      "grad_norm": 4.093292713165283,
      "learning_rate": 7.079822146940504e-06,
      "loss": 1.6983,
      "step": 22300
    },
    {
      "epoch": 0.23713615744147024,
      "grad_norm": 4.544417381286621,
      "learning_rate": 7.1115816218505184e-06,
      "loss": 1.6973,
      "step": 22400
    },
    {
      "epoch": 0.2381948010014768,
      "grad_norm": 4.428877353668213,
      "learning_rate": 7.143341096760533e-06,
      "loss": 1.6995,
      "step": 22500
    },
    {
      "epoch": 0.23925344456148337,
      "grad_norm": 4.091241836547852,
      "learning_rate": 7.175100571670548e-06,
      "loss": 1.6913,
      "step": 22600
    },
    {
      "epoch": 0.24031208812148994,
      "grad_norm": 4.639453887939453,
      "learning_rate": 7.206860046580563e-06,
      "loss": 1.7035,
      "step": 22700
    },
    {
      "epoch": 0.2413707316814965,
      "grad_norm": 4.69114351272583,
      "learning_rate": 7.238619521490577e-06,
      "loss": 1.6941,
      "step": 22800
    },
    {
      "epoch": 0.24242937524150307,
      "grad_norm": 4.02324914932251,
      "learning_rate": 7.270378996400592e-06,
      "loss": 1.6821,
      "step": 22900
    },
    {
      "epoch": 0.24348801880150964,
      "grad_norm": 4.194134712219238,
      "learning_rate": 7.302138471310607e-06,
      "loss": 1.6837,
      "step": 23000
    },
    {
      "epoch": 0.24348801880150964,
      "eval_loss": 1.6598451137542725,
      "eval_runtime": 57.7336,
      "eval_samples_per_second": 2908.703,
      "eval_steps_per_second": 363.601,
      "step": 23000
    },
    {
      "epoch": 0.24454666236151618,
      "grad_norm": 4.539987087249756,
      "learning_rate": 7.333897946220622e-06,
      "loss": 1.6854,
      "step": 23100
    },
    {
      "epoch": 0.24560530592152274,
      "grad_norm": 3.96242618560791,
      "learning_rate": 7.365657421130636e-06,
      "loss": 1.6902,
      "step": 23200
    },
    {
      "epoch": 0.2466639494815293,
      "grad_norm": 4.762688159942627,
      "learning_rate": 7.397416896040651e-06,
      "loss": 1.6724,
      "step": 23300
    },
    {
      "epoch": 0.24772259304153588,
      "grad_norm": 4.242143630981445,
      "learning_rate": 7.429176370950666e-06,
      "loss": 1.6807,
      "step": 23400
    },
    {
      "epoch": 0.24878123660154244,
      "grad_norm": 4.504339218139648,
      "learning_rate": 7.460935845860681e-06,
      "loss": 1.6854,
      "step": 23500
    },
    {
      "epoch": 0.249839880161549,
      "grad_norm": 4.505759239196777,
      "learning_rate": 7.492695320770696e-06,
      "loss": 1.6913,
      "step": 23600
    },
    {
      "epoch": 0.2508985237215556,
      "grad_norm": 4.637466907501221,
      "learning_rate": 7.524454795680711e-06,
      "loss": 1.6879,
      "step": 23700
    },
    {
      "epoch": 0.25195716728156214,
      "grad_norm": 4.673170566558838,
      "learning_rate": 7.556214270590726e-06,
      "loss": 1.672,
      "step": 23800
    },
    {
      "epoch": 0.2530158108415687,
      "grad_norm": 4.266088485717773,
      "learning_rate": 7.5879737455007404e-06,
      "loss": 1.6697,
      "step": 23900
    },
    {
      "epoch": 0.2540744544015753,
      "grad_norm": 4.524643421173096,
      "learning_rate": 7.619733220410755e-06,
      "loss": 1.6776,
      "step": 24000
    },
    {
      "epoch": 0.2540744544015753,
      "eval_loss": 1.6423640251159668,
      "eval_runtime": 57.4314,
      "eval_samples_per_second": 2924.01,
      "eval_steps_per_second": 365.514,
      "step": 24000
    },
    {
      "epoch": 0.25513309796158185,
      "grad_norm": 4.435993194580078,
      "learning_rate": 7.65149269532077e-06,
      "loss": 1.6743,
      "step": 24100
    },
    {
      "epoch": 0.2561917415215884,
      "grad_norm": 4.237164497375488,
      "learning_rate": 7.682934575481686e-06,
      "loss": 1.6687,
      "step": 24200
    },
    {
      "epoch": 0.257250385081595,
      "grad_norm": 4.207315444946289,
      "learning_rate": 7.7146940503917e-06,
      "loss": 1.6715,
      "step": 24300
    },
    {
      "epoch": 0.2583090286416015,
      "grad_norm": 4.427433967590332,
      "learning_rate": 7.746453525301715e-06,
      "loss": 1.6604,
      "step": 24400
    },
    {
      "epoch": 0.25936767220160806,
      "grad_norm": 4.682799339294434,
      "learning_rate": 7.77821300021173e-06,
      "loss": 1.6718,
      "step": 24500
    },
    {
      "epoch": 0.2604263157616146,
      "grad_norm": 4.335183620452881,
      "learning_rate": 7.809972475121744e-06,
      "loss": 1.6631,
      "step": 24600
    },
    {
      "epoch": 0.2614849593216212,
      "grad_norm": 4.3472442626953125,
      "learning_rate": 7.841731950031759e-06,
      "loss": 1.6724,
      "step": 24700
    },
    {
      "epoch": 0.26254360288162776,
      "grad_norm": 4.673148155212402,
      "learning_rate": 7.873491424941773e-06,
      "loss": 1.6699,
      "step": 24800
    },
    {
      "epoch": 0.2636022464416343,
      "grad_norm": 4.047822952270508,
      "learning_rate": 7.905250899851788e-06,
      "loss": 1.6507,
      "step": 24900
    },
    {
      "epoch": 0.2646608900016409,
      "grad_norm": 4.334671974182129,
      "learning_rate": 7.937010374761804e-06,
      "loss": 1.6534,
      "step": 25000
    },
    {
      "epoch": 0.2646608900016409,
      "eval_loss": 1.6204776763916016,
      "eval_runtime": 57.2956,
      "eval_samples_per_second": 2930.94,
      "eval_steps_per_second": 366.381,
      "step": 25000
    },
    {
      "epoch": 0.26571953356164746,
      "grad_norm": 4.523345470428467,
      "learning_rate": 7.968769849671818e-06,
      "loss": 1.655,
      "step": 25100
    },
    {
      "epoch": 0.266778177121654,
      "grad_norm": 4.4329609870910645,
      "learning_rate": 8.000529324581833e-06,
      "loss": 1.6501,
      "step": 25200
    },
    {
      "epoch": 0.2678368206816606,
      "grad_norm": 4.492023944854736,
      "learning_rate": 8.032288799491847e-06,
      "loss": 1.634,
      "step": 25300
    },
    {
      "epoch": 0.26889546424166716,
      "grad_norm": 4.274997234344482,
      "learning_rate": 8.064048274401862e-06,
      "loss": 1.6533,
      "step": 25400
    },
    {
      "epoch": 0.2699541078016737,
      "grad_norm": 4.559283256530762,
      "learning_rate": 8.095807749311878e-06,
      "loss": 1.6474,
      "step": 25500
    },
    {
      "epoch": 0.2710127513616803,
      "grad_norm": 3.870600461959839,
      "learning_rate": 8.127567224221893e-06,
      "loss": 1.6438,
      "step": 25600
    },
    {
      "epoch": 0.27207139492168686,
      "grad_norm": 4.807779312133789,
      "learning_rate": 8.159326699131907e-06,
      "loss": 1.6507,
      "step": 25700
    },
    {
      "epoch": 0.2731300384816934,
      "grad_norm": 4.354064464569092,
      "learning_rate": 8.191086174041922e-06,
      "loss": 1.6568,
      "step": 25800
    },
    {
      "epoch": 0.2741886820417,
      "grad_norm": 4.205133438110352,
      "learning_rate": 8.222845648951936e-06,
      "loss": 1.6622,
      "step": 25900
    },
    {
      "epoch": 0.27524732560170656,
      "grad_norm": 4.462773323059082,
      "learning_rate": 8.25460512386195e-06,
      "loss": 1.6437,
      "step": 26000
    },
    {
      "epoch": 0.27524732560170656,
      "eval_loss": 1.6050095558166504,
      "eval_runtime": 57.2443,
      "eval_samples_per_second": 2933.569,
      "eval_steps_per_second": 366.709,
      "step": 26000
    },
    {
      "epoch": 0.27630596916171307,
      "grad_norm": 4.029507160186768,
      "learning_rate": 8.286364598771967e-06,
      "loss": 1.6532,
      "step": 26100
    },
    {
      "epoch": 0.27736461272171964,
      "grad_norm": 4.85222053527832,
      "learning_rate": 8.318124073681981e-06,
      "loss": 1.647,
      "step": 26200
    },
    {
      "epoch": 0.2784232562817262,
      "grad_norm": 4.317286491394043,
      "learning_rate": 8.349565953842895e-06,
      "loss": 1.6465,
      "step": 26300
    },
    {
      "epoch": 0.2794818998417328,
      "grad_norm": 4.231604099273682,
      "learning_rate": 8.381325428752912e-06,
      "loss": 1.6176,
      "step": 26400
    },
    {
      "epoch": 0.28054054340173934,
      "grad_norm": 5.196064472198486,
      "learning_rate": 8.413084903662926e-06,
      "loss": 1.6206,
      "step": 26500
    },
    {
      "epoch": 0.2815991869617459,
      "grad_norm": 4.232684135437012,
      "learning_rate": 8.44484437857294e-06,
      "loss": 1.6278,
      "step": 26600
    },
    {
      "epoch": 0.2826578305217525,
      "grad_norm": 4.214280128479004,
      "learning_rate": 8.476603853482955e-06,
      "loss": 1.6363,
      "step": 26700
    },
    {
      "epoch": 0.28371647408175904,
      "grad_norm": 4.377377510070801,
      "learning_rate": 8.50836332839297e-06,
      "loss": 1.6214,
      "step": 26800
    },
    {
      "epoch": 0.2847751176417656,
      "grad_norm": 4.1473822593688965,
      "learning_rate": 8.540122803302984e-06,
      "loss": 1.6353,
      "step": 26900
    },
    {
      "epoch": 0.2858337612017722,
      "grad_norm": 4.218377113342285,
      "learning_rate": 8.571882278212999e-06,
      "loss": 1.6363,
      "step": 27000
    },
    {
      "epoch": 0.2858337612017722,
      "eval_loss": 1.5875834226608276,
      "eval_runtime": 57.3449,
      "eval_samples_per_second": 2928.421,
      "eval_steps_per_second": 366.066,
      "step": 27000
    },
    {
      "epoch": 0.28689240476177874,
      "grad_norm": 4.175299644470215,
      "learning_rate": 8.603641753123013e-06,
      "loss": 1.6212,
      "step": 27100
    },
    {
      "epoch": 0.2879510483217853,
      "grad_norm": 4.632535457611084,
      "learning_rate": 8.63540122803303e-06,
      "loss": 1.6142,
      "step": 27200
    },
    {
      "epoch": 0.2890096918817919,
      "grad_norm": 4.482456207275391,
      "learning_rate": 8.667160702943044e-06,
      "loss": 1.6175,
      "step": 27300
    },
    {
      "epoch": 0.29006833544179844,
      "grad_norm": 4.075785160064697,
      "learning_rate": 8.698920177853058e-06,
      "loss": 1.6492,
      "step": 27400
    },
    {
      "epoch": 0.291126979001805,
      "grad_norm": 4.5561676025390625,
      "learning_rate": 8.730679652763075e-06,
      "loss": 1.6492,
      "step": 27500
    },
    {
      "epoch": 0.2921856225618116,
      "grad_norm": 4.214321613311768,
      "learning_rate": 8.762439127673089e-06,
      "loss": 1.6083,
      "step": 27600
    },
    {
      "epoch": 0.2932442661218181,
      "grad_norm": 4.430943965911865,
      "learning_rate": 8.794198602583104e-06,
      "loss": 1.6335,
      "step": 27700
    },
    {
      "epoch": 0.29430290968182465,
      "grad_norm": 4.3662333488464355,
      "learning_rate": 8.825958077493118e-06,
      "loss": 1.6152,
      "step": 27800
    },
    {
      "epoch": 0.2953615532418312,
      "grad_norm": 4.304574966430664,
      "learning_rate": 8.857717552403133e-06,
      "loss": 1.6124,
      "step": 27900
    },
    {
      "epoch": 0.2964201968018378,
      "grad_norm": 4.065666198730469,
      "learning_rate": 8.889477027313147e-06,
      "loss": 1.6143,
      "step": 28000
    },
    {
      "epoch": 0.2964201968018378,
      "eval_loss": 1.5764131546020508,
      "eval_runtime": 57.389,
      "eval_samples_per_second": 2926.169,
      "eval_steps_per_second": 365.784,
      "step": 28000
    },
    {
      "epoch": 0.29747884036184435,
      "grad_norm": 4.130926609039307,
      "learning_rate": 8.921236502223162e-06,
      "loss": 1.6197,
      "step": 28100
    },
    {
      "epoch": 0.2985374839218509,
      "grad_norm": 4.613987922668457,
      "learning_rate": 8.952995977133178e-06,
      "loss": 1.6071,
      "step": 28200
    },
    {
      "epoch": 0.2995961274818575,
      "grad_norm": 4.173777103424072,
      "learning_rate": 8.984437857294092e-06,
      "loss": 1.6135,
      "step": 28300
    },
    {
      "epoch": 0.30065477104186406,
      "grad_norm": 4.51784610748291,
      "learning_rate": 9.016197332204106e-06,
      "loss": 1.6144,
      "step": 28400
    },
    {
      "epoch": 0.3017134146018706,
      "grad_norm": 4.266482830047607,
      "learning_rate": 9.047956807114121e-06,
      "loss": 1.6119,
      "step": 28500
    },
    {
      "epoch": 0.3027720581618772,
      "grad_norm": 4.043182849884033,
      "learning_rate": 9.079716282024137e-06,
      "loss": 1.6126,
      "step": 28600
    },
    {
      "epoch": 0.30383070172188376,
      "grad_norm": 4.397290229797363,
      "learning_rate": 9.111475756934152e-06,
      "loss": 1.6035,
      "step": 28700
    },
    {
      "epoch": 0.3048893452818903,
      "grad_norm": 4.527411460876465,
      "learning_rate": 9.143235231844166e-06,
      "loss": 1.6102,
      "step": 28800
    },
    {
      "epoch": 0.3059479888418969,
      "grad_norm": 4.177999973297119,
      "learning_rate": 9.17499470675418e-06,
      "loss": 1.5985,
      "step": 28900
    },
    {
      "epoch": 0.30700663240190346,
      "grad_norm": 4.607198238372803,
      "learning_rate": 9.206754181664195e-06,
      "loss": 1.6035,
      "step": 29000
    },
    {
      "epoch": 0.30700663240190346,
      "eval_loss": 1.564117670059204,
      "eval_runtime": 57.2773,
      "eval_samples_per_second": 2931.878,
      "eval_steps_per_second": 366.498,
      "step": 29000
    },
    {
      "epoch": 0.30806527596191,
      "grad_norm": 4.487621307373047,
      "learning_rate": 9.23851365657421e-06,
      "loss": 1.5987,
      "step": 29100
    },
    {
      "epoch": 0.3091239195219166,
      "grad_norm": 4.010489463806152,
      "learning_rate": 9.270273131484224e-06,
      "loss": 1.6087,
      "step": 29200
    },
    {
      "epoch": 0.31018256308192316,
      "grad_norm": 4.219598293304443,
      "learning_rate": 9.30203260639424e-06,
      "loss": 1.5984,
      "step": 29300
    },
    {
      "epoch": 0.31124120664192967,
      "grad_norm": 4.328794479370117,
      "learning_rate": 9.333792081304255e-06,
      "loss": 1.6121,
      "step": 29400
    },
    {
      "epoch": 0.31229985020193624,
      "grad_norm": 4.170210361480713,
      "learning_rate": 9.36555155621427e-06,
      "loss": 1.5983,
      "step": 29500
    },
    {
      "epoch": 0.3133584937619428,
      "grad_norm": 4.475955963134766,
      "learning_rate": 9.397311031124284e-06,
      "loss": 1.6017,
      "step": 29600
    },
    {
      "epoch": 0.31441713732194937,
      "grad_norm": 4.30648946762085,
      "learning_rate": 9.4290705060343e-06,
      "loss": 1.6022,
      "step": 29700
    },
    {
      "epoch": 0.31547578088195594,
      "grad_norm": 4.415274143218994,
      "learning_rate": 9.460829980944315e-06,
      "loss": 1.5847,
      "step": 29800
    },
    {
      "epoch": 0.3165344244419625,
      "grad_norm": 3.9848294258117676,
      "learning_rate": 9.49258945585433e-06,
      "loss": 1.5871,
      "step": 29900
    },
    {
      "epoch": 0.31759306800196907,
      "grad_norm": 3.873516321182251,
      "learning_rate": 9.524348930764344e-06,
      "loss": 1.5854,
      "step": 30000
    },
    {
      "epoch": 0.31759306800196907,
      "eval_loss": 1.55482017993927,
      "eval_runtime": 57.4385,
      "eval_samples_per_second": 2923.649,
      "eval_steps_per_second": 365.469,
      "step": 30000
    },
    {
      "epoch": 0.31865171156197564,
      "grad_norm": 4.1295695304870605,
      "learning_rate": 9.556108405674358e-06,
      "loss": 1.5879,
      "step": 30100
    },
    {
      "epoch": 0.3197103551219822,
      "grad_norm": 4.605686664581299,
      "learning_rate": 9.587867880584373e-06,
      "loss": 1.602,
      "step": 30200
    },
    {
      "epoch": 0.32076899868198877,
      "grad_norm": 4.208433628082275,
      "learning_rate": 9.619627355494387e-06,
      "loss": 1.5817,
      "step": 30300
    },
    {
      "epoch": 0.32182764224199534,
      "grad_norm": 4.449854850769043,
      "learning_rate": 9.651069235655303e-06,
      "loss": 1.5908,
      "step": 30400
    },
    {
      "epoch": 0.3228862858020019,
      "grad_norm": 4.207517147064209,
      "learning_rate": 9.682828710565317e-06,
      "loss": 1.5916,
      "step": 30500
    },
    {
      "epoch": 0.32394492936200847,
      "grad_norm": 4.312524318695068,
      "learning_rate": 9.714588185475332e-06,
      "loss": 1.5886,
      "step": 30600
    },
    {
      "epoch": 0.32500357292201504,
      "grad_norm": 4.197627067565918,
      "learning_rate": 9.746347660385346e-06,
      "loss": 1.5799,
      "step": 30700
    },
    {
      "epoch": 0.3260622164820216,
      "grad_norm": 4.010684490203857,
      "learning_rate": 9.778107135295363e-06,
      "loss": 1.579,
      "step": 30800
    },
    {
      "epoch": 0.32712086004202817,
      "grad_norm": 4.407808303833008,
      "learning_rate": 9.809866610205377e-06,
      "loss": 1.5878,
      "step": 30900
    },
    {
      "epoch": 0.32817950360203474,
      "grad_norm": 4.251208782196045,
      "learning_rate": 9.841626085115392e-06,
      "loss": 1.5735,
      "step": 31000
    },
    {
      "epoch": 0.32817950360203474,
      "eval_loss": 1.549640417098999,
      "eval_runtime": 57.3313,
      "eval_samples_per_second": 2929.113,
      "eval_steps_per_second": 366.152,
      "step": 31000
    },
    {
      "epoch": 0.32923814716204125,
      "grad_norm": 4.1712646484375,
      "learning_rate": 9.873385560025406e-06,
      "loss": 1.5749,
      "step": 31100
    },
    {
      "epoch": 0.3302967907220478,
      "grad_norm": 4.05344820022583,
      "learning_rate": 9.90514503493542e-06,
      "loss": 1.5876,
      "step": 31200
    },
    {
      "epoch": 0.3313554342820544,
      "grad_norm": 4.1888346672058105,
      "learning_rate": 9.936904509845435e-06,
      "loss": 1.5716,
      "step": 31300
    },
    {
      "epoch": 0.33241407784206095,
      "grad_norm": 4.1274566650390625,
      "learning_rate": 9.96866398475545e-06,
      "loss": 1.5866,
      "step": 31400
    },
    {
      "epoch": 0.3334727214020675,
      "grad_norm": 3.773531675338745,
      "learning_rate": 1.0000423459665466e-05,
      "loss": 1.5661,
      "step": 31500
    },
    {
      "epoch": 0.3345313649620741,
      "grad_norm": 4.388452053070068,
      "learning_rate": 1.003218293457548e-05,
      "loss": 1.5637,
      "step": 31600
    },
    {
      "epoch": 0.33559000852208065,
      "grad_norm": 4.237406253814697,
      "learning_rate": 1.0063942409485495e-05,
      "loss": 1.5836,
      "step": 31700
    },
    {
      "epoch": 0.3366486520820872,
      "grad_norm": 3.843046188354492,
      "learning_rate": 1.0095701884395511e-05,
      "loss": 1.5526,
      "step": 31800
    },
    {
      "epoch": 0.3377072956420938,
      "grad_norm": 4.24254846572876,
      "learning_rate": 1.0127461359305526e-05,
      "loss": 1.5623,
      "step": 31900
    },
    {
      "epoch": 0.33876593920210035,
      "grad_norm": 3.8713762760162354,
      "learning_rate": 1.015922083421554e-05,
      "loss": 1.5852,
      "step": 32000
    },
    {
      "epoch": 0.33876593920210035,
      "eval_loss": 1.5365755558013916,
      "eval_runtime": 57.2728,
      "eval_samples_per_second": 2932.108,
      "eval_steps_per_second": 366.527,
      "step": 32000
    },
    {
      "epoch": 0.3398245827621069,
      "grad_norm": 4.1940765380859375,
      "learning_rate": 1.0190980309125557e-05,
      "loss": 1.55,
      "step": 32100
    },
    {
      "epoch": 0.3408832263221135,
      "grad_norm": 4.103057384490967,
      "learning_rate": 1.0222739784035571e-05,
      "loss": 1.5843,
      "step": 32200
    },
    {
      "epoch": 0.34194186988212005,
      "grad_norm": 4.5785346031188965,
      "learning_rate": 1.0254499258945586e-05,
      "loss": 1.5638,
      "step": 32300
    },
    {
      "epoch": 0.3430005134421266,
      "grad_norm": 4.032073497772217,
      "learning_rate": 1.02862587338556e-05,
      "loss": 1.5844,
      "step": 32400
    },
    {
      "epoch": 0.3440591570021332,
      "grad_norm": 4.089195251464844,
      "learning_rate": 1.0317700614016516e-05,
      "loss": 1.5552,
      "step": 32500
    },
    {
      "epoch": 0.34511780056213975,
      "grad_norm": 4.388250350952148,
      "learning_rate": 1.034946008892653e-05,
      "loss": 1.5682,
      "step": 32600
    },
    {
      "epoch": 0.3461764441221463,
      "grad_norm": 4.2654266357421875,
      "learning_rate": 1.0381219563836545e-05,
      "loss": 1.5674,
      "step": 32700
    },
    {
      "epoch": 0.34723508768215283,
      "grad_norm": 4.152163028717041,
      "learning_rate": 1.041297903874656e-05,
      "loss": 1.5626,
      "step": 32800
    },
    {
      "epoch": 0.3482937312421594,
      "grad_norm": 3.724841833114624,
      "learning_rate": 1.0444738513656574e-05,
      "loss": 1.5578,
      "step": 32900
    },
    {
      "epoch": 0.34935237480216597,
      "grad_norm": 4.4128336906433105,
      "learning_rate": 1.0476497988566588e-05,
      "loss": 1.5691,
      "step": 33000
    },
    {
      "epoch": 0.34935237480216597,
      "eval_loss": 1.5282288789749146,
      "eval_runtime": 57.37,
      "eval_samples_per_second": 2927.141,
      "eval_steps_per_second": 365.906,
      "step": 33000
    },
    {
      "epoch": 0.35041101836217253,
      "grad_norm": 4.011973857879639,
      "learning_rate": 1.0508257463476603e-05,
      "loss": 1.5577,
      "step": 33100
    },
    {
      "epoch": 0.3514696619221791,
      "grad_norm": 4.1809587478637695,
      "learning_rate": 1.0540016938386617e-05,
      "loss": 1.5547,
      "step": 33200
    },
    {
      "epoch": 0.35252830548218567,
      "grad_norm": 3.9792964458465576,
      "learning_rate": 1.0571776413296634e-05,
      "loss": 1.5696,
      "step": 33300
    },
    {
      "epoch": 0.35358694904219223,
      "grad_norm": 4.281866550445557,
      "learning_rate": 1.0603535888206648e-05,
      "loss": 1.5491,
      "step": 33400
    },
    {
      "epoch": 0.3546455926021988,
      "grad_norm": 3.989171266555786,
      "learning_rate": 1.0635295363116663e-05,
      "loss": 1.5737,
      "step": 33500
    },
    {
      "epoch": 0.35570423616220537,
      "grad_norm": 3.9230833053588867,
      "learning_rate": 1.0667054838026677e-05,
      "loss": 1.5725,
      "step": 33600
    },
    {
      "epoch": 0.35676287972221193,
      "grad_norm": 4.081395149230957,
      "learning_rate": 1.0698814312936692e-05,
      "loss": 1.5506,
      "step": 33700
    },
    {
      "epoch": 0.3578215232822185,
      "grad_norm": 3.9757142066955566,
      "learning_rate": 1.0730573787846706e-05,
      "loss": 1.5509,
      "step": 33800
    },
    {
      "epoch": 0.35888016684222507,
      "grad_norm": 4.280269145965576,
      "learning_rate": 1.076233326275672e-05,
      "loss": 1.5484,
      "step": 33900
    },
    {
      "epoch": 0.35993881040223163,
      "grad_norm": 3.8690123558044434,
      "learning_rate": 1.0794092737666737e-05,
      "loss": 1.5401,
      "step": 34000
    },
    {
      "epoch": 0.35993881040223163,
      "eval_loss": 1.5211130380630493,
      "eval_runtime": 57.3367,
      "eval_samples_per_second": 2928.838,
      "eval_steps_per_second": 366.118,
      "step": 34000
    },
    {
      "epoch": 0.3609974539622382,
      "grad_norm": 3.972306966781616,
      "learning_rate": 1.0825852212576751e-05,
      "loss": 1.5514,
      "step": 34100
    },
    {
      "epoch": 0.36205609752224477,
      "grad_norm": 4.029960632324219,
      "learning_rate": 1.0857611687486766e-05,
      "loss": 1.558,
      "step": 34200
    },
    {
      "epoch": 0.36311474108225134,
      "grad_norm": 3.6444597244262695,
      "learning_rate": 1.088937116239678e-05,
      "loss": 1.54,
      "step": 34300
    },
    {
      "epoch": 0.3641733846422579,
      "grad_norm": 3.8793489933013916,
      "learning_rate": 1.0921130637306795e-05,
      "loss": 1.5378,
      "step": 34400
    },
    {
      "epoch": 0.3652320282022644,
      "grad_norm": 3.6629467010498047,
      "learning_rate": 1.095289011221681e-05,
      "loss": 1.5566,
      "step": 34500
    },
    {
      "epoch": 0.366290671762271,
      "grad_norm": 3.826115131378174,
      "learning_rate": 1.0984649587126824e-05,
      "loss": 1.5507,
      "step": 34600
    },
    {
      "epoch": 0.36734931532227755,
      "grad_norm": 4.212843418121338,
      "learning_rate": 1.101609146728774e-05,
      "loss": 1.5537,
      "step": 34700
    },
    {
      "epoch": 0.3684079588822841,
      "grad_norm": 4.130099296569824,
      "learning_rate": 1.1047850942197754e-05,
      "loss": 1.561,
      "step": 34800
    },
    {
      "epoch": 0.3694666024422907,
      "grad_norm": 4.06876802444458,
      "learning_rate": 1.1079610417107769e-05,
      "loss": 1.5349,
      "step": 34900
    },
    {
      "epoch": 0.37052524600229725,
      "grad_norm": 3.9569430351257324,
      "learning_rate": 1.1111369892017783e-05,
      "loss": 1.5501,
      "step": 35000
    },
    {
      "epoch": 0.37052524600229725,
      "eval_loss": 1.514155626296997,
      "eval_runtime": 57.2687,
      "eval_samples_per_second": 2932.317,
      "eval_steps_per_second": 366.553,
      "step": 35000
    },
    {
      "epoch": 0.3715838895623038,
      "grad_norm": 3.8193371295928955,
      "learning_rate": 1.11431293669278e-05,
      "loss": 1.5526,
      "step": 35100
    },
    {
      "epoch": 0.3726425331223104,
      "grad_norm": 4.224593162536621,
      "learning_rate": 1.1174888841837814e-05,
      "loss": 1.5534,
      "step": 35200
    },
    {
      "epoch": 0.37370117668231695,
      "grad_norm": 3.9368093013763428,
      "learning_rate": 1.1206648316747828e-05,
      "loss": 1.5481,
      "step": 35300
    },
    {
      "epoch": 0.3747598202423235,
      "grad_norm": 4.311707019805908,
      "learning_rate": 1.1238407791657843e-05,
      "loss": 1.5346,
      "step": 35400
    },
    {
      "epoch": 0.3758184638023301,
      "grad_norm": 4.187327861785889,
      "learning_rate": 1.1270167266567857e-05,
      "loss": 1.5242,
      "step": 35500
    },
    {
      "epoch": 0.37687710736233665,
      "grad_norm": 3.7090582847595215,
      "learning_rate": 1.1301926741477874e-05,
      "loss": 1.5498,
      "step": 35600
    },
    {
      "epoch": 0.3779357509223432,
      "grad_norm": 3.5008912086486816,
      "learning_rate": 1.133368621638789e-05,
      "loss": 1.5156,
      "step": 35700
    },
    {
      "epoch": 0.3789943944823498,
      "grad_norm": 3.963695764541626,
      "learning_rate": 1.1365445691297904e-05,
      "loss": 1.5334,
      "step": 35800
    },
    {
      "epoch": 0.38005303804235635,
      "grad_norm": 3.768784284591675,
      "learning_rate": 1.1397205166207919e-05,
      "loss": 1.5367,
      "step": 35900
    },
    {
      "epoch": 0.3811116816023629,
      "grad_norm": 3.7252678871154785,
      "learning_rate": 1.1428964641117933e-05,
      "loss": 1.5505,
      "step": 36000
    },
    {
      "epoch": 0.3811116816023629,
      "eval_loss": 1.5042482614517212,
      "eval_runtime": 57.4769,
      "eval_samples_per_second": 2921.694,
      "eval_steps_per_second": 365.225,
      "step": 36000
    },
    {
      "epoch": 0.38217032516236943,
      "grad_norm": 3.7939820289611816,
      "learning_rate": 1.1460724116027948e-05,
      "loss": 1.5274,
      "step": 36100
    },
    {
      "epoch": 0.383228968722376,
      "grad_norm": 4.040702819824219,
      "learning_rate": 1.1492483590937962e-05,
      "loss": 1.5338,
      "step": 36200
    },
    {
      "epoch": 0.38428761228238256,
      "grad_norm": 3.6645097732543945,
      "learning_rate": 1.1524243065847977e-05,
      "loss": 1.5477,
      "step": 36300
    },
    {
      "epoch": 0.38534625584238913,
      "grad_norm": 3.9279913902282715,
      "learning_rate": 1.1556002540757991e-05,
      "loss": 1.5438,
      "step": 36400
    },
    {
      "epoch": 0.3864048994023957,
      "grad_norm": 3.6566402912139893,
      "learning_rate": 1.1587762015668008e-05,
      "loss": 1.5389,
      "step": 36500
    },
    {
      "epoch": 0.38746354296240226,
      "grad_norm": 4.140382766723633,
      "learning_rate": 1.1619521490578022e-05,
      "loss": 1.5314,
      "step": 36600
    },
    {
      "epoch": 0.38852218652240883,
      "grad_norm": 3.9849185943603516,
      "learning_rate": 1.1651280965488037e-05,
      "loss": 1.5231,
      "step": 36700
    },
    {
      "epoch": 0.3895808300824154,
      "grad_norm": 3.696850538253784,
      "learning_rate": 1.1683040440398051e-05,
      "loss": 1.5286,
      "step": 36800
    },
    {
      "epoch": 0.39063947364242196,
      "grad_norm": 3.7298176288604736,
      "learning_rate": 1.1714799915308066e-05,
      "loss": 1.5401,
      "step": 36900
    },
    {
      "epoch": 0.39169811720242853,
      "grad_norm": 4.153665542602539,
      "learning_rate": 1.174655939021808e-05,
      "loss": 1.521,
      "step": 37000
    },
    {
      "epoch": 0.39169811720242853,
      "eval_loss": 1.5039664506912231,
      "eval_runtime": 57.3874,
      "eval_samples_per_second": 2926.25,
      "eval_steps_per_second": 365.794,
      "step": 37000
    },
    {
      "epoch": 0.3927567607624351,
      "grad_norm": 3.7513163089752197,
      "learning_rate": 1.1778318865128095e-05,
      "loss": 1.5207,
      "step": 37100
    },
    {
      "epoch": 0.39381540432244166,
      "grad_norm": 3.8864665031433105,
      "learning_rate": 1.181007834003811e-05,
      "loss": 1.5277,
      "step": 37200
    },
    {
      "epoch": 0.39487404788244823,
      "grad_norm": 3.648172616958618,
      "learning_rate": 1.1841520220199025e-05,
      "loss": 1.5228,
      "step": 37300
    },
    {
      "epoch": 0.3959326914424548,
      "grad_norm": 3.937497854232788,
      "learning_rate": 1.187327969510904e-05,
      "loss": 1.5254,
      "step": 37400
    },
    {
      "epoch": 0.39699133500246137,
      "grad_norm": 3.499821186065674,
      "learning_rate": 1.1905039170019054e-05,
      "loss": 1.5229,
      "step": 37500
    },
    {
      "epoch": 0.39804997856246793,
      "grad_norm": 3.792006254196167,
      "learning_rate": 1.193679864492907e-05,
      "loss": 1.5119,
      "step": 37600
    },
    {
      "epoch": 0.3991086221224745,
      "grad_norm": 3.9601023197174072,
      "learning_rate": 1.1968558119839085e-05,
      "loss": 1.5151,
      "step": 37700
    },
    {
      "epoch": 0.400167265682481,
      "grad_norm": 3.6785011291503906,
      "learning_rate": 1.20003175947491e-05,
      "loss": 1.532,
      "step": 37800
    },
    {
      "epoch": 0.4012259092424876,
      "grad_norm": 3.7012171745300293,
      "learning_rate": 1.2032077069659114e-05,
      "loss": 1.5118,
      "step": 37900
    },
    {
      "epoch": 0.40228455280249414,
      "grad_norm": 3.49686861038208,
      "learning_rate": 1.2063836544569128e-05,
      "loss": 1.5188,
      "step": 38000
    },
    {
      "epoch": 0.40228455280249414,
      "eval_loss": 1.491379976272583,
      "eval_runtime": 57.2695,
      "eval_samples_per_second": 2932.277,
      "eval_steps_per_second": 366.548,
      "step": 38000
    },
    {
      "epoch": 0.4033431963625007,
      "grad_norm": 4.052997589111328,
      "learning_rate": 1.2095596019479143e-05,
      "loss": 1.5309,
      "step": 38100
    },
    {
      "epoch": 0.4044018399225073,
      "grad_norm": 3.4983878135681152,
      "learning_rate": 1.2127355494389157e-05,
      "loss": 1.5056,
      "step": 38200
    },
    {
      "epoch": 0.40546048348251384,
      "grad_norm": 3.388148069381714,
      "learning_rate": 1.2159114969299172e-05,
      "loss": 1.5053,
      "step": 38300
    },
    {
      "epoch": 0.4065191270425204,
      "grad_norm": 3.6024653911590576,
      "learning_rate": 1.2190874444209188e-05,
      "loss": 1.5261,
      "step": 38400
    },
    {
      "epoch": 0.407577770602527,
      "grad_norm": 3.501161813735962,
      "learning_rate": 1.2222633919119203e-05,
      "loss": 1.5007,
      "step": 38500
    },
    {
      "epoch": 0.40863641416253355,
      "grad_norm": 3.475978374481201,
      "learning_rate": 1.2254393394029217e-05,
      "loss": 1.509,
      "step": 38600
    },
    {
      "epoch": 0.4096950577225401,
      "grad_norm": 3.900049924850464,
      "learning_rate": 1.2286152868939232e-05,
      "loss": 1.529,
      "step": 38700
    },
    {
      "epoch": 0.4107537012825467,
      "grad_norm": 3.730191946029663,
      "learning_rate": 1.2317912343849248e-05,
      "loss": 1.51,
      "step": 38800
    },
    {
      "epoch": 0.41181234484255325,
      "grad_norm": 4.127984523773193,
      "learning_rate": 1.2349671818759262e-05,
      "loss": 1.5289,
      "step": 38900
    },
    {
      "epoch": 0.4128709884025598,
      "grad_norm": 3.5132687091827393,
      "learning_rate": 1.2381431293669278e-05,
      "loss": 1.526,
      "step": 39000
    },
    {
      "epoch": 0.4128709884025598,
      "eval_loss": 1.485676884651184,
      "eval_runtime": 57.3641,
      "eval_samples_per_second": 2927.441,
      "eval_steps_per_second": 365.943,
      "step": 39000
    },
    {
      "epoch": 0.4139296319625664,
      "grad_norm": 3.769832134246826,
      "learning_rate": 1.2413190768579293e-05,
      "loss": 1.5104,
      "step": 39100
    },
    {
      "epoch": 0.41498827552257295,
      "grad_norm": 3.870650291442871,
      "learning_rate": 1.2444950243489308e-05,
      "loss": 1.5208,
      "step": 39200
    },
    {
      "epoch": 0.4160469190825795,
      "grad_norm": 3.8054137229919434,
      "learning_rate": 1.2476709718399322e-05,
      "loss": 1.5083,
      "step": 39300
    },
    {
      "epoch": 0.4171055626425861,
      "grad_norm": 3.6600797176361084,
      "learning_rate": 1.2508469193309337e-05,
      "loss": 1.5174,
      "step": 39400
    },
    {
      "epoch": 0.4181642062025926,
      "grad_norm": 3.5287868976593018,
      "learning_rate": 1.2540228668219351e-05,
      "loss": 1.496,
      "step": 39500
    },
    {
      "epoch": 0.41922284976259916,
      "grad_norm": 3.6913509368896484,
      "learning_rate": 1.2571988143129366e-05,
      "loss": 1.5081,
      "step": 39600
    },
    {
      "epoch": 0.4202814933226057,
      "grad_norm": 3.5748918056488037,
      "learning_rate": 1.260374761803938e-05,
      "loss": 1.5144,
      "step": 39700
    },
    {
      "epoch": 0.4213401368826123,
      "grad_norm": 3.885868787765503,
      "learning_rate": 1.2635507092949396e-05,
      "loss": 1.522,
      "step": 39800
    },
    {
      "epoch": 0.42239878044261886,
      "grad_norm": 3.048797607421875,
      "learning_rate": 1.266726656785941e-05,
      "loss": 1.5017,
      "step": 39900
    },
    {
      "epoch": 0.4234574240026254,
      "grad_norm": 3.6970863342285156,
      "learning_rate": 1.2699026042769425e-05,
      "loss": 1.5139,
      "step": 40000
    },
    {
      "epoch": 0.4234574240026254,
      "eval_loss": 1.4839438199996948,
      "eval_runtime": 57.3417,
      "eval_samples_per_second": 2928.584,
      "eval_steps_per_second": 366.086,
      "step": 40000
    },
    {
      "epoch": 0.424516067562632,
      "grad_norm": 3.7955658435821533,
      "learning_rate": 1.273078551767944e-05,
      "loss": 1.5067,
      "step": 40100
    },
    {
      "epoch": 0.42557471112263856,
      "grad_norm": 3.615780830383301,
      "learning_rate": 1.2762544992589454e-05,
      "loss": 1.5254,
      "step": 40200
    },
    {
      "epoch": 0.4266333546826451,
      "grad_norm": 3.6177194118499756,
      "learning_rate": 1.2794304467499469e-05,
      "loss": 1.4975,
      "step": 40300
    },
    {
      "epoch": 0.4276919982426517,
      "grad_norm": 3.368022918701172,
      "learning_rate": 1.2826063942409483e-05,
      "loss": 1.4843,
      "step": 40400
    },
    {
      "epoch": 0.42875064180265826,
      "grad_norm": 3.377514600753784,
      "learning_rate": 1.28578234173195e-05,
      "loss": 1.4894,
      "step": 40500
    },
    {
      "epoch": 0.42980928536266483,
      "grad_norm": 3.257133722305298,
      "learning_rate": 1.2889582892229514e-05,
      "loss": 1.496,
      "step": 40600
    },
    {
      "epoch": 0.4308679289226714,
      "grad_norm": 3.3713631629943848,
      "learning_rate": 1.2921024772390428e-05,
      "loss": 1.5025,
      "step": 40700
    },
    {
      "epoch": 0.43192657248267796,
      "grad_norm": 3.822495937347412,
      "learning_rate": 1.2952784247300443e-05,
      "loss": 1.5033,
      "step": 40800
    },
    {
      "epoch": 0.43298521604268453,
      "grad_norm": 3.6863210201263428,
      "learning_rate": 1.2984543722210459e-05,
      "loss": 1.5056,
      "step": 40900
    },
    {
      "epoch": 0.4340438596026911,
      "grad_norm": 3.499685049057007,
      "learning_rate": 1.3016303197120473e-05,
      "loss": 1.5023,
      "step": 41000
    },
    {
      "epoch": 0.4340438596026911,
      "eval_loss": 1.474569320678711,
      "eval_runtime": 57.2425,
      "eval_samples_per_second": 2933.66,
      "eval_steps_per_second": 366.721,
      "step": 41000
    },
    {
      "epoch": 0.43510250316269766,
      "grad_norm": 3.898566722869873,
      "learning_rate": 1.3048062672030488e-05,
      "loss": 1.4851,
      "step": 41100
    },
    {
      "epoch": 0.4361611467227042,
      "grad_norm": 3.792046070098877,
      "learning_rate": 1.3079822146940502e-05,
      "loss": 1.5045,
      "step": 41200
    },
    {
      "epoch": 0.43721979028271074,
      "grad_norm": 3.74188232421875,
      "learning_rate": 1.3111581621850517e-05,
      "loss": 1.4982,
      "step": 41300
    },
    {
      "epoch": 0.4382784338427173,
      "grad_norm": 3.8363566398620605,
      "learning_rate": 1.3143341096760531e-05,
      "loss": 1.5052,
      "step": 41400
    },
    {
      "epoch": 0.4393370774027239,
      "grad_norm": 3.355628252029419,
      "learning_rate": 1.3175100571670546e-05,
      "loss": 1.4948,
      "step": 41500
    },
    {
      "epoch": 0.44039572096273044,
      "grad_norm": 3.436868190765381,
      "learning_rate": 1.320686004658056e-05,
      "loss": 1.5005,
      "step": 41600
    },
    {
      "epoch": 0.441454364522737,
      "grad_norm": 3.3880887031555176,
      "learning_rate": 1.3238619521490577e-05,
      "loss": 1.4964,
      "step": 41700
    },
    {
      "epoch": 0.4425130080827436,
      "grad_norm": 3.4918084144592285,
      "learning_rate": 1.3270378996400591e-05,
      "loss": 1.4968,
      "step": 41800
    },
    {
      "epoch": 0.44357165164275014,
      "grad_norm": 3.2813684940338135,
      "learning_rate": 1.3302138471310606e-05,
      "loss": 1.5029,
      "step": 41900
    },
    {
      "epoch": 0.4446302952027567,
      "grad_norm": 3.6530966758728027,
      "learning_rate": 1.3333897946220622e-05,
      "loss": 1.5042,
      "step": 42000
    },
    {
      "epoch": 0.4446302952027567,
      "eval_loss": 1.4709898233413696,
      "eval_runtime": 57.3139,
      "eval_samples_per_second": 2930.003,
      "eval_steps_per_second": 366.263,
      "step": 42000
    },
    {
      "epoch": 0.4456889387627633,
      "grad_norm": 3.4659245014190674,
      "learning_rate": 1.3365657421130636e-05,
      "loss": 1.5059,
      "step": 42100
    },
    {
      "epoch": 0.44674758232276984,
      "grad_norm": 3.843684673309326,
      "learning_rate": 1.3397416896040653e-05,
      "loss": 1.4869,
      "step": 42200
    },
    {
      "epoch": 0.4478062258827764,
      "grad_norm": 3.4392709732055664,
      "learning_rate": 1.3429176370950667e-05,
      "loss": 1.5189,
      "step": 42300
    },
    {
      "epoch": 0.448864869442783,
      "grad_norm": 3.300776958465576,
      "learning_rate": 1.3460935845860682e-05,
      "loss": 1.4881,
      "step": 42400
    },
    {
      "epoch": 0.44992351300278954,
      "grad_norm": 3.489837169647217,
      "learning_rate": 1.3492695320770696e-05,
      "loss": 1.4982,
      "step": 42500
    },
    {
      "epoch": 0.4509821565627961,
      "grad_norm": 3.3751347064971924,
      "learning_rate": 1.352445479568071e-05,
      "loss": 1.4984,
      "step": 42600
    },
    {
      "epoch": 0.4520408001228027,
      "grad_norm": 3.867722988128662,
      "learning_rate": 1.3556214270590725e-05,
      "loss": 1.491,
      "step": 42700
    },
    {
      "epoch": 0.45309944368280924,
      "grad_norm": 3.4837026596069336,
      "learning_rate": 1.358797374550074e-05,
      "loss": 1.4926,
      "step": 42800
    },
    {
      "epoch": 0.45415808724281576,
      "grad_norm": 3.544940233230591,
      "learning_rate": 1.3619733220410754e-05,
      "loss": 1.4922,
      "step": 42900
    },
    {
      "epoch": 0.4552167308028223,
      "grad_norm": 3.381725549697876,
      "learning_rate": 1.365149269532077e-05,
      "loss": 1.487,
      "step": 43000
    },
    {
      "epoch": 0.4552167308028223,
      "eval_loss": 1.4666177034378052,
      "eval_runtime": 57.5118,
      "eval_samples_per_second": 2919.921,
      "eval_steps_per_second": 365.003,
      "step": 43000
    },
    {
      "epoch": 0.4562753743628289,
      "grad_norm": 3.5378503799438477,
      "learning_rate": 1.3683252170230785e-05,
      "loss": 1.4832,
      "step": 43100
    },
    {
      "epoch": 0.45733401792283546,
      "grad_norm": 2.8046107292175293,
      "learning_rate": 1.37150116451408e-05,
      "loss": 1.4847,
      "step": 43200
    },
    {
      "epoch": 0.458392661482842,
      "grad_norm": 3.3847827911376953,
      "learning_rate": 1.3746771120050814e-05,
      "loss": 1.4747,
      "step": 43300
    },
    {
      "epoch": 0.4594513050428486,
      "grad_norm": 3.4924285411834717,
      "learning_rate": 1.3778530594960829e-05,
      "loss": 1.4826,
      "step": 43400
    },
    {
      "epoch": 0.46050994860285516,
      "grad_norm": 3.448692560195923,
      "learning_rate": 1.3810290069870843e-05,
      "loss": 1.4917,
      "step": 43500
    },
    {
      "epoch": 0.4615685921628617,
      "grad_norm": 3.5174620151519775,
      "learning_rate": 1.3842049544780858e-05,
      "loss": 1.4758,
      "step": 43600
    },
    {
      "epoch": 0.4626272357228683,
      "grad_norm": 3.4196715354919434,
      "learning_rate": 1.3873809019690872e-05,
      "loss": 1.4608,
      "step": 43700
    },
    {
      "epoch": 0.46368587928287486,
      "grad_norm": 3.169471263885498,
      "learning_rate": 1.3905568494600888e-05,
      "loss": 1.4876,
      "step": 43800
    },
    {
      "epoch": 0.4647445228428814,
      "grad_norm": 3.2561862468719482,
      "learning_rate": 1.3937327969510903e-05,
      "loss": 1.4824,
      "step": 43900
    },
    {
      "epoch": 0.465803166402888,
      "grad_norm": 3.0168166160583496,
      "learning_rate": 1.3969087444420917e-05,
      "loss": 1.4903,
      "step": 44000
    },
    {
      "epoch": 0.465803166402888,
      "eval_loss": 1.4582821130752563,
      "eval_runtime": 57.2262,
      "eval_samples_per_second": 2934.497,
      "eval_steps_per_second": 366.825,
      "step": 44000
    },
    {
      "epoch": 0.46686180996289456,
      "grad_norm": 3.589907169342041,
      "learning_rate": 1.4000846919330932e-05,
      "loss": 1.487,
      "step": 44100
    },
    {
      "epoch": 0.4679204535229011,
      "grad_norm": 3.0747082233428955,
      "learning_rate": 1.4032606394240946e-05,
      "loss": 1.4754,
      "step": 44200
    },
    {
      "epoch": 0.4689790970829077,
      "grad_norm": 3.2972631454467773,
      "learning_rate": 1.4064365869150961e-05,
      "loss": 1.4794,
      "step": 44300
    },
    {
      "epoch": 0.47003774064291426,
      "grad_norm": 3.4718101024627686,
      "learning_rate": 1.4096125344060975e-05,
      "loss": 1.4776,
      "step": 44400
    },
    {
      "epoch": 0.47109638420292077,
      "grad_norm": 3.529143810272217,
      "learning_rate": 1.412788481897099e-05,
      "loss": 1.4813,
      "step": 44500
    },
    {
      "epoch": 0.47215502776292734,
      "grad_norm": 3.23166561126709,
      "learning_rate": 1.4159644293881008e-05,
      "loss": 1.4768,
      "step": 44600
    },
    {
      "epoch": 0.4732136713229339,
      "grad_norm": 3.245478391647339,
      "learning_rate": 1.419108617404192e-05,
      "loss": 1.4736,
      "step": 44700
    },
    {
      "epoch": 0.47427231488294047,
      "grad_norm": 3.205317735671997,
      "learning_rate": 1.4222845648951935e-05,
      "loss": 1.4702,
      "step": 44800
    },
    {
      "epoch": 0.47533095844294704,
      "grad_norm": 3.237128973007202,
      "learning_rate": 1.425460512386195e-05,
      "loss": 1.472,
      "step": 44900
    },
    {
      "epoch": 0.4763896020029536,
      "grad_norm": 3.60623836517334,
      "learning_rate": 1.4286047004022865e-05,
      "loss": 1.4945,
      "step": 45000
    },
    {
      "epoch": 0.4763896020029536,
      "eval_loss": 1.457139492034912,
      "eval_runtime": 57.4282,
      "eval_samples_per_second": 2924.174,
      "eval_steps_per_second": 365.535,
      "step": 45000
    },
    {
      "epoch": 0.47744824556296017,
      "grad_norm": 3.247616767883301,
      "learning_rate": 1.431780647893288e-05,
      "loss": 1.4751,
      "step": 45100
    },
    {
      "epoch": 0.47850688912296674,
      "grad_norm": 3.337766170501709,
      "learning_rate": 1.4349565953842894e-05,
      "loss": 1.4851,
      "step": 45200
    },
    {
      "epoch": 0.4795655326829733,
      "grad_norm": 3.055389404296875,
      "learning_rate": 1.438132542875291e-05,
      "loss": 1.4729,
      "step": 45300
    },
    {
      "epoch": 0.4806241762429799,
      "grad_norm": 3.145136833190918,
      "learning_rate": 1.4413084903662925e-05,
      "loss": 1.4598,
      "step": 45400
    },
    {
      "epoch": 0.48168281980298644,
      "grad_norm": 3.2034783363342285,
      "learning_rate": 1.4444844378572939e-05,
      "loss": 1.4759,
      "step": 45500
    },
    {
      "epoch": 0.482741463362993,
      "grad_norm": 3.3240935802459717,
      "learning_rate": 1.4476603853482954e-05,
      "loss": 1.4702,
      "step": 45600
    },
    {
      "epoch": 0.4838001069229996,
      "grad_norm": 3.5124855041503906,
      "learning_rate": 1.4508363328392968e-05,
      "loss": 1.459,
      "step": 45700
    },
    {
      "epoch": 0.48485875048300614,
      "grad_norm": 3.2297916412353516,
      "learning_rate": 1.4540122803302986e-05,
      "loss": 1.4666,
      "step": 45800
    },
    {
      "epoch": 0.4859173940430127,
      "grad_norm": 3.291322708129883,
      "learning_rate": 1.4571882278213e-05,
      "loss": 1.4817,
      "step": 45900
    },
    {
      "epoch": 0.4869760376030193,
      "grad_norm": 3.253419876098633,
      "learning_rate": 1.4603641753123015e-05,
      "loss": 1.4581,
      "step": 46000
    },
    {
      "epoch": 0.4869760376030193,
      "eval_loss": 1.4493381977081299,
      "eval_runtime": 57.3438,
      "eval_samples_per_second": 2928.475,
      "eval_steps_per_second": 366.072,
      "step": 46000
    },
    {
      "epoch": 0.48803468116302584,
      "grad_norm": 3.285088539123535,
      "learning_rate": 1.463540122803303e-05,
      "loss": 1.4657,
      "step": 46100
    },
    {
      "epoch": 0.48909332472303235,
      "grad_norm": 3.371140956878662,
      "learning_rate": 1.4667160702943044e-05,
      "loss": 1.4575,
      "step": 46200
    },
    {
      "epoch": 0.4901519682830389,
      "grad_norm": 3.211221694946289,
      "learning_rate": 1.4698920177853059e-05,
      "loss": 1.4725,
      "step": 46300
    },
    {
      "epoch": 0.4912106118430455,
      "grad_norm": 3.2974066734313965,
      "learning_rate": 1.4730679652763073e-05,
      "loss": 1.4693,
      "step": 46400
    },
    {
      "epoch": 0.49226925540305205,
      "grad_norm": 3.08174991607666,
      "learning_rate": 1.4762439127673088e-05,
      "loss": 1.4615,
      "step": 46500
    },
    {
      "epoch": 0.4933278989630586,
      "grad_norm": 3.95312762260437,
      "learning_rate": 1.4794198602583104e-05,
      "loss": 1.472,
      "step": 46600
    },
    {
      "epoch": 0.4943865425230652,
      "grad_norm": 3.2551515102386475,
      "learning_rate": 1.4825958077493118e-05,
      "loss": 1.4687,
      "step": 46700
    },
    {
      "epoch": 0.49544518608307175,
      "grad_norm": 2.9965505599975586,
      "learning_rate": 1.4857717552403133e-05,
      "loss": 1.4726,
      "step": 46800
    },
    {
      "epoch": 0.4965038296430783,
      "grad_norm": 3.133476734161377,
      "learning_rate": 1.4889477027313147e-05,
      "loss": 1.4535,
      "step": 46900
    },
    {
      "epoch": 0.4975624732030849,
      "grad_norm": 3.2079594135284424,
      "learning_rate": 1.4921236502223162e-05,
      "loss": 1.4625,
      "step": 47000
    },
    {
      "epoch": 0.4975624732030849,
      "eval_loss": 1.4476618766784668,
      "eval_runtime": 57.4207,
      "eval_samples_per_second": 2924.554,
      "eval_steps_per_second": 365.582,
      "step": 47000
    },
    {
      "epoch": 0.49862111676309145,
      "grad_norm": 3.504866123199463,
      "learning_rate": 1.4952995977133176e-05,
      "loss": 1.4801,
      "step": 47100
    },
    {
      "epoch": 0.499679760323098,
      "grad_norm": 3.0969934463500977,
      "learning_rate": 1.4984755452043191e-05,
      "loss": 1.457,
      "step": 47200
    },
    {
      "epoch": 0.5007384038831045,
      "grad_norm": 3.400057315826416,
      "learning_rate": 1.5016514926953205e-05,
      "loss": 1.4527,
      "step": 47300
    },
    {
      "epoch": 0.5017970474431112,
      "grad_norm": 3.286700487136841,
      "learning_rate": 1.5048274401863222e-05,
      "loss": 1.4592,
      "step": 47400
    },
    {
      "epoch": 0.5028556910031177,
      "grad_norm": 3.126338481903076,
      "learning_rate": 1.5080033876773236e-05,
      "loss": 1.461,
      "step": 47500
    },
    {
      "epoch": 0.5039143345631243,
      "grad_norm": 3.114229440689087,
      "learning_rate": 1.511179335168325e-05,
      "loss": 1.4664,
      "step": 47600
    },
    {
      "epoch": 0.5049729781231308,
      "grad_norm": 3.263653516769409,
      "learning_rate": 1.5143552826593265e-05,
      "loss": 1.4573,
      "step": 47700
    },
    {
      "epoch": 0.5060316216831374,
      "grad_norm": 3.149162769317627,
      "learning_rate": 1.517531230150328e-05,
      "loss": 1.4474,
      "step": 47800
    },
    {
      "epoch": 0.5070902652431439,
      "grad_norm": 3.3462023735046387,
      "learning_rate": 1.5207071776413294e-05,
      "loss": 1.459,
      "step": 47900
    },
    {
      "epoch": 0.5081489088031506,
      "grad_norm": 3.269362688064575,
      "learning_rate": 1.5238831251323309e-05,
      "loss": 1.4596,
      "step": 48000
    },
    {
      "epoch": 0.5081489088031506,
      "eval_loss": 1.441579818725586,
      "eval_runtime": 57.3383,
      "eval_samples_per_second": 2928.756,
      "eval_steps_per_second": 366.108,
      "step": 48000
    },
    {
      "epoch": 0.5092075523631571,
      "grad_norm": 3.1507232189178467,
      "learning_rate": 1.5270590726233325e-05,
      "loss": 1.4363,
      "step": 48100
    },
    {
      "epoch": 0.5102661959231637,
      "grad_norm": 2.9346511363983154,
      "learning_rate": 1.530235020114334e-05,
      "loss": 1.4597,
      "step": 48200
    },
    {
      "epoch": 0.5113248394831702,
      "grad_norm": 3.021420955657959,
      "learning_rate": 1.5334109676053354e-05,
      "loss": 1.4555,
      "step": 48300
    },
    {
      "epoch": 0.5123834830431768,
      "grad_norm": 3.1901822090148926,
      "learning_rate": 1.5365869150963372e-05,
      "loss": 1.4461,
      "step": 48400
    },
    {
      "epoch": 0.5134421266031833,
      "grad_norm": 2.9178833961486816,
      "learning_rate": 1.5397628625873386e-05,
      "loss": 1.4539,
      "step": 48500
    },
    {
      "epoch": 0.51450077016319,
      "grad_norm": 3.4937734603881836,
      "learning_rate": 1.54293881007834e-05,
      "loss": 1.4327,
      "step": 48600
    },
    {
      "epoch": 0.5155594137231965,
      "grad_norm": 3.209930419921875,
      "learning_rate": 1.5461147575693415e-05,
      "loss": 1.4366,
      "step": 48700
    },
    {
      "epoch": 0.516618057283203,
      "grad_norm": 2.983459234237671,
      "learning_rate": 1.549290705060343e-05,
      "loss": 1.4552,
      "step": 48800
    },
    {
      "epoch": 0.5176767008432096,
      "grad_norm": 3.3865175247192383,
      "learning_rate": 1.5524666525513444e-05,
      "loss": 1.4588,
      "step": 48900
    },
    {
      "epoch": 0.5187353444032161,
      "grad_norm": 3.2812411785125732,
      "learning_rate": 1.555610840567436e-05,
      "loss": 1.4471,
      "step": 49000
    },
    {
      "epoch": 0.5187353444032161,
      "eval_loss": 1.4379855394363403,
      "eval_runtime": 57.4349,
      "eval_samples_per_second": 2923.831,
      "eval_steps_per_second": 365.492,
      "step": 49000
    },
    {
      "epoch": 0.5197939879632227,
      "grad_norm": 2.9701082706451416,
      "learning_rate": 1.5587867880584373e-05,
      "loss": 1.451,
      "step": 49100
    },
    {
      "epoch": 0.5208526315232292,
      "grad_norm": 3.092811107635498,
      "learning_rate": 1.5619627355494387e-05,
      "loss": 1.4477,
      "step": 49200
    },
    {
      "epoch": 0.5219112750832359,
      "grad_norm": 3.2054059505462646,
      "learning_rate": 1.5651386830404402e-05,
      "loss": 1.4631,
      "step": 49300
    },
    {
      "epoch": 0.5229699186432424,
      "grad_norm": 3.284135580062866,
      "learning_rate": 1.5683146305314416e-05,
      "loss": 1.4419,
      "step": 49400
    },
    {
      "epoch": 0.524028562203249,
      "grad_norm": 3.3127450942993164,
      "learning_rate": 1.5714905780224434e-05,
      "loss": 1.4572,
      "step": 49500
    },
    {
      "epoch": 0.5250872057632555,
      "grad_norm": 3.209778070449829,
      "learning_rate": 1.574666525513445e-05,
      "loss": 1.4584,
      "step": 49600
    },
    {
      "epoch": 0.5261458493232621,
      "grad_norm": 2.9696226119995117,
      "learning_rate": 1.5778424730044463e-05,
      "loss": 1.4482,
      "step": 49700
    },
    {
      "epoch": 0.5272044928832686,
      "grad_norm": 3.278325319290161,
      "learning_rate": 1.5809866610205377e-05,
      "loss": 1.4461,
      "step": 49800
    },
    {
      "epoch": 0.5282631364432753,
      "grad_norm": 3.1346099376678467,
      "learning_rate": 1.5841626085115392e-05,
      "loss": 1.4438,
      "step": 49900
    },
    {
      "epoch": 0.5293217800032818,
      "grad_norm": 3.3120391368865967,
      "learning_rate": 1.5873385560025406e-05,
      "loss": 1.4355,
      "step": 50000
    },
    {
      "epoch": 0.5293217800032818,
      "eval_loss": 1.4277249574661255,
      "eval_runtime": 57.2433,
      "eval_samples_per_second": 2933.619,
      "eval_steps_per_second": 366.715,
      "step": 50000
    },
    {
      "epoch": 0.5303804235632884,
      "grad_norm": 3.1343014240264893,
      "learning_rate": 1.590514503493542e-05,
      "loss": 1.4443,
      "step": 50100
    },
    {
      "epoch": 0.5314390671232949,
      "grad_norm": 3.2903647422790527,
      "learning_rate": 1.5936904509845435e-05,
      "loss": 1.4361,
      "step": 50200
    },
    {
      "epoch": 0.5324977106833015,
      "grad_norm": 2.7698917388916016,
      "learning_rate": 1.596866398475545e-05,
      "loss": 1.4484,
      "step": 50300
    },
    {
      "epoch": 0.533556354243308,
      "grad_norm": 3.04636287689209,
      "learning_rate": 1.6000423459665464e-05,
      "loss": 1.433,
      "step": 50400
    },
    {
      "epoch": 0.5346149978033146,
      "grad_norm": 3.213608980178833,
      "learning_rate": 1.603218293457548e-05,
      "loss": 1.4525,
      "step": 50500
    },
    {
      "epoch": 0.5356736413633212,
      "grad_norm": 3.166999340057373,
      "learning_rate": 1.6063942409485497e-05,
      "loss": 1.4325,
      "step": 50600
    },
    {
      "epoch": 0.5367322849233277,
      "grad_norm": 3.0855746269226074,
      "learning_rate": 1.609570188439551e-05,
      "loss": 1.4445,
      "step": 50700
    },
    {
      "epoch": 0.5377909284833343,
      "grad_norm": 3.7460923194885254,
      "learning_rate": 1.6127461359305526e-05,
      "loss": 1.4275,
      "step": 50800
    },
    {
      "epoch": 0.5388495720433408,
      "grad_norm": 3.0675134658813477,
      "learning_rate": 1.615922083421554e-05,
      "loss": 1.4311,
      "step": 50900
    },
    {
      "epoch": 0.5399082156033475,
      "grad_norm": 3.1734085083007812,
      "learning_rate": 1.6190980309125555e-05,
      "loss": 1.4373,
      "step": 51000
    },
    {
      "epoch": 0.5399082156033475,
      "eval_loss": 1.4210723638534546,
      "eval_runtime": 57.4287,
      "eval_samples_per_second": 2924.148,
      "eval_steps_per_second": 365.532,
      "step": 51000
    },
    {
      "epoch": 0.540966859163354,
      "grad_norm": 3.17232084274292,
      "learning_rate": 1.622273978403557e-05,
      "loss": 1.431,
      "step": 51100
    },
    {
      "epoch": 0.5420255027233606,
      "grad_norm": 3.1207714080810547,
      "learning_rate": 1.6254499258945584e-05,
      "loss": 1.4458,
      "step": 51200
    },
    {
      "epoch": 0.5430841462833671,
      "grad_norm": 2.8886804580688477,
      "learning_rate": 1.62862587338556e-05,
      "loss": 1.4321,
      "step": 51300
    },
    {
      "epoch": 0.5441427898433737,
      "grad_norm": 3.0186455249786377,
      "learning_rate": 1.6318018208765613e-05,
      "loss": 1.449,
      "step": 51400
    },
    {
      "epoch": 0.5452014334033802,
      "grad_norm": 3.149080753326416,
      "learning_rate": 1.6349777683675628e-05,
      "loss": 1.4556,
      "step": 51500
    },
    {
      "epoch": 0.5462600769633869,
      "grad_norm": 2.9380815029144287,
      "learning_rate": 1.6381537158585642e-05,
      "loss": 1.4213,
      "step": 51600
    },
    {
      "epoch": 0.5473187205233934,
      "grad_norm": 2.865246295928955,
      "learning_rate": 1.6413296633495657e-05,
      "loss": 1.4398,
      "step": 51700
    },
    {
      "epoch": 0.5483773640834,
      "grad_norm": 2.899047374725342,
      "learning_rate": 1.644505610840567e-05,
      "loss": 1.4496,
      "step": 51800
    },
    {
      "epoch": 0.5494360076434065,
      "grad_norm": 3.1700010299682617,
      "learning_rate": 1.6476815583315686e-05,
      "loss": 1.4455,
      "step": 51900
    },
    {
      "epoch": 0.5504946512034131,
      "grad_norm": 2.963966131210327,
      "learning_rate": 1.65085750582257e-05,
      "loss": 1.4529,
      "step": 52000
    },
    {
      "epoch": 0.5504946512034131,
      "eval_loss": 1.4158903360366821,
      "eval_runtime": 57.358,
      "eval_samples_per_second": 2927.754,
      "eval_steps_per_second": 365.982,
      "step": 52000
    },
    {
      "epoch": 0.5515532947634196,
      "grad_norm": 3.080061674118042,
      "learning_rate": 1.6540334533135718e-05,
      "loss": 1.4343,
      "step": 52100
    },
    {
      "epoch": 0.5526119383234261,
      "grad_norm": 2.593569278717041,
      "learning_rate": 1.6572094008045733e-05,
      "loss": 1.4436,
      "step": 52200
    },
    {
      "epoch": 0.5536705818834328,
      "grad_norm": 2.996694326400757,
      "learning_rate": 1.6603853482955747e-05,
      "loss": 1.4369,
      "step": 52300
    },
    {
      "epoch": 0.5547292254434393,
      "grad_norm": 3.0874686241149902,
      "learning_rate": 1.663561295786576e-05,
      "loss": 1.4354,
      "step": 52400
    },
    {
      "epoch": 0.5557878690034459,
      "grad_norm": 3.121753454208374,
      "learning_rate": 1.6667372432775776e-05,
      "loss": 1.4471,
      "step": 52500
    },
    {
      "epoch": 0.5568465125634524,
      "grad_norm": 3.037822961807251,
      "learning_rate": 1.669913190768579e-05,
      "loss": 1.4376,
      "step": 52600
    },
    {
      "epoch": 0.557905156123459,
      "grad_norm": 3.128074884414673,
      "learning_rate": 1.673089138259581e-05,
      "loss": 1.4353,
      "step": 52700
    },
    {
      "epoch": 0.5589637996834655,
      "grad_norm": 3.0093610286712646,
      "learning_rate": 1.6762650857505823e-05,
      "loss": 1.4489,
      "step": 52800
    },
    {
      "epoch": 0.5600224432434722,
      "grad_norm": 3.173321008682251,
      "learning_rate": 1.6794410332415838e-05,
      "loss": 1.4258,
      "step": 52900
    },
    {
      "epoch": 0.5610810868034787,
      "grad_norm": 3.3951663970947266,
      "learning_rate": 1.6826169807325852e-05,
      "loss": 1.4191,
      "step": 53000
    },
    {
      "epoch": 0.5610810868034787,
      "eval_loss": 1.4112168550491333,
      "eval_runtime": 57.3523,
      "eval_samples_per_second": 2928.044,
      "eval_steps_per_second": 366.019,
      "step": 53000
    },
    {
      "epoch": 0.5621397303634853,
      "grad_norm": 2.9953837394714355,
      "learning_rate": 1.6857929282235867e-05,
      "loss": 1.4262,
      "step": 53100
    },
    {
      "epoch": 0.5631983739234918,
      "grad_norm": 3.0062384605407715,
      "learning_rate": 1.688968875714588e-05,
      "loss": 1.4421,
      "step": 53200
    },
    {
      "epoch": 0.5642570174834984,
      "grad_norm": 2.9464070796966553,
      "learning_rate": 1.6921448232055896e-05,
      "loss": 1.4355,
      "step": 53300
    },
    {
      "epoch": 0.565315661043505,
      "grad_norm": 2.933753252029419,
      "learning_rate": 1.695320770696591e-05,
      "loss": 1.4077,
      "step": 53400
    },
    {
      "epoch": 0.5663743046035116,
      "grad_norm": 3.1592628955841064,
      "learning_rate": 1.6984967181875925e-05,
      "loss": 1.4323,
      "step": 53500
    },
    {
      "epoch": 0.5674329481635181,
      "grad_norm": 3.1351985931396484,
      "learning_rate": 1.701672665678594e-05,
      "loss": 1.43,
      "step": 53600
    },
    {
      "epoch": 0.5684915917235247,
      "grad_norm": 2.6984803676605225,
      "learning_rate": 1.7048486131695954e-05,
      "loss": 1.4086,
      "step": 53700
    },
    {
      "epoch": 0.5695502352835312,
      "grad_norm": 2.8399667739868164,
      "learning_rate": 1.7079928011856868e-05,
      "loss": 1.4238,
      "step": 53800
    },
    {
      "epoch": 0.5706088788435377,
      "grad_norm": 2.9842939376831055,
      "learning_rate": 1.7111687486766886e-05,
      "loss": 1.419,
      "step": 53900
    },
    {
      "epoch": 0.5716675224035443,
      "grad_norm": 2.8374993801116943,
      "learning_rate": 1.71434469616769e-05,
      "loss": 1.4234,
      "step": 54000
    },
    {
      "epoch": 0.5716675224035443,
      "eval_loss": 1.4051332473754883,
      "eval_runtime": 57.3707,
      "eval_samples_per_second": 2927.105,
      "eval_steps_per_second": 365.901,
      "step": 54000
    },
    {
      "epoch": 0.5727261659635509,
      "grad_norm": 2.9654476642608643,
      "learning_rate": 1.7175206436586915e-05,
      "loss": 1.4271,
      "step": 54100
    },
    {
      "epoch": 0.5737848095235575,
      "grad_norm": 3.2506511211395264,
      "learning_rate": 1.720696591149693e-05,
      "loss": 1.4086,
      "step": 54200
    },
    {
      "epoch": 0.574843453083564,
      "grad_norm": 2.8144946098327637,
      "learning_rate": 1.7238725386406944e-05,
      "loss": 1.4238,
      "step": 54300
    },
    {
      "epoch": 0.5759020966435706,
      "grad_norm": 3.2179176807403564,
      "learning_rate": 1.7270484861316958e-05,
      "loss": 1.4221,
      "step": 54400
    },
    {
      "epoch": 0.5769607402035771,
      "grad_norm": 3.212495803833008,
      "learning_rate": 1.7302244336226973e-05,
      "loss": 1.4306,
      "step": 54500
    },
    {
      "epoch": 0.5780193837635837,
      "grad_norm": 3.2449755668640137,
      "learning_rate": 1.7334003811136987e-05,
      "loss": 1.4076,
      "step": 54600
    },
    {
      "epoch": 0.5790780273235903,
      "grad_norm": 3.145866870880127,
      "learning_rate": 1.7365763286047e-05,
      "loss": 1.433,
      "step": 54700
    },
    {
      "epoch": 0.5801366708835969,
      "grad_norm": 3.1669960021972656,
      "learning_rate": 1.7397522760957016e-05,
      "loss": 1.4204,
      "step": 54800
    },
    {
      "epoch": 0.5811953144436034,
      "grad_norm": 3.7756810188293457,
      "learning_rate": 1.742928223586703e-05,
      "loss": 1.4245,
      "step": 54900
    },
    {
      "epoch": 0.58225395800361,
      "grad_norm": 3.2430379390716553,
      "learning_rate": 1.7461041710777045e-05,
      "loss": 1.4309,
      "step": 55000
    },
    {
      "epoch": 0.58225395800361,
      "eval_loss": 1.4008944034576416,
      "eval_runtime": 57.4087,
      "eval_samples_per_second": 2925.169,
      "eval_steps_per_second": 365.659,
      "step": 55000
    },
    {
      "epoch": 0.5833126015636165,
      "grad_norm": 3.112257719039917,
      "learning_rate": 1.749280118568706e-05,
      "loss": 1.4166,
      "step": 55100
    },
    {
      "epoch": 0.5843712451236232,
      "grad_norm": 2.8256311416625977,
      "learning_rate": 1.7524560660597074e-05,
      "loss": 1.4294,
      "step": 55200
    },
    {
      "epoch": 0.5854298886836297,
      "grad_norm": 2.8671746253967285,
      "learning_rate": 1.755600254075799e-05,
      "loss": 1.4299,
      "step": 55300
    },
    {
      "epoch": 0.5864885322436362,
      "grad_norm": 3.145115852355957,
      "learning_rate": 1.7587762015668006e-05,
      "loss": 1.4262,
      "step": 55400
    },
    {
      "epoch": 0.5875471758036428,
      "grad_norm": 2.7237966060638428,
      "learning_rate": 1.761952149057802e-05,
      "loss": 1.4331,
      "step": 55500
    },
    {
      "epoch": 0.5886058193636493,
      "grad_norm": 3.006838321685791,
      "learning_rate": 1.7651280965488035e-05,
      "loss": 1.4107,
      "step": 55600
    },
    {
      "epoch": 0.5896644629236559,
      "grad_norm": 3.0919461250305176,
      "learning_rate": 1.768304044039805e-05,
      "loss": 1.4029,
      "step": 55700
    },
    {
      "epoch": 0.5907231064836624,
      "grad_norm": 2.8836894035339355,
      "learning_rate": 1.7714799915308064e-05,
      "loss": 1.4152,
      "step": 55800
    },
    {
      "epoch": 0.5917817500436691,
      "grad_norm": 3.0210134983062744,
      "learning_rate": 1.774655939021808e-05,
      "loss": 1.4106,
      "step": 55900
    },
    {
      "epoch": 0.5928403936036756,
      "grad_norm": 3.408264398574829,
      "learning_rate": 1.7778318865128097e-05,
      "loss": 1.4109,
      "step": 56000
    },
    {
      "epoch": 0.5928403936036756,
      "eval_loss": 1.3977622985839844,
      "eval_runtime": 57.277,
      "eval_samples_per_second": 2931.89,
      "eval_steps_per_second": 366.499,
      "step": 56000
    },
    {
      "epoch": 0.5938990371636822,
      "grad_norm": 3.0937259197235107,
      "learning_rate": 1.781007834003811e-05,
      "loss": 1.4196,
      "step": 56100
    },
    {
      "epoch": 0.5949576807236887,
      "grad_norm": 3.099132537841797,
      "learning_rate": 1.7841837814948126e-05,
      "loss": 1.4093,
      "step": 56200
    },
    {
      "epoch": 0.5960163242836953,
      "grad_norm": 2.9391937255859375,
      "learning_rate": 1.787359728985814e-05,
      "loss": 1.4058,
      "step": 56300
    },
    {
      "epoch": 0.5970749678437018,
      "grad_norm": 3.2235801219940186,
      "learning_rate": 1.7905356764768155e-05,
      "loss": 1.3945,
      "step": 56400
    },
    {
      "epoch": 0.5981336114037085,
      "grad_norm": 3.2247209548950195,
      "learning_rate": 1.793711623967817e-05,
      "loss": 1.4104,
      "step": 56500
    },
    {
      "epoch": 0.599192254963715,
      "grad_norm": 3.000718593597412,
      "learning_rate": 1.7968875714588184e-05,
      "loss": 1.4069,
      "step": 56600
    },
    {
      "epoch": 0.6002508985237216,
      "grad_norm": 3.0641143321990967,
      "learning_rate": 1.8000635189498198e-05,
      "loss": 1.4288,
      "step": 56700
    },
    {
      "epoch": 0.6013095420837281,
      "grad_norm": 3.1708688735961914,
      "learning_rate": 1.8032394664408213e-05,
      "loss": 1.4036,
      "step": 56800
    },
    {
      "epoch": 0.6023681856437347,
      "grad_norm": 3.2653884887695312,
      "learning_rate": 1.8064154139318227e-05,
      "loss": 1.4171,
      "step": 56900
    },
    {
      "epoch": 0.6034268292037412,
      "grad_norm": 3.218219041824341,
      "learning_rate": 1.8095913614228242e-05,
      "loss": 1.4015,
      "step": 57000
    },
    {
      "epoch": 0.6034268292037412,
      "eval_loss": 1.3897504806518555,
      "eval_runtime": 57.4425,
      "eval_samples_per_second": 2923.447,
      "eval_steps_per_second": 365.444,
      "step": 57000
    },
    {
      "epoch": 0.6044854727637478,
      "grad_norm": 3.1202967166900635,
      "learning_rate": 1.812767308913826e-05,
      "loss": 1.4117,
      "step": 57100
    },
    {
      "epoch": 0.6055441163237544,
      "grad_norm": 3.030242681503296,
      "learning_rate": 1.8159432564048274e-05,
      "loss": 1.4086,
      "step": 57200
    },
    {
      "epoch": 0.6066027598837609,
      "grad_norm": 3.114901304244995,
      "learning_rate": 1.819119203895829e-05,
      "loss": 1.4166,
      "step": 57300
    },
    {
      "epoch": 0.6076614034437675,
      "grad_norm": 3.392025947570801,
      "learning_rate": 1.8222951513868303e-05,
      "loss": 1.4201,
      "step": 57400
    },
    {
      "epoch": 0.608720047003774,
      "grad_norm": 3.2304487228393555,
      "learning_rate": 1.8254710988778318e-05,
      "loss": 1.4077,
      "step": 57500
    },
    {
      "epoch": 0.6097786905637806,
      "grad_norm": 3.2179715633392334,
      "learning_rate": 1.8286470463688332e-05,
      "loss": 1.4151,
      "step": 57600
    },
    {
      "epoch": 0.6108373341237872,
      "grad_norm": 2.8807671070098877,
      "learning_rate": 1.8318229938598347e-05,
      "loss": 1.4065,
      "step": 57700
    },
    {
      "epoch": 0.6118959776837938,
      "grad_norm": 3.034602403640747,
      "learning_rate": 1.834998941350836e-05,
      "loss": 1.4008,
      "step": 57800
    },
    {
      "epoch": 0.6129546212438003,
      "grad_norm": 2.872854232788086,
      "learning_rate": 1.8381748888418376e-05,
      "loss": 1.3961,
      "step": 57900
    },
    {
      "epoch": 0.6140132648038069,
      "grad_norm": 2.758415460586548,
      "learning_rate": 1.841350836332839e-05,
      "loss": 1.4051,
      "step": 58000
    },
    {
      "epoch": 0.6140132648038069,
      "eval_loss": 1.385687232017517,
      "eval_runtime": 57.3756,
      "eval_samples_per_second": 2926.856,
      "eval_steps_per_second": 365.87,
      "step": 58000
    },
    {
      "epoch": 0.6150719083638134,
      "grad_norm": 2.956901788711548,
      "learning_rate": 1.8445267838238405e-05,
      "loss": 1.3935,
      "step": 58100
    },
    {
      "epoch": 0.61613055192382,
      "grad_norm": 2.80316424369812,
      "learning_rate": 1.847702731314842e-05,
      "loss": 1.4072,
      "step": 58200
    },
    {
      "epoch": 0.6171891954838266,
      "grad_norm": 3.1601221561431885,
      "learning_rate": 1.8508786788058434e-05,
      "loss": 1.4087,
      "step": 58300
    },
    {
      "epoch": 0.6182478390438332,
      "grad_norm": 2.936659812927246,
      "learning_rate": 1.854054626296845e-05,
      "loss": 1.4037,
      "step": 58400
    },
    {
      "epoch": 0.6193064826038397,
      "grad_norm": 3.230966091156006,
      "learning_rate": 1.8572305737878466e-05,
      "loss": 1.4123,
      "step": 58500
    },
    {
      "epoch": 0.6203651261638463,
      "grad_norm": 3.249657392501831,
      "learning_rate": 1.860406521278848e-05,
      "loss": 1.3991,
      "step": 58600
    },
    {
      "epoch": 0.6214237697238528,
      "grad_norm": 2.949805974960327,
      "learning_rate": 1.8635824687698495e-05,
      "loss": 1.4173,
      "step": 58700
    },
    {
      "epoch": 0.6224824132838593,
      "grad_norm": 3.011119842529297,
      "learning_rate": 1.866758416260851e-05,
      "loss": 1.4136,
      "step": 58800
    },
    {
      "epoch": 0.623541056843866,
      "grad_norm": 2.8473949432373047,
      "learning_rate": 1.8699343637518524e-05,
      "loss": 1.4091,
      "step": 58900
    },
    {
      "epoch": 0.6245997004038725,
      "grad_norm": 3.1961851119995117,
      "learning_rate": 1.873110311242854e-05,
      "loss": 1.4128,
      "step": 59000
    },
    {
      "epoch": 0.6245997004038725,
      "eval_loss": 1.3778722286224365,
      "eval_runtime": 57.3072,
      "eval_samples_per_second": 2930.349,
      "eval_steps_per_second": 366.307,
      "step": 59000
    },
    {
      "epoch": 0.6256583439638791,
      "grad_norm": 3.251898765563965,
      "learning_rate": 1.8762862587338553e-05,
      "loss": 1.4079,
      "step": 59100
    },
    {
      "epoch": 0.6267169875238856,
      "grad_norm": 3.366309642791748,
      "learning_rate": 1.8794622062248568e-05,
      "loss": 1.3978,
      "step": 59200
    },
    {
      "epoch": 0.6277756310838922,
      "grad_norm": 2.818121910095215,
      "learning_rate": 1.8826063942409485e-05,
      "loss": 1.3921,
      "step": 59300
    },
    {
      "epoch": 0.6288342746438987,
      "grad_norm": 2.964157819747925,
      "learning_rate": 1.88578234173195e-05,
      "loss": 1.3897,
      "step": 59400
    },
    {
      "epoch": 0.6298929182039054,
      "grad_norm": 2.9778635501861572,
      "learning_rate": 1.8889582892229514e-05,
      "loss": 1.381,
      "step": 59500
    },
    {
      "epoch": 0.6309515617639119,
      "grad_norm": 2.6405553817749023,
      "learning_rate": 1.892134236713953e-05,
      "loss": 1.3916,
      "step": 59600
    },
    {
      "epoch": 0.6320102053239185,
      "grad_norm": 2.9526000022888184,
      "learning_rate": 1.8953101842049543e-05,
      "loss": 1.3987,
      "step": 59700
    },
    {
      "epoch": 0.633068848883925,
      "grad_norm": 3.1660101413726807,
      "learning_rate": 1.8984861316959558e-05,
      "loss": 1.4099,
      "step": 59800
    },
    {
      "epoch": 0.6341274924439316,
      "grad_norm": 2.8594810962677,
      "learning_rate": 1.9016620791869572e-05,
      "loss": 1.3925,
      "step": 59900
    },
    {
      "epoch": 0.6351861360039381,
      "grad_norm": 3.1111910343170166,
      "learning_rate": 1.9048380266779587e-05,
      "loss": 1.4101,
      "step": 60000
    },
    {
      "epoch": 0.6351861360039381,
      "eval_loss": 1.3750596046447754,
      "eval_runtime": 57.5046,
      "eval_samples_per_second": 2920.29,
      "eval_steps_per_second": 365.049,
      "step": 60000
    },
    {
      "epoch": 0.6362447795639448,
      "grad_norm": 2.9321506023406982,
      "learning_rate": 1.90801397416896e-05,
      "loss": 1.3944,
      "step": 60100
    },
    {
      "epoch": 0.6373034231239513,
      "grad_norm": 3.1526310443878174,
      "learning_rate": 1.9111899216599616e-05,
      "loss": 1.3966,
      "step": 60200
    },
    {
      "epoch": 0.6383620666839579,
      "grad_norm": 3.240506172180176,
      "learning_rate": 1.914365869150963e-05,
      "loss": 1.3898,
      "step": 60300
    },
    {
      "epoch": 0.6394207102439644,
      "grad_norm": 2.892054796218872,
      "learning_rate": 1.917541816641965e-05,
      "loss": 1.3941,
      "step": 60400
    },
    {
      "epoch": 0.6404793538039709,
      "grad_norm": 2.986957550048828,
      "learning_rate": 1.9207177641329663e-05,
      "loss": 1.3862,
      "step": 60500
    },
    {
      "epoch": 0.6415379973639775,
      "grad_norm": 3.147693157196045,
      "learning_rate": 1.9238937116239677e-05,
      "loss": 1.4008,
      "step": 60600
    },
    {
      "epoch": 0.642596640923984,
      "grad_norm": 2.8918027877807617,
      "learning_rate": 1.9270696591149692e-05,
      "loss": 1.3909,
      "step": 60700
    },
    {
      "epoch": 0.6436552844839907,
      "grad_norm": 3.004491090774536,
      "learning_rate": 1.9302456066059706e-05,
      "loss": 1.3959,
      "step": 60800
    },
    {
      "epoch": 0.6447139280439972,
      "grad_norm": 3.019230842590332,
      "learning_rate": 1.933421554096972e-05,
      "loss": 1.3795,
      "step": 60900
    },
    {
      "epoch": 0.6457725716040038,
      "grad_norm": 3.1873536109924316,
      "learning_rate": 1.9365975015879735e-05,
      "loss": 1.3893,
      "step": 61000
    },
    {
      "epoch": 0.6457725716040038,
      "eval_loss": 1.366033673286438,
      "eval_runtime": 57.3766,
      "eval_samples_per_second": 2926.801,
      "eval_steps_per_second": 365.863,
      "step": 61000
    },
    {
      "epoch": 0.6468312151640103,
      "grad_norm": 2.998274087905884,
      "learning_rate": 1.939773449078975e-05,
      "loss": 1.3688,
      "step": 61100
    },
    {
      "epoch": 0.6478898587240169,
      "grad_norm": 3.3907318115234375,
      "learning_rate": 1.9429493965699765e-05,
      "loss": 1.3874,
      "step": 61200
    },
    {
      "epoch": 0.6489485022840235,
      "grad_norm": 3.5501389503479004,
      "learning_rate": 1.946093584586068e-05,
      "loss": 1.3923,
      "step": 61300
    },
    {
      "epoch": 0.6500071458440301,
      "grad_norm": 2.969298839569092,
      "learning_rate": 1.9492695320770693e-05,
      "loss": 1.3981,
      "step": 61400
    },
    {
      "epoch": 0.6510657894040366,
      "grad_norm": 2.98051118850708,
      "learning_rate": 1.952445479568071e-05,
      "loss": 1.4021,
      "step": 61500
    },
    {
      "epoch": 0.6521244329640432,
      "grad_norm": 2.771005153656006,
      "learning_rate": 1.9556214270590725e-05,
      "loss": 1.3886,
      "step": 61600
    },
    {
      "epoch": 0.6531830765240497,
      "grad_norm": 3.2222940921783447,
      "learning_rate": 1.958797374550074e-05,
      "loss": 1.3849,
      "step": 61700
    },
    {
      "epoch": 0.6542417200840563,
      "grad_norm": 3.1475913524627686,
      "learning_rate": 1.9619733220410754e-05,
      "loss": 1.3829,
      "step": 61800
    },
    {
      "epoch": 0.6553003636440629,
      "grad_norm": 2.882429361343384,
      "learning_rate": 1.965149269532077e-05,
      "loss": 1.3877,
      "step": 61900
    },
    {
      "epoch": 0.6563590072040695,
      "grad_norm": 3.0250587463378906,
      "learning_rate": 1.9683252170230783e-05,
      "loss": 1.3873,
      "step": 62000
    },
    {
      "epoch": 0.6563590072040695,
      "eval_loss": 1.3633841276168823,
      "eval_runtime": 57.3495,
      "eval_samples_per_second": 2928.184,
      "eval_steps_per_second": 366.036,
      "step": 62000
    },
    {
      "epoch": 0.657417650764076,
      "grad_norm": 3.112962007522583,
      "learning_rate": 1.9715011645140798e-05,
      "loss": 1.3732,
      "step": 62100
    },
    {
      "epoch": 0.6584762943240825,
      "grad_norm": 2.8926146030426025,
      "learning_rate": 1.9746771120050812e-05,
      "loss": 1.3839,
      "step": 62200
    },
    {
      "epoch": 0.6595349378840891,
      "grad_norm": 3.0539963245391846,
      "learning_rate": 1.9778530594960827e-05,
      "loss": 1.3751,
      "step": 62300
    },
    {
      "epoch": 0.6605935814440956,
      "grad_norm": 2.798983573913574,
      "learning_rate": 1.981029006987084e-05,
      "loss": 1.3898,
      "step": 62400
    },
    {
      "epoch": 0.6616522250041023,
      "grad_norm": 3.1385750770568848,
      "learning_rate": 1.9842049544780856e-05,
      "loss": 1.38,
      "step": 62500
    },
    {
      "epoch": 0.6627108685641088,
      "grad_norm": 2.766787528991699,
      "learning_rate": 1.987380901969087e-05,
      "loss": 1.3719,
      "step": 62600
    },
    {
      "epoch": 0.6637695121241154,
      "grad_norm": 3.027782678604126,
      "learning_rate": 1.9905568494600885e-05,
      "loss": 1.3843,
      "step": 62700
    },
    {
      "epoch": 0.6648281556841219,
      "grad_norm": 2.9771158695220947,
      "learning_rate": 1.99373279695109e-05,
      "loss": 1.3827,
      "step": 62800
    },
    {
      "epoch": 0.6658867992441285,
      "grad_norm": 2.8728835582733154,
      "learning_rate": 1.9969087444420914e-05,
      "loss": 1.3786,
      "step": 62900
    },
    {
      "epoch": 0.666945442804135,
      "grad_norm": 3.0861291885375977,
      "learning_rate": 2.0000846919330932e-05,
      "loss": 1.3757,
      "step": 63000
    },
    {
      "epoch": 0.666945442804135,
      "eval_loss": 1.35576331615448,
      "eval_runtime": 57.3976,
      "eval_samples_per_second": 2925.732,
      "eval_steps_per_second": 365.73,
      "step": 63000
    },
    {
      "epoch": 0.6680040863641417,
      "grad_norm": 3.136578321456909,
      "learning_rate": 2.0032606394240947e-05,
      "loss": 1.3739,
      "step": 63100
    },
    {
      "epoch": 0.6690627299241482,
      "grad_norm": 2.7745296955108643,
      "learning_rate": 2.006436586915096e-05,
      "loss": 1.3841,
      "step": 63200
    },
    {
      "epoch": 0.6701213734841548,
      "grad_norm": 3.275723934173584,
      "learning_rate": 2.0095807749311875e-05,
      "loss": 1.3792,
      "step": 63300
    },
    {
      "epoch": 0.6711800170441613,
      "grad_norm": 3.0626015663146973,
      "learning_rate": 2.012756722422189e-05,
      "loss": 1.3859,
      "step": 63400
    },
    {
      "epoch": 0.6722386606041679,
      "grad_norm": 3.0208001136779785,
      "learning_rate": 2.0159326699131904e-05,
      "loss": 1.3692,
      "step": 63500
    },
    {
      "epoch": 0.6732973041641744,
      "grad_norm": 3.189323902130127,
      "learning_rate": 2.019108617404192e-05,
      "loss": 1.3877,
      "step": 63600
    },
    {
      "epoch": 0.6743559477241811,
      "grad_norm": 2.9202537536621094,
      "learning_rate": 2.0222845648951933e-05,
      "loss": 1.3715,
      "step": 63700
    },
    {
      "epoch": 0.6754145912841876,
      "grad_norm": 3.0721826553344727,
      "learning_rate": 2.0254605123861948e-05,
      "loss": 1.372,
      "step": 63800
    },
    {
      "epoch": 0.6764732348441941,
      "grad_norm": 2.668189287185669,
      "learning_rate": 2.0286364598771962e-05,
      "loss": 1.3734,
      "step": 63900
    },
    {
      "epoch": 0.6775318784042007,
      "grad_norm": 2.923463821411133,
      "learning_rate": 2.0318124073681977e-05,
      "loss": 1.3728,
      "step": 64000
    },
    {
      "epoch": 0.6775318784042007,
      "eval_loss": 1.3524037599563599,
      "eval_runtime": 57.375,
      "eval_samples_per_second": 2926.885,
      "eval_steps_per_second": 365.874,
      "step": 64000
    },
    {
      "epoch": 0.6785905219642072,
      "grad_norm": 2.9096593856811523,
      "learning_rate": 2.0349883548591995e-05,
      "loss": 1.3658,
      "step": 64100
    },
    {
      "epoch": 0.6796491655242138,
      "grad_norm": 3.1270594596862793,
      "learning_rate": 2.0381643023502012e-05,
      "loss": 1.3726,
      "step": 64200
    },
    {
      "epoch": 0.6807078090842203,
      "grad_norm": 2.9771411418914795,
      "learning_rate": 2.0413402498412027e-05,
      "loss": 1.3726,
      "step": 64300
    },
    {
      "epoch": 0.681766452644227,
      "grad_norm": 2.6242756843566895,
      "learning_rate": 2.044516197332204e-05,
      "loss": 1.3724,
      "step": 64400
    },
    {
      "epoch": 0.6828250962042335,
      "grad_norm": 3.1829044818878174,
      "learning_rate": 2.0476921448232056e-05,
      "loss": 1.3771,
      "step": 64500
    },
    {
      "epoch": 0.6838837397642401,
      "grad_norm": 3.032284736633301,
      "learning_rate": 2.050868092314207e-05,
      "loss": 1.3771,
      "step": 64600
    },
    {
      "epoch": 0.6849423833242466,
      "grad_norm": 3.0783231258392334,
      "learning_rate": 2.0540440398052085e-05,
      "loss": 1.3844,
      "step": 64700
    },
    {
      "epoch": 0.6860010268842532,
      "grad_norm": 3.0715878009796143,
      "learning_rate": 2.0571882278212996e-05,
      "loss": 1.3718,
      "step": 64800
    },
    {
      "epoch": 0.6870596704442598,
      "grad_norm": 3.2787363529205322,
      "learning_rate": 2.0603641753123017e-05,
      "loss": 1.3598,
      "step": 64900
    },
    {
      "epoch": 0.6881183140042664,
      "grad_norm": 3.143874168395996,
      "learning_rate": 2.063540122803303e-05,
      "loss": 1.3746,
      "step": 65000
    },
    {
      "epoch": 0.6881183140042664,
      "eval_loss": 1.3486624956130981,
      "eval_runtime": 57.2809,
      "eval_samples_per_second": 2931.695,
      "eval_steps_per_second": 366.475,
      "step": 65000
    },
    {
      "epoch": 0.6891769575642729,
      "grad_norm": 2.7552850246429443,
      "learning_rate": 2.0667160702943046e-05,
      "loss": 1.3631,
      "step": 65100
    },
    {
      "epoch": 0.6902356011242795,
      "grad_norm": 2.9898693561553955,
      "learning_rate": 2.069892017785306e-05,
      "loss": 1.3869,
      "step": 65200
    },
    {
      "epoch": 0.691294244684286,
      "grad_norm": 2.8843297958374023,
      "learning_rate": 2.0730679652763075e-05,
      "loss": 1.3465,
      "step": 65300
    },
    {
      "epoch": 0.6923528882442926,
      "grad_norm": 3.0470938682556152,
      "learning_rate": 2.076243912767309e-05,
      "loss": 1.3697,
      "step": 65400
    },
    {
      "epoch": 0.6934115318042992,
      "grad_norm": 2.994696617126465,
      "learning_rate": 2.0794198602583104e-05,
      "loss": 1.3579,
      "step": 65500
    },
    {
      "epoch": 0.6944701753643057,
      "grad_norm": 2.9063754081726074,
      "learning_rate": 2.082595807749312e-05,
      "loss": 1.3621,
      "step": 65600
    },
    {
      "epoch": 0.6955288189243123,
      "grad_norm": 3.1868984699249268,
      "learning_rate": 2.0857717552403133e-05,
      "loss": 1.3684,
      "step": 65700
    },
    {
      "epoch": 0.6965874624843188,
      "grad_norm": 2.9727656841278076,
      "learning_rate": 2.0889477027313148e-05,
      "loss": 1.3765,
      "step": 65800
    },
    {
      "epoch": 0.6976461060443254,
      "grad_norm": 2.800150156021118,
      "learning_rate": 2.0921236502223162e-05,
      "loss": 1.3495,
      "step": 65900
    },
    {
      "epoch": 0.6987047496043319,
      "grad_norm": 2.8481943607330322,
      "learning_rate": 2.0952995977133177e-05,
      "loss": 1.3614,
      "step": 66000
    },
    {
      "epoch": 0.6987047496043319,
      "eval_loss": 1.3359715938568115,
      "eval_runtime": 57.3713,
      "eval_samples_per_second": 2927.073,
      "eval_steps_per_second": 365.897,
      "step": 66000
    },
    {
      "epoch": 0.6997633931643386,
      "grad_norm": 3.215712308883667,
      "learning_rate": 2.098475545204319e-05,
      "loss": 1.3567,
      "step": 66100
    },
    {
      "epoch": 0.7008220367243451,
      "grad_norm": 3.2328085899353027,
      "learning_rate": 2.1016514926953206e-05,
      "loss": 1.3657,
      "step": 66200
    },
    {
      "epoch": 0.7018806802843517,
      "grad_norm": 3.222917318344116,
      "learning_rate": 2.104827440186322e-05,
      "loss": 1.3497,
      "step": 66300
    },
    {
      "epoch": 0.7029393238443582,
      "grad_norm": 3.047045946121216,
      "learning_rate": 2.1080033876773235e-05,
      "loss": 1.3554,
      "step": 66400
    },
    {
      "epoch": 0.7039979674043648,
      "grad_norm": 3.0431153774261475,
      "learning_rate": 2.1111793351683253e-05,
      "loss": 1.367,
      "step": 66500
    },
    {
      "epoch": 0.7050566109643713,
      "grad_norm": 3.2628118991851807,
      "learning_rate": 2.1143552826593267e-05,
      "loss": 1.3528,
      "step": 66600
    },
    {
      "epoch": 0.706115254524378,
      "grad_norm": 2.671374797821045,
      "learning_rate": 2.117531230150328e-05,
      "loss": 1.3486,
      "step": 66700
    },
    {
      "epoch": 0.7071738980843845,
      "grad_norm": 3.1395184993743896,
      "learning_rate": 2.1207071776413296e-05,
      "loss": 1.3527,
      "step": 66800
    },
    {
      "epoch": 0.7082325416443911,
      "grad_norm": 2.8234970569610596,
      "learning_rate": 2.123883125132331e-05,
      "loss": 1.353,
      "step": 66900
    },
    {
      "epoch": 0.7092911852043976,
      "grad_norm": 2.8508341312408447,
      "learning_rate": 2.1270590726233325e-05,
      "loss": 1.3459,
      "step": 67000
    },
    {
      "epoch": 0.7092911852043976,
      "eval_loss": 1.329383373260498,
      "eval_runtime": 57.4796,
      "eval_samples_per_second": 2921.557,
      "eval_steps_per_second": 365.208,
      "step": 67000
    },
    {
      "epoch": 0.7103498287644042,
      "grad_norm": 3.2960314750671387,
      "learning_rate": 2.130235020114334e-05,
      "loss": 1.3571,
      "step": 67100
    },
    {
      "epoch": 0.7114084723244107,
      "grad_norm": 3.289025068283081,
      "learning_rate": 2.1334109676053354e-05,
      "loss": 1.356,
      "step": 67200
    },
    {
      "epoch": 0.7124671158844172,
      "grad_norm": 3.0605506896972656,
      "learning_rate": 2.136586915096337e-05,
      "loss": 1.3547,
      "step": 67300
    },
    {
      "epoch": 0.7135257594444239,
      "grad_norm": 2.973716974258423,
      "learning_rate": 2.1397628625873383e-05,
      "loss": 1.3572,
      "step": 67400
    },
    {
      "epoch": 0.7145844030044304,
      "grad_norm": 2.6918087005615234,
      "learning_rate": 2.1429388100783398e-05,
      "loss": 1.345,
      "step": 67500
    },
    {
      "epoch": 0.715643046564437,
      "grad_norm": 3.1918346881866455,
      "learning_rate": 2.1461147575693412e-05,
      "loss": 1.3516,
      "step": 67600
    },
    {
      "epoch": 0.7167016901244435,
      "grad_norm": 2.990119457244873,
      "learning_rate": 2.1492907050603427e-05,
      "loss": 1.3434,
      "step": 67700
    },
    {
      "epoch": 0.7177603336844501,
      "grad_norm": 2.8786308765411377,
      "learning_rate": 2.152466652551344e-05,
      "loss": 1.3417,
      "step": 67800
    },
    {
      "epoch": 0.7188189772444566,
      "grad_norm": 2.9086527824401855,
      "learning_rate": 2.1556426000423456e-05,
      "loss": 1.3455,
      "step": 67900
    },
    {
      "epoch": 0.7198776208044633,
      "grad_norm": 3.1648669242858887,
      "learning_rate": 2.1588185475333474e-05,
      "loss": 1.3537,
      "step": 68000
    },
    {
      "epoch": 0.7198776208044633,
      "eval_loss": 1.3250329494476318,
      "eval_runtime": 57.296,
      "eval_samples_per_second": 2930.918,
      "eval_steps_per_second": 366.378,
      "step": 68000
    },
    {
      "epoch": 0.7209362643644698,
      "grad_norm": 2.931833505630493,
      "learning_rate": 2.1619944950243488e-05,
      "loss": 1.3502,
      "step": 68100
    },
    {
      "epoch": 0.7219949079244764,
      "grad_norm": 2.995203971862793,
      "learning_rate": 2.1651704425153503e-05,
      "loss": 1.3578,
      "step": 68200
    },
    {
      "epoch": 0.7230535514844829,
      "grad_norm": 2.907029151916504,
      "learning_rate": 2.1683463900063517e-05,
      "loss": 1.3473,
      "step": 68300
    },
    {
      "epoch": 0.7241121950444895,
      "grad_norm": 2.9169492721557617,
      "learning_rate": 2.1715223374973532e-05,
      "loss": 1.3599,
      "step": 68400
    },
    {
      "epoch": 0.725170838604496,
      "grad_norm": 3.203402280807495,
      "learning_rate": 2.1746982849883546e-05,
      "loss": 1.3384,
      "step": 68500
    },
    {
      "epoch": 0.7262294821645027,
      "grad_norm": 2.9072439670562744,
      "learning_rate": 2.177874232479356e-05,
      "loss": 1.3555,
      "step": 68600
    },
    {
      "epoch": 0.7272881257245092,
      "grad_norm": 3.261705160140991,
      "learning_rate": 2.1810501799703575e-05,
      "loss": 1.347,
      "step": 68700
    },
    {
      "epoch": 0.7283467692845158,
      "grad_norm": 2.985471725463867,
      "learning_rate": 2.184194367986449e-05,
      "loss": 1.3729,
      "step": 68800
    },
    {
      "epoch": 0.7294054128445223,
      "grad_norm": 3.4243881702423096,
      "learning_rate": 2.1873703154774504e-05,
      "loss": 1.3464,
      "step": 68900
    },
    {
      "epoch": 0.7304640564045288,
      "grad_norm": 3.0334253311157227,
      "learning_rate": 2.1905462629684518e-05,
      "loss": 1.3381,
      "step": 69000
    },
    {
      "epoch": 0.7304640564045288,
      "eval_loss": 1.3153942823410034,
      "eval_runtime": 57.4363,
      "eval_samples_per_second": 2923.76,
      "eval_steps_per_second": 365.483,
      "step": 69000
    },
    {
      "epoch": 0.7315226999645354,
      "grad_norm": 2.9463706016540527,
      "learning_rate": 2.1937222104594536e-05,
      "loss": 1.3486,
      "step": 69100
    },
    {
      "epoch": 0.732581343524542,
      "grad_norm": 3.109050750732422,
      "learning_rate": 2.196898157950455e-05,
      "loss": 1.3394,
      "step": 69200
    },
    {
      "epoch": 0.7336399870845486,
      "grad_norm": 2.839339256286621,
      "learning_rate": 2.2000741054414565e-05,
      "loss": 1.3421,
      "step": 69300
    },
    {
      "epoch": 0.7346986306445551,
      "grad_norm": 3.3075389862060547,
      "learning_rate": 2.203250052932458e-05,
      "loss": 1.3311,
      "step": 69400
    },
    {
      "epoch": 0.7357572742045617,
      "grad_norm": Infinity,
      "learning_rate": 2.2063942409485494e-05,
      "loss": 1.3379,
      "step": 69500
    },
    {
      "epoch": 0.7368159177645682,
      "grad_norm": 2.9391942024230957,
      "learning_rate": 2.2095701884395508e-05,
      "loss": 1.3408,
      "step": 69600
    },
    {
      "epoch": 0.7378745613245749,
      "grad_norm": 3.066066265106201,
      "learning_rate": 2.2127461359305523e-05,
      "loss": 1.3427,
      "step": 69700
    },
    {
      "epoch": 0.7389332048845814,
      "grad_norm": 3.1152405738830566,
      "learning_rate": 2.2159220834215537e-05,
      "loss": 1.337,
      "step": 69800
    },
    {
      "epoch": 0.739991848444588,
      "grad_norm": 3.039621114730835,
      "learning_rate": 2.2190980309125552e-05,
      "loss": 1.3364,
      "step": 69900
    },
    {
      "epoch": 0.7410504920045945,
      "grad_norm": 3.216265916824341,
      "learning_rate": 2.2222739784035566e-05,
      "loss": 1.3298,
      "step": 70000
    },
    {
      "epoch": 0.7410504920045945,
      "eval_loss": 1.3091447353363037,
      "eval_runtime": 57.3389,
      "eval_samples_per_second": 2928.726,
      "eval_steps_per_second": 366.104,
      "step": 70000
    },
    {
      "epoch": 0.7421091355646011,
      "grad_norm": 3.0931670665740967,
      "learning_rate": 2.225449925894558e-05,
      "loss": 1.3319,
      "step": 70100
    },
    {
      "epoch": 0.7431677791246076,
      "grad_norm": 3.1048147678375244,
      "learning_rate": 2.22862587338556e-05,
      "loss": 1.3398,
      "step": 70200
    },
    {
      "epoch": 0.7442264226846143,
      "grad_norm": 3.0066773891448975,
      "learning_rate": 2.2318018208765613e-05,
      "loss": 1.3447,
      "step": 70300
    },
    {
      "epoch": 0.7452850662446208,
      "grad_norm": 3.074845314025879,
      "learning_rate": 2.2349777683675628e-05,
      "loss": 1.3318,
      "step": 70400
    },
    {
      "epoch": 0.7463437098046273,
      "grad_norm": 3.0728275775909424,
      "learning_rate": 2.2381537158585642e-05,
      "loss": 1.329,
      "step": 70500
    },
    {
      "epoch": 0.7474023533646339,
      "grad_norm": 2.969904661178589,
      "learning_rate": 2.2413296633495657e-05,
      "loss": 1.3361,
      "step": 70600
    },
    {
      "epoch": 0.7484609969246404,
      "grad_norm": 3.4038612842559814,
      "learning_rate": 2.244505610840567e-05,
      "loss": 1.3218,
      "step": 70700
    },
    {
      "epoch": 0.749519640484647,
      "grad_norm": 3.0229508876800537,
      "learning_rate": 2.2476815583315686e-05,
      "loss": 1.3259,
      "step": 70800
    },
    {
      "epoch": 0.7505782840446535,
      "grad_norm": 3.1092400550842285,
      "learning_rate": 2.25085750582257e-05,
      "loss": 1.3283,
      "step": 70900
    },
    {
      "epoch": 0.7516369276046602,
      "grad_norm": 3.3040771484375,
      "learning_rate": 2.2540334533135715e-05,
      "loss": 1.334,
      "step": 71000
    },
    {
      "epoch": 0.7516369276046602,
      "eval_loss": 1.3017383813858032,
      "eval_runtime": 57.2869,
      "eval_samples_per_second": 2931.387,
      "eval_steps_per_second": 366.436,
      "step": 71000
    },
    {
      "epoch": 0.7526955711646667,
      "grad_norm": 3.2073709964752197,
      "learning_rate": 2.257209400804573e-05,
      "loss": 1.3303,
      "step": 71100
    },
    {
      "epoch": 0.7537542147246733,
      "grad_norm": 3.173267126083374,
      "learning_rate": 2.2603853482955747e-05,
      "loss": 1.3255,
      "step": 71200
    },
    {
      "epoch": 0.7548128582846798,
      "grad_norm": 3.171947956085205,
      "learning_rate": 2.2635612957865762e-05,
      "loss": 1.3073,
      "step": 71300
    },
    {
      "epoch": 0.7558715018446864,
      "grad_norm": 3.242223024368286,
      "learning_rate": 2.266737243277578e-05,
      "loss": 1.3252,
      "step": 71400
    },
    {
      "epoch": 0.7569301454046929,
      "grad_norm": 2.8422207832336426,
      "learning_rate": 2.2699131907685794e-05,
      "loss": 1.3363,
      "step": 71500
    },
    {
      "epoch": 0.7579887889646996,
      "grad_norm": 3.2782480716705322,
      "learning_rate": 2.273089138259581e-05,
      "loss": 1.3217,
      "step": 71600
    },
    {
      "epoch": 0.7590474325247061,
      "grad_norm": 3.4185612201690674,
      "learning_rate": 2.2762650857505823e-05,
      "loss": 1.3384,
      "step": 71700
    },
    {
      "epoch": 0.7601060760847127,
      "grad_norm": 2.876915216445923,
      "learning_rate": 2.2794410332415838e-05,
      "loss": 1.3309,
      "step": 71800
    },
    {
      "epoch": 0.7611647196447192,
      "grad_norm": 3.1413352489471436,
      "learning_rate": 2.2826169807325852e-05,
      "loss": 1.3284,
      "step": 71900
    },
    {
      "epoch": 0.7622233632047258,
      "grad_norm": 2.882984161376953,
      "learning_rate": 2.2857929282235867e-05,
      "loss": 1.3368,
      "step": 72000
    },
    {
      "epoch": 0.7622233632047258,
      "eval_loss": 1.2929078340530396,
      "eval_runtime": 57.3623,
      "eval_samples_per_second": 2927.531,
      "eval_steps_per_second": 365.954,
      "step": 72000
    },
    {
      "epoch": 0.7632820067647323,
      "grad_norm": 2.855314016342163,
      "learning_rate": 2.288968875714588e-05,
      "loss": 1.3261,
      "step": 72100
    },
    {
      "epoch": 0.7643406503247389,
      "grad_norm": 2.997323989868164,
      "learning_rate": 2.2921448232055896e-05,
      "loss": 1.3281,
      "step": 72200
    },
    {
      "epoch": 0.7653992938847455,
      "grad_norm": 3.3122692108154297,
      "learning_rate": 2.295320770696591e-05,
      "loss": 1.3235,
      "step": 72300
    },
    {
      "epoch": 0.766457937444752,
      "grad_norm": 3.0222771167755127,
      "learning_rate": 2.2984967181875925e-05,
      "loss": 1.3229,
      "step": 72400
    },
    {
      "epoch": 0.7675165810047586,
      "grad_norm": 3.170260190963745,
      "learning_rate": 2.301672665678594e-05,
      "loss": 1.3231,
      "step": 72500
    },
    {
      "epoch": 0.7685752245647651,
      "grad_norm": 2.8297922611236572,
      "learning_rate": 2.3048486131695954e-05,
      "loss": 1.3197,
      "step": 72600
    },
    {
      "epoch": 0.7696338681247717,
      "grad_norm": 2.9728379249572754,
      "learning_rate": 2.308024560660597e-05,
      "loss": 1.323,
      "step": 72700
    },
    {
      "epoch": 0.7706925116847783,
      "grad_norm": 3.206615686416626,
      "learning_rate": 2.3112005081515983e-05,
      "loss": 1.3249,
      "step": 72800
    },
    {
      "epoch": 0.7717511552447849,
      "grad_norm": 3.0055532455444336,
      "learning_rate": 2.3143764556425997e-05,
      "loss": 1.3179,
      "step": 72900
    },
    {
      "epoch": 0.7728097988047914,
      "grad_norm": 3.1952145099639893,
      "learning_rate": 2.3175524031336015e-05,
      "loss": 1.3371,
      "step": 73000
    },
    {
      "epoch": 0.7728097988047914,
      "eval_loss": 1.2887132167816162,
      "eval_runtime": 57.491,
      "eval_samples_per_second": 2920.98,
      "eval_steps_per_second": 365.136,
      "step": 73000
    },
    {
      "epoch": 0.773868442364798,
      "grad_norm": 3.028165817260742,
      "learning_rate": 2.320728350624603e-05,
      "loss": 1.3156,
      "step": 73100
    },
    {
      "epoch": 0.7749270859248045,
      "grad_norm": 3.093536376953125,
      "learning_rate": 2.3239042981156044e-05,
      "loss": 1.3167,
      "step": 73200
    },
    {
      "epoch": 0.7759857294848111,
      "grad_norm": 3.202613353729248,
      "learning_rate": 2.327080245606606e-05,
      "loss": 1.3203,
      "step": 73300
    },
    {
      "epoch": 0.7770443730448177,
      "grad_norm": 3.264129638671875,
      "learning_rate": 2.3302561930976073e-05,
      "loss": 1.329,
      "step": 73400
    },
    {
      "epoch": 0.7781030166048243,
      "grad_norm": 3.212247371673584,
      "learning_rate": 2.3334321405886088e-05,
      "loss": 1.3077,
      "step": 73500
    },
    {
      "epoch": 0.7791616601648308,
      "grad_norm": 3.1977806091308594,
      "learning_rate": 2.3365763286047002e-05,
      "loss": 1.312,
      "step": 73600
    },
    {
      "epoch": 0.7802203037248374,
      "grad_norm": 3.0799496173858643,
      "learning_rate": 2.3397522760957016e-05,
      "loss": 1.3274,
      "step": 73700
    },
    {
      "epoch": 0.7812789472848439,
      "grad_norm": 3.128546953201294,
      "learning_rate": 2.342928223586703e-05,
      "loss": 1.3297,
      "step": 73800
    },
    {
      "epoch": 0.7823375908448504,
      "grad_norm": 3.1258039474487305,
      "learning_rate": 2.3461041710777045e-05,
      "loss": 1.3254,
      "step": 73900
    },
    {
      "epoch": 0.7833962344048571,
      "grad_norm": 3.4792697429656982,
      "learning_rate": 2.349280118568706e-05,
      "loss": 1.3198,
      "step": 74000
    },
    {
      "epoch": 0.7833962344048571,
      "eval_loss": 1.2764360904693604,
      "eval_runtime": 57.3002,
      "eval_samples_per_second": 2930.704,
      "eval_steps_per_second": 366.351,
      "step": 74000
    },
    {
      "epoch": 0.7844548779648636,
      "grad_norm": 3.1793675422668457,
      "learning_rate": 2.3524560660597078e-05,
      "loss": 1.3046,
      "step": 74100
    },
    {
      "epoch": 0.7855135215248702,
      "grad_norm": 3.12492299079895,
      "learning_rate": 2.3556320135507092e-05,
      "loss": 1.3142,
      "step": 74200
    },
    {
      "epoch": 0.7865721650848767,
      "grad_norm": 3.33727765083313,
      "learning_rate": 2.3588079610417107e-05,
      "loss": 1.3069,
      "step": 74300
    },
    {
      "epoch": 0.7876308086448833,
      "grad_norm": 3.075960636138916,
      "learning_rate": 2.361983908532712e-05,
      "loss": 1.311,
      "step": 74400
    },
    {
      "epoch": 0.7886894522048898,
      "grad_norm": 3.0762088298797607,
      "learning_rate": 2.3651598560237136e-05,
      "loss": 1.3096,
      "step": 74500
    },
    {
      "epoch": 0.7897480957648965,
      "grad_norm": 3.6421353816986084,
      "learning_rate": 2.368335803514715e-05,
      "loss": 1.3094,
      "step": 74600
    },
    {
      "epoch": 0.790806739324903,
      "grad_norm": 3.4640815258026123,
      "learning_rate": 2.3715117510057165e-05,
      "loss": 1.3074,
      "step": 74700
    },
    {
      "epoch": 0.7918653828849096,
      "grad_norm": 3.0746066570281982,
      "learning_rate": 2.374687698496718e-05,
      "loss": 1.3032,
      "step": 74800
    },
    {
      "epoch": 0.7929240264449161,
      "grad_norm": 3.3175582885742188,
      "learning_rate": 2.3778636459877194e-05,
      "loss": 1.3164,
      "step": 74900
    },
    {
      "epoch": 0.7939826700049227,
      "grad_norm": 3.0327229499816895,
      "learning_rate": 2.381039593478721e-05,
      "loss": 1.3117,
      "step": 75000
    },
    {
      "epoch": 0.7939826700049227,
      "eval_loss": 1.26753568649292,
      "eval_runtime": 57.2628,
      "eval_samples_per_second": 2932.619,
      "eval_steps_per_second": 366.59,
      "step": 75000
    },
    {
      "epoch": 0.7950413135649292,
      "grad_norm": 2.954766035079956,
      "learning_rate": 2.3842155409697223e-05,
      "loss": 1.3167,
      "step": 75100
    },
    {
      "epoch": 0.7960999571249359,
      "grad_norm": 3.0341508388519287,
      "learning_rate": 2.3873914884607238e-05,
      "loss": 1.3016,
      "step": 75200
    },
    {
      "epoch": 0.7971586006849424,
      "grad_norm": 3.121018171310425,
      "learning_rate": 2.3905674359517252e-05,
      "loss": 1.3015,
      "step": 75300
    },
    {
      "epoch": 0.798217244244949,
      "grad_norm": 3.119448184967041,
      "learning_rate": 2.3937433834427267e-05,
      "loss": 1.2958,
      "step": 75400
    },
    {
      "epoch": 0.7992758878049555,
      "grad_norm": 2.9554548263549805,
      "learning_rate": 2.396919330933728e-05,
      "loss": 1.2907,
      "step": 75500
    },
    {
      "epoch": 0.800334531364962,
      "grad_norm": 3.1539158821105957,
      "learning_rate": 2.40006351894982e-05,
      "loss": 1.3103,
      "step": 75600
    },
    {
      "epoch": 0.8013931749249686,
      "grad_norm": 3.520282030105591,
      "learning_rate": 2.4032394664408213e-05,
      "loss": 1.2893,
      "step": 75700
    },
    {
      "epoch": 0.8024518184849752,
      "grad_norm": 3.259535551071167,
      "learning_rate": 2.4064154139318227e-05,
      "loss": 1.3028,
      "step": 75800
    },
    {
      "epoch": 0.8035104620449818,
      "grad_norm": 3.400390148162842,
      "learning_rate": 2.4095913614228242e-05,
      "loss": 1.3082,
      "step": 75900
    },
    {
      "epoch": 0.8045691056049883,
      "grad_norm": 3.204735040664673,
      "learning_rate": 2.4127673089138256e-05,
      "loss": 1.2953,
      "step": 76000
    },
    {
      "epoch": 0.8045691056049883,
      "eval_loss": 1.2597354650497437,
      "eval_runtime": 57.3553,
      "eval_samples_per_second": 2927.89,
      "eval_steps_per_second": 365.999,
      "step": 76000
    },
    {
      "epoch": 0.8056277491649949,
      "grad_norm": 3.430039167404175,
      "learning_rate": 2.415943256404827e-05,
      "loss": 1.3101,
      "step": 76100
    },
    {
      "epoch": 0.8066863927250014,
      "grad_norm": 3.0436439514160156,
      "learning_rate": 2.4191192038958285e-05,
      "loss": 1.31,
      "step": 76200
    },
    {
      "epoch": 0.807745036285008,
      "grad_norm": 3.4316978454589844,
      "learning_rate": 2.42229515138683e-05,
      "loss": 1.3116,
      "step": 76300
    },
    {
      "epoch": 0.8088036798450146,
      "grad_norm": 3.229066848754883,
      "learning_rate": 2.4254710988778315e-05,
      "loss": 1.3029,
      "step": 76400
    },
    {
      "epoch": 0.8098623234050212,
      "grad_norm": 2.9960854053497314,
      "learning_rate": 2.428647046368833e-05,
      "loss": 1.3035,
      "step": 76500
    },
    {
      "epoch": 0.8109209669650277,
      "grad_norm": 3.4554672241210938,
      "learning_rate": 2.4318229938598344e-05,
      "loss": 1.2978,
      "step": 76600
    },
    {
      "epoch": 0.8119796105250343,
      "grad_norm": 3.40720796585083,
      "learning_rate": 2.434998941350836e-05,
      "loss": 1.3156,
      "step": 76700
    },
    {
      "epoch": 0.8130382540850408,
      "grad_norm": 3.1948275566101074,
      "learning_rate": 2.4381748888418376e-05,
      "loss": 1.2908,
      "step": 76800
    },
    {
      "epoch": 0.8140968976450474,
      "grad_norm": 3.2685365676879883,
      "learning_rate": 2.441350836332839e-05,
      "loss": 1.2859,
      "step": 76900
    },
    {
      "epoch": 0.815155541205054,
      "grad_norm": 3.476571798324585,
      "learning_rate": 2.4445267838238405e-05,
      "loss": 1.2937,
      "step": 77000
    },
    {
      "epoch": 0.815155541205054,
      "eval_loss": 1.252497911453247,
      "eval_runtime": 57.2301,
      "eval_samples_per_second": 2934.297,
      "eval_steps_per_second": 366.8,
      "step": 77000
    },
    {
      "epoch": 0.8162141847650606,
      "grad_norm": 3.539506196975708,
      "learning_rate": 2.447702731314842e-05,
      "loss": 1.2789,
      "step": 77100
    },
    {
      "epoch": 0.8172728283250671,
      "grad_norm": 3.1957216262817383,
      "learning_rate": 2.4508786788058434e-05,
      "loss": 1.3038,
      "step": 77200
    },
    {
      "epoch": 0.8183314718850736,
      "grad_norm": 3.5067129135131836,
      "learning_rate": 2.454054626296845e-05,
      "loss": 1.2975,
      "step": 77300
    },
    {
      "epoch": 0.8193901154450802,
      "grad_norm": 3.08699107170105,
      "learning_rate": 2.4572305737878463e-05,
      "loss": 1.3032,
      "step": 77400
    },
    {
      "epoch": 0.8204487590050867,
      "grad_norm": 3.008317232131958,
      "learning_rate": 2.4604065212788478e-05,
      "loss": 1.2929,
      "step": 77500
    },
    {
      "epoch": 0.8215074025650934,
      "grad_norm": 3.226249933242798,
      "learning_rate": 2.463550709294939e-05,
      "loss": 1.2845,
      "step": 77600
    },
    {
      "epoch": 0.8225660461250999,
      "grad_norm": 3.0570034980773926,
      "learning_rate": 2.4667266567859406e-05,
      "loss": 1.2836,
      "step": 77700
    },
    {
      "epoch": 0.8236246896851065,
      "grad_norm": 3.1017372608184814,
      "learning_rate": 2.469902604276942e-05,
      "loss": 1.2833,
      "step": 77800
    },
    {
      "epoch": 0.824683333245113,
      "grad_norm": 3.366913318634033,
      "learning_rate": 2.473078551767944e-05,
      "loss": 1.2731,
      "step": 77900
    },
    {
      "epoch": 0.8257419768051196,
      "grad_norm": 3.150143623352051,
      "learning_rate": 2.4762544992589453e-05,
      "loss": 1.283,
      "step": 78000
    },
    {
      "epoch": 0.8257419768051196,
      "eval_loss": 1.241665244102478,
      "eval_runtime": 57.3242,
      "eval_samples_per_second": 2929.478,
      "eval_steps_per_second": 366.198,
      "step": 78000
    },
    {
      "epoch": 0.8268006203651261,
      "grad_norm": 2.9962477684020996,
      "learning_rate": 2.4794304467499468e-05,
      "loss": 1.2919,
      "step": 78100
    },
    {
      "epoch": 0.8278592639251328,
      "grad_norm": 3.49747896194458,
      "learning_rate": 2.4826063942409485e-05,
      "loss": 1.285,
      "step": 78200
    },
    {
      "epoch": 0.8289179074851393,
      "grad_norm": 3.672255754470825,
      "learning_rate": 2.48578234173195e-05,
      "loss": 1.2885,
      "step": 78300
    },
    {
      "epoch": 0.8299765510451459,
      "grad_norm": 3.113089084625244,
      "learning_rate": 2.4889582892229514e-05,
      "loss": 1.2715,
      "step": 78400
    },
    {
      "epoch": 0.8310351946051524,
      "grad_norm": 3.160508155822754,
      "learning_rate": 2.492134236713953e-05,
      "loss": 1.2869,
      "step": 78500
    },
    {
      "epoch": 0.832093838165159,
      "grad_norm": 3.543044328689575,
      "learning_rate": 2.4953101842049544e-05,
      "loss": 1.2718,
      "step": 78600
    },
    {
      "epoch": 0.8331524817251655,
      "grad_norm": 3.1064629554748535,
      "learning_rate": 2.4984861316959558e-05,
      "loss": 1.2728,
      "step": 78700
    },
    {
      "epoch": 0.8342111252851722,
      "grad_norm": 3.869281530380249,
      "learning_rate": 2.5016620791869573e-05,
      "loss": 1.28,
      "step": 78800
    },
    {
      "epoch": 0.8352697688451787,
      "grad_norm": 3.0079307556152344,
      "learning_rate": 2.5048380266779587e-05,
      "loss": 1.2621,
      "step": 78900
    },
    {
      "epoch": 0.8363284124051852,
      "grad_norm": 3.2751572132110596,
      "learning_rate": 2.5080139741689605e-05,
      "loss": 1.2787,
      "step": 79000
    },
    {
      "epoch": 0.8363284124051852,
      "eval_loss": 1.232775330543518,
      "eval_runtime": 57.4146,
      "eval_samples_per_second": 2924.864,
      "eval_steps_per_second": 365.621,
      "step": 79000
    },
    {
      "epoch": 0.8373870559651918,
      "grad_norm": 3.3186490535736084,
      "learning_rate": 2.511189921659962e-05,
      "loss": 1.2882,
      "step": 79100
    },
    {
      "epoch": 0.8384456995251983,
      "grad_norm": 3.099370241165161,
      "learning_rate": 2.5143658691509634e-05,
      "loss": 1.2829,
      "step": 79200
    },
    {
      "epoch": 0.8395043430852049,
      "grad_norm": 3.1662800312042236,
      "learning_rate": 2.517541816641965e-05,
      "loss": 1.2597,
      "step": 79300
    },
    {
      "epoch": 0.8405629866452115,
      "grad_norm": 3.39658260345459,
      "learning_rate": 2.5207177641329663e-05,
      "loss": 1.2682,
      "step": 79400
    },
    {
      "epoch": 0.8416216302052181,
      "grad_norm": 3.26332950592041,
      "learning_rate": 2.5238937116239678e-05,
      "loss": 1.2808,
      "step": 79500
    },
    {
      "epoch": 0.8426802737652246,
      "grad_norm": 3.516483783721924,
      "learning_rate": 2.527037899640059e-05,
      "loss": 1.2777,
      "step": 79600
    },
    {
      "epoch": 0.8437389173252312,
      "grad_norm": 3.3145864009857178,
      "learning_rate": 2.5302138471310606e-05,
      "loss": 1.2627,
      "step": 79700
    },
    {
      "epoch": 0.8447975608852377,
      "grad_norm": 3.3995015621185303,
      "learning_rate": 2.533389794622062e-05,
      "loss": 1.2746,
      "step": 79800
    },
    {
      "epoch": 0.8458562044452443,
      "grad_norm": 3.4032766819000244,
      "learning_rate": 2.5365657421130635e-05,
      "loss": 1.2681,
      "step": 79900
    },
    {
      "epoch": 0.8469148480052509,
      "grad_norm": 3.47981858253479,
      "learning_rate": 2.539741689604065e-05,
      "loss": 1.2717,
      "step": 80000
    },
    {
      "epoch": 0.8469148480052509,
      "eval_loss": 1.2242116928100586,
      "eval_runtime": 57.3313,
      "eval_samples_per_second": 2929.115,
      "eval_steps_per_second": 366.152,
      "step": 80000
    },
    {
      "epoch": 0.8479734915652575,
      "grad_norm": 3.708961009979248,
      "learning_rate": 2.5429176370950664e-05,
      "loss": 1.2882,
      "step": 80100
    },
    {
      "epoch": 0.849032135125264,
      "grad_norm": 3.3856430053710938,
      "learning_rate": 2.5460935845860682e-05,
      "loss": 1.2796,
      "step": 80200
    },
    {
      "epoch": 0.8500907786852706,
      "grad_norm": 3.574439764022827,
      "learning_rate": 2.5492695320770696e-05,
      "loss": 1.2659,
      "step": 80300
    },
    {
      "epoch": 0.8511494222452771,
      "grad_norm": 3.408480167388916,
      "learning_rate": 2.552445479568071e-05,
      "loss": 1.2739,
      "step": 80400
    },
    {
      "epoch": 0.8522080658052837,
      "grad_norm": 3.7492496967315674,
      "learning_rate": 2.5556214270590726e-05,
      "loss": 1.2741,
      "step": 80500
    },
    {
      "epoch": 0.8532667093652903,
      "grad_norm": 3.2420125007629395,
      "learning_rate": 2.558797374550074e-05,
      "loss": 1.2668,
      "step": 80600
    },
    {
      "epoch": 0.8543253529252968,
      "grad_norm": 3.283381700515747,
      "learning_rate": 2.5619733220410755e-05,
      "loss": 1.2571,
      "step": 80700
    },
    {
      "epoch": 0.8553839964853034,
      "grad_norm": 3.8476336002349854,
      "learning_rate": 2.565149269532077e-05,
      "loss": 1.2524,
      "step": 80800
    },
    {
      "epoch": 0.8564426400453099,
      "grad_norm": 3.2198455333709717,
      "learning_rate": 2.5683252170230784e-05,
      "loss": 1.2683,
      "step": 80900
    },
    {
      "epoch": 0.8575012836053165,
      "grad_norm": 3.141784191131592,
      "learning_rate": 2.5715011645140798e-05,
      "loss": 1.2573,
      "step": 81000
    },
    {
      "epoch": 0.8575012836053165,
      "eval_loss": 1.215482234954834,
      "eval_runtime": 57.3647,
      "eval_samples_per_second": 2927.408,
      "eval_steps_per_second": 365.939,
      "step": 81000
    },
    {
      "epoch": 0.858559927165323,
      "grad_norm": 3.4721152782440186,
      "learning_rate": 2.5746771120050813e-05,
      "loss": 1.2581,
      "step": 81100
    },
    {
      "epoch": 0.8596185707253297,
      "grad_norm": 4.033484935760498,
      "learning_rate": 2.5778530594960827e-05,
      "loss": 1.2683,
      "step": 81200
    },
    {
      "epoch": 0.8606772142853362,
      "grad_norm": 3.501354217529297,
      "learning_rate": 2.581029006987084e-05,
      "loss": 1.2692,
      "step": 81300
    },
    {
      "epoch": 0.8617358578453428,
      "grad_norm": 3.3881404399871826,
      "learning_rate": 2.5842049544780856e-05,
      "loss": 1.2538,
      "step": 81400
    },
    {
      "epoch": 0.8627945014053493,
      "grad_norm": 3.4317853450775146,
      "learning_rate": 2.587380901969087e-05,
      "loss": 1.266,
      "step": 81500
    },
    {
      "epoch": 0.8638531449653559,
      "grad_norm": 3.1621949672698975,
      "learning_rate": 2.5905250899851788e-05,
      "loss": 1.2577,
      "step": 81600
    },
    {
      "epoch": 0.8649117885253624,
      "grad_norm": 3.514784097671509,
      "learning_rate": 2.5937010374761803e-05,
      "loss": 1.265,
      "step": 81700
    },
    {
      "epoch": 0.8659704320853691,
      "grad_norm": 3.4960899353027344,
      "learning_rate": 2.5968769849671817e-05,
      "loss": 1.2566,
      "step": 81800
    },
    {
      "epoch": 0.8670290756453756,
      "grad_norm": 3.423367738723755,
      "learning_rate": 2.600052932458183e-05,
      "loss": 1.2521,
      "step": 81900
    },
    {
      "epoch": 0.8680877192053822,
      "grad_norm": 3.8082730770111084,
      "learning_rate": 2.6032288799491846e-05,
      "loss": 1.2536,
      "step": 82000
    },
    {
      "epoch": 0.8680877192053822,
      "eval_loss": 1.2059706449508667,
      "eval_runtime": 57.2512,
      "eval_samples_per_second": 2933.215,
      "eval_steps_per_second": 366.665,
      "step": 82000
    },
    {
      "epoch": 0.8691463627653887,
      "grad_norm": 3.4479451179504395,
      "learning_rate": 2.606404827440186e-05,
      "loss": 1.2576,
      "step": 82100
    },
    {
      "epoch": 0.8702050063253953,
      "grad_norm": 3.592977285385132,
      "learning_rate": 2.6095807749311875e-05,
      "loss": 1.2427,
      "step": 82200
    },
    {
      "epoch": 0.8712636498854018,
      "grad_norm": 3.3857815265655518,
      "learning_rate": 2.612756722422189e-05,
      "loss": 1.247,
      "step": 82300
    },
    {
      "epoch": 0.8723222934454083,
      "grad_norm": 3.8312978744506836,
      "learning_rate": 2.6159326699131904e-05,
      "loss": 1.2538,
      "step": 82400
    },
    {
      "epoch": 0.873380937005415,
      "grad_norm": 3.4813241958618164,
      "learning_rate": 2.619108617404192e-05,
      "loss": 1.2399,
      "step": 82500
    },
    {
      "epoch": 0.8744395805654215,
      "grad_norm": 3.757582426071167,
      "learning_rate": 2.6222845648951933e-05,
      "loss": 1.251,
      "step": 82600
    },
    {
      "epoch": 0.8754982241254281,
      "grad_norm": 3.5756020545959473,
      "learning_rate": 2.6254605123861948e-05,
      "loss": 1.2598,
      "step": 82700
    },
    {
      "epoch": 0.8765568676854346,
      "grad_norm": 3.257559299468994,
      "learning_rate": 2.6286364598771966e-05,
      "loss": 1.2352,
      "step": 82800
    },
    {
      "epoch": 0.8776155112454412,
      "grad_norm": 3.6721115112304688,
      "learning_rate": 2.631812407368198e-05,
      "loss": 1.2534,
      "step": 82900
    },
    {
      "epoch": 0.8786741548054477,
      "grad_norm": 3.390477418899536,
      "learning_rate": 2.6349883548591995e-05,
      "loss": 1.2399,
      "step": 83000
    },
    {
      "epoch": 0.8786741548054477,
      "eval_loss": 1.1960781812667847,
      "eval_runtime": 57.2753,
      "eval_samples_per_second": 2931.979,
      "eval_steps_per_second": 366.51,
      "step": 83000
    },
    {
      "epoch": 0.8797327983654544,
      "grad_norm": 3.097989082336426,
      "learning_rate": 2.638164302350201e-05,
      "loss": 1.2428,
      "step": 83100
    },
    {
      "epoch": 0.8807914419254609,
      "grad_norm": 3.317772150039673,
      "learning_rate": 2.6413402498412024e-05,
      "loss": 1.2409,
      "step": 83200
    },
    {
      "epoch": 0.8818500854854675,
      "grad_norm": 3.3871631622314453,
      "learning_rate": 2.6445161973322038e-05,
      "loss": 1.2431,
      "step": 83300
    },
    {
      "epoch": 0.882908729045474,
      "grad_norm": 3.4753410816192627,
      "learning_rate": 2.6476921448232053e-05,
      "loss": 1.2359,
      "step": 83400
    },
    {
      "epoch": 0.8839673726054806,
      "grad_norm": 3.445721387863159,
      "learning_rate": 2.6508680923142067e-05,
      "loss": 1.239,
      "step": 83500
    },
    {
      "epoch": 0.8850260161654872,
      "grad_norm": 3.7156453132629395,
      "learning_rate": 2.654012280330298e-05,
      "loss": 1.2458,
      "step": 83600
    },
    {
      "epoch": 0.8860846597254938,
      "grad_norm": 3.5644888877868652,
      "learning_rate": 2.6571882278212996e-05,
      "loss": 1.2412,
      "step": 83700
    },
    {
      "epoch": 0.8871433032855003,
      "grad_norm": 3.749098062515259,
      "learning_rate": 2.660364175312301e-05,
      "loss": 1.2432,
      "step": 83800
    },
    {
      "epoch": 0.8882019468455069,
      "grad_norm": 3.4937667846679688,
      "learning_rate": 2.6635401228033028e-05,
      "loss": 1.2449,
      "step": 83900
    },
    {
      "epoch": 0.8892605904055134,
      "grad_norm": 3.5231661796569824,
      "learning_rate": 2.6667160702943043e-05,
      "loss": 1.2479,
      "step": 84000
    },
    {
      "epoch": 0.8892605904055134,
      "eval_loss": 1.180823802947998,
      "eval_runtime": 57.2774,
      "eval_samples_per_second": 2931.873,
      "eval_steps_per_second": 366.497,
      "step": 84000
    },
    {
      "epoch": 0.8903192339655199,
      "grad_norm": 3.3317465782165527,
      "learning_rate": 2.6698920177853057e-05,
      "loss": 1.2565,
      "step": 84100
    },
    {
      "epoch": 0.8913778775255266,
      "grad_norm": 3.673921823501587,
      "learning_rate": 2.673067965276307e-05,
      "loss": 1.244,
      "step": 84200
    },
    {
      "epoch": 0.8924365210855331,
      "grad_norm": 3.517810583114624,
      "learning_rate": 2.6762439127673086e-05,
      "loss": 1.2316,
      "step": 84300
    },
    {
      "epoch": 0.8934951646455397,
      "grad_norm": 3.6165525913238525,
      "learning_rate": 2.67941986025831e-05,
      "loss": 1.2292,
      "step": 84400
    },
    {
      "epoch": 0.8945538082055462,
      "grad_norm": 3.447279691696167,
      "learning_rate": 2.6825958077493115e-05,
      "loss": 1.236,
      "step": 84500
    },
    {
      "epoch": 0.8956124517655528,
      "grad_norm": 3.753221035003662,
      "learning_rate": 2.685771755240313e-05,
      "loss": 1.2446,
      "step": 84600
    },
    {
      "epoch": 0.8966710953255593,
      "grad_norm": 3.514037847518921,
      "learning_rate": 2.6889477027313144e-05,
      "loss": 1.2374,
      "step": 84700
    },
    {
      "epoch": 0.897729738885566,
      "grad_norm": 3.604767322540283,
      "learning_rate": 2.692123650222316e-05,
      "loss": 1.2285,
      "step": 84800
    },
    {
      "epoch": 0.8987883824455725,
      "grad_norm": 3.7282981872558594,
      "learning_rate": 2.6952995977133173e-05,
      "loss": 1.2389,
      "step": 84900
    },
    {
      "epoch": 0.8998470260055791,
      "grad_norm": 3.3988757133483887,
      "learning_rate": 2.6984755452043188e-05,
      "loss": 1.2199,
      "step": 85000
    },
    {
      "epoch": 0.8998470260055791,
      "eval_loss": 1.1742862462997437,
      "eval_runtime": 57.3343,
      "eval_samples_per_second": 2928.964,
      "eval_steps_per_second": 366.134,
      "step": 85000
    },
    {
      "epoch": 0.9009056695655856,
      "grad_norm": 3.6656172275543213,
      "learning_rate": 2.7016514926953202e-05,
      "loss": 1.2257,
      "step": 85100
    },
    {
      "epoch": 0.9019643131255922,
      "grad_norm": 3.832108736038208,
      "learning_rate": 2.7048274401863224e-05,
      "loss": 1.2385,
      "step": 85200
    },
    {
      "epoch": 0.9030229566855987,
      "grad_norm": 3.8343565464019775,
      "learning_rate": 2.7080033876773238e-05,
      "loss": 1.227,
      "step": 85300
    },
    {
      "epoch": 0.9040816002456054,
      "grad_norm": 3.5588531494140625,
      "learning_rate": 2.7111793351683253e-05,
      "loss": 1.2382,
      "step": 85400
    },
    {
      "epoch": 0.9051402438056119,
      "grad_norm": 3.5559277534484863,
      "learning_rate": 2.7143552826593267e-05,
      "loss": 1.2243,
      "step": 85500
    },
    {
      "epoch": 0.9061988873656185,
      "grad_norm": 3.428884744644165,
      "learning_rate": 2.7174994706754178e-05,
      "loss": 1.2218,
      "step": 85600
    },
    {
      "epoch": 0.907257530925625,
      "grad_norm": 3.626616954803467,
      "learning_rate": 2.7206754181664192e-05,
      "loss": 1.229,
      "step": 85700
    },
    {
      "epoch": 0.9083161744856315,
      "grad_norm": 4.135260105133057,
      "learning_rate": 2.723851365657421e-05,
      "loss": 1.2183,
      "step": 85800
    },
    {
      "epoch": 0.9093748180456381,
      "grad_norm": 3.7864930629730225,
      "learning_rate": 2.7270273131484225e-05,
      "loss": 1.2252,
      "step": 85900
    },
    {
      "epoch": 0.9104334616056446,
      "grad_norm": 3.7974650859832764,
      "learning_rate": 2.730203260639424e-05,
      "loss": 1.2117,
      "step": 86000
    },
    {
      "epoch": 0.9104334616056446,
      "eval_loss": 1.160165786743164,
      "eval_runtime": 57.3145,
      "eval_samples_per_second": 2929.975,
      "eval_steps_per_second": 366.26,
      "step": 86000
    },
    {
      "epoch": 0.9114921051656513,
      "grad_norm": 3.606891632080078,
      "learning_rate": 2.7333792081304254e-05,
      "loss": 1.2276,
      "step": 86100
    },
    {
      "epoch": 0.9125507487256578,
      "grad_norm": 3.6927151679992676,
      "learning_rate": 2.736555155621427e-05,
      "loss": 1.2296,
      "step": 86200
    },
    {
      "epoch": 0.9136093922856644,
      "grad_norm": 4.016897678375244,
      "learning_rate": 2.7397311031124286e-05,
      "loss": 1.2408,
      "step": 86300
    },
    {
      "epoch": 0.9146680358456709,
      "grad_norm": 3.8065505027770996,
      "learning_rate": 2.74290705060343e-05,
      "loss": 1.2122,
      "step": 86400
    },
    {
      "epoch": 0.9157266794056775,
      "grad_norm": 3.8467674255371094,
      "learning_rate": 2.7460829980944315e-05,
      "loss": 1.2198,
      "step": 86500
    },
    {
      "epoch": 0.916785322965684,
      "grad_norm": 3.922337532043457,
      "learning_rate": 2.749258945585433e-05,
      "loss": 1.2213,
      "step": 86600
    },
    {
      "epoch": 0.9178439665256907,
      "grad_norm": 3.682422161102295,
      "learning_rate": 2.7524348930764344e-05,
      "loss": 1.218,
      "step": 86700
    },
    {
      "epoch": 0.9189026100856972,
      "grad_norm": 3.854142665863037,
      "learning_rate": 2.755610840567436e-05,
      "loss": 1.2299,
      "step": 86800
    },
    {
      "epoch": 0.9199612536457038,
      "grad_norm": 3.6091158390045166,
      "learning_rate": 2.7587867880584373e-05,
      "loss": 1.2215,
      "step": 86900
    },
    {
      "epoch": 0.9210198972057103,
      "grad_norm": 3.503811836242676,
      "learning_rate": 2.7619627355494388e-05,
      "loss": 1.2134,
      "step": 87000
    },
    {
      "epoch": 0.9210198972057103,
      "eval_loss": 1.153009295463562,
      "eval_runtime": 57.317,
      "eval_samples_per_second": 2929.847,
      "eval_steps_per_second": 366.244,
      "step": 87000
    },
    {
      "epoch": 0.9220785407657169,
      "grad_norm": 3.719420909881592,
      "learning_rate": 2.7651386830404402e-05,
      "loss": 1.213,
      "step": 87100
    },
    {
      "epoch": 0.9231371843257234,
      "grad_norm": 3.7311606407165527,
      "learning_rate": 2.7683146305314417e-05,
      "loss": 1.2115,
      "step": 87200
    },
    {
      "epoch": 0.92419582788573,
      "grad_norm": 3.380248785018921,
      "learning_rate": 2.771490578022443e-05,
      "loss": 1.2086,
      "step": 87300
    },
    {
      "epoch": 0.9252544714457366,
      "grad_norm": 3.4072718620300293,
      "learning_rate": 2.7746665255134446e-05,
      "loss": 1.2077,
      "step": 87400
    },
    {
      "epoch": 0.9263131150057431,
      "grad_norm": 3.8594918251037598,
      "learning_rate": 2.777842473004446e-05,
      "loss": 1.2009,
      "step": 87500
    },
    {
      "epoch": 0.9273717585657497,
      "grad_norm": 3.444807767868042,
      "learning_rate": 2.7809866610205378e-05,
      "loss": 1.2091,
      "step": 87600
    },
    {
      "epoch": 0.9284304021257562,
      "grad_norm": 3.7361414432525635,
      "learning_rate": 2.7841626085115392e-05,
      "loss": 1.213,
      "step": 87700
    },
    {
      "epoch": 0.9294890456857628,
      "grad_norm": 4.116249084472656,
      "learning_rate": 2.7873385560025407e-05,
      "loss": 1.211,
      "step": 87800
    },
    {
      "epoch": 0.9305476892457694,
      "grad_norm": 3.8563461303710938,
      "learning_rate": 2.790514503493542e-05,
      "loss": 1.2155,
      "step": 87900
    },
    {
      "epoch": 0.931606332805776,
      "grad_norm": 4.004701137542725,
      "learning_rate": 2.7936904509845436e-05,
      "loss": 1.2033,
      "step": 88000
    },
    {
      "epoch": 0.931606332805776,
      "eval_loss": 1.141735553741455,
      "eval_runtime": 57.3234,
      "eval_samples_per_second": 2929.521,
      "eval_steps_per_second": 366.203,
      "step": 88000
    },
    {
      "epoch": 0.9326649763657825,
      "grad_norm": 3.699840545654297,
      "learning_rate": 2.796866398475545e-05,
      "loss": 1.2016,
      "step": 88100
    },
    {
      "epoch": 0.9337236199257891,
      "grad_norm": 3.7672364711761475,
      "learning_rate": 2.8000423459665465e-05,
      "loss": 1.2177,
      "step": 88200
    },
    {
      "epoch": 0.9347822634857956,
      "grad_norm": 3.749626636505127,
      "learning_rate": 2.803218293457548e-05,
      "loss": 1.1975,
      "step": 88300
    },
    {
      "epoch": 0.9358409070458023,
      "grad_norm": 4.012855052947998,
      "learning_rate": 2.8063942409485494e-05,
      "loss": 1.2125,
      "step": 88400
    },
    {
      "epoch": 0.9368995506058088,
      "grad_norm": 3.838444232940674,
      "learning_rate": 2.809570188439551e-05,
      "loss": 1.2008,
      "step": 88500
    },
    {
      "epoch": 0.9379581941658154,
      "grad_norm": 3.6298024654388428,
      "learning_rate": 2.8127461359305523e-05,
      "loss": 1.1987,
      "step": 88600
    },
    {
      "epoch": 0.9390168377258219,
      "grad_norm": 3.7474253177642822,
      "learning_rate": 2.8159220834215537e-05,
      "loss": 1.1823,
      "step": 88700
    },
    {
      "epoch": 0.9400754812858285,
      "grad_norm": 3.4961161613464355,
      "learning_rate": 2.8190980309125552e-05,
      "loss": 1.2012,
      "step": 88800
    },
    {
      "epoch": 0.941134124845835,
      "grad_norm": 3.8217201232910156,
      "learning_rate": 2.822273978403557e-05,
      "loss": 1.2051,
      "step": 88900
    },
    {
      "epoch": 0.9421927684058415,
      "grad_norm": 3.7767088413238525,
      "learning_rate": 2.8254499258945584e-05,
      "loss": 1.1956,
      "step": 89000
    },
    {
      "epoch": 0.9421927684058415,
      "eval_loss": 1.1301716566085815,
      "eval_runtime": 57.278,
      "eval_samples_per_second": 2931.844,
      "eval_steps_per_second": 366.494,
      "step": 89000
    },
    {
      "epoch": 0.9432514119658482,
      "grad_norm": 3.501020669937134,
      "learning_rate": 2.82862587338556e-05,
      "loss": 1.1937,
      "step": 89100
    },
    {
      "epoch": 0.9443100555258547,
      "grad_norm": 4.11027717590332,
      "learning_rate": 2.8318018208765613e-05,
      "loss": 1.2032,
      "step": 89200
    },
    {
      "epoch": 0.9453686990858613,
      "grad_norm": 3.8079800605773926,
      "learning_rate": 2.8349777683675628e-05,
      "loss": 1.1999,
      "step": 89300
    },
    {
      "epoch": 0.9464273426458678,
      "grad_norm": 3.5300090312957764,
      "learning_rate": 2.8381537158585642e-05,
      "loss": 1.1981,
      "step": 89400
    },
    {
      "epoch": 0.9474859862058744,
      "grad_norm": 4.135409355163574,
      "learning_rate": 2.8413296633495657e-05,
      "loss": 1.1805,
      "step": 89500
    },
    {
      "epoch": 0.9485446297658809,
      "grad_norm": 3.966752290725708,
      "learning_rate": 2.844473851365657e-05,
      "loss": 1.1845,
      "step": 89600
    },
    {
      "epoch": 0.9496032733258876,
      "grad_norm": 3.7899277210235596,
      "learning_rate": 2.8476497988566585e-05,
      "loss": 1.1858,
      "step": 89700
    },
    {
      "epoch": 0.9506619168858941,
      "grad_norm": 3.7146189212799072,
      "learning_rate": 2.85082574634766e-05,
      "loss": 1.2031,
      "step": 89800
    },
    {
      "epoch": 0.9517205604459007,
      "grad_norm": 4.016342639923096,
      "learning_rate": 2.8540016938386614e-05,
      "loss": 1.1975,
      "step": 89900
    },
    {
      "epoch": 0.9527792040059072,
      "grad_norm": 4.171584606170654,
      "learning_rate": 2.8571776413296632e-05,
      "loss": 1.1962,
      "step": 90000
    },
    {
      "epoch": 0.9527792040059072,
      "eval_loss": 1.1172349452972412,
      "eval_runtime": 57.3395,
      "eval_samples_per_second": 2928.696,
      "eval_steps_per_second": 366.1,
      "step": 90000
    },
    {
      "epoch": 0.9538378475659138,
      "grad_norm": 3.9805893898010254,
      "learning_rate": 2.8603535888206647e-05,
      "loss": 1.1979,
      "step": 90100
    },
    {
      "epoch": 0.9548964911259203,
      "grad_norm": 4.154830455780029,
      "learning_rate": 2.863529536311666e-05,
      "loss": 1.2031,
      "step": 90200
    },
    {
      "epoch": 0.955955134685927,
      "grad_norm": 4.444653034210205,
      "learning_rate": 2.8667054838026676e-05,
      "loss": 1.1774,
      "step": 90300
    },
    {
      "epoch": 0.9570137782459335,
      "grad_norm": 4.072654724121094,
      "learning_rate": 2.869881431293669e-05,
      "loss": 1.1918,
      "step": 90400
    },
    {
      "epoch": 0.9580724218059401,
      "grad_norm": 3.540271043777466,
      "learning_rate": 2.8730573787846705e-05,
      "loss": 1.1754,
      "step": 90500
    },
    {
      "epoch": 0.9591310653659466,
      "grad_norm": 4.326841831207275,
      "learning_rate": 2.876233326275672e-05,
      "loss": 1.1683,
      "step": 90600
    },
    {
      "epoch": 0.9601897089259531,
      "grad_norm": 3.527097225189209,
      "learning_rate": 2.8794092737666734e-05,
      "loss": 1.1868,
      "step": 90700
    },
    {
      "epoch": 0.9612483524859597,
      "grad_norm": 3.8024470806121826,
      "learning_rate": 2.882585221257675e-05,
      "loss": 1.1868,
      "step": 90800
    },
    {
      "epoch": 0.9623069960459663,
      "grad_norm": 4.062926292419434,
      "learning_rate": 2.8857611687486763e-05,
      "loss": 1.1923,
      "step": 90900
    },
    {
      "epoch": 0.9633656396059729,
      "grad_norm": 4.032966136932373,
      "learning_rate": 2.8889371162396777e-05,
      "loss": 1.1824,
      "step": 91000
    },
    {
      "epoch": 0.9633656396059729,
      "eval_loss": 1.1109365224838257,
      "eval_runtime": 57.3102,
      "eval_samples_per_second": 2930.195,
      "eval_steps_per_second": 366.288,
      "step": 91000
    },
    {
      "epoch": 0.9644242831659794,
      "grad_norm": 3.8287553787231445,
      "learning_rate": 2.8921130637306792e-05,
      "loss": 1.1728,
      "step": 91100
    },
    {
      "epoch": 0.965482926725986,
      "grad_norm": 3.8963842391967773,
      "learning_rate": 2.8952890112216806e-05,
      "loss": 1.19,
      "step": 91200
    },
    {
      "epoch": 0.9665415702859925,
      "grad_norm": 3.758789300918579,
      "learning_rate": 2.898464958712682e-05,
      "loss": 1.1766,
      "step": 91300
    },
    {
      "epoch": 0.9676002138459991,
      "grad_norm": 4.102102756500244,
      "learning_rate": 2.9016409062036836e-05,
      "loss": 1.1708,
      "step": 91400
    },
    {
      "epoch": 0.9686588574060057,
      "grad_norm": 4.5309295654296875,
      "learning_rate": 2.904816853694685e-05,
      "loss": 1.1752,
      "step": 91500
    },
    {
      "epoch": 0.9697175009660123,
      "grad_norm": 3.839611530303955,
      "learning_rate": 2.9079610417107767e-05,
      "loss": 1.164,
      "step": 91600
    },
    {
      "epoch": 0.9707761445260188,
      "grad_norm": 3.9529953002929688,
      "learning_rate": 2.9111369892017782e-05,
      "loss": 1.1766,
      "step": 91700
    },
    {
      "epoch": 0.9718347880860254,
      "grad_norm": 3.7661356925964355,
      "learning_rate": 2.9143129366927796e-05,
      "loss": 1.1679,
      "step": 91800
    },
    {
      "epoch": 0.9728934316460319,
      "grad_norm": 4.096357345581055,
      "learning_rate": 2.917488884183781e-05,
      "loss": 1.1656,
      "step": 91900
    },
    {
      "epoch": 0.9739520752060385,
      "grad_norm": 3.783783435821533,
      "learning_rate": 2.9206648316747825e-05,
      "loss": 1.1824,
      "step": 92000
    },
    {
      "epoch": 0.9739520752060385,
      "eval_loss": 1.0924533605575562,
      "eval_runtime": 57.1835,
      "eval_samples_per_second": 2936.684,
      "eval_steps_per_second": 367.099,
      "step": 92000
    },
    {
      "epoch": 0.9750107187660451,
      "grad_norm": 4.270987510681152,
      "learning_rate": 2.923840779165784e-05,
      "loss": 1.1574,
      "step": 92100
    },
    {
      "epoch": 0.9760693623260517,
      "grad_norm": 4.013551712036133,
      "learning_rate": 2.9270167266567854e-05,
      "loss": 1.1677,
      "step": 92200
    },
    {
      "epoch": 0.9771280058860582,
      "grad_norm": 3.9858791828155518,
      "learning_rate": 2.930192674147787e-05,
      "loss": 1.1703,
      "step": 92300
    },
    {
      "epoch": 0.9781866494460647,
      "grad_norm": 4.124390602111816,
      "learning_rate": 2.9333686216387884e-05,
      "loss": 1.1659,
      "step": 92400
    },
    {
      "epoch": 0.9792452930060713,
      "grad_norm": 4.110015392303467,
      "learning_rate": 2.9365445691297898e-05,
      "loss": 1.1698,
      "step": 92500
    },
    {
      "epoch": 0.9803039365660778,
      "grad_norm": 4.138877868652344,
      "learning_rate": 2.9397205166207913e-05,
      "loss": 1.156,
      "step": 92600
    },
    {
      "epoch": 0.9813625801260845,
      "grad_norm": 4.141030788421631,
      "learning_rate": 2.942896464111793e-05,
      "loss": 1.1713,
      "step": 92700
    },
    {
      "epoch": 0.982421223686091,
      "grad_norm": 4.017240524291992,
      "learning_rate": 2.946072411602795e-05,
      "loss": 1.1542,
      "step": 92800
    },
    {
      "epoch": 0.9834798672460976,
      "grad_norm": 3.8701162338256836,
      "learning_rate": 2.9492483590937963e-05,
      "loss": 1.1562,
      "step": 92900
    },
    {
      "epoch": 0.9845385108061041,
      "grad_norm": 4.20713472366333,
      "learning_rate": 2.9524243065847977e-05,
      "loss": 1.1475,
      "step": 93000
    },
    {
      "epoch": 0.9845385108061041,
      "eval_loss": 1.0785987377166748,
      "eval_runtime": 57.3829,
      "eval_samples_per_second": 2926.48,
      "eval_steps_per_second": 365.823,
      "step": 93000
    },
    {
      "epoch": 0.9855971543661107,
      "grad_norm": 3.540471076965332,
      "learning_rate": 2.9556002540757992e-05,
      "loss": 1.149,
      "step": 93100
    },
    {
      "epoch": 0.9866557979261172,
      "grad_norm": 3.92739200592041,
      "learning_rate": 2.9587762015668006e-05,
      "loss": 1.1576,
      "step": 93200
    },
    {
      "epoch": 0.9877144414861239,
      "grad_norm": 3.9309303760528564,
      "learning_rate": 2.961952149057802e-05,
      "loss": 1.1602,
      "step": 93300
    },
    {
      "epoch": 0.9887730850461304,
      "grad_norm": 3.955430507659912,
      "learning_rate": 2.9651280965488035e-05,
      "loss": 1.1472,
      "step": 93400
    },
    {
      "epoch": 0.989831728606137,
      "grad_norm": 4.095554351806641,
      "learning_rate": 2.968304044039805e-05,
      "loss": 1.1678,
      "step": 93500
    },
    {
      "epoch": 0.9908903721661435,
      "grad_norm": 4.125962257385254,
      "learning_rate": 2.9714482320558967e-05,
      "loss": 1.1752,
      "step": 93600
    },
    {
      "epoch": 0.9919490157261501,
      "grad_norm": 4.257472038269043,
      "learning_rate": 2.9746241795468982e-05,
      "loss": 1.1598,
      "step": 93700
    },
    {
      "epoch": 0.9930076592861566,
      "grad_norm": 4.179004192352295,
      "learning_rate": 2.9778001270378996e-05,
      "loss": 1.1499,
      "step": 93800
    },
    {
      "epoch": 0.9940663028461633,
      "grad_norm": 4.044746398925781,
      "learning_rate": 2.980976074528901e-05,
      "loss": 1.1423,
      "step": 93900
    },
    {
      "epoch": 0.9951249464061698,
      "grad_norm": 3.83176851272583,
      "learning_rate": 2.9841520220199025e-05,
      "loss": 1.1533,
      "step": 94000
    },
    {
      "epoch": 0.9951249464061698,
      "eval_loss": 1.0699492692947388,
      "eval_runtime": 57.3755,
      "eval_samples_per_second": 2926.861,
      "eval_steps_per_second": 365.871,
      "step": 94000
    },
    {
      "epoch": 0.9961835899661763,
      "grad_norm": 3.8582379817962646,
      "learning_rate": 2.987327969510904e-05,
      "loss": 1.1475,
      "step": 94100
    },
    {
      "epoch": 0.9972422335261829,
      "grad_norm": 3.6446728706359863,
      "learning_rate": 2.9905039170019054e-05,
      "loss": 1.1471,
      "step": 94200
    },
    {
      "epoch": 0.9983008770861894,
      "grad_norm": 4.076566219329834,
      "learning_rate": 2.993679864492907e-05,
      "loss": 1.1246,
      "step": 94300
    },
    {
      "epoch": 0.999359520646196,
      "grad_norm": 4.549073696136475,
      "learning_rate": 2.9968558119839083e-05,
      "loss": 1.1492,
      "step": 94400
    },
    {
      "epoch": 1.0004128709884026,
      "grad_norm": 4.265600681304932,
      "learning_rate": 3.0000317594749098e-05,
      "loss": 1.14,
      "step": 94500
    },
    {
      "epoch": 1.0014715145484092,
      "grad_norm": 4.352781772613525,
      "learning_rate": 3.0032077069659112e-05,
      "loss": 1.1315,
      "step": 94600
    },
    {
      "epoch": 1.0025301581084156,
      "grad_norm": 4.358912944793701,
      "learning_rate": 3.0063836544569127e-05,
      "loss": 1.1352,
      "step": 94700
    },
    {
      "epoch": 1.0035888016684222,
      "grad_norm": 3.918459415435791,
      "learning_rate": 3.009559601947914e-05,
      "loss": 1.1311,
      "step": 94800
    },
    {
      "epoch": 1.0046474452284289,
      "grad_norm": 4.126499176025391,
      "learning_rate": 3.0127355494389156e-05,
      "loss": 1.1207,
      "step": 94900
    },
    {
      "epoch": 1.0057060887884355,
      "grad_norm": 3.9792256355285645,
      "learning_rate": 3.0159114969299174e-05,
      "loss": 1.1482,
      "step": 95000
    },
    {
      "epoch": 1.0057060887884355,
      "eval_loss": 1.0589828491210938,
      "eval_runtime": 57.2685,
      "eval_samples_per_second": 2932.326,
      "eval_steps_per_second": 366.554,
      "step": 95000
    },
    {
      "epoch": 1.0067647323484419,
      "grad_norm": 3.908627510070801,
      "learning_rate": 3.019087444420919e-05,
      "loss": 1.1311,
      "step": 95100
    },
    {
      "epoch": 1.0078233759084485,
      "grad_norm": 4.361867427825928,
      "learning_rate": 3.0222633919119203e-05,
      "loss": 1.1378,
      "step": 95200
    },
    {
      "epoch": 1.0088820194684551,
      "grad_norm": 4.079878330230713,
      "learning_rate": 3.0254393394029217e-05,
      "loss": 1.1282,
      "step": 95300
    },
    {
      "epoch": 1.0099406630284615,
      "grad_norm": 4.301836013793945,
      "learning_rate": 3.0286152868939232e-05,
      "loss": 1.1245,
      "step": 95400
    },
    {
      "epoch": 1.0109993065884681,
      "grad_norm": 4.030653953552246,
      "learning_rate": 3.0317912343849247e-05,
      "loss": 1.1302,
      "step": 95500
    },
    {
      "epoch": 1.0120579501484748,
      "grad_norm": 4.530422687530518,
      "learning_rate": 3.034935422401016e-05,
      "loss": 1.1325,
      "step": 95600
    },
    {
      "epoch": 1.0131165937084814,
      "grad_norm": 4.379424571990967,
      "learning_rate": 3.0381113698920175e-05,
      "loss": 1.1297,
      "step": 95700
    },
    {
      "epoch": 1.0141752372684878,
      "grad_norm": 4.231831073760986,
      "learning_rate": 3.041287317383019e-05,
      "loss": 1.123,
      "step": 95800
    },
    {
      "epoch": 1.0152338808284944,
      "grad_norm": 4.23319673538208,
      "learning_rate": 3.0444632648740204e-05,
      "loss": 1.134,
      "step": 95900
    },
    {
      "epoch": 1.016292524388501,
      "grad_norm": 4.326900482177734,
      "learning_rate": 3.047639212365022e-05,
      "loss": 1.1284,
      "step": 96000
    },
    {
      "epoch": 1.016292524388501,
      "eval_loss": 1.0468981266021729,
      "eval_runtime": 57.2654,
      "eval_samples_per_second": 2932.488,
      "eval_steps_per_second": 366.574,
      "step": 96000
    },
    {
      "epoch": 1.0173511679485077,
      "grad_norm": 3.6222665309906006,
      "learning_rate": 3.0508151598560236e-05,
      "loss": 1.1213,
      "step": 96100
    },
    {
      "epoch": 1.018409811508514,
      "grad_norm": 3.9487850666046143,
      "learning_rate": 3.053991107347025e-05,
      "loss": 1.1292,
      "step": 96200
    },
    {
      "epoch": 1.0194684550685207,
      "grad_norm": 3.947748899459839,
      "learning_rate": 3.0571670548380265e-05,
      "loss": 1.1216,
      "step": 96300
    },
    {
      "epoch": 1.0205270986285273,
      "grad_norm": 3.779433250427246,
      "learning_rate": 3.0603430023290277e-05,
      "loss": 1.1233,
      "step": 96400
    },
    {
      "epoch": 1.021585742188534,
      "grad_norm": 4.574626922607422,
      "learning_rate": 3.0635189498200295e-05,
      "loss": 1.1275,
      "step": 96500
    },
    {
      "epoch": 1.0226443857485403,
      "grad_norm": 4.167384624481201,
      "learning_rate": 3.0666948973110306e-05,
      "loss": 1.1226,
      "step": 96600
    },
    {
      "epoch": 1.023703029308547,
      "grad_norm": 4.4685235023498535,
      "learning_rate": 3.0698708448020324e-05,
      "loss": 1.1126,
      "step": 96700
    },
    {
      "epoch": 1.0247616728685536,
      "grad_norm": 4.295376777648926,
      "learning_rate": 3.0730467922930335e-05,
      "loss": 1.1107,
      "step": 96800
    },
    {
      "epoch": 1.0258203164285602,
      "grad_norm": 4.312382698059082,
      "learning_rate": 3.076222739784035e-05,
      "loss": 1.1246,
      "step": 96900
    },
    {
      "epoch": 1.0268789599885666,
      "grad_norm": 3.9906742572784424,
      "learning_rate": 3.079398687275037e-05,
      "loss": 1.1222,
      "step": 97000
    },
    {
      "epoch": 1.0268789599885666,
      "eval_loss": 1.031229853630066,
      "eval_runtime": 57.2659,
      "eval_samples_per_second": 2932.462,
      "eval_steps_per_second": 366.571,
      "step": 97000
    },
    {
      "epoch": 1.0279376035485732,
      "grad_norm": 4.358361721038818,
      "learning_rate": 3.082574634766038e-05,
      "loss": 1.1136,
      "step": 97100
    },
    {
      "epoch": 1.0289962471085798,
      "grad_norm": 4.2570319175720215,
      "learning_rate": 3.08575058225704e-05,
      "loss": 1.112,
      "step": 97200
    },
    {
      "epoch": 1.0300548906685862,
      "grad_norm": 4.543858051300049,
      "learning_rate": 3.088926529748041e-05,
      "loss": 1.1116,
      "step": 97300
    },
    {
      "epoch": 1.0311135342285929,
      "grad_norm": 4.038743019104004,
      "learning_rate": 3.092102477239043e-05,
      "loss": 1.116,
      "step": 97400
    },
    {
      "epoch": 1.0321721777885995,
      "grad_norm": 3.997115135192871,
      "learning_rate": 3.095278424730044e-05,
      "loss": 1.1204,
      "step": 97500
    },
    {
      "epoch": 1.033230821348606,
      "grad_norm": 4.336056232452393,
      "learning_rate": 3.0984226127461354e-05,
      "loss": 1.1333,
      "step": 97600
    },
    {
      "epoch": 1.0342894649086125,
      "grad_norm": 4.213796138763428,
      "learning_rate": 3.101598560237137e-05,
      "loss": 1.1115,
      "step": 97700
    },
    {
      "epoch": 1.0353481084686191,
      "grad_norm": 4.1369428634643555,
      "learning_rate": 3.104774507728138e-05,
      "loss": 1.1058,
      "step": 97800
    },
    {
      "epoch": 1.0364067520286258,
      "grad_norm": 4.260287284851074,
      "learning_rate": 3.10795045521914e-05,
      "loss": 1.1113,
      "step": 97900
    },
    {
      "epoch": 1.0374653955886324,
      "grad_norm": 4.214170455932617,
      "learning_rate": 3.111126402710142e-05,
      "loss": 1.1151,
      "step": 98000
    },
    {
      "epoch": 1.0374653955886324,
      "eval_loss": 1.0198001861572266,
      "eval_runtime": 57.431,
      "eval_samples_per_second": 2924.032,
      "eval_steps_per_second": 365.517,
      "step": 98000
    },
    {
      "epoch": 1.0385240391486388,
      "grad_norm": 4.822520732879639,
      "learning_rate": 3.114302350201143e-05,
      "loss": 1.1106,
      "step": 98100
    },
    {
      "epoch": 1.0395826827086454,
      "grad_norm": 4.441433429718018,
      "learning_rate": 3.117478297692145e-05,
      "loss": 1.1102,
      "step": 98200
    },
    {
      "epoch": 1.040641326268652,
      "grad_norm": 4.331331729888916,
      "learning_rate": 3.120654245183146e-05,
      "loss": 1.0911,
      "step": 98300
    },
    {
      "epoch": 1.0416999698286586,
      "grad_norm": 3.9763107299804688,
      "learning_rate": 3.1238301926741477e-05,
      "loss": 1.112,
      "step": 98400
    },
    {
      "epoch": 1.042758613388665,
      "grad_norm": 4.392089366912842,
      "learning_rate": 3.127006140165149e-05,
      "loss": 1.1127,
      "step": 98500
    },
    {
      "epoch": 1.0438172569486717,
      "grad_norm": 4.52116060256958,
      "learning_rate": 3.1301820876561506e-05,
      "loss": 1.0993,
      "step": 98600
    },
    {
      "epoch": 1.0448759005086783,
      "grad_norm": 4.671938896179199,
      "learning_rate": 3.133358035147152e-05,
      "loss": 1.109,
      "step": 98700
    },
    {
      "epoch": 1.0459345440686847,
      "grad_norm": 4.121927261352539,
      "learning_rate": 3.1365339826381535e-05,
      "loss": 1.089,
      "step": 98800
    },
    {
      "epoch": 1.0469931876286913,
      "grad_norm": 4.34920072555542,
      "learning_rate": 3.1397099301291546e-05,
      "loss": 1.0957,
      "step": 98900
    },
    {
      "epoch": 1.048051831188698,
      "grad_norm": 4.639710903167725,
      "learning_rate": 3.1428858776201564e-05,
      "loss": 1.0982,
      "step": 99000
    },
    {
      "epoch": 1.048051831188698,
      "eval_loss": 1.0054124593734741,
      "eval_runtime": 57.4309,
      "eval_samples_per_second": 2924.037,
      "eval_steps_per_second": 365.518,
      "step": 99000
    },
    {
      "epoch": 1.0491104747487046,
      "grad_norm": 3.996084690093994,
      "learning_rate": 3.1460618251111575e-05,
      "loss": 1.0994,
      "step": 99100
    },
    {
      "epoch": 1.050169118308711,
      "grad_norm": 3.970785617828369,
      "learning_rate": 3.149237772602159e-05,
      "loss": 1.1037,
      "step": 99200
    },
    {
      "epoch": 1.0512277618687176,
      "grad_norm": 4.419730186462402,
      "learning_rate": 3.1524137200931604e-05,
      "loss": 1.0801,
      "step": 99300
    },
    {
      "epoch": 1.0522864054287242,
      "grad_norm": 4.846554279327393,
      "learning_rate": 3.155589667584162e-05,
      "loss": 1.0971,
      "step": 99400
    },
    {
      "epoch": 1.0533450489887308,
      "grad_norm": 4.207505226135254,
      "learning_rate": 3.158765615075164e-05,
      "loss": 1.0893,
      "step": 99500
    },
    {
      "epoch": 1.0544036925487372,
      "grad_norm": 4.7762770652771,
      "learning_rate": 3.1619098030912554e-05,
      "loss": 1.0941,
      "step": 99600
    },
    {
      "epoch": 1.0554623361087438,
      "grad_norm": 4.191521644592285,
      "learning_rate": 3.1650857505822565e-05,
      "loss": 1.0808,
      "step": 99700
    },
    {
      "epoch": 1.0565209796687505,
      "grad_norm": 3.9642443656921387,
      "learning_rate": 3.168261698073258e-05,
      "loss": 1.0867,
      "step": 99800
    },
    {
      "epoch": 1.057579623228757,
      "grad_norm": 4.056772708892822,
      "learning_rate": 3.1714376455642594e-05,
      "loss": 1.0952,
      "step": 99900
    },
    {
      "epoch": 1.0586382667887635,
      "grad_norm": 4.011815071105957,
      "learning_rate": 3.174613593055261e-05,
      "loss": 1.0793,
      "step": 100000
    },
    {
      "epoch": 1.0586382667887635,
      "eval_loss": 0.9936718344688416,
      "eval_runtime": 57.3135,
      "eval_samples_per_second": 2930.026,
      "eval_steps_per_second": 366.266,
      "step": 100000
    },
    {
      "epoch": 1.0596969103487701,
      "grad_norm": 4.1748456954956055,
      "learning_rate": 3.177789540546262e-05,
      "loss": 1.0854,
      "step": 100100
    },
    {
      "epoch": 1.0607555539087767,
      "grad_norm": 3.9617366790771484,
      "learning_rate": 3.180965488037264e-05,
      "loss": 1.0927,
      "step": 100200
    },
    {
      "epoch": 1.0618141974687831,
      "grad_norm": 4.558441638946533,
      "learning_rate": 3.184141435528265e-05,
      "loss": 1.0899,
      "step": 100300
    },
    {
      "epoch": 1.0628728410287898,
      "grad_norm": 3.953272581100464,
      "learning_rate": 3.1873173830192676e-05,
      "loss": 1.0772,
      "step": 100400
    },
    {
      "epoch": 1.0639314845887964,
      "grad_norm": 4.795463562011719,
      "learning_rate": 3.190493330510269e-05,
      "loss": 1.0958,
      "step": 100500
    },
    {
      "epoch": 1.064990128148803,
      "grad_norm": 4.516709327697754,
      "learning_rate": 3.1936692780012705e-05,
      "loss": 1.087,
      "step": 100600
    },
    {
      "epoch": 1.0660487717088094,
      "grad_norm": 4.1211466789245605,
      "learning_rate": 3.196845225492272e-05,
      "loss": 1.079,
      "step": 100700
    },
    {
      "epoch": 1.067107415268816,
      "grad_norm": 4.145346641540527,
      "learning_rate": 3.2000211729832735e-05,
      "loss": 1.0685,
      "step": 100800
    },
    {
      "epoch": 1.0681660588288227,
      "grad_norm": 4.284575462341309,
      "learning_rate": 3.2031971204742746e-05,
      "loss": 1.0764,
      "step": 100900
    },
    {
      "epoch": 1.0692247023888293,
      "grad_norm": 4.417006969451904,
      "learning_rate": 3.2063730679652764e-05,
      "loss": 1.0866,
      "step": 101000
    },
    {
      "epoch": 1.0692247023888293,
      "eval_loss": 0.9824498295783997,
      "eval_runtime": 57.2955,
      "eval_samples_per_second": 2930.944,
      "eval_steps_per_second": 366.381,
      "step": 101000
    },
    {
      "epoch": 1.0702833459488357,
      "grad_norm": 4.5683183670043945,
      "learning_rate": 3.2095490154562775e-05,
      "loss": 1.081,
      "step": 101100
    },
    {
      "epoch": 1.0713419895088423,
      "grad_norm": 4.336721897125244,
      "learning_rate": 3.212724962947279e-05,
      "loss": 1.0817,
      "step": 101200
    },
    {
      "epoch": 1.072400633068849,
      "grad_norm": 4.368027687072754,
      "learning_rate": 3.2159009104382804e-05,
      "loss": 1.0884,
      "step": 101300
    },
    {
      "epoch": 1.0734592766288555,
      "grad_norm": 4.707001686096191,
      "learning_rate": 3.219076857929282e-05,
      "loss": 1.0781,
      "step": 101400
    },
    {
      "epoch": 1.074517920188862,
      "grad_norm": 4.1900224685668945,
      "learning_rate": 3.222252805420283e-05,
      "loss": 1.0798,
      "step": 101500
    },
    {
      "epoch": 1.0755765637488686,
      "grad_norm": 4.304346561431885,
      "learning_rate": 3.2253969934363753e-05,
      "loss": 1.0755,
      "step": 101600
    },
    {
      "epoch": 1.0766352073088752,
      "grad_norm": 4.947498321533203,
      "learning_rate": 3.2285729409273765e-05,
      "loss": 1.0802,
      "step": 101700
    },
    {
      "epoch": 1.0776938508688816,
      "grad_norm": 4.616950511932373,
      "learning_rate": 3.231748888418378e-05,
      "loss": 1.0717,
      "step": 101800
    },
    {
      "epoch": 1.0787524944288882,
      "grad_norm": 4.562636852264404,
      "learning_rate": 3.2349248359093794e-05,
      "loss": 1.0605,
      "step": 101900
    },
    {
      "epoch": 1.0798111379888948,
      "grad_norm": 4.411500930786133,
      "learning_rate": 3.238100783400381e-05,
      "loss": 1.0642,
      "step": 102000
    },
    {
      "epoch": 1.0798111379888948,
      "eval_loss": 0.9658770561218262,
      "eval_runtime": 57.233,
      "eval_samples_per_second": 2934.146,
      "eval_steps_per_second": 366.781,
      "step": 102000
    },
    {
      "epoch": 1.0808697815489015,
      "grad_norm": 4.255692005157471,
      "learning_rate": 3.241276730891382e-05,
      "loss": 1.073,
      "step": 102100
    },
    {
      "epoch": 1.0819284251089079,
      "grad_norm": 4.537589073181152,
      "learning_rate": 3.244452678382384e-05,
      "loss": 1.0675,
      "step": 102200
    },
    {
      "epoch": 1.0829870686689145,
      "grad_norm": 4.540051460266113,
      "learning_rate": 3.247628625873385e-05,
      "loss": 1.0751,
      "step": 102300
    },
    {
      "epoch": 1.084045712228921,
      "grad_norm": 4.657933235168457,
      "learning_rate": 3.250804573364387e-05,
      "loss": 1.0658,
      "step": 102400
    },
    {
      "epoch": 1.0851043557889277,
      "grad_norm": 4.360250949859619,
      "learning_rate": 3.253980520855388e-05,
      "loss": 1.0717,
      "step": 102500
    },
    {
      "epoch": 1.0861629993489341,
      "grad_norm": 3.94018292427063,
      "learning_rate": 3.25715646834639e-05,
      "loss": 1.0736,
      "step": 102600
    },
    {
      "epoch": 1.0872216429089407,
      "grad_norm": 4.631030082702637,
      "learning_rate": 3.260332415837391e-05,
      "loss": 1.0596,
      "step": 102700
    },
    {
      "epoch": 1.0882802864689474,
      "grad_norm": 4.295220375061035,
      "learning_rate": 3.263508363328393e-05,
      "loss": 1.0672,
      "step": 102800
    },
    {
      "epoch": 1.089338930028954,
      "grad_norm": 4.531124114990234,
      "learning_rate": 3.266684310819394e-05,
      "loss": 1.0574,
      "step": 102900
    },
    {
      "epoch": 1.0903975735889604,
      "grad_norm": 3.9014735221862793,
      "learning_rate": 3.269860258310396e-05,
      "loss": 1.0421,
      "step": 103000
    },
    {
      "epoch": 1.0903975735889604,
      "eval_loss": 0.9557795524597168,
      "eval_runtime": 57.411,
      "eval_samples_per_second": 2925.049,
      "eval_steps_per_second": 365.644,
      "step": 103000
    },
    {
      "epoch": 1.091456217148967,
      "grad_norm": 4.412528991699219,
      "learning_rate": 3.2730362058013975e-05,
      "loss": 1.0468,
      "step": 103100
    },
    {
      "epoch": 1.0925148607089736,
      "grad_norm": 4.441935062408447,
      "learning_rate": 3.2762121532923986e-05,
      "loss": 1.0506,
      "step": 103200
    },
    {
      "epoch": 1.0935735042689803,
      "grad_norm": 4.383016109466553,
      "learning_rate": 3.2793881007834004e-05,
      "loss": 1.0595,
      "step": 103300
    },
    {
      "epoch": 1.0946321478289867,
      "grad_norm": 4.400931358337402,
      "learning_rate": 3.2825640482744015e-05,
      "loss": 1.0577,
      "step": 103400
    },
    {
      "epoch": 1.0956907913889933,
      "grad_norm": 4.314419746398926,
      "learning_rate": 3.285708236290493e-05,
      "loss": 1.0503,
      "step": 103500
    },
    {
      "epoch": 1.096749434949,
      "grad_norm": 4.386185646057129,
      "learning_rate": 3.288884183781495e-05,
      "loss": 1.0501,
      "step": 103600
    },
    {
      "epoch": 1.0978080785090065,
      "grad_norm": 4.699766635894775,
      "learning_rate": 3.292060131272496e-05,
      "loss": 1.0407,
      "step": 103700
    },
    {
      "epoch": 1.098866722069013,
      "grad_norm": 4.714911937713623,
      "learning_rate": 3.2952360787634976e-05,
      "loss": 1.0518,
      "step": 103800
    },
    {
      "epoch": 1.0999253656290195,
      "grad_norm": 4.708316802978516,
      "learning_rate": 3.298412026254499e-05,
      "loss": 1.0372,
      "step": 103900
    },
    {
      "epoch": 1.1009840091890262,
      "grad_norm": 4.821380138397217,
      "learning_rate": 3.3015879737455005e-05,
      "loss": 1.0579,
      "step": 104000
    },
    {
      "epoch": 1.1009840091890262,
      "eval_loss": 0.9424939155578613,
      "eval_runtime": 57.205,
      "eval_samples_per_second": 2935.581,
      "eval_steps_per_second": 366.961,
      "step": 104000
    },
    {
      "epoch": 1.1020426527490326,
      "grad_norm": 4.756159782409668,
      "learning_rate": 3.304763921236502e-05,
      "loss": 1.0408,
      "step": 104100
    },
    {
      "epoch": 1.1031012963090392,
      "grad_norm": 4.6334099769592285,
      "learning_rate": 3.3079398687275034e-05,
      "loss": 1.0333,
      "step": 104200
    },
    {
      "epoch": 1.1041599398690458,
      "grad_norm": 4.324206829071045,
      "learning_rate": 3.311115816218505e-05,
      "loss": 1.0358,
      "step": 104300
    },
    {
      "epoch": 1.1052185834290524,
      "grad_norm": 4.5968241691589355,
      "learning_rate": 3.314291763709506e-05,
      "loss": 1.0427,
      "step": 104400
    },
    {
      "epoch": 1.1062772269890588,
      "grad_norm": 4.7744975090026855,
      "learning_rate": 3.317467711200508e-05,
      "loss": 1.0415,
      "step": 104500
    },
    {
      "epoch": 1.1073358705490655,
      "grad_norm": 4.253247261047363,
      "learning_rate": 3.320643658691509e-05,
      "loss": 1.0593,
      "step": 104600
    },
    {
      "epoch": 1.108394514109072,
      "grad_norm": 4.944363594055176,
      "learning_rate": 3.323819606182511e-05,
      "loss": 1.0381,
      "step": 104700
    },
    {
      "epoch": 1.1094531576690787,
      "grad_norm": 4.619009971618652,
      "learning_rate": 3.326995553673512e-05,
      "loss": 1.0361,
      "step": 104800
    },
    {
      "epoch": 1.110511801229085,
      "grad_norm": 4.748648643493652,
      "learning_rate": 3.330171501164514e-05,
      "loss": 1.0497,
      "step": 104900
    },
    {
      "epoch": 1.1115704447890917,
      "grad_norm": 4.8345112800598145,
      "learning_rate": 3.333347448655515e-05,
      "loss": 1.0476,
      "step": 105000
    },
    {
      "epoch": 1.1115704447890917,
      "eval_loss": 0.9332173466682434,
      "eval_runtime": 57.2624,
      "eval_samples_per_second": 2932.641,
      "eval_steps_per_second": 366.593,
      "step": 105000
    },
    {
      "epoch": 1.1126290883490983,
      "grad_norm": 4.720537185668945,
      "learning_rate": 3.336523396146517e-05,
      "loss": 1.0461,
      "step": 105100
    },
    {
      "epoch": 1.113687731909105,
      "grad_norm": 4.713188171386719,
      "learning_rate": 3.339699343637518e-05,
      "loss": 1.0369,
      "step": 105200
    },
    {
      "epoch": 1.1147463754691114,
      "grad_norm": 4.565537452697754,
      "learning_rate": 3.34287529112852e-05,
      "loss": 1.0295,
      "step": 105300
    },
    {
      "epoch": 1.115805019029118,
      "grad_norm": 4.473860263824463,
      "learning_rate": 3.346051238619521e-05,
      "loss": 1.0198,
      "step": 105400
    },
    {
      "epoch": 1.1168636625891246,
      "grad_norm": 4.702403545379639,
      "learning_rate": 3.3492271861105226e-05,
      "loss": 1.0361,
      "step": 105500
    },
    {
      "epoch": 1.117922306149131,
      "grad_norm": 4.513713359832764,
      "learning_rate": 3.3524031336015244e-05,
      "loss": 1.0285,
      "step": 105600
    },
    {
      "epoch": 1.1189809497091376,
      "grad_norm": 4.350518703460693,
      "learning_rate": 3.3555790810925255e-05,
      "loss": 1.0264,
      "step": 105700
    },
    {
      "epoch": 1.1200395932691443,
      "grad_norm": 4.890098571777344,
      "learning_rate": 3.358755028583527e-05,
      "loss": 1.041,
      "step": 105800
    },
    {
      "epoch": 1.1210982368291509,
      "grad_norm": 4.454325199127197,
      "learning_rate": 3.3619309760745284e-05,
      "loss": 1.0324,
      "step": 105900
    },
    {
      "epoch": 1.1221568803891573,
      "grad_norm": 4.250981330871582,
      "learning_rate": 3.36510692356553e-05,
      "loss": 1.0242,
      "step": 106000
    },
    {
      "epoch": 1.1221568803891573,
      "eval_loss": 0.9196592569351196,
      "eval_runtime": 57.1868,
      "eval_samples_per_second": 2936.518,
      "eval_steps_per_second": 367.078,
      "step": 106000
    },
    {
      "epoch": 1.123215523949164,
      "grad_norm": 4.74909782409668,
      "learning_rate": 3.368282871056531e-05,
      "loss": 1.0231,
      "step": 106100
    },
    {
      "epoch": 1.1242741675091705,
      "grad_norm": 4.256649017333984,
      "learning_rate": 3.371458818547533e-05,
      "loss": 1.0306,
      "step": 106200
    },
    {
      "epoch": 1.1253328110691772,
      "grad_norm": 4.749079704284668,
      "learning_rate": 3.374634766038534e-05,
      "loss": 1.0208,
      "step": 106300
    },
    {
      "epoch": 1.1263914546291836,
      "grad_norm": 5.01039457321167,
      "learning_rate": 3.377810713529536e-05,
      "loss": 1.011,
      "step": 106400
    },
    {
      "epoch": 1.1274500981891902,
      "grad_norm": 4.273294925689697,
      "learning_rate": 3.380986661020537e-05,
      "loss": 1.0194,
      "step": 106500
    },
    {
      "epoch": 1.1285087417491968,
      "grad_norm": 4.166898250579834,
      "learning_rate": 3.384162608511539e-05,
      "loss": 1.021,
      "step": 106600
    },
    {
      "epoch": 1.1295673853092034,
      "grad_norm": 4.611155033111572,
      "learning_rate": 3.38733855600254e-05,
      "loss": 1.0243,
      "step": 106700
    },
    {
      "epoch": 1.1306260288692098,
      "grad_norm": 4.668776035308838,
      "learning_rate": 3.3905145034935425e-05,
      "loss": 1.0263,
      "step": 106800
    },
    {
      "epoch": 1.1316846724292164,
      "grad_norm": 4.28524923324585,
      "learning_rate": 3.3936904509845436e-05,
      "loss": 1.0055,
      "step": 106900
    },
    {
      "epoch": 1.132743315989223,
      "grad_norm": 3.9104583263397217,
      "learning_rate": 3.3968663984755454e-05,
      "loss": 1.0284,
      "step": 107000
    },
    {
      "epoch": 1.132743315989223,
      "eval_loss": 0.9067943096160889,
      "eval_runtime": 57.4091,
      "eval_samples_per_second": 2925.148,
      "eval_steps_per_second": 365.657,
      "step": 107000
    },
    {
      "epoch": 1.1338019595492295,
      "grad_norm": 4.823135852813721,
      "learning_rate": 3.4000423459665465e-05,
      "loss": 1.0205,
      "step": 107100
    },
    {
      "epoch": 1.134860603109236,
      "grad_norm": 4.251469135284424,
      "learning_rate": 3.403218293457548e-05,
      "loss": 1.0182,
      "step": 107200
    },
    {
      "epoch": 1.1359192466692427,
      "grad_norm": 4.900644779205322,
      "learning_rate": 3.4063942409485494e-05,
      "loss": 1.0253,
      "step": 107300
    },
    {
      "epoch": 1.1369778902292493,
      "grad_norm": 4.638645648956299,
      "learning_rate": 3.409570188439551e-05,
      "loss": 1.0066,
      "step": 107400
    },
    {
      "epoch": 1.1380365337892557,
      "grad_norm": 4.719858169555664,
      "learning_rate": 3.4127143764556426e-05,
      "loss": 1.0001,
      "step": 107500
    },
    {
      "epoch": 1.1390951773492624,
      "grad_norm": 4.185101509094238,
      "learning_rate": 3.415890323946644e-05,
      "loss": 1.0091,
      "step": 107600
    },
    {
      "epoch": 1.140153820909269,
      "grad_norm": 4.194613933563232,
      "learning_rate": 3.4190662714376455e-05,
      "loss": 1.0154,
      "step": 107700
    },
    {
      "epoch": 1.1412124644692756,
      "grad_norm": 4.6803178787231445,
      "learning_rate": 3.4222422189286466e-05,
      "loss": 1.0126,
      "step": 107800
    },
    {
      "epoch": 1.142271108029282,
      "grad_norm": 4.958804607391357,
      "learning_rate": 3.4254181664196484e-05,
      "loss": 1.0166,
      "step": 107900
    },
    {
      "epoch": 1.1433297515892886,
      "grad_norm": 5.201964855194092,
      "learning_rate": 3.42859411391065e-05,
      "loss": 1.0168,
      "step": 108000
    },
    {
      "epoch": 1.1433297515892886,
      "eval_loss": 0.8931783437728882,
      "eval_runtime": 57.3126,
      "eval_samples_per_second": 2930.071,
      "eval_steps_per_second": 366.272,
      "step": 108000
    },
    {
      "epoch": 1.1443883951492952,
      "grad_norm": 4.590342044830322,
      "learning_rate": 3.431770061401651e-05,
      "loss": 1.0187,
      "step": 108100
    },
    {
      "epoch": 1.1454470387093019,
      "grad_norm": 4.772169589996338,
      "learning_rate": 3.434946008892653e-05,
      "loss": 1.0104,
      "step": 108200
    },
    {
      "epoch": 1.1465056822693083,
      "grad_norm": 4.516888618469238,
      "learning_rate": 3.438121956383654e-05,
      "loss": 1.0077,
      "step": 108300
    },
    {
      "epoch": 1.147564325829315,
      "grad_norm": 4.930634498596191,
      "learning_rate": 3.441297903874656e-05,
      "loss": 0.9987,
      "step": 108400
    },
    {
      "epoch": 1.1486229693893215,
      "grad_norm": 4.8559346199035645,
      "learning_rate": 3.444473851365657e-05,
      "loss": 1.0133,
      "step": 108500
    },
    {
      "epoch": 1.149681612949328,
      "grad_norm": 4.70967435836792,
      "learning_rate": 3.447649798856659e-05,
      "loss": 1.003,
      "step": 108600
    },
    {
      "epoch": 1.1507402565093345,
      "grad_norm": 4.476822853088379,
      "learning_rate": 3.45082574634766e-05,
      "loss": 1.0062,
      "step": 108700
    },
    {
      "epoch": 1.1517989000693412,
      "grad_norm": 4.987275123596191,
      "learning_rate": 3.454001693838662e-05,
      "loss": 0.9928,
      "step": 108800
    },
    {
      "epoch": 1.1528575436293478,
      "grad_norm": 4.584801197052002,
      "learning_rate": 3.457177641329663e-05,
      "loss": 0.9923,
      "step": 108900
    },
    {
      "epoch": 1.1539161871893544,
      "grad_norm": 4.726271629333496,
      "learning_rate": 3.460353588820665e-05,
      "loss": 0.9977,
      "step": 109000
    },
    {
      "epoch": 1.1539161871893544,
      "eval_loss": 0.8801805377006531,
      "eval_runtime": 57.213,
      "eval_samples_per_second": 2935.173,
      "eval_steps_per_second": 366.91,
      "step": 109000
    },
    {
      "epoch": 1.1549748307493608,
      "grad_norm": 4.88192081451416,
      "learning_rate": 3.463529536311666e-05,
      "loss": 1.0029,
      "step": 109100
    },
    {
      "epoch": 1.1560334743093674,
      "grad_norm": 4.761863708496094,
      "learning_rate": 3.4667054838026676e-05,
      "loss": 1.0027,
      "step": 109200
    },
    {
      "epoch": 1.157092117869374,
      "grad_norm": 4.718171119689941,
      "learning_rate": 3.469881431293669e-05,
      "loss": 1.0131,
      "step": 109300
    },
    {
      "epoch": 1.1581507614293804,
      "grad_norm": 4.757126331329346,
      "learning_rate": 3.4730573787846705e-05,
      "loss": 0.9795,
      "step": 109400
    },
    {
      "epoch": 1.159209404989387,
      "grad_norm": 4.826667308807373,
      "learning_rate": 3.476201566800762e-05,
      "loss": 0.9919,
      "step": 109500
    },
    {
      "epoch": 1.1602680485493937,
      "grad_norm": 5.1660542488098145,
      "learning_rate": 3.479377514291764e-05,
      "loss": 0.998,
      "step": 109600
    },
    {
      "epoch": 1.1613266921094003,
      "grad_norm": 4.342677116394043,
      "learning_rate": 3.482553461782765e-05,
      "loss": 0.9774,
      "step": 109700
    },
    {
      "epoch": 1.1623853356694067,
      "grad_norm": 4.300011157989502,
      "learning_rate": 3.4857294092737666e-05,
      "loss": 0.9939,
      "step": 109800
    },
    {
      "epoch": 1.1634439792294133,
      "grad_norm": 4.822358131408691,
      "learning_rate": 3.488905356764768e-05,
      "loss": 0.9916,
      "step": 109900
    },
    {
      "epoch": 1.16450262278942,
      "grad_norm": 4.62828254699707,
      "learning_rate": 3.4920813042557695e-05,
      "loss": 0.9996,
      "step": 110000
    },
    {
      "epoch": 1.16450262278942,
      "eval_loss": 0.8713570237159729,
      "eval_runtime": 57.4788,
      "eval_samples_per_second": 2921.599,
      "eval_steps_per_second": 365.213,
      "step": 110000
    },
    {
      "epoch": 1.1655612663494264,
      "grad_norm": 4.2072062492370605,
      "learning_rate": 3.4952572517467706e-05,
      "loss": 0.9886,
      "step": 110100
    },
    {
      "epoch": 1.166619909909433,
      "grad_norm": 4.953588008880615,
      "learning_rate": 3.498401439762863e-05,
      "loss": 0.9825,
      "step": 110200
    },
    {
      "epoch": 1.1676785534694396,
      "grad_norm": 5.090232849121094,
      "learning_rate": 3.501577387253864e-05,
      "loss": 0.984,
      "step": 110300
    },
    {
      "epoch": 1.1687371970294462,
      "grad_norm": 5.026788234710693,
      "learning_rate": 3.5047533347448656e-05,
      "loss": 0.9886,
      "step": 110400
    },
    {
      "epoch": 1.1697958405894529,
      "grad_norm": 4.761091232299805,
      "learning_rate": 3.507929282235867e-05,
      "loss": 0.9788,
      "step": 110500
    },
    {
      "epoch": 1.1708544841494593,
      "grad_norm": 5.007173538208008,
      "learning_rate": 3.5111052297268685e-05,
      "loss": 0.9816,
      "step": 110600
    },
    {
      "epoch": 1.1719131277094659,
      "grad_norm": 5.031378269195557,
      "learning_rate": 3.5142811772178696e-05,
      "loss": 0.9904,
      "step": 110700
    },
    {
      "epoch": 1.1729717712694725,
      "grad_norm": 4.3850932121276855,
      "learning_rate": 3.5174571247088714e-05,
      "loss": 0.9886,
      "step": 110800
    },
    {
      "epoch": 1.174030414829479,
      "grad_norm": 4.753615856170654,
      "learning_rate": 3.5206330721998725e-05,
      "loss": 0.9885,
      "step": 110900
    },
    {
      "epoch": 1.1750890583894855,
      "grad_norm": 4.7324724197387695,
      "learning_rate": 3.523809019690874e-05,
      "loss": 0.9635,
      "step": 111000
    },
    {
      "epoch": 1.1750890583894855,
      "eval_loss": 0.8558483123779297,
      "eval_runtime": 57.39,
      "eval_samples_per_second": 2926.118,
      "eval_steps_per_second": 365.778,
      "step": 111000
    },
    {
      "epoch": 1.1761477019494921,
      "grad_norm": 4.48552942276001,
      "learning_rate": 3.5269849671818754e-05,
      "loss": 0.9742,
      "step": 111100
    },
    {
      "epoch": 1.1772063455094988,
      "grad_norm": 4.2713823318481445,
      "learning_rate": 3.530160914672877e-05,
      "loss": 0.9679,
      "step": 111200
    },
    {
      "epoch": 1.1782649890695052,
      "grad_norm": 4.966119289398193,
      "learning_rate": 3.533336862163878e-05,
      "loss": 0.9635,
      "step": 111300
    },
    {
      "epoch": 1.1793236326295118,
      "grad_norm": 4.612917900085449,
      "learning_rate": 3.53651280965488e-05,
      "loss": 0.9698,
      "step": 111400
    },
    {
      "epoch": 1.1803822761895184,
      "grad_norm": 4.49338960647583,
      "learning_rate": 3.539688757145881e-05,
      "loss": 0.9866,
      "step": 111500
    },
    {
      "epoch": 1.1814409197495248,
      "grad_norm": 4.691024303436279,
      "learning_rate": 3.542864704636883e-05,
      "loss": 0.9842,
      "step": 111600
    },
    {
      "epoch": 1.1824995633095314,
      "grad_norm": 4.541269302368164,
      "learning_rate": 3.546040652127885e-05,
      "loss": 0.9802,
      "step": 111700
    },
    {
      "epoch": 1.183558206869538,
      "grad_norm": 4.711612224578857,
      "learning_rate": 3.549216599618886e-05,
      "loss": 0.9754,
      "step": 111800
    },
    {
      "epoch": 1.1846168504295447,
      "grad_norm": 5.024625301361084,
      "learning_rate": 3.552392547109888e-05,
      "loss": 0.9674,
      "step": 111900
    },
    {
      "epoch": 1.1856754939895513,
      "grad_norm": 5.137420654296875,
      "learning_rate": 3.555568494600889e-05,
      "loss": 0.9657,
      "step": 112000
    },
    {
      "epoch": 1.1856754939895513,
      "eval_loss": 0.8410722017288208,
      "eval_runtime": 57.2444,
      "eval_samples_per_second": 2933.563,
      "eval_steps_per_second": 366.708,
      "step": 112000
    },
    {
      "epoch": 1.1867341375495577,
      "grad_norm": 4.744097709655762,
      "learning_rate": 3.5587444420918906e-05,
      "loss": 0.9795,
      "step": 112100
    },
    {
      "epoch": 1.1877927811095643,
      "grad_norm": 4.406541347503662,
      "learning_rate": 3.561920389582892e-05,
      "loss": 0.9686,
      "step": 112200
    },
    {
      "epoch": 1.188851424669571,
      "grad_norm": 4.809876441955566,
      "learning_rate": 3.5650963370738935e-05,
      "loss": 0.9644,
      "step": 112300
    },
    {
      "epoch": 1.1899100682295773,
      "grad_norm": 4.3314008712768555,
      "learning_rate": 3.5682722845648946e-05,
      "loss": 0.9582,
      "step": 112400
    },
    {
      "epoch": 1.190968711789584,
      "grad_norm": 4.466166019439697,
      "learning_rate": 3.5714482320558964e-05,
      "loss": 0.9672,
      "step": 112500
    },
    {
      "epoch": 1.1920273553495906,
      "grad_norm": 5.2077436447143555,
      "learning_rate": 3.5746241795468975e-05,
      "loss": 0.9685,
      "step": 112600
    },
    {
      "epoch": 1.1930859989095972,
      "grad_norm": 5.009883880615234,
      "learning_rate": 3.577800127037899e-05,
      "loss": 0.9631,
      "step": 112700
    },
    {
      "epoch": 1.1941446424696036,
      "grad_norm": 5.398120880126953,
      "learning_rate": 3.5809760745289004e-05,
      "loss": 0.9521,
      "step": 112800
    },
    {
      "epoch": 1.1952032860296102,
      "grad_norm": 5.104313373565674,
      "learning_rate": 3.584152022019902e-05,
      "loss": 0.9603,
      "step": 112900
    },
    {
      "epoch": 1.1962619295896169,
      "grad_norm": 4.913372993469238,
      "learning_rate": 3.587327969510903e-05,
      "loss": 0.9685,
      "step": 113000
    },
    {
      "epoch": 1.1962619295896169,
      "eval_loss": 0.8338977694511414,
      "eval_runtime": 57.3179,
      "eval_samples_per_second": 2929.8,
      "eval_steps_per_second": 366.238,
      "step": 113000
    },
    {
      "epoch": 1.1973205731496235,
      "grad_norm": 4.708587646484375,
      "learning_rate": 3.590503917001905e-05,
      "loss": 0.9497,
      "step": 113100
    },
    {
      "epoch": 1.1983792167096299,
      "grad_norm": 5.371211051940918,
      "learning_rate": 3.593679864492907e-05,
      "loss": 0.9569,
      "step": 113200
    },
    {
      "epoch": 1.1994378602696365,
      "grad_norm": 4.659306049346924,
      "learning_rate": 3.596855811983908e-05,
      "loss": 0.9563,
      "step": 113300
    },
    {
      "epoch": 1.2004965038296431,
      "grad_norm": 4.581874370574951,
      "learning_rate": 3.60003175947491e-05,
      "loss": 0.9659,
      "step": 113400
    },
    {
      "epoch": 1.2015551473896497,
      "grad_norm": 4.589176177978516,
      "learning_rate": 3.603207706965911e-05,
      "loss": 0.954,
      "step": 113500
    },
    {
      "epoch": 1.2026137909496561,
      "grad_norm": 4.768279552459717,
      "learning_rate": 3.606383654456913e-05,
      "loss": 0.9571,
      "step": 113600
    },
    {
      "epoch": 1.2036724345096628,
      "grad_norm": 5.545390605926514,
      "learning_rate": 3.609559601947914e-05,
      "loss": 0.9482,
      "step": 113700
    },
    {
      "epoch": 1.2047310780696694,
      "grad_norm": 4.593245029449463,
      "learning_rate": 3.6127355494389156e-05,
      "loss": 0.9368,
      "step": 113800
    },
    {
      "epoch": 1.2057897216296758,
      "grad_norm": 4.855453968048096,
      "learning_rate": 3.6159114969299174e-05,
      "loss": 0.9683,
      "step": 113900
    },
    {
      "epoch": 1.2068483651896824,
      "grad_norm": 4.3659820556640625,
      "learning_rate": 3.6190874444209185e-05,
      "loss": 0.9521,
      "step": 114000
    },
    {
      "epoch": 1.2068483651896824,
      "eval_loss": 0.8179460167884827,
      "eval_runtime": 57.3262,
      "eval_samples_per_second": 2929.375,
      "eval_steps_per_second": 366.185,
      "step": 114000
    },
    {
      "epoch": 1.207907008749689,
      "grad_norm": 4.630506992340088,
      "learning_rate": 3.62226339191192e-05,
      "loss": 0.9404,
      "step": 114100
    },
    {
      "epoch": 1.2089656523096957,
      "grad_norm": 4.526369571685791,
      "learning_rate": 3.625407579928011e-05,
      "loss": 0.9381,
      "step": 114200
    },
    {
      "epoch": 1.210024295869702,
      "grad_norm": 4.778719425201416,
      "learning_rate": 3.628583527419013e-05,
      "loss": 0.9515,
      "step": 114300
    },
    {
      "epoch": 1.2110829394297087,
      "grad_norm": 4.9805192947387695,
      "learning_rate": 3.6317594749100146e-05,
      "loss": 0.9506,
      "step": 114400
    },
    {
      "epoch": 1.2121415829897153,
      "grad_norm": 4.942522048950195,
      "learning_rate": 3.6349354224010164e-05,
      "loss": 0.9414,
      "step": 114500
    },
    {
      "epoch": 1.213200226549722,
      "grad_norm": 5.061984539031982,
      "learning_rate": 3.6381113698920175e-05,
      "loss": 0.9603,
      "step": 114600
    },
    {
      "epoch": 1.2142588701097283,
      "grad_norm": 4.558525562286377,
      "learning_rate": 3.641287317383019e-05,
      "loss": 0.946,
      "step": 114700
    },
    {
      "epoch": 1.215317513669735,
      "grad_norm": 4.974576950073242,
      "learning_rate": 3.6444632648740204e-05,
      "loss": 0.9518,
      "step": 114800
    },
    {
      "epoch": 1.2163761572297416,
      "grad_norm": 4.662308216094971,
      "learning_rate": 3.647639212365022e-05,
      "loss": 0.9352,
      "step": 114900
    },
    {
      "epoch": 1.2174348007897482,
      "grad_norm": 4.981719017028809,
      "learning_rate": 3.650815159856023e-05,
      "loss": 0.9446,
      "step": 115000
    },
    {
      "epoch": 1.2174348007897482,
      "eval_loss": 0.8074536323547363,
      "eval_runtime": 57.2898,
      "eval_samples_per_second": 2931.236,
      "eval_steps_per_second": 366.418,
      "step": 115000
    },
    {
      "epoch": 1.2184934443497546,
      "grad_norm": 4.353193759918213,
      "learning_rate": 3.653991107347025e-05,
      "loss": 0.9379,
      "step": 115100
    },
    {
      "epoch": 1.2195520879097612,
      "grad_norm": 4.7821197509765625,
      "learning_rate": 3.657167054838026e-05,
      "loss": 0.9389,
      "step": 115200
    },
    {
      "epoch": 1.2206107314697678,
      "grad_norm": 5.539366245269775,
      "learning_rate": 3.660343002329028e-05,
      "loss": 0.9364,
      "step": 115300
    },
    {
      "epoch": 1.2216693750297742,
      "grad_norm": 4.210940361022949,
      "learning_rate": 3.663518949820029e-05,
      "loss": 0.9406,
      "step": 115400
    },
    {
      "epoch": 1.2227280185897809,
      "grad_norm": 5.097413539886475,
      "learning_rate": 3.666694897311031e-05,
      "loss": 0.9354,
      "step": 115500
    },
    {
      "epoch": 1.2237866621497875,
      "grad_norm": 4.705604076385498,
      "learning_rate": 3.669870844802033e-05,
      "loss": 0.9327,
      "step": 115600
    },
    {
      "epoch": 1.224845305709794,
      "grad_norm": 4.712667465209961,
      "learning_rate": 3.673015032818124e-05,
      "loss": 0.9319,
      "step": 115700
    },
    {
      "epoch": 1.2259039492698005,
      "grad_norm": 4.590601444244385,
      "learning_rate": 3.676190980309125e-05,
      "loss": 0.9352,
      "step": 115800
    },
    {
      "epoch": 1.2269625928298071,
      "grad_norm": 4.621417045593262,
      "learning_rate": 3.679366927800127e-05,
      "loss": 0.933,
      "step": 115900
    },
    {
      "epoch": 1.2280212363898138,
      "grad_norm": 5.215625286102295,
      "learning_rate": 3.682542875291128e-05,
      "loss": 0.9345,
      "step": 116000
    },
    {
      "epoch": 1.2280212363898138,
      "eval_loss": 0.7941415309906006,
      "eval_runtime": 57.2203,
      "eval_samples_per_second": 2934.796,
      "eval_steps_per_second": 366.863,
      "step": 116000
    },
    {
      "epoch": 1.2290798799498204,
      "grad_norm": 4.354996681213379,
      "learning_rate": 3.68571882278213e-05,
      "loss": 0.9345,
      "step": 116100
    },
    {
      "epoch": 1.2301385235098268,
      "grad_norm": 4.759397983551025,
      "learning_rate": 3.688894770273131e-05,
      "loss": 0.9371,
      "step": 116200
    },
    {
      "epoch": 1.2311971670698334,
      "grad_norm": 4.968101501464844,
      "learning_rate": 3.692070717764133e-05,
      "loss": 0.9298,
      "step": 116300
    },
    {
      "epoch": 1.23225581062984,
      "grad_norm": 5.055434226989746,
      "learning_rate": 3.695246665255134e-05,
      "loss": 0.9196,
      "step": 116400
    },
    {
      "epoch": 1.2333144541898466,
      "grad_norm": 4.278247356414795,
      "learning_rate": 3.698422612746136e-05,
      "loss": 0.9305,
      "step": 116500
    },
    {
      "epoch": 1.234373097749853,
      "grad_norm": 4.939261436462402,
      "learning_rate": 3.701598560237137e-05,
      "loss": 0.9229,
      "step": 116600
    },
    {
      "epoch": 1.2354317413098597,
      "grad_norm": 4.832704067230225,
      "learning_rate": 3.7047745077281386e-05,
      "loss": 0.9339,
      "step": 116700
    },
    {
      "epoch": 1.2364903848698663,
      "grad_norm": 4.90868616104126,
      "learning_rate": 3.7079504552191404e-05,
      "loss": 0.9221,
      "step": 116800
    },
    {
      "epoch": 1.2375490284298727,
      "grad_norm": 4.436450004577637,
      "learning_rate": 3.7111264027101415e-05,
      "loss": 0.9267,
      "step": 116900
    },
    {
      "epoch": 1.2386076719898793,
      "grad_norm": 4.421010971069336,
      "learning_rate": 3.714302350201143e-05,
      "loss": 0.9172,
      "step": 117000
    },
    {
      "epoch": 1.2386076719898793,
      "eval_loss": 0.7865438461303711,
      "eval_runtime": 57.4284,
      "eval_samples_per_second": 2924.162,
      "eval_steps_per_second": 365.533,
      "step": 117000
    },
    {
      "epoch": 1.239666315549886,
      "grad_norm": 4.956940650939941,
      "learning_rate": 3.7174782976921444e-05,
      "loss": 0.9069,
      "step": 117100
    },
    {
      "epoch": 1.2407249591098926,
      "grad_norm": 4.412907600402832,
      "learning_rate": 3.720654245183146e-05,
      "loss": 0.9187,
      "step": 117200
    },
    {
      "epoch": 1.2417836026698992,
      "grad_norm": 5.00552225112915,
      "learning_rate": 3.723830192674147e-05,
      "loss": 0.9288,
      "step": 117300
    },
    {
      "epoch": 1.2428422462299056,
      "grad_norm": 4.980460166931152,
      "learning_rate": 3.727006140165149e-05,
      "loss": 0.9317,
      "step": 117400
    },
    {
      "epoch": 1.2439008897899122,
      "grad_norm": 4.982026100158691,
      "learning_rate": 3.73018208765615e-05,
      "loss": 0.914,
      "step": 117500
    },
    {
      "epoch": 1.2449595333499188,
      "grad_norm": 4.379220962524414,
      "learning_rate": 3.733358035147152e-05,
      "loss": 0.9166,
      "step": 117600
    },
    {
      "epoch": 1.2460181769099252,
      "grad_norm": 5.097941875457764,
      "learning_rate": 3.736533982638153e-05,
      "loss": 0.9284,
      "step": 117700
    },
    {
      "epoch": 1.2470768204699318,
      "grad_norm": 5.071591377258301,
      "learning_rate": 3.739709930129155e-05,
      "loss": 0.9171,
      "step": 117800
    },
    {
      "epoch": 1.2481354640299385,
      "grad_norm": 4.9160590171813965,
      "learning_rate": 3.742885877620156e-05,
      "loss": 0.9069,
      "step": 117900
    },
    {
      "epoch": 1.249194107589945,
      "grad_norm": 5.354969024658203,
      "learning_rate": 3.746061825111158e-05,
      "loss": 0.9003,
      "step": 118000
    },
    {
      "epoch": 1.249194107589945,
      "eval_loss": 0.7730200290679932,
      "eval_runtime": 57.3546,
      "eval_samples_per_second": 2927.923,
      "eval_steps_per_second": 366.003,
      "step": 118000
    },
    {
      "epoch": 1.2502527511499515,
      "grad_norm": 4.967441558837891,
      "learning_rate": 3.749237772602159e-05,
      "loss": 0.9134,
      "step": 118100
    },
    {
      "epoch": 1.2513113947099581,
      "grad_norm": 5.120669841766357,
      "learning_rate": 3.7524137200931614e-05,
      "loss": 0.9185,
      "step": 118200
    },
    {
      "epoch": 1.2523700382699647,
      "grad_norm": 5.249866008758545,
      "learning_rate": 3.7555896675841625e-05,
      "loss": 0.9111,
      "step": 118300
    },
    {
      "epoch": 1.2534286818299711,
      "grad_norm": 4.899887561798096,
      "learning_rate": 3.758765615075164e-05,
      "loss": 0.9126,
      "step": 118400
    },
    {
      "epoch": 1.2544873253899778,
      "grad_norm": 4.353448390960693,
      "learning_rate": 3.7619415625661654e-05,
      "loss": 0.9029,
      "step": 118500
    },
    {
      "epoch": 1.2555459689499844,
      "grad_norm": 4.547221660614014,
      "learning_rate": 3.765117510057167e-05,
      "loss": 0.9108,
      "step": 118600
    },
    {
      "epoch": 1.256604612509991,
      "grad_norm": 4.583442687988281,
      "learning_rate": 3.768293457548168e-05,
      "loss": 0.9009,
      "step": 118700
    },
    {
      "epoch": 1.2576632560699976,
      "grad_norm": 4.797860145568848,
      "learning_rate": 3.77146940503917e-05,
      "loss": 0.9048,
      "step": 118800
    },
    {
      "epoch": 1.258721899630004,
      "grad_norm": 5.054913520812988,
      "learning_rate": 3.774645352530171e-05,
      "loss": 0.9126,
      "step": 118900
    },
    {
      "epoch": 1.2597805431900106,
      "grad_norm": 4.743434429168701,
      "learning_rate": 3.777821300021173e-05,
      "loss": 0.9135,
      "step": 119000
    },
    {
      "epoch": 1.2597805431900106,
      "eval_loss": 0.7665421962738037,
      "eval_runtime": 57.312,
      "eval_samples_per_second": 2930.101,
      "eval_steps_per_second": 366.276,
      "step": 119000
    },
    {
      "epoch": 1.2608391867500173,
      "grad_norm": 4.395725727081299,
      "learning_rate": 3.780997247512174e-05,
      "loss": 0.9059,
      "step": 119100
    },
    {
      "epoch": 1.2618978303100237,
      "grad_norm": 5.317966938018799,
      "learning_rate": 3.784173195003176e-05,
      "loss": 0.917,
      "step": 119200
    },
    {
      "epoch": 1.2629564738700303,
      "grad_norm": 5.036566734313965,
      "learning_rate": 3.787349142494177e-05,
      "loss": 0.9014,
      "step": 119300
    },
    {
      "epoch": 1.264015117430037,
      "grad_norm": 4.807994842529297,
      "learning_rate": 3.790525089985179e-05,
      "loss": 0.9036,
      "step": 119400
    },
    {
      "epoch": 1.2650737609900435,
      "grad_norm": 4.999385356903076,
      "learning_rate": 3.7937010374761806e-05,
      "loss": 0.9096,
      "step": 119500
    },
    {
      "epoch": 1.26613240455005,
      "grad_norm": 4.7404584884643555,
      "learning_rate": 3.796876984967182e-05,
      "loss": 0.9076,
      "step": 119600
    },
    {
      "epoch": 1.2671910481100566,
      "grad_norm": 4.844718933105469,
      "learning_rate": 3.800021172983273e-05,
      "loss": 0.899,
      "step": 119700
    },
    {
      "epoch": 1.2682496916700632,
      "grad_norm": 4.738124847412109,
      "learning_rate": 3.803197120474275e-05,
      "loss": 0.8964,
      "step": 119800
    },
    {
      "epoch": 1.2693083352300696,
      "grad_norm": 4.874422073364258,
      "learning_rate": 3.806373067965276e-05,
      "loss": 0.8929,
      "step": 119900
    },
    {
      "epoch": 1.2703669787900762,
      "grad_norm": 5.080951690673828,
      "learning_rate": 3.809549015456278e-05,
      "loss": 0.9064,
      "step": 120000
    },
    {
      "epoch": 1.2703669787900762,
      "eval_loss": 0.7528187036514282,
      "eval_runtime": 57.2574,
      "eval_samples_per_second": 2932.897,
      "eval_steps_per_second": 366.625,
      "step": 120000
    },
    {
      "epoch": 1.2714256223500828,
      "grad_norm": 4.908302307128906,
      "learning_rate": 3.812724962947279e-05,
      "loss": 0.8951,
      "step": 120100
    },
    {
      "epoch": 1.2724842659100895,
      "grad_norm": 5.044375896453857,
      "learning_rate": 3.815900910438281e-05,
      "loss": 0.8933,
      "step": 120200
    },
    {
      "epoch": 1.273542909470096,
      "grad_norm": 4.516486167907715,
      "learning_rate": 3.819076857929282e-05,
      "loss": 0.8957,
      "step": 120300
    },
    {
      "epoch": 1.2746015530301025,
      "grad_norm": 4.896594047546387,
      "learning_rate": 3.8222528054202836e-05,
      "loss": 0.8897,
      "step": 120400
    },
    {
      "epoch": 1.275660196590109,
      "grad_norm": 5.343209266662598,
      "learning_rate": 3.8254287529112854e-05,
      "loss": 0.9006,
      "step": 120500
    },
    {
      "epoch": 1.2767188401501157,
      "grad_norm": 5.269136905670166,
      "learning_rate": 3.8286047004022865e-05,
      "loss": 0.8781,
      "step": 120600
    },
    {
      "epoch": 1.2777774837101221,
      "grad_norm": 4.517550468444824,
      "learning_rate": 3.831780647893288e-05,
      "loss": 0.881,
      "step": 120700
    },
    {
      "epoch": 1.2788361272701287,
      "grad_norm": 4.705735206604004,
      "learning_rate": 3.8349565953842894e-05,
      "loss": 0.8846,
      "step": 120800
    },
    {
      "epoch": 1.2798947708301354,
      "grad_norm": 4.709869861602783,
      "learning_rate": 3.838132542875291e-05,
      "loss": 0.8871,
      "step": 120900
    },
    {
      "epoch": 1.280953414390142,
      "grad_norm": 5.072896957397461,
      "learning_rate": 3.8413084903662923e-05,
      "loss": 0.8782,
      "step": 121000
    },
    {
      "epoch": 1.280953414390142,
      "eval_loss": 0.7437450885772705,
      "eval_runtime": 57.2675,
      "eval_samples_per_second": 2932.379,
      "eval_steps_per_second": 366.56,
      "step": 121000
    },
    {
      "epoch": 1.2820120579501486,
      "grad_norm": 4.596808910369873,
      "learning_rate": 3.844484437857294e-05,
      "loss": 0.8779,
      "step": 121100
    },
    {
      "epoch": 1.283070701510155,
      "grad_norm": 4.792718410491943,
      "learning_rate": 3.847660385348295e-05,
      "loss": 0.8892,
      "step": 121200
    },
    {
      "epoch": 1.2841293450701616,
      "grad_norm": 4.6873779296875,
      "learning_rate": 3.850836332839297e-05,
      "loss": 0.8848,
      "step": 121300
    },
    {
      "epoch": 1.285187988630168,
      "grad_norm": 4.888143062591553,
      "learning_rate": 3.854012280330298e-05,
      "loss": 0.8843,
      "step": 121400
    },
    {
      "epoch": 1.2862466321901747,
      "grad_norm": 4.920286655426025,
      "learning_rate": 3.8571882278213e-05,
      "loss": 0.8741,
      "step": 121500
    },
    {
      "epoch": 1.2873052757501813,
      "grad_norm": 4.896917343139648,
      "learning_rate": 3.860364175312301e-05,
      "loss": 0.8688,
      "step": 121600
    },
    {
      "epoch": 1.288363919310188,
      "grad_norm": 5.339753150939941,
      "learning_rate": 3.863508363328393e-05,
      "loss": 0.8708,
      "step": 121700
    },
    {
      "epoch": 1.2894225628701945,
      "grad_norm": 5.194638252258301,
      "learning_rate": 3.866684310819394e-05,
      "loss": 0.8884,
      "step": 121800
    },
    {
      "epoch": 1.290481206430201,
      "grad_norm": 4.376000881195068,
      "learning_rate": 3.869860258310396e-05,
      "loss": 0.8638,
      "step": 121900
    },
    {
      "epoch": 1.2915398499902075,
      "grad_norm": 5.283166885375977,
      "learning_rate": 3.873036205801397e-05,
      "loss": 0.8661,
      "step": 122000
    },
    {
      "epoch": 1.2915398499902075,
      "eval_loss": 0.7339655160903931,
      "eval_runtime": 57.5063,
      "eval_samples_per_second": 2920.202,
      "eval_steps_per_second": 365.038,
      "step": 122000
    },
    {
      "epoch": 1.2925984935502142,
      "grad_norm": 5.446117401123047,
      "learning_rate": 3.8761803938174885e-05,
      "loss": 0.8778,
      "step": 122100
    },
    {
      "epoch": 1.2936571371102206,
      "grad_norm": 4.468740463256836,
      "learning_rate": 3.87935634130849e-05,
      "loss": 0.8801,
      "step": 122200
    },
    {
      "epoch": 1.2947157806702272,
      "grad_norm": 4.899449825286865,
      "learning_rate": 3.8825322887994914e-05,
      "loss": 0.8769,
      "step": 122300
    },
    {
      "epoch": 1.2957744242302338,
      "grad_norm": 5.088642597198486,
      "learning_rate": 3.885708236290493e-05,
      "loss": 0.8661,
      "step": 122400
    },
    {
      "epoch": 1.2968330677902404,
      "grad_norm": 4.792623043060303,
      "learning_rate": 3.8888841837814943e-05,
      "loss": 0.8656,
      "step": 122500
    },
    {
      "epoch": 1.297891711350247,
      "grad_norm": 4.484658241271973,
      "learning_rate": 3.892060131272496e-05,
      "loss": 0.8633,
      "step": 122600
    },
    {
      "epoch": 1.2989503549102535,
      "grad_norm": 4.684145927429199,
      "learning_rate": 3.895236078763497e-05,
      "loss": 0.8736,
      "step": 122700
    },
    {
      "epoch": 1.30000899847026,
      "grad_norm": 4.8958516120910645,
      "learning_rate": 3.898412026254499e-05,
      "loss": 0.8683,
      "step": 122800
    },
    {
      "epoch": 1.3010676420302667,
      "grad_norm": 5.318750858306885,
      "learning_rate": 3.901587973745501e-05,
      "loss": 0.8691,
      "step": 122900
    },
    {
      "epoch": 1.302126285590273,
      "grad_norm": 5.294607162475586,
      "learning_rate": 3.904763921236502e-05,
      "loss": 0.8644,
      "step": 123000
    },
    {
      "epoch": 1.302126285590273,
      "eval_loss": 0.723159909248352,
      "eval_runtime": 57.2571,
      "eval_samples_per_second": 2932.912,
      "eval_steps_per_second": 366.627,
      "step": 123000
    },
    {
      "epoch": 1.3031849291502797,
      "grad_norm": 4.803304672241211,
      "learning_rate": 3.907939868727504e-05,
      "loss": 0.8618,
      "step": 123100
    },
    {
      "epoch": 1.3042435727102863,
      "grad_norm": 4.595670223236084,
      "learning_rate": 3.911115816218505e-05,
      "loss": 0.8711,
      "step": 123200
    },
    {
      "epoch": 1.305302216270293,
      "grad_norm": 5.292222023010254,
      "learning_rate": 3.9142917637095066e-05,
      "loss": 0.873,
      "step": 123300
    },
    {
      "epoch": 1.3063608598302994,
      "grad_norm": 4.920395374298096,
      "learning_rate": 3.917467711200508e-05,
      "loss": 0.8554,
      "step": 123400
    },
    {
      "epoch": 1.307419503390306,
      "grad_norm": 4.059474945068359,
      "learning_rate": 3.9206436586915095e-05,
      "loss": 0.8636,
      "step": 123500
    },
    {
      "epoch": 1.3084781469503126,
      "grad_norm": 4.76890754699707,
      "learning_rate": 3.9238196061825106e-05,
      "loss": 0.8721,
      "step": 123600
    },
    {
      "epoch": 1.309536790510319,
      "grad_norm": 5.122255325317383,
      "learning_rate": 3.9269955536735124e-05,
      "loss": 0.8643,
      "step": 123700
    },
    {
      "epoch": 1.3105954340703256,
      "grad_norm": 4.9204559326171875,
      "learning_rate": 3.9301715011645136e-05,
      "loss": 0.8595,
      "step": 123800
    },
    {
      "epoch": 1.3116540776303323,
      "grad_norm": 4.832920074462891,
      "learning_rate": 3.9333474486555153e-05,
      "loss": 0.8556,
      "step": 123900
    },
    {
      "epoch": 1.3127127211903389,
      "grad_norm": 4.967505931854248,
      "learning_rate": 3.9365233961465165e-05,
      "loss": 0.8696,
      "step": 124000
    },
    {
      "epoch": 1.3127127211903389,
      "eval_loss": 0.7144829630851746,
      "eval_runtime": 57.2204,
      "eval_samples_per_second": 2934.791,
      "eval_steps_per_second": 366.862,
      "step": 124000
    },
    {
      "epoch": 1.3137713647503455,
      "grad_norm": 5.078064441680908,
      "learning_rate": 3.939699343637518e-05,
      "loss": 0.8644,
      "step": 124100
    },
    {
      "epoch": 1.314830008310352,
      "grad_norm": 5.070956707000732,
      "learning_rate": 3.9428752911285194e-05,
      "loss": 0.8564,
      "step": 124200
    },
    {
      "epoch": 1.3158886518703585,
      "grad_norm": 5.032500743865967,
      "learning_rate": 3.946051238619521e-05,
      "loss": 0.8518,
      "step": 124300
    },
    {
      "epoch": 1.3169472954303652,
      "grad_norm": 4.541250705718994,
      "learning_rate": 3.9491954266356125e-05,
      "loss": 0.8706,
      "step": 124400
    },
    {
      "epoch": 1.3180059389903716,
      "grad_norm": 4.246763706207275,
      "learning_rate": 3.952371374126614e-05,
      "loss": 0.8694,
      "step": 124500
    },
    {
      "epoch": 1.3190645825503782,
      "grad_norm": 5.080153942108154,
      "learning_rate": 3.9555473216176154e-05,
      "loss": 0.8615,
      "step": 124600
    },
    {
      "epoch": 1.3201232261103848,
      "grad_norm": 4.870337009429932,
      "learning_rate": 3.958723269108617e-05,
      "loss": 0.844,
      "step": 124700
    },
    {
      "epoch": 1.3211818696703914,
      "grad_norm": 4.71276330947876,
      "learning_rate": 3.9618992165996183e-05,
      "loss": 0.8412,
      "step": 124800
    },
    {
      "epoch": 1.3222405132303978,
      "grad_norm": 4.918514251708984,
      "learning_rate": 3.96507516409062e-05,
      "loss": 0.8552,
      "step": 124900
    },
    {
      "epoch": 1.3232991567904044,
      "grad_norm": 4.980179786682129,
      "learning_rate": 3.968251111581621e-05,
      "loss": 0.8397,
      "step": 125000
    },
    {
      "epoch": 1.3232991567904044,
      "eval_loss": 0.7028016448020935,
      "eval_runtime": 57.2609,
      "eval_samples_per_second": 2932.717,
      "eval_steps_per_second": 366.603,
      "step": 125000
    },
    {
      "epoch": 1.324357800350411,
      "grad_norm": 5.219299793243408,
      "learning_rate": 3.971427059072623e-05,
      "loss": 0.8486,
      "step": 125100
    },
    {
      "epoch": 1.3254164439104175,
      "grad_norm": 4.743536949157715,
      "learning_rate": 3.974603006563624e-05,
      "loss": 0.856,
      "step": 125200
    },
    {
      "epoch": 1.326475087470424,
      "grad_norm": 5.768863201141357,
      "learning_rate": 3.977778954054626e-05,
      "loss": 0.8535,
      "step": 125300
    },
    {
      "epoch": 1.3275337310304307,
      "grad_norm": 4.588894844055176,
      "learning_rate": 3.980954901545628e-05,
      "loss": 0.8453,
      "step": 125400
    },
    {
      "epoch": 1.3285923745904373,
      "grad_norm": 4.731173992156982,
      "learning_rate": 3.984130849036629e-05,
      "loss": 0.8552,
      "step": 125500
    },
    {
      "epoch": 1.329651018150444,
      "grad_norm": 4.97174596786499,
      "learning_rate": 3.9873067965276306e-05,
      "loss": 0.855,
      "step": 125600
    },
    {
      "epoch": 1.3307096617104504,
      "grad_norm": 4.927814960479736,
      "learning_rate": 3.990482744018632e-05,
      "loss": 0.8339,
      "step": 125700
    },
    {
      "epoch": 1.331768305270457,
      "grad_norm": 4.713958740234375,
      "learning_rate": 3.9936586915096335e-05,
      "loss": 0.8517,
      "step": 125800
    },
    {
      "epoch": 1.3328269488304636,
      "grad_norm": 4.4351630210876465,
      "learning_rate": 3.9968346390006347e-05,
      "loss": 0.8478,
      "step": 125900
    },
    {
      "epoch": 1.33388559239047,
      "grad_norm": 4.851820945739746,
      "learning_rate": 4.0000105864916364e-05,
      "loss": 0.8415,
      "step": 126000
    },
    {
      "epoch": 1.33388559239047,
      "eval_loss": 0.6987891793251038,
      "eval_runtime": 57.338,
      "eval_samples_per_second": 2928.772,
      "eval_steps_per_second": 366.11,
      "step": 126000
    },
    {
      "epoch": 1.3349442359504766,
      "grad_norm": 5.1326069831848145,
      "learning_rate": 4.0031865339826376e-05,
      "loss": 0.8451,
      "step": 126100
    },
    {
      "epoch": 1.3360028795104832,
      "grad_norm": 5.092447280883789,
      "learning_rate": 4.0063624814736394e-05,
      "loss": 0.8402,
      "step": 126200
    },
    {
      "epoch": 1.3370615230704899,
      "grad_norm": 5.087090015411377,
      "learning_rate": 4.0095384289646405e-05,
      "loss": 0.8384,
      "step": 126300
    },
    {
      "epoch": 1.3381201666304963,
      "grad_norm": 5.0500922203063965,
      "learning_rate": 4.012714376455642e-05,
      "loss": 0.8454,
      "step": 126400
    },
    {
      "epoch": 1.3391788101905029,
      "grad_norm": 5.156314373016357,
      "learning_rate": 4.0158903239466434e-05,
      "loss": 0.8473,
      "step": 126500
    },
    {
      "epoch": 1.3402374537505095,
      "grad_norm": 5.234172344207764,
      "learning_rate": 4.019066271437645e-05,
      "loss": 0.8362,
      "step": 126600
    },
    {
      "epoch": 1.341296097310516,
      "grad_norm": 5.10609245300293,
      "learning_rate": 4.022242218928646e-05,
      "loss": 0.8428,
      "step": 126700
    },
    {
      "epoch": 1.3423547408705225,
      "grad_norm": 4.880734443664551,
      "learning_rate": 4.025418166419648e-05,
      "loss": 0.8461,
      "step": 126800
    },
    {
      "epoch": 1.3434133844305292,
      "grad_norm": 4.927887439727783,
      "learning_rate": 4.028594113910649e-05,
      "loss": 0.8428,
      "step": 126900
    },
    {
      "epoch": 1.3444720279905358,
      "grad_norm": 4.879569053649902,
      "learning_rate": 4.031770061401651e-05,
      "loss": 0.8401,
      "step": 127000
    },
    {
      "epoch": 1.3444720279905358,
      "eval_loss": 0.6802302002906799,
      "eval_runtime": 57.3932,
      "eval_samples_per_second": 2925.955,
      "eval_steps_per_second": 365.757,
      "step": 127000
    },
    {
      "epoch": 1.3455306715505424,
      "grad_norm": 5.269286632537842,
      "learning_rate": 4.034946008892653e-05,
      "loss": 0.8418,
      "step": 127100
    },
    {
      "epoch": 1.3465893151105488,
      "grad_norm": 5.008642196655273,
      "learning_rate": 4.038121956383654e-05,
      "loss": 0.8361,
      "step": 127200
    },
    {
      "epoch": 1.3476479586705554,
      "grad_norm": 5.1041436195373535,
      "learning_rate": 4.0412979038746557e-05,
      "loss": 0.8246,
      "step": 127300
    },
    {
      "epoch": 1.348706602230562,
      "grad_norm": 5.242872714996338,
      "learning_rate": 4.044473851365657e-05,
      "loss": 0.825,
      "step": 127400
    },
    {
      "epoch": 1.3497652457905684,
      "grad_norm": 4.997116565704346,
      "learning_rate": 4.0476497988566586e-05,
      "loss": 0.8367,
      "step": 127500
    },
    {
      "epoch": 1.350823889350575,
      "grad_norm": 4.6305623054504395,
      "learning_rate": 4.05082574634766e-05,
      "loss": 0.8419,
      "step": 127600
    },
    {
      "epoch": 1.3518825329105817,
      "grad_norm": 5.232997417449951,
      "learning_rate": 4.0540016938386615e-05,
      "loss": 0.8354,
      "step": 127700
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 5.026101112365723,
      "learning_rate": 4.0571776413296626e-05,
      "loss": 0.8283,
      "step": 127800
    },
    {
      "epoch": 1.353999820030595,
      "grad_norm": 5.150323867797852,
      "learning_rate": 4.0603535888206644e-05,
      "loss": 0.8318,
      "step": 127900
    },
    {
      "epoch": 1.3550584635906013,
      "grad_norm": 4.566885471343994,
      "learning_rate": 4.0635295363116655e-05,
      "loss": 0.8231,
      "step": 128000
    },
    {
      "epoch": 1.3550584635906013,
      "eval_loss": 0.6717451810836792,
      "eval_runtime": 57.3855,
      "eval_samples_per_second": 2926.349,
      "eval_steps_per_second": 365.807,
      "step": 128000
    },
    {
      "epoch": 1.356117107150608,
      "grad_norm": 5.050841331481934,
      "learning_rate": 4.066705483802667e-05,
      "loss": 0.8307,
      "step": 128100
    },
    {
      "epoch": 1.3571757507106144,
      "grad_norm": 4.782276630401611,
      "learning_rate": 4.0698814312936684e-05,
      "loss": 0.8334,
      "step": 128200
    },
    {
      "epoch": 1.358234394270621,
      "grad_norm": 4.659464359283447,
      "learning_rate": 4.07305737878467e-05,
      "loss": 0.8135,
      "step": 128300
    },
    {
      "epoch": 1.3592930378306276,
      "grad_norm": 5.098333358764648,
      "learning_rate": 4.0762015668007616e-05,
      "loss": 0.8172,
      "step": 128400
    },
    {
      "epoch": 1.3603516813906342,
      "grad_norm": 5.379035472869873,
      "learning_rate": 4.0793775142917634e-05,
      "loss": 0.829,
      "step": 128500
    },
    {
      "epoch": 1.3614103249506408,
      "grad_norm": 5.029856204986572,
      "learning_rate": 4.0825534617827645e-05,
      "loss": 0.8223,
      "step": 128600
    },
    {
      "epoch": 1.3624689685106472,
      "grad_norm": 5.2783918380737305,
      "learning_rate": 4.085729409273766e-05,
      "loss": 0.8358,
      "step": 128700
    },
    {
      "epoch": 1.3635276120706539,
      "grad_norm": 4.5392961502075195,
      "learning_rate": 4.0889053567647674e-05,
      "loss": 0.8259,
      "step": 128800
    },
    {
      "epoch": 1.3645862556306605,
      "grad_norm": 4.905114650726318,
      "learning_rate": 4.092081304255769e-05,
      "loss": 0.8247,
      "step": 128900
    },
    {
      "epoch": 1.365644899190667,
      "grad_norm": 4.978336334228516,
      "learning_rate": 4.09525725174677e-05,
      "loss": 0.819,
      "step": 129000
    },
    {
      "epoch": 1.365644899190667,
      "eval_loss": 0.6626449823379517,
      "eval_runtime": 57.217,
      "eval_samples_per_second": 2934.968,
      "eval_steps_per_second": 366.884,
      "step": 129000
    },
    {
      "epoch": 1.3667035427506735,
      "grad_norm": 5.203851699829102,
      "learning_rate": 4.098433199237772e-05,
      "loss": 0.8226,
      "step": 129100
    },
    {
      "epoch": 1.3677621863106801,
      "grad_norm": 4.559260368347168,
      "learning_rate": 4.101609146728773e-05,
      "loss": 0.8162,
      "step": 129200
    },
    {
      "epoch": 1.3688208298706868,
      "grad_norm": 5.014102458953857,
      "learning_rate": 4.104785094219775e-05,
      "loss": 0.8144,
      "step": 129300
    },
    {
      "epoch": 1.3698794734306934,
      "grad_norm": 4.671160697937012,
      "learning_rate": 4.107961041710776e-05,
      "loss": 0.8077,
      "step": 129400
    },
    {
      "epoch": 1.3709381169906998,
      "grad_norm": 4.740516662597656,
      "learning_rate": 4.111136989201778e-05,
      "loss": 0.8195,
      "step": 129500
    },
    {
      "epoch": 1.3719967605507064,
      "grad_norm": 5.601657867431641,
      "learning_rate": 4.11431293669278e-05,
      "loss": 0.8199,
      "step": 129600
    },
    {
      "epoch": 1.3730554041107128,
      "grad_norm": 4.960109710693359,
      "learning_rate": 4.117488884183781e-05,
      "loss": 0.8123,
      "step": 129700
    },
    {
      "epoch": 1.3741140476707194,
      "grad_norm": 4.786811351776123,
      "learning_rate": 4.1206648316747826e-05,
      "loss": 0.8143,
      "step": 129800
    },
    {
      "epoch": 1.375172691230726,
      "grad_norm": 5.0374345779418945,
      "learning_rate": 4.123840779165784e-05,
      "loss": 0.8128,
      "step": 129900
    },
    {
      "epoch": 1.3762313347907327,
      "grad_norm": 4.897485256195068,
      "learning_rate": 4.1270167266567855e-05,
      "loss": 0.8244,
      "step": 130000
    },
    {
      "epoch": 1.3762313347907327,
      "eval_loss": 0.6563524603843689,
      "eval_runtime": 57.2858,
      "eval_samples_per_second": 2931.442,
      "eval_steps_per_second": 366.443,
      "step": 130000
    },
    {
      "epoch": 1.3772899783507393,
      "grad_norm": 4.8972487449646,
      "learning_rate": 4.1301926741477866e-05,
      "loss": 0.8217,
      "step": 130100
    },
    {
      "epoch": 1.3783486219107457,
      "grad_norm": 5.1868109703063965,
      "learning_rate": 4.1333686216387884e-05,
      "loss": 0.8131,
      "step": 130200
    },
    {
      "epoch": 1.3794072654707523,
      "grad_norm": 4.94716215133667,
      "learning_rate": 4.1365445691297895e-05,
      "loss": 0.8174,
      "step": 130300
    },
    {
      "epoch": 1.380465909030759,
      "grad_norm": 5.145591735839844,
      "learning_rate": 4.139688757145881e-05,
      "loss": 0.8051,
      "step": 130400
    },
    {
      "epoch": 1.3815245525907653,
      "grad_norm": 4.763559341430664,
      "learning_rate": 4.142864704636883e-05,
      "loss": 0.8069,
      "step": 130500
    },
    {
      "epoch": 1.382583196150772,
      "grad_norm": 5.45094633102417,
      "learning_rate": 4.146040652127884e-05,
      "loss": 0.8075,
      "step": 130600
    },
    {
      "epoch": 1.3836418397107786,
      "grad_norm": 4.935863018035889,
      "learning_rate": 4.1492165996188856e-05,
      "loss": 0.7976,
      "step": 130700
    },
    {
      "epoch": 1.3847004832707852,
      "grad_norm": 4.75486946105957,
      "learning_rate": 4.1523925471098874e-05,
      "loss": 0.798,
      "step": 130800
    },
    {
      "epoch": 1.3857591268307918,
      "grad_norm": 5.532531261444092,
      "learning_rate": 4.1555684946008885e-05,
      "loss": 0.8231,
      "step": 130900
    },
    {
      "epoch": 1.3868177703907982,
      "grad_norm": 4.8288750648498535,
      "learning_rate": 4.15874444209189e-05,
      "loss": 0.8027,
      "step": 131000
    },
    {
      "epoch": 1.3868177703907982,
      "eval_loss": 0.6440342664718628,
      "eval_runtime": 57.2547,
      "eval_samples_per_second": 2933.036,
      "eval_steps_per_second": 366.643,
      "step": 131000
    },
    {
      "epoch": 1.3878764139508049,
      "grad_norm": 4.959914207458496,
      "learning_rate": 4.1619203895828914e-05,
      "loss": 0.785,
      "step": 131100
    },
    {
      "epoch": 1.3889350575108115,
      "grad_norm": 4.754403114318848,
      "learning_rate": 4.165096337073893e-05,
      "loss": 0.7923,
      "step": 131200
    },
    {
      "epoch": 1.3899937010708179,
      "grad_norm": 5.198403835296631,
      "learning_rate": 4.168272284564894e-05,
      "loss": 0.8031,
      "step": 131300
    },
    {
      "epoch": 1.3910523446308245,
      "grad_norm": 5.364922046661377,
      "learning_rate": 4.171448232055896e-05,
      "loss": 0.8065,
      "step": 131400
    },
    {
      "epoch": 1.3921109881908311,
      "grad_norm": 4.7890214920043945,
      "learning_rate": 4.174624179546898e-05,
      "loss": 0.7988,
      "step": 131500
    },
    {
      "epoch": 1.3931696317508377,
      "grad_norm": 5.007669925689697,
      "learning_rate": 4.1778001270379e-05,
      "loss": 0.7974,
      "step": 131600
    },
    {
      "epoch": 1.3942282753108441,
      "grad_norm": 4.850435256958008,
      "learning_rate": 4.1809760745289015e-05,
      "loss": 0.7928,
      "step": 131700
    },
    {
      "epoch": 1.3952869188708508,
      "grad_norm": 5.0426130294799805,
      "learning_rate": 4.1841520220199026e-05,
      "loss": 0.7992,
      "step": 131800
    },
    {
      "epoch": 1.3963455624308574,
      "grad_norm": 5.072446346282959,
      "learning_rate": 4.1873279695109044e-05,
      "loss": 0.7962,
      "step": 131900
    },
    {
      "epoch": 1.3974042059908638,
      "grad_norm": 4.947597980499268,
      "learning_rate": 4.1905039170019055e-05,
      "loss": 0.797,
      "step": 132000
    },
    {
      "epoch": 1.3974042059908638,
      "eval_loss": 0.6361620426177979,
      "eval_runtime": 57.3195,
      "eval_samples_per_second": 2929.718,
      "eval_steps_per_second": 366.228,
      "step": 132000
    },
    {
      "epoch": 1.3984628495508704,
      "grad_norm": 4.882558345794678,
      "learning_rate": 4.193679864492907e-05,
      "loss": 0.8042,
      "step": 132100
    },
    {
      "epoch": 1.399521493110877,
      "grad_norm": 5.308872222900391,
      "learning_rate": 4.1968558119839084e-05,
      "loss": 0.7873,
      "step": 132200
    },
    {
      "epoch": 1.4005801366708837,
      "grad_norm": 5.0066328048706055,
      "learning_rate": 4.20003175947491e-05,
      "loss": 0.7959,
      "step": 132300
    },
    {
      "epoch": 1.4016387802308903,
      "grad_norm": 4.734037399291992,
      "learning_rate": 4.2031759474910016e-05,
      "loss": 0.7951,
      "step": 132400
    },
    {
      "epoch": 1.4026974237908967,
      "grad_norm": 4.628014087677002,
      "learning_rate": 4.206351894982003e-05,
      "loss": 0.7934,
      "step": 132500
    },
    {
      "epoch": 1.4037560673509033,
      "grad_norm": 4.997391223907471,
      "learning_rate": 4.2095278424730045e-05,
      "loss": 0.79,
      "step": 132600
    },
    {
      "epoch": 1.40481471091091,
      "grad_norm": 4.847594261169434,
      "learning_rate": 4.212703789964006e-05,
      "loss": 0.7902,
      "step": 132700
    },
    {
      "epoch": 1.4058733544709163,
      "grad_norm": 5.134976387023926,
      "learning_rate": 4.2158797374550074e-05,
      "loss": 0.7918,
      "step": 132800
    },
    {
      "epoch": 1.406931998030923,
      "grad_norm": 5.091916561126709,
      "learning_rate": 4.219055684946009e-05,
      "loss": 0.7991,
      "step": 132900
    },
    {
      "epoch": 1.4079906415909296,
      "grad_norm": 4.938581466674805,
      "learning_rate": 4.2221998729621005e-05,
      "loss": 0.8003,
      "step": 133000
    },
    {
      "epoch": 1.4079906415909296,
      "eval_loss": 0.6292992234230042,
      "eval_runtime": 57.3156,
      "eval_samples_per_second": 2929.919,
      "eval_steps_per_second": 366.253,
      "step": 133000
    },
    {
      "epoch": 1.4090492851509362,
      "grad_norm": 4.691347122192383,
      "learning_rate": 4.225375820453102e-05,
      "loss": 0.7889,
      "step": 133100
    },
    {
      "epoch": 1.4101079287109426,
      "grad_norm": 5.358158588409424,
      "learning_rate": 4.2285517679441035e-05,
      "loss": 0.7897,
      "step": 133200
    },
    {
      "epoch": 1.4111665722709492,
      "grad_norm": 4.642705917358398,
      "learning_rate": 4.2317277154351046e-05,
      "loss": 0.7812,
      "step": 133300
    },
    {
      "epoch": 1.4122252158309558,
      "grad_norm": 5.270687580108643,
      "learning_rate": 4.2349036629261064e-05,
      "loss": 0.7851,
      "step": 133400
    },
    {
      "epoch": 1.4132838593909622,
      "grad_norm": 4.786347389221191,
      "learning_rate": 4.2380796104171075e-05,
      "loss": 0.7934,
      "step": 133500
    },
    {
      "epoch": 1.4143425029509689,
      "grad_norm": 4.890759468078613,
      "learning_rate": 4.241255557908109e-05,
      "loss": 0.7896,
      "step": 133600
    },
    {
      "epoch": 1.4154011465109755,
      "grad_norm": 4.188843250274658,
      "learning_rate": 4.2444315053991104e-05,
      "loss": 0.7858,
      "step": 133700
    },
    {
      "epoch": 1.416459790070982,
      "grad_norm": 4.442891597747803,
      "learning_rate": 4.247607452890112e-05,
      "loss": 0.7797,
      "step": 133800
    },
    {
      "epoch": 1.4175184336309887,
      "grad_norm": 4.974255084991455,
      "learning_rate": 4.250783400381114e-05,
      "loss": 0.7957,
      "step": 133900
    },
    {
      "epoch": 1.4185770771909951,
      "grad_norm": 5.048403739929199,
      "learning_rate": 4.253959347872115e-05,
      "loss": 0.7927,
      "step": 134000
    },
    {
      "epoch": 1.4185770771909951,
      "eval_loss": 0.6239010691642761,
      "eval_runtime": 57.3114,
      "eval_samples_per_second": 2930.132,
      "eval_steps_per_second": 366.28,
      "step": 134000
    },
    {
      "epoch": 1.4196357207510018,
      "grad_norm": 4.296745300292969,
      "learning_rate": 4.257135295363117e-05,
      "loss": 0.7924,
      "step": 134100
    },
    {
      "epoch": 1.4206943643110084,
      "grad_norm": 5.311954498291016,
      "learning_rate": 4.260311242854118e-05,
      "loss": 0.7741,
      "step": 134200
    },
    {
      "epoch": 1.4217530078710148,
      "grad_norm": 4.4793853759765625,
      "learning_rate": 4.26348719034512e-05,
      "loss": 0.7704,
      "step": 134300
    },
    {
      "epoch": 1.4228116514310214,
      "grad_norm": 4.878600120544434,
      "learning_rate": 4.266663137836121e-05,
      "loss": 0.7863,
      "step": 134400
    },
    {
      "epoch": 1.423870294991028,
      "grad_norm": 5.172128677368164,
      "learning_rate": 4.269839085327123e-05,
      "loss": 0.7725,
      "step": 134500
    },
    {
      "epoch": 1.4249289385510346,
      "grad_norm": 5.230839252471924,
      "learning_rate": 4.273015032818124e-05,
      "loss": 0.7814,
      "step": 134600
    },
    {
      "epoch": 1.425987582111041,
      "grad_norm": 4.5367231369018555,
      "learning_rate": 4.2761909803091256e-05,
      "loss": 0.7684,
      "step": 134700
    },
    {
      "epoch": 1.4270462256710477,
      "grad_norm": 5.267834186553955,
      "learning_rate": 4.279366927800127e-05,
      "loss": 0.7745,
      "step": 134800
    },
    {
      "epoch": 1.4281048692310543,
      "grad_norm": 4.353870391845703,
      "learning_rate": 4.2825428752911285e-05,
      "loss": 0.7721,
      "step": 134900
    },
    {
      "epoch": 1.4291635127910607,
      "grad_norm": 4.9866943359375,
      "learning_rate": 4.2857188227821296e-05,
      "loss": 0.7647,
      "step": 135000
    },
    {
      "epoch": 1.4291635127910607,
      "eval_loss": 0.6154741644859314,
      "eval_runtime": 57.3547,
      "eval_samples_per_second": 2927.921,
      "eval_steps_per_second": 366.003,
      "step": 135000
    },
    {
      "epoch": 1.4302221563510673,
      "grad_norm": 4.5809831619262695,
      "learning_rate": 4.2888947702731314e-05,
      "loss": 0.7769,
      "step": 135100
    },
    {
      "epoch": 1.431280799911074,
      "grad_norm": 5.599516868591309,
      "learning_rate": 4.2920707177641325e-05,
      "loss": 0.7716,
      "step": 135200
    },
    {
      "epoch": 1.4323394434710806,
      "grad_norm": 4.804141998291016,
      "learning_rate": 4.2952149057802246e-05,
      "loss": 0.7732,
      "step": 135300
    },
    {
      "epoch": 1.4333980870310872,
      "grad_norm": 4.869698524475098,
      "learning_rate": 4.298390853271226e-05,
      "loss": 0.7755,
      "step": 135400
    },
    {
      "epoch": 1.4344567305910936,
      "grad_norm": 4.772603511810303,
      "learning_rate": 4.3015668007622275e-05,
      "loss": 0.767,
      "step": 135500
    },
    {
      "epoch": 1.4355153741511002,
      "grad_norm": 4.799520492553711,
      "learning_rate": 4.3047427482532286e-05,
      "loss": 0.761,
      "step": 135600
    },
    {
      "epoch": 1.4365740177111068,
      "grad_norm": 4.714877605438232,
      "learning_rate": 4.3079186957442304e-05,
      "loss": 0.7572,
      "step": 135700
    },
    {
      "epoch": 1.4376326612711132,
      "grad_norm": 4.871632099151611,
      "learning_rate": 4.3110946432352315e-05,
      "loss": 0.7562,
      "step": 135800
    },
    {
      "epoch": 1.4386913048311198,
      "grad_norm": 4.772158145904541,
      "learning_rate": 4.314270590726233e-05,
      "loss": 0.7629,
      "step": 135900
    },
    {
      "epoch": 1.4397499483911265,
      "grad_norm": 4.795986652374268,
      "learning_rate": 4.3174465382172344e-05,
      "loss": 0.7665,
      "step": 136000
    },
    {
      "epoch": 1.4397499483911265,
      "eval_loss": 0.6073720455169678,
      "eval_runtime": 57.3496,
      "eval_samples_per_second": 2928.182,
      "eval_steps_per_second": 366.036,
      "step": 136000
    },
    {
      "epoch": 1.440808591951133,
      "grad_norm": 5.124373435974121,
      "learning_rate": 4.320622485708236e-05,
      "loss": 0.7597,
      "step": 136100
    },
    {
      "epoch": 1.4418672355111397,
      "grad_norm": 4.636497497558594,
      "learning_rate": 4.323798433199237e-05,
      "loss": 0.7627,
      "step": 136200
    },
    {
      "epoch": 1.4429258790711461,
      "grad_norm": 5.0400071144104,
      "learning_rate": 4.326974380690239e-05,
      "loss": 0.7643,
      "step": 136300
    },
    {
      "epoch": 1.4439845226311527,
      "grad_norm": 4.897978782653809,
      "learning_rate": 4.33015032818124e-05,
      "loss": 0.7604,
      "step": 136400
    },
    {
      "epoch": 1.4450431661911591,
      "grad_norm": 5.2198991775512695,
      "learning_rate": 4.333326275672242e-05,
      "loss": 0.7536,
      "step": 136500
    },
    {
      "epoch": 1.4461018097511658,
      "grad_norm": 4.717920303344727,
      "learning_rate": 4.336502223163244e-05,
      "loss": 0.7539,
      "step": 136600
    },
    {
      "epoch": 1.4471604533111724,
      "grad_norm": 5.422501087188721,
      "learning_rate": 4.339678170654245e-05,
      "loss": 0.7569,
      "step": 136700
    },
    {
      "epoch": 1.448219096871179,
      "grad_norm": 4.879487991333008,
      "learning_rate": 4.342854118145247e-05,
      "loss": 0.762,
      "step": 136800
    },
    {
      "epoch": 1.4492777404311856,
      "grad_norm": 5.636409282684326,
      "learning_rate": 4.346030065636248e-05,
      "loss": 0.7559,
      "step": 136900
    },
    {
      "epoch": 1.450336383991192,
      "grad_norm": 4.5752787590026855,
      "learning_rate": 4.3492060131272496e-05,
      "loss": 0.7627,
      "step": 137000
    },
    {
      "epoch": 1.450336383991192,
      "eval_loss": 0.5987229943275452,
      "eval_runtime": 57.3315,
      "eval_samples_per_second": 2929.108,
      "eval_steps_per_second": 366.152,
      "step": 137000
    },
    {
      "epoch": 1.4513950275511986,
      "grad_norm": 4.860352516174316,
      "learning_rate": 4.352381960618251e-05,
      "loss": 0.7627,
      "step": 137100
    },
    {
      "epoch": 1.4524536711112053,
      "grad_norm": 4.877094268798828,
      "learning_rate": 4.3555579081092525e-05,
      "loss": 0.7513,
      "step": 137200
    },
    {
      "epoch": 1.4535123146712117,
      "grad_norm": 4.740148067474365,
      "learning_rate": 4.3587338556002536e-05,
      "loss": 0.7564,
      "step": 137300
    },
    {
      "epoch": 1.4545709582312183,
      "grad_norm": 4.994671821594238,
      "learning_rate": 4.361878043616345e-05,
      "loss": 0.7555,
      "step": 137400
    },
    {
      "epoch": 1.455629601791225,
      "grad_norm": 4.812590599060059,
      "learning_rate": 4.365053991107347e-05,
      "loss": 0.7441,
      "step": 137500
    },
    {
      "epoch": 1.4566882453512315,
      "grad_norm": 4.620763778686523,
      "learning_rate": 4.3682299385983486e-05,
      "loss": 0.7584,
      "step": 137600
    },
    {
      "epoch": 1.4577468889112382,
      "grad_norm": 4.936166286468506,
      "learning_rate": 4.37140588608935e-05,
      "loss": 0.7658,
      "step": 137700
    },
    {
      "epoch": 1.4588055324712446,
      "grad_norm": 5.03753137588501,
      "learning_rate": 4.3745818335803515e-05,
      "loss": 0.7523,
      "step": 137800
    },
    {
      "epoch": 1.4598641760312512,
      "grad_norm": 5.186310291290283,
      "learning_rate": 4.3777577810713526e-05,
      "loss": 0.7559,
      "step": 137900
    },
    {
      "epoch": 1.4609228195912578,
      "grad_norm": 4.8216657638549805,
      "learning_rate": 4.3809337285623544e-05,
      "loss": 0.7474,
      "step": 138000
    },
    {
      "epoch": 1.4609228195912578,
      "eval_loss": 0.5937603712081909,
      "eval_runtime": 57.3908,
      "eval_samples_per_second": 2926.081,
      "eval_steps_per_second": 365.773,
      "step": 138000
    },
    {
      "epoch": 1.4619814631512642,
      "grad_norm": 4.437466621398926,
      "learning_rate": 4.3841096760533555e-05,
      "loss": 0.7496,
      "step": 138100
    },
    {
      "epoch": 1.4630401067112708,
      "grad_norm": 5.422018051147461,
      "learning_rate": 4.387285623544357e-05,
      "loss": 0.7563,
      "step": 138200
    },
    {
      "epoch": 1.4640987502712774,
      "grad_norm": 4.6306071281433105,
      "learning_rate": 4.3904615710353584e-05,
      "loss": 0.7508,
      "step": 138300
    },
    {
      "epoch": 1.465157393831284,
      "grad_norm": 5.016623020172119,
      "learning_rate": 4.39363751852636e-05,
      "loss": 0.7495,
      "step": 138400
    },
    {
      "epoch": 1.4662160373912905,
      "grad_norm": 4.968000411987305,
      "learning_rate": 4.396813466017361e-05,
      "loss": 0.7533,
      "step": 138500
    },
    {
      "epoch": 1.467274680951297,
      "grad_norm": 4.50085973739624,
      "learning_rate": 4.399989413508363e-05,
      "loss": 0.7424,
      "step": 138600
    },
    {
      "epoch": 1.4683333245113037,
      "grad_norm": 5.315695762634277,
      "learning_rate": 4.403165360999364e-05,
      "loss": 0.7431,
      "step": 138700
    },
    {
      "epoch": 1.4693919680713101,
      "grad_norm": 4.38518762588501,
      "learning_rate": 4.406341308490366e-05,
      "loss": 0.7472,
      "step": 138800
    },
    {
      "epoch": 1.4704506116313167,
      "grad_norm": 5.000539302825928,
      "learning_rate": 4.409517255981367e-05,
      "loss": 0.7457,
      "step": 138900
    },
    {
      "epoch": 1.4715092551913234,
      "grad_norm": 5.349013805389404,
      "learning_rate": 4.412693203472369e-05,
      "loss": 0.751,
      "step": 139000
    },
    {
      "epoch": 1.4715092551913234,
      "eval_loss": 0.5835283398628235,
      "eval_runtime": 57.43,
      "eval_samples_per_second": 2924.081,
      "eval_steps_per_second": 365.523,
      "step": 139000
    },
    {
      "epoch": 1.47256789875133,
      "grad_norm": 4.686820983886719,
      "learning_rate": 4.415869150963371e-05,
      "loss": 0.7512,
      "step": 139100
    },
    {
      "epoch": 1.4736265423113366,
      "grad_norm": 5.32411527633667,
      "learning_rate": 4.419045098454372e-05,
      "loss": 0.7392,
      "step": 139200
    },
    {
      "epoch": 1.474685185871343,
      "grad_norm": 4.7791666984558105,
      "learning_rate": 4.4222210459453736e-05,
      "loss": 0.7382,
      "step": 139300
    },
    {
      "epoch": 1.4757438294313496,
      "grad_norm": 5.026553630828857,
      "learning_rate": 4.425396993436375e-05,
      "loss": 0.7497,
      "step": 139400
    },
    {
      "epoch": 1.4768024729913563,
      "grad_norm": 5.097016334533691,
      "learning_rate": 4.4285729409273765e-05,
      "loss": 0.738,
      "step": 139500
    },
    {
      "epoch": 1.4778611165513627,
      "grad_norm": 4.782561302185059,
      "learning_rate": 4.4317488884183776e-05,
      "loss": 0.7406,
      "step": 139600
    },
    {
      "epoch": 1.4789197601113693,
      "grad_norm": 4.380320072174072,
      "learning_rate": 4.4349248359093794e-05,
      "loss": 0.7378,
      "step": 139700
    },
    {
      "epoch": 1.479978403671376,
      "grad_norm": 4.490348815917969,
      "learning_rate": 4.4381007834003805e-05,
      "loss": 0.7461,
      "step": 139800
    },
    {
      "epoch": 1.4810370472313825,
      "grad_norm": 4.866335868835449,
      "learning_rate": 4.441276730891382e-05,
      "loss": 0.7461,
      "step": 139900
    },
    {
      "epoch": 1.482095690791389,
      "grad_norm": 4.722770690917969,
      "learning_rate": 4.4444526783823834e-05,
      "loss": 0.7378,
      "step": 140000
    },
    {
      "epoch": 1.482095690791389,
      "eval_loss": 0.5754920840263367,
      "eval_runtime": 57.4458,
      "eval_samples_per_second": 2923.276,
      "eval_steps_per_second": 365.423,
      "step": 140000
    },
    {
      "epoch": 1.4831543343513955,
      "grad_norm": 5.369462966918945,
      "learning_rate": 4.447628625873385e-05,
      "loss": 0.7478,
      "step": 140100
    },
    {
      "epoch": 1.4842129779114022,
      "grad_norm": 4.759352684020996,
      "learning_rate": 4.450804573364386e-05,
      "loss": 0.7421,
      "step": 140200
    },
    {
      "epoch": 1.4852716214714086,
      "grad_norm": 4.82321834564209,
      "learning_rate": 4.453980520855388e-05,
      "loss": 0.7372,
      "step": 140300
    },
    {
      "epoch": 1.4863302650314152,
      "grad_norm": 5.279195785522461,
      "learning_rate": 4.457156468346389e-05,
      "loss": 0.7337,
      "step": 140400
    },
    {
      "epoch": 1.4873889085914218,
      "grad_norm": 4.971400260925293,
      "learning_rate": 4.460332415837391e-05,
      "loss": 0.737,
      "step": 140500
    },
    {
      "epoch": 1.4884475521514284,
      "grad_norm": 5.450503826141357,
      "learning_rate": 4.463508363328392e-05,
      "loss": 0.7226,
      "step": 140600
    },
    {
      "epoch": 1.489506195711435,
      "grad_norm": 4.878630638122559,
      "learning_rate": 4.466684310819394e-05,
      "loss": 0.7389,
      "step": 140700
    },
    {
      "epoch": 1.4905648392714415,
      "grad_norm": 4.629794120788574,
      "learning_rate": 4.469860258310396e-05,
      "loss": 0.7294,
      "step": 140800
    },
    {
      "epoch": 1.491623482831448,
      "grad_norm": 4.771084785461426,
      "learning_rate": 4.473036205801397e-05,
      "loss": 0.7319,
      "step": 140900
    },
    {
      "epoch": 1.4926821263914547,
      "grad_norm": 4.988643169403076,
      "learning_rate": 4.4762121532923986e-05,
      "loss": 0.7236,
      "step": 141000
    },
    {
      "epoch": 1.4926821263914547,
      "eval_loss": 0.5666747689247131,
      "eval_runtime": 57.255,
      "eval_samples_per_second": 2933.021,
      "eval_steps_per_second": 366.641,
      "step": 141000
    },
    {
      "epoch": 1.493740769951461,
      "grad_norm": 4.798040390014648,
      "learning_rate": 4.4793881007834e-05,
      "loss": 0.7304,
      "step": 141100
    },
    {
      "epoch": 1.4947994135114677,
      "grad_norm": 4.589616775512695,
      "learning_rate": 4.4825640482744015e-05,
      "loss": 0.7274,
      "step": 141200
    },
    {
      "epoch": 1.4958580570714743,
      "grad_norm": 4.997782230377197,
      "learning_rate": 4.4857399957654026e-05,
      "loss": 0.7372,
      "step": 141300
    },
    {
      "epoch": 1.496916700631481,
      "grad_norm": 5.12446928024292,
      "learning_rate": 4.488884183781494e-05,
      "loss": 0.7197,
      "step": 141400
    },
    {
      "epoch": 1.4979753441914874,
      "grad_norm": 5.562687397003174,
      "learning_rate": 4.492060131272496e-05,
      "loss": 0.7239,
      "step": 141500
    },
    {
      "epoch": 1.499033987751494,
      "grad_norm": 5.384770393371582,
      "learning_rate": 4.495236078763497e-05,
      "loss": 0.7362,
      "step": 141600
    },
    {
      "epoch": 1.5000926313115006,
      "grad_norm": 4.757209300994873,
      "learning_rate": 4.498412026254499e-05,
      "loss": 0.7253,
      "step": 141700
    },
    {
      "epoch": 1.501151274871507,
      "grad_norm": 4.5217766761779785,
      "learning_rate": 4.5015879737455005e-05,
      "loss": 0.7204,
      "step": 141800
    },
    {
      "epoch": 1.5022099184315136,
      "grad_norm": 5.054485321044922,
      "learning_rate": 4.5047639212365016e-05,
      "loss": 0.7369,
      "step": 141900
    },
    {
      "epoch": 1.5032685619915203,
      "grad_norm": 4.671960353851318,
      "learning_rate": 4.5079398687275034e-05,
      "loss": 0.7185,
      "step": 142000
    },
    {
      "epoch": 1.5032685619915203,
      "eval_loss": 0.5659932494163513,
      "eval_runtime": 57.451,
      "eval_samples_per_second": 2923.014,
      "eval_steps_per_second": 365.39,
      "step": 142000
    },
    {
      "epoch": 1.5043272055515269,
      "grad_norm": 5.186501502990723,
      "learning_rate": 4.5111158162185045e-05,
      "loss": 0.7276,
      "step": 142100
    },
    {
      "epoch": 1.5053858491115335,
      "grad_norm": 5.184037685394287,
      "learning_rate": 4.514291763709506e-05,
      "loss": 0.721,
      "step": 142200
    },
    {
      "epoch": 1.50644449267154,
      "grad_norm": 4.4551801681518555,
      "learning_rate": 4.5174677112005074e-05,
      "loss": 0.7249,
      "step": 142300
    },
    {
      "epoch": 1.5075031362315465,
      "grad_norm": 4.978799819946289,
      "learning_rate": 4.520643658691509e-05,
      "loss": 0.7213,
      "step": 142400
    },
    {
      "epoch": 1.508561779791553,
      "grad_norm": 4.084186553955078,
      "learning_rate": 4.52381960618251e-05,
      "loss": 0.7251,
      "step": 142500
    },
    {
      "epoch": 1.5096204233515595,
      "grad_norm": 5.021059036254883,
      "learning_rate": 4.526995553673512e-05,
      "loss": 0.7232,
      "step": 142600
    },
    {
      "epoch": 1.5106790669115662,
      "grad_norm": 4.378058910369873,
      "learning_rate": 4.530171501164513e-05,
      "loss": 0.7291,
      "step": 142700
    },
    {
      "epoch": 1.5117377104715728,
      "grad_norm": 4.956527233123779,
      "learning_rate": 4.533347448655515e-05,
      "loss": 0.7209,
      "step": 142800
    },
    {
      "epoch": 1.5127963540315794,
      "grad_norm": 4.734280586242676,
      "learning_rate": 4.536523396146516e-05,
      "loss": 0.7207,
      "step": 142900
    },
    {
      "epoch": 1.513854997591586,
      "grad_norm": 4.557044506072998,
      "learning_rate": 4.539699343637518e-05,
      "loss": 0.7267,
      "step": 143000
    },
    {
      "epoch": 1.513854997591586,
      "eval_loss": 0.5592280030250549,
      "eval_runtime": 57.4272,
      "eval_samples_per_second": 2924.225,
      "eval_steps_per_second": 365.541,
      "step": 143000
    },
    {
      "epoch": 1.5149136411515924,
      "grad_norm": 5.2792439460754395,
      "learning_rate": 4.542875291128519e-05,
      "loss": 0.7186,
      "step": 143100
    },
    {
      "epoch": 1.515972284711599,
      "grad_norm": 5.033910751342773,
      "learning_rate": 4.546051238619521e-05,
      "loss": 0.7165,
      "step": 143200
    },
    {
      "epoch": 1.5170309282716055,
      "grad_norm": 5.521577835083008,
      "learning_rate": 4.5492271861105226e-05,
      "loss": 0.72,
      "step": 143300
    },
    {
      "epoch": 1.518089571831612,
      "grad_norm": 4.625704288482666,
      "learning_rate": 4.552371374126614e-05,
      "loss": 0.7116,
      "step": 143400
    },
    {
      "epoch": 1.5191482153916187,
      "grad_norm": 5.052796363830566,
      "learning_rate": 4.555547321617615e-05,
      "loss": 0.7179,
      "step": 143500
    },
    {
      "epoch": 1.5202068589516253,
      "grad_norm": 5.292398452758789,
      "learning_rate": 4.558723269108617e-05,
      "loss": 0.7129,
      "step": 143600
    },
    {
      "epoch": 1.521265502511632,
      "grad_norm": 4.316315174102783,
      "learning_rate": 4.561899216599618e-05,
      "loss": 0.7138,
      "step": 143700
    },
    {
      "epoch": 1.5223241460716386,
      "grad_norm": 4.9513115882873535,
      "learning_rate": 4.56507516409062e-05,
      "loss": 0.7243,
      "step": 143800
    },
    {
      "epoch": 1.523382789631645,
      "grad_norm": 5.252756118774414,
      "learning_rate": 4.568251111581621e-05,
      "loss": 0.7178,
      "step": 143900
    },
    {
      "epoch": 1.5244414331916514,
      "grad_norm": 4.272768974304199,
      "learning_rate": 4.571427059072623e-05,
      "loss": 0.7196,
      "step": 144000
    },
    {
      "epoch": 1.5244414331916514,
      "eval_loss": 0.5520901083946228,
      "eval_runtime": 57.3252,
      "eval_samples_per_second": 2929.425,
      "eval_steps_per_second": 366.191,
      "step": 144000
    },
    {
      "epoch": 1.525500076751658,
      "grad_norm": 5.022268772125244,
      "learning_rate": 4.574603006563624e-05,
      "loss": 0.7041,
      "step": 144100
    },
    {
      "epoch": 1.5265587203116646,
      "grad_norm": 4.479169845581055,
      "learning_rate": 4.5777789540546256e-05,
      "loss": 0.7179,
      "step": 144200
    },
    {
      "epoch": 1.5276173638716712,
      "grad_norm": 4.9567551612854,
      "learning_rate": 4.580954901545627e-05,
      "loss": 0.7125,
      "step": 144300
    },
    {
      "epoch": 1.5286760074316779,
      "grad_norm": 4.623400688171387,
      "learning_rate": 4.5841308490366285e-05,
      "loss": 0.7065,
      "step": 144400
    },
    {
      "epoch": 1.5297346509916845,
      "grad_norm": 5.6298747062683105,
      "learning_rate": 4.58730679652763e-05,
      "loss": 0.7134,
      "step": 144500
    },
    {
      "epoch": 1.5307932945516909,
      "grad_norm": 4.759365081787109,
      "learning_rate": 4.5904827440186314e-05,
      "loss": 0.713,
      "step": 144600
    },
    {
      "epoch": 1.5318519381116975,
      "grad_norm": 5.120285987854004,
      "learning_rate": 4.593658691509633e-05,
      "loss": 0.7158,
      "step": 144700
    },
    {
      "epoch": 1.532910581671704,
      "grad_norm": 5.0217180252075195,
      "learning_rate": 4.596834639000634e-05,
      "loss": 0.7108,
      "step": 144800
    },
    {
      "epoch": 1.5339692252317105,
      "grad_norm": 4.560394763946533,
      "learning_rate": 4.600010586491636e-05,
      "loss": 0.7082,
      "step": 144900
    },
    {
      "epoch": 1.5350278687917172,
      "grad_norm": 4.7881011962890625,
      "learning_rate": 4.603186533982637e-05,
      "loss": 0.7033,
      "step": 145000
    },
    {
      "epoch": 1.5350278687917172,
      "eval_loss": 0.5440687537193298,
      "eval_runtime": 57.28,
      "eval_samples_per_second": 2931.741,
      "eval_steps_per_second": 366.481,
      "step": 145000
    },
    {
      "epoch": 1.5360865123517238,
      "grad_norm": 5.038864612579346,
      "learning_rate": 4.606362481473639e-05,
      "loss": 0.7082,
      "step": 145100
    },
    {
      "epoch": 1.5371451559117304,
      "grad_norm": 4.962647914886475,
      "learning_rate": 4.60953842896464e-05,
      "loss": 0.7123,
      "step": 145200
    },
    {
      "epoch": 1.538203799471737,
      "grad_norm": 4.564509868621826,
      "learning_rate": 4.612714376455642e-05,
      "loss": 0.704,
      "step": 145300
    },
    {
      "epoch": 1.5392624430317434,
      "grad_norm": 5.082517147064209,
      "learning_rate": 4.615858564471733e-05,
      "loss": 0.6969,
      "step": 145400
    },
    {
      "epoch": 1.54032108659175,
      "grad_norm": 4.653710842132568,
      "learning_rate": 4.6190345119627344e-05,
      "loss": 0.7102,
      "step": 145500
    },
    {
      "epoch": 1.5413797301517564,
      "grad_norm": 4.804566383361816,
      "learning_rate": 4.622210459453736e-05,
      "loss": 0.7009,
      "step": 145600
    },
    {
      "epoch": 1.542438373711763,
      "grad_norm": 5.043115139007568,
      "learning_rate": 4.625386406944738e-05,
      "loss": 0.7017,
      "step": 145700
    },
    {
      "epoch": 1.5434970172717697,
      "grad_norm": 5.256414413452148,
      "learning_rate": 4.628562354435739e-05,
      "loss": 0.702,
      "step": 145800
    },
    {
      "epoch": 1.5445556608317763,
      "grad_norm": 4.7242045402526855,
      "learning_rate": 4.631738301926741e-05,
      "loss": 0.6993,
      "step": 145900
    },
    {
      "epoch": 1.545614304391783,
      "grad_norm": 4.459592819213867,
      "learning_rate": 4.634914249417742e-05,
      "loss": 0.7043,
      "step": 146000
    },
    {
      "epoch": 1.545614304391783,
      "eval_loss": 0.5390843749046326,
      "eval_runtime": 57.3661,
      "eval_samples_per_second": 2927.338,
      "eval_steps_per_second": 365.93,
      "step": 146000
    },
    {
      "epoch": 1.5466729479517893,
      "grad_norm": 4.236850738525391,
      "learning_rate": 4.6380901969087445e-05,
      "loss": 0.6867,
      "step": 146100
    },
    {
      "epoch": 1.547731591511796,
      "grad_norm": 4.892996788024902,
      "learning_rate": 4.6412661443997456e-05,
      "loss": 0.6999,
      "step": 146200
    },
    {
      "epoch": 1.5487902350718024,
      "grad_norm": 4.612391471862793,
      "learning_rate": 4.6444420918907474e-05,
      "loss": 0.7007,
      "step": 146300
    },
    {
      "epoch": 1.549848878631809,
      "grad_norm": 5.104673385620117,
      "learning_rate": 4.647618039381749e-05,
      "loss": 0.7086,
      "step": 146400
    },
    {
      "epoch": 1.5509075221918156,
      "grad_norm": 4.85957145690918,
      "learning_rate": 4.65079398687275e-05,
      "loss": 0.6889,
      "step": 146500
    },
    {
      "epoch": 1.5519661657518222,
      "grad_norm": 4.466153144836426,
      "learning_rate": 4.653969934363752e-05,
      "loss": 0.6857,
      "step": 146600
    },
    {
      "epoch": 1.5530248093118288,
      "grad_norm": 4.904584884643555,
      "learning_rate": 4.657145881854753e-05,
      "loss": 0.6946,
      "step": 146700
    },
    {
      "epoch": 1.5540834528718355,
      "grad_norm": 4.753983497619629,
      "learning_rate": 4.660321829345755e-05,
      "loss": 0.6927,
      "step": 146800
    },
    {
      "epoch": 1.5551420964318419,
      "grad_norm": 4.944286823272705,
      "learning_rate": 4.663497776836756e-05,
      "loss": 0.6985,
      "step": 146900
    },
    {
      "epoch": 1.5562007399918485,
      "grad_norm": 4.789067268371582,
      "learning_rate": 4.666673724327758e-05,
      "loss": 0.7012,
      "step": 147000
    },
    {
      "epoch": 1.5562007399918485,
      "eval_loss": 0.5295260548591614,
      "eval_runtime": 57.3904,
      "eval_samples_per_second": 2926.1,
      "eval_steps_per_second": 365.776,
      "step": 147000
    },
    {
      "epoch": 1.557259383551855,
      "grad_norm": 4.870813369750977,
      "learning_rate": 4.669849671818759e-05,
      "loss": 0.6926,
      "step": 147100
    },
    {
      "epoch": 1.5583180271118615,
      "grad_norm": 5.067284107208252,
      "learning_rate": 4.673025619309761e-05,
      "loss": 0.7025,
      "step": 147200
    },
    {
      "epoch": 1.5593766706718681,
      "grad_norm": 4.8041486740112305,
      "learning_rate": 4.676201566800762e-05,
      "loss": 0.6821,
      "step": 147300
    },
    {
      "epoch": 1.5604353142318748,
      "grad_norm": 4.5774688720703125,
      "learning_rate": 4.679345754816853e-05,
      "loss": 0.6855,
      "step": 147400
    },
    {
      "epoch": 1.5614939577918814,
      "grad_norm": 4.501223087310791,
      "learning_rate": 4.6824899428329454e-05,
      "loss": 0.6891,
      "step": 147500
    },
    {
      "epoch": 1.5625526013518878,
      "grad_norm": 4.731302261352539,
      "learning_rate": 4.6856658903239465e-05,
      "loss": 0.6918,
      "step": 147600
    },
    {
      "epoch": 1.5636112449118944,
      "grad_norm": 4.790130615234375,
      "learning_rate": 4.688841837814948e-05,
      "loss": 0.6872,
      "step": 147700
    },
    {
      "epoch": 1.5646698884719008,
      "grad_norm": 5.418545246124268,
      "learning_rate": 4.6920177853059494e-05,
      "loss": 0.6977,
      "step": 147800
    },
    {
      "epoch": 1.5657285320319074,
      "grad_norm": 4.522089958190918,
      "learning_rate": 4.695193732796951e-05,
      "loss": 0.685,
      "step": 147900
    },
    {
      "epoch": 1.566787175591914,
      "grad_norm": 4.8675537109375,
      "learning_rate": 4.698369680287952e-05,
      "loss": 0.6936,
      "step": 148000
    },
    {
      "epoch": 1.566787175591914,
      "eval_loss": 0.5296651124954224,
      "eval_runtime": 57.2591,
      "eval_samples_per_second": 2932.81,
      "eval_steps_per_second": 366.614,
      "step": 148000
    },
    {
      "epoch": 1.5678458191519207,
      "grad_norm": 5.041847229003906,
      "learning_rate": 4.701545627778954e-05,
      "loss": 0.6994,
      "step": 148100
    },
    {
      "epoch": 1.5689044627119273,
      "grad_norm": 4.731666088104248,
      "learning_rate": 4.704721575269955e-05,
      "loss": 0.6906,
      "step": 148200
    },
    {
      "epoch": 1.569963106271934,
      "grad_norm": 4.551720142364502,
      "learning_rate": 4.707897522760957e-05,
      "loss": 0.6893,
      "step": 148300
    },
    {
      "epoch": 1.5710217498319403,
      "grad_norm": 5.071589469909668,
      "learning_rate": 4.711073470251958e-05,
      "loss": 0.6965,
      "step": 148400
    },
    {
      "epoch": 1.572080393391947,
      "grad_norm": 5.495957374572754,
      "learning_rate": 4.71424941774296e-05,
      "loss": 0.6868,
      "step": 148500
    },
    {
      "epoch": 1.5731390369519533,
      "grad_norm": 4.97885274887085,
      "learning_rate": 4.717425365233962e-05,
      "loss": 0.6927,
      "step": 148600
    },
    {
      "epoch": 1.57419768051196,
      "grad_norm": 4.886606216430664,
      "learning_rate": 4.720601312724963e-05,
      "loss": 0.686,
      "step": 148700
    },
    {
      "epoch": 1.5752563240719666,
      "grad_norm": 4.459373950958252,
      "learning_rate": 4.7237772602159646e-05,
      "loss": 0.6817,
      "step": 148800
    },
    {
      "epoch": 1.5763149676319732,
      "grad_norm": 4.683763027191162,
      "learning_rate": 4.726953207706966e-05,
      "loss": 0.6813,
      "step": 148900
    },
    {
      "epoch": 1.5773736111919798,
      "grad_norm": 4.631349563598633,
      "learning_rate": 4.7301291551979675e-05,
      "loss": 0.6808,
      "step": 149000
    },
    {
      "epoch": 1.5773736111919798,
      "eval_loss": 0.5249025821685791,
      "eval_runtime": 57.4585,
      "eval_samples_per_second": 2922.632,
      "eval_steps_per_second": 365.342,
      "step": 149000
    },
    {
      "epoch": 1.5784322547519862,
      "grad_norm": 4.900910377502441,
      "learning_rate": 4.7333051026889686e-05,
      "loss": 0.6828,
      "step": 149100
    },
    {
      "epoch": 1.5794908983119929,
      "grad_norm": 4.892309665679932,
      "learning_rate": 4.7364810501799704e-05,
      "loss": 0.6804,
      "step": 149200
    },
    {
      "epoch": 1.5805495418719993,
      "grad_norm": 5.028820991516113,
      "learning_rate": 4.7396569976709715e-05,
      "loss": 0.6836,
      "step": 149300
    },
    {
      "epoch": 1.5816081854320059,
      "grad_norm": 5.420009613037109,
      "learning_rate": 4.742832945161973e-05,
      "loss": 0.6825,
      "step": 149400
    },
    {
      "epoch": 1.5826668289920125,
      "grad_norm": 4.392528533935547,
      "learning_rate": 4.7460088926529744e-05,
      "loss": 0.6796,
      "step": 149500
    },
    {
      "epoch": 1.5837254725520191,
      "grad_norm": 4.791810035705566,
      "learning_rate": 4.749184840143976e-05,
      "loss": 0.679,
      "step": 149600
    },
    {
      "epoch": 1.5847841161120257,
      "grad_norm": 4.635990619659424,
      "learning_rate": 4.752360787634977e-05,
      "loss": 0.6837,
      "step": 149700
    },
    {
      "epoch": 1.5858427596720324,
      "grad_norm": 4.350774765014648,
      "learning_rate": 4.755536735125979e-05,
      "loss": 0.6806,
      "step": 149800
    },
    {
      "epoch": 1.5869014032320388,
      "grad_norm": 4.877251625061035,
      "learning_rate": 4.75871268261698e-05,
      "loss": 0.6889,
      "step": 149900
    },
    {
      "epoch": 1.5879600467920454,
      "grad_norm": 4.976214408874512,
      "learning_rate": 4.761888630107982e-05,
      "loss": 0.6825,
      "step": 150000
    },
    {
      "epoch": 1.5879600467920454,
      "eval_loss": 0.5139064788818359,
      "eval_runtime": 57.4133,
      "eval_samples_per_second": 2924.933,
      "eval_steps_per_second": 365.63,
      "step": 150000
    },
    {
      "epoch": 1.5890186903520518,
      "grad_norm": 5.115708827972412,
      "learning_rate": 4.765064577598983e-05,
      "loss": 0.6769,
      "step": 150100
    },
    {
      "epoch": 1.5900773339120584,
      "grad_norm": 4.397368907928467,
      "learning_rate": 4.768240525089985e-05,
      "loss": 0.6782,
      "step": 150200
    },
    {
      "epoch": 1.591135977472065,
      "grad_norm": 4.862668037414551,
      "learning_rate": 4.771416472580987e-05,
      "loss": 0.6694,
      "step": 150300
    },
    {
      "epoch": 1.5921946210320717,
      "grad_norm": 4.6081461906433105,
      "learning_rate": 4.774592420071988e-05,
      "loss": 0.672,
      "step": 150400
    },
    {
      "epoch": 1.5932532645920783,
      "grad_norm": 4.356149196624756,
      "learning_rate": 4.7777683675629896e-05,
      "loss": 0.678,
      "step": 150500
    },
    {
      "epoch": 1.594311908152085,
      "grad_norm": 4.85272216796875,
      "learning_rate": 4.780944315053991e-05,
      "loss": 0.6789,
      "step": 150600
    },
    {
      "epoch": 1.5953705517120913,
      "grad_norm": 5.197958946228027,
      "learning_rate": 4.7841202625449925e-05,
      "loss": 0.6731,
      "step": 150700
    },
    {
      "epoch": 1.5964291952720977,
      "grad_norm": 4.432925701141357,
      "learning_rate": 4.787264450561084e-05,
      "loss": 0.6794,
      "step": 150800
    },
    {
      "epoch": 1.5974878388321043,
      "grad_norm": 4.908413887023926,
      "learning_rate": 4.790440398052085e-05,
      "loss": 0.6706,
      "step": 150900
    },
    {
      "epoch": 1.598546482392111,
      "grad_norm": 4.51416540145874,
      "learning_rate": 4.793616345543087e-05,
      "loss": 0.6636,
      "step": 151000
    },
    {
      "epoch": 1.598546482392111,
      "eval_loss": 0.5083032846450806,
      "eval_runtime": 57.3836,
      "eval_samples_per_second": 2926.444,
      "eval_steps_per_second": 365.819,
      "step": 151000
    },
    {
      "epoch": 1.5996051259521176,
      "grad_norm": 4.640778064727783,
      "learning_rate": 4.796792293034088e-05,
      "loss": 0.6682,
      "step": 151100
    },
    {
      "epoch": 1.6006637695121242,
      "grad_norm": 4.5103302001953125,
      "learning_rate": 4.79996824052509e-05,
      "loss": 0.6749,
      "step": 151200
    },
    {
      "epoch": 1.6017224130721308,
      "grad_norm": 4.46018648147583,
      "learning_rate": 4.8031441880160915e-05,
      "loss": 0.6714,
      "step": 151300
    },
    {
      "epoch": 1.6027810566321372,
      "grad_norm": 4.351942539215088,
      "learning_rate": 4.8063201355070926e-05,
      "loss": 0.676,
      "step": 151400
    },
    {
      "epoch": 1.6038397001921438,
      "grad_norm": 4.699544906616211,
      "learning_rate": 4.8094960829980944e-05,
      "loss": 0.6754,
      "step": 151500
    },
    {
      "epoch": 1.6048983437521502,
      "grad_norm": 4.59166955947876,
      "learning_rate": 4.8126720304890955e-05,
      "loss": 0.6659,
      "step": 151600
    },
    {
      "epoch": 1.6059569873121569,
      "grad_norm": 4.944070339202881,
      "learning_rate": 4.815847977980097e-05,
      "loss": 0.6661,
      "step": 151700
    },
    {
      "epoch": 1.6070156308721635,
      "grad_norm": 4.675043106079102,
      "learning_rate": 4.8190239254710984e-05,
      "loss": 0.6698,
      "step": 151800
    },
    {
      "epoch": 1.60807427443217,
      "grad_norm": 5.261157512664795,
      "learning_rate": 4.8221998729621e-05,
      "loss": 0.6778,
      "step": 151900
    },
    {
      "epoch": 1.6091329179921767,
      "grad_norm": 4.625637054443359,
      "learning_rate": 4.825375820453101e-05,
      "loss": 0.6706,
      "step": 152000
    },
    {
      "epoch": 1.6091329179921767,
      "eval_loss": 0.5049471259117126,
      "eval_runtime": 57.4956,
      "eval_samples_per_second": 2920.745,
      "eval_steps_per_second": 365.106,
      "step": 152000
    },
    {
      "epoch": 1.6101915615521833,
      "grad_norm": 4.856318950653076,
      "learning_rate": 4.828551767944103e-05,
      "loss": 0.6718,
      "step": 152100
    },
    {
      "epoch": 1.6112502051121897,
      "grad_norm": 4.882221698760986,
      "learning_rate": 4.831727715435104e-05,
      "loss": 0.6679,
      "step": 152200
    },
    {
      "epoch": 1.6123088486721961,
      "grad_norm": 4.8946380615234375,
      "learning_rate": 4.834903662926106e-05,
      "loss": 0.683,
      "step": 152300
    },
    {
      "epoch": 1.6133674922322028,
      "grad_norm": 4.5257248878479,
      "learning_rate": 4.838079610417107e-05,
      "loss": 0.6746,
      "step": 152400
    },
    {
      "epoch": 1.6144261357922094,
      "grad_norm": 4.827046871185303,
      "learning_rate": 4.841255557908109e-05,
      "loss": 0.6719,
      "step": 152500
    },
    {
      "epoch": 1.615484779352216,
      "grad_norm": 4.287778377532959,
      "learning_rate": 4.84443150539911e-05,
      "loss": 0.6592,
      "step": 152600
    },
    {
      "epoch": 1.6165434229122226,
      "grad_norm": 4.543097496032715,
      "learning_rate": 4.847607452890112e-05,
      "loss": 0.661,
      "step": 152700
    },
    {
      "epoch": 1.6176020664722293,
      "grad_norm": 4.961312294006348,
      "learning_rate": 4.8507834003811136e-05,
      "loss": 0.6587,
      "step": 152800
    },
    {
      "epoch": 1.6186607100322357,
      "grad_norm": 5.678182125091553,
      "learning_rate": 4.853959347872115e-05,
      "loss": 0.665,
      "step": 152900
    },
    {
      "epoch": 1.6197193535922423,
      "grad_norm": 4.271110534667969,
      "learning_rate": 4.8571352953631165e-05,
      "loss": 0.6635,
      "step": 153000
    },
    {
      "epoch": 1.6197193535922423,
      "eval_loss": 0.5003327131271362,
      "eval_runtime": 57.3725,
      "eval_samples_per_second": 2927.011,
      "eval_steps_per_second": 365.889,
      "step": 153000
    },
    {
      "epoch": 1.6207779971522487,
      "grad_norm": 5.089589595794678,
      "learning_rate": 4.860279483379208e-05,
      "loss": 0.6581,
      "step": 153100
    },
    {
      "epoch": 1.6218366407122553,
      "grad_norm": 4.902451038360596,
      "learning_rate": 4.863455430870209e-05,
      "loss": 0.6691,
      "step": 153200
    },
    {
      "epoch": 1.622895284272262,
      "grad_norm": 4.811267852783203,
      "learning_rate": 4.866631378361211e-05,
      "loss": 0.6625,
      "step": 153300
    },
    {
      "epoch": 1.6239539278322686,
      "grad_norm": 4.181025505065918,
      "learning_rate": 4.869807325852212e-05,
      "loss": 0.6563,
      "step": 153400
    },
    {
      "epoch": 1.6250125713922752,
      "grad_norm": 4.556618690490723,
      "learning_rate": 4.872983273343214e-05,
      "loss": 0.6634,
      "step": 153500
    },
    {
      "epoch": 1.6260712149522818,
      "grad_norm": 4.450497627258301,
      "learning_rate": 4.876159220834215e-05,
      "loss": 0.6631,
      "step": 153600
    },
    {
      "epoch": 1.6271298585122882,
      "grad_norm": 4.979936599731445,
      "learning_rate": 4.8793351683252166e-05,
      "loss": 0.6512,
      "step": 153700
    },
    {
      "epoch": 1.6281885020722948,
      "grad_norm": 4.685699939727783,
      "learning_rate": 4.882511115816218e-05,
      "loss": 0.6549,
      "step": 153800
    },
    {
      "epoch": 1.6292471456323012,
      "grad_norm": 4.8082380294799805,
      "learning_rate": 4.8856870633072195e-05,
      "loss": 0.6675,
      "step": 153900
    },
    {
      "epoch": 1.6303057891923078,
      "grad_norm": 4.96472692489624,
      "learning_rate": 4.888863010798221e-05,
      "loss": 0.6551,
      "step": 154000
    },
    {
      "epoch": 1.6303057891923078,
      "eval_loss": 0.4918448030948639,
      "eval_runtime": 57.4653,
      "eval_samples_per_second": 2922.287,
      "eval_steps_per_second": 365.299,
      "step": 154000
    },
    {
      "epoch": 1.6313644327523145,
      "grad_norm": 4.881210803985596,
      "learning_rate": 4.8920389582892224e-05,
      "loss": 0.6623,
      "step": 154100
    },
    {
      "epoch": 1.632423076312321,
      "grad_norm": 4.498335838317871,
      "learning_rate": 4.895214905780224e-05,
      "loss": 0.6592,
      "step": 154200
    },
    {
      "epoch": 1.6334817198723277,
      "grad_norm": 4.742245197296143,
      "learning_rate": 4.8983908532712253e-05,
      "loss": 0.6588,
      "step": 154300
    },
    {
      "epoch": 1.634540363432334,
      "grad_norm": 4.507328987121582,
      "learning_rate": 4.901566800762227e-05,
      "loss": 0.6564,
      "step": 154400
    },
    {
      "epoch": 1.6355990069923407,
      "grad_norm": 4.649607181549072,
      "learning_rate": 4.904742748253228e-05,
      "loss": 0.6502,
      "step": 154500
    },
    {
      "epoch": 1.6366576505523471,
      "grad_norm": 4.696025371551514,
      "learning_rate": 4.90791869574423e-05,
      "loss": 0.6521,
      "step": 154600
    },
    {
      "epoch": 1.6377162941123538,
      "grad_norm": 4.639342784881592,
      "learning_rate": 4.911094643235231e-05,
      "loss": 0.6611,
      "step": 154700
    },
    {
      "epoch": 1.6387749376723604,
      "grad_norm": 4.341306686401367,
      "learning_rate": 4.914270590726233e-05,
      "loss": 0.6483,
      "step": 154800
    },
    {
      "epoch": 1.639833581232367,
      "grad_norm": 4.833172798156738,
      "learning_rate": 4.917446538217234e-05,
      "loss": 0.6518,
      "step": 154900
    },
    {
      "epoch": 1.6408922247923736,
      "grad_norm": 5.25850772857666,
      "learning_rate": 4.920622485708236e-05,
      "loss": 0.6501,
      "step": 155000
    },
    {
      "epoch": 1.6408922247923736,
      "eval_loss": 0.4891381859779358,
      "eval_runtime": 57.2953,
      "eval_samples_per_second": 2930.955,
      "eval_steps_per_second": 366.382,
      "step": 155000
    },
    {
      "epoch": 1.6419508683523802,
      "grad_norm": 4.703349590301514,
      "learning_rate": 4.923798433199237e-05,
      "loss": 0.6551,
      "step": 155100
    },
    {
      "epoch": 1.6430095119123866,
      "grad_norm": 4.65397834777832,
      "learning_rate": 4.926942621215329e-05,
      "loss": 0.6602,
      "step": 155200
    },
    {
      "epoch": 1.6440681554723933,
      "grad_norm": 4.7314910888671875,
      "learning_rate": 4.93011856870633e-05,
      "loss": 0.6551,
      "step": 155300
    },
    {
      "epoch": 1.6451267990323997,
      "grad_norm": 4.8818793296813965,
      "learning_rate": 4.933294516197332e-05,
      "loss": 0.6502,
      "step": 155400
    },
    {
      "epoch": 1.6461854425924063,
      "grad_norm": 3.5429341793060303,
      "learning_rate": 4.936470463688333e-05,
      "loss": 0.6554,
      "step": 155500
    },
    {
      "epoch": 1.647244086152413,
      "grad_norm": 4.60239839553833,
      "learning_rate": 4.939646411179335e-05,
      "loss": 0.6519,
      "step": 155600
    },
    {
      "epoch": 1.6483027297124195,
      "grad_norm": 4.747413158416748,
      "learning_rate": 4.942822358670336e-05,
      "loss": 0.6522,
      "step": 155700
    },
    {
      "epoch": 1.6493613732724262,
      "grad_norm": 5.1209611892700195,
      "learning_rate": 4.945998306161338e-05,
      "loss": 0.6541,
      "step": 155800
    },
    {
      "epoch": 1.6504200168324326,
      "grad_norm": 4.196938514709473,
      "learning_rate": 4.949174253652339e-05,
      "loss": 0.6534,
      "step": 155900
    },
    {
      "epoch": 1.6514786603924392,
      "grad_norm": 4.390327453613281,
      "learning_rate": 4.9523502011433406e-05,
      "loss": 0.6466,
      "step": 156000
    },
    {
      "epoch": 1.6514786603924392,
      "eval_loss": 0.4874173402786255,
      "eval_runtime": 57.1955,
      "eval_samples_per_second": 2936.069,
      "eval_steps_per_second": 367.022,
      "step": 156000
    },
    {
      "epoch": 1.6525373039524456,
      "grad_norm": 4.823640823364258,
      "learning_rate": 4.955526148634342e-05,
      "loss": 0.6515,
      "step": 156100
    },
    {
      "epoch": 1.6535959475124522,
      "grad_norm": 4.45102596282959,
      "learning_rate": 4.9587020961253436e-05,
      "loss": 0.6495,
      "step": 156200
    },
    {
      "epoch": 1.6546545910724588,
      "grad_norm": 4.850052833557129,
      "learning_rate": 4.961878043616345e-05,
      "loss": 0.647,
      "step": 156300
    },
    {
      "epoch": 1.6557132346324654,
      "grad_norm": 4.605652332305908,
      "learning_rate": 4.9650539911073465e-05,
      "loss": 0.6458,
      "step": 156400
    },
    {
      "epoch": 1.656771878192472,
      "grad_norm": 4.3360090255737305,
      "learning_rate": 4.9682299385983476e-05,
      "loss": 0.6385,
      "step": 156500
    },
    {
      "epoch": 1.6578305217524787,
      "grad_norm": 4.5191473960876465,
      "learning_rate": 4.9714058860893494e-05,
      "loss": 0.6456,
      "step": 156600
    },
    {
      "epoch": 1.658889165312485,
      "grad_norm": 5.1329665184021,
      "learning_rate": 4.974581833580351e-05,
      "loss": 0.6495,
      "step": 156700
    },
    {
      "epoch": 1.6599478088724917,
      "grad_norm": 4.760811805725098,
      "learning_rate": 4.977757781071352e-05,
      "loss": 0.6464,
      "step": 156800
    },
    {
      "epoch": 1.6610064524324981,
      "grad_norm": 4.222245693206787,
      "learning_rate": 4.980933728562354e-05,
      "loss": 0.6432,
      "step": 156900
    },
    {
      "epoch": 1.6620650959925047,
      "grad_norm": 4.175293445587158,
      "learning_rate": 4.984109676053355e-05,
      "loss": 0.6458,
      "step": 157000
    },
    {
      "epoch": 1.6620650959925047,
      "eval_loss": 0.4817776083946228,
      "eval_runtime": 57.3614,
      "eval_samples_per_second": 2927.576,
      "eval_steps_per_second": 365.96,
      "step": 157000
    },
    {
      "epoch": 1.6631237395525114,
      "grad_norm": 4.517613887786865,
      "learning_rate": 4.987285623544357e-05,
      "loss": 0.6413,
      "step": 157100
    },
    {
      "epoch": 1.664182383112518,
      "grad_norm": 4.456191539764404,
      "learning_rate": 4.990461571035358e-05,
      "loss": 0.6432,
      "step": 157200
    },
    {
      "epoch": 1.6652410266725246,
      "grad_norm": 4.242403984069824,
      "learning_rate": 4.99363751852636e-05,
      "loss": 0.6463,
      "step": 157300
    },
    {
      "epoch": 1.666299670232531,
      "grad_norm": 4.450502395629883,
      "learning_rate": 4.996781706542451e-05,
      "loss": 0.6386,
      "step": 157400
    },
    {
      "epoch": 1.6673583137925376,
      "grad_norm": 5.04681921005249,
      "learning_rate": 4.9999576540334524e-05,
      "loss": 0.645,
      "step": 157500
    },
    {
      "epoch": 1.668416957352544,
      "grad_norm": 4.495242118835449,
      "learning_rate": 5.003133601524454e-05,
      "loss": 0.644,
      "step": 157600
    },
    {
      "epoch": 1.6694756009125507,
      "grad_norm": 4.766069412231445,
      "learning_rate": 5.006309549015456e-05,
      "loss": 0.6341,
      "step": 157700
    },
    {
      "epoch": 1.6705342444725573,
      "grad_norm": 4.6197190284729,
      "learning_rate": 5.009485496506457e-05,
      "loss": 0.6417,
      "step": 157800
    },
    {
      "epoch": 1.671592888032564,
      "grad_norm": 4.981351852416992,
      "learning_rate": 5.012661443997459e-05,
      "loss": 0.6352,
      "step": 157900
    },
    {
      "epoch": 1.6726515315925705,
      "grad_norm": 4.153853893280029,
      "learning_rate": 5.01583739148846e-05,
      "loss": 0.6375,
      "step": 158000
    },
    {
      "epoch": 1.6726515315925705,
      "eval_loss": 0.4765584170818329,
      "eval_runtime": 57.3908,
      "eval_samples_per_second": 2926.079,
      "eval_steps_per_second": 365.773,
      "step": 158000
    },
    {
      "epoch": 1.6737101751525771,
      "grad_norm": 4.390777587890625,
      "learning_rate": 5.019013338979462e-05,
      "loss": 0.6434,
      "step": 158100
    },
    {
      "epoch": 1.6747688187125835,
      "grad_norm": 4.683394432067871,
      "learning_rate": 5.022189286470463e-05,
      "loss": 0.6375,
      "step": 158200
    },
    {
      "epoch": 1.6758274622725902,
      "grad_norm": 4.2140212059021,
      "learning_rate": 5.0253652339614647e-05,
      "loss": 0.6446,
      "step": 158300
    },
    {
      "epoch": 1.6768861058325966,
      "grad_norm": 4.303685188293457,
      "learning_rate": 5.028541181452466e-05,
      "loss": 0.6306,
      "step": 158400
    },
    {
      "epoch": 1.6779447493926032,
      "grad_norm": 5.01198673248291,
      "learning_rate": 5.0317171289434676e-05,
      "loss": 0.648,
      "step": 158500
    },
    {
      "epoch": 1.6790033929526098,
      "grad_norm": 4.392139434814453,
      "learning_rate": 5.034893076434469e-05,
      "loss": 0.6417,
      "step": 158600
    },
    {
      "epoch": 1.6800620365126164,
      "grad_norm": 4.423037052154541,
      "learning_rate": 5.0380690239254705e-05,
      "loss": 0.6235,
      "step": 158700
    },
    {
      "epoch": 1.681120680072623,
      "grad_norm": 4.506580829620361,
      "learning_rate": 5.0412449714164716e-05,
      "loss": 0.6369,
      "step": 158800
    },
    {
      "epoch": 1.6821793236326297,
      "grad_norm": 4.205862998962402,
      "learning_rate": 5.0444209189074734e-05,
      "loss": 0.6353,
      "step": 158900
    },
    {
      "epoch": 1.683237967192636,
      "grad_norm": 4.360707759857178,
      "learning_rate": 5.0475968663984745e-05,
      "loss": 0.6321,
      "step": 159000
    },
    {
      "epoch": 1.683237967192636,
      "eval_loss": 0.4725431501865387,
      "eval_runtime": 57.3494,
      "eval_samples_per_second": 2928.191,
      "eval_steps_per_second": 366.037,
      "step": 159000
    },
    {
      "epoch": 1.6842966107526425,
      "grad_norm": 4.605842590332031,
      "learning_rate": 5.050772813889476e-05,
      "loss": 0.6368,
      "step": 159100
    },
    {
      "epoch": 1.685355254312649,
      "grad_norm": 4.376574516296387,
      "learning_rate": 5.0539487613804774e-05,
      "loss": 0.635,
      "step": 159200
    },
    {
      "epoch": 1.6864138978726557,
      "grad_norm": 4.425550937652588,
      "learning_rate": 5.057124708871479e-05,
      "loss": 0.6306,
      "step": 159300
    },
    {
      "epoch": 1.6874725414326623,
      "grad_norm": 4.092462062835693,
      "learning_rate": 5.060300656362481e-05,
      "loss": 0.6318,
      "step": 159400
    },
    {
      "epoch": 1.688531184992669,
      "grad_norm": 4.65641975402832,
      "learning_rate": 5.0634448443785724e-05,
      "loss": 0.6369,
      "step": 159500
    },
    {
      "epoch": 1.6895898285526756,
      "grad_norm": 4.917164325714111,
      "learning_rate": 5.0666207918695735e-05,
      "loss": 0.6324,
      "step": 159600
    },
    {
      "epoch": 1.690648472112682,
      "grad_norm": 4.33983850479126,
      "learning_rate": 5.069796739360575e-05,
      "loss": 0.6245,
      "step": 159700
    },
    {
      "epoch": 1.6917071156726886,
      "grad_norm": 4.588508605957031,
      "learning_rate": 5.0729726868515764e-05,
      "loss": 0.6262,
      "step": 159800
    },
    {
      "epoch": 1.692765759232695,
      "grad_norm": 4.825279712677002,
      "learning_rate": 5.076148634342578e-05,
      "loss": 0.6357,
      "step": 159900
    },
    {
      "epoch": 1.6938244027927016,
      "grad_norm": 4.556983470916748,
      "learning_rate": 5.079324581833579e-05,
      "loss": 0.6268,
      "step": 160000
    },
    {
      "epoch": 1.6938244027927016,
      "eval_loss": 0.46833449602127075,
      "eval_runtime": 57.4133,
      "eval_samples_per_second": 2924.932,
      "eval_steps_per_second": 365.63,
      "step": 160000
    },
    {
      "epoch": 1.6948830463527083,
      "grad_norm": 4.833308219909668,
      "learning_rate": 5.082500529324581e-05,
      "loss": 0.6325,
      "step": 160100
    },
    {
      "epoch": 1.6959416899127149,
      "grad_norm": 4.6645612716674805,
      "learning_rate": 5.085676476815582e-05,
      "loss": 0.6321,
      "step": 160200
    },
    {
      "epoch": 1.6970003334727215,
      "grad_norm": 4.4716572761535645,
      "learning_rate": 5.088852424306584e-05,
      "loss": 0.6245,
      "step": 160300
    },
    {
      "epoch": 1.6980589770327281,
      "grad_norm": 4.750092506408691,
      "learning_rate": 5.092028371797586e-05,
      "loss": 0.634,
      "step": 160400
    },
    {
      "epoch": 1.6991176205927345,
      "grad_norm": 4.1778459548950195,
      "learning_rate": 5.095204319288587e-05,
      "loss": 0.6373,
      "step": 160500
    },
    {
      "epoch": 1.7001762641527411,
      "grad_norm": 4.9239983558654785,
      "learning_rate": 5.098380266779589e-05,
      "loss": 0.6202,
      "step": 160600
    },
    {
      "epoch": 1.7012349077127475,
      "grad_norm": 4.45186185836792,
      "learning_rate": 5.1015562142705905e-05,
      "loss": 0.624,
      "step": 160700
    },
    {
      "epoch": 1.7022935512727542,
      "grad_norm": 4.401576519012451,
      "learning_rate": 5.104732161761592e-05,
      "loss": 0.6225,
      "step": 160800
    },
    {
      "epoch": 1.7033521948327608,
      "grad_norm": 4.735199451446533,
      "learning_rate": 5.1079081092525934e-05,
      "loss": 0.627,
      "step": 160900
    },
    {
      "epoch": 1.7044108383927674,
      "grad_norm": 4.673045635223389,
      "learning_rate": 5.111084056743595e-05,
      "loss": 0.624,
      "step": 161000
    },
    {
      "epoch": 1.7044108383927674,
      "eval_loss": 0.4663570821285248,
      "eval_runtime": 57.3747,
      "eval_samples_per_second": 2926.9,
      "eval_steps_per_second": 365.876,
      "step": 161000
    },
    {
      "epoch": 1.705469481952774,
      "grad_norm": 4.681502819061279,
      "learning_rate": 5.114260004234596e-05,
      "loss": 0.6204,
      "step": 161100
    },
    {
      "epoch": 1.7065281255127804,
      "grad_norm": 4.22634220123291,
      "learning_rate": 5.117435951725598e-05,
      "loss": 0.6234,
      "step": 161200
    },
    {
      "epoch": 1.707586769072787,
      "grad_norm": 4.4599385261535645,
      "learning_rate": 5.1206118992166e-05,
      "loss": 0.6283,
      "step": 161300
    },
    {
      "epoch": 1.7086454126327935,
      "grad_norm": 4.261423587799072,
      "learning_rate": 5.123787846707601e-05,
      "loss": 0.6266,
      "step": 161400
    },
    {
      "epoch": 1.7097040561928,
      "grad_norm": 4.085052490234375,
      "learning_rate": 5.126963794198603e-05,
      "loss": 0.6239,
      "step": 161500
    },
    {
      "epoch": 1.7107626997528067,
      "grad_norm": 4.585908889770508,
      "learning_rate": 5.130139741689604e-05,
      "loss": 0.6234,
      "step": 161600
    },
    {
      "epoch": 1.7118213433128133,
      "grad_norm": 4.085172653198242,
      "learning_rate": 5.133283929705695e-05,
      "loss": 0.6169,
      "step": 161700
    },
    {
      "epoch": 1.71287998687282,
      "grad_norm": 4.773190975189209,
      "learning_rate": 5.136459877196697e-05,
      "loss": 0.6286,
      "step": 161800
    },
    {
      "epoch": 1.7139386304328266,
      "grad_norm": 4.583485126495361,
      "learning_rate": 5.139635824687698e-05,
      "loss": 0.6099,
      "step": 161900
    },
    {
      "epoch": 1.714997273992833,
      "grad_norm": 4.489309787750244,
      "learning_rate": 5.1428117721787e-05,
      "loss": 0.623,
      "step": 162000
    },
    {
      "epoch": 1.714997273992833,
      "eval_loss": 0.46527883410453796,
      "eval_runtime": 57.2203,
      "eval_samples_per_second": 2934.796,
      "eval_steps_per_second": 366.863,
      "step": 162000
    },
    {
      "epoch": 1.7160559175528396,
      "grad_norm": 4.667335510253906,
      "learning_rate": 5.145987719669701e-05,
      "loss": 0.6176,
      "step": 162100
    },
    {
      "epoch": 1.717114561112846,
      "grad_norm": 4.44180154800415,
      "learning_rate": 5.149163667160703e-05,
      "loss": 0.6192,
      "step": 162200
    },
    {
      "epoch": 1.7181732046728526,
      "grad_norm": 4.706697463989258,
      "learning_rate": 5.1523396146517046e-05,
      "loss": 0.6224,
      "step": 162300
    },
    {
      "epoch": 1.7192318482328592,
      "grad_norm": 4.782515048980713,
      "learning_rate": 5.155515562142706e-05,
      "loss": 0.6235,
      "step": 162400
    },
    {
      "epoch": 1.7202904917928659,
      "grad_norm": 4.610527515411377,
      "learning_rate": 5.1586915096337075e-05,
      "loss": 0.6289,
      "step": 162500
    },
    {
      "epoch": 1.7213491353528725,
      "grad_norm": 4.564727783203125,
      "learning_rate": 5.1618674571247087e-05,
      "loss": 0.6109,
      "step": 162600
    },
    {
      "epoch": 1.7224077789128789,
      "grad_norm": 4.3791327476501465,
      "learning_rate": 5.1650434046157105e-05,
      "loss": 0.6209,
      "step": 162700
    },
    {
      "epoch": 1.7234664224728855,
      "grad_norm": 4.4712042808532715,
      "learning_rate": 5.1682193521067116e-05,
      "loss": 0.6296,
      "step": 162800
    },
    {
      "epoch": 1.724525066032892,
      "grad_norm": 4.728489398956299,
      "learning_rate": 5.1713952995977134e-05,
      "loss": 0.6159,
      "step": 162900
    },
    {
      "epoch": 1.7255837095928985,
      "grad_norm": 4.175848960876465,
      "learning_rate": 5.1745712470887145e-05,
      "loss": 0.6168,
      "step": 163000
    },
    {
      "epoch": 1.7255837095928985,
      "eval_loss": 0.4576048254966736,
      "eval_runtime": 57.2973,
      "eval_samples_per_second": 2930.852,
      "eval_steps_per_second": 366.37,
      "step": 163000
    },
    {
      "epoch": 1.7266423531529052,
      "grad_norm": 4.56320333480835,
      "learning_rate": 5.177747194579716e-05,
      "loss": 0.6115,
      "step": 163100
    },
    {
      "epoch": 1.7277009967129118,
      "grad_norm": 4.757515907287598,
      "learning_rate": 5.1809231420707174e-05,
      "loss": 0.6174,
      "step": 163200
    },
    {
      "epoch": 1.7287596402729184,
      "grad_norm": 4.145392894744873,
      "learning_rate": 5.184099089561719e-05,
      "loss": 0.6112,
      "step": 163300
    },
    {
      "epoch": 1.729818283832925,
      "grad_norm": 4.7460551261901855,
      "learning_rate": 5.18727503705272e-05,
      "loss": 0.6161,
      "step": 163400
    },
    {
      "epoch": 1.7308769273929314,
      "grad_norm": 5.032401084899902,
      "learning_rate": 5.190450984543722e-05,
      "loss": 0.6186,
      "step": 163500
    },
    {
      "epoch": 1.731935570952938,
      "grad_norm": 4.865833759307861,
      "learning_rate": 5.193626932034723e-05,
      "loss": 0.6034,
      "step": 163600
    },
    {
      "epoch": 1.7329942145129444,
      "grad_norm": 4.903388023376465,
      "learning_rate": 5.196802879525725e-05,
      "loss": 0.6114,
      "step": 163700
    },
    {
      "epoch": 1.734052858072951,
      "grad_norm": 4.362641334533691,
      "learning_rate": 5.1999470675418164e-05,
      "loss": 0.6107,
      "step": 163800
    },
    {
      "epoch": 1.7351115016329577,
      "grad_norm": 4.5530595779418945,
      "learning_rate": 5.203123015032818e-05,
      "loss": 0.6155,
      "step": 163900
    },
    {
      "epoch": 1.7361701451929643,
      "grad_norm": 4.286667346954346,
      "learning_rate": 5.206298962523819e-05,
      "loss": 0.6099,
      "step": 164000
    },
    {
      "epoch": 1.7361701451929643,
      "eval_loss": 0.4566221833229065,
      "eval_runtime": 57.3803,
      "eval_samples_per_second": 2926.617,
      "eval_steps_per_second": 365.84,
      "step": 164000
    },
    {
      "epoch": 1.737228788752971,
      "grad_norm": 4.7404022216796875,
      "learning_rate": 5.209474910014821e-05,
      "loss": 0.6143,
      "step": 164100
    },
    {
      "epoch": 1.7382874323129773,
      "grad_norm": 4.622793197631836,
      "learning_rate": 5.212650857505822e-05,
      "loss": 0.6168,
      "step": 164200
    },
    {
      "epoch": 1.739346075872984,
      "grad_norm": 4.935079097747803,
      "learning_rate": 5.215826804996824e-05,
      "loss": 0.6104,
      "step": 164300
    },
    {
      "epoch": 1.7404047194329904,
      "grad_norm": 4.579159736633301,
      "learning_rate": 5.219002752487825e-05,
      "loss": 0.6147,
      "step": 164400
    },
    {
      "epoch": 1.741463362992997,
      "grad_norm": 4.751307487487793,
      "learning_rate": 5.222178699978827e-05,
      "loss": 0.6125,
      "step": 164500
    },
    {
      "epoch": 1.7425220065530036,
      "grad_norm": 4.167551517486572,
      "learning_rate": 5.225354647469828e-05,
      "loss": 0.6103,
      "step": 164600
    },
    {
      "epoch": 1.7435806501130102,
      "grad_norm": 4.300376892089844,
      "learning_rate": 5.22853059496083e-05,
      "loss": 0.6105,
      "step": 164700
    },
    {
      "epoch": 1.7446392936730168,
      "grad_norm": 4.136415481567383,
      "learning_rate": 5.231706542451831e-05,
      "loss": 0.6019,
      "step": 164800
    },
    {
      "epoch": 1.7456979372330235,
      "grad_norm": 4.562756061553955,
      "learning_rate": 5.234882489942833e-05,
      "loss": 0.6097,
      "step": 164900
    },
    {
      "epoch": 1.7467565807930299,
      "grad_norm": 4.452812194824219,
      "learning_rate": 5.2380584374338345e-05,
      "loss": 0.6159,
      "step": 165000
    },
    {
      "epoch": 1.7467565807930299,
      "eval_loss": 0.4513910710811615,
      "eval_runtime": 57.2047,
      "eval_samples_per_second": 2935.6,
      "eval_steps_per_second": 366.963,
      "step": 165000
    },
    {
      "epoch": 1.7478152243530365,
      "grad_norm": 4.857870101928711,
      "learning_rate": 5.2412343849248356e-05,
      "loss": 0.6037,
      "step": 165100
    },
    {
      "epoch": 1.748873867913043,
      "grad_norm": 4.59922981262207,
      "learning_rate": 5.2444103324158374e-05,
      "loss": 0.6104,
      "step": 165200
    },
    {
      "epoch": 1.7499325114730495,
      "grad_norm": 4.612668037414551,
      "learning_rate": 5.2475862799068385e-05,
      "loss": 0.6104,
      "step": 165300
    },
    {
      "epoch": 1.7509911550330561,
      "grad_norm": 4.385636806488037,
      "learning_rate": 5.25076222739784e-05,
      "loss": 0.6125,
      "step": 165400
    },
    {
      "epoch": 1.7520497985930628,
      "grad_norm": 4.691148281097412,
      "learning_rate": 5.2539381748888414e-05,
      "loss": 0.6093,
      "step": 165500
    },
    {
      "epoch": 1.7531084421530694,
      "grad_norm": 4.587236404418945,
      "learning_rate": 5.257114122379843e-05,
      "loss": 0.61,
      "step": 165600
    },
    {
      "epoch": 1.754167085713076,
      "grad_norm": 4.991665363311768,
      "learning_rate": 5.260290069870844e-05,
      "loss": 0.606,
      "step": 165700
    },
    {
      "epoch": 1.7552257292730824,
      "grad_norm": 4.199767589569092,
      "learning_rate": 5.263434257886936e-05,
      "loss": 0.6115,
      "step": 165800
    },
    {
      "epoch": 1.7562843728330888,
      "grad_norm": 4.250484943389893,
      "learning_rate": 5.2666102053779375e-05,
      "loss": 0.6066,
      "step": 165900
    },
    {
      "epoch": 1.7573430163930954,
      "grad_norm": 4.761606216430664,
      "learning_rate": 5.2697861528689386e-05,
      "loss": 0.6036,
      "step": 166000
    },
    {
      "epoch": 1.7573430163930954,
      "eval_loss": 0.44642558693885803,
      "eval_runtime": 57.3081,
      "eval_samples_per_second": 2930.3,
      "eval_steps_per_second": 366.301,
      "step": 166000
    },
    {
      "epoch": 1.758401659953102,
      "grad_norm": 4.775491237640381,
      "learning_rate": 5.2729621003599404e-05,
      "loss": 0.6044,
      "step": 166100
    },
    {
      "epoch": 1.7594603035131087,
      "grad_norm": 4.694407939910889,
      "learning_rate": 5.276138047850942e-05,
      "loss": 0.6037,
      "step": 166200
    },
    {
      "epoch": 1.7605189470731153,
      "grad_norm": 4.585903167724609,
      "learning_rate": 5.279313995341943e-05,
      "loss": 0.606,
      "step": 166300
    },
    {
      "epoch": 1.761577590633122,
      "grad_norm": 3.993670701980591,
      "learning_rate": 5.282489942832945e-05,
      "loss": 0.6088,
      "step": 166400
    },
    {
      "epoch": 1.7626362341931283,
      "grad_norm": 4.243491172790527,
      "learning_rate": 5.285665890323946e-05,
      "loss": 0.6033,
      "step": 166500
    },
    {
      "epoch": 1.763694877753135,
      "grad_norm": 4.514244556427002,
      "learning_rate": 5.288841837814948e-05,
      "loss": 0.6031,
      "step": 166600
    },
    {
      "epoch": 1.7647535213131413,
      "grad_norm": 4.328210830688477,
      "learning_rate": 5.292017785305949e-05,
      "loss": 0.5912,
      "step": 166700
    },
    {
      "epoch": 1.765812164873148,
      "grad_norm": 4.482541561126709,
      "learning_rate": 5.295193732796951e-05,
      "loss": 0.5966,
      "step": 166800
    },
    {
      "epoch": 1.7668708084331546,
      "grad_norm": 4.794356822967529,
      "learning_rate": 5.298369680287952e-05,
      "loss": 0.5982,
      "step": 166900
    },
    {
      "epoch": 1.7679294519931612,
      "grad_norm": 3.886707067489624,
      "learning_rate": 5.301545627778954e-05,
      "loss": 0.5993,
      "step": 167000
    },
    {
      "epoch": 1.7679294519931612,
      "eval_loss": 0.44577398896217346,
      "eval_runtime": 57.4916,
      "eval_samples_per_second": 2920.946,
      "eval_steps_per_second": 365.131,
      "step": 167000
    },
    {
      "epoch": 1.7689880955531678,
      "grad_norm": 4.729049205780029,
      "learning_rate": 5.304721575269955e-05,
      "loss": 0.6104,
      "step": 167100
    },
    {
      "epoch": 1.7700467391131744,
      "grad_norm": 4.614967346191406,
      "learning_rate": 5.307897522760957e-05,
      "loss": 0.5971,
      "step": 167200
    },
    {
      "epoch": 1.7711053826731809,
      "grad_norm": 4.601379871368408,
      "learning_rate": 5.311073470251958e-05,
      "loss": 0.6036,
      "step": 167300
    },
    {
      "epoch": 1.7721640262331873,
      "grad_norm": 4.3732829093933105,
      "learning_rate": 5.3142494177429596e-05,
      "loss": 0.6008,
      "step": 167400
    },
    {
      "epoch": 1.7732226697931939,
      "grad_norm": 4.316978454589844,
      "learning_rate": 5.317425365233961e-05,
      "loss": 0.611,
      "step": 167500
    },
    {
      "epoch": 1.7742813133532005,
      "grad_norm": 5.096396446228027,
      "learning_rate": 5.3206013127249625e-05,
      "loss": 0.5962,
      "step": 167600
    },
    {
      "epoch": 1.7753399569132071,
      "grad_norm": 4.439629077911377,
      "learning_rate": 5.323777260215964e-05,
      "loss": 0.5998,
      "step": 167700
    },
    {
      "epoch": 1.7763986004732137,
      "grad_norm": 4.427005767822266,
      "learning_rate": 5.326921448232056e-05,
      "loss": 0.6002,
      "step": 167800
    },
    {
      "epoch": 1.7774572440332204,
      "grad_norm": 4.651953220367432,
      "learning_rate": 5.330097395723057e-05,
      "loss": 0.5992,
      "step": 167900
    },
    {
      "epoch": 1.7785158875932268,
      "grad_norm": 4.369607448577881,
      "learning_rate": 5.3332733432140586e-05,
      "loss": 0.6015,
      "step": 168000
    },
    {
      "epoch": 1.7785158875932268,
      "eval_loss": 0.4415454864501953,
      "eval_runtime": 57.3502,
      "eval_samples_per_second": 2928.151,
      "eval_steps_per_second": 366.032,
      "step": 168000
    },
    {
      "epoch": 1.7795745311532334,
      "grad_norm": 4.088803768157959,
      "learning_rate": 5.33644929070506e-05,
      "loss": 0.5902,
      "step": 168100
    },
    {
      "epoch": 1.7806331747132398,
      "grad_norm": 4.424105644226074,
      "learning_rate": 5.3396252381960615e-05,
      "loss": 0.5948,
      "step": 168200
    },
    {
      "epoch": 1.7816918182732464,
      "grad_norm": 4.240602016448975,
      "learning_rate": 5.3428011856870626e-05,
      "loss": 0.5988,
      "step": 168300
    },
    {
      "epoch": 1.782750461833253,
      "grad_norm": 5.153587818145752,
      "learning_rate": 5.3459771331780644e-05,
      "loss": 0.5929,
      "step": 168400
    },
    {
      "epoch": 1.7838091053932597,
      "grad_norm": 4.323111534118652,
      "learning_rate": 5.3491530806690655e-05,
      "loss": 0.5954,
      "step": 168500
    },
    {
      "epoch": 1.7848677489532663,
      "grad_norm": 4.4554033279418945,
      "learning_rate": 5.352329028160067e-05,
      "loss": 0.5916,
      "step": 168600
    },
    {
      "epoch": 1.785926392513273,
      "grad_norm": 4.42021369934082,
      "learning_rate": 5.3555049756510684e-05,
      "loss": 0.5999,
      "step": 168700
    },
    {
      "epoch": 1.7869850360732793,
      "grad_norm": 4.345828056335449,
      "learning_rate": 5.35868092314207e-05,
      "loss": 0.5925,
      "step": 168800
    },
    {
      "epoch": 1.788043679633286,
      "grad_norm": 3.966937303543091,
      "learning_rate": 5.361856870633072e-05,
      "loss": 0.5874,
      "step": 168900
    },
    {
      "epoch": 1.7891023231932923,
      "grad_norm": 4.28960657119751,
      "learning_rate": 5.365032818124073e-05,
      "loss": 0.5963,
      "step": 169000
    },
    {
      "epoch": 1.7891023231932923,
      "eval_loss": 0.4393461048603058,
      "eval_runtime": 57.4549,
      "eval_samples_per_second": 2922.814,
      "eval_steps_per_second": 365.365,
      "step": 169000
    },
    {
      "epoch": 1.790160966753299,
      "grad_norm": 5.031203746795654,
      "learning_rate": 5.368208765615075e-05,
      "loss": 0.5975,
      "step": 169100
    },
    {
      "epoch": 1.7912196103133056,
      "grad_norm": 4.801020622253418,
      "learning_rate": 5.371384713106076e-05,
      "loss": 0.5907,
      "step": 169200
    },
    {
      "epoch": 1.7922782538733122,
      "grad_norm": 3.869091749191284,
      "learning_rate": 5.374560660597078e-05,
      "loss": 0.5965,
      "step": 169300
    },
    {
      "epoch": 1.7933368974333188,
      "grad_norm": 4.100785255432129,
      "learning_rate": 5.377736608088079e-05,
      "loss": 0.5958,
      "step": 169400
    },
    {
      "epoch": 1.7943955409933252,
      "grad_norm": 4.508588790893555,
      "learning_rate": 5.380912555579081e-05,
      "loss": 0.5947,
      "step": 169500
    },
    {
      "epoch": 1.7954541845533318,
      "grad_norm": 4.705711364746094,
      "learning_rate": 5.384088503070082e-05,
      "loss": 0.5866,
      "step": 169600
    },
    {
      "epoch": 1.7965128281133382,
      "grad_norm": 4.7746758460998535,
      "learning_rate": 5.3872644505610836e-05,
      "loss": 0.5897,
      "step": 169700
    },
    {
      "epoch": 1.7975714716733449,
      "grad_norm": 4.063102722167969,
      "learning_rate": 5.390440398052085e-05,
      "loss": 0.5996,
      "step": 169800
    },
    {
      "epoch": 1.7986301152333515,
      "grad_norm": 5.275763988494873,
      "learning_rate": 5.393584586068177e-05,
      "loss": 0.5862,
      "step": 169900
    },
    {
      "epoch": 1.799688758793358,
      "grad_norm": 3.920454263687134,
      "learning_rate": 5.396760533559178e-05,
      "loss": 0.5892,
      "step": 170000
    },
    {
      "epoch": 1.799688758793358,
      "eval_loss": 0.4368157386779785,
      "eval_runtime": 57.4786,
      "eval_samples_per_second": 2921.607,
      "eval_steps_per_second": 365.214,
      "step": 170000
    },
    {
      "epoch": 1.8007474023533647,
      "grad_norm": 4.2455735206604,
      "learning_rate": 5.39993648105018e-05,
      "loss": 0.5905,
      "step": 170100
    },
    {
      "epoch": 1.8018060459133713,
      "grad_norm": 4.297884464263916,
      "learning_rate": 5.403112428541181e-05,
      "loss": 0.5884,
      "step": 170200
    },
    {
      "epoch": 1.8028646894733777,
      "grad_norm": 3.874943971633911,
      "learning_rate": 5.4062883760321826e-05,
      "loss": 0.5938,
      "step": 170300
    },
    {
      "epoch": 1.8039233330333844,
      "grad_norm": 4.258410930633545,
      "learning_rate": 5.409464323523184e-05,
      "loss": 0.5946,
      "step": 170400
    },
    {
      "epoch": 1.8049819765933908,
      "grad_norm": 4.688762664794922,
      "learning_rate": 5.4126402710141855e-05,
      "loss": 0.5918,
      "step": 170500
    },
    {
      "epoch": 1.8060406201533974,
      "grad_norm": 4.457647800445557,
      "learning_rate": 5.4158162185051866e-05,
      "loss": 0.589,
      "step": 170600
    },
    {
      "epoch": 1.807099263713404,
      "grad_norm": 4.291092395782471,
      "learning_rate": 5.4189921659961884e-05,
      "loss": 0.5823,
      "step": 170700
    },
    {
      "epoch": 1.8081579072734106,
      "grad_norm": 4.842592239379883,
      "learning_rate": 5.4221681134871895e-05,
      "loss": 0.592,
      "step": 170800
    },
    {
      "epoch": 1.8092165508334173,
      "grad_norm": 4.820900917053223,
      "learning_rate": 5.425344060978191e-05,
      "loss": 0.5882,
      "step": 170900
    },
    {
      "epoch": 1.8102751943934237,
      "grad_norm": 4.177670478820801,
      "learning_rate": 5.4285200084691924e-05,
      "loss": 0.591,
      "step": 171000
    },
    {
      "epoch": 1.8102751943934237,
      "eval_loss": 0.4294340908527374,
      "eval_runtime": 57.2363,
      "eval_samples_per_second": 2933.975,
      "eval_steps_per_second": 366.76,
      "step": 171000
    },
    {
      "epoch": 1.8113338379534303,
      "grad_norm": 4.664742946624756,
      "learning_rate": 5.431695955960194e-05,
      "loss": 0.5888,
      "step": 171100
    },
    {
      "epoch": 1.8123924815134367,
      "grad_norm": 4.579099178314209,
      "learning_rate": 5.434871903451195e-05,
      "loss": 0.5871,
      "step": 171200
    },
    {
      "epoch": 1.8134511250734433,
      "grad_norm": 4.137617588043213,
      "learning_rate": 5.438047850942197e-05,
      "loss": 0.5821,
      "step": 171300
    },
    {
      "epoch": 1.81450976863345,
      "grad_norm": 4.693020820617676,
      "learning_rate": 5.441223798433199e-05,
      "loss": 0.5844,
      "step": 171400
    },
    {
      "epoch": 1.8155684121934565,
      "grad_norm": 4.639885425567627,
      "learning_rate": 5.4443997459242e-05,
      "loss": 0.5803,
      "step": 171500
    },
    {
      "epoch": 1.8166270557534632,
      "grad_norm": 4.365481853485107,
      "learning_rate": 5.447575693415202e-05,
      "loss": 0.5842,
      "step": 171600
    },
    {
      "epoch": 1.8176856993134698,
      "grad_norm": 4.487180709838867,
      "learning_rate": 5.450751640906203e-05,
      "loss": 0.5799,
      "step": 171700
    },
    {
      "epoch": 1.8187443428734762,
      "grad_norm": 4.349223613739014,
      "learning_rate": 5.453927588397205e-05,
      "loss": 0.5908,
      "step": 171800
    },
    {
      "epoch": 1.8198029864334828,
      "grad_norm": 3.876044273376465,
      "learning_rate": 5.457071776413296e-05,
      "loss": 0.5831,
      "step": 171900
    },
    {
      "epoch": 1.8208616299934892,
      "grad_norm": 4.275196552276611,
      "learning_rate": 5.460247723904297e-05,
      "loss": 0.5804,
      "step": 172000
    },
    {
      "epoch": 1.8208616299934892,
      "eval_loss": 0.4326649308204651,
      "eval_runtime": 57.3104,
      "eval_samples_per_second": 2930.183,
      "eval_steps_per_second": 366.286,
      "step": 172000
    },
    {
      "epoch": 1.8219202735534958,
      "grad_norm": 4.331679344177246,
      "learning_rate": 5.463423671395299e-05,
      "loss": 0.5792,
      "step": 172100
    },
    {
      "epoch": 1.8229789171135025,
      "grad_norm": 4.569429397583008,
      "learning_rate": 5.4665996188863e-05,
      "loss": 0.5832,
      "step": 172200
    },
    {
      "epoch": 1.824037560673509,
      "grad_norm": 4.411563396453857,
      "learning_rate": 5.469775566377302e-05,
      "loss": 0.581,
      "step": 172300
    },
    {
      "epoch": 1.8250962042335157,
      "grad_norm": 4.563894748687744,
      "learning_rate": 5.472951513868303e-05,
      "loss": 0.5793,
      "step": 172400
    },
    {
      "epoch": 1.826154847793522,
      "grad_norm": 4.05531644821167,
      "learning_rate": 5.476127461359305e-05,
      "loss": 0.5784,
      "step": 172500
    },
    {
      "epoch": 1.8272134913535287,
      "grad_norm": 4.009285926818848,
      "learning_rate": 5.4793034088503066e-05,
      "loss": 0.5847,
      "step": 172600
    },
    {
      "epoch": 1.8282721349135351,
      "grad_norm": 4.897397994995117,
      "learning_rate": 5.482479356341308e-05,
      "loss": 0.5746,
      "step": 172700
    },
    {
      "epoch": 1.8293307784735418,
      "grad_norm": 4.066033363342285,
      "learning_rate": 5.4856553038323095e-05,
      "loss": 0.5684,
      "step": 172800
    },
    {
      "epoch": 1.8303894220335484,
      "grad_norm": 4.472072601318359,
      "learning_rate": 5.4888312513233106e-05,
      "loss": 0.582,
      "step": 172900
    },
    {
      "epoch": 1.831448065593555,
      "grad_norm": 4.2180914878845215,
      "learning_rate": 5.4920071988143124e-05,
      "loss": 0.5839,
      "step": 173000
    },
    {
      "epoch": 1.831448065593555,
      "eval_loss": 0.4257272779941559,
      "eval_runtime": 57.49,
      "eval_samples_per_second": 2921.028,
      "eval_steps_per_second": 365.142,
      "step": 173000
    },
    {
      "epoch": 1.8325067091535616,
      "grad_norm": 3.876573324203491,
      "learning_rate": 5.4951831463053135e-05,
      "loss": 0.5826,
      "step": 173100
    },
    {
      "epoch": 1.8335653527135682,
      "grad_norm": 4.599061965942383,
      "learning_rate": 5.498359093796315e-05,
      "loss": 0.5856,
      "step": 173200
    },
    {
      "epoch": 1.8346239962735746,
      "grad_norm": 3.6987338066101074,
      "learning_rate": 5.5015350412873164e-05,
      "loss": 0.5792,
      "step": 173300
    },
    {
      "epoch": 1.8356826398335813,
      "grad_norm": 4.127237319946289,
      "learning_rate": 5.504710988778318e-05,
      "loss": 0.5808,
      "step": 173400
    },
    {
      "epoch": 1.8367412833935877,
      "grad_norm": 4.017908573150635,
      "learning_rate": 5.507886936269319e-05,
      "loss": 0.574,
      "step": 173500
    },
    {
      "epoch": 1.8377999269535943,
      "grad_norm": 4.303151607513428,
      "learning_rate": 5.511062883760321e-05,
      "loss": 0.5787,
      "step": 173600
    },
    {
      "epoch": 1.838858570513601,
      "grad_norm": 4.162308216094971,
      "learning_rate": 5.514238831251322e-05,
      "loss": 0.5863,
      "step": 173700
    },
    {
      "epoch": 1.8399172140736075,
      "grad_norm": 3.83364200592041,
      "learning_rate": 5.517414778742324e-05,
      "loss": 0.5793,
      "step": 173800
    },
    {
      "epoch": 1.8409758576336142,
      "grad_norm": 4.551113128662109,
      "learning_rate": 5.520590726233325e-05,
      "loss": 0.5857,
      "step": 173900
    },
    {
      "epoch": 1.8420345011936208,
      "grad_norm": 4.1408162117004395,
      "learning_rate": 5.523734914249417e-05,
      "loss": 0.5781,
      "step": 174000
    },
    {
      "epoch": 1.8420345011936208,
      "eval_loss": 0.4250248372554779,
      "eval_runtime": 57.2333,
      "eval_samples_per_second": 2934.133,
      "eval_steps_per_second": 366.78,
      "step": 174000
    },
    {
      "epoch": 1.8430931447536272,
      "grad_norm": 4.145875930786133,
      "learning_rate": 5.526910861740418e-05,
      "loss": 0.5725,
      "step": 174100
    },
    {
      "epoch": 1.8441517883136336,
      "grad_norm": 4.4356207847595215,
      "learning_rate": 5.53008680923142e-05,
      "loss": 0.5782,
      "step": 174200
    },
    {
      "epoch": 1.8452104318736402,
      "grad_norm": 4.51071310043335,
      "learning_rate": 5.533262756722421e-05,
      "loss": 0.5738,
      "step": 174300
    },
    {
      "epoch": 1.8462690754336468,
      "grad_norm": 4.708525657653809,
      "learning_rate": 5.536438704213423e-05,
      "loss": 0.576,
      "step": 174400
    },
    {
      "epoch": 1.8473277189936534,
      "grad_norm": 4.064530372619629,
      "learning_rate": 5.539614651704424e-05,
      "loss": 0.5753,
      "step": 174500
    },
    {
      "epoch": 1.84838636255366,
      "grad_norm": 4.452769756317139,
      "learning_rate": 5.542790599195426e-05,
      "loss": 0.5756,
      "step": 174600
    },
    {
      "epoch": 1.8494450061136667,
      "grad_norm": 3.626175880432129,
      "learning_rate": 5.545966546686427e-05,
      "loss": 0.5753,
      "step": 174700
    },
    {
      "epoch": 1.850503649673673,
      "grad_norm": 4.257217884063721,
      "learning_rate": 5.549142494177429e-05,
      "loss": 0.573,
      "step": 174800
    },
    {
      "epoch": 1.8515622932336797,
      "grad_norm": 4.446316719055176,
      "learning_rate": 5.55231844166843e-05,
      "loss": 0.577,
      "step": 174900
    },
    {
      "epoch": 1.8526209367936861,
      "grad_norm": 4.139400482177734,
      "learning_rate": 5.555494389159432e-05,
      "loss": 0.5693,
      "step": 175000
    },
    {
      "epoch": 1.8526209367936861,
      "eval_loss": 0.4209904670715332,
      "eval_runtime": 57.3805,
      "eval_samples_per_second": 2926.602,
      "eval_steps_per_second": 365.838,
      "step": 175000
    },
    {
      "epoch": 1.8536795803536927,
      "grad_norm": 4.3935065269470215,
      "learning_rate": 5.558670336650433e-05,
      "loss": 0.5722,
      "step": 175100
    },
    {
      "epoch": 1.8547382239136994,
      "grad_norm": 3.861623525619507,
      "learning_rate": 5.5618462841414346e-05,
      "loss": 0.5696,
      "step": 175200
    },
    {
      "epoch": 1.855796867473706,
      "grad_norm": 4.42864990234375,
      "learning_rate": 5.565022231632437e-05,
      "loss": 0.568,
      "step": 175300
    },
    {
      "epoch": 1.8568555110337126,
      "grad_norm": 4.2167277336120605,
      "learning_rate": 5.568198179123438e-05,
      "loss": 0.5762,
      "step": 175400
    },
    {
      "epoch": 1.8579141545937192,
      "grad_norm": 4.261938571929932,
      "learning_rate": 5.57137412661444e-05,
      "loss": 0.57,
      "step": 175500
    },
    {
      "epoch": 1.8589727981537256,
      "grad_norm": 3.658855676651001,
      "learning_rate": 5.574550074105441e-05,
      "loss": 0.5689,
      "step": 175600
    },
    {
      "epoch": 1.8600314417137322,
      "grad_norm": 4.390036582946777,
      "learning_rate": 5.577726021596443e-05,
      "loss": 0.5717,
      "step": 175700
    },
    {
      "epoch": 1.8610900852737386,
      "grad_norm": 3.8236241340637207,
      "learning_rate": 5.580901969087444e-05,
      "loss": 0.5731,
      "step": 175800
    },
    {
      "epoch": 1.8621487288337453,
      "grad_norm": 3.8851990699768066,
      "learning_rate": 5.584077916578446e-05,
      "loss": 0.5702,
      "step": 175900
    },
    {
      "epoch": 1.863207372393752,
      "grad_norm": 4.396007537841797,
      "learning_rate": 5.587222104594537e-05,
      "loss": 0.5732,
      "step": 176000
    },
    {
      "epoch": 1.863207372393752,
      "eval_loss": 0.4179803729057312,
      "eval_runtime": 57.2427,
      "eval_samples_per_second": 2933.648,
      "eval_steps_per_second": 366.719,
      "step": 176000
    },
    {
      "epoch": 1.8642660159537585,
      "grad_norm": 4.653412818908691,
      "learning_rate": 5.590398052085539e-05,
      "loss": 0.5781,
      "step": 176100
    },
    {
      "epoch": 1.8653246595137651,
      "grad_norm": 4.223468780517578,
      "learning_rate": 5.59357399957654e-05,
      "loss": 0.5756,
      "step": 176200
    },
    {
      "epoch": 1.8663833030737715,
      "grad_norm": 3.998154878616333,
      "learning_rate": 5.596749947067542e-05,
      "loss": 0.5683,
      "step": 176300
    },
    {
      "epoch": 1.8674419466337782,
      "grad_norm": 4.31113862991333,
      "learning_rate": 5.599925894558543e-05,
      "loss": 0.5643,
      "step": 176400
    },
    {
      "epoch": 1.8685005901937846,
      "grad_norm": 4.1260247230529785,
      "learning_rate": 5.603101842049545e-05,
      "loss": 0.5708,
      "step": 176500
    },
    {
      "epoch": 1.8695592337537912,
      "grad_norm": 3.7117276191711426,
      "learning_rate": 5.606277789540546e-05,
      "loss": 0.5762,
      "step": 176600
    },
    {
      "epoch": 1.8706178773137978,
      "grad_norm": 4.084747314453125,
      "learning_rate": 5.609453737031548e-05,
      "loss": 0.5641,
      "step": 176700
    },
    {
      "epoch": 1.8716765208738044,
      "grad_norm": 4.063061714172363,
      "learning_rate": 5.612629684522549e-05,
      "loss": 0.5671,
      "step": 176800
    },
    {
      "epoch": 1.872735164433811,
      "grad_norm": 4.342619895935059,
      "learning_rate": 5.6158056320135506e-05,
      "loss": 0.5649,
      "step": 176900
    },
    {
      "epoch": 1.8737938079938177,
      "grad_norm": 4.244282245635986,
      "learning_rate": 5.618981579504552e-05,
      "loss": 0.5663,
      "step": 177000
    },
    {
      "epoch": 1.8737938079938177,
      "eval_loss": 0.415912926197052,
      "eval_runtime": 57.3299,
      "eval_samples_per_second": 2929.186,
      "eval_steps_per_second": 366.161,
      "step": 177000
    },
    {
      "epoch": 1.874852451553824,
      "grad_norm": 4.0489301681518555,
      "learning_rate": 5.6221575269955535e-05,
      "loss": 0.5717,
      "step": 177100
    },
    {
      "epoch": 1.8759110951138307,
      "grad_norm": 4.271090507507324,
      "learning_rate": 5.625333474486555e-05,
      "loss": 0.5666,
      "step": 177200
    },
    {
      "epoch": 1.876969738673837,
      "grad_norm": 4.077733039855957,
      "learning_rate": 5.6285094219775564e-05,
      "loss": 0.571,
      "step": 177300
    },
    {
      "epoch": 1.8780283822338437,
      "grad_norm": 4.366397380828857,
      "learning_rate": 5.631685369468558e-05,
      "loss": 0.56,
      "step": 177400
    },
    {
      "epoch": 1.8790870257938503,
      "grad_norm": 4.622849464416504,
      "learning_rate": 5.634861316959559e-05,
      "loss": 0.5649,
      "step": 177500
    },
    {
      "epoch": 1.880145669353857,
      "grad_norm": 3.8411409854888916,
      "learning_rate": 5.638037264450561e-05,
      "loss": 0.5671,
      "step": 177600
    },
    {
      "epoch": 1.8812043129138636,
      "grad_norm": 3.9177513122558594,
      "learning_rate": 5.641213211941562e-05,
      "loss": 0.5731,
      "step": 177700
    },
    {
      "epoch": 1.88226295647387,
      "grad_norm": 3.8898730278015137,
      "learning_rate": 5.644389159432564e-05,
      "loss": 0.5562,
      "step": 177800
    },
    {
      "epoch": 1.8833216000338766,
      "grad_norm": 3.9132072925567627,
      "learning_rate": 5.647565106923565e-05,
      "loss": 0.5619,
      "step": 177900
    },
    {
      "epoch": 1.884380243593883,
      "grad_norm": 4.6134138107299805,
      "learning_rate": 5.6507092949396565e-05,
      "loss": 0.5639,
      "step": 178000
    },
    {
      "epoch": 1.884380243593883,
      "eval_loss": 0.41390493512153625,
      "eval_runtime": 57.4549,
      "eval_samples_per_second": 2922.817,
      "eval_steps_per_second": 365.365,
      "step": 178000
    },
    {
      "epoch": 1.8854388871538896,
      "grad_norm": 4.363445281982422,
      "learning_rate": 5.653885242430658e-05,
      "loss": 0.5742,
      "step": 178100
    },
    {
      "epoch": 1.8864975307138963,
      "grad_norm": 4.325467109680176,
      "learning_rate": 5.6570611899216594e-05,
      "loss": 0.5628,
      "step": 178200
    },
    {
      "epoch": 1.8875561742739029,
      "grad_norm": 3.7813072204589844,
      "learning_rate": 5.660237137412661e-05,
      "loss": 0.5654,
      "step": 178300
    },
    {
      "epoch": 1.8886148178339095,
      "grad_norm": 4.1543145179748535,
      "learning_rate": 5.663413084903663e-05,
      "loss": 0.5666,
      "step": 178400
    },
    {
      "epoch": 1.8896734613939161,
      "grad_norm": 4.174543380737305,
      "learning_rate": 5.666589032394664e-05,
      "loss": 0.5622,
      "step": 178500
    },
    {
      "epoch": 1.8907321049539225,
      "grad_norm": 3.928956985473633,
      "learning_rate": 5.669764979885666e-05,
      "loss": 0.5587,
      "step": 178600
    },
    {
      "epoch": 1.8917907485139291,
      "grad_norm": 4.463919162750244,
      "learning_rate": 5.672940927376667e-05,
      "loss": 0.5628,
      "step": 178700
    },
    {
      "epoch": 1.8928493920739355,
      "grad_norm": 4.148786544799805,
      "learning_rate": 5.676116874867669e-05,
      "loss": 0.5635,
      "step": 178800
    },
    {
      "epoch": 1.8939080356339422,
      "grad_norm": 4.0312628746032715,
      "learning_rate": 5.67929282235867e-05,
      "loss": 0.5632,
      "step": 178900
    },
    {
      "epoch": 1.8949666791939488,
      "grad_norm": 3.7821686267852783,
      "learning_rate": 5.682468769849672e-05,
      "loss": 0.5629,
      "step": 179000
    },
    {
      "epoch": 1.8949666791939488,
      "eval_loss": 0.4119279086589813,
      "eval_runtime": 57.3694,
      "eval_samples_per_second": 2927.171,
      "eval_steps_per_second": 365.909,
      "step": 179000
    },
    {
      "epoch": 1.8960253227539554,
      "grad_norm": 4.835916042327881,
      "learning_rate": 5.685644717340673e-05,
      "loss": 0.5618,
      "step": 179100
    },
    {
      "epoch": 1.897083966313962,
      "grad_norm": 3.811413049697876,
      "learning_rate": 5.6888206648316746e-05,
      "loss": 0.5595,
      "step": 179200
    },
    {
      "epoch": 1.8981426098739684,
      "grad_norm": 4.039069652557373,
      "learning_rate": 5.691996612322676e-05,
      "loss": 0.5597,
      "step": 179300
    },
    {
      "epoch": 1.899201253433975,
      "grad_norm": 3.9737963676452637,
      "learning_rate": 5.6951725598136775e-05,
      "loss": 0.5637,
      "step": 179400
    },
    {
      "epoch": 1.9002598969939815,
      "grad_norm": 4.134841442108154,
      "learning_rate": 5.6983485073046786e-05,
      "loss": 0.5609,
      "step": 179500
    },
    {
      "epoch": 1.901318540553988,
      "grad_norm": 3.949937105178833,
      "learning_rate": 5.7015244547956804e-05,
      "loss": 0.5639,
      "step": 179600
    },
    {
      "epoch": 1.9023771841139947,
      "grad_norm": 4.563669204711914,
      "learning_rate": 5.7047004022866815e-05,
      "loss": 0.5592,
      "step": 179700
    },
    {
      "epoch": 1.9034358276740013,
      "grad_norm": 4.5231547355651855,
      "learning_rate": 5.707876349777683e-05,
      "loss": 0.567,
      "step": 179800
    },
    {
      "epoch": 1.904494471234008,
      "grad_norm": 3.805091381072998,
      "learning_rate": 5.711052297268685e-05,
      "loss": 0.5698,
      "step": 179900
    },
    {
      "epoch": 1.9055531147940146,
      "grad_norm": 4.344579696655273,
      "learning_rate": 5.714228244759686e-05,
      "loss": 0.5578,
      "step": 180000
    },
    {
      "epoch": 1.9055531147940146,
      "eval_loss": 0.410998672246933,
      "eval_runtime": 57.1887,
      "eval_samples_per_second": 2936.42,
      "eval_steps_per_second": 367.066,
      "step": 180000
    },
    {
      "epoch": 1.906611758354021,
      "grad_norm": 4.343329906463623,
      "learning_rate": 5.717404192250688e-05,
      "loss": 0.5589,
      "step": 180100
    },
    {
      "epoch": 1.9076704019140276,
      "grad_norm": 4.009679794311523,
      "learning_rate": 5.720580139741689e-05,
      "loss": 0.566,
      "step": 180200
    },
    {
      "epoch": 1.908729045474034,
      "grad_norm": 4.279111862182617,
      "learning_rate": 5.723756087232691e-05,
      "loss": 0.5562,
      "step": 180300
    },
    {
      "epoch": 1.9097876890340406,
      "grad_norm": 3.517343282699585,
      "learning_rate": 5.726932034723692e-05,
      "loss": 0.5564,
      "step": 180400
    },
    {
      "epoch": 1.9108463325940472,
      "grad_norm": 4.4866108894348145,
      "learning_rate": 5.730107982214694e-05,
      "loss": 0.5611,
      "step": 180500
    },
    {
      "epoch": 1.9119049761540539,
      "grad_norm": 4.426383972167969,
      "learning_rate": 5.733283929705695e-05,
      "loss": 0.5653,
      "step": 180600
    },
    {
      "epoch": 1.9129636197140605,
      "grad_norm": 4.2486090660095215,
      "learning_rate": 5.736459877196697e-05,
      "loss": 0.5595,
      "step": 180700
    },
    {
      "epoch": 1.914022263274067,
      "grad_norm": 4.147718906402588,
      "learning_rate": 5.739635824687698e-05,
      "loss": 0.5557,
      "step": 180800
    },
    {
      "epoch": 1.9150809068340735,
      "grad_norm": 4.569225311279297,
      "learning_rate": 5.7428117721786996e-05,
      "loss": 0.5574,
      "step": 180900
    },
    {
      "epoch": 1.91613955039408,
      "grad_norm": 4.174412727355957,
      "learning_rate": 5.745987719669701e-05,
      "loss": 0.5559,
      "step": 181000
    },
    {
      "epoch": 1.91613955039408,
      "eval_loss": 0.4075677990913391,
      "eval_runtime": 57.3171,
      "eval_samples_per_second": 2929.84,
      "eval_steps_per_second": 366.243,
      "step": 181000
    },
    {
      "epoch": 1.9171981939540865,
      "grad_norm": 4.08664608001709,
      "learning_rate": 5.7491636671607025e-05,
      "loss": 0.5609,
      "step": 181100
    },
    {
      "epoch": 1.9182568375140931,
      "grad_norm": 3.7049291133880615,
      "learning_rate": 5.7523396146517036e-05,
      "loss": 0.549,
      "step": 181200
    },
    {
      "epoch": 1.9193154810740998,
      "grad_norm": 4.753488063812256,
      "learning_rate": 5.7555155621427054e-05,
      "loss": 0.5566,
      "step": 181300
    },
    {
      "epoch": 1.9203741246341064,
      "grad_norm": 4.378996849060059,
      "learning_rate": 5.758691509633707e-05,
      "loss": 0.552,
      "step": 181400
    },
    {
      "epoch": 1.921432768194113,
      "grad_norm": 3.706939697265625,
      "learning_rate": 5.761867457124708e-05,
      "loss": 0.5565,
      "step": 181500
    },
    {
      "epoch": 1.9224914117541194,
      "grad_norm": 4.056438446044922,
      "learning_rate": 5.76504340461571e-05,
      "loss": 0.5575,
      "step": 181600
    },
    {
      "epoch": 1.923550055314126,
      "grad_norm": 3.997311592102051,
      "learning_rate": 5.768219352106711e-05,
      "loss": 0.5596,
      "step": 181700
    },
    {
      "epoch": 1.9246086988741324,
      "grad_norm": 4.366649627685547,
      "learning_rate": 5.771395299597713e-05,
      "loss": 0.5503,
      "step": 181800
    },
    {
      "epoch": 1.925667342434139,
      "grad_norm": 4.4167890548706055,
      "learning_rate": 5.774571247088714e-05,
      "loss": 0.5605,
      "step": 181900
    },
    {
      "epoch": 1.9267259859941457,
      "grad_norm": 3.995765209197998,
      "learning_rate": 5.7777154351048055e-05,
      "loss": 0.5475,
      "step": 182000
    },
    {
      "epoch": 1.9267259859941457,
      "eval_loss": 0.4060494899749756,
      "eval_runtime": 57.3566,
      "eval_samples_per_second": 2927.825,
      "eval_steps_per_second": 365.991,
      "step": 182000
    },
    {
      "epoch": 1.9277846295541523,
      "grad_norm": 3.6856961250305176,
      "learning_rate": 5.780891382595807e-05,
      "loss": 0.5564,
      "step": 182100
    },
    {
      "epoch": 1.928843273114159,
      "grad_norm": 4.097799777984619,
      "learning_rate": 5.7840673300868084e-05,
      "loss": 0.5438,
      "step": 182200
    },
    {
      "epoch": 1.9299019166741656,
      "grad_norm": 3.870753288269043,
      "learning_rate": 5.78724327757781e-05,
      "loss": 0.5605,
      "step": 182300
    },
    {
      "epoch": 1.930960560234172,
      "grad_norm": 3.977520227432251,
      "learning_rate": 5.7904192250688113e-05,
      "loss": 0.5581,
      "step": 182400
    },
    {
      "epoch": 1.9320192037941786,
      "grad_norm": 3.719850540161133,
      "learning_rate": 5.793595172559813e-05,
      "loss": 0.5533,
      "step": 182500
    },
    {
      "epoch": 1.933077847354185,
      "grad_norm": 4.164382457733154,
      "learning_rate": 5.796771120050815e-05,
      "loss": 0.5535,
      "step": 182600
    },
    {
      "epoch": 1.9341364909141916,
      "grad_norm": 4.317465305328369,
      "learning_rate": 5.799947067541816e-05,
      "loss": 0.5403,
      "step": 182700
    },
    {
      "epoch": 1.9351951344741982,
      "grad_norm": 4.218729496002197,
      "learning_rate": 5.803123015032818e-05,
      "loss": 0.5545,
      "step": 182800
    },
    {
      "epoch": 1.9362537780342048,
      "grad_norm": 4.230285167694092,
      "learning_rate": 5.806298962523819e-05,
      "loss": 0.5511,
      "step": 182900
    },
    {
      "epoch": 1.9373124215942115,
      "grad_norm": 4.439270973205566,
      "learning_rate": 5.809474910014821e-05,
      "loss": 0.551,
      "step": 183000
    },
    {
      "epoch": 1.9373124215942115,
      "eval_loss": 0.40346530079841614,
      "eval_runtime": 57.3098,
      "eval_samples_per_second": 2930.216,
      "eval_steps_per_second": 366.29,
      "step": 183000
    },
    {
      "epoch": 1.9383710651542179,
      "grad_norm": 4.109397888183594,
      "learning_rate": 5.812650857505822e-05,
      "loss": 0.5455,
      "step": 183100
    },
    {
      "epoch": 1.9394297087142245,
      "grad_norm": 3.875826120376587,
      "learning_rate": 5.8158268049968236e-05,
      "loss": 0.5496,
      "step": 183200
    },
    {
      "epoch": 1.9404883522742309,
      "grad_norm": 3.5127453804016113,
      "learning_rate": 5.819002752487825e-05,
      "loss": 0.5505,
      "step": 183300
    },
    {
      "epoch": 1.9415469958342375,
      "grad_norm": 3.878206729888916,
      "learning_rate": 5.8221786999788265e-05,
      "loss": 0.5549,
      "step": 183400
    },
    {
      "epoch": 1.9426056393942441,
      "grad_norm": 4.085826396942139,
      "learning_rate": 5.8253546474698277e-05,
      "loss": 0.5512,
      "step": 183500
    },
    {
      "epoch": 1.9436642829542508,
      "grad_norm": 3.555986166000366,
      "learning_rate": 5.8285305949608294e-05,
      "loss": 0.5423,
      "step": 183600
    },
    {
      "epoch": 1.9447229265142574,
      "grad_norm": 3.94622540473938,
      "learning_rate": 5.8317065424518306e-05,
      "loss": 0.5421,
      "step": 183700
    },
    {
      "epoch": 1.945781570074264,
      "grad_norm": 4.094287872314453,
      "learning_rate": 5.8348824899428323e-05,
      "loss": 0.5461,
      "step": 183800
    },
    {
      "epoch": 1.9468402136342704,
      "grad_norm": 4.4160356521606445,
      "learning_rate": 5.8380584374338335e-05,
      "loss": 0.5513,
      "step": 183900
    },
    {
      "epoch": 1.947898857194277,
      "grad_norm": 4.294723033905029,
      "learning_rate": 5.8412026254499255e-05,
      "loss": 0.545,
      "step": 184000
    },
    {
      "epoch": 1.947898857194277,
      "eval_loss": 0.40272533893585205,
      "eval_runtime": 57.3123,
      "eval_samples_per_second": 2930.086,
      "eval_steps_per_second": 366.274,
      "step": 184000
    },
    {
      "epoch": 1.9489575007542834,
      "grad_norm": 3.8956716060638428,
      "learning_rate": 5.844346813466017e-05,
      "loss": 0.5421,
      "step": 184100
    },
    {
      "epoch": 1.95001614431429,
      "grad_norm": 4.066079616546631,
      "learning_rate": 5.847522760957018e-05,
      "loss": 0.5519,
      "step": 184200
    },
    {
      "epoch": 1.9510747878742967,
      "grad_norm": 4.330808162689209,
      "learning_rate": 5.85069870844802e-05,
      "loss": 0.5513,
      "step": 184300
    },
    {
      "epoch": 1.9521334314343033,
      "grad_norm": 4.431099891662598,
      "learning_rate": 5.853874655939021e-05,
      "loss": 0.5432,
      "step": 184400
    },
    {
      "epoch": 1.95319207499431,
      "grad_norm": 4.384575843811035,
      "learning_rate": 5.857050603430023e-05,
      "loss": 0.547,
      "step": 184500
    },
    {
      "epoch": 1.9542507185543163,
      "grad_norm": 3.6915674209594727,
      "learning_rate": 5.860226550921024e-05,
      "loss": 0.5446,
      "step": 184600
    },
    {
      "epoch": 1.955309362114323,
      "grad_norm": 4.03389835357666,
      "learning_rate": 5.8634024984120256e-05,
      "loss": 0.5483,
      "step": 184700
    },
    {
      "epoch": 1.9563680056743293,
      "grad_norm": 4.115695953369141,
      "learning_rate": 5.8665784459030274e-05,
      "loss": 0.5488,
      "step": 184800
    },
    {
      "epoch": 1.957426649234336,
      "grad_norm": 3.7513411045074463,
      "learning_rate": 5.8697543933940285e-05,
      "loss": 0.5425,
      "step": 184900
    },
    {
      "epoch": 1.9584852927943426,
      "grad_norm": 4.125622749328613,
      "learning_rate": 5.87293034088503e-05,
      "loss": 0.5438,
      "step": 185000
    },
    {
      "epoch": 1.9584852927943426,
      "eval_loss": 0.3987550735473633,
      "eval_runtime": 57.3866,
      "eval_samples_per_second": 2926.294,
      "eval_steps_per_second": 365.8,
      "step": 185000
    },
    {
      "epoch": 1.9595439363543492,
      "grad_norm": 4.3758544921875,
      "learning_rate": 5.8761062883760314e-05,
      "loss": 0.5439,
      "step": 185100
    },
    {
      "epoch": 1.9606025799143558,
      "grad_norm": 4.486875057220459,
      "learning_rate": 5.879282235867033e-05,
      "loss": 0.5438,
      "step": 185200
    },
    {
      "epoch": 1.9616612234743624,
      "grad_norm": 3.5908188819885254,
      "learning_rate": 5.8824581833580343e-05,
      "loss": 0.5441,
      "step": 185300
    },
    {
      "epoch": 1.9627198670343688,
      "grad_norm": 3.847853899002075,
      "learning_rate": 5.885634130849036e-05,
      "loss": 0.5403,
      "step": 185400
    },
    {
      "epoch": 1.9637785105943755,
      "grad_norm": 3.882363796234131,
      "learning_rate": 5.888810078340037e-05,
      "loss": 0.546,
      "step": 185500
    },
    {
      "epoch": 1.9648371541543819,
      "grad_norm": 4.369241237640381,
      "learning_rate": 5.891986025831039e-05,
      "loss": 0.5392,
      "step": 185600
    },
    {
      "epoch": 1.9658957977143885,
      "grad_norm": 4.188266754150391,
      "learning_rate": 5.89516197332204e-05,
      "loss": 0.5452,
      "step": 185700
    },
    {
      "epoch": 1.9669544412743951,
      "grad_norm": 3.941469192504883,
      "learning_rate": 5.898337920813042e-05,
      "loss": 0.5472,
      "step": 185800
    },
    {
      "epoch": 1.9680130848344017,
      "grad_norm": 4.431057453155518,
      "learning_rate": 5.901513868304043e-05,
      "loss": 0.5496,
      "step": 185900
    },
    {
      "epoch": 1.9690717283944084,
      "grad_norm": 4.1244659423828125,
      "learning_rate": 5.904689815795045e-05,
      "loss": 0.5388,
      "step": 186000
    },
    {
      "epoch": 1.9690717283944084,
      "eval_loss": 0.39647233486175537,
      "eval_runtime": 57.2836,
      "eval_samples_per_second": 2931.556,
      "eval_steps_per_second": 366.458,
      "step": 186000
    },
    {
      "epoch": 1.9701303719544148,
      "grad_norm": 3.886660099029541,
      "learning_rate": 5.907865763286046e-05,
      "loss": 0.5436,
      "step": 186100
    },
    {
      "epoch": 1.9711890155144214,
      "grad_norm": 4.04350471496582,
      "learning_rate": 5.911041710777048e-05,
      "loss": 0.5478,
      "step": 186200
    },
    {
      "epoch": 1.9722476590744278,
      "grad_norm": 4.06578254699707,
      "learning_rate": 5.9142176582680495e-05,
      "loss": 0.5357,
      "step": 186300
    },
    {
      "epoch": 1.9733063026344344,
      "grad_norm": 4.097986221313477,
      "learning_rate": 5.9173936057590507e-05,
      "loss": 0.5432,
      "step": 186400
    },
    {
      "epoch": 1.974364946194441,
      "grad_norm": 3.7658774852752686,
      "learning_rate": 5.9205695532500524e-05,
      "loss": 0.5423,
      "step": 186500
    },
    {
      "epoch": 1.9754235897544477,
      "grad_norm": 3.7876784801483154,
      "learning_rate": 5.9237455007410536e-05,
      "loss": 0.539,
      "step": 186600
    },
    {
      "epoch": 1.9764822333144543,
      "grad_norm": 3.5742485523223877,
      "learning_rate": 5.9269214482320553e-05,
      "loss": 0.5458,
      "step": 186700
    },
    {
      "epoch": 1.977540876874461,
      "grad_norm": 3.867076873779297,
      "learning_rate": 5.9300973957230565e-05,
      "loss": 0.5461,
      "step": 186800
    },
    {
      "epoch": 1.9785995204344673,
      "grad_norm": 3.7917652130126953,
      "learning_rate": 5.933273343214058e-05,
      "loss": 0.5463,
      "step": 186900
    },
    {
      "epoch": 1.979658163994474,
      "grad_norm": 4.496640682220459,
      "learning_rate": 5.9364492907050594e-05,
      "loss": 0.5397,
      "step": 187000
    },
    {
      "epoch": 1.979658163994474,
      "eval_loss": 0.3964451253414154,
      "eval_runtime": 57.3667,
      "eval_samples_per_second": 2927.308,
      "eval_steps_per_second": 365.927,
      "step": 187000
    },
    {
      "epoch": 1.9807168075544803,
      "grad_norm": 3.51715350151062,
      "learning_rate": 5.939625238196061e-05,
      "loss": 0.5372,
      "step": 187100
    },
    {
      "epoch": 1.981775451114487,
      "grad_norm": 3.7954928874969482,
      "learning_rate": 5.942801185687062e-05,
      "loss": 0.5427,
      "step": 187200
    },
    {
      "epoch": 1.9828340946744936,
      "grad_norm": 3.8438918590545654,
      "learning_rate": 5.945977133178064e-05,
      "loss": 0.5398,
      "step": 187300
    },
    {
      "epoch": 1.9838927382345002,
      "grad_norm": 4.054104804992676,
      "learning_rate": 5.949153080669065e-05,
      "loss": 0.5443,
      "step": 187400
    },
    {
      "epoch": 1.9849513817945068,
      "grad_norm": 4.0015106201171875,
      "learning_rate": 5.952329028160067e-05,
      "loss": 0.5331,
      "step": 187500
    },
    {
      "epoch": 1.9860100253545132,
      "grad_norm": 3.923778533935547,
      "learning_rate": 5.955504975651068e-05,
      "loss": 0.5401,
      "step": 187600
    },
    {
      "epoch": 1.9870686689145198,
      "grad_norm": 3.931900978088379,
      "learning_rate": 5.95868092314207e-05,
      "loss": 0.5382,
      "step": 187700
    },
    {
      "epoch": 1.9881273124745262,
      "grad_norm": 4.0232253074646,
      "learning_rate": 5.9618568706330717e-05,
      "loss": 0.5319,
      "step": 187800
    },
    {
      "epoch": 1.9891859560345329,
      "grad_norm": 3.597933530807495,
      "learning_rate": 5.965032818124073e-05,
      "loss": 0.5394,
      "step": 187900
    },
    {
      "epoch": 1.9902445995945395,
      "grad_norm": 4.2887749671936035,
      "learning_rate": 5.9682087656150746e-05,
      "loss": 0.5381,
      "step": 188000
    },
    {
      "epoch": 1.9902445995945395,
      "eval_loss": 0.39319610595703125,
      "eval_runtime": 57.3905,
      "eval_samples_per_second": 2926.096,
      "eval_steps_per_second": 365.775,
      "step": 188000
    },
    {
      "epoch": 1.991303243154546,
      "grad_norm": 3.9442639350891113,
      "learning_rate": 5.971352953631166e-05,
      "loss": 0.5349,
      "step": 188100
    },
    {
      "epoch": 1.9923618867145527,
      "grad_norm": 4.121182918548584,
      "learning_rate": 5.974528901122167e-05,
      "loss": 0.5351,
      "step": 188200
    },
    {
      "epoch": 1.9934205302745593,
      "grad_norm": 4.2429423332214355,
      "learning_rate": 5.977704848613169e-05,
      "loss": 0.5313,
      "step": 188300
    },
    {
      "epoch": 1.9944791738345657,
      "grad_norm": 3.9455196857452393,
      "learning_rate": 5.98088079610417e-05,
      "loss": 0.5375,
      "step": 188400
    },
    {
      "epoch": 1.9955378173945724,
      "grad_norm": 4.185748100280762,
      "learning_rate": 5.984056743595172e-05,
      "loss": 0.5395,
      "step": 188500
    },
    {
      "epoch": 1.9965964609545788,
      "grad_norm": 4.356551647186279,
      "learning_rate": 5.987232691086173e-05,
      "loss": 0.529,
      "step": 188600
    },
    {
      "epoch": 1.9976551045145854,
      "grad_norm": 4.320939540863037,
      "learning_rate": 5.990408638577175e-05,
      "loss": 0.5384,
      "step": 188700
    },
    {
      "epoch": 1.998713748074592,
      "grad_norm": 3.739128589630127,
      "learning_rate": 5.993584586068176e-05,
      "loss": 0.5388,
      "step": 188800
    },
    {
      "epoch": 1.9997723916345986,
      "grad_norm": 4.056385517120361,
      "learning_rate": 5.9967605335591776e-05,
      "loss": 0.541,
      "step": 188900
    },
    {
      "epoch": 2.000825741976805,
      "grad_norm": 3.7393739223480225,
      "learning_rate": 5.9999364810501794e-05,
      "loss": 0.5205,
      "step": 189000
    },
    {
      "epoch": 2.000825741976805,
      "eval_loss": 0.39249858260154724,
      "eval_runtime": 57.3307,
      "eval_samples_per_second": 2929.147,
      "eval_steps_per_second": 366.156,
      "step": 189000
    },
    {
      "epoch": 2.001884385536812,
      "grad_norm": 4.057739734649658,
      "learning_rate": 6.0031124285411805e-05,
      "loss": 0.5334,
      "step": 189100
    },
    {
      "epoch": 2.0029430290968184,
      "grad_norm": 4.253291606903076,
      "learning_rate": 6.006288376032182e-05,
      "loss": 0.5304,
      "step": 189200
    },
    {
      "epoch": 2.0040016726568246,
      "grad_norm": 3.7356560230255127,
      "learning_rate": 6.009464323523184e-05,
      "loss": 0.5292,
      "step": 189300
    },
    {
      "epoch": 2.0050603162168312,
      "grad_norm": 3.815314531326294,
      "learning_rate": 6.012640271014186e-05,
      "loss": 0.5287,
      "step": 189400
    },
    {
      "epoch": 2.006118959776838,
      "grad_norm": 3.9837636947631836,
      "learning_rate": 6.015816218505187e-05,
      "loss": 0.5275,
      "step": 189500
    },
    {
      "epoch": 2.0071776033368445,
      "grad_norm": 4.297051906585693,
      "learning_rate": 6.018992165996189e-05,
      "loss": 0.5172,
      "step": 189600
    },
    {
      "epoch": 2.008236246896851,
      "grad_norm": 3.518610954284668,
      "learning_rate": 6.02216811348719e-05,
      "loss": 0.5306,
      "step": 189700
    },
    {
      "epoch": 2.0092948904568577,
      "grad_norm": 3.8644673824310303,
      "learning_rate": 6.0253440609781916e-05,
      "loss": 0.5293,
      "step": 189800
    },
    {
      "epoch": 2.0103535340168643,
      "grad_norm": 3.75119686126709,
      "learning_rate": 6.0285200084691934e-05,
      "loss": 0.528,
      "step": 189900
    },
    {
      "epoch": 2.011412177576871,
      "grad_norm": 4.170265197753906,
      "learning_rate": 6.0316959559601946e-05,
      "loss": 0.5312,
      "step": 190000
    },
    {
      "epoch": 2.011412177576871,
      "eval_loss": 0.3890531361103058,
      "eval_runtime": 57.4305,
      "eval_samples_per_second": 2924.058,
      "eval_steps_per_second": 365.52,
      "step": 190000
    },
    {
      "epoch": 2.012470821136877,
      "grad_norm": 4.061342239379883,
      "learning_rate": 6.034840143976286e-05,
      "loss": 0.5199,
      "step": 190100
    },
    {
      "epoch": 2.0135294646968838,
      "grad_norm": 4.408532619476318,
      "learning_rate": 6.038016091467288e-05,
      "loss": 0.5268,
      "step": 190200
    },
    {
      "epoch": 2.0145881082568904,
      "grad_norm": 4.078303337097168,
      "learning_rate": 6.041192038958289e-05,
      "loss": 0.5292,
      "step": 190300
    },
    {
      "epoch": 2.015646751816897,
      "grad_norm": 3.711521625518799,
      "learning_rate": 6.0443679864492906e-05,
      "loss": 0.5301,
      "step": 190400
    },
    {
      "epoch": 2.0167053953769036,
      "grad_norm": 3.812819480895996,
      "learning_rate": 6.047543933940292e-05,
      "loss": 0.524,
      "step": 190500
    },
    {
      "epoch": 2.0177640389369103,
      "grad_norm": 3.972973108291626,
      "learning_rate": 6.0507198814312935e-05,
      "loss": 0.5239,
      "step": 190600
    },
    {
      "epoch": 2.018822682496917,
      "grad_norm": 4.336397647857666,
      "learning_rate": 6.0538958289222947e-05,
      "loss": 0.5298,
      "step": 190700
    },
    {
      "epoch": 2.019881326056923,
      "grad_norm": 3.728829860687256,
      "learning_rate": 6.0570717764132964e-05,
      "loss": 0.5229,
      "step": 190800
    },
    {
      "epoch": 2.0209399696169297,
      "grad_norm": 4.067351341247559,
      "learning_rate": 6.060247723904298e-05,
      "loss": 0.5228,
      "step": 190900
    },
    {
      "epoch": 2.0219986131769363,
      "grad_norm": 3.8154125213623047,
      "learning_rate": 6.0634236713952994e-05,
      "loss": 0.5203,
      "step": 191000
    },
    {
      "epoch": 2.0219986131769363,
      "eval_loss": 0.3900442123413086,
      "eval_runtime": 57.153,
      "eval_samples_per_second": 2938.254,
      "eval_steps_per_second": 367.295,
      "step": 191000
    },
    {
      "epoch": 2.023057256736943,
      "grad_norm": 3.631728172302246,
      "learning_rate": 6.066599618886301e-05,
      "loss": 0.5303,
      "step": 191100
    },
    {
      "epoch": 2.0241159002969495,
      "grad_norm": 4.438848495483398,
      "learning_rate": 6.069775566377302e-05,
      "loss": 0.5291,
      "step": 191200
    },
    {
      "epoch": 2.025174543856956,
      "grad_norm": 3.7657299041748047,
      "learning_rate": 6.072951513868304e-05,
      "loss": 0.528,
      "step": 191300
    },
    {
      "epoch": 2.026233187416963,
      "grad_norm": 3.7534070014953613,
      "learning_rate": 6.076127461359305e-05,
      "loss": 0.5307,
      "step": 191400
    },
    {
      "epoch": 2.0272918309769694,
      "grad_norm": 4.1266770362854,
      "learning_rate": 6.079303408850307e-05,
      "loss": 0.526,
      "step": 191500
    },
    {
      "epoch": 2.0283504745369756,
      "grad_norm": 3.9175446033477783,
      "learning_rate": 6.082479356341308e-05,
      "loss": 0.5234,
      "step": 191600
    },
    {
      "epoch": 2.029409118096982,
      "grad_norm": 3.387852430343628,
      "learning_rate": 6.08565530383231e-05,
      "loss": 0.5275,
      "step": 191700
    },
    {
      "epoch": 2.030467761656989,
      "grad_norm": 3.8499460220336914,
      "learning_rate": 6.088831251323311e-05,
      "loss": 0.5298,
      "step": 191800
    },
    {
      "epoch": 2.0315264052169955,
      "grad_norm": 3.961413621902466,
      "learning_rate": 6.092007198814313e-05,
      "loss": 0.5241,
      "step": 191900
    },
    {
      "epoch": 2.032585048777002,
      "grad_norm": 3.884758710861206,
      "learning_rate": 6.095183146305314e-05,
      "loss": 0.5245,
      "step": 192000
    },
    {
      "epoch": 2.032585048777002,
      "eval_loss": 0.3885189890861511,
      "eval_runtime": 57.2464,
      "eval_samples_per_second": 2933.461,
      "eval_steps_per_second": 366.696,
      "step": 192000
    },
    {
      "epoch": 2.0336436923370087,
      "grad_norm": 4.05692720413208,
      "learning_rate": 6.098327334321406e-05,
      "loss": 0.517,
      "step": 192100
    },
    {
      "epoch": 2.0347023358970153,
      "grad_norm": 3.7968287467956543,
      "learning_rate": 6.101503281812407e-05,
      "loss": 0.5274,
      "step": 192200
    },
    {
      "epoch": 2.0357609794570215,
      "grad_norm": 3.9151053428649902,
      "learning_rate": 6.104679229303409e-05,
      "loss": 0.5271,
      "step": 192300
    },
    {
      "epoch": 2.036819623017028,
      "grad_norm": 3.6879665851593018,
      "learning_rate": 6.10785517679441e-05,
      "loss": 0.5275,
      "step": 192400
    },
    {
      "epoch": 2.0378782665770347,
      "grad_norm": 3.696324110031128,
      "learning_rate": 6.111031124285411e-05,
      "loss": 0.5292,
      "step": 192500
    },
    {
      "epoch": 2.0389369101370414,
      "grad_norm": 3.8560287952423096,
      "learning_rate": 6.114207071776413e-05,
      "loss": 0.5233,
      "step": 192600
    },
    {
      "epoch": 2.039995553697048,
      "grad_norm": 3.9689135551452637,
      "learning_rate": 6.117383019267415e-05,
      "loss": 0.5239,
      "step": 192700
    },
    {
      "epoch": 2.0410541972570546,
      "grad_norm": 3.9192917346954346,
      "learning_rate": 6.120558966758416e-05,
      "loss": 0.5256,
      "step": 192800
    },
    {
      "epoch": 2.0421128408170612,
      "grad_norm": 4.053020000457764,
      "learning_rate": 6.123734914249417e-05,
      "loss": 0.5263,
      "step": 192900
    },
    {
      "epoch": 2.043171484377068,
      "grad_norm": 3.990804672241211,
      "learning_rate": 6.126910861740419e-05,
      "loss": 0.5248,
      "step": 193000
    },
    {
      "epoch": 2.043171484377068,
      "eval_loss": 0.386557012796402,
      "eval_runtime": 57.3568,
      "eval_samples_per_second": 2927.811,
      "eval_steps_per_second": 365.989,
      "step": 193000
    },
    {
      "epoch": 2.044230127937074,
      "grad_norm": 3.781294345855713,
      "learning_rate": 6.13008680923142e-05,
      "loss": 0.5209,
      "step": 193100
    },
    {
      "epoch": 2.0452887714970807,
      "grad_norm": 3.862884998321533,
      "learning_rate": 6.133262756722422e-05,
      "loss": 0.5208,
      "step": 193200
    },
    {
      "epoch": 2.0463474150570873,
      "grad_norm": 3.7487378120422363,
      "learning_rate": 6.136438704213423e-05,
      "loss": 0.5194,
      "step": 193300
    },
    {
      "epoch": 2.047406058617094,
      "grad_norm": 3.9374287128448486,
      "learning_rate": 6.139614651704424e-05,
      "loss": 0.5243,
      "step": 193400
    },
    {
      "epoch": 2.0484647021771005,
      "grad_norm": 3.8147048950195312,
      "learning_rate": 6.142790599195426e-05,
      "loss": 0.5177,
      "step": 193500
    },
    {
      "epoch": 2.049523345737107,
      "grad_norm": 4.274939060211182,
      "learning_rate": 6.145966546686428e-05,
      "loss": 0.5245,
      "step": 193600
    },
    {
      "epoch": 2.0505819892971138,
      "grad_norm": 3.905240058898926,
      "learning_rate": 6.14914249417743e-05,
      "loss": 0.5262,
      "step": 193700
    },
    {
      "epoch": 2.0516406328571204,
      "grad_norm": 3.7498059272766113,
      "learning_rate": 6.15231844166843e-05,
      "loss": 0.5185,
      "step": 193800
    },
    {
      "epoch": 2.0526992764171266,
      "grad_norm": 3.2862608432769775,
      "learning_rate": 6.155494389159432e-05,
      "loss": 0.5243,
      "step": 193900
    },
    {
      "epoch": 2.053757919977133,
      "grad_norm": 3.97509503364563,
      "learning_rate": 6.158670336650434e-05,
      "loss": 0.5169,
      "step": 194000
    },
    {
      "epoch": 2.053757919977133,
      "eval_loss": 0.3846818208694458,
      "eval_runtime": 57.1806,
      "eval_samples_per_second": 2936.833,
      "eval_steps_per_second": 367.117,
      "step": 194000
    },
    {
      "epoch": 2.05481656353714,
      "grad_norm": 3.8166778087615967,
      "learning_rate": 6.161814524666525e-05,
      "loss": 0.5155,
      "step": 194100
    },
    {
      "epoch": 2.0558752070971464,
      "grad_norm": 3.7716615200042725,
      "learning_rate": 6.164990472157526e-05,
      "loss": 0.5215,
      "step": 194200
    },
    {
      "epoch": 2.056933850657153,
      "grad_norm": 4.357387065887451,
      "learning_rate": 6.168166419648528e-05,
      "loss": 0.5144,
      "step": 194300
    },
    {
      "epoch": 2.0579924942171597,
      "grad_norm": 3.644883155822754,
      "learning_rate": 6.17134236713953e-05,
      "loss": 0.5166,
      "step": 194400
    },
    {
      "epoch": 2.0590511377771663,
      "grad_norm": 3.733506441116333,
      "learning_rate": 6.17451831463053e-05,
      "loss": 0.5287,
      "step": 194500
    },
    {
      "epoch": 2.0601097813371725,
      "grad_norm": 4.245290279388428,
      "learning_rate": 6.177694262121532e-05,
      "loss": 0.5144,
      "step": 194600
    },
    {
      "epoch": 2.061168424897179,
      "grad_norm": 3.981826066970825,
      "learning_rate": 6.180870209612534e-05,
      "loss": 0.5099,
      "step": 194700
    },
    {
      "epoch": 2.0622270684571857,
      "grad_norm": 4.090139389038086,
      "learning_rate": 6.184046157103536e-05,
      "loss": 0.5254,
      "step": 194800
    },
    {
      "epoch": 2.0632857120171924,
      "grad_norm": 4.099998474121094,
      "learning_rate": 6.187222104594538e-05,
      "loss": 0.5233,
      "step": 194900
    },
    {
      "epoch": 2.064344355577199,
      "grad_norm": 4.0059709548950195,
      "learning_rate": 6.190366292610628e-05,
      "loss": 0.5229,
      "step": 195000
    },
    {
      "epoch": 2.064344355577199,
      "eval_loss": 0.38182562589645386,
      "eval_runtime": 57.3237,
      "eval_samples_per_second": 2929.503,
      "eval_steps_per_second": 366.201,
      "step": 195000
    },
    {
      "epoch": 2.0654029991372056,
      "grad_norm": 3.95185923576355,
      "learning_rate": 6.19354224010163e-05,
      "loss": 0.5115,
      "step": 195100
    },
    {
      "epoch": 2.066461642697212,
      "grad_norm": 3.880767822265625,
      "learning_rate": 6.196718187592632e-05,
      "loss": 0.5163,
      "step": 195200
    },
    {
      "epoch": 2.067520286257219,
      "grad_norm": 3.4014275074005127,
      "learning_rate": 6.199894135083632e-05,
      "loss": 0.5136,
      "step": 195300
    },
    {
      "epoch": 2.068578929817225,
      "grad_norm": 3.2963311672210693,
      "learning_rate": 6.203070082574634e-05,
      "loss": 0.5172,
      "step": 195400
    },
    {
      "epoch": 2.0696375733772316,
      "grad_norm": 3.553415298461914,
      "learning_rate": 6.206246030065636e-05,
      "loss": 0.5239,
      "step": 195500
    },
    {
      "epoch": 2.0706962169372383,
      "grad_norm": 4.1289963722229,
      "learning_rate": 6.209421977556638e-05,
      "loss": 0.5202,
      "step": 195600
    },
    {
      "epoch": 2.071754860497245,
      "grad_norm": 3.4783105850219727,
      "learning_rate": 6.212597925047638e-05,
      "loss": 0.5129,
      "step": 195700
    },
    {
      "epoch": 2.0728135040572515,
      "grad_norm": 3.9373581409454346,
      "learning_rate": 6.21577387253864e-05,
      "loss": 0.5172,
      "step": 195800
    },
    {
      "epoch": 2.073872147617258,
      "grad_norm": 4.222344875335693,
      "learning_rate": 6.218949820029642e-05,
      "loss": 0.5233,
      "step": 195900
    },
    {
      "epoch": 2.0749307911772648,
      "grad_norm": 3.853177785873413,
      "learning_rate": 6.222125767520643e-05,
      "loss": 0.5163,
      "step": 196000
    },
    {
      "epoch": 2.0749307911772648,
      "eval_loss": 0.381729394197464,
      "eval_runtime": 57.2552,
      "eval_samples_per_second": 2933.011,
      "eval_steps_per_second": 366.64,
      "step": 196000
    },
    {
      "epoch": 2.075989434737271,
      "grad_norm": 3.677940607070923,
      "learning_rate": 6.225301715011645e-05,
      "loss": 0.5191,
      "step": 196100
    },
    {
      "epoch": 2.0770480782972776,
      "grad_norm": 3.985670328140259,
      "learning_rate": 6.228477662502646e-05,
      "loss": 0.5152,
      "step": 196200
    },
    {
      "epoch": 2.078106721857284,
      "grad_norm": 3.3095479011535645,
      "learning_rate": 6.231653609993647e-05,
      "loss": 0.5185,
      "step": 196300
    },
    {
      "epoch": 2.079165365417291,
      "grad_norm": 3.591186761856079,
      "learning_rate": 6.234829557484649e-05,
      "loss": 0.5166,
      "step": 196400
    },
    {
      "epoch": 2.0802240089772974,
      "grad_norm": 3.622952938079834,
      "learning_rate": 6.238005504975651e-05,
      "loss": 0.5116,
      "step": 196500
    },
    {
      "epoch": 2.081282652537304,
      "grad_norm": 4.063910484313965,
      "learning_rate": 6.241181452466651e-05,
      "loss": 0.5224,
      "step": 196600
    },
    {
      "epoch": 2.0823412960973107,
      "grad_norm": 4.1373291015625,
      "learning_rate": 6.244357399957653e-05,
      "loss": 0.5163,
      "step": 196700
    },
    {
      "epoch": 2.0833999396573173,
      "grad_norm": 3.880507707595825,
      "learning_rate": 6.247533347448655e-05,
      "loss": 0.518,
      "step": 196800
    },
    {
      "epoch": 2.0844585832173235,
      "grad_norm": 4.058618545532227,
      "learning_rate": 6.250709294939657e-05,
      "loss": 0.5186,
      "step": 196900
    },
    {
      "epoch": 2.08551722677733,
      "grad_norm": 3.676201581954956,
      "learning_rate": 6.253885242430657e-05,
      "loss": 0.5172,
      "step": 197000
    },
    {
      "epoch": 2.08551722677733,
      "eval_loss": 0.3808770179748535,
      "eval_runtime": 57.2192,
      "eval_samples_per_second": 2934.854,
      "eval_steps_per_second": 366.87,
      "step": 197000
    },
    {
      "epoch": 2.0865758703373367,
      "grad_norm": 3.999314785003662,
      "learning_rate": 6.257061189921659e-05,
      "loss": 0.5168,
      "step": 197100
    },
    {
      "epoch": 2.0876345138973433,
      "grad_norm": 3.956937074661255,
      "learning_rate": 6.260237137412661e-05,
      "loss": 0.517,
      "step": 197200
    },
    {
      "epoch": 2.08869315745735,
      "grad_norm": 3.702136516571045,
      "learning_rate": 6.263413084903663e-05,
      "loss": 0.5155,
      "step": 197300
    },
    {
      "epoch": 2.0897518010173566,
      "grad_norm": 3.5822150707244873,
      "learning_rate": 6.266589032394664e-05,
      "loss": 0.5159,
      "step": 197400
    },
    {
      "epoch": 2.090810444577363,
      "grad_norm": 3.468641757965088,
      "learning_rate": 6.269764979885665e-05,
      "loss": 0.5118,
      "step": 197500
    },
    {
      "epoch": 2.0918690881373694,
      "grad_norm": 3.982022523880005,
      "learning_rate": 6.272940927376667e-05,
      "loss": 0.5126,
      "step": 197600
    },
    {
      "epoch": 2.092927731697376,
      "grad_norm": 4.026547908782959,
      "learning_rate": 6.276116874867668e-05,
      "loss": 0.5182,
      "step": 197700
    },
    {
      "epoch": 2.0939863752573826,
      "grad_norm": 3.8723762035369873,
      "learning_rate": 6.27929282235867e-05,
      "loss": 0.5143,
      "step": 197800
    },
    {
      "epoch": 2.0950450188173892,
      "grad_norm": 3.7586610317230225,
      "learning_rate": 6.282468769849671e-05,
      "loss": 0.5151,
      "step": 197900
    },
    {
      "epoch": 2.096103662377396,
      "grad_norm": 3.791477680206299,
      "learning_rate": 6.285644717340672e-05,
      "loss": 0.5184,
      "step": 198000
    },
    {
      "epoch": 2.096103662377396,
      "eval_loss": 0.37832552194595337,
      "eval_runtime": 57.3146,
      "eval_samples_per_second": 2929.967,
      "eval_steps_per_second": 366.259,
      "step": 198000
    },
    {
      "epoch": 2.0971623059374025,
      "grad_norm": 4.095690727233887,
      "learning_rate": 6.288820664831674e-05,
      "loss": 0.5154,
      "step": 198100
    },
    {
      "epoch": 2.098220949497409,
      "grad_norm": 3.703024387359619,
      "learning_rate": 6.291996612322676e-05,
      "loss": 0.5081,
      "step": 198200
    },
    {
      "epoch": 2.0992795930574157,
      "grad_norm": 3.929654359817505,
      "learning_rate": 6.295172559813677e-05,
      "loss": 0.5052,
      "step": 198300
    },
    {
      "epoch": 2.100338236617422,
      "grad_norm": 4.161444664001465,
      "learning_rate": 6.298348507304678e-05,
      "loss": 0.5189,
      "step": 198400
    },
    {
      "epoch": 2.1013968801774285,
      "grad_norm": 3.3038244247436523,
      "learning_rate": 6.30149269532077e-05,
      "loss": 0.5162,
      "step": 198500
    },
    {
      "epoch": 2.102455523737435,
      "grad_norm": 3.850653648376465,
      "learning_rate": 6.304668642811772e-05,
      "loss": 0.5155,
      "step": 198600
    },
    {
      "epoch": 2.103514167297442,
      "grad_norm": 4.01956033706665,
      "learning_rate": 6.307844590302773e-05,
      "loss": 0.5121,
      "step": 198700
    },
    {
      "epoch": 2.1045728108574484,
      "grad_norm": 4.036940097808838,
      "learning_rate": 6.311020537793774e-05,
      "loss": 0.5085,
      "step": 198800
    },
    {
      "epoch": 2.105631454417455,
      "grad_norm": 4.186519622802734,
      "learning_rate": 6.314196485284776e-05,
      "loss": 0.512,
      "step": 198900
    },
    {
      "epoch": 2.1066900979774617,
      "grad_norm": 3.941633701324463,
      "learning_rate": 6.317372432775778e-05,
      "loss": 0.5134,
      "step": 199000
    },
    {
      "epoch": 2.1066900979774617,
      "eval_loss": 0.37789928913116455,
      "eval_runtime": 57.3055,
      "eval_samples_per_second": 2930.435,
      "eval_steps_per_second": 366.317,
      "step": 199000
    },
    {
      "epoch": 2.107748741537468,
      "grad_norm": 3.28469181060791,
      "learning_rate": 6.320548380266778e-05,
      "loss": 0.5127,
      "step": 199100
    },
    {
      "epoch": 2.1088073850974745,
      "grad_norm": 3.5263216495513916,
      "learning_rate": 6.32372432775778e-05,
      "loss": 0.5122,
      "step": 199200
    },
    {
      "epoch": 2.109866028657481,
      "grad_norm": 3.6876883506774902,
      "learning_rate": 6.326900275248782e-05,
      "loss": 0.5059,
      "step": 199300
    },
    {
      "epoch": 2.1109246722174877,
      "grad_norm": 3.598771572113037,
      "learning_rate": 6.330076222739784e-05,
      "loss": 0.5107,
      "step": 199400
    },
    {
      "epoch": 2.1119833157774943,
      "grad_norm": 3.513780355453491,
      "learning_rate": 6.333252170230784e-05,
      "loss": 0.5049,
      "step": 199500
    },
    {
      "epoch": 2.113041959337501,
      "grad_norm": 4.227871417999268,
      "learning_rate": 6.336428117721786e-05,
      "loss": 0.5076,
      "step": 199600
    },
    {
      "epoch": 2.1141006028975076,
      "grad_norm": 3.6999380588531494,
      "learning_rate": 6.339604065212788e-05,
      "loss": 0.5109,
      "step": 199700
    },
    {
      "epoch": 2.115159246457514,
      "grad_norm": 4.085605621337891,
      "learning_rate": 6.34278001270379e-05,
      "loss": 0.516,
      "step": 199800
    },
    {
      "epoch": 2.1162178900175204,
      "grad_norm": 3.556417226791382,
      "learning_rate": 6.34595596019479e-05,
      "loss": 0.5104,
      "step": 199900
    },
    {
      "epoch": 2.117276533577527,
      "grad_norm": 3.6560580730438232,
      "learning_rate": 6.349131907685792e-05,
      "loss": 0.5129,
      "step": 200000
    },
    {
      "epoch": 2.117276533577527,
      "eval_loss": 0.3752836585044861,
      "eval_runtime": 57.2673,
      "eval_samples_per_second": 2932.389,
      "eval_steps_per_second": 366.562,
      "step": 200000
    },
    {
      "epoch": 2.1183351771375336,
      "grad_norm": 3.2765414714813232,
      "learning_rate": 6.352307855176794e-05,
      "loss": 0.5053,
      "step": 200100
    },
    {
      "epoch": 2.1193938206975402,
      "grad_norm": 3.8014206886291504,
      "learning_rate": 6.355483802667795e-05,
      "loss": 0.5168,
      "step": 200200
    },
    {
      "epoch": 2.120452464257547,
      "grad_norm": 4.172168731689453,
      "learning_rate": 6.358659750158797e-05,
      "loss": 0.5129,
      "step": 200300
    },
    {
      "epoch": 2.1215111078175535,
      "grad_norm": 3.8831937313079834,
      "learning_rate": 6.361835697649798e-05,
      "loss": 0.5096,
      "step": 200400
    },
    {
      "epoch": 2.12256975137756,
      "grad_norm": 3.7033402919769287,
      "learning_rate": 6.3650116451408e-05,
      "loss": 0.5076,
      "step": 200500
    },
    {
      "epoch": 2.1236283949375663,
      "grad_norm": 3.9876363277435303,
      "learning_rate": 6.368187592631801e-05,
      "loss": 0.5086,
      "step": 200600
    },
    {
      "epoch": 2.124687038497573,
      "grad_norm": 3.5912764072418213,
      "learning_rate": 6.371363540122803e-05,
      "loss": 0.5081,
      "step": 200700
    },
    {
      "epoch": 2.1257456820575795,
      "grad_norm": 3.9026544094085693,
      "learning_rate": 6.374539487613803e-05,
      "loss": 0.5094,
      "step": 200800
    },
    {
      "epoch": 2.126804325617586,
      "grad_norm": 4.014391899108887,
      "learning_rate": 6.377715435104805e-05,
      "loss": 0.509,
      "step": 200900
    },
    {
      "epoch": 2.1278629691775928,
      "grad_norm": 3.845970630645752,
      "learning_rate": 6.380891382595807e-05,
      "loss": 0.5015,
      "step": 201000
    },
    {
      "epoch": 2.1278629691775928,
      "eval_loss": 0.37367117404937744,
      "eval_runtime": 57.3162,
      "eval_samples_per_second": 2929.886,
      "eval_steps_per_second": 366.249,
      "step": 201000
    },
    {
      "epoch": 2.1289216127375994,
      "grad_norm": 3.9618942737579346,
      "learning_rate": 6.384035570611899e-05,
      "loss": 0.5131,
      "step": 201100
    },
    {
      "epoch": 2.129980256297606,
      "grad_norm": 3.9919538497924805,
      "learning_rate": 6.3872115181029e-05,
      "loss": 0.5042,
      "step": 201200
    },
    {
      "epoch": 2.1310388998576126,
      "grad_norm": 3.8873260021209717,
      "learning_rate": 6.390387465593901e-05,
      "loss": 0.5065,
      "step": 201300
    },
    {
      "epoch": 2.132097543417619,
      "grad_norm": 3.4975945949554443,
      "learning_rate": 6.393563413084903e-05,
      "loss": 0.5045,
      "step": 201400
    },
    {
      "epoch": 2.1331561869776254,
      "grad_norm": 3.6531708240509033,
      "learning_rate": 6.396739360575905e-05,
      "loss": 0.5129,
      "step": 201500
    },
    {
      "epoch": 2.134214830537632,
      "grad_norm": 3.7457568645477295,
      "learning_rate": 6.399915308066905e-05,
      "loss": 0.5089,
      "step": 201600
    },
    {
      "epoch": 2.1352734740976387,
      "grad_norm": 3.830366373062134,
      "learning_rate": 6.403091255557907e-05,
      "loss": 0.5112,
      "step": 201700
    },
    {
      "epoch": 2.1363321176576453,
      "grad_norm": 3.7501022815704346,
      "learning_rate": 6.406267203048909e-05,
      "loss": 0.5097,
      "step": 201800
    },
    {
      "epoch": 2.137390761217652,
      "grad_norm": 4.359776020050049,
      "learning_rate": 6.409443150539911e-05,
      "loss": 0.5107,
      "step": 201900
    },
    {
      "epoch": 2.1384494047776585,
      "grad_norm": 3.4925014972686768,
      "learning_rate": 6.412619098030911e-05,
      "loss": 0.507,
      "step": 202000
    },
    {
      "epoch": 2.1384494047776585,
      "eval_loss": 0.3714517056941986,
      "eval_runtime": 57.3003,
      "eval_samples_per_second": 2930.702,
      "eval_steps_per_second": 366.351,
      "step": 202000
    },
    {
      "epoch": 2.1395080483376647,
      "grad_norm": 3.831617593765259,
      "learning_rate": 6.415795045521913e-05,
      "loss": 0.4994,
      "step": 202100
    },
    {
      "epoch": 2.1405666918976713,
      "grad_norm": 3.4185683727264404,
      "learning_rate": 6.418970993012915e-05,
      "loss": 0.5087,
      "step": 202200
    },
    {
      "epoch": 2.141625335457678,
      "grad_norm": 3.4556963443756104,
      "learning_rate": 6.422146940503916e-05,
      "loss": 0.5035,
      "step": 202300
    },
    {
      "epoch": 2.1426839790176846,
      "grad_norm": 3.168424129486084,
      "learning_rate": 6.425322887994917e-05,
      "loss": 0.5006,
      "step": 202400
    },
    {
      "epoch": 2.143742622577691,
      "grad_norm": 3.645434856414795,
      "learning_rate": 6.428498835485919e-05,
      "loss": 0.504,
      "step": 202500
    },
    {
      "epoch": 2.144801266137698,
      "grad_norm": 3.516000986099243,
      "learning_rate": 6.43167478297692e-05,
      "loss": 0.5095,
      "step": 202600
    },
    {
      "epoch": 2.1458599096977045,
      "grad_norm": 3.1348001956939697,
      "learning_rate": 6.434850730467922e-05,
      "loss": 0.5041,
      "step": 202700
    },
    {
      "epoch": 2.146918553257711,
      "grad_norm": 3.7488160133361816,
      "learning_rate": 6.438026677958924e-05,
      "loss": 0.511,
      "step": 202800
    },
    {
      "epoch": 2.1479771968177173,
      "grad_norm": 3.918264627456665,
      "learning_rate": 6.441202625449925e-05,
      "loss": 0.51,
      "step": 202900
    },
    {
      "epoch": 2.149035840377724,
      "grad_norm": 3.81108021736145,
      "learning_rate": 6.444378572940926e-05,
      "loss": 0.5045,
      "step": 203000
    },
    {
      "epoch": 2.149035840377724,
      "eval_loss": 0.37050601840019226,
      "eval_runtime": 57.2072,
      "eval_samples_per_second": 2935.47,
      "eval_steps_per_second": 366.947,
      "step": 203000
    },
    {
      "epoch": 2.1500944839377305,
      "grad_norm": 3.6279478073120117,
      "learning_rate": 6.447554520431928e-05,
      "loss": 0.5054,
      "step": 203100
    },
    {
      "epoch": 2.151153127497737,
      "grad_norm": 3.7897162437438965,
      "learning_rate": 6.45073046792293e-05,
      "loss": 0.509,
      "step": 203200
    },
    {
      "epoch": 2.1522117710577437,
      "grad_norm": 3.645801067352295,
      "learning_rate": 6.453906415413932e-05,
      "loss": 0.5008,
      "step": 203300
    },
    {
      "epoch": 2.1532704146177504,
      "grad_norm": 3.1965432167053223,
      "learning_rate": 6.457082362904933e-05,
      "loss": 0.5111,
      "step": 203400
    },
    {
      "epoch": 2.154329058177757,
      "grad_norm": 3.600308895111084,
      "learning_rate": 6.460258310395935e-05,
      "loss": 0.4991,
      "step": 203500
    },
    {
      "epoch": 2.155387701737763,
      "grad_norm": 4.154588222503662,
      "learning_rate": 6.463402498412025e-05,
      "loss": 0.5043,
      "step": 203600
    },
    {
      "epoch": 2.15644634529777,
      "grad_norm": 3.5863168239593506,
      "learning_rate": 6.466578445903026e-05,
      "loss": 0.4993,
      "step": 203700
    },
    {
      "epoch": 2.1575049888577764,
      "grad_norm": 3.4437615871429443,
      "learning_rate": 6.46975439339403e-05,
      "loss": 0.5037,
      "step": 203800
    },
    {
      "epoch": 2.158563632417783,
      "grad_norm": 3.8621249198913574,
      "learning_rate": 6.47293034088503e-05,
      "loss": 0.5048,
      "step": 203900
    },
    {
      "epoch": 2.1596222759777897,
      "grad_norm": 3.2480356693267822,
      "learning_rate": 6.476106288376032e-05,
      "loss": 0.5034,
      "step": 204000
    },
    {
      "epoch": 2.1596222759777897,
      "eval_loss": 0.3715610206127167,
      "eval_runtime": 57.3492,
      "eval_samples_per_second": 2928.202,
      "eval_steps_per_second": 366.038,
      "step": 204000
    },
    {
      "epoch": 2.1606809195377963,
      "grad_norm": 3.7076661586761475,
      "learning_rate": 6.479282235867034e-05,
      "loss": 0.5098,
      "step": 204100
    },
    {
      "epoch": 2.161739563097803,
      "grad_norm": 3.747986316680908,
      "learning_rate": 6.482458183358035e-05,
      "loss": 0.5039,
      "step": 204200
    },
    {
      "epoch": 2.1627982066578095,
      "grad_norm": 3.5519676208496094,
      "learning_rate": 6.485634130849036e-05,
      "loss": 0.5112,
      "step": 204300
    },
    {
      "epoch": 2.1638568502178157,
      "grad_norm": 3.4310920238494873,
      "learning_rate": 6.488810078340038e-05,
      "loss": 0.4975,
      "step": 204400
    },
    {
      "epoch": 2.1649154937778223,
      "grad_norm": 3.699298143386841,
      "learning_rate": 6.49198602583104e-05,
      "loss": 0.5032,
      "step": 204500
    },
    {
      "epoch": 2.165974137337829,
      "grad_norm": 3.4004034996032715,
      "learning_rate": 6.495161973322041e-05,
      "loss": 0.5019,
      "step": 204600
    },
    {
      "epoch": 2.1670327808978356,
      "grad_norm": 3.6542866230010986,
      "learning_rate": 6.498337920813043e-05,
      "loss": 0.4969,
      "step": 204700
    },
    {
      "epoch": 2.168091424457842,
      "grad_norm": 3.7089622020721436,
      "learning_rate": 6.501513868304043e-05,
      "loss": 0.5055,
      "step": 204800
    },
    {
      "epoch": 2.169150068017849,
      "grad_norm": 3.663360118865967,
      "learning_rate": 6.504689815795045e-05,
      "loss": 0.4973,
      "step": 204900
    },
    {
      "epoch": 2.1702087115778554,
      "grad_norm": 3.705493927001953,
      "learning_rate": 6.507865763286047e-05,
      "loss": 0.5011,
      "step": 205000
    },
    {
      "epoch": 2.1702087115778554,
      "eval_loss": 0.367346853017807,
      "eval_runtime": 57.4315,
      "eval_samples_per_second": 2924.007,
      "eval_steps_per_second": 365.514,
      "step": 205000
    },
    {
      "epoch": 2.171267355137862,
      "grad_norm": 4.0275349617004395,
      "learning_rate": 6.511041710777049e-05,
      "loss": 0.507,
      "step": 205100
    },
    {
      "epoch": 2.1723259986978682,
      "grad_norm": 3.6920385360717773,
      "learning_rate": 6.514217658268049e-05,
      "loss": 0.5039,
      "step": 205200
    },
    {
      "epoch": 2.173384642257875,
      "grad_norm": 3.779345750808716,
      "learning_rate": 6.517393605759051e-05,
      "loss": 0.5066,
      "step": 205300
    },
    {
      "epoch": 2.1744432858178815,
      "grad_norm": 3.6594202518463135,
      "learning_rate": 6.520569553250053e-05,
      "loss": 0.5034,
      "step": 205400
    },
    {
      "epoch": 2.175501929377888,
      "grad_norm": 4.029668807983398,
      "learning_rate": 6.523745500741055e-05,
      "loss": 0.5008,
      "step": 205500
    },
    {
      "epoch": 2.1765605729378947,
      "grad_norm": 3.398277521133423,
      "learning_rate": 6.526921448232055e-05,
      "loss": 0.503,
      "step": 205600
    },
    {
      "epoch": 2.1776192164979014,
      "grad_norm": 3.5865237712860107,
      "learning_rate": 6.530097395723057e-05,
      "loss": 0.4978,
      "step": 205700
    },
    {
      "epoch": 2.178677860057908,
      "grad_norm": 3.800053596496582,
      "learning_rate": 6.533273343214059e-05,
      "loss": 0.5042,
      "step": 205800
    },
    {
      "epoch": 2.1797365036179146,
      "grad_norm": 3.0827982425689697,
      "learning_rate": 6.53644929070506e-05,
      "loss": 0.4979,
      "step": 205900
    },
    {
      "epoch": 2.180795147177921,
      "grad_norm": 3.2451388835906982,
      "learning_rate": 6.539625238196061e-05,
      "loss": 0.4986,
      "step": 206000
    },
    {
      "epoch": 2.180795147177921,
      "eval_loss": 0.36849045753479004,
      "eval_runtime": 57.2974,
      "eval_samples_per_second": 2930.851,
      "eval_steps_per_second": 366.369,
      "step": 206000
    },
    {
      "epoch": 2.1818537907379274,
      "grad_norm": 3.631300926208496,
      "learning_rate": 6.542801185687063e-05,
      "loss": 0.497,
      "step": 206100
    },
    {
      "epoch": 2.182912434297934,
      "grad_norm": 3.4763455390930176,
      "learning_rate": 6.545977133178064e-05,
      "loss": 0.5016,
      "step": 206200
    },
    {
      "epoch": 2.1839710778579406,
      "grad_norm": 4.09908390045166,
      "learning_rate": 6.549121321194156e-05,
      "loss": 0.5012,
      "step": 206300
    },
    {
      "epoch": 2.1850297214179473,
      "grad_norm": 3.466562271118164,
      "learning_rate": 6.552297268685157e-05,
      "loss": 0.5017,
      "step": 206400
    },
    {
      "epoch": 2.186088364977954,
      "grad_norm": 3.6075751781463623,
      "learning_rate": 6.555473216176159e-05,
      "loss": 0.4974,
      "step": 206500
    },
    {
      "epoch": 2.1871470085379605,
      "grad_norm": 3.5216944217681885,
      "learning_rate": 6.55864916366716e-05,
      "loss": 0.4964,
      "step": 206600
    },
    {
      "epoch": 2.1882056520979667,
      "grad_norm": 3.4389450550079346,
      "learning_rate": 6.561825111158162e-05,
      "loss": 0.495,
      "step": 206700
    },
    {
      "epoch": 2.1892642956579733,
      "grad_norm": 3.3800718784332275,
      "learning_rate": 6.565001058649163e-05,
      "loss": 0.499,
      "step": 206800
    },
    {
      "epoch": 2.19032293921798,
      "grad_norm": 3.5224151611328125,
      "learning_rate": 6.568177006140165e-05,
      "loss": 0.4961,
      "step": 206900
    },
    {
      "epoch": 2.1913815827779866,
      "grad_norm": 3.6215929985046387,
      "learning_rate": 6.571352953631166e-05,
      "loss": 0.499,
      "step": 207000
    },
    {
      "epoch": 2.1913815827779866,
      "eval_loss": 0.3666445016860962,
      "eval_runtime": 57.3859,
      "eval_samples_per_second": 2926.326,
      "eval_steps_per_second": 365.804,
      "step": 207000
    },
    {
      "epoch": 2.192440226337993,
      "grad_norm": 3.6748623847961426,
      "learning_rate": 6.574528901122168e-05,
      "loss": 0.4995,
      "step": 207100
    },
    {
      "epoch": 2.193498869898,
      "grad_norm": 3.950977325439453,
      "learning_rate": 6.577704848613169e-05,
      "loss": 0.4941,
      "step": 207200
    },
    {
      "epoch": 2.1945575134580064,
      "grad_norm": 3.353412389755249,
      "learning_rate": 6.58088079610417e-05,
      "loss": 0.4938,
      "step": 207300
    },
    {
      "epoch": 2.195616157018013,
      "grad_norm": 3.5159850120544434,
      "learning_rate": 6.584056743595172e-05,
      "loss": 0.5012,
      "step": 207400
    },
    {
      "epoch": 2.1966748005780192,
      "grad_norm": 3.5040056705474854,
      "learning_rate": 6.587232691086174e-05,
      "loss": 0.4981,
      "step": 207500
    },
    {
      "epoch": 2.197733444138026,
      "grad_norm": 3.56219482421875,
      "learning_rate": 6.590408638577176e-05,
      "loss": 0.501,
      "step": 207600
    },
    {
      "epoch": 2.1987920876980325,
      "grad_norm": 3.429488182067871,
      "learning_rate": 6.593584586068176e-05,
      "loss": 0.5011,
      "step": 207700
    },
    {
      "epoch": 2.199850731258039,
      "grad_norm": 3.36533522605896,
      "learning_rate": 6.596760533559178e-05,
      "loss": 0.4987,
      "step": 207800
    },
    {
      "epoch": 2.2009093748180457,
      "grad_norm": 3.556635856628418,
      "learning_rate": 6.59993648105018e-05,
      "loss": 0.4928,
      "step": 207900
    },
    {
      "epoch": 2.2019680183780523,
      "grad_norm": 4.081921577453613,
      "learning_rate": 6.603112428541182e-05,
      "loss": 0.4943,
      "step": 208000
    },
    {
      "epoch": 2.2019680183780523,
      "eval_loss": 0.3638177216053009,
      "eval_runtime": 57.3447,
      "eval_samples_per_second": 2928.433,
      "eval_steps_per_second": 366.067,
      "step": 208000
    },
    {
      "epoch": 2.203026661938059,
      "grad_norm": 3.4540302753448486,
      "learning_rate": 6.606288376032182e-05,
      "loss": 0.501,
      "step": 208100
    },
    {
      "epoch": 2.204085305498065,
      "grad_norm": 3.0685598850250244,
      "learning_rate": 6.609464323523184e-05,
      "loss": 0.4981,
      "step": 208200
    },
    {
      "epoch": 2.2051439490580718,
      "grad_norm": 3.646665334701538,
      "learning_rate": 6.612640271014186e-05,
      "loss": 0.4916,
      "step": 208300
    },
    {
      "epoch": 2.2062025926180784,
      "grad_norm": 3.3260245323181152,
      "learning_rate": 6.615816218505187e-05,
      "loss": 0.4988,
      "step": 208400
    },
    {
      "epoch": 2.207261236178085,
      "grad_norm": 3.9853086471557617,
      "learning_rate": 6.618960406521278e-05,
      "loss": 0.5036,
      "step": 208500
    },
    {
      "epoch": 2.2083198797380916,
      "grad_norm": 3.506349563598633,
      "learning_rate": 6.62213635401228e-05,
      "loss": 0.4946,
      "step": 208600
    },
    {
      "epoch": 2.2093785232980983,
      "grad_norm": 3.9742119312286377,
      "learning_rate": 6.625312301503282e-05,
      "loss": 0.4991,
      "step": 208700
    },
    {
      "epoch": 2.210437166858105,
      "grad_norm": 3.426356315612793,
      "learning_rate": 6.628488248994283e-05,
      "loss": 0.4949,
      "step": 208800
    },
    {
      "epoch": 2.2114958104181115,
      "grad_norm": 3.3707263469696045,
      "learning_rate": 6.631664196485284e-05,
      "loss": 0.4963,
      "step": 208900
    },
    {
      "epoch": 2.2125544539781177,
      "grad_norm": 3.6556615829467773,
      "learning_rate": 6.634840143976286e-05,
      "loss": 0.4987,
      "step": 209000
    },
    {
      "epoch": 2.2125544539781177,
      "eval_loss": 0.3641726076602936,
      "eval_runtime": 57.3016,
      "eval_samples_per_second": 2930.632,
      "eval_steps_per_second": 366.342,
      "step": 209000
    },
    {
      "epoch": 2.2136130975381243,
      "grad_norm": 3.611196517944336,
      "learning_rate": 6.638016091467287e-05,
      "loss": 0.4923,
      "step": 209100
    },
    {
      "epoch": 2.214671741098131,
      "grad_norm": 3.29937744140625,
      "learning_rate": 6.641192038958289e-05,
      "loss": 0.4947,
      "step": 209200
    },
    {
      "epoch": 2.2157303846581375,
      "grad_norm": 3.292724132537842,
      "learning_rate": 6.64436798644929e-05,
      "loss": 0.4949,
      "step": 209300
    },
    {
      "epoch": 2.216789028218144,
      "grad_norm": 3.7745370864868164,
      "learning_rate": 6.647543933940291e-05,
      "loss": 0.496,
      "step": 209400
    },
    {
      "epoch": 2.217847671778151,
      "grad_norm": 3.283888339996338,
      "learning_rate": 6.650719881431293e-05,
      "loss": 0.4894,
      "step": 209500
    },
    {
      "epoch": 2.2189063153381574,
      "grad_norm": 4.100371837615967,
      "learning_rate": 6.653895828922295e-05,
      "loss": 0.4963,
      "step": 209600
    },
    {
      "epoch": 2.2199649588981636,
      "grad_norm": 3.6026549339294434,
      "learning_rate": 6.657071776413295e-05,
      "loss": 0.4932,
      "step": 209700
    },
    {
      "epoch": 2.22102360245817,
      "grad_norm": 3.6848268508911133,
      "learning_rate": 6.660247723904297e-05,
      "loss": 0.4884,
      "step": 209800
    },
    {
      "epoch": 2.222082246018177,
      "grad_norm": 3.2494194507598877,
      "learning_rate": 6.663423671395299e-05,
      "loss": 0.4909,
      "step": 209900
    },
    {
      "epoch": 2.2231408895781835,
      "grad_norm": 3.8742265701293945,
      "learning_rate": 6.666599618886301e-05,
      "loss": 0.4954,
      "step": 210000
    },
    {
      "epoch": 2.2231408895781835,
      "eval_loss": 0.36229926347732544,
      "eval_runtime": 57.415,
      "eval_samples_per_second": 2924.844,
      "eval_steps_per_second": 365.619,
      "step": 210000
    },
    {
      "epoch": 2.22419953313819,
      "grad_norm": 3.7107841968536377,
      "learning_rate": 6.669775566377303e-05,
      "loss": 0.4946,
      "step": 210100
    },
    {
      "epoch": 2.2252581766981967,
      "grad_norm": 3.771080255508423,
      "learning_rate": 6.672951513868303e-05,
      "loss": 0.4909,
      "step": 210200
    },
    {
      "epoch": 2.2263168202582033,
      "grad_norm": 4.3028411865234375,
      "learning_rate": 6.676127461359305e-05,
      "loss": 0.4915,
      "step": 210300
    },
    {
      "epoch": 2.22737546381821,
      "grad_norm": 3.229534387588501,
      "learning_rate": 6.679303408850307e-05,
      "loss": 0.4916,
      "step": 210400
    },
    {
      "epoch": 2.228434107378216,
      "grad_norm": 4.105131149291992,
      "learning_rate": 6.682479356341308e-05,
      "loss": 0.493,
      "step": 210500
    },
    {
      "epoch": 2.2294927509382227,
      "grad_norm": 3.423243522644043,
      "learning_rate": 6.685655303832309e-05,
      "loss": 0.4909,
      "step": 210600
    },
    {
      "epoch": 2.2305513944982294,
      "grad_norm": 3.678929567337036,
      "learning_rate": 6.688799491848401e-05,
      "loss": 0.4913,
      "step": 210700
    },
    {
      "epoch": 2.231610038058236,
      "grad_norm": 3.364885091781616,
      "learning_rate": 6.691975439339403e-05,
      "loss": 0.4929,
      "step": 210800
    },
    {
      "epoch": 2.2326686816182426,
      "grad_norm": 3.77270770072937,
      "learning_rate": 6.695151386830403e-05,
      "loss": 0.4943,
      "step": 210900
    },
    {
      "epoch": 2.2337273251782492,
      "grad_norm": 3.5200159549713135,
      "learning_rate": 6.698327334321405e-05,
      "loss": 0.4885,
      "step": 211000
    },
    {
      "epoch": 2.2337273251782492,
      "eval_loss": 0.3627787232398987,
      "eval_runtime": 57.2597,
      "eval_samples_per_second": 2932.778,
      "eval_steps_per_second": 366.61,
      "step": 211000
    },
    {
      "epoch": 2.234785968738256,
      "grad_norm": 3.3598275184631348,
      "learning_rate": 6.701503281812407e-05,
      "loss": 0.4875,
      "step": 211100
    },
    {
      "epoch": 2.235844612298262,
      "grad_norm": 3.7684671878814697,
      "learning_rate": 6.704679229303409e-05,
      "loss": 0.4912,
      "step": 211200
    },
    {
      "epoch": 2.2369032558582687,
      "grad_norm": 3.3123414516448975,
      "learning_rate": 6.70785517679441e-05,
      "loss": 0.4975,
      "step": 211300
    },
    {
      "epoch": 2.2379618994182753,
      "grad_norm": 3.185972213745117,
      "learning_rate": 6.711031124285411e-05,
      "loss": 0.4944,
      "step": 211400
    },
    {
      "epoch": 2.239020542978282,
      "grad_norm": 3.4986953735351562,
      "learning_rate": 6.714207071776413e-05,
      "loss": 0.4911,
      "step": 211500
    },
    {
      "epoch": 2.2400791865382885,
      "grad_norm": 3.7443127632141113,
      "learning_rate": 6.717383019267414e-05,
      "loss": 0.4991,
      "step": 211600
    },
    {
      "epoch": 2.241137830098295,
      "grad_norm": 3.7845444679260254,
      "learning_rate": 6.720558966758416e-05,
      "loss": 0.4919,
      "step": 211700
    },
    {
      "epoch": 2.2421964736583018,
      "grad_norm": 3.6370651721954346,
      "learning_rate": 6.723734914249417e-05,
      "loss": 0.492,
      "step": 211800
    },
    {
      "epoch": 2.2432551172183084,
      "grad_norm": 3.3998546600341797,
      "learning_rate": 6.726910861740418e-05,
      "loss": 0.4895,
      "step": 211900
    },
    {
      "epoch": 2.2443137607783146,
      "grad_norm": 3.5932533740997314,
      "learning_rate": 6.73008680923142e-05,
      "loss": 0.4879,
      "step": 212000
    },
    {
      "epoch": 2.2443137607783146,
      "eval_loss": 0.3641025424003601,
      "eval_runtime": 57.238,
      "eval_samples_per_second": 2933.892,
      "eval_steps_per_second": 366.75,
      "step": 212000
    },
    {
      "epoch": 2.245372404338321,
      "grad_norm": 3.7530405521392822,
      "learning_rate": 6.733262756722422e-05,
      "loss": 0.4866,
      "step": 212100
    },
    {
      "epoch": 2.246431047898328,
      "grad_norm": 3.61913800239563,
      "learning_rate": 6.736438704213422e-05,
      "loss": 0.4876,
      "step": 212200
    },
    {
      "epoch": 2.2474896914583344,
      "grad_norm": 3.3537757396698,
      "learning_rate": 6.739614651704424e-05,
      "loss": 0.4935,
      "step": 212300
    },
    {
      "epoch": 2.248548335018341,
      "grad_norm": 3.696908950805664,
      "learning_rate": 6.742790599195426e-05,
      "loss": 0.4871,
      "step": 212400
    },
    {
      "epoch": 2.2496069785783477,
      "grad_norm": 3.3474905490875244,
      "learning_rate": 6.745966546686428e-05,
      "loss": 0.4914,
      "step": 212500
    },
    {
      "epoch": 2.2506656221383543,
      "grad_norm": 3.450611114501953,
      "learning_rate": 6.74914249417743e-05,
      "loss": 0.4922,
      "step": 212600
    },
    {
      "epoch": 2.2517242656983605,
      "grad_norm": 3.749561071395874,
      "learning_rate": 6.75231844166843e-05,
      "loss": 0.4882,
      "step": 212700
    },
    {
      "epoch": 2.252782909258367,
      "grad_norm": 3.683407783508301,
      "learning_rate": 6.755494389159432e-05,
      "loss": 0.4873,
      "step": 212800
    },
    {
      "epoch": 2.2538415528183737,
      "grad_norm": 3.1264209747314453,
      "learning_rate": 6.758670336650434e-05,
      "loss": 0.4938,
      "step": 212900
    },
    {
      "epoch": 2.2549001963783804,
      "grad_norm": 3.386716604232788,
      "learning_rate": 6.761846284141435e-05,
      "loss": 0.4852,
      "step": 213000
    },
    {
      "epoch": 2.2549001963783804,
      "eval_loss": 0.36112430691719055,
      "eval_runtime": 57.3317,
      "eval_samples_per_second": 2929.093,
      "eval_steps_per_second": 366.15,
      "step": 213000
    },
    {
      "epoch": 2.255958839938387,
      "grad_norm": 3.6780807971954346,
      "learning_rate": 6.765022231632436e-05,
      "loss": 0.4954,
      "step": 213100
    },
    {
      "epoch": 2.2570174834983936,
      "grad_norm": 3.4682083129882812,
      "learning_rate": 6.768198179123438e-05,
      "loss": 0.4894,
      "step": 213200
    },
    {
      "epoch": 2.2580761270584,
      "grad_norm": 3.2734713554382324,
      "learning_rate": 6.77137412661444e-05,
      "loss": 0.4861,
      "step": 213300
    },
    {
      "epoch": 2.259134770618407,
      "grad_norm": 3.4187824726104736,
      "learning_rate": 6.774550074105441e-05,
      "loss": 0.4946,
      "step": 213400
    },
    {
      "epoch": 2.260193414178413,
      "grad_norm": 3.7209739685058594,
      "learning_rate": 6.777726021596442e-05,
      "loss": 0.4859,
      "step": 213500
    },
    {
      "epoch": 2.2612520577384196,
      "grad_norm": 3.2351877689361572,
      "learning_rate": 6.780901969087443e-05,
      "loss": 0.4935,
      "step": 213600
    },
    {
      "epoch": 2.2623107012984263,
      "grad_norm": 3.592745065689087,
      "learning_rate": 6.784077916578445e-05,
      "loss": 0.4887,
      "step": 213700
    },
    {
      "epoch": 2.263369344858433,
      "grad_norm": 3.566737174987793,
      "learning_rate": 6.787253864069447e-05,
      "loss": 0.4935,
      "step": 213800
    },
    {
      "epoch": 2.2644279884184395,
      "grad_norm": 3.763293504714966,
      "learning_rate": 6.790429811560447e-05,
      "loss": 0.4938,
      "step": 213900
    },
    {
      "epoch": 2.265486631978446,
      "grad_norm": 3.7220377922058105,
      "learning_rate": 6.793605759051449e-05,
      "loss": 0.4833,
      "step": 214000
    },
    {
      "epoch": 2.265486631978446,
      "eval_loss": 0.360037624835968,
      "eval_runtime": 57.4161,
      "eval_samples_per_second": 2924.791,
      "eval_steps_per_second": 365.612,
      "step": 214000
    },
    {
      "epoch": 2.2665452755384528,
      "grad_norm": 3.248534917831421,
      "learning_rate": 6.796781706542451e-05,
      "loss": 0.4866,
      "step": 214100
    },
    {
      "epoch": 2.267603919098459,
      "grad_norm": 3.3428921699523926,
      "learning_rate": 6.799957654033453e-05,
      "loss": 0.495,
      "step": 214200
    },
    {
      "epoch": 2.2686625626584656,
      "grad_norm": 3.4882309436798096,
      "learning_rate": 6.803133601524455e-05,
      "loss": 0.4902,
      "step": 214300
    },
    {
      "epoch": 2.269721206218472,
      "grad_norm": 3.146298885345459,
      "learning_rate": 6.806309549015455e-05,
      "loss": 0.4902,
      "step": 214400
    },
    {
      "epoch": 2.270779849778479,
      "grad_norm": 3.4358959197998047,
      "learning_rate": 6.809485496506457e-05,
      "loss": 0.4792,
      "step": 214500
    },
    {
      "epoch": 2.2718384933384854,
      "grad_norm": 3.4252779483795166,
      "learning_rate": 6.812629684522549e-05,
      "loss": 0.4858,
      "step": 214600
    },
    {
      "epoch": 2.272897136898492,
      "grad_norm": 3.681399345397949,
      "learning_rate": 6.815805632013549e-05,
      "loss": 0.4887,
      "step": 214700
    },
    {
      "epoch": 2.2739557804584987,
      "grad_norm": 3.4619293212890625,
      "learning_rate": 6.818981579504551e-05,
      "loss": 0.4885,
      "step": 214800
    },
    {
      "epoch": 2.2750144240185053,
      "grad_norm": 3.3458549976348877,
      "learning_rate": 6.822157526995553e-05,
      "loss": 0.4892,
      "step": 214900
    },
    {
      "epoch": 2.2760730675785115,
      "grad_norm": 3.5175864696502686,
      "learning_rate": 6.825333474486555e-05,
      "loss": 0.4928,
      "step": 215000
    },
    {
      "epoch": 2.2760730675785115,
      "eval_loss": 0.35791170597076416,
      "eval_runtime": 57.2305,
      "eval_samples_per_second": 2934.272,
      "eval_steps_per_second": 366.797,
      "step": 215000
    },
    {
      "epoch": 2.277131711138518,
      "grad_norm": 3.696892023086548,
      "learning_rate": 6.828509421977555e-05,
      "loss": 0.4883,
      "step": 215100
    },
    {
      "epoch": 2.2781903546985247,
      "grad_norm": 3.7319445610046387,
      "learning_rate": 6.831685369468557e-05,
      "loss": 0.4869,
      "step": 215200
    },
    {
      "epoch": 2.2792489982585313,
      "grad_norm": 3.286511182785034,
      "learning_rate": 6.834861316959559e-05,
      "loss": 0.4857,
      "step": 215300
    },
    {
      "epoch": 2.280307641818538,
      "grad_norm": 3.2010626792907715,
      "learning_rate": 6.83803726445056e-05,
      "loss": 0.4916,
      "step": 215400
    },
    {
      "epoch": 2.2813662853785446,
      "grad_norm": 3.6074135303497314,
      "learning_rate": 6.841213211941562e-05,
      "loss": 0.4861,
      "step": 215500
    },
    {
      "epoch": 2.282424928938551,
      "grad_norm": 3.676179885864258,
      "learning_rate": 6.844389159432563e-05,
      "loss": 0.4951,
      "step": 215600
    },
    {
      "epoch": 2.2834835724985574,
      "grad_norm": 3.167104721069336,
      "learning_rate": 6.847565106923564e-05,
      "loss": 0.4871,
      "step": 215700
    },
    {
      "epoch": 2.284542216058564,
      "grad_norm": 3.390737771987915,
      "learning_rate": 6.850741054414566e-05,
      "loss": 0.486,
      "step": 215800
    },
    {
      "epoch": 2.2856008596185706,
      "grad_norm": 3.137906551361084,
      "learning_rate": 6.853917001905568e-05,
      "loss": 0.4859,
      "step": 215900
    },
    {
      "epoch": 2.2866595031785772,
      "grad_norm": 3.4185421466827393,
      "learning_rate": 6.857092949396568e-05,
      "loss": 0.4859,
      "step": 216000
    },
    {
      "epoch": 2.2866595031785772,
      "eval_loss": 0.35876134037971497,
      "eval_runtime": 57.2498,
      "eval_samples_per_second": 2933.286,
      "eval_steps_per_second": 366.674,
      "step": 216000
    },
    {
      "epoch": 2.287718146738584,
      "grad_norm": 3.0368754863739014,
      "learning_rate": 6.86026889688757e-05,
      "loss": 0.4825,
      "step": 216100
    },
    {
      "epoch": 2.2887767902985905,
      "grad_norm": 3.641314744949341,
      "learning_rate": 6.863444844378572e-05,
      "loss": 0.4861,
      "step": 216200
    },
    {
      "epoch": 2.289835433858597,
      "grad_norm": 3.353803873062134,
      "learning_rate": 6.866620791869574e-05,
      "loss": 0.4908,
      "step": 216300
    },
    {
      "epoch": 2.2908940774186037,
      "grad_norm": 3.3698103427886963,
      "learning_rate": 6.869796739360574e-05,
      "loss": 0.4841,
      "step": 216400
    },
    {
      "epoch": 2.29195272097861,
      "grad_norm": 3.318723678588867,
      "learning_rate": 6.872972686851576e-05,
      "loss": 0.4794,
      "step": 216500
    },
    {
      "epoch": 2.2930113645386165,
      "grad_norm": 3.450713634490967,
      "learning_rate": 6.876148634342579e-05,
      "loss": 0.485,
      "step": 216600
    },
    {
      "epoch": 2.294070008098623,
      "grad_norm": 4.016274452209473,
      "learning_rate": 6.87932458183358e-05,
      "loss": 0.4818,
      "step": 216700
    },
    {
      "epoch": 2.29512865165863,
      "grad_norm": 3.3003602027893066,
      "learning_rate": 6.882500529324581e-05,
      "loss": 0.4845,
      "step": 216800
    },
    {
      "epoch": 2.2961872952186364,
      "grad_norm": 3.3165993690490723,
      "learning_rate": 6.885676476815583e-05,
      "loss": 0.485,
      "step": 216900
    },
    {
      "epoch": 2.297245938778643,
      "grad_norm": 3.7123281955718994,
      "learning_rate": 6.888852424306585e-05,
      "loss": 0.4846,
      "step": 217000
    },
    {
      "epoch": 2.297245938778643,
      "eval_loss": 0.35824936628341675,
      "eval_runtime": 57.4395,
      "eval_samples_per_second": 2923.597,
      "eval_steps_per_second": 365.463,
      "step": 217000
    },
    {
      "epoch": 2.2983045823386496,
      "grad_norm": 3.0312230587005615,
      "learning_rate": 6.892028371797585e-05,
      "loss": 0.4874,
      "step": 217100
    },
    {
      "epoch": 2.299363225898656,
      "grad_norm": 3.205416202545166,
      "learning_rate": 6.895204319288587e-05,
      "loss": 0.4811,
      "step": 217200
    },
    {
      "epoch": 2.3004218694586624,
      "grad_norm": 3.5103728771209717,
      "learning_rate": 6.89834850730468e-05,
      "loss": 0.4915,
      "step": 217300
    },
    {
      "epoch": 2.301480513018669,
      "grad_norm": 3.1400017738342285,
      "learning_rate": 6.901524454795681e-05,
      "loss": 0.4868,
      "step": 217400
    },
    {
      "epoch": 2.3025391565786757,
      "grad_norm": 3.8042476177215576,
      "learning_rate": 6.904700402286682e-05,
      "loss": 0.4876,
      "step": 217500
    },
    {
      "epoch": 2.3035978001386823,
      "grad_norm": 3.881673812866211,
      "learning_rate": 6.907876349777683e-05,
      "loss": 0.4787,
      "step": 217600
    },
    {
      "epoch": 2.304656443698689,
      "grad_norm": 3.4607672691345215,
      "learning_rate": 6.911052297268685e-05,
      "loss": 0.4851,
      "step": 217700
    },
    {
      "epoch": 2.3057150872586956,
      "grad_norm": 3.2232108116149902,
      "learning_rate": 6.914228244759687e-05,
      "loss": 0.4817,
      "step": 217800
    },
    {
      "epoch": 2.306773730818702,
      "grad_norm": 2.9848101139068604,
      "learning_rate": 6.917404192250687e-05,
      "loss": 0.4797,
      "step": 217900
    },
    {
      "epoch": 2.307832374378709,
      "grad_norm": 3.6134283542633057,
      "learning_rate": 6.920580139741689e-05,
      "loss": 0.4816,
      "step": 218000
    },
    {
      "epoch": 2.307832374378709,
      "eval_loss": 0.3571719527244568,
      "eval_runtime": 57.2406,
      "eval_samples_per_second": 2933.755,
      "eval_steps_per_second": 366.732,
      "step": 218000
    },
    {
      "epoch": 2.308891017938715,
      "grad_norm": 3.643186569213867,
      "learning_rate": 6.923756087232691e-05,
      "loss": 0.4843,
      "step": 218100
    },
    {
      "epoch": 2.3099496614987216,
      "grad_norm": 3.480912446975708,
      "learning_rate": 6.926932034723693e-05,
      "loss": 0.4774,
      "step": 218200
    },
    {
      "epoch": 2.3110083050587282,
      "grad_norm": 3.5122623443603516,
      "learning_rate": 6.930107982214693e-05,
      "loss": 0.4777,
      "step": 218300
    },
    {
      "epoch": 2.312066948618735,
      "grad_norm": 3.2046990394592285,
      "learning_rate": 6.933283929705695e-05,
      "loss": 0.4861,
      "step": 218400
    },
    {
      "epoch": 2.3131255921787415,
      "grad_norm": 2.846907615661621,
      "learning_rate": 6.936459877196697e-05,
      "loss": 0.4792,
      "step": 218500
    },
    {
      "epoch": 2.314184235738748,
      "grad_norm": 3.315264940261841,
      "learning_rate": 6.939635824687699e-05,
      "loss": 0.4881,
      "step": 218600
    },
    {
      "epoch": 2.3152428792987543,
      "grad_norm": 3.1683411598205566,
      "learning_rate": 6.9428117721787e-05,
      "loss": 0.4825,
      "step": 218700
    },
    {
      "epoch": 2.316301522858761,
      "grad_norm": 3.4356510639190674,
      "learning_rate": 6.945987719669701e-05,
      "loss": 0.4782,
      "step": 218800
    },
    {
      "epoch": 2.3173601664187675,
      "grad_norm": 3.190016984939575,
      "learning_rate": 6.949163667160703e-05,
      "loss": 0.4789,
      "step": 218900
    },
    {
      "epoch": 2.318418809978774,
      "grad_norm": 3.2476751804351807,
      "learning_rate": 6.952339614651704e-05,
      "loss": 0.4787,
      "step": 219000
    },
    {
      "epoch": 2.318418809978774,
      "eval_loss": 0.3564995527267456,
      "eval_runtime": 57.3426,
      "eval_samples_per_second": 2928.54,
      "eval_steps_per_second": 366.081,
      "step": 219000
    },
    {
      "epoch": 2.3194774535387808,
      "grad_norm": 3.336034059524536,
      "learning_rate": 6.955515562142706e-05,
      "loss": 0.4825,
      "step": 219100
    },
    {
      "epoch": 2.3205360970987874,
      "grad_norm": 3.657001495361328,
      "learning_rate": 6.958691509633707e-05,
      "loss": 0.4821,
      "step": 219200
    },
    {
      "epoch": 2.321594740658794,
      "grad_norm": 3.8163158893585205,
      "learning_rate": 6.961867457124708e-05,
      "loss": 0.4819,
      "step": 219300
    },
    {
      "epoch": 2.3226533842188006,
      "grad_norm": 3.4592602252960205,
      "learning_rate": 6.9650116451408e-05,
      "loss": 0.4866,
      "step": 219400
    },
    {
      "epoch": 2.3237120277788073,
      "grad_norm": 3.049614667892456,
      "learning_rate": 6.968187592631801e-05,
      "loss": 0.4812,
      "step": 219500
    },
    {
      "epoch": 2.3247706713388134,
      "grad_norm": 3.289743423461914,
      "learning_rate": 6.971363540122803e-05,
      "loss": 0.4787,
      "step": 219600
    },
    {
      "epoch": 2.32582931489882,
      "grad_norm": 4.053600311279297,
      "learning_rate": 6.974539487613804e-05,
      "loss": 0.488,
      "step": 219700
    },
    {
      "epoch": 2.3268879584588267,
      "grad_norm": 2.759902000427246,
      "learning_rate": 6.977715435104806e-05,
      "loss": 0.4865,
      "step": 219800
    },
    {
      "epoch": 2.3279466020188333,
      "grad_norm": 3.298804521560669,
      "learning_rate": 6.980891382595808e-05,
      "loss": 0.4755,
      "step": 219900
    },
    {
      "epoch": 2.32900524557884,
      "grad_norm": 3.065053939819336,
      "learning_rate": 6.984067330086808e-05,
      "loss": 0.4819,
      "step": 220000
    },
    {
      "epoch": 2.32900524557884,
      "eval_loss": 0.3545546531677246,
      "eval_runtime": 57.2966,
      "eval_samples_per_second": 2930.887,
      "eval_steps_per_second": 366.374,
      "step": 220000
    },
    {
      "epoch": 2.3300638891388465,
      "grad_norm": 3.9798901081085205,
      "learning_rate": 6.98724327757781e-05,
      "loss": 0.4811,
      "step": 220100
    },
    {
      "epoch": 2.3311225326988527,
      "grad_norm": 3.196040153503418,
      "learning_rate": 6.990419225068812e-05,
      "loss": 0.4776,
      "step": 220200
    },
    {
      "epoch": 2.3321811762588593,
      "grad_norm": 3.3618907928466797,
      "learning_rate": 6.993595172559814e-05,
      "loss": 0.4825,
      "step": 220300
    },
    {
      "epoch": 2.333239819818866,
      "grad_norm": 3.4567151069641113,
      "learning_rate": 6.996771120050814e-05,
      "loss": 0.4828,
      "step": 220400
    },
    {
      "epoch": 2.3342984633788726,
      "grad_norm": 3.566117286682129,
      "learning_rate": 6.999947067541816e-05,
      "loss": 0.475,
      "step": 220500
    },
    {
      "epoch": 2.335357106938879,
      "grad_norm": 3.286895275115967,
      "learning_rate": 7.003123015032818e-05,
      "loss": 0.4749,
      "step": 220600
    },
    {
      "epoch": 2.336415750498886,
      "grad_norm": 3.4145283699035645,
      "learning_rate": 7.00629896252382e-05,
      "loss": 0.4791,
      "step": 220700
    },
    {
      "epoch": 2.3374743940588925,
      "grad_norm": 3.5544135570526123,
      "learning_rate": 7.00947491001482e-05,
      "loss": 0.491,
      "step": 220800
    },
    {
      "epoch": 2.338533037618899,
      "grad_norm": 3.0660715103149414,
      "learning_rate": 7.012650857505822e-05,
      "loss": 0.4825,
      "step": 220900
    },
    {
      "epoch": 2.3395916811789057,
      "grad_norm": 3.39264178276062,
      "learning_rate": 7.015826804996824e-05,
      "loss": 0.4826,
      "step": 221000
    },
    {
      "epoch": 2.3395916811789057,
      "eval_loss": 0.35341426730155945,
      "eval_runtime": 57.2725,
      "eval_samples_per_second": 2932.125,
      "eval_steps_per_second": 366.529,
      "step": 221000
    },
    {
      "epoch": 2.340650324738912,
      "grad_norm": 3.347041606903076,
      "learning_rate": 7.019002752487825e-05,
      "loss": 0.478,
      "step": 221100
    },
    {
      "epoch": 2.3417089682989185,
      "grad_norm": 3.455601930618286,
      "learning_rate": 7.022178699978826e-05,
      "loss": 0.4796,
      "step": 221200
    },
    {
      "epoch": 2.342767611858925,
      "grad_norm": 3.3508758544921875,
      "learning_rate": 7.025354647469828e-05,
      "loss": 0.4837,
      "step": 221300
    },
    {
      "epoch": 2.3438262554189317,
      "grad_norm": 3.360144853591919,
      "learning_rate": 7.02853059496083e-05,
      "loss": 0.4762,
      "step": 221400
    },
    {
      "epoch": 2.3448848989789384,
      "grad_norm": 3.2871360778808594,
      "learning_rate": 7.031706542451831e-05,
      "loss": 0.4791,
      "step": 221500
    },
    {
      "epoch": 2.345943542538945,
      "grad_norm": 3.2526583671569824,
      "learning_rate": 7.034882489942833e-05,
      "loss": 0.4752,
      "step": 221600
    },
    {
      "epoch": 2.347002186098951,
      "grad_norm": 3.592207908630371,
      "learning_rate": 7.038058437433833e-05,
      "loss": 0.4792,
      "step": 221700
    },
    {
      "epoch": 2.348060829658958,
      "grad_norm": 3.344635009765625,
      "learning_rate": 7.041234384924835e-05,
      "loss": 0.4774,
      "step": 221800
    },
    {
      "epoch": 2.3491194732189644,
      "grad_norm": 3.2368695735931396,
      "learning_rate": 7.044378572940927e-05,
      "loss": 0.4783,
      "step": 221900
    },
    {
      "epoch": 2.350178116778971,
      "grad_norm": 3.1652286052703857,
      "learning_rate": 7.047554520431928e-05,
      "loss": 0.4765,
      "step": 222000
    },
    {
      "epoch": 2.350178116778971,
      "eval_loss": 0.35251933336257935,
      "eval_runtime": 57.3455,
      "eval_samples_per_second": 2928.392,
      "eval_steps_per_second": 366.062,
      "step": 222000
    },
    {
      "epoch": 2.3512367603389777,
      "grad_norm": 3.2086148262023926,
      "learning_rate": 7.05073046792293e-05,
      "loss": 0.4801,
      "step": 222100
    },
    {
      "epoch": 2.3522954038989843,
      "grad_norm": 3.1828675270080566,
      "learning_rate": 7.053906415413931e-05,
      "loss": 0.4781,
      "step": 222200
    },
    {
      "epoch": 2.353354047458991,
      "grad_norm": 3.870410680770874,
      "learning_rate": 7.057082362904933e-05,
      "loss": 0.4704,
      "step": 222300
    },
    {
      "epoch": 2.3544126910189975,
      "grad_norm": 3.307558059692383,
      "learning_rate": 7.060258310395934e-05,
      "loss": 0.4772,
      "step": 222400
    },
    {
      "epoch": 2.355471334579004,
      "grad_norm": 3.3503317832946777,
      "learning_rate": 7.063434257886935e-05,
      "loss": 0.4752,
      "step": 222500
    },
    {
      "epoch": 2.3565299781390103,
      "grad_norm": 3.276949167251587,
      "learning_rate": 7.066610205377937e-05,
      "loss": 0.4805,
      "step": 222600
    },
    {
      "epoch": 2.357588621699017,
      "grad_norm": 3.3797390460968018,
      "learning_rate": 7.069786152868939e-05,
      "loss": 0.4812,
      "step": 222700
    },
    {
      "epoch": 2.3586472652590236,
      "grad_norm": 3.126471757888794,
      "learning_rate": 7.072962100359941e-05,
      "loss": 0.4789,
      "step": 222800
    },
    {
      "epoch": 2.35970590881903,
      "grad_norm": 2.9767510890960693,
      "learning_rate": 7.076138047850941e-05,
      "loss": 0.479,
      "step": 222900
    },
    {
      "epoch": 2.360764552379037,
      "grad_norm": 3.306983470916748,
      "learning_rate": 7.079313995341943e-05,
      "loss": 0.4771,
      "step": 223000
    },
    {
      "epoch": 2.360764552379037,
      "eval_loss": 0.3526483178138733,
      "eval_runtime": 57.4192,
      "eval_samples_per_second": 2924.63,
      "eval_steps_per_second": 365.592,
      "step": 223000
    },
    {
      "epoch": 2.3618231959390434,
      "grad_norm": 3.3203506469726562,
      "learning_rate": 7.082489942832945e-05,
      "loss": 0.4756,
      "step": 223100
    },
    {
      "epoch": 2.3628818394990496,
      "grad_norm": 3.4372189044952393,
      "learning_rate": 7.085665890323947e-05,
      "loss": 0.4761,
      "step": 223200
    },
    {
      "epoch": 2.3639404830590562,
      "grad_norm": 3.3303463459014893,
      "learning_rate": 7.088841837814947e-05,
      "loss": 0.4843,
      "step": 223300
    },
    {
      "epoch": 2.364999126619063,
      "grad_norm": 3.3917016983032227,
      "learning_rate": 7.092017785305949e-05,
      "loss": 0.4723,
      "step": 223400
    },
    {
      "epoch": 2.3660577701790695,
      "grad_norm": 3.6187005043029785,
      "learning_rate": 7.09519373279695e-05,
      "loss": 0.4678,
      "step": 223500
    },
    {
      "epoch": 2.367116413739076,
      "grad_norm": 3.5034403800964355,
      "learning_rate": 7.098369680287952e-05,
      "loss": 0.4806,
      "step": 223600
    },
    {
      "epoch": 2.3681750572990827,
      "grad_norm": 3.6035821437835693,
      "learning_rate": 7.101545627778953e-05,
      "loss": 0.4815,
      "step": 223700
    },
    {
      "epoch": 2.3692337008590894,
      "grad_norm": 3.4397411346435547,
      "learning_rate": 7.104721575269955e-05,
      "loss": 0.476,
      "step": 223800
    },
    {
      "epoch": 2.370292344419096,
      "grad_norm": 3.5128939151763916,
      "learning_rate": 7.107897522760956e-05,
      "loss": 0.4745,
      "step": 223900
    },
    {
      "epoch": 2.3713509879791026,
      "grad_norm": 2.884050130844116,
      "learning_rate": 7.111073470251958e-05,
      "loss": 0.4699,
      "step": 224000
    },
    {
      "epoch": 2.3713509879791026,
      "eval_loss": 0.350271999835968,
      "eval_runtime": 57.21,
      "eval_samples_per_second": 2935.329,
      "eval_steps_per_second": 366.929,
      "step": 224000
    },
    {
      "epoch": 2.3724096315391088,
      "grad_norm": 2.9538521766662598,
      "learning_rate": 7.11424941774296e-05,
      "loss": 0.4743,
      "step": 224100
    },
    {
      "epoch": 2.3734682750991154,
      "grad_norm": 3.5059332847595215,
      "learning_rate": 7.11742536523396e-05,
      "loss": 0.4771,
      "step": 224200
    },
    {
      "epoch": 2.374526918659122,
      "grad_norm": 3.3074474334716797,
      "learning_rate": 7.120601312724962e-05,
      "loss": 0.4765,
      "step": 224300
    },
    {
      "epoch": 2.3755855622191286,
      "grad_norm": 3.297207832336426,
      "learning_rate": 7.123777260215964e-05,
      "loss": 0.4737,
      "step": 224400
    },
    {
      "epoch": 2.3766442057791353,
      "grad_norm": 3.585084915161133,
      "learning_rate": 7.126953207706966e-05,
      "loss": 0.4742,
      "step": 224500
    },
    {
      "epoch": 2.377702849339142,
      "grad_norm": 2.9620611667633057,
      "learning_rate": 7.130097395723056e-05,
      "loss": 0.4742,
      "step": 224600
    },
    {
      "epoch": 2.3787614928991485,
      "grad_norm": 3.103837728500366,
      "learning_rate": 7.133273343214058e-05,
      "loss": 0.4713,
      "step": 224700
    },
    {
      "epoch": 2.3798201364591547,
      "grad_norm": 3.620852470397949,
      "learning_rate": 7.13644929070506e-05,
      "loss": 0.4738,
      "step": 224800
    },
    {
      "epoch": 2.3808787800191613,
      "grad_norm": 3.3612253665924072,
      "learning_rate": 7.13962523819606e-05,
      "loss": 0.4818,
      "step": 224900
    },
    {
      "epoch": 2.381937423579168,
      "grad_norm": 3.5069804191589355,
      "learning_rate": 7.142801185687062e-05,
      "loss": 0.4713,
      "step": 225000
    },
    {
      "epoch": 2.381937423579168,
      "eval_loss": 0.3512919843196869,
      "eval_runtime": 57.3311,
      "eval_samples_per_second": 2929.127,
      "eval_steps_per_second": 366.154,
      "step": 225000
    },
    {
      "epoch": 2.3829960671391746,
      "grad_norm": 3.0627920627593994,
      "learning_rate": 7.145977133178064e-05,
      "loss": 0.4738,
      "step": 225100
    },
    {
      "epoch": 2.384054710699181,
      "grad_norm": 3.399934768676758,
      "learning_rate": 7.149153080669066e-05,
      "loss": 0.4769,
      "step": 225200
    },
    {
      "epoch": 2.385113354259188,
      "grad_norm": 3.6010806560516357,
      "learning_rate": 7.152329028160068e-05,
      "loss": 0.4694,
      "step": 225300
    },
    {
      "epoch": 2.3861719978191944,
      "grad_norm": 3.395989418029785,
      "learning_rate": 7.155504975651068e-05,
      "loss": 0.4779,
      "step": 225400
    },
    {
      "epoch": 2.387230641379201,
      "grad_norm": 3.233656167984009,
      "learning_rate": 7.15868092314207e-05,
      "loss": 0.4747,
      "step": 225500
    },
    {
      "epoch": 2.3882892849392072,
      "grad_norm": 3.4235644340515137,
      "learning_rate": 7.161856870633072e-05,
      "loss": 0.4745,
      "step": 225600
    },
    {
      "epoch": 2.389347928499214,
      "grad_norm": 2.9983160495758057,
      "learning_rate": 7.165032818124073e-05,
      "loss": 0.4741,
      "step": 225700
    },
    {
      "epoch": 2.3904065720592205,
      "grad_norm": 3.2003250122070312,
      "learning_rate": 7.168208765615074e-05,
      "loss": 0.4757,
      "step": 225800
    },
    {
      "epoch": 2.391465215619227,
      "grad_norm": 3.422572612762451,
      "learning_rate": 7.171384713106076e-05,
      "loss": 0.4751,
      "step": 225900
    },
    {
      "epoch": 2.3925238591792337,
      "grad_norm": 3.19136381149292,
      "learning_rate": 7.174560660597077e-05,
      "loss": 0.4705,
      "step": 226000
    },
    {
      "epoch": 2.3925238591792337,
      "eval_loss": 0.3505263030529022,
      "eval_runtime": 57.3929,
      "eval_samples_per_second": 2925.972,
      "eval_steps_per_second": 365.76,
      "step": 226000
    },
    {
      "epoch": 2.3935825027392403,
      "grad_norm": 3.424797534942627,
      "learning_rate": 7.177736608088079e-05,
      "loss": 0.4709,
      "step": 226100
    },
    {
      "epoch": 2.394641146299247,
      "grad_norm": 3.5065195560455322,
      "learning_rate": 7.18091255557908e-05,
      "loss": 0.4692,
      "step": 226200
    },
    {
      "epoch": 2.395699789859253,
      "grad_norm": 3.71950626373291,
      "learning_rate": 7.184088503070082e-05,
      "loss": 0.4729,
      "step": 226300
    },
    {
      "epoch": 2.3967584334192598,
      "grad_norm": 3.1673784255981445,
      "learning_rate": 7.187264450561083e-05,
      "loss": 0.4652,
      "step": 226400
    },
    {
      "epoch": 2.3978170769792664,
      "grad_norm": 3.1007907390594482,
      "learning_rate": 7.190440398052085e-05,
      "loss": 0.4746,
      "step": 226500
    },
    {
      "epoch": 2.398875720539273,
      "grad_norm": 3.4032981395721436,
      "learning_rate": 7.193616345543086e-05,
      "loss": 0.4667,
      "step": 226600
    },
    {
      "epoch": 2.3999343640992796,
      "grad_norm": 3.0626330375671387,
      "learning_rate": 7.196792293034087e-05,
      "loss": 0.4694,
      "step": 226700
    },
    {
      "epoch": 2.4009930076592862,
      "grad_norm": 2.9288108348846436,
      "learning_rate": 7.199968240525089e-05,
      "loss": 0.4665,
      "step": 226800
    },
    {
      "epoch": 2.402051651219293,
      "grad_norm": 2.6891555786132812,
      "learning_rate": 7.203144188016091e-05,
      "loss": 0.469,
      "step": 226900
    },
    {
      "epoch": 2.4031102947792995,
      "grad_norm": 2.962968111038208,
      "learning_rate": 7.206320135507093e-05,
      "loss": 0.4726,
      "step": 227000
    },
    {
      "epoch": 2.4031102947792995,
      "eval_loss": 0.3483829200267792,
      "eval_runtime": 57.3732,
      "eval_samples_per_second": 2926.974,
      "eval_steps_per_second": 365.885,
      "step": 227000
    },
    {
      "epoch": 2.4041689383393057,
      "grad_norm": 3.0600075721740723,
      "learning_rate": 7.209496082998093e-05,
      "loss": 0.4753,
      "step": 227100
    },
    {
      "epoch": 2.4052275818993123,
      "grad_norm": 3.346348762512207,
      "learning_rate": 7.212672030489095e-05,
      "loss": 0.4738,
      "step": 227200
    },
    {
      "epoch": 2.406286225459319,
      "grad_norm": 3.035601854324341,
      "learning_rate": 7.215847977980097e-05,
      "loss": 0.4682,
      "step": 227300
    },
    {
      "epoch": 2.4073448690193255,
      "grad_norm": 3.097776174545288,
      "learning_rate": 7.219023925471098e-05,
      "loss": 0.4685,
      "step": 227400
    },
    {
      "epoch": 2.408403512579332,
      "grad_norm": 3.6816940307617188,
      "learning_rate": 7.222199872962099e-05,
      "loss": 0.4661,
      "step": 227500
    },
    {
      "epoch": 2.409462156139339,
      "grad_norm": 3.3377110958099365,
      "learning_rate": 7.225375820453101e-05,
      "loss": 0.4726,
      "step": 227600
    },
    {
      "epoch": 2.4105207996993454,
      "grad_norm": 3.079345464706421,
      "learning_rate": 7.228551767944103e-05,
      "loss": 0.4695,
      "step": 227700
    },
    {
      "epoch": 2.4115794432593516,
      "grad_norm": 3.281446933746338,
      "learning_rate": 7.231695955960195e-05,
      "loss": 0.4742,
      "step": 227800
    },
    {
      "epoch": 2.412638086819358,
      "grad_norm": 3.1016733646392822,
      "learning_rate": 7.234871903451195e-05,
      "loss": 0.4641,
      "step": 227900
    },
    {
      "epoch": 2.413696730379365,
      "grad_norm": 3.1828227043151855,
      "learning_rate": 7.238047850942197e-05,
      "loss": 0.471,
      "step": 228000
    },
    {
      "epoch": 2.413696730379365,
      "eval_loss": 0.34801045060157776,
      "eval_runtime": 57.4491,
      "eval_samples_per_second": 2923.108,
      "eval_steps_per_second": 365.402,
      "step": 228000
    },
    {
      "epoch": 2.4147553739393715,
      "grad_norm": 3.4070041179656982,
      "learning_rate": 7.241223798433199e-05,
      "loss": 0.468,
      "step": 228100
    },
    {
      "epoch": 2.415814017499378,
      "grad_norm": 3.2403836250305176,
      "learning_rate": 7.2443997459242e-05,
      "loss": 0.4723,
      "step": 228200
    },
    {
      "epoch": 2.4168726610593847,
      "grad_norm": 3.2715721130371094,
      "learning_rate": 7.247575693415201e-05,
      "loss": 0.4728,
      "step": 228300
    },
    {
      "epoch": 2.4179313046193913,
      "grad_norm": 3.020875930786133,
      "learning_rate": 7.250751640906203e-05,
      "loss": 0.4711,
      "step": 228400
    },
    {
      "epoch": 2.418989948179398,
      "grad_norm": 3.496633529663086,
      "learning_rate": 7.253927588397204e-05,
      "loss": 0.4708,
      "step": 228500
    },
    {
      "epoch": 2.420048591739404,
      "grad_norm": 2.909905433654785,
      "learning_rate": 7.257103535888206e-05,
      "loss": 0.4744,
      "step": 228600
    },
    {
      "epoch": 2.4211072352994107,
      "grad_norm": 3.006985664367676,
      "learning_rate": 7.260279483379207e-05,
      "loss": 0.4717,
      "step": 228700
    },
    {
      "epoch": 2.4221658788594174,
      "grad_norm": 2.721907377243042,
      "learning_rate": 7.263455430870208e-05,
      "loss": 0.4707,
      "step": 228800
    },
    {
      "epoch": 2.423224522419424,
      "grad_norm": 3.3622806072235107,
      "learning_rate": 7.26663137836121e-05,
      "loss": 0.471,
      "step": 228900
    },
    {
      "epoch": 2.4242831659794306,
      "grad_norm": 3.274629831314087,
      "learning_rate": 7.269807325852212e-05,
      "loss": 0.4671,
      "step": 229000
    },
    {
      "epoch": 2.4242831659794306,
      "eval_loss": 0.34840473532676697,
      "eval_runtime": 57.4395,
      "eval_samples_per_second": 2923.596,
      "eval_steps_per_second": 365.463,
      "step": 229000
    },
    {
      "epoch": 2.4253418095394372,
      "grad_norm": 3.3229591846466064,
      "learning_rate": 7.272983273343212e-05,
      "loss": 0.4711,
      "step": 229100
    },
    {
      "epoch": 2.426400453099444,
      "grad_norm": 2.8013267517089844,
      "learning_rate": 7.276159220834214e-05,
      "loss": 0.4665,
      "step": 229200
    },
    {
      "epoch": 2.42745909665945,
      "grad_norm": 3.4589526653289795,
      "learning_rate": 7.279335168325216e-05,
      "loss": 0.4705,
      "step": 229300
    },
    {
      "epoch": 2.4285177402194567,
      "grad_norm": 3.096303701400757,
      "learning_rate": 7.282511115816218e-05,
      "loss": 0.4681,
      "step": 229400
    },
    {
      "epoch": 2.4295763837794633,
      "grad_norm": 3.4017012119293213,
      "learning_rate": 7.28568706330722e-05,
      "loss": 0.4675,
      "step": 229500
    },
    {
      "epoch": 2.43063502733947,
      "grad_norm": 2.942915201187134,
      "learning_rate": 7.28886301079822e-05,
      "loss": 0.4682,
      "step": 229600
    },
    {
      "epoch": 2.4316936708994765,
      "grad_norm": 3.3334357738494873,
      "learning_rate": 7.292038958289222e-05,
      "loss": 0.4628,
      "step": 229700
    },
    {
      "epoch": 2.432752314459483,
      "grad_norm": 3.6902458667755127,
      "learning_rate": 7.295214905780224e-05,
      "loss": 0.4742,
      "step": 229800
    },
    {
      "epoch": 2.4338109580194898,
      "grad_norm": 3.4706404209136963,
      "learning_rate": 7.298390853271225e-05,
      "loss": 0.4707,
      "step": 229900
    },
    {
      "epoch": 2.4348696015794964,
      "grad_norm": 3.0974109172821045,
      "learning_rate": 7.301566800762227e-05,
      "loss": 0.4655,
      "step": 230000
    },
    {
      "epoch": 2.4348696015794964,
      "eval_loss": 0.3471246063709259,
      "eval_runtime": 57.1521,
      "eval_samples_per_second": 2938.298,
      "eval_steps_per_second": 367.3,
      "step": 230000
    },
    {
      "epoch": 2.4359282451395026,
      "grad_norm": 3.095010280609131,
      "learning_rate": 7.304742748253229e-05,
      "loss": 0.466,
      "step": 230100
    },
    {
      "epoch": 2.436986888699509,
      "grad_norm": 3.222914695739746,
      "learning_rate": 7.30788693626932e-05,
      "loss": 0.4689,
      "step": 230200
    },
    {
      "epoch": 2.438045532259516,
      "grad_norm": 3.5620625019073486,
      "learning_rate": 7.31106288376032e-05,
      "loss": 0.4693,
      "step": 230300
    },
    {
      "epoch": 2.4391041758195224,
      "grad_norm": 2.8022053241729736,
      "learning_rate": 7.314238831251322e-05,
      "loss": 0.4711,
      "step": 230400
    },
    {
      "epoch": 2.440162819379529,
      "grad_norm": 3.1881983280181885,
      "learning_rate": 7.317414778742325e-05,
      "loss": 0.4698,
      "step": 230500
    },
    {
      "epoch": 2.4412214629395357,
      "grad_norm": 3.5554192066192627,
      "learning_rate": 7.320590726233326e-05,
      "loss": 0.4651,
      "step": 230600
    },
    {
      "epoch": 2.4422801064995423,
      "grad_norm": 3.126253604888916,
      "learning_rate": 7.323766673724327e-05,
      "loss": 0.4716,
      "step": 230700
    },
    {
      "epoch": 2.4433387500595485,
      "grad_norm": 3.4096550941467285,
      "learning_rate": 7.326942621215329e-05,
      "loss": 0.4661,
      "step": 230800
    },
    {
      "epoch": 2.444397393619555,
      "grad_norm": 3.1602139472961426,
      "learning_rate": 7.330118568706331e-05,
      "loss": 0.4737,
      "step": 230900
    },
    {
      "epoch": 2.4454560371795617,
      "grad_norm": 3.2526283264160156,
      "learning_rate": 7.333294516197331e-05,
      "loss": 0.4629,
      "step": 231000
    },
    {
      "epoch": 2.4454560371795617,
      "eval_loss": 0.34420329332351685,
      "eval_runtime": 57.308,
      "eval_samples_per_second": 2930.308,
      "eval_steps_per_second": 366.302,
      "step": 231000
    },
    {
      "epoch": 2.4465146807395683,
      "grad_norm": 3.108346939086914,
      "learning_rate": 7.336470463688333e-05,
      "loss": 0.4686,
      "step": 231100
    },
    {
      "epoch": 2.447573324299575,
      "grad_norm": 3.202235221862793,
      "learning_rate": 7.339646411179335e-05,
      "loss": 0.4699,
      "step": 231200
    },
    {
      "epoch": 2.4486319678595816,
      "grad_norm": 3.2429428100585938,
      "learning_rate": 7.342822358670337e-05,
      "loss": 0.4667,
      "step": 231300
    },
    {
      "epoch": 2.449690611419588,
      "grad_norm": 3.4384074211120605,
      "learning_rate": 7.345998306161338e-05,
      "loss": 0.4659,
      "step": 231400
    },
    {
      "epoch": 2.450749254979595,
      "grad_norm": 2.909348964691162,
      "learning_rate": 7.349174253652339e-05,
      "loss": 0.4672,
      "step": 231500
    },
    {
      "epoch": 2.451807898539601,
      "grad_norm": 3.179419994354248,
      "learning_rate": 7.352350201143341e-05,
      "loss": 0.4623,
      "step": 231600
    },
    {
      "epoch": 2.4528665420996076,
      "grad_norm": 3.1341328620910645,
      "learning_rate": 7.355526148634342e-05,
      "loss": 0.4678,
      "step": 231700
    },
    {
      "epoch": 2.4539251856596143,
      "grad_norm": 2.9702892303466797,
      "learning_rate": 7.358702096125344e-05,
      "loss": 0.4656,
      "step": 231800
    },
    {
      "epoch": 2.454983829219621,
      "grad_norm": 3.2694671154022217,
      "learning_rate": 7.361878043616345e-05,
      "loss": 0.4604,
      "step": 231900
    },
    {
      "epoch": 2.4560424727796275,
      "grad_norm": 2.9487223625183105,
      "learning_rate": 7.365053991107347e-05,
      "loss": 0.4648,
      "step": 232000
    },
    {
      "epoch": 2.4560424727796275,
      "eval_loss": 0.3461354970932007,
      "eval_runtime": 57.3337,
      "eval_samples_per_second": 2928.995,
      "eval_steps_per_second": 366.137,
      "step": 232000
    },
    {
      "epoch": 2.457101116339634,
      "grad_norm": 3.1655101776123047,
      "learning_rate": 7.368229938598348e-05,
      "loss": 0.4632,
      "step": 232100
    },
    {
      "epoch": 2.4581597598996408,
      "grad_norm": 3.817019462585449,
      "learning_rate": 7.37140588608935e-05,
      "loss": 0.4643,
      "step": 232200
    },
    {
      "epoch": 2.459218403459647,
      "grad_norm": 3.4233601093292236,
      "learning_rate": 7.37458183358035e-05,
      "loss": 0.4605,
      "step": 232300
    },
    {
      "epoch": 2.4602770470196536,
      "grad_norm": 3.1946587562561035,
      "learning_rate": 7.377757781071352e-05,
      "loss": 0.4627,
      "step": 232400
    },
    {
      "epoch": 2.46133569057966,
      "grad_norm": 3.5801539421081543,
      "learning_rate": 7.380933728562354e-05,
      "loss": 0.4641,
      "step": 232500
    },
    {
      "epoch": 2.462394334139667,
      "grad_norm": 2.9016053676605225,
      "learning_rate": 7.384109676053356e-05,
      "loss": 0.4701,
      "step": 232600
    },
    {
      "epoch": 2.4634529776996734,
      "grad_norm": 3.5339763164520264,
      "learning_rate": 7.387285623544356e-05,
      "loss": 0.4607,
      "step": 232700
    },
    {
      "epoch": 2.46451162125968,
      "grad_norm": 2.7321319580078125,
      "learning_rate": 7.390461571035358e-05,
      "loss": 0.4654,
      "step": 232800
    },
    {
      "epoch": 2.4655702648196867,
      "grad_norm": 3.347210645675659,
      "learning_rate": 7.39363751852636e-05,
      "loss": 0.4646,
      "step": 232900
    },
    {
      "epoch": 2.4666289083796933,
      "grad_norm": 3.4035325050354004,
      "learning_rate": 7.396813466017362e-05,
      "loss": 0.4632,
      "step": 233000
    },
    {
      "epoch": 2.4666289083796933,
      "eval_loss": 0.3428890109062195,
      "eval_runtime": 57.2109,
      "eval_samples_per_second": 2935.282,
      "eval_steps_per_second": 366.923,
      "step": 233000
    },
    {
      "epoch": 2.4676875519397,
      "grad_norm": 3.1232688426971436,
      "learning_rate": 7.399989413508364e-05,
      "loss": 0.4647,
      "step": 233100
    },
    {
      "epoch": 2.468746195499706,
      "grad_norm": 3.3668606281280518,
      "learning_rate": 7.403165360999364e-05,
      "loss": 0.4619,
      "step": 233200
    },
    {
      "epoch": 2.4698048390597127,
      "grad_norm": 3.2917728424072266,
      "learning_rate": 7.406341308490366e-05,
      "loss": 0.4703,
      "step": 233300
    },
    {
      "epoch": 2.4708634826197193,
      "grad_norm": 2.7635996341705322,
      "learning_rate": 7.409517255981368e-05,
      "loss": 0.4655,
      "step": 233400
    },
    {
      "epoch": 2.471922126179726,
      "grad_norm": 2.9121625423431396,
      "learning_rate": 7.412693203472369e-05,
      "loss": 0.4627,
      "step": 233500
    },
    {
      "epoch": 2.4729807697397326,
      "grad_norm": 3.1189310550689697,
      "learning_rate": 7.41586915096337e-05,
      "loss": 0.4625,
      "step": 233600
    },
    {
      "epoch": 2.474039413299739,
      "grad_norm": 3.363264322280884,
      "learning_rate": 7.419045098454372e-05,
      "loss": 0.4646,
      "step": 233700
    },
    {
      "epoch": 2.4750980568597454,
      "grad_norm": 2.963433027267456,
      "learning_rate": 7.422221045945373e-05,
      "loss": 0.4634,
      "step": 233800
    },
    {
      "epoch": 2.476156700419752,
      "grad_norm": 3.054997444152832,
      "learning_rate": 7.425396993436375e-05,
      "loss": 0.4561,
      "step": 233900
    },
    {
      "epoch": 2.4772153439797586,
      "grad_norm": 2.542861223220825,
      "learning_rate": 7.428572940927376e-05,
      "loss": 0.4661,
      "step": 234000
    },
    {
      "epoch": 2.4772153439797586,
      "eval_loss": 0.3415307104587555,
      "eval_runtime": 57.2693,
      "eval_samples_per_second": 2932.289,
      "eval_steps_per_second": 366.549,
      "step": 234000
    },
    {
      "epoch": 2.4782739875397652,
      "grad_norm": 3.4515767097473145,
      "learning_rate": 7.431748888418377e-05,
      "loss": 0.464,
      "step": 234100
    },
    {
      "epoch": 2.479332631099772,
      "grad_norm": Infinity,
      "learning_rate": 7.43489307643447e-05,
      "loss": 0.4627,
      "step": 234200
    },
    {
      "epoch": 2.4803912746597785,
      "grad_norm": 3.412245750427246,
      "learning_rate": 7.43803726445056e-05,
      "loss": 0.4614,
      "step": 234300
    },
    {
      "epoch": 2.481449918219785,
      "grad_norm": 2.913588523864746,
      "learning_rate": 7.441213211941562e-05,
      "loss": 0.4682,
      "step": 234400
    },
    {
      "epoch": 2.4825085617797917,
      "grad_norm": 3.19201397895813,
      "learning_rate": 7.444389159432564e-05,
      "loss": 0.4654,
      "step": 234500
    },
    {
      "epoch": 2.4835672053397984,
      "grad_norm": 3.2591240406036377,
      "learning_rate": 7.447565106923565e-05,
      "loss": 0.463,
      "step": 234600
    },
    {
      "epoch": 2.4846258488998045,
      "grad_norm": 3.098698377609253,
      "learning_rate": 7.450741054414566e-05,
      "loss": 0.4585,
      "step": 234700
    },
    {
      "epoch": 2.485684492459811,
      "grad_norm": 3.0830557346343994,
      "learning_rate": 7.453917001905568e-05,
      "loss": 0.4622,
      "step": 234800
    },
    {
      "epoch": 2.486743136019818,
      "grad_norm": 3.4446957111358643,
      "learning_rate": 7.45709294939657e-05,
      "loss": 0.4592,
      "step": 234900
    },
    {
      "epoch": 2.4878017795798244,
      "grad_norm": 3.1508147716522217,
      "learning_rate": 7.460268896887571e-05,
      "loss": 0.4599,
      "step": 235000
    },
    {
      "epoch": 2.4878017795798244,
      "eval_loss": 0.3439338505268097,
      "eval_runtime": 57.2708,
      "eval_samples_per_second": 2932.209,
      "eval_steps_per_second": 366.539,
      "step": 235000
    },
    {
      "epoch": 2.488860423139831,
      "grad_norm": 3.0585663318634033,
      "learning_rate": 7.463444844378573e-05,
      "loss": 0.4599,
      "step": 235100
    },
    {
      "epoch": 2.4899190666998376,
      "grad_norm": 2.8384037017822266,
      "learning_rate": 7.466620791869574e-05,
      "loss": 0.4618,
      "step": 235200
    },
    {
      "epoch": 2.490977710259844,
      "grad_norm": 3.147177219390869,
      "learning_rate": 7.469796739360575e-05,
      "loss": 0.4638,
      "step": 235300
    },
    {
      "epoch": 2.4920363538198504,
      "grad_norm": 3.1613614559173584,
      "learning_rate": 7.472972686851577e-05,
      "loss": 0.4536,
      "step": 235400
    },
    {
      "epoch": 2.493094997379857,
      "grad_norm": 2.8385987281799316,
      "learning_rate": 7.476148634342579e-05,
      "loss": 0.4613,
      "step": 235500
    },
    {
      "epoch": 2.4941536409398637,
      "grad_norm": 3.2129733562469482,
      "learning_rate": 7.47932458183358e-05,
      "loss": 0.4704,
      "step": 235600
    },
    {
      "epoch": 2.4952122844998703,
      "grad_norm": 3.15405535697937,
      "learning_rate": 7.482500529324581e-05,
      "loss": 0.4562,
      "step": 235700
    },
    {
      "epoch": 2.496270928059877,
      "grad_norm": 3.3724660873413086,
      "learning_rate": 7.485676476815583e-05,
      "loss": 0.4615,
      "step": 235800
    },
    {
      "epoch": 2.4973295716198836,
      "grad_norm": 2.864219903945923,
      "learning_rate": 7.488852424306585e-05,
      "loss": 0.46,
      "step": 235900
    },
    {
      "epoch": 2.49838821517989,
      "grad_norm": 2.8917322158813477,
      "learning_rate": 7.492028371797585e-05,
      "loss": 0.4636,
      "step": 236000
    },
    {
      "epoch": 2.49838821517989,
      "eval_loss": 0.34256216883659363,
      "eval_runtime": 57.2626,
      "eval_samples_per_second": 2932.631,
      "eval_steps_per_second": 366.592,
      "step": 236000
    },
    {
      "epoch": 2.499446858739897,
      "grad_norm": 3.5027048587799072,
      "learning_rate": 7.495204319288587e-05,
      "loss": 0.4585,
      "step": 236100
    },
    {
      "epoch": 2.500505502299903,
      "grad_norm": 3.0683391094207764,
      "learning_rate": 7.498380266779589e-05,
      "loss": 0.4578,
      "step": 236200
    },
    {
      "epoch": 2.5015641458599096,
      "grad_norm": 3.1368467807769775,
      "learning_rate": 7.501556214270589e-05,
      "loss": 0.4591,
      "step": 236300
    },
    {
      "epoch": 2.5026227894199162,
      "grad_norm": 2.9287567138671875,
      "learning_rate": 7.504732161761591e-05,
      "loss": 0.4691,
      "step": 236400
    },
    {
      "epoch": 2.503681432979923,
      "grad_norm": 2.9739606380462646,
      "learning_rate": 7.507908109252593e-05,
      "loss": 0.4608,
      "step": 236500
    },
    {
      "epoch": 2.5047400765399295,
      "grad_norm": 3.0824506282806396,
      "learning_rate": 7.511084056743593e-05,
      "loss": 0.4642,
      "step": 236600
    },
    {
      "epoch": 2.505798720099936,
      "grad_norm": 3.2780911922454834,
      "learning_rate": 7.514228244759685e-05,
      "loss": 0.4563,
      "step": 236700
    },
    {
      "epoch": 2.5068573636599423,
      "grad_norm": 2.8593170642852783,
      "learning_rate": 7.517404192250687e-05,
      "loss": 0.458,
      "step": 236800
    },
    {
      "epoch": 2.507916007219949,
      "grad_norm": 3.1016998291015625,
      "learning_rate": 7.520580139741689e-05,
      "loss": 0.4535,
      "step": 236900
    },
    {
      "epoch": 2.5089746507799555,
      "grad_norm": 2.9622888565063477,
      "learning_rate": 7.523756087232689e-05,
      "loss": 0.4607,
      "step": 237000
    },
    {
      "epoch": 2.5089746507799555,
      "eval_loss": 0.3398326337337494,
      "eval_runtime": 57.3294,
      "eval_samples_per_second": 2929.211,
      "eval_steps_per_second": 366.164,
      "step": 237000
    },
    {
      "epoch": 2.510033294339962,
      "grad_norm": 3.235410451889038,
      "learning_rate": 7.526932034723691e-05,
      "loss": 0.4616,
      "step": 237100
    },
    {
      "epoch": 2.5110919378999688,
      "grad_norm": 3.2353861331939697,
      "learning_rate": 7.530107982214693e-05,
      "loss": 0.4601,
      "step": 237200
    },
    {
      "epoch": 2.5121505814599754,
      "grad_norm": 3.1728644371032715,
      "learning_rate": 7.533283929705695e-05,
      "loss": 0.4655,
      "step": 237300
    },
    {
      "epoch": 2.513209225019982,
      "grad_norm": 3.5842316150665283,
      "learning_rate": 7.536459877196695e-05,
      "loss": 0.4599,
      "step": 237400
    },
    {
      "epoch": 2.5142678685799886,
      "grad_norm": 2.844433069229126,
      "learning_rate": 7.539635824687698e-05,
      "loss": 0.4617,
      "step": 237500
    },
    {
      "epoch": 2.5153265121399953,
      "grad_norm": 2.7530345916748047,
      "learning_rate": 7.5428117721787e-05,
      "loss": 0.4598,
      "step": 237600
    },
    {
      "epoch": 2.5163851557000014,
      "grad_norm": 2.8411388397216797,
      "learning_rate": 7.545987719669702e-05,
      "loss": 0.4606,
      "step": 237700
    },
    {
      "epoch": 2.517443799260008,
      "grad_norm": 3.26777982711792,
      "learning_rate": 7.549163667160704e-05,
      "loss": 0.4567,
      "step": 237800
    },
    {
      "epoch": 2.5185024428200147,
      "grad_norm": 3.269416093826294,
      "learning_rate": 7.552339614651704e-05,
      "loss": 0.4613,
      "step": 237900
    },
    {
      "epoch": 2.5195610863800213,
      "grad_norm": 3.3199660778045654,
      "learning_rate": 7.555515562142706e-05,
      "loss": 0.4606,
      "step": 238000
    },
    {
      "epoch": 2.5195610863800213,
      "eval_loss": 0.3396340608596802,
      "eval_runtime": 57.3934,
      "eval_samples_per_second": 2925.948,
      "eval_steps_per_second": 365.757,
      "step": 238000
    },
    {
      "epoch": 2.520619729940028,
      "grad_norm": 2.8861031532287598,
      "learning_rate": 7.558691509633708e-05,
      "loss": 0.4547,
      "step": 238100
    },
    {
      "epoch": 2.5216783735000345,
      "grad_norm": 3.062952756881714,
      "learning_rate": 7.56186745712471e-05,
      "loss": 0.4568,
      "step": 238200
    },
    {
      "epoch": 2.5227370170600407,
      "grad_norm": 3.650979518890381,
      "learning_rate": 7.56504340461571e-05,
      "loss": 0.4588,
      "step": 238300
    },
    {
      "epoch": 2.5237956606200473,
      "grad_norm": 2.8575427532196045,
      "learning_rate": 7.568219352106712e-05,
      "loss": 0.4547,
      "step": 238400
    },
    {
      "epoch": 2.524854304180054,
      "grad_norm": 3.072221517562866,
      "learning_rate": 7.571395299597713e-05,
      "loss": 0.4617,
      "step": 238500
    },
    {
      "epoch": 2.5259129477400606,
      "grad_norm": 2.862621307373047,
      "learning_rate": 7.574571247088715e-05,
      "loss": 0.4574,
      "step": 238600
    },
    {
      "epoch": 2.526971591300067,
      "grad_norm": 2.9559390544891357,
      "learning_rate": 7.577747194579717e-05,
      "loss": 0.4685,
      "step": 238700
    },
    {
      "epoch": 2.528030234860074,
      "grad_norm": 2.6313419342041016,
      "learning_rate": 7.580923142070717e-05,
      "loss": 0.4598,
      "step": 238800
    },
    {
      "epoch": 2.5290888784200805,
      "grad_norm": 3.0720407962799072,
      "learning_rate": 7.584099089561719e-05,
      "loss": 0.4547,
      "step": 238900
    },
    {
      "epoch": 2.530147521980087,
      "grad_norm": 3.347604513168335,
      "learning_rate": 7.587275037052721e-05,
      "loss": 0.4566,
      "step": 239000
    },
    {
      "epoch": 2.530147521980087,
      "eval_loss": 0.34000277519226074,
      "eval_runtime": 57.2501,
      "eval_samples_per_second": 2933.269,
      "eval_steps_per_second": 366.672,
      "step": 239000
    },
    {
      "epoch": 2.5312061655400937,
      "grad_norm": 3.087847948074341,
      "learning_rate": 7.590450984543723e-05,
      "loss": 0.4599,
      "step": 239100
    },
    {
      "epoch": 2.5322648091001,
      "grad_norm": 3.0069096088409424,
      "learning_rate": 7.593626932034723e-05,
      "loss": 0.4582,
      "step": 239200
    },
    {
      "epoch": 2.5333234526601065,
      "grad_norm": 3.0876100063323975,
      "learning_rate": 7.596802879525725e-05,
      "loss": 0.4591,
      "step": 239300
    },
    {
      "epoch": 2.534382096220113,
      "grad_norm": 3.397515058517456,
      "learning_rate": 7.599978827016727e-05,
      "loss": 0.4557,
      "step": 239400
    },
    {
      "epoch": 2.5354407397801197,
      "grad_norm": 3.3523998260498047,
      "learning_rate": 7.603154774507729e-05,
      "loss": 0.4582,
      "step": 239500
    },
    {
      "epoch": 2.5364993833401264,
      "grad_norm": 3.0480802059173584,
      "learning_rate": 7.606330721998729e-05,
      "loss": 0.4556,
      "step": 239600
    },
    {
      "epoch": 2.537558026900133,
      "grad_norm": 3.0060789585113525,
      "learning_rate": 7.609506669489731e-05,
      "loss": 0.4609,
      "step": 239700
    },
    {
      "epoch": 2.538616670460139,
      "grad_norm": 3.2146642208099365,
      "learning_rate": 7.612682616980733e-05,
      "loss": 0.4625,
      "step": 239800
    },
    {
      "epoch": 2.539675314020146,
      "grad_norm": 3.139507293701172,
      "learning_rate": 7.615858564471734e-05,
      "loss": 0.4615,
      "step": 239900
    },
    {
      "epoch": 2.5407339575801524,
      "grad_norm": 3.0663225650787354,
      "learning_rate": 7.619034511962735e-05,
      "loss": 0.4556,
      "step": 240000
    },
    {
      "epoch": 2.5407339575801524,
      "eval_loss": 0.34068527817726135,
      "eval_runtime": 57.324,
      "eval_samples_per_second": 2929.487,
      "eval_steps_per_second": 366.199,
      "step": 240000
    },
    {
      "epoch": 2.541792601140159,
      "grad_norm": 3.2915616035461426,
      "learning_rate": 7.622210459453737e-05,
      "loss": 0.4572,
      "step": 240100
    },
    {
      "epoch": 2.5428512447001657,
      "grad_norm": 3.1668496131896973,
      "learning_rate": 7.625386406944738e-05,
      "loss": 0.4556,
      "step": 240200
    },
    {
      "epoch": 2.5439098882601723,
      "grad_norm": 2.7973577976226807,
      "learning_rate": 7.62856235443574e-05,
      "loss": 0.4588,
      "step": 240300
    },
    {
      "epoch": 2.544968531820179,
      "grad_norm": 3.057157516479492,
      "learning_rate": 7.631738301926742e-05,
      "loss": 0.4575,
      "step": 240400
    },
    {
      "epoch": 2.5460271753801855,
      "grad_norm": 2.8684685230255127,
      "learning_rate": 7.634914249417742e-05,
      "loss": 0.4547,
      "step": 240500
    },
    {
      "epoch": 2.547085818940192,
      "grad_norm": 3.268070697784424,
      "learning_rate": 7.638090196908744e-05,
      "loss": 0.4547,
      "step": 240600
    },
    {
      "epoch": 2.5481444625001988,
      "grad_norm": 3.181811809539795,
      "learning_rate": 7.641234384924836e-05,
      "loss": 0.4576,
      "step": 240700
    },
    {
      "epoch": 2.549203106060205,
      "grad_norm": 2.8296594619750977,
      "learning_rate": 7.644410332415837e-05,
      "loss": 0.454,
      "step": 240800
    },
    {
      "epoch": 2.5502617496202116,
      "grad_norm": 2.784420967102051,
      "learning_rate": 7.647586279906839e-05,
      "loss": 0.4616,
      "step": 240900
    },
    {
      "epoch": 2.551320393180218,
      "grad_norm": 3.191019058227539,
      "learning_rate": 7.65076222739784e-05,
      "loss": 0.4524,
      "step": 241000
    },
    {
      "epoch": 2.551320393180218,
      "eval_loss": 0.3385302424430847,
      "eval_runtime": 57.3194,
      "eval_samples_per_second": 2929.726,
      "eval_steps_per_second": 366.229,
      "step": 241000
    },
    {
      "epoch": 2.552379036740225,
      "grad_norm": 3.2071456909179688,
      "learning_rate": 7.653938174888842e-05,
      "loss": 0.459,
      "step": 241100
    },
    {
      "epoch": 2.5534376803002314,
      "grad_norm": 2.6959030628204346,
      "learning_rate": 7.657114122379843e-05,
      "loss": 0.4565,
      "step": 241200
    },
    {
      "epoch": 2.5544963238602376,
      "grad_norm": 3.0291783809661865,
      "learning_rate": 7.660290069870844e-05,
      "loss": 0.457,
      "step": 241300
    },
    {
      "epoch": 2.5555549674202442,
      "grad_norm": 3.1131038665771484,
      "learning_rate": 7.663466017361846e-05,
      "loss": 0.4586,
      "step": 241400
    },
    {
      "epoch": 2.556613610980251,
      "grad_norm": 2.962230920791626,
      "learning_rate": 7.666641964852848e-05,
      "loss": 0.4539,
      "step": 241500
    },
    {
      "epoch": 2.5576722545402575,
      "grad_norm": 3.005441904067993,
      "learning_rate": 7.66981791234385e-05,
      "loss": 0.4536,
      "step": 241600
    },
    {
      "epoch": 2.558730898100264,
      "grad_norm": 2.888382911682129,
      "learning_rate": 7.67299385983485e-05,
      "loss": 0.4551,
      "step": 241700
    },
    {
      "epoch": 2.5597895416602707,
      "grad_norm": 3.1063475608825684,
      "learning_rate": 7.676169807325852e-05,
      "loss": 0.4513,
      "step": 241800
    },
    {
      "epoch": 2.5608481852202774,
      "grad_norm": 3.0637741088867188,
      "learning_rate": 7.679345754816854e-05,
      "loss": 0.4566,
      "step": 241900
    },
    {
      "epoch": 2.561906828780284,
      "grad_norm": 3.1279115676879883,
      "learning_rate": 7.682521702307856e-05,
      "loss": 0.4515,
      "step": 242000
    },
    {
      "epoch": 2.561906828780284,
      "eval_loss": 0.33852535486221313,
      "eval_runtime": 57.1263,
      "eval_samples_per_second": 2939.624,
      "eval_steps_per_second": 367.466,
      "step": 242000
    },
    {
      "epoch": 2.5629654723402906,
      "grad_norm": 3.229614734649658,
      "learning_rate": 7.685665890323946e-05,
      "loss": 0.4547,
      "step": 242100
    },
    {
      "epoch": 2.564024115900297,
      "grad_norm": 3.4432404041290283,
      "learning_rate": 7.688841837814948e-05,
      "loss": 0.4513,
      "step": 242200
    },
    {
      "epoch": 2.5650827594603034,
      "grad_norm": 2.9803824424743652,
      "learning_rate": 7.69201778530595e-05,
      "loss": 0.4561,
      "step": 242300
    },
    {
      "epoch": 2.56614140302031,
      "grad_norm": 2.925011396408081,
      "learning_rate": 7.695193732796952e-05,
      "loss": 0.4539,
      "step": 242400
    },
    {
      "epoch": 2.5672000465803166,
      "grad_norm": 3.1528737545013428,
      "learning_rate": 7.698369680287952e-05,
      "loss": 0.4565,
      "step": 242500
    },
    {
      "epoch": 2.5682586901403233,
      "grad_norm": 2.8058791160583496,
      "learning_rate": 7.701545627778954e-05,
      "loss": 0.4554,
      "step": 242600
    },
    {
      "epoch": 2.56931733370033,
      "grad_norm": 2.889605760574341,
      "learning_rate": 7.704721575269956e-05,
      "loss": 0.4606,
      "step": 242700
    },
    {
      "epoch": 2.570375977260336,
      "grad_norm": 3.220005750656128,
      "learning_rate": 7.707897522760957e-05,
      "loss": 0.4541,
      "step": 242800
    },
    {
      "epoch": 2.5714346208203427,
      "grad_norm": 3.0996549129486084,
      "learning_rate": 7.711073470251958e-05,
      "loss": 0.456,
      "step": 242900
    },
    {
      "epoch": 2.5724932643803493,
      "grad_norm": 3.1503498554229736,
      "learning_rate": 7.71424941774296e-05,
      "loss": 0.4563,
      "step": 243000
    },
    {
      "epoch": 2.5724932643803493,
      "eval_loss": 0.33689117431640625,
      "eval_runtime": 57.3701,
      "eval_samples_per_second": 2927.135,
      "eval_steps_per_second": 365.905,
      "step": 243000
    },
    {
      "epoch": 2.573551907940356,
      "grad_norm": 3.186692476272583,
      "learning_rate": 7.717425365233961e-05,
      "loss": 0.459,
      "step": 243100
    },
    {
      "epoch": 2.5746105515003626,
      "grad_norm": 2.963320016860962,
      "learning_rate": 7.720601312724963e-05,
      "loss": 0.4561,
      "step": 243200
    },
    {
      "epoch": 2.575669195060369,
      "grad_norm": 2.8183047771453857,
      "learning_rate": 7.723777260215964e-05,
      "loss": 0.4588,
      "step": 243300
    },
    {
      "epoch": 2.576727838620376,
      "grad_norm": 3.0298397541046143,
      "learning_rate": 7.726953207706965e-05,
      "loss": 0.4526,
      "step": 243400
    },
    {
      "epoch": 2.5777864821803824,
      "grad_norm": 2.749444007873535,
      "learning_rate": 7.730129155197967e-05,
      "loss": 0.4537,
      "step": 243500
    },
    {
      "epoch": 2.578845125740389,
      "grad_norm": 3.1760082244873047,
      "learning_rate": 7.733305102688969e-05,
      "loss": 0.4547,
      "step": 243600
    },
    {
      "epoch": 2.5799037693003957,
      "grad_norm": 2.8594634532928467,
      "learning_rate": 7.73648105017997e-05,
      "loss": 0.4597,
      "step": 243700
    },
    {
      "epoch": 2.580962412860402,
      "grad_norm": 2.9876863956451416,
      "learning_rate": 7.739656997670971e-05,
      "loss": 0.4581,
      "step": 243800
    },
    {
      "epoch": 2.5820210564204085,
      "grad_norm": 3.084158182144165,
      "learning_rate": 7.742832945161973e-05,
      "loss": 0.4492,
      "step": 243900
    },
    {
      "epoch": 2.583079699980415,
      "grad_norm": 3.0841023921966553,
      "learning_rate": 7.746008892652975e-05,
      "loss": 0.4517,
      "step": 244000
    },
    {
      "epoch": 2.583079699980415,
      "eval_loss": 0.33740583062171936,
      "eval_runtime": 57.3601,
      "eval_samples_per_second": 2927.643,
      "eval_steps_per_second": 365.968,
      "step": 244000
    },
    {
      "epoch": 2.5841383435404217,
      "grad_norm": 3.1336960792541504,
      "learning_rate": 7.749184840143977e-05,
      "loss": 0.4506,
      "step": 244100
    },
    {
      "epoch": 2.5851969871004283,
      "grad_norm": 2.722766160964966,
      "learning_rate": 7.752360787634977e-05,
      "loss": 0.4567,
      "step": 244200
    },
    {
      "epoch": 2.5862556306604345,
      "grad_norm": 2.9382407665252686,
      "learning_rate": 7.755536735125979e-05,
      "loss": 0.4519,
      "step": 244300
    },
    {
      "epoch": 2.587314274220441,
      "grad_norm": 2.871595859527588,
      "learning_rate": 7.75871268261698e-05,
      "loss": 0.4566,
      "step": 244400
    },
    {
      "epoch": 2.5883729177804478,
      "grad_norm": 2.6880860328674316,
      "learning_rate": 7.761888630107982e-05,
      "loss": 0.4511,
      "step": 244500
    },
    {
      "epoch": 2.5894315613404544,
      "grad_norm": 3.1891515254974365,
      "learning_rate": 7.765064577598983e-05,
      "loss": 0.4554,
      "step": 244600
    },
    {
      "epoch": 2.590490204900461,
      "grad_norm": 2.7953901290893555,
      "learning_rate": 7.768240525089985e-05,
      "loss": 0.4548,
      "step": 244700
    },
    {
      "epoch": 2.5915488484604676,
      "grad_norm": 3.103907346725464,
      "learning_rate": 7.771416472580986e-05,
      "loss": 0.4529,
      "step": 244800
    },
    {
      "epoch": 2.5926074920204742,
      "grad_norm": 3.173391819000244,
      "learning_rate": 7.774592420071988e-05,
      "loss": 0.4516,
      "step": 244900
    },
    {
      "epoch": 2.593666135580481,
      "grad_norm": 2.855163812637329,
      "learning_rate": 7.777768367562989e-05,
      "loss": 0.4576,
      "step": 245000
    },
    {
      "epoch": 2.593666135580481,
      "eval_loss": 0.33536991477012634,
      "eval_runtime": 57.2182,
      "eval_samples_per_second": 2934.906,
      "eval_steps_per_second": 366.876,
      "step": 245000
    },
    {
      "epoch": 2.5947247791404875,
      "grad_norm": 2.946709632873535,
      "learning_rate": 7.78094431505399e-05,
      "loss": 0.4503,
      "step": 245100
    },
    {
      "epoch": 2.595783422700494,
      "grad_norm": 2.6558399200439453,
      "learning_rate": 7.784120262544992e-05,
      "loss": 0.4513,
      "step": 245200
    },
    {
      "epoch": 2.5968420662605003,
      "grad_norm": 2.9553537368774414,
      "learning_rate": 7.787296210035994e-05,
      "loss": 0.4583,
      "step": 245300
    },
    {
      "epoch": 2.597900709820507,
      "grad_norm": 3.454327344894409,
      "learning_rate": 7.790472157526994e-05,
      "loss": 0.4514,
      "step": 245400
    },
    {
      "epoch": 2.5989593533805135,
      "grad_norm": 3.127349376678467,
      "learning_rate": 7.793616345543087e-05,
      "loss": 0.455,
      "step": 245500
    },
    {
      "epoch": 2.60001799694052,
      "grad_norm": 3.062333583831787,
      "learning_rate": 7.796792293034088e-05,
      "loss": 0.4528,
      "step": 245600
    },
    {
      "epoch": 2.601076640500527,
      "grad_norm": 2.845107316970825,
      "learning_rate": 7.79996824052509e-05,
      "loss": 0.4507,
      "step": 245700
    },
    {
      "epoch": 2.6021352840605334,
      "grad_norm": 2.885171890258789,
      "learning_rate": 7.80314418801609e-05,
      "loss": 0.4503,
      "step": 245800
    },
    {
      "epoch": 2.6031939276205396,
      "grad_norm": 3.2264516353607178,
      "learning_rate": 7.806320135507092e-05,
      "loss": 0.4496,
      "step": 245900
    },
    {
      "epoch": 2.604252571180546,
      "grad_norm": 3.195605754852295,
      "learning_rate": 7.809496082998094e-05,
      "loss": 0.451,
      "step": 246000
    },
    {
      "epoch": 2.604252571180546,
      "eval_loss": 0.33477821946144104,
      "eval_runtime": 57.3486,
      "eval_samples_per_second": 2928.234,
      "eval_steps_per_second": 366.042,
      "step": 246000
    },
    {
      "epoch": 2.605311214740553,
      "grad_norm": 3.0238535404205322,
      "learning_rate": 7.812672030489096e-05,
      "loss": 0.446,
      "step": 246100
    },
    {
      "epoch": 2.6063698583005595,
      "grad_norm": 3.1084980964660645,
      "learning_rate": 7.815847977980096e-05,
      "loss": 0.4502,
      "step": 246200
    },
    {
      "epoch": 2.607428501860566,
      "grad_norm": 3.6147968769073486,
      "learning_rate": 7.819023925471098e-05,
      "loss": 0.4526,
      "step": 246300
    },
    {
      "epoch": 2.6084871454205727,
      "grad_norm": 2.9543278217315674,
      "learning_rate": 7.8221998729621e-05,
      "loss": 0.4456,
      "step": 246400
    },
    {
      "epoch": 2.6095457889805793,
      "grad_norm": 3.00534725189209,
      "learning_rate": 7.825375820453102e-05,
      "loss": 0.4564,
      "step": 246500
    },
    {
      "epoch": 2.610604432540586,
      "grad_norm": 3.1008594036102295,
      "learning_rate": 7.828551767944104e-05,
      "loss": 0.4547,
      "step": 246600
    },
    {
      "epoch": 2.6116630761005926,
      "grad_norm": 3.073847770690918,
      "learning_rate": 7.831727715435104e-05,
      "loss": 0.4508,
      "step": 246700
    },
    {
      "epoch": 2.6127217196605987,
      "grad_norm": 3.052018165588379,
      "learning_rate": 7.834903662926106e-05,
      "loss": 0.447,
      "step": 246800
    },
    {
      "epoch": 2.6137803632206054,
      "grad_norm": 3.156224489212036,
      "learning_rate": 7.838079610417108e-05,
      "loss": 0.4538,
      "step": 246900
    },
    {
      "epoch": 2.614839006780612,
      "grad_norm": 2.787482976913452,
      "learning_rate": 7.84125555790811e-05,
      "loss": 0.4552,
      "step": 247000
    },
    {
      "epoch": 2.614839006780612,
      "eval_loss": 0.3355424702167511,
      "eval_runtime": 57.5011,
      "eval_samples_per_second": 2920.464,
      "eval_steps_per_second": 365.071,
      "step": 247000
    },
    {
      "epoch": 2.6158976503406186,
      "grad_norm": 3.055255889892578,
      "learning_rate": 7.84443150539911e-05,
      "loss": 0.4572,
      "step": 247100
    },
    {
      "epoch": 2.6169562939006252,
      "grad_norm": 3.1989939212799072,
      "learning_rate": 7.847607452890112e-05,
      "loss": 0.4559,
      "step": 247200
    },
    {
      "epoch": 2.618014937460632,
      "grad_norm": 3.0323848724365234,
      "learning_rate": 7.850783400381113e-05,
      "loss": 0.447,
      "step": 247300
    },
    {
      "epoch": 2.619073581020638,
      "grad_norm": 3.056857109069824,
      "learning_rate": 7.853959347872115e-05,
      "loss": 0.4526,
      "step": 247400
    },
    {
      "epoch": 2.6201322245806447,
      "grad_norm": 2.6364080905914307,
      "learning_rate": 7.857135295363116e-05,
      "loss": 0.4481,
      "step": 247500
    },
    {
      "epoch": 2.6211908681406513,
      "grad_norm": 2.875903367996216,
      "learning_rate": 7.860279483379208e-05,
      "loss": 0.4498,
      "step": 247600
    },
    {
      "epoch": 2.622249511700658,
      "grad_norm": 2.7410459518432617,
      "learning_rate": 7.86345543087021e-05,
      "loss": 0.4425,
      "step": 247700
    },
    {
      "epoch": 2.6233081552606645,
      "grad_norm": 3.255995750427246,
      "learning_rate": 7.866631378361211e-05,
      "loss": 0.4495,
      "step": 247800
    },
    {
      "epoch": 2.624366798820671,
      "grad_norm": 3.1625568866729736,
      "learning_rate": 7.869807325852212e-05,
      "loss": 0.4482,
      "step": 247900
    },
    {
      "epoch": 2.6254254423806778,
      "grad_norm": 2.8644635677337646,
      "learning_rate": 7.872983273343213e-05,
      "loss": 0.4418,
      "step": 248000
    },
    {
      "epoch": 2.6254254423806778,
      "eval_loss": 0.33510464429855347,
      "eval_runtime": 57.303,
      "eval_samples_per_second": 2930.563,
      "eval_steps_per_second": 366.333,
      "step": 248000
    },
    {
      "epoch": 2.6264840859406844,
      "grad_norm": 2.793610095977783,
      "learning_rate": 7.876159220834215e-05,
      "loss": 0.4483,
      "step": 248100
    },
    {
      "epoch": 2.627542729500691,
      "grad_norm": 2.7782678604125977,
      "learning_rate": 7.879335168325217e-05,
      "loss": 0.4517,
      "step": 248200
    },
    {
      "epoch": 2.628601373060697,
      "grad_norm": 3.012645721435547,
      "learning_rate": 7.882511115816217e-05,
      "loss": 0.4547,
      "step": 248300
    },
    {
      "epoch": 2.629660016620704,
      "grad_norm": 3.191991090774536,
      "learning_rate": 7.885687063307219e-05,
      "loss": 0.4497,
      "step": 248400
    },
    {
      "epoch": 2.6307186601807104,
      "grad_norm": 3.13151478767395,
      "learning_rate": 7.888863010798221e-05,
      "loss": 0.4488,
      "step": 248500
    },
    {
      "epoch": 2.631777303740717,
      "grad_norm": 3.3111822605133057,
      "learning_rate": 7.892038958289223e-05,
      "loss": 0.4476,
      "step": 248600
    },
    {
      "epoch": 2.6328359473007237,
      "grad_norm": 3.372920036315918,
      "learning_rate": 7.895214905780223e-05,
      "loss": 0.4529,
      "step": 248700
    },
    {
      "epoch": 2.6338945908607303,
      "grad_norm": 2.7148807048797607,
      "learning_rate": 7.898390853271225e-05,
      "loss": 0.4525,
      "step": 248800
    },
    {
      "epoch": 2.6349532344207365,
      "grad_norm": 2.4741499423980713,
      "learning_rate": 7.901566800762227e-05,
      "loss": 0.4478,
      "step": 248900
    },
    {
      "epoch": 2.636011877980743,
      "grad_norm": 2.398881673812866,
      "learning_rate": 7.904742748253229e-05,
      "loss": 0.4469,
      "step": 249000
    },
    {
      "epoch": 2.636011877980743,
      "eval_loss": 0.33560895919799805,
      "eval_runtime": 57.3308,
      "eval_samples_per_second": 2929.139,
      "eval_steps_per_second": 366.155,
      "step": 249000
    },
    {
      "epoch": 2.6370705215407497,
      "grad_norm": 2.678318977355957,
      "learning_rate": 7.907918695744229e-05,
      "loss": 0.4518,
      "step": 249100
    },
    {
      "epoch": 2.6381291651007563,
      "grad_norm": 3.3063950538635254,
      "learning_rate": 7.911094643235231e-05,
      "loss": 0.4525,
      "step": 249200
    },
    {
      "epoch": 2.639187808660763,
      "grad_norm": 2.8814167976379395,
      "learning_rate": 7.914270590726233e-05,
      "loss": 0.448,
      "step": 249300
    },
    {
      "epoch": 2.6402464522207696,
      "grad_norm": 3.0785720348358154,
      "learning_rate": 7.917446538217234e-05,
      "loss": 0.4463,
      "step": 249400
    },
    {
      "epoch": 2.641305095780776,
      "grad_norm": 3.0746278762817383,
      "learning_rate": 7.920622485708236e-05,
      "loss": 0.451,
      "step": 249500
    },
    {
      "epoch": 2.642363739340783,
      "grad_norm": 2.4771647453308105,
      "learning_rate": 7.923798433199237e-05,
      "loss": 0.45,
      "step": 249600
    },
    {
      "epoch": 2.6434223829007895,
      "grad_norm": 2.4302079677581787,
      "learning_rate": 7.926974380690238e-05,
      "loss": 0.4505,
      "step": 249700
    },
    {
      "epoch": 2.6444810264607956,
      "grad_norm": 2.7650341987609863,
      "learning_rate": 7.93011856870633e-05,
      "loss": 0.4484,
      "step": 249800
    },
    {
      "epoch": 2.6455396700208023,
      "grad_norm": 3.1001548767089844,
      "learning_rate": 7.933294516197331e-05,
      "loss": 0.4489,
      "step": 249900
    },
    {
      "epoch": 2.646598313580809,
      "grad_norm": 2.9676201343536377,
      "learning_rate": 7.936470463688333e-05,
      "loss": 0.4544,
      "step": 250000
    },
    {
      "epoch": 2.646598313580809,
      "eval_loss": 0.33422330021858215,
      "eval_runtime": 57.4493,
      "eval_samples_per_second": 2923.101,
      "eval_steps_per_second": 365.401,
      "step": 250000
    },
    {
      "epoch": 2.6476569571408155,
      "grad_norm": 2.894883155822754,
      "learning_rate": 7.939646411179335e-05,
      "loss": 0.4462,
      "step": 250100
    },
    {
      "epoch": 2.648715600700822,
      "grad_norm": 2.875720739364624,
      "learning_rate": 7.942822358670336e-05,
      "loss": 0.4462,
      "step": 250200
    },
    {
      "epoch": 2.6497742442608287,
      "grad_norm": 2.811560869216919,
      "learning_rate": 7.945998306161337e-05,
      "loss": 0.4461,
      "step": 250300
    },
    {
      "epoch": 2.650832887820835,
      "grad_norm": 2.673947811126709,
      "learning_rate": 7.949174253652339e-05,
      "loss": 0.4486,
      "step": 250400
    },
    {
      "epoch": 2.6518915313808415,
      "grad_norm": 2.763381242752075,
      "learning_rate": 7.95235020114334e-05,
      "loss": 0.4483,
      "step": 250500
    },
    {
      "epoch": 2.652950174940848,
      "grad_norm": 2.619706392288208,
      "learning_rate": 7.955526148634342e-05,
      "loss": 0.4473,
      "step": 250600
    },
    {
      "epoch": 2.654008818500855,
      "grad_norm": 2.911794424057007,
      "learning_rate": 7.958702096125344e-05,
      "loss": 0.4472,
      "step": 250700
    },
    {
      "epoch": 2.6550674620608614,
      "grad_norm": 3.099504232406616,
      "learning_rate": 7.961878043616344e-05,
      "loss": 0.4439,
      "step": 250800
    },
    {
      "epoch": 2.656126105620868,
      "grad_norm": 2.6866273880004883,
      "learning_rate": 7.965053991107346e-05,
      "loss": 0.4463,
      "step": 250900
    },
    {
      "epoch": 2.6571847491808747,
      "grad_norm": 3.1172876358032227,
      "learning_rate": 7.968229938598348e-05,
      "loss": 0.4512,
      "step": 251000
    },
    {
      "epoch": 2.6571847491808747,
      "eval_loss": 0.33429232239723206,
      "eval_runtime": 57.2127,
      "eval_samples_per_second": 2935.188,
      "eval_steps_per_second": 366.912,
      "step": 251000
    },
    {
      "epoch": 2.6582433927408813,
      "grad_norm": 2.618635892868042,
      "learning_rate": 7.97140588608935e-05,
      "loss": 0.4498,
      "step": 251100
    },
    {
      "epoch": 2.659302036300888,
      "grad_norm": 3.0908043384552,
      "learning_rate": 7.97458183358035e-05,
      "loss": 0.4511,
      "step": 251200
    },
    {
      "epoch": 2.660360679860894,
      "grad_norm": 3.0747146606445312,
      "learning_rate": 7.977757781071352e-05,
      "loss": 0.4484,
      "step": 251300
    },
    {
      "epoch": 2.6614193234209007,
      "grad_norm": 2.6308135986328125,
      "learning_rate": 7.980933728562354e-05,
      "loss": 0.4493,
      "step": 251400
    },
    {
      "epoch": 2.6624779669809073,
      "grad_norm": 2.869013547897339,
      "learning_rate": 7.984109676053356e-05,
      "loss": 0.4404,
      "step": 251500
    },
    {
      "epoch": 2.663536610540914,
      "grad_norm": 2.7905068397521973,
      "learning_rate": 7.987285623544356e-05,
      "loss": 0.4452,
      "step": 251600
    },
    {
      "epoch": 2.6645952541009206,
      "grad_norm": 3.055173635482788,
      "learning_rate": 7.990461571035358e-05,
      "loss": 0.4505,
      "step": 251700
    },
    {
      "epoch": 2.665653897660927,
      "grad_norm": 3.1594595909118652,
      "learning_rate": 7.99363751852636e-05,
      "loss": 0.45,
      "step": 251800
    },
    {
      "epoch": 2.6667125412209334,
      "grad_norm": 2.739473819732666,
      "learning_rate": 7.996813466017361e-05,
      "loss": 0.4453,
      "step": 251900
    },
    {
      "epoch": 2.66777118478094,
      "grad_norm": 3.115936517715454,
      "learning_rate": 7.999989413508363e-05,
      "loss": 0.4493,
      "step": 252000
    },
    {
      "epoch": 2.66777118478094,
      "eval_loss": 0.33168861269950867,
      "eval_runtime": 57.3853,
      "eval_samples_per_second": 2926.357,
      "eval_steps_per_second": 365.808,
      "step": 252000
    },
    {
      "epoch": 2.6688298283409466,
      "grad_norm": 2.9936540126800537,
      "learning_rate": 8.003165360999364e-05,
      "loss": 0.442,
      "step": 252100
    },
    {
      "epoch": 2.6698884719009532,
      "grad_norm": 2.7488784790039062,
      "learning_rate": 8.006341308490365e-05,
      "loss": 0.4477,
      "step": 252200
    },
    {
      "epoch": 2.67094711546096,
      "grad_norm": 2.9530510902404785,
      "learning_rate": 8.009517255981367e-05,
      "loss": 0.4442,
      "step": 252300
    },
    {
      "epoch": 2.6720057590209665,
      "grad_norm": 3.197403907775879,
      "learning_rate": 8.012693203472369e-05,
      "loss": 0.4484,
      "step": 252400
    },
    {
      "epoch": 2.673064402580973,
      "grad_norm": 2.752838373184204,
      "learning_rate": 8.01586915096337e-05,
      "loss": 0.448,
      "step": 252500
    },
    {
      "epoch": 2.6741230461409797,
      "grad_norm": 2.868098497390747,
      "learning_rate": 8.019045098454371e-05,
      "loss": 0.4501,
      "step": 252600
    },
    {
      "epoch": 2.6751816897009864,
      "grad_norm": 2.825342893600464,
      "learning_rate": 8.022221045945373e-05,
      "loss": 0.4481,
      "step": 252700
    },
    {
      "epoch": 2.6762403332609925,
      "grad_norm": 2.9157164096832275,
      "learning_rate": 8.025396993436375e-05,
      "loss": 0.4433,
      "step": 252800
    },
    {
      "epoch": 2.677298976820999,
      "grad_norm": 2.8652234077453613,
      "learning_rate": 8.028572940927375e-05,
      "loss": 0.4452,
      "step": 252900
    },
    {
      "epoch": 2.6783576203810058,
      "grad_norm": 3.1004276275634766,
      "learning_rate": 8.031748888418377e-05,
      "loss": 0.4422,
      "step": 253000
    },
    {
      "epoch": 2.6783576203810058,
      "eval_loss": 0.3318435549736023,
      "eval_runtime": 57.3013,
      "eval_samples_per_second": 2930.65,
      "eval_steps_per_second": 366.344,
      "step": 253000
    },
    {
      "epoch": 2.6794162639410124,
      "grad_norm": 2.7390329837799072,
      "learning_rate": 8.034924835909379e-05,
      "loss": 0.4472,
      "step": 253100
    },
    {
      "epoch": 2.680474907501019,
      "grad_norm": 2.9808712005615234,
      "learning_rate": 8.03810078340038e-05,
      "loss": 0.4531,
      "step": 253200
    },
    {
      "epoch": 2.6815335510610256,
      "grad_norm": 2.8092267513275146,
      "learning_rate": 8.041276730891381e-05,
      "loss": 0.4472,
      "step": 253300
    },
    {
      "epoch": 2.682592194621032,
      "grad_norm": 2.8046388626098633,
      "learning_rate": 8.044452678382383e-05,
      "loss": 0.4475,
      "step": 253400
    },
    {
      "epoch": 2.6836508381810384,
      "grad_norm": 2.823202133178711,
      "learning_rate": 8.047628625873385e-05,
      "loss": 0.4442,
      "step": 253500
    },
    {
      "epoch": 2.684709481741045,
      "grad_norm": 3.089651107788086,
      "learning_rate": 8.050804573364386e-05,
      "loss": 0.449,
      "step": 253600
    },
    {
      "epoch": 2.6857681253010517,
      "grad_norm": 2.6328606605529785,
      "learning_rate": 8.053980520855388e-05,
      "loss": 0.4396,
      "step": 253700
    },
    {
      "epoch": 2.6868267688610583,
      "grad_norm": 3.0918335914611816,
      "learning_rate": 8.057124708871479e-05,
      "loss": 0.4482,
      "step": 253800
    },
    {
      "epoch": 2.687885412421065,
      "grad_norm": 2.4597251415252686,
      "learning_rate": 8.060300656362481e-05,
      "loss": 0.4483,
      "step": 253900
    },
    {
      "epoch": 2.6889440559810716,
      "grad_norm": 2.5622260570526123,
      "learning_rate": 8.063476603853482e-05,
      "loss": 0.4429,
      "step": 254000
    },
    {
      "epoch": 2.6889440559810716,
      "eval_loss": 0.3316381871700287,
      "eval_runtime": 57.1285,
      "eval_samples_per_second": 2939.513,
      "eval_steps_per_second": 367.452,
      "step": 254000
    },
    {
      "epoch": 2.690002699541078,
      "grad_norm": 2.712664842605591,
      "learning_rate": 8.066652551344483e-05,
      "loss": 0.4407,
      "step": 254100
    },
    {
      "epoch": 2.691061343101085,
      "grad_norm": 2.7265853881835938,
      "learning_rate": 8.069828498835485e-05,
      "loss": 0.4436,
      "step": 254200
    },
    {
      "epoch": 2.692119986661091,
      "grad_norm": 2.919903516769409,
      "learning_rate": 8.073004446326487e-05,
      "loss": 0.4469,
      "step": 254300
    },
    {
      "epoch": 2.6931786302210976,
      "grad_norm": 2.9773848056793213,
      "learning_rate": 8.076180393817488e-05,
      "loss": 0.4426,
      "step": 254400
    },
    {
      "epoch": 2.6942372737811042,
      "grad_norm": 3.0852575302124023,
      "learning_rate": 8.079356341308489e-05,
      "loss": 0.4436,
      "step": 254500
    },
    {
      "epoch": 2.695295917341111,
      "grad_norm": 2.7387337684631348,
      "learning_rate": 8.08253228879949e-05,
      "loss": 0.4442,
      "step": 254600
    },
    {
      "epoch": 2.6963545609011175,
      "grad_norm": 2.565614700317383,
      "learning_rate": 8.085708236290492e-05,
      "loss": 0.4479,
      "step": 254700
    },
    {
      "epoch": 2.697413204461124,
      "grad_norm": 3.2190234661102295,
      "learning_rate": 8.088884183781494e-05,
      "loss": 0.4482,
      "step": 254800
    },
    {
      "epoch": 2.6984718480211303,
      "grad_norm": 2.9274206161499023,
      "learning_rate": 8.092060131272496e-05,
      "loss": 0.4476,
      "step": 254900
    },
    {
      "epoch": 2.699530491581137,
      "grad_norm": 3.2107765674591064,
      "learning_rate": 8.095236078763496e-05,
      "loss": 0.447,
      "step": 255000
    },
    {
      "epoch": 2.699530491581137,
      "eval_loss": 0.3303142488002777,
      "eval_runtime": 57.319,
      "eval_samples_per_second": 2929.746,
      "eval_steps_per_second": 366.231,
      "step": 255000
    },
    {
      "epoch": 2.7005891351411435,
      "grad_norm": 2.901214122772217,
      "learning_rate": 8.098412026254498e-05,
      "loss": 0.4441,
      "step": 255100
    },
    {
      "epoch": 2.70164777870115,
      "grad_norm": 2.768812417984009,
      "learning_rate": 8.1015879737455e-05,
      "loss": 0.4405,
      "step": 255200
    },
    {
      "epoch": 2.7027064222611568,
      "grad_norm": 2.9702789783477783,
      "learning_rate": 8.104763921236502e-05,
      "loss": 0.444,
      "step": 255300
    },
    {
      "epoch": 2.7037650658211634,
      "grad_norm": 2.5572476387023926,
      "learning_rate": 8.107939868727502e-05,
      "loss": 0.4481,
      "step": 255400
    },
    {
      "epoch": 2.70482370938117,
      "grad_norm": 2.8681814670562744,
      "learning_rate": 8.111115816218504e-05,
      "loss": 0.4473,
      "step": 255500
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 3.137925863265991,
      "learning_rate": 8.114291763709506e-05,
      "loss": 0.4403,
      "step": 255600
    },
    {
      "epoch": 2.7069409965011832,
      "grad_norm": 2.877992868423462,
      "learning_rate": 8.117467711200508e-05,
      "loss": 0.4452,
      "step": 255700
    },
    {
      "epoch": 2.70799964006119,
      "grad_norm": 2.4891884326934814,
      "learning_rate": 8.120611899216598e-05,
      "loss": 0.4453,
      "step": 255800
    },
    {
      "epoch": 2.709058283621196,
      "grad_norm": 2.6462624073028564,
      "learning_rate": 8.1237878467076e-05,
      "loss": 0.4421,
      "step": 255900
    },
    {
      "epoch": 2.7101169271812027,
      "grad_norm": 3.2896289825439453,
      "learning_rate": 8.126963794198602e-05,
      "loss": 0.4444,
      "step": 256000
    },
    {
      "epoch": 2.7101169271812027,
      "eval_loss": 0.33037033677101135,
      "eval_runtime": 57.2295,
      "eval_samples_per_second": 2934.326,
      "eval_steps_per_second": 366.804,
      "step": 256000
    },
    {
      "epoch": 2.7111755707412093,
      "grad_norm": 2.9177041053771973,
      "learning_rate": 8.130139741689604e-05,
      "loss": 0.4425,
      "step": 256100
    },
    {
      "epoch": 2.712234214301216,
      "grad_norm": 2.9156582355499268,
      "learning_rate": 8.133315689180604e-05,
      "loss": 0.443,
      "step": 256200
    },
    {
      "epoch": 2.7132928578612225,
      "grad_norm": 2.5811357498168945,
      "learning_rate": 8.136491636671606e-05,
      "loss": 0.4408,
      "step": 256300
    },
    {
      "epoch": 2.7143515014212287,
      "grad_norm": 3.3394222259521484,
      "learning_rate": 8.139667584162608e-05,
      "loss": 0.4478,
      "step": 256400
    },
    {
      "epoch": 2.7154101449812353,
      "grad_norm": 2.9665768146514893,
      "learning_rate": 8.14284353165361e-05,
      "loss": 0.4459,
      "step": 256500
    },
    {
      "epoch": 2.716468788541242,
      "grad_norm": 2.9947731494903564,
      "learning_rate": 8.14601947914461e-05,
      "loss": 0.4413,
      "step": 256600
    },
    {
      "epoch": 2.7175274321012486,
      "grad_norm": 2.5127224922180176,
      "learning_rate": 8.149163667160702e-05,
      "loss": 0.4475,
      "step": 256700
    },
    {
      "epoch": 2.718586075661255,
      "grad_norm": 2.6620147228240967,
      "learning_rate": 8.152339614651704e-05,
      "loss": 0.4421,
      "step": 256800
    },
    {
      "epoch": 2.719644719221262,
      "grad_norm": 2.9928247928619385,
      "learning_rate": 8.155515562142705e-05,
      "loss": 0.4375,
      "step": 256900
    },
    {
      "epoch": 2.7207033627812685,
      "grad_norm": 2.8510470390319824,
      "learning_rate": 8.158691509633706e-05,
      "loss": 0.4431,
      "step": 257000
    },
    {
      "epoch": 2.7207033627812685,
      "eval_loss": 0.33065956830978394,
      "eval_runtime": 57.2288,
      "eval_samples_per_second": 2934.364,
      "eval_steps_per_second": 366.809,
      "step": 257000
    },
    {
      "epoch": 2.721762006341275,
      "grad_norm": 2.5072736740112305,
      "learning_rate": 8.161867457124708e-05,
      "loss": 0.4406,
      "step": 257100
    },
    {
      "epoch": 2.7228206499012817,
      "grad_norm": 3.028858184814453,
      "learning_rate": 8.16504340461571e-05,
      "loss": 0.4457,
      "step": 257200
    },
    {
      "epoch": 2.7238792934612883,
      "grad_norm": 2.8441221714019775,
      "learning_rate": 8.168219352106711e-05,
      "loss": 0.4413,
      "step": 257300
    },
    {
      "epoch": 2.7249379370212945,
      "grad_norm": 3.131174087524414,
      "learning_rate": 8.171395299597712e-05,
      "loss": 0.4443,
      "step": 257400
    },
    {
      "epoch": 2.725996580581301,
      "grad_norm": 3.0472865104675293,
      "learning_rate": 8.174571247088714e-05,
      "loss": 0.4429,
      "step": 257500
    },
    {
      "epoch": 2.7270552241413077,
      "grad_norm": 2.683215618133545,
      "learning_rate": 8.177747194579715e-05,
      "loss": 0.4424,
      "step": 257600
    },
    {
      "epoch": 2.7281138677013144,
      "grad_norm": 2.8463313579559326,
      "learning_rate": 8.180923142070717e-05,
      "loss": 0.4424,
      "step": 257700
    },
    {
      "epoch": 2.729172511261321,
      "grad_norm": 2.7350335121154785,
      "learning_rate": 8.184099089561718e-05,
      "loss": 0.4454,
      "step": 257800
    },
    {
      "epoch": 2.730231154821327,
      "grad_norm": 2.8193719387054443,
      "learning_rate": 8.18727503705272e-05,
      "loss": 0.4409,
      "step": 257900
    },
    {
      "epoch": 2.731289798381334,
      "grad_norm": 3.010120391845703,
      "learning_rate": 8.190450984543721e-05,
      "loss": 0.442,
      "step": 258000
    },
    {
      "epoch": 2.731289798381334,
      "eval_loss": 0.3288933038711548,
      "eval_runtime": 57.3416,
      "eval_samples_per_second": 2928.591,
      "eval_steps_per_second": 366.087,
      "step": 258000
    },
    {
      "epoch": 2.7323484419413404,
      "grad_norm": 2.7075400352478027,
      "learning_rate": 8.193626932034723e-05,
      "loss": 0.444,
      "step": 258100
    },
    {
      "epoch": 2.733407085501347,
      "grad_norm": 2.9899799823760986,
      "learning_rate": 8.196802879525723e-05,
      "loss": 0.4439,
      "step": 258200
    },
    {
      "epoch": 2.7344657290613537,
      "grad_norm": 2.591142416000366,
      "learning_rate": 8.199978827016725e-05,
      "loss": 0.4465,
      "step": 258300
    },
    {
      "epoch": 2.7355243726213603,
      "grad_norm": 2.730086326599121,
      "learning_rate": 8.203154774507727e-05,
      "loss": 0.445,
      "step": 258400
    },
    {
      "epoch": 2.736583016181367,
      "grad_norm": 2.6393744945526123,
      "learning_rate": 8.206330721998729e-05,
      "loss": 0.4432,
      "step": 258500
    },
    {
      "epoch": 2.7376416597413735,
      "grad_norm": 2.829799175262451,
      "learning_rate": 8.20950666948973e-05,
      "loss": 0.4438,
      "step": 258600
    },
    {
      "epoch": 2.73870030330138,
      "grad_norm": 2.9515726566314697,
      "learning_rate": 8.212682616980731e-05,
      "loss": 0.4433,
      "step": 258700
    },
    {
      "epoch": 2.7397589468613868,
      "grad_norm": 3.262570858001709,
      "learning_rate": 8.215858564471733e-05,
      "loss": 0.4377,
      "step": 258800
    },
    {
      "epoch": 2.740817590421393,
      "grad_norm": 2.7570102214813232,
      "learning_rate": 8.219034511962735e-05,
      "loss": 0.4374,
      "step": 258900
    },
    {
      "epoch": 2.7418762339813996,
      "grad_norm": 2.833197593688965,
      "learning_rate": 8.222210459453736e-05,
      "loss": 0.4417,
      "step": 259000
    },
    {
      "epoch": 2.7418762339813996,
      "eval_loss": 0.32801908254623413,
      "eval_runtime": 57.3098,
      "eval_samples_per_second": 2930.216,
      "eval_steps_per_second": 366.29,
      "step": 259000
    },
    {
      "epoch": 2.742934877541406,
      "grad_norm": 2.885838747024536,
      "learning_rate": 8.225386406944737e-05,
      "loss": 0.4393,
      "step": 259100
    },
    {
      "epoch": 2.743993521101413,
      "grad_norm": 2.983182430267334,
      "learning_rate": 8.228562354435739e-05,
      "loss": 0.4475,
      "step": 259200
    },
    {
      "epoch": 2.7450521646614194,
      "grad_norm": 2.9448928833007812,
      "learning_rate": 8.23173830192674e-05,
      "loss": 0.4345,
      "step": 259300
    },
    {
      "epoch": 2.7461108082214256,
      "grad_norm": 2.984485626220703,
      "learning_rate": 8.234914249417742e-05,
      "loss": 0.4374,
      "step": 259400
    },
    {
      "epoch": 2.7471694517814322,
      "grad_norm": 2.705441951751709,
      "learning_rate": 8.238090196908743e-05,
      "loss": 0.4418,
      "step": 259500
    },
    {
      "epoch": 2.748228095341439,
      "grad_norm": 3.3371572494506836,
      "learning_rate": 8.241266144399744e-05,
      "loss": 0.4422,
      "step": 259600
    },
    {
      "epoch": 2.7492867389014455,
      "grad_norm": 2.935072422027588,
      "learning_rate": 8.244442091890746e-05,
      "loss": 0.4426,
      "step": 259700
    },
    {
      "epoch": 2.750345382461452,
      "grad_norm": 2.5992355346679688,
      "learning_rate": 8.247618039381748e-05,
      "loss": 0.443,
      "step": 259800
    },
    {
      "epoch": 2.7514040260214587,
      "grad_norm": 2.6565921306610107,
      "learning_rate": 8.25079398687275e-05,
      "loss": 0.4403,
      "step": 259900
    },
    {
      "epoch": 2.7524626695814653,
      "grad_norm": 2.8791468143463135,
      "learning_rate": 8.25396993436375e-05,
      "loss": 0.4425,
      "step": 260000
    },
    {
      "epoch": 2.7524626695814653,
      "eval_loss": 0.3275946378707886,
      "eval_runtime": 57.2128,
      "eval_samples_per_second": 2935.183,
      "eval_steps_per_second": 366.911,
      "step": 260000
    },
    {
      "epoch": 2.753521313141472,
      "grad_norm": 3.0542547702789307,
      "learning_rate": 8.257145881854752e-05,
      "loss": 0.4393,
      "step": 260100
    },
    {
      "epoch": 2.7545799567014786,
      "grad_norm": 2.8972175121307373,
      "learning_rate": 8.260321829345754e-05,
      "loss": 0.4428,
      "step": 260200
    },
    {
      "epoch": 2.755638600261485,
      "grad_norm": 2.7706124782562256,
      "learning_rate": 8.263497776836756e-05,
      "loss": 0.4437,
      "step": 260300
    },
    {
      "epoch": 2.7566972438214914,
      "grad_norm": 2.4701032638549805,
      "learning_rate": 8.266673724327756e-05,
      "loss": 0.4444,
      "step": 260400
    },
    {
      "epoch": 2.757755887381498,
      "grad_norm": 3.0490896701812744,
      "learning_rate": 8.269849671818758e-05,
      "loss": 0.443,
      "step": 260500
    },
    {
      "epoch": 2.7588145309415046,
      "grad_norm": 2.7887637615203857,
      "learning_rate": 8.27302561930976e-05,
      "loss": 0.4386,
      "step": 260600
    },
    {
      "epoch": 2.7598731745015113,
      "grad_norm": 2.9955475330352783,
      "learning_rate": 8.27616980732585e-05,
      "loss": 0.4332,
      "step": 260700
    },
    {
      "epoch": 2.760931818061518,
      "grad_norm": 3.1170711517333984,
      "learning_rate": 8.279345754816852e-05,
      "loss": 0.4426,
      "step": 260800
    },
    {
      "epoch": 2.7619904616215245,
      "grad_norm": 2.7744805812835693,
      "learning_rate": 8.282521702307854e-05,
      "loss": 0.4427,
      "step": 260900
    },
    {
      "epoch": 2.7630491051815307,
      "grad_norm": 2.7540054321289062,
      "learning_rate": 8.285697649798856e-05,
      "loss": 0.44,
      "step": 261000
    },
    {
      "epoch": 2.7630491051815307,
      "eval_loss": 0.32795652747154236,
      "eval_runtime": 57.2712,
      "eval_samples_per_second": 2932.189,
      "eval_steps_per_second": 366.537,
      "step": 261000
    },
    {
      "epoch": 2.7641077487415373,
      "grad_norm": 2.952280044555664,
      "learning_rate": 8.288873597289857e-05,
      "loss": 0.4436,
      "step": 261100
    },
    {
      "epoch": 2.765166392301544,
      "grad_norm": 2.732767105102539,
      "learning_rate": 8.292049544780858e-05,
      "loss": 0.4373,
      "step": 261200
    },
    {
      "epoch": 2.7662250358615506,
      "grad_norm": 2.874788999557495,
      "learning_rate": 8.29522549227186e-05,
      "loss": 0.4406,
      "step": 261300
    },
    {
      "epoch": 2.767283679421557,
      "grad_norm": 3.1045289039611816,
      "learning_rate": 8.298401439762861e-05,
      "loss": 0.4368,
      "step": 261400
    },
    {
      "epoch": 2.768342322981564,
      "grad_norm": 3.255089044570923,
      "learning_rate": 8.301577387253863e-05,
      "loss": 0.4351,
      "step": 261500
    },
    {
      "epoch": 2.7694009665415704,
      "grad_norm": 2.811842918395996,
      "learning_rate": 8.304753334744864e-05,
      "loss": 0.4377,
      "step": 261600
    },
    {
      "epoch": 2.770459610101577,
      "grad_norm": 2.5714945793151855,
      "learning_rate": 8.307929282235865e-05,
      "loss": 0.4397,
      "step": 261700
    },
    {
      "epoch": 2.7715182536615837,
      "grad_norm": 2.6197140216827393,
      "learning_rate": 8.311105229726867e-05,
      "loss": 0.4368,
      "step": 261800
    },
    {
      "epoch": 2.77257689722159,
      "grad_norm": 2.3778202533721924,
      "learning_rate": 8.314281177217869e-05,
      "loss": 0.4375,
      "step": 261900
    },
    {
      "epoch": 2.7736355407815965,
      "grad_norm": 2.753291130065918,
      "learning_rate": 8.31745712470887e-05,
      "loss": 0.4336,
      "step": 262000
    },
    {
      "epoch": 2.7736355407815965,
      "eval_loss": 0.32781466841697693,
      "eval_runtime": 57.3175,
      "eval_samples_per_second": 2929.823,
      "eval_steps_per_second": 366.241,
      "step": 262000
    },
    {
      "epoch": 2.774694184341603,
      "grad_norm": 3.089953660964966,
      "learning_rate": 8.320633072199871e-05,
      "loss": 0.4377,
      "step": 262100
    },
    {
      "epoch": 2.7757528279016097,
      "grad_norm": 2.77573561668396,
      "learning_rate": 8.323809019690873e-05,
      "loss": 0.4402,
      "step": 262200
    },
    {
      "epoch": 2.7768114714616163,
      "grad_norm": 2.8462958335876465,
      "learning_rate": 8.326984967181875e-05,
      "loss": 0.4395,
      "step": 262300
    },
    {
      "epoch": 2.777870115021623,
      "grad_norm": 2.960266590118408,
      "learning_rate": 8.330160914672875e-05,
      "loss": 0.4374,
      "step": 262400
    },
    {
      "epoch": 2.778928758581629,
      "grad_norm": 2.595045804977417,
      "learning_rate": 8.333336862163877e-05,
      "loss": 0.4423,
      "step": 262500
    },
    {
      "epoch": 2.7799874021416358,
      "grad_norm": 2.9610133171081543,
      "learning_rate": 8.336512809654879e-05,
      "loss": 0.4404,
      "step": 262600
    },
    {
      "epoch": 2.7810460457016424,
      "grad_norm": 2.538186550140381,
      "learning_rate": 8.339656997670971e-05,
      "loss": 0.4412,
      "step": 262700
    },
    {
      "epoch": 2.782104689261649,
      "grad_norm": 2.594810724258423,
      "learning_rate": 8.342832945161971e-05,
      "loss": 0.4413,
      "step": 262800
    },
    {
      "epoch": 2.7831633328216556,
      "grad_norm": 3.0057497024536133,
      "learning_rate": 8.346008892652973e-05,
      "loss": 0.4348,
      "step": 262900
    },
    {
      "epoch": 2.7842219763816622,
      "grad_norm": 2.479938507080078,
      "learning_rate": 8.349184840143975e-05,
      "loss": 0.4383,
      "step": 263000
    },
    {
      "epoch": 2.7842219763816622,
      "eval_loss": 0.3265504539012909,
      "eval_runtime": 57.2133,
      "eval_samples_per_second": 2935.157,
      "eval_steps_per_second": 366.908,
      "step": 263000
    },
    {
      "epoch": 2.785280619941669,
      "grad_norm": 2.802875518798828,
      "learning_rate": 8.352360787634977e-05,
      "loss": 0.4404,
      "step": 263100
    },
    {
      "epoch": 2.7863392635016755,
      "grad_norm": 2.2921314239501953,
      "learning_rate": 8.355536735125977e-05,
      "loss": 0.4348,
      "step": 263200
    },
    {
      "epoch": 2.787397907061682,
      "grad_norm": 2.6981821060180664,
      "learning_rate": 8.358712682616979e-05,
      "loss": 0.4422,
      "step": 263300
    },
    {
      "epoch": 2.7884565506216883,
      "grad_norm": 2.960991621017456,
      "learning_rate": 8.361888630107981e-05,
      "loss": 0.4395,
      "step": 263400
    },
    {
      "epoch": 2.789515194181695,
      "grad_norm": 3.0597572326660156,
      "learning_rate": 8.365064577598983e-05,
      "loss": 0.4393,
      "step": 263500
    },
    {
      "epoch": 2.7905738377417015,
      "grad_norm": 2.88224458694458,
      "learning_rate": 8.368208765615073e-05,
      "loss": 0.432,
      "step": 263600
    },
    {
      "epoch": 2.791632481301708,
      "grad_norm": 3.016359329223633,
      "learning_rate": 8.371384713106075e-05,
      "loss": 0.4409,
      "step": 263700
    },
    {
      "epoch": 2.792691124861715,
      "grad_norm": 2.687687873840332,
      "learning_rate": 8.374560660597077e-05,
      "loss": 0.4378,
      "step": 263800
    },
    {
      "epoch": 2.7937497684217214,
      "grad_norm": 2.5164504051208496,
      "learning_rate": 8.377736608088079e-05,
      "loss": 0.437,
      "step": 263900
    },
    {
      "epoch": 2.7948084119817276,
      "grad_norm": 2.6598551273345947,
      "learning_rate": 8.380912555579079e-05,
      "loss": 0.4394,
      "step": 264000
    },
    {
      "epoch": 2.7948084119817276,
      "eval_loss": 0.32740598917007446,
      "eval_runtime": 57.3095,
      "eval_samples_per_second": 2930.23,
      "eval_steps_per_second": 366.292,
      "step": 264000
    },
    {
      "epoch": 2.795867055541734,
      "grad_norm": 2.596573829650879,
      "learning_rate": 8.384088503070081e-05,
      "loss": 0.4379,
      "step": 264100
    },
    {
      "epoch": 2.796925699101741,
      "grad_norm": 2.5576658248901367,
      "learning_rate": 8.387264450561083e-05,
      "loss": 0.4365,
      "step": 264200
    },
    {
      "epoch": 2.7979843426617474,
      "grad_norm": 2.5505144596099854,
      "learning_rate": 8.390440398052084e-05,
      "loss": 0.4422,
      "step": 264300
    },
    {
      "epoch": 2.799042986221754,
      "grad_norm": 2.9531149864196777,
      "learning_rate": 8.393616345543085e-05,
      "loss": 0.4388,
      "step": 264400
    },
    {
      "epoch": 2.8001016297817607,
      "grad_norm": 2.9518086910247803,
      "learning_rate": 8.396792293034087e-05,
      "loss": 0.4347,
      "step": 264500
    },
    {
      "epoch": 2.8011602733417673,
      "grad_norm": 2.551133871078491,
      "learning_rate": 8.399968240525088e-05,
      "loss": 0.4319,
      "step": 264600
    },
    {
      "epoch": 2.802218916901774,
      "grad_norm": 2.6398422718048096,
      "learning_rate": 8.40314418801609e-05,
      "loss": 0.4387,
      "step": 264700
    },
    {
      "epoch": 2.8032775604617806,
      "grad_norm": 2.7499070167541504,
      "learning_rate": 8.406320135507092e-05,
      "loss": 0.4361,
      "step": 264800
    },
    {
      "epoch": 2.8043362040217867,
      "grad_norm": 2.6805222034454346,
      "learning_rate": 8.409496082998095e-05,
      "loss": 0.436,
      "step": 264900
    },
    {
      "epoch": 2.8053948475817934,
      "grad_norm": 2.8238372802734375,
      "learning_rate": 8.412672030489096e-05,
      "loss": 0.43,
      "step": 265000
    },
    {
      "epoch": 2.8053948475817934,
      "eval_loss": 0.3266119956970215,
      "eval_runtime": 57.3149,
      "eval_samples_per_second": 2929.951,
      "eval_steps_per_second": 366.257,
      "step": 265000
    },
    {
      "epoch": 2.8064534911418,
      "grad_norm": 2.8464624881744385,
      "learning_rate": 8.415847977980097e-05,
      "loss": 0.44,
      "step": 265100
    },
    {
      "epoch": 2.8075121347018066,
      "grad_norm": 2.077773094177246,
      "learning_rate": 8.419023925471099e-05,
      "loss": 0.4303,
      "step": 265200
    },
    {
      "epoch": 2.8085707782618132,
      "grad_norm": 3.083693742752075,
      "learning_rate": 8.422199872962101e-05,
      "loss": 0.4402,
      "step": 265300
    },
    {
      "epoch": 2.80962942182182,
      "grad_norm": 3.1923022270202637,
      "learning_rate": 8.425375820453101e-05,
      "loss": 0.4368,
      "step": 265400
    },
    {
      "epoch": 2.810688065381826,
      "grad_norm": 2.81740665435791,
      "learning_rate": 8.428551767944103e-05,
      "loss": 0.4388,
      "step": 265500
    },
    {
      "epoch": 2.8117467089418327,
      "grad_norm": 2.69376540184021,
      "learning_rate": 8.431727715435105e-05,
      "loss": 0.4414,
      "step": 265600
    },
    {
      "epoch": 2.8128053525018393,
      "grad_norm": 2.504560947418213,
      "learning_rate": 8.434903662926107e-05,
      "loss": 0.4371,
      "step": 265700
    },
    {
      "epoch": 2.813863996061846,
      "grad_norm": 2.6968204975128174,
      "learning_rate": 8.438079610417107e-05,
      "loss": 0.4316,
      "step": 265800
    },
    {
      "epoch": 2.8149226396218525,
      "grad_norm": 2.526930093765259,
      "learning_rate": 8.441255557908109e-05,
      "loss": 0.4305,
      "step": 265900
    },
    {
      "epoch": 2.815981283181859,
      "grad_norm": 2.5644948482513428,
      "learning_rate": 8.444431505399111e-05,
      "loss": 0.4326,
      "step": 266000
    },
    {
      "epoch": 2.815981283181859,
      "eval_loss": 0.3256835341453552,
      "eval_runtime": 57.1544,
      "eval_samples_per_second": 2938.179,
      "eval_steps_per_second": 367.285,
      "step": 266000
    },
    {
      "epoch": 2.8170399267418658,
      "grad_norm": 2.5510473251342773,
      "learning_rate": 8.447607452890113e-05,
      "loss": 0.4368,
      "step": 266100
    },
    {
      "epoch": 2.8180985703018724,
      "grad_norm": 2.5161893367767334,
      "learning_rate": 8.450783400381113e-05,
      "loss": 0.4374,
      "step": 266200
    },
    {
      "epoch": 2.819157213861879,
      "grad_norm": 2.91007924079895,
      "learning_rate": 8.453959347872115e-05,
      "loss": 0.4302,
      "step": 266300
    },
    {
      "epoch": 2.820215857421885,
      "grad_norm": 2.93294620513916,
      "learning_rate": 8.457135295363117e-05,
      "loss": 0.4361,
      "step": 266400
    },
    {
      "epoch": 2.821274500981892,
      "grad_norm": 2.8478963375091553,
      "learning_rate": 8.460311242854118e-05,
      "loss": 0.4397,
      "step": 266500
    },
    {
      "epoch": 2.8223331445418984,
      "grad_norm": 2.4340710639953613,
      "learning_rate": 8.46348719034512e-05,
      "loss": 0.4308,
      "step": 266600
    },
    {
      "epoch": 2.823391788101905,
      "grad_norm": 3.112410068511963,
      "learning_rate": 8.46666313783612e-05,
      "loss": 0.432,
      "step": 266700
    },
    {
      "epoch": 2.8244504316619117,
      "grad_norm": 3.0807230472564697,
      "learning_rate": 8.469839085327122e-05,
      "loss": 0.4359,
      "step": 266800
    },
    {
      "epoch": 2.8255090752219183,
      "grad_norm": 2.6963610649108887,
      "learning_rate": 8.473015032818124e-05,
      "loss": 0.4345,
      "step": 266900
    },
    {
      "epoch": 2.8265677187819245,
      "grad_norm": 2.852774143218994,
      "learning_rate": 8.476190980309126e-05,
      "loss": 0.4344,
      "step": 267000
    },
    {
      "epoch": 2.8265677187819245,
      "eval_loss": 0.32367801666259766,
      "eval_runtime": 57.1976,
      "eval_samples_per_second": 2935.963,
      "eval_steps_per_second": 367.008,
      "step": 267000
    },
    {
      "epoch": 2.827626362341931,
      "grad_norm": 2.7045726776123047,
      "learning_rate": 8.479366927800126e-05,
      "loss": 0.4374,
      "step": 267100
    },
    {
      "epoch": 2.8286850059019377,
      "grad_norm": 2.6577489376068115,
      "learning_rate": 8.482542875291128e-05,
      "loss": 0.4382,
      "step": 267200
    },
    {
      "epoch": 2.8297436494619443,
      "grad_norm": 2.571629047393799,
      "learning_rate": 8.48571882278213e-05,
      "loss": 0.4338,
      "step": 267300
    },
    {
      "epoch": 2.830802293021951,
      "grad_norm": 2.722973585128784,
      "learning_rate": 8.488894770273132e-05,
      "loss": 0.4373,
      "step": 267400
    },
    {
      "epoch": 2.8318609365819576,
      "grad_norm": 2.7762045860290527,
      "learning_rate": 8.492070717764132e-05,
      "loss": 0.4361,
      "step": 267500
    },
    {
      "epoch": 2.832919580141964,
      "grad_norm": 2.793767213821411,
      "learning_rate": 8.495214905780224e-05,
      "loss": 0.434,
      "step": 267600
    },
    {
      "epoch": 2.833978223701971,
      "grad_norm": 2.9751241207122803,
      "learning_rate": 8.498390853271226e-05,
      "loss": 0.4397,
      "step": 267700
    },
    {
      "epoch": 2.8350368672619775,
      "grad_norm": 2.8804938793182373,
      "learning_rate": 8.501566800762228e-05,
      "loss": 0.4318,
      "step": 267800
    },
    {
      "epoch": 2.8360955108219836,
      "grad_norm": 2.899522542953491,
      "learning_rate": 8.504742748253228e-05,
      "loss": 0.4366,
      "step": 267900
    },
    {
      "epoch": 2.8371541543819903,
      "grad_norm": 2.806241273880005,
      "learning_rate": 8.50791869574423e-05,
      "loss": 0.4348,
      "step": 268000
    },
    {
      "epoch": 2.8371541543819903,
      "eval_loss": 0.3252139985561371,
      "eval_runtime": 57.3122,
      "eval_samples_per_second": 2930.09,
      "eval_steps_per_second": 366.274,
      "step": 268000
    },
    {
      "epoch": 2.838212797941997,
      "grad_norm": 2.583848476409912,
      "learning_rate": 8.511094643235232e-05,
      "loss": 0.4406,
      "step": 268100
    },
    {
      "epoch": 2.8392714415020035,
      "grad_norm": 2.911172389984131,
      "learning_rate": 8.514270590726234e-05,
      "loss": 0.4337,
      "step": 268200
    },
    {
      "epoch": 2.84033008506201,
      "grad_norm": 2.896240472793579,
      "learning_rate": 8.517446538217234e-05,
      "loss": 0.4314,
      "step": 268300
    },
    {
      "epoch": 2.8413887286220167,
      "grad_norm": 2.3602256774902344,
      "learning_rate": 8.520622485708236e-05,
      "loss": 0.435,
      "step": 268400
    },
    {
      "epoch": 2.842447372182023,
      "grad_norm": 2.5627188682556152,
      "learning_rate": 8.523798433199238e-05,
      "loss": 0.4328,
      "step": 268500
    },
    {
      "epoch": 2.8435060157420295,
      "grad_norm": 3.207934617996216,
      "learning_rate": 8.52697438069024e-05,
      "loss": 0.4336,
      "step": 268600
    },
    {
      "epoch": 2.844564659302036,
      "grad_norm": 2.600893497467041,
      "learning_rate": 8.53015032818124e-05,
      "loss": 0.4322,
      "step": 268700
    },
    {
      "epoch": 2.845623302862043,
      "grad_norm": 2.699799060821533,
      "learning_rate": 8.533326275672242e-05,
      "loss": 0.4327,
      "step": 268800
    },
    {
      "epoch": 2.8466819464220494,
      "grad_norm": 2.863715648651123,
      "learning_rate": 8.536502223163244e-05,
      "loss": 0.4312,
      "step": 268900
    },
    {
      "epoch": 2.847740589982056,
      "grad_norm": 3.005352735519409,
      "learning_rate": 8.539678170654245e-05,
      "loss": 0.4411,
      "step": 269000
    },
    {
      "epoch": 2.847740589982056,
      "eval_loss": 0.3228450119495392,
      "eval_runtime": 57.1743,
      "eval_samples_per_second": 2937.156,
      "eval_steps_per_second": 367.158,
      "step": 269000
    },
    {
      "epoch": 2.8487992335420627,
      "grad_norm": 2.9078872203826904,
      "learning_rate": 8.542854118145247e-05,
      "loss": 0.4334,
      "step": 269100
    },
    {
      "epoch": 2.8498578771020693,
      "grad_norm": 2.769609212875366,
      "learning_rate": 8.546030065636248e-05,
      "loss": 0.4374,
      "step": 269200
    },
    {
      "epoch": 2.850916520662076,
      "grad_norm": 2.725796937942505,
      "learning_rate": 8.54920601312725e-05,
      "loss": 0.4313,
      "step": 269300
    },
    {
      "epoch": 2.851975164222082,
      "grad_norm": 2.6723031997680664,
      "learning_rate": 8.552381960618251e-05,
      "loss": 0.4323,
      "step": 269400
    },
    {
      "epoch": 2.8530338077820887,
      "grad_norm": 2.624748468399048,
      "learning_rate": 8.555557908109253e-05,
      "loss": 0.4277,
      "step": 269500
    },
    {
      "epoch": 2.8540924513420953,
      "grad_norm": 2.7167017459869385,
      "learning_rate": 8.558702096125344e-05,
      "loss": 0.4371,
      "step": 269600
    },
    {
      "epoch": 2.855151094902102,
      "grad_norm": 2.9196629524230957,
      "learning_rate": 8.561878043616345e-05,
      "loss": 0.4315,
      "step": 269700
    },
    {
      "epoch": 2.8562097384621086,
      "grad_norm": 2.838094711303711,
      "learning_rate": 8.565053991107347e-05,
      "loss": 0.4318,
      "step": 269800
    },
    {
      "epoch": 2.857268382022115,
      "grad_norm": 2.236480712890625,
      "learning_rate": 8.568229938598348e-05,
      "loss": 0.4308,
      "step": 269900
    },
    {
      "epoch": 2.8583270255821214,
      "grad_norm": 2.7884328365325928,
      "learning_rate": 8.57140588608935e-05,
      "loss": 0.4353,
      "step": 270000
    },
    {
      "epoch": 2.8583270255821214,
      "eval_loss": 0.3233437240123749,
      "eval_runtime": 57.3595,
      "eval_samples_per_second": 2927.676,
      "eval_steps_per_second": 365.973,
      "step": 270000
    },
    {
      "epoch": 2.859385669142128,
      "grad_norm": 2.6035499572753906,
      "learning_rate": 8.574581833580351e-05,
      "loss": 0.4325,
      "step": 270100
    },
    {
      "epoch": 2.8604443127021346,
      "grad_norm": 2.8976998329162598,
      "learning_rate": 8.577757781071353e-05,
      "loss": 0.4297,
      "step": 270200
    },
    {
      "epoch": 2.8615029562621412,
      "grad_norm": 2.9316766262054443,
      "learning_rate": 8.580933728562355e-05,
      "loss": 0.4378,
      "step": 270300
    },
    {
      "epoch": 2.862561599822148,
      "grad_norm": 2.899027109146118,
      "learning_rate": 8.584109676053355e-05,
      "loss": 0.4362,
      "step": 270400
    },
    {
      "epoch": 2.8636202433821545,
      "grad_norm": 2.801440954208374,
      "learning_rate": 8.587285623544357e-05,
      "loss": 0.4298,
      "step": 270500
    },
    {
      "epoch": 2.864678886942161,
      "grad_norm": 2.8643300533294678,
      "learning_rate": 8.590461571035359e-05,
      "loss": 0.4372,
      "step": 270600
    },
    {
      "epoch": 2.8657375305021677,
      "grad_norm": 2.502732992172241,
      "learning_rate": 8.59363751852636e-05,
      "loss": 0.4346,
      "step": 270700
    },
    {
      "epoch": 2.8667961740621744,
      "grad_norm": 2.691622495651245,
      "learning_rate": 8.596813466017361e-05,
      "loss": 0.4315,
      "step": 270800
    },
    {
      "epoch": 2.867854817622181,
      "grad_norm": 2.5484936237335205,
      "learning_rate": 8.599989413508363e-05,
      "loss": 0.4283,
      "step": 270900
    },
    {
      "epoch": 2.868913461182187,
      "grad_norm": 2.579833984375,
      "learning_rate": 8.603165360999365e-05,
      "loss": 0.4303,
      "step": 271000
    },
    {
      "epoch": 2.868913461182187,
      "eval_loss": 0.324321985244751,
      "eval_runtime": 57.3175,
      "eval_samples_per_second": 2929.819,
      "eval_steps_per_second": 366.24,
      "step": 271000
    },
    {
      "epoch": 2.8699721047421938,
      "grad_norm": 2.368983745574951,
      "learning_rate": 8.606341308490366e-05,
      "loss": 0.4325,
      "step": 271100
    },
    {
      "epoch": 2.8710307483022004,
      "grad_norm": 2.788053274154663,
      "learning_rate": 8.609517255981367e-05,
      "loss": 0.4271,
      "step": 271200
    },
    {
      "epoch": 2.872089391862207,
      "grad_norm": 2.7166640758514404,
      "learning_rate": 8.612693203472369e-05,
      "loss": 0.4301,
      "step": 271300
    },
    {
      "epoch": 2.8731480354222136,
      "grad_norm": 2.7352302074432373,
      "learning_rate": 8.61586915096337e-05,
      "loss": 0.4345,
      "step": 271400
    },
    {
      "epoch": 2.87420667898222,
      "grad_norm": 2.850198268890381,
      "learning_rate": 8.619045098454372e-05,
      "loss": 0.4336,
      "step": 271500
    },
    {
      "epoch": 2.8752653225422264,
      "grad_norm": 2.4977686405181885,
      "learning_rate": 8.622189286470463e-05,
      "loss": 0.4314,
      "step": 271600
    },
    {
      "epoch": 2.876323966102233,
      "grad_norm": 2.5955357551574707,
      "learning_rate": 8.625365233961465e-05,
      "loss": 0.4312,
      "step": 271700
    },
    {
      "epoch": 2.8773826096622397,
      "grad_norm": 2.47023344039917,
      "learning_rate": 8.628541181452467e-05,
      "loss": 0.4291,
      "step": 271800
    },
    {
      "epoch": 2.8784412532222463,
      "grad_norm": 2.950734853744507,
      "learning_rate": 8.631717128943468e-05,
      "loss": 0.4313,
      "step": 271900
    },
    {
      "epoch": 2.879499896782253,
      "grad_norm": 2.817875385284424,
      "learning_rate": 8.634893076434469e-05,
      "loss": 0.4294,
      "step": 272000
    },
    {
      "epoch": 2.879499896782253,
      "eval_loss": 0.3242362141609192,
      "eval_runtime": 57.1632,
      "eval_samples_per_second": 2937.731,
      "eval_steps_per_second": 367.229,
      "step": 272000
    },
    {
      "epoch": 2.8805585403422596,
      "grad_norm": 2.494194269180298,
      "learning_rate": 8.63806902392547e-05,
      "loss": 0.4326,
      "step": 272100
    },
    {
      "epoch": 2.881617183902266,
      "grad_norm": 2.5949809551239014,
      "learning_rate": 8.641244971416472e-05,
      "loss": 0.4335,
      "step": 272200
    },
    {
      "epoch": 2.882675827462273,
      "grad_norm": 2.6301870346069336,
      "learning_rate": 8.644389159432563e-05,
      "loss": 0.434,
      "step": 272300
    },
    {
      "epoch": 2.8837344710222794,
      "grad_norm": 2.5720059871673584,
      "learning_rate": 8.647565106923565e-05,
      "loss": 0.4306,
      "step": 272400
    },
    {
      "epoch": 2.8847931145822856,
      "grad_norm": 2.64355731010437,
      "learning_rate": 8.650741054414567e-05,
      "loss": 0.4331,
      "step": 272500
    },
    {
      "epoch": 2.8858517581422922,
      "grad_norm": 2.7664644718170166,
      "learning_rate": 8.653917001905568e-05,
      "loss": 0.4314,
      "step": 272600
    },
    {
      "epoch": 2.886910401702299,
      "grad_norm": 2.8143694400787354,
      "learning_rate": 8.65709294939657e-05,
      "loss": 0.4304,
      "step": 272700
    },
    {
      "epoch": 2.8879690452623055,
      "grad_norm": 2.748375177383423,
      "learning_rate": 8.66026889688757e-05,
      "loss": 0.4355,
      "step": 272800
    },
    {
      "epoch": 2.889027688822312,
      "grad_norm": 2.812946319580078,
      "learning_rate": 8.663444844378572e-05,
      "loss": 0.4367,
      "step": 272900
    },
    {
      "epoch": 2.8900863323823183,
      "grad_norm": 2.437575578689575,
      "learning_rate": 8.666620791869574e-05,
      "loss": 0.4367,
      "step": 273000
    },
    {
      "epoch": 2.8900863323823183,
      "eval_loss": 0.3222571313381195,
      "eval_runtime": 57.3631,
      "eval_samples_per_second": 2927.491,
      "eval_steps_per_second": 365.949,
      "step": 273000
    },
    {
      "epoch": 2.891144975942325,
      "grad_norm": 2.550011396408081,
      "learning_rate": 8.669796739360576e-05,
      "loss": 0.4288,
      "step": 273100
    },
    {
      "epoch": 2.8922036195023315,
      "grad_norm": 2.865290641784668,
      "learning_rate": 8.672972686851576e-05,
      "loss": 0.4331,
      "step": 273200
    },
    {
      "epoch": 2.893262263062338,
      "grad_norm": 2.821272134780884,
      "learning_rate": 8.676148634342578e-05,
      "loss": 0.4329,
      "step": 273300
    },
    {
      "epoch": 2.8943209066223448,
      "grad_norm": 2.537937879562378,
      "learning_rate": 8.67932458183358e-05,
      "loss": 0.4314,
      "step": 273400
    },
    {
      "epoch": 2.8953795501823514,
      "grad_norm": 2.2596347332000732,
      "learning_rate": 8.682500529324582e-05,
      "loss": 0.431,
      "step": 273500
    },
    {
      "epoch": 2.896438193742358,
      "grad_norm": 2.65604567527771,
      "learning_rate": 8.685676476815582e-05,
      "loss": 0.4337,
      "step": 273600
    },
    {
      "epoch": 2.8974968373023646,
      "grad_norm": 2.449086904525757,
      "learning_rate": 8.688852424306584e-05,
      "loss": 0.4306,
      "step": 273700
    },
    {
      "epoch": 2.8985554808623712,
      "grad_norm": 2.9520461559295654,
      "learning_rate": 8.692028371797586e-05,
      "loss": 0.4305,
      "step": 273800
    },
    {
      "epoch": 2.899614124422378,
      "grad_norm": 2.609898805618286,
      "learning_rate": 8.695204319288588e-05,
      "loss": 0.4313,
      "step": 273900
    },
    {
      "epoch": 2.900672767982384,
      "grad_norm": 2.4685513973236084,
      "learning_rate": 8.69838026677959e-05,
      "loss": 0.4292,
      "step": 274000
    },
    {
      "epoch": 2.900672767982384,
      "eval_loss": 0.3223724067211151,
      "eval_runtime": 57.2719,
      "eval_samples_per_second": 2932.152,
      "eval_steps_per_second": 366.532,
      "step": 274000
    },
    {
      "epoch": 2.9017314115423907,
      "grad_norm": 2.9813408851623535,
      "learning_rate": 8.70155621427059e-05,
      "loss": 0.4344,
      "step": 274100
    },
    {
      "epoch": 2.9027900551023973,
      "grad_norm": 2.6315057277679443,
      "learning_rate": 8.704732161761592e-05,
      "loss": 0.4379,
      "step": 274200
    },
    {
      "epoch": 2.903848698662404,
      "grad_norm": 2.4567503929138184,
      "learning_rate": 8.707876349777684e-05,
      "loss": 0.4292,
      "step": 274300
    },
    {
      "epoch": 2.9049073422224105,
      "grad_norm": 2.913239002227783,
      "learning_rate": 8.711052297268684e-05,
      "loss": 0.4318,
      "step": 274400
    },
    {
      "epoch": 2.9059659857824167,
      "grad_norm": 2.804574966430664,
      "learning_rate": 8.714228244759686e-05,
      "loss": 0.4279,
      "step": 274500
    },
    {
      "epoch": 2.9070246293424233,
      "grad_norm": 2.70063853263855,
      "learning_rate": 8.717404192250688e-05,
      "loss": 0.4279,
      "step": 274600
    },
    {
      "epoch": 2.90808327290243,
      "grad_norm": 2.715625286102295,
      "learning_rate": 8.72058013974169e-05,
      "loss": 0.427,
      "step": 274700
    },
    {
      "epoch": 2.9091419164624366,
      "grad_norm": 2.6991162300109863,
      "learning_rate": 8.72375608723269e-05,
      "loss": 0.4265,
      "step": 274800
    },
    {
      "epoch": 2.910200560022443,
      "grad_norm": 2.9402997493743896,
      "learning_rate": 8.726932034723692e-05,
      "loss": 0.4347,
      "step": 274900
    },
    {
      "epoch": 2.91125920358245,
      "grad_norm": 2.5824663639068604,
      "learning_rate": 8.730107982214694e-05,
      "loss": 0.4353,
      "step": 275000
    },
    {
      "epoch": 2.91125920358245,
      "eval_loss": 0.3211187720298767,
      "eval_runtime": 57.2165,
      "eval_samples_per_second": 2934.994,
      "eval_steps_per_second": 366.887,
      "step": 275000
    },
    {
      "epoch": 2.9123178471424565,
      "grad_norm": 2.9869914054870605,
      "learning_rate": 8.733283929705695e-05,
      "loss": 0.4321,
      "step": 275100
    },
    {
      "epoch": 2.913376490702463,
      "grad_norm": 2.6095993518829346,
      "learning_rate": 8.736459877196697e-05,
      "loss": 0.4311,
      "step": 275200
    },
    {
      "epoch": 2.9144351342624697,
      "grad_norm": 2.6343531608581543,
      "learning_rate": 8.739635824687698e-05,
      "loss": 0.4292,
      "step": 275300
    },
    {
      "epoch": 2.9154937778224763,
      "grad_norm": 2.555185556411743,
      "learning_rate": 8.7428117721787e-05,
      "loss": 0.426,
      "step": 275400
    },
    {
      "epoch": 2.9165524213824825,
      "grad_norm": 2.7640626430511475,
      "learning_rate": 8.745987719669701e-05,
      "loss": 0.4282,
      "step": 275500
    },
    {
      "epoch": 2.917611064942489,
      "grad_norm": 2.4458370208740234,
      "learning_rate": 8.749163667160703e-05,
      "loss": 0.4305,
      "step": 275600
    },
    {
      "epoch": 2.9186697085024957,
      "grad_norm": 2.612978458404541,
      "learning_rate": 8.752339614651703e-05,
      "loss": 0.4251,
      "step": 275700
    },
    {
      "epoch": 2.9197283520625024,
      "grad_norm": 2.8407280445098877,
      "learning_rate": 8.755515562142705e-05,
      "loss": 0.4266,
      "step": 275800
    },
    {
      "epoch": 2.920786995622509,
      "grad_norm": 2.394233226776123,
      "learning_rate": 8.758691509633707e-05,
      "loss": 0.4251,
      "step": 275900
    },
    {
      "epoch": 2.9218456391825156,
      "grad_norm": 2.8107423782348633,
      "learning_rate": 8.761867457124709e-05,
      "loss": 0.4315,
      "step": 276000
    },
    {
      "epoch": 2.9218456391825156,
      "eval_loss": 0.32293501496315,
      "eval_runtime": 57.2666,
      "eval_samples_per_second": 2932.424,
      "eval_steps_per_second": 366.566,
      "step": 276000
    },
    {
      "epoch": 2.922904282742522,
      "grad_norm": 2.871047258377075,
      "learning_rate": 8.765043404615709e-05,
      "loss": 0.4274,
      "step": 276100
    },
    {
      "epoch": 2.9239629263025284,
      "grad_norm": 2.668429136276245,
      "learning_rate": 8.768219352106711e-05,
      "loss": 0.4302,
      "step": 276200
    },
    {
      "epoch": 2.925021569862535,
      "grad_norm": 2.8241007328033447,
      "learning_rate": 8.771395299597713e-05,
      "loss": 0.4283,
      "step": 276300
    },
    {
      "epoch": 2.9260802134225417,
      "grad_norm": 2.3552451133728027,
      "learning_rate": 8.774571247088715e-05,
      "loss": 0.4239,
      "step": 276400
    },
    {
      "epoch": 2.9271388569825483,
      "grad_norm": 2.716597318649292,
      "learning_rate": 8.777747194579715e-05,
      "loss": 0.4314,
      "step": 276500
    },
    {
      "epoch": 2.928197500542555,
      "grad_norm": 2.8153908252716064,
      "learning_rate": 8.780923142070717e-05,
      "loss": 0.4317,
      "step": 276600
    },
    {
      "epoch": 2.9292561441025615,
      "grad_norm": 2.7609055042266846,
      "learning_rate": 8.784099089561719e-05,
      "loss": 0.43,
      "step": 276700
    },
    {
      "epoch": 2.930314787662568,
      "grad_norm": 2.901327610015869,
      "learning_rate": 8.78727503705272e-05,
      "loss": 0.4289,
      "step": 276800
    },
    {
      "epoch": 2.9313734312225748,
      "grad_norm": 3.0607218742370605,
      "learning_rate": 8.790450984543722e-05,
      "loss": 0.4281,
      "step": 276900
    },
    {
      "epoch": 2.932432074782581,
      "grad_norm": 2.721337080001831,
      "learning_rate": 8.793626932034723e-05,
      "loss": 0.4267,
      "step": 277000
    },
    {
      "epoch": 2.932432074782581,
      "eval_loss": 0.3232816159725189,
      "eval_runtime": 57.3173,
      "eval_samples_per_second": 2929.831,
      "eval_steps_per_second": 366.242,
      "step": 277000
    },
    {
      "epoch": 2.9334907183425876,
      "grad_norm": 2.7171311378479004,
      "learning_rate": 8.796802879525724e-05,
      "loss": 0.4238,
      "step": 277100
    },
    {
      "epoch": 2.934549361902594,
      "grad_norm": 2.591686964035034,
      "learning_rate": 8.799978827016726e-05,
      "loss": 0.4302,
      "step": 277200
    },
    {
      "epoch": 2.935608005462601,
      "grad_norm": 2.4666991233825684,
      "learning_rate": 8.803154774507728e-05,
      "loss": 0.4307,
      "step": 277300
    },
    {
      "epoch": 2.9366666490226074,
      "grad_norm": 2.9187958240509033,
      "learning_rate": 8.806330721998728e-05,
      "loss": 0.4275,
      "step": 277400
    },
    {
      "epoch": 2.937725292582614,
      "grad_norm": 2.6964004039764404,
      "learning_rate": 8.80950666948973e-05,
      "loss": 0.4247,
      "step": 277500
    },
    {
      "epoch": 2.9387839361426202,
      "grad_norm": 2.4488632678985596,
      "learning_rate": 8.812650857505822e-05,
      "loss": 0.4274,
      "step": 277600
    },
    {
      "epoch": 2.939842579702627,
      "grad_norm": 2.723672389984131,
      "learning_rate": 8.815826804996823e-05,
      "loss": 0.4284,
      "step": 277700
    },
    {
      "epoch": 2.9409012232626335,
      "grad_norm": 2.569554328918457,
      "learning_rate": 8.819002752487824e-05,
      "loss": 0.434,
      "step": 277800
    },
    {
      "epoch": 2.94195986682264,
      "grad_norm": 2.1583492755889893,
      "learning_rate": 8.822178699978826e-05,
      "loss": 0.4293,
      "step": 277900
    },
    {
      "epoch": 2.9430185103826467,
      "grad_norm": 2.802957057952881,
      "learning_rate": 8.825354647469828e-05,
      "loss": 0.4306,
      "step": 278000
    },
    {
      "epoch": 2.9430185103826467,
      "eval_loss": 0.3230179250240326,
      "eval_runtime": 57.2331,
      "eval_samples_per_second": 2934.14,
      "eval_steps_per_second": 366.781,
      "step": 278000
    },
    {
      "epoch": 2.9440771539426533,
      "grad_norm": 2.4030072689056396,
      "learning_rate": 8.82853059496083e-05,
      "loss": 0.4305,
      "step": 278100
    },
    {
      "epoch": 2.94513579750266,
      "grad_norm": 2.6307787895202637,
      "learning_rate": 8.83170654245183e-05,
      "loss": 0.4299,
      "step": 278200
    },
    {
      "epoch": 2.9461944410626666,
      "grad_norm": 2.3788132667541504,
      "learning_rate": 8.834882489942832e-05,
      "loss": 0.4229,
      "step": 278300
    },
    {
      "epoch": 2.947253084622673,
      "grad_norm": 2.6944613456726074,
      "learning_rate": 8.838058437433834e-05,
      "loss": 0.4304,
      "step": 278400
    },
    {
      "epoch": 2.9483117281826794,
      "grad_norm": 2.502307415008545,
      "learning_rate": 8.841234384924836e-05,
      "loss": 0.4268,
      "step": 278500
    },
    {
      "epoch": 2.949370371742686,
      "grad_norm": 2.5113086700439453,
      "learning_rate": 8.844410332415836e-05,
      "loss": 0.4247,
      "step": 278600
    },
    {
      "epoch": 2.9504290153026926,
      "grad_norm": 2.419039487838745,
      "learning_rate": 8.847586279906838e-05,
      "loss": 0.4275,
      "step": 278700
    },
    {
      "epoch": 2.9514876588626993,
      "grad_norm": 2.1236422061920166,
      "learning_rate": 8.85076222739784e-05,
      "loss": 0.4292,
      "step": 278800
    },
    {
      "epoch": 2.952546302422706,
      "grad_norm": 2.617508888244629,
      "learning_rate": 8.853938174888841e-05,
      "loss": 0.4266,
      "step": 278900
    },
    {
      "epoch": 2.9536049459827125,
      "grad_norm": 2.8342418670654297,
      "learning_rate": 8.857114122379842e-05,
      "loss": 0.4301,
      "step": 279000
    },
    {
      "epoch": 2.9536049459827125,
      "eval_loss": 0.3212231993675232,
      "eval_runtime": 57.2472,
      "eval_samples_per_second": 2933.418,
      "eval_steps_per_second": 366.69,
      "step": 279000
    },
    {
      "epoch": 2.9546635895427187,
      "grad_norm": 2.510197401046753,
      "learning_rate": 8.860290069870844e-05,
      "loss": 0.4273,
      "step": 279100
    },
    {
      "epoch": 2.9557222331027253,
      "grad_norm": 2.669066905975342,
      "learning_rate": 8.863466017361845e-05,
      "loss": 0.4239,
      "step": 279200
    },
    {
      "epoch": 2.956780876662732,
      "grad_norm": 2.5638880729675293,
      "learning_rate": 8.866641964852847e-05,
      "loss": 0.4294,
      "step": 279300
    },
    {
      "epoch": 2.9578395202227385,
      "grad_norm": 2.776966094970703,
      "learning_rate": 8.869817912343849e-05,
      "loss": 0.4299,
      "step": 279400
    },
    {
      "epoch": 2.958898163782745,
      "grad_norm": 2.7380409240722656,
      "learning_rate": 8.87299385983485e-05,
      "loss": 0.4255,
      "step": 279500
    },
    {
      "epoch": 2.959956807342752,
      "grad_norm": 2.8345932960510254,
      "learning_rate": 8.876169807325851e-05,
      "loss": 0.4263,
      "step": 279600
    },
    {
      "epoch": 2.9610154509027584,
      "grad_norm": 2.507502555847168,
      "learning_rate": 8.879345754816853e-05,
      "loss": 0.4288,
      "step": 279700
    },
    {
      "epoch": 2.962074094462765,
      "grad_norm": 2.6085193157196045,
      "learning_rate": 8.882521702307855e-05,
      "loss": 0.4244,
      "step": 279800
    },
    {
      "epoch": 2.9631327380227717,
      "grad_norm": 2.799001693725586,
      "learning_rate": 8.885697649798855e-05,
      "loss": 0.4285,
      "step": 279900
    },
    {
      "epoch": 2.964191381582778,
      "grad_norm": 2.4622180461883545,
      "learning_rate": 8.888873597289857e-05,
      "loss": 0.4293,
      "step": 280000
    },
    {
      "epoch": 2.964191381582778,
      "eval_loss": 0.31930404901504517,
      "eval_runtime": 57.2559,
      "eval_samples_per_second": 2932.973,
      "eval_steps_per_second": 366.635,
      "step": 280000
    },
    {
      "epoch": 2.9652500251427845,
      "grad_norm": 2.71234393119812,
      "learning_rate": 8.892049544780859e-05,
      "loss": 0.4221,
      "step": 280100
    },
    {
      "epoch": 2.966308668702791,
      "grad_norm": 2.7077114582061768,
      "learning_rate": 8.895225492271861e-05,
      "loss": 0.4267,
      "step": 280200
    },
    {
      "epoch": 2.9673673122627977,
      "grad_norm": 2.313798666000366,
      "learning_rate": 8.898401439762861e-05,
      "loss": 0.4241,
      "step": 280300
    },
    {
      "epoch": 2.9684259558228043,
      "grad_norm": 2.6385345458984375,
      "learning_rate": 8.901545627778953e-05,
      "loss": 0.4247,
      "step": 280400
    },
    {
      "epoch": 2.969484599382811,
      "grad_norm": 2.8429312705993652,
      "learning_rate": 8.904721575269955e-05,
      "loss": 0.425,
      "step": 280500
    },
    {
      "epoch": 2.970543242942817,
      "grad_norm": 2.4152352809906006,
      "learning_rate": 8.907897522760957e-05,
      "loss": 0.4301,
      "step": 280600
    },
    {
      "epoch": 2.9716018865028238,
      "grad_norm": 2.3250319957733154,
      "learning_rate": 8.911073470251957e-05,
      "loss": 0.4266,
      "step": 280700
    },
    {
      "epoch": 2.9726605300628304,
      "grad_norm": 2.883357048034668,
      "learning_rate": 8.914249417742959e-05,
      "loss": 0.4243,
      "step": 280800
    },
    {
      "epoch": 2.973719173622837,
      "grad_norm": 2.6324939727783203,
      "learning_rate": 8.917425365233961e-05,
      "loss": 0.422,
      "step": 280900
    },
    {
      "epoch": 2.9747778171828436,
      "grad_norm": 2.5049471855163574,
      "learning_rate": 8.920601312724963e-05,
      "loss": 0.423,
      "step": 281000
    },
    {
      "epoch": 2.9747778171828436,
      "eval_loss": 0.3209497928619385,
      "eval_runtime": 57.3169,
      "eval_samples_per_second": 2929.852,
      "eval_steps_per_second": 366.245,
      "step": 281000
    },
    {
      "epoch": 2.9758364607428502,
      "grad_norm": 2.3679659366607666,
      "learning_rate": 8.923777260215963e-05,
      "loss": 0.4277,
      "step": 281100
    },
    {
      "epoch": 2.976895104302857,
      "grad_norm": 2.212890625,
      "learning_rate": 8.926953207706965e-05,
      "loss": 0.4283,
      "step": 281200
    },
    {
      "epoch": 2.9779537478628635,
      "grad_norm": 2.6414170265197754,
      "learning_rate": 8.930129155197967e-05,
      "loss": 0.4231,
      "step": 281300
    },
    {
      "epoch": 2.97901239142287,
      "grad_norm": 2.9414055347442627,
      "learning_rate": 8.933305102688968e-05,
      "loss": 0.4242,
      "step": 281400
    },
    {
      "epoch": 2.9800710349828763,
      "grad_norm": 2.363525152206421,
      "learning_rate": 8.936481050179969e-05,
      "loss": 0.4289,
      "step": 281500
    },
    {
      "epoch": 2.981129678542883,
      "grad_norm": 2.29137921333313,
      "learning_rate": 8.93965699767097e-05,
      "loss": 0.4289,
      "step": 281600
    },
    {
      "epoch": 2.9821883221028895,
      "grad_norm": 2.5770034790039062,
      "learning_rate": 8.942832945161972e-05,
      "loss": 0.424,
      "step": 281700
    },
    {
      "epoch": 2.983246965662896,
      "grad_norm": 2.6006133556365967,
      "learning_rate": 8.946008892652974e-05,
      "loss": 0.4273,
      "step": 281800
    },
    {
      "epoch": 2.9843056092229028,
      "grad_norm": 2.7366671562194824,
      "learning_rate": 8.949184840143975e-05,
      "loss": 0.4247,
      "step": 281900
    },
    {
      "epoch": 2.9853642527829094,
      "grad_norm": 2.662283182144165,
      "learning_rate": 8.952360787634976e-05,
      "loss": 0.4284,
      "step": 282000
    },
    {
      "epoch": 2.9853642527829094,
      "eval_loss": 0.31944313645362854,
      "eval_runtime": 57.2539,
      "eval_samples_per_second": 2933.074,
      "eval_steps_per_second": 366.647,
      "step": 282000
    },
    {
      "epoch": 2.9864228963429156,
      "grad_norm": 2.7837231159210205,
      "learning_rate": 8.955536735125978e-05,
      "loss": 0.4259,
      "step": 282100
    },
    {
      "epoch": 2.987481539902922,
      "grad_norm": 2.9088354110717773,
      "learning_rate": 8.95871268261698e-05,
      "loss": 0.4286,
      "step": 282200
    },
    {
      "epoch": 2.988540183462929,
      "grad_norm": 2.405463457107544,
      "learning_rate": 8.961888630107982e-05,
      "loss": 0.4256,
      "step": 282300
    },
    {
      "epoch": 2.9895988270229354,
      "grad_norm": 2.699758529663086,
      "learning_rate": 8.965064577598982e-05,
      "loss": 0.428,
      "step": 282400
    },
    {
      "epoch": 2.990657470582942,
      "grad_norm": 2.687814474105835,
      "learning_rate": 8.968240525089984e-05,
      "loss": 0.4192,
      "step": 282500
    },
    {
      "epoch": 2.9917161141429487,
      "grad_norm": 2.5267837047576904,
      "learning_rate": 8.971416472580986e-05,
      "loss": 0.4296,
      "step": 282600
    },
    {
      "epoch": 2.9927747577029553,
      "grad_norm": 2.534341335296631,
      "learning_rate": 8.974592420071988e-05,
      "loss": 0.4274,
      "step": 282700
    },
    {
      "epoch": 2.993833401262962,
      "grad_norm": 2.474148988723755,
      "learning_rate": 8.977768367562988e-05,
      "loss": 0.4202,
      "step": 282800
    },
    {
      "epoch": 2.9948920448229686,
      "grad_norm": 2.4798362255096436,
      "learning_rate": 8.98094431505399e-05,
      "loss": 0.422,
      "step": 282900
    },
    {
      "epoch": 2.9959506883829747,
      "grad_norm": 2.5980939865112305,
      "learning_rate": 8.984120262544992e-05,
      "loss": 0.4276,
      "step": 283000
    },
    {
      "epoch": 2.9959506883829747,
      "eval_loss": 0.31948375701904297,
      "eval_runtime": 57.3815,
      "eval_samples_per_second": 2926.552,
      "eval_steps_per_second": 365.832,
      "step": 283000
    },
    {
      "epoch": 2.9970093319429814,
      "grad_norm": 2.5192747116088867,
      "learning_rate": 8.987296210035993e-05,
      "loss": 0.4248,
      "step": 283100
    },
    {
      "epoch": 2.998067975502988,
      "grad_norm": 2.4156246185302734,
      "learning_rate": 8.990472157526994e-05,
      "loss": 0.4217,
      "step": 283200
    },
    {
      "epoch": 2.9991266190629946,
      "grad_norm": 2.6840150356292725,
      "learning_rate": 8.993648105017996e-05,
      "loss": 0.4261,
      "step": 283300
    },
    {
      "epoch": 3.000179969405201,
      "grad_norm": 2.7304165363311768,
      "learning_rate": 8.996824052508997e-05,
      "loss": 0.4288,
      "step": 283400
    },
    {
      "epoch": 3.0012386129652078,
      "grad_norm": 2.2577295303344727,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.4222,
      "step": 283500
    },
    {
      "epoch": 3.0022972565252144,
      "grad_norm": 2.5813002586364746,
      "learning_rate": 9.003175947491001e-05,
      "loss": 0.4149,
      "step": 283600
    },
    {
      "epoch": 3.003355900085221,
      "grad_norm": 2.461451530456543,
      "learning_rate": 9.006351894982001e-05,
      "loss": 0.425,
      "step": 283700
    },
    {
      "epoch": 3.004414543645227,
      "grad_norm": 2.5703611373901367,
      "learning_rate": 9.009527842473003e-05,
      "loss": 0.4139,
      "step": 283800
    },
    {
      "epoch": 3.005473187205234,
      "grad_norm": 2.4221765995025635,
      "learning_rate": 9.012672030489095e-05,
      "loss": 0.4189,
      "step": 283900
    },
    {
      "epoch": 3.0065318307652404,
      "grad_norm": 2.4708287715911865,
      "learning_rate": 9.015847977980096e-05,
      "loss": 0.4186,
      "step": 284000
    },
    {
      "epoch": 3.0065318307652404,
      "eval_loss": 0.31818050146102905,
      "eval_runtime": 57.331,
      "eval_samples_per_second": 2929.131,
      "eval_steps_per_second": 366.154,
      "step": 284000
    },
    {
      "epoch": 3.007590474325247,
      "grad_norm": 2.6048104763031006,
      "learning_rate": 9.019023925471098e-05,
      "loss": 0.4202,
      "step": 284100
    },
    {
      "epoch": 3.0086491178852537,
      "grad_norm": 2.55489182472229,
      "learning_rate": 9.022199872962099e-05,
      "loss": 0.4211,
      "step": 284200
    },
    {
      "epoch": 3.0097077614452603,
      "grad_norm": 2.942415952682495,
      "learning_rate": 9.025375820453101e-05,
      "loss": 0.4258,
      "step": 284300
    },
    {
      "epoch": 3.010766405005267,
      "grad_norm": 2.3583109378814697,
      "learning_rate": 9.028551767944102e-05,
      "loss": 0.4221,
      "step": 284400
    },
    {
      "epoch": 3.011825048565273,
      "grad_norm": 2.485963821411133,
      "learning_rate": 9.031727715435103e-05,
      "loss": 0.4166,
      "step": 284500
    },
    {
      "epoch": 3.0128836921252797,
      "grad_norm": 2.5140910148620605,
      "learning_rate": 9.034903662926105e-05,
      "loss": 0.4209,
      "step": 284600
    },
    {
      "epoch": 3.0139423356852864,
      "grad_norm": 2.27400279045105,
      "learning_rate": 9.038079610417107e-05,
      "loss": 0.4171,
      "step": 284700
    },
    {
      "epoch": 3.015000979245293,
      "grad_norm": 2.578815460205078,
      "learning_rate": 9.041255557908109e-05,
      "loss": 0.4199,
      "step": 284800
    },
    {
      "epoch": 3.0160596228052996,
      "grad_norm": 2.436152696609497,
      "learning_rate": 9.044431505399109e-05,
      "loss": 0.4152,
      "step": 284900
    },
    {
      "epoch": 3.0171182663653062,
      "grad_norm": 2.4805643558502197,
      "learning_rate": 9.047607452890111e-05,
      "loss": 0.4203,
      "step": 285000
    },
    {
      "epoch": 3.0171182663653062,
      "eval_loss": 0.3172187805175781,
      "eval_runtime": 57.2489,
      "eval_samples_per_second": 2933.332,
      "eval_steps_per_second": 366.68,
      "step": 285000
    },
    {
      "epoch": 3.018176909925313,
      "grad_norm": 2.658379316329956,
      "learning_rate": 9.050783400381113e-05,
      "loss": 0.4205,
      "step": 285100
    },
    {
      "epoch": 3.0192355534853195,
      "grad_norm": 2.535491466522217,
      "learning_rate": 9.053959347872115e-05,
      "loss": 0.4224,
      "step": 285200
    },
    {
      "epoch": 3.0202941970453256,
      "grad_norm": 2.5793981552124023,
      "learning_rate": 9.057135295363115e-05,
      "loss": 0.415,
      "step": 285300
    },
    {
      "epoch": 3.0213528406053323,
      "grad_norm": 2.394461154937744,
      "learning_rate": 9.060311242854117e-05,
      "loss": 0.4173,
      "step": 285400
    },
    {
      "epoch": 3.022411484165339,
      "grad_norm": 2.6804392337799072,
      "learning_rate": 9.063487190345119e-05,
      "loss": 0.4187,
      "step": 285500
    },
    {
      "epoch": 3.0234701277253455,
      "grad_norm": 2.274200439453125,
      "learning_rate": 9.06666313783612e-05,
      "loss": 0.4185,
      "step": 285600
    },
    {
      "epoch": 3.024528771285352,
      "grad_norm": 2.4866459369659424,
      "learning_rate": 9.069839085327121e-05,
      "loss": 0.4212,
      "step": 285700
    },
    {
      "epoch": 3.0255874148453588,
      "grad_norm": 2.3857107162475586,
      "learning_rate": 9.073015032818123e-05,
      "loss": 0.4191,
      "step": 285800
    },
    {
      "epoch": 3.0266460584053654,
      "grad_norm": 2.4819016456604004,
      "learning_rate": 9.076190980309124e-05,
      "loss": 0.4165,
      "step": 285900
    },
    {
      "epoch": 3.0277047019653716,
      "grad_norm": 2.5885744094848633,
      "learning_rate": 9.079366927800126e-05,
      "loss": 0.4157,
      "step": 286000
    },
    {
      "epoch": 3.0277047019653716,
      "eval_loss": 0.31827548146247864,
      "eval_runtime": 57.4422,
      "eval_samples_per_second": 2923.459,
      "eval_steps_per_second": 365.445,
      "step": 286000
    },
    {
      "epoch": 3.028763345525378,
      "grad_norm": 2.787726879119873,
      "learning_rate": 9.082542875291127e-05,
      "loss": 0.4198,
      "step": 286100
    },
    {
      "epoch": 3.029821989085385,
      "grad_norm": 2.363279342651367,
      "learning_rate": 9.085718822782128e-05,
      "loss": 0.4177,
      "step": 286200
    },
    {
      "epoch": 3.0308806326453914,
      "grad_norm": 2.3002400398254395,
      "learning_rate": 9.08889477027313e-05,
      "loss": 0.412,
      "step": 286300
    },
    {
      "epoch": 3.031939276205398,
      "grad_norm": 2.5255043506622314,
      "learning_rate": 9.092070717764132e-05,
      "loss": 0.4181,
      "step": 286400
    },
    {
      "epoch": 3.0329979197654047,
      "grad_norm": 2.4829299449920654,
      "learning_rate": 9.095246665255134e-05,
      "loss": 0.4226,
      "step": 286500
    },
    {
      "epoch": 3.0340565633254113,
      "grad_norm": 2.3595330715179443,
      "learning_rate": 9.098422612746134e-05,
      "loss": 0.4163,
      "step": 286600
    },
    {
      "epoch": 3.035115206885418,
      "grad_norm": 2.6380770206451416,
      "learning_rate": 9.101598560237136e-05,
      "loss": 0.4215,
      "step": 286700
    },
    {
      "epoch": 3.036173850445424,
      "grad_norm": 2.446969747543335,
      "learning_rate": 9.104774507728138e-05,
      "loss": 0.4244,
      "step": 286800
    },
    {
      "epoch": 3.0372324940054307,
      "grad_norm": 2.677821159362793,
      "learning_rate": 9.10795045521914e-05,
      "loss": 0.4153,
      "step": 286900
    },
    {
      "epoch": 3.0382911375654373,
      "grad_norm": 2.462738275527954,
      "learning_rate": 9.11112640271014e-05,
      "loss": 0.4189,
      "step": 287000
    },
    {
      "epoch": 3.0382911375654373,
      "eval_loss": 0.3178666830062866,
      "eval_runtime": 57.2703,
      "eval_samples_per_second": 2932.238,
      "eval_steps_per_second": 366.543,
      "step": 287000
    },
    {
      "epoch": 3.039349781125444,
      "grad_norm": 2.413778305053711,
      "learning_rate": 9.114302350201142e-05,
      "loss": 0.4112,
      "step": 287100
    },
    {
      "epoch": 3.0404084246854506,
      "grad_norm": 2.505953311920166,
      "learning_rate": 9.117478297692144e-05,
      "loss": 0.4192,
      "step": 287200
    },
    {
      "epoch": 3.041467068245457,
      "grad_norm": 2.3519132137298584,
      "learning_rate": 9.120654245183145e-05,
      "loss": 0.4211,
      "step": 287300
    },
    {
      "epoch": 3.042525711805464,
      "grad_norm": 2.373383045196533,
      "learning_rate": 9.123830192674146e-05,
      "loss": 0.4217,
      "step": 287400
    },
    {
      "epoch": 3.04358435536547,
      "grad_norm": 2.5663414001464844,
      "learning_rate": 9.127006140165148e-05,
      "loss": 0.4183,
      "step": 287500
    },
    {
      "epoch": 3.0446429989254766,
      "grad_norm": 2.427685260772705,
      "learning_rate": 9.13018208765615e-05,
      "loss": 0.4235,
      "step": 287600
    },
    {
      "epoch": 3.0457016424854833,
      "grad_norm": 2.553175449371338,
      "learning_rate": 9.133358035147151e-05,
      "loss": 0.4177,
      "step": 287700
    },
    {
      "epoch": 3.04676028604549,
      "grad_norm": 2.601383924484253,
      "learning_rate": 9.136533982638153e-05,
      "loss": 0.4225,
      "step": 287800
    },
    {
      "epoch": 3.0478189296054965,
      "grad_norm": 2.6464381217956543,
      "learning_rate": 9.139678170654244e-05,
      "loss": 0.4218,
      "step": 287900
    },
    {
      "epoch": 3.048877573165503,
      "grad_norm": 2.800699472427368,
      "learning_rate": 9.142854118145245e-05,
      "loss": 0.4211,
      "step": 288000
    },
    {
      "epoch": 3.048877573165503,
      "eval_loss": 0.3172532618045807,
      "eval_runtime": 57.1835,
      "eval_samples_per_second": 2936.688,
      "eval_steps_per_second": 367.099,
      "step": 288000
    },
    {
      "epoch": 3.0499362167255097,
      "grad_norm": 2.672015428543091,
      "learning_rate": 9.146030065636247e-05,
      "loss": 0.4162,
      "step": 288100
    },
    {
      "epoch": 3.0509948602855164,
      "grad_norm": 2.6082451343536377,
      "learning_rate": 9.149206013127248e-05,
      "loss": 0.4232,
      "step": 288200
    },
    {
      "epoch": 3.0520535038455225,
      "grad_norm": 2.3665692806243896,
      "learning_rate": 9.15238196061825e-05,
      "loss": 0.4198,
      "step": 288300
    },
    {
      "epoch": 3.053112147405529,
      "grad_norm": 2.4170985221862793,
      "learning_rate": 9.155557908109251e-05,
      "loss": 0.4185,
      "step": 288400
    },
    {
      "epoch": 3.054170790965536,
      "grad_norm": 2.4468483924865723,
      "learning_rate": 9.158733855600253e-05,
      "loss": 0.4149,
      "step": 288500
    },
    {
      "epoch": 3.0552294345255424,
      "grad_norm": 2.666293144226074,
      "learning_rate": 9.161909803091253e-05,
      "loss": 0.4136,
      "step": 288600
    },
    {
      "epoch": 3.056288078085549,
      "grad_norm": 2.775350332260132,
      "learning_rate": 9.165085750582255e-05,
      "loss": 0.4214,
      "step": 288700
    },
    {
      "epoch": 3.0573467216455557,
      "grad_norm": 2.491189479827881,
      "learning_rate": 9.168261698073257e-05,
      "loss": 0.4177,
      "step": 288800
    },
    {
      "epoch": 3.0584053652055623,
      "grad_norm": 2.755105495452881,
      "learning_rate": 9.171437645564259e-05,
      "loss": 0.4168,
      "step": 288900
    },
    {
      "epoch": 3.059464008765569,
      "grad_norm": 2.5402445793151855,
      "learning_rate": 9.17461359305526e-05,
      "loss": 0.418,
      "step": 289000
    },
    {
      "epoch": 3.059464008765569,
      "eval_loss": 0.3171740174293518,
      "eval_runtime": 57.2207,
      "eval_samples_per_second": 2934.776,
      "eval_steps_per_second": 366.86,
      "step": 289000
    },
    {
      "epoch": 3.060522652325575,
      "grad_norm": 2.7521400451660156,
      "learning_rate": 9.177789540546261e-05,
      "loss": 0.4134,
      "step": 289100
    },
    {
      "epoch": 3.0615812958855817,
      "grad_norm": 2.5053653717041016,
      "learning_rate": 9.180965488037263e-05,
      "loss": 0.4228,
      "step": 289200
    },
    {
      "epoch": 3.0626399394455883,
      "grad_norm": 2.820408344268799,
      "learning_rate": 9.184141435528265e-05,
      "loss": 0.4136,
      "step": 289300
    },
    {
      "epoch": 3.063698583005595,
      "grad_norm": 2.5163919925689697,
      "learning_rate": 9.187317383019266e-05,
      "loss": 0.4151,
      "step": 289400
    },
    {
      "epoch": 3.0647572265656016,
      "grad_norm": 2.8687546253204346,
      "learning_rate": 9.190493330510267e-05,
      "loss": 0.4156,
      "step": 289500
    },
    {
      "epoch": 3.065815870125608,
      "grad_norm": 2.4396796226501465,
      "learning_rate": 9.193669278001269e-05,
      "loss": 0.4213,
      "step": 289600
    },
    {
      "epoch": 3.066874513685615,
      "grad_norm": 2.33025860786438,
      "learning_rate": 9.19684522549227e-05,
      "loss": 0.4174,
      "step": 289700
    },
    {
      "epoch": 3.067933157245621,
      "grad_norm": 2.3829944133758545,
      "learning_rate": 9.200021172983272e-05,
      "loss": 0.4207,
      "step": 289800
    },
    {
      "epoch": 3.0689918008056276,
      "grad_norm": 2.4981696605682373,
      "learning_rate": 9.203165360999363e-05,
      "loss": 0.4161,
      "step": 289900
    },
    {
      "epoch": 3.0700504443656342,
      "grad_norm": 2.3571717739105225,
      "learning_rate": 9.206341308490365e-05,
      "loss": 0.4214,
      "step": 290000
    },
    {
      "epoch": 3.0700504443656342,
      "eval_loss": 0.316834419965744,
      "eval_runtime": 57.2837,
      "eval_samples_per_second": 2931.547,
      "eval_steps_per_second": 366.456,
      "step": 290000
    },
    {
      "epoch": 3.071109087925641,
      "grad_norm": 2.2902719974517822,
      "learning_rate": 9.209517255981367e-05,
      "loss": 0.4182,
      "step": 290100
    },
    {
      "epoch": 3.0721677314856475,
      "grad_norm": 2.716186761856079,
      "learning_rate": 9.212693203472368e-05,
      "loss": 0.4195,
      "step": 290200
    },
    {
      "epoch": 3.073226375045654,
      "grad_norm": 2.6419012546539307,
      "learning_rate": 9.215869150963369e-05,
      "loss": 0.4202,
      "step": 290300
    },
    {
      "epoch": 3.0742850186056607,
      "grad_norm": 2.2820253372192383,
      "learning_rate": 9.21904509845437e-05,
      "loss": 0.4225,
      "step": 290400
    },
    {
      "epoch": 3.0753436621656673,
      "grad_norm": 2.514862060546875,
      "learning_rate": 9.222221045945372e-05,
      "loss": 0.4172,
      "step": 290500
    },
    {
      "epoch": 3.0764023057256735,
      "grad_norm": 2.502495765686035,
      "learning_rate": 9.225396993436374e-05,
      "loss": 0.4187,
      "step": 290600
    },
    {
      "epoch": 3.07746094928568,
      "grad_norm": 2.5537164211273193,
      "learning_rate": 9.228572940927375e-05,
      "loss": 0.4189,
      "step": 290700
    },
    {
      "epoch": 3.0785195928456868,
      "grad_norm": 2.7029285430908203,
      "learning_rate": 9.231748888418376e-05,
      "loss": 0.4161,
      "step": 290800
    },
    {
      "epoch": 3.0795782364056934,
      "grad_norm": 2.4062588214874268,
      "learning_rate": 9.234924835909378e-05,
      "loss": 0.4192,
      "step": 290900
    },
    {
      "epoch": 3.0806368799657,
      "grad_norm": 2.344412088394165,
      "learning_rate": 9.23810078340038e-05,
      "loss": 0.4119,
      "step": 291000
    },
    {
      "epoch": 3.0806368799657,
      "eval_loss": 0.31782761216163635,
      "eval_runtime": 57.3058,
      "eval_samples_per_second": 2930.418,
      "eval_steps_per_second": 366.315,
      "step": 291000
    },
    {
      "epoch": 3.0816955235257066,
      "grad_norm": 2.656492233276367,
      "learning_rate": 9.24127673089138e-05,
      "loss": 0.4192,
      "step": 291100
    },
    {
      "epoch": 3.0827541670857133,
      "grad_norm": 2.632725477218628,
      "learning_rate": 9.244452678382382e-05,
      "loss": 0.4183,
      "step": 291200
    },
    {
      "epoch": 3.0838128106457194,
      "grad_norm": 2.6578760147094727,
      "learning_rate": 9.247628625873384e-05,
      "loss": 0.4171,
      "step": 291300
    },
    {
      "epoch": 3.084871454205726,
      "grad_norm": 2.3778178691864014,
      "learning_rate": 9.250804573364386e-05,
      "loss": 0.4114,
      "step": 291400
    },
    {
      "epoch": 3.0859300977657327,
      "grad_norm": 2.483975410461426,
      "learning_rate": 9.253980520855388e-05,
      "loss": 0.4136,
      "step": 291500
    },
    {
      "epoch": 3.0869887413257393,
      "grad_norm": 2.2930564880371094,
      "learning_rate": 9.257156468346391e-05,
      "loss": 0.4217,
      "step": 291600
    },
    {
      "epoch": 3.088047384885746,
      "grad_norm": 2.5103893280029297,
      "learning_rate": 9.260332415837391e-05,
      "loss": 0.4229,
      "step": 291700
    },
    {
      "epoch": 3.0891060284457525,
      "grad_norm": 2.5169434547424316,
      "learning_rate": 9.263508363328393e-05,
      "loss": 0.417,
      "step": 291800
    },
    {
      "epoch": 3.090164672005759,
      "grad_norm": 2.702700138092041,
      "learning_rate": 9.266652551344482e-05,
      "loss": 0.4177,
      "step": 291900
    },
    {
      "epoch": 3.091223315565766,
      "grad_norm": 2.355682611465454,
      "learning_rate": 9.269828498835484e-05,
      "loss": 0.4147,
      "step": 292000
    },
    {
      "epoch": 3.091223315565766,
      "eval_loss": 0.3159862458705902,
      "eval_runtime": 57.2175,
      "eval_samples_per_second": 2934.939,
      "eval_steps_per_second": 366.88,
      "step": 292000
    },
    {
      "epoch": 3.092281959125772,
      "grad_norm": 2.40962290763855,
      "learning_rate": 9.273004446326486e-05,
      "loss": 0.4158,
      "step": 292100
    },
    {
      "epoch": 3.0933406026857786,
      "grad_norm": 2.543416976928711,
      "learning_rate": 9.276180393817489e-05,
      "loss": 0.4198,
      "step": 292200
    },
    {
      "epoch": 3.094399246245785,
      "grad_norm": 2.406738042831421,
      "learning_rate": 9.279356341308491e-05,
      "loss": 0.4189,
      "step": 292300
    },
    {
      "epoch": 3.095457889805792,
      "grad_norm": 2.449493646621704,
      "learning_rate": 9.282532288799491e-05,
      "loss": 0.4149,
      "step": 292400
    },
    {
      "epoch": 3.0965165333657985,
      "grad_norm": 2.3778629302978516,
      "learning_rate": 9.285708236290493e-05,
      "loss": 0.4178,
      "step": 292500
    },
    {
      "epoch": 3.097575176925805,
      "grad_norm": 2.428478479385376,
      "learning_rate": 9.288852424306584e-05,
      "loss": 0.417,
      "step": 292600
    },
    {
      "epoch": 3.0986338204858117,
      "grad_norm": 2.6892974376678467,
      "learning_rate": 9.292028371797584e-05,
      "loss": 0.4176,
      "step": 292700
    },
    {
      "epoch": 3.099692464045818,
      "grad_norm": 2.725219964981079,
      "learning_rate": 9.295204319288587e-05,
      "loss": 0.4206,
      "step": 292800
    },
    {
      "epoch": 3.1007511076058245,
      "grad_norm": 2.6186153888702393,
      "learning_rate": 9.298380266779589e-05,
      "loss": 0.4222,
      "step": 292900
    },
    {
      "epoch": 3.101809751165831,
      "grad_norm": 2.7995049953460693,
      "learning_rate": 9.301556214270591e-05,
      "loss": 0.4167,
      "step": 293000
    },
    {
      "epoch": 3.101809751165831,
      "eval_loss": 0.3156299591064453,
      "eval_runtime": 57.3824,
      "eval_samples_per_second": 2926.505,
      "eval_steps_per_second": 365.826,
      "step": 293000
    },
    {
      "epoch": 3.1028683947258378,
      "grad_norm": 2.754545211791992,
      "learning_rate": 9.304732161761593e-05,
      "loss": 0.4165,
      "step": 293100
    },
    {
      "epoch": 3.1039270382858444,
      "grad_norm": 2.438981294631958,
      "learning_rate": 9.307908109252593e-05,
      "loss": 0.4158,
      "step": 293200
    },
    {
      "epoch": 3.104985681845851,
      "grad_norm": 2.656236410140991,
      "learning_rate": 9.311084056743595e-05,
      "loss": 0.414,
      "step": 293300
    },
    {
      "epoch": 3.1060443254058576,
      "grad_norm": 2.3549957275390625,
      "learning_rate": 9.314260004234597e-05,
      "loss": 0.4177,
      "step": 293400
    },
    {
      "epoch": 3.1071029689658642,
      "grad_norm": 2.2735166549682617,
      "learning_rate": 9.317435951725599e-05,
      "loss": 0.4168,
      "step": 293500
    },
    {
      "epoch": 3.1081616125258704,
      "grad_norm": 2.0585293769836426,
      "learning_rate": 9.320611899216599e-05,
      "loss": 0.4154,
      "step": 293600
    },
    {
      "epoch": 3.109220256085877,
      "grad_norm": 2.495612621307373,
      "learning_rate": 9.323787846707601e-05,
      "loss": 0.4203,
      "step": 293700
    },
    {
      "epoch": 3.1102788996458837,
      "grad_norm": 2.2052502632141113,
      "learning_rate": 9.326963794198603e-05,
      "loss": 0.4151,
      "step": 293800
    },
    {
      "epoch": 3.1113375432058903,
      "grad_norm": 2.41633677482605,
      "learning_rate": 9.330139741689604e-05,
      "loss": 0.4137,
      "step": 293900
    },
    {
      "epoch": 3.112396186765897,
      "grad_norm": 2.8922603130340576,
      "learning_rate": 9.333315689180606e-05,
      "loss": 0.4174,
      "step": 294000
    },
    {
      "epoch": 3.112396186765897,
      "eval_loss": 0.31595173478126526,
      "eval_runtime": 57.2422,
      "eval_samples_per_second": 2933.675,
      "eval_steps_per_second": 366.722,
      "step": 294000
    },
    {
      "epoch": 3.1134548303259035,
      "grad_norm": 2.435774326324463,
      "learning_rate": 9.336459877196697e-05,
      "loss": 0.4118,
      "step": 294100
    },
    {
      "epoch": 3.11451347388591,
      "grad_norm": 2.167336940765381,
      "learning_rate": 9.339635824687699e-05,
      "loss": 0.4169,
      "step": 294200
    },
    {
      "epoch": 3.1155721174459163,
      "grad_norm": 2.47025728225708,
      "learning_rate": 9.3428117721787e-05,
      "loss": 0.4156,
      "step": 294300
    },
    {
      "epoch": 3.116630761005923,
      "grad_norm": 2.583745002746582,
      "learning_rate": 9.345987719669701e-05,
      "loss": 0.4217,
      "step": 294400
    },
    {
      "epoch": 3.1176894045659296,
      "grad_norm": 2.4629955291748047,
      "learning_rate": 9.349163667160703e-05,
      "loss": 0.4134,
      "step": 294500
    },
    {
      "epoch": 3.118748048125936,
      "grad_norm": 2.3643951416015625,
      "learning_rate": 9.352339614651704e-05,
      "loss": 0.4138,
      "step": 294600
    },
    {
      "epoch": 3.119806691685943,
      "grad_norm": 2.3471336364746094,
      "learning_rate": 9.355515562142706e-05,
      "loss": 0.42,
      "step": 294700
    },
    {
      "epoch": 3.1208653352459494,
      "grad_norm": 2.4196367263793945,
      "learning_rate": 9.358691509633707e-05,
      "loss": 0.416,
      "step": 294800
    },
    {
      "epoch": 3.121923978805956,
      "grad_norm": 2.3892276287078857,
      "learning_rate": 9.361867457124708e-05,
      "loss": 0.4149,
      "step": 294900
    },
    {
      "epoch": 3.1229826223659627,
      "grad_norm": 2.6623380184173584,
      "learning_rate": 9.36504340461571e-05,
      "loss": 0.4145,
      "step": 295000
    },
    {
      "epoch": 3.1229826223659627,
      "eval_loss": 0.31725847721099854,
      "eval_runtime": 57.2383,
      "eval_samples_per_second": 2933.876,
      "eval_steps_per_second": 366.748,
      "step": 295000
    },
    {
      "epoch": 3.124041265925969,
      "grad_norm": 2.3516736030578613,
      "learning_rate": 9.368219352106712e-05,
      "loss": 0.4139,
      "step": 295100
    },
    {
      "epoch": 3.1250999094859755,
      "grad_norm": 2.2288315296173096,
      "learning_rate": 9.371395299597714e-05,
      "loss": 0.4139,
      "step": 295200
    },
    {
      "epoch": 3.126158553045982,
      "grad_norm": 2.471900224685669,
      "learning_rate": 9.374571247088714e-05,
      "loss": 0.415,
      "step": 295300
    },
    {
      "epoch": 3.1272171966059887,
      "grad_norm": 1.9754297733306885,
      "learning_rate": 9.377747194579716e-05,
      "loss": 0.4132,
      "step": 295400
    },
    {
      "epoch": 3.1282758401659954,
      "grad_norm": 2.597217559814453,
      "learning_rate": 9.380923142070718e-05,
      "loss": 0.417,
      "step": 295500
    },
    {
      "epoch": 3.129334483726002,
      "grad_norm": 2.541733980178833,
      "learning_rate": 9.38409908956172e-05,
      "loss": 0.4148,
      "step": 295600
    },
    {
      "epoch": 3.1303931272860086,
      "grad_norm": 2.5618393421173096,
      "learning_rate": 9.38727503705272e-05,
      "loss": 0.4107,
      "step": 295700
    },
    {
      "epoch": 3.131451770846015,
      "grad_norm": 2.440645217895508,
      "learning_rate": 9.390450984543722e-05,
      "loss": 0.414,
      "step": 295800
    },
    {
      "epoch": 3.1325104144060214,
      "grad_norm": 2.7439610958099365,
      "learning_rate": 9.393626932034724e-05,
      "loss": 0.4132,
      "step": 295900
    },
    {
      "epoch": 3.133569057966028,
      "grad_norm": 2.4512369632720947,
      "learning_rate": 9.396802879525725e-05,
      "loss": 0.4145,
      "step": 296000
    },
    {
      "epoch": 3.133569057966028,
      "eval_loss": 0.3161988854408264,
      "eval_runtime": 57.1381,
      "eval_samples_per_second": 2939.021,
      "eval_steps_per_second": 367.391,
      "step": 296000
    },
    {
      "epoch": 3.1346277015260346,
      "grad_norm": 2.424788475036621,
      "learning_rate": 9.399978827016726e-05,
      "loss": 0.4202,
      "step": 296100
    },
    {
      "epoch": 3.1356863450860413,
      "grad_norm": 2.6996829509735107,
      "learning_rate": 9.403154774507728e-05,
      "loss": 0.4154,
      "step": 296200
    },
    {
      "epoch": 3.136744988646048,
      "grad_norm": 2.353074789047241,
      "learning_rate": 9.40633072199873e-05,
      "loss": 0.4219,
      "step": 296300
    },
    {
      "epoch": 3.1378036322060545,
      "grad_norm": 2.6905760765075684,
      "learning_rate": 9.409506669489731e-05,
      "loss": 0.4177,
      "step": 296400
    },
    {
      "epoch": 3.138862275766061,
      "grad_norm": 2.724409341812134,
      "learning_rate": 9.412682616980733e-05,
      "loss": 0.4189,
      "step": 296500
    },
    {
      "epoch": 3.1399209193260673,
      "grad_norm": 2.274477958679199,
      "learning_rate": 9.415858564471733e-05,
      "loss": 0.4189,
      "step": 296600
    },
    {
      "epoch": 3.140979562886074,
      "grad_norm": 2.3621060848236084,
      "learning_rate": 9.419034511962735e-05,
      "loss": 0.4124,
      "step": 296700
    },
    {
      "epoch": 3.1420382064460806,
      "grad_norm": 2.348764657974243,
      "learning_rate": 9.422210459453737e-05,
      "loss": 0.4164,
      "step": 296800
    },
    {
      "epoch": 3.143096850006087,
      "grad_norm": 2.488682508468628,
      "learning_rate": 9.425386406944739e-05,
      "loss": 0.4109,
      "step": 296900
    },
    {
      "epoch": 3.144155493566094,
      "grad_norm": 2.629188060760498,
      "learning_rate": 9.428562354435739e-05,
      "loss": 0.4176,
      "step": 297000
    },
    {
      "epoch": 3.144155493566094,
      "eval_loss": 0.3152654469013214,
      "eval_runtime": 57.1568,
      "eval_samples_per_second": 2938.06,
      "eval_steps_per_second": 367.271,
      "step": 297000
    },
    {
      "epoch": 3.1452141371261004,
      "grad_norm": 2.5867788791656494,
      "learning_rate": 9.431738301926741e-05,
      "loss": 0.4178,
      "step": 297100
    },
    {
      "epoch": 3.146272780686107,
      "grad_norm": 2.5591959953308105,
      "learning_rate": 9.434914249417743e-05,
      "loss": 0.412,
      "step": 297200
    },
    {
      "epoch": 3.1473314242461132,
      "grad_norm": 2.187756299972534,
      "learning_rate": 9.438090196908745e-05,
      "loss": 0.4173,
      "step": 297300
    },
    {
      "epoch": 3.14839006780612,
      "grad_norm": 2.3935465812683105,
      "learning_rate": 9.441266144399745e-05,
      "loss": 0.416,
      "step": 297400
    },
    {
      "epoch": 3.1494487113661265,
      "grad_norm": 2.5057897567749023,
      "learning_rate": 9.444442091890747e-05,
      "loss": 0.4143,
      "step": 297500
    },
    {
      "epoch": 3.150507354926133,
      "grad_norm": 2.7549867630004883,
      "learning_rate": 9.447618039381749e-05,
      "loss": 0.4148,
      "step": 297600
    },
    {
      "epoch": 3.1515659984861397,
      "grad_norm": 2.4259889125823975,
      "learning_rate": 9.45079398687275e-05,
      "loss": 0.4136,
      "step": 297700
    },
    {
      "epoch": 3.1526246420461463,
      "grad_norm": 2.1798195838928223,
      "learning_rate": 9.453969934363751e-05,
      "loss": 0.4149,
      "step": 297800
    },
    {
      "epoch": 3.153683285606153,
      "grad_norm": 2.611086845397949,
      "learning_rate": 9.457145881854753e-05,
      "loss": 0.4126,
      "step": 297900
    },
    {
      "epoch": 3.1547419291661596,
      "grad_norm": 2.569951057434082,
      "learning_rate": 9.460321829345754e-05,
      "loss": 0.4154,
      "step": 298000
    },
    {
      "epoch": 3.1547419291661596,
      "eval_loss": 0.3138669729232788,
      "eval_runtime": 57.2252,
      "eval_samples_per_second": 2934.546,
      "eval_steps_per_second": 366.831,
      "step": 298000
    },
    {
      "epoch": 3.1558005727261658,
      "grad_norm": 2.9948878288269043,
      "learning_rate": 9.463497776836756e-05,
      "loss": 0.4124,
      "step": 298100
    },
    {
      "epoch": 3.1568592162861724,
      "grad_norm": 2.679999351501465,
      "learning_rate": 9.466673724327758e-05,
      "loss": 0.4137,
      "step": 298200
    },
    {
      "epoch": 3.157917859846179,
      "grad_norm": 2.6498963832855225,
      "learning_rate": 9.469849671818758e-05,
      "loss": 0.4177,
      "step": 298300
    },
    {
      "epoch": 3.1589765034061856,
      "grad_norm": 2.3537802696228027,
      "learning_rate": 9.47302561930976e-05,
      "loss": 0.418,
      "step": 298400
    },
    {
      "epoch": 3.1600351469661923,
      "grad_norm": 2.4019405841827393,
      "learning_rate": 9.476201566800762e-05,
      "loss": 0.4162,
      "step": 298500
    },
    {
      "epoch": 3.161093790526199,
      "grad_norm": 2.5985615253448486,
      "learning_rate": 9.479377514291764e-05,
      "loss": 0.4151,
      "step": 298600
    },
    {
      "epoch": 3.1621524340862055,
      "grad_norm": 2.396695852279663,
      "learning_rate": 9.482553461782764e-05,
      "loss": 0.4161,
      "step": 298700
    },
    {
      "epoch": 3.1632110776462117,
      "grad_norm": 2.8404130935668945,
      "learning_rate": 9.485729409273766e-05,
      "loss": 0.4136,
      "step": 298800
    },
    {
      "epoch": 3.1642697212062183,
      "grad_norm": 2.69588303565979,
      "learning_rate": 9.488905356764768e-05,
      "loss": 0.4166,
      "step": 298900
    },
    {
      "epoch": 3.165328364766225,
      "grad_norm": 2.4809141159057617,
      "learning_rate": 9.49208130425577e-05,
      "loss": 0.4104,
      "step": 299000
    },
    {
      "epoch": 3.165328364766225,
      "eval_loss": 0.3143681287765503,
      "eval_runtime": 57.2224,
      "eval_samples_per_second": 2934.688,
      "eval_steps_per_second": 366.849,
      "step": 299000
    },
    {
      "epoch": 3.1663870083262315,
      "grad_norm": 2.2291455268859863,
      "learning_rate": 9.49525725174677e-05,
      "loss": 0.4138,
      "step": 299100
    },
    {
      "epoch": 3.167445651886238,
      "grad_norm": 2.4946627616882324,
      "learning_rate": 9.498433199237772e-05,
      "loss": 0.415,
      "step": 299200
    },
    {
      "epoch": 3.168504295446245,
      "grad_norm": 2.88446307182312,
      "learning_rate": 9.501609146728774e-05,
      "loss": 0.4105,
      "step": 299300
    },
    {
      "epoch": 3.1695629390062514,
      "grad_norm": 2.3288912773132324,
      "learning_rate": 9.504785094219775e-05,
      "loss": 0.4122,
      "step": 299400
    },
    {
      "epoch": 3.170621582566258,
      "grad_norm": 2.504317283630371,
      "learning_rate": 9.507961041710776e-05,
      "loss": 0.4104,
      "step": 299500
    },
    {
      "epoch": 3.171680226126264,
      "grad_norm": 2.2566020488739014,
      "learning_rate": 9.511136989201778e-05,
      "loss": 0.4203,
      "step": 299600
    },
    {
      "epoch": 3.172738869686271,
      "grad_norm": 2.7851219177246094,
      "learning_rate": 9.51431293669278e-05,
      "loss": 0.4119,
      "step": 299700
    },
    {
      "epoch": 3.1737975132462775,
      "grad_norm": 2.352916955947876,
      "learning_rate": 9.517488884183781e-05,
      "loss": 0.4122,
      "step": 299800
    },
    {
      "epoch": 3.174856156806284,
      "grad_norm": 2.917936325073242,
      "learning_rate": 9.520664831674783e-05,
      "loss": 0.4157,
      "step": 299900
    },
    {
      "epoch": 3.1759148003662907,
      "grad_norm": 2.6871840953826904,
      "learning_rate": 9.523840779165783e-05,
      "loss": 0.4112,
      "step": 300000
    },
    {
      "epoch": 3.1759148003662907,
      "eval_loss": 0.31441110372543335,
      "eval_runtime": 57.275,
      "eval_samples_per_second": 2931.996,
      "eval_steps_per_second": 366.513,
      "step": 300000
    },
    {
      "epoch": 3.1769734439262973,
      "grad_norm": 2.6988718509674072,
      "learning_rate": 9.526984967181876e-05,
      "loss": 0.4146,
      "step": 300100
    },
    {
      "epoch": 3.178032087486304,
      "grad_norm": 2.3922934532165527,
      "learning_rate": 9.530160914672877e-05,
      "loss": 0.416,
      "step": 300200
    },
    {
      "epoch": 3.1790907310463106,
      "grad_norm": 2.6942672729492188,
      "learning_rate": 9.533336862163878e-05,
      "loss": 0.4141,
      "step": 300300
    },
    {
      "epoch": 3.1801493746063167,
      "grad_norm": 2.453296422958374,
      "learning_rate": 9.53651280965488e-05,
      "loss": 0.4089,
      "step": 300400
    },
    {
      "epoch": 3.1812080181663234,
      "grad_norm": 2.4803125858306885,
      "learning_rate": 9.539688757145881e-05,
      "loss": 0.4156,
      "step": 300500
    },
    {
      "epoch": 3.18226666172633,
      "grad_norm": 2.387941837310791,
      "learning_rate": 9.542864704636883e-05,
      "loss": 0.4101,
      "step": 300600
    },
    {
      "epoch": 3.1833253052863366,
      "grad_norm": 2.6031570434570312,
      "learning_rate": 9.546040652127885e-05,
      "loss": 0.4107,
      "step": 300700
    },
    {
      "epoch": 3.1843839488463432,
      "grad_norm": 2.0574307441711426,
      "learning_rate": 9.549216599618885e-05,
      "loss": 0.4136,
      "step": 300800
    },
    {
      "epoch": 3.18544259240635,
      "grad_norm": 2.236706256866455,
      "learning_rate": 9.552392547109887e-05,
      "loss": 0.4157,
      "step": 300900
    },
    {
      "epoch": 3.1865012359663565,
      "grad_norm": 2.471256732940674,
      "learning_rate": 9.555568494600889e-05,
      "loss": 0.4146,
      "step": 301000
    },
    {
      "epoch": 3.1865012359663565,
      "eval_loss": 0.31315895915031433,
      "eval_runtime": 57.2864,
      "eval_samples_per_second": 2931.413,
      "eval_steps_per_second": 366.44,
      "step": 301000
    },
    {
      "epoch": 3.187559879526363,
      "grad_norm": 2.299454689025879,
      "learning_rate": 9.558744442091891e-05,
      "loss": 0.4189,
      "step": 301100
    },
    {
      "epoch": 3.1886185230863693,
      "grad_norm": 2.5199756622314453,
      "learning_rate": 9.561920389582891e-05,
      "loss": 0.4126,
      "step": 301200
    },
    {
      "epoch": 3.189677166646376,
      "grad_norm": 2.445141077041626,
      "learning_rate": 9.565096337073893e-05,
      "loss": 0.4119,
      "step": 301300
    },
    {
      "epoch": 3.1907358102063825,
      "grad_norm": 2.3157567977905273,
      "learning_rate": 9.568272284564895e-05,
      "loss": 0.4143,
      "step": 301400
    },
    {
      "epoch": 3.191794453766389,
      "grad_norm": 2.502656936645508,
      "learning_rate": 9.571448232055897e-05,
      "loss": 0.4136,
      "step": 301500
    },
    {
      "epoch": 3.1928530973263958,
      "grad_norm": 2.6453616619110107,
      "learning_rate": 9.574624179546897e-05,
      "loss": 0.4163,
      "step": 301600
    },
    {
      "epoch": 3.1939117408864024,
      "grad_norm": 2.367166042327881,
      "learning_rate": 9.577800127037899e-05,
      "loss": 0.4109,
      "step": 301700
    },
    {
      "epoch": 3.194970384446409,
      "grad_norm": 2.281834363937378,
      "learning_rate": 9.5809760745289e-05,
      "loss": 0.4139,
      "step": 301800
    },
    {
      "epoch": 3.196029028006415,
      "grad_norm": 2.423422336578369,
      "learning_rate": 9.584152022019902e-05,
      "loss": 0.4111,
      "step": 301900
    },
    {
      "epoch": 3.197087671566422,
      "grad_norm": 2.038478136062622,
      "learning_rate": 9.587327969510903e-05,
      "loss": 0.4076,
      "step": 302000
    },
    {
      "epoch": 3.197087671566422,
      "eval_loss": 0.312519907951355,
      "eval_runtime": 57.2725,
      "eval_samples_per_second": 2932.124,
      "eval_steps_per_second": 366.529,
      "step": 302000
    },
    {
      "epoch": 3.1981463151264284,
      "grad_norm": 2.5147786140441895,
      "learning_rate": 9.590472157526995e-05,
      "loss": 0.4153,
      "step": 302100
    },
    {
      "epoch": 3.199204958686435,
      "grad_norm": 2.448697328567505,
      "learning_rate": 9.593648105017997e-05,
      "loss": 0.4131,
      "step": 302200
    },
    {
      "epoch": 3.2002636022464417,
      "grad_norm": 2.6772847175598145,
      "learning_rate": 9.596824052508998e-05,
      "loss": 0.4127,
      "step": 302300
    },
    {
      "epoch": 3.2013222458064483,
      "grad_norm": 2.691175937652588,
      "learning_rate": 9.599999999999999e-05,
      "loss": 0.4177,
      "step": 302400
    },
    {
      "epoch": 3.202380889366455,
      "grad_norm": 2.544961929321289,
      "learning_rate": 9.603175947491001e-05,
      "loss": 0.4164,
      "step": 302500
    },
    {
      "epoch": 3.2034395329264616,
      "grad_norm": 2.332040548324585,
      "learning_rate": 9.606351894982002e-05,
      "loss": 0.4124,
      "step": 302600
    },
    {
      "epoch": 3.2044981764864677,
      "grad_norm": 2.7185347080230713,
      "learning_rate": 9.609527842473004e-05,
      "loss": 0.4129,
      "step": 302700
    },
    {
      "epoch": 3.2055568200464744,
      "grad_norm": 2.2972989082336426,
      "learning_rate": 9.612703789964005e-05,
      "loss": 0.412,
      "step": 302800
    },
    {
      "epoch": 3.206615463606481,
      "grad_norm": 2.564941167831421,
      "learning_rate": 9.615879737455006e-05,
      "loss": 0.4153,
      "step": 302900
    },
    {
      "epoch": 3.2076741071664876,
      "grad_norm": 2.3782858848571777,
      "learning_rate": 9.619055684946008e-05,
      "loss": 0.4162,
      "step": 303000
    },
    {
      "epoch": 3.2076741071664876,
      "eval_loss": 0.31167367100715637,
      "eval_runtime": 57.2659,
      "eval_samples_per_second": 2932.459,
      "eval_steps_per_second": 366.571,
      "step": 303000
    },
    {
      "epoch": 3.208732750726494,
      "grad_norm": 2.878927230834961,
      "learning_rate": 9.62223163243701e-05,
      "loss": 0.4156,
      "step": 303100
    },
    {
      "epoch": 3.209791394286501,
      "grad_norm": 2.6232545375823975,
      "learning_rate": 9.62540757992801e-05,
      "loss": 0.4161,
      "step": 303200
    },
    {
      "epoch": 3.2108500378465075,
      "grad_norm": 2.691591739654541,
      "learning_rate": 9.628583527419012e-05,
      "loss": 0.4082,
      "step": 303300
    },
    {
      "epoch": 3.2119086814065136,
      "grad_norm": 2.6597707271575928,
      "learning_rate": 9.631759474910014e-05,
      "loss": 0.4166,
      "step": 303400
    },
    {
      "epoch": 3.2129673249665203,
      "grad_norm": 2.473602056503296,
      "learning_rate": 9.634935422401016e-05,
      "loss": 0.4164,
      "step": 303500
    },
    {
      "epoch": 3.214025968526527,
      "grad_norm": 2.459347724914551,
      "learning_rate": 9.638111369892018e-05,
      "loss": 0.4128,
      "step": 303600
    },
    {
      "epoch": 3.2150846120865335,
      "grad_norm": 2.654604434967041,
      "learning_rate": 9.641287317383018e-05,
      "loss": 0.4128,
      "step": 303700
    },
    {
      "epoch": 3.21614325564654,
      "grad_norm": 2.2829339504241943,
      "learning_rate": 9.64446326487402e-05,
      "loss": 0.4146,
      "step": 303800
    },
    {
      "epoch": 3.2172018992065468,
      "grad_norm": 2.391291856765747,
      "learning_rate": 9.647639212365022e-05,
      "loss": 0.4102,
      "step": 303900
    },
    {
      "epoch": 3.2182605427665534,
      "grad_norm": 2.509826183319092,
      "learning_rate": 9.650815159856023e-05,
      "loss": 0.4159,
      "step": 304000
    },
    {
      "epoch": 3.2182605427665534,
      "eval_loss": 0.31197690963745117,
      "eval_runtime": 57.3727,
      "eval_samples_per_second": 2927.004,
      "eval_steps_per_second": 365.889,
      "step": 304000
    },
    {
      "epoch": 3.21931918632656,
      "grad_norm": 2.1881797313690186,
      "learning_rate": 9.653959347872114e-05,
      "loss": 0.4083,
      "step": 304100
    },
    {
      "epoch": 3.220377829886566,
      "grad_norm": 2.393805503845215,
      "learning_rate": 9.657135295363116e-05,
      "loss": 0.4142,
      "step": 304200
    },
    {
      "epoch": 3.221436473446573,
      "grad_norm": 2.1199514865875244,
      "learning_rate": 9.660311242854118e-05,
      "loss": 0.4125,
      "step": 304300
    },
    {
      "epoch": 3.2224951170065794,
      "grad_norm": 2.258760929107666,
      "learning_rate": 9.663487190345118e-05,
      "loss": 0.4145,
      "step": 304400
    },
    {
      "epoch": 3.223553760566586,
      "grad_norm": 2.7643792629241943,
      "learning_rate": 9.66666313783612e-05,
      "loss": 0.4094,
      "step": 304500
    },
    {
      "epoch": 3.2246124041265927,
      "grad_norm": 2.3203189373016357,
      "learning_rate": 9.669839085327122e-05,
      "loss": 0.4101,
      "step": 304600
    },
    {
      "epoch": 3.2256710476865993,
      "grad_norm": 2.3581745624542236,
      "learning_rate": 9.673015032818124e-05,
      "loss": 0.4097,
      "step": 304700
    },
    {
      "epoch": 3.226729691246606,
      "grad_norm": 2.3397138118743896,
      "learning_rate": 9.676190980309125e-05,
      "loss": 0.4086,
      "step": 304800
    },
    {
      "epoch": 3.227788334806612,
      "grad_norm": 2.4243884086608887,
      "learning_rate": 9.679366927800126e-05,
      "loss": 0.4122,
      "step": 304900
    },
    {
      "epoch": 3.2288469783666187,
      "grad_norm": 2.2935376167297363,
      "learning_rate": 9.682542875291128e-05,
      "loss": 0.4112,
      "step": 305000
    },
    {
      "epoch": 3.2288469783666187,
      "eval_loss": 0.31192800402641296,
      "eval_runtime": 57.4191,
      "eval_samples_per_second": 2924.637,
      "eval_steps_per_second": 365.593,
      "step": 305000
    },
    {
      "epoch": 3.2299056219266253,
      "grad_norm": 2.4755637645721436,
      "learning_rate": 9.68571882278213e-05,
      "loss": 0.4086,
      "step": 305100
    },
    {
      "epoch": 3.230964265486632,
      "grad_norm": 2.4730355739593506,
      "learning_rate": 9.688894770273131e-05,
      "loss": 0.414,
      "step": 305200
    },
    {
      "epoch": 3.2320229090466386,
      "grad_norm": 2.471033811569214,
      "learning_rate": 9.692070717764132e-05,
      "loss": 0.41,
      "step": 305300
    },
    {
      "epoch": 3.233081552606645,
      "grad_norm": 2.2229278087615967,
      "learning_rate": 9.695246665255133e-05,
      "loss": 0.4034,
      "step": 305400
    },
    {
      "epoch": 3.234140196166652,
      "grad_norm": 2.324486255645752,
      "learning_rate": 9.698422612746135e-05,
      "loss": 0.4125,
      "step": 305500
    },
    {
      "epoch": 3.2351988397266584,
      "grad_norm": 2.2861502170562744,
      "learning_rate": 9.701598560237137e-05,
      "loss": 0.4094,
      "step": 305600
    },
    {
      "epoch": 3.2362574832866646,
      "grad_norm": 2.1725072860717773,
      "learning_rate": 9.704774507728137e-05,
      "loss": 0.4098,
      "step": 305700
    },
    {
      "epoch": 3.2373161268466712,
      "grad_norm": 2.55462908744812,
      "learning_rate": 9.707950455219139e-05,
      "loss": 0.4092,
      "step": 305800
    },
    {
      "epoch": 3.238374770406678,
      "grad_norm": 2.377973794937134,
      "learning_rate": 9.711126402710141e-05,
      "loss": 0.4154,
      "step": 305900
    },
    {
      "epoch": 3.2394334139666845,
      "grad_norm": 2.1496357917785645,
      "learning_rate": 9.714302350201143e-05,
      "loss": 0.4029,
      "step": 306000
    },
    {
      "epoch": 3.2394334139666845,
      "eval_loss": 0.31306028366088867,
      "eval_runtime": 57.2937,
      "eval_samples_per_second": 2931.037,
      "eval_steps_per_second": 366.393,
      "step": 306000
    },
    {
      "epoch": 3.240492057526691,
      "grad_norm": 2.681903600692749,
      "learning_rate": 9.717446538217234e-05,
      "loss": 0.4114,
      "step": 306100
    },
    {
      "epoch": 3.2415507010866977,
      "grad_norm": 2.440680742263794,
      "learning_rate": 9.720622485708235e-05,
      "loss": 0.4107,
      "step": 306200
    },
    {
      "epoch": 3.2426093446467044,
      "grad_norm": 2.109332799911499,
      "learning_rate": 9.723798433199237e-05,
      "loss": 0.4128,
      "step": 306300
    },
    {
      "epoch": 3.2436679882067105,
      "grad_norm": 2.436004638671875,
      "learning_rate": 9.726974380690239e-05,
      "loss": 0.4076,
      "step": 306400
    },
    {
      "epoch": 3.244726631766717,
      "grad_norm": 2.3474252223968506,
      "learning_rate": 9.730150328181239e-05,
      "loss": 0.409,
      "step": 306500
    },
    {
      "epoch": 3.245785275326724,
      "grad_norm": 2.249065399169922,
      "learning_rate": 9.733326275672241e-05,
      "loss": 0.4147,
      "step": 306600
    },
    {
      "epoch": 3.2468439188867304,
      "grad_norm": 2.296755313873291,
      "learning_rate": 9.736502223163243e-05,
      "loss": 0.4103,
      "step": 306700
    },
    {
      "epoch": 3.247902562446737,
      "grad_norm": 2.611813545227051,
      "learning_rate": 9.739678170654245e-05,
      "loss": 0.411,
      "step": 306800
    },
    {
      "epoch": 3.2489612060067437,
      "grad_norm": 2.3788793087005615,
      "learning_rate": 9.742854118145245e-05,
      "loss": 0.405,
      "step": 306900
    },
    {
      "epoch": 3.2500198495667503,
      "grad_norm": 2.476088285446167,
      "learning_rate": 9.746030065636247e-05,
      "loss": 0.4154,
      "step": 307000
    },
    {
      "epoch": 3.2500198495667503,
      "eval_loss": 0.31119343638420105,
      "eval_runtime": 57.3001,
      "eval_samples_per_second": 2930.713,
      "eval_steps_per_second": 366.352,
      "step": 307000
    },
    {
      "epoch": 3.251078493126757,
      "grad_norm": 2.052356481552124,
      "learning_rate": 9.749206013127249e-05,
      "loss": 0.4105,
      "step": 307100
    },
    {
      "epoch": 3.252137136686763,
      "grad_norm": 2.4766268730163574,
      "learning_rate": 9.75238196061825e-05,
      "loss": 0.41,
      "step": 307200
    },
    {
      "epoch": 3.2531957802467697,
      "grad_norm": 2.2127270698547363,
      "learning_rate": 9.755557908109252e-05,
      "loss": 0.4079,
      "step": 307300
    },
    {
      "epoch": 3.2542544238067763,
      "grad_norm": 2.4214928150177,
      "learning_rate": 9.758733855600253e-05,
      "loss": 0.4116,
      "step": 307400
    },
    {
      "epoch": 3.255313067366783,
      "grad_norm": 2.0784809589385986,
      "learning_rate": 9.761909803091255e-05,
      "loss": 0.4108,
      "step": 307500
    },
    {
      "epoch": 3.2563717109267896,
      "grad_norm": 2.3379440307617188,
      "learning_rate": 9.765085750582256e-05,
      "loss": 0.4155,
      "step": 307600
    },
    {
      "epoch": 3.257430354486796,
      "grad_norm": 2.116598606109619,
      "learning_rate": 9.768261698073258e-05,
      "loss": 0.4074,
      "step": 307700
    },
    {
      "epoch": 3.258488998046803,
      "grad_norm": 2.3432092666625977,
      "learning_rate": 9.771437645564259e-05,
      "loss": 0.4088,
      "step": 307800
    },
    {
      "epoch": 3.259547641606809,
      "grad_norm": 1.8398734331130981,
      "learning_rate": 9.77461359305526e-05,
      "loss": 0.4141,
      "step": 307900
    },
    {
      "epoch": 3.2606062851668156,
      "grad_norm": 2.341437339782715,
      "learning_rate": 9.777789540546262e-05,
      "loss": 0.4107,
      "step": 308000
    },
    {
      "epoch": 3.2606062851668156,
      "eval_loss": 0.31173455715179443,
      "eval_runtime": 57.2881,
      "eval_samples_per_second": 2931.326,
      "eval_steps_per_second": 366.429,
      "step": 308000
    },
    {
      "epoch": 3.2616649287268222,
      "grad_norm": 2.403498411178589,
      "learning_rate": 9.780933728562353e-05,
      "loss": 0.4073,
      "step": 308100
    },
    {
      "epoch": 3.262723572286829,
      "grad_norm": 2.2470221519470215,
      "learning_rate": 9.784109676053355e-05,
      "loss": 0.412,
      "step": 308200
    },
    {
      "epoch": 3.2637822158468355,
      "grad_norm": 2.0836002826690674,
      "learning_rate": 9.787285623544356e-05,
      "loss": 0.4112,
      "step": 308300
    },
    {
      "epoch": 3.264840859406842,
      "grad_norm": 2.5396554470062256,
      "learning_rate": 9.790461571035358e-05,
      "loss": 0.4067,
      "step": 308400
    },
    {
      "epoch": 3.2658995029668487,
      "grad_norm": 2.429218292236328,
      "learning_rate": 9.79363751852636e-05,
      "loss": 0.4081,
      "step": 308500
    },
    {
      "epoch": 3.2669581465268553,
      "grad_norm": 2.2323312759399414,
      "learning_rate": 9.79681346601736e-05,
      "loss": 0.4094,
      "step": 308600
    },
    {
      "epoch": 3.2680167900868615,
      "grad_norm": 2.1607909202575684,
      "learning_rate": 9.799989413508362e-05,
      "loss": 0.4122,
      "step": 308700
    },
    {
      "epoch": 3.269075433646868,
      "grad_norm": 2.5436344146728516,
      "learning_rate": 9.803165360999364e-05,
      "loss": 0.4086,
      "step": 308800
    },
    {
      "epoch": 3.2701340772068748,
      "grad_norm": 2.2980294227600098,
      "learning_rate": 9.806341308490366e-05,
      "loss": 0.4048,
      "step": 308900
    },
    {
      "epoch": 3.2711927207668814,
      "grad_norm": 2.332125186920166,
      "learning_rate": 9.809517255981366e-05,
      "loss": 0.4052,
      "step": 309000
    },
    {
      "epoch": 3.2711927207668814,
      "eval_loss": 0.3114319145679474,
      "eval_runtime": 57.233,
      "eval_samples_per_second": 2934.148,
      "eval_steps_per_second": 366.782,
      "step": 309000
    },
    {
      "epoch": 3.272251364326888,
      "grad_norm": 2.372175931930542,
      "learning_rate": 9.812693203472368e-05,
      "loss": 0.4076,
      "step": 309100
    },
    {
      "epoch": 3.2733100078868946,
      "grad_norm": 2.4641737937927246,
      "learning_rate": 9.81586915096337e-05,
      "loss": 0.4163,
      "step": 309200
    },
    {
      "epoch": 3.2743686514469013,
      "grad_norm": 2.5160043239593506,
      "learning_rate": 9.819045098454372e-05,
      "loss": 0.4147,
      "step": 309300
    },
    {
      "epoch": 3.2754272950069074,
      "grad_norm": 2.2860348224639893,
      "learning_rate": 9.822221045945372e-05,
      "loss": 0.4096,
      "step": 309400
    },
    {
      "epoch": 3.276485938566914,
      "grad_norm": 2.249758005142212,
      "learning_rate": 9.825396993436374e-05,
      "loss": 0.4102,
      "step": 309500
    },
    {
      "epoch": 3.2775445821269207,
      "grad_norm": 2.233187675476074,
      "learning_rate": 9.828572940927376e-05,
      "loss": 0.4085,
      "step": 309600
    },
    {
      "epoch": 3.2786032256869273,
      "grad_norm": 2.2857561111450195,
      "learning_rate": 9.831748888418377e-05,
      "loss": 0.4058,
      "step": 309700
    },
    {
      "epoch": 3.279661869246934,
      "grad_norm": 2.5091259479522705,
      "learning_rate": 9.834924835909379e-05,
      "loss": 0.4041,
      "step": 309800
    },
    {
      "epoch": 3.2807205128069405,
      "grad_norm": 1.9467358589172363,
      "learning_rate": 9.83810078340038e-05,
      "loss": 0.4116,
      "step": 309900
    },
    {
      "epoch": 3.281779156366947,
      "grad_norm": 2.4197564125061035,
      "learning_rate": 9.841276730891381e-05,
      "loss": 0.4159,
      "step": 310000
    },
    {
      "epoch": 3.281779156366947,
      "eval_loss": 0.3108678162097931,
      "eval_runtime": 57.1753,
      "eval_samples_per_second": 2937.106,
      "eval_steps_per_second": 367.151,
      "step": 310000
    },
    {
      "epoch": 3.282837799926954,
      "grad_norm": 2.1127750873565674,
      "learning_rate": 9.844420918907473e-05,
      "loss": 0.4083,
      "step": 310100
    },
    {
      "epoch": 3.28389644348696,
      "grad_norm": 2.071274757385254,
      "learning_rate": 9.847596866398474e-05,
      "loss": 0.4092,
      "step": 310200
    },
    {
      "epoch": 3.2849550870469666,
      "grad_norm": 2.6384119987487793,
      "learning_rate": 9.850772813889476e-05,
      "loss": 0.4089,
      "step": 310300
    },
    {
      "epoch": 3.286013730606973,
      "grad_norm": 2.505378246307373,
      "learning_rate": 9.853948761380478e-05,
      "loss": 0.4107,
      "step": 310400
    },
    {
      "epoch": 3.28707237416698,
      "grad_norm": 2.376415729522705,
      "learning_rate": 9.857124708871479e-05,
      "loss": 0.4146,
      "step": 310500
    },
    {
      "epoch": 3.2881310177269865,
      "grad_norm": 2.2443199157714844,
      "learning_rate": 9.86030065636248e-05,
      "loss": 0.4083,
      "step": 310600
    },
    {
      "epoch": 3.289189661286993,
      "grad_norm": 2.569638252258301,
      "learning_rate": 9.863476603853482e-05,
      "loss": 0.4069,
      "step": 310700
    },
    {
      "epoch": 3.2902483048469997,
      "grad_norm": 2.296100616455078,
      "learning_rate": 9.866652551344483e-05,
      "loss": 0.4127,
      "step": 310800
    },
    {
      "epoch": 3.291306948407006,
      "grad_norm": 2.320829153060913,
      "learning_rate": 9.869828498835485e-05,
      "loss": 0.4139,
      "step": 310900
    },
    {
      "epoch": 3.2923655919670125,
      "grad_norm": 2.367767333984375,
      "learning_rate": 9.873004446326487e-05,
      "loss": 0.4108,
      "step": 311000
    },
    {
      "epoch": 3.2923655919670125,
      "eval_loss": 0.3107430636882782,
      "eval_runtime": 57.2169,
      "eval_samples_per_second": 2934.971,
      "eval_steps_per_second": 366.885,
      "step": 311000
    },
    {
      "epoch": 3.293424235527019,
      "grad_norm": 2.2076964378356934,
      "learning_rate": 9.876180393817487e-05,
      "loss": 0.4108,
      "step": 311100
    },
    {
      "epoch": 3.2944828790870258,
      "grad_norm": 2.1752676963806152,
      "learning_rate": 9.879356341308489e-05,
      "loss": 0.4071,
      "step": 311200
    },
    {
      "epoch": 3.2955415226470324,
      "grad_norm": 2.193777561187744,
      "learning_rate": 9.882532288799491e-05,
      "loss": 0.4097,
      "step": 311300
    },
    {
      "epoch": 3.296600166207039,
      "grad_norm": 2.1635258197784424,
      "learning_rate": 9.885708236290493e-05,
      "loss": 0.4085,
      "step": 311400
    },
    {
      "epoch": 3.2976588097670456,
      "grad_norm": 2.090015172958374,
      "learning_rate": 9.888884183781493e-05,
      "loss": 0.4082,
      "step": 311500
    },
    {
      "epoch": 3.2987174533270522,
      "grad_norm": 2.458977699279785,
      "learning_rate": 9.892060131272495e-05,
      "loss": 0.4138,
      "step": 311600
    },
    {
      "epoch": 3.2997760968870584,
      "grad_norm": 2.4164953231811523,
      "learning_rate": 9.895236078763497e-05,
      "loss": 0.4062,
      "step": 311700
    },
    {
      "epoch": 3.300834740447065,
      "grad_norm": 2.0501413345336914,
      "learning_rate": 9.898412026254499e-05,
      "loss": 0.4053,
      "step": 311800
    },
    {
      "epoch": 3.3018933840070717,
      "grad_norm": 2.372974157333374,
      "learning_rate": 9.901587973745499e-05,
      "loss": 0.4063,
      "step": 311900
    },
    {
      "epoch": 3.3029520275670783,
      "grad_norm": 2.0694854259490967,
      "learning_rate": 9.904763921236501e-05,
      "loss": 0.4079,
      "step": 312000
    },
    {
      "epoch": 3.3029520275670783,
      "eval_loss": 0.30975934863090515,
      "eval_runtime": 57.2249,
      "eval_samples_per_second": 2934.562,
      "eval_steps_per_second": 366.833,
      "step": 312000
    },
    {
      "epoch": 3.304010671127085,
      "grad_norm": 2.4537298679351807,
      "learning_rate": 9.907908109252593e-05,
      "loss": 0.4037,
      "step": 312100
    },
    {
      "epoch": 3.3050693146870915,
      "grad_norm": 2.3540546894073486,
      "learning_rate": 9.911084056743595e-05,
      "loss": 0.4107,
      "step": 312200
    },
    {
      "epoch": 3.306127958247098,
      "grad_norm": 2.249128580093384,
      "learning_rate": 9.914260004234595e-05,
      "loss": 0.4069,
      "step": 312300
    },
    {
      "epoch": 3.3071866018071043,
      "grad_norm": 2.2151477336883545,
      "learning_rate": 9.917435951725597e-05,
      "loss": 0.4098,
      "step": 312400
    },
    {
      "epoch": 3.308245245367111,
      "grad_norm": 2.4826254844665527,
      "learning_rate": 9.920611899216599e-05,
      "loss": 0.405,
      "step": 312500
    },
    {
      "epoch": 3.3093038889271176,
      "grad_norm": 2.368880271911621,
      "learning_rate": 9.9237878467076e-05,
      "loss": 0.4085,
      "step": 312600
    },
    {
      "epoch": 3.310362532487124,
      "grad_norm": 2.027827262878418,
      "learning_rate": 9.926963794198601e-05,
      "loss": 0.4125,
      "step": 312700
    },
    {
      "epoch": 3.311421176047131,
      "grad_norm": 2.5693697929382324,
      "learning_rate": 9.930139741689603e-05,
      "loss": 0.4076,
      "step": 312800
    },
    {
      "epoch": 3.3124798196071374,
      "grad_norm": 2.2063050270080566,
      "learning_rate": 9.933315689180604e-05,
      "loss": 0.4112,
      "step": 312900
    },
    {
      "epoch": 3.313538463167144,
      "grad_norm": 2.231797456741333,
      "learning_rate": 9.936491636671606e-05,
      "loss": 0.4091,
      "step": 313000
    },
    {
      "epoch": 3.313538463167144,
      "eval_loss": 0.3091282546520233,
      "eval_runtime": 57.2042,
      "eval_samples_per_second": 2935.623,
      "eval_steps_per_second": 366.966,
      "step": 313000
    },
    {
      "epoch": 3.3145971067271507,
      "grad_norm": 2.577929735183716,
      "learning_rate": 9.939667584162607e-05,
      "loss": 0.4105,
      "step": 313100
    },
    {
      "epoch": 3.3156557502871573,
      "grad_norm": 2.1682260036468506,
      "learning_rate": 9.942843531653608e-05,
      "loss": 0.4058,
      "step": 313200
    },
    {
      "epoch": 3.3167143938471635,
      "grad_norm": 2.30609393119812,
      "learning_rate": 9.94601947914461e-05,
      "loss": 0.4103,
      "step": 313300
    },
    {
      "epoch": 3.31777303740717,
      "grad_norm": 2.432830333709717,
      "learning_rate": 9.949195426635612e-05,
      "loss": 0.4107,
      "step": 313400
    },
    {
      "epoch": 3.3188316809671767,
      "grad_norm": 2.6489923000335693,
      "learning_rate": 9.952371374126612e-05,
      "loss": 0.4131,
      "step": 313500
    },
    {
      "epoch": 3.3198903245271834,
      "grad_norm": 2.4473674297332764,
      "learning_rate": 9.955547321617614e-05,
      "loss": 0.407,
      "step": 313600
    },
    {
      "epoch": 3.32094896808719,
      "grad_norm": 2.3113746643066406,
      "learning_rate": 9.958723269108616e-05,
      "loss": 0.406,
      "step": 313700
    },
    {
      "epoch": 3.3220076116471966,
      "grad_norm": 2.402649402618408,
      "learning_rate": 9.961867457124708e-05,
      "loss": 0.4062,
      "step": 313800
    },
    {
      "epoch": 3.323066255207203,
      "grad_norm": 2.302267074584961,
      "learning_rate": 9.965043404615709e-05,
      "loss": 0.411,
      "step": 313900
    },
    {
      "epoch": 3.3241248987672094,
      "grad_norm": 2.281682014465332,
      "learning_rate": 9.96821935210671e-05,
      "loss": 0.4078,
      "step": 314000
    },
    {
      "epoch": 3.3241248987672094,
      "eval_loss": 0.3097551763057709,
      "eval_runtime": 57.3299,
      "eval_samples_per_second": 2929.187,
      "eval_steps_per_second": 366.161,
      "step": 314000
    },
    {
      "epoch": 3.325183542327216,
      "grad_norm": 2.190326690673828,
      "learning_rate": 9.971395299597712e-05,
      "loss": 0.4067,
      "step": 314100
    },
    {
      "epoch": 3.3262421858872226,
      "grad_norm": 2.235649585723877,
      "learning_rate": 9.974571247088714e-05,
      "loss": 0.4043,
      "step": 314200
    },
    {
      "epoch": 3.3273008294472293,
      "grad_norm": 2.293938398361206,
      "learning_rate": 9.977747194579714e-05,
      "loss": 0.4082,
      "step": 314300
    },
    {
      "epoch": 3.328359473007236,
      "grad_norm": 2.2174646854400635,
      "learning_rate": 9.980923142070716e-05,
      "loss": 0.4076,
      "step": 314400
    },
    {
      "epoch": 3.3294181165672425,
      "grad_norm": 2.0734646320343018,
      "learning_rate": 9.984099089561718e-05,
      "loss": 0.41,
      "step": 314500
    },
    {
      "epoch": 3.330476760127249,
      "grad_norm": 2.1892809867858887,
      "learning_rate": 9.98727503705272e-05,
      "loss": 0.4048,
      "step": 314600
    },
    {
      "epoch": 3.3315354036872558,
      "grad_norm": 2.416590690612793,
      "learning_rate": 9.990450984543722e-05,
      "loss": 0.4049,
      "step": 314700
    },
    {
      "epoch": 3.332594047247262,
      "grad_norm": 2.0414793491363525,
      "learning_rate": 9.993626932034722e-05,
      "loss": 0.4109,
      "step": 314800
    },
    {
      "epoch": 3.3336526908072686,
      "grad_norm": 2.055288076400757,
      "learning_rate": 9.996802879525724e-05,
      "loss": 0.4105,
      "step": 314900
    },
    {
      "epoch": 3.334711334367275,
      "grad_norm": 2.6110777854919434,
      "learning_rate": 9.999978827016726e-05,
      "loss": 0.4055,
      "step": 315000
    },
    {
      "epoch": 3.334711334367275,
      "eval_loss": 0.3110698461532593,
      "eval_runtime": 57.2826,
      "eval_samples_per_second": 2931.606,
      "eval_steps_per_second": 366.464,
      "step": 315000
    },
    {
      "epoch": 3.335769977927282,
      "grad_norm": 2.3639321327209473,
      "learning_rate": 0.00010003154774507727,
      "loss": 0.4129,
      "step": 315100
    },
    {
      "epoch": 3.3368286214872884,
      "grad_norm": 2.308865547180176,
      "learning_rate": 0.00010006330721998728,
      "loss": 0.4073,
      "step": 315200
    },
    {
      "epoch": 3.337887265047295,
      "grad_norm": 2.4585635662078857,
      "learning_rate": 0.0001000950666948973,
      "loss": 0.4052,
      "step": 315300
    },
    {
      "epoch": 3.3389459086073012,
      "grad_norm": 2.2937002182006836,
      "learning_rate": 0.00010012682616980731,
      "loss": 0.4103,
      "step": 315400
    },
    {
      "epoch": 3.340004552167308,
      "grad_norm": 2.0633535385131836,
      "learning_rate": 0.00010015858564471733,
      "loss": 0.4058,
      "step": 315500
    },
    {
      "epoch": 3.3410631957273145,
      "grad_norm": 2.278879404067993,
      "learning_rate": 0.00010019034511962734,
      "loss": 0.4125,
      "step": 315600
    },
    {
      "epoch": 3.342121839287321,
      "grad_norm": 2.158315896987915,
      "learning_rate": 0.00010022210459453735,
      "loss": 0.4052,
      "step": 315700
    },
    {
      "epoch": 3.3431804828473277,
      "grad_norm": 2.388075113296509,
      "learning_rate": 0.00010025386406944737,
      "loss": 0.4066,
      "step": 315800
    },
    {
      "epoch": 3.3442391264073343,
      "grad_norm": 2.308865547180176,
      "learning_rate": 0.00010028562354435739,
      "loss": 0.4109,
      "step": 315900
    },
    {
      "epoch": 3.345297769967341,
      "grad_norm": 2.162881851196289,
      "learning_rate": 0.0001003173830192674,
      "loss": 0.4057,
      "step": 316000
    },
    {
      "epoch": 3.345297769967341,
      "eval_loss": 0.3087097406387329,
      "eval_runtime": 57.3364,
      "eval_samples_per_second": 2928.853,
      "eval_steps_per_second": 366.12,
      "step": 316000
    },
    {
      "epoch": 3.3463564135273476,
      "grad_norm": 2.487732172012329,
      "learning_rate": 0.00010034914249417741,
      "loss": 0.4053,
      "step": 316100
    },
    {
      "epoch": 3.347415057087354,
      "grad_norm": 2.155994415283203,
      "learning_rate": 0.00010038090196908743,
      "loss": 0.4106,
      "step": 316200
    },
    {
      "epoch": 3.3484737006473604,
      "grad_norm": 2.4044225215911865,
      "learning_rate": 0.00010041266144399745,
      "loss": 0.4057,
      "step": 316300
    },
    {
      "epoch": 3.349532344207367,
      "grad_norm": 2.5801467895507812,
      "learning_rate": 0.00010044442091890747,
      "loss": 0.4072,
      "step": 316400
    },
    {
      "epoch": 3.3505909877673736,
      "grad_norm": 2.2084858417510986,
      "learning_rate": 0.00010047618039381747,
      "loss": 0.4108,
      "step": 316500
    },
    {
      "epoch": 3.3516496313273803,
      "grad_norm": 2.4035964012145996,
      "learning_rate": 0.00010050793986872749,
      "loss": 0.408,
      "step": 316600
    },
    {
      "epoch": 3.352708274887387,
      "grad_norm": 2.5023839473724365,
      "learning_rate": 0.0001005396993436375,
      "loss": 0.412,
      "step": 316700
    },
    {
      "epoch": 3.3537669184473935,
      "grad_norm": 2.2435154914855957,
      "learning_rate": 0.00010057145881854752,
      "loss": 0.406,
      "step": 316800
    },
    {
      "epoch": 3.3548255620073997,
      "grad_norm": 2.120652675628662,
      "learning_rate": 0.00010060321829345753,
      "loss": 0.4062,
      "step": 316900
    },
    {
      "epoch": 3.3558842055674063,
      "grad_norm": 2.5837454795837402,
      "learning_rate": 0.00010063497776836755,
      "loss": 0.4045,
      "step": 317000
    },
    {
      "epoch": 3.3558842055674063,
      "eval_loss": 0.3088407516479492,
      "eval_runtime": 57.3448,
      "eval_samples_per_second": 2928.425,
      "eval_steps_per_second": 366.066,
      "step": 317000
    },
    {
      "epoch": 3.356942849127413,
      "grad_norm": 2.2727112770080566,
      "learning_rate": 0.00010066673724327756,
      "loss": 0.4081,
      "step": 317100
    },
    {
      "epoch": 3.3580014926874195,
      "grad_norm": 2.3596062660217285,
      "learning_rate": 0.00010069849671818758,
      "loss": 0.406,
      "step": 317200
    },
    {
      "epoch": 3.359060136247426,
      "grad_norm": 2.3584675788879395,
      "learning_rate": 0.00010073025619309759,
      "loss": 0.4059,
      "step": 317300
    },
    {
      "epoch": 3.360118779807433,
      "grad_norm": 2.2225990295410156,
      "learning_rate": 0.0001007620156680076,
      "loss": 0.4054,
      "step": 317400
    },
    {
      "epoch": 3.3611774233674394,
      "grad_norm": 2.089068651199341,
      "learning_rate": 0.00010079377514291762,
      "loss": 0.4054,
      "step": 317500
    },
    {
      "epoch": 3.362236066927446,
      "grad_norm": 2.162292003631592,
      "learning_rate": 0.00010082553461782764,
      "loss": 0.4087,
      "step": 317600
    },
    {
      "epoch": 3.3632947104874527,
      "grad_norm": 2.28963303565979,
      "learning_rate": 0.00010085729409273764,
      "loss": 0.4058,
      "step": 317700
    },
    {
      "epoch": 3.364353354047459,
      "grad_norm": 2.245084047317505,
      "learning_rate": 0.00010088873597289856,
      "loss": 0.4057,
      "step": 317800
    },
    {
      "epoch": 3.3654119976074655,
      "grad_norm": 2.4146833419799805,
      "learning_rate": 0.00010092049544780858,
      "loss": 0.4075,
      "step": 317900
    },
    {
      "epoch": 3.366470641167472,
      "grad_norm": 1.9632991552352905,
      "learning_rate": 0.0001009522549227186,
      "loss": 0.4015,
      "step": 318000
    },
    {
      "epoch": 3.366470641167472,
      "eval_loss": 0.30872514843940735,
      "eval_runtime": 57.3582,
      "eval_samples_per_second": 2927.74,
      "eval_steps_per_second": 365.981,
      "step": 318000
    },
    {
      "epoch": 3.3675292847274787,
      "grad_norm": 2.09262752532959,
      "learning_rate": 0.0001009840143976286,
      "loss": 0.404,
      "step": 318100
    },
    {
      "epoch": 3.3685879282874853,
      "grad_norm": 2.2311325073242188,
      "learning_rate": 0.00010101577387253862,
      "loss": 0.4056,
      "step": 318200
    },
    {
      "epoch": 3.369646571847492,
      "grad_norm": 2.182379961013794,
      "learning_rate": 0.00010104753334744864,
      "loss": 0.4108,
      "step": 318300
    },
    {
      "epoch": 3.370705215407498,
      "grad_norm": 2.1070313453674316,
      "learning_rate": 0.00010107929282235866,
      "loss": 0.4074,
      "step": 318400
    },
    {
      "epoch": 3.3717638589675047,
      "grad_norm": 2.2812623977661133,
      "learning_rate": 0.00010111105229726866,
      "loss": 0.4014,
      "step": 318500
    },
    {
      "epoch": 3.3728225025275114,
      "grad_norm": 1.977981448173523,
      "learning_rate": 0.00010114281177217868,
      "loss": 0.404,
      "step": 318600
    },
    {
      "epoch": 3.373881146087518,
      "grad_norm": 2.362636089324951,
      "learning_rate": 0.0001011745712470887,
      "loss": 0.4096,
      "step": 318700
    },
    {
      "epoch": 3.3749397896475246,
      "grad_norm": 2.242283821105957,
      "learning_rate": 0.00010120633072199872,
      "loss": 0.4078,
      "step": 318800
    },
    {
      "epoch": 3.3759984332075312,
      "grad_norm": 2.365232229232788,
      "learning_rate": 0.00010123809019690873,
      "loss": 0.4031,
      "step": 318900
    },
    {
      "epoch": 3.377057076767538,
      "grad_norm": 2.231384515762329,
      "learning_rate": 0.00010126984967181874,
      "loss": 0.4051,
      "step": 319000
    },
    {
      "epoch": 3.377057076767538,
      "eval_loss": 0.30867084860801697,
      "eval_runtime": 57.2881,
      "eval_samples_per_second": 2931.324,
      "eval_steps_per_second": 366.429,
      "step": 319000
    },
    {
      "epoch": 3.3781157203275445,
      "grad_norm": 2.2710719108581543,
      "learning_rate": 0.00010130160914672876,
      "loss": 0.4043,
      "step": 319100
    },
    {
      "epoch": 3.379174363887551,
      "grad_norm": 2.3800547122955322,
      "learning_rate": 0.00010133336862163877,
      "loss": 0.4129,
      "step": 319200
    },
    {
      "epoch": 3.3802330074475573,
      "grad_norm": 2.4680755138397217,
      "learning_rate": 0.00010136512809654879,
      "loss": 0.4069,
      "step": 319300
    },
    {
      "epoch": 3.381291651007564,
      "grad_norm": 2.1505589485168457,
      "learning_rate": 0.0001013968875714588,
      "loss": 0.4044,
      "step": 319400
    },
    {
      "epoch": 3.3823502945675705,
      "grad_norm": 2.008131504058838,
      "learning_rate": 0.00010142864704636883,
      "loss": 0.4029,
      "step": 319500
    },
    {
      "epoch": 3.383408938127577,
      "grad_norm": 2.2632339000701904,
      "learning_rate": 0.00010146040652127885,
      "loss": 0.4057,
      "step": 319600
    },
    {
      "epoch": 3.3844675816875838,
      "grad_norm": 2.3161842823028564,
      "learning_rate": 0.00010149216599618886,
      "loss": 0.4083,
      "step": 319700
    },
    {
      "epoch": 3.3855262252475904,
      "grad_norm": 2.1905970573425293,
      "learning_rate": 0.00010152360787634976,
      "loss": 0.4072,
      "step": 319800
    },
    {
      "epoch": 3.386584868807597,
      "grad_norm": 2.06073260307312,
      "learning_rate": 0.00010155536735125978,
      "loss": 0.4096,
      "step": 319900
    },
    {
      "epoch": 3.387643512367603,
      "grad_norm": 2.326388359069824,
      "learning_rate": 0.0001015871268261698,
      "loss": 0.4043,
      "step": 320000
    },
    {
      "epoch": 3.387643512367603,
      "eval_loss": 0.3095273971557617,
      "eval_runtime": 57.1627,
      "eval_samples_per_second": 2937.755,
      "eval_steps_per_second": 367.233,
      "step": 320000
    },
    {
      "epoch": 3.38870215592761,
      "grad_norm": 2.4359638690948486,
      "learning_rate": 0.00010161888630107982,
      "loss": 0.404,
      "step": 320100
    },
    {
      "epoch": 3.3897607994876164,
      "grad_norm": 2.6581764221191406,
      "learning_rate": 0.00010165064577598984,
      "loss": 0.407,
      "step": 320200
    },
    {
      "epoch": 3.390819443047623,
      "grad_norm": 2.3337152004241943,
      "learning_rate": 0.00010168240525089985,
      "loss": 0.4009,
      "step": 320300
    },
    {
      "epoch": 3.3918780866076297,
      "grad_norm": 2.4585297107696533,
      "learning_rate": 0.00010171416472580987,
      "loss": 0.4005,
      "step": 320400
    },
    {
      "epoch": 3.3929367301676363,
      "grad_norm": 2.454479694366455,
      "learning_rate": 0.00010174592420071988,
      "loss": 0.4108,
      "step": 320500
    },
    {
      "epoch": 3.393995373727643,
      "grad_norm": 2.240776777267456,
      "learning_rate": 0.0001017776836756299,
      "loss": 0.4036,
      "step": 320600
    },
    {
      "epoch": 3.3950540172876496,
      "grad_norm": 2.377685308456421,
      "learning_rate": 0.0001018094431505399,
      "loss": 0.4101,
      "step": 320700
    },
    {
      "epoch": 3.3961126608476557,
      "grad_norm": 2.0551278591156006,
      "learning_rate": 0.00010184120262544992,
      "loss": 0.4066,
      "step": 320800
    },
    {
      "epoch": 3.3971713044076624,
      "grad_norm": 1.9884284734725952,
      "learning_rate": 0.00010187296210035994,
      "loss": 0.4067,
      "step": 320900
    },
    {
      "epoch": 3.398229947967669,
      "grad_norm": 2.2487523555755615,
      "learning_rate": 0.00010190472157526996,
      "loss": 0.4083,
      "step": 321000
    },
    {
      "epoch": 3.398229947967669,
      "eval_loss": 0.3080390989780426,
      "eval_runtime": 57.2266,
      "eval_samples_per_second": 2934.474,
      "eval_steps_per_second": 366.822,
      "step": 321000
    },
    {
      "epoch": 3.3992885915276756,
      "grad_norm": 2.122117042541504,
      "learning_rate": 0.00010193648105017996,
      "loss": 0.4007,
      "step": 321100
    },
    {
      "epoch": 3.400347235087682,
      "grad_norm": 2.3369274139404297,
      "learning_rate": 0.00010196824052508998,
      "loss": 0.4073,
      "step": 321200
    },
    {
      "epoch": 3.401405878647689,
      "grad_norm": 2.265803575515747,
      "learning_rate": 0.000102,
      "loss": 0.4086,
      "step": 321300
    },
    {
      "epoch": 3.4024645222076955,
      "grad_norm": 2.4355697631835938,
      "learning_rate": 0.00010203175947491002,
      "loss": 0.4097,
      "step": 321400
    },
    {
      "epoch": 3.4035231657677016,
      "grad_norm": 2.3123974800109863,
      "learning_rate": 0.00010206351894982002,
      "loss": 0.4028,
      "step": 321500
    },
    {
      "epoch": 3.4045818093277083,
      "grad_norm": 2.067430019378662,
      "learning_rate": 0.00010209527842473004,
      "loss": 0.4093,
      "step": 321600
    },
    {
      "epoch": 3.405640452887715,
      "grad_norm": 2.112673044204712,
      "learning_rate": 0.00010212703789964006,
      "loss": 0.407,
      "step": 321700
    },
    {
      "epoch": 3.4066990964477215,
      "grad_norm": 1.9244389533996582,
      "learning_rate": 0.00010215879737455008,
      "loss": 0.4017,
      "step": 321800
    },
    {
      "epoch": 3.407757740007728,
      "grad_norm": 2.7912025451660156,
      "learning_rate": 0.00010219023925471098,
      "loss": 0.4027,
      "step": 321900
    },
    {
      "epoch": 3.4088163835677348,
      "grad_norm": 2.3238842487335205,
      "learning_rate": 0.000102221998729621,
      "loss": 0.4009,
      "step": 322000
    },
    {
      "epoch": 3.4088163835677348,
      "eval_loss": 0.3088398575782776,
      "eval_runtime": 57.322,
      "eval_samples_per_second": 2929.592,
      "eval_steps_per_second": 366.212,
      "step": 322000
    },
    {
      "epoch": 3.4098750271277414,
      "grad_norm": 2.2363226413726807,
      "learning_rate": 0.00010225375820453102,
      "loss": 0.4042,
      "step": 322100
    },
    {
      "epoch": 3.410933670687748,
      "grad_norm": 2.151167154312134,
      "learning_rate": 0.00010228551767944104,
      "loss": 0.4033,
      "step": 322200
    },
    {
      "epoch": 3.411992314247754,
      "grad_norm": 2.3917956352233887,
      "learning_rate": 0.00010231727715435104,
      "loss": 0.4076,
      "step": 322300
    },
    {
      "epoch": 3.413050957807761,
      "grad_norm": 2.043602228164673,
      "learning_rate": 0.00010234903662926106,
      "loss": 0.4053,
      "step": 322400
    },
    {
      "epoch": 3.4141096013677674,
      "grad_norm": 2.141400098800659,
      "learning_rate": 0.00010238079610417108,
      "loss": 0.4054,
      "step": 322500
    },
    {
      "epoch": 3.415168244927774,
      "grad_norm": 2.166518449783325,
      "learning_rate": 0.0001024125555790811,
      "loss": 0.4076,
      "step": 322600
    },
    {
      "epoch": 3.4162268884877807,
      "grad_norm": 2.351602077484131,
      "learning_rate": 0.0001024443150539911,
      "loss": 0.4086,
      "step": 322700
    },
    {
      "epoch": 3.4172855320477873,
      "grad_norm": 2.0697476863861084,
      "learning_rate": 0.00010247607452890112,
      "loss": 0.402,
      "step": 322800
    },
    {
      "epoch": 3.418344175607794,
      "grad_norm": 2.2069287300109863,
      "learning_rate": 0.00010250783400381113,
      "loss": 0.4039,
      "step": 322900
    },
    {
      "epoch": 3.4194028191678,
      "grad_norm": 2.141774892807007,
      "learning_rate": 0.00010253959347872115,
      "loss": 0.3974,
      "step": 323000
    },
    {
      "epoch": 3.4194028191678,
      "eval_loss": 0.3069245517253876,
      "eval_runtime": 57.2789,
      "eval_samples_per_second": 2931.797,
      "eval_steps_per_second": 366.488,
      "step": 323000
    },
    {
      "epoch": 3.4204614627278067,
      "grad_norm": 2.2236411571502686,
      "learning_rate": 0.00010257135295363117,
      "loss": 0.4059,
      "step": 323100
    },
    {
      "epoch": 3.4215201062878133,
      "grad_norm": 2.259521007537842,
      "learning_rate": 0.00010260311242854117,
      "loss": 0.4033,
      "step": 323200
    },
    {
      "epoch": 3.42257874984782,
      "grad_norm": 2.3708877563476562,
      "learning_rate": 0.00010263487190345119,
      "loss": 0.4032,
      "step": 323300
    },
    {
      "epoch": 3.4236373934078266,
      "grad_norm": 2.30145525932312,
      "learning_rate": 0.00010266663137836121,
      "loss": 0.4021,
      "step": 323400
    },
    {
      "epoch": 3.424696036967833,
      "grad_norm": 2.247349739074707,
      "learning_rate": 0.00010269839085327123,
      "loss": 0.4064,
      "step": 323500
    },
    {
      "epoch": 3.42575468052784,
      "grad_norm": 2.1696605682373047,
      "learning_rate": 0.00010273015032818123,
      "loss": 0.4033,
      "step": 323600
    },
    {
      "epoch": 3.4268133240878464,
      "grad_norm": 2.1791868209838867,
      "learning_rate": 0.00010276190980309125,
      "loss": 0.4069,
      "step": 323700
    },
    {
      "epoch": 3.4278719676478526,
      "grad_norm": 2.463517665863037,
      "learning_rate": 0.00010279366927800127,
      "loss": 0.4047,
      "step": 323800
    },
    {
      "epoch": 3.4289306112078592,
      "grad_norm": 2.563746690750122,
      "learning_rate": 0.00010282511115816219,
      "loss": 0.4047,
      "step": 323900
    },
    {
      "epoch": 3.429989254767866,
      "grad_norm": 2.320695638656616,
      "learning_rate": 0.0001028568706330722,
      "loss": 0.4032,
      "step": 324000
    },
    {
      "epoch": 3.429989254767866,
      "eval_loss": 0.30796146392822266,
      "eval_runtime": 57.2046,
      "eval_samples_per_second": 2935.605,
      "eval_steps_per_second": 366.964,
      "step": 324000
    },
    {
      "epoch": 3.4310478983278725,
      "grad_norm": 2.1979780197143555,
      "learning_rate": 0.00010288863010798221,
      "loss": 0.4061,
      "step": 324100
    },
    {
      "epoch": 3.432106541887879,
      "grad_norm": 2.0417938232421875,
      "learning_rate": 0.00010292038958289223,
      "loss": 0.4034,
      "step": 324200
    },
    {
      "epoch": 3.4331651854478857,
      "grad_norm": 1.947831153869629,
      "learning_rate": 0.00010295214905780225,
      "loss": 0.4017,
      "step": 324300
    },
    {
      "epoch": 3.4342238290078924,
      "grad_norm": 2.142441511154175,
      "learning_rate": 0.00010298390853271225,
      "loss": 0.4049,
      "step": 324400
    },
    {
      "epoch": 3.4352824725678985,
      "grad_norm": 2.1648950576782227,
      "learning_rate": 0.00010301566800762227,
      "loss": 0.4069,
      "step": 324500
    },
    {
      "epoch": 3.436341116127905,
      "grad_norm": 2.07104754447937,
      "learning_rate": 0.00010304742748253229,
      "loss": 0.3986,
      "step": 324600
    },
    {
      "epoch": 3.437399759687912,
      "grad_norm": 2.3536376953125,
      "learning_rate": 0.0001030791869574423,
      "loss": 0.4048,
      "step": 324700
    },
    {
      "epoch": 3.4384584032479184,
      "grad_norm": 2.161447048187256,
      "learning_rate": 0.00010311094643235231,
      "loss": 0.4039,
      "step": 324800
    },
    {
      "epoch": 3.439517046807925,
      "grad_norm": 2.3789854049682617,
      "learning_rate": 0.00010314270590726233,
      "loss": 0.4082,
      "step": 324900
    },
    {
      "epoch": 3.4405756903679316,
      "grad_norm": 2.279639959335327,
      "learning_rate": 0.00010317446538217235,
      "loss": 0.406,
      "step": 325000
    },
    {
      "epoch": 3.4405756903679316,
      "eval_loss": 0.3075190484523773,
      "eval_runtime": 57.3315,
      "eval_samples_per_second": 2929.103,
      "eval_steps_per_second": 366.151,
      "step": 325000
    },
    {
      "epoch": 3.4416343339279383,
      "grad_norm": 2.17541241645813,
      "learning_rate": 0.00010320622485708236,
      "loss": 0.4057,
      "step": 325100
    },
    {
      "epoch": 3.442692977487945,
      "grad_norm": 2.169236898422241,
      "learning_rate": 0.00010323798433199237,
      "loss": 0.404,
      "step": 325200
    },
    {
      "epoch": 3.443751621047951,
      "grad_norm": 2.3490066528320312,
      "learning_rate": 0.00010326974380690239,
      "loss": 0.4035,
      "step": 325300
    },
    {
      "epoch": 3.4448102646079577,
      "grad_norm": 2.5410780906677246,
      "learning_rate": 0.0001033015032818124,
      "loss": 0.4039,
      "step": 325400
    },
    {
      "epoch": 3.4458689081679643,
      "grad_norm": 2.229645252227783,
      "learning_rate": 0.00010333326275672242,
      "loss": 0.4005,
      "step": 325500
    },
    {
      "epoch": 3.446927551727971,
      "grad_norm": 1.9867955446243286,
      "learning_rate": 0.00010336502223163244,
      "loss": 0.404,
      "step": 325600
    },
    {
      "epoch": 3.4479861952879776,
      "grad_norm": 2.2197744846343994,
      "learning_rate": 0.00010339678170654244,
      "loss": 0.4035,
      "step": 325700
    },
    {
      "epoch": 3.449044838847984,
      "grad_norm": 2.441770076751709,
      "learning_rate": 0.00010342854118145246,
      "loss": 0.4019,
      "step": 325800
    },
    {
      "epoch": 3.450103482407991,
      "grad_norm": 2.4651522636413574,
      "learning_rate": 0.00010345998306161338,
      "loss": 0.4035,
      "step": 325900
    },
    {
      "epoch": 3.451162125967997,
      "grad_norm": 2.256483793258667,
      "learning_rate": 0.00010349174253652339,
      "loss": 0.401,
      "step": 326000
    },
    {
      "epoch": 3.451162125967997,
      "eval_loss": 0.30657124519348145,
      "eval_runtime": 57.2609,
      "eval_samples_per_second": 2932.719,
      "eval_steps_per_second": 366.603,
      "step": 326000
    },
    {
      "epoch": 3.4522207695280036,
      "grad_norm": 1.9285573959350586,
      "learning_rate": 0.0001035235020114334,
      "loss": 0.4028,
      "step": 326100
    },
    {
      "epoch": 3.4532794130880102,
      "grad_norm": 2.0815589427948,
      "learning_rate": 0.00010355526148634342,
      "loss": 0.4064,
      "step": 326200
    },
    {
      "epoch": 3.454338056648017,
      "grad_norm": 2.254210948944092,
      "learning_rate": 0.00010358702096125344,
      "loss": 0.4027,
      "step": 326300
    },
    {
      "epoch": 3.4553967002080235,
      "grad_norm": 2.126683235168457,
      "learning_rate": 0.00010361878043616344,
      "loss": 0.4046,
      "step": 326400
    },
    {
      "epoch": 3.45645534376803,
      "grad_norm": 2.2479588985443115,
      "learning_rate": 0.00010365053991107346,
      "loss": 0.3969,
      "step": 326500
    },
    {
      "epoch": 3.4575139873280367,
      "grad_norm": 2.1380667686462402,
      "learning_rate": 0.00010368229938598348,
      "loss": 0.404,
      "step": 326600
    },
    {
      "epoch": 3.4585726308880433,
      "grad_norm": 2.1909027099609375,
      "learning_rate": 0.0001037140588608935,
      "loss": 0.4011,
      "step": 326700
    },
    {
      "epoch": 3.4596312744480495,
      "grad_norm": 1.9337987899780273,
      "learning_rate": 0.00010374581833580352,
      "loss": 0.4,
      "step": 326800
    },
    {
      "epoch": 3.460689918008056,
      "grad_norm": 1.9918938875198364,
      "learning_rate": 0.00010377757781071352,
      "loss": 0.4016,
      "step": 326900
    },
    {
      "epoch": 3.4617485615680628,
      "grad_norm": 2.2394049167633057,
      "learning_rate": 0.00010380933728562354,
      "loss": 0.4042,
      "step": 327000
    },
    {
      "epoch": 3.4617485615680628,
      "eval_loss": 0.3065211772918701,
      "eval_runtime": 57.2333,
      "eval_samples_per_second": 2934.131,
      "eval_steps_per_second": 366.779,
      "step": 327000
    },
    {
      "epoch": 3.4628072051280694,
      "grad_norm": 2.338575839996338,
      "learning_rate": 0.00010384109676053356,
      "loss": 0.4042,
      "step": 327100
    },
    {
      "epoch": 3.463865848688076,
      "grad_norm": 2.04085636138916,
      "learning_rate": 0.00010387285623544357,
      "loss": 0.3994,
      "step": 327200
    },
    {
      "epoch": 3.4649244922480826,
      "grad_norm": 2.638190984725952,
      "learning_rate": 0.00010390461571035358,
      "loss": 0.4022,
      "step": 327300
    },
    {
      "epoch": 3.4659831358080893,
      "grad_norm": 2.1640689373016357,
      "learning_rate": 0.0001039363751852636,
      "loss": 0.4001,
      "step": 327400
    },
    {
      "epoch": 3.4670417793680954,
      "grad_norm": 2.061173677444458,
      "learning_rate": 0.00010396813466017361,
      "loss": 0.4069,
      "step": 327500
    },
    {
      "epoch": 3.468100422928102,
      "grad_norm": 2.42564058303833,
      "learning_rate": 0.00010399989413508363,
      "loss": 0.4007,
      "step": 327600
    },
    {
      "epoch": 3.4691590664881087,
      "grad_norm": 1.7798008918762207,
      "learning_rate": 0.00010403165360999364,
      "loss": 0.4003,
      "step": 327700
    },
    {
      "epoch": 3.4702177100481153,
      "grad_norm": 1.9134066104888916,
      "learning_rate": 0.00010406341308490365,
      "loss": 0.3989,
      "step": 327800
    },
    {
      "epoch": 3.471276353608122,
      "grad_norm": 2.300907611846924,
      "learning_rate": 0.00010409485496506458,
      "loss": 0.4014,
      "step": 327900
    },
    {
      "epoch": 3.4723349971681285,
      "grad_norm": 2.396662950515747,
      "learning_rate": 0.0001041266144399746,
      "loss": 0.4035,
      "step": 328000
    },
    {
      "epoch": 3.4723349971681285,
      "eval_loss": 0.30536413192749023,
      "eval_runtime": 57.2943,
      "eval_samples_per_second": 2931.009,
      "eval_steps_per_second": 366.389,
      "step": 328000
    },
    {
      "epoch": 3.473393640728135,
      "grad_norm": 2.133662223815918,
      "learning_rate": 0.0001041583739148846,
      "loss": 0.4017,
      "step": 328100
    },
    {
      "epoch": 3.474452284288142,
      "grad_norm": 2.0824105739593506,
      "learning_rate": 0.00010419013338979462,
      "loss": 0.4068,
      "step": 328200
    },
    {
      "epoch": 3.4755109278481484,
      "grad_norm": 2.3114168643951416,
      "learning_rate": 0.00010422189286470463,
      "loss": 0.4024,
      "step": 328300
    },
    {
      "epoch": 3.4765695714081546,
      "grad_norm": 2.4910409450531006,
      "learning_rate": 0.00010425365233961465,
      "loss": 0.4068,
      "step": 328400
    },
    {
      "epoch": 3.477628214968161,
      "grad_norm": 2.178373336791992,
      "learning_rate": 0.00010428541181452466,
      "loss": 0.4041,
      "step": 328500
    },
    {
      "epoch": 3.478686858528168,
      "grad_norm": 2.4764912128448486,
      "learning_rate": 0.00010431717128943467,
      "loss": 0.4031,
      "step": 328600
    },
    {
      "epoch": 3.4797455020881745,
      "grad_norm": 2.2250757217407227,
      "learning_rate": 0.00010434893076434469,
      "loss": 0.406,
      "step": 328700
    },
    {
      "epoch": 3.480804145648181,
      "grad_norm": 2.113593578338623,
      "learning_rate": 0.00010438069023925471,
      "loss": 0.4004,
      "step": 328800
    },
    {
      "epoch": 3.4818627892081877,
      "grad_norm": 1.9024609327316284,
      "learning_rate": 0.00010441244971416471,
      "loss": 0.404,
      "step": 328900
    },
    {
      "epoch": 3.482921432768194,
      "grad_norm": 2.4382829666137695,
      "learning_rate": 0.00010444420918907473,
      "loss": 0.4019,
      "step": 329000
    },
    {
      "epoch": 3.482921432768194,
      "eval_loss": 0.3059450089931488,
      "eval_runtime": 57.2777,
      "eval_samples_per_second": 2931.858,
      "eval_steps_per_second": 366.495,
      "step": 329000
    },
    {
      "epoch": 3.4839800763282005,
      "grad_norm": 2.3580973148345947,
      "learning_rate": 0.00010447596866398475,
      "loss": 0.4037,
      "step": 329100
    },
    {
      "epoch": 3.485038719888207,
      "grad_norm": 2.11653470993042,
      "learning_rate": 0.00010450772813889477,
      "loss": 0.4026,
      "step": 329200
    },
    {
      "epoch": 3.4860973634482137,
      "grad_norm": 2.027986526489258,
      "learning_rate": 0.00010453948761380479,
      "loss": 0.3993,
      "step": 329300
    },
    {
      "epoch": 3.4871560070082204,
      "grad_norm": 2.009093999862671,
      "learning_rate": 0.00010457124708871479,
      "loss": 0.402,
      "step": 329400
    },
    {
      "epoch": 3.488214650568227,
      "grad_norm": 2.2072596549987793,
      "learning_rate": 0.00010460300656362481,
      "loss": 0.4056,
      "step": 329500
    },
    {
      "epoch": 3.4892732941282336,
      "grad_norm": 2.2815134525299072,
      "learning_rate": 0.00010463476603853483,
      "loss": 0.3996,
      "step": 329600
    },
    {
      "epoch": 3.4903319376882402,
      "grad_norm": 2.108050584793091,
      "learning_rate": 0.00010466652551344484,
      "loss": 0.4039,
      "step": 329700
    },
    {
      "epoch": 3.491390581248247,
      "grad_norm": 2.2257256507873535,
      "learning_rate": 0.00010469828498835485,
      "loss": 0.4025,
      "step": 329800
    },
    {
      "epoch": 3.492449224808253,
      "grad_norm": 2.3247475624084473,
      "learning_rate": 0.00010472972686851577,
      "loss": 0.3982,
      "step": 329900
    },
    {
      "epoch": 3.4935078683682597,
      "grad_norm": 1.8978211879730225,
      "learning_rate": 0.00010476148634342579,
      "loss": 0.3974,
      "step": 330000
    },
    {
      "epoch": 3.4935078683682597,
      "eval_loss": 0.305808961391449,
      "eval_runtime": 57.2942,
      "eval_samples_per_second": 2931.01,
      "eval_steps_per_second": 366.389,
      "step": 330000
    },
    {
      "epoch": 3.4945665119282663,
      "grad_norm": 2.0658254623413086,
      "learning_rate": 0.00010479324581833579,
      "loss": 0.4048,
      "step": 330100
    },
    {
      "epoch": 3.495625155488273,
      "grad_norm": 2.4518373012542725,
      "learning_rate": 0.00010482500529324581,
      "loss": 0.4021,
      "step": 330200
    },
    {
      "epoch": 3.4966837990482795,
      "grad_norm": 1.9787025451660156,
      "learning_rate": 0.00010485676476815583,
      "loss": 0.4027,
      "step": 330300
    },
    {
      "epoch": 3.497742442608286,
      "grad_norm": 2.1543354988098145,
      "learning_rate": 0.00010488852424306584,
      "loss": 0.3969,
      "step": 330400
    },
    {
      "epoch": 3.4988010861682923,
      "grad_norm": 2.0023717880249023,
      "learning_rate": 0.00010492028371797586,
      "loss": 0.4038,
      "step": 330500
    },
    {
      "epoch": 3.499859729728299,
      "grad_norm": 2.2865030765533447,
      "learning_rate": 0.00010495204319288587,
      "loss": 0.4008,
      "step": 330600
    },
    {
      "epoch": 3.5009183732883056,
      "grad_norm": 2.471853494644165,
      "learning_rate": 0.00010498380266779588,
      "loss": 0.4012,
      "step": 330700
    },
    {
      "epoch": 3.501977016848312,
      "grad_norm": 2.0215301513671875,
      "learning_rate": 0.0001050155621427059,
      "loss": 0.4012,
      "step": 330800
    },
    {
      "epoch": 3.503035660408319,
      "grad_norm": 2.137286901473999,
      "learning_rate": 0.00010504732161761592,
      "loss": 0.4033,
      "step": 330900
    },
    {
      "epoch": 3.5040943039683254,
      "grad_norm": 2.1444687843322754,
      "learning_rate": 0.00010507908109252592,
      "loss": 0.3983,
      "step": 331000
    },
    {
      "epoch": 3.5040943039683254,
      "eval_loss": 0.307007372379303,
      "eval_runtime": 57.2881,
      "eval_samples_per_second": 2931.322,
      "eval_steps_per_second": 366.428,
      "step": 331000
    },
    {
      "epoch": 3.505152947528332,
      "grad_norm": 1.9973374605178833,
      "learning_rate": 0.00010511084056743594,
      "loss": 0.4055,
      "step": 331100
    },
    {
      "epoch": 3.5062115910883387,
      "grad_norm": 2.261305570602417,
      "learning_rate": 0.00010514260004234596,
      "loss": 0.3973,
      "step": 331200
    },
    {
      "epoch": 3.5072702346483453,
      "grad_norm": 2.2396979331970215,
      "learning_rate": 0.00010517435951725598,
      "loss": 0.3984,
      "step": 331300
    },
    {
      "epoch": 3.5083288782083515,
      "grad_norm": 2.0005273818969727,
      "learning_rate": 0.00010520611899216598,
      "loss": 0.3953,
      "step": 331400
    },
    {
      "epoch": 3.509387521768358,
      "grad_norm": 1.884190320968628,
      "learning_rate": 0.000105237878467076,
      "loss": 0.4015,
      "step": 331500
    },
    {
      "epoch": 3.5104461653283647,
      "grad_norm": 2.327115535736084,
      "learning_rate": 0.00010526963794198602,
      "loss": 0.405,
      "step": 331600
    },
    {
      "epoch": 3.5115048088883714,
      "grad_norm": 1.8281224966049194,
      "learning_rate": 0.00010530139741689604,
      "loss": 0.4034,
      "step": 331700
    },
    {
      "epoch": 3.512563452448378,
      "grad_norm": 1.9459954500198364,
      "learning_rate": 0.00010533315689180604,
      "loss": 0.4007,
      "step": 331800
    },
    {
      "epoch": 3.5136220960083846,
      "grad_norm": 2.1318485736846924,
      "learning_rate": 0.00010536459877196696,
      "loss": 0.4021,
      "step": 331900
    },
    {
      "epoch": 3.5146807395683908,
      "grad_norm": 2.055861473083496,
      "learning_rate": 0.00010539635824687698,
      "loss": 0.4013,
      "step": 332000
    },
    {
      "epoch": 3.5146807395683908,
      "eval_loss": 0.3064895570278168,
      "eval_runtime": 57.2584,
      "eval_samples_per_second": 2932.844,
      "eval_steps_per_second": 366.619,
      "step": 332000
    },
    {
      "epoch": 3.5157393831283974,
      "grad_norm": 2.065600633621216,
      "learning_rate": 0.000105428117721787,
      "loss": 0.4013,
      "step": 332100
    },
    {
      "epoch": 3.516798026688404,
      "grad_norm": 2.1937344074249268,
      "learning_rate": 0.000105459877196697,
      "loss": 0.4013,
      "step": 332200
    },
    {
      "epoch": 3.5178566702484106,
      "grad_norm": 2.0191001892089844,
      "learning_rate": 0.00010549163667160702,
      "loss": 0.3993,
      "step": 332300
    },
    {
      "epoch": 3.5189153138084173,
      "grad_norm": 2.157681703567505,
      "learning_rate": 0.00010552339614651704,
      "loss": 0.4055,
      "step": 332400
    },
    {
      "epoch": 3.519973957368424,
      "grad_norm": 2.0511505603790283,
      "learning_rate": 0.00010555515562142706,
      "loss": 0.4015,
      "step": 332500
    },
    {
      "epoch": 3.5210326009284305,
      "grad_norm": 2.256700038909912,
      "learning_rate": 0.00010558691509633706,
      "loss": 0.4015,
      "step": 332600
    },
    {
      "epoch": 3.522091244488437,
      "grad_norm": 2.2898364067077637,
      "learning_rate": 0.00010561867457124708,
      "loss": 0.402,
      "step": 332700
    },
    {
      "epoch": 3.5231498880484438,
      "grad_norm": 1.933185338973999,
      "learning_rate": 0.0001056504340461571,
      "loss": 0.3933,
      "step": 332800
    },
    {
      "epoch": 3.52420853160845,
      "grad_norm": 2.140451431274414,
      "learning_rate": 0.00010568219352106711,
      "loss": 0.3968,
      "step": 332900
    },
    {
      "epoch": 3.5252671751684566,
      "grad_norm": 1.9086064100265503,
      "learning_rate": 0.00010571395299597713,
      "loss": 0.3993,
      "step": 333000
    },
    {
      "epoch": 3.5252671751684566,
      "eval_loss": 0.30657508969306946,
      "eval_runtime": 57.1582,
      "eval_samples_per_second": 2937.986,
      "eval_steps_per_second": 367.261,
      "step": 333000
    }
  ],
  "logging_steps": 100,
  "max_steps": 9446000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 5,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 5
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.159878626233549e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
